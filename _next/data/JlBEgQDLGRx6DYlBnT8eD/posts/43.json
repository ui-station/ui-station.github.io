{"pageProps":{"posts":[{"title":"FastAPI, Docker, 그리고 GCP를 활용하여 ML 솔루션 배포하는 방법","description":"","date":"2024-06-19 12:40","slug":"2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP","content":"\nFull Stack Data Science의 시리즈 중 5번째 기사입니다. 이 기사에서는 ML 기반 검색 API의 배포 방법을 안내합니다. 무수히 많은 방법으로 수행할 수 있지만, 여기에서는 거의 모든 머신 러닝 솔루션에 적용할 수 있는 간단한 3단계 접근법에 대해 설명합니다. 예시 코드는 GitHub 저장소에서 자유롭게 이용할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_0.png)\n\n머신 러닝이 모델 훈련에 관한 멋진 모델만이 아니라는 것을 생각하면, 실제로 모델 스스로는 가치를 만들어내지 않습니다. ML 모델을 ML 솔루션(즉, 가치 있는 것)으로 만들기 위해 \"배포\"해야 합니다.\n\n이를 다양한 형태로 구현할 수 있습니다. 예를 들어 사용자가 모델과 상호 작용할 수 있는 웹 인터페이스를 생성하거나, 기존 소프트웨어 시스템에 모델을 통합하거나, 개발자가 모델에 액세스할 수 있는 API를 설정하는 것 등이 있습니다 (OpenAI와 같은 사례를 생각해보세요).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기서 설명하는 3단계 전략은 모든 예제와 호환됩니다. 이는 다음으로 구성됩니다:\n\n- 추론 API 생성 (FastAPI 사용)\n- API 컨테이너화 (도커를 통해)\n- 클라우드 플랫폼에서 컨테이너 실행 (여기서는 GCP 사용)\n\n# FastAPI\n\n이 배포 전략의 첫 번째 단계는 모델을 API(즉, 응용 프로그램 프로그래밍 인터페이스)로 랩핑하는 것입니다. 간단히 말해, API를 사용하면 응용 프로그램과 프로그래밍 방식으로 상호 작용할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 단계를 수행하는 한 가지 방법은 파이썬 함수를 API 엔드포인트로 변환하는 매우 쉬운 방법을 제공하는 Python 라이브러리인 FastAPI를 사용하는 것입니다. 아래 코드는 구체적인 예제를 제공합니다.\n\n## Docker\n\n우리의 추론 API를 직접 클라우드에 배포할 수 있지만, 먼저 \"컨테이너화\"하는 것이 좋습니다. 이때 Docker가 필요합니다.\n\nDocker를 사용하면 API의 종속성을 모두 포함하는 가벼운 래퍼를 생성할 수 있어서 새로운 컴퓨터에서 더 쉽게 구동할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n작업은 2 단계 프로세스를 통해 수행됩니다. 첫째, 우리는 Docker 이미지를 생성합니다. 이는 기본적으로 시스템에 API를 제로에서 어떻게 구동할지 알려주는 레시피입니다 (걱정하지 마세요, 만들기 쉽습니다). 둘째, Docker가 설치된 시스템에서 이미지를 실행할 수 있습니다. 실행 중인 이미지를 컨테이너라고 하며, 이는 더 큰 시스템에 있는 작은 가상 머신과 같습니다.\n\n# Google Cloud Run\n\n마지막으로, Docker 이미지를 실행할 컴퓨팅 리소스가 필요합니다. 물론 노트북에서 이 작업을 수행할 수도 있지만 (아마 좋은 아이디어는 아닙니다), 온프레미스 서버나 클라우드 제공업체를 통해 이를 수행할 수 있습니다.\n\n여기서는 Google Cloud Run을 사용하여 Docker 컨테이너를 실행하는 GCP 서비스를 사용합니다. 이 서비스에는 무료 티어도 있으므로 불필요한 비용이 발생하지 않고 프로젝트를 배포할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 예시 코드: 시맨틱 검색 API 배포하기\n\n기본 개념을 이해했으니, 실제 코드에서 이 프로세스가 어떻게 보이는지 살펴봅시다. 아래 예시는 이 시리즈의 이전 기사들을 바탕으로 구축되었으며, 제 유튜브 비디오의 제목과 대본을 가져와 텍스트 임베딩으로 변환한 것을 사용합니다.\n\n간단히 말해, 텍스트 임베딩은 텍스트의 의미론적인 의미 있는 숫자 표현으로, 새로운 종류의 검색(시맨틱 검색이라고도 함)을 가능하게 합니다.\n\n여기에서는 제 유튜브 비디오의 모든 제목과 대본에 대한 시맨틱 검색 시스템을 위한 API를 구축하고 배포할 것입니다. 이 API는 Hugging Face spaces에서 실행되는 실시간 검색 애플리케이션의 백엔드입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 앱의 백엔드와 프론트엔드의 코드 저장소가 모두 무료로 제공됩니다.\n\n## 단계 1: API 만들기\n\nFastAPI를 사용하면 기존의 Python 스크립트를 몇 줄의 추가 코드로 API로 변환하는 것이 매우 쉽습니다. 이게 바로 그 모습입니다.\n\n먼저 유용한 라이브러리를 import할 거에요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nfrom fastapi import FastAPI\nimport polars as pl\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics import DistanceMetric\nimport numpy as np\nfrom app.functions import returnSearchResultIndexes\n```\n\n이제 우리는 시맨틱 검색 기능의 구성 요소를 정의할 겁니다. 구체적으로 텍스트 임베딩 모델, 우리가 검색하려는 비디오들의 제목 및 대본 임베딩, 그리고 사용자 쿼리에 가장 관련성 높은 비디오를 평가하는 거리 측정 기준입니다. 시맨틱 검색에 대해 더 깊게 알아보고 싶다면, 이에 대해 이전에 다룬 글을 참조해주세요.\n\n```js\n# define model info\nmodel_name = 'all-MiniLM-L6-v2'\n\n# load model\nmodel = SentenceTransformer(model_name)\n\n# load video index\ndf = pl.scan_parquet('app/data/video-index.parquet')\n\n# create distance metric object\ndist_name = 'manhattan'\ndist = DistanceMetric.get_metric(dist_name)\n```\n\n이제 API 작업을 정의합니다. 여기서 3개의 GET 요청을 생성할 것입니다. 첫 번째 요청은 아래 코드 블록에 표시되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# FastAPI 객체 생성\napp = FastAPI()\n\n# API 동작\n@app.get(\"/\")\ndef health_check():\n    return {'health_check': 'OK'}\n```\n\n위 블록에서는 FastAPI() 클래스를 사용하여 새 FastAPI 애플리케이션을 초기화하고 \"health check\" 엔드포인트를 만듭니다.\n\n이를 위해 입력이 없고 \"health_check\" 키와 값이 \"OK\"인 사전을 반환하는 Python 함수를 정의합니다. 이 함수를 API 엔드포인트로 변환하려면 단순히 데코레이터를 추가하고 엔드포인트의 경로를 지정하면 됩니다. 여기서는 루트인 즉, \"/\"를 사용합니다.\n\n또 다른 예제를 살펴보겠습니다. 여기서는 API에 대한 자세한 정보를 반환하는 info라는 엔드포인트가 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n@app.get(\"/info\")\ndef info():\n    return {'name': 'yt-search', 'description': \"Shaw Talebi의 YouTube 비디오를 검색하는 API입니다.\"}\n```\n\n이 엔드포인트는 헬스 체크와 매우 유사한 것을 볼 수 있습니다. 그러나 이것은 \"/info\" 엔드포인트에 위치합니다.\n\n마지막으로 사용자 쿼리를 받아 가장 관련 있는 비디오의 제목과 ID를 반환하는 검색 엔드포인트를 만들어 봅시다.\n\n```js\n@app.get(\"/search\")\ndef search(query: str):\n    idx_result = returnSearchResultIndexes(query, df, model, dist)\n    return df.select(['title', 'video_id']).collect()[idx_result].to_dict(as_series=False)\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 엔드포인트에는 입력이 필요합니다: 사용자의 쿼리입니다. 이 쿼리는 다른 스크립트에 정의된 또 다른 Python 함수로 전달됩니다. 이 함수는 검색에 대한 모든 수학 연산을 수행합니다. 여기서 자세히 다루지는 않겠지만, 궁금한 독자는 코드를 GitHub에서 볼 수도 있고 YouTube에서 검색 함수의 코드 설명을 볼 수도 있습니다.\n\n이 함수는 검색 결과의 행 번호만 df 데이터프레임에서 반환하므로, 우리는 이 출력을 사용하여 관심 있는 제목과 비디오 ID를 가져와서 이를 Python 사전으로 반환해야 합니다. API 엔드포인트의 모든 출력이 사전이어야 하는데요, 이는 API의 표준 JSON 형식을 준수하기 때문입니다.\n\n위 코드 블록에서 설명한대로, 두 개의 외부 파일인 app/functions.py 및 app/data/video-index.parquet을 참조합니다. 이는 다음 디렉토리 구조를 시사합니다.\n\n![image](https://example.com/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 API를 로컬에서 실행하려면 루트 디렉토리로 이동하여 다음 명령을 실행할 수 있습니다.\n\n```js\nuvicorn app.main:app --host 0.0.0.0 --port 8080\n```\n\nuvicorn은 FastAPI를 사용하여 작성한 웹 애플리케이션을 실행할 수 있게 해주는 파이썬 라이브러리입니다. 이 명령은 이 API를 로컬에서 http://0.0.0.0:8080에서 실행합니다. 나중에 Google Cloud Run에 배포할 때 이 호스트와 포트를 사용하는 이유를 나준내게 될 것입니다.\n\n## 단계 2: 도커 이미지 생성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우와, 우리 API가 로컬에서 작동하고 있어요! 이제 클라우드에서 실행할 수 있도록 다음 단계를 진행해 봐요.\n\n이를 위해서 API용 Docker 이미지를 생성할 거에요. 이를 위해 Dockerfile, requirements.txt, 그리고 app/**init**.py 이 3가지 파일을 만들어야 해요. 우리 디렉토리는 아래와 같이 보여야 해요.\n\n![이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_2.png)\n\nDockerfile은 Docker 이미지를 실행하는 단계별 지침을 포함하고 있어요. requirements.txt는 API를 실행하는 데 필요한 Python 라이브러리(버전 포함)를 지정해요. 마지막으로 app/**init**.py 파일은 app 폴더를 Python 패키지로 지정해주어, 컨테이너에서 실행될 때 Python이 API 코드를 찾고 적절하게 가져올 수 있도록 해줘요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 Dockerfile 내부의 내용입니다.\n\n```js\n# python 기본 이미지에서 시작\nFROM python:3.10-slim\n\n# 작업 디렉토리 변경\nWORKDIR /code\n\n# 요구 사항 파일을 이미지에 추가\nCOPY ./requirements.txt /code/requirements.txt\n\n# Python 라이브러리 설치\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\n# Python 코드 추가\nCOPY ./app/ /code/app/\n\n# 기본 명령어 지정\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n```\n\n첫 번째 줄은 기존에 Python 3.10이 설치된 이미지 위에 저희의 이미지를 부트스트랩합니다. 다음으로 작업 디렉토리를 루트에서 /code로 변경합니다.\n\n그런 다음 요구 사항 파일을 코드베이스에서 Docker 이미지로 복사합니다. 이를 통해 pip를 사용하여 요구 사항을 설치할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 다음으로, API에 대한 모든 코드를 복사합니다.\n\n참고: Python 패키지를 먼저 복사하고 설치했습니다. 이렇게 함으로써 요구 사항의 설치를 캐시할 수 있습니다. 개발 중에 빠르게 Docker 이미지를 실행할 때 의존성을 설치하는 데 몇 분을 기다릴 필요가 없도록 도와줍니다.\n\n마지막으로, 개발 중에 API를 실행할 때 지역에서 실행했던 것과 동일한 기본 명령을 지정합니다.\n\n## 단계 3: Google Cloud에 배포\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 시점에서 우리는 Docker 이미지를 빌드하고 Docker Hub에 푸시하여 여러 다른 클라우드 서비스에 쉽게 배포할 수 있습니다. 하지만 여기서는 대안 전략을 따를 거에요.\n\n대신에, 우리 모든 코드를 GitHub에 푸시할 거에요. 그럼 바로 이 코드를 Google Cloud Run에 컨테이너 배포할 수 있어요. 이 방법에는 두 가지 주요 장점이 있어요.\n\n첫째로, 로컬 시스템과 Google Cloud Run이 사용하는 시스템 아키텍처 간의 차이를 해결하느라 시간을 들일 필요가 없어요 (특히 저는 Mac이 ARM64로 동작하기 때문에 이 문제가 있었어요). 둘째로, GitHub 리포지토리에서 배포함으로써 지속적인 배포가 가능해져요. 그래서 API를 업데이트하고 싶다면, 그냥 새 코드를 리포지토리에 푸시하면 새 컨테이너가 자동적으로 생성돼요.\n\n우리는 새 GitHub 리포지토리를 만들면서 시작해볼게요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_3.png\" />\n\n이제 리포지토리를 복제하고 코드를 추가한 후 GitHub로 푸시합니다. 코드를 추가한 후 디렉토리 구조는 다음과 같이 보입니다.\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_4.png\" />\n\n코드가 준비되었으면 새 Google Cloud Platform 프로젝트를 만들 수 있습니다. GCP 콘솔로 이동하여 프로젝트 목록을 클릭한 다음 \"새 프로젝트\"를 선택하여 진행합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_5.png\" />\n\n프로젝트가 생성되면 해당 프로젝트를 열고 검색 창에 \"cloud run\"을 입력할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_6.png\" />\n\n그것을 열면 \"CREAT SERVICE\"를 클릭할 것입니다. 이렇게 하면 서비스를 구성할 수 있는 페이지가 열립니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 GitHub에서 서비스를 배포할 옵션을 선택합니다. 그런 다음 \"CLOUD BUILD로 설정\"을 클릭하세요.\n\n[이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_7.png)\n\n저장소 소스로는 GitHub을 선택하고 방금 만든 저장소를 선택합니다.\n\n[이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지점을 ^main$으로 유지하고 \"Build Type\"을 Dockerfile로 선택합니다.\n\n![이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_9.png)\n\n다음으로, 서비스 구성 화면으로 돌아갑니다. 서비스의 이름을 마음대로 지정할 수 있습니다 (저는 자동 생성된 이름을 그대로 두겠습니다). 지역은 us-central1로 남겨두겠습니다. 이 지역은 가장 저렴한 컴퓨팅 옵션을 제공하는 Tier 1이기 때문에 이 예시에서는 무료입니다.\n\n간단히 유지하려면 \"인증되지 않은 호출 허용\"을 선택합니다. 물론 대부분의 시스템에는 인증이 필요할 것입니다. 그런 다음, 나머지를 기본값으로 남겨둡니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 \"컨테이너, 볼륨, 네트워킹, 보안\" 아래에서 컨테이너를 편집하여 1 GiB의 메모리를 할당하세요. Dockerfile에서 구성한 대로 PORT가 8080으로 설정되어 있기 때문에 이것을 변경하시면 안 됩니다.\n\n나머지 설정은 기본값으로 그대로 두고 화면 아래의 \"생성\"을 클릭하세요. 수 분 후 컨테이너가 활성화될 것입니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_12.png)\n\n그런 다음 페이지 상단 근처에 지정된 URL을 사용하여 API에 액세스할 수 있습니다. 링크를 클릭하면 루트 엔드포인트가 열립니다. 이 엔드포인트는 건강 상태 확인이었습니다.\n\n![image](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_13.png)\n\n다음 URL을 사용하여 검색 API에 대한 GET 요청을 수동으로 실행할 수 있습니다: [여기에 앱의 URL 입력]/search?query=LLMs. 이를 통해 LLMs와 관련된 비디오를 검색할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_14.png\" />\n\n## 보너스: UI에 통합하기\n\nAPI 백엔드를 설정한 후, 사용자 친화적 인터페이스에 연결할 수 있습니다. 저는 Hugging Face Spaces를 통해 이를 수행합니다. 이 곳은 완전히 무료로 ML 앱을 호스팅합니다.\n\n이것이 같은 검색이 UI를 통해 어떻게 보이는지입니다. 여기서 UI를 테스트하고 코드를 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](https://miro.medium.com/v2/resize:fit:1200/1*St0OCAxBpqORc95WDpq4Pg.gif)\n\n# 결론\n\n데이터 과학은 멋진 모델을 훈련시키는 것 이상의 의미를 가지고 있습니다. 문제를 해결하고 가치를 창출하는 것이 중요합니다. 종종, 이를 위해서는 모델을 배포하여 최대 효과를 발휘할 수 있는 환경으로 이전해야 합니다. 여기에서는 FastAPI, Docker 및 GCP를 사용하여 ML 모델을 배포하는 간단한 3단계 전략을 살펴보았습니다.\n\n풀 스택 데이터 과학 시리즈를 마치는 글이지만, 이 글들은 이 검색 도구를 생성하는 과정에 관련된 실험에 대한 보너스 비디오가 포함된 YouTube 플레이리스트와 함께 제공됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nFull Stack Data Science에 관해 더 알아보기 👇\n\n# 자료\n\n연결하기: [내 웹사이트](링크) | 전화 상담 예약\n\n소셜 미디어: [YouTube 🎥](링크) | [LinkedIn](링크) | [Twitter](링크)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSupport: 커피 한 잔 사주세요 ☕️\n","ogImage":{"url":"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_0.png","tag":["Tech"],"readingTime":16},{"title":"컨테이너화된 모델과 작업 보안하기","description":"","date":"2024-06-19 12:37","slug":"2024-06-19-SecuringyourContainerisedModelsandWorkloads","content":"\n컨테이너화는 이제 많은 어플리케이션을 배포하는 주요 수단이 되었으며, Docker가 이를 주도하며 보급되고 있습니다. 그 인기에 따라 공격 위험이 증가하고 있습니다. 따라서 Docker 어플리케이션을 안전하게 지킬 필요가 있습니다. 이를 위한 가장 기본적인 방법은 컨테이너 내 사용자를 루트 사용자가 아닌 일반 사용자로 설정하는 것입니다.\n\n```js\n컨텐츠\n========\n\n왜 루트 사용자가 아닌 사용자를 사용해야 하는가?\n\n기본 일반 사용자로서 할 수 있는 일과 할 수 없는 일\n\n네 가지 시나리오\n  1) 호스트에서 모델 제공 (읽기 전용)\n  2) 데이터 처리 파이프라인 실행 (컨테이너 내에서 쓰기)\n  3) 라이브러리가 자동으로 파일 작성 (컨테이너 내에서 쓰기)\n  4) 훈련된 모델 저장 (호스트에 쓰기)\n\n요약\n```\n\n# 왜 루트 사용자가 아닌 사용자를 사용해야 하는가?\n\n혹은 왜 루트 사용자를 사용하지 말아야 하는가? 아래의 가짜 아키텍처 예제를 살펴봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Containerized Security](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png)\n\n보안은 종종 다층 접근법으로 간주됩니다. 공격자가 컨테이너에 들어갈 경우 사용자로서 가지는 권한이 첫 번째 방어층이 됩니다. 만약 컨테이너 사용자가 루트 액세스를 할당받는다면, 공격자는 컨테이너 내 모든 것을 자유롭게 제어할 수 있습니다. 이러한 넓은 액세스로 인해 잠재적인 취약점을 이용하여 호스트로 탈출하고 모든 연결된 시스템에 완전한 액세스를 획들할 수도 있습니다. 그 결과는 심각하며 다음과 같습니다:\n\n- 저장된 비밀 정보를 회수\n- 트래픽을 가로채거나 방해\n- 암호화 채굴과 같은 악성 서비스 실행\n- 데이터베이스와 같은 연결된 민감한 서비스에 액세스 획득\n\n![Containerized Security](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n와우, 그건 정말 무섭게 들리네요! 그러나 해결 방법은 간단합니다. 컨테이너를 루트 사용자가 아닌 다른 사용자로 변경하세요!\n\n우리가 나머지 기사를 읽기 전에, 리눅스 권한과 액세스 권한에 대한 좋은 이해가 없다면, 제 이전 기사를 꼭 확인해 보세요 [2].\n\n# 기본 비루트 사용자로서 할 수 있고 할 수 없는 것\n\n기본 비루트 사용자로 간단한 도커 어플리케이션을 만들어 보겠습니다. 아래의 도커 파일을 사용하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# create a dummy py file\nRUN echo \"print('I can run an existing py file')\" > example.py\n\n# create & switch to non-root user\nRUN adduser --no-create-home nonroot\nUSER nonroot\n```\n\nMake sure to build the image and create a container using the following commands:\n\n```js\ndocker build -t test .\ndocker run -it test bash\n```\n\nOnce you are inside the container, feel free to try out various commands. Keep in mind that certain actions like writing to restricted directories or installing software may not be permitted due to restricted permissions.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_2.png\" />\n\n반대로, 우리는 모든 종류의 읽기 권한을 실행할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_3.png\" />\n\n파이썬이 설치되어 있기 때문에 약간 독특합니다. ls -l $(which python)을 실행하면 파이썬 인터프리터에 완전한 권한이 있음을 볼 수 있습니다. 따라서 Dockerfile에서 처음에 만든 example.py 파일과 같은 기존의 파이썬 파일을 실행할 수 있습니다. 심지어 파이썬 콘솔에 들어가 간단한 명령을 실행할 수도 있습니다. 그러나 비 루트 사용자로 전환하면 다른 시스템 쓰기 권한이 제거된 것을 알 수 있습니다. 그렇기 때문에 스크립트를 생성하거나 수정하거나 파이썬을 사용해 쓰기 명령을 실행할 수 없음을 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_4.png)\n\n시스템 전반적인 제한은 보안에 좋지만, 특정 파일 및 디렉터리에 대한 쓰기 권한이 필요한 경우가 많이 발생하며, 그러한 허용 사항에 대응해야 합니다.\n\n다음 섹션에서는 기계 학습 운영 수명 주기의 네 가지 시나리오 예제를 제공합니다. 이러한 예제를 통해 대부분의 다른 경우에 대한 구현 방법을 이해할 수 있을 것입니다.\n\n# 네 가지 시나리오\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 1) 호스트에서 모델 제공하기 — 읽기 전용\n\n모델을 제공할 때, 추론 및 서빙 스크립트를 활용하여 모델을 로드하고 API를 통해 노출시킵니다 (예: Flask, FastAPI) 입력을 받도록 합니다. 때로는 모델이 호스트 머신에서 로드되어 이미지와 분리되어 이미지 크기가 최적으로 작고, 이미지를 다시 로드할 경우 반복적인 모델 다운로드 없이 최적으로 빠르게 할 수 있도록 합니다. 그런 다음 모델은 바인드-마운트 볼륨을 통해 컨테이너로 전달되어 로드되고 제공됩니다.\n\n<img src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_5.png\" />\n\n이것은 비루한 사용자를 구현하는 가장 번거롭지 않은 방법일 것입니다. 기본적으로 모든 사용자에게 부여되는 읽기 권한만 필요하기 때문입니다. 아래는 그 작업이 어떻게 이루어지는지를 보여주는 샘플 Dockerfile입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Dockerfile\n\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip3 install --no-cache-dir --upgrade pip~=23.2.1 \\\n && pip3 install --no-cache-dir -r requirements.txt\n\nCOPY ./project/ /app\n\n# add non-root user ---------------------\n\nRUN adduser --no-create-home nonroot\n\n# switch from root to non-root user -----\n\nUSER nonroot\n\nCMD [\"python\", \"inference.py\"]\n\n이 Dockerfile은 먼저 nonroot라는 새로운 시스템 사용자를 만드는 두 가지 간단한 명령어를 가지고 있습니다. 두 번째로, 마지막 CMD 라인 바로 전에 루트에서 nonroot 사용자로 전환됩니다. 기본 non-root 사용자의 경우 쓰기 및 실행 권한이 없기 때문에, 이전 단계에서 필요한 파일을 설치하거나 복사하거나 조작할 수 없습니다.\n\n이제 Docker에서 non-root 사용자를 할당하는 방법을 알았으니, 다음 단계로 넘어가 봅시다.\n\n## 2) 데이터 처리 파이프라인 실행하기 — 컨테이너 내에서 작성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가끔은 작업을 실행하기 위해 일시적인 파일을 저장하고 싶을 때가 있습니다. 예를 들어, 데이터 전처리 작업을 한다고 가정해봅시다. 파일을 추가하고 삭제하는 작업으로 이루어져 있죠. 파일이 영구적이지 않기 때문에 이런 작업은 컨테이너 내에서 수행할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_6.png)\n\n그러나 루트가 아닌 사용자를 사용한다면 쓰기 권한이 필요할 것입니다. 이를 위해 chown(소유자 변경) 명령을 사용하여 쓰기 액세스가 필요한 특정 폴더에 소유권을 할당해야 합니다. 이 작업을 완료하면 사용자를 루트가 아닌 사용자로 전환할 수 있습니다.\n\n```js\n# Dockerfile\n\n# ....\n\n# 루트가 아닌 사용자 추가 및 처리 폴더에 소유권 부여\nRUN adduser --no-create-home nonroot && \\\n    mkdir processing && \\\n    chown nonroot processing\n\n# 루트에서 루트가 아닌 사용자로 전환\nUSER nonroot\n\nCMD [\"python\", \"preprocess.py\"]\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 3) 라이브러리가 파일을 자동으로 작성하는 경우 - 컨테이너 내에서 작성\n\n이전 예시에서는 우리가 직접 만든 파일을 작성하는 방법을 보여줬어요. 그러나 사용하는 라이브러리가 파일과 디렉토리를 자동으로 만드는 경우가 흔합니다. 컨테이너를 실행해 보고 쓰기 권한이 거부되는 것을 알 수 있을 때 그것들이 만들어진 것임을 알게 될 거예요.\n\n저는 두 가지 예시를 보여드릴 거에요. 하나는 여러 프로세스를 관리하는 데 사용되는 supervisor에서 가져왔고, 다른 하나는 huggingface에서 모델을 다운로드할 때 사용하는 huggingface-hub에서 가져왔어요. 이러한 권한 오류들은 우리가 루트가 아닌 사용자로 전환할 때 볼 수 있을 거에요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Securing your Containerised Models and Workloads](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_8.png)\n\n![Securing your Containerised Models and Workloads](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_9.png)\n\n두 개의 슈퍼바이저 파일에 대해서 먼저 빈 파일로 생성하고 소유권 권한을 할당할 수 있습니다. Huggingface-hub 다운로드 문제에 대해 이미 오류 로그에서 TRANSFORMERS_CACHE 변수를 통해 다운로드 디렉토리를 변경할 수 있다는 힌트가 있었습니다. 따라서 먼저 디렉토리 변수를 할당하고, 디렉토리를 생성한 후 소유권을 할당할 수 있습니다.\n\n```js\n# Dockerfile\n\n# ....\n\n# non-root 사용자 추가 ................\n# huggingface 다운로드 디렉토리 변경\nENV TRANSFORMERS_CACHE=/app/model\n\nRUN adduser --no-create-home nonroot && \\\n    # 슈퍼바이저 파일 및 huggingfacehub 디렉토리 생성\n    touch /app/supervisord.log /app/supervisord.pid && \\\n    mkdir $TRANSFORMERS_CACHE && \\\n    # 슈퍼바이저 및 huggingfacehub 쓰기 권한 부여\n    chown nonroot /app/supervisord.log && \\\n    chown nonroot /app/supervisord.pid && \\\n    chown nonroot $TRANSFORMERS_CACHE\nUSER nonroot\n\nCMD [\"supervisord\", \"-c\", \"conf/supervisord.conf\"]\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n물론 여기에 제시된 것과 약간 다른 다른 예제가 있을 수 있습니다만, 쓰기 권한을 최소화하는 개념은 동일할 것입니다.\n\n## 4) 훈련된 모델 저장하기 — 호스트에 쓰기\n\n모델을 훈련하는 데 컨테이너를 사용하고 그 모델을 호스트에 쓰기를 원한다고 가정해 봅시다. 예를 들어, 모델을 준비하여 다른 작업에서 평가하거나 배포하기 위해 호스트에 쓰려고 하는 경우입니다. 이 경우에는 모델 파일을 쓰기 위해 컨테이너 디렉토리를 호스트 디렉토리에 연결하여 모델 파일을 기록해야 합니다. 이를 바인드 마운트라고도 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저, 우리는 nonroot를 위한 그룹과 사용자를 만들어야 합니다. 각각에 대해 고유한 ID를 지정하는데, 이 경우에 우리는 1001을 사용합니다 (1000 이상의 아무 숫자나 상관없습니다). 그런 다음, 모델을 저장할 모델 디렉토리를 생성합니다.\n\nScenario 2와 비교하여 여기서의 차이점은 모델 디렉토리에 대해 쓰기 권한을 설정하는 데 chown이 필요하지 않다는 것입니다. 왜냐하면?\n\n```js\n# Dockerfile\n\n# ....\n# add non-root group/user & create model folder\nENV UID=1001\nRUN addgroup --gid $UID nonroot && \\\n    adduser --uid $UID --gid $UID --no-create-home nonroot && \\\n    mkdir model\n\n# switch from root to non-root user\nUSER nonroot\n\nCMD [\"python\", \"train.py\"]\n```\n\n이는 bind-mounted 디렉토리의 권한이 호스트 디렉토리에서 결정되기 때문입니다. 따라서 우리는 호스트에서 다시 동일한 사용자를 만들어야 하며, 사용자 ID가 동일한지 확인해야 합니다. 그런 다음에 호스트에 모델 디렉토리를 만들고 nonroot 사용자에게 소유자 권한을 부여합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 호스트 터미널에서\n\n# 동일한 사용자 및 그룹 추가\naddgroup --gid 1001\nadduser --uid 1001 --gid 1001 --no-create-home nonroot\n# 바인드 마운트할 모델 디렉토리 만들고 nonroot를 소유자로 설정\nmkdir /home/model\nchown nonroot /home/model\n```\n\n바인드 마운트는 보다 유연성을 제공하기 위해 일반적으로 docker-compose.yml 파일이나 docker run 명령어에서 지정됩니다. 아래는 전자의 예시입니다.\n\n```js\nversion: \"3.5\"\n\nservices:\n    modeltraining:\n        container_name: modeltraining\n        build:\n            dockerfile: Dockerfile\n        volumes:\n            - type: bind\n              source: /home/model # 호스트 디렉토리\n              target: /app/model  # 컨테이너 디렉토리\n```\n\n그리고 후자에 대한 예시는 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndocker run -d --name modeltraining -v /home/model:/app/model <image_name>\n```\n\n아무거나 실행하시면, 비루트 사용자로 스크립트를 실행할 수 있음을 확인하실 수 있을 거예요.\n\n# 요약\n\n우리는 비루트 사용자를 할당하고도 컨테이너가 원하는 작업을 수행할 수 있는 방법을 살펴보았어요. 이는 특정 쓰기 권한이 필요할 때 주로 관련이 있어요. 그저 두 가지 기본 개념만 알면 돼요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 컨테이너에서의 쓰기 권한을 위해서는 Dockerfile에서 chown을 사용하세요.\n- 바인드 마운트를 위한 쓰기 권한은 호스트에서 동일한 비루트 사용자를 생성하고 호스트 디렉토리에서 chown을 사용하세요.\n\n루트 사용자로 일부 테스트를 실행하기 위해 도커 컨테이너로 들어가야할 때 다음 명령어를 사용할 수 있어요.\n\n```js\ndocker exec -it -u 0 <컨테이너_아이디/이름> bash\n```\n\n# 참고자료\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- [1] Wong et al. (2023) 컨테이너 보안에 관한: 위협 모델링, 공격 분석 및 완화 전략. 컴퓨터 및 보안, 제 128권.\n- [2] Linux 권한 및 접근 권한에 관한 이전 게시물: https://medium.com/@teosiyang/securing-linux-servers-with-two-commands-de5b565dc104\n","ogImage":{"url":"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png"},"coverImage":"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png","tag":["Tech"],"readingTime":13},{"title":"마이크로서비스 이해 소프트웨어 아키텍처에 대한 현대적인 접근법","description":"","date":"2024-06-19 12:34","slug":"2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture","content":"\n마이크로서비스\n\n마이크로서비스와 보안\n\n사가 패턴: 코레오그래피와 오케스트레이션\n\nAXON을 활용한 사가\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSage와 Eventuate를 이용한 트랜잭션 외부함으로 패턴 구현하기\n\n마이크로서비스에서의 전파\n\n# 소개\n\n이 블로그에서는 소프트웨어 개발의 풍경을 변화시킨 혁신적인 접근 방식인 마이크로서비스 아키텍처의 매력적인 세계에 대해 탐구해 보겠습니다. Netflix와 같은 선두 기업들이 전통적인 방법론과 관련된 공통적인 도전 과제를 극복하기 위해 이 아키텍처를 채택했습니다. 마이크로서비스의 흥미진진한 영역으로 뛰어들기 전에, 먼저 거대한(monolithic) 아키텍처 및 그 한계를 이해하는 것이 중요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 코드 링크입니다: [https://github.com/Blogs4Devs/Microservices](https://github.com/Blogs4Devs/Microservices).\n\n# Monolithic architecture\n\n전통적인 모놀리식 아키텍처에서는 전체 애플리케이션이 하나의 프로세스로 실행되며, 모든 애플리케이션 구성 요소가 서로 연결되어 의존하며 하나의 단일 단위로 묶여 있습니다. 이는 사용자 인터페이스, 비즈니스 로직 및 데이터 액세스 레이어가 모두 단일 프로그램의 일부라는 것을 의미합니다.\n\n![img](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 모놀리식 애플리케이션의 단점:\n\n- 확장성 문제:\n\n모놀리식 애플리케이션 내의 특정 서비스가 많은 호출을 받아 확장해야 하는 경우 전체 애플리케이션을 확장해야 합니다. 이는 전체 애플리케이션의 추가 인스턴스를 실행해야 하는 것을 의미하며, 이는 리소스를 많이 소비하고 비효율적입니다. 과부하된 구성 요소만 확장하는 대신 전체 시스템을 확장해야 하므로 불필요하게 리소스를 사용하게 됩니다.\n\n- 배포 속도가 느림:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n대규모 응용 프로그램에서는 작은 변경사항도 전체 응용 프로그램을 다시 컴파일하고 배포해야 합니다. 이로 인해 배포 주기가 크게 느려지며 전체 시스템을 테스트하고 통째로 배포해야 하므로 지속적인 배포가 어려워질 수 있습니다.\n\n- 기술 채택에 대한 장벽:\n\n대규모 응용 프로그램은 일반적으로 한 가지 언어 또는 프레임워크로 작성되어 있어 전체 개발 팀이 해당 특정 기술을 알고 있어야 합니다. 이는 특정 작업에 더 적합한 새로운 기술이나 언어를 채택하는 능력을 제한할 수 있습니다.\n\n- 코드 변경 및 테스트가 어려운 문제:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모놀리식 애플리케이션에서는 전체 시스템의 모든 로직이 얽혀있어 코드베이스가 복잡하고 관리하기 어렵습니다. 애플리케이션의 한 부분에 변경이 있을 때 다른 부분에 예상치 못한 영향을 미치는 경우가 많아 테스트와 유지보수가 어려워집니다. 이 복잡성은 버그를 분리하고 수정하기도 어렵게 만들어서 개발 주기를 늘릴 수 있습니다.\n\n이러한 단점을 이해하면 많은 기관이 더 큰 유연성, 확장성 및 유지보수 편의성을 제공하는 마이크로서비스 아키텍처로 전환하려는 이유가 분명해집니다.\n\n# 마이크로서비스 아키텍처\n\n마이크로서비스 아키텍처는 애플리케이션을 작은, 느슨하게 결합된 서비스로 분해하여 각각이 특정 비즈니스 기능을 담당하게 합니다. 이러한 서비스들은 독립적으로 개발, 배포 및 확장할 수 있어 모놀리식 아키텍처보다 여러 이점을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_1.png\" />\n\n다음은 마이크로서비스 아키텍처의 주요 이점 요약입니다:\n\n- 느슨한 결합:\n\n마이크로서비스는 각각 물리적으로 분리되어 있기 때문에 느슨하게 결합되어 있습니다. 이 분리로 인해 각 서비스는 개별적으로 개발, 배포 및 확장될 수 있어 다른 서비스에 영향을 미치지 않고 독립적으로 변경이 가능합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 독립성 팀:\n\n다른 팀은 서로 독립적으로 다른 마이크로서비스에 작업할 수 있습니다. 이 상대적 독립성은 병렬 개발을 가능케하며 전체 개발 프로세스를 가속화하고 효율성을 향상시킬 수 있습니다.\n\n- 테스트 및 배포의 용이성:\n\n마이크로서비스 아키텍처는 테스트와 배포를 쉽게 할 수 있게 해줍니다. 각 서비스가 별도의 단위이기 때문에 독립적으로 테스트하고 배포할 수 있어 테스트의 복잡성을 줄이고 배포 주기를 가속화할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 지속적 배포:\n\n마이크로서비스는 지속적인 배포 방법에 잘 맞습니다. 각 서비스는 전체 시스템에 영향을 미치지 않고 지속적으로 업데이트되고 배포될 수 있어 더 자주 릴리스하고 빠른 업데이트가 가능해집니다.\n\n이제, 마이크로서비스 아키텍처를 구성하는 주요 구성 요소를 살펴보겠습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_2.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 게이트웨이\n\n프로덕션 환경에서는 마이크로서비스와의 직접 통신이 허용되지 않습니다. 대신, 모든 마이크로서비스는 중개자(일반적으로 미들웨어 또는 API 게이트웨이)와 상호 작용하는 단일 응용 프로그램으로 그룹화되어 처리되어야 합니다. 이 중개자는 로드 밸런서 역할을 하여 들어오는 요청을 마이크로서비스에 골고루 분배하여 부하를 균형 있게 유지하고 최상의 성능을 보장합니다. 미들웨어가 단일 장애 지점(SPOF)이 될 수 있지만, 이러한 위험은 중복 및 고가용성 설정을 통해 강력하고 신뢰할 수 있는 작동을 보장함으로써 완화됩니다.\n\n게이트웨이를 구성하는 두 가지 방법이 있습니다 :\n\n- 정적 구성: 소수의 마이크로서비스를 다룰 때, 미들웨어를 정적으로 구성하여 특정 경로를 지정된 IP 주소로 라우팅할 수 있습니다. 예를 들어, /path1는 주소 1로, /path2는 주소 2로 이동할 수 있습니다. 이 구성에서는 마이크로서비스의 IP 주소를 알아야 하며, 마이크로서비스가 중지되거나 IP 주소가 변경되면 설정을 업데이트해야 합니다.\n- 동적 구성: 여러 마이크로서비스가 동적으로 시작 및 중지되는 환경에서는 정적 구성만으로는 충분하지 않습니다. 여기서는 발견 서비스를 통한 동적 구성이 필수적입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 발견 서비스\n\n발견 서비스는 디렉터리처럼 작동합니다 (DNS 또는 SOAP의 UDDI와 유사함). 마이크로서비스는 시작할 때 발견 서비스에 등록됩니다. 그런 다음 게이트웨이는 마이크로서비스의 현재 IP 주소를 확인하기 위해 서비스 레지스트리에 쿼리하도록 구성되어 라우팅 구성을 자동으로 업데이트할 수 있습니다.\n\n# 구성 서비스\n\n- 콜드 구성: 각 마이크로서비스는 자체 구성 파일(예: application.properties)을 갖습니다. 이러한 파일에 대한 수정은 해당 마이크로서비스를 다시 시작해야 합니다. 또한, 구성 설정이 여러 마이크로서비스 간에 공유되는 경우 각 개별 구성 파일을 따로 업데이트해야 합니다. 동일한 마이크로서비스의 여러 인스턴스가 실행 중인 경우 변경 사항을 각 인스턴스에 개별적으로 적용해야 하므로 불편하고 실수를 유발할 수 있는 프로세스가 됩니다.\n- 핫 구성: 중앙 집중식 구성 서비스는 단일 전역 구성 파일을 유지합니다. 이 파일의 변경 사항은 마이크로서비스에 자동으로 전파되어 다시 시작할 필요가 없습니다. 일반적으로 이 구성은 Git과 같은 버전 관리 리포지토리를 통해 관리됩니다. 구성 매개변수가 변경되면 커밋이 수행되고 특정 변경 사항만 마이크로서비스로 전송됩니다. 전체 구성 파일이 아니라 특정 변경 사항만 전송되므로 모든 마이크로서비스에서 효율적이고 일관된 구성 관리가 보장됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 커뮤니케이션 모델\n\n- 동기식 통신: 누군가에게 길을 물어본다고 상상해봅니다. 동기식 통신에서는 \"공원에 어떻게 가요?\" 라고 물어보고 그 후 그들이 답변할 때까지 그 자리에 기다립니다. 답변을 듣고 나서야만 앞으로 나아갑니다. 이는 마이크로서비스가 서로와 대화하는 방식과 유사합니다. 한 서비스가 무언가를 요청하고, 답변을 기다리며, 그것을 받은 후에만 다음 단계로 넘어갑니다. 이 방법은 빠르고 직관적이지만, 상대 서비스가 응답하는 데 오랜 시간이 걸리면 느릴 수 있습니다.\n\n![이미지1](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_3.png)\n\n![이미지2](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 비동기 통신: 이제, 지시를 기다리는 대신 \"공원에 가고 있어. 만나야 할 일이 있으면 알려줘\"라는 메모를 남기는 상황을 상상해봐. 그럼 너는 그냥 걷어가서 다른 일을 계속 한다. 나중에 답변이 있는지 확인하기 위해 메모를 확인한다. 이것은 메시지 브로커와 함께 하는 비동기 통신과 비슷하다. 한 서비스가 응답을 기다리지 않고 다른 서비스로 메시지를 보낸다. 메시지는 중개인(브로커)에게 보내지고, 그 이후 브로커가 다른 서비스에 전달한다. 보내는 서비스는 기다리지 않고 작업을 계속할 수 있다. 이것은 즉각적인 답변이 필요하지 않고 메시지가 도착했을 때 처리할 수 있는 경우에 좋다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_5.png)\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_6.png)\n\n우리는 Reactive 프로그래밍에 관한 다가오는 블로그에서 이 두 가지 모델을 자세히 살펴볼 것이다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 데모\n\n이 데모에서는 Spring 프레임워크를 사용하여 간단한 마이크로서비스 시스템을 구축하는 방법을 살펴보겠습니다. 특히 Spring Boot와 Spring Cloud에 초점을 맞출 것입니다. 이러한 도구들은 마이크로서비스를 쉽게 구축하고 관리할 수 있도록 설계되었습니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_7.png)\n\n이 데모에서는 두 개의 마이크로서비스인 고객 서비스와 계정 서비스가 있을 것입니다. 각 마이크로서비스는 간단한 Spring Boot 애플리케이션으로, 공통 종속성인 Lombok, Spring Data JPA, H2 Database, Spring Web을 사용해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 고객 서비스: 고객을 관리합니다.\n\n다음은 Customer 모델입니다.\n\n![Customer Model](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_8.png)\n\n- 계정 서비스: 고객에게 속한 각 계정을 관리합니다. 각 마이크로서비스는 자체 데이터베이스를 갖기 때문에, 계정 서비스 데이터베이스는 각 계정에 대해 고객 ID만 저장합니다. 이 고객 ID는 고객 서비스 데이터베이스에 존재해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 참조 무결성 보장하기\n\n참조 무결성은 테이블 간의 관계가 일관적으로 유지되도록 보장합니다. 이 시나리오에서의 적용 방법은 다음과 같습니다:\n\n계정 추가:\n\n- 새 계정을 추가하려면 계정 서비스 데이터베이스에 고객 ID만 저장합니다.\n- 참조 무결성을 보장하려면 고객 ID가 고객 서비스 데이터베이스에 존재하는지 확인해야 합니다.\n- 이를 위해 계정을 추가하기 전에 고객 ID가 유효한지 확인하기 위해 고객 서비스를 호출해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 Account 모델입니다.\n\n![Account Model](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_9.png)\n\n@Transient는 데이터베이스에 저장되지 말아야 하는 필드를 나타내는 주석입니다. 이 경우 accounts 데이터베이스에 customer 테이블이 없고 외래 키도 없기 때문에 customer 필드는 고객 서비스를 쿼리하여 수동으로 생성됩니다.\n\n# Discovery service\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금 새로운 스프링 부트 응용 프로그램을 시작하려고 하는데, 이번에는 이 종속성을 추가해야 합니다.\n\n![dependency](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_10.png)\n\n그런 다음 메인 클래스에 @EnableEurekaServer 주석을 추가해야 합니다.\n\n![annotation](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_11.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그런 다음, 우리는 이 구성을 추가합니다.\n\n<img src=\"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_12.png\" />\n\n그리고 애플리케이션을 시작합니다.\n\n마이크로서비스가 유레카 서버에 등록할 수 있도록 하려면, 각 마이크로서비스에 이 종속성을 추가해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_13.png)\n\n기본적으로 서비스는 서비스가 실행 중인 서버의 서비스 이름과 서버 이름으로 등록됩니다. 그러나 현실적인 시나리오에서는 서버 이름 대신 IP 주소가 필요합니다. 따라서 각 마이크로서비스 수준에 이러한 속성을 추가해야 합니다.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_14.png)\n\ndefaultZone 구성은 Eureka 인스턴스의 기본 위치를 http://localhost:8761/eureka URL로 지정합니다. 그러나 실제로는 적절한 IP 주소를 사용해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제, 마이크로서비스를 실행하고 Eureka 대시보드에 액세스하면 각 마이크로서비스의 주소와 포트를 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_15.png)\n\n# 게이트웨이\n\n새로운 스프링 부트 애플리케이션을 만들고 이 종속성을 추가합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_16.png)\n\n- 정적 구성:\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_17.png)\n\n- 프리디케이트: 요청을 라우팅하는 데 사용되는 조건입니다. 예를 들어, 요청 경로에 /customer가 포함되어 있으면 게이트웨이는 해당 마이크로서비스로 라우팅합니다. 프리디케이트는 요청 경로, 헤더 또는 쿼리 매개변수와 같은 다양한 기준을 바탕으로 할 수 있습니다.\n- URI: 이는 게이트웨이가 요청을 보내는 엔드포인트입니다. 예를 들어, URI가 http://localhost:8080/api로 설정된 경우 게이트웨이는 해당 주소로 요청을 전달합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 localhost:8888/customers를 입력하면 게이트웨이가 localhost:8082/customers로 요청을 리디렉션합니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_18.png)\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_19.png)\n\n- 동적 구성:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그냥 이 bean 하나 추가해주세요.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_20.png)\n\n그리고 이 구성요소도 추가해주세요.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_21.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그리고 CORS를 구성해야 합니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_22.png)\n\n이제 URL을 게이트웨이포트/대문자의 서비스이름 형식으로 입력한 후 특정 경로를 이어서 입력합니다.\n\n예를 들어: http://localhost:8888/ACCOUNT-SERVICE/accounts\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n게이트웨이는 해당 서비스의 경로를 찾기 위해 서비스 디스커버리에 해당 서비스의 이름만으로 요청을 전달합니다.\n\n![이미지1](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_23.png)\n\n![이미지2](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_24.png)\n\n지금까지 살펴본 것처럼, 우리가 계정을 조회할 때 고객 정보도 함께 얻습니다. 그렇다면 계정 서비스는 어떻게 고객 서비스에서 해당 정보를 검색할까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_25.png)\n\n특정 계정에 대한 정보를 얻기 위해 계정 서비스에 요청을 보낼 때, 먼저 해당 계정을 데이터베이스에서 찾습니다. 그런 다음, 계정과 연결된 고객 ID를 검색하고 해당 고객에 대한 정보를 얻기 위해 고객 서비스에 요청을 보냅니다. 최종적으로 결과를 구성하여 클라이언트에게 보냅니다.\n\n내부 요청을 보내기 위해 다양한 라이브러리를 사용할 수 있으며, 가장 흔한 것은 OpenFeign입니다.\n\n다음 종속성을 추가합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_26](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_26.png)\n\nOpenFeign은 HTTP 요청을 간편하게 만들어주는 선언적 프레임워크입니다. 복잡한 코드를 작성하는 대신 인터페이스를 정의하고 상호 작용하려는 서비스의 이름을 지정하고 사용하려는 엔드포인트를 나열하기만 하면 됩니다.\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_27](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_27.png)\n\nFeign을 사용하여 요청을 보내려면 Account 서비스의 주 클래스에 @EnableFeignClients 주석을 추가해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 우리는 인터페이스를 주입하고 해당 함수를 사용하여 고객 서비스에 요청을 보내는 방법을 알아봅니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_28.png)\n\n요청을 보내기 전에, 우리는 Discovery Service에 서비스의 주소를 요청합니다 (Gateway를 우회합니다). 예를 들어 findCustomerById를 호출하는 경우에 문제가 발생할 수 있고 서비스가 차단될 수 있습니다. 이를 해결하기 위해 \"서킷 브레이커\"를 사용합니다.\n\n서킷 브레이커는 전력 시스템의 전기 회로 차단기와 유사하게 작동합니다. 이는 지속적으로 구성 요소(예: 원격 서비스 호출)를 모니터링하고 반복된 실패 또는 성능 저하를 감지하면 해당 실패하는 구성 요소에 대한 호출을 일시적으로 차단하여 '회로를 열게' 합니다. 이 기간 동안 서킷 브레이커는 트래픽을 대체로 리다이렉트할 수 있습니다(예: 백업 시스템 또는 대체 기능).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n소프트웨어 아키텍처에서 회로 차단기 패턴의 이점은 다음과 같습니다:\n\n- 향상된 탄력성: 실패를 격리시켜 시스템의 다른 부분으로 전파되는 것을 방지합니다.\n- 지연 시간 단축: 빠르게 트래픽을 백업이나 Fallback로 리디렉션하여 최종 사용자의 지연 시간을 줄입니다.\n- 과부하 보호: 실패하는 구성 요소로의 새 요청을 일시적으로 제한함으로써 불필요한 과부하를 방지합니다.\n\n회로 차단기는 일반적으로 세 가지 주요 상태에서 작동합니다: Closed, Open, Half-Open:\n\n- Closed 상태:\n  - 구성 요소로의 정상 트래픽 흐름을 허용합니다.\n  - 구성 요소의 동작을 계속 모니터링합니다.\n- Open 상태:\n  - 회로 차단기가 비정상적인 실패 또는 성능 저하를 감지할 때 진입합니다.\n  - 실패하는 구성 요소로의 트래픽을 적극적으로 차단합니다.\n  - 더 이상의 실패 전파를 방지합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nHalf-Open 상태:\n\n- 오픈 상태에서 정의된 기간이 지난 후, 회로 차단기는 문제가 발생한 구성 요소가 회복되었는지 테스트하기 위해 Half-Open 상태로 전환될 수 있습니다.\n- 제한된 수의 테스트 요청을 통과시키도록 합니다.\n- 이러한 요청이 성공하면, 회로 차단기는 구성 요소가 작동 중이라는 것을 나타내는 Closed로 돌아갑니다.\n- 실패가 계속되면, 보호를 연장하기 위해 다시 Open 상태로 돌아갑니다.\n- Half-Open 상태에서는 이전에 실패한 구성 요소가 회복되었고 다시 트래픽을 신뢰할 수 있는지를 평가하기 위해 회로 차단기 메커니즘 자체에 의해 일반적으로 테스트 요청이 생성됩니다.\n\n![](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_29.png)\n\nCircuit Breaker 패턴을 구현하기 위해서는 필요한 종속성을 추가하는 것부터 시작해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_30.png)\n\n예외 상황 발생 시 기본 데이터 또는 캐싱된 데이터로 응답하겠습니다. 일정 기간이 지난 후에는 해당 서비스와의 통신을 재개할 것입니다. 서비스가 응답하고 클로즈드 서킷 모드로 전환되면, 그렇지 않을 경우 오픈 서킷 모드로 전환하겠습니다.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_31.png)\n\n간단한 예제를 살펴보죠: 모든 서비스를 시작한 후 고객 서비스를 중단할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_32.png)\n\nWe can see that the account service is still working, and the customer data returned is just default data.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_33.png)\n\nConfig-Service\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마이크로서비스마다 자체 설정이 있는 경우 변경 사항이 발생하면 해당 서비스를 다시 시작해야 합니다. 또한, 대부분의 설정이 모든 서비스에서 동일하며, 각 구성 파일에 반복된 항목이 있습니다.\n\n이 문제의 해결책은 모든 구성을 저장하고 관리할 수 있는 중앙 집중식 구성 서비스를 사용하는 것입니다.\n\n먼저 간단한 스프링 부트 애플리케이션을 만들고 이 종속성을 추가할 것입니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_34.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n효율적으로 설정을 관리하려면 모든 설정 파일을 저장할 Git 저장소를 만들어야 합니다. 이 저장소는 로컬에 있을 수도 있고(이 경우 구성 서버와 같은 기기에 있어야 함), 또는 원격 GitHub 저장소일 수 있습니다.\n\n- Application.properties: 이 파일에는 모든 마이크로서비스 간에 공유되는 설정이 포함됩니다.\n- 서비스별 구성: 각 마이크로서비스는 해당하는 이름(예: customer-service.properties)의 구성 파일을 가져야 합니다.\n\n마이크로서비스의 이름은 해당 내부 구성 파일에 명시되어야 합니다. 마이크로서비스가 시작되면 구성 서버에 해당 구성 파일을 요청하는 요청을 보냅니다. 구성 서버는 올바르게 응답하기 위해 마이크로서비스의 이름을 알아야 합니다(포트도 마찬가지).\n\n우리는 각 마이크로서비스에 이 구성을 추가해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_35](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_35.png)\n\n구성이 변경되면 구성 서비스에서 관련된 마이크로서비스로 요청이 전송됩니다 (/actuator/refresh로의 POST 요청), 그것에게 다시 시작하지 않고 구성을 새로 고쳐 달라는 것을 요청합니다. 그럼 마이크로서비스는 업데이트된 구성을 구성 서버에서 요청하고, 저장된 버전과 비교해서 변경된 부분만을 보내줍니다.\n\n그래서 우리는 각 마이크로서비스에 Actuator 종속성을 추가해야 합니다.\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_36](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_36.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모든 마이크로서비스 간에 공유되도록 application.properties 파일 내에서 config 리포지토리에 이 구성을 추가해야 합니다. 이 구성은 액추에이터 엔드포인트를 활성화합니다.\n\n![Actuator Configuration](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_37.png)\n\n구성 파일을 위한 Git 리포지토리는 여기에 있습니다.\n\n![Configuration Git Repository](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_38.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로, 설정 서비스의 구성 파일인 application.properties 내부에서 Git 리포지토리의 위치를 로컬 변수로 지정해야 합니다. 이는 구성 파일을 로컬 폴더에 포함하거나 구성 파일을 원격 리포지토리로 푸시하는 경우 GitHub 리포지토리의 URL일 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_39.png)\n\n# 마이크로서비스 아키텍처 도커화\n\n이제, 마이크로서비스를 실행하려면 발견 서비스를 먼저 실행한 다음 구성 서비스와 게이트웨이를 실행해야 합니다. 이러한 서비스들이 올바르게 시작되면 다른 마이크로서비스를 시작할 수 있습니다. 다수의 마이크로서비스를 처리할 때 각각을 필요한 순서대로 수동으로 시작하는 것은 어려울 수 있습니다. 해결책은 모든 서비스와 종속성을 지정하여 올바른 순서로 시작되도록 보장하는 Docker Compose 파일을 사용하는 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 각 마이크로서비스에 이 도커파일을 추가해줍니다.\n\n![도커파일](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_40.png)\n\n도커파일을 간단하게 만들기 위해서는 Docker Compose를 실행하기 전에 마이크로서비스를 먼저 빌드해야 합니다. 권장하는 방법은 컨테이너를 실행할 때 애플리케이션을 빌드하는 겁니다.\n\n다음은 도커 컴포즈입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_41.png)\n\nBuilding Images:\n\n- Running `docker-compose up --build` builds Docker images for each service from their respective Dockerfiles.\n- This ensures that each service starts with the latest configurations.\n\nHealth Checks:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Docker Compose는 각 컨테이너의 상태를 모니터링하기 위해 건강 검사(healthcheck)를 사용합니다.\n- 일반적으로 건강 검사는 컨테이너 내에서 특정 엔드포인트 (/actuator/health)를 쿼리하여 올바르게 작동하는지 확인합니다.\n\n의존성 관리 (Depends On):\n\n- 서비스는 시작 순서를 제어하기 위해 종속성(dependes_on)을 지정합니다.\n- 이를 통해 다른 서비스에 의존하는 서비스가 해당 의존성이 시작될 때까지 기다립니다.\n\n이제 환경 변수를 사용하기 위해 구성 파일을 변경해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_42](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_42.png)\n\nDocker Compose를 사용할 때는 DISCOVERY_SERVICE_URL 환경 변수를 활용합니다. 수동으로 실행하는 경우에는 일반적으로 localhost:8761/eureka를 사용합니다.\n\n이로써 이 블로그를 마치겠습니다. 다음에 다시 만나요! 👍\n","ogImage":{"url":"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png"},"coverImage":"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png","tag":["Tech"],"readingTime":28},{"title":"스파크-비욘드 기본 델타 테이블에서 동시 쓰기와 행 수준 동시성","description":"","date":"2024-06-19 12:31","slug":"2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable","content":"\n![image](/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png)\n\nDatabricks와 델타 테이블은 데이터 엔지니어의 삶을 쉽게 만들어줍니다. 😍🥰\n\n하지만 이 엔지니어들은 어쩔 수 없이 그들에게 맞서려고 할 것입니다. 😒😒\n\n델타 테이블이 제공하는 ACID 속성에 대해 이미 알고 있다면 좋겠지만(알지 못하신다고요? 읽어보세요), 이러한 속성은 델타 테이블에서 동시에 발생하는 쓰기 작업을 다루지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 현재 상황\n\n현재 델타 테이블에 병행(또는 동시) 쓰기 작업을 수행하면 \"ConcurrentAppendException\"이 발생합니다.\n\n# 동시 작성이란\n\n2명의 데이터 엔지니어인 Monica와 Ross Geller가 델타 테이블에 동시에 쓰기를 하려고 한다고 가정해보겠습니다. 🥴 (형제 맹견이야!)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이전에 (2024년 5월 16일 이전에 🙈), 데이터 엔지니어들은 어떻게든 동시 쓰기를 직렬 쓰기로 변환하기 위해 더러운 파이스파크 코드 💩를 작성해야 했습니다. 이러한 로직 중 하나를 아래에서 설명합니다.\n\n로직: 델타 테이블에 대한 쓰기가 진행 중이면, 해당 쓰기가 끝날 때까지 기다린 후 현재 쓰기 프로세스를 시작합니다. 여기서 자세한 내용을 확인하세요.\n\n따라서 델타 테이블에 동시에 쓰기할 수 있는 모든 노트북에는 위의 로직을 포함해야 합니다.\n\n# Databricks에서 이 문제에 대해 무엇을 하였을까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그렇다구요! 🥳 Databricks Runtime 14.2 이상에서 데이터브릭은 \"행 수준 동시성\"(RLC)이라 불리는 새로운 기능을 소개했어요.\n\n데이터브릭은 마치 요정 🧞‍♂️ 같죠. 무엇이든 물어보면 주어져요!\n\n## 행 수준 동시성(RLC)을 위한 요구 사항\n\n1. 델타 테이블의 \"삭제 벡터\"를 활성화해야 해요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nALTER TABLE table_name SET TBLPROPERTIES ('delta.enableDeletionVectors' = true);\n```\n\n2. 델타 테이블은 파티션이 없어야 합니다.\n\n# RLC를 사용한 동시 쓰기 작업 및 그 결과\n\n## 삽입-삽입:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 Ross와 Monica가 동시에 삽입 작업을 수행한다면, RLC는 어떤 문제도 없이 처리할 수 있어요 😏 (충돌 없음)\n\n## 삽입-갱신/삭제:\n\n만약 Ross가 삽입을 수행하고 Monica가 갱신/삭제를 수행한다면, RLC는 조금 답답해집니다. 🥵\n\n델타 테이블의 격리 수준이 \"WriteSerializable\"로 설정되어 있다면 (기본값), 동시 작성 작업은 어떤 문제도 발생하지 않고 수행됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그런데 고립 수준을 \"Serializable\"로 변경하면 (어떤 이유에서든 변경했을 것입니다 🤔) 충돌이 발생하고 오류가 발생할 것입니다.\n\n## 업데이트/삭제\n\nRoss와 Monica가 동일한 델타 테이블에서 업데이트 또는 삭제 작업을 수행하는 경우, 동일한 행에서 작업을 수행하면 오류가 발생합니다.\n\n업데이트/삭제 작업이 다른 행에서 발생하는 경우 문제없이 작업이 수행됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 요약:\n\n- 델타 테이블에 대한 동시 행 수준 동시성(RLC)은 Databricks에서 도입되었으며 동시 쓰기 작업을 수행할 수 있게 해줍니다.\n- RLC가 작동하기 위한 몇 가지 요구 사항이 있습니다.\n\n자세한 내용은 [여기](https://link-to-more-info)에서 읽을 수 있습니다.\n\n이 블로그를 좋아하셨다면 👏을 클릭하고 데이터 엔지니어들의 삶을 쉽게 만들기 위해 공유해주세요! 😉\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n읽어 주셔서 감사합니다! 😄\n","ogImage":{"url":"/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png"},"coverImage":"/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png","tag":["Tech"],"readingTime":5},{"title":"아저라 데이터브릭스 SQL 웨어하우스 인스턴스의 실제 비용을 계산하는 방법","description":"","date":"2024-06-19 12:28","slug":"2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances","content":"\n<img src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png\" />\n\n이야기에서는 Azure Databricks SQL Warehouse 인스턴스의 비용을 계산하는 방법에 대해 배워보겠습니다.\n\nDatabricks SQL Warehouse는 Azure Databricks에서 데이터를 쿼리하고 탐색할 수 있는 컴퓨팅 리소스입니다.\n\n현재 Azure Databricks에서는 3가지 유형의 SQL Warehouse를 제공합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- SQL Warehouse Classic: SQL Warehouse Classic의 컴퓨팅 레이어는 저희 Azure 구독 계정에 존재하며 Photon을 지원하지만 Predictive IO나 Intelligent Workload Management은 지원하지 않습니다.\n- SQL Warehouse Pro: SQL Warehouse Pro의 컴퓨팅 레이어는 저희 Azure 구독 계정에 존재하며 Photon과 Predictive IO를 지원하지만 Intelligent Workload Management는 지원하지 않습니다.\n- SQL Warehouse Serverless: Azure Databricks 서버리스 아키텍처를 사용하여 Databricks SQL Warehouse Serverless가 Azure Databricks 계정에 존재하며 Databricks SQL의 모든 성능 기능(Phton, Predictive IO 및 Intelligent Workload Management)을 지원합니다.\n\n위 목록에서 볼 수 있듯이, SQL Warehouse Classic과 SQL Warehouse Pro 사이의 가장 중요한 차이점은 컴퓨팅 레이어가 저희 Azure 구독 계정에 있고, SQL Warehouse Serverless가 저희 Azure Databricks 계정에 있다는 것입니다.\n\n## 관련 이야기:\n\n- Microsoft 및 Databricks API를 사용하여 Azure Databricks 클러스터의 비용을 최적화하고 90%까지 줄이는 방법\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1. DIY 방법\n\n첫 번째 섹션은 비용 분석 논리를 이해하고 아마도 자신만의 도구나 스크립트를 작성하여 Azure Databricks SQL Warehouse 인스턴스의 비용을 계산하고자 하는 개발자 또는 기술 직군을 위해 제공됩니다.\n\n# 1.1. DIY 방법 — SQL Warehouse Classic\n\nAzure Databricks SQL Warehouse Classic 또는 Azure Databricks SQL Warehouse Pro의 비용을 계산하려면 다음 구성 요소를 고려해야 합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- SQL 계산 시간: SQL Warehouse가 실행되었던 시간.\n- Databricks Unit (DBU) 시간: SQL Warehouse에서 사용된 컴퓨팅 단위가 시간당 청구됩니다.\n- 저장 비용: 적용된 경우 데이터 저장에 연관된 비용.\n- 대역폭 비용: 적용된 경우 대역폭 전송에 연관된 비용.\n\n# 1.1.1. Databricks API에서 SQL Warehouse Classic 인스턴스 목록 가져 오기\n\n첫 번째 단계는 Databricks API \"/api/2.0/sql/warehouses\"를 사용하여 SQL Warehouse 인스턴스 목록을 검색하는 것입니다.\n\nAPI 호출을 실행한 후, 모든 Databricks SQL Warehouse가 포함 된 JSON 응답을 받게됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQL Warehouse Classic의 JSON은 다음과 같습니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"2b1613d995c81e7d\",\n  \"name\":\"Classic Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":45,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"channel\":{\n    \"name\":\"CHANNEL_NAME_CURRENT\"\n  },\n  \"enable_serverless_compute\":false,\n  \"warehouse_type\":\"CLASSIC\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/2b1613d995c81e7d;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/2b1613d995c81e7d\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n위와 유사한 데이터를 얻을 수 있습니다(쉽게 이해할 수 있도록 형식화됨)\n\n<img src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_1.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1.1.2. Microsoft API를 통해 SQL Warehouse Classic 자원의 비용 가져오기\n\n검색한 사용 데이터와 비용 정보를 결합하여 SQL Warehouse Classic의 비용을 계산해야 합니다.\n\n저희는 Microsoft Generate Cost Details Report API를 사용하여 Databricks 클러스터가 실행되는 Azure 구독에 대한 모든 데이터를 가져올 것입니다.\n\nAPI를 사용할 때 주의할 점들:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Azure 구독의 비용 세부 정보 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 비용이 연관되지 않은 데이터는 제거해야 합니다.\n- 결과를 Pay-as-you-go 또는 Enterprise 유형의 Azure 구독에 따라 조정해야 하며, 결과가 서로 다릅니다.\n- API는 한 달 이하의 데이터만 가져오도록 허용하며 13개월 이전의 데이터는 제공하지 않습니다.\n\nMicrosoft API에서 데이터를 추출할 때, 보고서에서 다음 열을 선택해야 합니다:\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용된 Azure 리소스의 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용된 Azure 리소스의 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n# 1.1.3. SQL Warehouse 클래식 인스턴스 비용 계산\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMicrosoft Databricks 및 Azure API에서 데이터를 검색한 후, 마지막 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API의 SQL Endpoint ID와 일치시키는 것입니다.\n\n우리는 이와 유사한 데이터를 받을 것입니다 (이해하기 쉽게 형식화된 데이터입니다):\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_2.png)\n\nSQL Warehouse Classic 인스턴스에서 제품은 Azure Databricks - Premium - SQL Analytics이며, 미터 이름은 Premium SQL Analytics DBU입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼, SQL Warehouse 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n# 1.2. 직접 계산 방법 — SQL Warehouse Pro\n\nAzure Databricks SQL Warehouse Pro의 비용을 계산하기 위해 다음 구성 요소를 고려해야 합니다:\n\n- SQL 컴퓨트 시간: SQL Warehouse가 실행된 시간입니다.\n- 데이터브릭스 유닛(DBU) 시간: SQL Warehouse에서 사용된 컴퓨트 유닛으로, 매 시간마다 청구됩니다.\n- 저장 비용: 데이터 저장에 관련된 비용(해당하는 경우).\n- 대역폭 비용: 대역폭 전송에 관련된 비용(해당하는 경우).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI 호출을 실행한 후, 모든 Databricks SQL Warehouse에 대한 JSON 응답을 받게 됩니다.\n\n다음은 SQL Warehouse Pro의 JSON입니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"aedd502a582f673a\",\n  \"name\":\"Starter Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":10,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"channel\":{ },\n  \"enable_serverless_compute\":false,\n  \"warehouse_type\":\"PRO\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/aedd502a582f673ad;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/aedd502a582f673a\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n이와 유사한 데이터를 얻게 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_3.png)\n\n# 1.2.2. Microsoft API를 통한 SQL Warehouse PRO 자원 비용 가져오기\n\nSQL Warehouse Pro 비용을 계산하기 위해서는 검색된 사용 데이터와 비용 정보를 결합하여 총 비용을 계산해야 합니다.\n\nMicrosoft Generate Cost Details Report API를 사용하여 Databricks 클러스터가 실행 중인 Azure 구독에 대한 모든 데이터를 가져올 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI를 사용할 때 중요한 사항:\n\n- Azure 구독에 대한 비용 세부 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 관련된 데이터 또는 비용이 연관되지 않은 데이터를 제거해야 합니다.\n- Azure 구독 유형(유연한 요금제 또는 기업용)에 따라 결과를 조정해야 합니다. 왜냐하면 출력 결과물이 다르기 때문입니다.\n- API는 한 달 이하의 데이터만 가져올 수 있으며 13개월 이전의 데이터는 가져올 수 없습니다.\n\nMicrosoft API에서 데이터를 추출할 때, 보고서에서 다음 열을 선택해야 합니다.\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용된 Azure 리소스의 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용된 Azure 리소스의 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1.2.3. SQL Warehouse PRO Instances 비용 계산하기\n\nMicrosoft Databricks와 Azure API에서 데이터를 검색한 후, 최종 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API에서 SQL Endpoint ID와 일치시키는 것입니다.\n\n다음과 유사한 데이터를 얻게 됩니다:\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQL Warehouse Pro 인스턴스에서 Product가 Azure Databricks Regional — Premium — SQL Compute Pro이고 MeterName이 Premium SQL Compute Pro DBU인 경우, SQL Warehouse 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n# 1.3. 직접 만들기 방법 — SQL Warehouse Serverless\n\nAzure Databricks SQL Warehouse Serverless 인스턴스는 Azure Databricks 계정 내에서 실행되므로 Databricks Unit (DBU) 시간 단위로 청구됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI 호출을 실행한 후, Databricks SQL Warehouse에 관한 JSON을 받게 됩니다.\n\n다음은 Serverless SQL Warehouse의 JSON입니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"e6e7601bde7c3a43\",\n  \"name\":\"Serveless Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":10,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"enable_serverless_compute\":true,\n  \"warehouse_type\":\"PRO\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/e6e7601bde7c3a43;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/e6e7601bde7c3a43\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n이처럼 유사한 데이터를 얻을 수 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_5.png\" />\n\n# 1.3.2. Microsoft API를 통해 SQL Warehouse Serverless 리소스 비용 얻기\n\n검색된 사용량 데이터를 비용 정보와 결합하여 SQL Warehouse Serverless 비용을 계산해야 합니다.\n\nDatabricks 클러스터가 실행 중인 Azure 구독의 모든 데이터를 가져 오기 위해 Microsoft Generate Cost Details Report API를 사용할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI를 사용할 때 중요한 사항:\n\n- Azure 구독에 대한 비용 세부 내역 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 관련 없는 데이터를 제거해야 합니다.\n- 결과를 조정해야 하는 이유는 Azure 구독 유형(사용한 만큼 지불 또는 기업 서비스)에 따라 출력이 다르기 때문입니다.\n- API는 한 달 이하의 데이터만 검색할 수 있으며 13개월 이전의 데이터는 가져올 수 없습니다.\n\nMicrosoft API에서 데이터를 추출할 때 다음 보고서 열을 선택해야 합니다:\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용한 Azure 리소스 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용한 Azure 리소스 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1.3.3. SQL Warehouse Serveless 인스턴스 비용 계산하기\n\nMicrosoft Databricks와 Azure API에서 데이터를 검색한 후, 최종 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API에서 SQL Endpoint ID를 매칭하는 것입니다.\n\n우리가 얻게 되는 데이터는 이와 비슷할 것입니다:\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_6.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQL 웨어하우스 서버러스 인스턴스에서, 제품은 Azure Databricks Regional — Premium — Serverless SQL이고 미터 이름은 프리미엄 서버러스 SQL DBU입니다.\n\n그런 다음 SQL 웨어하우스 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n## 2. 쉬운 방법\n\nSQL 웨어하우스의 비용을 분 단위로 결정해야하는 경우, KopiCloud Azure Databricks 비용 도구를 사용하는 것이 쉽습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내가 API 데이터를 가져오고 필터링하며 추출하는 경험을 토대로, Microsoft 및 Databricks API에서 검색한 데이터를 읽고 관리하는 프로세스를 간소화하기 위해 이 도구를 개발했습니다.\n\n이 도구는 간단한 사용자 인터페이스를 사용하며, 몇 분 내에 서식이 지정된 데이터를 검색하려는 FinOps 전문가들을 위해 설계되었습니다.\n\n먼저 \"Databricks 비용 찾아보기\" 버튼을 클릭합니다.\n\n도구는 Microsoft 및 Databricks API와 연결하고 화면 및 Excel 파일에서 서식이 지정된 데이터를 생성할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_7.png](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_7.png)\n\n두 번째로 마지막 단계에서는 Cost per SQL Warehouse Report 버튼을 클릭하여 SQL Warehouse 및 해당 비용 목록을 생성합니다.\n\n이 도구는 화면에 정보를 표시하고 Excel 파일로 내보냅니다.\n\n![2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_8.png](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도구는 모든 데이터를 Excel 파일로 출력하여 데이터를 조작하거나 사용자 정의 보고서를 작성할 수 있도록 합니다.\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_9.png)\n\n또한 도구는 원시 및 형식화된 데이터를 생성하고 일일 및 총 일일 비용을 로컬 스토리지나 Azure Blob Storage에 저장하여 사용자 정의 PowerBI 보고서를 생성할 수 있습니다.\n\n그게 다에요. 만약 이 이야기가 마음에 드셨다면 👏을 눌러주세요. 읽어 주셔서 감사합니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- KopiCloud Azure Databricks Cost 도구는 KopiCloud 웹사이트에서 다운로드할 수 있어요.\n- 만약 Databrick 클러스터 비용을 줄이는 데 도움이 필요하다면 Linkedin에서 저에게 연락해 주세요.\n- 게시된 이미지는 Flaticon의 Dewi Sari가 만든 Cost 아이콘을 사용하여 생성되었어요.\n\n## 관련 이야기:\n\n- Microsoft 및 Databricks API를 사용하여 Azure Databricks 클러스터 비용을 최대 90%까지 최적화하고 줄이는 방법\n","ogImage":{"url":"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png"},"coverImage":"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png","tag":["Tech"],"readingTime":17},{"title":"눈꽃 폴라리스와 데이타브릭스 유니티 카탈로그 오픈 및 상호 운용 가능한 메타스토어 시대","description":"","date":"2024-06-19 12:26","slug":"2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores","content":"\n<img src=\"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png\" />\n\n이번 달에는 두 대형 클라우드 데이터 플랫폼인 Snowflake와 Databricks에서 비슷한 성격의 주요 발표가 이뤄졌습니다.\n\n6월 초 한 주쯤에, Snowflake는 매년 개최되는 컨퍼런스에서 Apache Iceberg 위에 구현된 오픈 카탈로그인 Polaris Catalog를 발표했습니다. 그리고 그 한 주 뒤에, Databricks가 데이터 거버넌스를 위한 통합 솔루션을 제공하는 Unity Catalog 제품을 오픈소스로 공개했습니다. 이 짧은 기사에서 자세히 살펴보도록 하겠습니다.\n\n# 데이터 호수(Datalake)에서의 메타데이터 카탈로그\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_1.png](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_1.png)\n\n이 제품에 대해 파헤치기 전에, 데이터 레이크의 맥락에서 정의에 대해 먼저 간단히 논의해보겠습니다. 메타데이터 카탈로그, 또는 메타스토어라고도 알려진 것은 데이터셋을 테이블로 표현하여 객체 저장소에 있는 데이터에 대한 추상화 레이어를 만듭니다. 데이터에 대한 접근은 메타스토어를 통해 관리되며, 상호 작용을 테이블에 저장된 것처럼 변환하여 저장소에서 필요한 작업을 수행합니다.\n\n# Databricks Unity Catalog\n\n처음 접하는 분들을 위해 - 2013년 Apache Spark의 창시자들에 의해 설립된 Databricks는 데이터 레이크와 데이터 웨어하우스를 결합하여 기업이 데이터 및 AI 솔루션을 구축, 관리 및 확장하는 데 도움이 되는 클라우드 기반 데이터 인텔리전스 플랫폼입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n약 2021년 중반쯤, 유니티 카탈로그가 독점 소스로 출시되었습니다. 이는 플랫폼 에코시스템 내에서 데이터 및 AI 자산을 접근하고 관리하기 위한 솔루션이었습니다. 이는 중앙 집중식 접근 제어, 감사, 계보, 공유 및 데이터 발견 기능과 같은 여러 기능을 제공했습니다.\n\n![이미지](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_2.png)\n\n오픈 테이블 형식 (OTFs)인 Iceberg, Delta 및 Hudi가 인기를 얻으면서, 주요 데이터 플랫폼 공급 업체들은 이 세 가지 중 하나를 선택해야 했습니다. 당연히 Databricks의 창립자로서 델타 레이크가 주요 형식으로 선택되었습니다.\n\n그러나 오픈 델타 형식을 사용하는 플랫폼과의 밀접한 결합은 Apache Iceberg 또는 Hudi와 호환되는 쿼리 엔진과의 상호 운용성이 제한되었음을 의미했습니다. Databricks가 이 문제를 해결하기 위한 최초의 시도는 Delta UniForm이었습니다. 이는 복사 또는 변환의 필요성을 제거하고 레이크하우스 상호 운용성을 위한 범용 형식을 제공했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n최신 발표에 따르면, Unity Catalog를 오픈 API와 아파치 2.0 라이센스로 빌드한 오픈 소스 서버로 제공하는 Databricks가 기업에게 오픈 데이터 형식(UniForm을 통한)을 지원하며 다양한 쿼리 엔진, 도구, 클라우드 플랫폼 간의 상호 운용성을 제공하는 범용 인터페이스를 제공하여 다음 수준으로 나아갔습니다.\n\n# Snowflake Polaris Catalog\n\n2012년 개발된 Snowflake는 데이터 웨어하우징, 데이터 레이크, 데이터 엔지니어링 및 데이터 과학을 위한 완전히 관리되는 SaaS 플랫폼입니다. Snowflake는 스토리지와 컴퓨팅의 분리, 온디맨드 확장 가능한 컴퓨팅, 데이터 공유, 데이터 복제, 그리고 성장하는 기업의 요구를 처리하기 위한 타사 도구 지원과 같은 기능들을 제공합니다.\n\nSnowflake는 자사의 프로프라이어터리 테이블 형식을 시작한 후, 재미있게도 얼마 전부터 Apache Iceberg와의 통합에 헌신하여 왔습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Snowflake Polaris and Databricks Unity Catalog](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_3.png)\n\n최근 출시된 Polaris 카탈로그는 Iceberg의 오픈 소스 REST 프로토콜을 기반으로 하여 사용자가 Iceberg Rest API를 지원하는 Apache Spark, Flink, Trino 등과 같은 원하는 엔진을 사용하여 데이터에 액세스하고 검색할 수 있는 오픈 표준을 제공합니다. Polaris는 다음 90일간(약 2024년 4분기) 오픈 소스로 공개될 예정입니다.\n\n# 개방성은 호환성을 의미하지 않을 수 있습니다\n\n이러한 프로젝트들을 오픈 소스 Apache 이니셔티브로 오픈하는 것은 긍정적인 단계이지만, 데이터 솔루션 아키텍처적인 측면에서 보면, 코드를 오픈할 필요는 없고 오히려 노출되는 인터페이스가 오픈되어야 합니다. 이 글을 쓰는 동안, Polaris는 원래 Iceberg만을 지원하며, Unity는 UniForm을 사용하여 네이티브 Delta 이외의 다른 OTF(Open Table Format)를 간접적으로 지원하고, Tabular 인수 이후 Iceberg와의 새로운 통합을 수행하고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\"이상적인 '오픈' 정의에서 이 메타스토어는 모든 표준 테이블 형식을 지원하고, 구성 가능한 저장 계층과 Hive Metastore가 한동안 있었던 것과 같은 메타스토어에 대한 표준 인터페이스를 가져야 합니다.\n\n# 결론\n\n대부분의 기업은 벤더 락인을 피하면서 데이터 생태계를 더 열린, 유연한, 상호 운용 가능한 것으로 하고 싶어합니다. 데이터브릭스 없이 유니티 카탈로그를 구현하거나, 스노우플레이크 없이 폴라리스를 사용하는 것은 흥미로운 전망입니다. 엔지니어링 팀은 이제 이러한 기능을 구매한 플랫폼이나 컨테이너를 사용하여 자체 인프라에서 독립적으로 호스팅하는 유연성을 가지게 되었습니다. 다가오는 몇 달 동안, 개방 커뮤니티의 협력으로 이 제품들의 성장과 채택을 지켜보는 것이 흥미로울 것입니다.\"\n","ogImage":{"url":"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png"},"coverImage":"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png","tag":["Tech"],"readingTime":5},{"title":"마이크로소프트 패브릭과 데이타브릭스 유니티 카탈로그 - 통합 시나리오 해석하기","description":"","date":"2024-06-19 12:25","slug":"2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios","content":"\n올해 첫 번째 Microsoft Fabric 커뮤니티 컨퍼런스가 개최되었습니다. 첫 번째 날 키노트에서 Fabric와 Databricks Unity Catalog (UC) 통합을 쇼케이스하는 두 가지 미리보기가 있었어요.\n\n이전 블로그 게시물에서는 Databricks에서 OneLake로 쓰는 옵션 및 Fabric Spark에서 ADLS Gen2로 쓰는 옵션(Unity Catalog가 활성화된 클러스터가 아닌 경우)에 대해 알아보았습니다. 이 블로그 게시물은 Fabric + Unity Catalog 통합(Unity Catalog가 활성화된 클러스터와 관련된 다양한 시나리오를 밝히는 것을 목표로 합니다. Lakehouse 시나리오에 대한 자세한 내용은 Piethein의 게시물에서 확인해주세요.\n\n- Unity Catalog 테이블을 OneLake 카탈로그로 동기화할 수 있을까요? 어떻게요?\n- Unity Catalog가 활성화된 클러스터에서 OneLake로 쓸 수 있을까요?\n- Unity Catalog를 OneLake와 통합할 수 있을까요? SQL 엔드포인트 / Fabric 데이터 웨어하우스에 대해 페더레이티드 쿼리를 실행할 수 있을까요?\n\n참고: 본 글은 제 개인적인 경험과 견해를 반영한 것이며, Microsoft나 Databricks의 공식 입장을 대변하는 것은 아닙니다. 또한, 이 블로그 게시물은 잠재적인 시나리오를 개요로 제시하였지만, Fabric 로드맵이나 의도를 반영하는 것은 아닙니다. 미래에 모든 언급된 옵션이 운영되지는 않을 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Databricks Unity Catalog and Microsoft Fabric\n\n통합 시나리오는 기본적으로 진입점에 따라 볼 수 있습니다. Unity Catalog 및 Fabric:\n\n- Fabric에서 Unity Catalog에 액세스하기 (Fabric → Unity Catalog): 이 기능을 통해 사용자는 Fabric 내에서 Unity Catalog 카탈로그, 스키마 및 테이블에 원활하게 액세스할 수 있습니다.\n- Unity Catalog에서 Fabric 활용하기 (DBX/Unity Catalog → Fabric): 이 기능을 사용하면 사용자는 Unity Catalog 내부에서 OneLake에 직접 액세스하고 SQL 엔드포인트 또는 Fabric 데이터 웨어하우스를 통해 연합 쿼리를 실행할 수 있습니다.\n\n이러한 시나리오를 자세히 살펴보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Fabric → Unity Catalog\n\n## Fabric에서 Unity Catalog 사용하기\n\nFabric에서 Unity Catalog 테이블에 액세스할 수 있는 몇 가지 옵션이 있습니다. Fabric Spark에서 ADLS Gen2로 직접 읽기 및 쓰기도 가능합니다.\n\n<img src=\"/assets/img/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios_0.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n현재 옵션\nUC 테이블에 바로 가기를 생성할 수 있는 옵션은 현재 두 가지 있습니다: 수동(지루한) 또는 반자동, 후자는 노트북을 통해 가능합니다. 반자동 방법을 사용하면 사용자들은 UC Delta 외부 테이블을 OneLake에 통합하여 바로 가기를 생성할 수 있습니다. 동기화를 위해 카탈로그와 스키마 이름을 지정하면, 해당 스키마 내 테이블에 대한 바로 가기가 Fabric 레이크하우스 내에 생성됩니다. 실행 유틸리티 노트북에 대한 추가 지침을 참조하세요.\n\n```js\n# configuration\ndbx_workspace = \"<databricks_workspace_url>\"\ndbx_token = \"<pat_token>\"\ndbx_uc_catalog = \"catalog1\"\ndbx_uc_schemas = '[\"schema1\", \"schema2\"]'\n\nfab_workspace_id = \"<workspace_id>\"\nfab_lakehouse_id = \"<lakehouse_id>\"\nfab_shortcut_connection_id = \"<connection_id>\"\nfab_consider_dbx_uc_table_changes = True\n\n# sync UC tables to lakehouse\nsc.addPyFile('https://raw.githubusercontent.com/microsoft/fabric-samples/main/docs-samples/onelake/unity-catalog/util.py')\nfrom util import *\ndatabricks_config = {\n    'dbx_workspace': dbx_workspace,\n    'dbx_token': dbx_token,\n    'dbx_uc_catalog': dbx_uc_catalog,\n    'dbx_uc_schemas': json.loads(dbx_uc_schemas)\n}\nfabric_config = {\n    'workspace_id': fab_workspace_id,\n    'lakehouse_id': fab_lakehouse_id,\n    'shortcut_connection_id': fab_shortcut_connection_id,\n    \"consider_dbx_uc_table_changes\": fab_consider_dbx_uc_table_changes\n}\nsync_dbx_uc_tables_to_onelake(databricks_config, fabric_config)\n```\n\n가능한 미래 옵션\n\n- Fabric에서 Unity Catalog 네이티브 항목: 하이브 메타스토어 메타데이터 이동과 유사하게, Unity Catalog 메타데이터를 Fabric 레이크하우스로 동기화하여 Unity Catalog 테이블에 액세스할 수 있게 합니다. 이 시나리오의 한 예시는 FabCon에서 시연되었는데, 사용자들이 Fabric UI를 통해 Unity Catalog 테이블에 직접 액세스하고 쿼리할 수 있는 것을 보여주었습니다.\n- Fabric에 Unity Catalog 바로 가기: Dataverse 바로 가기와 유사하게, OneLake 바로 가기 UX는 잠재적으로 Unity Catalog 테이블에 대한 바로 가기 생성을 지원할 수 있을 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n참고: 델타 공유, Databricks에서 JDBC/ODBC, Fabric 데이터 파이프라인 Databricks 활동 등의 옵션은 여기에 언급되지 않았습니다.\n\n# Databricks/Unity 카탈로그 → Fabric\n\n## Databricks/Unity 카탈로그에서 Fabric 및 OneLake 사용하기\n\nUnity 카탈로그는 클라우드 객체 저장소 연결(예: ADLS Gen2)을 활용하고 외부 데이터 시스템에 연결하여 연합 쿼리를 실행하는 다양한 방법을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 현재 옵션입니다. 사용자들은 UC 활성화된 클러스터에서 OneLake를 다음과 같이 사용할 수 있습니다: (i) Service Principal (SPN) 기반 인증을 사용하여 OneLake에 r/w, 그리고 (ii) SPN 인증을 사용하여 mount 지점으로 OneLake에 r/w.\n\n```js\n# spn을 사용한 r/w\nworkspace_name = \"<워크스페이스_이름>\"\nlakehouse_name = \"<레이크하우스_이름>\"\ntenant_id = \"<테넌트_ID>\"\nservice_principal_id = \"<서비스_프린시펄_ID>\"\nservice_principal_password = \"<서비스_프린시펄_비밀번호>\"\n\nspark.conf.set(\"fs.azure.account.auth.type\", \"OAuth\")\nspark.conf.set(\"fs.azure.account.oauth.provider.type\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\nspark.conf.set(\"fs.azure.account.oauth2.client.id\", service_principal_id)\nspark.conf.set(\"fs.azure.account.oauth2.client.secret\", service_principal_password)\nspark.conf.set(\"fs.azure.account.oauth2.client.endpoint\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n\n# 읽기\ndf = spark.read.format(\"parquet\").load(f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/Files/data\")\ndf.show(10)\n\n# 쓰기\ndf.write.format(\"delta\").mode(\"overwrite\").save(f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/Tables/dbx_delta_spn\")\n```\n\n```js\n# spn으로 Mount\nworkspace_id = \"<워크스페이스_ID>\"\nlakehouse_id = \"<레이크하우스_ID>\"\ntenant_id = \"<테넌트_ID>\"\nservice_principal_id = \"<서비스_프린시펄_ID>\"\nservice_principal_password = \"<서비스_프린시펄_비밀번호>\"\n\nconfigs = {\n    \"fs.azure.account.auth.type\": \"OAuth\",\n    \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n    \"fs.azure.account.oauth2.client.id\": service_principal_id,\n    \"fs.azure.account.oauth2.client.secret\": service_principal_password,\n    \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\n}\n\nmount_point = \"/mnt/onelake-fabric\"\ndbutils.fs.mount(\n    source = f\"abfss://{workspace_id}@onelake.dfs.fabric.microsoft.com\",\n    mount_point = mount_point,\n    extra_configs = configs\n)\n\n# 읽기\ndf = spark.read.format(\"parquet\").load(f\"/mnt/onelake-fabric/{lakehouse_id}/Files/data\")\ndf.show(10)\n\n# 쓰기\ndf.write.format(\"delta\").mode(\"overwrite\").save(f\"/mnt/onelake-fabric/{lakehouse_id}/Tables/dbx_delta_mount_spn\")\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알림: OneLake abfss 경로 또는 마운트 경로를 사용하여 외부 테이블을 만들 경우 UC에서 예외가 발생할 수 있습니다. 현재, OneLake를 기본 저장소로 사용하여 UC에 외부 테이블을 등록할 수 없습니다. 이는 잠재적인 미래 시나리오로 이어질 수 있습니다.\n\n- INVALID_PARAMETER_VALUE: 클라우드 파일 시스템 스키마 누락\n- 목록을 위한 SAS 토큰을 획득하지 못했습니다. 유효하지 않은 Azure 경로\n\n잠재적인 미래 옵션\nADLS Gen2와 Azure Synapse와 유사하게, 미래에는 다른 옵션이 존재할 수 있습니다:\n\n- 기본 관리 저장소로서 OneLake: Databricks는 Unity Catalog의 자동 활성화를 시작했습니다. 즉, 자동으로 ADLS Gen2와 같이 Databricks 관리 저장소로 Unity Catalog 메타스토어를 자동으로 프로비저닝합니다. 그러나 사용자는 Unity Catalog 메타스토어를 OneLake를 가리키도록하면서 사용자 관리 수준 저장소를 생성할 수도 있습니다. 참고: 아직 이 기능은 불가능합니다.\n- 외부 위치로서 OneLake: 외부 위치는 카탈로그 및 스키마의 관리 저장소 위치를 정의하고, 외부 테이블 및 외부 볼륨의 위치를 정의하는 데 사용됩니다. 예를 들어, Spark에서 외부 테이블을 사용하는 경우 OneLake를 외부 위치로 활용할 수 있습니다. 참고: 아직 이 기능은 불가능합니다.\n- 볼륨용 OneLake: 볼륨은 클라우드 객체 저장소 위치의 논리적 저장 볼륨을 나타내며 비 탭식 데이터셋에 대한 관리 방식을 추가합니다. ADLS Gen2와 같이 OneLake를 사용하여 외부 및 관리 볼륨을 생성할 수 있습니다. 참고: 아직 이 기능은 불가능합니다.\n- 연합 Lakehouse: SQL 엔드포인트나 Fabric Data Warehouse의 데이터에 대한 읽기 전용 액세스는 UC 외부 카탈로그를 사용하여 미래 옵션으로 가능할 수 있습니다. 현재 Azure Synapse 및 SQL 액세스 인증은 사용자 이름/암호를 기반으로 하며 SPN은 아직 지원되지 않으므로 이 옵션은 아직 불가능합니다. 외부 카탈로그는 현재 객체 저장소를 지원하지 않으므로, 아직 OneLake/Lakehouse로의 외부 카탈로그 연결이 가능한지 여전히 불분명합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n표 태그를 Markdown 형식으로 변경해주세요.\n\n## 잠깐, 액세스 정책은 어떻게 되나요?\n\n다른 옵션으로는 Databricks의 ODBC를 SQL 엔드포인트로 사용하거나 Partner Connect( Power BI + Databricks) 및 스트리밍 옵션이 여기에 언급되지 않았네요.\n\n계속해서 Unity 카탈로그 액세스 정책이 OneLake RBAC 및 OneSecurity와 어떻게 조화를 이루고 있는지, Unity 카탈로그에서 Fabric로 보안 및 액세스 정책을 이동하거나 그 반대로 이동할 수 있는지에 대해 살펴볼 수 있을 것입니다.\n\n참고 문헌:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Non-UC 시나리오: Databricks와 Fabric — OneLake 및 ADLS Gen2에 쓰기 | Aitor Murguzur 작성 | Medium\n- Lakehouse 시나리오: Azure Databricks와 Microsoft Fabric 통합 | Piethein Strengholt 작성 | 2024년 6월 | Medium\n- Databricks Unity Catalog를 OneLake와 통합 — Microsoft Fabric | Microsoft Learn\n","ogImage":{"url":"/assets/img/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios_0.png"},"coverImage":"/assets/img/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios_0.png","tag":["Tech"],"readingTime":10},{"title":"데이터브릭스, 데브옵스 및 파이테스트","description":"","date":"2024-06-19 12:24","slug":"2024-06-19-DatabricksDevOpsandpytest","content":"\nDatabricks에서 코드 품질을 지속적으로 보장하고 DevOps 작업 프로세스에 통합하는 방법에 궁금증을 풀어 보셨나요? 더 이상 망설이지 마세요.\n\n다음 예시에서는 Databricks에서 pytest와 DevOps를 사용하여 구현된 테스트 기능을 쉽게 시작하는 방법에 대해 살펴볼 것입니다.\n\n# 목표\n\n이 글을 마치면 Databricks에 구현된 함수를 테스트하고, DevOps에서 pull request가 제출될 때마다 테스트 스위트를 실행할 수 있게 될 것입니다. 아래에서 이를 어떻게 구현할지 살펴보세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png\" />\n\n# DevOps에서 프로젝트 설정하기\n\nPytest는 두 가지 테스트 레이아웃을 지원하는데, 이 예시에서는 테스트가 애플리케이션 코드 외부에 배치되는 테스트 레이아웃을 사용할 것입니다. 이 분리는 나중에 데브옵스와 데이타브릭스 자산 번들을 사용하여 자동 릴리스를 다루는 기사에서 유용할 것입니다.\n\n```js\nproject.toml;\npipelines / pipeline_pytest.yml;\nsrc / functions / column_funtions.py;\nsoultion / demo_notebook.py;\ntests / test_column_funtions.py;\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 예시에서는 src(소스 코드)와 tests(테스트)로 구성된 두 개의 주요 폴더를 갖춘 간단한 설정이 있습니다. src 폴더는 지원하는 함수를 포함하는 functions와 Lakehouse를 구현하는 노트북을 포함하는 solution 폴더로 구분됩니다.\n\ncolumn_functions.py에서는 주어진 열을 제곱하는 간단한 함수를 구현했습니다.\n\n```python\n# Databricks notebook source\ndef column_squared(df, columnname):\n    df_squared = df.withColumn(columnname + \"_squared\", df[columnname] * df[columnname])\n    return df_squared\n```\n\ntest_column_functions.py에서는 column_functions.py의 함수 기능을 유효성 검사하는 간단한 테스트를 구현했습니다. 여기서 중요한 부분은 외부 데이터 소스나 스파크 세션에 의존하지 않고 독립적으로 유닛 테스트를 구현하고 있다는 것입니다. 입력과 예상 출력을 비교하기 위해 Databricks의 내장 기능을 사용합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport pytest\nfrom pyspark.sql import SparkSession\nfrom pyspark.testing import assertDataFrameEqual\nfrom src.functions.column_functions import column_squared\n\nclass TestColumnFuntions(object):\n    def test_column_squared(self):\n        spark = SparkSession.builder.getOrCreate()\n\n        source_data = [(\"John\", 25), (\"Alice\", 30), (\"Bob\", 35)]\n        source_df = spark.createDataFrame(source_data, [\"name\", \"age\"])\n\n        df_actual = column_squared(source_df,'age')\n\n        expected_data = [(\"John\", 25, 625), (\"Alice\", 30, 900), (\"Bob\", 35, 1225)]\n        df_expected = spark.createDataFrame(expected_data, [\"name\", \"age\", \"age_squared\"])\n\n        assertDataFrameEqual(df_actual, df_expected)\n```\n\n# DevOps 파이프라인\n\n함수와 관련된 테스트를 구현한 후에는 이제 Azure DevOps에서 파이프라인을 설정할 수 있습니다.\n\n파이프라인(pipeline*pytest.yml)에 대해 가상 환경을 Python용으로 생성하고 필요한 패키지를 설치한 다음 'tests' 디렉토리에서 pytest를 실행합니다. 이 경우 pytest-azurepipelines를 사용하여 pytest를 DevOps 파이프라인에 통합합니다. 이제 pytest는 'test*.py'로 시작하거나 '\\_test.py'로 끝나는 모든 테스트를 찾아 이 경로를 따라 이동합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\ntrigger: none\n\nsteps:\n  - task: UsePythonVersion@0\n    inputs:\n      versionSpec: \"3.9\"\n      addToPath: true\n\n  - script: |\n      python -m venv .venv\n      source .venv/bin/activate\n      python -m pip install --upgrade pip\n      pip install numpy==1.22.4\n      pip install pyspark\n      pip install pandas\n      pip install pyarrow\n      pip install pytest-azurepipelines\n      python -m pytest -vv tests\n    displayName: \"pytest\"\n```\n\n이제 메인 브랜치에서 빌드 검증을 설정하여, 개발자가 풀 리퀘스트를 만들 때마다 정의된 테스트가 실행되도록 할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_1.png\" />\n\n# 결론\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 예시에서는 Databricks에서 구현된 기능에 대한 테스트 슈트를 설정하고 DevOps 워크플로에 통합하는 것이 얼마나 간단한지 살펴보았습니다. 이제 프로젝트에 필요한 테스트를 구현하여 지속적으로 고품질 코드를 제공할 수 있도록 만들어 보세요.\n","ogImage":{"url":"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png"},"coverImage":"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png","tag":["Tech"],"readingTime":5},{"title":"단위 테스트 및 코드 모듈화를 위한 Databricks","description":"","date":"2024-06-19 12:22","slug":"2024-06-19-UnitTestingandCodeModularizationinDatabricks","content":"\n노트북은 Databricks에서 데이터를 다루는 인기 있는 방법입니다. 노트북 사용자는 데이터를 빠르게 읽고 변환하며 상호적으로 탐색할 수 있습니다. 게다가, 노트북을 공유하고 협업하는 것은 간단합니다. 그러나 프로젝트가 확장될수록 코드 중복을 방지하고 재사용성을 용이하게 하는 모듈화 기능이 필요해집니다.\n\n이를 달성하는 한 가지 방법은 공유 함수를 포함하는 노트북을 생성하고 각 노트북의 시작 부분에서 실행하는 것입니다. 또는 모듈을 만들어 일반적인 Python 개발과 유사한 Python import 명령어를 사용할 수 있습니다. 긴 코드 블록을 함수로 나누면 코드의 재사용을 촉진할 뿐만 아니라 테스트도 용이해집니다.\n\n![이미지](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png)\n\n## 모듈화\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n파이썬에서 모듈화란 프로그램을 작은 관리 가능한 모듈로 나누는 것을 말합니다. 파이썬에서 코드를 모듈화하는 것에는 여러 가지 이점이 있습니다:\n\n- 재사용성: 모듈은 다른 프로젝트에서 다시 사용할 수 있어 재작성이 필요하지 않습니다.\n- 유지보수성: 작은 중점적인 모듈로 인해 업데이트와 디버깅이 쉬워집니다.\n- 확장성: 프로젝트가 성장할 때 효율적인 확장이 가능합니다.\n- 협업: 다른 개발자들이 동시에 작업하기를 용이하게 합니다.\n- 테스트: 단위 테스트가 간소화되어 더 신뢰할 수 있는 코드를 작성할 수 있습니다.\n- 가독성: 특정 작업에 집중함으로써 코드 이해가 향상됩니다.\n\nDatabricks에서 모듈을 사용하기 위해서는 클래스 또는 함수를 포함한 파일들로 구성된 폴더와 **init**.py 파일을 생성해야 합니다. 이는 Databricks에 모듈임을 알려줍니다. 아래는 공통 모듈과 함께 공유 함수, 변환 로직을 포함한 변환 모듈, 그리고 테스트 데이터가 포함된 내 솔루션의 구조입니다.\n\n코드 구조:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n워크스페이스\n├── test_data\n│    └── testdata.csv\n├── common\n│    └── __init__.py\n│    └── utilis.py\n├── transform\n│    └── __init__.py\n│    └── operations.py\n├── test_utils.py\n├── test_tran.py\n├── test\n```\n\ntestdata.csv:\n\n```js\nentity,iso_code,date,indicator,value\nUnited States,USA,2022-04-17,Daily ICU occupancy,\nUnited States,USA,2022-04-17,Daily ICU occupancy per million,4.1\nUnited States,USA,2022-04-17,Daily hospital occupancy,10000\nUnited States,USA,2022-04-17,Daily hospital occupancy per million,30.3\nUnited States,USA,2022-04-17,Weekly new hospital admissions,11000\nUnited States,USA,2022-04-17,Weekly new hospital admissions per million,32.8\n```\n\nulits.py:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\n\ndef mask_func(col_val):\n    if col_val is not None:\n        if len(col_val)>=16:\n            charList=list(col_val)\n            charList[4:12]='x'*8\n            return \"\".join(charList)\n        else:\n            return col_val\n    else:\n        return col_val\n```\n\noperations.py:\n\n```js\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import row_number, col\n\ndef deduplicate(df, uniq_col, orderby_col):\n    df = df.withColumn(\"rn\", row_number()\n        .over(Window.partitionBy(uniq_col)\n        .orderBy(col(orderby_col).desc())))\n\n    df = df.filter(col(\"rn\") == 1).drop(\"rn\")\n    return df\n\ndef clean_clients(df):\n    df = df.where(col(\"name\") != \"\").withColumn(\"timestamp\", col(\"timestamp\").cast(\"date\"))\n\n    return df\n```\n\n모듈에서 이러한 함수를 사용하려는 사람은 아래 예시와 같이 import 명령을 사용하여 노트북에 쉽게 추가할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![UnitTestingandCodeModularizationinDatabricks1](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_1.png)\n\nSimilarly, it’s possible to import transformation functions from the module and remove duplicated records from the DataFrame.\n\n![UnitTestingandCodeModularizationinDatabricks2](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_2.png)\n\n# Unit Testing in Databricks\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n소프트웨어 개발에서 단위 테스트는 코드의 정확성, 안정성, 유지 보수 가능성을 보장하는 중요한 요소입니다. 데이터 처리를 위해 노트북이 일반적으로 사용되는 Databricks에서는 단위 테스트가 더욱 중요해집니다.\n\nDatabricks에서 단위 테스트를 시작하려면 코드를 테스트할 수 있는 함수로 분해해야 합니다. 이 프로세스는 코드의 모듈성을 향상시키는 것뿐만 아니라 포괄적인 테스트 스위트를 작성하는 데 도움이 됩니다. Python에서 유닛 테스트를 수행하는 두 가지 인기있는 프레임워크인 Unittest와 pytest가 있습니다.\n\nUnittest 예시:\n\n```python\nimport unittest\n\nclass ExampleTestSuite(unittest.TestCase):\n\n    def test_import(self):\n        self.assertTrue(True)\n\n    def test_addition(self):\n        self.assertEqual(1 + 2, 3)\n\n    def test_subtraction(self):\n        self.assertNotEqual(1 - 2, 0)\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 왜 단위 테스팅을 해야 할까요?\n\n처음 테스트 중에 코드가 정상적으로 작동하는 것처럼 보이더라도, 단위 테스트는 여러 가지 이유로 중요한 역할을 합니다:\n\n- 정확성 확인: 단위 테스트는 코드의 개별 단위 기능을 확인하여 다양한 조건에서 예상대로 작동하는지 확인합니다.\n- 초기 버그 탐지: 개발 과정 초기에 버그를 식별함으로써, 개발자는 이를 신속히 해결하여 시스템의 다른 부분으로 전파되는 가능성을 줄일 수 있습니다.\n- 리팩토링 및 유지보수: 단위 테스트는 코드 리팩토링 및 유지보수 과정에서 안전망 역할을 하며, 개발자가 확신을 갖고 변경을 가할 수 있으면서도 일관된 동작을 보장합니다.\n- 회귀 테스트: 단위 테스트는 회귀 테스트로 작용하여 새로운 변경사항이나 기능이 기존의 기능을 망가뜨리지 않도록 하여 시스템의 안정성을 유지합니다.\n\n마스킹 기능에 대한 단위 테스트의 간단한 예제를 살펴보겠습니다. 이 단위 테스트는 입력 숫자가 올바르게 마스킹되거나 None을 반환하는지를 확인하여, 함수가 변경되더라도 예상되는 동작이 유지되도록 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\ntest_utils.py\n\n```python\nfrom common.utils import mask_func\n\ndef test_mask_func():\n    assert \"1234xxxxxxxx4568\" == mask_func(\"1234567891234568\")\n    assert mask_func(None) is None\n```\n\nETL(Extract, Transform, Load)과 같은 복잡한 프로세스의 경우, 데이터 변환 과정의 다양한 측면을 확인하는 데 개선된 테스트를 개발할 수 있습니다. 이러한 테스트에는 스키마 확인, 데이터프레임 비교, 행 수 유효성 검사 또는 특정 값의 존재 여부 확인이 포함될 수 있습니다.\n\ntest_tran.py:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport pytest\nfrom transform.operations import *\nfrom pyspark.testing.utils import assertDataFrameEqual\nfrom pyspark.sql import SparkSession\nfrom pyspark.testing import assertDataFrameEqual, assertSchemaEqual\nfrom pyspark.sql.types import *\nimport pandas as pd\n\n@pytest.fixture()\ndef spark():\n    return SparkSession.builder.appName(\"integrity-tests\").getOrCreate()\n\n@pytest.fixture()\ndef raw_input_df(spark):\n    df = pd.read_csv('test_data/testdata.csv')\n    return spark.createDataFrame(df)\n\n@pytest.fixture()\ndef test_df(spark):\n\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Los Angeles\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df = spark.createDataFrame(input_data, schema)\n\n    return df\n\ndef test_deduplicate(test_df, spark):\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df = spark.createDataFrame(input_data, schema)\n\n    df1 = deduplicate(test_df, \"Name\", \"timestamp\")\n    assertDataFrameEqual(df1, df)\n\ndef test_schema_deduplicated(test_df, spark):\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df_expected = spark.createDataFrame(input_data, schema)\n\n    test_df = deduplicate(test_df, \"Name\", \"timestamp\")\n    assertSchemaEqual(test_df.schema, df_expected.schema)\n\ndef test_clean_clients(test_df, spark):\n    df = clean_clients(test_df)\n    assert df.where(\"name == '' \").count() == 0\n\ndef test_readfromfile(raw_input_df):\n    assert raw_input_df.count() > 0\n```\n\n## Initializing Spark Session for Tests:\n\n테스트 파일은 주피터 노트북이 아니기 때문에, Spark 세션을 초기화하는 것이 필요합니다. 이를 위해서 `spark` 함수와 `fixture` 데코레이터를 사용해서 Spark 세션을 만들 수 있습니다. `fixture` 데코레이터는 자동으로 실행되며 각 테스트 함수에 해당하는 테스트 객체를 제공해주어 테스트 데이터의 생성 및 공유를 간편하게 할 수 있습니다.\n\n```js\n@pytest.fixture()\ndef spark():\n    return SparkSession.builder.appName(\"integrity-tests\").getOrCreate()\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n선언했던 fixture 데코레이터의 동작 방식을 주목하는 것이 중요합니다. 이 기법을 사용하면 테스트 데이터를 원활하게 실행하고 전달할 수 있습니다. 이 기법을 이용하면 Spark 세션을 생성하여 테스트 데이터를 로드하고 이를 테스트 함수 사이에서 공유할 수 있습니다. 테스트 데이터는 목록을 기반으로 생성하거나 테스트 파일에서 로드할 수 있습니다.\n\n```js\n@pytest.fixture()\ndef raw_input_df(spark):\n df = pd.read_csv('test_data/testdata.csv')\n\n return spark.createDataFrame(df)\n```\n\n테스트용 데이터 원본으로 샘플 파일을 사용하는 것도 가능합니다. 그러나 워크스페이스에서 로드해야 하는 경우에는 Spark가 워크스페이스로부터 파일을 직접 로드하는 것을 지원하지 않기 때문에 Pandas를 사용해야 합니다.\n\n## 모듈의 지연 변경 사항 처리하기:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모듈을 다룰 때 변경 내용을 구현하는 데 지연이 발생하는 것은 일반적입니다. 이 동작을 해결하기 위해 매직 함수를 사용할 수 있습니다:\n\n```js\n%load_ext autoreload\n\n%autoreload 2\n\n%aimport test_tran\n```\n\n# Databricks에서 단위 테스트 실행\n\nDatabricks에서 단위 테스트를 실행하려면 pytest 모듈을 호출하는 노트북을 생성해야 합니다. 아래는 지정된 저장소에서 테스트 실행을 트리거하는 코드 스니펫입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테스트 노트북:\n\n```js\n%pip install pytest\n```\n\n```js\nimport pytest\nimport sys\nimport os, sys\n\nrepo_name = \"<저장소 위치>\"\n\nnotebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\nrepo_root = os.path.dirname(os.path.dirname(notebook_path))\n\nos.chdir(f\"/Workspace/{repo_root}/{repo_name}\")\nprint(os.getcwd())\n# 읽기 전용 파일 시스템에 pyc 파일을 쓰지 않도록 설정합니다.\nsys.dont_write_bytecode = True\n\n# pytest 실행.\nretcode = pytest.main([\".\", \"-v\", \"-p\", \"no:cacheprovider\"])\n\n# 테스트 실패가 있는 경우 셀 실행 실패 처리합니다.\nassert retcode == 0, \"pytest 호출에 실패했습니다. 자세한 내용은 로그를 확인하세요.\"\n```\n\npytest를 실행하면 현재 디렉토리와 서브디렉토리에서 이름이 test\\__.py 또는 _\\_test.py 패턴을 따르는 모든 파일을 자동으로 실행합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n스크립트를 실행하면 다음과 비슷한 보고서가 표시됩니다:\n\n![보고서](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_4.png)\n\n# 요약\n\n요약하면 모듈화와 유닛 테스팅은 소프트웨어 개발에서 널리 사용되는 관행이며, 이러한 적용은 데이터 엔지니어링 활동에 매끄럽게 확장됩니다. 코드의 모듈화 및 유닛 테스트를 구현하여 데이터 처리 솔루션이 더욱 신뢰성 있고 유연해집니다. 모듈화는 코드 구성 요소의 더 나은 조직화와 재사용을 가능하게 하며, 유닛 테스트는 각 구성 요소가 다양한 조건에서 예상대로 동작하는지 확인합니다. 이러한 기술들이 함께 사용되면 데이터 엔지니어링 솔루션의 전체적인 견고성과 유지보수성에 기여하며, 마지막으로 데이터 처리 파이프라인 및 워크플로의 품질을 향상시킵니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 이 기사를 유익하게 여기셨다면, 'clap' 버튼을 클릭하거나 LinkedIn에서 좋아요를 표시해 주시면 감사하겠습니다. 여러분의 지원을 감사히 여깁니다. 궁금한 점이나 조언이 있으시다면 언제든 LinkedIn에서 연락해 주세요.\n","ogImage":{"url":"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png"},"coverImage":"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png","tag":["Tech"],"readingTime":13},{"title":"데이터  AI 서밋 by Databricks 2024의 주요 통찰 결과","description":"","date":"2024-06-19 12:21","slug":"2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024","content":"\nData + AI Summit by Databricks에서 얻은 주요 인사이트가 공개되었습니다! 다음과 같은 데이터 및 분석 공간의 흥미로운 업데이트가 있습니다.\n\n🚀 Unity Catalog가 이제 오픈 소스로 공개되었습니다! Duck DB와 같은 도구에서 Unity Catalog의 Delta 테이블에 외부에서 액세스할 수 있습니다. Azure Synapse, Azure SQL, Amazon Redshift, Snowflake를 추가하여 새로운 외부 데이터 소스에 연결할 수 있습니다.\n\n🛡️ Delta 테이블에 대한 규칙을 만들어 Unity Catalog에서 행 수준 보안 및 열 수준 가리기가 일반적으로 사용 가능해졌습니다.\n\n빌트인 데이터 품질 세부 정보로 GA로 된 Lake House 모니터링은 Delta 테이블을 모니터링하는 데 도움이 됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n📊 Unity Catalog metrics가 Databricks 및 Power BI, Tableau와 같은 외부 사용자를 위해 도입되어 데이터를 신뢰하고 사용할 수 있습니다.\n\n🔥 Delta 4.0은 파티셔닝과 관련된 문제를 극복하기 위해 더 나은 성능을 제공하는 Liquid 클러스터링을 도입했습니다. 작성 시 7배, 읽기 시 12배 빠른 성능을 제공합니다. JSON을 variant 데이터 유형으로 저장하는 VARIANT도 제공됩니다.\n\n💻 7월 1일부터 스파크 클러스터를 위한 100% 서버리스 인프라를 제공합니다. 초고속 클러스터를 즐기고 사용한 만큼 지불하며, 유휴 시간 요금은 없습니다. 클러스터 크기 조정, 자동 확장성, 스팟 인스턴스와 같은 복잡성에 작별을 고하세요.\n\n🔄 Databricks Lakeflow (곧 미리 보기 예정)는 DLT와 워크플로에 기반하여 데이터 수집, 변환, 오케스트레이션, 데이터 파이프라인의 모니터링을 간편화하는 솔루션입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n🔍 Databricks SQL은 이제 빠른 클러스터 시작, 향상된 성능, SQL UDF, 세션 변수, 그리고 SQL 분석가를 위한 AI 기능을 갖춘 데이터 웨어하우징 핵심 기능을 제공합니다.\n\n🤖 Databricks AI/BI에는 챗봇 \"Genie\"가 포함되어 있으며, Gen AI는 자연어 쿼리에서 자동으로 BI 대시보드를 만들어서 셀프 서비스 보고를 가능하게 합니다.\n\nApache Iceberg Tabular의 인수로 Delta lake에 이제 UniForm 형식을 통합하여 Parquet 및 Delta 형식과 함께 제공됩니다.\n\n스파크 4.0이 곧 출시될 예정이며 흥미로운 업데이트가 예정되어 있습니다. 더 많은 혁신을 기대해 주세요!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n새로운 기능들을 탐험하는 것을 기대하고 있어요!\n\n만약 이 기사를 좋아하신다면, 저의 링크드인 페이지에서 저를 팔로우해주세요. https://www.linkedin.com/in/kaviprakash-selvaraj/\n","ogImage":{"url":"/assets/img/2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024_0.png"},"coverImage":"/assets/img/2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024_0.png","tag":["Tech"],"readingTime":3}],"page":"43","totalPageCount":120,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}