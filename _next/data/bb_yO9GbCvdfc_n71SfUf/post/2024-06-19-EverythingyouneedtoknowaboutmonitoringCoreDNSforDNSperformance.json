{"pageProps":{"post":{"title":"DNS 성능을 모니터링하기 위해 알아야 할 모든 것","description":"","date":"2024-06-19 13:07","slug":"2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance","content":"\n![CoreDNS Monitoring](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png)\n\n# 📚 소개:\n\nDNS 집중 워크로드를 실행할 때 종종 DNS 쓰로틀링에 의한 간헐적인 CoreDNS 실패가 발생할 수 있습니다. 이러한 문제는 애플리케이션에 중대한 영향을 미칠 수 있습니다.\n\n이러한 중단은 서비스의 신뢰성과 성능에 영향을 미칠 수 있으므로 모니터링 솔루션이 필수적입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAWS는 모니터링 목적으로 통합할 수 있는 오픈 소스 도구인 CloudWatch, Fluentd 및 Grafana를 제공합니다. 이 도구들은 CoreDNS를 모니터링하는 데 사용할 수 있습니다.\n\n# Kubernetes DNS 소개:\n\nKubernetes는 클러스터 내에서 서비스 검색에 DNS를 의존합니다. 팟에서 실행되는 응용 프로그램이 서로 통신해야 할 때, 그들은 주로 IP 주소가 아닌 도메인 이름을 사용하여 서비스를 참조합니다.\n\n이 때 Kubernetes DNS가 필요합니다. 이는 도메인 이름이 올바른 IP 주소로 해석되도록 보장하여 팟과 서비스가 통신할 수 있도록 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKubernetes에서는 각 파드마다 일시적인 IP 주소가 할당됩니다. 그러나 이러한 IP 주소는 동적이며 시간이 지남에 따라 변경될 수 있어, 애플리케이션이 이를 추적하기 어렵습니다.\n\nKubernetes는 이러한 도전에 대응하기 위해 파드와 서비스에 완전히 정규화된 도메인 이름(FQDNs)을 할당합니다.\n\nKubernetes의 기본 DNS 제공자인 CoreDNS는 클러스터 내에서 DNS 쿼리를 처리하는 역할을 담당합니다. 그는 이러한 FQDN을 해당 IP 주소로 매핑하여 파드와 서비스 간의 통신을 가능하게 합니다.\n\n# 왜 DNS 문제가 흔할까요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n네트워크 문제 해결 중 공통적으로 발생하는 번거로움의 원인 중 하나인 DNS 문제! DNS는 사람이 읽기 쉬운 도메인 이름을 기계가 이해할 수 있는 IP 주소로 변환하는 데 큰 역할을 합니다.\n\n그러나 DNS 문제는 설정 오류, 네트워크 문제 또는 서버 장애와 같은 여러 요인으로 발생할 수 있습니다. 도메인 이름을 올바르게 해석하지 못할 때 애플리케이션이 외부 서비스에 연결 문제를 경험하거나 액세스에 실패할 수 있습니다.\n\n# 쿠버네티스의 CoreDNS:\n\nCoreDNS는 쿠버네티스 클러스터 내에서 DNS 서비스를 제공하는 데 중요한 역할을 합니다. Kubernetes v1.13 이후 기본 DNS 제공자로 사용되어 온 CoreDNS는 DNS 이름 대신 IP 주소 대신 DNS 이름을 사용하여 클라이언트가 서비스에 액세스할 수 있도록 함으로써 클러스터 네트워킹을 간소화합니다. 그는 도메인 이름 요청을 해결하고 클러스터 내에서 서비스 검색을 용이하게 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 코어디엔에스의 작동 방식:\n\n코어디엔에스는 쿠버네티스 클러스터 내에서 DNS 요청의 리졸버 및 포워더로 작동합니다. 파드가 다른 서비스와 통신해야 할 때, 대상 서비스의 도메인 이름을 지정하여 DNS 쿼리를 코어디엔에스에 보냅니다. 그럼 코어디엔에스는 내부 레코드를 사용하여 도메인 이름을 해당 IP 주소로 매핑하여 이 쿼리를 해결합니다.\n\n코어디엔에스가 권한이 없는 외부 도메인 이름에 대해서는, 이를 공개 리졸버나 상위 DNS 서버로 전달하여 해결합니다.\n\n성능을 향상시키고 대기 시간을 줄이기 위해 코어디엔에스는 자주 액세스하는 도메인 이름에 대한 DNS 응답을 캐시할 수 있습니다. 이 캐싱 메커니즘은 DNS 쿼리의 응답 속도를 향상시키고 상위 DNS 서버의 부하를 줄입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nCoreDNS는 이 기능을 모듈식 아키텍처와 확장 가능한 플러그인 시스템을 통해 구현하며, 운영자가 독자적인 요구 사항에 따라 DNS 해상도를 사용자 정의하고 최적화할 수 있게 합니다.\n\n# Amazon EKS에서의 CoreDNS 쓰로틀링 완화 방법:\n\nAmazon EKS 클러스터에서 CoreDNS와 DNS 쓰로틀링 문제는 식별하고 해결하기 어려울 수 있습니다. 많은 사용자가 CoreDNS 로그와 메트릭을 모니터링하는 데 주력하지만, 엘라스틱 네트워크 인터페이스(ENI) 수준에서 강제되는 초당 1024개 패킷(PPS)의 하드 제한을 자주 간과합니다. 이 한계가 쓰로틀링 문제로 이어질 수 있는 방식을 이해하려면 Kubernetes 파드의 전형적인 DNS 해상도 흐름에 대한 통찰력이 필요합니다.\n\nKubernetes 환경에서는 파드가 통신을 가능하게 하기 위해 내부 및 외부 서비스의 도메인 이름을 해상해야 합니다. 이 해상도 프로세스는 DNS 쿼리를 워커 노드의 ENI를 통해 라우팅하는 것을 포함하며, 특히 외부 엔드포인트를 해상하는 경우입니다. 내부 엔드포인트의 경우에도 쿼리하는 파드와 동일한 위치에 CoreDNS 파드가 없으면 DNS 패킷이 여전히 워커 노드의 ENI를 통해 이동합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n갑자기 DNS 쿼리가 급증하여 PPS가 하드 제한값 1024에 접근하는 상황이 발생할 수 있습니다. 이러한 상황은 DNS 쓰로틀링을 유발할 수 있으며, 이로 인해 영향을 받는 작업 노드에서 실행 중인 모든 마이크로서비스에 영향을 미칠 수 있습니다. 유감스럽게도, 이러한 문제 해결은 주로 CoreDNS pod에 초점을 맞추는 ENI 메트릭보다 어려울 수 있습니다.\n\nEKS 클러스터에서 DNS 쓰로틀링 문제를 완화하기 위해서는 ENI 수준에서 발생하는 패킷 손실을 지속적으로 모니터링하는 것이 중요합니다. 이 모니터링을 통해 잠재적인 중단을 조기에 감지하고 예방할 수 있습니다. 이 블로그 포스트에서는 네트워크 성능 메트릭을 활용하여 DNS 쓰로틀링 문제를 효과적으로 식별하는 솔루션을 소개합니다.\n\n## 해결책: 🎉\n\n작업 노드에서 DNS 쓰로틀링 문제를 식별하는 간단한 방법은 Elastic Network Adapter (ENA) 드라이버에서 제공하는 linklocal_allowance_exceeded 메트릭 및 다른 메트릭을 캡처하는 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n`linklocal_allowance_exceeded`은 로컬 프록시 서비스로의 트래픽 PPS가 네트워크 인터페이스의 최대를 초과하여 드롭된 패킷 수입니다. 이는 DNS 서비스, 인스턴스 메타데이터 서비스 및 Amazon 시간 동기화 서비스로의 트래픽에 영향을 줍니다.\n\n이 이벤트를 실시간으로 추적하는 대신, 우리는 이 메트릭을 Amazon Managed Service for Prometheus로 스트리밍하고 Amazon Managed Grafana에서 시각화할 수도 있습니다.\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_1.png)\n\n# 실전: AWS EKS에서 CoreDNS 메트릭 수집 및 시각화:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nCoreDNS 프로메테우스 플러그인은 OpenMetrics 형식으로 메트릭을 노출하며, 이는 프로메테우스 형식에서 발전한 텍스트 기반 표준입니다. Kubernetes 클러스터에서는 플러그인이 기본적으로 활성화되어 있어 클러스터를 시작하는 즉시 많은 중요한 메트릭을 모니터링할 수 있습니다.\n\n기본 설정에서 프로메테우스 플러그인은 각 CoreDNS 팟의 포트 9153에 있는 /metrics 엔드포인트에 메트릭을 기록합니다.\n\nAmazon Managed Service for Prometheus 워크스페이스와 Managed Service for Grafana를 생성하세요:\n\n이 단계에서는 Amazon Managed Service for Prometheus 및 Managed Service for Grafana를 위한 워크스페이스를 생성합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 파일 구성은 다음을 생성합니다:\n\n- AMP 작업 공간\n- AMP 경보 관리자 정의.\n\nmain.tf:\n\n```js\nmodule \"prometheus\" {\n  source = \"terraform-aws-modules/managed-service-prometheus/aws\"\n\n  workspace_alias = \"demo-coredns\"\n\n  alert_manager_definition = <<-EOT\n  alertmanager_config: |\n    route:\n      receiver: 'default'\n    receivers:\n      - name: 'default'\n  EOT\n\n  rule_group_namespaces = {}\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nversions.tf:\n\n```js\nterraform {\n  required_version = \">= 1.3\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \">= 5.32\"\n    }\n  }\n}\n```\n\n테라폼을 실행하려면 다음을 실행해야 합니다:\n\n```js\n$ terraform init\n$ terraform plan\n$ terraform apply\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래 구성 파일은 다음과 같은 것을 생성합니다:\n\n- 기본 Grafana 작업 공간 (모듈에서 제공하는 기본값 사용)\n\nmain.tf:\n\n```js\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  region      = \"eu-west-1\"\n  name        = \"amg-ex-${replace(basename(path.cwd), \"_\", \"-\")}\"\n  description = \"AWS Managed Grafana service for ${local.name}\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n}\n\n################################################################################\n# Managed Grafana Module\n################################################################################\n\nmodule \"managed_grafana\" {\n  source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n  # Workspace\n  name                      = local.name\n  associate_license         = false\n  description               = local.description\n  account_access_type       = \"CURRENT_ACCOUNT\"\n  authentication_providers  = [\"AWS_SSO\"]\n  permission_type           = \"SERVICE_MANAGED\"\n  data_sources              = [\"CLOUDWATCH\", \"PROMETHEUS\", \"XRAY\"]\n  notification_destinations = [\"SNS\"]\n  stack_set_name            = local.name\n  grafana_version           = \"9.4\"\n\n  configuration = jsonencode({\n    unifiedAlerting = {\n      enabled = true\n    },\n    plugins = {\n      pluginAdminEnabled = false\n    }\n  })\n\n  # vpc configuration\n  vpc_configuration = {\n    subnet_ids = module.vpc.private_subnets\n  }\n  security_group_rules = {\n    egress_postgresql = {\n      description = \"Allow egress to PostgreSQL\"\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      cidr_blocks = module.vpc.private_subnets_cidr_blocks\n    }\n  }\n\n  # Workspace API keys\n  workspace_api_keys = {\n    viewer = {\n      key_name        = \"viewer\"\n      key_role        = \"VIEWER\"\n      seconds_to_live = 3600\n    }\n    editor = {\n      key_name        = \"editor\"\n      key_role        = \"EDITOR\"\n      seconds_to_live = 3600\n    }\n    admin = {\n      key_name        = \"admin\"\n      key_role        = \"ADMIN\"\n      seconds_to_live = 3600\n    }\n  }\n\n  # Workspace IAM role\n  create_iam_role                = true\n  iam_role_name                  = local.name\n  use_iam_role_name_prefix       = true\n  iam_role_description           = local.description\n  iam_role_path                  = \"/grafana/\"\n  iam_role_force_detach_policies = true\n  iam_role_max_session_duration  = 7200\n  iam_role_tags                  = { role = true }\n\n\n  tags = local.tags\n}\n\nmodule \"managed_grafana_default\" {\n  source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n  name              = \"${local.name}-default\"\n  associate_license = false\n\n  tags = local.tags\n}\n\nmodule \"managed_grafana_disabled\" {\n  source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n  name   = local.name\n  create = false\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n  public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 48)]\n\n  enable_nat_gateway = false\n  single_nat_gateway = true\n\n  tags = local.tags\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\"versions.tf\" 파일입니다:\n\n```js\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \">= 5.0\"\n    }\n  }\n}\n```\n\n이 코드를 실행하려면 다음을 실행해야 합니다:\n\n```js\n$ terraform init\n$ terraform plan\n$ terraform apply\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로메테우스 ethtool 익스포터 배치:\n\nethtool은 워커 노드의 이더넷 장치에 대한 정보를 구성하고 수집하는 리눅스 도구입니다. 우리는 ethtool의 출력을 사용하여 패킷 손실을 감지하고 이를 프로메테우스 ethtool 익스포터 유틸리티를 사용하여 프로메테우스 형식으로 변환할 것입니다.\n\n배포에는 ethtool에서 정보를 가져 와서 프로메테우스 형식으로 게시하는 Python 스크립트가 포함되어 있습니다.\n\n```js\nkubectl apply -f https://raw.githubusercontent.com/Showmax/prometheus-ethtool-exporter/master/deploy/k8s-daemonset.yaml\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 ADOT 수집기를 배포하고 ADOT 수집기를 구성하여 Amazon Managed Service for Prometheus로 메트릭을 수집할 것입니다.\n\n우리는 Amazon EKS 애드온을 사용하여 ADOT 오퍼레이터를 CoreDNS 모니터링을 위해 메트릭 \"linklocal_allowance_exceeded\"를 Amazon Managed Service for Prometheus로 보내게 될 것입니다.\n\nIAM 역할과 Amazon EKS 서비스 계정을 생성하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nADOT 수집기를 Kubernetes 서비스 계정 \"adot-collector\"의 신원으로 배포할 예정입니다. 서비스 계정에 IAM 역할(IRSA)을 연결하여 Kubernetes 서비스 계정에 AmazonPrometheusRemoteWriteAccess 역할을 할당함으로써 해당 서비스 계정을 활용하는 모든 파드가 Amazon Managed Service for Prometheus에 메트릭을 수집하는 데 필요한 IAM 권한을 부여할 수 있습니다.\n\n스크립트를 실행하려면 kubectl 및 eksctl CLI 도구가 필요합니다. 이 도구들은 Amazon EKS 클러스터에 액세스할 수 있도록 구성되어 있어야 합니다.\n\n```js\neksctl create iamserviceaccount \\\n--name adot-collector \\\n--namespace default \\\n--region eu-west-1\\\n--cluster coredns-monitoring-demo\\\n--attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess \\\n--approve \\\n--override-existing-serviceaccounts\n```\n\nADOT 애드온 설치하기:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여러분은 다음 명령어를 사용하여 Amazon EKS의 다른 버전에 활성화된 애드온 목록을 확인할 수 있습니다:\n\n클러스터 버전에서 지원하는 ADOT 버전을 확인하십시오.\n\n```js\naws eks describe-addon-versions --addon-name adot --kubernetes-version 1.28 \\\n  --query \"addons[].addonVersions[].[addonVersion, compatibilities[].defaultVersion]\" --output text\n```\n\n다음 명령어를 실행하여 ADOT 애드온을 설치하십시오. 위 단계에서 기술된 것에 따라 --addon-version 플래그를 교체하십시오.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\naws eks create-addon --addon-name adot --addon-version v0.66.0-eksbuild.1 --cluster-name coredns-monitoring-demo\n```\n\n다음 명령어를 사용하여 ADOT 애드온이 준비되었는지 확인하세요.\n\n```js\nkubectl get po -n opentelemetry-operator-system\n```\n\n다음 절차는 배포를 모드 값으로 사용하는 예제 YAML 파일을 사용합니다. 이는 기본 모드이며 ADOT Collector를 독립 애플리케이션과 유사하게 배포합니다. 이 구성은 샘플 애플리케이션으로부터 OTLP 메트릭을 수신하고 클러스터의 pod에서 스크래핑된 Amazon Managed Service for Prometheus 메트릭을 수신합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\ncurl -o collector-config-amp.yaml https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml\n\ncollector-config-amp.yaml 파일에서 다음을 본인의 값으로 바꿔주세요: _ mode: deployment _ serviceAccount: adot-collector _ endpoint: \"\" _ region: \"\" \\* name: adot-collector\n\nkubectl apply -f collector-config-amp.yaml\n\nadot collector가 배포되면 메트릭이 Amazon Prometheus에 성공적으로 저장됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAmazon Managed Grafana에서 ethtool 메트릭을 시각화해보세요:\n\nAmazon Managed Grafana 콘솔 내에서 Prometheus 워크스페이스를 데이터 소스로 구성합니다.\n\n이제 Amazon Managed Grafana에서 메트릭을 살펴봅시다: \"탐색\" 버튼을 클릭한 후 ethtool을 검색하세요:\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_2.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n링크로컬 할당 초과 메트릭을 사용하여 대시보드를 만들어 봅시다. 쿼리는 다음과 같습니다.\n\n```js\nrate(node_net_ethtool{device=\"eth0\",type=\"linklocal_allowance_exceeded\"} [30s])\n```\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_3.png)\n\n값이 0이기 때문에 드랍된 패킷이 없다는 것을 확인할 수 있습니다. Amazon Managed Service for Prometheus의 경고 관리자에서 알림을 구성하여 알림을 보낼 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론:\n\n이 글에서는 AWS Distro for OpenTelemetry (ADOT), Amazon Managed Service for Prometheus 및 Amazon Managed Grafana를 사용하여 CoreDNS 쓰로틀링 문제를 모니터링하고 경고를 생성하는 방법을 보여드렸습니다. CoreDNS 메트릭을 모니터링함으로써 고객은 패킷 손실을 사전에 감지하고 예방 조치를 취할 수 있습니다.\n\n다음에 또 만나요 🇵🇸 🎉\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n읽어 주셔서 감사합니다!! 🙌🏻😁📃, 다음 블로그에서 만나요.🤘🇵🇸\n\n🚀 끝까지 함께해 줘서 감사합니다. 이 블로그에 관한 질문/피드백이 있으면 언제든지 연락해 주세요:\n\n♻️ 🇵🇸LinkedIn: https://www.linkedin.com/in/rajhi-saif/\n\n♻️🇵🇸 Twitter : https://twitter.com/rajhisaifeddine\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n끝! ✌🏻\n\n# 🔰 계속 배우고!! 계속 공유해요!! 🔰\n\n# 참고:\n\n[https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/](https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/)\n","ogImage":{"url":"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png"},"coverImage":"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png","tag":["Tech"],"readingTime":19},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png\" alt=\"CoreDNS Monitoring\"></p>\n<h1>📚 소개:</h1>\n<p>DNS 집중 워크로드를 실행할 때 종종 DNS 쓰로틀링에 의한 간헐적인 CoreDNS 실패가 발생할 수 있습니다. 이러한 문제는 애플리케이션에 중대한 영향을 미칠 수 있습니다.</p>\n<p>이러한 중단은 서비스의 신뢰성과 성능에 영향을 미칠 수 있으므로 모니터링 솔루션이 필수적입니다.</p>\n<p></p>\n<p>AWS는 모니터링 목적으로 통합할 수 있는 오픈 소스 도구인 CloudWatch, Fluentd 및 Grafana를 제공합니다. 이 도구들은 CoreDNS를 모니터링하는 데 사용할 수 있습니다.</p>\n<h1>Kubernetes DNS 소개:</h1>\n<p>Kubernetes는 클러스터 내에서 서비스 검색에 DNS를 의존합니다. 팟에서 실행되는 응용 프로그램이 서로 통신해야 할 때, 그들은 주로 IP 주소가 아닌 도메인 이름을 사용하여 서비스를 참조합니다.</p>\n<p>이 때 Kubernetes DNS가 필요합니다. 이는 도메인 이름이 올바른 IP 주소로 해석되도록 보장하여 팟과 서비스가 통신할 수 있도록 합니다.</p>\n<p></p>\n<p>Kubernetes에서는 각 파드마다 일시적인 IP 주소가 할당됩니다. 그러나 이러한 IP 주소는 동적이며 시간이 지남에 따라 변경될 수 있어, 애플리케이션이 이를 추적하기 어렵습니다.</p>\n<p>Kubernetes는 이러한 도전에 대응하기 위해 파드와 서비스에 완전히 정규화된 도메인 이름(FQDNs)을 할당합니다.</p>\n<p>Kubernetes의 기본 DNS 제공자인 CoreDNS는 클러스터 내에서 DNS 쿼리를 처리하는 역할을 담당합니다. 그는 이러한 FQDN을 해당 IP 주소로 매핑하여 파드와 서비스 간의 통신을 가능하게 합니다.</p>\n<h1>왜 DNS 문제가 흔할까요:</h1>\n<p></p>\n<p>네트워크 문제 해결 중 공통적으로 발생하는 번거로움의 원인 중 하나인 DNS 문제! DNS는 사람이 읽기 쉬운 도메인 이름을 기계가 이해할 수 있는 IP 주소로 변환하는 데 큰 역할을 합니다.</p>\n<p>그러나 DNS 문제는 설정 오류, 네트워크 문제 또는 서버 장애와 같은 여러 요인으로 발생할 수 있습니다. 도메인 이름을 올바르게 해석하지 못할 때 애플리케이션이 외부 서비스에 연결 문제를 경험하거나 액세스에 실패할 수 있습니다.</p>\n<h1>쿠버네티스의 CoreDNS:</h1>\n<p>CoreDNS는 쿠버네티스 클러스터 내에서 DNS 서비스를 제공하는 데 중요한 역할을 합니다. Kubernetes v1.13 이후 기본 DNS 제공자로 사용되어 온 CoreDNS는 DNS 이름 대신 IP 주소 대신 DNS 이름을 사용하여 클라이언트가 서비스에 액세스할 수 있도록 함으로써 클러스터 네트워킹을 간소화합니다. 그는 도메인 이름 요청을 해결하고 클러스터 내에서 서비스 검색을 용이하게 합니다.</p>\n<p></p>\n<h1>코어디엔에스의 작동 방식:</h1>\n<p>코어디엔에스는 쿠버네티스 클러스터 내에서 DNS 요청의 리졸버 및 포워더로 작동합니다. 파드가 다른 서비스와 통신해야 할 때, 대상 서비스의 도메인 이름을 지정하여 DNS 쿼리를 코어디엔에스에 보냅니다. 그럼 코어디엔에스는 내부 레코드를 사용하여 도메인 이름을 해당 IP 주소로 매핑하여 이 쿼리를 해결합니다.</p>\n<p>코어디엔에스가 권한이 없는 외부 도메인 이름에 대해서는, 이를 공개 리졸버나 상위 DNS 서버로 전달하여 해결합니다.</p>\n<p>성능을 향상시키고 대기 시간을 줄이기 위해 코어디엔에스는 자주 액세스하는 도메인 이름에 대한 DNS 응답을 캐시할 수 있습니다. 이 캐싱 메커니즘은 DNS 쿼리의 응답 속도를 향상시키고 상위 DNS 서버의 부하를 줄입니다.</p>\n<p></p>\n<p>CoreDNS는 이 기능을 모듈식 아키텍처와 확장 가능한 플러그인 시스템을 통해 구현하며, 운영자가 독자적인 요구 사항에 따라 DNS 해상도를 사용자 정의하고 최적화할 수 있게 합니다.</p>\n<h1>Amazon EKS에서의 CoreDNS 쓰로틀링 완화 방법:</h1>\n<p>Amazon EKS 클러스터에서 CoreDNS와 DNS 쓰로틀링 문제는 식별하고 해결하기 어려울 수 있습니다. 많은 사용자가 CoreDNS 로그와 메트릭을 모니터링하는 데 주력하지만, 엘라스틱 네트워크 인터페이스(ENI) 수준에서 강제되는 초당 1024개 패킷(PPS)의 하드 제한을 자주 간과합니다. 이 한계가 쓰로틀링 문제로 이어질 수 있는 방식을 이해하려면 Kubernetes 파드의 전형적인 DNS 해상도 흐름에 대한 통찰력이 필요합니다.</p>\n<p>Kubernetes 환경에서는 파드가 통신을 가능하게 하기 위해 내부 및 외부 서비스의 도메인 이름을 해상해야 합니다. 이 해상도 프로세스는 DNS 쿼리를 워커 노드의 ENI를 통해 라우팅하는 것을 포함하며, 특히 외부 엔드포인트를 해상하는 경우입니다. 내부 엔드포인트의 경우에도 쿼리하는 파드와 동일한 위치에 CoreDNS 파드가 없으면 DNS 패킷이 여전히 워커 노드의 ENI를 통해 이동합니다.</p>\n<p></p>\n<p>갑자기 DNS 쿼리가 급증하여 PPS가 하드 제한값 1024에 접근하는 상황이 발생할 수 있습니다. 이러한 상황은 DNS 쓰로틀링을 유발할 수 있으며, 이로 인해 영향을 받는 작업 노드에서 실행 중인 모든 마이크로서비스에 영향을 미칠 수 있습니다. 유감스럽게도, 이러한 문제 해결은 주로 CoreDNS pod에 초점을 맞추는 ENI 메트릭보다 어려울 수 있습니다.</p>\n<p>EKS 클러스터에서 DNS 쓰로틀링 문제를 완화하기 위해서는 ENI 수준에서 발생하는 패킷 손실을 지속적으로 모니터링하는 것이 중요합니다. 이 모니터링을 통해 잠재적인 중단을 조기에 감지하고 예방할 수 있습니다. 이 블로그 포스트에서는 네트워크 성능 메트릭을 활용하여 DNS 쓰로틀링 문제를 효과적으로 식별하는 솔루션을 소개합니다.</p>\n<h2>해결책: 🎉</h2>\n<p>작업 노드에서 DNS 쓰로틀링 문제를 식별하는 간단한 방법은 Elastic Network Adapter (ENA) 드라이버에서 제공하는 linklocal_allowance_exceeded 메트릭 및 다른 메트릭을 캡처하는 것입니다.</p>\n<p></p>\n<p><code>linklocal_allowance_exceeded</code>은 로컬 프록시 서비스로의 트래픽 PPS가 네트워크 인터페이스의 최대를 초과하여 드롭된 패킷 수입니다. 이는 DNS 서비스, 인스턴스 메타데이터 서비스 및 Amazon 시간 동기화 서비스로의 트래픽에 영향을 줍니다.</p>\n<p>이 이벤트를 실시간으로 추적하는 대신, 우리는 이 메트릭을 Amazon Managed Service for Prometheus로 스트리밍하고 Amazon Managed Grafana에서 시각화할 수도 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_1.png\" alt=\"이미지\"></p>\n<h1>실전: AWS EKS에서 CoreDNS 메트릭 수집 및 시각화:</h1>\n<p></p>\n<p>CoreDNS 프로메테우스 플러그인은 OpenMetrics 형식으로 메트릭을 노출하며, 이는 프로메테우스 형식에서 발전한 텍스트 기반 표준입니다. Kubernetes 클러스터에서는 플러그인이 기본적으로 활성화되어 있어 클러스터를 시작하는 즉시 많은 중요한 메트릭을 모니터링할 수 있습니다.</p>\n<p>기본 설정에서 프로메테우스 플러그인은 각 CoreDNS 팟의 포트 9153에 있는 /metrics 엔드포인트에 메트릭을 기록합니다.</p>\n<p>Amazon Managed Service for Prometheus 워크스페이스와 Managed Service for Grafana를 생성하세요:</p>\n<p>이 단계에서는 Amazon Managed Service for Prometheus 및 Managed Service for Grafana를 위한 워크스페이스를 생성합니다.</p>\n<p></p>\n<p>이 파일 구성은 다음을 생성합니다:</p>\n<ul>\n<li>AMP 작업 공간</li>\n<li>AMP 경보 관리자 정의.</li>\n</ul>\n<p>main.tf:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-variable language_\">module</span> <span class=\"hljs-string\">\"prometheus\"</span> {\n  source = <span class=\"hljs-string\">\"terraform-aws-modules/managed-service-prometheus/aws\"</span>\n\n  workspace_alias = <span class=\"hljs-string\">\"demo-coredns\"</span>\n\n  alert_manager_definition = &#x3C;&#x3C;-<span class=\"hljs-variable constant_\">EOT</span>\n  <span class=\"hljs-attr\">alertmanager_config</span>: |\n    <span class=\"hljs-attr\">route</span>:\n      <span class=\"hljs-attr\">receiver</span>: <span class=\"hljs-string\">'default'</span>\n    <span class=\"hljs-attr\">receivers</span>:\n      - <span class=\"hljs-attr\">name</span>: <span class=\"hljs-string\">'default'</span>\n  <span class=\"hljs-variable constant_\">EOT</span>\n\n  rule_group_namespaces = {}\n}\n</code></pre>\n<p></p>\n<p>versions.tf:</p>\n<pre><code class=\"hljs language-js\">terraform {\n  required_version = <span class=\"hljs-string\">\">= 1.3\"</span>\n\n  required_providers {\n    aws = {\n      source  = <span class=\"hljs-string\">\"hashicorp/aws\"</span>\n      version = <span class=\"hljs-string\">\">= 5.32\"</span>\n    }\n  }\n}\n</code></pre>\n<p>테라폼을 실행하려면 다음을 실행해야 합니다:</p>\n<pre><code class=\"hljs language-js\">$ terraform init\n$ terraform plan\n$ terraform apply\n</code></pre>\n<p></p>\n<p>아래 구성 파일은 다음과 같은 것을 생성합니다:</p>\n<ul>\n<li>기본 Grafana 작업 공간 (모듈에서 제공하는 기본값 사용)</li>\n</ul>\n<p>main.tf:</p>\n<pre><code class=\"hljs language-js\">provider <span class=\"hljs-string\">\"aws\"</span> {\n  region = local.<span class=\"hljs-property\">region</span>\n}\n\ndata <span class=\"hljs-string\">\"aws_availability_zones\"</span> <span class=\"hljs-string\">\"available\"</span> {}\n\nlocals {\n  region      = <span class=\"hljs-string\">\"eu-west-1\"</span>\n  name        = <span class=\"hljs-string\">\"amg-ex-${replace(basename(path.cwd), \"</span>_<span class=\"hljs-string\">\", \"</span>-<span class=\"hljs-string\">\")}\"</span>\n  description = <span class=\"hljs-string\">\"AWS Managed Grafana service for ${local.name}\"</span>\n\n  vpc_cidr = <span class=\"hljs-string\">\"10.0.0.0/16\"</span>\n  azs      = <span class=\"hljs-title function_\">slice</span>(data.<span class=\"hljs-property\">aws_availability_zones</span>.<span class=\"hljs-property\">available</span>.<span class=\"hljs-property\">names</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">3</span>)\n}\n\n################################################################################\n# <span class=\"hljs-title class_\">Managed</span> <span class=\"hljs-title class_\">Grafana</span> <span class=\"hljs-title class_\">Module</span>\n################################################################################\n\n<span class=\"hljs-variable language_\">module</span> <span class=\"hljs-string\">\"managed_grafana\"</span> {\n  source = <span class=\"hljs-string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n  # <span class=\"hljs-title class_\">Workspace</span>\n  name                      = local.<span class=\"hljs-property\">name</span>\n  associate_license         = <span class=\"hljs-literal\">false</span>\n  description               = local.<span class=\"hljs-property\">description</span>\n  account_access_type       = <span class=\"hljs-string\">\"CURRENT_ACCOUNT\"</span>\n  authentication_providers  = [<span class=\"hljs-string\">\"AWS_SSO\"</span>]\n  permission_type           = <span class=\"hljs-string\">\"SERVICE_MANAGED\"</span>\n  data_sources              = [<span class=\"hljs-string\">\"CLOUDWATCH\"</span>, <span class=\"hljs-string\">\"PROMETHEUS\"</span>, <span class=\"hljs-string\">\"XRAY\"</span>]\n  notification_destinations = [<span class=\"hljs-string\">\"SNS\"</span>]\n  stack_set_name            = local.<span class=\"hljs-property\">name</span>\n  grafana_version           = <span class=\"hljs-string\">\"9.4\"</span>\n\n  configuration = <span class=\"hljs-title function_\">jsonencode</span>({\n    unifiedAlerting = {\n      enabled = <span class=\"hljs-literal\">true</span>\n    },\n    plugins = {\n      pluginAdminEnabled = <span class=\"hljs-literal\">false</span>\n    }\n  })\n\n  # vpc configuration\n  vpc_configuration = {\n    subnet_ids = <span class=\"hljs-variable language_\">module</span>.<span class=\"hljs-property\">vpc</span>.<span class=\"hljs-property\">private_subnets</span>\n  }\n  security_group_rules = {\n    egress_postgresql = {\n      description = <span class=\"hljs-string\">\"Allow egress to PostgreSQL\"</span>\n      from_port   = <span class=\"hljs-number\">5432</span>\n      to_port     = <span class=\"hljs-number\">5432</span>\n      protocol    = <span class=\"hljs-string\">\"tcp\"</span>\n      cidr_blocks = <span class=\"hljs-variable language_\">module</span>.<span class=\"hljs-property\">vpc</span>.<span class=\"hljs-property\">private_subnets_cidr_blocks</span>\n    }\n  }\n\n  # <span class=\"hljs-title class_\">Workspace</span> <span class=\"hljs-variable constant_\">API</span> keys\n  workspace_api_keys = {\n    viewer = {\n      key_name        = <span class=\"hljs-string\">\"viewer\"</span>\n      key_role        = <span class=\"hljs-string\">\"VIEWER\"</span>\n      seconds_to_live = <span class=\"hljs-number\">3600</span>\n    }\n    editor = {\n      key_name        = <span class=\"hljs-string\">\"editor\"</span>\n      key_role        = <span class=\"hljs-string\">\"EDITOR\"</span>\n      seconds_to_live = <span class=\"hljs-number\">3600</span>\n    }\n    admin = {\n      key_name        = <span class=\"hljs-string\">\"admin\"</span>\n      key_role        = <span class=\"hljs-string\">\"ADMIN\"</span>\n      seconds_to_live = <span class=\"hljs-number\">3600</span>\n    }\n  }\n\n  # <span class=\"hljs-title class_\">Workspace</span> <span class=\"hljs-variable constant_\">IAM</span> role\n  create_iam_role                = <span class=\"hljs-literal\">true</span>\n  iam_role_name                  = local.<span class=\"hljs-property\">name</span>\n  use_iam_role_name_prefix       = <span class=\"hljs-literal\">true</span>\n  iam_role_description           = local.<span class=\"hljs-property\">description</span>\n  iam_role_path                  = <span class=\"hljs-string\">\"/grafana/\"</span>\n  iam_role_force_detach_policies = <span class=\"hljs-literal\">true</span>\n  iam_role_max_session_duration  = <span class=\"hljs-number\">7200</span>\n  iam_role_tags                  = { role = <span class=\"hljs-literal\">true</span> }\n\n\n  tags = local.<span class=\"hljs-property\">tags</span>\n}\n\n<span class=\"hljs-variable language_\">module</span> <span class=\"hljs-string\">\"managed_grafana_default\"</span> {\n  source = <span class=\"hljs-string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n  name              = <span class=\"hljs-string\">\"${local.name}-default\"</span>\n  associate_license = <span class=\"hljs-literal\">false</span>\n\n  tags = local.<span class=\"hljs-property\">tags</span>\n}\n\n<span class=\"hljs-variable language_\">module</span> <span class=\"hljs-string\">\"managed_grafana_disabled\"</span> {\n  source = <span class=\"hljs-string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n  name   = local.<span class=\"hljs-property\">name</span>\n  create = <span class=\"hljs-literal\">false</span>\n}\n\n################################################################################\n# <span class=\"hljs-title class_\">Supporting</span> <span class=\"hljs-title class_\">Resources</span>\n################################################################################\n\n<span class=\"hljs-variable language_\">module</span> <span class=\"hljs-string\">\"vpc\"</span> {\n  source  = <span class=\"hljs-string\">\"terraform-aws-modules/vpc/aws\"</span>\n  version = <span class=\"hljs-string\">\"~> 5.0\"</span>\n\n  name = local.<span class=\"hljs-property\">name</span>\n  cidr = local.<span class=\"hljs-property\">vpc_cidr</span>\n\n  azs             = local.<span class=\"hljs-property\">azs</span>\n  private_subnets = [<span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> local.<span class=\"hljs-property\">azs</span> : <span class=\"hljs-title function_\">cidrsubnet</span>(local.<span class=\"hljs-property\">vpc_cidr</span>, <span class=\"hljs-number\">4</span>, k)]\n  public_subnets  = [<span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> local.<span class=\"hljs-property\">azs</span> : <span class=\"hljs-title function_\">cidrsubnet</span>(local.<span class=\"hljs-property\">vpc_cidr</span>, <span class=\"hljs-number\">8</span>, k + <span class=\"hljs-number\">48</span>)]\n\n  enable_nat_gateway = <span class=\"hljs-literal\">false</span>\n  single_nat_gateway = <span class=\"hljs-literal\">true</span>\n\n  tags = local.<span class=\"hljs-property\">tags</span>\n}\n</code></pre>\n<p></p>\n<p>\"versions.tf\" 파일입니다:</p>\n<pre><code class=\"hljs language-js\">terraform {\n  required_version = <span class=\"hljs-string\">\">= 1.0\"</span>\n\n  required_providers {\n    aws = {\n      source  = <span class=\"hljs-string\">\"hashicorp/aws\"</span>\n      version = <span class=\"hljs-string\">\">= 5.0\"</span>\n    }\n  }\n}\n</code></pre>\n<p>이 코드를 실행하려면 다음을 실행해야 합니다:</p>\n<pre><code class=\"hljs language-js\">$ terraform init\n$ terraform plan\n$ terraform apply\n</code></pre>\n<p></p>\n<p>프로메테우스 ethtool 익스포터 배치:</p>\n<p>ethtool은 워커 노드의 이더넷 장치에 대한 정보를 구성하고 수집하는 리눅스 도구입니다. 우리는 ethtool의 출력을 사용하여 패킷 손실을 감지하고 이를 프로메테우스 ethtool 익스포터 유틸리티를 사용하여 프로메테우스 형식으로 변환할 것입니다.</p>\n<p>배포에는 ethtool에서 정보를 가져 와서 프로메테우스 형식으로 게시하는 Python 스크립트가 포함되어 있습니다.</p>\n<pre><code class=\"hljs language-js\">kubectl apply -f <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//raw.githubusercontent.com/Showmax/prometheus-ethtool-exporter/master/deploy/k8s-daemonset.yaml</span>\n</code></pre>\n<p></p>\n<p>이제 ADOT 수집기를 배포하고 ADOT 수집기를 구성하여 Amazon Managed Service for Prometheus로 메트릭을 수집할 것입니다.</p>\n<p>우리는 Amazon EKS 애드온을 사용하여 ADOT 오퍼레이터를 CoreDNS 모니터링을 위해 메트릭 \"linklocal_allowance_exceeded\"를 Amazon Managed Service for Prometheus로 보내게 될 것입니다.</p>\n<p>IAM 역할과 Amazon EKS 서비스 계정을 생성하세요.</p>\n<p></p>\n<p>ADOT 수집기를 Kubernetes 서비스 계정 \"adot-collector\"의 신원으로 배포할 예정입니다. 서비스 계정에 IAM 역할(IRSA)을 연결하여 Kubernetes 서비스 계정에 AmazonPrometheusRemoteWriteAccess 역할을 할당함으로써 해당 서비스 계정을 활용하는 모든 파드가 Amazon Managed Service for Prometheus에 메트릭을 수집하는 데 필요한 IAM 권한을 부여할 수 있습니다.</p>\n<p>스크립트를 실행하려면 kubectl 및 eksctl CLI 도구가 필요합니다. 이 도구들은 Amazon EKS 클러스터에 액세스할 수 있도록 구성되어 있어야 합니다.</p>\n<pre><code class=\"hljs language-js\">eksctl create iamserviceaccount \\\n--name adot-collector \\\n--namespace <span class=\"hljs-keyword\">default</span> \\\n--region eu-west-<span class=\"hljs-number\">1</span>\\\n--cluster coredns-monitoring-demo\\\n--attach-policy-arn <span class=\"hljs-attr\">arn</span>:<span class=\"hljs-attr\">aws</span>:<span class=\"hljs-attr\">iam</span>::<span class=\"hljs-attr\">aws</span>:policy/<span class=\"hljs-title class_\">AmazonPrometheusRemoteWriteAccess</span> \\\n--approve \\\n--override-existing-serviceaccounts\n</code></pre>\n<p>ADOT 애드온 설치하기:</p>\n<p></p>\n<p>여러분은 다음 명령어를 사용하여 Amazon EKS의 다른 버전에 활성화된 애드온 목록을 확인할 수 있습니다:</p>\n<p>클러스터 버전에서 지원하는 ADOT 버전을 확인하십시오.</p>\n<pre><code class=\"hljs language-js\">aws eks describe-addon-versions --addon-name adot --kubernetes-version <span class=\"hljs-number\">1.28</span> \\\n  --query <span class=\"hljs-string\">\"addons[].addonVersions[].[addonVersion, compatibilities[].defaultVersion]\"</span> --output text\n</code></pre>\n<p>다음 명령어를 실행하여 ADOT 애드온을 설치하십시오. 위 단계에서 기술된 것에 따라 --addon-version 플래그를 교체하십시오.</p>\n<p></p>\n<pre><code class=\"hljs language-js\">aws eks create-addon --addon-name adot --addon-version v0<span class=\"hljs-number\">.66</span><span class=\"hljs-number\">.0</span>-eksbuild<span class=\"hljs-number\">.1</span> --cluster-name coredns-monitoring-demo\n</code></pre>\n<p>다음 명령어를 사용하여 ADOT 애드온이 준비되었는지 확인하세요.</p>\n<pre><code class=\"hljs language-js\">kubectl get po -n opentelemetry-operator-system\n</code></pre>\n<p>다음 절차는 배포를 모드 값으로 사용하는 예제 YAML 파일을 사용합니다. 이는 기본 모드이며 ADOT Collector를 독립 애플리케이션과 유사하게 배포합니다. 이 구성은 샘플 애플리케이션으로부터 OTLP 메트릭을 수신하고 클러스터의 pod에서 스크래핑된 Amazon Managed Service for Prometheus 메트릭을 수신합니다.</p>\n<p></p>\n<p>curl -o collector-config-amp.yaml <a href=\"https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml\" rel=\"nofollow\" target=\"_blank\">https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml</a></p>\n<p>collector-config-amp.yaml 파일에서 다음을 본인의 값으로 바꿔주세요: _ mode: deployment _ serviceAccount: adot-collector _ endpoint: \"\" _ region: \"\" * name: adot-collector</p>\n<p>kubectl apply -f collector-config-amp.yaml</p>\n<p>adot collector가 배포되면 메트릭이 Amazon Prometheus에 성공적으로 저장됩니다.</p>\n<p></p>\n<p>Amazon Managed Grafana에서 ethtool 메트릭을 시각화해보세요:</p>\n<p>Amazon Managed Grafana 콘솔 내에서 Prometheus 워크스페이스를 데이터 소스로 구성합니다.</p>\n<p>이제 Amazon Managed Grafana에서 메트릭을 살펴봅시다: \"탐색\" 버튼을 클릭한 후 ethtool을 검색하세요:</p>\n<p><img src=\"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_2.png\" alt=\"이미지\"></p>\n<p></p>\n<p>링크로컬 할당 초과 메트릭을 사용하여 대시보드를 만들어 봅시다. 쿼리는 다음과 같습니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-title function_\">rate</span>(node_net_ethtool{device=<span class=\"hljs-string\">\"eth0\"</span>,type=<span class=\"hljs-string\">\"linklocal_allowance_exceeded\"</span>} [30s])\n</code></pre>\n<p><img src=\"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_3.png\" alt=\"이미지\"></p>\n<p>값이 0이기 때문에 드랍된 패킷이 없다는 것을 확인할 수 있습니다. Amazon Managed Service for Prometheus의 경고 관리자에서 알림을 구성하여 알림을 보낼 수 있습니다.</p>\n<p></p>\n<h1>결론:</h1>\n<p>이 글에서는 AWS Distro for OpenTelemetry (ADOT), Amazon Managed Service for Prometheus 및 Amazon Managed Grafana를 사용하여 CoreDNS 쓰로틀링 문제를 모니터링하고 경고를 생성하는 방법을 보여드렸습니다. CoreDNS 메트릭을 모니터링함으로써 고객은 패킷 손실을 사전에 감지하고 예방 조치를 취할 수 있습니다.</p>\n<p>다음에 또 만나요 🇵🇸 🎉</p>\n<p><img src=\"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_4.png\" alt=\"이미지\"></p>\n<p></p>\n<p>읽어 주셔서 감사합니다!! 🙌🏻😁📃, 다음 블로그에서 만나요.🤘🇵🇸</p>\n<p>🚀 끝까지 함께해 줘서 감사합니다. 이 블로그에 관한 질문/피드백이 있으면 언제든지 연락해 주세요:</p>\n<p>♻️ 🇵🇸LinkedIn: <a href=\"https://www.linkedin.com/in/rajhi-saif/\" rel=\"nofollow\" target=\"_blank\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p>♻️🇵🇸 Twitter : <a href=\"https://twitter.com/rajhisaifeddine\" rel=\"nofollow\" target=\"_blank\">https://twitter.com/rajhisaifeddine</a></p>\n<p></p>\n<p>끝! ✌🏻</p>\n<h1>🔰 계속 배우고!! 계속 공유해요!! 🔰</h1>\n<h1>참고:</h1>\n<p><a href=\"https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/\" rel=\"nofollow\" target=\"_blank\">https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/</a></p>\n</body>\n</html>\n"},"__N_SSG":true}