{"pageProps":{"posts":[{"title":"당신의 Git 히스토리 정리하기","description":"","date":"2024-05-17 20:17","slug":"2024-05-17-SanitisingYourGitHistory","content":"\n2005년에 창설된 이후 Git은 버전 관리 시스템(VCS)의 왕으로 부상했습니다. 빠르고 간단하며 분산 속성을 갖춘 Git은 두 대 혁신적인 클라우드 VCS 제공업체인 GitHub와 GitLab의 채택과 함께 다른 VCS를 대체했습니다.\n\n하지만 좋은 도구도 사용자가 어떻게 관리하는지에 달려 있습니다. 특히 적절한 검토와 강제 사항이 없이 여러 사용자들이 Git 저장소에 기여할 때, 대용량 파일이 많아지며 지나치게 복잡해지는 저장소가 만들어질 수 있습니다. 이는 다른 사용자들이 저장소를 복제하거나 CI 파이프라인을 실행할 때 더 큰 지연을 야기할 수 있습니다.\n\n더 나쁜 상황으로는, 암호와 같은 민감한 파일이 실수로 커밋되어 역사 속에 깊숙이 들어가 있고, 새로운 커밋을 통해 간단히 삭제할 수 없을 수도 있습니다.\n\nGit을 처음 사용하는 경우, 계속하기 전에 여기에서 Git 소개를 읽어보세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-17-SanitisingYourGitHistory_0.png\" />\n\n# Git 히스토리 이해하기\n\nGit(또는 다른 VCS)의 아름다움은 버전 내역에 있습니다. 그것이 Git에서 썩은 부분을 정리해야 할 때 발생하는 어려움 역시 그런 아름다움에 속합니다. Git에 실수로 커밋한 큰 파일을 예로 들어보죠.\n\n<img src=\"/assets/img/2024-05-17-SanitisingYourGitHistory_1.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 이 큰 파일은 feature 브랜치 1에서 처음 소개되었고 사용자 1에 의해 마스터 브랜치로 병합되었습니다.\n- 마스터 브랜치는 사용자 2에 의해 feature 브랜치 2로 쪼개졌습니다.\n- 사용자 1은 나중에 실수를 발견하여 큰 파일을 삭제하고 다시 마스터 브랜치로 병합했습니다.\n- 그러나 무심코 남아 있는 사용자 2의 feature 브랜치 2에 여전히 큰 파일이 있고, 사용자 2는 자신의 기능을 해결한 후에도 큰 파일을 마스터 브랜치로 다시 병합합니다.\n\n실수로 커밋할 때나 마스터 브랜치와 같은 공통 브랜치로 병합할 때 복잡성을 볼 수 있습니다. 사용자 2가 feature 2를 커밋하지 않아도 사용자 1이 삭제하고 새 커밋으로 병합한 후에도 큰 파일은 여전히 히스토리에 유지됩니다.\n\n따라서 해당 큰 파일을 제거하려면 원격 저장소의 모든 브랜치의 Git 히스토리를 완전히 지워야 합니다. 또한 제거한 후 로컬 복사본이 있는 다른 개발자들에게 알려주어서 그 파일을 삭제하고 제거 후 다시 저장소를 클론하도록 해야 합니다.\n\n# Git 히스토리 프로파일링\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저장소의 Git 기록은 숨겨진 폴더 .git에 저장됩니다. 로컬로 저장소의 사본을 복제하고 다음 명령을 실행하여 그 크기를 빠르게 확인할 수 있습니다. 이 Git 기록이 약 416Mb임을 알 수 있습니다.\n\n```js\ncd .git\ndu -d 1 -h\n\n416M ./objects\n4.0K ./info\n 12K ./logs\n 60K ./hooks\n8.0K ./refs\n416M .\n```\n\nGit을 프로파일링하는 훌륭한 도구는 git-sizer라는 도구를 사용하는 것입니다. MacOS에서는 brew를 사용하여 설치할 수 있습니다. 다른 운영 체제를 사용하는 경우, GitHub 릴리스 페이지에서 설치 파일을 다운로드할 수 있습니다. (아래 링크를 참조해주세요).\n\n```js\nbrew install git-sizer\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저장소로 이동해서 다음 명령어를 실행해주세요.\n\n```js\ncd your/git/repository\ngit-sizer --verbose\n```\n\n이 명령어를 실행하면 Git 기록의 명확한 프로필을 확인할 수 있어요. 저장소의 크기 및 최적화해야 할 관심 수준을 확인할 수 있습니다. 이 경우에는 기록 중 대부분의 저장소가 블롭으로 저장되어 있는 것을 확인할 수 있어요. 블롭은 Git-LFS (Large File Storage)나 다른 저장 영역(예: AWS S3)에 저장해야 합니다.\n\n```js\n블롭 처리 중: 1368개\n트리 처리 중: 1957개\n커밋 처리 중: 518개\n트리에 해당하는 커밋: 518개\n주석이 달린 태그 처리 중: 1개\n참조 처리 중: 24개\n| 이름                         | 값        | 관심 수준                         |\n| ---------------------------- | --------- | ------------------------------ |\n| 전체 저장소 크기             |           |                                |\n| * 커밋                      |           |                                |\n|   * 총 개수                  |   518     |                                |\n|   * 총 크기                 |   158 KiB |                                |\n| * 트리                      |           |                                |\n|   * 총 개수                  |  1.96 k   |                                |\n|   * 총 크기                 |   686 KiB |                                |\n|   * 총 트리 항목 수         |  17.7 k   |                                |\n| * 블롭                      |           |                                |\n|   * 총 개수                  |  1.37 k   |                                |\n|   * 총 크기                 |   453 MiB |                                |\n| * 주석이 달린 태그           |           |                                |\n|   * 개수                    |     1     |                                |\n| * 참조                      |           |                                |\n|   * 개수                    |    24     |                                |\n|     * 브랜치                |     1     |                                |\n|     * 태그                  |    15     |                                |\n|     * 원격 추적 참조         |     8     |                                |\n|                              |           |                                |\n| 가장 큰 객체들               |           |                                |\n| * 커밋                      |           |                                |\n|   * 최대 크기             [1] |   771 B   |                                |\n|   * 최대 부모 수          [2] |     2     |                                |\n| * 트리                      |           |                                |\n|   * 최대 엔트리 수        [3] |    23     |                                |\n| * 블롭                      |           |                                |\n|   * 최대 크기             [4] |   430 MiB | !!!!!!!!!!!!!!!!!!!!!!!!!!!!!! |\n|                              |           |                                |\n| 기록 구조                    |           |                                |\n| * 최대 기록 깊이            |   346     |                                |\n| * 최대 태그 깊이        [5] |     1     |                                |\n|                              |           |                                |\n| 가장 큰 체크아웃들           |           |                                |\n| * 디렉터리 수          [6] |   108     |                                |\n| * 최대 경로 깊이       [7] |     9     |                                |\n| * 최대 경로 길이       [7] |   134 B   | *                              |\n| * 파일 수              [3] |   283     |                                |\n| * 파일 총 크기        [8] |   442 MiB |                                |\n| * 심볼릭 링크 수       [9] |     1     |                                |\n| * 서브모듈 수         [10] |     2     |                                |\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Git 히스토리 삭제하기\n\n프로파일링 후 지우고 싶은 내용에 대한 명확한 아이디어가 생겼으니, Git 히스토리에서 해당 내용을 삭제해 보겠습니다. 이를 위해 git-filter-repo라는 Python 도구를 설치해야 합니다 (아래 링크를 참조하세요). 나중에 필요할 때를 대비해 참조용 원격 origin을 목록에 표시해 두세요.\n\n```js\n# 설치\npip install git-filter-repo\n\n# 원격 origin 목록 표시\ngit remote -v\n>> origin git@gitlab.com:jake/test.git (fetch)\n>> origin git@gitlab.com:jake/test.git (push)\n```\n\n여기에 파일이나 텍스트를 삭제하는 몇 가지 일반적인 예시 명령어를 포함했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 특정한 절대 파일 이름을 가진 파일을 삭제하는 방법\n- (\\*)를 사용하여 특정 유형의 모든 파일을 삭제하는 방법\n- 실수로 패스워드를 커밋한 경우와 같이 파일이나 스크립트에서 특정 텍스트를 대체하는 방법.\n\n```js\n# 파일 삭제\ngit filter-repo --invert-paths --path 'myfilename.jpg' --force\n\n# 글로브(*)를 사용하여 모든 파일 삭제\ngit filter-repo --invert-paths --path-glob '*.jpg' --force\ngit filter-repo --invert-paths --path-glob '*.jpg' --path-glob '*.png' --force\n\n# \"mypassword\"를 \"REPLACED\"로 대체하는 방법\ngit filter-repo --replace-text <(echo \"mypassword==>REPLACED\") --force\n```\n\n이전에 삭제한 것이 더 이상 남아 있지 않은지 확인하여 버전이나 브랜치를 검사하여 정상 작동하는지 확인할 수 있습니다.\n\n완료되면 정리된 복사본을 원격 저장소에 푸시할 수 있습니다. 이 도구는 안전상의 이유로 git 원격 URL을 자동으로 제거합니다. 따라서 다시 추가해야 합니다. 그런 다음 기존 브랜치를 원격에 강제로 푸시할 수 있습니다. 다른 브랜치가 있는 경우 체크아웃하여 그것들도 푸시해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# git filter-repo를 실행한 후 원격 저장소를 다시 추가하세요\ngit remote add origin git@gitlab.com:jake/test.git\n\n# 원격 저장소로 푸시하세요\ngit push --set-upstream origin main --force\n\n# 다른 브랜치가 있으면 변경사항을 푸시하세요\ngit checkout <branch>\ngit push --set-upstream origin <branch> --force\n```\n\n# 주의사항\n\n각 Git 버전은 Git 해시라는 고유한 ID를 가지고 있습니다. git-filter-repo나 기타 도구를 사용하여 Git 히스토리의 커밋을 변경하면 해시가 변경됩니다.\n\nGit 해시는 병합/풀 요청, Git 태그 또는 릴리스와 같은 VCS 플랫폼에서 참조로 사용됩니다. 이들은 작동하지 않고 특히 Git 히스토리에서 깊숙이 포함된 것을 제거하고 싶은 경우 문제가 될 수 있습니다. 중요하다면 저장소의 복사본을 만드는 것이 좋습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 요약\n\ngit-sizer와 git-filter-repo는 Git 히스토리를 프로파일링하고 정리하는 데 사용되는 인기 있는 신뢰할 수 있는 오픈 소스 도구입니다. 이러한 도구를 사용하면 필요에 따라 간편하게 리포지토리의 상태를 확인하고 정리하여 유지할 수 있습니다.\n\n# 참고\n","ogImage":{"url":"/assets/img/2024-05-17-SanitisingYourGitHistory_0.png"},"coverImage":"/assets/img/2024-05-17-SanitisingYourGitHistory_0.png","tag":["Tech"],"readingTime":10},{"title":"해커의 마음 - Recon 마인드 맵","description":"","date":"2024-05-17 20:16","slug":"2024-05-17-TheHackersMind-ReconMindmap","content":"\nBy Tahir Mujawar, 인증된 윤리적 해커 및 사이버 보안 연구원\n\n![이미지](/assets/img/2024-05-17-TheHackersMind-ReconMindmap_0.png)\n\n안녕하세요 👋 사이버 모험가 여러분! 여기 타히르 무자와르입니다. 사이버 보안의 복잡성을 탐험하는 전략적 안내서인 Recon Mind map을 소개합니다. 정교하게 제작된 이 지도는 각 하위 도메인, 기술 식별 및 콘텐츠 발견을 통해 우리를 안내하는 설계도입니다. 함께 사이버 공간의 비밀을 발견하고 Recon Mind map과 함께 더 안전한 디지털 프론티어를 개척해 봅시다.\n\nRecon은 정보 수집뿐만 아니라 통찰력, 선견지달력 및 보이지 않는 위협에 대항하는 촉매의 역할을 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nRecon Mind Map을 만드는 목적은 학습을 체계적으로 진행하는 데 있습니다. 온라인으로 다양한 자료가 풍부하게 제공되지만, 나와 같은 열정적인 사람들은 종종 어디에 초점을 맞춰야 할지 판별하기 어렵다고 느낍니다. Recon Mind Map은 웹 애플리케이션 탐색에 필수적인 모든 주요 주제를 아우르며, 학습 여정에서 명확성과 방향성을 제공합니다.\n\nRecon Mind Map은 다음과 같은 요소들을 포함합니다:\n\n1. 토폴로지 맵핑\n\n- NetBrain\n- NetCrunch\n- SolarWinds\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 방화벽 식별\n\n- WafW00f\n- Nmap NSE\n\n3. 로드 밸런서\n\n- lbd\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. ASN\n\n- bgp.he.net\n- Hacker Target\n- Amass\n\n5. CIDR Range\n\n- Asn Lookup\n- Mapcidr\n- Amass Intel\n- ipaddressguide.com\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n6. IP 블록 / 서브넷\n\n- viewdns\n- MxTools\n- whois.arin.net\n- whoxy\n- who.is\n- lopseg\n- shodan.io\n\n7. IP 주소\n\n오픈 포트, 서비스, 버전\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Masscan\n- Naabu\n- Rustscan\n- Nmap\n- Sandmap\n- Scan Cannon\n\n8. Cloud\n\n- Home Lister Directory\n\n## \\* Horizontal / Acquisitions Enumeration\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- WhoisXMLAPI\n- CrunchBase\n- Wikipedia\n- ChatGpt\n\n## 수직열거\n\n수동 열거:\n\n- 수동 소스\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 지피노\n- 아매스\n- 서브파인더\n- 서브리스트\n- 에셋파인더\n- 원포올\n- 파인도메인\n- 크로벳\n- 노크파이\n- 깃허브-서브도메인\n\n2. 인증서 로그\n\n- crt.sh\n- tls.bufferover.run\n\n3. 재귀적 열거\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 수동 소스\n\n## \\* 활성화 목록\n\n- DNS 무차별 강제 공격\n\n- Puredns\n- Cewl\n- FFUF\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 순열\n\n- 고타토르\n\n3. JS / 소스 코드 스크랩핑\n\n- 링크파인더\n- 겟제이에스\n- 고스파이더\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. Google Analytics\n\n- Analytics Relationships\n\n5. TLS, CNAME 프로빙\n\n- Cero\n- httpx\n- dnsx\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n6. VHOST 프로빙\n\n- 가상 호스트 스캐너\n- 호스트 헌터\n\n7. 웹 프로빙\n\n- Unimap\n- httpx\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Whatweb\n- Wappalyzer\n- Netcraft\n- Builtwith\n- Fingerprintx\n- Retire.JS\n\n1. URLs\n\n- GAU\n- Linx\n- Waybackurl\n- hakrawler\n- Gospider\n- URLgrab\n\n2. Parameters\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Param-Miner\n- x8\n- Parameth\n- Arjun\n- Github-Endpoints\n\n### 3. JS Enumeration\n\n- Secret Finder\n- JS Recon\n- Link Finder\n- Wayback URLs\n- JS Scan\n\n### 4. Directory & File Enumeration\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- FFUF\n- Dirb\n- Gobuster\n- DirSearch\n- WFuzz\n\n5. Google FU\n\n- Trufflehog\n- GitDorker\n- githound\n- GitGrabber\n- GitLeakes\n- Repo-Supervisor\n\n- S3 Scanner\n- S3 Bucket Finder\n- GrayHatWarfare\n- Lazy S3\n- AWS Bucket Dump\n- CloudBrute\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Wpscan\n- CMSmap\n- Joomscan\n\n- OSINT Framework\n- theHarvester\n- Recon-ng\n- Maltego\n- MOSINT\n- SpiderFoot\n\n- EyeWitness\n- LazyShot\n- Aquatone\n- Web shot\n- Eyeballer\n\n위에 언급한 마인드 맵이 있어요. 더 잘 보기 위해서는 중간 앱을 사용하거나 컴퓨터/노트북에서 여세요. PNG 파일을 받으려면 LinkedIn에서 연락 주세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nC\nonnect me on LinkedIn\n\nResearching takes considerable time. If you found this helpful, a Like, share, or follow would be greatly appreciated. Your support fuels our cyber journey!\n\nHappy Hacking! Bye Bye Hackers 👋\n\n![TheHackersMind ReconMindmap](/assets/img/2024-05-17-TheHackersMind-ReconMindmap_1.png)\n","ogImage":{"url":"/assets/img/2024-05-17-TheHackersMind-ReconMindmap_0.png"},"coverImage":"/assets/img/2024-05-17-TheHackersMind-ReconMindmap_0.png","tag":["Tech"],"readingTime":8},{"title":"중간 과정 프롬프트를 Shorten으로 개선하세요","description":"","date":"2024-05-17 20:14","slug":"2024-05-17-ImproveYourMidjourneyPromptsWithshorten","content":"\n<img src=\"/assets/img/2024-05-17-ImproveYourMidjourneyPromptsWithshorten_0.png\" />\n\n미드절니(Midjourney)는 상세하고 현실적인 AI 생성 이미지로 유명합니다. 그러나 미드절니의 모델이 당신이 제시한 프롬프트를 정확히 생성하는 것은 도전일 수 있습니다.\n\n예를 들어, 이 기사의 제목 이미지의 경우 저는 리본을 가로지르는 낡은 가위를 요청했습니다. 그러나 받은 이미지는 모두 리본 근처를 떠도는 가위의 이미지입니다.\n\n/shorten 명령어는 프롬프트를 분석하는 유용한 도구입니다. 미드절니의 알고리즘이 프롬프트를 해석하는 방식을 파악하고, 원하는 이미지를 만들기에 더 적합한 더 짧은 프롬프트를 제안해줍니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사에서 Midjourney Discord 인터페이스에서 `/shorten` 명령어가 어떻게 작동하는지 알게 될 것입니다. 그런 다음 두 가지 예제를 통해 안내해 드리겠습니다:\n\n- 복잡한 장면을 /shorten 명령어로 분석하여 prompt를 개선하기\n- prompt의 길이를 80% 줄이기\n\n## /shorten 명령어 동작\n\nMidjourney 봇은 프롬프트를 단어 또는 짧은 구문으로 구성된 토큰으로 분할합니다. 그런 다음 이러한 토큰과 교육 데이터의 연관성을 기반으로 이미지를 작성합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n직감과는 반대로 간결하고 간결한 프롬프트가 긴 설명보다 더 나은 성능을 발휘할 수 있다고 합니다. Midjourney는 시적인 언어와 과도한 설명이 이미지에 예상치 못한 객체들이 나타나게 할 수 있다고 설명합니다.\n\n사용자들은 Discord 채팅 인터페이스에서 /imagine 키워드로 이미지 프롬프트를 제공하고 알고리즘은 4가지 가능한 이미지 그리드를 생성합니다. 이들은 더 세부적으로 다듬을 수 있으며, 섬세하고 창의적인 업스케일링 및 인페인팅을 통해 더 발전시킬 수 있습니다.\n\n/imagine 와 마찬가지로, /shorten 도 Discord의 Midjourney 봇 채널에서 호출할 수 있습니다. 이것은 내 제목 이미지 프롬프트를 분석한 결과입니다:\n\n![2024-05-17-ImproveYourMidjourneyPromptsWithshorten_1.png](/assets/img/2024-05-17-ImproveYourMidjourneyPromptsWithshorten_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사용자에게 추가 옵션이 두 가지 더 있어요:\n\n- 해당 버튼을 클릭하여 다섯 가지 중 한 가지 단축 이미지 프롬프트를 기반으로 이미지를 생성합니다.\n- 각 토큰에 할당된 중요도를 표시하려면 “세부 정보 보기”를 클릭합니다.\n\n후자의 경우 Midjourney 봇은 각 토큰에 할당한 가중치를 반환합니다. 더 높은 가중치를 가진 토큰은 더 중요하다고 간주됩니다.\n\n알고리즘은 이미지 구성 요소와 각각의 색상, 스타일에 중점을 둡니다. 구성은 덜 중요한 것으로 보이며 리본에 쓰인 단어의 설명도 마찬가지입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 가족 모습\n\n다음에는 /shorten 명령어를 사용하여 가족 모습을 만드는 데 도움을 받겠어요. 네 개의 이미지 그리드 중에서, 주어진 프롬프트와 가장 일치하는 이미지를 항상 선택했어요.\n\n저는 Midjourney에게 아늑한 가족 모습을 만들어 달라고 요청했어요. 그 가족 구성원들과 애완동물의 자세한 설명, 각자의 직업, 이미지에서의 위치를 포함하여 구체적으로 설명했고, 이미지 스타일은 사실적인 것으로 지정했어요.\n\n![가족 모습](/assets/img/2024-05-17-ImproveYourMidjourneyPromptsWithshorten_2.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n생성된 장면에는 요청한 모든 객체들이 포함되어 있지만, 구성이 예상대로 되지는 않았어요. 예를 들어, 부엌 카운터 위에 있는 태비 고양이 한 마리 대신 바닥에 두 마리가 있었어요. 바닥에는 장난감이 있지만, 아이들이 그것들과 놀고 있지는 않았어요. 하지만 정말 당황한 건 창문의 아랫부분이 빠져있던 거에요.\n\n/shorten을 사용하여 Midjourney 봇이 제 원래 프롬프트를 분석한 결과를 제공해 주었어요. 봇은 가장 중요한 단어들을 굵은 글꼴로 강조했어요.\n\n분석 결과 사람들과 애완동물이 중요하게 여겨졌어요. 그러나 프롬프트의 가장 관련된 부분은 설정이에요: 사실적이고, 환한, 아침, 가족, ... 흥미로운 점은 모피 색상 \"태비\"가 고양이 자체보다 훨씬 중요하게 여겨졌다는 것인데요 - 아마도 \"태비\" 객체를 요청했을 때 \"고양이\"가 자동으로 추론된다는 힌트일지도 모르겠어요?\n\n봇은 또한 프롬프트를 다섯 가지 요약된 버전으로 제안했어요. 그것들은 프롬프트의 인식에 따라 중요한 부분을 포착하고 적절하지 않은 세부사항은 제외한 것으로 보입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 패널에서는 \"사실적인, 화창한 아침 가족 장면, 부엌에서 스무디를 준비하는 여성, 두 아이, 장난감 자동차로 뒤덮인 바닥. 태비 고양이, 과일, 커튼\"에서 \"사실적인, 화창한, 가족, 스무디\"로 줄어든 프롬프트에 대한 이미지가 보입니다.\n\n제가 만들고 싶은 장면과 일치하는 줄어든 프롬프트는 찾지 못했습니다. 알고리즘을 구성에 더 집중하도록 하기 위해, 스타일보다는 구성에 더 집중하게끔 아래의 수정된 프롬프트를 만들기로 결정했습니다.\n\n더 이상 사진을 사실적으로 요구하지 않고, 태비 고양이와 다른 물건들이 바닥이 아니라 카운터 위에 놓이도록 요청합니다. 이것이 스타일보다 더 중요하다고 생각했기 때문입니다.\n\n![이미지](/assets/img/2024-05-17-ImproveYourMidjourneyPromptsWithshorten_3.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 시적인 언어 줄이기\n\n다음 예시에서, 저는 시적이고 화려한 이미지 프롬프트를 만들 수 있도록 ChatGPT의 도움을 받았습니다:\n\n미드저니 봇이 이를 줄였습니다.\n\n이것은 총 5개 중 3번째 프롬프트였지만, 그 이후로는 포도와 키위가 사라지기 시작했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 패널은 두 프롬프트를 나란히 비교한 것을 보여줍니다. 원본 38단어 중 8단어만 남은 단축된 프롬프트는 장면을 충실하게 재구성합니다.\n\n![이미지](/assets/img/2024-05-17-ImproveYourMidjourneyPromptsWithshorten_4.png)\n\n## 결론\n\n첫 번째 복잡한 프롬프트 예제에서, /shorten 명령어와 Midjourney 봇이 제공한 단축된 프롬프트는 내 문제를 직접 해결하지 못했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n`/shorten`와 상호 작용하면 알고리즘을 더 잘 이해할 수 있었어요. 각 토큰에 부여하는 가중치를 알면, 지나치게 강조된 단어를 제외하고 다른 곳에서 설명을 개선할 수 있었어요.\n\n예를 들어, 알고리즘이 \"사실적인\"과 \"스무디\"라는 단어에 이렇게 중요성을 부여할 것이라고는 상상하지 못했을 겁니다. 그 이미지를 만드는 과정에서 그 단어들이 장면을 잡아내는 데 꼭 필요하지 않은 것을 깨달았어요.\n\n보다 간단한 두 번째 장면에서는 /shorten을 사용하여 원래 프롬프트의 장황한 언어를 줄일 수 있었어요. 구성 요소는 훨씬 짧은 프롬프트로 보존되었어요.\n\n저는 /shorten 명령을 Midjourney 봇과의 소통 수단으로 생각해요. 어쨌든, 이것은 어떻게 특정 이미지를 생성하는지 설명해 주지 않아요. 각 토큰의 가중치를 알고 있으면, 사용자는 생성된 장면이 그들의 원래 아이디어와 일치할 때까지 프롬프트를 조정해 나갈 수 있어요.\n","ogImage":{"url":"/assets/img/2024-05-17-ImproveYourMidjourneyPromptsWithshorten_0.png"},"coverImage":"/assets/img/2024-05-17-ImproveYourMidjourneyPromptsWithshorten_0.png","tag":["Tech"],"readingTime":7},{"title":"중간 과정 스타일 참조 코드를 위한 상위 10개 컬렉션","description":"","date":"2024-05-17 20:12","slug":"2024-05-17-Top10collectionsforMidjourneystylereferencecodes","content":"\nMidjourney 스타일 참조 코드가 소개된 이후로 취미로 삼는 이들은 열정적으로 sref 랜덤 접미사 매개변수를 활용하여 다양한 스타일을 발견하고 활용하고 있어요.\n\n커뮤니티의 집합된 노력으로 무수히 많은 Midjourney 스타일이 시험되었고, 그 결과 다양한 품질의 스타일이 드러났어요. 저는 개인적으로 첫 1000개의 스타일 코드를 조사한 결과, 많은 스타일이 하위 수준이었고 이상하고 구식이며 흠집이 많은 그리고 저품질의 만화 스타일을 냈다는 것을 발견했어요. 그 수많은 스타일들은 압도적일 수 있으며, 보석을 찾기 위해서는 인내가 필요해요.\n\n일부 Midjourney 사용자들은 끊임없이 Discord에서 스크립트를 실행하여 스타일을 생성하고 시험하고 있어요. 이는 조금 집착적일 수도 있지만, 스타일 코드가 전부가 아니라는 것을 기억하는 것이 중요해요. 고품질 이미지 생성은 프롬프트 작성의 기본에 많이 의존하게 됩니다.\n\nMidjourney 애호가들의 헌신 덕분에 방대한 양의 스타일 코드가 편집되어, 이 과정은 급속히 가속화되고 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n얼마 전에는 처음 300개 스타일 코드만 보았는데, 이제는 3,000개가 넘었습니다. Midjourney가 공식적으로 오픈 소스 sref 사전 생성 계획을 발표했기 때문에 우리가 직접 sref를 찾을 필요가 없게 될 때가 머지 않았습니다.\n\n제 개인적인 검색을 토대로, 지금까지 가장 좋은 Midjourney sref 컬렉션을 선별했습니다.\n\n# 1. AI IQ 포털\n\nMidjourney 영향력 있는 인플루언서 Alie Jules가 만든 AI IQ 포털은 매일 새로운 스타일 참조 (sref)를 업데이트하는 웹사이트입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n미래의 업데이트를 통해 sref 코드를 스타일, 색상 등으로 분류하게 될 예정이며, 선호하는 스타일을 쉽게 찾을 수 있게 될 것입니다. 이 사이트를 즐겨찾기에 추가하여 계속해서 업데이트를 확인해주세요.\n\n![이미지](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_0.png)\n\n링크: [https://aiiqportal.com/midjourney-style-reference-codes/](https://aiiqportal.com/midjourney-style-reference-codes/)\n\n# 2. Tatiana Tsiguleva의 콜렉션\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n디자이너 Tatiana Tsiguleva는 Gumroad에서 무료로 다운로드할 수 있는 그녀의 검증된 srefs의 PDF를 제공합니다. 가격으로 \"0\"을 입력하고 \"이것을 원합니다\"를 클릭하여 비용없이 다운로드하실 수 있습니다.\n\n[이미지](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_1.png)\n\n링크: https://aig.gumroad.com/l/sref\n\n# 3. Dogan Ural의 컬렉션\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n디자이너 Dogan Ural은 현재 트위터 기여를 기반으로 30번의 업데이트를 통해 Notion에 Midjourney 스타일 코드의 선별된 목록을 편집하여 표시했습니다.\n\n![이미지](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_2.png)\n\n링크: [https://doganural.notion.site/530d40d0f4bb4fd1bdb0aab216c5b4d4?v=f56817e5ea3d40da89b7e1163b099040](https://doganural.notion.site/530d40d0f4bb4fd1bdb0aab216c5b4d4?v=f56817e5ea3d40da89b7e1163b099040)\n\n# 4. Charlie Q의 Magical Sref 라이브러리\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nCharlie Q의 스타일 라이브러리에서 300가지 Midjourney 스타일 코드를 요약했어요. 더 많은 내용이 곧 출시될 예정이에요. 사용하기 편리한 디자인은 이미지를 클릭하면 sref 코드를 표시해줘요.\n\n![이미지](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_3.png)\n\n링크: [여기를 클릭하세요](https://sites.google.com/charlottequinndesigns.com/cqs-sref-library/mj-6-codes)\n\n# 5. GeniArt의 PDF 컬렉션\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n니코는 Midjourney 열정가인, 프랑스어 웹사이트 geniart.fr를 만들어 Midjourney 주변의 커뮤니티를 구축했습니다.\n\n최근에는 1000개의 스타일 코드 컬렉션을 PDF 형식으로 편집했습니다. PDF는 조잡하지만 각 테이블 헤더 셀에는 10개의 스타일 코드가 포함되어 있어 사용하기에는 문제가 없습니다.\n\n링크: [코드 다운로드](https://geniart.fr/upload/OrderedEntropy/OrderedEntropy_canvas_sref-style-codes.pdf)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 6. 에스레프 랜덤 채굴 링크\n\nDiscord 사용자 \"P-Logic\"은 매개변수 --v 6.0 --ar 16:9 --sw 1000 --sref random을 사용하여 11 세트의 스타일 코드를 테스트하고 Midjourney 커뮤니티와 공유했습니다.\n\n[![이미지](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_5.png)]\n\n링크: [https://discord.com/channels/662267976984297473/1238405277670178816](https://discord.com/channels/662267976984297473/1238405277670178816)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 7. 브리에르 씨의 컬렉션\n\n미드저니 열정가인 브리에르 씨는 노션에 수백 가지의 스타일 코드를 모아두었습니다. 이 코드들은 sref 랜덤에 기반한 임의로 생성된 코드들로, 숫자적인 순서가 아닙니다.\n\n![이미지](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_6.png)\n\n링크: [https://mrdelabruyere.notion.site/Midjourney-Style-Reference-43bf1f17ed9c4042a6f3b115c9dd1b39](https://mrdelabruyere.notion.site/Midjourney-Style-Reference-43bf1f17ed9c4042a6f3b115c9dd1b39)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 8. Sevenstyles\n\n트위터 Midjourney 영향력 있는 사용자 브래드\\_7S는 처음 4,000개의 sref를 테스트하고 집계하여 Sevenstyles 사이트에 공유했습니다. 이 코드들은 각각 1,000개씩 4개의 분할로 나누어져 있습니다.\n\n![Sevenstyles](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_7.png)\n\n코드에 액세스하려면 사이트에서 zip 파일을 다운로드하세요. 압축을 풀면 실제 다운로드 링크를 찾을 수 있습니다. 이 링크를 브라우저에 복사하여 써드파티 다운로드 사이트로 이동할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_8.png\" />\n\n서드 파티 사이트가 고트래픽으로 다운로드 제한이 있을 수 있으므로 문제가 발생하면 새벽에 다시 다운로드를 시도해보세요. 각 zip 패키지는 대략 600MB 크기이며 해당 스타일 샘플 이미지와 스타일 코드가 포함된 텍스트 파일이 포함되어 있습니다.\n\n링크: [Seven Styles](https://sevenstyles.com/b/sevenstyles/)\n\n# 9. Collection by CreatorImpact\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n웨이드 맥매스터 디자이너가 그의 웹사이트에 'Midjourney' 스타일 코드 컬렉션을 만들었습니다. 이 컬렉션에는 처음 300개 스타일 코드와 몇 가지 무작위 코드가 포함되어 있습니다.\n\n![Midjourney Style Codes](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_9.png)\n\n링크: [Midjourney V6 스타일 코드를 위한 참조](https://creatorimpact.com/project/midjourney-v6-style-codes-for-sref/)\n\n# 10. 요시히코 나리타의 컬렉션\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n일본을 좋아하는 YoshihikoNarita가 Notion에 첫 350개의 sref 코드를 요약하여 컬렉션을 만들었습니다.\n\n![image](/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_10.png)\n\n링크: [여기를 클릭하여 이동](https://tarry-blob-de9.notion.site/be0b2afd80944a5686c48d6ab33f8d88)\n\n# 요약하자면\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n코드가 40억 개가 넘는 sref가 있습니다. 이를 정리하거나 모으는 것은 끝이없는 것처럼 느껴질 수 있습니다. 모든 코드가 모두의 취향에 맞을 수는 없고, 모든 스타일이 일상적으로 사용하기에 적합한 것은 아닙니다.\n\n다른 사람과 공유된 스타일 코드를 발견하면 이를 살펴보고 디스코드에서 테스트하여 여러분의 필요에 맞는지 확인한 후 컬렉션에 추가하세요.\n\nsref 코드는 스타일 경향을 나타내지만 이미지 품질을 결정하는 유일한 요소는 아닙니다. 효과적인 프롬프트와 다른 접미사 매개변수를 결합하는 것이 중요합니다.\n\n- by 公众号：二阶导\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n💡관심이 있으신가요? 저의 Midjourney 컬렉션으로 깊은 내용을 살펴보세요.\n\n## 기사가 마음에 드셨나요?\n\n만약 마음에 드셨다면:\n\n- 댓글 남기기\n- 업데이트 팔로우하기\n- 무료 이메일 알림 받기\n","ogImage":{"url":"/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_0.png"},"coverImage":"/assets/img/2024-05-17-Top10collectionsforMidjourneystylereferencecodes_0.png","tag":["Tech"],"readingTime":9},{"title":"NodePiece 노드 ID에서 토큰으로","description":"","date":"2024-05-17 20:06","slug":"2024-05-17-NodePieceFromNodeIDstoTokens","content":"\n그래프 임베딩에 대한 혁신적인 접근\n\n![이미지](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_0.png)\n\n# 소개\n\n자연어 처리(NLP) 및 대형 언어 모델(LLM)에 대한 관심과 발전이 급증한 것은 잘 알려져 있습니다. “토큰화” 및 “트랜스포머”와 같은 용어들이 어디서든 볼 수 있을 정도입니다. 그러나 그래프 신경망(GNN) 및 특히 지식 그래프 임베딩이라는 또다른 강력한 분야는 전문가들을 제외하고는 훨씬 인기가 적습니다. 이러한 기술들은 추천 시스템에서 링크 예측, 노드 분류 등 다양한 애플리케이션 영역에서 강력한 솔루션을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nGNN 세계에서 주목할 만한 기술 중 하나는 NodePiece 토큰화인데, 이견에 따르면 많은 주의를 필요로 합니다. 이 접근 방식은 그래프 신경망의 기능성을 향상시키기 위해 자연어 처리(NLP)에서 여러 개념을 도입한 새로운 방법론입니다. 이 기술은 유니버셜 \"토큰\" 집합을 사용하여 그래프 내 노드를 표현합니다. 이 접근 방식은 미리 정의된 ID 어휘가 필요 없어져 노드의 좀 더 적응적인 표현을 가능케 하며 모델이 다양한 그래프에 대해 일반화할 수 있는 능력을 향상시킵니다.\n\n잠재력이 커도 NodePiece 토큰화 방법론은 널리 다뤄지지 않는데, 예를 들어 LLMs와 같이요. 이 블로그 글은 NodePiece 토큰화를 명쾌하고 직관적으로 설명하며, 기존 구현이 매우 복잡하고 이미 구현된 라이브러리에 내장되어 있어 학습이 어려운 점을 감안하여 실용적인 Python 구현을 제공합니다.\n\n이 글을 마치면 다음을 이해할 수 있을 것입니다:\n\n1. NodePiece 토큰화의 기본 개념들을 파악할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 이 기술의 근간과 원칙을 이해하세요.\n\n3. Python에서 NodePiece 토큰화의 기본 버전을 구현하는 기술을 익히세요.\n\n저의 Github에서 Jupyter 노트북 및 토큰화 및 모델을 담은 모듈을 찾을 수 있습니다.\n\n이 포스트는 꽤 길기 때문에 섹션 및 하위 섹션의 간단한 개요입니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제목 1: 건설 블록의 마법\n\n1.1. NLP 세계 - 역사 요약: 이 섹션은 자연어 처리의 진화를 강조하며 Word2Vec 및 GloVe와 같은 기본 알고리즘에 초점을 맞춥니다.\n1.2. 트랜스포머 토크나이저의 출현: NLP 모델의 효율성과 유연성에 미치는 트랜스포머 기반 토큰화의 중요한 영향을 논의합니다.\n1.3. 그래프 세계: NLP 토큰화 개념을 그래프 신경망에 적용하는 잠재력을 탐구하여 NodePiece를 위한 무대를 마련합니다.\n\n제목 2: NodePiece 알고리즘\n\n2.1. 기여 및 출처: NodePiece 모델을 소개하며 새로움과 NLP로부터 영감을 얻은 주요 출처에 집중합니다.\n2.2. 기본 개념: NodePiece 모델의 핵심 구성 요소를 설명하며 그래프 노드의 토큰화 방법을 소개합니다.\n2.3. 위치적 특징: NodePiece가 노드의 공간적 위치를 선택된 기준점에 상대적으로 어떻게 활용하는지 설명합니다.\n2.4. 관계적 특징: NodePiece가 노드가 참여하는 관계 유형을 어떻게 파악하는지 상세히 설명합니다.\n2.5. 독특한 지문 - 직관: NodePiece가 위치적 및 관계적 특징을 결합하여 독특한 노드 임베딩을 만드는 방식에 대한 직관적 설명을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n### 파트 3: 형식적 정의\n\n3.1. Set-Based Form: 노드를 앵커, 거리 및 관계의 집합을 통해 표현하는 프로세스를 형식화합니다.\n3.2. 앵커, 거리 및 관계의 내장: NodePiece가 벡터 표현으로 변환하는 집합의 방법을 설명합니다.\n3.3. 부호화: 노드 정보를 단일 벡터로 압축하는 부호화 프로세스를 설명합니다.\n3.4. 이것으로 무엇을 할까요?: NodePiece 임베딩이 그래프 신경망에서의 잠재적인 응용 및 이점에 대해 논의합니다.\n\n### 파트 4: 간소화된 구현\n\n4.1. 전체 개요: 교육 목적을 위해 설계된 NodePiece의 간소화된 버전을 소개합니다.\n4.2. 데이터: 데모에 사용된 데이터셋을 설명하며, 실용성을 위해 관리 가능한 하위 집합의 선택을 강조합니다.\n4.3. 토큰화: 간소화된 모델 내에서 NodePiece의 토큰화 프로세스를 설명합니다.\n4.4. 앵커 선택: 구현에서 앵커 노드를 선택하는 방법을 상세히 설명합니다.\n4.5. K개 최근 앵커까지의 거리 구성: 모델이 노드에서 가장 가까운 앵커까지의 거리를 계산하는 방법을 설명합니다.\n4.6. 관계적 컨텍스트 추출: 노드의 관계적 컨텍스트를 식별하고 내장하는 프로세스를 설명합니다.\n4.7. 특성 행렬: 토큰화 및 컨텍스트 추출 결과를 특성 행렬 형태로 강조합니다.\n4.8. 전체 모델 정의: 모델 아키텍처 및 구성 요소에 대해 포괄적으로 살펴봅니다.\n4.9. TransE 모델 훈련: 지식 그래프 임베딩 작업에 NodePiece 임베딩을 사용하여 TransE 모델 훈련에 대해 논의합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 파트1: 빌딩 블록의 마법\n\n## NLP 세계 — 역사 소개\n\nNLP의 발전을 되짚어보면 초기 단계는 단어 임베딩, 어근 추출 및 토크나이제이션과 같은 방법론들에 의해 주도되었습니다. Church(2017)와 Brochier 등(2019)과 같은 선구적인 알고리즘들이 Word2Vec 및 GloVe와 같은 표준을 설정하며, 비교적 간단한 절차하에서 작동했습니다:\n\n1. 큰 텍스트 말뭉치를 편집하십시오.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 토큰화, 표제어 추출 및 유사한 기술을 통해 전처리합니다.\n\n3. 처리된 단어를 고유한 ID로 매핑하는 임베딩 조회를 구축합니다.\n\n그러나 이 접근 방식은 공간을 많이 차지하고 계산 비용이 많이 드는 방식이었습니다.\n\n예를 들어, 임베딩 행렬이 다음과 같이 정의된 경우를 고려해보겠습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![NodePieceFromNodeIDstoTokens](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_1.png)\n\n어휘 크기(V) 및 임베딩 크기(E)였습니다. 어휘 크기가 100,000이고 임베딩 크기가 300인 경우, 리소스에 상당한 수요를 일으키는 30 백만개의 부동 소수점을 할당해야 합니다.\n\n## 트랜스포머 토크나이저의 등장\n\n트랜스포머 및 그와 관련된 토큰화 방법의 도입이 이 분야를 혁신적으로 변화시켰습니다. Byte-Pair Encoding (BPE) (Sennrich et al., 2016)과 같은 기술은 부분 단어 또는 알파벳과 같은 건설 블록에 유사한 개념을 도입하여 토큰화 프로세스를 혁신적으로 개선했습니다. 이러한 부분 단어 또는 토큰은 전체 단어보다 더 간결하면서도 보다 보편적이며, 다양한 언어에 적용될 수 있고 새로운 어휘를 순차적으로 도입할 수 있도록 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래와 같이 표시됩니다. 해당 표현은 전통적인 방법에서는 단어를 분리하여 각각 임베딩을 할당할 것이지만, 현대적인 토크나이저는 서브워드로 분할할 수 있습니다.\n\n```js\n[CLS]\nmodern\ntoken\n##izer\n##s\nrevolution\n##ized\nthe\nway\n,\nhow\nwe\nprocess\ntext\nthese\ndays\n[SEP]\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이는 \"tokenizer\"와 같은 각 새로운 단어에 대한 고유한 ID가 필요하지 않게되어 \"token\"과 \"##izers\"가 이미 어휘에 있는 상태로 다른 단어의 표현을 구성할 수 있게 해줍니다. 이는 임베딩 메모리 공간을 절약하면서 가능하게 합니다.\n\n## 그래프의 세계\n\n그래프 처리 및 지식 그래프 추론의 분야에서는 현대 NLP 토큰화에 사용되는 개념과 유사한 개념을 받아들이는 과정이 느리게 진행되어 왔습니다. TransE (Bordes et al., 2013) 및 RotatE (Sun et al., 2019)와 같은 지식 그래프 추론을 위한 전통적인 알고리즘은 대부분 엔티티와 관계를 고유한 임베딩에 매핑하는 데 의존해 왔습니다. 이 접근 방식은 간단하지만 메모리 집약적이며, 각 엔티티 및 관계는 임베딩 공간 내에서 고유한 식별자를 필요로 합니다 — 마치 word2vec이나 기존 NLP 솔루션에서의 단어들처럼!\n\nTransE, RotatE 및 유사한 모델에 대해 더 알고 싶은 분은 Medium.com의 게시물을 강력히 추천합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사는 이러한 모델 뒤에 있는 원칙들에 대해 포괄적인 개요를 제공합니다.\n\n그래프 도메인 내에서 확장 가능하고 효과적인 솔루션을 찾는 것은 오랜 시간이 걸리지만 결과가 있었습니다. 노드피스(NodePiece)는 이 맥락에서의 선도적인 알고리즘 중 하나로 등장했으며, NLP 토큰화 기술의 발전에서 많은 영감을 받았습니다. 최신 토큰화 기술의 원칙을 그래프 구조에 적용함으로써, 노드피스는 그래프 엔티티와 관계를 표현하는 새로운 방법을 제공하며, 지식 그래프 도메인에서 더 많은 메모리 효율적이고 일반화 가능한 모델을 향한 중요한 발전을 이룩했습니다.\n\n# 파트 2: 노드피스 알고리즘\n\n## 기여와 출처\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n노드피스 알고리즘은 대규모 지식 그래프에 대한 합성 및 매개변수 효율적인 표현에 중점을 둔 지식 그래프 임베딩 분야에서의 중요한 발전을 대표합니다. \"NodePiece: Compositional and parameter-efficient representations of large knowledge graphs\" (Galkin et al., 2021) 논문에서 소개된 이 방법은 널리 사용되는 Python 라이브러리인 PyKeen에 통합되어 있습니다.\n\nPyKeen 구현은 아래에서 찾을 수 있습니다:\n\n게다가, 논문 기여자들에 의해 작성된 구현은 GitHub에서 접근 가능하며, 원본 코드베이스를 더 탐구하려는 분들을 위해 제공됩니다:\n\n이론적 관점에서 노드피스에 대한 포괄적이고 접근성 있는 소개를 위해, 원문의 공헌자 중 한 명인 Michael Galkin이 작성한 Medium 블로그 게시물 \"NodePiece: Tokenizing Knowledge Graphs\"를 읽어보시기를 권장합니다. 이 기사는 알고리즘에 대한 귀중한 심층적인 통찰을 제공하여 개발자들로부터 직접 얻은 통찰을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마이클 갈킨의 블로그 게시물 'NodePiece: 지식그래프의 토큰화'는 NodePiece 알고리즘에 대한 깊은 설명으로 두루 짚고 있으며, 그 중 하나인 창조자에 의해 저술되었습니다. 이는 원래의 학술 논문을 넘어서 모델을 이해하려는 사람들에게 좋은 자료입니다.\n\n## 기본 개념\n\nNodePiece 알고리즘은 지식 그래프 내 개체마다 고유 식별자를 할당하는 전통적 요구사항에서 벗어나, 대신 기본적인 구성 요소의 조합을 통해 개체를 나타냅니다. NLP의 토큰화 개념과 유사점을 그리며, 이러한 구성 요소는 다음과 같습니다:\n\n1. 위치 특성: 지정된 앵커 노드에 대한 노드의 근접성.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 관계 특성: 노드가 포함된 관계 유형\n\n## 위치 특성\n\n노드는 미리 정한 일련의 기준 앵커 노드들까지의 거리로 특성화됩니다. 이러한 앵커 노드를 선택하는 방법은 가장 연결된 노드를 선택하거나 클러스터링 알고리즘을 사용하거나 심지어 무작위 선택과 같은 선택 옵션을 포함합니다.\n\n선택 기술에 관계없이 근본적인 원칙은 간단합니다. 각 노드는 K개의 가장 가까운 앵커 노드까지의 거리에 의해 정의됩니다. 전략적인 앵커 노드 선택을 통해 가장 가까운 앵커에 대한 근접성이 각 노드에 대한 고유한 \"지문\"을 제공하는 높은 가능성이 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 예시를 통해 이 개념을 설명해 보겠습니다:\n\n![NodePieceFromNodeIDstoTokens_2](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_2.png)\n\n아래 표는 각 노드에서 앵커까지의 거리를 요약한 것입니다:\n\n![NodePieceFromNodeIDstoTokens_3](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_3.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 관계형 기능\n\n이질적인 지식 그래프에서 엣지는 노드 간의 다양한 관계 유형을 캡슐화합니다. NodePiece 알고리즘은 이러한 관계를 노드 표현의 중요한 구성 요소로 활용하여 각 노드의 컨텍스트와 그래프 내에서의 연결성을 풍부하게 합니다. 관계형 기능이 어떻게 통합되는지 설명하기 위해, 우리의 이전 예제를 다시 살펴보고 확장하겠습니다. 이번에는 관계 유형을 포함하여:\n\n![노드의 관계형 기능](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_4.png)\n\n각 노드의 관계를 다음의 표로 요약할 수 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![NodePieceFromNodeIDstoTokens_5](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_5.png)\n\nOr with counting each relation type:\n\n![NodePieceFromNodeIDstoTokens_6](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_6.png)\n\nProbably you see now, where it is going…\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 독특한 지문 — 직감\n\nNodePiece 알고리즘의 본질은 각 노드에 대한 일관된 표현인 위치 및 관계형 두 가지 다른 기능을 종합하는 능력에 있습니다. 이 과정은 가장 가까운 앵커 노드와 노드가 참여하는 관계 유형을 연결하여 노드의 고유한 \"지문\"이라는 단일 벡터를 얻게 됩니다.\n\n이 과정을 개념화하기 위해 다음 단순화된 스키마를 통해 노드 2를 나타내는 것을 고려해보세요:\n\n![NodePieceFromNodeIDstoTokens_7](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_7.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 파트 3: 형식적인 정의\n\nNodePiece 알고리즘 코딩을 시작하기 전에 언급할 중요한 세부 정보가 몇 가지 있습니다. 예를 들어:\n\n1. 선택적 앵커 사용: 모든 노드의 표현에 모든 앵커가 관련이 있는 것은 아닙니다. 가장 가까운 k개의 앵커만이 각 노드에 임베딩하기 위해 고려됩니다.\n\n2. 관계 추출: 마찬가지로, 노드의 관계적 문맥은 즉시 외부 관계 중에서 샘플링을 통해 파생되며, 각 노드당 최대 m개의 관계로 제한됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 연결 끊김 처리: 노드가 연결이 끊겼거나 특정 앵커나 관계에 대한 링크가 없는 경우 — 특별한 [DISCONNECTED] 토큰이 사용됩니다. 이는 NLP 시나리오에서의 `OOV` (out-of-vocabulary) 토큰과 유사합니다.\n\n이제 수학 시간입니다.\n\nNodePiece에 대한 입력이 무엇인지 시작해 봅시다:\n\n![NodePieceFromNodeIDstoTokens_8.png](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nNodePiece는 다음과 같이 설계되었음을 알 수 있습니다:\n\n1. 지식 그래프 - 특정 관계(R)에 속하는 에지(E)로 연결된 노드(N)의 모음으로 표현됩니다.\n\n2. 선택된 앵커 노드 (A) - 이들은 각 노드의 \"지문\" 표현의 일부가 될 것입니다.\n\n3. 관계 (R) 및 앵커 (A)는 모델의 어휘 (V)를 형성합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. 논문에서 언급했듯이, 모든 노드에 대해 모든 앵커를 사용할 필요는 없으므로 k개의 앵커가 샘플링됩니다.\n\n5. 관계에도 같은 원칙이 적용됩니다. 각 노드에 대해 m개의 관계만이 샘플링됩니다.\n\n## 집합 기반 형태\n\n우리가 가지고 있는 핵심 요소들로부터, 그래프 내 각 노드의 고유한 \"지문\"에 대한 형식적인 정의로 이어질 수 있습니다. 이 지문은 세 가지 구성 요소로 나뉩니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n1. 앵커 세트: 모든 앵커(A) 집합에서 임의로 선택된 k개의 앵커입니다.\n\n2. 앵커 거리: 노드에 대해 결정된 k개 가장 가까운 앵커까지의 최단 경로 거리입니다. 앵커에 도달할 수 없는 경우, 해당 거리는 미리 정의된 \"마법 값\"으로 표시됩니다. (-1 또는 다른 토큰과 같이)\n\n3. 관계적 맥락: 노드를 위해 샘플링된 m개의 직접 외부 관계 중 일부로, 즉시 관계적 환경을 포함합니다.\n\n형식적으로 표현하면, 정점 집합 V의 각 노드 u에 대한 표현은 다음과 같이 설명할 수 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![2024-05-17-NodePieceFromNodeIDstoTokens_9.png](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_9.png)\n\n원본 논문의 저자들은 거리에 positional encoding을 적용하여 각 거리를 차원 d의 벡터로 매핑하는 것을 옹호합니다. 이 접근 방식은 임베딩의 의도된 차원을 유지하는 것을 보장합니다.\n\n![2024-05-17-NodePieceFromNodeIDstoTokens_10.png](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_10.png)\n\n앵커 및 해당 거리에 대해 임베딩 조회 전략이 제안됩니다. 이는 각 앵커 id(예: 앵커=0)가 임베딩 행렬의 특정 행에 연결되며, 거리에 대해서도 동일한 방식으로 적용됨을 의미합니다(예: 거리=1은 embedding 1에 해당). 이 방법은 각 노드의 그래프 내 고유한 서명의 위치 및 관계적 측면을 효율적이고 의미 있게 인코딩하는 데 도움이 됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n고려해야 할 점은 기존 방법에서 사용되는 고유 노드 ID의 인구보다 앵커 수와 앵커 거리가 훨씬 작다는 것이다!\n\n## 앵커, 거리, 관계의 임베딩\n\n방정식 (1)으로 구분된 세트의 변환을 통해 임베딩을 통한 벡터 표현으로 포함된 기본 단계가 여러 단계 포함됩니다 (텍스트와 방정식을 섞는 Medium.com의 제한으로 인해 아래 부분은 이미지로 게시되었습니다).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Node representation matrix](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_12.png)\n\nAfter that, authors sum vectors related to anchors, so that the matrix node representation is as follows:\n\n![Node representation matrix](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_13.png)\n\n## Encoding\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n방정식 (3)에 나온 행렬은 각 노드 u에 대해 해당 인코더(MLP 또는 Transformer)를 적용하여 벡터로 변환을 용이하게 합니다. 이것은 원래 연구에서 발표된 것처럼 진행됩니다.\n\n이 인코더는 행렬을 각 노드에 대한 \"펼쳐진\" 벡터 표현으로 변환하여 복잡한 관계 및 위치 정보를 간결한 형태로 요약합니다.\n\n아래는 이 인코딩 프로세스를 실제 예제로 설명하는 목적으로 노드 2에 대한 표현을 고려해 봅시다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Anchor를 0부터 시작하는 식별자로 할당하므로 id(Anchor 1) = 0 및 id(Anchor 2) = 1입니다.\n\n- 관계는 유사하게 식별자가 부여되어 id(r1) = 0, id(r2) = 1, id(r3) = 2 등입니다.\n\n- 거리는 id(dist=1) = 0, id(dist=2) = 1, id(dist=3) = 2 등과 같은 방식으로 인덱싱됩니다.\n\n- k=m=2인 경우 각 노드에 대해 두 개의 Anchor와 두 개의 관계가 샘플링됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n주어진 매핑을 가정하고 차원 공간 d = 3인 경우, 방정식 (2)에 따른 표현은 다음과 같이 나타납니다:\n\n![image1](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_15.png)\n\n![image2](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_16.png)\n\n\\*0부터 세는 것을 기억하세요 :) id(r1) = 0, id(Anchor1) = 0, 등등 :).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_17.png)\n\n그 후, 각 앵커, 거리, 그리고 관계에 d-차원 임베딩이 적용됩니다. 이들은 크기 d의 벡터로 매핑됩니다. 예를 들어, d=3인 경우, 앵커, 거리, 그리고 관계에 대한 결과 행렬은 방정식 (2)와 일치하는 다음과 같을 수 있습니다:\n\n![이미지](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_18.png)\n\n물론 각 행렬의 값은 예시입니다 — 실제 모델에서는 아마 무작위 숫자들이 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n앵커와 관련된 벡터를 합한 후에 방정식(3)에 정해진대로 연결하면 다음과 같이 유도됩니다:\n\n![image](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_19.png)\n\n이러한 과정은 인코딩이 각 노드에 대해 앵커, 거리 및 관계 데이터의 복잡한 배열을 통합하고 단순화하여 다운스트림 그래프 처리 작업에 즉시 사용할 수 있도록 만드는 능력을 보여줍니다.\n\n## 어떻게 활용할까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금부터 사용자는 분류, 클러스터링 등과 같은 하위 작업을 진행할 수 있습니다.\n\n각 노드의 표현은 이제 일반적인 특성처럼 사용할 수 있는 평면 벡터입니다.\n\n노드의 고유한 특성을 캡처해야 합니다. 즉, 그래프 내에서의 위치, 관계 등을 포함해야 합니다.\n\n논문 자체에서는 NodePiece 알고리즘의 기본적인 최적화, 트릭 및 개선 사항들이 여러 가지 언급되어 있지만, 이 간소화된 설명에서는 나머지 부분을 건너 뜁했습니다. 자세한 내용에 관심이 있다면 원본 논문을 꼭 읽어보시기를 강력히 권장합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 파트 4: 단순화된 구현\n\n## 개요\n\n노드피스 알고리즘의 기존 구현인 원본 논문의 저자들이 제공하고 있는 PyKeen 라이브러리 내의 버전들은 포괄적이지만 복잡합니다. 이러한 버전들은 성능 및 기존 프레임워크 내 통합을 최적화한 것이지만, 응용 프로그램 개발에 유용할 수 있지만, 알고리즘의 이론적 기초와 실제 코드 표현 사이의 개념적 공통점을 명확히하는데 어려움을 줄 수 있습니다. 이러한 복잡성은 알고리즘을 이해하려는 사람들에게 어려움을 줄 수 있습니다.\n\n교육용으로 맞춤화된 구현의 제한된 가용성과 알고리즘의 기본 메커니즘을 이해하고자 하는 사람들을 위한 것이 아닌 알고리즘에 대해 더 깊이있게 이해하려는 사람들을 위한 간소화된 NodePiece의 버전을 개발하기로 선택했습니다. 이 버전은 명확성과 확장성을 염두에 두고 설계되었으며, 최적화와 프레임워크별 고려사항을 초과하는 부담 없이 알고리즘의 기본 메커니즘을 이해하려는 개인들에게 더 접근성 있는 진입점을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위 간소화된 구현은 두 가지 주요 구성 요소로 구성되어 있습니다:\n\n1. Tokenization Module: 이 코드 세그먼트는 앵커 및 관계를 선택하고 노드 표현을 구성하는 데 책임이 있으며 앵커, 관계 및 거리에 대한 식별자로 노드 표현을 정렬합니다. 이는 방정식(1)에서 설명된 프로세스와 일치하며, 노드의 앵커와의 관계 및 다양한 관계에 참여함으로써 노드의 고유한 \"지문\"을 생성하는 초기 단계를 총망라합니다.\n\n2. Models Module: 이 부분은 식별자를 벡터 공간에 포함시키고 예측 모델을 구축하는 작업을 수행합니다. 이는 NodePiece 알고리즘의 후속 단계를 구현하는 것으로, 노드의 추상적인 표현을 밀집 벡터 표현으로 변환하고 이를 하류 기계 학습 작업에서 활용할 수 있게 합니다.\n\n## 데이터\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실습 목적으로 이 튜토리얼은 FB15k-237 데이터셋의 작은 하위 집합을 활용할 것입니다. 데이터셋의 축소판을 사용하는 이유는 실용성에 있습니다: 로컬에서 전체 데이터셋에 모델을 학습하는 데에는 시간이 많이 소요될 수 있습니다. 이 하위 집합은 결과 그래프가 일관되고 연결되어 있으며 전체 데이터셋의 구조적 무결성과 관계 복잡성을 유지하도록 꼼꼼히 만들어졌습니다. 이 방식을 통해 NodePiece 알고리즘을 빠르고 통찰력 있게 탐구할 수 있으며, 단순화된 구현을 더 관리하기 쉬운 규모로 실험하고 확장할 수 있습니다.\n\n저희 축소된 데이터셋은 다음과 같은 구성 요소로 이루어져 있습니다:\n\n1. 훈련 데이터셋 — 123,816 개의 삼중 세트.\n\n2. 검증 데이터셋 — 402 개의 삼중 세트.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 테스트 데이터셋 — 224개의 삼중 세트가 있습니다.\n\n4. 237가지 고유한 관계 유형이 있습니다.\n\n## 토큰화\n\n이제 그래프를 토큰화할 시간입니다. 우리는 단순화된 NodePiece 논리를 사용하는 사용자 정의 함수를 사용할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 내용을 다음과 같이 번역하겠습니다.\n\n전체 데이터셋에서:\n\n- 30개의 앵커를 선택합니다.\n- 각 노드에 대해 20개의 가장 가까운 앵커를 선택합니다.\n- 각 노드에 대해 10가지 관계를 선택합니다.\n\n## 앵커 선정\n\n앵커 선정 함수를 시작해보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndef degree_anchor_select(g: nx.Graph, n_anchors: int|float = 0.1) -> Tuple[List[int], Dict[int, int]]:\n    \"\"\"앵커 선택 방법으로, 용이한 경중에 따라 기초합니다. 가장 간단한 휴리스틱에 기초하여\n    이 그래프 내에서 가장 많은 노드와 연결되는 것으로 가정하고 노드의 최고 차수를 가진 노드를\n    앵커로 선택합니다.\n\n    매개변수\n    ----------\n    g : nx.Graph\n        Networkx 그래프입니다.\n    n_anchors : int | float, 선택사항\n        선택할 앵커의 수로, 기본값은 0.1입니다.\n        int일 경우 - 선택할 앵커 수입니다.\n        float일 경우 - 앵커로 선택할 노드의 비율입니다.\n\n    반환값\n    -------\n    Tuple[List[int], Dict[int, int]]\n        1. 앵커 노드 목록입니다.\n        2. 앵커 노드를 해당 ID로 매핑한 딕셔너리입니다. 앵커 ID는 [0, n_anchors) 범위 내에 있습니다.\n    \"\"\"\n    if type(n_anchors) == float:\n        n_anchors = int(g.number_of_nodes() * n_anchors)\n\n    degrees = sorted(g.degree, key=lambda x: x[1], reverse=True)\n    anchor_2_id = {}\n    anchors = []\n    for i, (node, _) in enumerate(degrees[:n_anchors]):\n        anchors.append(node)\n        anchor_2_id[node] = i\n\n    return anchors, anchor_2_id\n```\n\n`degree_anchor_select` 함수는 이 작업에 대해 직관적이면서도 효과적인 방법을 보여줍니다. 노드의 차수를 앵커 선택 기준으로 활용합니다. 이 방법은 높은 차수를 갖는 노드가 더 많은 연결을 의미하므로 해당 그래프의 다양한 부분에 연결될 가능성이 높기 때문에 최적의 앵커로 간주합니다. 함수가 작동하는 방식을 단계별로 살펴보겠습니다:\n\n1. 입력 매개변수: 함수는 NetworkX 그래프 `g`와 `n_anchors` 매개변수를 받습니다. `n_anchors` 매개변수는 선택할 앵커의 수를 지정하며, 이 값은 그래프의 노드 중 일정 비율(기본값은 0.1 또는 10%)을 앵커로 지정할 경우에 float로 지정하거나 원하는 앵커 수를 정수로 지정할 수 있습니다.\n\n2. 차수 계산 및 정렬: 함수는 그래프 내 각 노드의 차수를 계산합니다. 그런 다음, 노드들을 차수에 따라 내림차순으로 정렬하여 앵커로 선택할 때 높은 차수의 노드를 우선하여 고려합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. ID 매핑 앵커: 선택된 각 앵커 노드를 0부터 시작하는 고유 식별자에 매핑하는 anchor_2_id 사전이 초기화됩니다. 이 매핑은 NodePiece 토큰화 프로세스의 이후 단계에서 앵커 노드를 효율적으로 식별하고 활용할 수 있게 합니다.\n\n4. 반환 값: 이 함수는 선택된 앵커 노드의 목록과 anchor_2_id 사전을 포함하는 튜플을 반환합니다. 목록에는 앵커로 선택된 노드들이 포함되며, 사전은 이러한 앵커 노드와 할당된 ID 사이의 매핑을 제공하여 노드 표현 구성 시에 직접 참조할 수 있게 합니다.\n\n## K개 가까운 앵커까지의 거리 구축\n\n다음으로, 각 노드에서 K개 가까운 앵커 노드까지의 최단 경로 거리를 계산하는 함수를 구축할 예정입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\ndef build_distance_to_k_nearest_anchors(\n        G: nx.Graph,\n        anchors: List[int],\n        anchor2id: dict,\n        k_closest_anchors: int = 15,\n        use_closest: bool = True) -> Tuple[np.ndarray, np.ndarray, int]:\n    \"\"\"그래프의 각 노드에 대해 k개 가장 가까운 앵커까지의 거리를 계산합니다.\n\n    매개변수\n    ----------\n    G : nx.Graph\n        네트워크x 그래프.\n    anchors : List[int]\n        앵커 노드 목록.\n    anchor2id : dict\n        앵커에서 id로의 매핑.\n    k_closest_anchors : int, optional\n        각 노드에서 선택할 k개 가장 가까운 앵커의 수, 기본값은 15\n    use_closest : bool, optional\n        가장 가까운 앵커를 사용해야 하는지 또는 모두 사용해야 하는지 여부, 기본값은 True\n\n    반환값\n    -------\n    Tuple[np.ndarray, np.ndarray, int]\n        다음으로 구성된 튜플:\n        1. 노드와 앵커 사이의 거리 행렬. 형태: (노드 수, 앵커 수).\n        2. 노드와 앵커 id 행렬. 형태: (노드 수, 앵커 수).\n        3. 그래프 내의 최대 거리. 거리 인코딩/임베딩에 사용될 것입니다.\n    \"\"\"\n    node_distances = {i: [] for i in range(G.number_of_nodes())}\n    for a in tqdm(anchors):\n        for node, dist in nx.shortest_path_length(G, source=a).items():\n            node_distances[node].append((a, dist))\n\n    node2anchor_dist = np.zeros((G.number_of_nodes(), len(anchors)))\n    node2anchor_idx = np.zeros((G.number_of_nodes(), len(anchors)))\n    unreachable_anchor_token = len(anchors)\n    node2anchor_idx.fill(unreachable_anchor_token)\n\n    max_dist = 0\n\n    for node, distances in tqdm(node_distances.items()):\n        indices_of_anchors = sorted(distances, key=lambda x: x[1])[:k_closest_anchors] if use_closest else node_distances[node]\n        for i, (anchor, dist) in enumerate(indices_of_anchors):\n            anchor_id = anchor2id[anchor]\n            node2anchor_dist[node, anchor_id] = dist\n\n            node2anchor_idx[node, i] = anchor_id\n            if dist > max_dist:\n                max_dist = dist\n    unreachable_anchor_indices = node2anchor_idx == unreachable_anchor_token\n    node2anchor_dist[unreachable_anchor_indices] = max_dist + 1\n    return node2anchor_dist, node2anchor_idx, max_dist\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 거리 및 인덱스 행렬의 인구: 이 함수는 각 노드의 앵커까지의 거리를 정렬하여 각 노드에 대해 가장 가까운 k개의 앵커를 선택합니다. 선택된 앵커까지의 거리와 인덱스는 각각의 배열에 저장됩니다. 이 과정에서 max_dist 변수는 관측된 최대 거리를 반영하도록 업데이트되어, 도달할 수 없는 앵커는 이 최대값을 초과하는 거리로 표시됩니다 (max_dist +1 - \"마법 OOV 토큰\" :)).\n\n4. 도달할 수 없는 앵커 처리: 앵커에 대한 경로가 없어 도달할 수 없는 노드의 경우 거리가 max_dist + 1로 설정됩니다. 이 조정은 node2anchor_idx의 unreachable_anchor_token과 일치하는 인덱스를 식별하여 해당하는 node2anchor_dist 항목을 이 증가된 최대 거리로 설정함으로써 이뤄집니다. 이 메커니즘은 효과적으로 일부 앵커로부터 격리된 노드를 처리하며, 그래프 내에서 연결되지 않은 구성 요소의 가능성을 인정하여 NodePiece 표현의 무결성을 유지합니다.\n\n5. 반환 값: 함수는 노드마다 가장 가까운 앵커 지점에 대한 포용도를 제공하는 node2anchor_dist 거리 행렬, 앵커 인덱스 행렬 node2anchor_idx 및 max_dist 값을 포함하는 튜플을 반환함으로써 마무리됩니다. 이러한 출력은 NodePiece 임베딩을 구성하는 기초를 제공하여 각 노드의 근접성에 대한 종합적인 매핑을 제공합니다.\n\n## 관계적 컨텍스트 추출\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 단계는 각 노드에 대한 관련 컨텍스트를 추출하는 것입니다.\n\n```js\ndef sample_rels(pyg_g: pyg_data.Data, max_rels: int = 50) -> th.Tensor:\n    \"\"\"각 노드에 대해 m개의 외부 관계를 샘플링합니다. 노드의 관계가 m보다 적은 경우, 특수 토큰으로 출력을 채웁니다.\n\n    매개변수\n    ----------\n    pyg_g : pyg_data.Data\n        PyTorch Geometric 그래프.\n    max_rels : int, optional\n        사용할 관계의 최대 수, 기본값은 50입니다.\n\n    반환\n    -------\n    th.Tensor\n        각 노드에 대한 관계 행렬. 형태: (노드 수, max_rels).\n        각 행은 특정 노드에 해당하며, 각 열은 관계(ID)에 해당합니다.\n    \"\"\"\n    rels_matrix = []\n    missing_rel_token = pyg_g.edge_type.max() + 1\n    for node in tqdm(range(pyg_g.num_nodes)):\n        node_edges = pyg_g.edge_index[0] == node\n        node_edge_types = pyg_g.edge_type[node_edges].unique()\n        num_edge_types = len(node_edge_types)\n\n        if num_edge_types < max_rels:\n            pad = th.ones(max_rels - num_edge_types, dtype=th.long) * missing_rel_token\n            padded_edge_types = th.cat([node_edge_types, pad])\n            padded_edge_types = padded_edge_types.sort()[0]\n        else:\n            sampled_edge_types = th.randperm(num_edge_types)[:max_rels]\n            padded_edge_types = node_edge_types[sampled_edge_types].sort()[0]\n        rels_matrix.append(padded_edge_types)\n    return th.stack(rels_matrix)\n```\n\n1. 초기화: 함수는 PyTorch Geometric (PyG) 그래프 객체 pyg_g와 선택적으로 최대 관계 수를 결정하는 max_rels 매개변수를 필요로 합니다. 기본값은 50입니다. 모든 노드의 관계 데이터를 보유할 빈 리스트 rels_matrix가 준비되어 있습니다. 또한, 주어진 노드에 대한 관계가 없음을 나타내는 missing_rel_token이 정의되며, 사실상 다음 \"어휘 외\" 토큰으로 작동합니다. 이 토큰은 그래프에서 발견된 가장 큰 관계 ID보다 1 큰 값으로 설정됩니다.\n\n2. 고유 관계 탐색: 각 노드에 대해 고유한 외부 엣지 유형(관계)을 찾습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 관계 수 확인: 그래프의 각 노드에 대해, 이 함수는 노드에 연결된 모든 고유한 발신 관계 유형(엣지 유형)을 식별합니다.\n\n4. 관계 수 조정: 노드의 고유한 관계 수가 max_rels 임계값보다 작을 경우, 관계 목록에 누락된 관계 토큰을 추가하여 지정된 최대값에 도달하도록 패딩 처리됩니다. 이는 모든 노드에서 관계적 문맥의 길이를 균일하게 유지합니다.\n\n반대로, 노드가 max_rels로 허용하는 관계 유형보다 많이 연결된 경우, 제한에 맞게 일부가 무작위로 선택됩니다. 이 무작위 샘플링은 세부 정보와 계산 효율성 사이의 균형 유지에 필요한 것을 나타냅니다.\n\n4. 관계 정렬 및 저장: 각 노드에 대한 샘플링된(또는 추가된) 관계는 일관된 순서를 유지하도록 정렬됩니다. 정렬된 목록은 그래프 전체에 대한 포괄적인 관계적 문맥 저장소를 점진적으로 구축하기 위해 rels_matrix에 추가됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n6. 텐서 변환 및 결과 반환: 모든 노드에 대한 관계적 맥락 추출이 완료되면 rels_matrix 목록이 PyTorch 텐서로 변환됩니다. 이 텐서는 (num_nodes x max_rels) 모양을 가지며, 각 노드의 관계적 맥락을 구조화되고 기계가 읽을 수 있는 형식으로 체계적으로 나타냅니다.\n\n## 기능 행렬\n\n모든 작업이 완료되면 세 개의 행렬이 남습니다:\n\n1. anchor_distances — 각 노드에서 K 개 가장 가까운 앵커까지의 거리. 차원: N 노드 x K 앵커.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. anchor_hashes— 각 노드의 K 개 가장 가까운 앵커의 인덱스. 차원: N 노드 x K 앵커.\n\n3. rel_hashes — 각 노드의 관계적 맥락. 차원: N 노드 x M 관계.\n\n## 전체 모델 정의\n\n이 연습에서는 좀 더 간단하면서 효과적인 지식 그래프 임베딩 모델인 TransE로 피벗합니다. 원래 논문은 RotatE를 사용했지만 — 좀 더 복잡한 모델 — TransE는 그래프 내에서 관계를 임베딩하는 기본 측면에 초점을 맞춘 단순화된 접근 방식을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nTransE는 헤드 노드, 관계 및 테일 노드로 구성된 트리플릿을 평가하는 방식으로 작동합니다. 이는 헤드와 테일 노드 사이에 지정된 관계가 존재할 확률을 나타내는 likelihood 점수를 할당합니다. 모델의 목적은 실제 트리플릿을 인공적으로 생성된(변형된) 트리플릿과 구별하기 위해 설계된 손실 함수의 최적화에 담겨 있습니다.\n\n마크다운 형식으로 표를 변경하겠습니다:\n\n![이미지 1](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_20.png)\n\n![이미지 2](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_21.png)\n\n의사 코드로 작성하면 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nfor (head, relation, tail) in data:\n    head_embed = EMBED(head)\n    rel_embed = EMED(relation)\n    tail_embed = EMBED(tail)\n    score = -1 * [(head_embed + rel_embed) - tail_embed]\n    return score\n```\n\nWe return -1 x score as we want to minimize the score, and maximize the likelihood of the triplet.\n\nWhen interacting with NodePiece embeddings, TransE gets interesting when it comes to embedding head and tail nodes.\n\nTransE embedding in this case will perform several steps. For each head or tail node:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n1. 가장 가까운 앵커 인덱스를 가져와서 포함하세요.\n\n2. 가장 가까운 앵커까지의 거리를 가져와서 포함하세요.\n\n3. 관계적 맥락을 가져와서 포함하세요.\n\n4. 방정식 (3)에 따라서: 앵커 ID 임베딩과 거리 임베딩을 더해주고, 관계 임베딩과 연결하여 하나의 벡터로 연결하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n5. 이 벡터를 인코더(MLP 또는 Transformer)를 통해 최종 임베딩을 얻기 위해 전달합니다.\n\n우리의 구현은 다음과 같이 보일 것입니다 - 이 절차는 각 헤드 및 테일 노드에 대해 호출됩니다:\n\n```js\n    def embed_node(self, node: th.Tensor, closest_anchors, anchor_distances, rel_hash):\n\n        # Dim: (N x K) values are anchor ids --> (N x K x D)\n        anchor_embed = self.anchor_embed(closest_anchors[node])\n\n        # Dim: (N x K) values are anchor distances --> (N x K x D)\n        anchor_distances_embed = self.anchor_distances_embed(anchor_distances[node])\n\n        # Dim: (N x M) values are relation types --> (N x M x D)\n        rel_embed = self.rel_emb(rel_hash[node])\n\n        # Dim: (N x K x D)\n        combined_anchor_embed = anchor_embed + anchor_distances_embed\n\n        # N x (K + M) x D\n        stacked_embed = th.cat([combined_anchor_embed, rel_embed], dim=1)\n        N, anchors_plus_rel, hidden_channels = stacked_embed.shape\n\n        # reshape: (N x (K + M) x D) --> (N x (K + M) * D)\n        flattened_embed = stacked_embed.view(N, anchors_plus_rel * hidden_channels)\n\n        # N x (K + M) * D --> N x O\n        lin_out = self.lin_layer(flattened_embed)\n\n        return lin_out\n```\n\n1. anchor_embed는 앵커 해시에 대한 임베딩 조회입니다. 가중치 행렬의 차원은 ((K 앵커 + 1) x D 임베딩 크기)입니다. (N x K) 앵커 해시 행렬을 가져와 (N x K x D) 텐서를 반환합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. anchor_distances_embed은 앵커 거리를 위한 임베딩 조회입니다. 가중치 행렬은 ((최대 거리 +1) x D 임베딩 크기)의 차원을 가집니다. (N x K) 크기의 앵커 거리 행렬을 가져와 (N x K x D) 텐서를 반환합니다.\n\n3. rel_embed은 관계 해시를 위한 임베딩 조회입니다. 가중치 행렬은 ((고유 관계 +1) x D 임베딩 크기)의 차원을 가집니다. (N x M) 크기의 관계 해시 행렬을 가져와 (N x M x D) 텐서를 반환합니다.\n\n## TransE 모델 학습\n\n이제 TransE 모델을 준비하고, PyTorch Lightning으로 래핑하여 FB15k-237 데이터 하위 집합에서 훈련할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nuse_swa = True\nswa_lr = 0.05\n\npyg.seed_everything(111)\n\nparams = models.KGModelParams(\nnum_nodes=train_data_orig.num_nodes,\nnum_relations=train_features.n_rels+1,\nembedding_dim=200,\nmax_distance=max_distance+1,\nhidden_sizes=(400,),\nnum_anchors=train_features.n_anchors,\ntop_m_relations=train_features.m_relations,\ndevice=device,\nkg_model_type=models.ModelType.TransE,\ndrop_prob=0.2\n)\n\nmodel_pl = models.NodePiecePL(\nparams,\nlr=5e-2,\ntrain_features=train_features,\nval_features=val_features)\n\n저희가 인스턴스화한 모델은 다음과 같습니다:\n\nNodePieceTransE(\n(anchor_embed): Embedding(31, 200)\n(anchor_distances_embed): Embedding(13, 200)\n(rel_emb): Embedding(238, 200)\n\n(lin_layer): Sequential(\n(0): BatchNorm(8000)\n(1): Linear(in_features=8000, out_features=400, bias=True)\n(2): LeakyReLU(negative_slope=0.01)\n(3): Dropout(p=0.2, inplace=False)\n(4): Linear(in_features=400, out_features=200, bias=True)\n)\n)\n\n이전에 설명한 이론 부분과 완벽하게 일치합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째로는 기준 성능을 얻기 위해 모델을 어떤 학습도 하기 전에 유효성 검사 집합을 사용하여 모델을 평가할 것입니다. 결과는... 음... 예상대로 :)\n\n```js\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      검증 메트릭      ┃       데이터로더 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│    val_hits_at_k_epoch    │            0.0            │\n│    val_mean_rank_epoch    │   0.0005408872966654599   │\n└───────────────────────────┴───────────────────────────┘\n```\n\nHits@k(10) = 0.0이며 올바른 tail의 평균 순위는 매우 낮습니다. 이는 모델이 아직 학습되지 않았기 때문에 예상된 결과입니다.\n\n모델 학습에 시간을 투자한 후에는 학습 이후의 성능을 확인하기 위해 모델을 평가할 수 있습니다. 체크포인트 콜백이 사용되었으므로 모든 반복 중에서 최상의 모델을 선택할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nHits@k 및 평균 순위 메트릭에서 상당한 향상이 있음을 볼 수 있을 것입니다.\n\n```js\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│    val_hits_at_k_epoch    │    0.3240000009536743     │\n│    val_mean_rank_epoch    │    0.2862264811992645     │\n└───────────────────────────┴───────────────────────────┘\n```\n\n실제로, 예측 품질이 향상되었음을 확인할 수 있습니다. 물론, 이러한 작은 데이터 세트에 대해서도 실행하는 데 상당한 시간이 소요될 수 있습니다. 저는 1개의 GPU(T4), 16GB RAM 및 8개 가상 코어를 사용하는 Lightning.ai 플랫폼을 사용했고, 계산에 약 30분이 걸렸습니다.\n\n규모를 감을 수 있도록 말씀드리면, 원래 논문에서는 훨씬 큰 데이터 세트를 사용했으며, 학습에 GPU로 몇 시간이 걸렸습니다. 논문의 표 10에서 한 실험은 400번의 epoch와 1,000개의 앵커로 7시간이 소요되었습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n이 블로그 포스트에서는 NodePiece에 대해 자세히 알아보았습니다. NodePiece는 자연어 처리를 위해 사용되는 Transformer의 토크나이제이션 기법에서 영감을 받은 그래프 신경망의 혁신적인 접근 방식입니다. Transformer의 토크나이저가 텍스트를 관리 가능한 조각으로 분해하여 텍스트 분석을 혁신했던 것처럼, NodePiece는 그래프에 유사한 개념을 적용합니다. 그래프의 다양한 부분을 나타내기 위해 기본 요소 또는 \"토큰\"의 집합을 사용하여 복잡한 네트워크를 쉽게 처리할 수 있게 합니다.\n\nNodePiece가 거대하고 복잡한 그래프에서 노드를 나타내는 도전에 대응하기 위해 Transformer에서 사용되는 토크나이제이션 전략에서 아이디어를 빌렸다는 전반적인 내용을 시작으로 하였습니다. 이 접근 방식은 NodePiece가 노드의 본질과 관계를 효율적으로 포착할 수 있도록 하며, 각 노드를 명시적으로 식별할 필요가 없기 때문에(아이디를 통해서), 링크 예측, 노드 분류 등과 같은 작업에 대한 중요한 장점을 제공합니다.\n\n또한 NodePiece의 이론적 배경에 대해 다루었는데, 그래프 내에서 노드의 관계와 위치에 집중함으로써 노드를 유연하고 일반화된 방식으로 표현하는 방법을 설명했습니다. 이것은 노드의 표현을 단순화하고 모델이 다양한 그래프에서 학습하고 적응하는 능력을 향상시킵니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마침내, 교육적 목적을 고려하여 설계된 NodePiece 모델의 간소화된 구현을 소개했습니다. 이 구현은 NodePiece가 어떻게 작동하며 현실 세계의 그래프 신경망 작업에 어떻게 적용될 수 있는지를 이해하기 쉽도록 개념을 세분화했습니다.\n\n이 소개가 유용하게 느껴지길 바라며, 여러분의 그래프 프로젝트에서 NodePiece 토큰화를 활용할 수 있기를 기대합니다!\n\n이 이야기를 읽어주셔서 감사드립니다.\n\n# 참고문헌\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). 다중 관계 데이터 모델링을 위한 임베딩 번역. 신경 정보 처리 시스템 발전, 26. https://proceedings.neurips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html\n- Brochier, R., Guille, A., & Velcin, J. (2019). 노드 표현을 위한 글로벌 벡터. 월드 와이드 웹 컨퍼런스, 2587–2593. https://doi.org/10.1145/3308558.3313595\n- Church, K. W. (2017). Word2Vec. 자연어 공학, 23(1), 155–162.\n- Galkin, M., Denis, E., Wu, J., & Hamilton, W. L. (2021). Nodepiece: 대규모 지식 그래프의 구성적 및 매개 효율적 표현. arXiv Preprint arXiv:2106.12144.\n- Sennrich, R., Haddow, B., & Birch, A. (2016). 드문 단어의 신경 기계 번역 : 서브워드 단위(arXiv:1508.07909; 버전 5). arXiv. https://doi.org/10.48550/arXiv.1508.07909\n- Sun, Z., Deng, Z.-H., Nie, J.-Y., & Tang, J. (2019). RotatE: 복소 공간내 관계 회전에 의한 지식 그래프 임베딩(arXiv:1902.10197; 버전 1). arXiv. https://doi.org/10.48550/arXiv.1902.10197\n\n# 친근한 마음으로 안내합니다 💬\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 다음에도 놓치지 마세요:\n\n- 작가를 박수와 팔로우해 주세요 ️👏️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문: Stackademic | CoFeed | Venture | Cubed\n- PlainEnglish.io에서 더 많은 콘텐츠를 만나보세요\n","ogImage":{"url":"/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_0.png"},"coverImage":"/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_0.png","tag":["Tech"],"readingTime":42},{"title":"검색 및 분석 혁신 AI 통합으로 강화된 Elasticsearch의 벡터 검색 능력 탐색","description":"","date":"2024-05-17 20:03","slug":"2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration","content":"\n![링크 미리보기](/assets/img/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration_0.png)\n\n지속적으로 진화하는 검색 및 분석 환경에서 Elasticsearch는 동적이고 다재다능한 플랫폼으로 두각을 나타냅니다. Elasticsearch의 벡터 검색에 대한 여정은 그 진화의 핵심에 있습니다. 이 새로운 방법은 키워드로 검색하는 예전 방식을 뛰어넘어 게임을 완전히 바꿉니다. 최첨단 인공지능(AI) 기술을 통합함으로써 Elasticsearch의 벡터 검색 능력은 새로운 차원으로 확장되어 뛰어난 정확성, 맥락 인식, 확장성을 제공합니다.\n\n# 벡터 데이터베이스 이해: 기술적 관점\n\n벡터 데이터베이스는 데이터 저장 및 검색에서 패러다임 전환을 의미하며, 특히 전통적인 관계형 데이터베이스가 부족한 시나리오에서 빛을 발합니다. 일반적인 데이터베이스가 데이터를 표 형식으로 저장하는 데 반해, 벡터 데이터베이스는 고차원 공간에 벡터로 데이터를 저장합니다. 이를 통해 데이터의 세부적인 표현이 가능해지며, 특히 엔티티 간의 관계가 복잡하고 다면히된 도메인에서 더욱 정교한 표현이 가능해집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 벡터 데이터베이스의 주요 장점:\n\n- 효율적인 표현: 벡터는 복잡한 데이터 구조의 간결하고 효율적인 표현을 제공하여 고차원 데이터를 저장하고 처리하기에 이상적입니다.\n- 의미 유사성: 벡터 공간은 엔티티간의 의미 유사성을 측정할 수 있게 하여 보다 정교하고 문맥에 맞는 검색 및 분석이 가능합니다.\n- 확장성: 벡터 데이터베이스는 본질적으로 확장 가능하며, 성능이나 효율성을 희생하지 않고 대용량 데이터를 처리할 수 있습니다.\n\n# 벡터 데이터베이스 탐색: 비교적 개괄적인 투자\n\n벡터 데이터베이스 분야에서 Elasticsearch는 중요한 역할을 하지만, ChromaDB, Faiss, Milvus와 같은 대안 솔루션을 고려하는 것이 중요합니다. 각각에는 독특한 기능과 특정한 사용 사례가 있습니다. Elasticsearch가 빛을 발하는 시점과 대안적 벡터 데이터베이스가 선호되는 시점을 이해하기 위해 비교 분석에 대해 알아보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## ChromaDB:\n\nChromaDB는 미디어 응용 프로그램(예: 이미지 및 오디오 검색)에 특히 적합한 고차원 벡터의 효율적인 저장 및 검색을 위해 설계되었습니다. 전문적인 인덱싱 알고리즘을 사용하여 색 공간에서 유사성 검색을 최적화하여, 정확한 색 일치 및 인식이 필요한 작업에 이상적입니다.\n\n## Faiss:\n\nFacebook의 Faiss는 대규모 데이터셋에서의 유사성 검색에서 확장성과 속도로 유명합니다. 역 인덱스 및 제품 양자화와 같은 최첨단 인덱싱 기술을 활용하여, Faiss는 추천 시스템 및 멀티미디어 아카이브에서의 실시간 검색 및 분석 등을 요구하는 시나리오에서 뛰어난 성능을 발휘합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Milvus:\n\n밀부스는 질리즈가 개발한 오픈 소스 벡터 데이터베이스로, 방대한 양의 벡터 컬렉션을 효과적으로 관리하며 다양한 케이스에 맞는 인덱싱 전략을 제공합니다. GPU 가속 및 분산 컴퓨팅을 지원하여, 밀부스는 머신러닝 모델 관리, 산업용 IoT 배포에서의 고처리량 벡터 저장 및 검색을 필요로 하는 애플리케이션에 적합합니다.\n\n# Elasticsearch의 경쟁 우위: 비교 분석\n\n전문화된 벡터 검색 라이브러리 여러 개가 존재하지만, Elasticsearch는 벡터 데이터베이스 분야에서 독특한 장점을 제공하여 돋보입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Elasticsearch의 다재다능성:\n\nElasticsearch는 다른 백터 데이터베이스뿐만 아니라 강력한 검색 및 분석 플랫폼으로써 돋보입니다. 풍부한 쿼리 기능, 분산 아키텍처 및 AI 기술과의 원활한 통합을 통해 텍스트 및 벡터 기반 검색을 결합하는 응용프로그램에서 강력한 선택으로 인정받습니다. 많은 특수화된 벡터 검색 라이브러리와는 달리 Elasticsearch는 간단한 벡터 유사성 검색을 넘어 다양한 쿼리 유형, 필터 및 집계를 활용하는 풍부한 쿼리 환경을 제공합니다. Elasticsearch를 사용하면 사용자는 다양한 쿼리 유형, 필터 및 집계를 활용하여 복잡하고 미묘한 검색 작업을 수행할 수 있습니다.\n\n## 특수화된 사용 사례:\n\nElasticsearch는 다양한 사용 사례에 맞추어 제공되지만, ChromaDB, Faiss 및 Milvus와 같은 특수화된 벡터 데이터베이스는 특정 분야에서 뛰어난 성능을 발휘합니다. 실시간 검색을 필요로 하는 작업에서는 Faiss의 속도와 확장성이 탁월하며, ChromaDB는 색상 일치에 중점을 둔 다양한 멀티미디어 응용프로그램에서 필수적입니다. 반면 Milvus는 대규모 벡터 데이터셋을 효율적으로 관리해야 하는 시나리오에서 빛을 발하며, GPU 가속 및 분산 컴퓨팅을 활용하여 최적의 성능을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 확장성과 성능:\n\nElasticsearch의 분산 아키텍처는 대규모 데이터셋을 처리하기에 적합한 확장성과 내결함성을 보장합니다. 그러나 초고처리량 애플리케이션의 경우, Faiss와 Milvus는 GPU 가속화 및 분산 인덱싱과 같은 전문적인 최적화를 제공하여 특정 시나리오에서 우수한 성능을 발휘합니다.\n\n## AI 기술과의 원활한 통합:\n\nOpenAI의 GPT-3와 같은 AI 기술과 통합함으로써 Elasticsearch는 검색 및 분석 기능을 향상시킬 수 있는 탁월한 기회를 제공합니다. AI 기반 쿼리 이해, 콘텐츠 생성 및 문맥에 따른 추천 기능을 통해 Elasticsearch 사용자는 통찰력과 효율성의 새로운 차원을 열 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 벡터 검색의 역량을 발휘하는 Elasticsearch의 벡터 데이터베이스 기능\n\nElasticsearch가 전문 텍스트 검색 엔진에서 다양한 벡터 데이터베이스로 전환된 것은 dense_vector 데이터 유형과 script_score 기능과 같은 혁신적인 기능 덕분입니다. 이러한 기능은 사용자들이 벡터 검색의 모든 잠재력을 활용할 수 있게 하여 복잡한 데이터 환경을 쉽고 효율적으로 탐험할 수 있습니다.\n\n## dense_vector 데이터 유형 활용하기:\n\nElasticsearch의 dense_vector 데이터 유형은 고차원 벡터를 효율적으로 저장하는 데 특별히 설계되었습니다. dense_vector 데이터 유형을 활용하는 매핑을 정의함으로써 사용자들은 Elasticsearch 색인에 벡터 데이터를 신속하게 통합하여 다양한 고급 검색 및 분석 기능을 활용할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n{\n  \"properties\": {\n    \"text-vector\": {\n      \"type\": \"dense_vector\",\n      \"dims\": 512 // 벡터 내 차원 수\n    }\n  }\n}\n```\n\n예시 코드 구현:\n\n```js\nfrom elasticsearch import Elasticsearch\n# Elasticsearch 인스턴스에 연결\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n# dense_vector 데이터 유형을 사용하여 매핑 정의\nmapping = {\n    \"properties\": {\n        \"text-vector\": {\n            \"type\": \"dense_vector\",\n            \"dims\": 512\n        }\n    }\n}\n# 정의된 매핑으로 색인 생성\nes.indices.create(index='my_index', body={'mappings': mapping})\n```\n\n## script_score 함수 활용:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nElasticsearch의 script_score 함수를 사용하면 사용자가 특정 요구 사항에 따라 점수 매기는 알고리즘을 사용자 정의할 수 있어요. 이 기능을 활용하면 쿼리 벡터와 문서 벡터 간의 사용자 정의 유사성 점수를 계산하여 보다 세밀하고 문맥을 고려한 검색 경험을 제공할 수 있어요.\n\n아래는 Markdown 형식으로 테이블 태그를 변경한 예시 코드에요:\n\n```js\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\": {\n        \"match_all\": {}\n      },\n      \"script\": {\n        \"source\": \"dotProduct(params.queryVector, 'text-vector') + 1.0\",\n        \"params\": {\n          \"queryVector\": [0.1, 0.2, 0.3, ...] // Query vector\n        }\n      }\n    }\n  }\n}\n```\n\n예시 코드 실행:\n\n```js\nfrom elasticsearch import Elasticsearch\n# Elasticsearch 인스턴스에 연결\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n# 쿼리 벡터 정의\nquery_vector = [0.1, 0.2, 0.3, ...]  # 예시 쿼리 벡터\n# script_score 함수가 포함된 쿼리 본문 정의\nquery_body = {\n    \"query\": {\n        \"script_score\": {\n            \"query\": {\"match_all\": {},\n            \"script\": {\n                \"source\": \"dotProduct(params.queryVector, 'text-vector') + 1.0\",\n                \"params\": {\"queryVector\": query_vector}\n            }\n        }\n    }\n}\n# 검색 쿼리 실행\nres = es.search(index=\"my_index\", body=query_body)\nprint(res)\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Elasticsearch과 AI 통합: 새로운 가능성의 발현\n\nAI 기술을 Elasticsearch와 통합하면 사용자들이 데이터에서 더 깊은 통찰을 얻고 숨겨진 패턴을 발견할 수 있는 새로운 가능성이 열립니다.\n\n## 쿼리 이해를 위한 NLP 활용:\n\nElasticsearch와 자연어 처리(NLP) 모델을 결합하면 고급 쿼리 이해 기능을 활용할 수 있습니다. 사용자 쿼리의 의미론을 분석함으로써 Elasticsearch는 더 관련성 높은 검색 결과를 제공하고 사용자 경험을 향상시킬 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# elasticsearch과 transformers 패키지를 import합니다\nfrom elasticsearch import Elasticsearch\nfrom transformers import pipeline\n\n# Elasticsearch 인스턴스에 연결합니다\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n\n# 질문-답변 파이프라인을 정의합니다\nnlp = pipeline(\"question-answering\")\n\n# 사용자 질의를 정의합니다\nuser_query = \"Elasticsearch에서 벡터 검색의 이점은 무엇인가요?\"\n\n# 사용자 질의에서 관련 키워드를 추출합니다\nkeywords = nlp(user_query)[\"answer\"].split()\n\n# 키워드 매칭을 사용한 Elasticsearch 쿼리를 정의합니다\nquery_body = {\n    \"query\": {\n        \"match\": {\n            \"content\": \" \".join(keywords)\n        }\n    }\n}\n\n# 검색 쿼리를 실행합니다\nres = es.search(index=\"my_index\", body=query_body)\nprint(res)\n```\n\n## AI 기반 콘텐츠 생성 및 요약:\n\nAI 모델을 활용하여 콘텐츠 생성 및 요약은 Elasticsearch의 지식 추출 능력을 향상시킵니다. 문서의 요약을 자동으로 생성하거나 사용자 쿼리를 기반으로 새로운 콘텐츠를 생성함으로써, Elasticsearch는 정보 검색 및 의사 결정 프로세스를 용이하게 합니다.\n\n```python\n# elasticsearch과 transformers 패키지를 import합니다\nfrom elasticsearch import Elasticsearch\nfrom transformers import pipeline\n\n# Elasticsearch 인스턴스에 연결합니다\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n\n# 텍스트 요약을 위한 NLP 파이프라인을 정의합니다\nsummarizer = pipeline(\"summarization\")\n\n# Elasticsearch로부터 문서 내용을 검색합니다\ndoc_content = \"Elasticsearch로부터 추출한 샘플 문서 내용...\"\n# AI 모델을 사용하여 요약 생성합니다\nsummary = summarizer(doc_content, max_length=100, min_length=30, do_sample=False)\n# 생성된 요약을 Elasticsearch에 색인합니다\nes.index(index=\"my_index\", body={\"summary\": summary[0][\"summary_text\"]})\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Context-Aware Recommendations with ML:\n\n머신러닝 알고리즘은 사용자의 행동과 선호도를 분석하여 컨텍스트에 맞는 추천을 생성할 수 있습니다. ML 모델을 Elasticsearch와 통합함으로써 조직은 사용자 상호작용과 과거 데이터에 기반한 개인화된 추천을 제공할 수 있습니다.\n\n```python\nfrom elasticsearch import Elasticsearch\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Elasticsearch 인스턴스에 연결\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n\n# Elasticsearch에서 사용자 프로필 데이터 검색\nuser_profile = {\n    \"user_id\": \"123\",\n    \"interests\": [\"data science\", \"machine learning\", \"natural language processing\"]\n}\n\n# 사용자 관심사에 관련된 문서 검색\nquery_body = {\n    \"query\": {\n        \"terms\": {\n            \"content\": user_profile[\"interests\"]\n        }\n    }\n}\nres = es.search(index=\"my_index\", body=query_body)\n\n# 관련 문서 추출 및 유사도 점수 계산\ndocuments = [hit[\"_source\"][\"content\"] for hit in res[\"hits\"][\"hits\"]]\ntfidf_vectorizer = TfidfVectorizer()\ntfidf_matrix = tfidf_vectorizer.fit_transform(documents)\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n\n# 유사도 점수에 기반한 문서 추천\nsimilar_indices = cosine_similarities.argsort()[:, ::-1]\nrecommended_documents = [documents[i] for i in similar_indices[0][:5]]\nprint(recommended_documents)\n```\n\n# 결론: 검색과 분석의 미래를 선도하다\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n엘라스틱서치의 다양한 벡터 데이터베이스로의 진화는 AI 통합과 결합되어 검색 및 분석 분야에서 패러다임 전환을 이루었습니다. 강력한 기능, 포괄적인 쿼리 기능, 그리고 AI 기술과의 원활한 통합을 통해 엘라스틱서치는 사용자들에게 전례 없는 정밀성과 효율성으로 복잡한 데이터 환경을 탐색할 수 있는 능력을 부여합니다. 조직이 벡터 데이터베이스와 AI 기반 통찰력의 잠재력을 받아들이는 가운데, 엘라스틱서치는 검색 및 분석 분야의 미래를 개척하며 선두에 서 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration_0.png"},"coverImage":"/assets/img/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration_0.png","tag":["Tech"],"readingTime":12},{"title":"인과 검증 만병 통치제","description":"","date":"2024-05-17 19:57","slug":"2024-05-17-CausalValidationAUnifiedTheoryofEverything","content":"\n![Causal Inference](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_0.png)\n\n# 소개\n\n인과 추론은 머신 러닝 내에서 부상 중인 분야로, 무엇이 발생할 수 있는지 예측하는 것을 넘어 그 이유를 설명하고, 그로 인해 문제의 근본적인 해결책을 제시함으로써 잠재적인 파급효과를 다루는 대신 지속적으로 해결책을 제공합니다.\n\n인과 모형의 주요 구성 요소 중 하나는 변수와 사건 간의 인과 관계를 간단한 시각적 형식으로 포착하는 \"유향 비순환 그래프\" (DAG)입니다. 그러나 DAG의 주요 문제점은 일반적으로 도메인 전문가에 의해 주관적으로 구성된다는 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n따라서 DAG가 정확하다는 보장이 없습니다. 만약 DAG가 부정확하다면 인과 추론 모델의 연산과 결론이 잘못될 수 있습니다.\n\n인과 유효성은 DAG를 기반 데이터와 비교하여 오류나 모순을 식별하고 수정하는 과정을 설명하는 용어입니다. 이 작업을 신뢰성 있게 수행할 경우 인과 추론의 결론 및 관련 조치와 변경 사항이 개선된 영향과 결과로 이어질 것입니다.\n\n## 문제점\n\nDAG가 \"잘못\" 되는 여러 가지 방법이 있습니다. 인과 관련 문헌에서 다양한 유형의 오류에 대한 참조를 찾을 수 있지만, 인과 유효성을 종합적으로 다루는 방법에 대해 많은 정보가 없습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 기회\n\n만약 DAG(Directed Acyclic Graph)에서 모든 종류의 오류를 찾아 수정할 수 있는 통합적인 인과 유효성 알고리즘이 개발된다면, 영역 전문가의 주관적인 지식에 의존을 줄이고 인과 추론 모델의 신뢰성을 크게 향상시킬 수 있을 것입니다.\n\n## 계획 수립\n\n다른 종류의 DAG 오류에 대한 개별 알고리즘을 결합, 통합 및 테스트하여 인과 유효성을 위한 통합 이론을 만들 수 있는 방법에 대해 고민해 보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 배경\n\n다른 머신 러닝 문제와 마찬가지로 인과 추론 프로젝트는 기능 세트로 구성된 데이터로 시작됩니다…\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_1.png)\n\n인과 추론 모델의 목적은 모든 다른 변수의 효과가 고려되고 조정된 상태에서 치료(일반적으로 \"X\"로 레이블링)의 실제 효과를 결과(일반적으로 \"Y\"로 레이블링)에 수립하는 것이며, 시작점은 전문가들이 인과 관계에 대한 주관적 이해를 포착하기 위해 유향 비순환 그래프를 만드는 것입니다…\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Causal Validation Example](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_2.png)\n\n통합 인과 유효성 탐구를위한 가정의 예제로는 현실 세계에서의 의미가 없는 X, Z1, Z3 등의 노드 이름을 포함한 다양한 유형의 인과 관계가 포함 된 충분히 간단한 예제가 선택되었습니다.\n\n그러나 이해를 돕기 위해 X가 새 약 복용 수준을 나타낼 수 있고, W는 환자의 혈압에 미치는 약의 영향을 나타낼 수 있으며, Y는 환자 회복에 대한 영향을 나타낼 수 있습니다.\n\n이 예에서 화살표의 방향이 의미가 있습니다. 명백히 약을 복용하는 것은 혈압에 변화를 일으킬 수 있지만 그 반대는 아니며, 혈압의 변화가 환자 결과에 변화를 일으키는 경우도 마찬가지입니다. 그 반대는 매우 그럴듯하지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예시의 이 단계에서는 데이터가 캡처되었고 제안된 관계를 나타내는 DAG가 구성되었습니다.\n\n이것은 인과 유효성을 설명하기 위해 디자인된 테스트 케이스이므로 DAG는 정확합니다. DAG와 데이터가 함께 가짜로 생성되었기 때문에 확실합니다. 그러나 만약 이것이 현실 세계의 문제였다면 어떨까요?\n\n도메인 전문가들이 잘못된 다른 DAG를 만들었다면 어떤 종류의 실수를 저질렀을까요?\n\n## 누락된 엣지 오류\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 유형의 오류는 빠진 링크나 엣지입니다 (링크와 엣지는 상호 교환 가능한 용어로 동일한 의미를 가지며, 한 노드/기능과 다른 노드/기능 간의 연결을 의미합니다).\n\n도메인 전문가들이 실제로 데이터에 존재하는 몇 가지 엣지를 완전히 누락할 수 있습니다. 예를 들어, 데이터와 현실 세계 사이에 Z3와 Y 간의 인과 관계 링크가 존재할 수 있지만 DAG에는 반영되지 않은 경우 …\n\n![image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_3.png)\n\n이 예시에서 DAG에는 누락된 엣지 오류가 포함되어 있으며, 데이터에 존재하는 엣지나 링크가 DAG에서 누락되면 인과 모델의 모든 계산과 결론이 잘못될 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 잘못된 엣지 오류\n\n두 번째 유형의 오류는 가짜 엣지입니다. 즉, DAG에서 실제로 존재하지 않는 엣지가 식별되고 나타납니다.\n\n예를 들어, 도메인 전문가들이 Z1과 W 사이에 인과 관계가 있다고 제안했지만, DAG에 이 연결이 만들어졌지만 실제 데이터에는 존재하지 않을 수 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 데이터에는 존재하지 않지만 DAG에서 실제로 존재하지 않는 추가적인 인과 관계 링크가 식별되면, 인과 관계 계산 결과를 햇살이다는 결론을 내리는데 오류를 유발할 수 있습니다.\n\n## 역방향 엣지 오류\n\n마지막 오류 유형은 역방향 엣지 오류입니다. 즉, 전문가들이 두 기능 간의 관련을 정확하게 식별했지만 방향성을 잘못 이해한 경우입니다.\n\n예를 들어, 전문가들이 X와 Z3 사이에 인과 관계 링크를 제안했지만 실제 엣지 / 링크는 Z3에서 X로의 반대 방향에 있을 수 있습니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_5.png)\n\nDAG에서 실제 인과관계의 방향과 반대 방향에 있는 가장류가 원인을 계산하면 잘못된 답변도 나올 수 있습니다.\n\n# 인과 관계 유효성 검사 — 가장류 오류 감지 및 수정\n\n첫 번째 단계는 DAG에 어떤 유형의 오류가 존재하는지 이해하는 것입니다. 위에서 설명한 것처럼, 오류가 총 3가지 유형이 존재합니다 — 누락된 가장류, 부적절한 가장류 및 반전된 가장류입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 외 카테고리나 에러 유형이 없으므로 각각의 3가지 유형에 대한 인과 검증의 해결은 인과 검증을 위한 모든 것에 대한 통일된 이론으로 이어져야 합니다.\n\n## 독립과 의존의 중요성\n\n독립과 그 반대인 의존의 중요성이 DAG의 모든 3가지 유형의 오류를 감지하고 수정하는 데 중요하다는 것이 밝혀졌습니다.\n\n독립에 대한 공식적인 정의 제안 중 하나는 다음과 같습니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그리고 이것은 초기 DAG에 적용될 수 있습니다(오류가 없는 것이며 데이터를 정확하게 대표한다고 가정합니다)...\n\n![Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_6.png)\n\nDAG로부터 명백하게 알 수 있듯이, 노드 Z1과 Z2(데이터에서의 특성 Z1과 Z2)는 연결되어 있지 않습니다.\n\nZ1의 값이 변경되더라도 Z2의 값은 변경되지 않을 것이며, 그들 사이에는 직간접적인 연결이 없기 때문입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 경우 Z2는 Z1과 독립되었다고 합니다. 이는 다음 식으로 나타낼 수 있습니다 (⫫ 기호는 \"더블 업택\"으로 불립니다) -\n\n![Expression](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_7.png)\n\nZ2가 Z1과 독립적인 개념은 데이터의 행에서 Z1과 Z2의 사례를 산점도로 나타내고 산점의 관계 값을 나타내는 차트에 선을 추가하여 시각화하고 이해할 수 있습니다...\n\n![Scatter Plot](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nZ1과 Z2 사이에는 상관 관계가 없음을 쉽게 알 수 있습니다. 계수는 0.03이며(거의 0에 가깝습니다), Z1을 1, 2 또는 4 증가시키더라도 Z2가 증가하지 않음을 알 수 있습니다. 왜냐하면 선의 계수가 거의 평평하기 때문입니다.\n\n뿐만 아니라 산점도의 점들의 패턴은 직선이 아닌 구름 형태이며, 이것들은 모두 Z2가 Z1과 독립적임을 보여줍니다.\n\nZ2가 Z1과 독립적이지만, DAG에서 반대로 상관 관계에 있는 다른 경우도 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_9.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nW가 X에 의존한다는 것은 직관적으로 명백합니다. 이는 X의 값이 변함에 따라 W가 변화한다는 것을 의미합니다. 이를 다음 표현으로 나타낼 수 있습니다(⫫̸ 기호는 \"슬래시된 두 번의 업택\"이라고 합니다)...\n\n![표 1](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_10.png)\n\n독립변수와 마찬가지로, 의존성 개념을 이해하는 데는 데이터의 특성 간 관계를 시각화하는 산점도가 도움이 될 수 있습니다...\n\n![표 2](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_11.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 경우 X와 Y 사이에 관계가 있는 것이 명백하게 보입니다. X 값을 20, 40 또는 60 증가시키면 Y 값도 명확하게 증가하고 산점점을 가장 잘 표현하는 직선의 계수는 6.77입니다. 따라서 X 값을 1 증가시키면 Y 값이 6.77 증가합니다.\n\n독립성 예제와는 달리, 이번에는 산점점들이 구름이 아니라 선을 형성하고 있어 서로에 의한지의 징표입니다.\n\n독립성과 의존성에 대한 자세한 탐구는 본 문서의 범위를 벗어나지만, 관심이 있고 pandas의 DataFrame 객체에 확장 기능을 추가하여 어떤 독립성 표현식을 쉽게 계산할 수 있는 방법을 배우고 싶다면 이 문서를 확인해보세요.\n\n## 누락된 엣지 오류 탐지\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n링크 누락 오류는 원인 인과 문헌과 온라인에서 여러 곳에서 추적할 수 있는 알고리즘을 사용하여 탐지됩니다. 이 알고리즘은 독립성에 기반한 것인데요…\n\n다음에 나오는 DAG를 고려하여 설명할 수 있습니다. 여기에는 오류가 있는데요 — Z3에서 Y로의 링크가 누락되어 있습니다. 데이터가 합성적으로 생성되었기 때문에 데이터에 해당 링크가 존재하는 것으로 알려져 있습니다…\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_12.png)\n\n누락된 링크 유효성 검사 알고리즘은 독립성 테스트를 수행하는 모든 노드를 반복합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어, 알고리즘이 노드 Y에 도달하면 \"노드는 부모에 의존할 때 조건부로 이전 노드와 독립적임\"이라는 문장은 Y가 부모인 노드 W와 Z2에 의존할 때 Y가 이전 노드 X, Z1 및 Z3과 (Y의 이전 노드) 독립적이라는 것을 의미합니다.\n\n이 문장은 위에서 설명한 독립성 표기를 사용하여 다음과 같은 표현으로 단순화될 수 있습니다...\n\n![image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_13.png)\n\n한 단계 더 나아가 표현은 완전한 형태로 확장될 수 있는데, 이는 그래프에서 Y가 X, Z1, Z3에 대해 W, Z2가 주어졌을 때 독립이라는 것을 요약하는 문장 Y가 데이터에서 W, Z2가 주어졌을 때 X, Z1, Z3과 독립이라는 것을 나타냅니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Table 14](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_14.png)\n\nThis condition can then be tested using the `.dependence()` extension method of the DataFrame class that was introduced in the section above ...\n\n![Table 15](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_15.png)\n\nThe results show that node Y is independent of nodes X and Z1 but Y is not independent of Z3 because the co-efficient for Z3 in the regression is 3.5012 and the p-value is 0.000.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이것은 노드 Y에 대한 독립성 테스트가 DAG에 오류가 있는 것을 보여준 것뿐만 아니라 그 오류가 정확히 어디에 있는지, 즉 데이터에서 Z3와 Y 사이에 의존 관계가 있어 DAG에 추가해야 한다는 것을 보여준 것을 의미합니다.\n\n이제 DAG를 다음과 같이 \"고치\" 수 있습니다...\n\n![그림](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_16.png)\n\n전문가들이 제안한 DAG에 누락된 링크 오류가 있는 것으로 확인된 DAG는 원치 않는 유효성이 인식되어 Causal Validation을 사용하여 고쳐졌습니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이렇게 독립성을 사용하여 누락된 링크를 감지하는 방법을 간략히 살펴보았습니다. 자세하고 상세한 설명은 다음 기사를 참조해 주세요...\n\n## 잘못된 가장자리 오류 감지\n\n인과 유효성을 연구해온 여러 달 동안 문헌에서 이상한 링크 오류를 탐구하는 사례나 이 유형의 오류를 해결하기 위한 알고리즘 제안 중 단 하나도 찾지 못했습니다.\n\n사실, 나는 정확히 3종류의 오류가 있다고 주장하는 자료를 찾은 적이 없었기 때문에 가능한 오류 종류 및 잘못된 링크에 대한 제안된 알고리즘에 관한 결론은 제가 직접 조사하고 Python 코드를 사용하여 수많은 시행착오를 거쳐 얻은 결과입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n스풀러스 링크 알고리즘에 대한 아이디어가 떠올랐습니다. 빠진 링크 알고리즘을 파이썬으로 구현하는 과정에서 모든 오류를 \"고치는\" 데 충분한지 고민하며 도출되었습니다. 인과 유효성에 대한 통합 이론이 아직 멀리 떨어져 있지만, 스풀러스 링크 알고리즘은 상대적으로 직관적입니다.\n\n빠진 링크의 알고리즘을 수정하여 다음과 같은 명제에 도달했습니다...\n\n\"노드는 부모에 의존합니다.\"\n\n다음은 스풀러스 링크 오류(즉, DAG에 나타나지만 데이터에는 존재하지 않는 링크)가 의도적으로 도입된 예시 DAG입니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Causal Validation](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_17.png)\n\n이전 테스트와 마찬가지로, 의심 알고리즘 테스트는 모든 노드를 반복하면서, 이번에는 빠진 링크에 대한 독립성 테스트 대신 의존성 테스트를 진행합니다.\n\n알고리즘이 노드 W에 도달할 때 W가 그래프에서 X와 Z3(부모 노드)에 의존한다는 문장은 W가 데이터에서 X와 Z3에 의존한다는 것을 의미합니다...\n\n![Causal Validation](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_18.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다시 이 조건은 DataFrame 클래스의 .dependence() 확장 메서드를 사용하여 테스트할 수 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_19.png)\n\n결과에서 노드 W는 노드 X에 의존하지만 Z3에 대해 의존하지 않음을 보여줍니다. 이는 회귀에서 Z3에 대한 계수가 -0.1580(작음)이며 p-값이 0.566(0이 아님)임을 나타냅니다.\n\n이는 노드 W에 대한 의존성 테스트가 DAG에 오류가 있음을 보여주고 Z3로부터 W로의 잘못된 링크가 제거되어야한다는 것을 보여주었음을 의미합니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Image 1](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_20.png)\n\n## Detecting Reversed Edge Errors\n\nA solution to detecting reversed link errors eluded me for a long time and initially I thought it was impossible to solve because if the co-efficient between Z3 and X (for example) where 2.5 then the co-efficient between X and Z3 is the inverse …\n\n![Image 2](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_21.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n... 그리고 이 중 어떤 것이 방향성과 인과 관계를 함축하는지 알아내려면 어떻게 해야 할까요?\n\n이용 가능한 인과 관계 문헌과 온라인 기사에는 일부 단서와 징후가 있지만 포괄적이고 완전한 것은 없습니다. 제 연구를 통해 다음과 같은 결론과 해결책이 도출되었습니다...\n\n모든 DAG에는 처리 항목(X)과 결과 항목(Y)이 있으며 적어도 하나의 전방 경로(처리 항목에서 결과 항목까지의 DAG 경로)가 있습니다. 또한 추가적인 노드와 추가적인 링크가 있을 수 있지만, DAG는 비순환적이어야 합니다. 어떤 노드도 고아가 되어서는 안 됩니다.\n\n다양한 경로는 시작, 중간 및 끝 노드로 구성된 낮은 수준 단위인 점들로 분해할 수 있습니다. 이들은 정확히 2개의 링크를 가진 Chain(체인), Fork(포크) 및 Collider(충돌체)와 같이 3가지 유형의 점이 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 3가지 타입 중에서 콜라이더는 의존성 테스트를 사용하여 감지할 수 있기 때문에 중요합니다. 한편, 체인과 포크는 정확히 동일한 결과 집합을 생성하므로 둘을 구별할 수 없습니다.\n\n아래 내용으로 요약할 수 있습니다 ...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_22.png)\n\n... 위 내용은 다음과 같습니다 ...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 충돌체 Y(결과)는 X(치료)와는 독립적입니다.\n- 연결 또는 포크의 경우 Y(결과)는 X(치료)에 따라 달라집니다.\n\n대부분의 문헌에서는 여기서 멈추지만, 한 단계 더 나아갈 수 있습니다. 충돌체에서 Y는 X와 독립적이지만 X와 Y 사이에 직접적이거나 간접적인 연결이 없는 경우에만 그렇습니다. 연결이 있으면 X의 “메시지”나 변경 사항이 Y의 변화를 일으켜 다시 종속적으로 만듭니다.\n\n이로 인해 \"v-구조\"라는 충돌체 하위 집합이 생기는데, 여기서 시작 노드와 끝 노드가 연결되어 있지 않은 단순한 충돌체입니다. 이 예시 DAG에 존재하는 모든 충돌체를 고려함으로써 쉽게 시각화할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n5개의 충돌체가 있지만 두 개는 시작 노드와 끝 노드 사이에 직접적인 연결이 있습니다 (Z3 -`Y `- Z2 및 `- Z1 -` X `- Z2), 이를 \"인접\"이라고 합니다.\n\n\"인접\" 충돌체를 제거하면 예시 DAG에서 3개의 v-구조를 시각화할 수 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_24.png)\n\n3개의 v-구조는 다음과 같이 대체적으로 표현될 수 있습니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- W -`Y`- Z2\n- W -`Y`- Z3\n- Z1 -`Z3`- Z2\n\n시간을 내어 V-구조를 이해하는 이유는 해당 데이터에서 감지할 수 있으며, 이것을 기반으로한 알고리즘을 구성하여 링크의 방향성을 나타내고 따라서 반전을 탐지할 수 있게 됩니다. 이 알고리즘의 의사 코드는 다음과 같습니다.\n\n- DAG(Directed Acyclic Graph)의 모든 엣지 주위를 반복하며 각 엣지에 대해...\n- 현재 엣지를 뒤집어 새로운 DAG를 만듭니다.\n- 만약 V-구조가 파괴되고 해당 V-구조가 데이터에 존재하지 않는다면, 현재 DAG가 잘못되었고 엣지를 뒤집어야 합니다.\n\n- 엣지 뒤집기로 파괴된 DAG 내의 각 V-구조마다 이 종속성 테스트를 실행합니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_25.png\" />\n\n- 만약 이 테스트가 통과된다면, 현재 테스트 중인 엣지가 DAG에서 잘못되었고 뒤집어져야 한다는 것을 의미합니다.\n\n- 만약 v-구조가 생성되었거나 데이터에 해당 v-구조가 존재한다면 현재 DAG가 잘못되었고 엣지를 뒤집어야 합니다.\n\n- 엣지를 뒤집음으로써 DAG에서 생성된 각 v-구조에 대해 이 종속성 테스트를 실행합니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_26.png)\n\n- 이 테스트가 실패하면 현재 테스트 중인 엣지가 DAG(Directed Acyclic Graph)에서 잘못되었고 반전되어야 함을 나타냅니다.\n\nPython에서 DataFrame .dependency() 확장 메서드를 사용하여 이 알고리즘을 구현하면 반대로 링크된 부분을 감지하고 수정할 수 있습니다.\n\n예를 들어, 엣지/연결을 반전하려고 테스트할 때, 현재 테스트를 선택한 엣지가 Z1 -` Z3인 경우 다음 단계가 수행됩니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Z1을 Z3으로 뒤집으면 DAG에서 정확히 하나의 v-structure이 파괴됩니다 (Z1 -`Z3`- Z2)\n- 그런 다음 의존성 테스트를 데이터에 대해 다음과 같이 수행할 수 있습니다...\n\n![image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_27.png)\n\n결과는 Z2가 데이터에서 Z1에 의존하지 않는다는 것을 보여줍니다. 왜냐하면 계수가 매우 작기 때문이고 (-0.0253), p-값이 0이 아닙니다 (0.485).\n\n의존성 테스트는 통과되지 않았습니다 (즉, True를 반환하지 않았습니다). 따라서 Z1 -` Z3가 DAG에서 올바른 방향성을 가지고 있으며 뒤집어서는 안 됨을 추론할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 단계 1-4가 DAG(유향 비순환 그래프)의 각 엣지/링크에 반복적으로 적용된다면 모든 엣지의 방향성 및 전체 DAG의 유효성을 확인할 수 있습니다.\n\n더 자세한 내용을 알고 싶다면, 이 글에는 더 많은 코드 샘플이 포함된 v-구조에 대한 자세한 설명이 있습니다...\n\n## 누락된, 가짜 및 역방향 링크 오류 결합\n\n이전 섹션에서 DAG(유향 비순환 그래프)에는 누락된 엣지, 가짜 엣지 및 역방향 엣지라는 정확히 3가지 유형의 오류가 있음을 보여주었으며, 의존성 테스트가 어떻게 구현되는지를 보여주었으며, 파이썬에서 이 3가지 유형을 모두 탐지하는 방법을 보여주었습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이론적으로는 원인 규명을 위한 \"모든 것의 통합 이론\"을 순차적으로 결합하여 달성할 수 있습니다. 그래서 다음과 같은 통합 원인 규명 알고리즘을 제안하여 시작해 봅시다...\n\n- 누락된 엣지 오류를 검사합니다.\n- 잘못된 엣지 오류를 검사합니다.\n- 역으로 연결된 엣지 오류를 검사합니다.\n\n직관적으로 이 알고리즘이 작동해야 하지만 실제로 구현되고 견고하게 테스트되었을 때 일관적으로 실패하며 그 이유는 다음과 같습니다.\n\n시작하기 전에 DAG에 오류가 포함되어 있다고 가정해 봅시다 — Z2와 Z3 노드 사이에 누락된 엣지가 있는 경우...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_28.png)\n\nThe first step, which is testing for missing edges, will identify the missing edge. However, in step 3, the directionality of the v-structure at Z1 -`Z3`- Z2 cannot be tested because it does not exist due to the missing edge.\n\nThis issue can be easily resolved by updating the unified algorithm as follows:\n\n- Test for any Missing Edge Errors\n- Note any errors found and correct them\n- Test for Spurious Edge Errors\n- Note any errors found and correct them\n- Test for and Fix Reversed Edge Errors\n- Note any errors found\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 문제가 해결되었습니다. 단계 1은 Z2 - Z3 사이에 누락된 엣지를 복원하고, 그 후 단계 3에서의 반전 사항이 올바르게 테스트될 것입니다. 하지만 더 심각한 문제가 있습니다.\n\n이제 DAG에 다른 오류가 있다고 가정해 봅시다. 이 예제에서는 X와 W 사이의 엣지가 잘못된 방향을 가지고 있고 역전되어 있습니다...\n\nStep 1에서 누락된 링크를 테스트하는 과정은 \"노드가 부모에 조건을 붙여 조건이 부모에게 독립적일 때\"라는 조건을 실행하며 모든 노드를 반복합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 DAG가 정확하다면(X와 W 사이의 엣지가 X → W로 변경된다면) 이 조건은 다음과 같이 해결됩니다...\n\n<img src=\"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_30.png\" />\n\n그러나 이 DAG에 오류가 포함되어 있기 때문에 X가 더 이상 W의 상위 요소가 아닙니다(사실상 W가 이제 X의 상위 요소가 됩니다). 이것은 선행자인 Z1, Z2, Z3와 W 사이의 누락된 링크가 감지되지 않으며 심지어 새로운 부모 및 선행자 집합을 기반으로 반복에서 모든 노드에 대해 실행되는 누락된 링크 테스트 집합이 모두 완전히 잘못될 것입니다.\n\n특정 경우에는 순차 테스트의 순서를 변경하여 역방향 엣지 오류를 식별하고 수정한 후에 누락된 및 잘못된 엣지 테스트를 수행함으로써 만족스러운 결과를 얻을 수 있습니다. 그러나 이는 테스트에서 오류의 사전 지식, 즉 단일 역방향 엣지가 테스트를 생성하는 방법이기 때문에 가능합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실제 세계의 인과 추론 문제에서 데이터 팀은 완전히 알지 못할 것입니다...\n\n- DAG에 오류가 있는지 여부 및...\n- 오류의 종류(결여, 가짜 또는 반전)를 구별할 수 없을 것입니다.\n\n예를 들어 한 DAG에는 하나의 가짜 엣지 오류가 있을 수 있고 다른 DAG에는 결여 엣지와 반전 엣지가 있는 등 다양한 오류가 있을 수 있습니다.\n\n이는 순차적 테스트의 순서를 변경하여 인과 관계 유효성을 위한 통합 이론을 제시하는 시도를 무효화합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다른 해결책을 찾아야 합니다.\n\n# 인과 유효성을 위한 제안된 모든 것의 통합 이론\n\n내 연구에 있어서 나는 인과 유효성을 위한 모든 것의 통합 이론에 대해 포기할 뻔했습니다.\n\n저는 각각의 3가지 유형의 오류를 성공적으로 감지하기 위한 알고리즘을 개발했는데, 이는 해당 알고리즘이 일치하는 유형의 오류만이 있고 다른 오류는 없는 경우에만 사용할 수 있는 신뢰성이 있는 기능을 수행했습니다. 실제로 이것은 쓸모가 없습니다. 왜냐하면 사전에 오류가 무엇인지 알 수 없기 때문입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n순차 알고리즘의 실패로, 재귀적인 해결책이 동작할 수 있을 것이라 의심하기 시작했습니다. 나는 프로그래밍에서 재귀를 항상 좋아해왔어; 그것은 우아하게 간단하면서도 악랄하게 복잡한데 동시에 한번 복잡성을 이해하고 나면, 수십 줄의 비재귀 코드로 해결되기 어려운 문제들을 몇 줄의 우아한 코드로 해결할 수 있는 특정한 종류가 있습니다.\n\n프로그래밍에서의 재귀는 간단히 말해 자기 자신을 호출하는 함수를 의미합니다. 다른 함수를 호출하는 함수를 작성하는 것은 아주 흔하지만, 함수가 다시 자기 자신을 호출하는 것은 그렇게 흔하지 않죠.\n\n재귀적 해결책은 종종 나무 구조(가계도와 같은)를 탐색, 구문 분석 또는 수정하는 알고리즘에서 사용됩니다. 그것들을 이해하는 가장 좋은 방법은 자신에게 다시 호출하는 것을 새로운 함수를 호출하는 것으로 보는 것입니다.\n\n만약에 그것이 여전히 잘 이해되지 않는다면, 재귀 함수를 디버깅하고 모든 호출을 하나씩 따라가면 이해하고 구현하는 데 도움이 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이것이 인과 유효성을 위한 제안된 모든 것의 통합 이론에 대한 의사 코드입니다...\n\nfix_dag(DAG):\n\n- 만약 DAG가 유효하거나 재귀 호출의 최대 횟수에 도달했을 경우 재귀를 중단하고 DAG를 반환합니다.\n- 누락된 엣지가 발견되면 그것을 수정하고 fix_dag(FIXED_DAG)를 호출합니다.\n- 잘못된 엣지가 발견되면 그것을 수정하고 fix_dag(FIXED_DAG)를 호출합니다.\n- 역으로 뒤집힌 엣지가 발견되면 그것을 수정하고 fix_dag(FIXED_DAG)를 호출합니다.\n\n첫눈에 보기에는 이 순차 알고리즘과 거의 동일해 보이지만 매우 다릅니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테스트의 순서에 더 이상 의존하지 않습니다. 순환 내에 순서가 있더라도, 재귀 알고리즘은 계속해서 고침을 시도하고 \"고친\" DAG가 유효한지를 평가할 것입니다. 이렇게 변경이 축적되어 유효한 DAG를 얻게 됩니다(또는 재귀의 최대 횟수에 도달하게 됩니다).\n\n원래 DAG의 오류는 최종으로 고쳐진 DAG와 비교하여 차이점을 식별하는 것으로 유추할 수 있습니다.\n\n## 통합 이론을 위한 Python 코드\n\n백그라운드에서 실행되는 코드의 전부를 보여주는 것은 현실적이지 않습니다. 그러나 아래에 알고리즘을 구현한 fix_dag와 difference 코드가 있습니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 통합 이론 테스트\n\n제안된 알고리즘을 파괴하기 전에 고려해야 할 문제가 하나 더 있습니다.\n\n3가지 유형의 오류와 각각의 탐지 알고리즘을 탐구한 이전 기사들은 \"힌트\"를 제공하는 증거를 제공했습니다.\n\n힌트는 DAG 내의 특정 엣지가 정확하다는 것을 알고리즘에 전달하는 어설션으로, 알고리즘에 해당 엣지를 확인하지 않도록 지시합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3가지 유형의 테스트 운영에 있어서 힌트 제공은 중요하다는 것이 밝혀졌습니다. 실제로는 확인 및 테스트를 통해 구분할 수 없는 다양한 DAG(Directed Acyclic Graph)가 존재할 수 있기 때문입니다.\n\n인과 문헌에서는 구분할 수 없는 DAG 집합을 \"동등 클래스\"로 참조하며 유일한 방어 수단은 동등한 클래스를 검색 공간에서 제거하기 위해 충분한 힌트를 제공하는 것입니다.\n\n힌트의 또 다른 장점은 확인해야 하는 순열을 대폭 줄여준다는 것입니다.\n\n역방향 엣지 알고리즘의 일부인 부분은 유효한 DAG를 식별하기 위해 모든 역방향 엣지 조합을 탐색합니다. 11개의 엣지가 있는 경우 탐색 공간은 2의 11제곱 = 2048이지만 엣지 수를 1개만 늘리면 2의 12제곱 = 4096이 되는 식입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n파이썬은 해석형 언어이며 모서리의 수가 늘어날수록 성능이 기하급수적으로 저하되므로, 힌팅 엣지를 사용하면 처리 시간을 크게 줄일 수 있습니다.\n\n## 예제 테스트 DAG에서의 힌팅 엣지\n\nDAG에 관련된 몇 가지 원칙들이 힌팅 엣지 집합을 개발하는 데 도움이 됩니다.\n\n먼저, DAG를 순환적으로 만들 수 있는 모든 엣지는 정의상 제외되어야 하며, 순환 DAG를 유발할 가능성이 있는 변경 집합을 테스트하지 않는 것이 최상의 접근 방식입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n병리와 효과의 성질에서 단서가 있습니다. 일반적으로 경로는 치료에서 효과로 흐르며, 정의상 효과는 사건을 일으키지 않아야 합니다. 따라서 가장자리는 효과 노드로 흐르고 반대 방향으로 흐르면 안 됩니다. 이에 몇 가지 예외 사항이 있지만, 이것은 좋은 팁이며 마찬가지로 인과 관계와 따라서 가장자리는 치료에서 멀어져야 합니다.\n\n더 나아가서 외생 노드를 고려함으로써 추가적인 단서를 얻을 수 있습니다. 우리 예시에서는 Z1과 Z2가 외생노드입니다. 외생 노드는 DAG와 인과 관계 모델의 \"입력\"이며 다른 모든 노드는 보이지 않는 일련의 구조 방정식으로부터 구축됩니다(예: Z3 = 3 xZ1 + 1.5 x Z2+ ε).\n\n외생 노드와 변수의 식별이 잘못될 수 있지만, 데이터와 도메인 전문가는 DAG와 모델의 입력 변수가 무엇인지 모를 가능성이 매우 낮습니다.\n\n따라서 인과 관계와 가장자리가 외생 변수/노드에서 멀어지는 것이 매우 가능합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로 추적성 개념이 있습니다. 예를 들어 DAG에서 X가 W를 일으키고 W가 Y를 일으킨다고 가정해 봅시다. 만약 X가 약물이라면, W가 혈압이고 Y가 환자 결과라고 한다면, 약물이 직접적으로 환자 결과를 일으키하는 것은 불가능합니다.\n\n약물이 보통 환자들의 어떤 부분을 변경하고, 그 결과로 환자 결과를 개선시킵니다. 도메인 전문가가 Z2 -` Z3 -` X와 같이 어떤 추이적인 인과 관계를 식별했다면, Z2가 X를 직접 일으키는 것은 불가능합니다. Z2, Z3, X가 무엇을 나타내든 간에 그렇습니다.\n\n요약하면, 이러한 특성들은 힌트를 식별하는 데 도움이 되는 단서를 제공할 수 있습니다...\n\n- 비순환성\n- 외생성\n- 추적성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 시도하면서 더욱 발전시킬 수 있습니다...\n\n- 알고리즘 실행하기\n- 결과 확인하기\n- 도메인 전문가들이 동의하지 않는 알고리즘 오류를 제안했다면, 힌트로 추가하고 1단계로 돌아가기\n\nAcyclity, Exogeneity, Transitivity의 방법을 사용하여 (\"예시 DAG는 가짜이므로 도메인 전문가의 도움이 없는 경우\") 제안된 \"인과적 유효성에 대한 모든 것의 통합 이론\" 구현 알고리즘을 위하여 제공할 합리적인 힌트의 세트는 다음과 같이 테스트에 사용되었습니다.\n\n하이라이트가 에지(예: W -` Y)를 가려주면 해당 에지가 올바르다는 것을 암시하며, 공간을 가린다면(예: Z1 -` Z2) 에지가 없는 것이 올바르다는 것을 암시합니다. 부재 중인 에지가 양방향으로 힌트를 줄 수 있음에 유의하여, 일부 에지가 두 번 암시된 것처럼 보일 수 있습니다(예: Z1 -` Z2 및 Z2 -` Z1).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Test Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_31.png)\n\n# Testing the Algorithm\n\nThe next stage is to robustly and exhaustively test the algorithm for different combinations of the 3 types of errors and to measure performance.\n\nThe test harness works as follows:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n준비\n\n- 오류의 유형과 수를 선택합니다 (예: 누락된 엣지 1개, 잘못된 엣지 0개, 역전된 엣지 1개)\n- 이 조합을 포함하는 모든 유효한 DAG의 가능한 조합을 생성합니다 (즉, 정확히 1개의 누락된 엣지와 1개의 역전된 엣지를 포함하는 모든 DAG) 힌트를 제외한)\n- 유효한 조합에서 n개의 테스트를 선택합니다 (예: 10개의 테스트)\n\n실행\n\n- 선택한 각 테스트에 대해...\n- 테스트/예제 DAG를 시작점으로 사용하여 오류 DAG를 생성하고, 오류를 만들기 위해 변경 사항을 적용합니다 (즉, 1개의 누락된 엣지를 제거하고, 1개의 역전된 엣지를 반전합니다)\n- 유효한 DAG에 대한 새로운 데이터 세트를 생성합니다 (오류가 있는 것이 아닌)\n- 오류 DAG를 수정하고 생성된 데이터를 통해 오류를 확인하기 위해 재귀적인 fix_dag 함수를 호출합니다\n- 오류 DAG를 생성하는 데 사용된 확인된 오류와 비교합니다\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 마크다운 형식으로 변경해주세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 유효한 가짜 엣지 검사를 생성하기 위해 존재하지 않는 3 개의 엣지가 추가된 예시입니다...\n\n![예시 이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_33.png)\n\n마지막으로 역으로 변경된 유효한 엣지 검사를 생성하기 위해 3개의 엣지가 뒤바뀐 예시입니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_34.png\" />\n\n위 예에서 용어 \"유효한\" 테스트가 일부러 사용되었습니다. DAG를 순환적으로 만들거나 힌트에 포함된 변경 내용을 제외하고 제거, 추가 또는 반전할 수 있는 다른 엣지도 있습니다.\n\n## 테스트 결과\n\n다음은 3가지 유형의 오류 조합에 대한 테스트 결과입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 각 유형의 1개\n\n테스트 첫 번째 배치는 부재, 잘못된 및 역전된 엣지 각각 1개를 시도하는 것입니다. 결과는 다음과 같습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_35.png)\n\n결과는 단일 부족한 엣지가 있는 DAG(Directed Acyclic Graph)에서 단일 오류가 100%의 정확도로 감지됩니다. 단일 역전된 엣지가 있는 DAG 및 단일 잘못된 엣지가 있는 DAG도 각각 100%와 66.7%의 정확도로 감지됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n잘못된 가장자리 결과는 약간 좋지 않아 보일 수 있지만, 단일 가짜 링크에 대한 유효한 테스트 수는 3개 뿐이며 알고리즘이 Z1-W로부터의 가짜 링크를 감지하는 데 어려움을 겪습니다. 다른 방법으로 말하면, 가장자리 탐지에서 단일 실패만 있으며 다른 유형에 대한 실패는 없습니다.\n\n## 다른 두 가지 유형의 오류\n\n2가지 다른 오류에 대한 테스트는 다음과 같이 수행됩니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_36.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDAG에는 1개의 누락된 엣지 오류와 1개의 잘못된 엣지 오류가 있을 때, 통합 검증 알고리즘은 테스트 케이스의 100%에서 오류를 올바르게 식별합니다. 1개의 누락된 엣지 오류와 1개의 반대 방향 엣지 오류는 테스트의 78%에서 정확하게 식별되며, 1개의 잘못된 엣지 오류와 1개의 반대 방향 오류는 테스트의 78%에서 정확하게 식별됩니다.\n\n이러한 결과들은 인상적입니다. 이는 비재귀적 해결책에 대한 주요 문제인 개별 테스트가 DAG에 포함된 오류에 대한 일부 선험적 지식으로 순서가 지정되어야 한다는 것이 재귀 알고리즘에 의해 완전히 해결되었다는 것을 보여줍니다.\n\n또한 이러한 결과들은 해당 알고리즘이 실제 원인 추론 문제에서 유용할 것이라는 것을 시사합니다. 도메인 전문가들이 실제 세계에서 찾을 수 있는 실제 인과성과 유사한 DAG를 생성할 수 있다는 합리적인 가정을 한다면, 그들이 소수의 실수를 할 수 있다는 것을 의미합니다.\n\n이러한 가정을 고려할 때, 이러한 결과들은 알고리즘이 잘못된 DAG를 수정할 수 있으며, 후속 원인 모델링 단계에서 지시적이고 유용하며 사용 가능한 결과를 얻기 위한 선행 조건임을 보여줍니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 각 유형별로 2개씩\n\n각 유형의 오류가 2개씩 포함된 경우 테스트 결과는 다음과 같습니다...\n\n![그림](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_37.png)\n\n테스트 DAG에 각 종류의 오류가 2개씩 있는 경우 정확도가 저하됩니다. 2개의 누락된 엣지는 83.3%의 높은 정확도를 유지하지만, 2개의 가짜 엣지는 33.3%의 정확도로만 탐지되며, 2개의 역방향 엣지의 정확도는 25%입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 각 유형의 1개씩 있는 경우 DAG\n\n다음 단계는 테스트를 더 다양하게 만들고 각각 누락, 가짜 및 역방향 오류 중 하나를 포함하는 DAG 세트를 시도하는 것입니다. 즉, 1개의 누락, 1개의 가짜, 1개의 역방향 = 각 테스트 DAG에 3개의 오류가 있는 것입니다...\n\n![Test Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_38.png)\n\n이 테스트에서는, 각 유형의 1개씩 에러가 포함된 DAG가 80%의 케이스에서 정확하게 감지된다는 것을 보여줍니다. 이는 놀라운 테스트 결과입니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDAG에는 3가지 유형의 오류가 포함될 수 있으며, 이 오류 조합은 80%의 정확도로 올바르게 식별됩니다!\n\n## 동일한 DAG 내의 각 유형 2가지\n\n마지막으로 각 유형의 오류가 2개 포함된 DAG에 대한 테스트 결과는 다음과 같습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_39.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예시 DAG에는 총 6개의 오류가 있습니다. 이 중 2개는 누락, 2개는 잘못된 정보, 그리고 2개는 역전된 정보입니다. 이러한 오류들이 신뢰성 있게 감지되지 않을 수도 있습니다. 그러나 예시 DAG는 단지 8개의 엣지를 가지고 있고, 이 테스트에서 8개 중 6개 또는 75%의 엣지가 잘못되어 있기 때문에 이는 놀라운 일이 아닙니다.\n\n# 결론\n\n\"모든 것의 통합 이론\" 인과적 유효성 검사 알고리즘은 완벽하지 않으며, 더 복잡하고 다양하며 오류가 많을수록 정확도가 떨어집니다.\n\n그러나 정확도는 충분히 높아서 사용 가능하고 유용합니다. 실제 프로젝트에서는 알고리즘에 의해 식별된 오류가 도메인 전문가들에 의해 검토되고, DAG에 점진적인 변경이 가해지며, 최종 DAG가 합의될 때까지 검증이 반복적으로 실행됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n리뷰, 비판 및 수정에 더 많은 노력을 기울이면, 유효성 검사 알고리즘이 실행되기 전에 도메인 전문 지식을 활용하여 DAG를 개선하는 데 더 좋은 결과를 얻을 수 있습니다.\n\n재귀 및 힌트를 통해 제공된 모든 개선을 갖춘 통합 알고리즘조차도 한계가 있지만, 데이터와 현실에서 내재된 인과 관계를 정확하게 포착하는 DAG를 제안하는 핵심 단계에 도움이 되는 가치 있는 도구를 제공하는 정확도는 충분합니다. 이는 인과 추론 머신러닝 모델로부터 유용하고 실용적이며 신뢰할 수 있는 결과를 도출하는 데 중요합니다.\n\n# 추가 연구\n\n다양한 종류의 오류가 100% 신뢰성으로 감지되지 못하는 주요 이유 중 하나는 종속성 테스트의 성능 때문입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n의존성 테스트는 누락된 링크 테스트를 구현하고 각 변수에 대해 결과를 평가할 수 있어야 하는 Y ⫫ X, Z1, Z3 | W, Z2와 같은 식을 유연하게 평가할 수 있어야 합니다.\n\n이전 글에서 설명한 바와 같이 (위 링크 참조) p 값만으로 회귀 결과를 보는 것은 신뢰할 수 없습니다. 그래서 나의 해결책은 계수와 p 값의 조합을 보는 것이었고, 선택한 임계값은 여러 테스트에서 시행착오를 거쳐 결정했습니다.\n\n최종 결과는 내가 만든 의존성 테스트가 100% 신뢰할 수 없지만 가능한 한 가까울 수 있도록 구현했다는 것입니다. 개선할 수 있는 옵션이 있을 수도 있습니다.\n\n- 성능을 향상시키기 위해 p 값과 계수를 평가하는 다른 방법이 있을까요?\n- 성능이 더 좋은 회귀 솔루션에 대해 완전히 다른 접근 방식이 있을까요?\n- 인과 관계 검증을 위한 제안된 통일 된 모든 이론을 완전히 다른 것으로 바꿔 성능을 더 향상시킬 수 있을까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n수많은 달 동안 책과 온라인 기사를 찾아보고 여러 다른 소스에서 솔루션을 조합해왔는데, 이제 최상의 성능을 이룰 수 있었어요.\n\n제가 상기한 3가지 옵션 중 하나를 기반으로 개선 아이디어가 있는 분이나, 고려하지 못한 옵션을 사용하여 개선 아이디어가 있는 분 있으면 연락 주세요. 여러분의 소식을 듣고 싶어요.\n\n한편, 이 기사는 총 5편 중 마지막으로, 인과 관계 확인을 위한 모든 것의 통일된 이론을 달성한 결실을 의미하며, 이를 활용하여 실제 기업 환경에서 영향과 결과를 이끌어내기 위해 이론과 다른 기법을 어떻게 활용했는지 설명할 것입니다.\n\n# 연락하고 소통하기...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사가 마음에 들었다면 제 팔로우를 눌러주세요. 앞으로도 계속해서 새로운 기사들을 받아보실 수 있습니다.\n\n원하는 주제나 의견이 있다면, 특히 인과 추론 및 새로운 데이터 과학 분야에 관심이 있다면 댓글을 남겨주세요. 제게 연락 주시면 감사하겠습니다.\n\n저의 이전 기사를 확인하려면 제 블로그인 The Data Blog에서 제 연구와 인과 추론에 대한 모든 것을 찾아볼 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_0.png"},"coverImage":"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_0.png","tag":["Tech"],"readingTime":40},{"title":"더블 박사","description":"","date":"2024-05-17 19:54","slug":"2024-05-17-DoublePhD","content":"\n![이미지](/assets/img/2024-05-17-DoublePhD_0.png)\n\n\"어릴 적부터 과학에 대한 깊은 사랑을 품고 왔습니다. 이 열정이 나를 분야에서의 경력으로 자연스럽게 이끌었습니다. AIEEE 입학 시험을 통과한 후, 2010년 NIT Uttarakhand에서 제 첫 공학 여정을 시작했습니다. 그 해는 처음으로 개설된 공학 코스였지만, 많은 고난을 겪었습니다.\n\n당시 NIT Uttarakhand는 임시 캠퍼스와 필수적인 자원 부족으로 인한 어려움에 직면했습니다. 이로 인해 학생들의 불만이 끊임없이 솟구쳤고, 우리는 영구적인 캠퍼스를 원하며 우리의 열정적인 호소를 우탄칸드 정부 관리자들에게 전달했습니다. 그러나 10년이 지난 지금도 저희 학교는 여전히 영구 캠퍼스를 기다리고 있습니다!\n\n제 BTech 마지막 학년이 지나면서 상황은 조금 나아졌습니다. 대학 학부 과정을 진행하면서 Coursera와 같은 온라인 플랫폼을 통한 독학은 학교의 제약으로부터 남은 부분을 보충하는 데 있어서 귀중한 도구가 되었습니다.\"\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 원래 가르치는 직업에 매료되었습니다. 그러나 정부의 교육 역할에 대한 MTech 학위 필요 규정으로 인해 내 포부를 조정하게 되었습니다. GATE 점수가 기대에 못 미치는 수준이었지만, NIT Hamirpur에 석사과정 입학을 성공했습니다.\n\n가르치는 직업에 대한 나의 열망은 삶을 바꾸는 사건인 6개월간의 침대에서의 휴식을 강요하는 사고로 인해 일시적으로 중단되었습니다. 이때 나는 박사 과정을 쫓기로 결정했습니다. 나의 선택한 분야를 더 깊게 탐구할 뿐만 아니라 가르치는 역량을 향상시키는 발판으로 보았습니다.\n\n나의 박사 학위 연구 여정은 컴퓨터 과학, 신경과학, 그리고 심리학을 융합하여 기계 학습의 시각을 통해 우울증의 수수께끼를 풀어나가는 것에 초점을 맞추며 시작했습니다. 이 노력은 MHRD의 자금 지원을 통해 지원을 받아, 나의 IIT Roorkee에서의 임기 중에 많은 도움을 얻을 수 있었습니다. 그러나 기계 학습 분야의 급격한 변화는 가끔 내게 사기를 꺾는 느낌을 줬습니다.\n\n나의 학술적 여정에서의 전환점은 SPARK라 불리는 협력 프로그램으로 찾아왔습니다. 그것은 네덜란드 그로닌겐 대학과의 이중 박사 과정을 쫓을 수 있는 기회를 내게 제공했습니다. 이 국제적 협업은 팬데믹의 제약들로 인해 방해를 받았지만, 독특한 경험과 학습 기회를 제공하였습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금까지의 여정을 되돌아보면, 학업에서 가장 중요한 것은 열정과 목적의 중요성입니다. 머신 러닝과 같이 동적이고 도전적인 분야에서는 진로 전망이 풍부한데, 이러한 본래적 동기가 우리를 지탱하고 전진시킵니다. 비슷한 길을 고민하는 이들에게 알립니다. 지식을 쫓는 것은 목적을 달성하는 수단뿐만이 아니라 자아 발견과 성취의 여정입니다.\"\n\n- 인도 공과대학 쿠마오와 네덜란드 그로닌겐 대학에서 컴퓨터 과학 박사 Anmol Gupta\n\nPayel Das가 인터뷰하고 작성함\n","ogImage":{"url":"/assets/img/2024-05-17-DoublePhD_0.png"},"coverImage":"/assets/img/2024-05-17-DoublePhD_0.png","tag":["Tech"],"readingTime":2},{"title":"왜 인공지능이 음악가를 대체할 수 없을까","description":"","date":"2024-05-17 19:52","slug":"2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians","content":"\n<img src=\"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_0.png\" />\n\n작년 4월, 팝 스타 그라임스(Grimes)가 트위터에 발표하여 헤드라인을 독차지했어요. 현재 X(그녀의 베이비 대디 소유의 실패한 플랫폼)에 그녀의 목소리를 사용하는 사람과 로열티를 50-50으로 분할한다고 발표했어요. 이는 음악 산업을 광폭화시켰지만 사람들이 진지한 마음으로 생각하기 시작할 때까지 계속 되었어요. 그라임스는 미래 기술을 옹호해온 항상이지만, 그것이 이미 올 것을 의미하는 것은 아니에요. 그녀는 몇 년간 새 앨범을 발표하지 않았어요. 그리고 그녀는 어디에서든 노래를 부를 수 있지만, 그녀는 정확히 휘트니 휴스턴은 아니에요. 그녀의 재능은 노래 작곡가와 프로듀서로 더 많이 발휘되고 있어요.\n\n인공지능은 많은 일을 할 수 있고, 더 많은 기능을 추가하면서 진화하고 있어요. 사기 탐지, 천문학 연구, 챗봇, Siri 등이 그것의 사용 사례 중 일부예요. 하지만 우리는 여전히 많은 결함들을 해결하지 못하고 있어요. 최근 캘리포니아의 한 범죄 현장을 통과하던 자율 주행차가 노란 경찰 테이프로 둘러싸인 범죄 장면으로 통과했어요. 테슬라에는 교통 콘 위에 라이트를 올려두면 이동하지 않는 결함이 있어요. 짐미 키멜이 스마트 스피커인 Echo에 팬케이크 믹스를 주문하도록 지시하는 세그먼트가 있었는데, 시청자들은 다음 날 아침 아마존 위시리스트에 빅스퀵 두 상자를 발견했어요. 또한 인공지능이 반드시 좋은 습관을 유도하는 것은 아니에요. 예전 이웃인 에반은 글쎄요, 망치 한 봉지보다 서둘기였지만, \"나는 그녀에게 기술에 소리 지르게 가르치기 싫어\"라며 그의 3세 딸에게 알렉사를 빼앗아갔어요. (이 사람은 한번 라이터로 얼어붙은 진흙 더미를 불태워 겨울 뒷마당 스모어 쿠크아웃을 시작하려고 시도한 사람이에요. 그리 높은 표준은 아니죠.)\n\n<img src=\"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_1.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAI를 창의적 예술에 활용하는 데의 문제는 이러한 시스템이 출력물이 아닌 과정에 기반을 둔 훈련을 받기 때문입니다. AI 음악 생성기 Soundful에 따르면 \"딥 러닝은 기존 음악의 대규모 데이터 세트에서 인공 음악 생성기를 훈련시키는 것을 포함합니다... 신경망은 음악을 만들 때 우리 뇌가 작동하는 방식을 모방합니다.\"\n\n그러나 이 둘은 완전히 다른 것입니다. 대규모 언어 모델(LLM)은 기존(대부분 저작권이 있는) 노래의 입력에 의존하며, 엔지니어들에 의해 공급된 데이터에 기초하여 패턴을 분석하고 무작위로 리듬과 가사를 생성할 수 있습니다. 이것이 작곡할 때 인간 뇌가 작동하는 방식일까요? 아마도 아니지만, 솔직히 말하자면, 뇌과학자들이 아직 정확히 이를 해결하지 못했습니다. MRI, CAT 및 리간드 기반 PET와 같은 매우 고급 의료 영상 기술을 사용하면 뇌의 어느 부분이 활성화되고 어떤 화합물이 방출되는지를 확인할 수 있지만, 세포 수준에서의 실제 단계별 절차는 누구도 알 수 없습니다. 문제를 복잡하게 만드는 것은 음악이 한 영역에만 영향을 미치지 않는다는 사실입니다 - 대퇴, 신경 내분비 및 자율 신경계에서 처리되며 몇몇 대뇌 피질이 관여합니다.\n\n<table><img src=\"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_2.png\" /></table>\n\n하지만 음악에서 AI를 완전히 배제하는 것은 아닙니다. 버클리 음악 대학과 건강 신경학자 사마타 샤르마 박사와 데이비드 실버스와이그 박사가 2018년 발표한 논문에 따르면 음악이 뇌에 미치는 치료효과로 인해 머신 러닝이 언젠가 만성 통증, 우울증 및 파킨슨병과 같은 기능 장애를 치료하기 위해 맞춤형으로 사용될 수 있을 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그것은 예술인가요?\n\n옥스퍼드 영어 사전에 따르면, “예술”은 “인간의 창의적 기술과 상상력의 표현 또는 적용”이라고 정의됩니다. 우리가 우선 뇌의 창의적 절차를 정말로 이해하지 못한다면, 기술로 그것을 복제하려고 시도할 수 있을까요? AI에게 “이미지”나 “콘텐츠”를 생성하도록 유도할 수는 있지만, 그 결과물은 상상력적 사고의 인지적 과정을 통한 것이 아니라, 입력된 데이터를 기반으로 생성될 것입니다. 우리는 아직 그것이 어떻게 작동하는지 모릅니다.\n\n![이미지](/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_3.png)\n\n또한, 돈을 탐하는 MBA 기술 분야의 사람들이 인정하기 꺼려하는 사활적 사실이 있습니다: 위대한 예술은 규칙을 깨는 것입니다. 그 규칙을 깨려면 그 규칙을 알아야 하며, 그 규칙을 깰 때와 어디에서 깰지를 알아야 합니다. 그들이 체육관에서 $250 에어팟으로 터는 Wu-Tang과 Avicii의 노래들? 그들은 규칙을 깼습니다. RZA의 프로덕션 기법은 이후 10년간 랩에 영향을 미쳤고, Avicii는 일렉트로니카와 멜로디, 소울, 펑크, 블루스, 국가를 전통적인 노래 형식으로 결합한 것을 선도했습니다. 심지어 그라임스도- 그녀는 항상 음악을 만들기 위해 소프트웨어를 사용해 왔지만- 표준 일렉트로팝 루트에서 벗어난 점으로 악명을 얻었습니다; 2019년의 “Delete Forever”에서 그녀는 힙합 비트 위에 여유로운 어쿠스틱 기타와 신스를 겹쳐 넣고, 벤조와 바이올린의 슬픈 소용돌이가 서서히 사라지게 합니다. AI가 지금 이것을 할 수 있을까요? 전혀 아닙니다. 앞으로 AI가 할 수 있을까요? 그것도 의심스럽군요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n요즘 LinkedIn에서 AI 애호가와 음악 생성기인 Loudly와 Soundful과 같은 음악 생성기의 긍정적인 점에 대해 토론했어요. 그리고 그분 말대로 좋은 점이 많다는 걸 인정해야겠죠. 이런 도구들은 창의적인 과정을 민주화시켜줘요. 스튜디오나 악기, 심지어 음악에 대한 배경지식 조차 없어도, 인터넷만 연결되어 있다면 음악을 만들 수 있어요. 이런 도구들은 작곡가의 창작 고배를 극복하거나 출발점을 제공해 줄 수 있답니다. 학생들이 노래의 다른 부분들을 학습하도록 도울 수도 있어요 - 리듬, 멜로디, 조화, 가사 등. 즉, 이 도구들은 취미로 즐기는 사람들, 아마추어, 초보자들에게 딱이에요.\n\n문제는 CEO들이 AI가 실제 전문 음악가들을 대체할 수도 있고 해야한다고 결정할 때 발생해요. 아티스트들이 가끔 짜증나기도 하죠. 그들은 비싸고 이상하고 냄새 나며 무대에서 취준해 공연을 못하기도 하고, 기자들에게 엉뚱한 얘기를 하다가 기획사의 PR팀에게 악몽을 주기도 해요. 그런데 그들은 AI 시스템보다 훨씬 더 나은 제품을 만들어낼 능력을 가지고 있어요. 그리고 무엇보다 중요한 건, 그들이 청중과 연결이 될 수 있다는 점, 이건 봇이 할 수 없는 거예요. 최근에 나는 Girl in Red라는 노르웨이의 인디 팝 가수이자 퀸 아이콘의 콘서트를 보고 놀랐어요. 관객 중 몇몇 레즈비언 커플들이 공연 중에 약혼하거나, 그들의 예정된 결혼을 축하하기 위해 함께 참석했다는 거라니요. 음악이 생생하고 환영받는 공동체를 창조하며 안전한 공간을 만들 수 있는 능력에 대한 경이스러운 증거이자, 예술 내에 인간적인 구성요소의 중요성을 보여주는 일이었어요.\n\n하지만 Grimes의 제안을 받아들이고 싶다면, AI를 활용해볼 수 있어요. 장르, 템포, 지속 시간, 키, 악기를 선택하여 생성기에 입력해보세요. ChatGPT에게 일론 머스크나 기술파시즘에 대한 몇 줄의 울림 있는 가사를 요청하고 이를 그라임스의 고음 소리를 모방할 수 있는 소프트웨어를 통해 실행시켜보세요. 몇 개의 제품을 시험해본 결과 그들의 한계가 그 정도인 것 같아요 (비록 일부 제품이 다른 것보다 나을 수 있어요; Loudly는 “92년식 Ford Crown Victoria의 마모된 브레이크 패드와 같은 소음”이라고만 설명할 수 있는 30초 짜리 혼돈을 소환해냈어요.) 그 다음에는 가사와 멜로디를 결합하거나 전통적인 악절-브릿지-코러스 형식으로 작곡을 구성하는 코드를 작성해볼 수 있어요. 원한다면 이를 천 번 이상 반복해도 괜찮아요, 그때마다 다른, 하지만 똑같이 단조로운 4코드 팝송을 3분 35초에 만들어낼 수 있어요. 이건 그라임스가 최근 Coachella에서 치명적이었던 공연처럼 들릴 거에요, 하지만 그녀를 유명하게 한 음악처럼 들리지는 않을 거에요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 거의 열 년 동안 주요한 포춘 500 기술 기업에서 일한 매우 현명한 친구로부터 받은 조언을 전해드리고 싶어요. 얼마 전에 \"AI는 자신의 영역에 머물러야 한다\"고 현명한 충고를 받았거든요. 의료, 교통, 날씨 등 대량의 데이터 세트에 대한 수요, 패턴 인식, 예측이 필요한 분야에서 큰 약속을 지니고 있다고 의심할 여지가 없어요. 그러나 우리는 지금까지 주로 저작권 소유자의 동의없이 저작물을 도용하거나 Jennifer Lawrence의 가짜 누드를 생성하며, 고장 나는 웹사이트 판매 챗봇을 만드는 데 이용해 왔습니다 - 그러면서 낭비적이고 탐욕스러운 전력 요구로 인해 우리의 기후 위기를 악화시키고 있어요. AI가 절대 필요하지 않은 곳은 방송파에요. 예술이든 문학이든 마찬가지에요. 겨우 하는 말처럼 \"영롱해질 때까지 어둠 속에 그 레이오.\"\n","ogImage":{"url":"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_0.png"},"coverImage":"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_0.png","tag":["Tech"],"readingTime":6},{"title":"논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법","description":"","date":"2024-05-17 19:51","slug":"2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels","content":"\n큰 언어 모델 환시 문제를 해결하기 위해 프롬프트 엔지니어들이 얼마나 빠르게 작업하고 있는지 알아보세요.\n\n## TL;DR\n\nChat-GPT와 같은 대규모 언어 모델(Large Language Models, LLM)이 최근 몇 년 동안 인기를 얻고 있습니다. 불행하게도 LLM은 논리 추론을 필요로 하는 작업에 직면하면 종종 \"환시\"하는 경향이 있어 전문적인 응용 프로그램에서 신뢰할 수 없는 경우가 많습니다.\n\n인간-언어 모델 상호작용을 개선하려는 목적으로 일하는 프롬프트 엔지니어들은 LLM의 논리 추론을 개선하기 위한 새로운 방법을 개발했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사의 기반인 원본 논문 \"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic\"은 Zhao 등의 연구진에 의해 2023년 9월에 발표되었으며 다음에서 찾을 수 있습니다: [링크](https://arxiv.org/pdf/2309.13339).\n\n## 배경\n\n최근 몇 년간 대형 언어 모델(Large Language Models, LLM)이 인기를 얻고 있으며 가정, 학교 및 직장에서 일상생활에 영향을 미치고 있습니다. 특히 Chat-GPT는 불가결한 가정 이름이 되었습니다.\n\nLLM은 극도로 방대한 데이터셋을 활용하며 수십억 개 또는 심지어 수조 개의 기계 학습 매개변수로 훈련됩니다. 이 방대한 훈련을 통해 인간 언어의 미묘한 복잡성을 포착하여 인간 대화를 닮은 사용자와의 상호작용을 가능케 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLLM(거문고 언어 모델)은 다양한 정보를 검색하는 능력을 갖고 있어 신비롭게 보일 수 있지만, 심각한 응용에 사용하기에 제약이 있는 특성을 가지고 있습니다. 근본적으로 LLM은 인간과 같은 지식을 갖고 있지 않습니다. 그들은 단순히 자신의 훈련 데이터와 프롬프트에서 파생된 텍스트를 생성합니다.\n\n이러한 이유로 LLM은 인간 언어의 내재적 논리에 완전히 의존하며, 이는 \"환영\"의 경우를 초래할 수 있습니다. 여기서 환영은 잘못된 결과를 생성하거나 일반적으로 인간이 쉽게 처리하는 논리적 단어 문제를 해결하지 못하는 상황을 의미합니다. 이러한 논리적 도전은 프롬프트를 다시 구성함으로써 완화될 수 있으며, 이는 본질적으로 LLM이 논리적 사고를 하도록 강요하는 것입니다.\n\nLLM의 보급화를 고려할 때, 현대 기계 학습에서 중요한 프롬프트 엔지니어링이라는 전용 학문 분야가 LLM의 성능을 향상시키고 실용적 목적을 위해 그 출력을 정제하는 데 집중하고 있음을 발견하는 것은 놀라운 일이 아닙니다. 이 분야는 Chat-GPT와 같은 기존 LLM을 보다 효과적으로 활용하기 위한 해결책을 제공하기 때문에, 일종의 없던 기능을 개발하는 대신 기존 LLM을 개선하는 것이 필요한데 그것은 방대한 데이터, 처리 능력, 시간이 필요하기 때문입니다.\n\n본 기사에서 논의된 프롬프트 엔지니어링 논문은 LLM 환영 문제를 해결하기 위해 논리적 원칙을 프롬프트 디자인에 통합하려는 목표를 가지고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 방법\n\n해당 논문은 LLM을 위한 제로샷 연쇄사고 프롬프팅을 개선하기 위해 특별히 고안된 새로운 프롬프트 엔지니어링 방법인 Logical Thoughts(LoT)을 소개합니다.\n\nWei 등이 처음 제시한 연쇄사고(CoT) 프롬프팅은 퓨샷 프롬프팅의 한 형태입니다. 제로샷 프롬프팅과는 달리 퓨샷 프롬프팅은 LLM이 해결해야 할 질문을 제기하기 전에 비슷한 질문-답변 쌍의 \"예시\"를 제공하는 것을 포함합니다. CoT 프롬프팅에서 예시 답변은 문제를 단계별로 설명합니다. 이를 통해 LLM은 실제 질문에 단계별로 응답해야 하며, 예시 답변을 모방합니다. LLM에게 문제를 단계별로 처리하도록 강요함으로써 응답의 정확도를 크게 향상시킬 수 있습니다.\n\nKojima 등이 제시한 제로샷 연쇄사고 프롬프팅은 기존 예시를 제공하지 않고 프롬프트에 \"한 단계씩 생각해 봅시다\"라는 구문을 추가하여 이 효과를 흉내 낼려고 시도합니다. 이 새로운 방법이 개선하려는 것은 이 \"제로샷\" 연쇄사고 프롬프팅이며, 원래의 \"퓨샷\" CoT 프롬프팅이 아님을 이해하는 것이 중요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png)\n\nLoT은 LLM에게 일반적인 제로샷 CoT 프롬프팅에 따라 문제를 단계별로 해결하도록 합니다. LLM이 초기 단계별 솔루션을 제시한 후, 후속 프롬프트에서는 LLM에게 각 단계를 확인하고 필요에 따라 수정하도록 요청합니다. 이는 LLM에게 각 단계에 대해 긍정적 및 부정적 리뷰를 제공하도록 지시한 다음, 올바른 리뷰를 정당화하고 잘못된 리뷰를 비판하도록 지시하며, 원본 문제의 가정을 고려합니다. 그런 다음 필요한 경우 LLM에게 올바른 리뷰를 사용하여 단계를 수정하도록 요청합니다. 단계가 수정되거나 확인된 후, 원본 문제가 LLM에게 다시 제시되고, 이미 수정되거나 확인된 각 단계가 함께 제시됩니다.\n\n![이미지](/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_1.png)\n\n기본적으로, LoT은 LLM을 문제 해결 프로세스를 진행하도록 안내하여 각 단계를 검증하는 데 자체 논리를 사용하도록 요청합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 결과\n\n논문은 정확도를 기반으로 LoT 방법을 표준 제로샷 CoT 프롬팅과 비교한 결과를 평가합니다. 연구자들은 Vicuna-7b, Vicuna-13b, Vicuna-33b, GPT-3.5-turbo 및 GPT-4 모델을 GSM8K, AQuA, Date, SocialQA, CauseEffect, Objects, Letter 및 OddOut 데이터셋과 짝지어서 해당 방법을 평가했습니다.\n\n연구 결과는 LoT 방법을 사용할 때 대부분의 모델-데이터셋 조합에서 정확도가 향상된다는 것을 보여줍니다. 특히, OddOut 데이터셋에서 Vicuna-13b 모델을 사용했을 때 +16.28%의 정확도 향상이 있었습니다. 반면, Objects 데이터셋에서 GPT-3.5-turbo 모델을 사용했을 때 -2.50%의 정확도 감소가 관찰되었습니다.\n\n이러한 결과는 LoT 방법이 다양한 모델과 데이터셋에 걸쳐 LLM 응답의 정확도를 향상시키는 데 효과적임을 보여줍니다. 그러나 모델과 데이터셋에 따라 개선의 정도가 다르다는 것을 기억해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 토론\n\n사고 연결 추진이 프롬프팅 방식에 작은 변화만으로 LLM의 추론 능력을 크게 향상시켰지만, LoT 방법은 더 복잡한 프레임워크를 도입하여 실제적인 측면에서는 덜 실용적일 수 있습니다. 게다가 이 연구는 LoT 프롬프팅을 퓨-샷 CoT 프롬프팅과 비교하지 않았기 때문에 LoT가 퓨-샷 CoT 프롬프팅보다 더 효과적인지 여부가 분명하지 않습니다. LoT 프롬프팅은 매우 특화된 범위와 복잡한 구현 과정으로 인해 현실 세계에서 그다지 활용될 가능성이 낮을 수 있습니다.\n\n전반적으로, LoT는 LLM의 내재적인 논리 추론 한계를 해결하기 위한 또 다른 해결책에 불과합니다. 이상적인 시나리오에서 LLM이 인간과 같이 논리를 사용할 수 있기를 바라지만, 단순히 더 많은 매개변수로 훈련된 더 큰 모델을 만들더라도 달성될 수 있는지 여부는 불확실합니다. 아니면 보다 근본적인 논리 통합이 필요한지도 모릅니다.\n\n당분간은 LoT와 같은 접근 방식이 기존 LLM의 유틸리티를 최적화하는 데 효과적인 전략으로 기능할 수 있습니다. 특히 의학과 같이 의도적으로 실수를 줄이기 위해 AI로부터 도움을 받을 때 조심스런 경향이 있는 분야에 유용할 수 있는데, 이러한 프롬프팅 엔지니어링 방법은 고객 서비스 응용 프로그램의 효율성을 향상시킬 수 있는 AI 챗봇에도 활용될 수 있습니다. 이 경우, 이러한 프롬프팅 방식은 사용자와 LLM 자체 사이의 버퍼로 구현되어야 할 것으로 생각됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n앞으로 몇 년 동안의 프롬프트 엔지니어링 진화가 흥미로울 것입니다. 이는 LLMs가 더욱 신뢰할 만한 수준으로 발전하여 더욱 비판적인 응용 프로그램에도 사용될 수 있는 길을 열어 줄 수도 있고, 반대로 LLMs가 발전하여 프롬프트 엔지니어링이 쓸모 없어지는 지점까지 발전 할 수도 있습니다. AI가 일상생활에 더욱 통합되는 시대에 LLM 효과성을 향상시키기 위한 노력의 한 부분으로 LoT를 이해하는 것이 중요합니다.\n\n## 참고문헌\n\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. https://arxiv.org/abs/2205.11916\n\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nZhao, X., Li, M., Lu, W., Weber, C., Lee, J., Chu, K., & Wermter, S. (2023). 대규모 언어 모델에서 논리를 통한 Zero-Shot Chain-of-Thought Reasoning 강화. [arXiv 링크](https://arxiv.org/abs/2309.13339)\n","ogImage":{"url":"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png","tag":["Tech"],"readingTime":7}],"page":"104","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":10,"currentPageGroup":5},"__N_SSG":true}