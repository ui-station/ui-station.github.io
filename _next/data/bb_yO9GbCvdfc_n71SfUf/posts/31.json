{"pageProps":{"posts":[{"title":"OCI에서 Active Directory 게임을 실행하는 방법  1부","description":"","date":"2024-06-19 13:32","slug":"2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1","content":"\n제가 정말 즐겁게 즐겼던 프로젝트 중 하나는 GOAD입니다. 게임 오브 스로운즈 팬으로서 사이버 지식을 시험하고 동시에 즐길 수 있는 수단이었습니다. 만약 여러분이 스로운즈의 팬이라면, 이 Windows/AD/SCCM 랩은 여러분을 위한 것입니다.\n\n처음에는 중첩 가상화 서버를 만들려고 했는데, 테라폼과 앤서블 지식이 거의 없어서 어려움을 겪었습니다. 하지만 저는 자동화로 나아가기로 결정했습니다. 일상적인 작업에서 시간을 절약하고, 올바르게 구현된다면 인간 에러를 줄일 수 있기 때문에 자동화가 많은 도움이 된다는 점에 동의합니다.\n\n`Game of Active Directory (GOAD)` 프로젝트는 현실적이고 실용적인 경험을 통해 사이버 보안 기술을 향상시키는 포괄적인 랩 환경입니다. Oracle Cloud Infrastructure (OCI)에서 호스팅되며, 다양한 OCI 서비스와 통합하여 현실 세계의 보안 시나리오를 모의할 수 있습니다.\n\nhttps://github.com/adibirzu/GOAD/blob/main/docs/install_with_oci.md\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n랩 환경으로서 VCN 보안 목록에서 엄격한 ACL을 구현하지는 않았어요. 그러나 모든 포트에서 192.168.0.0/16에서의 액세스는 허용했어요.\n\n1- 우리는 OCI의 Windows Server/Ubuntu 이미지를 사용할 거에요. 이 선택은 PAYG 요금제를 사용해. Windows Server 평가판을 사용할 계획이라면, 자체 이미지를 빌드하고 테라폼 스크립트를 사용자 정의 이미지 OCID로 설정해야 해요:\n\nOracle Cloud Infrastructure 이미지\n\n2- 테라폼 스크립트와 PowerShell 스크립트는 ad →GOAD →providers →OCI 하위에 추가됐어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Screenshot](/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_0.png)\n\n```js\n./goad.sh -t check -l GOAD -p oci -m local\n```\n\n3- 서로 다른 공급업체에서 사용자들이 알고 있는 동일한 워크플로를 제공하기 위해 goad.sh 스크립트에 제공자로 oci를 추가했습니다.\n\n![Screenshot](/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nOCI에서 우분투의 기본 사용자는 ubuntu이므로 goad.sh의 모든 참조는 ubuntu 사용자를 사용할 것입니다:\n\n![2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_2](/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_2.png)\n\n4. 스크립트 아래에, 저는 설치 후 우분투 서버의 선행 조건을 설치하기 위해 setup_oci.sh 스크립트를 만들었습니다.\n\n![2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_3](/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_3.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n5- 오라클 클라우드 인프라에서 랩을 프로비저닝하는 방법을 설명하는 docs/install_with_oci.md를 업데이트했습니다.\n\n6- ad →GOAD →providers →oci →ssh_keys →ubuntu-jumpox.pem에 개인 키를 배치하여 Ubuntu 인스턴스에 연결을 테스트했습니다.\n\n!!!! 이 키를 매우 주의해서 다루고, git에 공개하지 마세요.\n\n![이미지](/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 마크다운 형식으로 변경하였습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n9- ad → GOAD → providers → oci → terraform 폴더에 Terraform/PowerShell 파일을 만들어주세요:\n\n- windows_cloud_init.ps1\n\n```powershell\n# 변수\n$adminUsername = “ansible”\n$adminPassword = ConvertTo-SecureString “YourSecurePassword123!” -AsPlainText -Force\n\n# ansible 사용자 생성\nNew-LocalUser $adminUsername -Password $adminPassword -FullName $adminUsername -Description “Ansible admin user”\nAdd-LocalGroupMember -Group “Administrators” -Member $adminUsername\n\n# WinRM 활성화\nwinrm quickconfig -q\nwinrm set winrm/config/service/auth @{Basic=”true”}\nwinrm set winrm/config/service @{AllowUnencrypted=”true”}\nwinrm set winrm/config/service @{EnableCompatibilityHttpsListener=”true”}\nwinrm set winrm/config/service @{EnableCompatibilityHttpListener=”true”}\n$cert = New-SelfSignedCertificate -DnsName $(hostname) -CertStoreLocation Cert:\\LocalMachine\\My\nwinrm create winrm/config/Listener?Address=*+Transport=HTTPS @{Hostname=$(hostname); CertificateThumbprint=$($cert.Thumbprint)}\nSet-Service -Name winrm -StartupType Automatic\nStart-Service -Name winrm\n\n# WinRM을 위한 기본 인증 및 암호화 트래픽 활성화\nSet-Item -Path WSMan:\\localhost\\Service\\Auth\\Basic -Value $true\nSet-Item -Path WSMan:\\localhost\\Service\\AllowUnencrypted -Value $true\n\n# WinRM 방화벽 예외 설정\nNew-NetFirewallRule -Name \"WinRM-HTTP\" -DisplayName \"WinRM (HTTP-In)\" -Protocol TCP -LocalPort 5985 -Action Allow -Enabled True\nNew-NetFirewallRule -Name \"WinRM-HTTPS\" -DisplayName \"WinRM (HTTPS-In)\" -Protocol TCP -LocalPort 5986 -Action Allow -Enabled True\n\n# TLS 1.2 프로토콜 설정\n[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12\n\n# NuGet 공급자 설치 및 PowerShellGet 업데이트\nInstall-PackageProvider -Name NuGet -Force -Confirm:$false\nUpdate-Module -Name PowerShellGet -Force -AllowClobber -Confirm:$false\n```\n\n- profile.tf\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nprovider \"oci\" {\n  tenancy_ocid      = var.tenancy_ocid\n  user_ocid         = var.user_ocid\n  fingerprint       = var.fingerprint\n  private_key_path  = var.private_key_path\n  region            = var.region\n}\n```\n\nvariables.tf\n\n```js\nvariable \"tenancy_ocid\" {\n  description = \"The OCID of your tenancy.\"\n  type        = string\n}\n\nvariable \"user_ocid\" {\n  description = \"The OCID of the user calling the API.\"\n  type        = string\n}\n\nvariable \"fingerprint\" {\n  description = \"The fingerprint of the API key.\"\n  type        = string\n}\n\nvariable \"private_key_path\" {\n  description = \"The path to the private key.\"\n  type        = string\n  default     = \"/Users/abirzu/.ssh/newpemkey.pem\"\n}\n\nvariable \"region\" {\n  description = \"The region to use.\"\n  type        = string\n  default     = \"eu-frankfurt-1\"\n}\n\nvariable \"compartment_ocid\" {\n  description = \"The OCID of the compartment to use.\"\n  type        = string\n}\n\nvariable \"availability_domain\" {\n  description = \"The availability domain to use.\"\n  type        = string\n  default     = \"NoEK:EU-FRANKFURT-1-AD-1\"\n}\n\nvariable \"shape\" {\n  description = \"The shape of the instance to be created.\"\n  type        = string\n  default     = \"VM.Standard.E5.Flex\"\n}\n\nvariable \"ocpus\" {\n  description = \"The number of OCPUs to allocate.\"\n  type        = number\n  default     = 1\n}\n\nvariable \"memory_in_gbs\" {\n  description = \"The amount of memory in GBs.\"\n  type        = number\n  default     = 12\n}\n\nvariable \"ssh_authorized_keys\" {\n  description = \"The public key for SSH access to the instances.\"\n  type        = string\n}\n\nvariable \"image_ocid\" {\n  description = \"The OCID of the image to use.\"\n  type        = string\n}\n\nvariable \"windows2016_image_ocid\" {\n  description = \"The OCID of the Windows Server 2016 image.\"\n  type        = string\n}\n\nvariable \"windows2019_image_ocid\" {\n  description = \"The OCID of the Windows Server 2019 image.\"\n  type        = string\n}\n```\n\nnetwork.tf\n\n```js\n\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nresource “oci_core_vcn” “generated_oci_core_vcn” {\n cidr_block = “192.168.0.0/16”\n compartment_id = var.compartment_ocid\n display_name = “goad-virtual-network”\n dns_label = “goadvcn”\n}\nresource “oci_core_subnet” “public_subnet” {\n cidr_block = “192.168.57.0/24”\n compartment_id = var.compartment_ocid\n display_name = “public-subnet”\n dns_label = “publicsubnet”\n vcn_id = oci_core_vcn.generated_oci_core_vcn.id\n route_table_id = oci_core_route_table.public_route_table.id\n}\nresource “oci_core_subnet” “private_subnet” {\n cidr_block = “192.168.56.0/24”\n compartment_id = var.compartment_ocid\n display_name = “private-subnet”\n dns_label = “privatesubnet”\n vcn_id = oci_core_vcn.generated_oci_core_vcn.id\n route_table_id = oci_core_route_table.private_route_table.id\n prohibit_internet_ingress = true\n prohibit_public_ip_on_vnic = true\n security_list_ids = [oci_core_security_list.winrm_rdp_security_list.id]\n}\nresource “oci_core_internet_gateway” “generated_oci_core_internet_gateway” {\n compartment_id = var.compartment_ocid\n display_name = “Internet Gateway goad-virtual-network”\n enabled = true\n vcn_id = oci_core_vcn.generated_oci_core_vcn.id\n}\nresource “oci_core_nat_gateway” “generated_oci_core_nat_gateway” {\n compartment_id = var.compartment_ocid\n display_name = “NAT Gateway goad-virtual-network”\n vcn_id = oci_core_vcn.generated_oci_core_vcn.id\n}\nresource “oci_core_route_table” “public_route_table” {\n compartment_id = var.compartment_ocid\n vcn_id = oci_core_vcn.generated_oci_core_vcn.id\n display_name = “public-route-table”\nroute_rules {\n destination = “0.0.0.0/0”\n destination_type = “CIDR_BLOCK”\n network_entity_id = oci_core_internet_gateway.generated_oci_core_internet_gateway.id\n }\n}\nresource “oci_core_route_table” “private_route_table” {\n compartment_id = var.compartment_ocid\n vcn_id = oci_core_vcn.generated_oci_core_vcn.id\n display_name = “private-route-table”\nroute_rules {\n destination = “0.0.0.0/0”\n destination_type = “CIDR_BLOCK”\n network_entity_id = oci_core_nat_gateway.generated_oci_core_nat_gateway.id\n }\n}\n  options {\n    type                  = \"DomainNameServer\"\n    server_type           = \"CustomDnsServer\"\n    custom_dns_servers    = [\"192.168.56.10\",\"8.8.8.8\"]\n  }\n options {\n        type = \"SearchDomain\"\n        search_domain_names = [ \"sevenkingdoms.local\" ]\n    }\n}\nresource “oci_core_security_list” “winrm_rdp_security_list” {\n compartment_id = var.compartment_ocid\n vcn_id = oci_core_vcn.generated_oci_core_vcn.id\n display_name = “winrm_rdp_security_list”\negress_security_rules {\n protocol = “all”\n destination = “0.0.0.0/0”\n stateless = false\n }\ningress_security_rules {\n protocol = “all”\n source = “192.168.0.0/16”\n stateless = false\n }\n}\n```\n\n```js\nresource “oci_core_default_dhcp_options” “default_dhcp_options” {\n manage_default_resource_id = oci_core_vcn.generated_oci_core_vcn.default_dhcp_options_id\noptions {\n type = “DomainNameServer”\n server_type = “CustomDnsServer”\n custom_dns_servers = [“192.168.56.10”]\n search_domain_names = [“sevenkingdoms.local”]\n }\n```\n\nThe DHCP configuration part is essential, as if it’s not properly configured, it will result in the failure of the ansible jobs. If the terraform variable will not add the search domain, you need to do this manually:\n\nGo to the VCN → DHCP Options:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_7.png\" />\n\n화면 오른쪽 상단에 있는 3 점을 클릭한 후 편집을 선택하세요. 여기에서 외부 DNS 서버를 추가하고 사용자 정의 검색 도메인인 Seven Kingdoms를 추가할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_8.png\" />\n\n이 부분에서 DNS 문제를 해결해야합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\noptions {\ntype = \"도메인 네임 서버\"\nserver_type = \"사용자 정의 DNS 서버\"\ncustom_dns_servers = [\"192.168.56.10\",\"8.8.8.8\"]\n}\noptions {\ntype = \"검색 도메인\"\nsearch_domain_names = [\"seven kingdoms.local\"]\n}\n```\n\njumpbox.tf\n\n```js\nresource \"oci_core_instance\" \"jumpbox\" {\n availability_domain = var.availability_domain\n compartment_id = var.compartment_ocid\n display_name = \"jumpbox\"\n shape = var.shape\nshape_config {\n baseline_ocpu_utilization = \"BASELINE_1_1\"\n memory_in_gbs = var.memory_in_gbs\n ocpus = var.ocpus\n }\nsource_details {\n source_id = var.image_ocid\n source_type = \"이미지\"\n }\n#이미지 OCID’S https://docs.oracle.com/en-us/iaas/images/image/bd616d0a-fae4-490e-bd31-a9406095b844/\n create_vnic_details {\n assign_ipv6ip = false\n assign_private_dns_record = true\n assign_public_ip = true\n subnet_id = oci_core_subnet.public_subnet.id\n }\nmetadata = {\n ssh_authorized_keys = var.ssh_authorized_keys\n }\nagent_config {\n is_management_disabled = false\n is_monitoring_disabled = false\nplugins_config {\n desired_state = \"사용 안 함\"\n name = \"취약점 스캐닝\"\n }\n plugins_config {\n desired_state = \"사용 안 함\"\n name = \"관리 에이전트\"\n }\n plugins_config {\n desired_state = \"사용함\"\n name = \"사용자 지정 로그 모니터링\"\n }\n plugins_config {\n desired_state = \"사용 안 함\"\n name = \"컴퓨팅 RDMA GPU 모니터링\"\n }\n plugins_config {\n desired_state = \"사용함\"\n name = \"컴퓨팅 인스턴스 모니터링\"\n }\n plugins_config {\n desired_state = \"사용 안 함\"\n name = \"컴퓨팅 HPC RDMA 자동 구성\"\n }\n plugins_config {\n desired_state = \"사용 안 함\"\n name = \"컴퓨팅 HPC RDMA 인증\"\n }\n plugins_config {\n desired_state = \"사용함\"\n name = \"클라우드 가드 워크로드 보호\"\n }\n plugins_config {\n desired_state = \"사용 안 함\"\n name = \"블록 볼륨 관리\"\n }\n plugins_config {\n desired_state = \"사용 안 함\"\n name = \"바스천\"\n }\n }\navailability_config {\n is_live_migration_preferred = true\n recovery_action = \"인스턴스 복원\"\n }\nplatform_config {\n is_symmetric_multi_threading_enabled = true\n type = \"AMD_VM\"\n }\ninstance_options {\n are_legacy_imds_endpoints_disabled = false\n }\n}\n```\n\nwindowsvm.tf\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n리소스 \"oci_core_instance\" \"windows_instance\" {\n for_each = {\n kingslanding = {\n name = \"kingslanding\"\n private_ip_address = \"192.168.56.10\"\n admin_username = \"ansible\"\n admin_password = \"8dCT-DJjgScp\"\n image_ocid = var.windows2019_image_ocid\n }\n winterfell = {\n name = \"winterfell\"\n private_ip_address = \"192.168.56.11\"\n admin_username = \"ansible\"\n admin_password = \"NgtI75cKV+Pu\"\n image_ocid = var.windows2019_image_ocid\n }\n castelblack = {\n name = \"castelblack\"\n private_ip_address = \"192.168.56.22\"\n admin_username = \"ansible\"\n admin_password = \"NgtI75cKV+Pu\"\n image_ocid = var.windows2019_image_ocid\n }\n meereen = {\n name = \"meereen\"\n private_ip_address = \"192.168.56.12\"\n admin_username = \"ansible\"\n admin_password = \"Ufe-bVXSx9rk\"\n image_ocid = var.windows2016_image_ocid\n }\n braavos = {\n name = \"braavos\"\n private_ip_address = \"192.168.56.23\"\n admin_username = \"ansible\"\n admin_password = \"978i2pF43UJ-\"\n image_ocid = var.windows2016_image_ocid\n }\n }\navailability_domain = var.availability_domain\n compartment_id = var.compartment_ocid\n display_name = each.value.name\n shape = \"VM.Standard.E5.Flex\"\nshape_config {\n ocpus = 2\n memory_in_gbs = 32\n }\nsource_details {\n source_id = each.value.image_ocid\n source_type = \"image\"\n }\ncreate_vnic_details {\n assign_ipv6ip = false\n assign_private_dns_record = true\n assign_public_ip = false\n subnet_id = oci_core_subnet.private_subnet.id\n hostname_label = each.value.name\n private_ip = each.value.private_ip_address\n }\nmetadata = {\n user_data = base64encode(file(\"${path.module}/windows_cloud_init.ps1\"))\n admin_password = each.value.admin_password\n }\n}\n```\n\noutputs.tf\n\n```js\noutput \"ubuntu_jumpbox_ip\" {\n value = oci_core_instance.jumpbox.public_ip\n}\noutput \"windows_instance_opc_passwords\" {\n value = { for k, v in oci_core_instance.windows_instance : k => v.metadata.admin_password }\n sensitive = true\n}\n```\n\n프로비저닝 중 발생한 일반적인 오류입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음과 같이 Markdown 형식에 맞게 표 태그를 변경하십시오.\n\n![이미지](/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_9.png)\n\n모든 TF가 생성된 후, GOAD git 저장소가 정상적으로 동기화된 경우 다음을 실행해야 합니다:\n\nabirzu@abirzu-mac GOAD % ./goad.sh -t destroy -l GOAD -p oci -m local\n\n모든 서버가 가동되고 작동 중인 것을 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_10.png\" />\n\n축하합니다! 환경이 작동 중에 있습니다.\n\n# 서버\n\n이 랩은 실제로 다섯 개의 가상 머신으로 구성되어 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- kingslanding: DC01는 Windows Server 2019에서 실행 중입니다(기본으로 windefender가 활성화됨)\n- winterfell: DC02는 Windows Server 2019에서 실행 중입니다(기본으로 windefender가 활성화됨)\n- castelblack: SRV02는 Windows Server 2019에서 실행 중입니다(windefender가 기본적으로 비활성화됨)\n- meereen: DC03은 Windows Server 2016에서 실행 중입니다(기본으로 windefender가 활성화됨)\n- braavos: SRV03은 Windows Server 2016에서 실행 중입니다(기본으로 windefender가 활성화됨)\n\n도메인: north.sevenkingdoms.local\n\n- winterfell: DC01\n- castelblack: SRV02: MSSQL / IIS\n\n도메인: sevenkingdoms.local\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- kingslanding: DC02\n- castelrock: SRV01 (자원 부족으로 비활성화됨)\n\n# 도메인: essos.local\n\n- braavos: DC03\n- meeren: SRV03: MSSQL / ADCS\n\n인터넷에서 몇 가지 가이드를 따르거나 자신만의 방법을 찾아 시작할 수 있습니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAD | Mayfly (mayfly277.github.io)\n\nSolving Game of Active Directory (GOAD) by Orange Cyberdefense Part-1 | by n00🔑 | Medium\n\n제1부에서는 OCI에서 GOAD 랩을 만드는 방법을 소개했고, 다음 부분에서는 다음에 초점을 맞출 것입니다:\n\nOCI 통합:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n1. OCI Management Agent:\n\n- 설명: 클라우드 작업을 자동화하고 모니터링합니다.\n- 통합: GOAD 환경 내 자원의 배포 및 관리를 간소화합니다.\n\n2. Sysmon 및 로깅 분석:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n• 설명: Sysmon은 시스템 활동을 기록하여 침입 탐지를 지원합니다.\n\n• 통합: Sysmon 이벤트를 수집하고 OCI Logging Analytics로 전송하여 고급 로그 분석 및 시각화를 지원합니다. 자세한 내용은 여기에서 확인하세요.\n\n3. Arkime 통합:\n\n• 설명: Arkime은 오픈 소스 패킷 캡처 및 검색 도구입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n• 통합: 효율적인 데이터 색인 및 검색을 위해 OCI OpenSearch를 활용합니다. 자세한 내용은 여기에서 확인할 수 있습니다.\n\n4. 클라우드 가드 인스턴스 보안:\n\n• 설명: 클라우드 가드는 포괄적인 클라우드 보안 관리를 제공합니다.\n\n• 통합: 로깅 분석을 활용하여 인스턴스 보안을 강화하며 실시간 위협 감지 및 대응이 가능합니다. 더 많은 정보는 여기에서 확인할 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_0.png"},"coverImage":"/assets/img/2024-06-19-HowtorunGameofActiveDirectoryinOCIPart1_0.png","tag":["Tech"],"readingTime":20},{"title":"의존성 관리자 Dependabot GitHub 및 Terraform 버전 관리","description":"","date":"2024-06-19 13:30","slug":"2024-06-19-DependabotGitHubandTerraformversionsmanagement","content":"\n![image](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_0.png)\n\n프로젝트가 성장함에 따라 언젠가는 패키지, 모듈 및 차트 버전을 업그레이드해야 할 필요성이 생길 것입니다.\n\n물론 수동으로 할 수도 있지만, 어느 정도까지만 가능합니다. 결국에는 물리적으로 모든 업데이트 사항을 추적하고 업데이트하는 것이 불가능해질 수 있습니다.\n\n이와 같은 프로세스를 자동화하는 다양한 솔루션이 있지만, 가장 일반적으로 사용되는 것은 Renovate와 Dependabot입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우크라옵스 슬랙 투표 결과에 따르면, Renovate가 훨씬 많은 투표를 받았으며 실제로 Dependabot보다 더 많은 작업을 수행할 수 있습니다.\n\n반면, Dependabot는 이미 GitHub 저장소에서 사용 가능하며 모든 가격 요금제에서 이용 가능합니다. 그러니까, GitHub를 사용하는 경우, Dependabot을 설정하려면 구성 파일을 추가하기만 하면 됩니다. 앞으로 봤을 때, Renovate를 설정하는 것이 더 쉬우나, 다음 게시물에서 더 자세히 다루겠습니다 — Renovate: GitHub 및 Helm 차트 버전 관리.\n\n실제로, Dependabot를 거의 모든 플랫폼에서 사용할 수 있습니다 — GitHub, Github 엔터프라이즈, Azure DevOps, GitLab, BitBucket 및 AWS CodeCommit 등. Dependabot를 실행하는 방법을 확인하려면 How to run Dependabot을 참조하세요.\n\n그러나 — 이게 제게는 큰 놀램이었습니다 — Dependabot은 Helm 차트와 함께 작동하지 않습니다. 그러나 Terraform에서 작동하며 이미 일부 파이썬 코드 저장소에서 사용 가능합니다. 그러니 먼저 그것에 대해 살펴보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다시 미래를 내다보면, 저는 Renovate를 훨씬 더 좋아했고, 이후에는 Renovate를 사용할 것입니다.\n\n# Dependabot가 작동하는 방식\n\n다음은 그 방식입니다:\n\n- 저장소에 Dependabot 구성 파일을 만듭니다.\n- 파일 내에서 무엇을 정확히 확인해야 하는지 설명합니다 — pip 라이브러리, Terraform 모듈 등을\n- 특히 관심 있는 것을 설명합니다 — 보안 업데이트 또는 버전 업데이트\n- 업데이트를 발견하면 — Dependabot은 Pull Request를 만들어 해당 업데이트에 대한 상세 정보를 추가합니다\n- …\n- 수익 창출!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오늘은 무엇을 할까요?\n\n- 우리는 모니터링을 위한 GitHub 저장소를 갖고 있어요\n- 거기에 Terraform 코드가 있고\n- Dependabot을 사용하여 버전 확인 및 PR 생성을 구성할 거예요\n\n문서 — Dependabot Quick Start Guide, dependabot.yml 파일 구성 옵션.\n\n지원되는 저장소 및 생태계 — Dependabot이 지원하는 시스템을 확인하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Dependabot과 Terraform\n\nTerraform의 맥락에서 Dependabot으로 모니터링할 수 있는 것은 프로바이더 및 모듈의 버전입니다.\n\n예를 들어, 제공자 버전이 설정된 versions.tf와 여러 모듈을 사용하는 lambda.tf와 같은 두 파일이 있습니다. 모듈에는 terraform-aws-modules/security-group/aws, terraform-aws-modules/lambda/aws 등이 있습니다:\n\n![이미지](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 Dependabot가 이들에서 버전을 모니터링하도록 시작하려면 디렉토리 .github를 생성하고 그 안에 dependabot.yml 파일을 만듭니다:\n\n![이미지](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_2.png)\n\n파일에 다음과 같이 매개변수를 설정합니다:\n\n```js\nversion: 2\nupdates:\n  - package-ecosystem: \"terraform\"\n    directory: \"/terraform\"\n    schedule:\n      interval: \"daily\"\n      time: \"09:00\"\n      timezone: \"Europe/Kyiv\"\n    assignees:\n      - arseny-zinchenko\n    reviewers:\n      - arseny-zinchenko\n    open-pull-requests-limit: 10\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n보편적으로 매개변수 이름에서 모든 것이 명확해요:\n\n- package-ecosystem: 이 설정이 Terraform을 위한 것이므로, 우리는 이것을 지정합니다\n- directory: Terraform 파일은 리포지토리 루트의 terraform 디렉토리에 있습니다\n- schedule: 체크 일정 - 먼저 dependabot.yml 파일을 추가하면 체크가 즉시 시작되며, 나중에 수동으로 실행할 수 있습니다\n- assignees and reviewers: 나를 위해 즉시 PR을 만들어주세요\n- open-pull-requests-limit: 기본적으로 Dependabot은 최대 5개의 PR을 엽니다. 이 매개변수로 증가시킬 수 있습니다\n\n리포지토리에 푸쉬하고 상태를 확인해보세요.\n\n리포지토리에서 Insights `Dependency graph` Dependabot로 이동하여 체크가 시작되었음을 확인하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_3.png)\n\nIn a minute, we’ll have open Pull Requests:\n\n![image](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_4.png)\n\n![image](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n동시에, Dependabot은 업데이트에 대한 세부 정보를 주석으로 추가합니다 — 릴리스 노트, 변경 내역 등:\n\n![이미지](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_6.png)\n\n그러나 이 모든 것이 어디서는 안 될 수도 있습니다.\n\n예를 들어, Lambda 모듈의 업데이트는 세부 정보 없이 생성되었습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_7.png)\n\nBut Renovate does it much better.\n\n# Dependabot, and GitHub Secrets\n\nAnother nuance is the GitHub Secrets that are available to Dependabot.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로젝트의 terraform 디렉토리에 변경 내용이 있는 PR이 올라오면, 우리는 GitHub Actions Workflow를 실행합니다. 해당 Workflow에서는 Terraform의 체크를 수행합니다 (GitHub Actions: Terraform deployments with a review of planned changes 참조).\n\n이 Workflow는 전용 저장소에 위치해 있으며, 접근하기 위해 GitHub 배포용 키가 GitHub Actions Secrets를 통해 호출하는 Workflow로 전달됩니다.\n\n그러나 Dependabot에서 시작된 GitHub Actions 작업에서 다음 단계가 실패했습니다:\n\n![Dependabot Error](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n워크플로 자체는 모든 비밀을 secrets: inherit:를 통해 전달합니다.\n\n```js\n...\njobs:\n  terraform-test:\n    # Reusable Workflow 파일 호출\n    uses: ORG_NAME/atlas-github-actions/.github/workflows/call-terraform-check-and-plan.yml@master\n    with:\n      aws-iam-role: ${ vars.AWS_IAM_ROLE }\n      aws-env: ${ vars.AWS_ENV }\n      pr-num: ${ github.event.pull_request.number }\n      environment: ops\n      slack-channel: '#cicd-devops'\n    secrets:\n      inherit\n```\n\n그러나 Dependabot에서는 이러한 비밀 정보를 Actions의 secrets 및 변수가 아닌 Actions의 secrets와 변수인 Dependabot에 별도로 설정해야 합니다:\n\n<img src=\"/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_9.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n새로운 비밀을 추가했고, 이제 확인이 작동합니다:\n\n![Dependabot, and private registries/repositories](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_10.png)\n\n# Dependabot 및 개인 레지스트리/저장소\n\n다른 것들 중에, 우리는 개인 저장소에 저장된 자체 Terraform 모듈을 가지고 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n의존성 보트에 액세스할 때 \"의존성 보트가 ORG_NAME/atlas-tf-modules에 액세스할 수 없습니다\"라는 오류가 발생합니다:\n\n![image](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_11.png)\n\n첫 번째 옵션은 dependabot.yml 파일에서이 저장소 또는 다른 레지스트리를 명시적으로 추가하는 것입니다. - 개인 레지스트리 구성 항목 참조.\n\n두 번째 옵션은 단순히 '액세스 권한 부여'를 클릭하는 것입니다. 이렇게 하면 조직의 모든 저장소에 대해 해당 저장소의 액세스가 열립니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n해당 테이블 태그를 마크다운 형식으로 변경하거나 수동으로 변경하세요. 조직 설정으로 이동한 후 `보안 코드` 및 `전역 설정`으로 이동하여 `사적 저장소에 Dependabot 액세스 권한 부여` 섹션에서 원하는 저장소에 대한 액세스를 추가하세요:\n\n![Dependabot GitHub and Terraform versions management](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_12.png)\n\n# Dependabot 및 수동 실행\n\n접근 권한을 추가했다면, 다시 저장소로 돌아가 Insights -> Dependency graph -> Dependabot으로 이동한 후 업데이트 확인을 클릭하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래와 같이 작동 중입니다:\n\n![Image 1](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_13.png)\n\n![Image 2](/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_14.png)\n\n일반적으로 그게 전부에요. 이제 우리는 모든 저장소를 직접 관리하지 않아도 Terraform 업데이트를 받게 될 거예요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n한번 더 말해도, Renovate가 정말로 더 좋아. Renovate: GitHub을 보고, Helm Charts 버전 관리를 확인해봐.\n\n원문은 RTFM: Linux, DevOps, 그리고 시스템 관리에서 공개되었습니다.\n","ogImage":{"url":"/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_0.png"},"coverImage":"/assets/img/2024-06-19-DependabotGitHubandTerraformversionsmanagement_0.png","tag":["Tech"],"readingTime":11},{"title":"Azure Storage Account에 개인 엔드포인트와 Terraform을 사용하여 컨테이너 문제 해결하는 방법","description":"","date":"2024-06-19 13:28","slug":"2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform","content":"\n<img src=\"/assets/img/2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform_0.png\" />\n\n오늘은 Terraform으로 Azure Storage Account와 Private Endpoint를 배포할 때 발생하는 일반적인 오류에 대해 이야기해보겠습니다.\n\n저희가 스토리지 계정 컨테이너를 추가하려고 시도하면, 다음과 같은 오류가 발생합니다:\n\n# 1. 우리의 시나리오\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 테라폼이 실행 중인 가상 머신이 있습니다.\n\n- 리소스 그룹 \"kopicloud-core-dev-we-rg\"\n- 가상 네트워크 \"kopicloud-core-dev-we-vnet\"\n- 서브넷 \"kopicloud-core-dev-we-subnet\"\n\n2. 기존의 \"privatelink.blob.core.windows.net\" 프라이빗 DNS 영역이 있습니다.\n\n- 리소스 그룹 \"kopicloud-core-dev-we-dns-rg\"\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 새로운 Azure Storage Account와 프라이빗 엔드포인트를 배포할 것입니다.\n\n- 리소스 그룹 \"kopicloud-storage-dev-we-rg\"\n- 가상 네트워크 \"kopicloud-storage-dev-we-vnet\"\n- 서브넷 \"kopicloud-storage-dev-we-endpoint-subnet\"\n\n# 2. Azure Storage Account와 프라이빗 엔드포인트를 배포하는 Terraform 코드\n\n이 코드에 대해 설명은 이 이야기에서 하지 않겠습니다. 더 자세한 내용은 \"Terraform을 사용한 Azure Storage Account의 프라이빗 엔드포인트\" 이야기를 확인해주세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 \"network-variables.tf\" 파일입니다:\n\n```js\nvariable \"network-vnet-cidr\" {\n  type        = string\n  description = \"네트워크 VNET의 CIDR\"\n}\n\nvariable \"network-endpoint-subnet-cidr\" {\n  type        = string\n  description = \"네트워크 서브넷의 CIDR\"\n}\n```\n\n아래는 \"network.tf\" 파일입니다:\n\n```js\n# 네트워크를 위한 리소스 그룹 생성\nresource \"azurerm_resource_group\" \"network-rg\" {\n  name     = \"kopicloud-storage-dev-we-rg\"\n  location = var.location\n}\n\n# 네트워크 VNET 생성\nresource \"azurerm_virtual_network\" \"network-vnet\" {\n  name                = \"kopicloud-storage-dev-we-vnet\"\n  address_space       = [var.network-vnet-cidr]\n  resource_group_name = azurerm_resource_group.network-rg.name\n  location            = azurerm_resource_group.network-rg.location\n}\n\n# Endpoint 서브넷 생성\nresource \"azurerm_subnet\" \"endpoint-subnet\" {\n  name                 = \"kopicloud-storage-dev-we-endpoint-subnet\"\n  address_prefixes     = [var.network-endpoint-subnet-cidr]\n  virtual_network_name = azurerm_virtual_network.network-vnet.name\n  resource_group_name  = azurerm_resource_group.network-rg.name\n\n  private_endpoint_network_policies_enabled = true\n\n  service_endpoints = [\"Microsoft.Storage\"]\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\"storage-account.tf\" 파일:\n\n```js\n# 기존 Private DNS Zone 참조\ndata \"azurerm_private_dns_zone\" \"dns-zone\" {\n  name                = \"privatelink.blob.core.windows.net\"\n  resource_group_name = \"kopicloud-core-dev-we-dns-rg\"\n}\n\n# Private DNS Zone 네트워크 링크 생성\nresource \"azurerm_private_dns_zone_virtual_network_link\" \"network_link\" {\n  name                  = \"kopicloud-storage-dev-we-vnet-link\"\n  resource_group_name = data.azurerm_private_dns_zone.dns-zone.resource_group_name\n  private_dns_zone_name = data.azurerm_private_dns_zone.dns-zone.name\n  virtual_network_id    = azurerm_virtual_network.network-vnet.id\n}\n\n# 스토리지 계정 생성\nresource \"azurerm_storage_account\" \"storage\" {\n  name                = \"kopicloudstoragedevwesta\"\n  resource_group_name = azurerm_resource_group.network-rg.name\n  location            = azurerm_resource_group.network-rg.location\n\n  account_kind             = \"StorageV2\"\n  account_tier             = \"Standard\"\n  account_replication_type = \"LRS\"\n}\n\n# 프라이빗 엔드포인트 생성\nresource \"azurerm_private_endpoint\" \"endpoint\" {\n  name                = \"kopicloudstoragedevwesta-pe\"\n  resource_group_name = azurerm_resource_group.network-rg.name\n  location            = azurerm_resource_group.network-rg.location\n  subnet_id           = azurerm_subnet.endpoint-subnet.id\n\n  private_service_connection {\n    name                           = \"kopicloudstoragedevwesta-psc\"\n    private_connection_resource_id = azurerm_storage_account.storage.id\n    is_manual_connection           = false\n    subresource_names              = [\"blob\"]\n  }\n}\n\n# DNS A 레코드 생성\nresource \"azurerm_private_dns_a_record\" \"dns_a\" {\n  name                = \"kopicloudstoragedevwesta\"\n  resource_group_name = data.azurerm_private_dns_zone.dns-zone.resource_group_name\n  zone_name = data.azurerm_private_dns_zone.dns-zone.name\n  ttl                 = 300\n  records             = [azurerm_private_endpoint.endpoint.private_service_connection.0.private_ip_address]\n}\n```\n\n# 3. 공개 액세스 해제\n\n기본적으로 이 코드는 공개 액세스가 있는 스토리지 계정을 생성합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform_1.png)\n\n공개 액세스를 종료해야만 Private Endpoint를 구현하는 의미가 있습니다.\n\n따라서 \"azurerm_storage_account\" 리소스를 수정하여 public_network_access_enabled = false 라인을 추가하겠습니다.\n\n```js\n// 스토리지 계정 생성\nresource \"azurerm_storage_account\" \"storage\" {\n  name                = \"${lower(replace(var.company,\" \",\"-\"))}${var.app_name}${var.environment}${var.shortlocation}sta\"\n  resource_group_name = azurerm_resource_group.network-rg.name\n  location            = azurerm_resource_group.network-rg.location\n\n  account_kind             = \"StorageV2\"\n  account_tier             = \"Standard\"\n  account_replication_type = \"LRS\"\n\n  public_network_access_enabled = false\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\"Terraform Apply\" 명령을 실행하여 공개 액세스가 비활성화되었음을 확인했습니다.\n\n![이미지](/assets/img/2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform_2.png)\n\n# 4. 스토리지 계정 컨테이너 생성\n\n이제 다음 코드로 스토리지 계정 컨테이너를 생성할 차례입니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n// 외부 저장소 계정용 Azure Storage 컨테이너 생성\nresource \"azurerm_storage_container\" \"external\" {\n  name                  = \"container\"\n  storage_account_name  = azurerm_storage_account.storage.name\n  container_access_type = \"private\"\n}\n```\n\n\"Terraform Apply\" 명령을 실행했는데 오류가 발생했습니다.\n\n# 4. 특정 네트워크에서 액세스 권한 활성화\n\n따라서 이 문제를 해결하기 위해 특정 네트워크에서의 공개 액세스를 허용할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼 \"azurerm_storage_account\" 리소스를 수정하여 public_network_access_enabled = true 라인을 추가하겠습니다.\n\n```js\n// 저장소 계정 생성\nresource \"azurerm_storage_account\" \"storage\" {\n  name                = \"${lower(replace(var.company,\" \",\"-\"))}${var.app_name}${var.environment}${var.shortlocation}sta\"\n  resource_group_name = azurerm_resource_group.network-rg.name\n  location            = azurerm_resource_group.network-rg.location\n  account_kind             = \"StorageV2\"\n  account_tier             = \"Standard\"\n  account_replication_type = \"LRS\"\n\n  public_network_access_enabled = true\n}\n```\n\n또한 지정된 네트워크에서 액세스 허용하도록 \"Azure Storage Account Network Rules\" 리소스를 생성해야 합니다; 이 경우 Storage Account Subnet에서 액세스를 허용할 것입니다.\n\n```js\n# Azure Storage Account Network Rules 생성\nresource \"azurerm_storage_account_network_rules\" \"rules\" {\n  storage_account_id = azurerm_storage_account.storage.id\n\n  default_action = \"Deny\"\n  virtual_network_subnet_ids = [ azurerm_subnet.endpoint-subnet.id ]\n  bypass         = [\"Metrics\", \"Logging\", \"AzureServices\"]\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n“Terraform Apply” 명령을 실행했을 때 다시 403 오류가 발생했어요.\n\n# 5. Azure Storage Account 네트워크 규칙 업데이트\n\n가시성을 위해 규칙을 변경하여 VM이 Terraform을 실행할 때 서브넷에서의 트래픽을 허용하도록 할게요. 우리는 데이터를 사용하여 서브넷 ID를 가져올 거에요.\n\n```js\n# 핵심 서브넷을 참조합니다\ndata \"azurerm_subnet\" \"core\" {\n  name                 = \"kopicloud-core-dev-we-subnet\"\n  virtual_network_name = \"kopicloud-core-dev-we-vnet\"\n  resource_group_name  = \"kopicloud-core-dev-we-rg\"\n}\n\n# Azure Storage Account 네트워크 규칙 생성\nresource \"azurerm_storage_account_network_rules\" \"rules\" {\n  storage_account_id = azurerm_storage_account.storage.id\n\n  default_action = \"Deny\"\n  virtual_network_subnet_ids = [ azurerm_subnet.endpoint-subnet.id, data.azurerm_subnet.core.id ]\n  bypass         = [\"Metrics\", \"Logging\", \"AzureServices\"]\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\"Terraform Apply\" 명령을 실행했는데 다시 403 오류가 발생했어요.\n\n포털을 살펴보니 규칙이 구현되지 않았다는 것을 알았어요. 컨테이너가 이전에 실패했기 때문이에요.\n\n<img src=\"/assets/img/2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform_3.png\"/>\n\n# 6. 코어와 스토리지 가상 네트워크 간 피어링 생성하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 후에, 어쩌면 두 가상 네트워크 사이에 피어링이 필요할지도 모른다고 생각했어요.\n\n그래서 \"peering.tf\" 파일을 만들고 이 코드를 추가했어요:\n\n```js\nlocals {\n  core_rg_name = \"kopicloud-core-dev-we-rg\"\n  core_vnet_name = \"kopicloud-core-dev-we-vnet\"\n}\n\n// Core VNET에 대한 참조\ndata \"azurerm_virtual_network\" \"core\" {\n  name                = local.core_vnet_name\n  resource_group_name = local.core_rg_name\n}\n\n// Core에서 스토리지로 피어링 생성\nresource \"azurerm_virtual_network_peering\" \"core-to-storage\" {\n  name                      = \"Core-to-Storage\"\n  resource_group_name       = local.core_rg_name\n  virtual_network_name      = local.core_vnet_name\n  remote_virtual_network_id = azurerm_virtual_network.network-vnet.id\n}\n\n// 스토리지에서 Core로 피어링 생성\nresource \"azurerm_virtual_network_peering\" \"storage-to-core\" {\n  name                      = \"Storage-to-Core\"\n  resource_group_name       = azurerm_resource_group.network-rg.name\n  virtual_network_name      = azurerm_virtual_network.network-vnet.name\n  remote_virtual_network_id = data.azurerm_virtual_network.core.id\n}\n```\n\n그리고 \"Terraform Apply\" 명령어를 실행했더니, 마침내 우리 코드가 잘 실행되고 있어요!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n최종 네트워크 구성은 다음과 같아야 합니다:\n\n![이미지](/assets/img/2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform_4.png)\n\n그리고 이것이 전부에요. 만약 이 이야기를 좋아하셨다면 👏을 눌러 서포트를 보여주세요. 읽어 주셔서 감사합니다!\n","ogImage":{"url":"/assets/img/2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoTroubleshootanAzureStorageAccountwithaPrivateEndpointandaContainerwithTerraform_0.png","tag":["Tech"],"readingTime":12},{"title":"2024년에 사용할 수 있는 가장 유용한 Terraform 도구들","description":"","date":"2024-06-19 13:26","slug":"2024-06-19-MostUsefulTerraformToolstoUsein2024","content":"\n개발자로서 2년정도 경력이 있고, 많은 도구들이 갑자기 등장하는 것을 보았어요. 요즘 제품을 쉽게 만들기 때문만이 아니라, 전체 Terraform 개발 라이프사이클 내에서 해결해야 할 많은 문제들이 있기 때문이에요. 그리고 제품의 각 미세 카테고리에서 오픈 소스, 무료, 프리미엄, 또는 맞춤 요금제와 같이 수천 가지 선택지가 있는 걸 잊지 마세요.\n\n그래서, 여기 귀하는 위한 모든 것을 간단히 해주기 위해 발견하고 철저히 테스트한 최고의 해결책을 소개합니다:\n\n# 전통적인 데브옵스 엔지니어가 사용하는 도구\n\n![Most Useful Terraform Tools to Use in 2024](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 할 일은 Infrastructure as Code (IaC)의 기본 형태로 돌아가서 엔지니어들이 일을 어떻게 하는지와 전체 라이프사이클이 얼마나 어려운지를 이해하는 것이었습니다.\n\n## 인프라 다이어그램:\n\n인프라 다이어그램은 종종 화이트보드에 그려졌습니다. Microsoft Visio나 Draw.io가 최고의 다이어그램 솔루션이었지만, 이 다이어그램들은 그저 다이어그램일 뿐이었고 종종 오래되어 있었습니다.\n\n## 코드 정의:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n공학자들은 CLI(Command Line Interface)를 사용하여 코드를 정의했어요.\n\n## 버전 관리 및 배포:\n\n오픈 소스 인프라스트럭처 코드(IaC) 도구인 terraform과 같은 도구들이 인프라 버전 관리에 인기를 끌게 되었어요. 지금은 OpenTofu와 같은 것이 등장해서, 좀 다른 것 같아요. 모든 것은 Git을 통해 배포되었어요.\n\n## 인프라스트럭처 관리:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n전체 인프라는 클라우드 제공 업체 콘솔을 통해 관리되었습니다. 클라우드 제공 업체 중심의 자원 관리가 일반적이었습니다.\n\n## 모니터링:\n\nDatadog와 같은 도구가 등장하기 전에는 홈메이드 제품이 초기에 인프라 모니터링에 사용되었습니다.\n\n## 보안 도구:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오픈 소스 보안 도구들은 여전히 널리 사용되고 있어요. Terrascan, Checkov, 그리고 OPA (Open Policy Agent)와 같은 도구들은 여전히 중요합니다.\n\n# Terraform을 위한 도구들\n\n![이미지](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_1.png)\n\n## TFLint: 코드 품질\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_2.png\" />\n\nTFLint는 Terraform을 위한 강력한 오픈 소스 린트 도구로 솟아납니다. 그 실력은 구문 오류부터 리소스 명명 규칙 및 사용되지 않는 변수까지 다양한 문제를 식별하는 데 있습니다. TFLint는 여러분의 도구 상자의 필수품으로, Terraform 코드가 높은 품질 기준을 준수하도록 보장합니다.\n\n## Terrascan: 보안 및 규정 준수\n\n<img src=\"/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_3.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nTerrascan은 보안 및 규정 준수에 초점을 맞춘 정적 코드 분석기로 무대에 올라섭니다. 전통적인 린트 이상으로 나아가 구성 오류, 보안이 취약한 리소스 설정 및 정책 위반을 식별합니다. 보안이 최우선 사항인 만큼 Terrascan은 Terraform 인프라를 견고하게 만들어 주는 경계를 지킵니다.\n\n## Checkov: Hashicorp Sentinel 대체안\n\n![이미지](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_4.png)\n\nCheckov은 인프라 코드 파일을 세심하게 검사하는 보안 스캐너로 등장합니다. Checkov의 역할은 Terraform 코드를 면밀히 검사하여 보안 취약성과 정책 위반 사항을 발견하는 것입니다. 사이버 보안이 중요시되는 시대에, Checkov은 감시병으로 작용하여 귀하의 인프라가 견고하고 규정을 준수할 수 있도록 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 인프라코스트: 클라우드 비용\n\n![이미지](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_5.png)\n\n테라폼 배포 비용을 예측하는 것은 효과적인 예산 편성에 중요합니다. 인프라코스트는 오픈 소스 툴로, 정확한 비용 추정을 제공하여 이러한 요구를 지원합니다. 다양한 클라우드 공급업체와 온프레미스 인프라를 수용함으로써 인프라코스트는 인프라 요구 사항을 절충하지 않고 예산 제약 내에서 유지할 수 있도록 합니다.\n\n## 브레인보드: 테라폼 GUI\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Brainboard](https://miro.medium.com/v2/resize:fit:1400/1*F9cAb0NT-xSvFhnEXx9SiQ.gif)\n\nBrainboard은 클라우드 인프라 관리를 위한 최첨단 플랫폼으로 나타납니다. 그 강점은 복잡한 클라우드 아키텍처를 디자인, 배포 및 관리하는 직관적인 시각적 인터페이스를 제공하는 데 있습니다. 프로세스를 단순화하고 협업을 강화함으로써, Brainboard는 클라우드 인프라를 효율적이고 확장 가능하게 만들어 현대의 데브옵스 팀에게 꼭 필요한 도구가 됩니다.\n\n## Terragrunt: Module Management\n\n![Terragrunt](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_6.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nTerragrunt은 Terraform 모듈의 조정 및 배포를 관리하는 도구입니다. 모듈 처리 기능 이상으로, Terragrunt은 Terraform 테스트를 용이하게하고 전체 개발 수명주기를 최적화하는 데 능숙합니다.\n\n## Terradozer: 사용되지 않는 인프라를 위한\n\n![Terradozer](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_7.png)\n\nTerradozer는 강력한 정리 도구로 등장하여 Terraform 상태 파일의 모든 리소스를 파괴하는 것을 목적으로 합니다. 이 기능은 사용되지 않는 인프라를 정리하고 효율적인 환경을 조성하는 데 매우 소중합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Eagle-Eye: 종속성 시각화\n\n![이미지](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_8.png)\n\n이글 아이(Eagle-Eye)란 복잡한 Terraform 구성을 탐색하는 것이 더 쉬워집니다. AWS를 위한 이 강력한 시각화 도구는 리소스 간 종속성에 대한 상세한 그래픽 표현을 생성하여 디버깅 및 복잡한 인프라 구성 이해에 중요한 통찰을 제공합니다.\n\n## DiagramGPT: D2 다이어그램\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_9.png)\n\nEraser.io의 DiagramGPT는 자연어 프롬프트를 사용하여 다이어그램을 만드는 혁신적인 도구로 빛을 발합니다. 고급 AI 기술을 활용하여 텍스트 설명에서 자세하고 정확한 다이어그램을 생성하는 과정을 간단화합니다. 이 도구는 생산성과 명확성을 향상시켜 전문가들이 문서 작성과 시각화 작업을 간소화하는 데 꼭 필요한 자산입니다.\n\n하나의 도구로는 모든 요구 사항이 충족되지 않지만, 특정 요구 사항마다 완벽한 도구가 있습니다. 현명하게 선택하고 도구 상자에 새로운 도구를 추가해야 하는지 알려주세요.\n","ogImage":{"url":"/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_0.png"},"coverImage":"/assets/img/2024-06-19-MostUsefulTerraformToolstoUsein2024_0.png","tag":["Tech"],"readingTime":7},{"title":"테라폼을 이용한 AWS 인프라 배포와 앤서블을 이용한 구성 설정","description":"","date":"2024-06-19 13:24","slug":"2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible","content":"\n# 소개:\n\n현재의 동적 클라우드 컴퓨팅 환경에서는 인프라 프로비저닝을 자동화하는 것이 확장성, 신뢰성, 및 비용 효율성을 원하는 기관들에게 필수적입니다. Terraform은 오픈 소스 인프라 코드 도구로, 선언적 구성 파일을 사용하여 인프라를 정의하고 관리할 수 있도록 팀에게 권한을 부여합니다. 이 블로그에서는 Terraform이 AWS 인프라 구성 요소의 배포를 체계적이고 효율적으로 간소화하는 방법을 탐색해보겠습니다.\n\n# 프로젝트 개요:\n\n우리 Terraform 프로젝트는 가상 사설 클라우드(VPC), 보안 그룹, Amazon Machine Image(AMI), Elastic Block Store(EBS) 볼륨, 및 EC2 인스턴스로 구성된 AWS 인프라 스택의 배포를 자동화하는 데 초점을 맞춥니다. Terraform의 모듈식이자 반복 가능한 구성을 활용하여 환경 간 일관성과 신뢰성을 보장하고, 수동 개입과 인적 오류를 최소화합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 상세 단계:\n\n## 1. AWS CLI 설치하기:\n\n- 먼저 로컬 컴퓨터에 AWS CLI를 설치해야 합니다.\n- 다음 링크를 따라 AWS CLI를 설치하세요:\n\n![AWS CLI 설치 링크](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- AWS CLI를 이곳에서 다운로드하여 계정에 구성하세요.\n- 또는 Linux 버전을 선택하여 설치할 수도 있습니다.\n- 이를 위해 계정에 IAM 사용자를 만들어야 합니다.\n\n![이미지1](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_1.png)\n\n![이미지2](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_2.png)\n\n- 현재는 관리자 액세스를 제공하지만 좋은 실천 방법은 아닙니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_3.png](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_3.png)\n\n![2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_4.png](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_4.png)\n\n- 보안 자격 증명에서 \"액세스 키 생성\" 옵션을 클릭하여 액세스 키 및 비밀 키를 생성하고 둘 다 복사합니다.\n\n![2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_5.png](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Access Key ID에 액세스 키를 붙여 넣고, Secret Access Key ID에 비밀 키를 입력해주세요. 그리고 설정하고 싶은 기본 지역도 지정해주세요.\n\n## 2. Terraform 초기화하기.\n\n- main.tf 파일을 생성하고, 제공자(provider) 구성을 거기에 입력해주세요.\n\n```js\n# main.tf\n\n# Provider configuration\nprovider \"aws\" {\n  region = \"us-west-1\"\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 그럼 아래 명령어를 입력해주세요.\n\n```js\nterraform.exe init\n```\n\n## 3. VPC 생성:\n\n우리는 VPC 구성을 정의합니다. CIDR 블록을 포함하여 네트워크 구조의 기반을 마련합니다. 이는 AWS 환경 내에서 격리되고 안전한 통신을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 이 프로젝트 전체에 대해 동일한 main.tf 파일을 사용할 것입니다.\n\n```js\n# main.tf\n\nresource \"aws_vpc\" \"vpc\"{\n        cidr_block = \"192.168.0.0/16\"\n\n        tags = {\n                Name = \"Terraform_VPC\"\n        }\n}\n```\n\n## 4. 서브넷 생성:\n\n- 이제 서브넷 구성을 정의합니다. 이 구성에는 공용 서브넷과 사설 서브넷이 모두 포함됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# main.tf\n\n변수 \"aws_azs\"를 정의합니다. 여기에는 public 서브넷의 가용 영역이 저장됩니다. 그리고 public 서브넷의 CIDR 블록을 저장하는 다른 변수를 만듭니다.\n\n그런 다음 각 가용 영역에 2개의 public 서브넷을 만듭니다.\n- length 함수는 주어진 목록, 맵 또는 문자열의 길이를 결정합니다. 목록이나 맵이 주어지면 해당 컬렉션의 요소 수가 결과로 나옵니다.\n- element() 함수는 목록에서 특정 인덱스의 요소를 검색합니다. 사용 사례: 목록에서 특정 요소에 액세스하는 것은 해당 인덱스를 기준으로 목록에서 특정 리소스나 매개변수를 선택하려고 할 때 유용합니다.\n- count.index 객체는 count 내의 현재 인스턴스의 인덱스를 나타냅니다. 인덱스는 0부터 시작하며, count가 4인 리소스가 있으면 count.index 객체는 0, 1, 2 및 3이 됩니다.\n- 그런 다음 private 서브넷을 만드는 동일한 단계를 반복합니다.\n\n## 5. Internet-Gateway 및 Route-table 생성:\n\n이제 public 서브넷에 인터넷에 연결할 Internet-Gateway를 만들 것입니다. 이를 위해 라우팅 테이블도 생성하여 경로를 만들어야 합니다.\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# main.tf\n\nresource \"aws_internet_gateway\" \"igw\" {\n        vpc_id = aws_vpc.vpc.id\n        tags = {\n                Name = \"terrform-vpc-igw\"\n        }\n}\n\nresource \"aws_route_table\" \"second-rt\" {\n        vpc_id = aws_vpc.vpc.id\n        route {\n                cidr_block = \"0.0.0.0/0\"\n                gateway_id = aws_internet_gateway.igw.id\n        }\n\n        tags = {\n                Name = \"Public-route-table\"\n        }\n}\n\nresource \"aws_route_table_association\" \"public-subnets-asso\" {\n        count = length(var.public_subnet_cidrs)\n        subnet_id = element(aws_subnet.public_subnets[*].id, count.index)\n        route_table_id = aws_route_table.second-rt.id\n}\n```\n\n- 여기서, 먼저 VPC 내에서 인터넷 게이트웨이를 생성합니다.\n- 그런 다음 인터넷 게이트웨이를 통해 안전한 인터넷 연결을 가능하게 하는 라우트를 생성하는 라우트 테이블을 만듭니다.\n- 그런 다음 이 라우트 테이블과 공용 서브넷을 연결해야합니다.\n\n## 6. 보안 그룹 구성:\n\nEC2 인스턴스로의 들어오고 나가는 트래픽을 제어하기 위해 보안 그룹 규칙을 지정합니다. 이렇게 하면 사전 정의된 규칙 세트에 따라 액세스를 제한하여 네트워크 보안이 강화되며 잠재적인 보안 취약점을 완화할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nresource \"aws_security_group\" \"sg\" {\n    name        = \"terraform_sg\"\n    description = \"This security group is for terraform practice\"\n    vpc_id      = aws_vpc.vpc.id\n\n    tags = {\n        Name = \"terraform_vg\"\n    }\n}\n\nresource \"aws_vpc_security_group_ingress_rule\" \"sg_in_rule\" {\n    security_group_id = aws_security_group.sg.id\n    cidr_ipv4        = \"0.0.0.0/0\"\n    from_port        = 80\n    ip_protocol      = \"tcp\"\n    to_port          = 80\n}\n\nresource \"aws_vpc_security_group_ingress_rule\" \"sg_in_rule2\" {\n    security_group_id = aws_security_group.sg.id\n    cidr_ipv4        = \"0.0.0.0/0\"\n    from_port        = 22\n    ip_protocol      = \"tcp\"\n    to_port          = 22\n}\n\nresource \"aws_vpc_security_group_egress_rule\" \"sg_eg_rule\" {\n    security_group_id = aws_security_group.sg.id\n    cidr_ipv4         = \"0.0.0.0/0\"\n    ip_protocol       = \"-1\" # semantically equivalent to all ports\n}\n```\n\n- 먼저 VPC 내에서 보안 그룹을 만듭니다.\n- 그런 다음 보안 그룹에 대한 인바운드 규칙을 정의하여 클라이언트가 포트 80 및 22에 도달할 수 있도록 허용합니다.\n- 그런 다음 아무 포트에서 어디로든 연결을 허용하는 보안 그룹에 대한 아웃바운드 규칙을 정의합니다.\n\n## 7. 데이터 소스를 활용한 AMI 구성:\n\nTerraform의 데이터 소스를 활용하여 지정된 필터에 따라 기존 AWS AMI에 대한 정보를 가져올 수 있습니다. 이러한 필터는 지역, 운영 체제 및 아키텍처와 같은 미리 정의된 것으로 구성됩니다. 이는 EC2 인스턴스에 가장 적합한 AMI를 동적으로 선택함으로써 배포 간의 호환성 및 일관성을 보장합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndata \"aws_ami\" \"rhel9\" {\n        most_recent = true\n\n        owners = [\"309956199498\"] // Red Hat의 계정 ID.\n\n        filter {\n                name   = \"architecture\"\n                values = [\"x86_64\"]\n        }\n\n        filter {\n                name   = \"root-device-type\"\n                values = [\"ebs\"]\n        }\n\n        filter {\n                name   = \"virtualization-type\"\n                values = [\"hvm\"]\n        }\n\n        filter {\n                name   = \"name\"\n                values = [\"RHEL-9.*\"]\n        }\n}\n```\n\n- 데이터 소스는 외부 시스템이나 기존 리소스에서 정보를 조회하고 해당 정보를 Terraform 구성에 통합하는 데 사용됩니다.\n\n## 8. EC2 인스턴스 프로비저닝:\n\n인스턴스 유형, 키페어, 보안 그룹을 포함한 EC2 인스턴스 구성을 정의합니다. Terraform은 VPC 내에서 EC2 인스턴스를 프로비저닝하여 지정된 구성을 준수하면서 연결성과 리소스 격리를 보장합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```json\n파일 이름 : main.tf\n```\n\n## 3. EC2 인스턴스 생성 :\n\n이 코드는 Terraform을 사용하여 AWS EC2 인스턴스를 생성하는 예시입니다. 우리는 AMI ID, 인스턴스 유형, 키 이름, 서브넷 ID, 보안 그룹 ID 등을 정의하고 있습니다. 이를 통해 인프라스트럭처 스택에 EC2 인스턴스를 통합할 수 있습니다. 태그를 지정하여 리소스를 식별할 수도 있습니다.\n\n## 테이블\n\n| 제목                | 설명                            |\n| ------------------- | ------------------------------- |\n| AMI                 | data.aws_ami.rhel9.id           |\n| 유형                | \"t2.micro\"                      |\n| 키 이름             | \"IAM_California\"                |\n| 서브넷 ID           | aws_subnet.public_subnets[0].id |\n| VPC 보안 그룹 ID    | aws_security_group.sg.id        |\n| 퍼블릭 IP 주소 연결 | true                            |\n\n태그 :\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 이제 새로운 EBS 볼륨을 생성했습니다. 중요한 점은 ec2 인스턴스와 ebs 볼륨이 동일한 가용 영역에 있어야 한다는 것입니다. 그렇지 않으면 서로 연결할 수 없습니다.\n\n## 10. EBS 볼륨 연결\n\n이제 다음 단계는 새로 생성한 ebs 볼륨을 ec2 인스턴스에 연결하는 것입니다.\n\n```js\nresource \"aws_volume_attachment\" \"ebs_attach\" {\n        device_name = \"/dev/xvdb\"\n        volume_id = aws_ebs_volume.EBS.id\n        instance_id = aws_instance.ec2-1.id\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 11. 공용 IP 주소 출력:\n\n마지막으로, 테라폼의 출력 기능을 사용하여 프로비저닝된 EC2 인스턴스의 공용 IP 주소를 표시합니다. 이는 관리자와 최종 사용자 모두가 인스턴스에 쉽게 액세스하고 관리할 수 있도록 합니다.\n\n```js\noutput \"ec2_instance_ip\" {\n        value = aws_instance.ec2-1.public_ip\n}\n```\n\n## 12. 테라폼 파일 적용하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금은 여태까지 AWS 인프라를 만든 main.tf 파일을 적용할 것입니다.\n\n```js\nterraform.exe apply\n```\n\n![AWS Infrastructure Deployment](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_6.png)\n\n- 먼저 전체 계획을 알려줍니다. 그렇지 않으면 계획을 보는 별도의 명령어가 있습니다. 즉, terraform.exe plan\n- 계획을 알려준 후에는 앞으로 진행하고 AWS 클라우드에 적용할 것인지 물어봅니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![AWS Infrastructure Deployment with Terraform and Configuration with Ansible 7](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_7.png)\n\n![AWS Infrastructure Deployment with Terraform and Configuration with Ansible 8](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_8.png)\n\n# Let’s Go on our AWS Console to verify this deployment.\n\n## VPC ARCHITECTURE:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_9](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_9.png)\n\n![AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_10](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_10.png)\n\n## SECURITY GROUP :\n\n![AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_11](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_11.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## EC2-INSTANCE :\n\n![EC2-INSTANCE](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_12.png)\n\n# Ansible Configuration Management:\n\n인프라가 프로비저닝된 후에는 프로비저닝된 인스턴스 내에서 Ansible을 사용하여 구성 관리 작업으로 신속하게 전환합니다. Ansible은 우리에게 idempotent playbooks 및 모듈을 사용하여 복잡한 구성 작업을 자동화할 수 있는 기능을 제공하여 효율적이고 확장 가능한 인프라 관리를 가능하게 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희 프로젝트는 Terraform과 Ansible을 완벽하게 통합하여 일관된 배포 파이프라인을 구축합니다. Terraform은 인프라 스택의 기반을 마련하는 데 도움을 주고, Ansible은 프로비전된 인스턴스를 구성하여 그들이 그 의도한 목적을 위해 완전히 기능하고 최적화되도록 보장합니다.\n\n## EC2-인스턴스 구성을 위한 Ansible의 실용적인 단계:\n\n- ANSIBLE 인벤토리:\n\n```js\nvim / etc / ansible / hosts;\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\\<img src=\"/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_13.png\" />\n\n2. REQUIRED MODULES 설치하기.\n\n```js\nansible-galaxy collections install community.general\nansible-galaxy collections install posix\n```\n\n3. ANSIBLE-PLAYBOOK:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nvim <file-name>.yml\n```\n\n![AWS Infrastructure Deployment with Terraform and Configuration with Ansible](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_14.png)\n\n![AWS Infrastructure Deployment with Terraform and Configuration with Ansible](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_15.png)\n\n![AWS Infrastructure Deployment with Terraform and Configuration with Ansible](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_16.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\n- hosts: all\n  become: yes\n  tasks:\n    - name: \"파티션 생성\"\n      community.general.parted:\n        device: \"/dev/xvdb\"\n        name: \"GPT\"\n        number: 1\n        part_end: \"1GiB\"\n        fs_type: \"ext4\"\n        state: present\n        label: \"gpt\"\n        unit: GiB\n\n    - name: \"중요 명령어 실행\"\n      command:\n        cmd: \"udevadm settle\"\n      register: cmd\n\n    - debug:\n        var: cmd\n\n    - command:\n        cmd: \"lsblk\"\n      register: cmd2\n\n    - debug:\n        var: cmd2\n\n    - name: \"파티션 포맷\"\n      community.general.filesystem:\n        fstype: ext4\n        dev: \"/dev/xvdb1\"\n\n    - name: \"웹 서버 설치\"\n      package:\n        name: \"httpd\"\n        state: present\n\n    - name: \"마운트된 볼륨과 연결\"\n      ansible.posix.mount:\n        path: \"/var/www/html\"\n        src: \"/dev/xvdb1\"\n        state: mounted\n        fstype: ext4\n\n    - name: \"데몬 다시로드\"\n      command:\n        cmd: \"systemctl daemon-reload\"\n\n    - command:\n        cmd: \"lsblk\"\n      register: cmd3\n\n    - debug:\n        var: cmd3\n\n    - name: \"인덱스 파일을 웹 서버로 복사\"\n      ansible.builtin.copy:\n        src: \"index.html\"\n        dest: \"/var/www/html/index.html\"\n\n    - name: \"서버 재시작\"\n      service:\n        name: \"httpd\"\n        state: \"started\"\n```\n\n## 이 Playbook은 다음을 수행할 수 있습니다:\n\n- 우리가 연결한 볼륨인 /dev/xvdb에 파티션 생성.\n- ext4 유형으로 새로 생성된 파티션 포맷.\n- 시스템에 아파치 웹 서버 설치.\n- 아파치 루트 문서인 /var/www/html에 파티션을 마운트.\n- 로컬 시스템의 인덱스 파일을 대상 시스템의 루트 문서에 복사.\n- 아파치 서비스 시작.\n\n## ANSIBLE PLAYBOOK 실행하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nansible-playbook <file-name>.yml\n```\n\n![Image](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_17.png)\n\n![Image](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_18.png)\n\n## 웹 서버가 성공적으로 시작되었는지 확인해 봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![AWS Infrastructure Deployment with Terraform and Configuration with Ansible](/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_19.png)\n\n# 결론:\n\n요약하면, Terraform과 Ansible의 통합은 AWS 인프라 자동화에서 강력한 패러다임 변화를 나타냅니다. 인프라 프로비저닝에 Terraform을 활용하고 구성 관리에는 Ansible을 활용함으로써, 조직은 클라우드 배포에서 전례 없는 민첩성, 확장성 및 신뢰성을 달성할 수 있습니다. 이 통합 접근 방식을 통해 팀은 DevOps 성숙도로 나아가는 여정을 가속화하고 클라우드 자동화의 모든 잠재력을 발휘할 수 있습니다.\n\n오늘 Terraform과 Ansible의 힘을 받아 AWS 인프라 배포 및 구성 워크플로를 혁신하세요! 🚀🔧\n","ogImage":{"url":"/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_0.png"},"coverImage":"/assets/img/2024-06-19-AWSInfrastructureDeploymentwithTerraformandConfigurationwithAnsible_0.png","tag":["Tech"],"readingTime":19},{"title":"랜딩 존 배포 Google Cloud 채택 시리즈","description":"","date":"2024-06-19 13:19","slug":"2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries","content":"\n구글 클라우드 채택 및 이전 시리즈에 다시 오신 것을 환영합니다. 이 글이 좀 늦게 나온 점 죄송합니다. 기술적인 문제가 있어서요! (나중에 더 설명하겠죠.)\n\n이전에는 핵심 LZ 팀을 구성하는 방법, 필요한 지원을 받는 방법, 실행해야 할 워크샵, 그리고 설계를 기록하고 문서화하는 방법을 다뤘습니다.\n\n오늘은 재미있는 부분에 진입합니다! 이제 실제로 LZ를 배포해 봅시다!\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# LZ를 배포하는 네 가지 방법\n\nGoogle 클라우드 랜딩 존을 배포하는 네 가지 접근 방법이 있습니다. 이러한 방법들은 다음과 같습니다:\n\n- “클릭하고 배포” — Google 클라우드 콘솔의 안내에 따라 클릭 단계별 프로세스를 따르는 방식으로, Google 클라우드 Foundation 설정 체크리스트에서 지원합니다. 버튼을 누르면 실제 배포가 수행됩니다.\n- “클릭하고 다운로드하고 배포” — 여기서는 콘솔에서 UI 기반 프로세스를 계속 따릅니다. 그러나 콘솔에서 배포를 실행하는 대신, 프로세스에 의해 생성된 Terraform 구성을 다운로드합니다. 이를 통해 배포를 별도로 저장, 조정 및 실행할 수 있습니다. 또한 배포를 취소할 수도 있습니다!\n- Cloud Foundation Fabric FAST — 사전에 Fabric 참조 블루프린트 세트를 사전 집계함으로써 구축된 기업용 랜딩 존 블루프린트 시범 구현입니다. 이는 Terraform 기반의 솔루션으로 처음부터 GCP LZ를 부트스트래핑하고 빌드하는 것입니다.\n- 직접 Terraform 구축 — 가능하긴 합니다. 그러나 추천하지는 않습니다. Google은 처음부터 FAST를 구축하고 다양한 기업들로부터 많은 피드백을 모았습니다. 그래서 이 옵션에 대해 더 이상 다루지 않겠습니다.\n\n# 사전 요구사항\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n어떤 방식을 선택하든, LZ 설계 단계를 완료하는 것이 중요합니다. 해야 할 결정 사항이 많이 있습니다.\n\n# 1 — 클릭 옵스 및 배포\n\n이 방법은 Google Cloud 콘솔을 통해 진행하는 클릭 단위 안내 프로세스를 사용합니다.\n\n## 누구를 위한 것인가?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이는 매우 작은 조직 및 매우 작은 Google Cloud 플랫폼 팀을 대상으로하며, Terraform 기술이 거의나 전혀 없는 경우가 많습니다.\n\n## 장점\n\n- 전반적인 프로세스가 매우 빠릅니다. Google 조직 및 랜딩 존을 구성하고 배포하는 데 1시간 또는 2시간이면 충분합니다.\n- Terraform 기술이 필요하지 않습니다. 전체 프로세스를 Google Cloud 콘솔을 통해 실행할 수 있습니다.\n- 제한된 구성 옵션을 제공하여 간단하고 쉽게 따르기 쉽습니다.\n\n## 단점\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 최종 LZ의 제한된 구성 가능성.\n- 반복성 없음.\n- 자동화된 CI/CD 파이프라인, 테넌트 팩토리 또는 프로젝트 팩토리 생성 불가.\n\n## 단계 요약\n\n- 조직 설정 — 조직 생성; 조직에 연결된 클라우드 ID 테넌트 설정; 도메인 확인; 및 수퍼 관리자 계정 설정.\n- 클라우드 ID의 사용자 및 그룹 구성 — GCDS를 사용한 동기화 포함; 필요한 경우 SSO 설정; 관리자 그룹 설정 (예: 조직, 결제, 네트워크, 보안, 로깅).\n- IAM을 사용한 관리적 액세스 설정 — 이전에 설정한 그룹에 사용자를 매핑; Google Cloud IAM 역할을 그룹에 할당.\n- 결제 설정 — 결제 계정; 예산 및 결제 경고; 결제 내보내기.\n- 리소스 계층 구조 및 액세스 생성 — 폴더 및 공통 프로젝트를 포함한 초기 리소스 계층 구조.\n- BigQuery로의 로깅 중앙화.\n- 네트워킹 — 공유 VPC 배포; 하이브리드 연결 구성; 초기 방화벽 구성; 출발 라우트 및 NAT.\n- 하이브리드 연결\n- 모니터링 — 중앙 집중식 클라우드 모니터링 구성.\n- 보안 — 조직 정책 구성; SCC 대시보드 활성화.\n- 지원 — 기본 또는 프리미엄 지원과 같은 선호하는 지원 옵션 선택.\n\n실제 배포 단계는 설정의 8단계 이후에만 발생합니다. 이 지점까지 모든 것은 적용할 구성입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n세부 단계를 자세히 살펴보기 전에 먼저 Google Cloud 설정 체크리스트를 시작해 보세요. 이 체크리스트는 프로세스를 완료하는 데 단계별 지침을 제공합니다. 체크리스트의 각 번호가 매겨진 항목은 더 많은 세부 정보를 보여줍니다.\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_1.png)\n\n## 1 — 조직 설정\n\n우선 Google Cloud Identity를 설정해야 하며(이미 Cloud Identity 또는 Google Workspace 고객이 아닌 경우), 그런 다음 Cloud Identity 계정을 Google Cloud 조직에 연결해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아직 구글 클라우드 아이덴티티 고객이 아니라면, 클라우드 아이덴티티 가입 페이지를 열어 진행할 것입니다. 클라우드 아이덴티티에는 무료 및 프리미엄 버전이 있지만, 이 프로세스에서는 무료 티어를 사용하는 방법을 안내해 드릴게요.\n\n여기 유용한 정보가 있어요! 저와 같이 이미 클라우드 아이덴티티 계정을 보유하고 구글 클라우드 조직을 만든 경우를 상상해봅시다. 하지만 이 프로세스를 실험하기 위해 새로운 클라우드 아이덴티티 계정과 별도의 조직을 만들고 싶을 수 있습니다. 그렇다면 서브도메인을 사용하여 그것을 할 수 있어요! 예를 들어, 저는 이미 구글 클라우드 조직으로 just2good.co.uk 도메인을 사용하고 있습니다. 그러나 데모 목적으로 gcp-demos.just2good.co.uk 서브도메인을 방금 만들었어요.\n\n클라우드 아이덴티티 가입은 다음과 같이 보이는 화면에서 시작됩니다:\n\n![클라우드 아이덴티티 가입 페이지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_2.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼 비즈니스 도메인 이름을 지정해야 합니다. 이것은 우리의 Google Cloud 조직 이름이 될 것입니다.\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_3.png)\n\n그런 다음 도메인 이름을 입력합니다:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 슈퍼 관리자 계정 세부 정보를 입력해야 합니다. 이 이메일 주소는 Google Cloud Identity의 슈퍼-관리자가 될 것입니다. Google Cloud Identity Admin 콘솔에 로그인하는 데 사용할 이메일 주소입니다. (Google Cloud 콘솔과는 구별되어야 합니다.) 방금 전에 지정한 비즈니스 도메인과 관련된 이메일이어야 합니다. 예를 들어: mydomain.com의 Bob이 슈퍼 관리자라면, super-bob@mydomain.com과 같은 주소를 사용하는 것이 좋습니다.\n\n참고: 이는 강력한 계정으로, Google Cloud 조직과 관련된 이메일 주소나 그룹과 완전히 분리되어 있습니다.\n\nCloud Identity Admin 콘솔에 로그인하십시오:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 도메인 이름을 확인해야 합니다.\n\n![도메인 확인](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_6.png)\n\n도메인 확인 프로세스는 빠르고 쉽습니다. 일반적으로 구글에서 제공하는 값을 사용하여 DNS TXT 레코드를 생성하여 이 작업을 수행합니다. Admin Console에서 프로세스를 안내해줍니다.\n\n도메인이 확인되면 Google Cloud 조직 리소스가 자동으로 생성됩니다. 이는 Google Cloud의 최상위 조직입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n어드민 콘솔에서는 사용자를 만드는 것을 제안합니다. 그러나 Cloud Identity 어드민 콘솔이 아닌 Google Cloud 콘솔에서 진행하려고 합니다. 그래서 \"Google Cloud 콘솔에서 설정\" 링크를 클릭해주세요.\n\n![Google Cloud 콘솔에서 설정](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_7.png)\n\n이제 Google Cloud 콘솔에서 Cloud Foundation 설정 체크리스트를 계속 진행할 수 있습니다.\n\n![Google Cloud 콘솔에서 설정](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러나 현재 이 단계에서 - Cloud Identity 관리자 콘솔에서 - 제안드리는 것이 있습니다:\n\n- 하나 또는 두 개의 추가 수퍼 관리자 계정을 추가하는 것. (만일 유일한 수퍼 관리자가 거대한 구덩이로 떨어진다면 어떻게 될까요?)\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_9.png)\n\n- 수퍼 관리자를 위해 이중 인증(MFA) 설정.\n- 계정 복구 설정.\n- 암호 만료를 포함한 암호 정책 정의.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n1단계가 완료되었습니다!\n\n## 2 — 클라우드 아이덴티티에서 사용자 및 그룹 설정\n\n여기서 사용자 그룹을 생성하고 이러한 그룹에 구성원을 추가합니다. 체크리스트의 이 단계에서는 클라우드 설정의 모든 단계에 참여할 사용자를 추가하는 것이 좋습니다.\n\n구글 클라우드 설정으로 돌아가 Step 2로 이동할 수 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_10.png\" />\n\n클라우드 ID 관리자 콘솔을 통해 슈퍼 관리자가 관리 그룹을 프로비저닝하고 초기 사용자를 설정할 수 있습니다. 다음과 같은 방법으로 할 수 있습니다:\n\n- 클라우드 ID 관리자 콘솔에서 그룹(및 사용자)을 수동으로 추가하는 것.\n- 기존 LDAP 또는 Active Directory (AD) 시스템에서 ID를 복제하기 위해 Google Cloud Directory Sync (GCDS)를 설정하는 것. 이 무료 도구는 사용자 및 그룹을 Google Cloud로 단방향 동기화합니다. 기존 LDAP/AD 시스템이 여전히 원본 소스로 유지됩니다. 시리즈 이전 기사에서 더 자세히 설명하겠습니다.\n\n<img src=\"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_11.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 그러나 가장 쉬운 방법은 Google Cloud Setup의 \"모든 그룹 생성\" 버튼을 사용하여 그룹을 만드는 것입니다. 이렇게 하면 클라우드 ID에서 권장하는 그룹이 자동으로 할당됩니다.\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_12.png)\n\n이 단계를 완료하면 그룹이 할당되어 Google 관리자 콘솔에서 볼 수 있습니다.\n\n이제이 그룹에 사용자(멤버)를 추가할 수 있습니다. \"Google 관리자 콘솔로 이동\"을 클릭하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![그룹에 사용자 추가](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_13.png)\n\n그런 다음 이 그룹에 사용자를 추가하세요. 몇 가지 샘플 사용자를 만들어 두었습니다:\n\n![샘플 사용자](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_14.png)\n\n이 사용자들은 자동 이메일을 받게 됩니다. 물론... 유효한 메일함이 있는 경우에만요! (이와 같은 데모용으로, 일반적으로 \\*@my-domain 전달 규칙을 설정해 유효한 이메일 계정으로 전달하곤 합니다.)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음으로, 해당 그룹에 그들을 추가하겠습니다:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_15.png)\n\n이제, 구글 클라우드 콘솔로 돌아가주세요. 그룹에 멤버가 추가된 것을 확인할 수 있을 거에요:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_16.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 \"관리 액세스로 계속\"을 클릭할 수 있습니다.\n\n## 3 - 관리 액세스\n\n다음으로, 이전 단계에서 생성한 각 그룹에 Google Cloud IAM 역할을 할당합니다. 이는 클라우드 ID 그룹에 적절한 Google Cloud 권한을 부여합니다.\n\n구글 클라우드 설정은 이전에 생성한 각 그룹에 할당될 역할을 제안할 것입니다. \"저장 및 액세스 권한 부여\"를 클릭하여 진행할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_17.png)\n\n## 4 — 청구\n\n이 단계에서는 청구 계정을 생성하고(이미 보유하고 있지 않은 경우) 새 Google Cloud 조직과 연결합니다. 예산 설정, 청구 알림 및 청구 내보내기를 선택적으로 구성할 수도 있습니다.\n\n청구 계정은 소비한 모든 Google Cloud 자원을 지불하는 데 사용됩니다. 자원 소비(및 비용)은 프로젝트 수준에서 누적되며, 각 프로젝트는 청구 계정과 연결됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 해당 데모를 위해 사용할 기본 청구 계정 유형인 온라인(\"셀프 서비스\") 유형으로 계속하겠습니다. 자격을 갖춘 조직은 나중에 청구서 청구 계정으로 변경할 수 있습니다.\n\n\"온라인 청구 계정\"을 선택한 후 \"계속\"을 클릭한 다음 \"청구 계정 생성\"을 클릭하세요:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_19.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n청구 계정 설정을 완료하려면 결제 카드 정보를 입력해야 합니다. 걱정하지 마세요. 아직 요금이 청구되지는 않을 거에요. 참고로 Google Cloud 초기 설정에는 300달러의 무료 크레딧이 제공됩니다.\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_20.png)\n\n\"내 청구 계정\"을 클릭하면 예산 및 청구 알림을 설정할 수 있습니다. (나중에도 언제든지 설정할 수 있어요.)\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_21.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예산 및 알림을 클릭한 후 예산 생성을 선택하세요. 예산 이름을 지정하고 시간 범위를 설정하고 적용할 프로젝트를 선택하세요 (\"모두\" 프로젝트가 기본 설정입니다).\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_22.png)\n\n다음으로 경고를 발생시킬 임계값과 경고를 전송할 위치를 지정합니다. 이 예에서는 청구 관리자 그룹에 이메일을 보낼 것이지만, Pub/Sub 주제에 쓰는 것과 같이 더 복잡한 작업도 수행할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_23.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 5 - 리소스 계층구조와 액세스\n\n이제 이른바 초기 설계 결정을 활용하기 시작하는 단계입니다. 여기서는 조직 리소스 계층구조를 설정합니다.\n\n이 단계에서는 계층구조 단계에서 여러 프로젝트를 생성하기 때문에 청구 계정과 연결된 프로젝트 할당량을 증가 요청해야 할 수도 있습니다. 클라우드 설정 단계에서 할당량 요청 방법을 안내해줍니다. 할당량 요청을 수행하는 계정이 유효한 이메일 주소를 가지고 있는지 확인해주세요!\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_24.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n한동안 이 기사를 완성하는 데 방해가 된 것은 할당량 요청 단계였어요. Google은 2영업일 이내에 요청에 대응해야 한다고 했지만 작성 시점에서 할당량 상승을 처리하는 구글 프로세스가 조금 문제가 있었네요. 그래서 수동 개입이 필요했죠! 구글 친구들이 이 문제가 곧 해결될 것이라고 말해 주었어요.\n\n그럼 'Cloud Setup'으로 돌아가볼게요… 우리는 네 가지 프리셋 계층 청사진 중 하나를 선택할 수 있어요.\n\n![Image](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_25.png)\n\n목록에서 계층을 선택하면 콘솔에서 생성된 계층이 어떻게 보일지 미리 보여 줍니다. 함께 비교해 볼까요…\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n간단하고 환경 중심의 계층 구조입니다:\n\n이 계층 구조는 매우 소규모 조직을 운영할 때 좋습니다. 아마 개발자 소수만 있을 것입니다.\n\n```js\nOrg/\n├── Common/\n│   ├── vpc-host-prod 📦\n│   ├── vpc-host-nonprod 📦\n│   ├── logging 📦\n│   ├── monitoring-prod 📦\n│   ├── monitoring-nonprod 📦\n│   └── monitoring-dev 📦\n├── Prod/\n│   ├── app1-prod-svc 📦\n│   └── app2-prod-svc 📦\n├── Nonprod/\n│   ├── app1-nonprod-svc 📦\n│   └── app2-nonprod-svc 📦\n└── Dev/\n```\n\n- 프로젝트는 📦 아이콘으로 표시됩니다. 다른 항목들은 폴더입니다.\n- 이 계층 구조는 공통(Common) 폴더와 Prod, Nonprod, Dev와 같은 세 가지 환경을 가장 상위 수준으로 구성합니다.\n- 여기서 Prod와 Nonprod에서 두 개의 공유 VPC 디자인을 구현하고 있음에 주목하세요. Common에는 각각의 호스트 프로젝트가 있습니다.\n- 이 디자인은 환경 당 메트릭 범위를 갖는 모니터링 디자인을 구현합니다. 각 메트릭 범위를 호스팅할 프로젝트가 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n간단하고 팀 중심적인 등급체계:\n\n```js\nOrg/\n├── Common/\n│   ├── vpc-host-prod 📦\n│   ├── vpc-host-nonprod 📦\n│   ├── logging 📦\n│   ├── monitoring-prod 📦\n│   ├── monitoring-nonprod 📦\n│   └── monitoring-dev 📦\n├── team-huey/\n│   ├── Prod/\n│   │   └── huey-prod-svc 📦\n│   ├── Nonprod/\n│   │   └── huey-nonprod-svc 📦\n│   └── Dev/\n└── team-dewey/\n    ├── Prod/\n    │   └── dewey-prod-svc 📦\n    ├── Nonprod/\n    │   └── dewey-nonprod-svc 📦\n    └── Dev/\n```\n\n- 여기서 최상위 분류는 환경이 아닌 팀에 따라 구성됩니다.\n- 각 팀은 그런 다음 세 환경을 위한 폴더로 나뉩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n조직/\n├── 공통/\n│   ├── vpc-host-prod 📦\n│   ├── vpc-host-nonprod 📦\n│   ├── 로깅 📦\n│   ├── 모니터링-운영 📦\n│   ├── 모니터링-비운영 📦\n│   └── 모니터링-개발 📦\n├── 운영/\n│   ├── 리테일뱅킹/\n│   │   ├── 휴이/\n│   │   │   └── 운영/\n│   │   │       └── rb-huey-prod-svc 📦\n│   │   └── 듀이/\n│   │       └── 운영/\n│   │           └── rb-dewey-prod-svc 📦\n│   ├── 자산관리/\n│   └── 모기지/\n├── 비운영/\n│   ├── 리테일뱅킹/\n│   │   ├── 휴이/\n│   │   │   └── 비운영/\n│   │   │       └── rb-huey-nonprod-svc 📦\n│   │   └── 듀이/\n│   │       └── 비운영/\n│   │           └── rb-dewey-nonprod-svc 📦\n│   ├── 자산관리/\n│   └── 모기지/\n└── 개발/\n    ├── 리테일뱅킹\n    ├── 자산관리\n    └── 모기지\n```\n\n- 상위 수준에서 각 환경을 기준으로 구성되었지만, 각 환경은 각각의 사업부로 나누어집니다.\n- 각 사업부에는 여러 팀이 포함되어 있습니다.\n\n사업부 중심 계층 구조:\n\n```js\n조직/\n├── 공통/\n│   ├── vpc-host-prod 📦\n│   ├── vpc-host-nonprod 📦\n│   ├── 로깅 📦\n│   ├── 모니터링-운영 📦\n│   ├── 모니터링-비운영 📦\n│   └── 모니터링-개발 📦\n├── 리테일뱅킹/\n│   ├── 휴이/\n│   │   ├── 운영/\n│   │   │   └── rb-huey-prod-svc 📦\n│   │   ├── 비운영/\n│   │   │   └── rb-huey-nonprod-svc 📦\n│   │   └── 개발/\n│   └── 듀이/\n│       ├── 운영/\n│       │   └── rb-dewey-prod-svc 📦\n│       ├── 비운영/\n│       │   └── rb-dewey-nonprod-svc 📦\n│       └── 개발/\n├── 자산관리/\n│   ├── 휴이/\n│   │   ├── 운영/\n│   │   ├── 비운영/\n│   │   └── 개발/\n│   └── 듀이/\n│       ├── 운영/\n│       ├── 비운영/\n│       └── 개발/\n└── 모기지/\n    ├── 휴이/\n    │   ├── 운영/\n    │   ├── 비운영/\n    │   └── 개발/\n    └── 듀이/\n        ├── 운영/\n        ├── 비운영/\n        └── 개발/\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 여기서는 비즈니스 단위, 상위 레벨의 팀, 환경을 카테고리화합니다.\n\n우리가 선택한 계층 구조에 관계없이 다음을 구성할 수 있다는 점에 유의하세요:\n\n- 비즈니스 단위의 수 및 이름. (본 데모에서는 내 조직이 금융 기관 / 은행이라고 가정하고, 소매 은행, 자산 관리 및 모기지를 위한 최상위 비즈니스 단위를 만들었습니다.)\n- 팀의 수와 이름.\n- 세 개의 환경의 이름.\n- 공유 VPC 호스트 프로젝트와 연결된 서비스 프로젝트의 이름.\n- 추가 사용자 정의 프로젝트.\n\n상당한 규모의 조직의 경우 환경 중심의 계층 구조 (환경 → 비즈니스 단위 → 팀)을 선호하는 편이며, 이 데모에서 이 계층 구조를 사용하려고 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 우리는 계층 구조의 폴더와 프로젝트에 IAM 역할을 적용해야 합니다. Google Cloud 설정은 각 그룹에 추가해야 할 역할을 권장합니다. 그러나 이번에는 조직 수준에서만 적용하는 것이 아니라 리소스 계층에 적용합니다. IAM 정책은 계층 구조를 따라 상속되며 권한이 누적됩니다. 따라서 유효한 액세스는 각 수준에서 상속된 정책과 가장 낮은 수준의 정책을 합한 것입니다.\n\nGoogle Cloud 설정 권장 사항은 다음과 같을 것입니다:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_26.png)\n\n\"드래프트 구성 확인\"을 클릭해주세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 6 - 중앙 집중식 로깅\n\n여기서 클라우드 설정을 통해 중앙 집중식 로깅을 설정할 수 있습니다.\n\n![Cloud Setup Image](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_27.png)\n\n시작 로깅 구성을 클릭하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_28.png\" />\n\n먼저, 모든 감사 로그의 집계 로깅을 중앙 집중식 로깅 버킷에 설정합니다. 이 버킷은 이전에 생성한 로깅 프로젝트에 저장됩니다. (여기에 문서화한 최상의 모범 사례대로입니다.)\n\n<img src=\"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_29.png\" />\n\n또한 BigQuery로 로그 라우팅 및 아카이브 로깅(예: 규정 준수 목적)을 더 저렴한 GCS 버킷으로 라우팅할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래와 같이 Markdown 형식으로 테이블 태그를 변경해주세요.\n\nGo ahead and “Confirm draft configuration.”\n\n![image](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_30.png)\n\n## 7 — VPC Networks\n\nIn this step, we set up a pair of shared virtual private cloud (VPC) networks, as per the dual shared VPC pattern: one in prod, and one in non-prod.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마크다운 형식의 이미지 테그를 변경하세요.\n\n![](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_31.png)\n\nGoogle Cloud 설정은 각 VPC마다 쌍으로 서브넷을 구성해야 합니다. 이것이 최소 요구사항이며, 추가 서브넷을 이 단계에서 구성할 수도 있습니다.\n\n![](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_32.png)\n\n추천드리는 것은:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 한 지역에서 첫 번째 프로드 Subnet을 생성하고, 다른 지역에서 두 번째 프로드 Subnet을 생성하세요. 이렇게 함으로써 지역적인 Redundancy가 필요한 이중 지역 아키텍처를 배포할 수 있습니다. 또한 제가 여기서 설명한 대로 99.99% SLA를 갖는 HA Hybrid Connectivity를 구성할 수 있습니다.\n- 비 프로드에도 비슷한 두 개의 Subnet을 구성하세요. 참고: 비 프로드 VPC에는 프로드 VPC에 선택한 IP CIDR 범위와 동일한 것을 사용할 수 있습니다. 이는 IP가 특정 VPC 내에서만 고유해야 한다는 점 때문입니다. 그러나 이로 인해 프로드 Subnet을 비프로드 Subnet에 피어링할 수 없게 되지만, 이 분리를 강제하고 싶을 수도 있습니다.\n- 각 Subnet에서 개인 Google 액세스를 활성화하세요. 이를 통해 외부 IP 주소가 없는 VM도 Google API 및 서비스의 공용 IP 주소에 액세스할 수 있습니다.\n- 각 Subnet에서 Cloud NAT를 활성화하세요. 이를 통해 다음에 대한 인터넷 외부 연결이 가능해집니다: 외부 IP 주소가 없는 VM, Private GKE 클러스터, 서버리스 VPC 액세스를 통한 Cloud Run, 서버리스 VPC 액세스를 통한 Cloud Functions.\n- 권장 VPC 방화벽 규칙을 구성된 상태로 유지하세요. 기본적으로 Google은 VPC 내의 어느 곳에서나 ICMP를 허용하는 방화벽 규칙을 적용하고, SSH 또는 RDP는 클라우드 ID 기반 프록시 (IAP) 범위(35.235.240.0/20)에서만 허용합니다.\n- 기본적으로 설정은 방화벽 규칙 로깅을 활성화합니다. 그러나 이는 비용이 많이 발생할 수 있습니다. 특정 규칙에 대해서만 로깅을 활성화하는 것을 고려해보세요.\n- 기본적으로 설정은 VPC 플로우 로그를 활성화합니다. 이는 VPC 내 VM(포함하여 GKE 노드)에 의해 송수신된 네트워크 흐름의 샘플을 기록합니다. 네트워크 분석 및 포렌식에 유용합니다. 그러나 다시 말씀드리지만, 비용이 많이 발생할 수 있습니다. 제 추천은 로그를 켜둔 채로 완전하게 설정한 후, 플로우 로그를 조절하여 로깅 양을 제한하는 것입니다. (나중에 FinOps 권장사항에서 이를 다룰 예정입니다.)\n\n여기가 제 구성입니다. (요금을 최대한 저렴하게 유지하기 위해 로깅은 꺼져 있습니다. 이 데모의 목적을 위해)\n\n`![image](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_33.png)`\n\n“서비스 프로젝트로 계속하기”를 클릭하세요. 이렇게 하면 우리가 이전에 구성한 프로젝트를 서비스 프로젝트로 연결할 수 있는 화면으로 이동합니다. 이를 통해 이러한 프로젝트가 공유 VPC를 사용할 수 있도록 할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로, \"확인된 초안 설정\"을 클릭하세요.\n\n## 8—하이브리드 연결\n\n그다음, 클라우드 설정에서는 하이브리드 연결을 설정합니다. 현재 이 설정 작업은 미리보기 단계에 있습니다. IPsec VPN을 사용하여 하이브리드 연결을 구성할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_34.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시작하면 다음과 같은 화면을 볼 수 있습니다:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_35.png)\n\n이 데모의 목적으로 하이브리드 연결 설정은 하지 않겠습니다.\n\n## 배포 또는 다운로드\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 중요한 선택이 있습니다. 지금까지 구성한 모든 것을 적용할 수 있는 콘솔에서 직접 배포할 수 있습니다.\n\n또는 구성한 Terraform을 다운로드할 수도 있습니다. Terraform을 다운로드하면...\n\n# 2 — “ClickOps, 다운로드하고 배포하기”\n\n여기서 위에서 한 모든 단계는 동일합니다. 그러나 콘솔에서 배포하는 대신에 Terraform을 다운로드합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_36.png\" />\n\n## 누구를 위한것인가요?\n\n이것은 중소 규모 조직을 위한 것입니다. 이 조직은:\n\n- Terraform을 사용하여 지속적인 LZ 및 Google Cloud 인프라 자원을 관리하려고 합니다. (그리고 이것은 항상 좋은 생각입니다!)\n- 기본 클릭 옵션 설정에 추가적인 사용자 정의 및 구성을 추가할 수 있기를 원합니다.\n- Fabric FAST와 같이 더 정교한 엔터프라이즈 LZ 배포로 진행하기에 충분히 강력한 플랫폼 팀이 필요하지는 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 장점\n\n- Cloud Console의 \"Click-Ops\" 프로세스로 생성된 Terraform 구성은 제가 설명한대로 가능한 한 쉽게 하루 안에 완료할 수 있습니다.\n- 원하는대로 Terraform을 조정할 수 있습니다.\n- Terraform은 소스 제어(예: GitHub)에 배치해야 합니다.\n- Terraform 구성을 협업하여 작업할 수 있습니다.\n- 향후 Terraform 구성에 변경 사항이 있으면 해당 변경 사항을 적용할 수 있습니다.\n- 전체 LZ를 삭제하려면 한 줄로 몇 초만에 삭제할 수 있습니다.\n\n## 단점\n\n- Terraform 기술이 약간 필요합니다.\n- 자동화된 CI/CD 파이프라인, 테넌트 팩토리 또는 프로젝트 팩토리를 생성하지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Terraform 설정 파일 다운로드하기\n\n시작해 봅시다!\n\n먼저, \"Terraform으로 다운로드\"를 클릭하세요. 이제 테라폼 상태를 저장할 버킷의 지역을 선택해 주세요. 실제로는 아직 버킷을 생성하지 않고, 나중에 다운로드할 backend.tf 파일에 고유한 버킷 식별자가 생성됩니다.\n\n그런 다음, 테라폼 구성 파일을 다운로드하세요. 이 파일은 terraform.tar.gz로 로컬 기기에 다운로드됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 테라폼을 클라우드 셸에 업로드하세요\n\n다운로드한 후, 테라폼을 실행하는 방법은 두 가지가 있습니다:\n\n- Google Cloud Shell에서 실행.\n- Cloud SDK가 설치된 장치에서 실행.\n\n이 데모를 위해 간단하게 클라우드 셸을 사용하겠습니다. 테라폼으로 기본 구성을 배포하는 데 필요한 모든 것이 미리 설치되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n클라우드 셸에 인증하고 Terraform 구성을 위한 폴더를 만들어봅시다:\n\n```js\n# 인증하기\ngcloud auth list\n\n# Terraform 구성을 위한 폴더 생성\nmkdir tf-foundation-setup\ncd $_\n```\n\n이제 콘솔을 통해 Terraform 구성 파일(.gz 파일)을 업로드한 다음, 이전에 만든 폴더에 파일을 추출해보세요:\n\n```js\n# 방금 업로드한 파일 추출\ntar -xzvf ../terraform.tar.gz\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리 폴더에 이 파일들이 있습니다:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_37.png)\n\n## 테라폼 상태를 저장할 시드 프로젝트 생성\n\n```sh\n# 테라폼 상태를 저장할 시드 프로젝트 생성\nSUFFIX=$RANDOM\nPROJECT_ID=시드-프로젝트-$SUFFIX\ngcloud projects create $PROJECT_ID\ngcloud config set project ${PROJECT_ID}\n\n# 요금 청구 계정 연결\ngcloud billing projects link $PROJECT_ID --billing-account <당신의_청구_계정_ID>\n\n# 테라폼으로 배포할 필요가 있는 API 활성화\ngcloud services enable cloudresourcemanager.googleapis.com\ngcloud services enable iam.googleapis.com\ngcloud services enable serviceusage.googleapis.com\ngcloud services enable cloudbilling.googleapis.com\ngcloud services enable cloudidentity.googleapis.com\ngcloud services enable orgpolicy.googleapis.com\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희 조직에서 현재 가지고 있는 프로젝트를 간단히 살펴봅시다:\n\n![프로젝트 이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_38.png)\n\n방금 만들어 놓은 씨드 프로젝트 seed-project-28844를 확인할 수 있습니다.\n\n이제 백엔드.tf 파일에서 상태 유지에 사용될 버킷을 살펴보겠습니다. 실제로 제 버킷 이름을 더 의미 있는 것으로 변경했습니다. 또한 전 세계적으로 고유한 이름이어야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_39.png\" />\n\n이 버킷을 사용하기 전에 만들어야 합니다:\n\n```js\ngsutil mb gs://tfstate-28844\n```\n\n다음을 통해 만들어졌는지 확인할 수 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_40.png\" />\n\n## GitHub에 저장하기\n\n이제 테라폼 구성을 GitHub에 저장하는 것이 좋을 시기입니다. 또는 Google Cloud Repos에 저장할 수도 있습니다. GitHub의 개인 저장소에 저장하는 과정을 다음과 같이 따를 수 있습니다:\n\n```js\n# 이전에 생성한 tf-foundation-setup 폴더에 있다고 가정합니다\n\n# Cloud Shell에서 git을 설정합니다. 이전에 설정하지 않았다면\ngit config --global user.email \"bob@wherever.com\"\ngit config --global user.name \"Bob\"\n\n# 로컬 git 저장소를 생성합니다.\n# 진행하기 전에 .gitignore 파일이 생성되어 있는지 확인해주세요.\n# .terraform 디렉토리 및 로컬 state, plans 등을 무시하도록 설정되어 있어야 합니다.\ngit init\ngit add .\ngit commit -m \"Initial commit\"\n\n# GitHub 명령줄 도구를 인증합니다.\n# 이미 Cloud Shell에 설치되어 있습니다.\ngh auth login\n\n# 이제 gh cli를 사용하여 GitHub에 원격 개인 저장소를 생성합니다.\ngh repo create gcp-demos-foundation-setup --private --source=.\ngit push -u origin master\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n좋아요. 이제 우리 코드는 안전하게 추적되어 있고 팀원들에게 제공됩니다.\n\n![image](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_41.png)\n\n## 권한이 있는지 확인하기\n\n조직 관리자 그룹이 시드 프로젝트에서 적절한 역할을 부여받았는지 확인해야 합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ngcloud 조직 add-iam-policy-binding $ORG_ID \\\n  --member=\"group:gcp-organization-admins@gcp-demos.just2good.co.uk\" \\\n  --role=\"roles/storage.admin\"\n\ngcloud 조직 add-iam-policy-binding $ORG_ID \\\n  --member=\"group:gcp-organization-admins@gcp-demos.just2good.co.uk\" \\\n  --role=\"roles/compute.xpnAdmin\"\n\ngcloud 프로젝트 add-iam-policy-binding $PROJECT_ID \\\n  --member=\"group:gcp-organization-admins@gcp-demos.just2good.co.uk\" \\\n  --role=\"roles/serviceusage.serviceUsageConsumer\"\n```\n\n## 테라폼\n\n마지막으로, 테라포밍할 준비가 됐어요!!\n\n```js\n# 테라폼 초기화\nterraform init\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 명령의 출력입니다.\n\n![2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_42](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_42.png)\n\nGCS 버킷의 콘솔 뷰를 새로고침하면 이제 버킷에 Terraform 상태 파일이 생성된 것을 확인할 수 있습니다:\n\n![2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_43](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_43.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금까지 잘 진행되고 있어요.\n\n```shell\n# 테라폼 계획을 작성하고 확인합니다\nterraform plan -out=plan.out\n```\n\n결과는 다음과 같습니다:\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_44.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그리고 이제 진실의 순간입니다. 마침내 저희의 랜딩 존을 배포할 수 있습니다!\n\n```js\n# 계획을 적용하십시오!\nterraform apply plan.out\n```\n\n몇 분이 소요됩니다. 그리고 성공했습니다! 만들어진 폴더와 프로젝트를 확인해보세요:\n\n![랜딩 존 배포 이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_45.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제, 만든 모든 것을 파괴하고 싶다면, 이렇게 하면 됩니다:\n\n```js\nterraform destroy\n```\n\n![이미지](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_46.png)\n\n한 가지 주의할 점: 클라우드 설정에서의 Terraform 구성에는 여러 하드코딩된 프로젝트 ID가 포함되어 있습니다. 위에서 설명한대로 LZ를 파괴하면 이러한 프로젝트 ID가 즉시 해제되지 않습니다. 결과적으로, 단순히 Terraform 구성을 다시 적용할 수 없습니다. 다시 적용하려면 프로젝트 ID를 변경해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 3 — 클라우드 기반 패브릭 FAST\n\n## 누구를 위한가요?\n\n구성 가능성이 높고, Terraform 기반 LZ를 사용하여 권한 분리, 다중 테넌시 및 즉시 사용 가능한 GitOps 및 CI/CD 파이프라인을 허용하는 대규모 조직을 위한 솔루션입니다.\n\n## 방법은?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실은, 이 주제에 대해 이전에 상세히 다룬 바 있습니다. 그래서 여기서 다시 다루지 않겠습니다.\n\n# 요약\n\n그럼 이 정도로 마무리 지어보겠습니다! 마침내, 착륙 구역 주제에 대한 이 섹션의 기사를 마쳤습니다. 이전에 다룬 내용은 다음과 같습니다:\n\n- LZ 디자인\n- LZ \"기술 온보딩\"을 위한 LZ 코어 팀 구성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사에는 LZ를 실제로 배포하는 방법을 안내했습니다.\n\n이제 우리는 작동 중인 기업용 구글 클라우드 플랫폼을 갖추었고, 워크로드를 배포할 준비가 되었습니다!\n\n다음 글에서 만나요.\n\n# 가기 전에\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 관심 있는 사람들에게 공유해주세요. 그들에게 도움이 될 수도 있고, 저에게 큰 도움이 됩니다!\n- 박수를 좀 주세요! 여러 번 박수 치는 거, 알고 계시죠?\n- 💬 댓글을 자유롭게 남겨주세요.\n- 내 콘텐츠를 놓치지 않으려면 팔로우하고 구독해주세요. 프로필 페이지로 이동하여 다음 아이콘을 클릭하세요:\n\n![Google Cloud](/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_47.png)\n\n# 링크\n\n- 구글 클라우드의 랜딩 존: 무엇인가, 왜 필요한가, 어떻게 만드는가\n- 구글 클라우드 콘솔: 클라우드 설정\n- 구글 클라우드 설정 체크리스트\n- 클라우드 아이덴티티 개요\n- 구글 프라이빗 액세스\n- 구글 클라우드 아이덴티티-인증 프록시 (IAP)\n- 콘솔에서 다운로드한 테라폼으로 기본 구조 배포\n- 테라폼 및 클라우드 기초 패브릭 FAST로 구글 클라우드 랜딩 존\n- 구글 클라우드 아키텍처 프레임워크\n- 엔터프라이즈 기본 토대\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 시리즈 탐색\n\n- 시리즈 전체 내용 및 구조\n- 이전: 랜딩 존 기술 입사 - \"어떻게\"\n- 다음: 클라우드 소비자 및 테넌트를 활성화하기\n","ogImage":{"url":"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_0.png"},"coverImage":"/assets/img/2024-06-19-LandingZoneDeploymentGoogleCloudAdoptionSeries_0.png","tag":["Tech"],"readingTime":37},{"title":"AKS 패칭 자동화 및 Terraform과 Logic Apps를 사용하여 Slack 알림 받기 파트 1","description":"","date":"2024-06-19 13:15","slug":"2024-06-19-AutomateAKSPatchingandGetSlackNotificationswithTerraformandLogicAppsPart1","content":"\nAKS 완전 자동 패칭 소개: 최신 패치와 업데이트로 Azure Kubernetes 서비스 (AKS) 클러스터를 최신 상태로 유지하는 것은 보안, 안정성 및 성능을 유지하는 데 중요합니다. 패치되지 않은 클러스터는 알려진 보안 취약점, 버그 및 성능 문제에 취약해지며, 다운타임, 데이터 침해 및 기타 비용 소모적인 결과로 이어질 수 있습니다.\n\n그러나 AKS 클러스터를 수동으로 패칭하는 것은 특히 여러 클러스터가 있는 대규모 환경에서 시간이 많이 소요되고 오류가 발생하기 쉬운 과정일 수 있습니다. 수동으로 패칭하려면 유지 보수 창을 조정하고 패칭 프로세스를 모니터링하며 모든 클러스터가 중요한 작업 부하를 방해하지 않고 성공적으로 업데이트되도록 보장해야 합니다.\n\n![AKS Patching](/assets/img/2024-06-19-AutomateAKSPatchingandGetSlackNotificationswithTerraformandLogicAppsPart1_0.png)\n\nTerraform 및 Azure의 유지 보수 창 기능을 활용하여 AKS 패칭 프로세스를 간편하게 진행하고 클러스터가 최신 상태로 안정하게 유지되도록 할 수 있습니다. 설정 작업이나 다운타임을 최소화하면서 클러스터를 업데이트할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 사전 준비 사항 (초보자용)\n\nAKS 패치 자동화를 위해 Terraform을 사용하여 시작하려면 다음 사전 준비 사항(기본 사항)이 필요합니다:\n\n- Azure 구독: Azure 구독이 활성화되어 있어야 합니다. Azure 클라우드 플랫폼 내에서 리소스를 생성하고 관리할 수 있습니다.\n- Terraform 설치: Terraform은 선언적 구성 파일을 사용하여 클라우드 리소스를 정의하고 제공할 수 있도록 해주는 오픈 소스 인프라 코드(IaC) 도구입니다. 로컬 머신이나 빌드 서버에 Terraform이 설치되어 있어야 합니다.\n- Azure CLI 설치 및 인증: Azure CLI는 Azure 서비스와 상호 작용할 수 있는 명령줄 인터페이스입니다. Azure CLI를 설치하고 Azure 구독과 인증해야 합니다. 이를 통해 Terraform이 Azure와 인증하고 필요한 작업을 수행할 수 있습니다.\n\n이러한 사전 준비 사항을 갖추었다면, Terraform 코드를 구성하여 AKS 패치 자동화를 진행할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Azure Provider 구성하기 (초보자용)\n\n우선, Terraform을 위해 Azure Provider를 구성해야 합니다. 이를 통해 Terraform에게 어떤 공급자(provider)를 사용할지 알려주고 선택적 기능을 활성화합니다.\n\n```js\nprovider \"azurerm\" {\n  features {}\n}\n```\n\nfeatures 블록을 사용하여 공급자의 동작을 사용하거나 비활성화하여 사용자 정의할 수 있습니다. 이 경우 비워 두었지만 필요에 따라 여기에 기능 플래그를 추가할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAzure Provider를 구성함으로써 Terraform은 Azure 리소스를 사용할 때 Azure Resource Manager(azurerm) 제공자를 사용하도록 알고 있습니다. 이 제공자를 통해 Terraform은 Azure 구독 내에서 리소스를 생성, 관리 및 업데이트할 수 있습니다.\n\n# 리소스 그룹 생성 (초보자용)\n\n다음으로 AKS 클러스터와 관련 리소스를 포함하는 Azure 리소스 그룹을 생성합니다. 우리는 리소스 그룹의 이름과 위치를 지정합니다.\n\n```js\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"example-resources\"\n  location = \"West Europe\"\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 블록에서는 azurerm_resource_group 리소스를 사용하여 새로운 Azure 리소스 그룹을 정의합니다. \"name\" 인수는 리소스 그룹의 이름을 \"example-resources\"로 지정합니다. \"location\" 인수는 리소스 그룹이 생성될 Azure 지역을 설정하며, 이 경우 \"West Europe\"입니다.\n\n전용 리소그룹을 생성함으로써 AKS 클러스터 배포에 관련된 모든 리소스를 논리적으로 그룹화하고 관리할 수 있습니다. 이는 깨끗하고 조직적인 Azure 환경을 유지하고 이 프로젝트와 관련된 리소스를 관리하고 모니터링하기 쉽게 만들어줍니다.\n\n# AKS 클러스터 정의\n\n이제, azurerm_kubernetes_cluster 리소스를 사용하여 AKS 클러스터를 정의해 봅시다. 클러스터 이름, 위치, 리소스 그룹, DNS 접두사, 기본 노드 풀 및 시스템 자동 할당 관리 ID와 같은 필요한 구성을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nresource \"azurerm_kubernetes_cluster\" \"example\" {\n  name                = \"example-aks1\"\n  location            = azurerm_resource_group.example.location\n  resource_group_name = azurerm_resource_group.example.name\n  dns_prefix          = \"exampleaks1\"\n  default_node_pool {\n    name       = \"default\"\n    node_count = 1\n    vm_size    = \"Standard_D2_v2\"\n  }\n  identity {\n    type = \"SystemAssigned\"\n  }\n  tags = {\n    Environment = \"Production\"\n  }\n  # ... (maintenance window configuration)\n}\n```\n\n이 블록에서는 AKS 클러스터의 이름을 example-aks1로 지정했습니다. 위치와 resource_group_name 속성은 이전에 만든 리소스 그룹을 참조하여 클러스터가 원하는 위치와 리소스 그룹에 배포되도록 합니다.\n\ndns_prefix는 클러스터에 대한 고유한 DNS 접두어로, 클러스터의 완전한 도메인 이름을 만들기 위해 필요합니다.\n\ndefault_node_pool 블록은 클러스터의 기본 노드 풀 구성을 정의합니다. 노드 풀의 이름을 default로 설정하고, 단일 노드를 지정하고(노드 수 = 1), Standard_D2_v2 가상 머신 크기를 선택합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아이덴티티 블록은 AKS 클러스터에 시스템 지정 관리되는 아이덴티티를 사용하려는 것을 나타냅니다. 이 관리되는 아이덴티티는 클러스터가 Azure Container Registry와 같은 다른 Azure 리소스에 액세스할 수 있도록 사용할 수 있습니다.\n\n마지막으로 우리는 클러스터 리소스에 키가 \"환경\"이고 값이 \"Production\"인 태그를 추가합니다.\n\n# 유지보수 창구 관리\n\nAKS 패치를 자동화하기 위해 AKS 클러스터 리소스 내에서 maintenance_window_auto_upgrade 및 maintenance_window_node_os 블록을 활용할 것입니다. 이러한 블록을 사용하여 자동 업그레이드 및 노드 OS 업그레이드를 위한 주기, 간격, 월별 일, 지속 시간, 시작 시간, UTC 오프셋 및 시작 날짜를 정의할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리는 var.automatic_channel_upgrade 및 var.node_os_channel_upgrade 변수의 값에 따라 조건에 따라 유지 관리 창 구성을 동적 블록을 사용하여 포함합니다.\n\nmaintenance_window_auto_upgrade 블록은 Kubernetes 클러스터 자체의 자동 업그레이드 설정을 구성하는 데 사용됩니다. 여기에서는 업그레이드 채널 (패치, 빠른, 노드 이미지 또는 안정), 업그레이드 빈도 (주간, 월간 등), 업그레이드할 달의 날짜, 유지 관리 창의 기간, 시작 시간, UTC 오프셋 및 시작 날짜를 지정할 수 있습니다.\n\n```js\ndynamic \"maintenance_window_auto_upgrade\" {\n  for_each = var.automatic_channel_upgrade != \"none\" ? [1] : []\n  content {\n    frequency     = var.auto_upgrade_frequency\n    interval      = var.auto_upgrade_interval\n    day_of_month  = var.auto_upgrade_day_of_month\n    duration      = var.auto_upgrade_duration\n    start_time    = var.auto_upgrade_start_time\n    utc_offset    = var.auto_upgrade_utc_offset\n    start_date    = var.auto_upgrade_start_date\n  }\n}\n```\n\n마찬가지로, maintenance_window_node_os 블록은 노드 OS 이미지의 업그레이드 설정을 구성하는 데 사용됩니다. 업그레이드 채널 (Unmanaged, SecurityPatch, NodeImage 또는 None), 빈도, 달의 날짜, 지속 시간, 시작 시간, UTC 오프셋 및 시작 날짜를 지정할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```json\ndynamic \"maintenance_window_node_os\" {\n  for_each = var.node_os_channel_upgrade != \"None\" ? [1] : []\n  content {\n    frequency     = var.node_os_upgrade_frequency\n    interval      = var.node_os_upgrade_interval\n    day_of_month  = var.node_os_upgrade_day_of_month\n    duration      = var.node_os_upgrade_duration\n    start_time    = var.node_os_upgrade_start_time\n    utc_offset    = var.node_os_upgrade_utc_offset\n    start_date    = var.node_os_upgrade_start_date\n  }\n}\n```\n\n이 유지 보수 창을 구성함으로써, 우리는 지정된 일정 및 환경 설정에 따라 AKS 클러스터 및 노드 OS 이미지가 자동으로 패치되고 업데이트되도록 보장할 수 있습니다. 이를 통해 수동 개입이 줄어들고 전체적인 보안과 안전성이 향상됩니다.\n\n# 변수 정의\n\nTerraform 구성을 더 유연하고 재사용 가능하게 만들기 위해 유지 보수 창 설정에 대한 변수를 정의합니다. 이러한 변수는 업그레이드 채널, 빈도, 기간, 시작 시간 및 기타 매개변수를 사용자 정의할 수 있도록 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음과 같이 변수를 정의합니다:\n\n```js\n변수 \"automatic_channel_upgrade\" {\n    유형        = 문자열\n    설명 = \"이 Kubernetes 클러스터의 업그레이드 채널입니다. patch, rapid, node-image, stable 중에서 선택할 수 있습니다. 이 필드를 생략하면 해당 값은 없음으로 설정됩니다.\"\n    기본값     = \"rapid\"\n유효성 검사 {\n        조건     = (var.automatic_channel_upgrade == null ? true : contains([\"patch\", \"rapid\", \"node-image\", \"stable\"], var.automatic_channel_upgrade))\n        오류 메시지 = \"반드시 'patch', 'rapid', 'node-image', 'stable' 또는 null이어야 합니다. 기본값: null.\"\n    }\n}\n\n변수 \"node_os_channel_upgrade\" {\n    유형        = string\n    설명 = \"이 Kubernetes 클러스터 노드의 OS 이미지의 업그레이드 채널입니다. Unmanaged, SecurityPatch, NodeImage, None 중에서 선택할 수 있습니다.\"\n    기본값     = \"Unmanaged\"\n}\n```\n\n이러한 변수들은 Kubernetes 클러스터 및 노드 OS 이미지의 업그레이드 채널을 제어합니다. automatic_channel_upgrade 변수를 사용하면 클러스터의 업그레이드 채널을 지정할 수 있으며, patch, rapid, node-image, stable과 같은 옵션이 있습니다. node_os_channel_upgrade 변수는 노드 OS 이미지의 업그레이드 채널을 제어하며, Unmanaged, SecurityPatch, NodeImage, None과 같은 옵션을 갖습니다.\n\n또한 유지 관리 창 설정을 구성하는 변수들을 정의합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nvariable \"auto_upgrade_frequency\" {\n    description = \"유지 관리 빈도입니다. 가능한 옵션은 주간, 절대월간 및 상대월간입니다.\"\n    default     = \"AbsoluteMonthly\"\n}\n\nvariable \"auto_upgrade_day_of_month\" {\n    description = \"유지 보수 실행을 위한 달의 날짜입니다. 절대월간 빈도와 함께 필요합니다. 0부터 31 사이의 값(포함)입니다.\"\n    default     = \"9\"\n}\nvariable \"auto_upgrade_duration\" {\n    description = \"유지 관리가 실행되는 창의 기간입니다.\"\n    default     = \"4\"\n}\nvariable \"auto_upgrade_start_time\" {\n    description = \"유지 보수가 시작되는 시간입니다. utc_offset에 따라 결정된 시간대를 기준으로합니다. 형식은 HH:mm입니다.\"\n    default     = \"12:33\"\n}\nvariable \"auto_upgrade_utc_offset\" {\n    description = \"클러스터 유지 관리를 위한 시간대를 결정하는데 사용됩니다.\"\n    default     = \"+00:00\"\n}\nvariable \"auto_upgrade_start_date\" {\n    description = \"유지 보수 창이 효력을 발생하는 날짜입니다.\"\n    default     = \"2024-05-09T00:00:00Z\"\n}\nvariable \"auto_upgrade_interval\" {\n    description = \"유지 보수 실행 간격입니다. 주간 또는 월간 기반으로이 간격이 지정됩니다.\"\n    default     = \"1\"\n}\n```\n\n이러한 변수들은 Kubernetes 클러스터의 유지 관리 창에 대한 여러 측면을 제어합니다. 주기(주간, 월간), 달의 날짜, 기간, 시작 시간, UTC 오프셋, 시작 날짜 및 간격과 같은 것이 포함됩니다.\n\n노드 OS 유지 관리 창에 대해 유사한 변수가 정의되어 있습니다:\n\n```js\nvariable \"node_os_upgrade_frequency\" {...}\nvariable \"node_os_upgrade_day_of_month\" {...}\nvariable \"node_os_upgrade_duration\" {...}\nvariable \"node_os_upgrade_start_time\" {...}\nvariable \"node_os_upgrade_utc_offset\" {...}\nvariable \"node_os_upgrade_start_date\" {...}\nvariable \"node_os_upgrade_interval\" {...}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이러한 변수를 정의함으로써, 쿠버네티스 클러스터와 노드 OS 이미지의 유지 보수 창 설정을 쉽게 사용자 정의하고 조정할 수 있습니다. 이는 우리의 테라폼 구성을 다양한 환경과 요구 사항에 걸쳐 더 유연하고 재사용 가능하게 만들어 줍니다.\n\n# 출력 설정 구성\n\nAKS 클러스터에 대한 중요 정보를 검색하기 위해 출력 블록을 정의합니다. 이러한 출력을 사용하면 클라이언트 인증서 및 원시 쿠버네티스 구성에 액세스할 수 있습니다.\n\n```js\noutput \"client_certificate\" {\n  value     = azurerm_kubernetes_cluster.example.kube_config[0].client_certificate\n  sensitive = true\n}\n\noutput \"kube_config\" {\n  value     = azurerm_kubernetes_cluster.example.kube_config_raw\n  sensitive = true\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nclient_certificate 출력은 Kubernetes 클러스터와 인증하는 데 필요한 클라이언트 인증서를 제공합니다. Terraform이 sensitive = true로 표시함으로써, 해당 값이 계획 출력에 표시되지 않거나 상태 파일에 저장되지 않도록 보장합니다.\n\nkube_config_raw 출력에는 클러스터 엔드포인트, 클라이언트 인증서 및 클러스터에 연결하는 데 필요한 기타 정보가 포함되어 있습니다. 이 출력도 민감한 데이터를 보호하기 위해 sensitive로 표시됩니다.\n\n이러한 출력을 정의함으로써, AKS 클러스터의 클라이언트 인증서 및 Kubernetes 구성에 쉽게 액세스할 수 있습니다. 이를 통해 컨테이너 애플리케이션을 안전하게 연결하고 관리할 수 있습니다.\n\n# 경보 및 작업 그룹 설정하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAKS 클러스터의 생성 또는 업데이트 작업을 모니터링하기 위해, azurerm_monitor_activity_log_alert 리소스를 사용하여 Azure Monitor Activity Log Alert를 설정했습니다. 이 경고는 AKS 클러스터의 생성 또는 업데이트 작업이 시작될 때 트리거되어 진행 중인 변경 사항을 추적할 수 있도록 합니다.\n\n```js\nresource \"azurerm_monitor_activity_log_alert\" \"aks-cluster-activity-log-alert\" {\n  name                = \"${azurerm_resource_group.example.name}-aks-activity-Started-alert\"\n  resource_group_name = azurerm_resource_group.example.name\n  scopes              = [azurerm_kubernetes_cluster.example.id]\n  description         = \"이 경고는 시작된 Azure Kubernetes Service (AKS) 클러스터의 생성 또는 업데이트 작업을 모니터링합니다. AKS 클러스터의 생성 또는 업데이트 작업이 시작될 때 트리거되어 진행 중인 변경 사항을 추적할 수 있습니다.\"\n  enabled             = true\n  criteria {\n    category           = \"Administrative\"\n    level              = \"Informational\"\n    operation_name     = \"Microsoft.ContainerService/managedClusters/write\"\n    status             = \"Started\"\n    resource_provider  = \"Create or update managed cluster\"\n   }\n  action {\n    action_group_id = azurerm_monitor_action_group.aks-activity-log-action-Started.id\n  }\n}\n```\n\n또한, azurerm_monitor_action_group 리소스를 사용하여 Azure Monitor Action Group을 생성했습니다. 이 액션 그룹은 활동 로그 경고와 연결되어 경고가 활성화될 때 Logic App을 트리거합니다.\n\n```js\nresource \"azurerm_monitor_action_group\" \"aks-activity-log-action-Started\" {\n  name                = \"${azurerm_resource_group.example.name}-aks-activity-log-action-Started\"\n  resource_group_name = azurerm_resource_group.example.name\n  short_name          = \"akslog\"\n  logic_app_receiver {\n    name                    = \"logicappaction-patch-start\"\n    resource_id             = \"\"\n    callback_url            = azurerm_logic_app_trigger_http_request.logicapp-started-trigger.callback_url\n    use_common_alert_schema = true\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이러한 경고 및 액션 그룹을 설정함으로써 AKS 클러스터를 효과적으로 모니터링하여 생성 또는 업데이트 작업이 발생할 때 필요에 따라 추가 작업이나 알림을 수행하는 로직 앱을 트리거할 수 있습니다.\n\n# 결론\n\n이 블로그 포스트에서는 Terraform과 Azure의 유지 보수 창 기능을 사용하여 AKS 패치를 자동화하는 방법에 대해 살펴보았습니다. AKS 클러스터를 정의하고 유지 보수 창을 구성함으로써 최신 패치와 업데이트를 반영하여 클러스터가 항상 최신 상태를 유지할 수 있습니다. 이 접근 방식은 패치 프로세스를 간소화하고 수동 노력을 줄이며 Kubernetes 환경의 전반적인 보안과 안정성을 향상시킵니다.\n\n이 자동화 프로세스에 관련된 주요 단계는 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Azure Provider를 구성하고 리소스 그룹을 생성합니다.\n- 필요한 구성, 노드 풀 및 관리 식별자와 함께 AKS 클러스터를 정의합니다.\n- 자동 업그레이드 및 노드 OS 업그레이드 일정을 예약하는 maintenance_window_auto_upgrade 및 maintenance_window_node_os 블록을 활용합니다.\n- 업그레이드 채널, 빈도, 기간, 시작 시간 및 기타 매개변수를 사용자 정의하는 변수를 정의합니다.\n- AKS 클러스터에 관한 중요한 정보를 검색하기 위해 outputs를 구성합니다.\n- AKS 클러스터 생성 또는 업데이트 작업을 모니터링하고 추적하기 위해 Azure Monitor Activity Log Alerts 및 Action Groups를 설정합니다.\n\n이 블로그 시리즈의 다음 부분에서는 Logic Apps를 사용하여 자동화된 Slack 메시지를 보내 AKS 패치 프로세스의 상태에 대해 알림을 받는 내용을 살펴볼 것입니다. 더 많은 자동화 소식을 기대해 주세요!\n","ogImage":{"url":"/assets/img/2024-06-19-AutomateAKSPatchingandGetSlackNotificationswithTerraformandLogicAppsPart1_0.png"},"coverImage":"/assets/img/2024-06-19-AutomateAKSPatchingandGetSlackNotificationswithTerraformandLogicAppsPart1_0.png","tag":["Tech"],"readingTime":16},{"title":"Kubernetes 클러스터에서 노드 회전 자동화 머신 이미지 업데이트 최적화하기","description":"","date":"2024-06-19 13:13","slug":"2024-06-19-StreamliningMachineImageUpdatesAutomatingNodeRotationinKubernetesClusters","content":"\n<img src=\"/assets/img/2024-06-19-StreamliningMachineImageUpdatesAutomatingNodeRotationinKubernetesClusters_0.png\" />\n\n# 문제\n\nSage AI 인프라 팀은 모든 환경에서 우리의 서비스 및 시스템의 유지 보수와 안정성을 담당합니다. 때로는 현재 머신 이미지에 보안 취약점이 발견된 경우와 같이 상대적으로 짧은 시간 내에 Kubernetes 클러스터의 노드를 새로운 머신 이미지로 업데이트해야 할 때도 있습니다. 우리는 Amazon 클라우드를 사용하기 때문에 작업하는 것은 Amazon Machine Images (AMIs)이지만, 문제와 해결책은 어떤 클라우드 환경의 Kubernetes 클러스터에도 적용 가능합니다.\n\n우리의 경우, 새로운 AMI ID를 적용할 것이지만, 그런 다음 노드가 새 AMI를 적용할 수 있도록 시간 내에 회전되도록 보장해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n과거에는 오래된 AMI를 감지하여 해당 노드를 드레인하고 있는 사용자 정의 쉘 스크립트를 사용했습니다(해당 노드에서 실행 중인 파드는 제어된 방식으로 종료되어야 하며, 해당 서비스에 중단이 발생하지 않도록해야 합니다). 이 방법을 사용하면 몇 가지 단점이 있었습니다. 첫째, 누군가가 수동으로 스크립트를 호출하고 모니터링해야 했습니다. 둘째, 클러스터에 액세스하기 위해 인증 프록시를 사용하고 있으며, 해당 프록시가 있는 노드를 드레인하면 스크립트가 서버 연결을 잃고 오류가 발생할 수 있습니다. 때로는 이러한 일이 연이어 발생할 수도 있었습니다. 당연히 노드를 회전시키는 작업은 해당 작업을 담당하는 엔지니어에게 상당한 시간, 주의 및 수동 노력이 필요했습니다.\n\n# 솔루션 설계\n\n우리는 클러스터에서 AMI를 업데이트하는 엔지니어들에게 주는 부담을 크게 줄일 수 있는 솔루션을 찾기로 결정했습니다. 오래된 AMI가 있는 노드를 자동으로 회전시킬 수 있는 도구가 필요했다는 것을 알았지만, 이 요구 사항은 넓은 범위를 요구합니다. 조금 더 세부적으로 이를 분석해보면 프로젝트에 대한 몇 가지 요구 사항이 있었습니다;\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 우리는 쉽게 운영할 수 있는 도구를 원했습니다. 가장 이상적인 경우에는 감독이 필요하지 않은 것이 좋습니다. 엔지니어의 시간은 귀중하며 딱딱한 도구를 감시하는 데 그 시간을 낭비하는 것은 별 의미가 없습니다.\n- 필요한 경우에는 간편하게 유지 및 업데이트할 수 있는 도구를 원했습니다. 우리는 많은 서드파티 도구를 사용하고 주기적으로 모두를 업그레이드해야 할 때가 있습니다. 그 중 일부는 다른 것들보다 업데이트하기가 훨씬 어려웠습니다.\n- 우리는 쿠버네티스 클러스터에서 실행 중인 워크로드에 대한 설정한 모니터링 및 가시성 프로세스를 사용할 수 있는 솔루션을 원했습니다.\n\n## 우리의 솔루션\n\n우리는 시스템을 두 단계로 작동하도록 설계하기로 결정했습니다. 교체해야 할 노드를 확인하고 해당 노드의 워크로드를 소진하는 것입니다.\n\n간단히 말해서, 노드를 소진한다는 것은 쿠버네티스가 해당 노드에 대해 어떠한 새로운 워크로드도 시도하지 않도록 태그를 달아놓고, 해당 노드의 프로세스와 상태가 해체되고, 새로운 노드가 대신 생성될 때까지 대기하는 것을 의미합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 작업을 하는 데 몇 가지 이유가 있었습니다.\n\n- 이를 통해 두 가지 구성 요소를 독립적으로 발전 및 유지할 수 있습니다.\n- 구성 요소에는 각각 다른 수명 주기 기대치가 있으며, 노드 선택 구성 요소는 선택 기준 또는 기본 인프라 변경에 따라 변경될 필요가 있습니다. 반면, 노드를 비우는 구성 요소는 비교적 안정적인 상태로 유지됩니다.\n- 노드 선택 구성 요소는 주로 AWS API와 상호 작용하고, 노드 비우기는 Kubernetes 컨트롤러입니다.\n\n두 구성 요소가 별도로 개발되는 또 다른 이유는 필요에 따라 서로 다른 언어로 작성되어 있으며, 선택 노드를 선택하는 구성 요소는 Bash 및 AWS CLI와 같은 성숙한 도구 및 jq와 같은 JSON 조작 도구 사용의 용이성과 간결성이 더 높을 것입니다. 반면에 우리는 솔루션을 Go 생태계에서 구현하기로 선택했습니다. 왜냐하면 Kubernetes 컨트롤러를 작성하는 데 라이브러리 및 문서 지원이 많기 때문에 노드를 비우는 구성 요소를 Go로 작성하는 것이 유리했기 때문입니다.\n\n다음으로, 부분 간 통신 방식을 결정해야 했습니다. 일반적으로 노드에 작업을 표시하는 방법은 레이블을 지정하는 것입니다. 그러나 이 경우에는 taint를 사용하기로 결정했습니다. 장점은 taint를 한 번 설정하면 해당 노드에는 pod를 실행할 수 없으며, 추방된 pod가 해당 노드에 실행되는 것을 방지합니다. 따라서 노드 선택 작업은 노드에 taint를 설정하고, 비우기 작업은 노드 선택 작업에 의해 tainted된 노드를 식별하고 해당 pod를 비웁니다. 그런 다음 비워진 노드의 후속 종료는 클러스터 자동 확장기에 의해 처리됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 거부된 방식\n\nAWS Lambda를 기반으로 한 노드 드레이너 구현체가 여러 가지 있습니다(예: https://github.com/aws-samples/amazon-k8s-node-drainer) 하지만, 우리는 클러스터 내에서 실행되도록 설계된 도구가 필요했습니다. 이는 이미 우리가 갖고 있는 모니터링 기능을 사용하기 위함입니다.\n\nAWS Auto Scaling 그룹 노드 새로 고침 프로세스를 기반으로 한 노드 드레이닝을 구현한 프로젝트들이 이미 존재하며, https://github.com/rebuy-de/node-drainer가 대표적인 예입니다. 이 프로젝트를 고려해 보았지만, 해당 프로젝트는 2023년 3월 이후에 어떠한 업데이트도 릴리스하지 않았기 때문에 채택하는 것이 리스크가 될 수 있습니다. 만약 이 프로젝트나 관련 종속성에 심각한 취약점이 발견된다면, 업데이트된 이미지를 얻을 수 없게 될 수 있으며, 우리 자신의 포크를 유지보수해야 할 수도 있습니다.\n\n# 구현\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n해결 방법의 두 번째 부분은 nodes를 감시하고 지정된 draining taint가 설정되면 node의 포드를 제거하기 시작하는 Kubernetes 컨트롤러로 구현되었습니다. 포드가 떠날 때까지 노드를 제거하는 작업은 타임 아웃 될 때까지 계속 됩니다 (가끔 포드가 떠나고 싶어하지 않을 수도 있어요) 또는 타임아웃 시간이 경과할 때까지입니다. 일정 시간이 지나면 그 노드를 다시 시도합니다. 프로그램은 항상 노드 제거를 직렬화하고, 노드를 처리한 후 클러스터에 보류 중인 포드가 없을 때까지 기다린 후 계속합니다. 이는 클러스터의 용량 문제를 최소화하기 위해 수행됩니다 - 모든 포드가 제거를 위해 tainted되어 있으면 새로운 노드가 생성될 때까지 새로운 포드를 시작할 수 없습니다.\n\n![이미지](/assets/img/2024-06-19-StreamliningMachineImageUpdatesAutomatingNodeRotationinKubernetesClusters_1.png)\n\n# 첫 번째 오픈 소스 기여물로 발표 결정\n\nSage AI 팀은 우리가 내부적으로 개발한 프로젝트들을 확인하여 일반 커뮤니티에 혜택을 줄 수 있다고 판단한 프로젝트들을 식별하기로 결정했습니다. 우리 인프라 팀은 MLOps 분야에서 많은 훌륭한 작업을 수행했고, 위에서 설명한 워크플로우의 자동화가 오픈 소스 커뮤니티에 공개되었다는 것을 자랑스럽게 발표합니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리의 방식은 내부에서 이미 1년 넘게 사용되어 왔고, 이제 코드는 여기에서 찾을 수 있습니다; https://github.com/sageailabs/ektopistis .\n\n관심이 있으시면 자유롭게 살펴보고, 유용하다고 판단되면 귀하의 환경에서 사용하거나 피드백이나 코드로 기여해 주시기 바랍니다!\n\n프로젝트 README의 설치 섹션의 지침을 따라 Helm을 사용하여 클러스터에 설치할 수 있습니다. 노드 선택 구성 요소의 의미론은 임의적이며, 원하는 선택 기준과 태깅 의미론에 기반하여 구성할 수 있습니다. 예를 들어, AWS 오토 스케일링 그룹에서 시작된 모든 클러스터 노드를 표시하고 설정이 ASG의 론칭 템플릿과 일치하지 않는 스크립트가 있습니다.\n\n우리는 우리의 도구를 공유함으로써 더 나은 해결책으로 이어질 것이라고 믿습니다. 귀하의 피드백과 기여를 기대하며, 즐거운 협업을 기대하고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 계획된 미래 작업에 대한 참고사항\n\n저희 노드 드레이너 구현은 중요한 작업 부하의 업데이트를 방해하지 않기 위해 클러스터에 보류 중인 파드가 있을 때 작업을 중지합니다. 그러나 이에는 중요한 하다고 할 수 있는 단점이 있습니다. 클러스터가 클수록 활동이 많을수록 파드의 순환율이 높아집니다. 이로 인해 보류 중인 파드가 계속 발생하여 노드 드레이너의 현재 버전이 멈춰있는 장기간이 발생할 수 있습니다. 저희는 이 대기 정책을 개선하여 프로세스를 가속화하는 계획이 있습니다.\n","ogImage":{"url":"/assets/img/2024-06-19-StreamliningMachineImageUpdatesAutomatingNodeRotationinKubernetesClusters_0.png"},"coverImage":"/assets/img/2024-06-19-StreamliningMachineImageUpdatesAutomatingNodeRotationinKubernetesClusters_0.png","tag":["Tech"],"readingTime":7},{"title":"Kubernetes K8s ConfigMap 또는 Secret가 업데이트될 때 배포 자동 재시작하기","description":"","date":"2024-06-19 13:11","slug":"2024-06-19-KubernetesAutoRestartDeploymentswhenK8sConfigMaporSecretisUpdated","content":"\n## 자동 롤아웃 재시작: K8s ConfigMap 또는 Secret가 업데이트될 때 배포 다시 시작하기\n\n쿠버네티스 배포는 모든 쿠버네티스 클러스터에서 가장 일반적인 리소스 중 하나입니다. 우리는 모두 pod를 K8s 배포를 사용하여 실행하여 높은 가용성을 보장하고, pod가 삭제되면 자동으로 생성되도록합니다.\n\n애플리케이션이 항상 여러 환경에서 원활하게 실행되도록하기 위해 구성이 필요한 것은 매우 흔합니다. 데이터베이스 사용자 이름, 비밀번호 등과 같은 중요한 정보가 필요할 수도 있습니다. 쿠버네티스에서는 구성 맵과 시크릿을 사용하여 응용 프로그램별 데이터를 저장하고 pod로 주입하여 응용 프로그램에서 사용할 수 있도록 할 수 있습니다.\n\n그렇다면 구성 맵이나 시크릿의 값을 업데이트했을 때는 어떨까요? 최신 값을 반영하려면 pod를 다시 시작해야합니다, 맞죠? 또는 롤아웃을 다시 시작하여 새로운 pod를 생성하게 할 수도 있습니다. 이제 상상해보세요. 공통 configmap 또는 secret을 사용하는 수백 개의 배포가 있고 그 값을 업데이트하고 사용하는 것이 최신 값이라는 것을 확실하게 해야한다고 가정해보세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저희는 AWS Secrets Manager에 비밀을 저장하고, Kubernetes Secrets Store CSI Driver를 위해 AWS Secrets 및 구성 제공자(ASCP)로부터 Kubernetes Secrets를 생성합니다.\n\n이 블로그 게시물에서는 Secret 또는 ConfigMap이 업데이트될 때 Kubernetes 배포를 자동으로 롤아웃 및 다시 시작하는 방법에 대해 설명하겠습니다.\n\n# 아키텍처 다이어그램:\n\n![Architecture Diagram](/assets/img/2024-06-19-KubernetesAutoRestartDeploymentswhenK8sConfigMaporSecretisUpdated_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 시작해 봅시다!\n\n### 준비물:\n\n- EKS 클러스터\n- EKS를 위한 OIDC 제공자 구성 필요\n- Kubectl\n- AWS CLI\n\n### 단계 1: ASCP를 위한 IAM 역할 및 정책 생성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nASCP(Amazon EKS Security Token Service)는 Amazon EKS 파드 ID를 검색하여 IAM 역할로 교환합니다. 해당 IAM 역할에 대한 IAM 정책에서 권한을 설정합니다. ASCP가 IAM 역할을 가정하면 권한을 부여받은 시크릿에 액세스할 수 있습니다. 다른 컨테이너는 IAM 역할과 연결되지 않는 한 시크릿에 액세스할 수 없습니다.\n\n- IAM 정책 문서 작성\n  \"secrets_policy\"라는 이름의 파일을 만들고 다음 내용을 추가하십시오.\n\n```js\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": [\n                \"secretsmanager:DescribeSecret\",\n                \"secretsmanager:GetSecretValue\"\n            ],\n            \"Effect\": \"Allow\",\n            \"Resource\": \"*\"\n        }\n}\n```\n\n2. 다음 명령을 실행하여 IAM 정책을 만듭니다.\n   IAM 정책을 IAM 역할에 연결할 때 policy ARN을 메모하십시오.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\naws iam create-policy \\\n    --policy-name my-secret-manager-policy \\\n    --policy-document file://secrets_policy\n```\n\n3. IAM 역할에 신뢰 정책 생성하기\n   \"trust_policy\"라는 이름의 파일을 생성하고 다음 내용을 추가하세요. 올바른 값으로 대체해야 합니다. `SERVICE_ACCOUNT_NAME`은 임의로 지정할 수 있지만 Kubernetes에서 실제 서비스 계정을 생성할 때 동일한 이름을 사용해야 합니다.\n\n```js\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n      \"Principal\": {\n        \"Federated\": \"arn:aws:iam::<AWS_ACCOUNT_ID>:oidc-provider/oidc.eks.<AWS_REGION>.amazonaws.com/id/<OIDC_ID>\"\n      },\n      \"Condition\": {\n        \"StringEquals\": {\n          \"oidc.eks.<AWS_REGION>.amazonaws.com/id/<OIDC_ID>:aud\": \"sts.amazonaws.com\",\n          \"oidc.eks.<AWS_REGION>.amazonaws.com/id/<OIDC_ID>:sub\": \"system:serviceaccount:<K8S_NAMESPACE>:<SERVICE_ACCOUNT_NAME>\"\n        }\n      }\n    }\n  ]\n}\n```\n\n4. 다음 명령어를 실행하여 IAM 역할을 만드세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\naws iam create-role --role-name my-secret-manager-role --assume-role-policy-document file://trust_policy\n```\n\n5. Attach IAM policy to IAM Role\n\n```js\naws iam attach-role-policy --policy-arn <your_policy_arn> --role-name my-secret-manager-role\n```\n\n우리는 필요한 모든 IAM 역할과 정책을 생성했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 2: ASCP 설치 및 구성\n\n이제 2개의 Helm 차트를 설치해야 합니다.\n\n- AWS Secrets and Configuration Provider (ASCP) 차트 설치\n\n```js\n# ASCP Helm 차트 리포지토리 추가\nhelm repo add aws-secrets-manager https://aws.github.io/secrets-store-csi-driver-provider-aws\n\n# ASCP Helm 차트 설치\nhelm install -n kube-system secrets-provider-aws aws-secrets-manager/secrets-store-csi-driver-provider-aws\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. Secrets Store CSI Driver 차트 설치\n\n- Secrets Store CSI Driver 차트를 위한 helm 레포지토리 추가\n\n```js\n# Secrets Store CSI Driver 차트 레포지토리 추가\nhelm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts\n```\n\n- 기본값 확인\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 기본 값 가져오기\n\nhelm show values secrets-store-csi-driver/secrets-store-csi-driver > secrets-store-csi-driver.yaml\n\n- secrets-store-csi-driver.yaml 파일에서 다음 값을 업데이트하세요.\n\n## K8S Secrets 동기화에 필요한 RBAC 역할 및 바인딩 설치 여부\n\nsyncSecret:\nenabled: true\n\n## 시크릿 로테이션 기능 활성화 [알파]\n\nenableSecretRotation: true\n\n위의 구성은 \"secrets-store-csi-driver\"가 AWS Secret Manager에서 최신 값을 가져와 해당 값을 Kubernetes Secrets 객체에 업데이트할 수 있게 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n회전-투표-간격은 기본적으로 2분으로 설정되어 있지만, 속성 rotationPollInterval을 설정함으로써 변경할 수 있습니다.\n\n- Helm 차트 설치\n\n```js\n# Helm 차트 설치\nhelm install -n kube-system csi-secrets-store secrets-store-csi-driver/secrets-store-csi-driver -f secrets-store-csi-driver.yaml\n```\n\n# 단계 3: AWS Secret Manager에 테스트 시크릿 생성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAWS Secret Manager에서 테스트 시크릿을 생성할 것입니다.\n\n```js\naws secretsmanager create-secret \\\n    --name my-test-secret \\\n    --description \"CLI로 생성한 내 테스트 시크릿.\" \\\n    --secret-string \"{\\\"user\\\":\\\"my-user\\\",\\\"password\\\":\\\"예시-비밀번호\\\"}\"\n```\n\n# 단계 4: Kubernetes ServiceAccount 생성\n\n이제 IAM 역할을 가정할 수 있도록 파드에 허용하는 ServiceAccount를 생성할 수 있습니다. 이 ServiceAccount는 K8s 배포에서 사용될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nserviceaccount.yaml이라는 이름의 파일을 생성해주세요.\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: <your_service_account_name> # 이 이름은 IAM 신뢰 정책을 만들 때 지정한 이름과 일치해야 합니다.\n  annotations:\n    eks.amazonaws.com/role-arn: <IAM_ROLE_ARN>\n```\n\n다음 명령을 실행하여 K8s에서 서비스 계정을 생성합니다.\n\n```bash\nkubectl apply -f serviceaccount.yaml\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 5: 테스트 객체 생성하기\n\n이제 필요한 모든 리소스를 배포했습니다. 이제 테스트 객체를 만들어 봅시다.\n\n- 이름이 “my-test-secret-manifest.yaml”인 파일 생성\n\n```js\n---\napiVersion: secrets-store.csi.x-k8s.io/v1\nkind: SecretProviderClass\nmetadata:\n  name: aws-secrets-providerclass\nspec:\n  provider: aws\n  secretObjects:\n    - secretName: my-test-k8s-secret\n      type: Opaque\n      data:\n        - objectName: user\n          key: user\n        - objectName: password\n          key: password\n  parameters:\n    objects: |\n      - objectName: arn:aws:secretsmanager:<AWS_REGION>:<AWS_ACCOUNT_ID>:secret:my-test-secret\n        jmesPath:\n          - path: user\n            objectAlias: user\n          - path: password\n            objectAlias: password\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: secret-rotation-test-ubuntu-deployment\n  labels:\n    app: ubuntu\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ubuntu\n  template:\n    metadata:\n      labels:\n        app: ubuntu\n    spec:\n      serviceAccountName: <your_service_account_name> # 이 이름은 단계 4에서 만든 서비스 계정 이름과 일치해야 합니다\n      volumes:\n      - name: mount-secrets-access\n        csi:\n          driver: secrets-store.csi.k8s.io\n          readOnly: true\n          volumeAttributes:\n            secretProviderClass: \"aws-secrets-providerclass\"\n      containers:\n      - name: ubuntu\n        image: ubuntu\n        command: [\"sleep\", \"123456\"]\n        env:\n        - name: USER\n          valueFrom:\n            secretKeyRef:\n              name: my-test-k8s-secret\n              key: user\n        - name: PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: my-test-k8s-secret\n              key: password\n        volumeMounts:\n        - name: mount-secrets-access\n          mountPath: \"/mnt/aws-secrets\"\n          readOnly: true\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. manifest를 적용하십시오\n\n```js\nkubectl apply -f my-test-secret-manifest.yaml\n```\n\n3. 다음 리소스가 생성됩니다.\n\n- SecretProviderClass 리소스 - AWS Secret Manager에서 데이터를 가져와 K8s Secret를 생성합니다\n- 볼륨 마운트가 있는 배포 - SecretProviderClass를 볼륨으로 마운트해야 합니다\n- Kubernetes Secret - 파드 내에서 환경 변수로 주입됩니다\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래 다이어그램은 YAML을 적용할 때 뒷단에서 무슨 일이 벌어지는지 잘 시각화한 것입니다.\n\n![다이어그램](/assets/img/2024-06-19-KubernetesAutoRestartDeploymentswhenK8sConfigMaporSecretisUpdated_1.png)\n\n4. 모든 것이 배포되었는지 확인해보세요.\n\n```js\n# SecretProviderClass 확인\nkubectl get SecretProviderClass aws-secrets-providerclass -o yaml\n\n# 배포 확인\nkubectl get deploy secret-rotation-test-ubuntu-deployment -o yaml\n\n# Pod 확인\nkubectl get po <pod_name> -o yaml\n\n# Secret 가져오기\nkubectl get secret my-test-k8s-secret -o yaml\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계 6: Reloader 설치하기\n\nReloader는 ConfigMap과 Secret의 변경 사항을 감지하고 관련된 DeploymentConfig, Deployment, DaemonSet, StatefulSet 및 Rollout과 함께 Pod의 롤링 업그레이드를 수행할 수 있습니다.\n\n- Reloader Helm Repo 추가\n\n```js\n# Helm Repo 추가\nhelm repo add stakater https://stakater.github.io/stakater-charts\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 기본값 가져오기\n\n```js\n# 기본값 가져오기\nhelm show values stakater/reloader > reloader.yaml\n```\n\n3. reloader.yaml 파일 업데이트하기\n\n```js\nreloader:\n  # 리더십 선출을 활성화하려면 true로 설정하여 여러 레플리카를 실행할 수 있습니다.\n  enableHA: true\n  deployment:\n    # 여러 레플리카를 실행하려면 reloader.enableHA = true로 설정합니다.\n    replicas: 2\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. Helm 차트 설치\n\n```js\n# Helm 차트 설치\nhelm install reloader -f reloader.yaml stakater/reloader -n kube-system\n```\n\n# 단계 7: Secret 업데이트로 테스트하기\n\n- Reloader는 주석에 영향을 받습니다.\n  기본 주석 reloader.stakater.com/auto는 주요 메타데이터에 있어야 합니다. 아래 명령을 사용하여 배포에 주석을 추가하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 배포 주석 추가\nkubectl annotate deployment secret-rotation-test-ubuntu-deployment \"reloader.stakater.com/auto=true\"\n```\n\n또는 다음 블록으로 배포 파일을 편집하고 적용할 수도 있습니다.\n\n```js\nmetadata:\n  annotations:\n    reloader.stakater.com/auto: \"true\"\n```\n\n2. AWS Secret Manager에서 시크릿 업데이트하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\naws secretsmanager put-secret-value \\\n      --secret-id my-test-secret \\\n      --secret-string \"{\\\"user\\\":\\\"diegor\\\",\\\"password\\\":\\\"SAMPLE-PASSWORD\\\"}\"\n```\n\n3. 한 번 시크릿이 AWS 시크릿 스토어 csi 드라이버에 업데이트되면 K8s 시크릿이 즉시 업데이트됩니다. K8s 시크릿이 업데이트되면 Reloader가 롤아웃을 다시 시작하도록 트리거합니다.\n\n```js\n# K8s 시크릿을 확인하세요. 새로운 값이 있어야 합니다.\nkubectl get secret my-test-k8s-secret -o yaml\n\n# Pod를 확인하세요. 몇 초 전에 시작되었어야 합니다.\nkubectl get po\n\n# Reloader 팟의 로그를 확인하세요.\nkubectl logs <reloader-pod-name> -n kube-system\n\n# Pod로 실행 후 새로운 값을 확인하세요.\nkubectl exec -it <pod_name> -- bash\n\n# Pod에 들어간 후 `env` 명령을 실행하세요. Pod에서 사용 가능한 모든 환경 변수가 출력됩니다.\n```\n\n# 단계 8: ConfigMap 업데이트를 테스트하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- \"my-test-cm-manifest.yaml\" 파일을 생성해주세요.\n\n```yaml\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-test-k8s-cm\ndata:\n  myvalue: \"Hello World\"\n  drink: coffee\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reloader-poc-ubuntu-deployment\n  labels:\n    app: ubuntu\n  annotations:\n    reloader.stakater.com/auto: \"true\"\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ubuntu\n  template:\n    metadata:\n      labels:\n        app: ubuntu\n    spec:\n      containers:\n        - name: ubuntu\n          image: ubuntu\n          command: [\"sleep\", \"123456\"]\n          env:\n            - name: DRINK\n              valueFrom:\n                configMapKeyRef:\n                  name: my-test-k8s-cm\n                  key: drink\n            - name: MYVALUE\n              valueFrom:\n                configMapKeyRef:\n                  name: my-test-k8s-cm\n                  key: myvalue\n```\n\n2. 매니페스트 적용\n\n```bash\nkubectl apply -f my-test-cm-manifest.yaml\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. my-test-cm-manifest.yaml 파일에서 configmap을 업데이트하세요.\n\n```yaml\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-test-k8s-cm\ndata:\n  myvalue: \"안녕하세요\"\n  drink: 차\n```\n\n4. 파일을 다시 적용하세요.\n\n```yaml\nkubectl apply -f my-test-cm-manifest.yaml\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n5. 확인\n\n```js\n# ConfigMap 확인\nkubectl get cm my-test-k8s-cm -o yaml\n\n# Pod 확인\nkubectl get po\n\n# Pod에 접속하여 새 값 확인\nkubectl exec -it <pod_name> -- bash\n\n# Pod에 들어간 후 `env` 명령어를 실행하면 Pod 내에서 사용 가능한 모든 환경 변수가 출력됩니다\n```\n\n축하합니다!!! secret-store-csi-driver와 reloader를 성공적으로 구성했습니다.\n\n감사합니다!!!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 참고 자료:\n\n- [AWS 공식 문서 - CSI 드라이버 통합](https://docs.aws.amazon.com/secretsmanager/latest/userguide/integrating_csi_driver.html)\n- [Bootlabs 기술 블로그 - AWS Secrets Manager in Kubernetes 시크릿 회전과 리로더](https://blog.bootlabstech.com/aws-secrets-manager-in-kubernetes-secret-rotation-and-reloader)\n- [Secrets Store CSI 드라이버 공식 홈페이지 - 시크릿 자동 회전](https://secrets-store-csi-driver.sigs.k8s.io/topics/secret-auto-rotation)\n- [Secrets Store CSI 드라이버 차트 값 설정 파일](https://github.com/kubernetes-sigs/secrets-store-csi-driver/blob/main/charts/secrets-store-csi-driver/values.yaml)\n- [Reloader GitHub 저장소](https://github.com/stakater/Reloader/tree/master)\n- [Reloader 작동 확인 문서](https://github.com/stakater/Reloader/blob/master/docs/Verify-Reloader-Working.md)\n- [Reloader 작동 방식 문서](https://github.com/stakater/Reloader/blob/master/docs/How-it-works.md)\n\n# 간단히 말하자면 🚀\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 계속 참여해 주세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 작가에게 박수를 보내고 팔로우를 눌러주세요 ️👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼에서 저희를 만나보세요: Stackademic | CoFeed | Venture | Cubed\n- 알고리즘 콘텐츠를 다뤄야 하는 블로그 플랫폼에 지쳤나요? Differ를 시도해보세요\n- PlainEnglish.io에서 더 많은 콘텐츠를 만나보세요\n","ogImage":{"url":"/assets/img/2024-06-19-KubernetesAutoRestartDeploymentswhenK8sConfigMaporSecretisUpdated_0.png"},"coverImage":"/assets/img/2024-06-19-KubernetesAutoRestartDeploymentswhenK8sConfigMaporSecretisUpdated_0.png","tag":["Tech"],"readingTime":19},{"title":"아마존 EKS의 미래","description":"","date":"2024-06-19 13:10","slug":"2024-06-19-FutureofAmazonEKS","content":"\nAWS re:Invent 2023 세션 중 \"Amazon EKS의 미래 (CON203)\"를 Nathan Taber, AWS의 Kubernetes 제품 총괄의 프레젠테이션을 시청해야 했어요. 이 기사에서는 논의된 주요 포인트들을 요약하겠으며, 이해를 돕기 위해 전체 내용을 확인해 보라는 주의문을 담을게요.\n\n# Kubernetes의 중요성\n\nKubernetes는 오케스트레이션을 위한 오픈 소스 기술로, 인기만 끌 뿐만 아니라 엄청난 성공을 거두었어요. Kubernetes의 관리 조직인 Cloud Native Computing Foundation (CNCF)의 설문 조사에 따르면, 지난 해 64%의 기업이 프로덕션에서 Kubernetes를 사용했으며, 추가 25%가 평가 중이거나 시범운영 중이었어요. 이러한 중요한 채용은 Kubernetes가 현대 IT 운영에서 발휘하는 중추적 역할을 반영하고 있어요. 이 기사에서는 이 인기 급증의 이유와 AWS가 Amazon EKS에 투자한 방대한 투자를 탐구해 보겠어요.\n\n## 그렇다면, 왜 사람들은 Kubernetes를 사용할까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 혁신 주행: 기관이 Kubernetes로 전환하는 주요 이유는 고객을 대신하여 혁신을 이루는 데 있습니다. 빠르게 움직이고 안전하고 신속하게 변화를주는 능력은 혁신에 대단히 중요합니다. Kubernetes는 개발팀을위한 표준 시스템과 표준 세트를 제공하여 조직이 변화를 수용하고 사용자를위한 더 나은 혁신을 이끌어 내도록합니다.\n- 고정 비용 감소: Kubernetes 도입의 또 다른 주요 동기는 고정 비용을 줄이기 위한 욕구입니다. 조직은 정적 자원에서 동적 공유 자원으로 전환하여 컨테이너를 사용하여 복잡한 계약을 분해하고 관리 오버헤드를 줄입니다. 이러한 전환은 비용 절감을 가져오면서 유연성과 확장성을 유지합니다.\n- 전체 조직 활성화: Kubernetes는 응용 프로그램을 조정하기 위한 API 표준을 제공하여 다양한 환경에 대한 공통 기반을 제공합니다. AWS 클라우드의 서로 다른 지역, 온프레미스 또는 다른 클라우드 제공 업체에서 실행 중이든 상관없이 Kubernetes를 사용하면 조직이 모든 배포 위치에서 일관되게 최상의 방법, 거버넌스 컨트롤, 보안 조치, 모니터링 및 비용 관리를 수립할 수 있습니다. 이 표준화는 조직이 인수, 합병 또는 멀티 클라우드 설정과 같은 시나리오에서도 복잡성을 관리할 수 있도록합니다.\n- 미래를 대비하고 위험 감소: Kubernetes는 즉각적인 운영 요구 사항뿐만 아니라 미래를 대비하고 위험을 감소하는 데도 도움을 줍니다. Kubernetes에서 제공하는 표준은 장기 개발 노력을 지원하고 기술 부채를 완화합니다. 이는 CEO 및 CTO뿐만 아니라 엔지니어 및 개발팀에게도 중요한 문제입니다.\n\nAWS의 Kubernetes 투자: 5주년을 축하하는 Amazon EKS는 AWS의 Kubernetes에 대한 중요한 투자를 대표합니다. AWS는 EKS를 강력한 플랫폼으로 만들기 위해 성실히 노력하고 성능, 규모, 신뢰성 및 가용성에서 뛰어납니다. CNCF 및 AWS 고객의 데이터에 따르면, AWS에서実行되는 Kubernetes 워크로드가 다른 모든 플랫폼보다 많이 있으며, 매주 수십억 개의 EC2 인스턴스 시간이 EKS에서 실행됩니다.\n\n## EKS에서 고객들이 무엇을하고 있을까요?\n\n고객들은 EKS를 다양한 목적으로 활용하고 있습니다. 활동 범위는 레거시 .NET 및 Java 응용 프로그램을 클라우드로 이전하고 데이터 처리 작업을 실행하며 실시간 백엔드를 구축하고 웹 프론트 엔드를 개발하는 등 다양합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n요즘에는 EKS와 Kubernetes를 활용한 기계 학습과 AI의 중요성이 크게 늘어났습니다. 생성적 AI와 로봇공학과 같은 다양한 분야를 다루며, 특히 저는 자율 주행 차량에 특히 흥미를 가지고 있습니다. EKS에서 중요한 자율 주행 차량 훈련 활동이 진행 중이라는 점을 강조하고 싶습니다. 기계 학습, kube ray, Spark, kube flow와 같은 도구를 활용하여 미래 기술을 개발 중인 기업들을 관찰하는 것은 현재의 환경에서 주목할 만하고 흥미로운 측면입니다.\n\n## Kubernetes 운영 체제\n\n![이미지](/assets/img/2024-06-19-FutureofAmazonEKS_0.png)\n\n인프라 조사에서 Kubernetes가 핵심적인 역할을 하는 복잡한 계층을 관찰하며, 다양한 인프라 요소를 조율하여 원활하게 통합하는 모습을 보게 됩니다. 고객들은 Kubernetes 위에 배포, 관측, 거버넌스, 트래픽 제어, 보안 제어를 추가하여 적극 참여하고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n놀랍게도 CNCF 내에서 599개의 프로젝트가 Kubernetes 내부 또는 옆에서 실행됩니다. 이 중 173개 프로젝트는 CNCF로부터 직접 지도 받는 개방형 지배를 갖고 있습니다. Kubernetes 위에 이러한 방대한 플랫폼 레이어를 관리하는 것은 상당한 일이죠.\n\n게다가 AWS는 자사의 서비스가 Kubernetes로의 기능 제공을 원활하게 하는 통합을 개발하기 위해 적극적으로 노력하고 있습니다. 또한, 통합 개발자 플랫폼(IDP)이 Kubernetes에서 응용 프로그램을 패키징하고 실행하며, 데이터 처리 작업을 조정하고, 기계 학습 워크플로를 관리하는 데 중요해집니다. 이 다양한 레이어를 통해 탐색이 진행됨에 따라 고객 경험 향상과 포장, 컨테이너, 실행 생태계 내에서 프로세스를 정교화하는 데 초점이 맞춰집니다.\n\n## AWS Kubernetes의 목표\n\n- 차별화되지 않은 무거운 작업 제거:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- AWS에서 Kubernetes를 관리하는 데 연관된 막거운 무거운 작업의 부담에서 해방된 고객들.\n- 운영 복잡성이 처리되어 사용자들이 핵심 역량에 초점을 맞추고 루틴적인 작업 관리에 관여하는 대신에 방향을 전환할 수 있게 합니다.\n\n2. 작업 단순화 및 액세스 부여:\n\n- AWS에서 Kubernetes 경험을 단순화하여 사용자들에게 간소화되고 사용자 친화적인 환경을 제공하는 것을 목표로 합니다.\n- 사용자들에게 클라우드의 규모, 안정성, 보안에 대한 완전한 액세스 권한이 부여되며, 운영 환경이 원활하고 효율적으로 관리되도록 보장합니다.\n\n3. 오픈 소스 표준의 계속적인 유지:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 쿠버네티스의 오픈 소스 표준을 계속해서 유지보수합니다.\n- 이는 CNCF 내 599개 프로젝트와의 호환성을 보장하며 빠른 혁신을 가능하게 하고 커뮤니티 및 파트너의 새로운 개발에 접근하며 커뮤니티 표준의 계속된 향상을 도와줍니다.\n\n## AWS가 어떻게 Kubernetes를 지원하나요\n\nAWS 생태계 내에서 Kubernetes에 대한 포괄적인 지원에 참여하고 있는 Amazon EKS는 관리 버킷에서 중요한 요소로 두드러집니다. Kubernetes에 대한 AWS의 약속의 중심 역할을 하는 EKS는 고객에 견고하고 효율적인 Kubernetes 관리 솔루션을 제공하는 의지를 보여줍니다. EKS 외에도 AWS는 Kubernetes 배포의 개발, Kubernetes와 AWS 구성 요소 간의 연결을 용이하게 해주는 다양한 방식을 제공하며 상류 개발에 적극적으로 참여함으로써 포용합니다.\n\nAWS 팀은 CNCF의 보안 협의회 및 Kubernetes 프로젝트에 기여함으로써 안전에 대한 약속을 확장하고 견고한 안전 조치를 보장합니다. 더불어 AWS는 공동 비용 절감 및 공유 리소스의 가용성 향상에 기여하는 커뮤니티 프로젝트에 금융적 지원을 제공함으로써 중요한 역할을 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 어디서나 Kubernetes 실행하기\n\n![Future of Amazon EKS](/assets/img/2024-06-19-FutureofAmazonEKS_1.png)\n\nEKS를 중심으로, AWS에서의 Kubernetes 제공은 다양한 환경으로 확장되었습니다. EKS는 우리의 Distro 및 EKS Anywhere에 걸쳐 퍼져 있으며 온-프레미스 Kubernetes 배포를 위한 툴 체인을 포함합니다. 전통적인 AWS 지역을 넘어, EKS는 Snow, Outposts, 로컬 존 및 파장까지 다양한 환경에 확장되었습니다. 이 방대한 커버리지는 사용자가 AWS 인프라 또는 다양한 온-프레미스 시나리오에서 Kubernetes를 실행하더라도 일관되고 성능 좋은 Kubernetes 경험을 쉽게 얻을 수 있도록 합니다. AWS의 목표는 사용자에게 유연한 옵션을 제공하여 선택한 배포 환경에 관계없이 일관되고 신뢰할 수 있는 Kubernetes 경험을 보장하는 것입니다.\n\n# EKS 5주년\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지난 5년 동안 이 제품에 투자된 상당한 개발을 되돌아보면, 2018년 EKS 발표 이후 222번 이상의 다양한 런칭이 진행되었다는 사실을 강조해야 합니다. 이러한 런칭은 가격 인하와 규정 준수 조치부터 새로운 프로젝트 시작, 클러스터 생성 시간 가속화, 새로운 인스턴스 및 지역 지원 추가, 중요한 기능 도입까지 다양한 향상을 포함하고 있습니다.\n\n노바 라일라툴 리즈키아\n","ogImage":{"url":"/assets/img/2024-06-19-FutureofAmazonEKS_0.png"},"coverImage":"/assets/img/2024-06-19-FutureofAmazonEKS_0.png","tag":["Tech"],"readingTime":7}],"page":"31","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}