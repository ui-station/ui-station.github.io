{"pageProps":{"post":{"title":"Apache Airflow을 시작하는 방법 2024 최신 업데이트","description":"","date":"2024-05-27 16:38","slug":"2024-05-27-HowtogetstartedwithApacheAirflow2024updated","content":"\n<img src=\"/assets/img/2024-05-27-HowtogetstartedwithApacheAirflow2024updated_0.png\" />\n\n- 노트북을 열어주세요\n- 터미널을 열어주세요\n- 아래 코드를 실행해주세요\n\n```js\npip uninstall apache-airflow\n```\n\n<img src=\"https://miro.medium.com/v2/resize:fit:534/0*iDdoQ91AdPvPcWGm.gif\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n죄송해요 — 이걸 쓸 때는 금요일이었어요!\n\nOrchestra를 시도해보세요 🚀\n\n(검색 엔진 최적화를 위해 추가한 내용입니다)\n\n# Apache Airflow은 쉽게 배울 수 있나요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아파치 에어플로우는 특히 초보자에게는 어느 정도의 도전이 될 수 있지만, 일부 필수적인 개념과 도구에 익숙해지면 더 쉬워집니다. 에어플로우를 배우기 위해 알아야 할 내용과 학습이 쉬운 또는 어려운 이유를 살펴보겠습니다:\n\n# 전제 조건\n\n- 파이썬: 에어플로우는 파이썬으로 작성되었으므로, 파이썬에 대한 탄탄한 이해가 필수적입니다.\n- 명령줄 인터페이스 (CLI): 명령줄 사용에 대한 기본 지식은 에어플로우의 설치와 구성에 도움이 됩니다.\n- SQL: SQL을 알고 있는 것은 에어플로우가 데이터베이스와 상호 작용하는 경우가 많으므로 유용합니다.\n- 예약 개념: 작업 예약 및 워크플로 관리의 기본 개념을 이해하는 것이 중요합니다.\n\n# 학습 곡선\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 초기 설정: Airflow를 설정하는 것은 여러 구성 요소(Web 서버, 스케줄러, 메타데이터 데이터베이스 등) 때문에 약간 복잡할 수 있어요.\n- DAGs (Directed Acyclic Graphs): Airflow의 핵심 개념은 DAGs를 중심으로 돌아갑니다. DAGs를 정의하고 관리하는 방법을 익히는 데는 시간이 필요하죠.\n- Operators와 Hooks: Airflow는 작업을 정의하고 다양한 시스템에 연결하기 위해 operators와 hooks를 사용해요. 이들의 다양성과 사용 사례를 이해하는 것은 처음에는 압도될 수 있어요.\n- 설정 및 배포: Airflow를 다른 환경(로컬, 온프레미스, 클라우드)에서 실행하도록 설정하는 것은 복잡성을 더합니다.\n\n# 학습 자료\n\n- 문서: 공식 Airflow 문서는 포괄적이며 좋은 시작점입니다.\n- 온라인 튜토리얼과 강의: Udemy, Coursera 등에서 온라인 튜토리얼, 강의, YouTube 비디오들이 Airflow의 기본을 안내해줄 수 있어요.\n- 커뮤니티와 포럼: 포럼, GitHub 이슈, Stack Overflow를 통해 Airflow 커뮤니티와 소통하면 일반적인 문제에 대한 가치 있는 통찰과 해결책을 얻을 수 있어요.\n- 책: “Data Pipelines with Apache Airflow”와 같은 책들은 체계적인 학습을 제공할 수 있어요.\n\n# 실용적인 팁\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 간단히 시작하기: 간단한 DAG부터 시작하여 점차 복잡성을 높여가세요.\n- 실습 중심: 더 많이 연습할수록 더 편안해질 거에요. 작은 프로젝트를 만들어보거나 예제를 복제해보세요.\n- 예제 탐색: 예제 DAG 및 일반 패턴을 검토하면 많은 실용적인 통찰력을 얻을 수 있어요.\n- 관리 서비스 사용: Apache Airflow 설정이 어렵게 느껴진다면 Google Cloud Composer나 Amazon Managed Workflows for Apache Airflow와 같은 관리 서비스 사용을 고려해보세요.\n\n# 요약\n\n- 학습 용이성: 중간 정도의 난이도로 Python 및 관련 도구에 익숙해야 합니다.\n- 학습 경로: 문서로 시작하여 튜토리얼을 사용하고 커뮤니티와 정기적인 실습을 통해 참여하세요.\n- 복잡성: 사용 사례에 따라 다를 수 있으며, 간단한 DAG가 쉽지만 복잡한 워크플로 및 배포에 더 많은 노력이 필요합니다.\n\n전반적으로 Apache Airflow에는 학습 곡선이 있지만 자원과 커뮤니티 지원이 많아 프로세스가 보다 원활해질 수 있습니다. 일관된 연습과 탐색을 통해 Airflow를 숙달하는 것은 분명히 가능합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Apache Airflow을 시작하는 방법은?\n\n오픈 소스라서 도커, 쿠버네티스를 배우고 다운로드하여 적극 활용해보세요:\n\nApache Airflow를 시작하려면 로컬 머신 또는 서버에 설치하고 설정하는 방법을 따르면 됩니다. 아래는 시작하는 데 도움이 되는 기본 가이드입니다:\n\n# 1. Apache Airflow 설치\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 준비 사항:\n\n- Python: Python이 설치되어 있는지 확인해주세요 (버전 3.6 이상).\n- 가상 환경: 충돌을 피하기 위해 가상 환경을 만드는 것이 좋은 습관입니다.\n\n## 설치 단계:\n\n- 가상 환경 만들기:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\npython -m venv airflow_env source airflow_env/bin/activate # Windows에서는 `airflow_env\\Scripts\\activate`를 사용하십시오\n\n- Apache Airflow 설치: Apache Airflow는 호환 가능한 종속성을 지정하기 위해 constraints 파일을 사용합니다. 아래 명령어를 사용하여 설치할 수 있습니다:\n\n```bash\nexport AIRFLOW_VERSION=2.5.0\nexport PYTHON_VERSION=\"$(python --version | cut -d \" \" -f 2 | cut -d \".\" -f 1-2)\"\nexport CONSTRAINT_URL=\"https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt\"\npip install \"apache-airflow==${AIRFLOW_VERSION}\" --constraint \"${CONSTRAINT_URL}\"\n```\n\n# 2. 데이터베이스 초기화\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAirflow은 작업 인스턴스 및 다른 메타데이터를 추적하는 데 데이터베이스를 사용합니다. Airflow를 실행하기 전에 데이터베이스를 초기화해야 합니다.\n\n```js\nairflow db init\n```\n\n# 3. 관리자 사용자 만들기\n\nAirflow 웹 인터페이스에 액세스할 수 있는 관리자 사용자를 만듭니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n에어플로우 사용자 생성 \\\n   --username admin \\\n   --firstname 당신의_이름 \\\n   --lastname 당신의_성 \\\n   --role Admin \\\n   --email 당신의_이메일\n```\n\n당신의 성, 이름 및 admin@example.com을 여러분의 정보로 대체하세요.\n\n# 4. 에어플로우 웹 서버 및 스케쥴러 시작\n\n- 웹 서버 시작:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 첫 번째 터미널 창에서:\nairflow webserver --port 8080\n\n# 두 번째 터미널 창에서:\nairflow scheduler\n```\n\n# 5. Airflow UI에 액세스하기\n\n웹 브라우저를 열고 http://localhost:8080로 이동하세요. 이전에 생성한 관리자 자격 증명을 사용하여 로그인할 수 있습니다.\n\n# 6. 첫 번째 DAG(Directed Acyclic Graph) 생성하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDAG은 실행하려는 작업을 관계와 종속성을 반영하는 방식으로 구성된 작업 모음입니다.\n\n- DAG 파일 생성: dags 디렉토리에 새 Python 파일을 생성합니다 (일반적으로 ~/airflow/dags에 위치).\n\n```python\n# ~/airflow/dags/example_dag.py\nfrom airflow import DAG\nfrom airflow.operators.dummy_operator import DummyOperator\nfrom datetime import datetime\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n}\n\ndag = DAG(\n    'example_dag',\n    default_args=default_args,\n    description='간단한 예제 DAG',\n    schedule_interval='@daily',\n)\n\nstart = DummyOperator(task_id='start', dag=dag)\nend = DummyOperator(task_id='end', dag=dag)\n\nstart >> end\n```\n\n- 파일 저장: 이 파일을 example_dag.py로 저장하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 7. Airflow UI에서 DAG 확인하기\n\nDAG 파일을 저장한 후 Airflow UI로 이동하면 새로운 DAG가 목록에 표시됩니다. 수동으로 트리거하거나 정의된 일정에 따라 자동으로 트리거될 수 있습니다.\n\n# 추가 자료\n\n- 공식 문서: Apache Airflow 문서\n- 튜토리얼 및 가이드: 여러 온라인 튜토리얼이 특정 사용 사례 및 고급 구성에 도움이 될 수 있습니다.\n- 커뮤니티 지원: Airflow의 Slack 채널이나 다른 커뮤니티 포럼에 가입하여 지원 및 네트워킹을 할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이러한 단계를 따라하면 Apache Airflow를 설정하고 실행하여 자체 워크플로를 만들고 관리할 수 있을 것입니다.\n\n## Airflow을 사용하려면 코딩이 필요한가요?\n\n당연히 그렇죠. Python 및 OOP 지식이 필요합니다. 또한 CI/CD, 약간의 terraform 및 Kubernetes도 필요합니다!\n\n## Apache Airflow를 배우는 데 얼마나 시간이 걸릴까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n너무 길어요. 궁금하다면, Orchestra를 사용해보세요. 누구나 사용할 수 있고 기업용 오케스트레이터 및 감시 도구의 모든 기능을 가지고 있지만 수고를 덜 수 있어요.\n","ogImage":{"url":"/assets/img/2024-05-27-HowtogetstartedwithApacheAirflow2024updated_0.png"},"coverImage":"/assets/img/2024-05-27-HowtogetstartedwithApacheAirflow2024updated_0.png","tag":["Tech"],"readingTime":9},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<img src=\"/assets/img/2024-05-27-HowtogetstartedwithApacheAirflow2024updated_0.png\">\n<ul>\n<li>노트북을 열어주세요</li>\n<li>터미널을 열어주세요</li>\n<li>아래 코드를 실행해주세요</li>\n</ul>\n<pre><code class=\"hljs language-js\">pip uninstall apache-airflow\n</code></pre>\n<img src=\"https://miro.medium.com/v2/resize:fit:534/0*iDdoQ91AdPvPcWGm.gif\">\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>죄송해요 — 이걸 쓸 때는 금요일이었어요!</p>\n<p>Orchestra를 시도해보세요 🚀</p>\n<p>(검색 엔진 최적화를 위해 추가한 내용입니다)</p>\n<h1>Apache Airflow은 쉽게 배울 수 있나요?</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>아파치 에어플로우는 특히 초보자에게는 어느 정도의 도전이 될 수 있지만, 일부 필수적인 개념과 도구에 익숙해지면 더 쉬워집니다. 에어플로우를 배우기 위해 알아야 할 내용과 학습이 쉬운 또는 어려운 이유를 살펴보겠습니다:</p>\n<h1>전제 조건</h1>\n<ul>\n<li>파이썬: 에어플로우는 파이썬으로 작성되었으므로, 파이썬에 대한 탄탄한 이해가 필수적입니다.</li>\n<li>명령줄 인터페이스 (CLI): 명령줄 사용에 대한 기본 지식은 에어플로우의 설치와 구성에 도움이 됩니다.</li>\n<li>SQL: SQL을 알고 있는 것은 에어플로우가 데이터베이스와 상호 작용하는 경우가 많으므로 유용합니다.</li>\n<li>예약 개념: 작업 예약 및 워크플로 관리의 기본 개념을 이해하는 것이 중요합니다.</li>\n</ul>\n<h1>학습 곡선</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<ul>\n<li>초기 설정: Airflow를 설정하는 것은 여러 구성 요소(Web 서버, 스케줄러, 메타데이터 데이터베이스 등) 때문에 약간 복잡할 수 있어요.</li>\n<li>DAGs (Directed Acyclic Graphs): Airflow의 핵심 개념은 DAGs를 중심으로 돌아갑니다. DAGs를 정의하고 관리하는 방법을 익히는 데는 시간이 필요하죠.</li>\n<li>Operators와 Hooks: Airflow는 작업을 정의하고 다양한 시스템에 연결하기 위해 operators와 hooks를 사용해요. 이들의 다양성과 사용 사례를 이해하는 것은 처음에는 압도될 수 있어요.</li>\n<li>설정 및 배포: Airflow를 다른 환경(로컬, 온프레미스, 클라우드)에서 실행하도록 설정하는 것은 복잡성을 더합니다.</li>\n</ul>\n<h1>학습 자료</h1>\n<ul>\n<li>문서: 공식 Airflow 문서는 포괄적이며 좋은 시작점입니다.</li>\n<li>온라인 튜토리얼과 강의: Udemy, Coursera 등에서 온라인 튜토리얼, 강의, YouTube 비디오들이 Airflow의 기본을 안내해줄 수 있어요.</li>\n<li>커뮤니티와 포럼: 포럼, GitHub 이슈, Stack Overflow를 통해 Airflow 커뮤니티와 소통하면 일반적인 문제에 대한 가치 있는 통찰과 해결책을 얻을 수 있어요.</li>\n<li>책: “Data Pipelines with Apache Airflow”와 같은 책들은 체계적인 학습을 제공할 수 있어요.</li>\n</ul>\n<h1>실용적인 팁</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<ul>\n<li>간단히 시작하기: 간단한 DAG부터 시작하여 점차 복잡성을 높여가세요.</li>\n<li>실습 중심: 더 많이 연습할수록 더 편안해질 거에요. 작은 프로젝트를 만들어보거나 예제를 복제해보세요.</li>\n<li>예제 탐색: 예제 DAG 및 일반 패턴을 검토하면 많은 실용적인 통찰력을 얻을 수 있어요.</li>\n<li>관리 서비스 사용: Apache Airflow 설정이 어렵게 느껴진다면 Google Cloud Composer나 Amazon Managed Workflows for Apache Airflow와 같은 관리 서비스 사용을 고려해보세요.</li>\n</ul>\n<h1>요약</h1>\n<ul>\n<li>학습 용이성: 중간 정도의 난이도로 Python 및 관련 도구에 익숙해야 합니다.</li>\n<li>학습 경로: 문서로 시작하여 튜토리얼을 사용하고 커뮤니티와 정기적인 실습을 통해 참여하세요.</li>\n<li>복잡성: 사용 사례에 따라 다를 수 있으며, 간단한 DAG가 쉽지만 복잡한 워크플로 및 배포에 더 많은 노력이 필요합니다.</li>\n</ul>\n<p>전반적으로 Apache Airflow에는 학습 곡선이 있지만 자원과 커뮤니티 지원이 많아 프로세스가 보다 원활해질 수 있습니다. 일관된 연습과 탐색을 통해 Airflow를 숙달하는 것은 분명히 가능합니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>Apache Airflow을 시작하는 방법은?</h1>\n<p>오픈 소스라서 도커, 쿠버네티스를 배우고 다운로드하여 적극 활용해보세요:</p>\n<p>Apache Airflow를 시작하려면 로컬 머신 또는 서버에 설치하고 설정하는 방법을 따르면 됩니다. 아래는 시작하는 데 도움이 되는 기본 가이드입니다:</p>\n<h1>1. Apache Airflow 설치</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h2>준비 사항:</h2>\n<ul>\n<li>Python: Python이 설치되어 있는지 확인해주세요 (버전 3.6 이상).</li>\n<li>가상 환경: 충돌을 피하기 위해 가상 환경을 만드는 것이 좋은 습관입니다.</li>\n</ul>\n<h2>설치 단계:</h2>\n<ul>\n<li>가상 환경 만들기:</li>\n</ul>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>python -m venv airflow_env source airflow_env/bin/activate # Windows에서는 <code>airflow_env\\Scripts\\activate</code>를 사용하십시오</p>\n<ul>\n<li>Apache Airflow 설치: Apache Airflow는 호환 가능한 종속성을 지정하기 위해 constraints 파일을 사용합니다. 아래 명령어를 사용하여 설치할 수 있습니다:</li>\n</ul>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-built_in\">export</span> AIRFLOW_VERSION=2.5.0\n<span class=\"hljs-built_in\">export</span> PYTHON_VERSION=<span class=\"hljs-string\">\"<span class=\"hljs-subst\">$(python --version | cut -d <span class=\"hljs-string\">\" \"</span> -f 2 | cut -d <span class=\"hljs-string\">\".\"</span> -f 1-2)</span>\"</span>\n<span class=\"hljs-built_in\">export</span> CONSTRAINT_URL=<span class=\"hljs-string\">\"https://raw.githubusercontent.com/apache/airflow/constraints-<span class=\"hljs-variable\">${AIRFLOW_VERSION}</span>/constraints-<span class=\"hljs-variable\">${PYTHON_VERSION}</span>.txt\"</span>\npip install <span class=\"hljs-string\">\"apache-airflow==<span class=\"hljs-variable\">${AIRFLOW_VERSION}</span>\"</span> --constraint <span class=\"hljs-string\">\"<span class=\"hljs-variable\">${CONSTRAINT_URL}</span>\"</span>\n</code></pre>\n<h1>2. 데이터베이스 초기화</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>Airflow은 작업 인스턴스 및 다른 메타데이터를 추적하는 데 데이터베이스를 사용합니다. Airflow를 실행하기 전에 데이터베이스를 초기화해야 합니다.</p>\n<pre><code class=\"hljs language-js\">airflow db init\n</code></pre>\n<h1>3. 관리자 사용자 만들기</h1>\n<p>Airflow 웹 인터페이스에 액세스할 수 있는 관리자 사용자를 만듭니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\">에어플로우 사용자 생성 \\\n   --username admin \\\n   --firstname 당신의_이름 \\\n   --lastname 당신의_성 \\\n   --role <span class=\"hljs-title class_\">Admin</span> \\\n   --email 당신의_이메일\n</code></pre>\n<p>당신의 성, 이름 및 <a href=\"mailto:admin@example.com\">admin@example.com</a>을 여러분의 정보로 대체하세요.</p>\n<h1>4. 에어플로우 웹 서버 및 스케쥴러 시작</h1>\n<ul>\n<li>웹 서버 시작:</li>\n</ul>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\"># 첫 번째 터미널 창에서:\nairflow webserver --port <span class=\"hljs-number\">8080</span>\n\n# 두 번째 터미널 창에서:\nairflow scheduler\n</code></pre>\n<h1>5. Airflow UI에 액세스하기</h1>\n<p>웹 브라우저를 열고 <a href=\"http://localhost:8080%EB%A1%9C\" rel=\"nofollow\" target=\"_blank\">http://localhost:8080로</a> 이동하세요. 이전에 생성한 관리자 자격 증명을 사용하여 로그인할 수 있습니다.</p>\n<h1>6. 첫 번째 DAG(Directed Acyclic Graph) 생성하기</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>DAG은 실행하려는 작업을 관계와 종속성을 반영하는 방식으로 구성된 작업 모음입니다.</p>\n<ul>\n<li>DAG 파일 생성: dags 디렉토리에 새 Python 파일을 생성합니다 (일반적으로 ~/airflow/dags에 위치).</li>\n</ul>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-comment\"># ~/airflow/dags/example_dag.py</span>\n<span class=\"hljs-keyword\">from</span> airflow <span class=\"hljs-keyword\">import</span> DAG\n<span class=\"hljs-keyword\">from</span> airflow.operators.dummy_operator <span class=\"hljs-keyword\">import</span> DummyOperator\n<span class=\"hljs-keyword\">from</span> datetime <span class=\"hljs-keyword\">import</span> datetime\n\ndefault_args = {\n    <span class=\"hljs-string\">'owner'</span>: <span class=\"hljs-string\">'airflow'</span>,\n    <span class=\"hljs-string\">'start_date'</span>: datetime(<span class=\"hljs-number\">2023</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>),\n    <span class=\"hljs-string\">'retries'</span>: <span class=\"hljs-number\">1</span>,\n}\n\ndag = DAG(\n    <span class=\"hljs-string\">'example_dag'</span>,\n    default_args=default_args,\n    description=<span class=\"hljs-string\">'간단한 예제 DAG'</span>,\n    schedule_interval=<span class=\"hljs-string\">'@daily'</span>,\n)\n\nstart = DummyOperator(task_id=<span class=\"hljs-string\">'start'</span>, dag=dag)\nend = DummyOperator(task_id=<span class=\"hljs-string\">'end'</span>, dag=dag)\n\nstart >> end\n</code></pre>\n<ul>\n<li>파일 저장: 이 파일을 example_dag.py로 저장하세요.</li>\n</ul>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>7. Airflow UI에서 DAG 확인하기</h1>\n<p>DAG 파일을 저장한 후 Airflow UI로 이동하면 새로운 DAG가 목록에 표시됩니다. 수동으로 트리거하거나 정의된 일정에 따라 자동으로 트리거될 수 있습니다.</p>\n<h1>추가 자료</h1>\n<ul>\n<li>공식 문서: Apache Airflow 문서</li>\n<li>튜토리얼 및 가이드: 여러 온라인 튜토리얼이 특정 사용 사례 및 고급 구성에 도움이 될 수 있습니다.</li>\n<li>커뮤니티 지원: Airflow의 Slack 채널이나 다른 커뮤니티 포럼에 가입하여 지원 및 네트워킹을 할 수 있습니다.</li>\n</ul>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>이러한 단계를 따라하면 Apache Airflow를 설정하고 실행하여 자체 워크플로를 만들고 관리할 수 있을 것입니다.</p>\n<h2>Airflow을 사용하려면 코딩이 필요한가요?</h2>\n<p>당연히 그렇죠. Python 및 OOP 지식이 필요합니다. 또한 CI/CD, 약간의 terraform 및 Kubernetes도 필요합니다!</p>\n<h2>Apache Airflow를 배우는 데 얼마나 시간이 걸릴까요?</h2>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>너무 길어요. 궁금하다면, Orchestra를 사용해보세요. 누구나 사용할 수 있고 기업용 오케스트레이터 및 감시 도구의 모든 기능을 가지고 있지만 수고를 덜 수 있어요.</p>\n</body>\n</html>\n"},"__N_SSG":true}