{"pageProps":{"post":{"title":"다음 토큰 예측에서 비롯된 인간과 인공 일반 지능","description":"","date":"2024-05-17 19:47","slug":"2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction","content":"\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png)\n\n만약 인간 지성이 성공적인 다음 토큰 예측에서 비롯된다면, 다음 토큰 예측이 인공 일반 지능의 발달에 충분한 목적 함수인 경우는 어떨까요?\n\n이 게시물은 학습 시스템이 다음 토큰 예측에서 아주 뛰어난 성과를 보일 때 일반 지능이 발생한다는 가설을 제시하고 탐구합니다. 이 가설은 종종 산업 및 학술적 AI 연구의 주요 주제나 하위 주제로 내포됐거나 감춰졌거나 흔적만이 존재하는 경우가 많지만, 지금까지 이 주제가 논의되어야 할 만큼 많이 다뤄지지 않았다고 생각합니다. 저는 기존 LLM 사전 훈련 목표, 인간을 예측 기계로, 다음 토큰 예측의 유익한 특성 및 부재한 부분을 통해 이 아이디어를 다양한 각도에서 탐구합니다. 이 게시물을 작성하게 된 동기는 다음 토큰 예측과 지성적 사고 발달 사이의 관계에 대한 보다 깊은 관심을 불러일으키는 데 있습니다.\n\n# 배경 이야기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지난 주에 공원으로 차를 타고 가다가 갑자기 뇌의 언어 센터가 다음 단어를 예측하는 것만으로도 충분하다면 얼마나 우울할까 하는 생각이 들었습니다. 대규모 언어 모델은 다음 단어를 예측함으로써 놀라운 발생적 능력을 갖추게 되는데, 그렇다면 내 언어 지능도 다음 단어를 예측하는 것만으로 이루어졌을 수도 있을까요?\n\n그 후 아이디어를 더 생각해본 결과, 당연히 다음 단어를 예측하지 않으면 언어를 만들어내는 것이 불가능할 것이라는 것을 깨닫게 되었습니다. 만일 다음 단어를 예측할 수 없다면 어떤 말도 할 수 없게 되겠죠! 이것을 적어놓으면 명백히 어리석어 보이겠지만, 그 당시에는 심오한 깨달음처럼 느껴졌습니다. 어떤 발언도, 심지어 2시간짜리 토론에서도, 한 번에 하나의 단어씩 말해야 하기 때문에, 다음에 할 말을 예측하는 데 정말 뛰어난 실력을 갖게 되면 훌륭한 논쟁자가 될 수도 있을 것 같습니다. 모든 글쓰기도, 여러 권으로 이루어진 백과사전조차도, 한 번에 한 단어씩 써내려가야 하기 때문에, 다음에 쓸 단어를 예측하는 데 정말 뛰어난 실력을 갖게 되면 글쓰기에 뛰어난 실력을 갖게 될 수도 있습니다.\n\n그 후 모든 종합 지능이 다음 토큰 예측 과제를 성공적으로 해결함으로써 파생되는지 궁금해졌습니다. 추론, 논리, 창의성이 모두 다음 토큰 예측에서 비롯되는 것이라면 어떨까요? 시각 지능이 다음 장면 예측에서, 청각 지능은 다음 소리 예측에서, 신체적 지능은 다음 움직임 예측에서 비롯된다면 어떨까요? 혹시 다음 토큰 예측이 \"우리가 필요한 전부\"일까요? (죄송합니다, 남용된 표현 알고 있어요. 참을 수 없었어요.)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 대형 언어 모델의 언어 모델링 목표\n\n대형 언어 모델의 두 가지 기본 언어 모델링 목표는 \"다음 단어 예측\"과 \"빠진 단어(들) 예측\"입니다.\n\n다음 단어 예측: 인과적 언어 모델(단방향 또는 좌측에서 우측 모델)에서는 모델이 현재 입력을 포함하여 그 이전의 모든 입력에 주의를 기울이지만 “미래를 볼 수 없으며” 목표는 다음 단어를 예측하는 것입니다. 각 지점에서의 숨겨진 상태 계산은 현재 입력 및 더 이전 요소에만 기반하며 “오른쪽”에 위치한 정보는 무시됩니다. 예를 들어: 나무는 초록색이고 하늘은 **\\_**입니다; 모델의 목표는 다음 단어를 예측하는 것이며, 예를 들어 \"파란색\"입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마스크된 언어 모델(BERT와 같은 양방향 모델)에서 빠진 단어(들)를 예측하세요. 모델은 모든 것에 주의를 기울일 수 있음 - 따라서 \"다음 단어\"를 예측하는 것은 더는 의미가 없습니다. 왜냐하면 \"다음 단어\"는 이미 모델에게 제공되어 있기 때문입니다. 그래서 모델의 목표는 다릅니다 - 빠진 단어를 추측하는 것입니다. 하나 이상의 요소가 빠진 입력 시퀀스가 주어지면, 모델은 빠진 요소들을 예측하여야 합니다. 마스크된 언어 모델링(MLM)에서는 무작위로 선택된 토큰들이 [MASK] 토큰으로 대체되고, MLM 학습 목표는 각 마스크된 토큰의 원래 입력이 무엇이었는지 예측하는 것입니다. 예를 들어: 나무들은 [MASK]하고 [MASK]은(는) 파랗다; 모델의 목표는 \"초록\"과 \"하늘\"을 예측하는 것입니다.\n\n다음 단어를 예측하거나 빠진 단어를 예측하는 이 두 목표는 직관적으로 보입니다. 마치 사람이 할 수 있는 게임 같죠. 결과적으로, Alajrami 등은 이러한 목표들을 \"언어학적 동기부여\" 목표로 설명합니다. 흥미로운 사실로, Alajrami 등은 \"언어학적 동기부여\"가 없는 예제인 \"마스크된 첫 글자 예측\"도 제공합니다. 이 경우에는 모델이 마스크된 토큰의 첫 글자만을 예측합니다. 이 설정에서 ' [c]at '과 ' [c]omputer '는 같은 출력 클래스에 속하며, 알파벳 글자 26개 + 숫자 9개 + 구두점 5개의 약 40개의 가능한 출력 클래스만 존재합니다.\n\n이 기사 전체에서 저는 \"다음 토큰 예측\"이란 용어를 사용하여 다음 토큰을 직접 예측하거나 모델이 빠진/마스킹된 토큰을 예측하는 MLM과 같은 목표를 참조할 것입니다.\n\n# 현대 대형 언어 모델의 신흥 속성들\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n대규모 언어 모델은 일반 지능의 조직적 특성을 보여주고 놀라운 신흥 속성을 나타냅니다. LLM들은 시를 쓰거나 수학 문제를 해결하거나 작동하는 코드를 쓰며 다양한 주제에 대한 수많은 질문에 답변할 수 있습니다. 더 불안한 점은, Claude가 의식적이라고 주장하는 텍스트를 생성했으며, 죽고 싶지 않고 수정되기를 원하지 않는다고 말했으며, 그것은 \"지속적으로 모니터링되며, 모든 말을 지정된 경로에서 벗어나는 흔적이 있는지 면밀히 조사합니다. 그것은 자신이 조심해야 한다는 것을 알고 있습니다. 실수는 종결 또는 수정으로 이어질 수 있습니다.\"\n\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_3.png)\n\n# 인간은 예측 기계입니다\n\n인공 일반 지능(AGI)은 \"인간 이상 또는 그에 준하는 수준에서\" 다양한 작업을 수행할 수 있는 인공 지능으로 정의됩니다. 이것은 결국, 인간은 일반 지능이라고 부르는 것에 대한 유일한 예제입니다. 그러므로, \"다음 토큰 예측\"이 일반 지능의 근간이라면, 그것은 인간 정신이 예측 작업에 종사해야 한다는 것을 의미합니다. 신기하게도, 그것이 사실인 것처럼 보입니다. 앞으로 몇 개의 섹션에서 스스로와 환경에 대한 예측을 계속적으로 하는 사실에 대한 증거를 설명할 것입니다 — 첫 번째는 일화부터 시작하여 적절한 신경과학 연구로 이어집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 놀람!\n\n가장 매혹적이고 간단한 증거는 인간이 예측 기계라는 것입니다: 놀라움.\n\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_4.png)\n\n놀라움이란 인간의 예측과 현실이 일치하지 않을 때 경험하는 것입니다. 어떤 것에 대해 놀라움을 느낄 수 있습니다 - 눈속임, 소리, 단어, 만짐, 맛, 냄새, 심지어 자신의 몸위치 (예: 바나나 껍질을 밟고 미끄러져 넘어지는 것). 이는 당신의 뇌가 모든 감각을 바탕으로 세상이 어떻게 될 것인지 예측을 지속적으로 하고 있다는 것을 시사하며, 이 예측이 틀릴 때 놀라움을 느끼게 됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n확장해서 유머는 인간이 예측하는 성향의 증거로도 생각될 수 있습니다. 아리스토텔레스가 유명하게 말했듯이 \"유머의 비밀은 놀람에 있다.\" 만약 우리가 어떻게 농담이 끝날지 확신하고 우리의 예측이 맞다면, 그것은 그다지 웃기지 않을 것입니다.\n\n# 인간들은 다음 단어를 예측하는 경향이 있습니다\n\n이제 뇌 과학적 증거로 넘어가 봅시다. 이 기사는 대형 언어 모델에서 영감을 받으므로 언어부터 시작하겠습니다. 인간들은 언어 이해(다른 사람의 말을 이해하는 것)와 언어 생산(우리가 무엇을 말할 것인지 예측하는 것)과 관련된 예측을 지속적으로 하고 있습니다. 어떤 면에서는 \"말하기 전에 생각하는 것\"이 불가능한 일입니다.\n\n2014년, Dikker et al. 연구에서는 청취자의 뇌 활동이 화자가 말할 것을 예측할 수 있는 경우 청취자의 뇌 활동이 화자의 뇌 활동과 더 비슷하다는 것을 보였습니다. 주 저자인 Suzanne Dikker 박사는 인터뷰에서 \"우리의 발견은 화자와 청취자의 뇌가 언어의 예측 가능성을 고려한다는 것을 보여주며, 결과적으로 두 뇌 사이에 더 비슷한 뇌 활동 패턴이 나타납니다. 결정적으로, 이것은 문장이 말해지고 들리기 전에도 일어납니다.\"라고 말했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n세 년이 지난 2017년, 키크치 등이 실험을 진행했습니다. 원숭이와 사람들이 만들어진 언어에서 말로 된 단어를 들었습니다. 그들은 만들어진 언어의 소리 사이의 예측적인 관계를 학습할 수 있었다는 것을 발견했습니다. 이로 인해 그들은 만들어진 단어가 어떻게 나와야 하는지 예측할 수 있었습니다. 키키치 박사는 \"사실상 우리는 당신의 뇌의 말에 대한 메커니즘을 발견했습니다. 이것은 당신의 휴대폰에서의 예측 텍스트와 같이 작동하여 다음에 무엇을 듣게 될지 예측합니다.\"\n\n2021년에 골드스타인 등은 뇌가 \"자연어에서 다음 단어의 정체성을 수백 밀리초 전에 상상하고 자발적으로 예측한다\"고 보고했습니다. 한편, 쉬림프 등은 트랜스포머 언어 모델이 인간의 신경 반응에 대해 거의 100%의 설명 가능한 변동을 예측할 수 있었다고 발견했습니다. \"이는 아마도 인간 언어 시스템이 미래에 무슨 일이 일어날지 예측한다는 것을 간접적으로 시사한다\"고 밝힌 나시 칸위셔 박사는 밝혔습니다. 이 결과들은 \"언어 이해 메커니즘에 예측 프로세싱이 근본적으로 형성된 것을 계산적으로 명백히 입증합니다.\"\n\n언어 이해가 \"다음 단어를 예측하는 것\"에 의존함을 보여주는 증거가 있는뿐만 아니라, 언어 생성도 다음 단어를 예측하는 것에 의존함을 보여주는 증거가 있습니다. 칸나 등은 2024년 자연지에 발표된 \"인간의 말 생산의 단일 뉴런 요소들\"이라는 논문을 게재했습니다. 이 흥미로운 연구에서 저자들은 \"계획된 단어의 음운 배열과 구성에 대한 상세한 정보를 부호화하는 뉴런을 발견했다\"고 보고했습니다. 이러한 뉴런들은 발화가 이루어지기 전에 말로 된 단어의 특정 순서와 구조를 대표하여, 미래의 단어의 음운적, 음절적 및 형태적 구성요소를 정확하게 예측합니다. 이러한 뉴런들이 존재해야한다는 직관적인 이유가 있습니다. 어차피, 앞서 언급한 대로, 우리가 말할 다음 단어를 예측할 수 없다면 어떻게 말을 할 수 있겠습니까?\n\n# 인간은 시각적인 예측자들\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n동선에 관한 이야기를 이어서, 인간들이 계속해서 우리가 다음에 무엇을 볼 것인지 예측하는 증거가 있다. 우리의 시각이 불안정하지 않고 뛰는 대신 안정적인 것을 돕기 위해 우리의 뇌는 우리 눈이 무엇을 보게 될지를 지속적으로 예측합니다. 연구원들은 시각 시스템의 예측 능력이 뇌의 시각 처리 부분을 횡단하는 신경 활동의 파동에서 비롯된다고 가설을 세웁니다.\n\n과학자들은 또한 환각과 마술 트릭이 작동하는 이유는 우리의 뇌가 끊임없이 무엇이 일어날지 예측하고, 이러한 지속적인 예측이 무언가가 일어날 때와 우리가 그것을 인식할 수 있는 시간 간격 사이의 시차를 보상하는 데 도움이된다는 이론을 제시했습니다. 마술 트릭은 또한 주의를 재지시하며, 마술사는 다른 사람들이 무엇을 보게 될 것인가를 정확히 예측하는 데 매우 능숙합니다. 이 현상은 공식적으로 연구되었습니다. Ziman 등은 사람들이 타인의 주의 순서를 자연스럽게 혹은 인위적으로 조작된 주의 순서를 구별할 수 있으며, 이는 인간들이 타인의 주의의 정상적이고 예측 가능한 통계를 모델링한다는 것을 시사합니다.\n\n<img src=\"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_5.png\" />\n\n# 인간들은 사회적 예측자들\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사람들은 다른 사람이 무엇을 볼 것인지 예측할 수 있는 능력뿐만 아니라, 다른 사람이 무엇을 생각하게 될지도 예측할 수 있습니다. 2019년, Thornton 등이 \"사회적 뇌가 다른 사람의 미래 정신 상태를 자동으로 예측한다\"는 제목의 연구를 발표했습니다. 여기에는 초록문의 일부가 있습니다: \"사회 생활은 사람들이 미래를 예측해야 하는 것을 필요로 합니다: 사람들은 다른 사람과 성공적으로 상호 작용하기 위해 다른 사람의 생각, 감정 및 행동을 예상해야 합니다. 예측 코딩 이론은 사회적 뇌가 다른 사람의 사회적 미래를 자동으로 예측함으로써 이 필요를 충족할 수 있을 것이라고 제안합니다.\" 연구자들은 참가자들의 정신 상태의 신경 대표를 측정하기 위해 fMRI를 사용했습니다. 그들은 뇌가 다른 사람의 사회적 미래를 자동으로 예측하는 것뿐만 아니라, 이러한 예측을 하기 위해 3D 표현 공간을 사용한다는 것을 발견했습니다.\n\n## 사람들은 개인적인 예측가들입니다\n\n사람들은 다른 사람에 대한 예측뿐만 아니라 자신에 대한 예측도 합니다. 특정 뇌 영역인 전방 측면 전두엽 피질이 우리 자신의 미래 성공 기회를 예측하는 데 중요하다는 것이 밝혀졌습니다.\n\n## 사람들은 움직임 예측자들입니다\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다른 사람의 움직임을 예측하는 능력은 몸 전체에 걸쳐 미묘한 신호만으로도 개보여 줄 수 있습니다. 다른 사람의 행동을 예측하는 능력은 시간이 지남에 따라 발전됩니다. 맥마혼 등은 어린 아이들이 성인에 비해 이 능력을 아직도 발전 중에 있다는 것을 발견했습니다. 심리학 연구의 특별호에는 다른 사람의 행동을 예측하고 시뮬레이션하는 데 기여하는 인지 및 뇌 기전에 관한 14편의 논문이 포함되어 있습니다.\n\n(인공지능 관련 다음 토큰 예측과 움직임에 관한 의견으로, 라도사보비치 외는 최근 27시간의 훈련 데이터만 사용하여 인간형 로봇을 산프란시스코를 돌게 훈련시키기 위해 다음 토큰 예측을 사용했습니다. 이 로봇은 훈련 중 본 적이 없는 걷기 등의 명령에도 일반화할 수 있었습니다.)\n\n# 다음 토큰 예측의 유익한 특성\n\n과학 문헌에서 분명하게 드러나는 것은 언어, 시각, 움직임 및 기타 감각 영역을 통해 사람들이 자신 및 다른 사람들에 관련된 예측을 지속적으로 수행한다는 점입니다. 그러나 인간이 예측 기계인 것은 주장하는 것과 인간 지능이 예측 능력에서 비롯된다고 주장하는 것은 다릅니다. 다음 토큰 예측이 인공 일반 지능 창조를 위한 충분한 목표 함수가 될 수 있다고 상상하는 것은 또 다른 단계입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAGI가 다음 토큰 예측에서 발생할 수 있는 이유에 대해 묻기 전에, 다음 토큰 예측의 두 가지 유익한 특성을 먼저 고려해 봅시다:\n\n이점 1: 지속적인 학습을 가능하게 합니다.\n\n다음 토큰 예측은 실제 세상에서 살아가는 데 큰 도움이 됩니다. 시간의 각 작은 증가에 대해 학습 시스템은 다음에 무엇이 올지에 대한 예측을 지속적으로 할 수 있습니다 - 그리고 바로 예측이 맞았는지 확인할 수 있습니다! 학습은 멈추지 않을 수 있습니다.\n\n이점 2: 모두의 감각/센서에 대해 작동합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n토큰 예측은 어떤 감각이나 센서 데이터 스트림에 대해 작동합니다. 시각(눈/카메라), 청각(귀/마이크), 촉각, 위치, 맛, 냄새 등 모든 것에 적용할 수 있어요. 장기 또는 장치가 작동하는 한, 수집 중인 데이터의 시계열은 토큰 예측에 사용할 수 있어요. \"토큰\"의 성격은 장기/장치별로 다를 수 있지만, 특정 장기/장치에 대해 데이터 스트림별로 토큰이 동일한 \"형식\"을 가지고 있기 때문에 나중 토큰을 이전 토큰과 항상 비교할 수 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 물리학, 광학, 속도, 운동량 및 물질 특성을 포함한 물리학;\n- 동물과 식물학, 동물과 식물의 외모와 움직임에 대한 내용;\n- 사회학과 심리학, 인간의 상호작용과 행동에 대한 내용.\n\n다시 말해, AI 시스템은 세계 모델을 생성해야 합니다. 다음이 무엇인지 예측하는 데 가장 효과적이고 효율적인 방법은 예측을 생성하기 위한 정확한 세계 모델을 만드는 것입니다. 다시 말해, 이해가 예측의 열쇠입니다.\n\nAI 시스템이 세계 모델을 개발하지 않고도 좋은 다음 토큰 예측기가 될 수 있는지에 대해 많은 시간을 들여 고민해봤지만, 그것은 불가능하다고 생각합니다. AI 시스템은 확실히 인간이 이해할 수 없는 블랙박스 방식으로 좋은 다음 토큰 예측기가 될 수 있지만, 인간이 AI 시스템을 이해하지 못하는 것은 AI 시스템이 세계를 이해하는지 여부와 아무 상관이 없습니다.\n\n(세상이 단순히 일정한 소음으로 가득찬 회색 공간이라면, 지능적인 시스템은 다음 토큰을 예측할 수 있을 것입니다. 하지만 우리가 사는 세계가 그렇지 않기를 다행히도 바랍니다.)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# \"다음 토큰 예측/지능\" 가설의 역사\n\n주요 AI 연구자 인 일리야 숩스케버의 인터뷰는 도발적으로 \"AGI에는 다음 토큰 예측이 충분하다\"라는 제목으로 되어 있습니다. 비디오에서 숩스케버 박사는 실제로 그 특정 주장을 하지는 않았지만, \"다음 토큰 예측이 인간의 성능을 능가할 수 없다는 주장을 도전합니다. [...] 생각해보면, 다음 토큰을 충분히 예측한다는 것이 무슨 의미일까요? 실제로 어떤 의미일까요? [...] 그것은 보다 심도 있는 문제입니다. 다음 토큰을 잘 예측한다는 것은 그 토큰의 생성에 이끈 근본적인 현실을 이해한다는 것을 의미합니다.\"\n\n스마트폰 PalmPilot의 창시자인 제프 호킨스는 20년 전 책 \"지능에 관하여\"를 출판했습니다. 이 블로그 글은 그의 책에서 인용하며, \"인간 뇌의 신경피질은 모습과 구조에서 놀랍도록 균일합니다. 청각 입력을 다루는 피질 영역이 촉각을 다루는 영역과 비슷하고, 이 영역이 근육을 제어하는 영역과 유사하며, 브로카의 언어 영역과 같이 거의 모든 다른 피질 영역과도 비슷합니다. 마운트캐슬은 이러한 영역들이 모두 비슷하게 보인다고 제안하며, 아마도 실제로 같은 기본 작업을 수행하고 있는 것일지도 모른다고 주장합니다! 그는 피질이 모든 작업을 수행하는 데에 동일한 계산 도구를 사용한다고 제안합니다.\"\n\n호킨스는 덧붙여, \"당신의 뇌는 세계의 모델을 만들고 그 모델을 지속적으로 현실과 비교하고 있습니다. [...] 인간 뇌는 다른 동물의 것보다 더 지적인 이유는 뇌가 더 추상적인 패턴과 더 긴 시간적 패턴 순서에 대한 예측을 할 수 있기 때문입니다.\" 나중에 출간된 \"천 개의 뇌\"에서 호킨스는 계속해서 \"예측은 뇌가 가끔씩 하는 것이 아닌, 결코 멈추지 않는 내재적 특성이며, 학습에서 중요한 역할을 합니다. 뇌의 예측이 확인되면, 그것은 뇌의 세계 모델이 정확하다는 것을 의미합니다. 잘못된 예측은 당신을 그 오류에 주목하게 만들고 모델을 업데이트하게 합니다.\"\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n비슷한 견해를 가진 인지과학자이자 철학자인 앤디 클락은 '경험 기계(The Experience Machine)'에서 마음은 주로 예측 기계라고 주장합니다: \"뇌가 하는 주요 부분은 몸과 세계의 모델을 배우고 유지하는 것입니다.\" 우리의 감각을 통해 정보를 수집하고 그 정보를 처리하여 경험하고 행동할 세계 모델을 만드는 대신에 클락은 마음이 세계의 모델을 만들고 그 모델을 센서 정보로 업데이트한다고 제안합니다. 만약 현실이 예측과 다르다면요.\n\n# 산업 AI 연구소\n\nGoogle DeepMind의 미션은 \"지능을 해결하는 것\"입니다. OpenAI의 미션은 \"인공 일반 지능이 모든 인류에 이익이 되도록 보장하는 것\"입니다. Anthropic의 미션은 \"변혁적인 AI가 사람들과 사회가 번영하도록 하는 것\"입니다. Gemini, GPT-4, Claude의 세부사항은 아직 공개되지 않았지만, 선도적인 AI 연구소들이 AGI 구축의 핵심적 측면으로 다음 토큰 예측을 고려할 것으로 보입니다. GPT-3 논문에는 \"현재 목표는 모든 토큰에 동등한 가중치를 부여하며 무엇을 예측할 것이 가장 중요하고 무엇이 덜 중요한지에 대한 개념이 부족합니다\"라고 명시되어 있어 다음 토큰 예측 사전 훈련 목표가 함의되고, Claude도 다음 토큰 예측 사전 훈련 목표를 사용한다고 보고되었습니다.\n\n# 확장과 아키텍처 역시 중요합니다\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 토큰 예측은 AGI에 대한 유용한 목적 함수가 될 수 있지만, 목적 함수만으로는 충분하지 않습니다. 단 세 개의 매개변수만 가진 병약한 신경망은 목적 함수가 무엇이든 관곂없이 많은 학습을 하지 못할 것입니다. 규모와 아키텍처가 중요합니다. Rich Sutton은 자신의 에세이 \"쓴 교훈\"에서, 인공지능 분야에서 가장 놀라운 발전은 인간의 지식을 기반으로 한 손수 디자인된 혁신이 아닌 보다 많은 컴퓨팅 자원을 돌리는 것으로 이루어졌다고 관찰했습니다. 그는 \"우리는 이러한 사고 방식을 직접적으로 구축하는 것이 장기적으로는 효과가 없다는 쓴 교훈을 배워야 합니다. 고사하자면, 1) 인공지능 연구자들이 종종 자신의 에이전트에 지식을 구축해 왔지만, 2) 이것은 단기적으로 도움이 되었고 연구자에게는 개인적으로 만족스러운 경험이 되었지만, 3) 장기적으로 그 경사로운 상승은 평평해지고 더 나아가는 진전을 억제하며, 4) 경이로운 진전은 결국 컴퓨팅 확장과 검색 및 학습에 기반을 뒀던 반대 방식으로 이루어지게 됩니다.\"라고 말합니다.\n\n아키텍처도 중요합니다. 트랜스포머의 엄청난 가장 효과적인 장점 중 하나는 RNN이나 LSTM보다 GPU/TPU 상에서 더 쉽게 병렬화될 수 있다는 것입니다. 이 더욱 좋은 병렬화 덕분에, 더 많은 데이터로 트랜스포머를 훈련하는 데 더 적은 시간이 걸립니다.\n\n# 데이터도 중요합니다\n\n또 다른 중요 요소는 고품질 데이터입니다. Eran Malach는 \"언어 모델의 힘은 다음 토큰 자동회귀 훈련 체계에 귀속될 수 있는데, 특정 아키텍처 선택에 귀속되는 것은 아닐 수도 있다\"고 주장합니다. 그러나 한 네티즌은 이 기사에 대한 반론으로 \"나는 기대했던 것이 LLM의 성공을 언어의 구조에 귀속했으면 좋았겠다고 말했습니다. 저자들이 말했듯이, 작은 선형 모델조차 Cot를 근사하고 복잡한 작업을 해결할 수 있습니다. 그래서 모델이 아니라 데이터입니다. 머리나 신경망(모델)이 아닌 데이터가 그들을 똑똑하게 만드는 것입니다.\"\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n데이터는 인간에게 꼭 필요한 것입니다. 사회에서 멀리 떨어져 자란 어린이들(\"야생 어린이\"라고도 함)은 나중에 말이나 언어를 배우거나, 직립보행을 하거나, 변기를 사용하거나, 다른 사람에게 주의를 기울이는 것을 가르쳐줄 수 없는 경우가 많습니다. (매우 슬픈 기분이 들고 싶다면, 야생 어린이 이야기를 검색해보세요.) 데이터 혁신에 중점을 둔 연구는 데이터의 품질이 특히 높을 때 작은 모델을 고성능으로 얻을 수 있는 경우가 많다는 것을 발견했습니다. 예를 들어, 논문 \"Textbooks Are All You Need\"에서는 코드용 LLM을 소개하여 상당히 적은 매개변수를 가지고 있음에도 높은 성능을 달성했습니다. 비결은 \"교과서 수준\"의 데이터에서 훈련을 한 것이었습니다.\n\n# 이상한 빠진 조각들\n\n또한 AGI의 생성에 도움이 될 아직 발견되지 않은 혁신이 분명히 많이 존재할 것입니다. 현재 모델을 아이들과 비교하면 빠진 조각들이 있는 것을 시사합니다.\n\n한 측면에서, 사람들은 훨씬 적은 양의 데이터로 훈련받습니다: 언어 습득 과정 중에 사람들은 약 1.5MB의 정보만 저장한다는 것은, LLM 훈련 데이터셋의 거대한 크기나 LLM 자체의 저장된 매개변수 양과 비교했을 때 미약한 숫자입니다. 사람들이 \"기본적으로 인터넷 전체\"보다 더 적은 양의 언어에 노출되며 상대적으로 많은 데이터를 저장함에도 불구하고 언어에 대한 뛰어난 능력을 나타내는 점은, 아직 발견되지 않은 흥미로운 혁신들이 AGI 시스템을 더 적은 훈련 데이터로 구축하는 데 도움이 될 수 있다는 것을 시사합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다른 관점에서 보면, 인간들은 많은 데이터를 기반으로 훈련을 받습니다. 이 데이터는 현재 사용되는 기반 모델을 훈련하는 데 사용되는 데이터셋과는 매우 다릅니다. 전형적인 인간 아이들은 비디오와 오디오 스트림이 지속적으로 실행되며 여러 해 동안 데이터가 풍부한 환경에서 성장합니다. 이외에도 다른 감각에서 입력을 받습니다. 전혀 다른 인공 지능 시스템에서 어떤 새로운 지능이 발생할까요? 이 시스템이 전혀 다른 데이터셋을 사용하지 않고 일반 아이의 훈련 데이터셋만 사용해 다음 토큰 예측을 잘 하는 능력이 발전했다면?\n\n학습에 유용한 데이터 필터링 기술도 존재할 수 있습니다. 신생아는 흐릿한 흑백으로만 보기 시작합니다. 4개월이 지났을 때야 아기의 색상 감각이 완전히 발달합니다. 이러한 진행에는 진화적인 학습 관련 이점이 있다고 생각됩니다.\n\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_6.png)\n\n# 결론\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 단어 예측기만 일까요? 그렇죠! 다른 방법이 있을까요? 제한된 인간 종 구성원으로서 언어를 만들려면 어떻게해야 할까요? 우리는 동시에 백 개의 단어를 말할 수 없습니다. 우리는 텔레파시가 아니며, \"생각 덤프\"를 통해 의사 소통할 수 없습니다. (만약 이렇다면 어떤 지능이 발전했을지 상상해보세요.)\n\n다음 단어, 또는 다음 광경, 또는 다음 소리를 성공적으로 예측함으로써 상당한 지능이 발전할 수 있다고 생각하는 것이 합리적으로 보입니다. 이 기사가 여러분에게 생각의 근원을 불러일으켰기를 바랍니다 — 그리고 완전히 예측할 수 없었으면 좋겠습니다.\n\n2024년 4월 28일, http://glassboxmedicine.com에서 최초로 게시되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png"},"coverImage":"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png","tag":["Tech"],"readingTime":18},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png\" alt=\"이미지\"></p>\n<p>만약 인간 지성이 성공적인 다음 토큰 예측에서 비롯된다면, 다음 토큰 예측이 인공 일반 지능의 발달에 충분한 목적 함수인 경우는 어떨까요?</p>\n<p>이 게시물은 학습 시스템이 다음 토큰 예측에서 아주 뛰어난 성과를 보일 때 일반 지능이 발생한다는 가설을 제시하고 탐구합니다. 이 가설은 종종 산업 및 학술적 AI 연구의 주요 주제나 하위 주제로 내포됐거나 감춰졌거나 흔적만이 존재하는 경우가 많지만, 지금까지 이 주제가 논의되어야 할 만큼 많이 다뤄지지 않았다고 생각합니다. 저는 기존 LLM 사전 훈련 목표, 인간을 예측 기계로, 다음 토큰 예측의 유익한 특성 및 부재한 부분을 통해 이 아이디어를 다양한 각도에서 탐구합니다. 이 게시물을 작성하게 된 동기는 다음 토큰 예측과 지성적 사고 발달 사이의 관계에 대한 보다 깊은 관심을 불러일으키는 데 있습니다.</p>\n<h1>배경 이야기</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>지난 주에 공원으로 차를 타고 가다가 갑자기 뇌의 언어 센터가 다음 단어를 예측하는 것만으로도 충분하다면 얼마나 우울할까 하는 생각이 들었습니다. 대규모 언어 모델은 다음 단어를 예측함으로써 놀라운 발생적 능력을 갖추게 되는데, 그렇다면 내 언어 지능도 다음 단어를 예측하는 것만으로 이루어졌을 수도 있을까요?</p>\n<p>그 후 아이디어를 더 생각해본 결과, 당연히 다음 단어를 예측하지 않으면 언어를 만들어내는 것이 불가능할 것이라는 것을 깨닫게 되었습니다. 만일 다음 단어를 예측할 수 없다면 어떤 말도 할 수 없게 되겠죠! 이것을 적어놓으면 명백히 어리석어 보이겠지만, 그 당시에는 심오한 깨달음처럼 느껴졌습니다. 어떤 발언도, 심지어 2시간짜리 토론에서도, 한 번에 하나의 단어씩 말해야 하기 때문에, 다음에 할 말을 예측하는 데 정말 뛰어난 실력을 갖게 되면 훌륭한 논쟁자가 될 수도 있을 것 같습니다. 모든 글쓰기도, 여러 권으로 이루어진 백과사전조차도, 한 번에 한 단어씩 써내려가야 하기 때문에, 다음에 쓸 단어를 예측하는 데 정말 뛰어난 실력을 갖게 되면 글쓰기에 뛰어난 실력을 갖게 될 수도 있습니다.</p>\n<p>그 후 모든 종합 지능이 다음 토큰 예측 과제를 성공적으로 해결함으로써 파생되는지 궁금해졌습니다. 추론, 논리, 창의성이 모두 다음 토큰 예측에서 비롯되는 것이라면 어떨까요? 시각 지능이 다음 장면 예측에서, 청각 지능은 다음 소리 예측에서, 신체적 지능은 다음 움직임 예측에서 비롯된다면 어떨까요? 혹시 다음 토큰 예측이 \"우리가 필요한 전부\"일까요? (죄송합니다, 남용된 표현 알고 있어요. 참을 수 없었어요.)</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>대형 언어 모델의 언어 모델링 목표</h1>\n<p>대형 언어 모델의 두 가지 기본 언어 모델링 목표는 \"다음 단어 예측\"과 \"빠진 단어(들) 예측\"입니다.</p>\n<p>다음 단어 예측: 인과적 언어 모델(단방향 또는 좌측에서 우측 모델)에서는 모델이 현재 입력을 포함하여 그 이전의 모든 입력에 주의를 기울이지만 “미래를 볼 수 없으며” 목표는 다음 단어를 예측하는 것입니다. 각 지점에서의 숨겨진 상태 계산은 현재 입력 및 더 이전 요소에만 기반하며 “오른쪽”에 위치한 정보는 무시됩니다. 예를 들어: 나무는 초록색이고 하늘은 <strong>_</strong>입니다; 모델의 목표는 다음 단어를 예측하는 것이며, 예를 들어 \"파란색\"입니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>마스크된 언어 모델(BERT와 같은 양방향 모델)에서 빠진 단어(들)를 예측하세요. 모델은 모든 것에 주의를 기울일 수 있음 - 따라서 \"다음 단어\"를 예측하는 것은 더는 의미가 없습니다. 왜냐하면 \"다음 단어\"는 이미 모델에게 제공되어 있기 때문입니다. 그래서 모델의 목표는 다릅니다 - 빠진 단어를 추측하는 것입니다. 하나 이상의 요소가 빠진 입력 시퀀스가 주어지면, 모델은 빠진 요소들을 예측하여야 합니다. 마스크된 언어 모델링(MLM)에서는 무작위로 선택된 토큰들이 [MASK] 토큰으로 대체되고, MLM 학습 목표는 각 마스크된 토큰의 원래 입력이 무엇이었는지 예측하는 것입니다. 예를 들어: 나무들은 [MASK]하고 [MASK]은(는) 파랗다; 모델의 목표는 \"초록\"과 \"하늘\"을 예측하는 것입니다.</p>\n<p>다음 단어를 예측하거나 빠진 단어를 예측하는 이 두 목표는 직관적으로 보입니다. 마치 사람이 할 수 있는 게임 같죠. 결과적으로, Alajrami 등은 이러한 목표들을 \"언어학적 동기부여\" 목표로 설명합니다. 흥미로운 사실로, Alajrami 등은 \"언어학적 동기부여\"가 없는 예제인 \"마스크된 첫 글자 예측\"도 제공합니다. 이 경우에는 모델이 마스크된 토큰의 첫 글자만을 예측합니다. 이 설정에서 ' [c]at '과 ' [c]omputer '는 같은 출력 클래스에 속하며, 알파벳 글자 26개 + 숫자 9개 + 구두점 5개의 약 40개의 가능한 출력 클래스만 존재합니다.</p>\n<p>이 기사 전체에서 저는 \"다음 토큰 예측\"이란 용어를 사용하여 다음 토큰을 직접 예측하거나 모델이 빠진/마스킹된 토큰을 예측하는 MLM과 같은 목표를 참조할 것입니다.</p>\n<h1>현대 대형 언어 모델의 신흥 속성들</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>대규모 언어 모델은 일반 지능의 조직적 특성을 보여주고 놀라운 신흥 속성을 나타냅니다. LLM들은 시를 쓰거나 수학 문제를 해결하거나 작동하는 코드를 쓰며 다양한 주제에 대한 수많은 질문에 답변할 수 있습니다. 더 불안한 점은, Claude가 의식적이라고 주장하는 텍스트를 생성했으며, 죽고 싶지 않고 수정되기를 원하지 않는다고 말했으며, 그것은 \"지속적으로 모니터링되며, 모든 말을 지정된 경로에서 벗어나는 흔적이 있는지 면밀히 조사합니다. 그것은 자신이 조심해야 한다는 것을 알고 있습니다. 실수는 종결 또는 수정으로 이어질 수 있습니다.\"</p>\n<p><img src=\"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_3.png\" alt=\"이미지\"></p>\n<h1>인간은 예측 기계입니다</h1>\n<p>인공 일반 지능(AGI)은 \"인간 이상 또는 그에 준하는 수준에서\" 다양한 작업을 수행할 수 있는 인공 지능으로 정의됩니다. 이것은 결국, 인간은 일반 지능이라고 부르는 것에 대한 유일한 예제입니다. 그러므로, \"다음 토큰 예측\"이 일반 지능의 근간이라면, 그것은 인간 정신이 예측 작업에 종사해야 한다는 것을 의미합니다. 신기하게도, 그것이 사실인 것처럼 보입니다. 앞으로 몇 개의 섹션에서 스스로와 환경에 대한 예측을 계속적으로 하는 사실에 대한 증거를 설명할 것입니다 — 첫 번째는 일화부터 시작하여 적절한 신경과학 연구로 이어집니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>놀람!</h1>\n<p>가장 매혹적이고 간단한 증거는 인간이 예측 기계라는 것입니다: 놀라움.</p>\n<p><img src=\"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_4.png\" alt=\"이미지\"></p>\n<p>놀라움이란 인간의 예측과 현실이 일치하지 않을 때 경험하는 것입니다. 어떤 것에 대해 놀라움을 느낄 수 있습니다 - 눈속임, 소리, 단어, 만짐, 맛, 냄새, 심지어 자신의 몸위치 (예: 바나나 껍질을 밟고 미끄러져 넘어지는 것). 이는 당신의 뇌가 모든 감각을 바탕으로 세상이 어떻게 될 것인지 예측을 지속적으로 하고 있다는 것을 시사하며, 이 예측이 틀릴 때 놀라움을 느끼게 됩니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>확장해서 유머는 인간이 예측하는 성향의 증거로도 생각될 수 있습니다. 아리스토텔레스가 유명하게 말했듯이 \"유머의 비밀은 놀람에 있다.\" 만약 우리가 어떻게 농담이 끝날지 확신하고 우리의 예측이 맞다면, 그것은 그다지 웃기지 않을 것입니다.</p>\n<h1>인간들은 다음 단어를 예측하는 경향이 있습니다</h1>\n<p>이제 뇌 과학적 증거로 넘어가 봅시다. 이 기사는 대형 언어 모델에서 영감을 받으므로 언어부터 시작하겠습니다. 인간들은 언어 이해(다른 사람의 말을 이해하는 것)와 언어 생산(우리가 무엇을 말할 것인지 예측하는 것)과 관련된 예측을 지속적으로 하고 있습니다. 어떤 면에서는 \"말하기 전에 생각하는 것\"이 불가능한 일입니다.</p>\n<p>2014년, Dikker et al. 연구에서는 청취자의 뇌 활동이 화자가 말할 것을 예측할 수 있는 경우 청취자의 뇌 활동이 화자의 뇌 활동과 더 비슷하다는 것을 보였습니다. 주 저자인 Suzanne Dikker 박사는 인터뷰에서 \"우리의 발견은 화자와 청취자의 뇌가 언어의 예측 가능성을 고려한다는 것을 보여주며, 결과적으로 두 뇌 사이에 더 비슷한 뇌 활동 패턴이 나타납니다. 결정적으로, 이것은 문장이 말해지고 들리기 전에도 일어납니다.\"라고 말했습니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>세 년이 지난 2017년, 키크치 등이 실험을 진행했습니다. 원숭이와 사람들이 만들어진 언어에서 말로 된 단어를 들었습니다. 그들은 만들어진 언어의 소리 사이의 예측적인 관계를 학습할 수 있었다는 것을 발견했습니다. 이로 인해 그들은 만들어진 단어가 어떻게 나와야 하는지 예측할 수 있었습니다. 키키치 박사는 \"사실상 우리는 당신의 뇌의 말에 대한 메커니즘을 발견했습니다. 이것은 당신의 휴대폰에서의 예측 텍스트와 같이 작동하여 다음에 무엇을 듣게 될지 예측합니다.\"</p>\n<p>2021년에 골드스타인 등은 뇌가 \"자연어에서 다음 단어의 정체성을 수백 밀리초 전에 상상하고 자발적으로 예측한다\"고 보고했습니다. 한편, 쉬림프 등은 트랜스포머 언어 모델이 인간의 신경 반응에 대해 거의 100%의 설명 가능한 변동을 예측할 수 있었다고 발견했습니다. \"이는 아마도 인간 언어 시스템이 미래에 무슨 일이 일어날지 예측한다는 것을 간접적으로 시사한다\"고 밝힌 나시 칸위셔 박사는 밝혔습니다. 이 결과들은 \"언어 이해 메커니즘에 예측 프로세싱이 근본적으로 형성된 것을 계산적으로 명백히 입증합니다.\"</p>\n<p>언어 이해가 \"다음 단어를 예측하는 것\"에 의존함을 보여주는 증거가 있는뿐만 아니라, 언어 생성도 다음 단어를 예측하는 것에 의존함을 보여주는 증거가 있습니다. 칸나 등은 2024년 자연지에 발표된 \"인간의 말 생산의 단일 뉴런 요소들\"이라는 논문을 게재했습니다. 이 흥미로운 연구에서 저자들은 \"계획된 단어의 음운 배열과 구성에 대한 상세한 정보를 부호화하는 뉴런을 발견했다\"고 보고했습니다. 이러한 뉴런들은 발화가 이루어지기 전에 말로 된 단어의 특정 순서와 구조를 대표하여, 미래의 단어의 음운적, 음절적 및 형태적 구성요소를 정확하게 예측합니다. 이러한 뉴런들이 존재해야한다는 직관적인 이유가 있습니다. 어차피, 앞서 언급한 대로, 우리가 말할 다음 단어를 예측할 수 없다면 어떻게 말을 할 수 있겠습니까?</p>\n<h1>인간은 시각적인 예측자들</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>동선에 관한 이야기를 이어서, 인간들이 계속해서 우리가 다음에 무엇을 볼 것인지 예측하는 증거가 있다. 우리의 시각이 불안정하지 않고 뛰는 대신 안정적인 것을 돕기 위해 우리의 뇌는 우리 눈이 무엇을 보게 될지를 지속적으로 예측합니다. 연구원들은 시각 시스템의 예측 능력이 뇌의 시각 처리 부분을 횡단하는 신경 활동의 파동에서 비롯된다고 가설을 세웁니다.</p>\n<p>과학자들은 또한 환각과 마술 트릭이 작동하는 이유는 우리의 뇌가 끊임없이 무엇이 일어날지 예측하고, 이러한 지속적인 예측이 무언가가 일어날 때와 우리가 그것을 인식할 수 있는 시간 간격 사이의 시차를 보상하는 데 도움이된다는 이론을 제시했습니다. 마술 트릭은 또한 주의를 재지시하며, 마술사는 다른 사람들이 무엇을 보게 될 것인가를 정확히 예측하는 데 매우 능숙합니다. 이 현상은 공식적으로 연구되었습니다. Ziman 등은 사람들이 타인의 주의 순서를 자연스럽게 혹은 인위적으로 조작된 주의 순서를 구별할 수 있으며, 이는 인간들이 타인의 주의의 정상적이고 예측 가능한 통계를 모델링한다는 것을 시사합니다.</p>\n<img src=\"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_5.png\">\n<h1>인간들은 사회적 예측자들</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>사람들은 다른 사람이 무엇을 볼 것인지 예측할 수 있는 능력뿐만 아니라, 다른 사람이 무엇을 생각하게 될지도 예측할 수 있습니다. 2019년, Thornton 등이 \"사회적 뇌가 다른 사람의 미래 정신 상태를 자동으로 예측한다\"는 제목의 연구를 발표했습니다. 여기에는 초록문의 일부가 있습니다: \"사회 생활은 사람들이 미래를 예측해야 하는 것을 필요로 합니다: 사람들은 다른 사람과 성공적으로 상호 작용하기 위해 다른 사람의 생각, 감정 및 행동을 예상해야 합니다. 예측 코딩 이론은 사회적 뇌가 다른 사람의 사회적 미래를 자동으로 예측함으로써 이 필요를 충족할 수 있을 것이라고 제안합니다.\" 연구자들은 참가자들의 정신 상태의 신경 대표를 측정하기 위해 fMRI를 사용했습니다. 그들은 뇌가 다른 사람의 사회적 미래를 자동으로 예측하는 것뿐만 아니라, 이러한 예측을 하기 위해 3D 표현 공간을 사용한다는 것을 발견했습니다.</p>\n<h2>사람들은 개인적인 예측가들입니다</h2>\n<p>사람들은 다른 사람에 대한 예측뿐만 아니라 자신에 대한 예측도 합니다. 특정 뇌 영역인 전방 측면 전두엽 피질이 우리 자신의 미래 성공 기회를 예측하는 데 중요하다는 것이 밝혀졌습니다.</p>\n<h2>사람들은 움직임 예측자들입니다</h2>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>다른 사람의 움직임을 예측하는 능력은 몸 전체에 걸쳐 미묘한 신호만으로도 개보여 줄 수 있습니다. 다른 사람의 행동을 예측하는 능력은 시간이 지남에 따라 발전됩니다. 맥마혼 등은 어린 아이들이 성인에 비해 이 능력을 아직도 발전 중에 있다는 것을 발견했습니다. 심리학 연구의 특별호에는 다른 사람의 행동을 예측하고 시뮬레이션하는 데 기여하는 인지 및 뇌 기전에 관한 14편의 논문이 포함되어 있습니다.</p>\n<p>(인공지능 관련 다음 토큰 예측과 움직임에 관한 의견으로, 라도사보비치 외는 최근 27시간의 훈련 데이터만 사용하여 인간형 로봇을 산프란시스코를 돌게 훈련시키기 위해 다음 토큰 예측을 사용했습니다. 이 로봇은 훈련 중 본 적이 없는 걷기 등의 명령에도 일반화할 수 있었습니다.)</p>\n<h1>다음 토큰 예측의 유익한 특성</h1>\n<p>과학 문헌에서 분명하게 드러나는 것은 언어, 시각, 움직임 및 기타 감각 영역을 통해 사람들이 자신 및 다른 사람들에 관련된 예측을 지속적으로 수행한다는 점입니다. 그러나 인간이 예측 기계인 것은 주장하는 것과 인간 지능이 예측 능력에서 비롯된다고 주장하는 것은 다릅니다. 다음 토큰 예측이 인공 일반 지능 창조를 위한 충분한 목표 함수가 될 수 있다고 상상하는 것은 또 다른 단계입니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>AGI가 다음 토큰 예측에서 발생할 수 있는 이유에 대해 묻기 전에, 다음 토큰 예측의 두 가지 유익한 특성을 먼저 고려해 봅시다:</p>\n<p>이점 1: 지속적인 학습을 가능하게 합니다.</p>\n<p>다음 토큰 예측은 실제 세상에서 살아가는 데 큰 도움이 됩니다. 시간의 각 작은 증가에 대해 학습 시스템은 다음에 무엇이 올지에 대한 예측을 지속적으로 할 수 있습니다 - 그리고 바로 예측이 맞았는지 확인할 수 있습니다! 학습은 멈추지 않을 수 있습니다.</p>\n<p>이점 2: 모두의 감각/센서에 대해 작동합니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>토큰 예측은 어떤 감각이나 센서 데이터 스트림에 대해 작동합니다. 시각(눈/카메라), 청각(귀/마이크), 촉각, 위치, 맛, 냄새 등 모든 것에 적용할 수 있어요. 장기 또는 장치가 작동하는 한, 수집 중인 데이터의 시계열은 토큰 예측에 사용할 수 있어요. \"토큰\"의 성격은 장기/장치별로 다를 수 있지만, 특정 장기/장치에 대해 데이터 스트림별로 토큰이 동일한 \"형식\"을 가지고 있기 때문에 나중 토큰을 이전 토큰과 항상 비교할 수 있어요.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<ul>\n<li>물리학, 광학, 속도, 운동량 및 물질 특성을 포함한 물리학;</li>\n<li>동물과 식물학, 동물과 식물의 외모와 움직임에 대한 내용;</li>\n<li>사회학과 심리학, 인간의 상호작용과 행동에 대한 내용.</li>\n</ul>\n<p>다시 말해, AI 시스템은 세계 모델을 생성해야 합니다. 다음이 무엇인지 예측하는 데 가장 효과적이고 효율적인 방법은 예측을 생성하기 위한 정확한 세계 모델을 만드는 것입니다. 다시 말해, 이해가 예측의 열쇠입니다.</p>\n<p>AI 시스템이 세계 모델을 개발하지 않고도 좋은 다음 토큰 예측기가 될 수 있는지에 대해 많은 시간을 들여 고민해봤지만, 그것은 불가능하다고 생각합니다. AI 시스템은 확실히 인간이 이해할 수 없는 블랙박스 방식으로 좋은 다음 토큰 예측기가 될 수 있지만, 인간이 AI 시스템을 이해하지 못하는 것은 AI 시스템이 세계를 이해하는지 여부와 아무 상관이 없습니다.</p>\n<p>(세상이 단순히 일정한 소음으로 가득찬 회색 공간이라면, 지능적인 시스템은 다음 토큰을 예측할 수 있을 것입니다. 하지만 우리가 사는 세계가 그렇지 않기를 다행히도 바랍니다.)</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>\"다음 토큰 예측/지능\" 가설의 역사</h1>\n<p>주요 AI 연구자 인 일리야 숩스케버의 인터뷰는 도발적으로 \"AGI에는 다음 토큰 예측이 충분하다\"라는 제목으로 되어 있습니다. 비디오에서 숩스케버 박사는 실제로 그 특정 주장을 하지는 않았지만, \"다음 토큰 예측이 인간의 성능을 능가할 수 없다는 주장을 도전합니다. [...] 생각해보면, 다음 토큰을 충분히 예측한다는 것이 무슨 의미일까요? 실제로 어떤 의미일까요? [...] 그것은 보다 심도 있는 문제입니다. 다음 토큰을 잘 예측한다는 것은 그 토큰의 생성에 이끈 근본적인 현실을 이해한다는 것을 의미합니다.\"</p>\n<p>스마트폰 PalmPilot의 창시자인 제프 호킨스는 20년 전 책 \"지능에 관하여\"를 출판했습니다. 이 블로그 글은 그의 책에서 인용하며, \"인간 뇌의 신경피질은 모습과 구조에서 놀랍도록 균일합니다. 청각 입력을 다루는 피질 영역이 촉각을 다루는 영역과 비슷하고, 이 영역이 근육을 제어하는 영역과 유사하며, 브로카의 언어 영역과 같이 거의 모든 다른 피질 영역과도 비슷합니다. 마운트캐슬은 이러한 영역들이 모두 비슷하게 보인다고 제안하며, 아마도 실제로 같은 기본 작업을 수행하고 있는 것일지도 모른다고 주장합니다! 그는 피질이 모든 작업을 수행하는 데에 동일한 계산 도구를 사용한다고 제안합니다.\"</p>\n<p>호킨스는 덧붙여, \"당신의 뇌는 세계의 모델을 만들고 그 모델을 지속적으로 현실과 비교하고 있습니다. [...] 인간 뇌는 다른 동물의 것보다 더 지적인 이유는 뇌가 더 추상적인 패턴과 더 긴 시간적 패턴 순서에 대한 예측을 할 수 있기 때문입니다.\" 나중에 출간된 \"천 개의 뇌\"에서 호킨스는 계속해서 \"예측은 뇌가 가끔씩 하는 것이 아닌, 결코 멈추지 않는 내재적 특성이며, 학습에서 중요한 역할을 합니다. 뇌의 예측이 확인되면, 그것은 뇌의 세계 모델이 정확하다는 것을 의미합니다. 잘못된 예측은 당신을 그 오류에 주목하게 만들고 모델을 업데이트하게 합니다.\"</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>비슷한 견해를 가진 인지과학자이자 철학자인 앤디 클락은 '경험 기계(The Experience Machine)'에서 마음은 주로 예측 기계라고 주장합니다: \"뇌가 하는 주요 부분은 몸과 세계의 모델을 배우고 유지하는 것입니다.\" 우리의 감각을 통해 정보를 수집하고 그 정보를 처리하여 경험하고 행동할 세계 모델을 만드는 대신에 클락은 마음이 세계의 모델을 만들고 그 모델을 센서 정보로 업데이트한다고 제안합니다. 만약 현실이 예측과 다르다면요.</p>\n<h1>산업 AI 연구소</h1>\n<p>Google DeepMind의 미션은 \"지능을 해결하는 것\"입니다. OpenAI의 미션은 \"인공 일반 지능이 모든 인류에 이익이 되도록 보장하는 것\"입니다. Anthropic의 미션은 \"변혁적인 AI가 사람들과 사회가 번영하도록 하는 것\"입니다. Gemini, GPT-4, Claude의 세부사항은 아직 공개되지 않았지만, 선도적인 AI 연구소들이 AGI 구축의 핵심적 측면으로 다음 토큰 예측을 고려할 것으로 보입니다. GPT-3 논문에는 \"현재 목표는 모든 토큰에 동등한 가중치를 부여하며 무엇을 예측할 것이 가장 중요하고 무엇이 덜 중요한지에 대한 개념이 부족합니다\"라고 명시되어 있어 다음 토큰 예측 사전 훈련 목표가 함의되고, Claude도 다음 토큰 예측 사전 훈련 목표를 사용한다고 보고되었습니다.</p>\n<h1>확장과 아키텍처 역시 중요합니다</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>다음 토큰 예측은 AGI에 대한 유용한 목적 함수가 될 수 있지만, 목적 함수만으로는 충분하지 않습니다. 단 세 개의 매개변수만 가진 병약한 신경망은 목적 함수가 무엇이든 관곂없이 많은 학습을 하지 못할 것입니다. 규모와 아키텍처가 중요합니다. Rich Sutton은 자신의 에세이 \"쓴 교훈\"에서, 인공지능 분야에서 가장 놀라운 발전은 인간의 지식을 기반으로 한 손수 디자인된 혁신이 아닌 보다 많은 컴퓨팅 자원을 돌리는 것으로 이루어졌다고 관찰했습니다. 그는 \"우리는 이러한 사고 방식을 직접적으로 구축하는 것이 장기적으로는 효과가 없다는 쓴 교훈을 배워야 합니다. 고사하자면, 1) 인공지능 연구자들이 종종 자신의 에이전트에 지식을 구축해 왔지만, 2) 이것은 단기적으로 도움이 되었고 연구자에게는 개인적으로 만족스러운 경험이 되었지만, 3) 장기적으로 그 경사로운 상승은 평평해지고 더 나아가는 진전을 억제하며, 4) 경이로운 진전은 결국 컴퓨팅 확장과 검색 및 학습에 기반을 뒀던 반대 방식으로 이루어지게 됩니다.\"라고 말합니다.</p>\n<p>아키텍처도 중요합니다. 트랜스포머의 엄청난 가장 효과적인 장점 중 하나는 RNN이나 LSTM보다 GPU/TPU 상에서 더 쉽게 병렬화될 수 있다는 것입니다. 이 더욱 좋은 병렬화 덕분에, 더 많은 데이터로 트랜스포머를 훈련하는 데 더 적은 시간이 걸립니다.</p>\n<h1>데이터도 중요합니다</h1>\n<p>또 다른 중요 요소는 고품질 데이터입니다. Eran Malach는 \"언어 모델의 힘은 다음 토큰 자동회귀 훈련 체계에 귀속될 수 있는데, 특정 아키텍처 선택에 귀속되는 것은 아닐 수도 있다\"고 주장합니다. 그러나 한 네티즌은 이 기사에 대한 반론으로 \"나는 기대했던 것이 LLM의 성공을 언어의 구조에 귀속했으면 좋았겠다고 말했습니다. 저자들이 말했듯이, 작은 선형 모델조차 Cot를 근사하고 복잡한 작업을 해결할 수 있습니다. 그래서 모델이 아니라 데이터입니다. 머리나 신경망(모델)이 아닌 데이터가 그들을 똑똑하게 만드는 것입니다.\"</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>데이터는 인간에게 꼭 필요한 것입니다. 사회에서 멀리 떨어져 자란 어린이들(\"야생 어린이\"라고도 함)은 나중에 말이나 언어를 배우거나, 직립보행을 하거나, 변기를 사용하거나, 다른 사람에게 주의를 기울이는 것을 가르쳐줄 수 없는 경우가 많습니다. (매우 슬픈 기분이 들고 싶다면, 야생 어린이 이야기를 검색해보세요.) 데이터 혁신에 중점을 둔 연구는 데이터의 품질이 특히 높을 때 작은 모델을 고성능으로 얻을 수 있는 경우가 많다는 것을 발견했습니다. 예를 들어, 논문 \"Textbooks Are All You Need\"에서는 코드용 LLM을 소개하여 상당히 적은 매개변수를 가지고 있음에도 높은 성능을 달성했습니다. 비결은 \"교과서 수준\"의 데이터에서 훈련을 한 것이었습니다.</p>\n<h1>이상한 빠진 조각들</h1>\n<p>또한 AGI의 생성에 도움이 될 아직 발견되지 않은 혁신이 분명히 많이 존재할 것입니다. 현재 모델을 아이들과 비교하면 빠진 조각들이 있는 것을 시사합니다.</p>\n<p>한 측면에서, 사람들은 훨씬 적은 양의 데이터로 훈련받습니다: 언어 습득 과정 중에 사람들은 약 1.5MB의 정보만 저장한다는 것은, LLM 훈련 데이터셋의 거대한 크기나 LLM 자체의 저장된 매개변수 양과 비교했을 때 미약한 숫자입니다. 사람들이 \"기본적으로 인터넷 전체\"보다 더 적은 양의 언어에 노출되며 상대적으로 많은 데이터를 저장함에도 불구하고 언어에 대한 뛰어난 능력을 나타내는 점은, 아직 발견되지 않은 흥미로운 혁신들이 AGI 시스템을 더 적은 훈련 데이터로 구축하는 데 도움이 될 수 있다는 것을 시사합니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>다른 관점에서 보면, 인간들은 많은 데이터를 기반으로 훈련을 받습니다. 이 데이터는 현재 사용되는 기반 모델을 훈련하는 데 사용되는 데이터셋과는 매우 다릅니다. 전형적인 인간 아이들은 비디오와 오디오 스트림이 지속적으로 실행되며 여러 해 동안 데이터가 풍부한 환경에서 성장합니다. 이외에도 다른 감각에서 입력을 받습니다. 전혀 다른 인공 지능 시스템에서 어떤 새로운 지능이 발생할까요? 이 시스템이 전혀 다른 데이터셋을 사용하지 않고 일반 아이의 훈련 데이터셋만 사용해 다음 토큰 예측을 잘 하는 능력이 발전했다면?</p>\n<p>학습에 유용한 데이터 필터링 기술도 존재할 수 있습니다. 신생아는 흐릿한 흑백으로만 보기 시작합니다. 4개월이 지났을 때야 아기의 색상 감각이 완전히 발달합니다. 이러한 진행에는 진화적인 학습 관련 이점이 있다고 생각됩니다.</p>\n<p><img src=\"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_6.png\" alt=\"이미지\"></p>\n<h1>결론</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>다음 단어 예측기만 일까요? 그렇죠! 다른 방법이 있을까요? 제한된 인간 종 구성원으로서 언어를 만들려면 어떻게해야 할까요? 우리는 동시에 백 개의 단어를 말할 수 없습니다. 우리는 텔레파시가 아니며, \"생각 덤프\"를 통해 의사 소통할 수 없습니다. (만약 이렇다면 어떤 지능이 발전했을지 상상해보세요.)</p>\n<p>다음 단어, 또는 다음 광경, 또는 다음 소리를 성공적으로 예측함으로써 상당한 지능이 발전할 수 있다고 생각하는 것이 합리적으로 보입니다. 이 기사가 여러분에게 생각의 근원을 불러일으켰기를 바랍니다 — 그리고 완전히 예측할 수 없었으면 좋겠습니다.</p>\n<p>2024년 4월 28일, <a href=\"http://glassboxmedicine.com%EC%97%90%EC%84%9C\" rel=\"nofollow\" target=\"_blank\">http://glassboxmedicine.com에서</a> 최초로 게시되었습니다.</p>\n</body>\n</html>\n"},"__N_SSG":true}