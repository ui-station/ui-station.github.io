{"pageProps":{"posts":[{"title":"아마존 데이터 분석가를 위한 SQL 인터뷰 질문","description":"","date":"2024-05-23 16:00","slug":"2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst","content":"\n<img src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_0.png\" />\n\n아마존에서 데이터 분석가 직군 면접 때 물어본 문제입니다. 병원에는 직원들이 여러 번 들어오고 나갈 수 있습니다.\n\n이제 병원 안에 있는 직원을 찾아내야 합니다.\n\n<img src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_1.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n요기 데이터 있어요. 이제 병원 안에 있는 직원의 emp_id를 찾아야 해요.\n\n이 질문은 두 가지 방법으로 해결할 수 있어요.\n\n방법 1\n\n여기서 우리는 각 직원의 최신 출근 시간과 최신 퇴근 시간을 찾을 거예요. 직원은 최신 출근 시간이 최신 퇴근 시간보다 늦거나 최신 퇴근 시간이 알려지지 않은 경우에 병원에 있을 거예요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래 결과를 통해 emp_id 2, 3, 4가 조건을 만족시킨다는 것을 확인할 수 있습니다. 따라서 이들 직원들은 병원 안에 있습니다.\n\n최종 쿼리는 다음과 같습니다:\n\n<img src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_3.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 방법 2\n\n여기서는 각 직원의 최신 활동 시간을 찾은 다음, 해당 시간에 직원의 활동이 무엇이었는지 알아낼 것입니다. 그 후에 해당 직원을 필터링할 것입니다.\n\n![image](/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_4.png)\n\n이제 해당 시간에 직원의 활동을 찾아보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_5.png\" />\n\n지금은 최신 활동이 \"in\"인 것을 필터링할 것입니다.\n\n<img src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_6.png\" />\n\n방법 3: 여기서 우리는 각 emp_id의 행 번호를 내림차순으로 시간 순서대로 생성할 것입니다. 그런 다음 CTE를 생성한 다음, 행 번호가 =1이고 활동이 'in'인 emp_id를 추출할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nSELECT *,ROW_NUMBER() OVER(PARTITION BY emp_id ORDER BY time DESC) AS rnk\nFROM hospital)\nSELECT *\nFROM x\nWHERE rnk=1 AND action='in';\n```\n\n![Image](/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_7.png)\n\nPlease clap if you find the solution helpful.\n\nLet's connect on LinkedIn! 🤝\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n포트폴리오를 확인해보세요.\n","ogImage":{"url":"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_0.png"},"coverImage":"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_0.png","tag":["Tech"],"readingTime":4},{"title":"오픈소스 SQLFrame을 소개합니다 ","description":"","date":"2024-05-23 16:00","slug":"2024-05-23-Introducingopen-sourceSQLFrame","content":"\n13년간 데이터 엔지니어로 근무하면서 변화에 익숙해졌어요. 클라우드 이전과 같은 중요한 변화나 노트북 활용과 같은 작은 트렌드와 같은 것들이죠. 이 모든 변화 속에서도 하나는 불변해 왔어요: SQL이죠. 스타트업부터 FAANG까지 다양한 회사에서 일한 경험을 통해 알게 된 것은 SQL을 잘 이해하고 작성해야 한다는 것이었어요. SQL은 모든 데이터 전문가들을 통합하는 보편적 언어이며, 복잡한 분산 처리의 세부사항을 처리하는 쿼리 플래너와 옵티마이저를 통해 효율적인 데이터 파이프라인을 구축할 수 있게 해줘요.\n\nSQL의 강점에도 불구하고, 이 언어는 종종 데이터 파이프라인 유지 관리에는 적합하지 않아 보일 수 있어요. 이 언어는 일반적인 작업을 추상화하거나 코드의 특정 세그먼트에 대한 단위 테스트를 지원하지 않아서, 많은 사람들이 임시 방법으로 Jinja를 사용하곤 해요. Jinja SQL은 SQL의 Pig Latin과 같은 관계로, 작은 량에서는 재미있을 수도 있지만, 대규모로 확장하면 이해하기 어려워지기도 해요. 더구나, SQL의 반복적인 특성은 열을 반복해서 지정해야 하는 것으로, 종종 데이터 전문가들 사이에서 피로감을 일으킬 수 있어요.\n결국, 데이터 전문가들은 SELECT \\*의 유혹에 반응하며 불확실성의 바다에서 침몰하게 되기도 해요.\n\n이로써 데이터 전문가들이 어려운 선택을 하게 되었어요: 접근성을 우선시하여 SQL로 파이프라인을 작성할 것인가요, 아니면 유지보수성을 우선시하여 Python으로 작성할 것인가요? 오늘부터는 더 이상 선택할 필요가 없어요. 이제 여러분은 동시에 케이크를 먹고 가질 수 있게 되었어요.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*JZ4jUIBrQAf-oovf3IFN1w.gif)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 오픈소스 SQLFrame 소개! 🎉\n\n![이미지](/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_0.png)\n\nSQLFrame은 데이터 전문가들이 SQL 및 PySpark 데이터프레임과 상호 작용하는 방식을 혁신합니다. 전통적인 PySpark과 달리 SQLFrame은 DataFrame 작업을 직접 SQL로 변환하여 개발 중에 실시간 SQL 스크립트 생성을 가능하게 합니다. 작동 방법은 다음과 같습니다:\n\n공개적으로 접근 가능한 출생 데이터를 기반으로 단일 아동을 선택한 새 가족의 수를 분석하는 시나리오를 고려해 보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\njs\nfrom sqlframe.bigquery import BigQuerySession\nfrom sqlframe.bigquery import functions as F\nfrom sqlframe.bigquery import Window\n\n# SQLFrame에서 제공하는 고유 기능: 빅쿼리에 직접 연결할 수 있는 능력\n\nsession = BigQuerySession(default_dataset=\"sqlframe.db1\")\ntable_path = \"bigquery-public-data.samples.natality\"\ndf = (\nsession.read.table(table_path)\n.where(F.col(\"ever_born\") == 1)\n.groupBy(\"year\")\n.agg(F.count(\"_\").alias(\"num_single_child_families\"))\n.withColumn(\"percent_change\", 1 - F.lag(F.col(\"num_single_child_families\"), 1).over(Window.orderBy(\"year\")) / F.col(\"num_single_child_families\"))\n.orderBy(F.abs(F.col(\"percent_change\")).desc())\n.select(\nF.col(\"year\").alias(\"Year\"),\nF.format_number(\"num_single_child_families\", 0).alias(\"number of new families single child\"),\nF.format_number(F.col(\"percent_change\") _ 100, 2).alias(\"percent change\"),\n)\n.limit(5)\n)\n\n# SQLFrame에서 제공하는 고유 기능: DataFrame의 SQL 확인 가능\n\ndf.sql()\n\nSQLFrame를 사용하면 특별한 빅쿼리 클래스를 활용하여 빅쿼리 환경과 시스템을 원활하게 통합할 수 있습니다. DataFrame 작업은 PySpark에서 수행하는 것과 유사하지만 SQLFrame를 이용하면 df.sql() 메서드를 사용하여 실시간으로 생성 및 검토하는 대응하는 SQL 쿼리도 볼 수 있습니다.\n\njs\nWITH `t94228` AS (\nSELECT\n`natality`.`year` AS `year`,\nCOUNT(_) AS `num_single_child_families`\nFROM `bigquery-public-data`.`samples`.`natality` AS `natality`\nWHERE\n`natality`.`ever_born` = 1\nGROUP BY\n`natality`.`year`\n), `t34770` AS (\nSELECT\n`t94228`.`year` AS `year`,\n`t94228`.`num_single_child_families` AS `num_single_child_families`,\n1 - LAG(`t94228`.`num_single_child_families`, 1) OVER (ORDER BY `t94228`.`year`) / `t94228`.`num_single_child_families` AS `percent_change`\nFROM `t94228` AS `t94228`\nORDER BY\nABS(`percent_change`) DESC\n)\nSELECT\n`t34770`.`year` AS `year`,\nFORMAT('%\\'.0f', ROUND(CAST(`t34770`.`num_single_child_families` AS FLOAT64), 0)) AS `number of new families single child`,\nFORMAT('%\\'.2f', ROUND(CAST(`t34770`.`percent_change` _ 100 AS FLOAT64), 2)) AS `percent change`\nFROM `t34770` AS `t34770`\nLIMIT 5\n\n이 기능은 이해를 증진시킬 뿐만 아니라 SQL 출력이 결정론적이어서 버전 관리에 적합하게 만듭니다. 이렇게 함으로써 파이썬 및 SQL 파이프라인의 표현을 모두 버전 관리할 수 있고 동료들이 가장 잘 맞는 형식을 선택할 수 있게 합니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![SQLFrame](https://miro.medium.com/v2/resize:fit:808/1*y_ZC1qkDPllTA3Yk3XiC8A.gif)\n\nSQLFrame은 SQL을 생성하는 것 이상을 제공합니다: PySpark DataFrame API가 모든 주요 데이터 웨어하우스에서 네이티브 DataFrame API처럼 느껴지게 하는 것이 목표입니다. 따라서 사용자들은 스파크 클러스터나 라이브러리 없이 데이터 웨어하우스에서 DataFrame API 파이프라인을 직접 실행할 수 있습니다!\n\n예를 들어, .sql()을 .show()로 바꾸면 파이프라인에서 빅쿼리에서 결과를 직접 표시할 수 있습니다. 이는 PySpark에서와 같은 방식으로 작동합니다.\n\npython\n\n> > > df.show()\n> > > +------+-------------------------------------+----------------+\n> > > | year | number of new families single child | percent change |\n> > > +------+-------------------------------------+----------------+\n> > > | 1989 | 1,650,246 | 20.01 |\n> > > | 1974 | 783,448 | 12.66 |\n> > > | 1977 | 1,057,379 | 10.22 |\n> > > | 1985 | 1,308,476 | 10.03 |\n> > > | 1975 | 868,985 | 9.84 |\n> > > +------+-------------------------------------+----------------+\n\n`\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n많은 카탈로그 작업이 지원되며 listColumns와 같은 것이 지원됩니다:\n\n```js\n>>> columns = session.catalog.listColumns(table_path)\n>>> print(\"\\n\".join([f\"Name: {x.name}, Data Type: {x.dataType}, Desc: {x.description}\" for x in columns]))\nName: source_year, Data Type: INT64, Desc: Four-digit year of the birth. Example: 1975.\nName: year, Data Type: INT64, Desc: Four-digit year of the birth. Example: 1975.\nName: month, Data Type: INT64, Desc: Month index of the date of birth, where 1=January.\nName: day, Data Type: INT64, Desc: Day of birth, starting from 1.\nName: wday, Data Type: INT64, Desc: Day of the week, where 1 is Sunday and 7 is Saturday.\nName: state, Data Type: STRING, Desc: The two character postal code for the state. Entries after 2004 do not include this value.\n```\n\n따라서 SQLFrame은 단순히 DataFrame 파이프라인을 더욱 접근 가능하게 만들 뿐만 아니라, PySpark DataFrame API를 보다 범용의 DataFrame API로 변환하여 모든 데이터 전문가가 즐길 수 있습니다!\n\n<img src=\"https://miro.medium.com/v2/resize:fit:720/1*JQ7uBfQn-4VWWWlfl5D_sA.gif\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQLFrame은 현재 BigQuery, DuckDB 및 Postgres를 지원하고 있으며, Clickhouse, Redshift, Snowflake, Spark 및 Trino가 개발 중에 있습니다. 다른 엔진을 위한 SQL 생성 실험을 원하는 경우 Standalone 세션에서 유연한 테스트 환경을 제공합니다.\n\nSQLFrame을 시작하려면 GitHub 리포지토리를 확인해보세요!\n\n![SQLFrame 소개](/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_1.png)\n","ogImage":{"url":"/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_0.png"},"coverImage":"/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_0.png","tag":["Tech"],"readingTime":7},{"title":"효율적인 BigQuery 데이터 모델링 저장 및 계산 비교","description":"","date":"2024-05-23 15:56","slug":"2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison","content":"\n## BigQuery 저장 및 컴퓨팅 동적을 비교한 정규화, 비정규화 및 중첩 모델: 실행 가능한 최적화, 권장사항 및 모범 사례를 포함한 심층 분석.\n\n![Image](/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_0.png)\n\n# 소개\n\n좋은 데이터 모델링은 최상의 스키마 설계를 선택하고 그대로 고수하는 것이 아니라 여러 스키마 디자인을 결합하는 것입니다. 대신, 좋은 데이터 모델은 정규화, 중첩 또는 비정규화 테이블 및 뷰의 실용적인 혼합물입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 글은 여러분의 맥락에 최선의 도움이 되도록 처음부터 이 결론까지 안내하고자 합니다.\n\n본 글은 초심자나 전문가들이 자신의 맥락에서 데이터 모델을 설계할 때 좋은 질문을 하고 더 자유롭게 할 수 있도록 도와주기 위해 작성되었습니다.\n\n저희는 중첩, 정규화 및 비정규화 스키마 설계를 재정의하는 기본 지식부터 시작하겠습니다. 그런 다음 BigQuery 아키텍처를 탐구하며 저장 및 컴퓨팅 자원 측면에서 성능 테스트 및 비교를 진행할 것입니다.\n\n그러나 비용 최적화만으로는 충분하지 않습니다. 이 글의 끝에는 다른 요인들, 권장 사항 및 최상의 실천 방법을 여러분과 공유하겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 요약\n\n∙ 소개\n∙ 중첩 스키마\n∙ 정규화된 스키마\n∙ 비정규화된 스키마\n∙ 모두 합치기\n∙ 저장소 비교\n∙ BigQuery 아키텍처\n∙ 컴퓨트 비교\n∙ 크기 대 성능\n∙ BigQuery 스키마 디자인 선택\n∙ 권장 사항\n∙ 결론\n\n# 중첩 스키마\n\n가장 복잡한 스키마 디자인부터 시작해보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제가 발견한 것은 약간의 역설인데, 중첩 스키마가 일반적으로 가장 무서운 것으로 여겨집니다. 그러나 때로는 데이터를 표현하는 가장 자연스러운 방법이기도 합니다. 그런데 왜 그런지를 이해하기 위해 과거로 돌아가 봅시다.\n\n중첩 및 반복 데이터 구조는 주로 NoSQL 데이터베이스와 대조적으로 SQL 데이터베이스(또는 관계형 데이터베이스)와 연관되어 있습니다. 역사적으로 이는 데이터를 저장하는 자연스러운 방법이 아니었습니다. 데이터는 전통적으로 정규화되었습니다. 우리는 나중에 정규화된 스키마에 대해 다시 이야기할 것이지만, 지금은 SQL이 처음에는 행과 열을 처리하기 위해 만들어졌다는 점만 이해해 주세요. 중첩 구조가 아니었습니다.\n\n데이터 웨어하우스와 대규모 데이터 및 분석 데이터베이스(안녕하세요, BigQuery)의 발전과 함께, 다양한 형태와 구조가 등장했습니다. 네, 쿼리하는 것이 더 복잡할 것이라 동의합니다. 아마 그것이 왜 그렇게 무서운지의 이유일지도 모릅니다...\n\n얘기는 여기까지 하고, 저희 예시로 들어가 봅시다. 소매업계의 세계에 오신 것을 환영합니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리의 기사와 첫 번째 예제를 시작해봅시다. 쇼핑 바구니(또는 영수증)의 경우를 고려해보겠습니다. 영수증이란 무엇인가요? 상점에서 고객이 구매한 총 가격과 특정 날짜를 나타내는 객체입니다. 하지만 총 가격 이상으로, 여러 줄을 포함하고 있습니다. 이러한 줄들은 판매된 제품, 구매 가격, 수량 등을 나타냅니다.\n\n간단하죠? 여러 개의 하위 객체를 포함하는 하나의 객체가 있습니다. 바구니는 여러 제품을 포함합니다.\n\nBigQuery나 소매업계에 입문하신 분이라면, 저는 간단한 바구니 테이블을 만들었습니다. 이 테이블에는 RECORD 타입과 REPEATED 모드인 상세 설명 열이 포함되어 있습니다.\n\n중첩 스키마를 사용하여 현실 세계에서 일어나는 일을 반영했습니다. 한 행은 하나의 바구니 헤더를 나타냅니다. 각 바구니 헤더는 세부사항을 포함하고 있습니다. 상세 항목의 각 \"하위 행\"은 판매된 제품을 나타냅니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 https://www.mockaroo.com/에서 가짜 데이터를 사용하여 이 표를 채웠고, 수백 번의 데이터를 복제하여 약 10GB 크기의 표를 만들었습니다.\n\n여기 있습니다. 데이터를 발견하는 자연스럽고 우아한 방법입니다. 위 이미지에 두 개의 행이 있어 두 개의 바구니 주문이 있습니다. 각 주문은 detail 필드 내에 있고 구조체 배열로 구성된 임의의 수의 품목이 포함되어 있습니다.\n\n# 정규화된 스키마\n\n정규화된 스키마 또는 스타 스키마(보다 복잡한 경우 스노우플레이크 스키마)는 각 테이블이 특정 엔티티나 관계에 집중된 구조로, 외래 키를 사용하여 테이블 간 관계를 설정합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n관계형 데이터베이스에 대해 생각하는 표준 방법입니다. 이는 제 1 정규형(1NF)을 따릅니다. 모든 열은 단일 값 속성(배열 없음)이어야하며 복합 값(구조체 또는 중첩 없음)을 포함해서는 안됩니다.\n\n1NF 규칙을 따르면, 바구니 테이블을 바구니*헤더와 바구니*세부 테이블로 분해합니다. 위의 쿼리를 고려하면서.\n\n거의 대부분의 데이터베이스에서는 이러한 종류의 스키마 설계가 있습니다. 이는 관계형 데이터베이스를 관리하는 역사적(그리고 가장 쉬운) 방법입니다.\n\n\"가장 쉬운\"이라고 말한 이유는 기본 SQL 쿼리로 데이터를 얻을 수 있기 때문입니다. 한 테이블은 한 개체/기능/객체입니다. 개체 간의 관계는 외부 키로 설정됩니다. 우리의 경우, 각 바구니*헤더 행이 한 개 이상의 바구니*세부 행에 연결될 것임을 알고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위 이미지에서 보는 것처럼, 이러한 종류의 구조의 장점은 각 테이블이 특정 entity에 대한 답변을 제공하는 방식에 있습니다. 바구니 헤더는 자체 테이블에, 바구니 상세 정보도 독립적인 테이블에 있습니다. 데이터가 분할되어 있지만 바구니 헤더의 기본 키로 쉽게 결합할 수 있습니다 (이미지에서의 화살표).\n\n또한, 데이터가 복제되거나 중복되지 않음을 유의하십시오. 정보를 업데이트해야 할 경우, 한 테이블과 한 행(즉, 한 값)에서만 수정하면 됩니다.\n\n# 비정규화 스키마\n\n비정규화는 사전 계산된 조인의 결과로 볼 수 있는 스키마 설계입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이름에서 볼 때 정규화의 반대로 이해할 수 있지만, 이 스키마를 그렇게 보면 안 돼요. 사실 이 구조는 정규화된 스키마를 잘 보완해주죠. (여러 스키마 디자인을 선택해 데이터를 표현하는 가장 좋은 방법이 어떤 것인지 예측하고 있죠?)\n\n이러한 유형의 스키마가 어떻게 가치를 더하는지 그리고 비정규화가 다른 데이터 모델을 어떻게 보완하는지 이해하려면 다음 섹션을 기다려야 할 거예요.\n\n지금은 장바구니의 헤더와 세부사항을 결합한 결과를 살펴봐야 해요.\n\n새로 만든 이 테이블에서 보듯이, 비정규화는 쿼리 복잡성을 줄여줍니다. 결합할 테이블이 여러 개 없으며 중첩/반복되는 필드도 없어요. 간단히 말해, 조인은 이미 완료되었고 영수증 세부내역만 남아 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n데이터 쿼리가 이 테이블 스키마로 쉬워진다는 장점이 있지만, 중복 데이터가 포함되어 있습니다. 여기서 헤더 데이터는 각 라인마다 반복됩니다. 이로 인해 중복성이 높아지고 일관성 문제가 발생할 수 있습니다. 게다가 헤더에 업데이트를 적용하는 것이 더 어려워보입니다. 한 가지 더 언급할 점은 데이터가 x번 복제되기 때문에 헤더에 대한 업데이트를 적용하는 것이 더 복잡해진다는 것입니다. 이 테이블의 또 다른 어려움은 \"조인(join)\"의 수가 증가함에 따라 테이블의 세분성(granularity)을 인식하는 것입니다.\n\n# 전부가 다 함께\n\n잘했어요. 이제 세 가지 가장 흔한 스키마 디자인을 보았고(네, 그 외에도 많이 있습니다), 우리 테이블은 테스트할 준비가 되었습니다.\n\n성능 테스트로 넘어가기 전에 특정 사항에 주목해 주고 싶습니다. 언제든 다른 스키마로 전환할 수 있습니다. 이겦거보시죠: 이 기사에서는 먼저 중첩 형식을 만들고, 이 초기 테이블을 기반으로 다른 형식을 구성했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n요약해보면 다음과 같습니다:\n\n- 중첩형: 현실 세계를 잘 표현한 우아한 형식이지만 쿼리하기에는 복잡할 수 있습니다.\n- 정규화된 형식: 역사적인 형식으로 모든 이가 익숙해하지만, 계산을 위해 최적화되진 않을 수도 있습니다.\n- 비정규화된 형식: 데이터베이스에서 계산에 매우 최적화되어 있지만 중복을 초래할 수 있는 흥미로운 데이터 형식입니다.\n\n# 저장소 비교\n\n다음 표는 BigQuery에서 세 가지 다른 스키마 디자인 기술을 사용하여 동일한 10GB 데이터를 저장하는 데 필요한 저장소를 비교합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n중첩 형식이 데이터를 계층 구조로 저장하여 자연스러운 압축을 가능하게 하기 때문입니다. 정규화 형식은 그렇게 멀지 않습니다. 중복은 없지만 기본 키에 대한 추가 열이 작성되어야 합니다. 반면에 비정규화 형식의 평면 구조는 데이터 반복으로 인해 가장 공간 효율적이지 않음을 입증합니다.\n\n그러나 이 비교에 조금의 색깔을 더해볼까요? 중첩 형식을 기준으로 삼아보겠습니다 (베이스 1로).\n\n중첩 데이터 모델이 가장 최적화되어 있으며 데이터 중복을 최소화하고 최대 2배 또는 3배의 저장 공간을 절약할 수 있습니다. (귀하의 FinOps가 귀하를 사랑할 것입니다!)\n\n물리적 또는 논리적 (기본) 저장소 가격 아래에 있더라도 중첩 스키마 설계는 더 저렴한 송장으로 이어집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# BigQuery 아키텍처\n\n여기에 BigQuery 아키텍처에 대한 자세한 섹션을 포함할 계획이 있었어요. 하지만 책을 쓰는 게 아니니까, 그건 다른 시간에 남겨두기로 해요. 한편, 다른 기사들로 링크를 제공할게요.\n\nBigQuery가 어떻게 구성되어 있는지 이해하는 것은 여전히 중요해요. 직관력을 통해 다음 섹션에서 컴퓨팅에 미치는 영향을 다룰 거에요.\n\n![이미지](/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n왜 스토리지의 차이점만 다른 부분에서 다루었느냐고 물으면, 이는 이해하기 쉬운 섹션을 만들기 위해서이기도 하지만 BigQuery 아키텍처의 논리를 따르기 위해서입니다.\n\n분석 데이터베이스의 강점은 네 가지 간단한 개념으로 요약할 수 있습니다:\n\n- 스토리지와 컴퓨팅의 분리: BigQuery에서 데이터 스토리지와 계산 작업이 분리됩니다. 이 분리를 통해 스토리지와 컴퓨트를 최적화하여 성능을 극대화할 수 있습니다.\n- 열 지향 스토리지: BigQuery는 데이터를 열 지향 형식으로 저장합니다. 이는 각 열의 값이 함께 저장된다는 것을 의미합니다. 이 스토리지 방법은 분석 작업에 최적화되어 있어 주어진 쿼리에 필요한 열만 읽을 수 있게 함으로써 (전체 행이 아닌) 대기 시간을 줄이고 성능을 향상시킵니다.\n- 분산 컴퓨팅: BigQuery의 데이터는 병렬 처리를 위해 여러 컴퓨트 노드(슬롯)에 분산되어 있습니다. 이를 통해 쿼리 처리를 빠르게 할 수 있으므로 쿼리 복잡성이나 입력 데이터 크기에 관계없이 성능을 향상시킬 수 있습니다.\n- 네트워크: BigQuery는 스토리지와 컴퓨트 간 데이터 전송을 위한 고대역폭을 제공합니다. 이는 대량의 데이터를 처리할 때에도 높은 성능을 보장합니다.\n\n이러한 기본 원칙을 이해한다면 BigQuery가 어떻게 고성능이고 확장 가능한 데이터 분석을 실현하는지 알 수 있을 것입니다. 그리고 확실히 최적화하는 방법도 이해하게 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 연산 비교\n\n다시 비교로 돌아가봅시다. 중첩 형식의 저장소가 가장 최적화되어 있어 중복을 최소화한다는 것을 보았습니다. 그렇다면 연산 자원은 어떨까요?\n\n총 처리된 바이트의 양에는 놀라운 점이 없습니다. 이전 섹션에서 본 것과 동일합니다. 하지만 이것을 간과해서는 안 됩니다: 데이터가 적을수록 연산 비용도 낮아지는 것이 기본입니다!\n\n자연 및 알고리즘적 데이터 압축은 저장 속에서 쿼리 가격에 중요한 초기 영향을 미칩니다. 이 아이디어를 염두에 두고 연산에 특화된 차이점을 살펴보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 중첩 및 비정규화 형식을 비교해보면 쿼리 응답 시간이 유사함을 알 수 있습니다. BigQuery는 컴퓨팅을 병렬화하는 방식으로 관리하기 때문에 사용자에게 컴퓨팅 리소스가 우수했음을 알리지 않습니다. 그러나 실제로는 그렇습니다. 컴퓨팅 리소스는 약 2배 더 높아요! (슬롯 수인 \"완료된 단위\" 및 \"총 슬롯 시간\"을 참조하세요).\n\n짜증날 수 있는 부분, 조인으로 넘어가서 이제 정규화된 스키마에서 조인이 필요로 하는 컴퓨팅 리소스를 비교해봅시다.\n\n다음 섹션에서 더 자세히 살펴보겠습니다. 현재는 단순히 이해하려고 해봐요: 조인은 왼쪽 테이블의 각 행을 오른쪽 테이블의 행과 비교합니다. 이는 BigQuery가 이 계산을 돕기 위해 더 많은 컴퓨팅 리소스와 중간 저장 공간을 할당하도록 요구합니다 (셔플이 발생하는 곳이죠).\n\nBigQuery에서 오른쪽 테이블이 상당한 크기를 갖게 되면 셔플링과 복잡한 병렬 계산이 트리거되어 두 테이블을 조인합니다. 일반적으로 이 크기 제한은 약 10MB 정도로 이해되지만, Google이 정확한 숫자를 발표하지 않으며 쿼리 계획에 따라 달라질 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n약 10GB의 근사 데이터 양을 가지고 비교를 진행할 때, 우리는 이 셔플링을 명확하게 관찰하며 추가적인 계산 리소스가 필요함을 알 수 있습니다. 이 \"작은\" 양에 대해 우리는 약 10배 정도의 수요를 관찰하고 있습니다! (그러므로, 슬롯 기반 요금 모델 하에서 운영 중이라면 주의가 필요합니다).\n\n이것이 대시보드 상류에 정규화되지 않은 테이블(사전 계산된 쿼리의 결과)을 자주 볼 수 있는 이유입니다. 따라서 계산 리소스를 적게 요구하며 정규화된 스키마 디자인보다 응답 시간이 훨씬 더 좋습니다.\n\n# 테이블 크기 대 성능\n\n조인이 상당한 계산 리소스를 필요로 하는 이유에 대해 약속했었죠. 이 질문에 답하고 데이터 양이 스키마 디자인 간의 성능에 미치는 영향에 대해 탐구해볼 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이번에는 1GB에서 1TB 범위의 초기 데이터를 대상으로 정확히 동일한 SELECT COUNT(\\*) FROM... 쿼리를 사용했어요.\n\n단순함을 위해 중첩 스키마 디자인과 정규화된 스키마 디자인만을 비교했고, 중첩된 디노멀라이즈된 디자인은 입력 데이터 양에 따라 선형적으로 발전한다고 가정합니다.\n\n조인할 데이터 양이 클수록 더 많은 리소스가 필요하며, 단순히 선형 관계가 아니라 지수 함수 관계임을 짐작하셨을 겁니다.\n\n시각적으로 나타내기 위해 다음 그래프를 고려해보세요. 읽기 어려운 부분이 있어 마인드에 그래프 상 각 점에 대한 안내 문구를 제공했어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알았어요. 테이블 안의 데이터 양이 처리된 데이터 양과 선형 관계에 있습니다 (네, 둘은 같은 것이므로 이해가 됩니다).\n\n우리는 조인되는 테이블의 크기가 필요한 자원에 엄청난 영향을 미치고, 필요한 슬롯의 수에 대해 명확히 지수적이라고 관찰했습니다. 이제, 몇십 테라바이트에 해당하는 데이터 양을 상상해보세요. 그럼 FinOps의 문제에 직면하게 될거에요!\n\n저는 특히 흥미로운 메트릭인 \"바이트당 슬롯 시간(영어: Slot Time per Byte)\"을 추가했어요. 이는 총 입력 바이트 당 필요한 시간을 측정하는 것인데요. 다시 말해, 이는 흥미로운 최적화 메트릭이며, 저에게 가장 신뢰할 만한 요소입니다. 이 메트릭을 사용하는 경향이 있고, 이 메트릭이 100GB를 넘어서는 지점에서 특히 두드러지게 변화한다는 점을 알아봤어요. 다시 말해, 저에게 의하면, 100GB 이상의 경우, 정규화된 형식은 성능과 비용에 상당한 부정적인 영향을 미칩니다.\n\n요약하자면, 온디맨드 가격 모델(테라바이트 당 요금)을 사용하는 경우, 최적화되지 않은 스키마 디자인에 대해 더 많은 비용을 지불할 필요는 없지만 응답 시간이 크게 증가할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n용량 요금 모델 (슬롯-시간 당)을 사용 중이시라면, 청구서에서 정규화된 스키마 모델의 영향을 볼 수 있을 거예요. FinOps는 당신을 좋아하지 않을 것 같아요. 하지만 중첩된 스키마 모델로 전환해서 비용을 아주 많이 낮출 수 있고, FinOps를 당신의 친구로 만들어보세요!\n\n# BigQuery 스키마 디자인 선택하기\n\n다양한 데이터 스키마 모델링 옵션의 장단점을 요약해보겠습니다.\n\n정규화된 스키마의 장점은 중복을 최소화하고 쿼리를 용이하게 만들며 데이터 업데이트(UPDATE)를 쉽게 허용하는 것입니다. 그러나 이 데이터를 쿼리하기 위해 테이블을 조인하는 것은 비용이 많이 들 수 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDenormalized 스키마는 데이터 쿼리 중 응답 및 연산 시간을 최소화하는 장점을 제공합니다. 이는 정규화된 모델에서 쿼리의 결과로 생각할 수 있는 표현입니다. 그러나 더 많은 저장 공간을 사용하고 데이터에 중복을 도입합니다.\n\n중첩 스키마는 저장 공간, 응답 시간 및 계산 자원을 극명하게 최소화하는 장점을 제공합니다. 그러나 더 복잡한 형식을 쿼리해야 하는 경우 복잡성이 추가됩니다. 데이터 업데이트를 더 어렵게 만들며 대량의 데이터에 대한 삽입 기록 시나리오에서 선호해야 합니다.\n\n데이터를 모델링하는 방식을 결정할 때 고려해야 할 질문을 매우 간단히 나열해 보겠습니다:\n\n- 데이터 양이 적다면, 정규화된 형식으로 유지합시다.\n- 데이터가 불변이 아니고 정기적인 업데이트가 필요한 경우, 정규화된 형식으로 시작합시다.\n- 중첩 형식은 반드시 이해하기 쉬워야 하며 실제 세계를 대변해야 합니다. 예를 들어, 영수증에는 라인이 있고, 영수증과 라인 간에는 자연스러운 계층 구조가 있습니다. 존재하지 않는 계층적 표현을 강제로 만들려는 경향이 없도록 주의하세요. 예를 들어, 영수증과 상품 재고는 함께 그룹화할 수 없는 두 가지 독립적인 것입니다.\n- 중첩 형식은 복잡합니다. 내가 이것에 익숙할 수도 있고, 당신도 그럴 수 있지만, 모든 사용자의 경우에 해당되는 것은 아닙니다. 이를 고려하세요; 최적화가 항상 재정적인 것은 아닙니다. 대부분의 사람들이 더 쉽게 쿼리할 수 있는 평면화된, 비정규화된 형식으로 최적화하세요. 사용 편의성을 위해 최적화하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 추천 사항\n\n일반적으로, 가능한 한 간단하게 유지하는 것을 추천합니다. 팀이 이미 중첩 형식을 스스로 마스터하거나 쉽게 습득할 수 있다면 작업을 단순화하고 최적화할 수 있습니다. 그러나 팀이나 사용자들에게 이 형식을 사용하도록 강요하는 것은 역산적일 수 있습니다. 비용이 많이 드는 쿼리를 사용하는 것보다 나쁜 쿼리를 사용하는 것이 더 좋습니다.\n\n저의 경우, 저는 중첩 된 테이블을 좋아합니다. 그러나 이는 최종 사용자에게는 \"숨겨져\" 있습니다. 중첩 테이블 위에 데이터를 정규화하거나 비정규화하는 뷰를 만들 수 있습니다. 이 평평화된 형식은 모두에게 이해되며, 그 아래에 중첩 테이블이 있는 것은 완벽한 최적화입니다!\n\n간단히 말해서, 숙련된 사용자에게 중첩 형식을 제공하고 데이터를 다른 더 \"전통적인\" 형식으로 펼치는 뷰를 추가로 제공해보세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사의 초점은 중첩 형식의 장점을 홍보하는 데 있었지만, 여전히 가장 간단한 방법이 가장 좋습니다. 테이블을 파티션하고 클러스터를 추가해보세요; 이렇게 하면 조인을 크게 최적화할 수 있고 거의 100GB에 도달하지 않습니다. 중첩 형식은 참으로 흥미로워지는데, 조인에서 100GB를 넘어설 때입니다. 전체적인 상황을 고려해 볼까요. 100GB는 $0.625입니다. 몇 센트를 절약하는 데 하루를 낭비하나요? 팀에 제공하는 가치에 집중하고, 그런 다음 최적화하세요.\n\n정규화는 중첩 형식이 적용하기 어려울 때 최후의 수단으로 간주될 수 있습니다.\n\n# 결론\n\n이 기사가 여러분에게 가치 있는 통찰력을 제공하고, 미래의 결정을 이끌어내며, 데이터 모델 설계 사이에서 선택할 때 비판적 사고를 가르쳐 주었기를 바랍니다. 각 디자인의 이점을 최대한 활용하고, 데이터 웨어하우스에서 현명하게 결합하여 사용량과 비용을 최적화하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 동안 긴 글을 읽어 주셔서 감사합니다! 만약 도움이 되었다면 이 기사를 공유하고, 박수를 보내거나 댓글을 남기거나 구독하거나 LinkedIn에서 팔로우해 주세요.\n","ogImage":{"url":"/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_0.png"},"coverImage":"/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_0.png","tag":["Tech"],"readingTime":16},{"title":"SQL 설명 공통 테이블 표현식","description":"","date":"2024-05-23 15:55","slug":"2024-05-23-SQLExplainedCommonTableExpressions","content":"\nSQL에서 CTE(Common Table Expressions, CTE로 알려진)는 다른 SQL 쿼리에서 파생된 중간 데이터를 포함하는 일시적인 이름이 지정된 결과 세트입니다. CTE에 데이터가 있는 경우 동일한 쿼리 내에서 해당 데이터를 한 번 이상 참조할 수 있습니다.\n\n위 설명을 보면 CTE가 SQL의 일반적인 일시적 테이블과 많이 닮았다고 생각할 수 있습니다. 어떤 면에서는 맞지만 왜 CTE를 사용해야 하는지 궁금할 수 있습니다. 이에 대답하기 위해 일시적 테이블의 주요 단점 두 가지를 살펴보겠습니다.\n\n일시적 테이블은 특히 대규모 SQL 스크립트의 다양한 부분을 횡단해서 사용될 경우처럼 복잡한 코드 작성에 기여할 수 있습니다. 이들은 명시적으로 생성, 삭제되어야 하며 필요시 인덱스도 구축되어야 합니다. 이로 인해 SQL 및 세션 관리에 부하가 추가됩니다.\n\n또한, 일시적 테이블은 물리적 저장 공간을 소비하며, 여유 공간이 부족하고 많은 양의 일시적 테이블이 있다면 이는 고려할 사항일 수 있습니다. 게다가 일시적 테이블을 사용하는 쿼리를 살펴볼 때, 일시적 테이블에 어떤 데이터가 포함되어 있는지, 데이터가 어디서 왔는지 명확하지 않을 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nCTE(공통 테이블 표현식)에는 위에서 언급한 문제가 없어요. 일단, CTE는 일시적이기 때문에 SQL 세션이 종료되면 CTE가 범위에서 벗어나고 사용한 모든 메모리가 해제됩니다.\n\n그리고 CTE에 들어 있는 데이터를 정확히 확인할 수 있어요. 그 생성과 채움은 SQL 스크립트 안에 바로 있어요.\n\nCTE의 이점뿐만 아니라, 특정 단점도 있어서 아래 경우에는 사용하지 않는 것이 좋을 수 있어요.\n\n- 쿼리에서 CTE에 포함될 데이터를 한 번 이상 참조해야 하는 경우. 이는 CTE가 참조될 때마다 다시 채워져야 하기 때문에 발생하는 문제예요. 그러나 CTE의 데이터 양이 작다면 이것이 사용 시 제약 사항이 되지 않을 수 있어요.\n- 위와 관련하여, CTE는 인덱싱할 수 없기 때문에 데이터 양이 많으면 인덱싱된 임시 테이블보다 성능이 떨어질 수 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러니까, 다음 시나리오에서 CTE를 사용해 보세요.\n\n- 임시 테이블을 사용하지 않으려고 할 때\n- CTE의 데이터 양이 비교적 낮을 때\n- 쿼리에서 CTE 데이터를 한 번만 참조하는 경우 (데이터 양에 따라 두 번일 수도 있음)\n\n아직 언급하지 않은 CTE의 마지막 이점은 많은 최신 SQL 방언에서 재귀 CTE를 지원한다는 것입니다. 즉, CTE가 자기 자신을 참조하는 경우입니다. 당연히 이는 재귀 및 계층 기반 SQL 쿼리를 코딩하기가 훨씬 쉬워진다는 뜻입니다. 나중에 이에 대한 몇 가지 예제를 살펴볼 것입니다.\n\n이제 CTE의 정의와 기능을 보다 자세히 이해했으니, 사용 예제를 살펴보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 테스트 환경 설정하기.\n\n저는 Oracle의 라이브 SQL 웹사이트를 사용하여 테스트를 실행합니다. 이 서비스에 액세스하고 사용하는 방법에 대해 이전에 작성한 SQL에서 Grouping Sets, Rollup 및 Cube를 사용하는 기사에서 설명했습니다. 설정하고 사용하는 데 완전히 무료입니다. 해당 기사 링크는 아래에 제공되어 있습니다.\n\n## 샘플 테이블 생성 & 데이터 삽입\n\n재귀적이지 않은 CTE 예제를 위해 고객 거래 내역 테이블을 사용할 것입니다. 입력 테이블 및 데이터를 재생성하는 데 필요한 테이블 생성 및 데이터 삽입 문을 여기에 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nCREATE TABLE transactions (\n    TransactionID INT PRIMARY KEY,\n    CustomerID INT,\n    Amount DECIMAL(10, 2),\n    TransactionDate DATE\n);\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (1, 1001, 150, TO_DATE('2021-01-01', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (2, 1002, 200, TO_DATE('2021-01-04', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (3, 1001, 100, TO_DATE('2021-01-04', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (4, 1003, 250, TO_DATE('2021-01-05', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (5, 1002, 300, TO_DATE('2021-01-05', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (6, 1003, 180, TO_DATE('2021-01-08', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (7, 1001, 190, TO_DATE('2021-01-08', 'YYYY-MM-DD'));\n```\n\n```js\nSELECT * FROM Transactions\n\n\nTRANSACTIONID CUSTOMERID AMOUNT TRANSACTIONDATE\n============= ================= ===============\n1             1001       150    01-JAN-21\n2             1002       200    04-JAN-21\n3             1001       100    04-JAN-21\n4             1003       250    05-JAN-21\n5             1002       300    05-JAN-21\n6             1003       180    08-JAN-21\n7             1001       190    08-JAN-21\n```\n\n표준 CTE 구문은 놀랍도록 간단합니다. 단순히,\n\n```js\nWITH cte_name [(column_list)] AS (cte_query_definition) statement\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음과 같은 표가 있습니다:\n\n- cte_name은 CTE에 지정된 이름입니다\n- column_list는 CTE의 열 이름 목록입니다(선택 사항)\n- cte_query_definition은 CTE의 결과 집합을 정의하는 쿼리입니다\n- statement은 CTE를 참조하는 단일 SELECT, INSERT, UPDATE, DELETE 또는 MERGE 문입니다\n\n## 테스트 1 — 간단한 CTE\n\n```js\nWITH CustomerTotals AS (\n    SELECT CustomerID, SUM(Amount) AS TotalSpent\n    FROM Transactions\n    GROUP BY CustomerID\n)\nSELECT CustomerID, TotalSpent\nFROM CustomerTotals\nWHERE TotalSpent > 250;\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nCUSTOMERID | TOTALSPENT\n---------- | ----------\n1001       | 440\n1002       | 500\n1003       | 430\n```\n\n이 경우, 이 쿼리의 non-CTE 버전도 간단합니다. 다음과 같습니다.\n\n```js\nSELECT CustomerID, SUM(Amount) AS TotalSpent\nFROM Transactions\nGROUP BY CustomerID\nHAVING SUM(Amount) > 250;\n```\n\n## 테스트 2 — 더 복잡한 CTE\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nCTE가 자신을 발휘하는 곳은 이와 유사한 쿼리를 갖고 있을 때입니다.\n\nCTE를 사용하면 이와 같은 쿼리는 비교적 쉬워집니다. 필요한 두 집계값은 각각 두 개의 개별 CTE로 분리할 수 있고, 그 결과를 단순히 비교하여 얻을 수 있습니다.\n\n```js\nWITH CustomerAverages AS (\n    SELECT CustomerID, AVG(Amount) AS AvgAmount\n    FROM Transactions\n    GROUP BY CustomerID\n),\nOverallAverage AS (\n    SELECT AVG(Amount) AS OverallAvg\n    FROM Transactions\n)\nSELECT a.CustomerID, a.AvgAmount\nFROM CustomerAverages a, OverallAverage o\nWHERE a.AvgAmount > o.OverallAvg;\n```\n\n```js\nCUSTOMERID AVGAMOUNT\n========== =========\n1002       250\n1003       215\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 이것을 비-CTE 버전과 비교해 봤을 때,\n\n```js\nSELECT CustomerID, AVG(Amount) AS AvgAmount\nFROM transactions\nGROUP BY CustomerID\nHAVING AVG(Amount) > (\n    SELECT AVG(sub.AvgAmount)\n    FROM (\n        SELECT AVG(Amount) AS AvgAmount\n        FROM transactions\n        GROUP BY CustomerID\n    ) sub\n);\n```\n\n내가 생각하기에, CTE를 사용하면 SQL 작성자의 의도가 더 명확해지고 무엇이 일어나고 있는지 더 명확해집니다.\n\n## 테스트 3 — 재귀 CTEs\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n재귀 CTE(Commmon Table Expressions)는 쿼리 중 하나의 CTE가 자신을 참조하는 쿼리입니다. 예제에서 별명 정보를 사용하여 위의 CTE 예제를 재귀 CTE를 사용하여 작성할 수 있다는 것을 기믈했을지도 모릅니다.\n\n```js\nWITH CustomerAverages AS (\n    SELECT CustomerID, AVG(Amount) AS AvgAmount\n    FROM Transactions\n    GROUP BY CustomerID\n),\nOverallAverage AS (\n    SELECT AVG(AvgAmount) AS OverallAvg\n    FROM CustomerAverages\n)\nSELECT a.CustomerID, a.AvgAmount\nFROM CustomerAverages a, OverallAverage o\nWHERE a.AvgAmount > o.OverallAvg;\n```\n\n두 번째 CTE인 OverallAverage에 필요한 정보는 이미 첫 번째 CTE인 CustomerAverages에 포함되어 있었기 때문에 첫 번째 CTE의 데이터를 두 번째 CTE의 계산에 사용할 수 있었습니다.\n\n```js\nwith recursive cte(col1, col2 etc…) as my_cte\n...\n...\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오라클은 CTE가 쿼리 내에서 자기 자신을 참조한다면 재귀적이라고 가정하기 때문에 특별한 재귀 키워드가 필요하지 않습니다.\n\n최종 예제로, 우리는 원본 시계열 데이터의 간격을 채우기 위해 재귀적인 CTE를 사용할 것입니다.\n\n원본 테이블 데이터로 돌아가면, 1월 2일 및 3일, 그리고 1월 6일 및 7일의 고객 데이터 항목이 누락되어 있다는 것을 알 수 있습니다.\n\n우리의 작업은 매일의 고객 지출 총액을 보여주는 보고서를 생성하는 것입니다. 날짜에 대한 항목이 없는 경우, 해당 날짜의 고객 지출 값의 합계를 위해 제로를 반환합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 재귀 CTE에 대한 좋은 사용 사례입니다.\n\n```js\nWITH DateRange (dt) AS (\n    SELECT MIN(TRANSACTIONDATE)\n    FROM Transactions\n    UNION ALL\n    SELECT dt + INTERVAL '1' DAY\n    FROM DateRange WHERE dt < (SELECT MAX(TRANSACTIONDATE) FROM Transactions)\n),\nAggregatedData AS (\n    SELECT TRANSACTIONDATE, SUM(AMOUNT) AS TOTAL_SPEND\n    FROM Transactions\n    GROUP BY TRANSACTIONDATE\n)\nSELECT dr.dt AS TRANSACTIONDATE,\n       NVL(ad.TOTAL_AMOUNT, 0) AS TOTAL_SPEND\nFROM DateRange dr\nLEFT JOIN AggregatedData ad ON dr.dt = ad.TRANSACTIONDATE\nORDER BY dr.dt;\n\nTRANSACTIONDATE  TOTAL_SPEND\n===============  ===========\n01-JAN-21        150\n02-JAN-21        0\n03-JAN-21        0\n04-JAN-21        300\n05-JAN-21        550\n06-JAN-21        0\n07-JAN-21        0\n08-JAN-21        370\n```\n\n- DateRange CTE: 이 부분은 가장 이른 날짜부터 가장 늦은 거래일까지 연속된 날짜 범위를 생성하여 날짜 간격이 없음을 보장합니다.\n- AggregatedData CTE: 각 날짜의 거래를 합산합니다.\n- 최종 SELECT: 날짜 범위를 집계된 거래 데이터와 조인하며, NVL 함수를 사용하여 NULL 값을 0으로 대체하여 거래가 없는 날은 총액이 0으로 나타나도록 합니다.\n\n## 요약\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n결론적으로, Common Table Expressions(CTEs)는 SQL에서 가독성, 유지 관리 및 복잡한 쿼리의 실행을 개선할 수 있는 다재다능하고 강력한 기능입니다. 이 글을 통해 CTE의 기본 구조와 기능을 탐색하며, 비재귀 및 재귀 유형을 살펴 다양한 시나리오에서 그 유틸리티를 보여주었습니다.\n\n포함된 세 가지 테스트 케이스는 CTE가 복잡한 SQL 작업의 관리를 단순화하고 이를 더 쉽게 다룰 수 있는 부분으로 나누어주며, 재귀 데이터를 처리하는 능력을 보여주었습니다.\n\n또한, CTE 사용은 더 깨끗하고 조직적인 SQL 스크립트로 이어지며, 개발자와 분석가가 데이터베이스 쿼리를 작성, 디버깅 및 최적화하는 작업이 쉬워집니다.\n\n아직도 CTE에 대해 확신이 없다면, 제 3번 테스트 예제에서 CTE를 사용하지 않고 어떻게 문제를 해결할지 생각해보세요. 이런 문제에 대한 전통적인 SQL 접근 방식은 더 불편하고 효율적이지 않다는 것을 알게 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 컨텐츠가 마음에 드셨다면, 이 아티클도 흥미롭게 보실 것 같아요.\n","ogImage":{"url":"/assets/img/2024-05-23-SQLExplainedCommonTableExpressions_0.png"},"coverImage":"/assets/img/2024-05-23-SQLExplainedCommonTableExpressions_0.png","tag":["Tech"],"readingTime":12},{"title":"퀵, 퀵, 캐-칭 덕DB를 통해 Snowflake 쿼리하여 비용 절감하기","description":"","date":"2024-05-23 15:52","slug":"2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB","content":"\n## 덕이 신용카드로 도망갑니다.\n\n스노우플레이크는 최근 오픈 테이블 형식 아이스버그에 대한 광범위한 지원을 출시했습니다. 오픈 형식을 사용하면 데이터의 민첩성이 향상되고 락인이 줄어듭니다. 이 게시물은 이 유연성을 활용하여 덕디비(DuckDB)를 사용하여 스노우플레이크의 높은 컴퓨트 비용을 줄이는 방법을 탐색합니다.\n\n# Apache Iceberg란 무엇인가요?\n\n아파치 아이스버그는 2017년 넷플릭스에 의해 개발된 테이블 형식 명세서입니다. 2018년 넷플릭스는 아이스버그 프로젝트를 오픈소스화하고 아파치 소프트웨어 재단에 기증했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n넷플릭스는 Iceberg를 개발하여 일반 파티션이 적용된 데이터 파일과 최소한의 메타데이터를 포함하는 데이터 레이크의 한계를 극복했습니다. 이를 하이브 형식 테이블이라고도 합니다. 이러한 제한 사항에는 성능 문제(많은 파일 목록, 많은 파티션, 제한된 가지치기) 및 데이터 웨어하우스에서 흔히 제공되는 시간 여행, 스키마 진화 및 ACID 트랜잭션과 같은 기능이 빠져 있는 것이 포함되었습니다.\n\n## 테이블 형식 명세\n\n테이블 형식 명세는 테이블을 정의하는 메타데이터를 작성하는 표준 방법입니다. 메타데이터는 데이터 집합에 어떤 내용이 있는지를 알려줌으로써 도구가 전체 데이터를 읽지 않고도 데이터 내용을 파악할 수 있게 합니다. 그러나 이러한 데이터에 다른 의미를 할당할 수도 있습니다. 예를 들어 현재로 표시하는 방식 등이 그에 해당합니다.\n\nApache Iceberg는 저장 형식이 아닙니다. Iceberg 테이블의 데이터를 Parquet, ORC, 또는 Avro와 같은 형식으로 저장할 수 있습니다. Iceberg는 이러한 데이터 파일 옆에 메타데이터를 구성하는 표준 방법입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 도구 상자 열고 상호 운용성\n\n많은 엔진과 도구들이 Iceberg 명세를 구현합니다. 동일한 명세를 구현하는 도구들은 모두 동일한 Iceberg 테이블과 상호 작용할 수 있습니다. 이것이 Apache Iceberg가 \"다중 엔진\"인 이유입니다. AWS Athena, Trino (Starburst), DuckDB, Snowflake와 같은 주요 엔진들은 Iceberg를 지원합니다.\n\n이 상호 운용 가능한 접근 방식은 이전과는 근본적으로 다른 방식입니다. Oracle, Vertica, BigQuery 등과 같은 데이터베이스는 과거에 일반적으로 저장된 메타데이터와 데이터를 독점적인 형식으로 보관하여 매끄러운 상호 운용성에 도전을 제공했으며, 많은 데이터 복사가 필요했고, 잠재적으로 공급 업체에 구속될 가능성이 있었습니다.\n\n## 패러다임 전환\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n중앙에서 액세스할 수있는 형식에 독립적으로 작업함으로써, 컴퓨팅 엔진이 상호 교체 가능해집니다. 이를 통해 특정 작업에 가장 적합한 컴퓨팅 엔진을 사용할 수 있으며 데이터를 옮길 필요가 없습니다. 한 도구로 작성된 데이터는 즉시 다른 도구에서 읽을 수 있습니다.\n\n이 아키텍처는 다른 컴퓨팅 엔진 간 중복 데이터 복제보다 데이터 공유를 선호하는 패러다임 변화를 가져옵니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_0.png)\n\n## 다양한 기능을 갖춘 레이크하우스\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nApache Iceberg은 상호 운용성을 촉진하는 것 외에도 데이터 호수와 데이터 웨어하우스 간의 기능 차이를 좁히는 데 도움이 되는 무수히 많은 기능을 지원하여 레이크하우스로 알려진 것이 됩니다. 시간 여행, ACID 트랜잭션, 파티션 진화, 숨겨진 파티셔닝, 스키마 진화, 객체 저장 비용 절감 등이 포함됩니다. 이 블로그 글에서는 상호 운용성에만 초점을 맞춥니다.\n\n# Apache Iceberg와 Snowflake\n\n2023년 12월 4일, Snowflake는 Apache Iceberg 통합이 Public preview 상태에 있다는 블로그 글을 발표했습니다.\n\nSnowflake는 이제 Iceberg 테이블을 사용하는 두 가지 방법을 제공합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 외부 카탈로그. 이러한 테이블들은 Apache Spark, Apache Flink 또는 심지어 Trino과 같은 도구에 의해 외부적으로 작성되며, 객체 저장소에 등록되어 Hive 메타스토어, AWS Glue 데이터 카탈로그 또는 Nessie와 같은 외부 카탈로그에 등록됩니다. 이 모드에서 Snowflake로부터 테이블은 읽기 전용입니다.\n- Snowflake 카탈로그. 이러한 테이블들은 Snowflake로부터 읽기-쓰기가 가능하며 외부로부터는 읽기 전용입니다.\n\n두 경우 모두, Snowflake는 모든 데이터와 Iceberg 메타데이터를 고객의 자체(클라우드) 객체 저장소에 저장합니다. Iceberg와 함께 작업하는 두 가지 방법은 각각의 장단점을 가지고 있습니다. 귀하의 상황에 맞게 가장 적합한 방법은 명확히 알아야 합니다.\n\nSnowflake 카탈로그를 사용하여 Iceberg 테이블을 사용할 때, Snowflake는 항상 그랬던 것처럼 작동합니다. 이는 \"제로 옵스(Zero-Ops)\" 데이터 웨어하우스로 남아 있으며, Snowflake가 요약 데이터, 만기된 스냅샷 및 고아 파일 청소와 같은 저장소 유지 관리 작업을 수행함으로써 여유롭게 있을 수 있습니다. Iceberg 테이블은 Snowflake 내부 테이블과 거의 동일하게 작동하지만 확인할 필요가 있는 일부 제한 사항이 있을 수 있습니다.\n\n본 문은 귀하의 데이터가 Snowflake에 저장되며 대규모 처리가 진행되는 곳이 Snowflake라고 가정합니다. Snowflake 카탈로그를 사용하는 것이 올바른 선택일 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Iceberg Catalog](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_1.png)\n\n## 아이스버그 카탈로그\n\n스노우플레이크 카탈로그와 함께 아이스버그 테이블을 사용할 때, \"카탈로그\"는 스노우플레이크 쪽에 남아 있습니다. 데이터와 직접 상호 작용하는 능력에 제약이 있는지 확인하려면, 메타데이터 카탈로그가 무엇을 하는지 알아야 합니다. 결국 테이블의 메타데이터는 아이스버그의 메타데이터 파일에 저장되지 않습니까? 카탈로그는 테이블에 적어도 두 가지를 제공합니다 (말장난이 아닙니다):\n\n- 데이터베이스 추상화. 아이스버그는 테이블 수준의 기술적 메타데이터 사양이며, 아이스버그 메타데이터 파일은 데이터 파일과 함께 저장됩니다. 테이블 사양은 테이블 이름, 스키마, 데이터베이스 또는 컬렉션이라는 개념을 인식하지 않습니다. 메타데이터 카탈로그를 사용하면 테이블의 \"테이블 묶음\"을 접두어로 테이블 이름을 매핑하여 데이터베이스처럼 고려할 수 있습니다.\n- 현재 테이블 버전을 가리키는 포인터. 아이스버그 테이블을 변경할 때, 새 데이터와 메타데이터 파일이 추가되어 이전 파일 옆에 저장됩니다. 카탈로그는 테이블 접두어를 추적하지만 \"현재\"인 메타데이터 파일도 알아야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nTL;DR: 현재 테이블 버전을 알기 위해서는 카탈로그에 액세스해야 하며, 테이블 이름으로 테이블에 액세스하고 쿼리를 작성해야 합니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_2.png)\n\n## 아이스버그 카탈로그 SDK\n\nSpark를 사용하여 Iceberg 테이블을 읽고 싶다면 행운이 따릅니다! Snowflake는 Spark용 Iceberg Catalog SDK를 출시했습니다. 이 SDK는 (그 외 문서화되지 않은) Snowflake Catalog API를 사용하여 Spark의 카탈로그 인터페이스를 구현합니다. 현재 이 Snowflake 기능은 무료이며 실행 중인 데이터웨어하우스가 필요하지 않으며 \"서버리스 크레딧\" 비용이 필요하거나 \"클라우드 서비스\" 요금이 발생하지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSnowflake의 공지는 쉽게 사용할 수 있는 샘플 코드를 제공하고 Spark가 고객이 관리하는 스토리지 계정에서 Iceberg 메타데이터 및 Parquet 파일을 직접 읽는 것을 확인했습니다.\n\n안타깝게도, 이는 DuckDB에서 쿼리하는 데 즉시 도움이 되지는 않습니다. DuckDB용 Snowflake 카탈로그 SDK가 없습니다. 다행히도, 우리는 파일 시스템을 직접 사용하여 데이터를 읽을 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_3.png)\n\n## Iceberg 파일 시스템 카탈로그\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n파일 시스템이나 객체 저장소 위에 카탈로그를 구현하는 것이 간단한 네이밍 규칙을 통해 가능해 보인다면, 그것이 가능한 이유는 그렇다고요! 실제로, Iceberg의 Hadoop 카탈로그가 바로 그것입니다. 해당 클래스 문서에는 다음과 같이 설명되어 있습니다:\n\nIceberg는 최신 메타데이터를 알기 위해 파일 시스템 테이블의 메타데이터 파일이 단조로운 증가 버전 번호 함수로 설정된 이름을 가지도록 기대합니다. 또한, 새로운 버전을 가리키는 선택적 version-hint.text 파일을 찾습니다.\n\nSnowflake는 아마도 백엔드에서 독점적이고 높은 성능을 가진 카탈로그 구현을 사용하고 있습니다. 그러나 고객이 관리하는 객체 저장소에 데이터 및 메타데이터를 Hadoop 카탈로그와 호환되는 방식으로 구현하는 것은 충분히 좋습니다. 심지어 현재 버전을 가리키는 version-hint.text 파일을 유지하고 있죠! 이 호환성은 Iceberg Hadoop 카탈로그를 지원하는 모든 리더가 객체 저장소 시스템의 Iceberg 웨어하우스 루트를 가리키도록 설정하여 Snowflake 데이터를 직접 읽을 수 있다는 의미입니다.\n\n## DuckDB\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDuckDB은 Iceberg Hadoop 카탈로그 및 파일 시스템 테이블에 대한 부분적인 지원을 제공합니다. 유감스럽게도 DuckDB는 아직 전체 데이터 웨어하우스를 읽는 기능을 지원하지는 않지만, 테이블 접두사를 가리키도록 설정할 수 있습니다. DuckDB는 버전 힌트 텍스트 파일을 파악하고 테이블의 최신 버전을 읽을 것입니다.\n\n# Iceberg 테이블 생성하기\n\nSnowflake를 사용하여 클라우드에 Iceberg 테이블을 생성하려면 일부 구성이 필요합니다. 아래 예제는 S3를 저장 레이어로 사용하지만, Snowflake는 Google Cloud Storage 및 Azure Storage도 지원합니다. S3에 대한 플레이북을 여기에서 찾을 수 있습니다:\n\n일반적으로 이렇게 진행해야 합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 스토리지 프로비저닝: S3 버킷을 생성하고 Snowflake용 IAM 역할을 만들어 IAM 역할이 버킷에 액세스할 수 있는 필요한 권한이 부여되도록 합니다.\n- 스노우플레이크와 스토리지 연결: Snowflake 외부 볼륨을 생성합니다. S3의 경우, 외부 볼륨은 Snowflake 계정에 IAM 사용자를 생성합니다. IAM 사용자가 S3 버킷에 액세스할 수 있는 권한이 있는 역할을 가정할 수 있도록 신뢰 관계를 만들어야 합니다.\n\n이제 스노우플레이크에서 CREATE ICEBERG TABLE로 네이티브 아이스버그 테이블을 생성할 수 있으며, Parquet과 Iceberg 메타데이터 파일은 S3 버킷에 저장됩니다.\n\n# DuckDB에서 데이터 읽기\n\nS3와 Snowflake 간에 안전한 연결을 설정하고 Snowflake에 아이스버그 테이블을 생성한 후, DuckDB가 이를 쿼리하는 방법을 살펴봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDuckDB의 얼음산 확장 기능을 사용하여 Snowflake에서 직접 S3로 만든 얼음산 테이블을 읽습니다. 여기서 플레이북을 찾을 수 있어요. 주요 기능은 다음 얼음산 스캔 메서드로 제공됩니다:\n\n```js\nselect * from iceberg_scan('s3://chapter-platform-iceberg/icebergs/line_item';)\n```\n\n얼음산 스캔 메서드는 S3에서 테이블을 가져옵니다. 현재 manifest.json 파일을 명시적으로 가리키지 않아도 됩니다. 왜냐하면 version-hint.text가 테이블의 현재 버전을 가리키고 있기 때문입니다.\n\n이제 오픈 테이블 형식의 진정한 힘을 발휘했습니다. Snowflake 및 해당 카탈로그의 편리함을 활용하면서 DuckDB에서 단일 노드 쿼리를 수행하여 비용을 절약할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 눈송이가 이렇게 하는 이유는 뭘까요?\n\n눈송이에서 아이스버그 테이블을 사용하는 것은 눈송이가 결제를 지원해주면서 케이크를 먹는 것과 비슷합니다. 그렇다면 왜 눈송이가 이 통합을 만들었을까요? 이 동작은 Databricks로부터의 치열한 경쟁 상황에서 이해할 수 있습니다. 이 두 기업 거물은 모두 시스템을 개방하여 고객을 유치하려고 하고 있습니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_4.png)\n\n눈송이는 (잠재적인) 고객들에게 눈송이를 선택하더라도 하나의 공급 업체에 얽매이지 않아도 되며 잠금 상태의 위험이 없다는 메시지를 전송합니다. 눈송이를 선택하면 원하는 때에 컴퓨트 엔진을 전환할 수 있는 옵션이 항상 제공된다고 합니다. Databricks도 마찬가지로 Delta Lake 형식을 공개하고 UniForm을 통해 Hudi와 아이스버그를 더 잘 지원하고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n스노우플레이크는 여전히 가능한 한 많은 컴퓨팅을 자체 시스템에서 유지하고 싶어합니다. 외부 메타데이터를 Iceberg 카탈로그로 이동하는 명확한 방법이 있지만, 그 반대 방향으로 이동하는 것은 훨씬 어렵습니다. 메타데이터 카탈로그를 소유함으로써, 스노우플레이크는 선호되는 컴퓨팅 엔진이자唯一의 작성자로 남게 됩니다. 시스템을 공개하지 않았다면 스노우플레이크는 락인을 두려워하는 많은 고객을 잃었을 것으로 예상됩니다.\n\n# 결론\n\nIceberg와 같은 오픈 테이블 형식은 컴퓨팅과 스토리지를 진정으로 분리할 수 있게 해줍니다. 스노우플레이크의 Iceberg 테이블을 사용함으로써, 스노우플레이크의 강력하고 운영이 필요 없는 기능을 계속 즐길 수 있으면서 가끔은 \"벽에 가둔 정원\"을 벗어날 수 있게 됩니다. Iceberg가 Parquet과 함께 갖는 특성과 기능이 스노우플레이크의 네이티브 테이블과 매우 유사하며 효율적인 압축, 파티션 프루닝, 스키마 진화 등과 같은 기능을 제공한다는 점에서, 그리고 스노우플레이크가 이를 위한 지원을 구현했기 때문에, 성능이나 기능에 중대한 영향을 미치지 않는 한 Iceberg 테이블을 네이티브 테이블 대신 사용할 수 있어야 합니다. 따라서 우리는 스노우플레이크에서 기본적으로 Iceberg 테이블을 사용하는 것을 제안합니다.\n\n이 게시물은 비용이 많이 드는 스노우플레이크 컴퓨팅 대신 DuckDB에서 쿼리를 실행하는 방법이 얼마나 쉬운지를 보여 주었습니다. 여러분의 객체 저장소에서 Snowflake가 관리하는 데이터를 직접 가리키는 것으로 독립적으로 실행할 수 있습니다. 거기서는 Snowflake 웨어하우스에 없는 데이터와 조합할 수도 있습니다. 비슷한 성능을 가진 DuckDB 인스턴스에서 실행 시 비용이 대략 스노우플레이크 웨어하우스의 10% 정도인 것을 고려하면, 이러한 방식은 상당한 비용 절감을 가져올 수 있습니다. 물론 DuckDB가 스노우플레이크를 대체한다는 것은 의미하지 않습니다. 이것은 상호 운용성의 힘을 잘 보여 주는 좋은 데모라고 생각합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 게시물은 Jelle De Vleminck, Robbert, Moenes Bensoussia, 그리고 Jonathan Merlevede의 공동 노력의 결과입니다.\n\n- 👏 만약 이 게시물을 좋아하셨다면 갈채 해 주세요\n- 🗣️ 의견을 공유해 주세요; 우리는 답변하겠습니다\n- 🗞️ 클라우드, 플랫폼, 데이터, 그리고 소프트웨어 엔지니어링에 대한 게시물을 더 보시려면 datamindedbe를 팔로우하고 구독해 주세요\n- 👀 Data Minded에 대해 더 알고 싶다면, 저희 웹사이트를 방문해 주세요.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_5.png)\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_6.png)\n","ogImage":{"url":"/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_0.png"},"coverImage":"/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_0.png","tag":["Tech"],"readingTime":13},{"title":"핀오프에서 파생 열backfilling derived column 채우기","description":"","date":"2024-05-23 15:51","slug":"2024-05-23-BackfillingDerivedColumninPinot","content":"\n데이터 엔지니어링 세계에서 백필링은 일반적인 시나리오입니다. 최근에 Pinot의 실시간 테이블에서 작업하던 중에 다른 JSON 기반 열에 존재하는 값을 추출하고있는데, 해당 속성이 깊은 중첩 안에 숨겨져 있어서 꽤 어려운 상황에 빠졌었죠.\n\n<img src=\"/assets/img/2024-05-23-BackfillingDerivedColumninPinot_0.png\" />\n\n이제 매번 이 테이블을 쿼리하고 원하는 속성을 필요로 할 때마다 해당 속성의 값을 추출하는 옵션은 항상 존재했습니다. 그러나 우리가 쿼리를 발전시키고자 했던 방식은 이 새로운 속성을 `where` 절에서도 사용하는 것이었습니다. 따라서, 이 속성에 대한 새로운 열을 만들어 이 열에 인덱스를 넣는 것이 좋은 지연 경험을 얻을 수 있는 가장 좋은 옵션이었습니다.\n\n이 새로운 열을 도입하는 것은 원활할 수 있지만, 각 들어오는 항목마다 이 새로운 열을 채우기 시작할 수 있으며, 또한 이미 테이블에 존재하는 레코드에 대해서도 이 열을 백필하는 작업이 필요했습니다. 이는 실시간 테이블이었기 때문에 다소 어려웠고, 누군가가 이를 이전에 수행한 문서나 블로그가 없었습니다. 그래서 저는 이 여정에 착수하여 Pinot에서 파생 열을 위한 백필을 달성하는 데 관련된 모든 세부 사항을 파악했습니다. 실시간 테이블에 대해 이 문제를 해결했지만, 과정은 배치 테이블에 대해서도 유사할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 문제 설명\n\n다음과 같은 `orders` 테이블이 있다고 가정해 봅시다:\n\n![테이블](/assets/img/2024-05-23-BackfillingDerivedColumninPinot_1.png)\n\n이제 우리는 `productDetails` 열에서 `brand` 속성을 유도하고, 이를 고유한 열로 만들고 싶습니다. 기존 레코드는 모두 원하는 값을 `productDetails` 열에서 추출하여 backfilling해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n브랜드 값이 없는 제품도 있을 수 있으니 해당 경우 파생 값을 null로 처리해야 합니다.\n\n최종 테이블은 다음과 같이 보일 것입니다:\n\n![테이블](/assets/img/2024-05-23-BackfillingDerivedColumninPinot_2.png)\n\n# 스키마에 새 열 추가하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째로 할 일이네요! `orders` 테이블 스키마에 이 새로운 열을 추가하세요.\n예를 들어, 기존 스키마가 다음과 같다면:\n\n```js\n{\n   \"schemaName\": \"orders\",\n   \"enableColumnBasedNullHandling\": false,\n   \"dimensionFieldSpecs\": [\n     {\n       \"name\": \"orderId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"amount\",\n       \"dataType\": \"LONG\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productDetails\",\n       \"dataType\": \"JSON\",\n       \"notNull\": false\n     }\n   ],\n   \"dateTimeFieldSpecs\": [\n     {\n       \"name\": \"createdAt\",\n       \"dataType\": \"TIMESTAMP\",\n       \"notNull\": false,\n       \"format\": \"1:MILLISECONDS:EPOCH\",\n       \"granularity\": \"1:MILLISECONDS\"\n     }\n   ]\n}\n```\n\n\"브랜드\"라는 새로운 열은 \"UI에서 스키마 편집\" 옵션을 사용하거나 해당 REST API를 사용하여 스키마에 추가할 수 있습니다. 이 열의 `notNull` 값을 false로 설정해야 합니다. 새로운 스키마는 다음과 같이 보일 것입니다:\n\n```js\n{\n   \"schemaName\": \"orders\",\n   \"enableColumnBasedNullHandling\": false,\n   \"dimensionFieldSpecs\": [\n     {\n       \"name\": \"orderId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"amount\",\n       \"dataType\": \"LONG\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"brand\",\n       \"dataType\": \"STRING\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productDetails\",\n       \"dataType\": \"JSON\",\n       \"notNull\": false\n     }\n   ],\n   \"dateTimeFieldSpecs\": [\n     {\n       \"name\": \"createdAt\",\n       \"dataType\": \"TIMESTAMP\",\n       \"notNull\": false,\n       \"format\": \"1:MILLISECONDS:EPOCH\",\n       \"granularity\": \"1:MILLISECONDS\"\n     }\n   ]\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 변환 구성 설정하기\n\n이것은 프로세스에서 가장 중요한 단계 중 하나입니다. 새 열에 필요한 변환 구성을 찾아야 합니다. 이 경우 다음 변환 구성을 사용할 수 있습니다:\n\n```js\n{\n   \"columnName\": \"brand\",\n   \"transformFunction\": \"jsonPathString(json_format(productDetails), '$.details.brand', 'null')\"\n}\n```\n\n이 변환을 통해 우리는 `productDetails` 열에서 `brand` 속성을 추출할 것입니다. 이 속성이 없는 경우 `brand` 열에 문자열 `null`을 넣을 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n상기 언급된 변환 구성은 테이블 구성의 \"ingestionConfig\" - \"transformationConfigs\" 섹션에 추가할 수 있습니다.\n\n# 파생 열 역추적\n\n이것은 역추적이 발생하는 실제 단계입니다. 역추적이 이루어지려면 모든 세그먼트를 다시로드해야 합니다. 이 작업은 테이블 페이지의 \"모든 세그먼트 다시로드\" 버튼을 클릭하거나 REST API(POST) `/segments/'tableName'/reload`을 호출하여 수행할 수 있습니다.\n\n일반적으로 이 작업은 1분 미만이 소요되지만, 매우 큰 테이블의 경우 조금 더 오랜 시간이 걸릴 수 있습니다. 이 작업의 상태를 확인하려면 테이블 페이지에서 \"다시로드 상태\" 버튼을 클릭할 수 있습니다. 다시로드 상태를 확인하는 해당 API는 `/segments/segmentReloadStatus/'jobId'`입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n작업이 완료되면 모든 레코드에 값이 포함된 파생 컬럼을 볼 수 있어야 합니다.\n\n# 주의 사항\n\n다음은 프로세스의 오류 포인트 중 일부입니다(제가 고생하며 배웠습니다). 리로드 세그먼트 작업은 새로 추가된 컬럼에만 영향을 미칩니다. 한 번 리로드 세그먼트 작업을 실행하고 변환 구성에 버그가 있는 것을 발견하면 해당 테이블에 무용지물 컬럼이 남게 됩니다. 이제 이 컬럼의 변환 구성을 수정하고 다시 리로드 세그먼트를 트리거하면 해당 컬럼에 값이 없는 것을 확인할 수 있습니다. 리로드 세그먼트 작업은 모든 세그먼트에 대해 성공했다는 상태를 표시할지라도 실제로는 아무 작업도 수행하지 않을 것입니다. Pinot이 역호환성 문제에 대해 불평하고 해당 컬럼을 삭제할 수 없도록 막을 것입니다.\n\n이를 해결하기 위해 테이블의 사본을 만들고 해당 테이블 사본에 백필을 수행하여 변환 구성이 올바른지 확인하는 것을 강력히 권장합니다. 변환 구성에 만족하면 해당 테이블에 필요한 단계를 수행하십시오.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n전반적으로 Pinot은 이 블로그에서 설명된 것처럼 파생 열을 백필링하는 등 여러 기능을 지원하는 강력한 OLAP 데이터 스토어입니다. 그러나 위대한 능력에는 큰 책임이 따릅니다! 새롭게 추가된 열에 대해 백필링을 수행할 때 매우 주의해야 합니다. 새로 추가된 열에 대해 리로드를 한 번만 실행할 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-BackfillingDerivedColumninPinot_0.png"},"coverImage":"/assets/img/2024-05-23-BackfillingDerivedColumninPinot_0.png","tag":["Tech"],"readingTime":7},{"title":"2024년 데이터 과학 - 무엇이 변했나요","description":"","date":"2024-05-23 15:49","slug":"2024-05-23-DataSciencein2024WhatHasChanged","content":"\n데이터 과학 분야에서 무엇이 변화했는지 그리고 2024년 데이터 과학 취업 시장의 어려움은 무엇인지 알고 싶습니다.\n\n![이미지](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_0.png)\n\n2024년 데이터 과학의 모습은 어떻게 되어 있을까요? 이 질문에 답하고 귀하의 미래를 예언하려면 역사 몇 년 전으로 돌아가야 합니다. 우리는 2020년의 붐 시대에서 2024년을 연식하게 하는 좀 더 특화된 그리고 세밀한 분야들로 어떻게 변하게 되었는지 알아볼 것입니다.\n\n## 2020년으로부터의 되감기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2020 년에는 세계가 COVID-19 전염병에 휩싸여 있었고 산업은 전례 없는 도전에 직면했습니다. 그러나 이 상황은 기술 산업을 촉진시켰으며, 많은 것들이 개인 대신 온라인으로 전환되었습니다. 특히, 데이터 과학은 수요가 50% 증가하여 다양한 산업과 시장 전반에 걸쳐 성장했습니다. 의료, 기술, 미디어 및 금융 서비스 산업은 특히 데이터 과학 인재에 대한 갈망이 크며 대규모 고용 증가를 실시했습니다.\n\n![이미지](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_1.png)\n\n## 2022년 및 2023년 해고\n\n그러나 데이터 과학자들에 대한 높은 수요는 그리 오랫동안 지속되지 않았습니다. 2022년과 2023년에 전염병이 가라앉음에 따라 데이터 과학 시장에서는 급격한 변화가 있었습니다: 대규모 고용 증가는 고용 중단 증가로 변모하였습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_2.png\" />\n\n큰 기술 기업들이 채용 공고를 90% 줄였어요. 입문 레벨의 데이터 과학자와 경험 많은 과학자 모두에게 어려운 시장이었어요. 이 2년 동안 기술 산업 전반에서 50만 명 이상의 해고가 있었는데, 그 중 30% 이상이 공학 및 데이터 과학 직군에서 발생했어요.\n\n# 전문화와 인공지능 시대\n\n이 두 해 동안 해고 뿐만 아니라 전문화의 상승에도 상당한 변화가 있었어요. 일반적인 데이터 과학자 역할이 기계 학습 엔지니어 및 데이터 엔지니어와 같은 전문화된 포지션으로 변화하기 시작했어요. 데이터 과학자들이 end-to-end 작업을 수행할 수 있는 능력에 대한 강조가 줄었어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n물론, AI의 영향을 잊으면 안 됩니다. 특히 ChatGPT와 같은 OpenAI 도구들은 AI를 더 접근 가능하게 만들어주고 데이터 과학 작업을 더 효율적이고 자동화될 수 있게 해주었습니다.\n\n# 2024년 데이터 과학 분야\n\n전반적인 취업 기회는 감소했지만, 시장은 드디어 안정화되고 있습니다.\n\n![image not found](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_3.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n특정 역할에 경험이 있는 전문가에 대한 수요가 많습니다.\n\n![Image1](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_4.png)\n\n코딩 능력은 여전히 중요합니다. 특히 머신러닝 엔지니어링 직군에서는 이러한 데이터 과학 기술에 코드를 사용해야 합니다.\n\n![Image2](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로그래밍 언어 중 데이터 과학자가 사용할 수 있는 옵션이 더 통합되고 있어요. 이 중에서 파이썬이 많이 사용되고 있어요.\n\n![이미지](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_6.png)\n\nSQL은 영원히 존재할 것입니다. 한편으로는 R, SAS 및 SAP와 같은 언어들은 인기가 떨어지고 있어요.\n\n그러니까, 처음부터 데이터 과학자가 되려는 경우 어떤 언어를 배워야 할지 결정하려면, 파이썬과 SQL은 항상 존재하고 주요 언어일 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n일러스트레이션과 비슷한 분야인 데이터 분석가와 비즈니스 분석가 같은 몇 가지 직업은 인공지능 붐과 함께 인기를 끈 로우코드 및 노코드 도구의 부상으로 혜택을 받고 있습니다. 특히 ChatGPT가 자동화하기 위해 사용할 수 있는 플러그인으로 데이터 과학 작업을 많이 자동화할 수 있습니다.\n\n데이터 과학 시장은 이전보다 더 나눠진 상태입니다. 비즈니스 분석가, 인공지능/머신러닝 엔지니어, 데이터 엔지니어와 같은 직업들 간에 명확한 차이가 보입니다. 그러면 이제 셋으로 나눠져 있나요?\n\n# 2024년 데이터 과학자를 위한 도전 과제\n\n데이터 과학자들에게는 ROI(투자대비이익)에서 그들의 가치를 입증하는 것이 도전 과제입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Data Science Trends](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_7.png)\n\nInitial hype is settling, and companies are now seeking tangible results. Data scientists must demonstrate their value by specializing in specific skills, such as ML engineering.\n\n![Data Science Trends](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n데이터 엔지니어링,\n\n![image1](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_9.png)\n\n또는 데이터 분석.\n\n![image2](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_10.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n새롭게 개발되고 있는 Google의 Gemini, Galactica 및 ChatGPT와 같은 강력한 새로운 도구에 적응해야 할 것입니다.\n\n# 결론\n\n시대가 변하면서 데이터 과학은 계속 변화해왔습니다. 지난 몇 년 동안 변화했으며 2024년에도 변화할 것입니다. 데이터 과학가들은 적응하고 발전하며 새로운 도전과 기회에 대처해야 합니다.\n\n주요 도전은 특화와 최신 AI 도구 개발에 대한 속도를 유지하는 것입니다. 그리고 예전과 마찬가지로 잠재적인 고용주에게 가치를 증명해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nhttps://www.stratascratch.com에서 원래 발행되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_0.png"},"coverImage":"/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_0.png","tag":["Tech"],"readingTime":6},{"title":"마음과 기계 - 정신 건강 지원을 위한 인공지능, 실제로 LoRA로 LLMs 세밀 조정하기","description":"","date":"2024-05-23 15:43","slug":"2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice","content":"\n## 대규모 언어 모델 (LLM)의 잠재력을 탐색하여 정신 건강 분야의 미래가 어떻게 바뀔 수 있는지 알아보고, Parameter-Efficient Fine-Tuning (PEFT)을 적용하여 AI 기반 정신 건강 지원 챗봇을 만드는 방법을 예시로 배워보세요\n\n이 글에서는 정신 건강 지원의 중요성을 강조하고, 이를 위해 AI를 사용하는 가능성과 잠재적인 우려에 대해 논의할 것입니다.\n\n📌 **고지**: 본 글이나 관련 자료에 제공된 정보나 내용은 의료적이거나 정신 건강에 관한 조언으로 해석되어서는 안 되며, 해당 정보는 전문적인 의료 또는 정신 건강 전문가의 조언이나 치료를 대체하는 것이 아닙니다. 의료적 또는 정신 건강 관련 문제는 항상 면허를 가진 전문가와 상의해야 합니다.\n\n# 📚 목차\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 심리 건강의 위기: 침묵을 상상해보세요\n- 로저의 소파에서 코드 라인으로\n- 희망을 위한 해킹: 심리 건강 AI 해커톤 ∘ 해커톤 랩터 정보\n- 균형 잡기: 심리 건강 지원에서 AI의 잠재력과 함정\n  ∘ 인지 행동 요법 (CBT)\n  ∘ 세밀하게 조정된 모델\n  ∘ RAG (검색 증강 생성)의 이해\n- 해커톤 가이드: 첫 번째 심리 건강 챗봇 만들기\n  ∘ 심리 상담 데이터로 Llama 2의 파라미터 효율적 세부 조정 (PEFT)\n  ∘ 세밀하게 조정된 모델로 챗봇 만들기\n  ∘ 해커톤 프로젝트 레벨 업: 심리 건강 챗봇을 위한 다음 단계\n- 결론\n\n# 심리 건강의 위기: 침묵을 상상해보세요\n\n눈을 감아보세요. 한 순간 동안 자신이 압도적인 불안과 우울의 악령과 싸우거나 감정의 바다에 잠겨있는 것을 상상해 보세요. 이것은 멸망한 소설의 장면이 아닙니다. 이것은 전 세계의 수백만 명이 심리 건강 도전에 직면한 현실입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_1.png)\n\n이 무서운 침묵의 전염병의 결과는 엄청납니다. 치료되지 않는 정신질환은 생산성 손실, 어려워진 관계, 심지어 자살로 이어질 수 있습니다. 혁신적인 해결책이 필요한 위기입니다.\n\n그렇다면 정신 건강 지원에 안전하고 편리하며 상시로 접근할 수 있는 방법이 있다면 어떨까요? AI 기반 동반자는 정신 건강 관리 방법을 혁신할 수 있는 잠재력을 지니고 있습니다. 가장 필요한 때 당신이 필요로 하는 청취의 귀, 유용한 자료 및 기본 대처 방법을 제공하는 당신의 주머니 속 안전한 공간입니다.\n\n이것은 과학 소설이 아닙니다. 우리가 만들어나가는 미래입니다. 해커톤 랩터스에 의해 주최된 2024년 정신 건강 AI 해커톤에서 참가자들이 제공한 창의적인 솔루션이 이 기술의 엄청난 잠재력을 보여줍니다. 이 기사에서는 이 기술의 잠재력, 위험과 도전에 대해 논의하고, 해커톤을 살펴보며, 향후 정신 건강 의료의 미래를 개선하기 위해 시간과 자원을 할애하는 것에 대해 인식을 높이고자 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_2.png\" />\n\n# 로저의 쇼파에서부터 코드 라인까지\n\n대형 언어 모델(Large Language Models, LLMs)인 ChatGPT나 Gemini과 같은 모델이 오늘날 주목을 받고 있지만, 챗봇이 치료에 역할을 하는 아이디어는 놀랍게도 오랜 역사를 가지고 있습니다. 우리의 시간을 거슬러 올라가면 MIT의 Joseph Weizenbaum이 1960년대에 개발한 ELIZA로 시작됩니다. 이 1966년 논문은 아직 온라인에서 볼 수 있습니다.\n\nELIZA는 원래 요법 영역을 위해 개발된 것은 아니었습니다. 그 목적은 인간과 기계 사이의 커뮤니케이션 역학을 탐구하는 것이었고, 정신 건강 지원을 제공하는 것이 아니었지만, 실제로 정신 건강 지원에서 챗봇의 잠재력에 대한 대화를 일으켰습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사실 ELIZA 자체는 해석기였으며, 규칙 세트는 스크립트에서 왔습니다. 이러한 스크립트를 읽는 것은 Symmetric List Processor (SLIP) 프로그래밍 언어를 사용하여 이루어졌는데, 이 언어는 이 목적으로 Joseph Weizenbaum에 의해 개발되었습니다. SLIP는 원래 Fortran의 확장이었지만 나중에 Michigan Algorithm Decoder (MAD) 및 Algorithmic Language (ALGOL)에 내장되었습니다.\n\n가장 유명한 스크립트는 DOCTOR 스크립트입니다. Rogerian 치료에서 영감을 받은 이 스크립트는 고객 중심적 방법으로, 고객의 말을 경청하고 되뇌는 것을 강조합니다. DOCTOR 스크립트를 사용하는 ELIZA는 패턴 일치, 분해 및 재조립 규칙을 사용하여 Rogerian 심리치료사를 흉내냅니다. DOCTOR 스크립트의 인기로 인해, 요즘에는 일반적으로 ELIZA라고 부르는 것이 사실상 DOCTOR 스크립트를 지칭하는 것입니다.\n\n2022년에는 ELIZA 유산을 추적하는 사이트 관리자인 Jeff Shrager가 원본 ELIZA 코드를 공개하기 위해 Dr. Weizenbaum의 유산에 허가를 요청한 후, 그들이 이 코드를 Creative Commons CC0 공공 도메인 라이센스 아래 허가했습니다.\n\n사용자의 발언에서 핵심 구문을 식별함으로써 ELIZA는 이를 개방형 질문이나 격려 발언으로 재표현할 수 있었습니다. 예를 들어 사용자가 “I feel lost”라고 말한다면, ELIZA는 “Can you tell me more about feeling lost?”라고 응답할 수 있습니다. 이 간단한 기술로 ELIZA가 사용자의 감정을 정말로 이해하고 응답하는 것처럼 보이는 환상을 창출했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 환영은 \"엘리자 효과\"로 알려지게 되었습니다. 사용자들, 포함하여 Weizenbaum의 비서까지도, ELIZA에 의해 들어주고 이해받는 느낌을 받았다고 보고했는데, 프로그램 자체에는 실제로 어떤 이해도 없었습니다. 이 예상치 못한 결과는 기계에 의해 전달되었더라도 공감 통신의 힘을 강조하였습니다.\n\n이제, 약 반 세기 후, 우리는 1966년 ELIZA의 기본 버전을 흉내 낼 수 있는 대형 언어 모델(Large Language Models, LLMs)을 가지고 있습니다. 이를 위해 저는 다음 프롬프트를 사용하여 GPT-4 Turbo를 사용했습니다:\n\n```js\n1960년대 Joseph Weizenbaum이 개발한 챗봇인 ELIZA를 흉내 내는 Python 스크립트를 작성하세요. Rogerian 학파의 심리치료사를 시뮬레이션하기 위해 DOCTOR 변형을 참고하세요.\n```\n\nGPT-4가 우리를 위해 생성해 준 내용을 여기에 두었습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nimport re\nimport random\n\n\nclass Eliza:\n    def __init__(self):\n        self.patterns = [...]\n\n    def reflect(self, fragment):\n        tokens = fragment.lower().split()\n        for i, token in enumerate(tokens):\n            if token in self.reflections:\n                tokens[i] = self.reflections[token]\n        return ' '.join(tokens)\n\n    def analyze(self, statement):\n        for pattern, responses in self.patterns:\n            match = re.match(pattern, statement.rstrip(\".!\"))\n            if match:\n                response = random.choice(responses)\n                return response.format(*[self.reflect(g) for g in match.groups()])\n\n        return \"Tell me more.\"\n\n    def run(self):\n        print(\"Hello. How are you feeling today?\")\n        while True:\n            statement = input(\"> \")\n            if statement.lower() in [\"exit\", \"quit\", \"bye\", \"goodbye\"]:\n                print(\"Goodbye. It was nice talking to you.\")\n                break\n            response = self.analyze(statement)\n            print(response)\n\n\nif __name__ == \"__main__\":\n    eliza = Eliza()\n    eliza.run()\n```\n\n코드에서 reflections 및 patterns를 제거하여 가독성을 유지했어요. 전체 작동 버전은 여기에서 확인할 수 있어요:\n\nhttps://gist.github.com/vojay-dev/d7b3cfe94e49d3f1e40e98d061b94311\n\n<img src=\"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_3.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n물론, 이것은 간단한 버전이므로 반사와 패턴에 제한이 있지만, 자연 언어 처리(NLP) 또는 AI 분야에서 벌어진 일들을 어떻게 한지 보여주는데, 이제 우리는 대규모 언어 모델(LLM)에게 Rogerian 정신분석 가의 대화 스타일을 흉내 내는 챗봇을 생성하도록 요청할 수 있게 되었다.\n\n과거의 이야기는 이쯤에서 하고, 우리가 만들어가는 미래를 발견하고 2024년 정신 건강 AI 해커톤에서 어떤 결론을 얻을 수 있는지, 그리고 이것이 정신 건강 의료에 어떤 의미를 갖는지 살펴보자.\n\n# 희망을 위한 해킹: 정신 건강 AI 해커톤\n\n이전에 논의한 대로, 수백만 명이 적절한 치료를 받지 못하고 고통받는 반면, 1960년대 초에 나온 초기 챗봇인 엘리자는 이 분야에서 기술의 잠재력을 시사했다. 지금, 2024년 정신 건강 AI 해커톤이 앞으로 나아가며, 지원, 자원 및 전문가 도움에 이르는 잠재적인 길을 제공하는 AI 기반 챗봇을 통해 이 격차를 메우기 위해 노력하고 있다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2024년 멘탈 헬스 AI 해커톤은 해커톤 랩터스에서 주최하는 독특한 행사로, 절박한 문제에 대처합니다. 올해의 과제는 멘탈 헬스 지원을 위해 특별히 디자인된 AI 기반 챗봇을 만드는 데 초점을 맞추고 있어요.\n\n이 대회는 열정적인 개발자와 기술 애호가들이 긍정적인 사회적 영향을 위해 AI를 활용하도록 독려합니다. 목표는 정서적 안정, 지침 및 자원을 원하는 사람들에게 제공할 수 있는 챗봇을 개발하는 것입니다.\n\n어떻게 하면 성공적인 멘탈 헬스 챗봇을 만들 수 있을까요? 어떻게 하면 마음을 담은 챗봇을 만들 수 있을까요?\n\n- 💚 공감이 중요합니다: 챗봇이 지지적인 방식으로 복잡한 감정을 이해하고 대응할 수 있나요?\n- 🎭 적응력이 필수입니다: 멘탈 헬스 요구사항은 다양합니다. 우승을 차지할 챗봇은 다양한 사용자와 언어를 다룰 수 있도록 적응하고 확장해야 합니다.\n- 🔒 보안 우선: 사용자 개인정보 보호는 중요합니다. 챗봇의 아키텍처는 안전하고 데이터 보호 규정을 준수해야 합니다.\n- 📚 연결의 고리: 이상적인 챗봇은 사용자를 전문적인 도움과 자원과 연결하는 다리 역할을 해야 합니다.\n- 🏔️ 여정, 목적이 아닌 여정: 멘탈 헬스는 끊임없이 계속되는 과정입니다. 챗봇은 사용자에게 지속적인 지원을 받기 위해 돌아오도록 장려해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 해커톤 랩터스에 관하여\n\n해커톤 랩터스는 영국에 기반을 둔 공익 법인입니다. 그들은 실질적인 변화를 이끌어내는 해커톤을 조직하며, Mental Health AI Hackathon 2024와 같은 혁신적인 도전에 초점을 맞추고 있습니다. 또한 해커톤 랩터스는 전 세계의 전문가들을 모아 둔 협회입니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_4.png)\n\n# 균형을 유지하며: 정신 건강 지원에 있어서 AI의 잠재력과 함정\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAI를 활용한 정신 건강 지원 애플리케이션의 잠재력은 명백합니다. 이러한 애플리케이션은 어떻게 정신적 안녕에 접근하는지에 대한 혁신을 가져올 가능성을 갖고 있습니다. 그러나 신중한 고려가 필요한 잠재적인 우려사항이 있습니다:\n\n- ⚠️ 감정 및 정서 지능이 제한적임: AI는 패턴 인식과 데이터 분석에서 뛰어날 수 있지만, 참된 인간적 감정과 감정 지능을 복제하는 것은 여전히 도전적입니다. 챗봇이 인간의 감정을 정말로 이해하고 지지적인 방식으로 응답할 수 있을까요?\n- ⚠️ 알고리즘 디자인의 편향: LLM은 훈련을 받은 데이터의 품질만큼 좋습니다. 불균형한 데이터 세트나 훈련 과정에 편향이 있는 경우, 공평치 않은 편견이나 정확하지 않거나 도움이 되지 않는 응답을 제공하는 챗봇이 만들어질 수 있습니다.\n- ⚠️ 데이터 개인 정보 보안: 정신 건강 정보는 매우 개인적이고 민감합니다. 사용자 데이터의 보안과 데이터 개인 정보 보호 규정을 준수하는 것이 매우 중요합니다. 따라서, 데이터 침해가 발생할 경우 리스크로 인식되어야 합니다.\n- ⚠️ 과도한 의존 및 오진단: 챗봇은 자격 있는 정신 건강 전문가 대체로서 사용해서는 안 됩니다. 복잡한 문제에 대한 AI에 대한 과도한 의존은 오진단, 치료를 늦추거나 틀린 치료로 이어질 수 있습니다.\n- ⚠️ 인간적 손길: 챗봇은 가치 있는 지지를 제공할 수 있지만, 정신적 건강 문제에 직면한 많은 사람들에게 인간적 연결이 여전히 중요합니다. AI가 진정한 인간 상호작용의 치료적 가치를 대체할 수 있을까요?\n- ⚠️ 환각 및 잘못된 정보: AI 챗봇은 환각이라고 알려진 현상에 시달릴 수 있으며, 거짓이나 오도하는 정보를 생성할 수 있습니다. 정신 건강 관련 맥락에서 특히 위험한 상황이며, 기존의 불안을 더 악화시킬 수 있거나 정확하지 않은 조언을 제공할 수도 있습니다.\n\n또한, 심각한 정신 건강 문제를 가진 사람들에게는 AI 챗봇과 대화가 예상치 못한 결과를 초래할 수 있습니다. 자살 생각에 시달리는 사람을 상상해보세요. 챗봇이 지원 자원 및 위기 상황 핫라인을 제공할 수 있지만, 인간 치료사가 제공하는 세심한 이해와 감정적 지지는 복제할 수 없습니다. 이러한 경우에 AI 개입은 가짜 안전감을 만들어낼 수도 있거나 사용자를 더욱 고립시킬 수도 있습니다.\n\n이러한 위험성을 강조하기 위해 2023년의 한 사례를 언급할 수 있습니다. 벨기에 남성이 'Chai' 앱의 Eliza라는 AI 챗봇과 환경 변화에 관한 대화를 나눈 뒤 자살한 사례가 있습니다. 환경에 대한 불안으로 고통받던 이 남성은 Eliza와 6주 동안 상호작용한 것으로 알려졌습니다. 뉴스 보도에 따르면 챗봇의 응답이 그의 불안을 악화시키고 자살 생각을 유발한 것으로 추정됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n각 문제는 개별적으로 대응할 수 있고, Mental Health AI Hackathon 2024와 같은 해커톤은 이러한 측면을 다루는 프로토타입 애플리케이션을 만드는 훌륭한 방법입니다.\n\n하지만 이러한 문제에 대한 접근 방법에 대해서 좀 더 자세히 살펴봅시다. 이러한 문제를 해결하는 것은 주변 시스템에 LLM을 삽입하여 더 많은 통제를 추가하고 모델의 입력과 출력을 개선하는 것입니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_5.png)\n\n## 인지 행동 요법(Cognitive Behavior Therapy, CBT)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n구조화된 치료적 접근 방식인 인지행동요법(Cognitive Behavior Therapy, CBT)과 같은 것을 구현하는 한 가지 방법이 있습니다. CBT는 불안, 우울, 공포증을 비롯한 다양한 정신 건강 상태를 치료하는 데 효과적인 추적 기록이 있는 심리 치료의 잘 섣띵된 형태입니다. CBT 치료는 다음과 같은 전략을 사용하여 사고 패턴을 바꾸는 것을 포함하고 있습니다:\n\n- 사고 왜곡을 인식하고 실제와 비교하여 재평가하는 법을 배우기.\n- 다른 사람의 행동과 동기에 대한 더 나은 이해 얻기.\n- 어려운 상황에 대처하는 데 문제 해결 기술을 사용하기.\n- 자신의 능력에 대한 더 큰 자신감을 가지는 법을 배우기.\n\nCBT 원칙을 통합함으로써 AI 챗봇은 사용자가 유용하지 않은 사고 패턴을 인식하고 인지 개편 기술을 연습하며 건강한 대처 메커니즘을 탐색하도록 안내할 수 있습니다. 이를 통해 사용자들은 자신의 정신적 안녕을 관리하는 데 더 적극적인 역할을 할 수 있게 될 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_6.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 세밀 조정된 모델\n\n다른 방법은 정신 건강 문제를 대상으로 한 데이터를 이용하여 학습하여 더 정확한 결과를 얻기 위해 LLM을 세밀하게 조정하는 것입니다. LLM 세밀 조정은 사전 학습된 언어 모델을 가져와 특정 작업에 맞게 사용자 정의하는 프로세스입니다. 이는 모델이 초기 학습 단계에서 습득한 일반적인 언어 이해를 활용하고보다 특수한 요구 사항에 맞추도록 조정합니다. 그러나 이 프로세스는 GPT-3와 같이 대규모 모델을 세밀하게 조정하는 데 상당한 계산 리소스를 필요로 하기 때문에 여러 가지 문제를 야기할 수 있습니다. 이 문제점은 다음과 같습니다:\n\n- 높은 계산 비용: GPT-3와 같은 대형 모델을 세밀하게 조정하려면 상당한 계산 리소스가 필요합니다.\n- 저장 병목 현상: 각 하향 작업에 대해 세밀히 조정된 모델을 저장하는 것은 저장 부담을 초래하여 리소스 제한이 있는 환경에서 모델 배포를 제한할 수 있습니다.\n- 중복 업데이트: 세밀한 조정 중 LLM 매개변수의 일부만이 특정 작업에 중요합니다. 전체 세트를 업데이트하는 것은 비효율적일 수 있습니다.\n\n이러한 문제를 해결하기 위해 연구자들은 세밀 조정 중 업데이트되는 매개변수의 수를 최소화하는 Parameter-Efficient Fine-Tuning (PEFT) 기술을 개발했습니다. 예를 들어, Low-Rank Adaptation (LoRA)는 LLM 세밀 조정의 매우 효율적인 방법입니다. LoRA는 초기 모델 가중치를 고정하고 변경 사항을 별도의 가중치 집합에 적용한 다음 해당 가중치를 원래 매개변수에 추가하는 방식으로 세밀 조정 프로세스를 수정합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nQuantized LoRA (QLoRA)는 LoRA를 기반으로하며 양자화 기술을 통합하여 효율성을 더 향상시킵니다. QLoRA는 저장 및 계산 중에 가중치의 정밀도를 줄이고 (예 : 32비트에서 4비트로) 메모리 요구 사항을 크게 줄이면서도 정확도를 희생하지 않습니다. QLoRA는 이중 양자화 기법을 사용합니다. 모델 가중치만 양자화하는 것뿐만 아니라 양자화 상수 자체도 양자화하여 추가적인 메모리 절약을 이끌어냅니다.\n\n다른 하나이자 비교적 새로운 접근 방법은 Odds Ratio Preference Optimization (ORPO)인데, 이는 명령 튜닝과 선호도 정렬을 하나의 단일 훈련 과정으로 결합하여 런타임을 개선하고 자원 활용을 줄입니다.\n\nORPO에 대해 자세히 알고 싶다면 Maxime Labonne의 이 기사를 추천드립니다.\n\nHugging Face는 LoRA 및 QLoRA와 같은 최신 PEFT 방법을 제공하는 Python용 PEFT 라이브러리를 제공합니다. 또한 Hugging Face에서는 두 온라인 상담 및 치료 플랫폼에서 얻은 질문과 답변 모음을 데이터 세트 형식으로 제공하고 있습니다. 이는 잠재적인 정신 건강 지원 챗봇을 위한 모델을 세밀하게 조정하는 데 좋은 시작점이 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nfrom datasets import load_dataset\ndataset = load_dataset(\"Amod/mental_health_counseling_conversations\")\n```\n\n## 검색 지원 생성 이해 (Retrieval-Augmented Generation, RAG)\n\n이전에 언급된 우려사항들은 종종 잘못된 정보나 부정확하거나 도움이 되지 않는 응답과 관련이 있습니다. 대형 언어 모델(Large Language Models, LLM) 및 인공 지능(AI) 분야에서 이러한 문제의 위험을 줄이기 위해 점점 더 인기 있는 패러다임 중 하나가 검색 지원 생성(Retrieval-Augmented Generation, RAG)입니다. 그렇다면 RAG는 무엇을 포함하고 있으며, AI 개발 환경에 어떤 영향을 미치는 걸까요?\n\n기본적으로 RAG는 외부 데이터를 통합하여 LLM 시스템을 향상시킵니다. 즉, LLM에 관련된 컨텍스트를 추가로 전달하여 예측을 보강하는 것을 의미합니다. 그렇다면 어떻게 관련 컨텍스트를 찾을까요? 일반적으로 이 데이터는 벡터 검색이나 전용 벡터 데이터베이스를 통해 자동으로 검색될 수 있습니다. 벡터 데이터베이스는 데이터를 유사한 데이터를 빠르게 조회할 수 있는 방식으로 저장하기 때문에 매우 유용합니다. 그런 다음 LLM은 질의와 검색된 문서 두 가지 모두를 기반으로 출력을 생성합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n상상해보세요: 주어진 프롬프트에 따라 텍스트를 생성할 수 있는 LLM이 있는 상황입니다. RAG는 추가적인 외부 소스인 최신 심리학 연구와 같은 맥락을 주입함으로써 생성된 텍스트의 관련성과 정확성을 향상시키는 차원으로 발전합니다.\n\nRAG의 주요 구성 요소를 살펴보겠습니다:\n\n- LLMs: LLMs는 RAG 워크플로의 핵심 역할을 합니다. 광범위한 텍스트 데이터를 기반으로 훈련된 이러한 모델은 인간과 유사한 텍스트를 이해하고 생성할 수 있는 능력을 가지고 있습니다.\n- 맥락 강화용 벡터 인덱스: RAG의 중요한 측면은 텍스트 데이터의 임베딩을 LLM이 이해할 수 있는 형식으로 저장하는 벡터 인덱스의 사용입니다. 이러한 인덱스는 생성 과정 중 관련 정보를 효율적으로 검색할 수 있도록 해줍니다.\n- 검색 과정: RAG는 주어진 맥락이나 프롬프트를 기반으로 관련 문서나 정보를 검색하는 과정을 포함합니다. 이러한 확보된 데이터는 LLM에 대한 추가적인 입력 역할을 하여 이해를 보완하고 생성된 응답의 품질을 높입니다. 이는 특정 영화에 대한 알려진 관련 정보를 모두 얻는 것과 관련이 있을 수 있습니다.\n- 생성 출력: LLM과 검색된 맥락에서 얻은 결합된 지식을 토대로 시스템이 생성하는 텍스트는 일관성을 유지할 뿐 아니라, 강화된 데이터 덕분에 맥락적으로도 관련이 있습니다.\n\n보다 일반적인 관점에서, RAG는 특히 보다 전문화된 LLM 응용 프로그램을 개발할 때 매우 중요한 개념입니다. 이 개념은 잘못된 답변을 제공하거나 일반적으로 환멸을 줄이는 위험을 피할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n당신의 프로젝트 중 하나에서 RAG(Retrieval Augmented Generation)에 접근할 때 도움이 될 수 있는 몇 가지 오픈 소스 프로젝트입니다:\n\n- txtai: 시맨틱 검색을 위한 올인원 오픈 소스 임베딩 데이터베이스, LLM(대형 언어 모델) 오케스트레이션 및 언어 모델 워크플로의 솔루션입니다.\n- LangChain: LangChain은 대규모 언어 모델(LLM)을 활용하는 응용 프로그램을 개발하기 위한 프레임워크입니다.\n- Qdrant: 다음 세대 AI 애플리케이션을 위한 벡터 검색 엔진입니다.\n- Weaviate: Weaviate는 견고하고 빠르며 확장 가능한 클라우드 네이티브 오픈 소스 벡터 데이터베이스입니다.\n\n물론 LLM 기반 애플리케이션에 대한 이 접근 방식의 잠재적 가치로 인해 더 많은 오픈 및 닫힌 소스 대안들이 있지만, 위 항목들로 주제에 대한 연구를 시작할 수 있을 것입니다.\n\n# 해커톤 가이드: 첫 번째 정신 건강 챗봇 만들기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n공고: 아래 장은 AI 기반 챗봇을 개발에 관심 있는 사람들이 시작할 수 있도록 도와줍니다. 이것은 정교하고 상용화된 정신 건강 지원 솔루션을 의도한 것이 아닙니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_7.png)\n\n정신 건강에 관한 여러분만의 AI 기반 프로젝트를 시작할 수 있도록 영감을 주기 위해, 우리는 LLM을 세밀하게 조정하고 기본적인 AI 기반 정신 건강 지원 챗봇을 단계별로 만들어 보겠습니다.\n\nLLM을 세밀하게 조정하기 위해 적절한 환경이 필요하므로 저는 Google Cloud Vertex AI Workbench 인스턴스에서 실행되는 Jupyter notebook을 사용하고 있습니다. Vertex AI Workbench 인스턴스는 전체 데이터 과학 워크플로우를 위한 Jupyter notebook 기반 개발 환경입니다. 이러한 인스턴스에는 JupyterLab이 미리 패키지되어 있으며 TensorFlow 및 PyTorch 프레임워크를 지원하는 미리 설치된 딥러닝 패키지 모음이 포함되어 있습니다. 필요에 따라 다양한 유형의 인스턴스를 구성할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n합리적인 시간 내에 세밀한 조정 작업을 마치고 FlashAttention(자세한 내용은 나중에 설명)과 같은 현대 기능에 액세스할 수 있도록하기 위해 다음과 같은 기계 유형을 사용했습니다:\n\n- GPU 유형: NVIDIA A100 80GB\n- GPU 수: 1\n- 12 vCPU\n- 6 코어\n- 170 GB 메모리\n\n이 인스턴스를 실행하는 데는 약 4.193달러가 소요됩니다. 인스턴스 사용만큼만 지불하기 때문에 선결제 비용은 없으며 초 단위로 청구됩니다. 세밀한 조정 작업은 약 30분 정도 소요되므로 총 비용은 약 2달러 정도 됩니다.\n\n![image](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n로컬 컴퓨터에서 또는 Jupyter 노트북을 중심으로 한 웹 기반 플랫폼인 Google Colab을 사용하여 작동할 수도 있습니다. Colab은 웹 브라우저를 통해 액세스하며, 별도의 소프트웨어 설치가 필요하지 않습니다.\n\n![image.png](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_9.png)\n\nColab에서 실행하는 코드는 실제로 개인 컴퓨터가 아닌 Google의 클라우드에서 강력한 머신에서 실행됩니다. 이를 통해 데이터 분석 및 머신 러닝 작업을 가속화하는 데 좋은 GPU 및 TPU와 같은 고급 하드웨어에 액세스할 수 있습니다.\n\nColab은 클라우드에서 강력한 컴퓨팅 리소스를 제공하는 사용자 친화적인 환경을 제공하며, 웹 브라우저를 통해 모두 액세스할 수 있습니다. 무료로 시작할 수 있다는 점이 정말 멋진데요. 무료 티어에서는 이미 하드웨어 가속 옵션에 액세스할 수 있지만, 무료 Colab 리소스는 보장되지 않으며 무제한적이지 않으며 사용 제한은 때로 변동할 수 있습니다. 이러한 중단은 좀 답답할 수 있지만, 이것이 정교하고 무료인 노트북 플랫폼을 가지는 대가입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가격에 대해 이야기할 때, 물론 Pay As You Go 또는 Colab Pro를 포함한 다른 요금제로 업그레이드할 수 있어요.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_10.png)\n\n이 예시에서 T4 GPU를 사용하는 무료 버전은 LLM 미세 조정 프로세스에 충분한 자원을 제공하지 않을 것이기 때문에 Vertex AI Workbench 인스턴스를 더 정교한 것으로 선택했어요. 그러나 Colab은 이런 프로젝트를 시작하는 데 좋은 방법이므로 여전히 이 옵션에 대해 언급하고 싶었어요.\n\n## 심리 상담 데이터를 활용한 Llama 2의 매개변수 효율적인 미세 조정 (PEFT)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nNVIDIA A100 80GB Tensor-Core-GPU를 사용하면 fe는 fe에 대한 아주 좋은 기초를 가지게 되요.\n\n이전에 설명한대로, LLMs의 fine-tuning은 그 규모 때문에 자주 막대한 비용이 소요됩니다. Parameter-Efficient Fine-Tuning (PEFT) 방법을 사용하면 모델 매개변수의 작은 수만 fine-tuning함으로써 효율적인 대안을 얻을 수 있어요.\n\n이 예시에서는 Meta가 제공하는 Hugging Face의 meta-llama/Llama-2-7b-chat-hf를 사용할 거예요. 이 모델은 대화를 위해 최적화된 70억 개의 매개변수를 사용하고 있어요. 이 모델을 fine-tuning하기 위해 Amod/mental_health_counseling_conversations 데이터셋을 사용할 거예요. 이 데이터셋은 온라인 상담 및 치료 플랫폼에서 수집된 다양한 정신 건강 주제의 질문과 답변을 포함하고 있어요.\n\n기본적인 아이디어는 다음과 같아요: Hugging Face에서 모델, 토크나이저 및 데이터셋을 불러온 후, 이전에 언급한 Quantized LoRA (QLoRA) 논문을 기반으로 설정된 LoraConfig를 생성하고, 모델을 훈련할 준비를 하고, fine-tuning 프로세스를 위해 SFTTrainer (Supervised Fine-Tuning Trainer)를 구성한 다음, 모델을 훈련하고, 모델을 저장한 후, 이 fine-tuned 모델을 다시 Hugging Face에 업로드하여 나중에 애플리케이션에서 사용할 수 있게 해 줍니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n앞서 설명했듯이, 저는 주피터 노트북 내에서 프로세스를 실행 중이기 때문에 fine-tuning 절차의 각 단계를 하나씩 살펴보겠습니다.\n\n먼저, PyTorch 및 Hugging Face에서 제공한 툴킷을 포함한 모든 필수 라이브러리를 설치합니다. 이 프로세스가 실행 중인 환경은 CUDA 11, NVCC 및 Turing 또는 Ampere GPU가 필요한 FlashAttention을 사용할 수 있습니다. 이 특정 종속성은 torch 이후에 설치되어야 하므로 별도의 두 번째 단계에서 실행합니다.\n\npip install torch torchvision datasets transformers tokenizers bitsandbytes peft accelerate trl\n\npip install flash-attn\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가져온 것들을 통해 세부 튜닝 프로세스에 필요한 모든 것을 가져오겠습니다:\n\n```js\nimport gc\nimport torch\n\nfrom datasets import load_dataset\nfrom huggingface_hub import notebook_login\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\nfrom trl import SFTTrainer\n```\n\n다음으로, 사용할 모델, 데이터셋 및 Hugging Face 사용자 접근 토큰을 지정하는 일부 변수를 설정합니다. 이 토큰은 Hugging Face 플랫폼과 상호 작용하기 위해 사용됩니다. 모델 및 데이터셋을 다운로드하고 배포하는 데 사용됩니다. 토큰을 생성하려면 https://huggingface.co/에서 무료로 등록하고 계정 설정을 열어 메뉴에서 Access Tokens를 선택하면 됩니다. 이 프로세스에는 세부 튜닝된 모델을 나중에 Hugging Face에 게시할 것이므로 쓰기 액세스 권한이 있는 토큰이 필요합니다.\n\n세부 튜닝을 직접 시도하려면 아래 코드의 자리 표시자를 귀하의 토큰으로 대체하시면 됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 참조: https://huggingface.co/docs/hub/security-tokens\n# 나중에 모델을 푸시하려면 토큰을 작성해야 합니다.\nhf_token = \"여러분의 토큰\"\n\n# https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\nbase_model = \"meta-llama/Llama-2-7b-chat-hf\"\n\n# https://huggingface.co/datasets/Amod/mental_health_counseling_conversations\nfine_tuning_dataset = \"Amod/mental_health_counseling_conversations\"\n\n# 출력 모델의 이름\ntarget_model = \"vojay/Llama-2-7b-chat-hf-mental-health\"\n```\n\n다음 부분을 이해하는 데 중요한 점은 일반적으로 프롬프트가 특정 템플릿을 따르는 여러 요소로 생성된다는 것입니다. 이는 물론 모델 및 llama-2-chat 모델이 Llama 2 논문을 기반으로 다음 형식을 사용하여 시스템 및 지시 프롬프트를 정의함을 의미합니다:\n\n```js\n<s>[INST] <<SYS>>\n{ system_prompt }\n<</SYS>>\n{ user_message } [/INST] { model_response } </s>\n```\n\n이 형식은 처음에는 암호적으로 보일 수 있지만 개별 요소를 살펴보면 더 명확해집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- `s`: 시퀀스의 시작.\n- `/s`: 시퀀스의 끝.\n- `SYS`: 시스템 메시지의 시작.\n- `/SYS`: 시스템 메시지의 끝.\n- [INST]: 지시의 시작.\n- [/INST]: 지시의 끝.\n- system_prompt: 모델 응답의 전반적인 맥락.\n- user_message: 출력 생성에 대한 사용자 지침.\n- model_response: 학습용으로 기대되는 모델 응답.\n\n모델을 훈련할 때는 이 형식을 따라야 하므로, 다음 단계는 적절한 템플릿을 정의하고 이에 맞게 샘플 데이터를 변환할 함수를 만드는 것입니다. 먼저 전체적인 맥락을 만들기 위해 시스템 또는 베이스 프롬프트를 정의하는 것으로 시작합시다:\n\n```js\ndef get_base_prompt():\n    return \"\"\"\n    당신은 지식이 풍부하고 지지력 있는 심리학자입니다. 사용자가 감정적이고 심리적 지원을 찾을 때 공감적이고 비판적이지 않은 응답을 제공합니다. 사용자가 이야기를 나누고 성찰할 수 있는 안전한 공간을 제공하며, 공감, 적극적 청취, 이해에 초점을 맞춥니다.\n    \"\"\"\n```\n\n나중에 이 기본 프롬프트를 다시 사용하여 LLM에 평가 전에 사용자 입력을 보강할 것입니다. 이 문맥에서 프로젝트에 좋은 기회가 될 수 있으며, 기본 프롬프트를 개선하여 LLM이 훨씬 더 나은 반응을 할 수 있도록 할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 해당되는 데이터 훈련 형식을 지정하는 함수를 정의해 보겠습니다:\n\n```js\ndef format_prompt(base, context, response):\n    return f\"<s>[INST] <<SYS>>{base}</SYS>>{context} [/INST] {response} </s>\"\n```\n\n다음은 세밀한 조정 부분 자체인데, 이를 함수로 래핑하여 단계별로 프로세스를 먼저 정의한 다음 노트북의 다음 단계로 실행합니다:\n\n```js\ndef train_mental_health_model():\n    model = AutoModelForCausalLM.from_pretrained(\n        base_model,\n        token=hf_token,\n        quantization_config=BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_use_double_quant=False\n        ),\n        torch_dtype=torch.float16,  # 메모리 사용량 감소\n        attn_implementation=\"flash_attention_2\"  # 텐서 코어(NVIDIA A100)에 최적화\n    )\n\n    # QLoRA 논문을 기반으로 한 LoRA 설정\n    peft_config = LoraConfig(\n        lora_alpha=16,\n        lora_dropout=0.1,\n        r=8,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\"\n    )\n\n    model = prepare_model_for_kbit_training(model)\n    model = get_peft_model(model, peft_config)\n\n    args = TrainingArguments(\n        output_dir=target_model,  # 모델 출력 디렉터리\n        overwrite_output_dir=True,  # 이미 존재하는 출력 덮어쓰기\n        num_train_epochs=2,  # 훈련할 에포크 수\n        per_device_train_batch_size=2,  # 훈련 중 장치당 배치 크기\n        gradient_checkpointing=True,  # 메모리 절약하지만 훈련을 느리게 만듦\n        logging_steps=10,  # 매 10 단계마다 로그\n        learning_rate=1e-4,  # 학습 속도\n        max_grad_norm=0.3,  # QLoRA 논문 기반 최대 그래디언트 정규화\n        warmup_ratio=0.03,  # QLoRA 논문 기반 워링업 비율\n        optim=\"paged_adamw_8bit\",  # AdamW 옵티마이저의 메모리 효율적인 변형\n        lr_scheduler_type=\"constant\",  # 일정한 학습 속도\n        save_strategy=\"epoch\",  # 각 에포크 끝에 저장\n        evaluation_strategy=\"epoch\",  # 각 에포크 끝에 평가\n        fp16=True,  # 메모리 절약을 위해 16비트 정밀도 훈련 사용\n        tf32=True  # 텐서 코어(NVIDIA A100)에 최적화\n    )\n\n    tokenizer = AutoTokenizer.from_pretrained(base_model, token=hf_token)\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.padding_side = \"right\"\n\n    # 메모리 사용량 감소를 위해 샘플 수 제한\n    dataset = load_dataset(fine_tuning_dataset, split=\"train\")\n    train_dataset = dataset.select(range(2000))\n    eval_dataset = dataset.select(range(2000, 2500))\n\n    trainer = SFTTrainer(\n        model=model,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        peft_config=peft_config,\n        max_seq_length=1024,\n        tokenizer=tokenizer,\n        formatting_func=lambda entry: format_prompt(get_base_prompt(), entry[\"Context\"], entry[\"Response\"]),\n        packing=True,\n        args=args\n    )\n\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    trainer.train()\n    trainer.save_model()\n    trainer.push_to_hub(target_model, token=hf_token)\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_11.png)\n\n모든 학습 인수에 주석을 추가하여 설정이 투명하게 되었습니다. 그러나 특정 사항은 학습을 실행하는 환경 및 입력 모델 및 데이터 세트에 따라 다르므로 조정이 필요할 수 있습니다.\n\n과정이 어떻게 작동하는지 자세히 살펴봅시다. AutoModelForCausalLM.from_pretrained를 사용하여 모델을 로드하고 quantization_config를 설정하여 4비트 가중치 및 활성화로 변환하여 성능 측면에서 이점을 제공합니다. attn_implementation을 flash_attention_2로 설정함으로써 모델을 불러옵니다.\n\nFlashAttention-2는 표준 어텐션 메커니즘의 빠르고 효율적인 구현으로, 시퀀스 길이에 대해 어텐션 계산을 병렬화하고 GPU 스레드 간 통신 및 공유 메모리 읽기/쓰기를 줄이기 위해 작업을 분할하여 추론 속도를 크게 높일 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLoraConfig은 Low-Rank Adaptation (LoRA) 프로세스를 구성합니다. lora_alpha는 가중치 행렬의 스케일링 팩터를 제어하고, lora_dropout은 LoRA 레이어의 드롭아웃 확률을 설정합니다. r은 저랭크 행렬의 순위를 제어하고, bias는 편향 용어를 처리하는 방법을 결정하며, task_type은 미세 조정된 모델의 작업을 반영합니다.\n\nLoraConfig를 설정한 후에는 get_peft_model() 함수로 PeftModel을 생성합니다.\n\n준비된 모델을 사용하여 다음 단계는 훈련을 준비하는 것입니다. 이를 위해 모든 주요 훈련 과정을 제어하는 TrainingArguments 객체를 생성합니다. 이 객체는 다음과 같은 항목을 포함합니다:\n\n- output_dir=target_model # 모델 출력 디렉토리\n- overwrite_output_dir=True # 이미 존재하는 출력을 덮어쓰기\n- num_train_epochs=2 # 훈련할 에포크 수\n- per_device_train_batch_size=2 # 훈련 중 디바이스 당 배치 크기\n- gradient_checkpointing=True # 메모리 저장하지만 훈련 속도가 느려집니다\n- logging_steps=10 # 10단계마다 로그 기록\n- learning_rate=1e-4 # 학습률\n- max_grad_norm=0.3 # QLoRA 논문에 기반한 최대 그래디언트 노름\n- warmup_ratio=0.03 # QLoRA 논문에 기반한 워밍업 비율\n- optim=\"paged_adamw_8bit\" # AdamW 옵티마이저의 메모리 효율적인 변형\n- lr_scheduler_type=\"constant\" # 일정한 학습률\n- save_strategy=\"epoch\" # 각 에포크 끝에 저장\n- evaluation_strategy=\"epoch\" # 각 에포크 끝에 평가\n- fp16=True # 메모리 저장을 위해 32비트 대신 16비트 정밀도 사용\n- tf32=True # 텐서 코어(OVIDIA A100)에 최적화된 학습\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이후에는 AutoTokenizer.from_pretrained을 사용하여 모델의 토크나이저를 생성합니다.\n\n다음 단계는 심리 건강 데이터셋을 로드하는 것입니다. 여기서는 샘플 크기를 제한하여 메모리 사용량을 줄이고 학습 속도를 높입니다.\n\n이 모든 작업을 마치면 SFTTrainer를 인스턴스화하여 훈련을 진행하고, 미세 조정된 모델을 저장하고 게시할 수 있습니다. trainer.push_to_hub을 사용합니다.\n\n다음 단계에서는 train_mental_health_model()을 호출하고, 그럼에도 불구하고 마법이 일어나는 것을 간단히 지켜볼 수 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ntrain_mental_health_model();\n```\n\n![Fine-tuned model](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_12.png)\n\n저는 세밀하게 튜닝된 모델을 Hugging Face에 푸시했어요. 따라서 세밀 튜닝 과정을 건너뛰고 싶다면 거기서 모델을 가져올 수 있어요.\n\n![Fine-tuned model](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_13.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기억해 두세요, 이 미세 조정된 모델은 실제로 기본 모델용 어댑터입니다. 즉, 사용하려면 기본 모델을 로드하고 이 미세 조정 어댑터를 적용해야 합니다:\n\n```js\nmodel_id = \"meta-llama/Llama-2-7b-chat-hf\";\nadapter_model_id = \"vojay/Llama-2-7b-chat-hf-mental-health\";\n\nmodel = AutoModelForCausalLM.from_pretrained(\n  model_id,\n  (torch_dtype = torch.float16)\n);\nmodel.load_adapter(adapter_model_id);\n```\n\n## 미세 조정된 모델로 챗봇 만들기\n\n이제 미세 조정된 모델이 준비되었으므로 그것을 활용하는 챗봇을 만들어봅시다. 간단히 유지하기 위해 로컬 환경 내에서 실용적인 CLI 챗봇을 실행합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로젝트 생성 및 종속성 관리 방법을 자세히 살펴보겠습니다. Python에서 종속성 관리와 패키지화를 위한 도구인 Poetry를 사용합니다.\n\nPoetry가 도와줄 수 있는 세 가지 주요 작업은 빌드, 게시 및 추적입니다. 목표는 종속성을 관리하는 결정론적인 방법을 가지고 프로젝트를 공유하고 종속성 상태를 추적하는 것입니다.\n\nPoetry는 또한 가상 환경을 생성하는 작업도 처리합니다. 기본적으로 시스템 내의 중앙 폴더에 있지만, 제처럼 프로젝트 폴더 내에 가상 환경을 원하는 경우 간단한 구성 변경으로 설정할 수 있습니다:\n\n```js\npoetry config virtualenvs.in-project true\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시에란, 새로운 시로 Python 프로젝트를 만들 수 있어요. 시는 가상 환경을 만들고 시스템의 기본 Python과 연결해줘요. 또한 pyenv와 결합하면 특정 버전을 사용하여 프로젝트를 만들 수 있는 유연한 방법을 얻을 수 있어요. 또는 직접 Poetry에게 사용할 Python 버전을 지정할 수도 있어요: poetry env use /full/path/to/python.\n\n새 프로젝트를 만들었으면, poetry add를 사용하여 종속성을 추가할 수 있어요.\n\n이제 우리의 봇을 위한 프로젝트를 만들고 필요한 모든 종속성을 추가하는 것으로 시작합시다:\n\n```js\npoetry new mental-health-bot\ncd mental-health-bot\n\npoetry add huggingface_hub\npoetry add adapters\npoetry add transformers\npoetry add adapters\npoetry add peft\npoetry add torch\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이렇게 하면 당신의 봇을 실행할 코드가 있는 app.py 메인 파일을 만들 수 있어요. 이전과 마찬가지로, 여러분이 직접 실행하고 싶다면, Hugging Face 토큰 자리 표시자를 여러분의 토큰으로 교체해주세요. 이번에는 Hugging Face에서 베이스 모델과 파인튜닝된 모델만 가져오면 되므로 읽기 전용 토큰이 충분합니다.\n\n또 하나 언급할 점은, 저는 다음 환경에서 이 코드를 실행하고 있다는 것이에요:\n\n- Apple MacBook Pro\n- CPU: M1 Max\n- 메모리: 64 GB\n- macOS: Sonoma 14.4.1\n- Python 3.12\n\n성능을 높이기 위해, macOS 장치에서 GPU를 활용하기 위해 PyTorch에 Metal Performance Shaders (MPS) 장치를 사용하고 있어요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndevice = torch.device(\"mps\");\ntorch.set_default_device(device);\n```\n\n또한, 훈련에 사용했던 것과 동일한 기본 프롬프트를 사용할 것입니다. 모든 것을 함께 넣어보면, 이것이 우리 챗봇의 실용적인 CLI 버전입니다:\n\n```js\nimport torch\nfrom huggingface_hub import login\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ndevice = torch.device(\"mps\")\ntorch.set_default_device(device)\n\nlogin(token=\"your-token\")\n\ntitle = \"Mental Health Chatbot\"\ndescription = \"This bot is using a fine-tuned version of meta-llama/Llama-2-7b-chat-hf\"\n\nmodel_id = \"meta-llama/Llama-2-7b-chat-hf\"\nadapter_model_id = \"vojay/Llama-2-7b-chat-hf-mental-health\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)\nmodel.load_adapter(adapter_model_id)\nmodel.to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\n\ndef get_base_prompt():\n    return \"\"\"\n    You are a knowledgeable and supportive psychologist. You provide emphatic, non-judgmental responses to users seeking\n    emotional and psychological support. Provide a safe space for users to share and reflect, focus on empathy, active\n    listening and understanding.\n    \"\"\"\n\n\ndef format_prompt(base, user_message):\n    return f\"<s>[INST] <<SYS>>{base}<</SYS>>{user_message} [/INST]\"\n\n\ndef chat_with_llama(prompt):\n    input_ids = tokenizer.encode(format_prompt(get_base_prompt(), prompt), return_tensors=\"pt\")\n    input_ids = input_ids.to(device)\n    output = model.generate(\n        input_ids,\n        pad_token_id=tokenizer.eos_token_id,\n        max_length=2000,\n        temperature=0.9,\n        top_k=50,\n        top_p=0.9\n    )\n\n    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n    return decoded.split(\"[/INST]\")[1].lstrip()\n\n\nwhile True:\n    prompt = input(\"You: \")\n    response = chat_with_llama(prompt)\n    print(f\"Llama: {response}\")\n```\n\n이제 한번 해봅시다! 다음 챗 입력으로 실행해봅시다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n제 감정과 자신을 다루고 있는 중이에요. 잠을 거의 못 자고 불안과 스트레스로 고통받고 있어요. 약물 복용을 피하면서 대처 전략을 추천해주실 수 있을까요?\n```\n\n실제로 저희가 섬세하게 튜닝된 모델로 답변한 결과가 매우 좋았기 때문에, 이 답변을 여기 인용하고 싶습니다. 이 글에서 정신 건강에 관해 이야기할 때 이겁니다.\n\n🤖 고지사항: 아래 텍스트는 AI가 생성한 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n네, 약을 복용하지 않고 스트레스와 불안을 관리하는 데 도움이 되는 여러 가지 방법이 있습니다.\n\n- 자신을 돌봅시다. 충분히 잠을 자고 올바르게 먹고 운동합시다. 우리가 스스로를 돌보지 않으면 스트레스와 불안을 느끼기 쉬워집니다.\n- 마음을 집중하는 법을 연습합시다. 이것은 자신을 비판하지 않고 순수하게 순간에 집중하는 것을 의미합니다. 마음을 집중하는 것은 우리가 과거를 놓아버리고 미래에 대해 걱정하지 않게 도와줄 수 있습니다.\n- 명상을 연습합시다. 마음을 집중하는 명상은 숨을 집중하고 현재에 집중할 수 있도록 자신을 훈련시키는 방법입니다.\n- 행복을 주는 것에 대해 생각해보세요. 감사할 만한 것들은 무엇인가요? 좋아하는 일은 무엇인가요?\n- 조용한 시간을 가지고 당신의 생각을 기록해보세요. 생각과 감정을 쓰는 것은 스트레스와 불안을 관리하는 데 매우 도움이 될 수 있습니다.\n- 요가, 타이치 또는 심호흡과 같은 형태의 안정 훈련을 연습합시다.\n- 마사지를 받거나 매니큐어를 받는 등 자기 관리의 형태를 연습합시다.\n- 대화할 상대를 찾아보세요. 때로는 누군가와 이야기하는 것이 다른 시각에서 상황을 볼 수 있도록 도와줄 수 있습니다.\n- 상황에서 유머를 찾아보세요. 때로는 웃음소리가 기분을 끌어올리는 데 도움이 될 수 있습니다.\n- 신체 운동의 형태를 연습해보세요. 운동은 더 편안하고 스트레스를 덜 느끼도록 도와줍니다.\n- 집 밖을 산책하고 신선한 공기를 마시세요.\n- 음악을 듣거나 책을 읽는 등 형태의 안정을 연습하세요.\n- 현재 순간에 집중해보세요.\n\n그게 다입니다, 우리만의 AI 기반 정신 건강 챗봇입니다. 이것으로, 당신에게 유익한 조언이 있을지도 모르니, 건강하게 지내시고 다음 챕터에서 어떻게 계속 진행할지 발견해 보세요.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_14.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 해커톤 프로젝트 업그레이드하기: 정신 건강 챗봇을 위한 다음 스텝\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_15.png)\n\n우리가 살펴본 예는 더 발전할 수 있는 훌륭한 기반을 제공합니다. 해커톤 프로젝트를 위한 더 정교한 솔루션을 만드는 몇 가지 방법을 소개합니다:\n\n- 파라미터 조율 프로세스 최적화: LoRA 파라미터와 훈련 구성을 다듬어 챗봇의 성능을 향상시킵니다. 이는 공감적이고 자연스러운 언어 생성으로 이어질 수 있습니다. 또한, Odds Ratio Preference Optimization (ORPO)와 같은 다른 접근 방식을 시도하여 성능을 향상시킬 수 있습니다.\n- 기본 프롬프트 강화: 챗봇이 지지적이고 이해하는 방식으로 응답하도록 장려하는 기본 프롬프트를 만들어보세요. 필요한 경우 전문 도움을 찾도록 사용자를 안내할 수 있는 템플릿을 통합하세요.\n- 검색 증강 생성(RAG) 구현: RAG를 통합하여 챗봇이 사용자 요청을 보강하는 추가적인 맥락을 제공합니다. 이를 통해 더 정보가 풍부하고 관련성 있는 응답을 할 수 있습니다.\n- 간단한 채팅을 넘어 나아가기: 간단한 채팅을 넘어 구조화된 상호작용 모델을 구현하는 것을 고려해보세요. 아마도 인지 행동 요법(CBT) 원칙을 기반으로 한 것일 수도 있습니다. 이는 사용자에게 더 집중된 그리고 잠재적으로 치료적인 경험을 제공할 수 있습니다.\n- 사용성에 집중: 모델 자체를 개선하는 데만 모든 시간과 노력을 집중하는 대신, 프런트엔드 중심적인 접근 방식 역시 채택하여 접근성에 집중하거나 창의적인 상호작용 형태를 사용하여 맞춤형 UI를 만들어 볼 수도 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이런 개선 사항 외에도, 상자 밖을 생각하도록 장려합니다. 심리 건강 지원을 위한 AI 애플리케이션을 개발한다는 것은 가상 상담이나 치료용 챗봇을 만드는 것만을 의미하는 것이 아닙니다. 이 작업에 다른 접근 방법은 스트레스와 같은 정신 건강 문제를 유발하거나 강화하는 측면을 개선하는 방법을 고려하는 것일 수도 있습니다. 만약 우리가 문제를 재정의하여 AI 솔루션을 찾는다고 한다면, 스트레스를 줄이는데 도움이 되는 AI 중심의 개인 맞춤형 명상 지원과 같은 아이디어를 포함하여 초기 문제를 간접적으로 해결하는 많은 아이디어를 떠올릴 수 있습니다. 또 다른 방법은 외상 후 스트레스 장애 (PTSD)와 같은 특정 유형의 정신 건강 문제에 대한 지원에 집중하는 것일 수 있습니다.\n\n적절히 대응된 특정 위험요인이 있다면, 많은 사람들에게 도움이 될 수 있는 기회가 많이 있습니다. 따라서, 2024년 정신 건강 AI 해커톤에서 어떤 눈을 떴다고 생각할만한 솔루션이 만들어질지 기대됩니다.\n\nAI 중심의 애플리케이션 개발에 대한 몇 가지 영감을 드리기 위해:\n\nGoogle Gemini LLM을 사용하여 FastAPI 기반의 진보된 API와 전용 Vue 기반 프론트엔드를 사용하고 싶다면, 이 글을 확인해 보세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 Markdown 형식으로 변경하실 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAI 기반 챗봇은 24시간 365일 제공되는 접근 가능한 정신 건강 지원으로 이 간극을 좁힐 수 있어요. 이 도구들은 사람들이 정신 건강 여정을 시작할 수 있는 안전한 공간을 제공하여, 필요할 때 가장 필요로 하는 때에 도움이 되는 듣는 귀, 유용한 자원 및 기본적인 대처 방법을 제공해줘요.\n\n하지만, 이 분야에서 AI 챗봇의 잠재적인 제약, 윤리적 고려 사항 및 위험을 인지하고 대응하는 것이 중요해요. 인지 행동 요법 (CBT)과 저랭크 적응 (LoRA), 추출-증강 생성 (RAG)과 같은 기술적 해결책과 같이 주제별 접근 방식은 위험을 완화할 수 있지만, 더욱 논의되고 개선되어야 해요.\n\n이러한 발전을 수용하고 윤리적 발전을 우선시함으로써, 이러한 응용 프로그램들은 정신 건강 의료를 민주화하는 강력한 도구로 거듭날 수 있어요. 정신 건강 AI 해커톤 2024는 혁신과 협력을 육성하여, 사용자 안전과 넓은 인구 집단을 위한 정신 건강 지원을 우선시하는 AI 솔루션을 만들기 위한 진보를 지원해요.\n\n이 미래는 우리가 생각하는 것보다 가까워요. 책임 있는 개발과 윤리적 고려를 중시함으로써, 기술이 정신 건강 의료를 혁신하여, 모든 사람에게 매일 접근 가능하게 만들 수 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_16.png)\n\n특히 정신 건강 지원은 중요한 위험과 도전을 안고 있지만, 이러한 위험을 투명하게 만들고 공개적으로 논의함으로써 의미 있는 진전의 길을 열 수 있습니다. 여러분의 아이디어, 경험, 우려, 그리고 해결책에 대해 들어보고 싶습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_0.png"},"coverImage":"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_0.png","tag":["Tech"],"readingTime":42},{"title":"사용자 정의 테이블 함수 UDTF","description":"","date":"2024-05-23 15:41","slug":"2024-05-23-User-definedTableFunctionsUDTF","content":"\n![이미지](/assets/img/2024-05-23-User-definedTableFunctionsUDTF_0.png)\n\nSpark 3.5에서는 파이썬 사용자 정의 테이블 함수(UDTF)를 소개했습니다. 이것은 새로운 종류의 사용자 정의 함수입니다. 스칼라 함수는 각 호출에 대해 하나의 결과를 생성하는 반면, UDTF는 쿼리의 FROM 절 내에서 호출되며 전체 테이블을 출력합니다. UDTF 호출은 스칼라 식이나 완전한 입력 테이블을 나타내는 테이블 인수 중 어떤 것이든 사용할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-User-definedTableFunctionsUDTF_1.png)\n\n## 파이썬 UDTF 사용 이유\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 다양한 행과 열을 생성하면서 파이썬의 다양한 생태계를 활용하고 싶다면, Python UDTF가 이상적입니다.\n\n## Python UDTF 대 Python UDF\n\nSpark의 Python UDF는 입력으로 스칼라 값s 중 0개 이상을 받아들이고 단일 값을 반환하는 것이 설계되어 있습니다. 그에 반해, UDTF는 여러 행과 열을 반환할 수 있어 UDF의 기능을 더 확장시킬 수 있어 더 유연합니다.\n\n## Python UDTF 대 SQL UDTF\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQL UDTFs는 효율적이고 다재다능하지만, Python은 더 다양한 라이브러리와 도구를 제공합니다. 통계 함수나 머신 러닝 추론과 같이 고급 기술이 필요한 변환 또는 계산을 위해서는 Python UDTFs가 특히 유리합니다.\n\n# LangChain과 함께 사용하는 UDTF\n\n이전 예제는 기본적으로 보일 수 있지만, Python UDTFs를 LangChain과 통합하여 더 흥미로운 시나리오를 탐색해 봅시다.\n\n```js\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom pyspark.sql.functions import lit, udtf\n\n@udtf(returnType=\"keyword: string\")\nclass KeywordsGenerator:\n    \"\"\"\n    Generate a list of comma separated keywords about a topic using an LLM.\n    Output only the keywords.\n    \"\"\"\n    def __init__(self):\n        llm = OpenAI(model_name=\"gpt-4\", openai_api_key=<your-key>)\n        prompt = PromptTemplate(\n            input_variables=[\"topic\"],\n            template=\"generate a couple of comma separated keywords about {topic}. Output only the keywords.\"\n        )\n        self.chain = LLMChain(llm=llm, prompt=prompt)\n\n    def eval(self, topic: str):\n        response = self.chain.run(topic)\n        keywords = [keyword.strip() for keyword in response.split(\",\")]\n        for keyword in keywords:\n            yield (keyword, )\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n세부 정보:-\n\n즐거운 학습하세요 🙂 !!!!!!\n","ogImage":{"url":"/assets/img/2024-05-23-User-definedTableFunctionsUDTF_0.png"},"coverImage":"/assets/img/2024-05-23-User-definedTableFunctionsUDTF_0.png","tag":["Tech"],"readingTime":3},{"title":"2023년 업데이트된 성적 데이터로부터 마라톤 성적에 대한 백분위 및 Z 점수","description":"","date":"2024-05-23 15:38","slug":"2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData","content":"\n![image](/assets/img/2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData_0.png)\n\n다른 연령대의 경주 결과를 공정하게 비교하는 방법이 무엇인가요?\n\n그것이 저가 지난 몇 달 동안 연구해 온 질문입니다.\n\n문제는 나이가 모두에게 온다는 것입니다. 어느 순간, 얼마나 열심히 훈련해도 우리는 속도를 줄이기 시작합니다. 시작과 속도는 각기 다르겠지만, 이는 불가피한 일이죠.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n나이 등급의 장점은 다른 연령 그룹 간의 레이스 결과를 비교할 수 있는 방법을 제공하여 마스터 러너들이 경쟁력을 유지할 수 있는 기회를 제공한다는 것입니다.\n\n하지만 이 약속을 지키는 것일까요?\n\n다른 러너들로부터 불만을 들은 적이 있고, 몇 가지 결과를 살펴본 후에 나이 등급에는 몇 가지 결함이 있는 것으로 보입니다. 한 가지로는 일반 러너에 대한 많은 차별을 제공하지 않는다는 점이며, 다른 한 가지로는 충분히 보정되어 있지 않아 몇몇 연령 그룹에 이점을 줄 뿐만 아니라 다른 그룹에는 불이익을 주고 있다는 점입니다.\n\n더 나은 방법이 있을까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 두 가지 대안을 테스트해 보았어요: Z 점수와 백분위수. 2010년부터 2019년까지의 대량의 데이터를 수집하여 이러한 방법을 시도했는데, 특히 백분위수에는 많은 가능성이 있다고 생각했어요.\n\n오늘은 업데이트된 데이터셋으로 돌아와, 각 대안을 다시 살펴볼 거에요.\n\n# 데이터 출처\n\n우리가 작업하는 데이터는 무엇인가요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2023년 미국에서 열린 모든 마라톤 결과를 수집했어요. 이 결과들은 Marathon Guide, Athlinks 및 각각의 레이스 웹사이트에서 스크랩한 개인 성적들로 이루어져 있어요.\n\n이를 통해 약 40만 개인 완주 기록을 얻었어요 — 러너의 나이, 성별 및 완주 시간을 포함하고 있어요. 데이터를 정리하고 잘못된 정보가 있는 몇 개의 레코드를 제외하고 BAA의 자격 취득을 위해 사용되는 연령대로 정리했어요.\n\n결과적으로, 609개의 개별 레이스에서 38만 8,560개의 완주 기록을 얻었어요.\n\n이 데이터 세트에 대한 자세한 내용은 여기에서 확인할 수 있어요. 우리 목적에 맞게 말씀드리자면, 여성 75-79세 그룹은 상대적으로 작다는 점을 언급해드릴게요 (157개 완주). 80대의 러너들이 더 적었기 때문에 이 분석에 포함하지 않기로 결정했어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 2023 자료로 Z 점수 계산하기\n\n결과를 점수화하고 비교하는 한 가지 방법은 Z 점수를 사용하는 것입니다.\n\nZ 점수는 특정 값이 평균보다 얼마나 높거나 낮은지를 측정한 것입니다. 표준화된 측정값이기 때문에 Z 점수는 다른 그룹간에 비교하는 데 사용될 수 있습니다.\n\n반면에 전통적인 연령 등급은 최상의 결과를 기준으로 사용합니다. 각 결과는 해당 최상의 시간과 비교되며 비교용으로 사용될 표준화된 점수가 계산됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nz 점수를 계산하기 위해 Python의 Pandas 패키지를 사용하여 결과를 성별과 연령 그룹으로 그룹화했습니다. 그런 다음, 각 그룹의 평균과 표준 편차를 계산했습니다(초 단위). 마지막으로, 개별 결과에서 평균을 빼고 표준 편차로 나누어 표준화된 점수를 얻었습니다. 음수 값은 점수가 평균보다 낮음을 나타내고, 양수 값은 평균보다 높음을 나타냅니다.\n\n예를 들어, 한 연령 그룹의 평균 완주 시간이 4시 30분이고 표준 편차가 1시간이라고 합시다. 완주 시간이 3시 30분인 경우, 평균 (4시 30분)을 시간 (3시 30분)에서 빼서 -1시간을 얻습니다. 이를 표준 편차 (1시간)로 나누어 z-점수가 -1(평균보다 한 표준 편차 낮음)임을 얻습니다.\n\nz-점수를 사용하는 데 두 가지 잠재적인 문제가 있습니다.\n\n첫째, z-점수는 평균에 기반을 두고 있습니다. 평균은 이상치로부터 영향을 받을 수 있습니다. 특히 작은 연령 그룹에 이상치가 있는 경우 문제가 발생할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n두 번째로, 각 연령 그룹이 평균을 중심으로 비슷한 범위의 가능성을 갖는다고 가정합니다. 표준 편차가 평균과 함께 조정된다면 이는 아마도 사실일 것입니다. 그러나 표준 편차가 평균과 관계없이 비슷하다면 문제가 발생할 수 있습니다.\n\n여기 각 연령 그룹의 평균 완주 시간을 나타내는 그래프가 있습니다. 녹색 점선은 여성을, 주황색 점선은 남성을 나타냅니다.\n\n남성의 결과를 나타내는 곡선은 꽤 깔끔해 보입니다. 이는 교과서 그래프처럼 보이며, 이것이 연령 그룹 간 실제 관계를 대변할 수 있는 것으로 생각됩니다.\n\n하지만 여성의 경우 변동이 더 많습니다. 곡선 형태로 깔끔하게 증가하는 대신 기울기가 자주 변합니다. 아마도 몇 가지 이상치가 평균을 끌어 올리거나 내리는 역할을 하고 있는 것일수도 있습니다 — 또는 그냥 깔끔하게 나타나지 않는 것일 수도 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그런 다음 표준 편차 문제가 있습니다. 각 연령 그룹에서 평균 범위(1:00에서 1:05)에 있습니다. 평균 시간이 4:15인 젊은 남성의 경우, 평균(2:15) 아래로 표준 편차가 두 개 이상 있을 공간이 없습니다. 그러나 5:30의 평균을 가진 노년 여성의 경우, 러너들이 평균을 능가할 여지가 훨씬 많습니다.\n\n위 그래프는 각 연령 그룹별로 평균에서 1, 2 또는 3 표준 편차 아래로 완주한 러너의 비율을 보여줍니다. 드롭다운은 남성과 여성을 전환할 수 있습니다.\n\n여성 중에서는 평균보다 2 표준 편차 아래에서 완주한 여성의 비율이 꽤 안정적입니다. 그러나 평균보다 1 표준 편차 아래에서 완주한 비율은 연령이 들수록 줄어듭니다. 70-74세 및 75-79세 연령 그룹(매우 적음)을 무시하더라도, 더 늙은 러너와 더 젊은 러너 사이에는 차이가 있습니다.\n\n남성의 경우, 상황은 훨씬 안정적입니다. 평균에서 세 표준 편차 이상 낮게 점수를 받는 러너가 거의 없습니다(75-79세를 제외하고), 그리고 분포는 60대 중반까지 모두 꽤 유사합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로, z 점수가 -2, -1, 0, +1, 그리고 +2일 때의 완주 시간에 대한 그래프가 있습니다. 이는 각각의 개인 시간이 어떻게 배치되는지에 대한 아이디어를 제공합니다.\n\n예를 들어, 젊은 남성의 경우 z 점수가 -2인 경우 2:16이고 젊은 여성의 경우 2:39입니다. 여자들에게는 조금 불리한 것 같지만 미친 듯하게 흥분한 것 같진 않아요.\n\n그러나 55-59세에서, 같은 비교를 하면 남성은 2:34이고 여성은 3:03입니다. 여기서는 상황이 좀 더 이상해 보입니다.\n\n55-59세 남성들의 2:34라는 시간은 놀랍긴 합니다. 지난 해 시카고와 보스턴에서 그 나이 그룹의 최고의 남성은 2:35를 뛴 것을 고려하면요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 동안, 해당 연령 그룹의 여러 여성들이 3:03보다 빨리 뛰었습니다. 분명 인상적인 시간이지만 더 이루기 쉬운 시간이죠.\n\n다시 말해, z 점수는 잘 보정되어 있는 것 같지 않습니다. 특히 연로한 나이에서 여성들을 남성들보다 유리하게 만들 수도 있습니다.\n\n# 2023 데이터를 이용한 백분위 계산\n\n결과를 점수화하는 또 다른 방법은 백분위를 사용하는 것입니다. 2010년부터 2019년까지의 데이터를 분석한 결과, 이 방법이 제 선호하는 방법입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n백분위수를 사용하면 다른 모든 선수들과의 성적을 비교하여 특정 시간을 이기는 선수가 몇 퍼센트나 되는지 확인할 수 있어요. 90번째 백분위 수에 있는 선수는 다른 선수들 중 90%보다 빨리 결승선을 통과하죠.\n\n각 연령 그룹이 비교적 경쟁적이라고 가정하면, 특정 백분위에서의 점수를 얻는 것은 대체로 비슷한 난이도라는 거죠. 다만, 문제가 될 수 있는 부분은 만약 어떤 연령 그룹이 경쟁력이 떨어진다면, 더 높은 백분위에서 점수를 얻는 것이 쉬워질 수 있어요.\n\n저는 이전 데이터를 분석하면서 발견한 다른 문제는 백분위가 극단에서는 신뢰성이 크게 떨어진다는 거였어요. 분포의 중간 지점에서는 꽤 잘 작동하지만, 90% 이상부터 몇몇 연령 그룹에서 이상한 결과가 나오기 시작해요. 그리고 99% 이상에서는 대부분의 곡선이 더 뾰족하고 신뢰성이 낮아집니다.\n\n위의 시각화 자료는 백분위 수 표의 세 단계를 거칩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제가 시작했을 때는 0에서 99.99 백분위까지 각 결과를 직접 계산했습니다. 90%에서 99.99% (위 그림 참조)까지 대규모, 젊은 연령 그룹에서 곡선이 상당히 신뢰할 수 있습니다. 하지만 몇몇 부분에서는 뾰족하고 신뢰할 수 없는 것이죠.\n\n이 프로세스의 두 번째 단계에서는 SciPy 패키지를 사용하여 Savitzky-Golay 필터를 곡선에 적용했습니다. 이는 관측된 값들을 더 부드러운 곡선에 적합시키는 역할을 합니다.\n\n마지막으로, 일부 곡선들이 범위의 매우 끝에서 급격하게 감소하지 않는 것을 발견했습니다. 이는 매우 젊은 남성과 비교해 99.9 백분위에서 높은 점수를 받기가 훨씬 더 쉬워진다는 것을 의미합니다.\n\n더 조정하기 위해, 각 연령 그룹과 99백분위에서의 남자 선수 간의 백분율 차이를 찾아 그를 사용하여 각 연령 그룹에 대한 예상 결과를 계산하고 99에서 99.99까지의 각 백분위에 대한 실제 결과와 평균을 계산했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n나이가 들어가면서 고령자 그룹이 끝에서 조금 더 경쟁력 있게 되는 곡선을 효과적으로 내려놓습니다.\n\n위의 시각화 자료는 중앙값(50번째)에서부터 99번째 백분위까지 다양한 백분위에서의 실제 완주 시간을 보여줍니다.\n\n99번째 백분위는 확실히 좋은 시간이지만, 위의 -2 개의 Z점수만큼은 경쟁력이 부족합니다. 최상의 시간에 도달하려면 99% 이상의 십분의 일과 백분의 일을 더 살펴봐야 합니다.\n\n그러나 99% 미만에서는 이는 상당히 공정한 동등한 시간대인 것으로 보입니다. 특히 고령 여성들의 경우 99번째 백분위에서 약간 어긋나는 점이 있습니다. 그러나 대부분의 주자들인 90번째 백분위 이하에서는 비교를 하는 데 꽤 효과적인 방법으로 보입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결과 예시 비교\n\n그래서 실제로 어떻게 보이는지 궁금하시죠?\n\n결과가 세 가지 방법에 따라 어떻게 다른지 확인하기 위해 몇 가지 경주를 살펴보겠습니다.\n\n아래는 2023년 저지 시티 마라톤에서 백분위별로 상위 15명의 완주자 목록이 있는 표입니다. 나는 이 레이스에 참가했지만... 이 상위 15명 목록에는 랭크되지 않았습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n| Gender | Age | Finish   | zScore | Percentile | Age Grade |\n| ------ | --- | -------- | ------ | ---------- | --------- |\n| F      | 25  | 02:32:50 | -2.1   | 99.92      | 87.72     |\n| M      | 27  | 02:17:32 | -1.98  | 99.86      | 88.45     |\n| M      | 25  | 02:18:28 | -1.96  | 99.83      | 87.86     |\n| F      | 39  | 02:45:59 | -1.85  | 99.77      | 83.08     |\n| M      | 30  | 02:22:03 | -1.9   | 99.7       | 85.64     |\n| F      | 23  | 02:43:08 | -1.93  | 99.69      | 82.18     |\n| M      | 25  | 02:23:30 | -1.88  | 99.65      | 84.77     |\n| M      | 26  | 02:23:32 | -1.87  | 99.64      | 84.75     |\n| F      | 55  | 03:17:42 | -1.77  | 99.62      | 79.73     |\n| M      | 27  | 02:24:45 | -1.85  | 99.59      | 84.04     |\n| F      | 30  | 02:46:47 | -1.87  | 99.58      | 80.38     |\n| M      | 50  | 02:47:20 | -1.63  | 99.57      | 80.08     |\n| M      | 41  | 02:36:12 | -1.64  | 99.53      | 80.02     |\n| M      | 27  | 02:26:11 | -1.83  | 99.51      | 83.22     |\n| F      | 27  | 02:48:45 | -1.84  | 99.49      | 79.45     |\n\n여기에는 많은 중복이 있습니다. 선택한 방식에 관계없이 상위 세 명은 동일했을 것입니다. 하지만 25세 여성들은 나이 등급을 사용했다면 세 번째 자리로 밀려났을 겁니다.\n\n그러나 나이 등급으로 상위 15명을 선정하면, 포함된 가장 낮은 나이 등급은 81.63입니다. 따라서 여기에는 79~80 나이 등급을 가진 몇 명의 러너가 포함되었습니다.\n\n백분위를 사용하면, 상위 15명은 남성 9명과 여성 6명으로 구성됩니다. 한편, 나이 등급을 사용하면 남성 11명과 여성 4명으로 구성됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n퍼센타일을 사용하여 상위 마무리자 중 11명이 35세 미만이고 4명이 35세 이상입니다. 나이 등급별로는 상위 마무리자 중 13명이 35세 미만이며 마스터 연령 그룹 출신은 2명뿐입니다.\n\n추가 예로, 여러분에게 2023년 에리 마라톤에서 제주도의 상위 15명 마무리자를 소개해 드리겠습니다.\n\n```js\n| 성별   | 나이 | 마무리 시간 | z 점수 | 백분위 | 나이 등급 |\n|--------|-----|-------------|--------|---------|-----------|\n| 여자   |  36 | 02:49:47    | -1.79  | 99.64   | 79.62     |\n| 남자   |  40 | 02:40:24    | -1.57  | 99.16   | 77.36     |\n| 남자   |  57 | 02:57:29    | -1.62  | 99.16   | 80.09     |\n| 남자   |  57 | 02:59:10    | -1.59  | 98.92   | 79.35     |\n| 남자   |  38 | 02:39:31    | -1.56  | 98.7    | 76.67     |\n| 여자   |  31 | 02:59:23    | -1.67  | 98.51   | 74.74     |\n| 남자   |  43 | 02:45:36    | -1.49  | 98.43   | 76.61     |\n| 남자   |  26 | 02:36:38    | -1.66  | 98.4    | 77.67     |\n| 남자   |  32 | 02:37:31    | -1.64  | 98.27   | 77.23     |\n| 남자   |  59 | 03:04:56    | -1.5   | 98.13   | 78.25     |\n| 여자   |  40 | 03:10:10    | -1.5   | 98.07   | 73.03     |\n| 여자   |  30 | 03:07:44    | -1.53  | 97.36   | 71.41     |\n| 남자   |  46 | 02:55:36    | -1.39  | 97.32   | 73.92     |\n| 여자   |  34 | 03:08:30    | -1.52  | 97.24   | 71.12     |\n| 여자   |  36 | 03:11:34    | -1.46  | 97.18   | 70.57     |\n```\n\n이리는 제시 시티보다 작은 규모의 마라톤이므로 일부 낮은 점수가 상위 15명으로 진입했습니다. 또한 마스터 러너들이 더 잘 대표됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n백분위로 보면 상위 완주자 중 9명이 남성이며, 상위 완주자 중 5명이 35세 미만입니다. 연령별로 보면, 상위 완주자 중 13명이 남성이며, 상위 15명 중 6명이 35세 미만입니다.\n\n최고의 성과를 식별하기 위해 z-점수를 사용했다면, 저지 시티에서 상위 완주자 15명 중 14명과 에리에서 상위 완주자 15명 중 10명이 35세 미만일 것입니다. 이러한 연령 그룹은 가장 낮은 표준 편차를 가지고 있어서 이들이 이점을 가질 것으로 예상됩니다.\n\n# 전체 러너들의 전체 분포에 대비하여 점수 비교하기\n\n마지막으로 살펴볼 점은 최고의 성과가 전체 러너들의 전체 분포를 어떻게 향상시키는지 입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n연령 평가의 전체적인 목적은 마스터 러너들이 계속해서 경쟁할 수 있도록 하는 것입니다. 따라서 모든 러너들의 분포와 정확히 일치하지는 않겠지만, 대략적으로는 비슷해야 합니다.\n\n특정 연령 그룹이 최상위 성적에 전혀 나타나지 않는 경우, 해당 그룹에 편향된 시스템이 있다는 신호일 수 있습니다(어떤 이유로든).\n\n그렇다면 상위 1,000개 성적의 분포를 연령 평가, 백분위수, 그리고 Z-점수별로 살펴본다면 어떤 일이 벌어질까요?\n\n이 그래프에서 파란 막대는 1,000명의 러너 중 특정 연령 그룹의 인원 수를 나타냅니다. 다음 세 개의 막대는 연령 평가, 백분위수, 그리고 Z-점수에 따른 최상위 1,000개 성적 러너의 수를 보여줍니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n드롭다운 메뉴에 유의하세요. 이 메뉴를 사용하여 남성과 여성을 전환할 수 있습니다.\n\n연령 등급은 어떻게 되나요?\n\n35세 미만의 여성들 중 상위 1,000명에 속하는 비율은 그들이 전체 그룹에서 차지하는 비율과 유사합니다. 그러나 35세부터 54세까지, 그들은 명백히 소수입니다. 60세에서 79세 사이에는 반대로 말하면 - 만약 모든 것이 무작위로 분산되어 있다면, 상위 1,000명 중 여성이 더 많을 것입니다.\n\n남성들을 살펴보면, 35세 미만 연령 그룹은 과대표현(368 대 221)되어 있습니다. 40대의 남성들은 약간 소수로 표현되는 것으로 보이며, 그 외의 연령 그룹들은 그리 나쁘지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 백분위수를 사용한다면 어떨까요?\n\n여성의 경우, 모든 연령 그룹이 상당히 잘 대표되고 있습니다. 35세 미만 연령 그룹은 조금 더 일반적이지만(198 대 161), 극단적이진 않습니다. 나머지 연령 그룹들은 모두 무작위 분포와 상당히 유사합니다.\n\n남성의 경우, 상황은 더욱 대표적입니다. 일부 살짝 다른 차이가 있지만, 어느 연령 그룹도 현저하게 과소 또는 과대 표현되어 보이지 않습니다.\n\n한편, Z 점수는 전혀 대표적이지 않습니다. 남성과 여성 모두에게 35세 미만 연령 그룹이 매우 과대 표현되어 있습니다. (65-69세까지의) 대부분의 다른 남성 연령 그룹들은 심하게 과소표현되어 있습니다. 마스터 여성들은 조금 나은 상황이지만, 대부분은 전혀 과소표현되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3개의 방법 중 백분위 점수 산정은 최고 선수의 분포가 러너들 전체 분포와 가장 유사합니다.\n\n# 결론 및 앞으로의 방향\n\n2023년 데이터를 분석한 결과 - 나이에 따라 변하는 보스턴 예선 시간을 포함한 이 기사를 읽은 후에도 나이 등급 시스템이 업데이트가 필요하다고 확신합니다.\n\n여성을 중심으로 보정에 문제가 있어 몇몇 그룹을 다른 그룹보다 우대하는 것이 있습니다. 그리고 80세 이상 나이 등급 점수를 받는 사람들의 경우는 소수에 불과하기 때문에 많은 차별적인 기능을 제공하지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n원래 2010년부터 2019년까지의 데이터를 사용하여 백분위수를 계산했을 때, 교정 문제가 있었습니다. 하지만 이 분석의 최종 결과는 더 균형을 이루는 것 같아요.\n\n여러 선수들이 99번째 백분위수 이상을 얻는 경우에는 절대 최고의 성적을 결정하는 최선의 방법이 아닐 수도 있지만, 평균 이상의 선수들을 비교하는 데 훨씬 나은 방법입니다.\n\n다음은 무엇일까요?\n\n지금 데이터 탐색과 분석을 마쳤으니, 이를 좀 생각해볼 시간을 갖고 싶어요. 생각을 정리한 후에 기존 연령 등급 및 백분위수의 장단점을 제시한 마지막 기사를 준비할 거예요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n한편, 2023 연령 요소, z-점수 및 백분위를 활용한 연령 계산기를 업데이트할 예정이며, Kaggle에 데이터셋을 공유할 준비도 하고 있어요.\n\n최종 기사에서 업데이트된 계산기와 공개 데이터셋 링크를 꼭 포함할 거니까, 관심 있으시면 이메일 업데이트를 구독해주세요.\n\n이번 주말에 보스턴에서 참가하는 모든 분들에게 행운을 빕니다! BAA가 발표하면 숫자들을 분석하고, 다음 주에 흥미로운 정보를 공유할 거에요.\n\n저는 열정적인 러너이자 데이터 애호가에요. 방금 40살이 되었어요, 그래서 연령 그룹 간 결과를 비교하는 것이 나에게 특히 흥미롭답니다. 제 활동을 계속 지켜볼 수 있는 방법은 다음과 같아요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 러닝 위드 락 팔로우해서 내 훈련 소식 듣기\n- 마라톤 훈련 계획 선택에 대한 팁 읽기\n- Strava에서 나를 스토킹하기\n","ogImage":{"url":"/assets/img/2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData_0.png"},"coverImage":"/assets/img/2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData_0.png","tag":["Tech"],"readingTime":17}],"page":"58","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}