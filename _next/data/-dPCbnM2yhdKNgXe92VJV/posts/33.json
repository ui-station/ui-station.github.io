{"pageProps":{"posts":[{"title":"원격 개발, 또는 메인프레임을 사랑하게 된 방법","description":"","date":"2024-06-19 12:50","slug":"2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe","content":"\n![2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_0](/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_0.png)\n\n리모트 서버에서의 개발은 생각보다 어렵지 않습니다. 사실 저렴한 VPS 도플릿이나 클러스터를 사용하는 것은 로컬 이진 해석기를 여러 개 사용하거나 Mac용 Docker를 사용하는 것보다 미쳤다고 할 정도의 혜택이 있습니다.\n\n2022년 업데이트: 요즘에는 님버스(Nimbus)만 사용합니다.\n\n여기에서 한 발 더 나아가서, 컨테이너 중심 환경에서 어떻게 작업하는지 배워보겠습니다. 여기서 우리는 완전한 네이티브 리눅스 성능과 17시간 배터리, 그리고 제로 팬 소음을 얻을 것입니다. 우리는 작은 도플릿 VPS를 임대하고, VSCode 및 JetBrains의 IntelliJ Idea CE를 통해 원격 개발 환경을 설정할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n항상 글이 너무 길어서 연구 과정을 이야기하는데, 읽기 싫다면 \"클라우드에서 로컬 개발 환경을 실행하세요. 생각한 것만큼 어렵지 않습니다\" 라는 것만 기억해 주세요. 여기에 목차가 있습니다:\n\n- 🐳 개발에서의 Docker\n  — Swapping and swinging\n  — Docker For Mac을 포기한 이유\n  — Parallels 모험\n- 💻 개발에서 얇은 클라이언트의 경우\n  — 가격\n  — 성능\n  — 학습 기회\n- 🛰 원격 개발 서버 설정\n  — 보안에 대한 메모\n  — 자동 생성\n- 🌍 원격 개발 기능이 있는 코드 편집기\n  — 서버에 액세스하기 위해 VSCode Remote 사용\n  — 원격 서버와 함께 JetBrains Projector 사용 방법\n\n# Docker에서 개발\n\n생산 환경에서 컨테이너를 사용하도록 설득하려고 하지 않을 것입니다. 그것은 이미 너무나 당연한 일입니다. 여기서 제가 살펴보고 있는 것은 Docker가 팀의 통합성과 생산성에 미치는 흔히 언급되지 않은 영향입니다. - 맥에서의 개발용 Docker.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n몇 년 전, 저는 꽤 큰 기업에서 꽤 큰 핵심 제품을 다루는 다양한 시니어도 함께하는 30명의 엔지니어 팀을 이끌었습니다. 시험적인 프로젝트로 Docker를 우리 프로덕션 환경에 (조심스럽게) 도입하는 것을 맡게 되었습니다.\n\n![이미지](/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_1.png)\n\n대부분 사람들이 Docker에 대해 이야기할 때, 그것이 프로덕션에 미치는 이점에 대해 얘기를 합니다. 그러나 누구도 팀에 어떤 영향을 미치는지에 대해 이야기하지 않습니다. 저는 개발에서 그것이 효과적이라는 것을 직접 경험했습니다. 오늘날 이것은 모든 개발자가 이해하고 사용해야 할 중요한 도구로 간주합니다.\n\n- 팀 내에서 평등화 작용을 합니다. 주니어들이 스택의 나머지에서 덜 고립되게 합니다. 시니어들은 이국적인 설정을 할 수 없습니다. 모두가 전체 스택을 더 잘 이해하고 덜 두려워하며 실험에 더 열려지게 됩니다.\n- 모든 엔지니어들에게 로컬을 프로덕션과 같은 환경으로 생각하도록 강제시킵니다. 어떤 꼼수도 허용되지 않습니다.\n- 설정 및 문서화를 추상화합니다. 앱 자체에 집중할 수 있게 합니다.\n- 그 결과, 공유된 비밀 및 데이터베이스 관리가 더 이상 yaml 파일을 잔뜩 다루고 구성 관련 문제를 처리하는 수동 작업이 아니었습니다.\n- 코드 편집기, 린터, 테스트, 종속성은 모두 애플리케이션과 같은 런타임에서 실행됩니다.\n- 로컬에서 많은 프로젝트를 한꺼번에 처리하기 쉬워졌습니다. 다른 팀의 엔지니어도 참여할 수 있습니다. 더 많은 협업, 멤버 교체 및 상호 교류가 이루어집니다.\n- 이제 코드 리뷰에 로컬 체크아웃, 테스트 실행 및 심지어 QA까지 포함됩니다.\n- 프로그램 코드 또는 설정 변경, 프로덕션 업그레이드 또는 잘못된 에셋 배치와 같은 지저분한 실천 방지합니다.\n- 그리고 더 많은 이점들이 있습니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n코드베이스의 일부로 최상위 레이어 또는 인프라를 유지하는 것은 모든 이해 관계자에게 도움이 됩니다. 이 방법으로 도구들을 서로 분리시키고 팀이 설정을 자유롭게 실험하고 매우 빨리 반복할 수 있게 합니다.\n\n저에게는 개발/운영 일치성은 인프라, 구조 또는 설정을 자유롭게 변경하고 장애 없이 배포할 수 있는 것을 의미합니다. 자동화된 다양한 테스트와 CI 파이프라인이 환경별로 동일한 동작을 할 것이라는 확신을 줍니다.\n\n내게 첫 번째 \"자랑스러운 아빠의 순간\"은 프론트엔드 엔지니어가 PR을 만들었을 때 발생했습니다. 거기에는 몇 가지 복잡한 빌드/자산 폴더와 모든 관련된 셸 스크립트를 스스로 이동했습니다. 그들이 한 해 전에 시도조차 하지 않았던 단계였습니다.\n\n이제 그들은 자신만의 스택을 소유하고 자랑스러워합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n어쨌든, Docker가 좋은 성과를 냈습니다. 회사에서는 오늘날까지도 사용하고 있고, 제가 더 이상 그곳의 일원이 아니더라도, 그들이 널리 도입할 계획을 세우고 있다는 소식을 듣고 기뻤습니다.\n\n[![이미지](/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_2.png)](이미지 주소)\n\n## 교체와 전환\n\n2021년에 대한 영감을 줄만한 재미있는 전쟁 스토리 시간입니다...\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n언젠가 오래 전에, 교수 블라디미르 렐리카닌은 저희 반에게 Git과 MAMP 환경 설정에 대해 가르치고 계셨어요. 농담으로 무언가 말씀하셨는데, 오늘까지 기억나는데요: \"새 컴퓨터에 앉아서 30분 이내에 완전히 설정이 되고 코딩을 시작하지 못하면 시간을 낭비하는 거예요. 무언가가 잘못되었다는 신호에요. 아마도 스택을 이해하지 못하고 있다는 거죠\".\n\n이제는 2021년인데, 5분 이내로 처리하고 싶네요. 그보다 더 빨리요.\n\n오래된 멘토이자 친구인 보리스 체라닉은 /Sites 폴더 전체를 Dropbox에 보관했어요. 이렇게 하면 모든 컴퓨터에서 단순히 모든 변경 사항이나 편집기 구성을 빠르게 반영할 수 있었죠.\n\n이제는 2021년이고, VPN과 SSH 키 뒤에 코드를 보관하는 게 더 좋을 것 같아요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2016년에는 3D 및 VR 작업을 많이 수행하는 회사에서 일했습니다. 제 동료 Kole는 모든 것을 Dropbox에 보관했습니다. 만약 그가 강력한 컴퓨터가 필요한 프로젝트를 작업 중이었다면, 그는 그냥 Cmd+S를 눌러 더 강력한 데스크탑으로 전환할 수 있었습니다.\n\n이제 2021년이 되어서 필요할 때 VPS의 규모를 확장하는 것이 더 좋습니다.\n\n## Docker For Mac을 버리게 된 이유\n\n내 30명의 엔지니어 팀을 기억하시나요? 모두에게 불행한 일이 되어버렸는데, Docker가 관련된 경우 Mac에서 코딩하는 성능과 일반적인 사용성에 만족스럽지 못했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n숙고하며 구멍 속으로 들어갈수록 더 어둡기만 했어요. 때로는 정말로 돌아갈 길이 없는 것 같아서 막막했죠. 회사로서는 200대의 우분투 컴퓨터를 사서 관련된 모두에게(그들의 코드베이스도 포함하여) 스위칭하는 법을 가르쳐야 했어요.\n\n저는 이 시리즈의 이전 두 부분에서 보았던 것처럼 문제를 해결할 방법을 찾았어요. 그러나 동시에, 제 우리가 부족한 도구로 인해 얼마나 많은 엔지니어링 에너지와 시간을 소비하는지를 더욱 명확하게 깨달았어요. 이제 저는 절대적으로 확신을 가지게 되었어요. 모든 도구, 편집기, 코드베이스, 이진파일을 반복가능하게(그리고 확장 가능하게) 설정하는 쉬운 방법이 있다면, 저희의 속도를 최소 30% 이상 높일 수 있을 것이라고, 그 영향이 학습과 멘토링에 미칠 효과가 시간이 지남에 따라 나타날 것이라고 확신합니다.\n\n회사에서 새로운 도구를 챔피언하는 것은 수월해야 해요. 이전 시스템보다 훨씬 좋아야 해요. 그 차이가 명확해야 해요. 그 이유가 널리 이해되어야 해요. Docker for Mac을 저희 팀에 도입하는 것은 이런 것들 중 한 가지도 아니었어요.\n\n## Parallels 모험\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n대처 전략 중 하나(파트#2에 개요되어 있음)은 D4M을 제거하고 새로운 도커 컨텍스트를 위한 하이퍼바이저로 Parallels VM을 사용하는 것이었습니다. 이를 통해 우분투용으로 개발된 Parallels 팀이 여러 해 동안 개발한 모든 멋진 최적화 기능을 활용할 수 있었습니다.\n\n이로써, 우리는 어떤 꼼수도 쓰지 않고 작동하는 도커를 가지게 되었고, 개발/프로덕션 둘 간의 일치성을 되찾았습니다. 성능은 거의 네이티브 수준이었고, 대표적으로 어려운 Symfony 캐시나 노드 모듈 폴더에 대한 완전한 동기화에도 그랬습니다.\n\n이 모두를 고려할 때, 우리는 코드를 VM에 유지하고, 그곳에서 실행시키며, 우리 컴퓨터와 동기화시키고 있습니다. 호스트에서 코드 편집기를 실행하고 있습니다. 도커 컨텍스트, DNS, 포트 포워딩, 원격 해석기와 같은 기교를 사용합니다. SSH와 HTTP를 통해 그것과 소통합니다. VM은 우리 호스트 관점에서 원격 머신입니다.\n\n그러므로 한 가지 의문이 제기됩니다 — 이미 많은 어려움을 겪고 이러한 모든 도구를 사용하고 있는데, 왜 우리는 VM을 완전히 제거하지 않고 그냥 그것을 원격 위치로 보내고, 멋지고 강력한 곳에 연결하여 같은 도구를 사용하지 않는지요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_3.png\" />\n\n# 개발에서 얇은 클라이언트 사용 사례\n\nMVP 시간이네요! DigitalOcean에서 가장 저렴한 드롭렛을 구입했고, SSH 키를 만들고, 몇 개의 Elixir 저장소를 다운로드하고 그들의 도커 프로젝트를 시작했어요. 좋아, 예상대로 잘 작동했어요, 이제 뭘 해야 할까요?\n\n빠르게 VSCode 인스턴스를 SSH를 통해 드롭렛에 연결하고 원격 폴더를 선택했어요. 코드를 편집하고 페이지를 다시로드했어요. 좋아, 충분히 잘 작동하네요, 예상대로요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_4.png)\n\n## 가격\n\n원격 개발 방법의 가격은 노트북을 구매하는 것과 비슷합니다. 시장에서 절대 최고의 노트북을 구할 수 있습니다 — 저렴한 M1 MacBook Pro. 프로젝트 및 팀 구성원에 따라 다르지만, 약 500달러에서 1500달러 정도를 절약했습니다.\n\n이제 드롭렛이나 EC2 인스턴스를 임대하고, 매월 15달러부터 50달러까지 지불합니다. 업타임만 지불한다면 훨씬 적게 지불할 수 있습니다. 그래도 가장 비싼 것을 가정해보면, 50달러입니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래서, 우리가 처음으로 저축한 돈은 이제 VPS 공급업체에 매월 작은 지불로 연중에 걸쳐 분할될 것입니다(절대 최악의 경우).\n\n일년이 지나가고, 혹은 두 해, 혹은 석 년이 지나가도 여전히 지출이 급증하지 않고 사람들은 새로운 컴퓨터가 필요하지 않습니다. Mac은 능력을 유지하는 시간으로 유명합니다. 더 심각한 프로젝트를 마주했나요? 그러면 드롭렛을 확장하세요!\n\n## 성능\n\n내 현재 노트북은 BTO MacBook입니다. 미친 듯이 $4000에 가까운 가격을 태웠죠. 원격 개발 세계에서, 저는 배터리가 오래 가고 열이 덜 발생하는 $900의 M1 기계와 제 노트북보다 훨씬 강력한 드롭렛을 구입했습니다. $3000 할인으로 더 나은 두 가지 도구를 얻었습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_5.png)\n\n물론 어느 기준에서도 인상적한 160GB의 RAM과 40개의 CPU 코어로 확장 가능한 드롭렛이 있습니다. 30분 안에 ML을 훈련해야 한다면, 그 유명한 Turbo 버튼을 눌러 몬스터 드롭렛을 생성해보세요.\n\nEC2 인스턴스는 심지어 더 나은 성능을 자랑합니다 (다만 관리하고 예측하기 어려울 수 있습니다). GPU 최적화된 작업 부하를 사용하거나 운영 업무 시간을 기준으로 청구 금액을 절약할 수 있는 매우 구체적인 인스턴스를 사용할 수 있습니다.\n\n숙련도가 충분하다면 기존 k8s 클러스터에 연결하고 이미 사용 가능한 다른 서비스를 사용할 수도 있습니다. 이에 대해 자세히 모르지만 Telepresence와 같이 해당 목적에 맞춘 특수 도구가 있다는 것은 여러해 전부터 알고 있습니다. 그렇지 않으면 DigitalOcean 관리 클러스터를 생성해보세요. 1클릭/무난한 작업으로 간단합니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_6.png\" />\n\n요즘에는 제 노트북 CPU 사용량이 항상 20%를 넘지 않고 온도도 34도에서 안정적으로 유지되고 있어요. 이제 무리없이 무릎 위에 올려두고 사용할 수 있고, 한 번도 충전기를 꽂지 않고도 하루 종일 일할 수 있어요. 개발 활동보다 크롬이 더 많은 배터리를 소비하니 (광고: 그래서 저는 Safari를 사용하는 것을 추천해요).\n\n<img src=\"/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_7.png\" />\n\n## 학습 기회\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n어떤 사람들은 주니어들이 이것을 받아들이기가 어려울 것이라고 할지도 모릅니다. 하지만 제 경험상 시니어 개발자들이 저항을 표했지만, 주니어들은 실제로 아주 빨리 이해했어요. 그들은 CLI 사용에 조금 더 배워야 할 수도 있고, 때로는 전체 서버를 망칠 수도 있지만 — 그러니까 뭐요? 로컬 머신과는 다르게, 새로운 서버를 생성하고, 단 둘만에 다시 트랙에 올라갈 수 있어요.\n\n그리고 이것은 엄청난 학습 기회입니다. 모든 형태와 크기의 개발자들이 실제 서버에서 운전대를 잡게 될 거예요! 그들은 SSH 사용하는 법, 자신의 코드가 어디에 저장되어 있는지, docker가 그에 어떻게 맞는지 등을 이해하게 될 거예요.\n\n이것은 어떤 사람들에게는 그렇게 중요하지 않아 보일 수 있지만, 저는 프론트엔드 개발자가 이 개념을 이해하는 것이 코드 페어링 워크샵보다 크로스폴리네이션 전략으로서 더 가치 있다고 주장할 거예요. 그리고 한 번만 배우면 돼요.\n\n# 원격 개발 서버 설정하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n업데이트 16.11.2021: 이후로 저는 새로운 워크박스를 생성해야 할 때 사용하는 Readme 파일을 조금 작성하기 시작했습니다. 언젠가는 자동화할 거지만, 지금은 매우 대략적인 Readme.md를 제공해요.\n\n제가 좋아하는 것은 간단함입니다. DigitalOcean 패널에 접속하고 새로운 드롭렛을 생성하세요. 최신 Ubuntu나 다른 것들 중 마음에 드는 것을 선택하세요. 지불할 크기를 선택하세요. 요즘에는 일반적으로 4 CPU 사이즈를 사용하지만, 실제로는 조금 과잉이에요.\n\n![이미지](/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_8.png)\n\n한 달에 20달러에 2 CPU는 꽤 좋은 거래에요. 충분한 RAM이 있어서 yarn 설치가 영원히 걸리지 않거나, 의존성 트리 계산 중에 Garbage Collection 한계에 부딪혀서 compose 설치가 실패하지 않아요. 여분의 돈이 있다면, 8GB/4CPU 설정을 추천합니다. 그 가치가 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가장 가까운 데이터 센터를 선택해주세요. 지연 시간은 별다른 문제가 없지만, 왜 안 하시겠어요! 옵션이 제공된다면 SSH 키와 모니터링을 삽입해주세요. 귀여운 이름을 지어서 만들어보세요!\n\nSSH를 통해 VPS에 액세스하고, SSH 키를 생성하여 GitHub 계정에 추가해주세요. 귀하의 저장소를 복제할 수 있어야 하므로 GitHub에 추가해야 합니다.\n\n패키지 목록을 업데이트하고, 시스템을 업그레이드하고, git, zip, docker 및 docker-compose와 같은 일반 소프트웨어를 설치해주세요.\n\n## 보안에 대한 참고사항\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n설정 중에 SSH 키를 추가하지 않았다면, 구글링해보세요. DigitalOcean에는 그것을 하는 방법과 비밀번호 인증을 비활성화하는 방법에 대한 많은 자습서가 있어요.\n\n이 목적으로 root 사용자를 사용하는 것을 좋아해요. 이것이 금기시되고 표식화된 주제라는 것을 알지만, 특정 사용 사례에서 여기서 더 이상 나아가는 필요성은 전혀 없어요. 기억하세요, 이 특정 기계는 아무것도 실행하지 않으며 공개적으로 접근할 수 없어요.\n\n블로그 글 등의 리소스가 있는데 이들은 이러한 서버를 공급하고 제품 서버를 보호하는 방식과 동일하게 보호합니다.\n\n저의 겸손한 의견으로는 이는 필요하지 않아요. SSH 키가 충분한 보호가 될 거에요 (안전하게 보관한다면요). 누군가가 HTTP로 공격하거나 스크랩을 하길 우려한다면, ufw에서 IP 주소를 화이트리스트에 추가하세요. 회사로서 이것을 읽는다면, 아마도 이미 회사 VPN을 가지고 계실 텐데, DigitalOcean에서 사설 네트워크를 생성하세요. 이에 대해 여전히 걱정이 된다면, DigitalOcean에 몇 가지 아이디어가 있는 것 같아요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 자동 생성물\n\nDO에는 HTTP API, 테라폼 지원 및 심지어 앤서블 스크립트 지원이 있습니다. 회사나 기업에서 이 워크플로우를 다루고 있다면, 이 시점에서 기본 스냅샷 이미지를 만들고 필요할 때마다 작은 드롭릿을 생성합니다.\n\n사실, 휴가를 떠날 때 계획할 때는 비슷한 프로세스를 수행합니다. — 머신의 스냅샷을 만들고, 그런 다음 파괴합니다. 이렇게하면 보관할 수 있고, 비용을 지불할 필요가 없습니다.\n\n# 원격 개발 기능이 있는 코드 편집기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2021년이고 편집기들이 이 필요성을 알아보기 시작했다. 언제나 그래왔듯이, 오래된 학교의 편집기인 emacs와 vim은 이미 기본 설정으로 이 설정을 지원한다. 왜냐하면 그들을 droplet이나 컨테이너 내에서 실행할 수 있기 때문에 이 설정에 이미 액세스할 수 있다고!\n\n최근 편집기들로 넘어올 때 (나는 아주 늦게 채택했기 때문에 냉소적인 미소를 짓는 중), VSCode를 사용하는 것을 권할 것이다. 원격 편집 기능이 있고, 그 주변의 전체 아키텍처가 내가 하는 일에 더 적합하다.\n\n## 서버에 액세스하려면 VSCode 원격 사용\n\nVSCode에는 내장된 \"원격 컨테이너에 연결\" 기능이 있습니다. 이 기능은 실제 편집기를 생성하고 컨테이너 내의 네이티브 인터프리터와 직접 작업할 수 있게 해줍니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 할 일은 VSCode를 사용하여 원격 VPS에 SSH 워크스페이스로 연결하는 것입니다. .vscode/workspace.code-workspace 위치에 새 파일을 만들어 해당 폴더를 여러 프로젝트의 루트로 정의해야 합니다. 여기에는 표준 vscode 설정을 포함할 수도 있습니다. 예시는 다음과 같습니다:\n\n```js\n{\n \"folders\": [\n  {\n   \"path\": \"..\"\n  }\n ],\n \"settings\": {\n  \"remote.autoForwardPorts\": false,\n  \"workbench.editor.labelFormat\": \"medium\",\n  \"workbench.colorCustomizations\": {\n   \"activityBar.activeBackground\": \"#1f6fd0\",\n   \"activityBar.activeBorder\": \"#ee90bb\",\n   \"activityBar.background\": \"#1f6fd0\",\n   \"activityBar.foreground\": \"#e7e7e7\",\n   \"activityBar.inactiveForeground\": \"#e7e7e799\",\n   \"activityBarBadge.background\": \"#ee90bb\",\n   \"activityBarBadge.foreground\": \"#15202b\",\n   \"statusBar.background\": \"#1857a4\",\n   \"statusBar.foreground\": \"#e7e7e7\",\n   \"statusBarItem.hoverBackground\": \"#1f6fd0\",\n   \"statusBarItem.remoteBackground\": \"#c92121\",\n   \"statusBarItem.remoteForeground\": \"#d3d3d3\",\n   \"titleBar.activeBackground\": \"#1857a4\",\n   \"titleBar.activeForeground\": \"#e7e7e7\",\n   \"titleBar.inactiveBackground\": \"#1857a499\",\n   \"titleBar.inactiveForeground\": \"#e7e7e799\"\n  }\n },\n \"extensions\": {\n  \"recommendations\": [\n   \"hashicorp.terraform\",\n   \"ms-azuretools.vscode-docker\",\n   \"eamodio.gitlens\",\n   \"k--kato.intellij-idea-keybindings\",\n   \"mutantdino.resourcemonitor\",\n   \"ow.vscode-subword-navigation\",\n   \"redhat.vscode-yaml\",\n   \"mikestead.dotenv\",\n   \"ms-vscode-remote.remote-containers\",\n   \"ckolkman.vscode-postgres\",\n   \"mohsen1.prettify-json\",\n   \"buianhthang.xml2json\"\n  ]\n }\n}\n```\n\n여기서 터미널에 액세스하여 프로젝트를 클론하거나 시작할 수 있습니다. 그러나 여기에서는 편집을 진행하지 않습니다. 편집은 컨테이너 내부에서 수행됩니다.\n\n컨테이너화된 앱을 시작하고, 쉘 파일, 도커 또는 도커 컴포즈가 됐던, 실행 중인 컨테이너에 \"Attach to a Running Container\" 기능을 사용하여 편집을 원하는 런타임을 포함한 컨테이너를 선택합니다. 이렇게 하면 해당 프로젝트가 있는 새 창이 열리며, 해당 프로젝트의 모든 설정과 린트가 표시됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nVSCode는 표준 .vscode 구성 파일에서 내린 모든 결정을 존중해줍니다. 그래서 보통처럼 자유롭게 사용할 수 있어요! 이러한 파일들은 일반적으로 프로젝트 내부에 커밋되어 프로젝트에 대해 모든 팀 멤버가 동일한 규칙과 에디터 설정을 사용하도록 보장합니다. 의존성과 규칙을 추가하는 방법을 아래 예시를 참고하세요:\n\n```js\n$ cat .vscode/extensions.json\n{\n    \"recommendations\": [\n        \"jakebecker.elixir-ls\",\n        \"pgourlain.erlang\",\n        \"mutantdino.resourcemonitor\",\n        \"mikestead.dotenv\",\n        \"eamodio.gitlens\"\n    ]\n}\n```\n\n제 편집 작업 흐름이 어떻게 보이는지 빠르게 살펴볼까요? 이를 비디오로 설명하는 게 조금 더 쉽겠지만, 괜찮으시겠지요?\n\n이것이 저에게 다른 프로젝트를 이동하고 시작하고 중지하고 파일을 이동하며 도트파일, 설정 파일 또는 컨테이너를 만드는 매우 좋은 방법을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금은 docker-compose를 통해 프로젝트를 시작할 수 있습니다. 서로 다른 편집기 창을 서로 다른 컨테이너에 연결할 수 있습니다.\n\n프로젝트 특정 창에서는 해당 런타임과 파일 시스템에 대한 접근이 가능합니다. 이는 편집기 내의 모든 린팅 및 구문 분석이 동일한 런타임으로 수행된다는 것을 의미합니다. 저는 호스트 머신이나 VPS에 node를 로컬로 설치하지 않았습니다. Intellisense가 정상적으로 작동합니다.\n\n원한다면 두 런타임을 동일한 컨테이너에 유지할 수 있습니다. 하지만 저는 이들을 분리하는 것을 강력히 권장합니다.\n\n재미를 위해, 동일한 VPS에서 동시에 다른 클라이언트를 위한 완전히 다른 프로젝트를 시작해 보죠. 해당 프로젝트는 elixir로 실행되며 다른 컨테이너나 그들의 런타임에 대해 전혀 알지 못합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이는 VSCode 창마다 실제로 각 프로젝트 및 해당 런타임에 대해 매우 특화되고 간소화되어 있다는 것을 의미합니다. 각각이 서로 다른 설정(색상도 다름)을 가지고 있으며, 프로젝트의 로컬 .vscode 파일을 준수하고 서로 다른 일련의 확장 기능이 실행됩니다. Out of the box.\n\n## 원격 서버와 함께 JetBrains Projector를 사용하는 방법\n\n업데이트: 이 방법은 더 이상 진행하지 않기로 결정했습니다. macOS에서는 키 바인딩이 때때로 랜덤하게 작동하지 않는 것 같은 버그가 발생합니다.\n\nJetBrains는 다른 아이디어를 가지고 있습니다. Docker 컨테이너 내에서 편집기를 생성한 다음, Projector 앱이나 브라우저를 사용하여 연결하는 방법을 허용합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n편집기는 프로젝트의 컨테이너 내에서 실행되지 않습니다. 대신 호스트에서 실행되며 호스트의 파일시스템 개요에 액세스할 수 있습니다. VPS에 직접 이진 파일로 설치하거나 Docker를 통해 별도의 컨테이너로 생성할 수 있습니다.\n\n여기서의 작업 흐름은 드롭렛에 연결하여 프로젝트를 시작하고, Docker 컨테이너 기반 편집기를 시작하는 것입니다. 모든 파일이 VPS 호스트와 동기화되어 있기 때문에 편집기는 VPS 파일 시스템에서 파일을 편집할 수 있습니다.\n\n그러나 JetBrains는 원격 인터프리터 사용을 가능하게 하는 데 많은 투자를 했기 때문에 모든 \"두꺼운\" 편집기가 원격 컨테이너 내에서 실행 중에 실행을 사용할 수 있습니다. 이는 편집기가 앱 실행과 동일한 런타임을 사용할 수 있는 능력이 있음을 의미합니다. 편집기는 컨테이너에 연결하고 편집기가 수행하는 컴파일에 대한 실행 시간을 사용할 수 있게 됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Example image](/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_10.png)\n\n상상할 수 있겠지만, 이 방법에는 몇 가지 단점이 있습니다. 관리하기 어려울 뿐만 아니라 개발자가 코드를 컨테이너를 먼저 보는 관점을 보는 것만큼 깔끔하지 않습니다. 그러나 이 접근 방식은 로컬 에디터에서 했던 것과 매우 비슷합니다.\n\n저는 JetBrains 제품을 오랫동안 사용해왔습니다. 그들이 얼마나 부피가 크고 압도적인지 항상 싫어했지만, 동시에 PHP, Ruby, Java 또는 Python을 다룰 때에는 더 좋은 IDE가 없다는 것을 직접 경험했습니다. 그러나 지난 몇 년간 특히 Python 및 PHP에서는 VSCode로 점점 더 많이 기울어졌습니다. 제 기능을 잃는 것이 어떻게든 개발의 용이성으로 보상된다는 점 때문입니다.\n\n따라 주셔서 감사합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저에게 귀하의 생각을 듣고 싶습니다. 완벽하지는 않지만, 지금까지 만들어본 최고의 설정입니다.\n\n배포하기 쉽고, 확장하기 쉽고, 파괴하기 쉽고, 사용하기 쉽습니다.\n\n한 가지 확실한 것은 이를 둘러싼 도구들은 앞으로 점점 더 나아질 것이며, 우리는 이를 통해 얻을 수밖에 없습니다!\n\n다음에 뵙겠습니다.\n","ogImage":{"url":"/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_0.png"},"coverImage":"/assets/img/2024-06-19-RemotedevelopmentorHowIlearnedtostopworryingandlovetheMainframe_0.png","tag":["Tech"],"readingTime":21},{"title":"스프링 부트 개발자를 위한 도커에 오신 것을 환영합니다","description":"","date":"2024-06-19 12:47","slug":"2024-06-19-WelcometoDockerforSpringBootDevelopers","content":"\n![Docker](/assets/img/2024-06-19-WelcometoDockerforSpringBootDevelopers_0.png)\n\n현대 소프트웨어 아키텍처에서 컨테이너는 선택사항에서 필수 요소로 전환되어 가고 있습니다. 다양한 플랫폼에서 소프트웨어를 이주하고 실행하는 민첩한 방법을 제공하여 전통적인 웹 서버 모델에 비해 속도, 이식성, 확장성 등의 혜택을 제공합니다. 이러한 작고 유연한 컨테이너는 더 큰이고 적응력이 덜한 세팅을 대체하며 특히 마이크로서비스를 향상시킵니다.\n\n본 문서는 Docker를 소개하며, 주요 클라우드 제공업체와의 호환성을 위해 선택된 컨테이너 기술입니다. Docker 기본 사항 및 Maven을 사용한 Spring Boot에서 Docker 실행 및 이미지 작성과 같은 실용적 작업에 대해 다룹니다.\n\n# Docker란 무엇인가요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도커는 2013년 Solomon Hykes에 의해 개발된 널리 사용되는 오픈 소스 컨테이너 엔진입니다. 초기에는 편리성으로 인식되었지만, 응용 프로그램 내에서 컨테이너를 관리하고 시작하는 데 중요한 도구로 진화하여 가상 머신(VM)과 같은 하드웨어 할당 대신 물리적 머신에서 자원 공유를 가능케했습니다.\n\nIBM, Microsoft, Google 등 주요 기업들의 지원으로 인해 도커는 소프트웨어 개발자들을 위한 필수 도구로 부상했습니다.\n\n서버, REST API 및 명령줄 인터페이스(CLI)로 구성된 Docker Engine은 도커 시스템의 핵심을 형성하여 서버 간에 컨테이너 배포를 용이하게 합니다.\n\n# 도커 엔진 구성 요소\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기본 구성 요소는 다음과 같습니다:\n\n- Docker 데몬: Docker 이미지를 생성하고 관리하는 서버(dockerd)로, REST API 및 CLI로부터 명령을 받습니다.\n- Docker 클라이언트: 사용자는 Docker 클라이언트를 통해 Docker와 상호 작용하며, 이 클라이언트는 데몬에 명령을 전송합니다.\n- Docker 레지스트리: Docker 이미지를 저장하는 곳으로, 공개(예: Docker 허브) 또는 비공개 레지스트리 옵션이 있습니다.\n- Docker 이미지: Docker 컨테이너를 생성하는 지침을 포함하는 읽기 전용 템플릿으로, 레지스트리에서 가져오거나 Dockerfile을 사용하여 새 이미지를 만들 수 있습니다.\n- Docker 컨테이너: 'docker run' 명령을 사용하여 Docker 이미지에서 만들어지며, 응용 프로그램 및 환경을 호스팅하며 Docker API 또는 CLI를 통해 관리할 수 있습니다.\n- Docker 볼륨: Docker 컨테이너에서 생성되고 사용되는 데이터에 대한 우선적인 저장 메커니즘으로, Docker API 또는 CLI를 통해 관리할 수 있습니다.\n- Docker 네트워크: 컨테이너가 통신을위한 여러 네트워크에 연결되도록 허용하며, 다섯 가지 네트워크 드라이버 유형이 있습니다: bridge, host, overlay, none 및 macvlan.\n\n# Dockerfiles\n\nDockerfile은 Docker 이미지를 자동으로 생성하고 구성하는 지침을 포함하는 텍스트 파일입니다. Linux와 유사한 명령을 사용하여 이미지 생성을 간소화하고 가독성을 향상시킵니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDockerfile을 생성한 후에는 Docker 이미지를 빌드하기 위해 docker build 명령을 실행합니다. 그런 다음, Docker 이미지가 준비되면 실행 명령을 사용하여 컨테이너를 생성합니다.\n\n가장 일반적인 Dockerfile 명령어:\n\n- FROM: 빌드 프로세스를 시작하는 기본 이미지를 지정합니다.\n- LABEL: 이미지에 메타데이터를 키-값 쌍 형식으로 추가합니다.\n- ARG: 사용자가 docker build 명령을 사용하여 빌더로 전달할 수 있는 변수를 정의합니다.\n- COPY: 호스트 시스템에서 파일이나 디렉토리를 Docker 이미지로 복사합니다.\n- ADD: COPY와 비슷하지만 원격 URL을 가져오고 tar 파일의 자동 추출과 같은 추가 기능을 지원합니다.\n- VOLUME: 볼륨 마운트를 생성합니다.\n- RUN: 이미지 빌드 중에 명령을 실행합니다.\n- CMD: 컨테이너가 시작될 때 실행할 기본 명령을 지정합니다.\n- ENTRYPOINT: 컨테이너가 실행 가능으로 설정됩니다.\n- ENV: 컨테이너 내에서 환경 변수를 설정합니다.\n\n# Docker Compose\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDocker Compose은 여러 컨테이너 애플리케이션을 관리하기 위한 도구입니다. 단일 YAML 파일을 사용하여 서비스를 정의하고 제어하며, 간단한 명령을 사용하여 전체 애플리케이션 스택을 시작하고 중지하고 관리할 수 있습니다.\n\nDocker Compose 사용 방법:\n\n- docker-compose.yml이라는 YAML 구성 파일을 생성합니다.\n- docker-compose config로 파일을 유효성 검사합니다.\n- docker-compose up을 사용하여 서비스를 시작합니다.\n\n샘플 docker-compose.yml 파일은 데이터베이스와 애플리케이션과 같은 서비스를 정의합니다. 명령어는 다음과 같습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 이미지를 빌드하고 서비스를 시작하려면 `docker-compose up -d`를 사용하세요.\n- 배포 정보를 확인하려면 `docker-compose logs`를 사용하세요.\n- 컨테이너 목록을 보려면 `docker-compose ps`를 사용하세요.\n- 서비스를 중지하려면 `docker-compose stop`을 사용하세요.\n- 모든 컨테이너를 중지하고 제거하려면 `docker-compose down`을 사용하세요.\n\n다음은 MySQL 및 Redis와 함께 Spring Boot 애플리케이션을 위한 Docker Compose YAML 파일(docker-compose.yml)의 예시입니다:\n\n```yaml\nversion: \"3.8\"\n\nservices:\n  spring-boot-app:\n    image: spring-boot-image:latest\n    ports:\n      - \"8080:8080\"\n    depends_on:\n      - mysql-db\n      - redis-cache\n    environment:\n      SPRING_DATASOURCE_URL: jdbc:mysql://mysql-db:3306/database_name\n      SPRING_DATASOURCE_USERNAME: $MYSQLDB_USERNAME\n      SPRING_DATASOURCE_PASSWORD: $MYSQLDB_PASSWORD\n      SPRING_REDIS_HOST: redis-cache\n\n  mysql-db:\n    image: mysql:latest\n    ports:\n      - \"3306:3306\"\n    environment:\n      MYSQL_ROOT_PASSWORD: mysql_root_password\n      MYSQL_DATABASE: database_name\n      MYSQL_USERNAME: $MYSQLDB_USERNAME\n      MYSQL_PASSWORD: $MYSQLDB_PASSWORD\n\n  redis-cache:\n    image: redis:latest\n    ports:\n      - \"6379:6379\"\n```\n\n이 파일에서:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- spring-boot-app은 Spring Boot 애플리케이션을 위한 서비스입니다.\n- mysql-db는 MySQL 데이터베이스를 위한 서비스입니다.\n- redis-cache는 Redis 캐시를 위한 서비스입니다.\n\n각 서비스를 위한 이미지(image)를 정의하고 필요한 포트(ports)를 노출시키며, 데이터베이스 연결 세부 정보를 위한 환경 변수(environment)를 설정합니다.\n\nSpring Boot 앱은 MySQL과 Redis에 의존하며(dependes_on), Spring Boot 앱보다 먼저 시작되도록 합니다.\n\n# Spring Boot으로 Docker 이미지 만들기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSpring Boot 2.3에서는 Spring Boot 애플리케이션용 Docker 이미지를 만드는 간단하고 효율적인 방법을 소개했습니다. 기존에는 Docker 이미지를 Dockerfile 및 docker build 명령을 사용하여 만들었지만, 이 방법은 몇 가지 단점이 있었습니다.\n첫째로 Spring Boot이 생성한 fat jar에 의존했기 때문에, 특히 컨테이너 환경에서 부팅 시간에 영향을 줄 수 있습니다. 이를 해결하기 위해 jar 파일의 폭발된 내용을 포함할 수 있습니다.\n둘째로 Docker 이미지는 계층으로 구성됩니다. Spring Boot fat jar을 사용하면 모든 애플리케이션 코드와 타사 라이브러리가 하나의 계층으로 묶입니다. 이는 작은 코드 변경이라도 전체 계층을 다시 빌드해야 한다는 것을 의미합니다.\n이미지를 빌드하기 전에 jar 파일을 폭파시키면 애플리케이션 코드와 타사 라이브러리가 별도 계층으로 구성됩니다. 이를 통해 Docker의 캐싱 메커니즘을 활용할 수 있습니다. 결과적으로 코드 변경이 발생하면 해당 계층만 재빌드하면 되어 효율성이 크게 향상되고 빌드 시간이 줄어듭니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSpring Boot 2.3에서 소개된 두 가지 새로운 기능은 이미지 작성 기술을 개선하는 데 도움이 되었습니다: Buildpacks와 Layered jars support.\n\n## Buildpacks\n\nBuildpacks는 Docker 이미지 작성을 간편화하여 필요한 프레임워크 및 응용 프로그램 종속성을 자동으로 제공하여 Dockerfile이 필요하지 않도록합니다. Spring Boot에서는 Maven과 Gradle이 buildpacks를 지원하여 간편한 이미지 생성을 가능하게합니다.\n\n예를 들어, Maven을 사용하여 pom.xml 파일을 변경하지 않고 다음을 실행합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n./mvnw spring-boot:build-image -Dspring-boot.build-image.imageName=myorg/app\n```\n\nGradle를 사용하는 경우:\n\n```js\n./gradlew bootBuildImage --imageName=myorg/app\n```\n\n첫 번째 빌드는 컨테이너 이미지 및 JDK를 다운로드해야 하기 때문에 시간이 오래 걸릴 수 있지만, 그 이후의 빌드는 빠릅니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 명령어는 먼저 표준 Fat Jar를 빌드한 다음 Docker 이미지 생성을 시작합니다. Packeto 빌더를 사용하여 클라우드 네이티브 빌드팩을 구현합니다. 이는 프로젝트를 분석하고 필요한 프레임워크 및 라이브러리(예: Spring Boot)를 식별하여 이미지에 추가합니다.\n\n이후의 빌드는 Docker의 레이어링을 활용하여, 애플리케이션 코드만 변경될 때에는 빌드 시간을 단축할 수 있습니다. 이 효율성은 빌드팩을 통해 도커 이미지를 생성하는 데 간편하고 빠른 옵션으로 만들어줍니다.\n\n## 계층화된 JARS\n\nSpring Boot은 jar에 레이어 인덱스 파일을 추가하는 것을 지원합니다. 이 인덱스는 레이어 목록과 해당 레이어에 포함되어야 하는 jar의 부분을 제공합니다. 인덱스의 레이어 목록은 Docker/OCI 이미지에 추가할 순서로 정렬됩니다. 기본적으로 다음 레이어가 지원됩니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 종속성\n- spring-boot-loader\n- snapshot-dependencies\n- application\n\n다음은 layers.idx 파일의 예시를 보여줍니다:\n\n```js\n- \"dependencies\":\n  - BOOT-INF/lib/library1.jar\n  - BOOT-INF/lib/library2.jar\n- \"spring-boot-loader\":\n  - org/springframework/boot/loader/launch/JarLauncher.class\n  - ... <other classes>\n- \"snapshot-dependencies\":\n  - BOOT-INF/lib/library3-SNAPSHOT.jar\n- \"application\":\n  - META-INF/MANIFEST.MF\n  - BOOT-INF/classes/a/b/C.class\n```\n\n이 레이어링은 응용 프로그램 빌드 간에 얼마나 자주 변경될 수 있는지에 따라 코드를 분리하는 데 사용됩니다. 라이브러리 코드는 빌드 간에 변경될 가능성이 낮기 때문에 캐시로부터 레이어를 재사용할 수 있도록 자체 레이어에 배치됩니다. 응용 프로그램 코드는 빌드 간에 변경될 가능성이 더 높기 때문에 별도의 레이어에 격리됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDocker 이미지를 만드는 데 이것을 어떻게 활용할 수 있는지 살펴보겠습니다.\n\n- 계층화된 JAR 생성: 먼저 pom.xml 파일의 Spring Boot Maven 플러그인에 계층 구성을 추가하세요. 아래는 예시 스니펫입니다:\n\n```js\n<plugin>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-maven-plugin</artifactId>\n  <configuration>\n    <layers>\n      <enabled>true</enabled>\n    </layers>\n  </configuration>\n</plugin>\n```\n\n- JAR 재빌드: pom.xml을 구성한 후에는 mvn clean package를 사용하여 Spring Boot JAR을 재빌드하여 새로운 계층화된 JAR을 생성하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n애플리케이션의 루트 디렉토리로 이동한 다음 다음 명령어를 실행하여 레이어와 그 순서를 표시하세요:\n\n```js\njava -Djarmode=layertools -jar target/app.jar list\n```\n\n- 레이어 도구(jar 모드)를 사용하여 jar 파일을 실행하세요:\n\n```js\n$ java -Djarmode=layertools -jar app.jar\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Dockerfile 생성하기: Docker 이미지에 이러한 레이어들을 포함하는 가장 쉬운 방법은 Dockerfile을 사용하는 것입니다:\n\n```js\nFROM eclipse-temurin:17-jre as builder\n\nWORKDIR application\nARG JAR_FILE=target/*.jar\nCOPY ${JAR_FILE} application.jar\nRUN java -Djarmode=layertools -jar application.jar extract\n\nFROM eclipse-temurin:17-jre\nWORKDIR application\n\nCOPY --from=build application/dependencies/ ./\nCOPY --from=build application/spring-boot-loader/ ./\nCOPY --from=build application/snapshot-dependencies/ ./\nCOPY --from=build application/application/ ./\n\nENTRYPOINT [\"java\", \"org.springframework.boot.loader.JarLauncher\"]\n```\n\n이 Dockerfile에서는 우리의 fat jar를 별도의 레이어로 분리하고 각 레이어를 Docker 이미지에 추가하는 방법을 제시했습니다. COPY 명령을 사용할 때마다 Docker 이미지에 새로운 레이어가 생성됩니다.\n\n- Docker 이미지 빌드하기: 위의 Dockerfile이 현재 디렉토리에 있다고 가정하면, 도커 이미지는 docker build . 명령을 사용하여 빌드할 수 있습니다. 또는 다음 예시와 같이 애플리케이션 jar 파일의 경로를 지정할 수도 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n$ docker build --build-arg JAR_FILE=path/to/app.jar .\n```\n\n# Jib을 사용하여 Java 컨테이너 빌드하기\n\nJib은 구글이 개발한 Java 도구로 Java 앱을 위한 Docker 이미지를 쉽게 빌드할 수 있습니다. Dockerfile을 작성할 필요도 없고 시스템에 Docker를 설치할 필요도 없어요.\n\nJib은 의존성, 리소스, 클래스와 같은 애플리케이션을 구별하는 레이어로 구성하고 Docker 이미지 레이어 캐싱을 이용하여 변경 사항만 다시 빌드하는 방식으로 빌드를 빠르게 유지합니다. Jib의 레이어 구조와 작은 베이스 이미지는 전체 이미지 크기를 작게 유지하여 성능과 이식성을 향상시킵니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n배포하기 전에 Docker 저장소에 대한 로컬 인증 설정을 하는 것이 매우 중요합니다. 예를 들어 DockerHub 자격 증명을 .m2/settings.xml 파일에 포함할 수 있습니다. 그러나 이 파일에 암호를 평문으로 저장하는 것은 권장되지 않습니다.\n\n```js\n<settings>\n  ...\n  <servers>\n    ...\n    <server>\n      <id>registry.hub.docker.com</id>\n      <username>내_사용자명</username>\n      <password>{내_시크릿}</password>\n    </server>\n  </servers>\n</settings>\n```\n\nid 필드가 이 자격 증명이 지정된 레지스트리 서버와 일치하는지 확인하세요.\n\nJib를 사용하여 Docker Hub에 배포하려면 jib-maven-plugin이나 그와 동등한 Gradle을 사용할 수 있습니다. 간단히 다음과 같은 명령을 실행하면 됩니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nmvn compile com.google.cloud.tools:jib-maven-plugin:3.1.1:build -Dimage=$IMAGE_PATH\n```\n\n예를 들어, 이미지를 DockerHub에 업로드하려면 $IMAGE_PATH를 registry.hub.docker.com/my-repo/my-app과 같은 값으로 설정하세요.\n\n이 명령은 앱의 Docker 이미지를 빌드하고 DockerHub로 푸시합니다. Google Container Registry나 Amazon Elastic Container Registry와 같은 다른 레지스트리에도 비슷한 방식으로 이미지를 업로드할 수 있습니다.\n\n## 추가 커스터마이징\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nJib 빌드를 Dockerfile과 비슷한 방식으로 사용자 정의할 수 있습니다. 이는 환경 변수를 추가하는 등의 방식입니다. 아래는 그 방법입니다:\n\n```js\n<project>\n  ...\n  <build>\n    <plugins>\n      ...\n      <plugin>\n        <groupId>com.google.cloud.tools</groupId>\n        <artifactId>jib-maven-plugin</artifactId>\n        <version>3.1.1</version>\n        <configuration>\n          <to>\n            <image>${IMAGE_PATH}</image>\n          </to>\n          <container>\n            <environment>\n              <ENV_VAR>VALUE</ENV_VAR>\n            </environment>\n          </container>\n        </configuration>\n      </plugin>\n      ...\n    </plugins>\n  </build>\n  ...\n</project>\n```\n\n이 변경으로 Maven 명령을 간소화할 수 있습니다:\n\n```js\nmvn compile jib:build\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n옵션으로 Docker를 설치한 경우, 로컬 Docker 설치로 빌드할 수 있습니다. 이렇게 하면 이미지를 다른 로컬 컨테이너처럼 검사하거나 실행할 수 있습니다:\n\n```js\nmvn compile jib:dockerBuild\n```\n\n# 결론\n\nDocker는 현대 소프트웨어 개발에 있어 필수 요소가 되었습니다. 민첩성과 확장성을 제공합니다. 본 문서에서는 Docker의 기초를 소개하고 Maven을 사용하여 Spring Boot 앱용 이미지를 생성하는 방법을 알아보았습니다. Spring Boot 2.3은 효율적인 이미지 생성을 위해 Buildpacks와 Layered Jars를 도입하였습니다. Google의 Jib는 Java 앱을 위한 Docker 이미지 생성을 간단하게 해줍니다. 이러한 도구들을 활용하면 배포를 간소화하고 생산성을 향상시킬 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-06-19-WelcometoDockerforSpringBootDevelopers_0.png"},"coverImage":"/assets/img/2024-06-19-WelcometoDockerforSpringBootDevelopers_0.png","tag":["Tech"],"readingTime":16},{"title":"컨테이네라이제이션의 힘을 발휘하기 데이터 과학자들이 도커와 쿠버네티스를 배워야 하는 이유","description":"","date":"2024-06-19 12:44","slug":"2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes","content":"\n데이터 과학 분야가 계속 발전함에 따라, 전문가들이 최신 도구와 기술에 대해 최신 정보를 학습하는 것이 점점 더 중요해지고 있습니다. 이 중 가장 중요한 두 가지는 Docker와 Kubernetes입니다. 이 두 도구는 소프트웨어 응용 프로그램을 개발하고 배포하는 방식을 변화시켰습니다. 그렇다면 이 도구들은 정확히 무엇이고, 데이터 과학자에게 어떤 이점을 제공할까요?\n\n이 글에서는 Docker와 Kubernetes에 대한 포괄적인 소개를 제공하겠습니다. 그들의 주요 기능과 이점에 대해 개요를 제공할 것입니다. 또한 이 두 기술 간의 차이를 탐구하고, 데이터 과학자가 두 기술을 모두 학습해야 하는 이유를 살펴볼 것입니다. 이 글을 마치면 컨테이너화와 오케스트레이션이 데이터 과학자로서 더 효율적으로 일할 수 있는 방법에 대한 확고한 이해를 갖게 될 것입니다.\n\n![이미지](/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_0.png)\n\n## 목차:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 도커에 대한 포괄적인 소개\n  1.1. 도커란 무엇인가요?\n  1.2. 컨테이너란 무엇인가요?\n  1.3. 도커 도구 및 용어\n  1.4. 도커의 장점\n- 쿠버네티스에 대한 포괄적인 소개\n  2.1. 쿠버네티스란 무엇인가요?\n  2.2. 쿠버네티스를 통한 컨테이너 오케스트레이션\n  2.3. 쿠버네티스의 역할은 무엇인가요?\n  2.4. 쿠버네티스의 장점\n- 도커와 쿠버네티스의 차이\n- 데이터 과학자로서 쿠버네티스와 도커를 왜 배워야 할까요?\n  4.1. 데이터 과학자로서 도커를 배워야 하는 이유는 무엇인가요?\n  4.2. 데이터 과학자가 데브옵스 팀이 있는 상황에서 도커를 배워야 하는가\n  4.3. 데이터 과학자로서 도커를 배우는 장점은?\n  4.4. 데이터 과학자가 쿠버네티스를 배워야 하는가?\n\n만약 무료로 데이터 과학 및 기계 학습을 공부하고 싶다면, 다음 자료를 확인해보세요:\n\n- 스스로 데이터 과학 및 기계 학습을 배울 수 있는 무료 대화형 로드맵. 여기에서 시작하세요: [https://aigents.co/learn/roadmaps/intro](https://aigents.co/learn/roadmaps/intro)\n- 데이터 과학 학습 자료를 위한 검색 엔진 (무료). 즐겨찾기에 추가하고, 완료된 기사를 표시하고, 학습 노트를 추가하세요. [https://aigents.co/learn](https://aigents.co/learn)\n- 멘토와 학습 커뮤니티의 지원을 받아 처음부터 데이터 과학을 배우고 싶나요? 무료로 이 스터디 서클에 가입하세요: [https://community.aigents.co/spaces/9010170/](https://community.aigents.co/spaces/9010170/)\n\n데이터 과학 및 인공 지능 분야에서 경력을 시작하고 싶지만 어떻게 시작해야 할지 모르겠다면, 데이터 과학 멘토링 세션과 장기적인 경력 멘토링을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 멘토링 세션: [링크](https://lnkd.in/dXeg3KPW)\n- 장기 멘토링: [링크](https://lnkd.in/dtdUYBrM)\n\n무제한으로 계속 학습하려면 5달러에 미디엄 멤버십 프로그램에 가입하세요. 아래 링크를 사용해 가입하면 추가 비용 없이 회원비의 일부가 저에게 전달됩니다.\n\n# 1. Docker의 포괄적 인트로덕션\n\n![이미지](/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 1.1. 도커란 무엇인가요?\n\n도커는 개발자가 컨테이너를 구축, 배포 및 실행하는 데 도움이 되는 상용 컨테이너화 플랫폼 및 런타임입니다. 도커는 간단한 명령어와 단일 API를 통해 자동화된 클라이언트-서버 아키텍처를 사용합니다.\n\n도커를 사용하면 개발자는 도커 파일(Dockerfile)을 작성하여 컨테이너화된 응용 프로그램을 만들 수 있습니다. 도커는 이러한 컨테이너 이미지를 빌드하고 관리하기 위한 일련의 도구를 제공하며, 개발자가 응용 프로그램을 일관적이고 재현 가능한 방식으로 패키지화하고 배포하는 것을 더 쉽게 만듭니다.\n\n이러한 컨테이너 이미지들은 Kubernetes, Docker Swarm, Mesos 또는 HashiCorp Nomad와 같은 컨테이너를 지원하는 어떤 플랫폼에서도 실행할 수 있습니다. 도커의 플랫폼은 개발자가 이러한 컨테이너 이미지를 생성하고 관리하기 쉽도록하며, 다양한 환경에서 응용 프로그램을 빌드하고 배포하는 프로세스를 간소화합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도커는 컨테이너화된 애플리케이션을 패키징하고 배포하는 효율적인 수단을 제공하지만, 대규모로 컨테이너를 관리하고 실행하는 것은 상당한 어려움을 야기할 수 있습니다. 여러 서버 또는 클러스터 간에 컨테이너를 조정하고 예약하고, 다운타임을 유발하지 않고 애플리케이션을 배포하며, 컨테이너 건강 상태를 모니터링하는 것만 몇 가지 복잡성 중 일부에 해당합니다.\n\n이러한 도전 과제를 해결하기 위해 Kubernetes, Docker Swarm, 메소스, HashiCorp Nomad 등의 오케스트레이션 솔루션이 등장했습니다. 이러한 플랫폼은 조직이 많은 수의 컨테이너 및 사용자를 관리하고, 리소스 할당을 최적화하며, 인증 및 보안을 제공하고, 다중 플랫폼 배포를 지원하는 등의 능력을 제공합니다. 컨테이너 오케스트레이션 솔루션을 활용함으로써 조직은 컨테이너화된 애플리케이션 및 인프라를 보다 쉽고 효율적으로 관리할 수 있습니다.\n\n현재 도커 컨테이너화는 마이크로소프트 윈도우 및 애플 맥OS와도 호환됩니다. 개발자는 어떤 운영 체제에서도 도커 컨테이너를 실행할 수 있으며, 아마존 웹 서비스(AWS), 마이크로소프트 애저, IBM 클라우드 등 주요 클라우드 제공업체 대부분은 도커로 컨테이너화된 애플리케이션을 구축, 배포 및 실행하는 데 도움이 되는 특정 서비스를 제공합니다.\n\n## 1.2. 컨테이너란 무엇인가?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_2.png)\n\n컨테이너는 코드, 라이브러리, 시스템 도구 및 설정을 포함하여 응용 프로그램을 실행하는 데 필요한 모든 것이 포함된 가볍고 휴대 가능한 실행 가능한 소프트웨어 패키지입니다.\n\n컨테이너는 컨테이너의 내용과 구성을 정의하는 이미지에서 생성되며, 호스트 운영 체제 및 동일한 시스템의 다른 컨테이너로부터 격리됩니다.\n\n이 격리는 가상화 및 프로세스 격리 기술을 사용하여 가능하며, 이를 통해 컨테이너는 호스트 운영 체제의 하나의 인스턴스의 자원을 공유하면서 응용 프로그램을 실행하는 안전하고 예측 가능한 환경을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n컨테이너는 소프트웨어 개발 및 배포에서 널리 사용되는데, 응용 프로그램 관리를 간소화하고 확장성을 향상시키며 인프라 비용을 줄일 수 있기 때문에 매력적입니다.\n\nLinux 커널은 프로세스 격리 및 가상화 기능을 제공하여 컨테이너를 실현 가능하게 합니다. 이러한 기능에는 프로세스 간에 리소스를 할당하는 Cgroups와 프로세스의 다른 시스템 리소스나 영역에 대한 액세스를 제한하는 네임스페이스가 포함되어 있습니다.\n\n이러한 기능을 활용하면 다양한 응용 프로그램 구성 요소가 호스트 운영 체제 인스턴스의 리소스를 공유할 수 있으며, 하이퍼바이저가 단일 하드웨어 서버의 CPU, 메모리 및 기타 리소스를 여러 가상 머신(VM)이 공유하는 방식과 유사합니다.\n\n결과적으로 컨테이너 기술은 VM의 모든 기능과 이점(응용 프로그램 격리, 비용 효율적인 확장성 및 처분 가능성을 포함)을 제공하는 동시에 중요한 추가 혜택을 제공합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 더 가벼운 무게: 컨테이너는 필요한 운영 체제 프로세스와 종속성만 포함하여 애플리케이션 코드를 실행하는 반면, 가상 머신(VM)과는 큰 차이가 있습니다. 이로 인해 컨테이너는 일반적으로 메가바이트로 측정되며, VM은 기가바이트 저장 공간을 필요로 할 수 있는 반면, 컨테이너는 훨씬 작습니다. 또한, 컨테이너는 하드웨어 리소스를 더 효율적으로 활용하며 VM보다 훨씬 빨리 시작할 수 있습니다.\n\n- 개발자 생산성 향상: 컨테이너를 사용하면 애플리케이션을 한 번 개발하고 다양한 환경에 심플하게 배포할 수 있어서 이동성과 적응성이 뛰어납니다. VM과 비교했을 때 컨테이너는 배포하기도, 프로비저닝하기도, 다시 시작하기도 더 간단하고 빠릅니다. 결과적으로 CI/CD(지속적 통합/지속적 배포) 파이프라인 구현에 뛰어난 선택지가 됩니다. 이는 팀이 빠르게 개발, 테스트, 애플리케이션 출시할 수 있도록 도와주어 Agile 및 DevOps 방법론을 실천하는 개발팀에 적합합니다. 컨테이너는 빠른 소프트웨어 개발, 테스트, 배포를 촉진하기 때문에 중단이 적고 최적 생산성을 제공합니다.\n\n- 자원 효율성 향상: 컨테이너를 사용하면 개발자는 VM을 사용할 때보다 동일한 하드웨어에서 응용 프로그램 복사본을 여러 배 더 많이 실행할 수 있습니다. 이로 인해 클라우드 비용을 절감할 수 있습니다.\n\n## 1.3. Docker 도구 및 용어\n\n- DockerFile: 모든 Docker 컨테이너는 Docker 컨테이너 이미지를 빌드하는 방법에 대한 지침이 포함된 간단한 텍스트 파일로 시작합니다. DockerFile은 Docker 이미지 생성 프로세스를 자동화합니다. 이는 Docker 엔진이 이미지를 조립하기 위해 실행하는 명령줄 인터페이스(CLI) 명령어 목록입니다. Docker 명령어 목록은 방대하지만 표준화되어 있습니다: Docker 작업은 내용, 인프라, 또는 다른 환경 변수에 관계없이 동일하게 작동합니다.\n\n- Docker Image: Docker 이미지는 실행 가능한 애플리케이션 소스 코드뿐만 아니라 모든 도구, 라이브러리 및 종속성을 포함하고 있습니다. Docker 이미지를 실행하면 컨테이너의 한 인스턴스(또는 여러 인스턴스)가 됩니다. Docker 이미지를 처음부터 만들 수 있지만 대부분의 개발자는 이러한 이미지를 일반적인 저장소에서 다운로드합니다. 동일한 베이스 이미지로부터 여러 Docker 이미지를 만들고 그들의 스택에서 일반적인 사항을 공유할 수 있습니다.\n- Docker 컨테이너: Docker 컨테이너는 Docker 이미지의 실시간 실행 인스턴스입니다. Docker 이미지는 읽기 전용 파일이지만, 컨테이너는 실행 가능한 일회성 내용입니다. 사용자는 이와 상호 작용할 수 있으며, 관리자는 Docker 명령어를 사용하여 설정 및 조건을 조정할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도커는 개발자가 간단한 명령어를 사용하여 이러한 네이티브 컨테이너화 기능에 액세스할 수 있도록 하고, 작업을 절약하는 응용 프로그램 프로그래밍 인터페이스(API)를 통해 자동화할 수 있습니다. 도커는 다음을 제공합니다:\n\n- 향상된 및 매끄러운 컨테이너 이식성: 도커 컨테이너는 수정 없이 모든 데스크톱, 데이터 센터 또는 클라우드 환경에서 실행됩니다.\n- 더 가벼우면서 더 세부적인 업데이트: 여러 프로세스를 하나의 컨테이너 내에서 결합할 수 있습니다. 이를 통해 애플리케이션을 구축하고 있는 동안 그 중 하나의 부분이 업데이트나 수리를 위해 중단되더라도 계속 실행할 수 있습니다.\n- 자동화된 컨테이너 생성: 도커는 애플리케이션 소스 코드를 기반으로 자동으로 컨테이너를 빌드할 수 있습니다.\n- 컨테이너 버전 관리: 도커는 컨테이너 이미지의 버전을 추적하고 이전 버전으로 되돌릴 수 있으며, 어떻게 버전을 빌드했는지 및 누가 빌드했는지를 추적할 수 있습니다. 기존 버전과 새 버전 간의 차이점만 업로드할 수도 있습니다.\n- 컨테이너 재사용: 기존 컨테이너를 기본 이미지로 사용할 수 있습니다. 이는 사실상 새로운 컨테이너를 구축하는 템플릿과 같은 역할을 합니다.\n- 공유 컨테이너 라이브러리: 개발자는 수천 개의 사용자 기여 컨테이너가 포함된 오픈소스 레지스트리에 액세스할 수 있습니다.\n\n# 2. Kubernetes에 대한 포괄적인 소개\n\n![이미지](/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_3.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 2.1. 쿠버네티스란?\n\n쿠버네티스(Kubernetes), 줄여서 K8s로도 불리는 이는 클러스터된 네트워크 리소스 위에서 컨테이너 런타임 시스템을 조립하기 위해 설계된 유명한 오픈소스 플랫폼입니다. 독립적으로 작동하거나 Docker와 같은 다른 컨테이너화 도구와 함께 작동할 수 있습니다.\n\nGoogle에서 최초 개발된 쿠버네티스는 수십억 개의 컨테이너를 대규모로 실행하기 위한 도전에 대응하기 위해 만들어졌습니다. Google은 2014년 이 플랫폼을 오픈소스 도구로 제공했으며, 이후 컨테이너 조립 및 분산 애플리케이션 배포를 위한 시장 리더 및 산업 표준 솔루션이 되었습니다.\n\nGoogle에 따르면 쿠버네티스는 복잡한 분산 시스템의 배포와 관리를 단순화하면서 컨테이너화의 장점을 활용하여 리소스 활용을 최적화하는 데 설계되었습니다. 쿠버네티스의 널리 퍼지는 채택으로 인해 제품 환경에서 컨테이너화된 응용 프로그램의 관리 및 확장에 중요한 도구로 부상했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n쿠버네티스는 독립적인 기능이 있는 각각의 컨테이너를 실행하는 Docker와는 달리, 하나의 머신에서 여러 컨테이너 그룹을 관리하여 네트워크 오버헤드를 줄이고 자원 이용을 최적화할 수 있는 실용적인 해결책을 제공합니다. 예를 들어, 컨테이너 세트는 응용 프로그램 서버, Redis 캐시, 그리고 SQL 데이터베이스로 구성될 수 있습니다.\n\n쿠버네티스는 서비스 검색, 클러스터 내 로드 밸런싱, 자동 배포 및 롤백, 실패한 컨테이너의 자가 치유, 그리고 구성 관리 등 다양한 기능을 제공하여 데브옵스 팀에게 매우 가치 있는 도구입니다. 게다가, 쿠버네티스는 견고한 데브옵스 지속적 통합/지속적 전달 (CI/CD) 파이프라인을 구축하는 데 필수적인 도구입니다.\n\n하지만 쿠버네티스는 완전한 플랫폼 서비스(PaaS)가 아니며, 쿠버네티스 클러스터를 구축하고 관리할 때 염두에 두어야 할 사항이 몇 가지 있습니다. 쿠버네티스를 관리하는 복잡성은 많은 고객이 클라우드 공급 업체가 제공하는 관리형 쿠버네티스 서비스를 선호하는 주요 이유 중 하나입니다.\n\n## 2.2. 쿠버네티스를 사용한 컨테이너 오케스트레이션\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n컨테이너의 보급으로 기업들은 수백 개나 수천 개의 컨테이너를 가지게 될 수 있습니다. 이는 운영 팀이 컨테이너 배포, 네트워킹, 확장성 및 가용성을 자동화하는 것이 중요하다는 것을 필수적으로 만듭니다. 이것이 컨테이너 오케스트레이션 시장의 출현으로 이어졌습니다.\n\n다른 컨테이너 오케스트레이션 옵션인 Docker Swarm, Apache Mesos 등이 처음에는 인기를 얻었지만 Kubernetes가 빠르게 가장 널리 채택되었습니다. 사실 어느 순간부터 역사상 가장 빠르게 성장하는 오픈소스 프로젝트가 되었습니다.\n\n개발자들은 Kubernetes를 폭넓은 기능, 계속 성장하는 오픈소스 지원 도구 생태계, 다양한 클라우드 서비스 제공업체를 지원하고 교차 작동할 수 있는 능력 때문에 선택했습니다. 아마존 웹 서비스(AWS), 구글 클라우드, IBM 클라우드, 마이크로소프트 애저를 비롯한 모든 주요 공개 클라우드 제공업체들은 Kubernetes를 완전히 관리하는 서비스를 제공하며 이는 업계 전체적으로 인기가 있다는 것을 강조합니다.\n\n## 2.3. Kubernetes가 하는 일은 무엇인가요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKubernetes는 애플리케이션 수명 주기 전반에 걸쳐 컨테이너 관련 작업을 스케줄하고 자동화합니다. 이러한 작업에는 다음이 포함됩니다:\n\n- 배포: 지정된 호스트에 지정된 수의 컨테이너를 배포하고 원하는 상태로 유지합니다.\n- 롤아웃: 롤아웃은 배포에 대한 변경 사항을 의미합니다. Kubernetes를 사용하면 롤아웃을 시작하거나 일시 중지하거나 다시 시작하거나 롤백할 수 있습니다.\n- 서비스 검색: Kubernetes는 컨테이너를 DNS 이름 또는 IP 주소를 사용하여 자동으로 인터넷이나 다른 컨테이너에 노출시킬 수 있습니다.\n- 스토리지 프로비저닝: Kubernetes를 설정하여 필요에 따라 컨테이너에 지속적인 로컬 또는 클라우드 스토리지를 마운트할 수 있습니다.\n- 부하 분산: CPU 이용률 또는 사용자 정의 지표를 기반으로 한 Kubernetes 부하 분산은 네트워크 전체에 작업 부하를 분산하여 성능과 안정성을 유지할 수 있습니다.\n- 자동 스케일링: 트래픽이 급증할 때 Kubernetes 자동 스케일링은 필요에 따라 추가 작업 부하를 처리하기 위해 새로운 클러스터를 생성할 수 있습니다.\n- 고가용성을 위한 자가 치유: 컨테이너가 실패하면 Kubernetes가 자동으로 다시 시작하거나 교체하여 다운타임을 방지할 수 있습니다. 또한 건강 검사 요구 사항을 충족하지 못하는 컨테이너를 중지할 수도 있습니다.\n\n## 2.4. Kubernetes의 장점\n\n- 자동화된 작업: Kubernetes는 효율적인 자동화를 가능하게 하는 강력한 API 및 명령줄 유틸리티인 kubectl을 갖추고 있습니다. Kubernetes는 컨트롤러 패턴을 통해 응용 프로그램/컨테이너가 자신의 사양에 정확히 따라 실행되도록 보장합니다.\n- 인프라 추상화: Kubernetes는 배정된 리소스를 대신하여 관리하고 응용프로그램 코드 작성에 집중할 수 있도록 해줍니다. 이를테면 컴퓨팅, 네트워킹 또는 스토리지의 기본 인프라 대신에 개발자가 애플리케이션 코드를 작성할 수 있습니다.\n- 서비스 상태 모니터링: Kubernetes는 운영 환경을 지속적으로 모니터링하고 의도된 구성과 일치 여부를 확인합니다. 서비스에 대한 건강 검사를 자동으로 수행하고 실패나 중단이 발생한 경우 컨테이너를 다시 시작합니다. Kubernetes는 서비스가 가동되어 있을 때에만 서비스를 노출합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Docker & Kubernetes의 차이점\n\n![Docker vs Kubernetes](/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_4.png)\n\nDocker와 Kubernetes는 모두 컨테이너화 생태계에서 중요한 구성 요소로, 각각 다른 목적으로 사용됩니다. Docker는 주로 컨테이너를 생성하고 실행하는 데 사용되며, Kubernetes는 호스트 클러스터 전체에서 컨테이너의 배포, 확장 및 관리를 조정하고 자동화하는 데 활용됩니다.\n\nDocker는 컨테이너화에 대해 직관적이고 효과적인 방법을 제공하는 반면, Kubernetes는 자동 스케일링, 자가 치유, 컨테이너 배포 등과 같은 고급 기능을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 4. 데이터 과학자로서 Kubernetes 및 Docker를 배워야 하는 이유\n\n![이미지](/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_5.png)\n\n## 4.1. 데이터 과학자로서 Docker를 배워야 하는 이유\n\n상상해보세요. 로컬 머신에서 완벽하게 작동하는 머신러닝 솔루션이 개발되었다고 가정해봅시다. 그러나 이를 다른 운영 체제나 라이브러리 버전이 다른 서버에 배포하려고 하면 코드가 예상대로 작동하지 않을 수 있습니다. 이는 개발자들에게는 좌절스러운 경험이 될 수 있지만, 이는 흔히 발생하는 일입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 문제의 해결책은 Docker를 사용하는 것입니다. Docker를 사용하면 프로젝트에 일관성 있고 정확한 환경을 정의할 수 있습니다. Docker를 사용하면 코드를 모든 필요한 종속성과 라이브러리와 함께 패키징하여 어느 기기에서나 실행할 수 있는 컨테이너로 만들 수 있습니다. 이는 대상 배포 환경에 관계없이 코드가 원활하고 일관되게 실행되도록 보장합니다.\n\n## 4.2. 데이터 과학자가 DevOps 팀이 존재하는 상황에서 Docker를 배워야 할까요\n\n데이터 과학자인 경우, 프로젝트의 인프라 측면을 처리하기 위해 전담된 DevOps 팀이 있는 경우에도 Docker를 배워야 할 필요성에 대해 의문을 갖을 수 있습니다. 그러나 Docker가 데이터 과학 작업 흐름에서 중요한 역할을 한다는 점을 인식하는 것이 중요합니다. DevOps 팀이 있더라도 Docker가 작업의 여러 측면을 간소화하고 효율화할 수 있다는 점을 발견하게 될 것입니다. 따라서 Docker가 데이터 과학자에게 귀중한 도구인 이유를 이해하는 것이 중요합니다.\n\n## 4.3. 데이터 과학자로서 Docker를 배우는 이점\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n데이터 과학자로서 Docker를 배우는 것은 여러 가지 이점을 제공합니다:\n\n- 일관성과 재현성: Docker를 사용하면 코드, 종속성 및 환경을 모두 포함한 전체 프로젝트를 단일 컨테이너에 패키징하여 배포할 수 있습니다. 이를 통해 작업이 다른 기계와 환경에서 일관되게 실행되며 호환성 및 버전 관리 문제를 제거할 수 있습니다. 또한 Docker 컨테이너는 언제든지 작업을 정확히 재현할 수 있어 과거 결과를 다시 확인하거나 다른 사람들과 작업을 공유하는 데 용이합니다.\n- 쉬운 배포: Docker를 사용하면 프로젝트를 로컬 컴퓨터나 클라우드와 같은 다양한 환경에 쉽게 배포할 수 있습니다. 프로젝트를 컨테이너에 묶어두면 최소한의 구성으로 배포할 수 있고 종속성이나 호환성 문제를 걱정하지 않아도 됩니다.\n- 협업: Docker를 통해 동일 프로젝트에 참여하는 팀원들 간에 쉽게 협력할 수 있습니다. 작업을 컨테이너에 패키징함으로써 모두가 동일한 환경에서 작업하도록 보장하여 코드를 공유하고 결과를 재현하기가 더욱 쉬워집니다.\n- 빠른 실행: Docker 컨테이너는 가벼우며 빠르게 시작되므로 전통적인 방법보다 코드를 테스트하고 실행하는 속도가 빠릅니다. 이는 더욱 효율적인 작업 흐름과 빠른 반복 시간으로 이어질 수 있습니다.\n\n## 4.4. 데이터 과학자가 Kubernetes를 배워야 할까요?\n\n데이터 과학자가 Kubernetes를 배워야 하는지에 대한 의견은 분분할 수 있지만, 컨테이너화 및 Kubernetes와 같은 오케스트레이션 기술에 대한 기본적인 이해를 갖는 것이 유익하다고 널리 인정받고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이러한 이유 중 하나는 데이터 과학자가 데브옵스 및 인프라 팀과 더 잘 소통할 수 있도록 도울 수 있다는 것입니다. 쿠버네티스에 대한 기본적인 이해를 갖고 있는 데이터 과학자는 모델 및 응용 프로그램을 프로덕션 환경에 배포하기 위한 인프라 요구 사항을 이해할 수 있습니다. 이는 데이터 과학자와 다른 팀 간의 원활한 소통과 협력을 촉진하여 더 효율적인 워크플로 및 빠른 배포 시간을 이끌어낼 수 있습니다.\n\n게다가, 쿠버네티스는 데이터 과학자들에게 확장 가능하고 신뢰할 수 있는 방식으로 모델 및 응용 프로그램을 쉽게 배포하고 관리할 수 있는 수단을 제공할 수 있습니다. 쿠버네티스를 사용하면 데이터 과학자들은 모델의 배포 및 확장을 자동화하여 대량의 데이터 및 요청을 처리하기가 더 쉬워집니다.\n\n게다가, 머신러닝 모델과 응용 프로그램이 더 복잡해지면 효율적으로 실행하기 위해 더 많은 인프라 자원이 필요할 때가 많습니다. 쿠버네티스는 데이터 과학자가 이러한 자원을 효과적으로 관리할 수 있게 하여 복잡한 모델과 응용 프로그램을 인프라 제약 사항에 대해 걱정하지 않고 규모에 맞게 실행할 수 있도록 도와줄 수 있습니다.\n\n종합하면, 데이터 과학자가 쿠버네티스 전문가가 될 필요는 없을지라도 이 기술에 대한 기본적인 이해를 갖는 것은 다른 팀과 더 효과적으로 작업하고 모델 및 응용 프로그램을 더 효율적으로 배포하는 데 도움이 될 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위 주제에 대해 더 많은 정보를 보려면 다음 블로그 포스트를 참조하세요:\n\n- 데이터 과학 워크로드에 쿠버네티스가 좋은 이유\n- 데이터 과학자가 쿠버네티스를 알 필요가 없는 이유\n- 데이터 과학을 위해 쿠버네티스가 정말 필요한가요?\n\n# 참고 자료:\n\n- 도커(Docker)란 무엇인가요?\n- Kubernetes vs. Docker: Kubernetes와 Docker의 주요 차이점 및 컨테이너화에 대한 역할\n- Kubernetes vs. Docker: 포괄적인 비교\n- 데이터 과학을 위한 도커: 소개\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 이 글을 좋아하고 제를 지원하고 싶으시다면, 반드시:\n\n- 👏 이 글에 박수를 보내주세요 (50번) - 이 글이 주목받을 수 있도록 도와주세요\n- 제 Medium 계정을 팔로우해주세요\n- 📰 제 Medium 프로필에서 더 많은 콘텐츠를 확인해주세요\n- 🔔 나를 팔로우해주세요: LinkedIn | Youtube | GitHub | Twitter\n\n5달러로 Medium 멤버십 프로그램에 가입하여 제한 없이 계속 학습할 수 있습니다. 만약 다음 링크를 사용하신다면 추가 비용 없이 멤버십 요금의 일부를 제가 받게 됩니다.\n\n데이터 과학과 인공지능 분야에서 경력을 시작하고자 하지만 방법을 모르는 경우. 데이터 과학 멘토링 세션과 장기적인 경력 멘토링을 제공합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 멘토링 세션: [링크](https://lnkd.in/dXeg3KPW)\n- 장기 멘토링: [링크](https://lnkd.in/dtdUYBrM)\n\n![이미지](/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_6.png)\n","ogImage":{"url":"/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_0.png"},"coverImage":"/assets/img/2024-06-19-UnlockingthePowerofContainerizationWhyDataScientistsNeedtoLearnDockersandKubernetes_0.png","tag":["Tech"],"readingTime":19},{"title":"라라벨 세일과 도커 컴포즈 파일을 사용자 정의하는 방법","description":"","date":"2024-06-19 12:42","slug":"2024-06-19-HowtoCustomizeLaravelSailwithDockerComposeFiles","content":"\n![](/assets/img/2024-06-19-HowtoCustomizeLaravelSailwithDockerComposeFiles_0.png)\n\n라라벨 Sail은 라라벨 개발에 혁명을 일으키는 도구입니다. 필요한 모든 서비스가 이미 설치된 미리 구성된 도커 환경을 제공합니다. 이를 통해 수동 설정이 필요없어지고, 팀 전체에 일관된 개발 환경을 제공합니다. 하지만 프로젝트에 특정 요구 사항이 있다면 어떨까요? 라라벨 Sail은 도커 컴포즈 파일을 사용하여 쉽게 사용자 정의할 수 있는 기능을 제공합니다.\n\n도커 컴포즈는 Sail의 핵심입니다. 여러 도커 컨테이너의 구성 및 조정을 관리합니다. docker-compose.yml 파일이 도커 컴포즈의 핵심이며, 애플리케이션에 필요한 서비스(컨테이너)를 정의합니다. 이 파일을 조정함으로써 Sail 환경을 프로젝트 요구 사항에 맞게 완벽히 맞출 수 있습니다.\n\n이 문서에서는 Docker Compose를 사용하여 라라벨 Sail을 사용자 정의하는 방법에 대해 알아보겠습니다. 서비스, 볼륨, 포트, 환경 변수를 조정하여 개발 경험을 효율적으로 만들고 프로젝트 요구 사항에 완벽하게 부합하도록 만들어 보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 도커-컴포즈.yml 파일 이해하기\n\n도커-컴포즈.yml 파일은 Laravel Sail 환경의 청사진으로 작용합니다. 이 파일은 도커 컴포즈에게 어떻게 설정하고 관리해야 하는지 지시하여 애플리케이션이 원활하게 실행되도록 하는 다양한 서비스(컨테이너)를 제어합니다. 이 파일을 텍스트 편집기에서 열면 일반적으로 다음과 같은 여러 주요 섹션을 포함하는 구조화된 형식을 볼 수 있습니다:\n\n# 1. 버전\n\n이 섹션은 도커 컴포즈 파일 형식 버전을 지정합니다. 최신 버전이 더 많은 기능을 제공하지만, Sail은 보다 널리 접근 가능한 지원되는 버전을 사용합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 2. 서비스\n\n이것은 구성의 핵심입니다. 이것은 응용 프로그램에 필요한 각 서비스(컨테이너)를 정의합니다. 일반적인 Sail 서비스는 다음과 같습니다:\n\n- laravel.test: Laravel 응용 프로그램을 실행하는 컨테이너입니다.\n- mysql: 데이터베이스 컨테이너로, 일반적으로 MySQL을 사용합니다.\n- phpmyadmin: 데이터베이스를 관리하기 위한 그래픽 사용자 인터페이스(GUI)를 제공하는 컨테이너입니다.\n\n각 서비스 정의에는 기본 이미지(예: php:8.1), 노출할 포트(예: 웹 트래픽용으로 80:80), 마운트할 볼륨(프로젝트 코드 및 데이터) 및 구성에 대한 환경 변수와 같은 세부 정보가 포함됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 3. 볼륨\n\n이 섹션은 컨테이너 재시작 시에도 데이터를 유지하는 이름이 지정된 볼륨을 정의합니다. 예를 들어, 애플리케이션 코드와 데이터베이스 파일을 볼륨으로 마운트하여, 컨테이너가 중지되고 다시 생성되어도 그 데이터가 보존되도록 할 수 있습니다.\n\n# 4. 네트워크\n\n이 섹션은 컨테이너 간 통신을 위한 사용자 정의 네트워크를 정의합니다. 기본적으로 Sail은 환경 내에서 서비스 간 통신을 위해 브리지 네트워크를 사용합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 5. 환경\n\n이 섹션에서는 애플리케이션 컨테이너 내에서 액세스할 수 있는 환경 변수를 정의할 수 있습니다. 이러한 변수는 데이터베이스 자격 증명이나 API 키와 같은 애플리케이션의 다양한 측면을 구성하는 데 사용할 수 있습니다.\n\n도커 컴포즈(.yml) 파일의 각 섹션의 목적과 구조를 이해하는 것은 사용자 정의에 들어가기 전에 중요합니다. 이러한 섹션들을 숙지하여 스스로를 잘 준비시켜 변경하고 Sail 환경을 프로젝트의 특정 요구 사항에 맞게 맞춤화할 수 있을 것입니다.\n\n# 서비스 사용자 정의하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리가 본 것처럼, docker-compose.yml 파일의 서비스 섹션은 Sail 환경에서 실행되는 각 컨테이너를 정의합니다. 이것이 맞춤화의 마법이 일어나는 곳입니다! 프로젝트에 맞춰 서비스를 개인화하는 몇 가지 방법을 살펴봅시다:\n\n## 1. 베이스 이미지:\n\n베이스 이미지는 컨테이너 내의 운영 체제 및 미리 설치된 소프트웨어를 지정합니다. 기본적으로 Sail은 laravel.test 서비스에 특정 PHP 버전 이미지(예: php:8.1)를 사용합니다. 그러나 프로젝트가 새로운 기능을 위해 다른 PHP 버전을 필요로 하는 경우(예: php:8.2), docker-compose.yml 파일에서 단순히 베이스 이미지 정의를 수정할 수 있습니다. 다음은 예시입니다:\n\n## 2. 포트:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기본적으로 Sail은 특정 컨테이너 포트를 호스트 머신 포트로 매핑합니다. 이를 통해 편리한 URL(일반적으로 http://localhost:80)을 통해 응용 프로그램에 액세스할 수 있습니다. 그런데 여러 프로젝트를 동시에 작업하고 있을 때는 어떻게 해야 할까요? 각 프로젝트의 laravel.test 서비스에 대해 포트를 사용자 정의하여 충돌을 피할 수 있습니다. 다음은 방법입니다:\n\n이 구성은 컨테이너의 포트 80(웹 트래픽)를 호스트 머신의 포트 8080으로 노출합니다. 이제 http://localhost:8080에서 응용 프로그램에 액세스할 수 있습니다.\n\n# 3. 볼륨:\n\n볼륨은 호스트 머신과 컨테이너 간에 공유되는 디렉터리입니다. 이를 통해 컨테이너가 다시 생성되어도 응용 프로그램 코드 및 데이터베이스 파일과 같은 데이터를 지속적으로 유지할 수 있습니다. Sail은 일부 볼륨을 사전 구성하지만 특정 요구 사항에 따라 추가 볼륨을 추가할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어, 프로젝트 디렉토리 외부에 사용자 지정 구성 파일이 있다고 상상해보세요. laravel.test 서비스에서 이 파일을 볼륨으로 마운트할 수 있습니다.\n\n이는 호스트 머신의 my-custom-config.php 파일을 컨테이너 내의 /var/www/html 디렉토리로 마운트하여 응용 프로그램에서 이에 액세스할 수 있도록 하는 것입니다.\n\n# 4. 환경 변수:\n\n환경 변수는 코드 자체를 수정하지 않고 응용 프로그램을 구성하는 방법을 제공합니다. Sail은 일부 기본 환경 변수를 정의하지만, 프로젝트에 특정한 사용자 정의 환경 변수를 추가할 수 있습니다. 다음은 예시입니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 환경 변수는 env() 도우미 함수를 사용하여 Laravel 애플리케이션 내에서 액세스할 수 있습니다.\n\n# Sail 고급 사용자 정의\n\n이전 섹션에서는 핵심 서비스 사용자 정의에 초점을 맞췄지만, Laravel Sail은 숙련된 개발자들을 위해 더 많은 유연성을 제공합니다. 여기에는 고급 옵션 중 일부를 살펴볼 수 있습니다:\n\n# 1. 네트워크:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기본적으로 Sail은 서비스간 통신을 위해 브릿지 네트워크를 사용합니다. 그러나 더 세밀한 제어가 필요한 복잡한 애플리케이션의 경우, docker-compose.yml 파일에서 사용자 정의 네트워크를 정의할 수 있습니다. 이러한 네트워크를 사용하면 서비스를 격리하고 통신 패턴을 제어할 수 있습니다.\n\n중요한 참고 사항: 사용자 정의 네트워크 구성은 Docker 네트워킹 개념에 대한 심층적인 이해가 필요하며, 고급 Docker Compose 기술에 익숙한 개발자를 대상으로 권장됩니다.\n\n# 2. 커스텀 서비스 추가하기:\n\nSail은 MySQL과 같은 미리 구성된 서비스를 제공하지만, 캐싱을 위해 Memcached나 이메일 테스트를 위해 Mailhog와 같은 추가 서비스가 필요한 경우는 어떨까요? Docker Compose의 장점은 다양한 서비스를 통합할 수 있는 능력에 있습니다. docker-compose.yml 파일에서 원하는 이미지와 구성 옵션을 지정하여 사용자 정의 서비스를 정의할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어 Memcached 서비스를 추가하려면:\n\n기억하세요: 사용자 정의 서비스를 추가하려면 그들의 목적과 구성 옵션을 이해해야 합니다. 선택한 서비스 이미지의 공식 문서를 참조하여 구체적인 지침을 얻을 수 있습니다.\n\n# 3. 도커 Secrets 사용하기:\n\n보안이 중요합니다. 데이터베이스 자격 증명과 같은 민감한 정보를 docker-compose.yml 파일에 직접 저장하는 것은 권장되지 않습니다. Docker Compose는 \"비밀\"이라고 불리는 안전한 솔루션을 제공합니다. 이 비밀은 docker-compose.yml 파일 외부에서 정의하고 서비스 내에서 환경 변수를 사용하여 참조할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n중요 사항: Docker 시크릿을 사용하려면 추가 구성이 필요하며, 민감한 정보를 위한 별도의 파일을 관리해야 할 수도 있습니다. 이 옵션을 구현하기 전에 Docker 보안 모베스트 프랙티스를 충분히 이해해야 합니다.\n\n이러한 고급 사용자 정의 옵션은 Laravel Sail 환경에 대한 새로운 수준의 유연성을 제공합니다. 그러나 이를 주의 깊게 다루고 Docker Compose 개념에 대해 꽤 꽤 잘 알고 있어야 합니다. 초심자들에게는 고급 구성으로 들어가기 전에 핵심 서비스 사용자 정의를 숙달해야 합니다.\n\n# 결론\n\nLaravel Sail은 사전 구성된 Docker 환경을 활용하여 Laravel 개발 워크플로우를 간소화할 수 있습니다. 하지만 진정한 매력은 사용자 정의할 수 있다는 점에 있습니다. Docker Compose 파일을 활용하여 Sail 설정을 프로젝트 요구 사항에 완벽히 맞게 조정할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사에서는 서비스 베이스 이미지 및 포트를 조정하여 볼륨을 마운트하고 사용자 정의 환경 변수를 정의하는 등 다양한 사용자 정의 옵션을 살펴보았습니다. 우리는 심화된 영역으로 들어가 커스텀 네트워크를 추가하고 서비스를 추가하며 Docker 시크릿을 활용하여 보안을 강화했습니다.\n\n기억하세요, 사용자 정의는 강력한 도구이지만 효과적으로 사용하려면 docker-compose.yml 파일과 Docker Compose 개념을 이해해야 합니다. 작은 규모로 시작하여 기본 사용자 정의를 실험하고 확신이 생기면 점진적으로 고급 옵션을 탐험해보세요.\n\n라라벨 Sail의 전체 잠재력을 발휘하고 싶나요? 깊이 있는 내용은 공식 Sail 문서를 참조하고 온라인 Docker Compose 자료의 방대한 세계를 탐험해보세요. 아래 댓글 섹션에서 여러분의 경험을 공유하고 질문해도 좋습니다. 즐거운 사용자 정의 되세요!\n","ogImage":{"url":"/assets/img/2024-06-19-HowtoCustomizeLaravelSailwithDockerComposeFiles_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoCustomizeLaravelSailwithDockerComposeFiles_0.png","tag":["Tech"],"readingTime":9},{"title":"FastAPI, Docker, 그리고 GCP를 활용하여 ML 솔루션 배포하는 방법","description":"","date":"2024-06-19 12:40","slug":"2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP","content":"\nFull Stack Data Science의 시리즈 중 5번째 기사입니다. 이 기사에서는 ML 기반 검색 API의 배포 방법을 안내합니다. 무수히 많은 방법으로 수행할 수 있지만, 여기에서는 거의 모든 머신 러닝 솔루션에 적용할 수 있는 간단한 3단계 접근법에 대해 설명합니다. 예시 코드는 GitHub 저장소에서 자유롭게 이용할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_0.png)\n\n머신 러닝이 모델 훈련에 관한 멋진 모델만이 아니라는 것을 생각하면, 실제로 모델 스스로는 가치를 만들어내지 않습니다. ML 모델을 ML 솔루션(즉, 가치 있는 것)으로 만들기 위해 \"배포\"해야 합니다.\n\n이를 다양한 형태로 구현할 수 있습니다. 예를 들어 사용자가 모델과 상호 작용할 수 있는 웹 인터페이스를 생성하거나, 기존 소프트웨어 시스템에 모델을 통합하거나, 개발자가 모델에 액세스할 수 있는 API를 설정하는 것 등이 있습니다 (OpenAI와 같은 사례를 생각해보세요).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기서 설명하는 3단계 전략은 모든 예제와 호환됩니다. 이는 다음으로 구성됩니다:\n\n- 추론 API 생성 (FastAPI 사용)\n- API 컨테이너화 (도커를 통해)\n- 클라우드 플랫폼에서 컨테이너 실행 (여기서는 GCP 사용)\n\n# FastAPI\n\n이 배포 전략의 첫 번째 단계는 모델을 API(즉, 응용 프로그램 프로그래밍 인터페이스)로 랩핑하는 것입니다. 간단히 말해, API를 사용하면 응용 프로그램과 프로그래밍 방식으로 상호 작용할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n첫 번째 단계를 수행하는 한 가지 방법은 파이썬 함수를 API 엔드포인트로 변환하는 매우 쉬운 방법을 제공하는 Python 라이브러리인 FastAPI를 사용하는 것입니다. 아래 코드는 구체적인 예제를 제공합니다.\n\n## Docker\n\n우리의 추론 API를 직접 클라우드에 배포할 수 있지만, 먼저 \"컨테이너화\"하는 것이 좋습니다. 이때 Docker가 필요합니다.\n\nDocker를 사용하면 API의 종속성을 모두 포함하는 가벼운 래퍼를 생성할 수 있어서 새로운 컴퓨터에서 더 쉽게 구동할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n작업은 2 단계 프로세스를 통해 수행됩니다. 첫째, 우리는 Docker 이미지를 생성합니다. 이는 기본적으로 시스템에 API를 제로에서 어떻게 구동할지 알려주는 레시피입니다 (걱정하지 마세요, 만들기 쉽습니다). 둘째, Docker가 설치된 시스템에서 이미지를 실행할 수 있습니다. 실행 중인 이미지를 컨테이너라고 하며, 이는 더 큰 시스템에 있는 작은 가상 머신과 같습니다.\n\n# Google Cloud Run\n\n마지막으로, Docker 이미지를 실행할 컴퓨팅 리소스가 필요합니다. 물론 노트북에서 이 작업을 수행할 수도 있지만 (아마 좋은 아이디어는 아닙니다), 온프레미스 서버나 클라우드 제공업체를 통해 이를 수행할 수 있습니다.\n\n여기서는 Google Cloud Run을 사용하여 Docker 컨테이너를 실행하는 GCP 서비스를 사용합니다. 이 서비스에는 무료 티어도 있으므로 불필요한 비용이 발생하지 않고 프로젝트를 배포할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 예시 코드: 시맨틱 검색 API 배포하기\n\n기본 개념을 이해했으니, 실제 코드에서 이 프로세스가 어떻게 보이는지 살펴봅시다. 아래 예시는 이 시리즈의 이전 기사들을 바탕으로 구축되었으며, 제 유튜브 비디오의 제목과 대본을 가져와 텍스트 임베딩으로 변환한 것을 사용합니다.\n\n간단히 말해, 텍스트 임베딩은 텍스트의 의미론적인 의미 있는 숫자 표현으로, 새로운 종류의 검색(시맨틱 검색이라고도 함)을 가능하게 합니다.\n\n여기에서는 제 유튜브 비디오의 모든 제목과 대본에 대한 시맨틱 검색 시스템을 위한 API를 구축하고 배포할 것입니다. 이 API는 Hugging Face spaces에서 실행되는 실시간 검색 애플리케이션의 백엔드입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 앱의 백엔드와 프론트엔드의 코드 저장소가 모두 무료로 제공됩니다.\n\n## 단계 1: API 만들기\n\nFastAPI를 사용하면 기존의 Python 스크립트를 몇 줄의 추가 코드로 API로 변환하는 것이 매우 쉽습니다. 이게 바로 그 모습입니다.\n\n먼저 유용한 라이브러리를 import할 거에요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nfrom fastapi import FastAPI\nimport polars as pl\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics import DistanceMetric\nimport numpy as np\nfrom app.functions import returnSearchResultIndexes\n```\n\n이제 우리는 시맨틱 검색 기능의 구성 요소를 정의할 겁니다. 구체적으로 텍스트 임베딩 모델, 우리가 검색하려는 비디오들의 제목 및 대본 임베딩, 그리고 사용자 쿼리에 가장 관련성 높은 비디오를 평가하는 거리 측정 기준입니다. 시맨틱 검색에 대해 더 깊게 알아보고 싶다면, 이에 대해 이전에 다룬 글을 참조해주세요.\n\n```js\n# define model info\nmodel_name = 'all-MiniLM-L6-v2'\n\n# load model\nmodel = SentenceTransformer(model_name)\n\n# load video index\ndf = pl.scan_parquet('app/data/video-index.parquet')\n\n# create distance metric object\ndist_name = 'manhattan'\ndist = DistanceMetric.get_metric(dist_name)\n```\n\n이제 API 작업을 정의합니다. 여기서 3개의 GET 요청을 생성할 것입니다. 첫 번째 요청은 아래 코드 블록에 표시되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\n# FastAPI 객체 생성\napp = FastAPI()\n\n# API 동작\n@app.get(\"/\")\ndef health_check():\n    return {'health_check': 'OK'}\n```\n\n위 블록에서는 FastAPI() 클래스를 사용하여 새 FastAPI 애플리케이션을 초기화하고 \"health check\" 엔드포인트를 만듭니다.\n\n이를 위해 입력이 없고 \"health_check\" 키와 값이 \"OK\"인 사전을 반환하는 Python 함수를 정의합니다. 이 함수를 API 엔드포인트로 변환하려면 단순히 데코레이터를 추가하고 엔드포인트의 경로를 지정하면 됩니다. 여기서는 루트인 즉, \"/\"를 사용합니다.\n\n또 다른 예제를 살펴보겠습니다. 여기서는 API에 대한 자세한 정보를 반환하는 info라는 엔드포인트가 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n@app.get(\"/info\")\ndef info():\n    return {'name': 'yt-search', 'description': \"Shaw Talebi의 YouTube 비디오를 검색하는 API입니다.\"}\n```\n\n이 엔드포인트는 헬스 체크와 매우 유사한 것을 볼 수 있습니다. 그러나 이것은 \"/info\" 엔드포인트에 위치합니다.\n\n마지막으로 사용자 쿼리를 받아 가장 관련 있는 비디오의 제목과 ID를 반환하는 검색 엔드포인트를 만들어 봅시다.\n\n```js\n@app.get(\"/search\")\ndef search(query: str):\n    idx_result = returnSearchResultIndexes(query, df, model, dist)\n    return df.select(['title', 'video_id']).collect()[idx_result].to_dict(as_series=False)\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 엔드포인트에는 입력이 필요합니다: 사용자의 쿼리입니다. 이 쿼리는 다른 스크립트에 정의된 또 다른 Python 함수로 전달됩니다. 이 함수는 검색에 대한 모든 수학 연산을 수행합니다. 여기서 자세히 다루지는 않겠지만, 궁금한 독자는 코드를 GitHub에서 볼 수도 있고 YouTube에서 검색 함수의 코드 설명을 볼 수도 있습니다.\n\n이 함수는 검색 결과의 행 번호만 df 데이터프레임에서 반환하므로, 우리는 이 출력을 사용하여 관심 있는 제목과 비디오 ID를 가져와서 이를 Python 사전으로 반환해야 합니다. API 엔드포인트의 모든 출력이 사전이어야 하는데요, 이는 API의 표준 JSON 형식을 준수하기 때문입니다.\n\n위 코드 블록에서 설명한대로, 두 개의 외부 파일인 app/functions.py 및 app/data/video-index.parquet을 참조합니다. 이는 다음 디렉토리 구조를 시사합니다.\n\n![image](https://example.com/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 API를 로컬에서 실행하려면 루트 디렉토리로 이동하여 다음 명령을 실행할 수 있습니다.\n\n```js\nuvicorn app.main:app --host 0.0.0.0 --port 8080\n```\n\nuvicorn은 FastAPI를 사용하여 작성한 웹 애플리케이션을 실행할 수 있게 해주는 파이썬 라이브러리입니다. 이 명령은 이 API를 로컬에서 http://0.0.0.0:8080에서 실행합니다. 나중에 Google Cloud Run에 배포할 때 이 호스트와 포트를 사용하는 이유를 나준내게 될 것입니다.\n\n## 단계 2: 도커 이미지 생성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우와, 우리 API가 로컬에서 작동하고 있어요! 이제 클라우드에서 실행할 수 있도록 다음 단계를 진행해 봐요.\n\n이를 위해서 API용 Docker 이미지를 생성할 거에요. 이를 위해 Dockerfile, requirements.txt, 그리고 app/**init**.py 이 3가지 파일을 만들어야 해요. 우리 디렉토리는 아래와 같이 보여야 해요.\n\n![이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_2.png)\n\nDockerfile은 Docker 이미지를 실행하는 단계별 지침을 포함하고 있어요. requirements.txt는 API를 실행하는 데 필요한 Python 라이브러리(버전 포함)를 지정해요. 마지막으로 app/**init**.py 파일은 app 폴더를 Python 패키지로 지정해주어, 컨테이너에서 실행될 때 Python이 API 코드를 찾고 적절하게 가져올 수 있도록 해줘요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 Dockerfile 내부의 내용입니다.\n\n```js\n# python 기본 이미지에서 시작\nFROM python:3.10-slim\n\n# 작업 디렉토리 변경\nWORKDIR /code\n\n# 요구 사항 파일을 이미지에 추가\nCOPY ./requirements.txt /code/requirements.txt\n\n# Python 라이브러리 설치\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\n# Python 코드 추가\nCOPY ./app/ /code/app/\n\n# 기본 명령어 지정\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n```\n\n첫 번째 줄은 기존에 Python 3.10이 설치된 이미지 위에 저희의 이미지를 부트스트랩합니다. 다음으로 작업 디렉토리를 루트에서 /code로 변경합니다.\n\n그런 다음 요구 사항 파일을 코드베이스에서 Docker 이미지로 복사합니다. 이를 통해 pip를 사용하여 요구 사항을 설치할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그 다음으로, API에 대한 모든 코드를 복사합니다.\n\n참고: Python 패키지를 먼저 복사하고 설치했습니다. 이렇게 함으로써 요구 사항의 설치를 캐시할 수 있습니다. 개발 중에 빠르게 Docker 이미지를 실행할 때 의존성을 설치하는 데 몇 분을 기다릴 필요가 없도록 도와줍니다.\n\n마지막으로, 개발 중에 API를 실행할 때 지역에서 실행했던 것과 동일한 기본 명령을 지정합니다.\n\n## 단계 3: Google Cloud에 배포\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 시점에서 우리는 Docker 이미지를 빌드하고 Docker Hub에 푸시하여 여러 다른 클라우드 서비스에 쉽게 배포할 수 있습니다. 하지만 여기서는 대안 전략을 따를 거에요.\n\n대신에, 우리 모든 코드를 GitHub에 푸시할 거에요. 그럼 바로 이 코드를 Google Cloud Run에 컨테이너 배포할 수 있어요. 이 방법에는 두 가지 주요 장점이 있어요.\n\n첫째로, 로컬 시스템과 Google Cloud Run이 사용하는 시스템 아키텍처 간의 차이를 해결하느라 시간을 들일 필요가 없어요 (특히 저는 Mac이 ARM64로 동작하기 때문에 이 문제가 있었어요). 둘째로, GitHub 리포지토리에서 배포함으로써 지속적인 배포가 가능해져요. 그래서 API를 업데이트하고 싶다면, 그냥 새 코드를 리포지토리에 푸시하면 새 컨테이너가 자동적으로 생성돼요.\n\n우리는 새 GitHub 리포지토리를 만들면서 시작해볼게요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_3.png\" />\n\n이제 리포지토리를 복제하고 코드를 추가한 후 GitHub로 푸시합니다. 코드를 추가한 후 디렉토리 구조는 다음과 같이 보입니다.\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_4.png\" />\n\n코드가 준비되었으면 새 Google Cloud Platform 프로젝트를 만들 수 있습니다. GCP 콘솔로 이동하여 프로젝트 목록을 클릭한 다음 \"새 프로젝트\"를 선택하여 진행합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_5.png\" />\n\n프로젝트가 생성되면 해당 프로젝트를 열고 검색 창에 \"cloud run\"을 입력할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_6.png\" />\n\n그것을 열면 \"CREAT SERVICE\"를 클릭할 것입니다. 이렇게 하면 서비스를 구성할 수 있는 페이지가 열립니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 GitHub에서 서비스를 배포할 옵션을 선택합니다. 그런 다음 \"CLOUD BUILD로 설정\"을 클릭하세요.\n\n[이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_7.png)\n\n저장소 소스로는 GitHub을 선택하고 방금 만든 저장소를 선택합니다.\n\n[이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지점을 ^main$으로 유지하고 \"Build Type\"을 Dockerfile로 선택합니다.\n\n![이미지](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_9.png)\n\n다음으로, 서비스 구성 화면으로 돌아갑니다. 서비스의 이름을 마음대로 지정할 수 있습니다 (저는 자동 생성된 이름을 그대로 두겠습니다). 지역은 us-central1로 남겨두겠습니다. 이 지역은 가장 저렴한 컴퓨팅 옵션을 제공하는 Tier 1이기 때문에 이 예시에서는 무료입니다.\n\n간단히 유지하려면 \"인증되지 않은 호출 허용\"을 선택합니다. 물론 대부분의 시스템에는 인증이 필요할 것입니다. 그런 다음, 나머지를 기본값으로 남겨둡니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 \"컨테이너, 볼륨, 네트워킹, 보안\" 아래에서 컨테이너를 편집하여 1 GiB의 메모리를 할당하세요. Dockerfile에서 구성한 대로 PORT가 8080으로 설정되어 있기 때문에 이것을 변경하시면 안 됩니다.\n\n나머지 설정은 기본값으로 그대로 두고 화면 아래의 \"생성\"을 클릭하세요. 수 분 후 컨테이너가 활성화될 것입니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_12.png)\n\n그런 다음 페이지 상단 근처에 지정된 URL을 사용하여 API에 액세스할 수 있습니다. 링크를 클릭하면 루트 엔드포인트가 열립니다. 이 엔드포인트는 건강 상태 확인이었습니다.\n\n![image](/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_13.png)\n\n다음 URL을 사용하여 검색 API에 대한 GET 요청을 수동으로 실행할 수 있습니다: [여기에 앱의 URL 입력]/search?query=LLMs. 이를 통해 LLMs와 관련된 비디오를 검색할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_14.png\" />\n\n## 보너스: UI에 통합하기\n\nAPI 백엔드를 설정한 후, 사용자 친화적 인터페이스에 연결할 수 있습니다. 저는 Hugging Face Spaces를 통해 이를 수행합니다. 이 곳은 완전히 무료로 ML 앱을 호스팅합니다.\n\n이것이 같은 검색이 UI를 통해 어떻게 보이는지입니다. 여기서 UI를 테스트하고 코드를 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](https://miro.medium.com/v2/resize:fit:1200/1*St0OCAxBpqORc95WDpq4Pg.gif)\n\n# 결론\n\n데이터 과학은 멋진 모델을 훈련시키는 것 이상의 의미를 가지고 있습니다. 문제를 해결하고 가치를 창출하는 것이 중요합니다. 종종, 이를 위해서는 모델을 배포하여 최대 효과를 발휘할 수 있는 환경으로 이전해야 합니다. 여기에서는 FastAPI, Docker 및 GCP를 사용하여 ML 모델을 배포하는 간단한 3단계 전략을 살펴보았습니다.\n\n풀 스택 데이터 과학 시리즈를 마치는 글이지만, 이 글들은 이 검색 도구를 생성하는 과정에 관련된 실험에 대한 보너스 비디오가 포함된 YouTube 플레이리스트와 함께 제공됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nFull Stack Data Science에 관해 더 알아보기 👇\n\n# 자료\n\n연결하기: [내 웹사이트](링크) | 전화 상담 예약\n\n소셜 미디어: [YouTube 🎥](링크) | [LinkedIn](링크) | [Twitter](링크)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSupport: 커피 한 잔 사주세요 ☕️\n","ogImage":{"url":"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoDeployMLSolutionswithFastAPIDockerandGCP_0.png","tag":["Tech"],"readingTime":16},{"title":"컨테이너화된 모델과 작업 보안하기","description":"","date":"2024-06-19 12:37","slug":"2024-06-19-SecuringyourContainerisedModelsandWorkloads","content":"\n컨테이너화는 이제 많은 어플리케이션을 배포하는 주요 수단이 되었으며, Docker가 이를 주도하며 보급되고 있습니다. 그 인기에 따라 공격 위험이 증가하고 있습니다. 따라서 Docker 어플리케이션을 안전하게 지킬 필요가 있습니다. 이를 위한 가장 기본적인 방법은 컨테이너 내 사용자를 루트 사용자가 아닌 일반 사용자로 설정하는 것입니다.\n\n```js\n컨텐츠\n========\n\n왜 루트 사용자가 아닌 사용자를 사용해야 하는가?\n\n기본 일반 사용자로서 할 수 있는 일과 할 수 없는 일\n\n네 가지 시나리오\n  1) 호스트에서 모델 제공 (읽기 전용)\n  2) 데이터 처리 파이프라인 실행 (컨테이너 내에서 쓰기)\n  3) 라이브러리가 자동으로 파일 작성 (컨테이너 내에서 쓰기)\n  4) 훈련된 모델 저장 (호스트에 쓰기)\n\n요약\n```\n\n# 왜 루트 사용자가 아닌 사용자를 사용해야 하는가?\n\n혹은 왜 루트 사용자를 사용하지 말아야 하는가? 아래의 가짜 아키텍처 예제를 살펴봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Containerized Security](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png)\n\n보안은 종종 다층 접근법으로 간주됩니다. 공격자가 컨테이너에 들어갈 경우 사용자로서 가지는 권한이 첫 번째 방어층이 됩니다. 만약 컨테이너 사용자가 루트 액세스를 할당받는다면, 공격자는 컨테이너 내 모든 것을 자유롭게 제어할 수 있습니다. 이러한 넓은 액세스로 인해 잠재적인 취약점을 이용하여 호스트로 탈출하고 모든 연결된 시스템에 완전한 액세스를 획들할 수도 있습니다. 그 결과는 심각하며 다음과 같습니다:\n\n- 저장된 비밀 정보를 회수\n- 트래픽을 가로채거나 방해\n- 암호화 채굴과 같은 악성 서비스 실행\n- 데이터베이스와 같은 연결된 민감한 서비스에 액세스 획득\n\n![Containerized Security](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n와우, 그건 정말 무섭게 들리네요! 그러나 해결 방법은 간단합니다. 컨테이너를 루트 사용자가 아닌 다른 사용자로 변경하세요!\n\n우리가 나머지 기사를 읽기 전에, 리눅스 권한과 액세스 권한에 대한 좋은 이해가 없다면, 제 이전 기사를 꼭 확인해 보세요 [2].\n\n# 기본 비루트 사용자로서 할 수 있고 할 수 없는 것\n\n기본 비루트 사용자로 간단한 도커 어플리케이션을 만들어 보겠습니다. 아래의 도커 파일을 사용하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```docker\n# Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# create a dummy py file\nRUN echo \"print('I can run an existing py file')\" > example.py\n\n# create & switch to non-root user\nRUN adduser --no-create-home nonroot\nUSER nonroot\n```\n\nMake sure to build the image and create a container using the following commands:\n\n```docker\ndocker build -t test .\ndocker run -it test bash\n```\n\nOnce you are inside the container, feel free to try out various commands. Keep in mind that certain actions like writing to restricted directories or installing software may not be permitted due to restricted permissions.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_2.png\" />\n\n반대로, 우리는 모든 종류의 읽기 권한을 실행할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_3.png\" />\n\n파이썬이 설치되어 있기 때문에 약간 독특합니다. ls -l $(which python)을 실행하면 파이썬 인터프리터에 완전한 권한이 있음을 볼 수 있습니다. 따라서 Dockerfile에서 처음에 만든 example.py 파일과 같은 기존의 파이썬 파일을 실행할 수 있습니다. 심지어 파이썬 콘솔에 들어가 간단한 명령을 실행할 수도 있습니다. 그러나 비 루트 사용자로 전환하면 다른 시스템 쓰기 권한이 제거된 것을 알 수 있습니다. 그렇기 때문에 스크립트를 생성하거나 수정하거나 파이썬을 사용해 쓰기 명령을 실행할 수 없음을 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_4.png)\n\n시스템 전반적인 제한은 보안에 좋지만, 특정 파일 및 디렉터리에 대한 쓰기 권한이 필요한 경우가 많이 발생하며, 그러한 허용 사항에 대응해야 합니다.\n\n다음 섹션에서는 기계 학습 운영 수명 주기의 네 가지 시나리오 예제를 제공합니다. 이러한 예제를 통해 대부분의 다른 경우에 대한 구현 방법을 이해할 수 있을 것입니다.\n\n# 네 가지 시나리오\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 1) 호스트에서 모델 제공하기 — 읽기 전용\n\n모델을 제공할 때, 추론 및 서빙 스크립트를 활용하여 모델을 로드하고 API를 통해 노출시킵니다 (예: Flask, FastAPI) 입력을 받도록 합니다. 때로는 모델이 호스트 머신에서 로드되어 이미지와 분리되어 이미지 크기가 최적으로 작고, 이미지를 다시 로드할 경우 반복적인 모델 다운로드 없이 최적으로 빠르게 할 수 있도록 합니다. 그런 다음 모델은 바인드-마운트 볼륨을 통해 컨테이너로 전달되어 로드되고 제공됩니다.\n\n<img src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_5.png\" />\n\n이것은 비루한 사용자를 구현하는 가장 번거롭지 않은 방법일 것입니다. 기본적으로 모든 사용자에게 부여되는 읽기 권한만 필요하기 때문입니다. 아래는 그 작업이 어떻게 이루어지는지를 보여주는 샘플 Dockerfile입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Dockerfile\n\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip3 install --no-cache-dir --upgrade pip~=23.2.1 \\\n && pip3 install --no-cache-dir -r requirements.txt\n\nCOPY ./project/ /app\n\n# add non-root user ---------------------\n\nRUN adduser --no-create-home nonroot\n\n# switch from root to non-root user -----\n\nUSER nonroot\n\nCMD [\"python\", \"inference.py\"]\n\n이 Dockerfile은 먼저 nonroot라는 새로운 시스템 사용자를 만드는 두 가지 간단한 명령어를 가지고 있습니다. 두 번째로, 마지막 CMD 라인 바로 전에 루트에서 nonroot 사용자로 전환됩니다. 기본 non-root 사용자의 경우 쓰기 및 실행 권한이 없기 때문에, 이전 단계에서 필요한 파일을 설치하거나 복사하거나 조작할 수 없습니다.\n\n이제 Docker에서 non-root 사용자를 할당하는 방법을 알았으니, 다음 단계로 넘어가 봅시다.\n\n## 2) 데이터 처리 파이프라인 실행하기 — 컨테이너 내에서 작성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가끔은 작업을 실행하기 위해 일시적인 파일을 저장하고 싶을 때가 있습니다. 예를 들어, 데이터 전처리 작업을 한다고 가정해봅시다. 파일을 추가하고 삭제하는 작업으로 이루어져 있죠. 파일이 영구적이지 않기 때문에 이런 작업은 컨테이너 내에서 수행할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_6.png)\n\n그러나 루트가 아닌 사용자를 사용한다면 쓰기 권한이 필요할 것입니다. 이를 위해 chown(소유자 변경) 명령을 사용하여 쓰기 액세스가 필요한 특정 폴더에 소유권을 할당해야 합니다. 이 작업을 완료하면 사용자를 루트가 아닌 사용자로 전환할 수 있습니다.\n\n```Dockerfile\n# Dockerfile\n\n# ....\n\n# 루트가 아닌 사용자 추가 및 처리 폴더에 소유권 부여\nRUN adduser --no-create-home nonroot && \\\n    mkdir processing && \\\n    chown nonroot processing\n\n# 루트에서 루트가 아닌 사용자로 전환\nUSER nonroot\n\nCMD [\"python\", \"preprocess.py\"]\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 3) 라이브러리가 파일을 자동으로 작성하는 경우 - 컨테이너 내에서 작성\n\n이전 예시에서는 우리가 직접 만든 파일을 작성하는 방법을 보여줬어요. 그러나 사용하는 라이브러리가 파일과 디렉토리를 자동으로 만드는 경우가 흔합니다. 컨테이너를 실행해 보고 쓰기 권한이 거부되는 것을 알 수 있을 때 그것들이 만들어진 것임을 알게 될 거예요.\n\n저는 두 가지 예시를 보여드릴 거에요. 하나는 여러 프로세스를 관리하는 데 사용되는 supervisor에서 가져왔고, 다른 하나는 huggingface에서 모델을 다운로드할 때 사용하는 huggingface-hub에서 가져왔어요. 이러한 권한 오류들은 우리가 루트가 아닌 사용자로 전환할 때 볼 수 있을 거에요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Securing your Containerised Models and Workloads](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_8.png)\n\n![Securing your Containerised Models and Workloads](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_9.png)\n\n두 개의 슈퍼바이저 파일에 대해서 먼저 빈 파일로 생성하고 소유권 권한을 할당할 수 있습니다. Huggingface-hub 다운로드 문제에 대해 이미 오류 로그에서 TRANSFORMERS_CACHE 변수를 통해 다운로드 디렉토리를 변경할 수 있다는 힌트가 있었습니다. 따라서 먼저 디렉토리 변수를 할당하고, 디렉토리를 생성한 후 소유권을 할당할 수 있습니다.\n\n```js\n# Dockerfile\n\n# ....\n\n# non-root 사용자 추가 ................\n# huggingface 다운로드 디렉토리 변경\nENV TRANSFORMERS_CACHE=/app/model\n\nRUN adduser --no-create-home nonroot && \\\n    # 슈퍼바이저 파일 및 huggingfacehub 디렉토리 생성\n    touch /app/supervisord.log /app/supervisord.pid && \\\n    mkdir $TRANSFORMERS_CACHE && \\\n    # 슈퍼바이저 및 huggingfacehub 쓰기 권한 부여\n    chown nonroot /app/supervisord.log && \\\n    chown nonroot /app/supervisord.pid && \\\n    chown nonroot $TRANSFORMERS_CACHE\nUSER nonroot\n\nCMD [\"supervisord\", \"-c\", \"conf/supervisord.conf\"]\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n물론 여기에 제시된 것과 약간 다른 다른 예제가 있을 수 있습니다만, 쓰기 권한을 최소화하는 개념은 동일할 것입니다.\n\n## 4) 훈련된 모델 저장하기 — 호스트에 쓰기\n\n모델을 훈련하는 데 컨테이너를 사용하고 그 모델을 호스트에 쓰기를 원한다고 가정해 봅시다. 예를 들어, 모델을 준비하여 다른 작업에서 평가하거나 배포하기 위해 호스트에 쓰려고 하는 경우입니다. 이 경우에는 모델 파일을 쓰기 위해 컨테이너 디렉토리를 호스트 디렉토리에 연결하여 모델 파일을 기록해야 합니다. 이를 바인드 마운트라고도 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저, 우리는 nonroot를 위한 그룹과 사용자를 만들어야 합니다. 각각에 대해 고유한 ID를 지정하는데, 이 경우에 우리는 1001을 사용합니다 (1000 이상의 아무 숫자나 상관없습니다). 그런 다음, 모델을 저장할 모델 디렉토리를 생성합니다.\n\nScenario 2와 비교하여 여기서의 차이점은 모델 디렉토리에 대해 쓰기 권한을 설정하는 데 chown이 필요하지 않다는 것입니다. 왜냐하면?\n\n```js\n# Dockerfile\n\n# ....\n# add non-root group/user & create model folder\nENV UID=1001\nRUN addgroup --gid $UID nonroot && \\\n    adduser --uid $UID --gid $UID --no-create-home nonroot && \\\n    mkdir model\n\n# switch from root to non-root user\nUSER nonroot\n\nCMD [\"python\", \"train.py\"]\n```\n\n이는 bind-mounted 디렉토리의 권한이 호스트 디렉토리에서 결정되기 때문입니다. 따라서 우리는 호스트에서 다시 동일한 사용자를 만들어야 하며, 사용자 ID가 동일한지 확인해야 합니다. 그런 다음에 호스트에 모델 디렉토리를 만들고 nonroot 사용자에게 소유자 권한을 부여합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 호스트 터미널에서\n\n# 동일한 사용자 및 그룹 추가\naddgroup --gid 1001\nadduser --uid 1001 --gid 1001 --no-create-home nonroot\n# 바인드 마운트할 모델 디렉토리 만들고 nonroot를 소유자로 설정\nmkdir /home/model\nchown nonroot /home/model\n```\n\n바인드 마운트는 보다 유연성을 제공하기 위해 일반적으로 docker-compose.yml 파일이나 docker run 명령어에서 지정됩니다. 아래는 전자의 예시입니다.\n\n```js\nversion: \"3.5\"\n\nservices:\n    modeltraining:\n        container_name: modeltraining\n        build:\n            dockerfile: Dockerfile\n        volumes:\n            - type: bind\n              source: /home/model # 호스트 디렉토리\n              target: /app/model  # 컨테이너 디렉토리\n```\n\n그리고 후자에 대한 예시는 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```docker\ndocker run -d --name modeltraining -v /home/model:/app/model <image_name>\n```\n\n아무거나 실행하시면, 비루트 사용자로 스크립트를 실행할 수 있음을 확인하실 수 있을 거예요.\n\n# 요약\n\n우리는 비루트 사용자를 할당하고도 컨테이너가 원하는 작업을 수행할 수 있는 방법을 살펴보았어요. 이는 특정 쓰기 권한이 필요할 때 주로 관련이 있어요. 그저 두 가지 기본 개념만 알면 돼요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 컨테이너에서의 쓰기 권한을 위해서는 Dockerfile에서 chown을 사용하세요.\n- 바인드 마운트를 위한 쓰기 권한은 호스트에서 동일한 비루트 사용자를 생성하고 호스트 디렉토리에서 chown을 사용하세요.\n\n루트 사용자로 일부 테스트를 실행하기 위해 도커 컨테이너로 들어가야할 때 다음 명령어를 사용할 수 있어요.\n\n```js\ndocker exec -it -u 0 <컨테이너_아이디/이름> bash\n```\n\n# 참고자료\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- [1] Wong et al. (2023) 컨테이너 보안에 관한: 위협 모델링, 공격 분석 및 완화 전략. 컴퓨터 및 보안, 제 128권.\n- [2] Linux 권한 및 접근 권한에 관한 이전 게시물: https://medium.com/@teosiyang/securing-linux-servers-with-two-commands-de5b565dc104\n","ogImage":{"url":"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png"},"coverImage":"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png","tag":["Tech"],"readingTime":13},{"title":"마이크로서비스 이해 소프트웨어 아키텍처에 대한 현대적인 접근법","description":"","date":"2024-06-19 12:34","slug":"2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture","content":"\n마이크로서비스\n\n마이크로서비스와 보안\n\n사가 패턴: 코레오그래피와 오케스트레이션\n\nAXON을 활용한 사가\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSage와 Eventuate를 이용한 트랜잭션 외부함으로 패턴 구현하기\n\n마이크로서비스에서의 전파\n\n# 소개\n\n이 블로그에서는 소프트웨어 개발의 풍경을 변화시킨 혁신적인 접근 방식인 마이크로서비스 아키텍처의 매력적인 세계에 대해 탐구해 보겠습니다. Netflix와 같은 선두 기업들이 전통적인 방법론과 관련된 공통적인 도전 과제를 극복하기 위해 이 아키텍처를 채택했습니다. 마이크로서비스의 흥미진진한 영역으로 뛰어들기 전에, 먼저 거대한(monolithic) 아키텍처 및 그 한계를 이해하는 것이 중요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 코드 링크입니다: [https://github.com/Blogs4Devs/Microservices](https://github.com/Blogs4Devs/Microservices).\n\n# Monolithic architecture\n\n전통적인 모놀리식 아키텍처에서는 전체 애플리케이션이 하나의 프로세스로 실행되며, 모든 애플리케이션 구성 요소가 서로 연결되어 의존하며 하나의 단일 단위로 묶여 있습니다. 이는 사용자 인터페이스, 비즈니스 로직 및 데이터 액세스 레이어가 모두 단일 프로그램의 일부라는 것을 의미합니다.\n\n![img](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 모놀리식 애플리케이션의 단점:\n\n- 확장성 문제:\n\n모놀리식 애플리케이션 내의 특정 서비스가 많은 호출을 받아 확장해야 하는 경우 전체 애플리케이션을 확장해야 합니다. 이는 전체 애플리케이션의 추가 인스턴스를 실행해야 하는 것을 의미하며, 이는 리소스를 많이 소비하고 비효율적입니다. 과부하된 구성 요소만 확장하는 대신 전체 시스템을 확장해야 하므로 불필요하게 리소스를 사용하게 됩니다.\n\n- 배포 속도가 느림:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n대규모 응용 프로그램에서는 작은 변경사항도 전체 응용 프로그램을 다시 컴파일하고 배포해야 합니다. 이로 인해 배포 주기가 크게 느려지며 전체 시스템을 테스트하고 통째로 배포해야 하므로 지속적인 배포가 어려워질 수 있습니다.\n\n- 기술 채택에 대한 장벽:\n\n대규모 응용 프로그램은 일반적으로 한 가지 언어 또는 프레임워크로 작성되어 있어 전체 개발 팀이 해당 특정 기술을 알고 있어야 합니다. 이는 특정 작업에 더 적합한 새로운 기술이나 언어를 채택하는 능력을 제한할 수 있습니다.\n\n- 코드 변경 및 테스트가 어려운 문제:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모놀리식 애플리케이션에서는 전체 시스템의 모든 로직이 얽혀있어 코드베이스가 복잡하고 관리하기 어렵습니다. 애플리케이션의 한 부분에 변경이 있을 때 다른 부분에 예상치 못한 영향을 미치는 경우가 많아 테스트와 유지보수가 어려워집니다. 이 복잡성은 버그를 분리하고 수정하기도 어렵게 만들어서 개발 주기를 늘릴 수 있습니다.\n\n이러한 단점을 이해하면 많은 기관이 더 큰 유연성, 확장성 및 유지보수 편의성을 제공하는 마이크로서비스 아키텍처로 전환하려는 이유가 분명해집니다.\n\n# 마이크로서비스 아키텍처\n\n마이크로서비스 아키텍처는 애플리케이션을 작은, 느슨하게 결합된 서비스로 분해하여 각각이 특정 비즈니스 기능을 담당하게 합니다. 이러한 서비스들은 독립적으로 개발, 배포 및 확장할 수 있어 모놀리식 아키텍처보다 여러 이점을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_1.png\" />\n\n다음은 마이크로서비스 아키텍처의 주요 이점 요약입니다:\n\n- 느슨한 결합:\n\n마이크로서비스는 각각 물리적으로 분리되어 있기 때문에 느슨하게 결합되어 있습니다. 이 분리로 인해 각 서비스는 개별적으로 개발, 배포 및 확장될 수 있어 다른 서비스에 영향을 미치지 않고 독립적으로 변경이 가능합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 독립성 팀:\n\n다른 팀은 서로 독립적으로 다른 마이크로서비스에 작업할 수 있습니다. 이 상대적 독립성은 병렬 개발을 가능케하며 전체 개발 프로세스를 가속화하고 효율성을 향상시킬 수 있습니다.\n\n- 테스트 및 배포의 용이성:\n\n마이크로서비스 아키텍처는 테스트와 배포를 쉽게 할 수 있게 해줍니다. 각 서비스가 별도의 단위이기 때문에 독립적으로 테스트하고 배포할 수 있어 테스트의 복잡성을 줄이고 배포 주기를 가속화할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 지속적 배포:\n\n마이크로서비스는 지속적인 배포 방법에 잘 맞습니다. 각 서비스는 전체 시스템에 영향을 미치지 않고 지속적으로 업데이트되고 배포될 수 있어 더 자주 릴리스하고 빠른 업데이트가 가능해집니다.\n\n이제, 마이크로서비스 아키텍처를 구성하는 주요 구성 요소를 살펴보겠습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_2.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 게이트웨이\n\n프로덕션 환경에서는 마이크로서비스와의 직접 통신이 허용되지 않습니다. 대신, 모든 마이크로서비스는 중개자(일반적으로 미들웨어 또는 API 게이트웨이)와 상호 작용하는 단일 응용 프로그램으로 그룹화되어 처리되어야 합니다. 이 중개자는 로드 밸런서 역할을 하여 들어오는 요청을 마이크로서비스에 골고루 분배하여 부하를 균형 있게 유지하고 최상의 성능을 보장합니다. 미들웨어가 단일 장애 지점(SPOF)이 될 수 있지만, 이러한 위험은 중복 및 고가용성 설정을 통해 강력하고 신뢰할 수 있는 작동을 보장함으로써 완화됩니다.\n\n게이트웨이를 구성하는 두 가지 방법이 있습니다 :\n\n- 정적 구성: 소수의 마이크로서비스를 다룰 때, 미들웨어를 정적으로 구성하여 특정 경로를 지정된 IP 주소로 라우팅할 수 있습니다. 예를 들어, /path1는 주소 1로, /path2는 주소 2로 이동할 수 있습니다. 이 구성에서는 마이크로서비스의 IP 주소를 알아야 하며, 마이크로서비스가 중지되거나 IP 주소가 변경되면 설정을 업데이트해야 합니다.\n- 동적 구성: 여러 마이크로서비스가 동적으로 시작 및 중지되는 환경에서는 정적 구성만으로는 충분하지 않습니다. 여기서는 발견 서비스를 통한 동적 구성이 필수적입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 발견 서비스\n\n발견 서비스는 디렉터리처럼 작동합니다 (DNS 또는 SOAP의 UDDI와 유사함). 마이크로서비스는 시작할 때 발견 서비스에 등록됩니다. 그런 다음 게이트웨이는 마이크로서비스의 현재 IP 주소를 확인하기 위해 서비스 레지스트리에 쿼리하도록 구성되어 라우팅 구성을 자동으로 업데이트할 수 있습니다.\n\n# 구성 서비스\n\n- 콜드 구성: 각 마이크로서비스는 자체 구성 파일(예: application.properties)을 갖습니다. 이러한 파일에 대한 수정은 해당 마이크로서비스를 다시 시작해야 합니다. 또한, 구성 설정이 여러 마이크로서비스 간에 공유되는 경우 각 개별 구성 파일을 따로 업데이트해야 합니다. 동일한 마이크로서비스의 여러 인스턴스가 실행 중인 경우 변경 사항을 각 인스턴스에 개별적으로 적용해야 하므로 불편하고 실수를 유발할 수 있는 프로세스가 됩니다.\n- 핫 구성: 중앙 집중식 구성 서비스는 단일 전역 구성 파일을 유지합니다. 이 파일의 변경 사항은 마이크로서비스에 자동으로 전파되어 다시 시작할 필요가 없습니다. 일반적으로 이 구성은 Git과 같은 버전 관리 리포지토리를 통해 관리됩니다. 구성 매개변수가 변경되면 커밋이 수행되고 특정 변경 사항만 마이크로서비스로 전송됩니다. 전체 구성 파일이 아니라 특정 변경 사항만 전송되므로 모든 마이크로서비스에서 효율적이고 일관된 구성 관리가 보장됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 커뮤니케이션 모델\n\n- 동기식 통신: 누군가에게 길을 물어본다고 상상해봅니다. 동기식 통신에서는 \"공원에 어떻게 가요?\" 라고 물어보고 그 후 그들이 답변할 때까지 그 자리에 기다립니다. 답변을 듣고 나서야만 앞으로 나아갑니다. 이는 마이크로서비스가 서로와 대화하는 방식과 유사합니다. 한 서비스가 무언가를 요청하고, 답변을 기다리며, 그것을 받은 후에만 다음 단계로 넘어갑니다. 이 방법은 빠르고 직관적이지만, 상대 서비스가 응답하는 데 오랜 시간이 걸리면 느릴 수 있습니다.\n\n![이미지1](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_3.png)\n\n![이미지2](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 비동기 통신: 이제, 지시를 기다리는 대신 \"공원에 가고 있어. 만나야 할 일이 있으면 알려줘\"라는 메모를 남기는 상황을 상상해봐. 그럼 너는 그냥 걷어가서 다른 일을 계속 한다. 나중에 답변이 있는지 확인하기 위해 메모를 확인한다. 이것은 메시지 브로커와 함께 하는 비동기 통신과 비슷하다. 한 서비스가 응답을 기다리지 않고 다른 서비스로 메시지를 보낸다. 메시지는 중개인(브로커)에게 보내지고, 그 이후 브로커가 다른 서비스에 전달한다. 보내는 서비스는 기다리지 않고 작업을 계속할 수 있다. 이것은 즉각적인 답변이 필요하지 않고 메시지가 도착했을 때 처리할 수 있는 경우에 좋다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_5.png)\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_6.png)\n\n우리는 Reactive 프로그래밍에 관한 다가오는 블로그에서 이 두 가지 모델을 자세히 살펴볼 것이다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 데모\n\n이 데모에서는 Spring 프레임워크를 사용하여 간단한 마이크로서비스 시스템을 구축하는 방법을 살펴보겠습니다. 특히 Spring Boot와 Spring Cloud에 초점을 맞출 것입니다. 이러한 도구들은 마이크로서비스를 쉽게 구축하고 관리할 수 있도록 설계되었습니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_7.png)\n\n이 데모에서는 두 개의 마이크로서비스인 고객 서비스와 계정 서비스가 있을 것입니다. 각 마이크로서비스는 간단한 Spring Boot 애플리케이션으로, 공통 종속성인 Lombok, Spring Data JPA, H2 Database, Spring Web을 사용해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 고객 서비스: 고객을 관리합니다.\n\n다음은 Customer 모델입니다.\n\n![Customer Model](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_8.png)\n\n- 계정 서비스: 고객에게 속한 각 계정을 관리합니다. 각 마이크로서비스는 자체 데이터베이스를 갖기 때문에, 계정 서비스 데이터베이스는 각 계정에 대해 고객 ID만 저장합니다. 이 고객 ID는 고객 서비스 데이터베이스에 존재해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 참조 무결성 보장하기\n\n참조 무결성은 테이블 간의 관계가 일관적으로 유지되도록 보장합니다. 이 시나리오에서의 적용 방법은 다음과 같습니다:\n\n계정 추가:\n\n- 새 계정을 추가하려면 계정 서비스 데이터베이스에 고객 ID만 저장합니다.\n- 참조 무결성을 보장하려면 고객 ID가 고객 서비스 데이터베이스에 존재하는지 확인해야 합니다.\n- 이를 위해 계정을 추가하기 전에 고객 ID가 유효한지 확인하기 위해 고객 서비스를 호출해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 Account 모델입니다.\n\n![Account Model](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_9.png)\n\n@Transient는 데이터베이스에 저장되지 말아야 하는 필드를 나타내는 주석입니다. 이 경우 accounts 데이터베이스에 customer 테이블이 없고 외래 키도 없기 때문에 customer 필드는 고객 서비스를 쿼리하여 수동으로 생성됩니다.\n\n# Discovery service\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금 새로운 스프링 부트 응용 프로그램을 시작하려고 하는데, 이번에는 이 종속성을 추가해야 합니다.\n\n![dependency](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_10.png)\n\n그런 다음 메인 클래스에 @EnableEurekaServer 주석을 추가해야 합니다.\n\n![annotation](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_11.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그런 다음, 우리는 이 구성을 추가합니다.\n\n<img src=\"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_12.png\" />\n\n그리고 애플리케이션을 시작합니다.\n\n마이크로서비스가 유레카 서버에 등록할 수 있도록 하려면, 각 마이크로서비스에 이 종속성을 추가해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_13.png)\n\n기본적으로 서비스는 서비스가 실행 중인 서버의 서비스 이름과 서버 이름으로 등록됩니다. 그러나 현실적인 시나리오에서는 서버 이름 대신 IP 주소가 필요합니다. 따라서 각 마이크로서비스 수준에 이러한 속성을 추가해야 합니다.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_14.png)\n\ndefaultZone 구성은 Eureka 인스턴스의 기본 위치를 http://localhost:8761/eureka URL로 지정합니다. 그러나 실제로는 적절한 IP 주소를 사용해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제, 마이크로서비스를 실행하고 Eureka 대시보드에 액세스하면 각 마이크로서비스의 주소와 포트를 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_15.png)\n\n# 게이트웨이\n\n새로운 스프링 부트 애플리케이션을 만들고 이 종속성을 추가합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_16.png)\n\n- 정적 구성:\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_17.png)\n\n- 프리디케이트: 요청을 라우팅하는 데 사용되는 조건입니다. 예를 들어, 요청 경로에 /customer가 포함되어 있으면 게이트웨이는 해당 마이크로서비스로 라우팅합니다. 프리디케이트는 요청 경로, 헤더 또는 쿼리 매개변수와 같은 다양한 기준을 바탕으로 할 수 있습니다.\n- URI: 이는 게이트웨이가 요청을 보내는 엔드포인트입니다. 예를 들어, URI가 http://localhost:8080/api로 설정된 경우 게이트웨이는 해당 주소로 요청을 전달합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 localhost:8888/customers를 입력하면 게이트웨이가 localhost:8082/customers로 요청을 리디렉션합니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_18.png)\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_19.png)\n\n- 동적 구성:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그냥 이 bean 하나 추가해주세요.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_20.png)\n\n그리고 이 구성요소도 추가해주세요.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_21.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그리고 CORS를 구성해야 합니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_22.png)\n\n이제 URL을 게이트웨이포트/대문자의 서비스이름 형식으로 입력한 후 특정 경로를 이어서 입력합니다.\n\n예를 들어: http://localhost:8888/ACCOUNT-SERVICE/accounts\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n게이트웨이는 해당 서비스의 경로를 찾기 위해 서비스 디스커버리에 해당 서비스의 이름만으로 요청을 전달합니다.\n\n![이미지1](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_23.png)\n\n![이미지2](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_24.png)\n\n지금까지 살펴본 것처럼, 우리가 계정을 조회할 때 고객 정보도 함께 얻습니다. 그렇다면 계정 서비스는 어떻게 고객 서비스에서 해당 정보를 검색할까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_25.png)\n\n특정 계정에 대한 정보를 얻기 위해 계정 서비스에 요청을 보낼 때, 먼저 해당 계정을 데이터베이스에서 찾습니다. 그런 다음, 계정과 연결된 고객 ID를 검색하고 해당 고객에 대한 정보를 얻기 위해 고객 서비스에 요청을 보냅니다. 최종적으로 결과를 구성하여 클라이언트에게 보냅니다.\n\n내부 요청을 보내기 위해 다양한 라이브러리를 사용할 수 있으며, 가장 흔한 것은 OpenFeign입니다.\n\n다음 종속성을 추가합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_26](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_26.png)\n\nOpenFeign은 HTTP 요청을 간편하게 만들어주는 선언적 프레임워크입니다. 복잡한 코드를 작성하는 대신 인터페이스를 정의하고 상호 작용하려는 서비스의 이름을 지정하고 사용하려는 엔드포인트를 나열하기만 하면 됩니다.\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_27](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_27.png)\n\nFeign을 사용하여 요청을 보내려면 Account 서비스의 주 클래스에 @EnableFeignClients 주석을 추가해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 우리는 인터페이스를 주입하고 해당 함수를 사용하여 고객 서비스에 요청을 보내는 방법을 알아봅니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_28.png)\n\n요청을 보내기 전에, 우리는 Discovery Service에 서비스의 주소를 요청합니다 (Gateway를 우회합니다). 예를 들어 findCustomerById를 호출하는 경우에 문제가 발생할 수 있고 서비스가 차단될 수 있습니다. 이를 해결하기 위해 \"서킷 브레이커\"를 사용합니다.\n\n서킷 브레이커는 전력 시스템의 전기 회로 차단기와 유사하게 작동합니다. 이는 지속적으로 구성 요소(예: 원격 서비스 호출)를 모니터링하고 반복된 실패 또는 성능 저하를 감지하면 해당 실패하는 구성 요소에 대한 호출을 일시적으로 차단하여 '회로를 열게' 합니다. 이 기간 동안 서킷 브레이커는 트래픽을 대체로 리다이렉트할 수 있습니다(예: 백업 시스템 또는 대체 기능).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n소프트웨어 아키텍처에서 회로 차단기 패턴의 이점은 다음과 같습니다:\n\n- 향상된 탄력성: 실패를 격리시켜 시스템의 다른 부분으로 전파되는 것을 방지합니다.\n- 지연 시간 단축: 빠르게 트래픽을 백업이나 Fallback로 리디렉션하여 최종 사용자의 지연 시간을 줄입니다.\n- 과부하 보호: 실패하는 구성 요소로의 새 요청을 일시적으로 제한함으로써 불필요한 과부하를 방지합니다.\n\n회로 차단기는 일반적으로 세 가지 주요 상태에서 작동합니다: Closed, Open, Half-Open:\n\n- Closed 상태:\n  - 구성 요소로의 정상 트래픽 흐름을 허용합니다.\n  - 구성 요소의 동작을 계속 모니터링합니다.\n- Open 상태:\n  - 회로 차단기가 비정상적인 실패 또는 성능 저하를 감지할 때 진입합니다.\n  - 실패하는 구성 요소로의 트래픽을 적극적으로 차단합니다.\n  - 더 이상의 실패 전파를 방지합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nHalf-Open 상태:\n\n- 오픈 상태에서 정의된 기간이 지난 후, 회로 차단기는 문제가 발생한 구성 요소가 회복되었는지 테스트하기 위해 Half-Open 상태로 전환될 수 있습니다.\n- 제한된 수의 테스트 요청을 통과시키도록 합니다.\n- 이러한 요청이 성공하면, 회로 차단기는 구성 요소가 작동 중이라는 것을 나타내는 Closed로 돌아갑니다.\n- 실패가 계속되면, 보호를 연장하기 위해 다시 Open 상태로 돌아갑니다.\n- Half-Open 상태에서는 이전에 실패한 구성 요소가 회복되었고 다시 트래픽을 신뢰할 수 있는지를 평가하기 위해 회로 차단기 메커니즘 자체에 의해 일반적으로 테스트 요청이 생성됩니다.\n\n![](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_29.png)\n\nCircuit Breaker 패턴을 구현하기 위해서는 필요한 종속성을 추가하는 것부터 시작해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_30.png)\n\n예외 상황 발생 시 기본 데이터 또는 캐싱된 데이터로 응답하겠습니다. 일정 기간이 지난 후에는 해당 서비스와의 통신을 재개할 것입니다. 서비스가 응답하고 클로즈드 서킷 모드로 전환되면, 그렇지 않을 경우 오픈 서킷 모드로 전환하겠습니다.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_31.png)\n\n간단한 예제를 살펴보죠: 모든 서비스를 시작한 후 고객 서비스를 중단할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_32.png)\n\nWe can see that the account service is still working, and the customer data returned is just default data.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_33.png)\n\nConfig-Service\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마이크로서비스마다 자체 설정이 있는 경우 변경 사항이 발생하면 해당 서비스를 다시 시작해야 합니다. 또한, 대부분의 설정이 모든 서비스에서 동일하며, 각 구성 파일에 반복된 항목이 있습니다.\n\n이 문제의 해결책은 모든 구성을 저장하고 관리할 수 있는 중앙 집중식 구성 서비스를 사용하는 것입니다.\n\n먼저 간단한 스프링 부트 애플리케이션을 만들고 이 종속성을 추가할 것입니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_34.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n효율적으로 설정을 관리하려면 모든 설정 파일을 저장할 Git 저장소를 만들어야 합니다. 이 저장소는 로컬에 있을 수도 있고(이 경우 구성 서버와 같은 기기에 있어야 함), 또는 원격 GitHub 저장소일 수 있습니다.\n\n- Application.properties: 이 파일에는 모든 마이크로서비스 간에 공유되는 설정이 포함됩니다.\n- 서비스별 구성: 각 마이크로서비스는 해당하는 이름(예: customer-service.properties)의 구성 파일을 가져야 합니다.\n\n마이크로서비스의 이름은 해당 내부 구성 파일에 명시되어야 합니다. 마이크로서비스가 시작되면 구성 서버에 해당 구성 파일을 요청하는 요청을 보냅니다. 구성 서버는 올바르게 응답하기 위해 마이크로서비스의 이름을 알아야 합니다(포트도 마찬가지).\n\n우리는 각 마이크로서비스에 이 구성을 추가해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_35](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_35.png)\n\n구성이 변경되면 구성 서비스에서 관련된 마이크로서비스로 요청이 전송됩니다 (/actuator/refresh로의 POST 요청), 그것에게 다시 시작하지 않고 구성을 새로 고쳐 달라는 것을 요청합니다. 그럼 마이크로서비스는 업데이트된 구성을 구성 서버에서 요청하고, 저장된 버전과 비교해서 변경된 부분만을 보내줍니다.\n\n그래서 우리는 각 마이크로서비스에 Actuator 종속성을 추가해야 합니다.\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_36](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_36.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모든 마이크로서비스 간에 공유되도록 application.properties 파일 내에서 config 리포지토리에 이 구성을 추가해야 합니다. 이 구성은 액추에이터 엔드포인트를 활성화합니다.\n\n![Actuator Configuration](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_37.png)\n\n구성 파일을 위한 Git 리포지토리는 여기에 있습니다.\n\n![Configuration Git Repository](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_38.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로, 설정 서비스의 구성 파일인 application.properties 내부에서 Git 리포지토리의 위치를 로컬 변수로 지정해야 합니다. 이는 구성 파일을 로컬 폴더에 포함하거나 구성 파일을 원격 리포지토리로 푸시하는 경우 GitHub 리포지토리의 URL일 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_39.png)\n\n# 마이크로서비스 아키텍처 도커화\n\n이제, 마이크로서비스를 실행하려면 발견 서비스를 먼저 실행한 다음 구성 서비스와 게이트웨이를 실행해야 합니다. 이러한 서비스들이 올바르게 시작되면 다른 마이크로서비스를 시작할 수 있습니다. 다수의 마이크로서비스를 처리할 때 각각을 필요한 순서대로 수동으로 시작하는 것은 어려울 수 있습니다. 해결책은 모든 서비스와 종속성을 지정하여 올바른 순서로 시작되도록 보장하는 Docker Compose 파일을 사용하는 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 각 마이크로서비스에 이 도커파일을 추가해줍니다.\n\n![도커파일](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_40.png)\n\n도커파일을 간단하게 만들기 위해서는 Docker Compose를 실행하기 전에 마이크로서비스를 먼저 빌드해야 합니다. 권장하는 방법은 컨테이너를 실행할 때 애플리케이션을 빌드하는 겁니다.\n\n다음은 도커 컴포즈입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_41.png)\n\nBuilding Images:\n\n- Running `docker-compose up --build` builds Docker images for each service from their respective Dockerfiles.\n- This ensures that each service starts with the latest configurations.\n\nHealth Checks:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Docker Compose는 각 컨테이너의 상태를 모니터링하기 위해 건강 검사(healthcheck)를 사용합니다.\n- 일반적으로 건강 검사는 컨테이너 내에서 특정 엔드포인트 (/actuator/health)를 쿼리하여 올바르게 작동하는지 확인합니다.\n\n의존성 관리 (Depends On):\n\n- 서비스는 시작 순서를 제어하기 위해 종속성(dependes_on)을 지정합니다.\n- 이를 통해 다른 서비스에 의존하는 서비스가 해당 의존성이 시작될 때까지 기다립니다.\n\n이제 환경 변수를 사용하기 위해 구성 파일을 변경해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_42](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_42.png)\n\nDocker Compose를 사용할 때는 DISCOVERY_SERVICE_URL 환경 변수를 활용합니다. 수동으로 실행하는 경우에는 일반적으로 localhost:8761/eureka를 사용합니다.\n\n이로써 이 블로그를 마치겠습니다. 다음에 다시 만나요! 👍\n","ogImage":{"url":"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png"},"coverImage":"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png","tag":["Tech"],"readingTime":28},{"title":"스파크-비욘드 기본 델타 테이블에서 동시 쓰기와 행 수준 동시성","description":"","date":"2024-06-19 12:31","slug":"2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable","content":"\n![image](/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png)\n\nDatabricks와 델타 테이블은 데이터 엔지니어의 삶을 쉽게 만들어줍니다. 😍🥰\n\n하지만 이 엔지니어들은 어쩔 수 없이 그들에게 맞서려고 할 것입니다. 😒😒\n\n델타 테이블이 제공하는 ACID 속성에 대해 이미 알고 있다면 좋겠지만(알지 못하신다고요? 읽어보세요), 이러한 속성은 델타 테이블에서 동시에 발생하는 쓰기 작업을 다루지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 현재 상황\n\n현재 델타 테이블에 병행(또는 동시) 쓰기 작업을 수행하면 \"ConcurrentAppendException\"이 발생합니다.\n\n# 동시 작성이란\n\n2명의 데이터 엔지니어인 Monica와 Ross Geller가 델타 테이블에 동시에 쓰기를 하려고 한다고 가정해보겠습니다. 🥴 (형제 맹견이야!)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이전에 (2024년 5월 16일 이전에 🙈), 데이터 엔지니어들은 어떻게든 동시 쓰기를 직렬 쓰기로 변환하기 위해 더러운 파이스파크 코드 💩를 작성해야 했습니다. 이러한 로직 중 하나를 아래에서 설명합니다.\n\n로직: 델타 테이블에 대한 쓰기가 진행 중이면, 해당 쓰기가 끝날 때까지 기다린 후 현재 쓰기 프로세스를 시작합니다. 여기서 자세한 내용을 확인하세요.\n\n따라서 델타 테이블에 동시에 쓰기할 수 있는 모든 노트북에는 위의 로직을 포함해야 합니다.\n\n# Databricks에서 이 문제에 대해 무엇을 하였을까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그렇다구요! 🥳 Databricks Runtime 14.2 이상에서 데이터브릭은 \"행 수준 동시성\"(RLC)이라 불리는 새로운 기능을 소개했어요.\n\n데이터브릭은 마치 요정 🧞‍♂️ 같죠. 무엇이든 물어보면 주어져요!\n\n## 행 수준 동시성(RLC)을 위한 요구 사항\n\n1. 델타 테이블의 \"삭제 벡터\"를 활성화해야 해요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nALTER TABLE table_name SET TBLPROPERTIES ('delta.enableDeletionVectors' = true);\n```\n\n2. 델타 테이블은 파티션이 없어야 합니다.\n\n# RLC를 사용한 동시 쓰기 작업 및 그 결과\n\n## 삽입-삽입:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 Ross와 Monica가 동시에 삽입 작업을 수행한다면, RLC는 어떤 문제도 없이 처리할 수 있어요 😏 (충돌 없음)\n\n## 삽입-갱신/삭제:\n\n만약 Ross가 삽입을 수행하고 Monica가 갱신/삭제를 수행한다면, RLC는 조금 답답해집니다. 🥵\n\n델타 테이블의 격리 수준이 \"WriteSerializable\"로 설정되어 있다면 (기본값), 동시 작성 작업은 어떤 문제도 발생하지 않고 수행됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그런데 고립 수준을 \"Serializable\"로 변경하면 (어떤 이유에서든 변경했을 것입니다 🤔) 충돌이 발생하고 오류가 발생할 것입니다.\n\n## 업데이트/삭제\n\nRoss와 Monica가 동일한 델타 테이블에서 업데이트 또는 삭제 작업을 수행하는 경우, 동일한 행에서 작업을 수행하면 오류가 발생합니다.\n\n업데이트/삭제 작업이 다른 행에서 발생하는 경우 문제없이 작업이 수행됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 요약:\n\n- 델타 테이블에 대한 동시 행 수준 동시성(RLC)은 Databricks에서 도입되었으며 동시 쓰기 작업을 수행할 수 있게 해줍니다.\n- RLC가 작동하기 위한 몇 가지 요구 사항이 있습니다.\n\n자세한 내용은 [여기](https://link-to-more-info)에서 읽을 수 있습니다.\n\n이 블로그를 좋아하셨다면 👏을 클릭하고 데이터 엔지니어들의 삶을 쉽게 만들기 위해 공유해주세요! 😉\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n읽어 주셔서 감사합니다! 😄\n","ogImage":{"url":"/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png"},"coverImage":"/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png","tag":["Tech"],"readingTime":5},{"title":"아저라 데이터브릭스 SQL 웨어하우스 인스턴스의 실제 비용을 계산하는 방법","description":"","date":"2024-06-19 12:28","slug":"2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances","content":"\n<img src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png\" />\n\n이야기에서는 Azure Databricks SQL Warehouse 인스턴스의 비용을 계산하는 방법에 대해 배워보겠습니다.\n\nDatabricks SQL Warehouse는 Azure Databricks에서 데이터를 쿼리하고 탐색할 수 있는 컴퓨팅 리소스입니다.\n\n현재 Azure Databricks에서는 3가지 유형의 SQL Warehouse를 제공합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- SQL Warehouse Classic: SQL Warehouse Classic의 컴퓨팅 레이어는 저희 Azure 구독 계정에 존재하며 Photon을 지원하지만 Predictive IO나 Intelligent Workload Management은 지원하지 않습니다.\n- SQL Warehouse Pro: SQL Warehouse Pro의 컴퓨팅 레이어는 저희 Azure 구독 계정에 존재하며 Photon과 Predictive IO를 지원하지만 Intelligent Workload Management는 지원하지 않습니다.\n- SQL Warehouse Serverless: Azure Databricks 서버리스 아키텍처를 사용하여 Databricks SQL Warehouse Serverless가 Azure Databricks 계정에 존재하며 Databricks SQL의 모든 성능 기능(Phton, Predictive IO 및 Intelligent Workload Management)을 지원합니다.\n\n위 목록에서 볼 수 있듯이, SQL Warehouse Classic과 SQL Warehouse Pro 사이의 가장 중요한 차이점은 컴퓨팅 레이어가 저희 Azure 구독 계정에 있고, SQL Warehouse Serverless가 저희 Azure Databricks 계정에 있다는 것입니다.\n\n## 관련 이야기:\n\n- Microsoft 및 Databricks API를 사용하여 Azure Databricks 클러스터의 비용을 최적화하고 90%까지 줄이는 방법\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1. DIY 방법\n\n첫 번째 섹션은 비용 분석 논리를 이해하고 아마도 자신만의 도구나 스크립트를 작성하여 Azure Databricks SQL Warehouse 인스턴스의 비용을 계산하고자 하는 개발자 또는 기술 직군을 위해 제공됩니다.\n\n# 1.1. DIY 방법 — SQL Warehouse Classic\n\nAzure Databricks SQL Warehouse Classic 또는 Azure Databricks SQL Warehouse Pro의 비용을 계산하려면 다음 구성 요소를 고려해야 합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- SQL 계산 시간: SQL Warehouse가 실행되었던 시간.\n- Databricks Unit (DBU) 시간: SQL Warehouse에서 사용된 컴퓨팅 단위가 시간당 청구됩니다.\n- 저장 비용: 적용된 경우 데이터 저장에 연관된 비용.\n- 대역폭 비용: 적용된 경우 대역폭 전송에 연관된 비용.\n\n# 1.1.1. Databricks API에서 SQL Warehouse Classic 인스턴스 목록 가져 오기\n\n첫 번째 단계는 Databricks API \"/api/2.0/sql/warehouses\"를 사용하여 SQL Warehouse 인스턴스 목록을 검색하는 것입니다.\n\nAPI 호출을 실행한 후, 모든 Databricks SQL Warehouse가 포함 된 JSON 응답을 받게됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQL Warehouse Classic의 JSON은 다음과 같습니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"2b1613d995c81e7d\",\n  \"name\":\"Classic Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":45,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"channel\":{\n    \"name\":\"CHANNEL_NAME_CURRENT\"\n  },\n  \"enable_serverless_compute\":false,\n  \"warehouse_type\":\"CLASSIC\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/2b1613d995c81e7d;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/2b1613d995c81e7d\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n위와 유사한 데이터를 얻을 수 있습니다(쉽게 이해할 수 있도록 형식화됨)\n\n<img src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_1.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1.1.2. Microsoft API를 통해 SQL Warehouse Classic 자원의 비용 가져오기\n\n검색한 사용 데이터와 비용 정보를 결합하여 SQL Warehouse Classic의 비용을 계산해야 합니다.\n\n저희는 Microsoft Generate Cost Details Report API를 사용하여 Databricks 클러스터가 실행되는 Azure 구독에 대한 모든 데이터를 가져올 것입니다.\n\nAPI를 사용할 때 주의할 점들:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Azure 구독의 비용 세부 정보 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 비용이 연관되지 않은 데이터는 제거해야 합니다.\n- 결과를 Pay-as-you-go 또는 Enterprise 유형의 Azure 구독에 따라 조정해야 하며, 결과가 서로 다릅니다.\n- API는 한 달 이하의 데이터만 가져오도록 허용하며 13개월 이전의 데이터는 제공하지 않습니다.\n\nMicrosoft API에서 데이터를 추출할 때, 보고서에서 다음 열을 선택해야 합니다:\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용된 Azure 리소스의 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용된 Azure 리소스의 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n# 1.1.3. SQL Warehouse 클래식 인스턴스 비용 계산\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMicrosoft Databricks 및 Azure API에서 데이터를 검색한 후, 마지막 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API의 SQL Endpoint ID와 일치시키는 것입니다.\n\n우리는 이와 유사한 데이터를 받을 것입니다 (이해하기 쉽게 형식화된 데이터입니다):\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_2.png)\n\nSQL Warehouse Classic 인스턴스에서 제품은 Azure Databricks - Premium - SQL Analytics이며, 미터 이름은 Premium SQL Analytics DBU입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼, SQL Warehouse 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n# 1.2. 직접 계산 방법 — SQL Warehouse Pro\n\nAzure Databricks SQL Warehouse Pro의 비용을 계산하기 위해 다음 구성 요소를 고려해야 합니다:\n\n- SQL 컴퓨트 시간: SQL Warehouse가 실행된 시간입니다.\n- 데이터브릭스 유닛(DBU) 시간: SQL Warehouse에서 사용된 컴퓨트 유닛으로, 매 시간마다 청구됩니다.\n- 저장 비용: 데이터 저장에 관련된 비용(해당하는 경우).\n- 대역폭 비용: 대역폭 전송에 관련된 비용(해당하는 경우).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI 호출을 실행한 후, 모든 Databricks SQL Warehouse에 대한 JSON 응답을 받게 됩니다.\n\n다음은 SQL Warehouse Pro의 JSON입니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"aedd502a582f673a\",\n  \"name\":\"Starter Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":10,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"channel\":{ },\n  \"enable_serverless_compute\":false,\n  \"warehouse_type\":\"PRO\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/aedd502a582f673ad;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/aedd502a582f673a\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n이와 유사한 데이터를 얻게 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_3.png)\n\n# 1.2.2. Microsoft API를 통한 SQL Warehouse PRO 자원 비용 가져오기\n\nSQL Warehouse Pro 비용을 계산하기 위해서는 검색된 사용 데이터와 비용 정보를 결합하여 총 비용을 계산해야 합니다.\n\nMicrosoft Generate Cost Details Report API를 사용하여 Databricks 클러스터가 실행 중인 Azure 구독에 대한 모든 데이터를 가져올 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI를 사용할 때 중요한 사항:\n\n- Azure 구독에 대한 비용 세부 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 관련된 데이터 또는 비용이 연관되지 않은 데이터를 제거해야 합니다.\n- Azure 구독 유형(유연한 요금제 또는 기업용)에 따라 결과를 조정해야 합니다. 왜냐하면 출력 결과물이 다르기 때문입니다.\n- API는 한 달 이하의 데이터만 가져올 수 있으며 13개월 이전의 데이터는 가져올 수 없습니다.\n\nMicrosoft API에서 데이터를 추출할 때, 보고서에서 다음 열을 선택해야 합니다.\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용된 Azure 리소스의 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용된 Azure 리소스의 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1.2.3. SQL Warehouse PRO Instances 비용 계산하기\n\nMicrosoft Databricks와 Azure API에서 데이터를 검색한 후, 최종 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API에서 SQL Endpoint ID와 일치시키는 것입니다.\n\n다음과 유사한 데이터를 얻게 됩니다:\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQL Warehouse Pro 인스턴스에서 Product가 Azure Databricks Regional — Premium — SQL Compute Pro이고 MeterName이 Premium SQL Compute Pro DBU인 경우, SQL Warehouse 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n# 1.3. 직접 만들기 방법 — SQL Warehouse Serverless\n\nAzure Databricks SQL Warehouse Serverless 인스턴스는 Azure Databricks 계정 내에서 실행되므로 Databricks Unit (DBU) 시간 단위로 청구됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI 호출을 실행한 후, Databricks SQL Warehouse에 관한 JSON을 받게 됩니다.\n\n다음은 Serverless SQL Warehouse의 JSON입니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"e6e7601bde7c3a43\",\n  \"name\":\"Serveless Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":10,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"enable_serverless_compute\":true,\n  \"warehouse_type\":\"PRO\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/e6e7601bde7c3a43;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/e6e7601bde7c3a43\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n이처럼 유사한 데이터를 얻을 수 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_5.png\" />\n\n# 1.3.2. Microsoft API를 통해 SQL Warehouse Serverless 리소스 비용 얻기\n\n검색된 사용량 데이터를 비용 정보와 결합하여 SQL Warehouse Serverless 비용을 계산해야 합니다.\n\nDatabricks 클러스터가 실행 중인 Azure 구독의 모든 데이터를 가져 오기 위해 Microsoft Generate Cost Details Report API를 사용할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAPI를 사용할 때 중요한 사항:\n\n- Azure 구독에 대한 비용 세부 내역 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 관련 없는 데이터를 제거해야 합니다.\n- 결과를 조정해야 하는 이유는 Azure 구독 유형(사용한 만큼 지불 또는 기업 서비스)에 따라 출력이 다르기 때문입니다.\n- API는 한 달 이하의 데이터만 검색할 수 있으며 13개월 이전의 데이터는 가져올 수 없습니다.\n\nMicrosoft API에서 데이터를 추출할 때 다음 보고서 열을 선택해야 합니다:\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용한 Azure 리소스 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용한 Azure 리소스 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 1.3.3. SQL Warehouse Serveless 인스턴스 비용 계산하기\n\nMicrosoft Databricks와 Azure API에서 데이터를 검색한 후, 최종 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API에서 SQL Endpoint ID를 매칭하는 것입니다.\n\n우리가 얻게 되는 데이터는 이와 비슷할 것입니다:\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_6.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nSQL 웨어하우스 서버러스 인스턴스에서, 제품은 Azure Databricks Regional — Premium — Serverless SQL이고 미터 이름은 프리미엄 서버러스 SQL DBU입니다.\n\n그런 다음 SQL 웨어하우스 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n## 2. 쉬운 방법\n\nSQL 웨어하우스의 비용을 분 단위로 결정해야하는 경우, KopiCloud Azure Databricks 비용 도구를 사용하는 것이 쉽습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내가 API 데이터를 가져오고 필터링하며 추출하는 경험을 토대로, Microsoft 및 Databricks API에서 검색한 데이터를 읽고 관리하는 프로세스를 간소화하기 위해 이 도구를 개발했습니다.\n\n이 도구는 간단한 사용자 인터페이스를 사용하며, 몇 분 내에 서식이 지정된 데이터를 검색하려는 FinOps 전문가들을 위해 설계되었습니다.\n\n먼저 \"Databricks 비용 찾아보기\" 버튼을 클릭합니다.\n\n도구는 Microsoft 및 Databricks API와 연결하고 화면 및 Excel 파일에서 서식이 지정된 데이터를 생성할 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_7.png](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_7.png)\n\n두 번째로 마지막 단계에서는 Cost per SQL Warehouse Report 버튼을 클릭하여 SQL Warehouse 및 해당 비용 목록을 생성합니다.\n\n이 도구는 화면에 정보를 표시하고 Excel 파일로 내보냅니다.\n\n![2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_8.png](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도구는 모든 데이터를 Excel 파일로 출력하여 데이터를 조작하거나 사용자 정의 보고서를 작성할 수 있도록 합니다.\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_9.png)\n\n또한 도구는 원시 및 형식화된 데이터를 생성하고 일일 및 총 일일 비용을 로컬 스토리지나 Azure Blob Storage에 저장하여 사용자 정의 PowerBI 보고서를 생성할 수 있습니다.\n\n그게 다에요. 만약 이 이야기가 마음에 드셨다면 👏을 눌러주세요. 읽어 주셔서 감사합니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- KopiCloud Azure Databricks Cost 도구는 KopiCloud 웹사이트에서 다운로드할 수 있어요.\n- 만약 Databrick 클러스터 비용을 줄이는 데 도움이 필요하다면 Linkedin에서 저에게 연락해 주세요.\n- 게시된 이미지는 Flaticon의 Dewi Sari가 만든 Cost 아이콘을 사용하여 생성되었어요.\n\n## 관련 이야기:\n\n- Microsoft 및 Databricks API를 사용하여 Azure Databricks 클러스터 비용을 최대 90%까지 최적화하고 줄이는 방법\n","ogImage":{"url":"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png"},"coverImage":"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png","tag":["Tech"],"readingTime":17},{"title":"눈꽃 폴라리스와 데이타브릭스 유니티 카탈로그 오픈 및 상호 운용 가능한 메타스토어 시대","description":"","date":"2024-06-19 12:26","slug":"2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores","content":"\n<img src=\"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png\" />\n\n이번 달에는 두 대형 클라우드 데이터 플랫폼인 Snowflake와 Databricks에서 비슷한 성격의 주요 발표가 이뤄졌습니다.\n\n6월 초 한 주쯤에, Snowflake는 매년 개최되는 컨퍼런스에서 Apache Iceberg 위에 구현된 오픈 카탈로그인 Polaris Catalog를 발표했습니다. 그리고 그 한 주 뒤에, Databricks가 데이터 거버넌스를 위한 통합 솔루션을 제공하는 Unity Catalog 제품을 오픈소스로 공개했습니다. 이 짧은 기사에서 자세히 살펴보도록 하겠습니다.\n\n# 데이터 호수(Datalake)에서의 메타데이터 카탈로그\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_1.png](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_1.png)\n\n이 제품에 대해 파헤치기 전에, 데이터 레이크의 맥락에서 정의에 대해 먼저 간단히 논의해보겠습니다. 메타데이터 카탈로그, 또는 메타스토어라고도 알려진 것은 데이터셋을 테이블로 표현하여 객체 저장소에 있는 데이터에 대한 추상화 레이어를 만듭니다. 데이터에 대한 접근은 메타스토어를 통해 관리되며, 상호 작용을 테이블에 저장된 것처럼 변환하여 저장소에서 필요한 작업을 수행합니다.\n\n# Databricks Unity Catalog\n\n처음 접하는 분들을 위해 - 2013년 Apache Spark의 창시자들에 의해 설립된 Databricks는 데이터 레이크와 데이터 웨어하우스를 결합하여 기업이 데이터 및 AI 솔루션을 구축, 관리 및 확장하는 데 도움이 되는 클라우드 기반 데이터 인텔리전스 플랫폼입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n약 2021년 중반쯤, 유니티 카탈로그가 독점 소스로 출시되었습니다. 이는 플랫폼 에코시스템 내에서 데이터 및 AI 자산을 접근하고 관리하기 위한 솔루션이었습니다. 이는 중앙 집중식 접근 제어, 감사, 계보, 공유 및 데이터 발견 기능과 같은 여러 기능을 제공했습니다.\n\n![이미지](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_2.png)\n\n오픈 테이블 형식 (OTFs)인 Iceberg, Delta 및 Hudi가 인기를 얻으면서, 주요 데이터 플랫폼 공급 업체들은 이 세 가지 중 하나를 선택해야 했습니다. 당연히 Databricks의 창립자로서 델타 레이크가 주요 형식으로 선택되었습니다.\n\n그러나 오픈 델타 형식을 사용하는 플랫폼과의 밀접한 결합은 Apache Iceberg 또는 Hudi와 호환되는 쿼리 엔진과의 상호 운용성이 제한되었음을 의미했습니다. Databricks가 이 문제를 해결하기 위한 최초의 시도는 Delta UniForm이었습니다. 이는 복사 또는 변환의 필요성을 제거하고 레이크하우스 상호 운용성을 위한 범용 형식을 제공했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n최신 발표에 따르면, Unity Catalog를 오픈 API와 아파치 2.0 라이센스로 빌드한 오픈 소스 서버로 제공하는 Databricks가 기업에게 오픈 데이터 형식(UniForm을 통한)을 지원하며 다양한 쿼리 엔진, 도구, 클라우드 플랫폼 간의 상호 운용성을 제공하는 범용 인터페이스를 제공하여 다음 수준으로 나아갔습니다.\n\n# Snowflake Polaris Catalog\n\n2012년 개발된 Snowflake는 데이터 웨어하우징, 데이터 레이크, 데이터 엔지니어링 및 데이터 과학을 위한 완전히 관리되는 SaaS 플랫폼입니다. Snowflake는 스토리지와 컴퓨팅의 분리, 온디맨드 확장 가능한 컴퓨팅, 데이터 공유, 데이터 복제, 그리고 성장하는 기업의 요구를 처리하기 위한 타사 도구 지원과 같은 기능들을 제공합니다.\n\nSnowflake는 자사의 프로프라이어터리 테이블 형식을 시작한 후, 재미있게도 얼마 전부터 Apache Iceberg와의 통합에 헌신하여 왔습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Snowflake Polaris and Databricks Unity Catalog](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_3.png)\n\n최근 출시된 Polaris 카탈로그는 Iceberg의 오픈 소스 REST 프로토콜을 기반으로 하여 사용자가 Iceberg Rest API를 지원하는 Apache Spark, Flink, Trino 등과 같은 원하는 엔진을 사용하여 데이터에 액세스하고 검색할 수 있는 오픈 표준을 제공합니다. Polaris는 다음 90일간(약 2024년 4분기) 오픈 소스로 공개될 예정입니다.\n\n# 개방성은 호환성을 의미하지 않을 수 있습니다\n\n이러한 프로젝트들을 오픈 소스 Apache 이니셔티브로 오픈하는 것은 긍정적인 단계이지만, 데이터 솔루션 아키텍처적인 측면에서 보면, 코드를 오픈할 필요는 없고 오히려 노출되는 인터페이스가 오픈되어야 합니다. 이 글을 쓰는 동안, Polaris는 원래 Iceberg만을 지원하며, Unity는 UniForm을 사용하여 네이티브 Delta 이외의 다른 OTF(Open Table Format)를 간접적으로 지원하고, Tabular 인수 이후 Iceberg와의 새로운 통합을 수행하고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\"이상적인 '오픈' 정의에서 이 메타스토어는 모든 표준 테이블 형식을 지원하고, 구성 가능한 저장 계층과 Hive Metastore가 한동안 있었던 것과 같은 메타스토어에 대한 표준 인터페이스를 가져야 합니다.\n\n# 결론\n\n대부분의 기업은 벤더 락인을 피하면서 데이터 생태계를 더 열린, 유연한, 상호 운용 가능한 것으로 하고 싶어합니다. 데이터브릭스 없이 유니티 카탈로그를 구현하거나, 스노우플레이크 없이 폴라리스를 사용하는 것은 흥미로운 전망입니다. 엔지니어링 팀은 이제 이러한 기능을 구매한 플랫폼이나 컨테이너를 사용하여 자체 인프라에서 독립적으로 호스팅하는 유연성을 가지게 되었습니다. 다가오는 몇 달 동안, 개방 커뮤니티의 협력으로 이 제품들의 성장과 채택을 지켜보는 것이 흥미로울 것입니다.\"\n","ogImage":{"url":"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png"},"coverImage":"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png","tag":["Tech"],"readingTime":5}],"page":"33","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}