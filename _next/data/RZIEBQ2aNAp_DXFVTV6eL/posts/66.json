{"pageProps":{"posts":[{"title":"테라폼 DevOps 안내서 보안 최상의 실천 방안","description":"","date":"2024-05-17 18:29","slug":"2024-05-17-TheGuidetoTerraformDevOpsSecurityBestPractices","content":"\n\n<img src=\"/assets/img/2024-05-17-TheGuidetoTerraformDevOpsSecurityBestPractices_0.png\" />\n\n# 요약\n\n전통적으로, 인프라 구축은 수동 구성을 포함하는 시간이 많이 소요되고 오류 발생 가능성이 있는 프로세스였습니다. Terraform은 코드로 인프라를 정의할 수 있도록 함으로써 이러한 관행을 바꿉니다. HashiCorp Configuration Language (HCL)로 작성된 코드는 필요한 리소스(서버, 네트워크, 데이터베이스)와 이들의 구성을 구체화합니다. 경험이 풍부한 실무자든 초보자든, 본 안내서는 현대적인 DevOps 방법론에 대한 Terraform의 패러다임 전환적인 영향에 대한 귀중한 통찰을 제공합니다.\n\n# 목차\n\n<div class=\"content-ad\"></div>\n\n- Terraform DevOps 안내서: 보안 모범 사례\n- 요약\n- 목차\n- 소개\n- 전제 조건\n  - 💡해결책💡\n- Terraform 상태를 안전하게 유지 🫶\n- 비밀 정보 안전하게 관리하기 🫶\n- 역할 기반 액세스 제어 (RBAC) 구현\n- 코드 리뷰와 협업 🫶\n- CI/CD 파이프라인 구현 💣\n- Terraform 모듈 및 제공업체 안전하게 사용하기 💣\n- 로깅 및 모니터링 🫶\n- 네트워크 보안 🫶\n- 감사 및 규정 준수 👀\n- 재해 복구 및 백업 👀\n- 결론\n- 내 정보\n- 참고 문헌\n\n# 소개\n\nTerraform은 인프라스트럭처의 코드 (IaC)에 대한 필수 도구로, 여러 클라우드 제공업체 간에 자원을 통합적으로 관리할 수 있게 해줍니다. 그러나 큰 권한에는 큰 책임이 따릅니다. 어떠한 구성 오류도 전체 인프라스트럭처에 영향을 줄 수 있기 때문에 보안이 매우 중요합니다.\n\n전통적으로 인프라스트럭처 프로비저닝은 수동 구성을 필요로 하며, 시간이 많이 걸리고 오류가 발생하기 쉬운 과정이었습니다. Terraform은 이에 도전하여 인프라스트럭처를 코드로 정의할 수 있도록 해주는 접근법을 제공합니다. HashiCorp Configuration Language (HCL)로 작성된 코드는 필요한 리소스 (서버, 네트워크, 데이터베이스)와 그 구성을 지정합니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사는 Terraform의 이점에 대해 탐구하고 IaC 배포가 안전하고 신뢰할 수 있도록 보장하기 위한 필수 보안 모범 사례를 제공합니다. 우리는 다음과 같은 주요 영역을 탐색할 것입니다:\n\n💣 취약점 감사: Terraform 구성에서 취약성을 예방적으로 식별하고 제거하는 방법을 배웁니다.\n\n💣 접근 제어 모범 사례: 접근 자격 증명을 안전하게 관리하고 최소 권한 원칙을 시행하는 전략을 발견합니다.\n\n💣 안전한 Terraform 모듈: 모듈을 안전하게 활용하고 보안을 염두에 두고 자체 모듈을 생성하는 방법을 이해합니다.\n\n<div class=\"content-ad\"></div>\n\n\"IBM와 HashiCorp의 병합된 포트폴리오는 고객이 증가하는 애플리케이션 및 인프라 복잡성을 관리하고 AI 시대를 위해 설계된 포괄적인 하이브리드 클라우드 플랫폼을 만들 수 있도록 도와줍니다.\" - IBM 회장이자 최고 경영자인 아빈드 크리슈나가 말했습니다.\n\n# 준비 사항\n\n우리가 본격적인 작업에 들어가기 전에, 먼저 로컬 머신이나 개발 서버에 필요한 서비스가 있는지 확인해야 합니다:\n\n- React 및 Terraform에 대한 기본 지식.\n- AWS 계정\n- GitHub 계정\n- AWS CLI 설치 및 구성 완료.\n- 로컬에 Docker 설치.\n- Terraform\n\n<div class=\"content-ad\"></div>\n\n## 💡 솔루션 💡\n\n데브옵스 환경에서 Terraform을 구현하려면 인프라스트럭처 코드(IaC) 방법론이 취약점을 도입하지 않도록 보안에 중점을 두어야 합니다.\n\n<img src=\"/assets/img/2024-05-17-TheGuidetoTerraformDevOpsSecurityBestPractices_1.png\" />\n\n다음은 Terraform을 사용할 때 보안을 유지하기 위한 모베스트 프랙티스입니다:\n\n<div class=\"content-ad\"></div>\n\n# 테라폼 상태 보안을 강화하세요 🫶\n\n- 원격 상태 저장소 사용: 상태 파일을 AWS S3, Azure Blob Storage 또는 Google Cloud Storage와 같은 원격 백엔드에 저장하여 무단 액세스를 방지하는 적절한 액세스 제어를 적용하세요.\n- 상태 파일 암호화: 원격 백엔드에 저장된 상태 파일에 대해 서버 측 암호화를 활성화하세요.\n- 액세스 제한: IAM 역할 및 정책을 사용하여 상태 파일에 대한 액세스를 필요한 사용자에게로 제한하세요.\n\n예시:\n\n```js\nvariable \"db_password\" {\n  type    = string\n  sensitive = true\n}\n\ndata \"terraform_remote_state\" \"foo\" {\n  backend = \"http\"\n  config = {\n    address = \"http://my.rest.api.com\"\n  }\n}\n```\n\n<div class=\"content-ad\"></div>\n\n여기에서 더 많은 정보를 얻을 수 있습니다:\n\n# **보안적으로 비밀을 관리하기 🫶**\n\n- **비밀 직접 코딩 피하기**: Terraform 파일에 비밀번호, API 키 또는 기밀 정보와 같은 중요한 정보를 직접 코딩하지 마세요.\n- **시크릿 관리 도구 사용하기**: HashiCorp Vault, AWS Secrets Manager 또는 Azure Key Vault와 같은 시크릿 관리 도구를 통합하여 Terraform 구성에 안전하게 시크릿을 관리하고 주입하세요.\n\n예를 들어 Azure Key Vault를 사용하여 비밀을 안전하게 관리하는 방법:\n\n<div class=\"content-ad\"></div>\n\nprovider.tf\n\n```js\nterraform {\n  required_version = \">=1.0\"\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~>3.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~>3.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n```\n\nmain.tf\n\n```js\nresource \"random_string\" \"secret_value\" {\n  length  = 20\n  special = true\n}\n\nresource \"azurerm_key_vault\" \"vault\" {\n  name                       = \"my-key-vault\"\n  location                   = \"East US\"\n  resource_group_name        = \"my-resource-group\"\n  tenant_id                  = data.azurerm_client_config.current.tenant_id\n  sku_name                   = \"standard\"\n  soft_delete_retention_days = 7\n\n  access_policy {\n    tenant_id = data.azurerm_client_config.current.tenant_id\n    object_id = local.current_user_id\n    secret_permissions = [\"get\", \"list\"]\n  }\n}\n\nresource \"azurerm_key_vault_secret\" \"my_secret\" {\n  name         = \"my-secret\"\n  value        = random_string.secret_value.result\n  key_vault_id = azurerm_key_vault.vault.id\n}\n\ndata \"azurerm_client_config\" \"current\" {}\n```\n\n<div class=\"content-ad\"></div>\n\n# Role-Based Access Control (RBAC) 구현\n\n- IAM 정책 사용: 사용자 및 서비스가 필요한 권한만 갖도록 IAM 정책을 정의하고 강제합니다.\n- 역할 분리: 각 단계 (개발, 스테이징, 프로덕션)에 대해 서로 다른 역할을 사용하고 최소 권한의 원칙을 적용합니다.\n\n예를 들어 Azure 리소스를 위한 Role-Based Access Control (RBAC) :\n\n```js\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~>2.0\"\n    }\n    azuread = {\n      source = \"hashicorp/azuread\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\n// main.tf\ndata \"azuread_user\" \"aad_user\" {\n  for_each            = toset(var.avd_users)\n  user_principal_name = format(\"%s\", each.key)\n}\n\ndata \"azurerm_role_definition\" \"role\" {\n  name = \"Desktop Virtualization User\"\n}\n\nresource \"azuread_group\" \"aad_group\" {\n  display_name     = var.aad_group_name\n  security_enabled = true\n}\n\nresource \"azuread_group_member\" \"aad_group_member\" {\n  for_each         = data.azuread_user.aad_user\n  group_object_id  = azuread_group.aad_group.id\n  member_object_id = each.value[\"id\"]\n}\n\nresource \"azurerm_role_assignment\" \"role\" {\n  scope              = azurerm_virtual_desktop_application_group.dag.id\n  role_definition_id = data.azurerm_role_definition.role.id\n  principal_id       = azuread_group.aad_group.id\n}\n``` \n\n<div class=\"content-ad\"></div>\n\n# 코드 리뷰 및 협업 🫶\n\n- 버전 관리 사용: 테라폼 구성을 Git과 같은 버전 관리 시스템(VCS)에 저장하세요.\n- 코드 리뷰: 잠재적인 보안 문제를 미리 발견하기 위해 테라폼 구성에 대한 모든 변경에 대해 필수 코드 리뷰를 실시하세요.\n- 풀 리퀘스트: 변경 사항을 본 브랜치로 병합하기 전에 리뷰 및 토론하기 위해 풀 리퀘스트를 사용하세요.\n\n# CI/CD 파이프라인 구현 💣\n\n```js\nname: 테라폼 CI/CD\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\nenv:\n  ARM_CLIENT_ID: ${ secrets.ARM_CLIENT_ID }\n  ARM_CLIENT_SECRET: ${ secrets.ARM_CLIENT_SECRET }\n  ARM_SUBSCRIPTION_ID: ${ secrets.ARM_SUBSCRIPTION_ID }\n  ARM_TENANT_ID: ${ secrets.ARM_TENANT_ID }\n  TF_VAR_client_id: ${ secrets.ARM_CLIENT_ID }\n  TF_VAR_client_secret: ${ secrets.ARM_CLIENT_SECRET }\n  TF_VAR_subscription_id: ${ secrets.ARM_SUBSCRIPTION_ID }\n  TF_VAR_tenant_id: ${ secrets.ARM_TENANT_ID }\n\njobs:\n  terraform:\n    name: '테라폼'\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: 코드 체크아웃\n        uses: actions/checkout@v2\n\n      - name: 테라폼 설정\n        uses: hashicorp/setup-terraform@v2\n        with:\n          terraform_version: 1.3.7\n\n      - name: 테라폼 초기화\n        run: terraform init\n\n      - name: 테라폼 포맷\n        run: terraform fmt -check\n\n      - name: 테라폼 유효성 검사\n        run: terraform validate\n\n      - name: 테라폼 계획\n        id: plan\n        run: terraform plan -out=plan.tfplan\n        continue-on-error: true\n\n      - name: 테라폼 적용\n        if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n        run: terraform apply -auto-approve plan.tfplan\n\n      - name: 테라폼 삭제 (옵션)\n        if: github.event_name == 'pull_request' && github.event.action == 'closed' && github.event.pull_request.merged == false\n        run: terraform destroy -auto-approve\n```\n\n<div class=\"content-ad\"></div>\n\n- 배포 자동화: CI/CD 파이프라인을 사용하여 Terraform 배포를 자동화하여 일관성을 유지하고 인간 에러의 위험을 줄입니다.\n- 취약점 검사: CI/CD 파이프라인에 보안 스캔 도구를 통합하여 배포 전에 Terraform 구성에서 취약점을 감지합니다.\n\n# Terraform 모듈과 프로바이더 안전하게 사용하기 💣\n\n- 프로바이더 확인: Terraform 레지스트리 또는 신뢰할 수 있는 소스에서 확인된 프로바이더와 모듈만 사용합니다.\n- 버전 핀: 프로바이더와 모듈의 버전을 핀하여 상위 업데이트로 인한 의도하지 않은 변경을 방지합니다.\n- 코드 검토: 모듈과 프로바이더의 코드를 정기적으로 검토하고 감사하여 보안 위험을 방지합니다.\n\n예시:\n\n<div class=\"content-ad\"></div>\n\n```js\nmodule \"network\" {\n  source  = \"terraform-azure-modules/network/azurerm\"\n  version = \"2.0.0\"\n  # 기타 모듈 입력 값\n}\n```\n\n# 로깅 및 모니터링 🫶\n\n- 로깅 활성화: 테라폼에서 수행되는 모든 작업이 로깅되고, 이러한 로그가 이상 활동을 모니터링하는 데 사용될 수 있도록 합니다.\n- 상태 변경 모니터링: 테라폼 상태 및 인프라 변경에 대한 경보를 설정하여 무단 수정에 신속하게 대응할 수 있도록 합니다.\n\n# 네트워크 보안 🫶\n\n\n<div class=\"content-ad\"></div>\n\n- VPC 및 서브넷 사용: 가상 사설 클라우드(VPC) 및 서브넷을 이용하여 리소스를 격리하도록 네트워크 아키텍처를 설계하세요.\n- 보안 그룹 및 방화벽: 엄격한 보안 그룹 규칙과 네트워크 방화벽 정책을 적용하여 트래픽 흐름을 제어하고 노출을 제한하세요.\n\n# 감사 및 규정 준수 👀\n\n- 정기 감사: Terraform 구성 및 배포된 인프라의 보안 감사와 규정 준수 점검을 정기적으로 수행하세요.\n- 규정 준수 코드: 규정 준수를 보장하기 위해 Terraform 구성에 규정 준수 점검을 통합하세요. regulatory and organizational standards을 준수합니다.\n\n# 재해 복구 및 백업 👀\n\n<div class=\"content-ad\"></div>\n\n```js\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"rg\" {\n  name     = var.resource_group_name\n  location = var.location\n}\n\nresource \"azurerm_recovery_services_vault\" \"recovery_vault\" {\n  name                = \"myRecoveryServicesVault\"\n  resource_group_name = azurerm_resource_group.rg.name\n  location            = azurerm_resource_group.rg.location\n  sku                 = \"Standard\"\n}\n\nresource \"azurerm_backup_policy_vm\" \"backup_policy\" {\n  name                = \"myBackupPolicy\"\n  resource_group_name = azurerm_resource_group.rg.name\n  recovery_vault_name = azurerm_recovery_services_vault.recovery_vault.name\n\n  backup {\n    frequency = \"Daily\"\n    time      = \"23:00\"\n  }\n\n  retention_daily {\n    count = 7\n  }\n}\n\nresource \"azurerm_kubernetes_cluster\" \"aks\" {\n  name                = var.aks_name\n  location            = azurerm_resource_group.rg.location\n  resource_group_name = azurerm_resource_group.rg.name\n  dns_prefix          = var.dns_prefix\n\n  default_node_pool {\n    name       = \"default\"\n    node_count = var.node_count\n    vm_size    = var.vm_size\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n\n  tags = {\n    environment = \"Production\"\n  }\n}\n\nresource \"azurerm_log_analytics_workspace\" \"log_analytics\" {\n  name                = var.log_analytics_workspace_name\n  location            = azurerm_resource_group.rg.location\n  resource_group_name = azurerm_resource_group.rg.name\n  sku                 = \"PerGB2018\"\n  retention_in_days   = 30\n}\n\nresource \"azurerm_kubernetes_cluster_node_pool\" \"node_pool\" {\n  name                  = \"additionalpool\"\n  kubernetes_cluster_id = azurerm_kubernetes_cluster.aks.id\n  vm_size               = \"Standard_DS2_v2\"\n  node_count            = 1\n}\n\nresource \"azurerm_backup_protected_vm\" \"protected_vm\" {\n  resource_group_name = azurerm_resource_group.rg.name\n  recovery_vault_name = azurerm_recovery_services_vault.recovery_vault.name\n  source_vm_id        = azurerm_kubernetes_cluster.aks.id\n  backup_policy_id    = azurerm_backup_policy_vm.backup_policy.id\n}\n```\n\n- 백업 상태 파일: 우연한 삭제나 손상으로부터 회복할 수 있도록 Terraform 상태 파일을 정기적으로 백업합니다.\n- 재해 복구 계획: 재해 복구 계획을 개발하고 테스트하여 치명적인 장애 발생 시 Terraform을 사용하여 인프라를 복원할 수 있도록 합니다.\n\n이런 모범 사례를 따르면 Terraform으로 관리되는 인프라의 보안을 크게 향상시키고 잠재적인 취약점과 잘못된 구성의 위험을 줄일 수 있습니다.\n\n고려해야 할 몇 가지 부가 사항이 있습니다:```\n\n<div class=\"content-ad\"></div>\n\n- 데이터의 존속중 암호화 #1 — 서버 측 암호화는 데이터를 적절히 보호하지만, 특히 환경 간 전송 시 상태 파일을 암호화하는 것을 고려해보세요. 👑\n- 서비스 계정에 대한 최소 권한 부여 #2 — Terraform과 서비스 계정을 사용할 때, 해당 계정이 특정 작업에 필요한 최소한의 권한을 갖도록하십시오.\n- 인프라 제거 테스트 #3 — 자동화된 테스트를 CI/CD 파이프라인에 포함하여 Terraform이 인프라를 안전하게 제거할 수 있는지 확인하세요. 재해 복구 시나리오에 중요합니다. 👑\n- 최신 유지 #3 — 정기적으로 Terraform 자체, 모듈 및 프로바이더를 업데이트하여 보안 패치와 버그 수정의 이점을 누리세요.\n\n# 결론\n\nDevOps 환경에서 Terraform을 보안하는 데 이러한 모범 사례를 따르면 리스크를 최소화하고 인프라를 코드로 제어하는 강력한 방어수단을 확보할 수 있습니다. 안전한 상태 관리, 적절한 비밀 처리, 역할 기반 액세스 제어, 철저한 코드 리뷰, 자동화된 CI/CD 파이프라인, 주시적인 로깅 및 모니터링, 엄격한 감사 및 규정 준수 프로세스 등의 조치를 시행하여 취약점에 대응하는 인프라를 강화할 수 있습니다. 궁극적으로 보안에 대한 선제적인 접근은 시스템을 안전하게 지키는 데 도움이 되는 것뿐만 아니라 조직 내 신뢰와 신뢰성을 육성할 것입니다.\n\n읽어 주셔서 감사합니다! 🙌🏻 구독하고 CLAP을 꼭 눌러주세요 👏 다음 기사에서 만나요.🤘\n\n<div class=\"content-ad\"></div>\n\n# 나에 대해\n\n“안녕하세요! 저는 조엘 오웜보이라고 합니다. AWS 인증 클라우드 아키텍트, 백엔드 개발자, 그리고 AWS 커뮤니티 빌더입니다. 필리핀에 거주하고 있어요. 제가 가지고 있는 강점은 클라우드 아키텍처, 데브옵스 실천 방법, 그리고 고가용성 (HA) 원칙에 대한 깊은 이해를 결합한 것입니다. 제 지식을 활용하여 효율적인 기업 배포를 위해 오픈 소스 도구를 사용하여 견고하고 확장 가능한 클라우드 애플리케이션을 만들어내고 있습니다.”\n\n저자(Joel O. Wembo)에 대한 더 많은 정보를 원하시면 아래 링크를 확인해주세요:\n\n<div class=\"content-ad\"></div>\n\n- Linkedin: [https://www.linkedin.com/in/joelotepawembo/](https://www.linkedin.com/in/joelotepawembo/)\n- Website: [https://joelwembo.com](https://joelwembo.com)\n- Twitter: [https://twitter.com/joelwembo1](https://twitter.com/joelwembo1)\n- GitHub: [https://github.com/joelwembo](https://github.com/joelwembo)\n- Portfolio: [joelwembo.github.io](joelwembo.github.io)\n- [https://www.patreon.com/joelwembo](https://www.patreon.com/joelwembo)\n\n# References","ogImage":{"url":"/assets/img/2024-05-17-TheGuidetoTerraformDevOpsSecurityBestPractices_0.png"},"coverImage":"/assets/img/2024-05-17-TheGuidetoTerraformDevOpsSecurityBestPractices_0.png","tag":["Tech"],"readingTime":12},{"title":"Vault 비밀, 엔진, 경로 및 더 많은 작동 방식","description":"","date":"2024-05-17 18:26","slug":"2024-05-17-HowVaultsecretsenginespathsandmorework","content":"\n\n## Hashicorp Vault은 구성 관리를 중앙 집중화하는 시크릿 관리 시스템입니다. 처음에 만났을 때 너무 방대한 설명서 때문에 헷갈렸었어요. 제게 제공된 정보가 제가 쉽게 이해할 수 있는 형태가 아니었거든요. 그래서 이 기사를 작성하여 그 간극을 좁히는 데 도움이 되길 바래봅니다.\n\n![HowVaultsecretsenginespathsandmorework](/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_0.png)\n\n이 기사에서는 Hashicorp 자습서를 자세히 살펴보기 전에 이해해야 할 개념에 대해 설명했습니다. 여기서 목표는 작업 방법을 보여주는 것이 아니라 작동 원리를 설명하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n본 글에서 Vault의 설치 과정을 다루지는 않았지만 다른 문서에서 다루었으니 참고하세요.\n\n# 기본 개념\n\nVault가 작동하는 방식에 기본적으로 필요한 여러 개념이 있습니다:\n\n- 네임스페이스\n- 시크릿\n- 시크릿 엔진\n- 경로\n- 인증 방법\n- 정책\n- 토큰\n- 래핑된 토큰\n- 개체와 별칭\n- 그룹 및 별칭\n- 역할\n\n<div class=\"content-ad\"></div>\n\n만약 이 내용을 이해하지 못한다면, Vault를 사용 사례에 어떻게 적용해야 하는지 이해하는 데 어려움을 겪을 수도 있어요.\n\n## 네임스페이스\n\n네임스페이스는 동일한 배포 내에서 가상 Vault 인스턴스를 만들어냅니다.\n\n네임스페이스는 서로 독립적으로 Vault의 설정을 관리하는 다른 팀, 고객 또는 테넌트를 허용합니다. 네임스페이스 내에서 비밀, 엔진, 정책 등은 다른 네임스페이스에서 완전히 격리되어 있어요.\n\n<div class=\"content-ad\"></div>\n\n비기업 사용자의 경우, 네임스페이스를 무시할 수 있습니다.\n\n## 비밀 정보\n\n알고 계실지도 모르겠지만 Vault는 비밀 정보를 관리합니다. 그렇다면 비밀 정보란 무엇일까요?\n\n비밀 정보란 기본적으로 접근 권한을 엄격히 제어해야 하는 정보입니다.\n\n<div class=\"content-ad\"></div>\n\nVault는 모든 유형의 비밀을 관리할 수 있지만, 특정 유형의 비밀을 처리하기 위해 내장된 기능이 있습니다. 이러한 유형은 다음과 같습니다:\n\n- 키-값 쌍\n- 비밀번호\n- 데이터베이스 접근\n- TLS 키 및 인증서\n- API 키\n- 암호화 키\n- SSH 키\n- 토큰\n- 등등…\n\n배포 구성에 따라 비밀의 크기 제한이 있습니다. 기본적으로 통합(raft) 저장 계층을 사용하는 경우, 제한은 1MiB입니다.\n\n## 시크릿 엔진\n\n<div class=\"content-ad\"></div>\n\n시크릿 엔진은 Vault가 특정 유형의 시크릿을 관리할 수 있도록 하는 플러그인으로 볼 수 있습니다. 실제로, 나는 엔진을 시크릿 관리자로 생각하지만 Vault에서는 엔진이라고 부릅니다.\n\n![image](/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_1.png)\n\n각 시크릿 엔진은 고유한 기능을 가지고 있지만, 전반적으로 시크릿을 다음과 같이 허용합니다:\n\n- 생성, 읽기, 수정 및 삭제\n- 암호화*\n- 만료 시간 (TTL)에 따라 만료\n- TTL 새로 고침되는지 여부에 관계없이 최대 수명 후 만료\n- 자동으로 생성되어 클라이언트 및 서버 응용 프로그램에 삽입됨\n- 취소됨\n- 버전 관리됨\n\n<div class=\"content-ad\"></div>\n\n엔진의 예로는 특정 권한 범위를 설정받은 일시적인 로그인 자격 증명을 생성할 수 있는 데이터베이스 엔진이 있습니다. 요청에 새 자격 증명을 생성함으로써 해당 자격 증명을 회전시킵니다.\n\n시크릿 엔진은 활성화 및 비활성화됩니다. 활성화되면 필요한 시크릿 관리 서비스를 제공하기 위해 구성됩니다. 비활성화되면 엔진은 모든 구성과 시크릿을 포함한 모든 정보가 삭제되며, 이것들은 저장소에서 삭제되어 되돌릴 수 없습니다.\n\n동일 유형의 엔진을 여러 인스턴스로 활성화하는 것이 가능하다는 점을 기억해야 합니다. 예를 들어 3개의 KV 엔진과 2개의 데이터베이스 엔진을 활성화할 수 있습니다. 이는 추가적인 보안을 제공합니다. 한 엔진 인스턴스는 같은 유형의 다른 엔진에서부터 아무 것도 접근할 수 없습니다.\n\nVault 내부에서 사용되는 Identity 시크릿 엔진이 있지만 이에 대해서는 나중에 자세히 알아보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## 경로\n\n파일 시스템과 같이 Vault는 비밀을 경로를 통해 추적합니다. 컴퓨터에서는 /my-work/docs/myreport.txt에 파일이 있을 수 있습니다. Vault를 사용할 때는 /my-secrets/my-app/login에 비밀이 있을 수 있습니다.\n\n비밀의 경로는 세 부분에서 구성됩니다:\n\n`namespace`/`엔진 마운트 지점`/`비밀 경로`\n\n<div class=\"content-ad\"></div>\n\n엔진을 활성화하면 엔진 마운트 포인트에서 그렇게 합니다. 기본적으로 이 마운트 포인트는 엔진의 이름으로 지정됩니다 (예: 데이터베이스) 하지만 이를 변경하거나 경로를 포함할 수도 있습니다. 예를 들어 my-dbs/postgres와 같이 이름을 지정할 수 있습니다. 이렇게 하면 다른 엔진을 my-dbs/my-sql과 같은 위치에서 활성화할 수 있습니다.\n\n경로의 두 번째 부분은 마운트 포인트 내의 특정 Secret의 경로를 식별합니다 (즉, 엔진 내에서).\n\n예를 들어 (이 예시에서 마운트 포인트는 ``를 사용하여 식별되었습니다):\n\n```js\n<kv>/path/to/my/kv-secret\n<database>/path/to/my/postgres-secret/credentials\n```\n\n<div class=\"content-ad\"></div>\n\n어떤 비밀 정보도 같은 엔진 내에서 동일한 하위 경로를 가질 수 없습니다. 이것은 말이 되지만(마운트 지점과 달리) 일부 하위 경로를 공유할 수도 있습니다. 다음과 같이:\n\n```js\n<database>/path/to/my/postgres-secret/credentials\n<database>/path/to/my/mysql-secret/credentials\n<database>/path/to/my/oracle-secret/credentials\n```\n\nUI 내에서 이것은 폴더 구조처럼 작동하여 엔진(database) - `path` - `to` - `my` - `postgres-secret`까지 credentials까지 이동할 수 있습니다.\n\n경로에 연결된 것은 비밀 정보뿐만 아니라 Vault에서 관리하는 리소스에도 해당되며, 인증 방법과 정책도 경로를 가지고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n경로를 떠나기 전에, 리소스에 대한 작업 또한 경로를 통해 참조될 수 있다는 점을 이해하는 것이 중요합니다. 이 경우 경로는 다음과 같이 생성됩니다:\n\n`namespace`/`engine mount point`/`path to secret`/`action`\n\n## 인증 방법\n\n지금까지 Secrets에 대해 이야기했지만, 이제는 어떻게 해당 Secrets에 접근하는지 살펴보아야 합니다.\n\n<div class=\"content-ad\"></div>\n\nVault에 액세스하는 세 가지 방법이 있습니다:\n\n- 사용자 인터페이스(UI)를 통해\n- 명령 줄 도구(CLI)를 통해\n- HTTP REST API(API)를 통해\n\n사실, 이들은 모두 주로 API를 사용합니다. 이것을 이해하는 것이 중요한데, UI나 CLI에서 수행하는 작업에 대해 curl 명령어를 구성할 수 있다는 의미입니다. 스크립트를 작성할 때 매우 유용합니다.\n\n‘우리’라는 말을 사용할 때, 물리적 서버, 애플리케이션 또는 사람 모두 식별(즉, 인증)되어야 하고, Vault를 사용하기 전에 특정 비밀(Secret)에 액세스하도록 허용(즉, 권한 부여)되어야 합니다. 권한 부여에 대해서는 나중에 다시 다루겠습니다.\n\n<div class=\"content-ad\"></div>\n\n우리는 고객을 '우리'라고 부르겠습니다.\n\n그래서, Vault는 고객을 어떻게 인증하나요? 사용 가능한 여러 가지 방법이 있습니다. Vault는 이러한 방법을 Auth 방법이라고 부릅니다:\n\n- AppRole\n- OAuth JWT\n- OIDC\n- TLS 인증서\n- 사용자명/암호\n- 클라우드 공급업체 (예: AWS, Azure, Google Cloud)\n- Kubernetes 서비스 계정\n- LDAP\n- 그 외...\n\n고객은 Auth 방법 중 하나를 사용하여 인증하고, 한 번 인증되면 클라이언트 토큰이 제공되어 클라이언트가 수행하려는 작업을 수행할 수 있는지 여부를 결정하는 데 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n![HowVaultsecretsenginespathsandmorework](/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_2.png)\n\n각 Auth Method는 클라이언트를 인증하는 고유한 방법을 갖고 있습니다. 일부는 사전 공유된 시크릿을 사용하고, 일부는 Vault 내에 저장된 로그인 자격 증명을 사용하며, 일부는 AWS IAM과 같은 타사 서비스를 사용합니다. Kubernetes 내의 서비스 계정을 사용하여 인증하는 것도 가능합니다.\n\n동일한 유형의 여러 Engine을 활성화할 수 있는 것처럼, Auth Method도 마찬가지입니다. 엔진과 마찬가지로, 활성화된 각 Auth Method에는 마운트 지점이 지정되어 UI, CLI 및/또는 API를 통해 참조할 수 있습니다. 기본 이름이 부여되거나 고유한 이름을 정의할 수 있습니다. 모든 Auth Method는 auth/ 경로 아래에 마운트됩니다. 예: auth/`auth method 이름`.\n\n## 정책\n\n<div class=\"content-ad\"></div>\n\n클라이언트가 비밀에 액세스하는 방법을 알아보기 전에 정책에 대해 이해해야 합니다.\n\n정책은 권한을 부여합니다. 하나 이상의 정책에서 권한을 부여하지 않은 경우 권한이 부여되지 않습니다.\n\n정책을 만들 때, 명령줄을 통해 직접 만들 수도 있지만 파일에 추가한 다음 파일을 로드하는 것이 더 쉽습니다. 정책은 Hashicorp Configuration Language (HCL)로 작성됩니다.\n\n정책은 특정 경로에 부여되는 권한을 정의합니다. 액션을 포함할 수 있는데, 예를 들어 auth/token/lookup-self와 같습니다. 그런 다음 해당 경로에서 허용된 기능이 권한으로 정의됩니다. 기본 정책의 일부는 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n```json\n# 자신의 속성을 조회할 수 있는 토큰 허용\npath \"auth/token/lookup-self\" {\n    capabilities = [\"read\"]\n}\n\n# 자신을 갱신할 수 있는 토큰 허용\npath \"auth/token/renew-self\" {\n    capabilities = [\"update\"]\n}\n\n# OIDC 공급자의 인증 엔드포인트로 요청을 보낼 수 있는 토큰 허용\npath \"identity/oidc/provider/+/authorize\" {\n    capabilities = [\"read\", \"update\"]\n}\n```\n\n위와 같이 정책은 여러 경로에 매핑되고 여러 기능을 허용할 수 있음을 알 수 있습니다. 경로 끝에 *를 포함하면 해당 경로의 모든 하위 경로에 정책이 적용됩니다. 경로의 leaf를 /+/로 대체하면 해당 leaf의 모든 값을 일치시킵니다. 이는 경로에 ID가 포함된 경우 유용합니다.\n\n권한은 누적되므로 사용자가 여러 정책과 관련이 있는 경우 모든 정책에서 모든 권한을 갖습니다.\n\n그러나 정책들이 함께 수집될 때 두 정책 경로가 겹칠 때, 예를 들어 secrets/* 및 secrets/my-secret과 같은 경우, 더 구체적인 경로의 기능이 사용됩니다. 더 정확히는 Hashicorp 문서에 따르면, 우선순위 순서로 두 유사한 경로 p1 및 p2가 주어질 때, p2가 선호되며 다음과 같은 경우 선택됩니다:\n\n<div class=\"content-ad\"></div>\n\n- 만약 p1에 * 또는 +이 p2보다 왼쪽에 나타나면\n- p1에 *가 있고 p2에 없을 경우\n- p1에 +가 p2보다 더 많을 경우\n- p1이 p2보다 짧을 경우\n- 사전에 p2보다 p1이 먼저 나타나야 할 경우\n\n다시 말해, 경로가 더 구체적일수록 선호됩니다.\n\n![image](/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_3.png)\n\n기능에는 (그들의 HTTP 동사를 포함하여):\n\n<div class=\"content-ad\"></div>\n\n- 생성 [POST/PUT]\n- 조회 [GET]\n- 업데이트 [POST/PUT]\n- 패치 [PATCH]\n- 삭제 [DELETE]\n- 목록 [LIST]\n\nHTTP 동사와 직접적으로 관련이 없는 세 가지 기능이 더 있습니다:\n\n- sudo — root로 보호된 경로에 액세스 허용\n- deny — 다른 기능 및 정책과 관계없이 모든 액세스 거부\n- subscribe — 이벤트 유형에 대한 구독 허용\n\n경로 일치를 통해 보안정책이 Secrets와 다른 리소스와 관련되어 있는 방식을 볼 수 있습니다. 그러나 아직 우리가 보지 않은 것은 보안정책이 요청과 어떻게 연관되어 있는지입니다. 그것을 알아보기 위해선 엔티티와 그룹을 이해해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n이 문서는 정책의 기본 사항만 다루었습니다. 자세한 내용은 Hashicorp 문서를 참조하십시오.\n\n## 엔티티와 별칭\n\n엔티티는 Vault 내에서 클라이언트를 나타냅니다. 클라이언트는 사람, 애플리케이션 및 시스템으로 나타낼 수 있다는 점을 알아보았습니다. 모두 엔티티로 나타낼 수 있습니다.\n\n특정 엔티티(예: 당신 또는 나)는 여러 Auth 방법(예: 사용자 이름/암호, GitHub 계정 등)을 통해 인증될 수 있습니다. 즉, 각 Auth 방법에서 엔티티를 나타내는 신원이 해당 엔티티에 연결되어야 하는 중요합니다. 이 작업은 Entity Aliases를 통해 수행됩니다.\n\n<div class=\"content-ad\"></div>\n\n한 Entity는 0개 이상의 Entity Aliases를 가질 수 있습니다.\n\n![Image](/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_4.png)\n\n이전에 Policies에 대해 이야기했습니다. 각 Entity는 하나 이상의 Policies와 관련될 수 있습니다. 클라이언트가 인증하는 방식에 상관없이, 그들은 Entity와 관련된 Policies에 제공된 권한을 받게 됩니다.\n\n우리는 이것이 Policy가 Entity에 연관될 수 있는 유일한 방법이 아니라는 것을 볼 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 그룹 및 별칭\n\nEntity는 유용하지만 액세스 관리가 어려워질 수 있습니다. 왜냐하면 각 Policy를 모든 Entity에 연결해야하기 때문입니다.\n\n대부분의 조직은 팀과 다부서 팀을 사용하여 구조화됩니다. 각 팀은 각자의 책임을 부여받습니다.\n\nVault는 이를 그룹을 사용하여 모델링합니다. 그룹은 임의의 수의 Entity를 보유할 수 있으며 Entity는 임의의 수의 그룹에 속할 수 있습니다. 그룹은 부모-자식 관계로 다른 그룹을 포함 할 수도 있습니다. Entity가 그룹의 일부인 경우 해당 그룹은 직접 그룹으로 알려집니다. 어떤 부모, 할아버지, 증조부모 등도 간접적 그룹으로 알려집니다.\n\n<div class=\"content-ad\"></div>\n\n```\n![image](/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_5.png)\n\n이제 그룹은 정책과 연관시킬 수 있습니다. 해당 그룹의 모든 엔티티는 해당 그룹이나 부모, 조부모 그룹의 정책을 받습니다.\n\n이제 엔티티 그룹의 액세스를 한 곳에서 관리할 수 있습니다.\n\n그룹 외에도 Vault는 그룹 별칭의 개념을 지원합니다. 이 별칭은 Active Directory 그룹과 같은 외부 그룹과 관련이 있습니다.\n```\n\n<div class=\"content-ad\"></div>\n\n## 토큰\n\n알겠어요. 우리는 Secrets에 대해 이야기했고, Policies가 Secrets의 경로에 따라 연결되는 방법과 Policies가 엔터티 및 그룹과 연결되는 방법에 대해 이야기했어요.\n\n하지만, 우리가 본 적이 없는 것은 제가 Secret에 대한 액세스를 요청할 때 Vault가 제가 필요한 액세스를 가지고 있는지 여부를 어떻게 알 수 있는지 입니다.\n\n이는 토큰을 사용하여 달성됩니다. \n\n<div class=\"content-ad\"></div>\n\n토큰은 Vault 내에서 Secrets 및 Auth Methods에 대한 액세스를 관리하는 데 필수적입니다.\n\n클라이언트가 자원(예: 생성, 읽기, 업데이트 및 삭제)을 사용하려면 유효한 토큰을 전달해야 합니다. 토큰을 통해 Vault는 해당 토큰과 관련된 정책 및 따라서 클라이언트의 기능을 결정합니다.\n\n모든 토큰에는 갱신되어야 하는 만료 시간(TTL)이 있습니다. 심지어 토큰 생성 시 최대 TTL이 있을 수 있으며 갱신 중일 때에도 해당됩니다. 이에는 초기화된 Vault에서 생성된 Root Token을 제외합니다.\n\n사용자가 토큰을 생성하도록 요청하면 해당 토큰은 사용자가 인증했을 때 제공된 정책을 상속합니다.\n\n<div class=\"content-ad\"></div>\n\n이제, 원래 토큰을 사용하여 새로운 토큰을 만드는 경우, 클라이언트는 새로운 토큰과 관련된 정책을 원래 토큰의 하위 집합으로 제한할 수 있습니다. 이를 통해 클라이언트는 '최소 권한' 액세스를 Vault에 요청할 수 있습니다.\n\n토큰은 인증된 클라이언트(개체)를 해당 개체에 연결된 정책과 관련시켜주며, 이러한 것들은 개체가 리소스에 액세스할 수 있는 권한을 제공합니다. 이러한 방식으로 Vault는 클라이언트가 리소스에 수행할 수 있는 권한이 있는지를 결정할 수 있습니다.\n\n예를 들어, 사용자는 사용자 이름과 비밀번호를 사용하여 로그인하고 시크릿을 생성하고 읽는 데 사용할 수 있는 토큰을 받을 수 있지만 업데이트는 할 수 없는 토큰을 받을 수 있습니다.\n\n토큰이 발급될 때 클라이언트에게 부여되는 권한은 다음의 조합입니다:\n\n<div class=\"content-ad\"></div>\n\n- 인증에 사용된 토큰들\n- 클라이언트를 대표하는 엔티티에게 주어진 토큰들\n- 엔티티가 직접 속한 그룹의 토큰들\n- 엔티티가 간접적으로 속한 그룹의 토큰들\n\n토큰에는 다음과 같은 속성이 있습니다:\n\n- 선택적인 유효기간 (TTL)\n- 갱신할 수 있는 능력 (또는 그렇지 않을 수도 있음)\n- 취소할 수 있는 능력\n\n토큰을 획득한 후 원본의 자식이 되는 다른 토큰을 얻는 것이 가능합니다. 이는 두 가지 이유로 유용합니다:\n\n<div class=\"content-ad\"></div>\n\n- 부모 토큰을 폐기하면 모든 하위 토큰이 재귀적으로 폐기됩니다.\n- 토큰을 요청할 때\n\n토큰에 대한 자세한 내용은 다음 해시코프 문서를 참조하십시오.\n\n## 래핑된 토큰\n\n래핑된 토큰은 일회용 토큰입니다. 클라이언트와의 핸드셰이크에 유용하며 클라이언트에게 원본 토큰을 전달하는 데 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n설명된 방식은 Wrapped Token이 원래 Token을 참조하는 것이라고 합니다.\n\nWrapped Token을 받으면 Vault에 Original Token을 요청하여 얻을 수 있습니다. 이미 언래핑된 경우 오류가 발생하고 위반이 발생했음을 알 수 있습니다. 원본 Token은 취소될 수 있고 새로운 Token을 생성할 수 있습니다.\n\nVault는 임의의 정보를 래핑하는 데 필요한 도구도 제공합니다.\n\n## Roles\n\n<div class=\"content-ad\"></div>\n\n기본 개념에서 Vault의 기본 개념을 떠날 때 전통적인 보안 세계에서 역할에 대해 얘기할 가치가 있다고 생 생각해요. 역할은 하나 이상의 사용자에게 권한 집합을 적용하는 데 사용됩니다. 이렇게 하면 사용자 그룹의 구성이 더 쉬워지며, 특정 권한 집합을 가져야 하는 사용자는 그 역할을 부여받습니다.\n\n그룹에 연결된 정책은 이와 같은 방식으로 작용합니다. 그룹은 전통적인 역할과 유사하게 볼 수 있으며, 엔티티 그룹을 권한 집합(또는 Vault가 그들을 언급하는 기능)에 연결합니다.\n\n주변을 둘러보면 역할이 Vault와 관련해 다음 두 가지 방법으로 언급된다는 것을 알게 될 거예요:\n\n- 데이터베이스 역할\n- 토큰 역할\n- AppRole 역할\n\n<div class=\"content-ad\"></div>\n\n데이터베이스 역할: 이러한 역할은 실제로 데이터베이스 엔진과 연관되어 있으며 데이터베이스 내의 역할을 나타냅니다. 즉, 자격 증명이 요청될 때 특정 데이터베이스 역할을 위해 요청할 수 있습니다.\n\n토큰 역할: 토큰 역할을 생성할 수 있으며 이는 일련의 프리셋 또는 토큰의 템플릿으로 작동할 수 있습니다. 한 번 생성되면 지정된 토큰 역할에 기반한 자식 토큰을 생성할 수 있습니다.\n\n앱롤 역할: AppRole 인증 방법을 사용하는 경우 AppRole 역할을 만들 수 있습니다. 이를 통해 응용 프로그램이이 방법으로 인증할 때 수신할 권한 및 기타 특성을 정의할 수 있습니다. AppRole 역할에는 응용 프로그램이 제출해야하는 ID가 부여됩니다. 그런 다음 응용 프로그램이 제출해야하는 비밀 ID를 생성할 수도 있습니다. 이렇게하면 AppRole 역할의 정책과 관련된 토큰을 얻을 수 있습니다.\n\n# 요약\n\n<div class=\"content-ad\"></div>\n\n이 기사에서 Vault 뒤에 있는 기본 개념을 소개했어요. 네임스페이스, 마운트 포인트 및 경로를 통해 비밀 및 다른 리소스를 찾는 방법을 살펴봤어요.\n\n또한 엔티티 및 인증 방법이 어떻게 사용되는지, 매칭 경로를 통해 리소스 액세스를 제어하기 위해 관련 정책이 있는 토큰을 생성하는 방법도 살펴봤어요.\n\n이러한 개념을 이해하면 Hashicorp의 제공하는 문서를 더 쉽게 이해할 수 있을 거예요.\n\n이 기사가 흥미로웠다면, 제게 박수를 한 번 부탁드릴게요. 이를 통해 사람들이 유용하게 여기는 것과 앞으로 써야 할 기사에 대한 정보를 얻을 수 있어요. 아이디어가 있으시면 댓글에 추가해주세요.","ogImage":{"url":"/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_0.png"},"coverImage":"/assets/img/2024-05-17-HowVaultsecretsenginespathsandmorework_0.png","tag":["Tech"],"readingTime":12},{"title":"롱혼Longhorn을 위한 최상의 관례","description":"","date":"2024-05-17 18:24","slug":"2024-05-17-BestPracticesforLonghorn","content":"\n\n\n![image](/assets/img/2024-05-17-BestPracticesforLonghorn_0.png)\n\n# 소개\n\nLonghorn은 Rancher에서 설계하고 Kubernetes 클러스터의 Storage Classes를 관리하기 위해 만들어진 오픈 소스 분산 스토리지 시스템입니다.\n\nLonghorn은 웹 UI 및 기타 도구로 설치 및 관리가 쉽게 설계되었습니다.\n\n\n<div class=\"content-ad\"></div>\n\n하지만, 클러스터 관리와 쿠버네티스 작업을 하는 모든 사람들은 대화에서 '쉽다'는 말을 듣기 쉽지 않다는 것을 알고 있습니다.\n\n이 기사에서는 Longhorn과의 여정에서 모은 정보를 제가 아닌 다른 많은 사람들에게 유용할 수 있다고 생각하는 내용을 제공하겠습니다.\n\n# 전제 조건\n\n우선, 문서를 읽어보세요. 왜냐하면...\n\n<div class=\"content-ad\"></div>\n\n나의 어리석음 속에서, 나는 롱혼(Longhorn)을 다룰 수 있을 것이라고 생각했고, 말 그대로 황소의 뿔을 잡을 수 있을 것으로 생각했다. 내가 한 것처럼 하지 마세요. 스스로를 많은 시간과 고통으로부터 구해주세요. 문서를 읽고 나서, 롱혼의 작동 방식을 근본적으로 이해했기 때문에 문제 해결이 가속화되었어요.\n\n여기 좋은 시작점이 있어요:\n롱혼(Longhorn) - 아키텍처와 개념\n롱혼(Longhorn) - 최선의 방법론\n\n이제 우리는 스스로에게 질문해 봅시다: 우리가 분산 저장 시스템(Distributed Storage System)을 생성하길 원할 때 우리가 찾고 있는 것은 무엇인가요?\n\n그것은 빠른 I/O, 혁신적인 백업 시스템, AI 디버깅 또는 어떤 반짝이는 새로운 기능이 될 수 있지만, 제 경우에는 간단합니다: 안정성과 신뢰성이 모든 분산 저장의 안내등표(Guiding Beacons)가 되어야 한다고 생각해요. 왜냐하면 핵심 데이터 손실은 어떤 클러스터에게든 가장 최악의 일이 일어날 수 있는 것이기 때문이에요.\n\n<div class=\"content-ad\"></div>\n\n이 문맥에서의 안정성은 저장 시스템이 작업 부하나 환경 조건에 관계없이 항상 예상대로 작동하는 것을 의미합니다. 이는 대량의 데이터를 처리하고 고가용성을 지원하며, 무거운 부하나 네트워크 분할 중에도 성능 수준을 유지하는 것을 포함합니다. 안정적인 시스템은 읽기, 쓰기 및 업데이트와 같은 데이터 작업이 예상치 못한 중단이나 실패 없이 발생하도록 보장합니다.\n\n신뢰성은 시스템이 데이터 무결성을 보호하고 필요할 때 언제든지 데이터에 접근할 수 있도록 하는 능력을 말합니다. 이는 강력한 오류 검출 및 수정 메커니즘을 구현하고, 데이터를 여러 노드로 복제하여 데이터 손실을 방지하며, 하드웨어 장애나 기타 문제 발생 시 효과적인 복구 프로세스를 갖는 것을 의미합니다. 신뢰할 수 있는 시스템은 빠르게 데이터를 복원하여 장애가 발생한 경우에 데이터를 빠르게 복원하는 강력한 백업 및 재해 복구 계획을 포함합니다.\n\n그리고 이 두 가지 단어를 떠올리며 분산 저장 시스템에서 안정성과 신뢰성을 실현하는 방법에 대한 통찰을 제공하기 위해 본 문서를 작성하고 있습니다.\n\n# Best Practices\n\n<div class=\"content-ad\"></div>\n\n좋아요! 이제 문서를 읽어보았고 분산 저장 시스템에서 원하는 것을 알게 되었어요.\n\n시작해볼까요?\n\n이 가이드를 따라하면 Longhorn의 성능, 신뢰성, 그리고 Kubernetes 환경에서의 관리 기능을 최적화할 수 있을 거예요.\n\n# 시작 지점\n\n<div class=\"content-ad\"></div>\n\n- 안정적인 빌드만 사용하세요. 더 나아가 최신 빌드를 사용하지 않는 것이 좋습니다. 아직 발견되지 않은 버그가 있을 수 있으니까요.\n- Longhorn을 실행할 때, 네트워크가 바쁜 클러스터 트래픽으로 인해 발생하는 네트워크 중단으로 인해 마운트가 실패하는 시나리오가 발생할 수 있으므로, 전용 스토리지 네트워크에서 실행하는 것을 고려해보세요.\n\n- 전용 스토리지 네트워크의 대안 또는 보완책은 순수 LonghornNodes를 가지는 것입니다. 이는 볼륨만 관리하며 다른 형태의 워크로드를 처리하지 않는 노드를 가지는 것을 의미합니다. 즉, NoSchedule 또는 NoExecute 효과를 적용하여 Longhorn에 전용 노드를 할당하는 것을 의미합니다.\n\n# 노드 구성\n\n- 고가용성을 위해 레플리카가 여러 노드와 가용 영역에 분산되어 있는지 확인하세요.\n- Longhorn 컴포넌트에 해당하는 허용을 추가하여 전용 스토리지 노드에 스케줄되도록 할 수 있습니다.\n- StorageClass가 필요에 따라 풀을 분할해야 하는 경우 노드 태그를 Longhorn에 추가하여 nodeSelector를 통해 해당 노드를 대상으로 할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 저장 구성\n\n- 최적의 디스크 성능을 위해 전용 SATA/NVMe SSD 또는 유사한 성능의 디스크 드라이브를 사용하세요.\n- 노드 간에 10 Gbps 네트워크 대역폭을 보유하도록 하세요.\n- 루트 디스크 대신 Longhorn 저장을 위한 전용 디스크를 사용하세요.\n\n# 레플리카 개수\n\n- 데이터 가용성을 달성하고 디스크 공간 사용량을 더욱 개선하며 시스템 성능에 덜 영향을 미치도록 기본 레플리카 수를 \"2\"로 설정하세요.\n- 더 많은 레플리카는 읽기 집계를 늘리지만, 더 많은 공간과 네트워크 대역폭을 사용합니다.\n- 기본값은 \"3\"이지만 Longhorn 공식 문서에서는 \"2\"라고 명시합니다. 특히 데이터 집약적인 애플리케이션에 매우 유용합니다.\n\n<div class=\"content-ad\"></div>\n\n# 볼륨 구성\n\n- 볼륨에는 기본 ext4 파일 시스템을 사용하세요.\n- 네트워크가 추가 트래픽을 처리할 수 없을 경우 노드를 불안정하게 만들 수 있으므로 가능하면 ReadWriteMany (RWX) 액세스 모드를 피하십시오. 가능한 경우 볼륨에는 ReadWriteOnce (RWO) 액세스 모드를 사용하세요. RWX와 RWO 사이의 성능 문제는 무시해도 좋습니다.\n- 주기적으로 네트워크 부하로 인해 마운트할 수 없는 RWX 마운트가 있는지 확인하려면 mount | grep 10.43을 사용하세요. 이를 식별하는 데 cron 작업이 설정되어 있습니다(추후 기사에서 자세한 내용을 다룰 예정).\n\n- 모든 노드 사이에 워크로드를 균형 있게 분산하는 것은 어려울 수 있습니다. Replica Node Level Soft Anti Affinity 및 Replica Auto Balance을 확인하여 시작하세요.\n\n- 이것이 도움이 되지 않으면 워크로드를 균형 있게 분산하기 위해 Descheduler를 사용할 수 있습니다. 그러나 Descheduler는 공식 제품이 아니므로 연구를 진행해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n# 데이터 지역성\n\n- Longhorn StorageClasses의 기본 데이터 지역성으로 최선을 다하십시오. 최선을 다한다는 것은 Longhorn이 첫 번째 복제본을 컨트롤 엔진이 있는 동일한 노드에 배치하려고 시도한다는 것을 의미합니다. 첫 번째 볼륨을 동일한 노드에 배치하면 I/O 및 효율성이 향상될 수 있습니다. 기억해 주십시오. 최선을 다하는 것이 기본 설정이 아닙니다.\n- 데이터 복제를 지원하는 응용 프로그램의 경우 strict-local 옵션을 사용하여 볼륨 당 복제본이 하나만 생성되도록합니다.\n- NodeSelectors 또는 Taints를 사용하여 특정 storage-tagged 노드에 데이터 집중 작업을 스케줄링하십시오.\n\n# 유지 보수 및 업그레이드\n\n- Longhorn 호스트를 다시 부팅할 때, 동일한 노드의 복제본 중 하나를 의도적으로 삭제하여 다시 구축 프로세스를 트리거하고 복제본을 노드 간에 균형 있게 배치합니다.\n- 라이브 볼륨과 관련된 문제를 피하려면 Longhorn을 업그레이드하기 전에 볼륨을 분리하는 것이 항상 바람직합니다.\n- 안정적이고 지원되는 버전으로만 업그레이드하십시오.\n- 일정한 간격으로 Longhorn UI에서 손상된 마운트를 확인하십시오. 건강한 복제본 수만큼 복제본 수를 업데이트하고 다시 정상 복제본 수로 업데이트하십시오.\n\n<div class=\"content-ad\"></div>\n\n# 스냅숏 및 백업\n\n- 필요한 만큼만 유지하면서 주기적으로 시스템에서 생성한 스냅숏을 정리하십시오.\n- 복제 기능이 있는 애플리케이션의 경우 정기적으로 모든 유형의 스냅숏을 삭제하십시오.\n- 중요한 애플리케이션 볼륨을 위한 반복 백업 작업을 생성하십시오.\n- 주기적인 시스템 백업을 실행하십시오.\n\n# 출처\n\nDevOps 이야기 LONGHORN: Best Practices — r/kubernetes Longhorn — Best Practices Rancher 포럼: Longhorn 재부팅시 Best Practice Harvester: Longhorn 디스크 성능 최적화를 위한 Best Practices Descheduling: 고가용성의 비밀\n\n<div class=\"content-ad\"></div>\n\n# 끝맺음\n\n본 작업은 다른 사람들의 경험과 제 경험의 결합물입니다. 이 글을 함께 만들어준 분들에게 감사를 표합니다. 또한, 저는 Longhorn 전문가가 아니므로 궁극적으로는 여러분들이 직접 조사해 보시기 바랍니다.\n\n행운을 빕니다!","ogImage":{"url":"/assets/img/2024-05-17-BestPracticesforLonghorn_0.png"},"coverImage":"/assets/img/2024-05-17-BestPracticesforLonghorn_0.png","tag":["Tech"],"readingTime":5},{"title":"KubeCon EU 2024 파리 주요 포인트들","description":"","date":"2024-05-17 18:20","slug":"2024-05-17-KubeConEU2024ParisKeyTakeaways","content":"\n\n## 회의 요약\n\n최근 파리, 프랑스에서 열린 쿠베콘 유럽 행사에 다녀온 후에 다시 여행에 대해 생각하게 되었습니다. 행사에서 주요 강연과 세션들로부터 많은 것을 배우고, 플랫폼 엔지니어링에 대한 강조와 커뮤니티에서 많은 흥미로운 사람들을 만났습니다. 12,000명 이상의 참가자들과 100여 개의 후원사들이 참석하여, 이전보다 더 붐볐습니다.\n\n다음은 쿠베콘 유럽 2024에 대한 내 주요 포인트들입니다:\n\n- 나는 우리의 새로운(클라우드 기반) AI 지배자들을 환영합니다.\n- 책임있는 혁신에 대한 요구, 즉 \"비용과 지속 가능성을 잊지 말자\"\n- 플랫폼 엔지니어링이 중심에 서 있습니다.\n- 제품 사고가 이깁니다!\n- 개발자 경험 및 내부 및 외부 개발 루프에 대한 더 많은 관심\n- 보안은 여전히 큰 사업입니다.\n- 최종 사용자 이야기가 위로 올라갑니다.\n- 도구와 프레임워크 번들링이 계속됩니다.\n- Wasm: 핫한 주제, 그러나 불확실성이 있습니다.\n- Dapr가 점점 클라우드 네이티브 ESB로 자리 잡고 있습니다(좋은 방법으로)\n\n<div class=\"content-ad\"></div>\n\n이러한 주요 사항을 자세히 살펴보겠습니다. 기사 맨 끝에는 보너스 \"KubeCon EU를 위한 GTM 주요 사항\" 섹션도 포함되어 있어요. 프랑스어로 말하자면, allons-y!\n\n![KubeConEU](/assets/img/2024-05-17-KubeConEU2024ParisKeyTakeaways_0.png)\n\n# 나는 새로운 (클라우드 기반의) AI 지배자들을 환영합니다\n\n작년 12월 KubeCon NA Chicago에서 AI/LMM 콘텐츠의 부족에 놀라신 분들이 많았습니다. 그런데 KubeCon EU Paris에서는 이를 보완해줬어요... 그리고 더 더해졌습니다! 오프닝 데이 키노트 중 거의 모두가 AI에 초점을 맞춘 내용이었고(AI에 대한 조급한 마음까지!), 한 주 내내 전적으로 AI에 초점을 맞춘 AI 랩도 있었으며 다양한 각도에서 AI/LLM에 집중한 분과 세션이 많았습니다. 또한 클라우드 네이티브 트렌드와 \"AI\", \"LLM\", 또는 \"Generative\"이라는 단어가 섞인 스폰서 부스를 보는 것조차 무한했을 정도에요.\n\n<div class=\"content-ad\"></div>\n\n농담은 물론, 나는 CNCF 생태계가 AI에 대해 매우 열려 있다는 메시지를 주로 받았어. 행사 전체에서 본 사용자 이야기들은 주로 모델 훈련이 아니라 추론에 대해 클라우드 네이티브 기술을 사용하는 데 초점을 맞췄어; 특히 엣지 근처의 추론. 이는 이전에 클레이튼 콜먼이 한 말을 반영하고 있었어: \"만약 추론이 새로운 웹 앱이라면, 쿠버네티스는 새로운 웹 서버야.\" 주요 무대와 후원사 홀에서 보여진 K8s 기반 AI 빌더들을 위한 관련 \"도구\"들도 풍부했어.\n\n오프닝 첫날 두 번째 주요 연설로 NVIDIA가 \"Kubernetes에서 GPU로 AI 워크로드 가속화\"를 주제로 성공적으로 등장한 것이 정말 흥미로웠어. 그들이 쿠버네티스 이야기를 잘 얽었지만, 이것은 주로 하드웨어/인프라스트럭처 플레이일 것 같았는데, 이는 이 대중에 조금 불편하게 느껴졌을지도 모르겠어. 또한 NVIDIA가 GPU와 AI 칩 분야에서 현재 주도적인 위치를 차지하고 있다는 것을 강하게 상기시켜 주었어.\n\n관련 주제로, 주말에 All-in 팟캐스트를 듣다가, 베타들이 AI 스택의 네 가지 계층 중 어디에서 혁신과 가치 창출이 발생할지 의문을 제기했어: 인프라스트럭처, (기초) 모델, 개발 도구, 애플리케이션. 만약 NVIDIA가 인프라스트럭처 계층을 확보했다면, 우리의 다음 주요 연설은 모델 및 개발 도구 계층을 확보하려는 다른 회사를 강조했어: Microsoft.\n\n우리가 나중에 다룰 주제를 시작으로, Microsoft가 행사에서 첫 번째로 \"Kubernetes AI Toolchain Operator (Kaito)\"라는 AI 주제의 \"번들\"을 발표했어. Kaito는 Kubernetes 클러스터에서 AI/ML 추론 모델 배포를 자동화하고 falcon 및 llama2와 같은 모델을 대상으로 하고 있어.\n\n<div class=\"content-ad\"></div>\n\n이어서, Ollama는 프로그램에서 많이 소개되었고, 대형 언어 모델을 로컬에서 실행하는 사실상의 방법으로 보였습니다. 우리가 파리에 있었기 때문에 Mistral AI 팀도 칭찬을 받았어요. KubeCon에 참석하지 못했다 하더라도 AI 주제의 몇 가지 모임이 근처에서 열렸어요:\n\nAI 분야에서 혁신이 빠른 속도로 일어나고 있음을 부정할 수 없어요. 후원사 홀에서 이야기를 나눈 많은 최종 사용자들은 발전에 발맞추기 위해 노력하고 있었어요. 리더십이 AI를 수용하도록 장려했지만, 그들은 소규모 실험만을 실행하고 관련 발전과 따라가려 애를 쓰고 있었어요.\n\n이 점을 더 확실하게 보여주기 위해, 회의가 진행되는 동안 나의 X/Twitter 뉴스피드에는 지금까지 언급된 두 회사의 더 많은 발전상황이 소개되었어요. 지난 주 NVIDIA의 Blackwell 칩 및 Microsoft의 AI 분야 최근 인재 영입에 대해 더 알고 싶다면, Ed Sim의 뉴스레터를 확인해보세요.\n\n키노트와 3일간의 부스 대화에서 떠날 때, AI 미래가 드디어 KubeCon에 왔다는 생각을 하지 않을 수 없었어요 — 그러나 소문처럼 고르게 퍼져 있지 않다는 게 분명해요; 특히 최종 사용자들 사이에서 그렇습니다. 이제 클라우드 네이티브 군중이 다음 세대의 AI 앱을 개발하기 시작할 때인 것은 분명해요. 그리고 저는 우리의 새로운(클라우드 기반) AI 지배자를 환영합니다.\n\n<div class=\"content-ad\"></div>\n\n# 비용과 지속 가능성을 잊지 말아 담당하는 혁신을 요청합니다.\n\nAI에 대한 다양한 언급과 함께, 오프닝 키노트에서는 \"책임있는 혁신\"을 촉구했습니다. 이 구문은 전시회 전체에서 여러 차례 사용되었습니다. 맥락을 고려하면 \"혁신을 지속하되 오픈 소스를 활용하고 비용 및 에너지 절감을 염두에 두어야 한다\"는 의미로 받아들였습니다.\n\nCNCF가 이벤트를 주최하고 있기 때문에 OSS를 수용하고, 이상적으로는 CNCF 생태계에서 기술을 활용하라는 명백한 요구가 있었습니다. Redis가 같은 날 오프닝 키노트에서 이중 라이선스로 전환한다고 발표함으로써 청중에 불편함을 느낀 장면이 있었는데, 이는 최근의 이러한 변경 사항을 모두 생각나게 했습니다.\n\nCNCF가 지속 가능성에 대한 일부 어려움을 인정하는 것을 볼 수 있어서 좋았습니다. 세 번째 날의 키노트에서 Gualter Barbas Baptista가 독일 철도에서의 실제(기업) 사례인 \"IT 그린 구축: Deutsche Bahn에서의 플랫폼, 데이터 및 개발자 권한 부여의 여정\"에 지속 가능성을 요구했습니다.\n\n<div class=\"content-ad\"></div>\n\n이 주제는 중요합니다. 키노트 시간을 충분히 할애하는 것을 보아 좋았어요.\n\n# 플랫폼 엔지니어링이 중심 무대에 서다\n\n2022년 KubeCon EU에서 몇 명이 \"플랫폼 엔지니어링\"의 신흥 트렌드에 대해 이야기했습니다. 2024년에는 플랫폼 엔지니어링이 주류로 자리 잡았습니다.\n\n스폰서 쇼케이스는 플랫폼, 플랫폼 엔지니어링, 개발자 경험에 대한 언급으로 넘쳤으며, Solomon Hykes인 Dagger와 Docker의 공동 창시자가 진행한 훌륭한 키노트 세션도 있었습니다. \"10년의 변곡점: 컨테이너화된 세계에서 애플리케이션 전달의 미래\" (말하자면, 최근 InfoQ 팟캐스트에서 Solomon과 이야기를 나누었는데, Dagger에 대해 많이 배웠어요!)\n\n<div class=\"content-ad\"></div>\n\n인프라스트럭처 레이어 도구 및 프레임워크인 Kubernetes, 서비스 메쉬, 게이트웨이, CI/CD 등이 잘 발전하여 대부분의 사람들에게는 \"지루한 기술\"로 여겨집니다 (적어도 이들에게는 그렇습니다). 지금 큰 도전은 퍼즐 조각들을 조합하여 내부 고객인 개발자들에게 가치를 전달하는 것입니다. 위 트윗에 댓글로 역동적으로 관찰한 Betty Junod는 \"우리는 그 시대의 모든 PaaS를 해체했고... 모든 개별 레고로 놀아보았으며... 새로운 레고도 얻었고... 이제 그것들을 다시 조립하려고 노력하고 있다\"고 언급했습니다.\n\n최근 Syntasso 블로그에서 플랫폼 구축 레이어에 대한 내 정신적 모델을 논의했습니다. 애플리케이션 코레오그래피, 플랫폼 오케스트레이션 및 인프라스트럭처 구성이라는 세 가지 레이어 중에서, 애플리케이션 (포털) 레이어에 과도하게 집중하는 위험이 있다고 봅니다.\n\n마치 사람들이 AI 레이어에서 가치 창출 및 확보가 어디에서 일어날지에 대해 논쟁하는 것처럼, 플랫폼 공간 레이어에서도 같은 경향이 보인다고 생각합니다.\n\n<div class=\"content-ad\"></div>\n\n인프라스트럭처 레이어는 이윤이 많이 나오는 것으로 보이지만, 주로 후발주자들이 참여하는 영역입니다. 최근 Adam Jacob이 언급한 바에 따르면, OpenShift는 연간 매출이 10억 달러 이상을 올립니다. 그러나 동시에 HashiCorp와 Terraform에 대한 시장에서의 어려움을 볼 수 있습니다 (관련해서 OpenTOFU가 행사에서 많은 관심을 받았습니다).\n\n많은 기업이 내부 개발자 포털을 통해 애플리케이션 코레오그래피 레이어의 도구 및 프레임워크를 홍보하고 있습니다. Backstage, Port, Cortex 등과 같은 워크로드 사양 언어(Score, Radius) 등도 활발히 활용되고 있습니다.\n\n제 친구 Abby Bangser와 Whitney Lee는 플랫폼 사용자 경험에 관한 훌륭한 강연을 발표했습니다: \"가끔 돼지에게 필요한 건 립스틱일 수도 있어요!\"\n\n![이미지](/assets/img/2024-05-17-KubeConEU2024ParisKeyTakeaways_2.png)\n\n<div class=\"content-ad\"></div>\n\n애플리케이션 코레오그래피 레이어에서는 명확한 가치가 창출될 수 있습니다. 그러나 이번 KubeCon에서 Backstage에 대해 최고와 최악의 순간이 겹쳐보였어요. Backstage 커뮤니티가 여러 훌륭한 세션을 제공했고, 분명히 많은 역동성이 있었습니다 (CNCF 최종 사용자에게 가장 많은 기여를 한 프로젝트였습니다). 그러나 채택자들로부터 \"외부에서 제공되는\" 기능 부재와 포털을 운영하고 유지하기 위해 필요한 노력에 대한 불평이 많았습니다.\n\n이 애플리케이션 레이어는 일컬어 말하는 \"[개발자]의 손에 [플랫폼]의 길이 만난다\" 곳이며, 아마도 개발자 경험이 여기서 제작됩니다. 그러나 제 소프트웨어 아키텍처 경험에 근거하여, 제는 올바른 추상화를 생성하는 찬성자이며, 포털은 플랫폼의 목표를 실현하기에는 필수적이지만 충분하지는 않다고 생각합니다. 플랫폼 오케스트레이션 레이어는 내년에 많은 혁신이 일어날 것으로 보입니다. 저는 현재 오픈 소스 Kratix 플랫폼 오케스트레이터를 구축 중인 Syntasso 팀과 조금 편향되어 있는 것 같습니다만, Humanitec, Upbound (Crossplane), Massdriver, Mia-Platform, Qovery 등 다른 많은 회사들도 이 공간에 투자하고 있습니다.\n\n플랫폼 구축 공간의 상대적으로 미숙함을 상기시키기 위해, 가장 많은 관람자가 참여한 내용 중 일부는 클라우드 네이티브 앱을 제공하는 기본원리에 중점을 둔 것이었습니다. 예를 들어, Adrian Mouat은 \"현대적인 방식으로 컨테이너 이미지 빌드하기\"를 가득 찬 키노트 룸에 제시했습니다. Docker 부스는 Docker Build Cloud에 중점을 두고 있었고, Docker 관련 인사들이 1년 만에 행사에 돌아온 것을 보는 것이 좋았습니다. 그리고 많은 101-레벨 세션이 가득 차서 서 있었습니다.\n\n마지막으로, AI가 플랫폼 엔지니어링에 큰 영향을 미치는 것 같지는 않았어요! 대부분 애플리케이션, 플랫폼 및 인프라 구성 요소를 오케스트레이팅하고 라이프사이클을 관리하기 때문에, \"AI ROI\"는 다른 곳에서 더 높아 보입니다.\n\n<div class=\"content-ad\"></div>\n\n# 제품 사고 FTW!\n\n이전에 이야기한 내용과 밀접하게 관련된 주제로, 이번 KubeCon에서는 플랫폼, 프레임워크 및 개발자 도구에 \"제품 사고\"가 훨씬 더 적용되는 것을 보았어요.\n\n저는 Platfom Engineering Day에서 함께하는 이벤트와 Spotify의 Samantha Coffman이 하는 \"제품 사고를 통한 개발자 플랫폼 팀의 지원 강화\"라는 발표를 정말 즐겼어요. 다른 몇몇 플랫폼 개발자들도 이 발표가 제일 좋았다고 했어요. 물론, 우리 모두가 Spotify가 될 수는 없겠지만, Samantha은 매우 유용한 사고 모델을 제시하고 Marty Cagan의 우수한 작업에 강한 참조를 했어요(가치, 생존 가능성, 실행 가능성, 사용 가능성과 같은 네 가지 큰 위험에 대해서).\n\nNatWest의 Chris Plank가 하는 발표 \"혁신 발휘: NatWest Bank가 클라우드 네이티브 도구를 활용하여 제품으로서의 플랫폼 제공\"도 저에게 큰 인상을 주었어요. Chris는 규제가 엄격한 환경에서 플랫폼을 전개하기 위한 도전을 잘 소개하고, 이러한 장애물을 극복하기 위해 제품 사고와 기관 간 협력을 적용하는 이점을 제시했어요.\n\n<div class=\"content-ad\"></div>\n\n관련해서, Aviatrix의 Mitch Connors가 \"Product Market Misfit: Adventures in User Empathy\"를 발표했어요. 제 친구이자 전 동료인 Open Credo의 Nicki Watt도 \"To K8S and Beyond — Maturing Your Platform Engineering Initiative\"를 발표했는데, CNCF App Delivery TAG의 Platform Maturity Model에 대한 유용한 안내와 제품에 대한 생각의 적절한 조화를 제공해 주었어요.\n\n만약 KubeCon의 미래가 플랫폼 모양이라면, 제품 중심으로도 지속됐으면 좋겠어요!\n\n# 개발자 경험 및 내부, 외부 개발자 루프에 대한 더 큰 관심\n\n저는 당연히 주관을 가지고 있지만, 부속으로 이루어진 App Developer Con에서 발표한 \"Testing Cloud Apps: Mocks vs. Service Virtualization vs. Remote Tools\" (아직 비디오는 없어요!) 를 보았어요. 그러나 행사 전체에서 개발자 경험 및 내부, 외부 개발자 루프에 집중하는 중요성에 대한 언급이 많이 있었어요.\n\n<div class=\"content-ad\"></div>\n\n![KubeConEU2024ParisKeyTakeaways](/assets/img/2024-05-17-KubeConEU2024ParisKeyTakeaways_3.png)\n\n안녕하세요! 제 친구 AtomicJar(이제는 Docker)와 Diagrid의 Oleg Šelajev, Alice Gibbons은 \"간단화된 내부 및 외부 클라우드 네이티브 개발 루프\"를 발표했어요. 그리고 멋진 분들인 GitPod 팀에서 클라우드 개발 환경 (CDEs)에 대한 이야기를 많이 들었어요. 또한 CDE 분야의 새로운 흥미로운 소식을 Daytona팀에서 들었죠.\n\n행사에서 고위 리더들과 이야기할 때, 모두 개발자 경험의 가치를 알고 있지만 그것을 리더십에 \"팔기\"에 어려움을 겪는다는 이야기를 자주 들었어요 (특히 후기 ZIRP 시대에서). 일반적인 의견은 DORA/SPACE 지표에 초점을 맞추고 조직간의 협업을 통해 도움을 받을 수 있다는 거예요. 이전에 SNS에서 공유했듯이 Abi Noda와 함께 DX Engineering Enablement 팟캐스트 몇 에피소드를 듣는 것은 언제나 좋은 선택이라는 걸 상기시켜 드립니다.\n\n# 보안은 여전히 중요한 비즈니스입니다.\n\n<div class=\"content-ad\"></div>\n\n키노트는 상대적으로 보안에 대해 가볍게 다뤄졌지만, 세션과 후원 쇼케이스는 분명히 다르더군요. \"보안\"이라는 용어로 세션 카탈로그를 싹 훑어보면 수십 개의 이야기가 나옵니다. 안전한 공급망부터 네트워크 침입 및 플랫폼 보안까지 다양한 주제가 잘 다뤄졌어요.\n\n특정 세션들은 보안 구현 및 도구에 명확한 초점을 맞추며, Kyverno, Falco 및 OPA가 쇼를 훔쳤습니다. 안전한 공급망은 컨테이너 빌드 도구(SBOMS 및 SLSA와 함께), Keptn, Harbor 등을 자세히 다뤘죠. 또한 네트워크 보안에 많은 주목이 갔는데, Cilium(및 이 문맥에서의 eBPF에 대한 흥미로운 언급), Linkerd(Cloudflare의 Pingora에 대한 의문이 있는 상태), Istio가 언급되었습니다.\n\n# 종단 사용자 이야기가 업계에서 주목받고 있어요\n\n한번 더 강조하면, 프로그램에 참여한 종단 사용자 키노트와 세션을 보는 것이 좋았습니다. 이러한 세션 중 많은 것들이 \"업계에서 주목받고 있어요\"는 방향으로 이동하고 있었습니다. 그들이 Kubernetes(또는 다른 CNCF 기술)를 도입한 방법을 소개하는 대신에, 확장, 지속가능성, 비용 절감, 또는 개발자 생산성 향상과 같은 메시지를 주로 다뤘어요. 앞서 언급한 Deutsche Bahn의 지속가능성에 대한 키노트는 이를 잘 보여주는 좋은 예시였습니다.\n\n<div class=\"content-ad\"></div>\n\n저는 닉 루티글리아노와 다니엘 드 레프렌티뇨가 진행한 “How Spotify Re-Created Our Entire Backend Without Skipping a Beat”라는 Spotify 토크도 즐겁게 감상했어요. 이 토크는 제품 사고를 사용하여 제품화되고 유지되는 K8s 기반 환경에 대해 다뤘죠. 이 분야에서 다른 좋은 토크들로는 다음과 같은 것들이 있어요:\n\n- 노르웨이 공공 부문 플랫폼 성숙도 현황\n- 레고 그룹의 제조용 플랫폼 엔지니어링 접근 방식: 기본 블록 유지하기\n- 인투잇의 서비스 메시 확장: 300개 이상 클러스터를 넘어서는 셀프 서비스\n- 블랙록의 KEDA를 사용해 몇 년 동안 수백만 달러를 절약하는 법\n- TikTok의 Edge Symphony: 멀티 클러스터 컨트롤러로 범위를 넓히는 방법\n\n# 도구 번들링이 계속됩니다\n\n이전 KubeCon 요약에서 본 것처럼, 도구와 프레임워크의 번들링이 계속되었습니다. 몇 가지 예외를 제외하고는, 공급업체들이 “클래스 최고의 솔루션”이 되려고 싸우던 시절은 사라졌어요.\n\n<div class=\"content-ad\"></div>\n\nCould you please change the table tag to Markdown format?\n\n<div class=\"content-ad\"></div>\n\n흥미를 끌기 위해, 제 플랫폼 엔지니어링에 초점을 맞춘 친구들과 얘기를 나눠본 결과, 여전히 Wasm에 대한 \"핵심 사용 사례\"를 찾고 있었어요. 이야기에 따르면 컨테이너 기반 및 서버리스 앱의 조합이 필요한 세분화와 리소스 사용 제어를 제공했습니다. 그들은 사무실로 돌아가서 AI 도구에 대해 더욱 탐구하고 싶어했습니다.\n\n일반적으로 Wasm에 대해 긍정적입니다. 예전에 프록시와 API 게이트웨이 작업을 많이 해왔기 때문에 항상 Lua와 같은 것을 대체할 수 있는 Wasm의 플러그인 사용 사례를 볼 수 있었습니다. 하지만 미래에는 기조 발표 시간 대신 뒷장에서 더 많은 사용 사례를 보게 될 지 궁금합니다.\n\n# Dapr는 클라우드 네이티브 ESB(좋은 방식으로)입니다\n\nDapr 프로젝트에 대해 오랫동안 긍정적이었던 것은 비밀이 아닙니다. 이 프레임워크는 10년 전 초기 클라우드 네이티브 앱을 개발할 때 접근할 수 있었으면 좋았을 것이라고 생각했습니다. 이번 이벤트 중에서도 기술에 관한 많은 언급을 볼 수 있어 기쁘었고, 예상치 못한 세션에서도 잘 통합된 것과 관련한 집중이 자주 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n평소처럼, Diagrid의 Bilgin, Mauricio 및 Mark와 흥미로운 토론을 나눴어요. 개발자 패턴, 클라우드 네이티브 응용 프로그램 미들웨어의 미래, 그리고 \"서버리스 시대 이후의 클라우드 컴퓨팅: 현재 트렌드 및 이상\"에 대해 이야기했죠.\n\n여러 명이 Dapr을 옛날 스타일의 엔터프라이즈 서비스 버스에서 언급할 때 웃음을 자아내며, Dapr을 \"클라우드 세대용 ESB\" 또는 \"그렇게 되어야 했던 ESB\"로 프레임하고 있었어요. 전 엔터프라이즈 자바 개발자로 일할 때 여러 ESB를 다뤘던 경험이 있어서 이 소리들을 들으면서 웃음과 고개를 끄덕였죠! 희망히, 새로운 세대의 개발자들은 우리가 ESB에 대해 했던 장난을 기억하지 않았으면 좋겠어요.\n\n# 보너스: KubeCon EU를 위한 GTM 요약\n\n이번에 제 일상 업무에서 여러 개발자 도구 회사들에게 Go-To-Market, 제품 마케팅 및 개발자 관계에 대한 조언을 제공하고 있어요. 그래서 한두 문단을 공유하고 싶어요. 후원사 쇼케이스를 둘러보면 현재 핫하고 판매 가능한 트렌드를 몇 가지 알 수 있었죠.\n\n<div class=\"content-ad\"></div>\n\n- AI 기반의 모든 것\n- 플랫폼 엔지니어링\n- 보안\n- 관찰 가능성\n- 비용 절감 (또한 흥미로운 것은 \"FinOps\" 라벨이 일관되게 적용되지 않았다.)\n\n나는 이번에 쿠베콘 정기 참가자 중에 부스를 운영하지 않는 사람들이 여러 명 있다는 것도 처음 알게 되었다, 특히 VC 지원을 받은 A/B 시리즈 펀딩 공간에 속한 사람들 중. 창립자와 GTM 직원들과 이야기를 나누면서 비용 절감, EU 시장을 대상으로 지향하지 않음, 그리고 이전 쿠베콘에서의 부스 스캔이 $$$/€€€로 전환되지 않았다는 이유로 그들의 ICP(즉, 이전 쿠베콘의 부스 스캔이 돈으로 전환이 되지 않았다는 것)의 리드 품질이 낮다고 믿는 것을 발견했다.\n\n이는 소소한 예기지만, 나는 또한 이번 이벤트에서 훨씬 더 많은 영업 사원들을 발견했다. 내가 커리어 초반(2000년대 후반의 Java 공간)에 컨퍼런스에 참석하기 시작했을 때, 스폰서 쇼케이스에서 과도하게 열정적인 영업 사원들에게 접근당하는 것은 완전히 정상적이었다. 이것은 소프트웨어 툴링이 제품 중심으로 발전하고 구매력이 개발자로 변하며 개발자 관련 역할이 나타남에 따라 서서히 변화했다(Stephen O'Grady의 \"The New Kingmakers: How Developers Conquered the World\" 참조).\n\n쿠베콘 부스는 역사적으로 개발자 관계, 기술적인 Go-To-Market, 그리고 창립자들이 중심에 있었다. 이들은 여기에도 있었지만, 나는 부스에서 만남에서 만남으로 걸어갈 때 말할 것을 찾는 영업 사원들에게 비유적으로 (가끔은 실제로도) 당한 것을 발견했다. 한 영업 사원은 나가 바쁘다고 대답하고 영업 설명에 관심이 없다고 답했을 때 거의 적대적이었는데, 그 정도로 나는 내 대답을 확인하고 입맛을 감췄다(그는 몇 가지 근거 없는 공격으로 나를 완전히 당황하게 했지만, 행동 규범은 양쪽 모두에게 적용된다!)\n\n<div class=\"content-ad\"></div>\n\n시간이 까다롭고 영업 목표가 어려울 수 있다는 것을 알지만, 대상 체르의 문화를 이해해야 합니다. KubeCon 스폰서 홀에서 강하게 팔아넣는 것은 효과적이지 않다고 생각해요.\n\n저는 개인적으로 Shomik Ghosh의 Software Snack Bites 팟캐스트에서 처음 알게 된 기술 SDR 역할에 대해 열정을 가지고 있어요. 또한 개발자 관계자들이 제품 중심 역할에 더 많이 눈길을 띄게 될 것이라고 믿어요. 이에 대해 더 자세히 썼으니 링크를 참조해주세요:\n\n# 마무리: 커뮤니티, 커뮤니티, 커뮤니티!\n\nKubeCon을 포함한 모든 행사에서 이벤트를 더 포괄적으로 만들기 위해 커뮤니티의 노력에 감명을 받았어요. 저는 중요한 강연 및 다른 세션에 수어 통역자를 확보한 청각장애 및 장애인 작업 그룹에 박수를 보내요.\n\n<div class=\"content-ad\"></div>\n\n니키타 라그나스와 아파르나 수브라마니안이 행사를 공동 주최한 데에서 훌륭한 일을 해냈어요. 또한, 처음으로 행사 공동 주최한 클라우드 네이티브 친구 카스퍼 보그 니센에게도 큰 박수를 보냅니다! 포용에 관한 주제를 더 깊이 다루기 위해, 카스퍼는 클라우드 네이티브 커뮤니티의 포용적 성장의 10년을 주제로 한 주요 토론 패널 \"다양성 속의 통일: 클라우드 네이티브 커뮤니티의 포용적 성장\"을 주관했어요.\n\n나는 KubeCon EU에서 보낸 시간을 철저히 즐겼어요. 커뮤니티 여러분과 많은 소통을 나눌 수 있어 정말 좋았고, O'Reilly 부스에서 \"API 아키텍처 마스터링\" 책 서명 행사를 열면서 즐거운 시간을 보냈어요. 또한, PlatEngDay의 공동 주최자인 Syntasso 크루와 같이 현재 함께 일하고 있는 분들과 시간을 보낸 건 정말 즐거웠어요. 이 협력 행사의 다음 단계가 기대돼요!\n\n아직 모든 배운 것을 정리 중이라 놓친 중요한 주제나 주요 인물 언급이 있었다면 알려주세요! \n\n만나지 못한 분들과 만날 기회가 없었다면 소셜 미디어나 평소의 연락처로 연락해주세요. 11월에 솔트레이크시티에서 만나요!","ogImage":{"url":"/assets/img/2024-05-17-KubeConEU2024ParisKeyTakeaways_0.png"},"coverImage":"/assets/img/2024-05-17-KubeConEU2024ParisKeyTakeaways_0.png","tag":["Tech"],"readingTime":13},{"title":"DevOps 엔지니어로 빛날 5가지 간단하면서도 강력한 전략","description":"","date":"2024-05-17 18:18","slug":"2024-05-17-5simpleyetpowerfulstrategiestoshinebrightasaDevOpsengineer","content":"\n\n안녕하세요, 미래의 데브옵스 엔지니어 여러분!\n\n데브옵스 여정에 착수하셨군요! 이것은 단순히 도구와 프로세스를 숙달하는 것 이상의 의미가 있습니다.\n\n데브옵스에서 빛을 발하는 것은 기민성, 협력, 지속적 개선이 필요한 환경에서 돋보일 수 있는 능력을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n경험丰富한 데브옵스 엔지니어로서, 저는 여러분을 도우기 위해 다섯 가지 간단하지만 강력한 전략을 공유하려고 해요. 이 전략은 여러분을 돋보이게 하는 데에 도움이 되는 것뿐만 아니라 데브옵스 역량을 한 단계 높여줄 거예요.\n\n# 1. 지속적인 개선을 위한 지속적인 학습\n\n데브옵스는 끊임없이 발전하고 있기 때문에, 굳어버림은 적의요.\n\n지속적인 학습의 마인드를 가지세요. 최신 도구, 방법론 및 산업의 최고 관행에 대해 최신 정보를 유지하세요.\n\n<div class=\"content-ad\"></div>\n\n웨비나에 참석하고, 온라인 강좌를 수강하며, DevOps 커뮤니티에 적극적으로 참여하세요. 배울수록 팀에 더 큰 가치를 제공할 수 있습니다.\n\n# 2. 모든 것을 자동화하세요. 단, 전략적으로\n\n자동화는 DevOps의 핵심이지만 무모한 스크립팅과는 다릅니다.\n\n자동화가 실질적인 영향을 미칠 수 있는 영역을 전략적으로 선택하세요. Jenkins, Ansible 또는 GitLab CI와 같은 도구들을 숙달하여 반복적인 작업을 간소화하고, 더 복잡한 도전에 집중할 수 있도록 해보세요.\n\n<div class=\"content-ad\"></div>\n\n효율적인 자동화는 단순히 시간을 절약하는 것뿐만이 아니라, DevOps 파이프라인 전반의 효율성을 향상시키는 것이 중요합니다.\n\n# 3. 핵심 원칙으로서의 보안\n\n보안은 나중에 고려해야 할 사항이 아니라, DevOps의 기본적인 요소입니다.\n\n프로젝트의 시작부터 보안을 중요시하십시오. 코드, 컨테이너 및 인프라를 안전하게 유지하기 위한 모범 사례를 이해하고 실행하세요.\n\n<div class=\"content-ad\"></div>\n\n안전하고 견고한 시스템을 구축하는 의지를 과시하세요. 데브옵스의 세계에서 강력한 보안 포지션은 영예의 표입니다.\n\n## 4. 지속적인 개선 문화를 육성하세요\n\n데브옵스는 도구와 프로세스뿐만이 아니라 문화적 전환입니다. 팀 내에서 지속적인 개선 문화를 육성해보세요.\n\n정기적인 회고를 추진하고 피드백을 수집하며 프로세스를 개선해보세요. 카이젠(Kaizen)의 마인드를 수용하세요 - 지속적인 개선을 추구하는 태도입니다.\n\n<div class=\"content-ad\"></div>\n\n이는 당신의 데브옵스 관행의 효율성을 향상시키는 것뿐만 아니라 뛰어난 결과물을 전달하기 위한 당신의 헌신을 보여줍니다.\n\n## 5. 다양한 팀과의 효과적인 협업\n\n데브옵스는 협업에 중점을 두고 있습니다. 개발과 운영 팀 간의 간극을 좁히기 위해 강력한 커뮤니케이션과 협업 기술을 개발하세요.\n\n복잡한 기술적 개념을 간단한 용어로 설명할 수 있다면 이는 귀한 자산입니다. 팀원들과 적극 소통하고, 그들의 관점을 이해하며 통합된 목표를 향해 노력하세요.\n\n<div class=\"content-ad\"></div>\n\n협업에서 능숙한 데브옵스 엔지니어는 가치 있는 팀원입니다.\n\n# 실행 가능한 전략\n\n- 매주 학습과 탐험을 위한 전용 시간을 확보하세요.\n- 업무 흐름에서 반복되는 작업을 식별하고 점진적으로 자동화를 시작하세요.\n- 프로젝트의 보안 평가를 정기적으로 실시하고 피드백을 요청하세요.\n- 팀 회의에 적극적으로 참여하고 인사이트를 공유하며 개방적인 소통을 장려하세요.\n- 프로세스 개선에 대한 토론을 시작하고 팀으로 작은 성취를 축하하세요.\n\n# 마무리 생각\n\n<div class=\"content-ad\"></div>\n\nDevOps 엔지니어로 미래를 염두에 두려면 기술 능력, 협업 능력, 지속적인 개선에 대한 헌신이 결합된 조합이 필요합니다.\n\n이러한 전략들을 일상적인 실천에 적용함으로써, 여러분은 단순히 자신의 역할에서 뛰어나는 것뿐만 아니라 다양한 DevOps 커뮤니티에 기여할 수 있을 것입니다.\n\n여정이 목적만큼 중요하다는 것을 기억하세요. 즐거운 코딩과 협업되는 시간 보내세요!","ogImage":{"url":"/assets/img/2024-05-17-5simpleyetpowerfulstrategiestoshinebrightasaDevOpsengineer_0.png"},"coverImage":"/assets/img/2024-05-17-5simpleyetpowerfulstrategiestoshinebrightasaDevOpsengineer_0.png","tag":["Tech"],"readingTime":3},{"title":"우리의 오픈 데이터 플랫폼으로의 변혁 여정","description":"","date":"2024-05-17 18:16","slug":"2024-05-17-Ourtransformationjourneytowardanopendataplatform","content":"\n\n저자: Condé Nast의 데이터 엔지니어링 부사장 Nana Yaw Essuman, Condé Nast의 고급 엔지니어링 매니저 Ben Hall 및 Condé Nast의 엔지니어링 매니저 Zachary Bannor\n\n# 데이터 미로 헤쳐나가기: 도전에 맞서다\n\n우리 조직은 전 세계 관객에게 탁월한 콘텐츠와 매혹적인 경험을 전달하는 미션을 추진하고 있습니다. 오늘날의 디지털 환경에서 데이터의 가치를 인지한 우리는 37개의 미디어 브랜드를 32개 시장에서 대상으로 고객 상호작용과 참여를 극대화할 데이터 인사이트를 내부 팀에게 제공하기 위해 데이터 여정을 시작했습니다.\n\n그러나 우리는 기존의 복잡한 다양한 데이터 플랫폼으로 이루어진 인프라가 우리의 진전을 방해한다는 것을 빨리 깨달았습니다. 가치 있는 데이터가 조직 전체에 걸쳐 고립되어 있을 때 우리는 여러 기술을 분리해서 탐색해야 했습니다. 데이터 과학자들이 데이터에 접근하기 위해 엄청난 시간을 소비하는 반면, 비즈니스를 촉진할 수 있는 새로운 ML 모델 실험에 거의 시간을 할애할 수 없었습니다. 특히 중앙화된 기업 데이터 플랫폼인 \"에버그린\"을 내부적으로 부르는 세계 3개 주요 지역 전체 영역에 확장하는 결정으로 이 복잡한 환경의 확장이 큰 장애물이었습니다.\n\n<div class=\"content-ad\"></div>\n\n에버그린의 비전을 실현하려면 3가지 과제를 해결해야 했습니다:\n\n- 높은 양과 다양성의 데이터를 이해하기: 우리는 유명 패션, 라이프스타일 및 엔터테인먼트 브랜드가 포함된 방대한 출판물, 웹사이트 및 디지털 플랫폼의 포트폴리오를 보유하고 있어 매일 수십 테라바이트의 데이터를 생성합니다. 서로 다른 비즈니스 부문 간의 데이터 솔로로 인해 이 데이터를 관리하기가 매우 어렵습니다. 일관되지 않은 보고서와 상충되는 데이터 숫자로 신뢰의 결여가 발생하며 이는 이해관계자들이 데이터에 신뢰를 하지 못하게 만듭니다. 게다가 데이터를 수집하고 분석할 중앙화된 지점의 부재는 소비자나 상업적 수익을 포함한 다양한 수익 채널의 전반적인 건강을 평가하는 것을 어렵게 만들었습니다.\n- 증가하는 비용 관리: 또 다른 장애는 저장 및 컴퓨팅 비용을 정확하게 반영하는 것이었습니다. 초기에는 특정 데이터 솔로를 위해 레드시프트를 일부로 사용했습니다. 레드시프트 및 일부 구글 빅쿼리를 사용하면, BI 사용자에게 관련 데이터를 제공하는 분석 쿼링 기능을 제공했습니다. 그러나 하류 분석적인 요구사항을 지원하기 위해 이를 다른 서비스들과 연결해야 했으며, 이는 시간과 비용이 많이 소요되는 과정이었습니다. 저장 측면에서, 데이터는 다른 Amazon S3 버킷에 저장되어 중복된 데이터, 운영 효율성의 저하 및 비용 증가를 초래했습니다. 이는 우리의 세계화된 운영 목표에 부합하지 않음을 인지했습니다.\n- 리소스 집약적인 프로세스 개선: 데이터 팀 내 많은 프로세스가 매우 수동적이었습니다. 데이터에 접근하기 어려워 데이터 엔지니어는 ML 및 분석 팀을 위한 스크립트를 작성하는 데 상당한 시간을 소비했습니다. ML 팀 또한 이러한 수동적인 프로세스로 인해 심각한 어려움을 겪었습니다. 데이터 과학팀은 자신의 클러스터를 프로비저닝하고 세부 조정하기 위해 시간을 투자할 때 ML 모델을 빌드하고 훈련하는 데 시간을 집중하지 못했습니다. 데이터 엔지니어링의 리소스 제약은 총 플랫폼 비용을 높여 그럼에 불을 붙였습니다.\n\n# 가치와 규모를 제공하기 위한 오픈 플랫폼을 활용하기\n\n저희 여정의 첫걸음은 적합한 데이터 플랫폼을 선택하는 것이었습니다. 이전 섹션에서 제시된 3가지 과제를 극복할 수 있는 플랫폼을 선택하는 것이 중요했습니다. 우리는 데이터 팀과 비즈니스 팀 모두에 걸칠 수 있는 중앙 집중식 데이터 플랫폼을 구축해야 한다는 것을 알고 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n우리는 우리의 요구 사항을 어떻게 효과적으로 해결할 수 있는지 보기 위해 Snowflake를 평가하기 시작했지만, 빠르게 적합하지 않다는 것을 깨달았습니다. 구조화된 데이터 세트를 중앙에 집중시킬 수 있는 능력을 제공했지만, 주로 분석 및 보고 작업을 위해 설계되었습니다. 우리의 데이터 과학 작업에 필요한 네이티브 지원이 부족했기 때문에 데이터 팀이 다시 기계 학습 팀과 분리되어 있는 것이었습니다. 우리의 데이터 규모를 감안할 때, Snowflake에서 ETL 프로세스를 실행하는 비용과 앞으로 구현하고자 했던 실시간 사용 사례를 지원할 수 있는지에 대해 걱정되었습니다. 우리가 정말 원했던 것은 우리의 기계 학습 요구 사항을 네이티브로 지원하고 데이터와 분석 팀 간의 협업을 촉진할 수 있는 열린 데이터 환경이었습니다.\n\n다음으로, Databricks를 데이터 플랫폼으로 채택하는 것이 우리의 과제를 해결할 수 있는지를 평가했습니다. 그 당시 이미 워크스페이스가 운영 중이었기 때문에 아직까지 확장할 수 있는 플랫폼으로 선택하지 않았습니다. 그러나 데이터 및 기계 학습 능력을 하나의 중앙 플랫폼에서 제공하는 포괄적인 솔루션을 제공했습니다. 이는 사일로를 제거하고 비즈니스 팀 뿐만 아니라 데이터 및 분석 팀 전체에 걸쳐 데이터와 프로세스를 통합하는 목표를 달성할 수 있게 해 줄 것입니다. ML을 위한 네이티브 지원 및 MLflow를 사용한 ML Ops 능력은 데이터 과학자가 효율적으로 작업할 수 있도록 허용할 것입니다.\n\n구조화된 데이터뿐만 아니라 구조화되지 않은 데이터 모두에 대한 Apache Spark™ 지원을 통해 우리는 실시간 사용 사례와 콘텐츠(편집, 비디오, 오디오) 데이터 처리와 같은 고급 기능으로 성장할 수 있었습니다. 생산성 측면에서 단일 진실의 단일 환경과 원격 개발자, 데이터 과학자가 작성한 코드 모두를 버전 관리하고 CI/CD를 사용하여 쉽고 빠르게 배포하는 것이 중요한 요구 사항이었습니다.\n\n규모 확장을 지원하기 위해 열린 플랫폼을 갖고 싶다는 우리의 욕망을 고려하여 Databricks Data Intelligence Platform으로 결정했습니다. 이 플랫폼은 오픈 소스 기술 위에 구축되어 있으며 오픈 소스 커뮤니티에 다시 기여합니다. 또한, 이들의 플랫폼이나 동등한 오픈 소스 기술을 활용하는 엔지니어들의 커뮤니티는 세계적으로 엔지니어들이 많은 도움을 받을 수 있게 해줍니다. 우리의 여정 중 가장 중요한 부분은 데이터 이전이었으며, Delta Lake의 기본 파일 형식이 Apache Parquet(다른 오픈 소스 프로젝트)인 것을 보고 데이터와 통합된 기존 시스템이 다른 파일 형식으로 변환하는 시간을 소모하지 않고도 문제없이 원활하게 작동할 것이라는 것을 간단하게 이해할 수 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n데이터브릭스를 도입함으로써 데이터 과학 능력이 크게 향상되었습니다. 이를 통해 우리는 데이터를 효과적으로 활용하여 다양한 사용 사례를 통해 소비자 경험을 개인화하고 타깃팅할 수 있게 되었습니다. 광범위한 사용자 행동 데이터에 접근하여, 데이터 과학자와 머신 러닝 엔지니어들은 독창적인 구독 성향 모델을 개발하는 등의 사용 사례를 구현할 수 있었으며, 독자의 참여를 높은 정확도로 예측하여 독자가 레시피를 손쉽게 찾을 수 있게 해주는 것과 사용자에게 더 정확하고 관련성 높은 광고 타켓팅을 제공하는 등의 기능을 구현할 수 있었습니다.\n\n## 데이터 오디세이에 도입된 레이크하우스 아키텍처가 우리에게 준 이점\n\n지금까지 우리는 저희의 여정과 전 세계적으로 흩어진 다양한 비즈니스 단위에 걸처있는 분열된 인프라를 실행하려고 한 도전들에 대해 살펴보았습니다. 비즈니스 단위 소유자들과 협력하여 데이터와 분석 요구 사항을 분석하여 새로운 프레임워크에 대한 요구 사항을 정의하기 시작했습니다. 우리의 목표는 데이터에 대한 새로운 신뢰를 구축하고 모든 데이터 및 플랫폼 비용을 효율적으로 향상시키고 생산성을 향상시키기 위해 모든 데이터를 한 곳에 모으는 것이었습니다.\n\n레이크하우스 아키텍처를 통합한 이후, 데이터 과학자들의 생산성이 크게 향상되었으며, 약 2.6백만 달러(USD)의 가치를 창출했습니다. 데이터브릭스의 노트북, PySpark 및 MLflow 솔루션을 결합하여 ML 실험을 빠르게 수행하고 동시에 약 6백만 달러(USD)의 클라우드 LTD에서 데이터 오케스트레이션 및 운영 비용을 줄일 수 있었습니다. 내부 라이브러리에서 모델을 배포하거나 새로운 써드파티 모델을 실험하는 것과 같은 작업들이 쉬워졌습니다. 데이터브릭스를 사용하기 전에 우리의 모델을 제공하는 서버를 배포하는 것은 상당한 노력이 필요했습니다. 자동화된 인프라, 클러스터 관리 능력 및 서버리스 추론을 이용하여 기존과 달리 모델을 즉시 제공할 수 있게 되었습니다. 이를 통해 고객에게 제공하는 데 걸리는 시간을 개념에서 고객까지의 시간을 개월에서 일 수준으로 줄일 수 있었습니다. 또한 새로운 모델을 배포하기 위해 단계적인 롤아웃을 사용하여 운영 위험을 크게 줄일 수 있었습니다. 이러한 모든 요인을 결합하여 배포되는 실험의 수와 속도가 급격히 증가하며, 이로 인해 반복 속도와 팀 간 협업이 가속화되었습니다. 결과적으로, 데이터 과학 팀의 고객에게 미치는 영향과 ML 워크플로우의 성능이 크게 향상되었습니다.\n\n<div class=\"content-ad\"></div>\n\n더 많은 오픈 데이터 인텔리전스 플랫폼 제품을 사용함에 따라 우리는 생태계에서 다른 혜택을 발견했습니다. 예를 들어, Databricks 피처 스토어를 사용하면 모델 간에 기능을 쉽게 구성, 공유, 재사용할 수 있으므로 모델마다 기능을 새롭게 만들 필요가 없습니다. 실험을 위한 놀이터로서, 우리에게 가치 있는 엔지니어링 시간을 절약하고 생산 중인 모델 수를 빠르게 늘릴 수 있게 해 줍니다.\n\n# 데이터 민주화를 통한 비즈니스 지원\n\n조직 전체에 이러한 가치 있는 데이터 인사이트를 공유하기 위해 Presto를 Databricks SQL Serverless로 대체하여 데이터를 중앙 집중화하고 비용을 줄이면서 사용자에게 셀프 서비스를 제공하는 결정을 내렸습니다. SQL 데이터 웨어하우스는 이제 BI 도구를 지원하고 수백 건의 애드혹 보고서와 경영 대시보드를 생성하여 브랜드 건강, 관객 데이터 및 콘텐츠 성과를 분석할 수 있게 해 줍니다.\n\nSQL 데이터 웨어하우스를 사용하면 분석가들이 데이터 엔지니어 및 데이터 과학자들이 사용하는 동일한 데이터 세트에 액세스할 수 있습니다. 이를 통해 조직 전체에 단일 정보원을 제공하고, 분석가들이 다른 시스템에서 복사한 오래된 데이터를 기반으로 작업하는 것을 방지할 수 있습니다. SQL 데이터 웨어하우스는 BI 워크로드를 지원하고 전통적인 테이블 액세스 제어를 사용하기 때문에 사용자들이 데이터와 상호 작용하는 안전하고 확장 가능한 방법을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n저희에게 데이터 거버넌스를 강화하는 것이 매우 중요합니다. 그래서 Databricks 워크스페이스 전반에 Unity Catalog를 도입했습니다. 저희 데이터는 여러 지역에 걸쳐 퍼져 있기 때문에 Unity Catalog와 Delta Sharing을 활용하여 다양한 정밀도로 데이터를 안전하게 공유했습니다. 이러한 기능들을 통해 데이터의 전체적인 시각을 갖게 되었고, 규정 요건을 준수하는 것을 확인할 수 있었습니다. 앞으로는 Unity Catalog를 기반으로 거버넌스 도구를 도입하여 데이터 거버넌스와 법률 팀이 자산 거버넌스를 강화하는 데 도움이 되기를 기대합니다.\n\n# 지출 효율과 생산성을 재상상하고 고속화하기\n\n또한 Fivetran과 dbt를 레이크하우스에 통합하여 데이터 통합을 크게 단순화하고 비즈니스 로직 변환을 중앙 집중화했습니다. Fivetran을 통해 모든 채널에서 데이터를 손쉽게 중앙 집중화할 수 있었습니다. 3rd 파티 SaaS 플랫폼에 대한 다양한 커넥터는 우리의 모든 브랜드에서 데이터를 통합하여 종합적인 데이터에 기반한 신속한 의사결정을 가능하게 했습니다. dbt를 통해 레이크하우스 아키텍처 내 골드 수준 테이블에서 SQL 쿼리를 실행할 수 있었습니다. 이를 통해 동적 플랫폼 전반의 지출을 효과적으로 관리하고 자원을 최적화하여 더 나은 ROI를 이끌어냈습니다.\n\n<div class=\"content-ad\"></div>\n\n# 하류 애플리케이션을 위한 데이터 인사이트 및 분석 가속화\n\nDatabricks 플랫폼을 활용하여 통합 데이터 플랫폼 아키텍처를 구축했습니다. 이를 통해 데이터 활용 방법이 혁신되어 협업과 ML 모델 실험이 촉진되었습니다. 저희의 레이크하우스에서는 월별 방문자가 1억 명을 넘는 웹 사이트를 기반으로 한 인사이트를 수집, 분석, 및 배포하고 있습니다. 횡단팀 협업과 통합된 데이터의 동력으로 현재 2000개 이상의 ML 모델이 운영 중이며 미래에 더 많은 모델을 계획 중에 있습니다.\n\n프로덕션 환경의 2000개 이상의 ML 모델을 구현하는 결정적인 솔루션 제공과 데이터 과학팀이 참여하여 참여와 충성도를 증진하는 새로운 ML 솔루션을 지속적으로 개발할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n우리의 비전을 가능하게 한 모든 데이터 엔지니어들에게 특별한 감사를 전합니다.","ogImage":{"url":"/assets/img/2024-05-17-Ourtransformationjourneytowardanopendataplatform_0.png"},"coverImage":"/assets/img/2024-05-17-Ourtransformationjourneytowardanopendataplatform_0.png","tag":["Tech"],"readingTime":7},{"title":"데이터브릭스에서 CDC를 활용해 민감한 데이터 보호하기","description":"","date":"2024-05-17 18:15","slug":"2024-05-17-ProtectingSensitiveDatawithCDCinDatabricks","content":"\n\n빅 데이터를 활용하여 비즈니스 지능적인 의사 결정을 하는 데 관심이 있는 모든 종류의 기업들에게 Databricks가 선호되는 선택지로 자리 잡고 있습니다. Spark의 창시자들에 의해 설립된 이 기업급 플랫폼은 데이터 애플리케이션을 개발하는 데 필요한 다양한 데이터 엔지니어링 및 ML 리소스를 통합합니다.\n\n![이미지](/assets/img/2024-05-17-ProtectingSensitiveDatawithCDCinDatabricks_0.png)\n\nDatabricks가 제공하는 모든 기능을 설명하면 이 글이 너무 길어져서 읽기 어려워질 것입니다. 그들은 지속적으로 새로운 기능을 출시하고 현재 서비스를 개선하여 사용자 경험을 향상시키고 있습니다. 간략하게 설명하자면, 저희가 Secure CDC 애플리케이션에 적용한 Databricks의 일부 능력에 주로 초점을 맞출 것입니다. 그러기 전에, 먼저 CDC가 무엇을 의미하고 왜 중요한지 설명하겠습니다.\n\n## 변경 데이터 캡처\n\n<div class=\"content-ad\"></div>\n\n전통적인 데이터베이스 엔진은 시스템에 들어오는 모든 트랜잭션을 최적으로 정확하게 등록하는 데 설계되어 있습니다. 특히 데이터베이스에 변경 사항을 도입하는 작업은 데이터 일관성을 유지하기 위해 순서대로 정확하게 적용되어야 합니다. 다른 한편으로, 분석 시스템은 기존 데이터로 복잡한 쿼리와 변환 작업을 실행하는 데 초점을 맞추며, 쓰기 성능보다 읽기 성능에 우선순위를 두기 때문에 동기화되지 않은 데이터 업데이트가 발생할 수 있습니다. 비구조화 또는 반구조화된 데이터 원본의 흡수 과정의 일환으로 데이터 일관성 제어가 종종 구현되어야 합니다. 데이터 수정을 올바르게 캡처하고 적용하는 이 메커니즘을 Change Data Capture (CDC)라고 합니다.\n\n데이터브릭의 두 가지 주요 기능인 Delta Live Tables와 Autoloader가 CDC 파이프라인을 배포하는 데 도움이 되었습니다.\n\nDelta Live Tables (DLT)은 실시간 데이터 처리 파이프라인을 만들기 위해 Spark 위에 구축된 강력한 선언적 프레임워크입니다. Spark는 Python, SQL, R, Scala라는 네 가지 다른 언어를 지원하지만, 이 글을 작성하는 시점에서 DLT 파이프라인은 Python 또는 SQL로만 설명할 수 있습니다.\n\nDLT는 Autoloader를 활용하여 클라우드 위치에서 새 데이터를 자동으로 파이프라인으로 가져옵니다. Autoloader는 JSON, CSV, XML, PARQUET, AVRO, ORC, TEXT 및 BINARYFILE 형식의 여러 유형의 파일을 다양한 클라우드 제공 업체(S3, GCP, Azure 또는 DBFS)에서로드할 수 있습니다. 또한 파일 유형 및 클라우드 위치에 따라 사용자 지정 옵션을 지원하여 입력 데이터를 올바르게 읽고 포맷팅하는 과정을 간소화합니다. 저희는 Autoloader를 사용하여 파이프라인에 적용해야 하는 변경 사항을 캡처했습니다.\n\n<div class=\"content-ad\"></div>\n\n이제 실제 사용 사례로 들어가 봅시다.\n\n## 민감한 정보 보호\n\n우리는 DLT 파이프라인 내에서 Change Data Capture를 사용하여 일반화된 GDPR(일반 개인정보 보호법) 준수 데이터 애플리케이션을 만들었습니다. GDPR 준수란 특정 조건이 충족되어야 한다는 것을 의미합니다:\n\n- 인가된 사용자만 민감한 데이터에 질의할 수 있습니다.\n- 민감한 데이터는 요청에 따라 데이터베이스에서 제거되어야 합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-17-ProtectingSensitiveDatawithCDCinDatabricks_1.png\" />\n\n이러한 조건을 달성하기 위해 먼저 민감한 데이터를 식별하고 처리하여 무단 사용자가 액세스하지 못하게 했습니다. 이 개념을 익명화라고 합니다. 민감한 데이터를 익명화하기 위해 우리는 각 엔터티마다 고유한 암호화 키로 암호화하는 스파크의 내장 AES 함수를 사용했습니다. 두 번째 요구 사항을 위해 우리는 데이터베이스에서 제거해야 하는 엔터티의 암호화 키를 해싱하는 프로세스를 만들어서 더 이상 액세스할 수 없도록 했습니다. 심지어 인증된 사용자도 액세스할 수 없도록 처리했습니다. 이 프로세스에 대해 더 자세히 살펴보겠습니다.\n\n## 워크플로우의 상세 설명\n\n우리의 애플리케이션을 테스트하기 위해, 패키지의 처리를 위해 S3에 더미 고객 정보를 생성 및 저장하는 준비 노트북을 작성했습니다. 이 노트북은 또한 데이터베이스에서 민감한 정보를 삭제하길 요청한 고객 ID 목록 (기본적으로 삭제 요청을 하는 고객 ID 목록)을 저장하기 위해 동일한 클라우드 위치에 다른 폴더를 만들었습니다.\n\n<div class=\"content-ad\"></div>\n\nDLT 파이프라인의 주요 기능은 CDC를 사용하여 암호화된 고객 테이블을 업데이트하는 것입니다. 암호화 키 테이블에 대한 CDC를 사용합니다. 다음 그림에서 파이프라인의 표현을 확인할 수 있습니다:\n\n![image](/assets/img/2024-05-17-ProtectingSensitiveDatawithCDCinDatabricks_2.png)\n\n그림에서 보듯이 파이프라인에는 다음과 같은 요소들이 포함되어 있습니다:\n\n- customers와 delete_requests 뷰는 Autoloader를 사용하여 해당 정보를 파이프라인으로 로드합니다.\n- encryption_keys_v 뷰는 encryption_keys 테이블의 현재 상태를 쿼리하므로 적용할 변경 사항을 보다 쉽게 식별할 수 있습니다.\n- new_keys 뷰는 customers와 encryption_keys_v 뷰를 비교하여 데이터베이스에 새로운 고객이 들어오는 것을 식별하고 이러한 새로운 고객을 위해 암호화 키를 생성합니다.\n- delete_keys 뷰는 delete_requests 뷰를 읽어서 암호화된 고객의 암호화 키를 해시하는 고객을 식별합니다. 그런 다음, encryption_keys_v와 new_keys에서 가져온 이러한 암호화 키를 해싱합니다.\n- keys_to_upsert 뷰는 delete_keys와 new_keys 뷰를 병합합니다.\n- encryption_keys 테이블의 경우 DLT의 CDC apply_changes 함수를 사용하여 keys_to_upsert 뷰에서 레코드를 업서트합니다.\n- quarantine 뷰는 마지막으로, encryption_keys 테이블의 해당 암호화 키를 사용하여 customer의 민감한 필드를 암호화합니다.\n- 마지막으로, encrypted_customers는 파이프라인의 최종 출력 테이블입니다. quarantine 뷰를 구성합니다.\n\n<div class=\"content-ad\"></div>\n\napply_changes 함수는 CDC를 처리하는 우리의 파이프라인의 핵심 구성 요소입니다. 다음과 같은 필수 인수를 받습니다:\n\n- target: 업데이트할 테이블이며, 우리의 경우에는 encryption_keys 테이블입니다.\n- source: 적용할 변경 사항을 포함하는 테이블 또는 뷰입니다. 여기서는 keys_to_upsert 뷰를 사용합니다.\n- keys: 행을 업데이트하거나 삽입할 기본 키입니다. 여기서는 고객 ID를 사용할 것입니다.\n- sequence_by: 처리할 변경 사항의 순서를 정렬하는 열입니다. 이벤트가 등록된 타임스탬프를 사용합니다.\n\n이 함수는 column_list와 같은 출력 열을 유지하는 추가적인 선택적 인수를 지원하며, 레코드를 삭제하는 조건을 받는 apply_as_deletes와 같은 선택적 인수를 지원합니다. (우리의 경우에는 사용하지 않았습니다).\n\n## 후처리 작업\n\n<div class=\"content-ad\"></div>\n\n지금까지 민감한 데이터의 암호화와 데이터베이스로부터의 삭제에 대해 다뤘습니다. 하지만 이 데이터에 권한이 있는 사용자에게 액세스를 부여하는 방법은 무엇일까요? 다음과 같이 진행됩니다: 우리는 사용자 쿼리에 따라 암호화된 또는 해독된 데이터를 검색하는 동적 뷰를 생성하는 후 처리 작업을 만들었습니다. 이 후 처리 작업은 키를 해싱한 후 encryption_keys 테이블을 초기화하는 작업도 수행합니다. 이 마지막 단계는 앞의 테이블 버전이 쿼리될 경우 해싱된 후에도 암호화 키를 복구할 수 있는 델타 라이브 테이블의 시간 이동 기능을 제한하기 위해 필요했습니다.\n\n우리의 파이프라인의 주요 구성 요소를 설명했으니, 이제 최종 결과를 살펴보겠습니다.\n\n## 아키텍처 개요\n\nDLT 파이프라인의 순차 실행과 후 처리 작업을 보장하기 위해 우리는 두 구성 요소를 포함하고 종속성을 정의하는 전체적인 워크플로우(이름: GDPR Job)를 만들었습니다. 우리 애플리케이션의 마지막 구성 요소로, AWS Lambda Functions와 Databricks의 Statement Execution API를 사용하여 사용자에게 출력 데이터를 제공하는 API를 개발했습니다. 마지막으로, 이러한 Databricks 및 AWS 리소스의 배포는 Terraform 및 Terragrunt를 사용하여 스크립팅되고 매개변수화되었습니다.\n\n<div class=\"content-ad\"></div>\n\n다음 이미지를 통해 최종 애플리케이션을 더 잘 이해할 수 있습니다:\n\n![보호되고 있는 민감한 데이터와 CDC를 사용한 Databricks](/assets/img/2024-05-17-ProtectingSensitiveDatawithCDCinDatabricks_3.png)\n\n## 마무리 말\n\nTerraform와 Terragrunt를 활용하여 CDC 지원이 포함된 이식 가능한 GDPR 준수 ETL 파이프라인 템플릿을 생성할 수 있었습니다. 통합 및 QA 테스팅을 위해 우리 애플리케이션을 위한 테스트 스위트를 작성했는데, 이는 사전 작업 노트북과 유사합니다. 이 노트북은 서로 다른 시나리오를 테스트하기 위해 데이터를 해당 경로에 저장한 후 GDPR 작업을 트리거하고 출력물이 예상과 일치하는지 확인합니다.\n\n<div class=\"content-ad\"></div>\n\n요약하자면, Databricks가 안전하고 견고한 데이터 처리 애플리케이션을 개발하는 데 필요한 모든 구성 요소를 제공한다는 것을 보여드렸습니다. 그러나 이 프로젝트의 실행은 간단하지 않았습니다. 호환성 문제와 통합 문제가 있었는데 이는 우리가 원래의 아키텍처를 수정하여 해결해야 했습니다. 다행히, 이러한 문제들 중 많은 것들이 이미 Databricks에 의해 해결되었거나 향후 배포를 위해 노력 중이라는 점입니다.\n\n## 참고문헌\n\n- Databricks Delta Live Tables를 사용한 변경 데이터 캡처 간소화\n- Databricks Delta Live Tables로 PII 방화벽 구축하기","ogImage":{"url":"/assets/img/2024-05-17-ProtectingSensitiveDatawithCDCinDatabricks_0.png"},"coverImage":"/assets/img/2024-05-17-ProtectingSensitiveDatawithCDCinDatabricks_0.png","tag":["Tech"],"readingTime":6},{"title":"다중 모달 광고 분석 및 창의적 콘텐츠 생성을 Amazon Bedrock에서 Anthropic Claude 3를 활용하여 수행하기","description":"","date":"2024-05-17 18:11","slug":"2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock","content":"\n\n요즘은 산업 비즈니스 및 엔지니어링 리더들의 대규모 그룹 앞에서 \"진화하는 생성형 AI 아키텍처 패턴: 광고기술, 마케팅기술 및 광고대행사\"이라는 강연을 하는 영권을 가졌습니다. 이 강연 중에는 9가지 변화하는 산업별 생성형 AI 아키텍처 패턴을 소개했습니다. 이 게시물에서는 생성형 AI를 사용하여 기존 마케팅 및 광고 콘텐츠에서 통찰을 얻는 하나와 해당 분석 및 관련 데이터를 사용하여 새로운 창의적 컨셉을 개발하는 또 다른 보조적 아키텍처 패턴 두 가지를 탐구해 보겠습니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*F_6zO6yr3wEzDF8v78qaFQ.gif)\n\n## 아키텍처 1: 생성적 통찰력 도출\n\n첫 번째 아키텍처는 안토픽 클로드 3 패밀리와 같은 비전 가능한 모델이 문서 및 이미지를 이해하고 분석할 수 있는 능력을 강조합니다. 텍스트 기반 프롬프트 외에도 업로드된 문서 및 이미지를 분석할 수 있습니다. 프롬프트는 인간 피드백과 함께 프롬프트 라이브러리에 저장될 수 있습니다. 아마존 베드락의 가드레일은 여전히 미리보기 단계에 있지만 프롬프트 및 응답 모두에 대한 규정 준수를 보장합니다. 마지막으로, 동일한 기반 모델 또는 다른 모델을 사용하여 사용자의 초기 프롬프트를 최적화합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_0.png)\n\n## 아키텍처 2: 창의적 광고 콘텐츠 생성\n\n두 번째 아키텍처는 기초 모델이 창의적 디렉터, 카피 라이터, 디지털 아티스트 및 그래픽 디자이너가 새로운 컨셉, 레이아웃, 헤드라인, 광고 복사본 및 이미지를 개발하는 능력을 강조합니다. 기초 모델은 내용을 실제 디지털 광고로 바꾸는 컴퓨터 코드를 작성하는 데도 도움을 줄 수 있습니다.\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_1.png)\n\n\n<div class=\"content-ad\"></div>\n\n이 두 가지 패턴은 서로 보완하며 마케팅 및 광고 콘텐츠 분석 및 작성 능력을 향상시키는데 큰 역할을 합니다.\n\n# Anthropik Claude 3 모델\n\n이 게시물은 Anthropik의 최근 2024년 3월 클로드 3 기반 인공 지능 모델인 Claude 3 Haiku, Claude 3 Sonnet 및 Claude 3 Opus를 발표한 소식 없이는 불가능했습니다. 클로드 3 모델 패밀리는 단순한 패턴 인식이나 텍스트 생성을 넘어 복잡한 인지 작업을 수행하며, 필기 노트부터 그래프, 사진까지 거의 모든 정적 이미지를 전사 및 분석하며, 코드를 생성하고 복잡한 코드 베이스를 디버그하며, 다양한 언어 간 실시간으로 번역하고 문법을 연습하거나 다국어 콘텐츠를 생성할 수 있습니다. 이 게시물에 가장 중요한 것은 Anthropik에 따르면 \"클로드 3 모델은 다른 주요 모델과 윤곽이 유사한 정교한 시각 능력을 갖고 있습니다. 사진, 차트, 그래프 및 기술도표 등 다양한 시각 형식을 처리할 수 있습니다.\"\n\n# Amazon Bedrock\n\n<div class=\"content-ad\"></div>\n\nAnthropic가 발표한 지 하루도 채 되지 않은 시점에 AWS는 Claude 3 모델 패밀리가 Amazon Bedrock을 통해 이용 가능하다고 발표했습니다. AWS에 따르면 \"Amazon Bedrock은 AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI 및 Amazon과 같은 주요 AI 기업들의 고효율 기본 모델(FMs)을 단일 API를 통해 제공하며, 보안, 개인 정보 보호 및 책임 있는 AI를 구축하는 데 필요한 다양한 기능을 함께 제공하는 완전 관리형 서비스입니다.\"\n\n# 소스 코드\n\n이 게시물의 모든 오픈 소스 코드는 GitHub에서 이용할 수 있습니다.\n\n# 멀티모달 프롬프팅\n\n<div class=\"content-ad\"></div>\n\nAnthropic Claude 3 패밀리의 다중 모달 프롬프트 기능을 활용하기 위해 Amazon Bedrock에서 Streamlit 애플리케이션을 개발했어요. 현재 이 애플리케이션을 통해 하나 이상의 JPG, PNG, GIF, WEBP, PDF, CSV 또는 TXT 형식 파일을 업로드할 수 있어요. 또한 모델 (Sonnet 또는 Haiku)을 변경하고 max_tokens, temperature, top_p, top_k와 같은 추론 매개변수를 조절할 수 있는 기능도 제공돼요. 게다가 이 애플리케이션은 총 분석 시간(초)과 소비된 입력 및 출력 토큰 수를 반환할 거예요.\n\n아래는 Streamlit 애플리케이션을 실행하는 방법이에요. 먼저 프로젝트 종속성을 설치할 파이썬 가상 환경을 생성하는 것을 제안해요.\n\n```js\npython3 -m pip install virtualenv -Uq\nvirtualenv claude-streamlit-venv\npython3 -m venv claude-streamlit-venv\n\nsource claude-streamlit-venv/bin/activate\n\npython3 -m pip install -r requirements.txt -Uq\n```\n\n<div class=\"content-ad\"></div>\n\n가상 환경이 생성되고 종속성이 설치된 후, 다음 명령어를 사용하여 터미널에서 Streamlit 앱을 시작하세요:\n\n```js\nstreamlit run app.py \\\n    --server.runOnSave true \\\n    --theme.base \"light\" \\\n    --theme.backgroundColor \"#333333\" \\\n    --theme.primaryColor \"#CCC8AA\" \\\n    --theme.secondaryBackgroundColor \"#777777\" \\\n    --ui.hideTopBar \"true\" \\\n    --client.toolbarMode \"minimal\"\n```\n\n# 다중 모달 프롬프트 예제\n\nGitHub 저장소의 README 파일에는 제가 강연에서 보여준 다양한 다중 모달 프롬프트 예제가 포함되어 있습니다. 이 예제들에 사용된 브랜드와는 어떠한 제휴도 없음을 유의해 주세요.\n\n<div class=\"content-ad\"></div>\n\n## 예시 1: 기존 광고 분석\n\n이 예시에서는 시각을 인식할 수 있는 Claude 3 기반 모델을 활용하여 인터넷에서 쉽게 찾을 수 있는 몇 가지 기존 메르세데스-벤츠 인쇄 광고 예시를 조사하고 창의적인 분석을 제공할 것입니다. 잘 설계된 예시 프롬프트는 다음과 같습니다:\n\n영어로 된 메르세데스-벤츠 세단을 위한 네 개의 인쇄 광고를 분석하십시오. 이 중 두 개는 영어로, 두 개는 독일어로 되어 있습니다. 성공에 기여하는 적어도 다섯 가지 공통 창의적 요소를 식별하십시오. 시각적 디자인 및 이미지, 메시지 및 복사 쓰기, 색상, 타이포그래피 및 브랜드 활용, 상호작용 또는 멀티미디어 구성 요소, 메르세데스-벤츠 브랜드 정체성 및 포지셔닝과의 일치와 같은 요소를 검토하십시오.\n\n각 요소에 대해 광고를 통해 효과적으로 활용된 방법을 설명하고 왜 이것이 강력한 창의적 선택임을 설명하십시오. 분석을 지원하기 위한 구체적인 예시와 통찰을 제공하십시오. 목표는 이러한 메르세데스-벤츠 광고를 매력적이고 효과적으로 만드는 주요 창의 전략을 발견하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n중요: 광고가 제공되지 않았다면 분석 결과를 생성하지 마십시오.\n\n업로드하고 분석할 네 가지 광고 예시가 있습니다.\n\n\n![advertising example](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_3.png)\n\n\n분석은 Anthropic Claude 3 Sonnet on Amazon Bedrock을 사용하여 약 13초가 소요되었습니다. 프롬프트는 5,463개의 입력 토큰을 사용하였고, 응답은 432개의 출력 토큰을 사용하였습니다. 모델의 창조적 분석은 중요한 디자인 요소를 세심하게 식별했습니다. 이 요소에는 1/ 강렬한 시각적 이미지, 2/ 미니멀하고 우아한 타이포그래피, 3/ 효과적인 색상 활용, 4/ 일관된 브랜딩과 태그 라인, 그리고 5/ 성능과 혁신에 대한 강조가 포함되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_4.png)\n\n## 예시 2: 프롬프트 최적화\n\n다음 예시에서는 Anthropic Claude 3 모델에게 사용자의 프롬프트 품질을 향상시키도록 요청할 것입니다. 이 기술은 프롬프트 엔지니어링 기술에 익숙하지 않거나 분석 주제에 익숙하지 않은 사용자에게 효과적일 수 있습니다. 다음은 예시 프롬프트입니다:\n\n당신은 마케팅 분석가를 위한 대규모 언어 모델 프롬프트 최적화 전문가입니다. 다음 마케팅 분석가의 작업 설명과 수반하는 광고 샘플을 고려하면, 제공된 콘텐츠를 기반으로 대규모 언어 모델로부터 효과적인 응답을 제공할 수 있는 간결하고 효과적인 긍정적인 프롬프트를 작성해야 합니다. 분석에 초점을 맞출 요소들의 간결한 목록을 포함하십시오.\n\n<div class=\"content-ad\"></div>\n\n과제: 이러한 성공적인 영어와 독일어 인쇄 광고를 분석하고 효과적인 요소들을 발견해보세요.\n\nAnthropic Claude 3 Sonnet을 사용하여 프롬프트 최적화 요청 작업에는 약 8.7초가 걸렸습니다. 프롬프트는 5,381개의 입력 토큰을 사용했으며, 응답은 141개의 출력 토큰을 사용했습니다. 새로운 프롬프트에는 광고 콘텐츠에 대한 사실들과 보다 완전한 분석을 보장하기 위한 추가 지시사항이 포함되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 예시 3: 분석을 통한 새로운 창의적 개념 생성\n\n<div class=\"content-ad\"></div>\n\n이전 예시에서 생성된 창의적인 분석을 사용하여, 우리는 기반 모델을 활용하여 새로운 광고 컨셉을 개발할 수 있습니다. 이 예시에서는 제품, 대상 고객 세그먼트, 광고 채널 및 광고 형식을 제공하고 모델에게 창의적 컨셉을 개발하도록 요청합니다. 다음은 예시 프롬프트입니다:\n\n4개의 성공적인 메르세데스-벤츠 인쇄 광고에 대한 다음 분석을 기반으로, '모던 럭셔리 | 맨해튼' 웹사이트에 나타나는 '대형 리더보드' 사이즈 디지털 광고를 위한 새롭고 매력적인 디자인을 설명하십시오. 이 광고는 25~35세의 젊은 부유한 도시 부부를 대상으로 한 메르세데스-벤츠 C-클래스 세단을 타깃팅합니다. 레이아웃을 참조할 수 있도록 '모던 럭셔리 | 맨해튼' 온라인 광고 사양에 대한 PDF를 사용하십시오. 답변에 광고의 크기를 포함하세요.\n\n여기서 분석 내용... 이 메르세데스-벤츠 인쇄 광고는 몇 가지 매력적인 창의적 요소를 보여줍니다...\n\n프롬프트와 함께, 발행사 정보를 담은 PDF 파일과 발행사의 디지털 광고 사양을 담은 다른 PDF 파일을 업로드해 주세요.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_6.png)\n\nAnthropic Claude 3 소네트를 사용하여 작업은 약 14초가 걸렸습니다. 분석에는 4,145개의 입력 토큰과 516개의 출력 토큰이 사용되었습니다. 결과 광고 컨셉에는 요약, 이미지 제안, 헤드라인 텍스트, 광고 복사본, 로고 및 콜 투 액션이 포함되어 있습니다.\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_7.png)\n\n우리는 이제, 같은 브랜드와 제품을 위한 기존 광고의 생성 AI 분석을 기반으로 한 새 광고 컨셉을 갖게 되었습니다.\n\n\n<div class=\"content-ad\"></div>\n\n## 4: 창의적 브리프 분석 및 새로운 창의적 컨셉 생성\n\n이제 두 가지 이전 예제를 하나의 작업으로 결합하겠습니다. 첫 번째로, 인터넷에서 널리 이용 가능한 PayPal에 대한 창의적 브리프를 기반으로 모델에게 창의적 디렉터의 역할을 맡겨 새로운 디지털 광고 아이디어 세 가지를 생성하도록 할 것입니다. 우리는 아래의 예시 프롬프트를 사용하여 JSON 형식으로 잘 정리된 응답을 출력하고, 이를 API 호출이나 아마존 DynamoDB와 같은 데이터 저장소를 통해 신속하게 하부 서비스로 전송할 것입니다.\n\n프롬프트 예시:\n\n당신은 선두주자 광고 기관의 창의적 디렉터입니다. PayPal을 위한 다음 창의적 브리프를 기반으로 매력적인 온라인 디지털 광고 세 개를 개발하십시오. 응답에는 각 광고에 대한 고유한 광고 ID(UUID), 헤드라인, 광고 문구, 콜 투 액션, 그리고 이미지 설명을 포함하십시오. 다음 템플릿을 사용하여 응답 형식을 JSON 개체 시리즈로 만들어주십시오.\n\n템플릿 여기에...''...\n\n<div class=\"content-ad\"></div>\n\n위의 프롬프트와 함께 창조적 브리프를 이미지 파일로 업로드해주세요. Foundation 모델은 이미지에서 텍스트를 추출하여 분석할 수 있습니다.\n\n![Creative Brief](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_8.png)\n\n위는 스트림릿 애플리케이션에서 프롬프트 및 업로드된 파일이 나타나는 모습입니다.\n\n![Streamlit](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_9.png)\n\n<div class=\"content-ad\"></div>\n\nThe model’s response is correctly formatted as a series of JSON objects.\n\n![Image](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_10.png)\n\nThe JSON-formatted output can be easily serialized and written to a downstream system without additional string manipulation.\n\n```js\n{\n    \"advertisements\": [\n        {\n            \"id\": \"9b1deb4d-3b7d-4bad-9bdd-2b0d7b3dcb6d\",\n            \"headline\": \"자유롭게 수입해보세요, 언제든지\",\n            \"ad_copy\": \"PayPal의 가상 지갑으로 재정적 독립을 누려보세요. 언제 어디서나 돈 받을 수 있어요.\",\n            \"call_to_action\": \"지금 가입하기\",\n            \"imagery\": \"광고에는 다양한 활동에 참여하는 다양한 청소년들이 나와 있습니다. 파트타임으로 일하거나 취미를 추구하거나 친구들과 어울려 시간을 보내는 모습들이 그려져, 그들의 다양한 삶을 상징합니다.\"\n        },\n        {\n            \"id\": \"3e67f83a-5f3e-4b4f-8653-b1c3c6b7147e\",\n            \"headline\": \"당신의 돈, 당신이 관리하세요\",\n            \"ad_copy\": \"PayPal로 재정을 자유롭게 통제하세요. 복잡함 없이 편리함만을 제공합니다.\",\n            \"call_to_action\": \"앱 다운로드하기\",\n            \"imagery\": \"광고에는 손에 스마트폰을 든 청소년의 손 모습이 그려져, 이동 중인 돈을 쉽게 관리하는 방법을 보여줍니다.\"\n        },\n        {\n            \"id\": \"c54f7d4d-b2d4-4b63-8b2b-d5a7b3c9e2f0\",\n            \"headline\": \"수익 창출, 지출, 반복\",\n            \"ad_copy\": \"용돈이든 파트타임으로 번 돈이든, PayPal이 돈의 움직임을 지원합니다.\",\n            \"call_to_action\": \"지금 PayPal 가입하기\",\n            \"imagery\": \"광고에는 한 손으로 돈을 받는 모습(수익을 나타냄)과 다른 손으로 지불하는 모습(지출을 나타냄)이 동적으로 그려져, PayPal로의 돈의 원활한 흐름을 상징합니다.\"\n        }\n    ]\n}\n```\n\n<div class=\"content-ad\"></div>\n\n아래는 Amazon DynamoDB에 저장된 광고를 위한 새로운 창의적인 개념을 볼 수 있습니다. 그럼 광고 구성 시스템이 실제 디지털 광고를 만들 때 쉽게 읽을 수 있습니다.\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_11.png)\n\n## 5: 새 광고를 위한 레이아웃 디자인\n\n그래픽 디자이너의 역할을 가정하면, 이제 이 모델에게 이전에 생성된 헤드라인, 광고 복사본, 콜 투 액션 및 이미지 설명 중 하나를 기반으로 새로운 디지털 광고의 레이아웃을 디자인하도록 요청할 수 있습니다. 여기 예제 프롬프트가 있습니다:\n\n<div class=\"content-ad\"></div>\n\n당신은 선도적 광고 대행사의 능력 있는 그래픽 디자이너입니다. 다음 제목, 광고 복사본, 콜 투 액션 및 이미지 설명을 기반으로 매력적인 온라인 디지털 광고를 위한 디자인을 설명해주세요. 광고물은 세로 방향의 형식으로 디자인되어야 하며, 너비는 300픽셀, 높이는 600픽셀이어야 합니다. PayPal을 위한 창의적 브리프도 참고로 포함되어 있습니다.\n\n창의적 개념이 여기에 있습니다…''…\n\n다음은 응용프로그램에서 프롬프트와 업로드된 파일이 나타날 것입니다.\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_12.png)\n\n<div class=\"content-ad\"></div>\n\n알림에 따라 Foundation 모델은 제공된 헤드라인, 광고 복사, 호출-투-액션, 로고, 그리고 이미지 설명을 사용하여 레이아웃 세부 정보를 제공합니다. 이 접근 방식의 도전점은 여전히 이러한 쓰기된 레이아웃 설명을 실제 디지털 광고로 어떻게 전환할지입니다.\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_13.png)\n\n## 6: 광고 컨셉에서 이미지 생성하기\n\n저희의 새로운 광고 컨셉에는 이미지가 포함되어 있습니다. Amazon Bedrock와 최근 발표된 Amazon Titan Image Generator G1 foundation 모델을 사용하여, 이전 예시에서 생성된 이미지 설명에서 여러 이미지 변형을 만들 수 있습니다. 우리의 긍정적인 동기부여가 되겠습니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 우리의 디지털 광고의 여러 변형을 생성하는 데 사용할 이미지 변형입니다.\n\n<div class=\"content-ad\"></div>\n\n## 7: 모두 함께하는 시간 — 프로그래밍적으로 광고 생성\n\n우리는 이전 예제에서 생성된 디자인 컨셉과 이미지 변형을 사용하여 여러 광고 변형을 만들 수 있습니다. 우리는 Pillow 패키지를 사용하여 이 작업을 수행하는 Python 스크립트를 작성할 것입니다. Pillow은 Python Imaging Library (PIL)의 한 종류로, Python 인터프리터에 이미지 처리 기능을 추가합니다. 아래는 예시 프롬프트입니다:\n\n당신은 선도적인 광고 대행사의 명문 Graphic Designer이자 Python 개발자입니다. 다음 헤드라인, 광고 복사본, 콜 투 액션 및 이미지 설명을 기반으로 매력적인 온라인 디지털 광고를 만들기 위해 PILLOW 패키지를 사용한 Python 프로그램을 작성하세요. 광고는 400픽셀의 폭과 600픽셀의 높이를 갖는 세로 형식으로 설계되어야 합니다. PayPal을 위한 크리에이티브 브리프가 참조용으로 포함되어 있습니다.\n\n여기서 Kreative 컨셉이 나오네요...\n\n<div class=\"content-ad\"></div>\n\n다음은 응용 프로그램에서 프롬프트와 업로드된 파일이 보일 것입니다.\n\n![Image](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_17.png)\n\n기반 모델은 디지털 광고를 만들기 위한 Python 스크립트를 작성할 수 있었습니다. 모델은 광고 요소를 구성하기 위해 Pillow 패키지를 올바르게 사용했으며 코드 옆에 주석도 추가되었습니다.\n\n![Image](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_18.png)\n\n<div class=\"content-ad\"></div>\n\n파이썬 스크립트는 모델의 응답에서 영감을 받아 Microsoft Visual Studio Code에서 수정되었습니다. 스크립트 내에서 생성된 이미지와 TrueType 글꼴의 기본 위치가 업데이트되었고, 레이아웃의 요소들이 약간 조정되어 전체 가독성과 영향력이 향상되었습니다. 마지막으로, 여러 이미지 변형으로부터 여러 광고 버전을 생성하도록 스크립트가 수정되었습니다. 개발 가속화를 위해 VS Code에서 Amazon CodeWhisperer를 사용했습니다. 최종 코드의 80% 이상은 기존 모델의 기반 응답에서 변경되지 않았습니다.\n\n```js\nfrom PIL import Image, ImageDraw, ImageFont\n\nfor idx, generated_image in enumerate(\n    [\n        \"generated_images/paypal_generated_image_v1.png\",\n        \"generated_images/paypal_generated_image_v2.png\",\n        \"generated_images/paypal_generated_image_v3.png\",\n        \"generated_images/paypal_generated_image_v4.png\",\n        \"generated_images/paypal_generated_image_v5.png\",\n        \"generated_images/paypal_generated_image_v6.png\",    ]\n):\n    # 원하는 크기로 새 이미지 생성\n    width, height = 400, 500\n    img = Image.new(\"RGB\", (width, height), color=\"white\")\n    draw = ImageDraw.Draw(img)\n\n    # 글꼴 로드\n    headline_font = ImageFont.truetype(\n        \"/Users/garystafford/Library/Fonts/Montserrat-Bold.ttf\", 36\n    )\n    copy_font = ImageFont.truetype(\n        \"/Users/garystafford/Library/Fonts/Montserrat-Regular.ttf\", 18\n    )\n    cta_font = ImageFont.truetype(\n        \"/Users/garystafford/Library/Fonts/Montserrat-SemiBold.ttf\", 20\n    )\n\n    # 헤드라인\n    headline = \"Your Money,\\nYour Control\"\n\n    headline_width, headline_height = draw.textbbox((0, 0), headline, font=headline_font)[2:]\n    headline_x = (width - headline_width) / 2\n    headline_y = 20\n    draw.text((headline_x, headline_y), headline, font=headline_font, fill=\"#0C9C00\", align=\"center\")\n\n    # 광고 복사본\n    ad_copy = (\n        \"Take charge of your finances with PayPal.\\nNo complexities, just convenience.\"\n    )\n    copy_width, copy_height = draw.textbbox((0, 0), ad_copy, font=copy_font)[2:]\n    copy_x = (width - copy_width) / 2\n    copy_y = headline_y + headline_height + 20\n    draw.text((copy_x, copy_y), ad_copy, font=copy_font, fill=\"#000000\", align=\"center\")\n\n    # 콜 투 액션\n    cta = \"Download the App\"\n    cta_width, cta_height = draw.textbbox((0, 0), cta, font=cta_font)[2:]\n    cta_x = (width - cta_width) / 2\n    cta_y = height - cta_height - 30\n    draw.rectangle(\n        (cta_x - 10, cta_y - 10, cta_x + cta_width + 10, cta_y + cta_height + 10),\n        fill=\"#0C9C00\",\n        outline=\"#0C9C00\",\n    )\n    draw.text((cta_x, cta_y), cta, font=cta_font, fill=\"white\")\n\n    # 이미지\n    image = Image.open(generated_image)\n    image = image.resize((400, 240))\n    image_x = (width - image.width) / 2\n    image_y = copy_y + copy_height + 20\n    img.paste(image, (int(image_x), int(image_y)))\n\n    # 전체 이미지 경계선\n    draw.rectangle(\n        [0, 0, width - 1, height - 1], outline=\"#999999\", width=1\n    )\n\n    # 이미지 저장\n    img.save(f\"generated_ads/paypal_generated_ad_v1_{idx + 1}.png\", format=\"PNG\")\n```\n\n이전 예제에서 생성된 창의적인 개념과 이미지를 사용하여, 이 파이썬 스크립트를 사용하여 몇 초만에 생성된 수십 개의 디지털 광고 중 일부를 확인할 수 있습니다.\n\n![2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_19.png](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_19.png)\n\n\n<div class=\"content-ad\"></div>\n\n광고 결과물은 다양한 이미지, 헤드라인, 광고 복사본, 콜 투 액션 및 색상 팔레트를 사용합니다.\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_20.png)\n\n## 8: 결과 분석\n\n마지막으로, 우리는 다시 한 번 Claude 3 패밀리의 기본 모델을 사용하여 표 데이터를 분석할 수 있습니다. 예를 들어, 광고 예산과 에이전시 고객의 판매 내역이 포함된 스프레드시트가 있다면, 모델에 다양한 계산을 수행하도록 요청할 수 있습니다. 모델은 확실히 답변을 제공할 것이지만, 해당 답변이 정확한 가능성은 매우 낮습니다. 모델은 표 데이터에서 수학적 계산을 신뢰할 수 없지만, 선택한 언어로 컴퓨터 프로그램을 작성해 정확하게 계산하도록 요청할 수 있습니다. 여기 몇 가지 예시 문구입니다:\n\n<div class=\"content-ad\"></div>\n\n- 광고 예산 및 판매 CSV 파일을 기반으로 한 Python 프로그램을 작성하여 총 매출을 계산해보세요. Pandas 패키지를 사용해보세요.\n- 광고 예산 및 판매 CSV 파일을 기반으로 한 Java 프로그램을 작성하여 총 매출을 계산해보세요.\n- 광고 예산 및 판매 CSV 파일을 기반으로 한 Node.js 프로그램을 작성하여 TV, 라디오, 신문 광고 예산의 총 합계를 계산해보세요. csv-parser 패키지를 사용해보세요.\n- 광고 예산 및 판매 CSV 파일을 기반으로 한 Python 프로그램을 작성하여 ID 100의 TV, 라디오, 신문 광고 예산의 총 합계 대비 매출의 비율을 계산해보세요. Pandas 패키지를 사용해보세요.\n\n기본 모델은 요청된 Pandas 패키지를 사용하여 계산 작업을 수행하는 Python 스크립트를 성공적으로 작성했습니다. 해당 Python 스크립트는 정확한 답을 계산했습니다.\n\n![이미지](/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_21.png)\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n이 게시물에서는 진화하는 두 가지 생성적 AI 아키텍처 패턴을 살펴보았습니다: 하나는 기존의 창의적 콘텐츠에서 통찰을 얻는 데 사용되는 생성적 AI를 활용한 것이고, 다른 하나는 해당 통찰과 관련 데이터를 사용하여 새로운 창의적 개념을 개발하는 데 사용되는 생성적 AI를 사용한 것입니다. 우리는 생성적 AI를 활용하여 기존 광고를 분해하고 분석하고, 몇 가지 Python 코드와 함께 새로운 창의적 광고 개념을 작성했습니다.\n\nMedium 회원이 아니고 나와 같은 작가들을 지원하고 싶다면 여기에서 가입하세요: https://garystafford.medium.com/membership.\n\n이 블로그는 제 의견을 대표하며 제 고용주인 Amazon Web Services (AWS)의 의견을 대변하지 않습니다. 모든 제품 이름, 이미지, 로고 및 브랜드는 각 소유자의 재산입니다.","ogImage":{"url":"/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_0.png"},"coverImage":"/assets/img/2024-05-17-MultimodalAdvertisingAnalysisandCreativeContentGenerationusingAnthropicClaude3onAmazonBedrock_0.png","tag":["Tech"],"readingTime":16},{"title":"AWS CodePipeline 업데이트를 Zoom 채팅에 연결하는 방법 단계별 안내","description":"","date":"2024-05-17 18:09","slug":"2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide","content":"\n\n코드 파이프 라인 콘솔에 계속해서 붙어 있어 지친 적이 있나요? 이 안내서를 통해 코드 파이프 라인 실행에 대한 실시간 알림을 직접 Zoom 채널에서 받는 방법을 안내해 드릴 거예요.\n\n파이프 라인 실패를 신속히 식별하고 해결하는 데 도움을 주며, 문맥 전환을 줄여주는 이 통합은 집중력 향상에 도움을 주고 팀원들을 알려주며, 더 나아가 전반적인 의사 소통과 효율성을 향상시키는 데 도움이 될 거예요.\n\n## 절차:\n\n![이미지](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_0.png)\n\n<div class=\"content-ad\"></div>\n\n### 단계 1: Zoom 수신 웹훅 설정하기\n\n먼저, AWS CodePipeline에서 알림을 보낼 수 있는 Zoom 수신 웹훅을 설정해야 합니다.\n\n- Zoom 계정에 로그인하고 Zoom Marketplace로 이동합니다.\n- \"수신 웹훅\"을 검색하고 앱을 설치합니다. 앱을 설치할 수 없는 경우 계정 관리자에게 문의하세요.\n- 앱이 설치되면 Zoom 채팅의 앱 섹션에서 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 설치가 완료되면 'Incoming Webhooks' 앱으로 이동하세요.\n\n![이미지](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_2.png)\n\n- 도움말을 입력하는 동안 '앱 비활성화' 메시지가 표시되면, 관리자에게 앱을 활성화할 수 있도록 요청해보세요.\n- 웹훅에 대한 명령어를 확인하려면 'help'를 입력하세요.\n\n![이미지](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_3.png)\n\n<div class=\"content-ad\"></div>\n\n- 원하는 채널/그룹으로 이동하여 CodePipeline 알림을 받기를 원하는 곳에서 '/ '을 메시지 상자에 입력하여 사용 가능한 명령을 확인하세요.\n\n![Image 1](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_4.png)\n\n- 연결 명령을 선택하고 웹훅에 대한 설명적인 이름을 입력하세요.\n\n![Image 2](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_5.png)\n\n<div class=\"content-ad\"></div>\n\n- 제공된 엔드포인트와 검증 토큰을 확인하세요.\n\n단계 2: 코드파이프라인 알림을 위한 SNS 토픽 설정\n\n- SNS 서비스로 이동합니다.\n- \"토픽 생성\"을 클릭하고 \"표준\"을 선택합니다.\n- 토픽에 이름을 입력하고 토픽을 생성합니다.\n\n단계 3: 코드파이프라인 알림 구성\n\n<div class=\"content-ad\"></div>\n\n- CodePipeline으로 이동하세요.\n- 구성하려는 파이프라인을 선택하세요.\n- \"알림 관리\"를 선택하세요.\n- \"이벤트 유형\" 아래에서, 알림을 받기 원하는 이벤트를 선택하세요.\n- \"대상\" 섹션에서 \"SNS 주제\"를 선택하고, 이전에 생성한 주제의 SNS 주제 ARN을 붙여넣으세요.\n\n![이미지](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_6.png)\n\n4단계: 람다 함수 생성\n\n- Lambda 서비스로 이동하세요.\n- \"함수 생성\"을 클릭하고, \"스크래치부터 작성\"을 선택하세요.\n- 함수 이름을 제공하고 런타임을 선택하세요.\n- 나머지 옵션은 기본값으로 남기고, \"함수 생성\"을 클릭하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport urllib.request\nimport json\n\nZOOM_WEBHOOK_URL = \"여기에 Zoom 웹훅 URL을 입력하세요\"\nBEARER_TOKEN = \"베어러 토큰\"\n\ndef lambda_handler(event, context):\n    # 받은 이벤트 기록\n    print(\"받은 이벤트: \" + json.dumps(event, indent=2))\n    \n    for record in event['Records']:\n        sns_message = json.loads(record['Sns']['Message'])\n        \n        pipeline = sns_message['detail']['pipeline']\n        stage = sns_message['detail']['stage']\n        state = sns_message['detail']['state']\n        \n        # 메시지 준비\n        message = f\"{pipeline}의 {stage} 스테이지가 {state} 상태입니다.\"\n        data = json.dumps(message).encode('utf-8')\n        \n        # Zoom 웹훅으로 메시지 보내기\n        req = urllib.request.Request(\n            ZOOM_WEBHOOK_URL, \n            data=data, \n            headers={\n                'Content-Type': 'application/json',\n                'Authorization': f'Bearer {BEARER_TOKEN}'\n            }\n        )\n        \n        try:\n            with urllib.request.urlopen(req) as response:\n                print(\"Zoom으로부터 응답: \" + response.read().decode('utf-8'))\n        except urllib.error.URLError as e:\n            print(f\"Zoom에 메시지 보내는 중 오류 발생: {e.reason}\")\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Zoom으로 푸시된 알림')\n    }\n```\n\nURL 및 베어러 토큰을 코드에 직접 입력하는 대신, Parameter Store를 활용할 수 있습니다.\n\n이제 코드를 배포합니다.\n\n스텝 5: SNS 토픽으로 Lambda 함수 구성하기\n\n\n<div class=\"content-ad\"></div>\n\n- 이전에 만든 SNS 주제를 Lambda 함수의 트리거로 추가하세요.\n\n![img](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_7.png)\n\n단계 6: 통합 테스트\n\n- 모든 것이 올바르게 설정되었는지 확인하기 위해 SNS 템플릿을 사용하여 람다 함수를 테스트하세요. 테스트를 진행하면 구성된 웹훅 그룹/채널에서 예시 이벤트를 받게 될 겁니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Screenshot](/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_8.png)\n\n- 이제 콘솔을 통해 수동으로 변경 사항을 CodePipeline에서 해제하거나, 파이프라인이 트리거되기를 기다립니다.\n- 파이프라인에서 변경 사항이 있을 때, 이전에 선택한 단계에 대한 알림을 받게 됩니다.\n\nAWS CodePipeline 알림을 Zoom 채팅 채널과 통합하면 지속적인 콘솔 확인이 필요 없어지며, 팀을 최신 상태로 유지하고 개발 워크플로우를 향상시킬 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-05-17-ConnectingAWSCodePipelineUpdatestoZoomChatAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":4},{"title":"게임 마스터리의 즐거움과 고통","description":"","date":"2024-05-17 18:06","slug":"2024-05-17-TheJoyandPainofGameMastery","content":"\n\n![게임 마스터리의 즐거움과 고통](/assets/img/2024-05-17-TheJoyandPainofGameMastery_0.png)\n\n슈터 책을 쓰고 있을 때 지난 10년간의 더 나은 슈터 게임들을 되돌아보며 Doom Eternal을 다시 플레이했습니다. Eternal은 독특한 디자인으로 사랑하거나 싫어하는 게임이라고 생각해요. 저는 사랑파입니다. 이번에는 더 많은 마스터 레벨을 살펴보기로 결정했어요. 이것은 Doom Eternal의 겸손한 모드로, 게임을 끝내는 사람에게 완벽한 장식이라고 생각해요. 좋고 도전적인 콘텐츠를 만드는 것은 생각보다 훨씬 어려운 일이에요. 스텟을 강화한다고 해서 끝나는 건 아니거든요.\n\n# 마스터 슬레이어\n\nDoom Eternal 출시 후 업데이트를 놓쳤다면, 마스터 레벨은 DLC 챕터와 함께 지난 몇 년 동안 추가되었어요. 이들은 흐름이나 경로를 바꾸지 않는 레벨의 재판매로, 모든 교전과 아레나를 크게 다양하게 변화시키는 매우 어려운 리믹스에요. 이제는 그냥 복도였던 곳이 큰 적들이 당신을 향해 오는 작은 아레나가 될 수 있어요. 적들에게 새로운 능력이나 꼼수는 주어지지 않지만, 언제 어디서 무엇과 싸우느냐에 따라 완전히 다르다는 것이 좋은 액션 디자인의 핵심이에요.\n\n<div class=\"content-ad\"></div>\n\n# 도전에 무릎 꿇지 않기\n\n액션 게임을 하는 사람이라면 마스터리 수준에 도달하는 것이 그 중 하나의 매력이라는 것을 알고 있을 것입니다. 자신이 쌓아온 기술과 능력을 과시할 수 있는 순간이 바로 그것입니다. 액션 디자이너들에게 종종 발생하는 문제는 단순히 능력치를 높이는 것 이상으로 플레이어를 정말로 시험해야 한다는 점을 이해하는 것입니다. 적을 더 단단하게 만들거나 한 번에 플레이어를 처치하게 하는 것으로 게임을 어렵게 만드는 것은 쉽지만, 실제로 흥미진진한 상황을 만드는 것은 훨씬 더 어렵습니다.\n\n게임을 어렵게 만들었다고 플레이어를 처벌하는 것이 아니라, 플레이어가 모든 능력, 무기, 기술을 마음껏 사용하고 풀어낼 수 있도록 하는 것이 중요합니다. 높은 난이도가 설정되었을 때 흔히 발생하는 함정 중 하나는 플레이어의 게임 플레이를 최적의 무기나 전략만 사용할 수 있도록 제한하는 것입니다. 액션 디자인이나 반사 신경을 요구하는 게임은, 적의 행동 방식을 변경하는 것이 아닌 새롭고 흥미로운 상황을 플레이어에게 제공하는 경우에 가장 빛을 발합니다.\n\n![게임 마스터리의 기쁨과 고통](/assets/img/2024-05-17-TheJoyandPainofGameMastery_1.png)\n\n<div class=\"content-ad\"></div>\n\n이것이 돔 이터널의 마스터 레벨이 정말 빛을 발하는 곳입니다. 플레이어는 같은 사이버악마, 같은 마라우더 등과 싸우지만 새로운 배치와 패턴을 보여줍니다. 좋은 적 디자인은 게임 전체를 통틀어 항상 좋다고 할 수 있습니다. 게임에서 기본 적으로 시작하는 적은 플레이어를 정말 테스트하고 싶다면 심술부리게 활용할 수 있습니다. 이는 Nintendo가 게임에서 칭찬받는 디자인의 종류와도 유사합니다. 게임에 초보자 친화적인 주요 어드벤스 파트를 제공하면서 전문 플레이어를 위한 어려운 보너스 콘텐츠를 제공하는 것입니다. 마지막으로 중요한 점은 대부분의 사람들이 게임에서 완벽한 숙달을 고민하는 것이 아니라는 점입니다. 게임을 모든 난이도 수준의 사람들을 위해 균형 있게 맞추는 것이 좋은 난이도 디자인입니다.\n\n돔 이터널의 마스터 레벨만으로 이뤄진 게임은 수많은 수용자들 중 소수의 사용자들에게만 호소력이 있을 수 있지만, 저는 그런 게임이 돔 이터널만큼 많이 팔리거나 칭찬받을 가능성이 없다고 확신합니다. 추상적인 게임보다 반사 신경 주도형 디자인의 매력은 RPG 메카닉 때문에 이미 게임 내에 있는 것을 직접 변경하지 않고 더 어렵게 만드는 것이 훨씬 어렵다는 것입니다. 이것이 많은 RPG에서 어려움을 조절할 때 적들이 더 세게 공격하고 더 오랜 시간이 걸리도록 만드는 이유입니다. 그러나 대부분의 경우 이러한 게임들에서 높은 난이도는 메카닉을 더 흥미롭게 만들지 않거나 플레이어가 정복했을 때 보상을 주지 않고 단지 더 많은 시간과 그라인딩을 추가합니다.\n\n숙달을 기쁘고 보람 있게 느끼고 싶다면, 귀하의 게임이 이를 위해 설정되어 있어야 할뿐만 아니라 추구하는 흥미로운 이유를 제공해야 합니다.\n\n# P는 고통을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n내 책을 쓰는 동안 내 자신에게 가해진 또 다른 시련은 Ultrakill의 P-Rank 도전을 하는 것이었습니다. Doom Eternal과 함께, 두 게임 모두 플레이하는 데 매우 기술적인 FPS 게임입니다. Doom Eternal은 다행히도 당신의 기술에 대해 점수를 매기지는 않지만, Ultrakill은 그렇습니다. 현재 게임에서 가장 어려운 도전인 P-2를 해제하려면 해당 지점까지의 모든 레벨에서 최상의 순위를 얻어야 합니다. 적을 모두 죽이고, 빠르게 하고, 세련되게 해야 합니다. 마지막 항목은 약간의 노력이 필요할 것입니다.\n\nUltrakill은 Doom Eternal보다 게임 플레이의 총기 사용에 대한 매우 많은 기술적 측면을 통합하고 있습니다. 무기 간의 빠른 스왑은 고급 Doom Eternal 플레이를 위해 플레이어가 배워야 할 주요 기술 형태입니다. Ultrakill에서는 다양한 교전 옵션이 있을 뿐만 아니라, 각각의 무기 간에 독특한 콤보가 있어 공격의 역학을 바꿉니다. 샷건의 대체 발사는 모의 수류탄으로 폭발성 코어를 발사하지만, 만약 레일 캐논으로 그것을 쏘면 작은 적들의 아레나를 순식간에 제거하는 파괴적인 AOE 누크로 변환됩니다.\n\n중요한 점은 Ultrakill이 다양한 무기의 행동 방식을 숨기지 않는다는 것입니다. 무기에 대한 모든 로그 엔트리는 플레이어가 사용할 수 있는 콤보를 명확히 설명하며, 이것은 특히 p-ranking 때문에 이루어집니다. P 레인지의 점수를 얻으려면 플레이어는 상등 평가를 유지하기 위해 지속적으로 무기를 바꿔야 하며, 물론 많이 맞지 않아야 합니다. Doom Eternal과 마찬가지로 Ultrakill에서 능숙해지면 게임이 더 쉬워집니다. 가브리엘과의 두 번째 전투는 처음 싸울 때 엄청난 난이도 상승으로 보일 수 있습니다. 그러나 한 번 P-rank를 획득하면 전투가 약 10초 정도로 단축됩니다.\n\n<div class=\"content-ad\"></div>\n\n플레이어의 기술은 메커니즘을 배우면서 성장할 것이지만, 이는 게임 플레이를 더 쉽게 만드는 것은 아닙니다. P-2에 도달하면 지금까지 가장 어렵고 미친 투기장 전투가 펼쳐집니다. Ultrakill의 적 디자인은 다른 슈팅 게임과 구별되는 독특함을 지니고 있습니다. 각 적 유형은 특정한 역할뿐만 아니라 행동 방식에 대한 고유한 규칙과 요소를 갖추고 있습니다. 이러한 배치를 서로 다른 투기장과 다양한 적과 조합함으로써, 게임은 다른 슈팅 게임과 비교해 아주 쉬운 것에서 굉장히 어려운 전투로 순조롭게 이어질 수 있습니다. \n\n'Doom Eternal'과 마찬가지로, 플레이어의 능력과 적의 통계는 특히 이 고급 도전을 위해 명시적으로 변경되는 것은 아니지만, 게임은 플레이어에게 승리할 희망을 품고 있다면 더 많은 것을 요구합니다. Ultrakill의 P-2를 넘기는 것, Sisyphus Prime을 포함한 것은 플레이어를 위한 시련의 도전입니다.\n\n하지만 이러한 시련은 Ultrakill을 깊이 학습하고자 하는 사람들을 위해 만들어졌으며, Doom Eternal의 마스터 레벨은 언제든지 선택사항으로 존재합니다. P-2를 직접 만나보고 싶다면 Ultrakill에 대해 매우 뛰어나고 헌신적이어야 하며, 이것이 어떤 표본이든지 P-3이 어떨지 지금 생각만으로도 소름이 돋을 것입니다.\n\n# 완벽한 고통\n\n<div class=\"content-ad\"></div>\n\n능숙함은 디자이너로서 플레이어에게 강요할 수 있는 것이 아니지만, 캐주얼 플레이어에게는 혜택이 있다는 것을 눈치 챘을지도 모릅니다. 게임을 시작부터 끝까지 진행하는 것 이상의 즐거움이 있다는 것을 알면 누군가는 게임의 메커니즘과 플레이를 더 깊게 탐구하게 될 수 있습니다. 이는 다양한 실력 수준이나 플레이 스타일을 가진 사람들이 게임을 플레이하는데 다양한 꿀팁을 배울 수 있게 합니다. 저는 Ultrakill의 코인 플립 테크 타이밍을 익힐 수는 없겠지만, 레일 캐논 트릭으로 P랭크를 얻을 수는 있습니다. 다양한 실력 수준을 수용할 수 있는 게임을 디자인하면 더 균형 잡힌 게임이 되고, 어떤 유형의 플레이어가 무엇을 하는지 아는 것으로 레벨과 도전 과제를 쉽게 구축할 수도 있습니다.\n\n![이미지](/assets/img/2024-05-17-TheJoyandPainofGameMastery_3.png)\n\nUltrakill의 다양한 난이도를 살펴보면, 각 설정에 대한 변경 사항은 다른 경험을 제공하되 여전히 플레이어를 시험합니다. 제가 가장 쉬운 설정으로 게임을 하지는 않겠지만, 다른 사람은 해당 설정으로 게임을 즐기며 배우는 전체 게임플레이를 경험할 수 있습니다. 플레이어에 渚琉빀好뼃方 플을 헝들수 섞진 있딘데, 게임을 쉽게 하든 어렵게 하든 선택하게 함으로써 누구든지 참여하게 유도하고 게임을 플레이하는 \"올바른\" 방법이 딱히 없음을 알리기 때문에 누군가를 참여시킬 수 있다는 것을 알고 계시는 거죠.\n\n여러분께 질문: 어떤 게임들이 그들의 내부적 능숙함을 촉진하고 장려한 좋은 사례로 떠오르시나요? 댓글로 알려주세요.\n\n<div class=\"content-ad\"></div>\n\n슈터 및 FPS 디자인에 대해 더 알고 싶다면 출시되는 순간, Game Design Deep Dive Shooters를 반드시 구입해보세요.\n\n더 많은 일일 스트리밍을 할 수 있도록 지원하고 싶다면, 제 패트론을 확인해주세요. \n\n게임 및 게임 디자인에 대해 이야기를 나눌 수 있는 디스코드가 모든 사람들에게 열렸습니다.","ogImage":{"url":"/assets/img/2024-05-17-TheJoyandPainofGameMastery_0.png"},"coverImage":"/assets/img/2024-05-17-TheJoyandPainofGameMastery_0.png","tag":["Tech"],"readingTime":5}],"page":"66","totalPageCount":68,"totalPageGroupCount":4,"lastPageGroup":8,"currentPageGroup":3},"__N_SSG":true}