{"pageProps":{"post":{"title":"BiTCN 컨볼루션 네트워크를 활용한 다변수 시계열 예측","description":"","date":"2024-05-18 19:41","slug":"2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks","content":"\n\n![image](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png)\n\n시계열 예측 분야에서는 모델의 아키텍처가 주로 다층 퍼셉트론(MLP) 또는 트랜스포머 아키텍처에 의존합니다.\n\nN-HiTS, TiDE 및 TSMixer와 같은 MLP 기반 모델은 훈련 속도가 빠르면서 매우 좋은 예측 성능을 달성할 수 있습니다.\n\n한편, PatchTST 및 iTransformer와 같은 트랜스포머 기반 모델도 좋은 성능을 달성하지만 더 많은 메모리를 소비하고 더 많은 훈련 시간이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n아직도 예측에서 널리 활용되고 있지 않은 아키텍처 하나가 있습니다: 합성곱 신경망(CNN).\n\n전통적으로 CNN은 컴퓨터 비전에 적용되었지만, 예측 분야에서는 TimesNet이 최근의 예만 있습니다.\n\n그러나 CNN은 순차 데이터를 처리하는 데 효과적임이 입증되었으며, 그들의 아키텍처는 병렬 계산을 허용하여 훈련 속도를 크게 높일 수 있습니다.\n\n따라서 본 기사에서는 2023년 3월 논문 'Parameter-efficient deep probabilistic forecasting'에서 제안된 BiTCN을 탐색합니다. 두 개의 시계열 합성곱 신경망(TCN)을 활용하여 이 모델은 과거와 미래의 변수를 인코딩하면서도 계산 효율적인 특징을 유지합니다.\n\n<div class=\"content-ad\"></div>\n\n더 자세한 내용은 원본 논문을 꼭 읽어보세요.\n\n시작해봅시다!\n\n## BiTCN 탐험\n\n이전에 언급된대로, BiTCN은 두 개의 시계열 합성곱 신경망을 활용하므로 그 이름이 BiTCN입니다.\n\n<div class=\"content-ad\"></div>\n\n한 TCN은 미래 공변량을 인코딩하고, 다른 하나는 과거 공변량 및 시계열의 역사적 값들을 인코딩합니다. 이렇게 함으로써 모델은 데이터로부터 시간 정보를 배울 수 있고, 합성곱의 사용으로 계산 효율성을 유지할 수 있습니다.\n\n여기에는 분석할 것이 많기 때문에 아키텍처를 좀 더 자세히 살펴보겠습니다.\n\n## BiTCN 아키텍처\n\nBiTCN의 아키텍처는 많은 시계열 블록으로 구성되어 있습니다. 각 블록은 다음과 같이 구성됩니다:\n\n<div class=\"content-ad\"></div>\n\n- 확장된 합성곱\n- GELU 활성화 함수\n- 드롭아웃 단계\n- 완전 연결 레이어\n\n시계열 블록의 일반적인 아키텍처는 아래에 표시됩니다.\n\n![temporal block](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_1.png)\n\n위 그림에서 각 시계열 블록이 출력 O를 생성함을 볼 수 있습니다. 최종 예측은 N개의 레이어에 쌓인 각 블록의 모든 출력을 더하여 얻습니다.\n\n<div class=\"content-ad\"></div>\n\n드롭아웃과 댄스 레이어는 신경망에서 흔한 구성 요소입니다. 그러나 이번에는 확장 컨볼루션(dilated convolution)과 GELU 활성화 함수에 대해 좀 더 자세히 살펴봅시다.\n\n## 확장 컨볼루션\n\n확장 컨볼루션의 목표를 더 잘 이해하기 위해, 기본적인 컨볼루션이 어떻게 작동하는지 상기해 봅시다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_2.png)\n\n<div class=\"content-ad\"></div>\n\n위 그림에서 일차원 입력에 대한 전형적인 합성곱이 어떻게 보이는지 볼 수 있습니다. 출력의 길이를 동일하게 유지하기 위해 입력 시리즈는 왼쪽에 0으로 채워집니다.\n\n세 개의 커널 크기와 한 개의 스트라이드를 가정할 때, 위 그림에 나와 있는대로 출력 텐서도 네 개의 길이를 가집니다.\n\n출력의 각 요소가 세 개의 입력 값을 기반으로 한다는 것을 볼 수 있습니다. 다시 말해 출력은 색인의 값과 이전 두 값에 의존합니다.\n\n이를 수용 영역(Receptive Field)이라고 합니다. 시계열 데이터를 다루고 있으므로 출력 계산이 더 긴 이력을 볼 수 있도록 수용 영역을 증가시키는 것이 유익할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n그렇게 하려면, 커널 크기를 크게 하거나 더 많은 합성곱 계층을 쌓을 수 있습니다. 커널 크기를 크게 하는 것은 최선의 선택이 아닙니다. 정보를 손실하고 모델이 데이터의 유용한 관계를 학습하지 못할 수 있습니다. 그래서 더 많은 합성곱을 쌓아보겠습니다.\n\n위 그림에서 볼 수 있듯이, 커널 크기가 3인 두 개의 합성곱 작업을 쌓으면 출력의 마지막 요소는 이제 입력의 다섯 요소에 의존합니다. 따라서 수용 영역이 3에서 5로 증가했습니다.\n\n안타깝게도 이것도 문제가 됩니다. 이러한 방식으로 수용 영역을 증가시키면 아주 깊은 신경망이 생성될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n따라서, 우리는 모델에 너무 많은 레이어를 추가하지 않으면서 수용 영역을 증가시키기 위해 확장된 합성곱을 사용합니다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_4.png)\n\n위의 그림에서 우리는 2-확장된(convolution)을 실행한 결과를 볼 수 있습니다. 기본적으로 매 두 요소가 하나의 출력을 생성하는 것으로 간주됩니다. 따라서 우리는 이제 컨벌루션을 쌓지 않고도 수용 영역이 5임을 볼 수 있습니다.\n\n실제로 수용 영역을 더 증가시키기 위해, 주로 2로 설정된 확장 베이스를 사용하여 많은 희석커널(diluted kernel)을 쌓습니다. 이는 첫 번째 레이어가 2¹-확장 커널이되고, 그다음에 2²-확장 커널이 따르며, 그런 다음 2³로 이어지는 방식입니다.\n\n<div class=\"content-ad\"></div>\n\n수용 영역이 늘어나면 모델은 더 긴 입력 시퀀스를 고려하여 출력을 생성할 수 있습니다. Dilated convolutions을 사용하면 합리적인 수의 레이어를 유지할 수도 있습니다.\n\n이제 Dilated convolutions의 내부 작업을 이해했으니 GELU 활성화 함수를 알아보겠습니다.\n\n## GELU 활성화 함수\n\n많은 딥러닝 아키텍처에서는 ReLU(Recitified Linear Unit) 활성화 함수를 사용합니다. ReLU의 방정식은 아래와 같이 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n위의 식을 보면 ReLU는 간단히 0과 입력 중 최대 값을 취하는 것을 알 수 있습니다. 다시 말해, 입력이 양수이면 입력이 반환되고, 입력이 음수이면 0이 반환됩니다.\n\nReLU는 사라지는 그래디언트 문제를 완화하는 데 도움이 되지만 죽은 ReLU 문제를 만들 수도 있습니다.\n\n이는 네트워크에서 일부 뉴런이 오직 0만 출력하여 모델의 학습에 더 이상 기여하지 않는 경우에 발생합니다.\n\n<div class=\"content-ad\"></div>\n\n해당 상황에 대처하기 위해 가우시안 에러 선형 유닛 또는 GELU를 사용할 수 있습니다. GELU 방정식은 아래와 같이 나타낼 수 있습니다.\n\n\n![GELU Equation](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_6.png)\n\n\n이 함수를 사용하면 입력 값이 0보다 작을 때 작은 음수 값을 활성화 함수로 사용할 수 있습니다.\n\n\n![Activation Function with GELU](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_7.png)\n\n\n<div class=\"content-ad\"></div>\n\n이렇게 하면 신경세포가 소멸하지 않게 되어 음수 입력 값을 사용하여 0이 아닌 값이 반환될 수 있습니다. 이는 역전파에 대해 더 풍부한 그래디언트를 제공하며 모델의 기능을 유지할 수 있습니다.\n\n## BiTCN에서 모두 모아보기\n\n이제 BiTCN의 시간 블록의 내부 작업을 이해했으니, 우리는 모델에서 모든 것이 어떻게 함께 동작하는지 살펴봅시다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_8.png)\n\n<div class=\"content-ad\"></div>\n\n위 그림에서는 늦게 발생한 값들이 밀도 레이어를 통과하고 시간 블록 스택을 거친 후 모든 이전 공변량과 결합된 것을 볼 수 있습니다.\n\n상단에는 범주형 공변량이 다른 공변량과 결합되기 전에 먼저 임베딩된 것을 볼 수 있습니다. 여기서는 미래와 과거 공변량이 아래에 표시된 대로 모두 결합됨에 유의해주세요.\n\n그럼 그 값들은 밀도 레이어와 시간 블록 스택을 거쳐 이끌어집니다.\n\n최종 출력은 아래에 표시된 것과 같이 늦게 발생한 값과 공변량에서 나온 정보가 결합된 것입니다.\n\n<div class=\"content-ad\"></div>\n\n\n![그림](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_9.png)\n\n위의 그림은 하나의 시간 블록이 공변량의 미래 값을 활용하여 모델 출력을 결정하는 아이디어를 강조합니다 (빨간 점으로 표시됨).\n\n마지막으로, BiTCN은 예측 주변에 신뢰 구간을 구성하기 위해 Student’s t-분포를 사용합니다.\n\n이제 BiTCN의 내부 작업을 이해했으니, Python을 사용하여 소규모 예측 프로젝트에 적용해 봅시다.\n\n\n<div class=\"content-ad\"></div>\n\n# BiTCN을 사용한 예측\n\n이 실험에서는 BiTCN을 N-HiTS 및 PatchTST와 함께 사용하여 장기 예측 작업을 수행합니다.\n\n구체적으로, 블로그 웹사이트의 일일 조회수를 예측하는 데 사용합니다. 데이터셋에는 일일 조회수와 새로운 글이 게시된 날짜를 나타내는 지표, 미국의 공휴일을 나타내는 지표와 같은 외생 특성이 포함되어 있습니다.\n\n이 데이터셋은 제가 직접 제 웹사이트의 트래픽을 사용하여 컴파일했습니다. 데이터셋은 여기서 공개적으로 이용 가능합니다.\n\n<div class=\"content-ad\"></div>\n\n본 부분에서는 외부 기능을 지원하는 BiTCN의 사용 준비 구현을 제공하는 것으로 내가 알기로는 유일한 라이브러리인 neuralforcast를 사용합니다.\n\n언제나 GitHub에 이 실험의 전체 소스 코드가 있습니다.\n\n시작해 봅시다!\n\n## 초기 설정\n\n<div class=\"content-ad\"></div>\n\n이 프로젝트에 필요한 라이브러리를 가져오는 것이 첫 번째 단계입니다.\n\n```js\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.models import NHITS, PatchTST, BiTCN\n```\n\n그런 다음, 데이터를 DataFrame으로 읽어옵니다.\n\n```js\ndf = pd.read_csv('https://raw.githubusercontent.com/marcopeix/time-series-analysis/master/data/medium_views_published_holidays.csv')\ndf['ds'] = pd.to_datetime(df['ds]')\n```\n\n<div class=\"content-ad\"></div>\n\n데이터를 그래프로 나타낼 수도 있습니다.\n\n```js\npublished_dates = df[df['published'] == 1]\nholidays = df[df['is_holiday'] == 1]\n\nfig, ax = plt.subplots(figsize=(12,8))\n\nax.plot(df['ds'], df['y'])\nax.scatter(published_dates['ds'], published_dates['y'], marker='o', color='red', label='새 기사')\nax.scatter(holidays['ds'], holidays['y'], marker='x', color='green', label='미국 공휴일')\nax.set_xlabel('날짜')\nax.set_ylabel('총 조회수')\nax.legend(loc='best')\n\nfig.autofmt_xdate()\n\nplt.tight_layout()\n```\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_10.png)\n\n위 그림에서, 주중에 주말보다 더 많은 방문이 발생하는 주별 계절성이 명확히 나타납니다.\n\n<div class=\"content-ad\"></div>\n\n또한, 방문 횟수의 급증은 일반적으로 새로운 기사가 게시된 후 발생합니다(빨간 점으로 표시됨). 새로운 콘텐츠가 더 많은 트래픽을 유도하기 때문에 새로운 기사가 게시될 때 일반적으로 트래픽이 증가합니다. 마지막으로, 미국 공휴일(녹색 십자로 표시됨)은 종종 낮은 트래픽을 시사합니다.\n\n따라서, 외부 요인의 영향을 명확히 볼 수 있는 시리즈이며, BiTCN을 위한 훌륭한 사용 사례입니다.\n\n## 데이터 처리\n\n이제 데이터를 학습 세트와 테스트 세트로 분할해 봅시다. 테스트를 위해 마지막 28개 항목을 예약합니다.\n\n<div class=\"content-ad\"></div>\n\n```python\ntrain = df[:-28]\ntest = df[-28:]\n```\n\n그런 다음, 예보 기간에 대한 날짜 및 외생 변수의 미래 값이 포함된 DataFrame을 생성합니다.\n\n미래의 외생 변수 값을 제공하는 것이 의미가 있다는 점에 유의해야 합니다. 미래의 미국의 공휴일 날짜는 미리 알려져 있으며, 기사의 발행 또한 계획할 수 있기 때문입니다.\n\n```python\nfuture_df = test.drop(['y'], axis=1)\n```\n\n<div class=\"content-ad\"></div>\n\n좋아요! 이제 시리즈를 모델링할 준비가 되었습니다.\n\n## 모델링\n\n언급했듯이, 이 프로젝트에서는 N-HiTS(MLP 기반), BiTCN(CNN 기반) 및 PatchTST(Transformer 기반)를 사용합니다.\n\nN-HiTS와 BiTCN은 둘 다 외부 특성을 사용한 모델링을 지원하지만, PatchTST는 지원하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n이 실험의 수평선은 테스트 세트의 전체 길이를 포함하기 위해 28로 설정됩니다.\n\n```js\nhorizon = len(test)\n\nmodels = [\n    NHITS(\n        h=horizon,\n        input_size = 5*horizon,\n        futr_exog_list=['published', 'is_holiday'],\n        hist_exog_list=['published', 'is_holiday'],\n        scaler_type='robust'),\n    BiTCN(\n        h=horizon,\n        input_size=5*horizon,\n        futr_exog_list=['published', 'is_holiday'],\n        hist_exog_list=['published', 'is_holiday'],\n        scaler_type='robust'),\n    PatchTST(\n        h=horizon,\n        input_size=2*horizon,\n        encoder_layers=3,\n        hidden_size=128,\n        linear_hidden_size=128,\n        patch_len=4,\n        stride=1,\n        revin=True,\n        max_steps=1000\n    )\n]\n```\n\n그런 다음, 훈련 세트에 모델을 적용합니다.\n\n```js\nnf = NeuralForecast(models=models, freq='D')\nnf.fit(df=train)\n```\n\n<div class=\"content-ad\"></div>\n\n그럼, 우리는 외부 요인의 미래 값을 사용하여 예측을 생성할 수 있어요.\n\n```js\npreds_df = nf.predict(futr_df=future_df)\n```\n\n좋아요! 지금 이 시점에서, preds_df에 저장된 예측이 있어요. 각 모델의 성능을 평가할 수 있어요.\n\n## 평가\n\n<div class=\"content-ad\"></div>\n\n예측값과 실제 값들을 하나의 DataFrame으로 합치는 것으로 시작합니다.\n\n```python\ntest_df = pd.merge(test, preds_df, 'left', 'ds')\n```\n\n선택적으로, 예측값을 실제 값과 비교해서 아래 그림과 같이 시각화할 수도 있습니다.\n\n![예제 그림](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_11.png)\n\n<div class=\"content-ad\"></div>\n\n위의 그림에서는 모든 모델이 실제 트래픽을 전반적으로 과대 예측한 것으로 보입니다.\n\n그럼 최상의 성능을 발휘하는 모델을 찾기 위해 평균 절대 오차 (MAE)와 대칭 평균 절대 백분율 오차 (sMAPE)를 측정해보겠습니다.\n\n```js\nfrom utilsforecast.losses import mae, smape\nfrom utilsforecast.evaluation import evaluate\n\nevaluation = evaluate(\n    test_df,\n    metrics=[mae, smape],\n    models=[\"NHITS\", \"BiTCN\", \"PatchTST\"],\n    target_col=\"y\",\n)\n\nevaluation = evaluation.drop(['unique_id'], axis=1)\nevaluation = evaluation.set_index('metric')\n\nevaluation.style.highlight_min(color='blue', axis=1)\n```\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_12.png)\n\n<div class=\"content-ad\"></div>\n\n위의 표에서 BiTCN이 최상의 성능을 달성했음을 확인할 수 있습니다. 해당 모델의 MAE 및 sMAPE가 가장 낮기 때문입니다.\n\n이 실험만으로는 BiTCN의 강력한 벤치마크는 아니지만, 외생 변수를 활용한 예측 문맥에서 가장 우수한 결과를 달성하는 것을 볼 수 있어 흥미로운 실험입니다.\n\n# 결론\n\nBiTCN 모델은 이전 값과 미래 값을 함께 인코딩하기 위해 두 개의 시간 합성곱 신경망을 활용하여 효율적인 다변량 시계열 예측을 수행합니다.\n\n<div class=\"content-ad\"></div>\n\n시계열 분야에서 컨볼루션 신경망의 성공적인 응용을 보는 것은 흥미로운 일이죠. 대부분의 모델은 MLP 또는 트랜스포머를 기반으로 하지만요.\n\n저희의 소규모 실험에서 BiTCN이 가장 우수한 성능을 발휘했습니다. 하지만 저는 각 문제에는 독특한 해결책이 필요하다고 믿습니다. 이제 BiTCN을 도구 상자에 추가하고 여러분의 프로젝트에 적용해 보세요.\n\n독자 여러분, 읽어 주셔서 감사합니다! 즐기셨기를 바라며 무엇인가 새로운 것을 배우셨기를 기대합니다.\n\n건배 🍻\n\n<div class=\"content-ad\"></div>\n\n# 저를 지지해주세요\n\n제 작품을 즐기고 계신가요? Buy me a coffee로 제게 지지를 보여주세요. 그러면 여러분은 제게 격려를 주고, 저는 커피 한 잔을 즐길 수 있어요! 만약 그러고 싶다면, 아래 버튼을 클릭해주세요 👇\n\n![Buy me a coffee](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_13.png)\n\n# 참고자료\n\n<div class=\"content-ad\"></div>\n\n**Parameter-efficient deep probabilistic forecasting** by Olivier Sprangers, Sebastian Schelter, Maarten de Rijke\n\nExplanation of **dilated convolution** and figures of **dilates convolutions** inspired: **Temporal convolutional networks and forecasting** by Unit8","ogImage":{"url":"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png"},"coverImage":"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png","tag":["Tech"],"readingTime":11},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png\" alt=\"image\"></p>\n<p>시계열 예측 분야에서는 모델의 아키텍처가 주로 다층 퍼셉트론(MLP) 또는 트랜스포머 아키텍처에 의존합니다.</p>\n<p>N-HiTS, TiDE 및 TSMixer와 같은 MLP 기반 모델은 훈련 속도가 빠르면서 매우 좋은 예측 성능을 달성할 수 있습니다.</p>\n<p>한편, PatchTST 및 iTransformer와 같은 트랜스포머 기반 모델도 좋은 성능을 달성하지만 더 많은 메모리를 소비하고 더 많은 훈련 시간이 필요합니다.</p>\n<p>아직도 예측에서 널리 활용되고 있지 않은 아키텍처 하나가 있습니다: 합성곱 신경망(CNN).</p>\n<p>전통적으로 CNN은 컴퓨터 비전에 적용되었지만, 예측 분야에서는 TimesNet이 최근의 예만 있습니다.</p>\n<p>그러나 CNN은 순차 데이터를 처리하는 데 효과적임이 입증되었으며, 그들의 아키텍처는 병렬 계산을 허용하여 훈련 속도를 크게 높일 수 있습니다.</p>\n<p>따라서 본 기사에서는 2023년 3월 논문 'Parameter-efficient deep probabilistic forecasting'에서 제안된 BiTCN을 탐색합니다. 두 개의 시계열 합성곱 신경망(TCN)을 활용하여 이 모델은 과거와 미래의 변수를 인코딩하면서도 계산 효율적인 특징을 유지합니다.</p>\n<p>더 자세한 내용은 원본 논문을 꼭 읽어보세요.</p>\n<p>시작해봅시다!</p>\n<h2>BiTCN 탐험</h2>\n<p>이전에 언급된대로, BiTCN은 두 개의 시계열 합성곱 신경망을 활용하므로 그 이름이 BiTCN입니다.</p>\n<p>한 TCN은 미래 공변량을 인코딩하고, 다른 하나는 과거 공변량 및 시계열의 역사적 값들을 인코딩합니다. 이렇게 함으로써 모델은 데이터로부터 시간 정보를 배울 수 있고, 합성곱의 사용으로 계산 효율성을 유지할 수 있습니다.</p>\n<p>여기에는 분석할 것이 많기 때문에 아키텍처를 좀 더 자세히 살펴보겠습니다.</p>\n<h2>BiTCN 아키텍처</h2>\n<p>BiTCN의 아키텍처는 많은 시계열 블록으로 구성되어 있습니다. 각 블록은 다음과 같이 구성됩니다:</p>\n<ul>\n<li>확장된 합성곱</li>\n<li>GELU 활성화 함수</li>\n<li>드롭아웃 단계</li>\n<li>완전 연결 레이어</li>\n</ul>\n<p>시계열 블록의 일반적인 아키텍처는 아래에 표시됩니다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_1.png\" alt=\"temporal block\"></p>\n<p>위 그림에서 각 시계열 블록이 출력 O를 생성함을 볼 수 있습니다. 최종 예측은 N개의 레이어에 쌓인 각 블록의 모든 출력을 더하여 얻습니다.</p>\n<p>드롭아웃과 댄스 레이어는 신경망에서 흔한 구성 요소입니다. 그러나 이번에는 확장 컨볼루션(dilated convolution)과 GELU 활성화 함수에 대해 좀 더 자세히 살펴봅시다.</p>\n<h2>확장 컨볼루션</h2>\n<p>확장 컨볼루션의 목표를 더 잘 이해하기 위해, 기본적인 컨볼루션이 어떻게 작동하는지 상기해 봅시다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_2.png\" alt=\"이미지\"></p>\n<p>위 그림에서 일차원 입력에 대한 전형적인 합성곱이 어떻게 보이는지 볼 수 있습니다. 출력의 길이를 동일하게 유지하기 위해 입력 시리즈는 왼쪽에 0으로 채워집니다.</p>\n<p>세 개의 커널 크기와 한 개의 스트라이드를 가정할 때, 위 그림에 나와 있는대로 출력 텐서도 네 개의 길이를 가집니다.</p>\n<p>출력의 각 요소가 세 개의 입력 값을 기반으로 한다는 것을 볼 수 있습니다. 다시 말해 출력은 색인의 값과 이전 두 값에 의존합니다.</p>\n<p>이를 수용 영역(Receptive Field)이라고 합니다. 시계열 데이터를 다루고 있으므로 출력 계산이 더 긴 이력을 볼 수 있도록 수용 영역을 증가시키는 것이 유익할 것입니다.</p>\n<p>그렇게 하려면, 커널 크기를 크게 하거나 더 많은 합성곱 계층을 쌓을 수 있습니다. 커널 크기를 크게 하는 것은 최선의 선택이 아닙니다. 정보를 손실하고 모델이 데이터의 유용한 관계를 학습하지 못할 수 있습니다. 그래서 더 많은 합성곱을 쌓아보겠습니다.</p>\n<p>위 그림에서 볼 수 있듯이, 커널 크기가 3인 두 개의 합성곱 작업을 쌓으면 출력의 마지막 요소는 이제 입력의 다섯 요소에 의존합니다. 따라서 수용 영역이 3에서 5로 증가했습니다.</p>\n<p>안타깝게도 이것도 문제가 됩니다. 이러한 방식으로 수용 영역을 증가시키면 아주 깊은 신경망이 생성될 수 있습니다.</p>\n<p>따라서, 우리는 모델에 너무 많은 레이어를 추가하지 않으면서 수용 영역을 증가시키기 위해 확장된 합성곱을 사용합니다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_4.png\" alt=\"이미지\"></p>\n<p>위의 그림에서 우리는 2-확장된(convolution)을 실행한 결과를 볼 수 있습니다. 기본적으로 매 두 요소가 하나의 출력을 생성하는 것으로 간주됩니다. 따라서 우리는 이제 컨벌루션을 쌓지 않고도 수용 영역이 5임을 볼 수 있습니다.</p>\n<p>실제로 수용 영역을 더 증가시키기 위해, 주로 2로 설정된 확장 베이스를 사용하여 많은 희석커널(diluted kernel)을 쌓습니다. 이는 첫 번째 레이어가 2¹-확장 커널이되고, 그다음에 2²-확장 커널이 따르며, 그런 다음 2³로 이어지는 방식입니다.</p>\n<p>수용 영역이 늘어나면 모델은 더 긴 입력 시퀀스를 고려하여 출력을 생성할 수 있습니다. Dilated convolutions을 사용하면 합리적인 수의 레이어를 유지할 수도 있습니다.</p>\n<p>이제 Dilated convolutions의 내부 작업을 이해했으니 GELU 활성화 함수를 알아보겠습니다.</p>\n<h2>GELU 활성화 함수</h2>\n<p>많은 딥러닝 아키텍처에서는 ReLU(Recitified Linear Unit) 활성화 함수를 사용합니다. ReLU의 방정식은 아래와 같이 표시됩니다.</p>\n<p>위의 식을 보면 ReLU는 간단히 0과 입력 중 최대 값을 취하는 것을 알 수 있습니다. 다시 말해, 입력이 양수이면 입력이 반환되고, 입력이 음수이면 0이 반환됩니다.</p>\n<p>ReLU는 사라지는 그래디언트 문제를 완화하는 데 도움이 되지만 죽은 ReLU 문제를 만들 수도 있습니다.</p>\n<p>이는 네트워크에서 일부 뉴런이 오직 0만 출력하여 모델의 학습에 더 이상 기여하지 않는 경우에 발생합니다.</p>\n<p>해당 상황에 대처하기 위해 가우시안 에러 선형 유닛 또는 GELU를 사용할 수 있습니다. GELU 방정식은 아래와 같이 나타낼 수 있습니다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_6.png\" alt=\"GELU Equation\"></p>\n<p>이 함수를 사용하면 입력 값이 0보다 작을 때 작은 음수 값을 활성화 함수로 사용할 수 있습니다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_7.png\" alt=\"Activation Function with GELU\"></p>\n<p>이렇게 하면 신경세포가 소멸하지 않게 되어 음수 입력 값을 사용하여 0이 아닌 값이 반환될 수 있습니다. 이는 역전파에 대해 더 풍부한 그래디언트를 제공하며 모델의 기능을 유지할 수 있습니다.</p>\n<h2>BiTCN에서 모두 모아보기</h2>\n<p>이제 BiTCN의 시간 블록의 내부 작업을 이해했으니, 우리는 모델에서 모든 것이 어떻게 함께 동작하는지 살펴봅시다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_8.png\" alt=\"이미지\"></p>\n<p>위 그림에서는 늦게 발생한 값들이 밀도 레이어를 통과하고 시간 블록 스택을 거친 후 모든 이전 공변량과 결합된 것을 볼 수 있습니다.</p>\n<p>상단에는 범주형 공변량이 다른 공변량과 결합되기 전에 먼저 임베딩된 것을 볼 수 있습니다. 여기서는 미래와 과거 공변량이 아래에 표시된 대로 모두 결합됨에 유의해주세요.</p>\n<p>그럼 그 값들은 밀도 레이어와 시간 블록 스택을 거쳐 이끌어집니다.</p>\n<p>최종 출력은 아래에 표시된 것과 같이 늦게 발생한 값과 공변량에서 나온 정보가 결합된 것입니다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_9.png\" alt=\"그림\"></p>\n<p>위의 그림은 하나의 시간 블록이 공변량의 미래 값을 활용하여 모델 출력을 결정하는 아이디어를 강조합니다 (빨간 점으로 표시됨).</p>\n<p>마지막으로, BiTCN은 예측 주변에 신뢰 구간을 구성하기 위해 Student’s t-분포를 사용합니다.</p>\n<p>이제 BiTCN의 내부 작업을 이해했으니, Python을 사용하여 소규모 예측 프로젝트에 적용해 봅시다.</p>\n<h1>BiTCN을 사용한 예측</h1>\n<p>이 실험에서는 BiTCN을 N-HiTS 및 PatchTST와 함께 사용하여 장기 예측 작업을 수행합니다.</p>\n<p>구체적으로, 블로그 웹사이트의 일일 조회수를 예측하는 데 사용합니다. 데이터셋에는 일일 조회수와 새로운 글이 게시된 날짜를 나타내는 지표, 미국의 공휴일을 나타내는 지표와 같은 외생 특성이 포함되어 있습니다.</p>\n<p>이 데이터셋은 제가 직접 제 웹사이트의 트래픽을 사용하여 컴파일했습니다. 데이터셋은 여기서 공개적으로 이용 가능합니다.</p>\n<p>본 부분에서는 외부 기능을 지원하는 BiTCN의 사용 준비 구현을 제공하는 것으로 내가 알기로는 유일한 라이브러리인 neuralforcast를 사용합니다.</p>\n<p>언제나 GitHub에 이 실험의 전체 소스 코드가 있습니다.</p>\n<p>시작해 봅시다!</p>\n<h2>초기 설정</h2>\n<p>이 프로젝트에 필요한 라이브러리를 가져오는 것이 첫 번째 단계입니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> matplotlib.<span class=\"hljs-property\">pyplot</span> <span class=\"hljs-keyword\">as</span> plt\n\n<span class=\"hljs-keyword\">from</span> neuralforecast.<span class=\"hljs-property\">core</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">NeuralForecast</span>\n<span class=\"hljs-keyword\">from</span> neuralforecast.<span class=\"hljs-property\">models</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-variable constant_\">NHITS</span>, <span class=\"hljs-title class_\">PatchTST</span>, <span class=\"hljs-title class_\">BiTCN</span>\n</code></pre>\n<p>그런 다음, 데이터를 DataFrame으로 읽어옵니다.</p>\n<pre><code class=\"hljs language-js\">df = pd.<span class=\"hljs-title function_\">read_csv</span>(<span class=\"hljs-string\">'https://raw.githubusercontent.com/marcopeix/time-series-analysis/master/data/medium_views_published_holidays.csv'</span>)\ndf[<span class=\"hljs-string\">'ds'</span>] = pd.<span class=\"hljs-title function_\">to_datetime</span>(df[<span class=\"hljs-string\">'ds]'</span>)\n</code></pre>\n<p>데이터를 그래프로 나타낼 수도 있습니다.</p>\n<pre><code class=\"hljs language-js\">published_dates = df[df[<span class=\"hljs-string\">'published'</span>] == <span class=\"hljs-number\">1</span>]\nholidays = df[df[<span class=\"hljs-string\">'is_holiday'</span>] == <span class=\"hljs-number\">1</span>]\n\nfig, ax = plt.<span class=\"hljs-title function_\">subplots</span>(figsize=(<span class=\"hljs-number\">12</span>,<span class=\"hljs-number\">8</span>))\n\nax.<span class=\"hljs-title function_\">plot</span>(df[<span class=\"hljs-string\">'ds'</span>], df[<span class=\"hljs-string\">'y'</span>])\nax.<span class=\"hljs-title function_\">scatter</span>(published_dates[<span class=\"hljs-string\">'ds'</span>], published_dates[<span class=\"hljs-string\">'y'</span>], marker=<span class=\"hljs-string\">'o'</span>, color=<span class=\"hljs-string\">'red'</span>, label=<span class=\"hljs-string\">'새 기사'</span>)\nax.<span class=\"hljs-title function_\">scatter</span>(holidays[<span class=\"hljs-string\">'ds'</span>], holidays[<span class=\"hljs-string\">'y'</span>], marker=<span class=\"hljs-string\">'x'</span>, color=<span class=\"hljs-string\">'green'</span>, label=<span class=\"hljs-string\">'미국 공휴일'</span>)\nax.<span class=\"hljs-title function_\">set_xlabel</span>(<span class=\"hljs-string\">'날짜'</span>)\nax.<span class=\"hljs-title function_\">set_ylabel</span>(<span class=\"hljs-string\">'총 조회수'</span>)\nax.<span class=\"hljs-title function_\">legend</span>(loc=<span class=\"hljs-string\">'best'</span>)\n\nfig.<span class=\"hljs-title function_\">autofmt_xdate</span>()\n\nplt.<span class=\"hljs-title function_\">tight_layout</span>()\n</code></pre>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_10.png\" alt=\"이미지\"></p>\n<p>위 그림에서, 주중에 주말보다 더 많은 방문이 발생하는 주별 계절성이 명확히 나타납니다.</p>\n<p>또한, 방문 횟수의 급증은 일반적으로 새로운 기사가 게시된 후 발생합니다(빨간 점으로 표시됨). 새로운 콘텐츠가 더 많은 트래픽을 유도하기 때문에 새로운 기사가 게시될 때 일반적으로 트래픽이 증가합니다. 마지막으로, 미국 공휴일(녹색 십자로 표시됨)은 종종 낮은 트래픽을 시사합니다.</p>\n<p>따라서, 외부 요인의 영향을 명확히 볼 수 있는 시리즈이며, BiTCN을 위한 훌륭한 사용 사례입니다.</p>\n<h2>데이터 처리</h2>\n<p>이제 데이터를 학습 세트와 테스트 세트로 분할해 봅시다. 테스트를 위해 마지막 28개 항목을 예약합니다.</p>\n<pre><code class=\"hljs language-python\">train = df[:-<span class=\"hljs-number\">28</span>]\ntest = df[-<span class=\"hljs-number\">28</span>:]\n</code></pre>\n<p>그런 다음, 예보 기간에 대한 날짜 및 외생 변수의 미래 값이 포함된 DataFrame을 생성합니다.</p>\n<p>미래의 외생 변수 값을 제공하는 것이 의미가 있다는 점에 유의해야 합니다. 미래의 미국의 공휴일 날짜는 미리 알려져 있으며, 기사의 발행 또한 계획할 수 있기 때문입니다.</p>\n<pre><code class=\"hljs language-python\">future_df = test.drop([<span class=\"hljs-string\">'y'</span>], axis=<span class=\"hljs-number\">1</span>)\n</code></pre>\n<p>좋아요! 이제 시리즈를 모델링할 준비가 되었습니다.</p>\n<h2>모델링</h2>\n<p>언급했듯이, 이 프로젝트에서는 N-HiTS(MLP 기반), BiTCN(CNN 기반) 및 PatchTST(Transformer 기반)를 사용합니다.</p>\n<p>N-HiTS와 BiTCN은 둘 다 외부 특성을 사용한 모델링을 지원하지만, PatchTST는 지원하지 않습니다.</p>\n<p>이 실험의 수평선은 테스트 세트의 전체 길이를 포함하기 위해 28로 설정됩니다.</p>\n<pre><code class=\"hljs language-js\">horizon = <span class=\"hljs-title function_\">len</span>(test)\n\nmodels = [\n    <span class=\"hljs-title function_\">NHITS</span>(\n        h=horizon,\n        input_size = <span class=\"hljs-number\">5</span>*horizon,\n        futr_exog_list=[<span class=\"hljs-string\">'published'</span>, <span class=\"hljs-string\">'is_holiday'</span>],\n        hist_exog_list=[<span class=\"hljs-string\">'published'</span>, <span class=\"hljs-string\">'is_holiday'</span>],\n        scaler_type=<span class=\"hljs-string\">'robust'</span>),\n    <span class=\"hljs-title class_\">BiTCN</span>(\n        h=horizon,\n        input_size=<span class=\"hljs-number\">5</span>*horizon,\n        futr_exog_list=[<span class=\"hljs-string\">'published'</span>, <span class=\"hljs-string\">'is_holiday'</span>],\n        hist_exog_list=[<span class=\"hljs-string\">'published'</span>, <span class=\"hljs-string\">'is_holiday'</span>],\n        scaler_type=<span class=\"hljs-string\">'robust'</span>),\n    <span class=\"hljs-title class_\">PatchTST</span>(\n        h=horizon,\n        input_size=<span class=\"hljs-number\">2</span>*horizon,\n        encoder_layers=<span class=\"hljs-number\">3</span>,\n        hidden_size=<span class=\"hljs-number\">128</span>,\n        linear_hidden_size=<span class=\"hljs-number\">128</span>,\n        patch_len=<span class=\"hljs-number\">4</span>,\n        stride=<span class=\"hljs-number\">1</span>,\n        revin=<span class=\"hljs-title class_\">True</span>,\n        max_steps=<span class=\"hljs-number\">1000</span>\n    )\n]\n</code></pre>\n<p>그런 다음, 훈련 세트에 모델을 적용합니다.</p>\n<pre><code class=\"hljs language-js\">nf = <span class=\"hljs-title class_\">NeuralForecast</span>(models=models, freq=<span class=\"hljs-string\">'D'</span>)\nnf.<span class=\"hljs-title function_\">fit</span>(df=train)\n</code></pre>\n<p>그럼, 우리는 외부 요인의 미래 값을 사용하여 예측을 생성할 수 있어요.</p>\n<pre><code class=\"hljs language-js\">preds_df = nf.<span class=\"hljs-title function_\">predict</span>(futr_df=future_df)\n</code></pre>\n<p>좋아요! 지금 이 시점에서, preds_df에 저장된 예측이 있어요. 각 모델의 성능을 평가할 수 있어요.</p>\n<h2>평가</h2>\n<p>예측값과 실제 값들을 하나의 DataFrame으로 합치는 것으로 시작합니다.</p>\n<pre><code class=\"hljs language-python\">test_df = pd.merge(test, preds_df, <span class=\"hljs-string\">'left'</span>, <span class=\"hljs-string\">'ds'</span>)\n</code></pre>\n<p>선택적으로, 예측값을 실제 값과 비교해서 아래 그림과 같이 시각화할 수도 있습니다.</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_11.png\" alt=\"예제 그림\"></p>\n<p>위의 그림에서는 모든 모델이 실제 트래픽을 전반적으로 과대 예측한 것으로 보입니다.</p>\n<p>그럼 최상의 성능을 발휘하는 모델을 찾기 위해 평균 절대 오차 (MAE)와 대칭 평균 절대 백분율 오차 (sMAPE)를 측정해보겠습니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">from</span> utilsforecast.<span class=\"hljs-property\">losses</span> <span class=\"hljs-keyword\">import</span> mae, smape\n<span class=\"hljs-keyword\">from</span> utilsforecast.<span class=\"hljs-property\">evaluation</span> <span class=\"hljs-keyword\">import</span> evaluate\n\nevaluation = evaluate(\n    test_df,\n    metrics=[mae, smape],\n    models=[<span class=\"hljs-string\">\"NHITS\"</span>, <span class=\"hljs-string\">\"BiTCN\"</span>, <span class=\"hljs-string\">\"PatchTST\"</span>],\n    target_col=<span class=\"hljs-string\">\"y\"</span>,\n)\n\nevaluation = evaluation.<span class=\"hljs-title function_\">drop</span>([<span class=\"hljs-string\">'unique_id'</span>], axis=<span class=\"hljs-number\">1</span>)\nevaluation = evaluation.<span class=\"hljs-title function_\">set_index</span>(<span class=\"hljs-string\">'metric'</span>)\n\nevaluation.<span class=\"hljs-property\">style</span>.<span class=\"hljs-title function_\">highlight_min</span>(color=<span class=\"hljs-string\">'blue'</span>, axis=<span class=\"hljs-number\">1</span>)\n</code></pre>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_12.png\" alt=\"이미지\"></p>\n<p>위의 표에서 BiTCN이 최상의 성능을 달성했음을 확인할 수 있습니다. 해당 모델의 MAE 및 sMAPE가 가장 낮기 때문입니다.</p>\n<p>이 실험만으로는 BiTCN의 강력한 벤치마크는 아니지만, 외생 변수를 활용한 예측 문맥에서 가장 우수한 결과를 달성하는 것을 볼 수 있어 흥미로운 실험입니다.</p>\n<h1>결론</h1>\n<p>BiTCN 모델은 이전 값과 미래 값을 함께 인코딩하기 위해 두 개의 시간 합성곱 신경망을 활용하여 효율적인 다변량 시계열 예측을 수행합니다.</p>\n<p>시계열 분야에서 컨볼루션 신경망의 성공적인 응용을 보는 것은 흥미로운 일이죠. 대부분의 모델은 MLP 또는 트랜스포머를 기반으로 하지만요.</p>\n<p>저희의 소규모 실험에서 BiTCN이 가장 우수한 성능을 발휘했습니다. 하지만 저는 각 문제에는 독특한 해결책이 필요하다고 믿습니다. 이제 BiTCN을 도구 상자에 추가하고 여러분의 프로젝트에 적용해 보세요.</p>\n<p>독자 여러분, 읽어 주셔서 감사합니다! 즐기셨기를 바라며 무엇인가 새로운 것을 배우셨기를 기대합니다.</p>\n<p>건배 🍻</p>\n<h1>저를 지지해주세요</h1>\n<p>제 작품을 즐기고 계신가요? Buy me a coffee로 제게 지지를 보여주세요. 그러면 여러분은 제게 격려를 주고, 저는 커피 한 잔을 즐길 수 있어요! 만약 그러고 싶다면, 아래 버튼을 클릭해주세요 👇</p>\n<p><img src=\"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_13.png\" alt=\"Buy me a coffee\"></p>\n<h1>참고자료</h1>\n<p><strong>Parameter-efficient deep probabilistic forecasting</strong> by Olivier Sprangers, Sebastian Schelter, Maarten de Rijke</p>\n<p>Explanation of <strong>dilated convolution</strong> and figures of <strong>dilates convolutions</strong> inspired: <strong>Temporal convolutional networks and forecasting</strong> by Unit8</p>\n</body>\n</html>\n"},"__N_SSG":true}