{"pageProps":{"post":{"title":"인간 수준의 로봇을 위한 훌륭한 AI로의 길","description":"","date":"2024-05-20 20:04","slug":"2024-05-20-ThePathtoGreatAIforHuman-CapableRobots","content":"\n\n<img src=\"/assets/img/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots_0.png\" />\n\n내가 가장 좋아하는 스타워즈 장면은 츄바카가 우키의 울음소리를 내고 작은 토스트기 크기의 마우스 드로이드가 짹짹 거리며 뒤로 물러나는 장면입니다. 그 배경에는 무슨 일이 일어나고 있는지 상상해보세요? 그 로봇은 그 소리를 내는 것이 자신을 뭉개버릴 수 있는 무서운 협박하는 존재임을 인식해야 합니다. 두려움에 반응해야 합니다. 그리고 뒤로 바퀴로 이동하여 도망가야 합니다.\n\n오늘날의 로봇들은 이러한 이해와 제어 수준을 갖고 있지 않습니다. 이로 인해 그들은 자연스러워 보이지 않습니다. 현재의 로봇들은 일반적으로 딱딱하고 자연스럽지 않은 모습을 하고 있습니다. 또는 이상한 부조리한 계곡에 앉아서 자연스러워 보이려고 하지만 그것을 완전히 이룰 수 없습니다.\n\n# 시뮬레이션 및 유전 알고리즘에 대한 초기 작업\n\n<div class=\"content-ad\"></div>\n\n1994년에 Karl Sims가 \"진화하는 가상 생물체\"라는 논문을 썼습니다. 그 논문은 물 속에서 움직이고 땅 위에서 움직이는 혁신적인 블록 생물체들을 보여주었습니다. Karl은 유전 알고리즘을 사용하여 생물체와 움직임을 진화시키는 아이디어를 시연했습니다. 그 비디오는 30년이 지난 지금도 여전히 매혹적입니다.\n\n이 연구는 새로운 행동과 새로운 제어를 갖는 혁신적인 생물체가 전진하거나 회전하는 등의 작업을 배울 수 있다는 것을 보여줬습니다. 시뮬레이션을 통해 건설함으로써 Karl Sims는 혁신적인 생물체들이 나타날 때까지 수많은 반복과 실험을 할 수 있었습니다. 게다가, 유전 알고리즘은 이전에 작동한 것을 채택하고 발전시킴으로써 점점 더 나은 것으로 수렴할 수 있다는 것을 보여줬습니다.\n\n# 강화 학습의 등장\n\n리치 서튼 박사는 1984년에 발표한 박사 논문에서 강화 학습의 개념을 고안했다고 인정받고 있습니다. 그의 말에 따르면, \"강화 학습은 보상으로부터 배움으로, 세계와의 평범한 상호작용 중에 시행착오를 통해 배우는 것\"입니다. 이후에는 Karl Sims의 작업과 비슷하게 시뮬레이션 세계에서 학습하도록 적응되었습니다.\n\n<div class=\"content-ad\"></div>\n\n강화 학습은 딥마인드가 아타리 게임을 플레이하는 시스템을 가르칠 수 있다는 것을 증명한 경우를 포함하여 탐험의 핫한 분야로 부상했습니다. 이 시스템은 입력 비디오 프레임을 받아 조이스틱 컨트롤을 모방한 컨트롤 출력을 생성했습니다(비디오).\n\n이것은 RL이 시행착오를 통해 행동을 배우고 최적화할 수 있는 능력을 증명한 중대한 순간이었습니다. 이는 단순히 게임 그 자체를 숙달하는 데서 그치는 것이 아니라 기계가 원시 시각 입력과 게임 환경으로부터의 피드백만을 이용하여 복잡한 작업을 처음부터 배울 수 있다는 것을 입증한 것이었습니다.\n\n이러한 움직임을 기반으로, 오픈AI의 DOTA 2에 대한 작업은 복잡한 멀티플레이어 온라인 배틀 아레나 게임에서 큰 발전을 이뤘습니다(비디오). 강화 학습을 통해 훈련된 신경망 팀 오픈AI Five는 프로 수준의 인간 플레이어와 경쟁하고 이기는 능력을 보여주었습니다. 이 성취는 RL이 복잡성과 동적성이 증가하는 작업을 처리할 수 있는 능력, 전략적 계획, 팀워크, 예측할 수 없는 상대에 대한 실시간 의사 결정을 포함하는 작업을 다룰 수 있는 능력을 강조했습니다.\n\n오픈AI의 학습 능력 프로젝트는 RL이 달성할 수 있는 영역을 더 넓혀주었습니다. 로봇 손을 훈련시켜 인간 손과 유사한 미세 조작 능력을 갖도록 하는 것을 통해, 이 프로젝트는 RL이 미세한 운동 통제와 적응력을 필요로 하는 물리적 작업에서의 잠재력을 강조했습니다(비디오). 이 프로젝트는 손을 훈련시키기 위해 실제 환경으로 그 기술을 옮기기 전에 시뮬레이션 환경을 사용한 것으로, sim-to-real 전이라고 알려진 기술을 사용한 점에서 특히 주목할 만했습니다.\n\n<div class=\"content-ad\"></div>\n\n# 강화 학습의 한계 극복하기\n\n강화 학습의 첫 번째 큰 난제는 많은 시행 착오를 하는 데 비용이 많이 든다는 것입니다. 특히 학습 초기 단계에서 많은 테스트된 가설이 정말로 좋지 않은 것들이 많습니다. 따라서 나쁜 가치를 구별하여 목표에 근접한 것을 찾아내려고 하는 것은 어렵습니다. 또한 필요한 시행 착오 횟수는 액추에이터 수와 함께 증가합니다. 이것은 부트스트래핑 문제로 볼 수 있습니다... 강화 학습이 더 효율적일 수 있도록 모델을 시작할 수 있는 방법은 무엇인가요?\n\n이 문제를 해결하는 데 도움이 될 수 있는 다양한 기술이 있습니다:\n\n- 먼저 시뮬레이션 사용: 실제 세계에서 작동을 확인하기 전에 시뮬레이션에서 모든 시행 착오를 수행하여 작동하는 솔루션에 더 가까워지려고 노력합니다.\n- 모방 학습: 강화 학습을 세부 조정하기 전에 기본 모델을 얻기 위해 다른 기술을 사용합니다. 이 기술 중 하나는 사람이 액추에이터를 제어하도록 하고, 그 후에 학습하는 것입니다. 또는 \"One-shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning\"에서 시연된 것처럼 비디오에서 모방합니다. 최근 CMU 로봇 공학 연구소의 논문 \"SloMo: A General System for Legged Robot Motion Imitation from Casual Videos\"에서는 개와 고양이의 비디오에서 배운 것을 다리로봇에 전달하는 능력을 보였습니다.\n- 액추에이터 공간의 차원 축소: 인간의 손은 40개 이상의 제어 차원을 가지고 있으며 OpenAI Detrous Manipulation 프로젝트에서 사용된 Shadow Hand와 같은 장치는 26개의 차원을 가지고 있습니다. Columbia는 \"eigengrasps\"를 만들어 알려진 잡음 상태에서의 접근 문제를 단순화하기 위해 손을 간단한 문제로 전환하려고 노력했습니다.\n- 문제 단순화: 특히 로봇 픽킹에서 널리 사용되는 방법은 물건을 집을 때 기존 것을 잡아들이기에 걱정할 필요 없도록 매우 높은 유동성 진공을 단순히 사용하는 것입니다. Agility는 로봇의 다리를 설계하여 다리 제어 모델을 탄성 질량 진자로 모델링할 수 있도록 하여 제어 문제를 단순화했습니다.\n- 행동 클로닝: 이미 작동하는 시스템이 있다면 다른 시스템이 그 행동을 복제하도록 시도할 수 있습니다. 처음에는 지도 학습 기술을 사용해보는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n강화 학습의 두 번째 큰 도전은 매우 견고하지 않으며 지정된 보상에 과적합될 수 있다는 것입니다. 예를 들어, 인간 형상 로봇이 농구 골대에 골을 넣도록 훈련하려면, 목표가 단순히 골을 넣는 것이라면 로봇은 보다 성공적인 방법으로 공을 던질 것입니다. 그러나 인간이 농구를 차는 것과 같이 보이기를 원한다면, 골을 넣는 것과 인간처럼 보이는 것 둘 다 보상하는 더 정교한 보상 함수가 필요합니다.\n\n- 도메인 랜덤화: 입력 공간을 교란하고 동일한 목표를 달성하려고 하면 모델이 더 견고해질 수 있습니다.\n- 인간 취향: 인간들은 성공이 어떻게 보이어야 하는지에 대해 보다 세밀한 버전을 가지고 있습니다. 그래서 목표를 달성하는 것으로 시스템을 보상하는 대신에, 주로 인간이 선호하는 대로 행동하도록 시스템에 보상을 줄 수 있습니다. 일반적으로 인간에게 두 가지 예시를 나란히 보여주고 어느 쪽이 더 좋은지 묻습니다.\n\n강화 학습의 세 번째 큰 도전은 한 번에 한 가지 작업만 배운다는 것입니다! 문을 열어본 방법을 배웠다고 해서 다른 어떤 문의 손잡이나 심지어 높이가 2인치 낮은 문의 손잡이를 열 수 있다는 것을 의미하지 않습니다. 사실, 이 문제는 전혀 잘 해결되지 않습니다. 이를 해결하기 위한 몇 가지 대처 방법이 있습니다:\n\n- 동적 손재능 로봇 행동의 순차적 구성: 이 논문은 한 제어 체제에서 다른 체제로 부드럽게 전환하는 기술을 유도했는데, 두 제어 체제 간에 중첩이 있을 때 전환하는 방법을 제시합니다. 이는 매우 통찰력있는 논문입니다. Boston Dynamics은 아틀라스가 팽이를 하도록 만들기 위해 이 기술을 사용하거나 이 기술의 진화형을 사용한다고 여겨집니다.\n- 환경 제한: 작업을 매우 구체적인 상황으로 제한하면 문제를 크게 단순화할 수 있습니다. 예를 들어, 일반적인 세계에서 물건을 움켜쥐는 것은 매우 어렵습니다. 하지만 그냥 통에 있는 물건을 집는 것으로 제한한다면 문제를 상당히 단순화하고 그 후 하나의 작업만 배울 수 있습니다. 마찬가지로, 로봇이 할 수 있는 것을 충족하기 위해 모든 문 손잡이를 변경할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n로봇 공학 분야에서 이 문제는 매우 큰 문제이며, 로봇 공학 커뮤니티 외부에서는 잘 이해되지 않는 문제입니다. 진짜 인상적인 로봇 액션의 데모를 자주 보게 되는데, 우리는 로봇이 백플립을 할 수 있는 로봇이라면 당연히 몽키 바도 할 수 있을 것이라고 바로 생각합니다. 왜냐하면 우리는 7세 어린이가 백플립을 할 수 있는 아이라면 몽키 바에는 문제가 없을 것이기 때문입니다. 하지만 로봇은 그렇지 않습니다. 만약 로봇이 몽키 바를 할 수 있도록 훈련받지 않았다면, 그것은 그 일을 할 능력이 전혀 없을 것입니다.\n\n인간이 할 수 있는 모든 것을 하나씩 배우려고 할 때 우리는 영원히 걸릴 것입니다.\n\n# 데이터의 역할\n\n우리가 알려진 정답 테스트 세트와 같은 결과를 생성해내는 모델을 고안하는 지도 학습에서는, 데이터가 많을수록 좋습니다. 음성 인식 분야의 초기 진전의 많은 부분은 지도 학습을 통해 이루어졌습니다. Tellme에서는, Nuance의 음성 인식 엔진을 사용하고 있음에도 불구하고 더 많은 데이터를 가지고 있기 때문에 어느 순간 Nuance보다 더 나은 음성 인식을 할 수 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n사람들이 더 많은 데이터가 이긴다고 가정하는 것으로 이어졌습니다. 어느 정도는 여전히 사실이지만, 지도 학습을 시도하는 경우 테스트 세트가 필요합니다. 그리고 결과물은 당신의 테스트 및 훈련 세트의 크기만큼 좋습니다. 그래서 더 많은 데이터를 원하게 됩니다. Scale AI가 한 초기 작업 중 하나는, 자율 주행 자동차 회사들이 자동차, 정지 신호, 보행자, 교통 가로등 등이 어디에 있는지 보여 주는 레이블된 데이터 세트를 구축하는 데 도움을 주었습니다. 이러한 훈련 세트들을 구축하는 데는 매우 비용이 많이 들며 우리가 희망하는 것만큼 결과가 좋지 않습니다.\n\n이를 해결하기 위해 연구자들은 일부 레이블 데이터를 대규모의 레이블되지 않은 데이터 코퍼스와 융합하는 방법을 찾았습니다. 예를 들어, 아마존은 7,000시간의 레이블된 음성 및 100만 시간의 레이블되지 않은 음성을 사용하여 음성에 대한 그들의 음향 모델을 개선했습니다. 테슬라는 지금 자동 레이블링을 할 수 있는 충분한 레이블 데이터가 있다고 주장하지만, 그 정보는 희박합니다.\n\n그래서 더 많은 데이터가 승리하는 건가요? 그런데, 로봇 공학 분야에선 조금 다르게 작용할 수 있습니다. 로봇 공학의 문제는 텍스트, 음성, 이미지 또는 차량에서의 비디오와 달리, 우리가 데이터를 수집하고 다니는 로봇이 많지 않다는 점입니다. 세계에 있는 대부분의 데이터는 사람들이 한 결과물입니다... 우리가 쓰거나 말했거나, 사진을 찍었거나, 우리가 운전했거나 했습니다.\n\n만약 길을 운전하는 사람으로부터 어떠한 데이터도 캡처할 수 없다면 자율 주행 자동차를 만드는 것을 상상해 보세요. 더 나아가, 자율 주행이 되지 않은 자동차는 거의 유용하지 않습니다. 이것이 로봇과 관련된 문제입니다. 넓은 범위의 숙련된 작업을 수행하지 못하는 로봇들은 본질적으로 덜 유용하지만, 우리는 실제 세계에서 사람들이 하는 일들로부터 데이터를 캡처하는 좋은 방법을 가지고 있지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n어느 정도의 실험으로 우리는 움직임 캡처 슈트를 입거나 Mobile Aloha와 같은 릭을 사용하여 이 데이터(비디오)를 캡처하는 방식을 시도해 보았습니다.\n\n우리가 그 방법에 이를 수 있는 이론 중 하나는 매우 복잡한 로봇이 매우 간단한 작업을 수행하고, 그런 다음 우리가 음성 인식과 같이 점진적으로 개선하는 것일 것이라는 것입니다. 이 주장은 좋아 보이지만, 실제로는 아무런 의미가 없습니다. 복잡한 로봇을 사용해서 간단한 작업을 수행하는 데는 엄청난 비용이 들기 때문에 그 중 많은 수를 배치하지 않을 것이므로, 우리는 많은 데이터를 갖지 않게 됩니다.\n\n또 다른 도전 과제는 세계가 굉장히 복잡하다는 것입니다. 수백만개의 레이블이 붙은 항목들이 있어도, 자율 주행 차량은 여전히 이전에 본 적이 없는 상황에 직면할 수 있습니다. 수십 년 동안의 데이터 레이블링과 전통적 기술들도 몇 개의 도시를 넘어선 일반화된 무인 운전차를 만드는 데 성과를 내지 못했습니다.\n\n# 트랜스포머와 토큰\n\n<div class=\"content-ad\"></div>\n\nTransformer Architecture는 훨씬 더 나은 모델을 생성하는 데 차별화를 가져온 혁신이었습니다. Transformer 아키텍처는 토큰 시퀀스를 살펴보고 다음 토큰을 예측할 수 있도록 패턴을 찾아 작동합니다. ChatGPT 4의 Transformer 아키텍처는 인터넷에서 수집된 대량의 데이터 코퍼스로부터 13조 개의 토큰(사실상 \"단어\"들)로 훈련되었습니다. 우리는 많은 텍스트가 있고 그 텍스트는 토큰 시퀀스로 잘 구조화되어 있습니다.\n\n우리는 ChatGPT를 다음 단어 텍스트를 생성하는 것으로 생각하지만, 우리는 또한 토큰 간 번역을 할 수 있으며, 이것은 텍스트와 음성의 기계 번역을 놀라울 만큼 좋게 만들었습니다.\n\n그러나 transformer 아키텍처의 핵심은 공간을 transformer architecture에 적합하게 표현하기 위해 어떻게 토큰화하는 지를 결정하는 것입니다. 로봇 공학에서, 이러한 토큰들은 액션 스트림이 될 수 있습니다. TRI의 최근 확산 정책 작업은 견고한 제어의 개발을 가속화하는 데 큰 성과를 거두며 이것을 수행합니다. 그러나 그들은 여전히 한 번에 하나의 제어 정책만을 학습하고 있습니다.\n\n그러나 실제로 일반화하려면 많은 양의 토큰이 필요합니다. 우리는 충분한 양의 로봇이 토큰을 생성하지 않아 심각한 토큰 저장소를 구축하기에 충분하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n# 토큰의 원천\n\n토큰의 하나의 원천은 간단히 말해서 로봇 동작의 일반적인 표현을 고안하여 연구자들 사이에서 토큰을 공유할 수 있는 방법입니다. 첼시 핀과 다른 연구자들이 이를 시작하고 있습니다. 이제 충분히 흥미로운 토큰을 얻는 것이 여전히 난제입니다.\n\n또 다른 잠재적인 토큰의 원천은 대형 언어 모델의 잠재적 이해력을 활용하여 모션 플랜을 생성하고, 그 모션 플랜을 시뮬레이터에 공급한 다음 해당 시뮬레이션에서 모션의 토큰을 추출하는 것입니다. 이에 대한 논문들이 있는지는 아직 접하지 못했지만, ChatGPT가 학습한 월드 모델은 우리를 놀라게 하며 모션에 대한 깊은 본질적인 이해력을 가지고 있을 수 있습니다. 오늘은 아니더라도, 비디오와 이미지로부터 훈련된 다중 모달 모델들은 점차적으로 더 나은 모션에 대한 본질적인 이해력을 갖게 될 것으로 예상됩니다.\n\n또 다른 원천은 이미 존재하는 풍부한 비디오 자료입니다. 90년대 중반, 저는 MIT의 컴퓨터 과학 연구소 내 그래픽스 연구실에서 석사 논문 작업을 했습니다. 세스 텔러 교수님은 제 논문 지도 교수였습니다. 제 논문은 컴퓨터 그래픽을 위한 교육 플랫폼으로 웹을 활용하는 것에 중점을 둔 반면, 제 동료는 도시 맵핑을 위한 로봇 데이터 수집 장치를 구축하고 있었습니다. 도시 맵핑 프로젝트는 이 데이터 수집 장치로 수집된 2D 이미지에서 3D 지오메트리를 재구성하기 위해 계산 기하학을 활용했습니다.\n\n<div class=\"content-ad\"></div>\n\n동일한 컴퓨터 기하학 기법은 SLAM (Simultaneous Localization and Mapping)의 기초를 형성합니다. 이것은 현재의 로봇들이 2D 비디오에서 3D 기하를 재구성하여 우리 주변 세계를 탐색할 수 있는 방법입니다. 이러한 기법을 사용하여 스켈레톤을 추적하고 사람의 동작을 재구성할 수도 있습니다.\n\n이것은 많은 동작 토큰들의 잠재적 출처를 만듭니다.\n\n## 인간 수준의 로봇 구축에 대한 영향\n\n오늘날 우리는 양쪽 다 처리와 조작 분야에서 복잡한 실제 상호작용을 위해 안정적으로 인간형 로봇을 제어할 수 있는 모델이 충분히 좋지 않다는 문제를 가지고 있습니다. Boston Dynamics가 다양한 작업의 좋은 조합을 보여줄 수 있고, Agility가 매우 견고한 걷기 동역학을 보여주고, 연구소들이 박스를 오르내리며 멋진 스크래블을 하는 네 다리 동물을 보여줄 수 있을지라도, 우리는 여전히 새로운 상황이나 새로운 작업에 안정적으로 일반화할 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 이 복잡한 로봇들이 더 일반화된 강력한 제어 없이 의미 있는 작업을 수행할 수 없다면, 우리는 단순히 많은 수의 로봇을 배치할 수 없을 것이며, 캡쳐할 수 있는 데이터의 양이 제한될 것입니다.\n\n이전에 썼던 “인간 수준 로봇에 이르는 길”이라는 글에서 설명한 대로, 나는 현재 고성능 로봇을 신속히 투입하는 것이 최선의 방법이라고 생각합니다. 그러나 인간 형태 제약에서 벗어나 인간이 실제로 하는 일에 대한 관점에서 데이터를 수집해야 합니다.\n\nLLM(Large Language Models)의 내재 지식을 비디오에서 추출된 토큰과 결합하고 소량의 실제 데이터를 시뮬레이션에서 재구성하여, 우리는 어떤 로봇 형태도 가능하게 할 로봇 제어의 기본 모델을 구축하기 시작할 수 있을 것입니다. 그러면 Diffusion Policies의 기술을 이용하여 인간이 이끄는 다중 모델 제어가 지원된 기본 모델을 지도하는 방식으로 로봇을 가르쳐 7세처럼 어떤 작업이든 수행할 수 있게 할 수 있을 것입니다.\n\n저는 그 미래를 기대합니다. 이미 유용한 코로봇들은 이 기본 모델이 사용 가능해지면 더욱 더 유능한 협업자가 될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 다른 흥미로운 논문 및 강연:\n\n- Chelsea Finn - MIT에서 2023년 10월 23일에 로봇 학습의 일반화 및 민첩성에 관한 발표\n- Russ Tedrake - 프린스턴 로보틱스 - Russ Tedrake - 확산 정책을 이용한 민첩한 조작\n- Pieter Abbeel - 로봇 조각 집기를 위한 기반 모델 구축에 대해\n\n<div class=\"content-ad\"></div>\n\nChelsea Finn & Pieter Abbeel S3 E2 스탠포드 교수 첼시 핀: 항상 변화하는 세상에 대응할 수 있는 AI를 구축하는 방법\n\n브래드 포터는 Collaborative Robotics, Inc의 CEO이자 설립자로, Sequoia, Khosla 및 Mayo Clinic이 후원하는 캘리포니아 산타클라라에 본사를 둔 로봇 기업입니다. Cobot을 창립하기 전에, 브래드는 아마존의 물류 네트워크를 위한 로봇 기술을 감독하며 10,000명의 글로벌 팀을 이끄는 부사장 겸 탁월한 엔지니어였습니다. 그는 또한 Scale AI의 CTO, Tellme Networks의 플랫폼 아키텍트, 그리고 Netscape의 초기 엔지니어였습니다. 브래드는 MIT에서 컴퓨터 과학 학사학위와 석사학위를 취득했으며, 프로페서 Seth Teller 아래에서 컴퓨터 그래픽스에 중점을 둔 연구를 진행했습니다.","ogImage":{"url":"/assets/img/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots_0.png"},"coverImage":"/assets/img/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots_0.png","tag":["Tech"],"readingTime":10},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>내가 가장 좋아하는 스타워즈 장면은 츄바카가 우키의 울음소리를 내고 작은 토스트기 크기의 마우스 드로이드가 짹짹 거리며 뒤로 물러나는 장면입니다. 그 배경에는 무슨 일이 일어나고 있는지 상상해보세요? 그 로봇은 그 소리를 내는 것이 자신을 뭉개버릴 수 있는 무서운 협박하는 존재임을 인식해야 합니다. 두려움에 반응해야 합니다. 그리고 뒤로 바퀴로 이동하여 도망가야 합니다.</p>\n<p>오늘날의 로봇들은 이러한 이해와 제어 수준을 갖고 있지 않습니다. 이로 인해 그들은 자연스러워 보이지 않습니다. 현재의 로봇들은 일반적으로 딱딱하고 자연스럽지 않은 모습을 하고 있습니다. 또는 이상한 부조리한 계곡에 앉아서 자연스러워 보이려고 하지만 그것을 완전히 이룰 수 없습니다.</p>\n<h1>시뮬레이션 및 유전 알고리즘에 대한 초기 작업</h1>\n<p>1994년에 Karl Sims가 \"진화하는 가상 생물체\"라는 논문을 썼습니다. 그 논문은 물 속에서 움직이고 땅 위에서 움직이는 혁신적인 블록 생물체들을 보여주었습니다. Karl은 유전 알고리즘을 사용하여 생물체와 움직임을 진화시키는 아이디어를 시연했습니다. 그 비디오는 30년이 지난 지금도 여전히 매혹적입니다.</p>\n<p>이 연구는 새로운 행동과 새로운 제어를 갖는 혁신적인 생물체가 전진하거나 회전하는 등의 작업을 배울 수 있다는 것을 보여줬습니다. 시뮬레이션을 통해 건설함으로써 Karl Sims는 혁신적인 생물체들이 나타날 때까지 수많은 반복과 실험을 할 수 있었습니다. 게다가, 유전 알고리즘은 이전에 작동한 것을 채택하고 발전시킴으로써 점점 더 나은 것으로 수렴할 수 있다는 것을 보여줬습니다.</p>\n<h1>강화 학습의 등장</h1>\n<p>리치 서튼 박사는 1984년에 발표한 박사 논문에서 강화 학습의 개념을 고안했다고 인정받고 있습니다. 그의 말에 따르면, \"강화 학습은 보상으로부터 배움으로, 세계와의 평범한 상호작용 중에 시행착오를 통해 배우는 것\"입니다. 이후에는 Karl Sims의 작업과 비슷하게 시뮬레이션 세계에서 학습하도록 적응되었습니다.</p>\n<p>강화 학습은 딥마인드가 아타리 게임을 플레이하는 시스템을 가르칠 수 있다는 것을 증명한 경우를 포함하여 탐험의 핫한 분야로 부상했습니다. 이 시스템은 입력 비디오 프레임을 받아 조이스틱 컨트롤을 모방한 컨트롤 출력을 생성했습니다(비디오).</p>\n<p>이것은 RL이 시행착오를 통해 행동을 배우고 최적화할 수 있는 능력을 증명한 중대한 순간이었습니다. 이는 단순히 게임 그 자체를 숙달하는 데서 그치는 것이 아니라 기계가 원시 시각 입력과 게임 환경으로부터의 피드백만을 이용하여 복잡한 작업을 처음부터 배울 수 있다는 것을 입증한 것이었습니다.</p>\n<p>이러한 움직임을 기반으로, 오픈AI의 DOTA 2에 대한 작업은 복잡한 멀티플레이어 온라인 배틀 아레나 게임에서 큰 발전을 이뤘습니다(비디오). 강화 학습을 통해 훈련된 신경망 팀 오픈AI Five는 프로 수준의 인간 플레이어와 경쟁하고 이기는 능력을 보여주었습니다. 이 성취는 RL이 복잡성과 동적성이 증가하는 작업을 처리할 수 있는 능력, 전략적 계획, 팀워크, 예측할 수 없는 상대에 대한 실시간 의사 결정을 포함하는 작업을 다룰 수 있는 능력을 강조했습니다.</p>\n<p>오픈AI의 학습 능력 프로젝트는 RL이 달성할 수 있는 영역을 더 넓혀주었습니다. 로봇 손을 훈련시켜 인간 손과 유사한 미세 조작 능력을 갖도록 하는 것을 통해, 이 프로젝트는 RL이 미세한 운동 통제와 적응력을 필요로 하는 물리적 작업에서의 잠재력을 강조했습니다(비디오). 이 프로젝트는 손을 훈련시키기 위해 실제 환경으로 그 기술을 옮기기 전에 시뮬레이션 환경을 사용한 것으로, sim-to-real 전이라고 알려진 기술을 사용한 점에서 특히 주목할 만했습니다.</p>\n<h1>강화 학습의 한계 극복하기</h1>\n<p>강화 학습의 첫 번째 큰 난제는 많은 시행 착오를 하는 데 비용이 많이 든다는 것입니다. 특히 학습 초기 단계에서 많은 테스트된 가설이 정말로 좋지 않은 것들이 많습니다. 따라서 나쁜 가치를 구별하여 목표에 근접한 것을 찾아내려고 하는 것은 어렵습니다. 또한 필요한 시행 착오 횟수는 액추에이터 수와 함께 증가합니다. 이것은 부트스트래핑 문제로 볼 수 있습니다... 강화 학습이 더 효율적일 수 있도록 모델을 시작할 수 있는 방법은 무엇인가요?</p>\n<p>이 문제를 해결하는 데 도움이 될 수 있는 다양한 기술이 있습니다:</p>\n<ul>\n<li>먼저 시뮬레이션 사용: 실제 세계에서 작동을 확인하기 전에 시뮬레이션에서 모든 시행 착오를 수행하여 작동하는 솔루션에 더 가까워지려고 노력합니다.</li>\n<li>모방 학습: 강화 학습을 세부 조정하기 전에 기본 모델을 얻기 위해 다른 기술을 사용합니다. 이 기술 중 하나는 사람이 액추에이터를 제어하도록 하고, 그 후에 학습하는 것입니다. 또는 \"One-shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning\"에서 시연된 것처럼 비디오에서 모방합니다. 최근 CMU 로봇 공학 연구소의 논문 \"SloMo: A General System for Legged Robot Motion Imitation from Casual Videos\"에서는 개와 고양이의 비디오에서 배운 것을 다리로봇에 전달하는 능력을 보였습니다.</li>\n<li>액추에이터 공간의 차원 축소: 인간의 손은 40개 이상의 제어 차원을 가지고 있으며 OpenAI Detrous Manipulation 프로젝트에서 사용된 Shadow Hand와 같은 장치는 26개의 차원을 가지고 있습니다. Columbia는 \"eigengrasps\"를 만들어 알려진 잡음 상태에서의 접근 문제를 단순화하기 위해 손을 간단한 문제로 전환하려고 노력했습니다.</li>\n<li>문제 단순화: 특히 로봇 픽킹에서 널리 사용되는 방법은 물건을 집을 때 기존 것을 잡아들이기에 걱정할 필요 없도록 매우 높은 유동성 진공을 단순히 사용하는 것입니다. Agility는 로봇의 다리를 설계하여 다리 제어 모델을 탄성 질량 진자로 모델링할 수 있도록 하여 제어 문제를 단순화했습니다.</li>\n<li>행동 클로닝: 이미 작동하는 시스템이 있다면 다른 시스템이 그 행동을 복제하도록 시도할 수 있습니다. 처음에는 지도 학습 기술을 사용해보는 것입니다.</li>\n</ul>\n<p>강화 학습의 두 번째 큰 도전은 매우 견고하지 않으며 지정된 보상에 과적합될 수 있다는 것입니다. 예를 들어, 인간 형상 로봇이 농구 골대에 골을 넣도록 훈련하려면, 목표가 단순히 골을 넣는 것이라면 로봇은 보다 성공적인 방법으로 공을 던질 것입니다. 그러나 인간이 농구를 차는 것과 같이 보이기를 원한다면, 골을 넣는 것과 인간처럼 보이는 것 둘 다 보상하는 더 정교한 보상 함수가 필요합니다.</p>\n<ul>\n<li>도메인 랜덤화: 입력 공간을 교란하고 동일한 목표를 달성하려고 하면 모델이 더 견고해질 수 있습니다.</li>\n<li>인간 취향: 인간들은 성공이 어떻게 보이어야 하는지에 대해 보다 세밀한 버전을 가지고 있습니다. 그래서 목표를 달성하는 것으로 시스템을 보상하는 대신에, 주로 인간이 선호하는 대로 행동하도록 시스템에 보상을 줄 수 있습니다. 일반적으로 인간에게 두 가지 예시를 나란히 보여주고 어느 쪽이 더 좋은지 묻습니다.</li>\n</ul>\n<p>강화 학습의 세 번째 큰 도전은 한 번에 한 가지 작업만 배운다는 것입니다! 문을 열어본 방법을 배웠다고 해서 다른 어떤 문의 손잡이나 심지어 높이가 2인치 낮은 문의 손잡이를 열 수 있다는 것을 의미하지 않습니다. 사실, 이 문제는 전혀 잘 해결되지 않습니다. 이를 해결하기 위한 몇 가지 대처 방법이 있습니다:</p>\n<ul>\n<li>동적 손재능 로봇 행동의 순차적 구성: 이 논문은 한 제어 체제에서 다른 체제로 부드럽게 전환하는 기술을 유도했는데, 두 제어 체제 간에 중첩이 있을 때 전환하는 방법을 제시합니다. 이는 매우 통찰력있는 논문입니다. Boston Dynamics은 아틀라스가 팽이를 하도록 만들기 위해 이 기술을 사용하거나 이 기술의 진화형을 사용한다고 여겨집니다.</li>\n<li>환경 제한: 작업을 매우 구체적인 상황으로 제한하면 문제를 크게 단순화할 수 있습니다. 예를 들어, 일반적인 세계에서 물건을 움켜쥐는 것은 매우 어렵습니다. 하지만 그냥 통에 있는 물건을 집는 것으로 제한한다면 문제를 상당히 단순화하고 그 후 하나의 작업만 배울 수 있습니다. 마찬가지로, 로봇이 할 수 있는 것을 충족하기 위해 모든 문 손잡이를 변경할 수 있습니다.</li>\n</ul>\n<p>로봇 공학 분야에서 이 문제는 매우 큰 문제이며, 로봇 공학 커뮤니티 외부에서는 잘 이해되지 않는 문제입니다. 진짜 인상적인 로봇 액션의 데모를 자주 보게 되는데, 우리는 로봇이 백플립을 할 수 있는 로봇이라면 당연히 몽키 바도 할 수 있을 것이라고 바로 생각합니다. 왜냐하면 우리는 7세 어린이가 백플립을 할 수 있는 아이라면 몽키 바에는 문제가 없을 것이기 때문입니다. 하지만 로봇은 그렇지 않습니다. 만약 로봇이 몽키 바를 할 수 있도록 훈련받지 않았다면, 그것은 그 일을 할 능력이 전혀 없을 것입니다.</p>\n<p>인간이 할 수 있는 모든 것을 하나씩 배우려고 할 때 우리는 영원히 걸릴 것입니다.</p>\n<h1>데이터의 역할</h1>\n<p>우리가 알려진 정답 테스트 세트와 같은 결과를 생성해내는 모델을 고안하는 지도 학습에서는, 데이터가 많을수록 좋습니다. 음성 인식 분야의 초기 진전의 많은 부분은 지도 학습을 통해 이루어졌습니다. Tellme에서는, Nuance의 음성 인식 엔진을 사용하고 있음에도 불구하고 더 많은 데이터를 가지고 있기 때문에 어느 순간 Nuance보다 더 나은 음성 인식을 할 수 있었습니다.</p>\n<p>사람들이 더 많은 데이터가 이긴다고 가정하는 것으로 이어졌습니다. 어느 정도는 여전히 사실이지만, 지도 학습을 시도하는 경우 테스트 세트가 필요합니다. 그리고 결과물은 당신의 테스트 및 훈련 세트의 크기만큼 좋습니다. 그래서 더 많은 데이터를 원하게 됩니다. Scale AI가 한 초기 작업 중 하나는, 자율 주행 자동차 회사들이 자동차, 정지 신호, 보행자, 교통 가로등 등이 어디에 있는지 보여 주는 레이블된 데이터 세트를 구축하는 데 도움을 주었습니다. 이러한 훈련 세트들을 구축하는 데는 매우 비용이 많이 들며 우리가 희망하는 것만큼 결과가 좋지 않습니다.</p>\n<p>이를 해결하기 위해 연구자들은 일부 레이블 데이터를 대규모의 레이블되지 않은 데이터 코퍼스와 융합하는 방법을 찾았습니다. 예를 들어, 아마존은 7,000시간의 레이블된 음성 및 100만 시간의 레이블되지 않은 음성을 사용하여 음성에 대한 그들의 음향 모델을 개선했습니다. 테슬라는 지금 자동 레이블링을 할 수 있는 충분한 레이블 데이터가 있다고 주장하지만, 그 정보는 희박합니다.</p>\n<p>그래서 더 많은 데이터가 승리하는 건가요? 그런데, 로봇 공학 분야에선 조금 다르게 작용할 수 있습니다. 로봇 공학의 문제는 텍스트, 음성, 이미지 또는 차량에서의 비디오와 달리, 우리가 데이터를 수집하고 다니는 로봇이 많지 않다는 점입니다. 세계에 있는 대부분의 데이터는 사람들이 한 결과물입니다... 우리가 쓰거나 말했거나, 사진을 찍었거나, 우리가 운전했거나 했습니다.</p>\n<p>만약 길을 운전하는 사람으로부터 어떠한 데이터도 캡처할 수 없다면 자율 주행 자동차를 만드는 것을 상상해 보세요. 더 나아가, 자율 주행이 되지 않은 자동차는 거의 유용하지 않습니다. 이것이 로봇과 관련된 문제입니다. 넓은 범위의 숙련된 작업을 수행하지 못하는 로봇들은 본질적으로 덜 유용하지만, 우리는 실제 세계에서 사람들이 하는 일들로부터 데이터를 캡처하는 좋은 방법을 가지고 있지 않습니다.</p>\n<p>어느 정도의 실험으로 우리는 움직임 캡처 슈트를 입거나 Mobile Aloha와 같은 릭을 사용하여 이 데이터(비디오)를 캡처하는 방식을 시도해 보았습니다.</p>\n<p>우리가 그 방법에 이를 수 있는 이론 중 하나는 매우 복잡한 로봇이 매우 간단한 작업을 수행하고, 그런 다음 우리가 음성 인식과 같이 점진적으로 개선하는 것일 것이라는 것입니다. 이 주장은 좋아 보이지만, 실제로는 아무런 의미가 없습니다. 복잡한 로봇을 사용해서 간단한 작업을 수행하는 데는 엄청난 비용이 들기 때문에 그 중 많은 수를 배치하지 않을 것이므로, 우리는 많은 데이터를 갖지 않게 됩니다.</p>\n<p>또 다른 도전 과제는 세계가 굉장히 복잡하다는 것입니다. 수백만개의 레이블이 붙은 항목들이 있어도, 자율 주행 차량은 여전히 이전에 본 적이 없는 상황에 직면할 수 있습니다. 수십 년 동안의 데이터 레이블링과 전통적 기술들도 몇 개의 도시를 넘어선 일반화된 무인 운전차를 만드는 데 성과를 내지 못했습니다.</p>\n<h1>트랜스포머와 토큰</h1>\n<p>Transformer Architecture는 훨씬 더 나은 모델을 생성하는 데 차별화를 가져온 혁신이었습니다. Transformer 아키텍처는 토큰 시퀀스를 살펴보고 다음 토큰을 예측할 수 있도록 패턴을 찾아 작동합니다. ChatGPT 4의 Transformer 아키텍처는 인터넷에서 수집된 대량의 데이터 코퍼스로부터 13조 개의 토큰(사실상 \"단어\"들)로 훈련되었습니다. 우리는 많은 텍스트가 있고 그 텍스트는 토큰 시퀀스로 잘 구조화되어 있습니다.</p>\n<p>우리는 ChatGPT를 다음 단어 텍스트를 생성하는 것으로 생각하지만, 우리는 또한 토큰 간 번역을 할 수 있으며, 이것은 텍스트와 음성의 기계 번역을 놀라울 만큼 좋게 만들었습니다.</p>\n<p>그러나 transformer 아키텍처의 핵심은 공간을 transformer architecture에 적합하게 표현하기 위해 어떻게 토큰화하는 지를 결정하는 것입니다. 로봇 공학에서, 이러한 토큰들은 액션 스트림이 될 수 있습니다. TRI의 최근 확산 정책 작업은 견고한 제어의 개발을 가속화하는 데 큰 성과를 거두며 이것을 수행합니다. 그러나 그들은 여전히 한 번에 하나의 제어 정책만을 학습하고 있습니다.</p>\n<p>그러나 실제로 일반화하려면 많은 양의 토큰이 필요합니다. 우리는 충분한 양의 로봇이 토큰을 생성하지 않아 심각한 토큰 저장소를 구축하기에 충분하지 않습니다.</p>\n<h1>토큰의 원천</h1>\n<p>토큰의 하나의 원천은 간단히 말해서 로봇 동작의 일반적인 표현을 고안하여 연구자들 사이에서 토큰을 공유할 수 있는 방법입니다. 첼시 핀과 다른 연구자들이 이를 시작하고 있습니다. 이제 충분히 흥미로운 토큰을 얻는 것이 여전히 난제입니다.</p>\n<p>또 다른 잠재적인 토큰의 원천은 대형 언어 모델의 잠재적 이해력을 활용하여 모션 플랜을 생성하고, 그 모션 플랜을 시뮬레이터에 공급한 다음 해당 시뮬레이션에서 모션의 토큰을 추출하는 것입니다. 이에 대한 논문들이 있는지는 아직 접하지 못했지만, ChatGPT가 학습한 월드 모델은 우리를 놀라게 하며 모션에 대한 깊은 본질적인 이해력을 가지고 있을 수 있습니다. 오늘은 아니더라도, 비디오와 이미지로부터 훈련된 다중 모달 모델들은 점차적으로 더 나은 모션에 대한 본질적인 이해력을 갖게 될 것으로 예상됩니다.</p>\n<p>또 다른 원천은 이미 존재하는 풍부한 비디오 자료입니다. 90년대 중반, 저는 MIT의 컴퓨터 과학 연구소 내 그래픽스 연구실에서 석사 논문 작업을 했습니다. 세스 텔러 교수님은 제 논문 지도 교수였습니다. 제 논문은 컴퓨터 그래픽을 위한 교육 플랫폼으로 웹을 활용하는 것에 중점을 둔 반면, 제 동료는 도시 맵핑을 위한 로봇 데이터 수집 장치를 구축하고 있었습니다. 도시 맵핑 프로젝트는 이 데이터 수집 장치로 수집된 2D 이미지에서 3D 지오메트리를 재구성하기 위해 계산 기하학을 활용했습니다.</p>\n<p>동일한 컴퓨터 기하학 기법은 SLAM (Simultaneous Localization and Mapping)의 기초를 형성합니다. 이것은 현재의 로봇들이 2D 비디오에서 3D 기하를 재구성하여 우리 주변 세계를 탐색할 수 있는 방법입니다. 이러한 기법을 사용하여 스켈레톤을 추적하고 사람의 동작을 재구성할 수도 있습니다.</p>\n<p>이것은 많은 동작 토큰들의 잠재적 출처를 만듭니다.</p>\n<h2>인간 수준의 로봇 구축에 대한 영향</h2>\n<p>오늘날 우리는 양쪽 다 처리와 조작 분야에서 복잡한 실제 상호작용을 위해 안정적으로 인간형 로봇을 제어할 수 있는 모델이 충분히 좋지 않다는 문제를 가지고 있습니다. Boston Dynamics가 다양한 작업의 좋은 조합을 보여줄 수 있고, Agility가 매우 견고한 걷기 동역학을 보여주고, 연구소들이 박스를 오르내리며 멋진 스크래블을 하는 네 다리 동물을 보여줄 수 있을지라도, 우리는 여전히 새로운 상황이나 새로운 작업에 안정적으로 일반화할 수 없습니다.</p>\n<p>하지만 이 복잡한 로봇들이 더 일반화된 강력한 제어 없이 의미 있는 작업을 수행할 수 없다면, 우리는 단순히 많은 수의 로봇을 배치할 수 없을 것이며, 캡쳐할 수 있는 데이터의 양이 제한될 것입니다.</p>\n<p>이전에 썼던 “인간 수준 로봇에 이르는 길”이라는 글에서 설명한 대로, 나는 현재 고성능 로봇을 신속히 투입하는 것이 최선의 방법이라고 생각합니다. 그러나 인간 형태 제약에서 벗어나 인간이 실제로 하는 일에 대한 관점에서 데이터를 수집해야 합니다.</p>\n<p>LLM(Large Language Models)의 내재 지식을 비디오에서 추출된 토큰과 결합하고 소량의 실제 데이터를 시뮬레이션에서 재구성하여, 우리는 어떤 로봇 형태도 가능하게 할 로봇 제어의 기본 모델을 구축하기 시작할 수 있을 것입니다. 그러면 Diffusion Policies의 기술을 이용하여 인간이 이끄는 다중 모델 제어가 지원된 기본 모델을 지도하는 방식으로 로봇을 가르쳐 7세처럼 어떤 작업이든 수행할 수 있게 할 수 있을 것입니다.</p>\n<p>저는 그 미래를 기대합니다. 이미 유용한 코로봇들은 이 기본 모델이 사용 가능해지면 더욱 더 유능한 협업자가 될 것입니다.</p>\n<h1>다른 흥미로운 논문 및 강연:</h1>\n<ul>\n<li>Chelsea Finn - MIT에서 2023년 10월 23일에 로봇 학습의 일반화 및 민첩성에 관한 발표</li>\n<li>Russ Tedrake - 프린스턴 로보틱스 - Russ Tedrake - 확산 정책을 이용한 민첩한 조작</li>\n<li>Pieter Abbeel - 로봇 조각 집기를 위한 기반 모델 구축에 대해</li>\n</ul>\n<p>Chelsea Finn &#x26; Pieter Abbeel S3 E2 스탠포드 교수 첼시 핀: 항상 변화하는 세상에 대응할 수 있는 AI를 구축하는 방법</p>\n<p>브래드 포터는 Collaborative Robotics, Inc의 CEO이자 설립자로, Sequoia, Khosla 및 Mayo Clinic이 후원하는 캘리포니아 산타클라라에 본사를 둔 로봇 기업입니다. Cobot을 창립하기 전에, 브래드는 아마존의 물류 네트워크를 위한 로봇 기술을 감독하며 10,000명의 글로벌 팀을 이끄는 부사장 겸 탁월한 엔지니어였습니다. 그는 또한 Scale AI의 CTO, Tellme Networks의 플랫폼 아키텍트, 그리고 Netscape의 초기 엔지니어였습니다. 브래드는 MIT에서 컴퓨터 과학 학사학위와 석사학위를 취득했으며, 프로페서 Seth Teller 아래에서 컴퓨터 그래픽스에 중점을 둔 연구를 진행했습니다.</p>\n</body>\n</html>\n"},"__N_SSG":true}