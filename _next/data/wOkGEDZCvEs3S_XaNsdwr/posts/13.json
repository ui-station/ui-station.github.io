{"pageProps":{"posts":[{"title":"Ubuntu 2204에 Docker Desktop 설치하는 방법","description":"","date":"2024-06-23 22:53","slug":"2024-06-23-HowToInstallDockerDesktoponUbuntu2204","content":"\n<img src=\"/assets/img/2024-06-23-HowToInstallDockerDesktoponUbuntu2204_0.png\" />\n\n이 블로그에서는 Ubuntu 22.04에 Docker Desktop을 설정하는 방법을 살펴보겠습니다.\n\nDocker Desktop:\n\nDocker Desktop은 macOS, Linux 및 Windows 컴퓨터용 응용 프로그램으로, 컨테이너화된 응용 프로그램 및 마이크로서비스를 빠르고 안전하게 구축하고 공유할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDocker Desktop에는 응용 프로그램 개발을 위한 내장 Kubernetes 설정이 포함되어 있으며, 인증된 이미지, 템플릿, 그리고 원하는 언어와 도구를 사용할 수 있습니다. 개발 워크플로우는 Docker Hub를 활용하여 개발 환경을 안전한 저장소로 확장하여 빠른 자동 빌드, 지속적 통합 및 안전한 협업을 지원합니다.\n\n## 준비 사항\n\nPC가 다음 기본 요구 사항을 충족하는지 확인해주세요.\n\n- 가상화 지원이 활성화된 64비트 CPU\n- 적어도 4GB RAM\n- GUI 데스크톱 환경 (가능하면 GNOME, MATE 또는 KDE)\n- 관리자 권한이 있는 Sudo 사용자\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# KVM 가상화 지원\n\n호스트가 가상화 지원을 하는 경우 kvm 모듈은 자동으로 로드됩니다. 모듈을 수동으로 로드하려면 다음을 실행하세요:\n\n```js\nmodprobe kvm\n```\n\n호스트 머신의 프로세서에 따라 해당 모듈을 로드해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nmodprobe kvm_intel  # 인텔 프로세서\nmodprobe kvm_amd    # AMD 프로세서\n```\n\n단계 1: Gnome 데스크톱이 없는 상황에서는 Gnome 터미널을 설치해야 합니다:\n\n```js\nsudo apt install gnome-terminal\n```\n\n단계 2: Linux용 Docker Desktop의 기술 미리보기 또는 베타 버전을 제거하세요. 실행하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nsudo apt remove docker-desktop\n```\n\n# 우분투 22.04에 Docker 설치하기:\n\n이제 Docker를 설치해봅시다. 하지만 그 전에 패키지 목록을 업데이트하고 필수 종속성을 설치해야 합니다. 다음과 같이 입력해주세요.\n\n```js\n$ sudo apt update\n$ sudo apt install software-properties-common curl apt-transport-https ca-certificates -y\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n설치가 완료되면 Docker의 GPG 서명 키를 추가해주세요.\n\n```js\n$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/docker-archive-keyring.gpg\n```\n\n다음으로, 아래와 같이 시스템에 공식 Docker 저장소를 추가해주세요.\n\n```js\n$ sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\"\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n레포지토리가 준비되었으면 다음과 같이 Docker 및 기타 도커 도구를 설치합니다.\n\n```js\n$ sudo apt install docker-ce docker-ce-cli containerd.io uidmap -y\n```\n\n도커가 실행 중인지 확인하려면 다음 명령어를 실행하세요:\n\n```js\nsudo systemctl status docker\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 Docker 버전을 확인하는 방법입니다.\n\n```js\ndocker version\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우분투 22.04에 Docker Desktop 설치 방법:\n\n아래 wget 명령어를 사용하여 Docker Desktop을 설치하세요. Docker Desktop의 최신 버전은 Docker Desktop 버전 4.19.0입니다.\n\n```js\n$ wget https://desktop.docker.com/linux/main/amd64/docker-desktop-4.19.0-amd64.deb\n```\n\n또한 이 링크에서 DEB 패키지를 다운로드할 수 있고 아래 명령어를 사용하여 설치할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n$ sudo apt install ./docker-desktop-*-amd64.deb\n```\n\n![Docker Desktop Installation](/assets/img/2024-06-23-HowToInstallDockerDesktoponUbuntu2204_3.png)\n\n도커 데스크톱을 실행하세요:\n\n이제 애플리케이션 메뉴에서 도커 데스크톱을 실행하고 라이센스 약관을 수락하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-HowToInstallDockerDesktoponUbuntu2204_4.png\" />\n\n이제 CLI에서 명령어 대신 도커 데스크톱에서 컨테이너를 만들 수 있어요.\n\n즐거운 학습 되세요!\n","ogImage":{"url":"/assets/img/2024-06-23-HowToInstallDockerDesktoponUbuntu2204_0.png"},"coverImage":"/assets/img/2024-06-23-HowToInstallDockerDesktoponUbuntu2204_0.png","tag":["Tech"],"readingTime":6},{"title":"Docker 볼륨 이해하기 완벽 가이드","description":"","date":"2024-06-23 22:52","slug":"2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide","content":"\n도커(Docker)의 컨테이너는 상태를 유지하지 않고 쉽게 폐기할 수 있는 방식으로 설계되었습니다. 볼륨(Volumes)은 컨테이너가 생성하고 사용하는 데이터를 단일 컨테이너의 수명 주기를 넘어서 계속 유지하는 방법을 제공합니다. 이는 데이터베이스, 파일 저장소 및 지속적인 저장 공간이 필요한 다른 응용 프로그램에 필수적입니다.\n\n본 문서는 도커 볼륨을 생성하고 사용하는 다양한 방법을 탐구하며, 실제 응용 사례를 설명하기 위한 예제가 포함되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Docker Volume 소개\n\nDocker 볼륨은 Docker 컨테이너에서 생성된 데이터를 저장하고 사용하기 위해 설계된 지속적인 저장 메커니즘입니다. 이들은 데이터 수명주기를 컨테이너 수명주기와 분리하여 데이터가 컨테이너가 삭제되거나 다시 생성되더라도 손상되지 않도록 보장합니다.\n\n# Docker Volume의 종류\n\n## Named Volumes\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이름이 지정된 볼륨은 사용자가 정의한 볼륨으로, 이름으로 쉽게 참조하고 여러 컨테이너 간에 재사용할 수 있습니다. 이러한 볼륨은 Docker의 내부 볼륨 저장소에 저장됩니다.\n\n```js\ndocker volume create myVolume\ndocker run -d --name my_container -v myVolume:/data node_container\n```\n\n## 익명 볼륨\n\n이름이 지정되지 않은 볼륨은 생성된 이름이 없을 때 생성됩니다. 이러한 볼륨들은 일반적으로 컨테이너의 수명주기를 넘어서 지속되지 않아야 하는 일시적인 데이터에 사용됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 실행 -d --name my_container -v /data node_container\n```\n\n## 바인드 마운트\n\n바인드 마운트는 호스트 파일 시스템의 디렉터리나 파일을 컨테이너에 매핑합니다. 이를 통해 호스트 파일 시스템에 직접 액세스하여 데이터를 호스트와 컨테이너 간에 공유해야하는 시나리오에 이상적입니다.\n\n```js\n도커 실행 -d --name my_container -v /호스트/경로:/data node_container\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## tmpfs 볼륨\n\ntmpfs 볼륨은 컨테이너의 메모리에 임시 파일 시스템을 마운트합니다. 민감한 정보나 임시 파일과 같이 디스크에 쓰여서는 안 되는 비영구 데이터를 저장하는 데 유용합니다.\n\n```js\ndocker run -d --name my_container --tmpfs /data node_container\n```\n\n# Docker 볼륨 생성 및 관리\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 볼륨 만들기\n\n이름이 지정된 볼륨을 만들려면 다음 명령을 사용하세요:\n\n```js\ndocker volume create myVolume\n```\n\n## 볼륨 검사\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n볼륨을 검사하고 세부 정보를 확인하려면\n\n```js\ndocker volume inspect myVolume\n```\n\n## 볼륨 제거\n\n더 이상 필요하지 않은 볼륨을 제거하려면:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 볼륨 삭제 myVolume\n```\n\n![이미지](/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_2.png)\n\n# 도커 볼륨 사용하기\n\n## 명명된 볼륨 마운트하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n특정 이름의 볼륨을 컨테이너에 마운트하려면:\n\n```js\ndocker run -d -v myVolume:/app/data myImage\n```\n\n## 익명 볼륨 마운트\n\n익명 볼륨을 마운트하려면:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 실행 -d -v /app/data myImage\n```\n\n## 바인드 마운트 사용하기\n\n바인드 마운트를 사용하려면 호스트 경로와 컨테이너 경로를 지정하십시오:\n\n```js\n도커 실행 -d -v /host/data:/app/data myImage\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 예시\n\n## 1. 이름있는 볼륨을 사용하여 데이터 유지하기\n\n이름이 지정된 볼륨을 생성하고 컨테이너에서 사용하기\n\n```js\ndocker volume create mydata\ndocker run -d -v mydata:/app/data myImage\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n컨테이너 내부의 /app/data 경로에 작성된 모든 데이터는 컨테이너가 삭제되더라도 유지됩니다.\n\n## 2. 컨테이너 간 데이터 공유\n\n여러 컨테이너 간 데이터를 공유하려면 명명된 볼륨을 사용할 수 있습니다:\n\n```js\ndocker volume create shared_data\ndocker run -d -v shared_data:/app/data container1\ndocker run -d -v shared_data:/app/data container2\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Understanding Docker Volumes](/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_3.png)\n\n두 컨테이너 모두 /app/data에 읽고 쓸 수 있어 데이터 공유가 가능합니다.\n\n## 개발을 위한 Bind Mount 사용\n\n호스트 디렉토리를 컨테이너에 매핑하는 Bind Mount를 사용하여 실시간 코드 변경을 가능하게 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 실행 -d -v $(pwd):/app myImage\n```\n\n호스트 디렉토리의 파일에 대한 변경 사항은 즉시 컨테이너에 반영됩니다.\n\n# 간단한 Node.js 애플리케이션 예제\n\n## 단계 1: Node.js 애플리케이션 생성\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저 파일에 데이터를 작성하는 간단한 Node.js 애플리케이션을 만들어봅시다:\n\n![이미지](/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_4.png)\n\n## 단계 2: Dockerfile 생성\n\n다음으로 Node.js 애플리케이션을 위한 Dockerfile을 만들어봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nFROM node:14\n\nWORKDIR /app\n\nCOPY . .\n\nCMD [\"node\", \"app.js\"]\n```\n\n## Step 3: 이제 도커 이미지를 빌드하세요\n\n![Step 3](/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_5.png)\n\n## Step 4: 컨테이너를 실행하세요\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_6.png\" />\n\n- myVolume: 호스트 머신에있는 볼륨의 이름입니다.\n- :/app/data: 이는 컨테이너 내부의 마운트 포인트를 지정합니다. 이 경우 호스트의 myVolume 볼륨을 컨테이너 내부의 /app/data 디렉토리로 마운트합니다.\n\n## 단계 5: data.txt 파일의 내용을 확인합니다.\n\n<img src=\"/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_7.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_8.png\" />\n\n# 도커 볼륨 사용에 대한 최상의 방법\n\n- 컨테이너 수명 주기를 초과하는 데이터에 사용할 때는 명명된 볼륨을 사용합니다.\n- 개발 목적이거나 호스트 파일에 직접 액세스해야 할 때는 바인드 마운트를 사용합니다.\n- 사용되지 않는 볼륨을 정기적으로 검사하고 정리하여 공간을 확보합니다.\n- 보안 위험을 피하기 위해 바인드 마운트를 사용할 때 올바른 액세스 권한을 보장합니다.\n\n# 결론\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도커 볼륨은 컨테이너화된 응용 프로그램의 유연성과 효율성을 향상시키는 강력한 기능입니다. 다양한 유형의 볼륨을 이해하고 관리하는 방법을 알면 도커를 사용하여 컨테이너 내에서 데이터를 지속적으로 유지, 공유 및 관리할 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_0.png"},"coverImage":"/assets/img/2024-06-23-UnderstandingDockerVolumesAComprehensiveGuide_0.png","tag":["Tech"],"readingTime":9},{"title":"쿠버네티스 Pod 간 통신 완벽 가이드 마스터하기 위한 모든 것","description":"","date":"2024-06-23 22:50","slug":"2024-06-23-MasteringKubernetesPod-to-PodCommunicationAComprehensiveGuide","content":"\n<img src=\"/assets/img/2024-06-23-MasteringKubernetesPod-to-PodCommunicationAComprehensiveGuide_0.png\" />\n\n# 소개\n\nKubernetes는 컨테이너 오케스트레이션을 혁신하여 기업이 규모에 맞게 응용 프로그램을 배포하고 관리할 수 있게 하였습니다. Kubernetes의 주요 구성요소 중 하나인 pod는 하나 이상의 강하게 결합된 컨테이너들의 논리적 그룹입니다. pod가 서로 통신하는 방식을 이해하는 것은 Kubernetes 클러스터에서 탄력적이고 확장 가능한 응용 프로그램을 구축하는 데 중요합니다. 이 블로그 게시물에서는 Kubernetes pod 간 통신에 대해 깊이 알아보고 다양한 통신 패턴과 기술을 탐구할 것입니다.\n\n# Pod 네트워킹 이해하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n쿠버네티스에서 Pods는 클러스터 내에서 고유한 IP 주소가 할당되어 직접 통신할 수 있습니다. 기본적으로 각 Pod는 격리되어 고유한 IP 주소를 가지며, 안전한 통신을 가능하게 하고 포트 충돌을 피할 수 있습니다. 이러한 IP 주소는 외부 액세스를 위해 특정 구성이 없는 한 쿠버네티스 클러스터 네트워크 내에서만 접근 가능합니다.\n\n# 쿠버네티스 네트워킹 모델\n\n- 동일 노드 내 Pod 간 통신: 동일한 노드에 여러 개의 Pod가 예약되면 localhost 또는 루프백 인터페이스를 사용하여 직접 통신할 수 있습니다. 이 통신은 주로 가상 이더넷(veth) 쌍 형태로 클러스터 내에 할당된 Pod의 IP 주소를 통해 이루어집니다. 이 통신은 네트워크 계층에서 발생하여 동일 노드의 Pod 간 높은 성능과 낮은 지연 시간 상호작용을 가능하게 합니다.\n- 노드 간 Pod 간 통신: 클러스터 내 서로 다른 노드 간에 통신이 필요한 경우, 쿠버네티스는 다양한 네트워킹 솔루션인 Container Network Interfaces (CNIs) 및 소프트웨어 정의 네트워킹(SDN) 기술을 활용합니다. 이러한 솔루션은 전체 클러스터를 가로지르는 가상 네트워크 오버레이를 생성하여 노드 간 Pod 간 통신을 가능하게 합니다. Calico, Flannel, Weave, Cilium 등이 인기 있는 CNIs 중 일부이며, 이러한 네트워킹 솔루션은 Pod의 IP 주소가 Reachable하도록 보장하며, 클러스터 내에서 Pod의 위치에 관계없이 투명한 네트워크 연결성을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기본적으로 쿠버네티스 클러스터 내의 파드는 내부 IP 주소를 사용하여 서로 통신할 수 있습니다. 이 통신은 백그라운드의 컨테이너 런타임이나 네트워크 플러그인에서 제공하는 가상 네트워크 오버레이를 통해 이루어집니다. 내부 IP 주소는 쿠버네티스 클러스터 네트워킹 솔루션에 의해 할당되며 클러스터 내에서만 라우터링됩니다.\n\n# DNS 기반 서비스 검색\n\n쿠버네티스는 클러스터 내에서 서비스 검색을 위한 내장 DNS 서비스를 제공합니다. 서비스들은 기본 파드를 추상화한 안정적인 엔드포인트 역할을 합니다. 각 서비스는 DNS 이름이 할당되며, 해당 서비스를 지원하는 파드의 IP 주소로 해석됩니다. 이 DNS 기반 접근 방식을 통해 파드는 개별 파드 IP 주소를 직접 참조하는 대신 서비스 이름을 사용하여 서로 통신할 수 있습니다.\n\n# 서비스 로드 밸런싱\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여러 개의 팟이 동일한 애플리케이션을 제공할 때, Kubernetes는 이러한 팟들 간의 트래픽을 분산하는 데 사용하는 내장된 로드 밸런싱 기능을 제공합니다. 서비스 객체를 생성하고 이를 일련의 팟과 연결함으로써, Kubernetes는 사용 가능한 팟들 사이에 들어오는 요청을 자동으로 로드 밸런싱합니다. 이 로드 밸런싱 메커니즘은 애플리케이션의 고가용성과 확장성을 보장합니다.\n\n# 네트워크 정책\n\nKubernetes는 팟 간의 트래픽 흐름을 제어하기 위한 수단으로 네트워크 정책을 제공합니다. 네트워크 정책은 IP 주소, 포트 및 프로토콜과 같은 다양한 매개변수를 기반으로 어떤 팟이 서로 통신할 수 있는지를 지정하는 규칙을 정의합니다. 네트워크 정책을 시행함으로써, 애플리케이션의 네트워크 트래픽을 세분화하고 추가적인 보안 층을 추가할 수 있습니다.\n\n# 외부 통신\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKubernetes 클러스터 바깥의 리소스와 통신해야 하는 팟이 자주 있습니다. 외부 서비스나 데이터베이스와 통신하는 방법을 용이하게 해주는 여러 메커니즘이 Kubernetes에서 제공됩니다. 한 가지 접근법은 서비스 유형이 \"LoadBalancer\" 또는 \"NodePort\"인 서비스를 사용하여 팟 또는 팟 세트를 노출하는 것으로, 외부 클라이언트가 팟에 액세스할 수 있게 합니다. 또 다른 옵션은 Ingress 컨트롤러를 사용하는 것인데, 이를 통해 외부 클러스터로부터 들어오는 트래픽을 정의된 규칙에 따라 적절한 팟으로 라우팅할 수 있습니다.\n\n# 서비스 메쉬\n\n고급 네트워킹 시나리오를 위해, 서비스 메쉬를 사용하여 팟 간 통신을 강화할 수 있습니다. Istio나 Linkerd와 같은 서비스 메쉬는 Kubernetes 클러스터 상단에 있는 레이어로써 트래픽 관리, 관찰가능성, 보안과 같은 기능을 제공합니다. 서비스 메쉬를 사용하면 고급 라우팅 규칙, 회로 차단, 분산 추적을 통해 팟 간 통신을 제어하고 모니터링할 수 있습니다.\n\n# 예시\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKubernetes에서 pod 간 통신을 구성하는 방법을 보여드리기 위해 예제 사양을 살펴보겠습니다. 이 예제에서는 서비스를 사용하여 두 개의 파드를 생성하고 그들 간의 통신을 수립할 것입니다.\n\n- Pod A 생성: 먼저 간단한 웹 애플리케이션을 실행하는 Pod A를 생성해 보겠습니다. pod-a.yaml이라는 파일을 만들고 아래 내용을 추가하세요:\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-a\nspec:\n  containers:\n    - name: web-app\n      image: your-web-app-image\n      ports:\n        - containerPort: 8080\n```\n\n\"your-web-app-image\"를 사용 중인 웹 애플리케이션의 적절한 이미지로 교체해 주세요. 이 사양은 지정된 포트 8080이 노출된 상태로 \"pod-a\"라는 이름의 파드를 생성합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. Pod B를 생성하세요: 이제 Pod A와 통신하는 클라이언트 Pod인 Pod B를 생성해 봅시다. pod-b.yaml이라는 파일을 만들고 다음 내용을 추가해 주세요:\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-b\nspec:\n  containers:\n    - name: client-app\n      image: your-client-app-image\n      command: [\"sleep\", \"infinity\"]\n```\n\nyour-client-app-image를 사용하고 있는 클라이언트 어플리케이션에 해당하는 이미지로 변경해 주세요. 이 명세는 \"pod-b\"라는 이름의 pod를 생성하고, 해당 컨테이너를 실행하여 pod를 계속 실행 상태로 유지할 수 있는 무한 sleep 명령을 실행합니다.\n\n3. 서비스 생성하기: Pod A와 Pod B 간의 통신을 가능하게 하기 위해 안전한 엔드포인트로 작동하는 서비스를 생성할 것입니다. service.yaml이라는 파일을 만들고 다음 내용을 추가하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: pod-service\nspec:\n  selector:\n    app: web-app\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8080\n```\n\n이 구성은 \"pod-service\"라는 서비스를 생성하며, 이 서비스는 app: web-app 라벨을 가진 파드를 대상으로합니다 (우리가 Pod A에 추가 할 것입니다). 이 서비스는 포트 80을 노출하고 선택한 파드의 포트 8080으로 트래픽을 전달합니다.\n\n4. 설정 적용: 다음 명령을 사용하여 생성된 구성을 적용하십시오:\n\n```yaml\nkubectl apply -f pod-a.yaml\nkubectl apply -f pod-b.yaml\nkubectl apply -f service.yaml\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 쿠버네티스 클러스터에 Pod A, Pod B 및 서비스가 생성됩니다.\n\n5. 통신 테스트: 통신을 테스트하려면 Pod B에 접속하여 서비스의 DNS 이름을 사용하여 Pod A에 요청을 보낼 수 있습니다. 다음 명령어를 실행하세요:\n\n```sh\nkubectl exec -it pod-b -- sh\n```\n\nPod B 쉘에 들어간 후에 curl과 같은 도구를 사용하여 Pod A에 요청을 보낼 수 있습니다. 서비스 명세서에서 다른 이름을 사용했다면 실제 서비스 이름으로 pod-service를 대체하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ncurl pod-service\n```\n\n이 명령은 서비스로 요청을 보내어 트래픽을 로드 밸런싱하고 Pod A로 전달합니다.\n\n여기까지입니다! 이제 쿠버네티스에서 서비스를 사용하여 pod 간 통신을 설정했습니다. 다양한 통신 패턴을 탐색하거나 네트워크 정책을 적용하거나 특정 요구 사항을 충족시키기 위해 추가적인 쿠버네티스 기능을 활용하여 이 예시를 확장할 수 있습니다.\n\n# 결론\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마크다운 형식으로 테이블 태그를 변경하세요.\n","ogImage":{"url":"/assets/img/2024-06-23-MasteringKubernetesPod-to-PodCommunicationAComprehensiveGuide_0.png"},"coverImage":"/assets/img/2024-06-23-MasteringKubernetesPod-to-PodCommunicationAComprehensiveGuide_0.png","tag":["Tech"],"readingTime":8},{"title":"마이크로서비스 아키텍처 모두가 알아야 할 필수 개념과 방법","description":"","date":"2024-06-23 22:48","slug":"2024-06-23-MicroservicesArchitectureAllYouNeedtoknow","content":"\n<img src=\"/assets/img/2024-06-23-MicroservicesArchitectureAllYouNeedtoknow_0.png\" />\n\n단일 버그가 전체 시스템을 충돌시킬 수 있는 단일체 응용 프로그램을 업데이트하는 악몽에 직면해 본 적이 있나요? 여러분, 응용 프로그램을 보다 견고하고 확장 가능하며 유지보수하기 쉽게 만들 수있는 방법이 있다는 것을 말해 드릴까요? 마이크로서비스의 세계로 환영합니다.\n\n컬러풀한 비유로 들어가 봅시다.\n\n니가 소개해 준 마이크로서비스는 대형 응용 프로그램의 느슨하게 결합된 작은 응용 프로그램들입니다. 각 마이크로서비스는 단일 기능 또는 프로세스에 책임을지어야 합니다. 코드 또는 데이터를 공유하면 안되며, 데이터 또는 코드를 공유하다가 데이터베이스가 다운되면 각 서비스/시스템 전체가 실패할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마이크로서비스의 경우 독립성과 자율성이 코드 재사용보다 더 중요합니다. 이들은 서로 직접 통신할 수 없지만 이벤트/메시지 버스를 활용하여 서로 통신합니다.\n\n## 전형적인 마이크로서비스 아키텍처\n\n![이미지](/assets/img/2024-06-23-MicroservicesArchitectureAllYouNeedtoknow_1.png)\n\n전형적인 마이크로서비스 아키텍처는 다음 구성 요소 또는 빌딩 블록으로 구성됩니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 클라이언트\n\n클라이언트는 웹 애플리케이션, 모바일 애플리케이션 또는 챗봇과 같은 다양한 인터페이스를 통해 시스템과 상호 작용하는 최종 사용자들을 말합니다. 이러한 인터페이스를 통해 사용자들은 마이크로서비스 아키텍처에서 제공되는 서비스에 액세스할 수 있습니다.\n\n## 컨테이너 호스트\n\n마이크로서비스는 일반적으로 애플리케이션을 실행하는 가벼운, 휴대 가능하고 일관된 환경인 컨테이너에 배포됩니다. Docker와 Kubernetes는 이러한 컨테이너를 관리하기 위한 인기 있는 선택지입니다. Docker는 컨테이너화를 제공하고, Kubernetes는 이러한 컨테이너를 조정하고 관리하여 효율적이고 신뢰성 있게 실행되도록 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 데이터베이스\n\n마이크로서비스 아키텍처에서 각 서비스는 자체 데이터베이스를 가질 수 있습니다. 이를 통해 각 서비스에 가장 적합한 데이터베이스 유형을 선택할 수 있습니다. 예를 들어 한 서비스가 PostgreSQL과 같은 관계형 데이터베이스를 사용할 수 있고, 다른 서비스는 MongoDB와 같은 NoSQL 데이터베이스를 사용할 수 있습니다. 이러한 분리는 서비스가 느슨하게 결합되어 독립적으로 확장될 수 있음을 보장합니다.\n\n## API 게이트웨이\n\nAPI 게이트웨이는 클라이언트와 마이크로서비스 간의 통신을 HTTP를 통해 할 수 있도록 중개자 역할을 합니다. 클라이언트가 각 마이크로서비스를 직접 호출하는 대신 API 게이트웨이에 요청을 보냅니다. API 게이트웨이는 이후 이러한 HTTP 요청을 적절한 마이크로서비스로 라우팅합니다. 이는 클라이언트 측 로직을 단순화시키는데 그치지 않고 인증, 로깅, 속도 제한, 부하 분산 등과 같은 다양한 관심사를 위한 단일 진입점을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 인증 서비스\n\n인증 서비스는 마이크로서비스에 대한 클라이언트 액세스를 보호하는 데 매우 중요합니다. 이는 클라이언트 애플리케이션을 인증하고 인증 토큰(일반적으로 JWT)을 제공합니다. 이 토큰은 각 HTTP 요청에 포함되어야 하며 마이크로서비스에 안전하게 액세스할 수 있도록 합니다.\n\n## 작동 방식\n\n- 토큰 요청: 클라이언트 애플리케이션은 먼저 인증 서비스에 HTTP 요청을 보내어 액세스 토큰을 획득합니다. 이 요청에는 일반적으로 클라이언트의 자격 증명(예: 사용자 이름과 비밀번호)이 포함됩니다.\n- 액세스 토큰: 성공적으로 인증된 경우, 인증 서비스는 클라이언트에게 액세스 토큰(JWT)을 발급합니다.\n- 마이크로서비스 액세스: 클라이언트는 이 액세스 토큰을 API 게이트웨이의 후속 HTTP 요청 헤더에 포함시킵니다. API 게이트웨이는 요청을 원하는 마이크로서비스로 라우팅하기 전에 토큰을 유효성 검사합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 토큰 만료 :\n\n액세스 토큰은 일반적으로 구성 가능한 시간 동안만 유효합니다. 예를 들어 토큰이 5분 동안 유효하다면, 클라이언트는 토큰이 만료되기 전에 여러 요청을 만들 수 있어 매 호출마다 새 토큰 요청을 할 필요가 없어집니다. 따라서 액세스 빈도와 만료 시간 사이에 균형을 유지하는 것이 중요합니다. 만료 시간이 짧을수록 요청이 더 안전해집니다.\n\n## 이벤트 버스\n\n이벤트 버스는 비동기, 이벤트 기반 메시징을 통해 마이크로서비스간의 통신을 용이하게합니다. 마이크로서비스가 강하게 결합되지 않으면서 상호 작용할 수 있도록 보장하는 데 중요한 역할을 하며, 전반적인 확장성과 유연성을 향상시킵니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 작동 방식\n\n- 이벤트 생성 : 마이크로서비스들은 이벤트 생성기능을 통해 이벤트를 생성하거나 발행합니다. 이러한 이벤트는 새로운 사용자 생성, 거래 완료, 재고 수준 변화 등 다양한 상태 변경 또는 동작을 나타낼 수 있습니다.\n- 이벤트 소비 : 다른 마이크로서비스들은 이벤트 버스에 구독하고 특정 이벤트를 감지합니다. 관심 있는 이벤트가 발행되면, 해당하는 구독 중인 마이크로서비스는 해당 이벤트를 처리하고 소비합니다.\n- 겹합되지 않은 통신 : 발행 마이크로서비스는 이벤트를 소비하는 마이크로서비스를 알 필요가 없습니다. 마찬가지로 소비하는 마이크로서비스들은 이벤트의 출처를 알 필요가 없습니다. 이러한 겹합 없는 통신은 마이크로서비스들이 서로 영향을 미치지 않고 독립적으로 발전할 수 있도록 보장합니다.\n\n# 안티 패턴 (신화)\n\n안티 패턴은 일반적으로 반복되는 문제에 대한 해결책으로 매우 비생산적이거나 생산성이 낮은 것입니다. 이러한 것들을 고려해서는 안됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 모든 것들은 **database를 제외하고 작아져야 합니다**: 하나의 database만 있다면, 그것은 잠재적인 단일 장애점이 될 수 있습니다. 모든 Microservices가 동일한 단일 database에 결합되어 있으면 개별적으로 실패할 수 없습니다.\n- Microservices가 마법처럼 나쁜 개발 관행을 해결해 주지는 않습니다\\*\\*: 오래된 아키텍처에서 나쁜 개발이나 배포 습관이 Microservices 아키텍처로 전이된다면, 더 큰 해를 불러올 수 있습니다. 아키텍처 선택과 관계없이 코딩 및 배포 최상의 관행은 항상 최우선 과제여야 합니다.\n- Microservices는 단일 시스템 기능 또는 프로세스를 해결하는 데 중점을 두기 때문에 개발 팀 간의 조정이 필요하지 않습니다\\*\\*: 신 개념이므로 항상 팀간의 조정이 필요합니다. 소프트웨어 아키텍트가 모든 팀에서 동일한 높은 기준과 최상의 관행에 따라 Microservices를 설계하는 것이 좋습니다.\n- Microservices 기술을 핵심에 두면 안 됩니다\\*\\*: Microservices는 도구와 기술 선택의 유연성을 제공하지만, 주요 초점이 되어서는 안 됩니다. 주요 초점은 시스템 기능을 Microservices로 어떻게 분해할지 및 각 Microservice의 목적을 정의하는 데 있어야 합니다.\n\n# Microservices의 이점은 무엇인가요?\n\n- 복잡성 감소: 각 Microservice당 더 작은 코드베이스로 복잡성이 줄어듭니다.\n- 모듈성 향상: 시스템을 이해, 개발 및 테스트하기 쉽게 만들어 모듈성을 향상시킵니다.\n- 확장성: 높은 확장성을 갖는 아키텍처를 만듭니다.\n- 분할 정복: 분할 정복 원칙을 적용하여 대규모 및 복잡한 애플리케이션의 지속적인 전달 및 개발을 가능하게 합니다.\n- 독립적 배포: 서비스는 독립적으로 배포될 수 있습니다.\n\n# 왜 Microservices는 RESTful API로 개발되었나요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마이크로서비스는 종종 작은 RESTful API로 개발됩니다. RESTful API는 Representational State Transfer로 알려진 아키텍처 스타일을 기반으로 하는 웹 API 또는 서비스입니다. 클라이언트 응용 프로그램이 RESTful API와 HTTP를 통해 통신하는 방법을 정의합니다. 그렇다면 왜 RESTful API가 마이크로서비스에 적합한 것일까요? 주요 이유를 알아봅시다:\n\n- 간결함: CRUD에 기반한 HTTP 동사이므로 이해하기 쉽습니다.\n- 상태 없음: REST는 상태를 유지하지 않도록 설계되어 있으며 클라이언트와 서버의 역할을 분리합니다. 이는 서버가 클라이언트의 상태를 알 필요가 없거나 클라이언트가 서버의 상태를 걱정할 필요가 없음을 의미합니다.\n- 성능 및 확장성: REST 읽기는 성능과 확장성을 위해 캐싱될 수 있습니다.\n- 데이터 형식 유연성: REST는 많은 데이터 형식을 지원하지만 JSON의 주요 사용은 브라우저 클라이언트에서 더 나은 지원을 가능하게 합니다.\n\n# 직접적인 클라이언트 액세스의 문제 및 API 게이트웨이 사용의 이유\n\n- 직접적인 클라이언트 액세스는 많은 마이크로서비스 엔드포인트를 추적해야 하는 경우 클라이언트 통합의 복잡성을 증가시킵니다.\n- 이 경우 클라이언트는 자체적으로 로드 밸런싱 및 장애 감지를 구현해야 합니다.\n- 클라이언트가 여러 서비스에 공개적으로 액세스하려면 이러한 서비스들이 각자의 보안 문제를 다루어야 하며 SSL 종료 및 인증을 포함합니다.\n- API 게이트웨이는 클라이언트 애플리케이션이 마이크로서비스에 액세스하는 데 사용할 수 있는 통합된 진입점을 생성합니다.\n- 이는 클라이언트 요청을 원하는 백엔드 마이크로서비스로 라우팅하는 리버스 프록시 역할을 합니다.\n- API 게이트웨이는 클라이언트 인증, 로드 밸런싱 및 SSL 종료와 같은 중요한 기능을 수행할 수도 있습니다.\n- API 게이트웨이는 지정된 게이트웨이 경로에 허용되는 HTTP 동사의 유형을 제한할 수도 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 추가 읽을거리\n\n- 완전한 고수준 시스템 디자인 재생 목록\n\n---\n\nPS: 안녕하세요! 저는 Ankit Agarwal이라고 합니다. 소프트웨어 공학에 대한 열정을 가진 시니어 소프트웨어 엔지니어입니다.\n이 기사가 도움이 되셨나요? 멋집니다! 언제든지 제가 가진 소프트웨어 엔지니어링에 대한 지식과 열정을 공유하는 것을 기쁘게 생각합니다. 더 배우고 싶거나 연결하고 싶다면 LinkedIn에서 저를 찾아주십시오 @ https://www.linkedin.com/in/ankit-agarwal-87331a17b/\n","ogImage":{"url":"/assets/img/2024-06-23-MicroservicesArchitectureAllYouNeedtoknow_0.png"},"coverImage":"/assets/img/2024-06-23-MicroservicesArchitectureAllYouNeedtoknow_0.png","tag":["Tech"],"readingTime":8},{"title":"Keycloak 및 PostgreSQL을 Docker Compose로 배포하는 방법","description":"","date":"2024-06-23 22:47","slug":"2024-06-23-DockerComposeDeploymentsforKeycloakandPostgreSQL","content":"\n# 키클로크란 무엇인가요?\n\n![이미지](/assets/img/2024-06-23-DockerComposeDeploymentsforKeycloakandPostgreSQL_0.png)\n\n## 중앙 집중식 사용자 관리\n\n키클로크를 사용하면 사용자 관리를 한곳에서 중앙 집중화할 수 있어 여러 애플리케이션과 서비스 간에 사용자, 역할 및 권한을 쉽게 관리할 수 있습니다. 사용자 페더레이션을 지원하여 기존 사용자 디렉터리(예: LDAP 또는 Active Directory)와 통합할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단일 로그인(SSO) 및 단일 로그아웃\n\nKeycloak의 가장 중요한 기능 중 하나는 단일 로그인(SSO)을 지원한다는 점입니다. SSO를 통해 사용자는 한 번 로그인하면 각각의 애플리케이션에서 다시 로그인해야 할 필요 없이 여러 애플리케이션에 접근할 수 있습니다. 비슷하게, 단일 로그아웃 기능을 사용하면 사용자는 모든 애플리케이션에서 동시에 로그아웃할 수 있습니다.\n\n## 소셜 로그인\n\nKeycloak은 소셜 로그인 기능을 지원하며, 사용자들이 Google, Facebook, Twitter 등의 소셜 미디어 계정을 사용하여 로그인할 수 있습니다. 이 기능은 등록 및 로그인 절차를 간소화하여 사용자 경험을 향상시킵니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 다중 인증 (MFA)\n\n보안을 강화하기 위해 Keycloak은 다중 인증(MFA)을 지원합니다. 이는 사용자가 응용 프로그램에 액세스하려면 두 개 이상의 인증 요소를 제공해야 하도록하여 추가 보안 계층을 추가합니다.\n\n## OpenID Connect (OIDC) 및 SAML\n\nKeycloak은 OpenID Connect (OIDC) 및 SAML 2.0과 같은 현대 프로토콜을 구현하여 인증 및 승인을 처리하여 다양한 응용 프로그램과 호환성이 있고 다재다능합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 사용자화 가능한 테마\n\nKeycloak에서 제공하는 로그인 페이지의 외관과 느낌은 귀하의 브랜딩 요구 사항에 따라 사용자화할 수 있습니다. Keycloak은 테마 사용자화를 허용하여 로그인, 등록 및 계정 관리 페이지의 외관을 변경할 수 있습니다.\n\n## 관리 콘솔\n\nKeycloak은 렘(Realms), 사용자, 역할 및 권한을 관리하기 위한 쉽게 사용할 수 있는 웹 기반 관리 콘솔이 제공됩니다. Keycloak에서 렘은 사용자, 자격 증명, 역할 및 그룹을 관리하는 공간입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 보안\n\nKeycloak은 SSL/TLS, 비밀번호 정책, 브루트 포스 탐지 등을 포함한 견고한 보안 기능을 기본 제공합니다. 또한 사용자 자격 증명을 안전하게 저장할 수 있습니다.\n\n## API 액세스 관리\n\nKeycloak을 사용하면 토큰(JWT 토큰 또는 SAML 어설션)을 사용하여 애플리케이션 API를 안전하게 보호할 수 있습니다. 보호해야 하는 리소스 및 해당 리소스에 액세스 할 수 있는 역할 또는 클라이언트를 쉽게 정의할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 확장성 및 고가용성\n\nKeycloak은 확장 가능하게 설계되어 있으며 고가용성 구성으로 배포할 수 있어 사용자와 애플리케이션에 항상 인증 서비스를 제공할 수 있습니다.\n\n# 도커로 설정하기\n\ndocker-compose.yml 파일\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\nversion: \"3.7\"\n\nservices:\n  postgres:\n    image: postgres:16.2\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_DB: ${POSTGRES_DB}\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n    networks:\n      - keycloak_network\n\n  keycloak:\n    image: quay.io/keycloak/keycloak:23.0.6\n    command: start\n    environment:\n      KC_HOSTNAME: localhost\n      KC_HOSTNAME_PORT: 8080\n      KC_HOSTNAME_STRICT_BACKCHANNEL: false\n      KC_HTTP_ENABLED: true\n      KC_HOSTNAME_STRICT_HTTPS: false\n      KC_HEALTH_ENABLED: true\n      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN}\n      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD}\n      KC_DB: postgres\n      KC_DB_URL: jdbc:postgresql://postgres/${POSTGRES_DB}\n      KC_DB_USERNAME: ${POSTGRES_USER}\n      KC_DB_PASSWORD: ${POSTGRES_PASSWORD}\n    ports:\n      - 8080:8080\n    restart: always\n    depends_on:\n      - postgres\n    networks:\n      - keycloak_network\n\nvolumes:\n  postgres_data:\n    driver: local\n\nnetworks:\n  keycloak_network:\n    driver: bridge\n```\n\n.env file\n\n```yaml\nPOSTGRES_DB=keycloak_db\nPOSTGRES_USER=keycloak_db_user\nPOSTGRES_PASSWORD=keycloak_db_user_password\nKEYCLOAK_ADMIN=admin\nKEYCLOAK_ADMIN_PASSWORD=password\n```\n\n# Services\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nPostgreSQL Service (postgres):\n\n- **이미지**: PostgreSQL 서버를 실행하기 위해 Docker 이미지 postgres:16.2를 사용합니다.\n- **볼륨**: 데이터베이스 데이터의 지속적인 저장을 위해 컨테이너 내부의 /var/lib/postgresql/data에 대한 postgres_data라는 볼륨을 매핑합니다.\n- **환경 변수**: 환경 변수로 지정된 이름(POSTGRES_DB), 사용자(POSTGRES_USER), 비밀번호(POSTGRES_PASSWORD)로 데이터베이스를 구성합니다.\n- **네트워크**: Keycloak 서비스와의 통신을 위해 keycloak_network라는 사용자 정의 네트워크에 연결합니다.\n\nKeycloak Service (keycloak):\n\n- **이미지**: Keycloak 서버를 실행하기 위해 quay.io/keycloak/keycloak:23.0.6을 활용합니다.\n- **명령어**: Keycloak을 실행하기 위해 start를 지정합니다.\n- **환경 변수**: 호스트명(KC_HOSTNAME), 포트(KC_HOSTNAME_PORT), HTTP 구성(KC_HTTP_ENABLED, KC_HOSTNAME_STRICT_HTTPS), 헬스 체크(KC_HEALTH_ENABLED), 관리자 자격 증명(KEYCLOAK_ADMIN, KEYCLOAK_ADMIN_PASSWORD), 데이터베이스 연결 세부 정보(KC_DB, KC_DB_URL, KC_DB_USERNAME, KC_DB_PASSWORD) 등 다양한 설정을 구성합니다.\n- **포트**: 호스트의 포트 8080을 웹 접근을 위해 Keycloak 컨테이너의 포트 8080에 매핑하여 노출합니다.\n- **재시작 정책**: 수동으로 중지할 때까지 항상 다시 시작되도록 구성합니다.\n- **의존성**: Postgres 서비스에 종속성을 선언하여 먼저 시작되도록 합니다.\n- **네트워크**: keycloak_network에도 연결됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 볼륨\n\n- postgres_data: 기본 로컬 스토리지 드라이버를 사용하여 컨테이너를 다시 시작할 때도 지속적으로 PostgreSQL 데이터를 저장하는 명명된 볼륨입니다.\n\n# 네트워크\n\n- keycloak_network: 브릿지 드라이버를 사용하는 사용자 정의 네트워크로, Keycloak과 PostgreSQL 컨테이너 간의 통신을 원활하게 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 환경 변수\n\n데이터베이스 구성 (POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD) 및 Keycloak 관리자 자격 증명 (KEYCLOAK_ADMIN, KEYCLOAK_ADMIN_PASSWORD)의 값을 지정하는 변수입니다. 서비스가 안전하게 통신하고 작동하는 데 필수적입니다.\n\n# 요약\n\n이 Docker Compose 파일은 인증 시스템을 제공하는 Keycloak와 PostgreSQL을 설정합니다. 데이터 저장을 위한 인증 시스템을 제공합니다. 액세스를 위한 환경 변수 및 서비스 구성을 지정하며 서비스 간 통신을 위한 사용자 지정 네트워크가 포함되어 있습니다. 개발에 이상적이며 응용 프로그램 인증 관리를 위한 기반을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 소스 코드\n\n전체 코드 및 더 많은 예제는 GitHub 저장소를 확인하세요: ForgeContainer\n","ogImage":{"url":"/assets/img/2024-06-23-DockerComposeDeploymentsforKeycloakandPostgreSQL_0.png"},"coverImage":"/assets/img/2024-06-23-DockerComposeDeploymentsforKeycloakandPostgreSQL_0.png","tag":["Tech"],"readingTime":8},{"title":"FastAPI와 MongoDB 소개 첫 걸음부터 시작하기","description":"","date":"2024-06-23 22:46","slug":"2024-06-23-IntrotoFastAPIandMongoDB","content":"\n이 튜토리얼에서는 FastAPI에 의존하는 간단한 파이썬 애플리케이션을 구축하는 방법을 배울 수 있습니다. 이 애플리케이션은 MongoDB로 요청을 보내는 기능을 갖추고 있습니다.\n\n프로그램이 모든 장치에서 실행될 수 있도록 하기 위해, 이 튜토리얼은 보편적인 접근 방식을 취하며 Docker Compose를 사용하여 코드를 실행합니다.\n\n또한 보안과 확장성에 대한 내용에 대해서는 이 PoC에서는 중점을 두지 않았음을 알려드립니다. 해당 정보에 대해서는 FastAPI 보안 문서를 확인하는 것이 좋습니다.\n\n## 사전 요구 사항\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n친구야, 기기에 다음 소프트웨어가 있는지 확인해주세요.\n\n- Git\n- Docker Desktop\n- Python\n- MongoDB Compass 또는 Mongosh\n\n## PoC 실행 방법\n\n저장소를 복제(clone)하기 전에, 모든 선행 요구 사항이 충족되었는지 확인하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ngit clone https://github.com/raduul/FastMongo.git\n```\n\nDocker Desktop을 켜고, 데이터가 유지될 볼륨을 구성하세요.\n\n```js\nDocker Desktop > Settings > Resources > File Sharing > 원하는 위치 선택\n```\n\n애플리케이션을 실행한 후, 복제한 저장소로 이동해서 다음 명령어를 실행하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndocker compose -f deployment/docker-compose-fastapi.yaml up --build\n```\n\n로컬에서 실행 중인 MongoDB에 샘플 데이터를 보내려면 Swagger UI(localhost:8000/docs)에 액세스하십시오.\n\n‘send_data’를 열어서 “Try it out”을 선택한 후 “Execute”를 선택하여 데이터를 데이터베이스로 보내세요.\n\n<img src=\"/assets/img/2024-06-23-IntrotoFastAPIandMongoDB_0.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이후에는 \"실행\" 버튼 아래에 요청 상태가 표시됩니다. 상태 코드 200은 데이터가 성공적으로 추가되었음을 나타냅니다!\n\n![이미지](/assets/img/2024-06-23-IntrotoFastAPIandMongoDB_1.png)\n\n데이터가 성공적으로 추가되면 MongoDB Compass로 이동하여 추가된 데이터가 있는 데이터베이스 및 컬렉션에 액세스하십시오.\n연결 문자열은 다음과 같습니다:\n\n```js\nmongodb://root:example@localhost:27017/fast-api?authSource=admin\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-IntrotoFastAPIandMongoDB_2.png\" />\n\n이제 데이터를 MongoDB에 성공적으로 보냈습니다. 코드를 실험하고 MongoDB 데이터베이스에 추가 경로와 컬렉션을 생성해보세요. 축하합니다 🥳🎊\n\n## 코드 소개\n\n이 애플리케이션을 실행하는 데 필요한 코드는 매우 간단합니다! 세 개의 그룹으로 구성되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- FastAPI — 데이터를 전송하는 API Endpoint를 구축하는 데 사용됩니다.\n- MongoDB — FastAPI에서 전송된 데이터를 저장하는 데 사용됩니다.\n- Docker Compose — FastAPI 및 MongoDB의 컨테이너화된 이미지를 실행하는 데 사용됩니다.\n\n## FastAPI\n\n이 코드는 여러 개의 파이썬 파일로 구성되어 있지만, 가장 중요한 두 개는 다음과 같습니다:\n\n- 먼저 MongoDB 데이터베이스에 연결이 설정됩니다: (database.py)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport logging\nfrom motor.motor_asyncio import AsyncIOMotorClient\nimport os\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\nclient: AsyncIOMotorClient = None\n\ndef startup_db_client():\n    global client\n    try:\n        mongo_uri = os.getenv('MONGO_URL')\n        client = AsyncIOMotorClient(mongo_uri)\n        logging.info(\"Connected to MongoDB successfully.\")\n    except Exception as e:\n        logging.error(f\"Failed to connect to MongoDB: {e}\")\n    return client['fast-api']\n\ndef shutdown_db_client():\n    client.close()\n    logging.info(\"MongoDB connection closed.\")\n\ndef get_database():\n    return startup_db_client()\n```\n\n둘째로, 연결이 설정되면 데이터를 보낼 때 유추합니다 (main.py)\n\n```js\nfrom fastapi import FastAPI, Depends\nfrom database import startup_db_client, shutdown_db_client, get_database\n\napp = FastAPI()\n\napp.add_event_handler(\"startup\", startup_db_client)\napp.add_event_handler(\"shutdown\", shutdown_db_client)\n\n@app.post(\"/send_data\")\nasync def insert_sample_data(sample_data: dict, db=Depends(get_database)):\n    try:\n        collection = db['sample-users']\n        result = await collection.insert_one(sample_data)\n        return {\"id of inserted record\": str(result.inserted_id)}\n    except Exception as e:\n        return {\"error\": str(e)}\n```\n\n## MongoDB\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMongoDB 구성은 PoC를 이해하기 쉽게 만들기 위해 간단하게 유지되었습니다. 따라서 구성은 순전히 기본 설정입니다. MongoDB의 두 가지 주요 파일은 \"deployment/docker-compose-fastapi.yaml\" 및 \"deployment/init-mongo.js\"입니다.\n\n- docker-compose-fastapi.yaml — MongoDB를 위한 기본 배포 구성이 포함되어 있습니다.\n- deployment/init-mongo.js — Docker Compose에 의해 MongoDB가 배포될 때 PoC를 위해 생성될 스키마에 대한 정보가 포함되어 있습니다.\n\n## Docker Compose\n\nDocker Compose은 이 PoC에서 사용되는 이미지 중 두 개를 실행하는 데 사용됩니다. 구성은 \"deployment/docker-compose-fastapi.yaml\"에서 찾을 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- fastapi 서비스는 루트에 위치한 Dockerfile을 참조하며 FastAPI 앱을 빌드하고 빌드된 후에 실행하는 방법에 대한 구성을 포함합니다.\n- mongo 서비스는 MongoDB 이미지를 참조합니다. \"docker compose down\" 후에도 데이터가 유지되도록 보장하기 위해 볼륨이 생성되어 데이터를 보관합니다. 사용 중인 특정 이미지는 OS/ARCH Amd64 및 Arm64와 호환됩니다.\n\nLinkedIn에서 언제든지 연락 주세요.\n","ogImage":{"url":"/assets/img/2024-06-23-IntrotoFastAPIandMongoDB_0.png"},"coverImage":"/assets/img/2024-06-23-IntrotoFastAPIandMongoDB_0.png","tag":["Tech"],"readingTime":7},{"title":"CDS JAR vs Uber JAR 도커화 및 비교 20 빠른 시작 시간 달성하는 방법","description":"","date":"2024-06-23 22:45","slug":"2024-06-23-DockerizingandComparingCDSJARvsUberJARAchieving20FasterStartupTimes","content":"\n## JAVA | JVM | CDS | DOCKER\n\n![Dockerizing and Comparing CDS JAR vs Uber JAR Achieving 20% Faster Startup Times](/assets/img/2024-06-23-DockerizingandComparingCDSJARvsUberJARAchieving20FasterStartupTimes_0.png)\n\n이 기사에서는 Java Spring Boot 애플리케이션 greetings-app을 Uber JAR 및 CDS JAR을 사용하여 두 가지 방법으로 도커화할 것입니다. 나중에 이들의 시작 시간을 비교할 것입니다.\n\n아래 연결된 기사에서 greetings-app의 전체 코드 및 구현을 찾을 수 있습니다. 기사에서 설명된 단계를 따라 진행하고 시작하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러면 시작해봅시다!\n\n## 준비물\n\n이 튜토리얼을 따라하려면 컴퓨터에 Java 17+와 Docker가 설치되어 있어야 합니다.\n\n## Docker 이미지 빌드하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Uber JAR을 사용하여 도커 이미지 생성하기\n\n인사 앱 루트 폴더에서 Dockerfile-Uber-JAR라는 파일을 다음 내용으로 생성해 봅시다:\n\n```js\nFROM amazoncorretto:17.0.10\n\nCOPY target/greetings-app-0.0.1-SNAPSHOT.jar greetings-app.jar\n\nENTRYPOINT [\"java\", \"-jar\", \"greetings-app.jar\"]\n```\n\n다음으로, 터미널을 열고 인사 앱 루트 폴더 내에서 아래 명령어를 실행하여 greetings-app-uber-jar 도커 이미지를 생성해 봅시다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 이미지를 CDS JAR로 빌드하려면\n\ngreetings-app 루트 폴더에 Dockerfile-CDS-JAR이라는 파일을 다음 내용으로 생성해보세요:\n\nFROM amazoncorretto:17.0.10\n\nCOPY greetings-app-0.0.1-SNAPSHOT/greetings-app-0.0.1-SNAPSHOT.jar greetings-app.jar\nCOPY greetings-app-0.0.1-SNAPSHOT/lib/ lib/\n\nENTRYPOINT [\"java\", \"-jar\", \"greetings-app.jar\"]\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음으로, 터미널에서 greetings-app 루트 폴더 안으로 이동한 다음 아래 명령어를 실행하여 greetings-app-cds-jar 도커 이미지를 생성해 봅시다:\n\ndocker build -f Dockerfile-CDS-JAR -t greetings-app-cds-jar .\n\n## 도커 이미지 크기\n\n도커 이미지의 크기를 확인해 봅시다. 터미널에서 다음 명령어를 실행해 주세요:\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n도커 이미지 | grep greetings-app\n\n이렇게 나와야 해요:\n\ngreetings-app-cds-jar                                latest                   50613179d4fa   3 minutes ago   486MB\ngreetings-app-uber-jar                               latest                   67c71f76b553   3 minutes ago   486MB\n\n둘 다 크기가 486MB로 동일해요.\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 시작 및 중지 시간 5번\n\n## Uber JAR로 Docker 컨테이너 시작 및 중지\n\n터미널에서 다음 명령을 실행하여 애플리케이션의 Docker 컨테이너를 시작합니다. 중지하려면 Ctrl+C를 누르고, 이 프로세스를 다섯 번 반복하세요:\n\ndocker run --rm -m 1024M -p 8080:8080 --name greetings-app greetings-app-uber-jar\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 우리가 진행한 5회 실행의 결과입니다 (일부 로그 라인은 간략하게 생략되었습니다):\n\n➜  greetings-app docker run --rm -m 1024M -p 8080:8080 --name greetings-app greetings-app-uber-jar\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n\n :: Spring Boot ::                (v3.3.1)\n\n...\n2024-06-28 오후 06:52:23.982Z  INFO 1 --- [greetings-app] [           main] c.e.g.GreetingsAppApplication            : GreetingsAppApplication이 2.767초 안에 시작되었습니다 (프로세스 실행 시간 3.48초).\n2024-06-28 오후 06:52:23.988Z  INFO 1 --- [greetings-app] [           main] c.e.greetingsapp.MemoryUsageLogger       : 시작 시 메모리 풋프린트: 14MB\n^C%\n➜  greetings-app docker run --rm -m 1024M -p 8080:8080 --name greetings-app greetings-app-uber-jar\n\n...\n\n이를 반복하여 총 다섯 번 실행하시면 됩니다.\n\n## CDS JAR로 Docker 컨테이너 시작 및 정지\n\n터미널에서 다음 명령을 실행하여 애플리케이션의 Docker 컨테이너를 시작하세요. 중지하려면 Ctrl+C를 누르고, 이 작업을 총 다섯 번 반복하세요.\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 우리가 실시한 5회 실행 결과입니다 (간결함을 위해 일부 로그 라인이 생략되었습니다):\n\n➜  greetings-app docker run --rm -m 1024M -p 8080:8080 --name greetings-app greetings-app-cds-jar\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n\n :: Spring Boot ::                (v3.3.1)\n\n...\n2024-06-23T06:52:53.646Z  INFO 1 --- [greetings-app] [           main] c.e.g.GreetingsAppApplication            : Started GreetingsAppApplication in 2.285 seconds (process running for 2.673)\n2024-06-23T06:52:53.651Z  INFO 1 --- [greetings-app] [           main] c.e.greetingsapp.MemoryUsageLogger       : Memory footprint at startup: 15 MB\n^C%\n➜  greetings-app docker run --rm -m 1024M -p 8080:8080 --name greetings-app greetings-app-cds-jar\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n\n :: Spring Boot ::                (v3.3.1)\n\n...\n2024-06-23T06:52:58.858Z  INFO 1 --- [greetings-app] [           main] c.e.g.GreetingsAppApplication            : Started GreetingsAppApplication in 2.422 seconds (process running for 2.814)\n2024-06-23T06:52:58.864Z  INFO 1 --- [greetings-app] [           main] c.e.greetingsapp.MemoryUsageLogger       : Memory footprint at startup: 16 MB\n^C%\n➜  greetings-app docker run --rm -m 1024M -p 8080:8080 --name greetings-app greetings-app-cds-jar\n\n...\n\n# 비교결과\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 스타트업 시간\n\n아래 표는 위 실행에서 얻은 스타트업 시간과 평균을 보여줍니다:\n\n```\n\n| Docker Image | 스타트업 시간(초) | 평균 스타트업 시간(초) |\n| ------------ | ----------------- | ---------------------- |\n| uber-jar     | 2.767             |                        |\n| uber-jar     | 2.841             |                        |\n| uber-jar     | 2.864             |                        |\n| uber-jar     | 2.916             |                        |\n| uber-jar     | 2.860             | 2.849                  |\n| cds-jar      | 2.285             |                        |\n| cds-jar      | 2.422             |                        |\n| cds-jar      | 2.318             |                        |\n| cds-jar      | 2.335             |                        |\n| cds-jar      | 2.319             | 2.335                  |\n\n평균 표를 통해 CDS JAR가 있는 Docker 컨테이너의 스타트업 시간이 Uber JAR가 있는 것보다 약 18.03% 빠르다는 것을 알 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 성능\n\n성능을 분석하기 위해 API에 대한 부하 테스트를 실행하는 oha 도구를 사용할 것입니다. 도커 컨테이너를 시작하고 동시성이 2인 상태에서 10,000개의 요청을 제출할 것입니다.\n\n다음은 oha 명령어입니다:\n\n```js\noha -n 10000 -c 2 --latency-correction --disable-keepalive http://localhost:8080/greetings\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기 결과가 있어요:\n\n```js\nDocker Container with Uber JAR | Docker Container with CDS JAR\n------------------------------ | -----------------------------\nSummary:                       | Summary:\n  Success rate: 100.00%        |   Success rate: 100.00%\n  Total: 13.2974 secs          |   Total: 13.3007 secs\n  Slowest: 0.2332 secs         |   Slowest: 0.2062 secs\n  Fastest: 0.0012 secs         |   Fastest: 0.0012 secs\n  Average: 0.0027 secs         |   Average: 0.0027 secs\n  Requests/sec: 752.0248       |   Requests/sec: 751.8427\n  Total data: 117.19 KiB       |   Total data: 117.19 KiB\n  Size/request: 12 B           |   Size/request: 12 B\n  Size/sec: 8.81 KiB           |   Size/sec: 8.81 KiB\n```\n\nUber JAR를 사용한 Docker 컨테이너가 CDS JAR를 사용한 것보다 약간 더 나은 성능을 보였어요. Uber JAR를 이용한 컨테이너는 초당 752.02개의 요청을 처리하는 반면, CDS JAR를 이용한 컨테이너는 초당 751.84개의 요청을 처리했어요.\n\n## 메모리 사용량\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n메모리 사용량을 비교하기 위해 Google의 cAdvisor 도구를 사용했어요.\n\n다음은 결과입니다:\n\nUber JAR를 사용한 Docker 컨테이너\n\n![이미지](/assets/img/2024-06-23-DockerizingandComparingCDSJARvsUberJARAchieving20FasterStartupTimes_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위와 같이 볼 때, Uber JAR를 사용한 Docker 컨테이너는 시작할 때 140MB에 이르렀고 부하 테스트 중에 최대 182MB까지 증가했습니다.\n\nCDS JAR를 사용한 Docker 컨테이너\n\n![이미지](/assets/img/2024-06-23-DockerizingandComparingCDSJARvsUberJARAchieving20FasterStartupTimes_2.png)\n\nCDS JAR를 사용한 Docker 컨테이너는 시작할 때 127MB에 이르렀고 부하 테스트 중에 최대 174MB까지 증가했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사, 시작 시 메모리 사용량을 9.3% 절약했고 로드 테스트 중에는 4.4%를 절약했다고 결론지을 수 있습니다.\n\n# 정리\n\n이 기사에서 생성된 도커 이미지를 삭제하려면 다음 명령을 실행하세요:\n\n```js\ndocker rmi greetings-app-cds-jar:latest greetings-app-uber-jar:latest\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n이 글에서는 Java Spring Boot 애플리케이션 greetings-app을 Uber JAR 및 CDS JAR을 사용하여 두 가지 방법으로 Docker화했습니다. 그리고 이들 Docker 컨테이너를 다섯 번 실행 및 중지시키고 시작 시간을 기록했습니다. 결과는 CDS JAR이 적용된 Docker 컨테이너가 시작 시간을 약 20% 개선시켰다는 것을 보여주었습니다. 또한 성능을 확인했을 때, Uber JAR이 적용된 Docker 컨테이너가 CDS JAR 적용된 것보다 약간 더 우수했습니다. 마지막으로 메모리 사용량을 살펴보면, 시작 시에 CDS JAR이 적용된 Docker 컨테이너가 메모리 사용량을 9.3% 줄이고 부하 테스트 중에는 4.4% 줄였음을 확인할 수 있었습니다.\n\n# 지원과 참여\n\n만약 이 글을 즐겁게 읽으셨고 지원을 보여주고 싶다면, 아래의 조치를 고려해 주시기 바랍니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 👏 제 이야기에 박수를 치거나 강조하고 답글을 남겨주셔요. 궁금한 점이 있다면 언제든지 물어봐주세요.\n- 🌐 제 이야기를 소셜 미디어에 공유해주세요.\n- 🔔 Medium | LinkedIn | Twitter | GitHub에서 저를 팔로우해주세요.\n- ✉️ 제 뉴스레터를 구독하여 최신 포스트를 놓치지 마세요.\n","ogImage":{"url":"/assets/img/2024-06-23-DockerizingandComparingCDSJARvsUberJARAchieving20FasterStartupTimes_0.png"},"coverImage":"/assets/img/2024-06-23-DockerizingandComparingCDSJARvsUberJARAchieving20FasterStartupTimes_0.png","tag":["Tech"],"readingTime":13},{"title":"컨테이너화란 무엇이며 어떤 문제를 해결하나요","description":"","date":"2024-06-23 22:44","slug":"2024-06-23-WhatisContainerizationandwhatproblemdoesitsolve","content":"\n컨테이너화는 응용 프로그램 코드와 모든 필요한 파일 및 라이브러리를 패키지로 묶어서 모든 인프라에서 실행할 수 있도록 하는 소프트웨어 배포 방법입니다. 이는 응용 프로그램과 해당 종속성을 컨테이너라고 하는 단일 패키지로 캡슐화하는 경량 가상화 형태입니다.\n\n## 가상화란?\n\n가상화는 서버, 저장 장치 또는 네트워크와 같은 물리적 구성 요소의 가상 버전을 생성하여 단일 물리 시스템에서 여러 가상 시스템이 실행되도록 하는 프로세스입니다. 이는 효율적인 자원 활용 및 다른 작업 부하 사이의 격리를 가능하게 합니다.\n\n## 이미지란 무엇인가요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n컨테이너화(context of containerization)란 이미지(image)란 것이 경량(lighweight), 독립적(standalone), 실행 가능한(executable) 소프트웨어 패키지로, 코드, 런타임(runtime), 라이브러리(libraries), 환경 변수(environment variables), 설정 파일(configuration files)을 내장하고 있는 것을 의미합니다.\n\n## 왜 컨테이너화가 인기가 높을까요?\n\n컨테이너화는 다양한 컴퓨팅 환경에서 일관된 효율적인 애플리케이션 배포를 필요로 하여 중요해졌습니다. 전통적인 방법은 종속성 충돌과 환경별 버그에 직면하여 개발에서 운영 환경으로 이동할 때 응용프로그램이 신뢰할 수 있게 잘 실행될 것을 보장하기 어려웠습니다. 컨테이너화는 응용프로그램과 종속성을 격리된 이동 가능한 컨테이너에 캡슐화하여 이러한 문제를 해결하며, 어디서든 일관되게 실행될 수 있다는 장점을 제공합니다. 이를 통해 배포를 간소화하고 리소스 활용을 향상시키며 확장 가능하고 견고한 인프라를 구축하는데 도움이 됩니다. 이 기술은 현대 IT 관행에서 빠른 개발, 지속적 통합, 매끄러운 전달에 대한 요구를 해결합니다.\n\n주요 문제 해결:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-06-23-WhatisContainerizationandwhatproblemdoesitsolve_0.png)\n\n## 컨테이너화의 장점:\n\n- 독립성: 각 컨테이너는 독립된 환경에서 실행되어 필요한 모든 종속성 및 구성 파일을 보장합니다. 이 독립성은 응용 프로그램 및 환경 간의 충돌을 피하는 데 도움이 됩니다.\n\n- 일관성: 컨테이너를 통해 소프트웨어가 배포된 위치에 관계없이 동일하게 실행되도록 보장할 수 있습니다. 이 일관성은 컨테이너가 라이브러리, 이진 파일 및 기타 종속성과 같이 응용 프로그램에 필요한 모든 것을 포함하므로 달성됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n효율성: 전통적인 가상 머신(VM)과 달리, 컨테이너는 호스트 시스템의 운영 체제 커널을 공유하여 더 가볍고 효율적입니다. 이로써 단일 호스트에서 더 많은 응용 프로그램을 실행할 수 있습니다.\n\n이식성: 컨테이너는 개발자의 노트북에서 테스트 환경으로 그리고 본 프로덕션 환경으로 쉽게 이동할 수 있습니다. 이식성을 통해 배포 프로세스를 간소화하고 환경별 버그 위험을 줄일 수 있습니다.\n\n마이크로서비스 아키텍처: 컨테이너화는 응용 프로그램을 작은 독립적인 서비스로 분해하는 마이크로서비스 아키텍처를 가능하게 합니다. 각 서비스는 독립적으로 개발, 배포 및 확장할 수 있어 더 큰 유연성과 확장성을 제공합니다.\n\n아래 이미지는 컨테이너화된 응용 프로그램이 어떻게 작동하는지 가장 잘 설명합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-WhatisContainerizationandwhatproblemdoesitsolve_1.png\" />\n\n가장 널리 사용되고 보급된 컨테이너화 애플리케이션 솔루션에는 Docker와 Kubernetes가 포함됩니다.\n\n# Docker\n\n# 개요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 도커는 애플리케이션을 컨테이너로 자동화하여 배포, 확장 및 관리하는 플랫폼입니다. 컨테이너 이미지를 사용하여 컨테이너를 쉽게 만들어 줍니다. 컨테이너 이미지는 가볍고 독립적이며 실행 가능한 소프트웨어 패키지로, 소프트웨어를 실행하는 데 필요한 모든 것을 포함하고 있습니다.\n\n## 주요 기능:\n\n- 컨테이너 엔진: 도커 엔진은 도커 컨테이너를 생성, 실행 및 관리하는 핵심 구성 요소입니다.\n- 도커 허브: 도커 사용자 및 파트너가 컨테이너 이미지를 생성, 테스트, 저장 및 배포하는 클라우드 기반 레지스트리 서비스입니다.\n- 도커 컴포즈: 간단한 YAML 파일을 사용하여 애플리케이션 서비스를 구성하는 데 사용되는 다중 컨테이너 도커 애플리케이션을 정의하고 실행하는 도구입니다.\n- 도커 스웜: 도커 컨테이너를 위한 네이티브 클러스터링 및 스케줄링 도구로, 도커 노드의 클러스터를 단일 가상 시스템으로 조정하고 관리하는 방법을 제공합니다.\n\n# 쿠버네티스\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 개요:\n\n- Kubernetes는 컨테이너화된 응용 프로그램의 배포, 확장 및 운영을 자동화하기 위해 고안된 오픈 소스 컨테이너 오케스트레이션 플랫폼입니다. Google에서 최초로 개발되었으며 현재는 Cloud Native Computing Foundation (CNCF)에서 유지보수되고 있습니다.\n\n## 주요 기능:\n\n- 자동 롤아웃 및 롤백: Kubernetes는 응용 프로그램에 대한 변경 사항을 자동으로 배포하고 문제가 발생할 경우 롤백할 수 있습니다.\n- 서비스 검색 및 로드 밸런싱: Kubernetes는 DNS 이름이나 IP 주소를 사용하여 컨테이너를 노출하고 이를 로드 밸런싱할 수 있습니다.\n- 스토리지 오케스트레이션: Kubernetes는 로컬 스토리지, 공개 클라우드 제공업체 또는 네트워크 스토리지 시스템에서 선택한 스토리지 시스템을 자동으로 마운트합니다.\n- 자가 치유: Kubernetes는 실패한 컨테이너를 다시 시작하거나 교체하며, 사용자 정의 건강 확인에 응답하지 않는 컨테이너를 종료하고 이를 클라이언트에 제공 준비가 될 때까지 공개하지 않습니다.\n- 수평 스케일링: Kubernetes는 CPU 사용률 또는 기타 메트릭에 따라 응용 프로그램을 자동으로 확장하거나 축소할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDockerFile을 사용하여 애플리케이션 코드에서 이미지를 생성하는 다음 기사를 기대해주세요!\n","ogImage":{"url":"/assets/img/2024-06-23-WhatisContainerizationandwhatproblemdoesitsolve_0.png"},"coverImage":"/assets/img/2024-06-23-WhatisContainerizationandwhatproblemdoesitsolve_0.png","tag":["Tech"],"readingTime":5},{"title":"Auto Scaling 그룹으로 데이터 센터 장애 복구하는 방법","description":"","date":"2024-06-23 22:42","slug":"2024-06-23-RecoveringfromadatacenteroutagewithanAutoScalinggroup","content":"\n이전 글에서 논의한 시스템 상태 확인 및 클라우드워치를 사용하여 EC2 인스턴스를 복구하는 것은 가능합니다.\n\n하지만 만약 전체 데이터 센터가 전원 장애, 화재 또는 다른 재해로 인해 중단된다면 어떨까요?\n\n## 가상 머신을 복구하는 과정에서는 동일한 데이터 센터에서 EC2 인스턴스를 시작하려고 하기 때문에 실패합니다.\n\nAWS는 실패에 대비하여 설계되어 있어서, 전체 데이터 센터가 중단되는 이러한 드문 경우에도 대비할 수 있습니다. AWS 지역은 여러 데이터 센터가 가용 영역으로 그룹화된 것으로 구성되어 있습니다. 여러 가용 영역에 작업 부하를 분산시킴으로써 데이터 센터 장애로부터 복구할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다중 가용 영역을 이용한 고가용성 설정 구축 시 발생할 수 있는 두 가지 문제점이 있습니다:\n\n- 다른 가용 영역으로 failover된 후에는 기본 설정에서 네트워크 연결 스토리지(EBS)에 저장된 데이터에 액세스할 수 없을 수 있습니다. 이 경우에는 데이터에 접근할 수 없는 경우가 발생할 수 있는데, 이는 해당 가용 영역이 온라인 상태가 될 때까지 데이터(EBS 볼륨에 저장된)에 액세스할 수 없는 상황이지만 데이터는 손실되지 않습니다.\n- 다른 가용 영역에서 같은 개인 IP 주소로 새 가상 머신을 시작할 수 없습니다. 이는 서브넷이 가용 영역에 바인딩되고 각 서브넷에는 고유한 IP 주소 범위가 있기 때문입니다. 디폴트로, 회복 후에도 동일한 공용 IP 주소를 자동으로 유지할 수 없으며, 이는 CloudWatch 경보가 회복을 트리거하는 경우처럼 전에 논의한 경우와 같습니다.\n\n# 자동 확장을 이용하여 다른 가용 영역으로 실패한 가상 머신 복구\n\n첫 번째 독서에서 CloudWatch 경보를 사용하여 실패 시 Jenkins CI 서버를 실행 중인 가상 머신의 복구를 트리거하는 방법을 사용했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 메커니즘은 필요한 경우 원본 가상 머신의 동일한 사본을 시작합니다. 이것은 가상 머신의 사설 IP 주소와 EBS 볼륨이 단일 서브넷과 단일 가용 영역에 바운드되어 있기 때문에 동일한 가용 영역에서만 가능합니다.\n\n그러나 만약 가용 영역 장애가 발생할 경우 젠킨스 서버를 사용하여 새로운 소프트웨어를 테스트, 빌드 및 배포할 수 없다는 사실에 팀원들이 만족스럽지 않다고 가정해 보겠습니다. 다른 가용 영역에서 복구할 수 있는 도구가 필요합니다.\n\n다른 가용 영역으로 장애 조치(failover)하는 것은 자동 확장(autoscaling)의 도움을 받아 가능합니다.\n\n자동 확장은 EC2 서비스의 일부이며, 가용 영역이 사용 불가능한 경우에도 지정된 수의 EC2 인스턴스가 실행 중인지를 보장하는 데 도움을 줍니다. 자동 확장을 사용하여 가상 머신을 시작하고 원본 인스턴스가 실패할 경우 새 인스턴스가 시작되도록 할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가상 머신을 여러 서브넷에서 시작하는 데 사용할 수 있습니다. 예를 들어 전체 가용 영역의 장애가 발생하면 다른 가용 영역의 다른 서브넷에서 새 인스턴스를 시작할 수 있습니다.\n\n필요한 경우 다른 가용 영역에서 복구할 수 있는 가상 머신을 만들기 위해 다음 명령을 실행하세요. $Password는 8~40자로 이루어진 암호로 교체해주세요:\n\n```js\n$ aws cloudformation create-stack --stack-name jenkins-multiaz \\\n --template-url https:/ /s3.amazonaws.com/\\\n awsinaction-code3/chapter13/multiaz.yaml \\\n --parameters \"ParameterKey=JenkinsAdminPassword,\n ParameterValue=$Password\" \\\n --capabilities CAPABILITY_IAM\n```\n\n# 오토스케일링을 구성하려면 구성의 다음 두 부분을 만들어야 합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 런치 템플릿에는 EC2 인스턴스를 시작하는 데 필요한 모든 정보가 포함되어 있습니다: 인스턴스 유형(가상 머신의 크기) 및 시작할 이미지(AMI)입니다.\n- 오토 스케일링 그룹은 EC2 서비스에게 특정 런치 템플릿으로 시작해야 할 가상 머신의 수, 인스턴스를 모니터링하는 방법 및 EC2 인스턴스를 시작해야 하는 서브넷 등을 알려줍니다.\n\n읽어주셔서 감사합니다. 다음에는 오토 스케일링 그룹에 대해 더 자세히 알아보고 런치 템플릿의 다양한 매개변수에 대해 논의할 예정입니다.\n","ogImage":{"url":"/assets/img/2024-06-23-RecoveringfromadatacenteroutagewithanAutoScalinggroup_0.png"},"coverImage":"/assets/img/2024-06-23-RecoveringfromadatacenteroutagewithanAutoScalinggroup_0.png","tag":["Tech"],"readingTime":4},{"title":"AWS에서 ECS  EC2 오토스케일링 인프라 구축하는 방법","description":"","date":"2024-06-23 22:40","slug":"2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS","content":"\n# 소개:\n\n대규모로 백엔드 응용 프로그램을 배포하는 것은 일관된 성능 및 가용성을 보장하기 위해 중요합니다.\n\nAWS에서 Docker 컨테이너를 배포하는 여러 방법이 있습니다. 예를 들어, EC2 인스턴스, AWS Lambda, Fargate를 사용한 ECS 및 EC2를 이용한 ECS 등이 있습니다. 이 블로그에서는 ECS와 EC2를 사용하여 자동 확장 인프라를 설정하는 방법을 안내합니다. 우리의 요구에 맞는 최적의 선택인 이유를 알아보고 AWS UI를 사용하여 인프라를 구축하며, 다음 블로그에서는 Terraform을 사용하여 관리할 것입니다. 예시로, 백엔드 응용 프로그램으로 Rick Roll Docker 이미지를 사용할 예정입니다. 😎\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 블로그 개요:\n\n- 컨테이너를 배포하는 다양한 방법\n- ECS + EC2를 선택하는 이유?\n- 다이어그램을 활용한 인프라 구조\n- 플로우 설명\n- AWS Management Console을 사용한 인프라 구축\n\n# 요구 사항:\n\n- AWS 계정: 활성화된 AWS 계정이 필요합니다.\n- AWS 서비스에 대한 기본 지식: EC2, IAM 역할, VPC, 서브넷, 보안 그룹 및 로드 밸런서에 대한 이해가 필요합니다.\n- Docker에 대한 익숙함: Docker 및 컨테이너화 개념에 대한 경험이 필요합니다.\n- 인프라 구축 경험: AWS 또는 다른 클라우드 제공업체에서 인프라를 구축한 경험이 유용합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 컨테이너 배포의 다양한 방법:\n\n도커 컨테이너를 배포하는 방법은 다양한 AWS 서비스를 통해 가능합니다. 각각의 장단점이 있습니다:\n\n- CI/CD 자동화를 활용한 EC2 머신에서 컨테이너 실행: 전체적인 제어가 가능하지만 더 많은 설정과 유지보수가 필요하며 자동으로 확장되지 않습니다. 컨테이너 오케스트레이션 서비스를 사용하는 것이 더 나을 수 있습니다.\n\n2. AWS App Runner:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 장점: 최소 구성으로 간편한 배포, 자동 스케일링.\n- 단점:\n  — 최대 4 vCPU, 12 GB RAM.\n  — 요청 횟수에 기반한 스케일링으로 CPU 또는 RAM이 아닌 요청 횟수에 따라 스케일링되어 부하를 잘못 추정했을 경우 금액 낭비나 성능 문제 발생 가능성.\n  — 서비스 생성 후 구성 변경 불가; 구성 변경을 위해 삭제 및 재생성 필요.\n  — 서비스 생성 후 구성 변경 불가; 구성 변경을 위해 삭제 및 재생성 필요.\n- 왜 부적합한가: 제한된 자원과 스케일링 메커니즘은 일관된 트래픽을 가진 진행 중인 프로젝트에 적합하지 않습니다.\n\n3. AWS Lambda: 짧은 작업에 적합하지만 콜드 스타트 문제와 메모리 및 실행 시간 제약이 있습니다.\n\n4. ECS: 강력한 컨테이너 조작, 자동화 관리 및 스케일링을 제공하여 CI/CD, AWS App Runner 또는 AWS Lambda와 비교했을 때 EC2보다 유연성과 제어 능력을 제공합니다.\n\n## 왜 ECS + EC2를 선택해야 하나요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리는 여러 이유로 ECS + EC2를 선택했습니다:\n\n- 컨테이너 오케스트레이션: ECS는 강력한 컨테이너 오케스트레이션 기능을 제공합니다.\n- 확장성: 높은 사용량에 따라 자동으로 스케일링할 수 있는 능력.\n- 일관된 트래픽: 안정적인 트래픽을 갖는 B2B 애플리케이션에 적합하며, AWS의 권장을 따르고 있습니다.\n- Cold Starts 회피: AWS 람다나 Fargate와 같은 서버리스 옵션과 달리, EC2의 ECS는 Cold Start 지연 문제가 없습니다.\n- 미래 지향성: ECS + EC2는 GPU 워크로드 및 높은 RAM 사용을 처리할 수 있으며, 람다, 앱 러너 또는 심지어 ECS + Fargate와 같은 서비스가 지원할 수 없습니다. 이는 애플리케이션 요구사항이 계속 발전하는 경우에도 주요 재설계 없이 대응할 수 있는 미래 지향적인 솔루션이 됩니다.\n- 제어 및 유연성: 인스턴스 유형, 스케일링 정책 및 다른 구성에 대한 완전한 제어로, 복잡한 재설계 없이 인프라를 발전시킬 수 있습니다.\n- 장기 비용 절감: Fargate는 EC2 인스턴스 관리를 추상화하지만, 안정적인 트래픽을 처리할 때 EC2 인스턴스를 직접 사용하는 것이 장기적으로 더 비용 효율적일 수 있습니다.\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_1.png\" />\n\n무서워하지 마세요. 깊게 들이마셔… 깊게 내쉬세요. 그래, 그렇습니다. 여전히 여기 있네요? 멋져요. 이해를 돕기 위해 이해해야 할 네 가지 주요 구성 요소가 있습니다: Route 53 부분, ECS 부분, 로드 밸런서 부분 및 자동 스케일링 부분입니다. 이는 이전에 이미 본 것의 상세한 버전일 뿐입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모든 녹색 항목은 우리 인프라에서 정의해야 하는 자원입니다. 모든 빨간색 항목은 해당 자원의 부산물입니다. 그렇기 때문에 인프라를 코드로 관리한다면, 녹색으로 표시된 모든 것을 Terraform 자원으로 정의해야 합니다.\n\n# 인프라 작동 방식:\n\n인프라스트럭처에서 ECS + EC2 자동 확장 기능이 작동하는 방법\n\n먼저 자원의 기본적인 정의부터 시작해봅시다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Route 53 호스티드 존: 특정 도메인의 DNS 레코드를 관리합니다.\n- Route 53 레코드: 귀하의 애플리케이션으로 트래픽을 라우팅하는 DNS 레코드입니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_2.png)\n\n- 로드 밸런서: 여러 대상 (EC2 인스턴스) 사이에 들어오는 애플리케이션 트래픽을 분산시킵니다.\n- 리스너: 클라이언트에서 로드 밸런서로의 연결을 위한 프로토콜과 포트를 정의합니다.\n- 대상 그룹: 트래픽을 라우팅할 대상 (EC2 인스턴스)의 논리적 그룹화입니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_3.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- ECS 클러스터: 작업 및 서비스의 논리적 그룹화입니다.\n- ECS 서비스: ECS 클러스터 내의 작업을 배포하고 확장하는 서비스입니다.\n- 작업 정의: Docker 컨테이너가 어떻게 시작되어야 하는지를 지정합니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_4.png)\n\n- ECS Capacity Provider: ECS 클러스터 내에서 작업을 실행하기 위한 인프라를 관리합니다.\n- Auto Scaling 그룹: EC2 인스턴스 그룹을 관리하고 수요에 따라 자동으로 조정합니다.\n- 시작 템플릿: EC2 인스턴스를 시작하기 위한 구성 세부정보를 제공합니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 앱 자동 스케일링 정책: CPU 사용률과 같은 메트릭에 기반한 스케일링 정책을 정의합니다.\n- 앱 자동 스케일링 대상: 어떤 ECS 서비스를 스케일할지 지정합니다.\n\n# 플로우 설명:\n\n- Route 53을 이용한 DNS 구성:\n  도메인을 위한 Route 53 호스트된 존이 있으며, lb-prod.domain.com과 같은 DNS 레코드를 생성합니다. 이 레코드는 사용자 트래픽을 로드 밸런서로 보냅니다.\n- 로드 밸런서를 통한 트래픽 관리:\n\n- 로드 밸런서는 사용자로부터 트래픽을 수신합니다. EC2 인스턴스가 실행 중인 작업에 직접 트래픽을 보낼 수 없으므로 트래픽을 대상 그룹으로 전달합니다.\n- 로드 밸런서의 리스너는 트래픽 전달에 사용할 프로토콜과 포트를 정의합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 대상 그룹 및 ECS 서비스 통합:\n\n- 대상 그룹은 EC2 인스턴스에서 실행 중인 작업을 대상으로 하는 ECS 서비스에 연결됩니다.\n- ECS 서비스는 ECS 클러스터에서 작업을 관리하여 예상대로 실행되도록 합니다.\n\n4. 작업 정의 및 ECS 클러스터:\n\n- 작업 정의는 Docker 컨테이너의 세부 정보를 지정합니다. ECS 서비스는 이 정의를 사용하여 작업을 생성합니다.\n- 이러한 작업은 ECS 클러스터 내에서 실행되며, 이는 작업과 서비스의 논리적 그룹화입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n5. EC2 인스턴스에서 작업 실행:\n\n- 작업을 실행하기 위해 EC2 인스턴스에서 제공되는 인프라가 필요합니다.\n- 자동 확장 그룹은 런치 템플릿을 사용하여 EC2 인스턴스를 자동으로 시작하고 관리합니다.\n\n6. ECS Capacity Provider:\n\n- ECS 용량 제공자는 작업 실행에 필요한 인프라를 관리합니다. EC2 인스턴스가 작업 실행에 사용할 수 있는지를 보장합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n7. 자동 스케일링 정책:\n\n- 앱의 자동 스케일링 정책은 CPU 사용률 임계값을 50%로 정의합니다. 평균 CPU 사용률이 이 임계값을 초과하면 ECS 용량 공급자를 사용하는 ECS 서비스가 확장되어 실행 중인 작업 수가 증가합니다.\n- 자동 스케일링 그룹은 수요에 맞게 EC2 인스턴스 수를 조정합니다.\n\n8. 앱 자동 스케일링 대상:\n\n- 자동 스케일링 대상은 스케일링 정책이 올바른 ECS 서비스에 연결되어 있는지 확인합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n9. ECS 클러스터 용량 공급자:\n\n- 이 구성 요소는 여러 ECS 용량 공급자를 추적하고 ECS 클러스터와 연결합니다. 서비스에 특정 용량 공급자가 연결되지 않은 경우 기본 전략을 적용합니다.\n\n## 요약하면 다음과 같은 흐름이 됩니다\n\n- 사용자 트래픽은 Route 53 하위 도메인 레코드를 통해 로드 밸런서로 이동됩니다.\n- 로드 밸런서는 트래픽을 대상 그룹으로 전달하여 ECS 서비스에서 관리하는 작업으로 경로 지정합니다.\n- 작업은 ECS 용량 공급자와 오토스케일링 그룹에서 관리하는 EC2 인스턴스에서 실행됩니다.\n- 오토스케일링 정책은 수요에 따라 인프라가 확장되어 최적의 성능을 유지하게 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# AWS UI를 사용하여 인프라 구축하기\n\n일단 루트 53 부분은 선택 사항이며 인프라 재구성 시 로드 밸런서의 동일한 DNS가 필요한 경우에만 사용될 예정이니 지금은 건너 뛰도록 하겠습니다. 이 부분은 terraform을 통해 관리할 때 다시 설정하는 것으로 할 거에요.\n\n## 우리가 구축할 내용 개요:\n\n- 먼저 ECS 클러스터를 구축합니다\n- EC2 인스턴스를 선택할 겁니다\n- 이들을 위해 새로운 auto-scaling 그룹을 생성합니다\n- 런치 템플릿 정의\n  — 원하는 용량 정의\n  — 인스턴스 유형\n  — AMI\n  — 스토리지\n  — 사용할 키페어\n  — 서브넷\n  — 보안 그룹\n- 태스크 정의를 생성합니다\n- EC2를 런치 타입으로 설정\n- OS\n- CPU, RAM 요구 사항\n- 태스크 실행 롤\n- 사용할 이미지로 최소한 하나의 컨테이너를 정의합니다\n- 볼륨 추가\n- 컨테이너 포트 설정\n- 이제 ECS 서비스를 생성합니다\n- Capacity provider 전략\n- 태스크 패밀리\n- 원하는 태스크\n- 로드 밸런싱 (로드 밸런서 생성)\n  — 응용 프로그램 로드 밸런서\n  — 타겟 그룹\n  — 서비스 자동 확장 정책\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 단계:\n\n우선 AWS 계정에 로그인하신 후, ECS를 검색하고 열어주세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_6.png)\n\n이제 ECS 클러스터 생성부터 시작해봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- \"Create Cluster\"을 클릭하세요. 이름을 지어주세요; 저는 \"rick-roll-prod-cluster\"로 부를 거에요. 자원의 이름 짓는 규칙으로 kebab-case를 사용할 거예요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_7.png)\n\n2. \"Infrastructure\" 섹션으로 스크롤 내려가보세요. EC2 또는 Fargate 중 하나를 선택할 수 있습니다; 이전에 논의했던대로 EC2 런치 타입을 선택할 거예요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 저희는 EC2 인스턴스의 생성 및 종료를 관리할 자동 스케일링 그룹을 생성할 예정입니다.\n\n- 새로운 EC2 인스턴스를 생성하기 위해서는 ASG가 사용할 런치 템플릿을 지정해야 합니다:\n  - AMI: 이를 유지합시다.\n  - 인스턴스 유형: t2.micro로 진행합시다.\n  - EC2 인스턴스 역할: 새 역할을 생성할 것입니다.\n  - 원하는 수용 능력: 최소값을 0으로 설정하고 최대값을 4로 설정해주세요. 이는 ASG가 유지하는 ECS 클러스터의 인스턴스 수에 대한 제한입니다.\n  - SSH 키: 선택적으로 이 인스턴스에 로그인하기 위한 SSH 키를 생성하거나 무시해주세요.\n  - 볼륨: 기본값인 30으로 설정해주세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_9.png)\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_10.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. 이제 VPC 및 서브넷은 기본 설정으로 남겨두세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_11.png)\n\n5. 새 보안 그룹을 만들고 어디에서나 HTTP 액세스를 허용하는 인바운드 규칙을 추가하세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_12.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n6. 모니터링을 활성화하고 원하는 경우 태그를 추가할 수 있습니다. 이제 클러스터를 생성하세요.\n\n![Cluster Image](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_13.png)\n\n- 시간이 걸릴 수 있지만, ASG, EC2 런치 템플릿 및 보안 그룹이 포함된 ECS 클러스터를 성공적으로 만들었습니다.\n\n태스크 정의 생성:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 태스크는 컨테이너 주변의 래퍼와 같습니다. 태스크 정의를 만들고, 그에 따라 우리의 컨테이너가 실행됩니다. 왼쪽에 있는 \"태스크 정의\"를 클릭하고, \"새 태스크 정의 생성\"을 클릭하세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_14.png)\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_15.png)\n\n2. 이름을 지정하고 EC2에서 실행하려는 것을 명시합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_16.png)\n\n3. 이제 작업 크기를 결정해야 합니다. 작업 크기는 작업(컨테이너)에 필요한 CPU 및 메모리 양을 결정합니다.\n\n- CPU를 1 vCPU로, Memory를 0.5 GB로 설정합니다. 둘 다 EC2 하드웨어(t2.micro) 한도 내에 있습니다.\n- OS 및 Network 모드는 기본 설정으로 유지합니다.\n- Task 역할을 `ecsTaskExecutionRole`로 설정합니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_17.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n4. 작업에서 실행할 적어도 하나의 컨테이너를 지정해야 합니다.\n\n- 컨테이너에 이름을 지정하세요.\n- 이미지로는 Docker Hub에서 사용 가능한 Rick Roll 이미지를 사용할 것입니다.\n- Rick Roll이 실행될 포트인 80으로 설정하세요.\n\n```js\nkale5/rickroll:vclatest\n```\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_18.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n5. 건강 상태 확인: 저희 컨테이너의 건강 상태를 모니터링하기 위해 건강 상태 확인을 설정해야 합니다. ECS 서비스는 서버가 작동 중인지 계속 확인하기 위해 이 엔드포인트를 반복해서 핑합니다. 우리 경우에는 root 엔드포인트로 curl을 수행하는 건강 상태 확인을 생성할 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_19.png)\n\n6. 원하는 경우 작업 정의에 태그를 추가할 수 있습니다. 이제 \"만들기\"를 클릭하면 작업이 생성됩니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_20.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 이제 ECS 클러스터와 작업 정의를 갖고 있으니 클러스터에서 작업을 시작할 수 있습니다. 그러나 작업을 자동으로 관리하고 확장하기 위해 ECS 서비스를 생성할 것입니다.\n\nECS 서비스 생성:\n\n- 이제 ECS 클러스터를 열고 “Service” 섹션을 클릭한 다음 “Create”를 클릭하세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_21.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 컴퓨팅 옵션의 경우, 기본 설정을 사용하겠습니다. 클러스터 용량 공급자와 ECS 용량 공급자가 이미 생성되어 있습니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_22.png)\n\n3. 애플리케이션 유형은 기본값인 Service로 남겨두세요.\n\n4. 작업 정의의 경우, 이전에 정의한 작업 패밀리를 선택하세요. 가장 최신의 수정본이 자동으로 가져와집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_23.png\" />\n\n5. 서비스에 이름을 지정해주세요. \"원하는 작업\" 섹션에서는 ECS 서비스가 ECS 클러스터에서 실행 중인 작업을 얼마나 유지할지 정의합니다. 2로 설정하면 언제나 최소 2개의 작업이 실행 중임을 보장합니다.\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_24.png\" />\n\n6. 이제 로드 밸런서를 만들고 해당 로드 밸런서를 ECS 서비스에 연결하여 ECS에 부하를 분산합니다. \"로드 밸런싱 - 선택 사항\"을 선택하여 시작하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_25.png\" />\n\n- 자세히 보기에서 로드 밸런서 유형을 ALB로 선택하세요. 컨테이너에서는 \"rick-roll-vc-image 80:80\"를 선택하세요. 새로운 로드 밸런서를 만들고 이름을 붙여주세요.\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_26.png\" />\n\n7. 아래로 스크롤하세요. 이제 새로운 리스너와 타겟 그룹을 만듭니다. 리스너는 로드 밸런서에서 타겟 그룹으로 트래픽을 보내고, 해당 타겟 그룹은 실행 중인 ECS 태스크를 대상으로합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_27.png\" />\n\n8. 이제 모든 로드 밸런서 관련 구성이 완료되었습니다. 더 아래로 스크롤하세요. 부하에 따라 확장 및 축소하려면 서비스에 대한 자동 확장 정책을 정의해야 합니다.\n\n- \"서비스 자동 확장\" 드롭다운 메뉴를 엽니다.\n- \"서비스 자동 확장 사용\" 확인란을 선택합니다.\n- 서비스가 실행되기를 원하는 최소 및 최대 작업 수를 정의합니다.\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_28.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 자동 스케일링 정책의 정책 이름을 정의하세요. 서비스 메트릭에서는 임계값으로 평균 CPU 사용률을 사용할 것입니다. 서비스가 작업을 확장하거나 축소하는 데 사용할 수 있는 다른 메트릭을 선택할 수도 있습니다.\n- 타겟 값을 50%로 설정하면, 언제든지 평균 CPU 사용률이 이 숫자를 넘어가면 시스템을 확장하고, 그 밑으로 내려가면 축소할 것입니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_29.png)\n\n9. 다른 것들은 그대로 두고 고유한 태그를 부착한 후 “생성”을 클릭하여 서비스를 만드세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_30.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 생성 프로세스가 완료될 때까지 몇 분 정도 소요될 예정이니, 조금만 기다려 주세요.\n\n# 인프라 테스트 중:\n\n- AWS 관리 콘솔에서 \"부하 분산기\"를 검색하고 클릭합니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_31.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n2. 이제 새로 생성한 Application Load Balancer (ALB)을 찾아서 열어보세요.\n\n![ALB image](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_32.png)\n\n- DNS 레코드를 복사하고 새 탭에서 열어보세요. 이것이 우리 앱의 URL입니다 (Application Load Balancer의 DNS 레코드).\n\n![DNS record image](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_33.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 503 에러가 발생할 수 있습니다. 이는 로드 밸런서가 작동 중이지만 ECS 작업으로 트래픽이 수신되지 않음을 의미합니다. 이는 서비스가 아직 생성 중이거나 작업이 아직 시작되지 않았을 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_34.png)\n\n3. 리스너, 서비스, 대상 그룹 및 작업을 확인하세요. 일부 리소스가 아직 완전히 생성되지 않은 경우가 있습니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_35.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 일정 시간이 지나면 모든 리소스가 완전히 생성되어 ​​건강한 작업이 실행되는 것을 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_36.png)\n\n- 이제 로드 밸런서 DNS가 열린 탭을 새로고침해주세요.\n\n![이미지](/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_37.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 와! 우리 인프라가 작동 중이야! 🎉\n\n# 결론 및 다음 단계\n\n우리 인프라가 마침내 가동 중임을 확인할 수 있어요. 고량의 트래픽을 보내면 EC2 인스턴스에서 실행 중인 작업을 자동으로 확장하여 수요를 충족시킬 거에요.\n\n이 정도까지 오다니 축하해요!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_38.png\" />\n\n다음 블로그에서는 이 인프라를 테라폼을 사용하여 코드로 변환하는 방법을 보여드리겠습니다. 이를 통해 인프라의 쉬운 사용자 정의, 수정 및 여러 버전을 제공할 수 있습니다. 현재는 여러분의 여정에 튼튼한 출발점이 될 것입니다. 테라폼을 다룬 다음 파트에 관심이 있다면 댓글을 남겨주세요. 계속해서 지켜봐 주시고 즐거운 코딩 되세요!\n\n저와 연결을 원하시나요? 여기가 제 LinkedIn입니다.\n\n# 감사의 글\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nYogendra Manawat ( SDE Intern @AiCaller.io ) : 리뷰 및 플로우를 완벽하게 만드는 데 도움을 주었습니다.\n\nChirag Panjwani ( SDE @ Genesis Technologies ): 가치 있는 피드백을 제공해 주셨습니다.\n\nSiddharth Singh Patel : 개선을 위한 제안 및 선행 조건 추가와 같은 아이디어에 대해 감사드립니다.\n","ogImage":{"url":"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_0.png"},"coverImage":"/assets/img/2024-06-23-HowtoBuildanECSEC2Auto-ScalingInfrastructureonAWS_0.png","tag":["Tech"],"readingTime":23}],"page":"13","totalPageCount":119,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}