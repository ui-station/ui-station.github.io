{"pageProps":{"posts":[{"title":"앱 테마 변경하기  접근성 맞춤 설정하기","description":"","date":"2024-05-27 17:50","slug":"2024-05-27-ChangeAppThemePersonalizingAccessibility","content":"\n<img src=\"/assets/img/2024-05-27-ChangeAppThemePersonalizingAccessibility_0.png\" />\n\n이전 두 개의 게시물로 시작한 개인화 접근성 주제를 이어가고 있어요. 아래 링크에서 확인할 수 있어요:\n\n- 설정으로 개인화 접근성\n- 아이콘과 레이블 전환 - 개인화 접근성\n\n이전 게시물에서 설명한 것처럼, 일반적으로 개인화는 접근성을 개선하는 열쇠가 될 수 있다는 것과 아이콘과 레이블을 숨기거나 표시하는 설정을 추가하는 구체적인 예시를 제시했어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 블로그 포스트에서는 구체적인 예시를 계속 다루겠습니다. 앱의 테마를 변경할 수 있는 설정을 추가할 것입니다. 사용자는 시스템 설정을 따르는 것(기본값), 밝은 테마, 어두운 테마, 고대비 색상 테마 중에서 선택할 수 있습니다. 함께 알아보겠습니다.\n\n# 왜?\n\n가끔 사용자들은 핸드폰의 테마와 다른 테마로 앱을 사용하고 싶어합니다. 저는 개인적으로 모든 것을 어두운 모드로 사용하지만, 제게는 사용하기 어려운 색상이 들어간 어두운 테마를 가진 몇몇 앱을 만난 적이 있습니다. 너무 많은 대비가 있는 경우도 있고, 때로는 너무 적은 경우도 있습니다. 그런 경우에는 밝은 테마로 변경하고 싶었습니다. 일반적으로 그런 옵션이 없어서 그 앱을 포기했거나, 필요할 때 최소한 사용했습니다.\n\n그래서 사용자에게 제어력을 주는 것이 중요합니다. 이런 종류의 설정을 위한 최소 옵션은 시스템 기본값, 밝은 테마, 어두운 테마입니다. 하지만 고대비 테마는 어떨까요? 왜 추가해야 하며 누가 필요로 할까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 고대비 테마\n\n고대비 테마는 더 높은 대비를 가진 색상으로 이루어진 색상 팔레트를 가지고 있습니다. 구체적인 예로는 Windows 7 이후에 개발된 Windows 고대비 모드가 있습니다. 안드로이드는 고대비 텍스트를 설정할 수 있는 기능을 제공하지만, 그것은 텍스트에만 적용됩니다.\n\nWebAIM은 2018년에 저시력 사용자들을 대상으로 설문조사를 실시해, 응답자 중 51.4% (n=248)가 고대비 모드를 사용했다고 나타냈습니다. 저시력 사용자는 고대비 테마를 필요로 하는 큰 그룹 중 하나지만, 다른 사람들도 필요할 수 있습니다. 예를 들어, 편두통을 앓는 사람이나 아일린 증후군을 가진 사람, 또는 일부 언어 장애를 가진 사람들도 고대비 테마를 통해 혜택을 받을 수 있습니다. 또한 고대비 모드는 눈에 좋은 햇빛 속에서 모두에게 유용할 수 있습니다.\n\n# 어떻게?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n앱 테마를 변경할 수 있는 기능을 추가하는 흐름은 이전 블로그 게시물의 레이블 및 아이콘과 유사합니다. 설정 화면에 설정을 추가하고 설정 값을 데이터 저장소에 저장한 다음 앱에서 해당 값을 사용하여 어떤 테마를 표시할지 결정합니다.\n\n먼저 설정 화면부터 시작해보겠습니다. 테마를 선택할 수 있는 섹션과 선택할 수 있는 옵션을 추가하고 싶습니다. 리스트에는 시스템 기본, 다크 테마, 라이트 테마 및 고대비 테마 네 가지 옵션이 포함되어 있습니다. 예시에서 색상이 표시됩니다:\n\n![테마 선택 화면](/assets/img/2024-05-27-ChangeAppThemePersonalizingAccessibility_1.png)\n\n## 데이터 저장하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저, 이전 블로그 게시물에서 설정 저장에 사용한 설정 데이터 저장소에 키-값 쌍을 추가하려고 합니다. 이전 블로그 게시물에서 언급했듯이, 블로그 게시물을 단순하게 유지하기 위해 데이터 저장소는 SettingsRepository에서 정의되고 상호 작용됩니다.\n\n네 가지 옵션이 있기 때문에 이 경우에는 간단한 부울 값이 작동하지 않습니다. 코드에서는 테마에 대해 미리 정의된 값들을 사용하고자 하므로, 테마에 대한 옵션을 모두 포함하는 enum 클래스를 만들고 시스템 기본값으로 null을 사용합니다.\n\n```js\n// ThemeExt.kt\n\nenum class Theme {\n    Dark,\n    Light,\n    HighContrast;\n}\n```\n\n데이터 저장소는 enum 값들을 저장할 수 없으므로, enum을 문자열로 변환하고 다시 변환할 방법이 필요합니다. 문자열로 변환하는 부분은 쉽습니다 - toString() 함수를 사용할 수 있습니다. 다른 변환에 대해서는 도우미 함수를 정의해야 합니다. enum 클래스에 추가해보겠습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```kotlin\nenum class Theme {\n    ...\n\n    companion object {\n        fun from(value: String?): Theme? {\n            return when (value) {\n                Dark.name -> Dark\n                Light.name -> Light\n                HighContrast.name -> HighContrast\n                else -> null\n            }\n        }\n    }\n}\n```\n\n이 메서드에서는 주어진 값과 일치하는 테마 이름이 무엇인지 확인합니다. 또한, 일치하는 것이 없을 때의 기본 케이스는 null입니다 - 일치하는 것이 없으면 시스템 기본값으로 가정하고 값을 null로 설정합니다.\n\n이제 데이터 스토어에 테마를 저장하기 위한 모든 준비가 되었습니다. 먼저 값을 읽기 위한 flow를 추가해 보겠습니다:\n\n```kotlin\n// SettingsRepository.kt\n\nprivate object PreferencesKeys {\n    ...\n    val colorTheme = stringPreferencesKey(\"color_theme\")\n}\n\nval colorThemeFlow: Flow<Theme?> = dataStore.data\n    .map {\n        Theme.from(it[PreferencesKeys.colorTheme])\n    }\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼, 먼저 preferences 키 오브젝트에 preferences 키를 추가합니다. 플로우를 위해 데이터 스토어에서 값을 읽은 다음, 앞서 정의한 Theme.from()을 사용하여 문자열을 Theme-enum으로 파싱합니다.\n\n값을 편집하기 위해 다음과 같은 함수를 정의합니다:\n\n```kotlin\n// SettingsRepository.kt\n\nsuspend fun setColorScheme(theme: Theme?) {\n    dataStore.edit { preferences ->\n        preferences[PreferencesKeys.colorTheme] = theme.toString()\n    }\n}\n```\n\n이 함수에서는 enum의 문자열 값을 정의한 preference 키를 사용하여 데이터 저장소에 설정합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음으로 할 일은 SettingsViewModel을 업데이트하는 것입니다. 먼저, 테마 값을 저장할 Mutable State Flow를 추가하고 UI에서 사용합니다:\n\n```kotlin\n// SettingsViewModel.kt\n\nprivate var _colorScheme =\n    MutableStateFlow<Theme?>(Theme.Dark)\nval colorScheme = _colorScheme.asStateFlow()\n```\n\n그런 다음, 리포지토리에서 값을 읽고 setColorScheme 함수를 사용할 수 있도록 함수를 정의합니다:\n\n```kotlin\n// SettingsViewModel.kt\n\nprivate fun getColorScheme() {\n    viewModelScope.launch {\n        settingsRepository.colorThemeFlow.collect {\n            _colorScheme.value = it\n        }\n    }\n}\n\nfun setColorScheme(theme: Theme?) {\n    viewModelScope.launch {\n        settingsRepository.setColorScheme(theme)\n    }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로 앱을 열 때 초기값을 얻기 위해 init 블록에서 getColorScheme()을 호출하는 것입니다:\n\n```js\n// SettingsViewModel.kt\n\ninit {\n    ...\n    getColorScheme()\n}\n```\n\n## 설정 화면\n\n지난 게시물과 마찬가지로 SettingsViewModel에서 값을 사용하는 방법을 보여주지는 않겠지만, 접근성 및 의미론적인 관점에서 몇 가지 사항을 언급하고 싶습니다: 각 색상 옵션은 선택 가능한 변경자를 가져야하며, 색상 옵션을 감싸는 구성 요소는 selectableGroup()-변경자를 가져야합니다. 내 코드에서 이러한 것들은 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n부모 컴포넌트에서 다음을 사용하고 있어요:\n\n```js\n// SettingsScreen.kt\n\nColumn(\n    modifier = Modifier.selectableGroup(),\n) {\n    colorOptions.map { option ->\n        ...\n    }\n}\n```\n\n이 작업이 왜 이루어지는지 더 알고 싶다면, 제 블로그 게시물인 젯팩 콤포즈에서 Modifier를 활용하여 Android 접근성 향상하기를 확인해보세요.\n\n## UI에 대한 테마 변경\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n최종 단계는 테마의 저장된 값 사용하여 해당 값을 업데이트하는 것입니다. 저장된 값에 따라 테마를 설정하는 로직을 추가해야 합니다.\n\n실제 테마 정의는 이 블로그 포스트의 범위를 벗어납니다. 저는 어두운, 밝은 및 고대비 테마에 대한 색상을 정의했고 코드에서 이를 사용할 것입니다.\n\nTheme.kt 파일에서 애플리케이션 테마의 기본 구현에 추가적인 확인을 추가해봅시다:\n\nAppTheme 코파서블에 Theme 유형의 선택적 매개변수를 추가하고 해당 값을 사용하여 MaterialTheme 구성 요소에 설정할 색상을 결정합니다. 테마가 null이 아닌 경우 값을 기준으로 색상을 설정하고, null이면 시스템의 기본 색상을 사용해야 합니다. 이를 위해 isSystemInDarkTheme 값을 확인하여 색상을 설정합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로, 앱의 루트가 정의된 MainActivity에서 우리는 저장된 테마의 값을 읽은 다음 그 값을 AppTheme-composable에 전달합니다:\n\n```js\n// MainActivity.kt\n\nval theme = settingsViewModel.colorScheme.collectAsState()\n\nAppTheme(theme = theme.value) { ... }\n```\n\n그리고 이러한 변경 사항들로 설정에서 선택했을 때 다음 테마들을 볼 수 있게 될 것입니다:\n\n# 마무리\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 블로그 글에서는 앱에서 사용자가 테마를 선택할 수 있도록 설정을 추가하여 사용자가 소프트웨어의 테마를 결정하는 방법을 살펴보았어요. 제공되는 테마는 밝은 테마, 어두운 테마, 고대비 테마 또는 시스템의 기본 테마를 따를 수 있어요.\n\n당신의 앱에 테마 선택기를 구현해 보셨나요? 지금까지 고대비 테마를 경험해 보신 적이 있나요? 앞으로 다룰 수 있는 접근성 설정 유형에 대한 아이디어가 있으신가요?\n\n# 블로그 글 내 링크\n\n- 설정으로 접근성 개인화하기\n- 아이콘과 레이블을 토글하기 — 접근성 개인화\n- WebAIM\n- Jetpack Compose에서 Modifier로 안드로이드 접근성 향상하기\n","ogImage":{"url":"/assets/img/2024-05-27-ChangeAppThemePersonalizingAccessibility_0.png"},"coverImage":"/assets/img/2024-05-27-ChangeAppThemePersonalizingAccessibility_0.png","tag":["Tech"],"readingTime":9},{"title":"안녕하세요 이번 Android 스택 주간 소식입니다  Issue126","description":"","date":"2024-05-27 17:49","slug":"2024-05-27-AndroidStackWeeklyIssue126","content":"\n<img src=\"/assets/img/2024-05-27-AndroidStackWeeklyIssue126_0.png\" />\n\n# 기사\n\n## Jetpack Compose에서 공유 요소 전환으로 부드러운 탐색 경험\n\n안드로이드 앱에서 매끄러운 내비게이션 경험을 만들기 위해 Jetpack Compose에서 공유 요소 전환이 어떻게 구현되는지 배우세요. 이 안내서에는 설정, 종속성 및 코드 예시가 포함되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Compose 컴파일러 보고서의 무난한 분석\n\nJetpack Compose 컴파일러 보고서를 쉽게 분석하여 안드로이드 앱의 성능을 최적화하는 방법을 알아보세요.\n\n## 접근성을 위한 앱 테마 개인화\n\n사용자가 빛, 어둠 및 고대비 옵션을 포함한 테마를 사용자 정의할 수 있도록 함으로써 앱 접근성을 향상시키는 방법을 배워보세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 안드로이드 뷰에 예측 후진 구현 로드맵\n\n안드로이드 앱에서 뷰를 사용하여 예측 후진 애니메이션을 통합하는 단계에 대해 설명하는 블로그 포스트입니다.\n\n## 안드로이드에서 효과적인 캐싱 전략\n\n안드로이드 앱을 위한 다양한 캐싱 전략을 탐색하며 API 캐싱에 초점을 맞춥니다. 이 글은 Cache Only, Network Only, Network First 및 여러 Cache First 전략과 같은 다양한 접근 방식에 대해 논의합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 토끼굴 속으로: 성능 최적화 통찰\n\n안드로이드 앱 개발에서 성능 최적화의 미묘한 점들을 로맹 가이와 함께 살펴보세요.\n\n**협찬**\n\n**라이브러리 및 자원**\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## ComposeGuard\n\nJetpack Compose에서 regression을 감지하는 Gradle 플러그인입니다.\n\n# Videos\n\n## 안드로이드 앱 경험을 향상시키는 3가지 방법: Edge to Edge, Predictive Back, 그리고 Glance\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 더 빠르게 만들기 - Android Developers Backstage\n\n## Jetpack Compose UI를 쉽게 디버깅하세요!\n\n## Google의 새로운 스크린샷 테스팅 프레임워크를 Compose에 어떻게 사용할 수 있을까요?\n\n## Stream SDK로 안드로이드 비디오 통화 앱 만들기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 다음 주간 소식을 위한 링크를 추천해주세요\n\n의겈이나 피드백을 환영합니다!\n\n제안하고 싶은 내용이나 의견이 있으시면 Canopas Twitter 계정 @canopas_eng 로 연락주시고, 다음 주간에 고려해 드리겠습니다.\n","ogImage":{"url":"/assets/img/2024-05-27-AndroidStackWeeklyIssue126_0.png"},"coverImage":"/assets/img/2024-05-27-AndroidStackWeeklyIssue126_0.png","tag":["Tech"],"readingTime":3},{"title":"Terraform을 활용한 Multi-Cloud 관리 마스터하기","description":"","date":"2024-05-27 17:46","slug":"2024-05-27-MasteringMulti-CloudManagementwithTerraform","content":"\n<img src=\"/assets/img/2024-05-27-MasteringMulti-CloudManagementwithTerraform_0.png\" />\n\n여러 공개 클라우드(Azure, AWS, GCP 등)를 사용하면 유연성을 제공하고 비용을 최적화하며 벤더 락인을 줄일 수 있습니다. 그러나 다양한 클라우드 플랫폼 간에 인프라 및 서비스를 관리하는 것은 어렵습니다.\n\n테라폼을 통해 일관되고 자동화된 멀티 클라우드 관리가 가능한지 알아봅시다. 이 포함사항은 멀티 클라우드 아키텍처, 테라폼 추상화, 프로비저닝, 거버넌스, 네트워킹, 배포 패턴, 테스팅, 그리고 Azure 및 GCP 전반적인 모니터링입니다.\n\n# 개요\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 주제를 다룰 것입니다:\n\n- 테라폼을 사용한 멀티 클라우드 아키텍처\n- 인프라 차이점 추상화\n- 리소스 프로비저닝 및 의존성 관리\n- 정책 강화 및 거버넌스\n- 네트워킹 토폴로지와 연결\n- 블루-그린, 카나리아, 멀티 리전 배포 패턴\n- 통합 테스트 및 목 객체(Mock) 사용\n- 중앙 집중식 로깅, 메트릭 및 관찰 가능성\n\n이 코드 예제들은 테라폼을 사용해 Azure와 GCP로 인프라 및 서비스를 배포하는 방법을 보여줍니다. 이는 테라폼을 일관된 추상화 계층으로 사용하여 실제 멀티 클라우드 관리를 보여줍니다.\n\n# 멀티 클라우드 아키텍처\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기본적인 멀티 클라우드 아키텍처는 Terraform을 사용하면 다음과 같이 보입니다:\n\nTerraform은 여러 클라우드 계정에 인프라를 프로비저닝하고 플랫폼 간의 차이를 추상화합니다. 상태는 원격으로 저장되며 계정 간에 공유됩니다.\n\n멀티 클라우드 아키텍처를 위한 몇 가지 주요 디자인 원칙:\n\n- 차이 추상화 — 공급자별 논리를 최소화하고 차이를 추상화 뒤에 숨깁니다\n- 환경 모듈화 — 환경 및 구성 요소별로 모듈화된 파일로 구성을 분리합니다\n- 표준화된 네이밍 — 쉽게 연관을 확인하기 위해 클라우드 간에 일관된 네이밍 체계 사용\n- 정책 캡슐화 — 정책 및 거버넌스 규칙을 모듈화된 재사용 가능한 파일에 유지합니다\n- 상태 중앙화 — 원격 상태를 사용하여 서비스 및 클라우드 전체의 상태를 공유합니다\n- 공유 서비스 추출 — ID, DNS, CDN과 같은 공유 서비스를 한 번 빌드하고 재사용합니다\n- 파이프라인 통합 — 모든 클라우드 대상으로 배포하는 표준 CI/CD 파이프라인 사용\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이러한 원칙을 따라서, 여러 대상 클라우드 간에 일관성있는 이동 가능한 구성을 구축할 수 있습니다.\n\n그 다음으로, Terraform이 클라우드 간의 차이를 추상화하는 데 어떻게 도움을 주는지 살펴보겠습니다.\n\n# 인프라 추상화\n\nTerraform의 강점 중 하나는 클라우드 플랫폼 간의 차이를 추상화하는 균일한 추상화 계층을 제공할 수 있는 능력입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어, Azure 대 GCP에서 MySQL 데이터베이스 프로비저닝:\n\nAzure\n\n```js\nresource \"azurerm_mysql_server\" \"db\" {\n  name                = \"mysqlserver\"\n  location            = \"eastus\"\n  resource_group_name = azurerm_resource_group.rg.name\n```\n\n```js\n  sku {\n    name     = \"B_Gen5_2\"\n    capacity = 2\n  }\n}\nresource \"azurerm_mysql_database\" \"db\" {\n  name                = \"mydatabase\"\n  resource_group_name = azurerm_resource_group.rg.name\n  server_name         = azurerm_mysql_server.db.name\n  charset             = \"utf8\"\n  collation           = \"utf8_unicode_ci\"\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nGCP\n\n```js\nresource \"google_sql_database_instance\" \"db\" {\n  name             = \"mysql-instance\"\n  database_version = \"MYSQL_5_7\"\n  region           = \"us-central1\"\n```\n\n```js\n  settings {\n    tier = \"db-f1-micro\"\n  }\n}\nresource \"google_sql_database\" \"database\" {\n  name     = \"my-database\"\n  instance = google_sql_database_instance.db.name\n}\n```\n\nTerraform의 리소스 유형은 일관된 인터페이스를 제공하기 위해 기본 API 차이를 추상화합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 추상화는 대규모 변경없이 클라우드 간에 쉽게 전환할 수 있도록 도와줍니다. 필요한 경우 각 클라우드 공급업체에 맞게 엣지에서 맞춤 설정할 수 있습니다.\n\n테라폼이 다중 클라우드 추상화를 제공하는 주요 분야 몇 가지:\n\n- 컴퓨팅 — 가상 머신, 컨테이너, 쿠버네티스, 스케일링\n- 네트워크 — 서브넷, 라우팅, 보안 그룹, 로드 밸런싱\n- 스토리지 — 블롭, 디스크, 데이터베이스\n- 아이덴티티 — 역할, 권한, 액세스 제어\n- 인프라스트럭처 — DNS, VPN, 규칙, 정책\n\n최대한 다중 클라우드 추상화를 활용하여 구성을 작성하면 이동성이 높아집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 프로비저닝 및 의존성\n\n여러 클라우드 인프라를 프로비저닝할 때 가장 좋은 방법은 리소스를 의존성 레이어로 구조화하는 것입니다.\n\n상위 수준의 구성은 하위 수준의 구성을 의존합니다. 예를 들어:\n\n테라폼을 사용할 때, depends_on 속성을 사용하여 리소스 의존성을 명시적으로 정의하세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n리소스 \"azurerm_subnet\" \"public\" {\n#...\n}\n\n리소스 \"azurerm_network_interface\" \"nic\" {\n#...\nsubnet_id = azurerm_subnet.public.id\n}\n리소스 \"azurerm_virtual_machine\" \"main\" {\n#...\n\nnetwork_interface_ids = [\nazurerm_network_interface.nic.id,\n]\ndepends_on = [\nazurerm_network_interface.nic\n]\n}\n\n테라폼은 리소스 간 종속성을 분석하고 변경 사항을 올바른 순서로 적용합니다.\n\n멀티 클라우드 환경에서의 종속성에 대한 팁:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 공통 빌딩 블록을 기본 모듈에 네트워크와 같은 것으로 포함시킵니다.\n- 독립적인 구성 요소를 계층별로 분리합니다.\n- 암시적이어도 `depends_on`을 명시적으로 정의합니다.\n- 데드락을 일으키는 종속성 순환이 있는지 확인합니다.\n- 종속성 순서대로 계획하고 적용합니다.\n\n자원 종속성을 올바르게 설정하는 것이 여러 클라우드에서 원활한 프로비저닝을 위해 중요합니다.\n\n# 정책 집행과 거버넌스\n\n기관 정책과 규정 준수 요구사항을 강제하는 것은 여러 클라우드 관리에 있어 중요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 운용 규칙의 몇 가지 예시입니다:\n\n- VM 유형 제한\n- 데이터 주권을 위한 지역 및 존 제어\n- 태깅 규칙과 표준 설정\n- 네트워킹 노출 제한\n- 암호화 요구 사항 강제\n- 고위험 자원 사용 제한\n\n테라폼을 통해 정책 강제를 활성화할 수 있습니다:\n\n변수\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n허용된 값 제한:\n\n```js\nvariable \"region\" {\n  type    = string\n  default = \"us-east-1\"\n}\n```\n\n```js\nresource \"aws_db_instance\" \"db\" {\n  region = var.region # us-east-1만 허용됩니다\n}\n```\n\n모듈\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n친구야, 모듈 내에서 지배 논리를 캡슐화하고 재사용하세요:\n\n```js\nmodule \"server\" {\n  source = \"./modules/certified_server\"\n# 인증된 서버는 합리적인 기본값을 설정합니다\n}\n```\n\nSentinel 정책\n\n리소스를 제한하는 대상 정책을 적용하십시오:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\naws_instance_disallowed_type = rule {\n  all aws_instance as _, instance {\n    instance.instance_type is not in [\"t2.micro\", \"t3.micro\"]\n  }\n}\n```\n\n이러한 메커니즘은 구성에 직접 규제를 포함하여 규정 준수를 쉽게 만듭니다.\n\n# 네트워킹 토폴로지\n\n다양한 클라우드 간 네트워크 연결성을 관리하는 것은 복잡성을 증가시킵니다. 일부 하이브리드 클라우드 네트워크 토폴로지는 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 형식을 Markdown 형식으로 변경하실래요.\n\n| Pairing                                                                                   |\n| ----------------------------------------------------------------------------------------- |\n| Connect cloud regions to on-prem data centers. Useful for migration and hybrid workloads. |\n\n| Hub-and-Spoke                                                                                    |\n| ------------------------------------------------------------------------------------------------ |\n| Central hub VPC with connectivity to multiple cloud spokes. Enables transitivity between spokes. |\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n메시\n\n클라우드 간 사이트 간 VPN이 구성된 완전히 메시된 네트워크입니다. 지역 간 직접 통신을 제공합니다.\n\n테라폼은 terraform-provider-aws, terraform-provider-azurerm 및 유사한 네트워킹 제공업체를 통해 이러한 네트워크 토폴로지를 조정하는 것을 단순화합니다.\n\n예를 들어, AWS에서 Azure로 사이트 간 VPN을 생성하는 방법:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# AWS 측\n리소스 \"aws_customer_gateway\" \"gw\" {\n  bgp_asn    = 65002\n  ip_address = \"172.0.0.1\"\n  type       = \"ipsec.1\"\n}\n```\n\n```js\n리소스 \"aws_vpn_connection\" \"main\" {\n  vpn_gateway_id      = aws_vpn_gateway.vgw.id\n  customer_gateway_id = aws_customer_gateway.gw.id\n  type                = \"ipsec.1\"\n  static_routes_only  = true\n  tunnel1_ike_versions   = [\"ikev2\"]\n  tunnel2_ike_versions   = [\"ikev2\"]\n  tunnel1_phase1_dh_group_numbers = [31]\n  tunnel2_phase1_dh_group_numbers = [31]\n}\n# Azure 측\n리소스 \"azurerm_local_network_gateway\" \"lgw\" {\n  name                = \"aws-conn\"\n  resource_group_name = azurerm_resource_group.rg.name\n  location            = azurerm_resource_group.rg.location\n  gateway_address = aws_customer_gateway.gw.ip_address\n  address_space     = [\"172.16.0.0/16\"]\n}\n리소스 \"azurerm_virtual_network_gateway_connection\" \"main\" {\n  name                       = \"aws-conn\"\n  resource_group_name        = azurerm_resource_group.rg.name\n  location                   = azurerm_resource_group.rg.location\n  type                       = \"IPsec\"\n  virtual_network_gateway_id = azurerm_virtual_network_gateway.vgw.id\n  local_network_gateway_id   = azurerm_local_network_gateway.lgw.id\n  shared_key = aws_vpn_connection.main.tunnel1_preshared_key\n\n  ipsec_policy {\n    dh_group         = \"DHGroup31\"\n    ike_encryption   = \"AES256\"\n    ike_integrity    = \"SHA256\"\n    ipsec_encryption = \"AES256\"\n    ipsec_integrity  = \"SHA256\"\n    pfs_group        = \"PFS31\"\n    sa_datasize      = 536870912\n  }\n}\n```\n\n이 방법을 통해 멀티 클라우드에 일관된 방식으로 전체 연결 구성을 정의할 수 있습니다.\n\n# 배포 패턴\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여러 클라우드로 배포할 때 블루-그린, 카나리아, 다중 지역과 같은 패턴을 사용하면 관리가 간단해질 수 있어요.\n\n블루-그린\n\n블루-그린은 새 버전을 병렬로 배포한 다음 트래픽을 원자적으로 전환합니다. 이는 롤백 및 점진적인 롤아웃 기능을 제공합니다.\n\n예시:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 파란 환경\nmodule \"blue_env\" {\n  source = \"./env\"\n  color  = \"blue\"\n}\n```\n\n```js\n# 초록 환경\nmodule \"green_env\" {\n  source = \"./env\"\n  color  = \"green\"\n  # 처음에는 트래픽이 없음\n  traffic_weight = 0\n}\n# 트래픽 분할기\nresource \"aws_lb\" \"main\" {\n  # 100%의 트래픽을 파란 쪽에 보냅니다.\n}\n```\n\n그런 다음 로드 밸런서를 통해 점진적으로 파란 색에서 초록 색으로 트래픽을 이동합니다.\n\n카나리아\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n파란색-초록색처럼 변경되지만 처음에는 일부 사용자에게만 공개됩니다.\n\n```js\nmodule \"prod_env\" {\n  source = \"./env\"\n```\n\n```js\n  # 대부분의 트래픽이 본 프로덕션 환경으로 이동합니다.\n}\nmodule \"canary_env\" {\n  source = \"./env\"\n  # 소수의 트래픽이 canary로 이동합니다.\n  traffic_weight = 0.1\n}\n```\n\nMulti-Region\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n고가용성 및 낮은 대기 시간을 위해 여러 지역에 리소스를 프로비저닝합니다.\n\n예를 들어:\n\n```js\n# 서부 지역\nmodule \"west\" {\n  source = \"./region\"\n  providers = {\n    azurerm.west = azurerm.west\n  }\n}\n```\n\n```js\n# 동부 지역\nmodule \"east\" {\n  source = \"./region\"\n  providers = {\n    azurerm.east = azurerm.east\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼 DNS와 로드 밸런싱을 사용하여 전 세계적으로 분산하세요.\n\n이러한 패턴은 멀티 클라우드 배포를 간단하게 해줍니다. 모듈 재사용은 일관성을 도와줍니다.\n\n# 통합 테스트\n\n여러 클라우드에 걸친 배포를 유효성 검사하려면 자동화된 통합 테스트가 필요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테라폼을 사용한 멀티 클라우드 테스팅을 위한 몇 가지 최상의 방법:\n\n- 인프라 테스트 — terraform plan 및 terraform show를 사용하여 올바른 구성의 리소스를 검증합니다.\n- 프로비저닝 테스트 — 처음부터 일회용 테스트 환경을 배포합니다.\n- 실패 테스트 — 종료된 인스턴스와 같은 실패를 시뮬레이션합니다.\n- 서비스 테스트 — 목업을 사용하여 서비스 접근성과 동작을 유효성 검사합니다.\n\n예를 들어, 일회용 테스트 환경을 생성하는 방법:\n\n```js\nmodule \"test_env\" {\n  source = \"./env\"\n  providers = {\n    aws = aws.test\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 Markdown 형식으로 변경해주세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다양한 환경에서 배포를 유효성 검사하려면 자동화된 테스트가 필요합니다.\n\nTerraform을 사용하는 몇 가지 권장사항:\n\n- 사용 및 폐기 가능한 테스트 환경 프로비저닝\n- 리소스 구성 검증\n- 다양한 장애 시나리오 시뮬레이션\n- 의존성에 대한 모의 테스트 사용\n\n예시:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nmodule \"test_env\" {\n  source = \"./env\"\n```\n\n```js\n  # AWS 계정 자격 증명 테스트\n}\nresource \"null_resource\" \"check_connectivity\" {\n  provisioner \"local-exec\" {\n    command = \"ping.exe -n 3 ${module.test_env.ip}\"\n  }\n}\n```\n\n이렇게 하면 안전하게 변경 사항을 테스트할 수 있는 격리된 환경이 생성됩니다.\n\n다른 예시:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 성능 테스트를 위해 과거 트래픽을 다시 재생합니다.\n- 종료된 인스턴스와 같은 결함을 주입합니다.\n- 결정론적 테스트를 위해 외부 서비스를 스텁 처리합니다.\n\n자동화된 테스트는 구성 요소를 리팩토링할 때 자신감을 유지하는 데 중요합니다.\n\n## 가시성\n\n이질적인 클라우드 간 로그, 지표 및 추적에 대한 가시성을 확보하는 것은 어렵습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테라폼을 사용하면 관측 가능성 데이터를 공유 플랫폼에 집계할 수 있습니다:\n\n로그 기능\n\n```js\nresource \"aws_cloudwatch_log_group\" \"app\" {\n  name = \"/aws/lambda/app\"\n}\nresource \"azurerm_monitor_diagnostic_setting\" \"app\" {\n  name               = \"diag\"\n  target_resource_id = azurerm_function_app.app.id\n  log_analytics_workspace_id = azurerm_log_analytics_workspace.main.id\n  log {\n    category = \"FunctionAppLogs\"\n    enabled  = true\n  }\n}\nresource \"google_logging_project_sink\" \"app\" {\n  name        = \"app-sink\"\n  destination = google_storage_bucket.logs.name\n}\n```\n\nSplunk와 같은 도구에서 로그를 중앙 집계하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n메트릭\n\n```js\n리소스 \"signalfx_detector\" \"지연시간\" {\n  이름 = \"높은 지연시간\"\n  프로그램_텍스트 = <<-EOF\n    A = 데이터('지연시간', 필터=필터('클라우드', '*') and 필터('환경', '*')).게시(label='A')\n    B = (A).합계(by=['클라우드', '환경']).게시(label='B')\n    detect(when(B > 1000, '5m')).게시('높은 지연시간!')\n  EOF\n}\n```\n\nDatadog와 같은 플랫폼에서 메트릭을 통합해보세요.\n\n트레이싱\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nmodule \"opentelemetry\" {\n  source = \"./opentelemetry\"\n  providers = {\n    aws = aws\n    azure = azurerm\n    google = google\n  }\n}\n```\n\n일반적인 형식으로 OpenTelemetry을 사용하면 추적을 쉽게 연결할 수 있어요.\n\n테라폼을 사용하면 다양한 플랫폼 사이에서 공유 관찰 패턴을 구축할 수 있어요.\n\n# 예시: 멀티-클라우드 웹 애플리케이션\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n실제로 멀티 클라우드 웹 애플리케이션을 Terraform으로 배포하는 실제 사례를 살펴봅시다.\n\nAWS ECS 및 Azure Container Instances (ACI)의 클러스터 전체에 애플리케이션 인프라를 배포할 것입니다. 글로벌 로드 밸런서가 트래픽을 플랫폼 간에 분배할 것입니다.\n\n네트워킹\n\n먼저, AWS VPC와 Azure VNet을 연결해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# AWS VPC 및 서브넷\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n```\n\n```js\nresource \"aws_subnet\" \"public\" {\n  vpc_id = aws_vpc.main.id\n  cidr_block = \"10.1.1.0/24\"\n}\n# Azure VNet\nresource \"azurerm_virtual_network\" \"main\" {\n  name                = \"app-network\"\n  address_space       = [\"10.2.0.0/16\"]\n}\nresource \"azurerm_subnet\" \"public\" {\n  name                 = \"public-subnet\"\n  resource_group_name  = azurerm_resource_group.main.name\n  virtual_network_name = azurerm_virtual_network.main.name\n  address_prefixes     = [\"10.2.1.0/24\"]\n}\n```\n\nVPC 피어링을 통해 이들을 연결하십시오:\n\n```js\n# AWS 쪽 피어링\nresource \"aws_vpc_peering_connection\" \"peer\" {\n  vpc_id      = aws_vpc.main.id\n  peer_vpc_id = azurerm_virtual_network.main.id\n  auto_accept = true\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# Azure 측 피어링\nresource \"azurerm_virtual_network_peering\" \"peer\" {\n  name                      = \"peer-aws\"\n  resource_group_name       = azurerm_resource_group.main.name\n  virtual_network_name      = az\n```\n\n컴퓨팅\n\nAzure Container Instances 배포:\n\n```js\nresource \"azurerm_container_group\" \"app\" {\n  name                = \"app-aci\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  ip_address_type     = \"public\"\n  dns_name_label      = \"app-aci\"\n  os_type             = \"Linux\"\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n  container {\n    name   = \"app\"\n    image  = \"myapp:v1\"\n    cpu    = \"1\"\n    memory = \"1\"\n    ports {\n      port     = 80\n      protocol = \"TCP\"\n    }\n  }\n```\n\n아마존 ECS 클러스터 및 서비스:\n\n```js\nresource \"aws_ecs_cluster\" \"main\" {\n  name = \"myapp-cluster\"\n}\n```\n\n```js\nresource \"aws_ecs_service\" \"web\" {\n  name            = \"web\"\n  cluster         = aws_ecs_cluster.main.id\n  task_definition = aws_ecs_task_definition.app.arn\n  desired_count   = 3\n  launch_type     = \"FARGATE\"\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n로드 밸런싱\n\n각 클라우드에 백엔드가 있는 글로벌 로드 밸런서를 배포하십시오:\n\n```js\nresource \"aws_lb\" \"web\" {\n  name               = \"myapp-lb\"\n  internal           = false\n\n  subnets = [\n    aws_subnet.public.id\n  ]\n}\n```\n\n```js\nresource \"azurerm_lb\" \"web\" {\n  name                = \"myapp-lb\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n\n  frontend_ip_configuration {\n    name                 = \"public\"\n    public_ip_address_id = azurerm_public_ip.main.id\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMarkdown 포맷으로 DNS\n\n로드 밸런서를 통해 단일 도메인을 라우팅합니다:\n\n```js\nresource \"aws_route53_zone\" \"main\" {\n  name = \"myapp.com\"\n}\n```\n\n```js\nresource \"aws_route53_record\" \"webapp\" {\n  zone_id = aws_route53_zone.main.id\n  name    = \"webapp.myapp.com\"\n  type = \"CNAME\"\n  ttl  = \"300\"\n  records = [aws_lb.web.dns_name]\n}\nresource \"azurerm_dns_cname_record\" \"webapp\" {\n  name                = \"webapp\"\n  zone_name           = azurerm_dns_zone.main.name\n  resource_group_name = azurerm_resource_group.main.name\n  ttl                 = 300\n  record              = azurerm_lb.web.fqdn\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이는 웹 애플리케이션을 다중 클라우드에서 실행하기 위한 핵심 인프라를 제공하며, 로드 밸런싱과 DNS를 통해 연결됩니다.\n\n테라폼 추상화는 우리에게 클라우드 플랫폼 간에 일관된 방식으로 아키텍처를 표현할 수 있는 기회를 제공합니다. 배포를 확장하고 필요에 따라 데이터베이스, 객체 저장소 및 캐시와 같은 추가 구성 요소를 추가할 수 있습니다.\n\n# 결론\n\n이 블로그에서는 테라폼을 사용하여 다중 클라우드 인프라, 네트워킹, 배포, 테스트 및 모니터링을 관리하는 패턴과 모범 사례를 다루었습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 추상화 — 추상화된 공급자 및 리소스를 사용하여 이식 가능한 구성물 생성\n- 모듈 — 복잡한 구성 요소를 재사용 가능한 모듈로 캡슐화\n- 상태 — 협업 가능하도록 원격 상태 저장\n- 네트워킹 — VPC와 VNET 간의 연결성 조정\n- 배포 — 블루-그린, 카나리아, 다중 지역 패턴 사용\n- 테스트 — 테스트 환경의 자동 프로비저닝\n- 가시성 — 로그, 메트릭 및 추적을 중앙 집중화\n\n테라폼은 각종 공용 클라우드, 개인 데이터 센터 및 SaaS 환경에서 인프라를 프로비저닝하고 관리하기 위한 일관된 워크플로우를 제공합니다. 이 가이드에서 다룬 패턴을 사용하면 다양한 API, 플랫폼 및 토폴로지를 연결하여 다중 클라우드 자동화 및 오케스트레이션을 더 쉽게 구현할 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-27-MasteringMulti-CloudManagementwithTerraform_0.png"},"coverImage":"/assets/img/2024-05-27-MasteringMulti-CloudManagementwithTerraform_0.png","tag":["Tech"],"readingTime":24},{"title":"GitOps와 Kubernetes, Terraform, Gitlab 그리고 FluxCD","description":"","date":"2024-05-27 17:43","slug":"2024-05-27-GitOpswithKubernetesTerraformGitlabandFluxCD","content":"\n<img src=\"/assets/img/2024-05-27-GitOpswithKubernetesTerraformGitlabandFluxCD_0.png\" />\n\n# 소개:\n\n이 블로그 포스트에서는 테라폼, gitlab, fluxcd 및 kustomize를 사용하여 엔드 투 엔드 gitops 워크플로를 설계하는 방법에 대해 논의하려고 합니다.\n\n그러나 구현 세부 정보에 대해 깊이 파고들기 전에, gitops가 다루는 문제 설명과 테라폼이 어떻게 관련되는지에 대해 이해해 봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# GitOps의 무엇과 왜\n\n현재 우리가 인프라를 구축하는 방식을 살펴보면 대부분의 경우 인프라를 코드로 구축하거나 적어도 대부분의 클라우드 인프라가 그러한 방식으로 구축됩니다. 인프라를 코드로 사용하는 것의 하나의 어려움은 코드베이스가 성장하고 더 많은 사람들이 개발 프로세스에 참여함에 따라 코드베이스를 유지하는 것이 어려워진다는 것입니다.\n\n이것이 바로 gitops가 나타나는 곳입니다. 핵심적으로 gitops는 git을 활용하여 인프라 코드의 코드 베이스를 유지하고 설정을 대상 환경에 자동으로 매칭하는 방식을 사용합니다. 이러한 방식으로 우리는 이전보다 빠르게 배포할 수 있을 뿐만 아니라 시간이 지남에 따라 무엇이 변경되었는지 완전한 기록이 있기 때문에 이전보다 빨리 오류를 감지하고 복구할 수 있습니다.\n\n# GitOps에 대한 Terraform 선택이유\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금쯤이면 terraform이 어떻게 관련되며 어떻게 도움이 되는지 궁금해할 수 있습니다. 이전 섹션에서는 구성을 매치하는 자동화된 방법에 대해 이야기했습니다. 일반적인 Kubernetes 환경에서는 fluxcd와 같은 도구를 사용하여 이를 수행합니다. 그러나 이러한 추가 구성과 설정이 필요합니다. 여기서 terraform이 등장합니다. terraform을 사용하면 인프라를 구축할 뿐만 아니라 flux와 같은 도구를 설치하고 구성할 수도 있습니다. 이렇게 하면 한 번에 Kubernetes 클러스터를 구축하고 flux를 부트스트랩하며 그에 따라 gitops 워크플로우를 설정할 수 있습니다. 이렇게 하면 처음부터 완전히 기능적인 gitops 워크플로우가 구축됩니다.\n\n## 도구 개요:\n\n## FluxCD:\n\nFlux는 Kubernetes 클러스터를 구성 소스(예: Git 저장소)와 동기화하고 새 코드를 배포할 때 구성을 자동으로 업데이트하는 도구입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Gitlab:\n\nGitLab은 응용 프로그램 빌드 및 릴리스 프로세스를 자동화하는 데 도움이되는 CI/CD 도구입니다.\n\n# Terraform:\n\nTerraform을 사용하면 선언적 구성 언어를 사용하여 가상 머신, 네트워크, 저장소 및 기타 클라우드 서비스와 같은 인프라 리소스를 정의하고 프로비저닝할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 우리가 만들 것:\n\n해결책에서는 nginx 앱을 eks 클러스터에 배포하고, flux를 사용하여 eks 클러스터에 대한 배포를 관리하며, 인프라 프로비저닝 및 flux 부트스트랩 구성을 위해 terraform을 사용합니다.\n\n# 설정\n\n# 준비 사항:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n1) AWS 계정\n2) Gitlab 클라우드 계정 / 자체 호스팅된 Gitlab\n3) 로컬 시스템에 설치된 최신 버전의 Terraform\n\n# 환경 설정:\n\n## AWS 설정:\n\nECR Repository 생성\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAWS ECR 레지스트리에 로그인합니다.\n\n```bash\naws ecr get-login-password | docker login --username AWS --password-stdin <aws_account_id>.dkr.ecr.<region>.amazonaws.com\n```\n\nDocker Hub에서 Nginx 이미지를 가져옵니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 pull nginx:latest\n```\n\n당신의 ECR 저장소에 Nginx 이미지를 태그하기\n\n```js\n도커 tag nginx:latest <aws_account_id>.dkr.ecr.<region>.amazonaws.com/nginx-repo:0.0.1\n```\n\n이미지를 ECR 저장소에 푸시하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n도커 푸시 <aws_account_id>.dkr.ecr.<region>.amazonaws.com/nginx-repo:0.0.1\n```\n\n## Gitlab 설정\n\nPAT 토큰 생성\n\n```js\n- GitLab 인스턴스에 로그인하세요\n- 프로필 아이콘을 클릭하세요\n- 환경설정을 클릭한 후에 접근 토큰을 클릭하세요\n- 토큰의 이름을 입력하고 만료 날짜를 설정하세요\n- 그 다음에 api 라는 scopes 아래의 첫 번째 확인란을 선택하세요\n- 개인 접근 토큰 만들기를 클릭한 후에 토큰을 표시하세요\n- 토큰을 저장하세요.\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n프로젝트 설정:\n\n```js\n- gitlab의 클라우드 인스턴스에서 새 프로젝트 버튼을 클릭합니다.\n- 빈 프로젝트 생성을 클릭합니다.\n- 프로젝트 이름을 제공합니다 (나중에 사용할 이름을 메모해 둡니다).\n- 프로젝트 URL 옆의 드롭 다운에서 그룹 이름을 선택하고,\n   이 그룹 이름을 나중에 사용할 것이니 메모해 둡니다.\n- 프로젝트를 위한 이름을 제공합니다.\n- 가시성을 선택합니다.\n- 프로젝트를 저장합니다.\n- 코드 버튼을 클릭하고, https용 github URL을 복사하여\n  나중에 필요할 때를 대비하여 URL을 메모해 둡니다.\n```\n\n## Terraform 설정\n\nTerraform 구성 및 스니펫을 사용하여 인프라를 구축하기 전에 아래 명령어를 사용하여 AWS 자격 증명을 설정해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAWS 자격 증명 설정\n\n```js\n% export AWS_ACCESS_KEY_ID=\"anaccesskey\"\n% export AWS_SECRET_ACCESS_KEY=\"asecretkey\"\n% export AWS_REGION=\"us-west-2\"\n```\n\n위 설정을 완료한 후 로컬 환경에서 gitlab 토큰을 설정해야 합니다. 아래 섹션에서 그 방법을 안내하겠습니다. gitlab 설정 섹션에서 pat 토큰 섹션에서 복사한 토큰을 붙여넣어주세요.\n\nGitLab 토큰 설정 (Linux/MacOS)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nexport GITLAB_TOKEN=<Gitlab 설정에서 저장한 토큰>\n```\n\nWindows\n\n```js\n$env: GITLAB_TOKEN = \"<Gitlab 설정에서 저장한 토큰>\";\n```\n\n# 안내:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 데모 레포지토리 복제\n\n```js\ngit clone https://gitlab.com/devops5480719/devops-samples.git\n```\n\n그런 다음 인프라 디렉토리로 이동하세요\n\n```js\ncd devops-samples/gitops-gitlab/infra/\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n디렉토리 안으로 들어가시면 아래의 파일과 폴더를 찾을 수 있어요.\n\n```js\n├── config_files\n│   ├── app-nginx.yml\n│   ├── ecr-sync.yml\n│   └── nginx.yml\n├── main.tf\n├── variables.tf\n└── versions.tf\n```\n\n안에 config_files라는 폴더가 있고, 몇 개의 terraform 파일도 있어요.\n\n우선 terraform 파일들을 자세히 살펴보도록 해봐요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 변수 구성\n\n먼저 변수 구성을 살펴봅시다.\n\nvariables.tf\n\n```js\nvariable \"gitlab_group\" {\n  type = string\n  default = <gitlab 그룹의 이름>\n}\n\nvariable \"gitlab_project\" {\n  type = string\n  default = <gitlab 프로젝트의 이름>\n}\n\nvariable \"aws_region\" {\n  type = string\n  default = <리소스를 배포할 AWS 지역의 이름>\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위 코드 조각에서 기본 값 대신에 gitlab 섹션에서 이전에 복사한 이름이있는 gitlab_group으로 대체하십시오. gitlab_project에 대해서도 마찬가지입니다.\n\naws_region으로는 리소스를 배포할 지역을 선택하십시오.\n\n## 공급자 구성\n\n이제 versions.tf 파일에서 공급자 구성을 살펴봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n변수.tf 파일에는 인증 및 권한 부여를 위한 각 프로바이더 블록의 필수 구성 및 필수 제공자가 포함되어 있습니다.\n\n버전.tf\n\n```js\nrequired_providers {\n    flux = {\n      source  = \"fluxcd/flux\"\n      version = \">= 1.0.0\"\n    }\n    gitlab = {\n      source  = \"gitlabhq/gitlab\"\n      version = \">=15.10.0\"\n    }\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \">= 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \">= 2.16.1\"\n    }\n  }\n}\nprovider \"gitlab\" {\n  base_url = \"https://gitlab.com/api/v4/\"\n}\nprovider \"flux\" {\n  kubernetes = {\n    host                   = module.eks.endpoint\n    cluster_ca_certificate = base64decode(module.eks.cluster_ca_certificate)\n    exec = {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", var.cluster_name]\n      command     = \"aws\"\n    }\n  }\n  git = {\n    url = \"ssh://git@gitlab.com/${data.gitlab_project.this.path_with_namespace}.git\"\n    ssh = {\n      username    = \"git\"\n      private_key = tls_private_key.flux.private_key_pem\n    }\n    branch = \"main\"\n  }\n}\n```\n\n## 리소스 구성:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n자원 구성을 살펴보겠습니다.\n\nVPC 구성\n\nmain.tf\n\n```js\nmodule \"vpc\" {\n  source = \"terraform-aws-modules/vpc/aws\"\n  name = \"flux-vpc\"\n  cidr = \"10.0.0.0/16\"\n  azs = [\"<aws-region>a\", \"<aws-region>b\", \"<aws-region>c\"]\n  private_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\", \"10.0.4.0/24\", \"10.0.5.0/24\", \"10.0.6.0/24\"]\n  public_subnets = [\"10.0.101.0/24\", \"10.0.102.0/24\", \"10.0.103.0/24\"]\n  enable_nat_gateway = true\n  enable_vpn_gateway = false\n  single_nat_gateway = true\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = \"1\"\n  }\n  tags = {\n    Terraform = \"true\"\n    Environment = \"dev\"\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nEKS 구성\n\nEKS를 위해 아래 리소스를 정의할 것입니다.\n\n- EKS 클러스터\n- kubeconfig를 컨텍스트에 추가하기 위한 Null 리소스\n\nmain.tf\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모듈 \"eks\" {\nsource = \"terraform-aws-modules/eks/aws\"\nversion = \"~> 20.0\"\ncluster_name = \"flux-cluster\"\ncluster_version = \"1.29\"\ncluster_endpoint_private_access = true\ncluster_endpoint_public_access = true\ncloudwatch_log_group_retention_in_days = 7\ncloudwatch_log_group_class = \"INFREQUENT_ACCESS\"\ncluster_enabled_log_types = [\"api\"]\nvpc_id = module.vpc.vpc_id\nsubnet_ids = module.vpc.private_subnets\ncluster_addons = {\ncoredns = {\nmost_recent = true\n}\nkube-proxy = {\nmost_recent = true\n}\naws-ebs-csi-driver = {\nmost_recent = true\n}\neks-pod-identity-agent = {\nmost_recent = true\n}\nvpc-cni = {\nmost_recent = true\n}\n}\neks_managed_node_group_defaults = {\nami_type = \"AL2_x86_64\"\ndisk_size = 50\ninstance_types = [\"t3.large\"]\ncapacity_type = \"SPOT\"\nupdate_config = {\nmax_unavailable_percentage = 100\n}\n}\neks_managed_node_groups = {\nps-cluster-sample = {\nmin_size = 1\ndesired_size = 1\nmax_size = 4\ninstance_types = [\"t3.large\"]\ncapacity_type = \"SPOT\"\n}\n}\nenable_cluster_creator_admin_permissions = false\naccess_entries = {\nadmin_sso = {\nkubernetes_groups = []\nprincipal_arn = \"<arn of the role or the user to which you want to grant admin privileges>\"\npolicy_associations = {\nClusterAdmin = {\npolicy_arn = \"arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy\"\naccess_scope = {\ntype = \"cluster\"\n}\n}\nEKSAdmin = {\npolicy_arn = \"arn:aws:eks::aws:cluster-access-policy/AmazonEKSAdminPolicy\"\naccess_scope = {\ntype = \"cluster\"\n}\n}\n}\n}\n}\n}\nresource \"null_resource\" \"update_kubeconfig\" {\ntriggers = {\neks_cluster_id = module.eks.cluster_id\n}\nprovisioner \"local-exec\" {\ncommand = \"aws eks update-kubeconfig --name ${module.eks.cluster_name} --region ${var.aws_region}\"\n}\n}\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n자바스크립트\n리소스 \"tls_private_key\" \"flux\" {\n  depends_on = [module.eks, module.vpc, null_resource.update_kubeconfig]\n  algorithm   = \"ECDSA\"\n  ecdsa_curve = \"P256\"\n}\n데이터 \"gitlab_project\" \"this\" {\n  path_with_namespace = \"${var.gitlab_group}/${var.gitlab_project}\"\n}\n리소스 \"gitlab_deploy_key\" \"this\" {\n  depends_on = [module.eks, module.vpc]\n  project  = data.gitlab_project.this.id\n  title    = \"Flux\"\n  key      = tls_private_key.flux.public_key_openssh\n  can_push = true\n}\n리소스 \"flux_bootstrap_git\" \"this\" {\n  depends_on = [gitlab_deploy_key.this, module.eks, module.vpc, null_resource.update_kubeconfig]\n  path = \"clusters/${module.eks.cluster_name}\"\n  components_extra = [\"image-reflector-controller\",\"image-automation-controller\"]\n}\n로컬 {\n  yaml_files = fileset(\"${path.module}/config_files\", \"*.yml\")\n  yaml_content = { for file in local.yaml_files : file => file(\"${path.module}/config_files/${file}\") }\n}\n리소스 \"gitlab_repository_file\" \"yaml_files\" {\n  depends_on = [flux_bootstrap_git.this, null_resource.update_kubeconfig]\n  for_each = local.yaml_content\n  project = data.gitlab_project.this.id // 새 프로젝트를 생성한 경우 기존 프로젝트나 gitlab_project.example_project.id의 프로젝트 ID를 사용하십시오.\n  file_path = \"clusters/${module.eks.cluster_name}/${each.key}\"\n  content   = base64encode(each.value)\n  commit_message = \"added flux image configs\"\n  branch    = \"main\"\n}\n```\n\n위의 코드 조각에서는 flux_bootstrap_git 리소스에 image-reflector-controller 및 image-automation-controller라는 두 가지 추가 컴포넌트를 추가하고 있습니다.\n\n이 두 컨트롤러는 ECR 리포지토리에서 태그를 가져오거나 업데이트할 책임을 질 것입니다.\n\nflux가 이 작업을 수행하려면 복제 데모 리포지토리의 config_files 폴더에서 찾을 수 있는 몇 가지 추가 구성 요소를 정의해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n├── config_files\n│ ├── app-nginx.yml\n│ ├── ecr-sync.yml\n│ └── nginx.yml\n├── main.tf\n├── variables.tf\n└── versions.tf\n\n이제 이 파일들 각각을 살펴보고 그 내용을 살펴보겠습니다. 우선 app-nginx.yaml 파일부터 시작해봅시다.\n\napp-nginx.yaml\n\n```yaml\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: nginx-auth-pat\n  namespace: flux-system\ntype: Opaque\ndata:\n  password: < gitlab 토큰을 base64로 인코딩 된 문자열 >\n  username: < 사용자 이름을 base64로 인코딩 된 문자열 >\n---\napiVersion: source.toolkit.fluxcd.io/v1\nkind: GitRepository\nmetadata:\n  name: nginx\n  namespace: flux-system\nspec:\n  interval: 1m0s\n  ref:\n    branch: main\n  url: <gitlab_repo_url>\n  secretRef:\n    name: nginx-auth-pat\n---\napiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\n  name: nginx\n  namespace: flux-system\nspec:\n  prune: true\n  interval: 1m0s\n  path: \"./app/nginx/environments/production\"\n  sourceRef:\n    kind: GitRepository\n    name: nginx\n---\napiVersion: image.toolkit.fluxcd.io/v1beta2\nkind: ImageRepository\nmetadata:\n  name: nginx\n  namespace: flux-system\nspec:\n  image: <aws-account-id>.dkr.ecr.<region>.amazonaws.com/<image name>\n  interval: 1m0s\n  secretRef:\n    name: ecr-credentials\n---\napiVersion: image.toolkit.fluxcd.io/v1beta2\nkind: ImagePolicy\nmetadata:\n  name: nginx\n  namespace: flux-system\nspec:\n  imageRepositoryRef:\n    name: nginx\n  policy:\n    semver:\n      range: 0.0.x\n---\napiVersion: image.toolkit.fluxcd.io/v1beta1\nkind: ImageUpdateAutomation\nmetadata:\n  name: nginx\n  namespace: flux-system\nspec:\n  interval: 1m0s\n  sourceRef:\n    kind: GitRepository\n    name: nginx\n  git:\n    checkout:\n      ref:\n        branch: main\n    commit:\n      author:\n        email: flux@example.com\n        name: flux\n      messageTemplate: \"{range .Updated.Images}{println .}{end}\"\n    push:\n      branch: main\n  update:\n    path: ./clusters/flux-cluster/nginx.yml\n    strategy: Setters\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위 구성에서는 아래 구성 요소를 정의했습니다:\n\n- Secret: 우리는 gitlab 설정 섹션에서 만든 base64로 인코딩된 pat 토큰 및 gitlab의 git repo에 대한 사용자 이름을 정의했습니다. 사용자 이름은 terraform의 provider 섹션 구성에 따라 'git'을 사용했습니다.\n- GitRepository: 이는 flux가 yaml 파일을 폴링할 gitlab 리포지토리 URL입니다. 이는 gitlab 설정 섹션에서 만든 파일입니다.\n- ImageRepository: 특정 태그 집합을 스캔하고 저장할 리포지토리를 정의했습니다.\n- ImagePolicy: 이미지 리포지토리에서 \"latest\" 이미지를 선택하는 규칙을 정의합니다.\n- ImageUpdateAutomation: 동일한 네임스페이스 내의 이미지 정책 객체를 기반으로 git 리포지토리를 업데이트할 자동화 프로세스를 정의합니다.\n\nImageUpdateAutomation 아래 파일에서, flux가 이미지 태그를 업데이트할 경로를 .spec.update.path 아래 ./clusters/flux-cluster/nginx.yml로 정의했습니다. 이것은 flux에 이미지 태그를 업데이트할 위치를 알려줍니다.\n\n위 구성 이후에는 또한 ecr 동기화 파일을 정의해야 합니다. 이 파일은 ecr에 대한 인증을 자동화하고 이미지 자동화 컨트롤러가 ecr 리포지토리에서 이미지 태그를 가져올 수 있도록 합니다. 아래 파일은 매 6시간마다 ecr에서 인증하는 데 필요한 권한을 가진 크론 작업을 설정하고 비밀 정보를 업데이트합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: ecr-credentials-sync\n  namespace: flux-system\nrules:\n  - apiGroups: [\"\"]\n    resources:\n      - secrets\n    verbs:\n      - get\n      - create\n      - patch\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: ecr-credentials-sync\n  namespace: flux-system\nsubjects:\n  - kind: ServiceAccount\n    name: ecr-credentials-sync\nroleRef:\n  kind: Role\n  name: ecr-credentials-sync\n  apiGroup: \"\"\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: ecr-credentials-sync\n  namespace: flux-system\n  # Uncomment and edit if using IRSA\n  # annotations:\n  #   eks.amazonaws.com/role-arn: <role arn>\n---\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: ecr-credentials-sync\n  namespace: flux-system\nspec:\n  suspend: false\n  schedule: 0 */6 * * *\n  failedJobsHistoryLimit: 1\n  successfulJobsHistoryLimit: 1\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: ecr-credentials-sync\n          restartPolicy: Never\n          volumes:\n            - name: token\n              emptyDir:\n                medium: Memory\n          initContainers:\n            - image: amazon/aws-cli\n              name: get-token\n              imagePullPolicy: IfNotPresent\n              # You will need to set the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables if not using\n              # IRSA. It is recommended to store the values in a Secret and load them in the container using envFrom.\n              # envFrom:\n              # - secretRef:\n              #     name: aws-credentials\n              env:\n                - name: REGION\n                  value: us-east-1 # change this if ECR repo is in a different region\n              volumeMounts:\n                - mountPath: /token\n                  name: token\n              command:\n                - /bin/sh\n                - -ce\n                - aws ecr get-login-password --region ${REGION} > /token/ecr-token\n          containers:\n            - image: ghcr.io/fluxcd/flux-cli:v0.25.2\n              name: create-secret\n              imagePullPolicy: IfNotPresent\n              env:\n                - name: SECRET_NAME\n                  value: ecr-credentials\n                - name: ECR_REGISTRY\n                  value: <account id>.dkr.ecr.<region>.amazonaws.com # fill in the account id and region\n              volumeMounts:\n                - mountPath: /token\n                  name: token\n              command:\n                - /bin/sh\n                - -ce\n                - |-\n                  kubectl create secret docker-registry $SECRET_NAME \\\n                    --dry-run=client \\\n                    --docker-server=\"$ECR_REGISTRY\" \\\n                    --docker-username=AWS \\\n                    --docker-password=\"$(cat /token/ecr-token)\" \\\n                    -o yaml | kubectl apply -f -\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 1\n  template:\n    spec:\n      containers:\n        - name: nginx\n          image: <aws-account-id>.dkr.ecr.<aws-region>.amazonaws.com/nginx:0.0.0 # {\"$imagepolicy\": \"flux-system:nginx\"}\n```\n\n위의 두 줄 # '\"$imagepolicy\": \"flux-system:nginx\"' 는 flux-system이 네임스페이스이고 nginx가 이미지 정책의 이름임을 나타내는 표식입니다. 이는 app-nginx.yml 파일에서 정의된 자동화 구성과 일치해야 합니다.\n\n이 작은 단편은 flux에게 컨테이너 이미지를 업데이트할 때 사용해야 하는 정책을 알려줍니다.\n\n이 모든 파일은 이것을 적용하기 위해 flux 폴더로 복사되어 메인.tf 파일의 아래 코드 단편을 통해 eks 클러스터에 적용될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nlocals {\n  yaml_files = fileset(\"${path.module}/config_files\", \"*.yml\")\n  yaml_content = { for file in local.yaml_files : file => file(\"${path.module}/config_files/${file}\") }\n}\nresource \"gitlab_repository_file\" \"yaml_files\" {\n  depends_on = [flux_bootstrap_git.this, null_resource.update_kubeconfig]\n  for_each = local.yaml_content\n  project = data.gitlab_project.this.id // Use the project ID of an existing project or gitlab_project.example_project.id if you created a new project\n  file_path = \"clusters/${module.eks.cluster_name}/${each.key}\"\n  content   = base64encode(each.value)\n  commit_message = \"added flux image configs\"\n  branch    = \"main\"\n}\n```\n\n# 배포:\n\n그 다음 아래 명령어를 실행하여 Terraform 초기화를 수행하십시오.\n\n```js\nterraform init\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그럼 진행되는 모든 리소스를 확인하려면 plan 명령어를 실행해주세요.\n\n```js\nterraform plan\n```\n\n그 다음에는 테라폼 설정을 적용할 수 있어요.\n\n```js\nterraform apply --auto-approve\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래 Terraform이 다음 작업을 수행할 것입니다.\n\n```js\nVPC 및 지원 리소스 생성\nEKS 클러스터 및 지원 리소스 생성\nEKS와 함께 Flux를 부트스트랩하고 모든 구성 및 애플리케이션 파일을 GitLab 저장소에 저장\n```\n\nTerraform 실행이 완료되면 아래 명령을 실행하세요.\n\n```js\nkubectl get po -n flux-system\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래의 Flux 구성 요소가 모두 실행 중인 것을 확인해야 합니다.\n\n```js\nNAME                                           READY   STATUS    RESTARTS   AGE\nhelm-controller-5f7457c9dd-6svk8               1/1     Running   0          40s\nimage-automation-controller-79447887bb-blqp4   1/1     Running   0          40s\nimage-reflector-controller-65df777f5c-nrgsx    1/1     Running   0          40s\nkustomize-controller-5f58d55f76-tpgs6          1/1     Running   0          40s\nnotification-controller-685bdc466d-mp46f       1/1     Running   0          40s\nsource-controller-86b8b57796-vl2fp             1/1     Running   0          39s\n```\n\n이제 모든 구성 요소가 실행 중이므로, ecr 비밀 cron 작업이 실행되었는지 확인해보겠습니다. 터미널에서 다음 명령을 실행하세요.\n\n```js\nkubectl get cronjob -n flux-system\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래 출력을 얻어야 합니다.\n\n```js\nNAME                   SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE\necr-credentials-sync   0/1 * * * *   False     0        51초           2분 42초\n```\n\n이제 flux-system 네임스페이스에 시크릿이 있는지 확인해 보겠습니다. 아래 출력이 표시되어야 합니다:\n\n```js\nk get secret -n flux-system\n\nNAME              TYPE                             DATA   AGE\necr-credentials   kubernetes.io/dockerconfigjson   1      3분 7초\nflux-system       Opaque                           3      5분 39초\nnginx-auth-pat    Opaque                           2      4분 19초\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 출력에서 확인할 수 있듯이 ecr-credentials라는 시크릿이 있습니다.\n\n이제 ecr을 확인해 봅시다.\n\n이제 flux 이미지 컨트롤러가 우리의 ecr 저장소에서 태그를 가져올 수 있는지 확인해 보겠습니다.\n\n```js\nflux get image all\nNAME                   LAST SCAN                       SUSPENDED       READY   MESSAGE\nimagerepository/nginx   2024-05-23T16:55:46+05:30       False           True    successful scan: found 2 tags\nNAME                    LATEST IMAGE                                                    READY   MESSAGE\nimagepolicy/nginx       <aws-account-id>.dkr.ecr.<aws-region>.amazonaws.com/nginx:0.0.1       True    '<aws-account-id>.dkr.ecr.<aws-region>.amazonaws.com/nginx'의 최신 이미지 태그가 0.0.1로 해결되었습니다\nNAME                            LAST RUN                        SUSPENDED       READY   MESSAGE\nimageupdateautomation/nginx     2024-05-23T16:55:39+05:30       False           True    레포지토리가 최신 상태입니다\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 출력에서 볼 수 있듯이, 이미지 정책은 ECR에서 최신 이미지 태그를 스캔하고 가져왔습니다.\n\n이제 아래 명령을 사용하여 배포에 동일한 업데이트가 반영되었는지 확인해봅시다:\n\n```js\nkubectl get deployment nginx-deployment -o=jsonpath='{.spec.template.spec.containers[*].image}' | awk -F '[:@]' '{print $1, $2}'\n```\n\n아래는 우리가 얻은 출력입니다. 이미지가 업데이트된 것을 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n<aws-account-id>.dkr.ecr.<aws-region>.amazonaws.com/nginx:0.0.1\n```\n\n이제 깃랩 쪽으로 이동하여 플럭스가 필요한 변경 사항을 수행했는지 확인해보세요.\n\nUI를 통해 레포지토리의 커밋 히스토리를 확인하거나 레포지토리를 복제한 후 아래 명령어를 실행할 수 있습니다.\n\n아래 명렁어를 실행해보세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```bash\ngit log --author=\"flux\" --since=\"today 00:00\" --until=\"today 23:59\" --pretty=format:\"%h %s\" -- clusters/flux-cluster/nginx.yml\n```\n\n아래는 출력된 내용입니다:\n\n```bash\n85e5b48 <aws-account-d>.dkr.ecr.<aws-region>.amazonaws.com/nginx:0.0.1\n```\n\n위의 출력에서 확인할 수 있듯이 flux가 nginx.yml 파일에서 임의의 이미지 번호에서 실제 태그로 이미지를 업데이트했으며, 동일한 업데이트가 배포에서 수행되었습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이미지의 새로운 버전을 푸시해보고 flux가 자동으로 업데이트되는지 확인해봐요.\n\nECR 저장소에 Nginx 이미지를 태그해보세요.\n\n```js\ndocker tag nginx:latest <aws_account_id>.dkr.ecr.<region>.amazonaws.com/nginx-repo:0.0.2\n```\n\n이제 아래 명령어를 사용하여 배포가 정상적으로 업데이트되었는지 확인해보세요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 표시되는 출력 값 입니다:\n\n```bash\n<aws-account-id>.dkr.ecr.<aws-region>.amazonaws.com/nginx:0.0.2\n```\n\n# 결론\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래서 결론적으로, 우리는 flux, gitlab, terraform, kubernetes를 사용하여 gitops 워크플로우를 설정했고, 새 이미지를 컨테이너 저장소에 푸시할 때마다 flux가 배포를 관리할 것입니다.\n\n# 참고 자료:\n\nFlux 문서: [https://fluxcd.io/flux/](https://fluxcd.io/flux/)\n","ogImage":{"url":"/assets/img/2024-05-27-GitOpswithKubernetesTerraformGitlabandFluxCD_0.png"},"coverImage":"/assets/img/2024-05-27-GitOpswithKubernetesTerraformGitlabandFluxCD_0.png","tag":["Tech"],"readingTime":30},{"title":"아마존 EKS 업그레이드 여정 129에서 130으로 - 귀여운 우베르네티스를 만나보세요","description":"","date":"2024-05-27 17:41","slug":"2024-05-27-AmazonEKSUpgradeJourneyFrom129to130-sayhellotocuteUwubernetes","content":"\n\"Uwubernetes\" 릴리스를 환영합니다. EKS 제어 평면을 버전 1.30으로 업그레이드하는 과정 및 주의 사항.\n\n![이미지](/assets/img/2024-05-27-AmazonEKSUpgradeJourneyFrom129to130-sayhellotocuteUwubernetes_0.png)\n\n# 개요\n\nAWS EKS 1.30에 오신 것을 환영합니다. 이것은 Kubernetes v1.30 릴리스로, 당신의 클러스터를 더 귀여워 지게 만듭니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKubernetes는 전 세계의 수천 명의 사람들이 만들고 공개하는데, 그들은 모든 삶의 영역에서 온 사람들입니다. 대부분의 기여자들은 이를 위해 돈을 받지 않지만, 재미로 만들거나 문제를 해결하거나, 무언가를 배우거나, 커뮤니티를 사랑하기 때문에 만듭니다. 우리 중 많은 사람들이 여기서 집, 친구, 그리고 직업을 찾았습니다. 릴리스 팀은 Kubernetes의 지속적인 성장에 참여하여 영광으로 생각합니다.\n\n한번 더 커뮤니티에 대해 감사 인사를 전하고자 합니다. 많은 회사들에서는 전문가들이 가치를 인정받지 못하고 간과되는 경우가 많지만, 이는 옳지 않습니다. 그래서 이를 대중에게 알리고 싶습니다.\n\nKubernetes v1.30: Uwubernetes, 이제까지 가장 귀여운 릴리스입니다. 이 이름은 \"kubernetes\"와 \"UwU\"라는 행복이나 귀여움을 나타내는 이모티콘의 합성어입니다.\n\n# 이전 이야기와 업그레이드\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 당신이 다음을 찾고 있다면\n\n- EKS를 1.28에서 1.29로 업그레이드하려면 이 이야기를 확인해보세요\n- EKS를 1.27에서 1.28로 업그레이드하려면 이 이야기를 확인해보세요\n- EKS를 1.26에서 1.27로 업그레이드하려면 이 이야기를 확인해보세요\n- EKS를 1.25에서 1.26으로 업그레이드하려면 이 이야기를 확인해보세요\n- EKS를 1.24에서 1.25로 업그레이드하려면 이 이야기를 확인해보세요\n- EKS를 1.23에서 1.24로 업그레이드하려면 이 이야기를 확인해보세요\n\n![이미지](https://miro.medium.com/v2/resize:fit:836/0*gWRKqyTE1gOT5wiD.gif)\n\n# 업그레이드를 위한 필수 조건\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAmazon EKS의 Kubernetes v1.30로 업그레이드하기 전에 완료해야 할 중요한 작업이 몇 가지 있습니다. 이 작업들은 \"업그레이드 인사이트\"에서 쉽게 확인할 수 있습니다. 제 경우에는 항상 클러스터를 최신 상태로 유지하고 있어서 완료해야 할 작업이 없었습니다.\n\n# Kubernetes 1.30- 이 릴리스에서 변경 사항\n\n항상 Kubernetes 버전 1.30에서의 변경 사항과 업데이트의 완전한 목록을 찾으려면 Kubernetes 변경 로그를 확인하십시오. 아래에서 v1.30 릴리스에 중요한 개선 사항 몇 가지를 찾을 수 있습니다. 전체 목록은 여기를 확인해주세요.\n\n## Kubernetes v1.30에서 안정 버전으로 졸업한 개선 사항\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Robust VolumeManager 재구성 후 kubelet 재시작. 이것은 kubelet이 시작될 때 기존 볼륨이 어떻게 마운트되는지에 대한 추가 정보를 제공하도록 볼륨 관리자를 재구성하는 것입니다. 사용자나 클러스터 관리자에게는 어떤 변화도 가져오지 않습니다. 이것은 이전 동작으로 되돌아갈 수 있도록 feature process와 feature gate NewVolumeManagerReconstruction을 사용합니다.\n- 볼륨 복원 중 무단으로 볼륨 모드 변환 방지. 이 릴리스에서, 볼륨을 PersistentVolume로 복원할 때 컨트롤 플레인은 항상 무단으로 볼륨 모드를 변경하는 것을 방지합니다. 클러스터 관리자로서, 복원 시 그러한 변경을 허용하려면 적절한 신원 원칙(ServiceAccounts representing a storage integration과 같은)에 권한을 부여해야 합니다.\n- Pod 스케줄링 준비 상태. 지금 안정적인 상태인 이 기능은 클러스터가 실제로 그 Pod를 노드에 바인딩할 수 있도록 필요한 리소스가 아직 제공되지 않을 때 Kubernetes가 해당 Pod를 스케줄링하려는 시도를 피하도록 합니다. 또한 Pod가 스케줄링될 수 있는지 여부에 대한 사용자 정의 제어를 제공하고 할당량 메커니즘, 보안 제어 등을 구현할 수 있도록 합니다. k8s v1.30에서 .spec.schedulingGates를 지정하여 Pod가 스케줄링에 고려될 준비가 되었는지를 제어할 수 있습니다.\n- PodTopologySpread의 최소 도메인. 이번 릴리스에서 PodTopologySpread 제약 조건의 minDomains 매개변수가 안정적으로 졸업했으며 최소 도메인 수를 정의할 수 있게 되었습니다. 이 기능은 Cluster Autoscaler와 함께 사용하도록 설계되었습니다. 저는 개인적으로 Karpenter를 사용하고 있기 때문에 제 상황에서 큰 변화를 가져다주지는 않을 것입니다.\n\n여기에 안정화된 17가지 개선 사항의 전체 목록이 있습니다:\n\n- Container Resource를 기반으로 하는 Pod Autoscaling\n- KCCM의 서비스 컨트롤러에서 일시적인 노드 예측 삭제\n- k/k를 위한 Go 작업 영역\n- Secret 기반 서비스 계정 토큰의 감소\n- Admission Control을 위한 CEL\n- CEL 기반의 admission webhook match 조건\n- Pod 스케줄링 준비 상태\n- PodTopologySpread의 최소 도메인\n- 볼륨 복원 중 무단으로 볼륨 모드 변환 방지\n- API 서버 추적\n- 클라우드 듀얼 스택 - 노드 IP 처리\n- AppArmor 지원\n- kubelet 재시작 후 강력한 VolumeManager 재구성\n- kubectl delete: 상호작용(-i) 플래그 추가\n- 메트릭 카디널리티 강제 실행\n- Pod에 status.hostIPs 필드 추가\n- 집합 된 발견\n\n# 테라폼을 사용하여 EKS를 업그레이드하세요\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내 모든 업그레이드와 마찬가지로, 나는 Terraform을 사용합니다. 이는 빠르고 효율적이며 내 삶을 간편하게 만들어줍니다. 이번 업그레이드에 사용한 프로바이더는 다음과 같습니다:\n\n![이미지1](/assets/img/2024-05-27-AmazonEKSUpgradeJourneyFrom129to130-sayhellotocuteUwernetes_1.png)\n\n![이미지2](/assets/img/2024-05-27-AmazonEKSUpgradeJourneyFrom129to130-sayhellotocuteUwernetes_2.png)\n\n이번에는 컨트롤 플레인의 업그레이드에 약 8분 정도 소요되었습니다. 이것은 정말 빠르다고 생각해요. 업그레이드 후에는 어떠한 문제도 경험하지 않았습니다. 이전 업그레이드에서 있었던 API 서버 자체의 일시적인 사용 불가 상황조차도 전혀 인지하지 못했을 정도입니다. AWS는 EKS 컨트롤 플레인 업그레이드에 소요되는 시간을 줄이는 데 훌륭한 일을 하고 있습니다. EKS 1.29 업그레이드는 8분 24초가 걸렸지만, EKS 1.30은 참고로 4초 더 소요되었습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-27-AmazonEKSUpgradeJourneyFrom129to130-sayhellotocuteUwubernetes_3.png)\n\n저는 즉시 워커 노드를 업그레이드하여 업그레이드된 EKS 클러스터에 가입하는 데 약 14분이 걸렸어요. 이 시간은 워커 노드 수와 이전 노드에서 배출해야 하는 포드 수에 따라 다를 수 있어요.\n\n일반적으로 제어 플레인 + 워커 노드의 전체 업그레이드 과정은 약 22분이 걸렸어요. 정말 좋은 시간이라고 말씀드릴 수 있습니다.\n\n저는 개인적으로 Terraform을 사용하여 EKS 클러스터를 배포하고 업그레이드합니다. 여기 EKS 클러스터 리소스의 예시가 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nresource \"aws_eks_cluster\" \"cluster\" {\n  enabled_cluster_log_types = [\"audit\"]\n  name                      = local.name_prefix\n  role_arn                  = aws_iam_role.cluster.arn\n  version                   = \"1.30\"\n\n  vpc_config {\n    subnet_ids              = flatten([module.vpc.public_subnets, module.vpc.private_subnets])\n    security_group_ids      = []\n    endpoint_private_access = \"true\"\n    endpoint_public_access  = \"true\"\n  }\n\n  encryption_config {\n    resources = [\"secrets\"]\n    provider {\n      key_arn = module.kms-eks.key_arn\n    }\n  }\n\n  access_config {\n    authentication_mode                         = \"API_AND_CONFIG_MAP\"\n    bootstrap_cluster_creator_admin_permissions = false\n  }\n\n  tags = var.tags\n}\n```\n\n워커 노드에는 AMI로 공식 AMI인 아이디 ami-0e6a4f108467d0c54를 사용했습니다. 이 AMI는 유럽 런던 지역인 eu-west-2와 관련이 있을 수 있습니다. 모든 노드를 회전한 후 문제가 없는 것으로 보입니다. 현재 노드들은 다음 버전을 실행 중입니다: v1.30.0-eks-036c24b.\n\n따라서 초기 EKS 1.30 버전 릴리스는 최신 버전 1.30.1이 아닌 첫 번째 1.30.0을 사용 중입니다.\n\n제가 Terraform을 사용하여 EKS 클러스터를 생성하는 데 사용하는 템플릿은 Github 저장소인 https://github.com/marcincuber/eks에서 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 관리형 EKS 애드온 업그레이드\n\n이 경우 변경 사항은 사소하며 잘 작동합니다. 애드온의 버전을 간단히 업데이트하면 됩니다. 제 경우 이번 릴리스에서 kube-proxy, coreDNS 및 ebs-csi-driver를 활용했습니다.\n\n# 애드온을 위한 Terraform 자원\n\n```js\nresource \"aws_eks_addon\" \"kube_proxy\" {\n  cluster_name      = aws_eks_cluster.cluster[0].name\n  addon_name        = \"kube-proxy\"\n  addon_version     = \"v1.30.0-eksbuild.3\"\n  resolve_conflicts = \"OVERWRITE\"\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n리소스 \"aws_eks_addon\" \"core_dns\" {\n  cluster_name      = aws_eks_cluster.cluster[0].name\n  addon_name        = \"coredns\"\n  addon_version     = \"v1.11.1-eksbuild.9\"\n  resolve_conflicts = \"OVERWRITE\"\n}\n```\n\n```js\n리소스 \"aws_eks_addon\" \"aws_ebs_csi_driver\" {\n  cluster_name      = aws_eks_cluster.cluster[0].name\n  addon_name        = \"aws-ebs-csi-driver\"\n  addon_version     = \"v1.31.1-eksbuild.1\"\n  resolve_conflicts = \"OVERWRITE\"\n}\n```\n\n# EKS 컨트롤 플레인 업그레이드 후\n\nEKS 1.30을 위해 권장되는 핵심 배포 및 데몬 세트를 업그레이드하는 것을 잊지 마세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- CoreDNS — v1.11.1-eksbuild.9\n- Kube-proxy — 1.30.0-eksbuild.3\n- VPC CNI — 1.18.1-eksbuild.3\n- aws-ebs-csi-driver- v1.31.1-eksbuild.1\n\n위는 AWS의 권장 사항입니다. 모든 구성 요소를 1.30 Kubernetes 버전과 일치하도록 업그레이드하는 것을 고려해보세요. 업그레이드 대상에는 다음이 포함될 수 있습니다:\n\n- 로드 밸런서 컨트롤러\n- calico-node\n- 클러스터 오토스케일러 또는 Karpenter\n- External Secrets Operator\n- Kube State Metrics\n- Metrics Server\n- csi-secrets-store\n- calico-typha 및 calico-typha-horizontal-autoscaler\n- Reloader\n- Keda (이벤트 기반 오토스케일러)\n- nvidia 장치 플러그인 (GPU 사용 시에 사용)\n\n## 최종 결과\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n> $ kubectl version                                                                                                                                                                                           [±d1fbdc7c ✓(✹)]\nClient Version: v1.30.1\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.30.0-eks-036c24b\n```\n\n제 CLI와 Kubernetes 클러스터 버전을 일치시키기 위해 kubectl를 업그레이드해야 해요.\n\n# 요약 및 결론\n\n이전보다 더 빠르게 EKS 클러스터를 업그레이드했어요. 8분 만에 제어플레인 업그레이드 작업이 완료되었어요. 클러스터 및 노드 업그레이드를 실행하기 위해 Terraform을 사용하고, GitHub Actions 파이프라인을 통해 쉽고 편리하게 작업을 처리할 수 있어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n한국어 번역:\n\n한번 더 중요한 문제가 없었어요. 당신이 수행할 작업도 쉬울 거에요. 모든 작업이 잘 작동했어요. 정말 아무것도 수정할 필요가 없었죠.\n\nEKS에 대한 전체 Terraform 설정에 관심이 있다면, GitHub에서 찾아볼 수 있어요 - [https://github.com/marcincuber/eks](https://github.com/marcincuber/eks).\n\n이 기사가 EKS를 버전 1.30으로 업그레이드하는 중요한 정보들을 모두 모아놓아 잘 정리되었으면 하며, 사람들이 자신의 작업을 빠르게 진행할 수 있도록 도움이 되길 바라요.\n\n요약하면, 쿠버네티스를 싫어하거나/또는 사랑해도 그래도 여전히 사용하고 있어요 ;).\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래 표를 Markdown 형식으로 변경해 주십시오.\n\nEnjoy Kubernetes!!!\n\n# Sponsor Me\n\n저의 모든 노트는 공식 AWS와 Kubernetes 소스를 기반으로 합니다.\n\nMedium에 있는 다른 이야기와 마찬가지로, 문서화된 작업을 수행했습니다. 이것은 제 개인적인 연구이며 직면한 문제들에 대한 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n모두 읽어 주셔서 감사합니다. Marcin Cuber\n","ogImage":{"url":"/assets/img/2024-05-27-AmazonEKSUpgradeJourneyFrom129to130-sayhellotocuteUwubernetes_0.png"},"coverImage":"/assets/img/2024-05-27-AmazonEKSUpgradeJourneyFrom129to130-sayhellotocuteUwubernetes_0.png","tag":["Tech"],"readingTime":12},{"title":"내 IaC AWS 다중 계정 프로비저닝 블루프린트, 최고의 관행","description":"","date":"2024-05-27 17:37","slug":"2024-05-27-MyIaCAWSMulti-AccountProvisioningBluePrintBestPractices","content":"\n## SSO 사용자와 함께 Terraform 실행 역할을 가정하는 방법.\n\n이 기사에서는 IaC (Terraform) 프로젝트의 구조를 보여드리겠습니다. 이 프로젝트는 보통 여기저기 흩어져 있는 값 파일이 필요하지 않도록 구성됩니다. 또한 하나의 구성 파일만으로 모든 환경을 제어하는 방법과 플랫폼과 응용프로그램 인프라 코드를 어떻게 분리하는지도 보여드리겠습니다.\n\n## 이 기사에서 다루는 주제들:\n\n- 여러 계정 배포 도구의 우승자인 Terragrunt\n- Terraform 및 Terragrunt의 협력\n- 응용프로그램 인프라 Terragrunt Main 구성 파일 (Locals/Backend S3/AWS Provider)\n- Terraform 실행을 위한 AWS Identity Center (SSO) 권한 집합 (AWS 키와 비밀번호가 영구적이지 않는 역할으로 가정)\n- 플랫폼 vs 응용프로그램 인프라\n- 플랫폼 인프라 Terragrunt Main 구성 파일 (Locals/Backend S3/AWS Provider)\n- Terraform 실행 역할 생성 (응용프로그램 인프라 배포를 위해) IAM 액세스 Identity (SSO)로 프로비저닝된 역할의 신뢰 정책\n- 안전하게 SSO AWS 임시 자격 증명 구성\n- AWS-VAULT\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 테라그런트\n\n내 의견으로 테라그런트는 인프라를 위한 다중 계정 배포 구조화에 사용 가능한 (내가 아는 한) 최고 도구입니다.\n\n테라그런트 문서에 따르면 코드를 다음과 같이 구조화하는 것을 제안합니다:\n\n![테라그런트 구조](/assets/img/2024-05-27-MyIaCAWSMulti-AccountProvisioningBluePrintBestPractices_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러나 주의해야 할 점은 terragrunt를 자원을 조정하는 데 과도하게 사용하지 않아야 합니다.\n\nTerraform은 여러 모듈을 하나로 번들링하여 응용 프로그램이나 플랫폼 서비스를 사용하는 것을 목적으로 합니다.\n\nTerragrunt는 이미 통합된 Terraform 모듈을 서로 다른 환경에 배포하는 데만 사용해야 합니다.\n\n# 응용 프로그램 모듈을 생성하는 데 Terraform을 사용하고, 다른 환경에 배포하는 데 Terragrunt를 사용하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n애플리케이션 모듈(왼쪽)을 만들 때 Terragrunt를 사용하지 마세요. 그렇지 않으면 복잡해질 수 있고 테라폼 상태가 앱 단위가 아닌 구성 요소 단위로 생성될 수 있습니다. Terragrunt를 사용하는 경우 배포(오른쪽)에만 사용하세요.\n\n과거에 저희가 한 실수를 피하기 위해 이렇게 말씀 드리는데요. 저는 Terragrunt 내부의 컴포넌트에 너무 많이 나눠 애플리케이션 인프라를 분리하면서 개별 리소스를 더 잘 관리하려고 했지만 더 많은 문제를 발생시켰습니다.\n\n# 왜 이런 문제가 발생할 수 있나요?\n\n저의 몇몇 프로젝트 중 하나에서 저는 Terragrunt에서 Terraform 워크스페이스로 다중 계정 배포 방법을 변경하는 작업을 맡게 되었습니다. 이것은 서로 다른 AWS 환경을 관리하기 위해 조직의 표준 절차에 맞추기 위한 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 프로세스는 Terragrunt가 단순히 테라폼 래퍼일 뿐이기 때문에 매우 간단할 수 있었을 것입니다.\n\n하지만 앱을 구성 요소로 분할하고 그 구성 요소가 모듈 내에 존재하면 상태 파일을 병합해야 하는 악몽이 될 수 있습니다.\n\n그래서 Terragrunt 풋프린트를 최소화하려면...\n\nT\nerraform은 애플리케이션이나 플랫폼 서비스를 위해 서로 다른 모듈을 번들로 묶을 것으로 의도되어야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 예시: 최소한의 애플리케이션 인프라 리소스:\n\n```js\ndata \"aws_caller_identity\" \"current\" {}\n\nlocals {\n  aws_account_id = data.aws_caller_identity.current.account_id\n}\n\nmodule \"app_logs\" {\n  source = \"git::https://github.com/terraform-aws-modules/terraform-aws-dynamodb-table.git//\"\n  name         = \"${var.app_name}-logs\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"organization\"\n  range_key    = \"job_id\"\n\n  server_side_encryption_enabled = true\n  deletion_protection_enabled    = false\n\n  attributes = [\n    {\n      name = \"organization\"\n      type = \"S\"\n    },\n    {\n      name = \"job_id\"\n      type = \"S\"\n    }\n  ]\n}\n\nmodule \"app_users\" {\n  source = \"git::https://github.com/terraform-aws-modules/terraform-aws-dynamodb-table.git//\"\n  # 필요 시 다른 DynamoDB 테이블을 여기에 추가\n}\n\nmodule \"lambda_execution_role\" {\n  source = \"../lambda-execution-role\"\n  aws_account_id = local.aws_account_id\n  app_name       = var.app_name\n  env            = var.env\n}\n\nmodule \"s3_bucket_files\" {\n  source = \"git::https://github.com/terraform-aws-modules/terraform-aws-s3-bucket.git//?ref=v3.6.1\"\n  bucket                  = var.env == \"production\" ? \"my-company-app-${var.app_name}-files\" : \"my-company-app-${var.app_name}-files-${var.env}\"\n  block_public_acls       = \"true\"\n  block_public_policy     = \"true\"\n  ignore_public_acls      = \"true\"\n  restrict_public_buckets = \"true\"\n}\n\nmodule \"another_s3_bucket_files\" {\n  source = \"git::https://github.com/terraform-aws-modules/terraform-aws-s3-bucket.git//?ref=v3.6.1\"\n  # 필요 시 다른 S3 버켓을 여기에 추가\n}\n\n# SSM Params는 서버리스나 다른 도구에 값들을 전달하는 좋은 방법입니다.\nmodule \"ssm_params\" {\n  source = \"../ssm-parameters-store\"\n  parameters = {\n    1 = {\n      name  = \"/app/${var.app_name}/s3_bucket_files\"\n      value = module.s3_bucket_files.s3_bucket_id\n    }\n    2 = {\n      name  = \"/app/${var.app_name}/lambda_role\"\n      value = module.lambda_execution_role.role_arn\n    }\n    3 = {\n      name  = \"/app/${var.app_name}/event_bridge_name\"\n      value = \"${var.app_name}-event-bus\"\n    }\n    4 = {\n      name  = \"/app/${var.app_name}/logs\"\n      value = module.app_logs.dynamodb_table_id\n    }\n  }\n}\n```\n\n이 모듈에서는 다른 모듈을 호출하여 다음과 같은 종류의 리소스를 생성합니다:\n\n- DynamoDB 테이블\n- S3 버켓\n- IAM Lambda 실행 역할\n- 이전에 생성된 리소스의 ARN 또는 ID를 보관하는 SSM 매개변수\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기서 빠진 것은 다른 기사에서 보여준 것처럼 백엔드 S3 및 AWS 제공자 구성입니다... 여기서 Terragrunt가 등장합니다...\n\n# 플랫폼 대 응용 프로그램\n\n이러한 염려 사항의 분리는 서로 다른 GIT 저장소를 가지거나 단순히 동일한 Repo 내에서 다른 프로젝트로 취급함을 의미합니다... 여기서 중요한 것은 응용 프로그램 인프라 코드가 플랫폼 인프라 코드에 직접적인 종속성을 포함해서는 안된다는 것입니다... 따라서 이것은 응용 프로그램 소스 코드(BE/FE)와 함께 쉽게 추출될 수 있습니다...\n\n하지만 우리는 어떻게 알 수 있을까요? 무엇을 플랫폼 인프라에 위치시키고 어떤 것을 애플리케이션 인프라에 위치시켜야 할지요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 플랫폼 인프라스트럭처:\n\n플랫폼 인프라스트럭처는 보다 포괄적이며 조직 전체에서 여러 응용 프로그램을 지원하는 기본 구성 요소와 서비스를 지칭합니다. 일반적으로 다음을 포함합니다:\n\n- CI/CD용 IAM 역할\n- Route53 호스팅 영역\n- 네트워킹: VPC, 방화벽 및 NAT와 같은 구성 요소\n- 모니터링 및 로깅: Prometheus, Grafana 또는 CloudWatch와 같은 요소\n\n## 응용 프로그램 인프라스트럭처:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n응용 프로그램 인프라는 특정 응용 프로그램 또는 응용 프로그램 세트를 실행하는 데 필요한 구성 요소와 리소스로 구성됩니다. 이는 종종 다음을 포함합니다:\n\n- EC2 인스턴스, 람다 함수\n- 트랜짓 게이트웨이, 로드 밸런서\n- 앱 데이터베이스: MySQL, PostgreSQL 또는 MongoDB와 같은 데이터베이스\n- 메시지 대기열: SQS 또는 Kafka와 같은 메시지 대기열\n\n## 주요 포인트는 개별 앱의 요구 사항에 맞추는 것입니다.\n\n예를 들어 Serverless Framework나 AWS SAM이 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n서버리스 애플리케이션에 대해서는 테라폼과 서버리스를 사용하는 멋진 가이드가 있어요.\n\n## 테라폼을 사용하지 않고 다른 도구를 사용할 때, 서버리스 프레임워크나 SAM같은:\n\n# 애플리케이션 IaC를 위한 Terragrunt\n\n‘live‘ 디렉토리 내에서 배포할 환경을 지정하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n├── README.md\n├── live\n│   ├── _env\n│   │   └── app.hcl\n│   ├── dev\n│   │   └── app\n│   │       └── terragrunt.hcl <--- this is not a config file, but an environment resource file\n│   ├── production\n│   │   └── app\n│   │       └── terragrunt.hcl\n│   ├── terragrunt.hcl         <------ Terragrunt config file (Unique)\n│   └── test\n│       └── app\n│           └── terragrunt.hcl\n└── modules\n    ├── lambda-execution-role\n    │   ├── data.tf\n    │   ├── main.tf\n    │   ├── output.tf\n    │   └── variables.tf\n    ├── application_1\n    │   ├── main.tf\n    │   └── variables.tf\n    └── ssm-parameters-store\n        ├── main.tf\n        └── variables.tf\n```\n\n# 유일무이한 terragrunt.hcl 설정 파일\n\n여기에는 하나의 terragrunt.hcl 구성 파일을 사용하여 멀티 계정 배포를 구성하는 방법이 나와 있어요.\n\n테라폼 워크스페이스 구성과 Terragrunt 구성을 비교해보겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n로컬 변수 정의는 \"거의\" 같은 상태로 유지되고 있으며, Terragrunt Live 디렉터리를 다른 환경의 이름으로 구조화하고 있습니다.\n\nAWS 환경 이름과 디렉터리 이름이 일치하므로 간단한 정규 표현식으로 실행 시간에 환경 값을 추론할 수 있습니다.\n\n## infrastructure/live/terragrunt.hcl\n\n여기에 완전한 terragrunt.hcl 파일이 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nbackend.tf와 provider.tf 생성기에서 \"profile\" 매개변수를 주목해주세요. 다음 섹션에서 이들을 제거할 예정입니다.\n\n```js\nlocals {\n  # 환경\n  env_regex = \"infrastructure/live/([a-zA-Z0-9-]+)/\"\n  aws_env   = try(regex(local.env_regex, get_original_terragrunt_dir())[0])\n  # 어플리케이션\n  app_name = \"my-app\"\n  component = \"api\"\n\n  # AWS 조직 계정\n  account_mapping = {\n    dev             = 22222222222\n    test            = 111111111111\n    production      = 000000000000\n    shared-services = 555555555555\n  }\n  # 가정할 IAM 역할\n  account_role_name     = \"apps-terraform-execution-role\" # <--- 가정할 역할\n  # 지역 및 가용 영역\n  region = \"us-east-1\"\n}\nremote_state {\n  backend = \"s3\"\n  generate = {\n    path      = \"backend.tf\"\n    if_exists = \"overwrite_terragrunt\"\n  }\n  config = {\n    bucket         = \"terraform-state-shared-services\"\n    key            = \"${local.app_name}/${get_path_from_repo_root()}/terraform.tfstate\"\n    region         = local.region\n    profile        = \"shared-services\" #<----- AWS 프로필\n    encrypt        = true\n    dynamodb_table = \"shared-services-lock-table\"\n  }\n}\ngenerate \"provider\" {\n  path      = \"provider.tf\"\n  if_exists = \"overwrite_terragrunt\"\n  contents  = <<-EOF\n    provider \"aws\" {\n      region = \"${local.region}\"\n      profile = \"shared-services\" #<----- AWS 프로필\n      allowed_account_ids = [\n        \"${local.account_mapping[local.aws_env]}\"\n      ]\n      assume_role {\n        role_arn = \"arn:aws:iam::${local.account_mapping[local.aws_env]}:role/${local.account_role_name}\"\n      }\n      default_tags {\n        tags = {\n          Environment = \"${local.aws_env}\"\n          ManagedBy   = \"terraform\"\n          DeployedBy  = \"terragrunt\"\n          Creator     = \"${get_env(\"USER\", \"NOT_SET\")}\"\n          Application = \"${local.app_name}\"\n          Component   = \"${local.component}\"\n        }\n      }\n    }\nEOF\n}\n```\n\nTerragrunt가 생성기에 보간을 허용하므로 모든 대상 AWS 계정에 대해 매개변수화할 수 있습니다.\n\n## infrastructure/live/\\_env/app.hcl\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n테이블 태그를 마크다운 형식으로 변경해주세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Terraform 프로비저닝 인프라에 필요한 역할 설정하기\n\n```js\naccount_role_name     = \"apps-terraform-execution-role\" # <--- 전환할 역할\n```\n\n또한 이전 게시물에서 AWS 공유 서비스 계정에 terraform-multiaccount-role 및 각 작업 부하 계정(개발, 테스트, 프로덕션)에 terraform-role을 설정하는 방법을 설명했습니다.\n\n그러나 이 설정은 하나의 엔터티(terraform-multiaccount-role)가 모든 계정에서 terraform-role을 가정(Assume)할 수 있도록 허용합니다. 이는 개발팀이 자체 인프라를 개발 환경에서 관리할 수 있도록 하려는 경우에는 편리하지 않습니다. 따라서 개발 팀이 Dev 계정에서만 역할을 전환할 수 있는 엔터티와 Test 및 Production에 대한 다른 엔터티가 필요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## AWS Identity Center 위임된 관리자 계정 및 권한 집합\n\nAWS 계정에 권한 집합을 만드는 방법 및 권한 집합을 AWS 계정에 할당하는 방법에 대한 문서를 따르세요.\n\n다음과 같은 권한 집합을 만들어 보세요: terraform-dev, terraform-test, terraform-production.\n\n각 권한 집합에 대한 대상 계정에 다음과 같은 내부 정책을 만드세요. 허용하는 권한 집합(Identity 계정에 설정된)이 공유 서비스 계정에 배포되어 다음 계정에서 역할을 가정할 수 있도록합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이렇게 보이는 3가지 다른 권한 세트가 있습니다:\n\n```js\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"sts:AssumeRole\",\n            \"Resource\": \"arn:aws:iam::000000000000:role/apps-terraform-execution-role\"\n        },\n        {\n            \"Sid\": \"Statement1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n              \"s3:GetObject\",\n              \"s3:PutObject\",\n              \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::terraform-state-shared-services*\",\n                \"arn:aws:s3:::terraform-state-shared-services/*\"\n            ]\n        },\n        {\n            \"Sid\": \"Statement2\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n              \"dynamodb:GetItem\",\n              \"dynamodb:PutItem\",\n              \"dynamodb:DeleteItem\"\n            ],\n            \"Resource\": [\n                \"arn:aws:dynamodb:us-east-1:555555555555:table/shared-services-lock-table\"\n            ]\n        }\n    ]\n}\n```\n\n각 워크로드 계정에 apps-terraform-execution-role을 만들고 SSO 사용자가 역할을 할 수 있도록 허용합니다.\n\n참고: \"terraform-production\"에게도 Test에서 역할을 수행할 수 있도록 정책을 약간 조정할 수도 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 플랫폼 인프라 (IaC)\n\n최소한의 애플리케이션을 위해 DNS, 네트워킹 및 식별 관리 역할 및 정책과 같은 플랫폼 리소스를 제공해야 합니다.\n\n```js\n➜  live git:(main) ✗ tree\n.\n├── _env\n│   ├── route53-zones.hcl\n│   └── iam-roles.hcl\n├── dev\n│   ├── iam-roles\n│   │   └── terragrunt.hcl\n│   ├── route53-zones\n│   │   └── terragrunt.hcl\n│   └── platform\n│       └── terragrunt.hcl\n├── network\n│   ├── dmz\n│   │   └── terragrunt.hcl\n│   ├── network-egress\n│   │   └── terragrunt.hcl\n│   ├── transitgateway-dmz-vpc-attachment\n│   │   └── terragrunt.hcl\n│   └── transitgateway-egress-vpc-attachment\n│       ├── mystate.tfstate\n│       └── terragrunt.hcl\n├── production\n│   ├── iam-roles\n│   │   └── terragrunt.hcl\n│   └── platform\n│       └── terragrunt.hcl\n├── terragrunt.hcl\n└── test\n    ├── iam-roles\n    │   └── terragrunt.hcl\n    ├── route53-zones\n    │   └── terragrunt.hcl\n    └── platform\n        └── terragrunt.hcl\n```\n\n## 로컬 변수\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여러 개의 계정 값들을 하나의 장소에서 중앙화하는 방법의 예시입니다:\n\n```js\nlocals {\n  # 환경 변수\n  env_regex = \"infrastructure/live/([a-zA-Z0-9-]+)/\"\n  aws_env   = try(regex(local.env_regex, get_original_terragrunt_dir())[0])\n  # 어플리케이션\n  app_name  = \"my-application-platform\"\n  component = \"platform\"\n  platform_apps = [\n    \"application_1\",\n    \"application_2\",\n    \"application_3\"\n  ]\n  # AWS 조직 계정\n  application_account_mapping = {\n    dev        = 222222222222\n    test       = 111111111111\n    production = 000000000000\n  }\n  platform_account_mapping = {\n    shared-services = 555555555555\n    network         = \"666666666666\"\n    dns             = 888888888888\n  }\n  account_mapping = merge(local.application_account_mapping, local.platform_account_mapping)\n\n  # 가정할 IAM 역할\n  account_role_name     = \"terraform-role\"\n  multiaccount_role_arn = \"arn:aws:iam::555555555555:role/terraform-multiaccount-role\" # shared-services\n\n  terraform_execution_role_mapping = {\n    dev = \"arn:aws:iam::555555555555:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_terraform-dev_ab1\"\n    test = \"arn:aws:iam::555555555555:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_terraform-test_ab2\"\n    production = \"arn:aws:iam::555555555555:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_terraform-production_ab3\"\n  }\n\n  # 기타 플랫폼 구성 값들\n  # ===================================\n  # DNS\n  main_public_dns_zone_name     = \"example.com\"\n  env_public_dns_zone_subdomain = \"${local.aws_env}\"\n  environment_hosted_zone_name  = \"${local.env_public_dns_zone_subdomain}.${local.main_public_dns_zone_name}\"\n  acm_subject_alternative_names = [\n    \"${local.environment_hosted_zone_name}\",\n    \"*.${local.environment_hosted_zone_name}\",\n    \"*.api.${local.environment_hosted_zone_name}\",\n    \"*.myapps.${local.environment_hosted_zone_name}\",\n    \"*.apps.${local.environment_hosted_zone_name}\"\n  ]\n  # 지역 및 가용 영역\n  region = \"us-east-1\"\n  azs = [\n    \"us-east-1a\",\n    \"us-east-1b\",\n    \"us-east-1c\"\n  ]\n  platform_accounts = {\n    dev = {\n      cidr = \"10.3.0.0/16\"\n      private_subnets = [\n        \"10.3.1.0/24\",\n        \"10.3.2.0/24\",\n        \"10.3.3.0/24\"\n      ]\n    }\n    test = {\n      cidr = \"10.2.0.0/16\"\n      private_subnets = [\n        \"10.2.1.0/24\",\n        \"10.2.2.0/24\",\n        \"10.2.3.0/24\"\n      ]\n    }\n    production = {\n      cidr = \"10.0.0.0/16\"\n      private_subnets = [\n        \"10.0.1.0/24\",\n        \"10.0.2.0/24\",\n        \"10.0.3.0/24\"\n      ]\n    }\n  }\n}\n```\n\n```js\ninclude \"root\" {\n  path = find_in_parent_folders()\n}\n\ninclude \"env\" {\n  path = \"../../_env/iam-roles.hcl\"\n}\n```\n\n```js\nlocals {\n  env_vars = read_terragrunt_config(find_in_parent_folders(\"terragrunt.hcl\"))\n  env      = local.env_vars.locals.aws_env\n}\n\nterraform {\n  source = \"../../../modules//platform/iam-roles\"\n}\n\ninputs = {\n  trusted_role_arns = [\n    local.env_vars.locals.terraform_execution_role_mapping[local.env]\n  ]\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## infrastructure/modules/platform/iam-roles\n\n\"Iam:_\"에 대한 범위를 좁히고 있음을 알려드립니다. 이는 Terraform이 응용 프로그램을 위해 Role 및 정책을 생성, 제거 및 업데이트해야하기 때문에 필요한 권한입니다. 그러나 이 경우 \":role/app/_\" 내의 Roles 및 Policies로 범위를 좁힐 수 있습니다.\n\n```json\ndata \"aws_caller_identity\" \"current\" {}\nmodule \"app_terraform_execution_role\" {\n  source                            = \"../../iam-role\"\n  role_name                         = \"apps-terraform-execution-role\"\n  create_role                       = true\n  role_requires_mfa                 = var.role_requires_mfa\n  path                              = \"/\"\n  description                       = \"Terraform Execution role\"\n  trusted_role_arns                 = var.trusted_role_arns\n  number_of_custom_role_policy_arns = 1\n  policy = jsonencode(\n    {\n      \"Version\" : \"2012-10-17\",\n      \"Statement\" : [\n        {\n          \"Action\" : var.app_allowed_actions,\n          \"Effect\" : \"Allow\",\n          \"Resource\" : \"*\",\n          \"Condition\" : {\n            \"StringEquals\" : {\n              \"aws:RequestedRegion\" : \"us-east-1\"\n            }\n          }\n        },\n        {\n          \"Action\" : [\n            \"iam:*\"\n          ],\n          \"Effect\" : \"Allow\",\n          \"Resource\" : \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/app/*\"\n        }\n      ]\n  })\n}\n\nvariable \"app_allowed_actions\" {\n  default = [\n    \"cloudwatch:*\",\n    \"iam:List*\",\n    \"iam:Get*\",\n    \"iam:Describe*\",\n    \"logs:*\",\n    \"logs:ListTagsLogGroup\",\n    \"s3:*\",\n    \"secretsmanager:*\",\n    \"ses:*\",\n    \"sns:*\",\n    \"ssm:*\",\n    \"dynamodb:*\",\n    \"sts:*\",\n    \"route53:*\"\n  ]\n}\n```\n\n```json\nmodule \"iam_policy\" {\n  source      = \"git::https://github.com/terraform-aws-modules/terraform-aws-iam.git//modules/iam-policy\"\n  path        = var.path\n  name        = \"${var.role_name}-policy\"\n  description = var.description\n  policy      = var.policy\n}\n\nmodule \"iam_assumable_role\" {\n  source            = \"git::https://github.com/terraform-aws-modules/terraform-aws-iam.git//modules/iam-assumable-role\"\n  create_role       = var.create_role\n  role_name         = var.role_name\n  role_requires_mfa = var.role_requires_mfa\n  trusted_role_arns = var.trusted_role_arns\n  custom_role_policy_arns = [\n    module.iam_policy.arn\n  ]\n  number_of_custom_role_policy_arns = var.number_of_custom_role_policy_arns\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# AWS 인가: SSO를 사용할 예정이므로 장기적으로 유효한 자격 증명이 필요하지 않아요 🥳\n\n# 로컬 구성 프로파일 구성 (~/.aws/config)\n\n## 플랫폼\n\n요기 못생긴 닭과 계란 문제가 있는데... 깔끔한 AWS 계정이 있고, 플랫폼 인프라 프로비저닝에 권한을 부여해야 해요. 이건 IaC를 사용할 수 없어서 할 수 없는 문제에요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAWS 콘솔이나 CLI를 사용하여 Terraform 플랫폼에 대한 IAM 또는 IAM Identity Center 사용자를 수동으로 설정해야 합니다. 설정이 완료되면 IaC를 프로비저닝할 수 있습니다.\n\n애플리케이션 프로비저닝을 위한 모든 역할과 정책(CICD 측면을 고려한)은 플랫폼 IaC에서 생성됩니다. 애플리케이션 실행을 위한 모든 역할과 정책(예: 람다 실행 역할)은 응용 프로그램 코드 내에서 생성됩니다.\n\n```js\n[profile terraform-platform]\nsso_start_url=https://my-organization.awsapps.com/start\nsso_region=us-east-1\nsso_account_id=555555555555\nsso_role_name=PlatformTerraform\nregion=us-east-1\noutput=json\n```\n\n## 응용 프로그램 리소스 (개발자가 쓰기 액세스를 얻는 곳)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-27-MyIaCAWSMulti-AccountProvisioningBluePrintBestPractices_1.png\" />\n\n```js\n[profile terraform]\nsso_start_url=https://my-organization.awsapps.com/start\nsso_region=us-east-1\nsso_account_id=555555555555\nsso_role_name=terraform-dev\nregion=us-east-1\noutput=json\n\n[profile terraform-test]\nsso_start_url=https://my-organization.awsapps.com/start\nsso_region=us-east-1\nsso_account_id=555555555555\nsso_role_name=terraform-test\nregion=us-east-1\noutput=json\n\n[profile terraform-production]\nsso_start_url=https://my-organization.awsapps.com/start\nsso_region=us-east-1\nsso_account_id=555555555555\nsso_role_name=terraform-production\nregion=us-east-1\noutput=json\n```\n\n# AWS Backend & Provider Config\n\n어머머... 휴스턴, 문제 발생했어요.... AWS 계정 별로 다른 권한 세트가 있어요... 이제 더 이상 `profile = shared-services`를 사용할 수 없게 됐네요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n혹시 매핑할까요? 아니면 환경과 접두사를 추가할까요?….\n\n```js\nremote_state {\n  backend = \"s3\"\n .....\n  }\n  config = {\n   ........\n\n    # 여기가 문제입니다\n    profile        = \"terraform\" # 혹은 \"terraform-test\" 또는 \"terraform-production\"\n  }\n}\n\ngenerate \"provider\" {\n  path      = \"provider.tf\"\n  if_exists = \"overwrite_terragrunt\"\n  contents  = <<-EOF\n    provider \"aws\" {\n      ...\n      ....\n      profile = \"terraform\" # 혹은 \"terraform-test\" 또는 \"terraform-production\"\n    }\nEOF\n}\n```\n\n## 이것을 제거하고 환경 변수로 설정합시다\n\n```js\nlocals {\n  # ENV\n  env_regex = \"infrastructure/live/([a-zA-Z0-9-]+)/\"\n  aws_env   = try(regex(local.env_regex, get_original_terragrunt_dir())[0])\n  # Application\n  app_name  = \"my-application-platform\"\n  component = \"platform\"\n  platform_apps = [\n    \"application_1\",\n    \"application_2\",\n    \"application_3\"\n  ]\n  # AWS Organizations Accounts\n  application_account_mapping = {\n    dev        = 222222222222\n    test       = 111111111111\n    production = 000000000000\n  }\n  platform_account_mapping = {\n    shared-services = 555555555555\n    network         = \"666666666666\"\n    dns             = 888888888888\n  }\n  account_mapping = merge(local.application_account_mapping, local.platform_account_mapping)\n\n  # IAM Roles to Assume\n  account_role_name     = \"terraform-role\"\n  multiaccount_role_arn = \"arn:aws:iam::555555555555:role/terraform-multiaccount-role\" # shared-services\n\n  terraform_execution_role_mapping = {\n    dev = \"arn:aws:iam::555555555555:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_terraform-dev_ab1\"\n    test = \"arn:aws:iam::555555555555:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_terraform-test_ab2\"\n    production = \"arn:aws:iam::555555555555:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_terraform-production_ab3\"\n  }\n\n  # Other Platform Config Values Below\n  # ===================================\n  # DNS\n  main_public_dns_zone_name     = \"example.com\"\n  env_public_dns_zone_subdomain = \"${local.aws_env}\"\n  environment_hosted_zone_name  = \"${local.env_public_dns_zone_subdomain}.${local.main_public_dns_zone_name}\"\n  acm_subject_alternative_names = [\n    \"${local.environment_hosted_zone_name}\",\n    \"*.${local.environment_hosted_zone_name}\",\n    \"*.api.${local.environment_hosted_zone_name}\",\n    \"*.myapps.${local.environment_hosted_zone_name}\",\n    \"*.apps.${local.environment_hosted_zone_name}\"\n  ]\n  # Region and Zones\n  region = \"us-east-1\"\n  azs = [\n    \"us-east-1a\",\n    \"us-east-1b\",\n    \"us-east-1c\"\n  ]\n  platform_accounts = {\n    dev = {\n      cidr = \"10.3.0.0/16\"\n      private_subnets = [\n        \"10.3.1.0/24\",\n        \"10.3.2.0/24\",\n        \"10.3.3.0/24\"\n      ]\n    }\n    test = {\n      cidr = \"10.2.0.0/16\"\n      private_subnets = [\n        \"10.2.1.0/24\",\n        \"10.2.2.0/24\",\n        \"10.2.3.0/24\"\n      ]\n    }\n    production = {\n      cidr = \"10.0.0.0/16\"\n      private_subnets = [\n        \"10.0.1.0/24\",\n        \"10.0.2.0/24\",\n        \"10.0.3.0/24\"\n      ]\n    }\n  }\n}\nremote_state {\n  backend = \"s3\"\n  generate = {\n    path      = \"backend.tf\"\n    if_exists = \"overwrite_terragrunt\"\n  }\n  config = {\n    bucket         = \"terraform-state-shared-services\"\n    key            = \"${local.app_name}/${get_path_from_repo_root()}/terraform.tfstate\"\n    region         = local.region\n    encrypt        = true\n    dynamodb_table = \"shared-services-lock-table\"\n  }\n}\n\ngenerate \"provider\" {\n  path      = \"provider.tf\"\n  if_exists = \"overwrite_terragrunt\"\n  contents  = <<-EOF\n    provider \"aws\" {\n      region = \"${local.region}\"\n      allowed_account_ids = [\n        \"${local.account_mapping[local.aws_env]}\"\n      ]\n      assume_role {\n        role_arn = \"arn:aws:iam::${local.account_mapping[local.aws_env]}:role/${local.account_role_name}\"\n      }\n      default_tags {\n        tags = {\n          Environment = \"${local.aws_env}\"\n          ManagedBy   = \"terraform\"\n          DeployedBy  = \"terragrunt\"\n          Creator     = \"${get_env(\"USER\", \"NOT_SET\")}\"\n          Application = \"${local.app_name}\"\n          Component   = \"${local.component}\"\n        }\n      }\n    }\nEOF\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 배포\n\n## 플랫폼\n\n```js\naws sso login --profile terraform-platform\nexport AWS_PROFILE=terraform-platform\n\n# 개발\ncd infrastructure/live/dev/iam-roles\nterragrunt init\nterragrunt plan\nterragrunt apply\n\n# 테스트\ncd infrastructure/live/test/iam-roles\nterragrunt init\nterragrunt plan\nterragrunt apply\n\n# 프로덕션\ncd infrastructure/live/production/iam-roles\nterragrunt init\nterragrunt plan\nterragrunt apply\n```\n\n## 어플리케이션\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기서는 방금 만든 새 역할을 사용합니다.\n\n```js\n# 개발\ncd infrastructure/live/dev/app\naws sso login --profile terraform-dev\nexport AWS_PROFILE=terraform-dev\nterragrunt init\nterragrunt plan\nterragrunt apply\n\n# 테스트\ncd infrastructure/live/test/app\naws sso login --profile terraform-test\nexport AWS_PROFILE=terraform-test\nterragrunt init\nterragrunt plan\nterragrunt apply\n\n# 프로덕션\ncd infrastructure/live/production/app\naws sso login --profile terraform-production\nexport AWS_PROFILE=terraform-production\nterragrunt init\nterragrunt plan\nterragrunt apply\n```\n\n# AWS Vault\n\nAWS Vault은 개발 환경에서 AWS 자격 증명을 안전하게 저장하고 액세스하는 도구입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAWS Vault은 IAM 자격 증명을 사용자의 운영 체제 안전한 키 저장소에 저장한 다음 해당 자격 증명을 임시 자격 증명으로 생성하여 쉘 및 응용 프로그램에 노출합니다. 이는 AWS CLI 도구와 함께 보조적으로 사용되도록 설계되었으며 ~/.aws/config에 있는 프로필과 구성을 인식합니다.\n\n```js\nbrew install --cask aws-vault\n```\n\n## 따라서 이는 백엔드 구성 및 공급자에서 \"프로필\" 매개변수를 제거할 수 있음을 의미합니다.\n\n# AWS-Vault로 배포하기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 플랫폼\n\n```js\n# Dev\ncd infrastructure/live/dev/iam-roles\naws-vault exec terraform-platform terragrunt init\naws-vault exec terraform-platform terragrunt plan\naws-vault exec terraform-platform terragrunt apply\n\n# 테스트\ncd infrastructure/live/test/iam-roles\naws-vault exec terraform-platform terragrunt init\naws-vault exec terraform-platform terragrunt plan\naws-vault exec terraform-platform terragrunt apply\n\n# 프로덕션\ncd infrastructure/live/production/iam-roles\naws-vault exec terraform-platform terragrunt init\naws-vault exec terraform-platform terragrunt plan\naws-vault exec terraform-platform terragrunt apply\n```\n\n# 애플리케이션\n\n```js\ncd infrastructure/live/dev/app\naws-vault exec terraform-dev terragrunt init\naws-vault exec terraform-dev terragrunt plan\naws-vault exec terraform-dev terragrunt apply\n\ncd infrastructure/live/test/app\naws-vault exec terraform-test terragrunt init\naws-vault exec terraform-test terragrunt plan\naws-vault exec terraform-test terragrunt apply\n\ncd infrastructure/live/production/app\naws-vault exec terraform-production terragrunt init\naws-vault exec terraform-production terragrunt plan\naws-vault exec terraform-production terragrunt apply\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-27-MyIaCAWSMulti-AccountProvisioningBluePrintBestPractices_2.png\" />\n\n## 결과\n\n```js\n $ aws-vault exec terraform-production terragrunt apply\n\n\n\n백엔드 초기화 중...\n\n백엔드 \"s3\"이 성공적으로 구성되었습니다! 백엔드 구성이 변경되지 않는 한 Terraform은\n자동으로이 백엔드를 사용할 것입니다.\n모듈 초기화 중...\njobs_logs(을)를 위해 git::https://github.com/terraform-aws-modules/terraform-aws-dynamodb-table.git을(를) 다운로드 중...\n- .terraform/modules/logs에 jobs_logs\n- ../lambda-execution-role에 lambda_execution_role\ns3_bucket_files(을)를 위해 git::https://github.com/terraform-aws-modules/terraform-aws-s3-bucket.git?ref=v3.6.1을(를) 다운로드 중...\n- .terraform/modules/s3_bucket_files에 s3_bucket_files\n- ../ssm-parameters-store에 ssm_params\n\n제공자 플러그인 초기화 중...\n- 종속성 잠금 파일에서 이전 버전의 hashicorp/aws 재사용\n- hashicorp/aws v5.23.1 설치 중...\n- hashicorp/aws v5.23.1 설치됨 (HashiCorp에서 서명됨)\n\nTerraform이 성공적으로 초기화되었습니다!\n\n이제 Terraform을 사용하여 작업을 시작할 수 있습니다. \"terraform plan\"을 실행하여\n인프라에 필요한 모든 변경 사항을 확인해 보세요. 이제 모든 Terraform 명령이\n작동해야 합니다.\n\nTerraform을 위해 모듈이나 백엔드 구성을 설정 또는 변경한 경우,\n작업 디렉터리를 다시 초기화하려면이 명령을 다시 실행하세요. 잊어 버린 경우\n다른 명령이 필요한 경우이를 감지하고 다시 실행하라는 메시지가 표시됩니다.\n상태 잠금 획득 중. 이 작업은 몇 분 정도 걸릴 수 있습니다...\nmodule.lambda_execution_role.data.aws_iam_policy_document.lambda_assume_role_policy: 읽는 중...\nmodule.s3_bucket_files.data.aws_caller_identity.current: 읽는 중...\nmodule.s3_bucket_files.data.aws_canonical_user_id.this: 읽는 중...\ndata.aws_caller_identity.current: 읽는 중...\nmodule.s3_bucket_files.aws_s3_bucket.this[0]: 상태 새로 고침 중... [id=my-company-myapp-files-dev]\nmodule.jobs_logs.aws_dynamodb_table.this[0]: 상태 새로 고침 중... [id=my-company-myapp-logs]\nmodule.lambda_execution_role.data.aws_iam_policy_document.lambda_assume_role_policy: 0초 후에 읽기 완료 [id=000000000]\ndata.aws_caller_identity.current: 0초 후에 읽기 완료 [id=000000000]\nmodule.lambda_execution_role.data.aws_iam_policy_document.inline_policy: 읽는 중...\nmodule.s3_bucket_files.data.aws_caller_identity.current: 0초 후에 읽기 완료 [id=000000000]\nmodule.lambda_execution_role.data.aws_iam_policy_document.inline_policy: 0초 후에 읽기 완료 [id=000000000]\nmodule.lambda_execution_role.aws_iam_role.lambda_execution_role: 상태 새로 고침 중... [id=my-company-myapp-lambda-execution-role]\nmodule.s3_bucket_files.data.aws_canonical_user_id.this: 1초 후에 읽기 완료 [id=51528157cefbacf17d3cc90bf31e07f8f463cadfbf31739f6b264afac67fb2ce]\nmodule.s3_bucket_files.aws_s3_bucket_public_access_block.this[0]: 상태 새로 고침 중... [id=my-company-myapp-files-dev]\nmodule.ssm_params.aws_ssm_parameter.this[\"2\"]: 상태 새로 고침 중... [id=/app/myapp/lambda_role]\nmodule.ssm_params.aws_ssm_parameter.this[\"3\"]: 상태 새로 고침 중... [id=/app/myapp/event_bridge_name]\nmodule.ssm_params.aws_ssm_parameter.this[\"4\"]: 상태 새로 고침 중... [id=/app/myapp/logs]\nmodule.ssm_params.aws_ssm_parameter.this[\"1\"]: 상태 새로 고침 중... [id=/app/myapp/s3_bucket_files]\n\n변경 사항이 없습니다. 인프라가 구성과 일치합니다.\n\nTerraform은 실제 인프라를 구성과 비교하고 차이점을 찾았으며 변경 사항이 필요하지 않습니다.\n상태 잠금 해제 중. 이 작업은 몇 분 정도 걸릴 수 있습니다...\n```\n\n읽어 주셔서 감사합니다!\n","ogImage":{"url":"/assets/img/2024-05-27-MyIaCAWSMulti-AccountProvisioningBluePrintBestPractices_0.png"},"coverImage":"/assets/img/2024-05-27-MyIaCAWSMulti-AccountProvisioningBluePrintBestPractices_0.png","tag":["Tech"],"readingTime":35},{"title":"테라폼으로 AWS-VPC 피어링하기","description":"","date":"2024-05-27 17:35","slug":"2024-05-27-AWS-VPCPeeringwithTerraform","content":"\n![AWS VPC Peering with Terraform](/assets/img/2024-05-27-AWS-VPCPeeringwithTerraform_0.png)\n\nAWS에서 VPC는 무엇인가요?\n\nAWS에서 VPC 피어링이란 무엇인가요?\n\nTerraform은 무엇인가요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 글에서는 AWS에서 Terraform을 사용하여 VPC 피어링 프로세스를 자동화하는 단계를 살펴보겠습니다.\n\nAWS에서 생성된 자원 목록\n\n- EC2 (2대)\n- VPC (2개)\n- Internet Gateways (2개)\n- 보안 그룹 (4개)\n- VPC 피어링 연결 (1개)\n- 라우트 테이블 (2개)\n\n# 프로젝트 구조\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nterraform_project/\n│\n├── module/\n│ ├── ec2/\n│ │ ├── main.tf\n│ │ ├── output.tf\n│ │ └── variables.tf\n│ ├── vpc/\n│ │ ├── main.tf\n│ │ ├── output.tf\n│ │ └── variables.tf\n│ └── ...\n│\n├── main.tf\n├── variables.tf\n└── variable.tfvars/\n├── dev-env.tfvars\n├── stage-env.tfvars\n└── prod-env.tfvars\n\n## 단계 1: VPC를 위한 모듈 생성 및 가져오기\n\nmodules/vpc-peering/main.tf\n\n```js\nterraform {\n  required_providers {\n    aws = {\n      source                = \"hashicorp/aws\"\n      version               = \"~> 5.0\"\n      configuration_aliases = [aws.us_west]\n    }\n  }\n}\n\nprovider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-1\"\n}\n\nresource \"aws_vpc\" \"main_vpc\" {\n  cidr_block = var.vpc_cidr\n\n  tags = {\n    Name       = var.vpc_name\n    created_by = var.owner_name\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n지금, 프로젝트 루트의 main.tf 파일에 모듈을 가져오겠습니다.\n\n```js\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nprovider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-1\"\n}\n\nmodule \"vpc_A\" {\n  source     = \"./modules/vpc\"\n  vpc_name   = var.vpcs[\"vpc_A\"][\"vpc_name\"]\n  vpc_cidr   = var.vpcs[\"vpc_A\"][\"cidr_block\"]\n  owner_name = var.owner_name\n}\n\nmodule \"vpc_B\" {\n  source     = \"./modules/vpc\"\n  vpc_name   = var.vpcs[\"vpc_B\"][\"vpc_name\"]\n  vpc_cidr   = var.vpcs[\"vpc_B\"][\"cidr_block\"]\n  owner_name = var.owner_name\n  providers = {\n    aws = aws.us_west\n  }\n}\n```\n\n## Step 2: Subnets용 모듈을 만들어 import해보세요.\n\nmodules/subnets/main.tf\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n      # configuration_aliases = [aws.us_west]\n    }\n  }\n}\n\nprovider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-1\"\n}\n\nresource \"aws_subnet\" \"main_subnet\" {\n  vpc_id            = var.vpc_id\n  cidr_block        = var.subnet_cidr\n  availability_zone = var.availability_zone\n\n  tags = {\n    Name       = var.subnet_name\n    created_by = var.owner_name\n  }\n}\n```\n\n이제 프로젝트 루트의 main.tf 파일에 모듈을 가져 오겠습니다.\n\n```js\nmodule \"subnetsForvpc_A\" {\n  for_each          = var.subnetsForvpc_A\n  source            = \"./modules/subnets\"\n  vpc_id            = module.vpc_A.vpc_id\n  subnet_cidr       = var.subnetsForvpc_A[each.key][\"subnet_cidr\"]\n  subnet_name       = var.subnetsForvpc_A[each.key][\"subnet_name\"]\n  availability_zone = var.subnetsForvpc_A[each.key][\"availability_zone\"]\n  owner_name        = var.owner_name\n}\n\nmodule \"subnetsForvpc_B\" {\n  for_each          = var.subnetsForvpc_B\n  source            = \"./modules/subnets\"\n  vpc_id            = module.vpc_B.vpc_id\n  subnet_cidr       = var.subnetsForvpc_B[each.key][\"subnet_cidr\"]\n  subnet_name       = var.subnetsForvpc_B[each.key][\"subnet_name\"]\n  availability_zone = var.subnetsForvpc_B[each.key][\"availability_zone\"]\n  owner_name        = var.owner_name\n  providers = {\n    aws = aws.us_west\n  }\n}\n```\n\n## 단계 3: 보안 그룹 모듈을 생성하고 가져 오기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nmodules/security-groups/main.tf\n\n```js\nterraform {\n  required_providers {\n    aws = {\n      source                = \"hashicorp/aws\"\n      version               = \"~> 5.0\"\n      configuration_aliases = [aws.us_west]\n    }\n  }\n}\n\nprovider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-1\"\n}\n\nresource \"aws_security_group\" \"allow_ssh\" {\n  name        = var.sg_name\n  description = var.sg_description\n  vpc_id      = var.vpc_id\n\n  ingress {\n    description = var.ingress_description\n    from_port   = var.ingress_from_port\n    to_port     = var.ingress_to_port\n    protocol    = var.ingress_protocol\n    cidr_blocks = var.ingress_cidr_blocks\n  }\n\n  egress {\n    from_port   = \"0\"\n    to_port     = \"0\"\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name       = var.sg_name\n    created_by = var.owner_name\n  }\n}\n```\n\n보안 그룹을 위해, 저는 main.tf 파일에서 프로젝트 루트로 모듈을 두 번 가져왔습니다. 첫 번째 보안 그룹은 EC2로 SSH를 허용하고, 두 번째는 EC2에서 ICMP 패킷의 흐름을 허용합니다.\n\n```js\nmodule \"ssh_sg_vpcA\" {\n  source              = \"./modules/security-groups\"\n  sg_name             = var.sgs[\"ssh_sg\"][\"sg_name\"]\n  sg_description      = var.sgs[\"ssh_sg\"][\"sg_description\"]\n  ingress_description = var.sgs[\"ssh_sg\"][\"ingress_description\"]\n  ingress_from_port   = var.sgs[\"ssh_sg\"][\"ingress_from_port\"]\n  ingress_to_port     = var.sgs[\"ssh_sg\"][\"ingress_to_port\"]\n  ingress_protocol    = var.sgs[\"ssh_sg\"][\"ingress_protocol\"]\n  ingress_cidr_blocks = var.sg_cidr_blocks[\"ssh_sg\"][\"ingress_cidr_blocks\"]\n  owner_name          = var.owner_name\n  vpc_id              = module.vpc_A.vpc_id\n}\n\nmodule \"ssh_sg_vpcB\" {\n  source              = \"./modules/security-groups\"\n  sg_name             = var.sgs[\"ssh_sg\"][\"sg_name\"]\n  sg_description      = var.sgs[\"ssh_sg\"][\"sg_description\"]\n  ingress_description = var.sgs[\"ssh_sg\"][\"ingress_description\"]\n  ingress_from_port   = var.sgs[\"ssh_sg\"][\"ingress_from_port\"]\n  ingress_to_port     = var.sgs[\"ssh_sg\"][\"ingress_to_port\"]\n  ingress_protocol    = var.sgs[\"ssh_sg\"][\"ingress_protocol\"]\n  ingress_cidr_blocks = var.sg_cidr_blocks[\"ssh_sg\"][\"ingress_cidr_blocks\"]\n  owner_name          = var.owner_name\n  vpc_id              = module.vpc_B.vpc_id\n  providers = {\n    aws = aws.us_west\n  }\n}\n\nmodule \"icmp_sg_vpcA\" {\n  source              = \"./modules/security-groups\"\n  sg_name             = var.sgs[\"icmp_sg\"][\"sg_name\"]\n  sg_description      = var.sgs[\"icmp_sg\"][\"sg_description\"]\n  ingress_description = var.sgs[\"icmp_sg\"][\"ingress_description\"]\n  ingress_from_port   = var.sgs[\"icmp_sg\"][\"ingress_from_port\"]\n  ingress_to_port     = var.sgs[\"icmp_sg\"][\"ingress_to_port\"]\n  ingress_protocol    = var.sgs[\"icmp_sg\"][\"ingress_protocol\"]\n  ingress_cidr_blocks = var.sg_cidr_blocks[\"icmp_sg\"][\"ingress_cidr_blocks_for_vpcA\"]\n  owner_name          = var.owner_name\n  vpc_id              = module.vpc_A.vpc_id\n}\n\nmodule \"icmp_sg_vpcB\" {\n  source              = \"./modules/security-groups\"\n  sg_name             = var.sgs[\"icmp_sg\"][\"sg_name\"]\n  sg_description      = var.sgs[\"icmp_sg\"][\"sg_description\"]\n  ingress_description = var.sgs[\"icmp_sg\"][\"ingress_description\"]\n  ingress_from_port   = var.sgs[\"icmp_sg\"][\"ingress_from_port\"]\n  ingress_to_port     = var.sgs[\"icmp_sg\"][\"ingress_to_port\"]\n  ingress_protocol    = var.sgs[\"icmp_sg\"][\"ingress_protocol\"]\n  ingress_cidr_blocks = var.sg_cidr_blocks[\"icmp_sg\"][\"ingress_cidr_blocks_for_vpcB\"]\n  owner_name          = var.owner_name\n  vpc_id              = module.vpc_B.vpc_id\n  providers = {\n    aws = aws.us_west\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 4: EC2를 위한 모듈 생성 및 가져오기\n\nmodules/ec2/main.tf\n\n```js\nterraform {\n  required_providers {\n    aws = {\n      source                = \"hashicorp/aws\"\n      version               = \"~> 5.0\"\n      configuration_aliases = [aws.us_west]\n    }\n  }\n}\n\nprovider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-1\"\n}\n\nresource \"aws_instance\" \"my_ec2\" {\n\n  ami                         = var.ami_id\n  instance_type               = var.instance_type\n  subnet_id                   = var.subnet_id\n  associate_public_ip_address = true\n  key_name                    = var.key_name\n\n  tags = {\n    Name       = var.ec2_name\n    created_by = var.owner_name\n  }\n}\n\nresource \"aws_network_interface_sg_attachment\" \"ssh_sg_attachment\" {\n  security_group_id    = var.ssh_sg_id\n  network_interface_id = aws_instance.my_ec2.primary_network_interface_id\n}\n\nresource \"aws_network_interface_sg_attachment\" \"icmp_sg_attachment\" {\n  security_group_id    = var.icmp_sg_id\n  network_interface_id = aws_instance.my_ec2.primary_network_interface_id\n}\n```\n\n이제 모듈을 프로젝트 루트의 main.tf 파일에 가져오겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nmodule \"ec2_vpcA\" {\nsource = \"./modules/ec2\"\nsubnet_id = module.subnetsForvpc_A[\"subnet1\"].subnet_id\nami_id = var.ec2s[\"ec2_vpcA\"][\"ami_id\"]\ninstance_type = var.ec2s[\"ec2_vpcA\"][\"instance_type\"]\nec2_name = var.ec2s[\"ec2_vpcA\"][\"ec2_name\"]\nkey_name = var.ec2s[\"ec2_vpcA\"][\"key_name\"]\nssh_sg_id = module.ssh_sg_vpcA.sg_id\nicmp_sg_id = module.icmp_sg_vpcA.sg_id\nowner_name = var.owner_name\n}\n\nmodule \"ec2_vpcB\" {\nsource = \"./modules/ec2\"\nsubnet_id = module.subnetsForvpc_B[\"subnet1\"].subnet_id\nami_id = var.ec2s[\"ec2_vpcB\"][\"ami_id\"]\ninstance_type = var.ec2s[\"ec2_vpcB\"][\"instance_type\"]\nec2_name = var.ec2s[\"ec2_vpcB\"][\"ec2_name\"]\nkey_name = var.ec2s[\"ec2_vpcB\"][\"key_name\"]\nssh_sg_id = module.ssh_sg_vpcB.sg_id\nicmp_sg_id = module.icmp_sg_vpcB.sg_id\nowner_name = var.owner_name\nproviders = {\naws = aws.us_west\n}\n}\n\n## Step 5: Create modules for Internet Gateways and importing them\n\nmodules/internet-gateways/main.tf\n\nterraform {\nrequired_providers {\naws = {\nsource = \"hashicorp/aws\"\nversion = \"~> 5.0\"\nconfiguration_aliases = [aws.us_west]\n}\n}\n}\n\nprovider \"aws\" {\nalias = \"us_west\"\nregion = \"us-west-1\"\n}\n\nresource \"aws_internet_gateway\" \"i_gw\" {\nvpc_id = var.vpc_id\n\ntags = {\nName = var.igw_name\ncreated_by = var.owner_name\n}\n}\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제, 프로젝트 루트의 main.tf 파일에 모듈을 가져오겠습니다.\n\n```js\nmodule \"igw_vpcA\" {\n  source     = \"./modules/internet-gateways\"\n  vpc_id     = module.vpc_A.vpc_id\n  igw_name   = var.igws[\"igw_vpcA\"][\"name\"]\n  owner_name = var.owner_name\n}\n\nmodule \"igw_vpcB\" {\n  source     = \"./modules/internet-gateways\"\n  vpc_id     = module.vpc_B.vpc_id\n  igw_name   = var.igws[\"igw_vpcB\"][\"name\"]\n  owner_name = var.owner_name\n  providers = {\n    aws = aws.us_west\n  }\n}\n```\n\n## 단계 6: VPC Peering, VPC Peering accepter, VPC Peering configure용 모듈 생성 및 가져오기\n\n모듈 - VPC Peering (modules/vpc-peering/main.tf)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```kotlin\n테라폼 {\n  필수_제공자 {\n    aws = {\n      소스 = \"hashicorp/aws\"\n      버전 = \"~> 5.0\"\n      구성_별칭 = [aws.us_west]\n    }\n  }\n}\n\n제공자 \"aws\" {\n  별칭  = \"us_west\"\n  지역 = \"us-west-1\"\n}\n\n리소스 \"aws_vpc_peering_connection\" \"vpc_peering\" {\n  peer_vpc_id = var.peer_vpc_id\n  vpc_id      = var.vpc_id\n  peer_region = \"us-west-1\"\n  tags = {\n    이름       = var.vpcpeer_name\n    생성자 = var.owner_name\n  }\n}\n```\n\n모듈 — VPC 피어링 수락자 (modules/vpc-peering-accepter/main.tf)\n\n```kotlin\n테라폼 {\n  필수_제공자 {\n    aws = {\n      소스 = \"hashicorp/aws\"\n      버전 = \"~> 5.0\"\n      구성_별칭 = [aws.us_west]\n    }\n  }\n}\n\n제공자 \"aws\" {\n  별칭  = \"us_west\"\n  지역 = \"us-west-1\"\n}\n\n리소스 \"aws_vpc_peering_connection_accepter\" \"peer_vpc_AB\" {\n  provider = aws.us_west\n\n  vpc_peering_connection_id = var.vpc_peering_id\n  auto_accept               = true\n\n  tags = {\n    쪽       = \"수락자\"\n    소유자_이름 = var.owner_name\n  }\n}\n```\n\n모듈 — VPC 피어링 구성 (modules/vpc-peering-configure/main.tf)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nterraform {\n  required_providers {\n    aws = {\n      source                = \"hashicorp/aws\"\n      version               = \"~> 5.0\"\n      configuration_aliases = [aws.us_west]\n    }\n  }\n}\n\nprovider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-1\"\n}\n\nresource \"aws_vpc_peering_connection_options\" \"vpc_peering_configure\" {\n  vpc_peering_connection_id = var.vpc_peering_connection_id\n}\n```\n\n이제, 위의 모든 모듈을 루트의 main.tf 파일로 가져오겠습니다.\n\n```js\nmodule \"vpc_peering\" {\n  source       = \"./modules/vpc-peering\"\n  peer_vpc_id  = module.vpc_B.vpc_id\n  vpc_id       = module.vpc_A.vpc_id\n  vpcpeer_name = var.vpcpeer_name\n  owner_name   = var.owner_name\n}\n\nmodule \"vpc_peering_accepter\" {\n  source         = \"./modules/vpc-peering-accepter\"\n  vpc_peering_id = module.vpc_peering.aws_vpc_peering_connection_id\n  owner_name     = var.owner_name\n  providers = {\n    aws = aws.us_west\n  }\n}\n\nmodule \"vpc_peering_configureA\" {\n  source                    = \"./modules/vpc_peer_configure\"\n  vpc_peering_connection_id = module.vpc_peering_accepter.aws_vpc_peering_connection_accepter\n}\n\nmodule \"vpc_peering_configureB\" {\n  source                    = \"./modules/vpc_peer_configure\"\n  vpc_peering_connection_id = module.vpc_peering_accepter.aws_vpc_peering_connection_accepter\n  providers = {\n    aws = aws.us_west\n  }\n}\n```\n\n## 단계 7: 라우트 테이블을 위한 모듈 만들기 및 가져오기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nmodules/route-tables/main.tf\n\n```js\nterraform {\n  required_providers {\n    aws = {\n      source                = \"hashicorp/aws\"\n      version               = \"~> 5.0\"\n      configuration_aliases = [aws.us_west]\n    }\n  }\n}\n\nprovider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-1\"\n}\n\nresource \"aws_route\" \"route\" {\n  route_table_id            = var.route_table_id\n  destination_cidr_block    = var.destination_cidr_block\n  gateway_id                = var.gateway_id != \"\" ? var.gateway_id : null\n  vpc_peering_connection_id = var.vpc_peering_connection_id != \"\" ? var.vpc_peering_connection_id : null\n}\n```\n\n이제 프로젝트 루트의 main.tf 파일에 모듈을 가져와보겠습니다.\n\n```js\nmodule \"route_table_vpcA_pcgw\" {\n  source                    = \"./modules/route-table\"\n  route_table_id            = module.vpc_A.default_route_table_id\n  destination_cidr_block    = var.destination_cidr_blocks_for_routetable[\"for_route_vpcA\"][\"pcgw_cidr\"]\n  vpc_peering_connection_id = module.vpc_peering.aws_vpc_peering_connection_id\n  gateway_id                = \"\"\n}\n\nmodule \"route_table_vpcB_pcgw\" {\n  source                    = \"./modules/route-table\"\n  route_table_id            = module.vpc_B.default_route_table_id\n  destination_cidr_block    = var.destination_cidr_blocks_for_routetable[\"for_route_vpcB\"][\"pcgw_cidr\"]\n  vpc_peering_connection_id = module.vpc_peering.aws_vpc_peering_connection_id\n  gateway_id                = \"\"\n  providers = {\n    aws = aws.us_west\n  }\n}\n\nmodule \"route_table_vpcA_igw\" {\n  source                    = \"./modules/route-table\"\n  route_table_id            = module.vpc_A.default_route_table_id\n  destination_cidr_block    = var.destination_cidr_blocks_for_routetable[\"for_route_vpcA\"][\"igw_cidr\"]\n  gateway_id                = module.igw_vpcA.igw_id\n  vpc_peering_connection_id = \"\"\n}\n\nmodule \"route_table_vpcB_igw\" {\n  source                    = \"./modules/route-table\"\n  route_table_id            = module.vpc_B.default_route_table_id\n  destination_cidr_block    = var.destination_cidr_blocks_for_routetable[\"for_route_vpcB\"][\"igw_cidr\"]\n  gateway_id                = module.igw_vpcB.igw_id\n  vpc_peering_connection_id = \"\"\n  providers = {\n    aws = aws.us_west\n  }\n}\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 단계 8: dev-env.tfvars 파일 작성\n\nvariable.tfvars/dev-env.tfvars\n\n```js\nowner_name = \"NIKUNJ\"\n\nvpcs = {\n  \"vpc_A\" = {\n    vpc_name   = \"vpc-us-east1\"\n    cidr_block = \"10.1.0.0/16\"\n  }\n  \"vpc_B\" = {\n    vpc_name   = \"vpc-us-west1\"\n    cidr_block = \"10.2.0.0/16\"\n  }\n}\n\nvpc_A에 대한 서브넷 목록 = {\n  \"subnet1\" = {\n    subnet_cidr       = \"10.1.0.0/20\"\n    subnet_name       = \"subnet-us-east1a\"\n    availability_zone = \"us-east-1a\"\n  }\n  \"subnet2\" = {\n    subnet_cidr       = \"10.1.16.0/20\"\n    subnet_name       = \"subnet-us-east1b\"\n    availability_zone = \"us-east-1b\"\n  }\n  \"subnet3\" = {\n    subnet_cidr       = \"10.1.32.0/20\"\n    subnet_name       = \"subnet-us-east1c\"\n    availability_zone = \"us-east-1c\"\n  }\n}\n\nvpc_B에 대한 서브넷 목록 = {\n  \"subnet1\" = {\n    subnet_cidr       = \"10.2.0.0/20\"\n    subnet_name       = \"subnet-us-west1a\"\n    availability_zone = \"us-west-1a\"\n  }\n  \"subnet2\" = {\n    subnet_cidr       = \"10.2.16.0/20\"\n    subnet_name       = \"subnet-us-west1b\"\n    availability_zone = \"us-west-1b\"\n  }\n}\n\n보안 그룹 목록 = {\n  \"ssh_sg\" = {\n    sg_name             = \"allow_ssh\"\n    sg_description      = \"내 IP에서 SSH 허용\"\n    ingress_description = \"내 IP를 위한 SSH\"\n    ingress_from_port   = \"22\"\n    ingress_to_port     = \"22\"\n    ingress_protocol    = \"tcp\"\n  }\n  \"icmp_sg\" = {\n    sg_name             = \"allow_ping_traffic\"\n    sg_description      = \"내 IP에서 ping 허용\"\n    ingress_description = \"내 IP로부터의 ping\"\n    ingress_from_port   = \"8\"\n    ingress_to_port     = \"0\"\n    ingress_protocol    = \"icmp\"\n  }\n}\n\nsg_cidr_blocks = {\n  \"ssh_sg\" = {\n    ingress_cidr_blocks = [\"12.34.56.78/32\"] # ec2로의 SSH가 허용된 IP를 언급\n  }\n  \"icmp_sg\" = {\n    ingress_cidr_blocks_for_vpcA = [\"10.2.0.0/16\"]\n    ingress_cidr_blocks_for_vpcB = [\"10.1.0.0/16\"]\n  }\n}\n\nec2 목록 = {\n  \"ec2_vpcA\" = {\n    ami_id        = \"ami-0e8a34246278c21e4\"\n    instance_type = \"t2.micro\"\n    ec2_name      = \"ec2-us-east1\"\n    key_name      = \"us-east-1-demo\"\n  }\n  \"ec2_vpcB\" = {\n    ami_id        = \"ami-09ab9d570789dfdd4\"\n    instance_type = \"t2.micro\"\n    ec2_name      = \"ec2-us-west1\"\n    key_name      = \"us-west-1-demo\"\n  }\n}\n\n인터넷 게이트웨이 목록 = {\n  \"igw_vpcA\" = {\n    name = \"igw_vpcA\"\n  }\n  \"igw_vpcB\" = {\n    name = \"igw_vpcB\"\n  }\n}\n\nVPC 피어링 이름 = \"vpc_AB_peering\"\n\nroute 테이블용 대상 CIDR 블록 = {\n  \"for_route_vpcA\" = {\n    pcgw_cidr = \"10.2.0.0/16\"\n    igw_cidr  = \"0.0.0.0/0\"\n  }\n  \"for_route_vpcB\" = {\n    pcgw_cidr = \"10.1.0.0/16\"\n    igw_cidr  = \"0.0.0.0/0\"\n  }\n}\n```\n\n## 단계 9: 작업 디렉토리 초기화\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 작업 디렉토리에서 terraform init 명령을 실행하세요. 이 명령은 필요한 모든 공급자 및 모듈을 다운로드하고 백엔드를 초기화합니다.\n\n## 단계 10: 테라폼 실행 계획 생성\n\n- 작업 디렉토리에서 terraform plan 명령을 실행하세요. 실행 계획을 제공합니다.\n\n## 단계 11: terraform apply 실행\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 작업 디렉토리에서 terraform apply 명령을 실행하면 AWS에 필요한 모든 리소스가 생성됩니다.\n\n## 단계 12: 연결 확인\n\n- SSH를 사용하여 EC2 인스턴스 중 하나에 연결하고 다른 EC2 인스턴스의 사설 IP를 사용하여 핑을 보냅니다.\n- 모든 것이 잘 되었다면 ICMP 데이터 패킷이 성공적으로 전송됩니다.\n\n여기까지입니다. 이제 Terraform을 사용하여 AWS VPC 피어링 연결을 생성하는 방법을 배웠습니다. 이제 여러분은 이것을 사용하고 필요에 따라 수정할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n전체 코드는 여기에서 찾을 수 있어요.\n\n이 가이드가 도움이 되었다면 👏 버튼을 클릭해 주세요. 댓글도 자유롭게 남겨주세요.\n","ogImage":{"url":"/assets/img/2024-05-27-AWS-VPCPeeringwithTerraform_0.png"},"coverImage":"/assets/img/2024-05-27-AWS-VPCPeeringwithTerraform_0.png","tag":["Tech"],"readingTime":22},{"title":"쿠버네티스를 시작할 때 알았더라면 좋았을 것 같은 점","description":"","date":"2024-05-27 17:33","slug":"2024-05-27-WhatIWishIKnewWhenIGotStartedwithKubernetes","content":"\nKubernetes를 처음 봤을 때는 복잡해 보일 수 있지만, 이해해야 할 수많은 핵심 개념과 용어가 있습니다. 더욱 사실적인 것은 Kubernetes에 대해 깊이 파고들기 위해서는 많은 실전 실습이 필요하다는 점입니다.\n\n그래서 이 블로그 포스트에서는 Kubernetes를 처음 시작할 때 알았으면 하는 내용을 공유하고자 합니다. 함께 실전학습을 위한 예시 로컬 클러스터를 설정해봅시다.\n\n![이미지](/assets/img/2024-05-27-WhatIWishIKnewWhenIGotStartedwithKubernetes_0.png)\n\n# Kubernetes를 배워야 하는 이유?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nOpenAI가 쿠버네티스에 배포되어 7,500개의 워커 노드로 확장되고 있다는 걸 알고 계셨나요? 그리고 Apple과 같은 기술 거물들은 2022년에 아파치 메소스에서 쿠버네티스로 전환하여 쿠버네티스를 주요 컨테이너화 플랫폼으로 채택했어요.\n\n쿠버네티스가 마이크로서비스 아키텍처에 어떻게 적합한지 이야기할 때, 느슨하게 결합된 단위의 단일 개념을 컨테이너에 넣거나 서버리스 함수를 활용하는 것은 모두 타당한 해결책입니다.\n\n컨테이너는 응용 프로그램과 해당 종속성을 쉽게 한 컴퓨팅 환경에서 다른 환경으로 쉽게 이동할 수 있도록 패키지화하고 격리하는 방법입니다. 더불어 애플리케이션을 일관되고 신뢰할 수 있게 배포하는 데 도움이 되며, 사용자의 컴퓨터 설정과 무관하게 작동합니다.\n\n2024년에 올바른 방법으로 쿠버네티스를 배우는 데 도움이 되는 미디움 포스트를 작성했어요. 그리고 이 분야에서 경력을 시작하기 위해 학습을 확장하고 싶다면, 쿠버네티스 인증을 취득하는 것이 좋은 길일 거예요. 아래 책이 도움이 될 거예요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 관리 Kubernetes 플레이그라운드 활용하기\n\n시작하기 전에, 시장에는 많은 관리 Kubernetes 플레이그라운드가 있음을 감안해야 합니다.\n\n- 관리 Kubernetes 플레이그라운드는 인프라를 설정하고 관리하는 수고를 들이지 않고 Kubernetes 클러스터를 실험할 수 있는 기회를 제공합니다. 보통 미리 구성된 Kubernetes 환경을 제공하여 사용자가 웹 인터페이스나 명령줄 인터페이스를 통해 액세스할 수 있습니다.\n- 이러한 플랫폼은 교육 자료와 대화형 튜토리얼도 제공하는데, 새로운 Kubernetes 기능들을 번거롭지 않은 환경에서 사용해보는 좋은 방법입니다.\n\n## Killercoda 플레이그라운드\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKillercoda는 로컬 설정이나 자원 소모가 많은 브라우저의 귀찮음 없이 완전히 기능적인 Linux 또는 Kubernetes 환경에 즉시 브라우저 액세스를 제공하는 가상 놀이터입니다. 원격 유지 보수는 로컬에서 액세스했을 때 원활한 사용성을 보장합니다. 최신 상태를 유지하기 위한 계속된 헌신으로, Killercoda는 지난릴리즈 후 몇 주만에 최신 Kubeadm Kubernetes 버전을 지속적으로 업데이트합니다.\n\n이 게시물 작성 시점을 기준으로 사용자들은 두 개의 2GB 노드로 구성된 초기 빈 Kubeadm 클러스터에 액세스를 즐길 수 있습니다:\n\n![Kubernetes Image](/assets/img/2024-05-27-WhatIWishIKnewWhenIGotStartedwithKubernetes_1.png)\n\n## 킬러 셸 플레이그라운드\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n특정 시나리오나 시험 시뮬레이션을 찾고 있는 분들은 CKS, CKA, CKAD, LFCS, 그리고 LFCT 시험을 위해 디자인된 Killer Shell을 살펴보세요. Killer Shell은 실제 시뮬레이터와 인터랙티브 학습 환경을 제공하여 사용자가 시나리오를 철저히 탐구하고 편리하게 학습할 수 있도록 돕습니다. 위 시험 중 하나를 패스하고 싶다면, 공식 CKA 시험 시뮬레이터인 Killer Shell에서 제공되는 샘플 시나리오를 살펴보는 것을 강력히 추천합니다.\n\n또한, 실전 중심 시험에서의 시간 관리가 매우 중요합니다. 공식 문서의 특정 페이지를 북마크해두는 것은 당신의 준비에 매우 도움이 될 것입니다.\n\n또한, Kubernetes를 배우기 시작하는 플레이리스트를 준비했습니다. 관심이 있다면 확인해보세요.\n\n## Kubernetes Playground에서 Kubernetes와 놀아보세요\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nPlay with Kubernetes는 도커가 제공하는 랩 사이트로, K8s 플레이그라운드를 제공합니다. 사용자는 빠르게 K8s 클러스터를 시작하고 브라우저에서 직접 무료 Alpine Linux VM을 경험할 수 있습니다. Docker-in-Docker (DinD)를 사용하여 여러 VM/PC를 시뮬레이션하여 원활한 경험을 제공합니다. 그들의 안내에 따라 GitHub 저장소에서 최신 정보를 확인하세요.\n\n플레이그라운드를 이용하는 것은 Kubernetes를 배우고 배운 내용을 실험하면서 시간을 절약하는 좋은 방법입니다.\n\n# Kubernetes 노드 아키텍처\n\nKubernetes는 단일 노드 및 다중 노드 아키텍처를 모두 지원하며, 각각의 장점과 사용 사례가 있습니다. Kubernetes 클러스터 아키텍처에 대해 더 자세히 알고 싶다면 이 포스트를 확인해보세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기서 각각의 것을 살펴보겠습니다 :\n\n## 단일 노드 아키텍처\n\n단일 노드 아키텍처에서는 모든 Kubernetes 구성 요소가 한 대의 기계에서 실행됩니다. 이 설정은 단순성이 확장성과 고가용성보다 우선이 되는 로컬 개발 환경이나 테스트 환경에 적합합니다.\n\n단일 노드 배포를 지원하는 Kubernetes 배포 중 하나는 Minikube입니다. Minikube는 사용자의 워크스테이션에서 로컬로 실행되는 가벼운 Kubernetes 클러스터를 제공하여 개발자가 Kubernetes 기능과 응용 프로그램을 쉽게 실험할 수 있도록 하며 완전한 규모의 클러스터가 필요하지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다른 예로는 MicroK8s가 있습니다. MicroK8s는 엣지 컴퓨팅 및 사물인터넷(IoT) 디바이스를 위한 최소한의 단일 노드 Kubernetes 배포를 제공합니다. 이러한 Kubernetes 배포는 단일 노드 클러스터의 설정과 관리를 간소화하여 개발자들이 Kubernetes 개발 및 테스트를 시작하기 편리하게 만듭니다.\n\n![Image](/assets/img/2024-05-27-WhatIWishIKnewWhenIGotStartedwithKubernetes_2.png)\n\n## 다중 노드 아키텍처\n\n그러나 대부분의 엔터프라이즈 환경은 주로 고유노드 클러스터를 만족시키기 위해 단일 노드 클러스터보다 많은 노드를 필요로 합니다. 이러한 환경은 주로 다중 노드 설정입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nKubernetes에서 다중 노드 아키텍처는 Kubernetes 구성 요소를 여러 대의 머신에 분산하여 중복성과 확장성을 제공합니다. 이는 고가용성 및 오류 허용성을 가능하게 하며, 프로덕션 환경 및 대규모 배포에 이상적입니다.\n\n다중 노드 클러스터를 구성하고 관리하는 것은 단일 노드보다 더 복잡하며 최적의 성능과 자원 활용을 보장하기 위해 신중한 계획이 필요합니다.\n\n최종적으로, 단일 노드 및 다중 노드 아키텍처 사이의 선택은 Kubernetes 배포의 구체적인 요구 사항과 목표에 따라 다릅니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 첫 번째 로컬 쿠버네티스 클러스터 설정하기\n\nminikube를 사용하여 Kubernetes 클러스터를 만드는 것은 로컬 Kubernetes 클러스터를 생성하는 가장 쉬운 방법이며 몇 분만에 완료할 수 있습니다. 다음은 해야 할 일입니다:\n\n## minikube 설치\n\n로컬이나 클라우드 기반 Linux VM에서 minikube 이진 파일을 검색하기 위해 curl 명령을 사용하고, 다음과 같이 /usr/local/bin/minikube에 설치하십시오:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n```\n\n다음 단계로 넘어가기 전에 minikube 이진 파일이 설치되었는지 확인하려면 /usr/local/bin/minikube로 이동하십시오. 또한 터미널에 다음을 입력하여 Minikube를 사용할 수 있는지 확인할 수도 있습니다 :\n\n```js\nminikube –-help\n```\n\n## 단일 노드 Kubernetes 클러스터 프로비저닝\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMinikube를 사용하여 단일 노드 Kubernetes 클러스터를 프로비저닝하려면 단순히 다음 명령을 사용할 수 있어요 :\n\n```js\nminikube start\n```\n\n만약 minikube 클러스터를 시작할 때 CPU 코어와 메모리를 설정하고 싶다면, 메모리 및 CPU 플래그를 추가하여 다음과 같이 실행하세요 :\n\n```js\nminikube start --memory 8192 --cpus 4\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n명령이 실행된 후, 당신의 minikube 클러스터는 프로비저닝 프로세스에 있습니다. 마지막에는 minikube Kubernetes 클러스터를 사용할 준비가 되었다는 메시지가 표시될 것입니다.\n\n## 설치 확인\n\nMinikube 클러스터는 단일 노드로 구성되어 있으며, 통제 평면 및 워커 노드 역할을 수행합니다. 이 설정을 통해 구성된지 한 뒤에는 로컬 Kubernetes 클러스터 내에서 작업 로드를 예약하기 시작할 수 있습니다. 노드가 사용 준비되었는지 확인하려면 다음 명령을 사용할 수 있습니다:\n\n```js\nKubectl get node\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 명령어의 단축키를 사용해보세요:\n\n```js\nalias k=kubectl\nk get no\n```\n\n출력 결과를 통해 다음 정보를 확인할 수 있습니다:\n\n- 노드의 상태(사용 가능 여부)\n- 해당 노드의 역할\n- Kubernetes 버전\n- 초기 배포 이후의 노드 연령\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Minikube 클러스터 구성\n\n만약 새로운 클러스터를 다시 제공하지 않고 minikube 클러스터를 구성하고 싶다면, minikube 클러스터를 중지해야 합니다.\n\nBash\n\n```js\nminikube stop\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nminikube config set 명령어를 사용하면 원하는 설정을 minikube 클러스터에 적용할 수 있어요.\n\nMinikube 클러스터 구성을 마치면 클러스터를 시작해야 해요. 그 후에는 새 구성으로 클러스터에서 작업할 거예요.\n\n더 많은 메모리와 CPU를 사용하여 minikube 클러스터를 구성해볼까요:\n\n```js\nminikube stop\n\nminikube config set memory 8192\nminikube config set cpus 4\nminikube start\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 미니큐브 클러스터를 사용할 준비가 되었어요.\n\n## 미니큐브 클러스터 삭제\n\n로컬 Kubernetes 클러스터와 모든 프로파일을 삭제합니다 :\n\n```js\nminikube delete --all\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 실습이 최고입니다!\n\n다음 비디오에서 몇 분 만에 Minikube 클러스터를 쉽게 설정하는 방법을 보여드립니다. Apple 실리콘 (ARM 기반)인 M1/M2 맥북과 같은 환경을 설정합니다:\n\n여기 릴리스 노트에 기능이 특징화된 최신 Kubernetes 릴리스를 빠르게 테스트하기 위해 이 섹션에서 배운 내용을 복제할 수 있습니다.\n\n# 기대가 됩니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n로컬 Kubernetes를 쉽게 설정할 수 있는 다양한 옵션이 많이 있다는 것을 기쁘게 생각해요. 대부분의 플레이그라운드는 무료로 제공되니 현명한 선택을 해서 다양한 방법을 시도해보세요. 이 블로그가 2024년 Kubernetes를 시작하려는 분들에 도움이 되길 진심으로 바랍니다! 더 알고 싶다면 제 미디엄 팔로우나 YouTube 채널을 구독해주시고, 댓글로 의견을 공유해주세요.\n\n# 간단하게 설명하자면 🚀\n\nIn Plain English 커뮤니티에 함께해주셔서 감사합니다! 떠나시기 전에:\n\n- 꼬옥 박수를 치시고 작가를 팔로우해주세요 ️👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문: Stackademic | CoFeed | Venture | Cubed\n- PlainEnglish.io에서 더 많은 콘텐츠를 만나보세요\n","ogImage":{"url":"/assets/img/2024-05-27-WhatIWishIKnewWhenIGotStartedwithKubernetes_0.png"},"coverImage":"/assets/img/2024-05-27-WhatIWishIKnewWhenIGotStartedwithKubernetes_0.png","tag":["Tech"],"readingTime":11},{"title":"지난 18개월간의 내부 개발자 플랫폼 붐","description":"","date":"2024-05-27 17:31","slug":"2024-05-27-TheBoomofInternalDeveloperPlatformsintheLast18Months","content":"\n지난 18개월 동안 내부 개발자 플랫폼(IDP)에 대한 관심이 급증했습니다. 이 추세는 개발자 친화적 인프라 관리 솔루션에 대한 필요성이 증대되고 있다는 것을 반영합니다. 그렇다면 이런 폭증을 촉발하는 것은 무엇이며, 현재의 상황은 어떻게 보이나요?\n\n# 왜 이렇게 성장하고 있는 것일까요?\n\n## 개발자 효율성\n\n개발자들은 소프트웨어를 더 빠르고 신뢰할 수 있게 제공해야 하는 지속적인 압박을 받고 있습니다. IDP는 개발자가 코딩에 집중할 수 있도록 반복적인 작업을 자동화하고 복잡한 워크플로우를 간단하게 만들어 생산성을 향상시킴으로써 개발자의 효율성을 높입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 현대 애플리케이션의 복잡성\n\n현대 애플리케이션은 마이크로서비스와 다양한 기술로 복잡합니다. IDP는 이를 효율적으로 관리할 수 있는 통합 인터페이스를 제공합니다.\n\n## 비용과 자원 관리\n\n효율적인 자원 사용이 중요합니다. IDP는 인프라를 최적화하고 낭비를 줄이며 특히 대규모 기업에게 비용 효율성을 보장합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 보안 및 규정 준수\n\n점점 더 늘어나는 보안 위협과 규정 요구 사항으로 인해, 통제된 및 일관된 배포 환경을 유지하는 것이 중요합니다. IDP는 모든 개발 수명 주기 단계에서 보안 정책과 규정 준수 기준을 강제합니다.\n\n# 현재의 경향\n\n![Image](/assets/img/2024-05-27-TheBoomofInternalDeveloperPlatformsintheLast18Months_0.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내부 개발자 플랫폼의 풍경은 내부 개발자 포털과 내부 개발자 플랫폼 두 가지 주요 범주로 나눌 수 있습니다. 각각의 특징은 다르지만, 그들 사이의 경계가 흐려지기 시작했습니다.\n\n내부 개발자 포털은 개발자들이 문서, API 및 서비스에 접근할 수 있는 중앙 집중형 장소를 제공합니다. 내부 자원의 발견 및 접근성을 향상시켜 개발자들이 필요한 도구를 찾고 사용하기 쉽게 만듭니다.\n\n내부 개발자 플랫폼은 코드부터 배포까지 인프라 관리에 대한 완전한 솔루션을 제공함으로써 한 걸음 더 나아갑니다. 환경 프로비저닝, CI/CD 파이프라인, 모니터링 등을 자동화하여 개발 운영을 위한 포괄적인 플랫폼을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n주요 산업 기업이 개발자 효율성의 가치를 인정하고 자체 IDP 제품을 적극적으로 개발 중임을 알 수 있습니다. Atlassian은 Compass를 소개했고, Red Hat은 자체 솔루션을 개발 중이며, HashiCorp는 Waypoint을 출시했습니다. 기술 세계는 IDP에 대해 열광하고 있습니다! IDP의 중요성은 점점 더 많은 사람들이 참여함에 따라 급속하게 증가하고 있습니다.\n\n# 솔루션의 융합\n\n플랫폼 엔지니어링 팀이 수렴하는 요구에 직면함에 따라 두 범주는 서로의 기능을 통합하기 시작했습니다. 내부 개발자 포털은 더 많은 자동화 및 통합 기능을 추가하고, 내부 개발자 플랫폼은 사용자 인터페이스 및 리소스 검색 기능을 향상시키고 있습니다. 몇 가지 예시는 다음과 같습니다:\n\n- Humanitec: 원래 오케스트레이터로 유명한 Humanitec은 이제 초기 범위를 넘어 확장된 포털을 제공하는 작업에 착수했습니다.\n- Qovery: 훌륭한 개발자 경험에 초점을 맞춘 내부 개발자 플랫폼을 제공하는 Qovery는 포털을 포함한 기능을 확장했습니다.\n- Port: 원래 내부 개발자 포털이었던 Port는 이제 더 많은 통합 및 기능을 통합하여 플랫폼으로 변화하고 있습니다. 자동화된 인프라 생성이 필요한 단명 환경과 같은 사용 사례를 제안하는 등 종합적인 내부 개발자 플랫폼의 상징적인 특징을 갖추고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-05-27-TheBoomofInternalDeveloperPlatformsintheLast18Months_2.png)\n\n이 통합은 현대 개발 팀의 다양한 요구를 충족하는 통합 솔루션을 제공하기 위해 노력하고 있습니다.\n\n# 결론\n\n내부 개발자 플랫폼은 효율적인 소프트웨어 개발의 요구를 충족하기 위해 급부상하고 있습니다. 그들은 복잡성에 대처하고 비용을 절감하며 보안에 대한 최상의 실천 방법을 강화합니다. 포털과 플랫폼 사이의 경계가 흐려지면서 원활한 개발자 생산성과 인프라 관리의 새로운 시대가 열리고 있습니다. 더 기대되는 일이 없겠죠! 여러분은 어떠신가요? :)\n","ogImage":{"url":"/assets/img/2024-05-27-TheBoomofInternalDeveloperPlatformsintheLast18Months_0.png"},"coverImage":"/assets/img/2024-05-27-TheBoomofInternalDeveloperPlatformsintheLast18Months_0.png","tag":["Tech"],"readingTime":4},{"title":"Grafana Alloy OpenTelemetry","description":"","date":"2024-05-27 17:29","slug":"2024-05-27-GrafanaAlloyOpenTelemetry","content":"\n## Alloy에 인사를 전해보세요\n\n## 소개\n\nGrafana 에이전트가 최근에 Alloy로 전환되었습니다. 이 게시물에서는 이에 대해 안내해 드리겠습니다. 대부분의 예시는 에이전트에서 벤더의 백엔드로 직접 텔레미터 데이터를 보내는 것을 보여줍니다. 그러나 OpenTelemetry는 Collector라는 흥미로운 구성 요소를 소개했습니다.\n\nOpenTelemetry Collector를 사용하면 사용자는 데이터를 효과적으로 제어하여 변형, 보완 및 벤더 중립적인 대상 결정을 할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저번 포스트인 \"OpenTelemetry as a Service\"를 참고해보세요. 그곳에서 중앙 OpenTelemetry 수집기(게이트웨이)를 설정하는 더 많은 정보를 얻을 수 있습니다.\n\n## Grafana Alloy가 무엇이며, 사용해야 하는 이유는 무엇인가요?\n\nGrafana Alloy는 OpenTelemetry (OTEL) 에이전트로 작동하여 다양한 소스에서 텔레메트리 데이터를 수집하고 모니터링 시스템으로 전송하여 분석 및 시각화하는 기능을 제공합니다.\n\nAlloy는 OpenTelemetry 수집기나 Grafana 에이전트와 같은 데이터 수집 구성 요소를 대체합니다. 하지만 Mimir, Tempo, 또는 Loki와 같은 도구를 대체하지는 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예를 들어, Grafana에서 로그, 메트릭 및 추적 데이터를 소화하고 표시하려는 경우, Loki, Mimir 및 Tempo를 데이터 원본으로 설정하고 Alloy를 배포하여 데이터를 스크랩하고 전송할 수 있습니다.\n\n이 방법을 통해 한 구성 요소로 여러 목적을 위한 소화를 관리할 수 있습니다. 이를 통해 Alloy는 다양한 모니터링 요구 사항을 충족할 수 있는 다재다능한 도구가 됩니다.\n\n## Grafana Alloy의 Walkthrough\n\n## Prerequisites\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n시작하기 전에 Kubernetes 클러스터를 설정해 두세요. 다음 명령을 실행하여 새로운 로컬 Kubernetes 클러스터를 만들 수 있어요: kind create cluster\n\n그리고 무료 Grafana Cloud 계정이 필요해요. Grafana Cloud는 Grafana, Mimir, Loki, Tempo와 같은 오픈 소스 프로젝트로 구축된 완전히 관리되는 클라우드 관측성 플랫폼이에요. 아직 가입하지 않았다면 무료 계정으로 가입하세요. 여기서 할 작업에 대해 충분히 제공해 줄 거에요.\n\n필요한 저장소를 추가하세요:\n\n```js\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 환경 설정 설정\n\nGrafana Alloy를 Grafana Cloud에서 Kubernetes 클러스터에 구성하는 두 가지 대안이 있습니다. 간단한 방법부터 시작하여 둘 다 자세히 설명하겠습니다.\n\n## 대안 1 (가장 쉬운 방법)\n\nGrafana Cloud에서 Kubernetes 클러스터용 Grafana Alloy를 구성하려면 다음 단계를 따라주십시오:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Grafana Cloud에서 인프라스트럭처 `Kubernetes` 구성으로 이동합니다.\n- 활성화하려는 기능을 선택합니다.\n\n- 메트릭: 이 옵션은 Kubernetes 클러스터 인프라 메트릭을 수집하여 Grafana Cloud Prometheus로 전송합니다.\n- 비용 메트릭: 비용 메트릭을 스크랩하고 Grafana Cloud Prometheus로 전송하려면 이 기능을 활성화하세요.\n- 클러스터 이벤트: Kubernetes 클러스터 이벤트를 캡처하여 Grafana Cloud Loki로 전송합니다.\n- Pod 로그: Pod 로그를 캡처하고 Grafana Cloud Loki로 전송합니다.\n- OTLP 수신기: Grafana Alloy를 구성하여 OTLP/gRPC 및 OTLP/HTTP를 통해 OpenTelemetry 데이터를 수신합니다.\n\n3. 구성 프로세스를 계속합니다.\n\n그러나 데이터를 별도의 OpenTelemetry Collector로 전송하려면 대체 2를 계속하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 대안 2 (권장하는 방법)\n\n이 방법은 구성 프로세스에 대한 더 많은 유연성과 제어를 제공합니다.\n\n- 먼저 헬름 값 파일을 준비하세요.\n- 요구 사항에 따라 헬름 값 파일을 구성하고, 'OTLP endpoint', 'your_endpoint', 'my_username', 'my_secret_password'를 실제 값으로 교체해야 합니다. 또한, OTLP를 HTTP를 통해 사용하는 경우 서버 프로토콜이 otlphttp로 설정되어 있는지 확인해주세요.\n\n```js\nhost: <OTLP 엔드포인트>\nwriteEndpoint: /<your_endpoint>\nprotocol: otlphttp\nbasicAuth:\n  username: <my_username>\n  password: <my_secret_password>\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n3. 쿠버네티스 클러스터에 Helm 차트를 배포하세요.\n\n```js\nhelm repo add grafana https://grafana.github.io/helm-charts &&\n  helm repo update &&\n  helm upgrade --install --atomic --timeout 300s grafana-k8s-monitoring grafana/k8s-monitoring \\\n    --namespace \"default\" --create-namespace --values - <<EOF\n```\n\n## 배포 검증\n\nkubectl get all -n default을 사용하여 배포가 성공적으로 이루어졌는지 확인하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\nPODS\n\nNAME                                                        READY   STATUS    RESTARTS   AGE\ngrafana-k8s-monitoring-alloy-0                              2/2     Running   0          7m29s\ngrafana-k8s-monitoring-alloy-events-6fc5d58d6f-k4fz9        2/2     Running   0          7m29s\ngrafana-k8s-monitoring-alloy-logs-x4chm                     2/2     Running   0          7m29s\ngrafana-k8s-monitoring-kube-state-metrics-f995ccbbc-7gdkh   1/1     Running   0          7m29s\ngrafana-k8s-monitoring-opencost-6659b44b6f-dn8ck            1/1     Running   0          7m29s\ngrafana-k8s-monitoring-prometheus-node-exporter-g2ddm       1/1     Running   0          7m29s\n\nDEPLOYMENT\nNAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\ngrafana-k8s-monitoring-alloy-events         1/1     1            1           7m46s\ngrafana-k8s-monitoring-kube-state-metrics   1/1     1            1           7m46s\ngrafana-k8s-monitoring-opencost             1/1     1            1           7m46s\n\nSERVICES\nNAME                                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                               AGE\ngrafana-k8s-monitoring-alloy                      ClusterIP   10.96.55.19     <none>        12345/TCP,4317/TCP,4318/TCP,9999/TCP,14250/TCP,6832/TCP,6831/TCP,14268/TCP,9411/TCP   8m7s\ngrafana-k8s-monitoring-alloy-cluster              ClusterIP   None            <none>        12345/TCP,4317/TCP,4318/TCP,9999/TCP,14250/TCP,6832/TCP,6831/TCP,14268/TCP,9411/TCP   8m7s\ngrafana-k8s-monitoring-alloy-events               ClusterIP   10.96.222.205   <none>        12345/TCP                                                                             8m7s\ngrafana-k8s-monitoring-alloy-logs                 ClusterIP   10.96.68.158    <none>        12345/TCP                                                                             8m7s\ngrafana-k8s-monitoring-grafana-agent              ClusterIP   10.96.207.204   <none>        12345/TCP,4317/TCP,4318/TCP,9999/TCP,14250/TCP,6832/TCP,6831/TCP,14268/TCP,9411/TCP   8m7s\ngrafana-k8s-monitoring-kube-state-metrics         ClusterIP   10.96.168.190   <none>        8080/TCP                                                                              8m7s\ngrafana-k8s-monitoring-opencost                   ClusterIP   10.96.55.101    <none>        9003/TCP                                                                              8m7s\ngrafana-k8s-monitoring-prometheus-node-exporter   ClusterIP   10.96.162.70    <none>        9100/TCP\n\nDAEMONSET\nNAME                                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ngrafana-k8s-monitoring-alloy-logs                 1         1         1       1            1           kubernetes.io/os=linux   8m52s\ngrafana-k8s-monitoring-prometheus-node-exporter   1         1         1       1            1           kubernetes.io/os=linux   8m52s\n\nCONFIGMAPS\nNAME                                  DATA   AGE\ngrafana-k8s-monitoring-alloy          1      9m4s\ngrafana-k8s-monitoring-alloy-events   1      9m4s\ngrafana-k8s-monitoring-alloy-logs     1      9m4s\nkube-root-ca.crt                      1      121m\nkubernetes-monitoring-telemetry       1      9m4s\n```\n\n## Inspecting Grafana Alloy\n\nTo inspect the Grafana Alloy configuration, run:\n\n```yaml\nkubectl get cm grafana-k8s-monitoring-alloy -o yaml\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기에서 OpenTelemetry Collector 내에서 사용되는 수신기, 프로세서, 커넥터 및 익스포터 구성 세부 정보를 살펴볼 수 있습니다.\n\n## 발견\n\nGrafana Alloy가 먼저 다양한 Kubernetes 리소스에 대한 Kubernetes 발견 설정을 설정합니다. 노드, 서비스, 엔드포인트 및 파드와 같은 Kubernetes 리소스를 시각화, 모니터링 및 분석에 활용할 수 있습니다.\n\n```js\n     discovery.kubernetes \"nodes\" {\n       role = \"node\"\n     }\n\n     discovery.kubernetes \"services\" {\n       role = \"service\"\n     }\n\n     discovery.kubernetes \"endpoints\" {\n       role = \"endpoints\"\n     }\n\n     discovery.kubernetes \"pods\" {\n       role = \"pod\"\n     }\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## OTLP 수신기\n\n수신기는 gRPC 및 HTTP를 통해 OpenTelemetry 프로토콜 (OTLP)을 사용하여 텔레미터 데이터를 수집하도록 설정됩니다.\n\n```js\n     // OTLP Receivers\n     otelcol.receiver.otlp \"receiver\" {\n       debug_metrics {\n         disable_high_cardinality_metrics = true\n       }\n\n       grpc {\n         endpoint = \"0.0.0.0:4317\"\n       }\n\n       http {\n         endpoint = \"0.0.0.0:4318\"\n       }\n       output {\n         metrics = [otelcol.processor.resourcedetection.default.input]\n         logs = [otelcol.processor.resourcedetection.default.input]\n         traces = [otelcol.processor.resourcedetection.default.input]\n       }\n     }\n```\n\noutput 블록은 메트릭, 로그 및 추적이 otelcol.processor.resourcedetection.default.input이라는 프로세서로 전송되어야 함을 나타냅니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 처리기\n\n처리기는 텔레메트리 데이터를 변환하고 향상시키기 위해 구성되어 있으며, 모니터링 인프라의 가시성을 향상시키는 데 사용할 수 있습니다. 처리기는 OpenTelemetry Collector 내에서 텔레메트리 데이터를 변환, 감지, 추출 및 필터링하는 데 중요한 역할을 합니다.\n\n예를 들어, 사용되고 있는 처리기는 다음과 같습니다.\n\n```js\notelcol.processor.transform         # 속성을 추가하여 메트릭 데이터를 변환합니다.\notelcol.processor.resourcedetection # 환경에서 리소스를 감지합니다.\notelcol.processor.k8sattributes     # Kubernetes 관련 메타데이터를 추출합니다.\notelcol.connector.host_info         # 호스트 정보를 수집합니다.\notelcol.processor.batch             # 데이터 처리를 일괄로 처리합니다.\notelcol.processor.filter            # 데이터를 필터링합니다.\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Exporters\n\n수출기는 외부 시스템으로 텔레메트리 데이터를 내보내기 위해 정의됩니다. 예를 들어, 메트릭을 프로메테우스로 내보내기, 로그를 로키로 내보내기, 그리고 Tempo로 추적을 내보내는 방식입니다.\n\n## 주석 자동 탐지\n\n주석을 기반으로 동적으로 포드 및 서비스에서 메트릭을 발견하고 스크랩하기 위해 규칙이 정의되어 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 스크래핑 구성\n\n구성은 Kubernetes, cAdvisor, Kubelet 및 Node Exporter와 같은 다양한 구성 요소에서 메트릭을 스크랩하는 데 설정됩니다.\n\n## 라벨 재설정\n\n규칙은 메트릭 및 로그에 부착된 레이블을 수정하기 위해 정의됩니다. 예를 들어 레이블 이름 바꾸기, 불필요한 레이블 삭제 및 특정 메트릭 필터링 등이 포함됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 인증\n\n기본 인증은 수출 업체 및 필요한 다른 구성 요소에 구성되어 있습니다.\n\n구성 파일을 이해하기 위해 구성 맵을 확인하는 것을 권장합니다. 이는 완전한 세부 정보와 구성을 제공합니다.\n\n요구 사항에 맞게 Grafana Alloy 설정을 검토하고 구성한 후 UI로 돌아가서 모든 것이 예상대로 작동하는지 확인하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_0.png\" />\n\n## 모니터링 컴포넌트 탐색\n\n## 클러스터 탐색\n\nGrafana에서 제공하는 기본 클러스터 탐색 기능을 활용하여 Kubernetes 클러스터에 대한 유용한 통찰을 얻어보세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![GrafanaAlloyOpenTelemetry_1](/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_1.png)\n![GrafanaAlloyOpenTelemetry_2](/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_2.png)\n![GrafanaAlloyOpenTelemetry_3](/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_3.png)\n![GrafanaAlloyOpenTelemetry_4](/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 비용 모니터링\n\nGrafana의 비용 개요 페이지를 활용하여 클라우드 비용을 모니터링하세요. 효율적인 자원 관리에 중요합니다.\n\n## 알림\n\n중요한 이벤트에 대한 예방적인 모니터링과 즉각적인 대응을 위해 경보 규칙 및 기록 규칙을 설정하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Cardinality\n\n이 게시물은 카디널리티에 집중한 것은 아니지만, 중요한 부분이기 때문에 언급해야 합니다. 카디널리티를 모니터링하면 데이터의 고유성을 이해할 수 있어 성능 및 자원 이용을 최적화하는 데 중요합니다. 고카디널리티는 많은 고유값을 가진 데이터 세트를 가리킵니다.\n\nGrafana Cloud의 적응형 메트릭을 사용하여 증가한 카디널리티 문제를 해결할 수 있습니다.\n\n![이미지](/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 애플리케이션 기기 설정\n\n이제 우리는 우리 애플리케이션들에게 Grafana Alloy로 텔레미터 데이터를 보내도록 지시해야 합니다. http://grafana-k8s-monitoring-grafana-agent.default.svc.cluster.local:4318\n\n맞아요, 이 로컬 OpenTelemetry 에이전트는 클러스터와 애플리케이션으로부터 데이터를 수신하는 중개자 역할을 합니다.\n\n## 메트릭과 로그\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 우리의 메트릭과 로그가 Kubernetes 클러스터에서 Grafana Alloy로 흘러들어가고, 중앙 OpenTelemetry Collector를 거쳐 Grafana Cloud에서 시각화됩니다.\n\n이 데이터에 액세스하는 것은 쉽습니다. 클러스터 내비게이션을 통해 이동하거나 Explore 도구를 사용할 수 있습니다. 제 개인적으로는 다양한 소스에서 텔레메트리 데이터를 탐색할 수 있는 Explore 도구를 선호합니다. 이 강력한 도구를 사용하면 쿼리를 작성하고 필터 및 변환을 적용하며 가치 있는 통찰을 효율적으로 추출할 수 있습니다.\n\n## 추적\n\n그렇다면 추적은 어떨까요? 추적은 사용자 요청이 응용 프로그램을 통해 이동하는 과정에 대한 중요한 통찰을 제공합니다. 추적을 활용하려면 데이터를 Grafana Alloy로 보내도록 설정된 계기가 설치된 응용 프로그램이 필요합니다. 이를 위해 응용 프로그램이 다음 주소 중 하나로 데이터를 보내도록 설정해야 합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- OTLP/gRPC 엔드포인트: http://grafana-k8s-monitoring-grafana-agent.default.svc.cluster.local:4317\n- OTLP/HTTP 엔드포인트: http://grafana-k8s-monitoring-grafana-agent.default.svc.cluster.local:4318\n\nSpring Boot 애플리케이션에서는 다음 주소를 OTEL_EXPORTER_OTLP_ENDPOINT 환경 변수로 설정할 수 있습니다:\n\n```js\n- name: OTEL_EXPORTER_OTLP_ENDPOINT\n  value: http://grafana-k8s-monitoring-grafana-agent.default.svc.cluster.local:4317\n```\n\n또한 springboot-service에 OTEL_SERVICE_NAME 변수를 추가했습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```yaml\n- name: OTEL_SERVICE_NAME\n  value: springboot-service\n```\n\n애플리케이션이 배포되고 데이터를 생성하면 Explore 도구에서 추적을 분석할 수 있습니다.\n\n## Tempo에서 추적 탐색\n\nTempo로 추적을 탐색해 봅시다. Tempo는 오픈 소스 분산 추적 시스템으로, 분산 시스템 간 요청 흐름에 대한 가시성을 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n분산 시스템에서 추적(trace)은 단일 사용자 요청이 다양한 서비스를 거쳐 이동하는 여정을 나타내는 데이터 집합입니다. 이 여정의 각 단계를 스팬(span)이라고 하며, 서비스 이름, 수행된 작업, 소요된 시간 등의 정보가 포함됩니다. 추적 및 스팬을 통해 개발자는 복잡하고 연결된 환경에서 애플리케이션의 성능 및 동작을 이해하는 데 도움을 받습니다.\n\nExplore 도구에서 grafanacloud-`name`-traces 데이터 소스를 선택합니다. 서비스 이름 드롭다운 목록에서 서비스를 선택하고(예: springboot-service), 추적을 찾아봅니다. 자세한 통찰을 얻으려면 어떤 추적이든 클릭하세요.\n\n<img src=\"/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_6.png\" />\n\n자세한 통찰을 얻으려면 어떤 추적이든 클릭하세요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_7.png)\n\n저희는 서비스, 응용 프로그램 및 인프라에 대한 탁월한 관측성을 위해 스스로를 성공적으로 설정했습니다. 하지만 더 많은 가능성이 있습니다! 다음 포스트에서 모든 관측성 요구 사항을 충족시키는 또 다른 Grafana 제품인 애플리케이션 관측성을 알아보겠습니다. 계속 주시해 주세요! 😊\n\n## 결론\n\n이 단계를 따르면 오픈텔레미트리의 강력함을 활용하여 Kubernetes 클러스터에 Grafana Alloy를 성공적으로 배포할 수 있을 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n만약 이 내용이 도움이 되었다면 👏 버튼을 클릭하시고 제 프로필을 팔로우해주세요. 더 많은 기사를 확인할 수 있습니다!\n","ogImage":{"url":"/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_0.png"},"coverImage":"/assets/img/2024-05-27-GrafanaAlloyOpenTelemetry_0.png","tag":["Tech"],"readingTime":19}],"page":"53","totalPageCount":119,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}