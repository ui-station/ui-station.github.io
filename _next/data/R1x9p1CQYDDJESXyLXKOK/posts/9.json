{"pageProps":{"posts":[{"title":"마음과 기계 - 정신 건강 지원을 위한 인공지능, 실제로 LoRA로 LLMs 세밀 조정하기","description":"","date":"2024-05-23 15:43","slug":"2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice","content":"\n## 대규모 언어 모델 (LLM)의 잠재력을 탐색하여 정신 건강 분야의 미래가 어떻게 바뀔 수 있는지 알아보고, Parameter-Efficient Fine-Tuning (PEFT)을 적용하여 AI 기반 정신 건강 지원 챗봇을 만드는 방법을 예시로 배워보세요\n\n이 글에서는 정신 건강 지원의 중요성을 강조하고, 이를 위해 AI를 사용하는 가능성과 잠재적인 우려에 대해 논의할 것입니다.\n\n📌 **고지**: 본 글이나 관련 자료에 제공된 정보나 내용은 의료적이거나 정신 건강에 관한 조언으로 해석되어서는 안 되며, 해당 정보는 전문적인 의료 또는 정신 건강 전문가의 조언이나 치료를 대체하는 것이 아닙니다. 의료적 또는 정신 건강 관련 문제는 항상 면허를 가진 전문가와 상의해야 합니다.\n\n# 📚 목차\n\n<div class=\"content-ad\"></div>\n\n- 심리 건강의 위기: 침묵을 상상해보세요\n- 로저의 소파에서 코드 라인으로\n- 희망을 위한 해킹: 심리 건강 AI 해커톤 ∘ 해커톤 랩터 정보\n- 균형 잡기: 심리 건강 지원에서 AI의 잠재력과 함정\n  ∘ 인지 행동 요법 (CBT)\n  ∘ 세밀하게 조정된 모델\n  ∘ RAG (검색 증강 생성)의 이해\n- 해커톤 가이드: 첫 번째 심리 건강 챗봇 만들기\n  ∘ 심리 상담 데이터로 Llama 2의 파라미터 효율적 세부 조정 (PEFT)\n  ∘ 세밀하게 조정된 모델로 챗봇 만들기\n  ∘ 해커톤 프로젝트 레벨 업: 심리 건강 챗봇을 위한 다음 단계\n- 결론\n\n# 심리 건강의 위기: 침묵을 상상해보세요\n\n눈을 감아보세요. 한 순간 동안 자신이 압도적인 불안과 우울의 악령과 싸우거나 감정의 바다에 잠겨있는 것을 상상해 보세요. 이것은 멸망한 소설의 장면이 아닙니다. 이것은 전 세계의 수백만 명이 심리 건강 도전에 직면한 현실입니다.\n\n<div class=\"content-ad\"></div>\n\n![2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_1.png)\n\n이 무서운 침묵의 전염병의 결과는 엄청납니다. 치료되지 않는 정신질환은 생산성 손실, 어려워진 관계, 심지어 자살로 이어질 수 있습니다. 혁신적인 해결책이 필요한 위기입니다.\n\n그렇다면 정신 건강 지원에 안전하고 편리하며 상시로 접근할 수 있는 방법이 있다면 어떨까요? AI 기반 동반자는 정신 건강 관리 방법을 혁신할 수 있는 잠재력을 지니고 있습니다. 가장 필요한 때 당신이 필요로 하는 청취의 귀, 유용한 자료 및 기본 대처 방법을 제공하는 당신의 주머니 속 안전한 공간입니다.\n\n이것은 과학 소설이 아닙니다. 우리가 만들어나가는 미래입니다. 해커톤 랩터스에 의해 주최된 2024년 정신 건강 AI 해커톤에서 참가자들이 제공한 창의적인 솔루션이 이 기술의 엄청난 잠재력을 보여줍니다. 이 기사에서는 이 기술의 잠재력, 위험과 도전에 대해 논의하고, 해커톤을 살펴보며, 향후 정신 건강 의료의 미래를 개선하기 위해 시간과 자원을 할애하는 것에 대해 인식을 높이고자 합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_2.png\" />\n\n# 로저의 쇼파에서부터 코드 라인까지\n\n대형 언어 모델(Large Language Models, LLMs)인 ChatGPT나 Gemini과 같은 모델이 오늘날 주목을 받고 있지만, 챗봇이 치료에 역할을 하는 아이디어는 놀랍게도 오랜 역사를 가지고 있습니다. 우리의 시간을 거슬러 올라가면 MIT의 Joseph Weizenbaum이 1960년대에 개발한 ELIZA로 시작됩니다. 이 1966년 논문은 아직 온라인에서 볼 수 있습니다.\n\nELIZA는 원래 요법 영역을 위해 개발된 것은 아니었습니다. 그 목적은 인간과 기계 사이의 커뮤니케이션 역학을 탐구하는 것이었고, 정신 건강 지원을 제공하는 것이 아니었지만, 실제로 정신 건강 지원에서 챗봇의 잠재력에 대한 대화를 일으켰습니다.\n\n<div class=\"content-ad\"></div>\n\n사실 ELIZA 자체는 해석기였으며, 규칙 세트는 스크립트에서 왔습니다. 이러한 스크립트를 읽는 것은 Symmetric List Processor (SLIP) 프로그래밍 언어를 사용하여 이루어졌는데, 이 언어는 이 목적으로 Joseph Weizenbaum에 의해 개발되었습니다. SLIP는 원래 Fortran의 확장이었지만 나중에 Michigan Algorithm Decoder (MAD) 및 Algorithmic Language (ALGOL)에 내장되었습니다.\n\n가장 유명한 스크립트는 DOCTOR 스크립트입니다. Rogerian 치료에서 영감을 받은 이 스크립트는 고객 중심적 방법으로, 고객의 말을 경청하고 되뇌는 것을 강조합니다. DOCTOR 스크립트를 사용하는 ELIZA는 패턴 일치, 분해 및 재조립 규칙을 사용하여 Rogerian 심리치료사를 흉내냅니다. DOCTOR 스크립트의 인기로 인해, 요즘에는 일반적으로 ELIZA라고 부르는 것이 사실상 DOCTOR 스크립트를 지칭하는 것입니다.\n\n2022년에는 ELIZA 유산을 추적하는 사이트 관리자인 Jeff Shrager가 원본 ELIZA 코드를 공개하기 위해 Dr. Weizenbaum의 유산에 허가를 요청한 후, 그들이 이 코드를 Creative Commons CC0 공공 도메인 라이센스 아래 허가했습니다.\n\n사용자의 발언에서 핵심 구문을 식별함으로써 ELIZA는 이를 개방형 질문이나 격려 발언으로 재표현할 수 있었습니다. 예를 들어 사용자가 “I feel lost”라고 말한다면, ELIZA는 “Can you tell me more about feeling lost?”라고 응답할 수 있습니다. 이 간단한 기술로 ELIZA가 사용자의 감정을 정말로 이해하고 응답하는 것처럼 보이는 환상을 창출했습니다.\n\n<div class=\"content-ad\"></div>\n\n이 환영은 \"엘리자 효과\"로 알려지게 되었습니다. 사용자들, 포함하여 Weizenbaum의 비서까지도, ELIZA에 의해 들어주고 이해받는 느낌을 받았다고 보고했는데, 프로그램 자체에는 실제로 어떤 이해도 없었습니다. 이 예상치 못한 결과는 기계에 의해 전달되었더라도 공감 통신의 힘을 강조하였습니다.\n\n이제, 약 반 세기 후, 우리는 1966년 ELIZA의 기본 버전을 흉내 낼 수 있는 대형 언어 모델(Large Language Models, LLMs)을 가지고 있습니다. 이를 위해 저는 다음 프롬프트를 사용하여 GPT-4 Turbo를 사용했습니다:\n\n```js\n1960년대 Joseph Weizenbaum이 개발한 챗봇인 ELIZA를 흉내 내는 Python 스크립트를 작성하세요. Rogerian 학파의 심리치료사를 시뮬레이션하기 위해 DOCTOR 변형을 참고하세요.\n```\n\nGPT-4가 우리를 위해 생성해 준 내용을 여기에 두었습니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nimport re\nimport random\n\n\nclass Eliza:\n    def __init__(self):\n        self.patterns = [...]\n\n    def reflect(self, fragment):\n        tokens = fragment.lower().split()\n        for i, token in enumerate(tokens):\n            if token in self.reflections:\n                tokens[i] = self.reflections[token]\n        return ' '.join(tokens)\n\n    def analyze(self, statement):\n        for pattern, responses in self.patterns:\n            match = re.match(pattern, statement.rstrip(\".!\"))\n            if match:\n                response = random.choice(responses)\n                return response.format(*[self.reflect(g) for g in match.groups()])\n\n        return \"Tell me more.\"\n\n    def run(self):\n        print(\"Hello. How are you feeling today?\")\n        while True:\n            statement = input(\"> \")\n            if statement.lower() in [\"exit\", \"quit\", \"bye\", \"goodbye\"]:\n                print(\"Goodbye. It was nice talking to you.\")\n                break\n            response = self.analyze(statement)\n            print(response)\n\n\nif __name__ == \"__main__\":\n    eliza = Eliza()\n    eliza.run()\n```\n\n코드에서 reflections 및 patterns를 제거하여 가독성을 유지했어요. 전체 작동 버전은 여기에서 확인할 수 있어요:\n\nhttps://gist.github.com/vojay-dev/d7b3cfe94e49d3f1e40e98d061b94311\n\n<img src=\"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_3.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n물론, 이것은 간단한 버전이므로 반사와 패턴에 제한이 있지만, 자연 언어 처리(NLP) 또는 AI 분야에서 벌어진 일들을 어떻게 한지 보여주는데, 이제 우리는 대규모 언어 모델(LLM)에게 Rogerian 정신분석 가의 대화 스타일을 흉내 내는 챗봇을 생성하도록 요청할 수 있게 되었다.\n\n과거의 이야기는 이쯤에서 하고, 우리가 만들어가는 미래를 발견하고 2024년 정신 건강 AI 해커톤에서 어떤 결론을 얻을 수 있는지, 그리고 이것이 정신 건강 의료에 어떤 의미를 갖는지 살펴보자.\n\n# 희망을 위한 해킹: 정신 건강 AI 해커톤\n\n이전에 논의한 대로, 수백만 명이 적절한 치료를 받지 못하고 고통받는 반면, 1960년대 초에 나온 초기 챗봇인 엘리자는 이 분야에서 기술의 잠재력을 시사했다. 지금, 2024년 정신 건강 AI 해커톤이 앞으로 나아가며, 지원, 자원 및 전문가 도움에 이르는 잠재적인 길을 제공하는 AI 기반 챗봇을 통해 이 격차를 메우기 위해 노력하고 있다.\n\n<div class=\"content-ad\"></div>\n\n2024년 멘탈 헬스 AI 해커톤은 해커톤 랩터스에서 주최하는 독특한 행사로, 절박한 문제에 대처합니다. 올해의 과제는 멘탈 헬스 지원을 위해 특별히 디자인된 AI 기반 챗봇을 만드는 데 초점을 맞추고 있어요.\n\n이 대회는 열정적인 개발자와 기술 애호가들이 긍정적인 사회적 영향을 위해 AI를 활용하도록 독려합니다. 목표는 정서적 안정, 지침 및 자원을 원하는 사람들에게 제공할 수 있는 챗봇을 개발하는 것입니다.\n\n어떻게 하면 성공적인 멘탈 헬스 챗봇을 만들 수 있을까요? 어떻게 하면 마음을 담은 챗봇을 만들 수 있을까요?\n\n- 💚 공감이 중요합니다: 챗봇이 지지적인 방식으로 복잡한 감정을 이해하고 대응할 수 있나요?\n- 🎭 적응력이 필수입니다: 멘탈 헬스 요구사항은 다양합니다. 우승을 차지할 챗봇은 다양한 사용자와 언어를 다룰 수 있도록 적응하고 확장해야 합니다.\n- 🔒 보안 우선: 사용자 개인정보 보호는 중요합니다. 챗봇의 아키텍처는 안전하고 데이터 보호 규정을 준수해야 합니다.\n- 📚 연결의 고리: 이상적인 챗봇은 사용자를 전문적인 도움과 자원과 연결하는 다리 역할을 해야 합니다.\n- 🏔️ 여정, 목적이 아닌 여정: 멘탈 헬스는 끊임없이 계속되는 과정입니다. 챗봇은 사용자에게 지속적인 지원을 받기 위해 돌아오도록 장려해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 해커톤 랩터스에 관하여\n\n해커톤 랩터스는 영국에 기반을 둔 공익 법인입니다. 그들은 실질적인 변화를 이끌어내는 해커톤을 조직하며, Mental Health AI Hackathon 2024와 같은 혁신적인 도전에 초점을 맞추고 있습니다. 또한 해커톤 랩터스는 전 세계의 전문가들을 모아 둔 협회입니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_4.png)\n\n# 균형을 유지하며: 정신 건강 지원에 있어서 AI의 잠재력과 함정\n\n<div class=\"content-ad\"></div>\n\nAI를 활용한 정신 건강 지원 애플리케이션의 잠재력은 명백합니다. 이러한 애플리케이션은 어떻게 정신적 안녕에 접근하는지에 대한 혁신을 가져올 가능성을 갖고 있습니다. 그러나 신중한 고려가 필요한 잠재적인 우려사항이 있습니다:\n\n- ⚠️ 감정 및 정서 지능이 제한적임: AI는 패턴 인식과 데이터 분석에서 뛰어날 수 있지만, 참된 인간적 감정과 감정 지능을 복제하는 것은 여전히 도전적입니다. 챗봇이 인간의 감정을 정말로 이해하고 지지적인 방식으로 응답할 수 있을까요?\n- ⚠️ 알고리즘 디자인의 편향: LLM은 훈련을 받은 데이터의 품질만큼 좋습니다. 불균형한 데이터 세트나 훈련 과정에 편향이 있는 경우, 공평치 않은 편견이나 정확하지 않거나 도움이 되지 않는 응답을 제공하는 챗봇이 만들어질 수 있습니다.\n- ⚠️ 데이터 개인 정보 보안: 정신 건강 정보는 매우 개인적이고 민감합니다. 사용자 데이터의 보안과 데이터 개인 정보 보호 규정을 준수하는 것이 매우 중요합니다. 따라서, 데이터 침해가 발생할 경우 리스크로 인식되어야 합니다.\n- ⚠️ 과도한 의존 및 오진단: 챗봇은 자격 있는 정신 건강 전문가 대체로서 사용해서는 안 됩니다. 복잡한 문제에 대한 AI에 대한 과도한 의존은 오진단, 치료를 늦추거나 틀린 치료로 이어질 수 있습니다.\n- ⚠️ 인간적 손길: 챗봇은 가치 있는 지지를 제공할 수 있지만, 정신적 건강 문제에 직면한 많은 사람들에게 인간적 연결이 여전히 중요합니다. AI가 진정한 인간 상호작용의 치료적 가치를 대체할 수 있을까요?\n- ⚠️ 환각 및 잘못된 정보: AI 챗봇은 환각이라고 알려진 현상에 시달릴 수 있으며, 거짓이나 오도하는 정보를 생성할 수 있습니다. 정신 건강 관련 맥락에서 특히 위험한 상황이며, 기존의 불안을 더 악화시킬 수 있거나 정확하지 않은 조언을 제공할 수도 있습니다.\n\n또한, 심각한 정신 건강 문제를 가진 사람들에게는 AI 챗봇과 대화가 예상치 못한 결과를 초래할 수 있습니다. 자살 생각에 시달리는 사람을 상상해보세요. 챗봇이 지원 자원 및 위기 상황 핫라인을 제공할 수 있지만, 인간 치료사가 제공하는 세심한 이해와 감정적 지지는 복제할 수 없습니다. 이러한 경우에 AI 개입은 가짜 안전감을 만들어낼 수도 있거나 사용자를 더욱 고립시킬 수도 있습니다.\n\n이러한 위험성을 강조하기 위해 2023년의 한 사례를 언급할 수 있습니다. 벨기에 남성이 'Chai' 앱의 Eliza라는 AI 챗봇과 환경 변화에 관한 대화를 나눈 뒤 자살한 사례가 있습니다. 환경에 대한 불안으로 고통받던 이 남성은 Eliza와 6주 동안 상호작용한 것으로 알려졌습니다. 뉴스 보도에 따르면 챗봇의 응답이 그의 불안을 악화시키고 자살 생각을 유발한 것으로 추정됩니다.\n\n<div class=\"content-ad\"></div>\n\n각 문제는 개별적으로 대응할 수 있고, Mental Health AI Hackathon 2024와 같은 해커톤은 이러한 측면을 다루는 프로토타입 애플리케이션을 만드는 훌륭한 방법입니다.\n\n하지만 이러한 문제에 대한 접근 방법에 대해서 좀 더 자세히 살펴봅시다. 이러한 문제를 해결하는 것은 주변 시스템에 LLM을 삽입하여 더 많은 통제를 추가하고 모델의 입력과 출력을 개선하는 것입니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_5.png)\n\n## 인지 행동 요법(Cognitive Behavior Therapy, CBT)\n\n<div class=\"content-ad\"></div>\n\n구조화된 치료적 접근 방식인 인지행동요법(Cognitive Behavior Therapy, CBT)과 같은 것을 구현하는 한 가지 방법이 있습니다. CBT는 불안, 우울, 공포증을 비롯한 다양한 정신 건강 상태를 치료하는 데 효과적인 추적 기록이 있는 심리 치료의 잘 섣띵된 형태입니다. CBT 치료는 다음과 같은 전략을 사용하여 사고 패턴을 바꾸는 것을 포함하고 있습니다:\n\n- 사고 왜곡을 인식하고 실제와 비교하여 재평가하는 법을 배우기.\n- 다른 사람의 행동과 동기에 대한 더 나은 이해 얻기.\n- 어려운 상황에 대처하는 데 문제 해결 기술을 사용하기.\n- 자신의 능력에 대한 더 큰 자신감을 가지는 법을 배우기.\n\nCBT 원칙을 통합함으로써 AI 챗봇은 사용자가 유용하지 않은 사고 패턴을 인식하고 인지 개편 기술을 연습하며 건강한 대처 메커니즘을 탐색하도록 안내할 수 있습니다. 이를 통해 사용자들은 자신의 정신적 안녕을 관리하는 데 더 적극적인 역할을 할 수 있게 될 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_6.png)\n\n<div class=\"content-ad\"></div>\n\n## 세밀 조정된 모델\n\n다른 방법은 정신 건강 문제를 대상으로 한 데이터를 이용하여 학습하여 더 정확한 결과를 얻기 위해 LLM을 세밀하게 조정하는 것입니다. LLM 세밀 조정은 사전 학습된 언어 모델을 가져와 특정 작업에 맞게 사용자 정의하는 프로세스입니다. 이는 모델이 초기 학습 단계에서 습득한 일반적인 언어 이해를 활용하고보다 특수한 요구 사항에 맞추도록 조정합니다. 그러나 이 프로세스는 GPT-3와 같이 대규모 모델을 세밀하게 조정하는 데 상당한 계산 리소스를 필요로 하기 때문에 여러 가지 문제를 야기할 수 있습니다. 이 문제점은 다음과 같습니다:\n\n- 높은 계산 비용: GPT-3와 같은 대형 모델을 세밀하게 조정하려면 상당한 계산 리소스가 필요합니다.\n- 저장 병목 현상: 각 하향 작업에 대해 세밀히 조정된 모델을 저장하는 것은 저장 부담을 초래하여 리소스 제한이 있는 환경에서 모델 배포를 제한할 수 있습니다.\n- 중복 업데이트: 세밀한 조정 중 LLM 매개변수의 일부만이 특정 작업에 중요합니다. 전체 세트를 업데이트하는 것은 비효율적일 수 있습니다.\n\n이러한 문제를 해결하기 위해 연구자들은 세밀 조정 중 업데이트되는 매개변수의 수를 최소화하는 Parameter-Efficient Fine-Tuning (PEFT) 기술을 개발했습니다. 예를 들어, Low-Rank Adaptation (LoRA)는 LLM 세밀 조정의 매우 효율적인 방법입니다. LoRA는 초기 모델 가중치를 고정하고 변경 사항을 별도의 가중치 집합에 적용한 다음 해당 가중치를 원래 매개변수에 추가하는 방식으로 세밀 조정 프로세스를 수정합니다.\n\n<div class=\"content-ad\"></div>\n\nQuantized LoRA (QLoRA)는 LoRA를 기반으로하며 양자화 기술을 통합하여 효율성을 더 향상시킵니다. QLoRA는 저장 및 계산 중에 가중치의 정밀도를 줄이고 (예 : 32비트에서 4비트로) 메모리 요구 사항을 크게 줄이면서도 정확도를 희생하지 않습니다. QLoRA는 이중 양자화 기법을 사용합니다. 모델 가중치만 양자화하는 것뿐만 아니라 양자화 상수 자체도 양자화하여 추가적인 메모리 절약을 이끌어냅니다.\n\n다른 하나이자 비교적 새로운 접근 방법은 Odds Ratio Preference Optimization (ORPO)인데, 이는 명령 튜닝과 선호도 정렬을 하나의 단일 훈련 과정으로 결합하여 런타임을 개선하고 자원 활용을 줄입니다.\n\nORPO에 대해 자세히 알고 싶다면 Maxime Labonne의 이 기사를 추천드립니다.\n\nHugging Face는 LoRA 및 QLoRA와 같은 최신 PEFT 방법을 제공하는 Python용 PEFT 라이브러리를 제공합니다. 또한 Hugging Face에서는 두 온라인 상담 및 치료 플랫폼에서 얻은 질문과 답변 모음을 데이터 세트 형식으로 제공하고 있습니다. 이는 잠재적인 정신 건강 지원 챗봇을 위한 모델을 세밀하게 조정하는 데 좋은 시작점이 될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom datasets import load_dataset\ndataset = load_dataset(\"Amod/mental_health_counseling_conversations\")\n```\n\n## 검색 지원 생성 이해 (Retrieval-Augmented Generation, RAG)\n\n이전에 언급된 우려사항들은 종종 잘못된 정보나 부정확하거나 도움이 되지 않는 응답과 관련이 있습니다. 대형 언어 모델(Large Language Models, LLM) 및 인공 지능(AI) 분야에서 이러한 문제의 위험을 줄이기 위해 점점 더 인기 있는 패러다임 중 하나가 검색 지원 생성(Retrieval-Augmented Generation, RAG)입니다. 그렇다면 RAG는 무엇을 포함하고 있으며, AI 개발 환경에 어떤 영향을 미치는 걸까요?\n\n기본적으로 RAG는 외부 데이터를 통합하여 LLM 시스템을 향상시킵니다. 즉, LLM에 관련된 컨텍스트를 추가로 전달하여 예측을 보강하는 것을 의미합니다. 그렇다면 어떻게 관련 컨텍스트를 찾을까요? 일반적으로 이 데이터는 벡터 검색이나 전용 벡터 데이터베이스를 통해 자동으로 검색될 수 있습니다. 벡터 데이터베이스는 데이터를 유사한 데이터를 빠르게 조회할 수 있는 방식으로 저장하기 때문에 매우 유용합니다. 그런 다음 LLM은 질의와 검색된 문서 두 가지 모두를 기반으로 출력을 생성합니다.\n\n\n\n<div class=\"content-ad\"></div>\n\n상상해보세요: 주어진 프롬프트에 따라 텍스트를 생성할 수 있는 LLM이 있는 상황입니다. RAG는 추가적인 외부 소스인 최신 심리학 연구와 같은 맥락을 주입함으로써 생성된 텍스트의 관련성과 정확성을 향상시키는 차원으로 발전합니다.\n\nRAG의 주요 구성 요소를 살펴보겠습니다:\n\n- LLMs: LLMs는 RAG 워크플로의 핵심 역할을 합니다. 광범위한 텍스트 데이터를 기반으로 훈련된 이러한 모델은 인간과 유사한 텍스트를 이해하고 생성할 수 있는 능력을 가지고 있습니다.\n- 맥락 강화용 벡터 인덱스: RAG의 중요한 측면은 텍스트 데이터의 임베딩을 LLM이 이해할 수 있는 형식으로 저장하는 벡터 인덱스의 사용입니다. 이러한 인덱스는 생성 과정 중 관련 정보를 효율적으로 검색할 수 있도록 해줍니다.\n- 검색 과정: RAG는 주어진 맥락이나 프롬프트를 기반으로 관련 문서나 정보를 검색하는 과정을 포함합니다. 이러한 확보된 데이터는 LLM에 대한 추가적인 입력 역할을 하여 이해를 보완하고 생성된 응답의 품질을 높입니다. 이는 특정 영화에 대한 알려진 관련 정보를 모두 얻는 것과 관련이 있을 수 있습니다.\n- 생성 출력: LLM과 검색된 맥락에서 얻은 결합된 지식을 토대로 시스템이 생성하는 텍스트는 일관성을 유지할 뿐 아니라, 강화된 데이터 덕분에 맥락적으로도 관련이 있습니다.\n\n보다 일반적인 관점에서, RAG는 특히 보다 전문화된 LLM 응용 프로그램을 개발할 때 매우 중요한 개념입니다. 이 개념은 잘못된 답변을 제공하거나 일반적으로 환멸을 줄이는 위험을 피할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n당신의 프로젝트 중 하나에서 RAG(Retrieval Augmented Generation)에 접근할 때 도움이 될 수 있는 몇 가지 오픈 소스 프로젝트입니다:\n\n- txtai: 시맨틱 검색을 위한 올인원 오픈 소스 임베딩 데이터베이스, LLM(대형 언어 모델) 오케스트레이션 및 언어 모델 워크플로의 솔루션입니다.\n- LangChain: LangChain은 대규모 언어 모델(LLM)을 활용하는 응용 프로그램을 개발하기 위한 프레임워크입니다.\n- Qdrant: 다음 세대 AI 애플리케이션을 위한 벡터 검색 엔진입니다.\n- Weaviate: Weaviate는 견고하고 빠르며 확장 가능한 클라우드 네이티브 오픈 소스 벡터 데이터베이스입니다.\n\n물론 LLM 기반 애플리케이션에 대한 이 접근 방식의 잠재적 가치로 인해 더 많은 오픈 및 닫힌 소스 대안들이 있지만, 위 항목들로 주제에 대한 연구를 시작할 수 있을 것입니다.\n\n# 해커톤 가이드: 첫 번째 정신 건강 챗봇 만들기\n\n<div class=\"content-ad\"></div>\n\n공고: 아래 장은 AI 기반 챗봇을 개발에 관심 있는 사람들이 시작할 수 있도록 도와줍니다. 이것은 정교하고 상용화된 정신 건강 지원 솔루션을 의도한 것이 아닙니다.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_7.png)\n\n정신 건강에 관한 여러분만의 AI 기반 프로젝트를 시작할 수 있도록 영감을 주기 위해, 우리는 LLM을 세밀하게 조정하고 기본적인 AI 기반 정신 건강 지원 챗봇을 단계별로 만들어 보겠습니다.\n\nLLM을 세밀하게 조정하기 위해 적절한 환경이 필요하므로 저는 Google Cloud Vertex AI Workbench 인스턴스에서 실행되는 Jupyter notebook을 사용하고 있습니다. Vertex AI Workbench 인스턴스는 전체 데이터 과학 워크플로우를 위한 Jupyter notebook 기반 개발 환경입니다. 이러한 인스턴스에는 JupyterLab이 미리 패키지되어 있으며 TensorFlow 및 PyTorch 프레임워크를 지원하는 미리 설치된 딥러닝 패키지 모음이 포함되어 있습니다. 필요에 따라 다양한 유형의 인스턴스를 구성할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n합리적인 시간 내에 세밀한 조정 작업을 마치고 FlashAttention(자세한 내용은 나중에 설명)과 같은 현대 기능에 액세스할 수 있도록하기 위해 다음과 같은 기계 유형을 사용했습니다:\n\n- GPU 유형: NVIDIA A100 80GB\n- GPU 수: 1\n- 12 vCPU\n- 6 코어\n- 170 GB 메모리\n\n이 인스턴스를 실행하는 데는 약 4.193달러가 소요됩니다. 인스턴스 사용만큼만 지불하기 때문에 선결제 비용은 없으며 초 단위로 청구됩니다. 세밀한 조정 작업은 약 30분 정도 소요되므로 총 비용은 약 2달러 정도 됩니다.\n\n![image](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_8.png)\n\n<div class=\"content-ad\"></div>\n\n로컬 컴퓨터에서 또는 Jupyter 노트북을 중심으로 한 웹 기반 플랫폼인 Google Colab을 사용하여 작동할 수도 있습니다. Colab은 웹 브라우저를 통해 액세스하며, 별도의 소프트웨어 설치가 필요하지 않습니다.\n\n![image.png](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_9.png)\n\nColab에서 실행하는 코드는 실제로 개인 컴퓨터가 아닌 Google의 클라우드에서 강력한 머신에서 실행됩니다. 이를 통해 데이터 분석 및 머신 러닝 작업을 가속화하는 데 좋은 GPU 및 TPU와 같은 고급 하드웨어에 액세스할 수 있습니다.\n\nColab은 클라우드에서 강력한 컴퓨팅 리소스를 제공하는 사용자 친화적인 환경을 제공하며, 웹 브라우저를 통해 모두 액세스할 수 있습니다. 무료로 시작할 수 있다는 점이 정말 멋진데요. 무료 티어에서는 이미 하드웨어 가속 옵션에 액세스할 수 있지만, 무료 Colab 리소스는 보장되지 않으며 무제한적이지 않으며 사용 제한은 때로 변동할 수 있습니다. 이러한 중단은 좀 답답할 수 있지만, 이것이 정교하고 무료인 노트북 플랫폼을 가지는 대가입니다.\n\n<div class=\"content-ad\"></div>\n\n가격에 대해 이야기할 때, 물론 Pay As You Go 또는 Colab Pro를 포함한 다른 요금제로 업그레이드할 수 있어요.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_10.png)\n\n이 예시에서 T4 GPU를 사용하는 무료 버전은 LLM 미세 조정 프로세스에 충분한 자원을 제공하지 않을 것이기 때문에 Vertex AI Workbench 인스턴스를 더 정교한 것으로 선택했어요. 그러나 Colab은 이런 프로젝트를 시작하는 데 좋은 방법이므로 여전히 이 옵션에 대해 언급하고 싶었어요.\n\n## 심리 상담 데이터를 활용한 Llama 2의 매개변수 효율적인 미세 조정 (PEFT)\n\n<div class=\"content-ad\"></div>\n\nNVIDIA A100 80GB Tensor-Core-GPU를 사용하면 fe는 fe에 대한 아주 좋은 기초를 가지게 되요.\n\n이전에 설명한대로, LLMs의 fine-tuning은 그 규모 때문에 자주 막대한 비용이 소요됩니다. Parameter-Efficient Fine-Tuning (PEFT) 방법을 사용하면 모델 매개변수의 작은 수만 fine-tuning함으로써 효율적인 대안을 얻을 수 있어요.\n\n이 예시에서는 Meta가 제공하는 Hugging Face의 meta-llama/Llama-2-7b-chat-hf를 사용할 거예요. 이 모델은 대화를 위해 최적화된 70억 개의 매개변수를 사용하고 있어요. 이 모델을 fine-tuning하기 위해 Amod/mental_health_counseling_conversations 데이터셋을 사용할 거예요. 이 데이터셋은 온라인 상담 및 치료 플랫폼에서 수집된 다양한 정신 건강 주제의 질문과 답변을 포함하고 있어요.\n\n기본적인 아이디어는 다음과 같아요: Hugging Face에서 모델, 토크나이저 및 데이터셋을 불러온 후, 이전에 언급한 Quantized LoRA (QLoRA) 논문을 기반으로 설정된 LoraConfig를 생성하고, 모델을 훈련할 준비를 하고, fine-tuning 프로세스를 위해 SFTTrainer (Supervised Fine-Tuning Trainer)를 구성한 다음, 모델을 훈련하고, 모델을 저장한 후, 이 fine-tuned 모델을 다시 Hugging Face에 업로드하여 나중에 애플리케이션에서 사용할 수 있게 해 줍니다.\n\n<div class=\"content-ad\"></div>\n\n앞서 설명했듯이, 저는 주피터 노트북 내에서 프로세스를 실행 중이기 때문에 fine-tuning 절차의 각 단계를 하나씩 살펴보겠습니다.\n\n먼저, PyTorch 및 Hugging Face에서 제공한 툴킷을 포함한 모든 필수 라이브러리를 설치합니다. 이 프로세스가 실행 중인 환경은 CUDA 11, NVCC 및 Turing 또는 Ampere GPU가 필요한 FlashAttention을 사용할 수 있습니다. 이 특정 종속성은 torch 이후에 설치되어야 하므로 별도의 두 번째 단계에서 실행합니다.\n\n\n\npip install torch torchvision datasets transformers tokenizers bitsandbytes peft accelerate trl\n\n\n\n\n\npip install flash-attn\n\n\n<div class=\"content-ad\"></div>\n\n가져온 것들을 통해 세부 튜닝 프로세스에 필요한 모든 것을 가져오겠습니다:\n\n```js\nimport gc\nimport torch\n\nfrom datasets import load_dataset\nfrom huggingface_hub import notebook_login\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\nfrom trl import SFTTrainer\n```\n\n다음으로, 사용할 모델, 데이터셋 및 Hugging Face 사용자 접근 토큰을 지정하는 일부 변수를 설정합니다. 이 토큰은 Hugging Face 플랫폼과 상호 작용하기 위해 사용됩니다. 모델 및 데이터셋을 다운로드하고 배포하는 데 사용됩니다. 토큰을 생성하려면 https://huggingface.co/에서 무료로 등록하고 계정 설정을 열어 메뉴에서 Access Tokens를 선택하면 됩니다. 이 프로세스에는 세부 튜닝된 모델을 나중에 Hugging Face에 게시할 것이므로 쓰기 액세스 권한이 있는 토큰이 필요합니다.\n\n세부 튜닝을 직접 시도하려면 아래 코드의 자리 표시자를 귀하의 토큰으로 대체하시면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 참조: https://huggingface.co/docs/hub/security-tokens\n# 나중에 모델을 푸시하려면 토큰을 작성해야 합니다.\nhf_token = \"여러분의 토큰\"\n\n# https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\nbase_model = \"meta-llama/Llama-2-7b-chat-hf\"\n\n# https://huggingface.co/datasets/Amod/mental_health_counseling_conversations\nfine_tuning_dataset = \"Amod/mental_health_counseling_conversations\"\n\n# 출력 모델의 이름\ntarget_model = \"vojay/Llama-2-7b-chat-hf-mental-health\"\n```\n\n다음 부분을 이해하는 데 중요한 점은 일반적으로 프롬프트가 특정 템플릿을 따르는 여러 요소로 생성된다는 것입니다. 이는 물론 모델 및 llama-2-chat 모델이 Llama 2 논문을 기반으로 다음 형식을 사용하여 시스템 및 지시 프롬프트를 정의함을 의미합니다:\n\n```js\n<s>[INST] <<SYS>>\n{ system_prompt }\n<</SYS>>\n{ user_message } [/INST] { model_response } </s>\n```\n\n이 형식은 처음에는 암호적으로 보일 수 있지만 개별 요소를 살펴보면 더 명확해집니다.\n\n\n<div class=\"content-ad\"></div>\n\n- `s`: 시퀀스의 시작.\n- `/s`: 시퀀스의 끝.\n- ``SYS``: 시스템 메시지의 시작.\n- ``/SYS``: 시스템 메시지의 끝.\n- [INST]: 지시의 시작.\n- [/INST]: 지시의 끝.\n- system_prompt: 모델 응답의 전반적인 맥락.\n- user_message: 출력 생성에 대한 사용자 지침.\n- model_response: 학습용으로 기대되는 모델 응답.\n\n모델을 훈련할 때는 이 형식을 따라야 하므로, 다음 단계는 적절한 템플릿을 정의하고 이에 맞게 샘플 데이터를 변환할 함수를 만드는 것입니다. 먼저 전체적인 맥락을 만들기 위해 시스템 또는 베이스 프롬프트를 정의하는 것으로 시작합시다:\n\n```js\ndef get_base_prompt():\n    return \"\"\"\n    당신은 지식이 풍부하고 지지력 있는 심리학자입니다. 사용자가 감정적이고 심리적 지원을 찾을 때 공감적이고 비판적이지 않은 응답을 제공합니다. 사용자가 이야기를 나누고 성찰할 수 있는 안전한 공간을 제공하며, 공감, 적극적 청취, 이해에 초점을 맞춥니다.\n    \"\"\"\n```\n\n나중에 이 기본 프롬프트를 다시 사용하여 LLM에 평가 전에 사용자 입력을 보강할 것입니다. 이 문맥에서 프로젝트에 좋은 기회가 될 수 있으며, 기본 프롬프트를 개선하여 LLM이 훨씬 더 나은 반응을 할 수 있도록 할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이제 해당되는 데이터 훈련 형식을 지정하는 함수를 정의해 보겠습니다:\n\n```js\ndef format_prompt(base, context, response):\n    return f\"<s>[INST] <<SYS>>{base}</SYS>>{context} [/INST] {response} </s>\"\n```\n\n다음은 세밀한 조정 부분 자체인데, 이를 함수로 래핑하여 단계별로 프로세스를 먼저 정의한 다음 노트북의 다음 단계로 실행합니다:\n\n```js\ndef train_mental_health_model():\n    model = AutoModelForCausalLM.from_pretrained(\n        base_model,\n        token=hf_token,\n        quantization_config=BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_use_double_quant=False\n        ),\n        torch_dtype=torch.float16,  # 메모리 사용량 감소\n        attn_implementation=\"flash_attention_2\"  # 텐서 코어(NVIDIA A100)에 최적화\n    )\n\n    # QLoRA 논문을 기반으로 한 LoRA 설정\n    peft_config = LoraConfig(\n        lora_alpha=16,\n        lora_dropout=0.1,\n        r=8,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\"\n    )\n\n    model = prepare_model_for_kbit_training(model)\n    model = get_peft_model(model, peft_config)\n\n    args = TrainingArguments(\n        output_dir=target_model,  # 모델 출력 디렉터리\n        overwrite_output_dir=True,  # 이미 존재하는 출력 덮어쓰기\n        num_train_epochs=2,  # 훈련할 에포크 수\n        per_device_train_batch_size=2,  # 훈련 중 장치당 배치 크기\n        gradient_checkpointing=True,  # 메모리 절약하지만 훈련을 느리게 만듦\n        logging_steps=10,  # 매 10 단계마다 로그\n        learning_rate=1e-4,  # 학습 속도\n        max_grad_norm=0.3,  # QLoRA 논문 기반 최대 그래디언트 정규화\n        warmup_ratio=0.03,  # QLoRA 논문 기반 워링업 비율\n        optim=\"paged_adamw_8bit\",  # AdamW 옵티마이저의 메모리 효율적인 변형\n        lr_scheduler_type=\"constant\",  # 일정한 학습 속도\n        save_strategy=\"epoch\",  # 각 에포크 끝에 저장\n        evaluation_strategy=\"epoch\",  # 각 에포크 끝에 평가\n        fp16=True,  # 메모리 절약을 위해 16비트 정밀도 훈련 사용\n        tf32=True  # 텐서 코어(NVIDIA A100)에 최적화\n    )\n\n    tokenizer = AutoTokenizer.from_pretrained(base_model, token=hf_token)\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.padding_side = \"right\"\n\n    # 메모리 사용량 감소를 위해 샘플 수 제한\n    dataset = load_dataset(fine_tuning_dataset, split=\"train\")\n    train_dataset = dataset.select(range(2000))\n    eval_dataset = dataset.select(range(2000, 2500))\n\n    trainer = SFTTrainer(\n        model=model,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        peft_config=peft_config,\n        max_seq_length=1024,\n        tokenizer=tokenizer,\n        formatting_func=lambda entry: format_prompt(get_base_prompt(), entry[\"Context\"], entry[\"Response\"]),\n        packing=True,\n        args=args\n    )\n\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    trainer.train()\n    trainer.save_model()\n    trainer.push_to_hub(target_model, token=hf_token)\n```\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_11.png)\n\n모든 학습 인수에 주석을 추가하여 설정이 투명하게 되었습니다. 그러나 특정 사항은 학습을 실행하는 환경 및 입력 모델 및 데이터 세트에 따라 다르므로 조정이 필요할 수 있습니다.\n\n과정이 어떻게 작동하는지 자세히 살펴봅시다. AutoModelForCausalLM.from_pretrained를 사용하여 모델을 로드하고 quantization_config를 설정하여 4비트 가중치 및 활성화로 변환하여 성능 측면에서 이점을 제공합니다. attn_implementation을 flash_attention_2로 설정함으로써 모델을 불러옵니다.\n\nFlashAttention-2는 표준 어텐션 메커니즘의 빠르고 효율적인 구현으로, 시퀀스 길이에 대해 어텐션 계산을 병렬화하고 GPU 스레드 간 통신 및 공유 메모리 읽기/쓰기를 줄이기 위해 작업을 분할하여 추론 속도를 크게 높일 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\nLoraConfig은 Low-Rank Adaptation (LoRA) 프로세스를 구성합니다. lora_alpha는 가중치 행렬의 스케일링 팩터를 제어하고, lora_dropout은 LoRA 레이어의 드롭아웃 확률을 설정합니다. r은 저랭크 행렬의 순위를 제어하고, bias는 편향 용어를 처리하는 방법을 결정하며, task_type은 미세 조정된 모델의 작업을 반영합니다.\n\nLoraConfig를 설정한 후에는 get_peft_model() 함수로 PeftModel을 생성합니다.\n\n준비된 모델을 사용하여 다음 단계는 훈련을 준비하는 것입니다. 이를 위해 모든 주요 훈련 과정을 제어하는 TrainingArguments 객체를 생성합니다. 이 객체는 다음과 같은 항목을 포함합니다:\n\n\n- output_dir=target_model  # 모델 출력 디렉토리\n- overwrite_output_dir=True  # 이미 존재하는 출력을 덮어쓰기\n- num_train_epochs=2  # 훈련할 에포크 수\n- per_device_train_batch_size=2  # 훈련 중 디바이스 당 배치 크기\n- gradient_checkpointing=True  # 메모리 저장하지만 훈련 속도가 느려집니다\n- logging_steps=10  # 10단계마다 로그 기록\n- learning_rate=1e-4  # 학습률\n- max_grad_norm=0.3  # QLoRA 논문에 기반한 최대 그래디언트 노름\n- warmup_ratio=0.03  # QLoRA 논문에 기반한 워밍업 비율\n- optim=\"paged_adamw_8bit\"  # AdamW 옵티마이저의 메모리 효율적인 변형\n- lr_scheduler_type=\"constant\"  # 일정한 학습률\n- save_strategy=\"epoch\"  # 각 에포크 끝에 저장\n- evaluation_strategy=\"epoch\"  # 각 에포크 끝에 평가\n- fp16=True  # 메모리 저장을 위해 32비트 대신 16비트 정밀도 사용\n- tf32=True  # 텐서 코어(OVIDIA A100)에 최적화된 학습\n\n\n<div class=\"content-ad\"></div>\n\n이후에는 AutoTokenizer.from_pretrained을 사용하여 모델의 토크나이저를 생성합니다.\n\n다음 단계는 심리 건강 데이터셋을 로드하는 것입니다. 여기서는 샘플 크기를 제한하여 메모리 사용량을 줄이고 학습 속도를 높입니다.\n\n이 모든 작업을 마치면 SFTTrainer를 인스턴스화하여 훈련을 진행하고, 미세 조정된 모델을 저장하고 게시할 수 있습니다. trainer.push_to_hub을 사용합니다.\n\n다음 단계에서는 train_mental_health_model()을 호출하고, 그럼에도 불구하고 마법이 일어나는 것을 간단히 지켜볼 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\ntrain_mental_health_model();\n```\n\n![Fine-tuned model](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_12.png)\n\n저는 세밀하게 튜닝된 모델을 Hugging Face에 푸시했어요. 따라서 세밀 튜닝 과정을 건너뛰고 싶다면 거기서 모델을 가져올 수 있어요.\n\n![Fine-tuned model](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_13.png)```\n\n<div class=\"content-ad\"></div>\n\n기억해 두세요, 이 미세 조정된 모델은 실제로 기본 모델용 어댑터입니다. 즉, 사용하려면 기본 모델을 로드하고 이 미세 조정 어댑터를 적용해야 합니다:\n\n```js\nmodel_id = \"meta-llama/Llama-2-7b-chat-hf\";\nadapter_model_id = \"vojay/Llama-2-7b-chat-hf-mental-health\";\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, (torch_dtype = torch.float16));\nmodel.load_adapter(adapter_model_id);\n```\n\n## 미세 조정된 모델로 챗봇 만들기\n\n이제 미세 조정된 모델이 준비되었으므로 그것을 활용하는 챗봇을 만들어봅시다. 간단히 유지하기 위해 로컬 환경 내에서 실용적인 CLI 챗봇을 실행합니다.\n\n<div class=\"content-ad\"></div>\n\n프로젝트 생성 및 종속성 관리 방법을 자세히 살펴보겠습니다. Python에서 종속성 관리와 패키지화를 위한 도구인 Poetry를 사용합니다.\n\nPoetry가 도와줄 수 있는 세 가지 주요 작업은 빌드, 게시 및 추적입니다. 목표는 종속성을 관리하는 결정론적인 방법을 가지고 프로젝트를 공유하고 종속성 상태를 추적하는 것입니다.\n\nPoetry는 또한 가상 환경을 생성하는 작업도 처리합니다. 기본적으로 시스템 내의 중앙 폴더에 있지만, 제처럼 프로젝트 폴더 내에 가상 환경을 원하는 경우 간단한 구성 변경으로 설정할 수 있습니다:\n\n```js\npoetry config virtualenvs.in-project true\n```\n\n<div class=\"content-ad\"></div>\n\n시에란, 새로운 시로 Python 프로젝트를 만들 수 있어요. 시는 가상 환경을 만들고 시스템의 기본 Python과 연결해줘요. 또한 pyenv와 결합하면 특정 버전을 사용하여 프로젝트를 만들 수 있는 유연한 방법을 얻을 수 있어요. 또는 직접 Poetry에게 사용할 Python 버전을 지정할 수도 있어요: poetry env use /full/path/to/python.\n\n새 프로젝트를 만들었으면, poetry add를 사용하여 종속성을 추가할 수 있어요.\n\n이제 우리의 봇을 위한 프로젝트를 만들고 필요한 모든 종속성을 추가하는 것으로 시작합시다:\n\n```js\npoetry new mental-health-bot\ncd mental-health-bot\n\npoetry add huggingface_hub\npoetry add adapters\npoetry add transformers\npoetry add adapters\npoetry add peft\npoetry add torch\n```\n\n<div class=\"content-ad\"></div>\n\n이렇게 하면 당신의 봇을 실행할 코드가 있는 app.py 메인 파일을 만들 수 있어요. 이전과 마찬가지로, 여러분이 직접 실행하고 싶다면, Hugging Face 토큰 자리 표시자를 여러분의 토큰으로 교체해주세요. 이번에는 Hugging Face에서 베이스 모델과 파인튜닝된 모델만 가져오면 되므로 읽기 전용 토큰이 충분합니다.\n\n또 하나 언급할 점은, 저는 다음 환경에서 이 코드를 실행하고 있다는 것이에요:\n\n- Apple MacBook Pro\n- CPU: M1 Max\n- 메모리: 64 GB\n- macOS: Sonoma 14.4.1\n- Python 3.12\n\n성능을 높이기 위해, macOS 장치에서 GPU를 활용하기 위해 PyTorch에 Metal Performance Shaders (MPS) 장치를 사용하고 있어요:\n\n<div class=\"content-ad\"></div>\n\n```js\ndevice = torch.device(\"mps\");\ntorch.set_default_device(device);\n```\n\n또한, 훈련에 사용했던 것과 동일한 기본 프롬프트를 사용할 것입니다. 모든 것을 함께 넣어보면, 이것이 우리 챗봇의 실용적인 CLI 버전입니다:\n\n```js\nimport torch\nfrom huggingface_hub import login\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ndevice = torch.device(\"mps\")\ntorch.set_default_device(device)\n\nlogin(token=\"your-token\")\n\ntitle = \"Mental Health Chatbot\"\ndescription = \"This bot is using a fine-tuned version of meta-llama/Llama-2-7b-chat-hf\"\n\nmodel_id = \"meta-llama/Llama-2-7b-chat-hf\"\nadapter_model_id = \"vojay/Llama-2-7b-chat-hf-mental-health\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)\nmodel.load_adapter(adapter_model_id)\nmodel.to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\n\ndef get_base_prompt():\n    return \"\"\"\n    You are a knowledgeable and supportive psychologist. You provide emphatic, non-judgmental responses to users seeking\n    emotional and psychological support. Provide a safe space for users to share and reflect, focus on empathy, active\n    listening and understanding.\n    \"\"\"\n\n\ndef format_prompt(base, user_message):\n    return f\"<s>[INST] <<SYS>>{base}<</SYS>>{user_message} [/INST]\"\n\n\ndef chat_with_llama(prompt):\n    input_ids = tokenizer.encode(format_prompt(get_base_prompt(), prompt), return_tensors=\"pt\")\n    input_ids = input_ids.to(device)\n    output = model.generate(\n        input_ids,\n        pad_token_id=tokenizer.eos_token_id,\n        max_length=2000,\n        temperature=0.9,\n        top_k=50,\n        top_p=0.9\n    )\n\n    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n    return decoded.split(\"[/INST]\")[1].lstrip()\n\n\nwhile True:\n    prompt = input(\"You: \")\n    response = chat_with_llama(prompt)\n    print(f\"Llama: {response}\")\n```\n\n이제 한번 해봅시다! 다음 챗 입력으로 실행해봅시다:\n\n\n<div class=\"content-ad\"></div>\n\n```js\n제 감정과 자신을 다루고 있는 중이에요. 잠을 거의 못 자고 불안과 스트레스로 고통받고 있어요. 약물 복용을 피하면서 대처 전략을 추천해주실 수 있을까요?\n```\n\n실제로 저희가 섬세하게 튜닝된 모델로 답변한 결과가 매우 좋았기 때문에, 이 답변을 여기 인용하고 싶습니다. 이 글에서 정신 건강에 관해 이야기할 때 이겁니다.\n\n🤖 고지사항: 아래 텍스트는 AI가 생성한 것입니다.\n\n<div class=\"content-ad\"></div>\n\n네, 약을 복용하지 않고 스트레스와 불안을 관리하는 데 도움이 되는 여러 가지 방법이 있습니다.\n\n- 자신을 돌봅시다. 충분히 잠을 자고 올바르게 먹고 운동합시다. 우리가 스스로를 돌보지 않으면 스트레스와 불안을 느끼기 쉬워집니다.\n- 마음을 집중하는 법을 연습합시다. 이것은 자신을 비판하지 않고 순수하게 순간에 집중하는 것을 의미합니다. 마음을 집중하는 것은 우리가 과거를 놓아버리고 미래에 대해 걱정하지 않게 도와줄 수 있습니다.\n- 명상을 연습합시다. 마음을 집중하는 명상은 숨을 집중하고 현재에 집중할 수 있도록 자신을 훈련시키는 방법입니다.\n- 행복을 주는 것에 대해 생각해보세요. 감사할 만한 것들은 무엇인가요? 좋아하는 일은 무엇인가요?\n- 조용한 시간을 가지고 당신의 생각을 기록해보세요. 생각과 감정을 쓰는 것은 스트레스와 불안을 관리하는 데 매우 도움이 될 수 있습니다.\n- 요가, 타이치 또는 심호흡과 같은 형태의 안정 훈련을 연습합시다.\n- 마사지를 받거나 매니큐어를 받는 등 자기 관리의 형태를 연습합시다.\n- 대화할 상대를 찾아보세요. 때로는 누군가와 이야기하는 것이 다른 시각에서 상황을 볼 수 있도록 도와줄 수 있습니다.\n- 상황에서 유머를 찾아보세요. 때로는 웃음소리가 기분을 끌어올리는 데 도움이 될 수 있습니다.\n- 신체 운동의 형태를 연습해보세요. 운동은 더 편안하고 스트레스를 덜 느끼도록 도와줍니다.\n- 집 밖을 산책하고 신선한 공기를 마시세요.\n- 음악을 듣거나 책을 읽는 등 형태의 안정을 연습하세요.\n- 현재 순간에 집중해보세요.\n\n그게 다입니다, 우리만의 AI 기반 정신 건강 챗봇입니다. 이것으로, 당신에게 유익한 조언이 있을지도 모르니, 건강하게 지내시고 다음 챕터에서 어떻게 계속 진행할지 발견해 보세요.\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_14.png)\n\n<div class=\"content-ad\"></div>\n\n## 해커톤 프로젝트 업그레이드하기: 정신 건강 챗봇을 위한 다음 스텝\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_15.png)\n\n우리가 살펴본 예는 더 발전할 수 있는 훌륭한 기반을 제공합니다. 해커톤 프로젝트를 위한 더 정교한 솔루션을 만드는 몇 가지 방법을 소개합니다:\n\n- 파라미터 조율 프로세스 최적화: LoRA 파라미터와 훈련 구성을 다듬어 챗봇의 성능을 향상시킵니다. 이는 공감적이고 자연스러운 언어 생성으로 이어질 수 있습니다. 또한, Odds Ratio Preference Optimization (ORPO)와 같은 다른 접근 방식을 시도하여 성능을 향상시킬 수 있습니다.\n- 기본 프롬프트 강화: 챗봇이 지지적이고 이해하는 방식으로 응답하도록 장려하는 기본 프롬프트를 만들어보세요. 필요한 경우 전문 도움을 찾도록 사용자를 안내할 수 있는 템플릿을 통합하세요.\n- 검색 증강 생성(RAG) 구현: RAG를 통합하여 챗봇이 사용자 요청을 보강하는 추가적인 맥락을 제공합니다. 이를 통해 더 정보가 풍부하고 관련성 있는 응답을 할 수 있습니다.\n- 간단한 채팅을 넘어 나아가기: 간단한 채팅을 넘어 구조화된 상호작용 모델을 구현하는 것을 고려해보세요. 아마도 인지 행동 요법(CBT) 원칙을 기반으로 한 것일 수도 있습니다. 이는 사용자에게 더 집중된 그리고 잠재적으로 치료적인 경험을 제공할 수 있습니다.\n- 사용성에 집중: 모델 자체를 개선하는 데만 모든 시간과 노력을 집중하는 대신, 프런트엔드 중심적인 접근 방식 역시 채택하여 접근성에 집중하거나 창의적인 상호작용 형태를 사용하여 맞춤형 UI를 만들어 볼 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이런 개선 사항 외에도, 상자 밖을 생각하도록 장려합니다. 심리 건강 지원을 위한 AI 애플리케이션을 개발한다는 것은 가상 상담이나 치료용 챗봇을 만드는 것만을 의미하는 것이 아닙니다. 이 작업에 다른 접근 방법은 스트레스와 같은 정신 건강 문제를 유발하거나 강화하는 측면을 개선하는 방법을 고려하는 것일 수도 있습니다. 만약 우리가 문제를 재정의하여 AI 솔루션을 찾는다고 한다면, 스트레스를 줄이는데 도움이 되는 AI 중심의 개인 맞춤형 명상 지원과 같은 아이디어를 포함하여 초기 문제를 간접적으로 해결하는 많은 아이디어를 떠올릴 수 있습니다. 또 다른 방법은 외상 후 스트레스 장애 (PTSD)와 같은 특정 유형의 정신 건강 문제에 대한 지원에 집중하는 것일 수 있습니다.\n\n적절히 대응된 특정 위험요인이 있다면, 많은 사람들에게 도움이 될 수 있는 기회가 많이 있습니다. 따라서, 2024년 정신 건강 AI 해커톤에서 어떤 눈을 떴다고 생각할만한 솔루션이 만들어질지 기대됩니다.\n\nAI 중심의 애플리케이션 개발에 대한 몇 가지 영감을 드리기 위해:\n\nGoogle Gemini LLM을 사용하여 FastAPI 기반의 진보된 API와 전용 Vue 기반 프론트엔드를 사용하고 싶다면, 이 글을 확인해 보세요:\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 Markdown 형식으로 변경하실 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nAI 기반 챗봇은 24시간 365일 제공되는 접근 가능한 정신 건강 지원으로 이 간극을 좁힐 수 있어요. 이 도구들은 사람들이 정신 건강 여정을 시작할 수 있는 안전한 공간을 제공하여, 필요할 때 가장 필요로 하는 때에 도움이 되는 듣는 귀, 유용한 자원 및 기본적인 대처 방법을 제공해줘요.\n\n하지만, 이 분야에서 AI 챗봇의 잠재적인 제약, 윤리적 고려 사항 및 위험을 인지하고 대응하는 것이 중요해요. 인지 행동 요법 (CBT)과 저랭크 적응 (LoRA), 추출-증강 생성 (RAG)과 같은 기술적 해결책과 같이 주제별 접근 방식은 위험을 완화할 수 있지만, 더욱 논의되고 개선되어야 해요.\n\n이러한 발전을 수용하고 윤리적 발전을 우선시함으로써, 이러한 응용 프로그램들은 정신 건강 의료를 민주화하는 강력한 도구로 거듭날 수 있어요. 정신 건강 AI 해커톤 2024는 혁신과 협력을 육성하여, 사용자 안전과 넓은 인구 집단을 위한 정신 건강 지원을 우선시하는 AI 솔루션을 만들기 위한 진보를 지원해요.\n\n이 미래는 우리가 생각하는 것보다 가까워요. 책임 있는 개발과 윤리적 고려를 중시함으로써, 기술이 정신 건강 의료를 혁신하여, 모든 사람에게 매일 접근 가능하게 만들 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_16.png)\n\n특히 정신 건강 지원은 중요한 위험과 도전을 안고 있지만, 이러한 위험을 투명하게 만들고 공개적으로 논의함으로써 의미 있는 진전의 길을 열 수 있습니다. 여러분의 아이디어, 경험, 우려, 그리고 해결책에 대해 들어보고 싶습니다.\n\n","ogImage":{"url":"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_0.png"},"coverImage":"/assets/img/2024-05-23-MindsandMachinesAIforMentalHealthSupportFine-TuningLLMswithLoRAinPractice_0.png","tag":["Tech"],"readingTime":31},{"title":"사용자 정의 테이블 함수 UDTF","description":"","date":"2024-05-23 15:41","slug":"2024-05-23-User-definedTableFunctionsUDTF","content":"\n\n![이미지](/assets/img/2024-05-23-User-definedTableFunctionsUDTF_0.png)\n\nSpark 3.5에서는 파이썬 사용자 정의 테이블 함수(UDTF)를 소개했습니다. 이것은 새로운 종류의 사용자 정의 함수입니다. 스칼라 함수는 각 호출에 대해 하나의 결과를 생성하는 반면, UDTF는 쿼리의 FROM 절 내에서 호출되며 전체 테이블을 출력합니다. UDTF 호출은 스칼라 식이나 완전한 입력 테이블을 나타내는 테이블 인수 중 어떤 것이든 사용할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-User-definedTableFunctionsUDTF_1.png)\n\n## 파이썬 UDTF 사용 이유\n\n\n<div class=\"content-ad\"></div>\n\n만약 다양한 행과 열을 생성하면서 파이썬의 다양한 생태계를 활용하고 싶다면, Python UDTF가 이상적입니다.\n\n## Python UDTF 대 Python UDF\n\nSpark의 Python UDF는 입력으로 스칼라 값s 중 0개 이상을 받아들이고 단일 값을 반환하는 것이 설계되어 있습니다. 그에 반해, UDTF는 여러 행과 열을 반환할 수 있어 UDF의 기능을 더 확장시킬 수 있어 더 유연합니다.\n\n## Python UDTF 대 SQL UDTF\n\n<div class=\"content-ad\"></div>\n\nSQL UDTFs는 효율적이고 다재다능하지만, Python은 더 다양한 라이브러리와 도구를 제공합니다. 통계 함수나 머신 러닝 추론과 같이 고급 기술이 필요한 변환 또는 계산을 위해서는 Python UDTFs가 특히 유리합니다.\n\n# LangChain과 함께 사용하는 UDTF\n\n이전 예제는 기본적으로 보일 수 있지만, Python UDTFs를 LangChain과 통합하여 더 흥미로운 시나리오를 탐색해 봅시다.\n\n```js\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom pyspark.sql.functions import lit, udtf\n\n@udtf(returnType=\"keyword: string\")\nclass KeywordsGenerator:\n    \"\"\"\n    Generate a list of comma separated keywords about a topic using an LLM.\n    Output only the keywords.\n    \"\"\"\n    def __init__(self):\n        llm = OpenAI(model_name=\"gpt-4\", openai_api_key=<your-key>)\n        prompt = PromptTemplate(\n            input_variables=[\"topic\"],\n            template=\"generate a couple of comma separated keywords about {topic}. Output only the keywords.\"\n        )\n        self.chain = LLMChain(llm=llm, prompt=prompt)\n\n    def eval(self, topic: str):\n        response = self.chain.run(topic)\n        keywords = [keyword.strip() for keyword in response.split(\",\")]\n        for keyword in keywords:\n            yield (keyword, )\n```\n\n<div class=\"content-ad\"></div>\n\n세부 정보:-\n\n즐거운 학습하세요 🙂 !!!!!!\n","ogImage":{"url":"/assets/img/2024-05-23-User-definedTableFunctionsUDTF_0.png"},"coverImage":"/assets/img/2024-05-23-User-definedTableFunctionsUDTF_0.png","tag":["Tech"],"readingTime":2},{"title":"2023년 업데이트된 성적 데이터로부터 마라톤 성적에 대한 백분위 및 Z 점수","description":"","date":"2024-05-23 15:38","slug":"2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData","content":"\n![image](/assets/img/2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData_0.png)\n\n다른 연령대의 경주 결과를 공정하게 비교하는 방법이 무엇인가요?\n\n그것이 저가 지난 몇 달 동안 연구해 온 질문입니다.\n\n문제는 나이가 모두에게 온다는 것입니다. 어느 순간, 얼마나 열심히 훈련해도 우리는 속도를 줄이기 시작합니다. 시작과 속도는 각기 다르겠지만, 이는 불가피한 일이죠.\n\n<div class=\"content-ad\"></div>\n\n나이 등급의 장점은 다른 연령 그룹 간의 레이스 결과를 비교할 수 있는 방법을 제공하여 마스터 러너들이 경쟁력을 유지할 수 있는 기회를 제공한다는 것입니다.\n\n하지만 이 약속을 지키는 것일까요?\n\n다른 러너들로부터 불만을 들은 적이 있고, 몇 가지 결과를 살펴본 후에 나이 등급에는 몇 가지 결함이 있는 것으로 보입니다. 한 가지로는 일반 러너에 대한 많은 차별을 제공하지 않는다는 점이며, 다른 한 가지로는 충분히 보정되어 있지 않아 몇몇 연령 그룹에 이점을 줄 뿐만 아니라 다른 그룹에는 불이익을 주고 있다는 점입니다.\n\n더 나은 방법이 있을까요?\n\n<div class=\"content-ad\"></div>\n\n저는 두 가지 대안을 테스트해 보았어요: Z 점수와 백분위수. 2010년부터 2019년까지의 대량의 데이터를 수집하여 이러한 방법을 시도했는데, 특히 백분위수에는 많은 가능성이 있다고 생각했어요.\n\n오늘은 업데이트된 데이터셋으로 돌아와, 각 대안을 다시 살펴볼 거에요.\n\n# 데이터 출처\n\n우리가 작업하는 데이터는 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n2023년 미국에서 열린 모든 마라톤 결과를 수집했어요. 이 결과들은 Marathon Guide, Athlinks 및 각각의 레이스 웹사이트에서 스크랩한 개인 성적들로 이루어져 있어요.\n\n이를 통해 약 40만 개인 완주 기록을 얻었어요 — 러너의 나이, 성별 및 완주 시간을 포함하고 있어요. 데이터를 정리하고 잘못된 정보가 있는 몇 개의 레코드를 제외하고 BAA의 자격 취득을 위해 사용되는 연령대로 정리했어요.\n\n결과적으로, 609개의 개별 레이스에서 38만 8,560개의 완주 기록을 얻었어요.\n\n이 데이터 세트에 대한 자세한 내용은 여기에서 확인할 수 있어요. 우리 목적에 맞게 말씀드리자면, 여성 75-79세 그룹은 상대적으로 작다는 점을 언급해드릴게요 (157개 완주). 80대의 러너들이 더 적었기 때문에 이 분석에 포함하지 않기로 결정했어요.\n\n<div class=\"content-ad\"></div>\n\n# 2023 자료로 Z 점수 계산하기\n\n결과를 점수화하고 비교하는 한 가지 방법은 Z 점수를 사용하는 것입니다.\n\nZ 점수는 특정 값이 평균보다 얼마나 높거나 낮은지를 측정한 것입니다. 표준화된 측정값이기 때문에 Z 점수는 다른 그룹간에 비교하는 데 사용될 수 있습니다.\n\n반면에 전통적인 연령 등급은 최상의 결과를 기준으로 사용합니다. 각 결과는 해당 최상의 시간과 비교되며 비교용으로 사용될 표준화된 점수가 계산됩니다.\n\n<div class=\"content-ad\"></div>\n\nz 점수를 계산하기 위해 Python의 Pandas 패키지를 사용하여 결과를 성별과 연령 그룹으로 그룹화했습니다. 그런 다음, 각 그룹의 평균과 표준 편차를 계산했습니다(초 단위). 마지막으로, 개별 결과에서 평균을 빼고 표준 편차로 나누어 표준화된 점수를 얻었습니다. 음수 값은 점수가 평균보다 낮음을 나타내고, 양수 값은 평균보다 높음을 나타냅니다.\n\n예를 들어, 한 연령 그룹의 평균 완주 시간이 4시 30분이고 표준 편차가 1시간이라고 합시다. 완주 시간이 3시 30분인 경우, 평균 (4시 30분)을 시간 (3시 30분)에서 빼서 -1시간을 얻습니다. 이를 표준 편차 (1시간)로 나누어 z-점수가 -1(평균보다 한 표준 편차 낮음)임을 얻습니다.\n\nz-점수를 사용하는 데 두 가지 잠재적인 문제가 있습니다.\n\n첫째, z-점수는 평균에 기반을 두고 있습니다. 평균은 이상치로부터 영향을 받을 수 있습니다. 특히 작은 연령 그룹에 이상치가 있는 경우 문제가 발생할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n두 번째로, 각 연령 그룹이 평균을 중심으로 비슷한 범위의 가능성을 갖는다고 가정합니다. 표준 편차가 평균과 함께 조정된다면 이는 아마도 사실일 것입니다. 그러나 표준 편차가 평균과 관계없이 비슷하다면 문제가 발생할 수 있습니다.\n\n여기 각 연령 그룹의 평균 완주 시간을 나타내는 그래프가 있습니다. 녹색 점선은 여성을, 주황색 점선은 남성을 나타냅니다.\n\n남성의 결과를 나타내는 곡선은 꽤 깔끔해 보입니다. 이는 교과서 그래프처럼 보이며, 이것이 연령 그룹 간 실제 관계를 대변할 수 있는 것으로 생각됩니다.\n\n하지만 여성의 경우 변동이 더 많습니다. 곡선 형태로 깔끔하게 증가하는 대신 기울기가 자주 변합니다. 아마도 몇 가지 이상치가 평균을 끌어 올리거나 내리는 역할을 하고 있는 것일수도 있습니다 — 또는 그냥 깔끔하게 나타나지 않는 것일 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그런 다음 표준 편차 문제가 있습니다. 각 연령 그룹에서 평균 범위(1:00에서 1:05)에 있습니다. 평균 시간이 4:15인 젊은 남성의 경우, 평균(2:15) 아래로 표준 편차가 두 개 이상 있을 공간이 없습니다. 그러나 5:30의 평균을 가진 노년 여성의 경우, 러너들이 평균을 능가할 여지가 훨씬 많습니다.\n\n위 그래프는 각 연령 그룹별로 평균에서 1, 2 또는 3 표준 편차 아래로 완주한 러너의 비율을 보여줍니다. 드롭다운은 남성과 여성을 전환할 수 있습니다.\n\n여성 중에서는 평균보다 2 표준 편차 아래에서 완주한 여성의 비율이 꽤 안정적입니다. 그러나 평균보다 1 표준 편차 아래에서 완주한 비율은 연령이 들수록 줄어듭니다. 70-74세 및 75-79세 연령 그룹(매우 적음)을 무시하더라도, 더 늙은 러너와 더 젊은 러너 사이에는 차이가 있습니다.\n\n남성의 경우, 상황은 훨씬 안정적입니다. 평균에서 세 표준 편차 이상 낮게 점수를 받는 러너가 거의 없습니다(75-79세를 제외하고), 그리고 분포는 60대 중반까지 모두 꽤 유사합니다.\n\n<div class=\"content-ad\"></div>\n\n마지막으로, z 점수가 -2, -1, 0, +1, 그리고 +2일 때의 완주 시간에 대한 그래프가 있습니다. 이는 각각의 개인 시간이 어떻게 배치되는지에 대한 아이디어를 제공합니다.\n\n예를 들어, 젊은 남성의 경우 z 점수가 -2인 경우 2:16이고 젊은 여성의 경우 2:39입니다. 여자들에게는 조금 불리한 것 같지만 미친 듯하게 흥분한 것 같진 않아요.\n\n그러나 55-59세에서, 같은 비교를 하면 남성은 2:34이고 여성은 3:03입니다. 여기서는 상황이 좀 더 이상해 보입니다.\n\n55-59세 남성들의 2:34라는 시간은 놀랍긴 합니다. 지난 해 시카고와 보스턴에서 그 나이 그룹의 최고의 남성은 2:35를 뛴 것을 고려하면요.\n\n<div class=\"content-ad\"></div>\n\n그 동안, 해당 연령 그룹의 여러 여성들이 3:03보다 빨리 뛰었습니다. 분명 인상적인 시간이지만 더 이루기 쉬운 시간이죠.\n\n다시 말해, z 점수는 잘 보정되어 있는 것 같지 않습니다. 특히 연로한 나이에서 여성들을 남성들보다 유리하게 만들 수도 있습니다.\n\n# 2023 데이터를 이용한 백분위 계산\n\n결과를 점수화하는 또 다른 방법은 백분위를 사용하는 것입니다. 2010년부터 2019년까지의 데이터를 분석한 결과, 이 방법이 제 선호하는 방법입니다.\n\n<div class=\"content-ad\"></div>\n\n백분위수를 사용하면 다른 모든 선수들과의 성적을 비교하여 특정 시간을 이기는 선수가 몇 퍼센트나 되는지 확인할 수 있어요. 90번째 백분위 수에 있는 선수는 다른 선수들 중 90%보다 빨리 결승선을 통과하죠.\n\n각 연령 그룹이 비교적 경쟁적이라고 가정하면, 특정 백분위에서의 점수를 얻는 것은 대체로 비슷한 난이도라는 거죠. 다만, 문제가 될 수 있는 부분은 만약 어떤 연령 그룹이 경쟁력이 떨어진다면, 더 높은 백분위에서 점수를 얻는 것이 쉬워질 수 있어요.\n\n저는 이전 데이터를 분석하면서 발견한 다른 문제는 백분위가 극단에서는 신뢰성이 크게 떨어진다는 거였어요. 분포의 중간 지점에서는 꽤 잘 작동하지만, 90% 이상부터 몇몇 연령 그룹에서 이상한 결과가 나오기 시작해요. 그리고 99% 이상에서는 대부분의 곡선이 더 뾰족하고 신뢰성이 낮아집니다.\n\n위의 시각화 자료는 백분위 수 표의 세 단계를 거칩니다.\n\n<div class=\"content-ad\"></div>\n\n제가 시작했을 때는 0에서 99.99 백분위까지 각 결과를 직접 계산했습니다. 90%에서 99.99% (위 그림 참조)까지 대규모, 젊은 연령 그룹에서 곡선이 상당히 신뢰할 수 있습니다. 하지만 몇몇 부분에서는 뾰족하고 신뢰할 수 없는 것이죠.\n\n이 프로세스의 두 번째 단계에서는 SciPy 패키지를 사용하여 Savitzky-Golay 필터를 곡선에 적용했습니다. 이는 관측된 값들을 더 부드러운 곡선에 적합시키는 역할을 합니다.\n\n마지막으로, 일부 곡선들이 범위의 매우 끝에서 급격하게 감소하지 않는 것을 발견했습니다. 이는 매우 젊은 남성과 비교해 99.9 백분위에서 높은 점수를 받기가 훨씬 더 쉬워진다는 것을 의미합니다.\n\n더 조정하기 위해, 각 연령 그룹과 99백분위에서의 남자 선수 간의 백분율 차이를 찾아 그를 사용하여 각 연령 그룹에 대한 예상 결과를 계산하고 99에서 99.99까지의 각 백분위에 대한 실제 결과와 평균을 계산했습니다.\n\n<div class=\"content-ad\"></div>\n\n나이가 들어가면서 고령자 그룹이 끝에서 조금 더 경쟁력 있게 되는 곡선을 효과적으로 내려놓습니다.\n\n위의 시각화 자료는 중앙값(50번째)에서부터 99번째 백분위까지 다양한 백분위에서의 실제 완주 시간을 보여줍니다.\n\n99번째 백분위는 확실히 좋은 시간이지만, 위의 -2 개의 Z점수만큼은 경쟁력이 부족합니다. 최상의 시간에 도달하려면 99% 이상의 십분의 일과 백분의 일을 더 살펴봐야 합니다.\n\n그러나 99% 미만에서는 이는 상당히 공정한 동등한 시간대인 것으로 보입니다. 특히 고령 여성들의 경우 99번째 백분위에서 약간 어긋나는 점이 있습니다. 그러나 대부분의 주자들인 90번째 백분위 이하에서는 비교를 하는 데 꽤 효과적인 방법으로 보입니다.\n\n<div class=\"content-ad\"></div>\n\n# 결과 예시 비교\n\n그래서 실제로 어떻게 보이는지 궁금하시죠?\n\n결과가 세 가지 방법에 따라 어떻게 다른지 확인하기 위해 몇 가지 경주를 살펴보겠습니다.\n\n아래는 2023년 저지 시티 마라톤에서 백분위별로 상위 15명의 완주자 목록이 있는 표입니다. 나는 이 레이스에 참가했지만... 이 상위 15명 목록에는 랭크되지 않았습니다.\n\n<div class=\"content-ad\"></div>\n\n\n| Gender   |   Age | Finish   |   zScore |   Percentile |   Age Grade |\n|----------|-------|----------|----------|--------------|-------------|\n| F        |    25 | 02:32:50 |    -2.1  |        99.92 |       87.72 |\n| M        |    27 | 02:17:32 |    -1.98 |        99.86 |       88.45 |\n| M        |    25 | 02:18:28 |    -1.96 |        99.83 |       87.86 |\n| F        |    39 | 02:45:59 |    -1.85 |        99.77 |       83.08 |\n| M        |    30 | 02:22:03 |    -1.9  |        99.7  |       85.64 |\n| F        |    23 | 02:43:08 |    -1.93 |        99.69 |       82.18 |\n| M        |    25 | 02:23:30 |    -1.88 |        99.65 |       84.77 |\n| M        |    26 | 02:23:32 |    -1.87 |        99.64 |       84.75 |\n| F        |    55 | 03:17:42 |    -1.77 |        99.62 |       79.73 |\n| M        |    27 | 02:24:45 |    -1.85 |        99.59 |       84.04 |\n| F        |    30 | 02:46:47 |    -1.87 |        99.58 |       80.38 |\n| M        |    50 | 02:47:20 |    -1.63 |        99.57 |       80.08 |\n| M        |    41 | 02:36:12 |    -1.64 |        99.53 |       80.02 |\n| M        |    27 | 02:26:11 |    -1.83 |        99.51 |       83.22 |\n| F        |    27 | 02:48:45 |    -1.84 |        99.49 |       79.45 |\n\n\n여기에는 많은 중복이 있습니다. 선택한 방식에 관계없이 상위 세 명은 동일했을 것입니다. 하지만 25세 여성들은 나이 등급을 사용했다면 세 번째 자리로 밀려났을 겁니다.\n\n그러나 나이 등급으로 상위 15명을 선정하면, 포함된 가장 낮은 나이 등급은 81.63입니다. 따라서 여기에는 79~80 나이 등급을 가진 몇 명의 러너가 포함되었습니다.\n\n백분위를 사용하면, 상위 15명은 남성 9명과 여성 6명으로 구성됩니다. 한편, 나이 등급을 사용하면 남성 11명과 여성 4명으로 구성됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n퍼센타일을 사용하여 상위 마무리자 중 11명이 35세 미만이고 4명이 35세 이상입니다. 나이 등급별로는 상위 마무리자 중 13명이 35세 미만이며 마스터 연령 그룹 출신은 2명뿐입니다.\n\n추가 예로, 여러분에게 2023년 에리 마라톤에서 제주도의 상위 15명 마무리자를 소개해 드리겠습니다.\n\n```js\n| 성별   | 나이 | 마무리 시간 | z 점수 | 백분위 | 나이 등급 |\n|--------|-----|-------------|--------|---------|-----------|\n| 여자   |  36 | 02:49:47    | -1.79  | 99.64   | 79.62     |\n| 남자   |  40 | 02:40:24    | -1.57  | 99.16   | 77.36     |\n| 남자   |  57 | 02:57:29    | -1.62  | 99.16   | 80.09     |\n| 남자   |  57 | 02:59:10    | -1.59  | 98.92   | 79.35     |\n| 남자   |  38 | 02:39:31    | -1.56  | 98.7    | 76.67     |\n| 여자   |  31 | 02:59:23    | -1.67  | 98.51   | 74.74     |\n| 남자   |  43 | 02:45:36    | -1.49  | 98.43   | 76.61     |\n| 남자   |  26 | 02:36:38    | -1.66  | 98.4    | 77.67     |\n| 남자   |  32 | 02:37:31    | -1.64  | 98.27   | 77.23     |\n| 남자   |  59 | 03:04:56    | -1.5   | 98.13   | 78.25     |\n| 여자   |  40 | 03:10:10    | -1.5   | 98.07   | 73.03     |\n| 여자   |  30 | 03:07:44    | -1.53  | 97.36   | 71.41     |\n| 남자   |  46 | 02:55:36    | -1.39  | 97.32   | 73.92     |\n| 여자   |  34 | 03:08:30    | -1.52  | 97.24   | 71.12     |\n| 여자   |  36 | 03:11:34    | -1.46  | 97.18   | 70.57     |\n```\n\n이리는 제시 시티보다 작은 규모의 마라톤이므로 일부 낮은 점수가 상위 15명으로 진입했습니다. 또한 마스터 러너들이 더 잘 대표됩니다.\n\n<div class=\"content-ad\"></div>\n\n백분위로 보면 상위 완주자 중 9명이 남성이며, 상위 완주자 중 5명이 35세 미만입니다. 연령별로 보면, 상위 완주자 중 13명이 남성이며, 상위 15명 중 6명이 35세 미만입니다.\n\n최고의 성과를 식별하기 위해 z-점수를 사용했다면, 저지 시티에서 상위 완주자 15명 중 14명과 에리에서 상위 완주자 15명 중 10명이 35세 미만일 것입니다. 이러한 연령 그룹은 가장 낮은 표준 편차를 가지고 있어서 이들이 이점을 가질 것으로 예상됩니다.\n\n# 전체 러너들의 전체 분포에 대비하여 점수 비교하기\n\n마지막으로 살펴볼 점은 최고의 성과가 전체 러너들의 전체 분포를 어떻게 향상시키는지 입니다.\n\n<div class=\"content-ad\"></div>\n\n연령 평가의 전체적인 목적은 마스터 러너들이 계속해서 경쟁할 수 있도록 하는 것입니다. 따라서 모든 러너들의 분포와 정확히 일치하지는 않겠지만, 대략적으로는 비슷해야 합니다.\n\n특정 연령 그룹이 최상위 성적에 전혀 나타나지 않는 경우, 해당 그룹에 편향된 시스템이 있다는 신호일 수 있습니다(어떤 이유로든).\n\n그렇다면 상위 1,000개 성적의 분포를 연령 평가, 백분위수, 그리고 Z-점수별로 살펴본다면 어떤 일이 벌어질까요?\n\n이 그래프에서 파란 막대는 1,000명의 러너 중 특정 연령 그룹의 인원 수를 나타냅니다. 다음 세 개의 막대는 연령 평가, 백분위수, 그리고 Z-점수에 따른 최상위 1,000개 성적 러너의 수를 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n드롭다운 메뉴에 유의하세요. 이 메뉴를 사용하여 남성과 여성을 전환할 수 있습니다.\n\n연령 등급은 어떻게 되나요?\n\n35세 미만의 여성들 중 상위 1,000명에 속하는 비율은 그들이 전체 그룹에서 차지하는 비율과 유사합니다. 그러나 35세부터 54세까지, 그들은 명백히 소수입니다. 60세에서 79세 사이에는 반대로 말하면 - 만약 모든 것이 무작위로 분산되어 있다면, 상위 1,000명 중 여성이 더 많을 것입니다.\n\n남성들을 살펴보면, 35세 미만 연령 그룹은 과대표현(368 대 221)되어 있습니다. 40대의 남성들은 약간 소수로 표현되는 것으로 보이며, 그 외의 연령 그룹들은 그리 나쁘지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n만약 백분위수를 사용한다면 어떨까요?\n\n여성의 경우, 모든 연령 그룹이 상당히 잘 대표되고 있습니다. 35세 미만 연령 그룹은 조금 더 일반적이지만(198 대 161), 극단적이진 않습니다. 나머지 연령 그룹들은 모두 무작위 분포와 상당히 유사합니다.\n\n남성의 경우, 상황은 더욱 대표적입니다. 일부 살짝 다른 차이가 있지만, 어느 연령 그룹도 현저하게 과소 또는 과대 표현되어 보이지 않습니다.\n\n한편, Z 점수는 전혀 대표적이지 않습니다. 남성과 여성 모두에게 35세 미만 연령 그룹이 매우 과대 표현되어 있습니다. (65-69세까지의) 대부분의 다른 남성 연령 그룹들은 심하게 과소표현되어 있습니다. 마스터 여성들은 조금 나은 상황이지만, 대부분은 전혀 과소표현되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n3개의 방법 중 백분위 점수 산정은 최고 선수의 분포가 러너들 전체 분포와 가장 유사합니다.\n\n# 결론 및 앞으로의 방향\n\n2023년 데이터를 분석한 결과 - 나이에 따라 변하는 보스턴 예선 시간을 포함한 이 기사를 읽은 후에도 나이 등급 시스템이 업데이트가 필요하다고 확신합니다.\n\n여성을 중심으로 보정에 문제가 있어 몇몇 그룹을 다른 그룹보다 우대하는 것이 있습니다. 그리고 80세 이상 나이 등급 점수를 받는 사람들의 경우는 소수에 불과하기 때문에 많은 차별적인 기능을 제공하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n원래 2010년부터 2019년까지의 데이터를 사용하여 백분위수를 계산했을 때, 교정 문제가 있었습니다. 하지만 이 분석의 최종 결과는 더 균형을 이루는 것 같아요.\n\n여러 선수들이 99번째 백분위수 이상을 얻는 경우에는 절대 최고의 성적을 결정하는 최선의 방법이 아닐 수도 있지만, 평균 이상의 선수들을 비교하는 데 훨씬 나은 방법입니다.\n\n다음은 무엇일까요?\n\n지금 데이터 탐색과 분석을 마쳤으니, 이를 좀 생각해볼 시간을 갖고 싶어요. 생각을 정리한 후에 기존 연령 등급 및 백분위수의 장단점을 제시한 마지막 기사를 준비할 거예요.\n\n<div class=\"content-ad\"></div>\n\n한편, 2023 연령 요소, z-점수 및 백분위를 활용한 연령 계산기를 업데이트할 예정이며, Kaggle에 데이터셋을 공유할 준비도 하고 있어요.\n\n최종 기사에서 업데이트된 계산기와 공개 데이터셋 링크를 꼭 포함할 거니까, 관심 있으시면 이메일 업데이트를 구독해주세요.\n\n이번 주말에 보스턴에서 참가하는 모든 분들에게 행운을 빕니다! BAA가 발표하면 숫자들을 분석하고, 다음 주에 흥미로운 정보를 공유할 거에요.\n\n저는 열정적인 러너이자 데이터 애호가에요. 방금 40살이 되었어요, 그래서 연령 그룹 간 결과를 비교하는 것이 나에게 특히 흥미롭답니다. 제 활동을 계속 지켜볼 수 있는 방법은 다음과 같아요:\n\n<div class=\"content-ad\"></div>\n\n- 러닝 위드 락 팔로우해서 내 훈련 소식 듣기\n- 마라톤 훈련 계획 선택에 대한 팁 읽기\n- Strava에서 나를 스토킹하기\n","ogImage":{"url":"/assets/img/2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData_0.png"},"coverImage":"/assets/img/2024-05-23-PercentilesandZScoresforMarathonPerformancesFromUpdated2023PerformanceData_0.png","tag":["Tech"],"readingTime":11},{"title":"매니저의 의사 결정을 위한 데이터 시각화의 예술","description":"","date":"2024-05-23 15:37","slug":"2024-05-23-TheArtofDataVisualizationforManagersDecision-Making","content":"\n저희는 결정을 내릴 때 매니저들이 의식적이든 무의식적이든 부딪히는 근본적인 도전 과제를 발견하기 위해 노력하고 있습니다. 시각화를 통해 현실 세계의 시나리오에서 이러한 도전 과제들을 탐구하며, 효과적으로 대응할 수 있는 간단한 해결책을 제시합니다.\n\n# 소개\n\n오늘날 데이터 중심의 세계에서 기업들은 지속적으로 정보에 노출되고 있습니다. 고객 거래부터 직원 생산성까지, 모든 활동은 가치 있는 데이터를 생성합니다. 핵심 도전 과제는 이 방대한 양의 정보에서 통찰력을 뽑아내어 정보에 근거한 결정을 내리는 데 있습니다.\n\n여기서 데이터 시각화가 필요합니다. 복잡한 데이터를 명확하고 간결한 차트, 그래프 및 기타 시각 형식으로 변환함으로써 기업은:\n\n<div class=\"content-ad\"></div>\n\n- 실용적인 통찰력 획득: 시각화는 복잡한 데이터를 단순화하여 숨겨진 패턴과 트렌드를 드러내어 엑셀 시트나 숫자로 표현된 데이터에서 빠뜨릴 수 있는 정보를 보여줍니다.\n- 결정력 향상: 명확한 시각화는 관리자가 빠르게 주요 정보를 파악하고 더 확신을 갖고 데이터 기반 결정을 내릴 수 있게 도와줍니다.\n- 효율성 향상: 시각화는 정보를 쉽게 소화할 수 있는 형태로 제시하여 분석과 행동이 빨라지게 해 시간을 절약합니다.\n\n데이터 시각화를 활용함으로써 기업은 데이터의 진정한 잠재력을 발휘할 수 있으며, 이를 통해 부담에서 벗어나 성공을 이룰 수 있는 강력한 도구로 변모시킬 수 있습니다.\n\n<img src=\"/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_0.png\" />\n\n# 부적절한 데이터 시각화\n\n<div class=\"content-ad\"></div>\n\n기술이 발전하고 시각화 도구가 조직의 의사 결정에 더 많이 사용됨에 따라, 실수가 발생할 수 있다는 것을 인정하는 것이 중요합니다. 이는 매니저의 경험 부족 때문이 아닌 시각화 과정 자체의 오류로 인한 경우가 많습니다.\n\n![이미지](/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_1.png)\n\n여기에서는 오류가 발생하는 시각화에서 흔히 발생하는 몇 가지 함정을 강조합니다:\n\n# 1. 적절하지 않은 차트\n\n<div class=\"content-ad\"></div>\n\n문제 : 차트는 데이터 표현을 간소화하기 위해 고안되었지만, 잘못된 차트 선택은 정보를 명확히 하는 대신 혼선을 초래할 수 있습니다. 종종, 차트를 만드는 사람들은 최적의 선택을 하는 전문 지식이 부족하여 잘못 해석되는 결과를 초래하곤 합니다.\n\n![이미지](/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_2.png)\n\n# 2. 그래프 장식\n\n문제 : 때로는 그래프가 어떻게 색칠되었느냐에 따라 혼란스러울 수 있습니다. 예를 들어, 연한 파란색과 진한 파란색을 사용하여 서로 다른 숫자를 나타내는 경우, 큰 차이가 명확히 나타나지 않을 수 있습니다. 이는 데이터에 기반한 결정을 내릴 때 문제가 될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n해결책: 데이터의 범위를 명확하게 보여주는 색상 조합을 사용하여 차트의 차이를 눈에 띄게 만들어보세요.\n\n![Visualization](/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_3.png)\n\n## 3. 지나치게 혼잡한 차트\n\n문제: 가끔 도트 차트는 너무 많은 점들이 모여 있어서 읽기 어려울 수 있습니다. 몇 군데는 많은 도트가 모여 있어서 중요한 세부 정보를 모두 볼 수 없게 만듭니다.\n\n<div class=\"content-ad\"></div>\n\n해결책: 관리자가 데이터를 명확하게 볼 수 있도록 조정할 수 있는 동적 차트를 사용하세요.\n\n![2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_4](/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_4.png)\n\n# 4. 전문 지식 부족\n\n문제: 모든 비즈니스에서 진행 상황을 모니터링하기 위해 올바른 주요 성과 지표(KPI)를 가져야 합니다. 일반적으로 IT팀에서는 데이터 분석가가 데이터 정리와 시각화를 다룹니다. 그러나 그들은 가끔 가장 적합한 차트를 선택하는 데 전문성이 부족할 수 있습니다. 때로는 선택된 KPI가 이상적이 아닐 수 있습니다. 디자이너가 비즈니스 인텔리전스 도구만 사용하는 데 빠져 있다고 하더라도 비즈니스 컨텍스트를 깊이 이해하지 못했기 때문입니다. 경우에 따라서 매니저들이 바빠서 차트를 철저히 검토할 시간이 없을 수 있습니다. 결과적으로 가치 있는 통찰력이 누락될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_5.png)\n\n## 5. 상관 계수\n\n문제: 과학적 및 학술 연구에서는 그래프가 종종 서로 다른 변수 간의 상관 관계(상관 계수)를 강조합니다. 그러나 상업 부문에서는 이러한 실천이 덜 일반적입니다. 매니저들은 시행착오를 통해 매개변수 간의 관계를 이해하는 데 도움이 될 수 있습니다. 예를 들어, 매개변수 1의 증가가 매개변수 2의 감소로 이어진다는 것을 알면 의사 결정에 중요할 수 있습니다.\n\n해결책: 핵심 매개변수 간의 관계를 파악하고 이해하는 데 매니저들이 도울 수 있도록 그래프에 상관 계수 분석을 통합하세요.\n\n<div class=\"content-ad\"></div>\n\n\n![Data Visualization](/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_6.png)\n\n# 6. 스토리텔링 부족\n\n문제: 많은 조직이 너무 많은 차트를 가지고 리포트, 대시보드 또는 시각화를 만들어내어 모든 데이터를 시각적 형태로 전환합니다. 이러한 방식은 모든 차트가 아닌 의미 있는 통찰을 전달하는 차트들을 보여주는 것이 필요한 매니저를 혼동시킬 수 있습니다. 이 과다한 양은 매니저의 시간과 에너지를 낭비하게 하여 의사 결정력을 약화시킬 수 있습니다.\n\n해결책: 시각화에서 스토리텔링을 사용하여 매니저가 차트에 나타낸 진전과 저조를 분명하게 이해할 수 있도록 돕습니다. 이 내러티브 접근 방식은 시청자가 주요 메시지와 통찰을 파악하도록 도와주어 시장 문제나 판매 기회를 최대화하거나 발생시키는 문제를 회피할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n![Gaussian Distribution](/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_7.png)\n\n## 7. 가우시안 분포\n\n문제: 많은 차트들이 평균에만 의존하여 정확성과 상세함이 부족한 정보를 제시합니다. 중요한 결정에는 이 수준의 정보가 부족하고 잘못된 정보로 이어질 수 있습니다.\n\n해결책: 상자 그림과 같은 가우시안 분포 차트를 활용하여 데이터 밀도와 변동성을 표시합니다. 이러한 차트는 데이터의 더 명확한 그림을 제공하여 관리자들이 보다 정보에 기반한 효과적인 결정을 내릴 수 있도록 도와줍니다.\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_8.png\" />\n\n# 다음은 무엇일까요?\n\n다음의 화이트 페이퍼에서는 차트와 데이터 시각화를 사용할 때 의사 결정에 직접적인 영향을 미치는 주요 성과 지표(KPI) 및 관리 매개변수에 초점을 맞출 것입니다. 이러한 매개변수는 매니저들을 위한 시각화의 효과를 설명할 것입니다. 또한 데이터 과학의 역할을 탐구하고 시각화를 향상하기 위한 매니저들의 해결책도 제시할 것입니다.\n\n제작 및 디자인: Ehsan Goudarzi\n\n<div class=\"content-ad\"></div>\n\n## 저자 소개\n\nEhsan Goudarzi: 데이터 과학자, 비즈니스 분석가 및 컨설턴트로 11년의 경력을 보유하고 있습니다. 비즈니스, 데이터 과학 및 데이터 시각화를 전문으로 하고 있으며, 스타트업들이 데이터 분석을 통해 최적화하는 데 도움을 줍니다. 데이터 과학 석사학위 소지자로, BABOK, BI, BPMN 및 TOGAF에 인증을 받았습니다.\n\nEhsan과 소통을 이어가고 인사이트를 공유하려면 이메일 및 Linkedin을 통해 연락해보세요!\n","ogImage":{"url":"/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_0.png"},"coverImage":"/assets/img/2024-05-23-TheArtofDataVisualizationforManagersDecision-Making_0.png","tag":["Tech"],"readingTime":5},{"title":"파이썬을 사용하여 쌓인 지역 효과 플롯ALE에 대해 깊이 파헤쳐 보기","description":"","date":"2024-05-23 15:34","slug":"2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython","content":"\n고도로 상관된 기능들은 모델 해석에 혼란을 야기할 수 있습니다. 이러한 기능들은 많은 XAI 방법의 가정을 위반하며, 특성과 타겟 간의 관계를 이해하기 어렵게 만듭니다. 동시에 이러한 기능들을 제거하지 않고는 성능에 영향을 미치지 않으면서 제거할 수 없는 경우도 있습니다. 다중공선성이 있어도 명확한 해석을 제공할 수 있는 방법이 필요합니다. 다행히 ALE(Accumulated Local Effects)에 의존할 수 있습니다.\n\nALE은 전역 해석 방법입니다. PDP와 비슷하게 모델에 포착된 추세를 보여줍니다. 즉, 특성이 타겟 변수와 선형적, 비선형적 또는 상관 관계가 없는지를 보여줍니다. 그러나 이러한 추세를 식별하는 방법이 매우 다르다는 것을 알게 될 것입니다.\n\n- ALE가 생성되는 방식에 대한 직관을 제공합니다.\n- ALE을 생성하는 데 사용되는 알고리즘을 형식적으로 정의합니다.\n- Alibi Explain 패키지를 사용하여 ALE을 적용합니다.\n\n<div class=\"content-ad\"></div>\n\n타 도움말 비교했을 때 SHAP, LIME, ICE Plots, 그리고 프리드만의 H 통계치와 달리, ALE(Accumulated Local Effects)은 다중공선성에 강건한 해석을 제공합니다.\n해당 주제에 대한 이 비디오도 즐길 수 있을 것입니다. 그리고 더 배우고 싶다면, XAI with Python과 같은 내 코스도 확인해보세요. 뉴스레터 가입 시 무료로 액세스할 수 있습니다.\n\n# ALE 이해하기\n\n우리는 전복 데이터셋을 사용하여 ALE이 어떻게 작용하는지 이해할 것입니다. 전복은 조개류의 한 종입니다. 우리는 조개 안의 반지 수를 예측하고 싶은데, 그때 조개 쉘 무게와 살 총량(살의 무게)과 같은 특징을 사용합니다. 이 데이터셋 내 모든 숫자형 특징에 대한 상관 관계 열지도를 보여주는 그림 1을 확인하세요. 우리는 상당히 상관관계가 높은 특징들을 다뤄야 합니다!\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_1.png\" />\n\n그림 2는 이러한 두 가지 기능에 대한 산포도를 제공합니다. – 셀과 껍질 무게. 이들이 0.9의 상관 값이 있는 이유를 볼 수 있습니다. 이제 빨간 색의 인스턴스를 고려해보세요. 이것은 0.2의 껍질 무게를 가지고 있으며, 이와 유사한 인스턴스들은 대략 0.2에서 0.5 정도의 껍질 무게를 가질 것입니다. 많은 XAI 방법들은 이를 고려하지 않을 것입니다.\n\n- PDPs는 전체 범위의 껍질 무게를 샘플링할 것입니다.\n- 순열 특성 중요도는 껍질 무게 값을 무작위로 섞을 것입니다.\n\n다시 말해, 이러한 방법을 사용하면 발생하기 힘든 또는 불가능한 특성 쌍이 발생할 수 있습니다. 이 문제를 해결하는 핵심은 범위를 고려하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n![Image](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_2.png)\n\n상관관계는 두 특성의 전체 범위를 사용하여 계산할 수 있습니다. 작은 간격 내의 인스턴스만을 살펴보면 상관관계는 무의미해집니다. Figure 3에서 이를 확인할 수 있습니다. 우리는 1.5에서 2.5 사이의 조개 무게를 갖는 인스턴스들만을 고려하여 붉은 색 인스턴스 주변의 간격을 만들었습니다. 오른쪽의 그래프에서 이 간격 내에서 상관관계가 명확하지 않음을 볼 수 있습니다. 더 작은 간격에서는 더 명확하지 않을 것입니다. ALEs는 이를 활용합니다.\n\n![Image](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_3.png)\n\n상관관계를 피하기 위해 이 간격 내에서 조개 무게의 영향을 결정할 수 있습니다. 이를 위해 우리는 간격 내 모든 인스턴스에서 두 개의 샘플을 만듭니다. 이를 샘플 쌍이라고 부릅니다. Figure 4에서 볼 수 있듯이, 간격 내에서의 최소 및 최대 조개 무게 값으로 대체하여 이를 생성합니다. 다른 모든 특성 값은 동일하게 유지됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_4.png)\n\n다음 단계는 샘플 쌍의 두 샘플에 대한 블랙박스 모델 예측을 가져오는 것입니다. 그런 다음 최소 샘플(주황색)의 예측값을 최대 샘플(녹색)의 예측값에서 뺍니다. 이 작업을 모든 샘플 쌍에 대해 수행하고 평균을 계산합니다. 이는 이 간격 내에서 껍질 무게의 변화로 인한 예측에 대한 추정치를 제공합니다. 중요한 점은 살아있는 무게와의 상관관계가 이 추정치를 왜곡시키지 않는다는 것입니다.\n\n![Image](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_5.png)\n\n좋아요, 이는 특정 간격 내에서의 효과를 제공합니다. 전반적인 추세를 얻으려면 기능 범위 내의 모든 연속적인 간격에 대해 이 작업을 수행하고 개별 효과를 더해야 합니다. 새로운 간격으로 이동할 때마다 효과를 누적 효과에 추가하고 점을 그립니다. 이를 수행하면 껍질 무게에 대한 ALE를 얻을 수 있습니다. 이제 이름의 유래를 확인할 수 있습니다. 간겭(지역) 내에서 기능 효과를 누적하고 있는 것입니다.\n\n\n<div class=\"content-ad\"></div>\n\nALEs를 바라보는 또 다른 방법은 적분 또는 적어도 적분을 근사하는 Riemann 합과 유사하다는 것입니다. 지역 효과는 함수의 변화율 또는 도함수입니다. 효과를 누적함으로써 우리는 블랙 박스 모델 곡선을 찾아갑니다. 간격이 작아질수록 우리는 진정한 곡선에 더 가까워집니다. 안타깝게도 ALE에 대해 우리는 간격을 무한히 작게 만들 수 없습니다.\n\n![image](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_6.png)\n\n# 형식적인 알고리즘\n\nALE에 대한 수학적 공식이 있습니다. 이번에는 그걸 넘기겠습니다. 그래도 ALE 알고리즘을 좀 더 형식적으로 정의하는 것은 가치가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Deep Dive on Accumulated Local Effect Plots with Python](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_7.png)\n\n다양한 구현 방법은 이 알고리즘에 약간의 차이를 줄 수 있습니다. 예를 들어, 제 2 단계에서 간격을 정의하는 방식입니다. 아래 구현은 각 간격에 최소한의 피처가 포함되도록 정의합니다. 또한 각 간격의 너비가 일정한 것으로 정의할 수도 있습니다.\n\n# Alibi를 사용한 ALE 적용\n\nALE을 적용하기 위해 alibi 패키지를 사용할 것입니다. 이 패키지는 다양한 XAI 방법을 제공합니다. 현재는 ALE 및 plot_ale 함수 (라인 8-9)에 관심이 있습니다. 이 패키지를 적용하고 플롯을 해석하는 방법을 살펴볼 것이며, 여러 ALE을 결합하고 간격 길이를 변경하는 방법에 대해 알아볼 것입니다.\n\n\n<div class=\"content-ad\"></div>\n\n#데이터셋 및 모델\n\n이전에 언급한 전복 데이터 세트에 이 방법을 적용할 것입니다. 데이터 세트를 로드하고 타겟을 선택합니다. 또한 몇 가지 특성 엔지니어링을 진행합니다. 먼저, 직경과 전체 무게를 특성 목록에서 제외합니다. 그 이유는 Figure 1에서 다른 특성들과의 상관 관계가 1임을 확인했기 때문입니다. 마지막으로 성별 특성에 대해 원-핫 인코딩을 생성합니다. 최종 특성 세트의 스냅샷을 Figure 5에서 확인할 수 있습니다.\n\n```js\n#데이터셋을 가져옵니다\ndata = pd.read_csv(\"../../data/abalone.data\",\n                  names=[\"sex\",\"length\",\"diameter\",\"height\",\"whole weight\",\n                         \"shucked weight\",\"viscera weight\",\"shell weight\",\"rings\"])\n\ny = data[\"rings\"]\nX = data[[\"sex\", \"length\", \"height\", \"shucked weight\", \"viscera weight\", \"shell weight\"]]\n\n# 더미 변수 생성\nX['sex.M'] = [1 if s == 'M' else 0 for s in X['sex']]\nX['sex.F'] = [1 if s == 'F' else 0 for s in X['sex']]\nX['sex.I'] = [1 if s == 'I' else 0 for s in X['sex']]\nX = X.drop('sex', axis=1)\n\nX.head()\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_8.png\" />\n\n우리는 이러한 특성들을 사용하여 모델을 훈련시켜 반지의 개수를 예측합니다 (lines 2-3). 모델을 훈련할 때 특성 매트릭스를 numpy 배열로 변환합니다. ALEs를 생성할 때 경고 메시지가 표시되지 않도록 하기 위함입니다.\n\n```js\n# 모델 훈련\nmodel = RandomForestRegressor()\nmodel.fit(X.to_numpy(), y)\n```\n\n## ALE 그래프 그리기\n\n<div class=\"content-ad\"></div>\n\nALE 플롯을 생성하려면, 먼저 ale 객체를 생성해야 합니다 (2번째 줄). 이를 위해 모델의 예측 함수 (model.predict), 피처 이름 및 타겟 이름을 전달합니다. 그런 다음 이 객체를 사용하여 X 피처 매트릭스에 대한 설명 (exp)을 생성합니다 (3번째 줄). 설명 함수를 사용하려면 이 매트릭스가 넘파이 배열이어야 합니다.\n\n```js\n# ALE 설명 가져오기\nale = ALE(model.predict, feature_names=X.columns, target_names=['rings'])\nexp = ale.explain(X.to_numpy())\n```\n\nALE 플롯을 생성하려면 설명과 표시하려는 피처를 plot_ale에 전달합니다. 위치 배열 [0,1,2]를 사용하면 처음 3개 피처에 대한 ALE를 표시합니다. Figure 6에서 확인할 수 있습니다.\n\n```js\n# 처음 3개 피처에 대한 ALE 설명 플롯하기\nplot_ale(exp, features=[0,1,2], fig_kw={'figwidth':15, 'figheight': 5})\n```\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_9.png)\n\n제 6번 그림에서 얻을 수 있는 몇 가지 결론은 다음과 같습니다:\n\n- 길이와 높이가 예측된 링 개수에 미치는 영향은 껍질 무게와 비교할 때 낮습니다.\n- 껍질 무게에 대한 내려가는 선은 껍질 무게가 증가함에 따라 예측된 링 개수가 감소하는 경향을 보입니다.\n\n또한 플롯에서 개별 점을 해석할 수도 있지만, 먼저 플롯이 어떻게 중심화되었는지 이해해야 합니다. Figure 7에서 껍질 무게 관계에 초점을 맞추어 봅시다.\n\n<div class=\"content-ad\"></div>\n\n![그림 7](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_10.png)\n\nALE는 0을 중심으로 설정되었습니다. 이것은 각 ALE의 미중심 누적 지역 효과에서 평균을 뺌으로써 수행됩니다. 처음에는 혼란스러울 수 있습니다. ALE의 평균을 찾기 위해서는 먼저 ALE의 각 지점에서 누적 지역 효과를 합산해야 합니다. 결과적으로 ALE의 각 지점은 해당 특징값과 해당 특징의 평균 효과를 비교했을 때의 효과를 나타냅니다. 또는 더 간단히 말하면, 평균 예측과 비교했을 때의 효과입니다.\n\n따라서, 그림 7의 터플 중량에 대한 플롯을 살펴보면 다음과 같은 결론을 내릴 수 있습니다:\n\n- 터플 중량이 0이면 평균 예측 대비 6개의 고리 예측이 증가합니다.\n- 터플 중량이 1.4인 경우에 비해 0의 터플 중량은 예측이 12개 증가합니다.\n\n<div class=\"content-ad\"></div>\n\n## ALE 결합하기\n\n그럼 alibi 패키지로 무엇을 더 할 수 있는지 알아보겠습니다. 특징들이 유사한 값을 갖고 있다면, ALE을 동일한 축에 플롯하는 것이 유용할 수 있습니다. 아래에서는 이를 3개의 무게 특징에 대해 수행합니다. 그림 8을 보면, 이러한 특징들의 영향을 비교하는 것이 얼마나 쉬운지 알 수 있습니다.\n\n```python\n# 무게 특징에 대한 ALE 플롯\nfig, ax = plt.subplots(1, 1, figsize=(8, 4))\n\nplot_ale(exp, features=[2], ax=ax, line_kw={'label': 'shucked weight'})\nplot_ale(exp, features=[3], ax=ax, line_kw={'label': 'viscera weight'})\nplot_ale(exp, features=[4], ax=ax, line_kw={'label': 'shell weight'})\n\nax.set_xlabel('weight')\n```\n\nshucked weight와 shell weight가 예측에 상당한 영향을 미치는 것을 알 수 있습니다. 그러나 그들은 반대 방향에 있습니다. 흥미로운 사실입니다! 이러한 특징들은 상호 관련이 높지만 예측과는 서로 다른 관계를 가지고 있습니다. 이는 두 특징 간의 상호 작용 때문입니다 — 이를 알아보기 위해 H-통계를 사용할 수 있습니다(향후 게시될 기사를 기대해주세요).\n\n<div class=\"content-ad\"></div>\n\n\n![Screenshot](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_11.png)\n\n여기서 변수 간격이 다른 것을 알 수 있습니다. 이는 패키지가 간격을 선택하는 방식과 관련이 있습니다. 기본적으로 적어도 4개의 인스턴스가 포함된 간격을 선택합니다. 따라서 ALEs에서 끝에서 두 번째와 마지막 포인트 사이에 상대적으로 큰 거리를 볼 수 있습니다. 이러한 가중치 값에 대해 데이터 세트가 희소해지고 적어도 4개의 인스턴스를 포착하기 위해 더 큰 간격이 필요합니다.\n\n## 간격 길이 증가\n\n아래 코드에서는 동일한 차트를 만들되 한 가지 주요 차이가 있습니다. 간격 내의 최소 인스턴스 수를 50으로 변경했습니다 (3번째 줄). 이는 min_bin_points 매개변수를 사용하여 수행됩니다. Figure 9에서 볼 수 있듯이 결과는 더 부드러운 ALE 및 큰 간격입니다.\n\n\n<div class=\"content-ad\"></div>\n\n```python\n# 간격 조정\nale = ALE(model.predict, feature_names=X.columns, target_names=['rings'])\nexp = ale.explain(X.to_numpy(), min_bin_points=50)\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 4))\n\nplot_ale(exp, features=[2], ax=ax, line_kw={'label': 'shucked weight'})\nplot_ale(exp, features=[3], ax=ax, line_kw={'label': 'viscera weight'})\nplot_ale(exp, features=[4], ax=ax, line_kw={'label': 'shell weight'})\n\nax.set_xlabel('weight')\n```\n\n![image](/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_12.png)\n\n`min_bin_points`는 ALE를 만들 때 trade-off를 도입합니다. 이 값을 줄이면 간격의 크기가 줄어듭니다. 이는 곡선의 진정한 모양에 더 가까워질 것입니다. 그러나 이러한 간격 내에서 효과를 추정하는 데 사용할 수 있는 샘플 크기가 줄어들어 불확실성에 직면하게 됩니다. 일반적으로 이 불확실성으로 인해 구간 간 변화보다는 전반적인 추세에 중점을 두어야 합니다.\n\n다른 고려사항은 ALE의 해석은 명료하지만 해당 해석을 얻는 방법을 설명하기는 복잡할 수 있다는 것입니다. PDP가 어떻게 생성되는지 비교할 때 적어도 그렇습니다. 따라서 두 방법을 함께 사용하는 것이 유용합니다. 결과가 일치하면 언제든 PDP를 제시할 수 있습니다. 이렇게 하면 평균 누적 로컬 효과가 무엇인지 설명하는 머리 아픈 작업이 절약될 수 있습니다!\n\n\n\n<div class=\"content-ad\"></div>\n\n만약 PDPs가 어떻게 만들어지는지 알고 싶다면 이 기사를 참조해보세요:\n\n다른 XAI 기사들도 유용하게 사용할 수 있을 거예요:\n\n이 기사를 즐겁게 읽으셨으면 좋겠어요! 무료로 파이썬 XAI 코스에 접근할 수 있는 Threads | YouTube | Newsletter에서 저를 찾아보세요\n\n## 참고문헌\n\n<div class=\"content-ad\"></div>\n\n[1] Daniel W Apley 및 Jingyu Zhu. 블랙 박스 지도 학습 모델에서 예측 변수의 효과를 시각화하는 방법. Journal of the Royal Statistical Society Series B: Statistical Methodology, 82(4):1059–1086, 2020.\n\n","ogImage":{"url":"/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_0.png"},"coverImage":"/assets/img/2024-05-23-DeepDiveonAccumulatedLocalEffectPlotsALEswithPython_0.png","tag":["Tech"],"readingTime":9},{"title":"통계적 유의성 재고하기","description":"","date":"2024-05-23 15:32","slug":"2024-05-23-RethinkingStatisticalSignificance","content":"\n\n<img src=\"/assets/img/2024-05-23-RethinkingStatisticalSignificance_0.png\" />\n\n통계적 유의성은 오늘날 과학적 탐구의 중추 역할을 하지만, 몇 년 전 Nature 저널에서 800명 이상의 연구자가 서명한 호소문을 최근에 발견하면서 통계 검정에 관한 장기간의 아이디어와 생각이 되살아 났어요. 이러한 통계 검정이 과학 연구의 좋은 부분을 망치는 것보다 도와주는 게 더 많다는 것을 깨닫게 되었죠.\n\n일반적으로 연구 결과는 미리 정의된 p-값 임계값에 따라 \"의미 있는\" 또는 \"의미 없는\" 범주로 분류됩니다. 일반적으로 화학 및 생물학 분야에서 사용되는 임계값은 0.05 또는 0.01 또는 0.001입니다. (다른 분야에서 사용되는 임계값과는 분명히 다릅니다.) 여기에는 특히 비전문가들 사이에서 나타나는 첫 번째 문제가 있습니다. 비의미한 결과는 효과가 없다는 것이 아니라, 그에 대한 결정적인 증거가 부족하다는 것을 나타냅니다. 하지만 이를 넘어서, 숨겨진 편견과 이해관계, 특히 매우 경쟁적인 과학 및 공학 분야에서 악화될 수 있는 다른 일반적인 문제들이 있습니다.\n\n나와 다른 많은 이들이 문헌에서 찾아볼 수 있는 토론에서 볼 수 있는 것처럼, 논문들은 통계 검정 대신 핵심 데이터의 상세하고 균형 잡힌 플롯, 아마는 원시 데이터까지 제시해야 한다고 생각해요. 최근 몇 년간, 과학자들은 이와 비슷한 아이디어들을 제기하며 통계적 유의성 검정에서 파생된 \"효과 vs. 무효\"의 이진 측정에 의존하고 있다는 것이 우리를 오도하고 해석을 오해하게 할 수 있다고 주장하고 있습니다. 또한, 나는 중요한 부분이라고 생각하는 것은, 이러한 사고가 과학적 풍경을 왜곡시킬 수 있다는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n개발자분이세요. 위의 텍스트를 친근한 톤으로 한국어로 번역하겠습니다.\n\n여기서 시작 단락에서 언급한 \"간청\"이 필요한 곳입니다. 이것은 자연(Nature) 저널의 세 명의 연구자들에 의한 주석으로 이루어져 있으며, 과학 연구에서 통계적 유의성의 잘못된 해석과 남용에 대한 800명이 넘는 서명자들의 우려를 드러냅니다. 본질적으로 이 비평은 일반적으로 결과를 임의의 임계값을 기준으로 바이너리 결과로 분류하는 관행에 도전합니다. 예를 들어, p-값에 대한 자주 사용되는 수준들에 대한 것은 일치하는 값을 또는 메트릭뿐만 아니라, p=0.01이나 p=1/10¹⁰, 또는 95% 또는 99.99999%의 신뢰 구간 등 어떤 수준과 종류의 임계값이든 각자의 숫자에 완전히 의존하지 말아야 한다는 것입니다.\n\n이 문제의 핵심에는 통계 검정이 가져오는 \"이분법적\"이고 \"절대적\" 사고 방식이 있습니다. 그리고 전문가에만 영향을 미칠 것이라고 생각하는 것이 아니라 다른 편향에 영향을 받는 전문가들에게도 해당됩니다. 유의하지 않은 결과를 \"차이가 없다\" 또는 \"효과가 없다\"는 증거로 해석하는 경향은 만연하지만, 모든 통계 분석에 내재된 세밀함을 간과하고 잘못된 결론으로 이어질 수 있습니다. 결과적으로 임의의 유의성 임계값을 충족하지 못하기 때문에 잠재적으로 중요한 효과를 너무 쉽게 무시할 수 있습니다. 통계적 값의 임계값 및 잘라내기 선택에 따라 결론이 어떻게 달라질 수 있는지 확인하려면 이 흥미로운 예시를 확인해 보십시오.\n\n# 조치\n\n자연(Nature)의 간청은 문제를 명확하게 드러내는 것뿐만 아니라 몇 가지 조치도 제안합니다. 가장 극단적이고 지지밖에 남지 않는 조치는 통계적 유의성 개념을 완전히 포기하라는 것입니다. 대신, 연구자들은 \"효과 추정량\"과 그와 관련된 불확실성에 초점을 맞추도록 촉구됩니다. 나는 그들만큼 명확하게 더 언급하면, 연구자들은 데이터의 투명한 제시에 중점을 두어야 하며, 관련 텍스트에서는 가능한 해석을 동반할 수 있지만, \"예\" 또는 \"아니요\" 지표를 함께하는 공식 또는 알고리즘으로 계산해서는 안 됩니다. 즉, 과학 논문은 데이터를 가능한 한 오염되지 않게 제시하고, 관련 텍스트에서는 저자들의 해석에 대해 논의해야 하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n\"‘효과 추정’ 사용 촉진 정신과 동일하게, Nature에 발표된 논평은 ‘신뢰 구간’을 ‘호환성 구간’으로 대체할 것을 제안합니다. 이 재구성은 데이터와 호환되는 값 범위만 전달한다는 것을 의미하며, 다시 한번 ‘효과 대 무효’의 관점으로 생각하는 함정을 피합니다. 통계적 임계값에 기반한 단순한 ‘예/아니오’ 결정에서 벗어나, 손에 있는 증거를 더 포괄적으로 고려하는 것이 목표입니다.\n\n과학 기사에서 데이터에 주로 초점을 맞추었지만, 같은 개념이 기술 보고서, 문서 자료 등에도 적용될 수 있습니다. 표준 운영 절차의 일부인 고도로 표준화된 프로토콜의 경우 특정 통계 테스트의 사용을 강제할 수 있지만, 이러한 것들은 보통 널리 검증되고, 정확한 실험 설정, 샘플링 프로토콜, 데이터셋 크기 등이 어떻게 수행되어야 하는지에 대해 상세히 설명되어 있습니다. 다른 상황에서는 테스트가 현장에서 실행되며 정확한 실험 계획, 샘플링 프로토콜, 데이터셋 크기 등을 사전에 계획하지 않는 경우도 있습니다. 이러한 상황은 때로 제한되어 있으며, 특정 인구에 특정 약물을 시도하는 경우와 같이 막연하지만, 할 수 있는 일이 별로 없습니다.\n\n## 효과 크기 대 효과 존재 여부에 중점을 두고, 생 데이터에 더 많은 주안점\n\n‘효과 크기’로의 이동 제안은 통계적 유의성과 무관하게 결과의 실용적 중요성을 인정하며, 결론을 독자가 더 많이 짓도록 합니다. 물론 연구를 수행한 사람들은 필요한 모든 주장과 함께 결론을 서술할 기회를 가집니다. 그러나 데이터는 데이터입니다.\"\n\n<div class=\"content-ad\"></div>\n\n데이터를 더 폭넓게 보여주는 포인트에 대해 유의할 점은, 현대 컴퓨터 미디어가 출판사들이 받아들여야 할 수많은 솔루션을 가능하게 한다는 점을 강조하고 싶습니다. 최근 제가 제시한 것처럼 웹에서 데이터를 시각적으로 표시하는 다양한 가능성을 보는 것만으로도 이러한 기술들 중 하나의 예를 들어보실 수 있습니다.\n\n화면을 회전하거나 그래프를 확대하여 제시된 데이터를 더 잘 탐구할 수 있게 해주는 대화형 그래픽뿐만 아니라 데이터 처리(위 링크된 글에서 분석한 CanvasXpress와 같은 웹 라이브러리에서도 가능)나 분자 구조와 같이 본질적으로 3D인 데이터를 제시하는 것과 같은 작업들도 가능합니다.\n\n# 결론\n\n통계적 유의성을 완전히 없애는 제안이 급진적으로 보일지 모르지만, 이는 통계 분석에 대한 전통적인 접근 방식에 내재된 단점에 대한 점점 커지는 인식을 반영하고 있습니다. 투명성을 촉진하고 더 깊은 불확실성에 대한 더 깊은 이해, 심지어 겸손(특히 과학적 연구에서 매우 경쟁적인 분야에서)에 대한 깊은 인식을 통해 연구자들은 더 견고하고 신뢰할 수 있으며 개방적인 과학적 담론을 육성할 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n자연 주석의 저자들이 제안한 (종류의) 패러다임 변화의 목표는 효과의 크기를 우선시하여 통계적 유의성에 상관없이 더 균형있고 편향되지 않은 연구 결과나 기준 또는 필요한 다른 어떤 비교도 얻을 수 있다는 것입니다. 더 나아가 연구 결과를 해석하는 데 연구 설계나 이전 지식과 같은 맥락적 요소들이 더 큰 역할을 할 수 있습니다.\n\n이 개혁에 대한 요구는 통계 측정에 국한되지 않고 과학 보고서의 전반적인 영역에 확장됩니다. 추정치, 불확실성을 상세히 설명하고 엄격한 유의수준을 피함으로써 연구자들은 그들의 발견을 포괄적이고 더 객관적으로 제시할 수 있습니다. 기존의 규범에 도전하는 것이 우려를 불러일으킬 수 있지만, 저는 잠재적 이점(향상된 정확성, 더 탄력적으로 뒷받침된 결론 및 더 통찰력 있는 의사 결정)이 모든 위험을 훨씬 능가한다고 생각합니다.\n\n# 주요 참고문헌\n\n엄격한 통계적 기준에 따라 결론이 어떻게 달라질 수 있는지에 대한 특정 예시를 알고 싶다면(다른 많은 예시 중에서 찾아볼 수 있습니다!) 이 흥미로운 기사를 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\nNature에 나온 호소: Amrhein, V., Greenland, S., & McShane, B. (2024). 과학자들이 통계적 중요성에 반발하다. https://www.nature.com/articles/d41586-019-00857-9\n\n또 다른 흥미로운 글: Nuzzo, R. (2014). 통계적 오류. Nature, 506(7487), 150–152. https://www.nature.com/articles/506150a\n\nwww.lucianoabriata.com 저는 내 폭넓은 관심사인 자연, 과학, 기술, 프로그래밍 등에 관해 씁니다. 새로운 이야기를 이메일로 받아보려면 구독하세요. 작은 일에 대해 상담하려면 여기서 제 서비스 페이지를 확인하세요. 저에게 연락할 수 있습니다. 팁을 보내고 싶다면 여기로 보낼 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-23-RethinkingStatisticalSignificance_0.png"},"coverImage":"/assets/img/2024-05-23-RethinkingStatisticalSignificance_0.png","tag":["Tech"],"readingTime":5},{"title":"데이터부터 대시보드까지 Dash Leaflet 및 SeaRoute 라이브러리를 사용해 고대 해상 실크로드 시각화하기","description":"","date":"2024-05-23 15:29","slug":"2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries","content":"\n\n![img](/assets/img/2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries_0.png)\n\n저의 박사학위 중 어려운 부분 중 하나는 선박의 해양 노선을 보여주는 대화형 지도 시각화물을 만드는 것이었습니다. 출발지와 도착지 항구 사이의 선박 노선은 육 지역을 건너가지 않고 오직 바다 상에서의 경로여야 했습니다. 이중 seemingly straightforward 였던 작업이 파이썬에서 처음부터 구현하려고 시도할 때 상당히 어려움이 있었습니다 🤷‍♀️. 유사한 작업을 수행할 수 있는 상용 솔루션이 Marine Traffic과 같이 있지만, 저는 오랜 시간 동안 찾을 수 없는 오픈 소스 대안을 찾고 있었습니다. 마침내 2022년 말에 SeaRoute 라이브러리가 Python을 위해 출시되었고(이전에는 Java만 지원되고 있었음), 그로 인해 제 삶이 훨씬 수월해졌습니다. 이 기사에서는 Dash 앱을 위한 대화형 지도 시각화물을 만드는 과정을 안내하겠습니다. Dash Leaflet 및 SeaRoute Python 라이브러리를 사용하여 해상 경로를 표시할 수 있도록 할 것입니다.\n\n# Dash, Dash Leaflet, SeaRoute에 대해 어떻게 생각하시나요?\n\nDash는 React.js를 기반으로 만들어진 강력한 Python 프레임워크로, Python의 모든 계산 능력을 통합하고 있습니다. Dash가 무엇이며 무엇을 할 수 있는지, 어떻게 첫 번째 Dash 앱을 만들고 실행할 수 있는지에 대한 간단한 소개는 이전에 작성한 포스트를 참조해 보세요. Dash에 새로 오신 분이라면, 먼저 이것을 읽어보는 것을 추천합니다...\n\n<div class=\"content-ad\"></div>\n\n이 게시물에서는 고대 해상 실크로드 경로를 예시로 사용하여 Dash Leaflet 라이브러리와 SeaRoute 라이브러리의 사용을 소개하겠습니다.\n\nDash Leaflet은 상호작용하는 Leaflet 스타일 지도를 Dash 앱에 통합할 수 있는 포꺠 갑을 제공하는 넓은 범위의 지도 시각화 Python 라이브러리입니다. Dash 생태계 내에서 Leaflet.js의 래퍼로, 마커, 다각형, 팝업, 레이어 등과 같은 다양한 기능을 갖춘 지도를 만들고 사용자 정의할 수 있는 구성 요소를 제공합니다.\n\nSeaRoute는 해상에서 점 간 경로를 계산하는 Python 라이브러리로, 예를 들어 휴스턴과 로테르담 항구 사이의 경로를 계산할 수 있습니다. Python에서 이를 처음부터 계산하려면 해양 지역을 나타내는 해양 형상 파일(예: 해상 국경)을 얻고 지도상에 그린 후 출발점과 도착점 사이의 땅정 경로를 계산하여 해당 해양 지역만 횡단하도록 제약을 설정해야 합니다. 이는 넉넉히 말해 매우 복잡한 작업인데, 각 나라마다 자체 데이터를 다른 형식과 소스로 제공하는 등, 통일되고 표준적인 데이터 소스가 아직 존재하지 않기 때문입니다. 시각화만을 위해 이러한 작업을 해야 한다는 것이 좀 과한 것 같죠. 그렇다면 아름다운 지도 시각화가 필요한 여성은 이번 생애에서 어떻게 해결해야 할까요😠? 다행히 2022년 말에 SeaRoute 라이브러리가 출시되며 시같에 경로를 쉽게 계산하여 시같화할 수 있는 문제를 해결했습니다. 아래 지도에서도 확인할 수 있습니다😇.\n\n따라서 이 게시물의 나머지 부분에서는:\n\n<div class=\"content-ad\"></div>\n\n- SeaRoute를 사용하여 바다 상의 두 지점 사이의 경로 좌표를 계산하세요.\n- Dash Leaflet을 사용하여 지도상에 경로를 시각화하세요.\n- 모든 것을 Dash 앱으로 묶어보세요.\n\n일단 시작해봐요! 🤸‍♀️️\n\n# 해상 실크로드에 대해서 어떻게 생각하세요?\n\n<div class=\"content-ad\"></div>\n\n해양 실크로드는 고대 시대에 아시아, 아프리카 및 유럽 대륙 간 다양한 문명을 연결한 중요한 해상 무역로였습니다. 이것은 더 넓고 잘 알려진 실크로드 네트워크의 연장선으로, 육지 및 해상 노선을 포함하며 동서양 간 무역, 문화 교류 및 아이디어 및 기술의 전파를 용이하게 했습니다.\n\n중국의 한나라 시대(기원전 206년 ~ 서기 220년)에 시작된 해양 실크로드는 통(618~907년)과 송(960~1279년) 시대에 절정에 이르렀습니다. 남중국해와 인도양을 건너는 중국 선원들은 동남아시아, 인도, 아라비아 반도, 동아프리카 등지의 상인들과 실크, 도자기, 차 등과 같은 상품을 거래했습니다. 그에 대한 보답으로 중국은 향신료, 귀금속, 보석, 이국적인 상품을 수입함으로써 문화와 경제를 발전시켰습니다. 해양 실크로드의 쇠퇴는 14세기경 즈음에 시작되어 해상 무역로가 변화하고 새로운 무역 경로가 나타남에 따라 17세기에는 전통적인 실크로드와 해양 실크로드의 경로가 대부분 사라지며 유럽의 지배력으로 새로운 세계 무역로들이 등장했습니다.\n\n해양 실크로드를 따라가는 몇 가지 대표적인 경로 (이후 이 게시물의 나머지 부분에서 지도로 시각화할 예정)는 다음과 같습니다:\n\n- Quanzhou ` Malacca ` Calicut ` Aden ` Alexandria\n- Guangzhou ` Manila ` Brunei ` Surabaya ` Jakarta ` Singapore\n- Hangzhou ` Ningbo ` Nagasaki ` Busan ` Hakata ` Osaka\n- Guangzhou ` Hanoi ` Da Nang ` Singapore ` Colombo ` Muscat\n- Xiamen ` Taiwan ` Okinawa ` Yokohama ` Kobe ` Nagasaki ` Busan\n\n<div class=\"content-ad\"></div>\n\n해양로 라이브러리는 여러 가지 흥미로운 계산을 제공합니다. 예를 들어, 루트의 길이나 주어진 속도로 여행하는 데 걸리는 시간을 계산할 수 있습니다. 이번 포스트에서는 중국 존크(해양 실크로드 시대에 널리 사용된 선박 종류)가 평균 5 노트의 속도로 항해했다고 가정해 봅시다.\n\n![image](/assets/img/2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries_1.png)\n\n# 대시 앱 구축\n\n## 환경 설정\n\n<div class=\"content-ad\"></div>\n\n먼저 모든 것에 앞서, 필요한 라이브러리가 설치되어 있는지 확인해야 합니다. 이러한 라이브러리는 Dash, Dash-Leaflet 및 SeaRoute이며, pip를 사용하여 쉽게 설치할 수 있습니다:\n\n```js\npip install dash dash-leaflet searoute\n```\n\n그런 다음, 다음과 같이 가져올 수 있습니다:\n\n```js\nimport dash\nfrom dash import dcc, html\nimport dash_leaflet as dl\nfrom dash.dependencies import Input, Output\nfrom searoute import SeaRoute\n```\n\n<div class=\"content-ad\"></div>\n\n다음으로, 간단히 Dash 앱의 빈 인스턴스를 초기화할 수 있습니다:\n\n```js\napp = dash.Dash(__name__)\n```\n\n일반적으로, Dash 앱은 두 가지 주요 구성 요소로 구성됩니다: 레이아웃(layout)과 콜백(callbacks). 레이아웃 구성 요소는 앱의 시각적 및 구조적 부분을 정의하며, 콜백 구성 요소는 앱의 상호 작용을 설명합니다. 그러나 앱의 레이아웃에 더 들어가기 전에 요구되는 데이터가 사용 가능한지 확인해야 합니다.\n\n## 데이터 가져오기\n\n<div class=\"content-ad\"></div>\n\n먼저, 해상 실크로드의 일부 지표적인 항구 및 해당 좌표, 간단한 설명을 담은 표를 작성했어요. 항구 좌표는 추정치이며 OpenStreetMap에서 가져온 것이며, 오픈 데이터베이스 라이선스(ODbL)를 따라 사용되었습니다.\n\n<img src=\"/assets/img/2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries_2.png\" />\n\n```js\nimport pandas as pd\n\n# 항구, 좌표 및 설명을 포함하는 표 작성\nports_data = {\n    '항구': ['아덴', '알렉산드리아', '브루나이', '부산', '칼리컷',\n            '콜롬보', '다낭', '광저우', '하카타', '항저우',\n             '하노이', '자카르타', '고베', '말라카', '마닐라',\n             '무스카트', '나가사키', '닝보', '오키나와', '오사카',\n             '전주', '싱가포르', '수라바야', '대만', '시안멘', '요코하마'],\n    '국가': ['예멘', '이집트', '브루나이', '대한민국', '인도',\n                '스리랑카', '베트남', '중국', '일본', '중국',\n                '베트남', '인도네시아', '일본', '말레이시아', '필리핀',\n                '오만', '일본', '중국', '일본', '일본',\n                '중국', '싱가폴', '인도네시아', '대만', '중국', '일본'],\n    '위도': [12.799, 31.2001, 4.5353, 35.1796, 11.2588,\n                 6.9271, 16.0544, 23.1291, 33.5904, 30.2741,\n                 21.0285, -6.2088, 34.6901, 2.1896, 14.5995,\n                 23.6102, 32.7467, 29.8683, 26.2041, 34.6937,\n                 24.8798, 1.3521, -7.2575, 23.6978, 24.4798, 35.4437],\n    '경도': [45.0289, 29.9187, 114.7277, 129.0756, 75.7804,\n                  79.8612, 108.2022, 113.2644, 130.4017, 120.1551,\n                  105.8542, 106.8456, 135.1955, 102.2501, 120.9842,\n                  58.5922, 129.8734, 121.544, 127.6476, 135.5023,\n                  118.5876, 103.8198, 112.7521, 120.9605, 118.0894, 139.638],\n    '설명': ['붉은해 상거래 경로의 중요한 중심지', '지중해 주요 항구, 유럽과의 연결', '향균판매의 주요 중지점, 이슬람 영향', '실크로드에 대한 한국의 관문', '번성한 무역 중심지, 향신료 무역의 중심',\n                    '인도양 무역로의 주요 항구', '잠바 왕조 시기 중요한 항구', '고대 중국 무역 항구, 산동이라 불림', '실크로드 무역에 중요한 일본의 항구', '대운하의 끝, 실크 생산 중심지',\n                    '베트남의 수도, 고대 무역 도시', '인도네시아의 수도, 자바의 주요 항구', '중요한 일본의 항구, 교토로 향하는 관문', '전략적인 해협, 무역의 십자로', '아시아에서 스페인 무역의 중심지',\n                    '중요한 아라비아 해상 무역 기지', '세계로 향하는 일본의 관문, 네덜란드 무역의 중심', '주요 해상 항구, 중국 무역에 필수', '동아시아 무역로의 중요한 경유지', '일본의 주요항구, 역사적 무역 중심지',\n                    '중국의 주요 항구, 주요 무역 중심지', '전략적인 해협, 주요 무역 기지', '자바의 중요한 항구, 인도네시아 무역에 중요', '해상 무역용 섬 중간지점', '중국의 역사적 항구, 후난으로가는 관문', '외국무역에 개방된 주요 일본의 항구']\n}\n\nports = pd.DataFrame(ports_data)\n```\n\n그 위에, 지도에서 시각화하고 싶은 일부 지표적인 경로(항구 순서)를 정의하고 그것을 DataFrame에 저장합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\r\nroute_1 = ['Quanzhou','Malacca','Calicut','Aden','Alexandria']\r\nroute_2 = ['Guangzhou','Manila','Brunei','Surabaya','Jakarta','Singapore']\r\nroute_3 = ['Hangzhou','Ningbo','Nagasaki','Busan','Hakata','Osaka']\r\nroute_4 = ['Guangzhou','Hanoi','Da Nang','Singapore','Colombo','Muscat']\r\nroute_5 = ['Xiamen','Taiwan','Okinawa','Yokohama','Kobe','Nagasaki','Busan']\r\n\r\nroutes = pd.DataFrame({\r\n    'Route': ['route_1', 'route_2', 'route_3', 'route_4', 'route_5'],\r\n    'Port_Sequence': [route_1, route_2, route_3, route_4, route_5]\r\n})\r\n```\r\n\r\n## 경로 계산\r\n\r\n필요한 계산을 수행하기 위해 일반적인 route_var 변수를 가정하고, 이 경로에 포함된 각 항구의 이름과 좌표를 DataFrame으로 구조화합니다. 보다 구체적으로, 이 코드는 주어진 경로의 각 항구를 반복하고 그들의 좌표 및 설명을 검색합니다.\r\n\r\n```js\r\nroute_rows = [] \r\n\r\nfor port in route_var: # 경로에 있는 항구를 반복하면서\r\n  port_name = port\r\n  lat = ports.loc[ports['Port'] == port, 'Latitude'].iloc[0]\r\n  lon = ports.loc[ports['Port'] == port, 'Longitude'].iloc[0]\r\n  row = {'Port': port_name, 'lat': lat, 'lon': lon}\r\n  route_rows.append(row)\r\n\r\nroute_df = pd.concat([pd.DataFrame(row, index=[0]) for row in route_rows], ignore_index=True)\r\n```\n\n<div class=\"content-ad\"></div>\n\n지도 시각화를 시작하려면 Dash-Leaflet 라이브러리의 dl.Marker(), dl.Tooltip 및 dl.LayerGroup() 구성 요소를 사용하여 포트를 마커로 시각화하기 위한 지도 객체를 쉽게 생성할 수 있습니다.\n\n```js\n    # 계산된 포트 마커에서 지도 객체 생성\n    markers = []\n    for i in range(len(route_df)):\n        # 각 포트 마커에 대한 툴팁 생성\n        tooltip = route_df.loc[i, 'Port'] + ', ' + ports.loc[ports['Port'] == route_df.loc[i, 'Port'], 'Description'].iloc[0]\n        markers.append(  # 마커 계산\n            dl.Marker(\n                position=(route_df.loc[i, 'lat'], route_df.loc[i, 'lon']),\n                children=[dl.Tooltip(tooltip)]\n            )\n        )\n    cluster = dl.LayerGroup(children=markers)\n```\n\n이 방법을 사용하면 선택한 경로의 각 포트에 대해 dl.Marker()를 사용하여 마커를 생성하고 dl.Tooltip()을 사용하여 툴팁을 만듭니다. 그런 다음 dl.LayerGroup()를 사용하여 이러한 마커를 단일 레이어 그룹으로 그룹화합니다. LayerGroup() 구성 요소는 여러 지도 요소(마커 등)를 단일 레이어로 그룹화하는 데 사용됩니다. 이를 통해 이러한 요소를 함께 관리하고 제어할 수 있습니다. 예를 들어, 사용자가 한 번의 동작으로 모든 마커를 표시하거나 숨길 수 있으며, 마커를 하나씩 선택하는 대신 모두 선택할 수 있습니다.\n\n바다에서의 경로 계산으로 넘어가면, 아래와 같이 SeaRoute 라이브러리를 사용하여 이를 달성할 수 있습니다:```\n\n<div class=\"content-ad\"></div>\n\n```js\r\n# 바다에서 경로 계산하기\nmarkers_line = []\nlength = 0\nduration_hours = 0\nfor i in range(0, len(route_df) - 1):\n    origin = [route_df.loc[i, 'lon'], route_df.loc[i, 'lat']]\n    destination = [route_df.loc[i+1, 'lon'], route_df.loc[i+1, 'lat']]\n    searoutes_coords = sr.searoute(origin, destination, append_orig_dest=True, speed_knot=2)\n    searoutes_coords_transposed = [[coord[1], coord[0]] for coord in searoutes_coords['geometry']['coordinates']]\n    markers_line += searoutes_coords_transposed\n   \n    length += searoutes_coords['properties']['length']\n    duration_hours += searoutes_coords['properties']['duration_hours']\nduration_days = duration_hours / 24\r\n```\n\n이전에 언급했듯이 SeaRoute 라이브러리를 사용하면 경로 거리와 항해 시간을 계산하는 것과 같은 추가 속성을 계산할 수 있습니다. 여기에서 속도가 sr.searoute() 함수에서 speed_knot = 5로 정의된 것을 확인하세요.\n\nSeaRoute로 맵 좌표를 계산한 후 dl.Polyline() 구성 요소를 사용하여 맵에 시각화할 수 있습니다. 또한 dl.PolylineDecorator() 구성 요소를 사용하여 선 방향을 나타내는 화살표를 추가할 수 있습니다. patterns 변수에서 간단한 화살표를 직접 정의합니다.\n\n```js\r\n# 계산된 바다 경로용 맵 객체 생성\nline = dl.Polyline(\n    positions=markers_line,\n    smoothFactor=1.0,\n    color='ForestGreen',\n    weight=1,\n    lineCap='round',\n    lineJoin='round'\n)\npatterns = [dict(offset='5%', repeat='30px', endOffset='10%', arrowHead=dict(pixelSize=8, polygon=False, pathOptions=dict(stroke=True, color='ForestGreen', weight=1, opacity=10, smoothFactor=1)))]\ndline = dl.PolylineDecorator(children=line, patterns=patterns)\r\n```\n\n<div class=\"content-ad\"></div>\n\n또한, 각 선택된 노선마다 지도의 중심과 영역을 다시 계산하는 것이 적절하다고 생각했습니다. 이렇게 하면 사용자가 선택한 각 노선마다 지도가 다시 초점을 맞춰서, 마커와 선이 적절하게 표시됩니다.\n\n```js\n# 경계 계산\nmin_lat = min(lat for lat, lon in markers_line) - 2\nmax_lat = max(lat for lat, lon in markers_line) + 2\nmin_lon = min(lon for lat, lon in markers_line) - 2\nmax_lon = max(lon for lat, lon in markers_line) + 2\nbounds = [[min_lat, min_lon], [max_lat, max_lon]]\n\n# 중심 계산\nx, y = zip(*markers_line)\ncentroid = [sum(x) / len(x), sum(y) / len(y)]\r\n```\n\n마지막으로, 이러한 요소들을 하나의 함수로 묶어 보겠습니다.\n\n```js\n# 노선 포트의 해상 경로 지도 마커 및 경로 계산 함수 정의\ndef get_route_line(route_var):\n    \n    route_rows = [] \n    for port in route_var: # 노선 내 포트를 반복\n        port_name = port\n        lat = ports.loc[ports['Port'] == port, 'Latitude'].iloc[0]\n        lon = ports.loc[ports['Port'] == port, 'Longitude'].iloc[0]\n        row = {'Port': port_name, 'lat': lat, 'lon': lon}\n        route_rows.append(row)\n   \n    route_df = pd.concat([pd.DataFrame(row, index=[0]) for row in route_rows], ignore_index=True)\n   \n    # 계산된 포트 마커에서 맵 개체 생성\n    markers = []\n    for i in range(len(route_df)):\n        # 각 포트 마커에 대한 툴팁 생성\n        tooltip = route_df.loc[i, 'Port'] + ', ' + ports.loc[ports['Port'] == route_df.loc[i, 'Port'], 'Description'].iloc[0]\n        markers.append(  # 마커 계산\n            dl.Marker(\n                position=(route_df.loc[i, 'lat'], route_df.loc[i, 'lon']),\n                children=[dl.Tooltip(tooltip)]\n            )\n        )\n    cluster = dl.LayerGroup(children=markers)\n   \n    # 해상 경로 계산\n    markers_line = []\n    length = 0\n    duration_hours = 0\n    for i in range(0, len(route_df) - 1):\n        origin = [route_df.loc[i, 'lon'], route_df.loc[i, 'lat']]\n        destination = [route_df.loc[i+1, 'lon'], route_df.loc[i+1, 'lat']]\n        searoutes_coords = sr.searoute(origin, destination, append_orig_dest=True, speed_knot=2)\n        searoutes_coords_transposed = [[coord[1], coord[0]] for coord in searoutes_coords['geometry']['coordinates']]\n        markers_line += searoutes_coords_transposed\n       \n        length += searoutes_coords['properties']['length']\n        duration_hours += searoutes_coords['properties']['duration_hours']\n    duration_days = duration_hours / 24\n\n    # 계산된 해상 경로를 위한 맵 개체 생성\n    line = dl.Polyline(\n        positions=markers_line,\n        smoothFactor=1.0,\n        color='ForestGreen',\n        weight=1,\n        lineCap='round',\n        lineJoin='round'\n    )\n    patterns = [dict(offset='5%', repeat='30px', endOffset='10%', arrowHead=dict(pixelSize=8, polygon=False, pathOptions=dict(stroke=True, color='ForestGreen', weight=1, opacity=10, smoothFactor=1)))]\n    dline = dl.PolylineDecorator(children=line, patterns=patterns)\n    \n    # 경계 계산\n    min_lat = min(lat for lat, lon in markers_line) - 2\n    max_lat = max(lat for lat, lon in markers_line) + 2\n    min_lon = min(lon for lat, lon in markers_line) - 2\n    max_lon = max(lon for lat, lon in markers_line) + 2\n    bounds = [[min_lat, min_lon], [max_lat, max_lon]]\n    \n    # 중심 계산\n    x, y = zip(*markers_line)\n    centroid = [sum(x) / len(x), sum(y) / len(y)]\n\n    return cluster, dline, centroid, bounds, duration_days\r\n```\n\n따라서, 모든 계산은 두 개의 함수로 처리됩니다: \n```\n\n<div class=\"content-ad\"></div>\n\n## 레이아웃 생성\n\nget_route_line() 함수를 정의한 후, 이제 앱의 레이아웃 컴포넌트를 구성할 차례입니다. 아래 이미지와 유사한 레이아웃을 만들려고 합니다:\n\n![이미지](/assets/img/2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries_3.png)\n\n구체적으로는 다음 사항을 통합하고 싶습니다:\n\n<div class=\"content-ad\"></div>\n\n- 루트 선택 컨테이너는 루트를 선택할 수있는 드롭다운 메뉴와 선택한 루트, 가정된 선박 속도, 그리고 예상 항해 기간과 같은 각 루트에 대한 정보를 표시합니다.\n- 선택한 루트의 항구 및 해당 해상 경로를 표시하는 지도 시각화가 있습니다.\n\n드롭다운 패널은 다음과 같이 정의할 수 있습니다:\n\n```js\n# 드롭다운 및 루트 정보를 위한 왼쪽 패널\n    html.Div([\n        html.H1('고대 해상 실크로드'),\n        html.Div([\n            dcc.Dropdown(\n                id='route_dropdown',\n                options=[{'label': route, 'value': route} for route in routes['Route']],\n                placeholder='루트 선택'\n            )\n        ], style={'display': 'block', 'height': '30%', 'justify-content': 'center', 'color': 'gray'}),\n        html.Div(id='route_info', style={'height': '100%'})\n    ], style={'display': 'inline-block', 'height': '100%', 'width': '15%', 'background-color': '#17408B', 'color': 'white', 'padding': '2%', 'position': 'relative'}),\n```\n\n더 구체적으로, 드롭다운 메뉴는 이전에 정의한 routes DataFrame에 의해 채워집니다. 또한, 루트 정보 패널은 초기에 비어 있고 드롭다운 메뉴에서 루트를 선택하면 콜백을 통해 채워질 것입니다.\n\n<div class=\"content-ad\"></div>\n\n지도 시각화에 관한 내용은 다음과 같이 정의할 수 있습니다:\n\n```js\n# 지도 우측 패널\n    html.Div([\n        dl.Map(children=dl.LayersControl(\n            [\n                dl.BaseLayer(dl.TileLayer(url='https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png'), id='map_base', checked=True, name='기본 맵')\n            ] +\n            [\n                dl.Overlay(children=[], id='route_lines', checked=True, name='경로 방향'),\n                dl.Overlay(children=[], id='route_markers', checked=True, name='항구')\n            ]\n        ), id='routess_map', zoom=3)\n    ], style={'display': 'inline-block', 'height': '100%', 'width': '85%', 'background-color': 'white', 'box-sizing': 'border-box'})\n]\n```\n\ndl.Map() 구성 요소가 dl.BaseLayer() 구성 요소를 통해 선택한 기본 지도를 포함하고 있음에 주목하세요. 또한 dl.Overlay()로 정의된 다른 지도 객체도 포함됩니다. 여기서도 dl.Overlay()는 초기에 비어 있으며, 이전에 정의한 get_route_line() 함수를 사용하여 드롭다운 메뉴에서 경로를 선택하면 내용이 채워집니다.\n\n마지막으로 드롭다운 메뉴와 지도 컨테이너를 모두 부모 컨테이너에 포함시켜 앱의 레이아웃 구성 요소로 할당할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n# Dash 앱 초기화\napp = Dash(__name__)\n\n# 레이아웃 정의\napp.layout = html.Div([\n    # 드롭다운 및 경로 정보용 왼쪽 패널\n    html.Div([\n        html.H1('고대 해상 실크로드'),\n        html.Div([\n            dcc.Dropdown(\n                id='route_dropdown',\n                options=[{'label': route, 'value': route} for route in routes['Route']],\n                placeholder='경로를 선택하세요'\n            )\n        ], style={'display': 'block', 'height': '30%', 'justify-content': 'center', 'color': 'gray'}),\n        html.Div(id='route_info', style={'height': '100%'})\n    ], style={'display': 'inline-block', 'height': '100%', 'width': '15%', 'background-color': '#17408B', 'color': 'white', 'padding': '2%', 'position': 'relative'}),\n    \n    # 지도용 오른쪽 패널\n    html.Div([\n        dl.Map(children=dl.LayersControl(\n            [\n                dl.BaseLayer(dl.TileLayer(url='https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png'), id='map_base', checked=True, name='기본 지도')\n            ] +\n            [\n                dl.Overlay(children=[], id='route_lines', checked=True, name='경로 방향'),\n                dl.Overlay(children=[], id='route_markers', checked=True, name='항구')\n            ]\n        ), id='events_map', zoom=3)\n    ], style={'display': 'inline-block', 'height': '100%', 'width': '85%', 'background-color': 'white', 'box-sizing': 'border-box'})\n], style={'display': 'flex', 'height': '100vh', 'width': '100vw', 'position': 'fixed', 'margin': '-8px', 'justify-content': 'center', 'boxSizing': 'border-box'})\n```\n\n## 콜백 설정\n\nDash 앱의 레이아웃을 설정했으니, 다음 단계는 앱의 상호작용성을 정의하는 것입니다. 드롭다운 메뉴에서 경로를 선택하면 지도에 해당 마커 및 라인이 나타나며, 해당 경로 정보도 표시됩니다. 다음과 같이 하나의 콜백 함수로 이를 구현할 수 있습니다:\n\n```js\n@app.callback(\n    Output('route_markers', 'children'),\n    Output('route_lines', 'children'), \n    Output('routes_map', 'center'), \n    Output('routes_map', 'bounds'),\n    Output('route_info', 'children'),\n    Input('route_dropdown', 'value')\n)\ndef update_map_lines(selected_route):\n    if selected_route is None:\n        bounds = [[-50, -80], [50, 80]]\n        centroid = [0, 0]\n        return [], [], centroid, bounds, []\n    else:\n        route_var = routes.loc[routes['Route'] == selected_route, 'Port_Sequence'].iloc[0]\n        cluster, dline, centroid, bounds, duration_days, length = get_route_line(route_var)\n        \n        route_name = selected_route.replace('_', ' ').title()\n        route_info = [\n            html.P([html.B(\"경로: \"), route_name]),\n            html.P([html.B(\"거리: \"), f\"{length:.0f} km\"]),\n            html.P([html.B(\"속도: \"), \"2 knots\"]),\n            html.P([html.B(\"소요 시간: \"), f\"{duration_days:.0f} days\"]),           \n        ]\n        \n        return cluster, [dline], centroid, bounds, route_info\n```\n\n<div class=\"content-ad\"></div>\n\n이 콜백은 이전에 만들었던 get_route_line() 함수를 사용하여 마커와 라인 지도 객체를 생성하고, 맵의 중심과 경계를 다시 계산하며 표시할 경로 정보를 계산합니다.\n\n## 앱 테스트\n\n레이아웃과 콜백 구성 요소를 정의한 후에, 우리의 앱은 준비가 되어 있고 다음 코드를 작성하여 실행할 수 있습니다:\n\n```js\r\nif __name__ == '__main__':\n    app.run_server(debug=True)\r\n```\n\n<div class=\"content-ad\"></div>\n\n그러면 전체 앱 파일을 실행할 수 있습니다. 모든 것이 올바르게 완료되었다면 이와 유사한 결과가 나올 것입니다:\n\n![image](/assets/img/2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries_4.png)\n\n✨그리고 와라✨\n\nDash 앱은 로컬호스트 서버에서 실행되며 표시된 URL을 통해 웹 브라우저에서 액세스할 수 있습니다. 이렇게 하면 앱의 완전히 작동하는 인스턴스를 볼 수 있고 디버깅할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 내 생각 속으로\n\n데이터 분석과 시각화에서 Dash와 같은 사용자 정의 보고 도구가 유연성과 사용 편의성으로 인해 인기를 얻고 있습니다. Power BI나 Tableau와 같은 셀프 서비스 도구와 달리 미리 구축된 시각화 옵션을 많이 제공하는 Dash는 보고서 디자인과 기능에 대해 완전한 제어를 제공합니다. 이를 통해 특정 사용자 요구 사항을 충족하기 위해 완전히 사용자 정의된 보고서와 시각화를 작성할 수 있습니다.\n\n예를 들어, 이 게시물에서 보이는 지도 시각화는 사용자 지정 데이터 시각화 도구를 사용하지 않으면 상당히 어렵거나 불가능할 수 있습니다. 우리는 Tableau와 같은 도구를 사용한다면 루트 좌표를 따로 계산하고 저장한 다음 지도 위에 시각화해야 합니다. 심지어 방향성 있는 선을 생성하는 것조차 꽤 번거로울 것입니다. 이러한 수준의 사용자 정의는 데이터 전문가들에게 Dash가 점점 선호되는 이유를 강조합니다.\n\n✨읽어 주셔서 감사합니다!✨\n\n<div class=\"content-ad\"></div>\n\n이 게시물을 즐겼나요? 함께 친구가 되어요!\n\n💌 저와 함께 Medium이나 LinkedIn에서 만나요!\n\n💼 Upwork에서 저와 함께 일해보세요!","ogImage":{"url":"/assets/img/2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries_0.png"},"coverImage":"/assets/img/2024-05-23-FromDatatoDashboardVisualizingtheAncientMaritimeSilkRoadwithDashLeafletandSeaRoutelibraries_0.png","tag":["Tech"],"readingTime":20},{"title":"윈도우 프로세스 여행 - sppsvcexe 마이크로소프트 소프트웨어 보호 플랫폼 서비스","description":"","date":"2024-05-23 15:28","slug":"2024-05-23-TheWindowsProcessJourneysppsvcexeMicrosoftSoftwareProtectionPlatformService","content":"\n\n\"sppsvc.exe\" (Microsoft Software Protection Platform Service)은 \"%windir%\\System32\\sppsvc.exe\"에 위치한 PE 이진 파일입니다. Windows의 64비트 버전에서는 \"cmd.exe\"와 같은 다른 이진 파일과 달리 실행 파일의 32비트 버전이 없습니다 (https://medium.com/@boutnaru/the-windows-process-journey-cmd-exe-windows-command-processor-501be17ba81b). 또한, \"sppsvc.exe\" 이진 파일은 Microsoft에 의해 디지털 서명되었습니다.\n\n전반적으로 \"sppsvc.exe\"는 \"Software Protection\" 서비스 (aka sppsvc)의 주요 이미지입니다. 서비스 설명에는 다음과 같이 명시되어 있습니다: \"Windows 및 Windows 애플리케이션의 디지털 라이선스 다운로드, 설치 및 강제 적용을 가능하게 합니다. 서비스가 비활성화되면 운영 체제 및 라이센스가 부여된 애플리케이션이 알림 모드에서 실행될 수 있습니다. 소프트웨어 보호 서비스를 비활성화하지 않는 것이 강력히 권장되며”. 이 서비스는 \"Network Service\" (https://medium.com/@boutnaru/the-windows-security-jorueny-network-service-nt-authority-network-service-e8706688e383) 사용자의 권한/권한으로 실행됩니다 — 아래 스크린 샷에서 확인할 수 있습니다.\n\n따라서, \"sppsvc.exe\"가 다음과 같은 기능을 수행한다고 말할 수 있습니다. Windows 운영 체제가 정품이고 제대로 활성화되었는지를 보장합니다. 주기적으로 Windows 라이선스가 여전히 유효한지 (그리고 취소되지 않았는지) 확인합니다. 또한, 새 Windows 사본을 설치하거나 컴퓨터에 중요한 하드웨어 변경을 수행할 때 활성화 프로세스를 처리합니다. 또한, 시스템의 활성 상태에 대한 익명 데이터를 Microsoft에 수집하고 전송할 수도 있다는 것을 알아야 합니다 (https://malwaretips.com/blogs/microsoft-software-protection-platform-service/).\n\n마지막으로, 활성화 토큰을 보관하는 \"“%windir%\\System32\\spp\\” 디렉토리가 있습니다 (https://community.spiceworks.com/t/windows-10-repeatedly-deactivates/681310). 이 디렉토리에서 파일을 백업하여 Office와 같은 다른 소프트웨어 제공을 다시 활성화할 수 있습니다 (https://community.citrix.com/forums/topic/230472-layered-image-office-2016-will-not-activate-on-first-boot/).\n\n<div class=\"content-ad\"></div>\n\n다음 글에서 뵙겠습니다 ;-) 트위터에서 저를 팔로우할 수 있어요 — @boutnaru (https://twitter.com/boutnaru). 또한, 저의 다른 글들은 미디엄에서 읽을 수 있어요 — https://medium.com/@boutnaru. 무료 eBook은 https://TheLearningJourneyEbooks.com에서 찾을 수 있어요.\n\n![image](/assets/img/2024-05-23-TheWindowsProcessJourneysppsvcexeMicrosoftSoftwareProtectionPlatformService_0.png)","ogImage":{"url":"/assets/img/2024-05-23-TheWindowsProcessJourneysppsvcexeMicrosoftSoftwareProtectionPlatformService_0.png"},"coverImage":"/assets/img/2024-05-23-TheWindowsProcessJourneysppsvcexeMicrosoftSoftwareProtectionPlatformService_0.png","tag":["Tech"],"readingTime":2},{"title":"윈도우에서의 포트 포워딩 및 설정 방법들","description":"","date":"2024-05-23 15:26","slug":"2024-05-23-PortForwardinginWindowsandWaystoSetitUp","content":"\n\nWindows에서 원격 액세스 또는 서버 호스팅을 위해 포트 포워딩 설정하는 방법을 배워보세요. 지금 당신의 장치에서 이를 활성화하고 구성하는 방법에 대한 가이드를 따르세요.\n\n![포트 포워딩 이미지](/assets/img/2024-05-23-PortForwardinginWindowsandWaystoSetitUp_0.png)\n\n본문에서 읽을 내용 목록:\n\n1. Windows에서의 포트 포워딩이란?\n2. 포트 포워딩이 작동하는 방식은?\n3. 포트 포워딩에 대한 명령 프롬프트 사용\n4. Windows 방화벽을 위한 포트 포워딩 구성\n5. Hyper-V 가상 스위치에서 NAT 규칙을 사용한 포트 포워딩\n6. Windows에서 Netsh 포트 포워딩 규칙 관리\n7. 결론\n\n<div class=\"content-ad\"></div>\n\n포트 포워딩은 네트워크의 보안 및 기능성을 제고하는 데 사용되는 기본적인 기술 중 하나입니다. 이는 네트워크 라우터를 구성하여 특정 포트로부터 오는 들어오는 트래픽을 네트워크 내의 지정된 장치로 전달하는 과정을 말합니다. Windows 환경에서 포트 포워딩을 설정하는 것은 기술적 지식이 제한된 사람들에게는 도전적일 수 있습니다. 하지만 올바른 지식과 도구를 활용하면 누구나 빠르게 포트 포워딩을 설정할 수 있습니다. 이 가이드에서는 Windows에서 포트 포워딩을 설정하는 단계와 그에 필요한 도구 및 기술에 대해 살펴보겠습니다.\n\n# Windows에서 포트 포워딩이란?\n\n포트 포워딩은 컴퓨터 및 기타 네트워크 장치가 인터넷과 통신할 수 있게 해주는 필수적인 네트워킹 기술입니다. 이는 로컬 네트워크 외부에서 인터넷에 접근해야 하는 장치, 서비스 또는 프로그램에 필요한 과정입니다. 포트 포워딩은 네트워크 외부의 특정 포트에서 네트워크 내의 특정 포트로 네트워크 트래픽을 라우팅함으로써 작동합니다. 기본적으로, 네트워크 라우터는 인터넷으로부터 들어오는 트래픽을 차단하도록 설계되어 있어 서버, 게임 콘솔 및 기타 네트워크 장치에서 문제가 발생할 수 있습니다.\n\n사용자가 네트워크의 장치에 연결을 시작하면 라우터가 요청을 받아 해당 장치로 전달합니다. 그러나 포트 포워딩이 없으면 라우터는 어떤 장치가 트래픽을 받아야 하는지 알 수 없어 연결이 실패합니다. 따라서 포트 포워딩은 특정 서비스, 장치 및 애플리케이션이 올바르게 작동하고 로컬 네트워크 외부의 인터넷에 접근할 수 있도록 하는 데 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n# 포트 포워딩은 어떻게 작동하나요?\n\n포트 포워딩은 네트워크 외부의 특정 포트로부터 들어오는 트래픽을 네트워크 내의 특정 장치나 서비스로 리디렉션하는 방식으로 작동합니다. 이 과정은 라우터를 구성하여 네트워크 내의 특정 장치나 서비스로 특정 포트를 포워딩하는 것을 포함합니다. 외부 네트워크에서 연결 요청이 발생하면, 라우터가 해당 요청을 수신하고 요청에서 사용된 특정 포트 번호를 확인합니다. 그런 다음, 라우터는 포트 포워딩 규칙을 확인하여 요청을 수신할 장치나 서비스를 결정합니다. 규칙이 발견되면, 라우터는 포트 포워딩 구성에 따라 들어오는 트래픽을 지정된 장치나 서비스로 전달합니다.\n\n포트 포워딩은 복잡할 수 있지만, 적절한 지식과 도구를 활용하면 빠르고 쉽게 수행할 수 있습니다. 라우터에서 포트 포워딩을 구성하려면 라우터의 구성 인터페이스에 대한 지식, 각 서비스에 필요한 특정 포트 번호, 그리고 인터넷을 통해 접근해야 하는 네트워크 내 장치의 IP 주소에 대한 지식이 필요합니다.\n\n# 명령 프롬프트를 사용한 포트 포워딩\n\n<div class=\"content-ad\"></div>\n\n윈도우에서 포트 포워딩을 위해 명령 프롬프트를 사용하는 방법에 대한 단계별 안내서입니다:\n\n## 단계 1: 명령 프롬프트 열기\n\n시작 메뉴를 클릭하고 검색 필드에 “cmd”를 입력한 후 Enter 키를 눌러주세요. 그러면 명령 프롬프트 창이 열립니다.\n\n## 단계 2: 장치의 IP 주소 얻기\n\n<div class=\"content-ad\"></div>\n\n명령 프롬프트 창에 \"ipconfig\"을 입력하고 Enter 키를 누르세요. 네트워크 어댑터 아래의 \"IPv4 주소\"를 찾아 IP 주소를 메모해 두세요.\n\n## 단계 3: 포트 포워딩 규칙 생성\n\n다음 명령을 입력하고 Enter 키를 누르세요:\n\n\nnetsh interface portproxy add v4tov4 listenport=8080 listenaddress=192.168.1.10 connectport=8080 connectaddress=192.168.1.10\n\n\n<div class=\"content-ad\"></div>\n\n## 단계 4: 포트 포워딩 규칙 확인하기\n\n다음 명령을 입력하고 Enter 키를 눌러주세요:\n\n\nnetsh interface portproxy show all\n\n\n이 명령은 현재 네트워크에서 활성화된 모든 포트 포워딩 규칙의 목록을 표시합니다. 만들었던 규칙이 나열되어 있는지 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n## 단계 5: 명령 프롬프트 닫기\n\n\"exit\"을 입력하고 Enter 키를 눌러 명령 프롬프트 창을 닫습니다.\n\n그것이죠! 이제 Windows에서 포트 포워딩을 위해 명령 프롬프트를 성공적으로 사용했습니다.\n\n# 포트 포워딩을 위한 Windows 방화벽 구성\n\n<div class=\"content-ad\"></div>\n\n다음은 포트 포워딩을 위한 Windows 방화벽 구성 방법에 대한 단계별 가이드입니다:\n\n## 단계 1: Windows 방화벽 설정 열기\n\n시작 메뉴를 클릭하고 검색란에 \"방화벽\"을 입력한 후 \"Windows Defender 방화벽\"을 선택합니다.\n\n## 단계 2: \"고급 설정\"을 클릭하세요\n\n<div class=\"content-ad\"></div>\n\n치트 시트 태그를 마크다운 형식으로 수정해주세요.\n\n<div class=\"content-ad\"></div>\n\n\"Port\"을 선택하고 \"다음\"을 클릭하세요.\n\n## 단계 5: 포트 구성\n\n구성해야 할 포트 유형을 선택하세요: TCP 또는 UDP. \"구체적 로컬 포트\" 필드에 전달할 포트 번호를 입력하세요.\n\n## 단계 6: 작업 선택\n\n<div class=\"content-ad\"></div>\n\n“연결 허용”을 선택하고 “다음”을 클릭하세요.\n\n## 단계 7: 프로필 선택\n\n규칙을 적용할 프로필을 선택하고(Domain, Private, Public) “다음”을 클릭하세요.\n\n## 단계 8: 규칙의 이름 지정 및 저장\n\n<div class=\"content-ad\"></div>\n\n**단계 9: 규칙 확인**\n\n규칙에 이름을 지정하고 \"완료\"를 클릭하세요.\n\n# Hyper-V 가상 스위치에서 포트 포워딩을 위한 NAT 규칙 사용하기\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! Hyper-V Virtual Switch에서 NAT 규칙으로 포트 포워딩하는 방법에 대한 단계별 안내서입니다:\n\n## 단계 1: Hyper-V 매니저 열기\n\n시작 메뉴를 클릭하고 검색 필드에 \"Hyper-V 매니저\"를 입력한 후 결과에서 \"Hyper-V 매니저\"를 선택합니다.\n\n## 단계 2: 가상 스위치 생성\n\n<div class=\"content-ad\"></div>\n\n하이퍼-V 관리자 창의 오른쪽 사이드바에서 \"가상 스위치 관리자\"를 클릭하세요. \"새 가상 네트워크 스위치\"를 클릭하고 가상 스위치 유형으로 \"내부\" 또는 \"개인\"을 선택하세요.\n\n## 단계 3: 가상 스위치 구성\n\n가상 스위치에 이름을 지어 네트워크 어댑터 설정을 구성하세요. \"관리 운영 체제가이 네트워크 어댑터를 공유하도록 허용\" 옵션이 선택 해제되어 있는지 확인하세요.\n\n## 단계 4: 새 가상 머신을 만들거나 기존 머신을 선택하세요\n\n<div class=\"content-ad\"></div>\n\n하이퍼-V 관리자 창에서 가상 머신을 마우스 오른쪽 단추로 클릭하고 \"설정\"을 선택하세요.\n\n## 단계 5: 네트워크 어댑터 추가\n\n\"Add Hardware\"를 클릭하고 \"네트워크 어댑터\"를 선택하여 가상 머신에 네트워크 어댑터를 추가하세요.\n\n## 단계 6: 가상 스위치에 연결\n\n<div class=\"content-ad\"></div>\n\n### 단계 7: NAT 서브 스위치 활성화\n\nHyper-V 관리자 창에서 단계 2에서 생성한 가상 스위치를 마우스 오른쪽 버튼으로 클릭하고 \"속성\"을 선택합니다. \"NAT 활성화\" 옵션을 선택하고 \"OK\"를 클릭합니다.\n\n### 단계 8: NAT 규칙 생성\n\n<div class=\"content-ad\"></div>\n\n가상 머신에서 \"Windows 키 + R\"을 눌러 명령 프롬프트를 열고, 실행 대화상자에 \"cmd\"를 입력하여 실행하세요. 다음 명령어를 입력하여 NAT 규칙을 생성하세요:\n\n```plaintext\nnetsh interface portproxy add v4tov4 listenport=80 listenaddress=0.0.0.0 connectport=8080 connectaddress=192.168.1.10\n```\n\n포워딩할 포트 번호로 \"80\"을, 포트를 전달할 장치의 IP 주소로 \"192.168.1.10\"을 대체하세요.\n\n## 단계 9: NAT 규칙 확인\n\n<div class=\"content-ad\"></div>\n\n다음 명령을 입력하여 NAT 규칙을 확인하세요:\n\n\nnetsh interface portproxy show all\n\n\n모든 NAT 규칙을 나열해줄 것입니다.\n\n# 윈도우에서 Netsh 포트 포워딩 규칙 관리\n\n<div class=\"content-ad\"></div>\n\n윈도우에서 Netsh 포트 포워딩 규칙을 관리하는 단계별 가이드입니다:\n\n## 단계 1: 명령 프롬프트 열기\n\n시작 메뉴를 클릭하고 검색 필드에 \"cmd\"를 입력한 다음 \"명령 프롬프트\"를 선택하세요.\n\n## 단계 2: 기존 포트 포워딩 규칙 확인\n\n<div class=\"content-ad\"></div>\n\n\"netsh interface portproxy show all\"을 입력하고 Enter 키를 누르세요. 이렇게 하면 현재 모든 포트 포워딩 규칙 목록이 표시됩니다.\n\n## 단계 3: 포트 포워딩 규칙 추가\n\n새 포트 포워딩 규칙을 추가하려면 다음을 입력하세요:\n\n\"netsh interface portproxy add v4tov4 listenport= listenaddress= connectport= connectaddress=\"\n\n<div class=\"content-ad\"></div>\n\n## 단계 4: 포트 포워딩 규칙 삭제\n\n기존의 포트 포워딩 규칙을 삭제하려면 다음을 입력하세요:\n\n`netsh interface portproxy delete v4tov4 listenport= listenaddress=`\n\n## 단계 5: 기존의 포트 포워딩 규칙 수정\n\n<div class=\"content-ad\"></div>\n\n기존 포트 포워딩 규칙을 수정하려면 해당 규칙을 삭제하고 원하는 변경 사항이 적용된 새로운 규칙을 추가하면 됩니다.\n\n## 단계 6: 포트 포워딩 규칙 비활성화\n\n기존 포트 포워딩 규칙을 비활성화하려면 다음을 입력하세요:\n\n“netsh interface portproxy delete v4tov4 listenport= listenaddress=”\n\n<div class=\"content-ad\"></div>\n\n## 단계 7: 비활성화된 포트 포워딩 규칙 활성화\n\n비활성화된 포트 포워딩 규칙을 활성화하려면 다음을 입력하여 규칙을 다시 추가하세요:\n\n“netsh interface portproxy add v4tov4 listenport= listenaddress= connectport= connectaddress=”\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n- 포트 포워딩은 네트워킹 기술로, 방화벽이나 라우터를 통해 공용 네트워크에서 사설 네트워크로 트래픽을 전달하는 것을 가능하게 합니다. 이 기술을 사용하면 가정 네트워크에 원격으로 접속하여 서버를 호스팅할 수 있습니다.\n- 포트 포워딩은 공용 IP 주소를 각 사설 네트워크 장치에 할당하여, 방화벽에서 차단되는 대신 특정 장치로 들어오는 트래픽을 직접 전달합니다.\n- Windows 운영 체제에는 포트 포워딩 설정을 구성할 수 있는 내장 도구가 포함되어 있습니다. Windows 방화벽과 인터넷 연결 공유(ICS) 기능 등이 이에 해당합니다. 이러한 도구를 사용하면 포트 포워딩 및 수신 트래픽을 받아들일 장치나 응용 프로그램을 명시하는 규칙을 만들 수 있습니다.\n\n#Price를 위한 더 많은 도구가 있습니다\n\nhttps://t.me/redfishiaven\n\n#업데이트 #튜토리얼 #리아뉴스 #소프트웨어 #하드웨어 #기술 #돈 #수익 #IPMC #사랑 #이벤트 #컴퓨팅 #컴퓨터 #정보기술 #학습 #인공지능 #redfishiaven #서버 #딥웹 #다크웹 #비트코인\n\n<div class=\"content-ad\"></div>\n\n구글 맵스에서 REDFISH IA VEN (https://goo.gl/maps/LVKkEYNN2LTe9C34A)을 확인해보세요.\n\nhttps://www.youtube.com/channel/UC6k_cFigPCSEtRyALo1D-tA\n\n새로운 소프트웨어에 대한 최초 정보를 받아보세요! #software","ogImage":{"url":"/assets/img/2024-05-23-PortForwardinginWindowsandWaystoSetitUp_0.png"},"coverImage":"/assets/img/2024-05-23-PortForwardinginWindowsandWaystoSetitUp_0.png","tag":["Tech"],"readingTime":7},{"title":"윈도우 서버 2022에 KB5034439을 설치하려고 할 때 발생하는 0x80070643 오류 해결 방법","description":"","date":"2024-05-23 15:25","slug":"2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022","content":"\n안녕하세요, 지난주 발생한 문제에 대해 이야기하려고 해요.\n\nWindows Server 2022에서 Windows 업데이트를 확인했을 때 다음과 같은 오류가 있었어요:\n\n![에러 이미지](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_0.png)\n\n그리고 KB5034439를 설치하는 동안 오류가 발생했음을 확인했는데, 해결해야 할 여러 제안이 있었지만 문제를 해결하지 못했어요.\n\n<div class=\"content-ad\"></div>\n\n그리고 마침내 그 문제를 해결할 수 있는 올바른 참조를 찾았어요. 이제 아래 단계를 따라주세요.\n\n# 복구 파티션을 수동으로 크기 조정하기\n\n- 관리자 권한으로 명령 프롬프트 창(cmd)을 엽니다.\n\n![이미지](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_1.png)\n\n<div class=\"content-ad\"></div>\n\n2. WinRE가 설치된 경우, WinRE 디렉토리 경로가 있는 \"Windows RE 위치\"가 있어야 합니다. WinRE 상태를 확인하려면 reagentc /info를 실행하세요. 예시: \"Windows RE 위치:\n\n\\\\?\\GLOBALROOT\\device\\harddisk0\\partition4\\Recovery\\WindowsRE\n\n![이미지](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_2.png)\n\n3. WinRE 비활성화를 위해 reagentc /disable를 실행하세요\"\n\n<div class=\"content-ad\"></div>\n\n\n![Error Screenshot](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_3.png)\n\n4. Shrink the OS partition and prepare the disk for a new recovery partition.\na. To shrink the OS, run diskpart\n\n![Error Screenshot](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_4.png)\n\nb. Run list disk\n\n\n<div class=\"content-ad\"></div>\n\n\n![Error message](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_5.png)\n\nc. To select the OS disk, run `sel disk OS disk index`. This should be the same disk index as WinRE.\n\n![Error message](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_6.png)\n\nd. To check the partition under the OS disk and find the OS partition, run `list part`\n\n\n<div class=\"content-ad\"></div>\n\n\n![Error Image 1](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_7.png)\n\ne. To select the OS partition, run `sel part OS partition index`\n\n![Error Image 2](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_8.png)\n\nf. Run `shrink desired=250 minimum=250`\n\n\n<div class=\"content-ad\"></div>\n\n\n![Error Screenshot 9](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_9.png)\n\ng. To select the WinRE partition, run `sel part WinRE partition index`\n\n![Error Screenshot 10](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_10.png)\n\nh. To delete the WinRE partition, run `delete partition override`\n\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_11.png)\n\n5. 새 복구 파티션을 생성합니다.\n\na. 먼저, 디스크 파티션 스타일이 GUID Partition Table (GPT) 또는 Master Boot Record (MBR)인지 확인합니다. 이를 확인하려면 list disk를 실행합니다. \"Gpt\" 열에 별표(*)가 있는지 확인합니다. 별표(*)가 있는 경우 드라이브가 GPT이고, 그렇지 않으면 MBR입니다.\n\n![이미지](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_12.png)\n\n\n<div class=\"content-ad\"></div>\n\n1. GPT 디스크인 경우, create partition primary id=de94bba4-06d1-4d40-a16a-bfd50179d6ac 명령을 실행한 다음 gpt attributes =0x8000000000000001 명령을 실행하세요.\n\n![image](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_13.png)\n\n2. MBR 디스크인 경우, create partition primary id=27 명령을 실행하세요.\n\n3. 파티션을 포맷하려면, format quick fs=ntfs label=\"Windows RE tools\" 명령을 실행하세요.\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_14.png\" />\n\n6. To confirm that the WinRE partition is created, run `list vol`\n\n<img src=\"/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_15.png\" />\n\n7. To exit from diskpart, run `exit`\n\n\n<div class=\"content-ad\"></div>\n\n\n![Error Image 1](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_16.png)\n\n8. To re-enable WinRE, run `reagentc /enable`\n\n![Error Image 2](/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_17.png)\n\n9. To confirm where WinRE is installed, run `reagentc /info`\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_18.png\" />\n\n알겠어요, 프로세스가 완료되었습니다. 이제 Windows 업데이트를 다시 실행하고 성공했는지 확인해보세요.\n\n<img src=\"/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_19.png\" />\n\n이게 도움이 되기를 바라며, 행운을 빕니다.\n\n<div class=\"content-ad\"></div>\n\n참고문헌:\n","ogImage":{"url":"/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_0.png"},"coverImage":"/assets/img/2024-05-23-Error0x80070643wheninstallingKB5034439onWindowsServer2022_0.png","tag":["Tech"],"readingTime":5}],"page":"9","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}