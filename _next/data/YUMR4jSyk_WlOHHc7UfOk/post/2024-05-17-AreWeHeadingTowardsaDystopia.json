{"pageProps":{"post":{"title":"지금 우리가 디스토피아로 향하고 있을까요","description":"","date":"2024-05-17 20:18","slug":"2024-05-17-AreWeHeadingTowardsaDystopia","content":"\n<img src=\"/assets/img/2024-05-17-AreWeHeadingTowardsaDystopia_0.png\" />\n\n이틀 전, 2024 Google I/O 컨퍼런스에서 Google은 새로운 도구인 Illuminate를 선보였어. 이 AI 도구는 학술 논문을 입력으로 받아들여 인간과 구별할 수 없는 실제 음성과 함께 오디오 토론을 생성할 수 있어. 이것은 음성 AI의 발전을 보여주는 한 예일 뿐이야.\n\nAI와의 커뮤니케이션이 더 자연스럽고 인간적으로 변하면서 AI와 인간을 구분하기가 거의 불가능해지고 있어. AI 전문가로서 저는 미래에 대해 궁금하면서 동시에 걱정스러워해. 곧, AI 챗봇이 우릴 쓰기만 하는 것이 아니라 우리와 대화를 나눌 거야. 미래에 전화 상대가 우리가 생각하는 사람인지 아니면 AI 복제물인지 어떻게 구분할 수 있을까?\n\n중국에서는 일부 TV 프로그램에서 진행자의 클론을 만들어 휴가 중에 대신하고 있어. 두 달 전 우크라이나 인플루언서가 자신의 클론이 중국에 러시아 제품을 판다는 것을 보고 신고했어. 다음으로 어떤 수준이 있을까? 우리 자신의 클론을 만들어 번거로운 전화를 처리하게 하거나, 비서 역할을 수행하게 하거나, 심지어는 면접까지 진행하게 할 수 있을까? 우리의 상담사가 ChatGPT의 지식, pi.ai의 공감능력, 그리고 Google의 실제 음성 생성 능력을 갖춘 AI 에이전트가 될까?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n왜 AI를 상담사로 선택해야 할까요? 왜냐하면 AI는 항상 접근 가능하며, 낮과 밤을 가리지 않고 언제든지 이야기할 수 있습니다. 우리의 걱정에 대해 최적의 조언을 받을 수 있으며, 시간당이 아닌 토큰 단위로 과금되어 가장 합리적인 가격으로 제공됩니다.\n\n![이미지](/assets/img/2024-05-17-AreWeHeadingTowardsaDystopia_1.png)\n\n이러한 솔루션이 완벽하게 구현되면 하나의 질문이 남습니다: 우리는 여전히 우리의 인간적 정체성을 유지할 수 있을까요, 아니면 우리 모두가 동일한 성격으로 수렴할까요?\n\nAI 전문가로서, 저는 트렌드를 주의 깊게 관찰하고 있으며 AI가 가져다주는 기회에 흥분하고 있습니다. 그러나 AI 도구에 적합한 작업과 인간이 해야 하는 작업을 구별해야 합니다. 비록 AI가 완벽하게 수행하더라도 우리 인간에 의해 수행되어야 할 작업이 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAI에 대해 가장 우려되는 측면 중 하나는 데이터 개인정보 보호입니다. 당신이 입력하거나 말하는 매 말은 몇 초 내에 처리되며, 당신에 대한 추론을 도출하는 모델을 활성화합니다: 당신이 좋아하는 것, 무엇을 살 것이며, 다음에 무엇을 말할 것인지 등을 파악합니다.\n\n좋은 소식은 모든 사람이 동일한 도구를 사용하여 데이터를 수집하고 텍스트를 작성하는데 사용한다는 것입니다(예: ChatGPT 및 유사한 도구). 미래에는 예측을 건너뛰고 도구에 직접 물어볼 수도 있을지도 모릅니다.\n\nAI 분야에서의 인상적인 발전은 우리를 The Truman Show와 같은 가짜 현실에 접근시키는데, 여기서 AI가 우리의 모든 작업을 처리하고 우리의 사고와 의사 결정까지 돌보게 할 수 있습니다. 우리에게 남은 것은 먹기, 자기, 숨기뿐인 것일까요? 더구나 당신의 목소리를 완벽하게 복제하는 이러한 도구들은 보안 문제를 야기시킬 수 있습니다. 누군가의 목소리를 복제하면 그 사람의 신원 도용도 쉽게 이루어집니다.\n\n어떤 연구소에서 이미 성취되었든지, 곧 당신도 몇 가지 예시만 가지고도 특정 행동을 하는 사람의 포토리얼리스틱 비디오를 생성할 수 있을 것입니다. 이로 인한 위험은 상상할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그런 도구들은 영화 생성에 대한 멋진 선택으로 들리죠. 유명 배우들의 얼굴 또는 심지어 여러분과 친구들의 영화를 주인공으로 삼는 아이디어도 참 좋은데, 때로는 아니죠. DALL-E2와 같은 모델들은 이미 무작위 얼굴을 사용한 영화 제작을 허용하고 있어요.\n\n요약하자면, AI 기술의 발전은 틀림없이 인상적이지만, 무시할 수 없는 윤리적이고 실용적인 문제들을 동반하고 있어요. 인간과 AI 사이의 경계가 희미해지고, 우리의 정체성과 개인정보에 대한 질문들을 던지고 있어요. 신원 도용이나 가짜 현실 생성과 같은 남용 가능성은 상당한 위험을 야기합니다. 앞으로 나아가면서, AI에 적합한 작업과 인간이 갖고 있어야 할 영역을 신중하게 고려하는 것이 중요합니다. AI의 미래는 큰 기회를 품고 있지만, 경계 감각, 책임감, 그리고 우리를 독특하게 만드는 것을 보존하기 위한 헌신이 필요합니다.\n\n참고: 이 기사가 마음에 드셨다면 — 내용은 저의 것이며, chatGPT 4o에서의 일부 복사 편집 지원, 이미지 DALL-E.\n","ogImage":{"url":"/assets/img/2024-05-17-AreWeHeadingTowardsaDystopia_0.png"},"coverImage":"/assets/img/2024-05-17-AreWeHeadingTowardsaDystopia_0.png","tag":["Tech"],"readingTime":4},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<img src=\"/assets/img/2024-05-17-AreWeHeadingTowardsaDystopia_0.png\">\n<p>이틀 전, 2024 Google I/O 컨퍼런스에서 Google은 새로운 도구인 Illuminate를 선보였어. 이 AI 도구는 학술 논문을 입력으로 받아들여 인간과 구별할 수 없는 실제 음성과 함께 오디오 토론을 생성할 수 있어. 이것은 음성 AI의 발전을 보여주는 한 예일 뿐이야.</p>\n<p>AI와의 커뮤니케이션이 더 자연스럽고 인간적으로 변하면서 AI와 인간을 구분하기가 거의 불가능해지고 있어. AI 전문가로서 저는 미래에 대해 궁금하면서 동시에 걱정스러워해. 곧, AI 챗봇이 우릴 쓰기만 하는 것이 아니라 우리와 대화를 나눌 거야. 미래에 전화 상대가 우리가 생각하는 사람인지 아니면 AI 복제물인지 어떻게 구분할 수 있을까?</p>\n<p>중국에서는 일부 TV 프로그램에서 진행자의 클론을 만들어 휴가 중에 대신하고 있어. 두 달 전 우크라이나 인플루언서가 자신의 클론이 중국에 러시아 제품을 판다는 것을 보고 신고했어. 다음으로 어떤 수준이 있을까? 우리 자신의 클론을 만들어 번거로운 전화를 처리하게 하거나, 비서 역할을 수행하게 하거나, 심지어는 면접까지 진행하게 할 수 있을까? 우리의 상담사가 ChatGPT의 지식, pi.ai의 공감능력, 그리고 Google의 실제 음성 생성 능력을 갖춘 AI 에이전트가 될까?</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>왜 AI를 상담사로 선택해야 할까요? 왜냐하면 AI는 항상 접근 가능하며, 낮과 밤을 가리지 않고 언제든지 이야기할 수 있습니다. 우리의 걱정에 대해 최적의 조언을 받을 수 있으며, 시간당이 아닌 토큰 단위로 과금되어 가장 합리적인 가격으로 제공됩니다.</p>\n<p><img src=\"/assets/img/2024-05-17-AreWeHeadingTowardsaDystopia_1.png\" alt=\"이미지\"></p>\n<p>이러한 솔루션이 완벽하게 구현되면 하나의 질문이 남습니다: 우리는 여전히 우리의 인간적 정체성을 유지할 수 있을까요, 아니면 우리 모두가 동일한 성격으로 수렴할까요?</p>\n<p>AI 전문가로서, 저는 트렌드를 주의 깊게 관찰하고 있으며 AI가 가져다주는 기회에 흥분하고 있습니다. 그러나 AI 도구에 적합한 작업과 인간이 해야 하는 작업을 구별해야 합니다. 비록 AI가 완벽하게 수행하더라도 우리 인간에 의해 수행되어야 할 작업이 있습니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>AI에 대해 가장 우려되는 측면 중 하나는 데이터 개인정보 보호입니다. 당신이 입력하거나 말하는 매 말은 몇 초 내에 처리되며, 당신에 대한 추론을 도출하는 모델을 활성화합니다: 당신이 좋아하는 것, 무엇을 살 것이며, 다음에 무엇을 말할 것인지 등을 파악합니다.</p>\n<p>좋은 소식은 모든 사람이 동일한 도구를 사용하여 데이터를 수집하고 텍스트를 작성하는데 사용한다는 것입니다(예: ChatGPT 및 유사한 도구). 미래에는 예측을 건너뛰고 도구에 직접 물어볼 수도 있을지도 모릅니다.</p>\n<p>AI 분야에서의 인상적인 발전은 우리를 The Truman Show와 같은 가짜 현실에 접근시키는데, 여기서 AI가 우리의 모든 작업을 처리하고 우리의 사고와 의사 결정까지 돌보게 할 수 있습니다. 우리에게 남은 것은 먹기, 자기, 숨기뿐인 것일까요? 더구나 당신의 목소리를 완벽하게 복제하는 이러한 도구들은 보안 문제를 야기시킬 수 있습니다. 누군가의 목소리를 복제하면 그 사람의 신원 도용도 쉽게 이루어집니다.</p>\n<p>어떤 연구소에서 이미 성취되었든지, 곧 당신도 몇 가지 예시만 가지고도 특정 행동을 하는 사람의 포토리얼리스틱 비디오를 생성할 수 있을 것입니다. 이로 인한 위험은 상상할 수 있습니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>그런 도구들은 영화 생성에 대한 멋진 선택으로 들리죠. 유명 배우들의 얼굴 또는 심지어 여러분과 친구들의 영화를 주인공으로 삼는 아이디어도 참 좋은데, 때로는 아니죠. DALL-E2와 같은 모델들은 이미 무작위 얼굴을 사용한 영화 제작을 허용하고 있어요.</p>\n<p>요약하자면, AI 기술의 발전은 틀림없이 인상적이지만, 무시할 수 없는 윤리적이고 실용적인 문제들을 동반하고 있어요. 인간과 AI 사이의 경계가 희미해지고, 우리의 정체성과 개인정보에 대한 질문들을 던지고 있어요. 신원 도용이나 가짜 현실 생성과 같은 남용 가능성은 상당한 위험을 야기합니다. 앞으로 나아가면서, AI에 적합한 작업과 인간이 갖고 있어야 할 영역을 신중하게 고려하는 것이 중요합니다. AI의 미래는 큰 기회를 품고 있지만, 경계 감각, 책임감, 그리고 우리를 독특하게 만드는 것을 보존하기 위한 헌신이 필요합니다.</p>\n<p>참고: 이 기사가 마음에 드셨다면 — 내용은 저의 것이며, chatGPT 4o에서의 일부 복사 편집 지원, 이미지 DALL-E.</p>\n</body>\n</html>\n"},"__N_SSG":true}