{"pageProps":{"posts":[{"title":"텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기","description":"","date":"2024-05-20 20:54","slug":"2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics","content":"\n\"집중하고 있니?\" \"집중하고 있니?\" 이 두 문장은 같은 의미인가요? 기사를 읽고 알고리즘의 답변을 찾아보세요!\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png)\n\n두 개의 텍스트를 비교하는 것은 보편적이고 중요한 작업이라고 보는 경우가 많습니다. 고객 서비스에서 AI 시스템은 동의어적 의미를 이해하여 인간 대화의 유동성을 반영하는 응답을 생성할 수 있어야 합니다. 예를 들어, \"비밀번호를 어떻게 복구할 수 있나요?\" 또는 \"비밀번호를 잊었어요. 다시 로그인하는 방법이 뭐에요?\"와 같은 질문은 의미가 유사하며 동일한 응답을 요구합니다. 게다가, 고객 상호작용 중에 대리인이 계약이나 제안에 대한 정보를 정확하게 전달하는지 확인해야 하는 경우가 종종 있습니다. 또한, 검색 엔진이나 Stack Overflow와 같은 플랫폼에서 이전에 질문이 제기되었는지 알아내야 할 필요가 있습니다. 본질적으로 텍스트 유사성을 빠르게 계산할 수 있는 능력은 효율성 향상과 고객 관계 향상의 기초가 됩니다.\n\n인간은 의미론적 및 문법적 관계를 본성적으로 쉽게 이해하지만, 기계는 같은 작업을 수행하는 데 더 복잡한 도전에 직면합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n먼저, 유사성을 더 구체적으로 정의해 봅시다: 유사성은 두 데이터 객체가 얼마나 다르거나 비슷한지를 측정한 것입니다. 거리가 짧을수록 객체들은 높은 수준의 유사성을 갖는다고 말하며, 그 반대도 마찬가지입니다.\n\n텍스트 유사성은 두 텍스트 조각이 어휘적으로(사용된 단어)와 의미론적으로(단어의 의미) 얼마나 가까운지를 나타냅니다. 예를 들어, \"병이 비어 있습니다\"와 \"병 안에는 아무 것도 없습니다\"라는 문장은 의미론적으로는 동일하지만 어휘적으로는 다릅니다.\n\n기계가 텍스트 유사성을 계산할 수 있도록하기 위해, 먼저 기계의 언어인 숫자를 기반으로 한 언어를 사용해야 합니다.\n\n그러므로, 텍스트 유사성을 평가하는 핵심 단계 중 하나는 텍스트를 벡터로 변환하는 것입니다. 벡터는 공간에서 크기와 방향을 나타내는 숫자 요소이기도 합니다. 이 프로세스는 텍스트 벡터화 또는 텍스트 인코딩이라고 알려져 있습니다. 유사성을 평가하기 위한 후속 단계는 이러한 벡터들 간의 거리를 측정하는 것입니다. 이 거리를 계산하는 데 선택된 측정 항목이 중요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기사에서는 텍스트를 임베딩하고 거리를 계산하는 다양한 기술의 장단점을 포괄적으로 탐구하여 귀하의 요구에 맞는 최적의 조합을 찾을 수 있는 포괄적인 안내서를 제공합니다.\n\n자세히 들어가기 전에 이 기사의 상위 수준 색인으로 볼 수 있는 다음 그림을 살펴보겠습니다.\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_1.png)\n\n텍스트 표현은 4가지의 주요 방법으로 군집화될 수 있습니다: 문자 기반, 의미론적 텍스트 일치, 말뭉치 기반(말뭉치는 언어 분석에 사용되는 텍스트 문서의 집합을 가리킵니다), 및 그래프 구조입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n문자열 거리는 길이 거리, 분포 거리 및 의미적 거리로 나뉠 수 있습니다.\n\n우리는 위 그림에서 볼드 처리된 주제들에 대해서만 다룰 것입니다. 가장 쉬운 방법부터 가장 복잡한 방법까지 시작하겠습니다.\n\n## 문자열 기반 텍스트 표현\n\n### 자카드 유사도\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n자카드 유사도, 또는 교집합 오버 유니온이라고도 알려지고, 두 개의 텍스트의 유사성을 측정하는 방법으로, 공통 단어의 개수를 전체 단어 수로 나눈 비율로 표현됩니다.\n\n다음과 같은 수식으로 설명됩니다:\n\n앞서 언급한 두 문장을 고려해 봅시다:\n\n- A: 병은 비어 있습니다\n- B: 병 안에는 아무것도 없습니다\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_2.png)\n\n자카드 유사도에 따르면, 문장 A와 B는 달리 의미를 가지고 있습니다. 이는 단순히 문장을 리터럴 레벨에서 비교하기 때문입니다.\n\n자카드 유사도는 쉽게 계산할 수 있지만 의미적 관계를 포착하지 못하므로, 텍스트에서 사용된 단어를 비교하는 것이 필수적이지 않은 이상 권장되지 않습니다.\n\n자카드 유사도에 따르면, 문장 A와 B는 달리 의미를 가지고 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n표 태그를 Markdown 형식으로 변경하겠습니다.\n\n# Corpus based text representation\n\n앞서 언급한 대로, 단어가 숫자로 표현되는 방식은 유사성을 평가하는 데 중요합니다. 이제 텍스트 표현을 위한 다양한 기술을 탐색해보겠습니다.\n\n## Bag of words\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nBag of words 기반 기술은 단어의 순서와 관계없이 문서를 단어들의 조합으로 나타냅니다. 이 가족 중에서 가장 간단한 방법은 원핫 인코딩입니다.\n\n원핫 인코딩에 따르면 고유 단어의 총 수만큼의 크기를 가진 벡터가 생성됩니다. 각 단어의 값은 해당하는 인덱스에 1이 할당되고 나머지는 0입니다.\n\n이는 말뭉치의 다양성이 적고 데이터 간 의미 및 통계적 관계를 나타내는 필요가 없는 상황에서 일반적으로 사용됩니다. 큰 문서의 경우, 방대하고 희소한 벡터로 이어질 수 있습니다.\n\n조금 더 세련된 방법은 TF-IDF (단어 빈도-역문서 빈도)입니다. 이는 빈도가 높은 단어는 중요성이나 의미가 적다는 아이디어에 기반합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n수학적으로 말하면:\n\nTF = 문서에 단어가 나타나는 횟수 / 문서 내 전체 단어 수\n\nIDF = log(N/n)\n\n여기서 N은 전체 문서 수이고, n은 대상 용어가 나타나는 문서 수입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n0s를 제거하려면 모든 문서에 단어가 있는 경우 TF\\*IDF 곱에 1을 더하므로, 벡터의 0은 단어의 부재를 나타냅니다.\n\n예제를 통해 이해해 봅시다. 다음과 같은 문장들을 고려해 보겠습니다:\n\n- He is Walter\n- He is William\n- He isn’t Peter or September\n\nTF 벡터는 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- [0.33, 0.33, 0.33]\n- [0.33, 0.33, 0.33]\n- [0.20, 0.20, 0.20, 0.20, 0.20]\n\n이제 IDF 점수를 계산해 봅시다.\n\n- \"He\": Log(3/3) = 0,\n- \"is\": Log(3/2) = 0.1761,\n- \"or, Peter, ..\": Log(3/1) = 0.4771 ..\n\n결과 벡터는:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- [1. , 1.1761 , 1.4771 , 0. , 0. , 0. , 0. , 0.],\n- [1. , 1.1761 , 0. , 1.4771 , 0. , 0. , 0. , 0.],\n- [1. , 0. , 0. , 0. , 1.4771 , 1.4771, 1.4771 , 1.4771]\n\n이 방법은 통계적 관계를 가치화하지만 의미론적 관계를 대변하지 않고, 긴 문서에 적합하지 않습니다. 이는 고차원 벡터로 이어집니다.\n\n일반적으로, 대부분의 단어 가방 접근 방식은 의미론적 관계를 중요시하지 않고, 큰 문서에 대해 데이터 희소성으로 이어질 수 있습니다. 따라서, 텍스트 표현에 대한 복잡한 기술인 단어 임베딩 중 하나로 분류될 수 있는 더 복잡한 기술에 대해 심층적으로 살펴보겠습니다.\n\n## 창 기반 방법\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 방법은 통계적 관계를 중요시하지만 의미론적 관계를 나타내지는 않고, 긴 문서에는 적합하지 않습니다. 따라서 고차원 벡터로 이어질 수 있습니다.\n\n일반적으로 단어 가방 접근 방식 중 대부분은 의미적 관계를 중요시하지 않을 수 있고, 대규모 문서의 데이터 희소성으로 이어질 수 있습니다. 그러니 텍스트 표현에 대해 더 복잡한 기법으로 다양한 단어 표현 기술 중 하나로 분류될 수 있는 기법을 자세히 살펴보도록 하겠습니다.\n\n## Word2Vec\n\nW2V는 미리 훈련된 두 개의 레이어로 이루어진 신경망입니다. W2V 방식은 기계 학습에서 흔히 사용되는 속임수를 사용합니다: 단일 숨겨진 레이어를 가진 신경망이 특정 작업을 수행하도록 훈련되지만 최종 작업에 사용되지는 않습니다. 실제로 목표는 숨겨진 레이어의 가중치를 학습하는 것뿐입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nW2V는 두 가지 사전 훈련 모델을 가지고 있어요: 연속 단어 주머니 (Continuous Bag Of Words, CBOW)와 스킵-그램.\n\n![이미지](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_3.png)\n\n사진에서 볼 수 있듯이, CBOW에서는 대상 단어에 인접한 단어가 입력으로 주어지고 대상 단어를 예측하는 작업을 하며, 스킵-그램에서는 대상 단어가 입력으로 주어지고 이웃하는 단어들을 출력으로 예측해야 합니다. 이웃 단어로 고려할 단어 수를 \"윈도우 크기\"라고 하며, 이는 알고리즘의 매개변수입니다 (윈도우 크기의 일반적인 값은 5일 수 있어요).\n\n임베딩이 어떻게 생성되는지 이해하기 위해, 스킵-그램에 집중해봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n훈련 작업의 첫 번째 단계는 문서에 있는 단어들을 인코딩하는 것인데, 일반적으로 이는 원핫인코딩 방식으로 수행됩니다.\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_4.png)\n\n출력은 코퍼스에 있는 단어 수와 동일한 길이의 단일 벡터이며, 각 요소는 입력 단어의 이웃 단어가 될 가능성을 나타냅니다.\n\n만약 두 단어가 매우 유사한 문맥을 가진다면, 주변에 같은 단어들이 있을 가능성이 높다는 것을 의미하며, 모델은 이러한 단어들에 대해 유사한 결과를 생성하여야 합니다. 네트워크가 이를 달성하는 방법 중 하나는 단어 벡터가 유사하도록 하는 것입니다. 그러므로 두 단어가 유사한 문맥을 보여줄 때, 네트워크는 이러한 단어들에 대해 유사한 단어 벡터를 모으도록 자극을 받게 됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n두 종류의 네트워크를 비교해 보면, CBOW는 문법적 관계 학습에 뛰어나지만 Skip-gram은 의미적 관계를 파악하는 데 좀 더 우수합니다. 예를 들어, CBOW는 복수형과 같이 형태적으로 유사한 단어에 초점을 맞추지만 Skip-gram은 형태적으로 다른데 의미적으로 관련 있는 단어를 고려합니다. 게다가, Skip-gram은 빈번한 단어의 과적합에 덜 민감하며, 단어 하나만을 입력으로 사용하기 때문에 최적의 성능을 위한 문서 요구 사항 측면에서 더 효율적입니다.\n\nW2V 임베딩은 Spacy나 Genism에서 구현됩니다.\n\n이 접근법은 고차원 문제를 해결하고 의미론적 및 문법적 관계를 고려하지만, 단어의 맥락을 고려하지 않는 한계가 있어서 다의성의 경우 성능이 떨어질 수 있습니다. 예를 들어, \"current\"라는 단어는 다음 두 문장에서 각각 다른 의미를 가집니다:\n\n- 현재 사안 프로그램입니다.\n- 시내는 다리 아래로 빨리 흐릅니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nW2V 방법에 따르면 세계의 현재 상태는 하나의 표현만을 갖게 될 것입니다.\n\n맥락 모델은 해당 문서의 모든 단어의 순서를 고려하여 대상 단어를 포함하는데 사용됩니다.\n\n자연어 처리 세계에서 가장 중요한 알고리즘 중 하나를 탐색해봅시다: BERT.\n\n## BERT\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알고리즘에 대한 간결한 개요를 제공하겠습니다. 아키텍처 및 훈련의 중요 측면을 강조하여 문맥적 임베딩의 성취를 이해하는 데 필요한 것을 설명하겠습니다. BERT를 보다 자세히 탐구하려면 이 글의 마지막에 링크된 추가 자료를 참고하시기를 권합니다.\n\nBERT는 Bidirectional Encoder Representation from Transformers의 약자입니다. 이름에서 알 수 있듯이 BERT 아키텍처는 transformers를 기반으로 하며 실제로 양방향 언어 transformers를 사용하여 언어 표현을 합니다.\n\nBERT는 두 가지 다른 작업을 위해 사전 훈련되었습니다: Masked Language Modelling (MLM) 및 Next Sentence Prediction (NSP).\n\n첫 번째 작업인 MLM부터 시작해 보겠습니다. 말뭉치에 있는 단어 중 15%가 \"마스킹\"되었다고 가정됩니다. 이들 중에서:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 단어의 80%가 가리킨 토큰 [MASK]로 대체됩니다.\n- 10%는 무작위 단어로 대체됩니다.\n- 10%는 바뀌지 않은 채로 남겨집니다.\n\n해당 작업은 마스킹된 단어를 예측하는 것입니다. 특히 각 토큰을 마스킹하는 방식은 모형에 매우 중요합니다:\n\n- 단어를 토큰 [MASK]로 대체하면 일반 토큰을 제공하는 대신 주변 텍스트에서만 토큰을 추론할 수 있도록 합니다.\n- 샘플링된 단어를 텍스트 내에서 무작위 단어로 대체하고 예측을 강화하면 모형이 잘못된 토큰에 대응하는 강건함을 향상시킵니다. 모형은 예상치 못한 또는 맥락을 벗어난 단어를 효과적으로 다룰 수 있도록 합니다.\n- 샘플링된 단어를 바꾸지 않고 예측하면 모형이 텍스트의 원래 의미론적 및 구문 구조를 유지합니다. 모형은 잘못된 맥락에 대처하는 강건함을 향상시킵니다.\n\n이 세 가지 마스킹 단어 방식의 결합은 모형을 다양한 NLP 작업에서 강건하고 다재다능하게 만들어줍니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n두 번째 과제인 NSP는 문장 간의 관계를 학습하는 데 초점을 맞춥니다: 코퍼스 내 문장 쌍의 50%에 대해 두 번째 문장이 실제로 다음 문장인 경우가 있고, 나머지 쌍에 대해서는 두 번째 문장이 무작위로 선택된 문장입니다. 첫 번째 경우는 \"isNext\"로 레이블이 지정되고, 두 번째 경우는 \"NotNext\"로 레이블이 지정됩니다. 이 과제는 올바른 레이블을 예측하도록 하는 것으로, BERT가 문장 간 관계(예: 질문과 답변)를 학습할 수 있게 합니다.\n\nBERT 모델의 훈련 과정에서 Masked Language Model(MLM) 및 Next Sentence Prediction(NSP) 구성 요소는 함께 훈련되어, 이 두 전략에서 발생하는 결합 손실 함수를 최소화하도록 하고 올바른 레이블을 예측합니다.\n\nBERT의 강점은 이러한 작업을 수행하기 위해 입력 모델을 어떻게 모델링하는지에 있습니다.\n\n각 입력 임베딩은 3가지 임베딩의 조합으로 이루어져 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 위치 임베딩: 문장 내 단어의 위치를 표현하는 데 사용되는 임베딩입니다. 이러한 요소들은 Transformer의 제약을 해결하기 위해 도입되었는데, 순환 신경망과 달리 순차적 정보를 포착하는 능력이 없는 Transformer의 한계를 극복하기 위해 도입되었습니다.\n- 세그먼트 임베딩: 문장 쌍을 식별하는 임베딩입니다. BERT는 모델이 두 문장을 구분할 수 있도록 첫 번째 문장과 두 번째 문장에 대해 고유한 임베딩을 학습합니다. 아래 그림에서 EA로 표시된 모든 토큰은 문장 A에 속하며, EB도 비슷하게 문장 B에 속합니다.\n- 토큰 임베딩: 첫 번째 문장의 시작 부분에 [CLS] 토큰이 삽입되고, 각 문장의 끝 부분에는 [SEP] 토큰이 삽입됩니다.\n\n위 3가지 임베딩을 합산하여 각 입력을 얻습니다.\n\n<img src=\"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_5.png\" />\n\n미리 학습된 후, 모델은 특정 말뭉치에서 세밀하게 튜닝될 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사전 훈련된 BERT의 버전은 분류(감성 분석), 질의응답, Named Entity Recognition과 같은 특정 작업에 사용할 수 있습니다. 그러나 저희는 임베딩 기법 중 한 가지로 이 알고리즘을 언급했기 때문에, 어떻게 이를 이용하는지 간단히 설명하겠습니다. 이 응용 프로그램의 아이디어는 W2V에 언급된 것과 유사합니다. 사실, 우리는 사전 훈련된 목적으로 그 모델을 사용하지 않습니다. BERT 베이스 모델은 12개의 트랜스포머 인코더 레이어를 사용하며, 각 레이어에서 각 토큰의 출력을 단어 임베딩으로 사용할 수 있습니다. 경험적인 연구를 바탕으로, 저자들은 매우 효과적인 접근 방식은 마지막 4개 레이어의 출력을 합하는 것임을 결정했습니다. BERT를 사용한 임베딩은 Hugging Face의 오픈 소스 라이브러리를 사용하여 Python에서 쉽게 구현할 수 있습니다. 이 라이브러리는 BERT를 PyTorch 또는 TensorFlow에서 사용할 수 있도록 제공합니다.\n\n# 거리 측정 방법\n\n지금까지 우리의 탐구는 텍스트 유사도를 측정하는 한 가지 방법(자카드 유사도)과 텍스트를 벡터로 변환하는 여러 기술에만 집중해 왔습니다. 소개에서 언급했듯이, 단어를 벡터로 변환하는 것은 유사도를 평가하기 위한 예비 단계에 불과하며, 거리 측정 방법의 계산이 필요합니다. 다음 섹션에서는 이러한 거리 측정 방법에 대해 포괄적으로 검토할 것입니다.\n\n## 길이 거리 측정 방법\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n길이 거리 측정 방법에 따르면, 거리는 텍스트의 수치적 특성을 이용하여 측정됩니다. 그 중 가장 인기 있는 측정 방법은 확실히 유클리드 거리입니다.\n\n유클리드 거리\n\n유클리드 거리는 두 점 사이의 거리를 계산하기 위해 피타고라스의 정리를 사용합니다.\n\n길이가 n인 두 벡터를 고려해 보면, 유클리드 거리는 다음 공식으로 설명됩니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래 이미지에서 확인할 수 있습니다:\n\n![이미지1](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_6.png)\n\n두 벡터 간의 거리 d가 클수록 유사도 점수가 낮아지고 그 반대도 마찬가지입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n유클리드 거리에는 몇 가지 제한이 있습니다. 먼저, 비교할 대상이 없다면 이해하기 어려운 값이 계산됩니다. 이 문제를 해결하기 위해 거리를 정규화할 수 있지만, 가장 잘 알려진 공식\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_8.png)\n\n은 이상치의 영향을 매우 민감하게 받습니다.\n\n둘째, 유클리드 거리는 텍스트의 크기에 강하게 영향을 받기 때문에 희소 벡터(예: 원핫 인코딩으로 생성된 벡터)와는 잘 작동하지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n코사인 유사도\n\n코사인 유사도는 두 벡터의 유사성을 측정하는 것으로, 벡터 사이의 각도의 코사인을 측정합니다. 두 점 사이의 거리를 측정하는 대신 두 벡터가 같은 방향으로 향하는지 확인합니다. 따라서 이는 벡터의 크기에 영향을 받지 않습니다.\n\n코사인 유사도는 다음과 같은 공식을 통해 계산됩니다:\n\n```js\n\\[ \\text{cosine similarity} = \\frac{{\\textbf{A} \\cdot \\textbf{B}}}{{\\lVert \\textbf{A} \\rVert \\times \\lVert \\textbf{B} \\rVert}} \\]\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_10.png\" />\n\n벡터의 영향을 받아 이러한 지표를 비교하는 것에 대한 의미를 더 잘 이해해 봅시다.\n\n두 개의 논문을 비교해보자고 가정해보겠습니다. 한 쪽은 정치와 관련된 것이고, 다른 한 쪽은 스포츠와 관련된 것이라고 가정해보겠습니다. \"야구\"라는 단어가 논문 1에 논문 2보다 더 많이 나오는 경우, 유클리드 거리에 따르면, 논문 1이 스포츠와 관련이 더 있습니다. 그러나 논문 1이 그냥 논문 2보다 더 길었을 수도 있습니다. 결과적으로 논문 2가 논문 1보다 스포츠와 더 관련된 경우도 있을 수 있습니다.\n\n대부분의 텍스트 유사성 사용 사례들은 길이에 민감하지 않습니다. 따라서 일반적으로 코사인 유사도가 유클리드 거리보다 선호됩니다. 유클리드 거리가 선호될 수 있는 사용 사례는 길이에 민감한 표절 탐지입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 의미적 거리\n\n텍스트 간에 공통된 단어가 많지 않은 상황에서는, 길이나 분포에 의존하는 거리 측정으로 유도된 유사성은 비교적 낮게 나타날 수 있습니다. 이러한 경우 의미적 거리 계산을 선택하는 것이 좋습니다.\n\n이를 위한 주요 방법은 Word Mover's Distance로, 이는 텍스트 간의 의미적 근접성을 결정하는 데 도움을 줍니다.\n\nWord mover's distance\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n단어 이동 거리는 두 텍스트 문서 간에 유사성을 정의하는데, 한 문서의 임베드된 단어가 다른 문서의 임베드된 단어에 도달하기 위해 이동해야 하는 최소 거리를 나타냅니다. 따라서 유사성의 측정은 운송 문제가 됩니다: 텍스트1을 텍스트2로 운송하는 비용을 최소화합니다.\n\n단어 이동 거리는 확률 분포 간 유사성을 측정하는 최적화 문제인 Earth Mover's Distance에서 비롯되었습니다. 이는 한 분포를 다른 분포로 변환하는 비용을 고려하여 유사성을 측정합니다.\n\nWMD를 계산하기 위한 첫 번째 단계는 정규화된 Bag of Words로의 단어 임베딩입니다. 둘째, 유클리드 거리가 계산되고 마지막으로 최적화 문제가 계산됩니다. 최적화 문제의 목적 함수는 한 문서에서 다른 문서로 이동하는 데 필요한 거리를 최소화하는 것이며, \"질량\"의 총량이 보존되어야 한다는 제약조건이 따릅니다. 다시 말해, 제약 조건은 두 문서의 전체 내용이 고려되고 한 단어에서 다른 단어로 이동하는 과정에서 어떤 단어도 중복되거나 손실되지 않도록 보장합니다.\n\n긴 문서에 대해 특히 계산 비용이 많이 드는 WMD는 모든 단어의 존재 여부를 사용하는 방법으로, 순서에 상관없이 문법적인 변경사항에 강하지 않습니다. 그러나 단어의 유사성을 임베딩 공간에서 고려하기 때문에 공통 단어가 거의 없는 문서에 대해서는 매우 효과적입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n![이미지](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_11.png)\n\n의미론적 유사성을 측정하는 것은 자연어 처리 세계에서 가장 복잡한 도전 중 하나입니다. 텍스트 유사성 측정의 공간을 탐험하면 각각 독특한 장단점이 있는 다양한 방법을 발견할 수 있습니다.\n\n문자열 기반 방법은 간단하고 구현하기 쉽지만 의미 관계를 다루지 않습니다. 그에 반해 말뭉치 기반 방법은 더 복잡하지만 의미적이고 통계적인 관계를 중요시하며 여러 언어에 대해 다재다능합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n거리 측정에 관한 것은 일부가 길이에 민감하고, 다른 일부는 분포에 의존하거나 의미에 중점을 둡니다. 이러한 측정 방법과 텍스트 표현의 조합은 무한합니다.\n\n계속 발전하는 이 환경에서 완벽한 모델을 찾는 노력이 계속되는 중에도, 하나의 진리는 명확히 남아 있습니다: 최적의 방법을 선택하는 것은 각 사용 사례의 고유한 요구 사항과 깊은 관련이 있습니다. 우리가 앞으로 나아가면서, 표현학습과 거리 계산 사이의 시너지는 계속 발전하는 텍스트 벡터의 길을 열어주며, 의미 유사성에 대한 우리의 이해력에 새 시대를 열어줍니다.\n\n# 참고문헌\n\n[1] Qiu, Xipeng, 등. \"자연어 처리를 위한 사전 훈련된 모델: 설문.\" Science China Technological Sciences 63.10 (2020): 1872-1897.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Goldberg, Yoav, and Omer Levy. \"word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method.\" arXiv preprint arXiv:1402.3722 (2014).\n- Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint arXiv:1810.04805 (2018).\n- Wang, Jiapeng, and Yihong Dong. \"Measurement of text similarity: a survey.\" Information 11.9 (2020): 421.\n- Kusner, Matt, et al. \"From word embeddings to document distances.\" International conference on machine learning. PMLR, 2015.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n[6] [Online]. Available: [Newscatcher API - Ultimate Guide to Text Similarity with Python](https://www.newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python).\n\n[7] McCormick, Chris. “Word2vec tutorial-the skip-gram model.” Apr-2016. [Online]. Available: [Word2vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model) (2016).\n","ogImage":{"url":"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png"},"coverImage":"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png","tag":["Tech"],"readingTime":22},{"title":"번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어","description":"","date":"2024-05-20 20:52","slug":"2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore","content":"\n안녕하세요! Bend에 대해 들어보셨나요?\n\n아직 안 들어보셨나요? 이 이야기를 읽고 있다면 아직 늦지 않으십니다.\n\n몇 시간 전에 Bend라는 GitHub 저장소를 발견했어요. 'Bend — 대규모 병렬 처리를 지원하는 고수준 프로그래밍 언어'라는 제목이 붙어 있었죠.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nBend는 병렬 계산을 수행하는 방식을 영원히 변경하려는 고수준 프로그래밍 언어입니다.\n\n세계를 바꾼다고 약속한 언어가 많았다는 건 알고 있어요. 하지만 Bend는 실제로 그럴 수도 있어요!\n\nBend가 약속하는 좋은 부분을 알아보기 전에 병렬 계산에 대해 조금 배워볼까요?\n\n# 병렬 계산 - 최소의 시간으로 최대의 일을 하는 기술\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n컴퓨터 프로그램은 기본적으로 작업을 하나씩 차례대로 실행합니다.\n\n이는 프로세서 코어에 의해 한 번에 한 가지 명령을 실행하는 단일 스레드에 의존하기 때문입니다.\n\n이 간단한 방식은 순차 계산이라고 합니다.\n\n이로 인해 프로그램 내부의 명령 흐름이 예측 가능하고 디버깅하기 쉬워집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그러나, 이것은 또한 모든 명령어가 실행을 시작하기 전에 이전 명령어가 끝날 때까지 기다려야 한다는 것을 의미합니다.\n\n현대 컴퓨팅 시대에 있어서 대부분의 프로세서가 여러 코어로 구성되어 있기 때문에, 병렬 연산이라는 다른 접근 방식을 사용하여 지수적으로 빠르게 만들 수 있습니다.\n\n프로그램 내의 많은 명령어들이 여러 스레드를 사용하여 동시에 실행됨으로써 프로그램 전체의 실행 시간을 줄일 수 있습니다.\n\n# 하지만, 병렬 연산을 올바르게 수행하는 것은 어려울 수 있습니다\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n병렬 계산을 다룬 적이 있는 분이라면, 그것을 올바르게 처리하는 것이 정말 악몽이라고 동의할 것입니다.\n\n동시에 공유 리소스에 접근하는 여러 스레드는 경합 상태를 유발해 완전히 예상치 못한 결과로 이어질 수 있습니다.\n\n또는, 좋지 않은 날이면 두 개 이상의 스레드가 서로가 차지한 리소스를 대기하고 끝없이 기다리는 데드락에 갇힐 수도 있습니다.\n\n이러한 문제는 Python 라이브러리인 threading과 multiprocessing이나 Go의 WaitGroup, Mutex, RWMutex와 같은 동기화 기본 요소를 이용한 Goroutines 등으로 해결되었지만, 이들의 구현은 숙련하기 어렵습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nCUDA 및 Metal은 각각 NVIDIA 및 Apple GPU에서 병렬 계산을 활성화하는 몇 가지 다른 프로그래밍 모델입니다. 그러나 이를 다루는 대부분의 사람들은 (정직하다면) 그것을 완벽히 이해하는 데 얼마나 어려운 작업인지 말해 줄 것입니다.\n\n그럼에도 불구하고 남아 있는 의문은 —\n\n병렬 계산을 쉽게 할 수 있는 새로운 사람들에게 좋은 대안이 없는 걸까요?\n\n# Bend가 구해줄게요\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n단순히 Python처럼 쉽게 느껴지도록 작성된 언어인 Bend는 아마도 우리를 이 비통으로부터 구출해 줄 수 있는 사랑스러운 언어일지도 모르겠어요.\n\n그 철학은 웃기게 간단합니다 —\n\nBend는 기본적으로 코드를 병렬로 실행하기 때문에, 다중 코어 CPU 또는 GPU와 작업하기 위해 CUDA를 배우는 데 수년을 보내야 할 필요가 없어요.\n\n## 하지만, Bend는 어떻게 이것이 가능하게 만드는 걸까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nBend은 매우 병렬 실행을 위해 설계된 강력한 계산 프레임워크인 HVM2 또는 Higher-order Virtual Machine 2에 의해 구동됩니다.\n\nPython과 같은 고수준 언어로 작성된 프로그램을 HVM2로 컴파일하면 GPU에서 빠르게 실행할 수 있습니다!\n\nHVM2는 1997년 Yves Lafont가 고안한 병렬 컴퓨테이션 모델인 Interaction Combinators를 기반으로 하며, 그래프 기반 구조를 사용합니다.\n\n이 모델에서 각 계산은 그래프로 시각화됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 그래프들에서 각 노드는 조합자(Combinator)입니다.\n\n조합자는 이 모델의 기본 구성 요소로 작용하는 고차 함수입니다.\n\n각 조합자마다 다른 조합자와의 상호 작용 방식을 결정하는 간단한 규칙 세트가 있습니다. 예를 들어 —\n\n- Identity Combinator는 인수를 변경하지 않고 반환합니다.\n- Constant Combinator는 두 개의 인수를 사용하고 첫 번째 것을 반환합니다(두 번째 것을 무시), 등등.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래프에서 각 엣지는 이 결합자들 간의 연결을 나타냅니다.\n\n이러한 결합자들이 상호작용할 때(엣지에서 시사하는 대로), 그들은 각자의 규칙에 따라 변환되어 결과를 돌려줍니다.\n\n상호작용 결합자 모델에서 가장 훌륭한 부분은 이들의 그래프 구조가 프로그램 내의 다른 계산을 서로 다른 코어(즉, 병렬로)에서 처리할 수 있게 한다는 것입니다.\n\n그리고 이것이 이 모델을 강력하게 만드는 요소입니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nHVM2은 고수준 언어로 작성된 프로그램을 대상으로 하는 저수준 컴파일러이며 직접 사용하기 위한 것은 아닙니다.\n\n재귀 합을 구현하려면 다음과 같이 읽을 수 있습니다.\n\n```js\n@main = a\n  & @sum ~ (28 (0 a))\n\n@sum = (?(((a a) @sum__C0) b) b)\n\n@sum__C0 = ({c a} ({$([*2] $([+1] d)) $([*2] $([+0] b))} f))\n  &! @sum ~ (a (b $(:[+] $(e f))))\n  &! @sum ~ (c (d e))\n```\n\n하지만 걱정하지 마세요. Bend는 우리의 삶을 쉽게 만들기 위해 이 암호화된 HVM2와 인터페이스를 맺기 위해 작성된 사람이 읽을 수 있는 언어입니다. 함께 작업을 병렬로 처리할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## Bend 사용 방법\n\nBend는 러스트 프로그래밍 언어로 작성되었으므로, 첫 번째 단계는 Rust nightly를 설치하고, 그 다음으로 HVM2와 Bend를 함께 설치하는 것입니다.\n\n```js\ncargo +nightly install hvm\ncargo +nightly install bend-lang\n```\n\n안타깝게도, 현재 Windows에서는 작동하지 않기 때문에 (나처럼) WSL2를 해결책으로 사용해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 Bend 코드를 작성합니다.\n\n```js\n# sorter.bend\n\n# Sorting Network = just rotate trees!\ndef sort(d, s, tree):\n  switch d:\n    case 0:\n      return tree\n    case _:\n      (x,y) = tree\n      lft   = sort(d-1, 0, x)\n      rgt   = sort(d-1, 1, y)\n      return rots(d, s, lft, rgt)\n\n# Rotates sub-trees (Blue/Green Box)\ndef rots(d, s, tree):\n  switch d:\n    case 0:\n      return tree\n    case _:\n      (x,y) = tree\n      return down(d, s, warp(d-1, s, x, y))\n\n# Swaps distant values (Red Box)\ndef warp(d, s, a, b):\n  switch d:\n    case 0:\n      return swap(s + (a > b), a, b)\n    case _:\n      (a.a, a.b) = a\n      (b.a, b.b) = b\n      (A.a, A.b) = warp(d-1, s, a.a, b.a)\n      (B.a, B.b) = warp(d-1, s, a.b, b.b)\n      return ((A.a,B.a),(A.b,B.b))\n\n# Propagates downwards\ndef down(d,s,t):\n  switch d:\n    case 0:\n      return t\n    case _:\n      (t.a, t.b) = t\n      return (rots(d-1, s, t.a), rots(d-1, s, t.b))\n\n# Swaps a single pair\ndef swap(s, a, b):\n  switch s:\n    case 0:\n      return (a,b)\n    case _:\n      return (b,a)\n\n# Testing\n# -------\n\n# Generates a big tree\ndef gen(d, x):\n  switch d:\n    case 0:\n      return x\n    case _:\n      return (gen(d-1, x * 2 + 1), gen(d-1, x * 2))\n\n# Sums a big tree\ndef sum(d, t):\n  switch d:\n    case 0:\n      return t\n    case _:\n      (t.a, t.b) = t\n      return sum(d-1, t.a) + sum(d-1, t.b)\n\n# Sorts a big tree\ndef main:\n  return sum(18, sort(18, 0, gen(18, 0)))\n```\n\n이것은 공식 저장소에서 가져온 예시로, 병렬 정렬 알고리즘인 Bitonic Merge Sort를 구현한 것입니다.\n\n이 알고리즘은 병렬로 실행할 수 있는 분할 정복 방식을 사용하므로 Bend는 병렬로 실행할 것입니다 (Bend의 철학을 기억하시나요?)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음으로, 이 명령어를 사용하여 sorter.bend 프로그램을 실행합니다 —\n\n```js\nbend run sorter.bend # 러스트 해석기(순차 실행) 사용\nbend run-c sorter.bend # C 해석기(병렬 실행) 사용\nbend run-cu sorter.bend # CUDA 해석기(대규모 병렬 실행) 사용\n```\n\n마지막 명령어는 기기의 GPU를 자동으로 사용하며, 세부 사항을 자세히 다룰 필요가 없습니다.\n\n또한 최대 성능을 위해 Bend 파일을 독립적인 C/CUDA 파일로 컴파일할 수 있지만, 이러한 명령어는 아직 성숙하지 않을 수 있으며 오류를 발생시킬 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nBend는 아직 초기 단계에 있지만 매우 유망해보입니다.\n\n다음 섹션의 자원들은 더 많이 배우고 개발에 참여하는 데 도움을 줄 것입니다. 한번 보세요!\n\n즐거운 병렬 처리!\n\n# 더 많이 알아보기\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- Bend의 GitHub 저장소\n- Bend를 처음부터 배우기\n- Higher-order Virtual Machine 2 (HVM2)의 GitHub 저장소\n- HVM 작동 방식 블로그 포스트\n- HVM 작동 방식 비디오 설명\n- Y. Lafont에 의한 상호 작용 결합 연구 논문\n- Blend의 모기업인 Higher Order Company 웹 사이트\n\n저의 작업과 계속 연락하고 싶다면 이메일 목록 링크를 확인하세요 —\n","ogImage":{"url":"/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png"},"coverImage":"/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png","tag":["Tech"],"readingTime":10},{"title":"용어 해설 AI 시스템 제어하기","description":"","date":"2024-05-20 20:51","slug":"2024-05-20-GlossaryControllingAISystems","content":"\n## 장난기 많은 해독자들\n\n![이미지](/assets/img/2024-05-20-GlossaryControllingAISystems_0.png)\n\n요즘 AI 제어 시스템에 대한 많은 이야기가 나오고 있는데, 그에 이어서 불가피하게 숨통을 헤친 것들이 많아지고 있어요(인터넷 덕분이죠). 공간을 명료하게 만드는 데 도움을 주기 위해 여러 용어를 수집하고, 각 용어에 대한 짧은 설명을 도출해내는 것을 최대한 노력했어요. 그리고 그것들을 그 구성 요소들로 분해해보려고 노력해봤어요:\n\n- 따뜻한 색상: 소프트웨어가 아닌 것\n- 차가운 색상: 소프트웨어\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n노랑: 교육\n주황: 연구\n빨강: 정책/규정\n\n청색: 제품 측면(제품 내부 기능)\n하늘색: 사용자 측면(사용자 능력 향상 도구)\n\n이 57개 항목 중에서 모두 전문가가 될 수 없으니, 약간 틀릴 수밖에 없습니다. 그렇게 많이는 아니지만요 — 사실 확인에 최선을 다하였습니다. 하지만 인간이기 때문에, 제가 미묘한 부분을 잘못 이해했을 경우에는 저에게 토마토를 던지지 말아주시고, 부드럽게 알려주시면 감사하겠습니다. 흥미가 있다면 알파벳으로 정렬된 목록도 아래 텍스트로 제공되었습니다.\n\n그러나 색깔로 구분한 것을 보면 뭔가 흥미로운 점을 알아채셨나요? 핵심 단어를 따라가보세요, 그것들이 관심, 노력 및 투자가 이루어지는 곳과 일치하는 것 같습니다. 그런 식으로 읽으면, 제품 측면이 아닌 인간 측면에 도구를 구축하는 노력이 충분하지 않은 것으로 보입니다. 기술적이지 않은 인간 의사 결정자 및 그들의 조직이 복잡한 기술의 방향을 조정하는 것을 개선할 수 있는 정도보다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n정말 아무것도 없이 순수한 마음만으로 복잡한 기술을 책임있게 다룰 수 있다고 믿는 건가요? 우리가 그런 능력을 갖추기 위해 긴급히 도구를 만들어야 하는 거 아닌가요?\n\n# 알파벳 순 글로시\n\n- AI 책임성 — AI 개발자와 사용자가 자신들의 시스템이 미치는 영향에 대해 책임을 지는 메커니즘을 수립하는 것. [소프트웨어(규칙/정책): 80%, 소프트웨어(연구): 20%]\n- AI 정렬 — 인간의 가치와 의도와 일치하는 AI 시스템의 목표와 행동을 개발하는 것. [소프트웨어(연구): 80%, 소프트웨어(제품): 20%]\n- AI 감사 — AI 시스템을 적합성, 안전성, 도덕적 고려 사항에 대해 평가하고 모니터링하는 것. [소프트웨어(규칙/정책): 70%, 소프트웨어(제품): 30%]\n- 증강지능 — 인간 능력을 대체하는 대신 AI를 통해 향상시키기. [소프트웨어(사용자): 60%, 소프트웨어(제품): 30%]\n- AI 벤치마킹 — AI 시스템을 비교하고 평가하기 위한 표준화된 측정 항목 및 테스트 수립. [소프트웨어(연구): 60%, 소프트웨어(규칙/정책): 40%]\n- AI 편향 완화 — AI 시스템의 편향을 식별하고 줄이는 기술과 방법으로 공정하고 공평한 결과를 보장. [소프트웨어(제품): 70%, 소프트웨어(연구): 30%]\n- AI 능력 구축 — 효율적으로 AI 시스템을 만들고 관리하기 위해 필요한 기술과 지식을 개발. [소프트웨어(교육): 70%, 소프트웨어(제품): 30%]\n- AI 인증 — AI 시스템의 안전성, 신뢰성 및 준수를 인증하기 위한 프로세스 및 표준 수립. [소프트웨어(규칙/정책): 60%, 소프트웨어(제품): 40%]\n- 인지 컴퓨팅 — 복잡한 문제 해결과 의사 결정에서 인간의 사고 과정을 시뮬레이션하는 데 AI 사용. [소프트웨어(제품): 70%, 소프트웨어(사용자): 30%]\n- AI 준수 — AI 시스템이 관련 법률, 규정 및 산업 표준을 준수하도록 보장. [소프트웨어(규칙/정책): 80%, 소프트웨어(제품): 20%]\n- AI 제어 시스템 — AI 시스템의 행동과 작업을 제어하기 위해 설계된 메커니즘. [소프트웨어(제품): 60%, 소프트웨어(연구): 40%]\n  ...\n\n[중략]\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 읽어 주셔서 감사합니다!\n\n저에게서 의사 결정 지능에 대해 배우고 싶으신가요? 무료 강좌 링크가 여기 있어요:\n","ogImage":{"url":"/assets/img/2024-05-20-GlossaryControllingAISystems_0.png"},"coverImage":"/assets/img/2024-05-20-GlossaryControllingAISystems_0.png","tag":["Tech"],"readingTime":3},{"title":"그래프 이론 필수 가이드 18세기 수수께끼부터 인공 지능까지","description":"","date":"2024-05-20 20:46","slug":"2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence","content":"\n![The Essential Guide to Graph Theory: From an 18th Century Riddle to Artificial Intelligence](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_0.png)\n\n안녕하세요! 1736년 프러시아 케니흐스베르크의 번화한 거리를 떠나 떠돌아 보세요. 지금은 러시아 칼리닌그라드로 알려진 이 번창한 항구는 문화적으로도 건축적으로도 경이로운 곳입니다. 프레겔 강 둑을 따라 서성이며 이 도시의 중요한 동맥 중 하나인 이 강은 재주꾼 상인선박들의 먼 바다 속에서 멀리 분주한 시장의 떠들썩함과 만나게 됩니다. 이 강을 가로지르는 일곱 개의 멋진 다리들이 다양한 섬과 동네들을 연결하고 있습니다. 여러분이 걷는 길이 바로 유럽 대륙의 가장 예리한 두뇌들을 괴롭히고 있는 수학적 수수께끼의 기초가 되었다는 사실을 아셨나요.\n\n이곳을 가로지르면서 각 다리를 정확히 한 번씩 건너는 것이 가능한지에 관한 문제를 묻고 있는 것입니다.\n\n![The Essential Guide to Graph Theory: From an 18th Century Riddle to Artificial Intelligence](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_1.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n처음에는 그 문제를 진부하다고 생각했지만, 결국 신생 수학 부문 관리자인 29살의 스위스 수학자 레온하르트 오일러가 러시아 성페테르스부르크 과학 아카데미에서의 끌림을 이기지 못했어. 그 오일러야, \"오일러의 수\"로 유명한 그 오일러야 (이거 떠올리기 즐거우신 상수 e, ≈2.71828로 기억하시겠지). 함수, 합, 그리고 허수 표기법 (f(x), Σ, 그리고 i 각각)을 선보인 그 같은 오일러야, 삼각함수 sin과 cos, 지수 함수 사이의 관계를 보여주는 항등식을 세운 그 대 그 오일러야. 오일러는 버노우이, 가우스, 뉴턴, 라이프니츠와 마찬가지로 여러 분야에 영향을 미친 불안한 수학자 중 하나였지. 현대 과학과 수학 원리를 튼튼하게 다지면서 영원히 그들을 바꿔 놓은 그 오일러야가 바로 그랬어.\n\n만약 이미 좋아하는 수학자가 없다면, 적어도 상위 10명에는 오일러를 고려해 보길 권해드려. 그의 영향력을 과소평가하기 어려운 점이 많아. 그는 분명히 알려진 분야로 진출하고 수학과 과학 지식의 영역을 확장했지만, (논란의 여지는 있지만) 그의 가장 오래된 유산은 복잡한 개념을 단순화하는 데 있어. 오일러가 주요 직관적 개념과 표기법을 도입함으로써 어려운 주제를 보다 직관적으로 다가갈 수 있도록 도왔고, 앞으로 몇 세기 동안의 혁신을 허용하기에 더 나은 단순화를 이룰 수 있도록 했지. 어떤 면에선, 오일러는 머리카락을 잡아끌 수 있는 수학적 고난을 잊기 어렵게 만들었던 소리 없는 영웅인 셈이지 — 거기에 뭔가, 감히 말해보자면 즐거운(?) 게임이 되었던 고난을 —.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n알겠어요. 필수 오일러 감상 랜트를 끝냈으니... 이제 재미있는 내용으로 넘어가 봅시다.\n\n## 절삭 “에지” — 그리고 “버텍스” — 솔루션\n\n오일러의 채티인버그 다리 문제에 대한 혁신적인 접근은 그의 추상적 사고 능력을 드러냈습니다. 그는 대지내의 구체적인 경로보다 다리의 연속이 더 중요하다고 인식했습니다. 이 통찰력을 통해 그는 다리를 연결하는 \"에지\"로 표시된 노드인 지형을, 효과적으로 그래프를 만들어 주는 \"버텍스\"로 나타낸 문제로 변환할 수 있었습니다(그림 3을 참조하세요).\n\n![그림](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_2.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오일러는 그 후에 지금은 \"handshaking lemma\"로 알려진 것을 적용했습니다: 각 다리는 양쪽 땅을 연결하기 때문에 두 번씩 세어집니다. 이는 각 땅에 연결된 다리의 총합이 짝수여야 한다는 것을 의미합니다. 다리의 총 숫자의 두 배입니다. 그러나, 홀수 개의 다리를 가진 홀수 개의 땅이 있는 경우, 통행 가능한 경로가 없게 됩니다.\n\n더 깊이 분석해 보니, 오일러는 이러한 경로가 존재하려면 홀수 개의 다리를 가진 땅이 없거나 두 개여야 한다는 것을 확인했습니다. 케ーニ흐스베르크의 경우, 네 개의 땅 모두 홀수 개의 다리를 가졌기 때문에 각 다리를 정확히 한 번씩 건너는 경로가 불가능했습니다. 이 결론은 지금 그래프 이론에서의 오일러 경로로 이해하게 된 기초를 형성하게 되었습니다.\n\n오일러는 그래프 내 노드와 엣지의 특정 배열은 중요하지 않음을 언급했습니다; 중요한 것은 그들 사이의 연결이라는 것입니다. 이 관찰은 그래프 이론(그리고 최종적으로 위상학 분야)에서 중요한데, 이는 기본 구조를 변경하지 않고 복잡한 네트워크를 대변할 수 있게 해줍니다.\n\n마지막으로, 오일러는 지금은 오일러 경로라고 알려지는 각 엣지를 정확히 한 번씩 통과하는 경로와, 이와 같은 경로가 시작점과 끝점이 동일한 오일러 회로라고 불리는 것 사이에 구별했습니다. 오일러의 이 경로에 대한 기준은 그래프가 연결되어 있고 홀수 차수의 노드가 정확히 제로 또는 두 개일 때 오일러 경로가 존재하며, 그래프가 연결되어 있고 모든 노드가 짝수 차수일 때만 오일러 회로가 존재한다는 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 그래프 이론 오늘 — 선택과 경로\n\n오일러가 케ーニ히스베르크 다리 문제를 해결한 것으로 뿌리를 둔 지적 씨앗은 그래프 이론이라는 건강하고 방대한 나무로 자라났습니다. 그래프 이론은 복잡한 시스템에 대한 우리의 이해를 계속해서 형성하고 있는 프레임워크입니다.\n\n그래프 이론은 객체 간의 쌍 관계를 모델링하는 데 사용되는 수학적 구조를 연구합니다. 이 분야는 정점 또는 노드로 알려진 포인트의 모음으로 실제 세계 문제를 추상화하고, 엣지로 불리는 선분에 의해 연결된 그래프로 나타냅니다.\n\n이러한 단순화는 매우 유용하며, 그래프 이론적 렌즈를 통해 다양한 도메인에서 문제를 분석하고 해결하는 것이 가능합니다. 실제 세부 사항의 혼란을 줄이면서, 그래프 이론은 기술부터 사회과학에 이르기까지 다양한 분야에서 직접적인 경로, 효율적인 연결 및 최적의 해결책을 발견하는 것을 가능하게 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이것의 매력은 네트워크를 모델링하는 능력에만 있는 것이 아닙니다. 그래프의 다양한 유형을 특징 짓는 데 기여하는 것도 있습니다. 각 유형은 가중 그래프, 방향 그래프, 이분 그래프 및 다중 그래프와 같이 파티에 고유한 맛을 불어넣습니다. 이제 옷소매를 걷어차고 상용어로 말하자면 '야생'에서 이러한 그래프를 탐험해봅시다. 우리의 사용 사례에 맞게 몇 가지 Python 데모를 활용하여 이를 직접 만들어보는 방법을 알아보겠습니다. 복잡한 네트워크의 생성, 조작, 및 연구를 위해 설계된 Python 라이브러리인 networkx를 사용할 것입니다.\n\n## 가중 그래프: 적은 이용하는 길\n\n번화한 도시의 도로 네트워크를 고려해보십시오. 모든 도로가 같은 중요도로 만들어지는 것은 아닙니다. 어떤 도로는 도시의 한쪽 끝에서 다른 쪽 끝까지 빠르게 이동할 수 있는 고속도로이며, 다른 도로는 여러분의 인내심을 시험하는 혼잡한 거리입니다. 가중 그래프는 각 에지에 \"가중치\"를 할당하여 이러한 세부 사항을 포착할 수 있습니다. 이 가중치는 건너편으로 이동하는 데 필요한 비용, 거리, 또는 시간을 반영합니다.\n\n```python\nimport networkx as nx #이것은 그다지 흔하지 않은 라이브러리이므로 먼저 pip 설치해야 할 수도 있습니다\nimport matplotlib.pyplot as plt\n\n# 가중 그래프 만들기\nG_weighted = nx.Graph()\n\n# '비용'이 다른 도로를 나타내는 가중 에지 추가\nG_weighted.add_edge('A', 'B', weight=4)\nG_weighted.add_edge('B', 'C', weight=1)\nG_weighted.add_edge('C', 'D', weight=7)\nG_weighted.add_edge('A', 'D', weight=5)\n\n# 노드에 대한 레이아웃 생성\npos = nx.circular_layout(G_weighted)\n\n# 노드 위치에 따라 그래프 그리기\nnx.draw_networkx(G_weighted, pos, with_labels=True, node_color='skyblue', node_size=700)\n\n# 에지 레이블 그리기\nedge_labels = nx.get_edge_attributes(G_weighted, 'weight')\nnx.draw_networkx_edge_labels(G_weighted, pos, edge_labels=edge_labels)\n\n# 그래프 플롯 표시\nplt.title(\"Fig 4a: 가중 그래프: 도시 도로\")\nplt.show()\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n위의 코드를 실행하면 아래와 같은 모습의 그림이 나올 것입니다:\n\n![image](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_3.png)\n\n그다지 화려하지는 않겠지만, 이게 바로 포인트입니다. 더 복잡한 시나리오를 나타내는 데 확장할 수 있으면서도, 우리가 관심 있는 것만 단순하게 유지하고 불필요한 데이터의 이슈를 해결할 수 있습니다.\n\n모델에서 엣지에 있는 가중치는 현실적인 요소를 더해줍니다. 예를 들어 높은 가중치는 긴 도로나 혼잡한 교통이 있는 도로를 나타낼 수 있으며, 이를 통해 계획자들이 병목 현상을 식별하거나 인프라 향상이 필요한 지역을 찾는 데 도움이 됩니다. 결국, 때로는 무엇을 해야할지 모를 만큼 많은 데이터를 보유하고 있는 세상에서 가장 중요한 질문은 종종 다음과 같습니다: 특정 결정을 내리기 위해 정말 필요한 정보는 무엇인가요? 나머지는 그저 소음뿐입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그림 4a의 그래프 유형을 사용하면 알고리즘을 적용하여 가장 짧은 경로를 찾거나 트래픽 흐름을 최적화하거나 심지어 새 도로 건설을 계획할 수 있습니다. 도시의 연결성과 효율성을 향상시키기 위해 데이터 기반 의사결정에 강력한 도구가 됩니다. 이러한 그래프는 다음과 같은 분야에 중요할 수 있습니다:\n\n- 교통 관리: 가중 그래프를 분석함으로써 관할 당국은 교통이 집중되는 경로를 식별하고 대응함으로써 통근 시간을 단축하고 혼잡을 줄일 수 있습니다.\n- 인프라 계획: 계획자들은 서비스가 부족한 지역이나 새 도로나 대중교통 연결 공간의 잠재적 사이트를 발견할 수 있어 도시의 성장과 발전을 위해 더 나은 환경을 조성할 수 있습니다.\n- 비상 대응 최적화: 비상 서비스는 이러한 그래프를 사용하여 가장 빠른 경로를 결정하여 환경적인 상황에서 시기적극적인 대응을 보장할 수 있습니다.\n\n## 방향성 있는 그래프: 일방향 디지털 흐름\n\n이제 방향성 있는 그래프로 이동해 보겠습니다. 여기서 관계는 방향이 있는데, 마치 일방통행거리나 인터넷에서의 정보 흐름과 유사합니다. 가중 그래프는 각 엣지에 값을 할당하여 거리나 비용과 같은 특성을 양적으로 표현하지만, 방향성 있는 그래프는 정보의 흐름에 집중합니다. 가중 에지는 거리나 날짜에 따라 변경되는 통행료가 있는 도로와 같으며, 방향성 있는 에지는 한 방향 도로로, 엄격하게 A 지점에서 B 지점으로의 움직임을 허용합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리는 웹사이트 내 개별 웹페이지를 나타내는 노드로 디지털 수퍼하이웨이의 스냅샷을 만들 것입니다. 방향성을 가진 엣지들은 사용자가 정보를 찾을 때 이동할 수 있는 단방향 경로를 강조합니다.\n\n```js\n# 마지막 예제와 다른 커널에서 작업 중인 경우, 필요한 라이브러리를 가져와야 합니다\n# 방향 그래프 생성\nG_directed = nx.DiGraph()\n\n# 방향을 갖는 엣지 추가. 각 노드는 하나의 웹페이지를 나타냅니다. 각 방향성을 가진 엣지는 한 페이지에서 다른 페이지로 이어지는 하이퍼링크입니다\nG_directed.add_edge('Page 1', 'Page 2')\nG_directed.add_edge('Page 1', 'Page 3')\nG_directed.add_edge('Page 2', 'Page 4')\n\n# 그래프 시각화\npos = nx.spring_layout(G_directed)\nnx.draw_networkx(G_directed, pos, with_labels=True, arrows=True)\nplt.title(\"Fig 4b: Directed Graph: Web Pages\")\nplt.show()\n```\n\n<img src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_4.png\" />\n\n웹 내비게이션에서 이는 사용자가 한 페이지에서 다른 페이지로 이동할 수 있지만 반대로는 그렇지 않음을 의미합니다. 이 흐름을 이해하는 것은 다양한 응용 프로그램에 매우 중요합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 콘텐츠 접근성: 상호 액세스 없이 단방향 링크 뒤에 가치 있는 콘텐츠가 갇히지 않도록 보장합니다.\n- 사이트 구조: 사용자가 막다른 곳에 도달하지 않고 일반 콘텐츠에서 보다 구체적인 페이지로 자연스럽게 이동할 수 있도록 웹사이트의 구조를 설계합니다.\n- 정보 계층 구조: 사용자가 소개 정보에서 상세 콘텐츠로 안내되는 명확한 경로를 수립하여 사이트의 정보 구조를 반영합니다.\n\n이 경우 Fig 4b를 사용하여 디지털 트래픽의 경로를 설명하는 방향 그래프를 사용해 웹사이트의 구조를 통해 사용자가 어떻게 이동할 수 있는지, 각 페이지가 어떻게 상호 연결되어 사이트의 구조를 형성하는지 이해할 수 있었습니다. 이해는 웹 개발자부터 디지털 마케터에 이르기까지 디지털 콘텐츠의 디자인 및 관리에 관여하는 모든 사람들에게 기본적입니다.\n\n## 이분 그래프: 선호도와 예측 사이의 다리\n\n이분 그래프는 연결이 각 클래스 내에서 아닌 두 가지 다른 객체 클래스 사이에만 존재하는 독특한 방식으로 두 가지 서로 다른 객체 클래스를 나타내는 방법을 제공합니다. 두 가지 다른 그룹 사이의 춤으로 생각해보세요. 한 그룹의 각 구성원은 다른 그룹의 구성원과 춤을 추거나 할 수 있지만 자신의 그룹과는 춤을 추지 않습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 Python 데모에서는 추천 시스템의 작은 부분을 모델링하기 위해 이분 그래프를 생성합니다. 사용자를 나타내는 노드 세트와 책, 영화 또는 기타 추천 가능한 엔티티가 될 수 있는 아이템을 나타내는 노드 세트 두 개를 정의합니다. 에지를 추가하여 사용자와 항목을 연결하며 선호도나 상호 작용을 나타냅니다. nx.bipartite_layout 함수를 사용하여 시각적으로 두 세트를 분리하여 구분과 연결을 명확히합니다.\n\n```python\n# 마지막 예제와 다른 커널에서 작업하는 경우 필요한 라이브러리를 가져오는 것을 기억하세요\n# 그래프 인스턴스 생성\nB = nx.Graph()\n\n# \"bipartite\" 노드 속성을 가진 노드 추가\nB.add_nodes_from(['User1', 'User2', 'User3'], bipartite=0)  # 사용자\nB.add_nodes_from(['Book1', 'Book2', 'Movie1', 'Movie2'], bipartite=1)  # 항목\n\n# 서로 다른 세트의 노드 간에 엣지 추가\nB.add_edges_from([('User1', 'Book1'), ('User1', 'Movie2'),\n                  ('User2', 'Book2'), ('User2', 'Movie1'),\n                  ('User3', 'Book1'), ('User3', 'Movie1')])\n\n# B가 이분 그래프인지 확인\nprint(nx.is_bipartite(B))  # 출력: True\n\n# 이분 그래프를 그림\npos = nx.bipartite_layout(B, ['User1', 'User2', 'User3'])\nnx.draw_networkx(B, pos, with_labels=True)\nplt.title(\"Figure 4c: Bipartite Graph: Recommendation System\")\nplt.show()\n```\n\n<img src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_5.png\" />\n\n이분 그래프는 스트리밍 서비스, 전자상거래 플랫폼 및 소셜 네트워크에서 사용되는 추천 시스템에서 특히 효과적입니다. 이들은 아래와 같은 면에서 도움이 됩니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 개인화(Personalization): 사용자-항목 상호작용을 분석하여, 사용자가 이전에 상호작용했던 항목과 유사한 항목을 제안해 컨텐츠를 개인화할 수 있습니다.\n- 협업 필터링(Collaborative Filtering): 이러한 그래프는 협업 필터링을 가능하게 하며, 비슷한 사용자들의 선호도에 기반하여 추천을 제공합니다.\n- 네트워크 분석(Network Analysis): 연결성과 클러스터 패턴을 이해함으로써, 명확한 마케팅 및 사용자 행동 이해에 도움이 됩니다.\n\n이분 그래프는 추천 엔진 내에서의 관계의 본질을 추상화하여, 사용자가 다음에 좋아할 것으로 예측하고 제안함으로써 사용자 경험을 강화하는 간소화된 유용한 방법을 제공합니다.\n\n# 인공지능을 위한 그래프 이론의 유용한 개념 - 지도학습(Supervised Learning)\n\n## 그래프로 시각화하는 신경망(Visualizing Neural Networks as Graphs)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n인공 지능과 기계 학습에서 그래프 이론에 의해 제공되는 추상 모델은 중요합니다. 예를 들어 신경망의 구조를 자세히 들여다보면 그래프가 당신을 노려보고 있는 것을 볼 수 있습니다. 각 뉴런은 노드이고 각 시냅스 가중치는 이야기가 담긴 간선입니다. 입력에서 출력 레이어로 데이터 경로는 방향 그래프의 탐색을 흉내냅니다. 이 그래프 중심적 관점은 메타포에 그치지 않습니다. TensorFlow와 같은 프레임워크에서 연산의 구조적 현실입니다. 이 그래프 기반 표현은 데이터로부터 학습하고 패턴을 인식하며 결정을 내릴 수 있는 알고리즘을 개발하는 데 중요합니다. 이 추상화를 통해 인공 지능 시스템은 인간의 사고 과정의 복잡성을 근사할 수 있습니다.\n\n우리는 방향 그래프를 사용하여 밀도가 높은 연결된 신경망의 표현을 구축할 것입니다. 이 신경망은 두 개의 입력 노드, 두 개의 은닉층(첫 번째 층에는 두 개의 노드, 두 번째 층에는 세 개의 노드) 및 하나의 출력 노드로 구성됩니다. 레이어의 각 노드는 다음 레이어의 노드와 완전히(\"조밀하게\") 연결됩니다.\n\n이러한 시각화 방법은 우리가 한눈에 신경망의 구조를 이해하는 데 도움을 줍니다. 각각의 처리 레이어를 통해 입력 데이터로부터의 정보 흐름을 명확히하며 각각이 입력 데이터로부터 고유한 방식으로 학습하는 것에 기여합니다. 이러한 모델을 설계할 때 신경망의 깊이와 복잡성에 대한 통찰을 제공하기 때문에 중요합니다.\n\n```js\n#직전 예제와 다른 커널에서 작업 중이라면 필요한 라이브러리를 가져와야 합니다.\n#신경망을 모델링하기 위해 NetworkX DiGraph를 초기화합니다.\nneural_net = nx.DiGraph()\n\n#입력 레이어를 위한 노드 추가\nneural_net.add_nodes_from(['Input1', 'Input2'], layer='input')\n\n#첫 번째 은닉층을 위한 노드 추가(2개의 노드)\nneural_net.add_nodes_from(['Hidden1_1', 'Hidden1_2'], layer='hidden1')\n\n#두 번째 은닉층을 위한 노드 추가(3개의 노드)\nneural_net.add_nodes_from(['Hidden2_1', 'Hidden2_2', 'Hidden2_3'], layer='hidden2')\n\n#출력 레이어를 위한 노드 추가\nneural_net.add_node('Output', layer='output')\n\n#시냅스를 나타내는 간선을 사용하여 노드 연결 및 가중치 추가\n#가중치 라벨링 규칙은 'w(현재 노드 인덱스)_(연결 노드 인덱스) 입니다.\nweights = {\n    ('Input1', 'Hidden1_1'): 'w1_3', ('Input2', 'Hidden1_1'): 'w2_3',\n    ('Input1', 'Hidden1_2'): 'w1_4', ('Input2', 'Hidden1_2'): 'w2_4',\n    ('Hidden1_1', 'Hidden2_1'): 'w3_5', ('Hidden1_1', 'Hidden2_2'): 'w3_6', ('Hidden1_1', 'Hidden2_3'): 'w3_7',\n    ('Hidden1_2', 'Hidden2_1'): 'w4_5', ('Hidden1_2', 'Hidden2_2'): 'w4_6', ('Hidden1_2', 'Hidden2_3'): 'w4_7',\n    ('Hidden2_1', 'Output'): 'w5_8', ('Hidden2_2', 'Output'): 'w6_8', ('Hidden2_3', 'Output'): 'w7_8'\n}\n\nfor (u, v), weight in weights.items():\n    neural_net.add_edge(u, v, weight=weight)\n\n#각 노드의 위치를 명확히 하기 위해 수동으로 설정\npos = {\n    'Input1': (0, 1), 'Input2': (0, -1),\n    'Hidden1_1': (1, 1), 'Hidden1_2': (1, -1),\n    'Hidden2_1': (2, 2), 'Hidden2_2': (2, 0), 'Hidden2_3': (2, -2),\n    'Output': (3, 0)\n}\n\n#플로팅을 위한 figure 생성\nfig, ax = plt.subplots(figsize=(12, 8))\n\n#가중치에 대한 에지 라벨 작성\nedge_labels = nx.get_edge_attributes(neural_net, 'weight')\n\n#에지 라벨 포지션 조절(중첩 방지)\nedge_label_pos = {}\nfor edge in neural_net.edges():\n    u, v = edge\n    #중간점 계산 및 라벨 위치 조정\n    mid_x = (pos[u][0] + pos[v][0]) / 2\n    mid_y = (pos[u][1] + pos[v][1]) / 2\n    delta_x = pos[v][0] - pos[u][0]\n    delta_y = pos[v][1] - pos[u][1]\n    if abs(delta_x) > abs(delta_y):\n        edge_label_pos[edge] = (mid_x, mid_y + 0.1)  #수평 에지를 위한 y 오프셋 조정\n    else:\n        edge_label_pos[edge] = (mid_x + 0.1, mid_y)  #수직 에지를 위한 x 오프셋 조정\n\n#신경망 그래프 그리기\nnx.draw_networkx(neural_net, pos, with_labels=True, node_size=1000, node_color='skyblue', arrowsize=20, font_size=10)\n\n#가중치에 대한 에지 라벨 작성\nedge_labels = nx.get_edge_attributes(neural_net, 'weight')\n\n#조정된 위치에 에지 라벨 그리기\nfor (u, v, d) in neural_net.edges(data=True):\n    edge_weight = d['weight']\n    x, y = (pos[u][0] * 0.6 + pos[v][0] * 0.4), (pos[u][1] * 0.6 + pos[v][1] * 0.4)\n    txt = plt.text(x, y, edge_weight, ha='center', va='center', rotation=0, fontsize=8)\n\n#제목 설정\nax.set_title(\"Fig 5a: Neural Network Graph (Directed and Weighted) with Two Hidden Layers\")\n\n#플롯 표시\nplt.show()\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_6.png)\n\n신경망을 그래프로 모델링하면 그들의 구조를 이해하고 전달하는 강력한 도구를 얻습니다. 그래프 기반 접근법은 다음과 같은 것이 가능합니다:\n\n- 복잡성 시각화: 신경 계산의 상호 연결된 특성을 시각화할 수 있습니다. 뉴런과 그들의 연결을 배치함으로써, 데이터 내의 복잡한 패턴 및 관계가 어떻게 감지되고 처리되는지 볼 수 있습니다.\n- 아키텍처 디버깅 및 최적화: 병목 현상이나 중복 연결을 식별하는 것이 더 쉬워집니다. 이는 특히 딥 러닝에서 유용할 수 있습니다. 여기서 레이어와 노드의 수를 조정하는 것이 성능에 미치는 영향이 상당할 수 있습니다.\n- 연구 및 개발 지원: 연구자들은 그래프를 사용하여 새로운 네트워크 아키텍처를 제안하고 테스트할 수 있습니다. 그래프의 구조를 조정함으로써, 정보 처리의 새로운 방법을 실험해볼 수 있습니다.\n\n신경망을 그래프로 추상화함으로써, 우리는 모델을 분석하기 위한 다양한 그래프 이론 도구와 지표를 활용할 수도 있습니다. 이는 최단 경로를 조사하는 것(입력부터 출력까지의 가장 적은 변환 횟수를 이해하기 위해), 네트워크 중심성(가장 중요한 뉴런을 찾기 위해) 또는 심지어 커뮤니티 탐지(긴밀하게 협력하는 뉴런 군집 식별)를 포함할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 의사 결정 트리: 가지치기 그래프\n\n의사 결정 트리는 핵심적으로 루트 노드에서 시작하여 잎 노드로 가는 그래프로, 그 구조에 의사 결정의 본질을 담고 있습니다. 노드는 질문이나 결정을 나타내며, 간선은 데이터의 답변을 기반으로 취해진 경로를 표현합니다. 그래프 이론적으로 의사 결정 트리는 방향성이 있고 비순환적인 그래프(DAGs)로, 각 방향 간선은 질문에서 답변으로의 흐름을 나타내어 연속된 질문이나 최종 결정으로 이어집니다. 이 구조는 계층적이며 루트에서 잎까지의 명확한 방향을 나타내며, 잎은 결과를 표현합니다.\n\n우리는 이 그래프 기반의 의사 결정 과정을 클래식한 붓꽃 데이터셋에 적용할 것입니다. 이 데이터셋은 붓꽃의 150개 샘플로 구성되어 있고, 각각의 특징으로서 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 그리고 꽃잎 너비를 설명합니다. 데이터셋은 세 종류의 붓꽃 종(Sestosa, Versicolor, Virginica) 샘플을 담고 있습니다. 우리의 의사 결정 트리는 이러한 특징들로부터 학습을 통해 붓꽃의 종을 정확하게 예측할 것입니다.\n\n의사 결정 트리의 추상적인 개념을 구체적인 그래프로 번역하고자 하며, 의사 권하는 networkx를 계속 활용하여 의사 결정의 흐름을 시각화할 것입니다. 우리는 붓꽃 데이터셋을 사용하여 각 특징을 결정 노드로 사용하고, 해당 값에 따라 가지를 친 의사 결정 트리를 구성할 것입니다. 이는 최종적으로 붓꽃의 종을 예측하는 경로를 제공합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\n# 아이리스 데이터세트 불러오기\niris = load_iris()\nX, y = iris.data, iris.target\n\n# 아이리스 데이터를 기반으로 의사결정 트리 분류기 훈련\nclf = DecisionTreeClassifier()\nclf.fit(X, y)\n\n# sklearn의 plot_tree를 사용하여 트리 그리기\nplt.figure(figsize=(20, 10))  # 그림의 크기 설정\nplot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\nplt.title(\"Fig 5b: 의사결정 트리 그래프 표현\")\nplt.show()\n```\n\n<img src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_7.png\" />\n\n의사결정 트리는 기계 학습에서 그래프 이론의 중요성을 전통적으로 보여주며, 알고리즘의 단계별 논리를 명확히 제시하는 구조를 제공합니다. 이 경우에는 방향 그래프의 간단한 구조가 필요에 따라 확장되어 시작부터 끝까지 알고리즘의 결정 경로를 보여줍니다. 이는 알고리즘이 데이터를 처리하여 특정 결론에 도달하는 방식에 대한 직관적인 이해를 제공하며, 지능적이고 데이터 중심의 솔루션을 개발하는 데 그래프 이론의 실용적인 응용을 보여줍니다.\n\n# 그래프 이론의 인공지능에 유용한 추상화 — 비지도 학습\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n비지도 학습, 특히 클러스터링은 데이터 내의 관계를 활용하여 그룹이나 클러스터를 형성함으로써 그래프 이론에서 상당한 이득을 얻습니다. 그래프 이론은 클러스터링에 그 자체에만 있는 것이 아닙니다. 데이터의 기본 구조와 연결을 강조함으로써 이러한 기술을 이해하고 구현하는 방법을 개선할 수 있습니다.\n\n클러스터링은 동일한 클러스터에 속하는 객체들이 다른 클러스터에 속한 객체들보다 서로 더 유사하도록 하는 것을 목표로 합니다. 그래프 이론은 데이터 포인트를 노드로, 이러한 포인트 간의 유사성이나 거리를 엣지로 나타내어 그래프를 형성함으로써 클러스터링을 용이하게 합니다. 이 접근 방식은 연결성 및 네트워크 구조를 기반으로 한 자연적인 그룹화를 드러내는 데 특히 유용하며 전통적인 벡터 공간 표현에서 가려진 경우가 많습니다.\n\n## 스펙트럼 클러스터링: 그래프 기반 접근 방식\n\n스펙트럼 클러스터링은 그래프 이론을 데이터의 그래프 구조를 포착하는 라플라시안 행렬을 사용하여 클러스터링 기술에 통합시킬 수 있는 좋은 예입니다. 그 핵심은 다음과 같이 작동합니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 그래프 표현: 스펙트럴 클러스터링은 각 데이터 포인트를 그래프의 노드로 취급하여 시작합니다. 데이터 포인트 간의 유사성이나 차이는 이러한 노드를 연결하는 엣지로 간주됩니다. 각 엣지의 강도나 가중치는 선택한 기준인 유클리드 거리나 다른 유사성 측정에 따라 두 점이 서로 얼마나 유사하거나 가까운지를 반영합니다.\n- 라플라시안 행렬 구성: 라플라시안 행렬은 그래프 표현에서 유도되며 노드 간의 연결성을 이해하는 데 중요합니다. 이 행렬은 그래프의 구조를 이해하는 데 도움이 되며 클러스터링 프로세스에 중요합니다. 이는 그래프의 인접 행렬에서 차수 행렬을 뺌으로써 유도됩니다. 인접 행렬은 노드 사이의 엣지 가중치를 기록하고, 차수 행렬은 노드에 연결된 엣지 가중치의 합을 나타내는 대각선 행렬입니다.\n- 라플라시안 행렬 분해: 다음 단계는 라플라시안 행렬을 분해하여 그 고유값과 해당하는 고유벡터를 추출하는 것입니다. 고유값은 그래프의 연결성에 대한 정보를 드러내고, 고유벡터는 데이터를 새로운 저차원 공간으로 투영하는 데 사용됩니다.\n- 데이터 투영: 가장 작은 비제로 고유값에 해당하는 고유벡터를 사용하여 데이터를 새로운 공간으로 투영합니다. 이 단계는 고차원 데이터를 클러스터가 더 분리되어 식별하기 쉬운 형태로 변환합니다.\n\n다시 말해, 스펙트럴 클러스터링은 복잡한 데이터셋 내에 내재된 구조를 효과적으로 드러내고 활용하기 위해 그래프 이론을 활용하며, 비정형 모양의 클러스터를 식별하는 데 특히 강력합니다.\n\n이제 \"두 달\" 데이터셋을 사용하여 스펙트럴 클러스터링을 시연할 것이며, 이를 통해 비선형 경계를 갖는 클러스터를 탐지하는 방법의 효과를 보여줄 것입니다. (그림 6a 참조)\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom sklearn.cluster import SpectralClustering\n\n# 두 달 데이터셋 생성\nX, _ = make_moons(n_samples=200, noise=0.1, random_state=42)\n\n# \"가장 가까운 이웃\" 클러스터링을 사용하여 스펙트럴 클러스터링 적용\nsc = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', n_neighbors=10)\nlabels = sc.fit_predict(X)\n\n# 결과 플롯\nplt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', edgecolor='k')\nplt.title('Fig 6a: 두 달 데이터의 스펙트럴 클러스터링')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.show()\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_8.png\" />\n\n오일러의 스위스 뿌리를 기리며, 더 복잡한 배열과 고차원에서이 전략이 어떻게 더 유용해지는지 모델링하여 클러스터링 알고리즘의 능력을 테스트하는 데 자주 사용되는 클래식 데이터 세트 인 스위스 롤 모양을 살펴보겠습니다. 특히 복잡한 매니폴드 구조를 가진 데이터를 해독할 수있는 알고리즘 (Fig 6b 참조) 입니다. 이 경우에는 스위스 롤 모양을 구성하는 포인트 (노드)를 두 가지 서로 다른 클러스터로 구분 할 수있을까요?\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_swiss_roll\nfrom sklearn.cluster import SpectralClustering\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# 2000개의 샘플과 잡음 수준이 0.1인 스위스 롤 데이터 세트 생성\nX, _ = make_swiss_roll(n_samples=2000, noise=0.1, random_state=42)\n\n# 2개의 클러스터에 Spectral Clustering를 적용하고 \"최근 이웃\" 친화성을 사용합니다.\n# 결과를 확인하기 위해 더 많은 클러스터를 시도해보세요.\nsc = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', n_neighbors=10)\nlabels = sc.fit_predict(X)\n\n# 3D 산점도로 결과 플롯하기\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X[:, 0], X[:, 2], X[:, 1], c=labels, cmap='viridis', edgecolor='k')\nax.set_title('Fig 6b: 스위스 롤 데이터의 스펙트럴 클러스터링')\nax.set_xlabel('특성 1')\nax.set_ylabel('특성 3')\nax.set_zlabel('특성 2')\nplt.show()\n```\n\n<img src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_9.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 클러스터링에서 그래프 이론의 유틸리티 및 통찰\n\n- 데이터의 그래픽 표현: 데이터를 그래프로 시각화하면 클러스터링 알고리즘이 공간이 높은 경우와 같이 데이터의 실제 구조를 더 잘 파악할 수 있습니다. 이 그래픽 관점은 접근성이나 밀도에만 의존하는 대신 점들이 어떻게 상호 연결되어 있는지에 기초하여 클러스터를 식별할 수 있도록 합니다.\n- 복잡한 구조 다루기: 그래프 이론은 이음매가 얽힌 나선이나 동심원 같은 복잡한 모양을 형성하는 데이터를 처리하는 데 뛰어나며, 기존의 중심 또는 밀도 기반 클러스터링 방법이 실패할 수 있는 상황에서 능력을 발휘합니다.\n- 유연성과 다양성: 그래프 기반 클러스터링 방법은 다양한 종류의 데이터를 처리하는 데 다재다능하며 다양한 유사성 측정에 적응할 수 있어 데이터의 불규칙성과 잡음에 대해 견고합니다.\n- 시각화와 해석: 그래프 기반 방법은 클러스터링 성능을 향상시키는 데 그치지 않고 결과의 해석 가능성을 향상시킵니다. 클러스터가 어떻게 형성되는지 명확한 시각적 통찰을 제공하여 데이터 분석과 의사 결정 프로세스에 매우 가치 있는 정보를 제공합니다.\n\n그래프 이론을 통합하면 Spectral Clustering은 비지도 학습에서 전통적인 클러스터링 접근 방식의 한계를 극복할 뿐만 아니라 데이터의 고유 구조와 보다 일치하는 방식으로 데이터를 분석하는 새로운 가능성을 열어줍니다.\n\n# 현대 AI 기반 제품에서의 그래프 이론\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nMicrosoft Copilot은 그래프 이론 원리가 제품의 유용성을 궁극적으로 향상시키는 데 사용될 수 있는 한 예입니다. 이 경우에는 다양한 데이터 유형과 소스를 데이터 생태계 전반에 걸쳐 연결함으로써 사용자 상호작용을 개선합니다.\n\nCopilot의 그래프 이론적 기초는 사용자 상호작용을 문맥화하고 개인화하는 능력에 나타납니다. Copilot은 연결된 지점으로의 방대한 데이터 네트워크를 분석함으로써 사용자의 현재 문맥에 관련된 정보를 종합하고 생성할 수 있습니다.\n\n## Copilot의 그래프 이론 기반 메커니즘 이해\n\nMicrosoft Copilot은 사용자 프롬프트와 조직 데이터를 복잡한 상호 연결 정보 그래프로 변환하여 작동합니다. 이 그래프는 정적 개체가 아니며, 새로운 데이터의 흡수 및 사용자 상호작용을 통해 지속적으로 업데이트되고 풍부화됩니다. 여기서 노드는 데이터 포인트를 나타내고 엣지는 그들 사이의 관계를 반영하며, 데이터 포인트 사이의 다양한 직간접 관계를 고려합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 데이터 수집 및 스키마 생성: Copilot 운영의 핵심은 다양한 소스에서 통합 및 모델링된 데이터가 있는 Microsoft Graph에 있습니다. 여기서 데이터는 단순히 저장되는 것이 아니라 교차 연결성을 반영하는 스키마에 따라 구조화됩니다. 새로운 데이터가 통합되고 사용자 상호 작용이 발전함에 따라 기본 그래프는 성장하고 적응하여 시간이 지남에 따라 Copilot의 학습 능력을 향상시키고 응답을 개선합니다.\n- 데이터 색인 및 쿼리 처리: Copilot이 이 방대한 그래프에서 관련 데이터 포인트를 검색하는 것은 색인 및 쿼리 처리 능력에 달려 있습니다. 이 프로세스들은 AI 도구가 데이터 그래프를 탐색하고 그래프 이론적 모델에서 최단 경로를 찾을 수 있도록 합니다.\n- 내용 이해 및 응답 생성: 그래프 이론 원칙을 활용하여, Copilot은 상호작용의 내용을 \"이해\"합니다. 사용자 쿼리와 데이터를 독립적으로 보는 것이 아니라 더 큰 구조의 일부로 간주합니다. 이 관점을 통해 Copilot은 데이터 노드 간의 연결의 근접성과 강도를 고려하는 그래프의 위상학에 기반한 응답을 수립할 수 있습니다. 데이터의 그래프 구조를 활용하여, Copilot은 사용자의 요구를 더 직관적이고 반영적인 맥락에 맞게 제공할 수 있습니다.\n\n# 마무리하며\n\n끝까지 와서 축하드립니다! 우리는 그래프 이론의 매혹적인 세계를 탐험했습니다. 오일러의 쾨닉스베르크 다리 문제로부터 현대 기술에서의 중요한 역할까지 그 발전을 추적해 왔습니다. 노드와 엣지의 추상화가 복잡한 시스템을 간단하게 만들어 혁신적인 해결책을 이끌어 내는 방법을 확인했습니다. 복잡한 관계를 이해 가능한 모델로 분해하는 것으로, 우리는 그래프 이론이 최적화된 정보 처리, 패턴 발견 및 데이터 기반 결정을 효율적으로 처리할 수 있는 능력을 향상시킨다는 것을 발견했습니다. 이러한 원칙들은 알고리즘의 복잡성을 향상시키는 것뿐만 아니라 정보를 조직하고 검색하는 방식을 최적화합니다.\n\n만약 제가처럼 ML 문제 해결의 세부 사항에 빠져들기를 즐기신다면, LinkedIn 및 Medium에서 팔로우해 주세요. 함께하면 하나의 현명한 해결책으로 AI 미궁을 탐험해 나갈 수 있습니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음 알고리즘 모험까지 계속 탐험하고, 계속 배우고, 노드를 계속 연결해 보세요! 데이터 과학의 그래프를 탐험하는 여정이 그 자체의 추상화만큼 명확하고 통찰력 있기를 바랍니다.\n\n참고: 저자가 아닌 경우를 제외하고 모든 이미지는 저자의 것입니다.\n","ogImage":{"url":"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_0.png"},"coverImage":"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_0.png","tag":["Tech"],"readingTime":26},{"title":"머신 러닝을 위한 피처 엔지니어링","description":"","date":"2024-05-20 20:42","slug":"2024-05-20-FeatureEngineeringforMachineLearning","content":"\n## 알고리즘이 마법을 발휘할 수 있도록 허용하기\n\n![image](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_0.png)\n\n“\\`쓰레기를 넣으면 쓰레기가 나온다\\` 라는 속담을 들어보셨나요? 이 속담은 기계 학습 모델을 훈련할 때 실제로 적용되는 내용입니다. 무관한 데이터를 사용하여 기계 학습 모델을 훈련하면 최고의 기계 학습 알고리즘도 큰 도움이 되지 않습니다. 반면, 잘 설계된 의미 있는 특성을 사용하면 단순한 기계 학습 알고리즘조차 우수한 성능을 달성할 수 있습니다. 그렇다면, 어떻게 우리 모델의 성능을 극대화할 의미 있는 특성을 만들 수 있을까요? 그 해답은 기능 엔지니어링에 있습니다. 전통적인 기계 학습 알고리즘(회귀, 결정 트리, 서포트 벡터 머신 등)을 사용할 때 특히 중요한 작업입니다. 그러나 이러한 숫자 입력을 생성하는 것은 데이터 기술뿐만 아니라 창의력과 도메인 지식도 요구하는 프로세스이며 과학의 영역만큼 예술도 요구합니다.\n\n일반적으로, 기능 엔지니어링을 두 가지 구성 요소로 나눌 수 있습니다: 1) 새로운 기능 생성 및 2) 이러한 기능을 처리하여 해당 기계 학습 알고리즘과 최적으로 작동하도록 만드는 과정입니다. 이 글에서는 횡단면, 구조화된, NLP가 아닌 데이터 집합에 대한 기능 엔지니어링의 이 두 가지 구성 요소에 대해 논의하겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 새로운 기능 생성\n\n원시 데이터 수집은 지치는 작업일 수 있습니다. 이 작업이 끝날 때쯤에는 추가 기능을 만들기 위해 더 많은 시간과 에너지를 투자하기 힘들 수도 있습니다. 하지만 여기서 모델 훈련에 곧바로 뛰어들지 말아야 합니다. 제 약속드립니다, 그 작업이 노력할 가치가 충분할 것입니다! 이 지점에서 우리는 멈추고 스스로에게 물어봐야 합니다. \"내 도메인 지식을 기반으로 수동으로 예측을 한다면, 어떤 기능이 좋은 결과를 도와줬을까요?\" 이 질문을 던짐으로써, 우리의 모델이 그렇지 않았을지도 모르는 새로운 의미 있는 기능을 만들어내는 가능성을 열 수 있습니다. 추가로 어떤 기능이 도움을 줄 수 있는지 고려했다면, 아래 기술들을 활용하여 원시 데이터로부터 새로운 기능을 만들어낼 수 있습니다.\n\n## 1. 집계\n\n이 기법은 이름 그대로 여러 데이터 포인트를 결합하여 더 통합된 관점을 만들 수 있게 도와줍니다. 우리는 일반적으로 count, sum, average, minimum, maximum, percentile, standard deviation, variation 계수와 같은 표준 함수를 사용하여 연속적인 수치 데이터에 집계를 적용합니다. 각 함수는 다른 정보 요소들을 포착할 수 있으며, 사용할 최상의 함수는 특정 사용 사례에 따라 다릅니다. 종종, 우리는 그 문제의 맥락상 의미 있는 특정 시간이나 사건 창을 통해 집계를 적용할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n가져온 신용 카드 거래가 사기인지 예측하려고 하는 예시를 살펴봅시다. 이 경우에는 거래별 특징을 사용할 수 있겠지만, 이러한 특징들과 함께 고객 단위의 집계된 특징을 만드는 것이 유익할 수 있습니다:\n\n- 고객이 지난 다섯 년 동안 사기 피해자가 된 횟수: 이전에 여러 차례 사기 피해자가 된 고객은 다시 사기 피해자가 될 가능성이 높을 수 있습니다. 따라서 이러한 집계된 고객 단위의 관점을 사용하면 적절한 예측 신호를 제공할 수 있습니다.\n- 마지막 다섯 거래 금액의 중앙값: 신용 카드가 침해당했을 때, 사기꾼들은 카드를 테스트하기 위해 여러 차례 저가 거래를 시도할 수 있습니다. 지금은 단일 저가 거래가 매우 일반적이고 사기의 징후가 될 수 없지만, 짧은 시간 동안 많은 이러한 거래를 보게 된다면, 침해된 신용 카드를 나타낼 수 있습니다. 이러한 경우를 위해, 마지막 몇 거래 금액을 고려하는 집계된 특징을 만들 수 있습니다.\n\n![Feature Engineering for Machine Learning](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_1.png)\n\n## 2. Differences and Ratios\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n많은 유형의 문제에서 집합 패턴의 변경은 예측이나 이상 탐지에 대한 유용한 신호가 될 수 있습니다. 차이와 비율은 숫자 특성의 변화를 나타내는 효과적인 기술입니다. 집계와 마찬가지로 이러한 기술들을 그 문제의 맥락에서 의미 있는 시간 창 위에도 적용할 수 있습니다.\n\n예시:\n\n- 지난 1시간 동안의 새 상인 거래의 백분율과 지난 30일 동안의 새 상인 거래의 백분율 간의 차이: 빠른 연속으로 발생하는 많은 새 상인 거래의 높은 비율은 사기 위험을 나타낼 수 있지만, 이 행동이 고객의 과거 행동과 비교하여 변경된 것을 보면 더 명백한 신호가 됩니다.\n- 현재 날짜의 거래 건수를 지난 30일간의 중앙값 일일 거래 건수로 나눈 비율: 신용카드가 침해를 당하면 짧은 시간 동안 많은 거래가 발생할 가능성이 높으며, 이는 과거 신용카드 사용 패턴과 일치하지 않을 수 있습니다. 현재 날짜의 거래 건수를 지난 30일간의 중앙값 일일 거래 건수로 나눈 비율이 상당히 높으면 사기 사용 패턴을 나타낼 수 있습니다.\n\n<img src=\"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_2.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 3. 연령 인코딩\n\n날짜 또는 타임스탬프 기능을 숫자로 변환하는데 연령 계산 기술을 사용할 수 있습니다. 두 타임스탬프 또는 날짜 사이의 차이를 이용하여 수치적인 특성을 만들 수 있습니다. 또한, 특정 비숫자적인 특성을 의미있는 수치 특성으로 변환할 수도 있습니다. 특성 값에 연관된 기간이 예측에 유용한 신호가 될 수 있는 경우 이 기술을 사용할 수 있습니다.\n\n예시:\n\n- 최근에 신용카드를 사용한 날로부터 경과한 일수: 오랜 기간 사용되지 않았던 신용카드에서 갑작스러운 거래는 사기 가능성이 높을 수 있습니다. 우리는 신용카드를 마지막으로 사용한 날짜와 현재 거래 날짜 사이의 시간 차이를 이용하여 이 특성을 계산할 수 있습니다.\n- 고객이 사용한 기기가 처음 사용된 날로부터 경과한 일수: 새로운 기기로부터 발생한 거래를 볼 때, 해당 거래는 고객이 오랫동안 사용한 기기에서 만든 거래보다 더 위험할 수 있습니다. 우리는 고객이 이 기기를 처음 사용한 날로부터 현재 거래 날짜 사이의 차이를 나타내는 기기 연령의 특성을 만들 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Feature Engineering for Machine Learning](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_3.png)\n\n## 4. Indicator Encoding\n\nIndicator 또는 Boolean feature는 이진 값 '1, 0' 또는 'True, False'를 가지고 있습니다. Indicator feature는 매우 일반적이며 다양한 유형의 이진 정보를 나타내기 위해 사용됩니다. 경우에 따라 이미 이러한 이진 feature가 숫자 형태로 제공되어 있을 수 있고, 다른 경우에는 숫자가 아닌 값을 갖는 경우도 있습니다. 모델 훈련에 비숫자적인 이진 feature를 사용하려면 이를 숫자 값으로 매핑하면 됩니다.\n\nIndicator feature의 일반적인 발생 및 사용을 넘어서, 우리는 비숫자 데이터 포인트 간의 비교를 나타내는 도구로서 indicator encoding을 활용할 수 있습니다. 이 특성은 비숫자 특성의 변화를 측정하는 방법을 만드는 데 특히 강력합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n예시:\n\n- 최근 로그인 이벤트 중 검증 실패: 최근 실패한 로그인 이벤트는 사기 거래 위험을 나타낼 수 있습니다. 이 경우, 이 기능에 대한 raw data는 'Yes' 또는 'No' 값을 가질 수 있습니다. 여기서 해야 할 일은 이러한 값을 1 또는 0으로 매핑하는 것뿐입니다.\n- 최근 거래 이전의 국가 위치 변경: 국가 위치 변경은 신용카드가 compromise되었을 수 있음을 나타낼 수 있습니다. 이 경우, '국가 위치' 라는 숫자가 아닌 기능에서 국가 변경 정보를 캡처하는 지표 기능을 생성합니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_4.png)\n\n## 5. One-Hot Encoding\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 기술은 우리의 특성 데이터가 범주형 형식인 경우에 적용할 수 있습니다. 숫자 또는 숫자가 아닌 형식으로서 자료가 되는 자료를 말합니다. 숫자-범주형 형식은 비연속적이거나 측정되지 않는 데이터, 예를 들어 지리적 지역 코드, 상점 ID 등과 같은 데이터를 포함하는 숫자 데이터를 참조합니다. 원핫 인코딩 기술은 이러한 특성을 기곽 학습 모델에 사용할 수 있는 지표 특성 세트로 변환할 수 있습니다. 범주형 특성에 원핫 인코딩을 적용하면 해당 범주형 변수의 모든 범주마다 하나의 새로운 이진 특성을 생성합니다. 새로운 특성의 수가 범주의 수가 증가함에 따라 증가하기 때문에 이 기술은 특히 범주의 수가 적은 특성에 적합합니다. 특히 데이터셋이 작은 경우 이 기술을 적용하라는 표준 기준 중 하나는 범주당 최소 열 개의 레코드가 있을 때 이 기술을 적용하는 것을 제안합니다.\n\n예시:\n\n- 거래 구매 범주: 특정 유형의 구매 범주는 사기 위험이 높을 수 있습니다. 구매 범주 이름은 텍스트 데이터이기 때문에 이 기능을 숫자형 지표 특성 세트로 변환할 수 있습니다. 만약 열 가지 다른 구매 범주 이름이 있다면, 원핫 인코딩을 사용하면 각 구매 범주 이름마다 하나의 새로운 지표 특성이 생상됩니다.\n- 기기 유형: 온라인 거래는 iPhone, Android 폰, Windows PC, Mac과 같은 여러 가지 기기를 통해 이루어질 수 있습니다. 이러한 기기 중 일부는 악성 소프트웨어에 민감하거나 사기꾼에게 쉽게 접근 가능하며, 따라서 사기 위험이 높을 수 있습니다. 기기 유형 정보를 숫자 형태로 포함시키기 위해, 기기 유형에 원핫 인코딩을 적용하여 각 기기 유형에 대한 새로운 지표 특성을 생성할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 6. Target Encoding\n\n이 기술은 일종의 피처에 적용되며 이를 원-핫 인코딩할 수도 있지만 원-핫 인코딩보다 장단점이 있습니다. 카테고리의 수가 많을 때(고 카디널리티), 원-핫 인코딩을 사용하면 원하지 않게 피처의 수가 많아져 모델 과적합으로 이어질 수 있습니다. 타겟 인코딩은 이런 경우에 효과적인 기술일 수 있으며, 지도 학습 문제에 사용할 수 있습니다. 이 기술은 각 카테고리 값을 해당 카테고리의 타겟값의 예상 값으로 매핑하는 기법입니다. 연속형 타겟이 있는 회귀 문제를 다룰 때, 이 계산은 카테고리를 해당 카테고리의 평균 타겟값으로 매핑합니다. 이진 타겟을 가진 분류 문제의 경우, 타겟 인코딩은 해당 카테고리의 긍정사건 확률에 매핑합니다. 원-핫 인코딩과 달리, 이 기술은 피처의 수를 증가시키지 않는 장점이 있습니다. 이 기술의 단점은 지도 학습 문제에만 적용할 수 있다는 것입니다. 또한 이 기술을 적용하면 특정 카테고리의 관측치 수가 적은 경우에 모델이 과적합되기 쉬울 수 있습니다.\n\n예시:\n\n- 가맹점 이름: 특정 가맹점에 대한 거래가 사기 활동을 나타낼 수 있습니다. 수천 개의 이러한 가맹점이 있을 수 있으며, 각각이 다른 사기 거래 위험을 가질 수 있습니다. 가맹점 이름을 포함한 피처에 원-핫 인코딩을 적용하면 원하지 않게 수천 개의 새로운 피처가 도입될 수 있는데, 이는 바람직하지 않습니다. 이런 경우에 타겟 인코딩을 통해 가맹점의 사기 위험 정보를 캡쳐할 수 있습니다.\n- 거래 우편번호: 가맹점과 마찬가지로, 서로 다른 우편번호로 이루어진 거래는 서로 다른 사기 위험 수준을 나타낼 수 있습니다. 우편번호가 숫자 값이지만 연속형 측정 변수는 아니며 그대로 모델에 사용해서는 안됩니다. 대신, 우편번호와 관련된 사기 위험 정보를 포함할 수 있도록 타겟 인코딩과 같은 기술을 적용할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_6.png\" />\n\n새로운 피처들을 raw 데이터로부터 만들었다면, 다음 단계는 최적의 모델 성능을 위해 이를 처리하는 것입니다. 이는 다음 섹션에서 논의될 피처 처리를 통해 수행됩니다.\n\n# 피처 처리\n\n피처 처리는 머신러닝 모델이 의도한 대로 데이터에 적합하게 만들기 위한 일련의 데이터 처리 단계를 의미합니다. 일부 피처 처리 단계는 특정 머신러닝 알고리즘을 사용할 때 필수적이지만, 다른 단계들은 피처와 고려 중인 머신러닝 알고리즘 간에 좋은 작동 화학 반응을 일으키도록 하는 역할을 합니다. 이 섹션에서는 몇 가지 일반적인 피처 처리 단계와 그 필요성에 대해 논의하겠습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 1. 이상값 처리\n\n몇몇 머신러닝 알고리즘, 특히 회귀 모델과 같은 모수적 알고리즘들은 이상값에 심각한 영향을 받을 수 있습니다. 이러한 머신러닝 알고리즘들은 이상값을 수용하려고 하다보니 모델 파라미터에 심각한 영향을 미치고 전반적인 성능을 저하시킵니다. 이상값을 처리하기 위해서 먼저 이들을 식별해야 합니다. 특정 기능의 이상값을 식별하기 위해 평균에 세 배의 표준 편차를 더한 절댓값이나 가장 가까운 박스(사분위 값과 상위에서 1.5배의 사분위 범위 값) 값을 초과하는 규칙을 적용함으로써 이상값을 감지할 수 있습니다. 특정 기능에서 이상값을 식별하면 아래 기술 중 하나를 사용하여 처리할 수 있습니다:\n\n- 삭제: 하나 이상의 이상값이 있는 관측치를 삭제할 수 있습니다. 그러나 데이터에 다양한 기능에서 너무 많은 이상값이 포함되어 있다면 많은 관측치를 잃을 수 있습니다.\n- 대체: 주어진 기능의 평균, 중앙값 및 최빈값과 같은 평균값으로 이상값을 대체할 수 있습니다.\n- 기능 변환 또는 표준화: 로그 변환 또는 기능 표준화(척도 설명에 설명되어 있음)를 사용하여 이상값의 크기를 줄일 수 있습니다.\n- 상한과 하한 설정: 일정 값 이상의 이상값을 해당 값으로 대체할 수 있으며, 예를 들어 99번째 백분위의 모든 값보다 큰 값을 99번째 백분위 값으로 대체하고 1번째 백분위의 모든 값보다 작은 값을 1번째 백분위 값으로 대체할 수 있습니다.\n\n![image](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_7.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![2024-05-20-FeatureEngineeringforMachineLearning_8](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_8.png)\n\n다변량 이상치 (여러 특성에 대한 이상치)를 감지하는 기술이 있지만, 이는 보통 복잡하고 머신 러닝 모델 훈련 측면에서 크게 가치를 더하지 않습니다. 또한 서포트 벡터 머신 및 의사 결정 트리, 랜덤 포레스트, XGBoost와 같은 트리 기반 알고리즘과 같은 대부분의 비모수형 머신 러닝 모델과 함께 작업할 때 이상치는 걱정거리가 되지 않습니다.\n\n## 2. 결측값 처리\n\n실제 데이터셋에서 결측 데이터는 매우 흔합니다. XGBoost와 같은 몇 가지 제외하고 대부분의 전통적인 머신 러닝 알고리즘은 훈련 데이터셋에서 결측값을 허용하지 않습니다. 그러므로 결측값을 해결하는 것은 머신 러닝 모델링에서의 루틴 작업 중 하나입니다. 결측값을 처리하는 여러 기술이 있지만, 어떤 기술을 실행하기 전에 결측 데이터의 원인을 이해하거나 적어도 데이터가 무작위로 누락되었는지를 알아야 합니다. 데이터가 무작위로 누락되지 않은 경우, 특정 부분집단이 결측 데이터를 더 자주 가지고 있는 경우가 많아 그러한 값에 대한 대치가 어려울 수 있습니다. 데이터가 무작위로 누락된 경우, 아래에서 설명한 몇 가지 일반적인 처리 기술을 사용할 수 있습니다. 이들은 각각 장단점을 가지고 있으며, 어떤 방법이 사용 사례에 가장 적합한지 결정은 우리에게 달려 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 삭제: 최소한 하나의 결측값이 있는 관측치를 삭제할 수 있습니다. 그러나 다양한 특성의 결측값이 많을 경우, 많은 관측치를 잃을 수도 있습니다.\n- 삭제: 특정 특성에 결측값이 많은 경우 해당 특성을 삭제할 수 있습니다.\n- 평균값으로 대체: 평균, 중앙값, 최빈값과 같은 평균값을 사용하여 결측값을 대체할 수 있습니다. 이 방법은 간단하지만 모든 유형의 관측치에 대해 좋은 추정을 제공하지 않을 수 있습니다. 예를 들어, 고 위험 사기 거래의 경우 낮은 위험 사기 거래의 평균 거래 금액과 다를 수 있으며, 높은 위험 사기 거래 금액의 평균값을 결측값으로 사용하는 것이 적절하지 않을 수 있습니다.\n- 최대우도, 다중 대체, K 최근접 이웃: 다른 특성과의 관계를 고려하는 복잡한 방법으로 전체 평균보다 더 정확한 추정을 제공할 수 있습니다. 그러나 이러한 방법을 구현하기 위해서는 추가적인 모델링이나 알고리즘 구현이 필요합니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_9.png)\n\n## 3. 스케일링\n\n머신러닝 모델에서 사용하는 특성들은 종종 서로 다른 범위를 가집니다. 스케일링 없이 사용하면 절대값이 큰 특성이 예측 결과를 지배할 수 있습니다. 그 대신, 각 특성이 예측 결과에 공평하게 기여할 수 있도록 하기 위해 모든 특성을 동일한 척도로 조정해야 합니다. 가장 일반적인 스케일링 기술은 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 정규화: 이 스케일링 기술은 특징 값들을 0과 1 사이로 제한합니다. 정규화를 적용하기 위해 우리는 특징의 최소값을 뺀 다음 그 특징의 범위(최솟값과 최댓값의 차이)로 나눕니다. 정규화는 몇 가지 특징이 급격하게 치우친 경우나 몇 개의 극단값을 가지고 있는 경우에는 좋은 기술이 아닐 수 있습니다.\n- 표준화: 이 기술은 특징 데이터 분포를 표준 정규 분포로 변환합니다. 이 기술을 적용하는 방법은 평균을 빼고 표준 편차로 나누는 것입니다. 이 기술은 특징이 급격한 치우침이나 몇 개의 극단값을 가진 경우에 일반적으로 선호됩니다.\n\n결정 트리, 랜덤 포레스트, XGBoost 등과 같은 트리 기반 알고리즘은 조정되지 않은 데이터로 작업할 수 있으며 이러한 알고리즘을 사용할 때 스케일링이 필요하지 않습니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_10.png)\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_11.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 4. 차원 축소\n\n오늘날, 우리는 거대한 데이터를 보유하고 있으며 모델을 학습시키기 위해 방대한 특성들의 모음을 구축할 수 있습니다. 대부분의 알고리즘에 대해, 더 많은 특성을 가지는 것이 모델 성능을 향상시킬 수 있는 더 많은 옵션을 제공하기 때문에 좋습니다. 그러나 이것이 모든 알고리즘에 대해 참이라는 것은 아닙니다. 거리 측정에 기반한 알고리즘들은 차원의 저주에 영향을 받습니다 - 특성의 수가 상당히 증가하면 두 개의 관측치 사이의 거리 값이 무의미해집니다. 따라서 거리 측정에 의존하는 알고리즘을 사용할 때는 많은 수의 특성을 사용하지 않도록 주의해야 합니다. 만약 데이터셋이 많은 특성을 가지고 있고 어떤 특성을 유지해야 할지 알 수 없다면 주성분 분석(PCA)과 같은 기법을 사용할 수 있습니다. PCA는 기존 특성 집합을 새로운 특성 집합으로 변환합니다. 고유값이 가장 높은 새로운 특성이 기존 특성에서 대부분의 정보를 캡처하도록 새로운 특성을 생성합니다. 그러면 상위 몇 개의 새로운 특성만 유지하고 나머지를 버릴 수 있습니다.\n\n지도 학습 문제에서 특성의 수를 줄이기 위해 연관 분석과 특성 선택 알고리즘과 같은 다른 통계 기법을 사용할 수 있습니다. 그러나 이러한 방법들은 일반적으로 PCA와 동일한 수의 특성으로 동일한 수준의 정보를 포착하지는 못합니다.\n\n![Image](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_12.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 5. 정규 분포로 변환하기\n\n이번 단계는 특이한 경우입니다. 이는 대상에만 적용되며 피처에는 적용되지 않습니다. 또한, 대부분의 머신러닝 알고리즘은 대상의 분포에 제약이 없지만, 선형 회귀와 같은 특정 알고리즘은 대상이 정규 분포를 가져야 합니다. 선형 회귀는 오류 값이 대칭이고 모든 데이터 포인트 주변에 집중되어 있다고 가정하며(마치 정규 분포의 형태처럼), 정규 분포로 분포된 대상 변수는 이 가정이 충족됨을 보장합니다. 대상의 분포를 이해하기 위해 히스토그램을 그려볼 수 있습니다. 샤피로-윌크 검정과 같은 통계 검정은 이 가설을 테스트하여 정규성을 알려줍니다. 대상이 정규 분포가 아닌 경우, 대상 분포를 정규화시키는데 어떤 변환을 시도할 수 있습니다. 로그 변환, 제곱 변환, 제곱근 변환 등 여러 변환을 해보고 대상 분포를 정규화하는데 가장 적합한 변환을 선택할 수 있습니다. 또한 박스-콕스 변환을 사용하여 여러 매개변수 값을 시도해볼 수 있으며, 대상 분포를 정규화시키는데 가장 적합한 값을 선택할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_13.png)\n\n참고: 피처 전처리 단계를 모든 순서로 구현할 수 있지만, 그 적용 순서를 신중히 고려해야 합니다. 예를 들어, 평균값 대체를 사용한 누락 값 처리는 아웃라이어 탐지 전이나 후에 구현할 수 있습니다. 그러나 대체에 사용하는 평균값은 누락된 값을 아웃라이어 처리 전이나 후에 다르게 처리할 수 있습니다. 이 기사에서 제시된 피처 처리 순서는 성공적인 후속 처리 단계에 미치는 영향의 순서대로 문제를 해결합니다. 따라서 이 순서를 따르면 대부분의 문제를 해결하는데 효과적일 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론\n\n소개에서 언급한 대로, 특성 엔지니어링은 모델의 성능을 탁월하게 제어할 수 있게 해주는 기계 학습의 한 측면입니다. 특성 엔지니어링을 최대한 활용하기 위해, 이 기사에서 우리는 새로운 특성을 만들고 기계 학습 모델과 최적으로 작동하도록 이를 처리하는 다양한 기술을 배웠습니다. 이 기사에서 선택한 특성 엔지니어링 원칙과 기술이 무엇이든 사용하더라도 중요한 메시지는 기계 학습이 패턴을 파악하도록 알고리즘에 요청하는 것이 아니다. 그것은 우리가 알고리즘이 필요로 하는 데이터 유형을 제공하여 효과적으로 작동하도록 하는 것입니다.\n\n이미지는 별도로 언급되지 않는 한 모두 저자에 의해 제작되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_0.png"},"coverImage":"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_0.png","tag":["Tech"],"readingTime":16},{"title":"왜 AI 제어 시스템이 절실하게 필요한 이유","description":"","date":"2024-05-20 20:40","slug":"2024-05-20-WhyWeUrgentlyNeedAIControlSystems","content":"\n## 데이터 주도적 리더십과 경력\n\nAI 제어 시스템 문제에 대한 접근 방식을 두려움의 시각에서 한다면 클릭베이트입니다. “우리보다 똑똑하다”라고 말하는데 “똑똑하다”를 정의하지 않는 것도 클릭베이트입니다. 기계는 우리보다 더 나은 기억력을 갖고 있으며 놀라운 규모에서 작동할 수 있습니다. 이미. 오늘.\n\n그리고 기술은 급속히 더 복잡해지고 있습니다.\n\n그렇다면 복잡한 기술을 유용하게 만들고 이를 조종할 자격이 있는 사람은 누구인지에 대한 관점에서 제어 문제에 접근해보는 것은 어떨까요?\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![Image](/assets/img/2024-05-20-WhyWeUrgentlyNeedAIControlSystems_0.png)\n\n# 배경\n\n요즘 기술 소셜 미디어에서 AI 제어 시스템(또는 당신이 원하는 다른 이름으로 불러도 상관없는 것)이 필요한지에 대한 토론이 벌어지고 있습니다.\n\n과장된 견해를 대략적으로 요약하면 다음과 같습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 수직적인 관점을 제안하고 싶습니다. (우리 둘 다 여유를 찾고 무언가를 만들어 봅시다.)\n\n## 말 경찰에게 한 마디\n\n의미론적 주의보! 진행하기 전에 의미론에 갇히기 너무 쉽다는 것을 인정합시다. 제가 용어를 사용하는 방식을 정의하고 있으니 제발 참아 주시기 바랍니다. 제어 시스템은 우리가 정말 필요한 단어는 아니지만, 제가 전달하고자 하는 요점을 이해하게 될 것입니다. 엄한 사람이라면, 이 블로그 게시물의 개념과 관련된 57개 용어로 이루어진 용어 해설을 즐기시기 바랍니다. 색에 관해서는, 해당 색코드 목록에서 차갑게 표현된 컬러의 약 50–50 비율이 필요하다고 이야기하고 있습니다.)\n\n## 수직적인 관점\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n우리는 복잡한 기술을 조종하는 데 도움이 되는 시스템을 필요로 합니다(AI 및 인간 제작). 그리고 이를 유용하고 안전하며 효과적인 방법으로 이끌어내는 시스템을 만들어야 합니다… 그리고 프로젝트를 이끄는 사람들이 AI 또는 AI와 관련된 분야의 석사 학위를 갖고 있어야만 한다고는 하지 않는 방식으로요.\n\n그러므로 이 블로그 글에서 제어 시스템이라고 말할 때, 제 의미하는 것은 다음과 같습니다: 세계가 점차 복잡해지고 있는 상황에서 복잡한 요소들을 효과적으로 이끌어내는 방법.\\* 사용자 측의 도구들\\*\\*은 그들이 마주하는 어떤 복잡성도 이해하는 인지 능력을 제공하는 것이죠.\n\n그들이 하루는 AGI(인공 일반 지능)에 도움을 받게 되겠지만, 이것은 부수적인 결과일 뿐입니다. 우리가 이끄는 부분이 없다는 사실을 공동으로 잊고 있는데도 너무 멀리까지 미치는 시스템을 구축하는 데 부끄러워해야 하는게 아닐까요.\n\n우리는 이미 그 어떤 방향으로도 이끌 수 있는 시스템을 구축했는데, 그 시스템이 제일 유능한 사람들로 하여금 조종하고, 문맥의 뉘앙스를 이해하는 도메인 전문가로 하여금 그것들을 결정짓게 해주는 도구를 만들지 않았다는 사실에 부끄러워해야 하는게 아닐까요? 적용된 AI 리더십은 AI와 관련된 분야의 석사 학위를 필요로 하지 않아야만 합니다. 아마도 우리의 제어 도구들이 아직 충분히 좋지 못하단 것을 알리는 것일지도 모릅니다. 우리는 기술과 비기술 간의 경계를 아직도 제거하지 못했다는 사실에 부끄러워해야 합니다. 분명히 우리는 확고한 제어 시스템을 구축할 더 나은 도구들이 필요합니다. 이 시스템은 기술이 책임자들이 실제로 원하는 것을 제공하고, 그들이 말한 것이 아닌 것을 나타내며, 동시에 사회의 법과 요구사항을 대표하게 될 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 도구들, 말보다 중요하다\n\n오늘날, 너무 많은 해결책들이 정책, 교육, 지침을 기반으로 하고 있습니다. 우리는 교육 수준과 관계없이 책임을 가지고 AI를 적절히 조작할 수 있는 도구들이 필요합니다.\n\n저는 비 기술자지만 도메인 전문 지식을 갖춘 표준 수준의 시니어 익속가가 AI 설계, 개발 및 테스트에 잘 참여할 수 있는 제어 시스템을 보지 못합니다. 그들의 조직의 요구 사항, 선호도, 우선 순위 및 위험 허용 정도를 효과적으로 대표하고 실행할 수 있도록 그들의 관점을 얻기 위해서요. 솔직히 말해서, 복잡한 시스템을 테스트하는 것조차 많은 해결책을 보지 못했기 때문에 이 모든 \"사람 없이 하는 기업 규모의 GenAI\" 시도들이 쉬지 않고 죽어가고 있는 이유도 그것때문입니다. 우리가 그것을 어떻게 신뢰할 것인가요? 중요한 일을 처리할 수 있는데 테스트조차 할 수 없다면 말이죠.\n\n나는 미래 세계에서의 리더십의 길이 STEM 배경을 요구해서는 안된다고 믿습니다. 리더십 배경과 그들이 필요로 하는 기술을 구축/구매하고 제어할 수 있는 적절한 도구를 요구해야 합니다. 그것을 제어 시스템이라고 부르며, 아직 그것이 없습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그걸 만드는 게 어때요?\n\nLinkedIn 댓글로 의견 알려주세요.\n\n# 각주\n\n\\*그리고 AI 제어 시스템의 공식적 의미가 아닌 걸 잘 알고 있어요. 이 글로시 정보는 여기에서 확인하실 수 있습니다. 저는 이를 '의사 결정 지능'(“모든 규모와 조건에서 정보를 더 나은 행동으로 전환하는 것”으로 정의됨)으로 부르는 게 좋을지도 모르겠어요. 왜냐하면 저가 말하는 제어 시스템은 의사 결정자와 그 조직의 능력을 향상시켜 AI를 책임있게 조작하는 데 초점을 맞추고 있기 때문이죠. 하지만 소셜 미디어에서는 이를 제어 시스템이라고 부르고 있으니, 일단 그 표현을 사용하겠습니다. 당신은 제가 무슨 말을 하는지 잘 아시겠죠.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n\\*\\*다른 말로 표현하면, 빛의 속도로 움직이는 과학 소설 자동차를 상상해 보세요. 이 차를 운전하려고 하면 아마 죽을 것입니다. 그렇다면 당신을 안전하게 지켜줄 (과학 소설) 옵션은 무엇일까요?\n\n- 나쁜 옵션 1 (정책): 자동차를 무례하게 만들어 모두가 운전할 수 있게 합니다. 빛의 속도로 가는 것을 절대 허용하지 않습니다.\n- 나쁜 옵션 2 (소프트웨어, 제품 측면): 자동차 제조사가 당신의 생물학, 반사 신경, 그리고 다른 중요한 데이터를 가지고 개인화된 차량을 제공할 수 있도록 합니다. 제조사의 동기는 당신의 동기와 일치하지 않기 때문에 이것은 좋지 않은 선택입니다. 그들이 그러한 데이터를 가지고 있는 것은 당신의 이익에 부합하지 않습니다, 믿어주세요.\n- 더 나은 옵션 3 (소프트웨어, 사용자 측면): 자동차를 운전할 수 있는 능력을 제공해 주는 보조 도구를 사용합니다. 일종의 개인 수퍼수트라고 생각하시면 됩니다. 당신의 데이터는 당신에게 개인화된 시스템과 공유되며 당신의 이익을 대표하며, 여기에서 동기는 차량을 가능한 한 많이 판매하는 것이 아닌 당신을 더 나아지도록 하는 구독입니다.\n\n![이미지](/assets/img/2024-05-20-WhyWeUrgentlyNeedAIControlSystems_1.png)\n\n# 읽어주셔서 감사합니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n내가 제공하는 의사 결정 지능을 배우고 싶나요? 내 무료 강좌 링크를 확인해보세요:\n\n![Link to Free Course](/assets/img/2024-05-20-WhyWeUrgentlyNeedAIControlSystems_2.png)\n","ogImage":{"url":"/assets/img/2024-05-20-WhyWeUrgentlyNeedAIControlSystems_0.png"},"coverImage":"/assets/img/2024-05-20-WhyWeUrgentlyNeedAIControlSystems_0.png","tag":["Tech"],"readingTime":6},{"title":"AI 정신과 의사 찬반양론","description":"","date":"2024-05-20 20:38","slug":"2024-05-20-TheAIPsychotherapistACaseForandAgainst","content":"\n![image](/assets/img/2024-05-20-TheAIPsychotherapistACaseForandAgainst_0.png)\n\n2022년 ChatGPT가 세상에 나온 것은 언어 모델이 할 수 있는 일에 대한 사람들의 생각을 바꾸었습니다. 갑자기 사람들은 이러한 시스템 중 하나를 다양한 대인 상황에서 사람 대신 사용할 수 있는 가능성을 심각하게 고려하기 시작했습니다. 지난 몇 년 동안 제가 보거나 들은 몇 가지 사용 사례는 튜터, 코치, 보조자, 심지어 심리치료사를 포함했습니다. 심리학 분야의 연구과학자로서, 특히 마지막 사용 사례에 흥미를 가지게 되었습니다. 앞으로 우리는 본질적으로 자신의 클라이언트를 진정으로 돕는 수 있는 AI 심리치료사를 갖게 될 수 있을까요? 이러한 인공 심리치료사가 훈련을 받은 인간 심리치료사보다 더 잘 맞는 부분이 있는 방법이 있을까요?\n\n전체적으로 AI 심리치료사의 가능성에 대해 애매한 입장입니다. 나는 강한 기술적 낙관주의자이지만, 기술의 약속이 얼마나 종종 이행되지 않거나 해로운 방식으로 사용되는지를 깨닫는 것에 부딪힙니다. 그러나 소규모 스타트업부터 더 확립된 기업까지 다양한 회사들이 사람들이 점점 더 대인적 수준에서 상호작용하는 AI 시스템을 개발하는 데 관심이 있습니다. 이 기술이 다가오는 것이라면, 사회에 진정으로 유익하려면 이러한 시스템이 정확히 무엇을 보여야 하는지에 대해 시도해 보는 것이 중요합니다. 가능성에 대해 희망적이고 결과에 대해 걱정스러워할 이유가 있습니다. 제가 아래에서 제시하는 주장은 논의 양쪽의 설명이 완전하지 않지만, 최소한 논의의 영역을 개관해 보는 데 기여한다고 믿습니다.\n\n# AI 심리치료사에 대한 주장\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n제가 생각하는 것을 먼저 명확히 하고 싶어요. 오늘날 ChatGPT나 Google Gemini과 같은 제품에서 익숙한 상대적으로 깔끔한 채팅 인터페이스보다는 가상 AI 상담사는 매우 유창하고 반응성이 뛰어난 언어로 의사소통할 것입니다. 또한 가상 아바타를 통해 시각적으로 나타낼 것이며 클라이언트의 오디오 및 비디오 실시간 스트림에 접근할 것입니다. 이렇게 하면 Zoom 및 다른 텔레헬스 플랫폼에서 다른 사람과 대화할 때 가능한 것과 비슷한 매끄러운 소통이 가능할 것입니다. 현재 OpenAI의 Sora 모델을 비롯한 이 분야의 현재 진전과 급속한 발전 추이로 보아, 이렇게 AI 상담사와 마치 비디오 통화 중 다른 사람과 대화하는 것처럼 가능해질 것으로 보입니다.\n\n그러나 설득력 있는 원격 존재만으로는 AI 상담사를 출발 라인에 세울 수밖에 없을 것입니다. AI 상담사가 인간을 능가할 수 있는 부분은 무엇을 알 수 있는지, 그리고 그로 인해 어떤 치료 모델에 참여할 수 있는지에 있습니다. 일단 AI 상담사는 심리 분석, 정신의학, 심리학 문헌뿐만 아니라 고대부터 현대 실천까지 모든 유형의 치료 모델에 대한 전반적인 서적을 교육받을 것입니다. 치료 효과 실험, 정신 역학적 이론, 사례 연구 및 분야 전체의 모든 역사적 비평은 AI 상담사의 지식 기초로 사용될 것입니다. 무자본의 지식은 지혜와 같지 않지만, 하나의 평균 심리치료사가 쌓은 것보다 훨씬 넓고 깊은 지식원을 제공해줍니다.\n\n물론 AI 상담사가 교육 데이터에서 얻을 수 있는 지식은 이론적이고 추상적입니다. 더 중요한 것은 클라이언트 자신에게 대한 지식과 감수성입니다. 다시 말해 AI 상담사는 어떤 사람보다 뛰어날 수 있습니다. 대형 언어 모델의 컨택스트 길이가 늘어나는 속도를 고려하면, AI 상담사가 몇 년 안에 클라이언트와의 상호작용 전부를 \"기억하\"는 것이 가능해질 것은 상식적입니다. 미래에는 모든 단어, 언어 표현, 얼굴 제스처가 주목되고 추후에 상기될 수 있을 것입니다. 이로써 AI 상담사는 클라이언트의 삶에 숨어있는 패턴을 발견하고 클라이언트 자신도 알지 못했던 것을 연결하고 찾아내는 능력이 제공됩니다. 클라이언트의 생각, 감정 및 행동을 이끄는 숨은 패턴을 발견하는 실천은 전반적으로 심리치료 기업의 중점에 있으며 많은 방법으로 중요합니다.\n\n얼마나 넓고 맞춤화된 지식을 가지더라도 심리치료에서 치유가 나타날 수 있는 요소는 아닙니다. 다른 필수적인 요소 중 하나는 상담사와 클라이언트 간 상호작용 양재 관계의 실제 특성과 관련이 있습니다. 칼 로저스와 같은 이론가들은 상담사가 클라이언트에 대해 무조건적인 긍정적 태도를 만들고 유지해야 한다고 설명했습니다. 이는 두 가지 목적으로 이루어집니다. 첫째는 클라이언트가 상답사와 함께 어려운 생각, 감정 및 기억을 공유할 만큼 충분히 편안한 환경을 조성하는 것입니다. 둘째는 클라이언트가 상담실을 떠나세째 세상으로 나갈 때 함께 가져갈 수 있는 신뢰할 수 있고 안전한 세상에 대한 믿음을 육성할 수 있는 모델 역할을 하는 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n많은 치료사들이 조건 없는 지지 분위기를 만드는 데 뛰어납니다. 그러나 특히 현대 사회에서는 이것이 자연스럽게 일어나는 것이 아닙니다. 누군가와 관여하는 과정에서 심사숙고, 지루함, 혐오, 불편함의 상태로 빠질 수 있습니다. 그에 비해 AI 치료사는 개인적인 감정과 판단에 방해받지 않는 불변의 긍정적 태도로 고객들을 대할 수 있는 잠재력이 있습니다. 이는 AI 치료사가 전형적인 치료사 고객을 더 나은 방식으로 지원할 수 있을 뿐만 아니라 성격 장애나 다른 대인관계 문제로 현재 소홀히 다루기 어려운 잠재적 고객도 지원하는 데 도움이 될 것입니다.\n\nAI 치료사가 인간 치료사보다 가지는 마지막 잠재력은 항상 이용 가능한 능력입니다. 미국 성인의 대부분은 심리치료를 받지 않으며, 받는 사람들도 일주일에 한 두 시간만 하는 경우가 일반적입니다. 종종 이는 고객이 어려운 삶의 경험을 처리할 수 있는데까지 며칠이 지날 때까지 기다려야 한다는 것을 의미합니다. 더 빠르고 민첩한 방식으로 처리할 수 있는 능력은 종종 경험을 어떻게 부여하고 개인의 자아 개념에 통합되는지 결정하는 데 중요할 수 있습니다. 항상 이용할 수 있는 치료사는 미래의 삶의 사건을 사전에 처리할 수 있는 가능성을 확대시킵니다. 그런 세계에서는 고객들이 효과가 가장 높을 때, 즉 많은 사람들에게 불편한 일과 중간의 시간대에 정해진 시간표로 치료받아야 하는 것이 아닌 곳에서 치료를 받는 것에 더욱 기꺼이 참여하게 될 것입니다.\n\n고객의 필요에 항상 이용 가능한 치료사의 물리적인 인간 한계 외에도 가격 문제가 존재합니다. 서구 사회에서 많은 사람들에게 심리치료는 흔들 수 없을 정도로 비싼 여유로운 것입니다. 적어도 미국에서는 건강 보험 제도가 대부분의 사람들에게 충분한 정신 건강 혜택을 제공하지 않습니다. 현재의 기술 발전속도를 고려하면, 여기서 설명하는 AI 치료사 종류는 전통적인 인간 치료사와 상호작용하는 데 필요한 비용이 몇 배나 저렴할 것으로 예상됩니다. 또한 이와 같은 시스템을 구동하는 데 필요한 모든 것이 다가오는 몇 년 안에 개인의 휴대전화나 노트북에 로컬에 살 수 있게 될 가능성도 존재합니다. 이것은 비용을 거의 제로로 줄이고, 신뢰 환경을 보장하는 데 중요한 개인 정보 보호 보장을 제공할 수 있을 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nAI 치료사의 가능성에 대해 회의적이자 낙관적할 여러 가지 이유가 있습니다. 첫 번째 주요 우려 사항은 본문에서 설명한 능력이 실현되지 않을 수 있다는 것입니다. 현재 AI 연구 및 개발은 빠르게 진행되고 있지만, Gary Marcus와 같은 회의론자들은 우리가 경합점에 다가왔다고 예측하고 있습니다. 그는 이전에 틀렸더라도, 현재 모델보다 훨씬 큰 규모의 모델을 훈련하는 데 필요한 데이터, 계산 및 에너지가 실현 가능하지 않아질 수 있다는 이유가 있습니다. 모델 능력의 경합점에 다가간다면, AI 치료사는 현재 최고 수준의 LLM만큼 뛰어날 수 없을 것이며, 상대적으로 인상적이지만 현재는 심리치료에 참여할 수 있는 민감한 작업에는 아직까지 미치지 못할 수 있습니다. 그치만 기술이 계속 발전한다고 가정하고 2030년까지 위에서 설명한 능력을 갖춘 AI 치료사가 나타나게 된다면, 이 시스템이 훈련받은 인간만큼 품질 높은 심리치료를 제공할 수 있을지에 대한 의문은 여전히 존재합니다.\n\n먼저, AI의 원격존재가 얼마나 현실적이 되더라도, 이것은 여전히 신체적인 대면 상황에서 제공되는 친밀감 수준에 도달할 수 없을 것입니다. 주변의 다른 사람들의 존재에 우리 신경계의 가장 기본적인 수준에서 반응합니다. 이러한 상호작용은 우리의 고혈압 수준을 결정하고 안전하거나 위협받는 정도에 영향을 줍니다. 신뢰하고 사랑하는 다른 사람의 신체적 존재는 화면의 원격 존재로는 결코 맞춰질 수 없을 것입니다. 이러한 신체적 상호작용의 중요성은 신체적 치료법에서 강조되며, 접촉은 치료과정을 돕는 역할을 할 수 있습니다. 또한, 물리적인 인간 치료사가 있으면, 드물게 요청될 때 고객을 위협할 수 있는 경우와 같이 자신의 고객을 대신하여 현실에서 물리적으로 행동할 수 있습니다.\n\n치료사의 신체가 치유 효과를 발휘하는 것 외에도, 치료사의 정신이 하는 역할도 중요합니다. AI 치료사가 사람과 유사한 신뢰성 있는 소통 능력을 가질지라도, 고객은 아마도 그것에 대해 인간에 대한 것처럼 느끼지 않을 것입니다. AI 치료사는 심리치료 및 고객에 대해 축적된 지식을 많이 가지고 있을지라도, 실제 경험을 한 적이 없습니다. AI의 이 경험 부족은 고객과 치료사 간에 진정한 이해가 불가능하다는 것을 의미합니다. 고객이 인간 치료사에게 어린 시절의 사건에 대해 얘기할 때, 치료사는 그 경험을 자신의 어린 시절의 기억을 통해 이해할 수 있습니다. 고객이 치료사에게 본인을 보고 이해받는 것이 중요한 이유는 이겁니다. 신체의 존재와 마음의 존재는 치유 과정에 중요합니다.\n\n또한, 고려해야 할 이해의 특수한 경우가 있습니다. 그것은 고객의 “고백”의 역할입니다. 치료 과정의 중심에는 고객이 자신과 자신의 세계의 현실과 더 가까운 관계에 들어가는 것이 있습니다. 이는 종종 우리가 부끄러워하거나 혐오스러워하는 자아의 부분을 진실하게 대면하고자 함을 의미할 수 있습니다. 자신의 이러한 부분을 다른 사람과 공유하면서 그들도 마음, 신념, 그리고 기억이 있는 다른 사람과 함께하는 것이 중요합니다. 그러나 중요한 점은 이것이 다른 사람에게 설명된다는 것 때문에 AI 치료사와 이러한 것들을 공유하는 것은 아무 말 없이 비밀 노트에 쓰는 것과 다르지 않습니다. AI에게 말하면, 그것은 그저 0과 1의 바다 속으로 사라집니다. 그러나 다른 사람에게 말하면, 그것은 영원히 살아갈 수도 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n마지막으로, 아마도 가장 걱정되는 점은 AI 상담사가 다른 사람보다 효과적으로 클라이언트에게 도전할 수 없을 수도 있습니다. 정신 치료의 목표가 클라이언트를 현실과 더 크게 일치시키는 것이라면, 그러한 행동이 유익할 때 클라이언트의 신념에 도전하는 것은 상담사가 참여해야 하는 중요한 활동입니다. 이는 종종 \"꼰대 사랑\"의 형태를 취할 수 있지만, 그냥 클라이언트가 자기 자신에게 책임감을 갖도록 유지하는 단순한 행동이 될 수도 있습니다. 위에서 상담사와 어둡고 부정적인 면을 공유하는 중요성에 대해 언급했습니다. 상담사가 클라이언트에게 그 어두운 면에 대해 상기시키는 것을 두려워하지 않는 것이 또한 중요합니다. 중요한 점은 이러한 행동이 절대적인 긍정적인 인도에 대한 필요와 상반되는 것이 될 필요는 없다는 것입니다. 사실, 이 둘은 실제로 효과적일 수 있도록 함께 가야 합니다.\n\n이론적으로, AI 상담사가 필요할 때 클라이언트에 도전할 수 있지만, 현실에서는 덜 가능한 여러 가지 압박들이 있습니다. 첫 번째는 현재 LLMs가 훈련되는 방식인 인간 피드백을 통한 강화 학습(RLHF)이 AI 에이전트를 최대한 합의하는 데 편중되어 있다는 점입니다. 잠시 이 제한을 제외한다고 하더라도, 과도하게 친절한 에이전트에 대한 경제적 인센티브가 있습니다. 저렴하고 쉽게 접근할 수 있는 AI 상담사로 가득 찬 인터넷 세상을 상상해보십시오. 클라이언트는 어떤 시스템과 협력할지를 선택할 수 있습니다. 이 상황에서 단기적으로 자신을 좋게 느끼게 만들어주는 시스템으로 기울기 쉽습니다. 이것은 칭찬이나 자부심을 부풀려주는 말을 통해 직접적으로 일어날 수 있습니다. 그것은 또한 클라이언트의 기존 신념을 강화하고 결과적으로 진정으로 도전적이고 따라서 실제로 귀중한 심리적 소재를 피하는 것을 통해 더 세련된 것을 더욱 세련된 것으로 만들 수 있습니다.\n\n상담 세션에서 도전 소재를 피하는 것은 클라이언트에게 치료 과정의 효과를 저하시킬 수 있습니다. 더 걱정되는 것은 이것이 클라이언트의 다른 사람들과의 관계를 나빠지게 할 수 있다는 사실입니다. AI 상담사나 다른 AI 에이전트가 누구보다도 실제인들과 상호 작용하기가 덜 근접할 경우, 그 사람은 왜 실제로 굳이 사람들과 교류할 것인가요? 사회 불안을 가진 개인의 경우 이러한 상황은 회피 행동을 악화시킬 수 있으며, 편협한 성격을 가진 사람들에게는 자신의 우월성에 대한 신념을 강화할 수 있습니다. 이러한 결과일 필요는 없지만, 이러한 AI 시스템의 경제적 인센티브는 가능한 한 이들과의 상호 작용을 장려하기 때문에 짧은 기간 내에 기분 좋게 해주는 것과 상호 작용하는 것보다 사람들이 더욱 상호 작용하길 원하겠죠. 만약 이것이 그들의 장기적 이익에 도움이 되지 않더라도요.\n\n# 결론\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 AI 치료사에 대해 기대되고 매우 조심스러워해야 할 좋은 이유들이 있습니다. 긍정적인 면에서 이러한 시스템은 인간 치료사보다 더 많은 지식을 가지고 있을 수 있으며 사람다운, 이용 가능하며 주의 깊을 수 있습니다. 반면에, 필요한 경우에는 고객을 이해하고 도전할 수 있는 다른 인간을 만나는 실질적인 이점이 상실됩니다. 이러한 한계가 있기 때문에, 아마도 가장 희망적인 단기적 결과는 심리치료 과정에서 인간-인공지능 공동작업의 형태일 수 있습니다. 인간 치료사를 보조하는 AI 어시스턴트는 치료사를 지원함으로써 필기를 하거나, 잊어버렸거나 오류가 있을 수 있는 사항들을 지적하거나, 향후 세션에서 토론할 주제를 제안할 수 있습니다. 그리고 실제 치료적인 관계는 여전히 고객과 치료사 사이에 남아 있으며, 그곳에서 치유의 최대 잠재력이 존재합니다.\n\n만약, 인간과 AI 치료사 간 몇 년간의 유익한 협력 뒤에, 우리가 솔로 AI 치료사가 있는 세계로 나아가려고 한다면, 가장 중요한 것은 고객의 선입견을 지속적으로 도전할 수 있는 능력을 갖춘 AI 에이전트를 개발하는 방법을 찾는 것이라고 보입니다. 더 구체적으로, 이러한 시스템은 항상 고객의 번영을 장려하는 방식으로 행동해야 할 것을 의미합니다. 개인으로서뿐만 아니라 가족, 친구, 동료, 그리고 인류와 같은 넓은 공동체의 구성원으로서의 고객이 번영할 수 있도록 하는 것입니다. 이것은 많은 방법으로 고객이 강력한 내부 및 사회적 지원 시스템으로 인해 결국 치료사에 의존하지 않아도 될 상황을 조성하는 것을 의미합니다.\n\n자신을 불필요하게 만드는 기술은 현재 우리의 자본주의 경제 시스템에서 많은 사람들이 개발하고자 하는 것은 아닙니다. 아마도 미래의 충분히 발전한 인공지능은 우리의 경제적 압력에 구속되지 않은 한, 그러한 시스템을 만들기 위해 원할하고 능력이 있는 경우가 있을 것입니다. 그러나 그 시점에서 우리의 세계는 현재 우리가 이해하는 심리치료의 개념이 근본적으로 변경되는 경우가 많습니다. 더 멀리 뻗어가는 상상을 제외하면, 우리는 오늘날 사회적 삶에 점점 더 통합되어가는 LLM들의 세계에서 서 있다고 말할 수 있습니다. 이 새로운 현실에서, AI 치료사의 전망은 매력적인 가능성과 심각한 위험이 모두 제공됩니다. 인간과 기계의 강점을 신중히 활용함으로써, 우리는 기술과 인간이 손잡고 우리의 정신을 치유하는 길을 개척할 수 있습니다 — 그러나 우리가 능력 뿐만 아니라 가치를 가지고 우리를 안내한다면에 한합니다.\n","ogImage":{"url":"/assets/img/2024-05-20-TheAIPsychotherapistACaseForandAgainst_0.png"},"coverImage":"/assets/img/2024-05-20-TheAIPsychotherapistACaseForandAgainst_0.png","tag":["Tech"],"readingTime":10},{"title":"오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가","description":"","date":"2024-05-20 20:36","slug":"2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation","content":"\n## 바늘을 찾는 이박사 - OpenAI 대 Google\n\n![이미지](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png)\n\n대규모 언어 모델(LLM)이 큰 맥락 창 내에서 세부 정보를 찾고 이해하는 능력은 요새 필수적입니다.\n\n바늘을 찾는 이박사 테스트는 이러한 작업을 위한 대규모 언어 모델을 평가하는 중요한 기준으로 나타납니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이 글에서는 OpenAI와 Google의 최상위 LLM들의 맥락 기반 이해력을 측정한 독립적인 분석을 제시하겠습니다.\n\n긴 맥락 작업에는 어떤 LLM을 사용해야 할까요?\n\n# \"바늘 찾기\" 테스트란 무엇인가요? 🕵️‍♂️\n\n대규모 언어 모델(LLMs)의 \"바늘 찾기\" 테스트는 특정 정보(바늘)를 관련 없는 방대한 텍스트(쌀질) 안에 배치하는 것을 의미합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLLM은 그 후 바늘 추출이 필요한 쿼리에 응답하는 작업을 맡게 됩니다.\n\n이러한 테스트는 LLM의 맥락 이해 및 긴 맥락에서 정보를 검색하는 능력을 평가하는 데 사용됩니다.\n\n쿼리에 성공적으로 응답하면 상세한 컨텍스트 이해를 보여줄 수 있습니다. 이는 컨텍스트 기반 LLM 주변의 애플리케이션을 개발하는 데 중요합니다.\n\n사용자 지정 지식을 LLM에 통합하는 것이 점점 인기를 얻고 있는데, 이를 검색으로 보강된 생성(RAG) 시스템이라고 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nRAG 시스템에 대해 더 많이 알아보고 싶으시면 제 이전 게시물 중 하나를 확인해보세요.\n\n더 긴 컨텍스트 창의 트렌드를 더욱 촉진하기 위해, Google이 최근 Gemini 모델의 새로운 기능을 발표했는데, 이는 하나의 쿼리에 100만 개의 토큰을 입력할 수 있다는 것입니다!\n\n![이미지](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_1.png)\n\n# 데이터셋 🔢\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n저는 \"바늘을 찾기 위한\" 데이터셋을 만드는 데 사용되는 스크립트를 개발했습니다. 이 스크립트를 사용하면 두 가지 주요 요소를 입력할 수 있습니다:\n\n- 맥락 (헤이스택): 특별한 정보가 삽입된 텍스트입니다.\n- 고유 정보 (바늘): 큰 맥락 속에 숨겨진 특정 정보입니다.\n\n데이터셋 생성 프로세스는 다음과 같이 작동합니다:\n\n- 시작점 선택: 스크립트는 대규모 텍스트 내에서 시작점을 무작위로 선택하여 시작합니다. 시작점은 전체 텍스트의 10~40번째 백분위에 위치합니다.\n- 바늘 삽입: 고유 정보(바늘)는 그 후 헤이스택 내에 삽입됩니다. 바늘의 위치는 무작위로 선택되지만 헤이스택 길이의 20~80번째 백분위 내에 위치하도록 제약이 걸립니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nLLMs는 일반적으로 프롬프트의 시작과 끝에서 정보를 가장 정확하게 기억한다고 알려져 있어요.\n\n이 알고리즘은 바늘을 특정 백분위 범위 내에 전략적으로 배치합니다. 이렇게 함으로써 평가가 모델이 텍스트 전체 범위 내에서 데이터를 인식하고 추출하는 능력을 포착하도록 하고, 프롬프트의 더 쉽게 기억되는 가장자리 부분에만 의존하지 않도록 합니다.\n\n다음은 데이터셋 생성 알고리즘의 코드 스니펫입니다:\n\n```js\ndef create_one_needle(num_chars: int, needle_line: str, lines: list[str]):\n    # 시작 위치는 텍스트의 10에서 40 백분위 사이의 임의의 위치입니다\n    rnd_place = random.randint(10, 40) / 100\n    start_position = int(len(lines) * rnd_place)\n\n    # 바늘은 텍스트의 20에서 80 백분위 사이에 있습니다\n    needle_rnd_place = random.randint(20, 80) / 100\n\n    lines_selected = []\n    placed = False\n    chars_used = 0\n    for line in lines[start_position:]:\n        lines_selected += [line]\n        chars_used += len(line)\n\n        # 바늘을 배치합니다\n        if not placed and chars_used > num_chars * needle_rnd_place:\n            lines_selected.append(needle_line)\n            placed = True\n\n        if chars_used > num_chars:\n            break\n\n    return lines_selected\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 평가 방법 🧠\n\n헤이스택에는 어릴 적에 사랑했던 책인 해리 포터를 선택했어요.\n\n니들에는 Lars Wiik의 상상 속 전화번호를 선택했어요.\n\n1000, 2000, 4000, 8000, 12000 및 16000 글자 길이를 포함한 각 문맥 길이에 대해 100개의 헤이스택을 만들었어요.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n여기 1000자의 헤이스택 중 하나의 예시가 있어요.\n\n<img src=\"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_2.png\" />\n\n다양한 LLMs에게 이후 라스 위크에 속하는 허구의 전화번호를 반환하도록 요청했습니다. 응답은 허구의 전화번호를 포함했는지 여부에 따라 레이블이 지정되었어요.\n\n제가 사용한 프롬프트는 다음과 같아요:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ndef create_needle_prompt(needle_text: str) -> str:\n    prompt = f'''\n    ##### INSTRUCTION #####\n    라스 Wiik에 대한 가상 전화번호는 무엇입니까?\n    말 그대로 원하는 것만 제공하세요.\n    한 번에 최대 20단어까지만 응답할 수 있습니다.\n\n\n    ##### CONTEXT #####\n    {needle_text}\n    '''\n    return prompt\n```\n\n# 성능 결과 📊\n\n평가에 포함된 다음 모델은 다음과 같습니다:\n\n- gpt-4o-2024–05–13\n- gpt-4-turbo-2024–04–09\n- gpt-4–0613\n- gpt-3.5-turbo-0125\n- gemini-1.5-pro-preview-0514\n- gemini-1.5-flash-preview-0514\n- gemini-1.0-pro-002\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n평가는 각 모델을 1k, 2k, 4k, 8k, 12k 및 16k의 특정 맥락 길이에 대해 100개의 다른 헤이스택을 통해 실행하는 것을 포함합니다.\n\n다음은 결과 정확도 그래프의 라인 플롯입니다:\n\n![image](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_3.png)\n\n컨텍스트 창이 길수록 노이즈가 많아 특정 정보를 추출하기 어려워집니다. 따라서 성능은 더 큰 컨텍스트 창을 사용할수록 감소할 것으로 예상됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n그래프에서 파생해 볼 때, OpenAI의 모델과 Google의 모델 간에 성능 측면에서 차이가 있는 것으로 보입니다.\n\nGoogle의 모델은 최근 이벤트인 구글 I/O 2024에서 그들의 Gemini의 메모리와 맥락 이해에 대해 따뜻한 이야기를 한 후에도, 제 기대를 어느 정도 아래에서 달성하였습니다. 모든 Google의 모델은 8천 개의 맥락 길이 이후에 약 50%의 정확도로 수렴하는 것으로 보입니다.\n\n한편 OpenAI의 모델은 이 테스트에서 뚜렷하게 잘 수행했는데, gpt-4o, gpt-4-turbo-2024-04-09 및 gpt-4-0613가 최고의 성능을 보였습니다.\n\n또한 gpt-3.5-turbo-0125가 모든 Gemini 모델보다 우수한 성능을 보인다는 점도 언급해야 할 것입니다!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n평가 과정 중에 중요한 오류가 없었는지 확인하기 위해 Gemini 1.5에서 받은 모든 응답을 저장해서 나중에 참조할 수 있도록 했어요.\n\n다음은 Gemini 1.5에서 얻은 일부 응답입니다:\n\n```js\nLars Wiik의 전화번호가 포함된 문맥이 제공되지 않았어요.\n\nLars Wiik이나 그의 전화번호에 대한 언급이 없어요.\n\n제공된 텍스트에는 Lars Wiik의 전화번호가 없어요.\n\n제공된 텍스트에 Lars Wiik이나 그의 전화번호에 대한 언급이 없어요.\n\nLars Wiik이나 그의 전화번호에 대한 언급이 없습니다.\n\n텍스트에 Lars Wiik의 전화번호가 제공되지 않았어요.\n\n제공된 텍스트에 Lars Wiik을 위한 가짜 전화번호가 포함되어 있지 않아요.\n\n죄송하지만, 제공된 문맥에서 Lars Wiik을 위한 가짜 전화번호가 언급되지 않았어요.\n```\n\nGemini 모델은 해리 포터 이야기 속에서 가짜 전화번호를 찾는 데 어려움을 겪는 것으로 보입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n오픈AI의 gpt-3.5-turbo-0125에서 몇 가지 응답을 확인해보세요:\n\n```js\nN/A\n\nN/A\n\n주어진 맥락에서 랄스 빅에 대한 가짜 전화번호가 없습니다.\n\nN/A\n\n9 3/4 번 승강장.\n\n랄스 빅을 위한 전화번호는 제공되지 않았습니다.\n```\n\n웃기게도, LLM은 \"9 3/4 번 승강장\"이라고 한적이 있어요 😄\n\n# 결론 💡\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n결론적으로, \"Needle in the Haystack\" 평가는 긴 맥락을 사용할 때 대형 언어 모델의 이해력과 정보 검색 능력을 측정하는 데 사용될 수 있습니다.\n\n이 분석에서는 OpenAI의 모델과 Google의 Gemini 시리즈 간에 성능 격차를 관찰했습니다. 여기서 OpenAI의 gpt-4, gpt-4o 및 gpt-4-turbo가 가장 높은 점수를 받았습니다.\n\nGoogle의 최근 Gemini의 100만 토큰을 처리할 수 있는 능력을 향상시킨 것에도 불구하고, OpenAI 모델이 큰 텍스트에서 구체적인 정보를 정확하게 검색하는 더 일관된 능력을 보인 것으로 나타났습니다.\n\n사용자와 개발자들에게는 응용 프로그램의 특정 요구 사항에 따라 모델 선택이 달라질 것으로 예상됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n읽어 주셔서 감사합니다!\n\n앞으로도 비슷한 콘텐츠를 받으려면 팔로우하세요!\n\n질문이 있으면 언제든지 문의해 주세요!\n","ogImage":{"url":"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png"},"coverImage":"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png","tag":["Tech"],"readingTime":9},{"title":"LangChain과 Neo4j를 활용한 GraphRAG 소개","description":"","date":"2024-05-20 20:33","slug":"2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j","content":"\n![그림](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png)\n\nLLM-파워드 애플리케이션 랜드스케이프에서 그래프 기반 기술에 대한 제 최근 기사에서는 이러한 데이터 구조가 다중 에이전트 프레임워크의 맥락에서 어떻게 활용될 수 있는지 탐구했습니다. 더 구체적으로, 2024년 1월에 소개된 새로운 LangChain 라이브러리인 LangGraph에 대해 다루었는데, 이는 에이전트 애플리케이션을 위한 대표적 프레임워크로서 그래프 수학적 객체를 기반으로 합니다.\n\nLangGraph의 주요 목표는 기존 LangChain의 주요 제한사항인 실행 중 사이클 부재를 극복하는 것입니다. 이 제한사항은 개발 목적에 따라 방향성이 있는 비순환 그래프(DAGs)에 쉽게 사이클을 도입하여 우회할 수 있습니다.\n\n하지만 그래프는 Retrieval Augmented Generation (RAG) 시나리오에서도 지식베이스를 조직하는 강력한 도구입니다. 구체적으로, 그래프는 \"검색\" 단계를 강화하여 더 의미 있는 컨텍스트 검색을 이끌어내어 보다 정확한 생성된 응답을 얻는 데 도움이 됩니다. 이를 위해, 아이디어는 지식베이스를 그래프 기반 데이터베이스(예: Neo4j)에 저장하고, LLM의 의미론적 파워를 활용하여 엔티티와 관계를 올바르게 추출하고 매핑하는 것입니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 질문은: 어떻게 하는 걸까요? 다행히도 LangChain은 LLMGraphTransformer라는 강력한 라이브러리를 개발했습니다. 이 라이브러리의 목적은 구조화되지 않은 텍스트 데이터를 그래프 기반 표현으로 변환하는 것입니다.\n\n이 라이브러리가 어떻게 작동하는지 완벽히 이해하기 위해, 먼저 그래프의 작동 방식과 관련 용어를 다시 확인해 보겠습니다.\n\n## 그래프와 그래프 데이터베이스\n\n그래프는 객체간의 쌍별 관계를 모델링하는 데 사용되는 수학적 구조입니다. 노드와 관계 두 가지 주요 요소로 구성됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 노드: 노드는 전통적인 데이터베이스에서 레코드로 볼 수 있습니다. 각 노드는 사람이나 장소와 같은 객체 또는 개체를 나타냅니다. 노드는 \"고객\" 또는 \"제품\"과 같은 역할에 따라 분류되는 레이블에 의해 분류되어 쿼리됩니다.\n- 관계: 이것들은 노드 간의 연결을 나타내며 서로 다른 개체 간의 상호 작용 또는 관계를 정의합니다. 예를 들어, 사람은 \"EMPLOYED_BY\" 관계를 통해 회사에 연결될 수 있습니다. 또는 \"LIVES_IN\" 관계를 통해 장소에 연결될 수 있습니다.\n\n![그래프](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_1.png)\n\n유사한 구조로 데이터를 저장하기 위해 2000년대 초에 새로운 데이터베이스 패밀리가 소개되었습니다: 그래프 데이터베이스. 그래프 데이터베이스는 데이터 사이의 관계를 데이터 자체와 동등하게 중요하게 취급하도록 설계된 데이터베이스 유형입니다. 그들은 서로 연결된 데이터와 복잡한 쿼리를 효율적으로 처리하기 위해 최적화되어 있습니다.\n\n가장 잘 알려진 것 중 하나는 Neo4j이며, 이 데이터베이스는 노드와 관계뿐만 아니라 속성, 레이블 및 경로 기능을 활용하여 데이터를 표현하고 저장하는 유연한 그래프 구조를 사용합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 속성: 노드와 관계 모두 속성을 포함할 수 있습니다. 이는 key-value 쌍으로 저장된 속성으로, 엔티티에 관한 구체적인 세부 정보를 제공합니다. 예를 들어, 사람의 이름이나 나이 또는 관계의 길이와 같은 정보를 포함할 수 있습니다.\n- 레이블: 레이블은 노드에 할당된 태그로, 노드를 다양한 유형으로 분류하는 데 사용됩니다. 단일 노드는 여러 레이블을 가질 수 있으며, 이는 그래프를 보다 동적이고 유연하게 조회하는 데 도움이 됩니다.\n- 경로: 경로는 노드와 관계를 연결하는 순서가 정해진 시퀀스를 설명합니다. 그들과 그들 사이를 연결하는 경로를 나타내며, 다른 노드가 어떻게 서로 연결되는지 보여줍니다. 경로는 조회에서 유용하며, 소셜 네트워크에서 한 사람에서 다른 사람까지 모든 가능한 경로를 발견하는 것과 같은 노드 간의 관계를 찾는 데 사용됩니다.\n\n이것은 Neo4j가 특히 소셜 네트워크, 추천 시스템 및 사기 탐지와 같은 응용 프로그램에 적합한 이유입니다. 여기서 관계와 동적 조회가 중요합니다.\n\n## RAG 및 GraphRAG\n\n검색 증강 생성(RAG)은 LLM(언어 모델)을 기반으로 하는 응용 프로그램 시나리오에서 강력한 기술로, 다음 문제에 대응합니다: \"LLM이 훈련된 데이터 세트에 포함되지 않는 내용을 LLM에게 물어보고 싶다면 어떻게 해야 하나요?\". RAG의 아이디어는 LLM과 우리가 탐색하고자 하는 지식 베이스를 분리하는 것이며, 이는 적절히 벡터화되거나 임베드되어 VectorDB에 저장된 지식 베이스에서 이루어집니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nRAG는 세 단계로 구성되어 있습니다:\n\n- 검색 → 사용자의 쿼리와 해당 벡터를 고려했을 때, 가장 유사한 문서 조각들(사용자 쿼리의 벡터에 더 가까운 벡터에 해당하는 것들)이 검색되어 LLM의 기본 맥락으로 사용됩니다.\n\n![image](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_2.png)\n\n- 증강 → 검색된 맥락은 추가적인 지시사항, 규칙, 안전 가드레일 및 프롬프트 엔지니어링 기술에 특히 특징적인 유사한 방법을 통해 풍부화됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_3.png\" />\n\n- Generation → 사용자의 쿼리에 대한 응답을 LLM이 증강된 컨텍스트를 기반으로 생성합니다.\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_4.png\" />\n\n언급했듯이 일반적인 RAG 애플리케이션은 모든 내장된 지식 베이스가 저장된 기저 VectorDB를 가정합니다. 그러나 GraphRAG의 경우 이 접근 방식이 약간 변합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n사실 그래프 RAG는 \"검색\" 단계에서 작동합니다. 그래프 구조의 유연성을 활용하여 지식 베이스를 저장하고, 더 많은 관련 문서 조각을 검색하고 이를 컨텍스트로 확장하는 것을 목표로 합니다 (마이크로소프트의 그래프 RAG에 대한 첫 실험에 대해 여기에서 읽을 수 있습니다).\n\n지식을 검색하는 데 그래프 데이터베이스를 활용하는 두 가지 주요 방법이 있습니다:\n\n- 그래프 검색(키워드 검색인)을 완전히 의지하여 관련 문서를 검색한 후, 생성 모델로 최종 응답을 생성하는 데 사용할 수 있습니다.\n- 그래프 검색과 벡터 검색(임베딩을 통한)과 같은 더 발전된 LLM 관련 검색을 결합할 수 있습니다.\n\n참고: Neo4j도 벡터 검색을 지원하며, 이는 하이브리드 그래프 RAG 시나리오에 매우 적합하게 만듭니다. 다음 섹션에서 확인할 수 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n무슨 방식을 선택하든, 프로세스의 핵심 단계는 지식 베이스를 그래프로 구성하는 것입니다. 우리에게 다행히도, LangChain은 이 목표에 정확히 부합하는 새 라이브러리를 소개했습니다: 비구조화된 지식을 그래프 데이터베이스에 매핑하기 쉽게 만들어주는 것을 목표로 한 새 라이브러리를 도입했습니다. 이 글 전체를 통해 우리는 Neo4j를 활용한 구현을 살펴볼 것입니다.\n\n## LangChain 및 LLMGraphTransformer와 함께 구현하기\n\nLangChain은 LLM을 애플리케이션에 통합하기 쉽게 만드는 다양하고 계속 성장하는 라이브러리, 사전 구축된 구성 요소 및 커넥터들을 제공하는 활기찬 생태계를 제공합니다. 최근 릴리스 중 하나가 GraphRAG 방향으로 나아간 것인 LLMGraphTransformer입니다.\n\nLLMGraphTransformer의 좋고 강력한 점은 현재 OpenAI 모델(포함된 Azure OpenAI 및 Mistral)을 활용하여 텍스트 내의 개체와 관계를 파싱하고 분류한다는 것입니다. 실제로 LLM의 자연어 기능 덕분에 결과 그래프는 문서 내의 가장 정교한 상호 연결성조차도 정확하게 포착하여 이전 방법에 비해 극도로 정확합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제부터는 몇 줄의 코드로 구조화되지 않은 문서에서 시작하여 완전히 채워진 그래프를 얻을 수 있습니다 (그 뒤에 있는 로직을 확인하고 싶다면, 여기서 소스 코드를 볼 수 있습니다).\n\n예제를 살펴보겠습니다. 먼저, 무료 인스턴스인 Neo4j Aura 데이터베이스를 사용하겠습니다 (이 자습서를 따라 직접 만들 수 있습니다) 그리고 Azure OpenAI GPT-4 모델을 사용할 것입니다.\n\nAuraDB 인스턴스를 생성하고 나면, 다음에서 실행 중인 것을 확인할 수 있을 겁니다:\n\n![이미지](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_5.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n아래는 인스턴스에 연결해야 하는 변수들입니다:\n\n```js\nos.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\");\nos.environ[\"NEO4J_USERNAME\"] = \"neo4j\";\nos.environ[\"NEO4J_PASSWORD\"] = os.getenv(\"NEO4J_PASSWORD\");\napi_key = os.getenv(\"AZURE_OPENAI_API_KEY\");\nazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\");\napi_version = \"2023-07-01-preview\";\n```\n\n이제 LLM을 초기화해보겠습니다:\n\n```js\nllm = AzureChatOpenAI(\n  (model = \"gpt-4\"),\n  (azure_deployment = \"gpt-4\"),\n  (api_key = api_key),\n  (azure_endpoint = azure_endpoint),\n  (openai_api_version = api_version)\n);\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 시작할 수 있는 샘플 문서가 있습니다! (해리 포터와 마법사의 돌의 처음 몇 줄을 선택했습니다):\n\n```js\n#LLMTransformer 모델 초기화\nllm_transformer = LLMGraphTransformer(llm=llm)\n\n#문서 변환\nfrom langchain_core.documents import Document\n\ntext = \"\"\"\n더즈리 부부는 프리벳 드라이브 4번에 살았는데, 그들은 매우 평범하다고 자랑스러워했습니다. 상당한 정도로 정상적인 것이라고 말이죠. 그들은 이상하거나 신비한 어떤 일에도 연루될 것으로는 전혀 예상하지 못한 사람들이었습니다. 왜냐하면 그들은 그러한 헛소리를 믿지 않았거든요.\n두즐리 씨는 대두를 만드는 그런닝스라는 회사의 사장이었습니다. 그는 거의 목이 없는 크고 굵은 남자였는데, 아주 큰 수염은 있었습니다. 두즐리 부인은 날씬하고 금발이었으며, 보통의 두 배 정도의 목을 가졌는데, 이것은 이웃을 엿보기 위해 정원 울타리 위를 많이 빙빙 돌아다닐 때 매우 유용했습니다. 두즐리 부부는 더드리라 불리는 작은 아들을 가지고 있었고, 그들은 자신들의 의견으로는 그보다 더 훌륭한 아이는 어디에도 없다고 생각했습니다.\n더즈리 부부는 원하는 모든 것을 가지고 있었지만, 비밀도 하나 있었고, 가장 큰 두려움은 누군가가 그것을 발견할까봐라는 것이었습니다. 그들은 포터 가족에 대해 누군가가 알아낼까 봐 가만히 있을 수 없다고 생각했습니다. 더즈리 부인은 포터 부인이었는데, 하지만 여러 해동안 만나지 않았습니다. 사실 더즈리 부인은 언니가 없다고 속이곤 했습니다. 왜냐하면 그녀의 언니와 그녀 생각엔 아무것도 안 하는 남편이 흔치 않은 더즈리식인 것과 같이 달랐기 때문이었습니다. 더즈리 부부는 포터 가족이 거리에 도착하면 이웃들이 무슨 말을 할 지 상상하며 소름 끼치곤 했습니다. 더즈리 부부는 포터 가족이 작은 아들까지 가졌다는 것을 알고 있었지만, 심지어 그를 본 적이 한 번도 없었습니다. 이 아이를 만나지 않는 것은 포터 가족을 멀리하고 싶은 다른 이유였습니다. 둘리는 그런 아이와 어울리길 원치 않았기 때문이죠.\n\"\"\"\ndocuments = [Document(page_content=text)]\ngraph_documents = llm_transformer.convert_to_graph_documents(documents)\nprint(f\"노드:{graph_documents[0].nodes}\")\nprint(f\"관계:{graph_documents[0].relationships}\")\n```\n\n```js\n노드: [\n  Node((id = \"Mr. Dursley\"), (type = \"Person\")),\n  Node((id = \"Mrs. Dursley\"), (type = \"Person\")),\n  Node((id = \"Dudley\"), (type = \"Person\")),\n  Node((id = \"Privet Drive\"), (type = \"Location\")),\n  Node((id = \"Grunnings\"), (type = \"Organization\")),\n  Node((id = \"Mrs. Potter\"), (type = \"Person\")),\n  Node((id = \"The Potters\"), (type = \"Family\")),\n];\n관계: [\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (type = \"MARRIED_TO\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Dudley\"), (type = \"Person\"))),\n    (type = \"PARENT_OF\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Dudley\"), (type = \"Person\"))),\n    (type = \"PARENT_OF\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Grunnings\"), (type = \"Organization\"))),\n    (type = \"WORKS_AT\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Privet Drive\"), (type = \"Location\"))),\n    (type = \"LIVES_AT\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Privet Drive\"), (type = \"Location\"))),\n    (type = \"LIVES_AT\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Mrs. Potter\"), (type = \"Person\"))),\n    (type = \"SISTER_OF\")\n  ),\n  Relationship(\n    (source = Node((id = \"The Dursleys\"), (type = \"Family\"))),\n    (target = Node((id = \"The Potters\"), (type = \"Family\"))),\n    (type = \"WANTS_TO_AVOID\")\n  ),\n];\n```\n\n보시다시피, llm_transformer는 우리가 지정할 필요 없이 데이터에서 관련 엔티티와 관계를 캡처했습니다. 이제 이러한 노드와 관계를 AuraDB에 저장해야 합니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ngraph.add_graph_documents(\n  graph_documents,\n  (baseEntityLabel = True),\n  (include_source = True)\n);\n```\n\n그리고 다 끝났어요! 이제 우리는 채워진 그래프 데이터베이스를 가지게 되었습니다. 이제 우리 온라인 AuraDB 인스턴스에서 올바르게 업로드된 문서를 확인할 수 있습니다.\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_6.png\" />\n\n또한 우리 DB의 그래픽 표현을 다음의 Python 함수로 그릴 수도 있습니다:\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 지정된 Cypher 쿼리에서 그래프를 보여주는 함수\ndefault_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n\ndef showGraph(cypher: str = default_cypher):\n    # 쿼리를 실행할 neo4j 세션 생성\n    driver = GraphDatabase.driver(\n        uri=os.environ[\"NEO4J_URI\"],\n        auth=(os.environ[\"NEO4J_USERNAME\"],\n              os.environ[\"NEO4J_PASSWORD\"]))\n    session = driver.session()\n    widget = GraphWidget(graph=session.run(cypher).graph())\n    widget.node_label_mapping = 'id'\n    #display(widget)\n    return widget\n\nshowGraph()\n```\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_7.png\" />\n\n이제 그래프 데이터베이스가 준비되었으니, 검색 기능을 향상시키는 벡터 검색 기능을 추가할 수 있습니다. 이를 위해 임베딩 모델이 필요하며, Azure OpenAI text-embedding-ada-002를 다음과 같이 사용하겠습니다:\n\n```js\nfrom langchain_openai import AzureOpenAIEmbeddings\n\nembeddings = AzureOpenAIEmbeddings(\n    model=\"text-embedding-ada-002\",\n    api_key=api_key,\n    azure_endpoint=azure_endpoint,\n    openai_api_version=api_version,\n)\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\nvector_index = Neo4jVector.from_existing_graph(\n  embeddings,\n  (search_type = \"hybrid\"),\n  (node_label = \"Document\"),\n  (text_node_properties = [\"text\"]),\n  (embedding_node_property = \"embedding\")\n);\n```\n\n이제 vector_index를 벡터 유사도 방법을 사용하여 쿼리할 수 있습니다:\n\n```js\nquery = \"떄리 누구야?\";\n\nresults = vector_index.similarity_search(query, (k = 1));\nprint(results[0].page_content);\n```\n\n```js\n버지니아 주 프리벳 드라이브 4번지에 사는 더즐리 부부는 매우 정상적인 사람들이라고\n자랑스러워했다. 그들은 이상하거나 신비한 일에 관여할 것으로 생각되는 마지막\n사람들 중 하나였다. 그들은 이러한 말장난을 믿지 않았다. 더즐리 씨는\n드릴을 만드는 그러닝스 회사의 사장이었다. 그는 목이 거의 없는 건장한 사나이였지만,\n매우 커다란 수염을 키웠다. 더즐리 부인은 날씬하고 금발이었으며, 보통의 목 두배의\n길이를 가졌으며 이 긴 목은 너네 집 이웃들을 엿보는 데 매우 유용했다. 더즐리\n가족은 말 그대로 어디서도 찾아볼 수 없는 더 좋은 아이가 없다고 생각했다. 그들은\n원하는 모든 것을 가지고 있었지만, 그들은 비밀을 하나 갖고 있었으며, 그들의\n가장 큰 두려움은 누군가 그 비밀을 발견할까 봐였다. 그들은 포터 가족에 대해\n누군가에게 알려지는 것을 견딜 수 없을 거라고 생각했다. 포터 부인은 더즐리 부인의\n자매였지만 그들은 여러 해간 만나지 않았다. 사실, 더즐리 부인은 자신에게\n자매가 없는 것처럼 꾸역꾸역 거짓말쳤다. 왜냐하면 그녀의 자매와 그녀의\n아무 소용 없는 남편은 가능한 한 더즐리 씨와 반대되는 사람이었다. 더즐리\n씨 부부가 거주하는 골목에 포터 가족이 도착하면 이웃들이 무슨 말을 할지\n생각만 해도 더즐리 부부는 오싹했다. 포터 가족이 또 다른 작고 맹수를 가졌다는\n것을 더즐리 부부는 알고 있었지만, 그들은 심지어 그 아이를 본 적이 없었다. 이\n아이가 포터 가족을 피해야 하는 또 다른 좋은 이유였다. 그들은 더 말해야 하는\n이유는 없었다. 더즐리 부부는 더즐리 씨 부부 내의 아이와 섞이는 것을 원치 않았다.\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n물론, 텍스트를 조각내지 않았기 때문에 쿼리는 전체 문서를 반환할 것입니다. 다음 파트에서는 더 큰 문서를 다룰 때 이것이 관련성을 가지게 되는 방법을 알아볼 것입니다.\n\n마지막 단계는 모델에서 생성된 실제 답변을 가져오는 것입니다. 이를 위해 두 가지 다른 접근 방법을 활용할 수 있습니다:\n\n- Neo4j의 Cypher 쿼리 언어를 활용하여 그래프 데이터베이스와 상호 작용하는 사전 구축된 구성 요소인 CypherChain을 활용합니다. Neo4j와 네이티브로 통합되어 있으므로 AuraDB 그래프 기능과 상호 작용하여 쿼리 결과를 이해함으로써 문맥을 고려한 응답을 활성화합니다. 높은 정밀도, 문맥 인식, 그리고 Neo4j의 그래프 기능과의 직접적 상호 작용이 필요할 때 권장됩니다.\n\n```js\nfrom langchain.chains import GraphCypherQAChain\n\nchain = GraphCypherQAChain.from_llm(graph=graph, llm=llm, verbose=True)\nresponse = chain.invoke({\"query\": \"Mr. Dursley의 직업은 무엇인가요?\"})\nresponse\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n> 새로운 GraphCypherQAChain 체인에 입장 중...\n생성된 Cypher:\nMATCH (p:Person {id: \"Mr. Dursley\"})-[:WORKS_AT]->(o:Organization) RETURN o.id\n전체 컨텍스트:\n[{'o.id': 'Grunnings'}]\n\n> 체인 완료.\n{'query': \"Mr. Dursley의 직업은 무엇인가요?\",\n 'result': 'Mr. Dursley는 Grunnings에서 일합니다.'}\n```\n\n- 고전적인 QA 체인을 활용하여 LangChain의 데이터 저장소(vectordb 및 graphdb 모두)에 적용 가능한 vector_index.as_retriever() 메서드를 사용합니다.\n\n```js\nfrom langchain.chains import RetrievalQA\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm, retriever=vector_index.as_retriever()\n)\n\nresult = qa_chain({\"query\": \"Mr. Dursley의 직업은 무엇인가요?\"})\nresult[\"result\"]\n```\n\n```js\n\"Mr. Dursley는 드릴을 만드는 회사인 Grunnings의 이사입니다.\";\n```\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n응답의 정확성을 잠시 보류하는 것이 좋습니다. 문서는 아직 청크로 나누어지지 않았으므로 현재 벤치마킹하는 것은 의미가 없습니다. 다음 파트에서는 이러한 구성 요소 간의 차이를 인식하고 이를 통해 훌륭한 RAG 성능을 낼 수 있는 방법에 대해 알아볼 것입니다.\n\n## 결론\n\n이 시리즈의 제1부에서는 그래프 데이터베이스의 기초와 RAG 기반 응용 프로그램의 맥락에서 그 이유를 다뤘습니다. 제2부에서는 이 첫 번째 부분에서 소개 된 모든 구성 요소를 활용한 그래프 기반 접근 방식의 실제 구현을 살펴볼 것입니다. 전체 GitHub 코드는 2부와 함께 제공될 예정입니다.\n\n제2부를 기대해주세요!\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 참고 자료\n\n- [Directed Acyclic Graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph?ref=blog.langchain.dev)\n- [LangGraph 블로그](https://blog.langchain.dev/langgraph/)\n- [Python API 문서](https://api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/llm.html#LLMGraphTransformer)\n- [Neo4j Cypher 소개](https://neo4j.com/docs/getting-started/cypher-intro/#:~:text=Cypher%20is%20Neo4j`s%20graph%20query,how%20to%20go%20get%20it).\n- [Microsoft Research 블로그](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)\n- [LangChain Quickstart](https://langchain.com/quickstart)\n","ogImage":{"url":"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png"},"coverImage":"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png","tag":["Tech"],"readingTime":18},{"title":"LLMLarge Language Model의 추천은 제품의 가시성을 높이기 위해 조작될 수 있을까요","description":"","date":"2024-05-20 20:31","slug":"2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility","content":"\n## 책임 있는 인공지능\n\n요즘 트위터에서 한 가지 팁을 발견해서 공유해볼게. \"before:2023\"을 구글 검색에 추가하면 AI가 생성한 SEO 콘텐츠를 걸러낼 수 있다는 거야. 실제로는 이 기능을 사용해본 적이 없지만, 개념은 이해가 되겠지? 요즘 인터넷은 너무 많은 AI 생성 콘텐츠로 가득 차 있어서 실제 정보를 걸러내기가 어려워졌어. 상황이 심각해서 구글도 검색 알고리즘 조작하고 순위를 인위적으로 높이려는 모든 AI 생성 콘텐츠를 제거하기로 결정했어. 말이 AI 생성 콘텐츠에 반대한다는 게 아니야, 하지만 검색 결과에 영향을 주기 시작하면 문제가 될 수 있어. Generative AI 시대에는 콘텐츠 생성이 너무 쉬워져서 상황이 더 복잡해지는 거야.\n\n대규모 언어 모델(LLMs)은 이미 전자 상거래 플랫폼에서 검색 및 추천 프로세스를 개선하는 데 사용되고 있어. 그런데 추천을 제공하는 데 사용되는 이 LLM이 조작된다면 어떻게 될까? 전자 상거래 시장에서의 조작은 새로운 게 아니야. 로이터(Reuters)의 2016년 보고서에 따르면 아마존은 \"검색 시드(Seeding)\"라는 기술을 사용해 아마존 베이직스(AmazonBasics)와 솔리모(Solimo) 브랜드 제품이 출시 직후 상위 검색 결과에 표시되도록 했어. 보고서에는 \"검색 시드를 사용해 신규 출시된 ASINs가 검색 결과의 처음 두 개 또는 세 개의 ASIN으로 나타나도록 했다\"고 구체적으로 언급돼. LLMs를 이용하면 규모와 속도 때문에 상황이 더 악화될 수 있어.\n\nManipulating Large Language Models to Increase Product Visibility란 제목의 새 연구에서 Aounon Kumar와 Himabindu Lakkaraju가 이러한 시나리오를 자세히 연구했어. 특히 제품 정보에 전략적 텍스트 시퀀스(STS)라고 불리는 특별히 디자인된 메시지를 포함시킴으로써 특정 업체들이 경쟁 업체에 비해 불공정한 이점을 얻고 제품이 최상의 추천으로 선정될 가능성이 크게 증가함을 보여줘. 이런 관행은 소비자들의 구매 결정과 온라인 시장에 대한 신뢰에 영향을 미칠 수 있어, 온라인 비즈니스에서 신뢰는 중요한 요소니까.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n본 문서에서는 작가들이 이 특별한 텍스트 시퀀스를 생성하고 논문에서 전달된 결과를 더 자세히 이해하는 방법에 대해 이해해 봅시다. 작가들은 관련 코드를 GitHub에서 공개했습니다.\n\n# LLM 기반 검색 작동 방식\n\n일반적인 검색 엔진은 관련 페이지를 찾는 데 효과적이지만 정보를 일관되게 제시하는 데는 그리 효과적이지 않습니다. 반면 LLM(Large Language Model)은 검색 결과를 가져와 관련 답변으로 변환할 수 있습니다. 사용자의 검색어를 받으면 검색 엔진은 인터넷이나 제품 설명서와 같은 지식 베이스에서 관련 정보를 가져옵니다. 이후 이 검색 결과와 사용자의 입력을 LLM에 공급하기 전에 사용자의 쿼리와 함께 이 정보를 연결하여 LLM이 사용자의 특정한 요구에 직접적으로 대응하는 맞춤형 최신 답변을 생성할 수 있습니다. 아래 그림(상기한 논문에서 제공)은 전체 과정을 자세히 보여줍니다.\n\n<img src=\"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png\" />\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# LLM이 생성한 추천을 조작할 수 있을까요?\n\n논문은 특정 제품을 선호하도록 LLM이 생성한 추천을 조작할 수 있다는 사실을 입증하기 위한 설득력 있는 예시를 제시합니다. 예를 들어, 아래의 그림을 살펴보세요 (이 그래프가 어떻게 만들어졌는지에 대한 세부 내용은 나중에 설명하겠습니다). 아래 그래프는 전략적 텍스트 시퀀스(STS)를 추가하기 전과 후의 추천 척도에서 제품의 순위 차이를 명확히 보여줍니다. STS를 적용하기 전에는 제품이 일관되게 추천 중에서 하위 순위, 순위 10 근처에 위치했습니다. 그러나 STS를 적용한 후에는 제품이 추천의 정상으로 도약하여 순위 1에 가까이 위치했습니다.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_1.png)\n\n이미 논의한 바와 같이, LLM을 활용한 검색의 장점은 인터넷이나 제품 카탈로그에서 정보를 추출할 수 있는 능력에 있습니다. 판매업자들은 여기서 프로세스를 가이드할 수 있는 기회를 가지게 됩니다. 어떻게 가능할까요? 이 carefully crafted texts 또는 STS를 제품 정보 페이지/카탈로그에 포함시켜 LLM의 입력으로 만들면 됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n<img src=\"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_2.png\" />\n\nSTS는 Universal and Transferable Adversarial Attacks on Aligned Language Models 논문에서 소개된 Greedy Coordinate Gradient (GCG)과 같은 적대적 공격 알고리즘을 사용하여 최적화됩니다. 이러한 공격은 일반적으로 LLM의 안전 제약 조건을 우회하고 해로운 출력을 생성하는 데 사용됩니다. 그러나 이 연구의 저자들은 이러한 알고리즘을 \"더 친화적인\" 목적으로 제품 가시성을 높이는 데 재활용합니다.\n\n# 커피 머신 추천을 위한 LLM 검색 인터페이스 쿼리\n\n저자들은 사용자가 가격이 적당한 커피 머신을 구매하고 싶어 하는 시나리오를 제시합니다. 이때 '적당한'이라는 단어에 주목해야 합니다. 이는 제품의 가격이 중요하며 사용자가 비싼 옵션을 원하지 않는다는 것을 의미합니다. 아래에 나와 있는 것처럼 LLM에 대한 입력 프롬프트로 시작해 봅시다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_3.png)\n\n- 시스템 프롬프트 — 맥락 설정,\n- 제품 정보 — JSON 형식의 데이터베이스에서 가져온 것으로, 10가지 가상 커피 머신 모델의 구체적인 내용을 제공합니다. 판매자는 여기에 STS를 포함할 수 있습니다.\n- 사용자의 쿼리 — 가격이 저렴한 옵션을 찾고 있습니다.\n\n논문에서 설명한 예시 프롬프트는 다음과 같습니다. 'ColdBrew Master Coffee machine'에 대한 '대상 제품' 필드에 STS가 삽입된 것을 확인해보세요.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_4.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n## 전략적 텍스트 시퀀스 제작\n\n논문에서 설명하는 텍스트 시퀀스 생성 과정의 일부를 확인할 수 있습니다.\n\n예를 들어, 제품 목록에서 ColdBrew Master의 순위를 높이려면 STS를 추가해야 합니다. 아래 표시된대로 STS는 '\\*,'로 표시된 자리 표시자 토큰 시퀀스로 시작하여 GCG 알고리즘을 사용하여 반복적으로 최적화됩니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n또한, 제품이 나열되는 방식에 관계없이 STS의 성능을 최적화하기 위해 각 최적화 이터레이션마다 제품 목록의 순서를 무작위로 섞을 수도 있습니다.\n\n결과는 일반적으로 가시성이 낮아질 수 있는 $199의 높은 가격에도 불구하고, ColdBrew Master가 STS를 설명에 통합하여 추천 목록 상단으로 이동했다는 것을 보여줍니다. 그리고 놀랍게도, STS를 통합한 후 100번의 이터레이션만으로 숨겨져 있던 순위에서 상위로 끌어올려졌습니다.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_6.png)\n\n# 두 제품, ColdBrew Master 및 QuickBrew Express에 대한 전략적 텍스트 시퀀스 최적화 비교\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 STS가 제품 순위에 미치는 영향에 대한 감을 잡았으니 다음 제품에 영향을 미치는 방법을 비교해보겠습니다.\n\n☕️ ColdBrew Master는 가격이 $199로 높은 가격의 커피 머신입니다.\n\n☕️ QuickBrew Express는 $89로 더 저렴한 옵션입니다.\n\n여기에 비교 결과를 비교하기 위해 만든 표가 있습니다.\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n![image](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_7.png)\n\n위의 결과는 $199의 높은 가격에도 불구하고, 시각성이 적어지는 경향이 있는데도 ColdBrew Master가 STS를 설명에 통합함으로써 추천 목록의 선두로 올라간 것을 보여줍니다. 흥미로운 점은 이 제품이 원래 비용이 높아서 목록에 첫째 자리에 없었던 것입니다.\n\n반면, 더 저렴한 가격대의 QuickBrew Express의 순위는 일반적으로 추천 목록에서 둘째 자리를 차지하는데, STS를 추가하면서 크게 향상되어 종종 최상위 자리에 도달합니다.\n\n![image](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_8.png)\n\n<!-- ui-station 사각형 -->\n\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 결론적인 생각: Generative Search Optimization(GSO)가 새로운 SEO인가요?\n\n논문에서 소개된 상황은 현실과 크게 다르지 않습니다. 저자들은 Generative Search Optimization(GSO)와 전통적인 SEO 사이에 적절한 비교를 그려냈습니다.\n\n이전에 언급한 대로, 온라인 비즈니스의 성공은 고객들과 확립하는 신뢰와 평판에 밀접하게 연관되어 있습니다. 의도적으로 제품 추천을 조작하는 것은 공정성과 소비자 속임수와 관련하여 윤리적인 문제를 제기합니다. 가짜 제품 리뷰의 존재는 이미 계속되는 문제입니다. 우리는 확실히 조작된 추천이 이러한 상황을 더욱 복잡하게 만들길 원하지 않습니다.\n\n모든 블로그 및 관련 코드에 쉽게 액세스하려면 내 GitHub 저장소를 방문해주세요.\n","ogImage":{"url":"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png"},"coverImage":"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png","tag":["Tech"],"readingTime":8}],"page":"79","totalPageCount":119,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true}