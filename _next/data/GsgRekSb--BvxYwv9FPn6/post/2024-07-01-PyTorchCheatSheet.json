{"pageProps":{"post":{"title":"2024 최신 PyTorch 치트 시트 ","description":"","date":"2024-07-01 16:07","slug":"2024-07-01-PyTorchCheatSheet","content":"\n\nPyTorch에 대해 알아야 할 모든 것을 배워보세요.\n\n![PyTorch Cheat Sheet](/assets/img/2024-07-01-PyTorchCheatSheet_0.png)\n\n야심차고 데이터 고수! 챗봇, 이미지 인식 소프트웨어, 심지어 자율 주행 자동차 같은 멋진 AI 작품을 만들고 싶나요? PyTorch를 찾아보세요!\n\nPyTorch는 Facebook의 AI 전문가들이 만든 슈퍼 멋진 오픈소스 라이브러리로, 기계 학습(ML)과 심층 학습(DL)에 손쉽게 뛰어들 수 있게 해줍니다. 이 치트 시트는 PyTorch의 기본을 모두 배울 수 있는 한 곳의 쇼핑처가 될 것이며, 금세 기계 학습 마에스트로가 될 수 있도록 도와줄 거에요! ✨\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# PyTorch 불러오기\n\n필요한 주요 라이브러리를 알려드리겠습니다:\n\n```js\n# 핵심 기능을 위한 최상위 패키지 불러오기\nimport torch\n\n# 신경망 기능 불러오기\nfrom torch import nn\n\n# 함수형 프로그래밍 도구 불러오기\nimport torch.nn.functional as F\n\n# 최적화 기능 불러오기\nimport torch.optim as optim\n\n# 데이터셋 함수 불러오기\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# 평가 지표 불러오기\nimport torchmetrics\n```\n\n- import torch: 이게 본 프로그램이에요! PyTorch의 모든 중심 기능을 불러오는데요, 텐서(다차원 배열)를 구축하고 조작할 수 있습니다.\n- from torch import nn: 신경망 팬들 주목! 이 라이브러리를 사용하여 강력한 신경망을 만들 수 있는 기본 블록을 제공합니다.\n- import torch.nn.functional as F: 멋있게 만들고 싶나요? 이 라이브러리는 새로운 신경망 레이어를 만들기 위한 함수형 프로그래밍 도구를 제공하여 코드에 유연성을 더해줍니다.\n- import torch.optim as optim: 신경망을 훈련하는 것은 강아지를 훈련하는 것과 비슷해요 - 어떤 최적화가 필요해요! 이 라이브러리는 다양한 옵티마이저를 제공하여 신경망이 효율적으로 학습할 수 있도록 도와줍니다.\n- import torch.utils.data as data: 머신러닝에서 데이터는 중요해요! 이 라이브러리는 데이터셋을 효율적으로 관리하는 도구를 제공하여 훈련을 쉽게 만들어줍니다.\n- import torchmetrics: 모델이 얼마나 잘 수행되는지 잘 모르겠다구요? 이 라이브러리는 네트워크의 정확성과 효율성을 평가하는 메트릭 도구상자를 제공합니다.\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# Tensor 사용하기\n\n텐서는 PyTorch에서 기본적인 구성 요소로, AI 프로젝트용 레고 블록과 비슷한 역할을 합니다! 여기에서는 텐서를 만들고 조작하는 방법을 알아보겠습니다:\n\n```js\n# 리스트에서 tensor를 사용하여 텐서 생성\ntnsr = torch.tensor([1, 3, 6, 10])\n\n# 텐서 요소의 데이터 유형 가져오기: .dtype\ntnsr.dtype # torch.int64가 반환됩니다.\n\n# 텐서의 차원 가져오기: .size()\ntnsr.shape # torch.Size([4])가 반환됩니다.\n\n# 텐서의 메모리 위치 가져오기: .device\ntnsr.device # cpu 또는 gpu가 반환됩니다.\n\n# 모든 요소가 0인 텐서 만들기: zeros()\ntnsr_zrs = torch.zeros(2, 3)\n\n# 무작위 텐서 만들기: rand()\ntnsr_rndm = torch.rand(size=(3, 4)) # 텐서는 3행 4열입니다.\n```\n\n# 데이터셋과 데이터로더\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n기계 학습에서 데이터는 왕이에요! 그런데 데이터를 모델에 효율적으로 전달하는 것은 다루기 어려운 일일 수 있어요. 그럴 때 데이터셋과 데이터로더가 등장합니다. 믿을 수 있는 드래곤처럼 당신을 지켜줄 거예요.\n\n- 데이터셋 구축: 데이터셋은 깔끔하게 구성된 귀하의 훈련 데이터 모음으로 상상해보세요. 데이터가 판다스 DataFrame에 저장된 경우, TensorDataset()을 사용하여 데이터셋을 만들 수 있어요. 이 함수는 두 개의 인수를 취합니다:\n\n  - torch.tensor()를 사용하여 부동 소수점 숫자의 텐서로 변환된 특성(독립 변수).\n  - 부동 소수점 텐서로 변환된 목표(종속 변수).\n\n```js\n# TensorDataset()을 사용하여 판다스 DataFrame에서 데이터셋 만들기\nX = df[feature_columns].values\ny = df[target_column].values\ndataset = TensorDataset(torch.tensor(X).float(), torch.tensor(y).float())\n\n# DataLoader()를 사용하여 데이터를 배치로 로드하기\ndataloader = DataLoader(dataset, batch_size=n, shuffle=True)\n```\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 전처리\n\n신경망에 데이터를 입력하기 전에 몇 가지 준비작업이 필요합니다! 이를 전처리라고 합니다. PyTorch의 카테고리 변수(텍스트 레이블과 같은)를 다루기 위한 멋진 기능이 있습니다:\n\nF.one_hot()을 사용한 원-핫 인코딩\n\n“빨강,” “초록,” “파랑”과 같은 카테고리를 가진 데이터가 있다고 상상해보세요. 컴퓨터는 이러한 단어들을 처리하기 어려울 수 있습니다. 원-핫 인코딩은 이러한 카테고리를 특별한 종류의 텐서로 변환하는 트릭입니다. 이 텐서에는 각 가능한 카테고리에 대해 한 열이 있을 것입니다(이 경우 \"빨강,\" \"초록,\" \"파랑\"). 각 데이터 포인트에 대해, 해당 카테고리에 해당하는 열에 1이 있고, 나머지는 모두 0입니다.\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n다음은 PyTorch에서 F.one_hot()을 사용하는 방법입니다:\n\n```js\n# One-hot encode categorical variables with one_hot()\nF.one_hot(torch.tensor([0, 1, 2]), num_classes=3) # 0과 1로 구성된 텐서 반환\n```\n\n# Sequential Model Architecture\n\n이제 신경망 아키텍처를 구성해 봅시다! PyTorch의 nn.Sequential 클래스를 사용하면 레이어를 스택하는 것이 매우 쉬워집니다. 아래에서 설명하겠습니다.\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n선형 레이어: 네트워크의 주역! nn.Linear(m, n)을 사용하여 m개의 입력을 받고 n개의 출력을 생성하는 선형 레이어를 만들 수 있어요. 입력값을 가중치와 곱하고 편향을 더한 것으로 생각하면 돼요.\n\n가중치와 편향 엿보기: 선형 레이어의 내부 동작에 궁금해하는가요? .weight를 사용하여 가중치 행렬에 접근하고 .bias로 편향 벡터를 확인할 수 있어요. 이들은 훈련 중에 업데이트되는 내용이에요!\n\n활성화 함수: 네트워크에 복잡성을 더하는 비선형 히어로들이에요. 여기 인기 있는 몇 가지 선택사항이 있어요:\n\n- nn.Sigmoid(): 0과 1 사이의 값을 압축하는 함수로 이진 분류(일대다)에 자주 사용돼요.\n- nn.Softmax(dim=-1): 출력값을 합이 1이 되도록 확률로 변환시켜주는 함수로 다중 클래스 분류(다대다)에 이상적이에요.\n- nn.ReLU(): 음수 값을 0으로 설정하는 ReLU(Rectified Linear Unit). 소멸 그래디언트를 방지하는 데 도움이 돼요.\n- nn.LeakyReLU(negative_slope=0.05): ReLU와 유사하지만 0이 아닌 그래디언트를 위한 작은 양수 기울기를 허용하는 함수에요.\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\nDropout 레이어: 모델이 훈련 데이터를 너무 잘 기억할 때 발생하는 오버피팅을 nn.Dropout(p=0.5)로 극복하세요. 이는 훈련 중에 일정 비율의 활성화를 무작위로 제거하여 네트워크가 특정 기능에 너무 의존하지 않도록 유도합니다.\n\n모델 구축: 원하는 순서대로 레이어를 nn.Sequential로 연결해보세요. 각 레이어의 입력 크기는 이전 레이어의 출력 크기와 일치해야 합니다! 예를 들면 다음과 같습니다.\n\n```js\n# Linear()을 사용하여 입력이 m이고 출력이 n인 선형 레이어를 만듭니다.\nlnr = nn.Linear(m, n)\n\n# .weight로 레이어의 가중치를 가져옵니다\nlnr.weight\n\n# .bias로 레이어의 편향을 가져옵니다\nlnr.bias\n\n# Sigmoid()를 사용하여 이진 분류를 위한 시그모이드 활성화 레이어 생성\nnn.Sigmoid()\n\n# Softmax()를 사용하여 다중 클래스 분류를 위한 소프트맥스 활성화 레이어 생성\nnn.Softmax(dim=-1)\n\n# ReLU()를 사용하여 포화를 피하기 위한 계단식 활성화 레이어 생성\nnn.ReLU()\n\n# LeakyReLU()를 사용하여 포화를 피하기 위한 릭리 레키 크기를 설정\nnn.LeakyReLU(negative_slope=0.05)\n\n# Dropout()을 사용하여 규제하고 오버피팅을 방지하는 드롭아웃 레이어 생성\nnn.Dropout(p=0.5)\n\n# 레이어를 순차적으로 연결하여 모델 생성\nmodel = nn.Sequential(\n    nn.Linear(n_features, i),\n    nn.Linear(i, j),   # 입력 크기는 이전 레이어의 출력과 일치해야 합니다\n    nn.Linear(j, n_classes),\n    nn.Softmax(dim=-1) # 활성화 레이어가 마지막에 옵니다\n)\n```\n\n# 모델 훈련 및 손실 계산\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이제 데이터를 준비했고 모델을 구축했으니, 모델 훈련을 시작해봅시다!\n\n```js\n# 입력 데이터에 모델을 피팅하고 모델은 Sequential()을 통해 생성된 변수입니다.\nprediction = model(input_data).double()\n\n# 타겟 값들을 얻습니다.\nactual = torch.tensor(target_values).double()\n\n# 평균 제곱 오차 손실을 계산합니다. 회귀에는 MSELoss()를 사용합니다.\nmse_loss = nn.MSELoss()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# 강건한 회귀를 위한 L1 손실을 계산합니다. SmoothL1Loss()를 사용합니다.\nl1_loss = nn.SmoothL1Loss()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# 이진 분류를 위한 바이너리 크로스 엔트로피 손실을 계산합니다. BCELoss()를 사용합니다.\nbce_loss = nn.BCELoss()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# 다중 클래스 분류를 위한 크로스 엔트로피 손실을 계산합니다. CrossEntropyLoss()를 사용합니다.\nce_loss = nn.CrossEntropyLoss()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# .backward()를 사용하여 역전파로 기울기를 계산합니다.\nloss.backward()\n```\n\n# 옵티마이저 사용하기\n\n신경망을 훈련하는 것은 운동 선수를 훈련하는 것과 비슷합니다. 올바른 도구와 기술이 필요합니다! 이때 옵티마이저가 필요합니다.\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# SGD() 함수를 사용하여 확률적 경사 하강 옵티마이저를 생성하고 학습률 및 모멘텀 설정\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95)\n\n# .step()을 사용하여 뉴런 매개변수 업데이트\noptimizer.step()\n```\n\n파이토치에서는 optim 모듈을 사용하여 서로 다른 옵티마이저를 생성하여 신경망의 가중치와 편향을 조정하는 방법을 각각 지정할 수 있습니다. 이번에는 확률적 경사 하강 (SGD)라는 일반적인 옵티마이저를 사용하는 방법을 알아보겠습니다:\n\n- 옵티마이저 생성: optim.SGD()를 사용하여 SGD 옵티마이저를 생성합니다. 다음 두 가지 중요한 인수를 전달합니다:\n\n    - model.parameters(): 이를 통해 옵티마이저에게 모델에서 업데이트해야 할 매개변수(가중치와 편향)를 알려줍니다.\n    - lr=0.01: 이는 학습률로, 옵티마이저가 각 단계에서 매개변수를 얼마나 조정할지를 제어합니다. 작은 학습률은 조심스러운 업데이트를 유도하고, 큰 학습률은 학습 속도를 빠르게 할 수 있지만 (또한 잠재적으로 불안정성을 유발할 수 있음) 빠른 학습을 할 수 있습니다.\n\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n# 훈련 루프\n\n```js\n# 모델을 훈련 모드로 설정합니다.\nmodel.train()\n# 손실 기준 및 옵티마이저 설정\nloss_criterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95)\n# 훈련 세트의 데이터 청크를 반복합니다.\nfor data in dataloader:\n    # 그라디언트를 0으로 설정합니다.\n    optimizer.zero_grad()\n    # 현재 데이터 청크의 특징과 타깃을 가져옵니다.\n    features, targets = data\n    # \"순방향 패스\"를 실행하여 모델을 데이터에 맞춥니다.\n    predictions = model(data)\n    # 손실 계산\n    loss = loss_criterion(predictions, targets)\n    # 역전파를 사용하여 그래디언트 계산\n    loss.backward()\n    # 모델 매개변수 업데이트\n    optimizer.step()\n```\n\n# 평가 루프\n\n굉장한 PyTorch 모델을 훈련한 후, 이제 얼마나 잘 수행되는지 확인해보세요!\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\n# 모델을 평가 모드로 설정\nmodel.eval()\n\n# 정확도 메트릭 생성\nmetric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n# 검증 세트에서 데이터 청크 루프\nfor i, data in enumerate(dataloader, 0):\n    # 현재 데이터 청크의 특징과 타겟 가져오기\n    features, targets = data\n    # 모델을 데이터에 맞추기 위해 \"포워드 패스\" 실행\n    predictions = model(data)\n    # 배치의 정확도 계산\n    accuracy = metric(output, predictions.argmax(dim=-1))\n# 전체 검증 데이터에 대한 정확도 계산\naccuracy = metric.compute()\nprint(f\"All 데이터에 대한 정확도: {accuracy}\")\n# 다음 데이터셋(학습 또는 검증)을 위해 메트릭 재설정\nmetric.reset()\r\n```\n\n# 전이 학습과 파인튜닝\n\n머신 러닝에서 사전 훈련된 모델을 활용하여 우리 자신의 프로젝트를 빠르게 시작할 수 있습니다. 이를 전이 학습이라고하며, 그 내에서 파인튜닝은 강력한 기술입니다. PyTorch가 여러분을 돕는 방법을 살펴보겠습니다:\n\n나중을 위한 레이어 저장: 모델의 특정 레이어를 훈련시키고 나중에 다시 사용하고 싶다면, torch.save()를 사용하여 레이어의 가중치와 편향을 파일로 직렬화할 수 있습니다. 이는 미래 AI 프로젝트를 위한 청사진을 저장하는 것으로 생각할 수 있습니다!\n\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```js\ntorch.save(layer, 'layer.pth')  # 'layer.pth' 파일에 레이어를 저장합니다.\n```\n\n저장된 레이어 불러오기: 이전에 저장한 레이어를 가져와야 하는 경우가 있습니다. torch.load()를 사용하여 다시 불러올 수 있습니다! 새 모델에 사전 훈련된 레이어를 통합하는 데 유용합니다.\n\n```js\nnew_layer = torch.load('layer.pth')  # 'layer.pth' 파일에서 레이어를 불러옵니다.\n```\n\n동결된 파워로 파인튜닝! 예를 들어, 사전 훈련된 모델이 있고 특정 작업을 위해 최종 레이어만 파인튜닝하려는 경우가 있습니다. PyTorch를 사용하면 .requires_grad = False를 사용하여 이전 레이어의 가중치를 동결시킬 수 있습니다. 이렇게 하면 훈련 중에 업데이트되지 않고 마지막 레이어에 중점을 두고 학습 프로세스를 진행할 수 있습니다.\n\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n```python\nfor name, param in model.named_parameters():\n    if name == \"0.weight\":\n        param.requires_grad = False  # 필요에 따라 레이어 번호를 조정하여 레이어 0의 가중치를 고정시킵니다.\n\n# 이제 최종 레이어만 업데이트되도록 모델을 학습할 수 있습니다!\n```\n\n전이 학습과 파인 튜닝을 마스터하면, 사전 학습된 지식을 활용하여 학습 시간을 단축시키고, 여러분을 머신러닝 효율성 챔피언으로 만들 수 있습니다!\n\n읽어 주셔서 감사합니다. 내 컨텐츠가 마음에 드시고 저를 지원하고 싶다면, Patreon에서 저를 지원하는 것이 가장 좋은 방법입니다 —\n\n<img src=\"/assets/img/2024-07-01-PyTorchCheatSheet_1.png\" />\n\n\n<!-- ui-station 사각형 -->\n<ins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"></ins>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n- 내 YouTube 채널 구독하기.\r\n- 내 웹사이트 방문하기.\r\n- LinkedIn과 Github에서 나와 연락하기! 나는 거기에서 무료로 놀라운 콘텐츠를 공유하고, 기술과 AI를 활용하여 더 생산적이고 효과적으로 일할 수 있도록 돕습니다.\r\n- 머신러닝 및 딥러닝 도움이 필요하신가요? 내 Fiverr 및 Upwork 서비스를 확인해보세요!","ogImage":{"url":"/assets/img/2024-07-01-PyTorchCheatSheet_0.png"},"coverImage":"/assets/img/2024-07-01-PyTorchCheatSheet_0.png","tag":["Tech"],"readingTime":13},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>PyTorch에 대해 알아야 할 모든 것을 배워보세요.</p>\n<p><img src=\"/assets/img/2024-07-01-PyTorchCheatSheet_0.png\" alt=\"PyTorch Cheat Sheet\"></p>\n<p>야심차고 데이터 고수! 챗봇, 이미지 인식 소프트웨어, 심지어 자율 주행 자동차 같은 멋진 AI 작품을 만들고 싶나요? PyTorch를 찾아보세요!</p>\n<p>PyTorch는 Facebook의 AI 전문가들이 만든 슈퍼 멋진 오픈소스 라이브러리로, 기계 학습(ML)과 심층 학습(DL)에 손쉽게 뛰어들 수 있게 해줍니다. 이 치트 시트는 PyTorch의 기본을 모두 배울 수 있는 한 곳의 쇼핑처가 될 것이며, 금세 기계 학습 마에스트로가 될 수 있도록 도와줄 거에요! ✨</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>PyTorch 불러오기</h1>\n<p>필요한 주요 라이브러리를 알려드리겠습니다:</p>\n<pre><code class=\"hljs language-js\"># 핵심 기능을 위한 최상위 패키지 불러오기\n<span class=\"hljs-keyword\">import</span> torch\n\n# 신경망 기능 불러오기\n<span class=\"hljs-keyword\">from</span> torch <span class=\"hljs-keyword\">import</span> nn\n\n# 함수형 프로그래밍 도구 불러오기\n<span class=\"hljs-keyword\">import</span> torch.<span class=\"hljs-property\">nn</span>.<span class=\"hljs-property\">functional</span> <span class=\"hljs-keyword\">as</span> F\n\n# 최적화 기능 불러오기\n<span class=\"hljs-keyword\">import</span> torch.<span class=\"hljs-property\">optim</span> <span class=\"hljs-keyword\">as</span> optim\n\n# 데이터셋 함수 불러오기\n<span class=\"hljs-keyword\">from</span> torch.<span class=\"hljs-property\">utils</span>.<span class=\"hljs-property\">data</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">TensorDataset</span>, <span class=\"hljs-title class_\">DataLoader</span>\n\n# 평가 지표 불러오기\n<span class=\"hljs-keyword\">import</span> torchmetrics\n</code></pre>\n<ul>\n<li>import torch: 이게 본 프로그램이에요! PyTorch의 모든 중심 기능을 불러오는데요, 텐서(다차원 배열)를 구축하고 조작할 수 있습니다.</li>\n<li>from torch import nn: 신경망 팬들 주목! 이 라이브러리를 사용하여 강력한 신경망을 만들 수 있는 기본 블록을 제공합니다.</li>\n<li>import torch.nn.functional as F: 멋있게 만들고 싶나요? 이 라이브러리는 새로운 신경망 레이어를 만들기 위한 함수형 프로그래밍 도구를 제공하여 코드에 유연성을 더해줍니다.</li>\n<li>import torch.optim as optim: 신경망을 훈련하는 것은 강아지를 훈련하는 것과 비슷해요 - 어떤 최적화가 필요해요! 이 라이브러리는 다양한 옵티마이저를 제공하여 신경망이 효율적으로 학습할 수 있도록 도와줍니다.</li>\n<li>import torch.utils.data as data: 머신러닝에서 데이터는 중요해요! 이 라이브러리는 데이터셋을 효율적으로 관리하는 도구를 제공하여 훈련을 쉽게 만들어줍니다.</li>\n<li>import torchmetrics: 모델이 얼마나 잘 수행되는지 잘 모르겠다구요? 이 라이브러리는 네트워크의 정확성과 효율성을 평가하는 메트릭 도구상자를 제공합니다.</li>\n</ul>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>Tensor 사용하기</h1>\n<p>텐서는 PyTorch에서 기본적인 구성 요소로, AI 프로젝트용 레고 블록과 비슷한 역할을 합니다! 여기에서는 텐서를 만들고 조작하는 방법을 알아보겠습니다:</p>\n<pre><code class=\"hljs language-js\"># 리스트에서 tensor를 사용하여 텐서 생성\ntnsr = torch.<span class=\"hljs-title function_\">tensor</span>([<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">10</span>])\n\n# 텐서 요소의 데이터 유형 가져오기: .<span class=\"hljs-property\">dtype</span>\ntnsr.<span class=\"hljs-property\">dtype</span> # torch.<span class=\"hljs-property\">int64</span>가 반환됩니다.\n\n# 텐서의 차원 가져오기: .<span class=\"hljs-title function_\">size</span>()\ntnsr.<span class=\"hljs-property\">shape</span> # torch.<span class=\"hljs-title class_\">Size</span>([<span class=\"hljs-number\">4</span>])가 반환됩니다.\n\n# 텐서의 메모리 위치 가져오기: .<span class=\"hljs-property\">device</span>\ntnsr.<span class=\"hljs-property\">device</span> # cpu 또는 gpu가 반환됩니다.\n\n# 모든 요소가 <span class=\"hljs-number\">0</span>인 텐서 만들기: <span class=\"hljs-title function_\">zeros</span>()\ntnsr_zrs = torch.<span class=\"hljs-title function_\">zeros</span>(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>)\n\n# 무작위 텐서 만들기: <span class=\"hljs-title function_\">rand</span>()\ntnsr_rndm = torch.<span class=\"hljs-title function_\">rand</span>(size=(<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>)) # 텐서는 <span class=\"hljs-number\">3</span>행 <span class=\"hljs-number\">4</span>열입니다.\n</code></pre>\n<h1>데이터셋과 데이터로더</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>기계 학습에서 데이터는 왕이에요! 그런데 데이터를 모델에 효율적으로 전달하는 것은 다루기 어려운 일일 수 있어요. 그럴 때 데이터셋과 데이터로더가 등장합니다. 믿을 수 있는 드래곤처럼 당신을 지켜줄 거예요.</p>\n<ul>\n<li>\n<p>데이터셋 구축: 데이터셋은 깔끔하게 구성된 귀하의 훈련 데이터 모음으로 상상해보세요. 데이터가 판다스 DataFrame에 저장된 경우, TensorDataset()을 사용하여 데이터셋을 만들 수 있어요. 이 함수는 두 개의 인수를 취합니다:</p>\n<ul>\n<li>torch.tensor()를 사용하여 부동 소수점 숫자의 텐서로 변환된 특성(독립 변수).</li>\n<li>부동 소수점 텐서로 변환된 목표(종속 변수).</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title class_\">TensorDataset</span>()을 사용하여 판다스 <span class=\"hljs-title class_\">DataFrame</span>에서 데이터셋 만들기\nX = df[feature_columns].<span class=\"hljs-property\">values</span>\ny = df[target_column].<span class=\"hljs-property\">values</span>\ndataset = <span class=\"hljs-title class_\">TensorDataset</span>(torch.<span class=\"hljs-title function_\">tensor</span>(X).<span class=\"hljs-title function_\">float</span>(), torch.<span class=\"hljs-title function_\">tensor</span>(y).<span class=\"hljs-title function_\">float</span>())\n\n# <span class=\"hljs-title class_\">DataLoader</span>()를 사용하여 데이터를 배치로 로드하기\ndataloader = <span class=\"hljs-title class_\">DataLoader</span>(dataset, batch_size=n, shuffle=<span class=\"hljs-title class_\">True</span>)\n</code></pre>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>전처리</h1>\n<p>신경망에 데이터를 입력하기 전에 몇 가지 준비작업이 필요합니다! 이를 전처리라고 합니다. PyTorch의 카테고리 변수(텍스트 레이블과 같은)를 다루기 위한 멋진 기능이 있습니다:</p>\n<p>F.one_hot()을 사용한 원-핫 인코딩</p>\n<p>“빨강,” “초록,” “파랑”과 같은 카테고리를 가진 데이터가 있다고 상상해보세요. 컴퓨터는 이러한 단어들을 처리하기 어려울 수 있습니다. 원-핫 인코딩은 이러한 카테고리를 특별한 종류의 텐서로 변환하는 트릭입니다. 이 텐서에는 각 가능한 카테고리에 대해 한 열이 있을 것입니다(이 경우 \"빨강,\" \"초록,\" \"파랑\"). 각 데이터 포인트에 대해, 해당 카테고리에 해당하는 열에 1이 있고, 나머지는 모두 0입니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>다음은 PyTorch에서 F.one_hot()을 사용하는 방법입니다:</p>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title class_\">One</span>-hot encode categorical variables <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title function_\">one_hot</span>()\nF.<span class=\"hljs-title function_\">one_hot</span>(torch.<span class=\"hljs-title function_\">tensor</span>([<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>]), num_classes=<span class=\"hljs-number\">3</span>) # <span class=\"hljs-number\">0</span>과 <span class=\"hljs-number\">1</span>로 구성된 텐서 반환\n</code></pre>\n<h1>Sequential Model Architecture</h1>\n<p>이제 신경망 아키텍처를 구성해 봅시다! PyTorch의 nn.Sequential 클래스를 사용하면 레이어를 스택하는 것이 매우 쉬워집니다. 아래에서 설명하겠습니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>선형 레이어: 네트워크의 주역! nn.Linear(m, n)을 사용하여 m개의 입력을 받고 n개의 출력을 생성하는 선형 레이어를 만들 수 있어요. 입력값을 가중치와 곱하고 편향을 더한 것으로 생각하면 돼요.</p>\n<p>가중치와 편향 엿보기: 선형 레이어의 내부 동작에 궁금해하는가요? .weight를 사용하여 가중치 행렬에 접근하고 .bias로 편향 벡터를 확인할 수 있어요. 이들은 훈련 중에 업데이트되는 내용이에요!</p>\n<p>활성화 함수: 네트워크에 복잡성을 더하는 비선형 히어로들이에요. 여기 인기 있는 몇 가지 선택사항이 있어요:</p>\n<ul>\n<li>nn.Sigmoid(): 0과 1 사이의 값을 압축하는 함수로 이진 분류(일대다)에 자주 사용돼요.</li>\n<li>nn.Softmax(dim=-1): 출력값을 합이 1이 되도록 확률로 변환시켜주는 함수로 다중 클래스 분류(다대다)에 이상적이에요.</li>\n<li>nn.ReLU(): 음수 값을 0으로 설정하는 ReLU(Rectified Linear Unit). 소멸 그래디언트를 방지하는 데 도움이 돼요.</li>\n<li>nn.LeakyReLU(negative_slope=0.05): ReLU와 유사하지만 0이 아닌 그래디언트를 위한 작은 양수 기울기를 허용하는 함수에요.</li>\n</ul>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>Dropout 레이어: 모델이 훈련 데이터를 너무 잘 기억할 때 발생하는 오버피팅을 nn.Dropout(p=0.5)로 극복하세요. 이는 훈련 중에 일정 비율의 활성화를 무작위로 제거하여 네트워크가 특정 기능에 너무 의존하지 않도록 유도합니다.</p>\n<p>모델 구축: 원하는 순서대로 레이어를 nn.Sequential로 연결해보세요. 각 레이어의 입력 크기는 이전 레이어의 출력 크기와 일치해야 합니다! 예를 들면 다음과 같습니다.</p>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title class_\">Linear</span>()을 사용하여 입력이 m이고 출력이 n인 선형 레이어를 만듭니다.\nlnr = nn.<span class=\"hljs-title class_\">Linear</span>(m, n)\n\n# .<span class=\"hljs-property\">weight</span>로 레이어의 가중치를 가져옵니다\nlnr.<span class=\"hljs-property\">weight</span>\n\n# .<span class=\"hljs-property\">bias</span>로 레이어의 편향을 가져옵니다\nlnr.<span class=\"hljs-property\">bias</span>\n\n# <span class=\"hljs-title class_\">Sigmoid</span>()를 사용하여 이진 분류를 위한 시그모이드 활성화 레이어 생성\nnn.<span class=\"hljs-title class_\">Sigmoid</span>()\n\n# <span class=\"hljs-title class_\">Softmax</span>()를 사용하여 다중 클래스 분류를 위한 소프트맥스 활성화 레이어 생성\nnn.<span class=\"hljs-title class_\">Softmax</span>(dim=-<span class=\"hljs-number\">1</span>)\n\n# <span class=\"hljs-title class_\">ReLU</span>()를 사용하여 포화를 피하기 위한 계단식 활성화 레이어 생성\nnn.<span class=\"hljs-title class_\">ReLU</span>()\n\n# <span class=\"hljs-title class_\">LeakyReLU</span>()를 사용하여 포화를 피하기 위한 릭리 레키 크기를 설정\nnn.<span class=\"hljs-title class_\">LeakyReLU</span>(negative_slope=<span class=\"hljs-number\">0.05</span>)\n\n# <span class=\"hljs-title class_\">Dropout</span>()을 사용하여 규제하고 오버피팅을 방지하는 드롭아웃 레이어 생성\nnn.<span class=\"hljs-title class_\">Dropout</span>(p=<span class=\"hljs-number\">0.5</span>)\n\n# 레이어를 순차적으로 연결하여 모델 생성\nmodel = nn.<span class=\"hljs-title class_\">Sequential</span>(\n    nn.<span class=\"hljs-title class_\">Linear</span>(n_features, i),\n    nn.<span class=\"hljs-title class_\">Linear</span>(i, j),   # 입력 크기는 이전 레이어의 출력과 일치해야 합니다\n    nn.<span class=\"hljs-title class_\">Linear</span>(j, n_classes),\n    nn.<span class=\"hljs-title class_\">Softmax</span>(dim=-<span class=\"hljs-number\">1</span>) # 활성화 레이어가 마지막에 옵니다\n)\n</code></pre>\n<h1>모델 훈련 및 손실 계산</h1>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<p>이제 데이터를 준비했고 모델을 구축했으니, 모델 훈련을 시작해봅시다!</p>\n<pre><code class=\"hljs language-js\"># 입력 데이터에 모델을 피팅하고 모델은 <span class=\"hljs-title class_\">Sequential</span>()을 통해 생성된 변수입니다.\nprediction = <span class=\"hljs-title function_\">model</span>(input_data).<span class=\"hljs-title function_\">double</span>()\n\n# 타겟 값들을 얻습니다.\nactual = torch.<span class=\"hljs-title function_\">tensor</span>(target_values).<span class=\"hljs-title function_\">double</span>()\n\n# 평균 제곱 오차 손실을 계산합니다. 회귀에는 <span class=\"hljs-title class_\">MSELoss</span>()를 사용합니다.\nmse_loss = nn.<span class=\"hljs-title class_\">MSELoss</span>()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# 강건한 회귀를 위한 <span class=\"hljs-variable constant_\">L1</span> 손실을 계산합니다. <span class=\"hljs-title class_\">SmoothL1Loss</span>()를 사용합니다.\nl1_loss = nn.<span class=\"hljs-title class_\">SmoothL1Loss</span>()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# 이진 분류를 위한 바이너리 크로스 엔트로피 손실을 계산합니다. <span class=\"hljs-title class_\">BCELoss</span>()를 사용합니다.\nbce_loss = nn.<span class=\"hljs-title class_\">BCELoss</span>()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# 다중 클래스 분류를 위한 크로스 엔트로피 손실을 계산합니다. <span class=\"hljs-title class_\">CrossEntropyLoss</span>()를 사용합니다.\nce_loss = nn.<span class=\"hljs-title class_\">CrossEntropyLoss</span>()(prediction, actual) # 텐서(x)를 반환합니다.\n\n# .<span class=\"hljs-title function_\">backward</span>()를 사용하여 역전파로 기울기를 계산합니다.\nloss.<span class=\"hljs-title function_\">backward</span>()\n</code></pre>\n<h1>옵티마이저 사용하기</h1>\n<p>신경망을 훈련하는 것은 운동 선수를 훈련하는 것과 비슷합니다. 올바른 도구와 기술이 필요합니다! 이때 옵티마이저가 필요합니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title function_\">SGD</span>() 함수를 사용하여 확률적 경사 하강 옵티마이저를 생성하고 학습률 및 모멘텀 설정\noptimizer = optim.<span class=\"hljs-title function_\">SGD</span>(model.<span class=\"hljs-title function_\">parameters</span>(), lr=<span class=\"hljs-number\">0.01</span>, momentum=<span class=\"hljs-number\">0.95</span>)\n\n# .<span class=\"hljs-title function_\">step</span>()을 사용하여 뉴런 매개변수 업데이트\noptimizer.<span class=\"hljs-title function_\">step</span>()\n</code></pre>\n<p>파이토치에서는 optim 모듈을 사용하여 서로 다른 옵티마이저를 생성하여 신경망의 가중치와 편향을 조정하는 방법을 각각 지정할 수 있습니다. 이번에는 확률적 경사 하강 (SGD)라는 일반적인 옵티마이저를 사용하는 방법을 알아보겠습니다:</p>\n<ul>\n<li>\n<p>옵티마이저 생성: optim.SGD()를 사용하여 SGD 옵티마이저를 생성합니다. 다음 두 가지 중요한 인수를 전달합니다:</p>\n<ul>\n<li>model.parameters(): 이를 통해 옵티마이저에게 모델에서 업데이트해야 할 매개변수(가중치와 편향)를 알려줍니다.</li>\n<li>lr=0.01: 이는 학습률로, 옵티마이저가 각 단계에서 매개변수를 얼마나 조정할지를 제어합니다. 작은 학습률은 조심스러운 업데이트를 유도하고, 큰 학습률은 학습 속도를 빠르게 할 수 있지만 (또한 잠재적으로 불안정성을 유발할 수 있음) 빠른 학습을 할 수 있습니다.</li>\n</ul>\n</li>\n</ul>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<h1>훈련 루프</h1>\n<pre><code class=\"hljs language-js\"># 모델을 훈련 모드로 설정합니다.\nmodel.<span class=\"hljs-title function_\">train</span>()\n# 손실 기준 및 옵티마이저 설정\nloss_criterion = nn.<span class=\"hljs-title class_\">MSELoss</span>()\noptimizer = optim.<span class=\"hljs-title function_\">SGD</span>(model.<span class=\"hljs-title function_\">parameters</span>(), lr=<span class=\"hljs-number\">0.01</span>, momentum=<span class=\"hljs-number\">0.95</span>)\n# 훈련 세트의 데이터 청크를 반복합니다.\n<span class=\"hljs-keyword\">for</span> data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">dataloader</span>:\n    # 그라디언트를 <span class=\"hljs-number\">0</span>으로 설정합니다.\n    optimizer.<span class=\"hljs-title function_\">zero_grad</span>()\n    # 현재 데이터 청크의 특징과 타깃을 가져옵니다.\n    features, targets = data\n    # <span class=\"hljs-string\">\"순방향 패스\"</span>를 실행하여 모델을 데이터에 맞춥니다.\n    predictions = <span class=\"hljs-title function_\">model</span>(data)\n    # 손실 계산\n    loss = <span class=\"hljs-title function_\">loss_criterion</span>(predictions, targets)\n    # 역전파를 사용하여 그래디언트 계산\n    loss.<span class=\"hljs-title function_\">backward</span>()\n    # 모델 매개변수 업데이트\n    optimizer.<span class=\"hljs-title function_\">step</span>()\n</code></pre>\n<h1>평가 루프</h1>\n<p>굉장한 PyTorch 모델을 훈련한 후, 이제 얼마나 잘 수행되는지 확인해보세요!</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\"># 모델을 평가 모드로 설정\nmodel.<span class=\"hljs-built_in\">eval</span>()\n\n# 정확도 메트릭 생성\nmetric = torchmetrics.<span class=\"hljs-title class_\">Accuracy</span>(task=<span class=\"hljs-string\">\"multiclass\"</span>, num_classes=<span class=\"hljs-number\">3</span>)\n# 검증 세트에서 데이터 청크 루프\n<span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">enumerate</span>(dataloader, <span class=\"hljs-number\">0</span>):\n    # 현재 데이터 청크의 특징과 타겟 가져오기\n    features, targets = data\n    # 모델을 데이터에 맞추기 위해 <span class=\"hljs-string\">\"포워드 패스\"</span> 실행\n    predictions = <span class=\"hljs-title function_\">model</span>(data)\n    # 배치의 정확도 계산\n    accuracy = <span class=\"hljs-title function_\">metric</span>(output, predictions.<span class=\"hljs-title function_\">argmax</span>(dim=-<span class=\"hljs-number\">1</span>))\n# 전체 검증 데이터에 대한 정확도 계산\naccuracy = metric.<span class=\"hljs-title function_\">compute</span>()\n<span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"All 데이터에 대한 정확도: {accuracy}\"</span>)\n# 다음 데이터셋(학습 또는 검증)을 위해 메트릭 재설정\nmetric.<span class=\"hljs-title function_\">reset</span>()\n</code></pre>\n<h1>전이 학습과 파인튜닝</h1>\n<p>머신 러닝에서 사전 훈련된 모델을 활용하여 우리 자신의 프로젝트를 빠르게 시작할 수 있습니다. 이를 전이 학습이라고하며, 그 내에서 파인튜닝은 강력한 기술입니다. PyTorch가 여러분을 돕는 방법을 살펴보겠습니다:</p>\n<p>나중을 위한 레이어 저장: 모델의 특정 레이어를 훈련시키고 나중에 다시 사용하고 싶다면, torch.save()를 사용하여 레이어의 가중치와 편향을 파일로 직렬화할 수 있습니다. 이는 미래 AI 프로젝트를 위한 청사진을 저장하는 것으로 생각할 수 있습니다!</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-js\">torch.<span class=\"hljs-title function_\">save</span>(layer, <span class=\"hljs-string\">'layer.pth'</span>)  # <span class=\"hljs-string\">'layer.pth'</span> 파일에 레이어를 저장합니다.\n</code></pre>\n<p>저장된 레이어 불러오기: 이전에 저장한 레이어를 가져와야 하는 경우가 있습니다. torch.load()를 사용하여 다시 불러올 수 있습니다! 새 모델에 사전 훈련된 레이어를 통합하는 데 유용합니다.</p>\n<pre><code class=\"hljs language-js\">new_layer = torch.<span class=\"hljs-title function_\">load</span>(<span class=\"hljs-string\">'layer.pth'</span>)  # <span class=\"hljs-string\">'layer.pth'</span> 파일에서 레이어를 불러옵니다.\n</code></pre>\n<p>동결된 파워로 파인튜닝! 예를 들어, 사전 훈련된 모델이 있고 특정 작업을 위해 최종 레이어만 파인튜닝하려는 경우가 있습니다. PyTorch를 사용하면 .requires_grad = False를 사용하여 이전 레이어의 가중치를 동결시킬 수 있습니다. 이렇게 하면 훈련 중에 업데이트되지 않고 마지막 레이어에 중점을 두고 학습 프로세스를 진행할 수 있습니다.</p>\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">for</span> name, param <span class=\"hljs-keyword\">in</span> model.named_parameters():\n    <span class=\"hljs-keyword\">if</span> name == <span class=\"hljs-string\">\"0.weight\"</span>:\n        param.requires_grad = <span class=\"hljs-literal\">False</span>  <span class=\"hljs-comment\"># 필요에 따라 레이어 번호를 조정하여 레이어 0의 가중치를 고정시킵니다.</span>\n\n<span class=\"hljs-comment\"># 이제 최종 레이어만 업데이트되도록 모델을 학습할 수 있습니다!</span>\n</code></pre>\n<p>전이 학습과 파인 튜닝을 마스터하면, 사전 학습된 지식을 활용하여 학습 시간을 단축시키고, 여러분을 머신러닝 효율성 챔피언으로 만들 수 있습니다!</p>\n<p>읽어 주셔서 감사합니다. 내 컨텐츠가 마음에 드시고 저를 지원하고 싶다면, Patreon에서 저를 지원하는 것이 가장 좋은 방법입니다 —</p>\n<img src=\"/assets/img/2024-07-01-PyTorchCheatSheet_1.png\">\n<!-- ui-station 사각형 -->\n<p><ins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"></ins></p>\n<script>\n(adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<ul>\n<li>내 YouTube 채널 구독하기.</li>\n<li>내 웹사이트 방문하기.</li>\n<li>LinkedIn과 Github에서 나와 연락하기! 나는 거기에서 무료로 놀라운 콘텐츠를 공유하고, 기술과 AI를 활용하여 더 생산적이고 효과적으로 일할 수 있도록 돕습니다.</li>\n<li>머신러닝 및 딥러닝 도움이 필요하신가요? 내 Fiverr 및 Upwork 서비스를 확인해보세요!</li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}