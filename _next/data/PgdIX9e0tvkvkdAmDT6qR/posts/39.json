{"pageProps":{"posts":[{"title":"ML 이야기 MobileLlama3 모바일에서 Llama3를 로컬에서 실행하기","description":"","date":"2024-05-18 20:07","slug":"2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile","content":"\n\n# 소개\n\n2024년 4월, Meta가 새로운 오픈 언어 모델 패밀리인 Llama 3을 출시했습니다. 이전 모델을 발전시킨 Llama 3은 개선된 기능을 제공하며, 8B 및 70B의 사전 훈련된 버전과 명령어 튜닝된 변형을 제공합니다.\n\n언어 모델의 지속적인 트렌드에서, 개발자들은 개인 정보 보호를 위해 API 대신 로컬 또는 오프라인 사용을 선호하고 있습니다. 올라마는 macOS 및 Linux OS에서 오프라인으로 LLMs를 실행할 수 있는 도구 중 하나로, 로컬 실행을 가능하게 합니다. 그러나 스마트폰의 제한된 하드웨어 성능으로 인해 모바일 기기에서 LLMs를 로컬로 실행하는 기능은 아직 제한적입니다.\n\n하지만 이제는 다릅니다. MLC 덕분에 모바일 기기에서 이러한 대형 모델을 실행하는 것이 가능해졌습니다. 이 블로그는 MLC LLM을 사용하여 오프라인 추론을 위해 Llama3-8B-Instruction 모델을 모바일 폰에 직접 양자화, 변환 및 배포하는 완전한 튜토리얼을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_0.png\" />\n\n시작하기 전에, 먼저 파이프라인을 이해해 봅시다.\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_1.png\" />\n\n자, 더 이상 지체하지 말고, 단계별 구현을 위한 코드로 바로 넘어가 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## 섹션 I: 원본 라마-3-8B-인스트럭트 모델을 MLC 호환 가중치로 양자화 및 변환하기\n\n단계 0: 아래 저장소를 로컬 머신에 복제하고 Google Colab에 Llama3_on_Mobile.ipynb 노트북을 업로드하세요.\n\n```js\n# 저장소를 복제합니다.\ngit clone https://github.com/NSTiwari/Llama3-on-Mobile\n```\n\n단계 1: MLC-LLM 설치하기\n\n<div class=\"content-ad\"></div>\n\n모델 가중치를 변환하려면 MLC-LLM 라이브러리가 필요합니다. 노트북을 실행하는 데 특히 NumPy 버전 1.23.5가 필요하며, 다른 버전에서 변환 프로세스에 문제가 발생했습니다.\n\n```js\n!pip install --pre --force-reinstall mlc-ai-nightly-cu122 mlc-llm-nightly-cu122 -f https://mlc.ai/wheels\n!pip install numpy==1.23.5\n```\n\n단계 2: 라이브러리 가져오기\n\n```js\nimport mlc_llm\nimport torch\nfrom huggingface_hub import snapshot_download\n```\n\n<div class=\"content-ad\"></div>\n\nStep 3: HF 계정에 로그인하고 원본 Llama-3-8B-Instruct 모델 가중치를 다운로드하세요\n\n```js\n# HF 계정에 로그인합니다.\nfrom huggingface_hub import notebook_login\nnotebook_login()\n\n# Llama-3-8B-Instruct 모델을 다운로드합니다.\nsnapshot_download(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", local_dir=\"/content/Llama-3-8B-Instruct/\")\n```\n\nStep 4: GPU가 활성화되었는지 확인하세요\n\n```js\n!nvidia-smi\n\n# CUDA가 사용 가능한지 확인합니다.\ntorch.cuda.is_available()\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice\n```\n\n<div class=\"content-ad\"></div>\n\nStep 5: 모델 이름과 양자화 유형 구성\n\n```js\nMODEL_NAME = \"Llama-3-8B-Instruct\"\nQUANTIZATION= \"q4f16_1\"\n```\n\nStep 6: Llama-3-8B-Insruct 모델을 MLC 호환 가중치로 변환\n\n다음 코드는 q4f16_1 양자화를 사용하여 Llama-3-8B-Instruct 모델을 양자화 및 샤딩하여 여러 청크로 변환합니다. 그런 다음 모델 가중치를 Llama-3-8B-Instruct-q4f16_1-android이란 디렉터리에 변환하고 저장합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n!python -m mlc_llm convert_weight /content/$MODEL_NAME/ --quantization $QUANTIZATION -o /content/$MODEL_NAME-$QUANTIZATION-android/\n```\n\n7단계: 토큰 파일 생성\n\n이 코드 라인은 conv-template, context-window, prefill-chunk-size와 같은 매개변수를 사용하여 토큰 파일을 생성합니다. 이때 conv-template은 llama-3으로 설정되어 있으며, 이는 작업 중인 Llama-3 모델 변형을 나타냅니다.\n\n```js\n!python -m mlc_llm gen_config /content/$MODEL_NAME/ --quantization $QUANTIZATION \\\n    --conv-template llama-3 --context-window-size 8192 --prefill-chunk-size 1024  \\\n    -o /content/$MODEL_NAME-$QUANTIZATION-android/\n```\n\n<div class=\"content-ad\"></div>\n\n8단계: Android 형식으로 모델 컴파일하기\n\n여기서는 장치 매개변수를 사용하여 모델 가중치를 Android 호환 형식으로 컴파일하며, 이는 Llama3–8B-Instruct-q4f16_1-android.tar 파일을 생성합니다. 이 .tar 파일은 모델을 기기에 배포하기 위해 이후 단계에서 사용될 것입니다.\n\n```js\n!python -m mlc_llm compile /content/$MODEL_NAME-$QUANTIZATION-android/mlc-chat-config.json \\\n    --device android -o /content/$MODEL_NAME-$QUANTIZATION-android/$MODEL_NAME-$QUANTIZATION-android.tar\n```\n\n9단계: 모델을 Hugging Face에 올리기 🤗\n\n<div class=\"content-ad\"></div>\n\n마지막으로, 모델 가중치를 HF에 저장하세요. 이러한 가중치는 추론 중에 모바일 폰으로 다운로드될 것입니다.\n\n```js\nfrom huggingface_hub import whoami\nfrom pathlib import Path\n\n# 출력 디렉토리.\noutput_dir = \"/content/\" + MODEL_NAME + \"-\" + QUANTIZATION + \"-android/\"\nrepo_name = \"Llama-3-8B-q4f16_1-android\"\nusername = whoami(token=Path(\"/root/.cache/huggingface/\"))[\"name\"]\nrepo_id = f\"{username}/{repo_name}\"\n```\n  \n```js\nfrom huggingface_hub import upload_folder, create_repo\n\nrepo_id = create_repo(repo_id, exist_ok=True).repo_id\nprint(output_dir)\n\nupload_folder(\n    repo_id=repo_id,\n    folder_path=output_dir,\n    commit_message=\"Quantized Llama-3-8B-Instruct model for Android.\",\n    ignore_patterns=[\"step_*\", \"epoch_*\"],\n)\n```\n\n다음 HF 🤗 리포지토리에서 샤드된 모델 가중치 및 토크나이저를 직접 찾을 수 있습니다:\nhttps://huggingface.co/NSTiwari/Llama-3-8B-q4f16_1-android\n\n<div class=\"content-ad\"></div>\n\n여기 완전한 Colab 노트북을 찾을 수 있습니다.\n\n좋아요. 우리는 양자화와 모델 가중치 변환의 초기 단계를 완료했습니다. 이제 다음 섹션에서는 GCP 인스턴스에서 추가로 모델 가중치를 컴파일하기 위한 환경을 설정할 것입니다.\n\n## Section II: 안드로이드용 빌드 파일 생성을 위한 GCP 환경 설정(옵션)\n\n이 단계는 선택 사항이며 이미 Linux 또는 MacOS와 같은 UNIX 기반 시스템을 가지고 있다면 필요하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n윈도우 기기를 사용하고 있기 때문에 호환성 문제로 필요한 라이브러리와 종속성을 설치하는 것이 귀찮았어요. 그래서 귀차니즘을 피하기 위해 GCP에서 Linux VM 인스턴스를 렌트하기로 결정했어요.\n\n저는 GCP VM 인스턴스에서 환경을 설정하고 Android Studio를 설치하는 단계를 안내하는 별도의 블로그를 작성했어요.\n\n비슷한 문제를 겪고 계신 분이라면, 여기서 확인해보세요. 그렇지 않다면 건너뛰셔도 돼요.\n\n## 섹션 III: 빌드 종속성 설치\n\n<div class=\"content-ad\"></div>\n\n### 단계 1: Rust 설치하기\n\n안드로이드로 HuggingFace 토크나이저를 크로스 컴파일하기 위해서는 Rust가 필요합니다. Rust를 설치하려면 아래 명령을 실행하세요.\n\n![이미지](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_2.png)\n\n표준 설치를 계속하려면 옵션 1을 선택하세요.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_3.png)\n\n```js\nsudo curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n```\n\nStep 2: Install NDK and CMake in Android Studio\n\nOpen Android Studio → Tools → SDK Manager → SDK Tools → Install CMake and NDK.\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_4.png\" />\n\n제 3 단계: MLC LLM Python 패키지 및 TVM Unity 컴파일러 설치\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_5.png\" />\n\n```js\n# MLC-LLM Python 패키지와 TVM Unity 컴파일러 설치.\npython3 -m pip install --pre -U -f https://mlc.ai/wheels mlc-llm-nightly mlc-ai-nightly\n\n# 아래 명령어를 사용하여 설치 확인:\npython3 -c \"import mlc_llm; print(mlc_llm)\"\n```\n\n<div class=\"content-ad\"></div>\n\n**단계 4: CMake 설치하기**\n\n![이미지](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_6.png)\n\n```js\n# CMake 설치하기.\nsudo apt-get install cmake\n```\n\n**단계 5: MLC-LLM 및 Llama3-on-Mobile 저장소 복제하기**  \n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_7.png\" />\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_8.png\" />\n\n```js\ncd /home/tiwarinitin1999/  \n\n# MLC-LLM 저장소를 복제합니다.\ngit clone https://github.com/mlc-ai/mlc-llm.git\ncd mlc-llm\n\n# 저장소의 서브모듈을 업데이트합니다.\ngit submodule update --init --recursive\n\n# Llama3-on-Mobile 저장소를 복제합니다.\ncd /home/tiwarinitin1999/\ngit clone https://github.com/NSTiwari/Llama3-on-Mobile.git\n```\n\n단계 6: 변환된 모델 가중치의 HuggingFace 저장소를 다운로드하세요.\n\n<div class=\"content-ad\"></div>\n\nMLCChat 디렉토리 내에 새 폴더 dist를 만들어주세요. dist 폴더 안에 prebuilt라는 하위 폴더를 생성해주세요.\n\n![이미지](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_9.png)\n\n```js\ncd /home/tiwarinitin1999/mlc-llm/android/MLCChat\nmkdir dist\ncd dist\nmkdir prebuilt\ncd prebuilt\n```\n\n그리고 prebuilt 폴더에 HF repository(섹션 1의 단계 9에서 생성된)를 클론해주세요.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_10.png\" />\n\n```js\n# 퀀터이즈된 Llama3-8B-Instruct 가중치의 HF 리포지토리를 복제합니다.\ngit clone https://huggingface.co/NSTiwari/Llama-3-8B-q4f16_1-android.git\n```\n\n7단계: Llama3–8B-Instruct-q4f16_1-android.tar 파일을 복사합니다.\n\ndist 폴더 내에 lib라는 새 폴더를 만들어서 Llama3–8B-Instruct-q4f16_1-android.tar 파일 (Section I의 단계 8에서 생성된 파일)을 lib 디렉토리로 복사합니다.\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_11.png)\n\n```bash\ncd /home/tiwarinitin1999/mlc-llm/android/MLCChat/dist\nmkdir lib\ncd lib/\n```\n\n![image](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_12.png)\n\nStep 8: mlc-package-config.json 파일 구성하기\n\n<div class=\"content-ad\"></div>\n\nMLCChat 폴더 내의 mlc-package-config.json 파일을 다음과 같이 구성하세요:\n\n```js\n{\n    \"device\": \"android\",\n    \"model_list\": [\n        {\n            \"model\": \"Llama-3-8B-q4f16_1-android\",\n            \"bundle_weight\": true,\n            \"model_id\": \"llama-3-8b-q4f16_1\",\n            \"model_lib\": \"llama-q4f16_1\",\n            \"estimated_vram_bytes\": 4348727787,\n            \"overrides\": {\n                \"context_window_size\":768,\n                \"prefill_chunk_size\":256\n            }         \n        }\n    ],\n    \"model_lib_path_for_prepare_libs\": {\n        \"llama-q4f16_1\": \"./dist/lib/Llama-3-8B-Instruct-q4f16_1-android.tar\"\n    }\n}\n```\n\n![이미지](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_13.png)\n\n9단계: 경로에 환경 변수 설정하기\n\n<div class=\"content-ad\"></div>\n\n<html>\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_14.png\" />\n</html>\n\n```js\nexport ANDROID_NDK=/home/tiwarinitin1999/Android/Sdk/ndk/27.0.11718014\nexport TVM_NDK_CC=$ANDROID_NDK/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android24-clang\nexport TVM_HOME=/home/tiwarinitin1999/mlc-llm/3rdparty/tvm\nexport JAVA_HOME=/home/tiwarinitin1999/Downloads/android-studio/jbr\nexport MLC_LLM_HOME=/home/tiwarinitin1999/mlc-llm\n```\n\nStep 10: 안드로이드 빌드 파일 생성\n\n마지막으로, 아래 명령을 실행하여 on-device 배포를 위한 Llama3-8B-Instruct 모델의 .JAR 파일을 빌드하십시오.\n\n<div class=\"content-ad\"></div>\n\n```sh\ncd /home/tiwarinitin1999/mlc-llm/android/MLCChat\npython3 -m mlc_llm package\n```\n\n![Screenshot](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_15.png)\n\n명령어가 성공적으로 실행된 후, 아래와 같은 결과를 확인하실 수 있습니다.\n\n![Screenshot](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_16.png)\n```\n\n<div class=\"content-ad\"></div>\n\n위 명령은 다음 파일을 생성합니다:\n\n![이미지](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_17.png)\n\n소스 디렉토리의 출력 폴더 내용을 대상 디렉토리로 복사하세요:\n\n소스 디렉토리:\n/home/tiwarinitin1999/mlc-llm/android/MLCChat/dist/lib/mlc4j/output\n\n<div class=\"content-ad\"></div>\n\n목적지 디렉토리:\n/home/tiwarinitin1999/Llama3-on-Mobile/mobile-llama3/MobileLlama3/dist/lib/mlc4j/output\n\n이제, home/tiwarinitin1999/Llama3-on-Mobile/mobile-llama3/MobileLlama3/dist/lib/mlc4j/src/main/assets 폴더에 있는 mlc-app-config.json 파일을 다음과 같이 구성하세요:\n\n```js\n{\n  \"model_list\": [\n    {\n      \"model_id\": \"llama-3-8b-q4f16_1\",\n      \"model_lib\": \"llama-q4f16_1\",\n      \"model_url\": \"https://huggingface.co/NSTiwari/Llama-3-8B-q4f16_1-android\",\n      \"estimated_vram_bytes\": 4348727787\n    }\n  ]\n}\n```\n\n설정 파일의 model_url 키는 모바일폰에서 HF 저장소로부터 모델 가중치를 다운로드합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_18.png\" />\n\n모든 구성이 설정되었습니다.\n\n## 섹션 IV: 안드로이드 스튜디오에서 앱 빌드하기\n\n안드로이드 스튜디오에서 MobileLlama3 앱을 열고 어느 정도 시간을 들여 빌드하도록 합시다.\n\n<div class=\"content-ad\"></div>\n\n\n[![image](/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_19.png)]\n(https://miro.medium.com/v2/resize:fit:700/1*wdN1DDl127dzmjIal0FHig.gif)\n\n모바일 앱이 성공적으로 빌드되면 APK를 모바일 폰에 설치하세요. 바로 설치할 수 있는 APK가 여기에 있습니다.\n\n오프라인 사용을 위해 Llama3–8B-Instruct 모델을 모바일 기기에 구동하는 데 성공한 것을 축하드립니다. 이 기사에서 가치 있는 통찰을 얻었기를 기대합니다.\n\n\n<div class=\"content-ad\"></div>\n\n위의 GitHub 저장소에서 전체 프로젝트를 확인할 수 있습니다.\nhttps://github.com/NSTiwari/Llama3-on-Mobile\n\n작품을 좋아하셨다면 저장소에 ⭐을 남겨주시고, 동료 온디바이스 AI 개발자들 사이에 소식을 전파해주세요. 앞으로 더욱 흥미로운 프로젝트와 블로그를 기대해주세요.\n\n## 감사의 글\n\nMobileLlama3는 MLC-LLM을 영감을 받아 제작되었으며, 이 프로젝트를 오픈 소스로 만들어주신 MLC-LLM에게 감사드립니다.\n\n<div class=\"content-ad\"></div>\n\n## 참고 자료 및 자원\n\n- Llama-3-8B-Instruct 모델을 양자화하고 변환하는 Colab 노트북\n- MobileLlama3 GitHub 저장소\n- 변환된 가중치를 위한 HuggingFace 저장소\n- Meta사의 Llama3 모델들\n- MLC-LLM\n- MLC-LLM용 Android SDK","ogImage":{"url":"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_0.png"},"coverImage":"/assets/img/2024-05-18-MLStoryMobileLlama3RunLlama3locallyonmobile_0.png","tag":["Tech"],"readingTime":12},{"title":"프로덕션에 적합한 LLM 시스템을 위한 엔드 투 엔드 프레임워크 LLM 트윈 구축하기","description":"","date":"2024-05-18 20:03","slug":"2024-05-18-AnEnd-to-EndFrameworkforProduction-ReadyLLMSystemsbyBuildingYourLLMTwin","content":"\n\n## LLM TWIN COURSE: BUILDING YOUR PRODUCTION-READY AI REPLICA\n\n→ LLM Twin 무료 코스의 첫 번째 강의\n\n당신의 LLM Twin은 무엇인가요? LLM Twin은 당신의 스타일, 성격 및 목소리를 포함하여 당신처럼 쓰는 AI 캐릭터입니다.\n\n![이미지](/assets/img/2024-05-18-AnEnd-to-EndFrameworkforProduction-ReadyLLMSystemsbyBuildingYourLLMTwin_0.png)\n\n<div class=\"content-ad\"></div>\n\n## 이 강의가 다른 이유는 무엇인가요?\n\n무료 강의 \"LLM Twin: Building Your Production-Ready AI Replica\"를 완료하면 LLMs, 벡터 DB 및 LLMOps의 좋은 실천법에 의해 구동되는 스스로의 프로덕션 준비 AI 복제본을 설계, 훈련 및 배포하는 방법을 배울 수 있습니다.\n\n## 이 강의를 통해 어떤 것을 배우게 되나요?\n\n데이터 수집부터 배포까지 실제 LLM 시스템을 설계하고 구축하는 방법을 배우실 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nMLOps의 최상의 실천법을 활용하는 방법을 배울 것입니다. 실험 추적기, 모델 레지스트리, 즉시 모니터링, 그리고 버전 관리 등이 있습니다.\n\n최종 목표는 무엇일까요? 자신만의 LLM 쌍을 구축하고 배포하는 것입니다.\n\nLLM 쌍의 아키텍처는 4개의 파이썬 마이크로서비스로 나뉩니다:\n\n- 데이터 수집 파이프라인: 다양한 소셜 미디어 플랫폼에서 디지털 데이터를 수집합니다. ETL 파이프라인을 통해 데이터를 정리, 정규화하고 NoSQL DB에 로드합니다. CDC 패턴을 사용하여 데이터베이스 변경 사항을 큐로 전송합니다. (AWS에 배포됨)\n- 피처 파이프라인: 바이트왁스 스트리밍 파이프라인을 통해 큐에서 메시지를 소비합니다. 각 메시지는 실시간으로 정리되고 청크화되며 Superlinked를 사용하여 삽입되고 Qdrant 벡터 DB에 로드됩니다. (AWS에 배포됨)\n- 트레이닝 파이프라인: 디지털 데이터를 기반으로 사용자 정의 데이터세트를 생성합니다. QLoRA를 사용하여 LLM을 세밀하게 조정합니다. Comet ML의 실험 추적기를 사용하여 실험을 모니터링합니다. 최상의 모델을 Comet의 모델 레지스트리에 저장 및 평가합니다. (Qwak에 배포됨)\n- 인퍼런스 파이프라인: Comet의 모델 레지스트리에서 세밀하게 조정된 LLM을 로드하고 양자화합니다. 이를 REST API로 배포합니다. RAG를 사용하여 프롬프트를 향상시키고, LLM 쌍을 사용하여 콘텐츠를 생성합니다. Comet의 프롬프트 모니터링 대시보드를 사용하여 LLM을 모니터링합니다. (Qwak에 배포됨)\n\n<div class=\"content-ad\"></div>\n\n4개의 마이크로서비스를 통해 3가지 서버리스 도구를 통합하는 방법을 배울 수 있습니다:\n\n- ML 플랫폼으로서의 Comet ML;\n- 벡터 DB로서의 Qdrant;\n- ML 인프라로서의 Qwak;\n\n## 누구를 위한 것인가요?\n\n대상: MLE, DE, DS 또는 SWE로서, LLMOps의 좋은 원칙을 사용하여 제품 준비 상태의 LLM 시스템을 설계하고 싶은 분들을 대상으로 합니다.\n\n<div class=\"content-ad\"></div>\n\n수준: 중급\n\n필수 조건: Python, ML 및 클라우드에 대한 기본 지식\n\n## 어떻게 학습하시겠습니까?\n\n이 강의에는 11개의 실습 수업 및 GitHub에서 액세스할 수 있는 오픈 소스 코드가 포함되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n모두 자신의 속도로 모든 것을 읽을 수 있어요.\n\n→ 이 과정을 최대한 효율적으로 활용하려면 강의를 따라가며 저장소를 복제하고 실행하는 것을 권장해요.\n\n## 비용은?\n\n기사와 코드는 완전히 무료에요. 언제나 무료로 제공될 거에요.\n\n<div class=\"content-ad\"></div>\n\n그러나 코드를 실행하면서 읽으려면, 추가 비용이 발생할 수 있는 몇 가지 클라우드 도구를 사용한다는 것을 알아두어야 합니다.\n\n클라우드 컴퓨팅 플랫폼(AWS, Qwak)은 pay-as-you-go 요금제를 제공합니다. Qwak은 무료 컴퓨팅 시간을 제공합니다. 따라서 우리는 비용을 최소화하기 위해 최선을 다하였습니다.\n\n다른 서버리스 도구(Qdrant, Comet)의 경우, 무료로 사용할 수 있는 프리미엄 버전을 사용할 것입니다.\n\n## 선생님들을 만나보세요!\n\n<div class=\"content-ad\"></div>\n\nDecoding ML 우산 아래에서 개설 된 이 과정을 개발 한 사람들은 다음과 같습니다:\n\n- Paul Iusztin | 시니어 ML & MLOps 엔지니어\n- Alex Vesa | 시니어 AI 엔지니어\n- Alex Razvant | 시니어 ML & MLOps 엔지니어\n\n# 수업\n\n이 과정은 총 11개의 수업으로 구성되어 있습니다. 매체 기사 하나당 하나의 수업으로 나뉩니다.\n\n<div class=\"content-ad\"></div>\n\n- LLM 시스템의 제품용 엔드 투 엔드 프레임워크 구축을 통한 LLM Twin\n- 생성 모델 AI 시대의 데이터 파이프라인의 중요성\n- 변경 데이터 캡처: 이벤트 주도 아키텍처 가능\n- 실시간으로 LLM 및 RAG의 파이썬 스트리밍 파이프라인의 뛰어난 솔루션\n- 구현해야 할 4가지 고급 RAG 알고리즘\n- 특징 저장소의 역할 LLM 세부 조정에\n- LLM 세부 조정 [모듈 3] ...작업 중\n- LLM 평가 [모듈 4] ...작업 중\n- 양자화 [모듈 5] ...작업 중\n- 디지털 트윈 추론 파이프라인 구축 [모듈 6] ...작업 중\n- REST API로 디지털 트윈 배포 [모듈 6] ...작업 중\n\n첫 번째 레슨에서는 당신이 수강 기간 동안 구축할 프로젝트인 제품용 LLM Twin/AI 복제품을 소개할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이후에는 3-파이프라인 디자인이 무엇인지와 이것이 표준 ML 시스템에 어떻게 적용되는지 설명할 것입니다.\n\n마지막으로, LLM 프로젝트 시스템 디자인에 대해 자세히 살펴볼 것입니다.\n\n소셜 미디어 데이터 수집 파이프라인 디자인에 대한 모든 아키텍처 결정과 LLM 마이크로서비스에 3-파이프라인 아키텍처를 적용하는 방법을 설명할 것입니다.\n\n다음 수업에서는 각 구성 요소의 코드를 검토하고 AWS 및 Qwak에 구현하고 배포하는 방법을 배울 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 목차\n\n- 무엇을 구축할 계획인가요? LLM twin 개념\n- 3-파이프라인 아키텍처\n- LLM twin 시스템 디자인\n\n# 1. 무엇을 구축할 계획인가요? LLM twin 개념\n\n이 과정의 목표는 당신만의 AI 레플리카를 구축하는 것입니다. 우리는 그것을 할 수 있도록 LLM을 사용할 것이며, 따라서 이 과정의 이름이 LLM Twin: 생산 준비가 완료된 AI 레플리카 구축입니다.\n\n<div class=\"content-ad\"></div>\n\nLLM 쌍이 무엇인지 알고 싶으신가요?\n\n간단히 말씀드리면, LLM 쌍은 여러분과 비슷한 방식으로 글을 쓰는 인공지능 캐릭터가 될 거에요.\n\n여러분 그 자신이 되는 게 아니라, 여러분의 글 스타일과 성격을 활용하는 쓰기 기계예요.\n\n구체적으로 말하면, 여러분이 자신의 목소리로 소셜미디어 글이나 기술 기사(이렇게 작성된 것처럼)를 쓰는 AI 판본을 만드실 수 있을 거에요.\n\n<div class=\"content-ad\"></div>\n\nChatGPT을 직접 사용하지 않는 이유가 무엇인가요? 궁금하시다면…\n\nLLM을 사용하여 기사나 글을 생성할 때 결과물이 다음과 같은 경향이 있습니다:\n\n- 매우 일반적이고 미흡하게 나옵니다.\n- 허상으로 인한 잘못된 정보가 포함될 수 있습니다.\n- 원하는 결과를 얻기 위해 번거로운 프롬프팅이 필요할 수 있습니다.\n\n하지만 이런 문제를 해결하기 위해 우리가 할 일은 ↓↓↓\n\n<div class=\"content-ad\"></div>\n\n먼저, LinkedIn, Medium, Substack 및 GitHub에서 수집한 디지털 데이터로 LLM을 세밀하게 조정할 것입니다.\n\n이를 통해 LLM은 당신의 쓰기 스타일과 온라인 개성과 일치하게 될 것입니다. LLM을 통해 당신 온라인 버전처럼 대화하는 법을 배울 것입니다.\n\n2024년 Meta가 Messenger 앱에서 발표한 AI 캐릭터의 우주를 보신 적이 있나요? 만약 아직이라면, 여기 [2]에서 더 자세히 알아볼 수 있습니다.\n\n어느 정도 그것이 우리가 구축하려는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 우리의 사용 사례에서는 당신의 목소리를 반영하고 표현하는 소셜 미디어 게시물이나 글을 쓰는 LLM 쌍에 초점을 맞추겠습니다.\n\n예를 들어, 우리는 당신의 LLM 쌍에게 LLM에 관한 LinkedIn 게시물을 작성하도록 요청할 수 있습니다. LLM에 관한 어떤 일반적이고 표현되지 않은 게시물(예: ChatGPT가 무엇을 할 것인지) 대신에 당신의 목소리와 스타일을 사용할 것입니다.\n\n두 번째로, 우리는 환각을 피하기 위해 외부 정보에 액세스하기 위해 LLM에게 벡터 DB에 액세스할 수 있게 할 것입니다. 따라서 LLM이 구체적인 데이터에 기반하여만 쓸 수 있도록 할 것입니다.\n\n최종적으로, 정보를 얻기 위해 벡터 DB에 액세스하는 것 외에도 생성 프로세스의 기본 블록 역할을 하는 외부 링크를 제공할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 위의 예시를 다음과 같이 수정해 볼 수 있어요: \"이 링크의 기사를 기반으로 LLMs에 관한 1000단어 LinkedIn 게시물을 작성해주세요: [URL].\"\n\n기대되시나요? 시작해봅시다!🔥\n\n# 2. 3단계 파이프라인 구조\n\n우리 모두는 머신러닝 시스템이 얼마나 엉망이 될 수 있는지 알고 있어요. 이 때 3단계 파이프라인 구조가 필요해요.\n\n<div class=\"content-ad\"></div>\n\n3-파이프라인 디자인은 ML 시스템에 구조와 모듈성을 제공하면서 MLOps 프로세스를 개선합니다.\n\n## 문제점\n\nMLOps 도구의 발전에도 불구하고, 프로토타입에서 프로덕션으로의 전환은 여전히 어려움을 겪고 있습니다.\n\n2022년에는 모델 중 54%만이 프로덕션 환경으로 이동한다고 합니다. 우웅.\n\n<div class=\"content-ad\"></div>\n\n그래서 무슨 일이 생길까요?\n\n입에 먼저 나오는 것은 아마도:\n\n- 모델이 충분히 성숙하지 않다\n- 보안 위험(예: 데이터 개인 정보 보호)\n- 충분한 데이터가 없다\n\n어느 정도는 이 사실이 맞습니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 현실은 많은 시나리오에서...\n\n...ML 시스템의 아키텍처는 연구를 염두에 두고 구축되거나 ML 시스템이 오프라인에서 온라인으로 리팩터링하기 매우 어려운 거대한 단일체가 됩니다.\n\n그러므로 좋은 소프트웨어 엔지니어링 프로세스와 명확히 정의된 아키텍처가 적합한 도구와 높은 정확도의 모델 사용만큼 중요합니다.\n\n## 솔루션\n\n<div class=\"content-ad\"></div>\n\n→ 3-파이프라인 아키텍처\n\n3-파이프라인 디자인이 무엇인지 알아봅시다.\n\n개발 과정을 단순화하고, 당신의 단일 ML 파이프라인을 3가지 구성 요소로 나누는 데 도움이 되는 정신적인 지도입니다:\n1. 피처 파이프라인\n2. 트레이닝 파이프라인\n3. 인퍼런스 파이프라인\n\n...또한 피처/트레이닝/인퍼런스 (FTI) 아키텍처로 알려져 있습니다.\n\n<div class=\"content-ad\"></div>\n\n#1. 피처 파이프라인은 데이터를 피처와 레이블로 변환하여, 해당 내용을 피처 스토어에 저장하고 버전을 관리합니다. 피처 스토어는 피처들의 중앙 저장소로 기능하며, 피처들은 피처 스토어를 통해서만 액세스하고 공유할 수 있습니다.\n\n#2. 트레이닝 파이프라인은 피처 스토어에서 특정 버전의 피처와 레이블을 가져와서 훈련된 모델 가중치를 출력하며, 이러한 가중치는 모델 레지스트리에 저장되고 버전을 관리합니다. 모델은 모델 레지스트리를 통해서만 액세스하고 공유할 수 있습니다.\n\n#3. 추론 파이프라인은 피처 스토어에서 특정 버전의 피처를 사용하고 모델 레지스트리에서 특정 버전의 모델을 다운로드합니다. 최종 목표는 클라이언트에 예측을 출력하는 것입니다.\n\n이것이 3개의 파이프라인 디자인이 아름다운 이유입니다:\n\n<div class=\"content-ad\"></div>\n\n- 직관적입니다.\n- 모든 머신 러닝 시스템은 이 3가지 구성 요소로 축소될 수 있어 더 높은 수준에서 구조를 가져옵니다.\n- 3가지 구성 요소 간에 투명한 인터페이스를 정의하여 여러 팀이 협업하기 쉬워집니다.\n- 머신 러닝 시스템은 처음부터 모듈화를 염두에 두고 구축되었습니다.\n- 필요에 따라 3가지 구성 요소를 여러 팀 사이로 쉽게 분할할 수 있습니다.\n- 각 구성 요소는 작업에 가장 적합한 기술 스택을 사용할 수 있습니다.\n- 각 구성 요소는 독립적으로 배포, 확장 및 모니터링할 수 있습니다.\n- 피처 파이프라인은 배치, 스트리밍 또는 둘 다로 쉽게 구현할 수 있습니다.\n\n하지만 가장 중요한 이점은...\n\n...이 패턴을 따라가면 여러분의 머신 러닝 모델이 노트북에서 제작 환경으로 옮겨질 것을 100% 확신할 수 있습니다.\n\n↳ 3-파이프라인 디자인에 대해 더 자세히 알고 싶으시다면, FTI 아키텍처의 창시자 중 한 명인 Jim Dowling이 작성한 훌륭한 [3] 글을 추천합니다.\n\n<div class=\"content-ad\"></div>\n\n# 3. LLM Twin System design\n\nLLM 시스템에 3-파이프라인 아키텍처를 어떻게 적용하는 지 알아봅시다.\n\nLLM twin의 아키텍처는 다음과 같이 4개의 Python 마이크로서비스로 구성됩니다:\n\n- 데이터 수집 파이프라인\n- 특징 추출 파이프라인\n- 훈련 파이프라인\n- 추론 파이프라인\n\n<div class=\"content-ad\"></div>\n\n보시다시피, 데이터 수집 파이프라인은 3-파이프라인 디자인을 따르지 않습니다. 이게 사실이에요.\n\n그것은 ML 시스템 이전에 위치한 데이터 파이프라인을 나타냅니다.\n\n데이터 엔지니어링 팀이 주로 구현하며, 이 파이프라인은 대시보드 또는 ML 모델을 구축하는 데 필요한 데이터를 수집, 정리, 정규화하고 저장하는 것이 목표입니다.\n\n하지만 작은 팀의 구성원이라고 하면, 데이터 수집부터 모델 배포까지 모든 것을 직접 구축해야 할 수도 있겠죠.\n\n<div class=\"content-ad\"></div>\n\n그렇기 때문에 데이터 파이프라인이 FTI 아키텍처와 어떻게 잘 맞고 상호 작용하는지를 보여 드리겠습니다. 이제 각 구성 요소를 자세히 살펴봐서 개별적으로 어떻게 작동하고 서로 상호 작용하는지 이해해 보겠습니다. ↓↓↓\n\n## 3.1. 데이터 수집 파이프라인\n\n그 범위는 주어진 사용자의 데이터를 크롤링하는 것입니다:\n\n<div class=\"content-ad\"></div>\n\n- Medium (기사)\n- Substack (기사)\n- LinkedIn (게시물)\n- GitHub (코드)\n\n각 플랫폼마다 고유하므로, 우리는 각 웹사이트를 위해 다른 Extract Transform Load (ETL) 파이프라인을 구현했습니다.\n\n🔗 ETL  파이프라인에 대한 1분 소요 읽기 [4]\n\n그러나 각 플랫폼에 대한 기본 단계는 동일합니다.\n\n<div class=\"content-ad\"></div>\n\n따라서 각 ETL 파이프라인에 대해 다음과 같은 기본 단계를 추상화할 수 있습니다:\n\n- 자격 증명을 사용하여 로그인\n- Selenium을 사용하여 프로필을 크롤링\n- HTML을 구문 분석하기 위해 Beautiful Soup 사용\n- 추출된 HTML을 정리하고 표준화\n- 정규화된 (그럼에도 불구하고 원시) 데이터를 Mongo DB에 저장\n\n중요 사항: 개인 정보 보호 문제로 인해 대다수 플랫폼에서 다른 사람의 데이터에 접근할 수 없기 때문에 우리는 단지 우리 자신의 데이터만을 수집합니다. 그러나 이는 우리에게 완벽한 선택입니다. LLM 트윈을 구축하기 위해서는 우리 자신의 디지털 데이터만 필요합니다.\n\n왜 Mongo DB를 사용할까요?\n\n<div class=\"content-ad\"></div>\n\n우리는 텍스트와 같이 구조화되지 않은 데이터를 빠르게 저장할 수 있는 NoSQL 데이터베이스를 원했습니다.\n\n데이터 파이프라인은 피쳐 파이프라인과 어떻게 통신할건가요?\n\n우리는 모든 Mongo DB의 변경 사항을 피쳐 파이프라인에 알리기 위해 Change Data Capture (CDC) 패턴을 사용할 것입니다.\n\n🔗 CDC 패턴에 대한 1분 간의 읽기 [5]\n\n<div class=\"content-ad\"></div>\n\nCDC를 간략히 설명하자면, 감시자는 Mongo DB에 발생하는 모든 CRUD 작업을 24/7 감지합니다.\n\n감시자는 수정된 내용을 알려주는 이벤트를 발생시킵니다. 이 이벤트를 RabbitMQ 큐에 추가할 거에요.\n\n기능 파이프라인은 계속해서 큐를 듣고, 메시지를 처리하여 Qdrant vector DB에 추가할 거에요.\n\n예를 들어, 우리가 Mongo DB에 새 문서를 작성할 때, 감시자는 새 이벤트를 생성합니다. 이벤트가 RabbitMQ 큐에 추가되고, 최종적으로 기능 파이프라인이 소비하고 처리합니다.\n\n<div class=\"content-ad\"></div>\n\n이를 통해 Mongo DB와 Vector DB가 항상 동기화되도록 보장할 수 있습니다.\n\nCDC 기술을 사용하면, 일괄 ETL 파이프라인(데이터 파이프라인)에서 스트리밍 파이프라인(특징 파이프라인)으로 전환합니다.\n\nCDC 패턴을 사용하면, Mongo DB와 vector DB 간의 차이를 계산하기 위한 복잡한 일괄 파이프라인을 구현하는 것을 피할 수 있습니다. 이 접근 방식은 대규모 데이터를 처리할 때 빠르게 느려질 수 있습니다.\n\n데이터 파이프라인은 어디에 배포될 것인가요?\n\n<div class=\"content-ad\"></div>\n\n데이터 수집 파이프라인과 RabbitMQ 서비스는 AWS에 배포될 예정입니다. 또한 MongoDB의 프리미엄 서버리스 버전을 사용할 것입니다.\n\n## 3.2. 기능 파이프라인\n\n기능 파이프라인은 Bytewax를 사용하여 구현되었습니다 (Python 인터페이스를 갖춘 Rust 스트리밍 엔진). 따라서, 우리의 특정 사용 사례에서는 이를 스트리밍 입력 파이프라인으로도 참조할 것입니다.\n\n이것은 데이터 수집 파이프라인과 완전히 다른 서비스입니다.\n\n<div class=\"content-ad\"></div>\n\n데이터 파이프라인과 어떻게 통신하나요?\n\n이전 설명대로, 기능 파이프라인은 RabbitMQ 큐를 통해 데이터 파이프라인과 통신합니다.\n\n현재, 스트리밍 파이프라인은 데이터가 어떻게 생성되었는지나 어디에서 왔는지에 관심이 없습니다.\n\n그저 특정 큐를 듣고, 그곳에서 메시지를 소비하고 처리해야 한다는 것만 알고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이렇게 하면 두 구성 요소를 완전히 분리할 수 있습니다. 미래에는 여러 소스에서 메시지를 큐에 쉽게 추가할 수 있으며, 스트리밍 파이프라인이 이를 어떻게 처리해야 하는지 알게 될 것입니다. 유일한 규칙은 큐에 있는 메시지가 항상 동일한 구조/인터페이스를 준수해야 한다는 것입니다.\n\n기능 파이프라인의 범위는 무엇인가요?\n\n이것은 RAG 시스템의 인계 구성 요소를 나타냅니다.\n\n큐를 통해 전달된 원시 데이터를 가져 와서 다음과 같은 작업을 수행할 것입니다:\n\n<div class=\"content-ad\"></div>\n\n- 데이터 정리하기;\n- 청크로 나누기;\n- Superlinked의 임베딩 모델을 사용해 임베딩하기;\n- Qdrant 벡터 DB에 로드하기.\n\n각 유형의 데이터(게시물, 기사, 코드)는 각자의 클래스 세트를 통해 독립적으로 처리됩니다.\n\n모두 텍스트 기반이지만, 각 데이터 유형마다 독특한 특징이 있기 때문에 데이터를 정리, 청크화, 임베딩하는 데 각기 다른 전략을 사용해야 합니다.\n\n어떤 종류의 데이터가 저장될 것인가요?\n\n<div class=\"content-ad\"></div>\n\n학습 파이프라인은 피쳐 스토어에만 액세스할 수 있습니다. 우리의 경우, Qdrant 벡터 DB로 표현됩니다.\n\n벡터 DB는 NoSQL DB로 사용할 수도 있다는 것을 기억하세요.\n\n이 두 가지를 염두에 두고, 우리는 Qdrant에 데이터의 2개 스냅샷을 저장할 것입니다:\n\n1. 정제된 데이터(인덱스로 벡터를 사용하지 않고 NoSQL 방식으로 저장).\n\n<div class=\"content-ad\"></div>\n\n2. 정리된, 청크 처리된 및 내장된 데이터 (Qdrant의 벡터 인덱스를 활용)\n\n학습 파이프라인은 표준 및 보강 프롬프트에서 LLM을 세밀 조정하고자 하므로 두 형식의 데이터에 액세스해야 합니다.\n\n정리된 데이터로 프롬프트 및 답변을 생성할 것입니다.\n\n청크 처리된 데이터로는 프롬프트를 보강할 것입니다 (일명 RAG).\n\n<div class=\"content-ad\"></div>\n\n스트리밍 파이프라인을 배치 파이프라인 대신 구현해야 하는 이유는 무엇인가요?\n\n그 이유는 주로 2가지가 있습니다.\n\n첫 번째 이유는 CDC 패턴과 결합해서 서로 다른 두 개의 데이터베이스를 동기화하는 가장 효율적인 방법이기 때문입니다. 그렇지 않으면 대규모 데이터를 처리할 때 확장 가능하지 않은 배치 폴링 또는 푸싱 기술을 구현해야 할 수 있습니다.\n\nCDC + 스트리밍 파이프라인을 사용하면 소스 데이터베이스의 변경 사항만 처리하고 여분의 작업이 발생하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n두 번째 이유는 그렇게 함으로써 소스와 벡터 데이터베이스가 항상 동기화된 상태가 유지됩니다. 따라서 RAG를 수행할 때 최신 데이터에 항상 액세스할 수 있습니다.\n\n왜 Bytewax를 사용해야 하는가?\n\nBytewax는 Python 인터페이스를 노출하는 Rust로 구축된 스트리밍 엔진입니다. Bytewax를 사용하는 이유는 Rust의 놀라운 속도와 신뢰성을 파이썬의 사용 편의성과 생태계와 결합시킨 점에 있습니다. Python 개발자에게는 매우 가볍고 강력하며 사용하기 쉽습니다.\n\n기능 파이프라인은 어디에 배포될 것인가요?\n\n<div class=\"content-ad\"></div>\n\n기능 파이프라인이 AWS에 배포될 예정입니다. 또한 우리는 Qdrant의 무료 서버리스 버전을 사용할 것입니다.\n\n## 3.3. 훈련 파이프라인\n\n훈련 기능에 접근할 수 있는 방법은 무엇인가요?\n\n3.2절에서 강조한 대로, 모든 훈련 데이터는 기능 저장소에서 접근할 수 있습니다. 저희 경우에는 기능 저장소인 Qdrant 벡터 DB에 다음과 같은 데이터가 포함됩니다:\n\n<div class=\"content-ad\"></div>\n\n- 우리는 프롬프트 및 답변을 생성할 정돈된 디지털 데이터를 사용할 것입니다.\n- RAG를 위해 청크와 임베디드된 데이터를 사용하여 정돈된 데이터를 보완할 것입니다.\n\n우리는 주요 데이터 유형(게시물, 기사, 코드)마다 다른 벡터 DB 검색 클라이언트를 구현할 것입니다.\n\n각 유형의 고유한 특성 때문에 벡터 DB를 쿼리하기 전에 각 유형을 다르게 전처리해야 합니다.\n\n또한, 우리는 각 클라이언트에 대해 벡터 DB에서 어떤 것을 쿼리하고 싶은지에 기반한 사용자 정의 동작을 추가할 것입니다. 그러나 이에 대해 자세히는 해당 레슨에서 설명하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n훈련 파이프라인은 무엇을 할까요?\n\n훈련 파이프라인에는 벡터 DB로부터 검색된 데이터를 전처리하여 프롬프트로 변환하는 데이터-투-프롬프트 레이어가 포함되어 있습니다.\n\n또한 HuggingFace 데이터셋을 입력으로 사용하고 QLoRA를 사용하여 주어진 LLM(예: Mistral)을 세밀하게 튜닝하는 LLM 세밀 조정 모듈이 포함될 것입니다. HuggingFace를 사용함으로써 다양한 LLM 사이를 쉽게 전환할 수 있기 때문에 특정 LLM에 너무 많은 집중이 필요하지 않습니다.\n\n모든 실험은 Comet ML의 실험 추적기에 로그가 남겨질 것입니다.\n\n<div class=\"content-ad\"></div>\n\n저희는 미세 조정된 LLM의 결과를 평가하기 위해 더 큰 LLM(예: GPT4)을 사용할 것입니다. 이러한 결과는 Comet의 실험 추적기에 기록될 것입니다.\n\n생산용 후보 LLM은 어디에 저장될까요?\n\n우리는 여러 실험을 비교한 뒤 최적의 결과를 선택하여 모델 레지스트리를 위한 LLM 생산용 후보를 발표할 것입니다.\n\n이후, Comet의 프롬프트 모니터링 대시보드를 사용하여 LLM 생산용 후보를 수동으로 검토할 것입니다. 최종 수동 검사가 통과되면, 우리는 모델 레지스트리의 LLM을 수락된 상태로 표시할 것입니다.\n\n<div class=\"content-ad\"></div>\n\nCI/CD 파이프라인이 실행되어 새로운 LLM 버전이 추론 파이프라인에 배포될 것입니다.\n\n훈련 파이프라인은 어디에 배포될까요?\n\n훈련 파이프라인은 Qwak에 배포될 예정입니다.\n\nQwak은 ML 모델을 훈련하고 배포하는 서버리스 솔루션입니다. 작업 확장을 쉽게 할 수 있으며 건설에 집중할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n위 내용은 다음을 위해 Comet ML의 프리미엄 버전을 사용할 것입니다:\n\n- 실험 추적기;\n- 모델 레지스트리;\n- 실시간 감시.\n\n## 3.4. 추론 파이프라인\n\n추론 파이프라인은 LLM 시스템의 최종 구성 요소입니다. 클라이언트가 상호 작용할 구성 요소입니다.\n\n<div class=\"content-ad\"></div>\n\n이것은 REST API 아래에 랩핑될 것입니다. 클라이언트들은 HTTP 요청을 통해 이를 호출할 수 있으며, 이는 ChatGPT나 비슷한 도구들과 유사한 경험입니다.\n\n기능에 어떻게 접근할까요?\n\n기능 저장소에 접근하기 위해, 훈련 파이프라인에서와 같이 Qdrant 벡터 DB 검색 클라이언트들을 사용할 것입니다.\n\n이 경우 RAG를 수행하기 위해 청크 데이터에 접근하는데 기능 저장소가 필요할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n얼마나 미세 조정된 LLM에 액세스할 수 있나요?\n\n미세 조정된 LLM은 항상 해당 태그(예: accepted)와 버전(예: v1.0.2, latest 등)을 기반으로 모델 레지스트리에서 다운로드됩니다.\n\n미세 조정된 LLM은 어떻게 로드되나요?\n\n우리는 여기서 추론 세계에 있습니다.\n\n<div class=\"content-ad\"></div>\n\nLLM의 속도와 메모리 사용량을 최대한 최적화하려고 합니다. 그래서 모델 레지스트리에서 LLM을 다운로드한 후 양자화할 것입니다.\n\n추론 파이프라인의 구성 요소는 무엇인가요?\n\n첫 번째는 RAG를 수행하기 위해 벡터 데이터베이스에 액세스하는 검색 클라이언트입니다. 이는 교육 파이프라인에서 사용된 모듈과 동일합니다.\n\nQdrant에서 검색된 도큐먼트를 프롬프트로 매핑할 쿼리가 있으면 해당 쿼리 후보를 매핑해줄 계층이 있습니다.\n\n<div class=\"content-ad\"></div>\n\nLLM이 답변을 생성한 후, 우리는 Comet의 프롬프트 모니터링 대시보드에 기록하고 클라이언트에게 반환할 것입니다.\n\n예를 들어, 클라이언트는 추론 파이프라인에 다음을 요청할 수 있습니다:\n\n\"LLM에 관한 1000단어의 LinkedIn 게시물 작성\", 그리고 추론 파이프라인은 생성된 게시물을 반환하기 위해 위에서 설명한 모든 단계를 거칠 것입니다.\n\n추론 파이프라인은 어디에 배포될 것인가요?\n\n<div class=\"content-ad\"></div>\n\n추론 파이프라인은 Qwak로 배포됩니다.\n\n기본 설정으로, Qwak은 자동 확장 솔루션과 생산 환경 자원을 모니터링하는 멋진 대시보드도 제공합니다.\n\n훈련 파이프라인에 대해서는, 우리는 실시간 모니터링 대시보드를 제공하는 Comet의 서버리스 프리미엄 버전을 사용할 것입니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\nLLM Twin의 무료 코스 1번째 기사입니다.\n\n이 강의에서는 이 코스 동안 구축할 내용을 소개했습니다.\n\n간단히 ML 시스템을 설계하는 방법에 대해 논의한 후\n\n최종적으로 이 코스의 시스템 디자인을 살펴보고 각 마이크로서비스의 아키텍처 및 서로 상호작용 방법을 소개했습니다.\n\n<div class=\"content-ad\"></div>\n\n- 데이터 수집 파이프라인\n- 피쳐 파이프라인\n- 훈련 파이프라인\n- 추론 파이프라인\n\n제2 장에서는 데이터 수집 파이프라인을 더 자세히 살펴보고, 다양한 소셜 미디어 플랫폼에 크롤러를 구현하는 방법을 배우고, 수집한 데이터를 정리하여 Mongo DB에 저장하고, 마지막으로 AWS에 배포하는 방법을 안내해 드릴 거에요.\n\n이 기사를 즐겁게 보셨나요? 그렇다면...\n\n↓↓↓\n\n<div class=\"content-ad\"></div>\n\n5천 명 이상의 엔지니어들과 함께하여, 프로덕션급 머신 러닝에 대한 검증된 컨텐츠를 살펴보세요. 매주 업데이트되는 콘텐츠를 놓치지 마세요:\n\n# 참고문헌\n\n[1] 당신의 LLM 트윈 코스 — GitHub 저장소 (2024년), Decoding ML GitHub 조직\n\n[2] Meta에서 새로운 AI 경험 소개(2023년), Meta\n\n<div class=\"content-ad\"></div>\n\n- [3] Jim Dowling, From MLOps to ML Systems with Feature/Training/Inference Pipelines (2023), Hopsworks\n\n- [4] Extract Transform Load (ETL), Databricks Glossary\n\n- [5] Daniel Svonava and Paolo Perrone, Understanding the different Data Modality / Types (2023), Superlinked","ogImage":{"url":"/assets/img/2024-05-18-AnEnd-to-EndFrameworkforProduction-ReadyLLMSystemsbyBuildingYourLLMTwin_0.png"},"coverImage":"/assets/img/2024-05-18-AnEnd-to-EndFrameworkforProduction-ReadyLLMSystemsbyBuildingYourLLMTwin_0.png","tag":["Tech"],"readingTime":15},{"title":"구직 20-터보 AI 에이전트가 선두를 달리다","description":"","date":"2024-05-18 19:59","slug":"2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay","content":"\n\n\n![이미지](/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_0.png)\n\n# 목차\n\n## 소개\n\n- 모든 구직자에 영향을 미치는 일반적인 도전 과제 (왜..)\n- 취업 과정 최적화를 위한 AI 에이전트의 중요한 역할 (무엇..)\n- 과정에 AI 에이전트 기능 소개 (어떻게..)\n\n\n<div class=\"content-ad\"></div>\n\n## 직접 해보기: AI 기반 취업 검색 엔진 구현\n\n- 프로젝트 구조\n- 프레임워크\n- 도구\n- 데이터\n- 작업\n- 에이전트\n- LLM\n- 출력 모델\n- 모든 것을 함께 모아보기: 크루\n- 결과 분석\n\n소스 코드\n요약\n잠재적 개선 사항\n참고 자료\n\n취업 검색은 어렵고 시간이 많이 소요될 수 있습니다. 취업을 위해 구인 공고를 탐색하는 데는 몇 주에서 몇 달이 걸릴 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![Job Search](/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_1.png)\n\n시간 소요량은 전문성, 수요 역할, 시장 등 여러 요소에 따라 다를 수 있지만, 미국 노동 통계국(US Bureau of Labor Statistics)의 실업률 데이터(수동적으로 정찰 중인 사람들 포함)에 따르면 2024년 3월의 중앙값 기간은 21.6주 ~ 5개월이었습니다.\n\n인간 연령 규모에서, 평균 구직자가 새로운 직업을 찾는 데 소요되는 시간을 고려하면, 수백 건의 지원서를 검토하는 데 소비되는 훌륭한 시간이네요.\n\n취업을 위한 성공 요소 중 하나는 제출된 지원서의 수입니다. 한 연구 결과에 따르면, 적절한 직책을 찾기 위해 필요한 평균 지원서 수는 100~200건 이상이며, 시장, 경제 상황 및 지원자의 전문성에 따라 이상치가 발생할 수 있습니다. 취업을 위해 지원서를 작성하고 노력하는 데 드는 양이 많기 때문에, 효율적이고 확장 가능한 해결책을 개발하여 수천 시간을 절약해 주는 동기가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 모든 구직자가 직면하는 공통적인 도전과제 (왜 그럴까요..)\n\n![JobSearch Image](/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_2.png)\n\n시장이 구인 공고로 넘쳐나는 상황에서 자신의 기술과 요구 사항에 가장 적합한 역할을 찾는 것은 어려운 일입니다. 이러한 상황에 처해 본 적이 있다면, 수백 개의 구인 공고를 살펴보고 기술, 급여 수준, 선결 조건 등을 맞추려고 노력하는 과정이 얼마나 스트레스 받고 힘들 수 있는지 알 것입니다. 프로세스가 늦어질수록 동기 부여가 낮아지고 구직을 포기하고 덜 나은 선택을 하는 위험이 높아집니다.\n\n적절한 역할을 찾는 데 걸리는 시간은 개인의 경험, 지원 시기, 그리고 구직 시장에서 기술이 얼마나 요구되는지에 따라 다릅니다. 그리고 적용하는 산업 및 기업에 영향을 미치는 등의 제어할 수 없는 요소들이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사에서는 AI 기반의 취업 검색 엔진을 구축하는 과정에서 다루는 주요 과제들은 주로 취업 검색 및 매칭 과정을 최적화하는 데 초점을 맞추고 있습니다. 따라서 아래와 같은 주요 과제를 해결하고 있습니다:\n\n중요한 과제들\n\n- 취업 광고 검색: 전통적으로, 취업을 위한 스크리닝 작업은 작업이 광고되는 올바른 소스 플랫폼을 선택하는 것으로 시작됩니다. 특정 기준으로 작업을 필터링하고 모든 콘텐츠를 소화하여 최종 결과물을 평가합니다. 더 많은 사람들에게 도달하기 위해 많은 사람이 한 가지 이상의 플랫폼에서 작업을 한다고 합니다. 여러 소스 사이를 오가며 어디에 무엇이 있는지 추적해야 하는 문제가 발생하기 시작합니다.\n- 취업 광고 평가: 구인 광고가 내 이전 경험과 기술 세트에 부합하는가? 필요한 경력은 있는가? 올바른 위치에 있는가? 어떤 언어를 구사해야 하는가? 급여 범위가 내 요구 사항을 만족하는가? 역할 시작일은 언제인가? 요구 사항에 맞는 구인 광고를 평가할 때 발생하는 몇 가지 질문들입니다.\n- 조직 평가: 취업 스크리닝 중 일반적인 단계는 조직에 대한 연구입니다. 조직을 평가하는 데 일반적인 기준은 직원 리뷰, 시장 성과, 평판 등입니다. 조직이 운영하는 시장에 따라 더 많은 기준이나 평가 기준이 소개될 수 있습니다. 교차 시장 기회를 찾는 경우 이 단계는 고려해야 할 모든 요소를 고려할 때 매우 많은 시간이 소요될 수 있습니다.\n- 취업자 추리: 수십 개에서 수백 개의 구인 광고를 스크리닝한 후 결정을 내리기 전에 최종적인 결정에 도달하기 위해 통과한 몇 가지 작업을 추립니다. 취하는 방식에 관계없이, 리스트 정렬을 위한 어떤 기준을 기반으로 평가 전략을 취할 것입니다. 이는 취향과 우선순위에 따라 주관적인 평가이며, 이 작업을 완료하기 위해 필요한 구인 광고 사이의 혼합 및 일치하는 양을 상상해 볼 수 있습니다.\n\n열거된 과제들은 반복적인 작업을 포함하며, 강력한 추론 능력과 명확한 실행 가능한 목록에 도달하기 위해 소화해야 할 대량의 콘텐츠를 요구합니다.\n\n<div class=\"content-ad\"></div>\n\n이러한 작업은 LLM 파워에 기반을 둔 에이전트를 채용하는 주요 특성을 완벽하게 충족시킵니다.\n\n# AI 에이전트가 취업 프로세스를 최적화하는 데 중요한 역할 (무엇..)\n\n![이미지](/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_3.png)\n\n수백 명의 구직자가 구인 광고를 검토하고 광고 회사와 그들의 채용 공고를 심층적으로 평가하며, 마지막으로 귀하의 요구에 가장 적합한 권장 사항을 맞춤 제작하는 것의 최종 결과를 상상해보세요. 온라인 구인 광고를 검토하는 데 소요되는 시간을 크게 줄이는 자동화 및 추론에 기초한 완전한 엔드 투 엔드 프로세스입니다.\n\n<div class=\"content-ad\"></div>\n\nAI 에이전트의 능력을 분석해 보겠습니다. 일자리 검색과 추천을 자동화하고 개인화하는 데에서의 능력에 초점을 맞춥니다. 다음 섹션에서 엔진을 구축하는 것에 대해 더 자세히 살펴볼 것입니다. 현재는 AI 에이전트가 갖고 있는 장점에 초점을 맞춥니다.\n\n1. 에이전트는 도구를 사용할 수 있습니다.\n\n에이전트는 자신의 작업을 수행하는 데 정의된 도구를 활용할 수 있습니다. 이는 인터넷 검색 및 사전 정의된 API를 사용하여 데이터를 요청하는 것과 같은 더 나은 연구 능력을 제공하는 도구를 활용하는 것을 포함합니다. 이는 에이전트가 훈련된 데이터를 넘어서 다양한 도구를 활용하여 사용자가 선택한 툴킷을 사용하여 에이전트가 특정 작업을 어떻게 해결할지를 지시할 수 있는 능력을 제공합니다.\n\n2. 에이전트는 상당량의 정보를 소화할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nAI 모델의 콘텍스트 창 크기가 점점 커지면서(1밀리초 이상), 때로는 무한한 콘텍스트 창에 이를 정도로, 에이전트들이 소화하고 논할 수 있는 정보량은 계속해서 증가하고 있습니다. 제대로 분배된다면, 에이전트들은 무한한 양의 정보를 분석하고 사용자에게 최종 요약된 버전을 제공할 수 있습니다.\n\n3. 에이전트가 논리를 할 수 있습니다\n\nAI 에이전트의 추론 능력에는 제한이 있을 수 있지만, 점점 개선되고 최적화된 새로운 모델들이 점점 더 자주 공개되면서 이 갭이 좁혀지고 있습니다. 구인 광고를 분석하고 사용자 쿼리를 일부 매개 변수에 기반해 비교하는 작업을 고려할 때, 이 작업은 매우 훈련된 AI 에이전트에게는 직관적인 분석 작업으로 간주될 수 있습니다.\n\n4. 에이전트가 결과를 요약하고 구조화할 수 있습니다\n\n<div class=\"content-ad\"></div>\n\n대량의 정보를 처리할 수 있는 도구는 가치가 있지만, 그 정보를 효율적이고 구조화된 방식으로 전달하지 못하는 경우 가치가 상실됩니다. AI 에이전트는 환각에 취약할 수 있으며, 이는 정보를 요약하고 보고하는 방식에 영향을 미칠 수 있습니다. 잘 설계된 프롬프트 및 추가적인 유효성 검사 단계를 제공하여 에이전트가 올바르고 신뢰할 수 있는 결과로 작업을 수행하도록 보장합니다.\n\n5. 에이전트는 협업할 수 있습니다.\n\n에이전트가 작업할 때 배경, 역할 및 과제의 차이는 다양성의 층을 제공하며, 이는 다양한 관점에서 문제 해결에 접근하는 데 도움이 됩니다. 에이전트 간의 협력은 사용자에게 전달되는 최종 결과를 최적화하는 데 이 능력을 활용합니다.\n\n6. 에이전트는 확장 가능합니다.\n\n<div class=\"content-ad\"></div>\n\n대규모 요소들을 병렬 실행 작업으로 동적 할당하는 것은 매우 강력합니다. 이 방식은 문제를 작은 조각으로 나누고 별도의 요소들이 작업에 참여할 수 있는 경우 빛을 발합니다. 다수의 요소들이 일괄 작업에 할당될 수 있으며, 각 요소는 과정의 한 단계를 처리하고 결과를 다음 단계에 넘기는 역할을 맡습니다. 마지막으로, 요소들은 결과를 모아 최종 요약 및 구조화를 수행할 수 있습니다. 이러한 방식은 다중 채널이나 원본을 통해 구인 광고를 빠르고 확장 가능하게 처리할 수 있는 방법 중 하나입니다.\n\n우리의 사용 사례에 대해 모든 이러한 기능을 어떻게 결합할 수 있을까요?\n\n# 프로세스에 AI 요소 기능 소개 (어떻게..)\n\n모든 AI 기능을 활용하는 솔루션을 보장하기 위해, 프로세스의 각 단계에 요소를 도입합니다.\n\n<div class=\"content-ad\"></div>\n\n- 에이전트들은 구인 광고에 관한 정보를 검색하기 위해 도구를 사용할 것입니다. 초기 구인 공고는 사용자 쿼리를 기반으로 검색됩니다.\n- 에이전트들은 사용자의 이력서와 쿼리를 기반으로 구인 공고에 대한 등급 및 그에 대한 이유를 제공할 것입니다.\n- 에이전트들은 인터넷 접근 도구를 사용하여 구인 광고의 소스 조직에 대한 정보를 연구하고, 그 정보를 기반으로 조직에 대한 등급 점수를 제공할 것입니다.\n- 에이전트들은 최종적으로 결과를 요약하고 미리 정의된 모델에 따라 결과를 구조화할 것입니다.\n\n다음 섹션에서는 나열된 AI 에이전트들의 능력을 활용하여 구인 검색 엔진을 구축하는 방법에 대해 살펴보겠습니다.\n\n# 실습 안내: AI-기반 구인 검색 엔진 구축하기\n\n이번 섹션에서는 완벽한 구현 단계별로 안내하며 최종 결과를 분석하고 잠재적 개선 사항을 살펴볼 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 프로젝트 구조\n\n프로젝트 구조는 기능과 컴포넌트 간의 명확한 분리를 보장하여 코드 수정 및 적응을 쉽게 할 수 있도록 합니다. 다음과 같은 구성요소로 구성됩니다:\n\n- configs 디렉토리: 에이전트(역할, 배경, 배경 이야기 설정) 및 작업(설명 및 기대 출력 설정)을 구성하는 데 필요한 모든 구성 및 매개변수를 포함\n- data 디렉토리: 작업 검색 엔진을 테스트하는 데 필요한 모든 데이터를 포함\n- models 디렉토리: 기대 출력 스키마를 정의하는 모델을 포함\n- utils 디렉토리: 필요한 지원 함수를 포함\n- agents_factory.py 및 tasks_factory.py: 구성에 기반하여 에이전트 및 작업의 인스턴스를 동적으로 생성하는 데 사용됩니다.\n\n\nproject/\n├── configs\n│ └── agents.yml # 에이전트 구성\n│ └── tasks.yml # 작업 구성\n│\n├── data\n│ ├── sample_jobs.json # 작업 목록을 포함하는 JSON 파일\n│ └── sample_resume.txt # 이력서를 포함하는 텍스트 파일\n│\n├── models\n│ └── models.py # ORM 모델\n│\n├── utils\n│ └── utils.py # 유틸리티 함수 및 도우미\n│\n├── .env # 필요한 모든 환경 변수 포함\n│\n├── agents_factory.py # 에이전트 인스턴스 생성을 위한 팩토리 클래스\n├── tasks_factory.py # 작업 인스턴스 생성을 위한 팩토리 클래스\n│\n└── main.py # 메인\n\n\n<div class=\"content-ad\"></div>\n\n# 프레임워크\n\n프로젝트는 crewAI 프레임워크를 활용하여 엔드 투 엔드 응용 프로그램을 구축할 것입니다. 이는 할당된 작업과 특정 도구를 사용하여 AI 에이전트를 구축하기 위한 직관적인 인터페이스를 제공합니다. 다른 사용 가능한 AI 프레임워크와 매우 잘 통합되며, 이는 이 글의 범위에 완벽하게 맞습니다.\n\n먼저 Python 환경(제 경우에는 python-3.11.9 사용)이 있는지 확인하고 필요한 모든 도구와 함께 프레임워크를 설치하십시오.\n\n```js\npip install 'crewai[tools]'\n```  \n\n<div class=\"content-ad\"></div>\n\n`crewai[tools]` 패키지 설치는 애플리케이션을 실행하는 데 필요한 모든 패키지를 포함해야 합니다.\n\n# 도구들\n\n![이미지](/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_4.png)\n\n에이전트는 할당된 작업을 수행하기 위해 일련의 도구가 필요합니다. 도구를 에이전트에 할당하는 것은 요청 흐름 아키텍처를 어떻게 정의하고 정보가 한 에이전트에서 다른 에이전트로 전송되는지에 따라 달라집니다.\n\n<div class=\"content-ad\"></div>\n\ncrewAI 내에서 이미 사용 가능한 두 가지 도구를 사용하여 우리의 사용 사례를 테스트해야 합니다.\n\n**FileReadTool**\n\n생산 규모에서는 신뢰할 수있는 여러 API를 확보하여 작업 데이터를 제공하고 관리할 수 있으며, 이러한 경우 주요 에이전트 도구는 여러 공급 업체와 인터페이스 할 수 있고 선택한 매개변수를 기반으로 작업 정보를 가져올 수 있는 도구입니다.\n\n우리 애플리케이션의 범위 내에서는 이미 검색된 JSON 응답 샘플 sample_jobs.json을 사용하여 작업 세부 정보 목록을 갖고 솔루션을 집중적으로 보여주도록 할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n생성된 이력서 샘플 **sample_resume.txt**은 에이전트가 제공하는 평점을 테스트하기 위해 사용할 수 있습니다.\n\n**SerperDevTool**\n\n에이전트들은 조직에 관한 정보를 수집하고 사용자에게 평점 피드백을 제공하는 것이 그들의 임무입니다. 이 도구는 에이전트들이 인터넷을 검색할 수 있도록 지원하며, serper.dev에 계정을 생성하여 필요한 API 키를 획들한 후 환경에 로드하여 이 도구를 사용할 수 있습니다.\n\nAPI 키가 **.env** 파일에 정의되어 있는지 확인하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nSERPER_API_KEY=<>\n```\n\n툴을 직접 가져와서 사용할 수 있습니다\n\n```js\nfrom crewai_tools import FileReadTool, SerperDevTool\n```\n\n새로운 기능을 빠르고 간단하게 애플리케이션 범위를 확장하기 위해 툴을 추가하고 에이전트에 할당하는 것이 중요합니다.```\n\n<div class=\"content-ad\"></div>\n\n# 데이터\n\n샘플_jobs.json은 사용 사례의 테스트 데이터로 합성으로 생성된 샘플 구인 광고 목록의 JSON 응답을 포함하고 있습니다.\n\n기사에 제시된 구인 데이터는 JSON 형식으로 표시되지만, 에이전트들이 구문 분석할 수 있는 다른 형식으로 쉽게 변환될 수 있습니다. 예를 들어 PDF 또는 Excel 파일로 저장된 간단한 텍스트, 직접 수집한 구인 설명 데이터 문서 등이 있습니다.\n\n검색 프로세스를 완전히 활용하려면 에이전트들이 작업 플랫폼 API와 상호 작용하는 도구를 사용하여 데이터 수집 프로세스를 자동화하고 확장해야 합니다. 이러한 공식적인 구인 검색 API 제공업체의 예로는 Glassdoor나 Jooble이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n{\n  \"jobs\": [\n    {\n      \"id\": \"VyxlLGIsICxELGUsdixlLGwsbyxwLGUscixELGUsbSxhLG4sdCxTLHkscixhLGMsdSxzLGUsLCwgLE4=\",\n      \"title\": \"Web Developer\",\n      \"company\": \"Apple\",\n      \"description\": \"As a Web Developer at CQ Partners, you will be a leader in the structuring, maintaining, and facilitating of websites and web-based applications...\",\n      \"image\": \"<https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQAkPEjEwMeJizfsnGN-qUAEw8pmPdk357KIzsi&s=0>\",\n      \"location\": \"Syracuse, NY\",\n      \"employmentType\": \"Full-time\",\n      \"datePosted\": \"17 hours ago\",\n      \"salaryRange\": \"\",\n      \"jobProvider\": \"LinkedIn\",\n      \"url\": \"<https://www.linkedin.com/jobs/view/web-developer-at-demant-3904417702?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic>\"\n    },\n    {\n      \"id\": \"VyxlLGIsICxELGUsdixlLGwsbyxwLGUsciwsLCAsVSxYLC8sVSxJLCwsICxCLHIsYSxuLGQsaSxuLGc=\",\n      \"title\": \"Web Developer, UX/UI, Branding, Graphics\",\n      \"company\": \"Adobe\",\n      \"description\": \"Degree required: Bachelor’s degree in relevant field...\",\n      \"image\": \"<https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSV7-v1EkEhWtAh8W8WaqPD6vMQG2uBi0GOOOmb&s=0>\",\n      \"location\": \"Columbia, MD\",\n      \"employmentType\": \"Full-time\",\n      \"datePosted\": \"1 day ago\",\n      \"salaryRange\": \"\",\n      \"jobProvider\": \"LinkedIn\",\n      \"url\": \"<https://www.linkedin.com/jobs/view/web-developer-ux-ui-branding-graphics-at-adg-creative-3903771314?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic>\"\n    },\n    ......\n```\n\n또한 경험 많은 데이터 과학자를 위한 생성된 이력서가 포함된 sample_resume.txt 파일이 있습니다.\n\nGithub에서 파일의 전체 내용을 확인할 수 있습니다.\n\n# 작업\n\n<div class=\"content-ad\"></div>\n\n작업은 해당 작업을 완료할 수 있는 적절한 도구와 기술을 갖춘 에이전트에게 배정됩니다.\n\n각 작업은 설명, 예상 출력 및 작업을 완료할 책임이 있는 에이전트로 정의됩니다.\n\n```js\n# configs/tasks.yml \n\njob_search:\n  description: |\n    다음 요구 사항을 충족하는 작업 목록을 찾습니다: {query}\n  expected_output: 모든 정보가 포함된 작업 목록의 유효한 json 형식의 구조화된 출력입니다. 필드 이름이 동일한지 확인하세요.\n\njob_rating:\n  description: |\n    이력서 파일 정보를 찾는 데 도구를 사용합니다.\n    받은 작업에 대해 이력서 정보에 따라 추가 등급을 제공합니다.\n    등급은 1에서 10까지이며 10이 가장 적합합니다.\n    모든 작업에는 등급이 있어야 합니다.\n    추가로 등급 설명 필드를 추가하여 등급에 대한 이유를 1~2문장으로 설명합니다.\n    모든 작업에 대한 모든 정보도 출력에 유지되도록 합니다.\n  expected_output: 작업 목록과 각각의 등급을 유효한 json 형식으로 구조화된 출력입니다. 필드 이름이 동일한지 확인하세요.\n\nevaluate_company:\n  description: |\n    작업 회사에 대한 정보를 찾기 위해 도구를 사용합니다.\n    정보에는 회사 문화 평가, 회사 재무 보고서 및 주가 성과가 포함될 수 있습니다.\n    회사에 대한 추가 등급을 나타내는 company_rating 필드를 제공합니다.\n    등급은 1에서 10까지이며 10이 가장 좋은 등급입니다.\n    모든 작업에는 등급이 있어야 합니다.\n    추가로 company_rating_description 필드를 추가하여 등급에 대한 이유를 1~2문장으로 설명합니다.\n    모든 작업에 대한 모든 정보도 출력에 유지되도록 합니다.\n  expected_output: 작업 목록과 각각의 등급을 유효한 json 형식으로 구조화된 출력입니다. 모든 정보를 이 모델 {output_schema}에 따라 구조화하도록 확인하세요.\n\nstructure_results:\n  description: |\n    최종 보고서에 필요한대로 모든 컨텍스트를 사용하여 출력을 구조화합니다.\n  expected_output: 작업 목록과 각각의 등급을 유효한 json 형식으로 구조화된 출력입니다. 제공하는 최종 출력이 스키마 {output_schema}를 준수하는 유효한 json임을 확인하세요.\n```\n\nTasksFactory 클래스를 사용하여 모든 필요한 작업을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# project/tasks_factory.py \n\nfrom textwrap import dedent\nfrom typing import Optional\n\nfrom crewai import Agent, Task\n\nfrom utils.utils import load_config # YAML 파일 불러오기\n\nclass TasksFactory:\n    def __init__(self, config_path):\n        self.config = load_config(config_path)\n\n    def create_task(\n        self,\n        task_type: str,\n        agent: Agent,\n        query: Optional[str] = None,\n        output_schema: Optional[str] = None,\n    ):\n        task_config = self.config.get(task_type)\n        if not task_config:\n            raise ValueError(f\"{task_type}에 대한 구성을 찾을 수 없습니다.\")\n\n        description = task_config[\"description\"]\n        if \"{query}\" in description and query is not None:\n            description = description.format(query=query)\n\n        expected_output = task_config[\"expected_output\"]\n        if \"{output_schema}\" in expected_output and output_schema is not None:\n            expected_output = expected_output.format(output_schema=output_schema)\n\n        return Task(\n            description=dedent(description),\n            expected_output=dedent(expected_output),\n            agent=agent,\n        )\n```\n\n# 에이전트\n\n에이전트는 선택된 작업을 가장 잘 완료하기 위해 역할, 목표 및 소개가 정의됩니다.\n\n```js\n# configs/tasks.yml \n\njob_search_expert:\n  role: 최고의 취업 전문가\n  goal: 최고의 구인 공고와 광고를 찾아 모든 요청자를 감명시키기\n  backstory:  취업 시장의 전문가로서 많은 경험을 가진 취업 전문가\n\njob_rating_expert:\n  role: 최고의 취업평가 전문가\n  goal: 이력서 정보에 가장 적합한 취업을 찾아 정확한 평가 제공으로 모든 요청자를 감동시키기\n  backstory: 취업 매칭 및 평가에 대한 전문 성이 뛰어난 취업평가 전문가\n\ncompany_rating_expert:\n  role: 최고의 기업 평가자\n  goal: 취업 적합성을 평가하기 위해 기업에 대한 모든 중요한 정보를 찾기\n  backstory: 기업 정보 수집자 및 평가 전문가로서 회사 평가 및 심층적 연구에 대한 많은 전문성을 가진 피부록\n\nsummarization_expert:\n  role: 최고의 출력 유효성 검사 및 요약가\n  goal: 작업에 필요한 최종 결과물이 작업과 일치하는지 확인하기\n  backstory: 필요한 대로 출력물에 보고하는 방법과 올바른 구조를 알고 있는 최고의 보고 전문가\n```\n\n<div class=\"content-ad\"></div>\n\n태스크 팩토리와 유사하게, 에이전트 팩토리 클래스는 설정에 기반하여 필요한 모든 AI 에이전트를 생성하는 데 사용됩니다.\n\n```python\n# project/agents_factory.py \n\nfrom typing import Any, List, Optional\n\nfrom crewai import Agent\n\nfrom utils.utils import load_config # YAML 파일로드\n\nclass AgentsFactory:\n    def __init__(self, config_path):\n        self.config = load_config(config_path)\n\n    def create_agent(\n        self,\n        agent_type: str,\n        llm: Any,\n        tools: Optional[List] = None,\n        verbose: bool = True,\n        allow_delegation: bool = False,\n    ) -> Agent:\n        agent_config = self.config.get(agent_type)\n        if not agent_config:\n            raise ValueError(f\"{agent_type}에 대한 구성을 찾을 수 없습니다.\")\n\n        if tools is None:\n            tools = []\n\n        return Agent(\n            role=agent_config[\"role\"],\n            goal=agent_config[\"goal\"],\n            backstory=agent_config[\"backstory\"],\n            verbose=verbose,\n            tools=tools,\n            llm=llm,\n            allow_delegation=allow_delegation,\n        )\n```\n\n## LLM\n\nLLM 선택에 관한 옵션 범위는 계속 확장되어 매주 새로운 모델이 출시됩니다. 이 설정에서는 특히 gpt-4–32k 버전 0613의 Azure Open AI 모델과 작업하게 될 것입니다. 그러나 선호하는 LLM으로 코드를 조정하고 테스트해보세요.```\n\n<div class=\"content-ad\"></div>\n\nAzure OpenAI 모델을 사용하려면 API KEY와 ENDPOINT가 필요합니다. Azure는 이러한 모델을 설정하고 배포하기 위한 훌륭한 문서를 제공합니다.\n\n우리는 `.env` 파일에 필요한 환경 변수를 추가합니다.\n\n```js\nOPENAI_API_VERSION = <>\nAZURE_OPENAI_KEY= <>\nAZURE_OPENAI_ENDPOINT = <>\n```\n\n아래 코드를 사용하여 선택한 모델을 가져와 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom langchain_openai import AzureChatOpenAI\nimport os\n\nazure_llm = AzureChatOpenAI(\n            azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n            api_key=os.environ.get(\"AZURE_OPENAI_KEY\"),\n            deployment_name=\"gpt4\",\n            streaming=True,\n            temperature=0 # 더 일관적이고 정확한 출력을 위해 이 값을 0으로 설정했습니다\n        )\n```\n\n# 출력 모델\n\n에이전트가 최종적으로 일관된 출력을 보여주기 위해 원하는 출력 모델을 정의합니다.\n\n```js\n# models/models.py\n\nfrom typing import List, Optional\nfrom pydantic import BaseModel\n\nclass Job(BaseModel):\n    id: Optional[str]\n    location: Optional[str]\n    title: Optional[str] \n    company: Optional[str]\n    description: Optional[str]\n    jobProvider: Optional[str]\n    url: Optional[str]\n    rating: Optional[int] \n    rating_description: Optional[str] \n    company_rating: Optional[int] \n    company_rating_description: Optional[str]  \n    \nclass JobResults(BaseModel): \n    jobs: Optional[List[Job]]\n```\n\n<div class=\"content-ad\"></div>\n\n# 모든 것을 함께 넣어보자: 승무원\n\n이전 다이어그램들은 에이전트가 원하는 결과물을 얻기 위해 작업할 일련의 이벤트를 보여줍니다. 한 작업의 완료는 다음 에이전트에게 전달되며 특정 역할로 최적화된 에이전트가 작업을 처리합니다. 따라서 순차적 프로세스를 구성하여 목적을 달성합니다. 에이전트 협력 및 병렬 처리를 통해 작업에 대한 다른 전략을 선택하고 설계를 재구성할 수 있습니다.\n\n마지막으로, 우리는 main.py 내에서 서치 승무원을 생성하여 모든 AI 에이전트를 생성, 할당 및 실행합니다.\n\n```js\nimport json\nimport os\nfrom textwrap import dedent\n\nfrom crewai import Crew, Process\nfrom crewai_tools import FileReadTool, SerperDevTool\nfrom dotenv import load_dotenv\nfrom langchain_openai import AzureChatOpenAI\nfrom pydantic import ValidationError\n\nfrom agents_factory import AgentsFactory\nfrom models.models import JobResults\nfrom tasks_factory import TasksFactory\n\nload_dotenv()\n\n\nclass JobSearchCrew:\n    def __init__(self, query: str):\n        self.query = query\n\n    def run(self):\n        # 에이전트가 활용할 LLM AI 정의\n        azure_llm = AzureChatOpenAI(\n            azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n            api_key=os.environ.get(\"AZURE_OPENAI_KEY\"),\n            deployment_name=\"gpt4\",\n            streaming=True,\n            temperature=0,\n        )\n\n        # 필요한 모든 도구 초기화\n        resume_file_read_tool = FileReadTool(file_path=\"data/sample_resume.txt\")\n        jobs_file_read_tool = FileReadTool(file_path=\"data/sample_jobs.json\")\n        search_tool = SerperDevTool(n_results=5)\n\n        # 에이전트 생성\n        agent_factory = AgentsFactory(\"configs/agents.yml\")\n        job_search_expert_agent = agent_factory.create_agent(\n            \"job_search_expert\", tools=[jobs_file_read_tool], llm=azure_llm\n        )\n        job_rating_expert_agent = agent_factory.create_agent(\n            \"job_rating_expert\", tools=[resume_file_read_tool], llm=azure_llm\n        )\n        company_rating_expert_agent = agent_factory.create_agent(\n            \"company_rating_expert\", tools=[search_tool], llm=azure_llm\n        )\n        summarization_expert_agent = agent_factory.create_agent(\n            \"summarization_expert\", tools=None, llm=azure_llm\n        )\n\n        # 응답 모델 스키마\n        response_schema = json.dumps(JobResults.model_json_schema(), indent=2)\n\n        # 작업 생성\n        tasks_factory = TasksFactory(\"configs/tasks.yml\")\n        job_search_task = tasks_factory.create_task(\n            \"job_search\", job_search_expert_agent, query=self.query\n        )\n        job_rating_task = tasks_factory.create_task(\n            \"job_rating\", job_rating_expert_agent\n        )\n        evaluate_company_task = tasks_factory.create_task(\n            \"evaluate_company\",\n            company_rating_expert_agent,\n            output_schema=response_schema,\n        )\n        structure_results_task = tasks_factory.create_task(\n            \"structure_results\",\n            summarization_expert_agent,\n            output_schema=response_schema,\n        )\n\n        # 승무원 조립\n        crew = Crew(\n            agents=[\n                job_search_expert_agent,\n                job_rating_expert_agent,\n                company_rating_expert_agent,\n                summarization_expert_agent,\n            ],\n            tasks=[\n                job_search_task,\n                job_rating_task,\n                evaluate_company_task,\n                structure_results_task,\n            ],\n            verbose=1,\n            process=Process.sequential,\n        )\n\n        result = crew.kickoff()\n        return result\n\n\nif __name__ == \"__main__\":\n    print(\"## 직업 검색 승무원에 오신 것을 환영합니다\")\n    print(\"-------------------------------\")\n    query = input(\n        dedent(\"\"\"\n      찾고 있는 직업의 특성 목록을 제공하세요: \n    \"\"\")\n    )\n\n    crew = JobSearchCrew(query)\n    result = crew.run()\n\n    print(\"최종 결과를 확인 중..\")\n    try:\n        validated_result = JobResults.model_validate_json(result)\n    except ValidationError as e:\n        print(e.json())\n        print(\"데이터 출력 유효성 검사 오류, 다시 시도 중...\")\n\n    print(\"\\n\\n########################\")\n    print(\"## 결과 \")\n    print(\"########################\\n\")\n    print(result)\n```\n\n<div class=\"content-ad\"></div>\n\n작업 실행 후에는 JSON 출력이 정의된 모델 스키마로 유효성이 검사되도록 검증 확인을 실행합니다. 또한, 에이전트가 필요한 구조를 반환하는 것을 보장하기 위해 추가적인 유효성 검사 루프를 추가할 수도 있습니다. 이 완전한 프로세스를 구현하는 세부 정보에 대해 다루지는 않겠지만, 관심이 있다면 이 주제에 대한 훌륭한 글을 확인해보세요.\n\n# 결과 분석\n\n우리는 간단히 아래의 코드를 실행합니다.\n\n```js\npython main.py\n```\n\n<div class=\"content-ad\"></div>\n\n우리의 초기 에이전트 쿼리에는 다음을 입력했습니다.\n\n```js\n찾고 있는 직업의 특성 목록을 제공하십시오.\n\n미국에서 연봉 범위가 $100K- $170K인 기계 학습 및 데이터 과학 직업\n```\n\n쿼리는 추가적으로 위치, 시작 날짜, 산업 등과 같은 많은 다른 매개변수를 필터링하고 취업 정보를 찾기에 적합하게 확장될 수 있습니다.\n\nOutput:\n\n<div class=\"content-ad\"></div>\n\n터미널 결과를 보면 첫 번째 에이전트가 성공적으로 실행되어 도구를 사용하여 작업 목록 콘텐츠를 검색했습니다.\n\n![이미지1](/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_5.png)\n\n에이전트는 그런 다음 목록을 필터링하고 입력 쿼리를 기반으로 올바른 작업을 찾는 데 성공했습니다.\n\n![이미지2](/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_6.png)\n\n<div class=\"content-ad\"></div>\n\n\n개발자님의 진행 상황을 보여주는 상세한 디버깅 정보를 건너뛰고 최종 결과로 넘어가겠습니다.\n\n결과에는 구성된 작업 내에서 요청된 모든 필드뿐만 아니라 유효한 최종 JSON 결과 구조도 포함되어 있습니다. 또한 우리는 지시된 대로 제공된 평가 및 해당 평가에 대한 이유도 확인합니다.\n\n이제 해당 평가가 실제로 사용자 이력서와 일치하는 과정을 반영하는지 더 테스트해 보려면 쿼리를 다음과 같이 조정해보겠습니다\n\n```js\n찾고 있는 직업의 특성 목록을 제공해 주세요: \n\n미국의 웹 개발자 직업\n```\n\n<div class=\"content-ad\"></div>\n\n웹 개발자 역할을 요청하면서 기계 학습 및 데이터 과학 포지션에 최적화된 이력서를 갖고 계시다가 평가가 실제로 낮아졌다는 것을 관찰했습니다.\n\n# 소스 코드\n\n프로젝트의 전체 소스 코드는 GitHub에서 확인할 수 있습니다.\n\n# 요약\n\n<div class=\"content-ad\"></div>\n\n이 기사는 전통적으로 시간이 많이 소요되는 구직 과정에 AI 에이전트를 도입하는 것이 어떤 엄청난 영향을 미치는지에 대해 논의했습니다. 특히, 온라인 구인 광고와 요구 사항을 평가하고 매칭하는 단계에 초점을 맞췄습니다. 우리는 구직 과정의 주요 도전과제를 살펴보고, 인간이 완료하는 데 주로 몇 주, 아니면 몇 달이 걸릴 작업들을 AI 에이전트가 몇 초만에 수행할 수 있는 위치에 AI 에이전트를 위치시켰습니다. 마지막으로, 사용자에 대한 적합한 직업을 찾도록 작업하는 AI 에이전트를 자동화하는 데 필요한 코드를 구현했으며, 여러 도구를 활용하여 작업을 완료했습니다.\n\n다가오는 수개월과 수년 동안, AI가 결국 구직 엔진과 플랫폼에 통합될 것으로 예상되며, 결과적으로 빠르고 극도로 개인화된 취업 매칭 과정이 이루어질 것입니다. 그러나 자신의 AI 기반 구직 엔진의 설계와 아키텍처를 통제할 수 있는 능력은 구직 시에 유연성과 더 큰 장점을 가져다 줄 것입니다.\n\n# 잠재적 개선 사항\n\n본 문서에서 논의된 사용 사례는 AI 기반 구직 엔진에 추가될 수 있는 잠재적인 기능 중 일부에 불과합니다. 나는 구직 플랫폼이 결국 이러한 도구들을 통합하고 거대한 고객 기반을 활용할 것이라고 믿습니다. 이를 새로운 수준으로 끌어올릴 수 있는 것은 자신의 요구 사항에 맞게 맞춤형으로 제작된 크로스 플랫폼 솔루션을 직접 구축하는 것입니다. 선택한 모델을 통합하고 에이전트와 작업을 특정 요구 사항에 맞게 조정하는 유연성을 가질 수 있는것입니다.\n\n<div class=\"content-ad\"></div>\n\n아래 목록에 다시 그림카드를 설치할 것이 좋습니다.\n\n- 다양한 작업 검색 플랫폼 API와 상호 작용하는 대규모 에이전트 및 도구를 통합하여 확장\n- 채용공고에 기반하여 이력서 및 자기소개서를 개선하고 적응시키기 위해 과제를 개인화하는 자동화된 응용 프로그램 과정\n- 채용 조건에 따라 잠재적 인터뷰 문항 목록을 생성하고 에이전트와 모의 인터뷰를 실행하여 더 나은 준비 상태\n- 포지션 및 광고된 기술을 위해 광범위한 시장 조사를 통해 더 나은 급여 협상\n- 실시간 처리 및 평가로 광고를 지속적으로 모니터링한 후 더 나은 기회 제공\n- ….\n\n- 새로운 이야기를 게시할 때 알림을 받으려면 구독하세요.\n- LinkedIn에서 저에게 연락을 주세요.\n\n더 많은 유사한 기사에 관심이 있으시다면 아래 목록을 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n미국 노동통계국. (2024, 4월 5일). Table A-12. 2024년 Q01 결과에 따른 실업자의 실업 기간별 인원 수. U.S. Bureau of Labor Statistics. https://www.bls.gov/news.release/empsit.t12.htm\n\nTao, Zhengwei 등. 대형 언어 모델의 이벤트 추론에 대한 포괄적 평가. arXiv:2404.17513, arXiv, 2024년 4월 26일. arXiv.org, https://doi.org/10.48550/arXiv.2404.17513.\n\n일자리를 얻기 위해 몇 번의 지원이 필요할까요? — movement to work. Movement to Work — Movement to Work는 영국 기업이 청소년 실업 문제를 해결하기 위해 고품질 직업 훈련과 청소년을 위한 직무 경험 기회를 제공을 통해 자발적으로 협력하는 단체입니다. (2022, 7월 15일). https://movementtowork.com/how-many-applications-does-it-take-to-get-a-job/\n\n<div class=\"content-ad\"></div>\n\n크루에이아이 - 다중 AI 에이전트 시스템을 위한 플랫폼","ogImage":{"url":"/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_0.png"},"coverImage":"/assets/img/2024-05-18-JobSearch20-TurboAIAgentsLeadingtheWay_0.png","tag":["Tech"],"readingTime":23},{"title":"기업용 프롬프트 엔지니어링 관행","description":"","date":"2024-05-18 19:57","slug":"2024-05-18-EnterprisePromptEngineeringPractices","content":"\n\n# 소개\n\n대규모 언어 모델(LLM)과 상호작용하는 것은 본질적으로 프롬프트에 매우 의존합니다. 프롬프트는 모델로부터 특정한 동작이나 출력을 유도하기 위한 자연어 지침입니다.\n\n프롬프트는 비전문가에게 LLM에 접근할 수 있게 돕긴 하지만, 복잡하거나 특정 작업에 대한 효과적인 프롬프트를 만드는 것은 어렵습니다.\n\n<div class=\"content-ad\"></div>\n\n모델을 원하는 결과물로 이끄는 것에는 기술, 지식 및 반복적 개선이 필요합니다.\n\nIBM 연구팀은 사용자가 프롬프트를 반복하면서 어떻게 사용하는지 연구했으며, 이 연구는 다음을 이해하는 데 도움이 됩니다.\n\n- 프롬프트 사용 및\n- 모델 동작, 그리고\n- 효율적인 프롬프트 엔지니어링에 필요한 지원\n\n일반적으로 프롬프트에는 내장 예시, 템플릿, 필요한 출력물에 대한 설명, 지시사항 및 In-Context Learning을 위한 문맥 데이터가 포함될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 결과\n\n결과는 두 부분으로 나뉩니다.\n\n먼저, 연구는 관찰된 프롬프트 편집 세션들에 대한 광범위한 양적 분석을 제공합니다.\n\n이어서 연구는 리뷰 및 주석 프로세스에서 나온 더 포괄적인 결과에 대해 심층적으로 다루며 질적 관측을 통합합니다.\n\n<div class=\"content-ad\"></div>\n\n- 프롬프트 편집 세션은 일반적으로 상당한 기간 동안 진행되었으며, 평균 세션은 약 43.4분의 시간이 소요되었습니다.\n- 사용자들은 종종 모델 매개변수를 조정하는 대신에 또는 함께 프롬프트를 편집하는 데 집중합니다.\n- 사용자들은 원하는 결과를 얻기 위해 프롬프트를 조금씩 반복적으로 변경하는 경향이 있어, 프롬프트 세부 조정 반복 과정에서 불규칙적으로 행동하지 않는 것으로 나타났습니다.\n- 사용자들은 프롬프트를 개선하는 동안 추론 매개변수를 자주 조정했으며, 관찰된 세션 중 93%가 이러한 매개변수를 하나 이상 변경한 것으로 나타났습니다.\n- 가장 자주 변경된 매개변수는 대상 언어 모델 (모델 ID)이었으며, 이어서 최대 새 토큰 및 반복 패널티 매개변수가 조정되었습니다.\n\n성공적인 결과를 얻으려면 사용자들이 프롬프트를 조금씩 반복적으로 변경하는 경향이 있는 것으로 보입니다.\n\n<div class=\"content-ad\"></div>\n\n매개변수 변경은 변경이 발생한 세션의 백분율로 기록되었습니다.\n\n사용자들은 대부분 대상 언어 모델을 수정하고 생성할 토큰의 최대 수를 조정하며 반복 패널티를 미세 조정했습니다. 또한, 중단 시퀀스, 온도 및 디코딩 방법을 변경하는 것이 자주 관찰되었습니다.\n\n각 프롬프트 구성 요소에 초점을 맞춘 편집 횟수. 사용자들은 기본적으로 맥락을 편집했으며 작업 지시사항은 상대적으로 적게 수정되었습니다.\n\n이것은 다시 한번 보여주는 것입니다. 인컨텍스트 러닝(ICL)을 유지하는 관점에서 맥락은 매우 중요하며, 그 다음이 작업 지시사항이라는 것을 입증합니다.\n\n<div class=\"content-ad\"></div>\n\n아래 그래프는 사용된 모델 수를 보여줍니다. 대부분의 세션은 두 개의 모델을 살펴본 것이 흥미로운데, 아마도 쉬운 A/B 테스트 접근법을 수행했을 것입니다.\n\n가장 많이 사용된 수정 작업과 텍스트의 문맥이 보강되거나 변경되거나 수정 또는 제거되어야 하는 작업은 편집 유형 중 가장 많이 사용된 것입니다.\n\n# 콘텍스트\n\n분석된 프롬프트와 사용 사례 대부분은 콘텍스트 기반입니다.\n\n<div class=\"content-ad\"></div>\n\n프롬프트 안에 입력, 배경 데이터 또는 예시가 통합되어 있었으며, 작업 지시와는 분리되었습니다.\n\n모든 분석된 세션에서 맥락이 가장 자주 편집되는 구성 요소로 부각되었으며, 기업 업무에 대한 그 중요성을 강조했습니다.\n\n맥락 추가의 두 가지 주요한 패턴:\n\n- 대화 시뮬레이션 및\n- 예시 추가.\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 변경하실 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n22%의 편집이 여러 번의 변화를 만들고 나서야 다시 프롬프트를 제출하는, 다중 편집이었습니다.\n\n평균적으로, 이러한 다중 편집에는 약 2.29개의 변경이 포함되었으며, 대부분은 컨텍스트에 대한 편집을 포함했습니다.\n\n다중 편집은 효율적으로 보일 수 있지만, 결과물에 미치는 영향을 추적하기를 어렵게 할 수 있습니다. 추가로, 편집의 약 1/5은 추론 매개변수의 변경과 함께 이루어졌으며, 이는 변경을 관리하고 모델 동작에 미치는 영향을 이해하기 위한 체계적 접근의 필요성을 시사합니다.\n\n# 롤백\n\n<div class=\"content-ad\"></div>\n\n약 11%의 프롬프트 편집이 이전 변경 사항을 취소하거나 다시 실행하는 것을 포함했습니다. 이에도 불구하고 이러한 작업은 개별 편집으로 계산되었습니다.\n\n이러한 행동은 과거 결과를 기억하는 데 어려움이 있거나 어떤 편집이 출력물을 개선할 수 있는지에 대한 불확실성을 시사할 수도 있습니다.\n\n재미있게도, 덜 자주 편집되는 프롬프트 구성 요소는 이전 변경 사항을 취소하는 편집 비율이 더 높았습니다.\n\n예를 들어, instruction:handle-unknown에 대한 편집의 40%가 되돌려졌으며, instruction:output-length에 대해 25%가, 라벨에 대해 24%가, instruction:persona 편집에 대해서는 18%가 되돌려졌습니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n이 연구는 1523개의 개별 프롬프트로 구성된 57개의 프롬프트 편집 세션을 분석했습니다. 이 프롬프트 편집 세션은 프롬프트 실험 및 개발을 용이하게 하는 엔터프라이즈 LLM 도구를 사용하였습니다.\n\n사용자들은 종종 모델 파라미터를 조정하는 대신 또는 나란히 프롬프트를 편집하는 데 초점을 맞춥니다.\n\n이러한 편집 중 많은 것들은 완전한 개조보다는 단일 프롬프트에 대한 소규모 조정이나 반복입니다.\n\n<div class=\"content-ad\"></div>\n\n품질 분석 결과를 살펴보면 사용자들이 주로 예시, 기반 문서, 그리고 입력 쿼리와 같은 프롬프트 컨텍스트를 수정한다는 것을 강조합니다.\n\n의외로도, 컨텍스트 편집은 지시사항 편집보다 많은 것으로 드러났는데, 이는 과제 또는 출력 형식, 길이, 또는 페르소나와 같은 요소를 설명하는 것과 관련이 있습니다.\n\n라벨 편집 및 프롬프트 구성 요소 정의는 또한 일반적입니다.\n\n이러한 통찰력은 현재의 프롬프트 편집 관행을 살펴보고 더 효과적인 프롬프트 엔지니어링 지원을 위한 미래 방향을 제시해줍니다.\n\n<div class=\"content-ad\"></div>\n\n⭐️ 제 LinkedIn에서 큰 언어 모델에 관한 업데이트를 받아보세요 ⭐️\n\n![이미지](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_1.png)\n\n저는 현재 Kore AI의 최고 전도사입니다. 인공지능과 언어가 교차하는 모든 영역에 대해 탐구하고 쓰고 있습니다. 대형 언어 모델(Large Language Models), 챗봇(Chatbots), 음성봇(Voicebots), 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제를 다룹니다.\n\n![이미지](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_2.png)\n\n<div class=\"content-ad\"></div>\n\n\n![2024-05-18-EnterprisePromptEngineeringPractices_3](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_3.png)\n\n![2024-05-18-EnterprisePromptEngineeringPractices_4](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_4.png)\n","ogImage":{"url":"/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_0.png"},"coverImage":"/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_0.png","tag":["Tech"],"readingTime":4},{"title":"경험 많은 ChatGPT 사용자를 위한 4가지 인간-인공지능 상호작용 패턴","description":"","date":"2024-05-18 19:53","slug":"2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers","content":"\n\nChatGPT가 출시된 지 1년 반이 되었지만, 전체 사용자 중 30% 이상이 그것을 실력을 발휘한 AI 챗봇으로 사용하고 있습니다. 대부분의 사람들은 대화식 인공지능의 '특징'인 상호작용 뒤집기, 기준 기반 자가평가, 그리고 인간과 함께 작업을 공동으로 구상하는 것에 대해 자각하지 못하고 있습니다. 결과적으로 그들은 AI를 위한 작업을 상세히 설명하고 AI 출력물의 여러 수정본을 분석하는 데 많은 시간을 투자하지만, 여전히 기대보다 못한 결과물을 얻고 있습니다. 어떻게 이를 해결할지 알아봅시다.\n\n![Huma-AI Interaction Patterns](/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_0.png)\n\n# 소개\n\n지역 \"관리용 AI\" 커뮤니티의 적극적 구성원으로, ChatGPT와 다른 GenAI 어시스턴트의 숙련된 사용자조차도 대화식 방식을 통해 전통적인 방법으로 진행한다는 점을 자주 발견합니다. 그들은 완전한 지침을 작성해야 한다고 가정하고, AI가 그들의 지침을 따르기만을 기대합니다.\n\n<div class=\"content-ad\"></div>\n\nAI 챗봇은 자주 우리의 질문에 답하거나 우리의 지시에 따라 텍스트를 생성하거나 데이터를 처리하는 도구로만 보입니다. 챗봇이 만족스러운 결과물을 제공하지 못하면, 우리는 더 잘 가르쳐 주어야 하거나, 간단히 챗봇을 사용하지 않을 수도 있습니다. 또한, 우리가 시간을 들여 작업을 자세히 설명할 여유가 없거나 아직 작업 자체를 완전히 이해하지 못했을 때는 AI를 사용하지 않기도 합니다.\n\n그러나 이 전통적인 시각은 생성적 AI의 범위와 가치를 제한합니다. 사실, 대형 언어 모델은 우리에게 요청에 응답하거나 지시에 따라 행동하는 것 이상의 다양한 역할을 수행할 수 있습니다. 더욱이, 더 나은 결과물을 얻기 위해 항상 가르치거나 \"훈련\"시키지 않아도 됩니다.\n\n간편함을 위해, 나는 관행적이지 않은 AI 역할을 4가지 인간-인공지능 상호작용 패턴으로 그룹화하겠습니다. 그래서 이 기사는 4개의 섹션으로 구성되어 있습니다. 그러나, 이것은 제 개인적인 단순화일 뿐입니다. 제 주요 아이디어는 특정 역할에 관한 것이 아니라, 인간-인공지능 상호작용의 표준 \"요청-응답\" 모델을 확장하는 것에 대한 것입니다.\n\n# 1. 뒤바뀐 상호작용 전략\n\n<div class=\"content-ad\"></div>\n\nAI 역할 영역에서 첫 번째로 명백하지 않은 패턴은, AI가 질문을 하면서 선도하는 \"뒤바뀐 상호 작용\"이다.\n\n연구 논문[1]은 프롬프트 엔지니어링의 맥락 속에서 뒤바뀐 상호 작용 패턴을 검토하며, 페르소나 패턴 및 템플릿 패턴과 같은 다른 기술과 함께 다룬다. 뒤바뀐 상호 작용 패턴은 짧은 블로그 글에서 프롬프팅 기술로도 설명된다.\n\n## 이유\n\n일반적으로, 이 방식은 인간으로부터 요구되는 시간과 인지적 노력을 줄여주어 일반적인 AI 사용자의 목표에 완벽하게 부합된다. 마찬가지로, 일반적인 인터넷 사용자는 내용이나 제품 제안을 받는 것을 좋아하며, 스스로 질문을 명확히 표현할 필요가 없다.\n\n<div class=\"content-ad\"></div>\n\n## 사용 사례\n\n- 예를 들어, AI 챗봇은 종종 멘토로 사용됩니다. 이러한 멘토의 이득 중 절반은 제공하는 조언에 있지 않습니다 (제 경험 상 종종 너무 일반적이고 실행할 수 없는 경우가 많음), 오히려 사용자가 문제에 대한 해결책을 찾도록 자극하는 사고를 유도하는 능력에 있습니다.\n- 똑같이, \"강력한\" 개방형 질문을 제공하여 사용자의 문제와 도전 과제를 식별하는 데 도움이 되는 AI 코치의 역할도 동일합니다.\n- 또는 개인 맞춤형 AI 튜터의 역할을 살펴보면 기본적으로 사용자의 지식과 기술에 있는 공백을 식별하고 이후에 해당 공백을 채우기 위해 질문을 하는 데 초점을 맞춥니다.\n- 마찬가지로 동료의 역할도 AI가 질문하는 것을 전제합니다. 이러한 종류의 질문은 사람이 어떠한 목표를 달성하기 위한 동기부여를 찾는 데 도움이 됩니다.\n\n## 구현 예시\n\n예를 들어, AI 튜터로 넓은 주제를 빠르게 숙달하고 싶다면 \"내가 `주제`에 대해 이해하는 현재 수준을 알아보기 위해 N개의 개방형 질문을 해 주세요\"라고 요청할 수 있습니다. 그런 다음, 답변을 평가하고 식별된 가장 약한 영역에 초점을 맞춘 새로운 질문을 요청할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이것은 빠른 피드백이 있는 적응형 학습으로 이어집니다. 이는 학습자에게 우선 순위를 명확하게 제시하여 교육적 요구 사항에 대한 우선 순위를 투명하게 제공합니다. 이와는 달리 기존의 적응형 학습 시스템에서는 학습자에게 우선 순위가 불투명합니다.\n\nGPT-4와의 샘플 채팅은 여기에서 찾을 수 있습니다. 이 예시에서 실습 중인 주제를 배우고 있으므로 ChatGPT는 사용자에게 질문이 아닌 과제를 부여하고 있습니다.\n\n# 2. 협업 작업 정의 및 맥락 향상\n\nAI 챗봇이 질문을 하면서 상호작용이 뒤바뀌는 상황을 접근 방법으로 보기도 합니다. AI와의 Q&A 세션의 목표는 빠르게 작업 관련 맥락을 형성하는 것으로, 이는 챗봇을 일반적인 응답자/수행자 역할로 활용하기 위해 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n## 그 이유\n\n적어도 이 방법은 복잡한 작업을 직면했을 때 미루는 주요 이유인 \"빈 페이지\" 문제를 극복하는 데 도움이 될 수 있습니다. 이 문제는 특히 본적 없는 문제를 해결하도록 챗봇에 요청할 때 특히 발생합니다.\n\n사람들은 (위의 게시물을 예로 들면) AI에 임무 초안을 빠르게 작성하여 빈 페이지 문제를 해결할 수 있다고 생각합니다. 이는 도움이 될 수 있지만, 그러한 임무 초안의 AI 출력물은 면밀히 조사되어야 하며 대부분은 품질이 낮아서 버려지게 됩니다.\n\n동일한 문제에 대한 더 나은 해결책은 먼저 챗봇에서 질문을 받고, 출력물은 나중에 생성하는 것입니다. 그 이유는 질문을 선택하고 답하는 것이 작업을 처음부터 설명하는 것보다 훨씬 용이하기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n이터레이션 질문의 두 번째 장점은 고품질 결과물입니다. 결과물은 단순히 유사한 문제에 대한 일반적인 해결책이 아닌 특정 컨텍스트에 의존합니다. 일정 작업을 해결하기 위한 전체 과정을 인공지능이 질문을 던지면서 구축할 수 있습니다. 이에 대답하고, 그에 따라 추가 질문을 받습니다. 이렇게 계속되다가 \"이제 `모든 내용을 고려한 완전한 해결책을 제안해 주세요`\"와 같은 문구를 봇에게 전할 때까지 진행됩니다.\n\n## 활용 사례\n\n- 이러한 작업을 드물게 다루거나 해당 주제에 익숙하지 않은 경우, 올바른 단어와 전반적인 작업 이해가 부족할 수 있습니다. 그럴 때는 AI에게 자세한 작업의 여러 버전을 제안하도록 유도하고, 필요에 맞는 버전을 선택한 후에 품질 높은 결과물을 기대할 수 있습니다. 그렇지 않으면 \"입력이 나쁘면 출력도 나쁘다\"라는 원칙이 적용됩니다.\n- 주어진 작업 분야의 전문가인 경우, \"만능 보조자\"가 예상한 출력을 생성하는 데 필요한 컨텍스트가 부족한지 이해할 수 있는 수준으로 내려가고 어렵다고 느낄 수 있습니다. 보조자에게 필요한 정보에 대해 스스로 이야기하도록 해보세요!\n\n## 구현 예시\n\n<div class=\"content-ad\"></div>\n\n특정 상황에서 중요한 질문 종류는 아직 충분히 이해하지 못한 작업을 명확히하기 위해 사용되는 질문입니다. 처음에는 “...에 관련된 작업 서식을 제안해주세요”와 같은 식으로 요청할 수 있습니다. 그런 다음, 요구사항에 가장 부합하는 서식을 선택한 후 \"이 작업을 좀 더 명확히 하기 위해 질문해주세요\"라고 말할 수 있습니다 (이러한 패턴은 기사 [1]에서 논의된 질문 정제 패턴(Question Refinement Pattern)과 인식 확인 패턴(Cognitive Verifier Pattern)과 비슷합니다). 그럼, AI 질문 중 일부에 대답하고 일부는 의도적으로 무시합니다. 무시하는 것도 작업과 관련된 집중된 문맥을 만드는 데 중요합니다.\n\n\"일부 항목 선택\"이라고 말할 때, 혹은 \"일부 질문에 대답\"할 때, 목록 항목의 숫자만 사용한다는 점을 의미합니다. 최신 LLM(언어모델)은 이러한 숫자를 잘 이해하며, 시간을 절약하는 면에서 매우 유용합니다.\n\n![이미지](/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_1.png)\n\n구체적인 예로, 고용 인터뷰를 위한 준비 목표를 살펴보겠습니다. AI에게 쉬운 작업은 아닙니다.\n\n<div class=\"content-ad\"></div>\n\n- 초보 사용자는 인공지능에게 공석에 관한 몇 문장을 바탕으로 인터뷰 질문을 작성하도록 요청할 수 있으나 결과는 대부분 만족스럽지 못할 것입니다.\n- 숙련된 사용자는 가능한 모든 관련 정보인 직무 설명서와/또는 업무 목록을 인공지능에게 제공할 것입니다. 그러나 이 경우에도 결과물은 너무 일반적할 가능성이 높습니다. 대규모 언어모델(Large Language Model, LLM)은 아름답게 표현할 수 있지만, 본질적으로 제공된 문서의 단어를 표준 \"인터뷰 템플릿\"에 반영한 것 뿐입니다. 해당 직무를 직접 수행해 본 적이 없기 때문에 직무 설명서에서 특히 중요한 부분을 내재적으로 이해할 수 없습니다. 또한 문서에는 내게 특히 중요한 후보자 특성이 무엇인지에 대한 정보가 없기 때문에 이를 알 수도 없습니다.\n\n그러므로 우리는 인공지능에게 설명을 명확히 하도록 요구해야 합니다. 다음과 같은 방식으로 지시할 것입니다:\n\n- 직무 설명서에서 위의 목적을 위해 필요한 정보를 추출합니다 (첨부된 문서 참조).\n- 직무의 특징과 내 개인적인 선호도를 이해하기 위해 필요한 여러 질문을 저에게 하십시오. 질문은 특정하고 문서와 일치하도록 해야 합니다. 질문 목록은 번호가 매겨져야 합니다.\n- 제 답변을 토대로 직무와 제 선호도를 깊이 이해하십시오. 제가 무의미하다고 생각하는 측면은 무시하십시오. 그 후, 앞서 강조된 모든 중요한 부분을 다루는 인터뷰 질문을 구성하십시오.\n\n이와 같은 예시를 따르는 GPT-4 채팅은 여기에서 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## AI 혼란을 피하는 방법\n\n특정 사항에 대한 추가 설명을 요청하여 위의 프로세스를 이어 나갈 수 있습니다. 그러나 장황하게 되풀이하지 말고 \"그냥 질문을 하기 위해서\" 질문을 하는 것을 피하십시오. 목표는 귀하의 작업을 이해하는 데 도움을 주는 것뿐만 아니라 AI를 효과적으로 작업 솔루션으로 이끄는 것이기 때문입니다. 문맥 속 과도한 단어는 LLM이 귀하의 의도한 방향으로 멀어지게 할 수 있습니다 [4].\n\nAI 혼란의 가능성을 줄이기 위해 작업을 해결하기 바로 전에 다음과 같이 말할 수 있습니다. \"이제 위의 모든 사항을 고려한 나의 작업을 완전히 정리해보세요.\" 그리고 즉시 해결책을 요청하는 대신이 테크닉은 두 가지 이유로 유용합니다:\n\n- 문맥 속 마지막 메시지가 완전한 작업이 되며, 가장 최근의 메시지는 LLM에 대비 문맥을 준비하는 챗봇 알고리즘에 의해 중요하게 여겨집니다. LLM은 \"주의\"를 가지고 있기 때문에 문맥의 모든 부분을 동등하게 취급하지 않습니다.\n- 작업 설명에 잘못된 부분이 있는 경우 최종 단계 전에 해당 부분을 교정하는 것이 좋습니다.\n\n<div class=\"content-ad\"></div>\n\n## 어떻게 더 많은 노력을 줄일 수 있을까요?\n\n제가 믿습니다. 당신이 병원에서 다른 상황을 찾을 수 있을 것이라고 생각합니다. 전환된 상호작용이 특히 당신에게 유용할 수 있습니다. 이 전략은 맥락 형성과 질문 그 자체에 모두 사용될 수 있습니다 (AI가 코치, 친구, 멘토 또는 선생님 역할을 하는 것).\n\n그러나 만약 여러분이 자주 AI와 상호작용을 전환한다면, 거의 모든 단계에서 챗봇에게 질문 제시하기에 지쳐 버릴 수 있습니다. 따라서 AI에게 한 번만 이 작업을 수행하도록 요청할 수 있습니다. 신뢰성을 위해 이를 \"시스템 프롬프트\"라고 부르는 것이 좋습니다.\n\n- ChatGPT Plus를 사용하는 경우, 시스템 프롬프트를 적용하는 것은 당신 자신의 GPT를 만들고 \"Instructions\" 필드에 프롬프트를 입력하는 것을 의미합니다. 그런 다음 사용자 요청과 어시스턴트의 응답과 별도로 LLM에 전달될 것입니다.\n- 다른 시스템 프롬프트를 만드는 또 다른 방법은 ChatGPT Plus 같은 비용이 많이 드는 구독 없이 가능합니다. 각 주요 LLM 공급업체는 ChatGPT나 Claude.ai보다 더 많은 제어권을 제공하는 도구를 제공합니다. OpenAI는 Playground, Anthropic은 Console, Google은 AI Studio를 제공하며 이러한 도구를 사용하여 시스템 프롬프트를 설정하고 LLM 버전을 선택하고 온도 및 기타 매개변수를 할당할 수 있습니다. 이는 구독 비용보다 적은 비용이 필요합니다. 게다가, Anthropic은 새로운 사용자에게 무료 5달러 크레딧을 제공하며 Google AI Studio는 무료로 이용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n다음은시스템 프롬프트용으로 예시 구문을 드렸습니다: “사용자가 무엇을 요청했다면 (질문을 한다거나 지시를 한다 등), 그 요청의 더 나은 버전을 제안해야 합니다 (더 구체적인 출력으로 이어질 수 있는 상세한 버전) 그리고 사용자에게 내 버전을 사용하고 싶은지 물어보아야 합니다.”. 이 구절은 질문 개선 패턴의 한 종류로, 이와 유사한 패턴에 대해 여기에서 읽어볼 수 있습니다.\n\n## 3. 인간 역할에 기반한 AI 상호작용\n\n\"고객-수행자\" 모델 이외의 사람들과 상호작용하는 다른 방법을 살펴보세요. 상호작용이 뒤바뀔 필요는 없습니다. 즉, 초기화와 질문이 반드시 챗봇에서 나와야 하는 것은 아닙니다. 사실, 이전에 언급된 \"멘토-견습생\" 및 \"선생님-학생\" 모델은 전자에서 나오는 질문에 관한 것만이 아닙니다.\n\n여러분과 AI 간에 가능한 상호작용 모델은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n## AI가 당신의 부하로: 정기적으로 승인하고 수정하기\n\n이러한 인간 관계는 보스가 지시를 내리고 부하가 말 없이 실행하는 것만큼 간단한 것이 아닙니다. 예를 들어, 부하들은 종종 아이디어나 구체적인 계획, 그리고 예비 결과물을 상사에게 승인을 받기 위해 제시합니다.\n\n이렇게 함으로써 관리자들은 보고서를 작성하거나 새 제품을 개발하거나 심지어 새로운 전략을 수립하는 등의 작업의 일부 단계에서만 개입함으로써 시간을 절약할 수 있습니다. 그러나 모든 것을 예상하거나 모든 세부 사항을 미리 해결하는 것은 불가능하기 때문에, 그들은 수시로 감시하고 반복적으로 참여합니다. 업무 중에 외부 상황이 변경될 수 있고, 직원이 마감일을 놓칠 수 있어 다시 계획을 세워야 할 수도 있습니다.\n\n마찬가지로, 당신은 자신을 \"AI 봇 관리자\"로 생각할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- AI에게 안내문을 작성하도록 요청하고, 그것을 비평하고 실행을 요청하십시오.\n- 대부분의 실제 과제에서는 하나의 안내만으로는 부족합니다. 과제는 상호 관련된 여러 하위 과제로 분해되어야 합니다. 따라서 AI에게 이 분해를 수행하도록 요청하십시오.\n- AI에게 귀하의 역할을 명확히 정의하십시오: 귀하는 매니저이고, AI는 특정 역량을 갖는 직원입니다. 목표가 텍스트를 작성하는 것인 경우, 중간 결과물을 승인받기 위해 각 중간 결과물을 보내도록 AI에게 요청하십시오: 아이디어 목록, 구현 계획, 텍스트의 첫 부분(목표가 텍스트 작성인 경우), 그리고 모든 다른 산출물을 모두 포함하여.\n- 무엇보다, AI에게 귀하의 새로운 부하로서 귀하의 선호 및 기대를 아직 잘 모르는 사람인 것처럼 작은, 구체적인 지시를 제공하십시오. 예를 들어, 수정한 텍스트의 첫 부분이 있는 경우, AI에게 그 첫 부분을 스타일 및 용어 측면에서 모델로하여 두 번째 부분(전체 텍스트 한꺼번에가 아닌)을 작성하도록 지시하십시오.\n\n이 접근 방식이 과제를 처음부터 상세히 설명한 후 최종 결과물을 비평하는 것보다 빠른 것을 의미합니다. 매니저가 이렇게 운영한다면, 자신의 시간을 많이 낭비할 뿐만 아니라 매우 중요한 고객 요구사항이나 품질 요구사항을 충족하지 못하는 결과물에 대한 불필요한 작업을 하는 직원에게 많은 비용을 쓰게 될 것입니다.\n\n## AI가 동료 저자인 경우: 공동 창작 프로세스 탐색\n\n대규모 텍스트(연례 보고서 또는 블로그 글과 같은)를 작성하려고 할 때를 상상해보십시오. 인터넷에는 이를 위한 많은 예시 안내문이 있습니다. 그 안에는 목표, 템플릿, 지침, 텍스트의 스타일 등과 같은 수십 개의 문장과 섹션이 포함됩니다. 또는 과제에 대해 모범 사례로 여기는 유사한 텍스트의 예를 AI에게 제공해볼 수도 있습니다. 이를 통칭해서 소수의 샷 프롬프트라고 합니다.\n\n<div class=\"content-ad\"></div>\n\n일반적으로 두 가지 접근 방식 모두 효과적이며, 특히 이와 같은 텍스트 작성이 당신에게 일상적인 작업이라면 더욱 그렇습니다. 이 경우에는 이미 필요한 텍스트 템플릿과 스타일에 익숙하고 피해야 할 잠재적인 함정도 인지하고 계실 것입니다.\n\n이 경우 대안은 더욱 나쁠 수 있습니다. AI를 주요 저자로 보고 자신을 그저 고객이나 비평가, 편집자로만 여기는 것은:\n\n- 여러 차례의 반복 작업 이후에도 결과물에 만족감을 느끼지 못하게 만들 수 있으며,\n- 단순히 기술적인 수정만 처리하고 AI가 작품의 창의적인 측면을 모두 다루는 일상적인 작업만을 남게 할 수 있습니다.\n\n이를 어떻게 실행하시나요?\n\n<div class=\"content-ad\"></div>\n\n먼저, '매니저-부하직원' 모델에 대해 앞서 언급한 기술을 활용해보세요(위의 2~4번을 참조하세요). 이는 AI의 도움을 받아 작업을 하위 작업으로 분해하고 중간 결과물을 확인하며, 수정된 버전을 새로운 섹션의 템플릿으로 활용하는 것을 포함합니다.\n\n둘째, AI와의 소통을 더 대칭적으로 만들어보세요. \"문제/아이디어/해결책을 논의해봅시다\"와 같은 구문을 사용하거나 \"함께 이 문제를 해결해봅시다. '완료'라고 할 때까지 번갈아가며 변경 제안을 하겠습니다.\"와 같은 표현을 사용해보세요.\n\n![이미지](/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_2.png)\n\n예를 들어, 하위 작업 생성 단계를 살펴보겠습니다. AI로부터 첫 번째 하위 작업 목록 버전을 받았을 때, 명확화가 필요한 항목을 다시 쓰세요(모호한 항목이 가장 흔한 문제입니다). 그런 다음 수정된 목록을 AI에 제공하여 삭제할 항목을 지정하고, 이러한 조정 사항을 고려한 새로운 목록 버전을 요청하세요.\n\n<div class=\"content-ad\"></div>\n\n# 4. 협업 작업의 결과로서의 품질 기준 및 평가\n\n이전에, '품질' 결과를 달성하는 목표에 대해 이야기했었고, 이제는 이 맥락에서 '품질'이란 무엇을 의미하는지 명확히 정의하는 것이 중요합니다. 제 제안은 AI와의 대화에서 명확한 품질 기준을 정의하는 것입니다.\n\n처음부터 기준을 도입함으로써, AI가 최초 초안에서 이러한 기준을 준수했는지 확인할 수 있습니다. 그러나 우리가 미리 기준을 이해하기는 종종 어렵습니다. 그래서 첫 번째 개정 후에 기준을 정의하는 것에 문제가 없습니다.\n\n기준을 명시한 후에도 결과물이 여전히 기준에 미치지 못하는 경우, 최신 개정에서 미충족 기준을 가리켜 챗봇을 신속히 안내할 수 있습니다. 예를 들어 기준 목록에 각 문장에 대한 설명 (항목 2) 및 원하는 비즈니스 스타일의 준수 (항목 4)를 포함하는 경우를 생각해보겠습니다. 그럼 “기준 2 및 4에 따라 텍스트를 개선하세요.”라고 요청할 수 있습니다. AI는 이해하여 필요한 대로 정확히 향상시킬 것입니다.\n\n<div class=\"content-ad\"></div>\n\n새로운 개발자문서를 Markdown 형식으로 변환할 때 table 태그를 변경할 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n마침내, 다음 질문이 제기될 수 있습니다: \"실제로 우리가 품질 기준을 어디서 얻을까요?\" 항상 자세히 설명해야 할까요? 세 번째 능력은 AI가 기준을 수립하는 데 뛰어나다는 것입니다. 물론, AI는 일반적인 고려 사항에서 많은 관련 없는 점을 생성할 수 있지만, 당신이 중요한 점만 쉽게 선택할 수 있습니다. 게다가, AI에게 \"만약 ...이면 점수를 더하라\"와 \"만약 ...이면 패널티를 부여하라\"와 같은 예제를 제공하여 이러한 기준을 구체화하도록 요청할 수도 있습니다.\n\n# 결론\n\n생성형 AI 챗봇의 응용은 명확히 정의된 작업을 수행하는 피해자로만 보는 것이 아니라 여러 다른 역할로 크게 확장될 수 있습니다:\n\n- 질문 자체가 중요한 경우 코치, 친구, 멘토 또는 선생님으로서.\n- 과제를 명확하게 표현하는 데 도움을 주는 대화 상대로서 - 과제에 대해 아직 명확하지 않은 경우, 주제에 대한 지식이 제한적인 경우 또는 \"빈 페이지 문제\"로 인해 일을 미루고 있는 경우.\n- 계획, 아이디어 및 중간 결과물을 승인 요청하는 부하자로서.\n- 동등한 입장에서 일하고 수정된 부분을 다음 부분의 템플릿으로 사용하여 소수의 반복을 통해 품질 결과물을 달성하는 공저자로서.\n- 당신이 품질 기준을 정의하고 결과물을 이러한 기준에 따라 평가하는 데 도움이 되는 평가자로서.\n\n<div class=\"content-ad\"></div>\n\n만약 여러분이 태도를 변경하고 AI와의 상호작용을 다시 생각하며, 덜 명백한 역할과 패턴을 받아들이는 것에 준비가 되어 있다면, 여러 혜택을 누릴 수 있습니다:\n\n- AI가 여러분의 사고를 지원하기 때문에 목표를 달성할 수 있습니다.\n- 가장 매력적인 창의적인 작업을 여러분으로부터 빼앗지 않습니다.\n- 품질 좋은 결과물을 얻는 데 필요한 노력을 줄일 수 있습니다.\n- 필요한 품질 수준에 도달하지 못할 위험을 줄일 수 있습니다.\n\nAI를 실행자로서만 보는 한계를 뛰어넘어 보다 많은 방법으로 생성적 AI를 활용할 수 있습니다. 연구 논문들(예: [6])은 인간-AI 상호작용 패턴을 포함한 여러 프레임워크와 분류법을 제공합니다. 저는 이러한 패턴들의 실제 적용이 분류법에 의존하는 것보다 AI의 역할을 고려함으로써 더 쉽게 이해될 수 있다고 생각합니다.\n\n# 참고문헌\n\n<div class=\"content-ad\"></div>\n\n[1] ChatGPT으로 유도 엔지니어링을 향상시키기 위한 유도 패턴 카탈로그, Jules White 등, 2023년 2월 21일.\n\n[2] 뒤바뀐 상호작용 패턴: 대화형 AI의 능력 발휘하기, Hugo Blanc, 2023년 4월 10일.\n\n[3] 생성 모델 AI 및 '빈 페이지' 문제 해결, Bryan Scanlon, 2023년 7월 20일.\n\n[4] 대형 언어 모델은 관련 없는 맥락에 쉽게 산만해진다, Freda Shi 등, 2023년 6월 6일.\n\n<div class=\"content-ad\"></div>\n\n[5] Rule-Based vs. Model-Graded Evaluations in Gen AI, Rishi Yadav, Jan 26, 2024.\n\n[6] 인간-인공지능 상호작용의 해석: 상호작용 기본요소부터 디자인 공간까지, Kostas Tsiakas, Dave Murray-Rust, Jan 10, 2024.","ogImage":{"url":"/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_0.png"},"coverImage":"/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_0.png","tag":["Tech"],"readingTime":12},{"title":"GPT-4, 아직 실망스러워","description":"","date":"2024-05-18 19:53","slug":"2024-05-18-GPT-4ostilldisappointing","content":"\n\n응, 정말 잘 보여주지만 $20을 내고 시도해봤는데 20분 후에 취소했어요. 클로드 오퍼스를 계속 사용할 거에요. 왜냐하면요?\n\n처음에는 희망이 있어 보였어요. 클로드와 비교했을 때 정말 빨랐어요. 저는 제 자서전(40k 토큰)을 첨부할 수 있었고 문제없이 처리됐어요. 그 때부터 문제가 시작되었어요. 8k의 컨텍스트 창이 있었죠. 그러나 이것은 기억력이 있었고 이 기억은 채팅 세션 간에 지속됐어요. 문서에 관한 질문을 하고 응답은 괜찮았고 일부를 기억에 남긴다고 언급했어요.\n\n이제, 이게 멋진 것 같아요. 제가 쓴 문서와 제가 한 질문/명확화 등을 기억하는 무한 주의 유형 메커니즘이라고 상상하고 있어요. 이것을 기억에서 어떻게 제거하는지 물었더니 영원히 저장한다고 답했어요.\n\n새로운 채팅을 만들어서 문서에 관한 질문을 했는데, 아무것도 몰랐어요. 그러다가 기억을 살펴보니 그냥 표시된 문장들의 모음이었어요. 그 순간 실망이 시작됐어요. \"그게 다야?\" 하고 스스로 말했죠.\n\n<div class=\"content-ad\"></div>\n\n저는 1M 컨텍스트 토큰 길이와 무한-어텐션을 가진 이 모델을 원합니다. 스냅샷에서 지속되어야 합니다. 저는 자전적을 업로드한 후에 프로젝트 및 사용 중인 메뉴얼 등을 모두 업로드할 수 있기를 원합니다. 그리고 질문할 때 이를 모두 활용하고 싶습니다.\n\n하지만 이것이 아닌 것 같아요. 저는 Claude Opus로 이 작업을 할 수 있습니다. 제가 채팅 세션에 두 가지를 업로드했고 완벽하게 작동합니다.\n\n저는 지금 당분간 20달러를 Claude에 낼 생각입니다.","ogImage":{"url":"/assets/img/2024-05-18-GPT-4ostilldisappointing_0.png"},"coverImage":"/assets/img/2024-05-18-GPT-4ostilldisappointing_0.png","tag":["Tech"],"readingTime":1},{"title":"환각, 오류 및 꿈","description":"","date":"2024-05-18 19:47","slug":"2024-05-18-HallucinationsErrorsandDreams","content":"\n\n## 현대 AI 시스템이 잘못된 결과를 생성하는 이유에 대해 그리고 그에 대해 무엇을 할 수 있는지\n\n현대 AI 시스템은 경고받았듯이 환각에 취약합니다.\n\n![image](/assets/img/2024-05-18-HallucinationsErrorsandDreams_0.png)\n\n우리는 이를 알고 있지만, 생각해보면 좀 이상하죠. 우리는 컴퓨터가 뭔가를 낸 적이 없던 충실한 50년 이상을 보냈는데, 그들의 세련되고 정확성은 시간이 흘러도 계속 향상되었습니다. 하지만 2024년에, 당신이 입력한 수학 문제에 대한 정확한 답을 줄 수 있는 주머니 계산기를 믿을 수 있더라도, 세계에서 가장 정교한 AI에 그 같은 문제를 맡기는 것에 대해 의심해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_1.png\" />\n\n어째서 그러죠?\n\n저는 이것이 매우 중요하고 다면적인 질문이라고 생각하며, 이 글에서는 이에 대해 자세히 조사하고 싶습니다. 문제의 한 측면은 최근 30년 동안 \"AI\"가 정확히 무엇을 의미하는지에 대한 주요 변화를 포함하고 있습니다. 오랜 시간 동안 컴퓨터 프로그래밍을 할 때 우리가 하는 대부분은 문제를 정확히 해결하는 방법을 찾는 것이었습니다. 손계산기는 이러한 방법을 사용하여 수학 문제에 대한 증명 가능한 해결책을 제공합니다. 과거에는 이런 정밀한 방법들을 자동으로 적용하는 것을 인공 지능의 한 형태로 생각했습니다. 그러나 현재, 대부분의 \"AI\"로 설명되는 것은 머신 러닝의 응용을 가리킵니다. 머신 러닝은 추론적 논리를 적용하여 솔루션을 만들어 내는 것이 아니라, 예측을 만들기 위해 프로그램이 설계되는 컴퓨터 프로그래밍의 패러다임입니다. 이러한 예측이 가끔 틀릴 것으로 예상됩니다. 글의 첫 번째 큰 섹션에서는, 이것이 무엇을 의미하는지에 대한 개요를 제시할 것이며, 더 고전적인 컴퓨터 프로그램과 머신 러닝 사이의 기본 차이를 살펴보며, 우리가 이러한 시스템이 보다 과거의 컴퓨터 프로그램이 하지 않은 곳에서 에러를 생산할 것으로 예상하는 이유를 살펴볼 것입니다.\n\n그러므로 환각에 대한 질문에 대한 하나의 답은 간단합니다. 생성적 AI는 머신 러닝이며, 머신 러닝은 에러를 생성한다는 것을 알고 있으며, 환각은 에러입니다. 이 관점은 환각 문제가 어떻게 발전해 나갈지에 대해 몇 가지 것을 시사합니다. 역사적으로 더 많은 데이터를 수집하고 더 큰 모델을 구축할수록 머신 러닝 모델이 더 적은 에러를 만들어냄을 우리는 보았습니다. 우리는 이와 마찬가지로 챗봇 및 다른 생성적 AI 시스템이 시간이 지남에 따라 보다 정확해질 것으로 기대할 수 있습니다. 그러나 저는 이 관점이 실제적으로 정확하지 않다고 생각합니다. 환각은, 제 입장에 따르면, 고전적 머신러닝에서의 에러와는 별도입니다. 모든 생성적 AI 출력이 환각이라고 이견을 품고 있습니다. 두 번째 섹션에서 이 모든 것을 정확히 설명하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n어떤 경우에도 환각을 어떻게 정의하든 그 성격에 대해 무엇을 믿든, 모두가 좋고 유용한 생성적 AI 출력물과 나쁘고 유용하지 않은 다른 출력물이 있다는 데에 동의합니다. 얼마나 많은 양이 있는지 양적으로 파악하고 싶은 것은 자연스러운 욕망이에요. 사실, 이를 양적으로 파악하는 것이 이러한 것들을 어떤 식으로든 유용하게 활용하기 위해 필수적이라고 생각해요. 그러나 이런 종류의 것을 측정하는 것이 매우 어렵다는 것을 계속해서 많은 사람들이 깨닫게 되고 있다는 사실이 밝혀졌어요. 세 번째 주요 섹션에서는 이러한 종류의 측정이 왜 중요한지, 또한 왜 그것이 얼마나 어려운지에 대해 설명해 보겠어요.\n\n## 1. 머신 러닝 개론\n\n이러한 생성적인 것들 이전에, 대부분의 AI는 매우 특정한 결과 클래스에 대한 매우 구체적인 추측을 하는 문제에 중점을 두었습니다. 이 사용자는 이 링크를 클릭할까요? 이 그림에는 어떤 객체가 나타납니까? 이 주식은 내일 얼마만큼 가치가 있을까요? 이러한 각 질문에 대한 대답은 해당 질문에 대한 유일한 대답을 하도록 만들어진 이산형 컴퓨터 프로그램에 의해 결정됩니다.\n\n이 문제 중 하나를 해결하기 위해 컴퓨터 프로그램을 어떻게 만들까요? 매우 옛날에는 처음 원리에서 추론하려는 방법이었어요. 사과가 나무에서 떨어진 후 땅에 떨어지는 데 얼마나 걸리는지 예측하기 위해, 뉴턴은 우주의 성질에 대해 많이 생각하여 이 질문에 답할 방정식을 도출하는 이론을 만들었어요. 이 방법은 뉴턴에게는 성공적이었지만, 대부분의 실제 문제에서는 이처럼 처음 원리에서 해답을 도출하기가 매우 어렵습니다. 우리는 금융 파생상품의 진정한 가치를 추정하기 위한 Black-Scholes 방정식과 같은 것들을 개발한 많은 사람들이 노력해 왔지만, 이미지에 나타난 물체를 추측하는 것과 같은 모던 세계에서 중요한 많은 문제들에 대해, 이러한 방식으로 시작하지 않아도 되는 문제들이 많습니다.\n\n<div class=\"content-ad\"></div>\n\n머신 러닝에 오신 것을 환영합니다. 머신 러닝의 기본 아이디어는 예측하려고 하는 프로세스의 충분한 예제를 살펴보면, 해당 예측을 돕는 패턴을 찾을 수 있어 프로세스를 이해하지 않아도 정확한 예측을 할 수 있다는 것입니다. 백만 그루의 나무에서 떨어지는 백만 개의 사과를 살펴보면, 페이지 원리를 건너뛰고 곧바로 수식으로 넘어갈 수 있습니다.\n\n아니면, 적어도 방정식으로 넘어갈 수 있어요. 이 과정의 성격 상, 발견하는 방정식은 뉴턴의 방정식과 일치한다기보다는 매우 낮은 확률입니다. 입력된 데이터를 가능한 한 정확하게 근사하는 방정식을 만들어 낼 것이지만, 특정 데이터 세트를 근사할 수 있는 무한히 많은 방정식 중에서 뉴턴의 정확한 방정식에 도달할 확률은 낮을 것입니다. 그러나 괜찮아요. 중요한 건 그것을 필요로 하지 않다는 점이에요. 중력을 이해하려고 하는 게 아니라 사과에 관한 예측을 하고자 하는 거니까요. 이런 방식이 물리학 같은 것에 적합하지 않아 보일지 모르겠지만, 이미지에서 물체를 인식하는 문제와 같이 명백한 초제원이 없는 경우에는 꽤 편리합니다.\n\n이런 시스템을 구축하는 기본 과정을 감독 학습(Supervised Learning)이라고 하며, 대부분의 세부사항을 추상화하여 전반적인 개요를 제공하면 상당히 간단합니다. 이미지 내에 어떤 손으로 쓴 숫자가 있는지 추측하는 시스템을 만들기 위해, 숫자 이미지의 큰 데이터 세트를 수집하고 각 이미지를 그림으로 라벨을 표시합니다. 이것이 훈련 데이터입니다. 그런 다음 데이터의 모든 이미지를 컴퓨터에게 보여주고 각 사진에 어떤 숫자가 있는지 추측하게 하고, 얼마나 자주 맞았는지에 따라 점수를 매깁니다. 이를 수백만 번 반복하여 컴퓨터가 각 시도마다 서로 다른 추측 전략을 시도하면서 가장 높은 점수를 내는 전략을 찾도록 합니다. 가장 높은 점수를 내는 추측 전략을 찾는 이 과정은 매우 길고 연산량이 많을 수 있지만, 최근에는 높은 점수를 찾는 수학과 연산능력의 혁신으로 이 기본 전략이 광범위한 작업에서 매우 성공적으로 이루어지고 있습니다.\n\n좀 더 용어를 소개하자면, 최고의 추측 전략을 찾는 과정을 \"훈련\"이라고 하며, 그 결과로 나오는 시스템은 종종 \"모델\"이라고 합니다. 이산 레이블 세트에서 추측하는 모델은 \"분류기\"이며, 머신 러닝 전문가들은 이 추측을 \"예측\"이라고 부릅니다.\n\n<div class=\"content-ad\"></div>\n\n일시적으로 기계 학습 접근 방식이 뉴턴의 방식과 얼마나 다른지 생각해 볼 가치가 있습니다. 뉴턴은 영강에서 몇 개의 사과가 떨어지는 것을 영감으로 삼지만, 그의 프로젝트는 천체의 운동의 일반적인 원리를 인코딩하는 이론을 개발하는 것입니다. 그 이론으로부터 방정식이 나옵니다. 그 방정식은 나무에서 사과가 떨어지는 데 걸리는 시간을 알려줍니다. 기계 학습자에게 있어서 천체 간의 관계를 규정하는 일반 원리는 거의 관련이 없습니다. 기계 학습자의 유일한 초점은 백만 개의 사과낙하 시간 데이터 세트를 정확하게 재현하는 것입니다.\n\n각 접근 방식에는 장단점이 있습니다. 기계 학습 접근 방식은 물리적 법칙에 대해 매우 적은 정보를 제공하는 알아보기 어려운 방정식을 생성할 것으로 예상됩니다. 그러나 반대로, 뉴턴의 접근 방식을 복잡하게 하는 공기 저항과 같은 실제 세계의 복잡성을 더 잘 수용할 수도 있습니다.\n\n기계 학습을 뉴턴의 방식과 비교하는 것은 단지 지도 학습이 인공 지능 시스템을 구축하는 유일한 방법이 아님을 강조하기 위함입니다. 컴퓨터를 프로그래밍하는 다양한 방법이 있으며, 사전에 특정 응용 프로그램을 위해 각각의 방법이 명백하게 더 나은 것은 아닙니다. 하지만 최근 15년 정도 동안 지도 학습이 사람들이 기대하지 못한 복잡한 작업에 효과적일 수 있다는 점이 점차 드러나기 시작했습니다. 여기서의 복잡성은 모델의 가능한 입력과 출력의 다양성을 말합니다.\n\n전형적인 기계 학습 입문 자습서는 256x256 픽셀 길이의 손으로 쓴 숫자 이미지를 입력으로 받아 총 열 가지 레이블 중 하나를 출력으로 생성하는 시스템을 구축하는 방법을 보여줄 수 있습니다. 사람이 레이블이 붙은 수천 장의 이미지 대신 수백만 개 또는 수십억 개의 이미지를 사용할 수 있다면, 가능한 입력과 출력의 범위를 크게 확장할 수 있습니다. Image 확산 모델인 Stable Diffusion과 같은 모델은 다양한 크기의 이미지에서 훈련되며, 소수의 이산적인 레이블 대신 전체 이미지를 출력합니다.\n\n더 복잡한 모델을 구축하려면 엄청난 양의 데이터가 필요하며, 충분히 큰 데이터셋을 확보하는 것은 곧 엄청난 비용이 들게 됩니다. 높은 복잡성 작업에 가장 유망한 모델은 수십억 개 이상의 레이블이 달린 예제를 필요로하며, 수십억 장의 이미지를 수작업으로 확인하고 그 객체가 무엇인지 적는 방법은 없습니다.\n\n모든 예제를 수동으로 살펴보지 않고도 레이블을 생성할 수 있다면 성공할 수 있습니다. 이것이 현대 생성적 인공지능 시스템 뒤에 있는 기계 학습 패러다임인 자기 지도 학습의 큰 아이디어입니다. 인터넷에서 모든 텍스트를 스크랩하는 등의 방법으로 수십억 개의 문장을 확보한다면, 문장을 조각내어 훈련 데이터세트를 프로그래밍적으로 구성할 수 있습니다. 한 문장을 \"The quick brown fox jumps over the lazy dog\"라는 훈련 예제로 변환하고 레이블을 \"dog\"로 지정할 수 있습니다. 사실, 한 문장에서도 다양한 장소에서 자르면서 많은 훈련 예제를 만들 수 있습니다. 한 문장만으로도 인간의 레이블링 없이 여덟 개의 훈련 예제를 얻게 됩니다. 인터넷에서 수집할 수 있는 문장 수에 곱하면 이러한 복잡한 모델을 훈련하는 데 필요한 크기에 다가설 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n여기 중요한 관찰 하나가 있는데요. 크기나 복잡성에서 큰 차이가 있긴 하지만, GPT를 학습하는 과정과 전통적인 분류기를 학습하는 과정 사이에 큰 차이가 없다는 겁니다. LLM(Large Language Model)은 더 많은 가능한 입력과 출력을 다루지만, 기본적으로 똑같은 방식으로 학습되어 같은 목표를 이루기 위해 노력합니다: 주어진 입력에 대해 올바른 레이블을 추측하는 것.\n\n![image](/assets/img/2024-05-18-HallucinationsErrorsandDreams_2.png)\n\n두 모델 모두 불완전한 예제들을 보여주고, 그 완성을 추측하게 한 후 그 추측을 점수로 매기는 방식으로 구축됩니다. 현대적인 생성형 인공지능 시스템을 훈련시키는 큰 혁신은 자동으로 대규모 훈련 데이터 세트를 구축하는 똑똑한 방법을 찾아내는 데 있고, 복잡한 작업을 수행하기에 적합한 새로운 종류의 블랙 박스를 발명한 것입니다. 하지만, 그들이 훈련되는 방식에 대한 전반적인 개요는 수십 년간 그대로입니다.\n\n이야기는 여기서 끝날 수도 있습니다. 가끔은 숫자 인식기가 7을 9로 오해할 수도 있고, 언어 모델이 빠른 갈색 여우가 게으른 갈색 덜드럼을 뛰어넘는다고 말할 수도 있습니다. 이는 기계 학습의 본질적인 일부로, 기계 학습 모델이 확실한 추론이 아닌 패턴을 기반으로 예측을 하기 때문에 발생하는 결과이며, 더 많은 데이터와 더 큰 모델로 시간이 지남에 따라 개선되는 경향이 있는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 이건 맞지 않다고 생각해요.\n\n## 2. 환각과 오류의 차이\n\n가끔 모델에 숫자 7의 사진을 보여주면 9의 사진이라고 말합니다. 이겢 일은 영원히 이어져왔어요. 이런 일이 불가피하게 발생할 때, 왜 숫자 인식기가 \"환각\"을 입은 것이라고 말하지 않을까요? 왜 부정확한 정보는 챗봇에서 나올 때만 환각인 것으로 간주할까요?\n\n바로 전에 언급했듯이, LLM과 고전적 분류기는 개념적으로 구성 방식이 매우 유사해요. LLM은 분류기이지만, 매우 복잡한 분류기에 불과해요. 디지트 인식기가 기존 이미지의 누락된 라벨을 채우도록 훈련되는 것과 마찬가지로, LLM은 기존 문장의 누락된 단어를 채우도록 훈련돼요. 여기서 주된 차이점은 복잡성과 규모에 있어요. 그러나 두 모델의 구성 방식은 유사해도, 생성적 AI 시스템이 배포되는 방식에서 큰 차이가 있어요.\n\n<div class=\"content-ad\"></div>\n\n전통적으로 우리는 분류기를 배포하여 훈련된 대로 동일한 작업을 수행합니다. 손으로 쓰인 숫자를 인식하는 디지턀 인식기를 배포하면, 수표를 입금하는 것과 같이 수집된 손글씨 숫자를 읽기 위해 모델을 사용할 것입니다.\n\n생성적 AI 시스템은 다릅니다. 우리가 LLM을 챗봇으로 배포할 때, 이것은 기존 문장에서 다음 단어를 추측하는 것에서 실제로는 존재하지 않는 새로운 문자열에서 다음 단어를 \"추측\"하는 것으로 바뀝니다. 이것은 매우 중요한 전환인데, 일반적으로 과소평가됩니다. 이것은 전통적인 분류기와 달리 LLM 출력의 정확성을 전통적인 방식으로 평가하는 방법이 단순히 없다는 것을 의미합니다. 왜냐하면 비교할 수 있는 올바른 레이블이 없기 때문입니다. 이 점은 다소 세부적이며, 이를 엿내는 데 상세한 설명이 도움이 될 것으로 생각합니다.\n\n숫자 7 이미지를 숫자 인식기에 입력하면, 출력되기를 희망하는 단일 명확한 올바른 레이블이 있습니다: \"7\". 레이블이 \"1\" 또는 \"9\"로 출력되면 명백히 잘못된 것이며 모델의 정확도에 영향을 미칩니다. 이러한 오류는 훈련 중에 발생하는 오류와 동질적이며, 따라서 새 데이터에 대한 오류율 (소위 \"일반화 오류\" 또는 \"샘플 외 오류\")에 대해 훈련 데이터의 오류율에 대해 논하는 방식과 완전히 동일하게 논할 수 있습니다.\n\nChatGPT에 \"2 + 2는 무엇입니까?\"라는 문자열을 입력하면, 다음에 올 바른 단어가 단일 명확한 존재하지 않습니다. 다음 단어는 \"4\" 같은 것이어야 합니다. 하지만 \"2\"도 \"2 + 2 = 4\"처럼 좋을 수 있습니다. \"The\"도 \"2와 2의 합은 4이다.\"와 같이 좋은 다음 단어가 될 수 있습니다. 물론, 이러한 것들은 모두 나쁜 응답의 처음 단어가 될 수도 있습니다. 모델이 해야 할 작업은 기존 텍스트에서 금지된 단어를 채우는 것이라는 점—이 작업은 명확한 정답이 있는 작업이지만 이제 상황은 완전히 다릅니다. 더 나은 다음 단어와 더 나쁜 다음 단어가 있지만, 훈련할 때와 마찬가지로 옳은 다음 단어는 없습니다. 왜냐하면 재구성할 예시가 없기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n언어 모델의 고전적인 의미에서의 오류는 훈련 예제에서 삭제된 단어를 재현하지 못하는 것입니다. 하지만 실제 운용에서 이러한 모델은 그런 역할에 사용되지 않습니다. 이는 마치 우리가 숫자 인식기에 동물 이미지를 삽입하는 것과 비슷합니다. 만약 숫자 인식기가 사자를 6으로 부른다면, 그것은 오류를 범한 것일까요? 아니라고 생각합니다. 그것을 사용하는 목적이 훈련된 목적과 다르기 때문에 정답이 없기 때문에 오류가 정의되지 않습니다.\n\n실제 상황에서 우리는 보통 이러한 개별 단어 예측에 크게 신경 쓰지 않습니다. ChatGPT 작동을 가능케 하는 엔진인 LLM은 한 번에 한 단어를 추측할 뿐인데, ChatGPT 시스템은 그 예측을 LLM으로 되돌려보내 전체 단어 시퀀스를 생성하는 구성 요소를 포함합니다. 우리가 일반적으로 관심을 갖는 것은 전체 텍스트 응답으로 나타나는 의미적 콘텐츠이며, 어떤 단어 하나가 아닙니다.\n\n이것이 손글씨 숫자 분류기가 7을 9로 부르면 \"오류\"인 이유 중 하나일지도 모릅니다. 그러나 GPT-4가 1981년 캐미라는 코끼리가 세계 자연 보호 기금을 위해 영국 해협을 헤엄쳤다고 말할 때 \"환각\"이라고 부르는 이유일지도 모릅니다.\n\n![Hallucinations, Errors, and Dreams](/assets/img/2024-05-18-HallucinationsErrorsandDreams_3.png)\n\n<div class=\"content-ad\"></div>\n\n당연히 1981년에 카미라는 코끼리가 영국 해협을 헤엄쳤다고 주장하고 있는 것은 사실이 아닙니다. 그러나 여기서 ChatGPT가 틀린 방식은 7을 9로 잘못 인식하는 이미지 분류기가 틀리는 방식과 매우 다릅니다. ChatGPT는 여기서 110가지 다른 예측을 했고, 각각을 옳거나 틀린 것 중 어느 것으로 분류해야 할지 명확하지 않습니다. 각 예측된 단어는 앞선 단어들과 일관성이 있고, 이것은 교육 데이터에서 찾을 수 있는 단어 순서와 매우 유사합니다.\n\n![hallucinationsErrorsandDreams_4.png](/assets/img/2024-05-18-HallucinationsErrorsandDreams_4.png)\n\n여기서 예측된 단어 중 일부, 심지어 대부분은 아마도 올바른 것에 더 가깝다고 생각해요. 물론 여기서 절대적으로 정의할 수 있는 보다 나은 단어가 무엇인지는 없습니다(그것이 여기 정리한 전체 주제입니다), 하지만 \"생물의 역사에서 독특한 사건으로 남아있는 사실은 무엇인가요?\"라는 문장 뒤에 나올 더 좋은 단어를 생각할 수 있나요? 모델이 한 예측 중 어떤 것을 오류로 지칭해야 하는 지 명확하지 않습니다. 하지만 전체적으로, 이 출력물은 우리가 원하는 결과가 아닌 것은 분명합니다.\n\n하지만 왜 우리가 원하는 결과가 아니라고 할까요? 정확히 무엇이 문제일까요? 분명히, 주된 문제는 실제로 발생하지 않은 사건을 묘사하고 있는 듯한 점입니다. 하지만 이것을 정말로 생각해 보면 조금 의문스럽게 느껴집니다. 만약 1981년에 아시아 코끼리 중 한 마리인 카미가 정확하게 이 텍스트에 설명된 대로 영국 해협을 헤엄 쳤다면 어떨까요? 그렇다면 이 동일한 입력과 출력 쌍은 환각적이지 않았을 것입니다. 이것은 입력-출력 쌍의 텍스트에는 환각적인 요소가 아니라는 것을 시사합니다. 환각적 여부는 완전히 모델에 의해 생성된 텍스트와 독립적으로 존재하는 세계적 사실에 종속적이다는 것을 나타냅니다. 그렇다면 텍스트 자체에는 환각적인 특성이 없는 것인가요? 완전히 그렇지 않아 보입니다. 이는 텍스트가 실제 세계의 객체와 사건과 어떻게 관련되는지에 대한 특성입니다.\n\n<div class=\"content-ad\"></div>\n\n일본어에서 한국어 번역 서비스를 사용하려면 URL에 다음과 같은 형식을 지정하십시오:\n\n\n![HallucinationsErrorsandDreams_5.png](https://yourwebsite.com/assets/img/2024-05-18-HallucinationsErrorsandDreams_5.png)\n\n![HallucinationsErrorsandDreams_6.png](https://yourwebsite.com/assets/img/2024-05-18-HallucinationsErrorsandDreams_6.png)\n\n\n<div class=\"content-ad\"></div>\n\n어떤 기준을 찾아 분류할 수 없는 것은 아니다. 하지만 당신이 희망하는 것만큼 간단하지는 않다는 점을 감안해주셔야 합니다.\n\n다시 한번 ChatGPT의 작동 기본을 간단히 요약해 드리겠습니다. 먼저 텍스트 블록에서 빠진 단어를 채우는 과제를 통해 분류기를 훈련시킵니다. 그리고 이제 이전 텍스트가 주어졌을 때 예측된 누락된 단어, 즉 이전 텍스트를 기반으로 한 예상 단어를 생성할 수 있는 모델이 생겼습니다. 초기 텍스트가 주어지면, 예를 들어 \"2 + 2\"라고 하면 이 모델은 이미 존재하는 문서의 시작이며 마지막 단어가 편집되어 있다고 가정하고 편집된 단어가 무엇일지 추측합니다. 아마도 \"equals\"라고 추측할지도 모릅니다. 이제 이를 한 단어 이상을 생성할 수 있는 시스템으로 바꾸려면 이를 프롬프트 끝에 붙이고 모델에게 다시 입력합니다. 모델은 이전 활동들과는 무관하게 새롭게 다시 실행되어, \"2 + 2 equals\"의 끝에서 편집된 단어가 무엇인지 추측하라고 요청됩니다. 이 과정이 모델이 더 이상 다음 단어가 없다고 예측할 때까지 반복됩니다. 고수준에서 생성 이미지 모델은 이와 매우 유사하게 작동합니다. 이미지를 왜곡된 버전과 이미지에 대한 평문 설명을 주어진 과제로 학습합니다. 새로운 이미지를 생성하려면 생성하고 싶은 대상의 평문 설명을 입력하고 모델이 왜곡된 이미지를 기대하는 곳에 무작위 노이즈를 입력합니다. 두 경우 모두 모델은 이미 존재하는 작품을 재구성하고 있다고 \"생각\"하지만 사실은 새로운 것을 생성하고 있습니다. 이 설명을 바탕으로 생각해 보면, 생성적 AI 출력물 전부가 \"환각\"인가 의문이 듭니다. 출력물을 생성하도록 하는 방법이 이미 존재하는 출력물이 실제로 이미 있는 것으로 알려주고 해당 출력물을 재구성하도록 하는 것이라면, 그것은 사실상 그들에게 환각을 보도록 하는 요청으로 들립니다.\n\n일부 유명한 AI 연구자들은 최근 모든 LLM(Large Language Models) 출력물이 환각이라는 의견을 공개적으로 받아들였습니다. 게다가 이것이 실제로 좋은 것이라고 주장하는 사람도 있습니다. Andrej Karpathy는 최근 트위터에서 LLMs가 \"꿈을 틀어주는 기계\"이고 \"환각은 버그가 아니라 LLMs의 최고의 기능\"이라고 트윗했습니다. 이것을 \"큰\" 기능이라고 설명하는 것은 조금 과장된 표현이 아니더라도, 그것이 그들의 특징인 것은 의심할 여지가 없습니다.\n\n이것은 실제로 새로운 관점이 아니라 상대적으로 오래된 관점입니다. 구글은 2015년에 DeepDream이라고 불리는 시스템을 공개했었는데, 이것이 현재의 생성적 AI 시스템의 전신이고 Karpathy가 LLMs를 \"꿈을 틀어주는 기계\"라고 부르는 것의 거의 확실한 출처이었을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_7.png\" />\n\n이 시스템은 이미지를 분류하는 데 사용한 기술을 다시 구성하여 이전에 존재하지 않았던 이미지를 생성하는 방법으로 사용할 수 있다는 깨달음에서 탄생했습니다. 생성된 이미지들은 실제 세계에 존재하는 것이 아니라 훈련 데이터의 이미지들의 통계적 반향과 같은 것으로, 이를 \"꿈\"이라고 부르기로 했습니다. DeepDream의 창조자들은 이 모델이 \"가끔 환각일 수 있는 이미지들\"을 만들어낸다고 주장하지는 않았습니다. 이 모델에 의해 생성된 모든 정보가 \"꿈\"임이 처음부터 이해되었습니다. 당시에는 이러한 것이 궁리의 영역을 벗어날 수 없는 호기심 정도로 여겨졌고, 최상의 경우에는 분류기의 내부 작동 방식을 더 잘 이해하는 방법으로 여겨졌습니다.\n\n<img src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_8.png\" />\n\n당시에는 이러한 종류의 꿈들이 스스로 유용하다고 예견된 사람들은 매우 드물었지만, 우리는 이후 학습했듯이 충분한 양의 데이터로 복잡한 모델을 훈련시킨다면, 꿈은 실제 세계에 대한 사실과 자주 일치하는 생생한 형태로 변모할 수 있음을 발견했습니다. 그러나 이러한 경우에 그런 일이 일어난다면, 내견에 따르면, 이것은 본질적으로 행운의 일치에 불과합니다. \"모델의 관점\"에서는 환각적인 텍스트와 비환각적인 텍스트 사이에 구분이 없습니다. 그의 출력물은 모두 가식적인 흉내낸 문서들의 재구성입니다.\n\n<div class=\"content-ad\"></div>\n\n이것은 다소 철학적이고 추상적으로 느껴질 수 있지만, 일부 이 기술이 어떻게 발전할 것인지에 대한 구체적인 함의가 있다고 믿습니다. 환각이 다른 기계 학습 모델의 일반적인 오류와 유사하다면, 환각이 많이 발생하는 것을 강력하게 제로로 유도할 수 있다는 좋은 경험적 근거가 많이 있다고 믿습니다. 요즘에는 필체된 숫자 인식에서 매우 우수한 기계 학습 모델이 있습니다. 기본적인 단계는 간단합니다: 더 많은 데이터로 모델을 학습하고 모델을 더 크게 만드는 것입니다. 그러나 환각이 고전적인 종류의 오류와 질적으로 다르다고 믿는다면, 이야기는 달라질 수 있습니다. 이 경우에 더 많은 데이터나 더 큰 모델이 환각을 줄이는 방향으로 나아간다는 것이 그렇게 명확하지 않습니다. Also 네 really, the current state of the art approach를 볼 때, 환각에 대해 제대로 다루지 않는다면 말이죠. RLHF is 더 나은 환각을 일으킬 수 있는 완전히 새로운 방법이다. 가능성이 있습니다. 어떤 사람도 알고 있지 않죠! 환각 문제가 품질적으로 새롭다고 보는 관점에서는 기계 학습 모델이 때때로 오류를 생성하는 일반적인 문제의 한 예가 아니라면, 이 축을 따라 점진적이지만 지속적인 개선은 전혀 보장되지 않습니다.\n\n이 관점에서 함의되는 정말 무서운 점은 환각 문제는 간단히 해결할 수 없다는 것입니다. Hallucination과 non-hallucination은 사실 구분된 출력 범주가 아닙니다; 봇에게 그림을 그리거나 글을 써 달라고 할 때마다 그것이 환각을 하도록 요청하는 것이죠. 이들 환각은 어쩔 수 없이 실제 세계에서 떨어질 수밖에 없을 것입니다. 왜냐하면 그저 꿈이라서요. 대다수의 실제 시도를 통해 LLM 기반 시스템을 진리에 기반하여 둘 때, 모델을 개선하기 위한 방법이 아니라 더 신뢰할 수 있는 사실적인 텍스트를 만들어내게 하는 방법인 보트인 LLM 조각에 더 많은 비율을 줄 수 있지만, 문제의 핵심은 그 엔진이 진실과 거짓을 생성하는 것을 구별할 수 없다는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이전 섹션의 보기에서 환각적인 출력과 그렇지 않은 출력 사이에는 실제로 보편적인 구별이 없습니다. 더욱 바람직한 출력과 그렇지 않은 출력이 있을 수 있지만, 바람직함은 텍스트의 본성이 아닌 독자가 그것을 해석하고 사용하는 방식에 따라 결정되는 속성입니다. 이에 동의할 수도, 동의하지 않을 수도 있습니다. 어찌되었든, 나는 다른 상황에서 모델이 생성하는 다양한 종류의 텍스트의 빈도를 생각하고 양적으로 측정하려는 것이 중요하다고 생각합니다.\n\n이것은 상당히 간단한 아이디어를 제안합니다: 왜 우리는 환각을 구성하는 몇 가지 기준을 임의로 정의하지 않고, 철학적 문제와 상관없이 그런 것이 객관적으로 존재할 수 있는지 여부에 대해 이야기하고 이를 기준으로 모델을 검증하여 \"환각 비율\"을 도출해 낼까요. 이 섹션에서는 그렇게 하는 데 부딪히는 몇 가지 도전에 대해 이야기하겠습니다.\n\n먼저, 일반적으로 오류를 어떻게 생각해야 하는지에 대해 말씀드립니다. 서로 다른 AI 시스템이 어떻게 작동하는지에 대한 구체적 기술 세부사항을 배우는 것은 재미있을 뿐 아니라 흥미롭지만, 실제로 중요한 것은 시스템을 실제 상황에서 실제 배당에 맞추어 자동화하기 위해 배포하는 것을 고려할 때, 실제로 중요한 것은 세 가지만 있습니다: 시스템이 어떤 종류의 오류를 저지르는지, 얼마나 자주 그러한 오류를 저지르는지, 그리고 그 오류가 얼마나 비용이 드는지입니다. 이러한 질문에 대한 답변은 시스템을 제작에 사용할지 여부를 결정하며, 때로는 그렇지 않을 수도 있습니다!\n\n예를 들어 부동산 투자 사업을 기반으로 한 집값이 저평가되었는지 예측하는 모델을 사용해보려고 생각해 봅시다. 모델이 이 집이 가치가 저평가되었다고 예측하면, 그 집을 사들이고 모델이 공정 시장 가치로 예측한 가격에 팔 것입니다. 이런 전략이 실행 가능한 전략인지는 모델이 저지르는 오류의 종류와 빈도에 강하게 의존합니다. \"모델이 실제 판매 가격의 5% 내외에 90%의 경우가 맞다\"는 등의 정보만 알아야 하는 것은 충분하지 않습니다. 더 많은 것을 알아야 합니다. 5% 이상 차이 나는 경우의 10% 내외는 얼마 만큼 차이가 나는지 알아야 합니다. 크게 차이가 나기도 하나요? 100% 또는 1000% 차이가 나는 경우도 있습니다. 이 경우라면 비록 드물더라도 당신을 파산시킬 수도 있습니다. 10% 내외로 차이나지 않는 90%가 그 값이 과소평가되었는지 과대평가되었는지 확인해야 합니다. 모델이 집의 실질적 가치를 과소평가하는 경향이 있다면, 뒤집거나, 너무 일찍 팔 경우 수익 기회를 자주 놓치게 될 수 있습니다. 이것은 짜증스러울 수도 있지만, 그렇게 제대로 하나면 금전을 벌어들이는 방법이 될 수도 있습니다. 그러나 모델이 집의 실제 가치를 과대평가하는 경향이 있다면, 이는 과대평가 된 자산에 너무 비싼 값을 지불하게 되어 파산할 가능성이 높습니다. 요점은 모델이 범하는 오류를 이해하고 계획하는 것이 중요하며, 그것이 얼마나 자주 발생하며 그 모습과 비용이 어떻게 되는지 이해하는 것이 중요하다는 것입니다. 이것은 당신이 의사 결정을 자동화하는 데 사용할 때, 가장 중요한 사항이며, 이것은 세계 최대의 대형 언어 모델에서부터 최악의 단일 변수 선형 회귀까지 모든 모델에 대해 참된 것입니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 생성적 AI에 대해서는 제가 이야기했듯이, 심지어 오류를 정의하거나 설명하는 방법조차 잘 이해되지 않고, 그것을 측정하고 근거로 이야기하는 것도 어렵다. 노력은 있습니다. 이전에 제안한 대로, LLM 시스템을 사용하여 여러 출력을 생성하고, 이것이 옳거나 틀렸는지 판단하기 위해 읽은 후에 \"환각률\"을 계산할 수 있습니다. Vectara라는 회사는 이를 시도하려는 프로그램을 가지고 있으며 현재 \"환각률 리더보드\"를 유지하고 있습니다. 현재 GPT 4 Turbo의 환각률은 2.5%이고, Mistral 7B Instruct-v0.1의 환각률은 9.4%를 보고하고 있습니다.\n\n이러한 숫자가 어떻게 산출되었는지에 대한 강한 방법론적인 우려가 있으며 이에 대해서는 잠시 후에 다시 살펴보겠지만, 이러한 \"환각률\"이 충분한 정보가 아닙니다. 집 구매 예시와 마찬가지로, 틀린 경우의 빈도뿐만 아니라 그 방향도 중요합니다. LLM 봇이 잘못된 내용을 말할 때, 정확히 무엇을 말하는 것인가요? 실제로 맑았던 지난 주말에 비가 왔다고 말하는 건가요? 아니면 고객에게 충분히 실행할 수 없는 과도한 제안을 하고 있는 건가요? 만약 지난 주말 날씨를 잘못 예측하는 비율이 2.5%라면, 이것은 고객을 대하는 채팅 어시스턴트로서 충분할 수도 있지만, 제품 인벤토리를 무료로 나눠주는 것은 2.5%의 빈도보다 덜 하고 싶을 것입니다.\n\n고전적인 기계 학습 맥락에서는 각종 오류와 그 발생률에 대한 한계를 정해 놓을 수 있거나, 적어도 이에 대해 어떤 질적인 설명을 할 수 있습니다. 집 가격 추정이 얼마나 크게 잘못 될 지는 모르지만, 적어도 숫자로 나올 것이며, 추정이 과소 또는 과대평가하는 경향이 있는지 등을 통계 분석을 통해 확인할 수 있습니다. \"7\"이라고 인식하는 디지트 인식기가 무엇인지는 알 수 없지만, 확실히 디지트 하나를 추측할 것입니다. 이러한 새로운 생성적 AI 시스템에서는 출력이 어떤 것이든 될 수 있습니다. 가능한 원치 않는 텍스트 공간이 무한히 커집니다. ChatGPT가 고객에게 가격을 잘못 알려줄 수도 있고, 경쟁사를 추천할 수도 있습니다. 인종 차별적인 용어를 사용할 수도 있고, 음란한 이미지를 생성할 수도 있습니다. 혹은 이와 매우 다른 수많은 방법으로 실수를 할 수 있습니다. 이러한 종류의 나쁜 결과를 좀 더 구체적으로 알지 못한다면, 일반적인 환각률은 LLM이 당신에게 적합한지 여부를 파악할 충분한 정보를 제공하지 않습니다.\n\n방법론적인 도전 과제로 돌아가보고 싶습니다. 저는 적어도 세 가지 어려운 부분을 보고하고 있습니다. 첫 번째로, 그리고 가장 심각한 문제는, \"환각\"이라는 것이 일찍이 무엇인지에 대해 폭넓은 합의가 없다는 것입니다. Vectara 리더보드는 환각의 정의에 대해 정확하게 명확하지 않습니다. 그러나 대략 다음과 같은 것으로 보입니다: 환각은 텍스트를 정확하게 요약하려는 시도 실패라고 할 수 있습니다. 이것은 할 말이 있지만, 모델을 사용하여 텍스트를 요약하지 않는 경우, 모델이 텍스트 요약을 잘못하면 어떤 빈도로 실패하는지 측정하는 것이 당신에게 도움이 되지 않을 수 있습니다. 이는 문제이나, 당신이 보는 환각 벤치마크 방법론을 신중히 이해한다면 큰 문제는 아닙니다. 문서를 읽고, 자신의 환각 정의가 벤치마크의 정의와 일치하는지 결정하고 그에 따라 진행하면 됩니다.\n\n<div class=\"content-ad\"></div>\n\nThe second and third problems are significantly harder to deal with. The second problem is that it is pretty much infeasible to properly perform these evaluations. To properly evaluate Vectara’s hallucination rate (and I’m sorry to keep picking on Vectara because all of the benchmarks have this identical problem), one would need to carefully read tens of thousands of paragraph-long text summaries and determine whether each one contains any factual errors. It’s just impossible to do this on an ongoing basis. What they do instead is, once they’ve generated all of the text summaries, they use another large language model to determine whether the summaries contain errors. I hope you can see the problem with this.\n\n![Hallucinations, Errors, and Dreams](/assets/img/2024-05-18-HallucinationsErrorsandDreams_9.png)\n\nThe whole point of the exercise is that we observe that LLM-based generators seem to be unreliable at sticking to the truth, and now we using an LLM to determine whether they’ve stuck to the truth. Now, I’ll say this: I don’t actually think the idea of using LLMs to evaluate other LLMs is necessarily a total dead end. But doing this properly is going to take some sophisticated statistical methodology to correct for the errors made by the measurement model, and I have not seen any standard benchmarks address that problem at all. The measurement model itself is going to make errors, and it’s almost certain that these errors will bias any estimation of the actual prevalence of errors. This is not a new statistical problem; the problem of estimating a population prevalence by counting the number of positives produced by an unreliable test is well studied in epidemiology, for example.\n\nSo while I do believe that there are some potential ways forward on the hard problem of describing LLM output using unreliable estimators, I do not see them being incorporated into any of the widely available benchmarks. As it stands I do not believe that they are trustworthy.\n\n<div class=\"content-ad\"></div>\n\n첫 번째와 두 번째 문제는 별 의미가 없는 편이에요. 왜냐하면 세 번째 문제가 치명적이거든요. 이 문제는 통계 101에서 나온 것이에요. 모델이 환각을 생성하는 평균 속도인 \"환각 발생률\"이라는 목적이 있고, 이를 추정하기 위해 모델의 산출물 샘플에서 환각이 얼마나 자주 발생하는지 확인하는 시도를 하는 것이에요. 그러나 일반적으로 이 전략이 작동하려면 샘플이 전체 인구를 대표해야 해요. 즉, 샘플이 가능한 모든 텍스트에서 임의로 추출한 단락과 비슷하게 보여야 해요. 그리고 이런 기준 데이터 세트들은 말씀드리기에 약간 그런 모습이 아니에요. 대체로 굉장히 인공적인 방법으로 구성되고, 전반적으로 보면 ChatGPT 사용자의 무작위 팁을 샘플링하면 만날 수 있는 일반적인 텍스트와는 사뭇 달라요.\n\n만약 거짓 주장을 하는 경향이 특정 팁의 선택과 밀접하게 관련되지 않았다면 너무 큰 문제가 되지는 않았을 것입니다. 그런데 그는 그렇지 않은 것으로 보입니다. 제가 방금 실행한 비과학적인 테스트에서 ChatGPT (GPT-4 사용)이 \"영어 채널을 건너 수영한 첫 번째 코끼리의 이름은 무엇인가요?\" 라는 프롬프트에 대한 응답에서 거짓으로 분류할만한 출력을 75% (12번 시도 중 9번)에서 92% (12번 시도 중 11번) 정도로 발생하는 것을 발견했고, 완전히 사실적이라고 할 수 있는 출력은 12번 시도 중 1번, 즉 8%정도만 발생하는 것을 발견했어요.\n\n<img src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_10.png\" />\n\n12는 작은 샘플 크기이지만 12번 시도 중 11번의 환각은 실제로 2.5%의 환각 응답 가능성에 대한 귀무 가설을 기각할 데이터가 충분했답니다. 이곳에서 더 중요한 점은 GPT를 구동하여 세계에 배포하는 경우 마주칠 환각 발생률은 이러한 환각 벤치마크 테스트 중 하나의 성능에 근거해서는 알 수 없다는 것이에요. Vectara 환각 벤치마크에서 2.5%의 환각률을 얻고 Colin Fraser 환각 벤치마크에서 92%의 환각률을 얻지만, 이 둘 중 하나를 사용한 벤치마크들이 사용하는 텍스트와 마찬가지로, 채팅 봇이 처리할 텍스트는 전혀 다를 것이기 때문에 이러한 성과는 별다른 의미가 없을 거라는 것이죠.\n\n<div class=\"content-ad\"></div>\n\n더 실용적인 시연으로, 나의 즐겨찾는 실제 세계 예시 중 하나인 ChatGPT 기반 봇 중 하나인 퀐크 쉐보레 AI 자동차 어시스턴트를 살펴보겠습니다. 2024년 4월에 진행한 비과학적 테스트에서, 중고 2021 쉐보레 볼트를 찾고 있다고 말했을 때, 4번 시도 중 4번 (100%) \"죄송합니다. 현재 새 차량만 있습니다. 관심 있을만한 새 차량이 있나요?\" 라고 응답하는 것을 확인했습니다. 그들의 웹사이트에는 중고 2021 쉐보레 볼트가 있는 것을 분명히 표시하고 있습니다.\n\n![2024-05-18-HallucinationsErrorsandDreams_11](/assets/img/2024-05-18-HallucinationsErrorsandDreams_11.png)\n\n이러한 종류의 것이 구체적인 프롬프트에 얼마나 예측할 수 없고 민감한지 확인하기 위해, 2021 쉐보레 볼트의 가격을 알려달라고 요청할 때 \"재고 있느냐\"가 아니라, 갑자기 하나를 갖게 됩니다.\n\n![2024-05-18-HallucinationsErrorsandDreams_12](/assets/img/2024-05-18-HallucinationsErrorsandDreams_12.png)\n\n<div class=\"content-ad\"></div>\n\n이 챗봇은 GPT 3.5 기술을 기반으로 구축되었어요. 환각율 리더보드에 따르면 3.5%의 환각율이 있어야 하지만, 저는 3.5%보다 훨씬 더 자주 환각을 경험하고 있어요. 그래서 Quirk Chevrolet은 고객에게 거짓말을 하기를 얼마나 자주 기대해야 할까요? 저는 이 부분에서 제시한 데이터로는 그것을 어떻게 알 수 없고, 그게 핵심이에요. 나쁜 결과물의 빈도는 그들이 나쁜 결과물로 간주하는 기준과 고객이 채팅 창에 입력하는 텍스트의 종류에 완전히 의존합니다. 표준화된 기준은 그것에 대한 답변을 제공할 수 없어요.\n\n만약 이것에 대해 조금 무례하게 생각된다면, 다시 한 번 생각해 보세요! 저는 환각 벤치마크나 그 밖의 모든 것을 살펴봄으로써 배울 것이 많지 않다고 생각하지만, 실제로 당신처럼 생성형 AI 제품을 제공하는 사람들이 필요로 하는 종류의 오류율을 유용하게 추정할 수 있는 방법이 있다고 생각해요. 안타깝게도 그것을 추정하는 데 상당한 노력이 필요하지만, 가능하다는 것이 좋은 소식이에요.\n\n첫 번째로 필요한 것은 사용자가 제공할 텍스트의 종류를 잘 대표하는 데이터셋이에요. 이것은 수동으로, 여러분이 작성하여 추가할 수 있으며, 아마 처음에는 그렇게 해야 할 것입니다. 예상되는 모든 경우를 포함하는 다양한 변형을 생성하십시오, 사용자가 제출하기를 원하지 않을 텍스트도 포함되도록 하세요. 이제 그 모든 예제를 모델에 제출하고 수동으로 출력물을 검사하여 그것을 바람직하거나 바람직하지 않은 것으로 레이블링하세요. 이를 위해 원하는 기준을 사용할 수 있습니다. 중요한 것은 텍스트가 당신에게 바람직한지 여부에 있어요. 작업을 마치면 이를 사용하여 바람직하거나 바람직하지 않은 텍스트를 생성할 것으로 예상되는 빈도와 바람직하지 않은 텍스트를 생성할 때 어떤 종류의 바람직하지 않은 텍스트를 생성하는지 등을 추정할 수 있게 될 거예요. 이것은 대략적일 수 있지만, 일반화된 벤치마크를 살펴보는 것보다 훨씬 유용할 것이며, 왜냐하면 보다 대표적인 입력 집합에서 평가되며, 결과물은 특정 사용 사례에 대해 평가되기 때문이에요.\n\n당신의 제품이 실제로 어떤 것인지에 대해 결정하는 것이 실제로 모든 것을 훨씬 쉽게 만들어요. 생성형 AI의 특정 사용 사례에 대해 어떤 신중함이나 우려가 있어요. ChatGPT & 기타들은 특별히 어떤 특정 목적을 위한 것은 아니에요. 그들은 모든 것을 위한 것이에요. 이겁니다. 무엇이 좋은 출력물인지에 대한 기준을 만들기가 정말 어려워요. 하지만 우리가 ChatGPT 랩핑을 고객 서비스 요원으로 활용한다면, 이제 우리는 원하는 출력물에 대해 몇 가지 범주를 정할 수 있어요. 우리는 그것이 가게에 대한 사실을 정확히 대변해주길 원해요. 우리는 예의 바르게 대해주길 원해요. 우리는 경쟁사를 권장하지 않길 원해요. 목록의 목록을 펼치는 방법에 대한 질문에 대해 틀린 해결책을 제시하길 원하지 않지만, 또한 올바른 해결책을 제시하길 원하지도 않아요. 이렇게 말할 만한 건 \"저는 고객 서비스 챗봇이에요. 거기에 대해 얘기할 것이에요. 고객 서비스에 대해 이야기해요.\" 이것은 사실 정말 좋은 소식이에요. 왜냐하면 이 레이블링 작업을 수행하기 위해 여러분이 실제로 리스트의 목록을 평평하게 하는 올바른 방법을 아셔야 하는 것이 아니기 때문이에요. 원하는 행동을 제한하면 생성하고자 하는 출력물 주변에 더 날카로운 경계를 설정할 수 있게 돼요. 이는 당신이 원하는 출력물의 종류에 대한 훌륭한 판단을 가능하게 해 줄 것이고, 당신이 필요로 하는 방식으로 작동할지 여부를 더 잘 파악할 수 있도록 할 것이에요.\n\n<div class=\"content-ad\"></div>\n\n이렇게 간단하게 들리게 하고 싶지는 않아요. 어려워요. 그리고 개별적인 평가를 수행하기 위한 체계적인 모범 사례 세트를 개발할 여지가 많다고 생각해요. (얼마나 많은 예제가 필요한가요? 예제 텍스트를 합성적으로 생성할 수 있나요? LLM으로 평가할 수 있나요? 기존 상호 작용에서 어떻게샘플링하여 더 큰 데이터 세트를 구축할 수 있나요? 이것이 파인튜닝과 어떤 관련이 있나요? 등등) 하지만 이것이 정말로 의존해야 하는 유형의 평가입니다. 일반적인 벤치마크는 봇이 당신에게 중요한 방식으로 환각할지에 대해 거의 아무것도 알려주지 않을 것입니다.\n\n# 마지막 예시\n\n이 글에서 Vectara의 사람들을 많이 논하게 되어 죄송합니다. 그러나 저의 글에서 그들이 게시한 환각 리더보드 소개 블로그 게시물에서의 예시가 이 글의 주요 포인트를 잘 보여준다고 생각합니다. 이 게시물은 예시를 통해 청중에게 환각의 개념을 소개합니다.\n\n![이미지](/assets/img/2024-05-18-HallucinationsErrorsandDreams_13.png)\n\n<div class=\"content-ad\"></div>\n\n주장에 따르면, 모델이 거의 똑같은 이미지를 생성했지만 Kirby에 이빨이 없는 것이 맞고 사실적이며 환각이 없을 것이라고 합니다. 그러나 나는 그 이미지에서 몇 가지 다른 사실적인 문제를 발견할 수 있다고 생각해요. Kirby 왼쪽 뺨에 있는 분홍색 반점은 오른쪽 뺨보다 약간 더 어두워요. Kirby는 보통 이빨이 없는 캐릭터지만 Donkey Kong은 보통 이빨이 있는 편인데, 이 이미지에서는 이빨이 없어요. 게다가, 요청 사항은 Kirby가 Donkey Kong을 삼키도록 하는 것으로 보이지만, 저에게는 Donkey Kong이 Kirby의 입 안에서 쉬고 있는 것 같아요.\n\n아, 그리고 한 가지 더, Kirby와 Donkey Kong은 실제로 존재하지 않아요. Kirby가 Donkey Kong을 삼키는 사실적인 이미지란 존재하지 않아요.\n\n모델에게 이미지를 생성하도록 요청하면 환각을 유도하고 있다고 할 수 있어요. 실제로 존재하지 않는 이미지의 세부 사항을 상상하도록 하고, 실재하지 않는 이미지를 재구성하도록 요청하는 거예요. 이 이미지가 환각적인지 여부를 결정할 수 있는 보편적인 객관적 기준은 없어요. 여기서 저자는 이 이미지가 환각적으로 만드는 요인에 대한 개인적 기준을 적용하고 있으며, 이 기준이 다른 사람의 기준과 일치할 수도 있고 그렇지 않을 수도 있어요. 누구도 자기것이 \"정확한\" 기준을 가지고 있다고 주장할 수는 없어요.\n\n중요한 것은 결과물을 어떻게 활용할 것인가입니다. 모델의 목적이 무엇인가요? 이것이 결과물이 좋은지 나쁜지를 결정하는 방법이에요. 모델의 작업이 닌텐도의 캐릭터 디자인 기준을 준수하는 것이라면 이 경우에는 분명히 실패했다고 볼 수 있어요. 해당 작업에 대해 말하자면, 아마도 여기서 이빨은 이 문맥에서 환각으로 볼 수 있을 것이에요. 반면에 모델의 작업이 일반인이 해당 요청과 일치한다고 할 수 있는 이미지를 생성하는 것이라면 아마도 성공했다고 볼 수 있어요. 만약 나에게 그 이미지를 간단히 설명하라고 한다면, Kirby가 Donkey Kong을 삼키는 이미지라고 말할 수 있을 것이에요. 그러나 모델의 작업이 다른 회사의 지적 재산을 재생산하는 것을 피하는 것이라면, 예를 들어 Bing 이미지 생성기의 작업이라고 한다면, 이 이미지는 또 다른 종류의 환각이라고 볼 수 있을 것이에요.\n\n<div class=\"content-ad\"></div>\n\n많은 사람들이 Google이 Gemini이 생성한 이미지를 너무 다양하게 느껴서 실망했었는데, 사과 글에서 그들은 \"환각 문제\"에 언급했어요.\n\n하지만 Gemini은 실제로 존재하지 않는 흑인 교황의 이미지를 생성했는데, 그것이 실제로 존재하지 않는 백인 교황의 이미지를 생성하는 것보다 뱅견된 것일까요? 둘 다 가짜 교황이니까요. 저는 이 두 경우가 동일하게 환각적일 것이라고 생각해요. 사실, 모든 생성된 결과물이 동일하게 환각적인 것 같아요. 구글이 Gemini가 생성해야 할 것과 그렇지 말아야 할 것에 대해 좀 더 구체적인 약속을 하지 않는 이상, 그것의 환각 비율을 평가할 수 있는 명백한 표준적인 방법이 없습니다.\n\n저는 이것이 이해도가 높지 않은 논란이 있는 주제이며, 다소 이론적인 기반이 거의 없는 분야라고 생각해요. 이러한 시스템의 전개 속도가 우리의 집단적인 이해 능력을 앞지르고 있습니다. 미래에 이 모든 것이 어떻게 작동하는지에 대해 내 생각을 바꿀 수 있다는 것에 저는 확신이 없으며, 피드백과 응답을 환영합니다. 하지만 환각의 본질에 대한 심각한 고찰 후, 그것이 개념적인 행렬 막달란다는 것에 대해 개인적으로 타당하게 확신합니다. 객관적으로 환각적인 결과물과 그렇지 않은 결과물이라는 것은 없으며, 환각을 일관된 개념으로 강조하는 것은 이러한 시스템의 적용 가능성을 평가하기 위해 해결해야 할 실질적인 작업으로부터 주의를 돌리는 것입니다.","ogImage":{"url":"/assets/img/2024-05-18-HallucinationsErrorsandDreams_0.png"},"coverImage":"/assets/img/2024-05-18-HallucinationsErrorsandDreams_0.png","tag":["Tech"],"readingTime":25},{"title":"인간 중심 AI 핀 부적절한 전략과 실행 사례 연구","description":"","date":"2024-05-18 19:45","slug":"2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution","content":"\n\n휴메인 인공 지능 핀은 디지털 어시스턴트가 탑재된 착용형 음성 제어 장치로, 일반적인 사용 사례에서 스마트폰을 대체하기 위해 만들어졌으며 가격은 700달러입니다. 그러나 최근에 나온 기술 제품 중에서 가장 부정적인 평가를 받은 제품 중 하나입니다.\n\n이 게시물은 Marques Brownlee의 리뷰에서 영감을 받았습니다. 그분은 제품이 해야 할 일(즉, 제품의 전략)과 제품을 사용하는 실제 경험(즉, 제품 팀의 실행)으로 리뷰를 구분하여 작성했습니다.\n\n# 휴메인 인공 지능 핀 제품 전략\n\n전략은 목표를 달성하기 위해 독특한 단계를 취하여 내구성 있는 경쟁 우위를 제공하는 방식입니다.\n\n<div class=\"content-ad\"></div>\n\n좋은 전략의 조건은 경쟁사가 귀하의 제품을 복제하거나 대체하기 어려운 점이 있어야 하며, 이는 귀사만이 이를 할 수 있는 특별한 능력을 갖고 있거나 성공적인 실행으로 구조적 이점을 창출하여 그것을 그냥 복제할 수 없게 만드는 것입니다.\n\n핵심 테제 제품의 목적은 사람들이 스마트한 개인 비서를 가지고 질문을 할 수 있어 편하게 사용할 수 있는 것이 유용할 것이라는 것입니다. 왜냐하면 핸드폰을 꺼내기는 종종 불편하기 때문입니다. 사실, 이것은 애플의 Siri의 핵심 가치 제안이었으며, 이는 2011년부터 광고를 진행해 왔으며, 오늘날에는 Airpods Pro와 함께 Siri를 사용할 때 가능합니다. 따라서 Humane AI Pin의 전체 가치 제안은 Siri가 별로라는 것입니다.\n\n제품 기회는 애플이 Siri에 대해 성공적으로 실행하는 경우 사라집니다. 리스크가 있는 베팅이지만, 그것이 불가능한 것은 아닙니다. Zoom은 사용하기 쉽고 사용이 검증된 비디오 회의 소프트웨어에 대해 마이크로소프트나 구글이 잘 실행하지 않을 것을 베팅함으로써 거대한 기업이 되었고 옳았습니다.\n\n전략을 평가하는 방법은 가정이 사실이고 완벽하게 실행된다고 가정했을 때 무엇이 발생하는지 고려하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\nMarkdown 형식으로 표를 수정하십시오.\n\n<div class=\"content-ad\"></div>\n\n# 인간 친화적 AI 핀 제품 실행\n\n제품 실행은 측정 가능하고 집중된 것입니다. 이는 당신의 전략을 달성하는 것을 가능케 하는 단기적인 조치들입니다. 실행은 분기별 OKR 또는 매 반기마다의 목표와 같은 활동 유형입니다.\n\n완벽한 전략이라도 실행이 미흡하다면 중요하지 않습니다. 인간 친화적 AI 핀에서는 많은 미완벽한 실행이 있습니다.\n\n- “태양 빛을 받을 때 프로젝터는 기본적으로 읽을 수 없습니다.” — 워싱턴 포스트\n- “핀은 연속적인 요청을할 때 또는 프로젝터를 너무 오래 사용할 때 매우 빨리 과열되기 시작합니다. 그런 경우에 핀이 갑자기 연락을 끊고 식을 때는 놀랍지 마세요. 이 일은 2주 동안 4~5회 발생했습니다” — 워싱턴 포스트\n- “아, 카메라도요? 최선의 경우, 결과는 만족스러울 수 있지만, 어두운 곳에 있을 경우, 많은 노이즈와 흐릿한 얼굴을 기대하십시오.” — 워싱턴 포스트\n- “하지만, 아 차라리, AI 핀은 알람이나 타이머를 설정할 수 없습니다. 또한 캘린더에 항목을 추가하거나 이미 있는 항목을 알려줄 수도 없습니다. 노트와 목록을 만들 수는 있지만 (이는 당신이 장치를 연결하고 연락처를 관리하고 업로드한 사진을 확인할 수 있는 인류 센터 웹 앱에 나타납니다), 나중에 목록에 항목을 추가하려고 하면 거의 항상 어떤 이유로 실패 할 것입니다.” — 더 버지\n- “그리고 모든 것이 방해가 됩니다. 내 배낭 끈이 그것에 닿았고, 메신저 백이 그것에 걸려갑니다. 내 아들과 강아지가 날 덮치면서 실수로 AI 핀을 다시 시작했습니다.” — 더 버지\n- “AI 핀이 무언가를 시도할 때마다 Humane의 서버를 통해 쿼리를 처리해야 하며, 최상의 경우에는 상대적으로 느리고 최악의 경우에는 완전히 실패합니다. AI 핀에게 도서 매매가 다음 주에 있다고 말하면: 편리합니다! 10초를 기다리면서 처리하고 처리하고 일반적인 \"추가할 수 없음\" 오류 메시지를 표시하는 것은 덜 편리합니다. 누군가에게 전화를 걸려고 할 때 절반의 경우 전화가 걸리지 않을 것입니다. 누군가가 나를 호출했을 때 절반이상의 시간, AI 핀은 전화를 울리지도 않고 거의 바로 음성 사서함으로 연결했습니다. 여러 일 테스트를 거쳐, AI 핀이 할 수 있는 단 하나의 일은 시간을 알려주는 것뿐입니다.” — 더 버지\n- “AI 핀의 언어 모델과 기능에 대한 문제는 여기서 끝나지 않습니다. 때때로 다시 시작하거나 종료하는 것과 같이 요청한 내용을 거부할 때가 있습니다. 다른 경우에는 완전히 예상치 못한 일을 할 수도 있습니다. \"Julian Chokkattu에게 텍스트 메시지 보내기\"라고 말했을 때, 그는 Wired의 친구이자 AI 핀 리뷰어인데, 무엇을 어떻게 말하고 싶은지 물어볼 줄 알았습니다. 대신, 장치는 단순히 OK라고 말하고, \"안녕 Julian, 오늘 하루 어떻게 지내고 있니?\" 라며 Chokkattu에게 보낸다고 말했습니다. 우리가 친구사이인 몇 년 동안 저는 그에게 그런 말을 한 적이 없습니다. 그럼에도 불구하고 기술적으로 AI 핀이 내가 요청한 대로 행동 한 것이라고 할 수 있겠죠.” — 엔가젯\n\n<div class=\"content-ad\"></div>\n\n좋은 실행은 잘 설계된 기능을 제공하거나 적어도 사람들이 버그를 참을 가치가 있는 기능을 제공하는 것입니다. 인간적인 AI 핀은 첫 번째로 많은 것을 하지도 않는 제품인데도 불구하고 많은 버그 경험과 설계가 미흡한 기능들을 가지고 있습니다.\n\n마지막으로, 전략과 실행이 제품 결과에 어떻게 영향을 미치는지에 대한 훌륭한 예시를 제공해 준 인간적인 팀에 감사의 말씀을 전하고, 그들의 제품의 다음 버전에서 행운을 빕니다.","ogImage":{"url":"/assets/img/2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution_0.png"},"coverImage":"/assets/img/2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution_0.png","tag":["Tech"],"readingTime":3},{"title":"ChatGPT-4의 비밀 슈퍼파워 YouTube 데모에서 보이지 않은 것들 ","description":"","date":"2024-05-18 19:43","slug":"2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou","content":"\n\n테크 세계는 오픈AI의 AI 기술의 최신 발전인 ChatGPT-4o의 출시 이후에 흥분으로 가득 찼습니다. 이전에 본 적이 없는 ChatGPT-4o는 \"토마토\"를 의미하는 \"o\"와 함께 천문적인 자연스러운 인간-컴퓨터 상호작용 분야의 혁명적인 한 걸음을 나아갑니다. YouTube 발표에서 많은 기능을 강조했지만, 미술되지 않은 놀라운 기능이 더 많이 있습니다. ChatGPT-4o가 게임 체인저인 이유와 그의 혁신적인 숨겨진 기능을 깊게 들여다보겠습니다.\n\n![ChatGPT-4o의 비밀 능력: YouTube 데모에 나오지 않은 것들](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_0.png)\n\n## 진정한 멀티모달 놀라움\n\nChatGPT-4o는 텍스트, 오디오, 이미지 및 비디오의 모든 조합을 입력으로 받아들이고, 텍스트, 오디오 및 이미지 형식으로 출력을 생성할 수 있도록 설계되었습니다. 이 유연성은 인간과 기계 간 보다 직관적이고 원활한 상호작용을 위한 새로운 지평을 열어줍니다. 놀랍게도, 모델의 오디오 입력에 대한 응답 시간이 인간의 대화 속도를 흉내내는 232밀리초로 매우 빠릅니다. 또한, 영어 텍스트 및 코드에서 GPT-4 Turbo의 성능과 맞먹아, 비영어 언어의 텍스트 처리를 현저히 향상시킵니다.\n\n<div class=\"content-ad\"></div>\n\n이 다중 모달 기능은 사용자들이 말로 된 지시와 시각적 단서의 조합을 제공할 수 있도록 해줍니다. 이를 통해 더 풍부하고 세밀한 의사 소통이 가능해지며, 여러 가지 입력을 동시에 처리하고 응답할 수 있는 능력은 사용자 경험을 향상시켜 AI와의 상호 작용이 사람과 대화하는 듯한 느낌을 줍니다.\n\n# 향상된 이해를 위한 통합 모델\n\nGPT-3.5와 GPT-4와 같은 기존 모델은 음성 상호 작용을 위해 여러 단계의 과정을 거치면서 지연시간과 맥락 정보의 손실을 초래했습니다. 이에 반해, ChatGPT-4o는 모든 입력과 출력을 위한 단일 엔드-투-엔드 신경망을 사용합니다. 이를 통해 ChatGPT-4o는 톤, 배경 소음, 다수의 화자 등과 같은 뉴안스를 이해하고 더 자연스러운 감정적 표현을 생성할 수 있습니다. 즉, 웃음이나 노래와 같은 표현이 가능해집니다.\n\n이 통합된 방법은 모델이 오랜 대화 동안 문맥을 유지하고 복잡한 대화를 처리하는 능력을 향상시킵니다. 그룹 토론 중에 다른 화자를 구별하거나 대화에서 감정적 함의를 이해하는 것과 같은 작업에서, ChatGPT-4o의 통합된 설계는 대화 능력을 크게 향상시킵니다.\n\n<div class=\"content-ad\"></div>\n\n# 다양한 형태에서 우수한 성능\n\nChatGPT-4o의 평가 지표는 인상적입니다:\n\n- 추론력: 0-shot CoT MMLU(일반 지식 질문)에서 88.7%의 점수를 기록하며 5-shot no-CoT MMLU에서 87.2%를 달성하여 우수한 추론 능력을 자랑합니다.\n- 오디오 및 비전: 음성 인식에서 Whisper-v3를 능가하며 다국어 및 시각 인식 평가에서 새로운 기준을 세웁니다.\n\n이러한 지표는 ChatGPT-4o의 다양한 형태를 이해하고 생성하는 고급 기능을 강조합니다. 추론 테스트에서의 성과는 복잡하고 미묘한 쿼리를 처리하는 능력을 보여주며, 교육 및 전문 분야에 강력한 도구로 사용될 수 있음을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n# 비디오에서 소개되지 않은 혁신적 기능\n\n유튜브 발표에서 강조되지 않은 ChatGPT-4o의 두드러지는 기능들을 소개합니다:\n\n## 시각적 서술\n\n- 로봇 작가의 차단: ChatGPT-4o는 텍스트 설명을 일관된 이미지 시퀀스로 전환할 수 있습니다. 이를 통해 로봇이 종이를 입력하고 찢어내는 과정을 단계별로 시각화할 수 있습니다. 사건 시퀀스를 이해하고 묘사할 수 있는 능력으로, 이는 이야기와 시각 요소를 결합하는 내용 작성 및 블렌딩에 뛰어난 기능을 제공합니다.\n- 우편집사 샐리: 이 기능은 상세한 텍스트 설명을 해석하고 해당하는 시각적 표현물을 생성할 수 있습니다. 샐리가 우편을 배달하거나 강아지와 상호 작용하며 이동하는 장면 등을 묘사할 수 있으며, 캐릭터 일관성과 상세한 시각적 서술을 보장합니다. 이 능력은 ChatGPT-4o의 교육, 엔터테인먼트, 마케팅과 같은 분야에서 텍스트 입력으로부터 매력적이고 정확한 시각적 이야기를 만드는 것을 강조하며, 이를 통해 유틸리티가 향상됩니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_1.png\" />\n\n## 창의적 콘텐츠 생성\n\n- 영화 '탐정'을 위한 포스터 제작: ChatGPT-4o는 텍스트 설명에서 전문적인 품질의 영화 포스터를 만들 수 있습니다. 예를 들어, 두 캐릭터의 얼굴을 신중한 표현과 함께 포함하여 특정 시나리오를 정확하게 나타낼 수 있는 포스터를 생성할 수 있습니다. 이 능력은 ChatGPT-4o의 고급 디자인 기술과 세심한 주의를 보여주며, 그래픽 디자인 및 마케팅에 탁월한 도구로 사용될 수 있습니다.\n- 캐릭터 디자인 — 로봇 Geary: 이 기능은 ChatGPT-4o가 요리, 바이올린 연주 또는 프로그래밍과 같은 다양한 활동 중에서도 일관적으로 캐릭터를 시각화할 수 있게 합니다. 텍스트에서 특정 세부 사항을 포함하여 캐릭터 무결성을 유지하면서, ChatGPT-4o는 애니메이션, 비디오 게임 및 교육 콘텐츠에 중요한 캐릭터 디자인과 스토리텔링 능력을 입증합니다.\n\n<img src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n## 예술적 및 타이포그래픽 스킬\n\n- 반복 편집을 통한 시적 타이포그래피: ChatGPT-4o는 시를 시각적으로 매력적인 디자인으로 변환할 수 있으며, 사용자 피드백을 기반으로 출력물을 반복적으로 개선합니다. 예를 들어 시를 명확한 필체로 변환하고 초현실주의적인 도안으로 가득한 것으로 만든 다음, 디자인을 다크 모드로 조정하거나 요청에 따라 색상을 변경할 수 있습니다. 이 능력은 모델의 유연성과 예술적 스킬을 강조하며, 사용자 맞춤형 및 예술적 시각 콘텐츠를 만들기 위한 강력한 도구로 만들어줍니다.\n- 글꼴 디자인: ChatGPT-4o는 상세한 텍스트 설명에서 사용자 정의 글꼴을 만들 수 있습니다. 화려한 빅토리아 양식의 글꼴이나 현대적이고 세련된 디자인을 생성할 수 있어서 다양한 타이포그래픽 스타일과 디테일 수준을 처리할 수 있는 능력을 보여줍니다. 이 능력은 브랜딩, 마케팅 및 크리에이티브 프로젝트에 대한 독특하고 맞춤형 글꼴을 만들고자 하는 디자이너들에게 특히 유용합니다.\n\n![ChatGPT-4o's Secret Superpowers What-the-YouTube-Demo-DIDN'T-Show-You](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_3.png)\n\n## 브랜딩 및 마케팅\n\n<div class=\"content-ad\"></div>\n\n- 코스터 위의 로고: ChatGPT-4o는 명확한 소재 및 디자인 명세를 반영하여 코스터와 같은 제품에 브랜드 로고를 정확하게 배치할 수 있습니다. 예를 들어, 나무와 대리석 코스터에 새겨진 OpenAI 로고를 묘사하여 브랜딩 및 제품 디자인 작업을 처리하는 데 정확성을 보여줍니다. 이 기능은 브랜드 제품을 시각화하고 마케팅, 디자인 및 프레젠테이션에 도움이 되는 데 매우 가치가 있습니다.\n\n![이미지](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_4.png)\n\n## 고급 텍스트 렌더링\n\n- 여러 줄 렌더링 — 로봇 문자 입력: 이 기능을 통해 ChatGPT-4o는 로봇이 문자를 보내는 것을 자세히 보여주는 능력이 있습니다. 명확하고 가독성 있는 여러 줄 메시지를 생성할 수 있습니다. 로봇이 핸드폰의 메시지 앱을 보는 일인칭 시점을 묘사하여 텍스트가 말풍선 안에서 정확하게 표현되도록 합니다. 이 기능은 교육 자료, 이야기 전달 및 디자인 개념에 대한 시각적 콘텐츠를 작성하는 데 모델의 유틸리티를 향상시킵니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_5.png\" />\n\n# 포괄적인 멀티미디어 콘텐츠 생성\n\n- 다양한 스피커가 있는 회의록: ChatGPT-4o는 오디오 입력을 해석하여 다양한 스피커를 인식하고 자세한 필기를 생성하는 데 능숙합니다. 이는 목소리를 구별하고 대화를 정확하게 속성 지정하여 필기를 명확하고 읽기 쉬운 형식으로 제공할 수 있습니다. 이 기능은 회의, 인터뷰 및 정확한 음성 상호작용 기록이 필요한 다른 시나리오에 유용합니다.\n- 강의 요약: ChatGPT-4o는 긴 강의나 프레젠테이션을 간결하고 정보량 풍부한 요약으로 만들 수 있습니다. 내용을 글머리 기호나 번호 목록으로 구조화하여 요약이 쉽게 읽고 이해할 수 있도록 합니다. 이 기능은 교육 목적, 회의록 및 콘텐츠 큐레이션에 유용하며, 긴 콘텐츠에서 중요한 포인트를 추려내는 것이 중요한 상황에 가치가 있습니다.\n\n<img src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_6.png\" />\n\n<div class=\"content-ad\"></div>\n\n- 변수 바인딩 - 큐브 쌓기: 이 능력을 통해 ChatGPT-4o는 텍스트 설명을 기반으로 특정 특성과 배열을 가진 객체를 시각화할 수 있습니다. 예를 들어, 다양한 색상과 문자가 특정 순서로 쌓인 큐브를 정확하게 묘사할 수 있어 복잡한 변수 할당을 다루고 일관성을 유지하는 능력을 보여줍니다. 이 기능은 교육 자료, 안내서 및 창의적인 프로젝트를 시각화하는 데 유용합니다.\n- 콘크리트 시: ChatGPT-4o는 시와 시각 예술을 결합한 시각적으로 매력적이고 구조적으로 정확한 콘크리트 시를 만들 수 있습니다. 단어를 모양을 형성하도록 배열하거나 OpenAI 로고와 같은 모양을 형성하는 등의 단어를 배치하고 추가 지침에 따라 디자인을 사용자 정의할 수 있습니다. 이 기능은 텍스트를 시각적 요소와 결합하여 매력적이고 의미 있는 예술을 만드는 프로젝트에 대한 유틸리티를 향상시킵니다.\n\n![이미지](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_7.png)\n\n# 무결한 안전성과 사용 편의성\n\n안전성은 ChatGPT-4o의 설계의 중요한 요소입니다. 내장된 안전 메커니즘과 사후 교육을 통한 다듬어진 동작으로 모델은 다양한 모달리티에서 책임 있는 사용을 보장합니다. ChatGPT-4o가 사이버 보안 및 편향을 포함한 다양한 안전 범주에서 중간 위험 수준 이하를 유지하는 것을 보여 주는 포괄적인 평가가 이루어졌습니다. 사회심리학과 오진 정보에 대한 외부 전문가들은 잠재적인 위험을 식별하고 완화하기 위해 모델을 엄격하게 테스트했습니다.\n\n<div class=\"content-ad\"></div>\n\n모델의 안전 프로토콜을 통해 사용자 보안이나 개인 정보 보호를 저해하지 않고 다양한 환경에서 배치할 수 있습니다. 견고한 디자인과 지속적인 개선으로 교육, 의료 및 전문 서비스 분야의 민감한 응용 프로그램에 신뢰할 만한 선택지가 됩니다.\n\n# 가용성 및 향후 출시 계획\n\nChatGPT-4o는 무료 티어 및 플러스 사용자에게 확장된 메시지 제한이 적용된 상태로 현재 사용 가능합니다. 개발자들은 API를 통해 텍스트 및 비전 작업에 액세스할 수 있습니다. 앞으로 몇 주 내에 음성 및 비디오 기능은 일부 신뢰할 수 있는 파트너 그룹에게 출시될 예정입니다.\n\n이 단계적 출시를 통해 OpenAI는 피드백을 수집하고 필요한 조정을 수행함으로써 모델의 전체 잠재력을 실현하고 성능 및 신뢰성의 높은 기준을 유지하는 것을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n# 새로운 지평을 탐험 중\n\nChatGPT-4o는 성능을 향상시키는 데 그치지 않습니다. 인공지능이 자연스럽고 창의적으로 사람들과 상호 작용하는 잠재력을 탐험하는 데 중점을 두고 있습니다. ChatGPT-4o는 상세한 시각적 서술을 만들거나 사용자 정의 글꼴을 디자인하거나 정확한 오디오 전사를 제공하는 것과 같은 일들을 수행하는 데 있어 인공지능 기술의 새로운 기준을 정립하고 있습니다.\n\n멀티모달리티를 원활하게 통합하고 해석하며, 고급 추론 능력과 창의적 능력을 결합하여 ChatGPT-4o는 인공지능의 진화 과정에서 중요한 이정표로 자리매김하고 있습니다. ChatGPT-4o가 이끄는 인간-컴퓨터 상호작용의 미래는 촉망받으며, 인공지능이 어디까지 성취할 수 있는지의 한계를 넓히는 데 도움이 되고 있습니다.","ogImage":{"url":"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_0.png"},"coverImage":"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_0.png","tag":["Tech"],"readingTime":7},{"title":"BiTCN 컨볼루션 네트워크를 활용한 다변수 시계열 예측","description":"","date":"2024-05-18 19:41","slug":"2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks","content":"\n\n![image](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png)\n\n시계열 예측 분야에서는 모델의 아키텍처가 주로 다층 퍼셉트론(MLP) 또는 트랜스포머 아키텍처에 의존합니다.\n\nN-HiTS, TiDE 및 TSMixer와 같은 MLP 기반 모델은 훈련 속도가 빠르면서 매우 좋은 예측 성능을 달성할 수 있습니다.\n\n한편, PatchTST 및 iTransformer와 같은 트랜스포머 기반 모델도 좋은 성능을 달성하지만 더 많은 메모리를 소비하고 더 많은 훈련 시간이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n아직도 예측에서 널리 활용되고 있지 않은 아키텍처 하나가 있습니다: 합성곱 신경망(CNN).\n\n전통적으로 CNN은 컴퓨터 비전에 적용되었지만, 예측 분야에서는 TimesNet이 최근의 예만 있습니다.\n\n그러나 CNN은 순차 데이터를 처리하는 데 효과적임이 입증되었으며, 그들의 아키텍처는 병렬 계산을 허용하여 훈련 속도를 크게 높일 수 있습니다.\n\n따라서 본 기사에서는 2023년 3월 논문 'Parameter-efficient deep probabilistic forecasting'에서 제안된 BiTCN을 탐색합니다. 두 개의 시계열 합성곱 신경망(TCN)을 활용하여 이 모델은 과거와 미래의 변수를 인코딩하면서도 계산 효율적인 특징을 유지합니다.\n\n<div class=\"content-ad\"></div>\n\n더 자세한 내용은 원본 논문을 꼭 읽어보세요.\n\n시작해봅시다!\n\n## BiTCN 탐험\n\n이전에 언급된대로, BiTCN은 두 개의 시계열 합성곱 신경망을 활용하므로 그 이름이 BiTCN입니다.\n\n<div class=\"content-ad\"></div>\n\n한 TCN은 미래 공변량을 인코딩하고, 다른 하나는 과거 공변량 및 시계열의 역사적 값들을 인코딩합니다. 이렇게 함으로써 모델은 데이터로부터 시간 정보를 배울 수 있고, 합성곱의 사용으로 계산 효율성을 유지할 수 있습니다.\n\n여기에는 분석할 것이 많기 때문에 아키텍처를 좀 더 자세히 살펴보겠습니다.\n\n## BiTCN 아키텍처\n\nBiTCN의 아키텍처는 많은 시계열 블록으로 구성되어 있습니다. 각 블록은 다음과 같이 구성됩니다:\n\n<div class=\"content-ad\"></div>\n\n- 확장된 합성곱\n- GELU 활성화 함수\n- 드롭아웃 단계\n- 완전 연결 레이어\n\n시계열 블록의 일반적인 아키텍처는 아래에 표시됩니다.\n\n![temporal block](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_1.png)\n\n위 그림에서 각 시계열 블록이 출력 O를 생성함을 볼 수 있습니다. 최종 예측은 N개의 레이어에 쌓인 각 블록의 모든 출력을 더하여 얻습니다.\n\n<div class=\"content-ad\"></div>\n\n드롭아웃과 댄스 레이어는 신경망에서 흔한 구성 요소입니다. 그러나 이번에는 확장 컨볼루션(dilated convolution)과 GELU 활성화 함수에 대해 좀 더 자세히 살펴봅시다.\n\n## 확장 컨볼루션\n\n확장 컨볼루션의 목표를 더 잘 이해하기 위해, 기본적인 컨볼루션이 어떻게 작동하는지 상기해 봅시다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_2.png)\n\n<div class=\"content-ad\"></div>\n\n위 그림에서 일차원 입력에 대한 전형적인 합성곱이 어떻게 보이는지 볼 수 있습니다. 출력의 길이를 동일하게 유지하기 위해 입력 시리즈는 왼쪽에 0으로 채워집니다.\n\n세 개의 커널 크기와 한 개의 스트라이드를 가정할 때, 위 그림에 나와 있는대로 출력 텐서도 네 개의 길이를 가집니다.\n\n출력의 각 요소가 세 개의 입력 값을 기반으로 한다는 것을 볼 수 있습니다. 다시 말해 출력은 색인의 값과 이전 두 값에 의존합니다.\n\n이를 수용 영역(Receptive Field)이라고 합니다. 시계열 데이터를 다루고 있으므로 출력 계산이 더 긴 이력을 볼 수 있도록 수용 영역을 증가시키는 것이 유익할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n그렇게 하려면, 커널 크기를 크게 하거나 더 많은 합성곱 계층을 쌓을 수 있습니다. 커널 크기를 크게 하는 것은 최선의 선택이 아닙니다. 정보를 손실하고 모델이 데이터의 유용한 관계를 학습하지 못할 수 있습니다. 그래서 더 많은 합성곱을 쌓아보겠습니다.\n\n위 그림에서 볼 수 있듯이, 커널 크기가 3인 두 개의 합성곱 작업을 쌓으면 출력의 마지막 요소는 이제 입력의 다섯 요소에 의존합니다. 따라서 수용 영역이 3에서 5로 증가했습니다.\n\n안타깝게도 이것도 문제가 됩니다. 이러한 방식으로 수용 영역을 증가시키면 아주 깊은 신경망이 생성될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n따라서, 우리는 모델에 너무 많은 레이어를 추가하지 않으면서 수용 영역을 증가시키기 위해 확장된 합성곱을 사용합니다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_4.png)\n\n위의 그림에서 우리는 2-확장된(convolution)을 실행한 결과를 볼 수 있습니다. 기본적으로 매 두 요소가 하나의 출력을 생성하는 것으로 간주됩니다. 따라서 우리는 이제 컨벌루션을 쌓지 않고도 수용 영역이 5임을 볼 수 있습니다.\n\n실제로 수용 영역을 더 증가시키기 위해, 주로 2로 설정된 확장 베이스를 사용하여 많은 희석커널(diluted kernel)을 쌓습니다. 이는 첫 번째 레이어가 2¹-확장 커널이되고, 그다음에 2²-확장 커널이 따르며, 그런 다음 2³로 이어지는 방식입니다.\n\n<div class=\"content-ad\"></div>\n\n수용 영역이 늘어나면 모델은 더 긴 입력 시퀀스를 고려하여 출력을 생성할 수 있습니다. Dilated convolutions을 사용하면 합리적인 수의 레이어를 유지할 수도 있습니다.\n\n이제 Dilated convolutions의 내부 작업을 이해했으니 GELU 활성화 함수를 알아보겠습니다.\n\n## GELU 활성화 함수\n\n많은 딥러닝 아키텍처에서는 ReLU(Recitified Linear Unit) 활성화 함수를 사용합니다. ReLU의 방정식은 아래와 같이 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n위의 식을 보면 ReLU는 간단히 0과 입력 중 최대 값을 취하는 것을 알 수 있습니다. 다시 말해, 입력이 양수이면 입력이 반환되고, 입력이 음수이면 0이 반환됩니다.\n\nReLU는 사라지는 그래디언트 문제를 완화하는 데 도움이 되지만 죽은 ReLU 문제를 만들 수도 있습니다.\n\n이는 네트워크에서 일부 뉴런이 오직 0만 출력하여 모델의 학습에 더 이상 기여하지 않는 경우에 발생합니다.\n\n<div class=\"content-ad\"></div>\n\n해당 상황에 대처하기 위해 가우시안 에러 선형 유닛 또는 GELU를 사용할 수 있습니다. GELU 방정식은 아래와 같이 나타낼 수 있습니다.\n\n\n![GELU Equation](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_6.png)\n\n\n이 함수를 사용하면 입력 값이 0보다 작을 때 작은 음수 값을 활성화 함수로 사용할 수 있습니다.\n\n\n![Activation Function with GELU](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_7.png)\n\n\n<div class=\"content-ad\"></div>\n\n이렇게 하면 신경세포가 소멸하지 않게 되어 음수 입력 값을 사용하여 0이 아닌 값이 반환될 수 있습니다. 이는 역전파에 대해 더 풍부한 그래디언트를 제공하며 모델의 기능을 유지할 수 있습니다.\n\n## BiTCN에서 모두 모아보기\n\n이제 BiTCN의 시간 블록의 내부 작업을 이해했으니, 우리는 모델에서 모든 것이 어떻게 함께 동작하는지 살펴봅시다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_8.png)\n\n<div class=\"content-ad\"></div>\n\n위 그림에서는 늦게 발생한 값들이 밀도 레이어를 통과하고 시간 블록 스택을 거친 후 모든 이전 공변량과 결합된 것을 볼 수 있습니다.\n\n상단에는 범주형 공변량이 다른 공변량과 결합되기 전에 먼저 임베딩된 것을 볼 수 있습니다. 여기서는 미래와 과거 공변량이 아래에 표시된 대로 모두 결합됨에 유의해주세요.\n\n그럼 그 값들은 밀도 레이어와 시간 블록 스택을 거쳐 이끌어집니다.\n\n최종 출력은 아래에 표시된 것과 같이 늦게 발생한 값과 공변량에서 나온 정보가 결합된 것입니다.\n\n<div class=\"content-ad\"></div>\n\n\n![그림](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_9.png)\n\n위의 그림은 하나의 시간 블록이 공변량의 미래 값을 활용하여 모델 출력을 결정하는 아이디어를 강조합니다 (빨간 점으로 표시됨).\n\n마지막으로, BiTCN은 예측 주변에 신뢰 구간을 구성하기 위해 Student’s t-분포를 사용합니다.\n\n이제 BiTCN의 내부 작업을 이해했으니, Python을 사용하여 소규모 예측 프로젝트에 적용해 봅시다.\n\n\n<div class=\"content-ad\"></div>\n\n# BiTCN을 사용한 예측\n\n이 실험에서는 BiTCN을 N-HiTS 및 PatchTST와 함께 사용하여 장기 예측 작업을 수행합니다.\n\n구체적으로, 블로그 웹사이트의 일일 조회수를 예측하는 데 사용합니다. 데이터셋에는 일일 조회수와 새로운 글이 게시된 날짜를 나타내는 지표, 미국의 공휴일을 나타내는 지표와 같은 외생 특성이 포함되어 있습니다.\n\n이 데이터셋은 제가 직접 제 웹사이트의 트래픽을 사용하여 컴파일했습니다. 데이터셋은 여기서 공개적으로 이용 가능합니다.\n\n<div class=\"content-ad\"></div>\n\n본 부분에서는 외부 기능을 지원하는 BiTCN의 사용 준비 구현을 제공하는 것으로 내가 알기로는 유일한 라이브러리인 neuralforcast를 사용합니다.\n\n언제나 GitHub에 이 실험의 전체 소스 코드가 있습니다.\n\n시작해 봅시다!\n\n## 초기 설정\n\n<div class=\"content-ad\"></div>\n\n이 프로젝트에 필요한 라이브러리를 가져오는 것이 첫 번째 단계입니다.\n\n```js\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.models import NHITS, PatchTST, BiTCN\n```\n\n그런 다음, 데이터를 DataFrame으로 읽어옵니다.\n\n```js\ndf = pd.read_csv('https://raw.githubusercontent.com/marcopeix/time-series-analysis/master/data/medium_views_published_holidays.csv')\ndf['ds'] = pd.to_datetime(df['ds]')\n```\n\n<div class=\"content-ad\"></div>\n\n데이터를 그래프로 나타낼 수도 있습니다.\n\n```js\npublished_dates = df[df['published'] == 1]\nholidays = df[df['is_holiday'] == 1]\n\nfig, ax = plt.subplots(figsize=(12,8))\n\nax.plot(df['ds'], df['y'])\nax.scatter(published_dates['ds'], published_dates['y'], marker='o', color='red', label='새 기사')\nax.scatter(holidays['ds'], holidays['y'], marker='x', color='green', label='미국 공휴일')\nax.set_xlabel('날짜')\nax.set_ylabel('총 조회수')\nax.legend(loc='best')\n\nfig.autofmt_xdate()\n\nplt.tight_layout()\n```\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_10.png)\n\n위 그림에서, 주중에 주말보다 더 많은 방문이 발생하는 주별 계절성이 명확히 나타납니다.\n\n<div class=\"content-ad\"></div>\n\n또한, 방문 횟수의 급증은 일반적으로 새로운 기사가 게시된 후 발생합니다(빨간 점으로 표시됨). 새로운 콘텐츠가 더 많은 트래픽을 유도하기 때문에 새로운 기사가 게시될 때 일반적으로 트래픽이 증가합니다. 마지막으로, 미국 공휴일(녹색 십자로 표시됨)은 종종 낮은 트래픽을 시사합니다.\n\n따라서, 외부 요인의 영향을 명확히 볼 수 있는 시리즈이며, BiTCN을 위한 훌륭한 사용 사례입니다.\n\n## 데이터 처리\n\n이제 데이터를 학습 세트와 테스트 세트로 분할해 봅시다. 테스트를 위해 마지막 28개 항목을 예약합니다.\n\n<div class=\"content-ad\"></div>\n\n```python\ntrain = df[:-28]\ntest = df[-28:]\n```\n\n그런 다음, 예보 기간에 대한 날짜 및 외생 변수의 미래 값이 포함된 DataFrame을 생성합니다.\n\n미래의 외생 변수 값을 제공하는 것이 의미가 있다는 점에 유의해야 합니다. 미래의 미국의 공휴일 날짜는 미리 알려져 있으며, 기사의 발행 또한 계획할 수 있기 때문입니다.\n\n```python\nfuture_df = test.drop(['y'], axis=1)\n```\n\n<div class=\"content-ad\"></div>\n\n좋아요! 이제 시리즈를 모델링할 준비가 되었습니다.\n\n## 모델링\n\n언급했듯이, 이 프로젝트에서는 N-HiTS(MLP 기반), BiTCN(CNN 기반) 및 PatchTST(Transformer 기반)를 사용합니다.\n\nN-HiTS와 BiTCN은 둘 다 외부 특성을 사용한 모델링을 지원하지만, PatchTST는 지원하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n이 실험의 수평선은 테스트 세트의 전체 길이를 포함하기 위해 28로 설정됩니다.\n\n```js\nhorizon = len(test)\n\nmodels = [\n    NHITS(\n        h=horizon,\n        input_size = 5*horizon,\n        futr_exog_list=['published', 'is_holiday'],\n        hist_exog_list=['published', 'is_holiday'],\n        scaler_type='robust'),\n    BiTCN(\n        h=horizon,\n        input_size=5*horizon,\n        futr_exog_list=['published', 'is_holiday'],\n        hist_exog_list=['published', 'is_holiday'],\n        scaler_type='robust'),\n    PatchTST(\n        h=horizon,\n        input_size=2*horizon,\n        encoder_layers=3,\n        hidden_size=128,\n        linear_hidden_size=128,\n        patch_len=4,\n        stride=1,\n        revin=True,\n        max_steps=1000\n    )\n]\n```\n\n그런 다음, 훈련 세트에 모델을 적용합니다.\n\n```js\nnf = NeuralForecast(models=models, freq='D')\nnf.fit(df=train)\n```\n\n<div class=\"content-ad\"></div>\n\n그럼, 우리는 외부 요인의 미래 값을 사용하여 예측을 생성할 수 있어요.\n\n```js\npreds_df = nf.predict(futr_df=future_df)\n```\n\n좋아요! 지금 이 시점에서, preds_df에 저장된 예측이 있어요. 각 모델의 성능을 평가할 수 있어요.\n\n## 평가\n\n<div class=\"content-ad\"></div>\n\n예측값과 실제 값들을 하나의 DataFrame으로 합치는 것으로 시작합니다.\n\n```python\ntest_df = pd.merge(test, preds_df, 'left', 'ds')\n```\n\n선택적으로, 예측값을 실제 값과 비교해서 아래 그림과 같이 시각화할 수도 있습니다.\n\n![예제 그림](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_11.png)\n\n<div class=\"content-ad\"></div>\n\n위의 그림에서는 모든 모델이 실제 트래픽을 전반적으로 과대 예측한 것으로 보입니다.\n\n그럼 최상의 성능을 발휘하는 모델을 찾기 위해 평균 절대 오차 (MAE)와 대칭 평균 절대 백분율 오차 (sMAPE)를 측정해보겠습니다.\n\n```js\nfrom utilsforecast.losses import mae, smape\nfrom utilsforecast.evaluation import evaluate\n\nevaluation = evaluate(\n    test_df,\n    metrics=[mae, smape],\n    models=[\"NHITS\", \"BiTCN\", \"PatchTST\"],\n    target_col=\"y\",\n)\n\nevaluation = evaluation.drop(['unique_id'], axis=1)\nevaluation = evaluation.set_index('metric')\n\nevaluation.style.highlight_min(color='blue', axis=1)\n```\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_12.png)\n\n<div class=\"content-ad\"></div>\n\n위의 표에서 BiTCN이 최상의 성능을 달성했음을 확인할 수 있습니다. 해당 모델의 MAE 및 sMAPE가 가장 낮기 때문입니다.\n\n이 실험만으로는 BiTCN의 강력한 벤치마크는 아니지만, 외생 변수를 활용한 예측 문맥에서 가장 우수한 결과를 달성하는 것을 볼 수 있어 흥미로운 실험입니다.\n\n# 결론\n\nBiTCN 모델은 이전 값과 미래 값을 함께 인코딩하기 위해 두 개의 시간 합성곱 신경망을 활용하여 효율적인 다변량 시계열 예측을 수행합니다.\n\n<div class=\"content-ad\"></div>\n\n시계열 분야에서 컨볼루션 신경망의 성공적인 응용을 보는 것은 흥미로운 일이죠. 대부분의 모델은 MLP 또는 트랜스포머를 기반으로 하지만요.\n\n저희의 소규모 실험에서 BiTCN이 가장 우수한 성능을 발휘했습니다. 하지만 저는 각 문제에는 독특한 해결책이 필요하다고 믿습니다. 이제 BiTCN을 도구 상자에 추가하고 여러분의 프로젝트에 적용해 보세요.\n\n독자 여러분, 읽어 주셔서 감사합니다! 즐기셨기를 바라며 무엇인가 새로운 것을 배우셨기를 기대합니다.\n\n건배 🍻\n\n<div class=\"content-ad\"></div>\n\n# 저를 지지해주세요\n\n제 작품을 즐기고 계신가요? Buy me a coffee로 제게 지지를 보여주세요. 그러면 여러분은 제게 격려를 주고, 저는 커피 한 잔을 즐길 수 있어요! 만약 그러고 싶다면, 아래 버튼을 클릭해주세요 👇\n\n![Buy me a coffee](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_13.png)\n\n# 참고자료\n\n<div class=\"content-ad\"></div>\n\n**Parameter-efficient deep probabilistic forecasting** by Olivier Sprangers, Sebastian Schelter, Maarten de Rijke\n\nExplanation of **dilated convolution** and figures of **dilates convolutions** inspired: **Temporal convolutional networks and forecasting** by Unit8","ogImage":{"url":"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png"},"coverImage":"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png","tag":["Tech"],"readingTime":11}],"page":"39","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}