{"pageProps":{"posts":[{"title":"Chat GPT-4o에 숨겨진 비밀은 발견 가능한 채팅으로 검색 엔진 결과를 영원히 바꿀 것입니다","description":"","date":"2024-05-23 17:29","slug":"2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats","content":"\n## 콘텐츠 작성 및 SEO용 인공 지능\n\nOpenAI의 새로운 모델인 GPT-4o와 그의 멀티모달 매직, 비교할 수 없는 강력함 및 접근성에 대한 많은 관심이 쏟아지고 있습니다. 그러나 AI가 웃고 애정을 나누는 모습들 속에서 (2013년 영화 'Her'나 2002년 'S1m0ne'과 같은 사이파이 영화 수준에 도달할 정도로), 우리가 AI와 인터넷과 상호 작용하는 방식을 바꿀 혁신적인 기술이 있습니다: 채팅을 발행하여 검색 엔진에서 직접 색인할 수 있는 능력입니다.\n\n## GPT-4o의 공개 채팅 기능에 대한 알아두어야 할 사항\n\nChatGPT 사용자들은 오랫동안 특정 대화에 대한 링크를 직접 복사하고 붙여넣기를 하지 않고도 친구나 동료들과 공유할 수 있었습니다(3.5버전과 4버전에서 작동합니다). 이를 통해 사용자들은 아이디어를 고민하고, 프롬프트를 공유하거나, 그냥 재미있는 채팅을 할 수 있었습니다. 이러한 순간들을 공유함으로써 생산성과 연결성을 증대시킬 수 있습니다. 그러나 4o의 \"공유 링크\" 기능은 다소 다릅니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-이챗GPT-4에숨겨진비밀은검색엔진결과를영원히변화시킬것입니다_0.png\" />\n\n이제 발견 가능한 링크를 생성할 수 있어요. 지혜로운 대화를 공유하는 것이 이전보다 쉬워졌어요. 이 대화들은 LinkedIn, Facebook, Reddit 및 X에 직접 게시할 수 있고, 무엇보다도 당신의 채팅이 웹 검색에서 발견될 수 있게 되어 SERP에 영향을 줄 수 있어요.\n\n저는 이것에 대한 SEO (검색 엔진 최적화) 가능성에 놀라고 있어요. 하지만 아직은 채팅이 어떻게 색인화될지 알려지지 않았어요. 실제로 OpenAI는 이에 대해 자세히 설명하지 않았고, 지난 주에 업데이트된 \"ChatGPT 공유 링크 FAQ\"에는 아직 설명이 없어요.\n\n정말 알면 알수록 좋은 기능이죠. 걱정 마세요. 저는 발견한 내용을 안내해 드릴게요:\n\n<div class=\"content-ad\"></div>\n\n## 어떻게 작동하나요?\n\n채팅을 검색 엔진에 푸시하는 방법을 알아보겠습니다:\n\n- 공개 링크 생성: 채팅 창의 오른쪽 상단에 공유 아이콘(트레이에서 위로 향하는 화살표)이 있습니다. 이를 통해 누구나 해당 링크를 통해 당신의 AI 채팅을 볼 수 있습니다. 여러분의 개인 계정에 액세스할 필요가 없습니다.\n- 여러 플랫폼에 공유: 링크가 생성되면 결과물을 인기 있는 플랫폼(LinikedIn, Facebook, Reddit, X)에 직접 게시할 수 있습니다.\n- 검색 효율: 여러분은 또한 여러분의 채팅을 웹 검색에서 검색할 수 있도록 설정할 수 있습니다. 이는 교육 콘텐츠, 튜토리얼 또는 더 넓은 관객이 더 많은 이득을 누릴 수 있다고 생각하는 토론에 특히 유용할 수 있습니다. (또는 SEO 전문가의 경우 SERP 로딩!)\n- 링크 관리: 개인 정보 보호나 여러 링크를 관리하는 데 걱정이 되시나요? 걱정하지 마세요! 설정 메뉴를 통해 이전에 공유된 채팅을 관리할 수 있습니다. 즉, 링크를 삭제하여 채팅을 다시 비공개로 만들 수 있습니다.\n\n<img src=\"/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_1.png\" />\n\n<div class=\"content-ad\"></div>\n\nGPT-4o의 발견 가능 옵션은 아직 사용 중이 아니며, 동의한 채팅의 미래 사용을 가리킬 수 있습니다. OpenAI의 현재 FAQ에 따르면 채팅이 인터넷의 공개 검색 결과에 사용되지 않는다고 합니다. 그러나 새로운 옵션 상자는 이 기능의 미래 잠재력을 시사합니다 - 아직 알아차릴 수 없었더라도요!\n\n심지어 이것은 OpenAI가 Gemini, Bing AI, Komo, You.com 등을 따라 전문 AI 검색 엔진 시장에 진입하려는 신호일 수도 있습니다.\n\n## ChatGPT 링크 공유의 실용적인 용도\n\n그래서, 이 기능을 최대한 활용하려면 어떻게 해야 할까요? 여기 GPT-4 채팅을 공유할 때 매우 유용할 수 있는 몇 가지 시나리오가 있습니다:\n\n<div class=\"content-ad\"></div>\n\n# 챗지피티 대화의 기본 링크 공유 (비공개):\n\n- 팀 협업: 팀 프로젝트에 참여 중이지만 Workspace가 없는 경우? 브레인스토밍 세션과 아이디어를 즉시 공유하세요.\n- 교육 목적: 교사와 학생들은 질문 응답 세션, 설명 및 토론을 공유하여 학습을 향상시킬 수 있습니다. AI를 에세이 작성 프로세스의 일환으로 사용할 때 학생들이 자신의 작업을 보여주는 좋은 방법이 될 것입니다. 교사는 에세이의 얼마나 많이 AI로 작성되었는지, 그리고 핵심적인 사고 및 유도 능력을 확인할 수 있습니다.\n\n검색 엔진 결과에서 공개 링크 공유 (검색 가능):\n\n- 고객 지원: 기업은 투명한 AI 지원 상호작용을 제공할 수 있으며, 이는 더 넓은 관객에게 검색 가능하고 접근 가능합니다.\n- 소셜 미디어: 특히 웃기거나 통찰력 있는 대화가 있었나요? 네트워크 이외의 관객과 공유하세요. 바이럴이 될 수도 있어요!\n- 콘텐츠 제작: 블로거, 인플루언서 및 컨텐츠 제작자들은 채팅을 공유하여 참여도를 높이고 팔로워들에게 콘텐츠를 제공할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 지금까지 가장 큰 응용 프로그램 중 하나 (좋다 나쁘다 모두)은 SEO에 미치는 잠재적 영향입니다. 정보가 색인화되고 발견되는 방식을 변경함으로써 SEO에 미치는 영향이 크게 변할 것입니다.\n\n## 검색 엔진 최적화(SEO)에서 발견 가능한 ChatGPT 링크의 혜택\n\n대화를 공개적으로 발견할 수 있도록 함으로써 SEO 작업을 크게 강화할 수 있습니다.\n\n다음과 같이 말이죠:\n\n<div class=\"content-ad\"></div>\n\n- 가시성 증가: 공용 링크는 검색 엔진에서 색인화될 수 있어 콘텐츠가 검색 결과에 나타날 확률을 높일 수 있어요.\n- 키워드 최적화: 대화에서 키워드를 전략적으로 사용하여 발견 가능한 대화의 SEO 가치를 극대화할 수 있어요 (어떻게 키워드를 찾아야 하는지 모르겠다면, SurferSEO를 사용하는 걸 추천해요).\n- 백링크 기회: 다른 사람들이 내용을 유용하게 여기고 자신의 사이트에서 링크할 때, 공유된 링크는 백링크를 생성할 수 있어요.\n- 채팅을 활용하여 당신에게 백링크 걸기: 채팅 내용에 자신의 콘텐츠 링크를 포함하도록 유도함으로써, 공유된 채팅이 사이트로의 백링크 역할을 하게 할 수 있어요. 웹사이트에서 관련 주제나 자료에 대해 이야기하고, 이 링크가 채팅에 맥락적으로 통합되도록 해주세요. 채팅이 게시되고 색인화되면, 이러한 링크가 트래픽을 유도하고 사이트의 권위를 향상시킬 수 있어요.\n\nGPT-4o의 화려한 기능들이 주목을 받을 때, 검색 가능성과 발견 가능성이 개선된 이 업그레이드는 아마도 그 가장 깊은 영향일지도 모르겠어요.\n\n👍 도움이 되셨나요? 박수를 부탁드립니다. Medium은 박수에 기반하여 작가에게 보상을 제공합니다.\n\n🌟 여러분의 지원은 매우 감사히 받고 있으며, 이러한 기사가 계속되도록 도와주는 역할을 합니다.\n\n<div class=\"content-ad\"></div>\n\n💡 여기 한 가지 팁이에요: 만지는 것 한 번으로 박수 버튼을 50번 칠 수 있어요!\n\n🤝 이 기사 링크를 소셜 미디어나 LinkedIn에 공유해도 괜찮아요\n\n## Jim the AI Whisperer은 누구일까요?\n\nJim the AI Whisperer은 AI 생성기를 사용하여 시각물을 만드는 방법에 대한 개인 트레이닝과, 흥미로운 콘텐츠를 위해 AI 출력을 개선하는 방법을 제공해줍니다.\n\n<div class=\"content-ad\"></div>\n\n## 만나서 반가워요!\n\n개인 코칭이나 제 서비스를 이용하고 싶다면 언제든지 연락해 주세요. 포드캐스트, 인터뷰 등에도 참여할 준비가 되어 있습니다. 그리고 제 작업을 지원하고 싶다면, 제 Buy Me a Coffee 페이지를 확인해 주세요.\n\n![이미지](/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_2.png)\n\n## 최신 소식을 받아 보세요!\n\n<div class=\"content-ad\"></div>\n\nAI에 관한 최신 소식을 놓치고 싶지 않으시다면 구독해주세요! 제가 새 글을 올릴 때마다 이메일을 받을 수 있습니다. 정보를 제공하고 흥미로운 내용을 담아 미리알리는 스타일을 유지하고 있어요.\n\n## Jim the AI Whisperer의 관련 기사를 즐기실지도 몰라요:\n\n![이미지](/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_3.png)\n\n이 이야기는 Generative AI에서 게시되었습니다. 최신 AI 이야기를 만나려면 LinkedIn에서 저희와 연결하고 Zeniteq를 팔로우해보세요.\n\n<div class=\"content-ad\"></div>\n\n우리의 뉴스레터에 가입하여 창의적 AI에 관한 최신 뉴스 및 업데이트를 받아보세요. 함께 AI의 미래를 함께 만들어 봅시다!\n\n\n![image](/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_4.png)\n\n","ogImage":{"url":"/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_0.png"},"coverImage":"/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_0.png","tag":["Tech"],"readingTime":5},{"title":"OpenAI의 ChatGPT-4o 좋은 점, 나쁜 점, 그리고 비책능성","description":"","date":"2024-05-23 17:27","slug":"2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible","content":"\n\n![OpenAI GPT-4o](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png)\n\n지난 주, OpenAI가 GPT-4o (\"o는 'onmi'의 약자)의 발표를 했습니다. 놀랍게도, 기대보다는 두려움을 느꼈습니다. 그 느낌이 가시지 않았죠.\n\n테크 분야에서 여성으로서, 디지털 기술, 특히 인공지능이 세상에 긍정적인 영향을 줄 수 있다는 증거가 있습니다. 예를 들어, 새로운 더 효과적이고 덜 독성이 있는 약물을 개발하거나 자동 자막을 통해 접근성을 향상시킬 수 있습니다.\n\n기술 옹호자일 뿐만 아니라 동시에 그에 의해 초래된 임박한 재앙감을 경험하고 있는 이 상반된 감정 때문에 대형(소형 포함) 기술, 인식적 부당한대, 그리고 인공지능 서사에 대해 탐구의 길로 빠졌습니다.\n\n\n<div class=\"content-ad\"></div>\n\n저는 우울주의자였나요? 숨은 러다이트주의자였나요? 아니면 그냥 시야가 좁았을 뿐이었나요?\n\n잠시 동안 되돌아보는 시간을 가졌더니, 빅테크와 다른 스무스한 AI 운영자들이 나를 위해 설치한 덫에 빠지고 있었다는 것을 깨달았어요: 디지털 유사한 유령의 여류적 미래 약속을 살펴보는 나 자신을 의심했던 것이죠.\n\n그 딜레마의 반대편에서, 저는 기술주의 대 도의미주의의 잘못된 이분법을 탐색하는 데 AI 대화에 내 기여가 중요하다는 믿음이 강해진 것 같아요.\n\n이 기사에서 OpenAI가 어떻게 중요한 기여자인지 보여주면서 그 대화를 극단적으로 이혁하는 데 어떤 역할을 하는지를 살펴봅니다:\n\n<div class=\"content-ad\"></div>\n\n- ChatGPT-4o 발표 소식에 대한 내용 — 그리고 그렇지 않은 것\n- OpenAI의 작동 방식\n- OpenAI의 안전 기준\n- 최종 책임소재\n\n# ChatGTP-4o: 발표\n\n5월 13일 월요일, OpenAI는 웹사이트에 또 다른 \"업데이트\"를 공개했습니다: ChatGPT-4o.\n\n잘 구성된 발표였어요. 그들의 웹사이트에 있는 공지에는 CTO인 Mira Murati가 진행하는 20분 이상의 비디오가 포함되어 있습니다. 그녀는 새로운 기능에 대해 논의하고 다른 OpenAI 동료들과 함께 몇 가지 데모를 수행합니다. 응용 프로그램 예시와 모델 평가, 안전, 가용성과 같은 주제에 대한 매우 고수준의 정보가 있는 작은 동영상과 스크린샷도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n저는 ChatGPT-4o와 OpenAI에 대한 공식 발표를 통해 배운 내용을 공유할게요.\n\n## 새로운 기능\n\n- 이용의 민주화 — 무료로 더 많은 기능을 사용하고 API 접속 비용이 50% 저렴해집니다.\n- 다중모드 — 텍스트, 오디오, 이미지의 어떤 조합도 생성합니다.\n- 속도 — 2배 빠른 응답속도.\n- 비영어권 언어 처리 개선 — 50개 언어를 다루며 이는 세계 인터넷 인구의 97%에 해당한다고 주장합니다.\n\n## OpenAI의 대형 기술 플레이북 채택\n\n<div class=\"content-ad\"></div>\n\n이 “업데이트”는 인공지능 회사가 실리콘밸리에서 “보스”처럼 보이는 방법에 대해 알아야 한다는 메모를받았음을 보여줍니다.\n\n1. 성역할 강화\n   발표 당일 Sam Altman은 X에 떼어난 단어를 게시했습니다. - “her” - 2013년 영화를 참조한 것입니다. 이 영화에는 Joaquin Phoenix가 주연으로 나오며 남성이 미래 버전의 Siri 또는 Alexa에게 반하는 모습을 보여줍니다. Siri 또는 Alexa는 Scarlett Johansson의 목소리로 연기되었습니다.\n\n이것은 우연이 아닙니다. ChatGPT-4o의 목소리는 뚜렷하게 여성적이고 애정적이며 데모에서는 남성 목소리가 들릴 수 있는 비디오를 한 개만 찾을 수 있었습니다.\n\n불행하게도 60년 전의 챗봇 ELIZA 이후에는 많은 변화가 일어나지 않았습니다...\n\n<div class=\"content-ad\"></div>\n\n2. 인간화\n\nOpenAI는 ChatGPT-4o의 능력을 묘사할 때 \"이성\"과 \"이해\"와 같은 본질적으로 인간적인 기술을 사용하여 그들의 모델이 인간과 같음을 강조합니다.\n\n3. 자기 규제 및 자가 평가\n   120년 이상의 경험을 보유한 미국 국립표준기술연구소(NIST)는 AI 리스크를 평가하고 관리하기 위한 프레임워크를 개발했습니다. 다른 다양한 이해관계자 기관들도 각자의 프레임워크를 개발하고 공유했습니다.\n\n그러나 OpenAI는 AI 규제가 필요하다고 주장하면서도 GPT-4o를 그들의 준비 프레임워크에 따라 평가하고 자발적 약속을 준수하기로 선택했습니다.\n\n<div class=\"content-ad\"></div>\n\n게이트키퍼피드백\nOpenAI는 “그들”이 사이버 보안, CBRN (화학, 생물학, 방사선, 핵 위협), 설득력 및 모델 자율성의 평가에서 GPT-4o가 추가적으로 수행된 테스트의 추가 증거 없이 중간 위험 이상을 얻지 못했다는 것을 말할 때, 안심하고 계속 진행해야 한다고 말합니다.\n\n또한, 오픈AI는 사회심리학, 편향 및 공정성, 그리고 정보 오해와 같은 영역에서 70명 이상의 외부 전문가들과 함께 외부 레드팀을 진행했고, 새로 추가된 다양한 모달리티에 의해 도입되거나 증폭된 위험을 식별했습니다.\n\n![이미지](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_1.png)\n\n전문분야 목록을 보면 역사, 지리 또는 철학과 같은 영역을 볼 수 없습니다. 또한, 70명 이상의 전문가가 누구인지 또는 그들이 이 행성에 살고 있는 80억 명의 사람들 사이의 다양성을 어떻게 다룰 수 있는지도 볼 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n요약하면, OpenAI는 모두를 위해 개발하지만 몇 명의 선택된 사람들의 피드백만을 토대로 합니다.\n\n5. 책임 면제\n   약의 안내 책자에 다음과 같은 문구를 읽어볼 수 있다고 상상해보세요.\n\n하지만 OpenAI가 최근 발표한 내용에는 바로 그런 내용이 포함되어 있습니다.\n\n뿐만 아니라, 우리를 베타 테스터로서 초대합니다.\n\n<div class=\"content-ad\"></div>\n\n문제가 뭘까요? 제품은 이미 세상에 공개되었습니다.\n\n6. 감정 \"추측\"의 유사과학을 홍보하는 것\n   더미에서 ChatGPT-4o에게 발표자 중 한 명의 감정을 예측하도록 요청합니다. 모델은 계속해서 그의 얼굴에서 보이는 것을 기반으로 개인의 감정 상태를 추측하는 것으로 들어갑니다. 이는 궁극적으로 미소라고 나타나는 것을 주장합니다.\n\n![이미지](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_2.png)\n\n그러나 얼굴 표정이 감정을 나타낸다는 믿음을 뒤엎는 과학적 연구가 많이 있습니다. 게다가, AI 공급업체들이 그 수작을 통해 이익을 얻는 것에 대해 과학자들이 비판을 퍼부었습니다.\n\n<div class=\"content-ad\"></div>\n\nOpenAI가 그 오해들에 대해 마케팅 수단으로 활용하는 대신 대중에게 그것들에 대해 교육을 돕는 것을 기대해야 할 텐데요?\n\n## 그들이 말하지 않았지만, 나는 그들이 했으면 하는 것들\n\n- 정부와 협력하여 능력/모델을 규제하고 전개하는 노력의 신호.\n- 에너지 효율성, 수소소비량 또는 CO2 배출에 대한 지속 가능성 기준.\n- ChatGPT-4o가 무료가 아니라는 인정 - 우리는 데이터에 대한 액세스 비용을 지불할 것입니다.\n- OpenAI의 시간표 및 향후 릴리스에서 기대되는 기능. 나는 20년 동안 소프트웨어 개발을 진지하게 다루는 소프트웨어 회사와 고객들과 공유하는 로드맵 및 릴리스 일정을 통해 구현과 채택을 돕는 조직에서 일해왔습니다.\n- 제품을 사용하는 수십억 명의 사람들이 경쟁사를 못 이길 것을 희망하는 것 이외의 신뢰할 만한 비즈니스 모델.\n\n하지만, 이것만으로는 제가 느끼는 불안한 기분을 설명하지 못했습니다. 패턴이 그것을 설명했어요.\n\n<div class=\"content-ad\"></div>\n\n# OpenAI의 청사진: 이건 기능이지 결함이 아니에요\n\nOpenAI의 모든 제품 발표는 비슷해요: 그들이 일방적으로 결정한 일들을 우리에게 알리고, 그것이 우리 삶에 어떻게 영향을 미칠지 설명하면서 우리가 그것을 막을 수 없다고 말해요.\n\n그 기분... 전 어디서 느꼈었지? 두 가지 사례가 떠올랐어요.\n\n- 트럼프 대통령 임기\n- 코로나19 전염병\n\n<div class=\"content-ad\"></div>\n\n이 두 가지 요소 - 어느 순간 얽혀 있는 것처럼 - 저와 수백만 명의 사람들의 삶이 인류에 대한 배려가 없는 무언가/누군가의 변덕에 위험에 처해 있다는 느낌을 일으킨다.\n\n구체적으로는 다음과 같은 느낌이었습니다.\n\n- 통제의 부재 - 각각의 트윗이나 각각의 감염 차트마다 엄청난 고통과 변화를 나타낼 수 있음을 의미했습니다.\n- 휴식의 여지가 없었습니다 - 모든 것이 평온해 보일 때라도, 트윗이 없거나 전염병이 감소하지 않을 때에도, 저는 떨어질 다른 부분을 기다렸습니다.\n\nOpenAI로 돌아와서, 지난 세 달 동안 ChatGPT-4o의 공개를 위해 따르던 동일한 방식의 사례들을 몇 가지 보았습니다. 저는 그 중 세 가지를 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## OpenAI Releases Sora\n\n2월 15일, OpenAI가 텍스트에서 비디오로 변환하는 모델인 Sora를 소개했습니다.\n\n간략히 요약하면,\n\n- 다른 공지와 마찬가지로, \"이해하다\"나 \"파악하다\"와 같은 단어는 Sora의 능력을 의인화하는 것을 나타냅니다.\n- \"Sora가 해로운 영역을 평가하는 레드 팀원에게 이용 가능해지고 있다\"는 것에 대해 우리는 확언받았습니다.\n- 이 새로운 기술의 긍정적인 사용 사례를 식별하고 세계적인 정책 입안자, 교육자 및 예술가들과의 대화가 나준에 있을 것\"이라고 우리는 나중에만 알게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n물론, 우리는 Sora를 약 한 달도 되지 않아, Taylor Swift의 비동의 성적 수치화된 딥페이크 영상이 X에서 확산된 후에 공개한 것은 무모했다는 것에도 경고받았습니다. 이는 유명인 문제가 아니었습니다 - 딥페이크의 96%가 비동의 성적 성향이며, 그 중 99%는 여성을 대상으로 합니다.\n\n여성을 굴욕시키고, 침묵시키고, 대상화하기 위한 콘텐츠를 쉽게 생성할 수 있도록 하는 도구를 개발할 때 안전 문제에 대해 이야기하는 OpenAI가 어떻게 할 수가 있나요?\n\n## OpenAI Releases Voice Engine\n\n<div class=\"content-ad\"></div>\n\n3월 29일, OpenAI가 \"사용자 지정 음성을 만드는 모델인 Voice Engine의 소형 미리보기에서 얻은 교훈\"을 공유하는 블로그를 게시했습니다.\n\n이 기사에서는 합성 음성 남용의 가능성으로 인해 \"보다 넓은 배포에 대해 신중하고 정보를 제공하는 접근 방식\"을 취하고 있음을 우리에게 안심시켰으며, 모델을 언제 공개할지에 대한 결정은 일방적으로 내릴 것이라고 알렸습니다.\n\n그리고 발표 끝 부분에서 OpenAI는 \"Voice Engine\"으로 인해 우리가 해야 하는 일이나 그만 두어야 하는 일에 대해 경고했습니다. 그 목록에는 음성 기반 인증을 은행 계좌에 접속하기 위한 보안 조치로 사용하던 것을 폐기하고, 음향-비주얼 콘텐츠의 출처를 추적하는 기술 개발을 가속화해야 한다는 내용이 포함되어 있습니다.\n\n## OpenAI, AI 에로티카, 과도한 그로티, 모욕 생성 허용\n\n<div class=\"content-ad\"></div>\n\n5월 8일, OpenAI가 ChatGPT 내의 AI 기술이 어떻게 행동해야 하는지에 대한 초안 가이드라인을 발표했고, '책임 있게' 음란 콘텐츠를 생성하는 방법을 탐구 중이라고 밝혔습니다.\n\n이 제안은 OpenAI가 AI 도구를 개발하는 방식에 대해 논의하는 OpenAI 문서의 일부였습니다.\n\nOpenAI 문서에서 작업한 OpenAI 직원 Joanne Jang은 출력물이 음란물로 간주되는지 여부는 \"당신의 정의에 달렸다\"며 추가로 \"우리가 가지길 원하는 정확히 이 대화들입니다\"라고 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n비반 키드론, 영국 파벤치 피어이자 아동 온라인 안전을 위한 캠페인가, 가 말한 것에 동의할 수밖에 없어요.\n\n## OpenAI 공식\n\n![Image](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_3.png)\n\n패턴을 봤나요?\n\n<div class=\"content-ad\"></div>\n\n- 이기적인 행동\n- 예측할 수 없음\n- 자기 규제\n- 무모함\n- 기술적 가부장주의\n\n# OpenAI에서 문제가 있다\n\nChatGPT-4o 발표 후, 안전 담당 상급 OpenAI 직원 두 명이 회사를 떠나기로 결정했다.\n\n먼저 OpenAI 공동 창업자이자 최고 과학자인 이리야 숫스케버는 X에 떠났다고 게시했다.\n\n<div class=\"content-ad\"></div>\n\n그날 나중에, Superalignment의 공동 리더이자 OpenAI의 임원인 삶 스쿠버와 함께 일하는 얀 라이케가 사임을 발표했습니다.\n\nX 쓰레드에서 그는 다음과 같이 말했습니다.\n\n안전, 정책 및 지배 영역에서 OpenAI를 떠나는 직원 목록 중 마지막으로 떠나는 사람들입니다.\n\nOpenAI 안전 리더들이 배를 떠나면 우리에게 무슨 의미가 될까요?\n\n<div class=\"content-ad\"></div>\n\n# 우리 정치인들에게 모든 책임이 있어\n\nLeike의 트윗에 대답하기 위해, OpenAI가 신뢰할 만하고 윤리적이며 포용적인 AI 프레임워크를 개발하는 책임을 맡기고 싶지 않아요.\n\n첫째, 회사가 지구 규모의 안전을 자사 이익보다 우선시할 능력이나 기질을 보여주지 않았기 때문이에요.\n\n둘째, 그건 그들의 역할이 아니기 때문에요.\n\n<div class=\"content-ad\"></div>\n\n그 역할은 누구의 것인가요? 우리 정치 대표자들이 정부 기관을 규제하도록 요구하며, 이에 따라 그러한 프레임워크를 개발하고 시행해야 합니다.\n\n나쁘게도 지금까지 정치인들의 자아가 방해 요인이 되었습니다.\n\n- AI에 대한 이해를 거부하는 것.\n- 장기적인 글로벌 AI 규제를 다른 국가들과 협력하여 개발하는 대신 자신들과 당의 일정을 우선시하는 것.\n- 현재의 해를 희망의 혁신 약속을 위하여 덜어주는 AI FOMO에 실패하는 것.\n\n요약하면, 선출된 대표들은 Sam과 팀과 친해지는 것을 그만두고 AI가 모두를 위해 작동하고 미래 세대의 생존을 위협하지 않도록하는 규제적 프레임워크를 시행해야 합니다.\n","ogImage":{"url":"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png"},"coverImage":"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png","tag":["Tech"],"readingTime":8},{"title":"오픈에이아이가 스타트업을 압도할 것 같다고 합니다 모델이 더 나아질 때 우리는 무엇을 개발해야 할까요","description":"","date":"2024-05-23 17:25","slug":"2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter","content":"\n\n![이미지](/assets/img/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter_0.png)\n\n만약 AI 제공 업체가 다른 회사들이 그들의 모델을 사용하여 단순히 특정 앱을 개발하고, 제공 업체가 영역에 절대 뛰어들지 않는 비즈니스 도메인을 발전시키길 원한다면 좋겠죠. 시장 전체에 온통 존재하기보다 더 똑똑한 전략이겠죠? 결국 공통 플랫폼 전략이죠.\n\n현실적으로, AI 제공 업체는 종합적인 시장 채택을 위해 그들의 길을 질주하며 모든 것을 압도할 것입니다. 기술 플랫폼 및 생태계 발전에는 빠르게 변화되는 패턴이 있습니다; 예를 들어 AWS의 플랫폼 지배력 증가.\n\n하지만 오늘날은 조금 다릅니다. 지능적이고 에이전트 자동화는 이제 비즈니스 및 특정 영역으로 확장되는 복잡한 변수입니다 (인프라 제공 업체로서 하지 않았던 AWS). 즉, 대형 업체들이 모든 것을 일반적으로 해결하기 위해 다른 것을 만들 때 어떻게 무언가를 만들 것인가요? 결국 일반 에이전트는 그런 목적으로 의도된 것이죠.\n\n\n<div class=\"content-ad\"></div>\n\n## 그럼 무엇을 만들까요?\n\n오늘 이 질문에 대한 대답은 어려우며 내일의 대답을 예측하는 것도 어렵습니다. 우리는 매 분기마다 새로운 고급 능력의 형태를 보고 있습니다. 지난 주 OpenAI는 AI와의 실시간 대화를 보여주며, 실시간 언어 번역과 같은 다양한 능력을 예시로 들었습니다. 그 다음 날, Duolingo의 주가가 하락했습니다. 그 후, OpenAI는 Google 시트의 자동 분석 및 생성을 시연하며, 적어도 5개의 개발자 중심의 \"데이터 분석 에이전트\" 스타트업을 가려냈으며, 데이터 분석가 자체에게는 잠재적인 경력 단축 시나리오를 시사했습니다.\n\n간단하게 말씀드리면, LLM(Large Language Models)이 직접 상호 작용할 수 없는 복잡한 작업 흐름을 향상시키도록 만들어야 합니다. 여러분은 고급 LLM 사용을 조율하는 데 그치지 않고 비즈니스 프로세스와 기타 시스템과 통합해야 합니다. 더 많은 접착제를 만들수록 AI가 발전함에 따라 스타트업이 더 안전해집니다.\n\n## 예시: AI를 활용한 이력서 생성\n\n<div class=\"content-ad\"></div>\n\n간단한 예시: 이력서 생성... 사실 누구나 오늘 ChatGPT로 이력서 텍스트를 만들 수 있어요. 시장은 이제 많은 이력서 생성기로 가득 차 있어요. 하지만 빠진 부분은 AI를 사용하여 풀 텍스트 뿐만 아니라 완전히 서식이 있는 Word 문서를 생성하는 것입니다 — json으로 채워진 웹 UI나 PDF가 아닌— 사용자가 양식을 작성할 필요가 없는 방식으로. 강력한 AI 인터페이스 + 사용자 참여 제한 + 통합이 열쇠라고 생각해요. CVGist.com은 이를 위한 간단한 예시예요. 사용자는 간단한 요지를 입력하면, CVGist가 ChatGPT와 여러 문서 통합을 사용하여 실제 단어 문서(90개 이상의 이력서 템플릿 서식)를 생성해줘요. 우리가 여기서 만들어낸 간단한 접착제는 단어 문서를 생성하는 것이었죠... 이것은 완전히 간단하지 않았어요. 단어 문서 생성이 우리가 사업 아이디어로 확장하고자 하는 것이죠; 이력서를 넘어, 심지어 우리는 여전히 AI로 단어 처리를 혁신하는 Microsoft의 능력에 능숙해야 해요.\n\n물론, 이것조차 오래가는 것이 아니에요. 우리는 곧 다양한 스타일의 구조화된 문서를 생성해주는 에이전트들이 있을 거에요. 요점은 통합을 구축하려고 하는 것이에요.\n\n## 더 많은 접착제가 열쇠\n\n이력서 예시를 위한 더 발전된 통합 또는 \"접착제\"는 사용자를 대신하여 여러 직업에 지원하는 것을 포함할 수 있어요 (웹 API, 아마도 헤드리스 브라우저 자동화 등을 활용). 그러나 OS 및 브라우저 제공업체들이 에이전트들을 기본적으로 통합할 것이며, 우리는 OpenAI가 언젠가 자체 에이전트 브라우저를 출시하는 것에 놀랄 필요가 없어요. 이러한 시나리오에서 브라우저 기반 에이전트/어시스턴트는 네이티브 브라우저 대화식 경험에서 사용자를 위한 어떤 기본적인 웹 작업(양식 작성 등)을 수행할 만큼 강력하게 될 거에요 (스타트업이 이곳에서 시도해야 하는 좋은 아이디어라고는 생각하지 않아요).\n\n<div class=\"content-ad\"></div>\n\n따라서 통합 기능이 미래에 대비되도록 하는 것은 아이디어 유효성 검증 과정에서 추가적인 단계입니다. 간단한 통합 관점에서 침투하기 어려운 시스템 및 비즈니스 워크플로 프로세스를 찾아 개선해야 합니다. 단순한 UI/API 상호작용을 넘어서 복잡한 워크플로에 집중해야 합니다 (다시 한 번, 공급 업체들은 일반화된 플랫폼 에이전트로 향하고 있기 때문입니다).\n\n그렇다면 알트만에 밀리지 않고 미래에 대비할 수 있는 아이디어가 무엇일까요? 여기에 답변하는 것은 상당히 가치가 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter_0.png"},"coverImage":"/assets/img/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter_0.png","tag":["Tech"],"readingTime":3},{"title":"알고 있는 것은 기억하는 것과도 같아요","description":"","date":"2024-05-23 17:22","slug":"2024-05-23-ToKnowIsAlsotoRemember","content":"\n\n![이미지](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_0.png)\n\n한 남자와 한 여자가 임상 연구 센터의 조용한 방 안에서 대화를 나누고 있습니다. 여자는 질문을 하고는 남자가 대답할 때까지 기다리면서 몇 가지 노트를 적습니다. 그냥 보통 대화처럼 보일 수도 있지만, 실제로는 전혀 보통이 아닙니다. 여자의 노트북 안에는 매 페이지마다 써 있는 날짜와 상관없이 남자의 대답이 항상 동일합니다. 대화가 80년대에 발생했더라도, 대답은 10년 이상 전에 일어난 사건을 참조하고 있습니다. Jenni Ogden은 나중에 네오심리학에 영향을 미치면서 그의 진짜 이름인 Henry Molaison으로 더 잘 알려지게 된 환자 H.M.과 대화를 나눈 최초의 연구자 중 한 명이었습니다. 며칠 후, 연구진은 Henry가 27세 때 받았던 뇌 절제술로 인해 새로운 기억을 생성하는 능력을 상실했다고 결론 내렸습니다. Henry의 사례는 뇌 기능과 기억 사이의 연결을 이해하고 단기와 장기 기억이라는 개념을 만들어내는 데 도움이 되었습니다. 이 개념은 기계 학습 분야에서 혁신적인 연구를 위한 토대를 마련했으며, 과학자들과 개발자들이 뇌의 신비한 내부 구조에서 더 나은 예측 모델을 만드는 데 노력하고 있습니다.\n\n# 소개\n\n인공 신경망(ANN)은 우리 뇌에서 작동하는 실제 신경망에서 영감을 받았습니다. 실제로 ANNs는 실제 신경세포가 어떻게 상호 연결되고 위에서 설명한 상황을 설명하는 추상화일 뿐입니다. 개미군 최적화, 차분 진화, 입자 미래 등의 프로세스와 유사하게, ANNs는 실제 과정의 본질을 포착하여 현재 대부분의 AI 솔루션 뒤에 있는 알고리즘을 설계하는 데 사용됩니다. ANNs가 정말로 학습하는지, 그들이 하는 일을 지능이라고 해야 하는지에 대한 논의는 넓고 계속됩니다. 그러나 그들의 다용도성과 성능은 부정할 수 없습니다. 새로운 ANN 구성은 매일 개발되고 있으며 다양한 문제에 성공적으로 적용되고 있습니다. 이러한 변형의 대부분은 여전히 실제 신경망의 행동에서 영감을 받고 있습니다.\n\n<div class=\"content-ad\"></div>\n\nRNN(RNNs)은 일련의 메모리 구성요소를 통합하여 처리하는데, 수년 전에 자연어 처리(NLP)에서 중요한 접근 방식을 나타냅니다. RNNs는 Long-Short Term Memory (LSTM) Networks로 나아가는 길을 열며, NLP 응용 프로그램에서 신경망의 성능을 높였습니다. 이후 LSTM 네트워크는 트랜스포머 모델과 GPT(Generative Pre-trained Transformer)에 의해 대체되었는데, 이것이 ChatGPT의 기초가 되었습니다. 이 기사에서는 LSTM 네트워크가 무엇이며, 그들을 특별하게 만드는 이유에 대해 살펴봅니다.\n\n# RNN의 의미\n\nLSTM 네트워크가 어떻게 작동하는지 이해하기 위해서는 그 목적에 대해 생각해 보는 것이 중요합니다. RNN과 LSTM 네트워크는 비슷한 목표를 따릅니다. 이들은 순차적으로 저장된 데이터를 모델링하고 예측하는 데 사용됩니다. 이는 이 유형의 네트워크가 데이터 시퀀스를 읽고 다음 값이 무엇인지 예측하려고 한다는 것을 의미합니다. 특정 도시의 지난 30일간의 평균 온도를 기록한 로그가 있다고 가정해 봅시다. 그리고 31일차의 온도를 추정하고 싶다면 어떻게 할까요? 한 가지 방법은 온도를 다른 변수에 상관시켜서, 31일에 이러한 변수의 값에 따라 새로운 온도를 추정하는 것입니다. RNN은 몇 일, 예를 들어 30일 이내의 일부 날짜를 고려하여 이전 온도 값을 기반으로 31일의 온도를 예측합니다. 한 마디로, RNN은 시퀀스를 기억하고 다음 값 또는 값 그룹을 제시하려고 노력합니다. 이전에 작성한 기사 중에 RNN이 메모리 전문가와 어떻게 비교되면서 RNN이 어떻게 단계적으로 작동하는지 설명했습니다.\n\n이전 날짜의 온도를 기반으로 새로운 온도를 예측하는 아이디어는 다른 응용 분야로 확장할 수 있습니다. 소개에서 언급된 것처럼, RNN은 NLP 중 첫 접근 방식 중 하나였습니다. 아이디어는 RNN을 텍스트로 학습한 다음, RNN을 사용하여 입력 후 다음에 나오는 단어 또는 단어 그룹을 예측하는 것입니다. 이러한 아이디어는 자동 번역뿐만 아니라 음성 및 필기 인식과 같은 과제에도 적용할 수 있습니다. RNN이 이러한 과제들을 다룰 때 직면하는 문제 중 하나는 죽거나 폭발하는 기울기(vanishing/exploding gradients)로 인한 어려움입니다. 이 문제의 해법은 LSTM 네트워크의 적용입니다.\n\n<div class=\"content-ad\"></div>\n\nFigure 1은 완전히 연결된 인공 신경망(ANNs)과 순환 신경망(RNNs) 간의 주요 구조적 차이를 보여줍니다. 이 간단한 예에서는 (X1,Y1) 및 (X2,Y2)의 값이 Y3의 새로운 값 계산에 사용됩니다. 실제로는 ANN과 RNN이 많은 입력-출력 쌍으로 훈련됩니다. 훈련 과정이 완료되면 네트워크는 새로운 값을 예측하는 데 사용됩니다. 이 프로세스에 익숙하지 않다면, 이 기사의 끝에 유용한 참고 자료를 추가했습니다. 여기에 이 프로세스를 설명한 나의 시도도 곁들였습니다. ANNs와 RNNs 사이의 훈련 및 예측의 일반적인 아이디어는 비슷하지만, 구조적으로 큰 차이가 있습니다. RNN에서는 Y1과 Y2의 값이 X1과 X2 대신 네트워크를 훈련하는 데 사용됨을 주목하십시오. 또한 첫 번째 단위와 두 번째 단위를 연결하는 가중치가 있으며, 이는 이전 단위에서 온 활성화를 나타냅니다. 이 가중치는 RNN의 \"기억\" 구성 요소를 나타냅니다. 더 큰 가중치는 RNN이 이전 값에 더 많은 중요성을 부여함을 의미하고, 더 작은 가중치는 RNN이 과거 값을 잘 기억하지 못한다는 것을 의미합니다. 이것은 신경망 구조의 가중치이므로, 그 값은 프로세스 중에 학습되며, RNN은 재현하려는 순서가 더 많은지 덜 많은지를 결정할 수 있습니다.\n\n![Image](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_1.png)\n\nRNN의 훈련 및 적용 중 중요한 측면은 네트워크가 읽고 훈련 및 예측에 사용하는 값 시퀀스의 길이입니다. 시퀀스 길이가 15라고 가정해 봅시다. 이는 RNN이 15개의 입력 값을 읽은 후 16번째 값을 찾아 훈련한다는 것을 의미합니다(항상 그렇지는 않습니다. 동적 RNN도 있기 때문입니다). 시퀀스 길이로 돌아가보면, 더 긴 시퀀스 길이는 RNN이 최종 출력에 여러 읽기를 통합할 수 있어 유익합니다. 그러나 더 긴 시퀀스 길이는 사라지는/폭주하는 그래디언트를 유발합니다. LSTM 네트워크는 이 문제를 어떻게 극복할까요? \n\n# LSTM 네트워크\n\n<div class=\"content-ad\"></div>\n\nLSTM 네트워크는 어떤 정보를 “기억”하고 어떤 정보를 “잊을지” 결정하도록 훈련됩니다. RNN에서는 이전 유닛의 활성화에만 적용되는 메모리 구성 요소에 대한 가중치가 있습니다. 그러나 LSTM에서는 메모리 구성 요소의 개념이 장기 메모리 구성 요소(셀 상태)와 단기 메모리 구성 요소(은닉 상태)로 대체됩니다. 각 구성 요소는 서로 다른 게이트에 분산된 일련의 편향 및 가중치와 관련이 있습니다. 이는 각 입력이 네트워크에서 얼마나 많은 정보를 유지하고 얼마나 버릴지 결정하는 게이트(또는 단계)를 통과한다는 것을 의미합니다. 이 결정은 훈련 과정 중에 학습된 가중치와 편향 값에 기반합니다.\n\n그림 2는 단일 입력을 읽는 매우 간단한 LSTM 네트워크 스케치를 보여줍니다. 실제 LSTM 네트워크 유닛을 살펴보기 전에이 단순화된 다이어그램을 먼저 분석하겠습니다. RNN을 나타내는 이전 그림과 얼마나 다른지에 주목하세요. 기억할 점 중 첫 번째는 입력 값 외에도 LSTM 네트워크에는 단기 및 장기 메모리 구성 요소가 있다는 것입니다. 이러한 구성 요소는 공식적으로 셀 상태(C)와 숨겨진 상태(h)로 알려져 있습니다. 이 표기법은 나중에 사용되겠지만, 우리는 현재 이전 이름을 사용할 것입니다. 입력 및 메모리 구성 요소는 세 가지 서로 다른 게이트를 통과합니다: 삭제, 입력 및 출력.\n\n- 삭제 게이트는 장기 기억의 얼마나 보관해야 하는지를 결정합니다. 이 게이트는 현재 입력뿐만 아니라 단기 메모리 구성 요소를 고려하여 0과 1 사이의 값을 계산하여 장기 메모리 구성 요소를 곱합니다. 0의 삭제 게이트는 네트워크가 이전 정보를 보존하지 않음을 의미합니다. 그 답은 새로운 입력에만 기초합니다.\n- 입력 게이트는 새 정보가 장기 메모리 구성 요소에 보존되어야 하는 양을 결정합니다. 이 게이트의 출력은 다음 입력에 보존되는 장기 기억 구성 요소에 추가됩니다. 이 구성 요소가 삭제 및 입력 게이트에만 연결된다는 점에 유의하십시오. 이는 각 반복에서 장기 기억이 무엇을 버리고 어떤 정보를 추가해야 하는지에 따라 업데이트된다는 것을 의미합니다.\n- 출력 게이트는 입력 및 단기 메모리 구성 요소를 고려하고 이전 단기 메모리 구성 요소로 저장될 새로운 장기 메모리 구성 요소의 양을 계산합니다. 이는 LSTM 네트워크에서 나온 최종 값이 장기 및 단기 메모리 구성 요소뿐만 아니라 출력 게이트도 고려하여 계산된다는 것을 의미합니다.\n\n<img src=\"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n이제 LSTM 네트워크 셀의 구조를 파악했으니 여기서 발생하는 계산에 더 가깝게 살펴보겠습니다. Figure 3은 LSTM 네트워크 셀을 더 자세히 보여줍니다. 입력, 단기 기억 구성 요소 및 장기 기억 구성 요소는 각각 x, h 및 C로 표시됩니다. 이들 각각의 글자는 분석 중인 시간 기간에 해당하는 아래 첨자를 가지고 있습니다. t-1의 아래 첨자는 값이 이전 반복에 속한다는 것을 의미합니다. 예를 들어, forget gate는 현재 입력(xt)과 이전 반복의 단기 기억 구성 요소(ht-1)를 고려합니다. 게이트들은 또한 일련의 가중치와 편향을 고려합니다. forget 및 output 게이트에는 각각 3개의 매개변수가 있습니다:\n\n- 편향(bxf, bxo)\n- 입력을 곱하는 가중치(wxf, wxo)\n- 단기 기억 구성 요소를 곱하는 가중치(whf, who)\n\n가중치와 편향은 활성화 함수로 들어가기 전에 입력 값에 곱해지고 더해집니다. 이 예에서 forget 및 output 게이트 모두 시그모이드 활성화 함수를 가지며 그 최종 활성화(af, ao)는 Figure 3 우측에 표시됩니다. 이러한 게이트와 달리, input 게이트는 두 개의 활성화 함수, 시그모이드 및 tanh가 있으며 해당 가중치와 편향을 가집니다. 이는 단일 LSTM 네트워크 단위에 대해 훈련해야 할 매개변수의 총 수가 12임을 의미합니다.\n\nLSTM 네트워크 셀에 대해 이해해야 할 마지막 중요한 측면은 새로운 C 및 h가 어떻게 계산되는지입니다. 이전 장기 기억 구성 요소는 먼저 forget 게이트의 출력과 곱해진 후 입력 게이트의 결과에 추가됩니다. 이는 forget 게이트가 C의 얼마나 다음 반복에 전달하는지를 결정하고, input 게이트가 C의 새 값에 얼마나 추가할지를 결정합니다. 단기 기억 구성 요소 계산을 위해 output 게이트의 결과는 새로운 C의 tanh와 곱해집니다. 이는 output 게이트가 장기 기억 구성 요소를 다음 반복에 얼마나 전달할지 결정합니다. C의 값이 1 이상일 수 있으므로, 값이 -1과 1 사이로 제한되도록 tanh 연산이 적용됩니다.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_3.png)\n\n입력이 모든 게이트를 통과하면, 새로운 C와 h가 다음 반복으로 전달되어 새 입력과 상호 작용합니다(그림 4). 이 과정은 시퀀스의 모든 값에 대해 반복되며, 해당 시퀀스의 최종 h에 도달할 때까지 반복됩니다.\n\n![이미지](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_4.png)\n\n# 앞으로 나아가기\n\n<div class=\"content-ad\"></div>\n\nLSTM 네트워크는 다른 인공 신경망(ANN)에서 사용되는 방법론과 유사한 방법으로 훈련될 수 있습니다. 문제에 따라 각 순전파 사이클 이후 업데이트되는 손실 함수를 정의합니다. 그런 다음 이 손실 함수를 사용하여 역전파 과정을 통해 가중치와 편향을 업데이트합니다. RNN 및 LSTM 네트워크의 경우, 역전파는 일반적으로 모든 반복 유닛을 통해 가중치와 편향을 누적하는 과정이기 때문에 시간을 거슬러 역전파(backpropagation through time, BPTT)라고합니다. 이는 LSTM 네트워크의 단일 유닛을 읽는 LSTM 네트워크 셀에서 순전파 과정이 어떻게 진행되는지 설명하는 간단한 구현과 순전파, 역전파 과정에 대해 상세히 설명하는 주피터 노트북입니다.\n\n그림 5는 LSTM 네트워크 셀에서 단일 유닌을 읽는 순전파 과정의 예시를 보여줍니다. h의 최종 값이 네트워크 내 모든 게이트를 통해 전달되는 정보를 함께 전달하는 반면, 최종 C는 출력 게이트와 상호작용하지 않는 것에 주목하세요. 이 게이트들 각각이 보존할 정보와 잊을 정보를 규제자로 작용합니다. 입력과 상호작용하는 최적의 방법을 학습하는 완전히 연결된 ANN에서 가중치와 편향이 학습되는 것과 유사하게, LSTM 네트워크에서 매개변수는 보존하거나 버릴 최적의 정보 양을 학습하기 위해 훈련됩니다.\n\n![image](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_5.png)\n\n# 더 많은 유닛?\n\n<div class=\"content-ad\"></div>\n\n지금까지의 숫자와 예제는 단일 유단 LSTM 네트워크를 보여주었지만, 다른 유형의 네트워크와 마찬가지로 LSTM 네트워크는 여러 개의 유닌을 가질 수 있습니다. 단위 수에 따라 매개 변수 수는 어떻게 변하나요? 두 개의 유닌을 갖는 LSTM 네트워크의 경우, 학습할 매개 변수가 12개가 아닌 32개가 있습니다. 추가된 20개의 매개 변수는 어디에 있을까요? 그러면, 이제 조금 복잡해 질 것입니다. 이를 여러 부분으로 나눠서 살펴보겠습니다.\n\n첫 번째 유닛에는 12개의 매개 변수가 있습니다. 이전에 설명한 것과 같은 매개 변수들입니다: 입력을 곱하는 4개의 가중치, 숨겨진 상태(h)를 곱하는 4개의 가중치, 그리고 각 게이트에 대한 4개의 바이어스입니다. 두 번째 유닌도 12개의 관련된 매개 변수를 가지고 있습니다. 이는 지금까지 총 24개의 매개 변수를 가지게 되었다는 것을 의미합니다. \n\nLSTM 네트워크는 특정 유형의 RNN이므로 각 유닌 사이에 연결이 있을 것입니다. 이는 유닌 1에서 처리된 정보가 유닌 2로 전달된다는 것을 의미합니다. 각각의 연결은 고유의 가중치를 갖습니다. 두 개의 유닌을 갖는 LSTM 네트워크에서, 이전에 언급된 24개의 매개 변수 외에, 유닌 2의 각 게이트와 유닌 1의 각 게이트 사이의 연결 및 유닌 1의 숨겨진 상태와 유닌 2의 게이트 사이의 연결에 해당하는 8개의 매개 변수가 추가로 필요합니다. 그림 7은 유닌 2의 잊기 게이트에서 활성화를 계산하는 방법을 보여줍니다. 이 게이트가 이전 게이트와 이전 숨겨진 상태에 연결되어 있다는 점에 주목하세요. 그림에는 새로운 가중치가 5개만 표시되어 있지만, 실제로는 첫 번째 유닌의 숨겨진 상태가 두 번째 유닌의 각 게이트에 연결되기 때문에 8개의 가중치가 있습니다. n개의 유닌에 대한 매개 변수 수는 12n+4n(n-1) 또는 간소화된 표현으로 8(n+n²/2)입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_7.png\" />\n\n# Going backwards\n\n인공 신경망(ANNs)에서 흔히 볼 수 있는 바와 같이, 역전파 프로세스는 일반적으로 이해하고 구현하기 가장 어려운 부분입니다. 단일 유닛 LSTM 네트워크에서는 각 역전파가 4개의 편향과 8개의 가중치를 업데이트해야 하며, h(t-1) 및 C(t-1)도 업데이트해야 합니다. h(t-1)가 출력 게이트에 의존하고 현재 C는 다시 입력 및 망각 게이트에 따라 달라짐을 주목해야 합니다. 손실에 대한 편도함수를 계산할 때 이 사항을 고려하는 것이 중요합니다. 이전에 언급한 바와 같이, 이 Jupyter 노트북에는 역전파 프로세스를 포함한 간단한 LSTM 네트워크를 구축하는 데 필요한 모든 방정식이 포함되어 있습니다. 그림 8은 각 편도함수를 계산하는 데 도움이 되는 매개변수 간 의존성을 보여줍니다.\n\n<img src=\"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_8.png\" />\n\n<div class=\"content-ad\"></div>\n\n# 응용 프로그램\n\n다음 섹션에는 LSTM 네트워크의 세 가지 응용 프로그램 예시가 포함되어 있습니다. 예시는 간단한 순서로 제공됩니다. 각 예시에 대한 파이썬 코드를 이 Jupyter 노트북에서 찾을 수 있습니다.\n\n## 연속 함수 모델링을 위한 바닐라 LSTM 네트워크\n\n이것은 처음부터 LSTM 네트워크를 구현하는 매우 간단한 예시입니다. 여기서 배울 중요한 교훈은 LSTM 네트워크에 데이터를 공급하기 전에 데이터를 올바르게 준비하는 중요성입니다. LSTM 네트워크로 모델링하고 싶은 연속 함수가 있다면, 먼저 입력-타겟 데이터의 쌍을 생성해야 합니다 (Figure 1 참조). 이 데이터는 시퀀스 길이에 따라 달라집니다. 예를 들어, 시퀀스 길이가 15인 경우, 각 입력 항목은 15개의 값이 포함되며 16번째 값은 해당 입력의 타겟이 됩니다. 네트워크에 입력하기 전에 데이터를 정규화하는 것도 중요합니다. 이 예시에서는 sin(x) 함수와 함께 웰에서의 석유 생산 행동을 모델링하기 위해 간단한 LSTM 네트워크가 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 워드 예측기를 구축하기 위한 바닐라 LSTM 네트워크  \n\n이 예시에서는 이전의 바닐라 LSTM 네트워크가 워드 예측 문제에 적용되었습니다. 짧은 텍스트로 훈련된 후, 모델은 다음에 나올 단어를 예측합니다. 실제로 워드 처리 및 워드 예측 문제는 이 예시처럼 다가가지 않습니다. 그러나 LSTM 네트워크의 가능한 응용에 대한 간단하고 명확한 설명입니다.  \n\n## Keras의 LSTM 네트워크를 사용하여 워드 예측기 구축  \n\n이 예시는 Keras의 LSTM 네트워크를 사용하여 긴 텍스트로 훈련된 후 다음 단어가 무엇인지 예측하는 더 현실적인 예제입니다. 이 예시에서는 NLP 문제에서 일반적인 추가인 임베딩 레이어를 사용합니다. 임베딩 레이어는 단어의 정수로 인코딩된 표현(인덱스)을 밀집된 벡터로 변환하여 단어 사이의 관계를 더 잘 모델링하는 데 도움이 되는 고정 크기의 벡터로 변환합니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n인공 신경망 및 특히 순환 신경망을 사용하여 자연어 처리 문제에 접근하거나 연속 데이터를 모델링하는 것은 최근에 개발된 것이 아닙니다. 이 응용 프로그램은 오랫동안 존재해 왔으며 새로운 기능으로 계속 발전하고 있습니다. LSTM 네트워크가 어떻게 작동하는지 이해하고 그것을 특별한 종류의 RNN으로 만드는 요소를 파악하는 것은 결과와 예상대로 작동하지 않을 수 있는 이유에 대한 통찰력을 제공할 수 있습니다. 본문은 LSTM 네트워크에 대한 포괄적인 설명을 포함하고, 그 응용 예시 세 가지를 제시합니다. 대부분의 현재 NLP 도구 및 솔루션은 다른 네트워크 구조에 의존하지만 LSTM 네트워크 내부 작업에 대한 탄탄한 개념은 머신러닝 분야에서 항상 유익할 것입니다. 이것을 장기 기억 셀에 저장하는 것을 기억하세요! 😉\n\n# 참고문헌\n\n- Ng, Andrew. Machine Learning Specialization.\n- Keras 'Embedding' 레이어는 어떻게 작동합니까? CrossValidated 게시물. 2017\n- Cowan, Nelson (2009). 장기, 단기 및 직업기억 사이의 차이점은 무엇인가? — PMC. Prog Brain Res. 2008;169:323–38. doi: 10.1016/S0079–6123(07)00020–9. PMID: 18394484; PMCID: PMC2657600.\n- Erz, Hendrik (2023). ChatGPT를 생산적으로 사용하는 방법 | Hendrik Erz. hendrik-erz.de, 2023년 2월 14일\n- Adams, Tim (2013). Henry Molaison: 우리가 결코 잊지 않을 기억상실자 | 기억 | The Guardian\n- Dittrich, Luke (2016). 기억할 수 없던 두뇌 — 뉴욕 타임즈","ogImage":{"url":"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_0.png"},"coverImage":"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_0.png","tag":["Tech"],"readingTime":11},{"title":"Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기","description":"","date":"2024-05-23 17:20","slug":"2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering","content":"\n\n금일의 데이터 중심 세계에서는 방대한 양의 정보를 활용하여 정확하게 질문에 답하는 능력이 중요합니다. 대형 언어 모델(LLM)을 활용한 질문 응답(QA) 시스템은 이러한 측면에서 큰 가능성을 보여주고 있습니다.\n\n하지만, 이러한 시스템의 정확도와 신뢰성을 보장하는 것은 여전히 중요한 과제입니다.\n\ndata.world의 최근 연구에 따르면, 온톨로지와 지식 그래프를 활용하면 LLM 기반 QA 시스템의 성능을 크게 향상시킬 수 있음을 입증했습니다.\n\n본 글에서는 온톨로지 기반의 쿼리 유효성 검증과 LLM을 활용한 쿼리 복구를 결합한 혁신적인 접근 방식을 탐구하여, 질문 응답에서 전례없는 수준의 정확성을 달성하는 방법을 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# 배경\n\n질문 응답 시스템은 구조화된 또는 구조화되지 않은 데이터 소스에서 정보를 추출하여 사용자 쿼리에 정확하고 관련성 높은 응답을 제공하는 것을 목표로 합니다. 기존의 QA 시스템은 종종 자연어 쿼리의 복잡성과 모호성에 노출되어 최적의 결과를 얻기 어려웠습니다. 지식 그래프와 온톨로지의 등장은 도메인 지식을 표현하고 추론하는 강력한 프레임워크를 제공하여 보다 정교한 QA 방법을 가능케 하였습니다 [2].\n\n대규모 언어 모델인 GPT-4와 같은 모델은 자연어 처리 분야를 혁신적으로 변화시켰으며, 인간과 유사한 텍스트를 이해하고 생성하는 놀라운 능력을 보여주었습니다. 대형 언어 모델은 SQL 또는 SPARQL 쿼리를 사용하여 구조화된 데이터베이스에서 질문에 답변하는 등 다양한 QA 작업에 적용되었습니다 [3]. 그러나 LLM이 생성한 쿼리의 정확도는 기반이 되는 데이터 스키마와 의미에 대한 명확한 지식 부족으로 제한될 수 있습니다.\n\n# Ontology-based Query Check (OBQC)\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png\" />\n\nLLM 기반 QA 시스템의 한계를 해결하기 위해 연구자들은 Ontology 기반 쿼리 체크 (OBQC) 접근 방식을 제안했습니다 [1]. OBQC는 온톨로지에 인코딩된 의미 정보를 활용하여 LLM이 생성한 SPARQL 쿼리의 정확성을 검증합니다. 이 과정은 몇 가지 주요 단계로 이루어집니다:\n\n1. 생성된 SPARQL 쿼리에서 기본 그래프 패턴 (BGP)을 추출하여 쿼리의 그래프 패턴을 나타냅니다 [1].\n2. :쿼리( BGP가 RDF로 바뀐 것을 나타냄)와 :온톨로지(온톨로지 자체를 나타냄)의 두 개의 명명된 그래프를 캡슐화한 결합 그래프를 구성합니다 [1].\n3. SPARQL 쿼리로 구현된 온톨로지 일관성 규칙을 적용하여 :쿼리와 :온톨로지 그래프 사이의 위반을 확인합니다 [1].\n4. 생성된 쿼리에서 구체적인 오류를 식별하고 각 규칙 위반에 대한 사람이 읽을 수 있는 설명을 생성합니다 [1].\n\nLLM이 생성한 쿼리를 온톨로지의 의미와 비교함으로써 OBQC는 도메인이나 범주 클래스 불일치, 호환되지 않는 속성 사용, 정의되지 않은 속성 등 다양한 유형의 오류를 감지할 수 있습니다. 이 유효성 검사 프로세스는 생성된 쿼리가 기저지식 그래프와 일관된지 확인하여 QA 시스템의 전체 정확성을 향상시키는 데 도움을 줍니다.\n\n<div class=\"content-ad\"></div>\n\n# LLM Repair\n\nOBQC는 생성된 쿼리의 오류를 식별하는 데 능숙하지만, 이러한 오류를 수정하는 메커니즘을 제공하지는 않습니다. 여기서 LLM Repair 구성 요소가 필요합니다. LLM Repair는 OBQC에 의해 제공된 오류 설명을 기반으로 쿼리를 반복적으로 다듬고 수정하는 능력을 활용합니다 [1].\n\n수리 과정은 오류 설명과 부정확한 SPARQL 쿼리를 포함하는 프롬프트를 작성하여 시작됩니다. 이 프롬프트는 그런 다음 LLM에 공급되며, LLM은 의도한 의미와 구조를 보존하면서 식별된 문제를 해결하기 위해 쿼리를 다시 작성하려고 시도합니다 [1]. 수정된 쿼리는 그런 다음 OBQC로 반환되어 확인을 받으며, 유효한 쿼리를 얻거나 최대 반복 횟수에 도달할 때까지 반복적인 피드백 루프를 형성합니다 [1].\n\nLLM Repair는 LLM이 자연어 설명을 이해하고 일관된 응답을 생성하는 능력에 활용합니다. 질문이나 온톨로지에 명시적인 액세스가 필요하지 않고 오류 설명을 활용함으로써, 쿼리를 수정하는 데 효과적으로 학습할 수 있습니다 [1].\n\n<div class=\"content-ad\"></div>\n\n수리 과정이 일정 횟수의 반복 이후 유효한 쿼리를 생성하지 못하면, LLM 수리는 \"알 수 없음\" 또는 \"불확실\" 응답을 반환하여 신뢰할만한 답변을 생성할 수 없음을 표시합니다 [1]. 이 실패 안전 기구는 수리 시도가 실패할 경우 잘못된 또는 오해를 일으킬 수 있는 결과를 시스템이 제공하는 것을 방지합니다.\n\n# 실험 설정 및 결과\n\nOBQC 및 LLM 수리 접근 방식의 효과를 평가하기 위해 연구자들은 Chat with the Data 벤치마크를 사용한 실험을 진행했습니다 [1]. 이 벤치마크에는 기업용 SQL 스키마, 질문-답변 쌍, 그리고 OWL 온톨로지 매핑이 포함되어 있습니다. 테스트된 QA 시스템은 SPARQL 제로샷 프롬프트로 GPT-4였으며, 쿼리는 가상화된 지식 그래프에서 실행되었습니다 [1].\n\n실험 결과는 정확도와 오류 감소에서 상당한 향상을 보여주었습니다:\n\n<div class=\"content-ad\"></div>\n\n- OBQC 및 LLM Repair을 사용하여 전체 실행 정확도가 42.88%에서 72.55%로 향상되었습니다 [1].\n- 시스템에서 잘못된 것으로 식별된 알 수 없는 쿼리가 전체 오류율인 19.44% 중 8%를 차지했습니다 [1].\n- 고복잡도 스키마에 관한 질문의 정확도 향상이 특히 유의미했습니다 [1].\n\n추가 분석 결과, OBQC의 도메인 관련 규칙이 수리의 70%를 담당하는 가장 일반적인 규칙임이 밝혀졌습니다 [1]. 이는 온톨로지에서 도메인 지식을 정확하게 모델링하는 것이 QA 성능을 향상시키는 데 중요한 역할을 한다는 것을 시사합니다.\n\n# 현실 세계의 영향과 응용\n\nOBQC 및 LLM Repair의 유망한 결과들은 이미 현실 세계 응용분야에서 찾아보실 수 있습니다. 기업용 데이터 카탈로그 및 발견 솔루션의 선도 업체인 data.world은 이러한 구성 요소를 AI Context Engine에 통합하였습니다 [1]. AI Context Engine은 구조화된 데이터와의 신뢰할 수 있는 대화를 지원하여 고객이 질문을 하고 정확하고 컨텍스트 인식형 답변을 받을 수 있도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n몇몇 data.world 고객은 AI Context Engine을 도입하여, 다양한 사용 사례에서 향상된 QA 능력을 활용하고 있습니다 [1]. 이는 실제 환경에서 온톨로지 기반 검증과 LLM 기반 복구를 결합한 가치와 영향을 보여줍니다.\n\n## 미래 방향성과 도전 과제\n현재 방법이 높은 성공률을 보여주고 있지만, 미래 연구와 개선을 위한 여러 분야가 아직 남아 있습니다. 하나의 주요 도전 과제는 OBQC를 보다 복잡한 온톨로지 구조에 대응할 수 있도록 확장하는 것입니다. 이는 OWL 어키오름이 포함된 온톨로지 조합(연합, 교집합 또는 다른 논리 연산자)에 대한 처리를 의미합니다 [1]. 이 도전에 대응함으로써 시스템이 쿼리를 풍부하고 표현력 있는 온톨로지에 대해 유효성을 검증하는 능력을 더욱 강화할 수 있을 것입니다.\n\n또 다른 중요한 방향은 해당 접근 방식을 다른 도메인과 데이터 집합으로 일반화하는 것입니다. 현재 실험은 기업용 SQL 스키마와 질문-답변 쌍을 다루는 Chat with the Data 벤치마크에 주로 초점을 맞추었습니다 [1]. 시스템의 성능을 다양한 도메인과 데이터 소스 범위에서 평가함으로써 보다 넓은 적용 가능성과 견고성을 평가할 수 있을 것입니다.\n\n확장성과 계산 비용에 대한 조사도 필요합니다. 온톨로지와 데이터 집합의 크기와 복잡성이 증가함에 따라, OBQC와 LLM Repair 구성 요소의 효율성은 점점 더 중요해집니다 [1]. 최적화된 알고리즘 및 병렬 처리 기술을 개발함으로써 대규모 응용 프로그램에 대한 시스템의 실용성과 반응성을 보장하는 데 도움이 될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n체계 기반 쿼리 유효성 검사와 LLM(언어 모델) 기반 쿼리 수리의 결합은 질문 응답 분야에서 중요한 발전을 나타냅니다. 오전톨로지에 인코딩된 의미 지식과 LLM의 생성적 능력을 활용하여, 이 방법은 전례없는 수준의 정확도와 신뢰성을 실현합니다.\n\n실험 결과와 현실 세계에서의 채택은 이 기법이 신뢰할 수 있고 맥락에 맞는 구조화된 데이터와의 대화를 가능케 함에 대한 엄청난 잠재력을 입증합니다. 조직이 통찰을 도출하고 데이터 기반 결정을 내리는 데 QA 시스템에 점점 더 의존함에 따라, 정확성의 중요성은 지나치게 강조될 수 없습니다.\n\n그러나 이 방법의 전체 잠재력을 실현하기 위해서는 계속된 연구 및 개발 노력이 필요합니다. 더 복잡한 온톨로지 구조를 처리하고, 다양한 도메인에 적용할 수 있도록 일반화하고, 확장성 문제를 해결하는 것이 미래 작업의 주요 분야입니다.\n\n<div class=\"content-ad\"></div>\n\nOBQC와 LLM Repair의 성공은 의미론, 온톨로지, 그리고 지식 그래프가 정확하고 신뢰할 수 있는 QA 시스템을 구축하는 데 중요한 역할을 한다는 점을 강조합니다. 이러한 기본기술에 투자하고 계속해서 가능한 한 경계를 넓힘으로써, 우리는 자연어 인터페이스의 진정한 잠재력을 발휘하고 사용자들이 필요로 하는 정보에 원활하게 액세스할 수 있도록 돕는 것이 가능합니다.\n\n# 참고문헌\n\n[1] Dean Allemang과 Juan F. Sequeda. 2024. “Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue!” 기술 보고서.\n[2] Aidan Hogan 등. 2021. “Knowledge Graphs.” 데이터, 의미론, 그리고 지식에 관한 합성 강의. Morgan & Claypool Publishers.\n[3] Juan Sequeda, Dean Allemang, 그리고 Brad Jesson. 2023. “A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model’s Accuracy for Question Answering on Enterprise SQL Databases.” arXiv 사전인쇄 arXiv:2406.01688.","ogImage":{"url":"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png"},"coverImage":"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png","tag":["Tech"],"readingTime":6},{"title":"깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개","description":"","date":"2024-05-23 17:17","slug":"2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming","content":"\n\n## .to(\"cuda\") 가 무엇을 하는지 이해하고 싶은 분들을 위해\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png)\n\n요즘에는 딥 러닝을 이야기할 때 성능을 향상시키기 위해 GPU를 활용한다고 연관 지어지는 것이 매우 일반적입니다.\n\nGPU(그래픽 처리 장치)는 원래 이미지, 2D 및 3D 그래픽의 렌더링을 가속화하기 위해 설계되었습니다. 그러나 다수의 병렬 작업을 수행할 수 있는 능력으로 인해 그 유용성은 그 이상으로 확장되어 딥 러닝과 같은 응용 프로그램에까지 이어집니다.\n\n<div class=\"content-ad\"></div>\n\n깊은 학습 모델에 GPU를 사용한 것은 2000년대 중후반 경에 시작되었으며 2012년에 AlexNet이 등장하면서 매우 인기를 끌었습니다. AlexNet은 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 디자인한 합성곱 신경망으로, 2012년 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 우승했습니다. 이 승리는 깊은 신경망을 통한 이미지 분류의 효과성 및 대형 모델 학습에 GPU 사용을 보여주어 중요한 이정표가 되었습니다.\n\n이후 이 기술적 발전을 통해 깊은 학습 모델에 GPU를 사용하는 것이 점점 인기를 얻으며, PyTorch나 TensorFlow와 같은 프레임워크 개발에 이바지했습니다.\n\n요즘에는 PyTorch에서 데이터를 GPU로 전송하려면 .to(\"cuda\")만 작성하면 학습이 가속화되는 것으로 예상됩니다. 하지만 실제로 어떻게 GPU 컴퓨팅 성능을 활용하는지 알아볼까요?\n\n신경망, CNNs, RNNs 및 트랜스포머와 같은 깊은 학습 아키텍처는 기본적으로 행렬 덧셈, 행렬 곱셈 및 행렬에 함수를 적용하는 수학 연산을 사용하여 구축됩니다. 따라서 이러한 연산을 최적화하는 방법을 찾으면 깊은 학습 모델의 성능을 개선할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그러니까, 간단하게 시작해 봅시다. 두 벡터 C = A + B를 추가하고 싶다고 상상해 보세요.\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_1.png)\n\n이를 C에서 간단히 구현하는 방법은 다음과 같습니다:\n\n```js\nvoid AddTwoVectors(float A[], float B[], float C[]) {\n    for (int i = 0; i < N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```\n\n<div class=\"content-ad\"></div>\n\n위에서 볼 수 있듯이 컴퓨터는 벡터를 반복해서 각 쌍의 요소를 순차적으로 더해야 합니다. 그러나 이러한 작업은 서로 독립적입니다. i번째 쌍의 요소를 더하는 것은 다른 쌍에 의존하지 않습니다. 그래서 만약 이러한 작업들을 병렬로 실행할 수 있다면 어떨까요?\n\n간단한 접근 방식은 CPU 멀티스레딩을 사용하여 모든 계산을 병렬로 실행하는 것일 것입니다. 그러나 딥러닝 모델에서는 수백만 개 요소를 가진 대규모 벡터를 다루게 됩니다. 일반적인 CPU는 동시에 약 10여 개의 스레드만 처리할 수 있습니다. 이때 GPU가 필요한 것입니다! 현대의 GPU는 수백만 개의 스레드를 동시에 실행할 수 있어 이러한 대규모 벡터에 대한 수학적 연산의 성능을 향상시킵니다.\n\n# GPU 대 CPU 비교\n\nCPU 연산이 GPU보다 단일 작업에서 빠를 수 있지만 GPUs의 장점은 병렬화 능력에 있습니다. 이것의 이유는 그들이 서로 다른 목표로 설계되었기 때문입니다. CPU는 가능한 한 빠르게 연산 순서(스레드)를 실행하는 데 설계되었지만(동시에 약 10여 개의 스레드만 실행할 수 있음) GPU는 수백만 개의 연산을 병렬로 실행하는 데 설계되었습니다(개별 스레드의 속도를 희생하면서).\n\n<div class=\"content-ad\"></div>\n\n아래의 비디오를 확인해보세요:\n\n예를 들어, CPU가 페라리와 같다고 상상해보세요. GPU는 버스입니다. 한 사람을 옮기는 작업이라면, 페라리(CPU)가 더 나은 선택일 것입니다. 그러나 여러 사람을 이동시키는 경우에는, 페라리(CPU)가 한 번에 더 빠르지만, 버스(GPU)는 한 번에 모두를 옮겨 더 빠르게 목적지에 도착하게 됩니다. CPU는 연속적인 작업을 처리하는 데 뛰어나지만 GPU는 병렬 작업에 적합하게 설계되어 있습니다.\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_2.png)\n\n더 높은 병렬 기능을 제공하기 위해 GPU 설계는 데이터 캐싱 및 흐름 제어 보다는 데이터 처리에 더 많은 트랜지스터를 할당합니다. 이는 CPU와는 달리, CPU가 단일 스레드 성능 및 복잡한 명령 실행을 최적화하기 위해 상당 부분의 트랜지스터를 할당하는데 사용하는 것과 대조적입니다.\n\n<div class=\"content-ad\"></div>\n\n아래 그림은 CPU와 GPU의 칩 자원 분포를 보여줍니다.\n\n![CPU vs GPU Resources](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_3.png)\n\nCPU는 강력한 코어와 더 복잡한 캐시 메모리 아키텍처(이를 위해 상당한 양의 트랜지스터를 할당)를 갖고 있습니다. 이 설계는 순차 작업의 신속한 처리를 가능하게 합니다. 반면, GPU는 고수준의 병렬성을 달성하기 위해 많은 코어를 갖는 것을 우선시합니다.\n\n이러한 기본 개념을 이해했으니, 실전에서 이러한 병렬 처리 능력을 어떻게 활용할 수 있을까요?\n\n<div class=\"content-ad\"></div>\n\n# CUDA 소개\n\n딥러닝 모델을 실행할 때, 아마도 PyTorch나 TensorFlow와 같은 인기있는 Python 라이브러리를 사용하게 될 것입니다. 그러나 이러한 라이브러리의 핵심이 C/C++ 코드로 구동된다는 것은 잘 알려져 있습니다. 또한 앞에서 언급했듯이, 처리 속도를 높이기 위해 GPU를 사용할 수 있습니다. 여기서 CUDA가 등장합니다! CUDA는 NVIDIA가 개발한 일반 목적의 처리를 위한 플랫폼으로, Compute Unified Architecture의 약자입니다. 그러므로 게임 엔진에서 그래픽 계산을 처리하는 데 DirectX가 사용되는 것과 달리, CUDA는 개발자가 NVIDIA의 GPU 연산 능력을 그래픽 렌더링에만 한정되지 않고 일반 목적의 소프트웨어 응용프로그램에 통합할 수 있도록 합니다.\n\n이를 구현하기 위해 CUDA는 GPU의 가상 명령어 집합과 특정 작업(예: CPU와 GPU 간의 데이터 이동)에 액세스를 제공하는 간단한 C/C++ 기반 인터페이스인 CUDA C/C++을 제공합니다.\n\n더 나아가기 전에, CUDA 프로그래밍 개념과 용어를 몇 가지 이해해 보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n- 호스트: CPU 및 해당 메모리를 가리킵니다.\n- 장치: GPU 및 해당 메모리를 가리킵니다.\n- 커널: 장치(GPU)에서 실행되는 함수를 가리킵니다.\n\n그래서 CUDA를 사용하여 작성된 기본 코드에서 프로그램은 호스트(CPU)에서 실행되며, 데이터를 장치(GPU)에 전송한 후 장치(GPU)에서 실행될 커널(함수)을 시작합니다. 이러한 커널은 병렬로 여러 스레드에 의해 실행됩니다. 실행이 완료되면 결과는 장치(GPU)에서 호스트(CPU)로 다시 전송됩니다.\n\n그러니까 두 벡터를 더하는 문제로 돌아가 봅시다:\n\n```js\n#include <stdio.h>\n\nvoid AddTwoVectors(float A[], float B[], float C[]) {\n    for (int i = 0; i < N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n\nint main() {\n    ...\n    AddTwoVectors(A, B, C);\n    ...\n}\n```\n\n<div class=\"content-ad\"></div>\n\nCUDA C/C++에서 프로그래머는 CUDA 스레드에 의해 병렬로 N번 실행되는 C/C++ 함수 인 켤널이라고 불리는 함수를 정의할 수 있습니다.\n\n켤널을 정의하려면 __global__ 선언 지정자를 사용하고, 이 켤널을 실행하는 CUDA 스레드의 수는 ... 표기법을 사용하여 지정할 수 있습니다:\n\n```js\n#include <stdio.h>\n\n// 켤널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n    ...\n    // N개의 스레드로 켤널 호출\n    AddTwoVectors<<<1, N>>>(A, B, C);\n    ...\n}\n```\n\n각 스레드는 켤널을 실행하고 내장 변수를 통해 켤널 내에서 액세스할 수있는 고유한 스레드 ID threadIdx가 제공됩니다. 위의 코드는 크기가 N 인 두 벡터 A와 B를 더하여 결과를 벡터 C에 저장합니다. 순차적으로 각 쌍-wise 추가를 실행하는 루프 대신, CUDA는 우리에게 모든 이러한 작업을 N 개의 스레드를 사용하여 동시에 수행할 수 있도록 허용합니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 이 코드를 실행하기 전에 다른 수정 작업을 해야 합니다. 커널 함수는 장치(GPU) 내에서 실행되기 때문에 모든 데이터는 장치 메모리에 저장되어야 합니다. 다음 CUDA 내장 함수를 사용하여 이 작업을 수행할 수 있습니다:\n\n```js\n#include <stdio.h>\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B, C를 위한 배열\n\n    ...\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B, C에 대한 장치 포인터\n\n    // 벡터 A, B, C에 대한 장치 메모리 할당\n    cudaMalloc((void **)&d_A, N * sizeof(float));\n    cudaMalloc((void **)&d_B, N * sizeof(float));\n    cudaMalloc((void **)&d_C, N * sizeof(float));\n\n    // 호스트에서 디바이스로 벡터 A와 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N 개의 스레드로 커널 호출\n    AddTwoVectors<<<1, N>>>(d_A, d_B, d_C);\n    \n    // 디바이스에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n}\n```\n\n커널에 변수 A, B, C를 직접 전달하는 대신 포인터를 사용해야 합니다. CUDA 프로그래밍에서는 커널 런치 내에서 호스트 배열(예: 예제의 A, B, C)을 직접 사용할 수 없습니다. CUDA 커널은 장치 메모리에서 작동하므로 커널이 작동하도록 장치 포인터(d_A, d_B, d_C)를 전달해야 합니다.\n\n이를 넘어서 cudaMalloc을 사용하여 장치에 메모리를 할당하고, cudaMemcpy를 사용하여 호스트와 장치 간에 데이터를 복사해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n이제 벡터 A와 B의 초기화를 추가하고 코드 끝에 cuda 메모리를 새로고침할 수 있습니다.\n\n```js\n#include <stdio.h>\n\n// Kernel 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n    \n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B, C에 대한 배열\n\n    // 벡터 A와 B 초기화\n    for (int i = 0; i < N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B, C에 대한 장치 포인터\n\n    // 벡터 A, B, C에 대한 메모리 장치에 할당\n    cudaMalloc((void **)&d_A, N * sizeof(float));\n    cudaMalloc((void **)&d_B, N * sizeof(float));\n    cudaMalloc((void **)&d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 벡터 A 및 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N 스레드를 사용하여 커널 호출\n    AddTwoVectors<<<1, N>>>(d_A, d_B, d_C);\n    \n    cudaDeviceSynchronize(); // 커널 호출 뒤 cudaDeviceSynchronize() 추가\n\n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\n또한, 커널 호출 후에 cudaDeviceSynchronize();를 추가해야 합니다. 이 함수는 호스트 스레드를 장치와 동기화하는 데 사용됩니다. 이 함수가 호출되면 호스트 스레드는 계속 실행하기 전에 이전에 발행된 모든 CUDA 명령이 장치에서 완료될 때까지 기다립니다.\n\n또한 GPU에서 버그를 식별할 수 있도록 일부 CUDA 오류 확인을 추가하는 것이 중요합니다. 이 확인을 추가하지 않으면 코드가 계속해서 호스트 스레드(CPU)를 실행하고 CUDA 관련 오류를 식별하는 것이 어려울 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n아래에 두 기술의 구현이 있습니다.\n\n```js\n#include <stdio.h>\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n    \n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B 및 C를 위한 배열\n\n    // 벡터 A와 B를 초기화\n    for (int i = 0; i < N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B 및 C의 장치 포인터\n\n    // 장치에서 벡터 A, B 및 C에 대한 메모리 할당\n    cudaMalloc((void **)&d_A, N * sizeof(float));\n    cudaMalloc((void **)&d_B, N * sizeof(float));\n    cudaMalloc((void **)&d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 벡터 A와 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N개의 스레드로 커널 호출\n    AddTwoVectors<<<1, N>>>(d_A, d_B, d_C);\n\n    // 오류 확인\n    cudaError_t error = cudaGetLastError();\n    if(error != cudaSuccess) {\n        printf(\"CUDA 오류: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n    \n    // 모든 CUDA 스레드가 실행될 때까지 대기\n    cudaDeviceSynchronize();\n    \n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\nCUDA 코드를 컴파일하고 실행하려면 시스템에 CUDA 툴킷이 설치되어 있는지 확인해야 합니다. 그런 다음 NVIDIA CUDA 컴파일러인 nvcc를 사용하여 코드를 컴파일할 수 있습니다. 만약 컴퓨터에 GPU가 없다면 Google Colab을 사용할 수 있습니다. Runtime → 노트 설정에서 GPU를 선택한 후 code.cu 파일에 코드를 저장하고 다음과 같이 실행하면 됩니다:\n\n```js\n%%shell\nnvcc example.cu -o compiled_example # 컴파일\n./compiled_example # 실행\n\n# 버그 감지 산소화 도구로 코드 실행도 가능합니다\ncompute-sanitizer --tool memcheck ./compiled_example \n```\n\n<div class=\"content-ad\"></div>\n\n그러나, 우리의 코드는 아직 완벽하게 최적화되지 않았습니다. 위의 예시에서는 크기가 N = 1000인 벡터를 사용했습니다. 그러나 이는 GPU의 병렬화 능력을 완전히 보여주지 못하는 작은 숫자입니다. 또한, 딥러닝 문제를 다룰 때는 종종 수백만 개의 매개변수를 가진 대규모 벡터를 다루게 됩니다. 그러나, 예를 들어 N = 500000으로 설정하고 위의 예시와 같이 1, 500000로 커널을 실행하면 오류가 발생할 것입니다. 이러한 작업을 개선하고 수행하기 위해서는 먼저 CUDA 프로그래밍의 중요한 개념인 Thread 계층 구조를 이해해야 합니다.\n\n# Thread 계층 구조\n\n커널 함수를 호출할 때는 블록의_개수, 블록당_쓰레드_개수 표기법을 사용합니다. 따라서, 위의 예시에서는 1개의 블록을 N개의 CUDA 쓰레드로 실행했습니다. 그러나, 각 블록은 지원할 수 있는 쓰레드 개수에 제한이 있습니다. 이는 블록 내의 모든 쓰레드가 동일한 스트리밍 멀티프로세서 코어에 있어야 하고 해당 코어의 메모리 자원을 공유해야 하기 때문에 발생합니다.\n\n다음 코드 스니펫을 사용하여 이 제한을 확인할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nint device;\ncudaDeviceProp props;\ncudaGetDevice(&device);\ncudaGetDeviceProperties(&props, device);\nprintf(\"블록당 최대 스레드 수: %d\\n\", props.maxThreadsPerBlock);\n```\n\n현재 코랩 GPU에서 스레드 블록 당 최대 1024개의 스레드가 포함될 수 있습니다. 그래서 우리는 예제에서 대량의 벡터를 처리하기 위해 훨씬 더 많은 스레드를 실행하기 위해 더 많은 블록이 필요합니다. 또한, 아래 그림에서 보여지는 대로 블록은 그리드로 구성됩니다.\n\n![CUDA Programming](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_4.png)\n\n이제 스레드 ID는 다음과 같이 액세스할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```c\n__global__ void AddTwoVectors(float A[], float B[], float C[], int N) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) // 배열 범위를 초과하지 않도록\n        C[i] = A[i] + B[i];\n}\n``` \n\n그래서 우리의 스크립트는 다음과 같아졌습니다:\n\n```c\n#include <stdio.h>\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[], int N) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) // 배열 범위를 초과하지 않도록\n        C[i] = A[i] + B[i];\n}\n\nint main() {\n    int N = 500000; // 벡터 크기\n    int threads_per_block;\n    int device;\n    cudaDeviceProp props;\n    cudaGetDevice(&device);\n    cudaGetDeviceProperties(&props, device);\n    threads_per_block = props.maxThreadsPerBlock;\n    printf(\"블록 당 최대 쓰레드 수: %d\\n\", threads_per_block); // 1024\n\n    float A[N], B[N], C[N]; // 벡터 A, B 및 C를 위한 배열\n\n    // 벡터 A와 B 초기화\n    for (int i = 0; i < N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B 및 C를 위한 장치 포인터\n\n    // 벡터 A, B 및 C를 위한 장치에 메모리 할당\n    cudaMalloc((void **)&d_A, N * sizeof(float));\n    cudaMalloc((void **)&d_B, N * sizeof(float));\n    cudaMalloc((void **)&d_C, N * sizeof(float));\n\n    // 벡터 A와 B를 호스트에서 장치로 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // 여러 블록과 블록 당 쓰레드 수로 커널 호출\n    int number_of_blocks = (N + threads_per_block - 1) / threads_per_block;\n    AddTwoVectors<<<number_of_blocks, threads_per_block>>>(d_A, d_B, d_C, N);\n\n    // 오류 확인\n    cudaError_t error = cudaGetLastError();\n    if (error != cudaSuccess) {\n        printf(\"CUDA 오류: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    // 모든 CUDA 쓰레드가 실행될 때까지 대기\n    cudaDeviceSynchronize();\n\n    // 벡터 C를 장치에서 호스트로 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\n# 성능 비교\n\n\n<div class=\"content-ad\"></div>\n\n다음은 다른 벡터 크기에 대해 CPU 및 GPU 연산을 비교한 것입니다.\n\n![Comparison of CPU and GPU computation](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_5.png)\n\n어떤 경우에는 대규모 벡터 크기 N에 대해 GPU 처리의 이점이 뚜렷해집니다. 또한, 시간 비교는 커널/함수의 실행만을 고려한 것임을 기억해주세요. 호스트와 장치 간 데이터 복사에 소요되는 시간은 고려되지 않았는데, 일반적으로 큰 문제가 아닐 수 있지만, 우리의 경우에는 단순 덧셈 연산만 수행하기 때문에 상당히 중요합니다. 따라서, GPU 계산은 고도로 계산 집약적이고 또한 고도로 병렬화된 계산을 다룰 때만 그 이점을 나타냄을 기억하는 것이 중요합니다.\n\n# 다차원 스레드\n\n<div class=\"content-ad\"></div>\n\n좋아요, 이제 간단한 배열 작업의 성능을 향상시키는 방법을 알게 되었습니다. 그러나 딥 러닝 모델을 다룰 때는 행렬 및 텐서 작업을 처리해야 합니다. 이전 예제에서는 N 스레드를 사용하여 1차원 블록만 사용했습니다. 그러나 최대 3차원까지 다차원 스레드 블록을 실행할 수도 있습니다. 행렬 작업을 실행해야 할 경우 편리하게 NxM 스레드의 스레드 블록을 실행할 수 있습니다. 이 경우에는 행 = threadIdx.x, 열 = threadIdx.y와 같이 행렬 행 및 열 인덱스를 얻을 수 있습니다. 또한 편리하게 number_of_blocks 및 threads_per_block을 정의하는 데 dim3 변수 유형을 사용할 수 있습니다.\n\n아래 예제는 두 행렬을 더하는 방법을 보여줍니다.\n\n```js\n#include <stdio.h>\n\n// Kernel definition\n__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {\n    int i = threadIdx.x;\n    int j = threadIdx.y;\n    C[i][j] = A[i][j] + B[i][j];\n}\n\nint main() {\n    ...\n    // 1개의 NxN 스레드 블록을 사용하여 커널 호출\n    dim3 threads_per_block(N, N);\n    AddTwoMatrices<<<1, threads_per_block>>>(A, B, C);\n    ...\n}\n```\n\n이 예제를 여러 블록을 처리할 수 있도록 확장할 수도 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n#include <stdio.h>\n\n// Kernel definition\n__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i < N && j < N) {\n        C[i][j] = A[i][j] + B[i][j];\n    }\n}\n\nint main() {\n    ...\n    // Kernel invocation with 1 block of NxN threads\n    dim3 threads_per_block(32, 32);\n    dim3 number_of_blocks((N + threads_per_block.x - 1) ∕ threads_per_block.x, (N + threads_per_block.y - 1) ∕ threads_per_block.y);\n    AddTwoMatrices<<<number_of_blocks, threads_per_block>>>(A, B, C);\n    ...\n}\n```\n\n이런 멀티 차원 데이터를 다루는 법을 알게 되어서 좋습니다. 또한, 커널 내에서 함수를 호출하는 방법을 알아보겠습니다. 기본적으로 이는 __device__ 선언 지정자를 사용하여 간단히 수행할 수 있습니다. 이는 기기(GPU)에서 직접 호출할 수 있는 함수를 정의합니다. 따라서 이러한 함수들은 오직 __global__ 또는 다른 __device__ 함수에서만 호출할 수 있습니다. 아래 예시는 시그모이드 연산을 벡터에 적용하는 방법을 보여줍니다.\n\n```js\n#include <math.h>\n\n// Sigmoid function\n__device__ float sigmoid(float x) {\n    return 1 / (1 + expf(-x));\n}\n\n// Kernel definition for applying sigmoid function to a vector\n__global__ void sigmoidActivation(float input[], float output[]) {\n    int i = threadIdx.x;\n    output[i] = sigmoid(input[i]);\n   \n}\n```\n\n<div class=\"content-ad\"></div>\n\n그래서, 이제 CUDA 프로그래밍의 기본적인 중요한 개념을 알았으니 CUDA 커널을 만들기 시작할 수 있어요. 딥 러닝 모델의 경우, 그들은 기본적으로 합, 곱셈, 컨볼루션, 정규화 등과 같은 매트릭스 및 텐서 연산들의 집합입니다. 예를 들어, 단순한 행렬 곱셈 알고리즘은 다음과 같이 병렬화될 수 있어요:\n\n![Image](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_6.png)\n\n```js\n// GPU 버전\n\n__global__ void matMul(float A[M][N], float B[N][P], float C[M][P]) {\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row < M && col < P) {\n        float C_value = 0;\n        for (int i = 0; i < N; i++) {\n            C_value += A[row][i] * B[i][col];\n        }\n        C[row][col] = C_value;\n    }\n}\n```\n\n이제 이것을 아래의 두 행렬 곱셈의 일반 CPU 구현과 비교해보세요:\n\n<div class=\"content-ad\"></div>\n\n```js\n// CPU 버전\n\nvoid matMul(float A[M][N], float B[N][P], float C[M][P]) {\n    for (int row = 0; row < M; row++) {\n        for (int col = 0; col < P; col++) {\n            float C_value = 0;\n            for (int i = 0; i < N; i++) {\n                C_value += A[row][i] * B[i][col];\n            }\n            C[row][col] = C_value;\n        }\n    }\n}\n```\n\nGPU 버전에는 더 적은 루프가 있어서 작업이 빨라진다는 것을 알 수 있습니다. 아래는 NxN 행렬 곱셈의 CPU와 GPU 성능 비교입니다:\n\n![performance-comparison](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_7.png)\n\n행렬의 크기가 커질수록 GPU 처리의 성능 향상이 더 큰 것을 관찰할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이제 기본 신경망을 고려해 보세요. 주로 y = σ(Wx + b) 작업을 포함하는데, 아래 그림과 같이 구성됩니다:\n\n![Neural Network Operations](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_8.png)\n\n이러한 작업은 주로 행렬 곱셈, 행렬 덧셈, 배열에 함수를 적용하는 것으로 이루어져 있습니다. 병렬화 기술에 익숙하신 분들이라면 이미 이들을 알고 계실 것입니다. 따라서 이제 GPU에서 실행되는 자체 신경망을 처음부터 구현할 수 있는 능력이 생겼습니다!\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n이 게시물에서는 GPU 처리에 대한 입문적인 개념을 다루어 딥러닝 모델의 성능을 향상시키는 방법에 대해 알아보았어요. 그러나 본 포스트에서 다룬 내용은 기초적인 것들뿐이며, 더 많은 것을 배울 수 있습니다. PyTorch와 Tensorflow와 같은 라이브러리는 최적화 기술을 구현하고 있으며, 최적화된 메모리 액세스, 배치 연산 등과 같은 보다 복잡한 개념들을 활용합니다 (이들은 cuBLAS 및 cuDNN과 같은 CUDA 기반 라이브러리 위에서 구축된 라이브러리를 활용합니다). 그러나 \"cuda\"로 지정하고 GPU에서 딥러닝 모델을 실행할 때 무슨 일이 벌어지는지에 대한 배경 정보를 이해하는 데 이 게시물이 도움이 되기를 바랍니다.\n\n향후 게시물에서는 CUDA 프로그래밍에 관련된 더 복잡한 개념들을 소개할 예정이에요. 의견을 주시거나 다음에 대해 무엇을 쓰기를 원하시는지 알려 주시면 감사하겠어요! 읽어주셔서 너무 감사해요! 😊\n\n# 추가 자료\n\nNVIDIA CUDA 프로그래밍 문서 — NVIDIA CUDA 프로그래밍 가이드.\n\n<div class=\"content-ad\"></div>\n\nCUDA 문서 — NVIDIA의 완전한 CUDA 문서입니다.\n\nCUDA 신경망 훈련 구현 — 순수 CUDA C++로 구현된 신경망 훈련입니다.\n\nCUDA LLM 훈련 구현 — 순수 CUDA C로 구현된 LLM의 훈련입니다.","ogImage":{"url":"/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png"},"coverImage":"/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png","tag":["Tech"],"readingTime":18},{"title":"재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠","description":"","date":"2024-05-23 17:14","slug":"2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction","content":"\n\nPrometheus, Triton, 그리고 Grafana를 사용하여 엔드 투 엔드 모니터링 대시보드를 구축해보세요.\n\nML 시스템을 배포하기 전에, 엔지니어들은 로컬 및 대규모에서 어떻게 성능을 발휘할지 정확한 통찰력이 필요합니다. 병목 현상을 식별하고 예상치 못한 동작을 파악하기 위해.\n\n클래식 ML 추론 파이프라인과 비교하면, 딥 러닝 시스템은 자원 소비, 복잡성 및 확장 가능성의 도전에 따라 낮은 지연 시간, 높은 처리량에 중점을 둔다는 것 때문에 보다 \"중요한\" 및 자세한 모니터링이 필요합니다. 특히, 컴퓨터 비전과 같은 자원 집중적인 응용 프로그램에서 딥 러닝 배포를 위해 ML 엔지니어들은 모니터링에 우선순위를 두어야 합니다.\n\n이 글에서는 배포 설정 및 모니터링의 워크플로우에 대해 다루겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# 목차\n\n1. 성능 모니터링 파이프라인 설정 방법\n\n- 컨테이너\n- 설정 파일\n- 도커 컴포즈\n\n2. 메트릭 스크랩 구성\n\n<div class=\"content-ad\"></div>\n\n프로메테우스 타겟을 추가하기\n- 그라파나 데이터소스 추가하기\n- 헬스체크 대상 스크랩\n\n3. 대시보드 생성\n\n- GPU 메트릭을 위한 패널\n- CPU/RAM 메트릭을 위한 패널\n\n4. 시각화\n\n<div class=\"content-ad\"></div>\n\n다음으로 넘어가기 전에 사용할 도구들을 살펴봅시다:\n\n- 도커는 가벼우고 휴대용한 컨테이너 내에서 애플리케이션을 개발, 배포, 실행할 수 있는 플랫폼입니다 — ML 엔지니어에게 꼭 필요한 도구입니다.\n- 도커 컴포즈는 멀티 컨테이너 애플리케이션을 정의하고 구성하는 도구입니다.\n- cAdvisor는 구글에서 개발한 리소스 사용량 및 컨테이너 성능 지표를 제공해주는 오픈소스 도구입니다.\n- 프로메테우스는 메트릭을 수집하고 저장하는 모니터링 및 경보 시스템으로, 프로메테우스에 대한 전문 지식은 ML/MLOps 엔지니어에게 큰 장점입니다.\n- 그라파나는 모니터링 및 가시성 플랫폼으로, 배포된 시스템의 메트릭을 생성, 시각화, 경보 및 이해할 수 있게 해줍니다. 모니터링 대시보드를 관리하는 것은 MLOps 엔지니어에게 중요한 기술입니다.\n- Triton Inference Server는 NVIDIA에서 개발한 인기 있는 모델 서빙 프레임워크로, 복잡한 ML 모델을 프로덕션 환경에 배포하는 데 중요한 역할을 합니다. Triton에 대한 전문 지식은 MLOps 엔지니어에게 필수적인 기술입니다.\n\n# 1. 도커 컴포즈 설정\n\n각 서비스가 무엇을 하는지 설명하고, 이러한 서비스를 캡슐화하고 실행할 도커 컴포즈를 준비하는 것부터 시작해봅시다.\n\n<div class=\"content-ad\"></div>\n\n다음과 같은 내용이 있습니다:\n\n![이미지](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png)\n\n도커 컴포즈 모니터링 yaml 파일을 살펴보겠습니다.\n\n```yaml\n# cat docker-compose-monitoring.yaml\nversion: '3.4'\n```\n\n<div class=\"content-ad\"></div>\n\n```yaml\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"${PROMETHEUS_PORT}:${PROMETHEUS_PORT}\"\n    container_name: prometheus\n    restart: always\n    volumes:\n      - \"${MONITORING_CONFIGURATIONS}/prometheus.monitoring.yml:/etc/prometheus/prometheus.monitoring.yml\"\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    command:\n      - \"--config.file=/etc/prometheus/prometheus.monitoring.yml\"\n      - \"--enable-feature=expand-external-labels\"\n    depends_on:\n      - cadvisor\n    networks:\n      monitor-net:\n        ipv4_address: ${PROM_IP}\n  grafana:\n    image: grafana/grafana-enterprise:8.2.0\n    container_name: grafana\n    ports:\n      - \"${GRAFANA_PORT}:${GRAFANA_PORT}\"\n    volumes:\n      - ${MONITORING_CONFIGURATIONS}/datasources:/etc/grafana/provisioning/datasources\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PWD}\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}\n    networks:\n      monitor-net:\n        ipv4_address: ${GRAFANA_IP}\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:latest\n    container_name: cadvisor\n    restart: always\n    ports:\n      - \"${CADVISOR_PORT}:${CADVISOR_PORT}\"\n    volumes:\n      - \"/etc/localtime:/etc/localtime:ro\"\n      - \"/etc/timezone:/etc/timezone:ro\"\n      - \"/:/rootfs:ro\"\n      - \"/var/run:/var/run:rw\"\n      - \"/sys:/sys:ro\"\n      - \"/var/lib/docker:/var/lib/docker:ro\"\n    networks:\n      monitor-net:\n        ipv4_address: ${CADVISOR_IP}\n  triton_server:\n    container_name: tis2109\n    image: nvcr.io/nvidia/tritonserver:21.09-py3\n    privileged: true\n    ports:\n      - \"8002:8002\"\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              capabilities: [gpu]\n    volumes:\n      - ${TRITON_MODELS_REPOSITORY}:/models\n    command: [\"tritonserver\",\"--model-repository=/models\", \"--strict-model-config=false\"]\n    networks:\n      monitor-net:\n        ipv4_address: ${TRITON_IP}\nnetworks:\n  monitor-net:\n    driver: bridge\n    internal: false\n    ipam:\n        driver: default\n        config:\n            - subnet: ${SUBNET}\n              gateway: ${GATEWAY}\n```\n\n보시다시피, .yaml 설정에 일부 마스킹된 $'변수'가 있습니다. 이들은 .env 파일 내부에서 자동으로 상속되어 로컬 개발 및 CI/CD 파이프라인에서 최상의 관행을 따르는 흐름을 가지고 있습니다.\n\n이제 .env 파일에 어떤 것이 있는지 살펴봅시다:\n\n```yaml\n# == 모니터링 변수 ==\nPROMETHEUS_PORT=9090\nGRAFANA_PORT=3000\nCADVISOR_PORT=8080\nMONITORING_CONFIGURATIONS=<your_configuration_files에 대한_경로>\n```\n\n<div class=\"content-ad\"></div>\n\n```js\n# == 자격 증명 ==\nGRAFANA_PWD=admin\nGRAFANA_USER=admin\n# == TIS 변수 == \nTRITON_MODELS_REPOSITORY=<당신의_triton_모델_저장소_경로>\n# == 기본 네트워크 ==\nSUBNET=172.17.0.0/16\nGATEWAY=172.17.0.1\n# == 서브넷 IP ==\nTRITON_IP=172.17.0.3\nCADVISOR_IP=172.17.0.4\nPROM_IP=172.17.0.5\nGRAFANA_IP=172.72.0.6\n```\n\n대부분의 변수가 설정되었지만, 여기서 살펴봐야 할 주요한 2가지 변수는 다음과 같습니다:\n\n- MONITORING_CONFIGURATIONS\n이것은 이러한 구조가 있는 폴더를 가리켜야 합니다\n\n```js\n.__ monitoring\n|  |_ datasources\n|  | |_ datasources.yml\n|  |_ prometheus.monitoring.yml\n```\n\n<div class=\"content-ad\"></div>\n\n- TRITON_MODEL_REPOSITORY\n모델 저장소의 구조는 다음과 같아야 합니다:\n\n```js\nmodel_repository\n└── prod_client1_encoder\n    └── 1\n        └──resnet50.engine\n    └── config.pbtxt\n```\n\n프로메테우스 모니터링 파일인 prometheus.monitoring.yml에는 메트릭을 가져올 대상(컨테이너)을 추가할 것입니다.\n데이터 소스 파일인 datasources.yml에는 그라파나 대시보드의 소스로 프로메테우스를 추가할 것입니다. 그렇게 하면 그라파나 UI를 열 때 나타날 것입니다.\n\n# 2. 프로메테우스 스크래핑 구성 정의\n\n<div class=\"content-ad\"></div>\n\n그럼 Prometheus 대상을 구성해 보겠습니다. `prometheus.monitoring.yml` 파일에 작성하겠습니다.\n\n```yaml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n```\n\n```yaml\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['172.17.0.5:9090']\n  - job_name: 'triton-server'\n    static_configs:\n      - targets: ['172.72.0.3:8002']\n  \n  - job_name: 'cadvisor'\n    static_configs:\n      - targets: ['172.72.0.4:8080']\n```\n\n3개의 대상이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 프로메테우스 — 모니터링 프로메테우스 자체를 유지하는 것이 건강한 모니터링을 위한 모범 사례로 작용합니다. 수천 개의 메트릭을 처리하면 병목 현상이 발생할 수 있으며 프로메테우스 자체의 자원 사용량을 알고 있는 것이 유용합니다.\n- Triton Server — 이것은 이 딥러닝 스택의 핵심에 있어 중요합니다. ML 모델을 제공하고 관리하기 때문입니다.\nTriton은 인퍼런스 프로세스 전반에 걸쳐 다양한 메트릭을 제공하는 포트 8002의 내장된 프로메테우스 엔드포인트가 있습니다.\n- cAdvisor — 이 배포에서 컨테이너 전반의 CPU/RAM 사용량 정보를 얻기 위해 사용됩니다.\n\n모두 구성한 뒤, 컴포저를 시작하고 문제가 있는지 검사할 수 있습니다.\n컨테이너를 시작해 봅시다.\n\n```js\ndocker compose -f docker-compose-monitoring.yaml up -d\n```\n\n프로메테우스 대상을 검사해 봅시다.\n\n<div class=\"content-ad\"></div>\n\n- 웹 브라우저로 가서 전체 Prometheus URL(IP:9090)을 입력해주세요.\n- 상태 → 대상(Targets)으로 이동해주세요.\n- 스크래핑 구성에서 각 대상이 정상인지 확인해주세요(녹색).\n\n이러한 사항을 확인한 후에는 Grafana에서 대시보드를 만들어 진행할 수 있습니다.\n\n# #3 대시보드 생성하기\n\nGrafana WebUI 대시보드에 액세스하려면 브라우저를 열고 `localhost:3000`으로 이동해주세요. 여기서 3000은 Grafana 컨테이너를 실행하는 포트입니다.\n\n<div class=\"content-ad\"></div>\n\n로그인 페이지로 이동하면 사용자 이름/암호 필드에 `admin/admin`을 사용하십시오. 더 높은 보안이 권장되지만, 이는 이 기사의 범위에 포함되지 않습니다.\n\nGrafana 웹을 열었으면 다음을 수행해야 합니다:\n\n- 데이터 소스를 우리의 Prometheus 메트릭 스크래퍼 엔드포인트로 지정합니다.\n- 새 대시보드 생성\n- 관심 있는 메트릭을 집계/시각화하기 위해 차트 추가\n\n#3.1 Prometheus 데이터 소스\n\n<div class=\"content-ad\"></div>\n\n왼쪽 패널에서 기어 아이콘(설정)을 클릭하고 DataSources를 선택하세요.\n다음과 같은 뷰가 나타날 것입니다:\n\n\"Add data source\"를 클릭한 후 Time Series Databases 아래에서 `Prometheus`를 선택하세요. Grafana는 여러 종류의 메트릭 스크랩을 지원하고 있습니다. 여기서는 Prometheus를 사용할 것입니다. 이런 뷰가 나타날 것입니다:\n\n<img src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_1.png\" />\n\n여기에는 Prometheus 엔드포인트의 URL을 추가해야 합니다. 우리의 도커 컴포즈 배포에서는 `http://prometheus:9090`을 사용할 것입니다. 이 템플릿을 따르면 `http://container_name:container_port`가 됩니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_2.png\" />\n\n여기까지 오셨군요. 이제 데이터 원본 추가 섹션이 완료되었습니다.\n이제 대시보드를 만들어보겠습니다.\n\n### 3.2 Grafana 대시보드 만들기\n\n왼쪽 패널에서 “+” 표시를 클릭하고 `Dashboard`를 선택하세요. 이렇게 하면 미리 정의된 패널 그룹이 있는 새 대시보드 페이지로 이동합니다. 우리는 모든 것을 처음부터 만들고 있으므로 `Empty Panels`만 사용하여 주요 지표를 표시할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n다음은 한 예제에 대한 따라할 프로세스입니다:\n\n- 새 쿼리를 추가하고 `promql` (Prometheus 쿼리 언어)를 정의합니다.\n- 시각화 유형, 그래프 스타일, 범례를 구성합니다.\n\n다음은 비어 있는 패널의 모습입니다:\n\n이제, 트리튼 추론 서버 모델 서빙 플랫폼을 모니터링하기 위해 몇 가지 사용자 정의 쿼리를 추가할 것입니다. 하지만 먼저 다음 참고 사항을 유념해야 합니다:\n\n<div class=\"content-ad\"></div>\n\n첫 번째 쿼리를 설정해보겠습니다. 이 쿼리는 성공적인 요청의 수를 고려하여 모델이 하나의 추론 요청을 수행하는 데 걸리는 시간(밀리초)을 측정할 것입니다. 우리는 시간이 지남에 따라 진행 상황을 보고 싶기 때문에 이 차트는 `시계열(time-series)`이 될 것입니다.\n다음은 해당 지표를 작성하는 쿼리입니다:\n\n```js\n(irate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\n```\n\n쿼리를 해석해 봅시다:\n\n아래에서 쿼리의 모습을 확인할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 새 차트의 설정을 구성할 때, 오른쪽에 다음을 지정할 수 있습니다:\n\n- 차트 유형 — 직선 / 곡선 / T-스텝 라인 중 선택\n- 메트릭 범위 — 메트릭 선택(예: 밀리초(ms))하고 low_range(예: 0)와 high_range(예: 100ms) 정의\n- 사용자 지정 텍스트 — 범례 또는 다른 필드에 표시될 내용\n\n#3.3 시각화 완료\n\n위의 흐름에 따라, 나머지 차트를 생성할 수 있습니다.\n전체 성능 모니터링 차트를 컴파일하려면 나머지 패널을 추가하십시오. 다음 각각에 대해 새 패널을 만들고 해당 세부 정보로 채워넣습니다:\n\n<div class=\"content-ad\"></div>\n\n- GPU 사용된 바이트 - VRAM 사용량의 백분율\n\n```js\n쿼리: nv_gpu_memory_used_bytes{job=\"triton-server\"}/nv_gpu_memory_total_bytes{job=\"triton-server\"}\n차트 유형: 파이\n범례: {인스턴스}\n```\n\n2. GPU 활용도 - 전체 GPU 활용도\n\n```js\n쿼리: nv_gpu_utilization{job=\"triton-server\"}\n차트 유형: 시계열\n범례: NULL\n```\n\n<div class=\"content-ad\"></div>\n\n3. 입력 시간/요청 — 클라이언트가 입력 데이터를 Triton 서버로 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n4. 출력 시간/요청 — 서버가 클라이언트에게 출력을 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000)/ irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n<div class=\"content-ad\"></div>\n\n5. DB 비율 (#요청/#실행) — 성공적인 요청의 전체 요청 대비 비율\n\n```js\n쿼리: sum by (모델,버전) (rate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])/rate(nv_inference_exec_count{job=\"triton-server\"}[$__rate_interval]) )\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n6. 대기 시간/요청 — 요청이 처리되기 전에 대기하는 시간\n\n```js\n쿼리: sum by (모델,버전) ((irate(nv_inference_queue_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval]))\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n<div class=\"content-ad\"></div>\n\n7. 집계된 입력/추론/출력 - 입력 출력 및 추론을 한 차트에 표시합니다.\n\n```js\n질의:\nA: rate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nB: rate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nC: rate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__interval]) / 1000\n\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n우리가 만든 완벽한 대시보드는 다음을 보여줍니다:\n\n- GPU VRAM 이용률\n- 클라이언트에서 서버로의 입력 송신 시간\n- 서버 추론 요청 시간\n- 서버에서 클라이언트로의 출력 송신 시간\n- 성공 요청/전체 요청 비율\n\n<div class=\"content-ad\"></div>\n\n이런 종류의 대시보드는 배포된 스택의 성능 및 스트레스 테스트 속에서의 동작을 모니터링하기 위한 시작점을 제시합니다. \n\n이는 배포의 실패 및 위험 지점을 연구하는 구체적인 방법을 제공하며 SLI(서비스 수준 지표)를 모니터링하는 데 도움이 됩니다.\n\n서비스 수준 지표는 SLA(서비스 수준 계약)를 준수하고 SLO(서비스 수준 목표)를 달성하기 위해 모니터링되는 메트릭입니다. 우리가 만든 대시보드는 제공되는 서비스 수준 계약을 준수하기 위한 목표에 도달하기 위한 가치 있는 통찰을 제공할 수 있습니다. \n\n또한 이는 다중 복제본을 추가하거나 추론 서빙 프레임워크를 실행하는 여러 기계로의 확장 전략을 계획하는 데 도움이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n본 문서에서는 Prometheus와 Grafana를 사용하여 자사의 ML 애플리케이션 및 모델 서빙 프레임워크를 위한 성능 모니터링 스택을 설정하고 구축하는 방법을 소개했습니다.\n\n도커 컴포즈 파일을 준비하는 것부터 시작하여 워크플로우의 각 단계를 설명하고 스택을 배포하고 데이터 원본을 구성하며 대시보드 패널을 생성하고 지표를 집계하는 과정을 마무리했습니다.\n\n모니터링은 MLOps 시스템의 중요한 부분입니다!\n이 튜토리얼을 따라 하면 테스트 환경에서 단일 배포로 ML 애플리케이션을 위한 모니터링 파이프라인을 구조화하고 배포하거나, 클라우드 시나리오 설정에서 여러 입력 소스를 결합하고 전체 스택 배포를 모니터링하는 단일 대시보드 소비자 지점을 갖도록 구성할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 더 많은 내용을 원하신다면!\n\n저는 미디엄에 새롭게 등장했습니다. 만약 이 글을 즐겨보셨다면 박수를 보내주시고 제 계정을 팔로우해주세요 - 정말로 감사하겠습니다! 🚀\n\n![How to ensure your deep learning stack is fail-safe in production](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_3.png)\n\n# 더 많은 글 보기\n\n<div class=\"content-ad\"></div>\n\n이 게시물과 관련성에 따라 정렬되었습니다.","ogImage":{"url":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png"},"coverImage":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png","tag":["Tech"],"readingTime":12},{"title":"자기 주의적 문장 임베딩을 사용한 추천 시스템","description":"","date":"2024-05-23 17:13","slug":"2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem","content":"\n\n![Self-attentive sentence embedding](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png)\n\n# 소개\n\n트랜스포머 레이어와 그의 어텐션 메커니즘은 자연어처리(NLP) 커뮤니티에서 가장 중요한 아이디어 중 하나입니다. 최근 세계를 휩쓴 ChatGPT와 LLaMA와 같은 대규모 언어 모델에서 핵심 역할을 합니다.\n\n하지만 NLP 커뮤니티에서 시작된 다른 흥미로운 아이디어가 있는데, 그 영향은 주로 추천 시스템 분야에서 실현됩니다. 바로 자기주의적 문장 임베딩(self-attentive sentence embedding)입니다. 이 기사에서는 자기주의적 문장 임베딩[1]과 추천 시스템에 적용하는 방법을 살펴볼 것입니다.\n\n\n<div class=\"content-ad\"></div>\n\n# 작동 방식\n\n## 전체 아이디어\n\n이 논문의 주된 아이디어는 문장을 여러 임베딩으로 인코딩하여 문장의 다양한 측면을 포착할 수 있는 더 나은 방법을 찾는 것입니다. 구체적으로, 저자들은 문장을 단일 임베딩으로 인코딩하는 대신 각 행 임베딩이 문장의 다른 측면을 포착하는 2D 행렬로 인코딩하고자 합니다.\n\n<div class=\"content-ad\"></div>\n\n문장 임베딩을 얻으면, 문장 분석, 작가 프로파일링, 텍스트 함의 등 다양한 하위 작업에 사용할 수 있습니다.\n\n## 모델 아키텍처\n\n모델 입력은 문장 배치입니다. 각 문장은 n개의 토큰을 가지고 있습니다. 우리는 i번째 문장을 다음과 같이 표현할 수 있습니다:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_2.png)\n\n<div class=\"content-ad\"></div>\n\nd는 표현의 숨겨진 차원을 나타내며, 우리는 문장 s를 n by d 행렬 H로 인코딩할 수 있습니다:\n\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_3.png)\n\n\n여기서 F는 문장의 토큰을 임베딩으로 인코딩하는 모델 함수를 나타냅니다. 논문에서는 단어 임베딩(Word2Vec을 사용하여 초기화)을 이용하여 토큰을 인코딩하고 이를 양방향 LSTM을 통해 전달합니다. 토큰을 임베딩으로 인코딩하는 다양한 방법이 있기 때문에 일반화를 위해 여기서 F를 사용했습니다.\n\n다음으로, 그들은 임베딩 H를 입력으로 사용하여 어텐션 가중치 행렬 A를 학습합니다:\n\n<div class=\"content-ad\"></div>\n\n\n![Image #1](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_4.png)\n\nHere, the softmax() is applied to the second dimension of its input. We can view the formula as a 2-layer MLP without bias.\n\nAs we can see from the above formula, the attention weight A matrix will have a shape of r by n where r is the number of aspects a sentence can have and n is the sentence length. The authors argue that there are many aspects that make up the semantics of a sentence. Thus, they need r embeddings to focus on different parts of the sentence. In other words, each embedding in A is the sentence attention weight:\n\n![Image #2](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_5.png)\n\n\n<div class=\"content-ad\"></div>\n\nTransformer처럼 이 행렬 A의 시각화를 통해 문장에 대한 각 측면의 주의를 더 잘 이해할 수 있습니다.\n\n마지막으로, 우리는 H와 A를 곱하여 r by d 행렬 M을 얻음으로써 문장 임베딩을 생성합니다:\n\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_6.png)\n\n\nM의 각 행은 토큰 임베딩과 그 토큰에 대한 측면의 가중치의 가중 합입니다. 시각적으로는 이렇게 보입니다:\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_7.png)\n\n## Regularization\n\nIn the paper, they also introduce a new regularization term:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_8.png)\n\n\n<div class=\"content-ad\"></div>\n\n표를 마크다운 형식으로 변경해주세요.\n\nF는 행렬의 프로베니우스 노름을 나타냅니다.\n\n정규화 항은 2가지 목적을 제공합니다:\n\n- 측면 임베딩이 겹칠 수 있기 때문에 다양성을 높입니다. 즉, 유사할 수 있음을 의미합니다.\n- 각 관심사가 가능한 적은 토큰에 초점을 맞추도록 만듭니다.\n\n이 글에서는 정규화가 중점이 아니기 때문에 정규화가 어떻게 작동하는지에 대해 더 읽어볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 추천 시스템에서의 다중 관심사\n\n셀프 어텐티브 문장 임베딩이 어떻게 작동하는지 이해하면, 추천 시스템에서 어떻게 활용할 지에 대해 집중할 수 있습니다.\n\n대규모 추천 시스템에서, 보통 두 개의 타워 모델 아키텍처를 사용합니다. 하나는 사용자 정보를 인코딩하고, 다른 하나는 후보 정보를 인코딩합니다. 사용자 타워에는 사용자의 과거 행동인 클릭, 좋아요, 공유 순서와 사용자 프로필을 사용합니다. 후보 타워에는 아이템 ID와 아이템 카테고리와 같은 후보 특징을 사용합니다.\n\n사용자 임베딩과 후보 임베딩을 내적하여 후보 아이템이 사용자에게 얼마나 관련 있는지를 반영합니다. 레이블은 사용자 시퀀스에서 다음 상호작용할 아이템입니다. 따라서 모델 목표는 사용자가 다음에 상호작용할 아이템을 예측하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n![Self-attentive sentence embedding for the recommendation system](/assets/img/2024-05-23-Self-attentive-sentence-embedding-for-the-recommendation-system_9.png)\n\n위 이미지에서 확인할 수 있듯이 사용자 타워의 출력은 모든 사용자 정보를 포함하는 임베딩입니다. 그러나 단일 사용자 임베딩은 모든 사용자의 다양한 관심사를 포착하는 데 좋지 않습니다. 따라서 더 나은 해결책은 사용자의 관심사를 여러 임베딩으로 인코딩하는 것입니다.\n\n사용자의 다양한 관심사를 어떻게 포착할지에 대한 많은 연구가 이루어졌습니다. 가장 두드러지는 두 가지 방법은 self-attentive 임베딩(SA) [2]과 dynamic routing (DR) [3]입니다. 두 방법 모두 비슷한 성능을 보이지만, self-attentive 방법이 더 안정적이고 훈련 속도가 빠릅니다.\n\nself-attentive 방법이 어떻게 작동하는지 이해하면 추천 시스템에 적용하는 것은 간단합니다. 입력으로 문장 토큰 대신에 유튜브에서 시청한 비디오 ID 목록이나 이커머스 플랫폼에서 클릭/주문한 상품 ID와 같은 사용자 행동을 사용합니다. 출력은 각 임베딩이 문장에서의 측면이 아니라 사용자 관심사를 인코딩합니다!\n\n<div class=\"content-ad\"></div>\n\n\n![Table 1](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_10.png)\n\nIn the ComiRec paper [2], the authors compare the self-attentive method with the dynamic routing method along with other popular models that produce a single user interest:\n\n![Table 2](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_11.png)\n\nAs the table shows, the self-attentive method produces results comparable to those of the dynamic routing method. Still, both multi-interest embedding solutions are significantly better than their single-interest embedding counterparts.\n\n\n<div class=\"content-ad\"></div>\n\n# 마무리\n\n여러 관심사를 포함한 임베딩을 사용하여 모델을 교육하고 제공하는 것에는 많은 미묘한 점이 있습니다. 이 기사에서는 자가 주목 방법이 작동하는 방법과 이를 추천 시스템에서 어떻게 사용하는지에 대해 안내했습니다. 이러한 모델을 교육하고 제공하는 데 대한 더 자세한 내용은 논문을 읽는 것만큼 좋은 자료는 없습니다. 이 기사는 추천 시스템을 위한 다중 관심 프레임워크를 이해하고자 하는 여정에서 참고할 만한 자료입니다.\n\n# 참고\n\n[1] Lin, Zhouhan, et al. “A structured self-attentive sentence embedding.” arXiv preprint arXiv:1703.03130 (2017).\n\n<div class=\"content-ad\"></div>\n\n## References\n\n[1] Cen, Yukuo, et al. “Controllable multi-interest framework for recommendation.” Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2020.\n\n[2] Li, Chao, et al. “Multi-interest network with dynamic routing for recommendation at Tmall.” Proceedings of the 28th ACM international conference on information and knowledge management. 2019.\n","ogImage":{"url":"/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png"},"coverImage":"/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png","tag":["Tech"],"readingTime":6},{"title":"포디즘의 새로운 모습","description":"","date":"2024-05-23 17:11","slug":"2024-05-23-ThenewfaceofFordism","content":"\n\n<img src=\"/assets/img/2024-05-23-ThenewfaceofFordism_0.png\" />\n\n미국 로봇 기업인 Figure은 특정 경제 분야에서 발생하는 노동 인력 부족을 해결하기 위해 인간 형상 로봇을 개발 중이며, 독일 자동차 제조사인 BMW과 협약을 발표했습니다. 이 협약에 따라 Figure 01 로봇들이 BMW의 미국에 위치한 Spartanburg 공장에 배치될 예정입니다. 해당 공장은 X 및 XM 시리즈 차량을 하루에 약 1,500대 조립하며 현재 약 11,000명을 고용하고 있습니다.\n\n아직 로봇 수나 그들이 수행할 작업에 대한 구체적인 내용은 알려지지 않았지만, \"그들은 몇 달 동안 특정 작업을 수행할 수 있도록 훈련받은 후, 생산 공정(보디 샵, 시트 금속 및 웨어하우스 등)에 통합될 것이며 앞으로 12개월에서 24개월 안에 배치될 예정입니다.\"라는 말을 제외하고 전반적인 작업에 대한 컨셉 증명입니다.\n\nBMW는 이미 공장에서 사용 중인 Optimus 로봇을 보유한 Tesla와 경쟁을 목표로 하고 있습니다. 이와 같이 인간 형상 로봇을 사용하여 반복적이고 위험한 작업을 수행하는 것에 대해 연구해온 Honda나 Boston Dynamics를 인수한 Hyundai 등의 자동차 제조사들은 기업들이 고용인력을 영입하고 유지하기 어려운 일부 여러 가치를 내지 않는 반복적인 작업이 바로 그들이 가장 어려워하는 작업이며, 회사들은 이에 대해 논의하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n지금은 다음 세대 로봇의 개발이 진행되고 있습니다. 이러한 로봇들은 사람들과 함께 공간을 공유하는 환경에서 완전히 안전하며, 일 중에 일어나는 학습 과정이 모방을 통해 이뤄집니다. 실제로 Figure의 접근 방식은 로봇이 기업이 생산성을 높이고 비용을 절감하며 더 안전하고 일관된 작업 환경을 조성하는 데 기여할 것으로 보고 있으며, 회사를 RaaS(로보틱스 서비스) 모델로 설립하고 로봇을 기업에 대여할 계획입니다. Figure는 인간의 형태 요소를 모방하고 손으로 수행되는 작업에서 높은 정밀도를 달성하는 데 초점을 맞추고 있습니다.\n\n자동차 제조 공장에서 작업하는 로봇들. 2024년이 로보틱스의 해가 될 것으로 생각했을 때, 이렇게 빨리 이러한 종류의 보고서들을 듣게 될 줄은 저도 예상치 못했습니다.","ogImage":{"url":"/assets/img/2024-05-23-ThenewfaceofFordism_0.png"},"coverImage":"/assets/img/2024-05-23-ThenewfaceofFordism_0.png","tag":["Tech"],"readingTime":2},{"title":"로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스","description":"","date":"2024-05-23 17:10","slug":"2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release","content":"\n\n<img src=\"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png\" />\n\nMerklebot에서는 로봇 플릿 운영자를 위한 데이터 관리 및 개발 도구를 만들고 있습니다. 우리는 다음 15년 안에 100억 대 이상의 로봇이 나올 가능성이 꽤 높다고 믿고 있으며, 이 비전을 실현하기 위해 견고하고 확장 가능하며 안전한 인프라 및 통신 스택을 구축하고 있습니다.\n\n## 로봇 에이전트란?\n\n몇 달 전에 Digital Black Box를 출시했습니다. 이 서비스는 로봇에서 로그, 카메라 피드 및 포인트 클라우드와 같은 데이터를 안전하고 저렴한 분산 저장 네트워크인 Filecoin에 백업하는 기능을 제공합니다. Digital Black Box는 다음으로 구성됩니다:\n\n<div class=\"content-ad\"></div>\n\n- 가장자리에서 실행되는 로봇 에이전트\n\n2. 클라우드 연결을 제공하는 Merklebot 플랫폼\n\n첫 번째 버전의 로봇 에이전트는 가장자리 장치에서 데이터를 수집하고 백업하는데 사용되었습니다. 나중에는 Merklebot 플랫폼을 구축하여 Docker 컨테이너를 가장자리 장치에 배포하고 그 위에서 실행 중인 에이전트에 기능을 추가했습니다.\n\n## 로봇 에이전트 0.0.7\n\n<div class=\"content-ad\"></div>\n\n- 👀 네트워크에서 다른 로봇의 mDNS 자동 탐색\n- 🤖↔🤖 로봇 간의 Libp2p 메시징\n\n안녕하세요! 오늘은 로봇 에이전트 0.0.7의 새로운 릴리스를 Libp2p 통신 모듈과 함께 발표합니다. 최신 버전의 로봇 에이전트는 이제 Libp2p 피어 탐색, 주소 설정 및 메시지 전송을 갖추고 있습니다. 네트워크를 유연한 토폴로지로 설정할 수 있으며, 위치 변경이나 다른 매개변수를 바꿀 때마다 통신 스택을 구성할 필요가 없습니다. 이제 저희의 Github에서 공개되어 있습니다.\n\n로봇 에이전트 0.0.7를 설치하면 기기가 다른 에이전트를 자동으로 찾아 정보(상태, 이벤트)를 서로 전달할 수 있습니다. 중앙 서버에 접근하지 않고도 기기 간 통신을 수행할 수 있습니다. 이 도구는 MIT 라이선스로 완전히 오픈 소스이며, 여러분의 필요에 맞게 이 도구를 자유롭게 사용할 수 있습니다.\n\n## Merklebot 플랫폼\n\n<div class=\"content-ad\"></div>\n\nMerklebot 플랫폼은 Robot Agents를 여러 기기 필릿에 중앙 집중식으로 롤아웃할 수 있도록 제공하여 로봇, 센서, 장비 및 기타 기계와 같은 다양한 기기를 안전하고 쉽게 관리할 수 있습니다. 전체 Robot Agents 필릿에 코드 및 Docker 컨테이너를 배포하고 데이터를 관리할 수 있습니다.\n\nMerklebot 없이:\n\n- 로봇에 연결\n- 로봇을 vpn 네트워크에 추가하거나 NAT 트래버셜을 우회하는 다른 방법\n- 🧑‍💻 코드를 작성합니다\n- ssh를 통해 로봇에 연결\n- ⏳ git pull\n- ⏳ docker build 및 run my-best-code\n- ⏳ 로봇 로그 보기\n- ⏳ 데이터(카메라 비디오 등)를 가져오기 위해 scp 실행\n- ⏳ 취합할 위치에 저장\n\nMerklebot을 사용하면:\n\n<div class=\"content-ad\"></div>\n\n- 로봇에 연결하세요\n- install.sh를 실행하세요\n- 🧑‍💻코드를 작성하세요\n- 🚀플랫폼에서 한 번 클릭하거나 API를 호출하세요\n- 😎로그, 비디오 및 기타 데이터를 플랫폼에서 확인하세요\n\n## 다음은 무엇인가요\n\nMerklebot 팀은 오픈 소스 Agent의 기능을 계속 향상시키고 Merklebot 플랫폼에 더 많은 유틸리티를 추가할 새로운 기능 세트에 현재 작업 중입니다.\n\n- 에이전트를 위한 향상된 CLI 도구 (일반 명령 인터페이스). SSH 우회, 구성 업데이트 전달 및 기기에서 편집 없이 에이전트를 관리하세요. 현재 Merklebot 플랫폼에서 활성화되어 있지만, 이를 오픈 소스로 만들 계획을 하고 있어요!\n- 오픈 소스 데이터 관리 및 시각화 도구와의 통합. 로그 수집 및 저장, 데이터 작업 실행 및 시각화 생성을 할 수 있어요.\n- Jenkins와 같은 CI/CD (지속적 통합 지속적 배포) 도구와의 통합. 자동으로 장치에 새 소프트웨어 릴리스 설치하세요.\n\n\n<div class=\"content-ad\"></div>\n\n우리 새로운 에이전트를 확인해보세요! 피드백을 기다리고 있어요.\n\n그리고 기기 편대를 관리해야 한다면, Merklebot Platform으로 시작해보세요.","ogImage":{"url":"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png"},"coverImage":"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png","tag":["Tech"],"readingTime":3}],"page":"41","totalPageCount":98,"totalPageGroupCount":5,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}