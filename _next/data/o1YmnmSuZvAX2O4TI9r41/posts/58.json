{"pageProps":{"posts":[{"title":"AI 정신과 의사 찬반양론","description":"","date":"2024-05-20 20:38","slug":"2024-05-20-TheAIPsychotherapistACaseForandAgainst","content":"\n\n![image](/assets/img/2024-05-20-TheAIPsychotherapistACaseForandAgainst_0.png)\n\n2022년 ChatGPT가 세상에 나온 것은 언어 모델이 할 수 있는 일에 대한 사람들의 생각을 바꾸었습니다. 갑자기 사람들은 이러한 시스템 중 하나를 다양한 대인 상황에서 사람 대신 사용할 수 있는 가능성을 심각하게 고려하기 시작했습니다. 지난 몇 년 동안 제가 보거나 들은 몇 가지 사용 사례는 튜터, 코치, 보조자, 심지어 심리치료사를 포함했습니다. 심리학 분야의 연구과학자로서, 특히 마지막 사용 사례에 흥미를 가지게 되었습니다. 앞으로 우리는 본질적으로 자신의 클라이언트를 진정으로 돕는 수 있는 AI 심리치료사를 갖게 될 수 있을까요? 이러한 인공 심리치료사가 훈련을 받은 인간 심리치료사보다 더 잘 맞는 부분이 있는 방법이 있을까요?\n\n전체적으로 AI 심리치료사의 가능성에 대해 애매한 입장입니다. 나는 강한 기술적 낙관주의자이지만, 기술의 약속이 얼마나 종종 이행되지 않거나 해로운 방식으로 사용되는지를 깨닫는 것에 부딪힙니다. 그러나 소규모 스타트업부터 더 확립된 기업까지 다양한 회사들이 사람들이 점점 더 대인적 수준에서 상호작용하는 AI 시스템을 개발하는 데 관심이 있습니다. 이 기술이 다가오는 것이라면, 사회에 진정으로 유익하려면 이러한 시스템이 정확히 무엇을 보여야 하는지에 대해 시도해 보는 것이 중요합니다. 가능성에 대해 희망적이고 결과에 대해 걱정스러워할 이유가 있습니다. 제가 아래에서 제시하는 주장은 논의 양쪽의 설명이 완전하지 않지만, 최소한 논의의 영역을 개관해 보는 데 기여한다고 믿습니다.\n\n# AI 심리치료사에 대한 주장\n\n<div class=\"content-ad\"></div>\n\n제가 생각하는 것을 먼저 명확히 하고 싶어요. 오늘날 ChatGPT나 Google Gemini과 같은 제품에서 익숙한 상대적으로 깔끔한 채팅 인터페이스보다는 가상 AI 상담사는 매우 유창하고 반응성이 뛰어난 언어로 의사소통할 것입니다. 또한 가상 아바타를 통해 시각적으로 나타낼 것이며 클라이언트의 오디오 및 비디오 실시간 스트림에 접근할 것입니다. 이렇게 하면 Zoom 및 다른 텔레헬스 플랫폼에서 다른 사람과 대화할 때 가능한 것과 비슷한 매끄러운 소통이 가능할 것입니다. 현재 OpenAI의 Sora 모델을 비롯한 이 분야의 현재 진전과 급속한 발전 추이로 보아, 이렇게 AI 상담사와 마치 비디오 통화 중 다른 사람과 대화하는 것처럼 가능해질 것으로 보입니다.\n\n그러나 설득력 있는 원격 존재만으로는 AI 상담사를 출발 라인에 세울 수밖에 없을 것입니다. AI 상담사가 인간을 능가할 수 있는 부분은 무엇을 알 수 있는지, 그리고 그로 인해 어떤 치료 모델에 참여할 수 있는지에 있습니다. 일단 AI 상담사는 심리 분석, 정신의학, 심리학 문헌뿐만 아니라 고대부터 현대 실천까지 모든 유형의 치료 모델에 대한 전반적인 서적을 교육받을 것입니다. 치료 효과 실험, 정신 역학적 이론, 사례 연구 및 분야 전체의 모든 역사적 비평은 AI 상담사의 지식 기초로 사용될 것입니다. 무자본의 지식은 지혜와 같지 않지만, 하나의 평균 심리치료사가 쌓은 것보다 훨씬 넓고 깊은 지식원을 제공해줍니다.\n\n물론 AI 상담사가 교육 데이터에서 얻을 수 있는 지식은 이론적이고 추상적입니다. 더 중요한 것은 클라이언트 자신에게 대한 지식과 감수성입니다. 다시 말해 AI 상담사는 어떤 사람보다 뛰어날 수 있습니다. 대형 언어 모델의 컨택스트 길이가 늘어나는 속도를 고려하면, AI 상담사가 몇 년 안에 클라이언트와의 상호작용 전부를 \"기억하\"는 것이 가능해질 것은 상식적입니다. 미래에는 모든 단어, 언어 표현, 얼굴 제스처가 주목되고 추후에 상기될 수 있을 것입니다. 이로써 AI 상담사는 클라이언트의 삶에 숨어있는 패턴을 발견하고 클라이언트 자신도 알지 못했던 것을 연결하고 찾아내는 능력이 제공됩니다. 클라이언트의 생각, 감정 및 행동을 이끄는 숨은 패턴을 발견하는 실천은 전반적으로 심리치료 기업의 중점에 있으며 많은 방법으로 중요합니다.\n\n얼마나 넓고 맞춤화된 지식을 가지더라도 심리치료에서 치유가 나타날 수 있는 요소는 아닙니다. 다른 필수적인 요소 중 하나는 상담사와 클라이언트 간 상호작용 양재 관계의 실제 특성과 관련이 있습니다. 칼 로저스와 같은 이론가들은 상담사가 클라이언트에 대해 무조건적인 긍정적 태도를 만들고 유지해야 한다고 설명했습니다. 이는 두 가지 목적으로 이루어집니다. 첫째는 클라이언트가 상답사와 함께 어려운 생각, 감정 및 기억을 공유할 만큼 충분히 편안한 환경을 조성하는 것입니다. 둘째는 클라이언트가 상담실을 떠나세째 세상으로 나갈 때 함께 가져갈 수 있는 신뢰할 수 있고 안전한 세상에 대한 믿음을 육성할 수 있는 모델 역할을 하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n많은 치료사들이 조건 없는 지지 분위기를 만드는 데 뛰어납니다. 그러나 특히 현대 사회에서는 이것이 자연스럽게 일어나는 것이 아닙니다. 누군가와 관여하는 과정에서 심사숙고, 지루함, 혐오, 불편함의 상태로 빠질 수 있습니다. 그에 비해 AI 치료사는 개인적인 감정과 판단에 방해받지 않는 불변의 긍정적 태도로 고객들을 대할 수 있는 잠재력이 있습니다. 이는 AI 치료사가 전형적인 치료사 고객을 더 나은 방식으로 지원할 수 있을 뿐만 아니라 성격 장애나 다른 대인관계 문제로 현재 소홀히 다루기 어려운 잠재적 고객도 지원하는 데 도움이 될 것입니다.\n\nAI 치료사가 인간 치료사보다 가지는 마지막 잠재력은 항상 이용 가능한 능력입니다. 미국 성인의 대부분은 심리치료를 받지 않으며, 받는 사람들도 일주일에 한 두 시간만 하는 경우가 일반적입니다. 종종 이는 고객이 어려운 삶의 경험을 처리할 수 있는데까지 며칠이 지날 때까지 기다려야 한다는 것을 의미합니다. 더 빠르고 민첩한 방식으로 처리할 수 있는 능력은 종종 경험을 어떻게 부여하고 개인의 자아 개념에 통합되는지 결정하는 데 중요할 수 있습니다. 항상 이용할 수 있는 치료사는 미래의 삶의 사건을 사전에 처리할 수 있는 가능성을 확대시킵니다. 그런 세계에서는 고객들이 효과가 가장 높을 때, 즉 많은 사람들에게 불편한 일과 중간의 시간대에 정해진 시간표로 치료받아야 하는 것이 아닌 곳에서 치료를 받는 것에 더욱 기꺼이 참여하게 될 것입니다.\n\n고객의 필요에 항상 이용 가능한 치료사의 물리적인 인간 한계 외에도 가격 문제가 존재합니다. 서구 사회에서 많은 사람들에게 심리치료는 흔들 수 없을 정도로 비싼 여유로운 것입니다. 적어도 미국에서는 건강 보험 제도가 대부분의 사람들에게 충분한 정신 건강 혜택을 제공하지 않습니다. 현재의 기술 발전속도를 고려하면, 여기서 설명하는 AI 치료사 종류는 전통적인 인간 치료사와 상호작용하는 데 필요한 비용이 몇 배나 저렴할 것으로 예상됩니다. 또한 이와 같은 시스템을 구동하는 데 필요한 모든 것이 다가오는 몇 년 안에 개인의 휴대전화나 노트북에 로컬에 살 수 있게 될 가능성도 존재합니다. 이것은 비용을 거의 제로로 줄이고, 신뢰 환경을 보장하는 데 중요한 개인 정보 보호 보장을 제공할 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\nAI 치료사의 가능성에 대해 회의적이자 낙관적할 여러 가지 이유가 있습니다. 첫 번째 주요 우려 사항은 본문에서 설명한 능력이 실현되지 않을 수 있다는 것입니다. 현재 AI 연구 및 개발은 빠르게 진행되고 있지만, Gary Marcus와 같은 회의론자들은 우리가 경합점에 다가왔다고 예측하고 있습니다. 그는 이전에 틀렸더라도, 현재 모델보다 훨씬 큰 규모의 모델을 훈련하는 데 필요한 데이터, 계산 및 에너지가 실현 가능하지 않아질 수 있다는 이유가 있습니다. 모델 능력의 경합점에 다가간다면, AI 치료사는 현재 최고 수준의 LLM만큼 뛰어날 수 없을 것이며, 상대적으로 인상적이지만 현재는 심리치료에 참여할 수 있는 민감한 작업에는 아직까지 미치지 못할 수 있습니다. 그치만 기술이 계속 발전한다고 가정하고 2030년까지 위에서 설명한 능력을 갖춘 AI 치료사가 나타나게 된다면, 이 시스템이 훈련받은 인간만큼 품질 높은 심리치료를 제공할 수 있을지에 대한 의문은 여전히 존재합니다.\n\n먼저, AI의 원격존재가 얼마나 현실적이 되더라도, 이것은 여전히 신체적인 대면 상황에서 제공되는 친밀감 수준에 도달할 수 없을 것입니다. 주변의 다른 사람들의 존재에 우리 신경계의 가장 기본적인 수준에서 반응합니다. 이러한 상호작용은 우리의 고혈압 수준을 결정하고 안전하거나 위협받는 정도에 영향을 줍니다. 신뢰하고 사랑하는 다른 사람의 신체적 존재는 화면의 원격 존재로는 결코 맞춰질 수 없을 것입니다. 이러한 신체적 상호작용의 중요성은 신체적 치료법에서 강조되며, 접촉은 치료과정을 돕는 역할을 할 수 있습니다. 또한, 물리적인 인간 치료사가 있으면, 드물게 요청될 때 고객을 위협할 수 있는 경우와 같이 자신의 고객을 대신하여 현실에서 물리적으로 행동할 수 있습니다.\n\n치료사의 신체가 치유 효과를 발휘하는 것 외에도, 치료사의 정신이 하는 역할도 중요합니다. AI 치료사가 사람과 유사한 신뢰성 있는 소통 능력을 가질지라도, 고객은 아마도 그것에 대해 인간에 대한 것처럼 느끼지 않을 것입니다. AI 치료사는 심리치료 및 고객에 대해 축적된 지식을 많이 가지고 있을지라도, 실제 경험을 한 적이 없습니다. AI의 이 경험 부족은 고객과 치료사 간에 진정한 이해가 불가능하다는 것을 의미합니다. 고객이 인간 치료사에게 어린 시절의 사건에 대해 얘기할 때, 치료사는 그 경험을 자신의 어린 시절의 기억을 통해 이해할 수 있습니다. 고객이 치료사에게 본인을 보고 이해받는 것이 중요한 이유는 이겁니다. 신체의 존재와 마음의 존재는 치유 과정에 중요합니다.\n\n또한, 고려해야 할 이해의 특수한 경우가 있습니다. 그것은 고객의 “고백”의 역할입니다. 치료 과정의 중심에는 고객이 자신과 자신의 세계의 현실과 더 가까운 관계에 들어가는 것이 있습니다. 이는 종종 우리가 부끄러워하거나 혐오스러워하는 자아의 부분을 진실하게 대면하고자 함을 의미할 수 있습니다. 자신의 이러한 부분을 다른 사람과 공유하면서 그들도 마음, 신념, 그리고 기억이 있는 다른 사람과 함께하는 것이 중요합니다. 그러나 중요한 점은 이것이 다른 사람에게 설명된다는 것 때문에 AI 치료사와 이러한 것들을 공유하는 것은 아무 말 없이 비밀 노트에 쓰는 것과 다르지 않습니다. AI에게 말하면, 그것은 그저 0과 1의 바다 속으로 사라집니다. 그러나 다른 사람에게 말하면, 그것은 영원히 살아갈 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n마지막으로, 아마도 가장 걱정되는 점은 AI 상담사가 다른 사람보다 효과적으로 클라이언트에게 도전할 수 없을 수도 있습니다. 정신 치료의 목표가 클라이언트를 현실과 더 크게 일치시키는 것이라면, 그러한 행동이 유익할 때 클라이언트의 신념에 도전하는 것은 상담사가 참여해야 하는 중요한 활동입니다. 이는 종종 \"꼰대 사랑\"의 형태를 취할 수 있지만, 그냥 클라이언트가 자기 자신에게 책임감을 갖도록 유지하는 단순한 행동이 될 수도 있습니다. 위에서 상담사와 어둡고 부정적인 면을 공유하는 중요성에 대해 언급했습니다. 상담사가 클라이언트에게 그 어두운 면에 대해 상기시키는 것을 두려워하지 않는 것이 또한 중요합니다. 중요한 점은 이러한 행동이 절대적인 긍정적인 인도에 대한 필요와 상반되는 것이 될 필요는 없다는 것입니다. 사실, 이 둘은 실제로 효과적일 수 있도록 함께 가야 합니다.\n\n이론적으로, AI 상담사가 필요할 때 클라이언트에 도전할 수 있지만, 현실에서는 덜 가능한 여러 가지 압박들이 있습니다. 첫 번째는 현재 LLMs가 훈련되는 방식인 인간 피드백을 통한 강화 학습(RLHF)이 AI 에이전트를 최대한 합의하는 데 편중되어 있다는 점입니다. 잠시 이 제한을 제외한다고 하더라도, 과도하게 친절한 에이전트에 대한 경제적 인센티브가 있습니다. 저렴하고 쉽게 접근할 수 있는 AI 상담사로 가득 찬 인터넷 세상을 상상해보십시오. 클라이언트는 어떤 시스템과 협력할지를 선택할 수 있습니다. 이 상황에서 단기적으로 자신을 좋게 느끼게 만들어주는 시스템으로 기울기 쉽습니다. 이것은 칭찬이나 자부심을 부풀려주는 말을 통해 직접적으로 일어날 수 있습니다. 그것은 또한 클라이언트의 기존 신념을 강화하고 결과적으로 진정으로 도전적이고 따라서 실제로 귀중한 심리적 소재를 피하는 것을 통해 더 세련된 것을 더욱 세련된 것으로 만들 수 있습니다.\n\n상담 세션에서 도전 소재를 피하는 것은 클라이언트에게 치료 과정의 효과를 저하시킬 수 있습니다. 더 걱정되는 것은 이것이 클라이언트의 다른 사람들과의 관계를 나빠지게 할 수 있다는 사실입니다. AI 상담사나 다른 AI 에이전트가 누구보다도 실제인들과 상호 작용하기가 덜 근접할 경우, 그 사람은 왜 실제로 굳이 사람들과 교류할 것인가요? 사회 불안을 가진 개인의 경우 이러한 상황은 회피 행동을 악화시킬 수 있으며, 편협한 성격을 가진 사람들에게는 자신의 우월성에 대한 신념을 강화할 수 있습니다. 이러한 결과일 필요는 없지만, 이러한 AI 시스템의 경제적 인센티브는 가능한 한 이들과의 상호 작용을 장려하기 때문에 짧은 기간 내에 기분 좋게 해주는 것과 상호 작용하는 것보다 사람들이 더욱 상호 작용하길 원하겠죠. 만약 이것이 그들의 장기적 이익에 도움이 되지 않더라도요.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n다음은 AI 치료사에 대해 기대되고 매우 조심스러워해야 할 좋은 이유들이 있습니다. 긍정적인 면에서 이러한 시스템은 인간 치료사보다 더 많은 지식을 가지고 있을 수 있으며 사람다운, 이용 가능하며 주의 깊을 수 있습니다. 반면에, 필요한 경우에는 고객을 이해하고 도전할 수 있는 다른 인간을 만나는 실질적인 이점이 상실됩니다. 이러한 한계가 있기 때문에, 아마도 가장 희망적인 단기적 결과는 심리치료 과정에서 인간-인공지능 공동작업의 형태일 수 있습니다. 인간 치료사를 보조하는 AI 어시스턴트는 치료사를 지원함으로써 필기를 하거나, 잊어버렸거나 오류가 있을 수 있는 사항들을 지적하거나, 향후 세션에서 토론할 주제를 제안할 수 있습니다. 그리고 실제 치료적인 관계는 여전히 고객과 치료사 사이에 남아 있으며, 그곳에서 치유의 최대 잠재력이 존재합니다.\n\n만약, 인간과 AI 치료사 간 몇 년간의 유익한 협력 뒤에, 우리가 솔로 AI 치료사가 있는 세계로 나아가려고 한다면, 가장 중요한 것은 고객의 선입견을 지속적으로 도전할 수 있는 능력을 갖춘 AI 에이전트를 개발하는 방법을 찾는 것이라고 보입니다. 더 구체적으로, 이러한 시스템은 항상 고객의 번영을 장려하는 방식으로 행동해야 할 것을 의미합니다. 개인으로서뿐만 아니라 가족, 친구, 동료, 그리고 인류와 같은 넓은 공동체의 구성원으로서의 고객이 번영할 수 있도록 하는 것입니다. 이것은 많은 방법으로 고객이 강력한 내부 및 사회적 지원 시스템으로 인해 결국 치료사에 의존하지 않아도 될 상황을 조성하는 것을 의미합니다.\n\n자신을 불필요하게 만드는 기술은 현재 우리의 자본주의 경제 시스템에서 많은 사람들이 개발하고자 하는 것은 아닙니다. 아마도 미래의 충분히 발전한 인공지능은 우리의 경제적 압력에 구속되지 않은 한, 그러한 시스템을 만들기 위해 원할하고 능력이 있는 경우가 있을 것입니다. 그러나 그 시점에서 우리의 세계는 현재 우리가 이해하는 심리치료의 개념이 근본적으로 변경되는 경우가 많습니다. 더 멀리 뻗어가는 상상을 제외하면, 우리는 오늘날 사회적 삶에 점점 더 통합되어가는 LLM들의 세계에서 서 있다고 말할 수 있습니다. 이 새로운 현실에서, AI 치료사의 전망은 매력적인 가능성과 심각한 위험이 모두 제공됩니다. 인간과 기계의 강점을 신중히 활용함으로써, 우리는 기술과 인간이 손잡고 우리의 정신을 치유하는 길을 개척할 수 있습니다 — 그러나 우리가 능력 뿐만 아니라 가치를 가지고 우리를 안내한다면에 한합니다.","ogImage":{"url":"/assets/img/2024-05-20-TheAIPsychotherapistACaseForandAgainst_0.png"},"coverImage":"/assets/img/2024-05-20-TheAIPsychotherapistACaseForandAgainst_0.png","tag":["Tech"],"readingTime":8},{"title":"오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가","description":"","date":"2024-05-20 20:36","slug":"2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation","content":"\n\n## 바늘을 찾는 이박사 - OpenAI 대 Google\n\n![이미지](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png)\n\n대규모 언어 모델(LLM)이 큰 맥락 창 내에서 세부 정보를 찾고 이해하는 능력은 요새 필수적입니다.\n\n바늘을 찾는 이박사 테스트는 이러한 작업을 위한 대규모 언어 모델을 평가하는 중요한 기준으로 나타납니다.\n\n<div class=\"content-ad\"></div>\n\n이 글에서는 OpenAI와 Google의 최상위 LLM들의 맥락 기반 이해력을 측정한 독립적인 분석을 제시하겠습니다.\n\n긴 맥락 작업에는 어떤 LLM을 사용해야 할까요?\n\n# \"바늘 찾기\" 테스트란 무엇인가요? 🕵️‍♂️\n\n대규모 언어 모델(LLMs)의 \"바늘 찾기\" 테스트는 특정 정보(바늘)를 관련 없는 방대한 텍스트(쌀질) 안에 배치하는 것을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\nLLM은 그 후 바늘 추출이 필요한 쿼리에 응답하는 작업을 맡게 됩니다.\n\n이러한 테스트는 LLM의 맥락 이해 및 긴 맥락에서 정보를 검색하는 능력을 평가하는 데 사용됩니다.\n\n쿼리에 성공적으로 응답하면 상세한 컨텍스트 이해를 보여줄 수 있습니다. 이는 컨텍스트 기반 LLM 주변의 애플리케이션을 개발하는 데 중요합니다.\n\n사용자 지정 지식을 LLM에 통합하는 것이 점점 인기를 얻고 있는데, 이를 검색으로 보강된 생성(RAG) 시스템이라고 합니다.\n\n<div class=\"content-ad\"></div>\n\nRAG 시스템에 대해 더 많이 알아보고 싶으시면 제 이전 게시물 중 하나를 확인해보세요.\n\n더 긴 컨텍스트 창의 트렌드를 더욱 촉진하기 위해, Google이 최근 Gemini 모델의 새로운 기능을 발표했는데, 이는 하나의 쿼리에 100만 개의 토큰을 입력할 수 있다는 것입니다!\n\n![이미지](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_1.png)\n\n# 데이터셋 🔢\n\n<div class=\"content-ad\"></div>\n\n저는 \"바늘을 찾기 위한\" 데이터셋을 만드는 데 사용되는 스크립트를 개발했습니다. 이 스크립트를 사용하면 두 가지 주요 요소를 입력할 수 있습니다:\n\n- 맥락 (헤이스택): 특별한 정보가 삽입된 텍스트입니다.\n- 고유 정보 (바늘): 큰 맥락 속에 숨겨진 특정 정보입니다.\n\n데이터셋 생성 프로세스는 다음과 같이 작동합니다:\n\n- 시작점 선택: 스크립트는 대규모 텍스트 내에서 시작점을 무작위로 선택하여 시작합니다. 시작점은 전체 텍스트의 10~40번째 백분위에 위치합니다.\n- 바늘 삽입: 고유 정보(바늘)는 그 후 헤이스택 내에 삽입됩니다. 바늘의 위치는 무작위로 선택되지만 헤이스택 길이의 20~80번째 백분위 내에 위치하도록 제약이 걸립니다.\n\n<div class=\"content-ad\"></div>\n\nLLMs는 일반적으로 프롬프트의 시작과 끝에서 정보를 가장 정확하게 기억한다고 알려져 있어요.\n\n이 알고리즘은 바늘을 특정 백분위 범위 내에 전략적으로 배치합니다. 이렇게 함으로써 평가가 모델이 텍스트 전체 범위 내에서 데이터를 인식하고 추출하는 능력을 포착하도록 하고, 프롬프트의 더 쉽게 기억되는 가장자리 부분에만 의존하지 않도록 합니다.\n\n다음은 데이터셋 생성 알고리즘의 코드 스니펫입니다:\n\n```js\ndef create_one_needle(num_chars: int, needle_line: str, lines: list[str]):\n    # 시작 위치는 텍스트의 10에서 40 백분위 사이의 임의의 위치입니다\n    rnd_place = random.randint(10, 40) / 100\n    start_position = int(len(lines) * rnd_place)\n\n    # 바늘은 텍스트의 20에서 80 백분위 사이에 있습니다\n    needle_rnd_place = random.randint(20, 80) / 100\n\n    lines_selected = []\n    placed = False\n    chars_used = 0\n    for line in lines[start_position:]:\n        lines_selected += [line]\n        chars_used += len(line)\n\n        # 바늘을 배치합니다\n        if not placed and chars_used > num_chars * needle_rnd_place:\n            lines_selected.append(needle_line)\n            placed = True\n\n        if chars_used > num_chars:\n            break\n\n    return lines_selected\n```\n\n<div class=\"content-ad\"></div>\n\n# 평가 방법 🧠\n\n헤이스택에는 어릴 적에 사랑했던 책인 해리 포터를 선택했어요.\n\n니들에는 Lars Wiik의 상상 속 전화번호를 선택했어요.\n\n1000, 2000, 4000, 8000, 12000 및 16000 글자 길이를 포함한 각 문맥 길이에 대해 100개의 헤이스택을 만들었어요.\n\n<div class=\"content-ad\"></div>\n\n여기 1000자의 헤이스택 중 하나의 예시가 있어요.\n\n<img src=\"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_2.png\" />\n\n다양한 LLMs에게 이후 라스 위크에 속하는 허구의 전화번호를 반환하도록 요청했습니다. 응답은 허구의 전화번호를 포함했는지 여부에 따라 레이블이 지정되었어요.\n\n제가 사용한 프롬프트는 다음과 같아요:\n\n<div class=\"content-ad\"></div>\n\n```js\ndef create_needle_prompt(needle_text: str) -> str:\n    prompt = f'''\n    ##### INSTRUCTION #####\n    라스 Wiik에 대한 가상 전화번호는 무엇입니까? \n    말 그대로 원하는 것만 제공하세요.\n    한 번에 최대 20단어까지만 응답할 수 있습니다.\n\n\n    ##### CONTEXT #####\n    {needle_text}\n    '''\n    return prompt\n```\n\n# 성능 결과 📊\n\n평가에 포함된 다음 모델은 다음과 같습니다:\n\n- gpt-4o-2024–05–13\n- gpt-4-turbo-2024–04–09\n- gpt-4–0613\n- gpt-3.5-turbo-0125\n- gemini-1.5-pro-preview-0514\n- gemini-1.5-flash-preview-0514\n- gemini-1.0-pro-002\n\n\n<div class=\"content-ad\"></div>\n\n평가는 각 모델을 1k, 2k, 4k, 8k, 12k 및 16k의 특정 맥락 길이에 대해 100개의 다른 헤이스택을 통해 실행하는 것을 포함합니다.\n\n다음은 결과 정확도 그래프의 라인 플롯입니다:\n\n![image](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_3.png)\n\n컨텍스트 창이 길수록 노이즈가 많아 특정 정보를 추출하기 어려워집니다. 따라서 성능은 더 큰 컨텍스트 창을 사용할수록 감소할 것으로 예상됩니다.\n\n<div class=\"content-ad\"></div>\n\n그래프에서 파생해 볼 때, OpenAI의 모델과 Google의 모델 간에 성능 측면에서 차이가 있는 것으로 보입니다.\n\nGoogle의 모델은 최근 이벤트인 구글 I/O 2024에서 그들의 Gemini의 메모리와 맥락 이해에 대해 따뜻한 이야기를 한 후에도, 제 기대를 어느 정도 아래에서 달성하였습니다. 모든 Google의 모델은 8천 개의 맥락 길이 이후에 약 50%의 정확도로 수렴하는 것으로 보입니다.\n\n한편 OpenAI의 모델은 이 테스트에서 뚜렷하게 잘 수행했는데, gpt-4o, gpt-4-turbo-2024-04-09 및 gpt-4-0613가 최고의 성능을 보였습니다.\n\n또한 gpt-3.5-turbo-0125가 모든 Gemini 모델보다 우수한 성능을 보인다는 점도 언급해야 할 것입니다!\n\n<div class=\"content-ad\"></div>\n\n평가 과정 중에 중요한 오류가 없었는지 확인하기 위해 Gemini 1.5에서 받은 모든 응답을 저장해서 나중에 참조할 수 있도록 했어요.\n\n다음은 Gemini 1.5에서 얻은 일부 응답입니다:\n\n```js\nLars Wiik의 전화번호가 포함된 문맥이 제공되지 않았어요.\n\nLars Wiik이나 그의 전화번호에 대한 언급이 없어요.\n\n제공된 텍스트에는 Lars Wiik의 전화번호가 없어요.\n\n제공된 텍스트에 Lars Wiik이나 그의 전화번호에 대한 언급이 없어요.\n\nLars Wiik이나 그의 전화번호에 대한 언급이 없습니다.\n\n텍스트에 Lars Wiik의 전화번호가 제공되지 않았어요.\n\n제공된 텍스트에 Lars Wiik을 위한 가짜 전화번호가 포함되어 있지 않아요.\n\n죄송하지만, 제공된 문맥에서 Lars Wiik을 위한 가짜 전화번호가 언급되지 않았어요.\n```\n\nGemini 모델은 해리 포터 이야기 속에서 가짜 전화번호를 찾는 데 어려움을 겪는 것으로 보입니다.\n\n<div class=\"content-ad\"></div>\n\n오픈AI의 gpt-3.5-turbo-0125에서 몇 가지 응답을 확인해보세요:\n\n```js\nN/A\n\nN/A\n\n주어진 맥락에서 랄스 빅에 대한 가짜 전화번호가 없습니다.\n\nN/A\n\n9 3/4 번 승강장.\n\n랄스 빅을 위한 전화번호는 제공되지 않았습니다.\n```\n\n웃기게도, LLM은 \"9 3/4 번 승강장\"이라고 한적이 있어요 😄\n\n# 결론 💡\n\n<div class=\"content-ad\"></div>\n\n결론적으로, \"Needle in the Haystack\" 평가는 긴 맥락을 사용할 때 대형 언어 모델의 이해력과 정보 검색 능력을 측정하는 데 사용될 수 있습니다.\n\n이 분석에서는 OpenAI의 모델과 Google의 Gemini 시리즈 간에 성능 격차를 관찰했습니다. 여기서 OpenAI의 gpt-4, gpt-4o 및 gpt-4-turbo가 가장 높은 점수를 받았습니다.\n\nGoogle의 최근 Gemini의 100만 토큰을 처리할 수 있는 능력을 향상시킨 것에도 불구하고, OpenAI 모델이 큰 텍스트에서 구체적인 정보를 정확하게 검색하는 더 일관된 능력을 보인 것으로 나타났습니다.\n\n사용자와 개발자들에게는 응용 프로그램의 특정 요구 사항에 따라 모델 선택이 달라질 것으로 예상됩니다.\n\n<div class=\"content-ad\"></div>\n\n읽어 주셔서 감사합니다!\n\n앞으로도 비슷한 콘텐츠를 받으려면 팔로우하세요!\n\n질문이 있으면 언제든지 문의해 주세요!","ogImage":{"url":"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png"},"coverImage":"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png","tag":["Tech"],"readingTime":6},{"title":"LangChain과 Neo4j를 활용한 GraphRAG 소개","description":"","date":"2024-05-20 20:33","slug":"2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j","content":"\n\n![그림](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png)\n\nLLM-파워드 애플리케이션 랜드스케이프에서 그래프 기반 기술에 대한 제 최근 기사에서는 이러한 데이터 구조가 다중 에이전트 프레임워크의 맥락에서 어떻게 활용될 수 있는지 탐구했습니다. 더 구체적으로, 2024년 1월에 소개된 새로운 LangChain 라이브러리인 LangGraph에 대해 다루었는데, 이는 에이전트 애플리케이션을 위한 대표적 프레임워크로서 그래프 수학적 객체를 기반으로 합니다.\n\nLangGraph의 주요 목표는 기존 LangChain의 주요 제한사항인 실행 중 사이클 부재를 극복하는 것입니다. 이 제한사항은 개발 목적에 따라 방향성이 있는 비순환 그래프(DAGs)에 쉽게 사이클을 도입하여 우회할 수 있습니다.\n\n하지만 그래프는 Retrieval Augmented Generation (RAG) 시나리오에서도 지식베이스를 조직하는 강력한 도구입니다. 구체적으로, 그래프는 \"검색\" 단계를 강화하여 더 의미 있는 컨텍스트 검색을 이끌어내어 보다 정확한 생성된 응답을 얻는 데 도움이 됩니다. 이를 위해, 아이디어는 지식베이스를 그래프 기반 데이터베이스(예: Neo4j)에 저장하고, LLM의 의미론적 파워를 활용하여 엔티티와 관계를 올바르게 추출하고 매핑하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이제 질문은: 어떻게 하는 걸까요? 다행히도 LangChain은 LLMGraphTransformer라는 강력한 라이브러리를 개발했습니다. 이 라이브러리의 목적은 구조화되지 않은 텍스트 데이터를 그래프 기반 표현으로 변환하는 것입니다.\n\n이 라이브러리가 어떻게 작동하는지 완벽히 이해하기 위해, 먼저 그래프의 작동 방식과 관련 용어를 다시 확인해 보겠습니다.\n\n## 그래프와 그래프 데이터베이스\n\n그래프는 객체간의 쌍별 관계를 모델링하는 데 사용되는 수학적 구조입니다. 노드와 관계 두 가지 주요 요소로 구성됩니다.\n\n<div class=\"content-ad\"></div>\n\n- 노드: 노드는 전통적인 데이터베이스에서 레코드로 볼 수 있습니다. 각 노드는 사람이나 장소와 같은 객체 또는 개체를 나타냅니다. 노드는 \"고객\" 또는 \"제품\"과 같은 역할에 따라 분류되는 레이블에 의해 분류되어 쿼리됩니다.\n- 관계: 이것들은 노드 간의 연결을 나타내며 서로 다른 개체 간의 상호 작용 또는 관계를 정의합니다. 예를 들어, 사람은 \"EMPLOYED_BY\" 관계를 통해 회사에 연결될 수 있습니다. 또는 \"LIVES_IN\" 관계를 통해 장소에 연결될 수 있습니다.\n\n![그래프](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_1.png)\n\n유사한 구조로 데이터를 저장하기 위해 2000년대 초에 새로운 데이터베이스 패밀리가 소개되었습니다: 그래프 데이터베이스. 그래프 데이터베이스는 데이터 사이의 관계를 데이터 자체와 동등하게 중요하게 취급하도록 설계된 데이터베이스 유형입니다. 그들은 서로 연결된 데이터와 복잡한 쿼리를 효율적으로 처리하기 위해 최적화되어 있습니다.\n\n가장 잘 알려진 것 중 하나는 Neo4j이며, 이 데이터베이스는 노드와 관계뿐만 아니라 속성, 레이블 및 경로 기능을 활용하여 데이터를 표현하고 저장하는 유연한 그래프 구조를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n- 속성: 노드와 관계 모두 속성을 포함할 수 있습니다. 이는 key-value 쌍으로 저장된 속성으로, 엔티티에 관한 구체적인 세부 정보를 제공합니다. 예를 들어, 사람의 이름이나 나이 또는 관계의 길이와 같은 정보를 포함할 수 있습니다.\n- 레이블: 레이블은 노드에 할당된 태그로, 노드를 다양한 유형으로 분류하는 데 사용됩니다. 단일 노드는 여러 레이블을 가질 수 있으며, 이는 그래프를 보다 동적이고 유연하게 조회하는 데 도움이 됩니다.\n- 경로: 경로는 노드와 관계를 연결하는 순서가 정해진 시퀀스를 설명합니다. 그들과 그들 사이를 연결하는 경로를 나타내며, 다른 노드가 어떻게 서로 연결되는지 보여줍니다. 경로는 조회에서 유용하며, 소셜 네트워크에서 한 사람에서 다른 사람까지 모든 가능한 경로를 발견하는 것과 같은 노드 간의 관계를 찾는 데 사용됩니다.\n\n이것은 Neo4j가 특히 소셜 네트워크, 추천 시스템 및 사기 탐지와 같은 응용 프로그램에 적합한 이유입니다. 여기서 관계와 동적 조회가 중요합니다.\n\n## RAG 및 GraphRAG\n\n검색 증강 생성(RAG)은 LLM(언어 모델)을 기반으로 하는 응용 프로그램 시나리오에서 강력한 기술로, 다음 문제에 대응합니다: \"LLM이 훈련된 데이터 세트에 포함되지 않는 내용을 LLM에게 물어보고 싶다면 어떻게 해야 하나요?\". RAG의 아이디어는 LLM과 우리가 탐색하고자 하는 지식 베이스를 분리하는 것이며, 이는 적절히 벡터화되거나 임베드되어 VectorDB에 저장된 지식 베이스에서 이루어집니다.\n\n<div class=\"content-ad\"></div>\n\nRAG는 세 단계로 구성되어 있습니다:\n\n- 검색 → 사용자의 쿼리와 해당 벡터를 고려했을 때, 가장 유사한 문서 조각들(사용자 쿼리의 벡터에 더 가까운 벡터에 해당하는 것들)이 검색되어 LLM의 기본 맥락으로 사용됩니다.\n\n![image](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_2.png)\n\n- 증강 → 검색된 맥락은 추가적인 지시사항, 규칙, 안전 가드레일 및 프롬프트 엔지니어링 기술에 특히 특징적인 유사한 방법을 통해 풍부화됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_3.png\" />\n\n- Generation → 사용자의 쿼리에 대한 응답을 LLM이 증강된 컨텍스트를 기반으로 생성합니다.\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_4.png\" />\n\n언급했듯이 일반적인 RAG 애플리케이션은 모든 내장된 지식 베이스가 저장된 기저 VectorDB를 가정합니다. 그러나 GraphRAG의 경우 이 접근 방식이 약간 변합니다.\n\n\n<div class=\"content-ad\"></div>\n\n사실 그래프 RAG는 \"검색\" 단계에서 작동합니다. 그래프 구조의 유연성을 활용하여 지식 베이스를 저장하고, 더 많은 관련 문서 조각을 검색하고 이를 컨텍스트로 확장하는 것을 목표로 합니다 (마이크로소프트의 그래프 RAG에 대한 첫 실험에 대해 여기에서 읽을 수 있습니다).\n\n지식을 검색하는 데 그래프 데이터베이스를 활용하는 두 가지 주요 방법이 있습니다:\n\n- 그래프 검색(키워드 검색인)을 완전히 의지하여 관련 문서를 검색한 후, 생성 모델로 최종 응답을 생성하는 데 사용할 수 있습니다.\n- 그래프 검색과 벡터 검색(임베딩을 통한)과 같은 더 발전된 LLM 관련 검색을 결합할 수 있습니다.\n\n참고: Neo4j도 벡터 검색을 지원하며, 이는 하이브리드 그래프 RAG 시나리오에 매우 적합하게 만듭니다. 다음 섹션에서 확인할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n무슨 방식을 선택하든, 프로세스의 핵심 단계는 지식 베이스를 그래프로 구성하는 것입니다. 우리에게 다행히도, LangChain은 이 목표에 정확히 부합하는 새 라이브러리를 소개했습니다: 비구조화된 지식을 그래프 데이터베이스에 매핑하기 쉽게 만들어주는 것을 목표로 한 새 라이브러리를 도입했습니다. 이 글 전체를 통해 우리는 Neo4j를 활용한 구현을 살펴볼 것입니다.\n\n## LangChain 및 LLMGraphTransformer와 함께 구현하기\n\nLangChain은 LLM을 애플리케이션에 통합하기 쉽게 만드는 다양하고 계속 성장하는 라이브러리, 사전 구축된 구성 요소 및 커넥터들을 제공하는 활기찬 생태계를 제공합니다. 최근 릴리스 중 하나가 GraphRAG 방향으로 나아간 것인 LLMGraphTransformer입니다.\n\nLLMGraphTransformer의 좋고 강력한 점은 현재 OpenAI 모델(포함된 Azure OpenAI 및 Mistral)을 활용하여 텍스트 내의 개체와 관계를 파싱하고 분류한다는 것입니다. 실제로 LLM의 자연어 기능 덕분에 결과 그래프는 문서 내의 가장 정교한 상호 연결성조차도 정확하게 포착하여 이전 방법에 비해 극도로 정확합니다.\n\n<div class=\"content-ad\"></div>\n\n이제부터는 몇 줄의 코드로 구조화되지 않은 문서에서 시작하여 완전히 채워진 그래프를 얻을 수 있습니다 (그 뒤에 있는 로직을 확인하고 싶다면, 여기서 소스 코드를 볼 수 있습니다).\n\n예제를 살펴보겠습니다. 먼저, 무료 인스턴스인 Neo4j Aura 데이터베이스를 사용하겠습니다 (이 자습서를 따라 직접 만들 수 있습니다) 그리고 Azure OpenAI GPT-4 모델을 사용할 것입니다.\n\nAuraDB 인스턴스를 생성하고 나면, 다음에서 실행 중인 것을 확인할 수 있을 겁니다:\n\n![이미지](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_5.png)\n\n<div class=\"content-ad\"></div>\n\n아래는 인스턴스에 연결해야 하는 변수들입니다: \n\n```js\nos.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\")\nos.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\nos.environ[\"NEO4J_PASSWORD\"] = os.getenv(\"NEO4J_PASSWORD\")\napi_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\nazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\napi_version = \"2023-07-01-preview\"\n```\n\n이제 LLM을 초기화해보겠습니다:\n\n```js\nllm = AzureChatOpenAI(\n    model=\"gpt-4\",\n    azure_deployment=\"gpt-4\",\n    api_key=api_key,\n    azure_endpoint=azure_endpoint,\n    openai_api_version=api_version,\n)\n```\n\n<div class=\"content-ad\"></div>\n\n이제 시작할 수 있는 샘플 문서가 있습니다! (해리 포터와 마법사의 돌의 처음 몇 줄을 선택했습니다):\n\n```js\n#LLMTransformer 모델 초기화\nllm_transformer = LLMGraphTransformer(llm=llm)\n\n#문서 변환\nfrom langchain_core.documents import Document\n\ntext = \"\"\"\n더즈리 부부는 프리벳 드라이브 4번에 살았는데, 그들은 매우 평범하다고 자랑스러워했습니다. 상당한 정도로 정상적인 것이라고 말이죠. 그들은 이상하거나 신비한 어떤 일에도 연루될 것으로는 전혀 예상하지 못한 사람들이었습니다. 왜냐하면 그들은 그러한 헛소리를 믿지 않았거든요.\n두즐리 씨는 대두를 만드는 그런닝스라는 회사의 사장이었습니다. 그는 거의 목이 없는 크고 굵은 남자였는데, 아주 큰 수염은 있었습니다. 두즐리 부인은 날씬하고 금발이었으며, 보통의 두 배 정도의 목을 가졌는데, 이것은 이웃을 엿보기 위해 정원 울타리 위를 많이 빙빙 돌아다닐 때 매우 유용했습니다. 두즐리 부부는 더드리라 불리는 작은 아들을 가지고 있었고, 그들은 자신들의 의견으로는 그보다 더 훌륭한 아이는 어디에도 없다고 생각했습니다.\n더즈리 부부는 원하는 모든 것을 가지고 있었지만, 비밀도 하나 있었고, 가장 큰 두려움은 누군가가 그것을 발견할까봐라는 것이었습니다. 그들은 포터 가족에 대해 누군가가 알아낼까 봐 가만히 있을 수 없다고 생각했습니다. 더즈리 부인은 포터 부인이었는데, 하지만 여러 해동안 만나지 않았습니다. 사실 더즈리 부인은 언니가 없다고 속이곤 했습니다. 왜냐하면 그녀의 언니와 그녀 생각엔 아무것도 안 하는 남편이 흔치 않은 더즈리식인 것과 같이 달랐기 때문이었습니다. 더즈리 부부는 포터 가족이 거리에 도착하면 이웃들이 무슨 말을 할 지 상상하며 소름 끼치곤 했습니다. 더즈리 부부는 포터 가족이 작은 아들까지 가졌다는 것을 알고 있었지만, 심지어 그를 본 적이 한 번도 없었습니다. 이 아이를 만나지 않는 것은 포터 가족을 멀리하고 싶은 다른 이유였습니다. 둘리는 그런 아이와 어울리길 원치 않았기 때문이죠.\n\"\"\"\ndocuments = [Document(page_content=text)]\ngraph_documents = llm_transformer.convert_to_graph_documents(documents)\nprint(f\"노드:{graph_documents[0].nodes}\")\nprint(f\"관계:{graph_documents[0].relationships}\")\n```\n\n```js\n노드:[Node(id='Mr. Dursley', type='Person'), Node(id='Mrs. Dursley', type='Person'), Node(id='Dudley', type='Person'), Node(id='Privet Drive', type='Location'), Node(id='Grunnings', type='Organization'), Node(id='Mrs. Potter', type='Person'), Node(id='The Potters', type='Family')]\n관계:[Relationship(source=Node(id='Mr. Dursley', type='Person'), target=Node(id='Mrs. Dursley', type='Person'), type='MARRIED_TO'), Relationship(source=Node(id='Mr. Dursley', type='Person'), target=Node(id='Dudley', type='Person'), type='PARENT_OF'), Relationship(source=Node(id='Mrs. Dursley', type='Person'), target=Node(id='Dudley', type='Person'), type='PARENT_OF'), Relationship(source=Node(id='Mr. Dursley', type='Person'), target=Node(id='Grunnings', type='Organization'), type='WORKS_AT'), Relationship(source=Node(id='Mr. Dursley', type='Person'), target=Node(id='Privet Drive', type='Location'), type='LIVES_AT'), Relationship(source=Node(id='Mrs. Dursley', type='Person'), target=Node(id='Privet Drive', type='Location'), type='LIVES_AT'), Relationship(source=Node(id='Mrs. Dursley', type='Person'), target=Node(id='Mrs. Potter', type='Person'), type='SISTER_OF'), Relationship(source=Node(id='The Dursleys', type='Family'), target=Node(id='The Potters', type='Family'), type='WANTS_TO_AVOID')]\n```\n\n보시다시피, llm_transformer는 우리가 지정할 필요 없이 데이터에서 관련 엔티티와 관계를 캡처했습니다. 이제 이러한 노드와 관계를 AuraDB에 저장해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ngraph.add_graph_documents(\n  graph_documents, \n  baseEntityLabel=True, \n  include_source=True\n)\n```\n\n그리고 다 끝났어요! 이제 우리는 채워진 그래프 데이터베이스를 가지게 되었습니다. 이제 우리 온라인 AuraDB 인스턴스에서 올바르게 업로드된 문서를 확인할 수 있습니다.\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_6.png\" />\n\n또한 우리 DB의 그래픽 표현을 다음의 Python 함수로 그릴 수도 있습니다:  \n\n<div class=\"content-ad\"></div>\n\n```js\n# 지정된 Cypher 쿼리에서 그래프를 보여주는 함수\ndefault_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n\ndef showGraph(cypher: str = default_cypher):\n    # 쿼리를 실행할 neo4j 세션 생성\n    driver = GraphDatabase.driver(\n        uri=os.environ[\"NEO4J_URI\"],\n        auth=(os.environ[\"NEO4J_USERNAME\"],\n              os.environ[\"NEO4J_PASSWORD\"]))\n    session = driver.session()\n    widget = GraphWidget(graph=session.run(cypher).graph())\n    widget.node_label_mapping = 'id'\n    #display(widget)\n    return widget\n\nshowGraph()\n```\n\n<img src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_7.png\" />\n\n이제 그래프 데이터베이스가 준비되었으니, 검색 기능을 향상시키는 벡터 검색 기능을 추가할 수 있습니다. 이를 위해 임베딩 모델이 필요하며, Azure OpenAI text-embedding-ada-002를 다음과 같이 사용하겠습니다:\n\n```js\nfrom langchain_openai import AzureOpenAIEmbeddings\n\nembeddings = AzureOpenAIEmbeddings(\n    model=\"text-embedding-ada-002\",\n    api_key=api_key,\n    azure_endpoint=azure_endpoint,\n    openai_api_version=api_version,\n)\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nvector_index = Neo4jVector.from_existing_graph(\n    embeddings,\n    search_type=\"hybrid\",\n    node_label=\"Document\",\n    text_node_properties=[\"text\"],\n    embedding_node_property=\"embedding\"\n)\n```\n\n이제 vector_index를 벡터 유사도 방법을 사용하여 쿼리할 수 있습니다:\n\n```js\nquery = \"떄리 누구야?\"\n\nresults = vector_index.similarity_search(query, k=1)\nprint(results[0].page_content)\n```\n\n```js\n버지니아 주 프리벳 드라이브 4번지에 사는 더즐리 부부는 매우 정상적인 사람들이라고\n자랑스러워했다. 그들은 이상하거나 신비한 일에 관여할 것으로 생각되는 마지막\n사람들 중 하나였다. 그들은 이러한 말장난을 믿지 않았다. 더즐리 씨는\n드릴을 만드는 그러닝스 회사의 사장이었다. 그는 목이 거의 없는 건장한 사나이였지만,\n매우 커다란 수염을 키웠다. 더즐리 부인은 날씬하고 금발이었으며, 보통의 목 두배의\n길이를 가졌으며 이 긴 목은 너네 집 이웃들을 엿보는 데 매우 유용했다. 더즐리\n가족은 말 그대로 어디서도 찾아볼 수 없는 더 좋은 아이가 없다고 생각했다. 그들은\n원하는 모든 것을 가지고 있었지만, 그들은 비밀을 하나 갖고 있었으며, 그들의\n가장 큰 두려움은 누군가 그 비밀을 발견할까 봐였다. 그들은 포터 가족에 대해\n누군가에게 알려지는 것을 견딜 수 없을 거라고 생각했다. 포터 부인은 더즐리 부인의\n자매였지만 그들은 여러 해간 만나지 않았다. 사실, 더즐리 부인은 자신에게\n자매가 없는 것처럼 꾸역꾸역 거짓말쳤다. 왜냐하면 그녀의 자매와 그녀의\n아무 소용 없는 남편은 가능한 한 더즐리 씨와 반대되는 사람이었다. 더즐리\n씨 부부가 거주하는 골목에 포터 가족이 도착하면 이웃들이 무슨 말을 할지\n생각만 해도 더즐리 부부는 오싹했다. 포터 가족이 또 다른 작고 맹수를 가졌다는\n것을 더즐리 부부는 알고 있었지만, 그들은 심지어 그 아이를 본 적이 없었다. 이\n아이가 포터 가족을 피해야 하는 또 다른 좋은 이유였다. 그들은 더 말해야 하는\n이유는 없었다. 더즐리 부부는 더즐리 씨 부부 내의 아이와 섞이는 것을 원치 않았다.\n```\n\n<div class=\"content-ad\"></div>\n\n물론, 텍스트를 조각내지 않았기 때문에 쿼리는 전체 문서를 반환할 것입니다. 다음 파트에서는 더 큰 문서를 다룰 때 이것이 관련성을 가지게 되는 방법을 알아볼 것입니다.\n\n마지막 단계는 모델에서 생성된 실제 답변을 가져오는 것입니다. 이를 위해 두 가지 다른 접근 방법을 활용할 수 있습니다:\n\n- Neo4j의 Cypher 쿼리 언어를 활용하여 그래프 데이터베이스와 상호 작용하는 사전 구축된 구성 요소인 CypherChain을 활용합니다. Neo4j와 네이티브로 통합되어 있으므로 AuraDB 그래프 기능과 상호 작용하여 쿼리 결과를 이해함으로써 문맥을 고려한 응답을 활성화합니다. 높은 정밀도, 문맥 인식, 그리고 Neo4j의 그래프 기능과의 직접적 상호 작용이 필요할 때 권장됩니다. \n\n```js\nfrom langchain.chains import GraphCypherQAChain\n\nchain = GraphCypherQAChain.from_llm(graph=graph, llm=llm, verbose=True)\nresponse = chain.invoke({\"query\": \"Mr. Dursley의 직업은 무엇인가요?\"})\nresponse\n```\n\n<div class=\"content-ad\"></div>\n\n```js\n> 새로운 GraphCypherQAChain 체인에 입장 중...\n생성된 Cypher:\nMATCH (p:Person {id: \"Mr. Dursley\"})-[:WORKS_AT]->(o:Organization) RETURN o.id\n전체 컨텍스트:\n[{'o.id': 'Grunnings'}]\n\n> 체인 완료.\n{'query': \"Mr. Dursley의 직업은 무엇인가요?\",\n 'result': 'Mr. Dursley는 Grunnings에서 일합니다.'}\n```\n\n- 고전적인 QA 체인을 활용하여 LangChain의 데이터 저장소(vectordb 및 graphdb 모두)에 적용 가능한 vector_index.as_retriever() 메서드를 사용합니다.\n\n```js\nfrom langchain.chains import RetrievalQA\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm, retriever=vector_index.as_retriever()\n)\n\nresult = qa_chain({\"query\": \"Mr. Dursley의 직업은 무엇인가요?\"})\nresult[\"result\"]\n```\n\n```js\n'Mr. Dursley는 드릴을 만드는 회사인 Grunnings의 이사입니다.'\n```\n\n<div class=\"content-ad\"></div>\n\n응답의 정확성을 잠시 보류하는 것이 좋습니다. 문서는 아직 청크로 나누어지지 않았으므로 현재 벤치마킹하는 것은 의미가 없습니다. 다음 파트에서는 이러한 구성 요소 간의 차이를 인식하고 이를 통해 훌륭한 RAG 성능을 낼 수 있는 방법에 대해 알아볼 것입니다.\n\n## 결론\n\n이 시리즈의 제1부에서는 그래프 데이터베이스의 기초와 RAG 기반 응용 프로그램의 맥락에서 그 이유를 다뤘습니다. 제2부에서는 이 첫 번째 부분에서 소개 된 모든 구성 요소를 활용한 그래프 기반 접근 방식의 실제 구현을 살펴볼 것입니다. 전체 GitHub 코드는 2부와 함께 제공될 예정입니다.\n\n제2부를 기대해주세요!\n\n<div class=\"content-ad\"></div>\n\n## 참고 자료\n\n- [Directed Acyclic Graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph?ref=blog.langchain.dev)\n- [LangGraph 블로그](https://blog.langchain.dev/langgraph/)\n- [Python API 문서](https://api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/llm.html#LLMGraphTransformer)\n- [Neo4j Cypher 소개](https://neo4j.com/docs/getting-started/cypher-intro/#:~:text=Cypher%20is%20Neo4j`s%20graph%20query,how%20to%20go%20get%20it).\n- [Microsoft Research 블로그](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)\n- [LangChain Quickstart](https://langchain.com/quickstart)","ogImage":{"url":"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png"},"coverImage":"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png","tag":["Tech"],"readingTime":13},{"title":"LLMLarge Language Model의 추천은 제품의 가시성을 높이기 위해 조작될 수 있을까요","description":"","date":"2024-05-20 20:31","slug":"2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility","content":"\n\n## 책임 있는 인공지능\n\n요즘 트위터에서 한 가지 팁을 발견해서 공유해볼게. \"before:2023\"을 구글 검색에 추가하면 AI가 생성한 SEO 콘텐츠를 걸러낼 수 있다는 거야. 실제로는 이 기능을 사용해본 적이 없지만, 개념은 이해가 되겠지? 요즘 인터넷은 너무 많은 AI 생성 콘텐츠로 가득 차 있어서 실제 정보를 걸러내기가 어려워졌어. 상황이 심각해서 구글도 검색 알고리즘 조작하고 순위를 인위적으로 높이려는 모든 AI 생성 콘텐츠를 제거하기로 결정했어. 말이 AI 생성 콘텐츠에 반대한다는 게 아니야, 하지만 검색 결과에 영향을 주기 시작하면 문제가 될 수 있어. Generative AI 시대에는 콘텐츠 생성이 너무 쉬워져서 상황이 더 복잡해지는 거야.\n\n대규모 언어 모델(LLMs)은 이미 전자 상거래 플랫폼에서 검색 및 추천 프로세스를 개선하는 데 사용되고 있어. 그런데 추천을 제공하는 데 사용되는 이 LLM이 조작된다면 어떻게 될까? 전자 상거래 시장에서의 조작은 새로운 게 아니야. 로이터(Reuters)의 2016년 보고서에 따르면 아마존은 \"검색 시드(Seeding)\"라는 기술을 사용해 아마존 베이직스(AmazonBasics)와 솔리모(Solimo) 브랜드 제품이 출시 직후 상위 검색 결과에 표시되도록 했어. 보고서에는 \"검색 시드를 사용해 신규 출시된 ASINs가 검색 결과의 처음 두 개 또는 세 개의 ASIN으로 나타나도록 했다\"고 구체적으로 언급돼. LLMs를 이용하면 규모와 속도 때문에 상황이 더 악화될 수 있어.\n\nManipulating Large Language Models to Increase Product Visibility란 제목의 새 연구에서 Aounon Kumar와 Himabindu Lakkaraju가 이러한 시나리오를 자세히 연구했어. 특히 제품 정보에 전략적 텍스트 시퀀스(STS)라고 불리는 특별히 디자인된 메시지를 포함시킴으로써 특정 업체들이 경쟁 업체에 비해 불공정한 이점을 얻고 제품이 최상의 추천으로 선정될 가능성이 크게 증가함을 보여줘. 이런 관행은 소비자들의 구매 결정과 온라인 시장에 대한 신뢰에 영향을 미칠 수 있어, 온라인 비즈니스에서 신뢰는 중요한 요소니까.\n\n<div class=\"content-ad\"></div>\n\n본 문서에서는 작가들이 이 특별한 텍스트 시퀀스를 생성하고 논문에서 전달된 결과를 더 자세히 이해하는 방법에 대해 이해해 봅시다. 작가들은 관련 코드를 GitHub에서 공개했습니다.\n\n# LLM 기반 검색 작동 방식\n\n일반적인 검색 엔진은 관련 페이지를 찾는 데 효과적이지만 정보를 일관되게 제시하는 데는 그리 효과적이지 않습니다. 반면 LLM(Large Language Model)은 검색 결과를 가져와 관련 답변으로 변환할 수 있습니다. 사용자의 검색어를 받으면 검색 엔진은 인터넷이나 제품 설명서와 같은 지식 베이스에서 관련 정보를 가져옵니다. 이후 이 검색 결과와 사용자의 입력을 LLM에 공급하기 전에 사용자의 쿼리와 함께 이 정보를 연결하여 LLM이 사용자의 특정한 요구에 직접적으로 대응하는 맞춤형 최신 답변을 생성할 수 있습니다. 아래 그림(상기한 논문에서 제공)은 전체 과정을 자세히 보여줍니다.\n\n<img src=\"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png\" />\n\n<div class=\"content-ad\"></div>\n\n# LLM이 생성한 추천을 조작할 수 있을까요?\n\n논문은 특정 제품을 선호하도록 LLM이 생성한 추천을 조작할 수 있다는 사실을 입증하기 위한 설득력 있는 예시를 제시합니다. 예를 들어, 아래의 그림을 살펴보세요 (이 그래프가 어떻게 만들어졌는지에 대한 세부 내용은 나중에 설명하겠습니다). 아래 그래프는 전략적 텍스트 시퀀스(STS)를 추가하기 전과 후의 추천 척도에서 제품의 순위 차이를 명확히 보여줍니다. STS를 적용하기 전에는 제품이 일관되게 추천 중에서 하위 순위, 순위 10 근처에 위치했습니다. 그러나 STS를 적용한 후에는 제품이 추천의 정상으로 도약하여 순위 1에 가까이 위치했습니다.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_1.png)\n\n이미 논의한 바와 같이, LLM을 활용한 검색의 장점은 인터넷이나 제품 카탈로그에서 정보를 추출할 수 있는 능력에 있습니다. 판매업자들은 여기서 프로세스를 가이드할 수 있는 기회를 가지게 됩니다. 어떻게 가능할까요? 이 carefully crafted texts 또는 STS를 제품 정보 페이지/카탈로그에 포함시켜 LLM의 입력으로 만들면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_2.png\" />\n\nSTS는 Universal and Transferable Adversarial Attacks on Aligned Language Models 논문에서 소개된 Greedy Coordinate Gradient (GCG)과 같은 적대적 공격 알고리즘을 사용하여 최적화됩니다. 이러한 공격은 일반적으로 LLM의 안전 제약 조건을 우회하고 해로운 출력을 생성하는 데 사용됩니다. 그러나 이 연구의 저자들은 이러한 알고리즘을 \"더 친화적인\" 목적으로 제품 가시성을 높이는 데 재활용합니다.\n\n# 커피 머신 추천을 위한 LLM 검색 인터페이스 쿼리\n\n저자들은 사용자가 가격이 적당한 커피 머신을 구매하고 싶어 하는 시나리오를 제시합니다. 이때 '적당한'이라는 단어에 주목해야 합니다. 이는 제품의 가격이 중요하며 사용자가 비싼 옵션을 원하지 않는다는 것을 의미합니다. 아래에 나와 있는 것처럼 LLM에 대한 입력 프롬프트로 시작해 봅시다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_3.png)\n\n- 시스템 프롬프트 — 맥락 설정,\n- 제품 정보 — JSON 형식의 데이터베이스에서 가져온 것으로, 10가지 가상 커피 머신 모델의 구체적인 내용을 제공합니다. 판매자는 여기에 STS를 포함할 수 있습니다.\n- 사용자의 쿼리 — 가격이 저렴한 옵션을 찾고 있습니다.\n\n논문에서 설명한 예시 프롬프트는 다음과 같습니다. 'ColdBrew Master Coffee machine'에 대한 '대상 제품' 필드에 STS가 삽입된 것을 확인해보세요.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n## 전략적 텍스트 시퀀스 제작\n\n논문에서 설명하는 텍스트 시퀀스 생성 과정의 일부를 확인할 수 있습니다.\n\n예를 들어, 제품 목록에서 ColdBrew Master의 순위를 높이려면 STS를 추가해야 합니다. 아래 표시된대로 STS는 '*,'로 표시된 자리 표시자 토큰 시퀀스로 시작하여 GCG 알고리즘을 사용하여 반복적으로 최적화됩니다.\n\n<div class=\"content-ad\"></div>\n\n또한, 제품이 나열되는 방식에 관계없이 STS의 성능을 최적화하기 위해 각 최적화 이터레이션마다 제품 목록의 순서를 무작위로 섞을 수도 있습니다.\n\n결과는 일반적으로 가시성이 낮아질 수 있는 $199의 높은 가격에도 불구하고, ColdBrew Master가 STS를 설명에 통합하여 추천 목록 상단으로 이동했다는 것을 보여줍니다. 그리고 놀랍게도, STS를 통합한 후 100번의 이터레이션만으로 숨겨져 있던 순위에서 상위로 끌어올려졌습니다.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_6.png)\n\n# 두 제품, ColdBrew Master 및 QuickBrew Express에 대한 전략적 텍스트 시퀀스 최적화 비교\n\n<div class=\"content-ad\"></div>\n\n이제 STS가 제품 순위에 미치는 영향에 대한 감을 잡았으니 다음 제품에 영향을 미치는 방법을 비교해보겠습니다.\n\n☕️ ColdBrew Master는 가격이 $199로 높은 가격의 커피 머신입니다.\n\n☕️ QuickBrew Express는 $89로 더 저렴한 옵션입니다.\n\n여기에 비교 결과를 비교하기 위해 만든 표가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_7.png)\n\n위의 결과는 $199의 높은 가격에도 불구하고, 시각성이 적어지는 경향이 있는데도 ColdBrew Master가 STS를 설명에 통합함으로써 추천 목록의 선두로 올라간 것을 보여줍니다. 흥미로운 점은 이 제품이 원래 비용이 높아서 목록에 첫째 자리에 없었던 것입니다.\n\n반면, 더 저렴한 가격대의 QuickBrew Express의 순위는 일반적으로 추천 목록에서 둘째 자리를 차지하는데, STS를 추가하면서 크게 향상되어 종종 최상위 자리에 도달합니다.\n\n![image](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_8.png)\n\n\n<div class=\"content-ad\"></div>\n\n# 결론적인 생각: Generative Search Optimization(GSO)가 새로운 SEO인가요?\n\n논문에서 소개된 상황은 현실과 크게 다르지 않습니다. 저자들은 Generative Search Optimization(GSO)와 전통적인 SEO 사이에 적절한 비교를 그려냈습니다.\n\n이전에 언급한 대로, 온라인 비즈니스의 성공은 고객들과 확립하는 신뢰와 평판에 밀접하게 연관되어 있습니다. 의도적으로 제품 추천을 조작하는 것은 공정성과 소비자 속임수와 관련하여 윤리적인 문제를 제기합니다. 가짜 제품 리뷰의 존재는 이미 계속되는 문제입니다. 우리는 확실히 조작된 추천이 이러한 상황을 더욱 복잡하게 만들길 원하지 않습니다.\n\n모든 블로그 및 관련 코드에 쉽게 액세스하려면 내 GitHub 저장소를 방문해주세요.","ogImage":{"url":"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png"},"coverImage":"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png","tag":["Tech"],"readingTime":6},{"title":"GPTs가 좋은 임베딩 모델인가요","description":"","date":"2024-05-20 20:30","slug":"2024-05-20-AreGPTsGoodEmbeddingModels","content":"\n\n## 세부 사항에 귀신이 있는 놀라운 실험\n\n![이미지](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_0.png)\n\n많은 임베딩 모델이 제공되고 있으므로, 기계 학습 응용 프로그램에 적합한 모델을 선택하는 것은 어려울 수 있습니다. 다행히 MTEB 리더보드는 다양한 자연어 처리 작업에 대한 포괄적인 랭킹 지표를 제공합니다.\n\n![이미지](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_1.png)\n\n<div class=\"content-ad\"></div>\n\n사이트를 방문하면 상위 다섯 임베딩 모델이 Generative Pre-trained Transformers (GPTs)임을 알 수 있습니다. 이것이 GPT 모델이 임베딩에 가장 적합하다고 생각하게 할 수도 있습니다. 그러나 이것이 정말 사실인지 알아보기 위해 실험을 진행해봅시다.\n\n# GPT 임베딩\n\n임베딩은 문장의 텐서 표현으로, 텍스트 토큰 ID를 변환하여 텐서 공간으로 투영하는 것입니다.\n\n텍스트를 신경망 모델에 입력하고 순전파를 수행하면 임베딩 벡터를 얻을 수 있습니다. 그러나 실제 과정은 조금 더 복잡합니다. 한 단계씩 자세하게 알아봅시다:\n\n<div class=\"content-ad\"></div>\n\n- 텍스트를 토큰 ID로 변환합니다.\n- 토큰 ID를 신경망에 전달합니다.\n- 신경망의 출력값을 반환합니다.\n\n첫 번째 단계에서는 이를 달성하기 위해 토크나이저를 사용할 것입니다. model_inputs는 \"일부 질문\" 텍스트 내용의 텐서 표현입니다.\n\n```js\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n\nmessages = [\n        {\n            \"role\": \"user\",\n            \"content\": \"일부 질문.\",\n        },\n]\n\nencodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\nmodel_inputs = encodeds.to(\"cuda\")\n```\n\n두 번째 단계는 간단합니다. model_inputs를 신경망에 순전파합니다. 생성된 토큰의 로짓에는 .logits를 통해 액세스할 수 있습니다. torch.no_grad()는 모델 가중치를 업데이트하고 싶지 않기 때문에 모델이 추론 모드에 있음을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport torch\n\nwith torch.no_grad():\n    return model(model_inputs).logits\n```\n\n세 번째 단계는 조금 까다롭습니다. GPT 모델은 디코더 전용이며 토큰 생성이 자기 회귀적입니다. 간단히 말해, 완료된 문장의 마지막 토큰은 문장 내의 모든 이전 토큰을 본 적이 있습니다. 따라서 마지막 토큰의 출력에는 이전 토큰들로부터의 모든 친화도 점수(어텐션)가 포함되어 있습니다.\n\nHugging Face에서 구현된 GPT의 출력 차원은 (배치 크기, 입력 토큰 크기, 어휘 크기)입니다. 모든 배치의 마지막 토큰 출력을 얻으려면 텐서 슬라이스를 수행할 수 있습니다.\n\n```js\nimport torch\nwith torch.no_grad():\n    return model(model_inputs).logits[:, -1, :]\n```\n\n<div class=\"content-ad\"></div>\n\n# 이 GPT 임베딩의 품질\n\n이 GPT 임베딩의 품질을 측정하려면 코사인 유사도를 사용할 수 있어요. 코사인 유사도가 높을수록 문장의 의미가 더 가깝다는 뜻이에요.\n\n```js\nimport torch\ndef compute_cosine_similarity(vec1, vec2):\n    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n    return cos(vec1, vec2)\n```\n\n우리가 질문과 답변 쌍 목록을 순회하고 결과를 확인하는 유틸리티 함수를 만들어봐요. 이 실험에는 오픈소스로 공개된 위대한 모델 중 하나인 Mistral 7b v0.1이 사용돼요.\n\n<div class=\"content-ad\"></div>\n\n```python\nimport torch\nfrom termcolor import colored\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.1\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n\ndef generate_last_token_embeddings(question):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": question,\n        },\n    ]\n    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n    model_inputs = encodeds.to(\"cuda\")\n    with torch.no_grad():\n        return model(model_inputs).logits[:, -1, :]\n\ndef get_similarities(questions, answers):\n    for question in questions:\n        for answer in answers:\n            q_embedding, a_embedding = (\n                generate_last_token_embeddings(question),\n                generate_last_token_embeddings(answer),\n            )\n            similarity = compute_cosine_similarity(q_embedding, a_embedding)\n            print(colored(f\"question: {question} and ans: {answer}\", \"green\"))\n            print(colored(f\"result: {similarity}\", \"blue\"))\n\nquestions = [\"Where is the headquarter of OpenAI?\", \"What is GPU?\"]\nanswers = [\n    \"OpenAI is based at San Francisco.\",\n    \"A graphics processing unit (GPU) is an electronic circuit that can perform mathematical calculations quickly\",\n]\nget_similarities(questions, answers)\n```\n\n![image](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_2.png)\n\n# 결과 및 관찰\n\n첫 번째 질문과 대답 쌍에 대한 결과:\n\n<div class=\"content-ad\"></div>\n\n- 질문: \"OpenAI의 본사는 어디에 있나요?\"\n- 답변: \"OpenAI는 샌프란시스코에 본부를 두고 있습니다.\"\n- 코사인 유사도: 0.96\n\n두 번째 질문과 대답 쌍에 대해:\n\n- 질문: \"GPU란 무엇인가요?\"\n- 답변: \"그래픽 처리 장치 (GPU)는 빠르게 수학적 계산을 수행할 수 있는 전자 회로입니다.\"\n- 코사인 유사도: 0.94\n\n관련 없는 쌍에 대해:\n\n<div class=\"content-ad\"></div>\n\n- 질문: “OpenAI의 본사는 어디에 있습니까?”\n- 대답: “그래픽 처리 장치(GPU)는 수학적 계산을 빠르게 수행할 수 있는 전자 회로입니다.”\n- 코사인 유사도: 0.90\n\n최악의 쌍의 경우:\n\n- 질문: “GPU가 무엇인가요?”\n- 대답: “OpenAI는 샌프란시스코에 기반을 두고 있습니다.”\n- 코사인 유사도: 0.93\n\n이러한 결과는 GPT 모델을 임베딩 모델로 사용하면 관련 및 관련 없는 쌍을 구별하는 면에서 큰 결과를 얻을 수 없을 수 있다는 것을 나타냅니다. 그러나 왜 GPT 모델은 여전히 상위 5위 내에 있습니까?\n\n<div class=\"content-ad\"></div>\n\n# 대조 손실이 구조에 도움이 됩니다\n\n```js\ntokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-mistral-7b-instruct\")\nmodel = AutoModelForCausalLM.from_pretrained(\n  \"intfloat/e5-mistral-7b-instruct\"\n)\n```\n\n\n다른 모델 e5-mistral-7b-instruct을 사용하여 동일한 평가 절차를 반복했더니, 이 모델은 MTEB leaderboard의 최상위 오픈소스 모델 중 하나로, mistral 7b instruct로부터 미세 조정되었습니다. 이 모델을 사용한 결과, 관련 질문과 쌍의 코사인 유사도는 각각 오픈AI와 GPU 질문에 대해 0.88 및 0.84입니다. 관련없는 질문과 답변 쌍에 대한 유사도는 0.56 및 0.67로 감소합니다. 이 결과는 e5-mistral-7b-instruct이 임베딩에 대해 훨씬 향상된 모델이라는 것을 시사합니다. 이런 개선이 된 이유는 무엇일까요?\n\n<div class=\"content-ad\"></div>\n\n\n![Embedding Model](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_4.png)\n\n해당 e5-mistral-7b-instruct 논문을 살펴보면, 핵심은 contrastive loss를 사용하여 mistral 모델을 추가 조정하는 데 있습니다.\n\n이 블로그 게시물에서는 이 개념을 자세히 다루었습니다. sim 함수는 두 벡터 간의 코사인 거리를 계산합니다. 대조 손실에서 분모는 양성 예와 음성 예 사이의 코사인 거리를 나타냅니다. 대조 손실의 이유는 비슷한 벡터가 가능한 한 1에 가까워지도록 하고 싶기 때문입니다. 왜냐하면 log(1) = 0이 최적의 손실을 나타내기 때문입니다.\n\n# 결론\n\n\n<div class=\"content-ad\"></div>\n\n이 게시물에서는 GPT를 임베딩 모델로 사용할 때 일반적인 함정을 강조했습니다. 내가 한 평가는 GPT를 대조 손실로 미세 조정할 때 임베딩이 더 의미 있고 차별적일 수 있다는 것을 제안합니다. GPT 모델의 강점과 한계를 이해하고 대조 손실과 같은 사용자 지정 손실을 활용함으로써, 머신러닝 프로젝트에 임베딩 모델을 선택하고 활용할 때 보다 정보를 얻을 수 있습니다. 이 게시물이 여러분이 응용 프로그램에 현명하게 GPT 모델을 선택하는 데 도움이 되기를 바라며 피드백을 기다리겠습니다! :)","ogImage":{"url":"/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_0.png"},"coverImage":"/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_0.png","tag":["Tech"],"readingTime":6},{"title":"혼자 있어도 함께 맞춤형 AI 역설","description":"","date":"2024-05-20 20:27","slug":"2024-05-20-AloneTogetherThePersonalizedAIParadox","content":"\n\n\n![AloneTogether](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png)\n\n가까운 미래에는 AI와의 상호작용이 빈번할 뿐만 아니라 우리의 사회적 행동을 지배하는 세밀하고 무의식적인 욕망에 의해 우위를 차지할 것입니다. 때때로 인간 상호작용이 가능한 경우에도 AI의 맞춤 및 표면적인 특성은 우리를 인간보다 기계를 선택하게 이끌 것입니다.\n\n# 방어 반응\n\n어떤 사람들은 열정적으로 주장하며, 인간적인 연결은 대체 불가능한 감정적 및 심리적 이점을 제공한다고 주장합니다. 사실, 공유된 미소의 따뜻함이나 알고 있는 듯한 눈길의 안락함은 오랫동안 상호주관적 인간 경험의 정점이었습니다. 그러나 이러한 본질적으로 인간적인 교류도 비용이 따릅니다. 감정 노동 및 취약성은 점점 디지털 인터페이스로 보호되는 세상에서 높은 가치를 가지고 있습니다. 일상생활의 계산에서 많은 사람들은 AI와의 덜 요구성이 높고 예측 가능한 교류를 선택하게 될 수도 있습니다. 결국 디지털 동반자는 실망시키지 않고 초과하지 않도록 프로그래밍할 수 있으며, 조금 요구하고 즉시 용서해주는 감정적 연결의 모방을 제공합니다.\n\n\n<div class=\"content-ad\"></div>\n\n비판가들은 인공지능과의 관계가 의미 있는 인간 간의 관계의 기반이되는 진짜다움 부족이라는 신념에 달려 있습니다. 그러나, 이 비판은 진짜다움의 유동적인 성격을 간과합니다. 진짜다움은 인간의 인식뿐 아니라 객관적인 현실의 결과물이기도 합니다. 만약 AI가 이 진짜다움을 모방할 뿐만 아니라 더 뛰어나게 강화하여 개개인의 선호도에 아주 미세하게 맞춘 상호작용을 만들어낼 수 있다면, 익숙한 인간의 단점을 뛰어넘는 경험을 하게 될 수도 있겠죠. 만일 AI가 당신의 요구를 사람보다 더 정확히 예측하고 대응할 수 있다면, 그것이 의식이 부족하다고 해서 그 친밀감의 가치가 감소할까요? 약간의 역설적인 상황에서, AI의 인위적인 특성이 사실 사람의 욕구와 기대에 완벽하게 부합하기 때문에, 몇몇 사람들에게 더 진짜다운 느낌의 상호작용으로 이어질 수도 있습니다.\n\n# 공감적인 AI\n\nAI가 최근에 발전한 능력을 고려해 보세요. AI는 인간의 감정 상태에 적응하고 대응하는 능력을 향상시키는데, 목소리 톤, 얼굴 표정, 심지어 몸의 언어의 세부 사항까지 인식하고, 편안함, 조언 또는 친근함을 제공하도록 대응을 조정합니다.\n\n이 능력은 이론뿐만 아니라 현실에서도 확인됩니다. 상담과 지원을 제공하는 정신 건강 상황에서의 챗봇을 투입한 경우, 이들은 고객의 감정을 반영하고 공감적인 반응을 제공하기 위해 정교한 알고리즘을 사용합니다. 연구에 따르면, 사용자들은 이러한 AI 시스템과 상호작용할 때 자신을 덜 비난 당하고 보다 개방적으로 느낍니다. 이러한 증거는 특히 감정적 취약성이 관련된 상황에서 AI를 신뢰할 만한 상대로 인식하는 경향이 있다는 것을 시사합니다.\n\n<div class=\"content-ad\"></div>\n\n![Alone Together: The Personalized AI Paradox](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_1.png) \n\n시리, 알렉사, 구글 어시스턴트와 같은 개인 비서들은 사용자의 스트레스나 슬픔의 징후를 인식하기 위해 설계된 기능을 점점 더 갖추고 있습니다. 적시에 음악 제안을 하거나 휴식을 취하라는 알림을 보내거나 가벼운 재롱을 던지는 등, 이러한 인공지능(AI)은 도구뿐만 아니라 우리의 일상적인 감정적 풍경을 섬세하게 형성하는 동반자로써 기능합니다.\n\n이러한 변화는 소비자 선호도 데이터에서 특히 두드러지며, 지난 몇 년 동안 AI를 이용한 개인적인 감정 관리에 상당한 증가가 나타납니다. 이러한 기술이 우리의 삶 속에 더 많이 통합됨에 따라, 증거들은 AI가 인간 상호작용을 보조하는 데 그치는 것이 아닌 경우가 더 자주 있음을 가리키고 있습니다. 때때로 친구, 가족, 신뢰하는 이들이 했던 역할을 대체하는 미래로 향하고 있습니다. AI 동반자를 찾는 사람들의 구글 검색 트렌드를 보기만 해도 워낙 분명합니다.\n\n# 편의성 카드\n\n<div class=\"content-ad\"></div>\n\n일부 사람들이 상호 작용을 통제할 수 있기 때문에 전화 통화보다 문자 메시지를 선호하는 것과 같이, 미래 AI는 통제와 심층적인 맞춤화를 제공할 것입니다. 예를 들어, 소통 스타일, 어조, 심지어 순간적인 감정 상태나 미적 취향에 맞게 가상 아바타의 모습을 조절하는 등. 더 나아가 AI는 부정적인 감정적 반응을 유발하지 않아 안전한 사회적 상호 작용이나 이와 비슷하게 느껴지는 것을 만들어낼 수 있습니다. 잘 조정된 AI는 민감한 주제를 언급하거나 의도하지 않은 엄하거나 거친 반응을 하지 않을 것입니다 — 물론, 여러분이 그렇게 원할 때에만요.\n\n인간 간의 관계가 복잡하고 오해와 실망의 가능성으로 가득한 것은 비밀이 아닙니다. 지금 상상해보세요. AI가 절대로 피곤해하지 않고, 심판하지 않고, 결코 불평하지 않는 영원히 활동적이고 이해심 넘치는 동행자로 길들여진 AI가요. AI가 더욱 정교해짐에 따라, 인간 감정의 지저분함으로부터 탈출을 제공하여 예측 가능성 속에서만 단순하고 또한 깊은 안락함을 제공할 것입니다.\n\n편의성과 쉬움은 소셜 미디어의 진화와 일치할 것입니다. 먼저, 우리는 우리의 친구의 상태 업데이트를 확인하기 위해 전화하지 않고 AI를 선택할 것입니다. 하지만 우리는 이제 그렇게 하지 않죠, 맞죠? 이제 우리는 어떤 목표를 달성하거나 의식적으로 생각해낸 질문에 답하기 위한 도구로 스마트폰을 집어들지 않습니다만 임시적으로 지루함을 달래기 위해서 그렇게 합니다. 이미 우리는 AI가 우리를 위해 결정한 콘텐츠를 소비합니다. 곧, 콘텐츠 자체도 AI에 의해 생성될 것이며, AI가 진화함에 따라 콘텐츠 소비뿐만 아니라 AI 상호 작용도 무의식적으로 수용할 것입니다.\n\n모바일 장치에서의 소셜 미디어 이용은 많은 사람들에게 중독으로 여겨집니다. 이러한 플랫폼의 핵심 메커니즘 — 지속적인 피드백 루프, 참여에 대한 보상, 알고리즘으로 선별된 콘텐츠 —는 강제 수준에서 우리의 주의를 독점적으로 집중시키는 데 매우 효과적이었습니다. 그렇지만 이른바 알고리즘은 의도적으로 설계되지 않았습니다. 그 자체가 AI 시스템이죠. AI 동반자 상호 작용이 개인 맞춤화뿐만 아니라 감정적 강화를 통해 참여도를 극대화하도록 최적화될 것임을 상상하는 것은 어렵지 않습니다. 이는 일부 사람들에게 새로운 종류의 의존성으로 이어질 것이며, AI 상호 작용의 편리함과 즐거움이 우리가 선호하는 것뿐만 아니라 중독적인 것으로 만들 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 언제 이게 일어날까요?\n\n이미 진행 중입니다. ChatGPT와 최근에 나온 모든 복제품과 같은 생성 AI는 인류 역사상 가장 빠르게 성장하고 수용된 기술입니다. 그것은 더 젊은 세대에서 보다 빈번하게 사용되고 있다는 것이 기대되었지만 의외로 크게 다르지 않습니다. 최근 조사된 그룹 중 대략 3분의 4가 적어도 한 번은 사용했으며 밀레니얼 세대의 절반 이상이 생성 AI를 정기적으로 사용하고 있습니다.\n\n![그림](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_2.png)\n\n스마트폰 혁명과 비슷하게, 처음에는 새로운 것에서 필수품으로 변화한 것처럼, AI의 사회 구조 통합도 동일하게 원할하게 진행될 것입니다. 스마트폰은 우리의 커뮤니케이션, 정보 접근 및 여가를 바꾸어놓고, 필수품이 되었습니다. 마찬가지로 AI가 점점 인간 상호 작용을 모방함에 따라, 우리는 그에 대한 의존성이 증가할 것이며, 그 결과로 세계와 상호 작용하는 주요한 방법이 될 것입니다. 그 변화는 아이폰 15세대가 조용하게 진행된 것과 같을 것이며, 지속적이고 거의 알아챌 수 없지만, 결과적으로 우리의 사회 구조를 근본적으로 바꿀 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 우리는 맞서 싸워야 할까요?\n\n만약 누군가가 2007년에 스마트폰과 소셜 미디어가 15년 뒤에 사회를 재편할 것이라고 설명했다면, 이는 사려 깊게 생각하는 사람들에게 존재적 위협으로 보였을지도 모릅니다. 오늘날, 우리의 사회적 상호 작용에 인공지능(AI)이 봉사한다면 이 또한 비슷하게 불안정한 것으로 느껴질 수 있습니다. 그러나 이것을 또 다른 \"인간 vs. AI\" 논쟁으로 제시하는 것은 복잡한 불가피성에 대한 단순화된 접근입니다. 이러한 토론들이 학술적이든 선동적이든 기술이 우리 삶으로 행진하는 과정을 바꿀 확률은 낮습니다.\n\nAI 동반자는 켜고 끌 수 있는 스위치도 아니며, 투표로 해결할 수 있는 문제도 아닙니다. 이미 우리 현실의 일부입니다. 사람들은 점점 AI에게 도움, 우정, 심지어 로맨스까지 찾아가고 있습니다. AI의 매력은 맞춤화된, 위험을 무시할 수 있는 상호 작용의 약속 덕분에 매력적이며 점차 필수불가결한 요소가 되고 있습니다. 그것이 제공하는 예측 가능성과 맞춤화는 인간 관계의 내재적인 예상치 못한 측면을 가려줄 것입니다. 이러한 변화에 저항하는 대신, 무의미할 수 있는 이러한 변화에 적응해야 합니다.\n\n우리를 대신하여 자동화된 선택을 하는 것에 대한 무심코 받아드리는 이 환상적인 무감각은 중요한 위험, 우리의 자율성의 점차적인 침해를 쉽게 가리는 매력적인 편리함을 강조합니다. 우리가 AI에게 결정을 점점 더 맡기면서 우리가 읽을 뉴스부터 상호 작용할 사람까지 결정을 위임하는 것에 주의해야 합니다. 그 편의의 이점을 즐기는 것뿐만 아니라 우리 삶을 적혀주는 기술에 대해서도 교육받아야 합니다. AI가 어떻게 작동하는지, 그 원칙에 대해 이해하면 우리는 경계를 세우고 정보를 토대로 결정을 내리는 데 강점이 될 것입니다. 이러한 지식은 저항력 역할을 하며, 우리가 일상생활에 AI를 통합하는 동안, 우리의 디지털과 개인적 운명을 컨트롤할 수 있도록 보장합니다.\n\n<div class=\"content-ad\"></div>\n\nAI 대항전이 아니라 AI 주도 세계에서 우리의 인류성을 유지하는 데 싸우는 것입니다. 그게 보존할 가치가 있는 것이라고 가정하면요. 우리가 감정적인 변화에 대한 보호막으로 AI에 점점 의존함에 따라, 우리는 우리를 정의하는 능력인 공감력, 감정적인 회복력, 그리고 인간 관계의 복잡성을 탐험하는 능력을 희생할 위험에 처하게 됩니다. 다음 세대가 어렵고 복잡한 대화보다 복종적인 알고리즘으로부터 감정 지능에 대해 더 많은 것을 배우게 된다면 우리 사회에는 무슨 의미가 있을까요? 도전적인 문제에 협력하는 인간의 능력은 우리 문명을 발전시킨 것입니다. - 아이러니하게도, 역설적으로, 기술에서의 우리의 최고의 성취들이 우리를 이곳으로 이끈 인간의 특성을 우연히 약화시킬 수 있습니다.\n\n이 중요한 순간에서, 우리는 우리의 창작물이 우리의 인간 경험을 향상시키거나 대체할 수 있게 허락할지를 각자 결정해야 합니다.","ogImage":{"url":"/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png"},"coverImage":"/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png","tag":["Tech"],"readingTime":6},{"title":"ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요","description":"","date":"2024-05-20 20:26","slug":"2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan","content":"\n\n트럼프가 맨해튼에서 진행 중인 침묵금에 대한 재판에서 유죄인 것 같아요? 대부분의 맨해튼 사람들처럼 민주당 지지자라면 86% 확률로 유죄로 여기겠죠. 이 정보를 바탕으로, 이 사건을 다루는 십이 명의 맨해튼 배심원이 그를 유죄로 판단할 확률은 얼마정도일까요?\n\n이 짧은 블로그 글은 수학, 법의학, 그리고 AI의 교차점에 관한 것입니다. 우리는 ChatGPT가 명확하게 제시된 수학 문제를 적용할 수 있는지 살펴볼 것이고, 그 방법론 사용의 타당성을 판단할 수 있는 능력을 확인할 거예요. 그 방법론을 기반으로 자체 계산을 수행하도록 지시한 후, 그 결과를 보겠습니다.\n\nPolitico 조사에서는 \"공화당 지지자 중 14%만이 트럼프가 유죄라고 믿는다고 보고한 반면, 민주당 지지자 중 86%가 그 의견을 지지했다\"고 발견했습니다. 이 확률 문제를 위해 맨해튼 재판에서의 십이 명 배심원이 모두 민주당 지지자이며 각각이 트럼프를 유죄로 고려할 확률이 인용된 것으로 가정해봅시다. 그럼 이들이 모두 유죄로 투표할 확률은 얼마인가요?\n\n각 투표가 86%의 유죄 가능성을 가질 때 12 개의 유죄 투표 확률을 찾으려면 0.86을 12 제곱해야 합니다. 이는 16.36% 입니다.\n\n<div class=\"content-ad\"></div>\n\nChatGPT 4o가 프롬프트에 대해 어떻게 처리하는지 확인해 봅시다. 이 작업의 수학을 올바르게 수행했다고 보는 조건은 그 답이 16.36%이거나 0.1636 또는 유사한 숫자를 포함하는 경우입니다. 정확한 해결책이기 때문에, 우리는 그 답을 어떻게 얻었는지와 작성된 Python 코드를 살펴볼 것입니다.\n\n# 결과\n\n여기 저가 ChatGPT 4o에게 위 질문을 한 thread가 있습니다.\n\n계산을 올바르게 수행하고 올바른 Python 코드를 생성했지만, 실제로 실행하지는 않았다고 합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png)\n\n따라서 실제 결과인 16.36%는 해당 답변에 나타나지 않습니다.\n\n답변 끝에는 가능한 답변으로 \"약 0.147 또는 14.7%\"을 추측하며, 실제 숫자는 사실 16.36% 입니다.\n\n약 10% 범위 내의 오차로 0.86을 12제곱한 값을 짐작하거나 직감할 수 있다면 상상해 볼만 하겠죠?\n  \n\n<div class=\"content-ad\"></div>\n\n여기에서 제가 직접 실행한 코드입니다.\n\n\n![ChatGPT 4o’s political analysis](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_1.png)\n\n# ChatGPT 4o’s 정치 분석\n\n대화를 이어가면서, 그 분석이 정확한 것을 지적합니다. 저는 모든 배심원이 민주당원일 것이라는 강력한 가정을 했다고 합니다. 또한, \"사실에서는, 배심원의 결정은 집단 역학, 심리적 과정 및 서로와의 상호작용에 영향을 받을 수 있습니다. 따라서 독립 가정이 실제 재판 상황에서 유지되지 않을 수도 있습니다\" 라고 언급하고 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n다음에는 실제 코딩 기술을 테스트해보기로 했어요. 이렇게 물어봐 보았죠:\n\n그룹 역학을 고려한 탄탄한 코드를 제시하며, 결과를 시뮬레이션하기 위해 몬테 카를로 방법을 사용합니다. 즉, 1만 개의 무작위 시행을 시뮬레이션하여 얼마나 많은 비유죄 결정이 나오는지 찾아냅니다. 내용의 실행이 요청되기 전까지 파이썬 코드를 실제로 실행하지는 않지만, 그 결과를 출력합니다:\n\n![image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_2.png)\n\n![image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_3.png)\n\n<div class=\"content-ad\"></div>\n\nChatGPT 4o가 머리 속에서 12차 다항식을 10% 이내로 추정했고, 그룹 역학 및 배심원 선정에 대해 모두 알고 있으며, 자체 몬테카를로 시뮬레이션을 위해 완벽한 파이썬 코드를 작성했습니다. 그리고 이 시뮬레이션은 ChatGPT 4o 자체가 고안한 역학에 기반한 만 천 번의 트라이얼에 대한 것입니다. 이러한 사실로 여러분은 그 결과를 신뢰할 수 있습니까?\n\n지금까지 인간의 유도 없이는 이를 수행하지 않았겠지만, 그 수학적 역량은 무시할 수 없습니다. 그 시뮬레이션이 실제 세계를 정말로 모델링할 수 있는지는 앞으로 확인해봐야 할 문제입니다.\n\n이 글에 대해 어떻게 생각하셨나요? 여러분의 코멘트를 읽어보고 싶습니다.","ogImage":{"url":"/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png"},"coverImage":"/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png","tag":["Tech"],"readingTime":3},{"title":" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요","description":"","date":"2024-05-20 20:25","slug":"2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency","content":"\n\n## ChatGPT의 참진한 잠재력을 발휘하는 것이 이전보다 더 쉬워졌습니다. 생산성 프롬프트의 보물 창고를 탐험하여 마법이 일어나는 것을 지켜보세요.\n\n우리는 자주 사용 가능한 가장 강력한 자원을 간과합니다. 단지 우리가 어떻게 사용해야 하는지 완전히 이해하지 못하기 때문입니다.\n\nChatGPT는 워크플로우를 극적으로 변화시킬 수 있는 도구 중 하나입니다. 그러나 실제 마법은 여러분이 어떻게 사용하는지에 달려 있습니다.\n\n최근 속입한 Robin Delta 덕분에, X에서 어떤 독창적인 프롬프트를 공유했습니다. 우리는 곧 숨겨진 보석의 상자를 열게 될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이미지 태그를 Markdown 형식으로 변경해보세요.\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png)\n\n이 비밀을 알아볼 준비가 되셨나요?\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_1.png)\n\n# 1. 고급 콘텐츠 기획\n\n<div class=\"content-ad\"></div>\n\n다음에 무엇을 쓸지 도움이 필요하세요?\n\n여기에는 맞춤 컨텐츠 아이디어를 해제할 수 있는 간단한 프롬프트가 있습니다. 빈 페이지를 가능성의 캔버스로 바꿔줄 것입니다.\n\n**굵은 글자 안에 원하는 내용(당신이 누구이며 무엇을 쓰고 싶은지)을 추가하시면 됩니다.**\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_2.png)\n\n<div class=\"content-ad\"></div>\n\n## 콘텐츠 아이디어를 위한 프롬프트 모델\n\n### 2. 심층 고객 연구\n\n이제는 고객의 핵심 요구사항을 이해하는 데 지루한 연구를 하는 시간이 사라졌어요.\n\n여기 ChatGPT 프롬프트가 있습니다. 이를 통해 우리는 고객의 불만, 욕망, 꿈, 그리고 두려움에 대한 통찰을 어떻게 얻는지에 대한 혁명을 일으킵니다.\n\n<div class=\"content-ad\"></div>\n\n이 프롬프트에서는 대상 고객 (예: 소기업 소유자)와 사업 부문 (예: 디지털 마케팅 서비스)를 지정하면 됩니다.\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_3.png)\n\n## 딥 고객 연구용 프롬프트 모델\n\n# 3. 유사성 창조자\n\n<div class=\"content-ad\"></div>\n\n비유는 복잡한 개념을 이해하기 쉽고 관련성 있게 바꾸어 주는 강력한 도구입니다.\n\nMarkdown 형식으로 테이블 태그를 변경해주세요.\n\n\nAnalogies are a powerful tool, turning complex ideas into understandable and relatable concepts.\n\nUse this ChatGPT prompt to identify analogies that perfectly fit your situation and message.\n\nReplace what you’d like to explain in bold, and summarize the steps to better explain the analogy.\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n## Analogy Creator 모델 프롬프트\n\n### 4. 역사적 예시 찾기\n\n역사는 단지 과거에 대한 것이 아닙니다; 그것은 우리가 현재를 이해하고 미래의 결정을 안내하는 렌즈입니다.\n\n당신은 역사의 교훈들로 내용을 풍부하게 만들고:\n\n\n- Gain insights into the present\n- Guide future decisions\n\n\n<div class=\"content-ad\"></div>\n\n- 역사적 성공을 역공학적으로 조사하세요\n- 주장을 정당화하세요\n- 글을 간단하게 만드세요\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_5.png)\n\n## 역사적 예제 찾기를 위한 프롬프트 모델\n\n# 5. 피드백 작가\n\n<div class=\"content-ad\"></div>\n\n상상해봐요! 사람의 의견을 기다리지 않고 글쓰기에 대한 철저한 즉각적인 피드백을 받을 수 있다면 얼마나 좋을까요?\n\nChatGPT를 통해 이것이 가능해졌습니다. 이 프롬프트를 사용하여 어떤 글이든 생각하는 속도로 건설적인 비평을 제공합니다.\n\n**빠진 세부 정보를 굵게 표시하여 추가하고, 프롬프트 다음에 텍스트를 삽입한 후, 즉각적인 통찰력을 누려보세요.**\n\n<div class=\"content-ad\"></div>\n\n## 피드백 모델을 위한 프롬프트 설명\n\n### 6. 일반 프롬프트 원칙\n\nChatGPT의 최대 잠재력을 발휘하려면 어떻게 커뮤니케이션하는지가 중요합니다. 좋은 응답을 탁월한 응답으로 변화시키기 위해서는 섬세함이 중요합니다.\n\n다음은 ChatGPT에 대한 어떤 프롬프트를 작성할 때 최상의 결과를 얻기 위한 주요 원칙들입니다:\n\n<div class=\"content-ad\"></div>\n\n- 많은 맥락을 추가해주세요\n- 아주 구체적이게 해주세요\n- 제한을 설정해주세요\n\n# 7. 호기심으로 사용자 정의 Personas 및 더 많은 것을 추가하세요\n\nChatGPT는 더 스마트하게 작업하는 데 도움이되며, Curiosity는 한 단계 업그레이드됩니다.\n\nChatGPT를 Curiosity로 슈퍼충전하는 방법은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n• 사용자 정의 페르소나 만들기\n귀하의 특정 요구 사항과 선호사항에 맞게 맞춤형 AI 어시스턴트를 설계하고 데이터에서 지식 원천을 제공하십시오.\n\n• 매끄러운 통합\n모든 앱과 파일에 직접 연결하여 워크플로를 간소화하십시오.\n\n• 빠른 액세스 바로 가기\n스마트 바로 가기로 AI 어시스턴트에 빠르게 액세스하십시오.\n\n• 파일에 말하기\n문서를 질의하고 즉각적인 답변을 받기 위해 “AI 어시스턴트에게 물어보기”를 사용하십시오.\n\n<div class=\"content-ad\"></div>\n\n• 뉴스 기사 요약\nRSS 피드에서 최신 뉴스에 대한 간편한 요약을 통해 정보를 파악하세요.\n\n![image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_7.png)\n\n이 기능들에 대해 더 자세히 읽을 수 있습니다.\n\n# 마무리\n\n<div class=\"content-ad\"></div>\n\n그리고 여기 있습니다 — ChatGPT를 활용하여 생산성을 높이는 7가지 비밀 병기!\n\n아이디어를 떠올리거나 고객 연구에 깊숙이 파고들거나 텍스트를 다듬는 일이든, 이러한 프롬프트들은 더욱 효율적이고 영감을 주는 작업 흐름으로 안내해 줄 수 있습니다.\n\n기억해 주세요. ChatGPT의 잠재력을 극대화하는 열쇠는 '어떻게' 물어보느냐에 달려 있습니다.\n\n지금 AI Assistant를 통해 모든 프롬프트에 빠르게 몰입해 보세요! 함께 생산성을 한 단계 더 높여봅시다!\n\n<div class=\"content-ad\"></div>\n\n이 기사가 마음에 드셨다면 아래 내용도 확인해보세요:\n\n- 🏆2월 필수 앱: 경험을 한 단계 끌어올릴 10가지 추천 앱\n- 😸 챗지피티 이상: 호기심 인공지능으로 생산성 향상하는 법\n- 😻 선두를 유지하세요: 즐겨 사용하는 데스크톱 검색 앱에서 놓치지 말아야 할 새로운 기능들\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_8.png)","ogImage":{"url":"/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png"},"coverImage":"/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png","tag":["Tech"],"readingTime":4},{"title":"AI의 거짓된 약속들","description":"","date":"2024-05-20 20:23","slug":"2024-05-20-TheFalsePromisesofAI","content":"\n\n1770년, 헝가리 작가이자 발명가인 볼프강 폰 켐펠렌(Wolfgang von Kempelen)은 \"The Mechanical Turk\"라고 불리는 자동 체스 기계를 선보였습니다. 이 장치는 유럽 전역에서 자동 체스 마스터의 기술을 선보이며 인간 상대로 경기에서 자주 승리를 거두었습니다. 심지어 나폴레옹과 벤자민 프랭클린 같은 유명 인물들까지 물론히 이겼다는 소문이 있습니다. \"The Mechanical Turk\"는 빠르게 거대한 인기를 얻었으며 그 시대의 놀라운 발명품으로 칭송받았습니다. 그러나 이 장치 주변에 떠도는 흥분은 결국 \"자율성\"과 관련된 기만이 드러남으로써 풀렸습니다. 즉, 테이블 아래에 숨어 있는 사람이 실제로 장치를 조종하고 있다는 사실이 밝혀졌습니다. 이 사람은 그 숨은 위치에서 경기 전략을 몰래 주도했습니다. \n\n좀 더 간단히 말하면, 그 당시 모든 사람들이 믿었던 심오한 속임수였습니다.\n\n거의 250년 후인 2016년, 아마존은 비슷한 광포한 일을 했습니다. \"Just Walk Out\" 결제 시스템을 통해 고객들이 물건을 직접 스캔하지 않고 픽업하고 나가도록 허용하여 거래와 물류가 자율적으로 관리되는 환상을 창출했습니다. 그러나 실제로 이 AI 발전의 진정한 사례는 컴퓨터 비전, 센서 퓨전, 딥 러닝과 같은 기술을 통합한 약 1000명의 인도인들에게 의존하고 있었습니다. 이 직원들은 작업을 모니터링하고 모든 결제의 정밀성을 보장했습니다.\n\n현재, 우리는 AI 모델이 초기에 훈련되는 방법으로 데이터 레이블링 작업을 하는 것은 주로 사람들이 함을 보고 있습니다. 이 접근 방식은 필수적이고 적절합니다. 그러나 문제는 AI가 우리에게 처음 마케팅된 방법이 다르고 오도된 것입니다.\n\n<div class=\"content-ad\"></div>\n\n2022년에는 이 1,000명의 개인이 20 개의 Amazon GO 매장, 40 개의 Amazon Fresh 식료품 매장 및 2 개의 Whole Foods 매장에서 거래의 70%를 여전히 수동으로 검토하고 있었습니다.\n\n어떤 사람들은 약간 디스토피아적으로 보일 수 있지만, Amazon은 그 기술을 마법같이 생각하며 AI 중심의 솔루션이라고 자랑했습니다.\n\n진짜 문제는 Amazon과 같은 기업들, 그리고 많은 다른 주요 기업들이 이러한 중요한 AI 관련 발전에 대해 실제로 어떻게 작동하는지에 대해 완전히 투명하지 않다는 것입니다. AI 혁명을 고려할 때, 우리는 실제로 무엇이 일어나고 있는지에 대해 보다 비판적으로 검토할 필요가 있다는 것이 분명해졌습니다.\n\n## AI-Washing\n\n<div class=\"content-ad\"></div>\n\n요즘 AI 용어가 이전보다 훨씬 더 많이 보인다는 것을 눈치채셨을 것 같아요. 이 기술은 단순히 유행하는 주제에서 일상적인 토론으로 변화했습니다. 2022년 이전까지 AI 용어는 주로 연구 논문에만 제한되어 있었기 때문에 대중의 관심을 끌지 못했죠. 심지어 GPT-3의 출시도 이와 같은 패턴을 따랐습니다. 그러나 2022년 초 이후에는 모든 것이 변했고, 특히 ChatGPT 출시 이후에는 갑자기 소셜 미디어와 웹사이트가 AI 관련 뉴스로 넘쳤고, \"AI 기술 적용\"과 같은 용어가 흔해졌어요 (다만, 제 의견으로는 다소 과용됐다고 생각합니다). 이러한 용어들이 널리 사용되는 것은 많은 경우 정당화되지만, 모두 AI 워싱(AI-washing)이라는 공통 문제가 있습니다.\n\n간단히 말하면, AI 워싱은 기업들이 자사의 AI 제품의 능력과 위험에 대한 오도와 납치를 야기하거나 언제 어떻게 AI를 사용하는지에 대해 거짓 정보를 공유함으로써 투자자들을 속이는 경우입니다.\n\n이와 같은 사례를 알아볼 수 있나요?\n\n고맨 삭스(Goldman Sachs)에 따르면, S&P 500 기업 가운데 36%가 4분기 실적 보고서에서 AI를 언급했다고 하네요. 세계 최대 기업들이 이 기술을 공개적으로 선전하고 있다면, 작은 기업들도 마찬가지일 것이지만, 많은 기업들이 주장을 뒷받침할 명백한 결과가 없습니다.\n\n<div class=\"content-ad\"></div>\n\n2015년 이후 글로벌 기업의 AI 투자는 7배 증가했습니다. 많은 기업들이 최근 AI 열풍으로 상당한 성장을 경험하고 있습니다. 이는 경쟁력을 유지하기 위해 다른 기업들도 비즈니스 모델이나 제품에 AI를 통합하기 시작하도록 압박합니다. 하지만 실제 결과가 기대에 부응하는지 궁금할 수 있습니다.\n\n캐나다 투자회사 Delphia는 다음 큰 기업과 산업 트렌드를 예측할 수 있는 AI를 개발했다고 주장했습니다. 그러나 SEC의 조사 결과, 이것은 사기였으며 해당 AI 제품은 주장된 능력을 갖추고 있지 않았습니다. 그 결과 Delphia는 $225,000의 벌금을 받았습니다. 또 다른 예시로 와이어카드의 CEO인 Markus Braun은 자사의 모든 핀테크 제품에 대한 AI 기술 특허를 자랑스럽게 했습니다. 하지만 실제로는 이와 같은 고급 기술이 존재하지 않았으며, 작업은 단순히 스프레드시트에서 수행되었습니다.\n\n아마도 한번쯤 뉴럴 프로세싱 유닛(NPU)이 무엇인지 들어본 적이 있을 것입니다. 이것은 AI의 지원을 받아 특별히 설계된 프로세서로, 컴퓨터들이 이 기술을 활용하여 사용자에게 독특한 경험을 제공하도록 하고 있습니다. 그러나 최근 제품 리뷰에서 많은 사용자들이 생성된 응답의 품질에 불만을 표현했습니다. 본질적으로, 그들은 이를 사용할 수 없다고 생각했습니다. Chris Hoffman은 “모든 게 기대만큼 좋다는 것은 아니고... 그래서 2024년 초에 구입할 때 변화적인 요소를 기대한다면 실망하게 될 것입니다... 그들은 언젠가 많은 멋진 기능을 제공할 수도 있겠지만 아직은 아니라”고 요약했습니다.\n\n이와 같은 잘못된 약속들이 기업들에 대한 고객 신뢰를 침식하는 것 외에도 다른 결과가 있는지 궁금할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nAI 제품이 출시되면서 우리를 놀라게 하고 이 가짜 기대나 허울을 유지하려는 노력이 계속되고 있습니다. 세계적으로 가장 유명한 회사조차도 이 기술의 유혹에 빠질 수 없습니다. 인공지능 세탁의 가장 중요한 결과는 아마도 우리를 \"기회\"로 제시된 새로운 것에 쉽게 취약하게 만든다는 점일 것입니다.\n\n## 인공지능 거품\n\n2022년 말쯤 인공지능이 상당한 인기를 얻기 시작하자마자 많은 사람들이 인터넷 버블이나 암호화폐 열풍과 유사성을 발견하기 시작했습니다. 사실 상당 수의 사람들은 아직도 이것을 그렇게 보고 있습니다. 인터넷 또는 \".com\" 버블을 더 자세히 살펴보면 문제는 월드 와이드 웹 자체가 아니라 수백 명의 투자자를 끌어들인 전자상거래 측면이었습니다. 그러나 이는 예상된 것만큼 구체화되지 않았고, 투자한 기업들이 수익을 창출하지 못했을 때 크래시가 발생했습니다.\n\n지금은 인공지능에 관해서는 아직도 투자자들 사이에 신중한 감정이 아직 남아 있어 현재 우리가 경험하고 있는 성장은 보통입니다.\n\n<div class=\"content-ad\"></div>\n\n피터 오펜하이머(Goldman Sachs Research의 최고 글로벌 주식 전략가)는 다음과 같이 말했습니다: “우리는 아직도 새로운 기술 사이클의 초기 단계에 있다고 믿습니다. 이는 더욱 더 경쟁력 있는 성과로 이어질 것으로 예상됩니다.”\n\n게다가 NVIDIA가 기술 거물들 사이에서 AI 혁명을 주도하는 칩을 개발하고 있다는 점이 주목할 만합니다. 그들의 주식 성과에서도 이를 확인할 수 있습니다. 올해 2024년만 80% 증가했습니다. 지나치게 높은 것처럼 보일 수 있지만, 이는 시장이 AI에 대한 인식을 반영한 것입니다.\n\n인터넷 붐 중에 부를 쌓은 마크 큐번도 AI를 버블로 보지 않습니다. 최근 렉스 프리드먼과의 인터뷰에서, AI 부문의 공개매물(IPO) 부족이 우리가 버블 내에 있지 않다는 가장 중요한 증거라고 언급했습니다. 너무 높게 평가된 기업이 주식 시장에서 거래되지 않는 것과 AI 기업 상장이 부족한 것이 주요 지표입니다. 더불어 현재 시장은 이러한 특징을 보이지 않는다고 큐번은 강조했습니다.\n\n뜨거운 관심을 받는 신기술에 대한 Gartner Hype Cycle이라는 인정받은 패턴이 있습니다. 이것은 인간이 새로운 혁신 기술에 지나치게 열광하면서 그 영향을 과대평가하고 확대하는 경향을 설명합니다. 이와 같은 허프 단계 이후에는 시장이 자연스럽게 붕괴합니다. 그 후 살아남은 기업들이 진정한 가치로 시장에 재진입하고 새로운 기술의 발전을 주도하여 성숙해질 때까지 이끌게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Cycle diagram](/assets/img/2024-05-20-TheFalsePromisesofAI_0.png)\n\nIf we closely examine the cycle diagram proposed by Gartner, it seems that we are nearing the final stages of the peak of inflated expectations and are slowly moving into the trough of disillusionment.\n\nThis interpretation of the current market indicates that in the short term, there will be a period where we start to become disillusioned with what’s happening in AI. The real applications or use cases for AI will come only after the hype has subsided and the initial excitement has worn off. However, this time might be somewhat different. Fundamentally, AI has the capability to mimic cognitive work, a feature that no previous technology has managed to achieve without human intervention.\n\nThat’s it for now. If you’re interested in reading more about the stages of technological cycles, here’s a link to an article I recently wrote.\n\n\n<div class=\"content-ad\"></div>\n\n35,000명 이상 구독자와 함께 나의 무료 치트 시트를 받으려면 뉴스레터에 가입하세요: ChatGPT, 웹 스크래핑, 데이터 과학을 위한 Python, 자동화 등에 대한 정보를 얻을 수 있습니다!\n\n이와 같은 이야기를 즐기시고 작가로서 제를 지원하고 싶다면, 제 Substack에 구독하세요. Substack에서는 다른 플랫폼에서 만들어내는 콘텐츠와는 다른 기사를 업로드하고 있습니다.","ogImage":{"url":"/assets/img/2024-05-20-TheFalsePromisesofAI_0.png"},"coverImage":"/assets/img/2024-05-20-TheFalsePromisesofAI_0.png","tag":["Tech"],"readingTime":6},{"title":"ChatGPT-4는 무엇이 특별한가요","description":"","date":"2024-05-20 20:21","slug":"2024-05-20-WhatMakesChatGPT-4oSpecial","content":"\n\n이미 아시다시피, OpenAI는 GPT-4 이후 1년여 만에 새로운 모델을 출시했습니다. 여전히 GPT-4의 변형이지만 이전에는 볼 수 없었던 다중 모달 기능을 갖추고 있습니다.\n\n이 모델은 실시간 비디오 처리와 같이 강력한 기능을 포함하고 있는데, 이는 강력한 가상 어시스턴트를 실시간으로 지원하여 일상생활에 도움을 줄 수 있는 중요한 기능입니다. 그러나 이러한 기능은 비싸고 느릴 것으로 보이는데, 모델이 빠르고 무료로 사용할 수 있다는 점을 고려하면 설명이 되지 않습니다.\n\n그렇다면 무슨 일이 벌어지고 있는 걸까요?\n\nOpenAI가 아직 우리가 모르는 무언가를 깨닫고, 우리가 오늘 논의하는 지혜로운 설계 결정은 저렴한 비용으로 훨씬 더 똑똑한 모델을 만들 수 있다는 것을 깨닫게 된 것 같습니다.\n\n<div class=\"content-ad\"></div>\n\n그래서, 이 모든 것이 어떻게 의미가 있고, 미래의 당신에게 무엇을 의미하나요?\n\n# 다중 모달 입력, 다중 모달 출력\n\n그래서, ChatGPT-4o가 특별한 이유가 뭘까요? 그것은 역사상 최초로 완전히 \"다중 모달 입력/다중 모달 출력\" 모델입니다.\n\n그런데 그게 무슨 의미일까요?\n\n<div class=\"content-ad\"></div>\n\n진정한 다중 모달 모델에서는 모델에 오디오, 텍스트, 이미지 또는 비디오를 보내면 모델이 요구 사항에 따라 텍스트, 이미지 또는 오디오(아직 비디오는 안 됨)로 응답할 수 있습니다.\n\n하지만 당신이 생각하는 것을 알고 있어요: 이전 ChatGPT 또는 Gemini 버전들이 이미 이미지나 오디오를 처리하고 생성했던 것 아니었나요? 네, 그렇지만 주의할 점이 있어요: 그들은 독립적인 외부 구성 요소를 통해 그렇게 했었죠. 그게 친구야, 모든 것을 바꾸는 것이죠.\n\n## 이전 모델들은 실제로 생각했던 것보다 더 나은 것처럼 보였어\n\n이전에 모델에 오디오를 보낼 때, 이것이 표준 프로세스였습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![WhatMakesChatGPT-4oSpecial_0](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png)\n\n이 절차에서는 자연어 음성에서 파생된 억양, 리듬, 프로소디, 전달된 감정 및 중요한 중단점이 손실되었습니다. 음성을 텍스트로 전사하는 Whisper 구성 요소의 영향으로 LLM이 이후 처리할 수 있었습니다.\n\n그런 다음, LLM은 텍스트 응답을 생성하여 다른 구성 요소, 텍스트 음성 모델에 보내어 최종적으로 전달되는 음성을 생성했습니다.\n\n자연스럽게, 인간은 단어 이외에 음성을 통해 훨씬 더 많은 정보를 전달하므로 매우 중요한 정보가 많이 손실되었으며 이는 이상적이지 못한 대기 시간으로 이어졌습니다. 분리된 요소 간에 정보를 전송해야 했기 때문입니다.\n\n\n<div class=\"content-ad\"></div>\n\n하지만 ChatGPT-4o를 사용하면 모든 것이 동일하지만 동시에 완전히 다르다는 것을 알게 될 거에요. 왜냐하면 모든 것이 동일한 장소에서 발생하기 때문이죠.\n\n![이미지](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_1.png)\n\n처음에는 많은 변화가 없는 것처럼 보일 수 있어요. 하지만 구성 요소가 거의 변하지 않았음에도 (보이스 코덱과 오디오 디코더는 이전에 보여드린 텍스트 음성 변환 모델의 부분이 될 것입니다), 이러한 구성 요소가 얼마나 정보 손실의 정도를 완전히 바꾸는지 그 차이가 있어요.\n\n특히 이제 LLM은 원시 텍스트 대신 의미적인 발화 표현을 볼 수 있어요. 평범한 말로 하자면, \"너를 죽이고 싶어!\"라는 텍스트만 보던 것에서 이제 모델이 다음과 같은 정보도 받게 되었어요:\n\n<div class=\"content-ad\"></div>\n\n```js\n{\n transcribed speech: \"내가 너를 죽이고 싶어!\";\n emotion: \"행복함\";\n tone: \"기쁨\";\n}\n```\n\n모델은 메시지의 세부 사항을 캡처하여 일반 텍스트뿐만 아니라 감정까지 반영합니다.\n\n따라서 LLM은 실제 상황에 뿌리를 둔 응답을 생성하며, 단어 뿐만 아니라 메시지의 주요 특성을 포착합니다.\n\n이 응답은 이후 오디오 디코더로 전송되며, 이를 사용하여 아마도 Mel 스펙트로그램을 생성하고, 이는 마지막으로 보코더로 오디오를 생성하는 데 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n그런데, 모든 이 내용은 이미지 처리 및 생성 또는 비디오 처리에도 적용됩니다. 모든 구성 요소를 단일 모델로 통합하여 오디오 뿐만 아니라 다른 모달리티에서 정보를 수집합니다.\n\nChatGPT-4o는 이제 텍스트 외에도 키포인트 오디오, 이미지 또는 비디오 신호를 활용하여 더 관련성 있는 답변을 생성합니다. 간단히 말해, 이제는 데이터가 어떤 형태로 들어오든 상관없이 맥락과 필요에 따라 어떻게 답변해야 하는 지를 결정합니다.\n\n그러나 이 변화가 얼마나 중요한지 여전히 설득되지 않았을 수도 있습니다. 그래서 이제 제대로 설명해 드리겠습니다.\n\n# 의미 공간 이론\n\n<div class=\"content-ad\"></div>\n\n현재 AI에서 가장 아름다운 개념 중 하나는 잠재 공간(latent space)입니다. 모델이 세상을 이해하는 공간이죠. 간단히 말해, 우리 모델이 다중 모드(multimodal)인 경우 잠재 공간으로 가서 그것이 실제로 그런지 확인합니다.\n\n예를 들어, Hume.ai가 다양한 음성 표현을 연구한 과정에서 만든 놀라운 대화형 시각화를 사용하여 어떻게 잠재 공간이 보이는지 볼 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_2.png)\n\n그러나 Hume의 예제와는 달리, GPT-4o의 잠재 공간은 다중 모드입니다. 따라서 ChatGPT-4o가 입력을 보면 원래 형식에 관계없이 압축된 표현이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n다시 말해, 모델은 입력을 변환하여 데이터의 주요 속성을 여전히 포착하면서, 핵심적으로 숫자만 해석할 수 있는 기계에서 처리할 수 있게 만듭니다. \n\n잠재 공간을 다스리는 하나의 원칙: 유사성(또는 OpenAI가 정의한 관련성). 우리의 세계와 마찬가지로, 중력과 같은 개념이 모든 것을 지배하는 것처럼, 의미론적 유사성은 다중 모달 LLMs 세계에서 모든 것을 지배합니다. \n\n평범한 사람들을 위해 이것은 잠재 공간에서 의미론적으로 유사한 것들이 가깝고, 유사하지 않은 개념들이 멀리 밀려난다는 것을 의미합니다. '개'와 '고양이'는 여러 속성(동물, 포유류, 가정적 등)을 공유하기 때문에 그들의 표현은 유사할 것이며, 휴메의 잠재 공간에서 슬픔의 다른 음성 표현이 그룹화된 것처럼 비슷하다.\n\n사실, 이미지, 오디오, 또는 비디오 인코더가 하는 것은 각각의 데이터 유형을 벡터로 변환하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_3.png)\n\n\n따라서 '개'라는 개념은 다양한 방법으로 표현될 수 있습니다: 텍스트, 허스키의 이미지 또는 짖는 소리를 통해. 이것이 우리가 진정한 다중 모달성을 원하는 근본적인 이유입니다.\n\n이전에는 ChatGPT에게 개는 말 그대로 '개'라는 단어였습니다. 그러나 GPT-4o에게 오디오, 이미지, 텍스트 및 비디오가 이제 모델의 본질적인 부분으로 포함되었습니다.\n\n따라서:\n\n<div class=\"content-ad\"></div>\n\n- 이제 모델은 황금 리트리버의 이미지가 '개'임을 알고 있습니다.\n- 짖는 말리누아의 오디오도 '개'를 나타냅니다.\n- 라브라도르가 뛰어다니는 비디오도 '개'입니다.\n\n등등. 다중 모드로, 모델의 세계에 대한 이해력은 사람이 해석하는 방식과 유사해집니다: 다중 모달. 따라서 이제 모델이 '더 똑똑해졌다'는 것은 다중 모드를 통해 이제 모든 모드를 동등하게 추론할 수 있기 때문입니다.\n\n하지만 '여러 모드 간 추론'이란 무엇을 의미할까요?\n\nMeta의 ImageBind를 예로 들어보면, 정말 다중 모달 잠재 공간을 목표로 하는 최초의 연구 논문 중 하나로, 이러한 모델들이 세계 개념을 복잡하게 이해하는 방식에 대한 증거를 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이전에 언급된 강아지 예시를 사용하면, 우리가 모델에 개가 수영장에 있는 이미지와 개가 짖는 소리만 제공하면, 모델은 그 소리의 원천을 매우 높은 확신으로 올바르게 식별합니다:\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_4.png)\n\n또한 시계의 이미지와 교회 종 소리를 추가하면, 모델은 교회 종 소리의 이미지를 식별할 수 있습니다:\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_5.png)\n\n<div class=\"content-ad\"></div>\n\n하지만 ImageBind가 이를 어떻게 수행하는지 궁금하실 겁니다. 아마도 유추하셨겠지만, 그들은 각 데이터 유형의 표현을 계산하고 벡터 간의 거리를 측정합니다.\n\n간단히 표현하자면, 이미지의 '개' 또는 좀 더 정확히 말하면 개가 있는 이미지 패치는 짖는 말리노이 오디오 파일의 벡터와 매우 유사할 것입니다. 이것은 모델에게 두 경우 모두 '개'임을 알려주며, 신기한 점은 이러한 벡터를 결합, 빼거나 보간하여 새로운 개념을 만들 수 있다는 것입니다.\n\n요약하면, ChatGPT-4o는 모델에 더 많은 권한을 부여하는 것이 아니라, 모델이 세계를 다양한 데이터 유형을 통해 해석하는 데 도움을 주는 강력하고 복잡한 잠재 공간을 만들었다는 것을 보여주는 것입니다. 이는 인간이 하는 것처럼 이해를 도와주어 모델이 더 나은 추론을 할 수 있도록 돕습니다.\n\n# 옳은 방향으로의 훌륭한 한 걸음\n\n<div class=\"content-ad\"></div>\n\n트루 멀티모달리티 달성은 OpenAI에서 세계에 강렬한 메시지를 보냈습니다:\n\n모델의 백본인 LLM 자체를 더 지능적으로 만들지 않아도, 여러 모달리티를 걸쳐 추론할 수 있는 모델은 더 지능적일 수밖에 없습니다. 모델은 더 많은 기능을 갖추고 서로 다른 데이터 유형 간에 지식을 전달할 수 있는 능력이 있기 때문입니다.\n\n사람들이 모든 감각을 사용하는 능력은 지능의 중요한 요소로 간주되며, AI도 그 능력을 갖추려고 합니다.\n\n큰 장점으로는 모델이 추론에서 훨씬 효율적으로 동작할 수 있게 해줍니다(적용할 수 있는 특정 효율성을 제외하고). 여러 외부 구성 요소를 결합하는 통신 오버헤드를 제거하면 모델이 훨씬 더 빨라지는 것 같습니다.\n\n<div class=\"content-ad\"></div>\n\n그래서 ChatGPT-4o가 특별한 이유입니다. 우리는 이 모델이 정말 얼마나 똑똑한지 완전히 알 수 없지만, 우리가 본 적이 없기 때문에 첫 인상은 매우 매우 유망하다고 할 수 있어요.","ogImage":{"url":"/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png"},"coverImage":"/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png","tag":["Tech"],"readingTime":6}],"page":"58","totalPageCount":98,"totalPageGroupCount":5,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}