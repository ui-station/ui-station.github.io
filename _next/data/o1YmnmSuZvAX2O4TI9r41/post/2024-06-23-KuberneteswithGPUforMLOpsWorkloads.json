{"pageProps":{"post":{"title":"MLOps ì‘ì—…ì„ ìœ„í•œ GPUì™€ í•¨ê»˜ Kubernetes ì‚¬ìš© ë°©ë²•","description":"","date":"2024-06-23 00:51","slug":"2024-06-23-KuberneteswithGPUforMLOpsWorkloads","content":"\n\nì´ ê¸°ì‚¬ì—ì„œëŠ” GPUê°€ ì¿ ë²„ë„¤í‹°ìŠ¤ì™€ í†µí•©ë˜ì–´ ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë…¼ì˜í•˜ê³ ì í•©ë‹ˆë‹¤.\n\nì €ëŠ” ì£¼ë³€ì— ìˆëŠ” NVIDIA GeForce RTX 3050ì„ ê°€ì§€ê³  ì•„ì´ë””ì–´ë¥¼ ì–»ì—ˆì–´ìš” ğŸ’¡... ` Kubernetes\n\në¹ ë¥´ê²Œ ì¿ ë²„ë„¤í‹°ìŠ¤ì™€ GPUë¥¼ í†µí•©í•˜ì—¬ ë”¥ ëŸ¬ë‹ í›ˆë ¨ ë°°í¬ë¥¼ ì‹¤í–‰í•´ë´…ì‹œë‹¤!\n\n0. Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì•„ì§ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì—¬ê¸°ì—ì„œ Dockerë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.\n\n<div class=\"content-ad\"></div>\n\n# NVIDIA Container Toolkit for Docker\n\n- NVIDIA ë“œë¼ì´ë²„ë¥¼ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”\n\n```js\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb\nsudo dpkg -i cuda-keyring_1.1-1_all.deb\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-12-5\n```\n\n- ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í•´ë‹¹ OSì— ë§ëŠ” NVIDIA ì»¨í…Œì´ë„ˆ íˆ´í‚·ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.\n- ì œê°€ WSLì„ ì‚¬ìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì— apt ëª…ë ¹ì–´ë¥¼ í†µí•´ ì„¤ì¹˜í•˜ê² ìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n```js\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n```\n\n- ì €ì¥ì†Œì—ì„œ íŒ¨í‚¤ì§€ ëª©ë¡ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤:\n\n```js\nsudo apt-get update\n```\n\n- NVIDIA Container Toolkit íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:\n\n\n<div class=\"content-ad\"></div>\n\n```js\nsudo apt-get install -y nvidia-container-toolkit\n```\n\n![KuberneteswithGPUforMLOpsWorkloads](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png)\n\n- ë„ì»¤ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ëŸ°íƒ€ì„ êµ¬ì„±í•˜ê¸°\n\n```js\nsudo nvidia-ctk runtime configure --runtime=docker\n```\n\n<div class=\"content-ad\"></div>\n\nì•„ë˜ëŠ” í…Œì´ë¸” íƒœê·¸ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€ê²½í•œ ì½”ë“œì…ë‹ˆë‹¤.\n\n\n<img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_1.png\" />\n\n- restart docker\n\n```js\nsudo systemctl restart docker\n```\n\n- Docker Desktop\n\n\n<div class=\"content-ad\"></div>\n\në§Œì¼ Docker Desktopì„ ì‚¬ìš© ì¤‘ì´ë¼ë©´, ì„¤ì •ì„ ë‹¤ë¥´ê²Œ êµ¬ì„±í•˜ê³  daemon.jsonì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n\n- ì™¼ìª½ ìƒë‹¨ì˜ ì„¤ì • âš™ï¸ ë¡œ ì´ë™í•˜ì—¬ Docker Engineìœ¼ë¡œ ì´ë™í•œ ë‹¤ìŒ ë‹¤ìŒ êµ¬ì„±ì„ ì¶”ê°€í•˜ì‹­ì‹œì˜¤. (,ë¥¼ ìŠì§€ ë§ê³  json êµ¬ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš” ğŸ˜…)\n\n```js\n\"runtimes\": {\n  \"nvidia\": {\n    \"args\": [],\n    \"path\": \"nvidia-container-runtime\"\n  }\n}\n```\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_2.png)\n\n<div class=\"content-ad\"></div>\n\n2. Apply ë° ë‹¤ì‹œ ì‹œì‘ì„ í´ë¦­í•˜ê³  GPU í™•ì¸\n\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë„ì»¤ê°€ ëŸ°íƒ€ì„ìœ¼ë¡œ GPUë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n\n```shell\nsudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi\n```\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_3.png)\n\n<div class=\"content-ad\"></div>\n\n# Minikube\n\në¡œì»¬ì—ì„œ Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ëŠ” ë° Minikubeë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n\n- [ì—¬ê¸°](ë§í¬)ì—ì„œ ìš´ì˜ ì²´ì œì— ë§ê²Œ Minikubeë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.\n- Minikube ì´ì§„ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•œ í›„ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Minikubeë¥¼ ì‹œì‘í•˜ì„¸ìš”. Minikubeë¥¼ ì‹œì‘í•˜ê¸° ì „ì— Dockerê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\n\n```js\nminikube start --gpus all --driver=docker --addons=ingress\n```\n\n<div class=\"content-ad\"></div>\n\nMinikubeì˜ nvidia-gpu-device-plugin ì• ë“œì˜¨ì€ Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ GPU ì§€ì›ì„ í™œì„±í™”í•˜ëŠ” ë° ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì• ë“œì˜¨ì„ ì‚¬ìš©í•˜ë©´ Kubernetesê°€ GPUê°€ í•„ìš”í•œ ì‘ì—…ë¡œë“œë¥¼ ì¸ì‹í•˜ê³  ì˜ˆì•½í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì—ì„œ GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n\nNVIDIA GPU ì¥ì¹˜ í”ŒëŸ¬ê·¸ì¸ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\n\nNVIDIA GPU ì¥ì¹˜ í”ŒëŸ¬ê·¸ì¸ì€ Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ NVIDIA GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” Kubernetes ì¥ì¹˜ í”ŒëŸ¬ê·¸ì¸ì…ë‹ˆë‹¤. ì´ í”ŒëŸ¬ê·¸ì¸ì„ ì‚¬ìš©í•˜ë©´ Kubernetesê°€ GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆì— í• ë‹¹í•˜ê³  ì˜ˆì•½í•˜ì—¬ ì‘ìš© í”„ë¡œê·¸ë¨ì´ GPU ê°€ì†ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n\nì£¼ìš” ê¸°ëŠ¥\n\n<div class=\"content-ad\"></div>\n\n- GPU ë°œê²¬:\n\n    - ë…¸ë“œì—ì„œ NVIDIA GPUë¥¼ ìë™ìœ¼ë¡œ ë°œê²¬í•˜ì—¬ Kubernetesì—ì„œ ìŠ¤ì¼€ì¤„ ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ë¡œ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n- GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬:\n\n    - GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆì— í• ë‹¹í•˜ëŠ” ì‘ì—…ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. Podì— ìš”ì²­ëœ GPU ìˆ˜ë¥¼ í™•ì¸í•˜ê³  GPU ë¦¬ì†ŒìŠ¤ë¥¼ ìŠ¤ì¼€ì¤„ë§í•˜ëŠ” ë³µì¡ì„±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n3. ê²©ë¦¬:\n\n- GPU ë¦¬ì†ŒìŠ¤ì˜ ê²©ë¦¬ë¥¼ ì œê³µí•˜ì—¬ GPU ì›Œí¬ë¡œë“œê°€ ì„œë¡œ ê°„ì„­í•˜ì§€ ì•Šë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.\n\n4. ë©”íŠ¸ë¦­ ë° ëª¨ë‹ˆí„°ë§:\n\n- GPU í™œìš©ì— ê´€í•œ ë©”íŠ¸ë¦­ì„ ë…¸ì¶œí•˜ì—¬ GPU ì›Œí¬ë¡œë“œì˜ ëª¨ë‹ˆí„°ë§ê³¼ ìŠ¤ì¼€ì¼ë§ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n# ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ GPU ê°€ìš©ì„± í™•ì¸í•˜ê¸°\n\nGPU ë…¸ë“œê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ ë…¸ë“œ ì„¸ë¶€ì •ë³´ë¥¼ í™•ì¸í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”\n\n```js\nkubectl get nodes -o \"custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,CAPACITY:.status.capacity\"\n```\n\n- ì‘ì—…ìœ¼ë¡œ í™•ì¸í•˜ê³  ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ì„ ì ìš©í•˜ì„¸ìš”\n\n<div class=\"content-ad\"></div>\n\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: gpu-job\nspec:\n  template:\n    spec:\n      containers:\n      - name: gpu-container\n        image: nvidia/cuda:12.5.0-base-ubuntu22.04\n        resources:\n          limits:\n            nvidia.com/gpu: 1 # Request 1 GPU\n        command: [\"nvidia-smi\"]\n      restartPolicy: Never\n```\n\n```bash\nkubectl apply -f gpu-verify.yaml\n```\n\n![Kubernetes with GPU for MLOps Workloads](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_4.png)\n\n- íŒŒë“œ ê°€ì ¸ì˜¤ê¸°\n\n\n<div class=\"content-ad\"></div>\n\n```js\nkubectl get po \n```\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_5.png)\n\n- GPU ë¡œê·¸ í™•ì¸\n\n```js\nkubectl logs <pod>\n```\n\n<div class=\"content-ad\"></div>\n\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_6.png)\n\nê·¸ë¦¬ê³  ì‹œì‘í•©ë‹ˆë‹¤..!\n\nGPUë¥¼ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—…ë°ì´íŠ¸ë¥¼ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. ëª‡ ê°€ì§€ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ê³  ì—¬ê¸°ì— ê³µìœ í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n\nì´ì œ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\n<div class=\"content-ad\"></div>\n\nì½ì–´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!\n\n[LinkedIn í”„ë¡œí•„](https://www.linkedin.com/in/sivanaik/)\n\n[x.comì—ì„œì˜ í”„ë¡œí•„](https://x.com/sivanaikk)","ogImage":{"url":"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png"},"coverImage":"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png","tag":["Tech"],"readingTime":5},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>ì´ ê¸°ì‚¬ì—ì„œëŠ” GPUê°€ ì¿ ë²„ë„¤í‹°ìŠ¤ì™€ í†µí•©ë˜ì–´ ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë…¼ì˜í•˜ê³ ì í•©ë‹ˆë‹¤.</p>\n<p>ì €ëŠ” ì£¼ë³€ì— ìˆëŠ” NVIDIA GeForce RTX 3050ì„ ê°€ì§€ê³  ì•„ì´ë””ì–´ë¥¼ ì–»ì—ˆì–´ìš” ğŸ’¡... ` Kubernetes</p>\n<p>ë¹ ë¥´ê²Œ ì¿ ë²„ë„¤í‹°ìŠ¤ì™€ GPUë¥¼ í†µí•©í•˜ì—¬ ë”¥ ëŸ¬ë‹ í›ˆë ¨ ë°°í¬ë¥¼ ì‹¤í–‰í•´ë´…ì‹œë‹¤!</p>\n<ol start=\"0\">\n<li>Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì•„ì§ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì—¬ê¸°ì—ì„œ Dockerë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.</li>\n</ol>\n<h1>NVIDIA Container Toolkit for Docker</h1>\n<ul>\n<li>NVIDIA ë“œë¼ì´ë²„ë¥¼ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”</li>\n</ul>\n<pre><code class=\"hljs language-js\">wget <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb</span>\nsudo dpkg -i cuda-keyring_1<span class=\"hljs-number\">.1</span>-1_all.<span class=\"hljs-property\">deb</span>\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-<span class=\"hljs-number\">12</span>-<span class=\"hljs-number\">5</span>\n</code></pre>\n<ul>\n<li>ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í•´ë‹¹ OSì— ë§ëŠ” NVIDIA ì»¨í…Œì´ë„ˆ íˆ´í‚·ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.</li>\n<li>ì œê°€ WSLì„ ì‚¬ìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì— apt ëª…ë ¹ì–´ë¥¼ í†µí•´ ì„¤ì¹˜í•˜ê² ìŠµë‹ˆë‹¤.</li>\n</ul>\n<pre><code class=\"hljs language-js\">curl -fsSL <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\</span>\n  &#x26;&#x26; curl -s -L <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\</span>\n    sed <span class=\"hljs-string\">'s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g'</span> | \\\n    sudo tee /etc/apt/sources.<span class=\"hljs-property\">list</span>.<span class=\"hljs-property\">d</span>/nvidia-container-toolkit.<span class=\"hljs-property\">list</span>\n</code></pre>\n<ul>\n<li>ì €ì¥ì†Œì—ì„œ íŒ¨í‚¤ì§€ ëª©ë¡ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤:</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo apt-get update\n</code></pre>\n<ul>\n<li>NVIDIA Container Toolkit íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo apt-get install -y nvidia-container-toolkit\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png\" alt=\"KuberneteswithGPUforMLOpsWorkloads\"></p>\n<ul>\n<li>ë„ì»¤ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ëŸ°íƒ€ì„ êµ¬ì„±í•˜ê¸°</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo nvidia-ctk runtime configure --runtime=docker\n</code></pre>\n<p>ì•„ë˜ëŠ” í…Œì´ë¸” íƒœê·¸ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€ê²½í•œ ì½”ë“œì…ë‹ˆë‹¤.</p>\n<ul>\n<li>restart docker</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo systemctl restart docker\n</code></pre>\n<ul>\n<li>Docker Desktop</li>\n</ul>\n<p>ë§Œì¼ Docker Desktopì„ ì‚¬ìš© ì¤‘ì´ë¼ë©´, ì„¤ì •ì„ ë‹¤ë¥´ê²Œ êµ¬ì„±í•˜ê³  daemon.jsonì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.</p>\n<ul>\n<li>ì™¼ìª½ ìƒë‹¨ì˜ ì„¤ì • âš™ï¸ ë¡œ ì´ë™í•˜ì—¬ Docker Engineìœ¼ë¡œ ì´ë™í•œ ë‹¤ìŒ ë‹¤ìŒ êµ¬ì„±ì„ ì¶”ê°€í•˜ì‹­ì‹œì˜¤. (,ë¥¼ ìŠì§€ ë§ê³  json êµ¬ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš” ğŸ˜…)</li>\n</ul>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-string\">\"runtimes\"</span>: {\n  <span class=\"hljs-string\">\"nvidia\"</span>: {\n    <span class=\"hljs-string\">\"args\"</span>: [],\n    <span class=\"hljs-string\">\"path\"</span>: <span class=\"hljs-string\">\"nvidia-container-runtime\"</span>\n  }\n}\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_2.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<ol start=\"2\">\n<li>Apply ë° ë‹¤ì‹œ ì‹œì‘ì„ í´ë¦­í•˜ê³  GPU í™•ì¸</li>\n</ol>\n<p>ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë„ì»¤ê°€ ëŸ°íƒ€ì„ìœ¼ë¡œ GPUë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.</p>\n<pre><code class=\"hljs language-shell\">sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_3.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<h1>Minikube</h1>\n<p>ë¡œì»¬ì—ì„œ Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ëŠ” ë° Minikubeë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.</p>\n<ul>\n<li><a href=\"%EB%A7%81%ED%81%AC\">ì—¬ê¸°</a>ì—ì„œ ìš´ì˜ ì²´ì œì— ë§ê²Œ Minikubeë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.</li>\n<li>Minikube ì´ì§„ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•œ í›„ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Minikubeë¥¼ ì‹œì‘í•˜ì„¸ìš”. Minikubeë¥¼ ì‹œì‘í•˜ê¸° ì „ì— Dockerê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.</li>\n</ul>\n<pre><code class=\"hljs language-js\">minikube start --gpus all --driver=docker --addons=ingress\n</code></pre>\n<p>Minikubeì˜ nvidia-gpu-device-plugin ì• ë“œì˜¨ì€ Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ GPU ì§€ì›ì„ í™œì„±í™”í•˜ëŠ” ë° ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì• ë“œì˜¨ì„ ì‚¬ìš©í•˜ë©´ Kubernetesê°€ GPUê°€ í•„ìš”í•œ ì‘ì—…ë¡œë“œë¥¼ ì¸ì‹í•˜ê³  ì˜ˆì•½í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì—ì„œ GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.</p>\n<p>NVIDIA GPU ì¥ì¹˜ í”ŒëŸ¬ê·¸ì¸ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?</p>\n<p>NVIDIA GPU ì¥ì¹˜ í”ŒëŸ¬ê·¸ì¸ì€ Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ NVIDIA GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” Kubernetes ì¥ì¹˜ í”ŒëŸ¬ê·¸ì¸ì…ë‹ˆë‹¤. ì´ í”ŒëŸ¬ê·¸ì¸ì„ ì‚¬ìš©í•˜ë©´ Kubernetesê°€ GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆì— í• ë‹¹í•˜ê³  ì˜ˆì•½í•˜ì—¬ ì‘ìš© í”„ë¡œê·¸ë¨ì´ GPU ê°€ì†ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.</p>\n<p>ì£¼ìš” ê¸°ëŠ¥</p>\n<ul>\n<li>\n<p>GPU ë°œê²¬:</p>\n<ul>\n<li>ë…¸ë“œì—ì„œ NVIDIA GPUë¥¼ ìë™ìœ¼ë¡œ ë°œê²¬í•˜ì—¬ Kubernetesì—ì„œ ìŠ¤ì¼€ì¤„ ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ë¡œ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>\n</ul>\n</li>\n<li>\n<p>GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬:</p>\n<ul>\n<li>GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆì— í• ë‹¹í•˜ëŠ” ì‘ì—…ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. Podì— ìš”ì²­ëœ GPU ìˆ˜ë¥¼ í™•ì¸í•˜ê³  GPU ë¦¬ì†ŒìŠ¤ë¥¼ ìŠ¤ì¼€ì¤„ë§í•˜ëŠ” ë³µì¡ì„±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.</li>\n</ul>\n</li>\n</ul>\n<ol start=\"3\">\n<li>ê²©ë¦¬:</li>\n</ol>\n<ul>\n<li>GPU ë¦¬ì†ŒìŠ¤ì˜ ê²©ë¦¬ë¥¼ ì œê³µí•˜ì—¬ GPU ì›Œí¬ë¡œë“œê°€ ì„œë¡œ ê°„ì„­í•˜ì§€ ì•Šë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.</li>\n</ul>\n<ol start=\"4\">\n<li>ë©”íŠ¸ë¦­ ë° ëª¨ë‹ˆí„°ë§:</li>\n</ol>\n<ul>\n<li>GPU í™œìš©ì— ê´€í•œ ë©”íŠ¸ë¦­ì„ ë…¸ì¶œí•˜ì—¬ GPU ì›Œí¬ë¡œë“œì˜ ëª¨ë‹ˆí„°ë§ê³¼ ìŠ¤ì¼€ì¼ë§ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>\n</ul>\n<h1>ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ GPU ê°€ìš©ì„± í™•ì¸í•˜ê¸°</h1>\n<p>GPU ë…¸ë“œê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ ë…¸ë“œ ì„¸ë¶€ì •ë³´ë¥¼ í™•ì¸í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”</p>\n<pre><code class=\"hljs language-js\">kubectl get nodes -o <span class=\"hljs-string\">\"custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,CAPACITY:.status.capacity\"</span>\n</code></pre>\n<ul>\n<li>ì‘ì—…ìœ¼ë¡œ í™•ì¸í•˜ê³  ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ì„ ì ìš©í•˜ì„¸ìš”</li>\n</ul>\n<pre><code class=\"hljs language-yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">batch/v1</span>\n<span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Job</span>\n<span class=\"hljs-attr\">metadata:</span>\n  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">gpu-job</span>\n<span class=\"hljs-attr\">spec:</span>\n  <span class=\"hljs-attr\">template:</span>\n    <span class=\"hljs-attr\">spec:</span>\n      <span class=\"hljs-attr\">containers:</span>\n      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">gpu-container</span>\n        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">nvidia/cuda:12.5.0-base-ubuntu22.04</span>\n        <span class=\"hljs-attr\">resources:</span>\n          <span class=\"hljs-attr\">limits:</span>\n            <span class=\"hljs-attr\">nvidia.com/gpu:</span> <span class=\"hljs-number\">1</span> <span class=\"hljs-comment\"># Request 1 GPU</span>\n        <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">\"nvidia-smi\"</span>]\n      <span class=\"hljs-attr\">restartPolicy:</span> <span class=\"hljs-string\">Never</span>\n</code></pre>\n<pre><code class=\"hljs language-bash\">kubectl apply -f gpu-verify.yaml\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_4.png\" alt=\"Kubernetes with GPU for MLOps Workloads\"></p>\n<ul>\n<li>íŒŒë“œ ê°€ì ¸ì˜¤ê¸°</li>\n</ul>\n<pre><code class=\"hljs language-js\">kubectl get po \n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_5.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<ul>\n<li>GPU ë¡œê·¸ í™•ì¸</li>\n</ul>\n<pre><code class=\"hljs language-js\">kubectl logs &#x3C;pod>\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_6.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<p>ê·¸ë¦¬ê³  ì‹œì‘í•©ë‹ˆë‹¤..!</p>\n<p>GPUë¥¼ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—…ë°ì´íŠ¸ë¥¼ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. ëª‡ ê°€ì§€ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ê³  ì—¬ê¸°ì— ê³µìœ í•  ì˜ˆì •ì…ë‹ˆë‹¤.</p>\n<p>ì´ì œ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<p>ì½ì–´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!</p>\n<p><a href=\"https://www.linkedin.com/in/sivanaik/\" rel=\"nofollow\" target=\"_blank\">LinkedIn í”„ë¡œí•„</a></p>\n<p><a href=\"https://x.com/sivanaikk\" rel=\"nofollow\" target=\"_blank\">x.comì—ì„œì˜ í”„ë¡œí•„</a></p>\n</body>\n</html>\n"},"__N_SSG":true}