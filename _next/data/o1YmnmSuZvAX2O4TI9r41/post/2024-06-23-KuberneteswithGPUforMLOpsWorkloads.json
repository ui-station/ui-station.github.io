{"pageProps":{"post":{"title":"MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법","description":"","date":"2024-06-23 00:51","slug":"2024-06-23-KuberneteswithGPUforMLOpsWorkloads","content":"\n\n이 기사에서는 GPU가 쿠버네티스와 통합되어 기계 학습 워크로드를 실행하는 방법에 대해 논의하고자 합니다.\n\n저는 주변에 있는 NVIDIA GeForce RTX 3050을 가지고 아이디어를 얻었어요 💡... ` Kubernetes\n\n빠르게 쿠버네티스와 GPU를 통합하여 딥 러닝 훈련 배포를 실행해봅시다!\n\n0. Docker가 설치되어 있는지 확인하세요. 아직 설치되지 않았다면 여기에서 Docker를 다운로드하세요.\n\n<div class=\"content-ad\"></div>\n\n# NVIDIA Container Toolkit for Docker\n\n- NVIDIA 드라이버를 업데이트해주세요\n\n```js\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb\nsudo dpkg -i cuda-keyring_1.1-1_all.deb\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-12-5\n```\n\n- 공식 웹사이트에서 해당 OS에 맞는 NVIDIA 컨테이너 툴킷을 설치해주세요.\n- 제가 WSL을 사용하고 있기 때문에 apt 명령어를 통해 설치하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n```\n\n- 저장소에서 패키지 목록을 업데이트합니다:\n\n```js\nsudo apt-get update\n```\n\n- NVIDIA Container Toolkit 패키지를 설치합니다:\n\n\n<div class=\"content-ad\"></div>\n\n```js\nsudo apt-get install -y nvidia-container-toolkit\n```\n\n![KuberneteswithGPUforMLOpsWorkloads](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png)\n\n- 도커를 실행할 수 있도록 런타임 구성하기\n\n```js\nsudo nvidia-ctk runtime configure --runtime=docker\n```\n\n<div class=\"content-ad\"></div>\n\n아래는 테이블 태그를 Markdown 형식으로 변경한 코드입니다.\n\n\n<img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_1.png\" />\n\n- restart docker\n\n```js\nsudo systemctl restart docker\n```\n\n- Docker Desktop\n\n\n<div class=\"content-ad\"></div>\n\n만일 Docker Desktop을 사용 중이라면, 설정을 다르게 구성하고 daemon.json을 수정해야 합니다.\n\n- 왼쪽 상단의 설정 ⚙️ 로 이동하여 Docker Engine으로 이동한 다음 다음 구성을 추가하십시오. (,를 잊지 말고 json 구문을 확인해주세요 😅)\n\n```js\n\"runtimes\": {\n  \"nvidia\": {\n    \"args\": [],\n    \"path\": \"nvidia-container-runtime\"\n  }\n}\n```\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_2.png)\n\n<div class=\"content-ad\"></div>\n\n2. Apply 및 다시 시작을 클릭하고 GPU 확인\n\n다음 명령어로 도커가 런타임으로 GPU를 사용하는지 확인하세요.\n\n```shell\nsudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi\n```\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_3.png)\n\n<div class=\"content-ad\"></div>\n\n# Minikube\n\n로컬에서 Kubernetes 클러스터를 프로비저닝하는 데 Minikube를 사용할 것입니다.\n\n- [여기](링크)에서 운영 체제에 맞게 Minikube를 다운로드하세요.\n- Minikube 이진 파일을 다운로드한 후 다음 명령어로 Minikube를 시작하세요. Minikube를 시작하기 전에 Docker가 실행 중인지 확인하세요.\n\n```js\nminikube start --gpus all --driver=docker --addons=ingress\n```\n\n<div class=\"content-ad\"></div>\n\nMinikube의 nvidia-gpu-device-plugin 애드온은 Kubernetes 클러스터에서 GPU 지원을 활성화하는 데 설계되었습니다. 이 애드온을 사용하면 Kubernetes가 GPU가 필요한 작업로드를 인식하고 예약하여 클러스터에서 GPU 리소스를 사용할 수 있게 됩니다.\n\nNVIDIA GPU 장치 플러그인이란 무엇인가요?\n\nNVIDIA GPU 장치 플러그인은 Kubernetes 클러스터에서 NVIDIA GPU를 사용할 수 있게 하는 Kubernetes 장치 플러그인입니다. 이 플러그인을 사용하면 Kubernetes가 GPU 리소스를 컨테이너에 할당하고 예약하여 응용 프로그램이 GPU 가속을 사용할 수 있도록 합니다.\n\n주요 기능\n\n<div class=\"content-ad\"></div>\n\n- GPU 발견:\n\n    - 노드에서 NVIDIA GPU를 자동으로 발견하여 Kubernetes에서 스케줄 가능한 리소스로 이용할 수 있습니다.\n\n- GPU 리소스 관리:\n\n    - GPU 리소스를 컨테이너에 할당하는 작업을 관리합니다. Pod에 요청된 GPU 수를 확인하고 GPU 리소스를 스케줄링하는 복잡성을 처리합니다.\n\n<div class=\"content-ad\"></div>\n\n3. 격리:\n\n- GPU 리소스의 격리를 제공하여 GPU 워크로드가 서로 간섭하지 않도록 보장합니다.\n\n4. 메트릭 및 모니터링:\n\n- GPU 활용에 관한 메트릭을 노출하여 GPU 워크로드의 모니터링과 스케일링에 활용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 쿠버네티스에서 GPU 가용성 확인하기\n\nGPU 노드가 사용 가능한지 노드 세부정보를 확인하여 확인하세요\n\n```js\nkubectl get nodes -o \"custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,CAPACITY:.status.capacity\"\n```\n\n- 작업으로 확인하고 매니페스트 파일을 적용하세요\n\n<div class=\"content-ad\"></div>\n\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: gpu-job\nspec:\n  template:\n    spec:\n      containers:\n      - name: gpu-container\n        image: nvidia/cuda:12.5.0-base-ubuntu22.04\n        resources:\n          limits:\n            nvidia.com/gpu: 1 # Request 1 GPU\n        command: [\"nvidia-smi\"]\n      restartPolicy: Never\n```\n\n```bash\nkubectl apply -f gpu-verify.yaml\n```\n\n![Kubernetes with GPU for MLOps Workloads](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_4.png)\n\n- 파드 가져오기\n\n\n<div class=\"content-ad\"></div>\n\n```js\nkubectl get po \n```\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_5.png)\n\n- GPU 로그 확인\n\n```js\nkubectl logs <pod>\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_6.png)\n\n그리고 시작합니다..!\n\nGPU를 보실 수 있습니다. 업데이트를 기다려주세요. 몇 가지 워크로드를 실행하고 여기에 공유할 예정입니다.\n\n이제 쿠버네티스에서 머신러닝 모델을 훈련할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n읽어 주셔서 감사합니다!\n\n[LinkedIn 프로필](https://www.linkedin.com/in/sivanaik/)\n\n[x.com에서의 프로필](https://x.com/sivanaikk)","ogImage":{"url":"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png"},"coverImage":"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png","tag":["Tech"],"readingTime":5},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>이 기사에서는 GPU가 쿠버네티스와 통합되어 기계 학습 워크로드를 실행하는 방법에 대해 논의하고자 합니다.</p>\n<p>저는 주변에 있는 NVIDIA GeForce RTX 3050을 가지고 아이디어를 얻었어요 💡... ` Kubernetes</p>\n<p>빠르게 쿠버네티스와 GPU를 통합하여 딥 러닝 훈련 배포를 실행해봅시다!</p>\n<ol start=\"0\">\n<li>Docker가 설치되어 있는지 확인하세요. 아직 설치되지 않았다면 여기에서 Docker를 다운로드하세요.</li>\n</ol>\n<h1>NVIDIA Container Toolkit for Docker</h1>\n<ul>\n<li>NVIDIA 드라이버를 업데이트해주세요</li>\n</ul>\n<pre><code class=\"hljs language-js\">wget <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb</span>\nsudo dpkg -i cuda-keyring_1<span class=\"hljs-number\">.1</span>-1_all.<span class=\"hljs-property\">deb</span>\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-<span class=\"hljs-number\">12</span>-<span class=\"hljs-number\">5</span>\n</code></pre>\n<ul>\n<li>공식 웹사이트에서 해당 OS에 맞는 NVIDIA 컨테이너 툴킷을 설치해주세요.</li>\n<li>제가 WSL을 사용하고 있기 때문에 apt 명령어를 통해 설치하겠습니다.</li>\n</ul>\n<pre><code class=\"hljs language-js\">curl -fsSL <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\</span>\n  &#x26;&#x26; curl -s -L <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\</span>\n    sed <span class=\"hljs-string\">'s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g'</span> | \\\n    sudo tee /etc/apt/sources.<span class=\"hljs-property\">list</span>.<span class=\"hljs-property\">d</span>/nvidia-container-toolkit.<span class=\"hljs-property\">list</span>\n</code></pre>\n<ul>\n<li>저장소에서 패키지 목록을 업데이트합니다:</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo apt-get update\n</code></pre>\n<ul>\n<li>NVIDIA Container Toolkit 패키지를 설치합니다:</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo apt-get install -y nvidia-container-toolkit\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png\" alt=\"KuberneteswithGPUforMLOpsWorkloads\"></p>\n<ul>\n<li>도커를 실행할 수 있도록 런타임 구성하기</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo nvidia-ctk runtime configure --runtime=docker\n</code></pre>\n<p>아래는 테이블 태그를 Markdown 형식으로 변경한 코드입니다.</p>\n<ul>\n<li>restart docker</li>\n</ul>\n<pre><code class=\"hljs language-js\">sudo systemctl restart docker\n</code></pre>\n<ul>\n<li>Docker Desktop</li>\n</ul>\n<p>만일 Docker Desktop을 사용 중이라면, 설정을 다르게 구성하고 daemon.json을 수정해야 합니다.</p>\n<ul>\n<li>왼쪽 상단의 설정 ⚙️ 로 이동하여 Docker Engine으로 이동한 다음 다음 구성을 추가하십시오. (,를 잊지 말고 json 구문을 확인해주세요 😅)</li>\n</ul>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-string\">\"runtimes\"</span>: {\n  <span class=\"hljs-string\">\"nvidia\"</span>: {\n    <span class=\"hljs-string\">\"args\"</span>: [],\n    <span class=\"hljs-string\">\"path\"</span>: <span class=\"hljs-string\">\"nvidia-container-runtime\"</span>\n  }\n}\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_2.png\" alt=\"이미지\"></p>\n<ol start=\"2\">\n<li>Apply 및 다시 시작을 클릭하고 GPU 확인</li>\n</ol>\n<p>다음 명령어로 도커가 런타임으로 GPU를 사용하는지 확인하세요.</p>\n<pre><code class=\"hljs language-shell\">sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_3.png\" alt=\"이미지\"></p>\n<h1>Minikube</h1>\n<p>로컬에서 Kubernetes 클러스터를 프로비저닝하는 데 Minikube를 사용할 것입니다.</p>\n<ul>\n<li><a href=\"%EB%A7%81%ED%81%AC\">여기</a>에서 운영 체제에 맞게 Minikube를 다운로드하세요.</li>\n<li>Minikube 이진 파일을 다운로드한 후 다음 명령어로 Minikube를 시작하세요. Minikube를 시작하기 전에 Docker가 실행 중인지 확인하세요.</li>\n</ul>\n<pre><code class=\"hljs language-js\">minikube start --gpus all --driver=docker --addons=ingress\n</code></pre>\n<p>Minikube의 nvidia-gpu-device-plugin 애드온은 Kubernetes 클러스터에서 GPU 지원을 활성화하는 데 설계되었습니다. 이 애드온을 사용하면 Kubernetes가 GPU가 필요한 작업로드를 인식하고 예약하여 클러스터에서 GPU 리소스를 사용할 수 있게 됩니다.</p>\n<p>NVIDIA GPU 장치 플러그인이란 무엇인가요?</p>\n<p>NVIDIA GPU 장치 플러그인은 Kubernetes 클러스터에서 NVIDIA GPU를 사용할 수 있게 하는 Kubernetes 장치 플러그인입니다. 이 플러그인을 사용하면 Kubernetes가 GPU 리소스를 컨테이너에 할당하고 예약하여 응용 프로그램이 GPU 가속을 사용할 수 있도록 합니다.</p>\n<p>주요 기능</p>\n<ul>\n<li>\n<p>GPU 발견:</p>\n<ul>\n<li>노드에서 NVIDIA GPU를 자동으로 발견하여 Kubernetes에서 스케줄 가능한 리소스로 이용할 수 있습니다.</li>\n</ul>\n</li>\n<li>\n<p>GPU 리소스 관리:</p>\n<ul>\n<li>GPU 리소스를 컨테이너에 할당하는 작업을 관리합니다. Pod에 요청된 GPU 수를 확인하고 GPU 리소스를 스케줄링하는 복잡성을 처리합니다.</li>\n</ul>\n</li>\n</ul>\n<ol start=\"3\">\n<li>격리:</li>\n</ol>\n<ul>\n<li>GPU 리소스의 격리를 제공하여 GPU 워크로드가 서로 간섭하지 않도록 보장합니다.</li>\n</ul>\n<ol start=\"4\">\n<li>메트릭 및 모니터링:</li>\n</ol>\n<ul>\n<li>GPU 활용에 관한 메트릭을 노출하여 GPU 워크로드의 모니터링과 스케일링에 활용할 수 있습니다.</li>\n</ul>\n<h1>쿠버네티스에서 GPU 가용성 확인하기</h1>\n<p>GPU 노드가 사용 가능한지 노드 세부정보를 확인하여 확인하세요</p>\n<pre><code class=\"hljs language-js\">kubectl get nodes -o <span class=\"hljs-string\">\"custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,CAPACITY:.status.capacity\"</span>\n</code></pre>\n<ul>\n<li>작업으로 확인하고 매니페스트 파일을 적용하세요</li>\n</ul>\n<pre><code class=\"hljs language-yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">batch/v1</span>\n<span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Job</span>\n<span class=\"hljs-attr\">metadata:</span>\n  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">gpu-job</span>\n<span class=\"hljs-attr\">spec:</span>\n  <span class=\"hljs-attr\">template:</span>\n    <span class=\"hljs-attr\">spec:</span>\n      <span class=\"hljs-attr\">containers:</span>\n      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">gpu-container</span>\n        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">nvidia/cuda:12.5.0-base-ubuntu22.04</span>\n        <span class=\"hljs-attr\">resources:</span>\n          <span class=\"hljs-attr\">limits:</span>\n            <span class=\"hljs-attr\">nvidia.com/gpu:</span> <span class=\"hljs-number\">1</span> <span class=\"hljs-comment\"># Request 1 GPU</span>\n        <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">\"nvidia-smi\"</span>]\n      <span class=\"hljs-attr\">restartPolicy:</span> <span class=\"hljs-string\">Never</span>\n</code></pre>\n<pre><code class=\"hljs language-bash\">kubectl apply -f gpu-verify.yaml\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_4.png\" alt=\"Kubernetes with GPU for MLOps Workloads\"></p>\n<ul>\n<li>파드 가져오기</li>\n</ul>\n<pre><code class=\"hljs language-js\">kubectl get po \n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_5.png\" alt=\"이미지\"></p>\n<ul>\n<li>GPU 로그 확인</li>\n</ul>\n<pre><code class=\"hljs language-js\">kubectl logs &#x3C;pod>\n</code></pre>\n<p><img src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_6.png\" alt=\"이미지\"></p>\n<p>그리고 시작합니다..!</p>\n<p>GPU를 보실 수 있습니다. 업데이트를 기다려주세요. 몇 가지 워크로드를 실행하고 여기에 공유할 예정입니다.</p>\n<p>이제 쿠버네티스에서 머신러닝 모델을 훈련할 수 있습니다.</p>\n<p>읽어 주셔서 감사합니다!</p>\n<p><a href=\"https://www.linkedin.com/in/sivanaik/\" rel=\"nofollow\" target=\"_blank\">LinkedIn 프로필</a></p>\n<p><a href=\"https://x.com/sivanaikk\" rel=\"nofollow\" target=\"_blank\">x.com에서의 프로필</a></p>\n</body>\n</html>\n"},"__N_SSG":true}