{"pageProps":{"post":{"title":"원활한 사용을 위해 ExecuTorch와 함께 모바일 앱에 원시 AI를 적용하기 - 파트 1 - iOS","description":"","date":"2024-06-19 14:08","slug":"2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS","content":"\n\n<img src=\"/assets/img/2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS_0.png\" />\n\nExecuTorch는 PyTorch를 기반으로 한 새로운 프레임워크로, PyTorch AI 모델을 로컬 배포에 적합한 형식으로 내보낼 수 있게 해줍니다. 이는 약간의 네이티브 코드와 함께 React Native 앱에 AI 기능을 쉽게 통합할 수 있음을 의미합니다. iOS의 경우, Apple의 Neural Engines 덕분에 고성능을 제공하는 CoreML 백엔드를 활용할 수 있습니다.\n\n이 튜토리얼 시리즈에서는 API 호출이 필요 없이 자신이 선택한 AI 모델을 앱에서 직접 사용하는 방법을 안내해 드릴 것입니다.\n\n## 1. 모델 내보내기\n\n<div class=\"content-ad\"></div>\n\n가장 먼저 해야 할 일은 PyTorch 모델을 .pte 파일로 내보내는 것인데, 이는 본질적으로 PyTorch 실행 가능 파일입니다. 이 부분은 이미 처리해 드렸지만, 만약 여러분의 모델을 사용하고 싶으시다면 ExecuTorch의 Python API를 사용하여 가능합니다. 만약 재현하고 싶다면, 저희 레포지토리에서 모델을 다운로드할 수 있습니다. 여기에서 내보낸 모델들은 PyTorch 예제 레포지토리에서 가져왔습니다. 이를 하기 전에, 환경 설정이 필수적입니다. 기본 내보내기 튜토리얼은 다음을 참조하세요:\n\n전체 프로세스는 여러 단계로 이뤄져 있으며, 사용 사례에 따라 다를 수 있습니다. 모델은 먼저 그래프 표현으로 변환되며, 이후 여러분의 필요에 맞게 최적화될 수 있습니다. 이것은 컴파일, 옵셔널 양자화, 메모리 계획 등을 포함한 다단계 프로세스로, 최종적으로 실행 가능 파일로 내보냅니다. 실행 시, 특정 하드웨어 대상용으로 빌드된 ExecuTorch를 사용하여 장치에서 효율적으로 추론을 수행합니다.\n\n![이미지](/assets/img/2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS_1.png)\n\n이 튜토리얼에서는 이미지를 멋진 아트스타일로 변환하는 스타일 전송 모델을 사용할 것입니다. 만약 웹 및 비디오에 대해 비슷한 일을 하는 방법에 궁금하다면 이전 기사를 확인해보세요. 원하는 모델을 사용하고 싶다면 아래 스크립트를 사용할 수 있습니다. 이를 통해 CoreML 백엔드에 적합한 .pte 파일이 생성될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 2. 라이브러리 빌드 및 설정하기\n\n실제 코딩 부분에 들어가기 전에, 라이브러리를 빌드하고 Xcode 프로젝트에 연결해야 합니다. 빌드 프로세스는 문서에서 자세히 설명되어 있으므로, 익숙해지는 것을 강력히 권장합니다. 그러나 우리는 이미 빌드했으며 편의를 위해 GitHub 저장소에서 빌드를 다운로드할 수 있습니다.\n\n라이브러리를 다운로드한 후 (coreml_backend.xcframework와 executorch.xcframework), Xcode 프로젝트로 이동하여 -` 빌드 패스 -` 라이브러리와 함께 링크하기 -` +를 클릭하여 프로젝트에 추가해야 합니다. 또한 Xcode에서 기본 제공되는 CoreML.framework와 Accelerate.framework도 추가해야 합니다.\n\n코딩에 들어가기 전에 빌드 설정 -` 다른 링커 플래그로 이동하여 -all_load 플래그를 추가해야 합니다. 이를 통해 라이브러리가 제대로 연결되도록 할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 3. 코딩 파트 — Xcode\n\n구현으로 넘어가면 이제 Objective-C++ 파일을 만들어야 합니다. 이를 StyleTransferModule.mm으로 부르겠습니다. 우리 코드에서는 React Native 앱에서 네이티브 모듈을 사용하여 이 메서드를 호출합니다. 그러나 이것은 선택 사항이며 사용 사례에 맞게 조정할 수 있습니다.\n\n```js\n// StyleTransferModule.mm\n\n#import \"StyleTransferModule.h\"\n#import \"ImageProcessor.h\"\n#import <executorch/extension/module/module.h>\n\nusing namespace ::torch::executor;\n\nconst int32_t imageSize = 640;\nconst int32_t numChannels = 3;\n\n@implementation StyleTransferModule {\n  std::unique_ptr<Module> styleTransferModel;\n}\n\n\nRCT_EXPORT_METHOD(initModule:(NSString *)modelFileName resolver:(RCTPromiseResolveBlock)resolve rejecter:(RCTPromiseRejectBlock)reject) {\n    NSString *styleTransferPath = [[NSBundle mainBundle] pathForResource:modelFileName ofType:@\"pte\"];\n    styleTransferModel= std::make_unique<Module>(styleTransferPath.UTF8String);\n    \n    if (styleTransferModel) {\n        resolve(@\"Module created successfully\");\n    } else {\n        NSError *error = [NSError errorWithDomain:@\"com.example.module\" code:1 userInfo:nil];\n        reject(@\"module_error\", @\"Failed to create module\", error);\n    }\n}\n```\n\n먼저 Module 클래스의 인스턴스를 만들어야 합니다. 이는 ExecuTorch 프레임워크의 일부입니다. 이를 통해 모델의 forward()와 같은 내보낸 메서드를 호출할 수 있습니다. 클래스를 인스턴스화하려면 이전에 언급한 .pte 파일의 경로를 전달해야 합니다. 또한 RCT_EXPORT_METHOD 매크로를 사용하여 메서드를 JS로 내보냅니다.\n\n<div class=\"content-ad\"></div>\n\n모델을 실행하기 전에 다음 단계는 입력 텐서를 준비하는 것입니다. 머신 러닝 프레임워크와 작업을 해본 적이 있다면 텐서에 익숙할 것입니다. 고수준에서 말하면, 이것은 GPU에서 실행할 수 있는 배열입니다.\n\n텐서를 만들려면 이미지의 원시 RGB 데이터를 가져와야 합니다. 저희 저장소에서는 여러 모델을 로드하기 때문에 코드가 약간 다릅니다. 하지만 간단하게 유지하기 위해 이 튜토리얼에서는 한 모델에 집중하겠습니다.\n\n```js\n// StyleTransferModule.mm\nRCT_EXPORT_METHOD(applyStyleTransfer:(NSString *)imageUri resolver:(RCTPromiseResolveBlock)resolve rejecter:(RCTPromiseRejectBlock)reject) {\n{\n    if (!styleTransferModel) {\n        reject(@\"module_error\", @\"Module not initialized\", [NSError errorWithDomain:@\"com.example.module\" code:1 userInfo:nil]);\n        return;\n    }\n\n    NSURL *url = [NSURL URLWithString:imageUri];\n    NSData *data = [NSData dataWithContentsOfURL:url];\n    if (!data) {\n      reject(@\"img_loading_error\", @\"Unable to load image data\", nil);\n      return;\n    }\n    UIImage *inputImage = [UIImage imageWithData:data];\r\n```\n\n다시 한번 해당 메서드를 JS에 내보냅니다. applyStyleTransfer라고 부르며, NSString 포인터를 받도록 만들었습니다. 이는 표준 JS 문자열과 해당됩니다. 이 문자열은 우리 입력 이미지의 URI가 될 것입니다. 이제 모델이 예상하는 데이터 형식인 원시 RGB 데이터 배열을 만들어야 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// StyleTransferModule.mm\n// ...\n\n// StyleTransferModule.mm\n// ...\n\n  CGSize targetSize = CGSizeMake(imageSize, imageSize);\n  UIImage *resizedImage = [ImageProcessor resizeImage:inputImage toSize:targetSize];\n  \n  // to float array - the input\n  float *imageData = [ImageProcessor imageToFloatArray:resizedImage size:&targetSize];\n  \n  // make it a tensor\n  int32_t sizes[] = {1, numChannels, imageSize, imageSize};\n  TensorImpl inputTensorImpl(ScalarType::Float, std::size(sizes), sizes, imageData);\n  Tensor inputTensor = Tensor(&inputTensorImpl);\n\n이제 UIImage를 가져와서 사용자 정의 ImageProcessor에 전달합니다. 이것은 사용 사례와 모델에 따라 다양한 전처리 부분입니다. 여기서는 640x640 크기의 이미지 및 float 값 배열이 필요합니다. 크기 조정이 항상 필요한 것은 아니며 동적 입력 형태로 모델을 내보낼 수 있습니다. ImageProcessor가 정확히 무엇을 하는지 보려면 여기를 클릭하세요. 이후에는 해당 데이터로부터 텐서를 생성해야 하므로 데이터 및 텐서 크기를 TensorImpl 생성자에 전달해야 합니다. 마지막으로 TensorImpl을 Tensor 자체로 전달해야 합니다.\n\n다음 단계는 텐서를 모델에 전달하는 것입니다. 이 부분은 매우 간단합니다. 이전에 생성된 Tensor를 EValue로 래핑하고 벡터에 넣은 다음 forward() 메서드(또는 내보낸 다른 메서드)를 실행하기만 하면 됩니다. 벡터에 넣는 이유는 여러 입력을 예상하는 모델이 있기 때문입니다.\n\n// StyleTransferModule.mm\n// ...\n\nconst auto result = styleTransferModel->forward({EValue(inputTensor)});\nif (!result.ok()) {\nNSError *error = [NSError\n        errorWithDomain:@\"ModelForwardFailure\"\n        code:NSInteger(result.error())\n        userInfo:@{NSLocalizedDescriptionKey: [NSString stringWithFormat:@\"Failed to run forward on the torch module, error code: %i\", result.error()]}];\n  reject(@\"model_failure\", error.localizedDescription, error);\n}\nconst float *outputData = result->at(0).toTensor().const_data_ptr<float>();\nfree(imageData);\n\n<div class=\"content-ad\"></div>\n\n추론 중에 오류가 발생했는지 확인하려면 .ok() 메서드를 호출하면 됩니다. outputData 변수는 모델 호출 결과에 대한 포인터입니다. 이는 분류 작업의 확률부터 LLM 출력까지 어떤 것이든 될 수 있습니다. 마지막으로 후속 처리 단계를 수행하고 출력 이미지 URI를 JS 쪽에 반환해야 합니다.\n\n// StyleTransferModule.mm\n// ...\n\nCGSize outputSize = CGSizeMake(imageSize, imageSize);\nUIImage *outputImage = [ImageProcessor imageFromFloatArray:outputData size:outputSize];\n  \n// save img to tmp dir, return URI\nNSString *outputPath = [NSTemporaryDirectory() stringByAppendingPathComponent:@\"processed_image.png\"];\nif ([UIImagePNGRepresentation(outputImage) writeToFile:outputPath atomically:YES]) {\n  NSURL *fileURL = [NSURL fileURLWithPath:outputPath];\n  resolve([fileURL absoluteString]);\n} else {\n  reject(@\"img_write_error\", @\"Failed to write processed image to file\", nil);\n}\n\n그것이 거의 다입니다. 이 접근 방식을 React Native 앱에서 어떻게 사용할 수 있는지 보여주는 데모 앱을 준비했습니다. 왼쪽에 원본 이미지, 오른쪽에 모델 출력이 표시됩니다.\n\n<img src=\"/assets/img/2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n## 마지막으로\n\n축하해요! 모델을 성공적으로 실행했어요. ExecuTorch는 LLaMa만큼 큰 모델도 완전히 기기에서 실행할 수 있게 해 주는 거대한 프레임워크야.\n\n이 시리즈의 다음 부분에서는 Android에서도 똑같이 할 수 있는 방법을 보여줄 거에요. 또한 곧 우리의 객체 제거 데모와 관련된 꽤 인상적인 기능을 구현하는 튜토리얼을 공개할 예정이에요 👀. 우리의 AI 및 멀티미디어 작업에 대해 계속해서 소식을 받고 싶다면 RTC.ON 소식지에 가입해주세요. 계속 연락을 유지해 주세요!\n\n우리는 소프트웨어 마스터즈(Software Mansion)입니다: 소프트웨어 개발 컨설턴트, AI 탐험가, 멀티미디어 전문가, React Native 코어 기여자 및 커뮤니티 빌더들이에요. 우리를 고용하고 싶다면 projects@swmansion.com 으로 연락해 주세요.","ogImage":{"url":"/assets/img/2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS_0.png"},"coverImage":"/assets/img/2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS_0.png","tag":["Tech"],"readingTime":8},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>ExecuTorch는 PyTorch를 기반으로 한 새로운 프레임워크로, PyTorch AI 모델을 로컬 배포에 적합한 형식으로 내보낼 수 있게 해줍니다. 이는 약간의 네이티브 코드와 함께 React Native 앱에 AI 기능을 쉽게 통합할 수 있음을 의미합니다. iOS의 경우, Apple의 Neural Engines 덕분에 고성능을 제공하는 CoreML 백엔드를 활용할 수 있습니다.</p>\n<p>이 튜토리얼 시리즈에서는 API 호출이 필요 없이 자신이 선택한 AI 모델을 앱에서 직접 사용하는 방법을 안내해 드릴 것입니다.</p>\n<h2>1. 모델 내보내기</h2>\n<p>가장 먼저 해야 할 일은 PyTorch 모델을 .pte 파일로 내보내는 것인데, 이는 본질적으로 PyTorch 실행 가능 파일입니다. 이 부분은 이미 처리해 드렸지만, 만약 여러분의 모델을 사용하고 싶으시다면 ExecuTorch의 Python API를 사용하여 가능합니다. 만약 재현하고 싶다면, 저희 레포지토리에서 모델을 다운로드할 수 있습니다. 여기에서 내보낸 모델들은 PyTorch 예제 레포지토리에서 가져왔습니다. 이를 하기 전에, 환경 설정이 필수적입니다. 기본 내보내기 튜토리얼은 다음을 참조하세요:</p>\n<p>전체 프로세스는 여러 단계로 이뤄져 있으며, 사용 사례에 따라 다를 수 있습니다. 모델은 먼저 그래프 표현으로 변환되며, 이후 여러분의 필요에 맞게 최적화될 수 있습니다. 이것은 컴파일, 옵셔널 양자화, 메모리 계획 등을 포함한 다단계 프로세스로, 최종적으로 실행 가능 파일로 내보냅니다. 실행 시, 특정 하드웨어 대상용으로 빌드된 ExecuTorch를 사용하여 장치에서 효율적으로 추론을 수행합니다.</p>\n<p><img src=\"/assets/img/2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS_1.png\" alt=\"이미지\"></p>\n<p>이 튜토리얼에서는 이미지를 멋진 아트스타일로 변환하는 스타일 전송 모델을 사용할 것입니다. 만약 웹 및 비디오에 대해 비슷한 일을 하는 방법에 궁금하다면 이전 기사를 확인해보세요. 원하는 모델을 사용하고 싶다면 아래 스크립트를 사용할 수 있습니다. 이를 통해 CoreML 백엔드에 적합한 .pte 파일이 생성될 것입니다.</p>\n<h2>2. 라이브러리 빌드 및 설정하기</h2>\n<p>실제 코딩 부분에 들어가기 전에, 라이브러리를 빌드하고 Xcode 프로젝트에 연결해야 합니다. 빌드 프로세스는 문서에서 자세히 설명되어 있으므로, 익숙해지는 것을 강력히 권장합니다. 그러나 우리는 이미 빌드했으며 편의를 위해 GitHub 저장소에서 빌드를 다운로드할 수 있습니다.</p>\n<p>라이브러리를 다운로드한 후 (coreml_backend.xcframework와 executorch.xcframework), Xcode 프로젝트로 이동하여 -<code> 빌드 패스 -</code> 라이브러리와 함께 링크하기 -` +를 클릭하여 프로젝트에 추가해야 합니다. 또한 Xcode에서 기본 제공되는 CoreML.framework와 Accelerate.framework도 추가해야 합니다.</p>\n<p>코딩에 들어가기 전에 빌드 설정 -` 다른 링커 플래그로 이동하여 -all_load 플래그를 추가해야 합니다. 이를 통해 라이브러리가 제대로 연결되도록 할 수 있습니다.</p>\n<h2>3. 코딩 파트 — Xcode</h2>\n<p>구현으로 넘어가면 이제 Objective-C++ 파일을 만들어야 합니다. 이를 StyleTransferModule.mm으로 부르겠습니다. 우리 코드에서는 React Native 앱에서 네이티브 모듈을 사용하여 이 메서드를 호출합니다. 그러나 이것은 선택 사항이며 사용 사례에 맞게 조정할 수 있습니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-comment\">// StyleTransferModule.mm</span>\n\n#<span class=\"hljs-keyword\">import</span> <span class=\"hljs-string\">\"StyleTransferModule.h\"</span>\n#<span class=\"hljs-keyword\">import</span> <span class=\"hljs-string\">\"ImageProcessor.h\"</span>\n#<span class=\"hljs-keyword\">import</span> &#x3C;executorch/extension/<span class=\"hljs-variable language_\">module</span>/<span class=\"hljs-variable language_\">module</span>.<span class=\"hljs-property\">h</span>>\n\nusing namespace ::<span class=\"hljs-attr\">torch</span>::executor;\n\n<span class=\"hljs-keyword\">const</span> int32_t imageSize = <span class=\"hljs-number\">640</span>;\n<span class=\"hljs-keyword\">const</span> int32_t numChannels = <span class=\"hljs-number\">3</span>;\n\n@implementation <span class=\"hljs-title class_\">StyleTransferModule</span> {\n  <span class=\"hljs-attr\">std</span>::unique_ptr&#x3C;<span class=\"hljs-title class_\">Module</span>> styleTransferModel;\n}\n\n\n<span class=\"hljs-title function_\">RCT_EXPORT_METHOD</span>(<span class=\"hljs-params\">initModule:(NSString *)modelFileName resolver:(RCTPromiseResolveBlock)resolve rejecter:(RCTPromiseRejectBlock)reject</span>) {\n    <span class=\"hljs-title class_\">NSString</span> *styleTransferPath = [[<span class=\"hljs-title class_\">NSBundle</span> mainBundle] <span class=\"hljs-attr\">pathForResource</span>:modelFileName <span class=\"hljs-attr\">ofType</span>:@<span class=\"hljs-string\">\"pte\"</span>];\n    styleTransferModel= <span class=\"hljs-attr\">std</span>::make_unique&#x3C;<span class=\"hljs-title class_\">Module</span>>(styleTransferPath.<span class=\"hljs-property\">UTF8String</span>);\n    \n    <span class=\"hljs-keyword\">if</span> (styleTransferModel) {\n        <span class=\"hljs-title function_\">resolve</span>(@<span class=\"hljs-string\">\"Module created successfully\"</span>);\n    } <span class=\"hljs-keyword\">else</span> {\n        <span class=\"hljs-title class_\">NSError</span> *error = [<span class=\"hljs-title class_\">NSError</span> <span class=\"hljs-attr\">errorWithDomain</span>:@<span class=\"hljs-string\">\"com.example.module\"</span> <span class=\"hljs-attr\">code</span>:<span class=\"hljs-number\">1</span> <span class=\"hljs-attr\">userInfo</span>:nil];\n        <span class=\"hljs-title function_\">reject</span>(@<span class=\"hljs-string\">\"module_error\"</span>, @<span class=\"hljs-string\">\"Failed to create module\"</span>, error);\n    }\n}\n</code></pre>\n<p>먼저 Module 클래스의 인스턴스를 만들어야 합니다. 이는 ExecuTorch 프레임워크의 일부입니다. 이를 통해 모델의 forward()와 같은 내보낸 메서드를 호출할 수 있습니다. 클래스를 인스턴스화하려면 이전에 언급한 .pte 파일의 경로를 전달해야 합니다. 또한 RCT_EXPORT_METHOD 매크로를 사용하여 메서드를 JS로 내보냅니다.</p>\n<p>모델을 실행하기 전에 다음 단계는 입력 텐서를 준비하는 것입니다. 머신 러닝 프레임워크와 작업을 해본 적이 있다면 텐서에 익숙할 것입니다. 고수준에서 말하면, 이것은 GPU에서 실행할 수 있는 배열입니다.</p>\n<p>텐서를 만들려면 이미지의 원시 RGB 데이터를 가져와야 합니다. 저희 저장소에서는 여러 모델을 로드하기 때문에 코드가 약간 다릅니다. 하지만 간단하게 유지하기 위해 이 튜토리얼에서는 한 모델에 집중하겠습니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-comment\">// StyleTransferModule.mm</span>\n<span class=\"hljs-title function_\">RCT_EXPORT_METHOD</span>(<span class=\"hljs-params\">applyStyleTransfer:(NSString *)imageUri resolver:(RCTPromiseResolveBlock)resolve rejecter:(RCTPromiseRejectBlock)reject</span>) {\n{\n    <span class=\"hljs-keyword\">if</span> (!styleTransferModel) {\n        <span class=\"hljs-title function_\">reject</span>(@<span class=\"hljs-string\">\"module_error\"</span>, @<span class=\"hljs-string\">\"Module not initialized\"</span>, [<span class=\"hljs-title class_\">NSError</span> <span class=\"hljs-attr\">errorWithDomain</span>:@<span class=\"hljs-string\">\"com.example.module\"</span> <span class=\"hljs-attr\">code</span>:<span class=\"hljs-number\">1</span> <span class=\"hljs-attr\">userInfo</span>:nil]);\n        <span class=\"hljs-keyword\">return</span>;\n    }\n\n    <span class=\"hljs-variable constant_\">NSURL</span> *url = [<span class=\"hljs-variable constant_\">NSURL</span> <span class=\"hljs-title class_\">URLWithString</span>:imageUri];\n    <span class=\"hljs-title class_\">NSData</span> *data = [<span class=\"hljs-title class_\">NSData</span> <span class=\"hljs-attr\">dataWithContentsOfURL</span>:url];\n    <span class=\"hljs-keyword\">if</span> (!data) {\n      <span class=\"hljs-title function_\">reject</span>(@<span class=\"hljs-string\">\"img_loading_error\"</span>, @<span class=\"hljs-string\">\"Unable to load image data\"</span>, nil);\n      <span class=\"hljs-keyword\">return</span>;\n    }\n    <span class=\"hljs-title class_\">UIImage</span> *inputImage = [<span class=\"hljs-title class_\">UIImage</span> <span class=\"hljs-attr\">imageWithData</span>:data];\n</code></pre>\n<p>다시 한번 해당 메서드를 JS에 내보냅니다. applyStyleTransfer라고 부르며, NSString 포인터를 받도록 만들었습니다. 이는 표준 JS 문자열과 해당됩니다. 이 문자열은 우리 입력 이미지의 URI가 될 것입니다. 이제 모델이 예상하는 데이터 형식인 원시 RGB 데이터 배열을 만들어야 합니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-comment\">// StyleTransferModule.mm</span>\n<span class=\"hljs-comment\">// ...</span>\n\n<span class=\"hljs-comment\">// StyleTransferModule.mm</span>\n<span class=\"hljs-comment\">// ...</span>\n\n  <span class=\"hljs-title class_\">CGSize</span> targetSize = <span class=\"hljs-title class_\">CGSizeMake</span>(imageSize, imageSize);\n  <span class=\"hljs-title class_\">UIImage</span> *resizedImage = [<span class=\"hljs-title class_\">ImageProcessor</span> <span class=\"hljs-attr\">resizeImage</span>:inputImage <span class=\"hljs-attr\">toSize</span>:targetSize];\n  \n  <span class=\"hljs-comment\">// to float array - the input</span>\n  float *imageData = [<span class=\"hljs-title class_\">ImageProcessor</span> <span class=\"hljs-attr\">imageToFloatArray</span>:resizedImage <span class=\"hljs-attr\">size</span>:&#x26;targetSize];\n  \n  <span class=\"hljs-comment\">// make it a tensor</span>\n  int32_t sizes[] = {<span class=\"hljs-number\">1</span>, numChannels, imageSize, imageSize};\n  <span class=\"hljs-title class_\">TensorImpl</span> <span class=\"hljs-title function_\">inputTensorImpl</span>(<span class=\"hljs-title class_\">ScalarType</span>::<span class=\"hljs-title class_\">Float</span>, <span class=\"hljs-attr\">std</span>::<span class=\"hljs-title function_\">size</span>(sizes), sizes, imageData);\n  <span class=\"hljs-title class_\">Tensor</span> inputTensor = <span class=\"hljs-title class_\">Tensor</span>(&#x26;inputTensorImpl);\n\n이제 <span class=\"hljs-title class_\">UIImage</span>를 가져와서 사용자 정의 <span class=\"hljs-title class_\">ImageProcessor</span>에 전달합니다. 이것은 사용 사례와 모델에 따라 다양한 전처리 부분입니다. 여기서는 640x640 크기의 이미지 및 float 값 배열이 필요합니다. 크기 조정이 항상 필요한 것은 아니며 동적 입력 형태로 모델을 내보낼 수 있습니다. <span class=\"hljs-title class_\">ImageProcessor</span>가 정확히 무엇을 하는지 보려면 여기를 클릭하세요. 이후에는 해당 데이터로부터 텐서를 생성해야 하므로 데이터 및 텐서 크기를 <span class=\"hljs-title class_\">TensorImpl</span> 생성자에 전달해야 합니다. 마지막으로 <span class=\"hljs-title class_\">TensorImpl</span>을 <span class=\"hljs-title class_\">Tensor</span> 자체로 전달해야 합니다.\n\n다음 단계는 텐서를 모델에 전달하는 것입니다. 이 부분은 매우 간단합니다. 이전에 생성된 <span class=\"hljs-title class_\">Tensor</span>를 <span class=\"hljs-title class_\">EValue</span>로 래핑하고 벡터에 넣은 다음 <span class=\"hljs-title function_\">forward</span>() 메서드(또는 내보낸 다른 메서드)를 실행하기만 하면 됩니다. 벡터에 넣는 이유는 여러 입력을 예상하는 모델이 있기 때문입니다.\n\n<span class=\"hljs-comment\">// StyleTransferModule.mm</span>\n<span class=\"hljs-comment\">// ...</span>\n\n<span class=\"hljs-keyword\">const</span> auto result = styleTransferModel-><span class=\"hljs-title function_\">forward</span>({<span class=\"hljs-title class_\">EValue</span>(inputTensor)});\n<span class=\"hljs-keyword\">if</span> (!result.<span class=\"hljs-title function_\">ok</span>()) {\n<span class=\"hljs-title class_\">NSError</span> *error = [<span class=\"hljs-title class_\">NSError</span>\n        <span class=\"hljs-attr\">errorWithDomain</span>:@<span class=\"hljs-string\">\"ModelForwardFailure\"</span>\n        <span class=\"hljs-attr\">code</span>:<span class=\"hljs-title class_\">NSInteger</span>(result.<span class=\"hljs-title function_\">error</span>())\n        <span class=\"hljs-attr\">userInfo</span>:@{<span class=\"hljs-title class_\">NSLocalizedDescriptionKey</span>: [<span class=\"hljs-title class_\">NSString</span> <span class=\"hljs-attr\">stringWithFormat</span>:@<span class=\"hljs-string\">\"Failed to run forward on the torch module, error code: %i\"</span>, result.<span class=\"hljs-title function_\">error</span>()]}];\n  <span class=\"hljs-title function_\">reject</span>(@<span class=\"hljs-string\">\"model_failure\"</span>, error.<span class=\"hljs-property\">localizedDescription</span>, error);\n}\n<span class=\"hljs-keyword\">const</span> float *outputData = result-><span class=\"hljs-title function_\">at</span>(<span class=\"hljs-number\">0</span>).<span class=\"hljs-title function_\">toTensor</span>().<span class=\"hljs-property\">const_data_ptr</span>&#x3C;float>();\n<span class=\"hljs-title function_\">free</span>(imageData);\n\n<span class=\"xml\"><span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">\"content-ad\"</span>></span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">div</span>></span></span>\n\n추론 중에 오류가 발생했는지 확인하려면 .<span class=\"hljs-title function_\">ok</span>() 메서드를 호출하면 됩니다. outputData 변수는 모델 호출 결과에 대한 포인터입니다. 이는 분류 작업의 확률부터 <span class=\"hljs-variable constant_\">LLM</span> 출력까지 어떤 것이든 될 수 있습니다. 마지막으로 후속 처리 단계를 수행하고 출력 이미지 <span class=\"hljs-variable constant_\">URI</span>를 <span class=\"hljs-variable constant_\">JS</span> 쪽에 반환해야 합니다.\n\n<span class=\"hljs-comment\">// StyleTransferModule.mm</span>\n<span class=\"hljs-comment\">// ...</span>\n\n<span class=\"hljs-title class_\">CGSize</span> outputSize = <span class=\"hljs-title class_\">CGSizeMake</span>(imageSize, imageSize);\n<span class=\"hljs-title class_\">UIImage</span> *outputImage = [<span class=\"hljs-title class_\">ImageProcessor</span> <span class=\"hljs-attr\">imageFromFloatArray</span>:outputData <span class=\"hljs-attr\">size</span>:outputSize];\n  \n<span class=\"hljs-comment\">// save img to tmp dir, return URI</span>\n<span class=\"hljs-title class_\">NSString</span> *outputPath = [<span class=\"hljs-title class_\">NSTemporaryDirectory</span>() <span class=\"hljs-attr\">stringByAppendingPathComponent</span>:@<span class=\"hljs-string\">\"processed_image.png\"</span>];\n<span class=\"hljs-keyword\">if</span> ([<span class=\"hljs-title class_\">UIImagePNGRepresentation</span>(outputImage) <span class=\"hljs-attr\">writeToFile</span>:outputPath <span class=\"hljs-attr\">atomically</span>:<span class=\"hljs-variable constant_\">YES</span>]) {\n  <span class=\"hljs-variable constant_\">NSURL</span> *fileURL = [<span class=\"hljs-variable constant_\">NSURL</span> <span class=\"hljs-attr\">fileURLWithPath</span>:outputPath];\n  <span class=\"hljs-title function_\">resolve</span>([fileURL absoluteString]);\n} <span class=\"hljs-keyword\">else</span> {\n  <span class=\"hljs-title function_\">reject</span>(@<span class=\"hljs-string\">\"img_write_error\"</span>, @<span class=\"hljs-string\">\"Failed to write processed image to file\"</span>, nil);\n}\n\n그것이 거의 다입니다. 이 접근 방식을 <span class=\"hljs-title class_\">React</span> <span class=\"hljs-title class_\">Native</span> 앱에서 어떻게 사용할 수 있는지 보여주는 데모 앱을 준비했습니다. 왼쪽에 원본 이미지, 오른쪽에 모델 출력이 표시됩니다.\n\n&#x3C;img src=<span class=\"hljs-string\">\"/assets/img/2024-06-19-BringingnativeAItoyourmobileappswithExecuTorchpartIiOS_2.png\"</span> />\n\n<span class=\"xml\"><span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">\"content-ad\"</span>></span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">div</span>></span></span>\n\n## 마지막으로\n\n축하해요! 모델을 성공적으로 실행했어요. <span class=\"hljs-title class_\">ExecuTorch</span>는 <span class=\"hljs-title class_\">LLaMa</span>만큼 큰 모델도 완전히 기기에서 실행할 수 있게 해 주는 거대한 프레임워크야.\n\n이 시리즈의 다음 부분에서는 <span class=\"hljs-title class_\">Android</span>에서도 똑같이 할 수 있는 방법을 보여줄 거에요. 또한 곧 우리의 객체 제거 데모와 관련된 꽤 인상적인 기능을 구현하는 튜토리얼을 공개할 예정이에요 👀. 우리의 <span class=\"hljs-variable constant_\">AI</span> 및 멀티미디어 작업에 대해 계속해서 소식을 받고 싶다면 <span class=\"hljs-variable constant_\">RTC</span>.<span class=\"hljs-property\">ON</span> 소식지에 가입해주세요. 계속 연락을 유지해 주세요!\n\n우리는 소프트웨어 마스터즈(<span class=\"hljs-title class_\">Software</span> <span class=\"hljs-title class_\">Mansion</span>)입니다: 소프트웨어 개발 컨설턴트, <span class=\"hljs-variable constant_\">AI</span> 탐험가, 멀티미디어 전문가, <span class=\"hljs-title class_\">React</span> <span class=\"hljs-title class_\">Native</span> 코어 기여자 및 커뮤니티 빌더들이에요. 우리를 고용하고 싶다면 projects@swmansion.<span class=\"hljs-property\">com</span> 으로 연락해 주세요.\n</code></pre>\n</body>\n</html>\n"},"__N_SSG":true}