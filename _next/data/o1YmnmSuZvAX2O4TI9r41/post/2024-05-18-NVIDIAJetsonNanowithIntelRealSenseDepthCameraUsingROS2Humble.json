{"pageProps":{"post":{"title":"NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기","description":"","date":"2024-05-18 19:15","slug":"2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble","content":"\n\n<img src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png\" />\n\n이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.\n\n<img src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png\" />\n\n# Prerequisites\n\n<div class=\"content-ad\"></div>\n\n시작하기 전에 다음 구성 요소가 있는지 확인하십시오:\n\n- NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04\n- Intel RealSense Depth Camera (예: D435i)\n- Jetson Nano에 설치된 ROS2 Humble\n- RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블\n- 필요한 패키지를 다운로드하기 위한 인터넷 연결\n\nROS2 RealSense 패키지 설치\n\n```js\nsudo apt install ros-humble-realsense2-camera\n```\n\n<div class=\"content-ad\"></div>\n\nRealSense 노드를 시작해주세요:\n\nRealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:\n\n```python\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='realsense2_camera',\n            executable='realsense2_camera_node',\n            name='realsense2_camera',\n            output='screen',\n            parameters=[{\n                'enable_depth': True,\n                'enable_infra1': True,\n                'enable_infra2': True,\n                'enable_color': True,\n            }],\n        ),\n    ])\n```\n\n란치 파일을 실행하세요:\n\n<div class=\"content-ad\"></div>\n\n<table>\n    <tr>\n        <td>![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png)</td>\n    </tr>\n</table>\n\n```js\nros2 launch your_package_name realsense_launch.py\n```\n\nrqt에서 데이터 시각화:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png)\n\n<div class=\"content-ad\"></div>\n\nrqt에 RealSense 데이터 추가하기:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png)\n\n- 새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.\n- 이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png)\n\n<div class=\"content-ad\"></div>\n\n깊이 이미지\n\n![깊이 이미지](https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif)\n\n# 깊이 이미지란?\n\n깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n# 주요 주제 및 메시지\n\nROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:\n\n- 토픽: /camera/depth/image_raw\n- 메시지 유형: sensor_msgs/Image\n\n## sensor_msgs/Image 메시지\n\n<div class=\"content-ad\"></div>\n\nsensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:\n\n- header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.\n- height: 이미지의 높이(픽셀 단위).\n- width: 이미지의 너비(픽셀 단위).\n- encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.\n- is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.\n- step: 바이트 단위의 전체 행 길이.\n- data: 바이트 배열로 저장된 실제 픽셀 데이터.\n\n## 깊이 이미지 처리\n\n깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- 객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.\n- 장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.\n- 3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.\n\n# 결론\n\n위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.\n\n문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!","ogImage":{"url":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"},"coverImage":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png","tag":["Tech"],"readingTime":4},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.</p>\n<h1>Prerequisites</h1>\n<p>시작하기 전에 다음 구성 요소가 있는지 확인하십시오:</p>\n<ul>\n<li>NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04</li>\n<li>Intel RealSense Depth Camera (예: D435i)</li>\n<li>Jetson Nano에 설치된 ROS2 Humble</li>\n<li>RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블</li>\n<li>필요한 패키지를 다운로드하기 위한 인터넷 연결</li>\n</ul>\n<p>ROS2 RealSense 패키지 설치</p>\n<pre><code class=\"hljs language-js\">sudo apt install ros-humble-realsense2-camera\n</code></pre>\n<p>RealSense 노드를 시작해주세요:</p>\n<p>RealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> launch <span class=\"hljs-keyword\">import</span> LaunchDescription\n<span class=\"hljs-keyword\">from</span> launch_ros.actions <span class=\"hljs-keyword\">import</span> Node\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">generate_launch_description</span>():\n    <span class=\"hljs-keyword\">return</span> LaunchDescription([\n        Node(\n            package=<span class=\"hljs-string\">'realsense2_camera'</span>,\n            executable=<span class=\"hljs-string\">'realsense2_camera_node'</span>,\n            name=<span class=\"hljs-string\">'realsense2_camera'</span>,\n            output=<span class=\"hljs-string\">'screen'</span>,\n            parameters=[{\n                <span class=\"hljs-string\">'enable_depth'</span>: <span class=\"hljs-literal\">True</span>,\n                <span class=\"hljs-string\">'enable_infra1'</span>: <span class=\"hljs-literal\">True</span>,\n                <span class=\"hljs-string\">'enable_infra2'</span>: <span class=\"hljs-literal\">True</span>,\n                <span class=\"hljs-string\">'enable_color'</span>: <span class=\"hljs-literal\">True</span>,\n            }],\n        ),\n    ])\n</code></pre>\n<p>란치 파일을 실행하세요:</p>\n<pre><code class=\"hljs language-js\">ros2 launch your_package_name realsense_launch.<span class=\"hljs-property\">py</span>\n</code></pre>\n<p>rqt에서 데이터 시각화:</p>\n<p><img src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png\" alt=\"이미지\"></p>\n<p>rqt에 RealSense 데이터 추가하기:</p>\n<p><img src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png\" alt=\"이미지\"></p>\n<ul>\n<li>새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.</li>\n<li>이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.</li>\n</ul>\n<p><img src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png\" alt=\"이미지\"></p>\n<p>깊이 이미지</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif\" alt=\"깊이 이미지\"></p>\n<h1>깊이 이미지란?</h1>\n<p>깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.</p>\n<h1>주요 주제 및 메시지</h1>\n<p>ROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:</p>\n<ul>\n<li>토픽: /camera/depth/image_raw</li>\n<li>메시지 유형: sensor_msgs/Image</li>\n</ul>\n<h2>sensor_msgs/Image 메시지</h2>\n<p>sensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:</p>\n<ul>\n<li>header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.</li>\n<li>height: 이미지의 높이(픽셀 단위).</li>\n<li>width: 이미지의 너비(픽셀 단위).</li>\n<li>encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.</li>\n<li>is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.</li>\n<li>step: 바이트 단위의 전체 행 길이.</li>\n<li>data: 바이트 배열로 저장된 실제 픽셀 데이터.</li>\n</ul>\n<h2>깊이 이미지 처리</h2>\n<p>깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:</p>\n<ul>\n<li>객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.</li>\n<li>장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.</li>\n<li>3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.</li>\n</ul>\n<h1>결론</h1>\n<p>위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.</p>\n<p>문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!</p>\n</body>\n</html>\n"},"__N_SSG":true}