{"pageProps":{"post":{"title":"ì˜¤í”ˆ ì†ŒìŠ¤ LLMì„ í™œìš©í•œ ìì—°ì–´ë¥¼ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ê¸°","description":"","date":"2024-05-18 18:19","slug":"2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM","content":"\n\n# ì†Œê°œ\n\në°ì´í„° í™œìš©ì˜ ë™ì ì¸ í’ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì™€ ì†ì‰½ê²Œ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ ì´ ìƒí˜¸ ì‘ìš©ì€ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ì–¸ì–´(SQL)ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ê°€ í•„ìš”í•˜ì—¬ ë§ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ì§„ì… ì¥ë²½ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìì—°ì–´ ì²˜ë¦¬(NLP)ë¥¼ SQL ì¿¼ë¦¬ ì—”ì§„ì— ì ìš©í•˜ì—¬ ì´ í’ê²½ì´ ë³€í™”ë˜ì—ˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ì‚¬ìš©ìë“¤ì´ ìì—°ì–´ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì†Œí†µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì²¨ë‹¨ ê¸°ìˆ ì€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ SQL ì¿¼ë¦¬ë¡œ ìˆœì¡°ë¡­ê²Œ ë²ˆì—­í•˜ì—¬ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì¡°ì‘í•˜ëŠ” ë°©ì‹ì„ í˜ì‹ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nìì—°ì–´ ì²˜ë¦¬(NLP)ì—ì„œ Mistral 7B ë° Microsoft Phi-3ê³¼ ê°™ì€ ëª¨ë¸ì€ ì£¼ìš” ì—­í• ì„ í•˜ë©° ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì˜ ê²½ê³„ë¥¼ ì¬ì •ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nMistral 7BëŠ” NLP ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ê³¼ ì •ë°€ë„ë¡œ ë†’ì´ í‰ê°€ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜(GQA) ë° ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜(SWA)ê³¼ ê°™ì€ í˜ì‹ ì ì¸ ê¸°ëŠ¥ë“¤ì„ ê°–ì¶˜ Mistral 7BëŠ” ìˆ˜í•™ ë° ì½”ë“œ ìƒì„±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘ê³  ìˆìŠµë‹ˆë‹¤. Code-Llama 7Bì˜ ì½”ë”© ëŠ¥ë ¥ì— ê°€ê¹Œì›Œì§ê³¼ ë™ì‹œì— NLP ë°œì „ì—ì„œì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©° ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ìš°ìˆ˜ì„±ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nPhi-3 ëŠ” ì‘ì€ ì–¸ì–´ ëª¨ë¸(SLMs) ë¶„ì•¼ì—ì„œì˜ Microsoftì˜ ìµœì‹  í˜ì‹ ìœ¼ë¡œ, AIì˜ í’ê²½ì„ ë³€í™”ì‹œí‚¤ëŠ” ëŒ€ë‹¨í•œ ì œí’ˆì…ë‹ˆë‹¤. Phi-3-mini, Phi-3-small ë° Phi-3-mediumìœ¼ë¡œ êµ¬ì„±ëœ ì´ ëª¨ë¸êµ°ì€ ê°„ê²°í•œ êµ¬ì„±ìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ìë‘í•˜ëŠ” Phi-3-miniëŠ” ë” í° ëª¨ë¸ë“¤ê³¼ ê²¬ì¤„ ë§Œí•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©´ì„œë„ ìŠ¤ë§ˆíŠ¸í°ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. Phi-3ì˜ ì„±ê³µ ë’¤ì—ëŠ” ê²¬ê³ í•¨, ì•ˆì „ì„± ë° ëŒ€í™” ëŠ¥ë ¥ì„ ì¤‘ì‹œí•˜ëŠ” ì •êµí•˜ê²Œ ì„ ë³„ëœ í•™ìŠµ ë°ì´í„°ì…‹ì´ ìˆìŠµë‹ˆë‹¤. Phi-3-small ë° Phi-3-mediumì€ Phi-3ì˜ ëŠ¥ë ¥ì„ ë”ìš± í™•ì¥í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì— ëŒ€ì‘í•©ë‹ˆë‹¤. ì •êµí•˜ê²Œ ì„¤ê³„ëœ ì•„í‚¤í…ì²˜ì™€ í•™ìŠµ ë°©ë²•ì„ í†µí•´ Phi-3ì€ AI ê¸°ìˆ ì˜ í° ë°œì „ì„ ìƒì§•í•˜ë©°, ë‹¤ì–‘í•œ ìƒì„±í˜• AI ì‘ì—…ì— ëŒ€í•œ ìš°ìˆ˜í•œ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ì•½ì†í•©ë‹ˆë‹¤.\n\nNLPì™€ SQLì˜ êµì°¨ì ì„ íƒìƒ‰í•˜ì—¬ Mistral 7Bì™€ Microsoft Phi-3ì˜ í™œìš©ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ì¿¼ë¦¬ë¡œ ì›í™œí•˜ê²Œ ë³€í™˜í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‘ì—…ì—ì„œ í–¥ìƒëœ íš¨ìœ¨ì„±ê³¼ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\n![](/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png)\n\n# í•™ìŠµ ëª©í‘œ\n\n<div class=\"content-ad\"></div>\n\nì´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ Mistral 7B ëª¨ë¸ì„ NL2SQL ì‘ì—…ì— í™œìš©í•˜ëŠ” ë³µì¡ì„±ì„ íƒìƒ‰í•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ NL2SQL ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•´ ëª¨ë¸ì„ ë§ì¶¤í™”í•˜ê³  í›ˆë ¨í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë…¼ì˜í•  ê²ƒì…ë‹ˆë‹¤. ê¸°ì‚¬ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤.\n\n# ë™ê¸°ë¶€ì—¬\n\nì˜¤í”ˆ ì†ŒìŠ¤ LLMsë¥¼ í™œìš©í•˜ë©´ ìì—°ì–´ ëª…ë ¹ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í˜ì‹ ì ì¸ ê¸°ìˆ ì€ ì‚¬ìš©ìê°€ ìˆ˜ë™ ì¿¼ë¦¬ ì‘ì„± ì—†ì´ ë°ì´í„° ìš”êµ¬ ì‚¬í•­ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•˜ë„ë¡ ìë™í™”í•˜ë©°, ì´ë¡œì¨ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ê³  ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ì •í™•í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ í™œìš©ë©ë‹ˆë‹¤. ì´ëŠ” ë³€í™˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”ì‹œí‚¤ê³  ê´‘ë²”ìœ„í•œ ì‚¬ìš©ìë“¤ì—ê²Œ ê´‘ë²”ìœ„í•œ SQL ì§€ì‹ì´ ì—†ì–´ë„ ë°ì´í„°ë¥¼ ì´ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” í¸ë¦¬í•¨ì„ ì œê³µí•˜ë©° ë°ì´í„° ì ‘ê·¼ì„±ê³¼ ìš´ì˜ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. SQL ì „ë¬¸ ì§€ì‹ì˜ ì¥ë²½ì„ ì œê±°í•¨ìœ¼ë¡œì¨ ì´ ê¸°ìˆ ì€ ë°ì´í„° ì ‘ê·¼ì„±ì„ ë¯¼ì£¼í™”ì‹œí‚¤ê³  ê° ë¶„ì•¼ì˜ ì‚¬ìš©ìë“¤ì´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  í†µì°°ì„ ì–»ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì‹¤ì‹œê°„ í†µì°°ì„ ì°¾ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ë‚˜ ë°ì´í„° ì§‘í•©ì„ íƒìƒ‰í•˜ëŠ” ì¼ë°˜ ì‚¬ìš©ìë¥¼ ìœ„í•œ ê²ƒì´ë“ , ìì—°ì–´ ëª…ë ¹ì˜ ì§ê´€ì ì¸ ì„±ê²©ì€ ë°ì´í„° ê²€ìƒ‰ì„ ê°„ë‹¨í•˜ê²Œ í•©ë‹ˆë‹¤.\n\në˜í•œ ì´ëŸ¬í•œ ëª¨ë¸ì—ì„œ ë‚´ì¬ëœ ìë™í™”ëŠ” ì¿¼ë¦¬ ì‹¤í–‰ì„ ê°€ì†í™”í•˜ì—¬ ì „ë°˜ì ì¸ íš¨ìœ¨ì„±ê³¼ ìƒì‚°ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì˜¤í”ˆ ì†ŒìŠ¤ LLMsì˜ ì˜í–¥ë ¥ì€ ê´‘ë²”ìœ„í•˜ë©° ë‹¤ì–‘í•œ ì‚°ì—… ì „ë°˜ì— í˜ì‹ ê³¼ ë³€í™”ë¥¼ ê²©ë ¤í•©ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ì¬ë¬´, ê±´ê°• ê´€ë¦¬ ë° ì „ì ìƒê±°ë˜ ë¶„ì•¼ì™€ ê°™ì´ ë°ì´í„° ì£¼ë„ì  ì˜ì‚¬ ê²°ì •ì´ ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ ì´í•´ê¶Œìë¥¼ ë•ìŠµë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ê³ ê¸‰ ë¶„ì„ í”Œë«í¼ê³¼ ì¸ê³µ ì§€ëŠ¥ ì‹œìŠ¤í…œê³¼ì˜ í†µí•©ì„ í†µí•´ ì¡°ì§ì„ ë°ì´í„° ì£¼ë„ì  ìš°ìˆ˜ì„±ìœ¼ë¡œ ì´ë•ë‹ˆë‹¤. íƒêµ¬ ë¬¸í™”ë¥¼ ìœ¡ì„±í•˜ê³  ë°ì´í„° ìƒí˜¸ì‘ìš©ì„ ê°„ì†Œí™”í•¨ìœ¼ë¡œì¨ ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” ë°ì´í„° ìì‚°ì˜ ëª¨ë“  ì ì¬ë ¥ì„ ë°œíœ˜í•¨ìœ¼ë¡œì¨ ì‚°ì—… ì „ë°˜ì— í˜ì‹ ê³¼ ì„±ì¥ì„ ì´‰ì§„í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n# 1. NL2SQLì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ (Mistral 7B)\n\nMistral AIê°€ ê°œë°œí•œ 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì–¸ì–´ ëª¨ë¸ì¸ Mistral 7BëŠ” ì¸ê³µ ì§€ëŠ¥ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤.\n\n- ê¸°ë³¸ ëª¨ë¸ë¡œ ìœ„ì¹˜ ì§€ì •ëœ Mistral 7BëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ êµ¬ì¡°ì  ëª¨ë¸ë¡œ ìë¦¬ ì¡ì•˜ìœ¼ë©° ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ í™˜ê²½ ë‚´ì—ì„œ í•„ìˆ˜ì ì¸ ì½”ì–´ ë¹Œë”© ë¸”ë¡ì˜ ì¤‘ìš”ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n- ê±´ì¶•ì  ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ì°¨ë³„í™”ëœ Mistral 7BëŠ” ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•´ ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜ (GQA)ê³¼ ê¸´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜ (SWA)ê³¼ ê°™ì€ í˜ì‹ ì ì¸ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.\n- ì£¼ë¡œ ì˜ì–´ì— ì´ˆì ì„ ë§ì¶”ì§€ë§Œ ì½”ë”© ëŠ¥ë ¥ë„ ê°–ì¶˜ Mistral 7BëŠ” íŠ¹íˆ ë‹¤ë¥¸ ëª¨ë¸ë“¤ë³´ë‹¤ ë” ë„“ì€ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆëŠ” ë†’ì€ ë¬¸ë§¥ ìœˆë„ìš°ë¥¼ ê°€ì§€ê³  ìˆì–´ ë‘ê°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n- 73ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¡œ ì¸ìƒì ì¸ Mistral 7BëŠ” ìµœì‹  ì–¸ì–´ ëª¨ë¸ì„ ëŒ€í‘œí•˜ëŠ”ë°, Apache 2.0 ë¼ì´ì„¼ìŠ¤ í•˜ì— ì œí•œ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n- Mistral 7BëŠ” ëª¨ë“  í‰ê°€ëœ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœê³ ì˜ ì˜¤í”ˆ 13B ëª¨ë¸ (Llama-2)ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘ë©° ìµœê³ ì˜ 34B ëª¨ë¸ (Llama-1)ë³´ë‹¤ ì¶”ë¡ í‰ê°€, ìˆ˜í•™ ë° ì½”ë“œ ìƒì„±ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n- Mistral-7BëŠ” Llama2-13Bë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©° CodeLlama-7Bì™€ ê²½ìŸë ¥ ìˆëŠ” ì„±ê³¼ë¥¼ ë³´ì´ë©° íŠ¹íˆ ì¶”ë¡ , ìˆ˜í•™ ë° ì½”ë“œ ìƒì„± ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚©ë‹ˆë‹¤.\n- ë” í° ëª¨ë¸ë“¤ì— ë¹„í•´ í¬ê¸°ëŠ” ì‘ì§€ë§Œ, Mistral 7BëŠ” í…ìŠ¤íŠ¸ ìš”ì•½, ë¶„ë¥˜, í…ìŠ¤íŠ¸ ì™„ì„± ë° ì½”ë“œ ì™„ì„±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ìì—°ì–´ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘¡ë‹ˆë‹¤.\n- ì´ ëª¨ë¸ì´ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ëª…ë ¹ì–´ë¡œ ë³€í™˜í•˜ëŠ” íš¨ê³¼ë¥¼ íƒìƒ‰í•˜ì—¬ ëŠ¥ë ¥ì„ ìì„¸íˆ ì‚´í´ë´…ì‹œë‹¤.\n\n## Sliding Window Attention\n\n<div class=\"content-ad\"></div>\n\n- Mistral 7Bì€ ì „í†µì ì¸ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ë°œìƒí•˜ëŠ” ë„ì „ì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì²˜í•  ìˆ˜ ìˆëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜(Sliding Window Attention, SWA) ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ìëŠ” í† í° ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì¶”ë¡  ì¤‘ ì§€ì—° ì‹œê°„ì´ ì¦ê°€í•˜ê³  ì²˜ë¦¬ëŸ‰ì´ ê°ì†Œí•  ìˆ˜ ìˆìœ¼ë©°, ì‹œí€€ìŠ¤ ê¸¸ì´ì™€ ë©”ëª¨ë¦¬ì™€ ê´€ë ¨ëœ ì—°ì‚°ì´ ì´ì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ë©”ëª¨ë¦¬ê°€ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ì— SWAëŠ” ê° í† í°ì˜ ì£¼ì˜ë¥¼ ì´ì „ ë ˆì´ì–´ì˜ Wê°œ í† í°ì„ ìµœëŒ€í•œìœ¼ë¡œ ì œí•œí•˜ì—¬ ì£¼ì–´ì§„ ìœˆë„ìš° í¬ê¸° Wë¥¼ ë„˜ì–´ì„œ ì£¼ì˜ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.\n- SWAëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ìœ„ì¹˜ iì˜ ìˆ¨ê²¨ì§„ ìƒíƒœê°€ ì…ë ¥ ë ˆì´ì–´ì˜ í† í°ì„ W x k í† í°ê¹Œì§€ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ìµœì¢… ë ˆì´ì–´ì—ì„œ W = 4096ì˜ ìœˆë„ìš° í¬ê¸°ë¡œ, SWAëŠ” ì´ë¡ ì ìœ¼ë¡œ ëŒ€ëµ 131K í† í°ì˜ ì£¼ì˜ ë²”ìœ„ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œì ìœ¼ë¡œ W = 4096 ë° FlashAttentionê³¼ xFormersì˜ ìµœì í™” ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬, 16K í† í° ì‹œí€€ìŠ¤ì˜ ê²½ìš° ë°”ë‹ë¼ ì£¼ì˜ ê¸°ì¤€ì— ë¹„í•´ ì£¼ëª©í• ë§Œí•œ 2ë°°ì˜ ì†ë„ í–¥ìƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, SWAëŠ” ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ì„±ëŠ¥ì„ í˜ì‹ ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°•ë ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.\n\n### b. ë¡¤ë§ ë²„í¼ ìºì‹œ\n\n- ë¡¤ë§ ë²„í¼ ìºì‹œë¥¼ êµ¬í˜„í•¨ìœ¼ë¡œì¨, Mistral 7BëŠ” ê³ ì •ëœ ì£¼ì˜ ë²”ìœ„ë¥¼ ì „ëµì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìºì‹œ í¬ê¸°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤. ì´ ìºì‹œëŠ” Wë¡œ í‘œì‹œëœ ê³ ì •ëœ í¬ê¸°ë¡œ, ìºì‹œ ë‚´ì—ì„œ íŠ¹ì • ì‹œê°„ ë‹¨ê³„ iì—ì„œ ì‹œê°„ ë‹¨ê³„ i mod Wì— í‚¤ì™€ ê°’ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ì‹œí€€ìŠ¤ê°€ ì§„í–‰ë˜ê³  iê°€ Wë¥¼ ì´ˆê³¼í•  ë•Œ, ìºì‹œëŠ” ë¡¤ë§ ë²„í¼ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ ê°’ë“¤ì„ ë®ì–´ì“°ê³  ë¬´í•œì •ìœ¼ë¡œ í™•ì¥ë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. W = 3ìœ¼ë¡œ ì„¤ëª…ëœ ì´ ì ‘ê·¼ ë°©ì‹ì€ 32k í† í° ì‹œí€€ìŠ¤ì— ëŒ€í•´ 8ë°°ì˜ ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œë¥¼ ì‹¤í˜„í•¨ìœ¼ë¡œì¨, ëª¨ë¸ì˜ í’ˆì§ˆì„ í¬ìƒí•˜ì§€ ì•Šê³  ë‹¬ì„±í•©ë‹ˆë‹¤. ê³ ì •ëœ ì£¼ì˜ ë²”ìœ„ëŠ” íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì´ìš©ì„ ë³´ì¥í•  ë¿ë§Œ ì•„ë‹ˆë¼ Mistral 7Bê°€ ê¸¸ì´ê°€ ë‹¤ë¥¸ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ì— ì›í™œí•˜ê²Œ ê¸°ëŠ¥í•˜ëŠ” ë°ì— ê¸°ì—¬í•©ë‹ˆë‹¤.\n\n### c. ì‚¬ì „ ì±„ì›€ ë° ì²­í¬ ë¶„í• \n\n<div class=\"content-ad\"></div>\n\n- ì‹œí€€ìŠ¤ ìƒì„± ê³¼ì •ì—ì„œëŠ” ë¬¸ë§¥ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ”ë°, (k, v) ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤. ì•Œë ¤ì§„ í”„ë¡¬í”„íŠ¸ë¡œ ë¯¸ë¦¬ ì±„ì›Œì§„ ìºì‹œë¥¼ í™œìš©í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤. ê¸´ í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì§€ì •ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ê³ , ê° ì²­í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìºì‹œë¥¼ ë¯¸ë¦¬ ì±„ì›ë‹ˆë‹¤. ì´ ì „ëµì  ì ‘ê·¼ ë°©ì‹ì€ ì‹œí€€ìŠ¤ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì¤‘ ìºì‹œ ë‚´ë¶€ ë° í˜„ì¬ ì²­í¬ ì „ì²´ì—ì„œ ì£¼ì˜ë ¥ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì„ í™œìš©í•¨ìœ¼ë¡œì¨ Mistral 7BëŠ” ì‹œí€€ìŠ¤ ìƒì„±ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ë©°, ìºì‹œì— ì €ì¥ëœ ë¯¸ë¦¬ ì•Œë ¤ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ê° ì˜ˆì¸¡ëœ í† í°ì„ ì´ì „ í† í°ê³¼ ì¡°í™”ë¡­ê²Œ ì •ë ¬í•©ë‹ˆë‹¤.\n- ì–¸ì–´ ëª¨ë¸ì˜ ë™ì ì¸ í™˜ê²½ì—ì„œ Mistral 7Bì˜ ë“±ì¥ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ë©´ì—ì„œ í° ë„ì•½ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í¬ê´„ì ì¸ í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ Mistral 7BëŠ” ìì‹ ì˜ ëŠ¥ë ¥ì„ ì…ì¦í•˜ë©°, ì´ì „ ì œí’ˆì¸ Llama 2 7B ë° Llama 2 13Bë¿ë§Œ ì•„ë‹ˆë¼ Llama 1 34Bì™€ ê°™ì€ í•µì‹¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ ë›°ì–´ë‚œ ê²½ìŸë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n- Mistral 7Bì˜ ìš°ì›”ì„±ì€ ëª¨ë“  ì¸¡ì • í•­ëª©ì— ê±¸ì³ ëª…ë°±íˆ ë“œëŸ¬ë‚˜ë©°, í•´ë‹¹ ë¶„ì•¼ì˜ ì„ ë„ì£¼ìë¡œì„œì˜ ì§€ìœ„ë¥¼ ì¬í™•ì¸í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ë©´ë°€í•œ ì¬í‰ê°€ ê³¼ì •ì€ Mistral 7Bì˜ íƒì›”í•œ ëŠ¥ë ¥ì„ ì¼ê´€ë˜ê²Œ ì…ì¦í•˜ë©°, ê²½ìŸì‚¬ë¥¼ ë’¤ë¡œ ë‚¨ê¹ë‹ˆë‹¤.\n\n## í¬ê¸° ë° íš¨ìœ¨ì„± ë¶„ì„\n\n- Mistral 7Bì˜ ë§¤ë ¥ ì¤‘ìš” ìš”ì†Œ ì¤‘ í•˜ë‚˜ëŠ” í˜ì‹ ì ì¸ \"ë™ë“±í•œ ëª¨ë¸ í¬ê¸°\" ê³„ì‚° ë°©ì‹ì„ í†µí•œ íš¨ìœ¨ì„±ì…ë‹ˆë‹¤. ì¶”ë¡ , ì´í•´ ë° STEM ì¶”ë¡  ë“±ì—ì„œ í‰ê°€í•œ ê²°ê³¼, Mistral 7BëŠ” ì„¸ ë°° ì´ìƒ í¬ê¸°ì˜ Llama 2 ëª¨ë¸ê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ íš¨ìœ¨ì„±ì€ ê³¼ë„í•œ ë§¤ê°œë³€ìˆ˜ ë¶€ë‹´ ì—†ì´ ë›°ì–´ë‚œ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ” Mistral 7Bì˜ ëŠ¥ë ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.\n- Mistral 7Bì˜ íš¨ìœ¨ì„±ì„ ë” ìì„¸íˆ ì‚´í´ë³´ë©´, í‰ê°€ ê²°ê³¼ì—ì„œ ì§€ì‹ ì••ì¶•ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ í†µì°°ë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ì‹ ë²¤ì¹˜ë§ˆí¬ì—ì„œ 1.9ë°° ë‚®ì€ ì••ì¶•ë¥ ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ì´ëŠ” Mistral 7Bì˜ ì˜ë„ì ìœ¼ë¡œ ì œí•œëœ ë§¤ê°œë³€ìˆ˜ ìˆ˜ì— ê¸°ì¸í•©ë‹ˆë‹¤. ì´ ì œí•œì€ ì €ì¥ëœ ì§€ì‹ ì–‘ì„ ì œí•œí•˜ì§€ë§Œ, Mistral 7BëŠ” ì§‘ì¤‘í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ë§¤ê°œë³€ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë³´ìƒí•©ë‹ˆë‹¤.\n\n# í‰ê°€ì˜ ì°¨ì´ì \n\n<div class=\"content-ad\"></div>\n\në¶ˆì¼ì¹˜ ì‚¬í•­ì„ íˆ¬ëª…í•˜ê²Œ ë‹¤ë£¨ë©´ì„œ, í‰ê°€ ê·œì •ì˜ ë³€í™”ë¥¼ ìœ ì˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–¤ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” Llama 2ì˜ MBPPì™€ Mistral 7Bì˜ í‰ê°€ ê²°ê³¼ ì‚¬ì´ì— ì°¨ì´ê°€ ë°œìƒí•©ë‹ˆë‹¤. TriviaQAì—ì„œ ì†ìœ¼ë¡œ ê²€ì¦ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ Mistral 7Bì˜ ì„±ëŠ¥ ì§€í‘œì˜ ì‹ ë¢°ì„±ì— ê¸°ì—¬í•˜ëŠ” ê°•ê±´í•œ í‰ê°€ ê³¼ì •ì„ í™•ì¸í•˜ê²Œ ë©ë‹ˆë‹¤.\n\n# ë°ì´í„°ì…‹\n\nì•„ë˜ ì—´ë¡œ êµ¬ì„±ëœ êµ¬ì¡° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ê³„íšì…ë‹ˆë‹¤. ë‹¤ìŒ í…Œì´ë¸”ì—ì„œ ë‹¤ì–‘í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤.\n\n```js\ntransaction = [\n        \"transaction_id\",\n        \"transaction_amount\",\n        \"transaction_date\",\n        \"transaction_type\",\n        \"transaction_status\",\n        \"transaction_description\",\n        \"transaction_source_account\",\n        \"transaction_destination_account\",\n        \"transaction_currency\",\n        \"transaction_fee\"\n    ]\n```\n\n<div class=\"content-ad\"></div>\n\n# ì½”ë“œ êµ¬í˜„\n\n- íŒ¨í‚¤ì§€ ì„¤ì¹˜í•˜ê¸°\n\n```js\n!pip install git+https://github.com/huggingface/transformers.git \n!pip install deepspeed --upgrade\n!pip install accelerate\n!pip install sentencepiece\n!pip install langchain\n!pip install torch\n!pip install bitsandbytes\n``` \n\n2. íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n\n<div class=\"content-ad\"></div>\n\n```js\nimport os\nimport re\nimport torch\nfrom difflib import SequenceMatcher\nfrom langchain.chains import LLMChain\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n```\n\n3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n\n```js\nbase_model = LlamaForCausalLM.from_pretrained(\n     \"mistralai/Mistral-7B-Instruct-v0.1\",\n     load_in_8bit=True,\n     device_map='auto',\n    )\ntokenizer = LlamaTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\npipe = pipeline(\n        \"text-generation\",\n        model=base_model,\n        tokenizer=tokenizer,\n        max_length=500,\n        temperature=0.3,\n        top_p=0.95,\n        repetition_penalty=1.2\n    )\nlocal_llm = HuggingFacePipeline(pipeline=pipe)\n```\n\n4. SequenceMatcher\n\n\n<div class=\"content-ad\"></div>\n\nì´ Python í•¨ìˆ˜ëŠ” difflib ëª¨ë“ˆì˜ SequenceMatcher í´ë˜ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ì™€ ì§€ì •ëœ ì‚¬ì „ì˜ ì—´ ì´ë¦„ ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì¿¼ë¦¬ ì´í•´ë ¥ê³¼ ëŒ€ì²´ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n\n```js\ndef find_columns_match(question, input_dict):\ntry:\n  question_list = re.split(r'\\s|,|\\.', question)\n  for index, string2 in enumerate(question_list):\n    for string1 in input_dict.get('table1_columns'):\n      score = SequenceMatcher(None,string1.lower(), string2.lower()).ratio()*100\n      if score > 91:\n        question_list[index] = string1 + \",\"\n  return \" \".join(question_list)\n  \nexcept:\n return question\n```\n\nì´ Python í•¨ìˆ˜ query_generatorì€ ì œê³µëœ í…Œì´ë¸”ëª…, ì—´ ëª©ë¡ ë° ì§ˆë¬¸ì— ê¸°ë°˜í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” í…œí”Œë¦¿ ë¬¸ìì—´ì„ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬ì¡°í™”í•˜ë©°, í…Œì´ë¸” ëª…, ì—´ ëª©ë¡ ë° ì§ˆë¬¸ì— ëŒ€í•œ ìë¦¬ í‘œì‹œìë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ PromptTemplate ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ìë¦¬ í‘œì‹œìë¥¼ ì±„ì›Œë„£ê³  LLMChainì„ í†µí•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM)ê³¼ ìƒí˜¸ ì‘ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ìƒì„±ëœ SQL ì¿¼ë¦¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n\n```js\ndef query_generator(tble, cols, question):\n\n  template = \"\"\"Generate a SQL query using the following table name: {Table}, and columns as a list: {Columns}, to answer the following question:\n  {question}.\n  \n  Output Query:\n  \n  \"\"\"\n  \n  prompt = PromptTemplate(template=template, input_variables=[\"Table\", \"question\", \"Columns\"])\n  \n  llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n  \n  response = llm_chain.run({\"Table\": tble, \"question\": question, \"Columns\": cols})\n  print(response)\n```\n\n<div class=\"content-ad\"></div>\n\n# í‘œ\n\n\ntransaction = [\n        \"transaction_id\",\n        \"transaction_amount\",\n        \"transaction_date\",\n        \"transaction_type\",\n        \"transaction_status\",\n        \"transaction_description\",\n        \"transaction_source_account\",\n        \"transaction_destination_account\",\n        \"transaction_currency\",\n        \"transaction_fee\"\n    ]\n\n    inputs = [\"transaction_idê°€ 10ì¸ ê²½ìš° transaction_amount, transaction_date, transaction_type,transaction_descriptionì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n             \"transaction_statusê°€ 'completed'ì¸ ê²½ìš° transaction_id, transaction_date, transaction_type, transaction_source_accountì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n             \"transaction_type ë° í‰ê·  transaction_amountì˜ ê°œìˆ˜ë¥¼ ê²€ìƒ‰í•˜ê³  transaction_typeë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n             \"ê° ì†ŒìŠ¤ ê³„ì •ë³„ ì´ ê±°ë˜ ê¸ˆì•¡ ëª©ë¡ì„ ê²€ìƒ‰í•˜ê³  ì´ ê±°ë˜ ê¸ˆì•¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n             \"ê° ê±°ë˜ ìœ í˜•ë³„ ìµœëŒ€ ê±°ë˜ ê¸ˆì•¡ì„ ê²€ìƒ‰í•˜ê³  ê±°ë˜ ìœ í˜•ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\"]\n\n    for input in inputs:\n        query_generator(\"transaction\",transaction ,question=find_columns_match(input,transaction))\n\n\n# ì‘ë‹µ\n\n- ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì„ ì‚¬ìš©í•˜ê³  ì»¬ëŸ¼ì„ ë‚˜ì—´í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™], ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ ìœ„í•´ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: (â€˜transaction_idê°€ 10ì¸ ê²½ìš° transaction_amount, transaction_date, transaction_type,transaction_descriptionì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±â€™).\n\n<div class=\"content-ad\"></div>\n\n```js\nì¶œë ¥ ì¿¼ë¦¬: \n\n  SELECT transaction_amount, transaction_date, transaction_type, transaction_description FROM transaction WHERE transaction_id = 10;\n```\n\n2. ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì¸ transactionê³¼ ì—´ ëª©ë¡ì¸ [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™]ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤:\n(â€˜transaction_statusê°€ â€˜completedâ€™ì¸ ê²½ìš° transaction_id, transaction_date, transaction_type, transaction_source_accountë¥¼ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤â€™).\n\n```js\nì¶œë ¥ ì¿¼ë¦¬:\n  SELECT transaction_id, transaction_date, transaction_type, transaction_source_account FROM transaction WHERE transaction_status = 'completed'\n```\n\n3. ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì¸ transactionê³¼ ì—´ ëª©ë¡ì¸ [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™]ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤:\n(â€˜transaction_typeì˜ countì™€ í‰ê·  transaction_amountë¥¼ ê°€ì ¸ì˜¤ê³  transaction_typeìœ¼ë¡œ ì •ë ¬í•˜ì‹­ì‹œì˜¤â€™).\n\n<div class=\"content-ad\"></div>\n\n```js\nê²°ê³¼ ì¿¼ë¦¬:\n\n  SELECT transaction_type, AVG(transaction_amount) AS avg_transaction_amount, COUNT(*) AS total_count\n  FROM transaction\n  GROUP BY transaction_type\n  ORDER BY transaction_type;\n```\n\n4. ë‹¤ìŒ í…Œì´ë¸” ì´ë¦„ê³¼ ì—´ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° ì—´: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤:\n(â€˜ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ì†ŒìŠ¤ ê³„ì •ì˜ ì´ ê±°ë˜ ê¸ˆì•¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¡°íšŒí•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”â€™).\n\n```js\nê²°ê³¼ ì¿¼ë¦¬:\n\n       SELECT transaction_source_account, SUM(transaction_amount) AS TotalTransactionAmount\n        FROM transaction\n        GROUP BY transaction_source_account\n        ORDER BY TotalTransactionAmount DESC;\n```\n\n5. ë‹¤ìŒ í…Œì´ë¸” ì´ë¦„ê³¼ ì—´ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° ì—´: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤:\n(â€˜ê° ê±°ë˜ ìœ í˜•ì˜ ìµœëŒ€ ê±°ë˜ ê¸ˆì•¡ì„ ì°¾ì•„ ê±°ë˜ ìœ í˜•ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”â€™).\n\n<div class=\"content-ad\"></div>\n\n```js\nì¶œë ¥ ì¿¼ë¦¬:\n\n   SELECT transaction_type, MAX(transaction_amount) AS max_transaction_amount\n   FROM transaction\n   GROUP BY transaction_type\n   ORDER BY transaction_type;\n```\n\nì¼ë°˜ì ì¸ ì¶”ì¶œì€ íš¨ê³¼ì ì´ì§€ë§Œ, ì—°êµ¬ ê²°ê³¼, ë°ì´í„°ë¥¼ ì„¸ë¶€ ì¡°ì •í•˜ì—¬ LLMì„ ìˆ˜í–‰í•˜ë©´ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¸ë°€ ì¡°ì • ì ‘ê·¼ë²•ì„ ì±„ìš©í•´ ë´…ì‹œë‹¤.\n\n# 2 Fine-tune NL2SQL with Phi-3\n\nPhi-3ë¥¼ ë§Œë‚˜ë³´ì„¸ìš”, Microsoftì˜ ìµœì‹  ì˜¤í”ˆ AI ëª¨ë¸ì˜ ì£¼ìš” ì„±ê³¼ì…ë‹ˆë‹¤. Phi-3-mini, Phi-3-small ë° Phi-3-mediumì„ í†µí•´, ì´ ì‘ì€ ì–¸ì–´ ëª¨ë¸ (SLM)ì˜ Phi-3 íŒ¨ë°€ë¦¬ëŠ” AI ëª¨ë¸ì˜ ì„¸ê³„ë¥¼ í˜ì‹ í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ê³  33ì¡° ê°œì˜ í† í°ìœ¼ë¡œ í›ˆë ¨ëœ Phi-3-miniëŠ” ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©° Mixtral 8x7B ë° GPT-3.5ì™€ ê°™ì€ í° ëª¨ë¸ê³¼ ê°™ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê²Œë‹¤ê°€, ì´ ëª¨ë¸ì€ ìŠ¤ë§ˆíŠ¸í° ì¥ì¹˜ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Phi-3ì˜ ì„±ê³µì€ í›ˆë ¨ ë°ì´í„°ì…‹ì— ê¸°ì¸í•©ë‹ˆë‹¤. Phi-2ì˜ ë°ì´í„°ì…‹ì˜ ì§„í™”ëœ ë²„ì „ì…ë‹ˆë‹¤. ìƒì„¸íˆ ê±¸ëŸ¬ë‚¸ ì›¹ ë°ì´í„° ë° í•©ì„± ì…ë ¥ì„ í†µí•´ ì´ëŸ¬í•œ ëª¨ë¸ì€ ê°•ë„, ì•ˆì „ ë° ëŒ€í™” ëŠ¥ë ¥ì— ìš°ì„ ìˆœìœ„ë¥¼ ë‘ì–´ ë‹¤ì–‘í•œ ì‘ìš©í”„ë¡œê·¸ë¨ì— ì í•©í•©ë‹ˆë‹¤. 7B ë° 14B íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ Phi-3-small ë° Phi-3-mediumì€ íš¨ìœ¨ ìœ ì§€ì™€ í•¨ê»˜ Phi-3ì˜ ê¸°ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n\n<div class=\"content-ad\"></div>\n\n## Phi 3 Architecture and Evaluation\n\nPhi-3 íŒ¨ë°€ë¦¬ëŠ” í’ˆì§ˆê³¼ ë¹„ìš©ì„ ê· í˜•ìˆê²Œ ìœ ì§€í•˜ë„ë¡ ì„¤ê³„ëœ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì œê³µí•˜ì—¬ ìƒì„±í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ëŠ” ê³ ê°ì„ ìœ„í•œ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nPhi-3-mini: ì´ ëª¨ë¸ì€ 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ì¶”ê³  33ì¡° ê°œì˜ í† í°ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê´‘ë²”ìœ„í•œ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. 32ê°œì˜ ë ˆì´ì–´, 32ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  3072ê°œì˜ íˆë“  ë””ë©˜ì…˜ì„ ê°–ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì±„íƒí–ˆìŠµë‹ˆë‹¤. ë””í´íŠ¸ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ëŠ” 4ì²œ ê°œì˜ í† í°ì´ë©°, 32K ì–´íœ˜ ì‚¬ì „ì„ ì‚¬ìš©í•˜ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì¶”ê°€ë¡œ, 128K í† í°ì˜ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°–ì¶˜ í™•ì¥ ë²„ì „ì¸ Phi-3-mini-128Kë„ ìˆìŠµë‹ˆë‹¤.\n\nPhi-3-small: 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¡œ í›ˆë ¨ëœ Phi-3-smallì€ 48ì¡° ê°œì˜ í† í°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 100K ì–´íœ˜ ì‚¬ì „ê³¼ 8ì²œ ê°œì˜ ë””í´íŠ¸ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. ì•„í‚¤í…ì²˜ëŠ” 32ê°œì˜ ë ˆì´ì–´, 32ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  4096ê°œì˜ íˆë“  ë””ë©˜ì…˜ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜ê³¼ ë²ˆê°ˆì•„ê°€ë©° ì“°ì´ëŠ” ë°€ì§‘/í¬ì†Œ ì–´í…ì…˜ì„ í™œìš©í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nPhi-3-medium: ì´ ë¯¸ë¦¬ë³´ê¸° ëª¨ë¸ì€ 140ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ìë‘í•˜ë©° 4.8ì¡° ê°œì˜ í† í°ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. 40ê°œì˜ ë ˆì´ì–´, 40ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  ì„ë² ë”© í¬ê¸°ëŠ” 5120ì…ë‹ˆë‹¤.\n\n## í›ˆë ¨ ë°©ë²•:\n\n- í›ˆë ¨ ë°ì´í„° êµ¬ì„±: Phi-3 ëª¨ë¸ì˜ í›ˆë ¨ ë°ì´í„°ëŠ” ì‹ ì¤‘í•˜ê²Œ ì„ ë³„ë©ë‹ˆë‹¤. êµìœ¡ ìˆ˜ì¤€ë³„ë¡œ ë¶„ë¥˜ëœ ì›¹ ë°ì´í„°ì™€ í•©ì„± LLM ìƒì„± ë°ì´í„°ë¡œ êµ¬ì„±ë˜ë©° ë‘ ê°€ì§€ ì´ì§ˆì ì´ê³  ìˆœì°¨ì ì¸ ë‹¨ê³„ë¡œ ì‚¬ì „ í›ˆë ¨ì„ ê±°ì¹©ë‹ˆë‹¤.\n- ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„: ì œ1 ë‹¨ê³„ëŠ” ì¼ë°˜ ì§€ì‹ê³¼ ì–¸ì–´ ì´í•´ì— ì¤‘ì ì„ ë‘” ì›¹ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì œ2 ë‹¨ê³„ëŠ” ë…¼ë¦¬ ì¶”ë¡  ë° íŠ¹ì • ê¸°ìˆ ì„ ê°€ë¥´ì¹˜ê¸° ìœ„í•´ ì œ1 ë‹¨ê³„ì˜ ì›¹ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„°ë¥¼ ë” ë§ì´ í™œìš©í•©ë‹ˆë‹¤.\n- ì‚¬í›„ í›ˆë ¨ ë‹¨ê³„: ì‚¬ì „ í›ˆë ¨ í›„, Phi-3-miniëŠ” ê°ë…í˜• ì„¸ë°€ ì¡°ì • (SFT) ë° ì§ì ‘ ì„ í˜¸ë„ ìµœì í™” (DPO)ë¥¼ ê±°ì³¤ìŠµë‹ˆë‹¤. SFTëŠ” ìˆ˜í•™, ì½”ë”©, ì¶”ë¡ , ëŒ€í™”, ëª¨ë¸ ì‹ ì›, ì•ˆì „ ë„ë©”ì¸ ê°„ì— ë†’ì€ í’ˆì§ˆì˜ ë°ì´í„°ë¥¼ ì„ ë³„í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.\n- DPOëŠ” ì±„íŒ… í˜•ì‹ ë°ì´í„°, ì¶”ë¡ , ê·¸ë¦¬ê³  ì±…ì„ ìˆëŠ” AI ë…¸ë ¥ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.\n- ë§¥ë½ í™•ì¥: Phi-3-miniì˜ ë§¥ë½ ì°½ í¬ê¸°ê°€ Long Rope ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì—¬ 4k í† í°ì—ì„œ 128k í† í°ìœ¼ë¡œ í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í™•ì¥ì€ ë§¥ë½ì˜ ê¸¸ì´ê°€ í¬ê²Œ ì¦ê°€í•¨ì—ë„ ì¼ê´€ëœ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.\n- ë°ì´í„° ìµœì í™”: í›ˆë ¨ ë°ì´í„°ëŠ” ëª¨ë¸ì˜ ê·œëª¨ë¥¼ ìœ„í•œ \"ë°ì´í„° ìµœì \" ì§€ì ìœ¼ë¡œ ë³´ì •ë©ë‹ˆë‹¤. ì›¹ ë°ì´í„°ëŠ” ì§€ì‹ê³¼ ì¶”ë¡ ì˜ ì ì ˆí•œ ê· í˜•ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í•„í„°ë§ë©ë‹ˆë‹¤. íŠ¹íˆ ì‘ì€ ëª¨ë¸ì˜ ê²½ìš° ì´ëŠ” ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\n- ë‹¤ë¥¸ ëª¨ë¸ê³¼ì˜ ë¹„êµ: Phi-3ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì´ì „ ì‘ì—…ê³¼ ëŒ€ì¡°ì ìœ¼ë¡œ, í•´ë‹¹ ê·œëª¨ì— ëŒ€í•œ ë°ì´í„° í’ˆì§ˆì— ì¤‘ì ì„ ë‘ë©° ì»´í“¨íŒ…ì´ë‚˜ ê³¼ë„í•œ í›ˆë ¨ ë°©ë²•ë³´ë‹¤ ë°ì´í„° ìµœì í™”ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë¹„êµëŠ” Phi-3ê°€ ì‘ì€ ëª¨ë¸ ìš©ëŸ‰ì„ ìœ„í•œ ìµœì í™”ë¥¼ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.\n- Phi-3-medium ë¯¸ë¦¬ë³´ê¸°: 140ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ Phi-3-mediumì€ Phi-3-miniì™€ ìœ ì‚¬í•˜ê²Œ í›ˆë ¨ë˜ì—ˆì§€ë§Œ ë” í° ê·œëª¨ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì¼ë¶€ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” 7Bì—ì„œ 14B ë§¤ê°œë³€ìˆ˜ë¡œì˜ ì „í™˜ì—ì„œ í° ê°œì„ ì´ ì—†ì–´ ê³„ì†í•´ì„œ ë°ì´í„° í˜¼í•©ì„ ê°œì„  ì¤‘ì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n- ì‚¬í›„ í–¥ìƒ: ëª¨ë¸ì€ ì±„íŒ… ëŠ¥ë ¥, ê²¬ê³ ì„±, ê·¸ë¦¬ê³  ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê°ë…í˜• ì„¸ë°€ ì¡°ì • ë° DPOë¥¼ í†µí•œ ì„ í˜¸ë„ ì¡°ì •ì„ ê±°ì¹©ë‹ˆë‹¤.\n\n## ì•ˆì „ì„±\n\n<div class=\"content-ad\"></div>\n\nPhi-3-miniì€ Microsoftì˜ ì±…ì„ ìˆëŠ” AI ì›ì¹™ì— ë”°ë¼ ë§Œë“¤ì–´ì§„ AI ëª¨ë¸ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ê°œë°œ ì´ˆê¸°ë¶€í„° ì•ˆì „ì„ ìš°ì„ ì‹œí•˜ëŠ” ì›ì¹™ì„ ì¤‘ìš”ì‹œí•˜ì—¬ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ìœ¤ë¦¬ ê¸°ì¤€ì„ ì¤€ìˆ˜í•˜ê³  ì ì¬ì ì¸ í”¼í•´ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í¬ê´„ì ì¸ ì „ëµì´ ì±„íƒë˜ì—ˆìŠµë‹ˆë‹¤.\n\nëª¨ë¸ í•™ìŠµ í›„ì—ëŠ”, í•´ë‹¹ ëª¨ë¸ì´ ì±…ì„ ìˆëŠ” AI ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë©´ë°€í•œ ì•ˆì „ ì¡°ì •ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ê²Œë‹¤ê°€, Microsoftì˜ ë…ë¦½ëœ ë ˆë“œ íŒ€ì´ Phi-3-minië¥¼ ê²€í† í•˜ì—¬ ê°•í™” ë° ì•ˆì „ í”„ë¡œí† ì½œì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ì‹ë³„í•©ë‹ˆë‹¤.\n\nìë™í™”ëœ í…ŒìŠ¤íŒ…ê³¼ ì ì¬ì ì¸ í”¼í•´ì˜ ë‹¤ì–‘í•œ ë²”ì£¼ì— ëŒ€í•œ í‰ê°€ëŠ” í”„ë¡œì„¸ìŠ¤ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ëŠ” ëª¨ë¸ì˜ ì¶œë ¥ë¬¼ë¡œë¶€í„° ë°œìƒí•˜ëŠ” ëª¨ë“  ìœ„í—˜ì„ ê°ì§€í•˜ê³  í•´ê²°í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤.\n\në” ë‚˜ì•„ê°€, Phi-3-miniëŠ” ì˜ê²¬ ë°ì´í„° ì„¸íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì‘ë‹µì„ ë”ìš± ê°œì„ í•©ë‹ˆë‹¤. íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¤‘ í™•ì¸ëœ ì ì¬ì ì¸ í”¼í•´ ë²”ì£¼ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ë‚´ë¶€ì—ì„œ ìƒì„±ëœ ë°ì´í„° ì„¸íŠ¸ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n## ì½”ë“œ êµ¬í˜„\n\n- íŒ¨í‚¤ì§€ ì„¤ì¹˜\n\n```js\n !pip install -q -U bitsandbytes\n !pip install -q -U transformers\n !pip install -q -U xformers\n !pip install -q -U peft\n !pip install -q -U accelerate\n !pip install -q -U datasets\n !pip install -q -U trl\n !pip install -q -U einops\n !pip install -q -U nvidia-ml-py3\n !pip install -q -U huggingface_hub\n```\n\n2. íŒ¨í‚¤ì§€ ê°€ì ¸ì˜¤ê¸°\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling\nfrom pynvml import *\nimport time, torch\nfrom trl import SFTTrainer\nfrom peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\nfrom peft import AutoPeftModelForCausalLM\n```\n\n3. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n\n```python\ndataset = load_dataset(\"b-mc2/sql-create-context\")\ndataset\n```\n\n4. ë°ì´í„°ì…‹ í˜•ì‹í™”\n\n<div class=\"content-ad\"></div>\n\n```js\ndef create_prompt(sample):\n      system_prompt_template = \"\"\"<s>\n            ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n            ### ì§€ì‹œì‚¬í•­: <<user_question>>\n            ### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n            <<database_schema>>\n            ### ì‘ë‹µ:\n            <<user_response>>\n            </s>\n            \"\"\"\n      user_message = sample['question']\n      user_response = sample['answer']\n      database_schema = sample['context']\n      prompt_template = system_prompt_template.replace(\"<<user_question>>\",f\"{user_message}\").replace(\"<<user_response>>\",f\"{user_response}\").replace(\"<<database_schema>>\",f\"{database_schema} \")\n\n      return {\"inputs\":prompt_template}\n\n\ninstruct_tune_dataset = dataset.map(create_prompt)\nprint(instruct_tune_dataset)\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {info.used//1024**2} MB.\")\n```\n\n5. í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n# í† í¬ë‚˜ì´ì € ë¡œë“œ\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n# fp16ë¡œ ëª¨ë¸ ë¡œë“œ\nmodel = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, device_map={\"\": 0})\nprint(print_gpu_utilization())\n```\n\n6. ëª¨ë¸ ì¶”ë¡ \n\n\n<div class=\"content-ad\"></div>\n\n\n# í”„ë¡¬í”„íŠ¸ ì •ì˜\n\n\n```bash\n    prompt = [\n        \"ì½”ì½”ë„› ë°€í¬ë¡œ ë§Œë“  ì¹˜í‚¨ ì¹´ë ˆ ë ˆì‹œí”¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\",\n        \"ë‹¤ìŒ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: 'ë‚˜ëŠ” ë¹µê³¼ ì¹˜ì¦ˆë¥¼ ì¢‹ì•„í•´ìš”!'\",\n        \"ìœ ëª…í•œ 20ëª…ì˜ ì¸ë¬¼ì„ ì¸ìš©í•´ë³´ì„¸ìš”.\",\n        \"ì§€ê¸ˆ ë‹¬ì€ ì–´ë””ì— ìˆë‚˜ìš”?\"\n    ]\n\n    # ë³€ìˆ˜ ì´ˆê¸°í™”\n    duration = 0.0\n    total_length = 0\n\n    # í”„ë¡¬í”„íŠ¸ ë°˜ë³µ\n    for i in range(len(prompt)):\n        # í”„ë¡¬í”„íŠ¸ í† í°í™” ë° GPUë¡œ ì´ë™\n        inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n\n        # ì…ë ¥ í…ì„œ ì¸ë±ìŠ¤ë¥¼ torch.longìœ¼ë¡œ ë³€í™˜\n        inputs = {k: v.to(torch.long) for k, v in inputs.items()}\n\n        # ì‹œì‘ ì‹œê°„\n        start_time = time.time()\n\n        # ìë™ ìºìŠ¤íŒ…ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ìˆ˜í–‰\n        with torch.cuda.amp.autocast(enabled=False):  # ìë™ ìºìŠ¤íŒ… ë¹„í™œì„±í™”\n            output = model.generate(**inputs, max_length=500)\n\n        # ì†Œìš” ì‹œê°„ê³¼ ì´ ê¸¸ì´ ê³„ì‚°\n        duration += float(time.time() - start_time)\n        total_length += len(output)\n\n        # í”„ë¡¬í”„íŠ¸ë‹¹ í† í° ì†ë„ ê³„ì‚°\n        tok_sec_prompt = round(len(output) / float(time.time() - start_time), 3)\n\n        # í”„ë¡¬í”„íŠ¸ë‹¹ í† í° ì†ë„ ì¶œë ¥\n        print(\"í”„ë¡¬í”„íŠ¸ --- %s í† í°/ì´ˆ ---\" % (tok_sec_prompt))\n\n        # ë””ì½”ë“œëœ ì¶œë ¥ ì¶œë ¥\n        print(tokenizer.decode(output[0], skip_special_tokens=True))\n\n    # í‰ê·  í† í° ì†ë„ ê³„ì‚°\n    tok_sec = round(total_length / duration, 3)\n    print(\"í‰ê·  --- %s í† í°/ì´ˆ ---\" % (tok_sec))\n```\n\n9. Fine-tuningë˜ì§€ ì•Šì€ Text to SQL\n\n```bash\n    prompt = [\n        \"\"\"\n        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n        ### ì§€ì‹œì‚¬í•­ :\n        ê° ë„ì‹œì˜ ì—­ ì¤‘ ê°€ì¥ ë†’ì€ ìœ„ë„ë¥¼ ê°€ì§„ ì—­ìˆœìœ¼ë¡œ ëª¨ë“  ë„ì‹œë¥¼ ë‚˜ì—´í•˜ì‹­ì‹œì˜¤.\n        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n        CREATE TABLE station (city VARCHAR, lat INTEGER)\n        ### ì‘ë‹µ:\n        SELECT city, lat FROM station ORDER BY lat DESC;\n        \"\"\",\n        \"\"\"\n        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n        ### ì§€ì‹œì‚¬í•­ :\n        'ê° ì„ ìˆ˜ê°€ 20ì  ì´ìƒ ë° 10ì  ë¯¸ë§Œì„ ê°€ì§€ê³  ìˆìœ¼ë©° ìƒìœ„ 10ìœ„ ì•ˆì— ìˆëŠ” í¬ì§€ì…˜ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\n        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n        CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\n        ### ì‘ë‹µ:\n        SELECT POSITION, Points, Ranking\n        FROM player\n        WHERE Points > 20 AND Points < 10 AND Ranking IN (1,2,3,4,5,6,7,8,9,10)\n        \"\"\",\n        \"\"\"\n        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n        ### ì§€ì‹œì‚¬í•­ :\n        ë…¸ë˜ë¥¼ ê°€ì¥ ë§ì´ ì—°ì£¼í•œ ë°´ë“œ ë§´ë²„ì˜ ì´ë¦„ì„ ì°¾ì•„ë³´ì„¸ìš”.\n        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n        CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)\n        ### ì‘ë‹µ:\n        SELECT b.firstname\n        FROM Band b\n        JOIN Performance p ON b.id = p.bandmate\n        GROUP BY b.firstname\n        ORDER BY COUNT(*) DESC\n        LIMIT 1;\n        \"\"\"\n    ]\n\n    for i in range(len(prompt)):\n      model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n      start_time = time.time()\n      output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n      duration += float(time.time() - start_time)\n      total_length += len(output)\n      tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n      print(\"í”„ë¡¬í”„íŠ¸ --- %s í† í°/ì´ˆ ---\" % (tok_sec_prompt))\n      print(print_gpu_utilization())\n      print(tokenizer.decode(output, skip_special_tokens=False))\n\n    tok_sec = round(total_length/duration,3)\n    print(\"í‰ê·  --- %s í† í°/ì´ˆ ---\" % (tok_sec))\n\n    # Fine-tuning\n\n    base_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n    tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_eos_token=True, use_fast=True, max_length=250)\n    tokenizer.padding_side = 'right'\n    tokenizer.pad_token = tokenizer.eos_token\n\n    compute_dtype = getattr(torch, \"float16\") # Ampere (ë˜ëŠ” ìµœì‹ ) GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° bfloat16ë¡œ ë³€ê²½\n    bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=compute_dtype,\n            bnb_4bit_use_double_quant=True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n              base_model_id, trust_remote_code=True, quantization_config=bnb_config, revision=\"refs/pr/23\", device_map={\"\": 0}, torch_dtype=\"auto\", flash_attn=True, flash_rotary=True, fused_dense=True\n    )\n    print(print_gpu_utilization())\n\n    model = prepare_model_for_kbit_training(model)\n```\n\n10. LoRA ë§¤ê°œë³€ìˆ˜\n\n\n\n<div class=\"content-ad\"></div>\n\n```js\npeft_config = LoraConfig(\n            lora_alpha=16,\n            lora_dropout=0.05,\n            r=16,\n            bias=\"none\",\n            task_type=\"CAUSAL_LM\",\n          target_modules=[\n            'q_proj',\n            'k_proj',\n            'v_proj',\n            'dense',\n            'fc1',\n            'fc2',\n        ])\n```\n\n9. Training Parameters\n\n```js\ntraining_arguments = TrainingArguments(\n            output_dir=\"./phi3-results\",\n            save_strategy=\"epoch\",\n            per_device_train_batch_size=4,\n            gradient_accumulation_steps=12,\n            log_level=\"debug\",\n            save_steps=100,\n            logging_steps=25,\n            learning_rate=1e-4,\n            eval_steps=50,\n            optim='paged_adamw_8bit',\n            fp16=True, #change to bf16 if are using an Ampere GPU\n            num_train_epochs=1,\n            max_steps=400,\n            warmup_steps=100,\n            lr_scheduler_type=\"linear\",\n            seed=42)\n```\n\n10. Data Prepare for the training\n\n<div class=\"content-ad\"></div>\n\n```js\ntrain_dataset = instruct_tune_dataset.map(batched=True, remove_columns=['answer', 'question', 'context'])\ntrain_dataset\n```\n\n11. Fine-Tuned\n\n```js\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset[\"train\"],\n    #eval_dataset=dataset['test'],\n    peft_config=peft_config,\n    dataset_text_field=\"inputs\",\n    max_seq_length=1024,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False\n)\n\ntrainer.train()\n```\n\n12. Test inference with the fine-tuned adapter\n \n\n<div class=\"content-ad\"></div>\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n\ncompute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=True,\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n          base_model_id, trust_remote_code=True, quantization_config=bnb_config, device_map={\"\": 0}\n)\nadapter = \"/content/phi3-results/checkpoint-400\"\nmodel = PeftModel.from_pretrained(model, adapter)\n```\n\n13. ìˆ˜í–‰í•˜ê¸°\n\n```js\ndatabase_schema = 'CREATE TABLE station (city VARCHAR, lat INTEGER)'\nuser_question = \"List all the cities in a decreasing order of each city's stations' highest latitude.\"\n\nprompt_template = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{user_question}\nDatabase Schema:\n{database_schema}\n### Response:\n\"\"\"\n\nquestion = \"'What are the positions with both players having more than 20 points and less than 10 points and are in Top 10 ranking\"\ncontext = \"CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\"\n\nprompt_template1 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\ncontext = '''CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)'''\nquestion = \"Find the first name of the band mate that has performed in most songs.\"\n\nprompt_template2 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\nprompt = []\nprompt.append(prompt_template)\nprompt.append(prompt_template1)\nprompt.append(prompt_template2)\n\nfor i in range(len(prompt)):\n  model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n  start_time = time.time()\n  output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n  duration += float(time.time() - start_time)\n  total_length += len(output)\n  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n  print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n  print(print_gpu_utilization())\n  print(tokenizer.decode(output, skip_special_tokens=False))\n\ntok_sec = round(total_length/duration,3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n14. ëª¨ë¸ ì €ì¥í•˜ê¸°\n\n\n<div class=\"content-ad\"></div>\n\n```js\nimport locale\nimport shutil\nfrom huggingface_hub import notebook_login\nfrom google.colab import drive\n\n# Set the preferred encoding to UTF-8\nlocale.getpreferredencoding = lambda: \"UTF-8\"\n\n# Log in to the notebook\nnotebook_login()\n\n# Push the fine-tuned adapter to the Hugging Face Hub\ntrainer.push_to_hub(commit_message=\"fine-tuned adapter\")\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# Move the trained model to Google Drive\nshutil.move('/content/phi3-results', '/content/drive/MyDrive/PHI-3')\n\n# Load the trained model\ntrained_model = AutoPeftModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/checkpoint-400\",\n                                                         low_cpu_mem_usage=True,\n                                                         return_dict=True,\n                                                         torch_dtype=torch.float16,\n                                                         device_map='auto',)\n\n# Merge and unload the trained model\nlora_merged_model = trained_model.merge_and_unload()\n\n# Save the merged model\nlora_merged_model.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\", safe_serialization=True)\n\n# Save the tokenizer for the merged model\ntokenizer.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\")\n\n# Push the merged model to the Hugging Face Hub\nlora_merged_model.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n\n# Push the tokenizer to the Hugging Face Hub\ntokenizer.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n```\n\n15. Perform Inference on Fine-tuned Model\n\n```js\npeft_config = LoraConfig(\n            lora_alpha=16,\n            lora_dropout=0.05,\n            r=16,\n            bias=\"none\",\n            task_type=\"CAUSAL_LM\",\n    )\n\npeft_model_id = \"username/phi3-results\"\nconfig = peft_config.from_pretrained(peft_model_id)\n\nmodel = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n                                             return_dict=True,\n                                             load_in_4bit=True,\n                                             device_map=\"auto\",\n                                             )\n\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n\nmodel = PeftModel.from_pretrained(model, peft_model_id)\n\nprint(model.get_memory_footprint())\n\nfor i in range(len(prompt)):\n    model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n    start_time = time.time()\n    output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n    duration += float(time.time() - start_time)\n    total_length += len(output)\n    tok_sec_prompt = round(len(output)/float(time.time() - start_time), 3)\n    print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n    print(print_gpu_utilization())\n    print(f\"RESPONSE:\\n {tokenizer.decode(output, skip_special_tokens=False)[len(prompt[i]):].split('</')[0]}\")\n\ntok_sec = round(total_length/duration, 3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n# Conclusion\n\n\n<div class=\"content-ad\"></div>\n\nìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ SQL ì¿¼ë¦¬ ì—”ì§„ì˜ ê²°í•©ì€ ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ê²ƒì„ ë” ì‰½ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ì „ì—ëŠ” SQLì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ê°€ í•„ìš”í–ˆê¸° ë•Œë¬¸ì— ë§ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Mistral 7Bì™€ Microsoft Phi-3ì™€ ê°™ì€ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì´ë¥¼ ë°”ê¿¨ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ì¿¼ë¦¬ë¡œ ì‹ ì†í•˜ê²Œ ë³€í™˜í•˜ì—¬, ë°©ëŒ€í•œ SQL ì „ë¬¸ ì§€ì‹ì´ í•„ìš” ì—†ê²Œ í–ˆìŠµë‹ˆë‹¤.\n\nMistral 7Bì™€ Microsoft Phi-3ëŠ” NLP ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ” íƒì›”í•œ ëª¨ë¸ë“¤ì…ë‹ˆë‹¤. ê·¸ë“¤ì€ Grouped-Query Attentionê³¼ Sliding Window Attentionê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ê°–ì¶”ì–´ ë”ìš± íš¨ìœ¨ì ì…ë‹ˆë‹¤. í¬ê¸°ê°€ ì‘ì€ Microsoft Phi-3ë„ NLP ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì—ì„œ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¸ìš°ë©°, ë³µì¡í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë” í° ëª¨ë¸ë“¤ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.\n\nì˜¤í”ˆ ì†ŒìŠ¤ LLMsë¥¼ ê³ ê¸‰ ë¶„ì„ í”Œë«í¼ê³¼ AI ì‹œìŠ¤í…œì— í†µí•©í•¨ìœ¼ë¡œì¨ ê¸°ì—…ì€ ì†ì‰½ê²Œ í†µì°°ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ê¸ˆìœµ, ê±´ê°• ê´€ë¦¬, ì „ì ìƒê±°ë˜ì™€ ê°™ì€ ì‚°ì—…ë“¤ì´ ë°ì´í„° ê¸°ë°˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë°©ì‹ì„ ë³€í™”ì‹œì¼°ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ ë‹¤ì–‘í•œ ë¶€ë¬¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ìƒë‹¹í•˜ë©° í˜ì‹ ê³¼ ë³€í˜ì„ ì´‰ì§„í–ˆìŠµë‹ˆë‹¤.\n\nNLPì™€ SQLì˜ ìœµí•©ì„ í†µí•´ ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” ë°ì´í„° ì ‘ê·¼ì„ ë¯¼ì£¼í™”ì‹œí‚¤ê³  íš¨ìœ¨ì„±, ìƒì‚°ì„±, ê¸°ì—… ì„±ê³µì„ ì´‰ì§„í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë°ì´í„° ìì‚°ì˜ ìµœëŒ€ ì ì¬ë ¥ì„ ë°œíœ˜í•˜ë„ë¡ í—ˆìš©í•˜ì—¬ ì´í•´ë‹¹ì‚¬ìë“¤ì´ ì‹¤í–‰ ê°€ëŠ¥í•œ í†µì°°ì„ ì¶”ì¶œí•˜ê¸° ì‰¬ì›Œì§€ê³ , ì—¬ëŸ¬ ë¶€ë¬¸ì—ì„œ íƒêµ¬ì™€ í˜ì‹ ì˜ ë¬¸í™”ë¥¼ ìœ¡ì„±í–ˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\në…¸íŠ¸ë¶: phi3\n\nì œ ì´ì „ ğŸ“ ê¸€ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\n\n# ì°¸ê³  ìë£Œ\n\n- https://arxiv.org/pdf/2310.06825.pdf\n- https://artgor.medium.com/paper-review-mistral-7b-6acdf2f3132d\n- https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580\n- https://www.datacamp.com/tutorial/mistral-7b-tutorial\n- https://www.analyticsvidhya.com/blog/2023/11/from-gpt-to-mistral-7b-the-exciting-leap-forward-in-ai-conversations/\n- https://medium.com/@rubentak/mistral-7b-the-best-7-billion-parameter llm-yet-8b0aa03016f9\n- https://clarifai.com/mistralai/completion/models/mistral-7B-Instruc\n- https://iamgeekydude.com/2023/06/02/alpaca-llm-load-model-using-langchain-hf/\n- https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/\n- https://huggingface.co/microsoft/Phi-3-mini-128k-instruct","ogImage":{"url":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"},"coverImage":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png","tag":["Tech"],"readingTime":32},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h1>ì†Œê°œ</h1>\n<p>ë°ì´í„° í™œìš©ì˜ ë™ì ì¸ í’ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì™€ ì†ì‰½ê²Œ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ ì´ ìƒí˜¸ ì‘ìš©ì€ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ì–¸ì–´(SQL)ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ê°€ í•„ìš”í•˜ì—¬ ë§ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ì§„ì… ì¥ë²½ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìì—°ì–´ ì²˜ë¦¬(NLP)ë¥¼ SQL ì¿¼ë¦¬ ì—”ì§„ì— ì ìš©í•˜ì—¬ ì´ í’ê²½ì´ ë³€í™”ë˜ì—ˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ì‚¬ìš©ìë“¤ì´ ìì—°ì–´ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì†Œí†µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì²¨ë‹¨ ê¸°ìˆ ì€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ SQL ì¿¼ë¦¬ë¡œ ìˆœì¡°ë¡­ê²Œ ë²ˆì—­í•˜ì—¬ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì¡°ì‘í•˜ëŠ” ë°©ì‹ì„ í˜ì‹ í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>\n<p>ìì—°ì–´ ì²˜ë¦¬(NLP)ì—ì„œ Mistral 7B ë° Microsoft Phi-3ê³¼ ê°™ì€ ëª¨ë¸ì€ ì£¼ìš” ì—­í• ì„ í•˜ë©° ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì˜ ê²½ê³„ë¥¼ ì¬ì •ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>\n<p>Mistral 7BëŠ” NLP ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ê³¼ ì •ë°€ë„ë¡œ ë†’ì´ í‰ê°€ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜(GQA) ë° ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜(SWA)ê³¼ ê°™ì€ í˜ì‹ ì ì¸ ê¸°ëŠ¥ë“¤ì„ ê°–ì¶˜ Mistral 7BëŠ” ìˆ˜í•™ ë° ì½”ë“œ ìƒì„±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘ê³  ìˆìŠµë‹ˆë‹¤. Code-Llama 7Bì˜ ì½”ë”© ëŠ¥ë ¥ì— ê°€ê¹Œì›Œì§ê³¼ ë™ì‹œì— NLP ë°œì „ì—ì„œì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©° ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ìš°ìˆ˜ì„±ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>\n<p>Phi-3 ëŠ” ì‘ì€ ì–¸ì–´ ëª¨ë¸(SLMs) ë¶„ì•¼ì—ì„œì˜ Microsoftì˜ ìµœì‹  í˜ì‹ ìœ¼ë¡œ, AIì˜ í’ê²½ì„ ë³€í™”ì‹œí‚¤ëŠ” ëŒ€ë‹¨í•œ ì œí’ˆì…ë‹ˆë‹¤. Phi-3-mini, Phi-3-small ë° Phi-3-mediumìœ¼ë¡œ êµ¬ì„±ëœ ì´ ëª¨ë¸êµ°ì€ ê°„ê²°í•œ êµ¬ì„±ìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ìë‘í•˜ëŠ” Phi-3-miniëŠ” ë” í° ëª¨ë¸ë“¤ê³¼ ê²¬ì¤„ ë§Œí•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©´ì„œë„ ìŠ¤ë§ˆíŠ¸í°ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. Phi-3ì˜ ì„±ê³µ ë’¤ì—ëŠ” ê²¬ê³ í•¨, ì•ˆì „ì„± ë° ëŒ€í™” ëŠ¥ë ¥ì„ ì¤‘ì‹œí•˜ëŠ” ì •êµí•˜ê²Œ ì„ ë³„ëœ í•™ìŠµ ë°ì´í„°ì…‹ì´ ìˆìŠµë‹ˆë‹¤. Phi-3-small ë° Phi-3-mediumì€ Phi-3ì˜ ëŠ¥ë ¥ì„ ë”ìš± í™•ì¥í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì— ëŒ€ì‘í•©ë‹ˆë‹¤. ì •êµí•˜ê²Œ ì„¤ê³„ëœ ì•„í‚¤í…ì²˜ì™€ í•™ìŠµ ë°©ë²•ì„ í†µí•´ Phi-3ì€ AI ê¸°ìˆ ì˜ í° ë°œì „ì„ ìƒì§•í•˜ë©°, ë‹¤ì–‘í•œ ìƒì„±í˜• AI ì‘ì—…ì— ëŒ€í•œ ìš°ìˆ˜í•œ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ì•½ì†í•©ë‹ˆë‹¤.</p>\n<p>NLPì™€ SQLì˜ êµì°¨ì ì„ íƒìƒ‰í•˜ì—¬ Mistral 7Bì™€ Microsoft Phi-3ì˜ í™œìš©ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ì¿¼ë¦¬ë¡œ ì›í™œí•˜ê²Œ ë³€í™˜í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‘ì—…ì—ì„œ í–¥ìƒëœ íš¨ìœ¨ì„±ê³¼ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</p>\n<p><img src=\"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png\" alt=\"\"></p>\n<h1>í•™ìŠµ ëª©í‘œ</h1>\n<p>ì´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ Mistral 7B ëª¨ë¸ì„ NL2SQL ì‘ì—…ì— í™œìš©í•˜ëŠ” ë³µì¡ì„±ì„ íƒìƒ‰í•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ NL2SQL ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•´ ëª¨ë¸ì„ ë§ì¶¤í™”í•˜ê³  í›ˆë ¨í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë…¼ì˜í•  ê²ƒì…ë‹ˆë‹¤. ê¸°ì‚¬ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤.</p>\n<h1>ë™ê¸°ë¶€ì—¬</h1>\n<p>ì˜¤í”ˆ ì†ŒìŠ¤ LLMsë¥¼ í™œìš©í•˜ë©´ ìì—°ì–´ ëª…ë ¹ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í˜ì‹ ì ì¸ ê¸°ìˆ ì€ ì‚¬ìš©ìê°€ ìˆ˜ë™ ì¿¼ë¦¬ ì‘ì„± ì—†ì´ ë°ì´í„° ìš”êµ¬ ì‚¬í•­ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•˜ë„ë¡ ìë™í™”í•˜ë©°, ì´ë¡œì¨ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ê³  ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ì •í™•í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ í™œìš©ë©ë‹ˆë‹¤. ì´ëŠ” ë³€í™˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”ì‹œí‚¤ê³  ê´‘ë²”ìœ„í•œ ì‚¬ìš©ìë“¤ì—ê²Œ ê´‘ë²”ìœ„í•œ SQL ì§€ì‹ì´ ì—†ì–´ë„ ë°ì´í„°ë¥¼ ì´ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” í¸ë¦¬í•¨ì„ ì œê³µí•˜ë©° ë°ì´í„° ì ‘ê·¼ì„±ê³¼ ìš´ì˜ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. SQL ì „ë¬¸ ì§€ì‹ì˜ ì¥ë²½ì„ ì œê±°í•¨ìœ¼ë¡œì¨ ì´ ê¸°ìˆ ì€ ë°ì´í„° ì ‘ê·¼ì„±ì„ ë¯¼ì£¼í™”ì‹œí‚¤ê³  ê° ë¶„ì•¼ì˜ ì‚¬ìš©ìë“¤ì´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  í†µì°°ì„ ì–»ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì‹¤ì‹œê°„ í†µì°°ì„ ì°¾ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ë‚˜ ë°ì´í„° ì§‘í•©ì„ íƒìƒ‰í•˜ëŠ” ì¼ë°˜ ì‚¬ìš©ìë¥¼ ìœ„í•œ ê²ƒì´ë“ , ìì—°ì–´ ëª…ë ¹ì˜ ì§ê´€ì ì¸ ì„±ê²©ì€ ë°ì´í„° ê²€ìƒ‰ì„ ê°„ë‹¨í•˜ê²Œ í•©ë‹ˆë‹¤.</p>\n<p>ë˜í•œ ì´ëŸ¬í•œ ëª¨ë¸ì—ì„œ ë‚´ì¬ëœ ìë™í™”ëŠ” ì¿¼ë¦¬ ì‹¤í–‰ì„ ê°€ì†í™”í•˜ì—¬ ì „ë°˜ì ì¸ íš¨ìœ¨ì„±ê³¼ ìƒì‚°ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì˜¤í”ˆ ì†ŒìŠ¤ LLMsì˜ ì˜í–¥ë ¥ì€ ê´‘ë²”ìœ„í•˜ë©° ë‹¤ì–‘í•œ ì‚°ì—… ì „ë°˜ì— í˜ì‹ ê³¼ ë³€í™”ë¥¼ ê²©ë ¤í•©ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ì¬ë¬´, ê±´ê°• ê´€ë¦¬ ë° ì „ì ìƒê±°ë˜ ë¶„ì•¼ì™€ ê°™ì´ ë°ì´í„° ì£¼ë„ì  ì˜ì‚¬ ê²°ì •ì´ ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ ì´í•´ê¶Œìë¥¼ ë•ìŠµë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ê³ ê¸‰ ë¶„ì„ í”Œë«í¼ê³¼ ì¸ê³µ ì§€ëŠ¥ ì‹œìŠ¤í…œê³¼ì˜ í†µí•©ì„ í†µí•´ ì¡°ì§ì„ ë°ì´í„° ì£¼ë„ì  ìš°ìˆ˜ì„±ìœ¼ë¡œ ì´ë•ë‹ˆë‹¤. íƒêµ¬ ë¬¸í™”ë¥¼ ìœ¡ì„±í•˜ê³  ë°ì´í„° ìƒí˜¸ì‘ìš©ì„ ê°„ì†Œí™”í•¨ìœ¼ë¡œì¨ ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” ë°ì´í„° ìì‚°ì˜ ëª¨ë“  ì ì¬ë ¥ì„ ë°œíœ˜í•¨ìœ¼ë¡œì¨ ì‚°ì—… ì „ë°˜ì— í˜ì‹ ê³¼ ì„±ì¥ì„ ì´‰ì§„í•©ë‹ˆë‹¤.</p>\n<h1>1. NL2SQLì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ (Mistral 7B)</h1>\n<p>Mistral AIê°€ ê°œë°œí•œ 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì–¸ì–´ ëª¨ë¸ì¸ Mistral 7BëŠ” ì¸ê³µ ì§€ëŠ¥ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤.</p>\n<ul>\n<li>ê¸°ë³¸ ëª¨ë¸ë¡œ ìœ„ì¹˜ ì§€ì •ëœ Mistral 7BëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ êµ¬ì¡°ì  ëª¨ë¸ë¡œ ìë¦¬ ì¡ì•˜ìœ¼ë©° ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ í™˜ê²½ ë‚´ì—ì„œ í•„ìˆ˜ì ì¸ ì½”ì–´ ë¹Œë”© ë¸”ë¡ì˜ ì¤‘ìš”ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.</li>\n<li>ê±´ì¶•ì  ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ì°¨ë³„í™”ëœ Mistral 7BëŠ” ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•´ ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜ (GQA)ê³¼ ê¸´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜ (SWA)ê³¼ ê°™ì€ í˜ì‹ ì ì¸ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.</li>\n<li>ì£¼ë¡œ ì˜ì–´ì— ì´ˆì ì„ ë§ì¶”ì§€ë§Œ ì½”ë”© ëŠ¥ë ¥ë„ ê°–ì¶˜ Mistral 7BëŠ” íŠ¹íˆ ë‹¤ë¥¸ ëª¨ë¸ë“¤ë³´ë‹¤ ë” ë„“ì€ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆëŠ” ë†’ì€ ë¬¸ë§¥ ìœˆë„ìš°ë¥¼ ê°€ì§€ê³  ìˆì–´ ë‘ê°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.</li>\n<li>73ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¡œ ì¸ìƒì ì¸ Mistral 7BëŠ” ìµœì‹  ì–¸ì–´ ëª¨ë¸ì„ ëŒ€í‘œí•˜ëŠ”ë°, Apache 2.0 ë¼ì´ì„¼ìŠ¤ í•˜ì— ì œí•œ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>\n<li>Mistral 7BëŠ” ëª¨ë“  í‰ê°€ëœ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœê³ ì˜ ì˜¤í”ˆ 13B ëª¨ë¸ (Llama-2)ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘ë©° ìµœê³ ì˜ 34B ëª¨ë¸ (Llama-1)ë³´ë‹¤ ì¶”ë¡ í‰ê°€, ìˆ˜í•™ ë° ì½”ë“œ ìƒì„±ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.</li>\n<li>Mistral-7BëŠ” Llama2-13Bë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©° CodeLlama-7Bì™€ ê²½ìŸë ¥ ìˆëŠ” ì„±ê³¼ë¥¼ ë³´ì´ë©° íŠ¹íˆ ì¶”ë¡ , ìˆ˜í•™ ë° ì½”ë“œ ìƒì„± ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚©ë‹ˆë‹¤.</li>\n<li>ë” í° ëª¨ë¸ë“¤ì— ë¹„í•´ í¬ê¸°ëŠ” ì‘ì§€ë§Œ, Mistral 7BëŠ” í…ìŠ¤íŠ¸ ìš”ì•½, ë¶„ë¥˜, í…ìŠ¤íŠ¸ ì™„ì„± ë° ì½”ë“œ ì™„ì„±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ìì—°ì–´ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘¡ë‹ˆë‹¤.</li>\n<li>ì´ ëª¨ë¸ì´ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ëª…ë ¹ì–´ë¡œ ë³€í™˜í•˜ëŠ” íš¨ê³¼ë¥¼ íƒìƒ‰í•˜ì—¬ ëŠ¥ë ¥ì„ ìì„¸íˆ ì‚´í´ë´…ì‹œë‹¤.</li>\n</ul>\n<h2>Sliding Window Attention</h2>\n<ul>\n<li>Mistral 7Bì€ ì „í†µì ì¸ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ë°œìƒí•˜ëŠ” ë„ì „ì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì²˜í•  ìˆ˜ ìˆëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜(Sliding Window Attention, SWA) ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ìëŠ” í† í° ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì¶”ë¡  ì¤‘ ì§€ì—° ì‹œê°„ì´ ì¦ê°€í•˜ê³  ì²˜ë¦¬ëŸ‰ì´ ê°ì†Œí•  ìˆ˜ ìˆìœ¼ë©°, ì‹œí€€ìŠ¤ ê¸¸ì´ì™€ ë©”ëª¨ë¦¬ì™€ ê´€ë ¨ëœ ì—°ì‚°ì´ ì´ì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ë©”ëª¨ë¦¬ê°€ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ì— SWAëŠ” ê° í† í°ì˜ ì£¼ì˜ë¥¼ ì´ì „ ë ˆì´ì–´ì˜ Wê°œ í† í°ì„ ìµœëŒ€í•œìœ¼ë¡œ ì œí•œí•˜ì—¬ ì£¼ì–´ì§„ ìœˆë„ìš° í¬ê¸° Wë¥¼ ë„˜ì–´ì„œ ì£¼ì˜ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.</li>\n<li>SWAëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ìœ„ì¹˜ iì˜ ìˆ¨ê²¨ì§„ ìƒíƒœê°€ ì…ë ¥ ë ˆì´ì–´ì˜ í† í°ì„ W x k í† í°ê¹Œì§€ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ìµœì¢… ë ˆì´ì–´ì—ì„œ W = 4096ì˜ ìœˆë„ìš° í¬ê¸°ë¡œ, SWAëŠ” ì´ë¡ ì ìœ¼ë¡œ ëŒ€ëµ 131K í† í°ì˜ ì£¼ì˜ ë²”ìœ„ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œì ìœ¼ë¡œ W = 4096 ë° FlashAttentionê³¼ xFormersì˜ ìµœì í™” ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬, 16K í† í° ì‹œí€€ìŠ¤ì˜ ê²½ìš° ë°”ë‹ë¼ ì£¼ì˜ ê¸°ì¤€ì— ë¹„í•´ ì£¼ëª©í• ë§Œí•œ 2ë°°ì˜ ì†ë„ í–¥ìƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, SWAëŠ” ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ì„±ëŠ¥ì„ í˜ì‹ ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°•ë ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.</li>\n</ul>\n<h3>b. ë¡¤ë§ ë²„í¼ ìºì‹œ</h3>\n<ul>\n<li>ë¡¤ë§ ë²„í¼ ìºì‹œë¥¼ êµ¬í˜„í•¨ìœ¼ë¡œì¨, Mistral 7BëŠ” ê³ ì •ëœ ì£¼ì˜ ë²”ìœ„ë¥¼ ì „ëµì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìºì‹œ í¬ê¸°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤. ì´ ìºì‹œëŠ” Wë¡œ í‘œì‹œëœ ê³ ì •ëœ í¬ê¸°ë¡œ, ìºì‹œ ë‚´ì—ì„œ íŠ¹ì • ì‹œê°„ ë‹¨ê³„ iì—ì„œ ì‹œê°„ ë‹¨ê³„ i mod Wì— í‚¤ì™€ ê°’ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ì‹œí€€ìŠ¤ê°€ ì§„í–‰ë˜ê³  iê°€ Wë¥¼ ì´ˆê³¼í•  ë•Œ, ìºì‹œëŠ” ë¡¤ë§ ë²„í¼ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ ê°’ë“¤ì„ ë®ì–´ì“°ê³  ë¬´í•œì •ìœ¼ë¡œ í™•ì¥ë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. W = 3ìœ¼ë¡œ ì„¤ëª…ëœ ì´ ì ‘ê·¼ ë°©ì‹ì€ 32k í† í° ì‹œí€€ìŠ¤ì— ëŒ€í•´ 8ë°°ì˜ ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œë¥¼ ì‹¤í˜„í•¨ìœ¼ë¡œì¨, ëª¨ë¸ì˜ í’ˆì§ˆì„ í¬ìƒí•˜ì§€ ì•Šê³  ë‹¬ì„±í•©ë‹ˆë‹¤. ê³ ì •ëœ ì£¼ì˜ ë²”ìœ„ëŠ” íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì´ìš©ì„ ë³´ì¥í•  ë¿ë§Œ ì•„ë‹ˆë¼ Mistral 7Bê°€ ê¸¸ì´ê°€ ë‹¤ë¥¸ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ì— ì›í™œí•˜ê²Œ ê¸°ëŠ¥í•˜ëŠ” ë°ì— ê¸°ì—¬í•©ë‹ˆë‹¤.</li>\n</ul>\n<h3>c. ì‚¬ì „ ì±„ì›€ ë° ì²­í¬ ë¶„í• </h3>\n<ul>\n<li>ì‹œí€€ìŠ¤ ìƒì„± ê³¼ì •ì—ì„œëŠ” ë¬¸ë§¥ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ”ë°, (k, v) ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤. ì•Œë ¤ì§„ í”„ë¡¬í”„íŠ¸ë¡œ ë¯¸ë¦¬ ì±„ì›Œì§„ ìºì‹œë¥¼ í™œìš©í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤. ê¸´ í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì§€ì •ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ê³ , ê° ì²­í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìºì‹œë¥¼ ë¯¸ë¦¬ ì±„ì›ë‹ˆë‹¤. ì´ ì „ëµì  ì ‘ê·¼ ë°©ì‹ì€ ì‹œí€€ìŠ¤ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì¤‘ ìºì‹œ ë‚´ë¶€ ë° í˜„ì¬ ì²­í¬ ì „ì²´ì—ì„œ ì£¼ì˜ë ¥ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì„ í™œìš©í•¨ìœ¼ë¡œì¨ Mistral 7BëŠ” ì‹œí€€ìŠ¤ ìƒì„±ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ë©°, ìºì‹œì— ì €ì¥ëœ ë¯¸ë¦¬ ì•Œë ¤ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ê° ì˜ˆì¸¡ëœ í† í°ì„ ì´ì „ í† í°ê³¼ ì¡°í™”ë¡­ê²Œ ì •ë ¬í•©ë‹ˆë‹¤.</li>\n<li>ì–¸ì–´ ëª¨ë¸ì˜ ë™ì ì¸ í™˜ê²½ì—ì„œ Mistral 7Bì˜ ë“±ì¥ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ë©´ì—ì„œ í° ë„ì•½ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í¬ê´„ì ì¸ í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ Mistral 7BëŠ” ìì‹ ì˜ ëŠ¥ë ¥ì„ ì…ì¦í•˜ë©°, ì´ì „ ì œí’ˆì¸ Llama 2 7B ë° Llama 2 13Bë¿ë§Œ ì•„ë‹ˆë¼ Llama 1 34Bì™€ ê°™ì€ í•µì‹¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ ë›°ì–´ë‚œ ê²½ìŸë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.</li>\n<li>Mistral 7Bì˜ ìš°ì›”ì„±ì€ ëª¨ë“  ì¸¡ì • í•­ëª©ì— ê±¸ì³ ëª…ë°±íˆ ë“œëŸ¬ë‚˜ë©°, í•´ë‹¹ ë¶„ì•¼ì˜ ì„ ë„ì£¼ìë¡œì„œì˜ ì§€ìœ„ë¥¼ ì¬í™•ì¸í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ë©´ë°€í•œ ì¬í‰ê°€ ê³¼ì •ì€ Mistral 7Bì˜ íƒì›”í•œ ëŠ¥ë ¥ì„ ì¼ê´€ë˜ê²Œ ì…ì¦í•˜ë©°, ê²½ìŸì‚¬ë¥¼ ë’¤ë¡œ ë‚¨ê¹ë‹ˆë‹¤.</li>\n</ul>\n<h2>í¬ê¸° ë° íš¨ìœ¨ì„± ë¶„ì„</h2>\n<ul>\n<li>Mistral 7Bì˜ ë§¤ë ¥ ì¤‘ìš” ìš”ì†Œ ì¤‘ í•˜ë‚˜ëŠ” í˜ì‹ ì ì¸ \"ë™ë“±í•œ ëª¨ë¸ í¬ê¸°\" ê³„ì‚° ë°©ì‹ì„ í†µí•œ íš¨ìœ¨ì„±ì…ë‹ˆë‹¤. ì¶”ë¡ , ì´í•´ ë° STEM ì¶”ë¡  ë“±ì—ì„œ í‰ê°€í•œ ê²°ê³¼, Mistral 7BëŠ” ì„¸ ë°° ì´ìƒ í¬ê¸°ì˜ Llama 2 ëª¨ë¸ê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ íš¨ìœ¨ì„±ì€ ê³¼ë„í•œ ë§¤ê°œë³€ìˆ˜ ë¶€ë‹´ ì—†ì´ ë›°ì–´ë‚œ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ” Mistral 7Bì˜ ëŠ¥ë ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.</li>\n<li>Mistral 7Bì˜ íš¨ìœ¨ì„±ì„ ë” ìì„¸íˆ ì‚´í´ë³´ë©´, í‰ê°€ ê²°ê³¼ì—ì„œ ì§€ì‹ ì••ì¶•ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ í†µì°°ë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ì‹ ë²¤ì¹˜ë§ˆí¬ì—ì„œ 1.9ë°° ë‚®ì€ ì••ì¶•ë¥ ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ì´ëŠ” Mistral 7Bì˜ ì˜ë„ì ìœ¼ë¡œ ì œí•œëœ ë§¤ê°œë³€ìˆ˜ ìˆ˜ì— ê¸°ì¸í•©ë‹ˆë‹¤. ì´ ì œí•œì€ ì €ì¥ëœ ì§€ì‹ ì–‘ì„ ì œí•œí•˜ì§€ë§Œ, Mistral 7BëŠ” ì§‘ì¤‘í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ë§¤ê°œë³€ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë³´ìƒí•©ë‹ˆë‹¤.</li>\n</ul>\n<h1>í‰ê°€ì˜ ì°¨ì´ì </h1>\n<p>ë¶ˆì¼ì¹˜ ì‚¬í•­ì„ íˆ¬ëª…í•˜ê²Œ ë‹¤ë£¨ë©´ì„œ, í‰ê°€ ê·œì •ì˜ ë³€í™”ë¥¼ ìœ ì˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–¤ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” Llama 2ì˜ MBPPì™€ Mistral 7Bì˜ í‰ê°€ ê²°ê³¼ ì‚¬ì´ì— ì°¨ì´ê°€ ë°œìƒí•©ë‹ˆë‹¤. TriviaQAì—ì„œ ì†ìœ¼ë¡œ ê²€ì¦ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ Mistral 7Bì˜ ì„±ëŠ¥ ì§€í‘œì˜ ì‹ ë¢°ì„±ì— ê¸°ì—¬í•˜ëŠ” ê°•ê±´í•œ í‰ê°€ ê³¼ì •ì„ í™•ì¸í•˜ê²Œ ë©ë‹ˆë‹¤.</p>\n<h1>ë°ì´í„°ì…‹</h1>\n<p>ì•„ë˜ ì—´ë¡œ êµ¬ì„±ëœ êµ¬ì¡° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ê³„íšì…ë‹ˆë‹¤. ë‹¤ìŒ í…Œì´ë¸”ì—ì„œ ë‹¤ì–‘í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">transaction = [\n        <span class=\"hljs-string\">\"transaction_id\"</span>,\n        <span class=\"hljs-string\">\"transaction_amount\"</span>,\n        <span class=\"hljs-string\">\"transaction_date\"</span>,\n        <span class=\"hljs-string\">\"transaction_type\"</span>,\n        <span class=\"hljs-string\">\"transaction_status\"</span>,\n        <span class=\"hljs-string\">\"transaction_description\"</span>,\n        <span class=\"hljs-string\">\"transaction_source_account\"</span>,\n        <span class=\"hljs-string\">\"transaction_destination_account\"</span>,\n        <span class=\"hljs-string\">\"transaction_currency\"</span>,\n        <span class=\"hljs-string\">\"transaction_fee\"</span>\n    ]\n</code></pre>\n<h1>ì½”ë“œ êµ¬í˜„</h1>\n<ul>\n<li>íŒ¨í‚¤ì§€ ì„¤ì¹˜í•˜ê¸°</li>\n</ul>\n<pre><code class=\"hljs language-js\">!pip install git+<span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//github.com/huggingface/transformers.git </span>\n!pip install deepspeed --upgrade\n!pip install accelerate\n!pip install sentencepiece\n!pip install langchain\n!pip install torch\n!pip install bitsandbytes\n</code></pre>\n<ol start=\"2\">\n<li>íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°</li>\n</ol>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\">from</span> difflib <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">SequenceMatcher</span>\n<span class=\"hljs-keyword\">from</span> langchain.<span class=\"hljs-property\">chains</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">LLMChain</span>\n<span class=\"hljs-keyword\">from</span> langchain <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">PromptTemplate</span>, <span class=\"hljs-title class_\">LLMChain</span>\n<span class=\"hljs-keyword\">from</span> langchain.<span class=\"hljs-property\">llms</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">HuggingFacePipeline</span>\n<span class=\"hljs-keyword\">from</span> langchain_core.<span class=\"hljs-property\">prompts</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">PromptTemplate</span>\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">LlamaTokenizer</span>, <span class=\"hljs-title class_\">LlamaForCausalLM</span>, pipeline\n</code></pre>\n<ol start=\"3\">\n<li>ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°</li>\n</ol>\n<pre><code class=\"hljs language-js\">base_model = <span class=\"hljs-title class_\">LlamaForCausalLM</span>.<span class=\"hljs-title function_\">from_pretrained</span>(\n     <span class=\"hljs-string\">\"mistralai/Mistral-7B-Instruct-v0.1\"</span>,\n     load_in_8bit=<span class=\"hljs-title class_\">True</span>,\n     device_map=<span class=\"hljs-string\">'auto'</span>,\n    )\ntokenizer = <span class=\"hljs-title class_\">LlamaTokenizer</span>.<span class=\"hljs-title function_\">from_pretrained</span>(<span class=\"hljs-string\">\"mistralai/Mistral-7B-Instruct-v0.1\"</span>)\npipe = <span class=\"hljs-title function_\">pipeline</span>(\n        <span class=\"hljs-string\">\"text-generation\"</span>,\n        model=base_model,\n        tokenizer=tokenizer,\n        max_length=<span class=\"hljs-number\">500</span>,\n        temperature=<span class=\"hljs-number\">0.3</span>,\n        top_p=<span class=\"hljs-number\">0.95</span>,\n        repetition_penalty=<span class=\"hljs-number\">1.2</span>\n    )\nlocal_llm = <span class=\"hljs-title class_\">HuggingFacePipeline</span>(pipeline=pipe)\n</code></pre>\n<ol start=\"4\">\n<li>SequenceMatcher</li>\n</ol>\n<p>ì´ Python í•¨ìˆ˜ëŠ” difflib ëª¨ë“ˆì˜ SequenceMatcher í´ë˜ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ì™€ ì§€ì •ëœ ì‚¬ì „ì˜ ì—´ ì´ë¦„ ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì¿¼ë¦¬ ì´í•´ë ¥ê³¼ ëŒ€ì²´ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">find_columns_match</span>(question, input_dict):\n<span class=\"hljs-attr\">try</span>:\n  question_list = re.<span class=\"hljs-title function_\">split</span>(r<span class=\"hljs-string\">'\\s|,|\\.'</span>, question)\n  <span class=\"hljs-keyword\">for</span> index, string2 <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">enumerate</span>(question_list):\n    <span class=\"hljs-keyword\">for</span> string1 <span class=\"hljs-keyword\">in</span> input_dict.<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'table1_columns'</span>):\n      score = <span class=\"hljs-title class_\">SequenceMatcher</span>(<span class=\"hljs-title class_\">None</span>,string1.<span class=\"hljs-title function_\">lower</span>(), string2.<span class=\"hljs-title function_\">lower</span>()).<span class=\"hljs-title function_\">ratio</span>()*<span class=\"hljs-number\">100</span>\n      <span class=\"hljs-keyword\">if</span> score > <span class=\"hljs-number\">91</span>:\n        question_list[index] = string1 + <span class=\"hljs-string\">\",\"</span>\n  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\" \"</span>.<span class=\"hljs-title function_\">join</span>(question_list)\n  \n<span class=\"hljs-attr\">except</span>:\n <span class=\"hljs-keyword\">return</span> question\n</code></pre>\n<p>ì´ Python í•¨ìˆ˜ query_generatorì€ ì œê³µëœ í…Œì´ë¸”ëª…, ì—´ ëª©ë¡ ë° ì§ˆë¬¸ì— ê¸°ë°˜í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” í…œí”Œë¦¿ ë¬¸ìì—´ì„ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬ì¡°í™”í•˜ë©°, í…Œì´ë¸” ëª…, ì—´ ëª©ë¡ ë° ì§ˆë¬¸ì— ëŒ€í•œ ìë¦¬ í‘œì‹œìë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ PromptTemplate ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ìë¦¬ í‘œì‹œìë¥¼ ì±„ì›Œë„£ê³  LLMChainì„ í†µí•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM)ê³¼ ìƒí˜¸ ì‘ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ìƒì„±ëœ SQL ì¿¼ë¦¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">query_generator</span>(tble, cols, question):\n\n  template = <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"Generate a SQL query using the following table name: {Table}, and columns as a list: {Columns}, to answer the following question:\n  {question}.\n  \n  Output Query:\n  \n  \"</span><span class=\"hljs-string\">\"\"</span>\n  \n  prompt = <span class=\"hljs-title class_\">PromptTemplate</span>(template=template, input_variables=[<span class=\"hljs-string\">\"Table\"</span>, <span class=\"hljs-string\">\"question\"</span>, <span class=\"hljs-string\">\"Columns\"</span>])\n  \n  llm_chain = <span class=\"hljs-title class_\">LLMChain</span>(prompt=prompt, llm=local_llm)\n  \n  response = llm_chain.<span class=\"hljs-title function_\">run</span>({<span class=\"hljs-string\">\"Table\"</span>: tble, <span class=\"hljs-string\">\"question\"</span>: question, <span class=\"hljs-string\">\"Columns\"</span>: cols})\n  <span class=\"hljs-title function_\">print</span>(response)\n</code></pre>\n<h1>í‘œ</h1>\n<p>transaction = [\n\"transaction_id\",\n\"transaction_amount\",\n\"transaction_date\",\n\"transaction_type\",\n\"transaction_status\",\n\"transaction_description\",\n\"transaction_source_account\",\n\"transaction_destination_account\",\n\"transaction_currency\",\n\"transaction_fee\"\n]</p>\n<pre><code>inputs = [\"transaction_idê°€ 10ì¸ ê²½ìš° transaction_amount, transaction_date, transaction_type,transaction_descriptionì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n         \"transaction_statusê°€ 'completed'ì¸ ê²½ìš° transaction_id, transaction_date, transaction_type, transaction_source_accountì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n         \"transaction_type ë° í‰ê·  transaction_amountì˜ ê°œìˆ˜ë¥¼ ê²€ìƒ‰í•˜ê³  transaction_typeë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n         \"ê° ì†ŒìŠ¤ ê³„ì •ë³„ ì´ ê±°ë˜ ê¸ˆì•¡ ëª©ë¡ì„ ê²€ìƒ‰í•˜ê³  ì´ ê±°ë˜ ê¸ˆì•¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\",\n         \"ê° ê±°ë˜ ìœ í˜•ë³„ ìµœëŒ€ ê±°ë˜ ê¸ˆì•¡ì„ ê²€ìƒ‰í•˜ê³  ê±°ë˜ ìœ í˜•ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±\"]\n\nfor input in inputs:\n    query_generator(\"transaction\",transaction ,question=find_columns_match(input,transaction))\n</code></pre>\n<h1>ì‘ë‹µ</h1>\n<ul>\n<li>ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì„ ì‚¬ìš©í•˜ê³  ì»¬ëŸ¼ì„ ë‚˜ì—´í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™], ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ ìœ„í•´ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: (â€˜transaction_idê°€ 10ì¸ ê²½ìš° transaction_amount, transaction_date, transaction_type,transaction_descriptionì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±â€™).</li>\n</ul>\n<pre><code class=\"hljs language-js\">ì¶œë ¥ ì¿¼ë¦¬: \n\n  <span class=\"hljs-variable constant_\">SELECT</span> transaction_amount, transaction_date, transaction_type, transaction_description <span class=\"hljs-variable constant_\">FROM</span> transaction <span class=\"hljs-variable constant_\">WHERE</span> transaction_id = <span class=\"hljs-number\">10</span>;\n</code></pre>\n<ol start=\"2\">\n<li>ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì¸ transactionê³¼ ì—´ ëª©ë¡ì¸ [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™]ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤:\n(â€˜transaction_statusê°€ â€˜completedâ€™ì¸ ê²½ìš° transaction_id, transaction_date, transaction_type, transaction_source_accountë¥¼ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤â€™).</li>\n</ol>\n<pre><code class=\"hljs language-js\">ì¶œë ¥ ì¿¼ë¦¬:\n  <span class=\"hljs-variable constant_\">SELECT</span> transaction_id, transaction_date, transaction_type, transaction_source_account <span class=\"hljs-variable constant_\">FROM</span> transaction <span class=\"hljs-variable constant_\">WHERE</span> transaction_status = <span class=\"hljs-string\">'completed'</span>\n</code></pre>\n<ol start=\"3\">\n<li>ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì¸ transactionê³¼ ì—´ ëª©ë¡ì¸ [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™]ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤:\n(â€˜transaction_typeì˜ countì™€ í‰ê·  transaction_amountë¥¼ ê°€ì ¸ì˜¤ê³  transaction_typeìœ¼ë¡œ ì •ë ¬í•˜ì‹­ì‹œì˜¤â€™).</li>\n</ol>\n<pre><code class=\"hljs language-js\">ê²°ê³¼ ì¿¼ë¦¬:\n\n  <span class=\"hljs-variable constant_\">SELECT</span> transaction_type, <span class=\"hljs-title function_\">AVG</span>(transaction_amount) <span class=\"hljs-variable constant_\">AS</span> avg_transaction_amount, <span class=\"hljs-title function_\">COUNT</span>(*) <span class=\"hljs-variable constant_\">AS</span> total_count\n  <span class=\"hljs-variable constant_\">FROM</span> transaction\n  <span class=\"hljs-variable constant_\">GROUP</span> <span class=\"hljs-variable constant_\">BY</span> transaction_type\n  <span class=\"hljs-variable constant_\">ORDER</span> <span class=\"hljs-variable constant_\">BY</span> transaction_type;\n</code></pre>\n<ol start=\"4\">\n<li>ë‹¤ìŒ í…Œì´ë¸” ì´ë¦„ê³¼ ì—´ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° ì—´: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤:\n(â€˜ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ì†ŒìŠ¤ ê³„ì •ì˜ ì´ ê±°ë˜ ê¸ˆì•¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¡°íšŒí•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”â€™).</li>\n</ol>\n<pre><code class=\"hljs language-js\">ê²°ê³¼ ì¿¼ë¦¬:\n\n       <span class=\"hljs-variable constant_\">SELECT</span> transaction_source_account, <span class=\"hljs-title function_\">SUM</span>(transaction_amount) <span class=\"hljs-variable constant_\">AS</span> <span class=\"hljs-title class_\">TotalTransactionAmount</span>\n        <span class=\"hljs-variable constant_\">FROM</span> transaction\n        <span class=\"hljs-variable constant_\">GROUP</span> <span class=\"hljs-variable constant_\">BY</span> transaction_source_account\n        <span class=\"hljs-variable constant_\">ORDER</span> <span class=\"hljs-variable constant_\">BY</span> <span class=\"hljs-title class_\">TotalTransactionAmount</span> <span class=\"hljs-variable constant_\">DESC</span>;\n</code></pre>\n<ol start=\"5\">\n<li>ë‹¤ìŒ í…Œì´ë¸” ì´ë¦„ê³¼ ì—´ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° ì—´: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤:\n(â€˜ê° ê±°ë˜ ìœ í˜•ì˜ ìµœëŒ€ ê±°ë˜ ê¸ˆì•¡ì„ ì°¾ì•„ ê±°ë˜ ìœ í˜•ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”â€™).</li>\n</ol>\n<pre><code class=\"hljs language-js\">ì¶œë ¥ ì¿¼ë¦¬:\n\n   <span class=\"hljs-variable constant_\">SELECT</span> transaction_type, <span class=\"hljs-title function_\">MAX</span>(transaction_amount) <span class=\"hljs-variable constant_\">AS</span> max_transaction_amount\n   <span class=\"hljs-variable constant_\">FROM</span> transaction\n   <span class=\"hljs-variable constant_\">GROUP</span> <span class=\"hljs-variable constant_\">BY</span> transaction_type\n   <span class=\"hljs-variable constant_\">ORDER</span> <span class=\"hljs-variable constant_\">BY</span> transaction_type;\n</code></pre>\n<p>ì¼ë°˜ì ì¸ ì¶”ì¶œì€ íš¨ê³¼ì ì´ì§€ë§Œ, ì—°êµ¬ ê²°ê³¼, ë°ì´í„°ë¥¼ ì„¸ë¶€ ì¡°ì •í•˜ì—¬ LLMì„ ìˆ˜í–‰í•˜ë©´ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¸ë°€ ì¡°ì • ì ‘ê·¼ë²•ì„ ì±„ìš©í•´ ë´…ì‹œë‹¤.</p>\n<h1>2 Fine-tune NL2SQL with Phi-3</h1>\n<p>Phi-3ë¥¼ ë§Œë‚˜ë³´ì„¸ìš”, Microsoftì˜ ìµœì‹  ì˜¤í”ˆ AI ëª¨ë¸ì˜ ì£¼ìš” ì„±ê³¼ì…ë‹ˆë‹¤. Phi-3-mini, Phi-3-small ë° Phi-3-mediumì„ í†µí•´, ì´ ì‘ì€ ì–¸ì–´ ëª¨ë¸ (SLM)ì˜ Phi-3 íŒ¨ë°€ë¦¬ëŠ” AI ëª¨ë¸ì˜ ì„¸ê³„ë¥¼ í˜ì‹ í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ê³  33ì¡° ê°œì˜ í† í°ìœ¼ë¡œ í›ˆë ¨ëœ Phi-3-miniëŠ” ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©° Mixtral 8x7B ë° GPT-3.5ì™€ ê°™ì€ í° ëª¨ë¸ê³¼ ê°™ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê²Œë‹¤ê°€, ì´ ëª¨ë¸ì€ ìŠ¤ë§ˆíŠ¸í° ì¥ì¹˜ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Phi-3ì˜ ì„±ê³µì€ í›ˆë ¨ ë°ì´í„°ì…‹ì— ê¸°ì¸í•©ë‹ˆë‹¤. Phi-2ì˜ ë°ì´í„°ì…‹ì˜ ì§„í™”ëœ ë²„ì „ì…ë‹ˆë‹¤. ìƒì„¸íˆ ê±¸ëŸ¬ë‚¸ ì›¹ ë°ì´í„° ë° í•©ì„± ì…ë ¥ì„ í†µí•´ ì´ëŸ¬í•œ ëª¨ë¸ì€ ê°•ë„, ì•ˆì „ ë° ëŒ€í™” ëŠ¥ë ¥ì— ìš°ì„ ìˆœìœ„ë¥¼ ë‘ì–´ ë‹¤ì–‘í•œ ì‘ìš©í”„ë¡œê·¸ë¨ì— ì í•©í•©ë‹ˆë‹¤. 7B ë° 14B íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ Phi-3-small ë° Phi-3-mediumì€ íš¨ìœ¨ ìœ ì§€ì™€ í•¨ê»˜ Phi-3ì˜ ê¸°ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.</p>\n<h2>Phi 3 Architecture and Evaluation</h2>\n<p>Phi-3 íŒ¨ë°€ë¦¬ëŠ” í’ˆì§ˆê³¼ ë¹„ìš©ì„ ê· í˜•ìˆê²Œ ìœ ì§€í•˜ë„ë¡ ì„¤ê³„ëœ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì œê³µí•˜ì—¬ ìƒì„±í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ëŠ” ê³ ê°ì„ ìœ„í•œ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.</p>\n<p>Phi-3-mini: ì´ ëª¨ë¸ì€ 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ì¶”ê³  33ì¡° ê°œì˜ í† í°ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê´‘ë²”ìœ„í•œ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. 32ê°œì˜ ë ˆì´ì–´, 32ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  3072ê°œì˜ íˆë“  ë””ë©˜ì…˜ì„ ê°–ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì±„íƒí–ˆìŠµë‹ˆë‹¤. ë””í´íŠ¸ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ëŠ” 4ì²œ ê°œì˜ í† í°ì´ë©°, 32K ì–´íœ˜ ì‚¬ì „ì„ ì‚¬ìš©í•˜ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì¶”ê°€ë¡œ, 128K í† í°ì˜ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°–ì¶˜ í™•ì¥ ë²„ì „ì¸ Phi-3-mini-128Kë„ ìˆìŠµë‹ˆë‹¤.</p>\n<p>Phi-3-small: 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¡œ í›ˆë ¨ëœ Phi-3-smallì€ 48ì¡° ê°œì˜ í† í°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 100K ì–´íœ˜ ì‚¬ì „ê³¼ 8ì²œ ê°œì˜ ë””í´íŠ¸ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. ì•„í‚¤í…ì²˜ëŠ” 32ê°œì˜ ë ˆì´ì–´, 32ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  4096ê°œì˜ íˆë“  ë””ë©˜ì…˜ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜ê³¼ ë²ˆê°ˆì•„ê°€ë©° ì“°ì´ëŠ” ë°€ì§‘/í¬ì†Œ ì–´í…ì…˜ì„ í™œìš©í•©ë‹ˆë‹¤.</p>\n<p>Phi-3-medium: ì´ ë¯¸ë¦¬ë³´ê¸° ëª¨ë¸ì€ 140ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ìë‘í•˜ë©° 4.8ì¡° ê°œì˜ í† í°ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. 40ê°œì˜ ë ˆì´ì–´, 40ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  ì„ë² ë”© í¬ê¸°ëŠ” 5120ì…ë‹ˆë‹¤.</p>\n<h2>í›ˆë ¨ ë°©ë²•:</h2>\n<ul>\n<li>í›ˆë ¨ ë°ì´í„° êµ¬ì„±: Phi-3 ëª¨ë¸ì˜ í›ˆë ¨ ë°ì´í„°ëŠ” ì‹ ì¤‘í•˜ê²Œ ì„ ë³„ë©ë‹ˆë‹¤. êµìœ¡ ìˆ˜ì¤€ë³„ë¡œ ë¶„ë¥˜ëœ ì›¹ ë°ì´í„°ì™€ í•©ì„± LLM ìƒì„± ë°ì´í„°ë¡œ êµ¬ì„±ë˜ë©° ë‘ ê°€ì§€ ì´ì§ˆì ì´ê³  ìˆœì°¨ì ì¸ ë‹¨ê³„ë¡œ ì‚¬ì „ í›ˆë ¨ì„ ê±°ì¹©ë‹ˆë‹¤.</li>\n<li>ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„: ì œ1 ë‹¨ê³„ëŠ” ì¼ë°˜ ì§€ì‹ê³¼ ì–¸ì–´ ì´í•´ì— ì¤‘ì ì„ ë‘” ì›¹ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì œ2 ë‹¨ê³„ëŠ” ë…¼ë¦¬ ì¶”ë¡  ë° íŠ¹ì • ê¸°ìˆ ì„ ê°€ë¥´ì¹˜ê¸° ìœ„í•´ ì œ1 ë‹¨ê³„ì˜ ì›¹ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„°ë¥¼ ë” ë§ì´ í™œìš©í•©ë‹ˆë‹¤.</li>\n<li>ì‚¬í›„ í›ˆë ¨ ë‹¨ê³„: ì‚¬ì „ í›ˆë ¨ í›„, Phi-3-miniëŠ” ê°ë…í˜• ì„¸ë°€ ì¡°ì • (SFT) ë° ì§ì ‘ ì„ í˜¸ë„ ìµœì í™” (DPO)ë¥¼ ê±°ì³¤ìŠµë‹ˆë‹¤. SFTëŠ” ìˆ˜í•™, ì½”ë”©, ì¶”ë¡ , ëŒ€í™”, ëª¨ë¸ ì‹ ì›, ì•ˆì „ ë„ë©”ì¸ ê°„ì— ë†’ì€ í’ˆì§ˆì˜ ë°ì´í„°ë¥¼ ì„ ë³„í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.</li>\n<li>DPOëŠ” ì±„íŒ… í˜•ì‹ ë°ì´í„°, ì¶”ë¡ , ê·¸ë¦¬ê³  ì±…ì„ ìˆëŠ” AI ë…¸ë ¥ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.</li>\n<li>ë§¥ë½ í™•ì¥: Phi-3-miniì˜ ë§¥ë½ ì°½ í¬ê¸°ê°€ Long Rope ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì—¬ 4k í† í°ì—ì„œ 128k í† í°ìœ¼ë¡œ í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í™•ì¥ì€ ë§¥ë½ì˜ ê¸¸ì´ê°€ í¬ê²Œ ì¦ê°€í•¨ì—ë„ ì¼ê´€ëœ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.</li>\n<li>ë°ì´í„° ìµœì í™”: í›ˆë ¨ ë°ì´í„°ëŠ” ëª¨ë¸ì˜ ê·œëª¨ë¥¼ ìœ„í•œ \"ë°ì´í„° ìµœì \" ì§€ì ìœ¼ë¡œ ë³´ì •ë©ë‹ˆë‹¤. ì›¹ ë°ì´í„°ëŠ” ì§€ì‹ê³¼ ì¶”ë¡ ì˜ ì ì ˆí•œ ê· í˜•ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í•„í„°ë§ë©ë‹ˆë‹¤. íŠ¹íˆ ì‘ì€ ëª¨ë¸ì˜ ê²½ìš° ì´ëŠ” ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.</li>\n<li>ë‹¤ë¥¸ ëª¨ë¸ê³¼ì˜ ë¹„êµ: Phi-3ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì´ì „ ì‘ì—…ê³¼ ëŒ€ì¡°ì ìœ¼ë¡œ, í•´ë‹¹ ê·œëª¨ì— ëŒ€í•œ ë°ì´í„° í’ˆì§ˆì— ì¤‘ì ì„ ë‘ë©° ì»´í“¨íŒ…ì´ë‚˜ ê³¼ë„í•œ í›ˆë ¨ ë°©ë²•ë³´ë‹¤ ë°ì´í„° ìµœì í™”ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë¹„êµëŠ” Phi-3ê°€ ì‘ì€ ëª¨ë¸ ìš©ëŸ‰ì„ ìœ„í•œ ìµœì í™”ë¥¼ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.</li>\n<li>Phi-3-medium ë¯¸ë¦¬ë³´ê¸°: 140ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ Phi-3-mediumì€ Phi-3-miniì™€ ìœ ì‚¬í•˜ê²Œ í›ˆë ¨ë˜ì—ˆì§€ë§Œ ë” í° ê·œëª¨ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì¼ë¶€ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” 7Bì—ì„œ 14B ë§¤ê°œë³€ìˆ˜ë¡œì˜ ì „í™˜ì—ì„œ í° ê°œì„ ì´ ì—†ì–´ ê³„ì†í•´ì„œ ë°ì´í„° í˜¼í•©ì„ ê°œì„  ì¤‘ì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.</li>\n<li>ì‚¬í›„ í–¥ìƒ: ëª¨ë¸ì€ ì±„íŒ… ëŠ¥ë ¥, ê²¬ê³ ì„±, ê·¸ë¦¬ê³  ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê°ë…í˜• ì„¸ë°€ ì¡°ì • ë° DPOë¥¼ í†µí•œ ì„ í˜¸ë„ ì¡°ì •ì„ ê±°ì¹©ë‹ˆë‹¤.</li>\n</ul>\n<h2>ì•ˆì „ì„±</h2>\n<p>Phi-3-miniì€ Microsoftì˜ ì±…ì„ ìˆëŠ” AI ì›ì¹™ì— ë”°ë¼ ë§Œë“¤ì–´ì§„ AI ëª¨ë¸ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ê°œë°œ ì´ˆê¸°ë¶€í„° ì•ˆì „ì„ ìš°ì„ ì‹œí•˜ëŠ” ì›ì¹™ì„ ì¤‘ìš”ì‹œí•˜ì—¬ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ìœ¤ë¦¬ ê¸°ì¤€ì„ ì¤€ìˆ˜í•˜ê³  ì ì¬ì ì¸ í”¼í•´ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í¬ê´„ì ì¸ ì „ëµì´ ì±„íƒë˜ì—ˆìŠµë‹ˆë‹¤.</p>\n<p>ëª¨ë¸ í•™ìŠµ í›„ì—ëŠ”, í•´ë‹¹ ëª¨ë¸ì´ ì±…ì„ ìˆëŠ” AI ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë©´ë°€í•œ ì•ˆì „ ì¡°ì •ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ê²Œë‹¤ê°€, Microsoftì˜ ë…ë¦½ëœ ë ˆë“œ íŒ€ì´ Phi-3-minië¥¼ ê²€í† í•˜ì—¬ ê°•í™” ë° ì•ˆì „ í”„ë¡œí† ì½œì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ì‹ë³„í•©ë‹ˆë‹¤.</p>\n<p>ìë™í™”ëœ í…ŒìŠ¤íŒ…ê³¼ ì ì¬ì ì¸ í”¼í•´ì˜ ë‹¤ì–‘í•œ ë²”ì£¼ì— ëŒ€í•œ í‰ê°€ëŠ” í”„ë¡œì„¸ìŠ¤ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ëŠ” ëª¨ë¸ì˜ ì¶œë ¥ë¬¼ë¡œë¶€í„° ë°œìƒí•˜ëŠ” ëª¨ë“  ìœ„í—˜ì„ ê°ì§€í•˜ê³  í•´ê²°í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤.</p>\n<p>ë” ë‚˜ì•„ê°€, Phi-3-miniëŠ” ì˜ê²¬ ë°ì´í„° ì„¸íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì‘ë‹µì„ ë”ìš± ê°œì„ í•©ë‹ˆë‹¤. íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¤‘ í™•ì¸ëœ ì ì¬ì ì¸ í”¼í•´ ë²”ì£¼ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ë‚´ë¶€ì—ì„œ ìƒì„±ëœ ë°ì´í„° ì„¸íŠ¸ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>\n<h2>ì½”ë“œ êµ¬í˜„</h2>\n<ul>\n<li>íŒ¨í‚¤ì§€ ì„¤ì¹˜</li>\n</ul>\n<pre><code class=\"hljs language-js\"> !pip install -q -U bitsandbytes\n !pip install -q -U transformers\n !pip install -q -U xformers\n !pip install -q -U peft\n !pip install -q -U accelerate\n !pip install -q -U datasets\n !pip install -q -U trl\n !pip install -q -U einops\n !pip install -q -U nvidia-ml-py3\n !pip install -q -U huggingface_hub\n</code></pre>\n<ol start=\"2\">\n<li>íŒ¨í‚¤ì§€ ê°€ì ¸ì˜¤ê¸°</li>\n</ol>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n<span class=\"hljs-keyword\">from</span> pynvml <span class=\"hljs-keyword\">import</span> *\n<span class=\"hljs-keyword\">import</span> time, torch\n<span class=\"hljs-keyword\">from</span> trl <span class=\"hljs-keyword\">import</span> SFTTrainer\n<span class=\"hljs-keyword\">from</span> peft <span class=\"hljs-keyword\">import</span> LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n<span class=\"hljs-keyword\">from</span> peft <span class=\"hljs-keyword\">import</span> AutoPeftModelForCausalLM\n</code></pre>\n<ol start=\"3\">\n<li>ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°</li>\n</ol>\n<pre><code class=\"hljs language-python\">dataset = load_dataset(<span class=\"hljs-string\">\"b-mc2/sql-create-context\"</span>)\ndataset\n</code></pre>\n<ol start=\"4\">\n<li>ë°ì´í„°ì…‹ í˜•ì‹í™”</li>\n</ol>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">create_prompt</span>(sample):\n      system_prompt_template = <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"&#x3C;s>\n            ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n            ### ì§€ì‹œì‚¬í•­: &#x3C;&#x3C;user_question>>\n            ### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n            &#x3C;&#x3C;database_schema>>\n            ### ì‘ë‹µ:\n            &#x3C;&#x3C;user_response>>\n            &#x3C;/s>\n            \"</span><span class=\"hljs-string\">\"\"</span>\n      user_message = sample[<span class=\"hljs-string\">'question'</span>]\n      user_response = sample[<span class=\"hljs-string\">'answer'</span>]\n      database_schema = sample[<span class=\"hljs-string\">'context'</span>]\n      prompt_template = system_prompt_template.<span class=\"hljs-title function_\">replace</span>(<span class=\"hljs-string\">\"&#x3C;&#x3C;user_question>>\"</span>,f<span class=\"hljs-string\">\"{user_message}\"</span>).<span class=\"hljs-title function_\">replace</span>(<span class=\"hljs-string\">\"&#x3C;&#x3C;user_response>>\"</span>,f<span class=\"hljs-string\">\"{user_response}\"</span>).<span class=\"hljs-title function_\">replace</span>(<span class=\"hljs-string\">\"&#x3C;&#x3C;database_schema>>\"</span>,f<span class=\"hljs-string\">\"{database_schema} \"</span>)\n\n      <span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">\"inputs\"</span>:prompt_template}\n\n\ninstruct_tune_dataset = dataset.<span class=\"hljs-title function_\">map</span>(create_prompt)\n<span class=\"hljs-title function_\">print</span>(instruct_tune_dataset)\n\ndef <span class=\"hljs-title function_\">print_gpu_utilization</span>():\n    <span class=\"hljs-title function_\">nvmlInit</span>()\n    handle = <span class=\"hljs-title function_\">nvmlDeviceGetHandleByIndex</span>(<span class=\"hljs-number\">0</span>)\n    info = <span class=\"hljs-title function_\">nvmlDeviceGetMemoryInfo</span>(handle)\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {info.used//1024**2} MB.\"</span>)\n</code></pre>\n<ol start=\"5\">\n<li>í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ</li>\n</ol>\n<pre><code class=\"hljs language-js\">base_model_id = <span class=\"hljs-string\">\"microsoft/Phi-3-mini-4k-instruct\"</span>\n\n# í† í¬ë‚˜ì´ì € ë¡œë“œ\ntokenizer = <span class=\"hljs-title class_\">AutoTokenizer</span>.<span class=\"hljs-title function_\">from_pretrained</span>(base_model_id, use_fast=<span class=\"hljs-title class_\">True</span>)\n# fp16ë¡œ ëª¨ë¸ ë¡œë“œ\nmodel = <span class=\"hljs-title class_\">AutoModelForCausalLM</span>.<span class=\"hljs-title function_\">from_pretrained</span>(base_model_id, trust_remote_code=<span class=\"hljs-title class_\">True</span>, torch_dtype=torch.<span class=\"hljs-property\">float16</span>, device_map={<span class=\"hljs-string\">\"\"</span>: <span class=\"hljs-number\">0</span>})\n<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-title function_\">print_gpu_utilization</span>())\n</code></pre>\n<ol start=\"6\">\n<li>ëª¨ë¸ ì¶”ë¡ </li>\n</ol>\n<h1>í”„ë¡¬í”„íŠ¸ ì •ì˜</h1>\n<pre><code class=\"hljs language-bash\">    prompt = [\n        <span class=\"hljs-string\">\"ì½”ì½”ë„› ë°€í¬ë¡œ ë§Œë“  ì¹˜í‚¨ ì¹´ë ˆ ë ˆì‹œí”¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\"</span>,\n        <span class=\"hljs-string\">\"ë‹¤ìŒ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: 'ë‚˜ëŠ” ë¹µê³¼ ì¹˜ì¦ˆë¥¼ ì¢‹ì•„í•´ìš”!'\"</span>,\n        <span class=\"hljs-string\">\"ìœ ëª…í•œ 20ëª…ì˜ ì¸ë¬¼ì„ ì¸ìš©í•´ë³´ì„¸ìš”.\"</span>,\n        <span class=\"hljs-string\">\"ì§€ê¸ˆ ë‹¬ì€ ì–´ë””ì— ìˆë‚˜ìš”?\"</span>\n    ]\n\n    <span class=\"hljs-comment\"># ë³€ìˆ˜ ì´ˆê¸°í™”</span>\n    duration = 0.0\n    total_length = 0\n\n    <span class=\"hljs-comment\"># í”„ë¡¬í”„íŠ¸ ë°˜ë³µ</span>\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(len(prompt)):\n        <span class=\"hljs-comment\"># í”„ë¡¬í”„íŠ¸ í† í°í™” ë° GPUë¡œ ì´ë™</span>\n        inputs = tokenizer(prompt[i], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(<span class=\"hljs-string\">\"cuda:0\"</span>)\n\n        <span class=\"hljs-comment\"># ì…ë ¥ í…ì„œ ì¸ë±ìŠ¤ë¥¼ torch.longìœ¼ë¡œ ë³€í™˜</span>\n        inputs = {k: v.to(torch.long) <span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> inputs.items()}\n\n        <span class=\"hljs-comment\"># ì‹œì‘ ì‹œê°„</span>\n        start_time = time.time()\n\n        <span class=\"hljs-comment\"># ìë™ ìºìŠ¤íŒ…ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ìˆ˜í–‰</span>\n        with torch.cuda.amp.autocast(enabled=False):  <span class=\"hljs-comment\"># ìë™ ìºìŠ¤íŒ… ë¹„í™œì„±í™”</span>\n            output = model.generate(**inputs, max_length=500)\n\n        <span class=\"hljs-comment\"># ì†Œìš” ì‹œê°„ê³¼ ì´ ê¸¸ì´ ê³„ì‚°</span>\n        duration += <span class=\"hljs-built_in\">float</span>(time.time() - start_time)\n        total_length += len(output)\n\n        <span class=\"hljs-comment\"># í”„ë¡¬í”„íŠ¸ë‹¹ í† í° ì†ë„ ê³„ì‚°</span>\n        tok_sec_prompt = round(len(output) / <span class=\"hljs-built_in\">float</span>(time.time() - start_time), 3)\n\n        <span class=\"hljs-comment\"># í”„ë¡¬í”„íŠ¸ë‹¹ í† í° ì†ë„ ì¶œë ¥</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"í”„ë¡¬í”„íŠ¸ --- %s í† í°/ì´ˆ ---\"</span> % (tok_sec_prompt))\n\n        <span class=\"hljs-comment\"># ë””ì½”ë“œëœ ì¶œë ¥ ì¶œë ¥</span>\n        <span class=\"hljs-built_in\">print</span>(tokenizer.decode(output[0], skip_special_tokens=True))\n\n    <span class=\"hljs-comment\"># í‰ê·  í† í° ì†ë„ ê³„ì‚°</span>\n    tok_sec = round(total_length / duration, 3)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"í‰ê·  --- %s í† í°/ì´ˆ ---\"</span> % (tok_sec))\n</code></pre>\n<ol start=\"9\">\n<li>Fine-tuningë˜ì§€ ì•Šì€ Text to SQL</li>\n</ol>\n<pre><code class=\"hljs language-bash\">    prompt = [\n        <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n        ### ì§€ì‹œì‚¬í•­ :\n        ê° ë„ì‹œì˜ ì—­ ì¤‘ ê°€ì¥ ë†’ì€ ìœ„ë„ë¥¼ ê°€ì§„ ì—­ìˆœìœ¼ë¡œ ëª¨ë“  ë„ì‹œë¥¼ ë‚˜ì—´í•˜ì‹­ì‹œì˜¤.\n        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n        CREATE TABLE station (city VARCHAR, lat INTEGER)\n        ### ì‘ë‹µ:\n        SELECT city, lat FROM station ORDER BY lat DESC;\n        \"</span><span class=\"hljs-string\">\"\"</span>,\n        <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n        ### ì§€ì‹œì‚¬í•­ :\n        'ê° ì„ ìˆ˜ê°€ 20ì  ì´ìƒ ë° 10ì  ë¯¸ë§Œì„ ê°€ì§€ê³  ìˆìœ¼ë©° ìƒìœ„ 10ìœ„ ì•ˆì— ìˆëŠ” í¬ì§€ì…˜ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\n        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n        CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\n        ### ì‘ë‹µ:\n        SELECT POSITION, Points, Ranking\n        FROM player\n        WHERE Points > 20 AND Points &#x3C; 10 AND Ranking IN (1,2,3,4,5,6,7,8,9,10)\n        \"</span><span class=\"hljs-string\">\"\"</span>,\n        <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n        ### ì§€ì‹œì‚¬í•­ :\n        ë…¸ë˜ë¥¼ ê°€ì¥ ë§ì´ ì—°ì£¼í•œ ë°´ë“œ ë§´ë²„ì˜ ì´ë¦„ì„ ì°¾ì•„ë³´ì„¸ìš”.\n        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n        CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)\n        ### ì‘ë‹µ:\n        SELECT b.firstname\n        FROM Band b\n        JOIN Performance p ON b.id = p.bandmate\n        GROUP BY b.firstname\n        ORDER BY COUNT(*) DESC\n        LIMIT 1;\n        \"</span><span class=\"hljs-string\">\"\"</span>\n    ]\n\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(len(prompt)):\n      model_inputs = tokenizer(prompt[i], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(<span class=\"hljs-string\">\"cuda:0\"</span>)\n      start_time = time.time()\n      output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n      duration += <span class=\"hljs-built_in\">float</span>(time.time() - start_time)\n      total_length += len(output)\n      tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n      <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"í”„ë¡¬í”„íŠ¸ --- %s í† í°/ì´ˆ ---\"</span> % (tok_sec_prompt))\n      <span class=\"hljs-built_in\">print</span>(print_gpu_utilization())\n      <span class=\"hljs-built_in\">print</span>(tokenizer.decode(output, skip_special_tokens=False))\n\n    tok_sec = round(total_length/duration,3)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"í‰ê·  --- %s í† í°/ì´ˆ ---\"</span> % (tok_sec))\n\n    <span class=\"hljs-comment\"># Fine-tuning</span>\n\n    base_model_id = <span class=\"hljs-string\">\"microsoft/Phi-3-mini-4k-instruct\"</span>\n\n    tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_eos_token=True, use_fast=True, max_length=250)\n    tokenizer.padding_side = <span class=\"hljs-string\">'right'</span>\n    tokenizer.pad_token = tokenizer.eos_token\n\n    compute_dtype = getattr(torch, <span class=\"hljs-string\">\"float16\"</span>) <span class=\"hljs-comment\"># Ampere (ë˜ëŠ” ìµœì‹ ) GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° bfloat16ë¡œ ë³€ê²½</span>\n    bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=<span class=\"hljs-string\">\"nf4\"</span>,\n            bnb_4bit_compute_dtype=compute_dtype,\n            bnb_4bit_use_double_quant=True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n              base_model_id, trust_remote_code=True, quantization_config=bnb_config, revision=<span class=\"hljs-string\">\"refs/pr/23\"</span>, device_map={<span class=\"hljs-string\">\"\"</span>: 0}, torch_dtype=<span class=\"hljs-string\">\"auto\"</span>, flash_attn=True, flash_rotary=True, fused_dense=True\n    )\n    <span class=\"hljs-built_in\">print</span>(print_gpu_utilization())\n\n    model = prepare_model_for_kbit_training(model)\n</code></pre>\n<ol start=\"10\">\n<li>LoRA ë§¤ê°œë³€ìˆ˜</li>\n</ol>\n<pre><code class=\"hljs language-js\">peft_config = <span class=\"hljs-title class_\">LoraConfig</span>(\n            lora_alpha=<span class=\"hljs-number\">16</span>,\n            lora_dropout=<span class=\"hljs-number\">0.05</span>,\n            r=<span class=\"hljs-number\">16</span>,\n            bias=<span class=\"hljs-string\">\"none\"</span>,\n            task_type=<span class=\"hljs-string\">\"CAUSAL_LM\"</span>,\n          target_modules=[\n            <span class=\"hljs-string\">'q_proj'</span>,\n            <span class=\"hljs-string\">'k_proj'</span>,\n            <span class=\"hljs-string\">'v_proj'</span>,\n            <span class=\"hljs-string\">'dense'</span>,\n            <span class=\"hljs-string\">'fc1'</span>,\n            <span class=\"hljs-string\">'fc2'</span>,\n        ])\n</code></pre>\n<ol start=\"9\">\n<li>Training Parameters</li>\n</ol>\n<pre><code class=\"hljs language-js\">training_arguments = <span class=\"hljs-title class_\">TrainingArguments</span>(\n            output_dir=<span class=\"hljs-string\">\"./phi3-results\"</span>,\n            save_strategy=<span class=\"hljs-string\">\"epoch\"</span>,\n            per_device_train_batch_size=<span class=\"hljs-number\">4</span>,\n            gradient_accumulation_steps=<span class=\"hljs-number\">12</span>,\n            log_level=<span class=\"hljs-string\">\"debug\"</span>,\n            save_steps=<span class=\"hljs-number\">100</span>,\n            logging_steps=<span class=\"hljs-number\">25</span>,\n            learning_rate=<span class=\"hljs-number\">1e-4</span>,\n            eval_steps=<span class=\"hljs-number\">50</span>,\n            optim=<span class=\"hljs-string\">'paged_adamw_8bit'</span>,\n            fp16=<span class=\"hljs-title class_\">True</span>, #change to bf16 <span class=\"hljs-keyword\">if</span> are using an <span class=\"hljs-title class_\">Ampere</span> <span class=\"hljs-variable constant_\">GPU</span>\n            num_train_epochs=<span class=\"hljs-number\">1</span>,\n            max_steps=<span class=\"hljs-number\">400</span>,\n            warmup_steps=<span class=\"hljs-number\">100</span>,\n            lr_scheduler_type=<span class=\"hljs-string\">\"linear\"</span>,\n            seed=<span class=\"hljs-number\">42</span>)\n</code></pre>\n<ol start=\"10\">\n<li>Data Prepare for the training</li>\n</ol>\n<pre><code class=\"hljs language-js\">train_dataset = instruct_tune_dataset.<span class=\"hljs-title function_\">map</span>(batched=<span class=\"hljs-title class_\">True</span>, remove_columns=[<span class=\"hljs-string\">'answer'</span>, <span class=\"hljs-string\">'question'</span>, <span class=\"hljs-string\">'context'</span>])\ntrain_dataset\n</code></pre>\n<ol start=\"11\">\n<li>Fine-Tuned</li>\n</ol>\n<pre><code class=\"hljs language-js\">trainer = <span class=\"hljs-title class_\">SFTTrainer</span>(\n    model=model,\n    train_dataset=train_dataset[<span class=\"hljs-string\">\"train\"</span>],\n    #eval_dataset=dataset[<span class=\"hljs-string\">'test'</span>],\n    peft_config=peft_config,\n    dataset_text_field=<span class=\"hljs-string\">\"inputs\"</span>,\n    max_seq_length=<span class=\"hljs-number\">1024</span>,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=<span class=\"hljs-title class_\">False</span>\n)\n\ntrainer.<span class=\"hljs-title function_\">train</span>()\n</code></pre>\n<ol start=\"12\">\n<li>Test inference with the fine-tuned adapter</li>\n</ol>\n<pre><code class=\"hljs language-js\">base_model_id = <span class=\"hljs-string\">\"microsoft/Phi-3-mini-4k-instruct\"</span>\ntokenizer = <span class=\"hljs-title class_\">AutoTokenizer</span>.<span class=\"hljs-title function_\">from_pretrained</span>(base_model_id, use_fast=<span class=\"hljs-title class_\">True</span>)\n\ncompute_dtype = <span class=\"hljs-title function_\">getattr</span>(torch, <span class=\"hljs-string\">\"float16\"</span>)\nbnb_config = <span class=\"hljs-title class_\">BitsAndBytesConfig</span>(\n        load_in_4bit=<span class=\"hljs-title class_\">True</span>,\n        bnb_4bit_quant_type=<span class=\"hljs-string\">\"nf4\"</span>,\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=<span class=\"hljs-title class_\">True</span>,\n)\nmodel = <span class=\"hljs-title class_\">AutoModelForCausalLM</span>.<span class=\"hljs-title function_\">from_pretrained</span>(\n          base_model_id, trust_remote_code=<span class=\"hljs-title class_\">True</span>, quantization_config=bnb_config, device_map={<span class=\"hljs-string\">\"\"</span>: <span class=\"hljs-number\">0</span>}\n)\nadapter = <span class=\"hljs-string\">\"/content/phi3-results/checkpoint-400\"</span>\nmodel = <span class=\"hljs-title class_\">PeftModel</span>.<span class=\"hljs-title function_\">from_pretrained</span>(model, adapter)\n</code></pre>\n<ol start=\"13\">\n<li>ìˆ˜í–‰í•˜ê¸°</li>\n</ol>\n<pre><code class=\"hljs language-js\">database_schema = <span class=\"hljs-string\">'CREATE TABLE station (city VARCHAR, lat INTEGER)'</span>\nuser_question = <span class=\"hljs-string\">\"List all the cities in a decreasing order of each city's stations' highest latitude.\"</span>\n\nprompt_template = f<span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{user_question}\nDatabase Schema:\n{database_schema}\n### Response:\n\"</span><span class=\"hljs-string\">\"\"</span>\n\nquestion = <span class=\"hljs-string\">\"'What are the positions with both players having more than 20 points and less than 10 points and are in Top 10 ranking\"</span>\ncontext = <span class=\"hljs-string\">\"CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\"</span>\n\nprompt_template1 = f<span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"</span><span class=\"hljs-string\">\"\"</span>\n\ncontext = <span class=\"hljs-string\">''</span><span class=\"hljs-string\">'CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)'</span><span class=\"hljs-string\">''</span>\nquestion = <span class=\"hljs-string\">\"Find the first name of the band mate that has performed in most songs.\"</span>\n\nprompt_template2 = f<span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"</span><span class=\"hljs-string\">\"\"</span>\n\nprompt = []\nprompt.<span class=\"hljs-title function_\">append</span>(prompt_template)\nprompt.<span class=\"hljs-title function_\">append</span>(prompt_template1)\nprompt.<span class=\"hljs-title function_\">append</span>(prompt_template2)\n\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-title function_\">len</span>(prompt)):\n  model_inputs = <span class=\"hljs-title function_\">tokenizer</span>(prompt[i], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).<span class=\"hljs-title function_\">to</span>(<span class=\"hljs-string\">\"cuda:0\"</span>)\n  start_time = time.<span class=\"hljs-title function_\">time</span>()\n  output = model.<span class=\"hljs-title function_\">generate</span>(**model_inputs, max_length=<span class=\"hljs-number\">500</span>, no_repeat_ngram_size=<span class=\"hljs-number\">10</span>, pad_token_id=tokenizer.<span class=\"hljs-property\">eos_token_id</span>, eos_token_id=tokenizer.<span class=\"hljs-property\">eos_token_id</span>)[<span class=\"hljs-number\">0</span>]\n  duration += <span class=\"hljs-title function_\">float</span>(time.<span class=\"hljs-title function_\">time</span>() - start_time)\n  total_length += <span class=\"hljs-title function_\">len</span>(output)\n  tok_sec_prompt = <span class=\"hljs-title function_\">round</span>(<span class=\"hljs-title function_\">len</span>(output)/<span class=\"hljs-title function_\">float</span>(time.<span class=\"hljs-title function_\">time</span>() - start_time),<span class=\"hljs-number\">3</span>)\n  <span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"Prompt --- %s tokens/seconds ---\"</span> % (tok_sec_prompt))\n  <span class=\"hljs-title function_\">print</span>(<span class=\"hljs-title function_\">print_gpu_utilization</span>())\n  <span class=\"hljs-title function_\">print</span>(tokenizer.<span class=\"hljs-title function_\">decode</span>(output, skip_special_tokens=<span class=\"hljs-title class_\">False</span>))\n\ntok_sec = <span class=\"hljs-title function_\">round</span>(total_length/duration,<span class=\"hljs-number\">3</span>)\n<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"Average --- %s tokens/seconds ---\"</span> % (tok_sec))\n</code></pre>\n<ol start=\"14\">\n<li>ëª¨ë¸ ì €ì¥í•˜ê¸°</li>\n</ol>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> locale\n<span class=\"hljs-keyword\">import</span> shutil\n<span class=\"hljs-keyword\">from</span> huggingface_hub <span class=\"hljs-keyword\">import</span> notebook_login\n<span class=\"hljs-keyword\">from</span> google.<span class=\"hljs-property\">colab</span> <span class=\"hljs-keyword\">import</span> drive\n\n# <span class=\"hljs-title class_\">Set</span> the preferred encoding to <span class=\"hljs-variable constant_\">UTF</span>-<span class=\"hljs-number\">8</span>\nlocale.<span class=\"hljs-property\">getpreferredencoding</span> = <span class=\"hljs-attr\">lambda</span>: <span class=\"hljs-string\">\"UTF-8\"</span>\n\n# <span class=\"hljs-title class_\">Log</span> <span class=\"hljs-keyword\">in</span> to the notebook\n<span class=\"hljs-title function_\">notebook_login</span>()\n\n# <span class=\"hljs-title class_\">Push</span> the fine-tuned adapter to the <span class=\"hljs-title class_\">Hugging</span> <span class=\"hljs-title class_\">Face</span> <span class=\"hljs-title class_\">Hub</span>\ntrainer.<span class=\"hljs-title function_\">push_to_hub</span>(commit_message=<span class=\"hljs-string\">\"fine-tuned adapter\"</span>)\n\n# <span class=\"hljs-title class_\">Mount</span> <span class=\"hljs-title class_\">Google</span> <span class=\"hljs-title class_\">Drive</span>\ndrive.<span class=\"hljs-title function_\">mount</span>(<span class=\"hljs-string\">'/content/drive'</span>)\n\n# <span class=\"hljs-title class_\">Move</span> the trained model to <span class=\"hljs-title class_\">Google</span> <span class=\"hljs-title class_\">Drive</span>\nshutil.<span class=\"hljs-title function_\">move</span>(<span class=\"hljs-string\">'/content/phi3-results'</span>, <span class=\"hljs-string\">'/content/drive/MyDrive/PHI-3'</span>)\n\n# <span class=\"hljs-title class_\">Load</span> the trained model\ntrained_model = <span class=\"hljs-title class_\">AutoPeftModelForCausalLM</span>.<span class=\"hljs-title function_\">from_pretrained</span>(<span class=\"hljs-string\">\"/content/drive/MyDrive/PHI-3/phi3-results/checkpoint-400\"</span>,\n                                                         low_cpu_mem_usage=<span class=\"hljs-title class_\">True</span>,\n                                                         return_dict=<span class=\"hljs-title class_\">True</span>,\n                                                         torch_dtype=torch.<span class=\"hljs-property\">float16</span>,\n                                                         device_map=<span class=\"hljs-string\">'auto'</span>,)\n\n# <span class=\"hljs-title class_\">Merge</span> and unload the trained model\nlora_merged_model = trained_model.<span class=\"hljs-title function_\">merge_and_unload</span>()\n\n# <span class=\"hljs-title class_\">Save</span> the merged model\nlora_merged_model.<span class=\"hljs-title function_\">save_pretrained</span>(<span class=\"hljs-string\">\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\"</span>, safe_serialization=<span class=\"hljs-title class_\">True</span>)\n\n# <span class=\"hljs-title class_\">Save</span> the tokenizer <span class=\"hljs-keyword\">for</span> the merged model\ntokenizer.<span class=\"hljs-title function_\">save_pretrained</span>(<span class=\"hljs-string\">\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\"</span>)\n\n# <span class=\"hljs-title class_\">Push</span> the merged model to the <span class=\"hljs-title class_\">Hugging</span> <span class=\"hljs-title class_\">Face</span> <span class=\"hljs-title class_\">Hub</span>\nlora_merged_model.<span class=\"hljs-title function_\">push_to_hub</span>(repo_id=<span class=\"hljs-string\">\"\"</span>, commit_message=<span class=\"hljs-string\">\"merged model\"</span>)\n\n# <span class=\"hljs-title class_\">Push</span> the tokenizer to the <span class=\"hljs-title class_\">Hugging</span> <span class=\"hljs-title class_\">Face</span> <span class=\"hljs-title class_\">Hub</span>\ntokenizer.<span class=\"hljs-title function_\">push_to_hub</span>(repo_id=<span class=\"hljs-string\">\"\"</span>, commit_message=<span class=\"hljs-string\">\"merged model\"</span>)\n</code></pre>\n<ol start=\"15\">\n<li>Perform Inference on Fine-tuned Model</li>\n</ol>\n<pre><code class=\"hljs language-js\">peft_config = <span class=\"hljs-title class_\">LoraConfig</span>(\n            lora_alpha=<span class=\"hljs-number\">16</span>,\n            lora_dropout=<span class=\"hljs-number\">0.05</span>,\n            r=<span class=\"hljs-number\">16</span>,\n            bias=<span class=\"hljs-string\">\"none\"</span>,\n            task_type=<span class=\"hljs-string\">\"CAUSAL_LM\"</span>,\n    )\n\npeft_model_id = <span class=\"hljs-string\">\"username/phi3-results\"</span>\nconfig = peft_config.<span class=\"hljs-title function_\">from_pretrained</span>(peft_model_id)\n\nmodel = <span class=\"hljs-title class_\">AutoModelForCausalLM</span>.<span class=\"hljs-title function_\">from_pretrained</span>(config.<span class=\"hljs-property\">base_model_name_or_path</span>,\n                                             return_dict=<span class=\"hljs-title class_\">True</span>,\n                                             load_in_4bit=<span class=\"hljs-title class_\">True</span>,\n                                             device_map=<span class=\"hljs-string\">\"auto\"</span>,\n                                             )\n\ntokenizer = <span class=\"hljs-title class_\">AutoTokenizer</span>.<span class=\"hljs-title function_\">from_pretrained</span>(peft_model_id)\n\nmodel = <span class=\"hljs-title class_\">PeftModel</span>.<span class=\"hljs-title function_\">from_pretrained</span>(model, peft_model_id)\n\n<span class=\"hljs-title function_\">print</span>(model.<span class=\"hljs-title function_\">get_memory_footprint</span>())\n\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-title function_\">len</span>(prompt)):\n    model_inputs = <span class=\"hljs-title function_\">tokenizer</span>(prompt[i], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).<span class=\"hljs-title function_\">to</span>(<span class=\"hljs-string\">\"cuda:0\"</span>)\n    start_time = time.<span class=\"hljs-title function_\">time</span>()\n    output = model.<span class=\"hljs-title function_\">generate</span>(**model_inputs, max_length=<span class=\"hljs-number\">500</span>, no_repeat_ngram_size=<span class=\"hljs-number\">10</span>, pad_token_id=tokenizer.<span class=\"hljs-property\">eos_token_id</span>, eos_token_id=tokenizer.<span class=\"hljs-property\">eos_token_id</span>)[<span class=\"hljs-number\">0</span>]\n    duration += <span class=\"hljs-title function_\">float</span>(time.<span class=\"hljs-title function_\">time</span>() - start_time)\n    total_length += <span class=\"hljs-title function_\">len</span>(output)\n    tok_sec_prompt = <span class=\"hljs-title function_\">round</span>(<span class=\"hljs-title function_\">len</span>(output)/<span class=\"hljs-title function_\">float</span>(time.<span class=\"hljs-title function_\">time</span>() - start_time), <span class=\"hljs-number\">3</span>)\n    <span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"Prompt --- %s tokens/seconds ---\"</span> % (tok_sec_prompt))\n    <span class=\"hljs-title function_\">print</span>(<span class=\"hljs-title function_\">print_gpu_utilization</span>())\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"RESPONSE:\\n {tokenizer.decode(output, skip_special_tokens=False)[len(prompt[i]):].split('&#x3C;/')[0]}\"</span>)\n\ntok_sec = <span class=\"hljs-title function_\">round</span>(total_length/duration, <span class=\"hljs-number\">3</span>)\n<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"Average --- %s tokens/seconds ---\"</span> % (tok_sec))\n</code></pre>\n<h1>Conclusion</h1>\n<p>ìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ SQL ì¿¼ë¦¬ ì—”ì§„ì˜ ê²°í•©ì€ ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ê²ƒì„ ë” ì‰½ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ì „ì—ëŠ” SQLì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ê°€ í•„ìš”í–ˆê¸° ë•Œë¬¸ì— ë§ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Mistral 7Bì™€ Microsoft Phi-3ì™€ ê°™ì€ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì´ë¥¼ ë°”ê¿¨ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ì¿¼ë¦¬ë¡œ ì‹ ì†í•˜ê²Œ ë³€í™˜í•˜ì—¬, ë°©ëŒ€í•œ SQL ì „ë¬¸ ì§€ì‹ì´ í•„ìš” ì—†ê²Œ í–ˆìŠµë‹ˆë‹¤.</p>\n<p>Mistral 7Bì™€ Microsoft Phi-3ëŠ” NLP ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ” íƒì›”í•œ ëª¨ë¸ë“¤ì…ë‹ˆë‹¤. ê·¸ë“¤ì€ Grouped-Query Attentionê³¼ Sliding Window Attentionê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ê°–ì¶”ì–´ ë”ìš± íš¨ìœ¨ì ì…ë‹ˆë‹¤. í¬ê¸°ê°€ ì‘ì€ Microsoft Phi-3ë„ NLP ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì—ì„œ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¸ìš°ë©°, ë³µì¡í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë” í° ëª¨ë¸ë“¤ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.</p>\n<p>ì˜¤í”ˆ ì†ŒìŠ¤ LLMsë¥¼ ê³ ê¸‰ ë¶„ì„ í”Œë«í¼ê³¼ AI ì‹œìŠ¤í…œì— í†µí•©í•¨ìœ¼ë¡œì¨ ê¸°ì—…ì€ ì†ì‰½ê²Œ í†µì°°ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ê¸ˆìœµ, ê±´ê°• ê´€ë¦¬, ì „ì ìƒê±°ë˜ì™€ ê°™ì€ ì‚°ì—…ë“¤ì´ ë°ì´í„° ê¸°ë°˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë°©ì‹ì„ ë³€í™”ì‹œì¼°ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ ë‹¤ì–‘í•œ ë¶€ë¬¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ìƒë‹¹í•˜ë©° í˜ì‹ ê³¼ ë³€í˜ì„ ì´‰ì§„í–ˆìŠµë‹ˆë‹¤.</p>\n<p>NLPì™€ SQLì˜ ìœµí•©ì„ í†µí•´ ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” ë°ì´í„° ì ‘ê·¼ì„ ë¯¼ì£¼í™”ì‹œí‚¤ê³  íš¨ìœ¨ì„±, ìƒì‚°ì„±, ê¸°ì—… ì„±ê³µì„ ì´‰ì§„í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë°ì´í„° ìì‚°ì˜ ìµœëŒ€ ì ì¬ë ¥ì„ ë°œíœ˜í•˜ë„ë¡ í—ˆìš©í•˜ì—¬ ì´í•´ë‹¹ì‚¬ìë“¤ì´ ì‹¤í–‰ ê°€ëŠ¥í•œ í†µì°°ì„ ì¶”ì¶œí•˜ê¸° ì‰¬ì›Œì§€ê³ , ì—¬ëŸ¬ ë¶€ë¬¸ì—ì„œ íƒêµ¬ì™€ í˜ì‹ ì˜ ë¬¸í™”ë¥¼ ìœ¡ì„±í–ˆìŠµë‹ˆë‹¤.</p>\n<p>ë…¸íŠ¸ë¶: phi3</p>\n<p>ì œ ì´ì „ ğŸ“ ê¸€ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”.</p>\n<h1>ì°¸ê³  ìë£Œ</h1>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/2310.06825.pdf\" rel=\"nofollow\" target=\"_blank\">https://arxiv.org/pdf/2310.06825.pdf</a></li>\n<li><a href=\"https://artgor.medium.com/paper-review-mistral-7b-6acdf2f3132d\" rel=\"nofollow\" target=\"_blank\">https://artgor.medium.com/paper-review-mistral-7b-6acdf2f3132d</a></li>\n<li><a href=\"https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580\" rel=\"nofollow\" target=\"_blank\">https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580</a></li>\n<li><a href=\"https://www.datacamp.com/tutorial/mistral-7b-tutorial\" rel=\"nofollow\" target=\"_blank\">https://www.datacamp.com/tutorial/mistral-7b-tutorial</a></li>\n<li><a href=\"https://www.analyticsvidhya.com/blog/2023/11/from-gpt-to-mistral-7b-the-exciting-leap-forward-in-ai-conversations/\" rel=\"nofollow\" target=\"_blank\">https://www.analyticsvidhya.com/blog/2023/11/from-gpt-to-mistral-7b-the-exciting-leap-forward-in-ai-conversations/</a></li>\n<li><a href=\"https://medium.com/@rubentak/mistral-7b-the-best-7-billion-parameter\" rel=\"nofollow\" target=\"_blank\">https://medium.com/@rubentak/mistral-7b-the-best-7-billion-parameter</a> llm-yet-8b0aa03016f9</li>\n<li><a href=\"https://clarifai.com/mistralai/completion/models/mistral-7B-Instruc\" rel=\"nofollow\" target=\"_blank\">https://clarifai.com/mistralai/completion/models/mistral-7B-Instruc</a></li>\n<li><a href=\"https://iamgeekydude.com/2023/06/02/alpaca-llm-load-model-using-langchain-hf/\" rel=\"nofollow\" target=\"_blank\">https://iamgeekydude.com/2023/06/02/alpaca-llm-load-model-using-langchain-hf/</a></li>\n<li><a href=\"https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/\" rel=\"nofollow\" target=\"_blank\">https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/</a></li>\n<li><a href=\"https://huggingface.co/microsoft/Phi-3-mini-128k-instruct\" rel=\"nofollow\" target=\"_blank\">https://huggingface.co/microsoft/Phi-3-mini-128k-instruct</a></li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}