{"pageProps":{"post":{"title":"OpenAI의 ChatGPT-4o 좋은 점, 나쁜 점, 그리고 비책능성","description":"","date":"2024-05-23 17:27","slug":"2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible","content":"\n\n![OpenAI GPT-4o](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png)\n\n지난 주, OpenAI가 GPT-4o (\"o는 'onmi'의 약자)의 발표를 했습니다. 놀랍게도, 기대보다는 두려움을 느꼈습니다. 그 느낌이 가시지 않았죠.\n\n테크 분야에서 여성으로서, 디지털 기술, 특히 인공지능이 세상에 긍정적인 영향을 줄 수 있다는 증거가 있습니다. 예를 들어, 새로운 더 효과적이고 덜 독성이 있는 약물을 개발하거나 자동 자막을 통해 접근성을 향상시킬 수 있습니다.\n\n기술 옹호자일 뿐만 아니라 동시에 그에 의해 초래된 임박한 재앙감을 경험하고 있는 이 상반된 감정 때문에 대형(소형 포함) 기술, 인식적 부당한대, 그리고 인공지능 서사에 대해 탐구의 길로 빠졌습니다.\n\n\n<div class=\"content-ad\"></div>\n\n저는 우울주의자였나요? 숨은 러다이트주의자였나요? 아니면 그냥 시야가 좁았을 뿐이었나요?\n\n잠시 동안 되돌아보는 시간을 가졌더니, 빅테크와 다른 스무스한 AI 운영자들이 나를 위해 설치한 덫에 빠지고 있었다는 것을 깨달았어요: 디지털 유사한 유령의 여류적 미래 약속을 살펴보는 나 자신을 의심했던 것이죠.\n\n그 딜레마의 반대편에서, 저는 기술주의 대 도의미주의의 잘못된 이분법을 탐색하는 데 AI 대화에 내 기여가 중요하다는 믿음이 강해진 것 같아요.\n\n이 기사에서 OpenAI가 어떻게 중요한 기여자인지 보여주면서 그 대화를 극단적으로 이혁하는 데 어떤 역할을 하는지를 살펴봅니다:\n\n<div class=\"content-ad\"></div>\n\n- ChatGPT-4o 발표 소식에 대한 내용 — 그리고 그렇지 않은 것\n- OpenAI의 작동 방식\n- OpenAI의 안전 기준\n- 최종 책임소재\n\n# ChatGTP-4o: 발표\n\n5월 13일 월요일, OpenAI는 웹사이트에 또 다른 \"업데이트\"를 공개했습니다: ChatGPT-4o.\n\n잘 구성된 발표였어요. 그들의 웹사이트에 있는 공지에는 CTO인 Mira Murati가 진행하는 20분 이상의 비디오가 포함되어 있습니다. 그녀는 새로운 기능에 대해 논의하고 다른 OpenAI 동료들과 함께 몇 가지 데모를 수행합니다. 응용 프로그램 예시와 모델 평가, 안전, 가용성과 같은 주제에 대한 매우 고수준의 정보가 있는 작은 동영상과 스크린샷도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n저는 ChatGPT-4o와 OpenAI에 대한 공식 발표를 통해 배운 내용을 공유할게요.\n\n## 새로운 기능\n\n- 이용의 민주화 — 무료로 더 많은 기능을 사용하고 API 접속 비용이 50% 저렴해집니다.\n- 다중모드 — 텍스트, 오디오, 이미지의 어떤 조합도 생성합니다.\n- 속도 — 2배 빠른 응답속도.\n- 비영어권 언어 처리 개선 — 50개 언어를 다루며 이는 세계 인터넷 인구의 97%에 해당한다고 주장합니다.\n\n## OpenAI의 대형 기술 플레이북 채택\n\n<div class=\"content-ad\"></div>\n\n이 “업데이트”는 인공지능 회사가 실리콘밸리에서 “보스”처럼 보이는 방법에 대해 알아야 한다는 메모를받았음을 보여줍니다.\n\n1. 성역할 강화\n   발표 당일 Sam Altman은 X에 떼어난 단어를 게시했습니다. - “her” - 2013년 영화를 참조한 것입니다. 이 영화에는 Joaquin Phoenix가 주연으로 나오며 남성이 미래 버전의 Siri 또는 Alexa에게 반하는 모습을 보여줍니다. Siri 또는 Alexa는 Scarlett Johansson의 목소리로 연기되었습니다.\n\n이것은 우연이 아닙니다. ChatGPT-4o의 목소리는 뚜렷하게 여성적이고 애정적이며 데모에서는 남성 목소리가 들릴 수 있는 비디오를 한 개만 찾을 수 있었습니다.\n\n불행하게도 60년 전의 챗봇 ELIZA 이후에는 많은 변화가 일어나지 않았습니다...\n\n<div class=\"content-ad\"></div>\n\n2. 인간화\n\nOpenAI는 ChatGPT-4o의 능력을 묘사할 때 \"이성\"과 \"이해\"와 같은 본질적으로 인간적인 기술을 사용하여 그들의 모델이 인간과 같음을 강조합니다.\n\n3. 자기 규제 및 자가 평가\n   120년 이상의 경험을 보유한 미국 국립표준기술연구소(NIST)는 AI 리스크를 평가하고 관리하기 위한 프레임워크를 개발했습니다. 다른 다양한 이해관계자 기관들도 각자의 프레임워크를 개발하고 공유했습니다.\n\n그러나 OpenAI는 AI 규제가 필요하다고 주장하면서도 GPT-4o를 그들의 준비 프레임워크에 따라 평가하고 자발적 약속을 준수하기로 선택했습니다.\n\n<div class=\"content-ad\"></div>\n\n게이트키퍼피드백\nOpenAI는 “그들”이 사이버 보안, CBRN (화학, 생물학, 방사선, 핵 위협), 설득력 및 모델 자율성의 평가에서 GPT-4o가 추가적으로 수행된 테스트의 추가 증거 없이 중간 위험 이상을 얻지 못했다는 것을 말할 때, 안심하고 계속 진행해야 한다고 말합니다.\n\n또한, 오픈AI는 사회심리학, 편향 및 공정성, 그리고 정보 오해와 같은 영역에서 70명 이상의 외부 전문가들과 함께 외부 레드팀을 진행했고, 새로 추가된 다양한 모달리티에 의해 도입되거나 증폭된 위험을 식별했습니다.\n\n![이미지](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_1.png)\n\n전문분야 목록을 보면 역사, 지리 또는 철학과 같은 영역을 볼 수 없습니다. 또한, 70명 이상의 전문가가 누구인지 또는 그들이 이 행성에 살고 있는 80억 명의 사람들 사이의 다양성을 어떻게 다룰 수 있는지도 볼 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n요약하면, OpenAI는 모두를 위해 개발하지만 몇 명의 선택된 사람들의 피드백만을 토대로 합니다.\n\n5. 책임 면제\n   약의 안내 책자에 다음과 같은 문구를 읽어볼 수 있다고 상상해보세요.\n\n하지만 OpenAI가 최근 발표한 내용에는 바로 그런 내용이 포함되어 있습니다.\n\n뿐만 아니라, 우리를 베타 테스터로서 초대합니다.\n\n<div class=\"content-ad\"></div>\n\n문제가 뭘까요? 제품은 이미 세상에 공개되었습니다.\n\n6. 감정 \"추측\"의 유사과학을 홍보하는 것\n   더미에서 ChatGPT-4o에게 발표자 중 한 명의 감정을 예측하도록 요청합니다. 모델은 계속해서 그의 얼굴에서 보이는 것을 기반으로 개인의 감정 상태를 추측하는 것으로 들어갑니다. 이는 궁극적으로 미소라고 나타나는 것을 주장합니다.\n\n![이미지](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_2.png)\n\n그러나 얼굴 표정이 감정을 나타낸다는 믿음을 뒤엎는 과학적 연구가 많이 있습니다. 게다가, AI 공급업체들이 그 수작을 통해 이익을 얻는 것에 대해 과학자들이 비판을 퍼부었습니다.\n\n<div class=\"content-ad\"></div>\n\nOpenAI가 그 오해들에 대해 마케팅 수단으로 활용하는 대신 대중에게 그것들에 대해 교육을 돕는 것을 기대해야 할 텐데요?\n\n## 그들이 말하지 않았지만, 나는 그들이 했으면 하는 것들\n\n- 정부와 협력하여 능력/모델을 규제하고 전개하는 노력의 신호.\n- 에너지 효율성, 수소소비량 또는 CO2 배출에 대한 지속 가능성 기준.\n- ChatGPT-4o가 무료가 아니라는 인정 - 우리는 데이터에 대한 액세스 비용을 지불할 것입니다.\n- OpenAI의 시간표 및 향후 릴리스에서 기대되는 기능. 나는 20년 동안 소프트웨어 개발을 진지하게 다루는 소프트웨어 회사와 고객들과 공유하는 로드맵 및 릴리스 일정을 통해 구현과 채택을 돕는 조직에서 일해왔습니다.\n- 제품을 사용하는 수십억 명의 사람들이 경쟁사를 못 이길 것을 희망하는 것 이외의 신뢰할 만한 비즈니스 모델.\n\n하지만, 이것만으로는 제가 느끼는 불안한 기분을 설명하지 못했습니다. 패턴이 그것을 설명했어요.\n\n<div class=\"content-ad\"></div>\n\n# OpenAI의 청사진: 이건 기능이지 결함이 아니에요\n\nOpenAI의 모든 제품 발표는 비슷해요: 그들이 일방적으로 결정한 일들을 우리에게 알리고, 그것이 우리 삶에 어떻게 영향을 미칠지 설명하면서 우리가 그것을 막을 수 없다고 말해요.\n\n그 기분... 전 어디서 느꼈었지? 두 가지 사례가 떠올랐어요.\n\n- 트럼프 대통령 임기\n- 코로나19 전염병\n\n<div class=\"content-ad\"></div>\n\n이 두 가지 요소 - 어느 순간 얽혀 있는 것처럼 - 저와 수백만 명의 사람들의 삶이 인류에 대한 배려가 없는 무언가/누군가의 변덕에 위험에 처해 있다는 느낌을 일으킨다.\n\n구체적으로는 다음과 같은 느낌이었습니다.\n\n- 통제의 부재 - 각각의 트윗이나 각각의 감염 차트마다 엄청난 고통과 변화를 나타낼 수 있음을 의미했습니다.\n- 휴식의 여지가 없었습니다 - 모든 것이 평온해 보일 때라도, 트윗이 없거나 전염병이 감소하지 않을 때에도, 저는 떨어질 다른 부분을 기다렸습니다.\n\nOpenAI로 돌아와서, 지난 세 달 동안 ChatGPT-4o의 공개를 위해 따르던 동일한 방식의 사례들을 몇 가지 보았습니다. 저는 그 중 세 가지를 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## OpenAI Releases Sora\n\n2월 15일, OpenAI가 텍스트에서 비디오로 변환하는 모델인 Sora를 소개했습니다.\n\n간략히 요약하면,\n\n- 다른 공지와 마찬가지로, \"이해하다\"나 \"파악하다\"와 같은 단어는 Sora의 능력을 의인화하는 것을 나타냅니다.\n- \"Sora가 해로운 영역을 평가하는 레드 팀원에게 이용 가능해지고 있다\"는 것에 대해 우리는 확언받았습니다.\n- 이 새로운 기술의 긍정적인 사용 사례를 식별하고 세계적인 정책 입안자, 교육자 및 예술가들과의 대화가 나준에 있을 것\"이라고 우리는 나중에만 알게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n물론, 우리는 Sora를 약 한 달도 되지 않아, Taylor Swift의 비동의 성적 수치화된 딥페이크 영상이 X에서 확산된 후에 공개한 것은 무모했다는 것에도 경고받았습니다. 이는 유명인 문제가 아니었습니다 - 딥페이크의 96%가 비동의 성적 성향이며, 그 중 99%는 여성을 대상으로 합니다.\n\n여성을 굴욕시키고, 침묵시키고, 대상화하기 위한 콘텐츠를 쉽게 생성할 수 있도록 하는 도구를 개발할 때 안전 문제에 대해 이야기하는 OpenAI가 어떻게 할 수가 있나요?\n\n## OpenAI Releases Voice Engine\n\n<div class=\"content-ad\"></div>\n\n3월 29일, OpenAI가 \"사용자 지정 음성을 만드는 모델인 Voice Engine의 소형 미리보기에서 얻은 교훈\"을 공유하는 블로그를 게시했습니다.\n\n이 기사에서는 합성 음성 남용의 가능성으로 인해 \"보다 넓은 배포에 대해 신중하고 정보를 제공하는 접근 방식\"을 취하고 있음을 우리에게 안심시켰으며, 모델을 언제 공개할지에 대한 결정은 일방적으로 내릴 것이라고 알렸습니다.\n\n그리고 발표 끝 부분에서 OpenAI는 \"Voice Engine\"으로 인해 우리가 해야 하는 일이나 그만 두어야 하는 일에 대해 경고했습니다. 그 목록에는 음성 기반 인증을 은행 계좌에 접속하기 위한 보안 조치로 사용하던 것을 폐기하고, 음향-비주얼 콘텐츠의 출처를 추적하는 기술 개발을 가속화해야 한다는 내용이 포함되어 있습니다.\n\n## OpenAI, AI 에로티카, 과도한 그로티, 모욕 생성 허용\n\n<div class=\"content-ad\"></div>\n\n5월 8일, OpenAI가 ChatGPT 내의 AI 기술이 어떻게 행동해야 하는지에 대한 초안 가이드라인을 발표했고, '책임 있게' 음란 콘텐츠를 생성하는 방법을 탐구 중이라고 밝혔습니다.\n\n이 제안은 OpenAI가 AI 도구를 개발하는 방식에 대해 논의하는 OpenAI 문서의 일부였습니다.\n\nOpenAI 문서에서 작업한 OpenAI 직원 Joanne Jang은 출력물이 음란물로 간주되는지 여부는 \"당신의 정의에 달렸다\"며 추가로 \"우리가 가지길 원하는 정확히 이 대화들입니다\"라고 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n비반 키드론, 영국 파벤치 피어이자 아동 온라인 안전을 위한 캠페인가, 가 말한 것에 동의할 수밖에 없어요.\n\n## OpenAI 공식\n\n![Image](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_3.png)\n\n패턴을 봤나요?\n\n<div class=\"content-ad\"></div>\n\n- 이기적인 행동\n- 예측할 수 없음\n- 자기 규제\n- 무모함\n- 기술적 가부장주의\n\n# OpenAI에서 문제가 있다\n\nChatGPT-4o 발표 후, 안전 담당 상급 OpenAI 직원 두 명이 회사를 떠나기로 결정했다.\n\n먼저 OpenAI 공동 창업자이자 최고 과학자인 이리야 숫스케버는 X에 떠났다고 게시했다.\n\n<div class=\"content-ad\"></div>\n\n그날 나중에, Superalignment의 공동 리더이자 OpenAI의 임원인 삶 스쿠버와 함께 일하는 얀 라이케가 사임을 발표했습니다.\n\nX 쓰레드에서 그는 다음과 같이 말했습니다.\n\n안전, 정책 및 지배 영역에서 OpenAI를 떠나는 직원 목록 중 마지막으로 떠나는 사람들입니다.\n\nOpenAI 안전 리더들이 배를 떠나면 우리에게 무슨 의미가 될까요?\n\n<div class=\"content-ad\"></div>\n\n# 우리 정치인들에게 모든 책임이 있어\n\nLeike의 트윗에 대답하기 위해, OpenAI가 신뢰할 만하고 윤리적이며 포용적인 AI 프레임워크를 개발하는 책임을 맡기고 싶지 않아요.\n\n첫째, 회사가 지구 규모의 안전을 자사 이익보다 우선시할 능력이나 기질을 보여주지 않았기 때문이에요.\n\n둘째, 그건 그들의 역할이 아니기 때문에요.\n\n<div class=\"content-ad\"></div>\n\n그 역할은 누구의 것인가요? 우리 정치 대표자들이 정부 기관을 규제하도록 요구하며, 이에 따라 그러한 프레임워크를 개발하고 시행해야 합니다.\n\n나쁘게도 지금까지 정치인들의 자아가 방해 요인이 되었습니다.\n\n- AI에 대한 이해를 거부하는 것.\n- 장기적인 글로벌 AI 규제를 다른 국가들과 협력하여 개발하는 대신 자신들과 당의 일정을 우선시하는 것.\n- 현재의 해를 희망의 혁신 약속을 위하여 덜어주는 AI FOMO에 실패하는 것.\n\n요약하면, 선출된 대표들은 Sam과 팀과 친해지는 것을 그만두고 AI가 모두를 위해 작동하고 미래 세대의 생존을 위협하지 않도록하는 규제적 프레임워크를 시행해야 합니다.\n","ogImage":{"url":"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png"},"coverImage":"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png","tag":["Tech"],"readingTime":8},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png\" alt=\"OpenAI GPT-4o\"></p>\n<p>지난 주, OpenAI가 GPT-4o (\"o는 'onmi'의 약자)의 발표를 했습니다. 놀랍게도, 기대보다는 두려움을 느꼈습니다. 그 느낌이 가시지 않았죠.</p>\n<p>테크 분야에서 여성으로서, 디지털 기술, 특히 인공지능이 세상에 긍정적인 영향을 줄 수 있다는 증거가 있습니다. 예를 들어, 새로운 더 효과적이고 덜 독성이 있는 약물을 개발하거나 자동 자막을 통해 접근성을 향상시킬 수 있습니다.</p>\n<p>기술 옹호자일 뿐만 아니라 동시에 그에 의해 초래된 임박한 재앙감을 경험하고 있는 이 상반된 감정 때문에 대형(소형 포함) 기술, 인식적 부당한대, 그리고 인공지능 서사에 대해 탐구의 길로 빠졌습니다.</p>\n<p>저는 우울주의자였나요? 숨은 러다이트주의자였나요? 아니면 그냥 시야가 좁았을 뿐이었나요?</p>\n<p>잠시 동안 되돌아보는 시간을 가졌더니, 빅테크와 다른 스무스한 AI 운영자들이 나를 위해 설치한 덫에 빠지고 있었다는 것을 깨달았어요: 디지털 유사한 유령의 여류적 미래 약속을 살펴보는 나 자신을 의심했던 것이죠.</p>\n<p>그 딜레마의 반대편에서, 저는 기술주의 대 도의미주의의 잘못된 이분법을 탐색하는 데 AI 대화에 내 기여가 중요하다는 믿음이 강해진 것 같아요.</p>\n<p>이 기사에서 OpenAI가 어떻게 중요한 기여자인지 보여주면서 그 대화를 극단적으로 이혁하는 데 어떤 역할을 하는지를 살펴봅니다:</p>\n<ul>\n<li>ChatGPT-4o 발표 소식에 대한 내용 — 그리고 그렇지 않은 것</li>\n<li>OpenAI의 작동 방식</li>\n<li>OpenAI의 안전 기준</li>\n<li>최종 책임소재</li>\n</ul>\n<h1>ChatGTP-4o: 발표</h1>\n<p>5월 13일 월요일, OpenAI는 웹사이트에 또 다른 \"업데이트\"를 공개했습니다: ChatGPT-4o.</p>\n<p>잘 구성된 발표였어요. 그들의 웹사이트에 있는 공지에는 CTO인 Mira Murati가 진행하는 20분 이상의 비디오가 포함되어 있습니다. 그녀는 새로운 기능에 대해 논의하고 다른 OpenAI 동료들과 함께 몇 가지 데모를 수행합니다. 응용 프로그램 예시와 모델 평가, 안전, 가용성과 같은 주제에 대한 매우 고수준의 정보가 있는 작은 동영상과 스크린샷도 있습니다.</p>\n<p>저는 ChatGPT-4o와 OpenAI에 대한 공식 발표를 통해 배운 내용을 공유할게요.</p>\n<h2>새로운 기능</h2>\n<ul>\n<li>이용의 민주화 — 무료로 더 많은 기능을 사용하고 API 접속 비용이 50% 저렴해집니다.</li>\n<li>다중모드 — 텍스트, 오디오, 이미지의 어떤 조합도 생성합니다.</li>\n<li>속도 — 2배 빠른 응답속도.</li>\n<li>비영어권 언어 처리 개선 — 50개 언어를 다루며 이는 세계 인터넷 인구의 97%에 해당한다고 주장합니다.</li>\n</ul>\n<h2>OpenAI의 대형 기술 플레이북 채택</h2>\n<p>이 “업데이트”는 인공지능 회사가 실리콘밸리에서 “보스”처럼 보이는 방법에 대해 알아야 한다는 메모를받았음을 보여줍니다.</p>\n<ol>\n<li>성역할 강화\n발표 당일 Sam Altman은 X에 떼어난 단어를 게시했습니다. - “her” - 2013년 영화를 참조한 것입니다. 이 영화에는 Joaquin Phoenix가 주연으로 나오며 남성이 미래 버전의 Siri 또는 Alexa에게 반하는 모습을 보여줍니다. Siri 또는 Alexa는 Scarlett Johansson의 목소리로 연기되었습니다.</li>\n</ol>\n<p>이것은 우연이 아닙니다. ChatGPT-4o의 목소리는 뚜렷하게 여성적이고 애정적이며 데모에서는 남성 목소리가 들릴 수 있는 비디오를 한 개만 찾을 수 있었습니다.</p>\n<p>불행하게도 60년 전의 챗봇 ELIZA 이후에는 많은 변화가 일어나지 않았습니다...</p>\n<ol start=\"2\">\n<li>인간화</li>\n</ol>\n<p>OpenAI는 ChatGPT-4o의 능력을 묘사할 때 \"이성\"과 \"이해\"와 같은 본질적으로 인간적인 기술을 사용하여 그들의 모델이 인간과 같음을 강조합니다.</p>\n<ol start=\"3\">\n<li>자기 규제 및 자가 평가\n120년 이상의 경험을 보유한 미국 국립표준기술연구소(NIST)는 AI 리스크를 평가하고 관리하기 위한 프레임워크를 개발했습니다. 다른 다양한 이해관계자 기관들도 각자의 프레임워크를 개발하고 공유했습니다.</li>\n</ol>\n<p>그러나 OpenAI는 AI 규제가 필요하다고 주장하면서도 GPT-4o를 그들의 준비 프레임워크에 따라 평가하고 자발적 약속을 준수하기로 선택했습니다.</p>\n<p>게이트키퍼피드백\nOpenAI는 “그들”이 사이버 보안, CBRN (화학, 생물학, 방사선, 핵 위협), 설득력 및 모델 자율성의 평가에서 GPT-4o가 추가적으로 수행된 테스트의 추가 증거 없이 중간 위험 이상을 얻지 못했다는 것을 말할 때, 안심하고 계속 진행해야 한다고 말합니다.</p>\n<p>또한, 오픈AI는 사회심리학, 편향 및 공정성, 그리고 정보 오해와 같은 영역에서 70명 이상의 외부 전문가들과 함께 외부 레드팀을 진행했고, 새로 추가된 다양한 모달리티에 의해 도입되거나 증폭된 위험을 식별했습니다.</p>\n<p><img src=\"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_1.png\" alt=\"이미지\"></p>\n<p>전문분야 목록을 보면 역사, 지리 또는 철학과 같은 영역을 볼 수 없습니다. 또한, 70명 이상의 전문가가 누구인지 또는 그들이 이 행성에 살고 있는 80억 명의 사람들 사이의 다양성을 어떻게 다룰 수 있는지도 볼 수 없습니다.</p>\n<p>요약하면, OpenAI는 모두를 위해 개발하지만 몇 명의 선택된 사람들의 피드백만을 토대로 합니다.</p>\n<ol start=\"5\">\n<li>책임 면제\n약의 안내 책자에 다음과 같은 문구를 읽어볼 수 있다고 상상해보세요.</li>\n</ol>\n<p>하지만 OpenAI가 최근 발표한 내용에는 바로 그런 내용이 포함되어 있습니다.</p>\n<p>뿐만 아니라, 우리를 베타 테스터로서 초대합니다.</p>\n<p>문제가 뭘까요? 제품은 이미 세상에 공개되었습니다.</p>\n<ol start=\"6\">\n<li>감정 \"추측\"의 유사과학을 홍보하는 것\n더미에서 ChatGPT-4o에게 발표자 중 한 명의 감정을 예측하도록 요청합니다. 모델은 계속해서 그의 얼굴에서 보이는 것을 기반으로 개인의 감정 상태를 추측하는 것으로 들어갑니다. 이는 궁극적으로 미소라고 나타나는 것을 주장합니다.</li>\n</ol>\n<p><img src=\"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_2.png\" alt=\"이미지\"></p>\n<p>그러나 얼굴 표정이 감정을 나타낸다는 믿음을 뒤엎는 과학적 연구가 많이 있습니다. 게다가, AI 공급업체들이 그 수작을 통해 이익을 얻는 것에 대해 과학자들이 비판을 퍼부었습니다.</p>\n<p>OpenAI가 그 오해들에 대해 마케팅 수단으로 활용하는 대신 대중에게 그것들에 대해 교육을 돕는 것을 기대해야 할 텐데요?</p>\n<h2>그들이 말하지 않았지만, 나는 그들이 했으면 하는 것들</h2>\n<ul>\n<li>정부와 협력하여 능력/모델을 규제하고 전개하는 노력의 신호.</li>\n<li>에너지 효율성, 수소소비량 또는 CO2 배출에 대한 지속 가능성 기준.</li>\n<li>ChatGPT-4o가 무료가 아니라는 인정 - 우리는 데이터에 대한 액세스 비용을 지불할 것입니다.</li>\n<li>OpenAI의 시간표 및 향후 릴리스에서 기대되는 기능. 나는 20년 동안 소프트웨어 개발을 진지하게 다루는 소프트웨어 회사와 고객들과 공유하는 로드맵 및 릴리스 일정을 통해 구현과 채택을 돕는 조직에서 일해왔습니다.</li>\n<li>제품을 사용하는 수십억 명의 사람들이 경쟁사를 못 이길 것을 희망하는 것 이외의 신뢰할 만한 비즈니스 모델.</li>\n</ul>\n<p>하지만, 이것만으로는 제가 느끼는 불안한 기분을 설명하지 못했습니다. 패턴이 그것을 설명했어요.</p>\n<h1>OpenAI의 청사진: 이건 기능이지 결함이 아니에요</h1>\n<p>OpenAI의 모든 제품 발표는 비슷해요: 그들이 일방적으로 결정한 일들을 우리에게 알리고, 그것이 우리 삶에 어떻게 영향을 미칠지 설명하면서 우리가 그것을 막을 수 없다고 말해요.</p>\n<p>그 기분... 전 어디서 느꼈었지? 두 가지 사례가 떠올랐어요.</p>\n<ul>\n<li>트럼프 대통령 임기</li>\n<li>코로나19 전염병</li>\n</ul>\n<p>이 두 가지 요소 - 어느 순간 얽혀 있는 것처럼 - 저와 수백만 명의 사람들의 삶이 인류에 대한 배려가 없는 무언가/누군가의 변덕에 위험에 처해 있다는 느낌을 일으킨다.</p>\n<p>구체적으로는 다음과 같은 느낌이었습니다.</p>\n<ul>\n<li>통제의 부재 - 각각의 트윗이나 각각의 감염 차트마다 엄청난 고통과 변화를 나타낼 수 있음을 의미했습니다.</li>\n<li>휴식의 여지가 없었습니다 - 모든 것이 평온해 보일 때라도, 트윗이 없거나 전염병이 감소하지 않을 때에도, 저는 떨어질 다른 부분을 기다렸습니다.</li>\n</ul>\n<p>OpenAI로 돌아와서, 지난 세 달 동안 ChatGPT-4o의 공개를 위해 따르던 동일한 방식의 사례들을 몇 가지 보았습니다. 저는 그 중 세 가지를 살펴보겠습니다.</p>\n<h2>OpenAI Releases Sora</h2>\n<p>2월 15일, OpenAI가 텍스트에서 비디오로 변환하는 모델인 Sora를 소개했습니다.</p>\n<p>간략히 요약하면,</p>\n<ul>\n<li>다른 공지와 마찬가지로, \"이해하다\"나 \"파악하다\"와 같은 단어는 Sora의 능력을 의인화하는 것을 나타냅니다.</li>\n<li>\"Sora가 해로운 영역을 평가하는 레드 팀원에게 이용 가능해지고 있다\"는 것에 대해 우리는 확언받았습니다.</li>\n<li>이 새로운 기술의 긍정적인 사용 사례를 식별하고 세계적인 정책 입안자, 교육자 및 예술가들과의 대화가 나준에 있을 것\"이라고 우리는 나중에만 알게 됩니다.</li>\n</ul>\n<p>물론, 우리는 Sora를 약 한 달도 되지 않아, Taylor Swift의 비동의 성적 수치화된 딥페이크 영상이 X에서 확산된 후에 공개한 것은 무모했다는 것에도 경고받았습니다. 이는 유명인 문제가 아니었습니다 - 딥페이크의 96%가 비동의 성적 성향이며, 그 중 99%는 여성을 대상으로 합니다.</p>\n<p>여성을 굴욕시키고, 침묵시키고, 대상화하기 위한 콘텐츠를 쉽게 생성할 수 있도록 하는 도구를 개발할 때 안전 문제에 대해 이야기하는 OpenAI가 어떻게 할 수가 있나요?</p>\n<h2>OpenAI Releases Voice Engine</h2>\n<p>3월 29일, OpenAI가 \"사용자 지정 음성을 만드는 모델인 Voice Engine의 소형 미리보기에서 얻은 교훈\"을 공유하는 블로그를 게시했습니다.</p>\n<p>이 기사에서는 합성 음성 남용의 가능성으로 인해 \"보다 넓은 배포에 대해 신중하고 정보를 제공하는 접근 방식\"을 취하고 있음을 우리에게 안심시켰으며, 모델을 언제 공개할지에 대한 결정은 일방적으로 내릴 것이라고 알렸습니다.</p>\n<p>그리고 발표 끝 부분에서 OpenAI는 \"Voice Engine\"으로 인해 우리가 해야 하는 일이나 그만 두어야 하는 일에 대해 경고했습니다. 그 목록에는 음성 기반 인증을 은행 계좌에 접속하기 위한 보안 조치로 사용하던 것을 폐기하고, 음향-비주얼 콘텐츠의 출처를 추적하는 기술 개발을 가속화해야 한다는 내용이 포함되어 있습니다.</p>\n<h2>OpenAI, AI 에로티카, 과도한 그로티, 모욕 생성 허용</h2>\n<p>5월 8일, OpenAI가 ChatGPT 내의 AI 기술이 어떻게 행동해야 하는지에 대한 초안 가이드라인을 발표했고, '책임 있게' 음란 콘텐츠를 생성하는 방법을 탐구 중이라고 밝혔습니다.</p>\n<p>이 제안은 OpenAI가 AI 도구를 개발하는 방식에 대해 논의하는 OpenAI 문서의 일부였습니다.</p>\n<p>OpenAI 문서에서 작업한 OpenAI 직원 Joanne Jang은 출력물이 음란물로 간주되는지 여부는 \"당신의 정의에 달렸다\"며 추가로 \"우리가 가지길 원하는 정확히 이 대화들입니다\"라고 말했습니다.</p>\n<p>비반 키드론, 영국 파벤치 피어이자 아동 온라인 안전을 위한 캠페인가, 가 말한 것에 동의할 수밖에 없어요.</p>\n<h2>OpenAI 공식</h2>\n<p><img src=\"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_3.png\" alt=\"Image\"></p>\n<p>패턴을 봤나요?</p>\n<ul>\n<li>이기적인 행동</li>\n<li>예측할 수 없음</li>\n<li>자기 규제</li>\n<li>무모함</li>\n<li>기술적 가부장주의</li>\n</ul>\n<h1>OpenAI에서 문제가 있다</h1>\n<p>ChatGPT-4o 발표 후, 안전 담당 상급 OpenAI 직원 두 명이 회사를 떠나기로 결정했다.</p>\n<p>먼저 OpenAI 공동 창업자이자 최고 과학자인 이리야 숫스케버는 X에 떠났다고 게시했다.</p>\n<p>그날 나중에, Superalignment의 공동 리더이자 OpenAI의 임원인 삶 스쿠버와 함께 일하는 얀 라이케가 사임을 발표했습니다.</p>\n<p>X 쓰레드에서 그는 다음과 같이 말했습니다.</p>\n<p>안전, 정책 및 지배 영역에서 OpenAI를 떠나는 직원 목록 중 마지막으로 떠나는 사람들입니다.</p>\n<p>OpenAI 안전 리더들이 배를 떠나면 우리에게 무슨 의미가 될까요?</p>\n<h1>우리 정치인들에게 모든 책임이 있어</h1>\n<p>Leike의 트윗에 대답하기 위해, OpenAI가 신뢰할 만하고 윤리적이며 포용적인 AI 프레임워크를 개발하는 책임을 맡기고 싶지 않아요.</p>\n<p>첫째, 회사가 지구 규모의 안전을 자사 이익보다 우선시할 능력이나 기질을 보여주지 않았기 때문이에요.</p>\n<p>둘째, 그건 그들의 역할이 아니기 때문에요.</p>\n<p>그 역할은 누구의 것인가요? 우리 정치 대표자들이 정부 기관을 규제하도록 요구하며, 이에 따라 그러한 프레임워크를 개발하고 시행해야 합니다.</p>\n<p>나쁘게도 지금까지 정치인들의 자아가 방해 요인이 되었습니다.</p>\n<ul>\n<li>AI에 대한 이해를 거부하는 것.</li>\n<li>장기적인 글로벌 AI 규제를 다른 국가들과 협력하여 개발하는 대신 자신들과 당의 일정을 우선시하는 것.</li>\n<li>현재의 해를 희망의 혁신 약속을 위하여 덜어주는 AI FOMO에 실패하는 것.</li>\n</ul>\n<p>요약하면, 선출된 대표들은 Sam과 팀과 친해지는 것을 그만두고 AI가 모두를 위해 작동하고 미래 세대의 생존을 위협하지 않도록하는 규제적 프레임워크를 시행해야 합니다.</p>\n</body>\n</html>\n"},"__N_SSG":true}