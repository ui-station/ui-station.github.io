---
title: "인공지능 회사들에 속지 않기 위해 예술가들이 작품에 함정을 설치하고 있어요"
description: ""
coverImage: "/assets/img/2024-05-18-TiredofbeingrippedofbyAIcompaniesartistsareboobytrappingtheirwork_0.png"
date: 2024-05-18 20:46
ogImage: 
  url: /assets/img/2024-05-18-TiredofbeingrippedofbyAIcompaniesartistsareboobytrappingtheirwork_0.png
tag: Tech
originalTitle: "Tired of being ripped of by AI companies, artists are booby trapping their work"
link: "https://medium.com/enrique-dans/tired-of-being-ripped-of-by-ai-companies-artists-are-booby-trapping-their-work-5b169536d43a"
---


![이미지](/assets/img/2024-05-18-TiredofbeingrippedofbyAIcompaniesartistsareboobytrappingtheirwork_0.png)

포스트된 Dall-E의 출현 이후에 Midjourney나 Stable Diffusion과 같은 다른 생성 이미지 처리 알고리즘들이 나오기까지 오랜 시간이 걸리지는 않았습니다. 그러나 큰 문제가 드러났습니다: 이러한 알고리즘을 만든 기업들이 이미지에 설명을 달고 라벨을 붙인 거대한 이미지 컬렉션을 축적하고, 그러고는 이를 바탕으로 알고리즘을 훈련시켰다는 것입니다.

이러한 거대한 이미지 컬렉션은 어디서 얻었을까요? 대부분은 이미지 저장소 등의 웹 사이트를 스크랩핑함으로써 입수했습니다. Getty Images가 Stable Diffusion에 대한 소송을 제기함으로써 그들의 이미지 출처가 명백하게 드러났습니다. 많은 경우, 알고리즘은 그것을 이미지의 다른 부분으로 해석하여 그들의 워터마크의 왜곡 버전이 포함된 이미지를 생성하기도 했습니다.

법적 문제는 분명합니다: 웹 상에 공개된 정보는 스크랩핑 대상이 될 수 있다는 것을 수년간 말해 왔습니다. 어떤 목적으로든 웹 페이지에 가서 그 내용을 모두 복사하는 권리를 달성하는 다양한 법적 선례들이 있습니다. 복잡성 때문에 해당 사례가 몇 년간 계속되어 대법원에 이르기도 하겠지만, 이 중요한 사안에 대해 저작물이 알고리즘 훈련에 사용된 작가들은 자신들의 작품이 쉽게 모방될 수 있다는 것을 보거나 누군가가 그들의 스타일을 시뮬레이션하여 새로운 이미지를 만들어낼 수 있다는 것을 보게 됩니다.

<div class="content-ad"></div>

법원이 도움을 많이 제공하지 않을 것이라는 점을 인정하면, 일부 예술가들은 자신들의 작품을 보호하기 위해 보비 트랩을 설치하고 있습니다. 이들은 소프트웨어로 처리된 이미지를 생성하여 알고리즘이 혼란스럽게 만드는 무시무시한 변경을 가하고 있습니다. 이 과정은 사람들의 얼굴을 사진이나 동영상에서 무시무시하게 수정해서 얼굴 인식 알고리즘을 방지하는 방식과 동일합니다. Atropa belladonna 식물(환각을 일으키는 식물)을 기리며 명명된 Nightshade라는 알고리즘은 수정된 사진을 게시할 수 있게 허용하며, 이러한 수정된 사진은 알고리즘이 실제 내용과 다른 설명을 생성하도록 합니다. 이 때문에 알고리즘이 혼란스러워져 결과물로 요청된 것과 다른 이미지를 제공합니다.

결과적으로, 이는 아직도 기능을 수행하는 이미지를 “독”으로 오염시킨 것과 같습니다. 여전히 그림을 보고 예쁘게 고르고 예술가들이 설정한 조건에 따라 선택할 수 있지만, 알고리즘에 흡입되면 “환각”을 유발합니다. “독”이 가미된 이미지가 많을수록 알고리즘은 더 예측할 수 없어지며, 기업들은 알고리즘 교육에 사용하는 콘텐츠를 모니터링하기 위한 메커니즘을 구축하여 비용이 크게 증가합니다.

이것은 이러한 유형의 도구를 만드는 기업에게 경고의 신호이며, 그들이 경고받은 문제들 중 많은 것을 설명합니다: 알고리즘을 쓰레기로 먹이면 쓰레기가 생성됩니다. 많은 경우, 투자자들에게 정당화하기 위해 결과를 너무 빨리 제공해야하는 기업들이 있는데, 이 때문에 어중간한 정보를 사용하게 되어 어떤 교육의 기초가 되어서는 안 되는 상황이 됩니다. 따라서 그들의 알고리즘은 덜 신뢰할 수 있게 됩니다. 기본적으로, “쓰레기를 입력하면 쓰레기를 출력한다.” 대부분의 교육 과정에서 마찬가지로 서둘러서 움직이는 것은 좋은 생각이 아닙니다.

실무적으로, 예술가들은 자신들의 작품에 대해 마음대로 조작할 수 있습니다. 이전까지 회사가 아카이브 전체를 긁어 모든 내용으로 알고리즘을 교육시킬 수 있는 방법을 방해할 수 없다고 믿어져 왔던 것과 마찬가지로 말입니다. 아무것도 절대적으로 확정되어 있는 게 없으며, 일부 예술가들이 보여준 것처럼 특히 저작권을 관리하는 사람들이라면, 이미지가 알고리즘 교육용으로 사용될 때 적절한 보상을 받을 수 있도록 어떠한 협상이 이뤄져야 할 것으로 보입니다.

<div class="content-ad"></div>

이 공간을 주시해주세요. 

(스페인어로는 여기에)