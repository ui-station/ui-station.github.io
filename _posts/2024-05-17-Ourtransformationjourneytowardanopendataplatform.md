---
title: "우리의 오픈 데이터 플랫폼으로의 변혁 여정"
description: ""
coverImage: "/assets/img/2024-05-17-Ourtransformationjourneytowardanopendataplatform_0.png"
date: 2024-05-17 18:16
ogImage: 
  url: /assets/img/2024-05-17-Ourtransformationjourneytowardanopendataplatform_0.png
tag: Tech
originalTitle: "Our transformation journey toward an open data platform"
link: "https://medium.com/@bxh_io/our-transformation-journey-toward-an-open-data-platform-b6f869b6a173"
---


저자: Condé Nast의 데이터 엔지니어링 부사장 Nana Yaw Essuman, Condé Nast의 고급 엔지니어링 매니저 Ben Hall 및 Condé Nast의 엔지니어링 매니저 Zachary Bannor

# 데이터 미로 헤쳐나가기: 도전에 맞서다

우리 조직은 전 세계 관객에게 탁월한 콘텐츠와 매혹적인 경험을 전달하는 미션을 추진하고 있습니다. 오늘날의 디지털 환경에서 데이터의 가치를 인지한 우리는 37개의 미디어 브랜드를 32개 시장에서 대상으로 고객 상호작용과 참여를 극대화할 데이터 인사이트를 내부 팀에게 제공하기 위해 데이터 여정을 시작했습니다.

그러나 우리는 기존의 복잡한 다양한 데이터 플랫폼으로 이루어진 인프라가 우리의 진전을 방해한다는 것을 빨리 깨달았습니다. 가치 있는 데이터가 조직 전체에 걸쳐 고립되어 있을 때 우리는 여러 기술을 분리해서 탐색해야 했습니다. 데이터 과학자들이 데이터에 접근하기 위해 엄청난 시간을 소비하는 반면, 비즈니스를 촉진할 수 있는 새로운 ML 모델 실험에 거의 시간을 할애할 수 없었습니다. 특히 중앙화된 기업 데이터 플랫폼인 "에버그린"을 내부적으로 부르는 세계 3개 주요 지역 전체 영역에 확장하는 결정으로 이 복잡한 환경의 확장이 큰 장애물이었습니다.

<div class="content-ad"></div>

에버그린의 비전을 실현하려면 3가지 과제를 해결해야 했습니다:

- 높은 양과 다양성의 데이터를 이해하기: 우리는 유명 패션, 라이프스타일 및 엔터테인먼트 브랜드가 포함된 방대한 출판물, 웹사이트 및 디지털 플랫폼의 포트폴리오를 보유하고 있어 매일 수십 테라바이트의 데이터를 생성합니다. 서로 다른 비즈니스 부문 간의 데이터 솔로로 인해 이 데이터를 관리하기가 매우 어렵습니다. 일관되지 않은 보고서와 상충되는 데이터 숫자로 신뢰의 결여가 발생하며 이는 이해관계자들이 데이터에 신뢰를 하지 못하게 만듭니다. 게다가 데이터를 수집하고 분석할 중앙화된 지점의 부재는 소비자나 상업적 수익을 포함한 다양한 수익 채널의 전반적인 건강을 평가하는 것을 어렵게 만들었습니다.
- 증가하는 비용 관리: 또 다른 장애는 저장 및 컴퓨팅 비용을 정확하게 반영하는 것이었습니다. 초기에는 특정 데이터 솔로를 위해 레드시프트를 일부로 사용했습니다. 레드시프트 및 일부 구글 빅쿼리를 사용하면, BI 사용자에게 관련 데이터를 제공하는 분석 쿼링 기능을 제공했습니다. 그러나 하류 분석적인 요구사항을 지원하기 위해 이를 다른 서비스들과 연결해야 했으며, 이는 시간과 비용이 많이 소요되는 과정이었습니다. 저장 측면에서, 데이터는 다른 Amazon S3 버킷에 저장되어 중복된 데이터, 운영 효율성의 저하 및 비용 증가를 초래했습니다. 이는 우리의 세계화된 운영 목표에 부합하지 않음을 인지했습니다.
- 리소스 집약적인 프로세스 개선: 데이터 팀 내 많은 프로세스가 매우 수동적이었습니다. 데이터에 접근하기 어려워 데이터 엔지니어는 ML 및 분석 팀을 위한 스크립트를 작성하는 데 상당한 시간을 소비했습니다. ML 팀 또한 이러한 수동적인 프로세스로 인해 심각한 어려움을 겪었습니다. 데이터 과학팀은 자신의 클러스터를 프로비저닝하고 세부 조정하기 위해 시간을 투자할 때 ML 모델을 빌드하고 훈련하는 데 시간을 집중하지 못했습니다. 데이터 엔지니어링의 리소스 제약은 총 플랫폼 비용을 높여 그럼에 불을 붙였습니다.

# 가치와 규모를 제공하기 위한 오픈 플랫폼을 활용하기

저희 여정의 첫걸음은 적합한 데이터 플랫폼을 선택하는 것이었습니다. 이전 섹션에서 제시된 3가지 과제를 극복할 수 있는 플랫폼을 선택하는 것이 중요했습니다. 우리는 데이터 팀과 비즈니스 팀 모두에 걸칠 수 있는 중앙 집중식 데이터 플랫폼을 구축해야 한다는 것을 알고 있었습니다.

<div class="content-ad"></div>

우리는 우리의 요구 사항을 어떻게 효과적으로 해결할 수 있는지 보기 위해 Snowflake를 평가하기 시작했지만, 빠르게 적합하지 않다는 것을 깨달았습니다. 구조화된 데이터 세트를 중앙에 집중시킬 수 있는 능력을 제공했지만, 주로 분석 및 보고 작업을 위해 설계되었습니다. 우리의 데이터 과학 작업에 필요한 네이티브 지원이 부족했기 때문에 데이터 팀이 다시 기계 학습 팀과 분리되어 있는 것이었습니다. 우리의 데이터 규모를 감안할 때, Snowflake에서 ETL 프로세스를 실행하는 비용과 앞으로 구현하고자 했던 실시간 사용 사례를 지원할 수 있는지에 대해 걱정되었습니다. 우리가 정말 원했던 것은 우리의 기계 학습 요구 사항을 네이티브로 지원하고 데이터와 분석 팀 간의 협업을 촉진할 수 있는 열린 데이터 환경이었습니다.

다음으로, Databricks를 데이터 플랫폼으로 채택하는 것이 우리의 과제를 해결할 수 있는지를 평가했습니다. 그 당시 이미 워크스페이스가 운영 중이었기 때문에 아직까지 확장할 수 있는 플랫폼으로 선택하지 않았습니다. 그러나 데이터 및 기계 학습 능력을 하나의 중앙 플랫폼에서 제공하는 포괄적인 솔루션을 제공했습니다. 이는 사일로를 제거하고 비즈니스 팀 뿐만 아니라 데이터 및 분석 팀 전체에 걸쳐 데이터와 프로세스를 통합하는 목표를 달성할 수 있게 해 줄 것입니다. ML을 위한 네이티브 지원 및 MLflow를 사용한 ML Ops 능력은 데이터 과학자가 효율적으로 작업할 수 있도록 허용할 것입니다.

구조화된 데이터뿐만 아니라 구조화되지 않은 데이터 모두에 대한 Apache Spark™ 지원을 통해 우리는 실시간 사용 사례와 콘텐츠(편집, 비디오, 오디오) 데이터 처리와 같은 고급 기능으로 성장할 수 있었습니다. 생산성 측면에서 단일 진실의 단일 환경과 원격 개발자, 데이터 과학자가 작성한 코드 모두를 버전 관리하고 CI/CD를 사용하여 쉽고 빠르게 배포하는 것이 중요한 요구 사항이었습니다.

규모 확장을 지원하기 위해 열린 플랫폼을 갖고 싶다는 우리의 욕망을 고려하여 Databricks Data Intelligence Platform으로 결정했습니다. 이 플랫폼은 오픈 소스 기술 위에 구축되어 있으며 오픈 소스 커뮤니티에 다시 기여합니다. 또한, 이들의 플랫폼이나 동등한 오픈 소스 기술을 활용하는 엔지니어들의 커뮤니티는 세계적으로 엔지니어들이 많은 도움을 받을 수 있게 해줍니다. 우리의 여정 중 가장 중요한 부분은 데이터 이전이었으며, Delta Lake의 기본 파일 형식이 Apache Parquet(다른 오픈 소스 프로젝트)인 것을 보고 데이터와 통합된 기존 시스템이 다른 파일 형식으로 변환하는 시간을 소모하지 않고도 문제없이 원활하게 작동할 것이라는 것을 간단하게 이해할 수 있었습니다.

<div class="content-ad"></div>

데이터브릭스를 도입함으로써 데이터 과학 능력이 크게 향상되었습니다. 이를 통해 우리는 데이터를 효과적으로 활용하여 다양한 사용 사례를 통해 소비자 경험을 개인화하고 타깃팅할 수 있게 되었습니다. 광범위한 사용자 행동 데이터에 접근하여, 데이터 과학자와 머신 러닝 엔지니어들은 독창적인 구독 성향 모델을 개발하는 등의 사용 사례를 구현할 수 있었으며, 독자의 참여를 높은 정확도로 예측하여 독자가 레시피를 손쉽게 찾을 수 있게 해주는 것과 사용자에게 더 정확하고 관련성 높은 광고 타켓팅을 제공하는 등의 기능을 구현할 수 있었습니다.

## 데이터 오디세이에 도입된 레이크하우스 아키텍처가 우리에게 준 이점

지금까지 우리는 저희의 여정과 전 세계적으로 흩어진 다양한 비즈니스 단위에 걸처있는 분열된 인프라를 실행하려고 한 도전들에 대해 살펴보았습니다. 비즈니스 단위 소유자들과 협력하여 데이터와 분석 요구 사항을 분석하여 새로운 프레임워크에 대한 요구 사항을 정의하기 시작했습니다. 우리의 목표는 데이터에 대한 새로운 신뢰를 구축하고 모든 데이터 및 플랫폼 비용을 효율적으로 향상시키고 생산성을 향상시키기 위해 모든 데이터를 한 곳에 모으는 것이었습니다.

레이크하우스 아키텍처를 통합한 이후, 데이터 과학자들의 생산성이 크게 향상되었으며, 약 2.6백만 달러(USD)의 가치를 창출했습니다. 데이터브릭스의 노트북, PySpark 및 MLflow 솔루션을 결합하여 ML 실험을 빠르게 수행하고 동시에 약 6백만 달러(USD)의 클라우드 LTD에서 데이터 오케스트레이션 및 운영 비용을 줄일 수 있었습니다. 내부 라이브러리에서 모델을 배포하거나 새로운 써드파티 모델을 실험하는 것과 같은 작업들이 쉬워졌습니다. 데이터브릭스를 사용하기 전에 우리의 모델을 제공하는 서버를 배포하는 것은 상당한 노력이 필요했습니다. 자동화된 인프라, 클러스터 관리 능력 및 서버리스 추론을 이용하여 기존과 달리 모델을 즉시 제공할 수 있게 되었습니다. 이를 통해 고객에게 제공하는 데 걸리는 시간을 개념에서 고객까지의 시간을 개월에서 일 수준으로 줄일 수 있었습니다. 또한 새로운 모델을 배포하기 위해 단계적인 롤아웃을 사용하여 운영 위험을 크게 줄일 수 있었습니다. 이러한 모든 요인을 결합하여 배포되는 실험의 수와 속도가 급격히 증가하며, 이로 인해 반복 속도와 팀 간 협업이 가속화되었습니다. 결과적으로, 데이터 과학 팀의 고객에게 미치는 영향과 ML 워크플로우의 성능이 크게 향상되었습니다.

<div class="content-ad"></div>

더 많은 오픈 데이터 인텔리전스 플랫폼 제품을 사용함에 따라 우리는 생태계에서 다른 혜택을 발견했습니다. 예를 들어, Databricks 피처 스토어를 사용하면 모델 간에 기능을 쉽게 구성, 공유, 재사용할 수 있으므로 모델마다 기능을 새롭게 만들 필요가 없습니다. 실험을 위한 놀이터로서, 우리에게 가치 있는 엔지니어링 시간을 절약하고 생산 중인 모델 수를 빠르게 늘릴 수 있게 해 줍니다.

# 데이터 민주화를 통한 비즈니스 지원

조직 전체에 이러한 가치 있는 데이터 인사이트를 공유하기 위해 Presto를 Databricks SQL Serverless로 대체하여 데이터를 중앙 집중화하고 비용을 줄이면서 사용자에게 셀프 서비스를 제공하는 결정을 내렸습니다. SQL 데이터 웨어하우스는 이제 BI 도구를 지원하고 수백 건의 애드혹 보고서와 경영 대시보드를 생성하여 브랜드 건강, 관객 데이터 및 콘텐츠 성과를 분석할 수 있게 해 줍니다.

SQL 데이터 웨어하우스를 사용하면 분석가들이 데이터 엔지니어 및 데이터 과학자들이 사용하는 동일한 데이터 세트에 액세스할 수 있습니다. 이를 통해 조직 전체에 단일 정보원을 제공하고, 분석가들이 다른 시스템에서 복사한 오래된 데이터를 기반으로 작업하는 것을 방지할 수 있습니다. SQL 데이터 웨어하우스는 BI 워크로드를 지원하고 전통적인 테이블 액세스 제어를 사용하기 때문에 사용자들이 데이터와 상호 작용하는 안전하고 확장 가능한 방법을 제공합니다.

<div class="content-ad"></div>

저희에게 데이터 거버넌스를 강화하는 것이 매우 중요합니다. 그래서 Databricks 워크스페이스 전반에 Unity Catalog를 도입했습니다. 저희 데이터는 여러 지역에 걸쳐 퍼져 있기 때문에 Unity Catalog와 Delta Sharing을 활용하여 다양한 정밀도로 데이터를 안전하게 공유했습니다. 이러한 기능들을 통해 데이터의 전체적인 시각을 갖게 되었고, 규정 요건을 준수하는 것을 확인할 수 있었습니다. 앞으로는 Unity Catalog를 기반으로 거버넌스 도구를 도입하여 데이터 거버넌스와 법률 팀이 자산 거버넌스를 강화하는 데 도움이 되기를 기대합니다.

# 지출 효율과 생산성을 재상상하고 고속화하기

또한 Fivetran과 dbt를 레이크하우스에 통합하여 데이터 통합을 크게 단순화하고 비즈니스 로직 변환을 중앙 집중화했습니다. Fivetran을 통해 모든 채널에서 데이터를 손쉽게 중앙 집중화할 수 있었습니다. 3rd 파티 SaaS 플랫폼에 대한 다양한 커넥터는 우리의 모든 브랜드에서 데이터를 통합하여 종합적인 데이터에 기반한 신속한 의사결정을 가능하게 했습니다. dbt를 통해 레이크하우스 아키텍처 내 골드 수준 테이블에서 SQL 쿼리를 실행할 수 있었습니다. 이를 통해 동적 플랫폼 전반의 지출을 효과적으로 관리하고 자원을 최적화하여 더 나은 ROI를 이끌어냈습니다.

<div class="content-ad"></div>

# 하류 애플리케이션을 위한 데이터 인사이트 및 분석 가속화

Databricks 플랫폼을 활용하여 통합 데이터 플랫폼 아키텍처를 구축했습니다. 이를 통해 데이터 활용 방법이 혁신되어 협업과 ML 모델 실험이 촉진되었습니다. 저희의 레이크하우스에서는 월별 방문자가 1억 명을 넘는 웹 사이트를 기반으로 한 인사이트를 수집, 분석, 및 배포하고 있습니다. 횡단팀 협업과 통합된 데이터의 동력으로 현재 2000개 이상의 ML 모델이 운영 중이며 미래에 더 많은 모델을 계획 중에 있습니다.

프로덕션 환경의 2000개 이상의 ML 모델을 구현하는 결정적인 솔루션 제공과 데이터 과학팀이 참여하여 참여와 충성도를 증진하는 새로운 ML 솔루션을 지속적으로 개발할 수 있습니다.

<div class="content-ad"></div>

우리의 비전을 가능하게 한 모든 데이터 엔지니어들에게 특별한 감사를 전합니다.