---
title: "ì˜¤í”ˆ ì†ŒìŠ¤ LLMì„ í™œìš©í•œ ìì—°ì–´ë¥¼ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ê¸°"
description: ""
coverImage: "/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"
date: 2024-05-18 18:19
ogImage: 
  url: /assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png
tag: Tech
originalTitle: "Natural Language to SQL Query using an Open Source LLM"
link: "https://medium.com/@khadkechetan/natural-language-to-sql-query-using-an-open-source-llm-6b4b91a5519a"
---


# ì†Œê°œ

ë°ì´í„° í™œìš©ì˜ ë™ì ì¸ í’ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì™€ ì†ì‰½ê²Œ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ ì´ ìƒí˜¸ ì‘ìš©ì€ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ì–¸ì–´(SQL)ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ê°€ í•„ìš”í•˜ì—¬ ë§ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ì§„ì… ì¥ë²½ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìì—°ì–´ ì²˜ë¦¬(NLP)ë¥¼ SQL ì¿¼ë¦¬ ì—”ì§„ì— ì ìš©í•˜ì—¬ ì´ í’ê²½ì´ ë³€í™”ë˜ì—ˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ì‚¬ìš©ìë“¤ì´ ìì—°ì–´ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì†Œí†µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì²¨ë‹¨ ê¸°ìˆ ì€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ SQL ì¿¼ë¦¬ë¡œ ìˆœì¡°ë¡­ê²Œ ë²ˆì—­í•˜ì—¬ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì¡°ì‘í•˜ëŠ” ë°©ì‹ì„ í˜ì‹ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ìì—°ì–´ ì²˜ë¦¬(NLP)ì—ì„œ Mistral 7B ë° Microsoft Phi-3ê³¼ ê°™ì€ ëª¨ë¸ì€ ì£¼ìš” ì—­í• ì„ í•˜ë©° ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì˜ ê²½ê³„ë¥¼ ì¬ì •ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.

Mistral 7BëŠ” NLP ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ê³¼ ì •ë°€ë„ë¡œ ë†’ì´ í‰ê°€ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜(GQA) ë° ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜(SWA)ê³¼ ê°™ì€ í˜ì‹ ì ì¸ ê¸°ëŠ¥ë“¤ì„ ê°–ì¶˜ Mistral 7BëŠ” ìˆ˜í•™ ë° ì½”ë“œ ìƒì„±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘ê³  ìˆìŠµë‹ˆë‹¤. Code-Llama 7Bì˜ ì½”ë”© ëŠ¥ë ¥ì— ê°€ê¹Œì›Œì§ê³¼ ë™ì‹œì— NLP ë°œì „ì—ì„œì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©° ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ìš°ìˆ˜ì„±ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

<div class="content-ad"></div>

Phi-3 ëŠ” ì‘ì€ ì–¸ì–´ ëª¨ë¸(SLMs) ë¶„ì•¼ì—ì„œì˜ Microsoftì˜ ìµœì‹  í˜ì‹ ìœ¼ë¡œ, AIì˜ í’ê²½ì„ ë³€í™”ì‹œí‚¤ëŠ” ëŒ€ë‹¨í•œ ì œí’ˆì…ë‹ˆë‹¤. Phi-3-mini, Phi-3-small ë° Phi-3-mediumìœ¼ë¡œ êµ¬ì„±ëœ ì´ ëª¨ë¸êµ°ì€ ê°„ê²°í•œ êµ¬ì„±ìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ìë‘í•˜ëŠ” Phi-3-miniëŠ” ë” í° ëª¨ë¸ë“¤ê³¼ ê²¬ì¤„ ë§Œí•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©´ì„œë„ ìŠ¤ë§ˆíŠ¸í°ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. Phi-3ì˜ ì„±ê³µ ë’¤ì—ëŠ” ê²¬ê³ í•¨, ì•ˆì „ì„± ë° ëŒ€í™” ëŠ¥ë ¥ì„ ì¤‘ì‹œí•˜ëŠ” ì •êµí•˜ê²Œ ì„ ë³„ëœ í•™ìŠµ ë°ì´í„°ì…‹ì´ ìˆìŠµë‹ˆë‹¤. Phi-3-small ë° Phi-3-mediumì€ Phi-3ì˜ ëŠ¥ë ¥ì„ ë”ìš± í™•ì¥í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì— ëŒ€ì‘í•©ë‹ˆë‹¤. ì •êµí•˜ê²Œ ì„¤ê³„ëœ ì•„í‚¤í…ì²˜ì™€ í•™ìŠµ ë°©ë²•ì„ í†µí•´ Phi-3ì€ AI ê¸°ìˆ ì˜ í° ë°œì „ì„ ìƒì§•í•˜ë©°, ë‹¤ì–‘í•œ ìƒì„±í˜• AI ì‘ì—…ì— ëŒ€í•œ ìš°ìˆ˜í•œ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ì•½ì†í•©ë‹ˆë‹¤.

NLPì™€ SQLì˜ êµì°¨ì ì„ íƒìƒ‰í•˜ì—¬ Mistral 7Bì™€ Microsoft Phi-3ì˜ í™œìš©ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ì¿¼ë¦¬ë¡œ ì›í™œí•˜ê²Œ ë³€í™˜í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‘ì—…ì—ì„œ í–¥ìƒëœ íš¨ìœ¨ì„±ê³¼ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

![](/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png)

# í•™ìŠµ ëª©í‘œ

<div class="content-ad"></div>

ì´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ Mistral 7B ëª¨ë¸ì„ NL2SQL ì‘ì—…ì— í™œìš©í•˜ëŠ” ë³µì¡ì„±ì„ íƒìƒ‰í•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ NL2SQL ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•´ ëª¨ë¸ì„ ë§ì¶¤í™”í•˜ê³  í›ˆë ¨í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë…¼ì˜í•  ê²ƒì…ë‹ˆë‹¤. ê¸°ì‚¬ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤.

# ë™ê¸°ë¶€ì—¬

ì˜¤í”ˆ ì†ŒìŠ¤ LLMsë¥¼ í™œìš©í•˜ë©´ ìì—°ì–´ ëª…ë ¹ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í˜ì‹ ì ì¸ ê¸°ìˆ ì€ ì‚¬ìš©ìê°€ ìˆ˜ë™ ì¿¼ë¦¬ ì‘ì„± ì—†ì´ ë°ì´í„° ìš”êµ¬ ì‚¬í•­ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•˜ë„ë¡ ìë™í™”í•˜ë©°, ì´ë¡œì¨ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ê³  ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ì •í™•í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ í™œìš©ë©ë‹ˆë‹¤. ì´ëŠ” ë³€í™˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”ì‹œí‚¤ê³  ê´‘ë²”ìœ„í•œ ì‚¬ìš©ìë“¤ì—ê²Œ ê´‘ë²”ìœ„í•œ SQL ì§€ì‹ì´ ì—†ì–´ë„ ë°ì´í„°ë¥¼ ì´ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” í¸ë¦¬í•¨ì„ ì œê³µí•˜ë©° ë°ì´í„° ì ‘ê·¼ì„±ê³¼ ìš´ì˜ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. SQL ì „ë¬¸ ì§€ì‹ì˜ ì¥ë²½ì„ ì œê±°í•¨ìœ¼ë¡œì¨ ì´ ê¸°ìˆ ì€ ë°ì´í„° ì ‘ê·¼ì„±ì„ ë¯¼ì£¼í™”ì‹œí‚¤ê³  ê° ë¶„ì•¼ì˜ ì‚¬ìš©ìë“¤ì´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  í†µì°°ì„ ì–»ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì‹¤ì‹œê°„ í†µì°°ì„ ì°¾ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ë‚˜ ë°ì´í„° ì§‘í•©ì„ íƒìƒ‰í•˜ëŠ” ì¼ë°˜ ì‚¬ìš©ìë¥¼ ìœ„í•œ ê²ƒì´ë“ , ìì—°ì–´ ëª…ë ¹ì˜ ì§ê´€ì ì¸ ì„±ê²©ì€ ë°ì´í„° ê²€ìƒ‰ì„ ê°„ë‹¨í•˜ê²Œ í•©ë‹ˆë‹¤.

ë˜í•œ ì´ëŸ¬í•œ ëª¨ë¸ì—ì„œ ë‚´ì¬ëœ ìë™í™”ëŠ” ì¿¼ë¦¬ ì‹¤í–‰ì„ ê°€ì†í™”í•˜ì—¬ ì „ë°˜ì ì¸ íš¨ìœ¨ì„±ê³¼ ìƒì‚°ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì˜¤í”ˆ ì†ŒìŠ¤ LLMsì˜ ì˜í–¥ë ¥ì€ ê´‘ë²”ìœ„í•˜ë©° ë‹¤ì–‘í•œ ì‚°ì—… ì „ë°˜ì— í˜ì‹ ê³¼ ë³€í™”ë¥¼ ê²©ë ¤í•©ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ì¬ë¬´, ê±´ê°• ê´€ë¦¬ ë° ì „ì ìƒê±°ë˜ ë¶„ì•¼ì™€ ê°™ì´ ë°ì´í„° ì£¼ë„ì  ì˜ì‚¬ ê²°ì •ì´ ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ ì´í•´ê¶Œìë¥¼ ë•ìŠµë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ê³ ê¸‰ ë¶„ì„ í”Œë«í¼ê³¼ ì¸ê³µ ì§€ëŠ¥ ì‹œìŠ¤í…œê³¼ì˜ í†µí•©ì„ í†µí•´ ì¡°ì§ì„ ë°ì´í„° ì£¼ë„ì  ìš°ìˆ˜ì„±ìœ¼ë¡œ ì´ë•ë‹ˆë‹¤. íƒêµ¬ ë¬¸í™”ë¥¼ ìœ¡ì„±í•˜ê³  ë°ì´í„° ìƒí˜¸ì‘ìš©ì„ ê°„ì†Œí™”í•¨ìœ¼ë¡œì¨ ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” ë°ì´í„° ìì‚°ì˜ ëª¨ë“  ì ì¬ë ¥ì„ ë°œíœ˜í•¨ìœ¼ë¡œì¨ ì‚°ì—… ì „ë°˜ì— í˜ì‹ ê³¼ ì„±ì¥ì„ ì´‰ì§„í•©ë‹ˆë‹¤.

<div class="content-ad"></div>

# 1. NL2SQLì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ (Mistral 7B)

Mistral AIê°€ ê°œë°œí•œ 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì–¸ì–´ ëª¨ë¸ì¸ Mistral 7BëŠ” ì¸ê³µ ì§€ëŠ¥ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤.

- ê¸°ë³¸ ëª¨ë¸ë¡œ ìœ„ì¹˜ ì§€ì •ëœ Mistral 7BëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ êµ¬ì¡°ì  ëª¨ë¸ë¡œ ìë¦¬ ì¡ì•˜ìœ¼ë©° ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ í™˜ê²½ ë‚´ì—ì„œ í•„ìˆ˜ì ì¸ ì½”ì–´ ë¹Œë”© ë¸”ë¡ì˜ ì¤‘ìš”ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- ê±´ì¶•ì  ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ì°¨ë³„í™”ëœ Mistral 7BëŠ” ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•´ ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜ (GQA)ê³¼ ê¸´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜ (SWA)ê³¼ ê°™ì€ í˜ì‹ ì ì¸ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.
- ì£¼ë¡œ ì˜ì–´ì— ì´ˆì ì„ ë§ì¶”ì§€ë§Œ ì½”ë”© ëŠ¥ë ¥ë„ ê°–ì¶˜ Mistral 7BëŠ” íŠ¹íˆ ë‹¤ë¥¸ ëª¨ë¸ë“¤ë³´ë‹¤ ë” ë„“ì€ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆëŠ” ë†’ì€ ë¬¸ë§¥ ìœˆë„ìš°ë¥¼ ê°€ì§€ê³  ìˆì–´ ë‘ê°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- 73ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¡œ ì¸ìƒì ì¸ Mistral 7BëŠ” ìµœì‹  ì–¸ì–´ ëª¨ë¸ì„ ëŒ€í‘œí•˜ëŠ”ë°, Apache 2.0 ë¼ì´ì„¼ìŠ¤ í•˜ì— ì œí•œ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- Mistral 7BëŠ” ëª¨ë“  í‰ê°€ëœ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœê³ ì˜ ì˜¤í”ˆ 13B ëª¨ë¸ (Llama-2)ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘ë©° ìµœê³ ì˜ 34B ëª¨ë¸ (Llama-1)ë³´ë‹¤ ì¶”ë¡ í‰ê°€, ìˆ˜í•™ ë° ì½”ë“œ ìƒì„±ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- Mistral-7BëŠ” Llama2-13Bë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©° CodeLlama-7Bì™€ ê²½ìŸë ¥ ìˆëŠ” ì„±ê³¼ë¥¼ ë³´ì´ë©° íŠ¹íˆ ì¶”ë¡ , ìˆ˜í•™ ë° ì½”ë“œ ìƒì„± ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚©ë‹ˆë‹¤.
- ë” í° ëª¨ë¸ë“¤ì— ë¹„í•´ í¬ê¸°ëŠ” ì‘ì§€ë§Œ, Mistral 7BëŠ” í…ìŠ¤íŠ¸ ìš”ì•½, ë¶„ë¥˜, í…ìŠ¤íŠ¸ ì™„ì„± ë° ì½”ë“œ ì™„ì„±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ìì—°ì–´ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ê±°ë‘¡ë‹ˆë‹¤.
- ì´ ëª¨ë¸ì´ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ëª…ë ¹ì–´ë¡œ ë³€í™˜í•˜ëŠ” íš¨ê³¼ë¥¼ íƒìƒ‰í•˜ì—¬ ëŠ¥ë ¥ì„ ìì„¸íˆ ì‚´í´ë´…ì‹œë‹¤.

## Sliding Window Attention

<div class="content-ad"></div>

- Mistral 7Bì€ ì „í†µì ì¸ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ë°œìƒí•˜ëŠ” ë„ì „ì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì²˜í•  ìˆ˜ ìˆëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜(Sliding Window Attention, SWA) ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ìëŠ” í† í° ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì¶”ë¡  ì¤‘ ì§€ì—° ì‹œê°„ì´ ì¦ê°€í•˜ê³  ì²˜ë¦¬ëŸ‰ì´ ê°ì†Œí•  ìˆ˜ ìˆìœ¼ë©°, ì‹œí€€ìŠ¤ ê¸¸ì´ì™€ ë©”ëª¨ë¦¬ì™€ ê´€ë ¨ëœ ì—°ì‚°ì´ ì´ì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ë©”ëª¨ë¦¬ê°€ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ì— SWAëŠ” ê° í† í°ì˜ ì£¼ì˜ë¥¼ ì´ì „ ë ˆì´ì–´ì˜ Wê°œ í† í°ì„ ìµœëŒ€í•œìœ¼ë¡œ ì œí•œí•˜ì—¬ ì£¼ì–´ì§„ ìœˆë„ìš° í¬ê¸° Wë¥¼ ë„˜ì–´ì„œ ì£¼ì˜ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.
- SWAëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ìœ„ì¹˜ iì˜ ìˆ¨ê²¨ì§„ ìƒíƒœê°€ ì…ë ¥ ë ˆì´ì–´ì˜ í† í°ì„ W x k í† í°ê¹Œì§€ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ìµœì¢… ë ˆì´ì–´ì—ì„œ W = 4096ì˜ ìœˆë„ìš° í¬ê¸°ë¡œ, SWAëŠ” ì´ë¡ ì ìœ¼ë¡œ ëŒ€ëµ 131K í† í°ì˜ ì£¼ì˜ ë²”ìœ„ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œì ìœ¼ë¡œ W = 4096 ë° FlashAttentionê³¼ xFormersì˜ ìµœì í™” ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬, 16K í† í° ì‹œí€€ìŠ¤ì˜ ê²½ìš° ë°”ë‹ë¼ ì£¼ì˜ ê¸°ì¤€ì— ë¹„í•´ ì£¼ëª©í• ë§Œí•œ 2ë°°ì˜ ì†ë„ í–¥ìƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, SWAëŠ” ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ì„±ëŠ¥ì„ í˜ì‹ ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°•ë ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.

### b. ë¡¤ë§ ë²„í¼ ìºì‹œ

- ë¡¤ë§ ë²„í¼ ìºì‹œë¥¼ êµ¬í˜„í•¨ìœ¼ë¡œì¨, Mistral 7BëŠ” ê³ ì •ëœ ì£¼ì˜ ë²”ìœ„ë¥¼ ì „ëµì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìºì‹œ í¬ê¸°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤. ì´ ìºì‹œëŠ” Wë¡œ í‘œì‹œëœ ê³ ì •ëœ í¬ê¸°ë¡œ, ìºì‹œ ë‚´ì—ì„œ íŠ¹ì • ì‹œê°„ ë‹¨ê³„ iì—ì„œ ì‹œê°„ ë‹¨ê³„ i mod Wì— í‚¤ì™€ ê°’ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ì‹œí€€ìŠ¤ê°€ ì§„í–‰ë˜ê³  iê°€ Wë¥¼ ì´ˆê³¼í•  ë•Œ, ìºì‹œëŠ” ë¡¤ë§ ë²„í¼ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ ê°’ë“¤ì„ ë®ì–´ì“°ê³  ë¬´í•œì •ìœ¼ë¡œ í™•ì¥ë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. W = 3ìœ¼ë¡œ ì„¤ëª…ëœ ì´ ì ‘ê·¼ ë°©ì‹ì€ 32k í† í° ì‹œí€€ìŠ¤ì— ëŒ€í•´ 8ë°°ì˜ ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œë¥¼ ì‹¤í˜„í•¨ìœ¼ë¡œì¨, ëª¨ë¸ì˜ í’ˆì§ˆì„ í¬ìƒí•˜ì§€ ì•Šê³  ë‹¬ì„±í•©ë‹ˆë‹¤. ê³ ì •ëœ ì£¼ì˜ ë²”ìœ„ëŠ” íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì´ìš©ì„ ë³´ì¥í•  ë¿ë§Œ ì•„ë‹ˆë¼ Mistral 7Bê°€ ê¸¸ì´ê°€ ë‹¤ë¥¸ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ì— ì›í™œí•˜ê²Œ ê¸°ëŠ¥í•˜ëŠ” ë°ì— ê¸°ì—¬í•©ë‹ˆë‹¤.

### c. ì‚¬ì „ ì±„ì›€ ë° ì²­í¬ ë¶„í• 

<div class="content-ad"></div>

- ì‹œí€€ìŠ¤ ìƒì„± ê³¼ì •ì—ì„œëŠ” ë¬¸ë§¥ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ”ë°, (k, v) ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤. ì•Œë ¤ì§„ í”„ë¡¬í”„íŠ¸ë¡œ ë¯¸ë¦¬ ì±„ì›Œì§„ ìºì‹œë¥¼ í™œìš©í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤. ê¸´ í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì§€ì •ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ê³ , ê° ì²­í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìºì‹œë¥¼ ë¯¸ë¦¬ ì±„ì›ë‹ˆë‹¤. ì´ ì „ëµì  ì ‘ê·¼ ë°©ì‹ì€ ì‹œí€€ìŠ¤ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì¤‘ ìºì‹œ ë‚´ë¶€ ë° í˜„ì¬ ì²­í¬ ì „ì²´ì—ì„œ ì£¼ì˜ë ¥ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì„ í™œìš©í•¨ìœ¼ë¡œì¨ Mistral 7BëŠ” ì‹œí€€ìŠ¤ ìƒì„±ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ë©°, ìºì‹œì— ì €ì¥ëœ ë¯¸ë¦¬ ì•Œë ¤ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ê° ì˜ˆì¸¡ëœ í† í°ì„ ì´ì „ í† í°ê³¼ ì¡°í™”ë¡­ê²Œ ì •ë ¬í•©ë‹ˆë‹¤.
- ì–¸ì–´ ëª¨ë¸ì˜ ë™ì ì¸ í™˜ê²½ì—ì„œ Mistral 7Bì˜ ë“±ì¥ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ë©´ì—ì„œ í° ë„ì•½ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í¬ê´„ì ì¸ í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ Mistral 7BëŠ” ìì‹ ì˜ ëŠ¥ë ¥ì„ ì…ì¦í•˜ë©°, ì´ì „ ì œí’ˆì¸ Llama 2 7B ë° Llama 2 13Bë¿ë§Œ ì•„ë‹ˆë¼ Llama 1 34Bì™€ ê°™ì€ í•µì‹¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ ë›°ì–´ë‚œ ê²½ìŸë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- Mistral 7Bì˜ ìš°ì›”ì„±ì€ ëª¨ë“  ì¸¡ì • í•­ëª©ì— ê±¸ì³ ëª…ë°±íˆ ë“œëŸ¬ë‚˜ë©°, í•´ë‹¹ ë¶„ì•¼ì˜ ì„ ë„ì£¼ìë¡œì„œì˜ ì§€ìœ„ë¥¼ ì¬í™•ì¸í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ë©´ë°€í•œ ì¬í‰ê°€ ê³¼ì •ì€ Mistral 7Bì˜ íƒì›”í•œ ëŠ¥ë ¥ì„ ì¼ê´€ë˜ê²Œ ì…ì¦í•˜ë©°, ê²½ìŸì‚¬ë¥¼ ë’¤ë¡œ ë‚¨ê¹ë‹ˆë‹¤.

## í¬ê¸° ë° íš¨ìœ¨ì„± ë¶„ì„

- Mistral 7Bì˜ ë§¤ë ¥ ì¤‘ìš” ìš”ì†Œ ì¤‘ í•˜ë‚˜ëŠ” í˜ì‹ ì ì¸ "ë™ë“±í•œ ëª¨ë¸ í¬ê¸°" ê³„ì‚° ë°©ì‹ì„ í†µí•œ íš¨ìœ¨ì„±ì…ë‹ˆë‹¤. ì¶”ë¡ , ì´í•´ ë° STEM ì¶”ë¡  ë“±ì—ì„œ í‰ê°€í•œ ê²°ê³¼, Mistral 7BëŠ” ì„¸ ë°° ì´ìƒ í¬ê¸°ì˜ Llama 2 ëª¨ë¸ê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ íš¨ìœ¨ì„±ì€ ê³¼ë„í•œ ë§¤ê°œë³€ìˆ˜ ë¶€ë‹´ ì—†ì´ ë›°ì–´ë‚œ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ” Mistral 7Bì˜ ëŠ¥ë ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.
- Mistral 7Bì˜ íš¨ìœ¨ì„±ì„ ë” ìì„¸íˆ ì‚´í´ë³´ë©´, í‰ê°€ ê²°ê³¼ì—ì„œ ì§€ì‹ ì••ì¶•ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ í†µì°°ë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ì‹ ë²¤ì¹˜ë§ˆí¬ì—ì„œ 1.9ë°° ë‚®ì€ ì••ì¶•ë¥ ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ì´ëŠ” Mistral 7Bì˜ ì˜ë„ì ìœ¼ë¡œ ì œí•œëœ ë§¤ê°œë³€ìˆ˜ ìˆ˜ì— ê¸°ì¸í•©ë‹ˆë‹¤. ì´ ì œí•œì€ ì €ì¥ëœ ì§€ì‹ ì–‘ì„ ì œí•œí•˜ì§€ë§Œ, Mistral 7BëŠ” ì§‘ì¤‘í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ë§¤ê°œë³€ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë³´ìƒí•©ë‹ˆë‹¤.

# í‰ê°€ì˜ ì°¨ì´ì 

<div class="content-ad"></div>

ë¶ˆì¼ì¹˜ ì‚¬í•­ì„ íˆ¬ëª…í•˜ê²Œ ë‹¤ë£¨ë©´ì„œ, í‰ê°€ ê·œì •ì˜ ë³€í™”ë¥¼ ìœ ì˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–¤ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” Llama 2ì˜ MBPPì™€ Mistral 7Bì˜ í‰ê°€ ê²°ê³¼ ì‚¬ì´ì— ì°¨ì´ê°€ ë°œìƒí•©ë‹ˆë‹¤. TriviaQAì—ì„œ ì†ìœ¼ë¡œ ê²€ì¦ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ Mistral 7Bì˜ ì„±ëŠ¥ ì§€í‘œì˜ ì‹ ë¢°ì„±ì— ê¸°ì—¬í•˜ëŠ” ê°•ê±´í•œ í‰ê°€ ê³¼ì •ì„ í™•ì¸í•˜ê²Œ ë©ë‹ˆë‹¤.

# ë°ì´í„°ì…‹

ì•„ë˜ ì—´ë¡œ êµ¬ì„±ëœ êµ¬ì¡° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ê³„íšì…ë‹ˆë‹¤. ë‹¤ìŒ í…Œì´ë¸”ì—ì„œ ë‹¤ì–‘í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤.

```js
transaction = [
        "transaction_id",
        "transaction_amount",
        "transaction_date",
        "transaction_type",
        "transaction_status",
        "transaction_description",
        "transaction_source_account",
        "transaction_destination_account",
        "transaction_currency",
        "transaction_fee"
    ]
```

<div class="content-ad"></div>

# ì½”ë“œ êµ¬í˜„

- íŒ¨í‚¤ì§€ ì„¤ì¹˜í•˜ê¸°

```js
!pip install git+https://github.com/huggingface/transformers.git 
!pip install deepspeed --upgrade
!pip install accelerate
!pip install sentencepiece
!pip install langchain
!pip install torch
!pip install bitsandbytes
``` 

2. íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°

<div class="content-ad"></div>

```js
import os
import re
import torch
from difflib import SequenceMatcher
from langchain.chains import LLMChain
from langchain import PromptTemplate, LLMChain
from langchain.llms import HuggingFacePipeline
from langchain_core.prompts import PromptTemplate
from transformers import LlamaTokenizer, LlamaForCausalLM, pipeline
```

3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°

```js
base_model = LlamaForCausalLM.from_pretrained(
     "mistralai/Mistral-7B-Instruct-v0.1",
     load_in_8bit=True,
     device_map='auto',
    )
tokenizer = LlamaTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
pipe = pipeline(
        "text-generation",
        model=base_model,
        tokenizer=tokenizer,
        max_length=500,
        temperature=0.3,
        top_p=0.95,
        repetition_penalty=1.2
    )
local_llm = HuggingFacePipeline(pipeline=pipe)
```

4. SequenceMatcher


<div class="content-ad"></div>

ì´ Python í•¨ìˆ˜ëŠ” difflib ëª¨ë“ˆì˜ SequenceMatcher í´ë˜ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ì™€ ì§€ì •ëœ ì‚¬ì „ì˜ ì—´ ì´ë¦„ ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì¿¼ë¦¬ ì´í•´ë ¥ê³¼ ëŒ€ì²´ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

```js
def find_columns_match(question, input_dict):
try:
  question_list = re.split(r'\s|,|\.', question)
  for index, string2 in enumerate(question_list):
    for string1 in input_dict.get('table1_columns'):
      score = SequenceMatcher(None,string1.lower(), string2.lower()).ratio()*100
      if score > 91:
        question_list[index] = string1 + ","
  return " ".join(question_list)
  
except:
 return question
```

ì´ Python í•¨ìˆ˜ query_generatorì€ ì œê³µëœ í…Œì´ë¸”ëª…, ì—´ ëª©ë¡ ë° ì§ˆë¬¸ì— ê¸°ë°˜í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” í…œí”Œë¦¿ ë¬¸ìì—´ì„ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬ì¡°í™”í•˜ë©°, í…Œì´ë¸” ëª…, ì—´ ëª©ë¡ ë° ì§ˆë¬¸ì— ëŒ€í•œ ìë¦¬ í‘œì‹œìë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ PromptTemplate ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ìë¦¬ í‘œì‹œìë¥¼ ì±„ì›Œë„£ê³  LLMChainì„ í†µí•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM)ê³¼ ìƒí˜¸ ì‘ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ìƒì„±ëœ SQL ì¿¼ë¦¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

```js
def query_generator(tble, cols, question):

  template = """Generate a SQL query using the following table name: {Table}, and columns as a list: {Columns}, to answer the following question:
  {question}.
  
  Output Query:
  
  """
  
  prompt = PromptTemplate(template=template, input_variables=["Table", "question", "Columns"])
  
  llm_chain = LLMChain(prompt=prompt, llm=local_llm)
  
  response = llm_chain.run({"Table": tble, "question": question, "Columns": cols})
  print(response)
```

<div class="content-ad"></div>

# í‘œ


transaction = [
        "transaction_id",
        "transaction_amount",
        "transaction_date",
        "transaction_type",
        "transaction_status",
        "transaction_description",
        "transaction_source_account",
        "transaction_destination_account",
        "transaction_currency",
        "transaction_fee"
    ]

    inputs = ["transaction_idê°€ 10ì¸ ê²½ìš° transaction_amount, transaction_date, transaction_type,transaction_descriptionì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±",
             "transaction_statusê°€ 'completed'ì¸ ê²½ìš° transaction_id, transaction_date, transaction_type, transaction_source_accountì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±",
             "transaction_type ë° í‰ê·  transaction_amountì˜ ê°œìˆ˜ë¥¼ ê²€ìƒ‰í•˜ê³  transaction_typeë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±",
             "ê° ì†ŒìŠ¤ ê³„ì •ë³„ ì´ ê±°ë˜ ê¸ˆì•¡ ëª©ë¡ì„ ê²€ìƒ‰í•˜ê³  ì´ ê±°ë˜ ê¸ˆì•¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±",
             "ê° ê±°ë˜ ìœ í˜•ë³„ ìµœëŒ€ ê±°ë˜ ê¸ˆì•¡ì„ ê²€ìƒ‰í•˜ê³  ê±°ë˜ ìœ í˜•ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±"]

    for input in inputs:
        query_generator("transaction",transaction ,question=find_columns_match(input,transaction))


# ì‘ë‹µ

- ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì„ ì‚¬ìš©í•˜ê³  ì»¬ëŸ¼ì„ ë‚˜ì—´í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™], ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ ìœ„í•´ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: (â€˜transaction_idê°€ 10ì¸ ê²½ìš° transaction_amount, transaction_date, transaction_type,transaction_descriptionì„ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ ìƒì„±â€™).

<div class="content-ad"></div>

```js
ì¶œë ¥ ì¿¼ë¦¬: 

  SELECT transaction_amount, transaction_date, transaction_type, transaction_description FROM transaction WHERE transaction_id = 10;
```

2. ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì¸ transactionê³¼ ì—´ ëª©ë¡ì¸ [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™]ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤:
(â€˜transaction_statusê°€ â€˜completedâ€™ì¸ ê²½ìš° transaction_id, transaction_date, transaction_type, transaction_source_accountë¥¼ ê²€ìƒ‰í•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤â€™).

```js
ì¶œë ¥ ì¿¼ë¦¬:
  SELECT transaction_id, transaction_date, transaction_type, transaction_source_account FROM transaction WHERE transaction_status = 'completed'
```

3. ë‹¤ìŒê³¼ ê°™ì€ í…Œì´ë¸” ì´ë¦„ì¸ transactionê³¼ ì—´ ëª©ë¡ì¸ [â€˜transaction_idâ€™, â€˜transaction_amountâ€™, â€˜transaction_dateâ€™, â€˜transaction_typeâ€™, â€˜transaction_statusâ€™, â€˜transaction_descriptionâ€™, â€˜transaction_source_accountâ€™, â€˜transaction_destination_accountâ€™, â€˜transaction_currencyâ€™, â€˜transaction_feeâ€™]ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤:
(â€˜transaction_typeì˜ countì™€ í‰ê·  transaction_amountë¥¼ ê°€ì ¸ì˜¤ê³  transaction_typeìœ¼ë¡œ ì •ë ¬í•˜ì‹­ì‹œì˜¤â€™).```

<div class="content-ad"></div>

```js
ê²°ê³¼ ì¿¼ë¦¬:

  SELECT transaction_type, AVG(transaction_amount) AS avg_transaction_amount, COUNT(*) AS total_count
  FROM transaction
  GROUP BY transaction_type
  ORDER BY transaction_type;
```

4. ë‹¤ìŒ í…Œì´ë¸” ì´ë¦„ê³¼ ì—´ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° ì—´: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤:
(â€˜ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ì†ŒìŠ¤ ê³„ì •ì˜ ì´ ê±°ë˜ ê¸ˆì•¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¡°íšŒí•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”â€™).

```js
ê²°ê³¼ ì¿¼ë¦¬:

       SELECT transaction_source_account, SUM(transaction_amount) AS TotalTransactionAmount
        FROM transaction
        GROUP BY transaction_source_account
        ORDER BY TotalTransactionAmount DESC;
```

5. ë‹¤ìŒ í…Œì´ë¸” ì´ë¦„ê³¼ ì—´ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: transaction ë° ì—´: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤:
(â€˜ê° ê±°ë˜ ìœ í˜•ì˜ ìµœëŒ€ ê±°ë˜ ê¸ˆì•¡ì„ ì°¾ì•„ ê±°ë˜ ìœ í˜•ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”â€™).```

<div class="content-ad"></div>

```js
ì¶œë ¥ ì¿¼ë¦¬:

   SELECT transaction_type, MAX(transaction_amount) AS max_transaction_amount
   FROM transaction
   GROUP BY transaction_type
   ORDER BY transaction_type;
```

ì¼ë°˜ì ì¸ ì¶”ì¶œì€ íš¨ê³¼ì ì´ì§€ë§Œ, ì—°êµ¬ ê²°ê³¼, ë°ì´í„°ë¥¼ ì„¸ë¶€ ì¡°ì •í•˜ì—¬ LLMì„ ìˆ˜í–‰í•˜ë©´ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¸ë°€ ì¡°ì • ì ‘ê·¼ë²•ì„ ì±„ìš©í•´ ë´…ì‹œë‹¤.

# 2 Fine-tune NL2SQL with Phi-3

Phi-3ë¥¼ ë§Œë‚˜ë³´ì„¸ìš”, Microsoftì˜ ìµœì‹  ì˜¤í”ˆ AI ëª¨ë¸ì˜ ì£¼ìš” ì„±ê³¼ì…ë‹ˆë‹¤. Phi-3-mini, Phi-3-small ë° Phi-3-mediumì„ í†µí•´, ì´ ì‘ì€ ì–¸ì–´ ëª¨ë¸ (SLM)ì˜ Phi-3 íŒ¨ë°€ë¦¬ëŠ” AI ëª¨ë¸ì˜ ì„¸ê³„ë¥¼ í˜ì‹ í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ê³  33ì¡° ê°œì˜ í† í°ìœ¼ë¡œ í›ˆë ¨ëœ Phi-3-miniëŠ” ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©° Mixtral 8x7B ë° GPT-3.5ì™€ ê°™ì€ í° ëª¨ë¸ê³¼ ê°™ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê²Œë‹¤ê°€, ì´ ëª¨ë¸ì€ ìŠ¤ë§ˆíŠ¸í° ì¥ì¹˜ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Phi-3ì˜ ì„±ê³µì€ í›ˆë ¨ ë°ì´í„°ì…‹ì— ê¸°ì¸í•©ë‹ˆë‹¤. Phi-2ì˜ ë°ì´í„°ì…‹ì˜ ì§„í™”ëœ ë²„ì „ì…ë‹ˆë‹¤. ìƒì„¸íˆ ê±¸ëŸ¬ë‚¸ ì›¹ ë°ì´í„° ë° í•©ì„± ì…ë ¥ì„ í†µí•´ ì´ëŸ¬í•œ ëª¨ë¸ì€ ê°•ë„, ì•ˆì „ ë° ëŒ€í™” ëŠ¥ë ¥ì— ìš°ì„ ìˆœìœ„ë¥¼ ë‘ì–´ ë‹¤ì–‘í•œ ì‘ìš©í”„ë¡œê·¸ë¨ì— ì í•©í•©ë‹ˆë‹¤. 7B ë° 14B íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ Phi-3-small ë° Phi-3-mediumì€ íš¨ìœ¨ ìœ ì§€ì™€ í•¨ê»˜ Phi-3ì˜ ê¸°ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.


<div class="content-ad"></div>

## Phi 3 Architecture and Evaluation

Phi-3 íŒ¨ë°€ë¦¬ëŠ” í’ˆì§ˆê³¼ ë¹„ìš©ì„ ê· í˜•ìˆê²Œ ìœ ì§€í•˜ë„ë¡ ì„¤ê³„ëœ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì œê³µí•˜ì—¬ ìƒì„±í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ëŠ” ê³ ê°ì„ ìœ„í•œ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

Phi-3-mini: ì´ ëª¨ë¸ì€ 38ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ì¶”ê³  33ì¡° ê°œì˜ í† í°ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê´‘ë²”ìœ„í•œ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. 32ê°œì˜ ë ˆì´ì–´, 32ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  3072ê°œì˜ íˆë“  ë””ë©˜ì…˜ì„ ê°–ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì±„íƒí–ˆìŠµë‹ˆë‹¤. ë””í´íŠ¸ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ëŠ” 4ì²œ ê°œì˜ í† í°ì´ë©°, 32K ì–´íœ˜ ì‚¬ì „ì„ ì‚¬ìš©í•˜ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì¶”ê°€ë¡œ, 128K í† í°ì˜ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°–ì¶˜ í™•ì¥ ë²„ì „ì¸ Phi-3-mini-128Kë„ ìˆìŠµë‹ˆë‹¤.

Phi-3-small: 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¡œ í›ˆë ¨ëœ Phi-3-smallì€ 48ì¡° ê°œì˜ í† í°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 100K ì–´íœ˜ ì‚¬ì „ê³¼ 8ì²œ ê°œì˜ ë””í´íŠ¸ ì½˜í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. ì•„í‚¤í…ì²˜ëŠ” 32ê°œì˜ ë ˆì´ì–´, 32ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  4096ê°œì˜ íˆë“  ë””ë©˜ì…˜ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì–´í…ì…˜ê³¼ ë²ˆê°ˆì•„ê°€ë©° ì“°ì´ëŠ” ë°€ì§‘/í¬ì†Œ ì–´í…ì…˜ì„ í™œìš©í•©ë‹ˆë‹¤.

<div class="content-ad"></div>

Phi-3-medium: ì´ ë¯¸ë¦¬ë³´ê¸° ëª¨ë¸ì€ 140ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ìë‘í•˜ë©° 4.8ì¡° ê°œì˜ í† í°ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. 40ê°œì˜ ë ˆì´ì–´, 40ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, ê·¸ë¦¬ê³  ì„ë² ë”© í¬ê¸°ëŠ” 5120ì…ë‹ˆë‹¤.

## í›ˆë ¨ ë°©ë²•:

- í›ˆë ¨ ë°ì´í„° êµ¬ì„±: Phi-3 ëª¨ë¸ì˜ í›ˆë ¨ ë°ì´í„°ëŠ” ì‹ ì¤‘í•˜ê²Œ ì„ ë³„ë©ë‹ˆë‹¤. êµìœ¡ ìˆ˜ì¤€ë³„ë¡œ ë¶„ë¥˜ëœ ì›¹ ë°ì´í„°ì™€ í•©ì„± LLM ìƒì„± ë°ì´í„°ë¡œ êµ¬ì„±ë˜ë©° ë‘ ê°€ì§€ ì´ì§ˆì ì´ê³  ìˆœì°¨ì ì¸ ë‹¨ê³„ë¡œ ì‚¬ì „ í›ˆë ¨ì„ ê±°ì¹©ë‹ˆë‹¤.
- ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„: ì œ1 ë‹¨ê³„ëŠ” ì¼ë°˜ ì§€ì‹ê³¼ ì–¸ì–´ ì´í•´ì— ì¤‘ì ì„ ë‘” ì›¹ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì œ2 ë‹¨ê³„ëŠ” ë…¼ë¦¬ ì¶”ë¡  ë° íŠ¹ì • ê¸°ìˆ ì„ ê°€ë¥´ì¹˜ê¸° ìœ„í•´ ì œ1 ë‹¨ê³„ì˜ ì›¹ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„°ë¥¼ ë” ë§ì´ í™œìš©í•©ë‹ˆë‹¤.
- ì‚¬í›„ í›ˆë ¨ ë‹¨ê³„: ì‚¬ì „ í›ˆë ¨ í›„, Phi-3-miniëŠ” ê°ë…í˜• ì„¸ë°€ ì¡°ì • (SFT) ë° ì§ì ‘ ì„ í˜¸ë„ ìµœì í™” (DPO)ë¥¼ ê±°ì³¤ìŠµë‹ˆë‹¤. SFTëŠ” ìˆ˜í•™, ì½”ë”©, ì¶”ë¡ , ëŒ€í™”, ëª¨ë¸ ì‹ ì›, ì•ˆì „ ë„ë©”ì¸ ê°„ì— ë†’ì€ í’ˆì§ˆì˜ ë°ì´í„°ë¥¼ ì„ ë³„í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.
- DPOëŠ” ì±„íŒ… í˜•ì‹ ë°ì´í„°, ì¶”ë¡ , ê·¸ë¦¬ê³  ì±…ì„ ìˆëŠ” AI ë…¸ë ¥ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.
- ë§¥ë½ í™•ì¥: Phi-3-miniì˜ ë§¥ë½ ì°½ í¬ê¸°ê°€ Long Rope ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì—¬ 4k í† í°ì—ì„œ 128k í† í°ìœ¼ë¡œ í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í™•ì¥ì€ ë§¥ë½ì˜ ê¸¸ì´ê°€ í¬ê²Œ ì¦ê°€í•¨ì—ë„ ì¼ê´€ëœ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- ë°ì´í„° ìµœì í™”: í›ˆë ¨ ë°ì´í„°ëŠ” ëª¨ë¸ì˜ ê·œëª¨ë¥¼ ìœ„í•œ "ë°ì´í„° ìµœì " ì§€ì ìœ¼ë¡œ ë³´ì •ë©ë‹ˆë‹¤. ì›¹ ë°ì´í„°ëŠ” ì§€ì‹ê³¼ ì¶”ë¡ ì˜ ì ì ˆí•œ ê· í˜•ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í•„í„°ë§ë©ë‹ˆë‹¤. íŠ¹íˆ ì‘ì€ ëª¨ë¸ì˜ ê²½ìš° ì´ëŠ” ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
- ë‹¤ë¥¸ ëª¨ë¸ê³¼ì˜ ë¹„êµ: Phi-3ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì´ì „ ì‘ì—…ê³¼ ëŒ€ì¡°ì ìœ¼ë¡œ, í•´ë‹¹ ê·œëª¨ì— ëŒ€í•œ ë°ì´í„° í’ˆì§ˆì— ì¤‘ì ì„ ë‘ë©° ì»´í“¨íŒ…ì´ë‚˜ ê³¼ë„í•œ í›ˆë ¨ ë°©ë²•ë³´ë‹¤ ë°ì´í„° ìµœì í™”ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë¹„êµëŠ” Phi-3ê°€ ì‘ì€ ëª¨ë¸ ìš©ëŸ‰ì„ ìœ„í•œ ìµœì í™”ë¥¼ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.
- Phi-3-medium ë¯¸ë¦¬ë³´ê¸°: 140ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ Phi-3-mediumì€ Phi-3-miniì™€ ìœ ì‚¬í•˜ê²Œ í›ˆë ¨ë˜ì—ˆì§€ë§Œ ë” í° ê·œëª¨ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì¼ë¶€ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” 7Bì—ì„œ 14B ë§¤ê°œë³€ìˆ˜ë¡œì˜ ì „í™˜ì—ì„œ í° ê°œì„ ì´ ì—†ì–´ ê³„ì†í•´ì„œ ë°ì´í„° í˜¼í•©ì„ ê°œì„  ì¤‘ì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
- ì‚¬í›„ í–¥ìƒ: ëª¨ë¸ì€ ì±„íŒ… ëŠ¥ë ¥, ê²¬ê³ ì„±, ê·¸ë¦¬ê³  ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê°ë…í˜• ì„¸ë°€ ì¡°ì • ë° DPOë¥¼ í†µí•œ ì„ í˜¸ë„ ì¡°ì •ì„ ê±°ì¹©ë‹ˆë‹¤.

## ì•ˆì „ì„±

<div class="content-ad"></div>

Phi-3-miniì€ Microsoftì˜ ì±…ì„ ìˆëŠ” AI ì›ì¹™ì— ë”°ë¼ ë§Œë“¤ì–´ì§„ AI ëª¨ë¸ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ê°œë°œ ì´ˆê¸°ë¶€í„° ì•ˆì „ì„ ìš°ì„ ì‹œí•˜ëŠ” ì›ì¹™ì„ ì¤‘ìš”ì‹œí•˜ì—¬ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ìœ¤ë¦¬ ê¸°ì¤€ì„ ì¤€ìˆ˜í•˜ê³  ì ì¬ì ì¸ í”¼í•´ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í¬ê´„ì ì¸ ì „ëµì´ ì±„íƒë˜ì—ˆìŠµë‹ˆë‹¤.

ëª¨ë¸ í•™ìŠµ í›„ì—ëŠ”, í•´ë‹¹ ëª¨ë¸ì´ ì±…ì„ ìˆëŠ” AI ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë©´ë°€í•œ ì•ˆì „ ì¡°ì •ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ê²Œë‹¤ê°€, Microsoftì˜ ë…ë¦½ëœ ë ˆë“œ íŒ€ì´ Phi-3-minië¥¼ ê²€í† í•˜ì—¬ ê°•í™” ë° ì•ˆì „ í”„ë¡œí† ì½œì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ì‹ë³„í•©ë‹ˆë‹¤.

ìë™í™”ëœ í…ŒìŠ¤íŒ…ê³¼ ì ì¬ì ì¸ í”¼í•´ì˜ ë‹¤ì–‘í•œ ë²”ì£¼ì— ëŒ€í•œ í‰ê°€ëŠ” í”„ë¡œì„¸ìŠ¤ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ëŠ” ëª¨ë¸ì˜ ì¶œë ¥ë¬¼ë¡œë¶€í„° ë°œìƒí•˜ëŠ” ëª¨ë“  ìœ„í—˜ì„ ê°ì§€í•˜ê³  í•´ê²°í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤.

ë” ë‚˜ì•„ê°€, Phi-3-miniëŠ” ì˜ê²¬ ë°ì´í„° ì„¸íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì‘ë‹µì„ ë”ìš± ê°œì„ í•©ë‹ˆë‹¤. íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¤‘ í™•ì¸ëœ ì ì¬ì ì¸ í”¼í•´ ë²”ì£¼ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ë‚´ë¶€ì—ì„œ ìƒì„±ëœ ë°ì´í„° ì„¸íŠ¸ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.

<div class="content-ad"></div>

## ì½”ë“œ êµ¬í˜„

- íŒ¨í‚¤ì§€ ì„¤ì¹˜

```js
 !pip install -q -U bitsandbytes
 !pip install -q -U transformers
 !pip install -q -U xformers
 !pip install -q -U peft
 !pip install -q -U accelerate
 !pip install -q -U datasets
 !pip install -q -U trl
 !pip install -q -U einops
 !pip install -q -U nvidia-ml-py3
 !pip install -q -U huggingface_hub
```

2. íŒ¨í‚¤ì§€ ê°€ì ¸ì˜¤ê¸°

<div class="content-ad"></div>

```python
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling
from pynvml import *
import time, torch
from trl import SFTTrainer
from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training
from peft import AutoPeftModelForCausalLM
```

3. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°

```python
dataset = load_dataset("b-mc2/sql-create-context")
dataset
```

4. ë°ì´í„°ì…‹ í˜•ì‹í™”

<div class="content-ad"></div>

```js
def create_prompt(sample):
      system_prompt_template = """<s>
            ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
            ### ì§€ì‹œì‚¬í•­: <<user_question>>
            ### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:
            <<database_schema>>
            ### ì‘ë‹µ:
            <<user_response>>
            </s>
            """
      user_message = sample['question']
      user_response = sample['answer']
      database_schema = sample['context']
      prompt_template = system_prompt_template.replace("<<user_question>>",f"{user_message}").replace("<<user_response>>",f"{user_response}").replace("<<database_schema>>",f"{database_schema} ")

      return {"inputs":prompt_template}


instruct_tune_dataset = dataset.map(create_prompt)
print(instruct_tune_dataset)

def print_gpu_utilization():
    nvmlInit()
    handle = nvmlDeviceGetHandleByIndex(0)
    info = nvmlDeviceGetMemoryInfo(handle)
    print(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {info.used//1024**2} MB.")
```

5. í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ

```js
base_model_id = "microsoft/Phi-3-mini-4k-instruct"

# í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)
# fp16ë¡œ ëª¨ë¸ ë¡œë“œ
model = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, device_map={"": 0})
print(print_gpu_utilization())
```

6. ëª¨ë¸ ì¶”ë¡ 


<div class="content-ad"></div>


# í”„ë¡¬í”„íŠ¸ ì •ì˜
    prompt = [
        "ì½”ì½”ë„› ë°€í¬ë¡œ ë§Œë“  ì¹˜í‚¨ ì¹´ë ˆ ë ˆì‹œí”¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
        "ë‹¤ìŒ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: 'ë‚˜ëŠ” ë¹µê³¼ ì¹˜ì¦ˆë¥¼ ì¢‹ì•„í•´ìš”!'",
        "ìœ ëª…í•œ 20ëª…ì˜ ì¸ë¬¼ì„ ì¸ìš©í•´ë³´ì„¸ìš”.",
        "ì§€ê¸ˆ ë‹¬ì€ ì–´ë””ì— ìˆë‚˜ìš”?"
    ]

    # ë³€ìˆ˜ ì´ˆê¸°í™”
    duration = 0.0
    total_length = 0

    # í”„ë¡¬í”„íŠ¸ ë°˜ë³µ
    for i in range(len(prompt)):
        # í”„ë¡¬í”„íŠ¸ í† í°í™” ë° GPUë¡œ ì´ë™
        inputs = tokenizer(prompt[i], return_tensors="pt").to("cuda:0")

        # ì…ë ¥ í…ì„œ ì¸ë±ìŠ¤ë¥¼ torch.longìœ¼ë¡œ ë³€í™˜
        inputs = {k: v.to(torch.long) for k, v in inputs.items()}

        # ì‹œì‘ ì‹œê°„
        start_time = time.time()

        # ìë™ ìºìŠ¤íŒ…ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ìˆ˜í–‰
        with torch.cuda.amp.autocast(enabled=False):  # ìë™ ìºìŠ¤íŒ… ë¹„í™œì„±í™”
            output = model.generate(**inputs, max_length=500)

        # ì†Œìš” ì‹œê°„ê³¼ ì´ ê¸¸ì´ ê³„ì‚°
        duration += float(time.time() - start_time)
        total_length += len(output)

        # í”„ë¡¬í”„íŠ¸ë‹¹ í† í° ì†ë„ ê³„ì‚°
        tok_sec_prompt = round(len(output) / float(time.time() - start_time), 3)

        # í”„ë¡¬í”„íŠ¸ë‹¹ í† í° ì†ë„ ì¶œë ¥
        print("í”„ë¡¬í”„íŠ¸ --- %s í† í°/ì´ˆ ---" % (tok_sec_prompt))

        # ë””ì½”ë“œëœ ì¶œë ¥ ì¶œë ¥
        print(tokenizer.decode(output[0], skip_special_tokens=True))

    # í‰ê·  í† í° ì†ë„ ê³„ì‚°
    tok_sec = round(total_length / duration, 3)
    print("í‰ê·  --- %s í† í°/ì´ˆ ---" % (tok_sec))


9. Fine-tuningë˜ì§€ ì•Šì€ Text to SQL


    prompt = [
        """
        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        ### ì§€ì‹œì‚¬í•­ :
        ê° ë„ì‹œì˜ ì—­ ì¤‘ ê°€ì¥ ë†’ì€ ìœ„ë„ë¥¼ ê°€ì§„ ì—­ìˆœìœ¼ë¡œ ëª¨ë“  ë„ì‹œë¥¼ ë‚˜ì—´í•˜ì‹­ì‹œì˜¤.
        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:
        CREATE TABLE station (city VARCHAR, lat INTEGER)
        ### ì‘ë‹µ:
        SELECT city, lat FROM station ORDER BY lat DESC;
        """,
        """
        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        ### ì§€ì‹œì‚¬í•­ :
        'ê° ì„ ìˆ˜ê°€ 20ì  ì´ìƒ ë° 10ì  ë¯¸ë§Œì„ ê°€ì§€ê³  ìˆìœ¼ë©° ìƒìœ„ 10ìœ„ ì•ˆì— ìˆëŠ” í¬ì§€ì…˜ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?
        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:
        CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)
        ### ì‘ë‹µ:
        SELECT POSITION, Points, Ranking
        FROM player
        WHERE Points > 20 AND Points < 10 AND Ranking IN (1,2,3,4,5,6,7,8,9,10)
        """,
        """
        ë‹¤ìŒì€ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        ### ì§€ì‹œì‚¬í•­ :
        ë…¸ë˜ë¥¼ ê°€ì¥ ë§ì´ ì—°ì£¼í•œ ë°´ë“œ ë§´ë²„ì˜ ì´ë¦„ì„ ì°¾ì•„ë³´ì„¸ìš”.
        ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:
        CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)
        ### ì‘ë‹µ:
        SELECT b.firstname
        FROM Band b
        JOIN Performance p ON b.id = p.bandmate
        GROUP BY b.firstname
        ORDER BY COUNT(*) DESC
        LIMIT 1;
        """
    ]

    for i in range(len(prompt)):
      model_inputs = tokenizer(prompt[i], return_tensors="pt").to("cuda:0")
      start_time = time.time()
      output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]
      duration += float(time.time() - start_time)
      total_length += len(output)
      tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)
      print("í”„ë¡¬í”„íŠ¸ --- %s í† í°/ì´ˆ ---" % (tok_sec_prompt))
      print(print_gpu_utilization())
      print(tokenizer.decode(output, skip_special_tokens=False))

    tok_sec = round(total_length/duration,3)
    print("í‰ê·  --- %s í† í°/ì´ˆ ---" % (tok_sec))

    # Fine-tuning

    base_model_id = "microsoft/Phi-3-mini-4k-instruct"

    tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_eos_token=True, use_fast=True, max_length=250)
    tokenizer.padding_side = 'right'
    tokenizer.pad_token = tokenizer.eos_token

    compute_dtype = getattr(torch, "float16") # Ampere (ë˜ëŠ” ìµœì‹ ) GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° bfloat16ë¡œ ë³€ê²½
    bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=compute_dtype,
            bnb_4bit_use_double_quant=True,
    )
    model = AutoModelForCausalLM.from_pretrained(
              base_model_id, trust_remote_code=True, quantization_config=bnb_config, revision="refs/pr/23", device_map={"": 0}, torch_dtype="auto", flash_attn=True, flash_rotary=True, fused_dense=True
    )
    print(print_gpu_utilization())

    model = prepare_model_for_kbit_training(model)


10. LoRA ë§¤ê°œë³€ìˆ˜



<div class="content-ad"></div>

```js
peft_config = LoraConfig(
            lora_alpha=16,
            lora_dropout=0.05,
            r=16,
            bias="none",
            task_type="CAUSAL_LM",
          target_modules=[
            'q_proj',
            'k_proj',
            'v_proj',
            'dense',
            'fc1',
            'fc2',
        ])
```

9. Training Parameters

```js
training_arguments = TrainingArguments(
            output_dir="./phi3-results",
            save_strategy="epoch",
            per_device_train_batch_size=4,
            gradient_accumulation_steps=12,
            log_level="debug",
            save_steps=100,
            logging_steps=25,
            learning_rate=1e-4,
            eval_steps=50,
            optim='paged_adamw_8bit',
            fp16=True, #change to bf16 if are using an Ampere GPU
            num_train_epochs=1,
            max_steps=400,
            warmup_steps=100,
            lr_scheduler_type="linear",
            seed=42)
```

10. Data Prepare for the training

<div class="content-ad"></div>

```js
train_dataset = instruct_tune_dataset.map(batched=True, remove_columns=['answer', 'question', 'context'])
train_dataset
```

11. Fine-Tuned

```js
trainer = SFTTrainer(
    model=model,
    train_dataset=train_dataset["train"],
    #eval_dataset=dataset['test'],
    peft_config=peft_config,
    dataset_text_field="inputs",
    max_seq_length=1024,
    tokenizer=tokenizer,
    args=training_arguments,
    packing=False
)

trainer.train()
```

12. Test inference with the fine-tuned adapter
 

<div class="content-ad"></div>

```js
base_model_id = "microsoft/Phi-3-mini-4k-instruct"
tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)

compute_dtype = getattr(torch, "float16")
bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=compute_dtype,
        bnb_4bit_use_double_quant=True,
)
model = AutoModelForCausalLM.from_pretrained(
          base_model_id, trust_remote_code=True, quantization_config=bnb_config, device_map={"": 0}
)
adapter = "/content/phi3-results/checkpoint-400"
model = PeftModel.from_pretrained(model, adapter)
```

13. ìˆ˜í–‰í•˜ê¸°

```js
database_schema = 'CREATE TABLE station (city VARCHAR, lat INTEGER)'
user_question = "List all the cities in a decreasing order of each city's stations' highest latitude."

prompt_template = f"""
Below is an instruction that describes a task. Write a response that appropriately completes the request.
### Instruction:
{user_question}
Database Schema:
{database_schema}
### Response:
"""

question = "'What are the positions with both players having more than 20 points and less than 10 points and are in Top 10 ranking"
context = "CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)"

prompt_template1 = f"""
Below is an instruction that describes a task. Write a response that appropriately completes the request.
### Instruction:
{question}
Database Schema:
{context}
### Response:
"""

context = '''CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)'''
question = "Find the first name of the band mate that has performed in most songs."

prompt_template2 = f"""
Below is an instruction that describes a task. Write a response that appropriately completes the request.
### Instruction:
{question}
Database Schema:
{context}
### Response:
"""

prompt = []
prompt.append(prompt_template)
prompt.append(prompt_template1)
prompt.append(prompt_template2)

for i in range(len(prompt)):
  model_inputs = tokenizer(prompt[i], return_tensors="pt").to("cuda:0")
  start_time = time.time()
  output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]
  duration += float(time.time() - start_time)
  total_length += len(output)
  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)
  print("Prompt --- %s tokens/seconds ---" % (tok_sec_prompt))
  print(print_gpu_utilization())
  print(tokenizer.decode(output, skip_special_tokens=False))

tok_sec = round(total_length/duration,3)
print("Average --- %s tokens/seconds ---" % (tok_sec))
```

14. ëª¨ë¸ ì €ì¥í•˜ê¸°


<div class="content-ad"></div>

```js
import locale
import shutil
from huggingface_hub import notebook_login
from google.colab import drive

# Set the preferred encoding to UTF-8
locale.getpreferredencoding = lambda: "UTF-8"

# Log in to the notebook
notebook_login()

# Push the fine-tuned adapter to the Hugging Face Hub
trainer.push_to_hub(commit_message="fine-tuned adapter")

# Mount Google Drive
drive.mount('/content/drive')

# Move the trained model to Google Drive
shutil.move('/content/phi3-results', '/content/drive/MyDrive/PHI-3')

# Load the trained model
trained_model = AutoPeftModelForCausalLM.from_pretrained("/content/drive/MyDrive/PHI-3/phi3-results/checkpoint-400",
                                                         low_cpu_mem_usage=True,
                                                         return_dict=True,
                                                         torch_dtype=torch.float16,
                                                         device_map='auto',)

# Merge and unload the trained model
lora_merged_model = trained_model.merge_and_unload()

# Save the merged model
lora_merged_model.save_pretrained("/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model", safe_serialization=True)

# Save the tokenizer for the merged model
tokenizer.save_pretrained("/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model")

# Push the merged model to the Hugging Face Hub
lora_merged_model.push_to_hub(repo_id="", commit_message="merged model")

# Push the tokenizer to the Hugging Face Hub
tokenizer.push_to_hub(repo_id="", commit_message="merged model")
```

15. Perform Inference on Fine-tuned Model

```js
peft_config = LoraConfig(
            lora_alpha=16,
            lora_dropout=0.05,
            r=16,
            bias="none",
            task_type="CAUSAL_LM",
    )

peft_model_id = "username/phi3-results"
config = peft_config.from_pretrained(peft_model_id)

model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,
                                             return_dict=True,
                                             load_in_4bit=True,
                                             device_map="auto",
                                             )

tokenizer = AutoTokenizer.from_pretrained(peft_model_id)

model = PeftModel.from_pretrained(model, peft_model_id)

print(model.get_memory_footprint())

for i in range(len(prompt)):
    model_inputs = tokenizer(prompt[i], return_tensors="pt").to("cuda:0")
    start_time = time.time()
    output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]
    duration += float(time.time() - start_time)
    total_length += len(output)
    tok_sec_prompt = round(len(output)/float(time.time() - start_time), 3)
    print("Prompt --- %s tokens/seconds ---" % (tok_sec_prompt))
    print(print_gpu_utilization())
    print(f"RESPONSE:\n {tokenizer.decode(output, skip_special_tokens=False)[len(prompt[i]):].split('</')[0]}")

tok_sec = round(total_length/duration, 3)
print("Average --- %s tokens/seconds ---" % (tok_sec))
```

# Conclusion


<div class="content-ad"></div>

ìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ SQL ì¿¼ë¦¬ ì—”ì§„ì˜ ê²°í•©ì€ ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ê²ƒì„ ë” ì‰½ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ì „ì—ëŠ” SQLì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ê°€ í•„ìš”í–ˆê¸° ë•Œë¬¸ì— ë§ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Mistral 7Bì™€ Microsoft Phi-3ì™€ ê°™ì€ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì´ë¥¼ ë°”ê¿¨ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ SQL ì¿¼ë¦¬ë¡œ ì‹ ì†í•˜ê²Œ ë³€í™˜í•˜ì—¬, ë°©ëŒ€í•œ SQL ì „ë¬¸ ì§€ì‹ì´ í•„ìš” ì—†ê²Œ í–ˆìŠµë‹ˆë‹¤.

Mistral 7Bì™€ Microsoft Phi-3ëŠ” NLP ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ” íƒì›”í•œ ëª¨ë¸ë“¤ì…ë‹ˆë‹¤. ê·¸ë“¤ì€ Grouped-Query Attentionê³¼ Sliding Window Attentionê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ê°–ì¶”ì–´ ë”ìš± íš¨ìœ¨ì ì…ë‹ˆë‹¤. í¬ê¸°ê°€ ì‘ì€ Microsoft Phi-3ë„ NLP ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì—ì„œ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¸ìš°ë©°, ë³µì¡í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë” í° ëª¨ë¸ë“¤ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.

ì˜¤í”ˆ ì†ŒìŠ¤ LLMsë¥¼ ê³ ê¸‰ ë¶„ì„ í”Œë«í¼ê³¼ AI ì‹œìŠ¤í…œì— í†µí•©í•¨ìœ¼ë¡œì¨ ê¸°ì—…ì€ ì†ì‰½ê²Œ í†µì°°ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ê¸ˆìœµ, ê±´ê°• ê´€ë¦¬, ì „ì ìƒê±°ë˜ì™€ ê°™ì€ ì‚°ì—…ë“¤ì´ ë°ì´í„° ê¸°ë°˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë°©ì‹ì„ ë³€í™”ì‹œì¼°ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ ë‹¤ì–‘í•œ ë¶€ë¬¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ìƒë‹¹í•˜ë©° í˜ì‹ ê³¼ ë³€í˜ì„ ì´‰ì§„í–ˆìŠµë‹ˆë‹¤.

NLPì™€ SQLì˜ ìœµí•©ì„ í†µí•´ ì˜¤í”ˆ ì†ŒìŠ¤ LLMsëŠ” ë°ì´í„° ì ‘ê·¼ì„ ë¯¼ì£¼í™”ì‹œí‚¤ê³  íš¨ìœ¨ì„±, ìƒì‚°ì„±, ê¸°ì—… ì„±ê³µì„ ì´‰ì§„í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë°ì´í„° ìì‚°ì˜ ìµœëŒ€ ì ì¬ë ¥ì„ ë°œíœ˜í•˜ë„ë¡ í—ˆìš©í•˜ì—¬ ì´í•´ë‹¹ì‚¬ìë“¤ì´ ì‹¤í–‰ ê°€ëŠ¥í•œ í†µì°°ì„ ì¶”ì¶œí•˜ê¸° ì‰¬ì›Œì§€ê³ , ì—¬ëŸ¬ ë¶€ë¬¸ì—ì„œ íƒêµ¬ì™€ í˜ì‹ ì˜ ë¬¸í™”ë¥¼ ìœ¡ì„±í–ˆìŠµë‹ˆë‹¤.

<div class="content-ad"></div>

ë…¸íŠ¸ë¶: phi3

ì œ ì´ì „ ğŸ“ ê¸€ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”.

# ì°¸ê³  ìë£Œ

- https://arxiv.org/pdf/2310.06825.pdf
- https://artgor.medium.com/paper-review-mistral-7b-6acdf2f3132d
- https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580
- https://www.datacamp.com/tutorial/mistral-7b-tutorial
- https://www.analyticsvidhya.com/blog/2023/11/from-gpt-to-mistral-7b-the-exciting-leap-forward-in-ai-conversations/
- https://medium.com/@rubentak/mistral-7b-the-best-7-billion-parameter llm-yet-8b0aa03016f9
- https://clarifai.com/mistralai/completion/models/mistral-7B-Instruc
- https://iamgeekydude.com/2023/06/02/alpaca-llm-load-model-using-langchain-hf/
- https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/
- https://huggingface.co/microsoft/Phi-3-mini-128k-instruct