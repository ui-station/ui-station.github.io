<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/8" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/8" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_buildManifest.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="Ecoli, 다음 라즈베리 파이" href="/post/2024-05-23-EcolithenextRaspberryPi"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Ecoli, 다음 라즈베리 파이" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-EcolithenextRaspberryPi_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Ecoli, 다음 라즈베리 파이" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Ecoli, 다음 라즈베리 파이</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="나의 마법 상자를 통해 만든 우정들" href="/post/2024-05-23-TheFriendshipsIveMadeThroughMyMagicBox"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="나의 마법 상자를 통해 만든 우정들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheFriendshipsIveMadeThroughMyMagicBox_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="나의 마법 상자를 통해 만든 우정들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">나의 마법 상자를 통해 만든 우정들</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="효율적으로 BigQuery를 사용하는 결정적 가이드" href="/post/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="효율적으로 BigQuery를 사용하는 결정적 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="효율적으로 BigQuery를 사용하는 결정적 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">효율적으로 BigQuery를 사용하는 결정적 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">21<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="아마존 데이터 분석가를 위한 SQL 인터뷰 질문" href="/post/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="아마존 데이터 분석가를 위한 SQL 인터뷰 질문" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="아마존 데이터 분석가를 위한 SQL 인터뷰 질문" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">아마존 데이터 분석가를 위한 SQL 인터뷰 질문</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오픈소스 SQLFrame을 소개합니다 " href="/post/2024-05-23-Introducingopen-sourceSQLFrame"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈소스 SQLFrame을 소개합니다 " loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈소스 SQLFrame을 소개합니다 " loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">오픈소스 SQLFrame을 소개합니다 </strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="효율적인 BigQuery 데이터 모델링 저장 및 계산 비교" href="/post/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="효율적인 BigQuery 데이터 모델링 저장 및 계산 비교" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="효율적인 BigQuery 데이터 모델링 저장 및 계산 비교" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">효율적인 BigQuery 데이터 모델링 저장 및 계산 비교</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="SQL 설명 공통 테이블 표현식" href="/post/2024-05-23-SQLExplainedCommonTableExpressions"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="SQL 설명 공통 테이블 표현식" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-SQLExplainedCommonTableExpressions_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="SQL 설명 공통 테이블 표현식" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">SQL 설명 공통 테이블 표현식</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="퀵, 퀵, 캐-칭 덕DB를 통해 Snowflake 쿼리하여 비용 절감하기" href="/post/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="퀵, 퀵, 캐-칭 덕DB를 통해 Snowflake 쿼리하여 비용 절감하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="퀵, 퀵, 캐-칭 덕DB를 통해 Snowflake 쿼리하여 비용 절감하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">퀵, 퀵, 캐-칭 덕DB를 통해 Snowflake 쿼리하여 비용 절감하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="핀오프에서 파생 열backfilling derived column 채우기" href="/post/2024-05-23-BackfillingDerivedColumninPinot"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="핀오프에서 파생 열backfilling derived column 채우기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-BackfillingDerivedColumninPinot_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="핀오프에서 파생 열backfilling derived column 채우기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">핀오프에서 파생 열backfilling derived column 채우기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년 데이터 과학 - 무엇이 변했나요" href="/post/2024-05-23-DataSciencein2024WhatHasChanged"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 데이터 과학 - 무엇이 변했나요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 데이터 과학 - 무엇이 변했나요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">2024년 데이터 과학 - 무엇이 변했나요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link posts_-active__YVJEi" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Ecoli, 다음 라즈베리 파이","description":"","date":"2024-05-23 16:08","slug":"2024-05-23-EcolithenextRaspberryPi","content":"\n\n상상해보세요 — 작은 로봇들이 당신의 몸 속에서 작동하여 생명을 구할 수도 있는 약을 감지하거나 전달하거나, 바다에서부터 외부 공간까지 적대적인 환경으로 투입한다고 상상해보세요. 다시 말해서, 다양한 유용한 것들을 감지하고 전달하고 모니터링한다고 상상해보세요. 그런데 더 흥미로운 것은, 이 로봇들이 실제로 E.coli와 같은 살아있는 세균이었을 때 어떤 모습일지 상상해보세요? 이것이 어느 정도 우스꽝스러워 들릴 수 있지만, 실제로는 여러분이 생각하는 것보다 조금 더 현실적일 수 있습니다. IoT 영역에서, 더 정확하게 말하면, 미생물 사물 인터넷 (IoBT) 분야에서 연구진들은 이것을 실현하기 위한 진전을 이루고 있습니다.\n\nIoBT는 생물학적 개체와 나노 규모 장치를 혼합하여 통신하는 네트워크를 사용하는 것입니다. 합성 생물학과 나노 기술의 발전 덕분에 IoBT는 다양한 가능한 용도를 갖게 되었습니다. 과학자들은 이러한 바이오-나노 구성 요소 중 하나로 세균을 사용하는 것을 탐구하고 있습니다. 예를 들어, 환경 지속 가능성 분야에서, 이러한 세균은 독소와 오염물질을 감지하고 정보를 수집하며 심지어 자연적인 과정을 통해 환경 정화에 도움을 줄 수 있도록 프로그래밍되어 다양한 장소로 보내질 수 있습니다.\n\n마찬가지로, 의학 및 보건 분야에서 세균은 질병 치료에 도움이 되도록 공학적으로 개발될 수 있습니다. 이 모든 것은 좋고 아름다운데, 그리고 이른바 생물공학의 노동말들로 유용한 물질을 양조하는 데 세균을 사용하는 것은 새로운 것이 아닙니다. 그러나 IoBT의 맥락에서 세균을 커넥터로 취급할 때 흥미로운 일이 벌어집니다.\n\n## 세균을 IoT 장치로 사용하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDNA를 가지고 유용한 호르몬을 포함한 세균들은 인체 내에서 특정 영역으로 이동할 수 있습니다. 목적지에 도착하면 내부 센서에 의해 활성화되어 이러한 호르몬을 생성 및 방출할 수 있습니다. 이러한 잠재적 응용 프로그램은 세균의 감지, 활성화, 통신 및 생물학적 처리 능력을 활용하려는 것으로, 재미있게도 전형적인 컴퓨터 IoT 디바이스의 구성 요소와 유사한 것입니다. 이는 세균을 인터넷 오브 띵스(IoT) 장치의 생체 버전으로 볼 수 있다는 것을 시사합니다. 결과적으로, 세균에 대한 인식 변화는 바이오디자인 및 바이오-HCI(인간 컴퓨터 상호작용) 분야에서 탐구할만한 흥미로운 분야를 열어줍니다.\n\n아마도 의미 있는 방식으로 IoT에서 세균의 역할을 탐색하는 가장 쉬운 방법은 해당 분야의 기존 컴퓨터화된 IoT 장치와 미생물을 비교하는 것입니다(그림 1). 이렇게 하면 세균의 특징을 표준화된 디지털 모델과 비교하여 종의 속성 및 단점을 더 잘 이해할 수 있습니다.\n\nAkyildiz et al. [2]에서 일반적인 생물학적 세포와 전형적인 IoT 장치 간의 공통 요소를 보여주는 삽화가 제시되었습니다. 이제 이미지를 더 좁혀보겠습니다. 그림 1은 E.coli 세균(이하 '세균'이라고 함)과 라즈베리 파이에 추가 구성 요소를 붙인 것을 나타내어 생물학적 및 디지털 세계를 대표합니다. 본 논문에서는 이러한 선택을 의도적으로 한 것으로, DIY 생물학 및 오픈 소스 컴퓨팅의 공통 및 표준화된 '노동말'이기 때문입니다.\n\n따라서 두 가지 모두 의미 있는 참여와 학습을 위한 비용 효율적이고 접근하기 쉬운 도구가 될 수 있는 이상적인 후보입니다. 전체적으로, 그림 1에서 디지털과 생물학적 세계의 과도한 단순화를 인정하지만, 해당 삽화는 세균이 어떻게 프로그래밍되고 실제 상황에서 어떻게 적용될 수 있는지에 대한 중요한 질문을 제기하기 위해 설계되었습니다. 이러한 질문은 안정성, 반응성, 상호작용의 안전성과 더불어 바이오 세균물물(Internet of Bacterial Things, IoBT)이 우리 사회에 미치는 미래적인 도덕적 영향에 대한 중요성을 내포하고 있을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-EcolithenextRaspberryPi_0.png\" /\u003e\n\n## 박테리아 센서 및 구동기\n\n박테리아는 빛, 화학물질, 기계적 스트레스, 전자기장, 온도와 같은 다양한 자극에 반응할 수 있습니다. 이러한 자극에 대응하여 박테리아는 깃털을 이용한 이동(그림 2)이나 녹색 형광 단백질(GFP)과 같은 색소를 포함한 단백질 생산을 통해 상호 작용할 수 있습니다(그림 3).\n\n박테리아 센서 및 구동기의 분자 수준에서의 작동 방식 때문에, 디지털 상대품들과 비교했을 때 그 반응 성, 민감도, 안정성에 큰 차이가 있을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-EcolithenextRaspberryPi_1.png\" /\u003e\n\n## 박테리아 제어 장치, 메모리 및 프로세서\n\n박테리아 안의 DNA는 데이터 저장을 제공하고 실현 가능한 기능으로 해석될 수 있는 지시를 부호화하며, 컴퓨터의 제어 장치(예: '데이터 단위' 및 소프트웨어 조건 표현 단위를 관리하는 개체로서)와 유사한 역할을 합니다. 이러한 이유로, 이는 메모리(예: 포함된 시스템 데이터의 저장) 및 처리 장치(예: 소프트웨어 명령어 실행)와 유사한 역할을 제공합니다. 박테리아에 존재하는 DNA의 주요 형태로는 첫째로 세포 기능에 대한 대부분의 지시 사항을 포함하는 유전체 DNA와 두 번째로 플라스미드라고 불리는 보다 작은 원형 단위가 있습니다. 합성 생물학에서 플라스미드는 종 다양한 유전자를 생물체에 도입하는 데 자주 사용되며, 새 데이터의 비교적 저장 및 기능 맞춤화를 위한 다목적 도구로 사용됩니다.\n\n## 박테리아 송수신기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n통신의 송수신을 허용하도록 설계된 구성 요소로, 박테리아의 세포막은 송신기로 간주될 수 있습니다. 이는 세포 신호전달 경로의 일환으로 분자의 방출 및 수입에 관여합니다. 게다가 박테리아 필러스(그림 1)는 DNA 교환을 초래하는 두 세포 간의 쌍합 과정에 사용됩니다. 전반적으로 이러한 유형의 통신은 분자 통신으로 지칭되며, 이는 박테리아 나노네트워크의 기초를 형성합니다.\n\n## 박테리아 나노네트워크\n\n박테리아 나노네트워크는 분자 통신의 한 예로, IoT 커뮤니티에서 점차 주목받고 있습니다. 박테리아 나노네트워크는 분자 신호 및 최근에 발견된 전기장을 통해 박테리아 커뮤니티 간의 통신을 포함합니다. 통신의 또 다른 방법은 물리적 이동을 통해 이루어집니다. 즉, 대장균 등 박테리아의 이동 능력을 활용하여 정보를 운반합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 경우에는 디지턈 정보가 DNA로 번역되어 박테리아 세포로 변환되고, 나중에 디지턈 형식으로 다시 해독될 수 있습니다. 이 방법의 구현 예로는 비운동성 및 운동성 박테리아 간의 교합을 이용하여 DNA 데이터를 저장하고 전송하는 것이 Tavella 등에 의해 시연되었습니다. (그림 4, 5).\n\n![이미지](/assets/img/2024-05-23-EcolithenextRaspberryPi_3.png)\n\n## 도전과 가능한 방향\n\n박테리아가 HCI 조사에 가져다 주는 풍부한 프레임워크에도 불구하고, 미생물과 직접 작업하는 것은 실제적 및 윤리적 도전이 될 수 있습니다. 생물학적 성질 때문에 다루고 조작하는 것은 신중한 고려가 필요한데, 컴퓨터와 전자제품과 작업할 때 고려할 필요가 없는 문제들입니다. 이에는 전문적 감독이 필요할 수 있는 가능성, 일부 미생물을 안전하게 법적으로 다룰 수 있는 라이선스, 비용 측면의 영향과 발생할 수 있는 생명 윤리 및 생물안전 도전이 포함됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 나아가서, HCI 조사원들은 박테리아에 익숙하지 않을 수 있으며, 이 분야에 이전의 작업 경험이 없을 수도 있어 의미 있는 참여에 어려움이 있을 수 있습니다. 이는 과거 지식이 없는 사람들에게 추상적으로 보일 수 있는 박테리아 생리학의 기본 개념 중 일부로 악화될 수 있습니다. 이러한 도전을 극복하기 위해, DIY 생물학 운동 및 게이미피케이션에 대한 잠재적인 HCI 조사를 활용하기로 제안합니다. 아래에서 이에 대해 자세히 기술하고 이유를 설명하겠습니다.\n\n## DIY 생물학\n\nDIY 생물학 운동은 생물 기술의 도구, 데이터 및 재료의 접근성과 가용성을 증대시키는 데 공헌합니다 [9]. 현대 생물 기술 산업의 경제적 환경 변화를 활용하며, 지속적으로 하락하는 DNA 합성 및 서열 분석 비용을 대표합니다. 현재, 미생물과 소규모 실험을 수행하는 도구와 기술이 일반 대중에게 다양한 채널을 통해 널리 제공되고 있으며, 이는 메이커 스페이스를 포함합니다.\n\n게다가, 지원하는 키트도 있습니다. Amino Labs와 같은 교육용 제품은 특히 E.coli 종을 조작하고 유전적 엔지니어링에 관심 있는 사람들을 위해 고안되었습니다 [3]. 이는 다양한 환경 자극으로부터 트리거될 수 있는 유전 회로를 구축하여 박테리아로부터 맞춤형 색상을 만들 수 있도록 하여 사용자가 사용하는 것을 허용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n세균 중 특히 대장균은 획기적인 생명해킹 프로젝트를 위한 이상적인 도구로, 획득, 배양 및 유지하기 쉽다는 장점이 있습니다. 예를 들어 산화된 랩에서 사용되는 업계 표준 균주 K-12 E.coli는 비교적 안전하게 취급할 수 있습니다. 이 균주는 비병원성으로 개량되어 실험실 환경 이외에는 쉽게 전파되지 않도록 되어 있습니다. 대부분의 세균 종들과 달리 K-12 균주는 미국 및 유럽 대부분 지역에서 비교적 쉽게 구입할 수 있습니다.\n\n## 세균의 게임화\n\nIoT 분야에서 게임화는 여러 가지 이점을 보여주고 있습니다. 예를 들어, IoT 응용 프로그램의 참여를 증가시키고[4], 긍정적인 인간 행동 변화 (예: 스마트 시티 계획의 일환으로 여행 행동)를 유도해 왔습니다[12]. 비슷하게, Wood 등의 GPS Tarot은 참가자들이 즐기고 예술적인 도구로, 존재하는 글로벌 항법 위성 시스템(GNSS)을 활용하여 '숨겨진 기술'에 대해 배우고 인식하는 기회를 제공합니다[18,19].\n\n유사한 맥락에서, 대장균의 게임화가 HCI 및 IoT 연구에 대한 통합에서 참여도, 학습, 태도 변화에 도움이 될 것으로 가정합니다. 미생물은 이전에 생물 게임의 형태로 게임화되어왔으며, 실제 미생물을 컴퓨터 게임 플랫폼에 통합된 하이브리드 바이오 디지털 게임인 활자 게임으로 개발되어왔습니다[14]. 전반적으로, 세균의 게임화는 참여도, 플레이 경험 및 학습 측면에서 성공적으로 입증되었습니다[7,8,10].\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 윤리적 담론\n\n잠재적인 IoT 응용 프로그램과 마찬가지로, 세균 주도 IoT 시스템의 경우에도 사용자 데이터와 관련된 윤리적 고려 사항과 개인 정보 보호 문제가 적용될 것입니다. 그러나 흥미로운 점은 이러한 시스템이 작동할 수 있는 생물학적 성격으로 인해 추가적인 윤리적 도전 과제가 제시된다는 것입니다. 먼저, 세균이 작동할 수 있는 자율적인 성격에서 문제가 발생합니다. 세균은 진화하고 자율적으로 행동할 수 있기 때문에 자연 생태계에 위협을 가할 수 있고 병원성이 될 수도 있습니다. 물론 이는 교육적으로 배포된 K12 대장균 균주에는 적용되지 않을 수 있지만, 넓은 시각에서 고려할 가치가 있는 가능성입니다.\n\n둘째로, 세균 나노 네트워크는 DNA에 인코딩된 데이터를 공유하기 위해 교반 및 세포 운동이라는 자연 과정을 통해 의존합니다. 고도로 공학화된 세균이 효율적인 통신 시스템을 제공할 수 있지만, 그들은 결과적으로 예기치 않은 결과(예: 돌연변이)를 일으킬 수 있는 생물적 실체입니다. 모든면에서, IoT 및 HCI에서 세균 사용은 흥미로운 기회를 제공하면서도 새로운 윤리적 도전 과제를 제시하여 토론의 새로운 길을 열어줍니다.\n\n## 결론적으로...\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 논문에서는 E. coli 박테리아의 특징을 강조하며 IoT 및 HCI 문맥에서 미생물 탐구를 가능하게 할 수 있는 기능을 강조했습니다. 이는 이 생물체를 전통적인 컴퓨터 기반 IoT 장치와 비교함으로써 시작되었습니다. 더 나아가, 현재 IoT 및 HCI 분야의 연구자들이 박테리아에 대한 접근 및 실험을 할 수 있는 현실적인 인프라의 부재를 강조했습니다. 이러한 문제에 대한 잠재적인 해결책으로 DIY 생물학 운동과 게임화 기술을 활용하여 사용자 참여와 박테리아 소개를 촉진하는 것을 제안했습니다. 마지막으로, 박테리아 중심의 IoT 시스템이 제기할 수 있는 윤리적 도전 과제를 설명했습니다. 이는 박테리아의 자율적이고 생물학적 (따라서 예측할 수 없는) 성격에 의해 야기되는 것입니다. 이러한 도전 과제들은 박테리아 중심의 IoT 시스템이 가져다 줄 광범위한 영향에 대한 풍부한 토론 영역을 제공합니다.\n\n## 참고문헌\n\n[1] Akan et al., 2017.\n\n[2] Akyildiz et al., 2015.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[3] Amino Labs.\n\n[4] Charlton and Poslad. 2016.\n\n[5] Felicetti et al., 2018.\n\n[6] Gotovtsev and Dyakov, 2016.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[7] Hossain et al., 2017.\n\n[8] Kim et al., 2016.\n\n[9] Landrain et al., 2013.\n\n[10] Lee et al., 2015.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[11] Pataranutaporn et al., 2018.\n\n[12] Poslad et al., 2015.\n\n[13] Prindle et al., 2015.\n\n[14] Riedel Kruse et al., 2011.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Ron and Rosenberg. 2014.\n- Tavella et al., 2018.\n- Wood et al., 2017a.\n- Wood et al., 2017b.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[19] Zhang et al., 2015.","ogImage":{"url":"/assets/img/2024-05-23-EcolithenextRaspberryPi_0.png"},"coverImage":"/assets/img/2024-05-23-EcolithenextRaspberryPi_0.png","tag":["Tech"],"readingTime":8},{"title":"나의 마법 상자를 통해 만든 우정들","description":"","date":"2024-05-23 16:07","slug":"2024-05-23-TheFriendshipsIveMadeThroughMyMagicBox","content":"\n\n## 세계적인 친구들\n\n\"나는 싫은 사람을 만난 적이 없다.\" - 윌 로저스\n\n윌이 유명한 이 명언에서 말하고 싶었던 바를 이해합니다. 나는 사람들에 대해 같은 느낌을 가지고 있어요. 현실에서 누군가를 만나거나 가상으로 만날 때 기본 설정은 내가 그 사람을 좋아한다는 것이에요. 외모만 보고 누군가를 평가하는 일은 거의 없어요.\n\n물론, 그들이 빨간색 MAGA 모자를 쓰고 있거나 컨페더레이트 플래그 티셔츠를 입고 있다면 약간 더 어려워지죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래도 노력해봐요. 제 입장과는 정반대인 매우 다른 정치적, 종교적 신념을 가진 가족들이 있어요. 여성, 소수자, 그리고 사회적 약자들의 평등한 권리에 반대표를 던지는 것이 이해가 안 가지만, 그들이 혐오적이고 끔찍한 사람들은 아니라고 가정하려 해요.\n\n처음 만나는 사람들 대부분과는 개인적으로 알아가려 노력해요. 이번 주말은 바비큐 파티에 참석하게 되는데, 이전에 만난 적 없는 사람들이 많아요. 대면 후에도 우리 모두 예의바르고 친근하게 지내리라는 건 의심치 않아요. 대부분의 사람들은 사교적인 환경에서 대화하면 공통의 지점을 찾는 법을 알고 있어요.\n\n가상 친구들에게도 같은 말이 적용돼요. 20여 년 동안 인터넷을 사용해오면서, 자랑스럽게 칭찬할 만한 멋진 사람들을 많이 만났어요. 제 딸이 1살 때부터 알고 지내오는 온라인 친구들도 있어요. 그녀는 올해 7월에 19살이 될 거예요.\n\n그런데 아직 한 번도 대면한 적이 없어요. 그래도 거의 20년 동안 서로의 소셜미디어 글을 즐기며 지내왔어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2006년 MySpace에 가입한 지 2년 반이 훌쩍 넘어 Medium을 사용하고 있어요. 이 기간 동안 전체적으로 약 10만 명의 팔로워를 더했어요. 이 중에 실제로 만난 사람은 1% 정도일 것으로 추정돼요. 부동산 업을 하고 카펫 청소 회사를 운영하면서 만난 사람들이 대부분이에요.\n\n![image](/assets/img/2024-05-23-TheFriendshipsIveMadeThroughMyMagicBox_0.png)\n\n그들 대부분을 만나서 반가웠어요. 이렇게 많은 소셜 미디어 친구들과 실제로 만날 수 있어서 참 행복했어요. 우리는 몇몇 사람에게 가까워지기도 했고, 소중한 우정을 쌓기도 했어요.\n\n하지만 대부분의 사람들은 실제로 만나본 적이 없어요. 삶이 바쁘고, 사람들이 아이를 키우거나 삶의 어려움과 마주하고 있는 것을 해결하느라 분투하고 있어요. 멀리 떨어져 사는 사람들도 있고, 외국에 사는 사람들도 몇몇 있어요. 그래도 그들이 실제 친구가 아니라고 느끼지는 않아요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n매일 여러 온라인 친구들과 채팅을 해. 내가 가장 친한 사람들은 내 가족 구성원 대부분보다 나를 더 잘 알아. 내 형제나 부모님과 대화하는 시간보다 다양한 소셜 미디어 플랫폼에서 그들과 더 많은 시간을 보내고 있어. 그들은 나에게 생물학적 가족 구성원만큼 가족 같은 존재야.\n\n가끔은 자신이 선택한 가족이 가장 좋은 가족일 때가 있어.\n\n온라인 관계에서 많은 사람들을 “형제”나 “자매”라고 부르는 이유가 있어. 멋진 사람들과 친해지고 가까워지는 걸 좋아해. 너도 멋진 매력과 재치가 있다면, 우리는 멋지게 지낼 거야. 나는 글로 사람들을 웃게 해주는 것을 좋아하고, Medium에서 다른 작가들의 이야기와 코멘트를 읽을 때 웃음을 터뜨리는 걸 즐겨.\n\n작가로서 함께 나누는 이 멋진 커뮤니티를 통해 일생일대의 추억을 만들어 나가는 것이 환상적이야. Medium에서 보낸 2년 반 동안 만난 몇몇 가장 멋진 사람들을 통해 온라인에서 만날 수 있는 사람들 중 가장 멋진 사람들 중 일부를 만났어. Medium 작가들을 위한 Discord 서버를 만들고 성장시키는 과정에서, 서로를 격려하고 지지해 주는 가상의 친구들을 만나게 되어 정말 좋았어.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n좋은 사람들이 우리 곁에 있어 우리의 성취를 축하하고 어려울 때 우리를 격려해 주는 것은 정말 놀라운 일이죠.\n\n온라인에서 시간을 보내는 가장 큰 이점 중 하나는 우리가 공유하는 공동체 의식입니다. 글쓴이가 되고 요즘에는 사진작가가 되면서, 비슷한 관심사를 공유하는 사람들과 연결하는 것은 정말 놀라운 경험입니다. 이 두 주제에 대한 조언과 팁은 정말 소중합니다. 받은 만큼 많이 도울 수 있었으면 좋겠어요.\n\n웹을 통해 사랑을 얻은 이도 있습니다. 행운 아니라 정말로 로맨틱한 사랑을 말이에요. 페이스북에서 제 신부의 친구 요청을 수락하지 않았다면, 우리는 이렇게 멋진 12년 반을 함께 보내지 못했을 거에요. 우리 아이들은 지금처럼 훌륭하고 사랑스러운 덧엄마와 덧아빠를 갖지 못했을 거에요. 우리 가족은 함께 있진 않을 거에요, 서로를 사랑하고 지지해 주는 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어, 그리고 클레이그리스트를 잊을 수 있을까요? 가끔 클레이그리스트는 정말 수상한 곳이에요. 사기꾼들이 가득하고 온라인에서 상호 작용하는 가장 이상한 사람들 중 일부도 있죠. 그럼에도 불구하고, 저는 CL에 큰 감사를 하고 있어요. 그 사이트가 없었다면, 우리 아름다운 사랑스러운 개 Libby를 가질 수 없었을 텐데요.\n\n우리가 우리의 평생 친구로 부르는 Mooch. 우리가 살아온 동안 다른 어떤 애완 동물보다도 그녀를 더 사랑하고 소중히 여겨요. 그녀는 우리 가족에 매일 기쁨과 웃음을 선사해줘요. 우리 집 아래 사는 부족의 평등한 구성원이죠. 그녀는 이제 열두 살이 되었고, 그녀가 우리를 떠날 그 날을 앞두고 있어서 속상해요.\n\n우리 삶 중 가장 안 좋은 날 중 하나가 될 거예요. 사랑하는 사람, 가족, 친구 또는 사랑하는 애완 동물을 잃는 것은 너무나 힘들죠. 안타깝게도, 그게 인생이에요. 결국 모든 이들은 떠나게 되지요. 그 생각만으로 마음이 아파요.\n\n저는 다양한 이유로 여러 온라인 친구들이 세상을 떠났어요. 암으로 인해 젊은 어머니들이 세상을 떠났고, 자해한 전 군인들도 있었어요. 과다복용으로 사망한 사람들도 있었죠. 지난 몇 년 동안 코로나로 인해 몇 명의 온라인 친구가 떠나버렸어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당신이 마법의 기술 상자에 살고있는 사람들을 소중히 여기세요. 아마 아직 만나지 못한 분들이겠지만, 먼 거리에 있더라도 사랑하고 감사히 여길 가치가 있는 사람들입니다. 온라인 친구들은 때때로 만나는 실제 친구들만큼 중요하죠.\n\n그렇게 생각하고 있는 저의 친구들과 독자 여러분, 여러분은 더 많이 가치 있고 감사히 여기는 사람들입니다. 😊\n\n© 2024 Jason Provencio. 판권 소유.","ogImage":{"url":"/assets/img/2024-05-23-TheFriendshipsIveMadeThroughMyMagicBox_0.png"},"coverImage":"/assets/img/2024-05-23-TheFriendshipsIveMadeThroughMyMagicBox_0.png","tag":["Tech"],"readingTime":4},{"title":"효율적으로 BigQuery를 사용하는 결정적 가이드","description":"","date":"2024-05-23 16:02","slug":"2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently","content":"\n\n## 빅쿼리 사용을 최대한 활용하여 실질적 가치를 창출할 때, 돈 대신 데이터를 소모하세요. 실용적 기술로 진짜 가치를 창출해보세요.\n\n- 📝 소개\n- 💎 빅쿼리 기본 및 비용 이해\n  - 저장\n  - 계산\n- 📐 데이터 모델링\n  - 데이터 유형\n  - 정규화에서 비정규화로의 전환\n  - 파티셔닝\n  - 클러스터링\n  - 중첩 반복 열\n  - 인덱싱\n  - 물리 바이트 저장 요금 청구\n  - 기본 키 및 외래 키를 활용한 조인 최적화\n- ⚙️ 데이터 작업\n  - 데이터/테이블 복사\n  - 데이터 로드\n  - 파티션 삭제\n  - 테이블의 고유한 파티션 가져오기\n  - 계산된 측정값을 영속적으로 저장하지 말기\n- 📚 요약\n  - 데이터 모델링 최상의 방법 도입\n  - 비용 효율성을 위한 데이터 작업 마스터\n  - 효율성을 위한 설계 및 불필요한 데이터 영속화 피하기\n\n참고: 빅쿼리는 지속적으로 개발되는 제품이며, 가격은 언제든지 변경될 수 있습니다. 이 글은 제 개인적인 경험을 기반으로 작성되었습니다.\n\n# 📝 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 웨어하우징 분야에서는 보편적인 진실이 있어요: 데이터 관리는 비용이 많이 들 수 있다는 거죠. 마치 보물을 지키는 드래곤처럼, 저장된 각 바이트와 실행된 각 쿼리는 금화의 일부를 요구합니다. 하지만 제가 여러분께 드래곤을 달래는 마법 주문을 전해드리겠어요: 돈을 사용하는 게 아니라 데이터를 태워버리세요!\n\n이 기사에서는 비용을 줄이고 효율성을 높이는 빅쿼리 주술의 기술을 풀어보겠습니다. 모든 바이트가 소중한 동전인 비용 최적화의 심연으로 함께 여행해보세요.\n\n# 💎 빅쿼리 기본 사항 및 비용 이해\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빅쿼리는 그냥 도구가 아니라 구글에서 관리하는 확장 가능한 컴퓨트 및 저장 기술의 패키지입니다. 빠른 네트워크를 통해 모든 것을 관리합니다. 빅쿼리는 분석 목적을 위한 서버리스 데이터 웨어하우스로, 빅쿼리 ML과 같은 기능이 내장되어 있습니다. 빅쿼리는 구글의 Jupiter 네트워크를 통해 저장과 컴퓨트를 분리하여 1 Petabit/sec의 총 이분면 대역폭을 활용합니다. 저장 시스템은 구글의 반정형 데이터를 위한 전용 열 지향 저장 형식인 Capacitor를 사용하며, 하부 파일 시스템은 구글의 분산 파일 시스템인 Colossus입니다. 컴퓨트 엔진은 Dremel을 기반으로 하며, 수천 개의 Dremel 작업을 클러스터 내에서 실행하는 클러스터 관리에 Borg를 사용합니다.\n\n다음 그림은 빅쿼리의 기본 아키텍처를 보여줍니다:\n\n![빅쿼리 아키텍처](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_1.png)\n\n데이터는 Colossus에 저장될 수 있지만, 구글 클라우드 스토리지에 저장된 데이터 위에 빅쿼리 테이블을 만드는 것도 가능합니다. 이 경우 쿼리는 여전히 빅쿼리 컴퓨트 인프라를 사용하여 처리되지만 GCS에서 데이터를 읽습니다. 이러한 외부 테이블은 일부 단점이 있지만 경우에 따라 GCS에 데이터를 저장하는 것이 더 비용 효율적일 수 있습니다. 때로는 빅 데이터가 아니라 기존 CSV 파일에서 데이터를 간단히 읽는 것뿐인 경우도 있습니다. 이러한 종류의 테이블을 사용하는 것이 간단하고 편리할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**Markdown 형식으로 테이블 태그 변경**\n\n\u003cimg src=\"/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_2.png\" /\u003e\n\nBigQuery의 모든 잠재력을 활용하기 위해서는 데이터를 BigQuery 저장소에 저장하는 것이 보편적입니다.\n\n비용의 주요 구성 요소는 저장소와 컴퓨트이며, Google은 저장소와 컴퓨트 사이의 네트워크 전송과 같은 다른 부분에 대해 요금을 부과하지 않습니다.\n\n## 저장소\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저장 공간은 GB당 $0.02이며, 활성 데이터는 GB당 $0.04, 비활성 데이터(최근 90일간 수정되지 않은 데이터)는 GB당 $0.01입니다. 테이블이나 파티션을 90일 연속으로 수정하지 않으면 장기 저장으로 간주되어 저장 공간 비용이 자동으로 50% 떨어집니다. 할인은 테이블 또는 파티션 단위로 적용됩니다. 데이터 수정 시 90일 카운터가 재설정됩니다.\n\n## 계산\n\nBigQuery는 쿼리 실행 시간이 아닌 스캔된 데이터에 대해 청구하며, 저장 공간에서 컴퓨트 클러스터로 전송하는 비용은 청구되지 않습니다. 컴퓨트 비용은 위치에 따라 달라지며, 예를 들어 europe-west3의 비용은 TB당 $8.13입니다.\n\n즉,\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n쿼리를 실행할 때, BigQuery는 처리될 데이터량을 추정합니다. BigQuery Studio 쿼리 편집기에 쿼리를 입력한 후에는 오른쪽 상단에 추정치를 확인할 수 있어요.\n\n![이미지](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_3.png)\n\n위 스크린샷에서와 같이 1.27 GB가 나오고, 쿼리가 europe-west3 지역에서 처리된다면, 비용은 다음과 같이 계산할 수 있어요:\n\n```js\n1.27 GB / 1024 = 0.0010 TB * $8.13 = $0.0084 총 비용\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대부분 예측은 비관적인 계산이며, 종종 옵티마이저는 캐시된 결과, 자재화된 뷰 또는 기타 기술을 사용하여 실제 청구 바이트가 예측보다 낮게 될 수 있습니다. 여전히 작업의 영향을 대략적으로 파악하기 위해 이 예측을 확인하는 것이 좋은 실천법입니다.\n\n또한 쿼리에 대한 청구 바이트의 최대값을 설정할 수도 있습니다. 쿼리가 제한을 초과하면 실패하고 전혀 비용이 발생하지 않습니다. 이 설정은 '더 보기 - 쿼리 설정 - 고급 옵션 - 최대 청구 바이트'로 이동하여 변경할 수 있습니다.\n\n![image](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_4.png)\n\n![image](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아쉽게도 현재까지는 쿼리당 기본값을 설정하는 것이 불가능합니다. 하루에 사용자당 프로젝트당 또는 프로젝트당 모든 바이트에 대해 청구된 바이트를 제한하는 것만 가능합니다.\n\nBigQuery를 처음 사용할 때는 대부분 온디맨드 컴퓨트 요금 모델을 계속 사용할 것입니다. 온디맨드 가격 책정을 사용하면 일반적으로 하나의 프로젝트에서 모든 쿼리 사이에서 공유되는 최대 2000개의 동시 슬롯에 액세스할 수 있으며, 대부분의 경우 충분합니다. 슬롯은 쿼리 DAG의 작업 단위에서 작동하는 가상 CPU와 같습니다.\n\n월별 지출이 특정 금액에 도달하면 더 예측 가능한 비용을 제공하는 용량 가격 책정 모델을 고려할 가치가 있습니다.\n\n# 📐 데이터 모델링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터 유형\n\n저장 및 계산 비용을 줄이기 위해 항상 열에 가능한 가장 작은 데이터 유형을 사용하는 것이 매우 중요합니다. 다음 개요를 따라 특정 행 수에 대한 비용을 쉽게 추정할 수 있습니다:\n\n```js\n유형        | 크기\n-----------|---------------------------------------------------------------\nARRAY      | 요소의 크기 합계\nBIGNUMERIC | 32 논리 바이트\nBOOL       | 1 논리 바이트\nBYTES      | 2 논리 바이트 + 값의 논리 바이트\nDATE       | 8 논리 바이트\nDATETIME   | 8 논리 바이트\nFLOAT64    | 8 논리 바이트\nGEOGRAPHY  | 16 논리 바이트 + 지오 타입의 정점 개수 * 24 논리 바이트\nINT64      | 8 논리 바이트\nINTERVAL   | 16 논리 바이트\nJSON       | JSON 문자열의 UTF-8 인코딩된 논리 바이트\nNUMERIC    | 16 논리 바이트\nSTRING     | 2 논리 바이트 + UTF-8 인코딩된 문자열 크기\nSTRUCT     | 0 논리 바이트 + 포함된 필드의 크기\nTIME       | 8 논리 바이트\nTIMESTAMP  | 8 논리 바이트\n```\n\nNULL은 0 논리 바이트로 계산됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시:\n\n```js\nCREATE TABLE gold.some_table (\n  user_id INT64,\n  other_id INT64,\n  some_String STRING, -- 최대 10 자\n  country_code STRING(2),\n  user_name STRING,   -- 최대 20 자\n  day DATE\n);\n```\n\n위의 정의와 데이터 유형 테이블을 사용하여 100,000,000개의 행의 논리적 크기를 추정할 수 있습니다:\n\n```js\n100,000,000개 행 * (\n  8바이트 (INT64) +\n  8바이트 (INT64) +\n  2바이트 + 10바이트 (STRING) +\n  2바이트 + 2바이트 (STRING(2)) +\n  2바이트 + 20바이트 (STRING) +\n  8바이트 (DATE)\n) = 6200000000 바이트 / 1024 / 1024 / 1024\n  = 5.78 GB\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리가 이 테이블에 대해 SELECT *를 실행한다고 가정하면, Europe-west3에서는 5.78 GB / 1024 = 0.0056 TB * $8.13 = $0.05가 든다.\n\n데이터 모델을 설계하기 전에 이러한 계산을 하는 것은 좋은 생각입니다. 데이터 유형 사용을 최적화하는 것뿐만 아니라 작업 중인 프로젝트에 대한 비용을 예상할 수도 있기 때문입니다.\n\n## Denormalization으로의 이동\n\n데이터베이스 설계 및 관리 영역에서 데이터 정규화와 비정규화는 효율적인 저장, 검색 및 조작을 위해 데이터 구조를 최적화하기 위한 근본적인 개념들입니다. 전통적으로 정규화는 중복을 줄이고 데이터 무결성을 보존하는 것을 강조한 최고의 실천 방법으로 광명해왔습니다. 그러나 BigQuery와 다른 현대 데이터 웨어하우스의 맥락에서는 상황이 변하며 비정규화가 종종 선호되는 접근 방식으로 떠오르게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n정규화된 데이터베이스에서는 데이터가 여러 개의 테이블로 구조화되어 있으며, 각 테이블은 서로 다른 개체나 개념을 나타내며, 일대일, 일대다 또는 다대다와 같은 관계를 통해 연결됩니다. 이 접근 방식은 데이터베이스 정규화 양식에 의해 제시된 원칙을 따르며, 예를 들어 제1정규형(1NF), 제2정규형(2NF), 제3정규형(3NF) 등이 있습니다.\n\n이로 인해 중복 감소, 데이터 무결성 및 결과적으로 저장 공간 사용량이 줄어드는 이점이 있습니다.\n\n![image](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_6.png)\n\n데이터 정규화는 전통적인 관계형 데이터베이스에서는 가치가 있는 반면, BigQuery와 같은 현대적인 분석 플랫폼과 상호작용할 때는 패러다임이 변경됩니다. BigQuery는 대량의 데이터를 처리하고 규모에 맞는 복잡한 분석 쿼리를 수행하기 위해 설계되었습니다. 이 환경에서는 저장 공간을 최소화하는 것보다 쿼리 성능을 최적화하는 데 중점이 두어집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBigQuery에서는 여러 이유로 비정규화가 선호되는 전략으로 부상합니다:\n\n- 쿼리 성능: BigQuery의 분산 아키텍처는 대용량 데이터를 병렬로 스캔하는 데 뛰어납니다. 비정규화된 테이블은 복잡한 조인이 필요 없어져 쿼리 실행 시간이 빨라집니다.\n- 비용 효율성: 질의 처리에 필요한 계산 리소스를 최소화함으로써, 비정규화는 데이터 처리 양에 기반한 BigQuery의 쿼리 비용을 절감할 수 있습니다.\n- 단순화된 데이터 모델링: 비정규화된 테이블은 데이터 모델링 프로세스를 간단하게 만들어 분석 목적으로 스키마를 설계하고 유지하기 쉽게 합니다.\n- 분석 워크로드에 최적화: 비정규화된 구조는 집계, 변환 및 복잡한 쿼리가 일반적인 분석 워크로드에 적합합니다.\n\n또한, 저장소가 계산보다 훨씬 저렴하기 때문에:\n\n![image](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비정규화는 일반적으로 모든 상황에 적합한 해결책은 아니지만, 비용 및 성능 최적화를 위해 고려되어야 합니다. 그러나 다양한 측면이 있어 비용 효율적인 설계로 이어질 수 있습니다.\n\n특히 JOIN 오른쪽에 작은 테이블이 있는 경우, BigQuery는 Broadcast Join을 사용하여 각 슬롯에 전체 테이블 데이터 집합을 브로드캐스트하여 더 큰 테이블을 처리하는 방식으로 사용합니다. 이로 인해 정규화는 성능에 부정적인 영향을 미치지 않습니다. 사실, 그 반대가 되며 데이터 중복이 줄어들어 성능이 향상됩니다.\n\nBigQuery가 Broadcast Join을 사용하지 않을 때는 해시 조인 방식을 사용합니다. 이 경우 BigQuery는 해시 및 셔플 작업을 사용하여 일치하는 키가 동일한 슬롯에서 처리되도록 하여 로컬 조인을 수행합니다. 그러나 Broadcast Join과 비교할 때 이 작업은 데이터 이동이 필요하기 때문에 비용이 많이 들 수 있습니다.\n\n해시 조인이 사용되는 상황에 있다면, 여전히 성능을 개선할 수 있는 방법이 있습니다. 적어도 조인 열을 클러스터 열로 정의하는 것을 목표로 설정하세요. 이렇게 하면 데이터가 동일한 열 파일에 공존되어 셔플링의 영향이 줄어듭니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 최상의 접근 방식은 데이터 모델의 구체적인 내용과 정규화된 테이블의 크기에 따라 다릅니다. 정규화된 구조로 중복을 줄일 수 있고 동시에 JOIN 테이블의 크기를 작게 유지하여 Broadcast Joins를 사용할 수 있다면, 이것은 비정규화된 접근 방식보다 나은 해결책입니다. 그러나 10G 이상의 테이블에 대해서는 구체적인 벤치마킹을 통해 평가해야 하며, 이로 인해 아래의 황금 규칙이 나오게 됩니다:\n\n벤치마킹이 필수입니다! 이론에만 의존하지 마세요. 다양한 접근 방식(정규화, 비정규화, 중첩/반복)을 시험하여 특정 사용 사례에 가장 효율적인 해결책을 찾아보세요.\n\n## 파티션\n\n파티션은 한 가지 특정 열을 기준으로 테이블을 세그먼트로 나눕니다. 파티션 열은 3가지 접근 방식 중 하나를 사용할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n🗂️ 정수 범위 분할: 시작, 끝 및 간격을 기준으로 정수 열에 따라 분할하기\n\n⏰ 시간 단위 분할: 시간 단위, 일별, 월별 또는 연간 단위로 테이블의 날짜, 타임스탬프 또는 날짜/시간 열에 따라 분할하기\n\n⏱️ 적재 시간 분할: 현재 시간을 기준으로 데이터를 삽입할 때 _PARTITIONTIME이라는 가상 열을 사용하여 파티션 자동 할당하기\n\n파티션 열을 정의하는 것은 여러분에게 달려 있지만, 처리된 바이트량/청구액을 줄일 수 있는지 현명하게 선택하는 것이 매우 권장됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEff_8.png)\n\n예시:\n\n```js\nCREATE TABLE IF NOT EXISTS silver.some_partitioned_table (\n  title STRING,\n  topic STRING,\n  day DATE\n)\nPARTITION BY day\nOPTIONS (\n  partition_expiration_days = 365\n);\n```\n\n위 예시에서는 partition_expiration_days 옵션을 설정하는 방법도 확인할 수 있어요. 이 옵션은 X일 이전의 파티션을 자동으로 삭제해줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 클러스터링\n\n클러스터는 각 파티션 내의 데이터를 하나 이상의 열을 기반으로 정렬합니다. 쿼리 필터에서 클러스터 열을 사용할 때 이 기술을 사용하면 빅쿼리가 어떤 블록을 스캔해야 하는지 결정할 수 있어 실행 속도가 향상됩니다. 특히 다음 예제의 제목 열과 같은 고 카디널리티 열과 함께 사용하기를 권장합니다.\n\n최대 네 개의 클러스터 열을 정의할 수 있습니다.\n\n예시:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nCREATE TABLE IF NOT EXISTS silver.some_partitioned_table (\n  title STRING,\n  topic STRING,\n  day DATE\n)\nPARTITION BY day\nCLUSTER BY topic\nOPTIONS (\n  partition_expiration_days = 365\n);\n```\n\n## 중첩된 반복 열\n\n데이터 비정규화시 정보의 중복이 도입될 수 있습니다. 이러한 데이터 중복은 쿼리에서 처리해야 할 추가적인 저장 공간과 바이트를 추가합니다. 그러나 중복을 없애면서 비정규화된 테이블 디자인을 가질 수 있는 방법이 있습니다. 중첩 반복 열을 사용합니다.\n\n중첩된 열은 struct 타입을 사용하여 특정 속성을 하나의 객체로 결합합니다. 중첩 반복 열은 테이블의 단일 행에 대해 저장된 struct 배열입니다. 예를 들어, 사용자의 각 로그인마다 한 줄씩 저장하는 테이블이 있다면 해당 사용자의 ID 및 등록 국가와 함께 각 사용자의 로그인마다 ID 및 국가에 대한 중복이 발생합니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 사용자당 하나의 행을 저장하고 ARRAY STRUCT 유형의 열에 그 사용자의 모든 로그인을 저장할 수 있습니다. STRUCT는 날짜 및 장치와 같은 로그인에 연결된 모든 속성을 보유합니다. 다음 그림은 이 예시를 시각화한 것입니다:\n\n![그림](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_9.png)\n\n예시:\n\n```js\nCREATE TABLE silver.logins (\n    user_id INT64,\n    country STRING(2),\n    logins ARRAY\u003cSTRUCT\u003c\n        login_date DATE,\n        login_device STRING\n    \u003e\u003e,\n    day DATE\n)\nPARTITION BY day\nCLUSTER BY country, user_id\nOPTIONS (\n    require_partition_filter=true\n);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 예제는 partition column에 필터링이 없는 쿼리를 방지하는 require_partition_filter의 활용을 보여줍니다.\n\n이 데이터 모델링 기술은 저장 및 처리된 바이트를 크게 줄일 수 있습니다. 그러나 이것이 모든 비정규화나 데이터 모델링 경우에 대한 만병통치약은 아닙니다. 주요 단점은 다음과 같습니다: 구조체의 속성에 클러스터 또는 partition column을 설정할 수 없습니다.\n\n즉, 위의 예제에서 login_device로 필터링하는 경우 전체 테이블 스캔이 필요하며 이를 클러스터링으로 최적화할 수있는 옵션이 없습니다. 특히 테이블이 Excel 또는 PowerBI와 같은 타사 소프트웨어의 데이터 원본으로 사용될 경우 이것은 문제가 될 수 있습니다. 이러한 경우에는 중복성을 제거하는 이점이 클러스터링을 통한 최적화 부족을 보상하는지 신중히 평가해야 합니다.\n\n## 색인화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하나 이상의 열에 대한 검색 인덱스를 정의함으로써 BigQuery는 이를 사용하여 SEARCH 함수를 사용한 쿼리를 가속화할 수 있습니다.\n\n검색 인덱스는 다음과 같이 CREATE SEARCH INDEX 문을 사용하여 생성할 수 있습니다:\n\n```js\nCREATE SEARCH INDEX example_index ON silver.some_table(ALL COLUMNS);\n```\n\nALL COLUMNS를 사용하면 인덱스가 모든 STRING 및 JSON 열에 대해 자동으로 생성됩니다. 또한 더 선택적이며 열 이름 목록을 추가할 수도 있습니다. SEARCH 함수로는 인덱스를 활용하여 모든 열 또는 특정 열 내에서 검색할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT * FROM silver.some_table WHERE SEARCH(some_table, 'needle');\n```\n\n이 글을 쓰는 시점에 새로운 기능인 해당 기능은 미리 보기 상태에 있습니다. 추가로 =, IN, LIKE, STARTS_WITH와 같은 연산자에 대해 인덱스를 활용하는 것도 가능합니다. 이는 엔드 사용자가 직접 PowerBI나 Excel과 같은 제3자 도구를 통해 사용하는 데이터 구조에 매우 유용할 수 있으며, 일부 필터 작업의 속도를 높이고 비용을 절감하는 데 도움이 될 수 있습니다.\n\n이에 대한 자세한 내용은 공식 검색 인덱스 문서에서 확인할 수 있습니다.\n\n## 물리적 바이트 저장 요금\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빅쿼리는 저장에 대해 두 가지 요금 체계를 제공합니다: 표준 및 물리 바이트 저장 요금 청구. 올바른 모델을 선택하는 것은 데이터 액세스 패턴과 압축 능력에 따라 다릅니다.\n\n표준 모델은 간단합니다. 데이터 당 기가바이트당 일정 가격을 지불하며, 90일 동안 수정되지 않은 데이터에 대해 약간의 할인이 적용됩니다. 이 모델은 간단하게 사용할 수 있으며 다른 저장 구분을 관리할 필요가 없습니다. 그러나 데이터가 높은 압축률로 압축되었거나 자주 액세스하지 않는 경우에는 더 비싸게 나올 수 있습니다.\n\n물리 바이트 저장 요금 청구는 다른 방식으로 접근합니다. 저장하는 논리적 데이터의 양에 따라 비용을 지불하는 대신, 디스크에 차지하는 실제 공간에 따라 비용을 지불합니다. 액세스 빈도나 압축 정도에 상관없이, 이 모델은 높은 압축률로 저장된 데이터나 자주 액세스하지 않는 데이터에 대해 훨씬 저렴할 수 있습니다. 그러나 이 모델은 자주 액세스하는 데이터와 장기 보관용 데이터 두 가지 별도의 저장 클래스를 관리해야 하므로 복잡성이 더해집니다.\n\n그렇다면 어떤 모델을 선택해야 할까요? 여기에 간단한 안내가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표에 있는 내용을 Markdown 형식으로 변경해주세요.\n\n표:\n\n| 항목 | 설명 |\n|---|---|\n| 표준 모델 선택 | - 데이터가 고도로 압축되지 않았을 때. \u003cbr\u003e - 간단하고 쉽게 관리할 수 있는 방식을 선호할 때. |\n| PBSB 선택 | - 데이터가 고도로 압축되었을 때. \u003cbr\u003e - 비용을 최적화하기 위해 다양한 저장 등급을 관리하는 데 편안한 경우. |\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터셋의 고급 옵션에서 요금 청구 모델을 변경할 수 있어요. 또한 테이블 세부정보를 확인하여 논리적 vs 물리적 바이트를 비교할 수 있어서 모델 선택이 더 쉬워집니다.\n\n![image](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_10.png)\n\n## 기본 키 및 외래 키를 사용한 조인 최적화\n\n2023년 7월 이후로 BigQuery는 미적용된 기본 키 및 외래 키 제약 조건을 도입했어요. BigQuery가 고전적인 RDBMS가 아니라는 것을 염두에 두세요. 이 기능을 사용하여 데이터 모델을 정의하면 그런 느낌을 받을 수 있지만요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 키가 강제로 적용되지 않고 우리가 아는 관계형 데이터베이스가 아니라면 이것의 의미가 무엇일까요? 답은 다음과 같습니다: 쿼리 옵티마이저가 Inner Join Elimination, Outer Join Elimination, Join Reordering과 같은 개념을 사용하여 쿼리를 더 잘 최적화할 수 있습니다.\n\n제약 조건을 정의하는 것은 다른 SQL 방언과 유사하지만, 이를 NOT ENFORCED로 지정해야 한다는 것에 주의하세요:\n\n```js\nCREATE TABLE gold.inventory (\n date INT64 REFERENCES dim_date(id) NOT ENFORCED,\n item INT64 REFERENCES item(id) NOT ENFORCED,\n warehouse INT64 REFERENCES warehouse(id) NOT ENFORCED,\n quantity INT64,\n PRIMARY KEY(date, item, warehouse) NOT ENFORCED\n);\n```\n\n# ⚙️ 데이터 작업\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터 / 표 복사\n\n하나의 위치에서 다른 위치로 데이터를 복사하는 것은 데이터 엔지니어로서 일상적인 업무입니다. 예를 들어, BigQuery 데이터 세트인 bronze에서 다른 데이터 세트인 silver로 데이터를 복사하는 작업이라고 가정해 보겠습니다. 이를 위한 간단한 SQL 쿼리는 다음과 같습니다:\n\n```js\nCREATE OR REPLACE TABLE project_x.silver.login_count AS\nSELECT\n    user_id,\n    platform,\n    login_count,\n    day\nFROM project_x.bronze.login_count;\n```\n\n위 쿼리는 변환을 허용하지만, 많은 경우 단순히 데이터를 한 곳에서 다른 곳으로 복사하고 싶을 뿐입니다. 위 쿼리로 청구되는 바이트는 복사 대상에서 읽어야 하는 데이터 양에 해당합니다. 그러나 다음 쿼리로 이를 무료로 수행할 수도 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n토론_가장 login_count\n사본 project_x.bronze.login_count;\n```\n\n또는 bq CLI 도구를 사용하여 동일한 결과를 얻을 수 있습니다:\n\n```js\nbq cp project_x:bronze.login_count project_x:silver.login_count\n```\n\n이렇게 하면 데이터를 복사하는 데 비용이 발생하지 않습니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터 로드\n\n데이터 수집에는 Google Cloud Storage가 문제 해결에 실용적인 방법입니다. CSV 파일이든, 하둡 생태계의 ORC / Parquet 파일이든 또는 다른 소스에서 가져온 것이든 상관없이 데이터를 쉽게 업로드하고 저렴한 비용으로 저장할 수 있습니다.\n\n또한 GCS에 저장된 데이터 위에 BigQuery 테이블을 만들 수도 있습니다. 이러한 외부 테이블은 여전히 BigQuery의 컴퓨팅 인프라를 활용하지만 일부 기능과 성능을 제공하지는 않습니다.\n\nORC 스토리지 형식을 사용하는 분할된 하이브 테이블에서 데이터를 업로드한다고 가정해 봅시다. 데이터를 업로드하는 것은 distcp를 사용하거나 단순히 먼저 HDFS에서 데이터를 가져와서 사용 가능한 CLI 도구 중 하나를 사용하여 GCS로 업로드하는 것으로 이루어질 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가정하에 우리가 월이라는 하나의 파티션을 포함한 파티션 구조를 갖고 있다고 가정하면, 파일은 다음과 같이 보일 것입니다:\n\n```js\n/some_orc_table/month=2024-01/000000_0.orc\n/some_orc_table/month=2024-01/000000_1.orc\n/some_orc_table/month=2024-02/000000_0.orc\n```\n\n이 데이터를 GCS에 업로드했을 때, 외부 테이블 정의는 다음과 같이 생성될 수 있습니다:\n\n```js\nCREATE EXTERNAL TABLE IF NOT EXISTS project_x.bronze.some_orc_table\nWITH PARTITION COLUMNS\nOPTIONS(\n  format=\"ORC\",\n  hive_partition_uri_prefix=\"gs://project_x/ingest/some_orc_table\",\n  uris=[\"gs://project_x/ingest/some_orc_table/*\"]\n);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nORC 파일에서 스키마를 파생하고 파티션 열도 감지할 수 있습니다. GCS에서 BigQuery 스토리지로 데이터를 이동하는 가장 단순한 접근 방법은 이제 BigQuery에 테이블을 만든 다음 실용적인 INSERT INTO ... SELECT FROM 접근 방법을 따르는 것입니다.\n\n그러나 이전 예제와 마찬가지로 청구된 바이트는 gs://project_x/ingest/some_orc_table에 저장된 데이터 양을 반영할 것입니다. 데이터를 로드하는 데 0 비용으로 동일한 결과를 얻는 다른 방법이 있습니다. 이것은 LOAD DATA SQL 문을 사용하는 것입니다.\n\n```js\nLOAD DATA OVERWRITE project_x.silver.some_orc_table (\n  user_id INT64,\n  column_1 STRING,\n  column_2 STRING,\n  some_value INT64\n)\nCLUSTER BY column_1, column_2\nFROM FILES (\n  format=\"ORC\",\n  hive_partition_uri_prefix=\"gs://project_x/ingest/some_orc_table\",\n  uris=[\"gs://project_x/ingest/some_orc_table/*\"]\n)\nWITH PARTITION COLUMNS (\n  month STRING\n);\n```\n\n이 문을 사용하면 직접 데이터가 포함된 BigQuery 테이블을 얻게 되며, 먼저 외부 테이블을 만들 필요가 없습니다! 또한 이 쿼리는 0 비용으로 제공됩니다. OVERWRITE는 선택 사항입니다. 데이터가 추가되는 대신 테이블을 덮어쓸 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 볼 수 있듯이 파티션 열도 지정할 수 있습니다. 변환을 적용할 수 없더라도 한 가지 주요한 장점이 있습니다. 이미 클러스터 열을 정의할 수 있습니다. 이렇게 하면 추가 비용 없이 후속 처리를 위한 대상 테이블의 효율적인 버전을 만들 수 있습니다!\n\n## 파티션 삭제\n\n특정 ETL 또는 ELT 시나리오에서 흔한 워크플로우는 테이블이 날짜별로 파티셔닝되어 있고, 스테이징 / 적재 테이블에서 새 데이터가 기존 파티션을 대체하는 경우가 있습니다.\n\n![image](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBigQuery는 MERGE 문을 제공하지만 순진한 접근 방식은 먼저 대상 테이블에서 영향을 받는 파티션을 삭제한 다음 데이터를 삽입하는 것입니다.\n\n이러한 시나리오에서 파티션을 삭제하는 것은 다음과 같이 수행할 수 있습니다:\n\n```js\nDELETE FROM silver.target WHERE day IN (\n  SELECT DISTINCT day\n  FROM bronze.ingest\n);\n```\n\n두 경우 모두 day가 파티션 열이라 할지라도, 이 작업은 여러 비용과 관련이 있습니다. 그러나 다시 한 번 0 비용으로 제공되는 대안 솔루션이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nDROP TABLE silver.target$20240101\n```\n\nDROP TABLE을 사용하면 실제로는 $`partition_id` 접미사를 추가하여 하나의 파티션만 삭제할 수도 있어요.\n\n물론 위 예제는 단 하나의 파티션을 삭제하는 것 뿐이에요. 그러나 BigQuery의 프로시저 언어를 사용하면 쉽게 루프에서 문을 실행할 수 있어요.\n\n```js\nFOR x IN (SELECT DISTINCT day FROM bronze.ingest)\nDO\n  SELECT x; -- DROP TABLE으로 바꿔주세요\nEND FOR;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또는 Airflow 및/또는 dbt를 사용하여 먼저 파티션을 선택한 다음 특정 템플릿화된 쿼리를 반복해서 실행할 수 있습니다.\n\n그러나 파티션된 테이블의 고유한 파티션을 가져오는 것은 위의 예제처럼 진행할 수 있지만, 한 열만 읽는 경우에도 일부 비용이 발생할 수 있습니다. 그러나 여기에도 다시 한 번 이를 거의 무료로 얻을 수 있는 방법이 있습니다. 이에 대해 다음 챕터에서 알아보겠습니다.\n\n## 테이블의 고유한 파티션 가져오기\n\n위의 예제에서 우리는 파티션이 있는 BigQuery 테이블의 고유한 파티션을 가져오기 위해 다음 방법을 사용했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT DISTINCT day\nFROM bronze.ingest\n```\n\n이 예시 사용 사례에서 내가 사용한 쿼리가 얼마나 비용이 들었는지:\n\n```js\n청구된 바이트: 149.14 GB (= 위치에 따라 $1.18)\n```\n\nBigQuery는 테이블, 열 및 파티션에 대한 많은 유용한 메타데이터를 유지합니다. 이 정보에는 INFORMATION_SCHEMA를 통해 액세스할 수 있으며, 이 메타데이터를 사용하면 동일한 결과를 간단히 얻을 수 있습니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT PARSE_DATE('%Y%m%d', partition_id) AS day\nFROM bronze.INFORMATION_SCHEMA.PARTITIONS\nWHERE table_name = 'ingest'\n```\n\n그리고 위에서 언급한 것과 같은 사용 사례를 비교하면, 쿼리 비용은 다음과 같습니다:\n\n```js\n청구된 바이트: 10MB (위치에 따라 $0.00008)\n```\n\n149GB와 10MB를 비교하면 엄청난 차이가 납니다. 이 방법을 사용하면 거의 0 비용으로 거대한 테이블에 대한 고유한 파티션을 얻을 수 있습니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 계산된 측정치 유지하지 마세요\n\n처음으로 BigQuery를 사용하기 시작할 때는 대부분 온디맨드 컴퓨트 가격 모델을 사용할 것입니다. 온디맨드 가격 적용 시, 단일 프로젝트 내 모든 쿼리에서 공유되는 최대 2000개의 동시 슬롯에 액세스할 수 있습니다. 그러나 정적 가격 책정을 사용하더라도 최소 100개의 슬롯을 사용할 수 있습니다.\n\n많은 일일 ETL / ELT 워크로드 중에는 이러한 슬롯이 실제로 성능의 제한 요소가 아닙니다. \"BigQuery - Administration - Monitoring\"으로 이동하여 위치를 선택한 후 차트를 \"슬롯 사용량\"으로 변경하여 이를 직접 확인할 수 있습니다. 많은 경우, 실제 사용 중인 슬롯이 얼마나 적은지 놀랄 만할 것입니다.\n\n![이미지](/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_12.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그것이 비용 절감과 어떤 관련이 있을까요? 가정해봅시다. 고전적인 펙트 테이블이나 어떤 테이블이든 특정 KPI를 제공하는 테이블이 있다고 합시다. 이 테이블은 그런 다음 Looker, Excel, PowerBI 또는 다른 도구에서 분석/보고용으로 사용됩니다.\n\n이러한 도구는 종종 보고서나 대시 보드에 필요한 데이터를 제공하기 위해 쿼리를 자동으로 생성합니다. 이러한 생성된 쿼리는 BigQuery의 최상의 실행 관행을 적용하는 데 적합하지 않을 수 있습니다. 다시 말해, 필요한 것보다 더 많은 데이터를 스캔하게 되어 청구된 바이트가 증가할 수 있습니다.\n\n이 문제를 피하기 위해 사실 테이블 위에 뷰 레이어를 도입할 수 있습니다. 실제 테이블 대신 뷰로부터 도구에 데이터를 제공하는 것은 매우 중요한 최상의 실행 관행입니다. 이는 스키마 변경 시 더 많은 유연성을 제공하지만 동시에 데이터를 지속하지 않고 뷰 내에서 계산된 측정값을 도입할 수 있는 가능성도 제공합니다.\n\n물론 이러한 측정값이 사용될 때 CPU 사용량이 증가할 수 있지만, 반대로 기본 테이블의 총 크기를 줄일 수 있는 큰 장점이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 원리를 설명하기 위해 다음 사실 테이블을 기초로 삼아보겠습니다:\n\n```js\nCREATE TABLE IF NOT EXISTS gold.some_fact_table (\n  user_id INT64,\n  payment_count INT64,\n  value_1 INT64,\n  value_2 INT64,\n  day DATE\n)\nPARTITION BY day\nCLUSTER BY user_id\nOPTIONS (\n  partition_expiration_days = 365\n);\n```\n\n기본 아이디어는 해당 데이터에 액세스하는 이해관계자를 위한 뷰를 도입하고 계산된 측정값으로 확장하는 것입니다:\n\n```js\nCREATE OR REPLACE VIEW gold.some_fact_view AS\nSELECT\n  user_id,\n  payment_count,\n  value_1,\n  value_2,\n  payment_count \u003e 0 AS is_paying_user,\n  value_1 + value_2 AS total_value,\n  day\nFROM gold.some_fact_table;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예시에서는 두 개의 INT64 값을 영속화하지 않을 수 있었습니다. 이 중 하나는 8개의 논리적인 바이트를 사용합니다. 만약 우리의 팩트 테이블이 1,000,000,000 행을 가지고 있다면, 이것은 우리가 다음을 저장한다는 것을 의미합니다:\n\n```js\n1000000000 행 * 8 B * 2 열 / 1024 / 1024 / 1024 = 15 GB\n```\n\n이는 많은 양의 데이터가 아니지만, 이는 특정 상황에서 BigQuery가 15GB 덜 스캔해야 할 수도 있음을 의미합니다. 실제로 스캔해야 하는 데이터를 훨씬 줄일 수 있는 계산된 측정 값들이 있을 수 있습니다.\n\n# 📚 요약\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n용량을 보존하는 것이 아니라, 데이터를 스마트하게 관리하고 최적화하는 방법을 배워봐! 이 뜨거운 접근 방식을 통해 빅쿼리를 비용 부담이 아닌 데이터 탐색을 위한 강력한 엔진으로 변화시킬 수 있어. 이를 통해 돈이 아닌 데이터를 소모할 수 있을 거야!\n\n## 데이터 모델링 최고의 실천법 채택하기\n\n- 저장 및 처리 비용을 최소화하기 위해 가능한 가장 작은 데이터 유형을 활용해.\n- 쿼리 성능을 최적화하고 저장 공간을 줄이기 위해 적절한 경우에 비정규화 활용하기.\n- 쿼리에 필요한 데이터만 효율적으로 스캔할 수 있도록 파티셔닝 및 클러스터링 구현하기.\n- 중첩 반복되는 열을 탐색하여 중복성을 제거하고 데이터 무결성을 유지하되, 클러스터링에 관한 제한 사항을 염두에 두기.\n\n## 비용 효율성을 위한 데이터 작업 마스터하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 데이터 전송 시 요금을 부과하지 않고 테이블 간 데이터를 복사하려면 CREATE TABLE ... COPY 또는 bq cp 명령을 사용하세요.\n- LOAD DATA 문을 사용하여 클라우드 스토리지에서 BigQuery 테이블로 데이터를 직접 로드하는 것도 무료입니다.\n- 특정 파티션을 효율적으로 제거하려면 DROP TABLE과 분할 접미사를 활용하세요.\n- 전통적인 쿼리에 비해 비용을 크게 절감할 수 있는 DISTINCT 파티션 값을 포함한 테이블 메타데이터를 검색하려면 INFORMATION_SCHEMA를 활용하세요.\n\n## 효율성을 위해 설계하고 불필요한 데이터 지속성을 피하세요\n\n- 계산된 측정값으로 데이터를 제공하기 위한 뷰 레이어를 구현하여 중복 데이터를 저장하지 않습니다.\n- BigQuery 슬롯 사용량을 모니터링하여 슬롯 제한이 문제가 될 경우에 대비하여 쿼리 구조를 최적화하는 데 집중할 수 있습니다.\n\n댓글에서 여러분의 경험을 자유롭게 공유해주세요!","ogImage":{"url":"/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_0.png"},"coverImage":"/assets/img/2024-05-23-ADefinitiveGuidetoUsingBigQueryEfficiently_0.png","tag":["Tech"],"readingTime":21},{"title":"아마존 데이터 분석가를 위한 SQL 인터뷰 질문","description":"","date":"2024-05-23 16:00","slug":"2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst","content":"\n\u003cimg src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_0.png\" /\u003e\n\n아마존에서 데이터 분석가 직군 면접 때 물어본 문제입니다. 병원에는 직원들이 여러 번 들어오고 나갈 수 있습니다.\n\n이제 병원 안에 있는 직원을 찾아내야 합니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요기 데이터 있어요. 이제 병원 안에 있는 직원의 emp_id를 찾아야 해요.\n\n이 질문은 두 가지 방법으로 해결할 수 있어요.\n\n방법 1\n\n여기서 우리는 각 직원의 최신 출근 시간과 최신 퇴근 시간을 찾을 거예요. 직원은 최신 출근 시간이 최신 퇴근 시간보다 늦거나 최신 퇴근 시간이 알려지지 않은 경우에 병원에 있을 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 결과를 통해 emp_id 2, 3, 4가 조건을 만족시킨다는 것을 확인할 수 있습니다. 따라서 이들 직원들은 병원 안에 있습니다.\n\n최종 쿼리는 다음과 같습니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_3.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 방법 2\n\n여기서는 각 직원의 최신 활동 시간을 찾은 다음, 해당 시간에 직원의 활동이 무엇이었는지 알아낼 것입니다. 그 후에 해당 직원을 필터링할 것입니다.\n\n![image](/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_4.png)\n\n이제 해당 시간에 직원의 활동을 찾아보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_5.png\" /\u003e\n\n지금은 최신 활동이 \"in\"인 것을 필터링할 것입니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_6.png\" /\u003e\n\n방법 3: 여기서 우리는 각 emp_id의 행 번호를 내림차순으로 시간 순서대로 생성할 것입니다. 그런 다음 CTE를 생성한 다음, 행 번호가 =1이고 활동이 'in'인 emp_id를 추출할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT *,ROW_NUMBER() OVER(PARTITION BY emp_id ORDER BY time DESC) AS rnk\nFROM hospital)\nSELECT *\nFROM x\nWHERE rnk=1 AND action='in';\n```\n\n![Image](/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_7.png)\n\nPlease clap if you find the solution helpful.\n\nLet's connect on LinkedIn! 🤝\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n포트폴리오를 확인해보세요.\n","ogImage":{"url":"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_0.png"},"coverImage":"/assets/img/2024-05-23-AmazonSQLInterviewQuestionforDataAnalyst_0.png","tag":["Tech"],"readingTime":2},{"title":"오픈소스 SQLFrame을 소개합니다 ","description":"","date":"2024-05-23 16:00","slug":"2024-05-23-Introducingopen-sourceSQLFrame","content":"\n13년간 데이터 엔지니어로 근무하면서 변화에 익숙해졌어요. 클라우드 이전과 같은 중요한 변화나 노트북 활용과 같은 작은 트렌드와 같은 것들이죠. 이 모든 변화 속에서도 하나는 불변해 왔어요: SQL이죠. 스타트업부터 FAANG까지 다양한 회사에서 일한 경험을 통해 알게 된 것은 SQL을 잘 이해하고 작성해야 한다는 것이었어요. SQL은 모든 데이터 전문가들을 통합하는 보편적 언어이며, 복잡한 분산 처리의 세부사항을 처리하는 쿼리 플래너와 옵티마이저를 통해 효율적인 데이터 파이프라인을 구축할 수 있게 해줘요.\n\nSQL의 강점에도 불구하고, 이 언어는 종종 데이터 파이프라인 유지 관리에는 적합하지 않아 보일 수 있어요. 이 언어는 일반적인 작업을 추상화하거나 코드의 특정 세그먼트에 대한 단위 테스트를 지원하지 않아서, 많은 사람들이 임시 방법으로 Jinja를 사용하곤 해요. Jinja SQL은 SQL의 Pig Latin과 같은 관계로, 작은 량에서는 재미있을 수도 있지만, 대규모로 확장하면 이해하기 어려워지기도 해요. 더구나, SQL의 반복적인 특성은 열을 반복해서 지정해야 하는 것으로, 종종 데이터 전문가들 사이에서 피로감을 일으킬 수 있어요.\n결국, 데이터 전문가들은 SELECT \\*의 유혹에 반응하며 불확실성의 바다에서 침몰하게 되기도 해요.\n\n이로써 데이터 전문가들이 어려운 선택을 하게 되었어요: 접근성을 우선시하여 SQL로 파이프라인을 작성할 것인가요, 아니면 유지보수성을 우선시하여 Python으로 작성할 것인가요? 오늘부터는 더 이상 선택할 필요가 없어요. 이제 여러분은 동시에 케이크를 먹고 가질 수 있게 되었어요.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*JZ4jUIBrQAf-oovf3IFN1w.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 오픈소스 SQLFrame 소개! 🎉\n\n![이미지](/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_0.png)\n\nSQLFrame은 데이터 전문가들이 SQL 및 PySpark 데이터프레임과 상호 작용하는 방식을 혁신합니다. 전통적인 PySpark과 달리 SQLFrame은 DataFrame 작업을 직접 SQL로 변환하여 개발 중에 실시간 SQL 스크립트 생성을 가능하게 합니다. 작동 방법은 다음과 같습니다:\n\n공개적으로 접근 가능한 출생 데이터를 기반으로 단일 아동을 선택한 새 가족의 수를 분석하는 시나리오를 고려해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\njs\nfrom sqlframe.bigquery import BigQuerySession\nfrom sqlframe.bigquery import functions as F\nfrom sqlframe.bigquery import Window\n\n# SQLFrame에서 제공하는 고유 기능: 빅쿼리에 직접 연결할 수 있는 능력\nsession = BigQuerySession(default_dataset=\"sqlframe.db1\")\ntable_path = \"bigquery-public-data.samples.natality\"\ndf = (\n    session.read.table(table_path)\n    .where(F.col(\"ever_born\") == 1)\n    .groupBy(\"year\")\n    .agg(F.count(\"*\").alias(\"num_single_child_families\"))\n    .withColumn(\"percent_change\", 1 - F.lag(F.col(\"num_single_child_families\"), 1).over(Window.orderBy(\"year\")) / F.col(\"num_single_child_families\"))\n    .orderBy(F.abs(F.col(\"percent_change\")).desc())\n    .select(\n        F.col(\"year\").alias(\"Year\"),\n        F.format_number(\"num_single_child_families\", 0).alias(\"number of new families single child\"),\n        F.format_number(F.col(\"percent_change\") * 100, 2).alias(\"percent change\"),\n    )\n    .limit(5)\n)\n# SQLFrame에서 제공하는 고유 기능: DataFrame의 SQL 확인 가능\ndf.sql()\n\n\nSQLFrame를 사용하면 특별한 빅쿼리 클래스를 활용하여 빅쿼리 환경과 시스템을 원활하게 통합할 수 있습니다. DataFrame 작업은 PySpark에서 수행하는 것과 유사하지만 SQLFrame를 이용하면 df.sql() 메서드를 사용하여 실시간으로 생성 및 검토하는 대응하는 SQL 쿼리도 볼 수 있습니다.\n\njs\nWITH `t94228` AS (\n  SELECT\n    `natality`.`year` AS `year`,\n    COUNT(*) AS `num_single_child_families`\n  FROM `bigquery-public-data`.`samples`.`natality` AS `natality`\n  WHERE\n    `natality`.`ever_born` = 1\n  GROUP BY\n    `natality`.`year`\n), `t34770` AS (\n  SELECT\n    `t94228`.`year` AS `year`,\n    `t94228`.`num_single_child_families` AS `num_single_child_families`,\n    1 - LAG(`t94228`.`num_single_child_families`, 1) OVER (ORDER BY `t94228`.`year`) / `t94228`.`num_single_child_families` AS `percent_change`\n  FROM `t94228` AS `t94228`\n  ORDER BY\n    ABS(`percent_change`) DESC\n)\nSELECT\n  `t34770`.`year` AS `year`,\n  FORMAT('%\\'.0f', ROUND(CAST(`t34770`.`num_single_child_families` AS FLOAT64), 0)) AS `number of new families single child`,\n  FORMAT('%\\'.2f', ROUND(CAST(`t34770`.`percent_change` * 100 AS FLOAT64), 2)) AS `percent change`\nFROM `t34770` AS `t34770`\nLIMIT 5\n\n\n이 기능은 이해를 증진시킬 뿐만 아니라 SQL 출력이 결정론적이어서 버전 관리에 적합하게 만듭니다. 이렇게 함으로써 파이썬 및 SQL 파이프라인의 표현을 모두 버전 관리할 수 있고 동료들이 가장 잘 맞는 형식을 선택할 수 있게 합니다!\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\n![SQLFrame](https://miro.medium.com/v2/resize:fit:808/1*y_ZC1qkDPllTA3Yk3XiC8A.gif)\n\nSQLFrame은 SQL을 생성하는 것 이상을 제공합니다: PySpark DataFrame API가 모든 주요 데이터 웨어하우스에서 네이티브 DataFrame API처럼 느껴지게 하는 것이 목표입니다. 따라서 사용자들은 스파크 클러스터나 라이브러리 없이 데이터 웨어하우스에서 DataFrame API 파이프라인을 직접 실행할 수 있습니다!\n\n예를 들어, .sql()을 .show()로 바꾸면 파이프라인에서 빅쿼리에서 결과를 직접 표시할 수 있습니다. 이는 PySpark에서와 같은 방식으로 작동합니다.\n\npython\n\u003e\u003e\u003e df.show()\n+------+-------------------------------------+----------------+\n| year | number of new families single child | percent change |\n+------+-------------------------------------+----------------+\n| 1989 |              1,650,246              |     20.01      |\n| 1974 |               783,448               |     12.66      |\n| 1977 |              1,057,379              |     10.22      |\n| 1985 |              1,308,476              |     10.03      |\n| 1975 |               868,985               |      9.84      |\n+------+-------------------------------------+----------------+\n\n\n`\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n많은 카탈로그 작업이 지원되며 listColumns와 같은 것이 지원됩니다:\n\n```js\n\u003e\u003e\u003e columns = session.catalog.listColumns(table_path)\n\u003e\u003e\u003e print(\"\\n\".join([f\"Name: {x.name}, Data Type: {x.dataType}, Desc: {x.description}\" for x in columns]))\nName: source_year, Data Type: INT64, Desc: Four-digit year of the birth. Example: 1975.\nName: year, Data Type: INT64, Desc: Four-digit year of the birth. Example: 1975.\nName: month, Data Type: INT64, Desc: Month index of the date of birth, where 1=January.\nName: day, Data Type: INT64, Desc: Day of birth, starting from 1.\nName: wday, Data Type: INT64, Desc: Day of the week, where 1 is Sunday and 7 is Saturday.\nName: state, Data Type: STRING, Desc: The two character postal code for the state. Entries after 2004 do not include this value.\n```\n\n따라서 SQLFrame은 단순히 DataFrame 파이프라인을 더욱 접근 가능하게 만들 뿐만 아니라, PySpark DataFrame API를 보다 범용의 DataFrame API로 변환하여 모든 데이터 전문가가 즐길 수 있습니다!\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:720/1*JQ7uBfQn-4VWWWlfl5D_sA.gif\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSQLFrame은 현재 BigQuery, DuckDB 및 Postgres를 지원하고 있으며, Clickhouse, Redshift, Snowflake, Spark 및 Trino가 개발 중에 있습니다. 다른 엔진을 위한 SQL 생성 실험을 원하는 경우 Standalone 세션에서 유연한 테스트 환경을 제공합니다.\n\nSQLFrame을 시작하려면 GitHub 리포지토리를 확인해보세요!\n\n![SQLFrame 소개](/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_1.png)\n","ogImage":{"url":"/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_0.png"},"coverImage":"/assets/img/2024-05-23-Introducingopen-sourceSQLFrame_0.png","tag":["Tech"],"readingTime":6},{"title":"효율적인 BigQuery 데이터 모델링 저장 및 계산 비교","description":"","date":"2024-05-23 15:56","slug":"2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison","content":"\n\n## BigQuery 저장 및 컴퓨팅 동적을 비교한 정규화, 비정규화 및 중첩 모델: 실행 가능한 최적화, 권장사항 및 모범 사례를 포함한 심층 분석.\n\n![Image](/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_0.png)\n\n# 소개\n\n좋은 데이터 모델링은 최상의 스키마 설계를 선택하고 그대로 고수하는 것이 아니라 여러 스키마 디자인을 결합하는 것입니다. 대신, 좋은 데이터 모델은 정규화, 중첩 또는 비정규화 테이블 및 뷰의 실용적인 혼합물입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글은 여러분의 맥락에 최선의 도움이 되도록 처음부터 이 결론까지 안내하고자 합니다.\n\n본 글은 초심자나 전문가들이 자신의 맥락에서 데이터 모델을 설계할 때 좋은 질문을 하고 더 자유롭게 할 수 있도록 도와주기 위해 작성되었습니다.\n\n저희는 중첩, 정규화 및 비정규화 스키마 설계를 재정의하는 기본 지식부터 시작하겠습니다. 그런 다음 BigQuery 아키텍처를 탐구하며 저장 및 컴퓨팅 자원 측면에서 성능 테스트 및 비교를 진행할 것입니다.\n\n그러나 비용 최적화만으로는 충분하지 않습니다. 이 글의 끝에는 다른 요인들, 권장 사항 및 최상의 실천 방법을 여러분과 공유하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 요약\n\n∙ 소개\n∙ 중첩 스키마\n∙ 정규화된 스키마\n∙ 비정규화된 스키마\n∙ 모두 합치기\n∙ 저장소 비교\n∙ BigQuery 아키텍처\n∙ 컴퓨트 비교\n∙ 크기 대 성능\n∙ BigQuery 스키마 디자인 선택\n∙ 권장 사항\n∙ 결론\n\n# 중첩 스키마\n\n가장 복잡한 스키마 디자인부터 시작해보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 발견한 것은 약간의 역설인데, 중첩 스키마가 일반적으로 가장 무서운 것으로 여겨집니다. 그러나 때로는 데이터를 표현하는 가장 자연스러운 방법이기도 합니다. 그런데 왜 그런지를 이해하기 위해 과거로 돌아가 봅시다.\n\n중첩 및 반복 데이터 구조는 주로 NoSQL 데이터베이스와 대조적으로 SQL 데이터베이스(또는 관계형 데이터베이스)와 연관되어 있습니다. 역사적으로 이는 데이터를 저장하는 자연스러운 방법이 아니었습니다. 데이터는 전통적으로 정규화되었습니다. 우리는 나중에 정규화된 스키마에 대해 다시 이야기할 것이지만, 지금은 SQL이 처음에는 행과 열을 처리하기 위해 만들어졌다는 점만 이해해 주세요. 중첩 구조가 아니었습니다.\n\n데이터 웨어하우스와 대규모 데이터 및 분석 데이터베이스(안녕하세요, BigQuery)의 발전과 함께, 다양한 형태와 구조가 등장했습니다. 네, 쿼리하는 것이 더 복잡할 것이라 동의합니다. 아마 그것이 왜 그렇게 무서운지의 이유일지도 모릅니다...\n\n얘기는 여기까지 하고, 저희 예시로 들어가 봅시다. 소매업계의 세계에 오신 것을 환영합니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 기사와 첫 번째 예제를 시작해봅시다. 쇼핑 바구니(또는 영수증)의 경우를 고려해보겠습니다. 영수증이란 무엇인가요? 상점에서 고객이 구매한 총 가격과 특정 날짜를 나타내는 객체입니다. 하지만 총 가격 이상으로, 여러 줄을 포함하고 있습니다. 이러한 줄들은 판매된 제품, 구매 가격, 수량 등을 나타냅니다.\n\n간단하죠? 여러 개의 하위 객체를 포함하는 하나의 객체가 있습니다. 바구니는 여러 제품을 포함합니다.\n\nBigQuery나 소매업계에 입문하신 분이라면, 저는 간단한 바구니 테이블을 만들었습니다. 이 테이블에는 RECORD 타입과 REPEATED 모드인 상세 설명 열이 포함되어 있습니다.\n\n중첩 스키마를 사용하여 현실 세계에서 일어나는 일을 반영했습니다. 한 행은 하나의 바구니 헤더를 나타냅니다. 각 바구니 헤더는 세부사항을 포함하고 있습니다. 상세 항목의 각 \"하위 행\"은 판매된 제품을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 https://www.mockaroo.com/에서 가짜 데이터를 사용하여 이 표를 채웠고, 수백 번의 데이터를 복제하여 약 10GB 크기의 표를 만들었습니다.\n\n여기 있습니다. 데이터를 발견하는 자연스럽고 우아한 방법입니다. 위 이미지에 두 개의 행이 있어 두 개의 바구니 주문이 있습니다. 각 주문은 detail 필드 내에 있고 구조체 배열로 구성된 임의의 수의 품목이 포함되어 있습니다.\n\n# 정규화된 스키마\n\n정규화된 스키마 또는 스타 스키마(보다 복잡한 경우 스노우플레이크 스키마)는 각 테이블이 특정 엔티티나 관계에 집중된 구조로, 외래 키를 사용하여 테이블 간 관계를 설정합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n관계형 데이터베이스에 대해 생각하는 표준 방법입니다. 이는 제 1 정규형(1NF)을 따릅니다. 모든 열은 단일 값 속성(배열 없음)이어야하며 복합 값(구조체 또는 중첩 없음)을 포함해서는 안됩니다.\n\n1NF 규칙을 따르면, 바구니 테이블을 바구니_헤더와 바구니_세부 테이블로 분해합니다. 위의 쿼리를 고려하면서.\n\n거의 대부분의 데이터베이스에서는 이러한 종류의 스키마 설계가 있습니다. 이는 관계형 데이터베이스를 관리하는 역사적(그리고 가장 쉬운) 방법입니다.\n\n\"가장 쉬운\"이라고 말한 이유는 기본 SQL 쿼리로 데이터를 얻을 수 있기 때문입니다. 한 테이블은 한 개체/기능/객체입니다. 개체 간의 관계는 외부 키로 설정됩니다. 우리의 경우, 각 바구니_헤더 행이 한 개 이상의 바구니_세부 행에 연결될 것임을 알고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 이미지에서 보는 것처럼, 이러한 종류의 구조의 장점은 각 테이블이 특정 entity에 대한 답변을 제공하는 방식에 있습니다. 바구니 헤더는 자체 테이블에, 바구니 상세 정보도 독립적인 테이블에 있습니다. 데이터가 분할되어 있지만 바구니 헤더의 기본 키로 쉽게 결합할 수 있습니다 (이미지에서의 화살표).\n\n또한, 데이터가 복제되거나 중복되지 않음을 유의하십시오. 정보를 업데이트해야 할 경우, 한 테이블과 한 행(즉, 한 값)에서만 수정하면 됩니다.\n\n# 비정규화 스키마\n\n비정규화는 사전 계산된 조인의 결과로 볼 수 있는 스키마 설계입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이름에서 볼 때 정규화의 반대로 이해할 수 있지만, 이 스키마를 그렇게 보면 안 돼요. 사실 이 구조는 정규화된 스키마를 잘 보완해주죠. (여러 스키마 디자인을 선택해 데이터를 표현하는 가장 좋은 방법이 어떤 것인지 예측하고 있죠?)\n\n이러한 유형의 스키마가 어떻게 가치를 더하는지 그리고 비정규화가 다른 데이터 모델을 어떻게 보완하는지 이해하려면 다음 섹션을 기다려야 할 거예요.\n\n지금은 장바구니의 헤더와 세부사항을 결합한 결과를 살펴봐야 해요.\n\n새로 만든 이 테이블에서 보듯이, 비정규화는 쿼리 복잡성을 줄여줍니다. 결합할 테이블이 여러 개 없으며 중첩/반복되는 필드도 없어요. 간단히 말해, 조인은 이미 완료되었고 영수증 세부내역만 남아 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 쿼리가 이 테이블 스키마로 쉬워진다는 장점이 있지만, 중복 데이터가 포함되어 있습니다. 여기서 헤더 데이터는 각 라인마다 반복됩니다. 이로 인해 중복성이 높아지고 일관성 문제가 발생할 수 있습니다. 게다가 헤더에 업데이트를 적용하는 것이 더 어려워보입니다. 한 가지 더 언급할 점은 데이터가 x번 복제되기 때문에 헤더에 대한 업데이트를 적용하는 것이 더 복잡해진다는 것입니다. 이 테이블의 또 다른 어려움은 \"조인(join)\"의 수가 증가함에 따라 테이블의 세분성(granularity)을 인식하는 것입니다.\n\n# 전부가 다 함께\n\n잘했어요. 이제 세 가지 가장 흔한 스키마 디자인을 보았고(네, 그 외에도 많이 있습니다), 우리 테이블은 테스트할 준비가 되었습니다.\n\n성능 테스트로 넘어가기 전에 특정 사항에 주목해 주고 싶습니다. 언제든 다른 스키마로 전환할 수 있습니다. 이겦거보시죠: 이 기사에서는 먼저 중첩 형식을 만들고, 이 초기 테이블을 기반으로 다른 형식을 구성했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약해보면 다음과 같습니다:\n\n- 중첩형: 현실 세계를 잘 표현한 우아한 형식이지만 쿼리하기에는 복잡할 수 있습니다.\n- 정규화된 형식: 역사적인 형식으로 모든 이가 익숙해하지만, 계산을 위해 최적화되진 않을 수도 있습니다.\n- 비정규화된 형식: 데이터베이스에서 계산에 매우 최적화되어 있지만 중복을 초래할 수 있는 흥미로운 데이터 형식입니다.\n\n# 저장소 비교\n\n다음 표는 BigQuery에서 세 가지 다른 스키마 디자인 기술을 사용하여 동일한 10GB 데이터를 저장하는 데 필요한 저장소를 비교합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n중첩 형식이 데이터를 계층 구조로 저장하여 자연스러운 압축을 가능하게 하기 때문입니다. 정규화 형식은 그렇게 멀지 않습니다. 중복은 없지만 기본 키에 대한 추가 열이 작성되어야 합니다. 반면에 비정규화 형식의 평면 구조는 데이터 반복으로 인해 가장 공간 효율적이지 않음을 입증합니다.\n\n그러나 이 비교에 조금의 색깔을 더해볼까요? 중첩 형식을 기준으로 삼아보겠습니다 (베이스 1로).\n\n중첩 데이터 모델이 가장 최적화되어 있으며 데이터 중복을 최소화하고 최대 2배 또는 3배의 저장 공간을 절약할 수 있습니다. (귀하의 FinOps가 귀하를 사랑할 것입니다!)\n\n물리적 또는 논리적 (기본) 저장소 가격 아래에 있더라도 중첩 스키마 설계는 더 저렴한 송장으로 이어집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# BigQuery 아키텍처\n\n여기에 BigQuery 아키텍처에 대한 자세한 섹션을 포함할 계획이 있었어요. 하지만 책을 쓰는 게 아니니까, 그건 다른 시간에 남겨두기로 해요. 한편, 다른 기사들로 링크를 제공할게요.\n\nBigQuery가 어떻게 구성되어 있는지 이해하는 것은 여전히 중요해요. 직관력을 통해 다음 섹션에서 컴퓨팅에 미치는 영향을 다룰 거에요.\n\n![이미지](/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n왜 스토리지의 차이점만 다른 부분에서 다루었느냐고 물으면, 이는 이해하기 쉬운 섹션을 만들기 위해서이기도 하지만 BigQuery 아키텍처의 논리를 따르기 위해서입니다.\n\n분석 데이터베이스의 강점은 네 가지 간단한 개념으로 요약할 수 있습니다:\n\n- 스토리지와 컴퓨팅의 분리: BigQuery에서 데이터 스토리지와 계산 작업이 분리됩니다. 이 분리를 통해 스토리지와 컴퓨트를 최적화하여 성능을 극대화할 수 있습니다.\n- 열 지향 스토리지: BigQuery는 데이터를 열 지향 형식으로 저장합니다. 이는 각 열의 값이 함께 저장된다는 것을 의미합니다. 이 스토리지 방법은 분석 작업에 최적화되어 있어 주어진 쿼리에 필요한 열만 읽을 수 있게 함으로써 (전체 행이 아닌) 대기 시간을 줄이고 성능을 향상시킵니다.\n- 분산 컴퓨팅: BigQuery의 데이터는 병렬 처리를 위해 여러 컴퓨트 노드(슬롯)에 분산되어 있습니다. 이를 통해 쿼리 처리를 빠르게 할 수 있으므로 쿼리 복잡성이나 입력 데이터 크기에 관계없이 성능을 향상시킬 수 있습니다.\n- 네트워크: BigQuery는 스토리지와 컴퓨트 간 데이터 전송을 위한 고대역폭을 제공합니다. 이는 대량의 데이터를 처리할 때에도 높은 성능을 보장합니다.\n\n이러한 기본 원칙을 이해한다면 BigQuery가 어떻게 고성능이고 확장 가능한 데이터 분석을 실현하는지 알 수 있을 것입니다. 그리고 확실히 최적화하는 방법도 이해하게 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 연산 비교\n\n다시 비교로 돌아가봅시다. 중첩 형식의 저장소가 가장 최적화되어 있어 중복을 최소화한다는 것을 보았습니다. 그렇다면 연산 자원은 어떨까요?\n\n총 처리된 바이트의 양에는 놀라운 점이 없습니다. 이전 섹션에서 본 것과 동일합니다. 하지만 이것을 간과해서는 안 됩니다: 데이터가 적을수록 연산 비용도 낮아지는 것이 기본입니다!\n\n자연 및 알고리즘적 데이터 압축은 저장 속에서 쿼리 가격에 중요한 초기 영향을 미칩니다. 이 아이디어를 염두에 두고 연산에 특화된 차이점을 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 중첩 및 비정규화 형식을 비교해보면 쿼리 응답 시간이 유사함을 알 수 있습니다. BigQuery는 컴퓨팅을 병렬화하는 방식으로 관리하기 때문에 사용자에게 컴퓨팅 리소스가 우수했음을 알리지 않습니다. 그러나 실제로는 그렇습니다. 컴퓨팅 리소스는 약 2배 더 높아요! (슬롯 수인 \"완료된 단위\" 및 \"총 슬롯 시간\"을 참조하세요).\n\n짜증날 수 있는 부분, 조인으로 넘어가서 이제 정규화된 스키마에서 조인이 필요로 하는 컴퓨팅 리소스를 비교해봅시다.\n\n다음 섹션에서 더 자세히 살펴보겠습니다. 현재는 단순히 이해하려고 해봐요: 조인은 왼쪽 테이블의 각 행을 오른쪽 테이블의 행과 비교합니다. 이는 BigQuery가 이 계산을 돕기 위해 더 많은 컴퓨팅 리소스와 중간 저장 공간을 할당하도록 요구합니다 (셔플이 발생하는 곳이죠).\n\nBigQuery에서 오른쪽 테이블이 상당한 크기를 갖게 되면 셔플링과 복잡한 병렬 계산이 트리거되어 두 테이블을 조인합니다. 일반적으로 이 크기 제한은 약 10MB 정도로 이해되지만, Google이 정확한 숫자를 발표하지 않으며 쿼리 계획에 따라 달라질 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n약 10GB의 근사 데이터 양을 가지고 비교를 진행할 때, 우리는 이 셔플링을 명확하게 관찰하며 추가적인 계산 리소스가 필요함을 알 수 있습니다. 이 \"작은\" 양에 대해 우리는 약 10배 정도의 수요를 관찰하고 있습니다! (그러므로, 슬롯 기반 요금 모델 하에서 운영 중이라면 주의가 필요합니다).\n\n이것이 대시보드 상류에 정규화되지 않은 테이블(사전 계산된 쿼리의 결과)을 자주 볼 수 있는 이유입니다. 따라서 계산 리소스를 적게 요구하며 정규화된 스키마 디자인보다 응답 시간이 훨씬 더 좋습니다.\n\n# 테이블 크기 대 성능\n\n조인이 상당한 계산 리소스를 필요로 하는 이유에 대해 약속했었죠. 이 질문에 답하고 데이터 양이 스키마 디자인 간의 성능에 미치는 영향에 대해 탐구해볼 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이번에는 1GB에서 1TB 범위의 초기 데이터를 대상으로 정확히 동일한 SELECT COUNT(*) FROM... 쿼리를 사용했어요.\n\n단순함을 위해 중첩 스키마 디자인과 정규화된 스키마 디자인만을 비교했고, 중첩된 디노멀라이즈된 디자인은 입력 데이터 양에 따라 선형적으로 발전한다고 가정합니다.\n\n조인할 데이터 양이 클수록 더 많은 리소스가 필요하며, 단순히 선형 관계가 아니라 지수 함수 관계임을 짐작하셨을 겁니다.\n\n시각적으로 나타내기 위해 다음 그래프를 고려해보세요. 읽기 어려운 부분이 있어 마인드에 그래프 상 각 점에 대한 안내 문구를 제공했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알았어요. 테이블 안의 데이터 양이 처리된 데이터 양과 선형 관계에 있습니다 (네, 둘은 같은 것이므로 이해가 됩니다).\n\n우리는 조인되는 테이블의 크기가 필요한 자원에 엄청난 영향을 미치고, 필요한 슬롯의 수에 대해 명확히 지수적이라고 관찰했습니다. 이제, 몇십 테라바이트에 해당하는 데이터 양을 상상해보세요. 그럼 FinOps의 문제에 직면하게 될거에요!\n\n저는 특히 흥미로운 메트릭인 \"바이트당 슬롯 시간(영어: Slot Time per Byte)\"을 추가했어요. 이는 총 입력 바이트 당 필요한 시간을 측정하는 것인데요. 다시 말해, 이는 흥미로운 최적화 메트릭이며, 저에게 가장 신뢰할 만한 요소입니다. 이 메트릭을 사용하는 경향이 있고, 이 메트릭이 100GB를 넘어서는 지점에서 특히 두드러지게 변화한다는 점을 알아봤어요. 다시 말해, 저에게 의하면, 100GB 이상의 경우, 정규화된 형식은 성능과 비용에 상당한 부정적인 영향을 미칩니다.\n\n요약하자면, 온디맨드 가격 모델(테라바이트 당 요금)을 사용하는 경우, 최적화되지 않은 스키마 디자인에 대해 더 많은 비용을 지불할 필요는 없지만 응답 시간이 크게 증가할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n용량 요금 모델 (슬롯-시간 당)을 사용 중이시라면, 청구서에서 정규화된 스키마 모델의 영향을 볼 수 있을 거예요. FinOps는 당신을 좋아하지 않을 것 같아요. 하지만 중첩된 스키마 모델로 전환해서 비용을 아주 많이 낮출 수 있고, FinOps를 당신의 친구로 만들어보세요!\n\n# BigQuery 스키마 디자인 선택하기\n\n다양한 데이터 스키마 모델링 옵션의 장단점을 요약해보겠습니다.\n\n정규화된 스키마의 장점은 중복을 최소화하고 쿼리를 용이하게 만들며 데이터 업데이트(UPDATE)를 쉽게 허용하는 것입니다. 그러나 이 데이터를 쿼리하기 위해 테이블을 조인하는 것은 비용이 많이 들 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDenormalized 스키마는 데이터 쿼리 중 응답 및 연산 시간을 최소화하는 장점을 제공합니다. 이는 정규화된 모델에서 쿼리의 결과로 생각할 수 있는 표현입니다. 그러나 더 많은 저장 공간을 사용하고 데이터에 중복을 도입합니다.\n\n중첩 스키마는 저장 공간, 응답 시간 및 계산 자원을 극명하게 최소화하는 장점을 제공합니다. 그러나 더 복잡한 형식을 쿼리해야 하는 경우 복잡성이 추가됩니다. 데이터 업데이트를 더 어렵게 만들며 대량의 데이터에 대한 삽입 기록 시나리오에서 선호해야 합니다.\n\n데이터를 모델링하는 방식을 결정할 때 고려해야 할 질문을 매우 간단히 나열해 보겠습니다:\n\n- 데이터 양이 적다면, 정규화된 형식으로 유지합시다.\n- 데이터가 불변이 아니고 정기적인 업데이트가 필요한 경우, 정규화된 형식으로 시작합시다.\n- 중첩 형식은 반드시 이해하기 쉬워야 하며 실제 세계를 대변해야 합니다. 예를 들어, 영수증에는 라인이 있고, 영수증과 라인 간에는 자연스러운 계층 구조가 있습니다. 존재하지 않는 계층적 표현을 강제로 만들려는 경향이 없도록 주의하세요. 예를 들어, 영수증과 상품 재고는 함께 그룹화할 수 없는 두 가지 독립적인 것입니다.\n- 중첩 형식은 복잡합니다. 내가 이것에 익숙할 수도 있고, 당신도 그럴 수 있지만, 모든 사용자의 경우에 해당되는 것은 아닙니다. 이를 고려하세요; 최적화가 항상 재정적인 것은 아닙니다. 대부분의 사람들이 더 쉽게 쿼리할 수 있는 평면화된, 비정규화된 형식으로 최적화하세요. 사용 편의성을 위해 최적화하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 추천 사항\n\n일반적으로, 가능한 한 간단하게 유지하는 것을 추천합니다. 팀이 이미 중첩 형식을 스스로 마스터하거나 쉽게 습득할 수 있다면 작업을 단순화하고 최적화할 수 있습니다. 그러나 팀이나 사용자들에게 이 형식을 사용하도록 강요하는 것은 역산적일 수 있습니다. 비용이 많이 드는 쿼리를 사용하는 것보다 나쁜 쿼리를 사용하는 것이 더 좋습니다.\n\n저의 경우, 저는 중첩 된 테이블을 좋아합니다. 그러나 이는 최종 사용자에게는 \"숨겨져\" 있습니다. 중첩 테이블 위에 데이터를 정규화하거나 비정규화하는 뷰를 만들 수 있습니다. 이 평평화된 형식은 모두에게 이해되며, 그 아래에 중첩 테이블이 있는 것은 완벽한 최적화입니다!\n\n간단히 말해서, 숙련된 사용자에게 중첩 형식을 제공하고 데이터를 다른 더 \"전통적인\" 형식으로 펼치는 뷰를 추가로 제공해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사의 초점은 중첩 형식의 장점을 홍보하는 데 있었지만, 여전히 가장 간단한 방법이 가장 좋습니다. 테이블을 파티션하고 클러스터를 추가해보세요; 이렇게 하면 조인을 크게 최적화할 수 있고 거의 100GB에 도달하지 않습니다. 중첩 형식은 참으로 흥미로워지는데, 조인에서 100GB를 넘어설 때입니다. 전체적인 상황을 고려해 볼까요. 100GB는 $0.625입니다. 몇 센트를 절약하는 데 하루를 낭비하나요? 팀에 제공하는 가치에 집중하고, 그런 다음 최적화하세요.\n\n정규화는 중첩 형식이 적용하기 어려울 때 최후의 수단으로 간주될 수 있습니다.\n\n# 결론\n\n이 기사가 여러분에게 가치 있는 통찰력을 제공하고, 미래의 결정을 이끌어내며, 데이터 모델 설계 사이에서 선택할 때 비판적 사고를 가르쳐 주었기를 바랍니다. 각 디자인의 이점을 최대한 활용하고, 데이터 웨어하우스에서 현명하게 결합하여 사용량과 비용을 최적화하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 동안 긴 글을 읽어 주셔서 감사합니다! 만약 도움이 되었다면 이 기사를 공유하고, 박수를 보내거나 댓글을 남기거나 구독하거나 LinkedIn에서 팔로우해 주세요.","ogImage":{"url":"/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_0.png"},"coverImage":"/assets/img/2024-05-23-EfficientBigQueryDataModelingAStorageandComputeComparison_0.png","tag":["Tech"],"readingTime":11},{"title":"SQL 설명 공통 테이블 표현식","description":"","date":"2024-05-23 15:55","slug":"2024-05-23-SQLExplainedCommonTableExpressions","content":"\n\nSQL에서 CTE(Common Table Expressions, CTE로 알려진)는 다른 SQL 쿼리에서 파생된 중간 데이터를 포함하는 일시적인 이름이 지정된 결과 세트입니다. CTE에 데이터가 있는 경우 동일한 쿼리 내에서 해당 데이터를 한 번 이상 참조할 수 있습니다.\n\n위 설명을 보면 CTE가 SQL의 일반적인 일시적 테이블과 많이 닮았다고 생각할 수 있습니다. 어떤 면에서는 맞지만 왜 CTE를 사용해야 하는지 궁금할 수 있습니다. 이에 대답하기 위해 일시적 테이블의 주요 단점 두 가지를 살펴보겠습니다.\n\n일시적 테이블은 특히 대규모 SQL 스크립트의 다양한 부분을 횡단해서 사용될 경우처럼 복잡한 코드 작성에 기여할 수 있습니다. 이들은 명시적으로 생성, 삭제되어야 하며 필요시 인덱스도 구축되어야 합니다. 이로 인해 SQL 및 세션 관리에 부하가 추가됩니다.\n\n또한, 일시적 테이블은 물리적 저장 공간을 소비하며, 여유 공간이 부족하고 많은 양의 일시적 테이블이 있다면 이는 고려할 사항일 수 있습니다. 게다가 일시적 테이블을 사용하는 쿼리를 살펴볼 때, 일시적 테이블에 어떤 데이터가 포함되어 있는지, 데이터가 어디서 왔는지 명확하지 않을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCTE(공통 테이블 표현식)에는 위에서 언급한 문제가 없어요. 일단, CTE는 일시적이기 때문에 SQL 세션이 종료되면 CTE가 범위에서 벗어나고 사용한 모든 메모리가 해제됩니다.\n\n그리고 CTE에 들어 있는 데이터를 정확히 확인할 수 있어요. 그 생성과 채움은 SQL 스크립트 안에 바로 있어요.\n\nCTE의 이점뿐만 아니라, 특정 단점도 있어서 아래 경우에는 사용하지 않는 것이 좋을 수 있어요.\n\n- 쿼리에서 CTE에 포함될 데이터를 한 번 이상 참조해야 하는 경우. 이는 CTE가 참조될 때마다 다시 채워져야 하기 때문에 발생하는 문제예요. 그러나 CTE의 데이터 양이 작다면 이것이 사용 시 제약 사항이 되지 않을 수 있어요.\n- 위와 관련하여, CTE는 인덱싱할 수 없기 때문에 데이터 양이 많으면 인덱싱된 임시 테이블보다 성능이 떨어질 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러니까, 다음 시나리오에서 CTE를 사용해 보세요.\n\n- 임시 테이블을 사용하지 않으려고 할 때\n- CTE의 데이터 양이 비교적 낮을 때\n- 쿼리에서 CTE 데이터를 한 번만 참조하는 경우 (데이터 양에 따라 두 번일 수도 있음)\n\n아직 언급하지 않은 CTE의 마지막 이점은 많은 최신 SQL 방언에서 재귀 CTE를 지원한다는 것입니다. 즉, CTE가 자기 자신을 참조하는 경우입니다. 당연히 이는 재귀 및 계층 기반 SQL 쿼리를 코딩하기가 훨씬 쉬워진다는 뜻입니다. 나중에 이에 대한 몇 가지 예제를 살펴볼 것입니다.\n\n이제 CTE의 정의와 기능을 보다 자세히 이해했으니, 사용 예제를 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 테스트 환경 설정하기.\n\n저는 Oracle의 라이브 SQL 웹사이트를 사용하여 테스트를 실행합니다. 이 서비스에 액세스하고 사용하는 방법에 대해 이전에 작성한 SQL에서 Grouping Sets, Rollup 및 Cube를 사용하는 기사에서 설명했습니다. 설정하고 사용하는 데 완전히 무료입니다. 해당 기사 링크는 아래에 제공되어 있습니다.\n\n## 샘플 테이블 생성 \u0026 데이터 삽입\n\n재귀적이지 않은 CTE 예제를 위해 고객 거래 내역 테이블을 사용할 것입니다. 입력 테이블 및 데이터를 재생성하는 데 필요한 테이블 생성 및 데이터 삽입 문을 여기에 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nCREATE TABLE transactions (\n    TransactionID INT PRIMARY KEY,\n    CustomerID INT,\n    Amount DECIMAL(10, 2),\n    TransactionDate DATE\n);\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (1, 1001, 150, TO_DATE('2021-01-01', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (2, 1002, 200, TO_DATE('2021-01-04', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (3, 1001, 100, TO_DATE('2021-01-04', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (4, 1003, 250, TO_DATE('2021-01-05', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (5, 1002, 300, TO_DATE('2021-01-05', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (6, 1003, 180, TO_DATE('2021-01-08', 'YYYY-MM-DD'));\n\nINSERT INTO Transactions (TransactionID, CustomerID, Amount, TransactionDate)\nVALUES (7, 1001, 190, TO_DATE('2021-01-08', 'YYYY-MM-DD'));\r\n```\n\n```js\r\nSELECT * FROM Transactions\n\n\nTRANSACTIONID CUSTOMERID AMOUNT TRANSACTIONDATE\n============= ================= ===============\n1             1001       150    01-JAN-21\n2             1002       200    04-JAN-21\n3             1001       100    04-JAN-21\n4             1003       250    05-JAN-21\n5             1002       300    05-JAN-21\n6             1003       180    08-JAN-21\n7             1001       190    08-JAN-21\r\n```\n\n표준 CTE 구문은 놀랍도록 간단합니다. 단순히,\n\n```js\r\nWITH cte_name [(column_list)] AS (cte_query_definition) statement\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음과 같은 표가 있습니다:\n\n- cte_name은 CTE에 지정된 이름입니다\n- column_list는 CTE의 열 이름 목록입니다(선택 사항)\n- cte_query_definition은 CTE의 결과 집합을 정의하는 쿼리입니다\n- statement은 CTE를 참조하는 단일 SELECT, INSERT, UPDATE, DELETE 또는 MERGE 문입니다\n\n## 테스트 1 — 간단한 CTE\n\n```js\nWITH CustomerTotals AS (\n    SELECT CustomerID, SUM(Amount) AS TotalSpent\n    FROM Transactions\n    GROUP BY CustomerID\n)\nSELECT CustomerID, TotalSpent\nFROM CustomerTotals\nWHERE TotalSpent \u003e 250;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nCUSTOMERID | TOTALSPENT\n---------- | ----------\n1001       | 440\n1002       | 500\n1003       | 430\n```\n\n이 경우, 이 쿼리의 non-CTE 버전도 간단합니다. 다음과 같습니다.\n\n```js\nSELECT CustomerID, SUM(Amount) AS TotalSpent\nFROM Transactions\nGROUP BY CustomerID\nHAVING SUM(Amount) \u003e 250;\n```\n\n## 테스트 2 — 더 복잡한 CTE\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCTE가 자신을 발휘하는 곳은 이와 유사한 쿼리를 갖고 있을 때입니다.\n\nCTE를 사용하면 이와 같은 쿼리는 비교적 쉬워집니다. 필요한 두 집계값은 각각 두 개의 개별 CTE로 분리할 수 있고, 그 결과를 단순히 비교하여 얻을 수 있습니다.\n\n```js\nWITH CustomerAverages AS (\n    SELECT CustomerID, AVG(Amount) AS AvgAmount\n    FROM Transactions\n    GROUP BY CustomerID\n),\nOverallAverage AS (\n    SELECT AVG(Amount) AS OverallAvg\n    FROM Transactions\n)\nSELECT a.CustomerID, a.AvgAmount\nFROM CustomerAverages a, OverallAverage o\nWHERE a.AvgAmount \u003e o.OverallAvg;\n```\n\n```js\nCUSTOMERID AVGAMOUNT\n========== =========\n1002       250\n1003       215\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 이것을 비-CTE 버전과 비교해 봤을 때,\n\n```js\nSELECT CustomerID, AVG(Amount) AS AvgAmount\nFROM transactions\nGROUP BY CustomerID\nHAVING AVG(Amount) \u003e (\n    SELECT AVG(sub.AvgAmount)\n    FROM (\n        SELECT AVG(Amount) AS AvgAmount\n        FROM transactions\n        GROUP BY CustomerID\n    ) sub\n);\n```\n\n내가 생각하기에, CTE를 사용하면 SQL 작성자의 의도가 더 명확해지고 무엇이 일어나고 있는지 더 명확해집니다.\n\n## 테스트 3 — 재귀 CTEs\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n재귀 CTE(Commmon Table Expressions)는 쿼리 중 하나의 CTE가 자신을 참조하는 쿼리입니다. 예제에서 별명 정보를 사용하여 위의 CTE 예제를 재귀 CTE를 사용하여 작성할 수 있다는 것을 기믈했을지도 모릅니다.\n\n```js\nWITH CustomerAverages AS (\n    SELECT CustomerID, AVG(Amount) AS AvgAmount\n    FROM Transactions\n    GROUP BY CustomerID\n),\nOverallAverage AS (\n    SELECT AVG(AvgAmount) AS OverallAvg\n    FROM CustomerAverages\n)\nSELECT a.CustomerID, a.AvgAmount\nFROM CustomerAverages a, OverallAverage o\nWHERE a.AvgAmount \u003e o.OverallAvg;\n```\n\n두 번째 CTE인 OverallAverage에 필요한 정보는 이미 첫 번째 CTE인 CustomerAverages에 포함되어 있었기 때문에 첫 번째 CTE의 데이터를 두 번째 CTE의 계산에 사용할 수 있었습니다. \n\n```js\nwith recursive cte(col1, col2 etc…) as my_cte\n...\n...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오라클은 CTE가 쿼리 내에서 자기 자신을 참조한다면 재귀적이라고 가정하기 때문에 특별한 재귀 키워드가 필요하지 않습니다.\n\n최종 예제로, 우리는 원본 시계열 데이터의 간격을 채우기 위해 재귀적인 CTE를 사용할 것입니다.\n\n원본 테이블 데이터로 돌아가면, 1월 2일 및 3일, 그리고 1월 6일 및 7일의 고객 데이터 항목이 누락되어 있다는 것을 알 수 있습니다.\n\n우리의 작업은 매일의 고객 지출 총액을 보여주는 보고서를 생성하는 것입니다. 날짜에 대한 항목이 없는 경우, 해당 날짜의 고객 지출 값의 합계를 위해 제로를 반환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 재귀 CTE에 대한 좋은 사용 사례입니다.\n\n```js\nWITH DateRange (dt) AS (\n    SELECT MIN(TRANSACTIONDATE) \n    FROM Transactions\n    UNION ALL\n    SELECT dt + INTERVAL '1' DAY \n    FROM DateRange WHERE dt \u003c (SELECT MAX(TRANSACTIONDATE) FROM Transactions)\n),\nAggregatedData AS (\n    SELECT TRANSACTIONDATE, SUM(AMOUNT) AS TOTAL_SPEND\n    FROM Transactions\n    GROUP BY TRANSACTIONDATE\n)\nSELECT dr.dt AS TRANSACTIONDATE,\n       NVL(ad.TOTAL_AMOUNT, 0) AS TOTAL_SPEND\nFROM DateRange dr\nLEFT JOIN AggregatedData ad ON dr.dt = ad.TRANSACTIONDATE\nORDER BY dr.dt;\n\nTRANSACTIONDATE  TOTAL_SPEND\n===============  ===========\n01-JAN-21        150\n02-JAN-21        0\n03-JAN-21        0\n04-JAN-21        300\n05-JAN-21        550\n06-JAN-21        0\n07-JAN-21        0\n08-JAN-21        370\n```\n\n- DateRange CTE: 이 부분은 가장 이른 날짜부터 가장 늦은 거래일까지 연속된 날짜 범위를 생성하여 날짜 간격이 없음을 보장합니다.\n- AggregatedData CTE: 각 날짜의 거래를 합산합니다.\n- 최종 SELECT: 날짜 범위를 집계된 거래 데이터와 조인하며, NVL 함수를 사용하여 NULL 값을 0으로 대체하여 거래가 없는 날은 총액이 0으로 나타나도록 합니다.\n\n## 요약\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결론적으로, Common Table Expressions(CTEs)는 SQL에서 가독성, 유지 관리 및 복잡한 쿼리의 실행을 개선할 수 있는 다재다능하고 강력한 기능입니다. 이 글을 통해 CTE의 기본 구조와 기능을 탐색하며, 비재귀 및 재귀 유형을 살펴 다양한 시나리오에서 그 유틸리티를 보여주었습니다.\n\n포함된 세 가지 테스트 케이스는 CTE가 복잡한 SQL 작업의 관리를 단순화하고 이를 더 쉽게 다룰 수 있는 부분으로 나누어주며, 재귀 데이터를 처리하는 능력을 보여주었습니다.\n\n또한, CTE 사용은 더 깨끗하고 조직적인 SQL 스크립트로 이어지며, 개발자와 분석가가 데이터베이스 쿼리를 작성, 디버깅 및 최적화하는 작업이 쉬워집니다.\n\n아직도 CTE에 대해 확신이 없다면, 제 3번 테스트 예제에서 CTE를 사용하지 않고 어떻게 문제를 해결할지 생각해보세요. 이런 문제에 대한 전통적인 SQL 접근 방식은 더 불편하고 효율적이지 않다는 것을 알게 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 컨텐츠가 마음에 드셨다면, 이 아티클도 흥미롭게 보실 것 같아요.","ogImage":{"url":"/assets/img/2024-05-23-SQLExplainedCommonTableExpressions_0.png"},"coverImage":"/assets/img/2024-05-23-SQLExplainedCommonTableExpressions_0.png","tag":["Tech"],"readingTime":8},{"title":"퀵, 퀵, 캐-칭 덕DB를 통해 Snowflake 쿼리하여 비용 절감하기","description":"","date":"2024-05-23 15:52","slug":"2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB","content":"\n\n## 덕이 신용카드로 도망갑니다.\n\n스노우플레이크는 최근 오픈 테이블 형식 아이스버그에 대한 광범위한 지원을 출시했습니다. 오픈 형식을 사용하면 데이터의 민첩성이 향상되고 락인이 줄어듭니다. 이 게시물은 이 유연성을 활용하여 덕디비(DuckDB)를 사용하여 스노우플레이크의 높은 컴퓨트 비용을 줄이는 방법을 탐색합니다.\n\n# Apache Iceberg란 무엇인가요?\n\n아파치 아이스버그는 2017년 넷플릭스에 의해 개발된 테이블 형식 명세서입니다. 2018년 넷플릭스는 아이스버그 프로젝트를 오픈소스화하고 아파치 소프트웨어 재단에 기증했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n넷플릭스는 Iceberg를 개발하여 일반 파티션이 적용된 데이터 파일과 최소한의 메타데이터를 포함하는 데이터 레이크의 한계를 극복했습니다. 이를 하이브 형식 테이블이라고도 합니다. 이러한 제한 사항에는 성능 문제(많은 파일 목록, 많은 파티션, 제한된 가지치기) 및 데이터 웨어하우스에서 흔히 제공되는 시간 여행, 스키마 진화 및 ACID 트랜잭션과 같은 기능이 빠져 있는 것이 포함되었습니다.\n\n## 테이블 형식 명세\n\n테이블 형식 명세는 테이블을 정의하는 메타데이터를 작성하는 표준 방법입니다. 메타데이터는 데이터 집합에 어떤 내용이 있는지를 알려줌으로써 도구가 전체 데이터를 읽지 않고도 데이터 내용을 파악할 수 있게 합니다. 그러나 이러한 데이터에 다른 의미를 할당할 수도 있습니다. 예를 들어 현재로 표시하는 방식 등이 그에 해당합니다.\n\nApache Iceberg는 저장 형식이 아닙니다. Iceberg 테이블의 데이터를 Parquet, ORC, 또는 Avro와 같은 형식으로 저장할 수 있습니다. Iceberg는 이러한 데이터 파일 옆에 메타데이터를 구성하는 표준 방법입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 도구 상자 열고 상호 운용성\n\n많은 엔진과 도구들이 Iceberg 명세를 구현합니다. 동일한 명세를 구현하는 도구들은 모두 동일한 Iceberg 테이블과 상호 작용할 수 있습니다. 이것이 Apache Iceberg가 \"다중 엔진\"인 이유입니다. AWS Athena, Trino (Starburst), DuckDB, Snowflake와 같은 주요 엔진들은 Iceberg를 지원합니다.\n\n이 상호 운용 가능한 접근 방식은 이전과는 근본적으로 다른 방식입니다. Oracle, Vertica, BigQuery 등과 같은 데이터베이스는 과거에 일반적으로 저장된 메타데이터와 데이터를 독점적인 형식으로 보관하여 매끄러운 상호 운용성에 도전을 제공했으며, 많은 데이터 복사가 필요했고, 잠재적으로 공급 업체에 구속될 가능성이 있었습니다.\n\n## 패러다임 전환\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n중앙에서 액세스할 수있는 형식에 독립적으로 작업함으로써, 컴퓨팅 엔진이 상호 교체 가능해집니다. 이를 통해 특정 작업에 가장 적합한 컴퓨팅 엔진을 사용할 수 있으며 데이터를 옮길 필요가 없습니다. 한 도구로 작성된 데이터는 즉시 다른 도구에서 읽을 수 있습니다.\n\n이 아키텍처는 다른 컴퓨팅 엔진 간 중복 데이터 복제보다 데이터 공유를 선호하는 패러다임 변화를 가져옵니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_0.png)\n\n## 다양한 기능을 갖춘 레이크하우스\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nApache Iceberg은 상호 운용성을 촉진하는 것 외에도 데이터 호수와 데이터 웨어하우스 간의 기능 차이를 좁히는 데 도움이 되는 무수히 많은 기능을 지원하여 레이크하우스로 알려진 것이 됩니다. 시간 여행, ACID 트랜잭션, 파티션 진화, 숨겨진 파티셔닝, 스키마 진화, 객체 저장 비용 절감 등이 포함됩니다. 이 블로그 글에서는 상호 운용성에만 초점을 맞춥니다.\n\n# Apache Iceberg와 Snowflake\n\n2023년 12월 4일, Snowflake는 Apache Iceberg 통합이 Public preview 상태에 있다는 블로그 글을 발표했습니다.\n\nSnowflake는 이제 Iceberg 테이블을 사용하는 두 가지 방법을 제공합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 외부 카탈로그. 이러한 테이블들은 Apache Spark, Apache Flink 또는 심지어 Trino과 같은 도구에 의해 외부적으로 작성되며, 객체 저장소에 등록되어 Hive 메타스토어, AWS Glue 데이터 카탈로그 또는 Nessie와 같은 외부 카탈로그에 등록됩니다. 이 모드에서 Snowflake로부터 테이블은 읽기 전용입니다.\n- Snowflake 카탈로그. 이러한 테이블들은 Snowflake로부터 읽기-쓰기가 가능하며 외부로부터는 읽기 전용입니다.\n\n두 경우 모두, Snowflake는 모든 데이터와 Iceberg 메타데이터를 고객의 자체(클라우드) 객체 저장소에 저장합니다. Iceberg와 함께 작업하는 두 가지 방법은 각각의 장단점을 가지고 있습니다. 귀하의 상황에 맞게 가장 적합한 방법은 명확히 알아야 합니다.\n\nSnowflake 카탈로그를 사용하여 Iceberg 테이블을 사용할 때, Snowflake는 항상 그랬던 것처럼 작동합니다. 이는 \"제로 옵스(Zero-Ops)\" 데이터 웨어하우스로 남아 있으며, Snowflake가 요약 데이터, 만기된 스냅샷 및 고아 파일 청소와 같은 저장소 유지 관리 작업을 수행함으로써 여유롭게 있을 수 있습니다. Iceberg 테이블은 Snowflake 내부 테이블과 거의 동일하게 작동하지만 확인할 필요가 있는 일부 제한 사항이 있을 수 있습니다.\n\n본 문은 귀하의 데이터가 Snowflake에 저장되며 대규모 처리가 진행되는 곳이 Snowflake라고 가정합니다. Snowflake 카탈로그를 사용하는 것이 올바른 선택일 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Iceberg Catalog](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_1.png)\n\n## 아이스버그 카탈로그\n\n스노우플레이크 카탈로그와 함께 아이스버그 테이블을 사용할 때, \"카탈로그\"는 스노우플레이크 쪽에 남아 있습니다. 데이터와 직접 상호 작용하는 능력에 제약이 있는지 확인하려면, 메타데이터 카탈로그가 무엇을 하는지 알아야 합니다. 결국 테이블의 메타데이터는 아이스버그의 메타데이터 파일에 저장되지 않습니까? 카탈로그는 테이블에 적어도 두 가지를 제공합니다 (말장난이 아닙니다):\n\n- 데이터베이스 추상화. 아이스버그는 테이블 수준의 기술적 메타데이터 사양이며, 아이스버그 메타데이터 파일은 데이터 파일과 함께 저장됩니다. 테이블 사양은 테이블 이름, 스키마, 데이터베이스 또는 컬렉션이라는 개념을 인식하지 않습니다. 메타데이터 카탈로그를 사용하면 테이블의 \"테이블 묶음\"을 접두어로 테이블 이름을 매핑하여 데이터베이스처럼 고려할 수 있습니다.\n- 현재 테이블 버전을 가리키는 포인터. 아이스버그 테이블을 변경할 때, 새 데이터와 메타데이터 파일이 추가되어 이전 파일 옆에 저장됩니다. 카탈로그는 테이블 접두어를 추적하지만 \"현재\"인 메타데이터 파일도 알아야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTL;DR: 현재 테이블 버전을 알기 위해서는 카탈로그에 액세스해야 하며, 테이블 이름으로 테이블에 액세스하고 쿼리를 작성해야 합니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_2.png)\n\n## 아이스버그 카탈로그 SDK\n\nSpark를 사용하여 Iceberg 테이블을 읽고 싶다면 행운이 따릅니다! Snowflake는 Spark용 Iceberg Catalog SDK를 출시했습니다. 이 SDK는 (그 외 문서화되지 않은) Snowflake Catalog API를 사용하여 Spark의 카탈로그 인터페이스를 구현합니다. 현재 이 Snowflake 기능은 무료이며 실행 중인 데이터웨어하우스가 필요하지 않으며 \"서버리스 크레딧\" 비용이 필요하거나 \"클라우드 서비스\" 요금이 발생하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSnowflake의 공지는 쉽게 사용할 수 있는 샘플 코드를 제공하고 Spark가 고객이 관리하는 스토리지 계정에서 Iceberg 메타데이터 및 Parquet 파일을 직접 읽는 것을 확인했습니다.\n\n안타깝게도, 이는 DuckDB에서 쿼리하는 데 즉시 도움이 되지는 않습니다. DuckDB용 Snowflake 카탈로그 SDK가 없습니다. 다행히도, 우리는 파일 시스템을 직접 사용하여 데이터를 읽을 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_3.png)\n\n## Iceberg 파일 시스템 카탈로그\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파일 시스템이나 객체 저장소 위에 카탈로그를 구현하는 것이 간단한 네이밍 규칙을 통해 가능해 보인다면, 그것이 가능한 이유는 그렇다고요! 실제로, Iceberg의 Hadoop 카탈로그가 바로 그것입니다. 해당 클래스 문서에는 다음과 같이 설명되어 있습니다:\n\nIceberg는 최신 메타데이터를 알기 위해 파일 시스템 테이블의 메타데이터 파일이 단조로운 증가 버전 번호 함수로 설정된 이름을 가지도록 기대합니다. 또한, 새로운 버전을 가리키는 선택적 version-hint.text 파일을 찾습니다.\n\nSnowflake는 아마도 백엔드에서 독점적이고 높은 성능을 가진 카탈로그 구현을 사용하고 있습니다. 그러나 고객이 관리하는 객체 저장소에 데이터 및 메타데이터를 Hadoop 카탈로그와 호환되는 방식으로 구현하는 것은 충분히 좋습니다. 심지어 현재 버전을 가리키는 version-hint.text 파일을 유지하고 있죠! 이 호환성은 Iceberg Hadoop 카탈로그를 지원하는 모든 리더가 객체 저장소 시스템의 Iceberg 웨어하우스 루트를 가리키도록 설정하여 Snowflake 데이터를 직접 읽을 수 있다는 의미입니다.\n\n## DuckDB\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDuckDB은 Iceberg Hadoop 카탈로그 및 파일 시스템 테이블에 대한 부분적인 지원을 제공합니다. 유감스럽게도 DuckDB는 아직 전체 데이터 웨어하우스를 읽는 기능을 지원하지는 않지만, 테이블 접두사를 가리키도록 설정할 수 있습니다. DuckDB는 버전 힌트 텍스트 파일을 파악하고 테이블의 최신 버전을 읽을 것입니다.\n\n# Iceberg 테이블 생성하기\n\nSnowflake를 사용하여 클라우드에 Iceberg 테이블을 생성하려면 일부 구성이 필요합니다. 아래 예제는 S3를 저장 레이어로 사용하지만, Snowflake는 Google Cloud Storage 및 Azure Storage도 지원합니다. S3에 대한 플레이북을 여기에서 찾을 수 있습니다:\n\n일반적으로 이렇게 진행해야 합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 스토리지 프로비저닝: S3 버킷을 생성하고 Snowflake용 IAM 역할을 만들어 IAM 역할이 버킷에 액세스할 수 있는 필요한 권한이 부여되도록 합니다.\n- 스노우플레이크와 스토리지 연결: Snowflake 외부 볼륨을 생성합니다. S3의 경우, 외부 볼륨은 Snowflake 계정에 IAM 사용자를 생성합니다. IAM 사용자가 S3 버킷에 액세스할 수 있는 권한이 있는 역할을 가정할 수 있도록 신뢰 관계를 만들어야 합니다.\n\n이제 스노우플레이크에서 CREATE ICEBERG TABLE로 네이티브 아이스버그 테이블을 생성할 수 있으며, Parquet과 Iceberg 메타데이터 파일은 S3 버킷에 저장됩니다.\n\n# DuckDB에서 데이터 읽기\n\nS3와 Snowflake 간에 안전한 연결을 설정하고 Snowflake에 아이스버그 테이블을 생성한 후, DuckDB가 이를 쿼리하는 방법을 살펴봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDuckDB의 얼음산 확장 기능을 사용하여 Snowflake에서 직접 S3로 만든 얼음산 테이블을 읽습니다. 여기서 플레이북을 찾을 수 있어요. 주요 기능은 다음 얼음산 스캔 메서드로 제공됩니다:\n\n```js\nselect * from iceberg_scan('s3://chapter-platform-iceberg/icebergs/line_item';)\n```\n\n얼음산 스캔 메서드는 S3에서 테이블을 가져옵니다. 현재 manifest.json 파일을 명시적으로 가리키지 않아도 됩니다. 왜냐하면 version-hint.text가 테이블의 현재 버전을 가리키고 있기 때문입니다.\n\n이제 오픈 테이블 형식의 진정한 힘을 발휘했습니다. Snowflake 및 해당 카탈로그의 편리함을 활용하면서 DuckDB에서 단일 노드 쿼리를 수행하여 비용을 절약할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 눈송이가 이렇게 하는 이유는 뭘까요?\n\n눈송이에서 아이스버그 테이블을 사용하는 것은 눈송이가 결제를 지원해주면서 케이크를 먹는 것과 비슷합니다. 그렇다면 왜 눈송이가 이 통합을 만들었을까요? 이 동작은 Databricks로부터의 치열한 경쟁 상황에서 이해할 수 있습니다. 이 두 기업 거물은 모두 시스템을 개방하여 고객을 유치하려고 하고 있습니다.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_4.png)\n\n눈송이는 (잠재적인) 고객들에게 눈송이를 선택하더라도 하나의 공급 업체에 얽매이지 않아도 되며 잠금 상태의 위험이 없다는 메시지를 전송합니다. 눈송이를 선택하면 원하는 때에 컴퓨트 엔진을 전환할 수 있는 옵션이 항상 제공된다고 합니다. Databricks도 마찬가지로 Delta Lake 형식을 공개하고 UniForm을 통해 Hudi와 아이스버그를 더 잘 지원하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스노우플레이크는 여전히 가능한 한 많은 컴퓨팅을 자체 시스템에서 유지하고 싶어합니다. 외부 메타데이터를 Iceberg 카탈로그로 이동하는 명확한 방법이 있지만, 그 반대 방향으로 이동하는 것은 훨씬 어렵습니다. 메타데이터 카탈로그를 소유함으로써, 스노우플레이크는 선호되는 컴퓨팅 엔진이자唯一의 작성자로 남게 됩니다. 시스템을 공개하지 않았다면 스노우플레이크는 락인을 두려워하는 많은 고객을 잃었을 것으로 예상됩니다.\n\n# 결론\n\nIceberg와 같은 오픈 테이블 형식은 컴퓨팅과 스토리지를 진정으로 분리할 수 있게 해줍니다. 스노우플레이크의 Iceberg 테이블을 사용함으로써, 스노우플레이크의 강력하고 운영이 필요 없는 기능을 계속 즐길 수 있으면서 가끔은 \"벽에 가둔 정원\"을 벗어날 수 있게 됩니다. Iceberg가 Parquet과 함께 갖는 특성과 기능이 스노우플레이크의 네이티브 테이블과 매우 유사하며 효율적인 압축, 파티션 프루닝, 스키마 진화 등과 같은 기능을 제공한다는 점에서, 그리고 스노우플레이크가 이를 위한 지원을 구현했기 때문에, 성능이나 기능에 중대한 영향을 미치지 않는 한 Iceberg 테이블을 네이티브 테이블 대신 사용할 수 있어야 합니다. 따라서 우리는 스노우플레이크에서 기본적으로 Iceberg 테이블을 사용하는 것을 제안합니다.\n\n이 게시물은 비용이 많이 드는 스노우플레이크 컴퓨팅 대신 DuckDB에서 쿼리를 실행하는 방법이 얼마나 쉬운지를 보여 주었습니다. 여러분의 객체 저장소에서 Snowflake가 관리하는 데이터를 직접 가리키는 것으로 독립적으로 실행할 수 있습니다. 거기서는 Snowflake 웨어하우스에 없는 데이터와 조합할 수도 있습니다. 비슷한 성능을 가진 DuckDB 인스턴스에서 실행 시 비용이 대략 스노우플레이크 웨어하우스의 10% 정도인 것을 고려하면, 이러한 방식은 상당한 비용 절감을 가져올 수 있습니다. 물론 DuckDB가 스노우플레이크를 대체한다는 것은 의미하지 않습니다. 이것은 상호 운용성의 힘을 잘 보여 주는 좋은 데모라고 생각합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 게시물은 Jelle De Vleminck, Robbert, Moenes Bensoussia, 그리고 Jonathan Merlevede의 공동 노력의 결과입니다.\n\n- 👏 만약 이 게시물을 좋아하셨다면 갈채 해 주세요\n- 🗣️ 의견을 공유해 주세요; 우리는 답변하겠습니다\n- 🗞️ 클라우드, 플랫폼, 데이터, 그리고 소프트웨어 엔지니어링에 대한 게시물을 더 보시려면 datamindedbe를 팔로우하고 구독해 주세요\n- 👀 Data Minded에 대해 더 알고 싶다면, 저희 웹사이트를 방문해 주세요.\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_5.png)\n\n![이미지](/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_6.png)","ogImage":{"url":"/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_0.png"},"coverImage":"/assets/img/2024-05-23-QuackQuackKa-ChingCutCostsbyQueryingSnowflakefromDuckDB_0.png","tag":["Tech"],"readingTime":9},{"title":"핀오프에서 파생 열backfilling derived column 채우기","description":"","date":"2024-05-23 15:51","slug":"2024-05-23-BackfillingDerivedColumninPinot","content":"\n\n데이터 엔지니어링 세계에서 백필링은 일반적인 시나리오입니다. 최근에 Pinot의 실시간 테이블에서 작업하던 중에 다른 JSON 기반 열에 존재하는 값을 추출하고있는데, 해당 속성이 깊은 중첩 안에 숨겨져 있어서 꽤 어려운 상황에 빠졌었죠.\n\n\u003cimg src=\"/assets/img/2024-05-23-BackfillingDerivedColumninPinot_0.png\" /\u003e\n\n이제 매번 이 테이블을 쿼리하고 원하는 속성을 필요로 할 때마다 해당 속성의 값을 추출하는 옵션은 항상 존재했습니다. 그러나 우리가 쿼리를 발전시키고자 했던 방식은 이 새로운 속성을 `where` 절에서도 사용하는 것이었습니다. 따라서, 이 속성에 대한 새로운 열을 만들어 이 열에 인덱스를 넣는 것이 좋은 지연 경험을 얻을 수 있는 가장 좋은 옵션이었습니다.\n\n이 새로운 열을 도입하는 것은 원활할 수 있지만, 각 들어오는 항목마다 이 새로운 열을 채우기 시작할 수 있으며, 또한 이미 테이블에 존재하는 레코드에 대해서도 이 열을 백필하는 작업이 필요했습니다. 이는 실시간 테이블이었기 때문에 다소 어려웠고, 누군가가 이를 이전에 수행한 문서나 블로그가 없었습니다. 그래서 저는 이 여정에 착수하여 Pinot에서 파생 열을 위한 백필을 달성하는 데 관련된 모든 세부 사항을 파악했습니다. 실시간 테이블에 대해 이 문제를 해결했지만, 과정은 배치 테이블에 대해서도 유사할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 문제 설명\n\n다음과 같은 `orders` 테이블이 있다고 가정해 봅시다:\n\n![테이블](/assets/img/2024-05-23-BackfillingDerivedColumninPinot_1.png)\n\n이제 우리는 `productDetails` 열에서 `brand` 속성을 유도하고, 이를 고유한 열로 만들고 싶습니다. 기존 레코드는 모두 원하는 값을 `productDetails` 열에서 추출하여 backfilling해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n브랜드 값이 없는 제품도 있을 수 있으니 해당 경우 파생 값을 null로 처리해야 합니다.\n\n최종 테이블은 다음과 같이 보일 것입니다:\n\n![테이블](/assets/img/2024-05-23-BackfillingDerivedColumninPinot_2.png)\n\n# 스키마에 새 열 추가하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째로 할 일이네요! `orders` 테이블 스키마에 이 새로운 열을 추가하세요.\n예를 들어, 기존 스키마가 다음과 같다면:\n\n```js\n{\n   \"schemaName\": \"orders\",\n   \"enableColumnBasedNullHandling\": false,\n   \"dimensionFieldSpecs\": [\n     {\n       \"name\": \"orderId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"amount\",\n       \"dataType\": \"LONG\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productDetails\",\n       \"dataType\": \"JSON\",\n       \"notNull\": false\n     }\n   ],\n   \"dateTimeFieldSpecs\": [\n     {\n       \"name\": \"createdAt\",\n       \"dataType\": \"TIMESTAMP\",\n       \"notNull\": false,\n       \"format\": \"1:MILLISECONDS:EPOCH\",\n       \"granularity\": \"1:MILLISECONDS\"\n     }\n   ]\n}\n```\n\n\"브랜드\"라는 새로운 열은 \"UI에서 스키마 편집\" 옵션을 사용하거나 해당 REST API를 사용하여 스키마에 추가할 수 있습니다. 이 열의 `notNull` 값을 false로 설정해야 합니다. 새로운 스키마는 다음과 같이 보일 것입니다:\n\n```js\n{\n   \"schemaName\": \"orders\",\n   \"enableColumnBasedNullHandling\": false,\n   \"dimensionFieldSpecs\": [\n     {\n       \"name\": \"orderId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productId\",\n       \"dataType\": \"INT\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"amount\",\n       \"dataType\": \"LONG\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"brand\",\n       \"dataType\": \"STRING\",\n       \"notNull\": false\n     },\n     {\n       \"name\": \"productDetails\",\n       \"dataType\": \"JSON\",\n       \"notNull\": false\n     }\n   ],\n   \"dateTimeFieldSpecs\": [\n     {\n       \"name\": \"createdAt\",\n       \"dataType\": \"TIMESTAMP\",\n       \"notNull\": false,\n       \"format\": \"1:MILLISECONDS:EPOCH\",\n       \"granularity\": \"1:MILLISECONDS\"\n     }\n   ]\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 변환 구성 설정하기\n\n이것은 프로세스에서 가장 중요한 단계 중 하나입니다. 새 열에 필요한 변환 구성을 찾아야 합니다. 이 경우 다음 변환 구성을 사용할 수 있습니다:\n\n```js\n{\n   \"columnName\": \"brand\",\n   \"transformFunction\": \"jsonPathString(json_format(productDetails), '$.details.brand', 'null')\"\n}\n```\n\n이 변환을 통해 우리는 `productDetails` 열에서 `brand` 속성을 추출할 것입니다. 이 속성이 없는 경우 `brand` 열에 문자열 `null`을 넣을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상기 언급된 변환 구성은 테이블 구성의 \"ingestionConfig\" - \"transformationConfigs\" 섹션에 추가할 수 있습니다.\n\n# 파생 열 역추적\n\n이것은 역추적이 발생하는 실제 단계입니다. 역추적이 이루어지려면 모든 세그먼트를 다시로드해야 합니다. 이 작업은 테이블 페이지의 \"모든 세그먼트 다시로드\" 버튼을 클릭하거나 REST API(POST) `/segments/'tableName'/reload`을 호출하여 수행할 수 있습니다.\n\n일반적으로 이 작업은 1분 미만이 소요되지만, 매우 큰 테이블의 경우 조금 더 오랜 시간이 걸릴 수 있습니다. 이 작업의 상태를 확인하려면 테이블 페이지에서 \"다시로드 상태\" 버튼을 클릭할 수 있습니다. 다시로드 상태를 확인하는 해당 API는 `/segments/segmentReloadStatus/'jobId'`입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작업이 완료되면 모든 레코드에 값이 포함된 파생 컬럼을 볼 수 있어야 합니다.\n\n# 주의 사항\n\n다음은 프로세스의 오류 포인트 중 일부입니다(제가 고생하며 배웠습니다). 리로드 세그먼트 작업은 새로 추가된 컬럼에만 영향을 미칩니다. 한 번 리로드 세그먼트 작업을 실행하고 변환 구성에 버그가 있는 것을 발견하면 해당 테이블에 무용지물 컬럼이 남게 됩니다. 이제 이 컬럼의 변환 구성을 수정하고 다시 리로드 세그먼트를 트리거하면 해당 컬럼에 값이 없는 것을 확인할 수 있습니다. 리로드 세그먼트 작업은 모든 세그먼트에 대해 성공했다는 상태를 표시할지라도 실제로는 아무 작업도 수행하지 않을 것입니다. Pinot이 역호환성 문제에 대해 불평하고 해당 컬럼을 삭제할 수 없도록 막을 것입니다.\n\n이를 해결하기 위해 테이블의 사본을 만들고 해당 테이블 사본에 백필을 수행하여 변환 구성이 올바른지 확인하는 것을 강력히 권장합니다. 변환 구성에 만족하면 해당 테이블에 필요한 단계를 수행하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n전반적으로 Pinot은 이 블로그에서 설명된 것처럼 파생 열을 백필링하는 등 여러 기능을 지원하는 강력한 OLAP 데이터 스토어입니다. 그러나 위대한 능력에는 큰 책임이 따릅니다! 새롭게 추가된 열에 대해 백필링을 수행할 때 매우 주의해야 합니다. 새로 추가된 열에 대해 리로드를 한 번만 실행할 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-23-BackfillingDerivedColumninPinot_0.png"},"coverImage":"/assets/img/2024-05-23-BackfillingDerivedColumninPinot_0.png","tag":["Tech"],"readingTime":5},{"title":"2024년 데이터 과학 - 무엇이 변했나요","description":"","date":"2024-05-23 15:49","slug":"2024-05-23-DataSciencein2024WhatHasChanged","content":"\n데이터 과학 분야에서 무엇이 변화했는지 그리고 2024년 데이터 과학 취업 시장의 어려움은 무엇인지 알고 싶습니다.\n\n![이미지](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_0.png)\n\n2024년 데이터 과학의 모습은 어떻게 되어 있을까요? 이 질문에 답하고 귀하의 미래를 예언하려면 역사 몇 년 전으로 돌아가야 합니다. 우리는 2020년의 붐 시대에서 2024년을 연식하게 하는 좀 더 특화된 그리고 세밀한 분야들로 어떻게 변하게 되었는지 알아볼 것입니다.\n\n## 2020년으로부터의 되감기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2020 년에는 세계가 COVID-19 전염병에 휩싸여 있었고 산업은 전례 없는 도전에 직면했습니다. 그러나 이 상황은 기술 산업을 촉진시켰으며, 많은 것들이 개인 대신 온라인으로 전환되었습니다. 특히, 데이터 과학은 수요가 50% 증가하여 다양한 산업과 시장 전반에 걸쳐 성장했습니다. 의료, 기술, 미디어 및 금융 서비스 산업은 특히 데이터 과학 인재에 대한 갈망이 크며 대규모 고용 증가를 실시했습니다.\n\n![이미지](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_1.png)\n\n## 2022년 및 2023년 해고\n\n그러나 데이터 과학자들에 대한 높은 수요는 그리 오랫동안 지속되지 않았습니다. 2022년과 2023년에 전염병이 가라앉음에 따라 데이터 과학 시장에서는 급격한 변화가 있었습니다: 대규모 고용 증가는 고용 중단 증가로 변모하였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_2.png\" /\u003e\n\n큰 기술 기업들이 채용 공고를 90% 줄였어요. 입문 레벨의 데이터 과학자와 경험 많은 과학자 모두에게 어려운 시장이었어요. 이 2년 동안 기술 산업 전반에서 50만 명 이상의 해고가 있었는데, 그 중 30% 이상이 공학 및 데이터 과학 직군에서 발생했어요.\n\n# 전문화와 인공지능 시대\n\n이 두 해 동안 해고 뿐만 아니라 전문화의 상승에도 상당한 변화가 있었어요. 일반적인 데이터 과학자 역할이 기계 학습 엔지니어 및 데이터 엔지니어와 같은 전문화된 포지션으로 변화하기 시작했어요. 데이터 과학자들이 end-to-end 작업을 수행할 수 있는 능력에 대한 강조가 줄었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n물론, AI의 영향을 잊으면 안 됩니다. 특히 ChatGPT와 같은 OpenAI 도구들은 AI를 더 접근 가능하게 만들어주고 데이터 과학 작업을 더 효율적이고 자동화될 수 있게 해주었습니다.\n\n# 2024년 데이터 과학 분야\n\n전반적인 취업 기회는 감소했지만, 시장은 드디어 안정화되고 있습니다.\n\n![image not found](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특정 역할에 경험이 있는 전문가에 대한 수요가 많습니다.\n\n![Image1](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_4.png)\n\n코딩 능력은 여전히 중요합니다. 특히 머신러닝 엔지니어링 직군에서는 이러한 데이터 과학 기술에 코드를 사용해야 합니다.\n\n![Image2](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로그래밍 언어 중 데이터 과학자가 사용할 수 있는 옵션이 더 통합되고 있어요. 이 중에서 파이썬이 많이 사용되고 있어요.\n\n![이미지](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_6.png)\n\nSQL은 영원히 존재할 것입니다. 한편으로는 R, SAS 및 SAP와 같은 언어들은 인기가 떨어지고 있어요.\n\n그러니까, 처음부터 데이터 과학자가 되려는 경우 어떤 언어를 배워야 할지 결정하려면, 파이썬과 SQL은 항상 존재하고 주요 언어일 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일러스트레이션과 비슷한 분야인 데이터 분석가와 비즈니스 분석가 같은 몇 가지 직업은 인공지능 붐과 함께 인기를 끈 로우코드 및 노코드 도구의 부상으로 혜택을 받고 있습니다. 특히 ChatGPT가 자동화하기 위해 사용할 수 있는 플러그인으로 데이터 과학 작업을 많이 자동화할 수 있습니다.\n\n데이터 과학 시장은 이전보다 더 나눠진 상태입니다. 비즈니스 분석가, 인공지능/머신러닝 엔지니어, 데이터 엔지니어와 같은 직업들 간에 명확한 차이가 보입니다. 그러면 이제 셋으로 나눠져 있나요?\n\n# 2024년 데이터 과학자를 위한 도전 과제\n\n데이터 과학자들에게는 ROI(투자대비이익)에서 그들의 가치를 입증하는 것이 도전 과제입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Data Science Trends](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_7.png)\n\nInitial hype is settling, and companies are now seeking tangible results. Data scientists must demonstrate their value by specializing in specific skills, such as ML engineering.\n\n![Data Science Trends](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_8.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 엔지니어링,\n\n\n![image1](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_9.png)\n\n\n또는 데이터 분석.\n\n\n![image2](/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_10.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새롭게 개발되고 있는 Google의 Gemini, Galactica 및 ChatGPT와 같은 강력한 새로운 도구에 적응해야 할 것입니다.\n\n# 결론\n\n시대가 변하면서 데이터 과학은 계속 변화해왔습니다. 지난 몇 년 동안 변화했으며 2024년에도 변화할 것입니다. 데이터 과학가들은 적응하고 발전하며 새로운 도전과 기회에 대처해야 합니다.\n\n주요 도전은 특화와 최신 AI 도구 개발에 대한 속도를 유지하는 것입니다. 그리고 예전과 마찬가지로 잠재적인 고용주에게 가치를 증명해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://www.stratascratch.com에서 원래 발행되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_0.png"},"coverImage":"/assets/img/2024-05-23-DataSciencein2024WhatHasChanged_0.png","tag":["Tech"],"readingTime":4}],"page":"8","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"8"},"buildId":"R1x9p1CQYDDJESXyLXKOK","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>