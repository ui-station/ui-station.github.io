<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/83" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/83" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_buildManifest.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="파이썬 FastAPI를 사용한 Kubernetes로의 Microservices 배포 방법" href="/post/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이썬 FastAPI를 사용한 Kubernetes로의 Microservices 배포 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이썬 FastAPI를 사용한 Kubernetes로의 Microservices 배포 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">파이썬 FastAPI를 사용한 Kubernetes로의 Microservices 배포 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="K8s - kube-proxy 소개" href="/post/2024-05-20-K8skube-proxyIntroduction"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="K8s - kube-proxy 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-K8skube-proxyIntroduction_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="K8s - kube-proxy 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">K8s - kube-proxy 소개</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="디브옵스를 배우고 싶지만 어떻게 시작해야 할지 모르겠다구요 여기 가이드가 도와줄게요" href="/post/2024-05-20-WanttoLearnDevOpsbutDontKnowWheretoStartHeresYourGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="디브옵스를 배우고 싶지만 어떻게 시작해야 할지 모르겠다구요 여기 가이드가 도와줄게요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-WanttoLearnDevOpsbutDontKnowWheretoStartHeresYourGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="디브옵스를 배우고 싶지만 어떻게 시작해야 할지 모르겠다구요 여기 가이드가 도와줄게요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">디브옵스를 배우고 싶지만 어떻게 시작해야 할지 모르겠다구요 여기 가이드가 도와줄게요</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커 도컴포즈를 사용하여 PostgreSQL을 설치하는 방법" href="/post/2024-05-20-DockerHowtoInstallPostgreSQLusingDockerCompose"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커 도컴포즈를 사용하여 PostgreSQL을 설치하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-DockerHowtoInstallPostgreSQLusingDockerCompose_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커 도컴포즈를 사용하여 PostgreSQL을 설치하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">도커 도컴포즈를 사용하여 PostgreSQL을 설치하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커 컨테이너에서 상호 TLS를 구현하는 방법" href="/post/2024-05-20-HowtoImplementMutualTLSwithDockerContainers"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커 컨테이너에서 상호 TLS를 구현하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-HowtoImplementMutualTLSwithDockerContainers_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커 컨테이너에서 상호 TLS를 구현하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">도커 컨테이너에서 상호 TLS를 구현하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커 다이어트 보안 및 속도를 위한 데비안 이미지" href="/post/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커 다이어트 보안 및 속도를 위한 데비안 이미지" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커 다이어트 보안 및 속도를 위한 데비안 이미지" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">도커 다이어트 보안 및 속도를 위한 데비안 이미지</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="스파크와 데이터브릭스에서 파티셔닝으로 성능 향상을 달성하세요 파트 13" href="/post/2024-05-20-SuperchargingPerformancewithPartitioninginDatabricksandSparkPart13"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="스파크와 데이터브릭스에서 파티셔닝으로 성능 향상을 달성하세요 파트 13" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-SuperchargingPerformancewithPartitioninginDatabricksandSparkPart13_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="스파크와 데이터브릭스에서 파티셔닝으로 성능 향상을 달성하세요 파트 13" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">스파크와 데이터브릭스에서 파티셔닝으로 성능 향상을 달성하세요 파트 13</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기" href="/post/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트" href="/post/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터브릭스 리퀴드 클러스터링" href="/post/2024-05-20-DatabricksLiquidClustering"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터브릭스 리퀴드 클러스터링" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-DatabricksLiquidClustering_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터브릭스 리퀴드 클러스터링" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터브릭스 리퀴드 클러스터링</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/81">81</a><a class="link" href="/posts/82">82</a><a class="link posts_-active__YVJEi" href="/posts/83">83</a><a class="link" href="/posts/84">84</a><a class="link" href="/posts/85">85</a><a class="link" href="/posts/86">86</a><a class="link" href="/posts/87">87</a><a class="link" href="/posts/88">88</a><a class="link" href="/posts/89">89</a><a class="link" href="/posts/90">90</a><a class="link" href="/posts/91">91</a><a class="link" href="/posts/92">92</a><a class="link" href="/posts/93">93</a><a class="link" href="/posts/94">94</a><a class="link" href="/posts/95">95</a><a class="link" href="/posts/96">96</a><a class="link" href="/posts/97">97</a><a class="link" href="/posts/98">98</a><a class="link" href="/posts/99">99</a><a class="link" href="/posts/100">100</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"파이썬 FastAPI를 사용한 Kubernetes로의 Microservices 배포 방법","description":"","date":"2024-05-20 17:11","slug":"2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes","content":"\n![FastAPI 및 Kubernetes를 사용한 미니큐브에 두 마이크로서비스 배포하기](/assets/img/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes_0.png)\n\n이 기사에서는 FastAPI로 2개의 마이크로서비스를 만들고 이를 미니큐브에 배포할 것입니다. 우리는 쿠버네티스 인그레스를 사용하여 요청을 각각의 마이크로서비스로 라우팅할 것입니다.\n\n먼저, 이 기사에서 사용할 쿠버네티스 기능을 살펴보겠습니다.\n\n- **Kubernetes Deployment**: 쿠버네티스 배포는 애플리케이션 업데이트와 스케일링의 자동화를 담당합니다. 이는 애플리케이션의 원하는 상태를 정의하며, 레플리카 수, 사용할 컨테이너 이미지 및 업데이트 전략을 포함합니다. 배포 컨트롤러는 필요에 따라 파드를 작성하고 업데이트하여 애플리케이션의 실제 상태가 원하는 상태와 일치하도록 합니다. 배포는 롤링 업데이트, 롤백 기능 및 셀프 힐링을 지원하여 변경 사항 중에 애플리케이션 가용성과 안정성을 유지하기 쉽게 합니다. 이 추상화는 쿠버네티스 클러스터에서 스테이트리스 애플리케이션을 배포, 확장 및 관리를 간소화합니다. 자세한 정보는 [링크](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)를 참조하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n**Kubernetes Service:** 쿠버네티스 서비스는 논리적인 포드 집합과 이에 접근하기 위한 정책을 정의하는 추상화입니다. 일반적으로 안정적인 IP 주소와 DNS 이름을 통해 접근합니다. 서비스를 통해 응용 프로그램의 다른 부분 간에 통신할 수 있으며 포드의 IP 주소를 알 필요가 없어집니다. 왜냐하면 그 주소는 변경될 수 있기 때문입니다.\n\n[자세히 알아보기](https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/)\n\n**Kubernetes Ingress:** 쿠버네티스 인그레스는 쿠버네티스 클러스터 내의 서비스에 대한 외부 액세스를 관리합니다. 저희 어플리케이션에서는 해당 서비스(예: 마이크로서비스 1 또는 마이크로서비스 2)로 트래픽을 라우팅하는 데 사용할 것입니다. 호스트 이름 및 경로에 따라 트래픽을 특정 서비스로 라우팅하는 규칙을 정의합니다. NGINX 또는 Traefik과 같은 인그레스 컨트롤러는 이러한 규칙을 실행하여 중앙 집중형 관리, 로드 밸런싱, SSL 종료 및 경로 기반 라우팅을 제공합니다. 인그레스 리소스를 효과적으로 사용하려면 인그레스 컨트롤러를 배포해야 합니다.\n\n[자세히 알아보기](https://kubernetes.io/docs/concepts/services-networking/ingress/#what-is-ingress)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마이크로서비스 1\n\n마이크로서비스 1은 매우 간단하게 될 것입니다. \"You requested microservice 1\"을 반환하는 하나의 엔드포인트만을 가질 것입니다.\n\nmicroservice_1이라는 폴더를 만들고 main.py라는 파일을 추가하세요.\n\n```python\n# main.py (마이크로서비스 1)\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"You requested microservice 1\"}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요구사항.txt 파일을 추가하세요\n\n```js\nfastapi==0.111.0\n```\n\n```js\nFROM python:3.10-slim\n\nWORKDIR /app\n\nCOPY requirements.txt requirements.txt\n\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도커 이미지를 빌드하고 도커허브에 푸시하세요.\n\n이미지를 username/image_name:version 형식으로 태그해야 합니다. 그렇지 않을 경우 쿠버네티스가 이미지를 인식하지 못할 수 있습니다. 이 명령어는 마이크로서비스 1의 Dockerfile이 있는 디렉토리에서 실행되어야 합니다.\n\n```js\n$ docker build . -t sumangaire96/microservice1:v1\n$ docker push sumangaire96/microservice1:v1\n```\n\n이와 같은 메시지가 나타날 것입니다. 만약 나타나지 않는다면, 도커에 로그인되어 있는지 확인하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes_1.png)\n\n# 마이크로서비스 2\n\n마이크로서비스 2도 엔드포인트가 하나만 있어서 \"You requested microservice 2\"를 반환할 것입니다.\n\nmicroservice_1이라는 폴더를 만들고 main.py라는 파일을 추가하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# main.py (microservice 2)\n\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"You requested microservice 2\"}\n\n\nAdd requirements.txt\n\n\nfastapi==0.111.0\n\n\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nFROM python:3.10-slim\n\nWORKDIR /app\n\nCOPY requirements.txt requirements.txt\n\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n```\n\n도커 이미지를 빌드하고 도커허브에 푸시하세요.\n\n```bash\n$ docker build . -t sumangaire96/microservice2:v1\n$ docker push sumangaire96/microservice2:v1\n```\n\n# Minikube\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n미니큐브가 설치되어 있는지 확인하세요. 설치되어 있지 않다면 다음 링크를 따르세요: https://minikube.sigs.k8s.io/docs/start/. 터미널에서 미니큐브 클러스터와 상호 작용하기 위해 kubectl이 설치되어 있는지 확인하세요. 설치되어 있지 않다면 다음 링크를 따르세요: https://kubernetes.io/docs/tasks/tools/.\n\n쿠버네티스 클러스터를 생성하세요.\n\n```js\n$ minikube start\n```\n\n미니큐브에서 인그레스를 활성화하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```bash\n$ minikube addons enable ingress\n```\n\n**1. Create kubernetes manifest file for microservice 1.**\n\n```yaml\n# kubernetes/microservice_1.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: microservice1-deployment\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: microservice1\n  template:\n    metadata:\n      labels:\n        app: microservice1\n    spec:\n      containers:\n        - name: microservice1\n          image: sumangaire96/microservice1:v1\n          ports:\n            - containerPort: 80\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: microservice1-service\nspec:\n  selector:\n    app: microservice1\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n  type: ClusterIP\n```\n\n**2. Create kubernetes manifest file for microservice 2.**\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\n# kubernetes/microservice_2.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: microservice2-deployment\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: microservice2\n  template:\n    metadata:\n      labels:\n        app: microservice2\n    spec:\n      containers:\n        - name: microservice2\n          image: sumangaire96/microservice2:v1\n          ports:\n            - containerPort: 80\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: microservice2-service\nspec:\n  selector:\n    app: microservice2\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n  type: ClusterIP\n```\n\n쿠버네티스 인그레스 매니페스트 파일을 생성합니다.\n\n```yaml\n# kubernetes/ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n    - host: microservice1.local\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: microservice1-service\n                port:\n                  number: 80\n    - host: microservice2.local\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: microservice2-service\n                port:\n                  number: 80\n```\n\n매니페스트를 적용하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n$ kubectl apply -f microservice_1.yaml\n$ kubectl apply -f microservice_2.yaml\n$ kubectl apply -f ingress.yaml\n\n호스트 이름을 Minikube IP에 매핑하기 위해 호스트 파일을 업데이트하세요.\n\n$ echo \"$(minikube ip) microservice1.local\" | sudo tee -a /etc/hosts\n$ echo \"$(minikube ip) microservice2.local\" | sudo tee -a /etc/hosts\n\n이제 microservice1.local 및 microservice2.local로 이동하면 다음과 같은 출력이 나타납니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식으로 표로 변환한 내용입니다.\n\n| 이미지                                                                                                                                                            |\n| ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| ![FastAPI와 Kubernetes를 사용한 2024-05-20 날짜의 마이크로서비스 배포 이미지](/assets/img/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes_2.png)         |\n| ![FastAPI와 Kubernetes를 사용한 2024-05-20 날짜의 또 다른 마이크로서비스 배포 이미지](/assets/img/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes_3.png) |\n\n축하합니다! FastAPI로 2개의 마이크로서비스를 만들고 Kubernetes를 사용하여 성공적으로 배포했습니다. 앞으로 나올 문서를 기대해 주세요.\n","ogImage":{"url":"/assets/img/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes_0.png"},"coverImage":"/assets/img/2024-05-20-FastAPIMicroservicesDeploymentUsingKubernetes_0.png","tag":["Tech"],"readingTime":10},{"title":"K8s - kube-proxy 소개","description":"","date":"2024-05-20 17:09","slug":"2024-05-20-K8skube-proxyIntroduction","content":"\n![kube-proxy](/assets/img/2024-05-20-K8skube-proxyIntroduction_0.png)\n\nkube-proxy는 kubelet과 마찬가지로 Kubernetes 시스템 내 각 노드에서 실행되는 데몬입니다. 이것은 클러스터 내에서 기본로드 밸런싱을 담당합니다. kube-proxy의 작동은 서비스 및 엔드포인트/엔드포인트 슬라이스에 기반합니다:\n\n- 서비스: 이들은 팟 그룹을위한 로드 밸런서로 작동합니다.\n- 엔드포인트(및 엔드포인트 슬라이스): 이것들은 서비스에서 동일한 팟 선택기를 사용하여 자동으로 생성된 준비된 팟 IP 시리즈를 열거합니다.\n\nKubernetes의 대부분의 서비스 유형은 클러스터 내부 IP 주소 인 클러스터 IP 주소를 보유하며, 클러스터 외부에서 액세스할 수 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nkube-proxy는 여러분이 클러스터 IP 주소로 요청을 안내하고 그 요청이 건강한 파드에 도달하도록 하는 역할을 합니다. kube-proxy에는 네 가지 모드가 있으며, 이 모드에 따라 실행 모드와 구체적인 기능 세트가 변경됩니다:\n\n- Userspace 모드 (폐기 예정): 이 모드에서 kube-proxy는 각 서비스에 대해 포트에서 수신 대기합니다. 트래픽을 수신하면 해당 트래픽을 백엔드 파드 중 하나로 프록시합니다. 이 방법은 성능에 영향을 미치므로 일반적으로 사용되지 않습니다.\n- iptables 모드: 이 모드에서 kube-proxy는 네트워크 규칙을 구성하여 서비스의 트래픽을 올바른 백엔드 파드로 안내합니다. 이 모드는 userspace 모드보다 빠르고 믿을 만합니다. kube-proxy의 운영에 대한 기본 모드입니다.\n- IPVS 모드: IPVS (IP Virtual Server) 모드는 iptables와 유사하지만 해시 테이블을 사용하여 백엔드를 만들어 네트워크 트래픽 측면에서 훨씬 확장 가능하고 효율적입니다.\n- Kernelspace 프록시 모드: 이 프록시 모드는 Windows 노드에서만 사용할 수 있습니다. kube-proxy는 Windows Virtual Filtering Platform (VFP)에 있는 패킷 필터링 규칙을 구성합니다. 이것은 Windows vSwitch의 확장입니다.\n\n# Userspace 모드 (폐기 예정)\n\n최초이자 가장 오래된 운영 모드는 userspace 모드입니다. 이 모드에서 kube-proxy는 웹 서버를 운영하고 모든 서비스 IP 주소를 이 서버로 안내하여 iptables를 활용합니다. 이 웹 서버는 연결을 완료하고 프록시 역할을 수행하여 서비스의 엔드포인트에 나열된 파드로 요청을 전달합니다. 그러나 userspace 모드는 지금은 거의 사용되지 않으며, 이용할만한 강력한 이유가 없다면 피하는 것이 좋습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, Cluster IP가 10.0.0.1인 Service S가 있고 이 서비스에는 3개의 백엔드 Pod(A, B, C)가 있습니다. 이제 클라이언트가 Service S에 연결하려면 10.0.0.1로 연결될 것입니다.\n\n- 각 노드에서 실행되는 유저스페이스 모드의 kube-proxy는 이 연결을 가로챕니다. 이는 10.0.0.1로 오는 트래픽을 해당 노드에서 실행 중인 자체 프록시 서버로 전달하는 iptables 규칙을 유지합니다.\n- 프록시 서버는 건강한 백엔드 Pod 목록(A, B, C)을 유지하며, 서비스에 구성된 세션 어피니티 및 로드 밸런싱 알고리즘에 따라 요청을 전달할 Pod를 선택합니다.\n- 프록시 서버는 선택된 Pod에 대한 새로운 연결을 설정하고, 클라이언트의 요청을 보내고, Pod로부터 응답을 받은 후 응답을 클라이언트에게 전달합니다.\n\n이 프로세스는 기능적이지만 네트워크 경로에 추가적인 홉(유저스페이스 프록시 서버)을 도입하여 성능 부담을 유발하며, 다른 모드만큼 효율적이지 않을 수 있습니다. 이러한 이유로 유저스페이스 모드는 요즘 거의 사용되지 않습니다. kube-proxy의 기본 모드는 iptables이며, 고성능의 커널 수준 로드 밸런싱이 필요한 경우 ipvs 모드가 사용됩니다.\n\n# iptables 모드\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n`iptables` 모드는 작동에 iptables에만 의존합니다. 이게 기본 모드이자 가장 많이 사용되는 모드입니다. IPVS 모드는 최근에 General Availability (GA) 안정성을 달성했지만, iptables는 이미 잘 알려진 Linux 기술이기 때문에 일부로 인해 이 모드가 더 많이 사용될 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-K8skube-proxyIntroduction_1.png)\n\n`iptables` 모드는 실제 로드 밸런싱이 아니라 연결 분배를 용이하게 합니다. 다시 말해, `iptables` 모드가 연결을 백엔드 팟으로 라우팅하면 해당 연결을 통한 후속 요청은 해당 연결이 종료될 때까지 계속해서 동일한 팟으로 전달됩니다. 최적의 시나리오에서는, 이러한 행동이 간단하고 예측 가능하여 같은 연결 내 연속적인 요청은 백엔드 팟의 로컬 캐싱을 이용할 수 있습니다.\n\n하지만 이 방식은 HTTP/2 연결과 같이 오랜 기간 지속되는 연결 같은 예측할 수 없는 행동을 유발할 수 있습니다. 특히 HTTP/2가 gRPC의 전송 프로토콜로 사용되는 점이 주목할 만합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 예로, 서비스가 X와 Y 두 개의 팟으로 제공되는 상황을 고려해 봅시다. 전형적인 롤링 업데이트 중에 X가 Z로 교체됩니다. 이전 팟인 Y는 모든 기존 연결을 유지하면서도 X 팟이 종료되었을 때 다시 설정해야 했던 연결의 절반을 담당합니다. 이로 인해 Y 팟이 제공하는 트래픽이 상당히 증가할 수 있습니다. 이와 같이 트래픽의 불균형을 야기할 수 있는 여러 상황이 있습니다.\n\n예를 들어, 클러스터 IP가 10.0.0.1이고 백엔드 팟 A, B, C를 갖는 서비스 S가 있다고 가정해 봅시다.\n\niptables 모드에서 클라이언트가 10.0.0.1의 서비스 S에 연결하려고 하면, 연결 요청은 kube-proxy에 의해 가로채집니다.\n\n모든 노드에서 실행되는 kube-proxy는 10.0.0.1로 오는 트래픽을 백엔드 팟(A, B, 또는 C 중 하나)으로 투명하게 전달하는 iptables 규칙을 유지합니다. 이를 위해 패킷의 목적지 IP 주소를 하나의 팟의 IP 주소로 변경하는 NAT 규칙을 생성합니다. kube-proxy는 서비스가 구성한 세션 어피니티와 로드 밸런싱 알고리즘에 기반하여 백엔드 팟을 선택합니다. 이 결정은 연결이 설정될 때 만들어집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 번 iptables 규칙이 적용되어 패킷의 대상이 변경되면, Linux 커널 자체가 해당 패킷을 선택된 Pod로 전달합니다. 여기서 주요한 점은 한 번 연결이 설정되면, 해당 연결에 대한 모든 패킷이 iptables 규칙에 따라 Linux 커널에 의해 자동으로 선택된 Pod로 전달된다는 것입니다. 각 패킷을 처리하기 위해 kube-proxy가 필요하지 않으므로 iptables 모드가 사용자 공간 모드보다 더 효율적입니다.\n\n위 시나리오를 위한 샘플 iptables 규칙:\n\n```js\n# 서비스 S로 전송되는 트래픽을 일치시키고 대상을 변경하는 규칙\niptables -t nat -A PREROUTING -p tcp -d 10.0.0.1 --dport 80 -j DNAT --to-destination 172.17.0.2:80\niptables -t nat -A PREROUTING -p tcp -d 10.0.0.1 --dport 80 -j DNAT --to-destination 172.17.0.3:80\niptables -t nat -A PREROUTING -p tcp -d 10.0.0.1 --dport 80 -j DNAT --to-destination 172.17.0.4:80\n\n# Pod에서 나가는 트래픽을 노드 자체에서 생성된 것처럼 변형하는 규칙\niptables -t nat -A POSTROUTING -s 172.17.0.0/16 -j MASQUERADE\n```\n\n- 첫 번째 규칙 세트는 nat 테이블의 PREROUTING 체인에 있습니다. 이러한 규칙은 서비스 IP 10.0.0.1로 오는 트래픽과 포트 80으로 가는 트래픽과를 일치시키고 패킷의 대상을 백엔드 Pod 중 하나로 변경합니다.\n- POSTROUTING 체인의 MASQUERADE 규칙은 Pod에서 나오는 패킷의 소스 IP를 노드의 IP로 변경하여 응답이 올바르게 노드로 라우팅되고 클라이언트로 다시 라우팅될 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# IPVS 모드\n\nKubernetes의 kube-proxy에서 IPVS 모드는 IP Virtual Server를 나타냅니다. 이 모드는 iptables나 사용자 공간 모드보다 고성능의 커널 수준 로드 밸런싱 및 더 정교한 로드 밸런싱 알고리즘을 제공합니다.\n\nIPVS 모드에서 kube-proxy는 netfilter 후크를 사용하여 패킷을 캡처하고, 그런 다음 해당 패킷을 리눅스 커널의 IPVS 모듈에 전달합니다. IPVS 모듈은 IP 기반 로드 밸런싱을 수행하고 선택된 로드 밸런싱 알고리즘에 따라 패킷을 백엔드 Pod로 전달합니다. IPVS 로드 밸런싱 알고리즘에는 라운드로빈, 최소 연결, 가장 짧은 예상 지연 등이 포함될 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-K8skube-proxyIntroduction_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nIPVS 모드는 대규모 서비스 규모에 적합하며 iptables보다 일관된 해싱을 제공합니다. 또한 더 나은 네트워크 처리량, 더 나은 프로그래밀 수 및 IP 주소 및 포트 이외의 요소에 기반한 부하 분산 기능을 제공합니다.\n\n예를 들어 클러스터 IP가 10.0.0.1이고 백엔드 Pod A, B 및 C가 있는 S 서비스가 있다고 가정해 봅시다.\n\nIPVS 모드에서:\n\n- 클라이언트가 10.0.0.1에 연결하려고 할 때 연결 요청이 kube-proxy에 의해 잡힙니다.\n- 각 노드에서 실행되는 kube-proxy는 Linux 커널의 IPVS 모듈을 사용하여 10.0.0.1로 오는 트래픽을 백엔드 Pod (A, B 또는 C) 중 하나로 보냅니다.\n- IPVS 모듈은 서비스의 구성된 세션 어 피니티 및 부하 분산 알고리즘을 기반으로 백엔드 Pod를 선택합니다.\n- IPVS 모듈이 패킷의 대상을 업데이트하면 Linux 커널 자체가 선택된 Pod로 패킷을 전달합니다.\n  IPVS 모드는 고급 로드 밸런싱 기능을 제공하며 iptables 또는 사용자 공간 모드보다 더 많은 서비스 및 백엔드를 처리할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기는 kube-proxy가 로드 밸런싱을 설정하는 데 사용할 수 있는 IPVS 명령어를 시뮬레이션한 것입니다:\n\n```js\n# IPVS 서비스 추가\nipvsadm -A -t 10.0.0.1:80 -s rr\n\n# 백엔드 서버(팟) 추가\nipvsadm -a -t 10.0.0.1:80 -r 172.17.0.2:80 -m\nipvsadm -a -t 10.0.0.1:80 -r 172.17.0.3:80 -m\nipvsadm -a -t 10.0.0.1:80 -r 172.17.0.4:80 -m\n```\n\n-s rr 옵션은 스케줄링 방법을 라운드 로빈으로 설정합니다. -m 옵션은 포워딩 방법을 마스커레이팅으로 설정하며, 이는 SNAT과 유사합니다. 이러한 명령어로 규칙을 설정한 후, 다음과 같은 내용을 표시할 때 룰을 확인할 수 있습니다:\n\n```js\n# IPVS 규칙 표시\nipvsadm -L -n\n\nIP Virtual Server 버전 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -\u003e RemoteAddress:Port           Forward Weight ActiveConn InActConn\nTCP  10.0.0.1:80 rr\n  -\u003e 172.17.0.2:80                Masq    1      0          0\n  -\u003e 172.17.0.3:80                Masq    1      0          0\n  -\u003e 172.17.0.4:80                Masq    1      0          0\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# KernelSpace Mode\n\n**KernelSpace** 모드는 가장 최근에 추가된 기능이며 Windows 시스템에서만 사용할 수 있습니다. Kubernetes를 Windows에서 사용할 때 유저스페이스 모드에 대한 대체 방법을 제공합니다. 왜냐하면 iptables과 ipvs는 리눅스에 특화된 기능들이기 때문입니다.\n","ogImage":{"url":"/assets/img/2024-05-20-K8skube-proxyIntroduction_0.png"},"coverImage":"/assets/img/2024-05-20-K8skube-proxyIntroduction_0.png","tag":["Tech"],"readingTime":9},{"title":"디브옵스를 배우고 싶지만 어떻게 시작해야 할지 모르겠다구요 여기 가이드가 도와줄게요","description":"","date":"2024-05-20 17:07","slug":"2024-05-20-WanttoLearnDevOpsbutDontKnowWheretoStartHeresYourGuide","content":"\n안녕하세요 여러분, 이 블로그에서는 데브옵스 학습 과정에서 배운 몇 가지 팁을 공유하려고 합니다. 데브옵스 여정을 시작한 방법, 따라 온 경로 및 더 나은 미래를 위해 따를 수 있는 방법에 대해 설명할 것입니다. 또한 제 LinkedIn 프로필을 확인하여 현재까지 데브옵스에서 한 일들과 제 GitHub에 있는 모든 데브옵스 프로젝트를 확인할 수 있습니다.\n\n도구 경로에 대한 설명도 할 예정이에요. 공유하는 링크들에서 제 모든 노트를 찾을 수 있으며 사용한 강의도 함께 공유할 예정입니다.\n\n원하신다면 제 노트에 기여할 수도 있습니다 (GitHub 저장소에 있습니다). Pull 요청을 만들면 리뷰하고 병합할 것입니다.\n\n이제 시작해봅시다. 학습 경로에 들어가기 전에 먼저 데브옵스를 이해하려고 노력해 볼 것입니다. 이것은 책의 정의가 아니라 현재까지 모아 온 데브옵스에 대한 몇 마디일 뿐입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데브옵스란 무엇인가요?\n\n간단히 말해서, 데브옵스는 조직이 개발 및 운영 팀을 하나로 통합하는 방법론입니다. 이를 통해 두 팀이 협력하여 효율적으로 애플리케이션을 개발하고 배포할 수 있습니다.\n\n데브옵스는 애플리케이션을 개발하고 배포하는 프로세스를 자동화하는 다양한 도구를 포함한 종합적인 용어입니다.\n\n데브옵스의 주요 이점 중 하나는 이러한 프로세스를 자동화함으로써 수작업 방법에 비해 시간 소요가 적고 오류 가능성이 낮아진다는 점입니다. 이 자동화는 시장 진입 시간(TTM)을 단축시킴으로써 빠르게 성장하는 기업에 이상적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 어떻게 나는 데브옵스 학습 여정을 시작했을까? 🤔\n\n솔직히 처음에는 데브옵스를 배우기로 계획한 적이 없었습니다. 제 여정은 클라우드 컴퓨팅에 대한 흥미로 시작되었습니다. 클라우드 기술에 더 심층적으로 파고들수록, 데브옵스와 클라우드 컴퓨팅이 밀접하게 관련되어 있고 매우 잘 보완되는 것을 깨달았습니다.\n\n클라우드와 데브옵스에 대해 학습을 시작할 때 저는 파이썬에 대한 기본적인 이해만 있었습니다. 올바른 학습 자료와 다양한 기술을 배울 최적의 순서를 찾는 데 어려움을 겪었습니다. 길을 찾기 위해 블로그를 많이 읽고, 수많은 YouTube 비디오를 시청했습니다. 이러한 자료들은 데브옵스와 클라우드 컴퓨팅 분야에서 경력을 시작하는 방법을 이해하는 데 도움이 되었습니다.\n\n# 마주한 어려움들은 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제가 직면한 주요 어려움 중 하나는 올바른 학습 자원을 찾는 것이었습니다. 무수히 많은 자습서, 블로그, 강좌 및 비디오가 있지만, 모든 학습자에게 적합한 것은 아닙니다. 이 어려움을 극복한 방법은 다음과 같습니다:\n\n- 자원 과부하: 많은 자원이 제공되어 어떤 것을 따라가야할지 결정하기가 압도적이었습니다. 제 학습 스타일과 일치하는 자료를 찾기 위해 다양한 자료를 살펴본 시간이 많았습니다.\n- 진도와 이해: 모든 사람은 서로 다른 속도와 방식으로 학습합니다. 제 진도와 이해 수준에 맞는 자원을 찾아야 했습니다. 어떤 자료는 너무 고급스러웠고, 다른 것들은 너무 기초적이었습니다.\n\n# 학습 경로\n\n다음은 저의 데브옵스 여정 중 따라 온 학습 경로입니다. 이미 알고 있는 기술은 무시하셔도 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-WanttoLearnDevOpsbutDontKnowWheretoStartHeresYourGuide_0.png)\n\n1. 프로그래밍 기초부터 시작하세요 (Python 또는 Golang)\n   가장 먼저 해야 할 일은 프로그래밍 언어를 배우는 것입니다. Python과 Golang은 좋은 선택지입니다. 변수, 반복문, 함수와 같은 기초부터 시작해보세요.\n\n2. 컴퓨터 네트워킹 이해하기\n   다음으로 컴퓨터 네트워킹에 대해 잘 파악해보세요. 이것은 컴퓨터가 서로 연결하고 통신하는 방법에 관한 것입니다. IP 주소, DNS 및 기본 네트워킹 개념을 배워보세요.\n\n3. Linux와 Bash에 익숙해지기\n   대부분의 DevOps 도구는 Linux에서 실행되므로 이 운영 체제에 대해 잘 알고 있어야 합니다. Bash는 리눅스의 명령줄 도구로, 스크립트를 작성하고 작업을 자동화하는 데 사용할 것입니다. 걱정하지 마세요, Linux 전문가가 되어야 할 필요는 없습니다. 기본적인 것에 익숙해지기만 하면 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4. Git을 이용하여 버전 관리 마스터하기\n   Git은 코드의 변경사항을 추적하는 데 도움이 되는 도구입니다. 여러분의 프로젝트를 위한 타임머신 같은 역할을 합니다. 여러분의 작업을 저장하고 변경사항을 추적하며 다른 사람들과 협업하는 방법을 배워보세요.\n\n5. 클라우드 제공업체(AWS, Azure, Google Cloud) 배우기\n   클라우드 제공업체는 여러분이 인터넷을 통해 컴퓨터와 저장소를 빌릴 수 있게 해줍니다. AWS(Amazon Web Services)는 인기 있는 선택지이지만 Azure와 Google Cloud도 훌륭합니다. 이 플랫폼을 활용하여 여러분의 애플리케이션을 배포하고 관리하는 방법을 배워보세요.\n\n6. Docker로 컨테이너화에 몰두하기\n   Docker는 여러분의 애플리케이션을 패키징하여 여러분의 노트북부터 거대한 클라우드 서버까지 어디에서든 실행할 수 있게 해줍니다. 이는 애플리케이션을 위한 휴대용 컨테이너라고 생각하시면 됩니다. 이러한 컨테이너를 만들고 관리하는 방법을 배워보세요.\n\n7. CI/CD 도구 선택하기\n   CI/CD는 지속적 통합/지속적 배포를 의미합니다. Jenkins, CircleCI, GitLab CI와 같은 도구들은 여러분의 코드를 테스트하고 배포하는 프로세스를 자동화해줍니다. Jenkins는 흔히 선택되는 도구입니다. 자동화된 파이프라인을 설정하여 개발 프로세스를 효율적으로 운영하는 방법을 배워보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n8. Terraform을 사용해 인프라 관리하기\n   Terraform은 서버 및 데이터베이스와 같은 인프라를 코드로 정의할 수 있는 도구입니다. 이는 환경을 자동으로 설정하고 청소할 수 있음을 의미합니다. 클라우드 리소스를 관리하기 위해 Terraform 스크립트를 작성하는 방법을 배우세요.\n\n9. Ansible을 사용해 구성 자동화하기\n   Ansible은 서버 구성을 자동화하는 데 도움이 됩니다. 각 서버를 수동으로 설정하는 대신 스크립트인 Playbook을 작성하여 작업을 수행할 수 있습니다. 이렇게 함으로써 시간을 절약하고 오류를 줄일 수 있습니다.\n\n10. Kubernetes 또는 Docker Swarm을 사용해 컨테이너 조정하기\n    많은 컨테이너를 가지고 있을 때는 이를 관리해야 합니다. Kubernetes (일반적으로 K8S로 불림)와 Docker Swarm은 컨테이너화된 애플리케이션을 배포, 관리 및 확장하는 데 도움이 되는 도구입니다. 이 도구들을 사용하여 모든 것을 원활하게 유지하는 방법을 배우세요.\n\n11. Prometheus와 Grafana로 모니터링하기\n    모니터링은 애플리케이션의 건강을 유지하는 데 중요합니다. Prometheus는 애플리케이션 성능에 대한 데이터를 수집하며, Grafana는 이 데이터를 아름다운 대시보드로 시각화할 수 있게 해줍니다. 문제가 커지기 전에 문제를 파악할 수 있도록 모니터링을 설정하는 방법을 배우세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 단계를 따라가면 DevOps의 견고한 기초를 구축할 수 있습니다. 기초부터 시작하여 각 단계를 당신의 속도로 진행해보세요. 즐겁게 배우세요!\n\n# 위 기술에 대한 자료:\n\n위에서 언급한 기술에 대한 자료를 찾고 싶으시다면, 제가 학습한 대부분의 내용을 담은 GitHub 저장소가 있습니다. 이 저장소를 팔로우하고 자신의 노트를 병합하기 위한 풀 리퀘스트도 생성할 수 있습니다. 각 저장소마다 제가 작업한 도구 목록을 찾을 수 있습니다.\n\nAnsible 학습 저장소: 여기를 클릭하세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMarkdown 형식:\n\n- [도커 학습 레포지토리: 클릭하세요](https://github.com/docker-learning)\n- [쿠버네티스 학습 레포지토리: 클릭하세요](https://github.com/kubernetes-learning)\n- [Argo CD 학습 레포지토리: 클릭하세요](https://github.com/argo-cd-learning)\n- [젠킨스 학습 레포지토리: 클릭하세요](https://github.com/jenkins-learning)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGit, Networking, Linux Repository: [여기를 클릭해주세요](https://www.example.com)\n\n이제 사용한 리소스를 공유하겠습니다. 걱정 없이 사용하실 수 있을 거에요. 도움이 될 거라 믿어요.\n\n- 클라우드 컴퓨팅을 배우기 위해서는 해당 공식 학습 플랫폼을 사용하시면 됩니다. 예를 들어, AWS에는 AWS Skill Builder, Azure에는 Microsoft Learn 등이 있습니다.\n- DevOps 도구를 배우기 위해서는 해당 공식 문서를 효과적으로 활용하는 것을 추천해요. 만약 튜토리얼을 원하신다면, YouTube의 Abhishek Veeramala를 추천해요. 그의 YouTube 플레이리스트를 통해 다양한 도구에 대한 내용을 학습하실 수 있습니다. 그는 여러 도구에 대한 많은 Zero to Hero 시리즈도 만들었어요. Git, Linux, 그리고 Networking 관련된 비디오도 Abhishek Veeramala의 YouTube 채널에서 찾아보실 수 있습니다.\n\n이러한 기술들을 가장 잘 이해하고 실시간 경험을 하기 위해, 라이브 부트캠프에 참여하는 것을 권장해요. 클라우드와 DevOps를 위한 많은 무료 부트캠프들이 인터넷 상에서 제공되고 있어요. 만약 부트캠프에 참가할 기회가 있다면, 이 기회를 최대한 활용해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLinkedIn에서 연결합시다: LinkedIn 프로필\n\n더 많은 실전 프로젝트를 살펴보세요 (제 저장소가 도움이 되셨다면, GitHub에서 저를 팔로우하는 것을 잊지 마세요): 내 GitHub 계정\n","ogImage":{"url":"/assets/img/2024-05-20-WanttoLearnDevOpsbutDontKnowWheretoStartHeresYourGuide_0.png"},"coverImage":"/assets/img/2024-05-20-WanttoLearnDevOpsbutDontKnowWheretoStartHeresYourGuide_0.png","tag":["Tech"],"readingTime":8},{"title":"도커 도컴포즈를 사용하여 PostgreSQL을 설치하는 방법","description":"","date":"2024-05-20 17:06","slug":"2024-05-20-DockerHowtoInstallPostgreSQLusingDockerCompose","content":"\nPostgreSQL은 개발 커뮤니티에서 널리 사용되는 인기 있는 관계형 데이터베이스 관리 시스템입니다.\n\n![이미지](/assets/img/2024-05-20-DockerHowtoInstallPostgreSQLusingDockerCompose_0.png)\n\nDocker Compose는 여러 컨테이너로 구성된 Docker 응용 프로그램을 정의하고 실행할 수 있는 강력한 도구입니다. 여러 컨테이너를 쉽게 관리하기 위해 구성을 단일 YAML 파일에 정의할 수 있어요.\n\nPostgreSQL은 개발 커뮤니티에서 널리 사용되는 인기 있는 관계형 데이터베이스 관리 시스템입니다. Docker Compose를 사용하면 PostgreSQL 인스턴스를 컨테이너에서 쉽게 설정하고 실행할 수 있어요. 이는 개발, 테스트 및 배포 목적으로 훌륭한 솔루션일 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블로그 포스트에서는 Docker Compose를 사용하여 PostgreSQL을 설치하는 단계를 안내해 드리겠습니다.\n\n단계 1: Docker 설치\n\nDocker Compose를 설치하고 사용하기 전에 시스템에 Docker가 설치되어 있는지 확인해야 합니다. Docker는 Windows, macOS 및 Linux 운영 체제용으로 제공됩니다. 공식 Docker 웹사이트에서 적절한 버전의 Docker를 다운로드할 수 있습니다.\n\n단계 2: Docker Compose 설치\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도커를 시스템에 설치한 후에는 공식 도커 컴포즈 설치 안내에 따라 도커 컴포즈를 설치할 수 있어요. 운영 체제에 따라 설치 단계가 조금씩 다를 수 있지만, 일반적으로 직관적입니다.\n\nStep 3: 도커 컴포즈 파일 생성하기\n\n도커 컴포즈를 사용하여 PostgreSQL 컨테이너를 생성하기 위해 구성을 도커 컴포즈 파일에 정의해야 해요. 원하는 디렉토리에 docker-compose.yml이라는 새 파일을 만들고 다음 코드를 붙여넣어 주세요:\n\n```js\nversion: '3.9'\n\nservices:\n  postgres:\n    image: postgres:14-alpine\n    ports:\n      - 5432:5432\n    volumes:\n      - ~/apps/postgres:/var/lib/postgresql/data\n    environment:\n      - POSTGRES_PASSWORD=S3cret\n      - POSTGRES_USER=citizix_user\n      - POSTGRES_DB=citizix_db\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위와 같은 명령어입니다:\n\n- up은 컨테이너를 구동합니다.\n- -d는 백그라운드 모드로 실행합니다.\n\n이 파일에서는 official PostgreSQL 이미지를 사용하는 db라는 단일 서비스를 정의합니다. 또한 default postgres 사용자의 암호를 지정하기 위해 POSTGRES_PASSWORD 환경 변수를 설정합니다. 마지막으로 컨테이너 내의 /var/lib/postgresql/data 디렉토리에 로컬 ./data 디렉토리를 장착하여 PostgreSQL 데이터를 저장하는 위치를 지정합니다.\n\n단계 4: PostgreSQL 컨테이너 시작\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPostgreSQL 컨테이너를 시작하려면 터미널에서 docker-compose.yml 파일이 있는 디렉토리로 이동하고 다음 명령을 실행하세요:\n\n```js\ndocker-compose up -d\n```\n\n```js\n➜ docker-compose up -d\nCreating network \"pg_default\" with the default driver\nCreating pg_postgres_1 ... done\n```\n\n위 명령을 사용하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 'up' 명령어를 사용하면 컨테이너를 올릴 수 있습니다.\n- '-d' 옵션은 detached 모드로 실행합니다.\n\n이 명령어는 컨테이너를 detached 모드로 시작합니다. 이는 백그라운드에서 실행됨을 의미합니다. 컨테이너가 실행 중인지 확인하려면 다음 명령어를 실행하세요:\n\n```js\ndocker ps\n```\n\n```js\n➜ docker-compose ps\n    Name                   Command              State                    Ports\n------------------------------------------------------------------------------------------------\npg_postgres_1   docker-entrypoint.sh postgres   Up      0.0.0.0:5432-\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스텝 5: PostgreSQL 컨테이너 중지 및 제거\n\nPostgreSQL 컨테이너를 중지하고 제거하려면 터미널에서 docker-compose.yml 파일이 있는 디렉토리로 이동한 후 다음 명령을 실행하세요:\n\n```js\ndocker-compose down\n```\n\n이렇게 하면 컨테이너가 중지되고 제거됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도커 컴포즈를 사용하여 PostgreSQL을 설치하는 것은 컨테이너 내에서 빠르게 PostgreSQL 인스턴스를 설정할 수 있는 간단한 과정입니다. 도커 컴포즈 파일에서 컨테이너의 구성을 정의하여 여러 컨테이너를 쉽게 관리하고 확장할 수 있습니다.\n\n도커 컴포즈를 사용하여 PostgreSQL을 설치하려면 먼저 시스템에 도커와 도커 컴포즈를 설치해야 합니다. 그 후 도커 컴폏 파일을 만들고 PostgreSQL 컨테이너의 구성을 정의할 수 있습니다. 그런 다음 컨테이너를 시작하고 psql과 같은 PostgreSQL 클라이언트를 사용하여 연결할 수 있습니다.\n\n도커 컴포즈를 사용하면 PostgreSQL 컨테이너를 쉽게 관리하고 확장할 수 있으며 개발 및 테스트 환경을 설정하는 간단하고 반복 가능한 방법을 제공합니다. 전반적으로 도커 컴포즈는 복잡한 애플리케이션을 관리하고 배포하는 프로세스를 간소화할 수 있는 강력한 도구입니다.\n","ogImage":{"url":"/assets/img/2024-05-20-DockerHowtoInstallPostgreSQLusingDockerCompose_0.png"},"coverImage":"/assets/img/2024-05-20-DockerHowtoInstallPostgreSQLusingDockerCompose_0.png","tag":["Tech"],"readingTime":5},{"title":"도커 컨테이너에서 상호 TLS를 구현하는 방법","description":"","date":"2024-05-20 17:05","slug":"2024-05-20-HowtoImplementMutualTLSwithDockerContainers","content":"\n컨테이너와 마이크로서비스의 등장으로 인해 서비스 간의 통신이 HTTP와 같은 프로토콜을 통해 더 자주 발생할 가능성이 높아졌습니다. 그러나 서비스가 신뢰할 수 없는 네트워크를 통과하는 경우(예: 클라우드 내), 그들의 통신이 안전한지 어떻게 확인할 수 있을까요? 한 가지 방법은 상호 전송 계층 보안(mTLS)을 통해 가능합니다. 이를 통해 서비스들은 상호 인증(서비스가 자신이라고 주장하는 대로인지 어떻게 알 수 있을까요?) 및 통신 암호화를 할 수 있습니다. 그렇다면 mTLS는 어떻게 작동할까요? 한 번 자세히 알아봅시다.\n\n두 당사자 간의 상호 인증 및 암호화는 분명히 새로운 것이 아닙니다. SSH 및 IPSec(대부분의 VPN 기술을 구동하는 프로토콜의 기반이 되는)과 같은 프로토콜의 기초가 되었으며 최근에는 Istio와 Linkerd와 같은 서비스 메시 프로젝트에서도 채택되었습니다.\n\n운영용 사례에서 서비스 메시는 mTLS를 쉽게 활용할 수 있는 좋은 방법이지만, 서비스 메시를 채택하기 전에 두 개의 도커 컨테이너 간의 단순한 mTLS 구현이 어떻게 작동하는지 궁금할 수 있습니다.\n\n자세한 내용은 다음 GitHub 저장소를 참조해주세요: https://github.com/blhagadorn/mutual-tls-docker\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 기본 클라이언트 및 서버 설정\n\nGo를 사용하여 기본 클라이언트 및 서버를 설정해 봅시다 - GitHub 저장소의 01-client-server-basic 디렉토리로 이동하여 따라해 보세요. 기본 클라이언트 및 서버를 설정한 후에는 mTLS를 추가할 것입니다.\n\n기본 서버의 요약은 다음과 같습니다 (여기서 찾을 수 있습니다)\n\n```js\nfunc helloHandler(w http.ResponseWriter, r *http.Request) {\n  io.WriteString(w, \"Hello, world without mutual TLS!\\n\")\n}\nfunc main() {\n  http.HandleFunc(\"/hello\", helloHandler)\n  log.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기본적으로 우리는 8080포트에서 /hello 경로를 청취하고 호출되면 문자열을 반환합니다.\n\n여기 기본 클라이언트의 주요 내용입니다 (여기에서 찾을 수 있습니다):\n\n```js\n r, err := http.Get(\"http://localhost:8080/hello\")\n if err != nil {\n   log.Fatal(err)\n }\n defer r.Body.Close()\n body, err := ioutil.ReadAll(r.Body)\n```\n\n기본적으로, http://localhost:8080/hello로 HTTP GET 요청을 만들고 응답을 쓰기로 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리가 지금까지 한 것을 빌드하고 실행해 보세요. 01-client-server-basic/ 디렉토리 안에서 모두 수행합니다.\n\n```js\n$ docker build -t basic-server -f Dockerfile.server . \u0026\u0026 docker run -it --rm --network host basic-server\n```\n\n서버를 계속 실행한 채로 유지하고, 동일한 디렉토리에서 새 창을 열어서 클라이언트를 실행하세요:\n\n```js\n$ docker build -t basic-client -f Dockerfile.client . \u0026\u0026 docker run -it --rm --network host basic-client\n\u003e Hello, world without mutual TLS!\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n성공했습니다! 이제 각각의 도커 컨테이너에서 클라이언트와 서버가 대화하고 있습니다. 도커 컨테이너 간에 공유 네트워크를 만드는 --network host 옵션의 사용에 주목해 주세요. 따라서 두 컨테이너에서 localhost가 동일합니다.\n\n선택적으로 클라이언트를 실행하는 동안 tcpdump를 사용하여 평문 전송이 확인됩니다:\n\n```js\n$ docker run -it --network host --rm dockersec/tcpdump tcpdump -i any port 8080 -c 100 -A\n\u003e Date: Sat, 03 Feb 2024 15:05:20 GMT\n\u003e Content-Length: 33\n\u003e Content-Type: text/plain; charset=utf-8\n\u003e Hello, world without mutual TLS!\n```\n\n우리는 TLS가 사용되지 않았음을 알 수 있습니다. 간단히 말해서, 텍스트를 읽을 수 있기 때문에 (암호화되었다면 가독성이 떨어졌을 것입니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 상호 TLS 추가하기\n\n상호 TLS를 추가하려면 먼저 연결에 사용할 개인 키와 해당 인증서를 생성해야 합니다. 만약 GitHub 저장소를 따라가고 있다면 예제의 나머지 부분을 확인하기 위해 02-client-server-mtls 디렉토리로 이동해주세요.\n\n```js\nopenssl req -newkey rsa:2048 \\\n-nodes -x509 \\\n-days 3650 \\\n-keyout key.pem \\\n-out cert.pem \\\n-subj \"/C=US/ST=Montana/L=Bozeman/O=Organization/OU=Unit/CN=localhost\" \\\n-addext \"subjectAltName = DNS:localhost\"\n```\n\n여기서는 로컬호스트의 CN(공통 이름)과 SAN(대체 주체 이름)을 포함하는 대응하는 공개 키가 포함된 개인 키(key.pem)와 인증서(cert.pem)를 생성합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n참고: CN은 폐기되었으며 대부분의 최신 TLS 라이브러리에서 SAN을 포함하여 설정해야 합니다. 예를 들어 Golang의 net/http도 그렇습니다. 이 예제에서는 일부 라이브러리가 아직 CN을 설정하거나 이를 예비 수단으로 사용하는 경우를 고려하여 둘 다 설정했습니다.\n\n인증서(공개 키)와 개인 키는 여기서 몇 가지 역할을 합니다. 첫째, 개인/공개 키 조합은 세션 설정을 위해 통신을 암호화하는 데 사용됩니다. 둘째, 인증을 위해 인증서 정보가 사용되며, 해당 인증서로 보호하려는 도메인 이름은 localhost(즉, SAN)입니다.\n\n이제 클라이언트 코드(client-mtls.go 파일)를 살펴봅시다. 다음 함수는 주어진 인증서와 키로 HTTPS 클라이언트를 반환합니다:\n\n```go\nfunc getHTTPSClientFromFile() *http.Client {\n  caCert, err := ioutil.ReadFile(\"cert.pem\")\n  if err != nil {\n    log.Fatal(err)\n  }\n  caCertPool := x509.NewCertPool()\n  caCertPool.AppendCertsFromPEM(caCert)\n  cert, err := tls.LoadX509KeyPair(\"cert.pem\", \"key.pem\")\n  if err != nil {\n    log.Fatal(err)\n  }\n  client := \u0026http.Client{\n    Transport: \u0026http.Transport{\n      TLSClientConfig: \u0026tls.Config{\n        RootCAs:      caCertPool,\n        Certificates: []tls.Certificate{cert},\n      },\n    },\n  }\n  return client\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기에서 몇 가지가 발생하고 있습니다. 먼저, RootCAs가 생성한 인증서 풀(하나의 인증서만 포함)로 설정되고 있습니다. 이는 클라이언트가 다른 인증 기관을 확인하는 데 사용할 루트 인증서 집합입니다. 예제에서 중간 인증서를 생성하지 않았기 때문에 이것은 별 의미가 없지만, 여러 거래에서 이것은 신뢰의 루트를 정의합니다(루트가 서명한 모든 인증서가 유효할 것입니다). 둘째로, 우리 클라이언트가 안전한 연결을 설정할 때 서버에 전달할 인증서인 cert.pem을 전달하고 있습니다. 또한, 인증서 키 쌍은 통신을 암호화하는 데 사용할 비공개 키인 key.pem을 포함하고 있습니다.\n\n이제 관련 서버 코드를 살펴보겠습니다:\n\n```js\nfunc main() {\n  http.HandleFunc(\"/hello\", helloHandler)\n  caCert, err := ioutil.ReadFile(\"cert.pem\")\n  if err != nil {\n    log.Fatal(err)\n  }\n\n  caCertPool := x509.NewCertPool()\n  caCertPool.AppendCertsFromPEM(caCert)\n  tlsConfig := \u0026tls.Config{\n    ClientCAs:  caCertPool,\n    ClientAuth: tls.RequireAndVerifyClientCert,\n  }\n  tlsConfig.BuildNameToCertificate()\n  server := \u0026http.Server{\n    Addr:      \":8443\",\n    TLSConfig: tlsConfig,\n  }\n  log.Fatal(server.ListenAndServeTLS(\"cert.pem\", \"key.pem\"))\n}\n```\n\n서버 구성은 클라이언트 구성과 매우 유사합니다(이는 상호 인증이기 때문에 이해되는 바입니다). 루트 인증기관이 비슷하게 정의되어 있고, TLS 구성이 설정되며, 최종적으로 서버가 인증서와 인증서 키 쌍을 사용하여 수신 대기를 시작합니다. 클라이언트와 마찬가지로 서버도 연결하려는 모든 이해 관계자에게 자신의 인증서를 전달합니다(클라이언트가 인증서의 공개 키에 따라 통신을 암호화할 수 있도록 하는 TLS 핸드셰이크의 일부로), 그리고 또한 이 키는 메시지를 암호화하고 인증서의 공개 키의 소유권을 확인하는 데 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 02-client-server-mtls 디렉토리 안에서 예제를 실행해 보겠습니다.\n\n먼저 서버를 실행하겠습니다:\n\n```js\n$ docker build -t mtls-server -f Dockerfile.server . \u0026\u0026 docker run -it --rm --network host mtls-server\n```\n\n이후 클라이언트를 실행해주세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ docker build -t mtls-client -f Dockerfile.client . \u0026\u0026 docker run -it --rm --network host mtls-client\n\u003e 안녕하세요, 상호 TLS로 세계여!\n```\n\n다시 성공했어요!\n\n우리는 다시 tcpdump로 확인할 수 있습니다. 평문이 없고 컨테이너 간 통신이 암호화되어 있는지 확인할 수 있어요.\n\n```js\n$ docker run -it --network host --rm dockersec/tcpdump tcpdump -i any port 8443 -c 100 -A\n\u003e..V.(.@.................................. .\u0026............0.........\nO.f........\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과가 완전히 알아볼 수 없고 암호화를 사용하고 있어서 읽을 수 없는 것을 주목해주세요.\n\n# 빠른 다이어그램\n\n아래 다이어그램을 참조하시면 방금 수행한 mTLS 상호 작용에 대해 시각적으로 설명한 것을 보실 수 있습니다.\n\n![mTLS 상호 작용 다이어그램](/assets/img/2024-05-20-HowtoImplementMutualTLSwithDockerContainers_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마무리\n\n지금까지 상호 TLS 없이 한 클라이언트-서버 상호 작용과 상호 TLS가 포함된 다른 클라이언트-서버 상호 작용을 성공적으로 만들었습니다. 우리는 TLS를 추가하기 위해 로컬호스트를 SAN으로 사용한 키와 인증서를 생성했습니다. 이후에 우리는 클라이언트 코드를 편집하여 루트 CA에 대한 TLS 구성을 포함시키고 통신을 암호화할 인증서와 개인 키를 지정했습니다. 서버 코드도 마찬가지로 루트 CA를 지정하고, 서버가 청취해야 할 인증서와 키를 지정했습니다.\n\n이제 mTLS를 마이크로서비스 간에 서비스 메시를 통해 고려할 수 있는 기초가 생겼기를 바랍니다. 저희의 예에서는 한 번 인증서와 키를 생성하고 수동으로 구성에 입력했지만, 서비스 메시는 종종 짧은 갱신 주기로 자동으로 해당 인증서를 회전하고, 일반 통신을 측면 프록시를 통해 라우팅하며 — 그런 다음 일반 통신을 mTLS로 업그레이드하고 목적지에 도달하면 복호화합니다. 본질적으로 mTLS는 보이지 않고, 이것이 강력한 프록시 구성과 제어 계층의 마법입니다.\n\n이 글을 통해 컨테이너화된 작업을 보호하는 방법에 대해 조금이나마 배우셨기를 바랍니다. 그리고 언제나 — 더 많은 글을 보기 위해 저를 Medium에서 팔로우하거나 Twitter에서 확인해 보세요.\n","ogImage":{"url":"/assets/img/2024-05-20-HowtoImplementMutualTLSwithDockerContainers_0.png"},"coverImage":"/assets/img/2024-05-20-HowtoImplementMutualTLSwithDockerContainers_0.png","tag":["Tech"],"readingTime":10},{"title":"도커 다이어트 보안 및 속도를 위한 데비안 이미지","description":"","date":"2024-05-20 17:03","slug":"2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed","content":"\n\u003cimg src=\"/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_0.png\" /\u003e\n\n컨테이너화된 세상에서 이미지 크기가 중요합니다. 작은 이미지는 더 빠른 배포, 줄어든 저장 요구 사항 및 향상된 보안으로 이어집니다. Google의 Distroless Docker 이미지가 등장하는 곳입니다.\n\nDistroless 이미지는 극단적으로 최소한한 이미지입니다. 패키지 관리자, 셸 및 불필요한 유틸리티를 포함한 무겁고 복잡한 운영 체제 계층을 제거합니다. 대신, 이들은 당신의 애플리케이션이 실행하기 위해 필요한 것에만 집중합니다: 애플리케이션 자체와 필수 런타임 종속성입니다.\n\n# 왜 Distroless를 사용해야 할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDistroless 이미지를 사용하는 이점은 매우 많습니다:\n\n- 크기가 작음: Distroless 이미지는 극히 작아서 종종 몇 메가바이트에 불과합니다. 이는 배포가 빨라지고 컨테이너 레지스트리 및 클러스터의 저장 공간을 줄이는 것을 의미합니다.\n- 향상된 보안: 불필요한 구성 요소를 제거함으로써 Distroless 이미지는 잠재적인 취약점을 위한 공격 표면을 줄입니다. 관리해야 할 패키지가 적기 때문에 보안 패치 작업도 매우 간단해집니다.\n- 성능 향상: 작은 이미지는 컨테이너의 시작 시간이 빨라지도록 돕습니다.\n\n# Distroless로 시작하기\n\nDistroless는 다양한 언어 및 런타임을 지원하는 기본 이미지를 제공합니다. 다음은 이를 사용하는 빠른 가이드입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이미지 선택: 사용 가능한 이미지를 탐색하려면 GitHub의 Distroless 프로젝트(https://github.com/GoogleContainerTools/distroless)로 이동하세요. 인기 있는 옵션으로는 일반 목적의 애플리케이션용 gcr.io/distroless/base 및 언어별 이미지인 gcr.io/distroless/java17이 있습니다.\n- Dockerfile 빌드: Dockerfile에서 선택한 Distroless 이미지를 기본 레이어로 사용하세요.\n- 애플리케이션 복사: COPY 명령을 사용하여 애플리케이션 코드와 필요한 종속성을 이미지로 복사하세요.\n- 엔트리포인트 정의: Distroless 이미지에는 셸이 없으므로 ENTRYPOINT 명령을 사용하여 애플리케이션의 엔트리포인트를 정의해야 합니다. 이는 벡터 형태로 지정해야 합니다. (예: [\"/app/my_app\"])\n\n# JAVA를 위한 Distroless 이미지 사용\n\nDistroless 이미지 사용의 장점을 설명하기 위해 Java 애플리케이션 개발 프로세스에 이를 원활하게 통합하는 방법을 탐색해볼까요?\n\n애플리케이션 이미지를 빌드하는 데 사용된 샘플 Dockerfile입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nFROM gcr.io/distroless/java17:nonroot\nEXPOSE 8080\nCOPY target/*.jar app.jar\nCMD [\"app.jar\"]\n```\n\n취약점 수와 이미지 크기를 비교한 분석 결과, 상당한 개선이 있었습니다. 이러한 향상을 보여주는 자세한 통계는 다음과 같습니다.\n\n이전에 사용한 openjdk 베이스 이미지\n\n이전 취약점 통계: 총 96개 | 중요: 0 | 높음: 23 | 중간: 73\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_1.png)\n\nJava distroless 이미지 사용 중\n\n현재 취약점 통계: 총 1 | 심각: 0 | 높음: 0 | 중간: 1\n\n![이미지](/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n베이스 Java 이미지 크기: 226MB [이미지 크기의 50% 감소]\n\n# NGINX에 Distroless 이미지 사용하기\n\n미리 빌드된 Nginx Distroless 이미지가 즉시 사용 가능하지 않기 때문에, 베이스 Distroless 이미지를 사용하여 커스텀 이미지를 만드는 방법을 살펴보겠습니다.\n\n애플리케이션 이미지를 빌드하는 데 사용된 샘플 Dockerfile입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# Nginx를 빌드 이미지로 사용\nFROM nginx:1.25 as build\n\n# 메인 이미지로 distroless nonroot 사용\nFROM gcr.io/distroless/base-debian11:nonroot\nCOPY --from=build /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/ca-certificates.crt\nCOPY --from=build /etc/passwd /etc/passwd\nCOPY --from=build /etc/group /etc/group\nUSER nginx\n\n# 빌드 이미지로부터 필요한 Nginx 라이브러리 복사\nCOPY --from=build /lib/x86_64-linux-gnu/libdl.so.2 /lib/x86_64-linux-gnu/libdl.so.2\nCOPY --from=build /lib/x86_64-linux-gnu/libc.so.6 /lib/x86_64-linux-gnu/libc.so.6\nCOPY --from=build /lib/x86_64-linux-gnu/libz.so.1 /lib/x86_64-linux-gnu/libz.so.1\nCOPY --from=build /lib/x86_64-linux-gnu/libcrypt.so.1 /lib/x86_64-linux-gnu/libcrypt.so.1\nCOPY --from=build /lib/x86_64-linux-gnu/libpthread.so.0 /lib/x86_64-linux-gnu/libpthread.so.0\nCOPY --from=build /lib64/ld-linux-x86-64.so.2 /lib64/ld-linux-x86-64.so.2\nCOPY --from=build /usr/lib/x86_64-linux-gnu/libssl.so.3 /usr/lib/x86_64-linux-gnu/libssl.so.3\nCOPY --from=build /usr/lib/x86_64-linux-gnu/libpcre2-8.so.0 /usr/lib/x86_64-linux-gnu/libpcre2-8.so.0\nCOPY --from=build /usr/lib/x86_64-linux-gnu/libcrypto.so.3 /usr/lib/x86_64-linux-gnu/libcrypto.so.3\n\n# 빌드 이미지로부터 필요한 이진 파일 및 디렉토리 복사\nCOPY --from=build /usr/sbin/nginx /usr/sbin/nginx\nCOPY --from=build /etc/nginx /etc/nginx\nCOPY --from=build --chown=nginx:nginx /var/cache/nginx /var/cache/nginx\nCOPY --from=build --chown=nginx:nginx /var/log/nginx /var/log/nginx\nCOPY --from=build --chown=nginx:nginx /usr/share/nginx/html /usr/share/nginx/html\n\nCOPY nginx.conf /etc/nginx/nginx.conf\nCOPY default.conf /etc/nginx/conf.d/\n\nENTRYPOINT [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"]\n```\n\nNginx 베이스 이미지의 취약점 카운트와 이미지 크기를 비교 분석하였습니다.\n\n이전에 사용한 nginx 알파인 베이스 이미지\n\n이전 취약성 통계 \"Total: 32 | Critical: 1 | High: 13 | Medium: 18\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Dockerona Diet Distroless Images for Security Speed 3](/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_3.png)\n\nUsing base distroless image crafted with nginx\n\nCurrent Vulnerability Stats: Total: 0 | Critical: 0 | High: 0 | Medium: 0\n\n![Dockerona Diet Distroless Images for Security Speed 4](/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기본 Nginx 이미지의 크기: 28MB [이미지 크기 30% 감소]\n\n# 주의 사항\n\nDistroless는 큰 장점을 제공하지만 몇 가지 주의할 점이 있습니다:\n\n- 쉘 액세스 없음: Distroless 이미지에는 디자인상 셸이 없습니다. 컨테이너 내에서 디버깅을 하려면 추가 도구나 멀티 스테이지 빌드가 필요할 수 있습니다.\n- 기능 제한: 패키지 관리자가 없기 때문에 애플리케이션이 필요로 하는 추가 라이브러리, 유틸리티 또는 인증서를 명시적으로 포함해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Distroless 또는 Alpine...어느 쪽을 선택해야 할까요?\n\nDistroless와 Alpine 이미지의 장단점을 이해하여, 귀하의 애플리케이션 요구사항과 개발 흐름에 가장 적합한 결정을 내릴 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_5.png)\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDistroless 이미지는 안전하고 효율적인 도커 컨테이너를 만드는 매력적인 옵션입니다. 미니멀리즘을 포용함으로써 더 작은 공격 표면, 빠른 배포 및 향상된 성능을 얻을 수 있습니다. 다음 번에 도커 이미지를 만들 때는 여분의 부담을 줄이고 Distroless 기본 이미지를 선택하는 것을 고려해보세요.\n","ogImage":{"url":"/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_0.png"},"coverImage":"/assets/img/2024-05-20-DockeronaDietDistrolessImagesforSecuritySpeed_0.png","tag":["Tech"],"readingTime":8},{"title":"스파크와 데이터브릭스에서 파티셔닝으로 성능 향상을 달성하세요 파트 13","description":"","date":"2024-05-20 17:02","slug":"2024-05-20-SuperchargingPerformancewithPartitioninginDatabricksandSparkPart13","content":"\n## 데이터 엔지니어가 파티셔닝을 이해해야 하는 이유!\n\nSpark 및 Databricks의 가장 중요한 기능 중 하나를 다루는 세 개의 기사 중 첫 번째 기사입니다: Partitioning에 대해 얘기할 것입니다.\n\n- 이 첫 장은 파티셔닝의 일반 이론과 Spark에서의 파티셔닝에 초점을 맞출 것입니다.\n- 제2부에서는 테이블 파티셔닝에 대한 구체적인 내용을 다루고 데이터셋을 준비할 것입니다.\n- 제3부에서는 철저한 사례 연구를 다루고 성능 비교를 수행할 것입니다.\n\n# 소개\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 관련해서 말씀드리면, \"빅데이터\" 개념은 종종 3V(또는 소스에 따라 가끔 더)로 정의됩니다: 양(volume), 다양성(variety), 그리고 속도(velocity).\n\n- 양은 데이터셋의 크기에 관련되며, 이는 테라바이트 이상까지 될 수 있습니다.\n- 다양성은 다양한 데이터 유형과 소스를 처리하는 과제를 의미하며, 효과적으로 종합되어야 합니다.\n- 반면에 속도는 데이터를 받아들이는 속도에 관한 것이며, 매초 100MB 파일이 수신된다면 금방 방대한 양의 데이터로 축적될 수 있습니다.\n\n\"빅데이터\"를 처리하는 높은 성능의 솔루션을 개발하기 위해서는 다양한 기법과 패턴을 사용할 수 있습니다. Partitioning이라는 한 가지 기법이 있습니다. 대용량 데이터셋을 다룰 때 개별 기계의 처리 능력이 한계에 도달할 수 있어, Databricks와 Spark 같은 도구를 통해 제공되는 분산 및 병렬 처리 기능을 사용해야 할 때가 있습니다.\n\nPartitioning은 이것이 가능하게 하는 핵심입니다. 대용량 데이터셋을 파티션이라는 더 작고 관리하기 쉬운 조각으로 나누는 것을 포함합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n딥레닉과 같은 분산 데이터 처리 시스템에서는 파티션을 사용하여 데이터를 여러 노드에 분산시켜 병렬 처리와 뛰어난 성능을 확보합니다.\n\n데이터를 파티션으로 나누면 각각을 독립적으로 처리할 수 있어 처리 시간을 단축하고 확장성을 향상시킬 수 있습니다.\n\n파티션화는 작업 부하를 균형있게 분산시키고 데이터 이동을 줄이며 데이터의 불균형이나 불균형의 영향을 최소화하는 데도 도움이 됩니다.\n\n반면에 비효율적인 파티셔닝은 성능 병목 현상, 자원 낭비 및 처리 시간 증가로 이어질 수 있습니다. 따라서 딥레닉과 같은 분산 데이터 처리 시스템에서 성능을 최적화하기 위해 올바른 파티셔닝 전략을 선택하는 것이 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Databricks와 Spark에서 파티셔닝 이해하기\n\n먼저, DataFrame / RDD 수준에서의 파티셔닝과 테이블 수준에서의 파티셔닝을 구분해야 합니다.\n\n## RDDs와 DataFrames\n\nDatabricks의 계산 엔진은 Spark입니다. Databricks에서 SQL, Scala, R 또는 Python을 사용하여 코드를 작성할 때, 우리는 단지 해당 API를 사용하여 내부 Spark 엔진에 액세스합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스파크는 기본 데이터 구조로 RDDs(탄력적 분산 데이터 집합)를 사용합니다. 그들의 이름에서 알 수 있듯이, RDDs는 분산 데이터 집합입니다. 요즘에는 RDDs와 직접 작업하는 것보다는 DataFrame API와 함께 작업하는 것이 인기가 없지만, DataFrame API는 이름을 붙일 수 있는 열을 제공하는 RDDs의 상위 수준 추상화인 DataFrame 객체를 제공합니다. 따라서 DataFrame은 전통적인 관계형 데이터베이스의 테이블과 유사합니다. 게다가, DataFrames는 많은 성능 최적화 옵션을 제공합니다.\n\n우리의 데이터를 이러한 DataFrame으로 로드할 때, 이미 파티션되어 있습니다. 이를 아래의 스크린샷에서 볼 수 있습니다. 만약 DataFrame의 기본 RDD에 액세스하면, .rdd.getNumPartitions()를 사용하여 파티션 수를 얻을 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-SuperchargingPerformancewithPartitioninginDatabricksandSparkPart13_0.png)\n\nRDDs 또는 DataFrames로 작업할 때, 스파크는 파티션 프로세스를 자동으로 처리해 줍니다. 심지어 우리가 명시적으로 지정하지 않았더라도요. 이미 파티션된 테이블에서 데이터를 가져올 때, 기존 파티션 구조가 고려된다는 점을 언급하는 것이 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n화면 캡처에서 보듯이 나는 파티션이 없는 테이블에서 데이터를 로드하고 있습니다. 이는 Spark가 아래에서 다룰 여러 구성에 기반하여 파티셔닝을 처리할 것을 의미합니다.\n\n또한 파티션과 파일을 구분해야 합니다. 왜냐하면 이 둘은 같은 것이 아니기 때문입니다. 파티션은 분산 컴퓨팅 환경에서 데이터의 논리적 분할을 의미합니다. 반면 파일은 실제로 디스크에 저장된 데이터의 저장 단위입니다.\n\n데이터를 섞는 일부 작업을 수행할 때, Spark는 \"spark.sql.shuffle.partitions\" 구성을 기반으로 데이터를 파티션으로 분할합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 이 같은 속성은 데이터를 간단히 읽을 때 파티션 수도 제어합니다. 디폴트로 200으로 설정되어 있어 Spark는 200개의 파티션을 생성합니다. 그러나 \"spark.sql.files.maxPartitionBytes\" 구성 설정도 이 프로세스에 한도를 두고 있습니다.\n\n각 파티션의 실제 저장 크기는 사용 가능한 메모리와 데이터셋의 크기와 같은 다양한 요인에 따라 달라집니다. 그러나 Databricks는 \"spark.sql.files.maxPartitionBytes\" 구성 속성에 의해 정의된 최대 크기로 파티션을 생성합니다. 기본값으로 이 값은 128MB로 설정되어 있습니다.\n\n이미지 링크:\n![이미지](/assets/img/2024-05-20-SuperchargingPerformancewithPartitioninginDatabricksandSparkPart13_2.png)\n\n데이터프레임 파티션의 크기를 제어하는 다른 방법은 .repartition() 또는 .coalesce() 메서드를 사용하여 DataFrame을 다시 파티션하고 파티션 수 또는 파티션화하려는 열을 지정하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- repartition()은 DataFrame 또는 RDD의 파티션 수를 증가 또는 감소시키는 데 사용됩니다. .repartition()을 사용하면 Spark가 데이터를 섞고 지정된 파티션 수에 기반하여 새로운 파티션을 생성합니다.\n- coalesce()는 DataFrame 또는 RDD의 파티션 수를 감소시키는 데 사용됩니다. .coalesce()를 사용하면 Spark가 기존 파티션을 결합하여 새로운 파티션을 생성하려고 합니다. repartition()과 달리, coalesce()는 데이터를 섞지 않습니다.\n\n# 요약\n\n파티셔닝은 성능이 우수한 \"빅 데이터\" 솔루션을 구축하는 데 필수적인 기술이며, 적절한 파티셔닝 전략을 선택하는 것은 좋은 성능과 확장성을 달성하는 데 중요합니다. 그러나 최적의 파티셔닝 설정을 조사할 리소스가 없는 경우, Databricks의 기본 최적화 설정과 옵션을 사용하는 것이 좋습니다.\n\n모든 테이블에 대한 보편적인 해결책은 없으며, 우선 순위와 목표를 균형 있게 유지해야 합니다. 각 시나리오는 요구 사항과 도전에 대응하기 위한 맞춤형 접근 방식이 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDataFrame / RDD 수준의 파티셔닝은 데이터를 병렬 처리를 위해 클러스터 노드에 분산하는 것을 다루고, 테이블 수준의 파티셔닝은 저장 시스템 내에서 데이터를 조직화하여 쿼리 성능을 최적화하는 데 초점을 맞춥니다.\n\n이제 파티셔닝의 중요성과 RDD 및 DataFrame이 어떻게 파티셔닝되는지 이해했으니, 다음 글에서는 Databricks의 테이블이 어떻게 파티션되는지 설명하고 최종 챕터를 위해 데이터를 준비할 것입니다.\n\n읽어주셔서 감사합니다!\n","ogImage":{"url":"/assets/img/2024-05-20-SuperchargingPerformancewithPartitioninginDatabricksandSparkPart13_0.png"},"coverImage":"/assets/img/2024-05-20-SuperchargingPerformancewithPartitioninginDatabricksandSparkPart13_0.png","tag":["Tech"],"readingTime":6},{"title":"Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기","description":"","date":"2024-05-20 17:01","slug":"2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory","content":"\n아래는 Markdown 형식으로 변경한 텍스트입니다.\n\n![이미지](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png)\n\n최근 몇 명의 고객이 Databricks 노트북 액티비티를 Azure Data Factory에서 실행할 때, 노트북을 실행할 작업 클러스터에 동적으로 태그를 설정하는 방법에 대해 물어봤어요.\n\n다행히도 Azure Data Factory의 매개변수와 동적 콘텐츠 기능 덕분에 해결책을 상당히 쉽게 찾을 수 있어요.\n\n# Prerequisites\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Azure Databricks 워크스페이스에 액세스 권한, Azure Data Factory 인스턴스, 그리고 워크스페이스에서 작업을 만들고 실행할 수 있는 능력이 있다고 가정합니다.\n\n# 링크드 서비스를 매개변수화하기\n\n- Azure Data Factory에서 새로운 Azure Databricks 링크드 서비스를 만듭니다.\n- 편집기의 매개변수 섹션에 동적으로 지정하고자 하는 각 태그 값에 대해 매개변수를 추가하세요. 이 예시에서는 CustomTag라는 매개변수를 추가하고 기본값을 설정했습니다.\n\n![이미지](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 클러스터 사용자 정의 태그 섹션에서 태그 이름을 추가하고 값 필드를 선택하세요. 텍스트 상자 아래에 동적 콘텐츠를 추가할 링크가 나타납니다. 이를 클릭해주세요:\n\n![Cluster custom tags](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_2.png)\n\n4. 'Pipeline Expression Builder' 패널이 열립니다. 하단에는 이전에 생성한 'ClusterTag' 매개변수가 파라미터 목록에 있을 겁니다. 이 매개변수를 클릭하여 파이프라인 표현식에 삽입하세요. 확인을 클릭해주세요.\n\n![ClusterTag parameter](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. 클러스터의 나머지를 보통대로 구성하세요.\n\n최종 연결된 서비스 구성은 다음과 같아야 합니다.\n\n![Linked Service Configuration](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_4.png)\n\n# 파라미터에 동적 값을 바인딩하세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 우리가 연결된 서비스에서 태그 값에 대한 매개변수를 갖고 있으므로 해당 연결된 서비스를 사용하는 각 활동에 대해 값을 바인딩할 수 있습니다.\n\n- 새로운 Databricks 노트북 활동을 만듭니다.\n- 활동 구성 패널에서 Azure Databricks 탭을 참고하면 Linked Service 속성에 우리가 만든 매개변수가 포함되어 있음을 알 수 있습니다:\n\n![Linked Service Properties](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_5.png)\n\n3. 여기에는 세 가지 옵션이 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이 속성값을 비워두면 클러스터는 태그의 값에 이전에 설정한 기본값을 사용합니다.\n- 이곳에 정적 값을 지정할 수 있으며, 이 값은 태그의 값으로 매개변수를 통해 전달됩니다.\n- 다시 동적 콘텐츠 옵션을 사용하여 이 매개변수에 대한 표현식을 제공할 수 있습니다. 전체 ADF 파이프라인으로 전달되는 매개변수, 파이프라인 자체의 이름, 파이프라인이 트리거된 날짜 또는 다른 활동의 출력값일 수 있습니다.\n\n이 튜토리얼에서는 여기에 정적 값만 할당하겠습니다:\n\n![image](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_6.png)\n\n참고로 만일 우리 파이프라인에 여러 활동이 있다면, 각 활동에 대해 이 속성에 고유한 값을 할당할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수동으로 이 파이프라인을 실행한 후에는 Azure Databricks의 작업 클러스터로 사용자 정의 동적 태그 값이 전파된 것을 볼 수 있습니다:\n\n![동적 태그 적용 예시](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_7.png)\n\n이 태그는 클러스터에서 사용되는 Azure VM에도 전파되어, Azure 포털의 Azure 비용 관리 도구에서 청구 및 감사 목적으로 사용할 수 있습니다.\n\n이제 Databricks 시스템 테이블에서 이 태그를 조회하여 클러스터와 관련 청구 사용 내역을 찾을 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식의 테이블입니다.\n\n| 파일 이름                                                                     | 경로                                                                                      |\n| ----------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |\n| 2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_8.png | /assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_8.png |\n| 2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_9.png | /assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_9.png |\n\n이 내용이 Databricks에서의 컴퓨팅 및 파이프라인의 가시성 관리에 도움이 되기를 바랍니다. 피드백은 언제나 환영합니다!\n","ogImage":{"url":"/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png"},"coverImage":"/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png","tag":["Tech"],"readingTime":6},{"title":"모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트","description":"","date":"2024-05-20 16:59","slug":"2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers","content":"\n## 모든 Pyspark 스크립트 작성을 수정하고, 시간을 절약한 상태로 현명하게 연습하세요.\n\n\"일을 맹목적으로 끝내는 것보다는 최적의 효율성과 효과적인 방법으로 실행하는 것이 중요합니다.\"\n\n여기 제공된 치트 시트는 PySpark의 주요 측면을 신속하게 검토하고, 인터뷰 준비 또는 Databricks나 Python 기반 코딩 환경과 같은 다양한 플랫폼에서 데이터 분석 작업에 대비할 수 있게 돕습니다.\n\n이 도구를 이용하면 PySpark 및 관련 프레임워크에 필수적인 중요한 변환 기술 및 데이터 분석 방법론을 신속하게 검토할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 시작해봅시다\n\nPySpark를 사용하여 변환 작업이나 데이터 분석 작업을 시작하기 전에 Spark 세션을 설정하는 것이 중요합니다. 이 초기 단계는 Spark 프레임워크 내에서 코드 실행의 기반을 제공합니다. 더 중요한 것은 후속 작업을 위한 기반을 구축하고 Spark 기능과 원활하게 상호 작용할 수 있도록 합니다.\n\n먼저 의도한 작업에 필요한 모듈을 가져와야 하며, 모든 중요한 구성 요소가 사용 가능하도록 보장해야 합니다. 이 기본 절차를 준수함으로써 개발자와 데이터 전문가는 PySpark의 강력한 기능을 활용하여 데이터 처리와 분석 작업을 원활하게 수행할 수 있습니다.\n\n## 시작해봅시다!!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import types\nfrom pyspark.sql.types import SparkType, StructField, StringType, IntegerType, DataType\nfrom pyspark.sql.functions import col, date, year, time, sum, avg, upper, count, Broadcast, expr\nfrom pyspark.sql import window\nfrom pyspark.sql import functions as F\n\nspark = SparkSession.builder.appName(\"application\").getOrCreate()\n\n# read any file as given either csv, excel, parquet, or Avro any format of data\n\ndata = spark.read.csv(\"filePath\", header=True, inferschema=True) # if we want given data types as it is\nschema = StructType([StructField(\"id\", IntegerType), StructField(\"name\", StringType),\nStructField(\"dept\", StringType)]) # if we want our required data types then we use this\n\n# also for better performance of executions we will be using our custom schema rather depending on inferschema\n\nLet’s kickstart our PySpark application by first creating a Spark Session, the entry point to PySpark functionality.\n\nWe’ll then proceed with performing various transformations and analyses on sample data.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n데이터 = [(1, 'mahi', 100), (2, 'mahendra', 200), (3, 'harish', 300), (4, 'desh', 400)]\n\n스키마 = ['id', 'name', 'salary']\n# 데이터 프레임 생성\ndf = spark.createDataFrame(data, schema)\ndf.head()\ndf.show()\ndisplay(df)\n```\n\n![image](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png)\n\nPySpark에서 윈도우 함수를 사용하여 급여의 누적 합을 계산할 수 있습니다.\n\n```js\na = Window().orderBy(\"id\");\n누적_합 = df.withColumn(\"cumulative_sum\", sum(\"salary\").over(a));\n결과 = cumulative_sum.orderBy(\"id\");\n결과.show();\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\na = Window().orderBy('id')\n누적합 = df.withColumn(\"누적합\", avg(\"salary\").over(a))\n결과 = 누적합.orderBy('id')\n결과.show()\n```\n\n![이미지](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_1.png)\n\n```python\nemp=[(1,'마히', 100,1),(2,'마헨드라', 200,2),(3,'하리쉬',300,3),\n(4,'데시',400,4)]\n\n스키마=['id', 'name', 'salary', 'dept_id']\n# 데이터 프레임 생성\ndf=spark.createDataFrame(data,schema)\ndf.head()\ndf.show()\ndisplay(df)\n\ndept=[(1,'인사'),(2,'영업'),(3,'데이터 분석'),(4,'IT')]\n스키마=['dept_id', 'department']\n부서=spark.createDataFrame(dept,schema)\ndisplay(부서)\n```\n\n![이미지](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n공통 속성인 dept_id를 사용하여 두 개의 데이터 프레임을 결합해 봅시다. 예시를 들어보겠습니다:\n\n```js\ndf = employee\n  .join(department, \"dept_id\", \"inner\")\n  .select(\"id\", \"name\", \"salary\", \"department\");\ndisplay(df);\n```\n\n```js\ndf = employee.join(department, \"dept_id\", \"right\").select(\"name\", \"department\");\ndisplay(df);\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_3.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서는 다양한 PySpark 변환, 액션 및 기능에 대해 상세히 설명하겠습니다. 실행 가능한 코드 예제와 함께 다룰 예정이에요.\n\n기본적인 변환인 필터링 및 그룹화부터 창 함수와 같은 고급 기술까지 다양한 작업을 다룰 거에요.\n\n각 코드 조각은 개념을 포괄적으로 이해할 수 있도록 설명하는 문장과 함께 제공됩니다.\n\n데이터 조작 작업부터 시작하여 PySpark 데이터 프레임을 사용하여 데이터 필터링, 선택 및 집계를 살펴보겠습니다. 그 후에는 조인, 정렬 및 창 함수와 같은 변환을 통해 다수의 테이블에서 데이터를 조작하고 분석하는 방법을 살펴볼 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, 우리는 샘플 데이터셋을 활용하여 모델 학습과 평가를 통해 머신러닝 작업을 지원하는 Pyspark을 소개할 것입니다.\n\n이 치트 시트를 통해 각 코드 스니펫은 해당 개념의 실제 시연을 제공하여 빠른 참고와 이해를 돕게 됩니다.\n\n이 예제를 따라가며 사용자들은 Pyspark 능력을 향상시키고 데이터 엔지니어링 및 데이터 과학 인터뷰나 실제 데이터 처리 작업에 대비할 수 있습니다.\n\n## 필터링, 선택, 집계, 그룹화 및 정렬 조건:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndf = orders.join(products, \"order_id\", \"inner\") # 어떤 조인 적용\ndf.join(df2, '공통 열').groupBy('표시할 열').count().orderBy(desc('count'))\n\n\ndf1=df.groupBy(\"cust_id\").agg(sum(\"amount\").alias(\"bill\")) # 그룹화 함수 적용 및 집계 조건을 지정\n\ndf.groupBy(\"col1\").agg(count(\"col2\").alias(\"count\"),\n                          sum(\"col2\").alias(\"sum\"),\n                          max(\"col2\").alias(\"maximum\"),\n                          min(\"col2\").alias(\"minimum\"),\n                          avg(\"col2\").alias(\"average\")).show()\n\n\ndf.drop(\"column_name1\", \"column_name2\", \"column_name3\") # 열 삭제\ndf.drop(col(\"column_name\")) # 다른 열 삭제 방법\n\ndf.createOrReplaceTempView(\"원하는 이름 지정\") # 데이터 프레임을 테이블로 변환\n\ndf.orderBy(F.desc(\"column_name\")).first() # 특정 열(예: 급여)의 내림차순 첫 번째 행 반환\ndf.orderBy(col(\"column_name\").desc()).first() # 가장 높은 값을 반환하는 또 다른 방법\ndf.orderBy(col(\"column_name\").desc()).limit(5) # 상위 5개의 값을 반환\n\n# 원하는 열에 필터 적용\ndf.filter(df.column_name==값).show()\n\n# 필터링된 결과와 함께 필요한 열 선택\ndf.select(\"column1\", \"column2\", \"column3\").where(col(\"any column\")==\"any value\")\ndf.select(\"column1\").where(col(\"column1\")\u003e 값).show(5)\ndf.sort(\"원하는 열 이름\")\n\n# 열 이름 변경\ndf.withcolumn Renamed(\"기존 열 이름\", \"원하는 열 이름으로 변경\")\n```\n\nPySpark는 데이터 프레임 내에서 날짜 속성을 추출하고 조작하는 편리한 방법을 제공하며, 사용자가 연도, 월, 일과 같은 다양한 기준으로 통찰력을 얻을 수 있도록 합니다.\n\n또한, 이러한 속성들은 오름차순이나 내림차순으로 정렬하여 분석과 시각화를 용이하게 할 수 있습니다.\n\n## 날짜 열에서 일, 월, 연도 추출하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데이터 프레임에서 연도, 월, 일 세부 정보 추출하기\n\ndf.select(year(\"date column\").distinct().orderBy(year(\"date column\")).show()\ndf.select(month(\"date column\").distinct().orderBy(month(\"date column\")).show()\ndf.select(day(\"date column\").distinct().orderBy(day(\"date column\")).show()\n\ndf.withColumn(\"orderyear\", year(\"df.date column\"))\ndf.withColumn(\"ordermonth\", month(\"df.date column\"))\ndf.withColumn(\"orderday\", day(\"df.date column\"))\ndf.withColumn(\"orderquarter\", quarter(\"df.date column\"))\n\n특정 열에서 null 값을 필터링하고 그 다음에 지정된 순서로 그룹화 작업을 수행하기 위해 조건을 적용할 수 있습니다.\n\ndf.select(\"column name we want to retrieve\").where(col(\"column name we want to retrieve\").isNotNull())\\\n.groupBy(\"column name we want to retrieve\").count().orderBy(\"count\", ascending=False).show(10)\n\n## 함수 작성하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndf.write.format(\"CSV\").mode(\"overwrite\").save(\"원하는 파일 저장 경로\");\ndf.write.format(\"CSV\").mode(\"append\").save(\"원하는 파일 저장 경로\");\ndf.write.format(\"Parquet\").mode(\"overwrite\").save(\"원하는 파일 저장 경로\");\ndf.write.format(\"parquet\").mode(\"append\").save(\"원하는 파일 저장 경로\");\n```\n\n## 윈도우 함수:\n\n```js\nwind_a=Window.partitionBy(\"col1\").orderBy(\"col2\").rangeBetween(Window.unboundedpreceeding, 0)\n\ndf_w_coloumn= df.withColumn(\"col_sum\", F.sum(\"salary\").over(wind_a) #롤링 합계 또는 누적 합계:\n\n\n#행 번호\na=Window.orderBy(\"date_column\") #예시로 날짜 열을 고려하였지만 원하는 열을 선택할 수 있습니다\nsales_data=df.withColumn(\"row_number\", row_number().over(a))\n\n#순위\nb=Window.partitionBy(\"date\").orderBy(\"sales\")\nsales_data=df.withColumn(\"sales_rank\", rank() over(b))\n\n#조밀한 순위\nb=Window.partitionBy(\"date\").orderBy(\"sales\")\nsales_data=df.withColumn(\"sales_dense_rank\", desne_rank() over(b))\n\n\n#지연\nc=Window.partitionBy(\"Item\").orderBy(\"date\") #예시 열을 고려하여 원하는 열을 선택할 수 있습니다\nsales_data=df.withColumn(\"pre_sales\", lag(col(\"sales\"),1).over(c))\n\n\n#리드\nd=Window.partitionBy(\"Item\").orderBy(\"date\") #예시 열을 고려하여 원하는 열을 선택할 수 있습니다\nsales_data=df.withColumn(\"next_sales\", lead(col(\"sales\"),1).over(d))\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사는 데이터 엔지니어링 면접에 대비하는 개인들에게 가치 있는 도구로 작용하며, Databricks 플랫폼을 위해 구체적으로 맞춘 PySpark 함수와 수식들에 대한 간결하면서 포괄적인 요람을 제공합니다.\n\n구조화된 레이아웃과 각 예제와 함께 제공되는 자세한 설명으로, 본 자료는 독자들이 10분만 투자하여 주요 개념들을 효율적으로 검토하고 숙지할 수 있도록 도와줍니다.\n\n이러한 기본 기능들을 숙달함으로써 희망하는 데이터 엔지니어들은 자신감을 키우고 다양한 면접 상황을 쉽게 해결할 수 있는 준비를 갖추게 되며, 이를 통해 더욱 흥미로운 데이터 엔지니어링 직무를 얻을 성공 기회를 극대화할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래에서 데이터 엔지니어 인터뷰를 준비하는 데 도움이 되는 몇 가지 더 많은 기사를 찾을 수 있습니다.\n\n- SQL 사용 사례 - 데이터 엔지니어 인터뷰\n- 데이터 엔지니어 인터뷰에서 가장 일반적으로 묻는 빅데이터(Apache Spark) 개념\n- 데이터 엔지니어 인터뷰를 위한 Python 코딩 문제 제1부 (쉬운 난이도)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제 소중한 내용을 더 많이 공유할 수 있도록 함성 소리로 응원해주신다면 감사하겠습니다.\n\n저를 팔로우하고 구독하여 제 소식을 즉시 받아보세요.\n\n감사합니다 :)\n","ogImage":{"url":"/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png"},"coverImage":"/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png","tag":["Tech"],"readingTime":12},{"title":"데이터브릭스 리퀴드 클러스터링","description":"","date":"2024-05-20 16:57","slug":"2024-05-20-DatabricksLiquidClustering","content":"\n이전에 데이터 레이크하우스 세계에서 데이터 분할의 끊임없는 도전에 대한 동적 해결책이 있는지 궁금했나요?\n\n음, 저는 궁금했어요! 그럼 함께 이야기해보죠.\n\n## 고정된 데이터 레이아웃의 도전\n\n다음 그래프를 살펴보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![DatabricksLiquidClustering](/assets/img/2024-05-20-DatabricksLiquidClustering_0.png)\n\n이 그래프는 연도별 테이블 행 수를 예측하고 데이터 분포에서 상당한 치우침을 보여줍니다. 이 치우침은 소비자가 쿼리에서 연도 열을 자주 필터로 사용하기 때문에 특히 관련이 있습니다.\n\n이 테이블은 생성 시 year 및 month 열을 사용하여 파티션으로 설정되었습니다. 이것이 바로이 테이블을 위한 DDL의 형태입니다.\n\n```js\n%sql\nCREATE TABLE kaggle_partitioned (\n  year_month STRING,\n  exp_imp TINYINT,\n  hs9 SMALLINT,\n  Customs SMALLINT,\n  Country BIGINT,\n  quantity BIGINT,\n  value BIGINT,\n  year STRING,\n  month STRING\n) USING delta PARTITIONED BY (year, month);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기 문제가 있어요. 테이블의 전체 데이터 중 약 83%가 2개의 파티션에 있습니다.\n\n![이미지](/assets/img/2024-05-20-DatabricksLiquidClustering_1.png)\n\n위의 정보를 바탕으로 테이블이 너무 적게 파티셔닝되었는지, 아니면 너무 많이 파티셔닝되었는지 어떻게 생각하시나요?\n\n이 테이블의 데이터 분포를 더 깊게 살펴보겠습니다. 다음 차트는 연간 행 수의 월별 분할을 보여줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![데이터 분포의 그림적 표현](/assets/img/2024-05-20-DatabricksLiquidClustering_2.png)\n\n더 자세히 데이터 분포를 나타낸 그림을 살펴보면, 2020년 3월에 가장 많은 데이터가 있고, 그 뒤를 이어서 1월과 2월이, 다른 달들은 더 작은 파티션으로 이어지고 있습니다.\n\n그래서, 테이블이 과분할되었는지? 아니면 과소분할되었는지? 아니면 둘 다인가요?\n\n다음 그림이 어떤 연관성이 있나요? 무슨 의미를 전달하나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-DatabricksLiquidClustering_3.png\" /\u003e\n\n현재 파티셔닝 전략대로,\n\n- 2020–03과 같은 파티션의 경우, 한 시간치 데이터를 쿼리하기 위해 많은 양의 데이터를 읽어야 할 지도 모릅니다.\n- 반면에 다른 극단적인 상황에서는, 적은 양의 데이터를 가진 고객을 위한 쿼리를 수행하기 위해 여러 파티션을 가로질러 많은 작은 파일을 스캔해야 할 수도 있습니다.\n- 마지막으로, 테이블을 주/일/월 단위로 다시 파티셔닝해야 할 경우, 전체 테이블을 다시 작성해야 합니다. 또 다시요!\n\n이제 우리 테이블에서 데이터 쓰기 시나리오를 논의해 봅시다. 제 생각에는 이미지가 제 의견을 요약해 주고 있으므로 글로 다시 작성할 필요는 없을 것 같아요 ;)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-DatabricksLiquidClustering_4.png\" /\u003e\n\n지금! 이 기사의 맨 첫 줄을 한 번 더 반복합시다!\n\n데이터 레이크하우스 세계에서 데이터 파티셔닝의 끊임없는 도전에 대한 동적 솔루션이 있는지 궁금했던 적이 있나요?\n\n리퀴드 클러스터링이 등장했습니다! 데이터 레이아웃 결정을 간소화하고 쿼리 성능을 향상시키며, 지속적인 모니터링 및 조정을 요구하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서 어떻게 하는 건가요?\n\n- 빠름: 튜닝된 분할 테이블과 유사한 쓰기 및 읽기 속도\n- 자체 튜닝: 과다 및 부족한 분할을 피함\n- 점진적: 새 데이터의 자동 부분 클러스터링\n- 스쿠 내성: 일관된 파일 크기와 낮은 쓰기 증폭\n- 유연함: 클러스터링 열을 변경하고 싶나요? 문제 없어요!\n- 더 나은 병행성: 테이블에서 행 수준의 병행성 활성화\n\n좀 더 자세히 이해해 보겠습니다. 이전에 보여드린 샘플 레이아웃 다이어그램을 사용할 거예요.\n\n![다이어그램](/assets/img/2024-05-20-DatabricksLiquidClustering_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요렇게 Liquid Clustering이 어떻게 도와주는지 확인해보세요! Liquid Clustering은 군집화와 파일 크기의 효율적인 균형을 이룹니다.\n\n![Liquid Clustering](/assets/img/2024-05-20-DatabricksLiquidClustering_6.png)\n\n작은 파티션을 자동으로 처리할 뿐만 아니라, 큰 파티션에서 시간별 데이터만 가져오려면 더 효율적인 쿼리를 위해 더 나눌 수 있습니다.\n\n![Liquid Clustering](/assets/img/2024-05-20-DatabricksLiquidClustering_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n실제로 보여드릴게요! 여기 파티션된 테이블의 파일 크기 분포입니다.\n\n![이미지](/assets/img/2024-05-20-DatabricksLiquidClustering_8.png)\n\n이 파티션된 테이블에서 클러스터된 테이블을 생성해보겠습니다. CTAS를 사용할 거에요.\n\n```js\nCREATE TABLE kaggle_clustered CLUSTER BY(year, month) AS\nSELECT\n  *\nFROM\n  kaggle_partitioned;\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 군집 테이블의 파일 크기 분포도가 여기 있어요.\n\n![file size distribution](/assets/img/2024-05-20-DatabricksLiquidClustering_9.png)\n\n작은 파일 대부분이 통합되어 더 최적화된 파일이 생성된 것이 명백하게 나타나네요.\n\n액체 클러스터링은 일부/게으른 클러스터링을 활용하여 효율적으로 적재를 돕습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그걸 어떻게 이해하는지 알아봅시다.\n\n- 2021-01은 제가 파티션 테이블에 데이터가 없는 파티션입니다.\n- 해당 날짜 범위의 데이터를 적재하기 시작하면, 모든 고객을 포함하는 파일이 생성됩니다.\n- 데이터 집합이 증가함에 따라, Liquid Clustering은 고객을 위한 파일을 분할하기 시작합니다.\n- 분할 작업은 가끔 작은 파일로 나누어지지만, 테이블 유지 관리는 이 작은 파일을 자동으로 큰 파일로 병합하여 읽기 성능에 영향을 미치지 않도록 합니다.\n\n# 그래서! 테이블에서 어떻게 사용하나요?\n\n첫 번째로! 클러스터링은 파티셔닝이나 ZORDER와 호환되지 않으며, Databricks 클라이언트가 테이블의 데이터에 대한 모든 레이아웃 및 최적화 작업을 관리해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 리퀴드 클러스터링을 사용하여 델타 테이블을 생성하는 방법을 살펴보겠습니다.\n\n```js\n--빈 테이블 생성하기\nCREATE TABLE table1(col0 int, col1 string) USING DELTA CLUSTER BY (col0);\n\n\n--CTAS 문 사용하기\nCREATE EXTERNAL TABLE table2 CLUSTER BY (col0) --테이블 이름 뒤에 클러스터링을 지정하고, 서브쿼리에는 사용하지 않기\nLOCATION 'table_location' AS\nSELECT\n  *\nFROM\n  table1;\n\n\n--구성 복사를 위해 LIKE 문 사용하기\nCREATE TABLE table3 LIKE table1;\n```\n\n# 클러스터링을 트리거하는 방법\n\n간단히 테이블에 OPTIMIZE 명령을 사용하면 됩니다. 아래 예시를 참고하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n테이블 이름을 최적화하세요;\n```\n\n리퀴드 클러스터링은 증분 방식으로 작동합니다. 따라서 클러스터링해야 하는 데이터를 수용하기 위해서만 데이터가 다시 작성됩니다. 클러스터링 키를 갖는 데이터 파일이 클러스터링해야 하는 데이터와 일치하지 않는 경우 재작성되지 않습니다.\n\n데이터를 클러스터링하고 최상의 성능을 얻기 위해 정기적으로 최적화 작업을 실행해야 합니다. 리퀴드 클러스터링은 증분 방식이므로 대부분의 클러스터링된 테이블의 최적화 작업이 빠르게 실행됩니다.\n\n# 리퀴드 클러스터링은 무엇에 사용되나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDatabricks 문서에 따르면, 모든 새로운 Delta 테이블에는 리퀴드 클러스터링을 사용하는 것이 권장됩니다. 클러스터링이 유용한 시나리오의 예시는 다음과 같습니다:\n\n- 높은 카디널리티 열을 기반으로 자주 필터링되는 테이블.\n- 데이터 분포에서 상당한 불균형이 있는 테이블.\n- 빠르게 성장하여 유지보수와 조정 노력이 필요한 테이블.\n- 동시에 쓰기 요구사항이 있는 테이블.\n- 시간이 지남에 따라 액세스 패턴이 변경되는 테이블.\n- 전형적인 파티션 키가 테이블에 너무 많거나 너무 적은 파티션을 남길 수 있는 테이블.\n\n## 리퀴드 클러스터링 사용 시 고려해야 할 사항\n\n- 클러스터링 키로 수집된 통계가 있는 열만 지정할 수 있습니다. 기본적으로 Delta 테이블의 처음 32열에는 통계가 수집됩니다.\n- 최대 4개의 열을 클러스터링 키로 지정할 수 있습니다.\n- 구조화된 스트리밍 워크로드는 라이트 시 클러스터링을 지원하지 않습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-DatabricksLiquidClustering_0.png"},"coverImage":"/assets/img/2024-05-20-DatabricksLiquidClustering_0.png","tag":["Tech"],"readingTime":9}],"page":"83","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"83"},"buildId":"T_Nz0g9U1yttYMSEma95P","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>