<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/32" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/32" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_buildManifest.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="쿠버네티스 x509 인증서가 만료되었거나 아직 유효하지 않음 오류" href="/post/2024-06-19-Kubernetesx509certificatehasexpiredorisnotyetvaliderror"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="쿠버네티스 x509 인증서가 만료되었거나 아직 유효하지 않음 오류" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-Kubernetesx509certificatehasexpiredorisnotyetvaliderror_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="쿠버네티스 x509 인증서가 만료되었거나 아직 유효하지 않음 오류" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">쿠버네티스 x509 인증서가 만료되었거나 아직 유효하지 않음 오류</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="DNS 성능을 모니터링하기 위해 알아야 할 모든 것" href="/post/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="DNS 성능을 모니터링하기 위해 알아야 할 모든 것" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="DNS 성능을 모니터링하기 위해 알아야 할 모든 것" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">DNS 성능을 모니터링하기 위해 알아야 할 모든 것</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">19<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Kubernetes 보안 마스터하기 - 내 Admission Controllers 여행" href="/post/2024-06-19-MasteringKubernetesSecurityMyJourneyWithAdmissionControllers"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Kubernetes 보안 마스터하기 - 내 Admission Controllers 여행" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-MasteringKubernetesSecurityMyJourneyWithAdmissionControllers_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Kubernetes 보안 마스터하기 - 내 Admission Controllers 여행" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Kubernetes 보안 마스터하기 - 내 Admission Controllers 여행</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="온프레미스 쿠버네티스 대 관리형 쿠버네티스" href="/post/2024-06-19-On-PremisesKubernetesVsManagedKubernetes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="온프레미스 쿠버네티스 대 관리형 쿠버네티스" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-On-PremisesKubernetesVsManagedKubernetes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="온프레미스 쿠버네티스 대 관리형 쿠버네티스" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">온프레미스 쿠버네티스 대 관리형 쿠버네티스</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="어렵게 배운 교훈 Cilium의 기본 Pod CIDR을 사용하지 마세요" href="/post/2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="어렵게 배운 교훈 Cilium의 기본 Pod CIDR을 사용하지 마세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="어렵게 배운 교훈 Cilium의 기본 Pod CIDR을 사용하지 마세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">어렵게 배운 교훈 Cilium의 기본 Pod CIDR을 사용하지 마세요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="나의 쿠버네티스 클러스터에 MongoDB No-SQL 데이터베이스를 추가한 경험" href="/post/2024-06-19-MyexperienceaddingaMongoDBNo-SQLdatabasetomyKubernetescluster"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="나의 쿠버네티스 클러스터에 MongoDB No-SQL 데이터베이스를 추가한 경험" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-MyexperienceaddingaMongoDBNo-SQLdatabasetomyKubernetescluster_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="나의 쿠버네티스 클러스터에 MongoDB No-SQL 데이터베이스를 추가한 경험" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">나의 쿠버네티스 클러스터에 MongoDB No-SQL 데이터베이스를 추가한 경험</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">29<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Argo CD v212 릴리스 후보판" href="/post/2024-06-19-ArgoCDv212ReleaseCandidate"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Argo CD v212 릴리스 후보판" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ArgoCDv212ReleaseCandidate_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Argo CD v212 릴리스 후보판" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Argo CD v212 릴리스 후보판</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커에서 자체 서명 인증서를 사용한 NGINX" href="/post/2024-06-19-NGINXwithSelf-SignedCertificateonDocker"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커에서 자체 서명 인증서를 사용한 NGINX" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커에서 자체 서명 인증서를 사용한 NGINX" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">도커에서 자체 서명 인증서를 사용한 NGINX</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="편리한 클라우드 배포 Terraform과 GitHub Actions를 활용하여 AWS에서 NET API와 Angular 프론트엔드를 런칭하기 PART 23" href="/post/2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="편리한 클라우드 배포 Terraform과 GitHub Actions를 활용하여 AWS에서 NET API와 Angular 프론트엔드를 런칭하기 PART 23" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="편리한 클라우드 배포 Terraform과 GitHub Actions를 활용하여 AWS에서 NET API와 Angular 프론트엔드를 런칭하기 PART 23" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">편리한 클라우드 배포 Terraform과 GitHub Actions를 활용하여 AWS에서 NET API와 Angular 프론트엔드를 런칭하기 PART 23</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">21<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Ollama - Langchain을 사용해 챗봇 만들기, 도커로 배포하기" href="/post/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Ollama - Langchain을 사용해 챗봇 만들기, 도커로 배포하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Ollama - Langchain을 사용해 챗봇 만들기, 도커로 배포하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Ollama - Langchain을 사용해 챗봇 만들기, 도커로 배포하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link posts_-active__YVJEi" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"쿠버네티스 x509 인증서가 만료되었거나 아직 유효하지 않음 오류","description":"","date":"2024-06-19 13:09","slug":"2024-06-19-Kubernetesx509certificatehasexpiredorisnotyetvaliderror","content":"\n\u003cimg src=\"/assets/img/2024-06-19-Kubernetesx509certificatehasexpiredorisnotyetvaliderror_0.png\" /\u003e\n\n만약 잘 작동되던 쿠버네티스 환경에서 갑자기 \"x509: certificate has expired or is not yet valid\" 오류가 발생한다면 어떻게 하시겠어요?\n\n오늘 나에게 일어난 것과 똑같이요. 저도 이 오류를 경험했어요. 왜 나타나는지도 모르는데, 뭔가 조치를 취하지 않은 상태에서 발생한 문제였죠!\n\n저는 인증서 만료 문제라고 알고 있었지만, 문제를 어떻게 해결할지 알려고 많은 시간을 보냈어요. 그래서 이 주제에 대해 짧은 기사를 써서 이런 문제를 겪는 다른 분들에게 도움이 되길 바라는 마음으로 준비했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nKubernetes 문서에 따르면 kubeadm으로 생성된 클라이언트 인증서는 1년 후에 만료됩니다.\n\n그래서 제가 먼저 한 일은:\n\n- 인증서 세부 정보 확인하기\n\n```js\nkubeadm certs check-expiration\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 그런 다음 모든 인증서를 갱신했어요\n\n```js\nkubeadm certs renew all\n```\n\n3. 마지막으로 kubelet을 다시 시작했어요\n\n```js\nsudo systemctl restart kubelet\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만, 아무것도 바뀌지 않았네요! 계속해서 같은 오류가 발생하고 있습니다.\n\n여기서 뭔가 빠진 게 있는 것 같아요.\n\n이 문제를 조사하는 데 시간을 많이 쏟았는데, ~/.kube/config 파일을 살펴보던 중 예전 클라이언트 인증서 항목을 사용하고 있다는 것을 깨달았어요.\n\n그리고 kubeadm으로 클러스터를 구축할 때 /etc/kubernetes/admin.conf을 /.kube/config 파일로 복사해야 했다는 것을 기억했네요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인증서를 갱신하면 /etc/kubernetes/admin.conf 파일이 업데이트되므로, 당연히 내 /.kube/config 파일도 그에 맞게 업데이트해야 했어요.\n\n다음 명령어를 실행하여 문제를 해결했어요.\n\n```js\nsudo cp -i /etc/kubernetes/admin.conf ~/.kube/config\nsudo chown $(id -u):$(id -g) ~/.kube/config\n```\n\n쿠버네티스 문서에 따르면:\n","ogImage":{"url":"/assets/img/2024-06-19-Kubernetesx509certificatehasexpiredorisnotyetvaliderror_0.png"},"coverImage":"/assets/img/2024-06-19-Kubernetesx509certificatehasexpiredorisnotyetvaliderror_0.png","tag":["Tech"],"readingTime":3},{"title":"DNS 성능을 모니터링하기 위해 알아야 할 모든 것","description":"","date":"2024-06-19 13:07","slug":"2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance","content":"\n![CoreDNS Monitoring](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png)\n\n# 📚 소개:\n\nDNS 집중 워크로드를 실행할 때 종종 DNS 쓰로틀링에 의한 간헐적인 CoreDNS 실패가 발생할 수 있습니다. 이러한 문제는 애플리케이션에 중대한 영향을 미칠 수 있습니다.\n\n이러한 중단은 서비스의 신뢰성과 성능에 영향을 미칠 수 있으므로 모니터링 솔루션이 필수적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS는 모니터링 목적으로 통합할 수 있는 오픈 소스 도구인 CloudWatch, Fluentd 및 Grafana를 제공합니다. 이 도구들은 CoreDNS를 모니터링하는 데 사용할 수 있습니다.\n\n# Kubernetes DNS 소개:\n\nKubernetes는 클러스터 내에서 서비스 검색에 DNS를 의존합니다. 팟에서 실행되는 응용 프로그램이 서로 통신해야 할 때, 그들은 주로 IP 주소가 아닌 도메인 이름을 사용하여 서비스를 참조합니다.\n\n이 때 Kubernetes DNS가 필요합니다. 이는 도메인 이름이 올바른 IP 주소로 해석되도록 보장하여 팟과 서비스가 통신할 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nKubernetes에서는 각 파드마다 일시적인 IP 주소가 할당됩니다. 그러나 이러한 IP 주소는 동적이며 시간이 지남에 따라 변경될 수 있어, 애플리케이션이 이를 추적하기 어렵습니다.\n\nKubernetes는 이러한 도전에 대응하기 위해 파드와 서비스에 완전히 정규화된 도메인 이름(FQDNs)을 할당합니다.\n\nKubernetes의 기본 DNS 제공자인 CoreDNS는 클러스터 내에서 DNS 쿼리를 처리하는 역할을 담당합니다. 그는 이러한 FQDN을 해당 IP 주소로 매핑하여 파드와 서비스 간의 통신을 가능하게 합니다.\n\n# 왜 DNS 문제가 흔할까요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n네트워크 문제 해결 중 공통적으로 발생하는 번거로움의 원인 중 하나인 DNS 문제! DNS는 사람이 읽기 쉬운 도메인 이름을 기계가 이해할 수 있는 IP 주소로 변환하는 데 큰 역할을 합니다.\n\n그러나 DNS 문제는 설정 오류, 네트워크 문제 또는 서버 장애와 같은 여러 요인으로 발생할 수 있습니다. 도메인 이름을 올바르게 해석하지 못할 때 애플리케이션이 외부 서비스에 연결 문제를 경험하거나 액세스에 실패할 수 있습니다.\n\n# 쿠버네티스의 CoreDNS:\n\nCoreDNS는 쿠버네티스 클러스터 내에서 DNS 서비스를 제공하는 데 중요한 역할을 합니다. Kubernetes v1.13 이후 기본 DNS 제공자로 사용되어 온 CoreDNS는 DNS 이름 대신 IP 주소 대신 DNS 이름을 사용하여 클라이언트가 서비스에 액세스할 수 있도록 함으로써 클러스터 네트워킹을 간소화합니다. 그는 도메인 이름 요청을 해결하고 클러스터 내에서 서비스 검색을 용이하게 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 코어디엔에스의 작동 방식:\n\n코어디엔에스는 쿠버네티스 클러스터 내에서 DNS 요청의 리졸버 및 포워더로 작동합니다. 파드가 다른 서비스와 통신해야 할 때, 대상 서비스의 도메인 이름을 지정하여 DNS 쿼리를 코어디엔에스에 보냅니다. 그럼 코어디엔에스는 내부 레코드를 사용하여 도메인 이름을 해당 IP 주소로 매핑하여 이 쿼리를 해결합니다.\n\n코어디엔에스가 권한이 없는 외부 도메인 이름에 대해서는, 이를 공개 리졸버나 상위 DNS 서버로 전달하여 해결합니다.\n\n성능을 향상시키고 대기 시간을 줄이기 위해 코어디엔에스는 자주 액세스하는 도메인 이름에 대한 DNS 응답을 캐시할 수 있습니다. 이 캐싱 메커니즘은 DNS 쿼리의 응답 속도를 향상시키고 상위 DNS 서버의 부하를 줄입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCoreDNS는 이 기능을 모듈식 아키텍처와 확장 가능한 플러그인 시스템을 통해 구현하며, 운영자가 독자적인 요구 사항에 따라 DNS 해상도를 사용자 정의하고 최적화할 수 있게 합니다.\n\n# Amazon EKS에서의 CoreDNS 쓰로틀링 완화 방법:\n\nAmazon EKS 클러스터에서 CoreDNS와 DNS 쓰로틀링 문제는 식별하고 해결하기 어려울 수 있습니다. 많은 사용자가 CoreDNS 로그와 메트릭을 모니터링하는 데 주력하지만, 엘라스틱 네트워크 인터페이스(ENI) 수준에서 강제되는 초당 1024개 패킷(PPS)의 하드 제한을 자주 간과합니다. 이 한계가 쓰로틀링 문제로 이어질 수 있는 방식을 이해하려면 Kubernetes 파드의 전형적인 DNS 해상도 흐름에 대한 통찰력이 필요합니다.\n\nKubernetes 환경에서는 파드가 통신을 가능하게 하기 위해 내부 및 외부 서비스의 도메인 이름을 해상해야 합니다. 이 해상도 프로세스는 DNS 쿼리를 워커 노드의 ENI를 통해 라우팅하는 것을 포함하며, 특히 외부 엔드포인트를 해상하는 경우입니다. 내부 엔드포인트의 경우에도 쿼리하는 파드와 동일한 위치에 CoreDNS 파드가 없으면 DNS 패킷이 여전히 워커 노드의 ENI를 통해 이동합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n갑자기 DNS 쿼리가 급증하여 PPS가 하드 제한값 1024에 접근하는 상황이 발생할 수 있습니다. 이러한 상황은 DNS 쓰로틀링을 유발할 수 있으며, 이로 인해 영향을 받는 작업 노드에서 실행 중인 모든 마이크로서비스에 영향을 미칠 수 있습니다. 유감스럽게도, 이러한 문제 해결은 주로 CoreDNS pod에 초점을 맞추는 ENI 메트릭보다 어려울 수 있습니다.\n\nEKS 클러스터에서 DNS 쓰로틀링 문제를 완화하기 위해서는 ENI 수준에서 발생하는 패킷 손실을 지속적으로 모니터링하는 것이 중요합니다. 이 모니터링을 통해 잠재적인 중단을 조기에 감지하고 예방할 수 있습니다. 이 블로그 포스트에서는 네트워크 성능 메트릭을 활용하여 DNS 쓰로틀링 문제를 효과적으로 식별하는 솔루션을 소개합니다.\n\n## 해결책: 🎉\n\n작업 노드에서 DNS 쓰로틀링 문제를 식별하는 간단한 방법은 Elastic Network Adapter (ENA) 드라이버에서 제공하는 linklocal_allowance_exceeded 메트릭 및 다른 메트릭을 캡처하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n`linklocal_allowance_exceeded`은 로컬 프록시 서비스로의 트래픽 PPS가 네트워크 인터페이스의 최대를 초과하여 드롭된 패킷 수입니다. 이는 DNS 서비스, 인스턴스 메타데이터 서비스 및 Amazon 시간 동기화 서비스로의 트래픽에 영향을 줍니다.\n\n이 이벤트를 실시간으로 추적하는 대신, 우리는 이 메트릭을 Amazon Managed Service for Prometheus로 스트리밍하고 Amazon Managed Grafana에서 시각화할 수도 있습니다.\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_1.png)\n\n# 실전: AWS EKS에서 CoreDNS 메트릭 수집 및 시각화:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCoreDNS 프로메테우스 플러그인은 OpenMetrics 형식으로 메트릭을 노출하며, 이는 프로메테우스 형식에서 발전한 텍스트 기반 표준입니다. Kubernetes 클러스터에서는 플러그인이 기본적으로 활성화되어 있어 클러스터를 시작하는 즉시 많은 중요한 메트릭을 모니터링할 수 있습니다.\n\n기본 설정에서 프로메테우스 플러그인은 각 CoreDNS 팟의 포트 9153에 있는 /metrics 엔드포인트에 메트릭을 기록합니다.\n\nAmazon Managed Service for Prometheus 워크스페이스와 Managed Service for Grafana를 생성하세요:\n\n이 단계에서는 Amazon Managed Service for Prometheus 및 Managed Service for Grafana를 위한 워크스페이스를 생성합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 파일 구성은 다음을 생성합니다:\n\n- AMP 작업 공간\n- AMP 경보 관리자 정의.\n\nmain.tf:\n\n```js\nmodule \"prometheus\" {\n  source = \"terraform-aws-modules/managed-service-prometheus/aws\"\n\n  workspace_alias = \"demo-coredns\"\n\n  alert_manager_definition = \u003c\u003c-EOT\n  alertmanager_config: |\n    route:\n      receiver: 'default'\n    receivers:\n      - name: 'default'\n  EOT\n\n  rule_group_namespaces = {}\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nversions.tf:\n\n```js\nterraform {\n  required_version = \"\u003e= 1.3\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"\u003e= 5.32\"\n    }\n  }\n}\n```\n\n테라폼을 실행하려면 다음을 실행해야 합니다:\n\n```js\n$ terraform init\n$ terraform plan\n$ terraform apply\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 구성 파일은 다음과 같은 것을 생성합니다:\n\n- 기본 Grafana 작업 공간 (모듈에서 제공하는 기본값 사용)\n\nmain.tf:\n\n```js\nprovider \"aws\" {\n  region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n  region      = \"eu-west-1\"\n  name        = \"amg-ex-${replace(basename(path.cwd), \"_\", \"-\")}\"\n  description = \"AWS Managed Grafana service for ${local.name}\"\n\n  vpc_cidr = \"10.0.0.0/16\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n}\n\n################################################################################\n# Managed Grafana Module\n################################################################################\n\nmodule \"managed_grafana\" {\n  source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n  # Workspace\n  name                      = local.name\n  associate_license         = false\n  description               = local.description\n  account_access_type       = \"CURRENT_ACCOUNT\"\n  authentication_providers  = [\"AWS_SSO\"]\n  permission_type           = \"SERVICE_MANAGED\"\n  data_sources              = [\"CLOUDWATCH\", \"PROMETHEUS\", \"XRAY\"]\n  notification_destinations = [\"SNS\"]\n  stack_set_name            = local.name\n  grafana_version           = \"9.4\"\n\n  configuration = jsonencode({\n    unifiedAlerting = {\n      enabled = true\n    },\n    plugins = {\n      pluginAdminEnabled = false\n    }\n  })\n\n  # vpc configuration\n  vpc_configuration = {\n    subnet_ids = module.vpc.private_subnets\n  }\n  security_group_rules = {\n    egress_postgresql = {\n      description = \"Allow egress to PostgreSQL\"\n      from_port   = 5432\n      to_port     = 5432\n      protocol    = \"tcp\"\n      cidr_blocks = module.vpc.private_subnets_cidr_blocks\n    }\n  }\n\n  # Workspace API keys\n  workspace_api_keys = {\n    viewer = {\n      key_name        = \"viewer\"\n      key_role        = \"VIEWER\"\n      seconds_to_live = 3600\n    }\n    editor = {\n      key_name        = \"editor\"\n      key_role        = \"EDITOR\"\n      seconds_to_live = 3600\n    }\n    admin = {\n      key_name        = \"admin\"\n      key_role        = \"ADMIN\"\n      seconds_to_live = 3600\n    }\n  }\n\n  # Workspace IAM role\n  create_iam_role                = true\n  iam_role_name                  = local.name\n  use_iam_role_name_prefix       = true\n  iam_role_description           = local.description\n  iam_role_path                  = \"/grafana/\"\n  iam_role_force_detach_policies = true\n  iam_role_max_session_duration  = 7200\n  iam_role_tags                  = { role = true }\n\n\n  tags = local.tags\n}\n\nmodule \"managed_grafana_default\" {\n  source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n  name              = \"${local.name}-default\"\n  associate_license = false\n\n  tags = local.tags\n}\n\nmodule \"managed_grafana_disabled\" {\n  source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n  name   = local.name\n  create = false\n}\n\n################################################################################\n# Supporting Resources\n################################################################################\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~\u003e 5.0\"\n\n  name = local.name\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n  public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 48)]\n\n  enable_nat_gateway = false\n  single_nat_gateway = true\n\n  tags = local.tags\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"versions.tf\" 파일입니다:\n\n```js\nterraform {\n  required_version = \"\u003e= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"\u003e= 5.0\"\n    }\n  }\n}\n```\n\n이 코드를 실행하려면 다음을 실행해야 합니다:\n\n```js\n$ terraform init\n$ terraform plan\n$ terraform apply\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프로메테우스 ethtool 익스포터 배치:\n\nethtool은 워커 노드의 이더넷 장치에 대한 정보를 구성하고 수집하는 리눅스 도구입니다. 우리는 ethtool의 출력을 사용하여 패킷 손실을 감지하고 이를 프로메테우스 ethtool 익스포터 유틸리티를 사용하여 프로메테우스 형식으로 변환할 것입니다.\n\n배포에는 ethtool에서 정보를 가져 와서 프로메테우스 형식으로 게시하는 Python 스크립트가 포함되어 있습니다.\n\n```js\nkubectl apply -f https://raw.githubusercontent.com/Showmax/prometheus-ethtool-exporter/master/deploy/k8s-daemonset.yaml\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 ADOT 수집기를 배포하고 ADOT 수집기를 구성하여 Amazon Managed Service for Prometheus로 메트릭을 수집할 것입니다.\n\n우리는 Amazon EKS 애드온을 사용하여 ADOT 오퍼레이터를 CoreDNS 모니터링을 위해 메트릭 \"linklocal_allowance_exceeded\"를 Amazon Managed Service for Prometheus로 보내게 될 것입니다.\n\nIAM 역할과 Amazon EKS 서비스 계정을 생성하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nADOT 수집기를 Kubernetes 서비스 계정 \"adot-collector\"의 신원으로 배포할 예정입니다. 서비스 계정에 IAM 역할(IRSA)을 연결하여 Kubernetes 서비스 계정에 AmazonPrometheusRemoteWriteAccess 역할을 할당함으로써 해당 서비스 계정을 활용하는 모든 파드가 Amazon Managed Service for Prometheus에 메트릭을 수집하는 데 필요한 IAM 권한을 부여할 수 있습니다.\n\n스크립트를 실행하려면 kubectl 및 eksctl CLI 도구가 필요합니다. 이 도구들은 Amazon EKS 클러스터에 액세스할 수 있도록 구성되어 있어야 합니다.\n\n```js\neksctl create iamserviceaccount \\\n--name adot-collector \\\n--namespace default \\\n--region eu-west-1\\\n--cluster coredns-monitoring-demo\\\n--attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess \\\n--approve \\\n--override-existing-serviceaccounts\n```\n\nADOT 애드온 설치하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여러분은 다음 명령어를 사용하여 Amazon EKS의 다른 버전에 활성화된 애드온 목록을 확인할 수 있습니다:\n\n클러스터 버전에서 지원하는 ADOT 버전을 확인하십시오.\n\n```js\naws eks describe-addon-versions --addon-name adot --kubernetes-version 1.28 \\\n  --query \"addons[].addonVersions[].[addonVersion, compatibilities[].defaultVersion]\" --output text\n```\n\n다음 명령어를 실행하여 ADOT 애드온을 설치하십시오. 위 단계에서 기술된 것에 따라 --addon-version 플래그를 교체하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\naws eks create-addon --addon-name adot --addon-version v0.66.0-eksbuild.1 --cluster-name coredns-monitoring-demo\n```\n\n다음 명령어를 사용하여 ADOT 애드온이 준비되었는지 확인하세요.\n\n```js\nkubectl get po -n opentelemetry-operator-system\n```\n\n다음 절차는 배포를 모드 값으로 사용하는 예제 YAML 파일을 사용합니다. 이는 기본 모드이며 ADOT Collector를 독립 애플리케이션과 유사하게 배포합니다. 이 구성은 샘플 애플리케이션으로부터 OTLP 메트릭을 수신하고 클러스터의 pod에서 스크래핑된 Amazon Managed Service for Prometheus 메트릭을 수신합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ncurl -o collector-config-amp.yaml https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml\n\ncollector-config-amp.yaml 파일에서 다음을 본인의 값으로 바꿔주세요: _ mode: deployment _ serviceAccount: adot-collector _ endpoint: \"\" _ region: \"\" \\* name: adot-collector\n\nkubectl apply -f collector-config-amp.yaml\n\nadot collector가 배포되면 메트릭이 Amazon Prometheus에 성공적으로 저장됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAmazon Managed Grafana에서 ethtool 메트릭을 시각화해보세요:\n\nAmazon Managed Grafana 콘솔 내에서 Prometheus 워크스페이스를 데이터 소스로 구성합니다.\n\n이제 Amazon Managed Grafana에서 메트릭을 살펴봅시다: \"탐색\" 버튼을 클릭한 후 ethtool을 검색하세요:\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n링크로컬 할당 초과 메트릭을 사용하여 대시보드를 만들어 봅시다. 쿼리는 다음과 같습니다.\n\n```js\nrate(node_net_ethtool{device=\"eth0\",type=\"linklocal_allowance_exceeded\"} [30s])\n```\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_3.png)\n\n값이 0이기 때문에 드랍된 패킷이 없다는 것을 확인할 수 있습니다. Amazon Managed Service for Prometheus의 경고 관리자에서 알림을 구성하여 알림을 보낼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론:\n\n이 글에서는 AWS Distro for OpenTelemetry (ADOT), Amazon Managed Service for Prometheus 및 Amazon Managed Grafana를 사용하여 CoreDNS 쓰로틀링 문제를 모니터링하고 경고를 생성하는 방법을 보여드렸습니다. CoreDNS 메트릭을 모니터링함으로써 고객은 패킷 손실을 사전에 감지하고 예방 조치를 취할 수 있습니다.\n\n다음에 또 만나요 🇵🇸 🎉\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n읽어 주셔서 감사합니다!! 🙌🏻😁📃, 다음 블로그에서 만나요.🤘🇵🇸\n\n🚀 끝까지 함께해 줘서 감사합니다. 이 블로그에 관한 질문/피드백이 있으면 언제든지 연락해 주세요:\n\n♻️ 🇵🇸LinkedIn: https://www.linkedin.com/in/rajhi-saif/\n\n♻️🇵🇸 Twitter : https://twitter.com/rajhisaifeddine\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n끝! ✌🏻\n\n# 🔰 계속 배우고!! 계속 공유해요!! 🔰\n\n# 참고:\n\n[https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/](https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/)\n","ogImage":{"url":"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png"},"coverImage":"/assets/img/2024-06-19-EverythingyouneedtoknowaboutmonitoringCoreDNSforDNSperformance_0.png","tag":["Tech"],"readingTime":19},{"title":"Kubernetes 보안 마스터하기 - 내 Admission Controllers 여행","description":"","date":"2024-06-19 13:06","slug":"2024-06-19-MasteringKubernetesSecurityMyJourneyWithAdmissionControllers","content":"\nKubernetes는 Admission Controllers라는 확장 포인트를 포함하고 있습니다. 이들은 Kubernetes 클러스터의 문지기 역할을 하며 들어오고 나가는 모든 자원 요청을 감독합니다. 단순한 감시뿐만 아니라 이들 컨트롤러는 정교한 필터 역할을 합니다.\n\n그들은 조직의 정책을 집행하고 규정 준수를 보장하며 요청을 미리 정의된 표준에 맞게 수정할 수 있습니다.\n\n이 기사는 Kubernetes 보안 시리즈의 네 번째로 Admission Controllers에 중점을 둡니다.\n\n인증된 Kubernetes 보안 (CKS) 자격증 획득을 향해 진로를 나아가면서, CKS 커리큘럼의 \"마이크로서비스 취약점 최소화\" 섹션에서 Admission Controllers의 중요성을 탐구하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 어드미션 컨트롤러란 무엇인가요?\n\n어드미션 컨트롤러는 쿠버네티스 생태계에서 중요한 역할을 하는데, 쿠버네티스 API 서버의 출입구 역할을 합니다.\n\n어드미션 컨트롤러는 요청이 인증되고 권한이 부여된 후에 호출되며, 해당 객체가 쿠버네티스 클러스터에 지속되기 전에 작동합니다. 그들의 주요 기능은 요청을 가로채고 처리하여 클러스터의 운영 무결성과 보안을 유지하는 것입니다.\n\n쿠버네티스에서 어드미션 컨트롤러는 기본적으로 클러스터의 사용 방법을 지배하고 강제화하는 플러그인입니다. 이들은 쿠버네티스 API 서버로의 요청(예: 리소스 생성, 수정 또는 삭제)을 미리 정의된 규칙과 정책에 맞춰평가합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 두 가지 유형의 입장 컨트롤러: 변형 및 확인\n\n입장 컨트롤러는 변형과 확인 두 가지 주요 유형으로 분류될 수 있습니다.\n\n변형 입장 컨트롤러는 그들이 수락하는 객체들을 수정할 수 있습니다. 이는 객체가 특정 규칙을 준수하거나 추가 메타데이터로 객체를 향상시킬 때 Kubernetes API 서버에 의해 처리되기 전에 요청 내용을 변경할 수 있음을 의미합니다.\n\n예를 들어, 변형 입장 컨트롤러는 모니터링 에이전트가 모든 작업 부하에 존재함을 보장하기 위해 사이드카 컨테이너를 자동으로 주입할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한편, 유효성 검사 입합기는 객체를 수정하지 않습니다. 대신 요청이 모든 필요한 기준을 충족하는지 확인합니다. 예를 들어, 배포가 이미지의 최신 버전을 사용하는지 보장할 수 있습니다.\n\n만약 요청이 이러한 검사를 통과하지 못하면, 유효성 검사 입합기는 작업을 거부하고 객체가 생성, 수정 또는 삭제되지 않습니다.\n\n이 프로세스는 조직 정책을 강제하는 데 중요하며 클러스터에 적용되는 규정 준수 및 안전한 구성만이 보장됩니다.\n\n특정 요구 사항에 맞는 사용자 정의 유효성 검사 입합기를 만들 수 있지만, Kubernetes 클러스터에는 이미 내장된 유효성 검사 입합기 스위트가 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 섹션에서는 미리 구성된 컨트롤러의 역할과 기능을 탐색할 것입니다.\n\n## Kubernetes 내장 Admission 컨트롤러\n\n기본 Kubernetes 설치에는 자체 내장 Admission 컨트롤러 모음이 자동으로 포함되어 활성화됩니다. 대부분의 관리자와 사용자에게는 이러한 컨트롤러를 만지는 일이 거의 없고, 기본적으로 활성화된 것을 비활성화할 필요도 거의 없을 것입니다.\n\n그러나 클러스터의 동작을 사용자 정의하거나 활성화된 Admission 컨트롤러를 확인해야 하는 경우, Kubernetes는 제어 플레인에서 직접 수행할 수 있는 간단한 방법을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현재 활성화된 입장 컨트롤러 목록을 확인하려면 제어 플레인 터미널에서 다음 명령을 실행하세요:\n\n```js\nkube-apiserver -h | grep enable-admission-plugins\n```\n\n기본적으로 설치된 주요 입장 컨트롤러와 쿠버네티스 생태계에 대한 기여에 대해 간략히 살펴보겠습니다. 입장 컨트롤러는 쿠버네티스 버전에 따라 다양하며, 이것들은 v1.29에서 내장된 것들입니다.\n\n- NamespaceLifecycle — 삭제 중인 네임스페이스에 대한 요청을 차단하고 예약된 이름과 일치하는 경우 새로운 네임스페이스를 생성할 수 없도록 보장합니다. 네임스페이스별 리소스의 무결성을 유지하는 데 중요합니다.\n- LimitRanger — LimitRange 개체로 지정된 제약 조건을 네임스페이스 내의 Pod, Container 및 PersistentVolumeClaim 리소스에 적용합니다. 관리자가 정의한 제한을 초과하지 않도록하여 자원 사용을 효율적으로 할당하고 낭용을 방지합니다.\n- ServiceAccount — 명시적 ServiceAccount가 지정되지 않은 Pod에 자동으로 기본 서비스 계정을 첨부합니다. 권한을 관리하고 적절한 수준의 액세스로 Pod가 Kubernetes API에 안전하게 액세스할 수 있도록 중요합니다.\n- PersistentVolumeClaimResize — 기존 PersistentVolumeClaim (PVC)의 크기를 다시 조정할 수 있게 합니다. 이 기능을 통해 응용 프로그램 요구 사항이 변경될 때 저장소 리소스를 조정하는 작업이 간편해집니다.\n- PodSecurity — 사전 정의된 Pod 보안 설정을 강화하는 Pod Security Standards를 적용합니다. 지정된 보안 요구 사항을 충족하지 않는 Pod의 생성을 방지하여 클러스터 내 보안 취약성 위험을 크게 줄입니다.\n\n그 외에도 다음과 같은 입장 컨트롤러가 있습니다:\n\n- MutatingAdmissionWebhook 및 ValidatingAdmissionWebhook — 외부 서비스에 의해 강제된 사용자 정의 입장 정책을 허용하는 웹훅입니다. 동적 입장 제어에 대한 섹션에서 논의할 예정입니다.\n- ResourceQuota — 네임스페이스 내 리소스 할당량 제한을 적용하여 CPU, 메모리, 저장소 및 Pod, 서비스 등의 개수를 다룹니다. 클러스터 리소스의 공정한 사용을 장려하고 모든 서비스 및 사용자 간에 공정한 사용을 촉진합니다.\n- Priority — PriorityClass 이름을 기반으로 Pod의 스케줄링 우선 순위를 결정합니다. 특정 애플리케이션의 중요성을 기준으로 Pod 스케줄링의 우선 순위를 설정하여 중요한 애플리케이션이 최적으로 실행될 수 있도록 보장합니다.\n- RuntimeClass — 컨테이너 런타임 구성의 선택을 지원합니다. Pod에 대해 서로 다른 컨테이너 런타임을 허용하여 런타임별 기능 및 최적화를 간소화합니다.\n- DefaultStorageClass, DefaultIngressClass 및 DefaultTolerationSeconds — 명시적으로 지정되지 않은 경우 Pod에 대해 저장소 클래스, 인그레스 클래스 및 허용 시간의 기본값을 자동으로 설정합니다. 구성을 간소화하고 기본 정책이 클러스터 전체에 일관되게 적용되도록 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 쿠버네티스의 동적 입장 제어: 클러스터 보안 및 관리 향상\n\n동적 입장 제어는 사용자 정의 정책을 강요하고 MutatingAdmissionWebhook 및 ValidatingAdmissionWebhook 두 가지 중요한 구성 요소를 통해 클러스터 관리를 간소화하는 강력한 메커니즘입니다.\n\n## 동적 입장 제어 컨트롤러 이해\n\n동적 입장 제어 컨트롤러에는 MutatingAdmissionWebhook 및 ValidatingAdmissionWebhook 두 가지 종류가 있습니다. 이 컨트롤러는 외부 서비스에서 정의된 사용자 정책에 따라 쿠버네티스 API 서버에 대한 요청을 허용하거나 거부하는 게이트키퍼 역할을 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## MutatingAdmissionWebhook: 변환자\n\nMutatingAdmissionWebhook는 변환하는 어드미션 컨트롤러이며, 이전 섹션에서 본 것처럼 쿠버네티스 API 서버가 처리하기 전에 들어오는 요청을 수정하거나 변환하는 데 사용됩니다. 이 능력은 다음과 같은 시나리오에 유용합니다:\n\n- 사이드카 컨테이너 주입: 팟에 보조 컨테이너를 자동으로 추가하여 로깅, 모니터링 또는 네트워크 트래픽 제어에 사용할 수 있습니다.\n- 구성 변경: 조직 표준을 준수하도록 포드 사양을 수정하여 레이블이나 환경 변수를 추가하는 것과 같은 작업을 수행할 수 있습니다.\n\n## ValidatingAdmissionWebhook: 게이트키퍼\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한편, ValidatingAdmissionWebhook은 미리 정의된 규칙에 대한 요청을 검증하여 계속 진행하기 전에 확인하는 데 중점을 둔 유효성 검사 입장 컨트롤러입니다. 다음과 같은 중요한 역할을 합니다:\n\n- 사용자 지정 리소스 할당량 강제 적용: 리소스 생성이 조직 정책에서 설정한 한도를 초과하지 않도록 보장합니다.\n- 사용자 지정 보안 정책 확인: 구성이 보안 표준을 준수하는지 확인하여 컨테이너가 루트 사용자가 아닌 사용자로 실행되도록 합니다.\n\n# 웹훅 Admission 컨트롤러 구현\n\n사용자 정의 Admission 컨트롤러를 통합하거나 개발하는 두 가지 방법이 있습니다. 전통적인 방법은 Go와 같은 프로그래밍 언어를 사용하여 사용자 정의 Admission 컨트롤러를 생성하는 것인데, 이는 강력한 제어를 제공하지만 심층적인 Kubernetes 생태계 지식이 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n대신, 쿠버네티스는 MutatingAdmissionWebhook 및 ValidatingAdmissionWebhook이라는 웹훅 어드미션 컨트롤러 덕분에 더 접근성이 좋은 옵션을 제공합니다. 이를 통해 개발자는 쿠버네티스 API 서버가 웹훅을 통해 통신할 수 있는 REST API 서비스를 구현하여 사용자 정의 어드미션 로직을 도입할 수 있습니다.\n\n## 배포 유연성\n\n웹훅을 호스팅하는 REST API 서비스는 쿠버네티스 클러스터 내부나 외부 중 어디에나 배포할 수 있습니다. 이러한 유연성은 다양한 배포 시나리오와 아키텍처 디자인을 지원합니다.\n\n## 언어 중립성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n웹훅 기반 컨트롤러의 중요한 장점 중 하나는 언어에 구애받지 않는다는 점입니다. 개발자들은 Node.js, Java, C# 또는 기타 선호하는 프로그래밍 언어로 REST API 서비스를 구현할 수 있어 팀의 전문지식에 기반한 더 넓은 채택과 사용자 정의를 유도할 수 있습니다.\n\n## 운영 메커니즘\n\n두 종류의 웹훅은 JSON 형식의 직렬화된 AdmissionReview 객체와 상호작용하여 작동합니다. ValidatingAdmissionWebhook은 객체를 사용하여 허용/거부 결정을 내릴 수 있어야 합니다.\n\n동시에 MutatingAdmissionWebhook은 요청 페이로드를 변경하여 Kubernetes 리소스의 동작을 동적으로 강화하거나 수정하는 다재다능한 메커니즘을 제공할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGitHub에서 웹훅 구현을 보여주는 다양한 예제를 찾을 수 있어요. 예를 들면, 이겪은 Python을 사용합니다. [https://github.com/garethr/kubernetes-webhook-examples](https://github.com/garethr/kubernetes-webhook-examples)\n\n# Admission Controllers와 CKS 시험 준비\n\nCKS (Certified Kubernetes Security Specialist) 자격증 시험을 통과하기 위해 나의 여정 중, 마이크로서비스 취약점을 최소화하는 막대 아래에 있는 Admission Controllers 섹션에 도달했어요.\n\n아직 시험을 보지는 않았지만, 커스텀 Admission Controller를 제로부터 만들거나 검증을 위한 웹훅의 코딩 세부 사항에 대해 물어보지는 않을 거라고 생각해요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 대신, 나는 더 가능성이 높은 도전 과제에 대비하고 있어요: 어떤 입학 컨트롤러가 켜져 있는지 끄는지 알아내고 이러한 설정을 어떻게 조정하는지 알아내야 해요. 이것은 CKS가 추구하는 것과 더 일치하는데, 실제 Kubernetes 보안에서 요구되는 실용적이고 실무적인 기술에 부합합니다.\n\n# 마무리: Kubernetes의 문지기들\n\nCKS 시험 준비를 시작하기 전에, 입학 컨트롤러가 존재하는 것조차 몰랐어요. 지금은 몇 개의 입학 컨트롤러를 사용하여 배포에 레이블과 같은 기본적인 것들을 추가했어요.\n\n나의 공부를 통해, 다양한 작업을 위해 입학 컨트롤러를 활용하는 많은 도구와 구현을 발견했어요. 예를 들어, 특정 이미지의 최신 버전만 사용되도록 하는 것과 같이 컨테이너 이미지 스캔을 입학 컨트롤러와 통합하는 것이 가능해요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n더 나아가 몇 가지 도구는 입학 컨트롤러의 기초를 기반으로하여, 특정 보안 정책을 구현하는 과정을 간소화하는 계층을 추가합니다. 사용자 정의 정책 설명 언어를 사용하여 구체적인 보안 정책을 구현하는 과정을 단순화하는 도구들이 있습니다.\n\n그 중 하나가 OPA 또는 Open Policy Agent입니다. 이는 CKS 시험의 요구 사항 중 하나인 것으로 알고 있습니다. 다음 글에서 OPA에 대해 자세히 다룰 계획입니다.\n\n열심히 공부하세요!\n","ogImage":{"url":"/assets/img/2024-06-19-MasteringKubernetesSecurityMyJourneyWithAdmissionControllers_0.png"},"coverImage":"/assets/img/2024-06-19-MasteringKubernetesSecurityMyJourneyWithAdmissionControllers_0.png","tag":["Tech"],"readingTime":10},{"title":"온프레미스 쿠버네티스 대 관리형 쿠버네티스","description":"","date":"2024-06-19 13:04","slug":"2024-06-19-On-PremisesKubernetesVsManagedKubernetes","content":"\n쿠버네티스는 컨테이너화된 응용 프로그램을 관리하는 강력한 오케스트레이션 도구로, 다양한 방식으로 배포할 수 있습니다. 가장 흔한 두 가지 방법은 온프레미스 쿠버네티스와 관리형 쿠버네티스입니다. 이 옵션들을 일상 생활에서의 간단한 비유를 사용하여 설명하고, 서로 다른 점을 이해하고 어떤 것이 당신의 상황에 가장 적합한지 결정하는 데 도움이 되도록 해보겠습니다.\n\n![온프레미스 쿠버네티스 대 관리형 쿠버네티스](/assets/img/2024-06-19-On-PremisesKubernetesVsManagedKubernetes_0.png)\n\n온프레미스 쿠버네티스: 직접 관리하는 방식\n\n온프레미스 쿠버네티스는 자동차를 소유하는 것과 같습니다. 자동차를 소유하면서 할 수 있는 것들:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1. 구매 및 설정: 차량을 구매하며, 이는 비용이 많이 들 수 있으며 모델, 색상 및 기능 선택과 같은 모든 설정에 책임이 있습니다.\n\n2. 유지 보수: 오일 교환부터 브레이크 수리까지 모든 유지 보수를 당신이 처리해야 합니다. 이는 차량 관리 방법을 알거나 이를 담당할 전문가를 고용해야 한다는 뜻입니다.\n\n3. 통제: 차량을 완전히 통제합니다. 운전 시간과 장소를 결정하며 마음껏 사용할 수 있습니다.\n\n4. 비용: 초기 비용과 계속되는 유지 보수 비용이 있지만 매달 대여료는 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n동일한 방식으로, 온프레미스 Kubernetes는 다음을 의미합니다:\n\n- 인프라 소유권: Kubernetes가 실행되는 서버와 하드웨어를 소유하고 있습니다. 이 인프라를 구매, 설정 및 유지보수해야 합니다.\n\n- 완전한 제어: Kubernetes 환경을 완전히 제어할 수 있습니다. 특정한 요구 사항에 맞게 확장하여 사용할 수 있습니다.\n\n- 유지보수 책임: 모든 업데이트, 패치 및 시스템 모니터링에 대한 책임이 있습니다. 이를 위해 적절한 전문 지식을 가진 팀이 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n• 비용 고려 사항: 하드웨어 및 소프트웨어에 상당한 초기 비용이 들지만, 클라우드 서비스와 관련된 반복 비용을 피할 수 있습니다.\n\n## 관리형 Kubernetes: 차를 빌리는 것\n\n관리형 Kubernetes는 차를 빌리는 것과 비슷합니다:\n\n1. 쉬운 접근: 렌터카 회사에서 차를 선택하고 준비된 차량을 제공받습니다. 구매 프로세스를 걱정할 필요가 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 유지보수가 필요 없음: 렌탈 회사가 모든 유지보수와 수리를 처리합니다. 차량이 고장나면 다른 차량을 제공해줍니다.\n\n3. 편리함: 필요할 때에만 차량을 렌탈할 수 있어 장기간의 약정이나 유지보수 걱정 없이 이용할 수 있습니다.\n\n4. 반복 비용: 렌탈 비용을 지불하면 차량 이용과 유지보수 서비스가 모두 포함됩니다.\n\n## 관리형 쿠버네티스는 비슷한 방식으로 작동합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 서비스 제공업체: Google Kubernetes Engine (GKE), Amazon Elastic Kubernetes Service (EKS), 또는 Azure Kubernetes Service (AKS)와 같은 클라우드 제공업체가 인프라를 관리합니다.\n\n- 사용 편의성: 제공업체가 설정, 유지 관리 및 업데이트를 처리하므로 시작하고 운영하기 쉬워집니다.\n\n- 유지보수 없음: 클라우드 제공업체가 모든 업데이트, 보안 패치 및 모니터링을 처리하여 팀에 부담을 줄여줍니다.\n\n- 재발생 비용: 사용량에 따라 서비스를 지불하므로 인프라를 소유하는 것보다 예측 가능하고 확장 가능한 경우가 많습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 어떤 것이 당신에게 가장 적합할까요?\n\n온프레미스와 관리형 쿠버네티스 중 어떤 것을 선택할지는 당신의 특정 필요와 상황에 따라 다릅니다. 몇 가지 시나리오를 살펴보겠습니다:\n\n온프레미스 쿠버네티스가 가장 적합한 경우:\n\n1. 완벽한 통제가 필요한 경우: 규제 요건, 데이터 소유권 문제 또는 특정 맞춤화 요구사항으로 인해 인프라에 대한 완벽한 통제가 필요한 경우.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 기존 인프라: 온프레미스 하드웨어에 상당한 투자를 이미 했으며 효율적으로 활용하고 싶습니다.\n\n3. 비용 관리: 특히 클라우드 서비스와 관련된 반복 비용 대신 하드웨어에 선순위 투자를 선호합니다.\n\n관리형 Kubernetes는 다음 상황에 가장 적합합니다:\n\n- 확장성: 수요에 따라 운영을 유연하게 확장 또는 축소할 수 있는 유연성이 필요합니다. 특히 초기에는 빠르게 성장하거나 변동하는 워크로드를 경험하는 스타트업 및 기업에 유리합니다.\n- 전문 지식: Kubernetes 환경을 효과적으로 관리하는 데 필요한 내부 전문 지식이 부족합니다. 관리형 서비스는 Kubernetes 운영의 복잡성을 다루는 전문가 팀에 접근할 수 있도록 합니다.\n- 속도: 온프레미스 인프라를 설정하고 유지하는 데 연관된 지연 없이 가능한 빨리 응용 프로그램을 가동하고 싶습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 결정 요소들\n\n온프레미스와 관리형 쿠버네티스 사이를 결정할 때 고려해야 할 몇 가지 추가 요소가 있습니다:\n\n- 규정 준수와 보안: 귀하의 산업에 따라 규정 요구사항이 데이터를 어디에서 어떻게 관리해야 하는지를 결정할 수 있습니다. 클라우드 제공업체는 높은 수준의 보안을 제공하고 종종 다양한 규정을 준수하지만 특정 데이터는 특정 상황에서 내부에 보관해야 할 수도 있습니다.\n- 장기 비용: 관리형 쿠버네티스는 장기적으로 더 비싸지만, 그 대가는 책임을 줄이고 잠재적으로 낮은 운영 리스크가 따릅니다. 그에 반해, 온프레미스 쿠버네티스는 처음에는 비용이 더 들지만 지속적인 운영 비용이 낮을 수 있습니다.\n- 혁신과 업그레이드: 클라우드 제공업체들은 지속적으로 서비스를 업데이트하여 최신 기능과 보안 향상을 제공합니다. 온프레미스 쿠버네티스를 사용할 경우 귀하의 팀은 이러한 업데이트를 수동으로 관리해야 하며, 이는 새로운 기능에 접근하는 데 시간이 걸릴 수 있습니다.\n\n여기까지입니다...\n차를 구매할지 렌트할지 선택하는 것은 귀하의 재정적 및 기술적 요구사항 및 상황에 달려 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 문서를 읽어 주셔서 감사합니다 🙏\n더 많은 유용한 콘텐츠를 보시려면 제 블로그를 팔로우해 주세요. 놓치지 않으려면 구독도 잊지 말아 주세요.\n","ogImage":{"url":"/assets/img/2024-06-19-On-PremisesKubernetesVsManagedKubernetes_0.png"},"coverImage":"/assets/img/2024-06-19-On-PremisesKubernetesVsManagedKubernetes_0.png","tag":["Tech"],"readingTime":6},{"title":"어렵게 배운 교훈 Cilium의 기본 Pod CIDR을 사용하지 마세요","description":"","date":"2024-06-19 13:03","slug":"2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR","content":"\n전 eBPF에 상당히 오랫동안 관여해 왔습니다. 우리 팀장이 Azure CNI에서 Cilium CNI로 모든 클러스터를 라이브 이전하는 것을 제안했을 때, 기회에 바로 뛰어들었어요. 이 일은 내가 지금까지 맡았던 가장 힘든 일 중 하나였지만, 그 시간 동안 즐거웠어요.\n\n하지만, 그 이야기는 다음에 하기로 해요. 이 기사의 목표는 제 개인적인 k8s.af 이야기 중 하나를 해설하여, 머리카락을 몇 일 절약할 수 있는 누군가를 돕는 것입니다.\n\n![이미지](/assets/img/2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR_0.png)\n\n## 왜 Cilium을 선택했는가?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCilium을 선택한 우리의 주요 목표는 다음과 같습니다:\n\n- 더 나은 네트워크 격리: 일부 클러스터에서는 고객의 작업 부하를 실행하고 있기 때문에 출발 트래픽을 효과적으로 공유하고 제어해야 했습니다.\n- WireGuard를 사용한 투명한 암호화: 공유 클러스터에서는 제로 트러스트 접근 방식을 채택하고자 했습니다.\n- 관찰 가능성: Cilium은 다양한 관찰 기능을 갖추고 있어 추가 계측없이 Kubernetes 작업 부하를 모니터링할 수 있습니다.\n- 서비스 메시 기능: Cilium은 사이드카를 필요로하지 않고 다시 시도 및 회로 차단과 같은 서비스 메쉬 기능을 제공할 수 있습니다.\n- 효율적이고 가벼운 네트워크 스택: 하드웨어 비용을 낮추면서 더 나은 성능을 원하신다면 저희를 선택해 주세요!\n- 클러스터 매시 망: 우리는 인프라를 미래에 대비하기 위해 준비하고 싶었습니다.\n\n이주 후 모든 것이 원활했습니다 (대부분...). Cilium을 기반으로 개발한 기능을 출시하기 시작했고 고객들로부터 좋은 피드백을 받았습니다.\n\n그리고 모든게 좋았는데...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 사건\n\n일반적인 월요일 아침이었고, 매일 릴리스 주기의 일환으로 SRE 팀은 코어 서비스의 최신 업데이트를 스테이징 환경으로 프로모션했습니다.\n\n그러나 프로모션 파이프라인이 완료되자마자 우리의 업타임 모니터링 솔루션이 스테이징 환경에 접근할 수 없다는 이벤트를 트리거하면서 발생했습니다. SRE 팀은 즉시 문제의 근본 원인을 조사하기 시작했습니다.\n\n더 깊이 파고들기 전에, 빠른 다이어그램을 사용하여 우리의 네트워크 아키텍처(간소화된 버전)를 설명해 드리겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR_1.png\" /\u003e\n\n두 개의 클러스터가 있습니다. 하나는 외부에 공개되어 있고, 다른 하나는 비공개입니다. 외부 클러스터는 방화벽을 통해 노출되어 있습니다. 비공개 클러스터의 일부 서비스는 로드 밸런서를 통해 외부 클러스터와 통신합니다.\n\n초기 디버깅 후, SRE 팀은 문제가 방화벽과 클러스터 1의 인그레스 서비스 간의 연결에 있는 것으로 결론 내렸습니다. 클러스터 1 내의 모든 서비스가 실행되고 클러스터 1의 로드 밸런서를 향해 요청을 보내고 있기 때문에 클러스터 2의 pod들이 작동 중이었습니다.\n\nWireshark와 Hubble을 통해, 방화벽에서 전송된 \"SYN\" 패킷이 서비스에 도달했지만 서비스로부터 해당하는 \"ACK\" 패킷이 전송되지 않았음을 확인했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n문제를 해결하기 위한 몇 차례의 무산된 시도 끝에 SRE 팀은 프로덕션으로의 릴리스를 승인했습니다. 중요한 수정 사항을 가능한 빨리 릴리즈해야 했기 때문입니다. 이 결정의 근거는 애플리케이션 수준의 변경이 인프라를 손상시킬 수 없으며, 이 일은 격리된 사건이었습니다.\n\n그러나 릴리스가 프로덕션으로 승급되자마자 프로덕션 로드 밸런서도 응답을 중단했습니다. SRE 팀은 신속하게 변경 사항을 롤백하여 프로덕션에서 문제를 해결했습니다. 놀랍게도 스테이징 클러스터에서 변경 사항을 롤백해도 문제가 해결되지 않았습니다.\n\n## 재앙이 계속됩니다\n\n스테이징에서의 문제가 여전히 해결되지 않아 전문 네트워크 전문가와 함께 전투실에 호출되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금쯤 SRE 팀은 광범위한 실험을 통해 많은 데이터를 수집했습니다. 우리 VPC 내의 다른 서브넷에 VM을 배포하는 실험을 해보았는데, 로컬 노드 풀 서브넷부터 다른 클러스터에 속한 원격 서브넷, 로드 밸런서 서브넷까지 다양한 곳에 시도해봤습니다. 모든 것이 예상대로 작동되었는데, 방화벽을 통해 통과하는 트래픽에서 문제가 발생했습니다.\n\n제가 노력에 합류하면서, 그들이 수집한 모든 데이터를 철저히 검토했고, 여러 종류의 워크로드를 배포하고 Hubble과 Wireshark 로그를 분석하며 더 많은 테스트를 진행했습니다. 루트 원인을 밝힐 수 있는 단서나 누락된 부분을 찾기 위해 노력했습니다.\n\nAzure 네트워크 엔지니어가 합류하면서, SRE 팀은 그들이 지금까지 한 모든 단계에 대해 설명했습니다. 수집한 데이터를 분석한 후, 엔지니어는 방화벽 서브넷 내에 VM을 배포하고 문제가 있는 Kubernetes 클러스터로 TCP 연결을 시도하라는 제안을 했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저희 SRE 팀은 방화벽 서브넷 내에 임시 VM을 빠르게 설정하고 로드 밸런서 IP로 telnet을 시도해 보았어요. 이 테스트 중에 우리가 직면한 동일한 문제를 관찰했는데, telnet 연결이 초기화되지 않았어요. 그래서 그들은 방화벽 서브넷과 로드 밸런서 서브넷 또는 노드 풀 서브넷 간 네트워크 피어링에 문제가 있는지 조사하기로 결정했어요.\n\n호기심에 저는 다른 SRE 멤버에게 서버에 다시 ping을 시도하도록 요청하고 Hubble 로그를 모니터링했어요. 놀랍게도, telnet이 시작된 순간에 SYN 패킷이 수신되었지만 \"ACK\"은 전달되지 않았어요.\n\n이 행동은 이상하게 보였기 때문에 임시 VM에서 포트를 열도록 요청하고 쿠버네티스 클러스터에서 해당 VM으로 ping을 시도해 보았어요. 하지만 응답이 없었고, 임시 VM에 Wireshark를 설치한 후에도 들어오는 SYN 패킷을 볼 수 없었어요. 흥미로운 점은 방화벽 서브넷을 제외한 다른 목적지로 ping을 시도하면 문제가 없었다는 점이었어요.\n\n의아해하며, 그들에게 노드 풀 서브넷에 생성한 임시 VM을 사용하여 동일한 테스트를 수행해 보라고 요청했더니, 드디어 작동했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 루트 원인\n\n이러한 동작이 이상하다고 생각해, 주요 사고 대응 팀 구성원들의 작업을 방해하고 있는 피어링을 점검 중이었던 멤버들에게 얘기했어요. 문제가 인그레스가 아니라 이그레스에 문제가 있을 수 있다는 것을 알려줬죠. 이로써 AKS-관리 노드 내의 라우팅 테이블 문제일 수도 있다는 느낌을 받았어요.\n\n그래서 저희 SRE 팀은 쿠버네티스 클러스터에서 노드 중 하나로 SSH를 통해 연결하고 `ip route` 명령을 실행했어요. 이 명령을 실행하면 Cilium이 교차 노드 통신을 가능하게하기 위해 추가한 몇 가지 라우팅 규칙이 표시됐어요.\n\n![Image](/assets/img/2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Cilium 노드 라우팅\n\n고수준 개요에서 Cilium을 클러스터 범위 IPAM 모드에서 실행할 때, Cilium에게 가상 IP를 파드에 할당하도록 지시하기 위해 CIDR 범위를 제공해야 합니다. 기본적으로 이 CIDR 범위는 10.0.0.0/8입니다.\n\n새 노드가 클러스터에 가입하면, Cilium은 해당 노드에게 주어진 CIDR 블록에서 고유한 서브넷을 할당합니다. 노드의 모든 파드는 이 할당된 서브넷 범위에서 IP 주소를 받습니다.\n\n예를 들어, CIDR 범위인 10.0.0.0/8을 사용한다면:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 노드 A는 서브넷 10.1.0.0/16을 받을 수 있습니다.\n- 노드 B는 서브넷 10.4.0.0/16을 받을 수 있습니다.\n\n노드 간 통신을 원활하게 하기 위해 Cilium은 IP 경로를 설정하여 트래픽이 노드 간에 올바르게 전달되도록 합니다. 노드 A에 있는 IP가 10.1.5.13인 팟이 노드 B에 있는 IP가 10.4.63.38인 팟과 통신하려고 할 때, 데이터 패킷은 노드 A의 네트워크 인터페이스로 전송됩니다. 그 후 IP 라우팅 테이블을 기반으로 패킷은 노드 B로 라우팅되며, 이는 노드 B가 10.4.0.0/16 서브넷을 소유하기 때문입니다.\n\n## 잠자는 용\n\n보통은 정상적으로 작동합니다. 그러나 유감스럽게도, 노드에 할당된 서브넷 중 하나가 방화벽의 서브넷 범위와 겹치는 문제가 발생했습니다. 이로 인해 SYN 패킷이 팟에 성공적으로 도달하지만, 팟이 응답을 시도할 때 요청이 노드의 네트워크 인터페이스로 전달되는 상황이 발생했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 때, 노드의 IP 라우팅 규칙 때문에 패킷이 다른 노드로 라우팅되었습니다. 이는 방화벽의 VM IP 주소가 두 번째 노드의 서브넷 범위 내에 속했기 때문에 발생했습니다. 그러나 두 번째 노드에는 방화벽의 VM과 정확히 일치하는 IP 주소를 가진 pod가 없었기 때문에 패킷이 소멸하여 사라졌습니다.\n\n이 가설을 확인하기 위해 SRE 팀은 충돌하는 노드에 대해 `kubectl delete node`을 실행했고, 그 노드가 제거되자마자 방화벽을 통한 외부 연결이 다시 작동하기 시작했습니다.\n\n하지만 왜 Cilium을 배포한 후 거의 8개월이 지난 후에 이 문제가 발생했을까요? 이 모든 것은 자동 스케일링으로 귀결되었습니다. 관찰한 바에 따르면, 특정 CIDR 범위가 노드에 할당되면 해당 노드가 제거되더라도 재사용되지 않았습니다. 따라서 Cilium 운영자는 우리가 할당한 대규모 CIDR 범위를 하나씩 소비하면서 점진적으로 이동하고 있었고, 마침내 방화벽의 CIDR 범위에 다다랐습니다.\n\n그 판명날인 첫 월요일 아침, SRE 팀이 개발 환경에서 스테이징으로 릴리스를 승격시키자마자 노드 스케일업을 트리거하여 충돌하는 CIDR 범위가 있는 노드가 생성되었고, 이로 인해 전체 통신 경로가 다운되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 문제 수정\n\n스테이징에서 발생한 이슈를 해결하기 위해, 우리는 clusterPoolIPv4PodCIDRList를 기존 내부 서브넷과 충돌하지 않는 CIDR 범위로 업데이트해 보았습니다. 헬름 업그레이드를 실행한 후에도 아무 변화가 없었습니다. 그래서 노드 스케일 업을 트리거하고 다행히도 - 새로 생성된 노드가 새로운 CIDR 범위의 서브넷으로 생성되었습니다.\n\n저는 두 개의 DaemonSet을 사용하여 교차 노드 통신을 테스트하기 위해 만든 빠른 워크로드를 실행하여 두 개의 CIDR 범위가 아무 문제없이 작동하는 것을 확인했습니다. 그 후, SRE 팀은 기존 노드를 안전하게 비우고 제거하고 나쁜 CIDR 범위를 가진 모든 노드가 완전히 제거될 때까지 새로운 노드 풀을 확장하는 스크립트를 신속하게 작성했습니다. 그 스크립트를 실행하여 스테이징 클러스터를 완전히 복구했습니다.\n\n추가 테스트를 실행한 후에 우리의 프로덕션 클러스터도 동일한 문제를 겪었기 때문에, Cilium 문서에서 반대하고 있던 것에도 불구하고 clusterPoolIPv4PodCIDRList를 업데이트하여 문제를 영구적으로 해결하기로 결정했습니다. 이에 이해 관계자들로부터 동의를 받고 마이그레이션을 실행했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n다양한 테스트를 거친 후에도, 거의 2000개의 구성 가능한 값이 있는 Cilium과 같은 복잡한 시스템은 여전히 잘못된 구성을 빠뜨릴 수 있어 예상치 못한 실패로 이어질 수 있습니다.\n\n이 사건을 통해, 네트워크 문제를 체계적으로 해결하고 클라우드 추상화에 의해 제공된 낮은 수준의 네트워킹 인프라와 기술을 이해하는 중요성을 깨달았습니다. 이 문제에 대해 협업한 후, 매우 어려운 경험이었지만 소중한 학습 기회를 제공했다는 것에 대해 모두 동의했습니다.\n","ogImage":{"url":"/assets/img/2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR_0.png"},"coverImage":"/assets/img/2024-06-19-LearneditthehardwayDontuseCiliumsdefaultPodCIDR_0.png","tag":["Tech"],"readingTime":10},{"title":"나의 쿠버네티스 클러스터에 MongoDB No-SQL 데이터베이스를 추가한 경험","description":"","date":"2024-06-19 13:00","slug":"2024-06-19-MyexperienceaddingaMongoDBNo-SQLdatabasetomyKubernetescluster","content":"\n## SQL과 No-SQL 데이터베이스 사이를 선택하는 방법에 대해 읽었다면, Kubernetes 클러스터에 No-SQL MongoDB 데이터베이스를 추가할 수 있는지 궁금할 것입니다. 이 글에서는 그것을 어떻게 수행했는지 설명하고 Spring Boot 애플리케이션과 함께 사용하는 방법에 대해 알려드리겠습니다.\n\n![이미지](/assets/img/2024-06-19-MyexperienceaddingaMongoDBNo-SQLdatabasetomyKubernetescluster_0.png)\n\n# 시작하기\n\n일반적으로 Kubernetes 서비스를 개발할 때는, 개발을 위해 로컬 Kind Kubernetes 클러스터에서 시작합니다. Kind를 설정하는 방법에 대해 이전에 썼었고, 이 글에 관련된 GitHub 저장소에는 이를 수행하는 데 필요한 구성 파일이 포함되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클론하기 위해 저장소를 다음과 같이 복제할 수 있어요:\n\n```js\ngit clone git@github.com:MartinHodges/aquarium-with-mongo-db.git\n```\n\n# 왜 MongoDB를 사용해야 하나요?\n\n이전 기사에서 SQL 대 No-SQL 결정에 대해 다뤄 보았어요. 여러분이 이 글을 읽고 계신다면 No-SQL을 선택하겠다고 결정하신 거겠죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일단 그 결정이 내렸다면, 이제 No-SQL 데이터베이스를 어떤 것을 선택할지가 문제가 됩니다. MongoDB는 가장 가까운 경쟁상대보다 2배 더 높은 시장 점유율을 보유하고 있습니다. 그것은 매우 정교하며 커뮤니티 버전과 엔터프라이즈 버전 둘 다 가지고 있습니다. 전형적으로 가장 많이 사용되는 No-SQL 데이터베이스입니다.\n\n다른 데이터베이스와의 기술적인 비교는 이 기사의 범위를 벗어나지만, MongoDB가 인기 있는 이유와 일하도록 충분히 할 수 있는 사실에 기반하여 이 기사에서는 MongoDB를 선택했습니다!\n\n# MongoDB 설치\n\nKubernetes 클러스터에 MongoDB를 설치하는 방법은 다른 응용프로그램과 유사하게 operator를 사용하여 수행됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-MyexperienceaddingaMongoDBNo-SQLdatabasetomyKubernetescluster_1.png\" /\u003e\n\n쿠버네티스 오퍼레이터는 당신을 대신하여 응용 프로그램을 관리합니다. 응용 프로그램의 라이프사이클을 설치하고 관리하며 모니터링하고 필요한 조치를 취할 수 있습니다.\n\n데이터베이스의 경우 데이터베이스 클러스터를 생성하거나 확장하거나 백업하는 등의 작업을 수행할 수 있습니다. 일반적으로 오퍼레이터는 그 자체의 '쿠버네티스 구성 언어'를 제공하는 사용자 정의 리소스 정의 (CRD)를 설치하기에 의존합니다. 이는 클러스터에 사용자 정의 리소스를 추가하기 위한 요청을 감지하고 당신을 대신하여 작동합니다.\n\n## 개발용 쿠버네티스 클러스터 생성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nKind를 설치했다고 가정하면, 다음 구성을 사용하여 Kind 클러스터를 만들 수 있습니다:\n\nkind/kind-config.yml\n\n```js\napiVersion: kind.x-k8s.io/v1alpha4\nkind: Cluster\nnodes:\n- role: control-plane\n  extraPortMappings:\n  # apis\n  - containerPort: 30080\n    hostPort: 30080\n- role: worker\n- role: worker\n- role: worker\n```\n\n이렇게 하면 1개의 컨트롤러 및 3개의 워커로 구성된 4개 노드 클러스터가 생성됩니다. 또한 개발 머신의 포트 30080을 사용할 수 있습니다. 이를 사용하여 로컬 Kubernetes 클러스터를 생성할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```shell\nkind create cluster --config kind/kind-config.yml\n```\n\n## 오퍼레이터 설치\n\nHelm을 사용하여 커뮤니티 지원 오퍼레이터를 설치할 수 있습니다.\n\n먼저 다음과 같이 로컬 리포지토리에 Helm 링크를 추가하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nhelm repo add mongodb https://mongodb.github.io/helm-charts\n```\n\n아래 명령어로 이 리포지토리가 추가한 차트를 확인할 수 있어요:\n\n```js\nhelm search repo mongo\n```\n\n리스트에서 커뮤니티 오퍼레이터를 확인할 수 있을 거에요. 이것을 사용할 거에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저희는 오퍼레이터와 데이터베이스를 별도의 네임스페이스로 mongo라는 이름으로 분리해서 배치할 겁니다. 다음과 같이 생성해보겠습니다:\n\n```js\nkubectl create namespace mongo\n```\n\n이제 다음 명령으로 오퍼레이터를 설치할 수 있어요:\n\n```js\nhelm install community-operator mongodb/community-operator -n mongo\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 명령어를 사용하여 준비 상태가 1/1로 Running인지 확인할 수 있어요:\n\n```sh\nkubectl get pods -n mongo\n```\n\n이제 운영자가 작동 중인 것을 볼 수 있습니다. 설치된 CRD는 다음을 통해 확인할 수 있어요:\n\n```sh\nkubectl get crds\nkubectl describe crd mongodbcommunity.mongodbcommunity.mongodb.com\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 MongoDB 클러스터를 생성할 준비가 되었습니다.\n\n## 클러스터 생성\n\n오퍼레이터가 설치되었으므로 MongoDB 데이터베이스를 생성하는 요청을 대기 중입니다. 우리는 오퍼레이터에 의해 로드된 CRD를 사용하여 쿠버네티스 클러스터에 MongoDB 매니페스트를 적용하여 요청을 할 수 있습니다.\n\n이를 하기 전에 데이터베이스 사용자의 비밀번호를 쿠버네티스 시크릿으로 설정해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음과 같이 비밀을 생성하세요 (‘…’를 선택한 비밀번호로 교체하세요):\n\n```js\nkubectl create secret generic my-user-password -n mongo --from-literal=\"password=\u003c당신의 비밀번호\u003e\"\n```\n\n다음 명령어로 확인할 수 있어요:\n\n```js\nkubectl get secrets -n mongo my-user-password -o jsonpath={.data.password} | base64 -d; echo\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모든 쿠버네티스 시크릿은 base64로 인코드되어 있기 때문에 비밀번호를 디코딩하는 데 base64 -d를 사용하는 것을 알 수 있습니다. 우리가 --from-literal을 사용하였기 때문에 create secret 명령어에 의해 비밀번호가 자동으로 base64로 인코드되었습니다.\n\n이제 비밀번호가 준비되었으니, 이 비밀번호를 사용하는 관리자 사용자가 있는 MonogoDB 클러스터와 데이터베이스를 생성할 수 있습니다.\n\n매니페스트 파일을 생성해 보세요:\n\nk8s/my-mongo-db.yml\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\napiVersion: mongodbcommunity.mongodb.com/v1\nkind: MongoDBCommunity\nmetadata:\n  name: my-mongo-db\n  namespace: mongo\nspec:\n  members: 3\n  type: ReplicaSet\n  version: \"7.0.11\"\n  security:\n    authentication:\n      modes: [\"SCRAM\"]\n  users:\n    - name: my-user\n      db: admin\n      passwordSecretRef: # a reference to the secret that will be used to generate the user's password\n        name: my-user-password\n        key: password\n      roles:\n        - name: clusterAdmin\n          db: admin\n        - name: userAdminAnyDatabase\n          db: admin\n      scramCredentialsSecretName: my-user-scram\n  additionalMongodConfig:\n    storage.wiredTiger.engineConfig.journalCompressor: zlib\n```\n\n이제 다음과 같이 적용할 수 있습니다:\n\n```bash\nkubectl apply -f k8s/my-mongo-db.yml\n```\n\n그리고 진행 상황을 다음과 같이 확인할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nkubectl get pods -n mongo\n```\n\n3개의 인스턴스가 생성될 때까지 기다리고 있어요. 제 MacBook Pro(M2 Max Apple 실리콘)에서 4노드 Kind 클러스터를 사용하면, 모든 3개의 인스턴스를 시작하는 데 약 5분 정도 걸렸어요.\n\n시작되고 나면, 다음 명령어로 서비스가 정상적으로 작동하는지 확인할 수 있어요:\n\n```js\nkubectl get svc -n mongo\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 하면:\n\n```js\nNAME              TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)     AGE\nmy-mongo-db-svc   ClusterIP   None         \u003cnone\u003e        27017/TCP   6m\n```\n\n## 데이터베이스 테스트\n\n우리 애플리케이션에서는 쿠버네티스 내부에서 직접 데이터베이스에 연결할 것입니다. 데이터베이스의 서비스를 이용해 DNS 이름으로 연결하려고 하지만, 테스트 목적으로는 로컬 개발 머신에서 연결하고 싶습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n처음으로 이를 시도할 때 로컬 개발 머신으로 MonogoDB 파드 중 하나를 포워딩하기 위해 포트 포워딩을 사용했고, 어떤 변경을 시도했을 때 다음과 같은 오류 메시지를 받았습니다:\n\n```js\nMongoServerError[NotWriteablePrimary]: not primary\n```\n\n이것은 포트 포워딩한 파드가 클러스터의 주 파드가 아니기 때문에 발생한 문제입니다. 보조 파드는 읽기 전용 복사본이기 때문에 모든 쓰기 작업은 주 파드를 통해 이루어져야 합니다.\n\n이 문제를 피하려면 주 파드에 연결해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 노드가 기본 노드인지 알고 싶다면 다음 노드 중 하나의 로그를 조사하면 됩니다:\n\n```js\nkubectl logs my-mongo-db-0 -n mongo -c mongod | grep \"\\\"primary\\\":\"\n```\n\n만약 결과가 없다면, 기본 노드에 도달한 것입니다.\n\n만약 결과를 얻는다면, 몇 줄만 출력될 수 있지만, 그것들은 매우 길고 읽기 어려울 수 있습니다. JSON pretty printer 같은 것(jq와 같은)을 가지고 있다면 다음을 사용할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nkubectl logs my-mongo-db-0 -n mongo -c mongod | grep \"\\\"primary\\\":\" | jq\n```\n\n그러면 다음과 같은 줄을 볼 수 있습니다:\n\n```js\n...\n\"primary\": \"my-mongo-db-1.my-mongo-db-svc.mongo.svc.cluster.local:27017\",\n...\n```\n\n여기에 연결해야 하는 pod의 이름이 나옵니다 (제 경우: my-mongo-db-1). 이제 해당 pod를 포트 포워드할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nkubectl port-forward my-mongo-db-1 -n mongo 27017:27017\n```\n\n이 포트 포워딩이 설정되면 데이터베이스에 연결해야 합니다. MongoDB Compass 클라이언트를 사용할 수 있습니다. 해당 클라이언트는 https://www.mongodb.com/try/download/compass 에서 다운로드할 수 있습니다.\n\n설치 후 데이터베이스에 연결할 수 있어야 합니다. 연결 문자열(mongodb://localhost:27017)이 제안됩니다만, 몇 가지 설정을 변경해야합니다.\n\n고급 연결 옵션을 클릭하고 직접 연결을 클릭하십시오 (이 설정을 변경하지 않으면 내부 쿠버네티스 주소를 사용하려고 시도하여 찾을 수 없는 주소가 발생합니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인증 탭을 클릭해주세요. 사용자 이름/비밀번호를 선택하고 이전에 선택한 사용자 이름(my-user)과 비밀번호를 입력해주세요. Admin을 데이터베이스로 추가하고 SCRAM-SHA-256 인증 메커니즘을 선택해주세요 (필요하다면 아래로 스크롤).\n\n저장 및 연결을 클릭하고 연결 이름을 지정한 후, 데이터베이스에 연결된 Compass 콘솔이 표시됩니다.\n\n클러스터 내에서 admin, config 및 local 데이터베이스가 생성된 것을 확인하실 수 있습니다.\n\n여기까지 오셨다면, MongoDB 클러스터가 정상적으로 실행 중임을 의미합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 애플리케이션 사용자 생성\n\n우리의 MongoDB에 연결할 모든 애플리케이션이 우리가 생성한 my-user를 사용할 수 있을 것이라고 생각할 수 있습니다. 하지만, 이 사용자는 실제로 데이터베이스 유지 관리를 위한 것이기 때문에 그렇지 않습니다.\n\n애플리케이션이 데이터베이스 클러스터를 사용할 수 있도록하려면 데이터베이스와 해당 데이터에 액세스할 사용자를 생성해야 합니다.\n\nCompass 창의 맨 아래에 `_MONGOSH` 프롬프트가 나타납니다. 이를 클릭하여 명령줄에 액세스할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 다음과 같이 사용자를 생성할 것입니다:\n\n```js\nuse aquarium\ndb.createUser( { user: \"my-app-user\",\n              pwd: \"\u003cpassword\u003e\",\n              roles: [ {db: \"aquarium\", role: \"dbOwner\"} ] } )\n```\n\n알아둬야 할 몇 가지 사항이 있습니다. 첫번째로, 생성되기 전에 존재하지 않는 데이터베이스(aquarium)로 전환합니다. 이는 사용하기 전에 아무 것도 정의할 필요가 없다는 원칙에 부합합니다. 데이터베이스 및 모든 컬렉션은 문서를 추가할 때 처음 생성됩니다.\n\n두번째는 새 데이터베이스에 할당된 역할입니다. MongoDB에는 사용자에게 부여할 수 있는 소수의 기본 역할이 있습니다. 이 경우 dbOwner 역할은 사용자가 데이터베이스를 읽고 쓰고 관리할 수 있도록 합니다. 실제 운영에서는 사용자 권한을 적절히 제한해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n...\nok: 1,\n...\n```\n\n사용자를 확인하기 위해 새 Compass 연결을 열어보세요. 이는 메뉴를 통해 할 수 있습니다. 혹은 MacOS에서는 Cmd N을 누르세요. 창이 열릴 때까지 몇 초가 걸릴 수 있는데, 아무런 표시가 없으므로 한 번만 누르세요!\n\n새 연결 창이 나타나면, 이전에 저장한 연결을 복제하는 것이 더 쉽다고 생각합니다(연결 옆의 ... 메뉴를 사용하세요).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사용자 이름과 비밀번호를 변경해주세요. 또한 Authentication Database를 aquarium으로 변경해주세요. 그런 다음 연결하세요.\n\n이제 새로운 aquarium 데이터베이스를 확인할 수 있어야 합니다. \"fishes\"라는 collection을 생성해보면서 테스트해 볼 수 있습니다. 데이터베이스에 문서 형태로 데이터를 추가할 수 있습니다.\n\n```js\n{\n  \"_id\": 123,\n  \"fish\": \"Guppy\"\n}\n```\n\n이 시점에서 Spring Boot 애플리케이션과 함께 사용할 준비가 된 MongoDB가 준비되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 스프링 부트 애플리케이션 만들기\n\n간단한 데이터베이스 지원 예제를 만들 때는 제가 제일 먼저 수족관 애플리케이션을 사용합니다. REST API를 사용하여 물고기와 수족관을 만들고 관리할 수 있습니다. 그런 다음 물고기를 여러분의 수족관 중 하나에 추가할 수 있습니다.\n\n## 코드\n\n저는 코드를 여기에 포함하려는 의도는 없지만 관련된 GitHub 저장소에서 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 종속성\n\nSpring Boot 애플리케이션을 시작하는 것은 항상 https://start.spring.io/에서 Spring Initializr를 사용하는 것이 더 쉽습니다. 사용 방법을 알고 있다고 가정합니다.\n\n이 프로젝트에서 Spring Web과 Spring Data MongoDB를 종속성으로 추가하고 프로젝트를 생성합니다.\n\n## 패키지 구조\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n내가 만드는 애플리케이션에 따라, 패키지 구조를 구성하는 데 컴포넌트 유형(예: 컨트롤러, 서비스 및 리포지토리)에 기반을 둘 수도 있고, 비즈니스 도메인에 기반을 둘 수도 있습니다.\n\n물고기와 수조 두 가지 비즈니스 도메인만 있는 작은 애플리케이션인 경우, 이 프로젝트를 이러한 도메인을 기반으로 해서 다음과 같이 만들 것입니다:\n\n```js\nfishes;\nFishController;\nFishService;\nFishRepository;\nfishtanks;\nFishTankController;\nFishTankService;\nFishTankRepository;\n```\n\n보시다시피, 컨트롤러, 서비스 및 리포지토리 레이어를 사용하여 표준 계층 구조를 따르고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## API 엔드포인트\n\n이 컨트롤러들은 각각의 API에 대해 생성, 조회, 업데이트 및 삭제 (CRUD) 엔드포인트를 제공합니다.\n\n## 엔티티 및 문서\n\n만약 JPA와 Postgres와 같은 SQL 데이터베이스에 익숙하다면, 엔티티와 리포지토리로 익숙할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNo-SQL 데이터베이스에서는 테이블이 컬렉션으로 대체되고, 테이블 내의 행은 문서로 대체됩니다.\n\n이는 No-SQL 데이터베이스를 위한 리포지토리가 SQL 데이터베이스와는 조금 다르다는 것을 의미합니다.\n\nNo-SQL 데이터베이스는 어떤 구조든 다룰 수 있기 때문에, 엔티티(또는 문서)는 간단한 Plain Old Java Objects (POJOs)가 됩니다. 이는 우리 예시 애플리케이션에서 다음과 같이 엔티티를 생성할 수 있다는 것을 의미합니다:\n\naquarium/fishes/Fish.java\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n...\n\n@Setter\n@Getter\n@Document(\"fishes\")\n@NoArgsConstructor\npublic class Fish {\n\n  @Id\n  public UUID id;\n\n  public String type;\n\n  public Fish(String type) {\n      this.id = UUID.randomUUID();\n      this.type = type;\n  }\n  ...\n}\n```\n\n친구야, 여기 몇 가지 주의할 점이 있어요:\n\n- @Entity를 정의하는 대신 컬렉션의 이름을 사용하는 @Document를 정의하고 있어요.\n- 자체 UUID Id를 관리할 수 있도록 @mongoId 대신에 (필수는 아니지만 MongoDB가 제공하지 않은 경우 MongoDB로 제공할 수 있기 때문에) @Id를 사용하고 있어요.\n- Lombok(예: @Getter)을 사용하여 보일러플레이트 코드 일부를 제거하는 것을 좋아해요.\n\n이제 비슷한 방식으로 물고기 수조를 만들 수 있어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수족관/fishtanks/FishTank.java\n\n```java\n@Setter\n@Getter\n@Document(\"fish tanks\")\n@NoArgsConstructor\npublic class FishTank {\n\n    @Id\n    public UUID id;\n\n    public String name;\n\n    public FishTank(String name) {\n        this.id = UUID.randomUUID();\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return String.format(\n                \"FishTank[id=%s, type='%s']\",\n                id.toString(), name);\n    }\n}\n```\n\n## Repositories\n\n자, 이제 우리의 문서들이 준비되었어요. 이제 이들에 어떻게 접근할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제가 보여드릴 것은 우리 저장소의 변경 사항입니다. 물고기 저장소를 예로 들어보겠습니다:\n\n```js\n...\npublic interface FishRepository extends MongoRepository\u003cFish, UUID\u003e {\n\n    public List\u003cFish\u003e findAll();\n\n    public Optional\u003cFish\u003e findFirstById(UUID id);\n\n    public Optional\u003cFish\u003e findFirstByType(String type);\n}\n...\n```\n\n이것이 SQL 데이터베이스에서 찾을 수 있는 Repository 유형과 거의 동일하다는 것을 알 수 있습니다. 유일한 차이점은 인터페이스가 CrudRepository가 아닌 MongoRespository를 확장한다는 것뿐입니다.\n\n한 대 다 및 다른 매핑 주제는 다른 기사로 미루겠습니다. 그래서 현재로서는 물고기와 어항을 생성하고 관리할 수 있을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 어플리케이션 속성\n\n데이터베이스와 작업할 때는 어플리케이션이 어떻게 연결해야 하는지를 알려줘야 합니다. 우리는 SQL 데이터베이스와 마찬가지로 어플리케이션 속성을 통해 이를 수행합니다.\n\n나는 Spring Boot 속성 파일에 YAML 파일을 사용하는 것을 선호하며, 내 구성은 다음과 같이 보입니다 (나의 값으로 ` ` 필드를 교체해주시기 바랍니다):\n\nresources/application.yml\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\nspring:\n  application:\n    name: aquarium-with-mongo-db\n\n  data:\n    mongodb:\n      host: localhost\n      port: 27017\n      database: aquarium\n      username: my-app-user\n      password: \u003cpassword\u003e\n```\n\n나중에 프로필에 대해 이야기할 때 다시 돌아올게요.\n\n## 컨트롤러 및 서비스\n\n이제 SQL 데이터베이스와 마찬가지로 컨트롤러와 서비스를 추가할 수 있습니다. GitHub 저장소에서 이용 가능하므로 별도로 제시하지 않겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 애플리케이션 테스트\n\n코드를 완성하거나(또는 제 저장소를 복제)하여 IDE 내에서 애플리케이션을 실행하십시오. 여전히 주 서버로 포트 포워딩 중인 경우, 애플리케이션이 시작되어야 합니다.\n\n그런 다음 다음 curl 명령을 사용하여 테스트할 수 있습니다:\n\n```js\ncurl localhost:8080/api/v1/fishes -H \"Content-Type: application/json\" -d '{\"type\": \"guppy2\"}'\ncurl localhost:8080/api/v1/fish-tanks -H \"Content-Type: application/json\" -d '{\"name\": \"big one\"}'\ncurl localhost:8080/api/v1/fishes\ncurl localhost:8080/api/v1/fish-tanks\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 컴퍼스 클라이언트로 이동하여 아쿠아리움 데이터베이스를 새로 고침하면 fishes 및 fish tanks 두 개의 컬렉션이 표시됩니다. 이러한 컬렉션 내에는 만든 fishes 및 fish tanks가 표시됩니다.\n\n# 최종 단계\n\n이 시점에서 저희는 쿠버네티스 클러스터에서 실행 중인 MongoDB에 연결된 Spring Boot 애플리케이션을 갖추었습니다. 이제 해야 할 마지막 단계, 즉 Spring Boot 애플리케이션을 쿠버네티스 클러스터에 로드하는 것이 남았습니다.\n\n이를 위해 다음을 수행해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 팻 JAR 파일을 생성합니다 (모든 종속성이 포함됨)\n- 해당 JAR에서 Docker 이미지를 생성합니다\n- 이미지를 Docker 저장소에 업로드합니다\n- 배포 매니페스트 파일을 생성합니다\n- 배포 매니페스트를 Kubernetes 클러스터에 적용합니다\n\n제가 Kind를 사용하고 있기 때문에, 3단계를 간단한 로드 단계로 대체할 수 있습니다. 이렇게 하면 Docker 저장소를 사용할 필요가 없습니다.\n\n## 프로필\n\nJAR 파일을 생성하기 전에 Spring Boot 프로필 두 개를 생성하는 것이 유용합니다. 이를 통해 애플리케이션을 연결된 모드 (지금까지 한 것처럼) 및 Kubernetes 클러스터 내에서 실행할 수 있습니다. Spring Boot 프로필 두 개를 생성하겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- `connected` ... 클러스터 외부에서 실행 중일 때 사용되는 모드\n- `local-cluster` ... 클러스터 내부에서 실행 중일 때 사용되는 모드\n\n현재 실행 중인 모드는 첫 번째입니다. 이는 우리가 간단히 application.yml(또는 application.properties) 파일을 application-connected.yml로 복사할 수 있다는 것을 의미합니다. 그런 다음 JVM 명령줄에 다음 JVM 인수를 추가할 수 있습니다:\n\n```js\n-Dspring.profiles.active=connected\n```\n\n로컬 클러스터 파일에 대해서도 동일한 작업을 수행하지만 이번에는 변경이 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n...\n  data:\n    mongodb:\n      host: my-mongo-db-svc.mongo.svc.cluster.local\n      port: 27017\n...\n```\n\nDNS 이름을 사용하여 올바른 팟에 연결할 수 있습니다. 팟에서 DNS 검색 규칙이 설정되어 있어 my-mongo-db-svc.mongo.svc와 같은 이름 일부를 생략할 수 있습니다. 이를 통해 다른 클러스터로 배포하고도 응용 프로그램이 작동할 수 있습니다.\n\n## 이미지 생성\n\n이제 이미지를 만드는 방법을 살펴보겠습니다. GitHub에 있는 프로젝트가 Gradle 프로젝트이므로 루트 프로젝트 폴더에서 다음과 같이 JAR 파일을 생성할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngradle build\n```\n\ngradle.build에 아래 내용이 추가되었음을 유의해주세요. 이는 manifest가 주 애플리케이션 파일을 가리키도록 합니다:\n\ngradle.build\n\n```js\njar {\n    manifest {\n        attributes \"Main-Class\": \"com.requillion_solutions.aquarium.AquariumWithMongoDbApplication\"\n    }\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 하면 jar 파일이 생성됩니다: build/libs/aquarium-with-mongo-db-0.0.1-SNAPSHOT.jar.\n\n도커 이미지를 만들기 위해서는 도커 파일이 필요합니다. 아래 내용대로 만들어보세요:\n\nDockerfile\n\n```js\nFROM openjdk:17.0.2-slim-buster\nRUN addgroup --system spring \u0026\u0026 useradd --system spring -g spring\nUSER spring:spring\nARG JAR_FILE=build/libs/*.jar\nCOPY ${JAR_FILE} app.jar\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\nEXPOSE 8080\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이는 Java 17 기반 이미지를 시작으로 합니다 (이것은 롬복과의 문제를 피하기 위해 필요합니다) 그리고 새 사용자 (spring)를 추가하여 루트로 실행하지 않도록 합니다. 그런 다음 JAR 파일이 이미지로 복사되고 응용 프로그램을 실행하는 엔트리포인트가 생성됩니다.\n\n다음 명령어로 도커 이미지를 생성하세요:\n\n```bash\ndocker build -t aquarium .\n```\n\n그리고 만약 Kind를 사용 중이라면, 다음 명령어로 직접 Kubernetes 클러스터에 로드하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nkind load docker-image aquarium\n```\n\n이 작업이 완료되면 클러스터에서 실행하기 위한 배포 매니페스트를 생성할 준비가 되었습니다.\n\n## 배포 매니페스트\n\n이제 쿠버네티스 클러스터에 도커 이미지를 로드했으므로 배포 매니페스트를 사용하여 배포할 수 있습니다. 다음 파일을 만들어주세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nk8s/deployment.yml\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: aquarium\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aquarium\n  template:\n    metadata:\n      labels:\n        app: aquarium\n    spec:\n      containers:\n        - name: aquarium\n          image: aquarium\n          imagePullPolicy: IfNotPresent\n          ports:\n            - containerPort: 8080\n          env:\n            - name: SPRING_PROFILES_ACTIVE\n              value: local-cluster\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: aquarium\n  namespace: default\nspec:\n  selector:\n    app: aquarium\n  type: NodePort\n  ports:\n    - port: 8080\n      targetPort: 8080\n      nodePort: 30080\n```\n\n알아두어야 할 사항이 몇 가지 있어요:\n\n- 어플리케이션이 default 네임스페이스에 배포되었어요 (네임스페이스가 지정되지 않으면 사용되는 곳이죠)\n- 레플리카는 1개뿐이에요\n- 이미지는 이전에 불러왔으므로, 이미지가 없을 때만 불러와요\n- 프로필은 local-cluster로 설정돼요\n- 서비스가 생성되어 어플리케이션의 포트 8080을 개발 머신의 포트 30080으로 매핑돼요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 다음과 같이 배포할 수 있습니다:\n\n```js\nkubectl apply -f k8s/deployment.yml\n```\n\n시작이 성공적으로 이루어졌는지 확인해보세요:\n\n```js\nkubectl get pods\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 번이 배포되면 API는 이전에 사용한 것과 동일한 curl 명령으로 테스트할 수 있습니다. 단, 포트를 30080으로 변경해 주세요.\n\n```js\ncurl localhost:30080/api/v1/fishes -H \"Content-Type: application/json\" -d '{\"type\": \"guppy2\"}'\ncurl localhost:30080/api/v1/fish-tanks -H \"Content-Type: application/json\" -d '{\"name\": \"big one\"}'\ncurl localhost:30080/api/v1/fishes\ncurl localhost:30080/api/v1/fish-tanks\n```\n\nCompass UI에서 새 문서를 확인할 수도 있습니다 (포트 포워드가 여전히 유지되는지 확인해 주세요).\n\n# 요약\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사는 Kind Kubernetes 클러스터로 MongoDB를 설치하고 Spring Boot 애플리케이션과 통합하는 과정에 대해 다루었습니다.\n\n이 연습은 꽤 간단하지만 그냥 어떻게 하는지 보여주는 것뿐입니다. 실제로는 보안, 백업 및 장애 조치에 작업이 필요할 것입니다.\n\n다른 기사에서는 문서간의 관계를 어떻게 관리할 수 있는지도 보여드릴 예정입니다.\n\n이 연습을 통해 No-SQL 데이터베이스가 Kubernetes와 Spring Boot와 간단하게 사용될 수 있다는 것을 보여줬으면 좋겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 글을 즐겁게 읽으셨기를 바라며, 새로운 것을 배우며 기술을 향상시켰기를 바랍니다. 작은 거라도 새로운 지식을 얻었다면 좋겠네요.\n\n이 글이 유익하게 느껴진다면, 박수 한 번 부탁드립니다. 그렇게 하면 미래에 어떤 글을 써야 하는지 파악할 수 있고, 다음 글을 결정하는 데 도움이 됩니다. 개선 사항이나 제안 사항이 있다면 메모나 답글로 추가해 주세요.\n","ogImage":{"url":"/assets/img/2024-06-19-MyexperienceaddingaMongoDBNo-SQLdatabasetomyKubernetescluster_0.png"},"coverImage":"/assets/img/2024-06-19-MyexperienceaddingaMongoDBNo-SQLdatabasetomyKubernetescluster_0.png","tag":["Tech"],"readingTime":29},{"title":"Argo CD v212 릴리스 후보판","description":"","date":"2024-06-19 12:59","slug":"2024-06-19-ArgoCDv212ReleaseCandidate","content":"\n저희가 기쁜 마음으로 Argo CD v2.12 릴리스 후보판이 공개되었다는 소식을 전해드립니다! 이번 릴리스에는 30개 이상의 새로운 기능, 70여 개의 버그 수정, 그리고 60개의 문서 업데이트가 포함되어 있어요.\n\n곧바로 릴리스 후보판을 테스트하고 마주한 어떤 버그나 문제에 대한 피드백을 보내주시면 감사하겠습니다. 이는 여러분이 의견을 전할 수 있고 Argo CD가 더 나아지도록 도와줄 수 있는 큰 기회입니다.\n\n# Multi-source application advancements\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여러 소스에서 Argo CD 애플리케이션을 생성하는 것은 오랜 시간 동안 가장 요청이 많았던 Argo CD 기능 중 하나였습니다. 이 기능을 통해 여러 위치(예: 공개 Helm 차트 및 로컬 값 파일)에서 정보를 그룹화하여 단일 Argo CD 애플리케이션을 형성할 수 있습니다. 여러 소스를 정의하는 초기 지원은 이미 Argo CD 버전 2.6에 추가되었고, CLI를 위한 지원은 2.11에 추가되었습니다. UI는 여전히 애플리케이션이 단일 소스를 가지고 있다고 가정하고 롤백과 같은 특정 CLI 기능은 여러 소스를 가진 애플리케이션에 대해 아직 지원되지 않았습니다.\n\nArgo CD 버전 2.12에서는 여러 소스 애플리케이션의 롤백이 이제 Argo CD UI 및 CLI에서 모두 가능합니다.\n\n롤백 기능 외에도, 애플리케이션 세부 정보 페이지에 새로운 \"소스\" 탭이 추가되어 사용자가 애플리케이션의 소스를 관리(보기 및 편집)할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-ArgoCDv212ReleaseCandidate_1.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nKeith Chong (Red Hat)과 Jorge Turrado에게 이러한 기능들을 구현해 줘서 감사합니다.\n\n# 프로젝트별 저장소 자격증명 개선사항\n\n현재 Argo CD API에서는 동일한 URL을 공유하는 여러 저장소 자격증명을 허용하지 않습니다. 저장소 자격증명이 argocd 네임스페이스에 직접 추가된 경우, argocd-server는 오류를 반환하지 않지만 이 작업은 작동하지 않습니다. URL과 일치하는 첫 번째 시크릿이 반환되며 순서도 정의되어 있지 않기 때문입니다.\n\nArgo CD 버전 2.12부터는 여러 앱 프로젝트가 동일한 URL을 가진 별도의 저장소 자격증명을 가질 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n안녕하세요 Blake Pettersson님(Akuity)!\n\n# Kubernetes 이벤트에 레이블 추가하기\n\nArgo CD 버전 2.12에서 사용자들은 Argo CD에서 생성된 k8s 이벤트에 애플리케이션 레이블을 노출할 수 있게 될 것입니다. `resource.includeEventLabelKeys`에서 정의된 특정 레이블 키를 가진 애플리케이션에 대해 생성된 이벤트에 대응하는 레이블이 이벤트에 첨부될 것입니다. 이 연결은 이러한 레이블을 사용하는 애플리케이션을 기반으로 이벤트를 필터링하거나 처리하는 것을 더 간단하게 만들어 줍니다.\n\n이 기능을 구현해준 Siddhesh Ghadi(Red Hat)님에게 감사드립니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 일관성있는 샤딩 알고리즘\n\nArgo CD는 다른 Argo CD 애플리케이션 컨트롤러에 대한 샤딩 적용 기능을 제공합니다. 이를 통해 특정 클러스터를 특정 컨트롤러에 할당하여 부하를 다양한 샤드로 분산시킬 수 있습니다.\n\n기존의 샤딩 알고리즘인 레거시 방법과 라운드 로빈 알고리즘을 포함한 기존 방식은 최적의 부하 분산 유지와 불필요한 클러스터-샤드 할당 변경을 최소화하는 데 제한 사항이 있었습니다.\n\nArgo CD 버전 2.12부터 새로운 샤딩 알고리즘인 \"일관적 해싱(consistent-hashing)\"이 소개되었으며, 이는 클러스터-샤드 할당 변경을 줄이고 리소스 이용률을 최적화합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이번 특징을 구현한 Akram Ben Aissi (Red Hat)에게 감사드립니다.\n\n# 기타 주목할만한 변경 사항\n\n릴리스에 추가된 몇 가지 새로운 변경 사항은 다음과 같습니다.\n\n- 시멘틱 버전 태그 해결을 위한 git 클라이언트 업데이트 (Stone Payments의 Pablo Aguilar가 수행)\n- Application Set Git Generator가 이제 GPG 서명 확인을 지원합니다 (Red Hat의 Ishita Sequeira가 수행)\n- ls-remote 요청 실패 지표 추가 (Jack-R-lantern이 수행)\n- 새로운 주석 argocd.argoproj.io/sync-options: Force=true 추가 (CyberAgent, Inc.의 Kota Kimura가 수행)\n- gRPC 메시지 크기를 환경 변수로 설정하는 지원 추가 (Codefresh의 Pavel Kostohrys가 수행)\n- 삭제 팝업에서 종속 리소스 목록 표시 (Intuit의 Alexandre Gaudreault가 수행)\n- old tracking label applications.argoproj.io/app-name에 대한 지원 제거 (Akuity의 Soumya Ghosh Dastidar가 수행)\n- Argo CD CLI에 대한 fish 쉘 완성 지원 추가 (Sn0rt가 수행)\n- 로컬로 존재하는 체크아웃할 커밋이 있는 경우 git fetch 호출 건너뛰기 (Shady Rafehi가 수행)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 새 릴리스는 어디에서 받을 수 있나요?\n\n더 자세한 내용과 설치 지침은 릴리스 노트와 업그레이드 지침을 확인해주세요. 릴리스 후보를 시도하고 피드백을 공유해주세요. Argo 커뮤니티의 모든 기여자와 사용자들께 기여, 피드백 및 릴리스 테스트에서 도와준 점에 크게 감사드립니다!\n","ogImage":{"url":"/assets/img/2024-06-19-ArgoCDv212ReleaseCandidate_0.png"},"coverImage":"/assets/img/2024-06-19-ArgoCDv212ReleaseCandidate_0.png","tag":["Tech"],"readingTime":5},{"title":"도커에서 자체 서명 인증서를 사용한 NGINX","description":"","date":"2024-06-19 12:57","slug":"2024-06-19-NGINXwithSelf-SignedCertificateonDocker","content":"\n\u003cimg src=\"/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_0.png\" /\u003e\n\n저희 코드를 작업하는 동안 HTTPS에서 작업이 잘되는지 또는 더 중요한 것은 HTTPS에서 작동하는 방식을 빠르게 확인해야할 때가 많습니다. 온라인에서는 CSR(Certificate Sign Request)를 생성하고 해당 CSR을 자체로 서명하고 웹 서버의 구성을 수동으로 수정하여 해당 인증서를 사용하도록 만드는 방법을 보여주는 가이드가 많이 있습니다.\n\n이 기사에서는 어떤 것도 생성하거나 수동으로 편집하지 않고도 도커를 사용하여 자체 서명된 인증서가 있는 NGINX 컨테이너를 빠르게 실행하는 완전 자동화된 프로세스를 제시하겠습니다!\n\n# 보안 주의사항과 경고\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 자체 서명된 인증서는... 당신만 신뢰할 수 있습니다. 생산 환경에서 데이터를 제공하는 수단으로 사용할 수 없습니다. 그런 경우에는 적절한 인증서를 사용하세요.\n- 이 글에서 제시된 HTTPS로 콘텐츠를 제공하게끔 NGINX 구성은 작업을 수행하기 위한 최소한의 것입니다. 본격적인 TLS가 적용된 프로덕션 NGINX를 수정하려면 공식 가이드를 참고하세요.\n\n공개 키 암호화를 처음 시작하는 경우, 도움이 될 수 있는 소개 기사를 작성했습니다.\n\n# 설계 디자인\n\n빌드는 2단계 Docker 빌드로 설계되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_1.png\" /\u003e\n\n첫 번째 단계에서 Alpine Linux 이미지를 사용합니다. Alpine의 패키지 관리자인 APK를 사용하여 OpenSSL을 설치합니다. 다음 단계에서 OpenSSL을 사용하여 셀프 서명 인증서와 관련 개인 키를 생성합니다.\n\n두 번째 단계에서 NGINX 이미지를 사용합니다. 빌드는 이전 단계에서 생성된 인증서와 개인 키를 포함하도록 이미지를 수정하고 HTTPS를 활성화하기 위한 간단한 NGINX 구성을 작성합니다.\n\n# Dockerfile\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```dockerfile\n# syntax=docker/dockerfile:1\n# 이 Dockerfile을 빌드하려면 Docker BuildKit가 활성화되어 있어야 합니다.\n\n# 사용할 Alpine 및 NGINX 버전을 정의합니다.\nARG ALPINE_VERSION=3.17.3\nARG NGINX_VERSION=1.23.4\n\n# OpenSSL을 사용하기 위해 Alpine 기반 이미지를 준비합니다.\nFROM alpine:${ALPINE_VERSION} as alpine\nARG DOMAIN_NAME=localhost\nARG DAYS_VALID=30\n\nRUN apk add --no-cache openssl\nRUN echo \"${DAYS_VALID}일 동안 유효한 ${DOMAIN_NAME} 도메인을 위한 자체 서명 인증서를 생성합니다.\" \u0026\u0026 \\\n    openssl \\\n    req -x509 \\\n    -nodes \\\n    -subj \"/CN=${DOMAIN_NAME}\" \\\n    -addext \"subjectAltName=DNS:${DOMAIN_NAME}\" \\\n    -days ${DAYS_VALID} \\\n    -newkey rsa:2048 -keyout /tmp/self-signed.key \\\n    -out /tmp/self-signed.crt\n\n# 위에서 생성한 인증서를 사용하여 NGINX 기반 이미지를 준비합니다.\nFROM nginx:${NGINX_VERSION} as nginx\nCOPY --from=alpine /tmp/self-signed.key /etc/ssl/private\nCOPY --from=alpine /tmp/self-signed.crt /etc/ssl/certs\nCOPY \u003c\u003cEOF /etc/nginx/conf.d/default.conf\nserver {\n    listen 80;\n    listen [::]:80;\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    ssl_certificate /etc/ssl/certs/self-signed.crt;\n    ssl_certificate_key /etc/ssl/private/self-signed.key;\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n}\nEOF\n```\n\n👉 위의 Dockerfile을 시도하기 전에 Docker BuildKit가 활성화되어 있는지 확인해주세요. BuildKit는 레거시 빌더를 대체하는 개선된 백엔드로, Docker 데스크톱 및 Docker Engine 버전 23.0부터 사용자들에게 기본 빌더로 제공됩니다.\n\n## Stage 1: 인증서 생성\n\n인증서 및 개인 키를 생성하기 위해 OpenSSL을 사용하며 필요한 모든 정보를 인수로 전달하여 대화형 모드가 아닌 모드에서 명령을 실행합니다. 다음과 같은 Docker ARG를 지정하여 이 단계를 자신의 요구에 맞게 조정할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- DOMAIN_NAME: 이는 인증서가 유효한 도메인입니다. 이는 자체 서명된 인증서이므로 여기에 지정한 도메인 이름은 중요한 역할을 하지 않지만, 해당 인증서를 사용해야 하는 응용 프로그램이 있는 경우, 액세스할 리소스의 도메인 이름과 일치하도록 변경해야 할 수 있습니다. 빌드에 사용된 기본 도메인은 localhost입니다.\n- DAYS_VALID: 인증서가 유효한 일수입니다. 테스트를 완료할 수 있도록 충분히 큰 숫자를 사용하십시오. 빌드에 사용된 기본 유효 기간은 30일입니다.\n\n## 단계 2: 수정된 NGINX 이미지 생성\n\n이 단계에서는 이전 단계에서 생성된 인증서와 개인 키를 가져와 새로 생성된 이미지로 복사합니다. 또한 HTTPS를 활성화하기 위해 간단한 NGINX 구성을 생성하기 위해 heredoc를 사용합니다.\n\n직접 이미지 상에 다른 구성을 사용하려는 경우, heredoc를 자체 콘텐츠로 대체하거나 결과 이미지를 확장하여 자체 이미지에 추가할 수 있습니다. 이미지를 자체 구성 파일로 확장하는 경우, 해당 파일은 다음 위치에 배치해야 합니다.\n/etc/nginx/conf.d/default.conf.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 이미지 빌드하기\n\n알파인 이미지와 NGINX 이미지는 매우 작기 때문에 빌드 속도가 정말 빠릅니다. 다음으로 빌드를 시작하세요:\n\n```bash\ndocker build . -t nginx-self-signed\n```\n\n![이미지](/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 이미지 실행하기\n\n이미지를 실행할 때, Docker Engine이 실행 중인 컴퓨터에서 80번 포트를 HTTP용, 그리고 443번 포트를 HTTPS용으로 사용할 수 있도록 해 주세요. 아래 명령어를 사용하여 컨테이너를 시작할 수 있습니다:\n\ndocker run -p 80:80 -p 443:443 nginx-self-signed\n\n![NGINXwithSelf-SignedCertificateonDocker_3](/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 이미지 테스트 중\n\n신뢰할 수 있는 curl을 사용해서 몇 가지 테스트를 해봅시다. 만약 도커 엔진이 로컬 호스트에서 실행되지 않는다면 localhost를 적절한 주소로 바꿔주셔야 합니다.\n\n## HTTP 접근\n\ncurl localhost\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Screenshot](/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_4.png)\n\n여기에 볼 건 별거 없어요. HTTP 접근은 예상대로 작동합니다.\n\n## HTTPS 접근\n\ncurl https://localhost\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_5.png\" /\u003e\n\n여기서 NGINX가 HTTPS 요청에 응답했지만 curl은 다음과 같은 오류로 처리를 거부했습니다:\n\ncurl: (60) SSL certificate problem: self signed certificate\n\n이것은 HTTPS를 위한 기본 TLS를 설정하는 데 사용된 자체 서명된 인증서가 컴퓨터에 의해 신뢰되지 않기 때문입니다. 그렇다면 어떻게 해야 할까요? 여기에는 몇 가지 다른 옵션이 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 자체 서명된 인증서를 OS의 신뢰/인증서 저장소에 가져올 수 있습니다.\n- curl에 보안 인증서를 수락하도록 지시할 수 있습니다.\n\n보안 인증서를 수락하도록 curl에 요청해 봅시다:\n\ncurl https://localhost --insecure\n\n![이미지](/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ncurl은 이제 기초 리소스의 내용을 즐겁게 출력합니다.\n\n마찬가지로, HTTPS URL을 인터넷 브라우저로 열어보려고 하면 보안 경고가 표시됩니다. 실제 경고 메시지와 진행 방법은 각각 다른 인터넷 브라우저마다 다를 수 있습니다. Chrome에서는 다음과 같이 표시됩니다:\n\n![Chrome에서의 보안 경고](/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_7.png)\n\nChrome에서 '고급' 버튼을 클릭한 다음 'localhost로 진행(안전하지 않음)' 옵션을 클릭할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_8.png\" /\u003e\n\n# 추가 콘텐츠\n\n가기 전에, 여기서 생성한 이미지를 사용하여 여러분 자신의 콘텐츠와 함께 사용할 수 있는 몇 가지 추가 팁이 있습니다.\n\n## 1. 여러분 자신의 콘텐츠 제공\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기본 NGINX 환영 페이지를 제공하는 것은 누구에게나 큰 가치가 없을 것 같아요. 자신의 콘텐츠로 사용자 정의 NGINX 이미지를 가리킬 수 있도록 로컬 폴더를 컨테이너에 마운트하면 됩니다:\n\n```js\ndocker run \\\n  -p 80:80 -p 443:443 \\\n  -v {YOUR-PATH}:/usr/share/nginx/html \\\nnginx-self-signed\n```\n\n## 2. 자신의 콘텐츠에 대한 역방향 프록시 구성\n\n컨테이너 내부에 콘텐츠를 마운트하고 싶지 않을 경우, NGINX를 구성하여 이미 실행 중인 다른 서버에 대한 역방향 프록시로 사용할 수 있습니다. 다음 코드 조각은 이러한 구성을 설정하는 데 도움이 되나요. 그러나 역방향 프록시는 아래의 간단한 예제보다 더 복잡한데, 실제로 프록시하는 내용에 따라 다양한 문제가 발생할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNGINX 설정 파일의 상단에 upstream 서버를 정의해주세요:\n\n```js\nupstream api-gateway {\n  server http://some-server:80;\n}\n```\n\nNGINX 설정 파일의 server 블록을 다음과 같이 업그레이드해주세요:\n\n```js\nlocation /api/ {\n    proxy_pass                http://api-gateway;\n    proxy_redirect            off;\n    proxy_set_header          X-Real-IP $remote_addr;\n    proxy_set_header          X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header          X-NginX-Proxy true;\n    proxy_ssl_session_reuse   off;\n    proxy_set_header Host     $http_host;\n    proxy_cache_bypass        $http_upgrade;\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n이 글에서는 자체 서명 인증서를 사용하는 NGINX 도커 컨테이너를 빠르게 설정하는 방법을 소개했습니다. 컴퓨터에 OpenSSL을 설치할 필요가 없으며 인증서를 생성하기 위해 openssl 명령을 실행할 필요가 없습니다. 모든 작업이 Docker 빌드의 일부로 실행됩니다.\n\n또한 결과물인 NGINX 이미지에 자신의 콘텐츠를 통합하는 두 가지 예제를 제공했습니다. 컨테이너 내에서 콘텐츠를 마운트하거나 이미 실행 중인 다른 서버로 역방향 프록시하는 방법 등이 있습니다.\n\n이 글을 읽어주셔서 감사합니다. 다음 글에서 다시 뵙기를 기대합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n🔔 새 이야기를 발행할 때마다 알림을 받고 싶으세요? 제 콘텐츠는 항상 제가 본 것이나 일했던 것을 바탕으로 한 실용적인 기술 팁과 소프트웨어 엔지니어링 조언을 제공합니다:\nhttps://nmichas.medium.com/subscribe\n\n🚀 아직 Medium 회원이 아니신가요? 커피 한 잔 가격으로 매월 제 이야기에 액세스할 수 있습니다 (그리고 Medium의 수천 명의 다른 작가들의 이야기에도):\nhttps://medium.com/@nmichas/membership\n","ogImage":{"url":"/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_0.png"},"coverImage":"/assets/img/2024-06-19-NGINXwithSelf-SignedCertificateonDocker_0.png","tag":["Tech"],"readingTime":12},{"title":"편리한 클라우드 배포 Terraform과 GitHub Actions를 활용하여 AWS에서 NET API와 Angular 프론트엔드를 런칭하기 PART 23","description":"","date":"2024-06-19 12:54","slug":"2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23","content":"\n\u003cimg src=\"/assets/img/2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23_0.png\" /\u003e\n\n# 소개\n\n이 기사에서는 이전 기사에서 시작한 설정을 계속할 것입니다: IaC 기본: Terraform 및 GitHub Actions를 사용한 RDS 배포. 목표는 AWS에서 완전히 기능하는 .NET 백엔드(API)를 구성하는 것입니다. 응용 프로그램은 공개적으로 액세스 가능하며 RDS 데이터베이스에 연결될 것입니다. 민감한 정보 검색에 Secrets Manager를 활용할 것입니다.\n\nPART 1에서 이미 다음을 설정했습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Terraform을 지원하기 위한 AWS 백엔드 (S3에 상태 파일, DynamoDB에 상태 잠금 기능 포함).\n- Terraform을 이용해 인프라를 배포하기 위한 GitHub Actions.\n- DBeaver를 사용하여 테스트된 공개적으로 접근 가능한 RDS 데이터베이스.\n\nPART 2에서는 다음을 다룰 예정입니다::\n\n- RDS, ECR 및 Secrets Manager를 포함한 인프라 저장소 설정.\n- Secrets Manager에 비밀을 전송하는 인프라 파이프라인 생성 (데이터베이스 호스트, 사용자, 비밀번호).\n- API용 Dockerfile 정의.\n- 어플리케이션을 위해 Docker 컨테이너를 실행하는 ECS 서비스 구성.\n- API를 노출시키기 위해 로드 밸런서 구현.\n\n이 글을 마치면 GitHub Actions와 Terraform을 이용해 CI/CD 파이프라인을 통해 AWS에서 .NET 백엔드를 완벽히 설정할 수 있게 될 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 인프라 구성하기\n\n나는 논리적 구성 요소를 별도의 저장소로 분리하기로 결정했습니다. 이 접근법은 구조를 읽기 쉽게 만들 뿐만 아니라 인프라스트럭처의 코드 (IaC) 정의를 단순화합니다.\n\n![이미지](/assets/img/2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23_1.png)\n\n인프라 프로젝트는 자주 변경되지 않는 리소스를 만드는 것에 책임을 지기 때문에 분리됩니다. 이 프로젝트에서는 RDS, ECR 및 Secrets Manager의 생성을 구성했습니다. 파이프라인은 RDS 확장, ECR 또는 Secrets Manager 이름 변경과 같은 경우에 가끔 실행해야 할 수 있지만, 이러한 인스턴스는 드물 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 설정을 사용하여 개별 환경(개발, 스테이징 및 프로덕션과 같은)을 관리하는 데 상당한 잠재력이 있습니다. 그러나 이 기사는 이 측면을 다루지 않도록 중점을 두고 있습니다.\n\n# App.Infra 프로젝트\n\n이전에 언급했듯이, 인프라 프로젝트는 RDS, ECR 저장소 및 Secrets Manager(보강에 RDS 암호 저장)를 설정합니다. 이 분리는 인프라 관점에서 상대적으로 정적인 이러한 구성 요소 때문에 의도적입니다. 또한, ECR 저장소가 준비되어 있어야 하는 것이 중요합니다. Docker 이미지의 대상 역할을 합니다. 따라서 빌드 순서도 관련이 있습니다.\n\n이제 테라폼 파일로 직접 들어가 봅시다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n공급업체 \"aws\" {\n  지역 = var.aws_region\n}\n\n리소스 \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n\n  tags = {\n    Name = \"main\"\n  }\n}\n\n리소스 \"aws_subnet\" \"main_subnet_1\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.1.0/24\"\n  availability_zone = \"eu-north-1a\"\n\n  tags = {\n    Name = \"main-subnet-1\"\n  }\n}\n\n리소스 \"aws_subnet\" \"main_subnet_2\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.2.0/24\"\n  availability_zone = \"eu-north-1b\"\n\n  tags = {\n    Name = \"main-subnet-2\"\n  }\n}\n\n리소스 \"aws_security_group\" \"rds_sg\" {\n  name        = \"rds_security_group\"\n  description = \"어디서나 접근 허용하는 RDS용 보안 그룹\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    from_port   = 5432\n    to_port     = 5432\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"rds_security_group\"\n  }\n}\n\n리소스 \"aws_db_subnet_group\" \"default\" {\n  name       = \"main-subnet-group\"\n  subnet_ids = [aws_subnet.main_subnet_1.id, aws_subnet.main_subnet_2.id]\n\n  tags = {\n    Name = \"main-subnet-group\"\n  }\n}\n\n리소스 \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n}\n\n리소스 \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.main.id\n  }\n}\n\n리소스 \"aws_route_table_association\" \"subnet_association_1\" {\n  subnet_id      = aws_subnet.main_subnet_1.id\n  route_table_id = aws_route_table.public.id\n}\n\n리소스 \"aws_route_table_association\" \"subnet_association_2\" {\n  subnet_id      = aws_subnet.main_subnet_2.id\n  route_table_id = aws_route_table.public.id\n}\n\n리소스 \"aws_db_instance\" \"default\" {\n  allocated_storage    = 20\n  engine               = \"postgres\"\n  engine_version       = \"16.2\"\n  instance_class       = var.db_instance_class\n  db_name              = var.db_name\n  username             = var.db_username\n  password             = var.db_password\n  parameter_group_name = \"default.postgres16\"\n  skip_final_snapshot  = true\n  publicly_accessible  = true\n\n  vpc_security_group_ids = [aws_security_group.rds_sg.id]\n  db_subnet_group_name   = aws_db_subnet_group.default.name\n}\n\n리소스 \"aws_ecr_repository\" \"app_repository\" {\n  name = \"app-repo\"\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n  image_tag_mutability = \"MUTABLE\"\n}\n\n리소스 \"aws_secretsmanager_secret\" \"rds_secret\" {\n  name        = \"app-secrets-manager\"\n  description = \"APP 비밀\"\n}\n\n리소스 \"aws_secretsmanager_secret_version\" \"rds_secret_version\" {\n  secret_id     = aws_secretsmanager_secret.rds_secret.id\n  secret_string = jsonencode({\n    DB_HOST     = aws_db_instance.default.endpoint\n    DB_USER     = var.db_username\n    DB_PASSWORD = var.db_password\n    DB_NAME     = var.db_name\n  })\n}\n```\n\n위 글에서는 VPC 및 RDS 구성요소가 PART 1에서 다뤄졌습니다. 이제 ECR 및 Secrets Manager에 집중해 보겠습니다.\n\n## ECR 리포지토리\n\n```js\n리소스 \"aws_ecr_repository\" \"app_repository\" {\n  name = \"app-repo\"\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n  image_tag_mutability = \"MUTABLE\"\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블록은 Docker 이미지를 저장하기 위한 Elastic Container Registry (ECR) 리포지토리를 생성하며, 이미지 푸시 시 이미지 스캔이 활성화되어 있습니다.\n\n## Secrets Manager\n\n```js\nresource \"aws_secretsmanager_secret\" \"rds_secret\" {\n  name        = \"app-secrets-manager\"\n  description = \"APP secrets\"\n}\n\nresource \"aws_secretsmanager_secret_version\" \"rds_secret_version\" {\n  secret_id     = aws_secretsmanager_secret.rds_secret.id\n  secret_string = jsonencode({\n    DB_HOST     = aws_db_instance.default.endpoint\n    DB_USER     = var.db_username\n    DB_PASSWORD = var.db_password\n    db_name     = var.db_name\n  })\n}\n```\n\n이 블록은 Secrets Manager를 생성하고 그 안에 RDS 데이터베이스 자격 증명을 저장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n액션 정의는 기사의 이전 부분과 비교해 변경되지 않았습니다. 우리는 표준 경로를 실행합니다: AWS에 로그인 - `Init` - `Validate` - `Plan` - `Apply Terraform`. Github 액션을 활성화하고 실행합니다. 결과적으로 로컬 DB 클라이언트에서 RDS와 통신할 수 있어야 하며, AWS 콘솔에서 연결 문자열을 구축하기 위한 미리 입력된 시크릿이 포함된 Secrets Manager와 ECR(컨테이너 레지스트리)를 찾아야 합니다.\n\n## C#을 사용하여 Secrets Manager에 액세스\n\n어플리케이션의 보안을 보장하는 것은 인터넷에 노출되는 서비스를 개발하는 중요한 측면입니다. 코드나 환경 변수또는 Docker 컨테이너에 비밀번호를 저장하면 민감한 정보가 노출될 수 있습니다. 더 안전한 접근 방식은 민감한 데이터를 관리하기 위해 AWS Secrets Manager를 사용하는 것입니다.\n\n아래에서는 AWS Secrets Manager에 저장된 시크릿을 사용하여 PostgreSQL 연결 문자열을 구성하는 방법을 보여드리겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 AWSSDK.SecretsManager nuget을 다운로드해야 합니다. 작업이 완료되면 SecretsManagerService를 빌드해 봅시다:\n\n```js\nusing Amazon;\nusing Amazon.SecretsManager;\nusing Amazon.SecretsManager.Model;\n\nnamespace AppMonitor.AWS\n{\n    public class SecretsManagerService\n    {\n        private readonly IAmazonSecretsManager _secretsManager;\n\n        public SecretsManagerService(IAmazonSecretsManager secretsManager)\n        {\n            _secretsManager = secretsManager;\n        }\n\n        public async Task\u003cstring\u003e GetSecretValueAsync(string secretName)\n        {\n            var request = new GetSecretValueRequest\n            {\n                SecretId = secretName\n            };\n\n            var response = await _secretsManager.GetSecretValueAsync(request);\n            return response.SecretString;\n        }\n    }\n}\n```\n\n다음으로, DBConnectionStringProvider 클래스에서 SecretsManagerService를 사용합니다:\n\n```js\nusing Newtonsoft.Json.Linq;\nusing System.Configuration;\n\nnamespace AppMonitor.AWS\n{\n    public class AwsDatabaseConnectionStringProvider\n    {\n        private readonly SecretsManagerService _secretsManagerService;\n\n        public AwsDatabaseConnectionStringProvider(SecretsManagerService secretsManagerService)\n        {\n            _secretsManagerService = secretsManagerService;\n        }\n\n        public async Task\u003cstring\u003e GetConnectionStringAsync()\n        {\n            var secretValue = await _secretsManagerService.GetSecretValueAsync(\"app-secrets-manager\");\n            var secretJson = JObject.Parse(secretValue); //newtonsoft.json\n\n            var host = secretJson[\"DB_HOST\"].ToString();\n            var user = secretJson[\"DB_USER\"].ToString();\n            var password = secretJson[\"DB_PASSWORD\"].ToString();\n            var dbName = secretJson[\"DB_NAME\"].ToString();\n\n            return $\"Host={host};Port=5432;Database={dbName};User ID={user};Password={password};\";\n        }\n    }\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로, 우리 스타트업에서 서비스를 설정해야 합니다 (이 스니펫은 AWSSDK.Extensions.NETCore.Setup 너겟을 필요로 합니다):\n\n```js\n  context.Services.AddAWSService\u003cIAmazonSecretsManager\u003e();\n  context.Services.AddSingleton\u003cSecretsManagerService\u003e();\n  context.Services.AddSingleton\u003cAwsDatabaseConnectionStringProvider\u003e();\n```\n\n# .NET 앱을 위한 Docker 이미지 빌드\n\n도커는 가벼운 이식 가능한 컨테이너를 생성함으로써 응용 프로그램을 패키지화하고 배포하는 효율적인 방법을 제공합니다. 이러한 컨테이너는 쉽게 ECR로 푸시하고 AWS의 ECS 서비스로 배포할 수 있습니다. 아래는 우리 .NET 애플리케이션을 위한 Dockerfile입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base\nWORKDIR /app\nEXPOSE 44360\n\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build\nWORKDIR /src\n\nCOPY [\"AppMonitor/\", \"AppMonitor/\"]\nRUN dotnet restore \"TheApp/TheApp.csproj\"\n\nCOPY . .\n\nWORKDIR \"/src/TheApp\"\nRUN dotnet build \"TheApp.csproj\" -c Release -o /app/build\n\nFROM build AS publish\nRUN dotnet publish \"TheApp.csproj\" -c Release -o /app/publish\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\n\nENV ASPNETCORE_URLS=http://*:44360\nENTRYPOINT [\"dotnet\", \"TheApp.dll\"]\n```\n\n다음 부분에서는 ECS를 구성하여 이 Docker 컨테이너를 실행하고 API를 노출하는 로드 밸런서를 구현할 것입니다.\n\n## ECS 및 로드 밸런서 소개\n\nAmazon Elastic Container Service (ECS)는 Docker를 사용하여 컨테이너화된 응용 프로그램을 배포, 관리 및 확장하기 쉽게 만들어주는 완전관리형 컨테이너 오케스트레이션 서비스입니다. ECS를 활용하면 기본 인프라를 관리할 필요없이 응용 프로그램을 구축하는 데 집중할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로드 밸런서(LB)는 여러 대상(예: ECS 작업) 사이로 들어오는 응용 프로그램 트래픽을 분산하는 서비스입니다. 로드 밸런서는 트래픽을 건강한 대상으로 라우팅하고 부하를 균형있게 분배하여 리소스 활용을 최적화하여 고가용성과 신뢰성을 보장합니다.\n\n이 설정에서는 우리의 ECS 작업이 AWS Secrets Manager에 액세스하는 권한을 갖게되어 민감한 데이터의 안전한 관리를 보장합니다. 작업은 애플리케이션별 트래픽을 허용하도록 구성된 보안 그룹이 구성된 VPC에 배포될 것입니다. 애플리케이션 로드 밸런서(ALB)는 ECS 작업 간의 트래픽을 분산하여 부드럽고 신뢰할 수 있는 응용 프로그램 성능을 보장합니다.\n\n## ECS를 위한 Terraform 구성\n\n코드 예시\n\n# main.tf\n\nprovider \"aws\" {\nregion = \"eu-north-1\"\n}\n\ndata \"aws_vpc\" \"main\" {\nfilter {\nname = \"tag:Name\"\nvalues = [\"main\"]\n}\n}\n\n...\n\nresource \"aws_iam_role_policy\" \"ecs_task_secrets_policy\" {\nname = \"ecs-task-secrets-policy\"\nrole = aws_iam_role.ecs_task_execution_role.id\n\npolicy = jsonencode({\nVersion = \"2012-10-17\",\nStatement = [\n{\nEffect = \"Allow\",\nAction = [\n\"secretsmanager:GetSecretValue\"\n],\nResource = \"\\*\"\n}\n]\n})\n}\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# load_balancer.tf\n\nresource \"aws_lb\" \"app_lb\" {\n  name               = \"app-lb\"\n  internal           = false\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.ecs_sg.id]\n  subnets            = [data.aws_subnet.main_subnet_1.id, data.aws_subnet.main_subnet_2.id]\n\n  enable_deletion_protection = false\n}\n\nresource \"aws_lb_listener\" \"http_listener\" {\n  load_balancer_arn = aws_lb.app_lb.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.app_tg.arn\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_lb_target_group\" \"app_tg\" {\n  name     = \"app-tg\"\n  port     = 80\n  protocol = \"HTTP\"\n  vpc_id   = data.aws_vpc.main.id\n  target_type = \"ip\"\n\n  health_check {\n    interval            = 30\n    protocol            = \"HTTP\"\n    timeout             = 5\n    healthy_threshold   = 5\n    unhealthy_threshold = 2\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_ecs_cluster\" \"main\" {\n  name = \"main-cluster\"\n}\n\nresource \"aws_ecs_service\" \"app_service\" {\n  name            = \"app-service\"\n  cluster         = aws_ecs_cluster.main.id\n  task_definition = aws_ecs_task_definition.app_task.arn\n  desired_count   = 1\n  launch_type     = \"FARGATE\"\n\n  network_configuration {\n    subnets         = [data.aws_subnet.main_subnet_1.id, data.aws_subnet.main_subnet_2.id]\n    security_groups = [aws_security_group.ecs_sg.id]\n    assign_public_ip = true\n  }\n\n  load_balancer {\n    target_group_arn = aws_lb_target_group.app_tg.arn\n    container_name   = \"app-container\"\n    container_port   = 44360\n  }\n\n  depends_on = [\n    aws_lb_listener.http_listener\n  ]\n}\n```\n\n## Provider and VPC Data Sources:\n\n- The aws provider is set to the eu-north-1 region.\n- Data sources are defined to fetch details of the existing VPC and subnets based on tags.\n\n## Security Group for ECS:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 보안 그룹 ecs_sg가 생성되어 HTTP, HTTPS 및 애플리케이션 트래픽 (포트 44360)을 허용하도록 설정되어 있습니다.\n\n## IAM 역할 및 인스턴스 프로필:\n\n- ECS 작업 실행 및 인스턴스 역할에 필요한 정책이 포함된 IAM 역할이 생성되었습니다.\n- 인스턴스 프로필이 생성되고 인스턴스 역할에 연결되었습니다.\n\n## 시작 구성 밑 오토 스케일링 그룹:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- ECS 인스턴스를 위한 ECS 최적화 AMI로 시작 구성이 생성됩니다.\n- Auto Scaling 그룹이 ECS 인스턴스의 원하는 용량을 유지하도록 구성되어 있습니다.\n\n## ECR Repository:\n\n- ECR 저장소인 app-repo가 Docker 이미지를 가져오도록 참조됩니다.\n\n## ECS 작업 정의:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 작업 정의는 Docker 컨테이너 구성을 지정하는 것으로, 이미지, 포트 매핑 및 환경 변수를 포함합니다.\n- 작업에는 AWS Secrets Manager에 액세스할 수 있도록 IAM 정책이 있습니다.\n\n## 로드 밸런서 구성:\n\n- 어플리케이션 로드 밸런서(ALB)가 설정되어 있으며, 리스너 및 타겟 그룹을 사용하여 ECS 작업으로의 트래픽 관리가 이루어집니다.\n- 건강 점검이 구성되어 ALB가 건강한 인스턴스에만 트래픽을 라우팅하도록 합니다.\n\n## ECS 클러스터 및 서비스:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- ECS 클러스터 main-cluster가 생성되었습니다.\n- ECS 서비스 app-service는 Fargate 런치 유형을 사용하도록 구성되어 있어, 자동 스케일링 기능을 갖춘 서버리스 운영이 보장됩니다.\n\n# Github 액션 정의 및 테스트\n\nGithub 액션의 워크플로우 정의는 간단하고 명확합니다. 도커 이미지 빌드 및 AWS 내 Elastic Container Registry로 푸시하는 것을 강조할 만한 유일한 사항입니다. YAML 정의로 들어가 봅시다:\n\n```js\nname: AWS로 배포\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: 코드 가져오기\n        uses: actions/checkout@v2\n\n      - name: .NET Core 설정\n        uses: actions/setup-dotnet@v1\n        with:\n          dotnet-version: '8.0.x'\n\n      - name: 종속성 복원\n        run: dotnet restore src\n\n      - name: 빌드\n        run: dotnet build src --configuration Release --no-restore\n\n      - name: 게시\n        run: dotnet publish src --configuration Release --output ./output\n\n      - name: 도커 빌드 설정\n        uses: docker/setup-buildx-action@v1\n\n      - name: Terraform을 위한 AWS 자격 증명 구성\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${secrets.AWS_ACCESS_KEY_ID}\n          aws-secret-access-key: ${secrets.AWS_SECRET_ACCESS_KEY}\n          aws-region: ${secrets.AWS_REGION}\n\n      - name: Amazon ECR에 로그인\n        id: login-ecr\n        uses: aws-actions/amazon-ecr-login@v1\n\n      - name: 도커 이미지 빌드 및 푸시\n        run: |\n          REPOSITORY_URI=$(aws ecr describe-repositories --repository-names app-repo --query \"repositories[0].repositoryUri\" --output text --region eu-north-1)\n          docker build -t $REPOSITORY_URI:latest -f src/Dockerfile src\n          docker push $REPOSITORY_URI:latest\n        env:\n          AWS_REGION: eu-north-1\n\n      - name: Terraform 설정\n        uses: hashicorp/setup-terraform@v1\n        with:\n          terraform_version: 1.8.5\n\n      - name: Terraform 초기화\n        run: terraform init -input=false\n        working-directory: infra\n\n      - name: Terraform 계획 수립\n        run: terraform plan -input=false\n        working-directory: infra\n        env:\n          TF_VAR_db_password: ${secrets.DB_PASSWORD}\n          TF_VAR_aws_region: ${secrets.AWS_REGION}\n\n      - name: Terraform 적용\n        id: apply\n        run: terraform apply -auto-approve -input=false\n        working-directory: infra\n        env:\n          TF_VAR_db_password: ${secrets.DB_PASSWORD}\n          TF_VAR_aws_region: ${secrets.AWS_REGION}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상기 GitHub 액션 설정은 .NET 앱을 AWS로 쉽게 배포할 수 있도록 해주는 내용입니다. 이 설정에는 .NET Core 설정부터 의존성 복원, 앱 빌드 및 게시, 그리고 컨테이너화를 위한 Docker 통합까지 모두 다루는 여러 단계가 포함되어 있습니다. 또한 AWS 자격 증명을 처리하고 Docker 이미지를 Amazon ECR에 빌드 및 푸시하며, Terraform을 사용하여 인프라 구축도 수행합니다. 기본적으로 전체 프로세스를 자동화하여 배포가 완전히 간편해집니다.\n\n빌드가 성공적으로 완료되면 API의 URL을 얻기 위해 AWS 콘솔을 방문해보세요.\n\n![이미지](/assets/img/2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23_2.png)\n\nDNS 이름을 가져와 브라우저에서 해당 URL을 열어보세요. 모든 것이 잘 되었다면 API 백엔드가 응답해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 요약\n\n조금 길었지만, Terraform을 사용하여 AWS에 컨테이너화된 .NET API를 배포하는 모든 중요한 단계를 다루었습니다. 이 가이드가 새 프로젝트를 처음부터 시작하거나 인프라 설정의 복잡성을 탐색하는 데 도움이 되기를 바랍니다. 화이팅!\n","ogImage":{"url":"/assets/img/2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23_0.png"},"coverImage":"/assets/img/2024-06-19-EffortlessclouddeploymentLaunchNETAPIwithAngularFrontendonAWSUsingTerraformandGitHubActionsPART23_0.png","tag":["Tech"],"readingTime":21},{"title":"Ollama - Langchain을 사용해 챗봇 만들기, 도커로 배포하기","description":"","date":"2024-06-19 12:53","slug":"2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker","content":"\n## 생성적 AI 시리즈\n\n이 블로그는 생성적 AI에 관한 지속적인 시리즈이며 이전 블로그의 연장선입니다. 이 블로그 시리즈에서는 Ollama를 탐색하고 도커를 사용하여 분산 아키텍처에 배포할 수 있는 응용 프로그램을 구축할 것입니다.\n\nOllama는 강력한 언어 모델을 손쉽게 컴퓨터에서 실행할 수 있도록 도와주는 프레임워크입니다. Ollama 소개에 대해서는 2024년 2월에 A B Vijay Kumar에 의해 작성된 [Ollama — Brings runtime to serve LLMs everywhere. | by A B Vijay Kumar | Feb, 2024 | Medium](링크)를 참조해주세요. 이 블로그에서는 langchain 애플리케이션을 구축하고 도커에 배포할 것입니다.\n\n## Ollama를 위한 Langchain 챗봇 애플리케이션\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLangshan을 사용하여 챗봇 애플리케이션을 개발해 보겠습니다. Python 애플리케이션에서 모델에 액세스하기 위해 간단한 Streamlit 챗봇 애플리케이션을 만들 것입니다. 이 Python 애플리케이션을 컨테이너에 배포하고 다른 컨테이너에서 Ollama를 사용할 것입니다. Docker-compose를 사용하여 인프라를 구축할 것입니다. 만약 Docker 또는 docker-compose를 사용하는 방법을 모르신다면, 계속 진행하기 전에 인터넷에서 몇 가지 자습서를 참고해 주세요.\n\n아래 그림은 컨테이너 간 상호 작용과 접근하는 포트를 보여주는 아키텍처를 보여줍니다.\n\n![아키텍처 그림](/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_0.png)\n\n컨테이너를 2개 생성할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Ollama 컨테이너는 모델을 저장하고 로드하기 위해 호스트 볼륨을 사용합니다 (/root/.ollama는 로컬 ./data/ollama로 매핑됩니다). Ollama 컨테이너는 내부적으로 11434로 매핑된 외부 포트인 11434에서 수신 대기합니다.\n- Streamlit 챗봇 애플리케이션은 내부적으로 8501로 매핑된 외부 포트인 8501에서 수신 대기합니다.\n  코딩을 시작하기 전에 Python 가상 환경을 설정하겠습니다.\n\n```shell\npython3 -m venv ./ollama-langchain-venv\nsource ./ollama-langchain-venv/bin/activate\n```\n\n다음은 streamlit 애플리케이션의 소스 코드입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_1.png\" /\u003e\n\n제가 이전 블로그에서 작성한 것과 매우 유사한 소스 코드입니다. 이 코드가 어떻게 작동하는지에 대한 자세한 내용은 다른 블로그인 \"Retrieval Augmented Generation(RAG) - LlamaIndex를 사용한 문서용 챗봇\"을 참조하실 수 있어요. 주요 차이점은 Ollama를 사용하고 Ollama Langchain 라이브러리를 통해 모델을 호출한다는 점이에요 (이는 langchain_community의 일부입니다).\n\nrequirements.txt에서 종속성을 정의해 봅시다.\n\n\u003cimg src=\"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_2.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 Streamlit 애플리케이션의 도커 이미지를 빌드하기 위한 Dockerfile을 정의해 보겠습니다.\n\n![image](/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_3.png)\n\n우리는 베이스 이미지로 python 도커 이미지를 사용하고, /app이라는 작업 디렉토리를 생성합니다. 그런 다음 애플리케이션 파일을 해당 디렉토리로 복사하고, pip를 사용하여 모든 종속성을 설치합니다. 그 후에 포트 8501을 노출하고 Streamlit 애플리케이션을 시작합니다.\n\n아래에 표시된 대로 docker build 명령을 사용하여 도커 이미지를 빌드할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![docker_image_4](/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_4.png)\n\n도커 이미지가 빌드되었는지 확인할 수 있어야 합니다. 다음에 표시된 것처럼 `docker images` 명령어를 사용하세요.\n\n![docker_image_5](/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_5.png)\n\n이제 스트림릿 애플리케이션 및 올라마 컨테이너의 네트워크를 정의하는 docker-compose 구성 파일을 만들어보겠습니다. 이렇게 하면 두 애플리케이션이 상호 작용할 수 있습니다. 또한 위의 그림에서 보듯이 다양한 포트 구성을 정의할 것입니다. 올라마에 대해서는 모델들이 영구적으로 유지되도록 볼륨 매핑도 수행할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_6.png\" /\u003e\n\n도커 컴포즈 업 명령을 실행하면 어플리케이션을 실행할 수 있습니다. 도커 컴포즈 업을 실행하면 아래 스크린샷에 표시된 대로 두 컨테이너가 모두 실행되고 있는 것을 확인할 수 있어야 합니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_7.png\" /\u003e\n\n아래 스크린샷에 표시된 대로 도커 컴포즈 ps 명령을 실행하여 컨테이너가 실행 중인 것을 확인할 수 있어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image1](/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_8.png)\n\n올라마가 실행 중인지 확인하려면 아래 스크린샷에 표시된 대로 http://localhost:11434을 호출해야 합니다.\n\n![image2](/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_9.png)\n\n이제 아래에 표시된 대로 docker exec 명령을 사용하여 도커 컨테이너에 로그인하여 필요한 모델을 다운로드해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndocker exec -it ollama-langchain-ollama-container-1 ollama run phi\n```\n\n우리는 모델 phi를 사용 중이므로 해당 모델을 가져와서 실행하여 테스트 중입니다. 아래 스크린샷을 참고하세요. phi 모델이 다운로드되고 실행을 시작할 것입니다 (-it 플래그를 사용하므로 샘플 프롬프트로 상호작용 및 테스트가 가능해집니다).\n\n\u003cimg src=\"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_10.png\" /\u003e\n\n로컬 폴더 ./data/ollama에서 다운로드된 모델 파일 및 매니페스트를 확인할 수 있어야 합니다. 이 폴더는 내부적으로 컨테이너에 매핑되어 있으며(Ollama가 다운로드된 모델을 제공하기 위해 찾는 위치인 /root/.ollama에 매핑됨)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식으로 변경한 테이블입니다.\n\n| `\u003cimg src=\"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_11.png\" /\u003e`                                                                   |\n| -------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Lets now run access our streamlit application by opening [http://localhost:8501](http://localhost:8501) on the browser. The following screenshot shows the interface |\n\n| `\u003cimg src=\"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_12.png\" /\u003e`                                                                                                   |\n| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Lets try to run a prompt “generate a story about dog called bozo”. You shud be able to see the console logs reflecting the API calls, that are coming from our Streamlit application, as shown below |\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 스크린샷에서 확인할 수 있듯이, 내가 보낸 프롬프트에 대한 응답을 받았어요.\n\n도커 컴포즈 다운을 호출하여 배포를 중지할 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 스크린샷은 결과를 보여줍니다.\n\n![output](/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_15.png)\n\n여기 있습니다. 이 블로그를 준비하면서 랭체인과 함께 Ollama가 작동하고 Docker-Compose를 사용하여 Docker에 배포하는 것이 정말 즐거웠어요.\n\n도움이 되었기를 바랍니다. 더 많은 실험으로 돌아오겠습니다. 그 동안 즐기고 코딩하세요!!! 곧 다시 만나요!!!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 전체 소스 코드에 액세스할 수 있습니다. abvijaykumar/ollama-langchain (github.com)\n\n참고 자료\n\n- Ollama\n- Docker Compose 개요 | Docker 문서\n- Docker 문서\n- Ollama — LLM을 어디서나 제공하는 런타임을 제공합니다. | 작성자: A B Vijay Kumar | 2024년 2월 | Medium\n","ogImage":{"url":"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_0.png"},"coverImage":"/assets/img/2024-06-19-OllamaBuildaChatBotwithLangchainOllamaDeployonDocker_0.png","tag":["Tech"],"readingTime":9}],"page":"32","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"32"},"buildId":"bb_yO9GbCvdfc_n71SfUf","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>