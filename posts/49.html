<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/49" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/49" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_buildManifest.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="스캐니버스가 안드로이드를 지원하게 되었습니다" href="/post/2024-05-23-ScaniverseextendssupporttoAndroid"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="스캐니버스가 안드로이드를 지원하게 되었습니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ScaniverseextendssupporttoAndroid_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="스캐니버스가 안드로이드를 지원하게 되었습니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">스캐니버스가 안드로이드를 지원하게 되었습니다</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="테라스캔Terrascan이란 무엇인가요" href="/post/2024-05-23-WhatisTerrascan"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="테라스캔Terrascan이란 무엇인가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-WhatisTerrascan_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="테라스캔Terrascan이란 무엇인가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">테라스캔Terrascan이란 무엇인가요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데브옵스DevOps란 무엇인가요" href="/post/2024-05-23-WhatisDevOps"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데브옵스DevOps란 무엇인가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-WhatisDevOps_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데브옵스DevOps란 무엇인가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데브옵스DevOps란 무엇인가요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS CDK이 Terraform보다 뛰어난가요" href="/post/2024-05-23-IsAWSCDKbetterthanTerraform"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS CDK이 Terraform보다 뛰어난가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-IsAWSCDKbetterthanTerraform_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS CDK이 Terraform보다 뛰어난가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS CDK이 Terraform보다 뛰어난가요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ArgoCD와 Terraform으로 클라우드 리소스 조정하기" href="/post/2024-05-23-OrchestratingCloudResourceswithArgoCDandTerraform"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ArgoCD와 Terraform으로 클라우드 리소스 조정하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-OrchestratingCloudResourceswithArgoCDandTerraform_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ArgoCD와 Terraform으로 클라우드 리소스 조정하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ArgoCD와 Terraform으로 클라우드 리소스 조정하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="웹 애플리케이션을 위한 변경 불가능한 인프라 구축하기 단계별 가이드" href="/post/2024-05-23-BuildinganImmutableInfrastructureforYourWebApplicationAStep-by-StepGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="웹 애플리케이션을 위한 변경 불가능한 인프라 구축하기 단계별 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-BuildinganImmutableInfrastructureforYourWebApplicationAStep-by-StepGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="웹 애플리케이션을 위한 변경 불가능한 인프라 구축하기 단계별 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">웹 애플리케이션을 위한 변경 불가능한 인프라 구축하기 단계별 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes" href="/post/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법" href="/post/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기" href="/post/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요" href="/post/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link posts_-active__YVJEi" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"스캐니버스가 안드로이드를 지원하게 되었습니다","description":"","date":"2024-05-23 14:41","slug":"2024-05-23-ScaniverseextendssupporttoAndroid","content":"\n\n## 다양한 플랫폼에서 3D 스캐닝과 가우시안 스플래팅을 경험해보세요\n\n우리는 Scaniverse가 이제 Google Play Store에서 사용 가능하다는 것을 기쁘게 알려드립니다!\n\n2021년 1월에 론칭한 이후, 사용자들이 가장 많이 물어보는 질문 중 하나가 '언제 안드로이드용 Scaniverse가 출시될까요?' 였습니다. 그래서 오늘부터 Scaniverse를 Play Store에서 안드로이드 사용자들을 위해 제공할 수 있게 되어 너무 기쁩니다. 3D 스캐닝 및 크리에이션을 더 많은 사용자들에게 전 세계적으로 제공할 수 있게 되었습니다.\n\n![이미지](/assets/img/2024-05-23-ScaniverseextendssupporttoAndroid_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3D 창조물을 촬영, 편집 및 공유하세요\n\n안드로이드의 Scaniverse를 통해 iOS 앱의 최상의 기능을 경험할 수 있습니다. 주변 환경을 스캔하고 모델을 자르고 편집하여 창조물을 세계와 공유하거나 내보낼 수 있습니다. 최근 추가된 3D 가우시안 스플래팅 기능도 포함되어 있어, 좋아하는 장소와 물건의 환상적인 사실적인 세부사항을 캡처할 수 있습니다. 또한 Android에서 세계 최초로 3D 기기 내 스플래트 재구성 기능도 소개되어, 속도와 개인 정보 보호를 제로 저장 비용과 함께 제공합니다. 무료, 빠르고 제한이 없습니다.\n\n# 뒷이야기: Scaniverse 이식\n\nScaniverse의 안드로이드 버전을 만드는 것은 도전적이지만 보람 있는 여정이었습니다. 여기에는 어떻게 만들었는지에 대한 소개가 있습니다. 원래의 iOS 앱은 Swift와 네이티브 C++ 코드를 사용하여 만들어졌습니다. 안드로이드에서는 가능한 경우 네이티브 C++ 구성 요소를 재사용하여 플러터 프레임워크를 선택하여 크로스 플랫폼 구현을 만들었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현대 iPhones 중 일부는 LIDAR 센서가 장착된 반면, Android 폰은 그렇지 않아서 포토그램메트리 모드를 통해 3D 재구성할 때 카메라 데이터에만 의존해야 했습니다. 또한 다양한 SoC, CPU 및 GPU를 갖춘 Android 기기 범위에 대한 성능 및 안정성을 최적화하려면 상당한 노력이 필요했습니다. 고사양 Android 기기에서 처리 시간을 30분 이상에서 단 4~5분으로 줄였습니다. 초기 릴리스가 현대 iPhones의 속도에 미치지 못할 수도 있지만, 오늘날 Android 기기에서 훌륭한 성능과 품질을 제공합니다.\n\n자세한 내용은 [FAQ](https://faq.link)를 방문해보세요.\n\n# Android 여정에 참여하세요\n\n![이미지](https://miro.medium.com/v2/resize:fit:600/1*TfpgfZYjKOkVC_6fibRbIA.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 안드로이드에서의 여정이 이제 막 시작됐습니다. 우리는 iOS 앱과 기능의 동일성을 달성하고, 스캔 품질을 향상시키며, 각 업데이트마다 성능을 향상시키겠다는 다짐을 하고 있습니다. 여러분의 피드백은 저희에게 매우 중요합니다. Scaniverse가 여러분을 어떻게 더 잘 도울 수 있는지 support@scaniverse.com으로 연락주시면 감사하겠습니다.\n\n지금 구글 플레이 스토어에서 Scaniverse를 다운로드하고 멋진 3D 콘텐츠를 만들어보세요. 좋아하는 3D 작품을 @scaniverse를 태그하여 인스타그램에서 공유하거나 해시태그 #scandroid로 X에 공유해주시면 저희가 채널에서 공유해드리겠습니다!\n\nScaniverse 팀 드림","ogImage":{"url":"/assets/img/2024-05-23-ScaniverseextendssupporttoAndroid_0.png"},"coverImage":"/assets/img/2024-05-23-ScaniverseextendssupporttoAndroid_0.png","tag":["Tech"],"readingTime":2},{"title":"테라스캔Terrascan이란 무엇인가요","description":"","date":"2024-05-23 14:39","slug":"2024-05-23-WhatisTerrascan","content":"\n\n이 기사에서는 Terrascan을 살펴볼 것입니다. 이것이 무엇인지, 왜 사용해야 하는지, 어떻게 설치해야 하는지, 그리고 그 기능을 활용하는 방법에 대해 알아볼 것입니다. 우리는 일부 사용 사례 예제를 살펴보고, Terraform, Kubernetes (K8S) 및 Helm 차트를 스캔하는 방법을 보여줄 것입니다. 그리고 사용자 정의 정책을 정의하는 방법을 살펴보고, 마지막으로 Terrascan이 Chekov 및 TFSec와 같은 다른 유사한 제품과 비교되는 방법을 자세히 살펴볼 것입니다.\n\n![What is Terrascan](/assets/img/2024-05-23-WhatisTerrascan_0.png)\n\n## Terrascan이란 무엇인가요?\n\nTerrascan은 인프라를 코드로 정의하는(Infrastructure as Code, IaC)를 위한 오픈 소스 정적 코드 분석 도구입니다. Terrascan 웹사이트 태그라인이 Terrascan을 요약합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기의 핵심 키워드 중 하나는 'before'입니다. Terrascan 도구의 목표는 인프라가 프로비저닝되기 전에 규정 준수나 보안 문제를 알려줌으로써 이를 해결하여 문제를 피하는 것입니다.\n\nTerrascan은 Tenable이 소유하고 있으며, 이 회사는 Cloud Native Computing Foundation (CNCF) 및 Open Source Security Foundation (OpenSSF)의 회원입니다.\n\n## Terrascan의 사용 목적\n\nTerrascan은 개발자와 DevOps 팀이 인프라 코드가 모범 사례, 보안 표준 및 규정 요구 사항을 준수하는지를 보장하는 데 도움을 줍니다. Terrascan은 500개 이상의 미리 설정된 정책을 제공하여 CIS Benchmark와 같은 공통 정책 표준에 대해 IaC를 검사할 수 있습니다. Terrascan을 처음 사용할 때 -p 플래그가 지정되지 않은 경우, Terrascan은 Terrascan 리포지토리에서 최신 정책을 다운로드합니다. terrascan init를 실행하여 로컬 환경을 리포지토리에 게시된 최신 정책으로 업데이트할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Terrascan 특징\n\n- Terrascan은 AWS, Azure, Google Cloud Platform (GCP), K8S, ArgoCD, Atlantis, GitHub, Docker을 포함한 다양한 클라우드 제공업체 및 코드 유형과 함께 사용할 수 있어 교차 클라우드 인프라 배포에 다재다능합니다.\n- Terrascan은 사용자 정의 가능한 사전 정의된 보안 및 규정 준수 규칙 라이브러리를 제공합니다. 이러한 규칙은 암호화, 액세스 제어, 리소스 구성 등 인프라 보안 및 규정 준수의 다양한 측면을 포함합니다. 기본적으로 사용되는 정책을 자세히 보려면 terrascan 정책 문서 페이지를 확인할 수 있습니다.\n- Terrascan은 CI/CD 파이프라인, IDE(통합 개발 환경) 및 다른 개발 및 배포 워크플로에 통합할 수 있습니다. 이를 통해 IaC 코드의 자동 스캔 및 유효성 검사가 개발 프로세스의 일부로 이루어질 수 있습니다.\n- Terrascan은 클라우드 인프라의 지속적인 모니터링에 사용될 수 있습니다. 취약점이나 규정 준수 문제를 발생시킬 수 있는 변질이나 구성 변경을 정기적으로 검사하고 확인할 수 있도록 설정할 수 있습니다.\n- 보고 및 개선: Terrascan은 분석 중 발견된 문제를 강조하는 자세한 보고서를 생성합니다. 또한 이러한 문제를 어떻게 개선할지에 대한 지침을 제공하여 팀이 보안 및 규정 준수 문제를 효과적으로 해결할 수 있도록 도와줍니다.\n\n## Terrascan 설치 방법\n\n- Windows\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인기 있는 Windows 패키지 관리자 Chocolately를 사용하거나 수동으로 다운로드하여 설치할 수 있어요.\n\n```js\nchoco install terrascan\n```\n\n릴리스 페이지에서 Terrascan을 다운로드하세요:\n\nzip 파일에서 파일을 추출하고 Windows 경로에 추가하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 시작 단추를 마우스 오른쪽 버튼으로 클릭합니다.\n- 콘텍스트 메뉴에서 “시스템”을 선택합니다.\n- “고급 시스템 설정”을 클릭합니다.\n- “고급” 탭으로 이동합니다.\n- “환경 변수…”를 클릭합니다.\n- “Path”라는 변수를 클릭하고 “편집…”을 클릭합니다.\n- “새로 만들기”를 클릭합니다.\n- PATH에 포함하려는 Terrascan 파일이 있는 폴더의 경로를 입력하세요.\n\n- MacOS\n\n```js\ncurl -L \"$(curl -s https://api.github.com/repos/tenable/terrascan/releases/latest | grep -o -E \"https://.+?_Darwin_x86_64.tar.gz\")\" \u003e terrascan.tar.gz\ntar -xf terrascan.tar.gz terrascan \u0026\u0026 rm terrascan.tar.gz\ninstall terrascan /usr/local/bin \u0026\u0026 rm terrascan\nsudo install terrascan /usr/local/bin\n```\n\n- Linux\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ncurl -L \"$(curl -s https://api.github.com/repos/tenable/terrascan/releases/latest | grep -o -E \"https://.+?_Linux_x86_64.tar.gz\")\" \u003e terrascan.tar.gz\ntar -xf terrascan.tar.gz terrascan \u0026\u0026 rm terrascan.tar.gz\ninstall terrascan /usr/local/bin \u0026\u0026 rm terrascan\nsudo install terrascan /usr/local/bin\n```\n\n- 도커\n\n도커 허브에서 이미지를 다음과 같이 가져올 수도 있습니다:\n\n```js\n$ docker run --rm tenable/terrascan version\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테라스캔을 설치한 후 설치 여부를 확인하기 위해 명령줄에서 테라스캔을 실행하세요.\n\n![Terrascan](/assets/img/2024-05-23-WhatisTerrascan_1.png)\n\n## IaC 코드를 스캔하는 방법\n\n코드를 스캔하려면 구성 파일이 있는 폴더로 이동한 후 다음 명령을 실행하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nterrascan scan\n```\n\n--c 옵션을 사용하여 스캔할 디렉토리를 지정할 수도 있어요.\n\n## Terrascan 사용 사례 - 예시\n\nTerrascan을 여러 유형의 구성 파일과 함께 사용할 수 있어요. 여기에 몇 가지 예시가 있어요. 이를 통해 쉽게 시작할 수 있을 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 예제 1 — Terraform 코드 스캔\n\nAzure를 위한 예제 Terraform 설정 파일이 있습니다. 이 파일은 간단히 리소스 그룹을 생성합니다:\n\nmain.tf\n\n```js\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"example-resources\"\n  location = \"East US\"\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파일을 저장한 후 해당 디렉토리로 이동하여 terrascan scan을 실행하십시오. Terrascan이 1개의 정책 위반을 감지하고 리소스 그룹에 리소스 잠금을 활성화해야 한다고 권장함을 볼 수 있어요. 이 문제는 LOW 심각도로 표시돼요.\n\n![Terrascan Screenshot](/assets/img/2024-05-23-WhatisTerrascan_2.png)\n\n## 예제 2 - Helm 차트 스캔\n\nHelm 차트를 사용하여 Terrascan을 테스트하기 위해 demo-chart라는 새 차트를 만들어보겠어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nhelm create demo-chart\n```\n\n이제 values.yaml 파일을 편집하여 Terrascan이 보고할 몇 가지 추가 취약점을 추가해보겠습니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-WhatisTerrascan_3.png\" /\u003e\n\nvalues.yaml 파일이 있는 디렉토리로 이동한 다음 terrascan scan을 실행하세요. 보고된 위반 정책이 여러 개 표시되어야 합니다. 여기에는 위에 securityContext 라인을 추가하여 발생시킨 HIGH 심각도의 2개의 정책 위반이 포함될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-WhatisTerrascan_4.png\" /\u003e\n\n## 예제 3 — 쿠버네티스 매니페스트 스캔하기\n\nK8S 매니페스트를 스캔하는 방법을 테스트하기 위해 간단한 nginx 배포용 파일을 작성해보겠습니다:\n\nnginx.yaml\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n```\n\nnginx.yaml 파일이 있는 폴더로 이동하여 terrascan scan을 실행해주세요.\n\nTerrascan에서 여러 권장 사항을 보게 될 것인데, 그 중에는 2개의 HIGH 우선 순위 이슈('Minimize Admission of Root Containers' 및 'Containers Should Not Run with AllowPrivilegeEscalation')도 포함되어 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-WhatisTerrascan_5.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 예제 4 — Terrascan을 ArgoCD와 통합하기\n\nTerrascan은 인기있는 CI/CD 시스템인 Azure DevOps, GitHub, GitLab 및 Argo와 통합할 수 있습니다. ArgoCD의 경우, Terrascan은 ArgoCD의 리소스 후크를 사용하여 응용 프로그램 사전 동기화 프로세스 중 Argo CD 작업으로 구성될 수 있습니다. 또한 Terrascan의 K8S admission 컨트롤러를 사용하여 사전 동기화 및 컨트롤러 웹훅과 함께 구성된 저장소를 스캔할 수 있습니다.\n\nTerrascan 문서 페이지에서 전체 통합 예시를 찾을 수 있습니다.\n\n## Terrascan 사용자 정의 정책\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTerrascan은 사용자가 Rego 쿼리 언어를 사용하여 쉽게 사용자 정의 정책을 만들 수 있도록 Open Policy Agent (OPA) 엔진을 활용합니다. 각 rego 정책에는 정책에 대한 메타데이터를 정의하는 JSON \"rule\" 파일이 포함되어 있습니다. Terrascan에 포함된 정책은 pkg/policies/opa/rego 디렉토리에 저장됩니다. rule.json 파일은 Rego 파일에서 정의된 사용자 정의 정책을 참조하는 구성 파일로, Terrascan 스캔 중에 어떤 정책이 적용되고 심각성 수준이 어떻게되는지를 제어할 수 있습니다. 사용자 정책 로직 및 규칙은 .rego 파일에 정의되며, rule.json 파일은 해당 정책을 적용하고 구성하는 방법을 지정합니다.\n\n아래 정책 예시는 Azure 리소스가 \"UK South\" 또는 \"UK West\"에만 있어야 한다는 것을 강제합니다. 다른 위치에서 리소스를 찾으면 Terrascan에서 보고됩니다.\n\nazure_region_policy.rego\n\n```js\npackage main\n\nimport input.tfplan as tfplan\n\ndefault allow = false\n\nallowed_regions = [\"UK South\", \"UK West\"]\n\n# 테라폼 계획의 모든 Azure 리소스를 반복합니다.\nazure_resources[resource_name] {\n    resource_name = input.tfplan.resource_changes[_].address\n    input.tfplan.resource_changes[_].type == \"azurerm_resource\"\n}\n\n# 각 Azure 리소스의 지역이 허용되었는지 확인합니다.\nallow {\n    resource_name\n    resource_config := input.tfplan.resource_changes[resource_name].change.after\n    resource_config.location == allowed_region\n    allowed_region = allowed_regions[_]\n}\n```\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사용자 정책을 활성화하려면 rule.json 파일을 사용하여 Terrascan의 동작을 구성하고 스캔 중에 적용해야 할 정책을 지정합니다.\n\nrule.json\n\n```js\n{\n  \"rules\": {\n    \"azure_region_policy\": {\n      \"severity\": \"HIGH\",\n      \"message\": \"'UK South' 또는 'UK West' 지역에 Azure 리소스를 배포해야 합니다.\",\n      \"rules_file\": \"azure_region_policy.rego\"\n    }\n  }\n}\n```\n\n마지막으로 사용자 정책을 사용하여 스캔하려면 스캔하려는 디렉토리로 이동하고 -rules 플래그를 사용하여 json 파일 경로를 지정하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nterrascan scan -rules /path/to/rule.json\n```\n\n또한 Terrascan은 원하는 경우 정책을 준수하지 않으려면 해당 정책을 제외할 수도 있습니다. 예를 들어, 예시 1에서 구성한 Azure 리소스 그룹에 리소스 잠금을 사용하고 싶지 않다면 이 정책을 스캔에서 제외하여 이 문제로 표시되지 않게 할 수 있습니다. 이를 위해 -skip-rules 플래그를 사용하거나 특정 리소스에서 정책을 건너뛰는 파일 내부 기능을 사용합니다.\n\n## Terrascan 대 Checkov\n\n외관상으로 보면, Terrascan과 Checkov는 매우 유사합니다. 둘 다 IaC 보안 및 규정 준수 스캔을 위해 설계된 오픈 소스 정적 코드 분석 도구입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCheckov은 Terraform에 주로 초점을 맞추고 있지만, AWS SAM을 포함한 CloudFormation, Azure Resource Manager (ARM), Serverless framework, Helm 차트, K8S 및 Docker와 같은 여러 유형의 파일을 스캔할 수 있습니다. Checkov는 활발한 기여 및 DevSecOps 커뮤니티에서 강력한 존재감을 보이는 커뮤니티 주도 프로젝트입니다.\n\nCheckov는 Python을 사용하여 구축되었으며, Terrascan은 Go를 사용하며 Rego를 사용하여 사용자 정의 정책을 작성합니다. 사용자 정의 정책을 작성하는 데 Rego를 선호한다면 Terrascan은 좋은 선택입니다.\n\n## Terrascan vs tfsec\n\nTfsec는 또 다른 오픈 소스 정적 코드 분석 도구이며, 고려할 수 있는 주요 옵션 중 하나입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTerrascan과 달리 TFSec는 GO로 작성되었으며 사용자 정의 정책에는 Terrascan에서 사용되는 Rego 대신 YAML 정의를 사용합니다. K8S에 익숙한 사용자는 Rego 학습 대신 YAML을 사용하여 정책을 작성하는 것을 선호할 수 있습니다. 이는 TFSec를 선택하는 이유가 될 수 있습니다. 또한 커뮤니티에서 Checkov 및 Terrascan보다 가장 인기 있는 프로젝트이며 가장 많은 GitHub 스타를 가지고 있습니다.\n\n## 주요 포인트\n\nTerrascan은 IaC 템플릿 및 구성을 스캔하는 데 설계된 매우 유연하고 강력한 오픈 소스 정적 코드 분석 도구입니다. IaC 코드에서 보안 취약점, 준수 위반 및 최상의 실천 방법 문제를 식별하는 데 도움을 줍니다. 다양한 유형의 구성 파일과 함께 사용할 수 있으며 내장 정책을 제공하며 Rego를 사용하여 사용자 정의 정책을 사용할 수도 있습니다. CI/CD 시스템과 자동화 파이프라인에서 사용하는 것이 지원됩니다.\n\n여기에서 Terraform에 관한 다른 기사들도 확인해보세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n환호! 🍻\n\n원래 spacelift.io에서 발행되었습니다.","ogImage":{"url":"/assets/img/2024-05-23-WhatisTerrascan_0.png"},"coverImage":"/assets/img/2024-05-23-WhatisTerrascan_0.png","tag":["Tech"],"readingTime":9},{"title":"데브옵스DevOps란 무엇인가요","description":"","date":"2024-05-23 14:37","slug":"2024-05-23-WhatisDevOps","content":"\n## 시스템 엔지니어의 여정과 관점\n\n![이미지](/assets/img/2024-05-23-WhatisDevOps_0.png)\n\n# 소개\n\n데브옵스란 무엇일까요? 그 질문은 특정 IT 분야에 뛰어들기 전에 스스로에게 묻고 진정한 의미를 이해하기 전까지 기억하는 질문이었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 멜버른, 호주에서 열린 VMware 사용자 회의에 참석했던 때를 떠올립니다. 여러 다른 VMware 애호가들과 함께 있었는데, VMware 및 협력사들이 개발 중인 흥미로운 제품들에 대해 더 알아보기 위해 열정적으로 참석했었습니다. 발표를 하는 신사의 이름은 KevOps로 매우 재미있는 이름이었다고 기억해요.\n\n당시 시스템 엔지니어로서, 저는 데브옵스를 다음 단계로 여겼습니다. 상위 수준에서는 저에게 코드와 관련된 부분이라는 것은 알고 있었지만, 그 본질 자체가 이해되지 않아 솔직히 겁이 났어요. 처음으로 데브옵스를 이해할 때, 강력한 개발자여야 하고 높은 수준의 코딩 경험이 필요하다는 것을 이해했어요. 하지만 이것은 제가 잘하지 않았고 이 간극을 메우는 것은 불가능하다고 생각했어요. 하지만 더 깊이 파고들수록 더 많은 것을 발견하게 되었고, 결국은 저 스스로가 오르기 어려운 산처럼 보이던 그 직무까지 수행하고 있는 자신을 발견했습니다.\n\n# 데브옵스의 간략한 역사\n\n데브옵스가 무엇인지 알아가기 전에, 과거로 돌아가서 문제 상황을 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2007년 경, 개발 및 운영 팀이 산업 전반에 걸쳐 함께 일하는 방식에 문제가 있습니다. 서로 분리되어 있고 서로의 다음 목표가 일치하지 않는 경우가 많습니다. 개발자들은 운영팀이 서버를 관리해야 하는 많은 경쟁 우선 순위로 인해 배포를 제때에 할 수 없습니다. 이 모델로는 누구도 이길 수 없는 상황입니다.\n\n여기에서 DevOps 용어가 만들어지고, 제가 소개할 때 이 운동이 가속화되기 시작했습니다. 저의 겸손한 의견으로는 IT 산업의 일부 분야를 혁신적으로 변화시키기 위해 필요한 문제 해결을 단호히 요청하는 움직임입니다.\n\n# 그러면, DevOps란 무엇일까요?\n\n우선, DevOps는 한 문장이나 진술로 설명할 수 없습니다. 사실, 이것은 여러 요소나 측면을 갖고 있는 것입니다. 어떤 렌즈를 통해 보느냐에 따라 달라지는 정의가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDevOps를 설명하는 것은 다음과 같을 수 있어요:\n\n- 문화\n- 프레임워크\n- 기술적 방법론\n- 엔지니어 유형\n\n각각의 요소는 관점과 전문성에 따라 정의될 수 있어요. 이는 Agile이나 ITIL과 유사한데, 이러한 주제에 대한 이해는 당신의 역할과 책임에 따라 정말 중요해질 거예요.\n\n집과 같이, DevOps는 강력한 기초 위에 구축되어 구조를 구현하고 마무리를 지어나갈 거예요. 아래 다이어그램은 DevOps가 문화적 수준에서 시작하여 기술을 살아 숨쉬게 만들어가는 과정을 도와줍니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-23-WhatisDevOps_1.png)\n\n# 데브옵스란 문화\n\n현재 GenAI가 핫한 주제인 가운데, ChatGPT 또는 Gemini와 같은 대형 언어 모델(Large Language Models, LLM)에 대해 익숙할 것입니다. ChatGPT에게 데브옵스란 무엇인지 물어보면 대략 이와 같은 답을 얻을 수 있습니다:\n\n이 정의는 데브옵스의 문화적 측면을 잘 요약한 것입니다. 데브옵스는 개발팀과 운영팀 간의 장벽을 허물고 상호 유익한 관계를 구축하기 위해 함께 뭉치는 것을 목표로 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDevOps가 추구하는 문화 중 일부 맨트는 다음과 같습니다:\n\n- 수동 및 번거로운 작업을 없애겠습니다.\n- 자동화를 촉진하여 효율성과 민첩성을 높이겠습니다.\n- 일관성을 위해 반복 가능한 패턴을 사용하겠습니다.\n- 능력과 숙련도를 향상시키기 위해 협력을 촉진하겠습니다.\n- 우리는 복잡함 대신 단숨함을 향한 태도로 새로운 도전에 대응하고 적응할 것입니다.\n\nDevOps 모델을 준수하는 문화의 예를 살펴보겠습니다.\n\n## DevOps 모델을 준수하지 않는 경우\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n운영팀:\n\n- 소프트웨어 업데이트 설치와 같은 작업은 수동으로 처리됩니다.\n- 반복 작업이 자동화되지 않습니다.\n- 새로운 인프라 요청은 수동으로 처리됩니다.\n- 소유 애플리케이션을 위한 개발자 코드는 수동으로 배포됩니다.\n- 월간 주기 내에 작업을 완료하는 것에 대한 경쟁 우선순위가 있습니다.\n- 작업은 선형적인 프로세스를 따르지 않으며 인간 에러의 영향을 받습니다.\n\n개발팀:\n\n- 운영팀에 크게 의존하므로 소유 애플리케이션 배포에 상당한 지연이 있습니다.\n- 일부 배포를 적시에 테스트할 수 없습니다.\n- 인프라에 대한 이해가 없거나, 있더라도 인프라에 액세스할 수 없습니다.\n- 운영팀으로부터의 번거로운 피드백 루프로 배포 문제를 강조합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDevOps가 해결하는 것을 정말로 이해하려면 어떤 나쁜 환경이 무엇인지 이해해야 합니다. 난 이상한 걸 말했나? 오늘도 이런 일이 발생하고 있고 DevOps를 도입해도 모든 문제가 해결되는 것은 아닙니다. 그러나 위의 예에서 보면 타임라인과 배달 속도에 많은 도움이 될 것입니다.\n\n## DevOps 모델을 따른다\n\nDevOps 팀:\n\n- 인프라, 코드, 자동화 및 빌드 기술 간의 다양한 기술을 보유하고 있습니다.\n- 문제를 검토하고 자동화를 통해 최선의 해결 방법을 한 번 찾은 후, 향후에도 그 자동화를 의존하여 자가 치유 및 수정합니다.\n- 환경에 도입되는 변경 사항에 대해 패턴 기반 접근 방식을 사용하는 엄격한 프로세스를 따릅니다.\n- 가능한 한 많은 수동 작업을 사용하지 않습니다.\n- 변경 사항이 작고 점진적입니다.\n- 피드백 루프가 강하며 팀원과의 관계를 구축하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 두 예시를 옆에 놓을 때, 개선 사항이 분명합니다. 이러한 사고 방식에 노출되었을 때, 여러분은 진정으로 데브옵스에서 무엇을 얻을 수 있는지 그 가치를 온전히 이해하게 됩니다.\n\n데브옵스가 전혀 적용되지 않은 예시에서, 주요 키워드는 명확해야 합니다. 데브옵스의 본질은 가능한 만큼 많은 일을 자동화하는 것입니다. 그렇지만 모든 것을 자동화할 수는 없다는 점을 명심해야 합니다. 데브옵스는 여정입니다. 즉, 데브옵스 방법을 사용할 준비가 된 환경과 그렇지 않은 환경 사이에 명확한 구분을 가져야 합니다.\n\n데브옵스로의 전환을 위해 가장 중요한 요소는 문화입니다. 우리는 이를 받아들이고 온전히 수용해야 합니다. 문화가 없으면 우리는 단일한 토대나 공동의 기반을 갖지 못합니다. 데브옵스는 협업에 관한 것이며 개인이 성공하는 것이 아니라 팀이 성공하는 것임을 이해하는 것입니다. 약속을 견고하게 지키는 것이 무엇을 뜻하며, 데브옵스가 무엇을 의미하며 그 방법론이 우리에게 보여줄 수 있는 것에 대해 말하는 속담을 들어보셨을 것입니다.\n\n문화에 동의한 후, 나머지는 바닥 규칙이 마련된 후에 쉽게 자리에 맞게 되는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# DevOps 프레임워크\n\nDevOps를 프레임워크로 살펴볼 때, 우리는 더 많은 업무 방식을 고려합니다. 이는 다음을 포함합니다:\n\n- 팀에게 DevOps가 의미하는 것은 무엇인가요?\n- 이해해야 할 DevOps의 하위 개념은 무엇인가요?\n- 우리 팀의 모든 사람이 성공을 위해 어떻게 설정되었는지 확인하는 방법은 무엇인가요?\n\n이것들은 우리가 스스로 묻는 많은 다른 질문들 중 일부입니다. 이 프레임워크는 우리가 성공을 달성하고 현저한 혜택을 얻으면서 의미 있는 결과물을 제공하는 방식을 정의할 수 있도록 해줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오랜만에 만나서 반가워요!\n\n데브옵스의 각 측면이 전문성을 갖고 있는 내용을 간단히 살펴보겠습니다:\n\n![DevOps Expertise](/assets/img/2024-05-23-WhatisDevOps_2.png)\n\n이것은 데브옵스 프레임워크 내에서 흔히 사용되는 일부 주요 개념을 샘플링한 것입니다. 물론 다른 것도 있지만, 여기서는 주요 개념을 단순히 설명하는 데에 초점을 맞추고 있습니다. 문화로서의 데브옵스 섹션과 마찬가지로 서로 유익한 전문분야를 식별하기 시작할 수 있을 겁니다.\n\n본질적으로, 데브옵스는 이러한 다양한 전문분야를 결합하여 인프라 솔루션 및 애플리케이션을 배포하고 관리하며 유지보수하기 위한 목적을 달성하려는 프레임워크입니다. 이를 이루는 방법은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- SCM(소프트웨어 구성 관리) 및 CI/CD(지속적 통합/지속적 배포) 프로세스를 결합하여 인프라 기반 솔루션을 빌드하고 배포합니다. 보통 이를 GitOps 모델이라고 합니다.\n- 정기적으로 반복되는 수동 작업을 자동화합니다.\n- 수요에 따라 확장할 수 있는 용량이 탄탄하고 오류 허용이 가능한 무상태 아키텍처 개념을 활용합니다.\n- 애플리케이션 변경에 반응하는 이벤트-주도 아키텍처를 생성합니다.\n- 애자일성과 빠른 전달 속도를 향상시키기 위해 잘 알려진 패턴을 재사용합니다.\n\n# 기술적 접근으로서의 DevOps\n\nDevOps의 기술 세부 정보 및 기술 요소로 진입하기 전에, 직접 경험한 현실 시나리오를 한번 살펴보고 싶습니다.\n\n2017년 특정 환경에서, DevOps에서 언급된 것과 유사한 수동 작업을 수행했던 기억이 나네요. DevOps 모델을 따르지 않았던 윈도우 중심의 환경이었고, 가상 환경으로 VMware를 사용했습니다. 서버는 SCCM을 사용하여 수동으로 패치되었습니다. 이 프로세스는 다음과 같았습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 운영팀 구성원이 목록에서 서버를 손에 든다.\n- 관리 액세스를 사용하여 해당 서버에 로그인한다.\n- SCCM 클라이언트를 시작한다.\n- 업데이트를 설치한다.\n- 다시 부팅한다.\n\n특히 해당 방식으로 패치해야 하는 여러 서버가 있는 경우에는 번거로운 프로세스였습니다. 이 모든 것의 귀하의 유일한 상처는? 이것이 월간 행사였다는 사실입니다.\n\n이 예제는 DevOps가 개발 운영 측면에서 존재하기 전의 생활을 보여줍니다. 이는 환경을 유지하고 “불을 켜 있는” 과제 중 하나로써 정기적으로 수행되어야 하는 많은 작업 중 하나이기도 합니다. DevOps가 제공할 수 있는 가치를 실감하게 되면, 정기적으로 수동 작업을 수행하는 것은 시간의 대조적인 투자 수익이 매우 적은 것처럼 느껴집니다.\n\n기술적 접근 방법으로서의 DevOps에 관한 것은, 이제 다양한 작업 및 동작을 수행하는 데 사용되는 실제 도구에 대해 깊게 들어가 시작합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 익숙할지도 모르는 몇 가지 개념과 각각의 응용 프로그램 목록입니다:\n\n![이미지](/assets/img/2024-05-23-WhatisDevOps_3.png)\n\n이것은 그림을 보여주기 위한 목록 샘플만을 제시한 것입니다.\n\n이 도구들의 조합을 사용하여 환경을 운영하면, 플랫폼과 관련된 솔루션(대규모/확장된 환경에서 플랫폼을 지원)이나 특정 응용 프로그램을 구축할 수 있습니다. 이 다이어그램은 이러한 개념과 응용 프로그램을 실제 시나리오에 어떻게 적용할 수 있는지 보여줍니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-23-WhatisDevOps_4.png)\n\n**포인트 1 - 코드는 GitHub에 저장됩니다**\n\n이를 통해 우리는:\n\n- 전체 팀이 사용할 일관된 진실의 원천을 적절히 유지할 수 있습니다.\n- 코드베이스의 버전을 생성하여 개발, 테스트, 프로덕션 등 다양한 환경으로 단계적이고 제어된 배포를 할 수 있습니다.\n- 동료들로부터 제안된 변경 사항을 코드베이스에 도입하려고 하는 경우 동료들의 리뷰 및 승인 프로세스를 거치도록 합니다.\n- 자동 배포를 위해 Buildkite와 통합합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제 2점 — Terraform을 사용한 IaC\n\nTerraform은 AWS에서 자원을 생성/대체/업데이트/삭제(CRUD)하는 데 사용됩니다. Github 및 Buildkite와 함께 Terraform을 사용하여 GitOps 모델을 구현함으로써 배포를 처리할 수 있습니다. 이는 다음을 보장합니다:\n\n- 자원이 일관된 방식으로 배포됩니다.\n- 빌드카이트만을 통해 Terraform을 사용하여 배포를 수행할 수 있도록 하여 이 프로세스에서 벗어나지 않습니다.\n- 코드를 반복적으로 사용하여 매번 처음부터 작업하는 대신 개선만 하여 사용하는 DRY(Don’t Repeat Yourself) 모델을 촉진할 수 있습니다.\n\n제 3점 — CI/CD를 위한 Buildkite 사용\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBuildkite는 검증, 계획 및 배포를 수행하는 CI/CD 플랫폼으로 사용됩니다. Buildkite는 일관성을 유지하기 위해 GitHub를 소스로 사용할 것입니다.\n\n4번 항목 — 배포 전 코드 검증 (CI/CD의 CI)\n\n검증 및 계획 파이프라인이 배포 전에 실행되어 우리가 무엇을 기대해야 하는지 알 수 있습니다.\n\n또한 이 단계를 강화하고 개발 환경에서 모의 배포를 수행할 수도 있습니다. 이렇게 하면 예기치 못한 문제가 도드라지며 접근 방식을 재고하고 조정해야 할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n점 5 — Pull request 동료 리뷰\n\n충분한 증거가 축적되면 동료에게 우리의 pull request를 검토해 달라고 요청할 수 있으며, 모든 게 제대로 된 경우 병합을 진행할 수 있습니다.\n\n협업이 최고이며, DevOps의 문화 측면에서 언급된 대로 동료의 의견을 듣고 항상 배울 수 있고 조정할 수 있는 방법이 항상 있습니다.\n\n점 6 — Pull request 병합 및 배포 (CI/CD의 CD 부분)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 번 pull request가 승인되고 병합되면, 자동화가 실행되어 리소스가 배포됩니다.\n\nGitOps 모델을 활용함으로써, 각 단계는 통제되며 비교적 예측 가능한 작업이어야 합니다. 이 모델을 계속 사용하여 환경에 변경 사항을 계속 적용할 수 있습니다.\n\nDevOps는 당신이 가진 도구를 통해 쉽게 삶을 만드는 방법을 찾는 것입니다.\n\n# 엔지니어로서의 DevOps\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 레이어가 편하게 마련된 상태에서, 우리는 DevOps 하우스의 정상인 곳에 위치하게 되었습니다. DevOps 엔지니어들에게는 하위 레이어들이 강력한 기반을 제공하여 우리가 필요한 작업을 수행하고 전체 모델을 완성하는 데 도움이 됩니다.\n\n그러나 다소 상반된 방식으로, DevOps 엔지니어로 레이블이 지어지는 것이 산업 전반에 깔끔하게 부합되지는 않습니다. 예를 들어, 온프레미스 환경에 DevOps 모델을 적용하는 것에는 문제가 없습니다. 많은 개념적 도구들이 온프레미스 동등물을 갖고 있습니다. 또한 그렇지 않더라도 SaaS(Software as a Service) 기반 제공품을 사용하여 온프레미스 환경에서 배포를 수행할 수 있습니다.\n\n이 분야에서는 대부분 DevOps가 공용 클라우드에만 해당한다고 전체적으로 가정되어 왔지만, 그렇지 않습니다. DevOps 모델이 공용 클라우드에 편안하게 적용되지만, 온프레미스 환경에 적용할 수 있는 에지 케이스 시나리오들도 여전히 있습니다. 이것이 이 섹션의 요지로 이어지면서 누군가를 DevOps 엔지니어로 정의하기가 어렵다는 것을 알 수 있습니다.\n\n기술적 접근 방식 섹션에서는 IaC 및 CI/CD와 같은 개념을 다루었습니다. 이러한 개념을 기반으로 하는 도구들은 산업 전반에서 다양한 형태로 나타날 것입니다. 이는 이러한 개념을 기반으로 하는 (어떤 면에서) 도구의 수가 매우 많기 때문입니다. 예를 들어, 회사 A의 DevOps 엔지니어로는 GitHub (SCM), GitHub Actions (CI/CD) 및 Terraform (IaC) 도구를 사용할 수 있지만, 회사 B의 DevOps 엔지니어로는 BitBucket (SCM), Bamboo (CI/CD) 및 CloudFormation (AWS의 IaC)을 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n공학 수준의 DevOps는 산업 전반에 걸쳐 일관성이 없다는 것을 설명하고 있습니다. 개인적으로, 몇 가지 환경을 경험해 보았는데, 이러한 환경은 DevOps 모델을 활용하지만 정확히 같은 도구를 사용하는 환경은 없습니다. 유사점이 많지만, 완전히 동일한 것은 아닙니다.\n\n또 다른 좋은 예로는 DevOps 모델을 공개 클라우드 공간에 적용할 때를 들 수 있습니다. 비슷한 개념을 가지고 있지만 사용하는 용어 및 개념 적용 방식에서 다소 차이가 있습니다.\n\n이로 인해 누군가를 DevOps 엔지니어로 규정하는 것이 어렵습니다. 실제로, DevOps 엔지니어 역할을 볼 때, 해당 회사와 해당 환경에 대한 역할일 것입니다. 여러 클라우드 및 여러 다른 기술 스택에 대해 이야기할 때 플랫폼 엔지니어가 관련될 수 있다는 주장도 나올 수 있습니다. 그럼에도 불구하고, DevOps 엔지니어라는 용어는 계속 사용되고, 이와 관련된 일정 수준의 모호성이 예상된다는 가정이 있습니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어떠한 에셋을 가져오거나 동적으로 추가할 때 table 태그를 Markdown 형식으로 변경하세요.\n","ogImage":{"url":"/assets/img/2024-05-23-WhatisDevOps_0.png"},"coverImage":"/assets/img/2024-05-23-WhatisDevOps_0.png","tag":["Tech"],"readingTime":9},{"title":"AWS CDK이 Terraform보다 뛰어난가요","description":"","date":"2024-05-23 14:35","slug":"2024-05-23-IsAWSCDKbetterthanTerraform","content":"\n이 기사에서는 클라우드 인프라를 유지하는 데 AWS CDK를 사용하는 장점과 이해를 돕기 위한 코드 스니펫에 대해 설명하겠습니다.\n\n![AWS CDK vs Terraform](/assets/img/2024-05-23-IsAWSCDKbetterthanTerraform_0.png)\n\n저는 AWS 클라우드 엔지니어로 일하고 있으며, AWS 환경 내에서 내 프로젝트의 클라우드 인프라를 관리하는 역할을 맡고 있습니다. 이 역할에서 저는 Terraform과 AWS CDK를 모두 활용해 왔습니다. 제 경험과 인사이트를 바탕으로, 각각의 우세한 점에 대해 제 생각을 공유하겠습니다.\n\n그러나 그에 앞서, IaC를 이해해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# IaC(Infrastructure as Code)이란 무엇인가요?\n\nIaC 또는 Infrastructure as Code는 클라우드 인프라가 코드를 통해 프로비저닝되고 관리되는 소프트웨어 엔지니어링 방법론입니다. 이는 AWS 콘솔과 같은 수동 프로세스나 대화형 구성 도구를 통해 관리하는 것이 아니라 코드를 통해 인프라를 구축하는 방식을 의미합니다.\n\n간단히 말해, 콘솔을 통해 수동으로 생성하는 대신 인프라를 배포할 코드를 작성하는 것입니다. 이는 산업의 표준적인 실천 방법입니다. 현재 클라우드 인프라에 IaC를 적용하지 않는 조직은 없다고 생각해요.\n\nIaC를 적용하는 주요 이유는 재사용성, 일관성, 자동화 및 확장성입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 Terraform과 AWS CDK를 이해해 봅시다.\n\n## Terraform\n\nTerraform은 HashiCorp가 개발한 IaC 도구입니다. Terraform을 사용하면, 인프라 구성은 도메인 특화 언어인 HashiCorp 구성 언어 (HCL)를 사용하여 코드로 정의되어 버전 관리, 협업 및 자동화가 가능해집니다. Terraform은 그런 다양한 자원들의 전체 라이프사이클을 관리하며, 프로비저닝부터 업데이트, 파괴까지 정의된 설정 파일을 기반으로 합니다.\n\nS3 버킷을 생성하는 Terraform 스크립트의 간단한 예제입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# main.tf\n\nprovider \"aws\" {\n  region = \"us-east-1\"  # 원하는 AWS 지역을 설정하세요\n}\n\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  bucket = \"my-unique-bucket-name\"  # 원하는 버킷 이름을 설정하세요 (전역적으로 고유해야 함)\n}\n```\n\n# AWS CDK\n\nAWS CDK(Cloud Development Kit)는 AWS가 개발한 오픈소스 프로젝트로, 클라우드 리소스를 프로비저닝하기 위한 더 높은 수준의 추상화를 제공합니다.\n\nAWS CDK를 사용하면 Typescript, Python, Java, Go 등과 같은 익숙한 프로그래밍 언어를 사용하여 인프라 코드를 작성할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS CDK를 사용하여 Typescript로 S3 버킷을 만드는 간단한 예제입니다.\n\n```typescript\nimport * as cdk from \"aws-cdk-lib\";\nimport { Stack, StackProps } from \"aws-cdk-lib\";\nimport * as s3 from \"aws-cdk-lib/aws-s3\";\n\nexport class MyS3BucketStack extends Stack {\n  constructor(scope: cdk.Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // S3 버킷 생성\n    new s3.Bucket(this, \"MyBucket\", {\n      bucketName: \"my-unique-bucket-name\", // 원하는 버킷 이름으로 변경하세요\n    });\n  }\n}\n\n// 애플리케이션 생성\nconst app = new cdk.App();\nnew MyS3BucketStack(app, \"MyS3BucketStack\");\n```\n\n이제 Terraform 대 AWS CDK 논쟁에 대해 깊게 알아보겠습니다.\n\n# Terraform vs AWS CDK\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그것말고는 실제로 표 스타일이 아니라지만, 저희가 그 내용을 잘 이해할 수 있도록 글의 형식으로 바꿔 드릴게요.\n\n한 가지씩 살펴보며 이 도구들의 차이를 이해해 보겠습니다. 몇 가지 예시를 들어 몇 가지 포인트를 검증하겠습니다. 비교를 더 잘 이해하기 위해 마지막 부분만 주목해주세요.\n\n## 지원\n\nTerraform은 클라우드에 중립적입니다. 즉, AWS, Azure, GCP, Alibaba 등 여러 클라우드 제공업체를 지원합니다.\n\nAWS CDK는 AWS 팀이 특히 AWS 클라우드용으로 만들었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 다양한 클라우드 공급업체에서 작업 중이라면, Terraform이 최상의 선택일 것입니다. 몇몇 클라우드 공급업체는 자체 IaC 도구인 Azure의 Bicep과 같은 것들이 있지만, 아직 채택 초기 단계에 있습니다.\n\n## 언어\n\n이전에 언급했듯이, Terraform은 Hashicorp에서 특별히 만든 HCL(HashiCorp Configuration Language)을 사용합니다. HCL은 JSON과 유사한 구성 언어로, 배우기 쉽습니다.\n\nAWS CDK는 Typescript, Python, Java 등과 같은 일반 목적 프로그래밍 언어를 지원합니다. 따라서 새로운 언어를 배울 필요가 없습니다. 익숙한 프로그래밍 언어를 선택하고 IaC 작성을 시작할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로그래밍 언어는 견고하고 유연합니다. IaC에서 OOPS, 함수형 프로그래밍과 같은 다양한 프로그래밍 패러다임을 사용할 수 있어요. 이는 DSL(Domain Specific language)보다 많은 장점을 가지고 있어요.\n\n## 상태 관리\n\n테라폼은 terraform.tfstate 파일을 사용해 배포된 리소스의 상태를 저장해요. 이 파일은 인프라의 현재 상태와 배포된 리소스 및 구성을 추적합니다. 일반적으로 이 상태 파일은 중앙에 저장되며, 종종 S3 버킷에 저장되어 다양한 팀 간의 협업을 용이하게 합니다.\n\n제 경험 상으로, 테라폼 상태를 관리하는 것이 꽤 복잡할 수 있다는 것을 알았어요. 프로젝트 내에서 상태의 드리프트를 마주치는 것이 일반적이며, 이를 해결하는 데 시간이 많이 소요될 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS CDK는 상태가 없는 방식으로 작동합니다. 상태를 관리하기 위해 Git과 같은 버전 관리 시스템을 신뢰합니다. 배포할 때마다 최신 변경 사항을 가져와서 발생하는 모든 충돌을 해결하고 배포를 진행합니다. 이 방식은 깔끔하며 일관성을 유지합니다.\n\n## 버전 관리\n\n우리는 AWS가 계속해서 서비스를 확장하고 있다는 것에 익숙합니다. Terraform은 실행 파일로서 매번 최신 버전을 다운로드하고 업데이트해야 하므로 인프라 코드 업데이트가 어려운 작업이 됩니다. 우리 조직의 많은 프로젝트들은 여전히 오래된 버전에 의존하여 유지보수에 어려움을 겪고 있습니다.\n\n그에 반해 AWS CDK는 AWS가 직접 유지하고 있기 때문에 의존성을 간단히 관리하여 신속한 업데이트를 제공합니다. 이를 통해 시간이 지남에 따라 부드러운 전환과 더 적은 호환성 문제를 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 연결성\n\n이해하기 위해, 바로 예제로 들어가 봅시다.\n\n예를 들어, S3 버킷에 객체가 생성될 때마다 람다를 트리거해야 하는 시나리오를 생각해 봅시다. 이를 위해 S3 이벤트 알림과 람다를 결합하여 이를 달성할 수 있습니다.\n\n아래 테라폼 코드를 살펴봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  bucket = \"my-bucket\"\n  acl    = \"private\"\n}\n\nresource \"aws_lambda_function\" \"my_function\" {\n  filename      = \"lambda_function_payload.zip\"\n  function_name = \"my-function\"\n  role          = aws_iam_role.lambda_exec_role.arn\n  handler       = \"index.handler\"\n  runtime       = \"nodejs14.x\"\n}\n\nresource \"aws_lambda_permission\" \"s3_invoke_permission\" {\n  statement_id  = \"AllowExecutionFromS3Bucket\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.my_function.function_name\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket_notification.s3_notification.arn\n}\n\nresource \"aws_s3_bucket_notification\" \"s3_notification\" {\n  bucket = aws_s3_bucket.my_bucket.id\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.my_function.arn\n    events              = [\"s3:ObjectCreated:*\"]\n  }\n}\n```\n\nTerraform에서 모든 것을 리소스로 취급하는 개념을 따라갑니다. 먼저 Lambda 및 S3 버킷과 같은 리소스를 정의합니다. 그런 다음 Lambda 함수와 S3 객체 간의 연결을 설정하기 위해 권한을 부여해야 합니다. 이는 aws_lambda_permission 리소스를 사용하여 달성됩니다. 권한이 부여된 후 Lambda 함수와 S3 알림을 연결하는 데 또 다른 리소스인 aws_s3_bucket_notification이 필요합니다.\n\n이제 CDK 코드를 살펴봅시다.\n\n```typescript\nimport { aws_lambda_nodejs as lambda_nodejs } from \"aws-cdk-lib\";\nimport { aws_s3 as s3 } from \"aws-cdk-lib\";\nimport { aws_s3_notifications as s3notifications } from \"aws-cdk-lib\";\nimport { App, Stack, StackProps } from \"aws-cdk-lib\";\nimport { Construct } from \"constructs\";\n\nexport class MyStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // S3 버킷 생성\n    const bucket = new s3.Bucket(this, \"MyBucket\");\n\n    // Lambda 함수 생성\n    const fn = new lambda_nodejs.NodejsFunction(this, \"MyFunction\", {\n      runtime: lambda_nodejs.Runtime.NODEJS_14_X,\n      handler: \"handler\",\n      entry: \"lambda/index.ts\",\n    });\n\n    // S3 버킷에 대한 이벤트 소스 추가하여 Lambda 함수를 트리거합니다\n    fn.addEventSource(\n      new s3notifications.S3EventSource(bucket, {\n        events: [s3.EventType.OBJECT_CREATED],\n        filters: [{ prefix: \"uploads/\" }], // 필요에 따라 접두사 조정\n      })\n    );\n  }\n}\n\nconst app = new App();\nnew MyStack(app, \"MyStack\");\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드에서는 먼저 S3 버킷을 생성한 다음 람다 함수를 생성합니다. 람다 함수 코드 자체 안에서 S3를 이벤트 소스로 생성할 수 있음을 알 수 있습니다. 이것은 멋지며 프로그래밍의 힘을 보여줍니다.\n\n위의 코드는 모든 것을 Terraform의 리소스 블록을 사용하는 것보다 훨씬 이해하기 쉽습니다.\n\n## 보안\n\nAWS 내에서 보안을 논의할 때 IAM(Identity and Access Management)이 중심에 있습니다. IAM 역할과 정책은 사용자 액세스를 관리하고 서비스 간 안전한 통신을 용이하게 하는 데 사용되는 중요한 구성 요소입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테라폼 코드에서는 aws_lambda_permission 리소스 블록을 사용하여 S3이 람다를 호출할 수 있도록 필요한 권한을 부여했습니다. 그러나 CDK 코드에서는 그런 작업을 하지 않았습니다. CDK가 IAM 권한을 내부적으로 설정하기 때문입니다. CDK는 필요한 권한만 부여하여 더 안전합니다.\n\n다른 예시를 살펴봅시다. 람다 함수가 DynamoDB 테이블에 데이터를 추가하는 경우를 생각해보겠습니다. 인프라 개발자로서 우리는 람다가 어떻게 작동하는지 신경 쓸 필요가 없습니다. 우리는 람다와 DDB 테이블을 생성하고 람다가 DynamoDB에 데이터를 쓸 수 있는 권한을 부여하기만 하면 됩니다.\n\n먼저 CDK 코드를 살펴보겠습니다.\n\n```js\nimport * as cdk from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as dynamodb from 'aws-cdk-lib/aws-dynamodb';\n\nexport class MyStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // DynamoDB 테이블 생성\n    const table = new dynamodb.Table(this, 'MyTable', {\n      partitionKey: { name: 'id', type: dynamodb.AttributeType.STRING },\n      billingMode: dynamodb.BillingMode.PAY_PER_REQUEST,\n    });\n\n    // 람다 함수 생성\n    const myLambda = new lambda.Function(this, 'MyLambda', {\n      code: lambda.Code.fromAsset('path/to/your/lambda/code'), // 필요한 경우 경로를 조정\n      handler: 'index.handler',\n      runtime: lambda.Runtime.NODEJS_14_X,\n    });\n\n    // 람다 함수에 DynamoDB 테이블 쓰기 권한 부여\n    table.grantReadWriteData(myLambda);\n  }\n}\n\nconst app = new cdk.App();\nnew MyStack(app, 'MyStack');\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마음에 드실 정도로 간결하고 깔끔한 코드입니다. 우리는 ddb 테이블과 람다를 생성했습니다. 그 다음으로는 ddb 테이블의 grantReadWriteData 메서드를 사용하여 해당 람다를 전달했습니다. 이것으로 모든 필요한 IAM 권한을 처리합니다.\n\n이제 Terraform에서 같은 코드를 살펴보겠습니다.\n\n```js\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_dynamodb_table\" \"my_table\" {\n  name           = \"MyTable\"\n  billing_mode   = \"PAY_PER_REQUEST\"\n  hash_key       = \"id\"\n\n  attribute {\n    name = \"id\"\n    type = \"S\"\n  }\n}\n\nresource \"aws_iam_role\" \"lambda_execution_role\" {\n  name = \"lambda_execution_role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"lambda.amazonaws.com\"\n        }\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_policy\" \"ddb_access_policy\" {\n  name        = \"ddb_access_policy\"\n  description = \"람다가 DynamoDB 테이블에 액세스할 수 있는 정책\"\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"dynamodb:PutItem\",\n          \"dynamodb:UpdateItem\",\n          \"dynamodb:GetItem\",\n          \"dynamodb:Scan\",\n          \"dynamodb:Query\",\n          \"dynamodb:DeleteItem\"\n        ]\n        Effect   = \"Allow\"\n        Resource = aws_dynamodb_table.my_table.arn\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ddb_access_attachment\" {\n  role       = aws_iam_role.lambda_execution_role.name\n  policy_arn = aws_iam_policy.ddb_access_policy.arn\n}\n\nresource \"aws_lambda_function\" \"my_lambda\" {\n  function_name = \"MyLambdaFunction\"\n\n  filename         = \"이동/전달/패키지.zip의/경로\"\n  source_code_hash = filebase64sha256(\"이동/전달/패키지.zip의/경로\")\n  handler          = \"index.handler\"\n  runtime          = \"nodejs14.x\"\n  role             = aws_iam_role.lambda_execution_role.arn\n}\n```\n\n이 코드가 얼마나 지루한지 보이실 것입니다. 먼저 ddb 테이블을 생성하고, 그런 다음 람다 역할을 만듭니다. 이후 필요한 권한을 지정하는 정책을 만들고 해당 역할에 첨부합니다. 마지막으로 람다를 만들고 이 역할을 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 너무 길고 정책 문서에서 수동으로 권한을 지정하고 있습니다. 이렇게 하면 올바른 권한을 지정하지 않으면 액세스 문제가 발생할 수 있습니다.\n\n## 통합\n\nAWS CDK는 AWS SDK와 강력한 통합을 가지고 있습니다. 더 잘 이해하기 위해 람다 함수를 예로 들어봅시다.\n\nAWS 람다가 리눅스를 지원하고 있으며 Amd 및 Arm 기반의 두 가지 CPU 아키텍처만 지원한다는 점을 알고 있습니다. 또한 AWS는 파이썬, Node.js, Go 등 다양한 런타임을 지원합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제, 만약 람다 함수가 ARM 기반과 파이썬 런타임을 사용하고 개발자가 Windows 기계에서 작업 중이라면, 그는 OS에서 번들을 생성할 수 없을 것입니다. Lambda 런타임과 호환되지 않을 것입니다. 이 문제는 ARM 기반 리눅스 이미지를 사용하여 코드를 빌드하는 파이프라인을 사용하면 해결할 수 있습니다.\n\nCDK에서는 코드를 쉽게 Lambda에 배포할 수 있습니다. AWS CDK는 다른 런타임에 대해 다른 함수를 제공합니다.\n\n```js\n@aws-cdk/aws-lambda-python-alpha » PythonFunction\naws-cdk-lib » aws_lambda_nodejs » NodejsFunction\n@aws-cdk/aws-lambda-go-alpha » GoFunction\n```\n\n패키지를 사용하면 람다 함수의 소스 코드를 가리킬 수 있고 코드를 번들로 만들 필요가 없습니다. 번들링 옵션을 직접 선택할 수 있습니다. Node.js의 경우 esbuild, 다른 런타임의 경우 docker가 좋은 선택지입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nprivate createGetData(): PythonFunction {\n    const fn = new PythonFunction(this, \"GetData\", {\n      entry: join(__dirname, \"..\", \"src\", \"get-data\"),\n      runtime: lambda.Runtime.PYTHON_3_11,\n      bundling: {\n        assetExcludes: [\".venv\"],\n        assetHashType: AssetHashType.SOURCE\n      },\n      timeout: Duration.minutes(2),\n      index: \"lambda_handler.py\",\n      handler: \"lambda_handler\",\n      memorySize: 128\n    });\n    return fn;\n  }\n```\n\n위의 코드에서는 람다 코드 위치를 entry 매개변수에만 지정했습니다. 런타임이 파이썬이기 때문에 lambda_handler.py 및 requirements.txt 두 파일만 필요합니다.\n\n이 작업은 Terraform에서 수행할 수 없습니다.\n\n참고: AWS에서 풀 스택 개발을 수행 중이거나 AWS SDK 및 동시에 AWS 인프라 생성에 작업 중인 경우에 매우 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 마지막으로\n\n내 의견으로는, AWS CDK는 논의된 요소를 기반으로 Terraform을 능가한다고 생각합니다. 그러나 이것은 프로젝트와 조직의 특정 요구 사항에 따라 달라질 수 있는 주관적인 의견으로 인식합니다. 고유한 요구 사항과 상황에 기반하여 적합한 인프라스트럭처를 코드로 관리하는 도구(IaC)를 평가하고 선택하는 것이 중요합니다.\n\n# 내 프로젝트\n\n저는 Candletower(www.candletower.com)라는 프로젝트를 만들었습니다. 이 웹사이트는 캔들스틱 패턴 분석을 기반으로 한 주식 시장 분석을 제공합니다. 투자를 하거나 주식 시장에 입문하려는 경우, 이 웹사이트를 꼭 확인해보세요. 광고 없음, 로그인 없음, 완전 무료입니다. 여러분의 생각을 알려주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 읽어 주셔서 감사합니다!\n","ogImage":{"url":"/assets/img/2024-05-23-IsAWSCDKbetterthanTerraform_0.png"},"coverImage":"/assets/img/2024-05-23-IsAWSCDKbetterthanTerraform_0.png","tag":["Tech"],"readingTime":12},{"title":"ArgoCD와 Terraform으로 클라우드 리소스 조정하기","description":"","date":"2024-05-23 14:33","slug":"2024-05-23-OrchestratingCloudResourceswithArgoCDandTerraform","content":"\n## Terraform을 사용하여 ArgoCD 자동화하기\n\n최근 몇 년간 GitOps가 핫한 주제가 되었고, ArgoCD가 이 대화의 선두에 서 있습니다. GitOps를 많이 좋아하지만, 일상적인 작업에서는 GPC, AWS 및 온프레미스에서 클라우드 인프라를 관리해야 하며, 클라우드 리소스를 조정할 때 Terraform이 제 가장 좋아하는 도구입니다.\n\n![이미지](/assets/img/2024-05-23-OrchestratingCloudResourceswithArgoCDandTerraform_0.png)\n\n최근 RKE2 Kubernetes 클러스터를 사용하여 Cilium을 기본 네트워킹 솔루션으로 활용하는 프로젝트에 착수했습니다. 여러 테넌트 및 다양한 프로젝트를 효율적으로 처리하기 위해 애플리케이션 오케스트레이션을 ArgoCD로 선택했습니다. 이는 인기 있는 선택이지만, GitLab, GitHub 및 Bitbucket과 같은 다양한 버전 컨트롤 시스템에서 설정을 산재시킬 수 있는 선언적 애플리케이션 설정 방식을 가지고 있습니다. 전체적인 오케스트레이션 시스템을 구축하는 것은 많은 구성 요소를 고려해야 합니다. 이 게시물에서는 ArgoCD와 Terraform의 통합에 초점을 맞추어 이러한 도구들이 효과적인 애플리케이션 오케스트레이션을 위해 어떻게 원활하게 함께 작동하는지 강조하겠습니다. 이 접근 방식을 다양한 프로젝트에 성공적으로 통합하여 이해하기 쉽고 원활한 관리를 나타내었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# ArgoCD\n\n아르고 CD는 Kubernetes 애플리케이션의 선언적 지속적 전달을 위해 고안된 혁신적이고 오픈 소스 도구입니다. GitOps 지속적 전달 도구로서, ArgoCD는 Kubernetes 클러스터에서 애플리케이션의 배포와 관리를 자동화하고 최적화하는 데 도움을 줍니다. ArgoCD는 Git 저장소에서 애플리케이션의 원하는 상태를 정의하는 원칙에 따라 작동하며, 클러스터 내의 애플리케이션의 실제 상태가 선언된 상태로 수렴하도록 보장합니다.\n\n아르고 CD 인프라를 살펴보면, 여러 동적 구성 요소로 이루어진 모듈식으로 설계되었음을 알 수 있습니다. 한쪽에는 사용자 또는 CI 파이프라인이 새로운 애플리케이션의 배포를 시작하고, 다른 한쪽에는 실제 배포가 대상이 되는 Kubernetes 클러스터가 있습니다. ArgoCD는 선호하는 버전 관리 시스템(VCS)과 함께 중간 역할을 수행하여 설정을 사용자의 기호에 따라 구성할 수 있는 유연성을 제공합니다.\n\n이 유연성을 통해 회사 내 다른 팀의 액세스 수준을 자동화하고 제어하는 파트를 결정할 수 있습니다. 우리가 탐구할 설정은 생산 환경에서 효과적임이 입증되었으며, 이 프로젝트에 나중에 참여한 개발자들에게도 잘 받아들여졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 설계 선택 사항을 다루었으니, 기술적 세부 정보로 들어가 봅시다.\n\n# 요구 사항\n\n이 안내서는 기능적인 Kubernetes 클러스터가 있고 다음 전제 조건이 이미 설치되어 있다고 가정합니다:\n\n- Bitnami의 Sealed Secrets\n- Helm CLI 도구\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특정 쿠버네티스 배포 버전은 중요한 요소가 아닙니다. 배포 애플리케이션에 필요한 액세스만 있으면 됩니다. 저는 Rancher Kubernetes Engine 2 (RKE2)를 선택했는데, 이는 가벼우면서 다재다능한 Kubernetes 배포로 알려져 있어 간편하고 사용하기 쉽다는 장점이 있습니다. 또한 최신 보안 기준을 준수합니다. RKE2에 대한 더 깊은 통찰력을 얻으려면 이전 기사를 살펴보시고, Cilium의 기능과 어떻게 매끄럽게 통합되는지 알아보세요:\n\nSealed Secrets를 사용하기로 한 결정은 온프레미스 배포로 인해 GCP, AWS 또는 Azure에서 제공하는 관리형 솔루션과 다릅니다. 클라우드 제공업체를 활용하는 경우에는 SOPS가 배포 관련 비밀을 암호화하고 안전하게 보관하는 데 주목할만한 대안으로 제시됩니다. 하지만 우리의 온프레미스 시나리오에서는 Kubernetes에 더 네이티브한 솔루션을 채용했습니다:\n\n마지막으로, 이론적으로 OpenTofu 또는 Ansible이 유사한 결과를 달성할 수 있겠지만, HashiCorp BSL 라이선스 변경에 문제가 없어 Terraform을 계속 사용하게 되었습니다. Terraform과 Ansible 사이를 선택하는 실용적인 지침이 필요하다면 이 리소스를 확인하세요:\n\n# Terraform\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 마크다운 형식으로 변경해드리겠습니다.\n\n\n| 번호 | 항목   | 설명                            |\n|----|------|-------------------------------|\n| 1  | 이름   | 샘플 사용자                    |\n| 2  | 나이   | 30세                           |\n| 3  | 성별   | 여성                            |\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- ArgoCD 및 Sealed-Secrets Helm 차트 설치하기\n- ArgoCD 구성이 저장된 저장소를 참조 및 연결하기\n- ArgoCD 구성 저장소에서 구성 적용하기\n\n이 작업에서의 합리성은 ArgoCD 구성의 잠재적 복잡성에 있습니다. 별도의 저장소에 이를 구성함으로써 구조화된 접근 방식을 취할 수 있게 되며, 이에 대해 다음 섹션에서 보다 자세히 다루겠습니다. 또한 Terraform 구성을 포함하는 저장소가 ArgoCD 뿐만 아니라 다양한 인프라 관련 배포를 포함할 수 있다는 점을 고려할 때, 명확성과 관리 용이성을 위해 구분된 ArgoCD 구성 저장소를 선택하는 것이 도움이 됩니다. 예를 들어, 본 문서에서 철저히 논의한 Terraform을 사용한 Teleport 배포를 고려해보세요:\n\n## 비밀 관리\n\nTerraform 스크립트에서 강조되는 중요한 부분은 SSH 비밀 키를 암호화하기 위해 Sealed-secrets를 설치하고 활용하는 것입니다. 이 키는 ArgoCD가 특정 GitHub 저장소에서 응용 프로그램 구성을 검색하고 연결하는 데 필수적입니다. 이를 구성하는 다양한 방법이 있지만, 우리는 Kubernetes Secret 개체에 argocd.argoproj.io/secret-type: repo-creds 라벨을 사용하기로 선택했습니다. 이 라벨은 특정 접두사로 시작하는 저장소, 예를 들어 git@github.com:`your-github-username`,는 본인 인증을 위해 이 시크릿(우리의 경우 SSH 비밀 키)을 사용할 수 있음을 ArgoCD에 알려줍니다. 보다 명확한 이해를 위해, 이 파일 ssh-secret.yaml의 완전한 구성을 확인해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: argoproj-ssh-creds\n  namespace: argocd\n  labels:\n    argocd.argoproj.io/secret-type: repo-creds\nstringData:\n  url: git@github.com:\u003cyour-github-username\u003e\n  type: git\ndata:\n  sshPrivateKey: \u003cyour-super-secret-ssh-key\u003e\n```\n\n그러나 이것을 직접 버전 컨트롤 시스템 (VCS)에 푸시하는 것은 SSH 개인 키가 모두에게 노출되어 보안 위험이 발생한다는 것을 의미합니다. 이 우려를 해소하기 위해 Sealed-secrets를 사용하여 암호화하는 예방 조치를 취합니다. 이 조치로 sealed-ssh-secret.yaml이 생성됩니다. 이 암호화된 파일은 실제로 이전에 언급한 Terraform 스크립트에 의해 적용되며 ssh-secret.yaml을 삭제할 수 있습니다. Sealed Secrets가 작동하는 방식의 복잡성에 대해 자세히 알아가는 것은 이 글의 범위를 벗어납니다만, 자세한 탐구를 위해 다음 글을 참조할 수 있습니다:\n\n이러한 단계로 Terraform의 중요한 작업이 완료되었습니다. 그러나 이 스크립트가 참조하는 ArgoCD 구성 리포지토리 내의 컨텐츠를 이해하는 데 필요한 최종 퍼즐 조각에는 여전히 주목해야 합니다.\n\n# ArgoCD Configuration Repository\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nArgoCD의 선언적 구성을 사용하면 재배포 가능성이 권장됩니다. 이 저장소는 Argo의 구성의 기본 소스 역할을 합니다. 특히, UI를 통해 앱을 만들 경우, ArgoCD를 재배포하는 동안 자동으로 다시 생성되지 않음을 염두에 두세요.\n\n이 저장소는 다음과 같은 구조를 따릅니다. 이는 주관적 선택이며 개인적으로 매력적이고 명확하다고 생각합니다:\n\n```js\n├── apps\n│   ├── demo\n│   │   ├── config.yaml\n├── config\n│   ├── add-config.yaml\n├── projects\n│   ├── demo.yaml\n├── repositories\n│   ├── demo-app-config.yaml\n├── argo-config.yaml\n├── argo-projects.yaml\n└── argo-repositories.yaml\n```\n\n각 파일의 합리적인 근거와 이 구조를 권장하는 이유를 명확히 하기 위해 각 파일의 내용을 살펴보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- ./apps: 이 디렉토리는 ArgoCD Application 객체의 구성을 관리하고 응용 프로그램 구성이 저장된 외부 저장소를 가리킵니다. /apps/demo/config.yaml 파일의 예는 다음과 같습니다:\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: demo\nspec:\n  destination:\n    name: 'in-cluster'\n    namespace: \u003capp-namespace\u003e\n  source:\n    repoURL: '\u003cGitHub-저장소-URL\u003e'\n    targetRevision: \u003c대상-브랜치\u003e\n    path: './'\n  # 이 응용 프로그램이 속한 ArgoCD 프로젝트\n  project: demo\n```\n\n- ./config: 이 디렉토리는 ArgoCD 자체에 대한 추가 구성을 지정하는 데 사용됩니다. 예를 들어 회사 Slack 채널을 연결하여 응용 프로그램 관련 문제에 대해 개발자에게 알림을 보내는 알림 정책 구성이 포함됩니다.\n- ./projects: 이 디렉토리는 ArgoCD 프로젝트의 생성을 담당하며 다양한 응용 프로그램이 속할 수 있는 공동 공간 역할을 합니다.\n- ./repositories: 이 디렉토리는 응용 프로그램 구성을 가져올 수 있는 저장소를 whitelist로 지정하는 역할을 합니다.\n- ./argo-config.yaml, ./argo-projects.yaml 및 ./argo-repositories.yaml: Terraform으로 실행되는 ArgoCD Application 객체들입니다. 이들은 앞서 설명한 디렉토리에 정의된 ArgoCD 객체를 호출합니다. 다음은 argo-config.yaml의 예시이지만 다른 구성은 다른 파일들에도 적용됩니다:\n\n```js\n# Argo의 기본 구성. 이것은 helm/terraform 배포에 의해 설치된 앱입니다.\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: argo-config\n  namespace: argocd\nspec:\n  destination:\n    namespace: argocd\n    server: https://kubernetes.default.svc\n  project: default\n  # 각 저장소의 ./config 디렉토리에 대한 적용\n  source:\n    path: ./config\n    repoURL: \u003cargocd-구성-저장소-URL\u003e\n    targetRevision: \u003c대상-브랜치\u003e\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데모 애플리케이션을 위한 구성 파일이 이러한 폴더에 추가되었습니다:\n\n- projects/demo.yaml:\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: AppProject\nmetadata:\n  name: demo\n  namespace: argocd\n  # 해당 프로젝트가 어떠한 애플리케이션에도 참조되지 않을 때까지 삭제되지 않도록 하는 파이널 라이저\n  finalizers:\n    - resources-finalizer.argocd.argoproj.io\nspec:\n  description: 데모 애플리케이션\n  # 어떠한 Git 저장소에서도 배포할 수 있는 매니페스트 허용\n  sourceRepos:\n    - '*'\n  # 모든 애플리케이션이 모든 사용 가능한 클러스터의 모든 네임스페이스에 배포할 수 있도록 허용\n  destinations:\n    - namespace: '*'\n      server: '*'\n  # 앱에 의해 배포될 수 있는 쿠버네티스 오브젝트를 결정하는 정책\n  clusterResourceWhitelist:\n    - group: ''\n      kind: Namespace\n    - group: ''\n      kind: Deployment\n    - group: ''\n      kind: Service\n---\n\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: demo-apps\n  namespace: argocd\nspec:\n  destination:\n    namespace: argocd\n    server: https://kubernetes.default.svc\n  project: default\n  sources:\n    - path: ./apps/demo\n      repoURL: \u003capplication-repository-url\u003e\n      targetRevision: \u003ctarget-branch\u003e\n```\n\n- repositories/demo-app-config.yaml:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    argocd.argoproj.io/secret-type: repository\n  name: repo-kubernetes-config\n  namespace: argocd\nstringData:\n  name: \"demo-app-config\"\n  type: \"git\"\n  url: \u003capplication-repository-url\u003e\n  # No need to specify SSH Private Key since\n  # this is done by repo-creds in Terraform and applicable to all\n```\n\n이 설명은 이 리포지토리 구조를 선택한 이유와 왜 Terraform 리포지토리와 분리되었는지에 대해 밝혀줍니다. 비교적 간단한 예시라도 이 구조를 선택한 이유를 알 수 있게 해줍니다.\n\n애플리케이션 소스 코드와 분리된 별도의 Kubernetes 매니페스트용 Git 리포지토리를 활용하는 것이 여러 가지 이유로 매우 권장됩니다:\n\n- 깔끔한 분리: 응용 프로그램 코드와 구성을 명확히 구분하여 매니페스트를 격리된 수정 없이 불필요한 CI 빌드를 발생시키지 않고 수정할 수 있게 합니다.\n- 감사 로그의 명확성: 구성 전용 리포지토리는 감사 목적을 위한 더 깨끗한 Git 히스토리를 보장하여 정기 개발 활동으로 인한 잡음을 제거합니다.\n- 마이크로서비스 배포: 단일 단위로 배포되는 여러 리포지토리의 서비스로 구성된 응용 프로그램의 경우 중앙 구성 리포지토리에 매니페스트를 저장함으로써 다양한 버전 관리 체계와 릴리스 주기를 수용할 수 있습니다.\n- 접근 제어: 소스 코드와 구성 리포지토리를 분리하면 개발 중인 응용 프로그램에 작업하는 개발자가 프로덕션 환경에 직접 액세스할 수 없도록 구분된 액세스 제어를 제공합니다.\n- CI 파이프라인의 안정성: 무한한 작업 루프와 Git 커밋 트리거를 피하기 위해 매니페스트 변경을 별도 리포지토리에 푸시하여 CI 파이프라인의 안정성을 유지합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그게 전체 설정이에요 — 우리가 인프라 자원으로 흔히 참조하는 것들을 위한 한 저장소, 각 인프라 구성요소에 특화된 구성을 위한 별도의 저장소, 그리고 애플리케이션 매니페스트를 위한 세 번째 저장소가 있어요. 진짜 멋지죠?\n\n# 결론\n\n클라우드 인프라 관리 분야에서는 ArgoCD가 주도하는 GitOps 접근 방식이 상당한 인기를 얻었습니다. 클라우드 자원을 조정하는 이 여정을 통해 Terraform은 다양한 자원을 처리하는 중심 요소로 나타납니다. RKE2 Kubernetes 클러스터를 활용한 실제 프로젝트를 살펴보면, ArgoCD에 중점을 두어 애플리케이션 조정을 간소화하며, 이를 위해 Terraform과의 통합을 통해 선언적인 설정을 위한 원활한 설정을 탐구합니다. 이 게시물은 설계 선택의 이성, 깨끗한 저장소 구조의 필요성, 그리고 조율 환경에서 ArgoCD와 Terraform 사이의 조화로운 상호작용에 대한 실용적 가이드를 제공합니다.\n","ogImage":{"url":"/assets/img/2024-05-23-OrchestratingCloudResourceswithArgoCDandTerraform_0.png"},"coverImage":"/assets/img/2024-05-23-OrchestratingCloudResourceswithArgoCDandTerraform_0.png","tag":["Tech"],"readingTime":9},{"title":"웹 애플리케이션을 위한 변경 불가능한 인프라 구축하기 단계별 가이드","description":"","date":"2024-05-23 14:32","slug":"2024-05-23-BuildinganImmutableInfrastructureforYourWebApplicationAStep-by-StepGuide","content":"\n\n\n# 소개\n\n소프트웨어 개발의 빠르게 변화하는 세계에서 일관성, 확장성 및 신뢰성을 보장하는 것이 중요합니다. 데브옵스에서 핵심 개념인 불변 인프라는 인프라 구성요소를 불변하게 만들어 이러한 요구 사항을 해결합니다. 이 블로그에서는 Docker, Kubernetes 및 Terraform을 사용하여 간단한 웹 애플리케이션을 위한 불변 인프라를 생성하는 방법을 안내하겠습니다.\n\nwww.linkedin.com/in/mohammedtalhakalimi\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 불변 인프라란?\n\n불변 인프라는 서버(또는 다른 인프라 구성 요소)를 배포한 후에는 결코 수정하지 않는 방식을 말합니다. 업데이트나 변경이 필요한 경우 새로운 서버를 빌드하고 배포하며 이전 서버는 해제됩니다. 이 접근 방식은 일관성과 반복성을 보장하며 구성 드리프트를 줄이고 의도하지 않은 변경의 위험을 최소화합니다.\n\nwww.linkedin.com/in/mohammedtalhakalimi\n\n# 프로젝트 개요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 프로젝트에서는 Node.js 웹 애플리케이션을 위한 불변 인프라를 만들 것입니다. 이 프로젝트에는 다음이 포함됩니다:\n\n- Docker를 사용하여 애플리케이션을 컨테이너화하기\n- Kubernetes를 사용하여 배포를 조정하기\n- Terraform을 사용하여 인프라 프로비저닝 및 관리하기\n- CI/CD 파이프라인을 통해 빌드, 테스트 및 배포 프로세스 자동화하기\n\nwww.linkedin.com/in/mohammedtalhakalimi\n\n# 단계 1: Docker를 사용하여 애플리케이션을 컨테이너화하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 Docker를 사용하여 웹 애플리케이션을 컨테이너화해야 합니다. 프로젝트 디렉토리에 Dockerfile을 만들어주세요:\n\n```js\nDockerfile\n```\n\n```js\n# 부모 이미지로 공식 Node.js 런타임 사용\nFROM node:14\n```\n\n```js\n# 작업 디렉토리 설정\nWORKDIR /usr/src/app\n# package.json 복사 및 종속성 설치\nCOPY package*.json ./\nRUN npm install\n# 나머지 애플리케이션 코드 복사\nCOPY . .\n# 애플리케이션 포트 노출\nEXPOSE 3000\n# 앱 실행 명령 정의\nCMD [\"node\", \"app.js\"]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도커 이미지를 빌드하고 테스트해보세요:\n\n```bash\ndocker build -t my-web-app .\ndocker run -p 3000:3000 my-web-app\n```\n\n# 단계 2: 쿠버네티스로 오케스트레이션하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 도커 컨테이너를 쿠버네티스 클러스터에 배포할 것입니다. deployment.yaml 및 service.yaml 파일을 생성해주세요:\n\n```yaml\n# deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      containers:\n      - name: web-app\n        image: my-web-app:latest\n        ports:\n        - containerPort: 3000\n```\n\n```yaml\n# service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-app-service\nspec:\n  selector:\n    app: web-app\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 3000\n  type: LoadBalancer\n```\n\n쿠버네티스 구성을 적용해주세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```yaml\nkubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n```\n\nwww.linkedin.com/in/mohammedtalhakalimi\n\n# Step 3: Terraform으로 프로비저닝하기\n\n테라폼을 사용하여 쿠버네티스 클러스터를 프로비저닝할 것입니다. main.tf 파일을 작성해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# main.tf\nprovider \"aws\" {\n  region = \"us-west-2\"\n}\n```\n\n```js\nmodule \"eks\" {\n  source          = \"terraform-aws-modules/eks/aws\"\n  cluster_name    = \"my-cluster\"\n  cluster_version = \"1.20\"\n  subnets         = [\"subnet-0123456789abcdef0\", \"subnet-0123456789abcdef1\"]\n  vpc_id          = \"vpc-0123456789abcdef0\"\n  node_groups = {\n    my-node-group = {\n      desired_capacity = 2\n      max_capacity     = 3\n      min_capacity     = 1\n      instance_type = \"t3.medium\"\n    }\n  }\n}\noutput \"cluster_endpoint\" {\n  value = module.eks.cluster_endpoint\n}\n```\n\n테라폼 구성을 초기화하고 적용하십시오:\n\n```js\nterraform init\nterraform apply\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새 클러스터를 사용하도록 kubectl을 구성하세요:\n\n```bash\naws eks --region us-west-2 update-kubeconfig --name my-cluster\n```\n\nLinkedIn 프로필: www.linkedin.com/in/mohammedtalhakalimi\n\n# 단계 4: CI/CD로 자동화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, GitHub Actions를 사용하여 CI/CD 파이프라인을 설정할 것입니다. .github/workflows/ci-cd-pipeline.yaml 파일을 만들어주세요:\n\n```yaml\n# .github/workflows/ci-cd-pipeline.yaml\nname: CI/CD Pipeline\n```\n\n```yaml\non:\n  push:\n    branches:\n      - main\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v2\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v1\n    - name: Login to Docker Hub\n      uses: docker/login-action@v1\n      with:\n        username: ${secrets.DOCKER_USERNAME}\n        password: ${secrets.DOCKER_PASSWORD}\n    - name: Build and push Docker image\n      run: |\n        docker build -t my-web-app:latest .\n        docker tag my-web-app:latest ${secrets.DOCKER_USERNAME}/my-web-app:latest\n        docker push ${secrets.DOCKER_USERNAME}/my-web-app:latest\n  deploy:\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v2\n    - name: Set up kubectl\n      uses: azure/setup-kubectl@v1\n      with:\n        version: 'v1.20.0'\n    - name: Deploy to Kubernetes\n      run: |\n        kubectl apply -f deployment.yaml\n        kubectl apply -f service.yaml\n```\n\nwww.linkedin.com/in/mohammedtalhakalimi\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n위 단계를 따라 웹 애플리케이션을 위한 불변의 인프라를 구축했습니다. 이 방식을 통해 배포가 일관적이고 확장 가능하며 신뢰할 수 있음을 보장할 수 있습니다. 불변의 인프라 관행을 준수함으로써 응용 프로그램의 안정성과 관리 용이성을 크게 향상시킬 수 있습니다.\n\n의견이나 경험을 댓글로 공유해 주세요. 즐거운 코딩 되세요!\n\nwww.linkedin.com/in/mohammedtalhakalimi","ogImage":{"url":"/assets/img/2024-05-23-BuildinganImmutableInfrastructureforYourWebApplicationAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-05-23-BuildinganImmutableInfrastructureforYourWebApplicationAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":5},{"title":"에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes","description":"","date":"2024-05-23 14:29","slug":"2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings","content":"\n\n# Edge computing은 중요합니다\n\n현재 기업들은 머신러닝 및 실시간 애플리케이션과 같은 모든 종류의 워크로드에 대한 엣지 컴퓨팅의 혜택을 인정합니다. 이러한 시나리오에서는 데이터 처리를 로컬에서 수행해야 합니다.\n\n관련 데이터의 양이 많고 네트워크 연결이 제한적일 수 있습니다. 중앙 데이터 센터나 클라우드 컴퓨팅 환경에서 처리 및 분석을 수행하는 동안 빠른 응답 시간을 제공하는 것은 불가능합니다.\n\n엣지 컴퓨팅 사용 사례에서 이러한 소프트웨어 애플리케이션을 실행할 때 높은 가용성이 필수입니다. 단일 노드(단일 CPU, 디스크 등)를 의존하는 것은 완전히 위험합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 번잡한 패스트푸드 음식점의 포인트 오브 세일 애플리케이션이 클러스터 고장으로 다운되어 하루 매출(이상)을 손해 볼 때를 상상해보세요.\n\n또는 제조공장의 에지 서버가 고장나 IoT 디바이스를 운용 중이며, 생산이 중단될 때를 상상해보세요.\n\n또는 물류 창고에서 드론을 관리하는 컴퓨터 비전 앱이 하드웨어 고장으로 인해 작업자 안전이 위험에 처할 때를 상상해보세요.\n\n# 쿠버네티스에서의 고가용성은 비싸요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n에지 애플리케이션을 위한 고가용성 아키텍처를 구현하려면 일반적으로 사이트당 세 노드로 이동해야 합니다. 이것은 Kubernetes의 기본 키-값 저장소인 etcd가 일관성과 가용성을 보장하려면 최소 세 노드가 필요하기 때문입니다.\n\n빠뜨리기 쉬운 원가\n\n그리고 퀵 서비스 레스토랑 및 소매와 같은 섹터의 에지 배포는 종종 수만 개의 가게로 확장됩니다. 이로 인해 전사적인 세 개 노드 HA용으로 배포하는 비용은 빠르게 누적됩니다: 하드웨어, 케이블 연결, 전원, 그리고 센서 – 모두 중복됩니다!\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png)\n\n# 비용 지출 없는 가용성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 세 개가 아닌 두 개의 엣지 노드를 사용하여 비용 효율적이고 (대부분) 고가용성을 갖는 Kubernetes 클러스터를 제공할 수 있다면 어떨까요?\n\n작년 가을, Spectro Cloud 팀은 이 질문에 대한 답을 찾으려 노력했고 그 과정에서 진전 사항을 블로그와 KubeCon Paris에서의 프레젠테이션을 통해 공유했습니다 (이 때 데모 신이 우리 편은 아니었죠).\n\n오늘은 최신 2 노드 HA 아키텍처를 안내해 드릴 것이며, 이는 제대로 활용된 솔루션이며 제품 규모로 실행되는 엣지 Kubernetes 애플리케이션에 대해 약 33% 비용을 절감하는 해결책입니다!\n\n마지막으로 주의사항이 있습니다: CAP 이론 애호가 여러분을 걱정하며, 브루어의 불가침 제약을 극복했다고 주장하는 사람은 아무도 없습니다. 명확함을 위해 끝까지 읽어주세요...\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 솔루션 개요\n\n저희 2노드 HA 아키텍처는 Spectro Cloud의 기존, 검증된 엣지 솔루션을 사용하며 kairos, k3s, kube-vip, harbor 및 system-upgrader-controller를 포함한 오픈 소스 구성 요소 위에 구축됩니다.\n\n저희는 변경불가능하고 A/B 파티션으로 나눈 부팅 가능한 OS 이미지를 통해 솔루션을 배포합니다 (고마워요, Kairos). 저희 이미지에는 Kubernetes 배포 (주로 K3s), 독점적인 Go 에이전트 및 필요에 따라 개별적으로 추가하는 사용자 정의 소프트웨어가 포함됩니다. 모든 구성은 클라우드-컨피그 구문으로 선언적으로 지정되며 클라우드-이닛에 의해 실행됩니다.\n\n엣지 디바이스들은 초기에 등록 모드로 프로비저닝됩니다. 그 후 Spectro Cloud의 Palette 플랫폼이나 로컬 관리 GUI를 통해 클러스터에 추가되어 원하는 부팅 가능한 OS 이미지를 사용하여 설치 모드로 재부팅됩니다. Kubernetes가 온라인으로 되면 Go 에이전트에 의해 애드온이 설치되고 조정됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nImmutable upgrades are performed by streaming a new image to the node (or via USB for air-gapped use cases), writing it to disk, and rebooting from the B partition. If anything goes wrong, we automatically fail back to the A partition with known-stable configuration.\n\nFor two node support, we layered kine and postgresql into our existing edge solution and introduced a handful of additional mechanisms for lifecycle management, including liveness checks, a liveness client and server, and a finite state machine to ensure correctness of the kine endpoint configuration.\n\nAs always, a picture is worth a thousand words:\n\n![Image Description](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 가지 엣지 호스트가 프로비저닝되었습니다: 하나는 리더이고 다른 하나는 팔로워입니다. 양쪽 호스트에는 systemd 서비스로 구성된 Go 에이전트가 포함되어 있으며, 설정 가능한 주기로 지속적으로 살아있음 조정을 실행합니다. 살아있음 조정 루프는 각 호스트의 역할을 수정할 여부와 방법을 결정하는 유한 상태 기계(FSM)입니다.\n\n위 다이어그램은 명확성을 위해 개별적인 Kubernetes 구성 요소를 나타냈지만 실제로는 제어 플레인, kubelet 및 kube-proxy가 각 호스트의 단일 K3s 서버 프로세스에 포함되어 있습니다. 두 K3s 서버 모두 로컬 kine 프로세스의 데이터 저장소 엔드포인트로 http://localhost:2379를 사용하도록 구성되어 있습니다.\n\nKine 및 postgres는 각 호스트에서 systemd를 통해 구성되지만, 리더의 kine 엔드포인트는 로컬호스트의 postgres 프로세스를 가리키고 팔로워의 kine 엔드포인트는 리더의 postgres 프로세스를 가리킵니다.\n\n마지막으로, 두 postgres 프로세스 간에 단방향 논리 복제가 구성되어 있어서 각 호스트의 kine 테이블 내용을 동기화합니다. 두 kine 프로세스가 API 서버 트래픽을 리더로 인바운드하므로 모든 쓰기는 먼저 리더 데이터베이스에 기록된 다음 팔로워로 일관된 방식으로 복제됩니다. 각 호스트에서 부팅 시에 kine 및 k3s를 시작하기 전에 실행되는 한 번 실행되는 systemd 유닛인 kine 엔드포인트 조정기가 논리 복제 구성을 조율하고 kine 프로세스가 올바른 엔드포인트로 구성되어 있는지 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 초기화: 엣지 호스트 메타데이터\n\n시스템이 처음 프로비저닝될 때, 각 호스트는 호스트의 역할 및 주소, 컨트롤 플레인 엔드포인트 및 마지막 수정된 타임스탬프를 포함한 메타데이터 파일(이하 호스트메타로 지칭함)을 초기화합니다. 호스트메타 콘텐츠는 로컬 장치 구성(네트워크 인터페이스) 및 엣지 클러스터 구성의 조합에서 유추됩니다. 이 구성은 Spectro Cloud의 Palette 플랫폼에서 가져오거나 공기차단된 익스포트로부터 로드될 수 있습니다.\n\n```js\n// 호스트메타 예시\nlocalHost:\n  name: host-1\n  address: 10.10.10.1\n  uid: host-1-uid\naltHost:\n  name: host-2\n  address: 10.10.10.2\n  uid: host-2-uid\nleader:\n  name: host-1\n  address: 10.10.10.1\n  uid: host-1-uid\nfollower:\n  name: host-2\n  address: 10.10.10.2\n  uid: host-2-uid\ncontrolPlaneEndpoint: 10.10.10.0\nlastModified: \"Mon Apr 29 18:54:47 2024\"\n```\n\n호스트가 등록 모드에 있거나 특정 센티넬 파일인 /oem/.two-node-pause가 존재하는 경우, 라이브니스 조정은 무시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 센티넬 파일, /oem/.two-node-initialized,은 호스트 메타가 성공적으로 초기화된 후에 생성됩니다. 그 이후에는 엣지 클러스터 구성이 아닌 호스트 메타 파일만을 참조하여 역할 할당 및 상태 전이를 위해 사용됩니다. 이것은 클러스터가 완전히 연결이 끊겨 자체적으로 작동한다는 것을 의미합니다.\n\n## Kine 엔드포인트 조정기\n\nKine 엔드포인트 조정기는 먼저 /oem/.two-node-initialized 파일의 존재 여부를 확인합니다. 이 파일이 존재하지 않는 경우 미리 지정된 로컬 호스트 메타 파일을 가져와 /oem/.two-node-initialized 파일을 생성합니다.\n\n다음으로, 해당 호스트가 팔로워인 경우, 리더에서 발행 및 복제 슬롯 작업을 확인하거나 구성하기 위해 PostgreSQL 작업들의 일련을 수행합니다. 이 작업들은 리더에서 발행 및 팔로워에서 리더의 발행에 대한 구독을 포함합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템 상태에 따라 kine-endpoint-reconciler가 엣지 호스트 교체 작업을 수행할 수 있습니다.\n\n마지막으로, 로컬 및 원격 hostMeta 파일이 조정됩니다. 이 파일들이 일치하지 않으면 호스트의 역할이 변경될 수 있습니다. 즉, 승격 또는 강등될 수 있습니다. 이 단계에서 강등이 발생하면 로컬 Kubernetes 데이터베이스를 삭제하고 복제를 다시 구성하는 일련의 PostgreSQL 작업이 실행됩니다. 이는 로컬 Kubernetes 데이터베이스의 전체 동기화를 트리거합니다.\n\nkine-endpoint-reconciler가 완료되면 시스템은 정상 작동 모드로 들어가며 제어가 라이브니스 서비스로 전환됩니다.\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n키네 엔드포인트 조정기가 완료되면, 시스템은 정상 운영 모드로 전환되어 liveness 서비스로 제어가 전환됩니다.\n\n## Liveness reconciliation\n\n각각의 liveness 주기마다, 각 Go 에이전트는 두 개의 hostMeta 파일을 획득합니다. 하나는 로컬 파일 시스템에서 가져오고, 다른 하나는 대체 호스트의 liveness 서버에서 가져옵니다 (대체 호스트가 이용 가능하고 건강한 경우에만 일시적으로 검색됨). 이후 일련의 건강 검사가 실행되고, 결과에 따라 상태 전이가 발생할 수 있습니다:\n\n- 제어 플레인 엔드포인트로의 TCP 연결\n- 대체 호스트의 쿠버네티스 API 서버로의 TCP 연결\n- 대체 호스트에 대한 ICMP 핑\n- 건강 검사 스크립트 (선택사항) — 디스크 이용률, 메모리 압박 등을 확인하는 임의의 쉘 스크립트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 실패한 확인에 대해 카운터가 증가됩니다. 다음 다이어그램은 liveness-service의 조화 흐름을 보여줍니다:\n\n![Image](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_3.png)\n\n## 승급\n\n리더가 다운되고 팔로워의 라이브니스 서비스가 네 번의 건강 확인 실패를 감지하면 승급이 시작됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Image](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_4.png)\n\n프로모션 기간 중 팔로워 호스트에서 다음 이벤트 시퀀스가 발생합니다:\n\n- 다음 파일은 역할 변경을 반영하도록 업데이트됩니다:\n   - 로컬 호스트 메타 파일\n   - 다양한 클라우드 초기화 구성 파일\n   - kine 엔드포인트가 localhost를 가리키도록 다시 구성됨\n   - 리더에 대한 논리 복제 구독이 해제됨\n   - k3s 및 kine가 중지됨\n   - 다음 \"등록 해제\" SQL이 실행됨:\n\n```js\nDELETE FROM kine\nWHERE name LIKE '/registry/masterleases%'\nOR name LIKE '/registry/leases/%'\nOR name = '/registry/services/endpoints/default/kubernetes';\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n디폴트 네임스페이스에서 쿠버네티스 서비스의 엔드포인트를 삭제하면 k3s 서버가 손상된 호스트와의 웹소켓 터널을 끊게 됩니다.\n\n게다가, k3s를 다시 시작하면 모든 로컬 컨트롤러의 리소스 리소소르를 빠르게 확보하기 위해 kine 테이블에서 모든 k8s 리스를 삭제합니다.\n\n5. 다음의 \"시퀀스 복구\" SQL이 실행됩니다:\n\n```js\nSELECT setval('kine_id_seq', (SELECT MAX(id) FROM KINE), true);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 작업은 논리 복제 중에 시퀀스 데이터를 복제하지 않기 때문에 필수적입니다. 이 단계를 수행하지 않으면 kine 테이블에 prev_revision ` id로 새로운 행이 삽입되어 kine가 가정하는 키 불변성을 위반하고 데이터베이스 손상을 일으킬 수 있습니다.\n\n6. k3s 및 kine을 다시 시작합니다.\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_5.png)\n\n## Demotion\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n원래 리더였던 호스트가 일시적으로 오프라인 상태가 되면, 팔로워가 리더의 부재를 보완하여 자체를 승격합니다. 그 후 원래 리더가 온라인 상태로 돌아오면, 그의 kine-endpoint-reconciler은 불일치를 감지하고 강등을 시작합니다.\n\n강등 중에는 원래 리더(현재는 팔로워로 지칭함) 호스트에서 다음 일련의 이벤트가 발생합니다:\n\n- 리더(이후 팔로워로 지칭)는 두 호스트의 역할 변경을 반영하도록 다음 파일을 업데이트합니다:\n    - 로컬 호스트 메타\n    - 다양한 클라우드 초기화 구성 파일\n    - kine 엔드포인트를 localhost가 아닌 새 리더를 가리키도록 다시 구성합니다.\n    - 현재 리더의 데이터베이스에 게시물이 생성됩니다(이미 존재하지 않는 경우).\n    - 팔로워는 kine 테이블의 내용을 삭제합니다.\n    - 팔로워는 copy_data = true로 리더의 게시물을 구독하여 전체 kine 테이블을 다시 동기화합니다.\n    - 비활성 복제 슬롯이 이미 있는 경우 사용하고, 그렇지 않으면 리더에 새로운 복제 슬롯이 생성됩니다.\n    - k3s 및 kine이 다시 시작됩니다.\n\n## Edge 호스트 교체\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 두 호스트 중 하나가 영구적으로 손상된 경우(예: 하드 드라이브 고장, NIC 고장 등), 대체 장치가 엣지 사이트로 발송됩니다. 새 장치 부팅 후 저하된 팔로워를 원활하게 대체하며, 그 후 해당 장치를 폐기할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_6.png)\n\n대체 호스트가 부팅되며 클러스터 구성에 액세스하면 현재 리더의 주소 및 현재 팔로워임을 표시합니다. 연결된 환경에서는 클러스터 구성이 팔레트 플랫폼으로부터 가져옵니다. 공기가락된 환경에서는 새 대체 호스트가 \"클러스터 구성 내보내기\"로 미리 초기화됩니다.\n\n대체 호스트의 kine-endpoint-reconciler가 리더의 hostMeta를 요청하고 리더에 의해 팔로워로 간주되지 않음을 확인하고, 대체 API를 통해 리더에게 자신의 존재를 알리게 됩니다. 이로써 리더는 자신의 hostMeta를 업데이트하여 새 호스트를 팔로워로 등록합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 대체 호스트는 강등에서 설명한 것과 동일한 방식으로 리더를 구독하며, 이는 리더의 kine 테이블 전체를 복제하게 됩니다.\n\n## 업그레이드\n\n업그레이드 중에는 승급 또는 강등이 없습니다(호스트는 원래의 역할을 유지), 그러나 리더가 다시 부팅하는 동안 필수적인 API 서버 다운 타임이 발생합니다. 다음 표는 업그레이드 중 발생하는 이벤트 순서를 보여줍니다:\n\n![Sequential Events during Upgrade](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 개의 호스트는 시스템 업그레이드 컨트롤러 계획을 통해 모든 제어 평면 노드를 무작위 순서로 대상으로 업데이트됩니다. 업그레이드를 시작하기 전에 Go 에이전트가 각 호스트의 라이브니스 서비스를 일시 중지시킵니다. 이로써, 리더가 먼저 업그레이드되는 경우에 팔로워가 자신을 승격하지 못하도록합니다. 두 호스트가 모두 업그레이드된 후에는 그들의 라이브니스 서비스가 다시 시작됩니다.\n\n## 대체 업그레이드 흐름\n\n대체 업그레이드 흐름이 가능합니다. 여기서는 먼저 팔로워가 업그레이드되고, 그 후 호스트의 역할이 교환되어(팔로워 승격, 리더 강등) 원래의 리더가 업그레이드되는 흐름이 있습니다. 그러나 이러한 흐름은 매우 복잡하며 오류가 발생할 가능성이 있습니다. 첫째, 강등으로 인해 데이터베이스가 삭제되고 다시 동기화되어야 하므로, 위의 흐름을 선택했습니다.\n\n참고: 더 복잡한 흐름에서는 파드가 다시 균형을 이루는 데 걸리는 시간으로 인해 여전히 다운 타임이 있습니다. 아래 K8s 구성 옵션은 건강하지 않은 노드를 감지하고 해당 노드에서 파드가 추방될 때까지 걸리는 시간을 결정합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```json\nkube-controller-manager-arg:\n- node-monitor-period=5s\n- node-monitor-grace-period=20s\n```\n\n# HA 및 CAP 이론: 우리가 얼마나 잘 했을까요?\n\n소개에서는 CAP 이론과 솔루션의 (대부분) 고가용성에 대해 더 상세히 설명할 것을 약속했습니다. 제가 A*P라고 부르는 것입니다:\n\n- 일관성이 최종적으로 일치하기 때문에 일관성을 나타내는 C는 제외합니다.\n- 가용성을 나타내는 A에 별표가 붙는 이유는 프로모션, 강등 및 업그레이드 중에 일부 API 서버 다운타임이 발생하기 때문입니다 (벤치마크에 따르면 평균 4.5분). 그러나 팔로워에 배포된 어떠한 애플리케이션도 완전히 사용 가능할 것입니다. 이 아키텍처로 고가용성을 달성하기 위한 핵심은 모든 애플리케이션이 데몬셋이거나 적어도 하나의 레플리카가 각 노드에서 실행되도록 탑톨로지 분산 제약 조건을 가져야 한다는 것입니다. 롱혼은 상태 있는 애플리케이션을 위해 충돌 일관된 블록 스토리지를 제공하기 위해 쉽게 설치될 수 있습니다.\n- 파티션 허용도를 나타내는 P는 hostMeta의 lastModified 타임스탬프를 사용하여 처리됩니다. 네트워크 분할이 발생한 경우 두 호스트가 자체 프로모션합니다. 분할이 해소되면 가장 최근에 업데이트된 호스트가 \"승리\"합니다. 패배한 호스트는 자신을 강등시키고 승리자의 데이터베이스 내용을 복사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n의심의 여지없이, 3 노드 Kubernetes 클러스터는 아마도 덜한 아키텍처 복잡성으로 더 강력한 보장을 제공하지만, 규모에 따라 상당한 자본 투자가 필요합니다. 자체 상자 비용 뿐만 아니라 케이블링, 배송, 소프트웨어, 전력 소비 등의 비용도 발생합니다. 비용을 최적화하거나 엣지 컴퓨팅 사용 사례를 고려 중이라면, 2 노드 솔루션이 즉시 비용을 절감하고 중요한 절감을 실현할 수 있을 것입니다.\n\n마지막으로, K3s, kine 및 NATS를 사용한 2 노드 솔루션을 추구하며 한계를 느낀 Synadia 팀으로부터 영감을 받았다는 점을 언급하지 않을 수 없습니다. 그들의 작품은 우리 자신의 계획을 영감주었습니다.\n\n이렇게 멀리까지 읽어주셔서 감사합니다. 궁금한 점이 있으면 직접 tyler@spectrocloud.com 으로 문의하거나 Spectro Cloud 커뮤니티 Slack을 확인해주시기 바랍니다.\n\n그리고 쿠버네티스를 활용한 엣지 컴퓨팅 프로젝트를 진행 중이라면, 당사의 Palette Edge를 살펴보시고 도움이 필요한 부분이 있는지 확인해주시기 바랍니다.","ogImage":{"url":"/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png"},"coverImage":"/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png","tag":["Tech"],"readingTime":11},{"title":"Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법","description":"","date":"2024-05-23 14:28","slug":"2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover","content":"\n\n![Health probes](/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png)\n\n헬스 프로브는 견고한 클러스터를 유지하는 중요한 부분입니다. 프로브를 사용하면 클러스터가 응답 여부를 반복적으로 조사하여 응용 프로그램의 상태를 결정할 수 있습니다.\n\n일련의 헬스 프로브는 클러스터가 다음 작업을 수행하는 능력에 영향을 미칩니다:\n\n- 실패 중인 팟을 자동으로 다시 시작을 시도하여 충돌 방지\n- 건강한 팟에게만 요청을 보내어 장애 극복 및 부하 분산\n- 팟이 실패하는 시기와 이유를 결정하여 모니터링\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 프로브 유형\n\n쿠버네티스는 다음과 같은 프로브를 제공합니다: 시작, 준비 및 활성화. 어플리케이션에 따라 하나 이상의 이러한 유형을 구성할 수 있습니다.\n\n## 준비 프로브\n\n준비 프로브는 어플리케이션이 요청을 처리할 준비가 되어 있는지 확인합니다. 준비 프로브가 실패하면 쿠버네티스가 해당 어플리케이션에 대한 클라이언트 트래픽이 도달하는 것을 방지하기 위해 서비스 리소스에서 포드의 IP 주소를 제거합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n준비성 검사는 애플리케이션에 영향을 미칠 수 있는 일시적 문제를 감지하는 데 도움을 줍니다. 예를 들어, 애플리케이션이 시작될 때 초기 네트워크 연결을 설정하거나 캐시에 파일을 로드하거나 완료하는 데 시간이 걸리는 초기 작업을 수행해야 하기 때문에 애플리케이션이 일시적으로 사용할 수 없을 수 있습니다. 애플리케이션이 가끔은 긴 일괄 작업을 실행해야 할 수도 있어 클라이언트에게 일시적으로 사용할 수 없게 만듭니다.\n\nKubernetes는 애플리케이션이 실패한 후에도 계속해서 검사를 실행합니다. 검사가 다시 성공하면 Kubernetes는 포드의 IP 주소를 서비스 리소스에 다시 추가하고 요청을 다시 해당 포드로 보냅니다.\n\n이러한 경우에 준비성 검사는 일시적 문제를 해결하고 애플리케이션 가용성을 향상시킵니다.\n\n## 생존성 검사\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n준비 프로브와 마찬가지로, 라이브니스 프로브는 응용 프로그램의 수명 동안 호출됩니다. 라이브니스 프로브는 응용 프로그램 컨테이너가 건강한 상태인지를 확인합니다. 응용 프로그램이 라이브니스 프로브에 충분한 횟수로 실패하면 클러스터는 다시 시작 정책에 따라 파드를 다시 시작합니다.\n\n시작 프로브와 달리, 라이브니스 프로브는 응용 프로그램의 초기 시작 프로세스 이후에 호출됩니다. 보통 이 조치는 파드를 다시 시작하거나 다시 만들어서 해결됩니다.\n\n## 시작 프로브\n\n시작 프로브는 응용 프로그램의 시작이 완료된 시점을 결정합니다. 라이브니스 프로브와 달리, 시작 프로브는 성공한 후에도 호출되지 않습니다. 설정 가능한 시간 초과 후에 시작 프로브가 성공하지 않으면, 해당 파드는 다시 시작 정책 값에 기반하여 다시 시작됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앱 시작 시간이 긴 애플리케이션에 스타트업 프로브를 추가하는 것을 고려해보세요. 스타트업 프로브를 사용하면 라이브니스 프로브를 짧고 빠르게 유지할 수 있습니다.\n\n# 테스트 유형\n\n프로브를 정의할 때 수행할 테스트 유형을 다음 중 하나로 지정해야 합니다:\n\nHTTP GET\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 번 업된 때는 물고기가 클러스터에게 지정된 HTTP 엔드포인트로 요청을 보냅니다. 요청에 대한 응답이 200에서 399 사이의 HTTP 응답 코드로 오면 테스트는 성공한 것으로 간주됩니다. 다른 응답은 테스트를 실패하게 만듭니다.\n\n컨테이너 명령어\n\n각 번 업된 때는 물고기가 컨테이너에서 지정된 명령어를 실행합니다. 명령이 0의 상태 코드로 종료되면 테스트가 성공합니다. 다른 상태 코드는 테스트에 실패하게 만듭니다.\n\nTCP 소켓\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로브가 실행될 때마다 클러스터는 컨테이너에 소켓을 열려고 시도합니다. 연결이 수립되어야만 테스트가 성공합니다.\n\n# 시간과 임계값\n\n모든 유형의 프로브에는 시간 변수가 포함되어 있습니다. 주기 초 변수는 프로브가 실행되는 빈도를 정의합니다. 실패 임계값은 프로브 자체가 실패하기 전에 필요한 실패 시도 횟수를 정의합니다.\n\n예를 들어, 실패 임계값이 3이고 주기 초가 5인 프로브는 전체 프로브가 실패하기 전에 최대 세 번 실패할 수 있습니다. 이 프로브 구성을 사용하면 문제가 해결되기 전 10초 동안 문제가 발생할 수 있습니다. 그러나 너무 자주 프로브를 실행하면 리소스를 낭비할 수 있습니다. 프로브를 설정할 때 이러한 값을 고려해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시 1\n\n```yaml\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-exec\nspec:\n  containers:\n    - name: liveness\n      image: registry.k8s.io/busybox\n      args:\n        - /bin/sh\n        - -c\n        - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600\n      livenessProbe:\n        exec:\n          command:\n            - cat\n            - /tmp/healthy\n        initialDelaySeconds: 5\n        periodSeconds: 5\n```\n\n예시 2\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-app-liveness-pod\nspec:\n  containers:\n    - name: hello-app-container\n      image: gcr.io/google-samples/hello-app:1.0 # 애플리케이션 이미지로 교체하세요\n      ports:\n        - containerPort: 8080 # 애플리케이션의 수신 포트와 일치해야 합니다\n      livenessProbe:\n        httpGet:\n          path: /\n          port: 8080\ninitialDelaySeconds: 15 # 컨테이너가 시작된 후 생존성 프로브가 시작되기까지의 시간(초)\nperiodSeconds: 10 # 프로브를 수행하는 주기(초)\ntimeoutSeconds: 1 # 응답을 기다리는 시간(초)\nfailureThreshold: 3 # 재시작하기 전에 허용되는 실패 횟수\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오픈쉬프트에서 oc set probe 명령은 배포에 프로브를 추가하거나 수정합니다. 예를 들어, 다음 명령은 front-end라는 배포에 준비 상태 프로브를 추가합니다:\n\n```js\noc set probe deployment/front-end \\\n--readiness \\\n--failure-threshold 6 \\\n--period-seconds 10 \\\n--get-url http://:8080/healthz\n```\n\nset probe 명령은 RHOCP와 oc에만 존재합니다.\n","ogImage":{"url":"/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png"},"coverImage":"/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png","tag":["Tech"],"readingTime":4},{"title":"Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기","description":"","date":"2024-05-23 14:24","slug":"2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets","content":"\n\u003cimg src=\"/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png\" /\u003e\n\n시리즈의 이전 기사에서는 GitOps 환경을 모델링하고 응용 프로그램을 이 환경 간에 프로모션하는 방법을 설명했습니다. 그 기사는 단일 응용 프로그램과 해당 Kubernetes 리소스에 초점을 맞춰 작성되었습니다. 본 기사에서는 여러 관련 주제를 살펴보겠습니다:\n\n- Argo CD 애플리케이션 매니페스트를 넣는 위치\n- 여러 팀/클러스터/응용 프로그램과 어떻게 작업할 것인지\n- 더 쉬운 관리를 위해 Application Sets를 활용하는 방법\n- 단일 저장소 대신 GitOps 저장소를 분리하는 방법\n\n항상 그렇지만, 우리의 조언은 모범 사례를 따르는 일반적인 권장 사항입니다. 조직에 대한 시작점으로 활용할 수 있지만, 본인의 경우에 더 나은 접근 방식이 있다고 믿는다면, 언제든지 우리가 언급한 패턴을 본인의 환경에 맞게 적용하시기 바랍니다. 예시 저장소는 다음에서 확인할 수 있습니다: https://github.com/kostis-codefresh/many-appsets-demo\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앞선 기사는 매우 일반적이었고 Flux 사용자에게도 적용될 수 있지만, 여기서는 특히 Argo CD와 그 고급 기능에 초점을 맞출 것입니다.\n\n# 매니페스트의 다양한 유형\n\nArgo CD 애플리케이션을 조직하는 방법은 많은 자료와 블로그에서 다뤄지는 인기 있는 주제이며, 사용자들의 지속적인 질문과 토론이 있습니다. 불행히도 대부분의 기존 자료에서 다양한 매니페스트 유형을 혼합하며 응용 프로그램 세트와 그 기능에 대한 언급이 전혀 없습니다. \"매니페스트\"라는 용어는 Argo CD와 GitOps의 경우 오버로딩된 경우도 많습니다. 그래서 먼저 다양한 매니페스트 유형을 정의해봅시다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 카테고리는 Argo CD와 전혀 상관없는 표준 Kubernetes 자원(배포, 서비스, 인그레스, 구성, 시크릿 등)으로, 이러한 자원들은 쿠버네티스 클러스터에서 정의됩니다. 이러한 자원은 어플리케이션이 쿠버네티스 내에서 어떻게 실행되는지를 기술하며, Argo CD가 전혀 없는 로컬 클러스터에 어플리케이션을 설치하는 데 사용될 수 있습니다. 이러한 manifest는 개발자가 새로운 릴리스를 배포하면서 자주 변경되며, 일반적으로 다음과 같은 방법으로 지속적으로 업데이트됩니다:\n\n- 배포 manifest에서 컨테이너 이미지 버전을 업데이트하는 경우 (대부분의 경우 약 80%)\n- 컨테이너 이미지와 함께 configmap이나 시크릿에 대한 구성을 업데이트하는 경우 (대부분의 경우 약 15%)\n- 비즈니스 또는 기술 속성을 세부 조정하기 위해 구성만 업데이트하는 경우 (대부분의 경우 약 5%)\n\n이러한 manifest는 어플리케이션의 상태를 설명하기 때문에 개발자에게 매우 중요하며, 조직 환경(QA/Staging/Production 등)에서 모든 어플리케이션의 상태를 설명하는 데 사용됩니다. 프로모션 기사는 특히 이러한 유형의 manifest에 대해 언급했습니다.\n\n두 번째 카테고리는 Argo CD 어플리케이션 manifest입니다. 이들은 사실의 원천(첫 번째 유형의 manifest)과 해당 어플리케이션의 대상 및 동기화 정책을 참조하는 정책 설정입니다. Argo CD 어플리케이션은 근본적으로 Git 저장소(표준 Kubernetes manifest를 포함하는)와 대상 클러스터 간의 매우 간단한 링크입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_2](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_2.png)\n\n많은 사람들이 생각하는 것과는 달리, 개발자들은 이러한 유형의 manifest로 괴롭힘받길 원하지 않아요. 운영자들에게도 이 유형의 manifest는 한 번 설정하고 나면 그냥 잊어버릴 것입니다. 어플리케이션 세트 manifest 역시 동일한 범주에 속합니다.\n\n세 번째와 네 번째 범주는 첫 번째와 두 번째와 동일하지만, 이번에는 개발자들이 만드는 내부 애플리케이션 대신 인프라 애플리케이션(cert manager, nginx, coredns, prometheus 등)에 대해 이야기합니다.\n\n이 manifest에 대해 개발자의 애플리케이션과 다른 템플릿 시스템을 사용할 수 있습니다. 예를 들어, 준비된 애플리케이션에 대해서는 Helm을 사용하고, 개발자가 만든 애플리케이션에 대해서는 Kustomize를 선택하는 매우 인기 있는 패턴이 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 4가지 종류의 manifests로 핵심 포커스는 아래 2가지 카테고리에 대한 것입니다.\n\n- 개발자들은 인프라 manifests에 대해 신경 쓰지 않습니다.\n- 이러한 manifests는 매우 자주 변경되지 않습니다. 보통 해당 구성 요소를 업그레이드하거나 매개 변수를 세밀하게 조정할 때에만 변경됩니다.\n\n여기서 중요한 점은 이 4가지 유형의 manifests가 대상 청중과 무엇보다도 변경 빈도 등 여러 측면에서 서로 다른 요구 사항을 갖고 있다는 것입니다. \"GitOps 리포지토리 구조\"에 대해 이야기할 때, 어떤 카테고리의 manifests에 대해 이야기하는 지 (다수일 경우) 항상 먼저 설명해야 합니다.\n\n# 안티 패턴 1 — 서로 다른 유형의 manifests 혼합\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장 좋은 방법을 설명하기 전에 장기적으로 문제를 복잡하게 만들 수 있는 몇 가지 안티 패턴에 대해 경고하는 것이 중요합니다.\n\n매니페스트의 중요한 포인트 중 하나는 Kubernetes(카테고리 1)와 Argo CD 리소스(카테고리 2) 사이에 매우 명확한 분리를 가져야 한다는 것입니다. 편리하게, Argo CD에는 두 카테고리를 섞을 수 있게 해주는 여러 기능이 있습니다. 일부 극히 드문 경우에는 필요하지만, 다른 유형의 매니페스트를 섞는 것을 권장하지 않습니다.\n\n간단히 예를 들어, Argo CD는 다음과 같은 구문을 지원합니다:\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-helm-override\n  namespace: argocd\nspec:\n  project: default\n\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    path: my-chart\n\n\n    helm:\n      # 이렇게 하지 말아주세요\n      parameters:\n      - name: \"my-example-setting-1\"\n        value: my-value1\n      - name: \"my-example-setting-2\"\n        value: \"my-value2\"\n        forceString: true # 값이 문자열로 처리되도록 보장\n\n\n      # 이렇게 하지 말아주세요\n      values: |\n        ingress:\n          enabled: true\n          path: /\n          hosts:\n            - mydomain.example.com\n\n\n      # 이렇게 하지 말아주세요\n      valuesObject:\n        image:\n          repository: docker.io/example/my-app\n          tag: 0.1\n          pullPolicy: IfNotPresent\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 매니페스트는 두 가지를 동시에 수행합니다. 주 파일은 Argo 앱(카테고리 2)에 관한 내용이지만, \"helm\" 속성은 실제로 Kubernetes 응용 프로그램(카테고리 1)에 대한 값들을 포함하고 있습니다.\n\n이 매니페스트는 다음과 같이 차트와 동일한 Git 저장소에 있는 값 파일에 모든 매개변수를 넣음으로써 쉽게 수정할 수 있습니다.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-helm-override\n  namespace: argocd\nspec:\n  project: default\n\n\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    path: my-chart\n\n\n    helm:\n      ## 이렇게 하세요 (Git의 값 파일 개별로)\n      valueFiles:\n      - values-production.yaml\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n또한 Helm 어머렐라 차트를 사용하는 경우, 다른 차트를 참조하고 해당 값들을 재정의할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n외부 차트(즉, Git에 저장되지 않은)를 사용하는 것도 가능하지만, 우리가 추천하는 방법은 아닙니다. 제3자 소스에서 외부 차트를 사용하는 것은 보안 및 안정성 측면에서 많은 도전점을 제시합니다.\n\n이상적으로 모든 Helm 차트는 귀하의 통제 하에 있어야 하며 Git에 있어야 합니다. 이렇게 하면 GitOps의 모든 이점을 얻을 수 있습니다.\n\n하지만 때로는 이게 불가능한 경우도 있습니다. 그래서 최후 수단으로만 외부 Helm 차트를 참조하면서 여전히 로컬에 저장된 자체 값을 사용할 수 있습니다. 이 가이드를 작성하는 시점에 이 기능이 베타 버전임을 유의하십시오.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-proper-helm-app\n  namespace: argocd\nspec:\n  sources:\n  - repoURL: 'https://my-chart/helm-charts'\n    chart: my-helm-chart\n    targetRevision: 3.7.1\n    helm:\n      valueFiles:\n      - $values/my-chart-values/values-prod.yaml\n    ## DO THIS (values in Git on their own)\n  - repoURL: 'https://git.example.com/org/value-files.git'\n    targetRevision: dev\n    ref: values\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마찬가지로 Argo CD는 다음을 지원합니다:\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-kustomize-override\n  namespace: argocd\nspec:\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    path: my-app\n\n    # 이렇게 하지 마세요\n    kustomize:\n      namePrefix: prod-\n      images:\n      - docker.io/example/my-app:0.2\n      namespace: custom-namespace\n\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n여기서 Kustomize의 속성들(category 1)이 다시 주 응용 프로그램 매니페스트 (category 2)와 섞입니다. 이를 피하기 위해 Kustomize 값을 웹 애플리케이션 CRD에 하드 코딩하는 대신 오버레이로 저장하는 것이 좋습니다.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-proper-kustomize-app\n  namespace: argocd\nspec:\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    ## 이렇게 하세요. Kustomize 오버레이에 모든 값을 저장하세요\n    path: my-app/overlays/prod\n\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 여러분의 매니페스트가 올바르게 분할되었는지 이해하기 위한 리트머스 테스트는 다음 질문을 하는 것입니다:\n\n\"만약 개발자가 Kubernetes 리소스에 대해 전문가이지만 Argo CD에 대해서는 전혀 모른다면, 오직 kustomize(또는 Helm)만을 사용하여 자신의 노트북에 애플리케이션을 설치할 수 있을까요?\"\n\n만약 답이 \"아니오\"라면, 그렇다면 여러분은 Kubernetes 매니페스트가 Argo CD 애플리케이션과 어우러져 있는 부분을 찾아내고 강력한 결합을 제거해야 합니다.\n\n매니페스트를 혼합하는 함정에 빠져들어가 있는 기관들을 많이 보았습니다. 대화를 나눌 때 거의 항상, 그 기관들은 이러한 접근 방식이 \"필요하다\"고 생각했던 것입니다. 왜냐하면 그들은 기반이 되는 도구들(Helm/Kustomize)의 능력을 제대로 이해하지 못했기 때문입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n귀하의 조직이 Helm과 작업하는 경우, Helm 값 계층이 어떻게 작동하는지, 그리고 Helm 어머니 차트가 어떻게 작동하는지 알아야 합니다. 신중하게 설계된 Helm 값 계층으로 대부분의 일반적인 시나리오를 다룰 수 있습니다. Argo CD의 다중 소스 기능을 사용해야 할 경우에만 사용하세요. 그리고 현재 베타 버전이라는 것을 기억하세요.\n\n귀하의 조직이 Kustomize와 작업하는 경우, 구성 요소(재사용 가능한 블록)의 작동 방식과 모든 다양한 변환기/패치/대체 방법을 알아야 합니다.\n\n나중 장에서 볼 수 있듯이 두 종류의 manifest를 구분하는 것은 좋은 실천 방법입니다. 그러나 이전 섹션에 표시된 표에서는 생명 주기가 다른 것들을 섞는 것이 항상 문제의 원인임을 명백히 알 수 있어야 합니다.\n\n다른 종류의 manifest를 섞는 것에는 여러 가지 다른 도전과제가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 모든 관련 당사자들이 이해하기 어렵게 만듭니다.\n- 매니페스트를 사용하는 사람들(예: 개발자)과 매니페스트를 생성하는 사람들(즉, 관리자/운영자) 사이의 요구사항을 혼란스럽게 합니다.\n- 매니페스트를 특정 Argo CD 기능에 결합시킵니다.\n- 보안 관련 문제를 분리하기가 더 복잡해집니다.\n- 더 많은 부분들을 움직이게 하고 디버깅하기 어려운 시나리오를 야기합니다.\n- 개발자들에 대한 로컬 테스트를 더 어렵게 만듭니다.\n\n참고: 사용하지 말아야 할 다른 Argo CD 기능은 파라미터 오버라이드입니다. 가장 원시적인 형태에서 심지어 GitOps 원칙을 따르지 않습니다. Git에 저장해도 Argo CD와 쿠버네티스 정보가 동일한 위치에 혼합되어 있게 됩니다(카테고리 1 및 카테고리 2 정보 혼합).\n\n# 안티 패턴 2 — 잘못된 추상화 수준에서 작업\n\nArgo CD 애플리케이션 CRD의 목적은 주요 쿠버네티스 매니페스트를 '래퍼' 또는 '포인터'로 작동하는 것입니다. 중요한 것은 쿠버네티스 매니페스트(카테고리 1)와 Argo CD 매니페스트(카테고리 2)가 언제나 보조 역할을 해야 한다는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이상적인 경우에는 한 번 Application manifest를 만들어서 어떤 Git 저장소가 어떤 클러스터로 이동하는지 정의하고 이 파일을 다시는 손대지 않는 것이 좋습니다 (이것이 이전 테이블에서 변경 빈도가 \"거의 없음\"인 이유입니다).\n\n안타깝게도 많은 회사들이 실제 쿠버네티스 manifest 대신에 Application CRD를 주 작업 단위로 사용하는 것을 볼 수 있습니다.\n\n전형적인 예로는 CI 프로세스를 사용하여 Application의 \"targetRevision\" (또는 \"path\") 필드를 자동으로 업데이트하는 경우가 있습니다.\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  ## 이렇게 하지 마세요\n  name: my-ever-changing-app\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: dev\n    ## 이전에는 \"targetRevision: staging\"이었고, 그 이전에는 \"targetRevision: 1.0.0\"였으며,\n    ## 그보다 전에는 \"targetRevision: 1.0.0-rc\" 였습니다.\n    path: my-staging-app\n    ## 이전에는 \"path: my-qa-app\"이었습니다.\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어플리케이션 CRD를 계속 변경되는 가변 파일로 취급하는 것은 몇 가지 근본적인 문제와 나쁜 관행을 내포하고 있음을 의미합니다. 예를 들어, 대상 리비전 필드를 계속 다른 브랜치로 지정하는 것은 거의 항상 조직이 환경에 대해 브랜치를 사용하고 있는 것을 의미하는데 이는 강력히 권하지 않는 관례입니다.\n\n이것은 또한 Git 리포지토리 자체를 보는 것이 원하는 상태가 무엇인지 명확하게 나타내지 않는다는 것을 의미합니다. 대신, 각 응용 프로그램은 이해하고 전체 그림을 위해 다른 Git 리포지토리와 비교해야 하는 별도의 대상 리비전을 가질 수 있습니다.\n\nArgo CD 어플리케이션은 임의의 응용 프로그램을 실행하는 데 사용할 수 있는 재사용 가능한 상자가 아닙니다. GitOps의 핵심은 어플리케이션이 수행한 이벤트에 대한 명확한 이력을 가지는 것입니다. 하지만 어플리케이션 CRD를 완전히 다른 매니페스트를 가리키는 일반화된 작업 단위로 취급한다면 GitOps의 주요 이점 중 하나를 잃게 됩니다.\n\n대부분의 경우에는 CRD 대신에 백그라운드에 있는 쿠버네티스 매니페스트 자체를 변경해야 합니다. 예를 들어, 어플리케이션 이미지 CRD가 가리키는 쿠버네티스 배포 리소스 위에 정방향으로 새로운 앱 이미지를 가진 브랜치로 대상 리비전 필드를 변경하는 대신에 변경해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 안티패턴 3 — 다른/다중 레벨에서 템플릿 사용하는 것\n\n이전 안티패턴의 친척에 해당하는 것은 Application CRD (카테고리 2)에서 템플릿 기능을 적용하는 것입니다. Helm과 Kustomize는 이미 매우 강력한 도구이며 주요 Kubernetes 매니페스트에 대한 템플릿을 처리할 수 있습니다 (카테고리 1). 그리고 사용 사례가 해당되지 않더라도 사용자 정의 구성 플러그인을 사용하거나 좋아하는 외부 도구로 매니페스트를 사전 렌더링할 수 있습니다.\n\n문제는 사람들이 Application CRD를 템플릿화하려고 시도할 때 시작됩니다. 왜냐하면 그들은 이전 안티패턴에 의해 생성된 문제를 해결하려고 하기 때문입니다.\n\n이곳의 전형적인 예는 일팀이 Helm 차트를 생성하고 해당 Helm 차트가 Kubernetes 매니페스트의 Helm 차트를 가리키는 Application CRD를 포함할 때 발생합니다. 이제 동시에 두 가지 다른 수준에서 Helm 템플릿을 적용하려고 하게 됩니다. 그리고 Argo CD 풋프린트가 커질수록 새로 온 사람들이 매니페스트가 어떻게 구조화되어 있는지 이해하기가 매우 어렵습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nArgo CD에는 Application CRD에 대한 강력한 템플릿 메커니즘이 포함되어 있지 않다는 사실은 이 워크플로우를 권장하지 않음을 강력히 시사해야합니다. 또한 ApplicationSets(다음 항목 참조)이 소개되면서 템플릿을 적용해야 하는 적절한 위치는 개별 Application 파일이 아니라 ApplicationSet입니다.\n\n# 안티패턴 4 — Application Sets를 사용하지 않는 경우\n\n우리는 Application 매니페스트 (카테고리 2)에 대해 많이 이야기했으며 무엇을 하지 말아야 하는지에 대한 내용도 많았습니다. 이 기사의 주된 포인트는 여기에 있습니다. 이상적으로, Application CRD를 전혀 생성할 필요가 없어야합니다.🙂\n\n만약 비트 trivial한 Argo CD 설치가 있다면, 꼭 ApplicationSets가 어떻게 작동하는지 이해하고, 최소한 Git 생성기와 클러스터 생성기를 동시에 결합하는 방법을 공부해야합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어플리케이션 세트는 모든 애플리케이션 매니페스트(카테고리 2)의 생성을 담당할 수 있어요. 예를 들어, 20개의 애플리케이션과 5개의 클러스터가 있다면, Argo CD 애플리케이션을 위한 100가지 조합을 자동으로 생성해줄 수 있는 단일 어플리케이션 세트 파일을 만들 수 있어요.\n\nGitOps 인증에서 가져온 예제가 있어요.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: cluster-git\nspec:\n  generators:\n    # matrix 'parent' generator\n    - matrix:\n        generators:\n          # Git generator, 'child' #1\n          - git:\n              repoURL: https://github.com/codefresh-contrib/gitops-cert-level-2-examples.git\n              revision: HEAD\n              directories:\n                - path: application-sets/example-apps/*\n          # cluster generator, 'child' #2\n          - clusters: {}\n  template:\n    metadata:\n      name: '{path.basename}-{name}'\n    spec:\n      project: default\n      source:\n        repoURL: https://github.com/codefresh-contrib/gitops-cert-level-2-examples.git\n        targetRevision: HEAD\n        path: '{path}'\n      destination:\n        server: '{server}'\n        namespace: '{path.basename}'\n```\n\n이 생성기는 \"application-sets/example-apps\" 아래의 모든 앱을 Argo CD에 정의된 모든 클러스터에 배포하라고 말해요. 현재 연결된 클러스터 수나 Git 레포지토리에 있는 애플리케이션 수가 얼마나 많든 상관없어요. 어플리케이션 세트 생성기는 가능한 모든 조합을 자동으로 생성하며 새로운 클러스터나 새로운 애플리케이션을 추가할 때도 계속해서 재배포할 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nArgo CD Autopilot에 익숙한 분들은 이 패턴을 알아볼 수 있을 것입니다. 이는 모노레포 관점에서의 기본 설정입니다.\n\n애플리케이션 세트가 필요한 기본 템플릿을 지원한다는 점에 유의해주세요. 이를 통해 메인 Kubernetes 매니페스트에는 여전히 Helm/Kustomize를 유지하면서 Application CRD에 대해 어느 정도 유연성을 가질 수 있습니다. 또한 애플리케이션 세트에 대한 Go 템플릿 지원을 놓치지 않도록 주의하세요.\n\n모든 애플리케이션에 대해 하나의 ApplicationSet을 사용해야 하는 것은 아닙니다. 각 애플리케이션의 \"타입\"에 대해 여러 개의 세트를 사용할 수도 있습니다. 여기서 \"타입\"이 의미하는 바는 당신의 경우에 따라 다를 것입니다.\n\n# 최선의 방법 — 세 단계의 구조 사용하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 섹션에서는 권장하지 않는 몇 가지 방법과 피해야 할 몇 가지 함정을 살펴보았습니다. 이제 우리의 제안하는 해결책에 대해 이야기할 준비가 되었습니다.\n\n시작점은 아래 이미지에 표시된 대로 3단계 구조여야 합니다.\n\n![아이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_3.png)\n\n가장 낮은 수준에서는 응용 프로그램이 실행되는 방식을 정의하는 Kubernetes manifest(매니페스트)가 있습니다(매니페스트의 카테고리 1). 이러한 매니페스트는 Kustomize 또는 Helm 템플릿이며 완전히 자체 포함되어 있어 Argo CD가 없어도 어떤 클러스터에서든 별도로 배포될 수 있습니다. 이 파일들의 구조에 대해서는 프로모션 블로그 게시물에서 자세히 다루었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 섹션에서 설명한 대로 한 단계 위에는 응용 프로그램 세트가 있습니다. 이들은 주요 Kubernetes 매니페스트를 Argo CD 응용 프로그램(category 2 of manifests)으로 감싸줍니다. 대부분의 경우에는 개별 응용프로그램 CRD(Application CRDs)를 만들 필요 없이 ApplicationSets만 만들면 됩니다.\n\n마지막으로 선택적 구성 요소로, 모든 응용 프로그램 세트를 App-of-App에 그룹화하여 완전히 비어 있는 클러스터에 모든 응용 프로그램을 부트스트래핑할 수 있습니다. 만일 클러스터를 만드는 다른 방법이 있다면(예: terraform/pulumi/crossplane), 이 수준이 항상 필수적이지 않을 수 있습니다.\n\n그게 전부에요!\n\n이 패턴이 얼마나 간단한지에 주목하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 추상화 수준은 단 3개뿐이에요. 4개나 5개를 가진 회사들도 있지만, 그렇게 되면 메탈 모델이 훨씬 복잡해져요.\n- 각 수준은 완전히 독립적이에요. 쿠버네티스 Manifest를 별도로 설치할 수도 있고, 특정 애플리케이션 세트를 선택할 수도 있고, 모든 것을 최상위에서 선택할 수도 있어요. 하지만 선택은 당신의 몫이에요.\n- Helm과 Kustomize는 쿠버네티스 Manifest에서만 한 번 사용돼요. 이것 때문에 템플릿 시스템을 이해하기 정말 쉬워져요.\n\n실제 예시를 살펴봐요. 아래 링크에서 예시 리포지토리를 찾을 수 있어요. https://github.com/kostis-codefresh/many-appsets-demo\n\n![2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_4.png](https://example.com/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_4.png)\n\n여기서 우리는 쿠버네티스 Manifest를 \"apps\" 폴더에, 애플리케이션 세트를 \"appsets\" 폴더에 두기로 선택했어요. 이름이 중요한 건 아니에요. 무슨 일이 일어나고 있는지 명확하게 알면 무엇이든 선택할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"앱\" 디렉터리에는 표준 Kubernetes 매니페스트가 저장됩니다. 이 예제에서는 Kustomize를 사용하고 있습니다. 각 애플리케이션마다 해당 환경에 대한 오버레이만 있습니다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_5.png)\n\n이 구조에 대한 자세한 내용은 프로모션 블로그 게시물에 설명되어 있습니다.\n\n전체 구조를 살펴보면 각 환경이 \"apps/앱이름/envs/환경이름\" 디렉터리에 배치된다는 점이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앱세트 폴더에는 모든 애플리케이션 세트가 보관됩니다. 이 간단한 예제에서는 단순한 목록이지만 더 복잡한 예제에서는 조직을 더 잘하기 위해 여기에 폴더도 있을 수 있습니다.\n\n![ArgoCD Repository Structure](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_6.png)\n\n각 애플리케이션 세트는 단순히 Kubernetes 매니페스트에서 정의된 overlays를 언급합니다. 여기에 \"qa\" 앱세트의 예가 있습니다.\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: my-qa-appset\n  namespace: argocd\nspec:\n  goTemplate: true\n  goTemplateOptions: [\"missingkey=error\"]\n  generators:\n    - git:\n      repoURL: https://github.com/kostis-codefresh/many-appsets-demo.git\n      revision: HEAD\n      directories:\n        - path: apps/*/envs/qa\n  template:\n  metadata:\n    name: \"{index .path.segments 1}-{index .path.segments 3}\"\n  spec:\n    # 애플리케이션이 속한 프로젝트입니다.\n    project: default\n\n    # 애플리케이션 매니페스트의 소스\n    source:\n      repoURL: https://github.com/kostis-codefresh/many-appsets-demo.git\n      targetRevision: HEAD\n      path: \"{.path.path}\"\n\n    # 애플리케이션을 배포할 대상 클러스터 및 네임스페이스\n    destination:\n      server: https://kubernetes.default.svc\n      namespace: \"{index .path.segments 1}-{index .path.segments 3}\"\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 응용 프로그램 설정은 다음과 같이 말합니다:\n\n\"앱 폴더로 이동하십시오. 앱을 포함하는 모든 폴더를 검색하고 하위 폴더 envs/qa가 있는 경우 Argo CD 앱을 생성하십시오.\" 이 앱세트는 \"qa\" 오버레이가 있는 QA 클러스터 앱에만 배포됩니다. 이 오버레이가 없는 앱은 배포되지 않습니다. 앱 폴더를 살펴보면 모든 환경에 모든 앱이 배포되지 않음을 알 수 있습니다. 예를 들어 \"billing\"은 프로덕션에만 배포되고 \"fake-invoices\"는 QA에만 있습니다.\n\n또한 별도의 app-of-apps 매니페스트가 있으며 이것은 단순히 모든 앱 세트를 그룹화하는 데 도움이 됩니다. 이것은 엄격히 필수는 아니지만 빈 클러스터를 처음부터 모두 구성하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시에서 우리는 딱 한 개의 매니페스트만으로 12개의 애플리케이션을 배포했어요 (이는 애플리케이션 세트가 만드는 조합의 수입니다) 한 번에요.\n\n이 인위적인 데모 저장소는 모든 \"환경\"에 대해 단일 클러스터를 사용합니다. 프로덕션 설정에서는 모든 애플리케이션을 각각의 클러스터(qa/prod/staging)로 분리하기 위해 클러스터 생성기도 사용할 수 있어요.\n\n# Argo CD 애플리케이션의 두 번째 날 운영\n\n그렇다면 이 구조가 최적일까요? 이전 섹션의 데모 저장소를 사용하여 일반적인 시나리오를 살펴보고 얼마나 간단한지 확인해보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 장에서는 쿠버네티스 매니페스트(카테고리 1)와 Argo CD 매니페스트(카테고리 2)를 분리해야 한다는 주장을 했습니다. 이 결정의 주요 목표는 개발자들의 삶을 쉽게 만들고 공통 시나리오를 돕는 데 있습니다. 개발자를 위해 몇 가지 예시를 살펴보겠습니다:\n\n시나리오 1 — 개발자가 \"invoices\" 앱의 \"qa\" 구성을 검사하고 싶어 합니다.\n\n해결책 1:\n\n```js\ncd apps/invoices\nkustomize build envs/qa\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 문제는 한 줄의 명령어로 해결할 수 있으며 Argo CD 설치가 필요하지 않습니다.\n\n시나리오 2 — 개발자가 \"billing\" 앱의 미국과 유럽 간에 어떤 설정이 다른지 이해하려고 합니다.\n\n해결책 2:\n\n```js\ncd apps/billing\nkustomize build envs/prod-eu/\u003e /tmp/eu.yml\nkustomize build envs/prod-us/ \u003e /tmp/us.yml\nvimdiff /tmp/eu.yml /tmp/us.yml\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해결책은 3개의 명령어이며 Argo CD 설치가 필요하지 않습니다.\n\n시나리오 3 — 개발자가 \"orders\" 애플리케이션의 \"qa\" 환경설정을 로컬 클러스터에 설치하려고 합니다.\n\n해결책 3:\n\n```js\ncd apps/orders\nkubectl apply -k -f envs/qa\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다시 한 번, Argo CD 설치가 필요하지 않습니다.\n\n만약 다양한 유형의 manifest를 혼합한다면, 개발자들도 Argo CD를 다뤄야 할 수도 있습니다. Argo CD로 로컬 테스트를 진행하는 것은 Kubernetes 클러스터를 사용하는 것보다 훨씬 복잡합니다.\n\n관리자/운영자들에게도 매우 간단한 일입니다. 대부분의 작업은 클러스터와 어플리케이션의 수에 관계없이 단일 파일/폴더에서 단일 변경만으로 이루어집니다.\n\n예를 들어, 관리자가 \"payments\" 어플리케이션을 QA 환경에 배포하려고 한다고 가정해보겠습니다 (현재는 프로드 환경에서만 실행 중인 상태입니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ncd apps/payment/env\nmkdir qa\n\u003cqa를 위한 k8s manifest 생성\u003e\n\u003cArgo CD 동기화를 기다립니다\u003e\n```\n\n관리자가 원하는 모든 작업은 간단한 Git 작업에 해당합니다.\n\n- 기존 애플리케이션을 새 환경에 배포 - Kustomize overlay를 생성합니다. Argo CD 변경은 필요하지 않습니다.\n- 환경에서 애플리케이션 제거 - 해당 Kustomize overlay를 삭제합니다. Argo CD 변경은 필요하지 않습니다.\n- 새로운 애플리케이션 생성 - \"apps\" 폴더 아래 새 폴더에 K8s manifest를 커밋합니다. Argo CD 변경은 필요하지 않습니다.\n- \"integration\"이라는 새로운 환경 생성 - qa를 기반으로 \"integration\" 애플리케이션 세트를 새 파일로 복사/수정합니다. 다음 동기화에서 Argo CD는 \"integration\" 오버레이를 가진 모든 애플리케이션에 대해 새로운 조합을 생성합니다.\n- 새 클러스터 추가 - 클러스터를 Argo CD에 연결하면 해당 클러스터를 참조하는 모든 applicationset이 자동으로 애플리케이션을 해당 클러스터에 배포합니다.\n- 클러스터를 다른 환경으로 이동 - 해당하는 애플리케이션 세트에 새 라벨을 추가/편집하세요.\n\n이곳의 핵심은 명료한 manifest의 분리를 유지하고 있습니다. 개발자들은 Argo CD가 어떤 모델링을 하고 있는지 알 필요 없이 일반 쿠버네티스 리소스와 작업할 수 있으며, 관리자들은 applicationset과 폴더를 사용하여 쉽게 애플리케이션을 환경 간에 이동할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기존 환경에 대한 새로운 클러스터를 빠르게 설정하는 것은 정말 쉽습니다. 해당 클러스터 생성기에 추가하기만 하면 됩니다.\n\n# Monorepo, Monorepo, Monorepo\n\n이전 섹션에서 공유한 예제 저장소는 모든 애플리케이션이 어떤 식으로든 관련이 있다고 가정합니다. 아마도 그것들이 더 큰 애플리케이션의 일부이거나 동일한 팀에서 처리하는 것일지도 모릅니다.\n\n큰 조직에서는 여러 애플리케이션이 있고 완전히 다른 요구 사항과 제약 조건을 가진 여러 팀이 있습니다. 많은 팀이 여러 Git 저장소를 사용할지 또는 모든 애플리케이션에 대해 단일 저장소(monorepo)를 사용할지에 대한 선택에 고민합니다. 물론, 여기에서도 우리만의 권장 사항이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"우선 'Monorepo'가 무엇을 의미하는지를 우리가 정의하는 것이 매우 중요합니다. 왜냐하면 많은 관리자와 개발자와의 토론을 통해 백그라운드에 따라 단어의 의미가 다른 것을 명확하게 알 수 있기 때문입니다.\n\n기본적으로 우리는 사람들이 'monorepo'를 특정 Git 조직 구조로 부르는 3가지 다른 영역을 발견했습니다.\n\n개발자들은 주로 소스 코드를 구성할 때 'monorepo'를 언급합니다. 애플리케이션마다 하나의 저장소를 갖는 대신, 일부 팀은 조직 내 모든 애플리케이션의 소스 코드를 그룹화하는 단일 저장소를 선택합니다. 이 기술은 구글에서 지난 수십 년 동안 인기를 얻었으며 'monorepo'에 대한 대부분의 온라인 자료들은 주로 이 기술에 대해 이야기합니다.\n\n여기서 중요한 점은 이 정의가 소스 코드에만 해당한다는 것입니다. Argo CD는 소스 코드를 다루지 않으므로 이러한 방식에 대해 장단점을 언급하는 자료들은 실제로 Argo CD와 관련이 없습니다. 유감스럽게도, Argo CD를 채택할 때 이러한 유형의 기사를 참고하는 관리자들이 많이 보이며 이들은 Argo CD가 쿠버네티스 매니페스트를 관리하는 맥락에서 이러한 소스 코드 기술이 알맞지 않다는 것을 이해하지 못합니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"모노 리포\"에 대한 두 번째 정의는 소스 코드와 쿠버네티스 매니페스트 및 Argo CD 매니페스트를 동시에 포함하는 Git 저장소를 사람들이 \"모노 리포\"라고 설명하는 경우입니다. 이 기술은 Argo CD와 관련이 있지만, 여러 번 소스 코드와 매니페스트를 분리하는 것을 권장해왔습니다. 이 정의를 전체성을 위해 언급하는 것뿐이며, 몇몇 팀이 \"Argo CD 애플리케이션에 모노 리포를 사용한다\"고 말하는 경우가 있으며, 실제로는 Git 저장소가 매니페스트와 소스 코드를 모두 포함한다는 것을 의미하는 것입니다 (필수적으로 조직 전체에 대한 단일 Git 저장소를 사용하는 것은 아닙니다).\n\n\"모노 리포\"의 세 번째 정의이자 본 문서에서 중요하게 다루는 것은 조직이 모든 Argo CD 애플리케이션을 위한 단일 Git 저장소를 갖는 경우입니다. 이 저장소에는 소스 코드가 없지만, 중요한 점은 완전히 관련이 없는 경우에도 모든 배포된 애플리케이션을 포함한다는 것입니다. 그렇다면 이것이 좋은 방법인가요 아닌가요?\n\n# 최상의 방법 - 팀 당 Git 저장소 사용\n\n지난 섹션의 마지막 정의에 따라 정의된 모노 리포는 Argo CD 애플리케이션이 증가함에 따라 발생하는 여러 가지 확장성 및 성능 문제가 있습니다. Argo CD는 이미 모노 리포를 다루기 위한 여러 메커니즘을 가지고 있지만, 더 많은 팀이 Argo CD를 채택함에 따라 문제를 해결하지 말고, 미리 예방하는 것이 좋습니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단일 모노리포는 Argo CD 여정을 시작할 때 취할 수 있는 매우 논리적인 결정입니다. 단일 저장소를 갖는 것은 유지 보수와 관측성 측면에서 일을 쉽게 만듭니다. 그러나 장기적으로는 Argo CD가 커밋을 감지하는 방식 뿐만 아니라 Git 저장소가 다양한 워크플로와 충돌 및 재시도를 처리하는 방식에도 제약 사항이 몇 가지 있습니다.\n\n저희의 권장사항은 여러 개의 Git 저장소를 사용하는 것입니다. 이상적으로는 각 팀 또는 각 부서에 하나씩 있어야 합니다. 다시 말해 항상 스스로 질문해야 할 기본 질문은 Git 저장소에 포함된 응용 프로그램이 어떤 방식으로 관련되어 있는지입니다. 그것들이 마이크로 서비스이며 더 큰 응용 프로그램의 일부이거나 단일 팀에서 사용하는 해제된 구성 요소일 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_7.png)\n\n여러 개의 Git 저장소의 장점은 성능과 사용성 측면 모두에서 명백합니다. 특히 개발자들에게는, 다수의 Git 저장소가 선호됩니다. 그들은 자신의 팀에 속하지 않는 응용 프로그램들을 다루지 않고 자신들의 Kubernetes 매니페스트에 집중할 수 있기 때문입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 인프라 어플리케이션은 어떻게 할까요?\n\n우리는 Kubernetes manifest(분류 1) 및 Argo CD 리소스(분류 2)에 대해 많이 이야기했습니다. 인프라 어플리케이션(분류 3 및 4)은 어떨까요? 어디에 배치해야 할까요?\n\n인프라 매니페스트를 개발자 어플리케이션과 같은 방식으로 저장할 수 있습니다. 이전 섹션에서 언급한 3단계 구조를 사용하세요. 그러나 반드시 기억해야 할 점은 이 매니페스트를 개발자가 필요한 매니페스트와 혼합해서는 안 된다는 것입니다. 그리고 이들을 분리하는 가장 좋은 방법은 다른 Git 저장소를 갖는 것입니다.\n\n인프라 어플리케이션과 개발자 어플리케이션을 동일한 Git 리포지토리에 혼합하지 마세요. 다시 말하지만, 이것은 Argo CD 성능에 도움이 되는 것뿐만 아니라 개발자를 돕는 좋은 기술입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 이미지를 업데이트하고 인프라 애플리케이션을 처리하는 팀을 위한 또 다른 Git 저장소를 포함할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_8.png)\n\n이러한 방식으로 팀 내 개발자로서 나는 내가 관심 있는 것만 포함한 Git 저장소를 체크아웃할 수 있습니다. 해당 Argo CD 애플리케이션은 빠르며 이 Git 저장소에 영향을 미치는 CI 시스템 역시 빠릅니다. Git 충돌이 최소화되며 추가적인 보안 제약을 적용하려면 Git 공급 업체에서 제공하는 기존 Git 메커니즘을 사용할 수 있습니다.\n\n많은 애플리케이션과 팀이 있을 경우 어떤 공통 애플리케이션을 공유해야 할 필요성을 느낄 수 있습니다. 이를 처리하는 방법은 여러 가지가 있습니다. 빠른 방법 중 하나는 다른 팀의 매니페스트를 참조하는 Application Set를 사용하는 것입니다. 또 다른 방법은 모든 팀에서 필요로 하는 애플리케이션을 위해 \"공통\" Git 저장소를 사용하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앞으로의 글에서는 Git 서브모듈을 사용하여 두 가지 유형의 매니페스트에 대한 고급 시나리오와 공유 기술을 더 많이 다룰 예정입니다.\n\n# 요약\n\nArgo CD 애플리케이션을 구성하고 관리하기 위해 Application Sets를 활용하는 방법에 대한 포괄적인 안내서가 끝났습니다.\n\n다룬 내용은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 쿠버네티스와 Argo CD manifest의 다른 종류는 무엇인가요?\n- 이러한 manifest의 서로 다른 라이프사이클을 이해하는 것이 합리적한 이유는 무엇인가요?\n- Argo CD 애플리케이션 세트가 어떻게 작동하는지\n- 상호 연결된 애플리케이션 세트의 간단한 3단계 구조를 적용하는 방법은 무엇인가요?\n- 피해야 할 일반적인 함정은 무엇일까요?\n- 인프라 애플리케이션을 다루는 방법은 무엇인가요?\n- 서로 다른 팀을 위해 GitOps 리포지토리를 분할하는 방법은 무엇인가요?\n\nGitOps 리포지토리를 조직하는 방법에 대해 잘 이해하셨길 바라요. Argo CD에 오신 것을 환영합니다 🙂\n\n(Unsplash의 Breno Assis 사진 참고)\n","ogImage":{"url":"/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png"},"coverImage":"/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png","tag":["Tech"],"readingTime":23},{"title":"기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요","description":"","date":"2024-05-23 14:21","slug":"2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI","content":"\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e2024-05-23\u003c/td\u003e\n    \u003ctd\u003eUnlocking your Tech Wonderland by combining GitOps, Platforms, and AI\u003c/td\u003e\n    \u003ctd\u003e0.png\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n지난 몇 년 동안 많은 기술이 등장하고 사라지는 과정을 지켜봤고, 많은 사람들과 기업이 클라우드 네이티브 여정을 함께했습니다. 종종 듣는 말들 중에는 \"왜 쿠버네티스는 복잡한가요?\"와 \"문제 XYZ를 해결할 하나의 해결책만 없는 이유는 무엇인가요?\"라는 것들이 있었습니다. 동시에 플랫폼 엔지니어링과 AI가 현재 떠오르고 있는데, 저는 이 세 가지 주제가 서로 관련이 있다고 생각하기 때문에 함께 자세히 살펴보도록 하겠습니다.\n\n# 쿠버네티스의 등장 및 왜 그것이 복잡한가\n\n쿠버네티스는 응용 프로그램 인프라를 구축하기 위한 플랫폼 오케스트레이터로, 기반이 되는 인프라에 신경 쓰지 않고 기반을 만들도록 돕습니다. 우리가 조명을 비추면 (저는 예전 시스템 엔지니어로서) 익숙한 것들이 많이 보일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 시스템에서 잘 알려진 운영 절차들을 위한 추상화: Kubernetes에서 객체를 생성할 때, 우리는 과거에 우리가 한 것을 설명만 할 뿐입니다. 예를 들어, 인그레스 객체를 만들 때, 시스템에게 \"이 패턴과 일치하는 트래픽을 이 서비스로 전달하는 역방향 프록시를 구성해주세요\" 라고 말합니다. 파드 객체를 만들 때, 우리는 시스템에게 유닉스 네임스페이스를 생성하고 그 안에 프로세스를 캡슐화하며 환경 변수, 요청, 제한 등을 설정하도록 지시합니다.\n- 컨테이너: 컨테이너 개념은 완전히 새로운 것은 아니며 그 주변에 마법도 없습니다. 우리는 BSD jails로부터 이를 배웠고, OpenVZ나 LXC로 컨테이너를 만들었으며 마침내 Docker로 그 가능성을 확장했습니다.\n- 확장성과 탄력성: 시스템 엔지니어로서, 저는 종종 더 강력하고 확장 가능한 시스템을 만들기 위해 직면했습니다. 과거에 우리는 이를 위해 어떤 모험적인 구성을 만들었고, 많은 사람들은 클러스터 관리자, 부하 분산, 복제 및 하트비트 메커니즘과 맞닥뜨렸을 것입니다. 그들은 일을 잘했지만 구성하기 쉽지 않았고 종종 스스로 문제를 일으켰습니다. 익숙한 느낌이겠죠?\n\n제가 쿠버네티스 여정을 시작했을 때, 과거의 이러한 문제들을 보고 이를 해결해주는 것을 발견했습니다. 예를 들어, 간단한 구성 객체로 서비스를 여러 노드에 분산해서 로드 밸런싱할 수 있고, 수백 개의 노드로 자동으로 확장할 수 있습니다. 사실, 이러한 메커니즘들이 다소 무섭게 느껴질 수 있지만 결국에는 이를 배우고 시스템에 적용하는 것은 매우 간단합니다.\n\n아래 그림은 쿠버네티스로 가능한 자동화의 일부를 보여줍니다. 이 예시는 여러 컴포넌트에 작업 수행을 지시하는 매니페스트를 한 번에 만들 수 있다는 것을 보여줍니다. 이 경우에는 클러스터로의 인그레스 경로 생성, TLS 인증서 발급, 특정 호스트 이름을 위한 DNS 이름 생성 등이 될 것입니다. 물론, 이러한 지점에 도달하기 위해 약간의 구성 작업이 필요하지만 (전에 언급한 예시들보다는 훨씬 적습니다), 결국에는 복잡한 것들을 아주 간단한 방법으로 사용할 수 있도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n몇 년 전, Kelsey Hightower가 한 게시물에서 다음과 같이 썼어요:\n\n\"이것이란 암시적으로는 우리가 쿠버네티스를 애플리케이션을 배포하는 데 사용할 수 있다는 것을 의미하지만, 실제로 우리가 플랫폼을 구축하는 데 도움이 되는 플랫폼으로 고려하면 더 많은 것을 얻을 수 있습니다. 이로 인해 다음 질문에 이르게 됩니다:\"\n\n# 문제 XYZ를 해결할 수 있는 하나의 해결책만 있는 이유는 무엇인가요?\n\n쿠버네티스와 클라우드 네이티브 주변에 엄청난 생태계가 형성되었고, 많은 도구들이 사람들이 문제를 해결하는 데 도움을 줬어요. 우리가 그림 1에서 본 것처럼, 인그레스 오브젝트를 통해 들어오는 네트워크 트래픽을 구성하고, 인증서를 요청하거나 쿠버네티스 컨트롤러를 통해 DNS 항목을 구성하는 것은 오늘날 매우 간단해졌어요. 시간이 지남에 따라 많은 도구들이 이 생태계에 합류했고, 종종 사람들은 왜 같은 문제를 해결하는 것처럼 보이는 다양한 도구들이 존재하는지 묻곤 해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Tech Wonderland](/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_2.png)\n\nG. Hohpe’s book “Cloud Strategy”에서 회사에 가장 적합한 클라우드 공급업체를 찾는 데 관한 인용문을 발견했습니다.\n\n나는 클라우드 네이티브 랜드스케이프에 대해서도 동일하게 생각합니다(도표 2 참조). 다양한 옵션이 있지만 일부는 귀하의 요구 사항(및 전략)에 더 잘 맞을 수 있고 다른 일부는 그렇지 않을 수 있습니다. 예를 들어, 섬세하고 명료한 접근 방식을 따르는 도구를 선택할 수 있지만, 구성하거나 자체 의견을 구현할 수 있도록 지원해주는 도구도 있을 수 있습니다. 또한, 모든 것이 지원에 관한 문제일 수 있습니다. 가장 좋은 커뮤니티 주도형 오픈 소스 프로젝트가 제품마다 24/7 벤더 지원이 필요하다는 회사 정책을 준수해야 하는 경우에는 귀하의 요구 사항과 일치하지 않을 수 있습니다.\n\n우리는 이러한 것들을 끊임없이 진행할 수 있다고 상상할 수 있다고 생각하지만, 랜드스케이프의 각 도구는 더 많은 아이디어를 제공하며 더 많은 옵션을 제공하고(항상 그것들이 필요하지 않을 수 있지만) 귀하의 응용 프로그램에 대한 견고한 플랫폼을 구축하는 데 도움을 줍니다. 이를 통해 내가 좋아하는 이야기의 핵심인 플랫폼 엔지니어링으로 진행하고 싶습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 플랫폼 엔지니어링의 등장\n\n지난 두 섹션에서는 왜 사람들이 쿠버네티스를 복잡하게 생각하는지 (내 의견으로는 그렇지 않다고 생각합니다) 그리고 비슷한 문제를 해결하기 위해 수많은 도구가 있는 이유에 대해 설명했습니다. 이제 이러한 구성 요소들을 함께 조합해서 왜 쿠버네티스 위에 플랫폼을 구축하는 것이 절대적으로 의미가 있는지 알아보겠습니다.\n\n몇 년 전으로 돌아가서 회사들이 쿠버네티스를 채택하기 시작했던 시점에 대해 생각해 봅시다. 어떤 사람들은 새로운 멋진 기술(플랫폼 오케스트레이터)에 대해 들었고 이 기술을 기술 스택에 도입하고 싶어했습니다. 이 기간 동안 kubectl을 사용하여 응용 프로그램을 배포하고, 해당 플랫폼 구성 요소를 설치하고, Helm이라는 패키지 관리자에 대해 배워서 실천을 시작했습니다. 대기업의 경우, 이 일은 많은 기능 팀들에 의해 수행되었을 수 있고, 어느 순간에 회사는 이러한 것들을 함께 두어야 한다고 결정했습니다. 이 시점에서 다음과 같은 질문들에 직면하게 됩니다:\n\n- 어떻게 해야만 할 수 있을까요? 응용 프로그램 A의 리소스 소비가 응용 프로그램 B의 것과 간섭하지 않게 보장할까요?\n- 인그레스 컨트롤러로 ingress-nginx 또는 traefik을 사용해야 할까요? 그리고 누가 리소스를 마이그레이션해야 할까요?\n- 응용 프로그램 팀이 현재 사용 중인 5가지 메커니즘 중에서 선택해야 할 때 어떻게 응용 프로그램을 배포해야 할까요?\n- 개발자로서 클라우드 환경에서 데이터베이스를 사용하고 싶습니다. 어떤 것을 선택해야 할까요? 또 누가 그것을 관리해야 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n독립적인 응용 프로그램 팀마다 도구 스택에 약간의 노력을 기울였다고 상상해보세요. 대부분의 팀은 그것에 만족하고 있습니다. 그러나 이 방식으로 진행하면 확장이 잘 되지 않을 수 있으므로, 개발팀을 더 쉽게 만들고 제품 관리자를 더 만족시키기 위해 일부 사전 정의된 빌딩 블록을 사용하는 것이 합리적일 수 있습니다. 여러분의 플랫폼 엔지니어링 여정이 시작되었습니다.\n\nMartin Fowler와 Evan Bottcher는 이렇게 플랫폼을 정의합니다:\n\n다음과 같이 관련 부분으로 나눠봅시다:\n\n- 플랫폼은 기반이다: 개발자들의 운영 부담과 기초 작업을 줄이고, 플랫폼에서 제공되는 몇 가지 요소가 개발자들이 직접 만들어야 할 것이라는 점을 원합니다.\n- 셀프 서비스 API: 개발자들은 셀프 서비스 API를 통해 플랫폼을 사용할 수 있어야 합니다. 제 의견으로는 이것이 RESTful API일 수도 있지만, Kubernetes 객체로 구성돼 Git 리포지토리에 커밋되고 승인된 것이라면 안심할 수도 있습니다.\n- 도구: 플랫폼을 사용하는 데 필요한 모든 것\n- 서비스: 개발자들이 제품을 제공하는 데 도움이 되는 플랫폼의 일부인 것들, 예를 들어 시크릿 관리, 데이터베이스, 배달 도구, 메시지 큐잉 등\n- 지식과 지원: 플랫폼을 사용하는 사람들을 돕는 사항 및 서비스\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nIT에서 배운 한가지는 우리가 종종 무언가를 한 번 이상, 때로는 여러 차례 만들어낸다는 것입니다. 많은 경우, 우리는 이전에 만들어둔 인프라를 청사진으로 사용하고 많은 것을 반복합니다. 유감스럽게도, 이는 종종 해결책과 가끔은 유지보수가 잘 되지 않는 것들을 포함합니다. 플랫폼 접근 방식으로 수렴하는 것은 시간이 지남에 따라 개선될 수 있는 패턴 및 템플릿 카탈로그를 구축하는 데 도움이 될 수 있습니다 (각 IaC 템플릿을 버전화된 서비스로 생각해 보세요). 넓은 범위에서 적용될 때 해결책을 줄이는 데 관심 있는 많은 사람들이 있습니다. 플랫폼을 강아지집을 짓는 데 필요한 모든 도구 및 자재를 제공하는 도구 시장으로 생각해 보세요. 더 나아가, 프로젝트를 돕는 영업사원들과 문서가 있을 수 있습니다.\n\n![image](/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_3.png)\n\n플랫폼을 구축할 때 주요 주제 중 하나는 배포 전략입니다. 이는 시작부터 여러 가지 질문을 던지며 여러 가지 방법으로 플랫폼을 결정할 수 있습니다. 예를 들어, 어떤 서비스를 어떤 클라우드에서 제공할 것이며 어떻게 실행할 것인지 등의 질문에 대해 다룰 수 있습니다. 작은 예로, 모든 애플리케이션을 Kubernetes에서 제공하고 데이터베이스와 같은 종속 지원 서비스를 제공 업체의 PaaS 서비스로 사용하고 싶다는 결론에 도달할 수 있습니다. 이로 인해 다음과 같은 플랫폼 관련 솔루션이 나오게 됩니다:\n\n- 플랫폼 기능을 제공하는 방법\n- 애플리케이션 및 인프라 구성요소를 제공하는 방법\n- 솔루션 카탈로그의 첫 부분\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nIaC 솔루션과 소프트웨어를 전달하는 GitOps Controller에 자주 의존하는 편입니다. 이러한 솔루션을 기반으로 몇 가지 더 궁금증이 생길 것입니다. 예를 들어, 비밀 정보는 어떻게 전달할까요? DNS 항목은 어떻게 다룰까요? 버전 관리는 어떻게 진행할까요? 이러한 질문 목록은 끝없이 계속될 수 있으며 어떤 질문은 먼저 나오고 다른 것은 나준히 알려질 것입니다. 배포 전략은 현재 사용 가능한 애플리케이션과 해당 현재 메커니즘에 따라 당연히 달라질 것입니다. 그러나 애플리케이션과 배포 전략을 통해 지금까지 생각하지 못했을지도 모를 여백과 문제점을 찾게 될 것입니다. 하나의 중요한 포인트는 전달할 아티팩트의 유형과 표준화할 수 있는 방법입니다. 예를 들어, 컨테이너를 전달하고 배포 설명에 대한 내부 표준(예: manifests 및 helm charts)이 있는 경우 모든 것이 더 쉬워집니다.\n\n이 모든 과정을 거치면서 플랫폼은 발전하고 해당 구조를 정의하게 될 것입니다. Figure 4는 프로덕션 시스템에서 고려해야 할 내용의 예시를 보여줍니다. 개발자 포털을 통해 템플릿 활용 및 서비스에 대한 통찰력을 얻을 수 있으며 정보를 저장하는 리포지토리, 또한 서비스 인터페이스 및 개발자가 서비스에서 사용할 수 있는 서비스도 포함됩니다.\n\n이러한 플랫폼은 개발자에게 엄청난 가치를 제공할 수 있지만, 이들을 강요하여 그들이 만족하지 않는 프로세스에 밀어 넣어서는 안된다는 점을 명심해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 개발자를 배려하며 과거를 생각해보기\n\n플랫폼을 제공할 때, 주요 이해관계자는 그것을 사용하는 개발자들입니다. 따라서, 그들을 염두에 두고 그들의 의견을 물어보고 플랫폼 사용에 대해 교육해야 합니다. 또한, 사람들이 자신의 도구를 선택하고 이러한 방식으로 것들을 구축한 이유가 있습니다. 이로 인해 플랫폼 구축은 일상적인 해결책이 아니지만 여정에서 도움이 되는 패턴이 있습니다.\n\n- 플랫폼의 일부분으로 사람들을 만들기: 질문에 대한 답변을 얻고 최선을 다해 문제를 해결하고 싶어하는 사람들이 있을 수 있습니다. 사람들은 기술에 대해 이야기하는 것을 좋아하며, 서로 이야기를 나누면 더 나은 해결책을 찾을 수 있습니다.\n- 오픈/내부 소싱: 공유할 수 있는 아티팩트(예: 인프라 템플릿 및 구성)를 만들 때, 이를 회사 내에서 전역적으로 공유하고 다른 팀이 재사용할 수 있도록 하는 것이 유용할 수 있습니다. 이 경우, 모범 사례와 패턴이 수립되어 사람들이 전진하는 데 도움이 될 것입니다. 또한, 사람들은 풀/머지 요청을 제출하고 플랫폼에 기여할 수 있습니다.\n- 커뮤니티 구축: 내부 모임을 개최하고, 플랫폼을 기반으로 한 시스템을 소개하고 성공을 전달하세요. 이렇게 하면 플랫폼이 부각되고 해당 주제에 더 많은 사람들이 끌리게 될 것입니다.\n\n또한, 모든 회사는 각자의 역사, 내부 가치 및 프로세스를 가지고 있습니다. 플랫폼 구축을 시작할 때, 이를 염두에 두고 사람들을 어떻게 차지할지 알아보려고 노력해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AI에 대해 다루는 제목을 보면서 함께 멋진 것들에 대해 이야기해주셨네요!\n\n그동안 AI와 무슨 상관이 있는지, 그리고 여러분의 여정에서 어떻게 도움을 줄 수 있는지 궁금해하셨을 수도 있습니다. 이 기사의 처음에는 Kubernetes의 복잡성과 왜 일부 사람들이 어려워하는지에 대해 이야기했습니다. Kubernetes와 함께 작업하는 사람들을 돕기 위해 많은 노력이 기울여지고 있지만, 경험 많은 엔지니어조차도 문제를 해결하는 것에 어려움을 겪을 수 있습니다.\n\nKubernetes와 AI 영역에서의 최초 프로젝트 중 하나인 K8sGPT는 Kubernetes 환경의 문제 해결을 돕기 위해 시작되었습니다. 따라서 Kubernetes 클러스터에서 간단한 명령(k8sgpt analyze — explain)을 실행하면, 다양한 AI 제공 업체를 기반으로 한 잘못된 구성과 그 해결책을 찾을 수 있습니다. 또한 Developer Portals인 Backstage에서도 사용될 수 있을 것입니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_5.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 것들은 다양한 다른 도구들과 결합할 수 있습니다. 예를 들어, GitOps 도구를 사용하여 애플리케이션을 전달하고 분석을 실행한 후, 애플리케이션이 제대로 작동하는지 확인할 수 있습니다. 이와 같은 문제를 감지하고 자동으로 해결하기 위한 노력이 이미 있습니다. 내 최근 데모 중 하나에서는 GitOps 컨트롤러를 사용하여 애플리케이션을 배포하고, Keptn을 사용하여 기능을 유효성 검사하고, K8sGPT를 내장하여 배포에서 문제를 찾아내었습니다.\n\n# 요약\n\n본문은 플랫폼이 클라우드 네이티브 여정에서 어떻게 도와줄 수 있는지와 어떤 문제를 해결하는지에 대한 개요를 제공했어요. 시작할 때는 Kubernetes의 복잡성에 대한 대략적인 개요가 있었습니다. 그 후에는 대규모 클라우드 네이티브 생태계에 대해 이야기했고, 모든 것은 플랫폼으로 이어지도록 조합되었습니다. 이 섹션에서 배송 전략에 대해 작업하는 것이 문제를 해결하고(새로운 문제를 찾아내는 것이 가능) 도움이 된다는 것을 배웠습니다. 또한 플랫폼 구축과 표준화는 대부분 사람들에 관한 것이라는 것도 알게 되었습니다. 마지막으로 플랫폼에서의 AI와 Kubernetes의 복잡성을 줄일 수 있는 방법에 대해 알아보았습니다.\n\n# 참고문헌\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Hohpe, G. (2020). Cloud Strategy: A Decision-Based Approach to Successful Cloud Migration.\n- CNCF Platforms Working Group. (2023). CNCF Platforms Whitepaper. [https://tag-app-delivery.cncf.io/whitepapers/platforms/](https://tag-app-delivery.cncf.io/whitepapers/platforms/)\n- K8sGPT, [https://k8sgpt.ai](https://k8sgpt.ai)\n- Backstage K8sGPT Plugin, [https://github.com/suxess-it/backstage-plugin-k8sgpt/blob/main/README.md](https://github.com/suxess-it/backstage-plugin-k8sgpt/blob/main/README.md)\n","ogImage":{"url":"/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_0.png"},"coverImage":"/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_0.png","tag":["Tech"],"readingTime":9}],"page":"49","totalPageCount":98,"totalPageGroupCount":5,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"49"},"buildId":"o1YmnmSuZvAX2O4TI9r41","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>