<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/36" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/36" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_buildManifest.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="컨테이너화된 모델과 작업 보안하기" href="/post/2024-06-19-SecuringyourContainerisedModelsandWorkloads"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="컨테이너화된 모델과 작업 보안하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="컨테이너화된 모델과 작업 보안하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">컨테이너화된 모델과 작업 보안하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마이크로서비스 이해 소프트웨어 아키텍처에 대한 현대적인 접근법" href="/post/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마이크로서비스 이해 소프트웨어 아키텍처에 대한 현대적인 접근법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마이크로서비스 이해 소프트웨어 아키텍처에 대한 현대적인 접근법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">마이크로서비스 이해 소프트웨어 아키텍처에 대한 현대적인 접근법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">28<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="스파크-비욘드 기본 델타 테이블에서 동시 쓰기와 행 수준 동시성" href="/post/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="스파크-비욘드 기본 델타 테이블에서 동시 쓰기와 행 수준 동시성" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="스파크-비욘드 기본 델타 테이블에서 동시 쓰기와 행 수준 동시성" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">스파크-비욘드 기본 델타 테이블에서 동시 쓰기와 행 수준 동시성</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="아저라 데이터브릭스 SQL 웨어하우스 인스턴스의 실제 비용을 계산하는 방법" href="/post/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="아저라 데이터브릭스 SQL 웨어하우스 인스턴스의 실제 비용을 계산하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="아저라 데이터브릭스 SQL 웨어하우스 인스턴스의 실제 비용을 계산하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">아저라 데이터브릭스 SQL 웨어하우스 인스턴스의 실제 비용을 계산하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="눈꽃 폴라리스와 데이타브릭스 유니티 카탈로그 오픈 및 상호 운용 가능한 메타스토어 시대" href="/post/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="눈꽃 폴라리스와 데이타브릭스 유니티 카탈로그 오픈 및 상호 운용 가능한 메타스토어 시대" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="눈꽃 폴라리스와 데이타브릭스 유니티 카탈로그 오픈 및 상호 운용 가능한 메타스토어 시대" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">눈꽃 폴라리스와 데이타브릭스 유니티 카탈로그 오픈 및 상호 운용 가능한 메타스토어 시대</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마이크로소프트 패브릭과 데이타브릭스 유니티 카탈로그 - 통합 시나리오 해석하기" href="/post/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마이크로소프트 패브릭과 데이타브릭스 유니티 카탈로그 - 통합 시나리오 해석하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마이크로소프트 패브릭과 데이타브릭스 유니티 카탈로그 - 통합 시나리오 해석하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">마이크로소프트 패브릭과 데이타브릭스 유니티 카탈로그 - 통합 시나리오 해석하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터브릭스, 데브옵스 및 파이테스트" href="/post/2024-06-19-DatabricksDevOpsandpytest"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터브릭스, 데브옵스 및 파이테스트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터브릭스, 데브옵스 및 파이테스트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터브릭스, 데브옵스 및 파이테스트</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="단위 테스트 및 코드 모듈화를 위한 Databricks" href="/post/2024-06-19-UnitTestingandCodeModularizationinDatabricks"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="단위 테스트 및 코드 모듈화를 위한 Databricks" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="단위 테스트 및 코드 모듈화를 위한 Databricks" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">단위 테스트 및 코드 모듈화를 위한 Databricks</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터  AI 서밋 by Databricks 2024의 주요 통찰 결과" href="/post/2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터  AI 서밋 by Databricks 2024의 주요 통찰 결과" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터  AI 서밋 by Databricks 2024의 주요 통찰 결과" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터  AI 서밋 by Databricks 2024의 주요 통찰 결과</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Azure Databricks와 Microsoft Fabric 통합하기" href="/post/2024-06-19-IntegratingAzureDatabricksandMicrosoftFabric"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Azure Databricks와 Microsoft Fabric 통합하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-IntegratingAzureDatabricksandMicrosoftFabric_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Azure Databricks와 Microsoft Fabric 통합하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Azure Databricks와 Microsoft Fabric 통합하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link posts_-active__YVJEi" href="/posts/36">36</a><a class="link" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"컨테이너화된 모델과 작업 보안하기","description":"","date":"2024-06-19 12:37","slug":"2024-06-19-SecuringyourContainerisedModelsandWorkloads","content":"\n컨테이너화는 이제 많은 어플리케이션을 배포하는 주요 수단이 되었으며, Docker가 이를 주도하며 보급되고 있습니다. 그 인기에 따라 공격 위험이 증가하고 있습니다. 따라서 Docker 어플리케이션을 안전하게 지킬 필요가 있습니다. 이를 위한 가장 기본적인 방법은 컨테이너 내 사용자를 루트 사용자가 아닌 일반 사용자로 설정하는 것입니다.\n\n```js\n컨텐츠\n========\n\n왜 루트 사용자가 아닌 사용자를 사용해야 하는가?\n\n기본 일반 사용자로서 할 수 있는 일과 할 수 없는 일\n\n네 가지 시나리오\n  1) 호스트에서 모델 제공 (읽기 전용)\n  2) 데이터 처리 파이프라인 실행 (컨테이너 내에서 쓰기)\n  3) 라이브러리가 자동으로 파일 작성 (컨테이너 내에서 쓰기)\n  4) 훈련된 모델 저장 (호스트에 쓰기)\n\n요약\n```\n\n# 왜 루트 사용자가 아닌 사용자를 사용해야 하는가?\n\n혹은 왜 루트 사용자를 사용하지 말아야 하는가? 아래의 가짜 아키텍처 예제를 살펴봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Containerized Security](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png)\n\n보안은 종종 다층 접근법으로 간주됩니다. 공격자가 컨테이너에 들어갈 경우 사용자로서 가지는 권한이 첫 번째 방어층이 됩니다. 만약 컨테이너 사용자가 루트 액세스를 할당받는다면, 공격자는 컨테이너 내 모든 것을 자유롭게 제어할 수 있습니다. 이러한 넓은 액세스로 인해 잠재적인 취약점을 이용하여 호스트로 탈출하고 모든 연결된 시스템에 완전한 액세스를 획들할 수도 있습니다. 그 결과는 심각하며 다음과 같습니다:\n\n- 저장된 비밀 정보를 회수\n- 트래픽을 가로채거나 방해\n- 암호화 채굴과 같은 악성 서비스 실행\n- 데이터베이스와 같은 연결된 민감한 서비스에 액세스 획득\n\n![Containerized Security](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n와우, 그건 정말 무섭게 들리네요! 그러나 해결 방법은 간단합니다. 컨테이너를 루트 사용자가 아닌 다른 사용자로 변경하세요!\n\n우리가 나머지 기사를 읽기 전에, 리눅스 권한과 액세스 권한에 대한 좋은 이해가 없다면, 제 이전 기사를 꼭 확인해 보세요 [2].\n\n# 기본 비루트 사용자로서 할 수 있고 할 수 없는 것\n\n기본 비루트 사용자로 간단한 도커 어플리케이션을 만들어 보겠습니다. 아래의 도커 파일을 사용하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# create a dummy py file\nRUN echo \"print('I can run an existing py file')\" \u003e example.py\n\n# create \u0026 switch to non-root user\nRUN adduser --no-create-home nonroot\nUSER nonroot\n```\n\nMake sure to build the image and create a container using the following commands:\n\n```js\ndocker build -t test .\ndocker run -it test bash\n```\n\nOnce you are inside the container, feel free to try out various commands. Keep in mind that certain actions like writing to restricted directories or installing software may not be permitted due to restricted permissions.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_2.png\" /\u003e\n\n반대로, 우리는 모든 종류의 읽기 권한을 실행할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_3.png\" /\u003e\n\n파이썬이 설치되어 있기 때문에 약간 독특합니다. ls -l $(which python)을 실행하면 파이썬 인터프리터에 완전한 권한이 있음을 볼 수 있습니다. 따라서 Dockerfile에서 처음에 만든 example.py 파일과 같은 기존의 파이썬 파일을 실행할 수 있습니다. 심지어 파이썬 콘솔에 들어가 간단한 명령을 실행할 수도 있습니다. 그러나 비 루트 사용자로 전환하면 다른 시스템 쓰기 권한이 제거된 것을 알 수 있습니다. 그렇기 때문에 스크립트를 생성하거나 수정하거나 파이썬을 사용해 쓰기 명령을 실행할 수 없음을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_4.png)\n\n시스템 전반적인 제한은 보안에 좋지만, 특정 파일 및 디렉터리에 대한 쓰기 권한이 필요한 경우가 많이 발생하며, 그러한 허용 사항에 대응해야 합니다.\n\n다음 섹션에서는 기계 학습 운영 수명 주기의 네 가지 시나리오 예제를 제공합니다. 이러한 예제를 통해 대부분의 다른 경우에 대한 구현 방법을 이해할 수 있을 것입니다.\n\n# 네 가지 시나리오\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 1) 호스트에서 모델 제공하기 — 읽기 전용\n\n모델을 제공할 때, 추론 및 서빙 스크립트를 활용하여 모델을 로드하고 API를 통해 노출시킵니다 (예: Flask, FastAPI) 입력을 받도록 합니다. 때로는 모델이 호스트 머신에서 로드되어 이미지와 분리되어 이미지 크기가 최적으로 작고, 이미지를 다시 로드할 경우 반복적인 모델 다운로드 없이 최적으로 빠르게 할 수 있도록 합니다. 그런 다음 모델은 바인드-마운트 볼륨을 통해 컨테이너로 전달되어 로드되고 제공됩니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_5.png\" /\u003e\n\n이것은 비루한 사용자를 구현하는 가장 번거롭지 않은 방법일 것입니다. 기본적으로 모든 사용자에게 부여되는 읽기 권한만 필요하기 때문입니다. 아래는 그 작업이 어떻게 이루어지는지를 보여주는 샘플 Dockerfile입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Dockerfile\n\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip3 install --no-cache-dir --upgrade pip~=23.2.1 \\\n \u0026\u0026 pip3 install --no-cache-dir -r requirements.txt\n\nCOPY ./project/ /app\n\n# add non-root user ---------------------\n\nRUN adduser --no-create-home nonroot\n\n# switch from root to non-root user -----\n\nUSER nonroot\n\nCMD [\"python\", \"inference.py\"]\n\n이 Dockerfile은 먼저 nonroot라는 새로운 시스템 사용자를 만드는 두 가지 간단한 명령어를 가지고 있습니다. 두 번째로, 마지막 CMD 라인 바로 전에 루트에서 nonroot 사용자로 전환됩니다. 기본 non-root 사용자의 경우 쓰기 및 실행 권한이 없기 때문에, 이전 단계에서 필요한 파일을 설치하거나 복사하거나 조작할 수 없습니다.\n\n이제 Docker에서 non-root 사용자를 할당하는 방법을 알았으니, 다음 단계로 넘어가 봅시다.\n\n## 2) 데이터 처리 파이프라인 실행하기 — 컨테이너 내에서 작성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가끔은 작업을 실행하기 위해 일시적인 파일을 저장하고 싶을 때가 있습니다. 예를 들어, 데이터 전처리 작업을 한다고 가정해봅시다. 파일을 추가하고 삭제하는 작업으로 이루어져 있죠. 파일이 영구적이지 않기 때문에 이런 작업은 컨테이너 내에서 수행할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_6.png)\n\n그러나 루트가 아닌 사용자를 사용한다면 쓰기 권한이 필요할 것입니다. 이를 위해 chown(소유자 변경) 명령을 사용하여 쓰기 액세스가 필요한 특정 폴더에 소유권을 할당해야 합니다. 이 작업을 완료하면 사용자를 루트가 아닌 사용자로 전환할 수 있습니다.\n\n```js\n# Dockerfile\n\n# ....\n\n# 루트가 아닌 사용자 추가 및 처리 폴더에 소유권 부여\nRUN adduser --no-create-home nonroot \u0026\u0026 \\\n    mkdir processing \u0026\u0026 \\\n    chown nonroot processing\n\n# 루트에서 루트가 아닌 사용자로 전환\nUSER nonroot\n\nCMD [\"python\", \"preprocess.py\"]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3) 라이브러리가 파일을 자동으로 작성하는 경우 - 컨테이너 내에서 작성\n\n이전 예시에서는 우리가 직접 만든 파일을 작성하는 방법을 보여줬어요. 그러나 사용하는 라이브러리가 파일과 디렉토리를 자동으로 만드는 경우가 흔합니다. 컨테이너를 실행해 보고 쓰기 권한이 거부되는 것을 알 수 있을 때 그것들이 만들어진 것임을 알게 될 거예요.\n\n저는 두 가지 예시를 보여드릴 거에요. 하나는 여러 프로세스를 관리하는 데 사용되는 supervisor에서 가져왔고, 다른 하나는 huggingface에서 모델을 다운로드할 때 사용하는 huggingface-hub에서 가져왔어요. 이러한 권한 오류들은 우리가 루트가 아닌 사용자로 전환할 때 볼 수 있을 거에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Securing your Containerised Models and Workloads](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_8.png)\n\n![Securing your Containerised Models and Workloads](/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_9.png)\n\n두 개의 슈퍼바이저 파일에 대해서 먼저 빈 파일로 생성하고 소유권 권한을 할당할 수 있습니다. Huggingface-hub 다운로드 문제에 대해 이미 오류 로그에서 TRANSFORMERS_CACHE 변수를 통해 다운로드 디렉토리를 변경할 수 있다는 힌트가 있었습니다. 따라서 먼저 디렉토리 변수를 할당하고, 디렉토리를 생성한 후 소유권을 할당할 수 있습니다.\n\n```js\n# Dockerfile\n\n# ....\n\n# non-root 사용자 추가 ................\n# huggingface 다운로드 디렉토리 변경\nENV TRANSFORMERS_CACHE=/app/model\n\nRUN adduser --no-create-home nonroot \u0026\u0026 \\\n    # 슈퍼바이저 파일 및 huggingfacehub 디렉토리 생성\n    touch /app/supervisord.log /app/supervisord.pid \u0026\u0026 \\\n    mkdir $TRANSFORMERS_CACHE \u0026\u0026 \\\n    # 슈퍼바이저 및 huggingfacehub 쓰기 권한 부여\n    chown nonroot /app/supervisord.log \u0026\u0026 \\\n    chown nonroot /app/supervisord.pid \u0026\u0026 \\\n    chown nonroot $TRANSFORMERS_CACHE\nUSER nonroot\n\nCMD [\"supervisord\", \"-c\", \"conf/supervisord.conf\"]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n물론 여기에 제시된 것과 약간 다른 다른 예제가 있을 수 있습니다만, 쓰기 권한을 최소화하는 개념은 동일할 것입니다.\n\n## 4) 훈련된 모델 저장하기 — 호스트에 쓰기\n\n모델을 훈련하는 데 컨테이너를 사용하고 그 모델을 호스트에 쓰기를 원한다고 가정해 봅시다. 예를 들어, 모델을 준비하여 다른 작업에서 평가하거나 배포하기 위해 호스트에 쓰려고 하는 경우입니다. 이 경우에는 모델 파일을 쓰기 위해 컨테이너 디렉토리를 호스트 디렉토리에 연결하여 모델 파일을 기록해야 합니다. 이를 바인드 마운트라고도 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저, 우리는 nonroot를 위한 그룹과 사용자를 만들어야 합니다. 각각에 대해 고유한 ID를 지정하는데, 이 경우에 우리는 1001을 사용합니다 (1000 이상의 아무 숫자나 상관없습니다). 그런 다음, 모델을 저장할 모델 디렉토리를 생성합니다.\n\nScenario 2와 비교하여 여기서의 차이점은 모델 디렉토리에 대해 쓰기 권한을 설정하는 데 chown이 필요하지 않다는 것입니다. 왜냐하면?\n\n```js\n# Dockerfile\n\n# ....\n# add non-root group/user \u0026 create model folder\nENV UID=1001\nRUN addgroup --gid $UID nonroot \u0026\u0026 \\\n    adduser --uid $UID --gid $UID --no-create-home nonroot \u0026\u0026 \\\n    mkdir model\n\n# switch from root to non-root user\nUSER nonroot\n\nCMD [\"python\", \"train.py\"]\n```\n\n이는 bind-mounted 디렉토리의 권한이 호스트 디렉토리에서 결정되기 때문입니다. 따라서 우리는 호스트에서 다시 동일한 사용자를 만들어야 하며, 사용자 ID가 동일한지 확인해야 합니다. 그런 다음에 호스트에 모델 디렉토리를 만들고 nonroot 사용자에게 소유자 권한을 부여합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 호스트 터미널에서\n\n# 동일한 사용자 및 그룹 추가\naddgroup --gid 1001\nadduser --uid 1001 --gid 1001 --no-create-home nonroot\n# 바인드 마운트할 모델 디렉토리 만들고 nonroot를 소유자로 설정\nmkdir /home/model\nchown nonroot /home/model\n```\n\n바인드 마운트는 보다 유연성을 제공하기 위해 일반적으로 docker-compose.yml 파일이나 docker run 명령어에서 지정됩니다. 아래는 전자의 예시입니다.\n\n```js\nversion: \"3.5\"\n\nservices:\n    modeltraining:\n        container_name: modeltraining\n        build:\n            dockerfile: Dockerfile\n        volumes:\n            - type: bind\n              source: /home/model # 호스트 디렉토리\n              target: /app/model  # 컨테이너 디렉토리\n```\n\n그리고 후자에 대한 예시는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndocker run -d --name modeltraining -v /home/model:/app/model \u003cimage_name\u003e\n```\n\n아무거나 실행하시면, 비루트 사용자로 스크립트를 실행할 수 있음을 확인하실 수 있을 거예요.\n\n# 요약\n\n우리는 비루트 사용자를 할당하고도 컨테이너가 원하는 작업을 수행할 수 있는 방법을 살펴보았어요. 이는 특정 쓰기 권한이 필요할 때 주로 관련이 있어요. 그저 두 가지 기본 개념만 알면 돼요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 컨테이너에서의 쓰기 권한을 위해서는 Dockerfile에서 chown을 사용하세요.\n- 바인드 마운트를 위한 쓰기 권한은 호스트에서 동일한 비루트 사용자를 생성하고 호스트 디렉토리에서 chown을 사용하세요.\n\n루트 사용자로 일부 테스트를 실행하기 위해 도커 컨테이너로 들어가야할 때 다음 명령어를 사용할 수 있어요.\n\n```js\ndocker exec -it -u 0 \u003c컨테이너_아이디/이름\u003e bash\n```\n\n# 참고자료\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- [1] Wong et al. (2023) 컨테이너 보안에 관한: 위협 모델링, 공격 분석 및 완화 전략. 컴퓨터 및 보안, 제 128권.\n- [2] Linux 권한 및 접근 권한에 관한 이전 게시물: https://medium.com/@teosiyang/securing-linux-servers-with-two-commands-de5b565dc104\n","ogImage":{"url":"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png"},"coverImage":"/assets/img/2024-06-19-SecuringyourContainerisedModelsandWorkloads_0.png","tag":["Tech"],"readingTime":13},{"title":"마이크로서비스 이해 소프트웨어 아키텍처에 대한 현대적인 접근법","description":"","date":"2024-06-19 12:34","slug":"2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture","content":"\n마이크로서비스\n\n마이크로서비스와 보안\n\n사가 패턴: 코레오그래피와 오케스트레이션\n\nAXON을 활용한 사가\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSage와 Eventuate를 이용한 트랜잭션 외부함으로 패턴 구현하기\n\n마이크로서비스에서의 전파\n\n# 소개\n\n이 블로그에서는 소프트웨어 개발의 풍경을 변화시킨 혁신적인 접근 방식인 마이크로서비스 아키텍처의 매력적인 세계에 대해 탐구해 보겠습니다. Netflix와 같은 선두 기업들이 전통적인 방법론과 관련된 공통적인 도전 과제를 극복하기 위해 이 아키텍처를 채택했습니다. 마이크로서비스의 흥미진진한 영역으로 뛰어들기 전에, 먼저 거대한(monolithic) 아키텍처 및 그 한계를 이해하는 것이 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 코드 링크입니다: [https://github.com/Blogs4Devs/Microservices](https://github.com/Blogs4Devs/Microservices).\n\n# Monolithic architecture\n\n전통적인 모놀리식 아키텍처에서는 전체 애플리케이션이 하나의 프로세스로 실행되며, 모든 애플리케이션 구성 요소가 서로 연결되어 의존하며 하나의 단일 단위로 묶여 있습니다. 이는 사용자 인터페이스, 비즈니스 로직 및 데이터 액세스 레이어가 모두 단일 프로그램의 일부라는 것을 의미합니다.\n\n![img](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 모놀리식 애플리케이션의 단점:\n\n- 확장성 문제:\n\n모놀리식 애플리케이션 내의 특정 서비스가 많은 호출을 받아 확장해야 하는 경우 전체 애플리케이션을 확장해야 합니다. 이는 전체 애플리케이션의 추가 인스턴스를 실행해야 하는 것을 의미하며, 이는 리소스를 많이 소비하고 비효율적입니다. 과부하된 구성 요소만 확장하는 대신 전체 시스템을 확장해야 하므로 불필요하게 리소스를 사용하게 됩니다.\n\n- 배포 속도가 느림:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n대규모 응용 프로그램에서는 작은 변경사항도 전체 응용 프로그램을 다시 컴파일하고 배포해야 합니다. 이로 인해 배포 주기가 크게 느려지며 전체 시스템을 테스트하고 통째로 배포해야 하므로 지속적인 배포가 어려워질 수 있습니다.\n\n- 기술 채택에 대한 장벽:\n\n대규모 응용 프로그램은 일반적으로 한 가지 언어 또는 프레임워크로 작성되어 있어 전체 개발 팀이 해당 특정 기술을 알고 있어야 합니다. 이는 특정 작업에 더 적합한 새로운 기술이나 언어를 채택하는 능력을 제한할 수 있습니다.\n\n- 코드 변경 및 테스트가 어려운 문제:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모놀리식 애플리케이션에서는 전체 시스템의 모든 로직이 얽혀있어 코드베이스가 복잡하고 관리하기 어렵습니다. 애플리케이션의 한 부분에 변경이 있을 때 다른 부분에 예상치 못한 영향을 미치는 경우가 많아 테스트와 유지보수가 어려워집니다. 이 복잡성은 버그를 분리하고 수정하기도 어렵게 만들어서 개발 주기를 늘릴 수 있습니다.\n\n이러한 단점을 이해하면 많은 기관이 더 큰 유연성, 확장성 및 유지보수 편의성을 제공하는 마이크로서비스 아키텍처로 전환하려는 이유가 분명해집니다.\n\n# 마이크로서비스 아키텍처\n\n마이크로서비스 아키텍처는 애플리케이션을 작은, 느슨하게 결합된 서비스로 분해하여 각각이 특정 비즈니스 기능을 담당하게 합니다. 이러한 서비스들은 독립적으로 개발, 배포 및 확장할 수 있어 모놀리식 아키텍처보다 여러 이점을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_1.png\" /\u003e\n\n다음은 마이크로서비스 아키텍처의 주요 이점 요약입니다:\n\n- 느슨한 결합:\n\n마이크로서비스는 각각 물리적으로 분리되어 있기 때문에 느슨하게 결합되어 있습니다. 이 분리로 인해 각 서비스는 개별적으로 개발, 배포 및 확장될 수 있어 다른 서비스에 영향을 미치지 않고 독립적으로 변경이 가능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 독립성 팀:\n\n다른 팀은 서로 독립적으로 다른 마이크로서비스에 작업할 수 있습니다. 이 상대적 독립성은 병렬 개발을 가능케하며 전체 개발 프로세스를 가속화하고 효율성을 향상시킬 수 있습니다.\n\n- 테스트 및 배포의 용이성:\n\n마이크로서비스 아키텍처는 테스트와 배포를 쉽게 할 수 있게 해줍니다. 각 서비스가 별도의 단위이기 때문에 독립적으로 테스트하고 배포할 수 있어 테스트의 복잡성을 줄이고 배포 주기를 가속화할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 지속적 배포:\n\n마이크로서비스는 지속적인 배포 방법에 잘 맞습니다. 각 서비스는 전체 시스템에 영향을 미치지 않고 지속적으로 업데이트되고 배포될 수 있어 더 자주 릴리스하고 빠른 업데이트가 가능해집니다.\n\n이제, 마이크로서비스 아키텍처를 구성하는 주요 구성 요소를 살펴보겠습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 게이트웨이\n\n프로덕션 환경에서는 마이크로서비스와의 직접 통신이 허용되지 않습니다. 대신, 모든 마이크로서비스는 중개자(일반적으로 미들웨어 또는 API 게이트웨이)와 상호 작용하는 단일 응용 프로그램으로 그룹화되어 처리되어야 합니다. 이 중개자는 로드 밸런서 역할을 하여 들어오는 요청을 마이크로서비스에 골고루 분배하여 부하를 균형 있게 유지하고 최상의 성능을 보장합니다. 미들웨어가 단일 장애 지점(SPOF)이 될 수 있지만, 이러한 위험은 중복 및 고가용성 설정을 통해 강력하고 신뢰할 수 있는 작동을 보장함으로써 완화됩니다.\n\n게이트웨이를 구성하는 두 가지 방법이 있습니다 :\n\n- 정적 구성: 소수의 마이크로서비스를 다룰 때, 미들웨어를 정적으로 구성하여 특정 경로를 지정된 IP 주소로 라우팅할 수 있습니다. 예를 들어, /path1는 주소 1로, /path2는 주소 2로 이동할 수 있습니다. 이 구성에서는 마이크로서비스의 IP 주소를 알아야 하며, 마이크로서비스가 중지되거나 IP 주소가 변경되면 설정을 업데이트해야 합니다.\n- 동적 구성: 여러 마이크로서비스가 동적으로 시작 및 중지되는 환경에서는 정적 구성만으로는 충분하지 않습니다. 여기서는 발견 서비스를 통한 동적 구성이 필수적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 발견 서비스\n\n발견 서비스는 디렉터리처럼 작동합니다 (DNS 또는 SOAP의 UDDI와 유사함). 마이크로서비스는 시작할 때 발견 서비스에 등록됩니다. 그런 다음 게이트웨이는 마이크로서비스의 현재 IP 주소를 확인하기 위해 서비스 레지스트리에 쿼리하도록 구성되어 라우팅 구성을 자동으로 업데이트할 수 있습니다.\n\n# 구성 서비스\n\n- 콜드 구성: 각 마이크로서비스는 자체 구성 파일(예: application.properties)을 갖습니다. 이러한 파일에 대한 수정은 해당 마이크로서비스를 다시 시작해야 합니다. 또한, 구성 설정이 여러 마이크로서비스 간에 공유되는 경우 각 개별 구성 파일을 따로 업데이트해야 합니다. 동일한 마이크로서비스의 여러 인스턴스가 실행 중인 경우 변경 사항을 각 인스턴스에 개별적으로 적용해야 하므로 불편하고 실수를 유발할 수 있는 프로세스가 됩니다.\n- 핫 구성: 중앙 집중식 구성 서비스는 단일 전역 구성 파일을 유지합니다. 이 파일의 변경 사항은 마이크로서비스에 자동으로 전파되어 다시 시작할 필요가 없습니다. 일반적으로 이 구성은 Git과 같은 버전 관리 리포지토리를 통해 관리됩니다. 구성 매개변수가 변경되면 커밋이 수행되고 특정 변경 사항만 마이크로서비스로 전송됩니다. 전체 구성 파일이 아니라 특정 변경 사항만 전송되므로 모든 마이크로서비스에서 효율적이고 일관된 구성 관리가 보장됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 커뮤니케이션 모델\n\n- 동기식 통신: 누군가에게 길을 물어본다고 상상해봅니다. 동기식 통신에서는 \"공원에 어떻게 가요?\" 라고 물어보고 그 후 그들이 답변할 때까지 그 자리에 기다립니다. 답변을 듣고 나서야만 앞으로 나아갑니다. 이는 마이크로서비스가 서로와 대화하는 방식과 유사합니다. 한 서비스가 무언가를 요청하고, 답변을 기다리며, 그것을 받은 후에만 다음 단계로 넘어갑니다. 이 방법은 빠르고 직관적이지만, 상대 서비스가 응답하는 데 오랜 시간이 걸리면 느릴 수 있습니다.\n\n![이미지1](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_3.png)\n\n![이미지2](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 비동기 통신: 이제, 지시를 기다리는 대신 \"공원에 가고 있어. 만나야 할 일이 있으면 알려줘\"라는 메모를 남기는 상황을 상상해봐. 그럼 너는 그냥 걷어가서 다른 일을 계속 한다. 나중에 답변이 있는지 확인하기 위해 메모를 확인한다. 이것은 메시지 브로커와 함께 하는 비동기 통신과 비슷하다. 한 서비스가 응답을 기다리지 않고 다른 서비스로 메시지를 보낸다. 메시지는 중개인(브로커)에게 보내지고, 그 이후 브로커가 다른 서비스에 전달한다. 보내는 서비스는 기다리지 않고 작업을 계속할 수 있다. 이것은 즉각적인 답변이 필요하지 않고 메시지가 도착했을 때 처리할 수 있는 경우에 좋다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_5.png)\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_6.png)\n\n우리는 Reactive 프로그래밍에 관한 다가오는 블로그에서 이 두 가지 모델을 자세히 살펴볼 것이다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데모\n\n이 데모에서는 Spring 프레임워크를 사용하여 간단한 마이크로서비스 시스템을 구축하는 방법을 살펴보겠습니다. 특히 Spring Boot와 Spring Cloud에 초점을 맞출 것입니다. 이러한 도구들은 마이크로서비스를 쉽게 구축하고 관리할 수 있도록 설계되었습니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_7.png)\n\n이 데모에서는 두 개의 마이크로서비스인 고객 서비스와 계정 서비스가 있을 것입니다. 각 마이크로서비스는 간단한 Spring Boot 애플리케이션으로, 공통 종속성인 Lombok, Spring Data JPA, H2 Database, Spring Web을 사용해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 고객 서비스: 고객을 관리합니다.\n\n다음은 Customer 모델입니다.\n\n![Customer Model](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_8.png)\n\n- 계정 서비스: 고객에게 속한 각 계정을 관리합니다. 각 마이크로서비스는 자체 데이터베이스를 갖기 때문에, 계정 서비스 데이터베이스는 각 계정에 대해 고객 ID만 저장합니다. 이 고객 ID는 고객 서비스 데이터베이스에 존재해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 참조 무결성 보장하기\n\n참조 무결성은 테이블 간의 관계가 일관적으로 유지되도록 보장합니다. 이 시나리오에서의 적용 방법은 다음과 같습니다:\n\n계정 추가:\n\n- 새 계정을 추가하려면 계정 서비스 데이터베이스에 고객 ID만 저장합니다.\n- 참조 무결성을 보장하려면 고객 ID가 고객 서비스 데이터베이스에 존재하는지 확인해야 합니다.\n- 이를 위해 계정을 추가하기 전에 고객 ID가 유효한지 확인하기 위해 고객 서비스를 호출해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 Account 모델입니다.\n\n![Account Model](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_9.png)\n\n@Transient는 데이터베이스에 저장되지 말아야 하는 필드를 나타내는 주석입니다. 이 경우 accounts 데이터베이스에 customer 테이블이 없고 외래 키도 없기 때문에 customer 필드는 고객 서비스를 쿼리하여 수동으로 생성됩니다.\n\n# Discovery service\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금 새로운 스프링 부트 응용 프로그램을 시작하려고 하는데, 이번에는 이 종속성을 추가해야 합니다.\n\n![dependency](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_10.png)\n\n그런 다음 메인 클래스에 @EnableEurekaServer 주석을 추가해야 합니다.\n\n![annotation](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_11.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그런 다음, 우리는 이 구성을 추가합니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_12.png\" /\u003e\n\n그리고 애플리케이션을 시작합니다.\n\n마이크로서비스가 유레카 서버에 등록할 수 있도록 하려면, 각 마이크로서비스에 이 종속성을 추가해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_13.png)\n\n기본적으로 서비스는 서비스가 실행 중인 서버의 서비스 이름과 서버 이름으로 등록됩니다. 그러나 현실적인 시나리오에서는 서버 이름 대신 IP 주소가 필요합니다. 따라서 각 마이크로서비스 수준에 이러한 속성을 추가해야 합니다.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_14.png)\n\ndefaultZone 구성은 Eureka 인스턴스의 기본 위치를 http://localhost:8761/eureka URL로 지정합니다. 그러나 실제로는 적절한 IP 주소를 사용해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제, 마이크로서비스를 실행하고 Eureka 대시보드에 액세스하면 각 마이크로서비스의 주소와 포트를 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_15.png)\n\n# 게이트웨이\n\n새로운 스프링 부트 애플리케이션을 만들고 이 종속성을 추가합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_16.png)\n\n- 정적 구성:\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_17.png)\n\n- 프리디케이트: 요청을 라우팅하는 데 사용되는 조건입니다. 예를 들어, 요청 경로에 /customer가 포함되어 있으면 게이트웨이는 해당 마이크로서비스로 라우팅합니다. 프리디케이트는 요청 경로, 헤더 또는 쿼리 매개변수와 같은 다양한 기준을 바탕으로 할 수 있습니다.\n- URI: 이는 게이트웨이가 요청을 보내는 엔드포인트입니다. 예를 들어, URI가 http://localhost:8080/api로 설정된 경우 게이트웨이는 해당 주소로 요청을 전달합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 localhost:8888/customers를 입력하면 게이트웨이가 localhost:8082/customers로 요청을 리디렉션합니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_18.png)\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_19.png)\n\n- 동적 구성:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그냥 이 bean 하나 추가해주세요.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_20.png)\n\n그리고 이 구성요소도 추가해주세요.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_21.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 CORS를 구성해야 합니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_22.png)\n\n이제 URL을 게이트웨이포트/대문자의 서비스이름 형식으로 입력한 후 특정 경로를 이어서 입력합니다.\n\n예를 들어: http://localhost:8888/ACCOUNT-SERVICE/accounts\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n게이트웨이는 해당 서비스의 경로를 찾기 위해 서비스 디스커버리에 해당 서비스의 이름만으로 요청을 전달합니다.\n\n![이미지1](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_23.png)\n\n![이미지2](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_24.png)\n\n지금까지 살펴본 것처럼, 우리가 계정을 조회할 때 고객 정보도 함께 얻습니다. 그렇다면 계정 서비스는 어떻게 고객 서비스에서 해당 정보를 검색할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Understanding Microservices](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_25.png)\n\n특정 계정에 대한 정보를 얻기 위해 계정 서비스에 요청을 보낼 때, 먼저 해당 계정을 데이터베이스에서 찾습니다. 그런 다음, 계정과 연결된 고객 ID를 검색하고 해당 고객에 대한 정보를 얻기 위해 고객 서비스에 요청을 보냅니다. 최종적으로 결과를 구성하여 클라이언트에게 보냅니다.\n\n내부 요청을 보내기 위해 다양한 라이브러리를 사용할 수 있으며, 가장 흔한 것은 OpenFeign입니다.\n\n다음 종속성을 추가합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_26](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_26.png)\n\nOpenFeign은 HTTP 요청을 간편하게 만들어주는 선언적 프레임워크입니다. 복잡한 코드를 작성하는 대신 인터페이스를 정의하고 상호 작용하려는 서비스의 이름을 지정하고 사용하려는 엔드포인트를 나열하기만 하면 됩니다.\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_27](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_27.png)\n\nFeign을 사용하여 요청을 보내려면 Account 서비스의 주 클래스에 @EnableFeignClients 주석을 추가해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 우리는 인터페이스를 주입하고 해당 함수를 사용하여 고객 서비스에 요청을 보내는 방법을 알아봅니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_28.png)\n\n요청을 보내기 전에, 우리는 Discovery Service에 서비스의 주소를 요청합니다 (Gateway를 우회합니다). 예를 들어 findCustomerById를 호출하는 경우에 문제가 발생할 수 있고 서비스가 차단될 수 있습니다. 이를 해결하기 위해 \"서킷 브레이커\"를 사용합니다.\n\n서킷 브레이커는 전력 시스템의 전기 회로 차단기와 유사하게 작동합니다. 이는 지속적으로 구성 요소(예: 원격 서비스 호출)를 모니터링하고 반복된 실패 또는 성능 저하를 감지하면 해당 실패하는 구성 요소에 대한 호출을 일시적으로 차단하여 '회로를 열게' 합니다. 이 기간 동안 서킷 브레이커는 트래픽을 대체로 리다이렉트할 수 있습니다(예: 백업 시스템 또는 대체 기능).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n소프트웨어 아키텍처에서 회로 차단기 패턴의 이점은 다음과 같습니다:\n\n- 향상된 탄력성: 실패를 격리시켜 시스템의 다른 부분으로 전파되는 것을 방지합니다.\n- 지연 시간 단축: 빠르게 트래픽을 백업이나 Fallback로 리디렉션하여 최종 사용자의 지연 시간을 줄입니다.\n- 과부하 보호: 실패하는 구성 요소로의 새 요청을 일시적으로 제한함으로써 불필요한 과부하를 방지합니다.\n\n회로 차단기는 일반적으로 세 가지 주요 상태에서 작동합니다: Closed, Open, Half-Open:\n\n- Closed 상태:\n  - 구성 요소로의 정상 트래픽 흐름을 허용합니다.\n  - 구성 요소의 동작을 계속 모니터링합니다.\n- Open 상태:\n  - 회로 차단기가 비정상적인 실패 또는 성능 저하를 감지할 때 진입합니다.\n  - 실패하는 구성 요소로의 트래픽을 적극적으로 차단합니다.\n  - 더 이상의 실패 전파를 방지합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nHalf-Open 상태:\n\n- 오픈 상태에서 정의된 기간이 지난 후, 회로 차단기는 문제가 발생한 구성 요소가 회복되었는지 테스트하기 위해 Half-Open 상태로 전환될 수 있습니다.\n- 제한된 수의 테스트 요청을 통과시키도록 합니다.\n- 이러한 요청이 성공하면, 회로 차단기는 구성 요소가 작동 중이라는 것을 나타내는 Closed로 돌아갑니다.\n- 실패가 계속되면, 보호를 연장하기 위해 다시 Open 상태로 돌아갑니다.\n- Half-Open 상태에서는 이전에 실패한 구성 요소가 회복되었고 다시 트래픽을 신뢰할 수 있는지를 평가하기 위해 회로 차단기 메커니즘 자체에 의해 일반적으로 테스트 요청이 생성됩니다.\n\n![](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_29.png)\n\nCircuit Breaker 패턴을 구현하기 위해서는 필요한 종속성을 추가하는 것부터 시작해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_30.png)\n\n예외 상황 발생 시 기본 데이터 또는 캐싱된 데이터로 응답하겠습니다. 일정 기간이 지난 후에는 해당 서비스와의 통신을 재개할 것입니다. 서비스가 응답하고 클로즈드 서킷 모드로 전환되면, 그렇지 않을 경우 오픈 서킷 모드로 전환하겠습니다.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_31.png)\n\n간단한 예제를 살펴보죠: 모든 서비스를 시작한 후 고객 서비스를 중단할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_32.png)\n\nWe can see that the account service is still working, and the customer data returned is just default data.\n\n![Understanding Microservices: A Modern Approach to Software Architecture](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_33.png)\n\nConfig-Service\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마이크로서비스마다 자체 설정이 있는 경우 변경 사항이 발생하면 해당 서비스를 다시 시작해야 합니다. 또한, 대부분의 설정이 모든 서비스에서 동일하며, 각 구성 파일에 반복된 항목이 있습니다.\n\n이 문제의 해결책은 모든 구성을 저장하고 관리할 수 있는 중앙 집중식 구성 서비스를 사용하는 것입니다.\n\n먼저 간단한 스프링 부트 애플리케이션을 만들고 이 종속성을 추가할 것입니다.\n\n![image](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_34.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n효율적으로 설정을 관리하려면 모든 설정 파일을 저장할 Git 저장소를 만들어야 합니다. 이 저장소는 로컬에 있을 수도 있고(이 경우 구성 서버와 같은 기기에 있어야 함), 또는 원격 GitHub 저장소일 수 있습니다.\n\n- Application.properties: 이 파일에는 모든 마이크로서비스 간에 공유되는 설정이 포함됩니다.\n- 서비스별 구성: 각 마이크로서비스는 해당하는 이름(예: customer-service.properties)의 구성 파일을 가져야 합니다.\n\n마이크로서비스의 이름은 해당 내부 구성 파일에 명시되어야 합니다. 마이크로서비스가 시작되면 구성 서버에 해당 구성 파일을 요청하는 요청을 보냅니다. 구성 서버는 올바르게 응답하기 위해 마이크로서비스의 이름을 알아야 합니다(포트도 마찬가지).\n\n우리는 각 마이크로서비스에 이 구성을 추가해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_35](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_35.png)\n\n구성이 변경되면 구성 서비스에서 관련된 마이크로서비스로 요청이 전송됩니다 (/actuator/refresh로의 POST 요청), 그것에게 다시 시작하지 않고 구성을 새로 고쳐 달라는 것을 요청합니다. 그럼 마이크로서비스는 업데이트된 구성을 구성 서버에서 요청하고, 저장된 버전과 비교해서 변경된 부분만을 보내줍니다.\n\n그래서 우리는 각 마이크로서비스에 Actuator 종속성을 추가해야 합니다.\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_36](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_36.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모든 마이크로서비스 간에 공유되도록 application.properties 파일 내에서 config 리포지토리에 이 구성을 추가해야 합니다. 이 구성은 액추에이터 엔드포인트를 활성화합니다.\n\n![Actuator Configuration](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_37.png)\n\n구성 파일을 위한 Git 리포지토리는 여기에 있습니다.\n\n![Configuration Git Repository](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_38.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로, 설정 서비스의 구성 파일인 application.properties 내부에서 Git 리포지토리의 위치를 로컬 변수로 지정해야 합니다. 이는 구성 파일을 로컬 폴더에 포함하거나 구성 파일을 원격 리포지토리로 푸시하는 경우 GitHub 리포지토리의 URL일 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_39.png)\n\n# 마이크로서비스 아키텍처 도커화\n\n이제, 마이크로서비스를 실행하려면 발견 서비스를 먼저 실행한 다음 구성 서비스와 게이트웨이를 실행해야 합니다. 이러한 서비스들이 올바르게 시작되면 다른 마이크로서비스를 시작할 수 있습니다. 다수의 마이크로서비스를 처리할 때 각각을 필요한 순서대로 수동으로 시작하는 것은 어려울 수 있습니다. 해결책은 모든 서비스와 종속성을 지정하여 올바른 순서로 시작되도록 보장하는 Docker Compose 파일을 사용하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 각 마이크로서비스에 이 도커파일을 추가해줍니다.\n\n![도커파일](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_40.png)\n\n도커파일을 간단하게 만들기 위해서는 Docker Compose를 실행하기 전에 마이크로서비스를 먼저 빌드해야 합니다. 권장하는 방법은 컨테이너를 실행할 때 애플리케이션을 빌드하는 겁니다.\n\n다음은 도커 컴포즈입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_41.png)\n\nBuilding Images:\n\n- Running `docker-compose up --build` builds Docker images for each service from their respective Dockerfiles.\n- This ensures that each service starts with the latest configurations.\n\nHealth Checks:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Docker Compose는 각 컨테이너의 상태를 모니터링하기 위해 건강 검사(healthcheck)를 사용합니다.\n- 일반적으로 건강 검사는 컨테이너 내에서 특정 엔드포인트 (/actuator/health)를 쿼리하여 올바르게 작동하는지 확인합니다.\n\n의존성 관리 (Depends On):\n\n- 서비스는 시작 순서를 제어하기 위해 종속성(dependes_on)을 지정합니다.\n- 이를 통해 다른 서비스에 의존하는 서비스가 해당 의존성이 시작될 때까지 기다립니다.\n\n이제 환경 변수를 사용하기 위해 구성 파일을 변경해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어\n\n![UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_42](/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_42.png)\n\nDocker Compose를 사용할 때는 DISCOVERY_SERVICE_URL 환경 변수를 활용합니다. 수동으로 실행하는 경우에는 일반적으로 localhost:8761/eureka를 사용합니다.\n\n이로써 이 블로그를 마치겠습니다. 다음에 다시 만나요! 👍\n","ogImage":{"url":"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png"},"coverImage":"/assets/img/2024-06-19-UnderstandingMicroservicesAModernApproachtoSoftwareArchitecture_0.png","tag":["Tech"],"readingTime":28},{"title":"스파크-비욘드 기본 델타 테이블에서 동시 쓰기와 행 수준 동시성","description":"","date":"2024-06-19 12:31","slug":"2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable","content":"\n![image](/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png)\n\nDatabricks와 델타 테이블은 데이터 엔지니어의 삶을 쉽게 만들어줍니다. 😍🥰\n\n하지만 이 엔지니어들은 어쩔 수 없이 그들에게 맞서려고 할 것입니다. 😒😒\n\n델타 테이블이 제공하는 ACID 속성에 대해 이미 알고 있다면 좋겠지만(알지 못하신다고요? 읽어보세요), 이러한 속성은 델타 테이블에서 동시에 발생하는 쓰기 작업을 다루지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 현재 상황\n\n현재 델타 테이블에 병행(또는 동시) 쓰기 작업을 수행하면 \"ConcurrentAppendException\"이 발생합니다.\n\n# 동시 작성이란\n\n2명의 데이터 엔지니어인 Monica와 Ross Geller가 델타 테이블에 동시에 쓰기를 하려고 한다고 가정해보겠습니다. 🥴 (형제 맹견이야!)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전에 (2024년 5월 16일 이전에 🙈), 데이터 엔지니어들은 어떻게든 동시 쓰기를 직렬 쓰기로 변환하기 위해 더러운 파이스파크 코드 💩를 작성해야 했습니다. 이러한 로직 중 하나를 아래에서 설명합니다.\n\n로직: 델타 테이블에 대한 쓰기가 진행 중이면, 해당 쓰기가 끝날 때까지 기다린 후 현재 쓰기 프로세스를 시작합니다. 여기서 자세한 내용을 확인하세요.\n\n따라서 델타 테이블에 동시에 쓰기할 수 있는 모든 노트북에는 위의 로직을 포함해야 합니다.\n\n# Databricks에서 이 문제에 대해 무엇을 하였을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그렇다구요! 🥳 Databricks Runtime 14.2 이상에서 데이터브릭은 \"행 수준 동시성\"(RLC)이라 불리는 새로운 기능을 소개했어요.\n\n데이터브릭은 마치 요정 🧞‍♂️ 같죠. 무엇이든 물어보면 주어져요!\n\n## 행 수준 동시성(RLC)을 위한 요구 사항\n\n1. 델타 테이블의 \"삭제 벡터\"를 활성화해야 해요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nALTER TABLE table_name SET TBLPROPERTIES ('delta.enableDeletionVectors' = true);\n```\n\n2. 델타 테이블은 파티션이 없어야 합니다.\n\n# RLC를 사용한 동시 쓰기 작업 및 그 결과\n\n## 삽입-삽입:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 Ross와 Monica가 동시에 삽입 작업을 수행한다면, RLC는 어떤 문제도 없이 처리할 수 있어요 😏 (충돌 없음)\n\n## 삽입-갱신/삭제:\n\n만약 Ross가 삽입을 수행하고 Monica가 갱신/삭제를 수행한다면, RLC는 조금 답답해집니다. 🥵\n\n델타 테이블의 격리 수준이 \"WriteSerializable\"로 설정되어 있다면 (기본값), 동시 작성 작업은 어떤 문제도 발생하지 않고 수행됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그런데 고립 수준을 \"Serializable\"로 변경하면 (어떤 이유에서든 변경했을 것입니다 🤔) 충돌이 발생하고 오류가 발생할 것입니다.\n\n## 업데이트/삭제\n\nRoss와 Monica가 동일한 델타 테이블에서 업데이트 또는 삭제 작업을 수행하는 경우, 동일한 행에서 작업을 수행하면 오류가 발생합니다.\n\n업데이트/삭제 작업이 다른 행에서 발생하는 경우 문제없이 작업이 수행됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 요약:\n\n- 델타 테이블에 대한 동시 행 수준 동시성(RLC)은 Databricks에서 도입되었으며 동시 쓰기 작업을 수행할 수 있게 해줍니다.\n- RLC가 작동하기 위한 몇 가지 요구 사항이 있습니다.\n\n자세한 내용은 [여기](https://link-to-more-info)에서 읽을 수 있습니다.\n\n이 블로그를 좋아하셨다면 👏을 클릭하고 데이터 엔지니어들의 삶을 쉽게 만들기 위해 공유해주세요! 😉\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n읽어 주셔서 감사합니다! 😄\n","ogImage":{"url":"/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png"},"coverImage":"/assets/img/2024-06-19-Spark-BeyondBasicsConcurrentwritesandRow-levelconcurrencyinDeltaTable_0.png","tag":["Tech"],"readingTime":5},{"title":"아저라 데이터브릭스 SQL 웨어하우스 인스턴스의 실제 비용을 계산하는 방법","description":"","date":"2024-06-19 12:28","slug":"2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances","content":"\n\u003cimg src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png\" /\u003e\n\n이야기에서는 Azure Databricks SQL Warehouse 인스턴스의 비용을 계산하는 방법에 대해 배워보겠습니다.\n\nDatabricks SQL Warehouse는 Azure Databricks에서 데이터를 쿼리하고 탐색할 수 있는 컴퓨팅 리소스입니다.\n\n현재 Azure Databricks에서는 3가지 유형의 SQL Warehouse를 제공합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- SQL Warehouse Classic: SQL Warehouse Classic의 컴퓨팅 레이어는 저희 Azure 구독 계정에 존재하며 Photon을 지원하지만 Predictive IO나 Intelligent Workload Management은 지원하지 않습니다.\n- SQL Warehouse Pro: SQL Warehouse Pro의 컴퓨팅 레이어는 저희 Azure 구독 계정에 존재하며 Photon과 Predictive IO를 지원하지만 Intelligent Workload Management는 지원하지 않습니다.\n- SQL Warehouse Serverless: Azure Databricks 서버리스 아키텍처를 사용하여 Databricks SQL Warehouse Serverless가 Azure Databricks 계정에 존재하며 Databricks SQL의 모든 성능 기능(Phton, Predictive IO 및 Intelligent Workload Management)을 지원합니다.\n\n위 목록에서 볼 수 있듯이, SQL Warehouse Classic과 SQL Warehouse Pro 사이의 가장 중요한 차이점은 컴퓨팅 레이어가 저희 Azure 구독 계정에 있고, SQL Warehouse Serverless가 저희 Azure Databricks 계정에 있다는 것입니다.\n\n## 관련 이야기:\n\n- Microsoft 및 Databricks API를 사용하여 Azure Databricks 클러스터의 비용을 최적화하고 90%까지 줄이는 방법\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1. DIY 방법\n\n첫 번째 섹션은 비용 분석 논리를 이해하고 아마도 자신만의 도구나 스크립트를 작성하여 Azure Databricks SQL Warehouse 인스턴스의 비용을 계산하고자 하는 개발자 또는 기술 직군을 위해 제공됩니다.\n\n# 1.1. DIY 방법 — SQL Warehouse Classic\n\nAzure Databricks SQL Warehouse Classic 또는 Azure Databricks SQL Warehouse Pro의 비용을 계산하려면 다음 구성 요소를 고려해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- SQL 계산 시간: SQL Warehouse가 실행되었던 시간.\n- Databricks Unit (DBU) 시간: SQL Warehouse에서 사용된 컴퓨팅 단위가 시간당 청구됩니다.\n- 저장 비용: 적용된 경우 데이터 저장에 연관된 비용.\n- 대역폭 비용: 적용된 경우 대역폭 전송에 연관된 비용.\n\n# 1.1.1. Databricks API에서 SQL Warehouse Classic 인스턴스 목록 가져 오기\n\n첫 번째 단계는 Databricks API \"/api/2.0/sql/warehouses\"를 사용하여 SQL Warehouse 인스턴스 목록을 검색하는 것입니다.\n\nAPI 호출을 실행한 후, 모든 Databricks SQL Warehouse가 포함 된 JSON 응답을 받게됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSQL Warehouse Classic의 JSON은 다음과 같습니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"2b1613d995c81e7d\",\n  \"name\":\"Classic Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":45,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"channel\":{\n    \"name\":\"CHANNEL_NAME_CURRENT\"\n  },\n  \"enable_serverless_compute\":false,\n  \"warehouse_type\":\"CLASSIC\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/2b1613d995c81e7d;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/2b1613d995c81e7d\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n위와 유사한 데이터를 얻을 수 있습니다(쉽게 이해할 수 있도록 형식화됨)\n\n\u003cimg src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_1.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1.1.2. Microsoft API를 통해 SQL Warehouse Classic 자원의 비용 가져오기\n\n검색한 사용 데이터와 비용 정보를 결합하여 SQL Warehouse Classic의 비용을 계산해야 합니다.\n\n저희는 Microsoft Generate Cost Details Report API를 사용하여 Databricks 클러스터가 실행되는 Azure 구독에 대한 모든 데이터를 가져올 것입니다.\n\nAPI를 사용할 때 주의할 점들:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Azure 구독의 비용 세부 정보 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 비용이 연관되지 않은 데이터는 제거해야 합니다.\n- 결과를 Pay-as-you-go 또는 Enterprise 유형의 Azure 구독에 따라 조정해야 하며, 결과가 서로 다릅니다.\n- API는 한 달 이하의 데이터만 가져오도록 허용하며 13개월 이전의 데이터는 제공하지 않습니다.\n\nMicrosoft API에서 데이터를 추출할 때, 보고서에서 다음 열을 선택해야 합니다:\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용된 Azure 리소스의 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용된 Azure 리소스의 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n# 1.1.3. SQL Warehouse 클래식 인스턴스 비용 계산\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMicrosoft Databricks 및 Azure API에서 데이터를 검색한 후, 마지막 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API의 SQL Endpoint ID와 일치시키는 것입니다.\n\n우리는 이와 유사한 데이터를 받을 것입니다 (이해하기 쉽게 형식화된 데이터입니다):\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_2.png)\n\nSQL Warehouse Classic 인스턴스에서 제품은 Azure Databricks - Premium - SQL Analytics이며, 미터 이름은 Premium SQL Analytics DBU입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼, SQL Warehouse 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n# 1.2. 직접 계산 방법 — SQL Warehouse Pro\n\nAzure Databricks SQL Warehouse Pro의 비용을 계산하기 위해 다음 구성 요소를 고려해야 합니다:\n\n- SQL 컴퓨트 시간: SQL Warehouse가 실행된 시간입니다.\n- 데이터브릭스 유닛(DBU) 시간: SQL Warehouse에서 사용된 컴퓨트 유닛으로, 매 시간마다 청구됩니다.\n- 저장 비용: 데이터 저장에 관련된 비용(해당하는 경우).\n- 대역폭 비용: 대역폭 전송에 관련된 비용(해당하는 경우).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAPI 호출을 실행한 후, 모든 Databricks SQL Warehouse에 대한 JSON 응답을 받게 됩니다.\n\n다음은 SQL Warehouse Pro의 JSON입니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"aedd502a582f673a\",\n  \"name\":\"Starter Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":10,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"channel\":{ },\n  \"enable_serverless_compute\":false,\n  \"warehouse_type\":\"PRO\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/aedd502a582f673ad;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/aedd502a582f673a\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n이와 유사한 데이터를 얻게 될 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_3.png)\n\n# 1.2.2. Microsoft API를 통한 SQL Warehouse PRO 자원 비용 가져오기\n\nSQL Warehouse Pro 비용을 계산하기 위해서는 검색된 사용 데이터와 비용 정보를 결합하여 총 비용을 계산해야 합니다.\n\nMicrosoft Generate Cost Details Report API를 사용하여 Databricks 클러스터가 실행 중인 Azure 구독에 대한 모든 데이터를 가져올 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAPI를 사용할 때 중요한 사항:\n\n- Azure 구독에 대한 비용 세부 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 관련된 데이터 또는 비용이 연관되지 않은 데이터를 제거해야 합니다.\n- Azure 구독 유형(유연한 요금제 또는 기업용)에 따라 결과를 조정해야 합니다. 왜냐하면 출력 결과물이 다르기 때문입니다.\n- API는 한 달 이하의 데이터만 가져올 수 있으며 13개월 이전의 데이터는 가져올 수 없습니다.\n\nMicrosoft API에서 데이터를 추출할 때, 보고서에서 다음 열을 선택해야 합니다.\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용된 Azure 리소스의 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용된 Azure 리소스의 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1.2.3. SQL Warehouse PRO Instances 비용 계산하기\n\nMicrosoft Databricks와 Azure API에서 데이터를 검색한 후, 최종 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API에서 SQL Endpoint ID와 일치시키는 것입니다.\n\n다음과 유사한 데이터를 얻게 됩니다:\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSQL Warehouse Pro 인스턴스에서 Product가 Azure Databricks Regional — Premium — SQL Compute Pro이고 MeterName이 Premium SQL Compute Pro DBU인 경우, SQL Warehouse 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n# 1.3. 직접 만들기 방법 — SQL Warehouse Serverless\n\nAzure Databricks SQL Warehouse Serverless 인스턴스는 Azure Databricks 계정 내에서 실행되므로 Databricks Unit (DBU) 시간 단위로 청구됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAPI 호출을 실행한 후, Databricks SQL Warehouse에 관한 JSON을 받게 됩니다.\n\n다음은 Serverless SQL Warehouse의 JSON입니다:\n\n```js\n\"warehouses\":[\n{\n  \"id\":\"e6e7601bde7c3a43\",\n  \"name\":\"Serveless Warehouse\",\n  \"size\":\"XXSMALL\",\n  \"cluster_size\":\"2X-Small\",\n  \"min_num_clusters\":1,\n  \"max_num_clusters\":1,\n  \"auto_stop_mins\":10,\n  \"auto_resume\":true,\n  \"creator_name\":\"terraform@kopicloud.net\",\n  \"creator_id\":1036471128901988,\n  \"tags\":{ },\n  \"spot_instance_policy\":\"COST_OPTIMIZED\",\n  \"enable_photon\":true,\n  \"enable_serverless_compute\":true,\n  \"warehouse_type\":\"PRO\",\n  \"num_clusters\":0,\n  \"num_active_sessions\":0,\n  \"state\":\"STOPPED\",\n  \"jdbc_url\":\"jdbc:spark://adb-xxxxxxxx.x.azuredatabricks.net:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/e6e7601bde7c3a43;\",\n    \"odbc_params\":{\n      \"hostname\":\"adb-xxxxxxxx.x.azuredatabricks.net\",\n      \"path\":\"/sql/1.0/warehouses/e6e7601bde7c3a43\",\n      \"protocol\":\"https\",\n      \"port\":443\n    }\n   }\n  }\n]\n```\n\n이처럼 유사한 데이터를 얻을 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_5.png\" /\u003e\n\n# 1.3.2. Microsoft API를 통해 SQL Warehouse Serverless 리소스 비용 얻기\n\n검색된 사용량 데이터를 비용 정보와 결합하여 SQL Warehouse Serverless 비용을 계산해야 합니다.\n\nDatabricks 클러스터가 실행 중인 Azure 구독의 모든 데이터를 가져 오기 위해 Microsoft Generate Cost Details Report API를 사용할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAPI를 사용할 때 중요한 사항:\n\n- Azure 구독에 대한 비용 세부 내역 데이터를 가져올 때, Databricks와 관련된 데이터만 필터링하고 다른 서비스와 관련 없는 데이터를 제거해야 합니다.\n- 결과를 조정해야 하는 이유는 Azure 구독 유형(사용한 만큼 지불 또는 기업 서비스)에 따라 출력이 다르기 때문입니다.\n- API는 한 달 이하의 데이터만 검색할 수 있으며 13개월 이전의 데이터는 가져올 수 없습니다.\n\nMicrosoft API에서 데이터를 추출할 때 다음 보고서 열을 선택해야 합니다:\n\n- SqlEndpointId: SQL Warehouse 인스턴스의 ID\n- ProductName: 사용한 Azure 리소스 설명\n- MeterName: 청구되는 서비스 또는 리소스 유형을 식별하는 레이블\n- CostInBillingCurrency: 사용한 Azure 리소스 비용\n- BillingCurrency: 청구 통화 코드 (USD, EUR 등)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1.3.3. SQL Warehouse Serveless 인스턴스 비용 계산하기\n\nMicrosoft Databricks와 Azure API에서 데이터를 검색한 후, 최종 단계는 SQL Endpoint ID를 사용하여 Azure 비용 데이터를 필터링하고 Databricks API에서 SQL Endpoint ID를 매칭하는 것입니다.\n\n우리가 얻게 되는 데이터는 이와 비슷할 것입니다:\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSQL 웨어하우스 서버러스 인스턴스에서, 제품은 Azure Databricks Regional — Premium — Serverless SQL이고 미터 이름은 프리미엄 서버러스 SQL DBU입니다.\n\n그런 다음 SQL 웨어하우스 인스턴스의 최종 비용을 계산하기 위해 모든 레코드를 추가합니다.\n\n## 2. 쉬운 방법\n\nSQL 웨어하우스의 비용을 분 단위로 결정해야하는 경우, KopiCloud Azure Databricks 비용 도구를 사용하는 것이 쉽습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n내가 API 데이터를 가져오고 필터링하며 추출하는 경험을 토대로, Microsoft 및 Databricks API에서 검색한 데이터를 읽고 관리하는 프로세스를 간소화하기 위해 이 도구를 개발했습니다.\n\n이 도구는 간단한 사용자 인터페이스를 사용하며, 몇 분 내에 서식이 지정된 데이터를 검색하려는 FinOps 전문가들을 위해 설계되었습니다.\n\n먼저 \"Databricks 비용 찾아보기\" 버튼을 클릭합니다.\n\n도구는 Microsoft 및 Databricks API와 연결하고 화면 및 Excel 파일에서 서식이 지정된 데이터를 생성할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_7.png](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_7.png)\n\n두 번째로 마지막 단계에서는 Cost per SQL Warehouse Report 버튼을 클릭하여 SQL Warehouse 및 해당 비용 목록을 생성합니다.\n\n이 도구는 화면에 정보를 표시하고 Excel 파일로 내보냅니다.\n\n![2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_8.png](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도구는 모든 데이터를 Excel 파일로 출력하여 데이터를 조작하거나 사용자 정의 보고서를 작성할 수 있도록 합니다.\n\n![이미지](/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_9.png)\n\n또한 도구는 원시 및 형식화된 데이터를 생성하고 일일 및 총 일일 비용을 로컬 스토리지나 Azure Blob Storage에 저장하여 사용자 정의 PowerBI 보고서를 생성할 수 있습니다.\n\n그게 다에요. 만약 이 이야기가 마음에 드셨다면 👏을 눌러주세요. 읽어 주셔서 감사합니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- KopiCloud Azure Databricks Cost 도구는 KopiCloud 웹사이트에서 다운로드할 수 있어요.\n- 만약 Databrick 클러스터 비용을 줄이는 데 도움이 필요하다면 Linkedin에서 저에게 연락해 주세요.\n- 게시된 이미지는 Flaticon의 Dewi Sari가 만든 Cost 아이콘을 사용하여 생성되었어요.\n\n## 관련 이야기:\n\n- Microsoft 및 Databricks API를 사용하여 Azure Databricks 클러스터 비용을 최대 90%까지 최적화하고 줄이는 방법\n","ogImage":{"url":"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png"},"coverImage":"/assets/img/2024-06-19-HowToCalculatetheRealCostofAzureDatabricksSQLWarehouseInstances_0.png","tag":["Tech"],"readingTime":17},{"title":"눈꽃 폴라리스와 데이타브릭스 유니티 카탈로그 오픈 및 상호 운용 가능한 메타스토어 시대","description":"","date":"2024-06-19 12:26","slug":"2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores","content":"\n\u003cimg src=\"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png\" /\u003e\n\n이번 달에는 두 대형 클라우드 데이터 플랫폼인 Snowflake와 Databricks에서 비슷한 성격의 주요 발표가 이뤄졌습니다.\n\n6월 초 한 주쯤에, Snowflake는 매년 개최되는 컨퍼런스에서 Apache Iceberg 위에 구현된 오픈 카탈로그인 Polaris Catalog를 발표했습니다. 그리고 그 한 주 뒤에, Databricks가 데이터 거버넌스를 위한 통합 솔루션을 제공하는 Unity Catalog 제품을 오픈소스로 공개했습니다. 이 짧은 기사에서 자세히 살펴보도록 하겠습니다.\n\n# 데이터 호수(Datalake)에서의 메타데이터 카탈로그\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_1.png](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_1.png)\n\n이 제품에 대해 파헤치기 전에, 데이터 레이크의 맥락에서 정의에 대해 먼저 간단히 논의해보겠습니다. 메타데이터 카탈로그, 또는 메타스토어라고도 알려진 것은 데이터셋을 테이블로 표현하여 객체 저장소에 있는 데이터에 대한 추상화 레이어를 만듭니다. 데이터에 대한 접근은 메타스토어를 통해 관리되며, 상호 작용을 테이블에 저장된 것처럼 변환하여 저장소에서 필요한 작업을 수행합니다.\n\n# Databricks Unity Catalog\n\n처음 접하는 분들을 위해 - 2013년 Apache Spark의 창시자들에 의해 설립된 Databricks는 데이터 레이크와 데이터 웨어하우스를 결합하여 기업이 데이터 및 AI 솔루션을 구축, 관리 및 확장하는 데 도움이 되는 클라우드 기반 데이터 인텔리전스 플랫폼입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n약 2021년 중반쯤, 유니티 카탈로그가 독점 소스로 출시되었습니다. 이는 플랫폼 에코시스템 내에서 데이터 및 AI 자산을 접근하고 관리하기 위한 솔루션이었습니다. 이는 중앙 집중식 접근 제어, 감사, 계보, 공유 및 데이터 발견 기능과 같은 여러 기능을 제공했습니다.\n\n![이미지](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_2.png)\n\n오픈 테이블 형식 (OTFs)인 Iceberg, Delta 및 Hudi가 인기를 얻으면서, 주요 데이터 플랫폼 공급 업체들은 이 세 가지 중 하나를 선택해야 했습니다. 당연히 Databricks의 창립자로서 델타 레이크가 주요 형식으로 선택되었습니다.\n\n그러나 오픈 델타 형식을 사용하는 플랫폼과의 밀접한 결합은 Apache Iceberg 또는 Hudi와 호환되는 쿼리 엔진과의 상호 운용성이 제한되었음을 의미했습니다. Databricks가 이 문제를 해결하기 위한 최초의 시도는 Delta UniForm이었습니다. 이는 복사 또는 변환의 필요성을 제거하고 레이크하우스 상호 운용성을 위한 범용 형식을 제공했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n최신 발표에 따르면, Unity Catalog를 오픈 API와 아파치 2.0 라이센스로 빌드한 오픈 소스 서버로 제공하는 Databricks가 기업에게 오픈 데이터 형식(UniForm을 통한)을 지원하며 다양한 쿼리 엔진, 도구, 클라우드 플랫폼 간의 상호 운용성을 제공하는 범용 인터페이스를 제공하여 다음 수준으로 나아갔습니다.\n\n# Snowflake Polaris Catalog\n\n2012년 개발된 Snowflake는 데이터 웨어하우징, 데이터 레이크, 데이터 엔지니어링 및 데이터 과학을 위한 완전히 관리되는 SaaS 플랫폼입니다. Snowflake는 스토리지와 컴퓨팅의 분리, 온디맨드 확장 가능한 컴퓨팅, 데이터 공유, 데이터 복제, 그리고 성장하는 기업의 요구를 처리하기 위한 타사 도구 지원과 같은 기능들을 제공합니다.\n\nSnowflake는 자사의 프로프라이어터리 테이블 형식을 시작한 후, 재미있게도 얼마 전부터 Apache Iceberg와의 통합에 헌신하여 왔습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Snowflake Polaris and Databricks Unity Catalog](/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_3.png)\n\n최근 출시된 Polaris 카탈로그는 Iceberg의 오픈 소스 REST 프로토콜을 기반으로 하여 사용자가 Iceberg Rest API를 지원하는 Apache Spark, Flink, Trino 등과 같은 원하는 엔진을 사용하여 데이터에 액세스하고 검색할 수 있는 오픈 표준을 제공합니다. Polaris는 다음 90일간(약 2024년 4분기) 오픈 소스로 공개될 예정입니다.\n\n# 개방성은 호환성을 의미하지 않을 수 있습니다\n\n이러한 프로젝트들을 오픈 소스 Apache 이니셔티브로 오픈하는 것은 긍정적인 단계이지만, 데이터 솔루션 아키텍처적인 측면에서 보면, 코드를 오픈할 필요는 없고 오히려 노출되는 인터페이스가 오픈되어야 합니다. 이 글을 쓰는 동안, Polaris는 원래 Iceberg만을 지원하며, Unity는 UniForm을 사용하여 네이티브 Delta 이외의 다른 OTF(Open Table Format)를 간접적으로 지원하고, Tabular 인수 이후 Iceberg와의 새로운 통합을 수행하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"이상적인 '오픈' 정의에서 이 메타스토어는 모든 표준 테이블 형식을 지원하고, 구성 가능한 저장 계층과 Hive Metastore가 한동안 있었던 것과 같은 메타스토어에 대한 표준 인터페이스를 가져야 합니다.\n\n# 결론\n\n대부분의 기업은 벤더 락인을 피하면서 데이터 생태계를 더 열린, 유연한, 상호 운용 가능한 것으로 하고 싶어합니다. 데이터브릭스 없이 유니티 카탈로그를 구현하거나, 스노우플레이크 없이 폴라리스를 사용하는 것은 흥미로운 전망입니다. 엔지니어링 팀은 이제 이러한 기능을 구매한 플랫폼이나 컨테이너를 사용하여 자체 인프라에서 독립적으로 호스팅하는 유연성을 가지게 되었습니다. 다가오는 몇 달 동안, 개방 커뮤니티의 협력으로 이 제품들의 성장과 채택을 지켜보는 것이 흥미로울 것입니다.\"\n","ogImage":{"url":"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png"},"coverImage":"/assets/img/2024-06-19-SnowflakePolarisandDatabricksUnityCatalogTheageofOpenandInteroperableMetastores_0.png","tag":["Tech"],"readingTime":5},{"title":"마이크로소프트 패브릭과 데이타브릭스 유니티 카탈로그 - 통합 시나리오 해석하기","description":"","date":"2024-06-19 12:25","slug":"2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios","content":"\n올해 첫 번째 Microsoft Fabric 커뮤니티 컨퍼런스가 개최되었습니다. 첫 번째 날 키노트에서 Fabric와 Databricks Unity Catalog (UC) 통합을 쇼케이스하는 두 가지 미리보기가 있었어요.\n\n이전 블로그 게시물에서는 Databricks에서 OneLake로 쓰는 옵션 및 Fabric Spark에서 ADLS Gen2로 쓰는 옵션(Unity Catalog가 활성화된 클러스터가 아닌 경우)에 대해 알아보았습니다. 이 블로그 게시물은 Fabric + Unity Catalog 통합(Unity Catalog가 활성화된 클러스터와 관련된 다양한 시나리오를 밝히는 것을 목표로 합니다. Lakehouse 시나리오에 대한 자세한 내용은 Piethein의 게시물에서 확인해주세요.\n\n- Unity Catalog 테이블을 OneLake 카탈로그로 동기화할 수 있을까요? 어떻게요?\n- Unity Catalog가 활성화된 클러스터에서 OneLake로 쓸 수 있을까요?\n- Unity Catalog를 OneLake와 통합할 수 있을까요? SQL 엔드포인트 / Fabric 데이터 웨어하우스에 대해 페더레이티드 쿼리를 실행할 수 있을까요?\n\n참고: 본 글은 제 개인적인 경험과 견해를 반영한 것이며, Microsoft나 Databricks의 공식 입장을 대변하는 것은 아닙니다. 또한, 이 블로그 게시물은 잠재적인 시나리오를 개요로 제시하였지만, Fabric 로드맵이나 의도를 반영하는 것은 아닙니다. 미래에 모든 언급된 옵션이 운영되지는 않을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Databricks Unity Catalog and Microsoft Fabric\n\n통합 시나리오는 기본적으로 진입점에 따라 볼 수 있습니다. Unity Catalog 및 Fabric:\n\n- Fabric에서 Unity Catalog에 액세스하기 (Fabric → Unity Catalog): 이 기능을 통해 사용자는 Fabric 내에서 Unity Catalog 카탈로그, 스키마 및 테이블에 원활하게 액세스할 수 있습니다.\n- Unity Catalog에서 Fabric 활용하기 (DBX/Unity Catalog → Fabric): 이 기능을 사용하면 사용자는 Unity Catalog 내부에서 OneLake에 직접 액세스하고 SQL 엔드포인트 또는 Fabric 데이터 웨어하우스를 통해 연합 쿼리를 실행할 수 있습니다.\n\n이러한 시나리오를 자세히 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Fabric → Unity Catalog\n\n## Fabric에서 Unity Catalog 사용하기\n\nFabric에서 Unity Catalog 테이블에 액세스할 수 있는 몇 가지 옵션이 있습니다. Fabric Spark에서 ADLS Gen2로 직접 읽기 및 쓰기도 가능합니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios_0.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현재 옵션\nUC 테이블에 바로 가기를 생성할 수 있는 옵션은 현재 두 가지 있습니다: 수동(지루한) 또는 반자동, 후자는 노트북을 통해 가능합니다. 반자동 방법을 사용하면 사용자들은 UC Delta 외부 테이블을 OneLake에 통합하여 바로 가기를 생성할 수 있습니다. 동기화를 위해 카탈로그와 스키마 이름을 지정하면, 해당 스키마 내 테이블에 대한 바로 가기가 Fabric 레이크하우스 내에 생성됩니다. 실행 유틸리티 노트북에 대한 추가 지침을 참조하세요.\n\n```js\n# configuration\ndbx_workspace = \"\u003cdatabricks_workspace_url\u003e\"\ndbx_token = \"\u003cpat_token\u003e\"\ndbx_uc_catalog = \"catalog1\"\ndbx_uc_schemas = '[\"schema1\", \"schema2\"]'\n\nfab_workspace_id = \"\u003cworkspace_id\u003e\"\nfab_lakehouse_id = \"\u003clakehouse_id\u003e\"\nfab_shortcut_connection_id = \"\u003cconnection_id\u003e\"\nfab_consider_dbx_uc_table_changes = True\n\n# sync UC tables to lakehouse\nsc.addPyFile('https://raw.githubusercontent.com/microsoft/fabric-samples/main/docs-samples/onelake/unity-catalog/util.py')\nfrom util import *\ndatabricks_config = {\n    'dbx_workspace': dbx_workspace,\n    'dbx_token': dbx_token,\n    'dbx_uc_catalog': dbx_uc_catalog,\n    'dbx_uc_schemas': json.loads(dbx_uc_schemas)\n}\nfabric_config = {\n    'workspace_id': fab_workspace_id,\n    'lakehouse_id': fab_lakehouse_id,\n    'shortcut_connection_id': fab_shortcut_connection_id,\n    \"consider_dbx_uc_table_changes\": fab_consider_dbx_uc_table_changes\n}\nsync_dbx_uc_tables_to_onelake(databricks_config, fabric_config)\n```\n\n가능한 미래 옵션\n\n- Fabric에서 Unity Catalog 네이티브 항목: 하이브 메타스토어 메타데이터 이동과 유사하게, Unity Catalog 메타데이터를 Fabric 레이크하우스로 동기화하여 Unity Catalog 테이블에 액세스할 수 있게 합니다. 이 시나리오의 한 예시는 FabCon에서 시연되었는데, 사용자들이 Fabric UI를 통해 Unity Catalog 테이블에 직접 액세스하고 쿼리할 수 있는 것을 보여주었습니다.\n- Fabric에 Unity Catalog 바로 가기: Dataverse 바로 가기와 유사하게, OneLake 바로 가기 UX는 잠재적으로 Unity Catalog 테이블에 대한 바로 가기 생성을 지원할 수 있을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n참고: 델타 공유, Databricks에서 JDBC/ODBC, Fabric 데이터 파이프라인 Databricks 활동 등의 옵션은 여기에 언급되지 않았습니다.\n\n# Databricks/Unity 카탈로그 → Fabric\n\n## Databricks/Unity 카탈로그에서 Fabric 및 OneLake 사용하기\n\nUnity 카탈로그는 클라우드 객체 저장소 연결(예: ADLS Gen2)을 활용하고 외부 데이터 시스템에 연결하여 연합 쿼리를 실행하는 다양한 방법을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 현재 옵션입니다. 사용자들은 UC 활성화된 클러스터에서 OneLake를 다음과 같이 사용할 수 있습니다: (i) Service Principal (SPN) 기반 인증을 사용하여 OneLake에 r/w, 그리고 (ii) SPN 인증을 사용하여 mount 지점으로 OneLake에 r/w.\n\n```js\n# spn을 사용한 r/w\nworkspace_name = \"\u003c워크스페이스_이름\u003e\"\nlakehouse_name = \"\u003c레이크하우스_이름\u003e\"\ntenant_id = \"\u003c테넌트_ID\u003e\"\nservice_principal_id = \"\u003c서비스_프린시펄_ID\u003e\"\nservice_principal_password = \"\u003c서비스_프린시펄_비밀번호\u003e\"\n\nspark.conf.set(\"fs.azure.account.auth.type\", \"OAuth\")\nspark.conf.set(\"fs.azure.account.oauth.provider.type\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\nspark.conf.set(\"fs.azure.account.oauth2.client.id\", service_principal_id)\nspark.conf.set(\"fs.azure.account.oauth2.client.secret\", service_principal_password)\nspark.conf.set(\"fs.azure.account.oauth2.client.endpoint\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n\n# 읽기\ndf = spark.read.format(\"parquet\").load(f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/Files/data\")\ndf.show(10)\n\n# 쓰기\ndf.write.format(\"delta\").mode(\"overwrite\").save(f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/Tables/dbx_delta_spn\")\n```\n\n```js\n# spn으로 Mount\nworkspace_id = \"\u003c워크스페이스_ID\u003e\"\nlakehouse_id = \"\u003c레이크하우스_ID\u003e\"\ntenant_id = \"\u003c테넌트_ID\u003e\"\nservice_principal_id = \"\u003c서비스_프린시펄_ID\u003e\"\nservice_principal_password = \"\u003c서비스_프린시펄_비밀번호\u003e\"\n\nconfigs = {\n    \"fs.azure.account.auth.type\": \"OAuth\",\n    \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n    \"fs.azure.account.oauth2.client.id\": service_principal_id,\n    \"fs.azure.account.oauth2.client.secret\": service_principal_password,\n    \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\n}\n\nmount_point = \"/mnt/onelake-fabric\"\ndbutils.fs.mount(\n    source = f\"abfss://{workspace_id}@onelake.dfs.fabric.microsoft.com\",\n    mount_point = mount_point,\n    extra_configs = configs\n)\n\n# 읽기\ndf = spark.read.format(\"parquet\").load(f\"/mnt/onelake-fabric/{lakehouse_id}/Files/data\")\ndf.show(10)\n\n# 쓰기\ndf.write.format(\"delta\").mode(\"overwrite\").save(f\"/mnt/onelake-fabric/{lakehouse_id}/Tables/dbx_delta_mount_spn\")\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n알림: OneLake abfss 경로 또는 마운트 경로를 사용하여 외부 테이블을 만들 경우 UC에서 예외가 발생할 수 있습니다. 현재, OneLake를 기본 저장소로 사용하여 UC에 외부 테이블을 등록할 수 없습니다. 이는 잠재적인 미래 시나리오로 이어질 수 있습니다.\n\n- INVALID_PARAMETER_VALUE: 클라우드 파일 시스템 스키마 누락\n- 목록을 위한 SAS 토큰을 획득하지 못했습니다. 유효하지 않은 Azure 경로\n\n잠재적인 미래 옵션\nADLS Gen2와 Azure Synapse와 유사하게, 미래에는 다른 옵션이 존재할 수 있습니다:\n\n- 기본 관리 저장소로서 OneLake: Databricks는 Unity Catalog의 자동 활성화를 시작했습니다. 즉, 자동으로 ADLS Gen2와 같이 Databricks 관리 저장소로 Unity Catalog 메타스토어를 자동으로 프로비저닝합니다. 그러나 사용자는 Unity Catalog 메타스토어를 OneLake를 가리키도록하면서 사용자 관리 수준 저장소를 생성할 수도 있습니다. 참고: 아직 이 기능은 불가능합니다.\n- 외부 위치로서 OneLake: 외부 위치는 카탈로그 및 스키마의 관리 저장소 위치를 정의하고, 외부 테이블 및 외부 볼륨의 위치를 정의하는 데 사용됩니다. 예를 들어, Spark에서 외부 테이블을 사용하는 경우 OneLake를 외부 위치로 활용할 수 있습니다. 참고: 아직 이 기능은 불가능합니다.\n- 볼륨용 OneLake: 볼륨은 클라우드 객체 저장소 위치의 논리적 저장 볼륨을 나타내며 비 탭식 데이터셋에 대한 관리 방식을 추가합니다. ADLS Gen2와 같이 OneLake를 사용하여 외부 및 관리 볼륨을 생성할 수 있습니다. 참고: 아직 이 기능은 불가능합니다.\n- 연합 Lakehouse: SQL 엔드포인트나 Fabric Data Warehouse의 데이터에 대한 읽기 전용 액세스는 UC 외부 카탈로그를 사용하여 미래 옵션으로 가능할 수 있습니다. 현재 Azure Synapse 및 SQL 액세스 인증은 사용자 이름/암호를 기반으로 하며 SPN은 아직 지원되지 않으므로 이 옵션은 아직 불가능합니다. 외부 카탈로그는 현재 객체 저장소를 지원하지 않으므로, 아직 OneLake/Lakehouse로의 외부 카탈로그 연결이 가능한지 여전히 불분명합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n표 태그를 Markdown 형식으로 변경해주세요.\n\n## 잠깐, 액세스 정책은 어떻게 되나요?\n\n다른 옵션으로는 Databricks의 ODBC를 SQL 엔드포인트로 사용하거나 Partner Connect( Power BI + Databricks) 및 스트리밍 옵션이 여기에 언급되지 않았네요.\n\n계속해서 Unity 카탈로그 액세스 정책이 OneLake RBAC 및 OneSecurity와 어떻게 조화를 이루고 있는지, Unity 카탈로그에서 Fabric로 보안 및 액세스 정책을 이동하거나 그 반대로 이동할 수 있는지에 대해 살펴볼 수 있을 것입니다.\n\n참고 문헌:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Non-UC 시나리오: Databricks와 Fabric — OneLake 및 ADLS Gen2에 쓰기 | Aitor Murguzur 작성 | Medium\n- Lakehouse 시나리오: Azure Databricks와 Microsoft Fabric 통합 | Piethein Strengholt 작성 | 2024년 6월 | Medium\n- Databricks Unity Catalog를 OneLake와 통합 — Microsoft Fabric | Microsoft Learn\n","ogImage":{"url":"/assets/img/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios_0.png"},"coverImage":"/assets/img/2024-06-19-MicrosoftFabricandDatabricksUnityCatalogunravelingtheintegrationscenarios_0.png","tag":["Tech"],"readingTime":10},{"title":"데이터브릭스, 데브옵스 및 파이테스트","description":"","date":"2024-06-19 12:24","slug":"2024-06-19-DatabricksDevOpsandpytest","content":"\nDatabricks에서 코드 품질을 지속적으로 보장하고 DevOps 작업 프로세스에 통합하는 방법에 궁금증을 풀어 보셨나요? 더 이상 망설이지 마세요.\n\n다음 예시에서는 Databricks에서 pytest와 DevOps를 사용하여 구현된 테스트 기능을 쉽게 시작하는 방법에 대해 살펴볼 것입니다.\n\n# 목표\n\n이 글을 마치면 Databricks에 구현된 함수를 테스트하고, DevOps에서 pull request가 제출될 때마다 테스트 스위트를 실행할 수 있게 될 것입니다. 아래에서 이를 어떻게 구현할지 살펴보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png\" /\u003e\n\n# DevOps에서 프로젝트 설정하기\n\nPytest는 두 가지 테스트 레이아웃을 지원하는데, 이 예시에서는 테스트가 애플리케이션 코드 외부에 배치되는 테스트 레이아웃을 사용할 것입니다. 이 분리는 나중에 데브옵스와 데이타브릭스 자산 번들을 사용하여 자동 릴리스를 다루는 기사에서 유용할 것입니다.\n\n```js\nproject.toml;\npipelines / pipeline_pytest.yml;\nsrc / functions / column_funtions.py;\nsoultion / demo_notebook.py;\ntests / test_column_funtions.py;\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 예시에서는 src(소스 코드)와 tests(테스트)로 구성된 두 개의 주요 폴더를 갖춘 간단한 설정이 있습니다. src 폴더는 지원하는 함수를 포함하는 functions와 Lakehouse를 구현하는 노트북을 포함하는 solution 폴더로 구분됩니다.\n\ncolumn_functions.py에서는 주어진 열을 제곱하는 간단한 함수를 구현했습니다.\n\n```python\n# Databricks notebook source\ndef column_squared(df, columnname):\n    df_squared = df.withColumn(columnname + \"_squared\", df[columnname] * df[columnname])\n    return df_squared\n```\n\ntest_column_functions.py에서는 column_functions.py의 함수 기능을 유효성 검사하는 간단한 테스트를 구현했습니다. 여기서 중요한 부분은 외부 데이터 소스나 스파크 세션에 의존하지 않고 독립적으로 유닛 테스트를 구현하고 있다는 것입니다. 입력과 예상 출력을 비교하기 위해 Databricks의 내장 기능을 사용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport pytest\nfrom pyspark.sql import SparkSession\nfrom pyspark.testing import assertDataFrameEqual\nfrom src.functions.column_functions import column_squared\n\nclass TestColumnFuntions(object):\n    def test_column_squared(self):\n        spark = SparkSession.builder.getOrCreate()\n\n        source_data = [(\"John\", 25), (\"Alice\", 30), (\"Bob\", 35)]\n        source_df = spark.createDataFrame(source_data, [\"name\", \"age\"])\n\n        df_actual = column_squared(source_df,'age')\n\n        expected_data = [(\"John\", 25, 625), (\"Alice\", 30, 900), (\"Bob\", 35, 1225)]\n        df_expected = spark.createDataFrame(expected_data, [\"name\", \"age\", \"age_squared\"])\n\n        assertDataFrameEqual(df_actual, df_expected)\n```\n\n# DevOps 파이프라인\n\n함수와 관련된 테스트를 구현한 후에는 이제 Azure DevOps에서 파이프라인을 설정할 수 있습니다.\n\n파이프라인(pipeline*pytest.yml)에 대해 가상 환경을 Python용으로 생성하고 필요한 패키지를 설치한 다음 'tests' 디렉토리에서 pytest를 실행합니다. 이 경우 pytest-azurepipelines를 사용하여 pytest를 DevOps 파이프라인에 통합합니다. 이제 pytest는 'test*.py'로 시작하거나 '\\_test.py'로 끝나는 모든 테스트를 찾아 이 경로를 따라 이동합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\ntrigger: none\n\nsteps:\n  - task: UsePythonVersion@0\n    inputs:\n      versionSpec: \"3.9\"\n      addToPath: true\n\n  - script: |\n      python -m venv .venv\n      source .venv/bin/activate\n      python -m pip install --upgrade pip\n      pip install numpy==1.22.4\n      pip install pyspark\n      pip install pandas\n      pip install pyarrow\n      pip install pytest-azurepipelines\n      python -m pytest -vv tests\n    displayName: \"pytest\"\n```\n\n이제 메인 브랜치에서 빌드 검증을 설정하여, 개발자가 풀 리퀘스트를 만들 때마다 정의된 테스트가 실행되도록 할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_1.png\" /\u003e\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 예시에서는 Databricks에서 구현된 기능에 대한 테스트 슈트를 설정하고 DevOps 워크플로에 통합하는 것이 얼마나 간단한지 살펴보았습니다. 이제 프로젝트에 필요한 테스트를 구현하여 지속적으로 고품질 코드를 제공할 수 있도록 만들어 보세요.\n","ogImage":{"url":"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png"},"coverImage":"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png","tag":["Tech"],"readingTime":5},{"title":"단위 테스트 및 코드 모듈화를 위한 Databricks","description":"","date":"2024-06-19 12:22","slug":"2024-06-19-UnitTestingandCodeModularizationinDatabricks","content":"\n노트북은 Databricks에서 데이터를 다루는 인기 있는 방법입니다. 노트북 사용자는 데이터를 빠르게 읽고 변환하며 상호적으로 탐색할 수 있습니다. 게다가, 노트북을 공유하고 협업하는 것은 간단합니다. 그러나 프로젝트가 확장될수록 코드 중복을 방지하고 재사용성을 용이하게 하는 모듈화 기능이 필요해집니다.\n\n이를 달성하는 한 가지 방법은 공유 함수를 포함하는 노트북을 생성하고 각 노트북의 시작 부분에서 실행하는 것입니다. 또는 모듈을 만들어 일반적인 Python 개발과 유사한 Python import 명령어를 사용할 수 있습니다. 긴 코드 블록을 함수로 나누면 코드의 재사용을 촉진할 뿐만 아니라 테스트도 용이해집니다.\n\n![이미지](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png)\n\n## 모듈화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬에서 모듈화란 프로그램을 작은 관리 가능한 모듈로 나누는 것을 말합니다. 파이썬에서 코드를 모듈화하는 것에는 여러 가지 이점이 있습니다:\n\n- 재사용성: 모듈은 다른 프로젝트에서 다시 사용할 수 있어 재작성이 필요하지 않습니다.\n- 유지보수성: 작은 중점적인 모듈로 인해 업데이트와 디버깅이 쉬워집니다.\n- 확장성: 프로젝트가 성장할 때 효율적인 확장이 가능합니다.\n- 협업: 다른 개발자들이 동시에 작업하기를 용이하게 합니다.\n- 테스트: 단위 테스트가 간소화되어 더 신뢰할 수 있는 코드를 작성할 수 있습니다.\n- 가독성: 특정 작업에 집중함으로써 코드 이해가 향상됩니다.\n\nDatabricks에서 모듈을 사용하기 위해서는 클래스 또는 함수를 포함한 파일들로 구성된 폴더와 **init**.py 파일을 생성해야 합니다. 이는 Databricks에 모듈임을 알려줍니다. 아래는 공통 모듈과 함께 공유 함수, 변환 로직을 포함한 변환 모듈, 그리고 테스트 데이터가 포함된 내 솔루션의 구조입니다.\n\n코드 구조:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n워크스페이스\n├── test_data\n│    └── testdata.csv\n├── common\n│    └── __init__.py\n│    └── utilis.py\n├── transform\n│    └── __init__.py\n│    └── operations.py\n├── test_utils.py\n├── test_tran.py\n├── test\n```\n\ntestdata.csv:\n\n```js\nentity,iso_code,date,indicator,value\nUnited States,USA,2022-04-17,Daily ICU occupancy,\nUnited States,USA,2022-04-17,Daily ICU occupancy per million,4.1\nUnited States,USA,2022-04-17,Daily hospital occupancy,10000\nUnited States,USA,2022-04-17,Daily hospital occupancy per million,30.3\nUnited States,USA,2022-04-17,Weekly new hospital admissions,11000\nUnited States,USA,2022-04-17,Weekly new hospital admissions per million,32.8\n```\n\nulits.py:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\n\ndef mask_func(col_val):\n    if col_val is not None:\n        if len(col_val)\u003e=16:\n            charList=list(col_val)\n            charList[4:12]='x'*8\n            return \"\".join(charList)\n        else:\n            return col_val\n    else:\n        return col_val\n```\n\noperations.py:\n\n```js\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import row_number, col\n\ndef deduplicate(df, uniq_col, orderby_col):\n    df = df.withColumn(\"rn\", row_number()\n        .over(Window.partitionBy(uniq_col)\n        .orderBy(col(orderby_col).desc())))\n\n    df = df.filter(col(\"rn\") == 1).drop(\"rn\")\n    return df\n\ndef clean_clients(df):\n    df = df.where(col(\"name\") != \"\").withColumn(\"timestamp\", col(\"timestamp\").cast(\"date\"))\n\n    return df\n```\n\n모듈에서 이러한 함수를 사용하려는 사람은 아래 예시와 같이 import 명령을 사용하여 노트북에 쉽게 추가할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![UnitTestingandCodeModularizationinDatabricks1](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_1.png)\n\nSimilarly, it’s possible to import transformation functions from the module and remove duplicated records from the DataFrame.\n\n![UnitTestingandCodeModularizationinDatabricks2](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_2.png)\n\n# Unit Testing in Databricks\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n소프트웨어 개발에서 단위 테스트는 코드의 정확성, 안정성, 유지 보수 가능성을 보장하는 중요한 요소입니다. 데이터 처리를 위해 노트북이 일반적으로 사용되는 Databricks에서는 단위 테스트가 더욱 중요해집니다.\n\nDatabricks에서 단위 테스트를 시작하려면 코드를 테스트할 수 있는 함수로 분해해야 합니다. 이 프로세스는 코드의 모듈성을 향상시키는 것뿐만 아니라 포괄적인 테스트 스위트를 작성하는 데 도움이 됩니다. Python에서 유닛 테스트를 수행하는 두 가지 인기있는 프레임워크인 Unittest와 pytest가 있습니다.\n\nUnittest 예시:\n\n```python\nimport unittest\n\nclass ExampleTestSuite(unittest.TestCase):\n\n    def test_import(self):\n        self.assertTrue(True)\n\n    def test_addition(self):\n        self.assertEqual(1 + 2, 3)\n\n    def test_subtraction(self):\n        self.assertNotEqual(1 - 2, 0)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 왜 단위 테스팅을 해야 할까요?\n\n처음 테스트 중에 코드가 정상적으로 작동하는 것처럼 보이더라도, 단위 테스트는 여러 가지 이유로 중요한 역할을 합니다:\n\n- 정확성 확인: 단위 테스트는 코드의 개별 단위 기능을 확인하여 다양한 조건에서 예상대로 작동하는지 확인합니다.\n- 초기 버그 탐지: 개발 과정 초기에 버그를 식별함으로써, 개발자는 이를 신속히 해결하여 시스템의 다른 부분으로 전파되는 가능성을 줄일 수 있습니다.\n- 리팩토링 및 유지보수: 단위 테스트는 코드 리팩토링 및 유지보수 과정에서 안전망 역할을 하며, 개발자가 확신을 갖고 변경을 가할 수 있으면서도 일관된 동작을 보장합니다.\n- 회귀 테스트: 단위 테스트는 회귀 테스트로 작용하여 새로운 변경사항이나 기능이 기존의 기능을 망가뜨리지 않도록 하여 시스템의 안정성을 유지합니다.\n\n마스킹 기능에 대한 단위 테스트의 간단한 예제를 살펴보겠습니다. 이 단위 테스트는 입력 숫자가 올바르게 마스킹되거나 None을 반환하는지를 확인하여, 함수가 변경되더라도 예상되는 동작이 유지되도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ntest_utils.py\n\n```python\nfrom common.utils import mask_func\n\ndef test_mask_func():\n    assert \"1234xxxxxxxx4568\" == mask_func(\"1234567891234568\")\n    assert mask_func(None) is None\n```\n\nETL(Extract, Transform, Load)과 같은 복잡한 프로세스의 경우, 데이터 변환 과정의 다양한 측면을 확인하는 데 개선된 테스트를 개발할 수 있습니다. 이러한 테스트에는 스키마 확인, 데이터프레임 비교, 행 수 유효성 검사 또는 특정 값의 존재 여부 확인이 포함될 수 있습니다.\n\ntest_tran.py:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport pytest\nfrom transform.operations import *\nfrom pyspark.testing.utils import assertDataFrameEqual\nfrom pyspark.sql import SparkSession\nfrom pyspark.testing import assertDataFrameEqual, assertSchemaEqual\nfrom pyspark.sql.types import *\nimport pandas as pd\n\n@pytest.fixture()\ndef spark():\n    return SparkSession.builder.appName(\"integrity-tests\").getOrCreate()\n\n@pytest.fixture()\ndef raw_input_df(spark):\n    df = pd.read_csv('test_data/testdata.csv')\n    return spark.createDataFrame(df)\n\n@pytest.fixture()\ndef test_df(spark):\n\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Los Angeles\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df = spark.createDataFrame(input_data, schema)\n\n    return df\n\ndef test_deduplicate(test_df, spark):\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df = spark.createDataFrame(input_data, schema)\n\n    df1 = deduplicate(test_df, \"Name\", \"timestamp\")\n    assertDataFrameEqual(df1, df)\n\ndef test_schema_deduplicated(test_df, spark):\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df_expected = spark.createDataFrame(input_data, schema)\n\n    test_df = deduplicate(test_df, \"Name\", \"timestamp\")\n    assertSchemaEqual(test_df.schema, df_expected.schema)\n\ndef test_clean_clients(test_df, spark):\n    df = clean_clients(test_df)\n    assert df.where(\"name == '' \").count() == 0\n\ndef test_readfromfile(raw_input_df):\n    assert raw_input_df.count() \u003e 0\n```\n\n## Initializing Spark Session for Tests:\n\n테스트 파일은 주피터 노트북이 아니기 때문에, Spark 세션을 초기화하는 것이 필요합니다. 이를 위해서 `spark` 함수와 `fixture` 데코레이터를 사용해서 Spark 세션을 만들 수 있습니다. `fixture` 데코레이터는 자동으로 실행되며 각 테스트 함수에 해당하는 테스트 객체를 제공해주어 테스트 데이터의 생성 및 공유를 간편하게 할 수 있습니다.\n\n```js\n@pytest.fixture()\ndef spark():\n    return SparkSession.builder.appName(\"integrity-tests\").getOrCreate()\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n선언했던 fixture 데코레이터의 동작 방식을 주목하는 것이 중요합니다. 이 기법을 사용하면 테스트 데이터를 원활하게 실행하고 전달할 수 있습니다. 이 기법을 이용하면 Spark 세션을 생성하여 테스트 데이터를 로드하고 이를 테스트 함수 사이에서 공유할 수 있습니다. 테스트 데이터는 목록을 기반으로 생성하거나 테스트 파일에서 로드할 수 있습니다.\n\n```js\n@pytest.fixture()\ndef raw_input_df(spark):\n df = pd.read_csv('test_data/testdata.csv')\n\n return spark.createDataFrame(df)\n```\n\n테스트용 데이터 원본으로 샘플 파일을 사용하는 것도 가능합니다. 그러나 워크스페이스에서 로드해야 하는 경우에는 Spark가 워크스페이스로부터 파일을 직접 로드하는 것을 지원하지 않기 때문에 Pandas를 사용해야 합니다.\n\n## 모듈의 지연 변경 사항 처리하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모듈을 다룰 때 변경 내용을 구현하는 데 지연이 발생하는 것은 일반적입니다. 이 동작을 해결하기 위해 매직 함수를 사용할 수 있습니다:\n\n```js\n%load_ext autoreload\n\n%autoreload 2\n\n%aimport test_tran\n```\n\n# Databricks에서 단위 테스트 실행\n\nDatabricks에서 단위 테스트를 실행하려면 pytest 모듈을 호출하는 노트북을 생성해야 합니다. 아래는 지정된 저장소에서 테스트 실행을 트리거하는 코드 스니펫입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테스트 노트북:\n\n```js\n%pip install pytest\n```\n\n```js\nimport pytest\nimport sys\nimport os, sys\n\nrepo_name = \"\u003c저장소 위치\u003e\"\n\nnotebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\nrepo_root = os.path.dirname(os.path.dirname(notebook_path))\n\nos.chdir(f\"/Workspace/{repo_root}/{repo_name}\")\nprint(os.getcwd())\n# 읽기 전용 파일 시스템에 pyc 파일을 쓰지 않도록 설정합니다.\nsys.dont_write_bytecode = True\n\n# pytest 실행.\nretcode = pytest.main([\".\", \"-v\", \"-p\", \"no:cacheprovider\"])\n\n# 테스트 실패가 있는 경우 셀 실행 실패 처리합니다.\nassert retcode == 0, \"pytest 호출에 실패했습니다. 자세한 내용은 로그를 확인하세요.\"\n```\n\npytest를 실행하면 현재 디렉토리와 서브디렉토리에서 이름이 test\\__.py 또는 _\\_test.py 패턴을 따르는 모든 파일을 자동으로 실행합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스크립트를 실행하면 다음과 비슷한 보고서가 표시됩니다:\n\n![보고서](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_4.png)\n\n# 요약\n\n요약하면 모듈화와 유닛 테스팅은 소프트웨어 개발에서 널리 사용되는 관행이며, 이러한 적용은 데이터 엔지니어링 활동에 매끄럽게 확장됩니다. 코드의 모듈화 및 유닛 테스트를 구현하여 데이터 처리 솔루션이 더욱 신뢰성 있고 유연해집니다. 모듈화는 코드 구성 요소의 더 나은 조직화와 재사용을 가능하게 하며, 유닛 테스트는 각 구성 요소가 다양한 조건에서 예상대로 동작하는지 확인합니다. 이러한 기술들이 함께 사용되면 데이터 엔지니어링 솔루션의 전체적인 견고성과 유지보수성에 기여하며, 마지막으로 데이터 처리 파이프라인 및 워크플로의 품질을 향상시킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이 기사를 유익하게 여기셨다면, 'clap' 버튼을 클릭하거나 LinkedIn에서 좋아요를 표시해 주시면 감사하겠습니다. 여러분의 지원을 감사히 여깁니다. 궁금한 점이나 조언이 있으시다면 언제든 LinkedIn에서 연락해 주세요.\n","ogImage":{"url":"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png"},"coverImage":"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png","tag":["Tech"],"readingTime":13},{"title":"데이터  AI 서밋 by Databricks 2024의 주요 통찰 결과","description":"","date":"2024-06-19 12:21","slug":"2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024","content":"\nData + AI Summit by Databricks에서 얻은 주요 인사이트가 공개되었습니다! 다음과 같은 데이터 및 분석 공간의 흥미로운 업데이트가 있습니다.\n\n🚀 Unity Catalog가 이제 오픈 소스로 공개되었습니다! Duck DB와 같은 도구에서 Unity Catalog의 Delta 테이블에 외부에서 액세스할 수 있습니다. Azure Synapse, Azure SQL, Amazon Redshift, Snowflake를 추가하여 새로운 외부 데이터 소스에 연결할 수 있습니다.\n\n🛡️ Delta 테이블에 대한 규칙을 만들어 Unity Catalog에서 행 수준 보안 및 열 수준 가리기가 일반적으로 사용 가능해졌습니다.\n\n빌트인 데이터 품질 세부 정보로 GA로 된 Lake House 모니터링은 Delta 테이블을 모니터링하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n📊 Unity Catalog metrics가 Databricks 및 Power BI, Tableau와 같은 외부 사용자를 위해 도입되어 데이터를 신뢰하고 사용할 수 있습니다.\n\n🔥 Delta 4.0은 파티셔닝과 관련된 문제를 극복하기 위해 더 나은 성능을 제공하는 Liquid 클러스터링을 도입했습니다. 작성 시 7배, 읽기 시 12배 빠른 성능을 제공합니다. JSON을 variant 데이터 유형으로 저장하는 VARIANT도 제공됩니다.\n\n💻 7월 1일부터 스파크 클러스터를 위한 100% 서버리스 인프라를 제공합니다. 초고속 클러스터를 즐기고 사용한 만큼 지불하며, 유휴 시간 요금은 없습니다. 클러스터 크기 조정, 자동 확장성, 스팟 인스턴스와 같은 복잡성에 작별을 고하세요.\n\n🔄 Databricks Lakeflow (곧 미리 보기 예정)는 DLT와 워크플로에 기반하여 데이터 수집, 변환, 오케스트레이션, 데이터 파이프라인의 모니터링을 간편화하는 솔루션입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n🔍 Databricks SQL은 이제 빠른 클러스터 시작, 향상된 성능, SQL UDF, 세션 변수, 그리고 SQL 분석가를 위한 AI 기능을 갖춘 데이터 웨어하우징 핵심 기능을 제공합니다.\n\n🤖 Databricks AI/BI에는 챗봇 \"Genie\"가 포함되어 있으며, Gen AI는 자연어 쿼리에서 자동으로 BI 대시보드를 만들어서 셀프 서비스 보고를 가능하게 합니다.\n\nApache Iceberg Tabular의 인수로 Delta lake에 이제 UniForm 형식을 통합하여 Parquet 및 Delta 형식과 함께 제공됩니다.\n\n스파크 4.0이 곧 출시될 예정이며 흥미로운 업데이트가 예정되어 있습니다. 더 많은 혁신을 기대해 주세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n새로운 기능들을 탐험하는 것을 기대하고 있어요!\n\n만약 이 기사를 좋아하신다면, 저의 링크드인 페이지에서 저를 팔로우해주세요. https://www.linkedin.com/in/kaviprakash-selvaraj/\n","ogImage":{"url":"/assets/img/2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024_0.png"},"coverImage":"/assets/img/2024-06-19-KeyInsightsfromDataAISummitbyDatabricks2024_0.png","tag":["Tech"],"readingTime":3},{"title":"Azure Databricks와 Microsoft Fabric 통합하기","description":"","date":"2024-06-19 12:19","slug":"2024-06-19-IntegratingAzureDatabricksandMicrosoftFabric","content":"\n고지: 본 글은 Microsoft나 Databricks의 공식 입장이 아닌 저의 개인적인 경험과 견해를 반영하고 있습니다.\n\n본 글은 고객 상호작용 중 자주 언급되는 핫 토픽인 Azure Databricks와 Microsoft Fabric의 조합과 통합에 대해 다룹니다. 두 서비스는 각자의 분야에서 최고 수준을 자랑합니다. Azure Databricks는 데이터 엔지니어링, 데이터 과학 및 머신 러닝 워크로드의 확장에 능합니다. 마찬가지로 Microsoft Fabric은 다양한 데이터 사용을 위한 간편성과 셀프 서비스 기능으로 빛을 발합니다. 보통 제기되는 핵심 질문은: 이 두 강자를 어떻게 통합할 수 있을까요?\n\n현재 고려해야 할 다섯 가지 옵션이 있습니다. 이 글은 새로운 기능이 추가됨에 따라 발전할 수 있음을 염두에 두십시오.\n\n- 보고 및 분석 레이어를 추가하여 Databricks를 활용한 아키텍처를 더욱 강화합니다.\n- OneLake 골드 레이어를 통합하여 Databricks를 활용한 아키텍처를 보완합니다.\n- Databricks가 모든 데이터를 OneLake에 기록하도록 합니다. 권장되지는 않지만 논의할 가치가 있습니다.\n- V-ORDERED 활성화된 소비 레이어를 통해 Databricks를 확장합니다.\n- 추가 구성 요소를 추가하여 Databricks 및 Microsoft Fabric의 데이터 처리 효율성을 향상시킵니다. 이는 좀 더 개인적인 접근입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n금일 제공되는 옵션은 다음 섹션에서 철저히 검토될 것입니다. 미묘한 차이점을 제공하고 장단점을 고려하며 관련 문서를 참조할 것입니다. 그러나 그보다 앞서, 두 강력한 도구를 활용하기로 선택하는 조직이 그 이유를 이해하는 데 도움이 됩니다.\n\n## 왜 이 조합을 선택하는가?\n\n조직은 Azure Databricks와 Microsoft Service Fabric을 결합하는 이유 때문에 이 조합이 제공하는 독특한 기능들을 선호합니다.\n\n다양한 규모의 조직에서 선호하는 종합 데이터 처리, 분석 및 데이터 과학 플랫폼인 Azure Databricks는 긴 역사와 다양한 조직에서의 성공적인 채택으로 신뢰할 수 있는 플랫폼으로 자리매김했습니다. Spark의 창시자들에 의해 설립된 Databricks는 주로 엔지니어들을 위해 제공되며, 대규모로 Spark 워크로드를 관리하고 노트북 작성 및 복잡한 작업을 처리할 수 있는 플랫폼을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마이크로소프트 패브릭의 매력은 그 간단함에 있습니다. 2023년에 출시되어 파워 BI에서 진화한 이 제품은 기존 파워 BI 사용자에게 쉬운 전환을 제안합니다. 사용자 친화적인 인터페이스, 통합 셀프 서비스 기능, 그리고 마이크로소프트 365와의 심플한 통합으로 비즈니스 사용자들의 특히 매력을 끌고 있습니다. 마이크로소프트 패브릭은 데이터 사용을 민주화하고 진입 장벽을 낮추기 위해 설계되어 있어, 모든 사용자에게 접근성 있는 플랫폼으로 인기를 끌고 있습니다.\n\n본질적으로, Azure Databricks와 마이크로소프트 서비스 패브릭의 결합은 기술적, 비즈니스적 요구를 모두 충족하는 종합적인 솔루션을 제공하여, 많은 조직들 사이에서 인기를 얻고 있습니다.\n\n이제 조직들이 종종 이 결합을 선택하는 이유를 알게 되었습니다. 이제 두 서비스를 어떻게 통합할 수 있는지 알아보겠습니다.\n\n## 리포팅 및 분석 레이어를 추가하여 데이터브릭스 지원 아키텍처를 강화하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 디자인 고려 사항은 일반적인 Azure Databricks Medallion Lakehouse 아키텍처를 개선하는 데 관여합니다. 이 아키텍처는 Azure Data Lake Storage (ADLS) gen2, Azure Data Factory 및 Azure Databricks와 같은 서비스를 활용합니다. 이 설정에서 Databricks는 데이터 투입, 처리, 검증 및 보강의 모든 측면을 관리합니다. PowerBI는 일반적으로 보고와 분석적인 통찰을 전달하는 것을 포함한 나머지 작업을 처리합니다.\n\nMicrosoft Fabric을 포함한 Databricks 중심 아키텍처를 확장하여 자기 서비스 기능을 강화하고 비즈니스 사용자를 위한 사용자 경험을 향상시키는 것은 인기 있는 전략입니다. Databricks와 PowerBI에 새로운 기능과 능력을 갖추어 더욱 매력적이고 효율적인 경험을 제공한다고 생각해보세요.\n\nMicrosoft는 최근 Microsoft Fabric을 위한 '바로 가기'라는 새로운 기능을 소개했습니다. 이 기능은 다양한 소스에서 데이터를 읽어내어 데이터 중복을 제거하고 직접 데이터를 사용할 수 있게 하는 가벼운 데이터 가상화 엔진 역할을 합니다. 예를 들어, PowerBI를 사용할 때 PowerBI에 데이터를 복사하거나 가져오지 않고 필요한 데이터에 즉시 액세스할 수 있습니다.\n\n우리가 이전에 이야기한 Databricks 중심 디자인과 관련해서, Databricks가 모든 데이터를 ADLS에 쓰기 때문에 ADLS Gen2 바로 가기 기능을 활용할 수 있습니다. 그러나 주의해야 할 중요한 고려 사항이 몇 가지 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 단축키를 사용하려면 패브릭 레이크하우스가 필요합니다. 이미 보유하고 있지 않다면, 하나를 만드는 것을 잊지 마세요.\n- 테이블에 대한 바로 가기는 Delta Lake 형식의 데이터에만 액세스할 수 있습니다.\n- 다브릭 관리 테이블 대신 외부 테이블에 대한 바로 가기를 가능한 한 사용하세요. 다음 설계 고려 사항을 논의할 때 이 부분에 다시 언급하겠습니다.\n- 각 바로 가기는 단일 Delta 폴더를 참조할 수 있습니다. 그러므로 여러 Delta 폴더에서 데이터에 액세스해야 한다면, 각 폴더에 대해 개별적인 바로 가기를 만들어야 할 것입니다.\n- 이러한 테이블 디렉토리에서 파일을 직접 조작하지 마세요. 대신, ADLS에서 Delta 파일을 읽는 읽기 전용 접근 방식을 사용하세요. 이 접근 방식에서 ADLS는 중간 저장소로 작동합니다. Databricks에서 테이블을 직접 읽지 않습니다.\n- Lakehouse에 바로 가기를 만드는 것은 Fabric UI를 통해 수동으로 수행해야 합니다. 또는 REST API를 사용하여 모든 바로 가기를 자동으로 제공할 수 있습니다. 여기 튜토리얼 및 노트북 스크립트 링크가 있습니다.\n- ADLS에서 데이터를 직접 읽을 때는 Unity 카탈로그의 보안 모델의 데이터 액세스 정책이 적용되지 않습니다.\n\nDatabricks와 Microsoft Fabric을 통합하는 과정에서 흥미로운 발전이 동행되고 있습니다! 이러한 기능들은 Microsoft Build 2024 컨퍼런스에서 발표되었습니다. 곧 Azure Databricks Unity Catalog를 Fabric과 통합할 수 있을 것입니다. Fabric 포털을 통해 새로운 Azure Databricks Unity Catalog 항목을 만들고 구성할 수 있을 것입니다. 이 단계를 거치면 Unity Catalog에서 관리되는 모든 테이블이 즉시 바로 가기로 업그레이드될 수 있을 것입니다. 이 예정된 통합은 Azure Databricks 데이터를 Fabric에 효율적으로 통합하여 Fabric 워크로드 전반에 걸쳐 원활한 운영을 지원할 것입니다. 이 새로운 기능의 데모는 여기에서 찾아볼 수 있습니다: https://www.youtube.com/watch?v=BYob0cGW0Nk\u0026t=4434s\n\n데이터 사용을 위해 Microsoft Fabric을 사용하는 확장된 Databricks 중심 아키텍처는 Databricks에 아주 만족한 고객들 사이에서 흔히 관찰됩니다. 이들 고객은 이미 Databricks를 사용하여 레이크하우스를 구축하는 데 상당한 시간과 자원을 투자하였으며, 이를 계속 활용할 계획입니다. Microsoft Fabric는 Delta 형식을 사용하는 레이크하우스 접근 방식의 강점과 다재다능성을 인식합니다. 이는 데이터 소비에 최적화된 레이어를 추가하여 (기존) 아키텍처를 향상시킬 수 있게 해줍니다. 이를 통해 조직은 Databricks 중심 설정에 데이터 사용을 위한 추가적인 레이어를 특별히 추가함으로써 기존 아키텍처를 강화할 수 있습니다.\n\n## OneLake 골드 레이어를 통합하여 Databricks가 가능한 아키텍처를 칭찬하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 번째 디자인은 초기 디자인 패턴을 수정하여 OneLake 골드 레이어를 구조에 통합합니다. 이것은 Azure Databricks의 Azure Blob 파일 시스템 (ABFS) 드라이버 덕분에 가능합니다. 이 드라이버는 ADLS와 OneLake를 모두 지원합니다. 아래에 이 접근 방식의 그림을 보실 수 있고 MS Learn 페이지에서 Notebook 예제를 찾을 수 있습니다.\n\n이 구조 내에서 전반적인 워크플로 및 데이터 처리 단계 — 데이터 수집, 처리, 유효성 검사, 데이터 보강 — 는 크게 변경되지 않습니다. 모든 것은 Azure Databricks 내에서 관리됩니다. 핵심 차이점은 이제 데이터 사용을 위한 데이터가 Microsoft Fabric에 더 가까워졌다는 것입니다. 왜냐하면 Databricks는 데이터를 OneLake에 저장된 Gold 레이어에 기록하기 때문입니다. 이것이 최선의 방법이며 이것이 왜 유익한지 궁금할 수 있습니다.\n\n중요한 점은 이 통합 방식이 Databricks에서 공식적으로 지원되지 않는다는 것이며, 데이터 관리에 영향을 미칩니다. 이에 관해 다음에 자세히 다룰 것입니다. 더 많은 정보를 원하시면 Databricks 문서를 참조해 주세요.\n\nDatabricks는 관리형 테이블과 외부 테이블 두 가지 유형의 테이블을 구분합니다. 관리형 테이블은 기본적으로 생성되며 Unity Catalog에 의해 관리되며 수명주기 및 파일 레이아웃을 제어합니다. 외부 도구를 사용하여 이러한 테이블에서 파일을 직접 조작하는 것은 권장되지 않습니다. 이에 반해, 외부 테이블은 메타스토어, 카탈로그 또는 스키마에 지정된 관리형 저장 위치 외부에 데이터를 저장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서, 문서에서 제공한 지침을 기반으로, 이 접근 방식을 사용하여 OneLake에 직접 쓰여진 모든 테이블은 외부 테이블로 분류하는 것이 권장됩니다. 이는 데이터가 메타스토어의 범위 바깥에서 관리되기 때문입니다. 그 결과, 이러한 테이블의 관리는 Fabric 내부와 같은 다른 곳에서 수행해야 합니다. 이 방식의 동기는 다음과 같을 수 있습니다:\n\n첫째, OneLake에 데이터를 물리적으로 저장하는 것은 Microsoft Fabric 내에서 성능을 향상시킵니다. 이는 OneLake 테이블이 특히 조인 및 집계와 관련된 쿼리에 최적화되어 있기 때문입니다. 그에 반해, ADLS Gen2를 통해 바로가기를 통해 데이터를 읽는 경우, 이러한 작업을 포함하는 쿼리에 대해 성능이 느릴 수 있습니다.\n\n둘째, OneLake에서 데이터를 관리하는 것은 Microsoft Fabric 내에서 보안 조치를 적용하는 데 유용합니다. 예를 들어, OneLake 테이블은 역할 기반 액세스 제어 (RBAC)를 사용하여 보안할 수 있어 데이터 액세스를 관리하는 과정이 단순해집니다. 그러나 ADLS Gen2를 사용할 경우, ADLS Gen2 저장소 계정의 권한을 처리해야 하므로 더 복잡할 수 있습니다.\n\n셋째, OneLake 테이블은 정책에 따라 관리될 수 있어 데이터가 규정에 따라 사용되도록 보장하기가 더 쉽습니다. 예를 들어, 다른 곳에 있는 도메인과 테이블을 (외부적으로) 공유할 때입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터를 읽는 것 이외에도 Microsoft Fabric 내에서 새로운 데이터를 생성하는 것을 고려해 볼 수 있습니다. 만약 이것이 여러분의 계획 중 일부라면, 다가오는 기능이 매우 흥미로울 수 있습니다. 곧 Fabric 사용자들은 Unity 카탈로그를 통해 Azure Databricks에서 lakehouses와 같은 데이터 항목에 액세스할 수 있게 될 것입니다. 데이터는 여전히 OneLake에 남아 있겠지만, Azure Databricks에서 해당 데이터의 계보 및 다른 메타데이터에 직접 액세스하고 보는 능력을 갖게 될 것입니다. 이 향상된 기능은 Fabric에서 Databricks로 다시 데이터를 읽는 것을 용이하게 할 것입니다. 예를 들어, Azure Databricks의 Mosaic AI를 활용해 AI를 활용하려는 경우 Microsoft Fabric에서 다시 읽음으로써 가능할 것입니다. 이 기술은 아마도 Lakehouse Federation일 것입니다. 이 내용에 대한 자세한 정보는 이 비디오의 해당 부분에서 확인할 수 있습니다: https://youtu.be/BYob0cGW0Nk?t=4125\n\n마지막으로, 모든 통합 및 데이터 처리를 Databricks에서 처리하고 소비 레이어를 Fabric에서 관리하는 전략은 각 응용 프로그램 영역에서 가장 좋은 기능을 활용할 수 있도록 하는 편리함을 기관들에게 제공합니다. 이 접근 방식은 데이터 처리의 최적 성능과 보안을 보장합니다.\n\n## Databricks가 모든 데이터를 OneLake에 기록하도록 설정 (권장되지 않음)\n\nDatabricks를 OneLake와 통합하는 경험을 바탕으로, OneLake가 ADLS Gen2와 동일한 API를 지원한다는 것을 알고 있습니다. 이를 감안해 보면, 가상의 설계 가능성을 고려해 보겠습니다: 모든 Medallion 레이어를 OneLake에 저장하는 것입니다. 이 가능할까요? 알아보도록 하죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 접근 방식에 대한 인센티브는 신규 배포로부터 비롯될 수 있습니다. 여기서의 목표는 데이터 엔지니어링 작업을 효율적으로 확장하면서 Microsoft Fabric을 사용하여 모든 계층에서 데이터 사용 및 소비에 대한 설계 간결성과 셀프 서비스를 장려하는 데 Databricks의 기본 기능을 활용하는 것입니다.\n\n유감스럽게도, 이 설계는 효율적인 데이터 관리에 적합하지 않습니다. 이 구성은 각 워크스페이스 계층이 Microsoft Fabric의 자체 Lakehouse 엔터티를 필요로 하기 때문에 작업공간이 증가함에 따른 관리 오버헤드로 이어질 수 있습니다. 이 증식은 데이터 공유 시 통제, 메타데이터 관리 및 협업 오버헤드와 같은 추가적인 도전 과제를 야기할 수 있습니다. 또한 Databricks는 관리형 테이블을 사용할 때 이 접근 방식을 지원하지 않습니다. 따라서, 비록 이 아키텍처가 이론적으로 매력적으로 보일 수 있지만, 저는 최선의 실천으로 이를 사용하는 것을 강력히 비추합니다.\n\n## V-ORDERED 활성화 소비 계층으로 Databricks 확장\n\n다음 설계 고려사항은 Microsoft Fabric의 사용과 V-Order 기능을 활용하는 데 더 중점을 둘 것입니다. 이 기능은 파케이 파일 형식에 대한 라이트 타임 최적화로, Microsoft Fabric 컴퓨팅 엔진(예: Power BI)에서 빠른 데이터 읽기를 가능케 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDatabricks와 Microsoft은 오픈 소스 열 기반 파일 형식인 Delta Lake를 채택하기로 선택했습니다. 그러나 Microsoft은 V-Order 압축의 추가 레이어를 통합했는데, 이것은 최대 50%의 더 많은 압축을 제공합니다. V-Order는 오픈 소스 parquet 형식과 완전히 호환되며, 모든 parquet 엔진이 일반 parquet 파일처럼 읽을 수 있습니다.\n\n참고로 V-Order를 적용하여 Fabric의 유지 관리 기능을 활용하면 V-Order가 없는 테이블에 적용할 수 있습니다.\n\nV-Order는 Microsoft Fabric에 중요한 이점을 제공하는데, 특히 Power BI 및 SQL 엔드포인트와 같은 구성 요소에게 도움이 됩니다. 예를 들어, Power BI를 사용하여 데이터 쿼리 중에 뛰어난 성능을 유지하면서 실시간 데이터에 직접 연결할 수 있습니다. 데이터 소스의 변경 사항이 Power BI에 즉시 반영되므로 새로 고침을 기다릴 필요가 없어집니다.\n\nV-Order로 최적화된 테이블을 사용하는 것은 현재 Microsoft Fabric에게만 제한되어 있습니다. Databricks는 아직이 기능을 통합하지 않았습니다. 따라서 그런 경우에는 V-Order로 최적화된 테이블을 활용하기 위해 Microsoft Fabric 내의 서비스를 활용해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 실버(Silver)와 골드(Gold) 단계 사이의 Databricks를 통한 처리 단계가 V-Order 최적화가 필요하지 않을 경우에도 여전히 중요하다는 주장이 가능하다는 점을 감안해 볼 수 있습니다. 이 부분은 반복적으로 보일 수 있지만, Databricks를 이용한 지속적인 데이터 처리를 가능하게 하는 타당한 선택지입니다.\n\n다른 주목할만한 측면은 왜 조직이 이 설계를 선택하는지에 대한 것이며, 이는 여러 테이블 간의 거래 일관성을 유지하는 것입니다. 특히, 이러한 일관성을 Gold에서 유지하는 것은 매우 중요합니다. 현재 Spark는 개별 테이블에 대한 트랜잭션만 지원합니다. 따라서, 테이블 간에 데이터 불일치가 있는 경우 보상 조치를 통해 해결해야 할 수 있습니다. 예를 들어, 구매 주문에 대한 세 가지 테이블에 영향을 미치는 변경 사항을 하는 경우, 이러한 변경 사항을 하나의 트랜잭션으로 묶을 수 있습니다. 이것은 해당 테이블을 쿼리할 때 모든 변경 사항이 있거나 전혀 없을 것임을 의미합니다. 이러한 무결성 문제는 다수의 테이블에 걸쳐 복잡한 트랜잭션을 관리할 수 있는 환경의 중요성을 강조하며, Delta Lake 위에서 이를 지원할 수 있는 유일한 플랫폼은 Microsoft Fabric Warehouse입니다. 자세한 내용은 여기에서 확인할 수 있습니다.\n\n위 이미지에서 나타난 업데이트된 아키텍처에서는 Synapse Engineering이 이제 실버(Silver)에서 골드(Gold)로의 처리 엔진으로 작동합니다. 이 접근 방식은 모든 테이블이 V-Order 최적화되도록 보장합니다. 추가로, 트랜잭션 기능이 필요한 사용 사례를 위해 Synapse Warehouse가 추가되었습니다. 그러나 이러한 아키텍처 변경 사항은 데이터 엔지니어가 서로 다른 독특한 데이터 처리 서비스를 탐색해야 한다는 의미입니다. 따라서 모든 팀에게 명확한 지침을 제공하는 것이 중요합니다. 예를 들어, Databricks의 기본 기능인 AutoLoader와 Delta Live Tables를 활용한 데이터 품질 검증을 위해 브론즈(Bronze) 및 실버(Silver)에 대한 원칙을 수립하고, 골드(Gold)에서는 Microsoft Fabric와만 연동되는 소비특화 통합 로직 구축에 초점을 맞출 수 있습니다.\n\n## 추가 구성 요소를 추가하여 Databricks 및 Microsoft Fabric의 데이터 처리 효율성 향상하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리 이전 토론에서는 엔지니어들이 다른 데이터 처리 서비스를 탐험해야 하는 과제에 대해 논의했습니다. 이 문제는 메타데이터 주도 접근법과 DBT와 같은 템플릿 프레임워크를 채택하여 해결할 수 있습니다. 새로운 아키텍처에서는 Databricks와 Microsoft Fabric에 추가 구성 요소를 결합했습니다. 이 변경 사항에 대해 자세히 알아보도록 하겠습니다.\n\nDatabricks 측면에서는 메타데이터 주도 프레임워크(메타데이터 저장소), Great Expectations 및 Data Build Tool (DBT)를 추가했습니다. 메타데이터 주도 프레임워크는 작성하고 유지해야 하는 코드 양을 크게 줄일 수 있습니다. 다중 노트북을 생성하는 대신 이 접근 방식을 통해 모든 데이터의 수집 및 유효성 검사를 위한 범용 파이프라인을 활용할 수 있으며 Great Expectations라는 다른 오픈 소스 프레임워크로 데이터를 수집하고 유효성 검사할 수 있습니다. 이 접근 방식은 메타데이터 저장소에서 읽어와 다른 스크립트를 동적으로 호출함으로써 달성됩니다. 이 접근 방식에 대해 더 알고 싶다면 이 주제에 대한 또 다른 블로그 글을 추천합니다.\n\n다음으로 DBT에 대해 이야기해 봅시다. 이 오픈 소스 명령줄 도구인 데이터 빌드 툴(DBT)은 Python으로 작성되었습니다. 그 강점은 SQL의 SELECT 문과 유사한 구문을 사용하여 템플릿을 활용해 변환을 정의하는 범용 인터페이스를 제공하는 데 있습니다. Databricks는 dbt-databricks 패키지를 통해 지원됩니다. DBT와 Databricks를 사용하는 데 대한 자세한 정보를 원한다면 이 주제에 대한 다른 블로그 글을 읽는 것을 권장합니다.\n\nMicrosoft Fabric 측면에서도 DBT가 중요한 역할을 할 수 있습니다. Microsoft Fabric 내에서 Synapse Warehousing을 위해 dbt-fabric 또는 Synapse Spark을 위해 dbt-fabricspark 중에서 선택할 수 있습니다. 이 템플릿 접근 방식의 장점은 개발자가 모든 데이터 변환 사용 사례를 위한 단일 프론트엔드에 익숙해지기만 하면 두 서비스를 모두 활용할 수 있다는 점입니다. 이 방법론은 프로세스를 간소화하고 효율성을 높일 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 결론\n\nAzure Databricks와 Microsoft Fabric의 통합은 조직에 수많은 혜택과 가능성을 제공합니다. Azure Databricks의 유연성과 확장성이 Microsoft Fabric의 간편하고 사용자 친화적인 기능과 결합되면 모든 계층에서 데이터 사용 및 관리를 혁신적으로 개선할 수 있습니다. Databricks 중심 아키텍처를 Microsoft Fabric 레이어로 향상시키거나 성능 및 보안을 향상시키기 위해 아키텍처에 OneLake 골드 레이어를 통합하기까지 여러 아키텍처 디자인 선택지가 있습니다.\n\n또한, Microsoft Fabric의 V-Order 최적화 소개와 추가 구성 요소 사용은 데이터 처리 효율성을 현격히 향상시키고 간소화할 수 있습니다. 그러나 이러한 조합 또는 통합은 서비스 탐색과 유연성, 데이터 보안 및 격리를 균형있게 고려해야 할 수도 있습니다.\n\n요약하자면, Azure Databricks와 Microsoft Fabric의 통합은 Microsoft Build 2024 Conference에서 발표된 흥미로운 혁신과 함께 빅 데이터 처리 워크로드를 위한 희망찬 미래를 암시합니다.\n","ogImage":{"url":"/assets/img/2024-06-19-IntegratingAzureDatabricksandMicrosoftFabric_0.png"},"coverImage":"/assets/img/2024-06-19-IntegratingAzureDatabricksandMicrosoftFabric_0.png","tag":["Tech"],"readingTime":15}],"page":"36","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"36"},"buildId":"T_Nz0g9U1yttYMSEma95P","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>