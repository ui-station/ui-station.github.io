<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/102" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/102" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/wOkGEDZCvEs3S_XaNsdwr/_buildManifest.js" defer=""></script><script src="/_next/static/wOkGEDZCvEs3S_XaNsdwr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정" href="/post/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="메이테이어 언어의 기계 번역 앱 및 웹 페이지" href="/post/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="메이테이어 언어의 기계 번역 앱 및 웹 페이지" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="메이테이어 언어의 기계 번역 앱 및 웹 페이지" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">메이테이어 언어의 기계 번역 앱 및 웹 페이지</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요" href="/post/2024-05-18-DataEngineeringisforEngineersNOT"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">30<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" href="/post/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">38<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" href="/post/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" href="/post/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">25<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들" href="/post/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ML, 데이터 팀을 위한 Gen AI" href="/post/2024-05-18-MLGenAIfordatateams"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ML, 데이터 팀을 위한 Gen AI" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MLGenAIfordatateams_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ML, 데이터 팀을 위한 Gen AI" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ML, 데이터 팀을 위한 Gen AI</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 웨어하우징을 위한 5가지 사이버보안 팁" href="/post/2024-05-18-5CybersecurityTipsforDataWarehousing"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 웨어하우징을 위한 5가지 사이버보안 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 웨어하우징을 위한 5가지 사이버보안 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터 웨어하우징을 위한 5가지 사이버보안 팁</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Delta 테이블을 REST API를 통해 노출하는 방법" href="/post/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Delta 테이블을 REST API를 통해 노출하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Delta 테이블을 REST API를 통해 노출하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Delta 테이블을 REST API를 통해 노출하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/101">101</a><a class="link posts_-active__YVJEi" href="/posts/102">102</a><a class="link" href="/posts/103">103</a><a class="link" href="/posts/104">104</a><a class="link" href="/posts/105">105</a><a class="link" href="/posts/106">106</a><a class="link" href="/posts/107">107</a><a class="link" href="/posts/108">108</a><a class="link" href="/posts/109">109</a><a class="link" href="/posts/110">110</a><a class="link" href="/posts/111">111</a><a class="link" href="/posts/112">112</a><a class="link" href="/posts/113">113</a><a class="link" href="/posts/114">114</a><a class="link" href="/posts/115">115</a><a class="link" href="/posts/116">116</a><a class="link" href="/posts/117">117</a><a class="link" href="/posts/118">118</a><a class="link" href="/posts/119">119</a></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정","description":"","date":"2024-05-18 18:30","slug":"2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney","content":"\n기술 분야에서 인턴십은 청년들을 전문가 생활로 이끄는 발판입니다. 그러나 대부분의 인턴들은 기초 프로젝트에 갇혀 실제 세계에서의 경험을 놓치곤 합니다. 이 추세와는 달리, MRS Technologies는 작년에 다른 길을 선택하여 2022년도 인턴십 프로그램을 통해 풍부한 학습 기회를 제공했습니다. 인턴들은 실무 경험을 쌓고 최소 실현 가능 제품(MVP)을 선정하는데 주도적 역할을 하였습니다. 이 접근 방식은 커뮤니티로부터 높은 칭찬을 받았습니다. 이 경험은 졸업 전에 취직 기회를 얻는 데 도움이 되었으며, 프로그램의 깊은 영향력을 보여주었습니다.\n\n올해 관심이 폭발적으로 증가하여 13,500여 건의 열정적인 지원서가 접수되었습니다. 프로그램의 본질은 훈련을 집중적인 여섯 주 동안으로 압축하여 더 크고 열정적인 15명의 인턴 팀을 구성하여 슈퍼 차지하였습니다. 목표는 명확했습니다: 이 짧은 기간 안에 견고한 최소 실현 가능 제품(MVP)을 만들어 손쉬운 학습과 팀워크에서 새로운 기준을 세우는 것입니다.\n\nMRS Technologies의 CTO로써, 이 인턴십 프로그램은 나에게 특별한 자리를 차지하고 있습니다. 내 마음을 다하여 내일의 리더를 가꾸기 위해 최선을 다하며 성장시키고 있습니다. 이 블로그는 올해 프로그램의 주요 하이라이트를 통해 이 프로그램의 강한 실전 학습에 중점을 둔 세계 최고의 인턴십 프로그램 중 하나로 손꼽히는 이유를 보여줄 것입니다.\n\n# 1) 2023년 인턴십 프로그램의 비젼 - 기업가 정신을 일으키다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMRS 인턴십 프로그램의 핵심은 현실적인 기업가 정신의 본질에 직접 뛰어 들 수 있는 스타트업 분위기를 재현하는 데 있습니다. 보통의 인턴십과는 달리, 이 여정은 24시간 7일간의 과제, 학습 및 성장의 혼합으로 변모하여 매일이 도전, 학습 및 성장의 철저한 경험으로 됩니다. 아이디어를 최소 실행 가능 제품(MVP)으로 구현하기 위해 필요한 노력을 직접 체험하면서, 시계 소리에 성공적인 기업가의 세계의 무몰개한 속도가 반영됩니다. 이 프로그램은 모든 인턴이 기업가처럼 생각하고 행동하게 만드는 것을 목표로 하며, 성공은 노력과 지혜로 와야 한다는 것을 교훈으로 받아들이는 것이 중요합니다.\n\n# 2) 압도적인 반응 - 13,500건 이상 지원서 중 선정:\n\n2023년 MRS 인턴십 프로그램 발표는 학생들 사회에서 깊은 울림을 주었으며, 저희가 받은 13,500건 이상의 지원서 수를 반영했습니다. 이러한 관심의 파도는 숫자뿐만 아니라, 다양한 학위 및 전문 분야에서 이어지는 지원자들로 확장되었습니다. 이 섹션에 포함된 자세한 그래프는 이 분포를 생동감 있게 묘사하며, 이 프로그램의 광범위한 영향력과 매력을 강조합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 3) 선발 기준 및 최종 선발 과정:\n\n선발 단계는 강력한 MVP를 만들기에 적합한 후보자를 찾기 위해 30일에 걸친 철저한 과정이었습니다. 핵심은 기초 개념을 잘 이해하고 있으며, 열정적이고 협력을 할 의지가 있는 개인을 선발하는 데 집중했습니다. 애플리케이션 카테고리는 다양했으며, Frontend부터 Cloud 개발, UI/UX 디자인, 모바일 애플리케이션 개발, 프로젝트 관리, 임베디드 개발 및 기술 문서 작성 스킬을 포함했습니다.\n\n선발을 위한 기준은 엄격했지만 공정했으며, 의사 소통 능력, 태도, 이전 기술 경험, 성격 및 수행한 프리랜서 또는 자원 봉사 활동을 평가했습니다. 약 150명의 초기 후보자들로부터, 최종 인턴 15명으로 결린 최종 코호트는 각자가 독특한 가치를 지닌 인재로, 실용적인 학습, 혁신 및 팀워크 여정에 돌입할 준비가 되어 있었습니다.\n\n이 신중한 과정은 광범위한 지원자 풀에서 가장 유망한 후보자들을 선발하도록 도왔으며, 프로그램의 학습과 성과를 위한 높은 기준을 보장했습니다. 이 철저하고 필수적인 선발 과정은 MRS 인턴십 프로그램 2023의 고수준의 학습과 성과 유지에 대한 우리의 결연한 헌신을 강조합니다. 이 엄격한 선발은 각 참가자의 미래 전문가 활동을 통해 울림이 남을 것으로 믿는 흥미진진하고 풍부하며 생산적인 여정을 준비했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 3) 인턴십 프로그램의 톤 설정하기 - 첫째 날:\n\n어떠한 학생에게도 인턴십의 첫 날은 중요합니다. 기존의 지루한 경험에 실망했던 많은 사람들을 고려하여, MRS Technologies에서는 기대치를 첫단추부터 달리기 위해 노력하고 있습니다.\n\n![인턴십 이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_1.png)\n\n우리의 여정은 첫날의 조직적인 온보딩으로 시작되었는데, 각 인턴은 계정을 설정하고 업무 영역에 소개되었습니다. 그 후로는 우리 회사의 혁신적인 정신의 상징이 되는 혁신적인 프로젝트들을 엿볼 수 있는 층별 회사 투어가 인사팀이 이끄는 확장된 형태로 이어졌습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n투어를 따라 멘토와 함께하는 세션으로 에너지가 높아졌어요. 각 멘토가 자신을 소개하고 경험을 공유하며, 인턴들이 일상 업무와 프로젝트 목표를 이끌어나가는 데 중요한 역할을 강조했어요. 이 대화로 인턴들 사이에 기대감이 생기며, 존경과 협력의 초기 유대감이 형성되었어요.\n\n![이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_2.png)\n\n이 세션은 만남뿐만 아니라 성장을 격려하고 협력적인 환경을 약속하는 것이었어요. 이 멘토십 프레임워크를 통해 MRS Technologies는 배우고 전문가로 성장하는 푸른 토양으로 빛이 났어요.\n\n그날의 하이라이트는 제가 진행한 마음을 나누는 세션이었어요. 저는 전문 경력, 프로그램의 본질과 기대치, 그리고 이 특별한 경험으로부터 최대 이득을 얻는 데 대한 몇 가지 지혜를 공유했어요. 이 프로그램을 통해 자신의 경력을 형성하는 데 전례없는 기회임을 강조하며, 전문적인 가르침을 제공했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하루가 마무리되었습니다. 영감을 주는 일이 있었죠. 이제는 명확한 비전과 증진된 목적 의식으로 조정된 사고를 갖고, 변화의 여정에 도전할 준비가 돼 있습니다.\n\n### 4) 집중 교육 및 멘토십:\n\nMRS 인턴십 프로그램은 지식을 제공하고 호기심을 자극하며 지속적인 학습을 장려하기 위해 설계된 철저한 훈련 단계로, 기술과 소프트 스킬에 능숙한 다재다능한 인물을 육성하는 것을 목표로 했습니다. 제가 이끈 다양한 워크샵에 참여하여, 주제는 전통적인 범위를 넘어 시스템 디자인부터 효과적인 팀 협업, 초점, 명상, 정신건강의 중요성을 이해하는 등 다양한 주제를 포괄했습니다. 회사 전문가들이 워크샵을 이끌며 프로그램 전체 조직의 다양한 참여를 보장하였으며, 이는 우리 인턴들에게 학습 경험을 증폭시켰습니다.\n\n교육 모듈은 인턴에게 종합적인 기술 세트를 갖게끔 설계된 기술 및 비기술적 워크샵을 조심스럽게 조합한 것이었습니다. 몇 가지 주목할 만한 사례는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 브랜드 및 Figma 소개\n- 인간 심리학과 사용자 경험\n- WebFlow에서 웹사이트 구축\n- 스타트업, 타당성 분석, 비즈니스 모델 및 MVP\n- 클라우드 컴퓨팅, AWS 및 AWS Amplify 소개\n- 단위 테스팅(자동화된 테스트) 소개\n- 정신 건강 및 감정 지능\n- 재무 101 및 소득세 신고 방법\n- 이력서 작성\n- 효율적인 LinkedIn 활용\n- 임베디드 시스템 및 사물인터넷(IoT)에 대한 워크샵 시리즈\n- 프로젝트 관리 및 스크럼 프레임워크 등\n\n감정 지능 워크샵은 매우 호응이 좋았습니다. 우리 강사 라하트 자바이드는 수치스러운 문제인 수치심과 죄책감 유발을 다루면서 트리거와 침투적인 생각에 대해 명확히 알려주었습니다.\n\n창업 정신은 훈련의 중요한 측면이었으며, 스타트업 생태계를 이해하는 데 중점을 둔 여러 워크샵이 제공되었습니다. 이 세션에서는 타당성 분석, 아이디어 선택 및 비즈니스 모델 구축을 다루어 새로운 시각을 가질 수 있도록 견고한 기반을 제공했습니다. 기존의 틀을 벗어나 생각하도록 인턴들에게 기업가적 사고의 불꽃을 일으키고, 혁신을 상상하고 이끌도록 장려하는 것이 목적이었습니다.\n\n# 5) 임베디드 시스템과 사물인터넷(IoT) 교육:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저희 인턴십 프로그램에서는 내장 시스템과 사물 인터넷(IoT)에 대한 철저한 교육에 중점을 두고 있습니다. 이 특별한 교육은 저희 회사의 숙련된 강사들과 시니어 임베디드 팀 멤버들이 직접 진행하여, 풍부한 실습 경험을 제공합니다. 계획은 시장 관련 주제를 철저히 다루도록 구성되어 있어, 인턴들에게 인턴십 및 이후의 전문적인 노력을 위한 단단한 기반을 제공합니다.\n\n![Training Image 3](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_3.png)\n\n교육은 이론 이상으로 인턴들을 실제, 실습 경험으로 이끕니다. 이 교육의 핵심은 오늘날에 필수적인 클라우드와의 안전한 통신에 대해 배우는 것입니다. 이는 소프트웨어와 하드웨어를 결합한 흥미로운 프로젝트에 참여하는 데 도움이 되므로 중요합니다.\n\n![Training Image 4](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 철저한 교육을 통해 MRS에서 인턴은 견고한 최소 우선 제품(MVP)을 만들 준비가 되었으며, 앞으로의 경력을 위한 준비를 충분히 했습니다.\n\n# 6) 혁신 장려: 인턴들이 MVP 선택을 이끄는 중:\n\nMRS 인턴십 프로그램은 mGreens를 개발하는 중인 인턴이 식물 애호가들의 건강한 성장을 자동화하는 데 도움을 주는 MVP로 선도하는 동안 혁신적인 탐험의 길을 열었습니다.\n\n![이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n핵심 아이디어는 IoT 노드를 만들어 식물과 완벽하게 통합되며 주변 온도, 토양 온도, 습도, 그리고 토양 수분과 같은 다양한 요인을 세심하게 모니터링할 수 있는 것이었습니다. 이 지능형 노드는 각 식물에 맞는 최적 조건에서의 이탈을 감지하고, 사용자에게 즉각적으로 물 주기 또는 선풍기 가동과 같은 교정 조치를 취하도록 경고하는 방식으로 설계되었습니다. 따라서 이 플랫폼은 식물 목록을 표시하여 사용자가 건강하거나 관리가 필요한 식물을 구분해 줄 수 있었습니다.\n\n![Image](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_6.png)\n\n개발 단계에 착수하며 소프트웨어 및 하드웨어 팀은 자발적으로 협력하여 mGreens 비전을 실현했습니다. 짧은 기간 내에 프로젝트를 완료하기 위해 팀이 밤낮 없이 협업하는 모습을 보았습니다. 임베디드 팀은 ESP32와 여러 센서를 사용하여 IoT 노드를 개발하고, 내구성과 설치 편의를 위해 사용자 정의 3D 프린팅 케이스에 수납했습니다. 이 하드웨어 스위트는 원하는 임계 값에서 벗어날 때 실시간 경고를 보내도록 설계되었습니다. 이는 AWS 클라우드 서비스를 사용한 백엔드 시스템을 통해 이루어졌습니다.\n\nUI/UX 팀은 브랜딩을 담당하며 Figma를 사용해 시각적으로 매력적인 인터페이스를 만들었고, 기술 팀은 백엔드로 AWS, 웹앱 개발로 React, 데스크톱 기반의 관리 포털로 QT를 활용했습니다. 또한 Android 모바일 앱과 WebFlow 마케팅 웹사이트를 개발했는데, 이는 프로그램 중에 UI/UX 팀이 4주도 안 되어서 개발한 것입니다. 소프트웨어에는 주요 식물에 대한 최적 값이 포함된 데이터베이스도 포함되어 있어 사용자들이 농작물을 모니터할 수 있는 기반을 제공하며, 숙련된 사용자들은 고유한 요구사항에 따라 임계 값을 수정할 수 있는 유연성도 가지고 있었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기 우리 인턴들이 만든 멋진 사진 몇 장이 있어요.\n\n![Image 7](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_7.png)\n\n![Image 8](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_8.png)\n\n![Image 9](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_9.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 1](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_10.png)\n\n![Image 2](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_11.png)\n\n![Image 3](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_12.png)\n\n# 7) Retrospective Meeting with Interns and Mentors\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMRS 인턴십 프로그램의 결론은 모든 인턴과 멘토가 참석한 회고 회의로 마무리되었습니다. 각 인턴은 지난 몇 주 동안의 여정을 5분간의 내러티브로 소개하며 자신의 경험을 나누었습니다. 그들의 말은 학습, 우정, 지식 향상을 위한 지속적 노력이 담긴 여정을 보여주었습니다.\n\n인턴들 다음으로 각 멘토는 자신의 인사이트와 경험을 공유했습니다. 그들은 인턴의 진전과 함께 극복한 독특한 어려움을 주목했습니다. 방안은 감사함과 공유된 성취감으로 넘쳤으며 회의실 안의 모두에게 울려퍼졌습니다.\n\n마지막으로 CTO로서, 저는 그들의 여정에 대한 생각과 앞으로의 방향성을 나눴습니다. 인턴들이 이 소중한 경험을 마지막 학년과 전문가 생활로 나아가면서 어떻게 활용할 수 있는지에 대해 논의했습니다. 이 대화는 인턴들을 위한 도로를 제공하고, 얻은 지식과 기술이 실제 세계에서 어떻게 활용될 수 있는지 상상하도록 도왔습니다. 이는 희망, 야망, 그리고 기술 세계에서 의미 있는 흔적을 남기고자 하는 공동의 꿈으로 가득한 따뜻한 세션이었습니다. 순간의 감정적 깊이가 느껴지며, 성장, 팀워크, 혁신의 여정을 완벽하게 마무리하는 모습을 보여주었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_14.png)\n\n# 8) 업적을 기념하며: 최종 발표 및 폐회식\n\nMRS 인턴십 프로그램의 여정은 최종 발표 및 폐회식을 통해 업적을 축하하며 화려하게 마무리되었습니다. 이 자리에는 모든 멘토, 워크샵 강사, 인턴들, 그리고 MRS Technologies와 MTronic Pakistan의 C급 리더십이 참석했습니다.\n\n참석자들로 붐볐던 이번 세션은 각 인턴이 진지한 발표로 시작하여 프로젝트에서의 역할, MVP에 기여한 부분, 프로그램 중의 개인적 경험, 그리고 좋아했던 워크샵과 멘토에 관해 따뜻한 이야기를 나누었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n열정적인 노력과 혁신의 결과물을 보여주며 MVP의 자세한 데모가 발표되면서 분위기는 흥분으로 넘쳤어요. 인턴들이 참여자들을 놀라게 한 mGreens에 대한 매력적인 데모 비디오를 선보여 방 안에 기쁨과 자부심이 가득했던 특별한 순간이 있었어요.\n\n이어서 MRS Technologies의 CEO 인 Dr. Mansoor Shaukat과 MTronic Pakistan의 최고 경영 책임자인 와카스 칼릴이 프로그램에 대한 경탄과 감사의 뜻을 나누었어요. 와카스 칼릴은 연설 중 다수의 창업 기업과의 폭넓은 경험에도 불구하고 이처럼 철저하고 영향력 있는 프로그램을 다른 어디서도 경험하지 못했다고 말씀했어요.\n\n이후에는 CxOs가 인턴들에게 인턴십 완수 증명서, 멘토에게 인정 증명서, 워크숍 강사에게 감사 증명서를 수여했어요. 이 행동은 이 풍부한 여정에 참여한 개인 각각의 끈기와 우수한 노력을 인정하고 귀추를 상징합니다.\n\n이식은 Abdullah Umer에게 특별한 \"리더십상\"을 수여하며 절묘한 리더십과 프로그램 전체를 통틀어 뛰어난 성과를 인정받았어요. 이상의 시상은 인턴십 프로그램 동안 여러 명의 개인이 모니터링한 KPI를 기반으로 수여되었어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_15.png](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_15.png)\n\n하루를 단축하며 그룹 사진을 찍고 사소한 대화를 나누는 동안 감정, 동료애, 그리고 성취감을 나누며 방 안은 들뜬 분위기로 넘쳤습니다. 미소, 웃음소리, 그리고 작별 인사가 MRS 인턴십 프로그램 2023을 통해 각 참가자가 걸어온 보상적이고 변화적인 여정의 본질을 담아냈습니다.\n\n# 선발되지 않은 동료들은 어떨까요?\n\n선발되지 않은 분들을 위해 그들에게는 단순한 신청 상태 통지 이상을 제공했습니다. 앞날을 안내하기 위해 상세한 이메일을 작성했습니다. 프로그램에 합격하지 못했더라도, 이 이메일은 LinkedIn 네트워킹, 블로깅과 콘텐츠 제작, 개인 브랜딩과 같은 중요 영역에 초점을 맞추는 데 도움이 되었습니다. 이를 통해 역경을 겪더라도, 그들이 전문 경력을 이어 나갈 명확한 방향을 가지도록 돕는 것이 목표였습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n2023년 MRS 인턴십은 혁신적인 기술 시야의 실제 측면으로의 환상적인 여정으로 나타났습니다. 신입사원들을 기술 산업에 대비하는 좋은 모범 사례를 세우면서 훌륭한 예를 보여주었습니다. 이제 경험을 쌓은 각 인턴은 스타트업 문화 속에서 매끄럽게 녹아들며 도전을 극복하고 해결책을 찾아가며 전문적인 우정을 통해 성장했습니다. 모든 문제 해결, 모든 불일치 해소, 그리고 모든 프로젝트 완료는 전통적인 수업이 제공할 수 있는 것 이상으로 기술 세계에 대한 이해를 쌓게 해주었습니다.\n\n우리의 접근 방식은 다르다 - 우리는 기본적인 작업을 할당하는 전형적인 방식에서 벗어났습니다. 대신, 우리는 인턴을 의미 있는 프로젝트의 핵심으로 밀어넣어 현실적인 도전과 해결책을 이해하도록 돕았습니다. 실제 프로젝트를 통한 실무 경험은 단지 전문계에 발을 딛기 전에 체크할 상자일 뿐인 것보다 풍부한 경험으로 만들어 주었습니다.\n\n인턴들이 배우기 위해 노력하는 것이 아니라 뛰어나기 위해 보이는 열정과 결단력, 멘토들의 지식을 공유하기 위한 헌신, 그리고 결과적으로 나타난 혁신적인 프로젝트들이 모두 2023년 MRS 인턴십 프로그램의 성공에 대해 많은 이야기를 전합니다. 올해의 프로그램을 마무리하면서 다음 집단이 어떤 성과를 이룰지에 대한 기대가 쌓이기 시작합니다. 업데이트를 위해 MRS 여름 인턴십 페이지를 주시해 주시길 바랍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n더 많은 정보를 원하거나 가이던스가 필요하다면, LinkedIn에서 저와 연락해주세요. 모든 지망 기술 전문가들을 위해 더 많은 학습, 혁신, 그리고 밝은 미래가 되길 바라겠습니다!\n\n![image](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_16.png)\n","ogImage":{"url":"/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_0.png"},"coverImage":"/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_0.png","tag":["Tech"],"readingTime":15},{"title":"메이테이어 언어의 기계 번역 앱 및 웹 페이지","description":"","date":"2024-05-18 18:28","slug":"2024-05-18-MachinetranslationappsandwebsofMeiteilanguage","content":"\n![2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png)\n\n메이테이어, 또는 매니푸리어로도 알려진 메이테이어 언어는 매니푸르 주, 아사름 주의 공용어일 뿐만 아니라 인도 공화국의 헌법적 언어이기도 하며, 트리푸라 주의 문학적, 학술적인 공용어로 인정받고 있습니다. 이 언어는 다양한 기계 번역 앱과 웹에서 지원되지만, 어떤 것이 가장 정확한지 선택하는 것은 쉬운 일이 아닙니다. 흠... 소소한 조사를 해 봅시다!\n\n한 가지 유의할 점은 메이테이어가 매니푸리어, 미티, 미테이, 메이테일론, 미티론, 칸글레이 등 다양한 이름으로 알려져 있다는 것입니다. 따라서 서로 다른 앱과 웹사이트에서는 이러한 인기 있는 동의어 중 하나가 사용될 수 있습니다. 그러니 한 가지 이름을 입력했는데 찾을 수 없다면, 잠시 다시 확인해 보세요! 그렇게 어려운 일은 아닙니다!\n\n여기서는 실험을 목적으로 \"매니푸르는 멋진 곳입니다.\"라는 문장을 사용합니다. 이 문장이 모든 앱과 웹에서 번역에 사용될 것입니다. 일부는 메이테이 메이에크 문자 (mni-Mtei), 또는 벵골 문자 (mni-Beng), 또는 라틴 문자 (mni-Latn)을 사용합니다. 여기서 \"mni\"은 \"매니푸리어\"를 나타내고 다른 코드 단어는 각각의 문자체계를 참조합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 구글 번역 ???\n\n![이미지](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_1.png)\n\n구글 번역은 메이테이어 언어에 메이테이 마예크 문자체계를 사용합니다. 고급 용어에 대한 단어의 경우 구글 번역은 주로 번역하는 대신 음역합니다. 위 이미지에서 구글은 \"마니푸르는 멋진 장소입니다\"를 \"ꯃꯅꯤꯄꯨꯔ ꯑꯁꯤ ꯑꯉꯀꯄꯥ ꯃꯐꯝ ꯑꯃꯅꯤ꯫\" (manipur asi angakapa mapham amani)로 번역하고 있습니다. 여기서 맞춤법 오류가 발견되며, 이는 해당 언어에서 더 많은 경우에 자주 발생합니다. 그러나 문장 구조 표현 방법은 중간 수준입니다.\n\n평가한다면 5점 중 3.5점을 받을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Microsoft Translator 리뷰\n\n![마이크로소프트 트랜스레이터](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_2.png)\n\n마이크로소프트 트랜스레이터는 영어에서 매니푸리어로 번역할 때 나란히 메테이 마예크 문자와 라틴 문자를 사용하지만 매니푸리어에서 영어로 번역할 때는 라틴 문자를 사용할 수 없습니다. 다양한 어휘 사용에서 우수한 성능을 발휘합니다. 맞춤법 오류가 거의 없는 것으로 나타납니다. \"Manipur is a wonderful place\"이 \"ꯃꯅꯤꯄꯨꯔ ꯑꯁꯤ ꯌꯥꯝꯅ ꯐꯖꯕ ꯃꯐꯝ ꯑꯃꯅꯤ꯫\" (manipur asi yaamna phajaba mapham amani.)로 번역됩니다. 정확성은 완벽하진 않지만 여전히 꽤 양호합니다.\n\n평가하면 5점 만점에 4점을 줄 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## ???\n\n\u003cimg src=\"/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_3.png\" /\u003e\n\nBhashini은 인도 정부의 프로젝트로, 메이테이어 언어에는 Meetei Mayek 스크립트를 사용합니다. 이 알고리즘은 인도 정부와 협력하여 개발된 IIT 매드라스의 AI 기술 플랫폼인 AI4Bharat (인공 지능-인도를 위한)에서 사용됩니다. Bhashini는 메이테이어 언어에 대해 남성과 여성 음성 출력 기술을 모두 제공합니다. 일부 맞춤법 오류가 있습니다. 번역 정확도는 Microsoft Translator와 거의 동일하여 상당히 좋습니다.\n\n여기서 \"Manipuri is a wonderful place\"라는 문구를 \"ꯃꯅꯤꯄꯨꯔ ꯑꯁꯤ ꯐꯖꯔꯕ ꯃꯐꯝ ꯑꯃꯅꯤ ꯫\" (manipur asi phajaraba mapham amani.)로 번역합니다. 문구는 다른 번역 앱 및 웹과 달리 독특합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 평가해야 한다면 5점 만점에 4점을 줄 것입니다.\n\n## Glosbe 번역 ???\n\n![이미지](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_4.png)\n\nGlosbe 번역은 메이테이어 언어에 대해 벵골 문자를 사용합니다. 번역 정확도는 상당히 좋고 맞춤법 실수는 드물게 발생합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 \"Manipur is a wonderful place\"는 \"মনিপুর অসি য়াম্না ফবা মফম অমনি।\" (manipur asi yaamna phaba mapham amani.)로 번역됩니다. 완벽하지는 않지만 언어 어휘의 이해 수준에 맞게 사용됩니다.\n\n평가한다면, 5점 중 4점을 얻을 것입니다.\n\n## 현대기계번역 ???\n\n![이미지](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현대적인 MT는 메이테이어어를 번역할 때 벵골어 스크립트를 사용합니다. 2024년 중반 기준으로 번역 정확도는 상당히 낮지만 이전보다 크게 개선 중입니다. 맞춤법 실수는 단어 선택 오류에 비해 적습니다. 대부분의 문장 번역 결과는 정확도가 떨어지지만, 단어 번역에 대해서는 꽤 좋습니다.\n\n여기서 \"Manipur is a wonderful place\"는 \"মনিপুর অসি য়াম্না নুংঙাইবা মফম অমনি ।\" (manipur asi yaamna nungngaiba mapham amani.)로 번역됩니다. 관련된 단어가 사용되었지만, 이 간단한 짧은 문장에서도 완벽하게 번역되지는 못합니다.\n\n평가할 경우, 5점 중 2점을 받을 것입니다.\n\n## 그 외 ???\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 번역 서비스가 많이 있습니다. Bing AI의 Copilot, ELRA 카탈로그 등이 있어요.\n\nMeitei 언어로 Copilot of Bing AI는 매우 불규칙합니다. 때때로 벵골어 스크립트를 사용하고 때로는 Meitei 스크립트를 사용하며 때로는 라틴 스크립트를 사용하며 때로는 완전히 번역에 실패하기도 해요. Manipuri로 다음을 번역해 주세요: ... ... ... 와 같이 말하고 영어로 문장이나 단어를 입력해 주면 돼요. Manipuri에서 영어로 역변환은 2024년 중반 기준으로 작동하지 않는 것처럼 보여요.\n\n평가해야 한다면, 5점 만점에 2점을 줄 것입니다.\n\n이것은 Meitei 언어에 대해 가장 널리 사용되는 기계 번역 앱과 웹 중 일부에 대한 소개에 불과해요. 평가는 제 개인적인 의견이며 제 관찰에 기반하며 다른 사람들과 차이가 있을 수도 있어요. Meitei 언어의 언어 애호가, 학습자 및 학생들에게 이 작은 정보 조각이 어느 정도 도움이 되기를 바래요. 응원합니다! :-)\n","ogImage":{"url":"/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png"},"coverImage":"/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png","tag":["Tech"],"readingTime":6},{"title":"데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요","description":"","date":"2024-05-18 18:24","slug":"2024-05-18-DataEngineeringisforEngineersNOT","content":"\n## 글을 쓰는 사람이 데이터 엔지니어링도 배울 수 있을 거라고 생각해요.\n\n\"이게 무슨 일이죠.\"\n\n처음 데이터 엔지니어링 업무를 맡았을 때 나는 이렇게 생각했어요. 하지만 얼마 후, 우리가 하나씩 위키피디아에서 집어낼 몇 가지 숫자를 가져오는 것이 첫 번째 단계였다는 것을 깨달았죠.\n\n파이썬에서 작업을 해주셔야겠다고 말씀하셔야 했던 첫 번째 어려움이 있었어요! 즉, 데이터를 수동으로 가져오는 날이 끝났다는 거죠. 인내심을 가지고 자신에게 이런 말을 해보세요. 괜찮아, 이 일 잘 할 수 있어요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n문제: 사회과학 졸업생이 데이터 엔지니어링을 능숙하게 수행할 수 있을까요? 자동화된 데이터 파이프라인을 구축하고 안전하게 클라우드에 보관할 수 있을까요?\n\n귀무가설: 엔지니어는 생업으로 글을 쓰는 사람만큼 데이터 엔지니어링을 할 수 있습니다.\n\n이 가설을 기각해야 할까요? 내 직감은 \"예\"라고 말했습니다. IT 비전문가인 나 같은 사람이 그렇게 할 수는 없을 것 같아요.\n\n대안 가설은 아마도 이렇게 할 수 있을 것 같아요: 생업으로 글쓰는 사람도 엔지니어처럼 데이터 엔지니어링을 배울 수 있다면요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 시작해요...\n\n## 우리 비즈니스 케이스\n\n이 작업은 주로 전기 이동성에 관련된 사업을 하는 \"Gans\" 회사를 위한 데이터베이스를 생성하는 것을 포함하고 있습니다. 특정 시간에 충분한 이동성 단위를 제공하기 위해 날씨 요소를 기반으로 수요를 측정하기 위한 데이터 과학자를 필요로 합니다.\n\n회사의 주요 사업은 독일에서 스쿠터를 대여하는 것이기 때문에 비가 오거나 눈이 오는 경우에는 일반적으로 수요가 줄어들게 됩니다. 비나 눈이 예보된 경우, 임시 수요도 증가할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서, 현재 과제는 도시와 날씨 정보로 채워진 간단한 SQL 데이터베이스를 구축하는 것입니다. 회사의 운영 부서는 매일이 이 데이터베이스에 액세스하여 이동 가능 차량의 지리적 가용성에 관한 판단을 내릴 수 있을 것입니다.\n\n나중에 데이터베이스는 관광객 방문 예상 등을 제공하기 위해 공공 교통 도착 정보(예: 항공편, 기차, 또는 버스 API 사용)가 포함될 수 있습니다. 이들은 회사의 잠재적 고객 중 일부입니다.\n\n다음은 날씨와 항공편 API를 포함한 지도 프로젝트의 모습입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 날씨 데이터 통합만 다루고 나중에 전송 부분은 나중에 개선할 것입니다.\n\n시작하기 전에 Python에서 필요한 모든 라이브러리를 가져와야 합니다:\n\n```python\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nfrom pytz import timezone\n```\n\n## 웹 스크래핑 101: HTML 코드를 가져오는 방법?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저, 다른 테이블과 관련하는 주요 테이블로 작용하는 도시 정보가 포함된 테이블을 만들어야 합니다. 이 테이블은 주기적으로 업데이트할 필요가 없는 정적 테이블이 될 것입니다. 이 테이블을 \"cities_info\"라고 부를 것입니다.\n\n각 도시에 대해 고유한 도시 ID, 도시 이름, 독일의 소속 주(State), 위도 및 경도가 포함된 5개 열이 있을 것입니다. 각 도시에 대한 이 정보는 영어 위키피디아 사이트에서 스크래핑하여 얻을 수 있습니다. 예산이 허용한다면, 신뢰할 수 있는 데이터와 방법론적 정보가 포함된 도시의 API를 구매할 수 있습니다. 이 프로젝트에서는 위키피디아를 사용하여 스크래핑 기술을 연습할 것입니다.\n\n처음에는 각 웹사이트마다 HTML 코드를 수동으로 내보내고 Vs Code에 복사해야 한다는 생각이 압도적이었습니다. 그러나 다행히 파이썬의 \"requests\" 라이브러리를 사용하면 자동으로 수행할 수 있음을 알게 되어 안도했습니다:\n\n```js\nimport requests\nberlin_url = \"https://en.wikipedia.org/wiki/Berlin\"\nberlin_response = requests.get(berlin_url)\nberlin_soup = BeautifulSoup(berlin_response.content, 'html.parser')\nprint(berlin_soup.prettify)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬: 1 - 나: 0\n\n## 루프와 함수\n\n이터레이션의 성배입니다. 이들 없이는 동일한 코드를 재생산하고 다른 URL에 동시에 적용할 수 없습니다. 이것이 웹 스크레이핑을 자동화하는 열쇠입니다.\n\n여기에는 각 위키피디아 사이트의 HTML 코드를 검색하기 위해 사용한 루프의 예시가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncities_list = [\"Berlin\", \"Hamburg\", \"Munich\", \"Cologne\", \"Frankfurt\"]\n\nfor city in cities_list:\n  url = f\"https://www.wikipedia.org/wiki/{city}\"   # url을 f 문자열로 변환하여 도시를 변수로 넣어 해당 도시에서 다른 도시로 변경됨\n  response = requests.get(url)          # 위키백과 페이지의 모든 내용을 가져와 response에 저장\n  city_soup = BeautifulSoup(response.content, 'html.parser')\n```\n\n지금은 함수가 무서워서 최대한 피하고 있어요 😅\n\n파이썬: 1,000 — 나: 0\n\n## HTML에서 무엇을 접근하나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nHTML에서 \"p 태그\"라는 것이 있어요. 이를 액세스하는 데 유용합니다. 다음 코드를 사용하여 그렇게 할 수 있어요:\n\n```js\nprint(soup.p)   # 첫 번째 p 태그 자체에 접근\nprint(soup.p.string)  # 첫 번째 p 태그와 관련된 문자열에 접근\n```\n\n```js\nfor child in soup.div:  # 1번째 div에서 각 자식을 찾아서 인쇄하는 예제\n    print(child)\n```\n\n## Python에서 데이터프레임 및 SQL에서 해당 테이블 만들기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nHTML 및 웹 스크래핑 기술을 연마한 후, 첫 두 테이블에 필요한 모든 정보를 얻기 위해 이 루프를 만들었어요.\n\n첫 번째 데이터프레임은 정적 인덱스로 작동할 것이고 (즉, 정보를 정기적으로 업데이트할 필요가 없어요): cities_info\n\n```js\ncities_list = [\"베를린\", \"함부르크\", \"뮌헨\", \"쾰른\", \"프랑크푸르트\"]\nstates = []\nlatitudes = []\nlongitudes = []\n\nfor city in cities_list:\n  url = f\"https://www.wikipedia.org/wiki/{city}\"\n  city_soup = BeautifulSoup(response.content, 'html.parser')    # (위키백과 사이트의 내용을 city_soup 변수에 저장하는) 내용을 구문 분석합니다.\n\n  # 도시가 속한 주를 검색합니다\n  if city not in [\"함부르크\", \"베를린\"]:         # 베를린의 경우 일반적인 .find 공식도 작동할 거예요! 주 섹션이 없는 \"함부르크\"만이 예외에요\n    city_state = city_soup.find(\"table\", class_=\"vcard\").find(string=\"주\").find_next(\"td\").get_text()  # 다른 주 이름을 가진 도시에 대한 주를 검색합니다\n  else:\n    city_state = city     # 함부르크와 베를린의 경우, 동명의 도시 이름을 가져올 거예요\n  states.append(city_state)\n\n  # 각 도시의 위도를 검색하여 위도 열에 추가합니다\n  city_latitude = city_soup.find(class_=\"latitude\").get_text()\n  latitudes.append(city_latitude)\n\n   # 각 도시의 경도를 검색하여 경도 열에 추가합니다\n  city_longitude = city_soup.find(class_=\"longitude\").get_text()\n  longitudes.append(city_longitude)\n\ncities_info_non_rel = pd.DataFrame({         # 이것이 cities_info 데이터프레임이에요\n    \"도시 이름\": cities_list,\n    \"독일 주\": states,\n    \"위도\": latitudes,\n    \"경도\": longitudes\n})\n\ndisplay(cities_info_non_rel)    # 표시하면 테이블이 더 예쁘게 보여요\n```\n\n또한, 연간 한 번씩 업데이트될 것으로 예상되는 인구 데이터를 포함하는 두 번째 데이터프레임도 생성했어요: cities_population\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```sql\n/***************************\n환경 설정\n***************************/\n\n-- 데이터베이스가 이미 있는 경우 삭제\nDROP DATABASE IF EXISTS gans;\n\n-- 데이터베이스 생성\nCREATE DATABASE gans;\n\n-- 데이터베이스 사용\nUSE gans;\n\n\n/***************************\n첫 번째 테이블 생성\n***************************/\n\n-- 'cities_info' 테이블 생성\nCREATE TABLE cities_info (\n    cities_id INT AUTO_INCREMENT, -- 도시마다 자동으로 생성된 ID\n    city_name VARCHAR(255) NOT NULL, -- 도시 이름\n    german_state VARCHAR(255) NOT NULL, -- 주 이름\n    latitude VARCHAR(255) NOT NULL, -- 위도 좌표\n    longitude VARCHAR(255) NOT NULL, -- 경도 좌표\n    PRIMARY KEY (cities_id) -- 각 도시를 고유하게 식별하기 위한 기본 키\n    );\n\n\n/***************************\n두 번째 테이블 생성\n***************************/\n\nCREATE TABLE cities_population (\n    cities_id INT,\n    population INT, -- 인구수\n    year_data_retrieved INT, -- 인구 데이터를 검색한 해당 년도\n    FOREIGN KEY (cities_id) REFERENCES cities_info(cities_id)\n);\n```\n\n이제 Python에서 데이터를 첫 번째 SQL 테이블로 전송합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nschema = \"gans\"     # 데이터베이스 이름\nhost = \"xxx.x.x.x\"\nuser = \"root\"               # 사용자 이름\npassword = \"xxxx\"           # SQL 암호 직접 지정 또는 다른 노트북에서 가져오기 (\"from xxxfile import my_password\")\nport = 3306\n\nconnection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n# 이건 파이썬 노트북을 SQL Workbench에 연결하는 방법이에요\n```\n\n```js\ncities_info_non_rel.to_sql('cities_info',   # 파이썬에서 SQL로 데이터를 보내는 방법\n                  if_exists='append',       # 덮어쓰지 않고 기존 데이터에 추가하기 위함\n                  con=connection_string,    # SQL Workbench에 연결할 때 필요한 인자\n                  index=False)\n```\n\n첫 번째 시도는 로컬에서 이루어졌습니다. 나중에 Google Cloud Platform 인스턴스를 추가하면 \"host\" 필드를 편집하여 이 데이터를 클라우드에 직접 전송할 수 있습니다.\n\nSQL에 첫 번째 테이블이 생성되면 cities_info에 포함된 데이터를 검색하여 두 번째 cities_population 데이터 프레임에서 해당 cities_id 열을 인덱스로 사용할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncities_info = pd.read_sql(\"cities_info\", con=connection_string)   # 이 코드는 SQL에 저장된 정보를 \"읽어옵니다\"\ncities_info\n```\n\n다음은 cities_info의 모습입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_1.png\" /\u003e\n\n두 번째 데이터프레임의 내용을 SQL로 넣기 전에, 새로 생성된 cities_id 열을 사용하여 cities_populations 데이터프레임에 추가해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 칼럼 순서를 재조정하고, 이제 cities_populations 데이터프레임에 cities_id 칼럼이 있기 때문에 더 이상 city_name 칼럼이 필요하지 않으므로 삭제했습니다:\n\n```js\n# 다른 인구 데이터프레임에 cities_id 칼럼을 추가합니다\ncities_population[\"cities_id\"] = cities_info_non_rel[\"cities_id\"]\ncities_population\n\n# city_name 칼럼은 더 이상 필요하지 않기 때문에 삭제하고 칼럼 순서를 바꿔 더 직관적으로 만듭니다\ncities_population = cities_population[[\"cities_id\", \"population\", \"year_data_retrieved\"]]\ncities_population\n```\n\n그리고 제 두 번째 데이터프레임이 있습니다. 이 데이터프레임은 일부 동적입니다(데이터가 때때로 업데이트됩니다. 예: 연간 한 번):\n\n![데이터 엔지니어링은 엔지니어를 위한 것](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n당분간은, 다음 해까지 업데이트되지 않을 동적이 아닌 cities_population 테이블로 간주하겠습니다.\n\n이제 우리는 로컬 SQL 인스턴스로 내용을 푸시할 준비가 되었습니다:\n\n```js\n# 두 번째 테이블 내용을 SQL로 푸시합니다\ncities_population.to_sql('cities_population',   # 이렇게 하면 Python에서 SQL로 푸시합니다\n                  if_exists='append',       # 덮어쓰기를 원하지 않으므로, 기존 데이터에만 데이터를 추가합니다\n                  con=connection_string,    # con은 sql workbench에 연결하기 위해 필요한 인자입니다\n                  index=False)\n```\n\nSQL에서 모든 것을 실행하고 \"역공학\" 기능을 사용하면, 우리의 스키마의 가장 초기 버전을 얻을 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_3.png\" /\u003e\n\n우리는 학습 곡선 속으로 더 깊이 파고들고 있어요.\n\n다음 단계: API를 데이터베이스에 통합하기. 지구상의 모든 데이터 과학자의 본질이라고 할 수 있죠.\n\nAI가 따라잡기 전에 어떻게 해야 할지 배워야겠네요! (또는 외계인이 그들의 데이터 요구를 어떻게 처리하는지를 보일 때까지) 👽\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 날씨 API 사용하기\n\n이 프로젝트의 세 번째 큰 단계는 현재 존재하는 데이터 저장소에서 날씨 데이터를 추출하고 SQL 데이터베이스에 통합하는 것입니다. 이러한 저장소들은 API를 통해 접근할 수 있습니다. API는 Application Programming Interface의 약자로, 서로 다른 소프트웨어 응용 프로그램 간에 통신할 수 있도록 하는 규칙과 프로토콜의 집합입니다.\n\n이를 위해 우리는 openweathermap.org 웹사이트를 사용할 것입니다. 이 사이트를 통해 전 세계 어느 위치의 무료 날씨 예보에도 접근할 수 있습니다. 우리는 5일 날씨 예보 API를 사용할 것이며, 3시간 간격의 예보 데이터를 포함합니다: [https://openweathermap.org/forecast5](https://openweathermap.org/forecast5)\n\n이제 우리 프로젝트의 핵심 작업에 직면했습니다: 우리가 원하는 날씨 데이터를 검색하고 SQL 데이터베이스로 전송하기 위한 필요한 코드를 작성하는 것입니다. 수십 시간 동안 고군분투한 결과, 가장 관련성 있는 날씨 데이터를 추출하기 위한 이 코드를 개발해냈습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndef get_weather_data(cities):\n  # 클라우드에서 작업할 예정이므로 컴퓨터는 어디에 있을지 모릅니다 - 컴퓨터 시간대를 우리 지역 시간대로 수정합시다.\n  berlin_timezone = timezone(\"Europe/Berlin\")\n  API_key = \"7e5623c79f102b6c08b15c8hjib4cc9l\"    # 이것은 실제 값이 아닙니다.\n  weather_items = []\n\n  for city in cities:\n    url = (f\"http://api.openweathermap.org/data/2.5/forecast?q={city}\u0026appid={API_key}\u0026units=metric\")\n    response = requests.get(url)\n    json = response.json()\n\n    # 예보를 작성한 시간을 알기 위해 검색 시간을 추가했습니다.\n    retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    # 이제 우리의 관련 데이터베이스에서 데이터를 사용하므로, 도시는 도시 이름이 아닌 도시 ID를 반영해야 합니다.\n    city_id = cities_info.loc[cities_info[\"city_name\"] == city, \"city_id\"].values[0]  # 여기에서 값들을 검색해야 하며, 그렇지 않으면 시리즈를 보여줍니다.\n\n    for item in json[\"list\"]:\n        weather_item = {\n            # 여러 도시를 고려할 때 정보를 명확히 알 수 있게 도시 이름을 추가했습니다.\n            \"city_id\": city_id,\n            \"forecast_time\": item.get(\"dt_txt\", None),\n            \"temperature\": item[\"main\"].get(\"temp\", None),\n            \"feels_like\": item[\"main\"].get(\"feels_like\", None),\n            \"forecast\": item[\"weather\"][0].get(\"main\", None),\n            \"humidity\": item[\"main\"].get(\"humidity\", None),\n            \"rain_in_last_3h\": item.get(\"rain\", {}).get(\"3h\", 0),\n            \"risk_of_rain\": item[\"pop\"],\n            \"snow_in_last_3h\": item.get(\"snow\", {}).get(\"3h\", 0),\n            \"wind_speed\": item[\"wind\"].get(\"speed\", None),\n            \"data_retrieved_at\": retrieval_time\n        }\n\n        weather_items.append(weather_item)\n\n  weather_df = pd.DataFrame(weather_items)\n  weather_df[\"forecast_time\"] = pd.to_datetime(weather_df[\"forecast_time\"])\n  weather_df[\"data_retrieved_at\"] = pd.to_datetime(weather_df[\"data_retrieved_at\"])\n  weather_df[\"snow_in_last_3h\"] = pd.to_numeric(weather_df[\"snow_in_last_3h\"], downcast=\"float.\")\n\n  return weather_df\n\nweather_df = get_weather_data([\"Berlin\", \"Hamburg\", \"Munich\", \"Cologne\", \"Frankfurt\"])\nweather_df     # 함수를 사용하여 새로운 데이터프레임 생성\n```\n\n날씨 데이터프레임 및 테이블의 중요 기능 중 하나는 데이터 검색 시간을 기록하는 열을 포함해야 한다는 것입니다. 이를 통해 필터링 및 일정한 기간 후 자동으로 이전 데이터가 삭제되도록 SQL에서 프로시저나 함수를 작성하거나 만들 수 있습니다. 이는 데이터 일관성 목적으로 날씨와 데이터 검색 시간이 항상 예보에 대한 날짜/시간과 다른 것임을 항상 인식할 수 있도록 하기 위한 것입니다.\n\n이것이 Python에서 새로운 날씨 데이터프레임이 보이는 방식입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_4.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일단 날씨 데이터프레임 구조를 가지고 있었을 때, SQL에서 날씨 테이블을 생성하는 작업을 시작했습니다:\n\n```js\n/***************************\n날씨 테이블을 생성합니다\n***************************/\n\nCREATE TABLE weather (\n    city_id INT,\n    forecast_time datetime,\n    temperature float,\n    feels_like float,\n    forecast VARCHAR(255) NOT NULL,\n    humidity INT,\n    rain_in_last_3h FLOAT,\n    risk_of_rain FLOAT,\n    snow_in_last_3h FLOAT,\n    wind_speed FLOAT,\n    data_retrieved_at DATETIME,\n    FOREIGN KEY (city_id) REFERENCES cities_info(city_id)\n    );\n\n-- TRUNCATE TABLE weather;   -- 테이블이 너무 커지고 데이터가 오래되었을 때 모든 행을 지워야 할 수도 있습니다\n```\n\n이것은 엔지니어링을 통해 역 공학을 거쳐 업데이트된 SQL 스키마입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_5.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 지역에서 전역으로\n\n우리의 코드를 클라우드에 올리기 전에, 날씨 데이터 검색 코드가 로컬에서 작동하는지 확인해야 합니다. Python으로 코드를 작성한 후, 로컬 SQL 인스턴스로 전송해보겠습니다:\n\n```python\nweather_df.to_sql(\"weather\",\n                  if_exists='append',\n                  con=connection_string,\n                  index=False)\n```\n\n만약 새 데이터가 우리의 SQL 테이블에 추가된다면, 작동하는 것입니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬을 통해 로컬 데이터를 입력한 후 SQL 날씨 테이블이 어떻게 보이는지는 다음과 같습니다:\n\n![Weather Table](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_6.png)\n\n## Google Cloud Platform 통합\n\n로컬에서 코드가 작동하는 것을 확인하면, 이제 클라우드에 올려보는 시간입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n구글 클라우드 플랫폼(GCP) 계정을 열고 클라우드 인스턴스를 설정해야 합니다. 여기서는 자세히 다루지는 않겠지만 MySQL을 사용한 좋은 단계별 설명을 찾을 수 있습니다: https://support.google.com/appsheet/answer/10107301?hl=en\n\n제게 가장 중요한 단계 중 하나는 파이썬 노트북에서 로컬 IP 호스트를 구글 IP 호스트로 변경하는 것이었습니다. 구체적으로, 데이터를 SQL로 전송하는 코드 블록에서 변경했습니다:\n\n```js\nschema = \"gans\"         # 데이터베이스 이름\nhost = \"XX.XXX.XX.XX\"   # 로컬 호스트:\"xxx.x.x.x\" (클라우드로 변경하기 전)\nuser = \"root\"           # 사용자 이름 (가이드 참조)\npassword = \"XXXX\"       # 비밀번호 직접 입력하거나 다른 노트북에서 가져옵니다 (\"from xxxfile import my_password\")\nport = 3306\n\nconnection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'     # 이 부분이 파이썬 노트북을 SQL 워크벤치에 연결하는 역할을 합니다\n```\n\n이렇게 함으로써, 이전에 생성한 정적 테이블을 클라우드에 자동으로 업로드하고 파이썬에서 코드를 다시 실행하지 않고 이미 존재하는 SQL 테이블에 데이터를 채울 수 있었습니다. 아니면 적어도 파이썬에서 코드를 다시 실행할 필요가 없습니다. 혹은 새로운 비동적 테이블(도시 정보 및 도시 인구)을 업데이트하기로 결정할 때까지입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 프로젝트의 목적으로, Python에서 이 두 표를 GCP로 업로드하려면 호스트 IP를 변경하는 것으로 충분합니다. 또 다른 방법은 두 표를 만드는 코드를 클라우드에 업로드하는 것입니다. 이 경우, 우리는 클라우드에 동적 표 날씨를 만들고 채우는 코드만 올릴 것입니다.\n\nGCP의 \"Cloud Functions\" 필드에 함수를 만든 후 여러 번의 시행착오 끝에 코드가 마침내 작동했습니다:\n\n![cloud_function_image](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_7.png)\n\n하지만 코드가 작동하기 전에 클라우드 인스턴스에 함수를 연결해야합니다. 아래 단계를 따라야합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_8.png\" /\u003e\n\n작업이 잘되었는지 어떻게 알 수 있을까요? 가장 좋은 소식은 다음과 같이 보입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_9.png\" /\u003e\n\n로컬에서 테스트한 코드와 비교해 상당한 수정이 필요했습니다. 최종 코드는 이렇게 보입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nimport functions_framework\nimport pandas as pd\nimport sqlalchemy\nimport requests\nfrom pytz import timezone\nfrom datetime import datetime\n\n@functions_framework.http\ndef insert(request):\n  connection_string = connection()\n  insert_into_weather(connection_string)\n  return 'Data successfully added'\n\ndef connection():\n  connection_name = \"flying-dove-416317:europe-west1:wbs-mysql-db\"    # this is not a real one\n  db_user = \"root\"\n  db_password = \"xxxx\"   # fill in with your SQL password\n  schema_name = \"gans\"\n\n  driver_name = 'mysql+pymysql'\n  query_string = {\"unix_socket\": f\"/cloudsql/{connection_name}\"}\n\n  db = sqlalchemy.create_engine(\n      sqlalchemy.engine.url.URL(\n          drivername = driver_name,\n          username = db_user,\n          password = db_password,\n          database = schema_name,\n          query = query_string,\n      )\n  )\n  return db\n\n\n# HERE STARTS THE WEATHER DATA RETRIEVAL FUNCTION:\n\ndef extract_city(connection_string):\n    return pd.read_sql(\"cities_info\", con=connection_string)\n\ndef get_weather_data(cities_df):\n  berlin_timezone = timezone(\"Europe/Berlin\")\n  API_key = \"7e5623c79f102b6c08b15c8hjib4cc9l\"    # this is not a real one\n  weather_items = []\n\n  for city in cities_df[\"city_name\"]:\n    url = (f\"http://api.openweathermap.org/data/2.5/forecast?q={city}\u0026appid={API_key}\u0026units=metric\")\n    response = requests.get(url)\n    json = response.json()\n\n    # Added the time retrieved so we know when the forecast was made\n    retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    # As we are now using the data from our relational database, the city should reflect the city_id and not the city name\n    city_id = cities_df.loc[cities_df[\"city_name\"] == city, \"city_id\"].values[0]  # here we need to retrieve the values, otherwise it shows us the series\n\n    for item in json[\"list\"]:\n        weather_item = {\n            # Added the city name, so the information is clear when looking at multiple cities\n            \"city_id\": city_id,\n            \"forecast_time\": item.get(\"dt_txt\", None),\n            \"temperature\": item[\"main\"].get(\"temp\", None),\n            \"feels_like\": item[\"main\"].get(\"feels_like\", None),\n            \"forecast\": item[\"weather\"][0].get(\"main\", None),\n            \"humidity\": item[\"main\"].get(\"humidity\", None),\n            \"rain_in_last_3h\": item.get(\"rain\", {}).get(\"3h\", 0),\n            \"risk_of_rain\": item[\"pop\"],\n            \"snow_in_last_3h\": item.get(\"snow\", {}).get(\"3h\", 0),\n            \"wind_speed\": item[\"wind\"].get(\"speed\", None),\n            \"data_retrieved_at\": retrieval_time\n        }\n\n        weather_items.append(weather_item)\n\n  weather_df = pd.DataFrame(weather_items)\n  weather_df[\"forecast_time\"] = pd.to_datetime(weather_df[\"forecast_time\"])\n  weather_df[\"data_retrieved_at\"] = pd.to_datetime(weather_df[\"data_retrieved_at\"])\n  weather_df[\"snow_in_last_3h\"] = pd.to_numeric(weather_df[\"snow_in_last_3h\"], downcast=\"float\")\n\n  return weather_df\n\ndef insert_into_weather(connection_string):\n  cities_df = extract_city(connection_string)\n  weather_df = get_weather_data(cities_df)    # we create the new dataframe using the function\n  weather_df.to_sql(\"weather\",\n            if_exists=\"append\",\n            con=connection_string,\n            index=False)\n```\n\n## Lessons learned from making our code cloud-worthy\n\n### 1. Dependencies:\n\nWe need to add the right dependencies to the `requirements.txt` file. This was one of the main initial reasons preventing our code from working properly. It is important to note that some libraries are already uploaded on GCP by default and should not be included in the `.txt` file, but still need to be added as a library in our source code, e.g.:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom pytz import timezone\nfrom datetime import datetime\n```\n\n만약 배포를 시도한 후에 빨간 배너 에러가 발생한다면, 대부분의 경우 requirements.txt 파일에 명시되어 있지 않은 라이브러리를 import하는 것이 원인일 수 있습니다:\n\n![image](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_10.png)\n\nrequirements 섹션에서는 Python 모듈이 아닌 패키지만 추가해야 합니다. 미리 알려드리자면, 여기 Python 모듈들의 종합 목록이 있습니다: [Python 모듈 목록](https://docs.python.org/3/py-modindex.html)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 유용한 팁은 코드에서 사용 중인 모든 외부 라이브러리를 출력하는 것입니다. 노트북에서 함수를 호출한 후에는 다음을 실행해야 합니다:\n\n```js\nprint('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))\n```\n\n그런 다음 적절한 종속성으로 requirements.txt에 직접 복사하여 붙여넣을 수 있습니다:\n\n![이미지](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_11.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 프로젝트를 위해 필요한 의존성은 다음과 같습니다 .txt 파일:\n\n```js\nfunctions-framework==3.*\nSQLAlchemy==1.4.37\nPyMySQL==1.0.2\npandas==1.5.2\nrequests==2.31.0\n```\n\n## 2. 연결 코드 테스트\n\n데이터 검색 함수를 추가하기 전에 연결 코드가 작동하는지 먼저 테스트하는 것이 좋습니다. 이렇게 하면 문제가 연결 설정에 있는지 아닌지 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로컬 스크립트를 GCP로 이동할 때 좋은 시작 방법은 \"더미\" 함수를 만들고 테스트하는 것입니다. 예를 들어:\n\n```js\nimport functions_framework\nimport pandas as pd\nimport sqlalchemy\n\n@functions_framework.http\ndef insert(request):\n  connection_string = connection()\n  insert_into_test_table(connection_string)\n  return 'Data successfully added'\n\ndef connection():\n  connection_name = \"YOUR_DB_CON_NAME\"  # 변경해주세요\n  db_user = \"root\"                      # 변경\n  db_password = \"YOUR_PASSWORD\"         # 변경\n  schema_name = \"test_schema\"           # 변경\n\n  driver_name = 'mysql+pymysql'\n  query_string = {\"unix_socket\": f\"/cloudsql/{connection_name}\"}\n\n  db = sqlalchemy.create_engine(\n      sqlalchemy.engine.url.URL(\n          drivername = driver_name,\n          username = db_user,\n          password = db_password,\n          database = schema_name,\n          query = query_string,\n      )\n  )\n  return db\n\ndef insert_into_test_table(con_str):\n  data = {'FirstName': ['Function', 'Test'],\n          'City': ['Cloud', 'Complete']}\n  df = pd.DataFrame(data)\n  df.to_sql(name=\"test_table\", con=con_str, if_exists='append', index=False)\n```\n\n이 간단한 함수가 작동하면 연결이 작동하는 것이고, 할 일은 실제 코드를 추가하고 통합하는 것뿐입니다.\n\n다음 오류가 발생하면 우리의 코드에 문제가 있음을 가정할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3. 우리 실제 코드의 문제점\n\n내 코드를 온라인에 올릴 때 실수한 주요한 부분은 \"더미\" 템플릿을 기반으로 코드를 조정하고 실제로 정의되지 않은 \"insert_into_weather\" 함수를 \"@functions_framework.http\" 아래에서 호출했다는 것이었습니다.\n\n이 함수를 추가한 후에도 코드가 작동하지 않았습니다. 이는 필요한 도시를 수동으로 명명했기 때문에 도시 정보 데이터프레임에서 이미 가져오는 대신에 도시 이름을 수동으로 지정해서 오는 점과 관련이 있었습니다. 그래서 나는 먼저 \"extract_city\"라는 또 다른 함수를 추가해야 했고, 이 함수가 로컬에서 작동하는 것을 확인 후에 코드를 온라인에 배포해야 했습니다.\n\n도시 이름을 얻기 위해 cities_info 테이블을 사용한 후에, 도시 이름을 추출하지 않은 전 반복문을 업데이트하지 않은 다른 실수를 했습니다. 이제 도시 이름을 이전에 목록에서 가져오지 않고 데이터프레임에서 가져와야 했고, 이전 인수로는 도시 이름을 찾지 못했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마지막 단계\n\n우리 프로젝트를 완전히 기능적이고 자동화하기 위해 주기적으로 실행할 함수를 예약해야 합니다. GCP의 \"Cloud Scheduler\" 메뉴를 사용하면 상당히 쉽습니다.\n\n이를 위해 \"작업 예약\"을 하고 몇 가지 매개변수를 제공하고 빈도를 설정해야 합니다(매주 한 번 또는 Cron 표현식을 사용하여 특정 시간에 특정 요일에 실행하도록 설정). 이렇게 하면 해당 시간에 함수가 실행되어 SQL 테이블에 필요한 데이터를 채웁니다. 예를 들어, 여기서는 매주 월요일 오후 3시에 실행되도록 설정했습니다:\n\n![이미지](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_12.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSQL에서 작동하는지 확인할 수 있어요:\n\n![image](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_13.png)\n\n첫 번째 SQL-to-Python-to-GCP 프로젝트와 작별하기 전에, 무료 크레딧을 소비하지 않도록 GCP 계정에서 데이터를 삭제해야 해요. 이는 클라우드 인스턴스, 함수 및 예약된 작업을 포함해요.\n\n# 끝\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 글을 쓰면서 SQL, Python 및 클라우드 컴퓨팅을 결합한 매우 기본적인 데이터베이스를 구축하는 방법을 배웠어요.\n\n이 프로젝트를 시작할 때 구글 클라우드 플랫폼 또는 다른 클라우드 컴퓨팅 플랫폼에 대해 전혀 알지 몰랐어요. 서버, 호스트, 인스턴스 또는 소프트웨어 연결에 대해 아무것도 모르고 있었어요 (지금도요). SQL과 Python의 기본적인 지식만 있었어요.\n\n이렇게 초보자로 시작했을 때, 자동화된 데이터베이스를 생성하고 주기적으로 가치 있는 데이터로 채우는 일이 너무 어려울 것이라고 회의적이었어요. 이제 내가 할 수 있다는 것을 알게 되었어요!\n\n앞으로의 계획은 다른 API에서 데이터를 가져와 GCP 기능에 결합하여 더 완전하고 유용한 최종 제품을 만들고 싶어해요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n글을 쓰는 사람이라고 하더라도 데이터 엔지니어링을 소프트웨어 엔지니어만큼 잘 할 수는 없을 지도 모르겠어요. 하지만 우리는 기초를 배우고 거기서부터 성장할 수 있죠.\n\n# Stackademic 🎓\n\n끝까지 읽어주셔서 감사합니다. 떠나시기 전에:\n\n- 저자를 클랩하시고 팔로우해주시면 감사하겠습니다! 👏\n- 우리를 팔로우해주세요 X | LinkedIn | YouTube | Discord\n- 다른 플랫폼에서도 만나보세요: In Plain English | CoFeed | Venture | Cubed\n- 더 많은 콘텐츠는 Stackademic.com에서 확인하세요\n","ogImage":{"url":"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png"},"coverImage":"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png","tag":["Tech"],"readingTime":30},{"title":"오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기","description":"","date":"2024-05-18 18:19","slug":"2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM","content":"\n# 소개\n\n데이터 활용의 동적인 풍경에서는 데이터베이스와 손쉽게 상호 작용할 수 있는 능력이 중요합니다. 전통적으로 이 상호 작용은 구조화된 쿼리 언어(SQL)에 대한 심층적인 이해가 필요하여 많은 사용자들에게 진입 장벽이 되었습니다. 그러나 자연어 처리(NLP)를 SQL 쿼리 엔진에 적용하여 이 풍경이 변화되었으며, 이를 통해 사용자들이 자연어 명령을 사용하여 데이터베이스와 소통할 수 있게 되었습니다. 이 첨단 기술은 인간의 언어를 SQL 쿼리로 순조롭게 번역하여 데이터를 검색하고 조작하는 방식을 혁신하고 있습니다.\n\n자연어 처리(NLP)에서 Mistral 7B 및 Microsoft Phi-3과 같은 모델은 주요 역할을 하며 성능과 효율성의 경계를 재정의하고 있습니다.\n\nMistral 7B는 NLP 작업에서 뛰어난 성능과 정밀도로 높이 평가 받고 있습니다. 그룹화된 쿼리 어텐션(GQA) 및 슬라이딩 윈도우 어텐션(SWA)과 같은 혁신적인 기능들을 갖춘 Mistral 7B는 수학 및 코드 생성을 포함한 다양한 벤치마크에서 우수한 성과를 거두고 있습니다. Code-Llama 7B의 코딩 능력에 가까워짐과 동시에 NLP 발전에서의 중요성을 강조하며 다양한 분야에서 우수성을 유지하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPhi-3 는 작은 언어 모델(SLMs) 분야에서의 Microsoft의 최신 혁신으로, AI의 풍경을 변화시키는 대단한 제품입니다. Phi-3-mini, Phi-3-small 및 Phi-3-medium으로 구성된 이 모델군은 간결한 구성으로 뛰어난 성능을 제공합니다. 38억 개의 파라미터를 자랑하는 Phi-3-mini는 더 큰 모델들과 견줄 만한 성능을 발휘하면서도 스마트폰에서 효율적으로 동작합니다. Phi-3의 성공 뒤에는 견고함, 안전성 및 대화 능력을 중시하는 정교하게 선별된 학습 데이터셋이 있습니다. Phi-3-small 및 Phi-3-medium은 Phi-3의 능력을 더욱 확장하여 다양한 응용 분야에 대응합니다. 정교하게 설계된 아키텍처와 학습 방법을 통해 Phi-3은 AI 기술의 큰 발전을 상징하며, 다양한 생성형 AI 작업에 대한 우수한 성능과 효율성을 약속합니다.\n\nNLP와 SQL의 교차점을 탐색하여 Mistral 7B와 Microsoft Phi-3의 활용에 대해 알아봅니다. 이러한 모델들은 자연어 쿼리를 구조화된 SQL 쿼리로 원활하게 변환하여 데이터베이스 쿼리 작업에서 향상된 효율성과 정확도를 제공합니다.\n\n![](/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png)\n\n# 학습 목표\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블로그 포스트에서는 오픈 소스 Mistral 7B 모델을 NL2SQL 작업에 활용하는 복잡성을 탐색할 것입니다. 또한 NL2SQL 애플리케이션을 위해 모델을 맞춤화하고 훈련하는 방법에 대해 논의할 것입니다. 기사의 나머지 부분은 다음과 같은 내용을 다룹니다.\n\n# 동기부여\n\n오픈 소스 LLMs를 활용하면 자연어 명령을 SQL 쿼리로 변환하는 복잡한 프로세스를 실행할 수 있습니다. 이 혁신적인 기술은 사용자가 수동 쿼리 작성 없이 데이터 요구 사항을 자연스럽게 표현하도록 자동화하며, 이로써 사용자의 입력을 분석하고 의미론적으로 정확한 SQL 쿼리를 생성하는 복잡한 알고리즘과 대규모 언어 모델이 활용됩니다. 이는 변환 프로세스를 간소화시키고 광범위한 사용자들에게 광범위한 SQL 지식이 없어도 데이터를 이용할 수 있게 합니다. 오픈 소스 LLMs는 편리함을 제공하며 데이터 접근성과 운영 효율성을 크게 향상시킵니다. SQL 전문 지식의 장벽을 제거함으로써 이 기술은 데이터 접근성을 민주화시키고 각 분야의 사용자들이 데이터를 검색하고 통찰을 얻는 데 도움을 줍니다. 실시간 통찰을 찾는 비즈니스 분석가나 데이터 집합을 탐색하는 일반 사용자를 위한 것이든, 자연어 명령의 직관적인 성격은 데이터 검색을 간단하게 합니다.\n\n또한 이러한 모델에서 내재된 자동화는 쿼리 실행을 가속화하여 전반적인 효율성과 생산성을 높입니다. 오픈 소스 LLMs의 영향력은 광범위하며 다양한 산업 전반에 혁신과 변화를 격려합니다. 이 기술은 재무, 건강 관리 및 전자 상거래 분야와 같이 데이터 주도적 의사 결정이 중요한 분야에서 이해하기 쉬운 인사이트를 추출할 수 있도록 이해권자를 돕습니다. 더 나아가, 고급 분석 플랫폼과 인공 지능 시스템과의 통합을 통해 조직을 데이터 주도적 우수성으로 이끕니다. 탐구 문화를 육성하고 데이터 상호작용을 간소화함으로써 오픈 소스 LLMs는 데이터 자산의 모든 잠재력을 발휘함으로써 산업 전반에 혁신과 성장을 촉진합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1. NL2SQL을 위한 사전 훈련 모델 (Mistral 7B)\n\nMistral AI가 개발한 70억 개의 파라미터를 가진 언어 모델인 Mistral 7B는 인공 지능 분야에서 강력한 모델로 빠르게 인기를 얻고 있습니다.\n\n- 기본 모델로 위치 지정된 Mistral 7B는 자연어 처리에서 중요한 역할을 하는 가장 중요한 구조적 모델로 자리 잡았으며 대규모 언어 모델 환경 내에서 필수적인 코어 빌딩 블록의 중요성을 보여줍니다.\n- 건축적 접근 방식으로 차별화된 Mistral 7B는 빠른 추론을 위해 그룹화된 쿼리 어텐션 (GQA)과 긴 시퀀스를 효율적으로 처리하기 위한 슬라이딩 윈도우 어텐션 (SWA)과 같은 혁신적인 기능을 활용하여 우수한 성능을 발휘합니다.\n- 주로 영어에 초점을 맞추지만 코딩 능력도 갖춘 Mistral 7B는 특히 다른 모델들보다 더 넓은 컨텍스트에서 텍스트를 이해하고 생성할 수 있는 높은 문맥 윈도우를 가지고 있어 두각을 나타냅니다.\n- 73억 개의 파라미터로 인상적인 Mistral 7B는 최신 언어 모델을 대표하는데, Apache 2.0 라이센스 하에 제한 없이 사용할 수 있습니다.\n- Mistral 7B는 모든 평가된 벤치마크에서 최고의 오픈 13B 모델 (Llama-2)보다 우수한 성과를 거두며 최고의 34B 모델 (Llama-1)보다 추론평가, 수학 및 코드 생성에서 뛰어난 성능을 보여줍니다.\n- Mistral-7B는 Llama2-13B보다 우수한 성능을 보이며 CodeLlama-7B와 경쟁력 있는 성과를 보이며 특히 추론, 수학 및 코드 생성 벤치마크에서 뛰어납니다.\n- 더 큰 모델들에 비해 크기는 작지만, Mistral 7B는 텍스트 요약, 분류, 텍스트 완성 및 코드 완성을 포함한 다양한 자연어 작업에서 우수한 성과를 거둡니다.\n- 이 모델이 자연어 쿼리를 구조화된 SQL 명령어로 변환하는 효과를 탐색하여 능력을 자세히 살펴봅시다.\n\n## Sliding Window Attention\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Mistral 7B은 전통적인 주의 메커니즘에서 발생하는 도전에 효과적으로 대처할 수 있는 슬라이딩 윈도우 어텐션(Sliding Window Attention, SWA) 메커니즘을 포함하고 있습니다. 전자는 토큰 수가 증가함에 따라 추론 중 지연 시간이 증가하고 처리량이 감소할 수 있으며, 시퀀스 길이와 메모리와 관련된 연산이 이차적으로 증가하고 메모리가 선형적으로 증가할 수 있습니다. 반면에 SWA는 각 토큰의 주의를 이전 레이어의 W개 토큰을 최대한으로 제한하여 주어진 윈도우 크기 W를 넘어서 주의를 확장합니다.\n- SWA는 트랜스포머의 계층 구조를 활용하여 위치 i의 숨겨진 상태가 입력 레이어의 토큰을 W x k 토큰까지 액세스할 수 있도록 지원합니다. 최종 레이어에서 W = 4096의 윈도우 크기로, SWA는 이론적으로 대략 131K 토큰의 주의 범위를 달성할 수 있습니다. 실제적으로 W = 4096 및 FlashAttention과 xFormers의 최적화 기법을 사용하여, 16K 토큰 시퀀스의 경우 바닐라 주의 기준에 비해 주목할만한 2배의 속도 향상이 가능합니다. 따라서, SWA는 주의 메커니즘의 성능을 혁신적으로 향상시킬 수 있는 강력하고 효율적인 접근 방식입니다.\n\n### b. 롤링 버퍼 캐시\n\n- 롤링 버퍼 캐시를 구현함으로써, Mistral 7B는 고정된 주의 범위를 전략적으로 사용하여 캐시 크기를 효과적으로 제어합니다. 이 캐시는 W로 표시된 고정된 크기로, 캐시 내에서 특정 시간 단계 i에서 시간 단계 i mod W에 키와 값들을 효율적으로 저장합니다. 시퀀스가 진행되고 i가 W를 초과할 때, 캐시는 롤링 버퍼 메커니즘을 사용하여 이전 값들을 덮어쓰고 무한정으로 확장되는 것을 방지합니다. W = 3으로 설명된 이 접근 방식은 32k 토큰 시퀀스에 대해 8배의 캐시 메모리 사용량 감소를 실현함으로써, 모델의 품질을 희생하지 않고 달성합니다. 고정된 주의 범위는 효율적인 메모리 이용을 보장할 뿐만 아니라 Mistral 7B가 길이가 다른 시퀀스를 처리하는 데에 원활하게 기능하는 데에 기여합니다.\n\n### c. 사전 채움 및 청크 분할\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 시퀀스 생성 과정에서는 문맥 정보에 기반하여 순차적으로 토큰을 예측하는데, (k, v) 캐시를 사용하여 효율적으로 최적화됩니다. 알려진 프롬프트로 미리 채워진 캐시를 활용하여 효율성을 높입니다. 긴 프롬프트를 관리하기 위해 지정된 윈도우 크기를 사용하여 작은 청크로 나누고, 각 청크를 사용하여 캐시를 미리 채웁니다. 이 전략적 접근 방식은 시퀀스 생성 프로세스 중 캐시 내부 및 현재 청크 전체에서 주의력을 계산하는 것을 포함합니다. 이 방법을 활용함으로써 Mistral 7B는 시퀀스 생성의 효율성을 향상시키며, 캐시에 저장된 미리 알려진 프롬프트를 효율적으로 활용하여 각 예측된 토큰을 이전 토큰과 조화롭게 정렬합니다.\n- 언어 모델의 동적인 환경에서 Mistral 7B의 등장은 성능과 효율성 면에서 큰 도약을 의미합니다. 포괄적인 평가 파이프라인을 통해 Mistral 7B는 자신의 능력을 입증하며, 이전 제품인 Llama 2 7B 및 Llama 2 13B뿐만 아니라 Llama 1 34B와 같은 핵심 벤치마크에서 뛰어난 성능을 보여줌으로써 뛰어난 경쟁력을 나타냅니다.\n- Mistral 7B의 우월성은 모든 측정 항목에 걸쳐 명백히 드러나며, 해당 분야의 선도주자로서의 지위를 재확인합니다. 다양한 벤치마크에 대한 면밀한 재평가 과정은 Mistral 7B의 탁월한 능력을 일관되게 입증하며, 경쟁사를 뒤로 남깁니다.\n\n## 크기 및 효율성 분석\n\n- Mistral 7B의 매력 중요 요소 중 하나는 혁신적인 \"동등한 모델 크기\" 계산 방식을 통한 효율성입니다. 추론, 이해 및 STEM 추론 등에서 평가한 결과, Mistral 7B는 세 배 이상 크기의 Llama 2 모델과 동등한 성능을 보여줍니다. 이 효율성은 과도한 매개변수 부담 없이 뛰어난 결과를 제공할 수 있는 Mistral 7B의 능력을 입증합니다.\n- Mistral 7B의 효율성을 더 자세히 살펴보면, 평가 결과에서 지식 압축에 대한 흥미로운 통찰력을 확인할 수 있습니다. 지식 벤치마크에서 1.9배 낮은 압축률을 달성하지만, 이는 Mistral 7B의 의도적으로 제한된 매개변수 수에 기인합니다. 이 제한은 저장된 지식 양을 제한하지만, Mistral 7B는 집중하고 효과적으로 매개변수를 활용하여 보상합니다.\n\n# 평가의 차이점\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n불일치 사항을 투명하게 다루면서, 평가 규정의 변화를 유의하는 것이 중요합니다. 어떤 벤치마크에서는 Llama 2의 MBPP와 Mistral 7B의 평가 결과 사이에 차이가 발생합니다. TriviaQA에서 손으로 검증된 데이터를 사용하는 것이 Mistral 7B의 성능 지표의 신뢰성에 기여하는 강건한 평가 과정을 확인하게 됩니다.\n\n# 데이터셋\n\n아래 열로 구성된 구조 데이터베이스를 사용할 계획입니다. 다음 테이블에서 다양한 검색을 수행할 것입니다.\n\n```js\ntransaction = [\n  \"transaction_id\",\n  \"transaction_amount\",\n  \"transaction_date\",\n  \"transaction_type\",\n  \"transaction_status\",\n  \"transaction_description\",\n  \"transaction_source_account\",\n  \"transaction_destination_account\",\n  \"transaction_currency\",\n  \"transaction_fee\",\n];\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 코드 구현\n\n- 패키지 설치하기\n\n```js\n!pip install git+https://github.com/huggingface/transformers.git\n!pip install deepspeed --upgrade\n!pip install accelerate\n!pip install sentencepiece\n!pip install langchain\n!pip install torch\n!pip install bitsandbytes\n```\n\n2. 패키지 불러오기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport os\nimport re\nimport torch\nfrom difflib import SequenceMatcher\nfrom langchain.chains import LLMChain\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n```\n\n3. 모델 불러오기\n\n```js\nbase_model = LlamaForCausalLM.from_pretrained(\n  \"mistralai/Mistral-7B-Instruct-v0.1\",\n  (load_in_8bit = True),\n  (device_map = \"auto\")\n);\ntokenizer = LlamaTokenizer.from_pretrained(\n  \"mistralai/Mistral-7B-Instruct-v0.1\"\n);\npipe = pipeline(\n  \"text-generation\",\n  (model = base_model),\n  (tokenizer = tokenizer),\n  (max_length = 500),\n  (temperature = 0.3),\n  (top_p = 0.95),\n  (repetition_penalty = 1.2)\n);\nlocal_llm = HuggingFacePipeline((pipeline = pipe));\n```\n\n4. SequenceMatcher\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 Python 함수는 difflib 모듈의 SequenceMatcher 클래스를 활용하여 쿼리와 지정된 사전의 열 이름 간의 유사도 점수를 계산하여 쿼리 이해력과 대체를 향상시킵니다.\n\n```js\ndef find_columns_match(question, input_dict):\ntry:\n  question_list = re.split(r'\\s|,|\\.', question)\n  for index, string2 in enumerate(question_list):\n    for string1 in input_dict.get('table1_columns'):\n      score = SequenceMatcher(None,string1.lower(), string2.lower()).ratio()*100\n      if score \u003e 91:\n        question_list[index] = string1 + \",\"\n  return \" \".join(question_list)\n\nexcept:\n return question\n```\n\n이 Python 함수 query_generator은 제공된 테이블명, 열 목록 및 질문에 기반하여 SQL 쿼리를 생성합니다. 이는 템플릿 문자열을 활용하여 쿼리 생성 프로세스를 구조화하며, 테이블 명, 열 목록 및 질문에 대한 자리 표시자를 포함합니다. 그런 다음 PromptTemplate 객체를 사용하여 이러한 자리 표시자를 채워넣고 LLMChain을 통해 대형 언어 모델 (LLM)과 상호 작용하여 SQL 쿼리를 생성합니다. 마지막으로 생성된 SQL 쿼리를 출력합니다.\n\n```js\ndef query_generator(tble, cols, question):\n\n  template = \"\"\"Generate a SQL query using the following table name: {Table}, and columns as a list: {Columns}, to answer the following question:\n  {question}.\n\n  Output Query:\n\n  \"\"\"\n\n  prompt = PromptTemplate(template=template, input_variables=[\"Table\", \"question\", \"Columns\"])\n\n  llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n\n  response = llm_chain.run({\"Table\": tble, \"question\": question, \"Columns\": cols})\n  print(response)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 표\n\ntransaction = [\n\"transaction_id\",\n\"transaction_amount\",\n\"transaction_date\",\n\"transaction_type\",\n\"transaction_status\",\n\"transaction_description\",\n\"transaction_source_account\",\n\"transaction_destination_account\",\n\"transaction_currency\",\n\"transaction_fee\"\n]\n\n    inputs = [\"transaction_id가 10인 경우 transaction_amount, transaction_date, transaction_type,transaction_description을 검색하는 SQL 쿼리 생성\",\n             \"transaction_status가 'completed'인 경우 transaction_id, transaction_date, transaction_type, transaction_source_account을 검색하는 SQL 쿼리 생성\",\n             \"transaction_type 및 평균 transaction_amount의 개수를 검색하고 transaction_type로 정렬하는 SQL 쿼리 생성\",\n             \"각 소스 계정별 총 거래 금액 목록을 검색하고 총 거래 금액을 내림차순으로 정렬하는 SQL 쿼리 생성\",\n             \"각 거래 유형별 최대 거래 금액을 검색하고 거래 유형으로 정렬하는 SQL 쿼리 생성\"]\n\n    for input in inputs:\n        query_generator(\"transaction\",transaction ,question=find_columns_match(input,transaction))\n\n# 응답\n\n- 다음과 같은 테이블 이름을 사용하고 컬럼을 나열한 리스트를 사용하여 SQL 쿼리를 생성하십시오: transaction 및 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’], 다음 질문에 대한 응답을 위해 SQL 쿼리를 생성하십시오: (‘transaction_id가 10인 경우 transaction_amount, transaction_date, transaction_type,transaction_description을 검색하는 SQL 쿼리 생성’).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n출력 쿼리:\n\n  SELECT transaction_amount, transaction_date, transaction_type, transaction_description FROM transaction WHERE transaction_id = 10;\n```\n\n2. 다음과 같은 테이블 이름인 transaction과 열 목록인 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’]을 사용하여 다음 질문에 대한 SQL 쿼리를 생성하십시오:\n   (‘transaction_status가 ‘completed’인 경우 transaction_id, transaction_date, transaction_type, transaction_source_account를 검색하는 SQL 쿼리를 생성하십시오’).\n\n```js\n출력 쿼리:\n  SELECT transaction_id, transaction_date, transaction_type, transaction_source_account FROM transaction WHERE transaction_status = 'completed'\n```\n\n3. 다음과 같은 테이블 이름인 transaction과 열 목록인 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’]을 사용하여 다음 질문에 대한 SQL 쿼리를 생성하십시오:\n   (‘transaction_type의 count와 평균 transaction_amount를 가져오고 transaction_type으로 정렬하십시오’).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n결과 쿼리:\n\n  SELECT transaction_type, AVG(transaction_amount) AS avg_transaction_amount, COUNT(*) AS total_count\n  FROM transaction\n  GROUP BY transaction_type\n  ORDER BY transaction_type;\n```\n\n4. 다음 테이블 이름과 열 목록을 사용하여 SQL 쿼리를 생성하십시오: transaction 및 열: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], 다음 질문에 답하십시오:\n   (‘리스트에서 각 소스 계정의 총 거래 금액을 내림차순으로 정렬하여 조회하는 SQL 쿼리를 생성하세요’).\n\n```js\n결과 쿼리:\n\n       SELECT transaction_source_account, SUM(transaction_amount) AS TotalTransactionAmount\n        FROM transaction\n        GROUP BY transaction_source_account\n        ORDER BY TotalTransactionAmount DESC;\n```\n\n5. 다음 테이블 이름과 열 목록을 사용하여 SQL 쿼리를 생성하십시오: transaction 및 열: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], 다음 질문에 답하십시오:\n   (‘각 거래 유형의 최대 거래 금액을 찾아 거래 유형으로 정렬하는 SQL 쿼리를 생성하세요’).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n출력 쿼리:\n\n   SELECT transaction_type, MAX(transaction_amount) AS max_transaction_amount\n   FROM transaction\n   GROUP BY transaction_type\n   ORDER BY transaction_type;\n```\n\n일반적인 추출은 효과적이지만, 연구 결과, 데이터를 세부 조정하여 LLM을 수행하면 우수한 결과를 얻을 수 있습니다. 세밀 조정 접근법을 채용해 봅시다.\n\n# 2 Fine-tune NL2SQL with Phi-3\n\nPhi-3를 만나보세요, Microsoft의 최신 오픈 AI 모델의 주요 성과입니다. Phi-3-mini, Phi-3-small 및 Phi-3-medium을 통해, 이 작은 언어 모델 (SLM)의 Phi-3 패밀리는 AI 모델의 세계를 혁신하도록 설계되었습니다. 38억 개의 파라미터를 사용하고 33조 개의 토큰으로 훈련된 Phi-3-mini는 높은 성능을 발휘하며 Mixtral 8x7B 및 GPT-3.5와 같은 큰 모델과 같은 성능을 보여줍니다. 게다가, 이 모델은 스마트폰 장치에서 효율적으로 작동할 수 있습니다. Phi-3의 성공은 훈련 데이터셋에 기인합니다. Phi-2의 데이터셋의 진화된 버전입니다. 상세히 걸러낸 웹 데이터 및 합성 입력을 통해 이러한 모델은 강도, 안전 및 대화 능력에 우선순위를 두어 다양한 응용프로그램에 적합합니다. 7B 및 14B 파라미터를 가진 Phi-3-small 및 Phi-3-medium은 효율 유지와 함께 Phi-3의 기능을 더욱 향상시키도록 설계되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Phi 3 Architecture and Evaluation\n\nPhi-3 패밀리는 품질과 비용을 균형있게 유지하도록 설계된 다양한 모델을 제공하여 생성형 AI 애플리케이션을 개발하는 고객을 위한 옵션을 제공합니다.\n\nPhi-3-mini: 이 모델은 38억 개의 파라미터를 갖추고 33조 개의 토큰으로 이루어진 광범위한 데이터셋을 기반으로 훈련되었습니다. 32개의 레이어, 32개의 어텐션 헤드, 그리고 3072개의 히든 디멘션을 갖는 트랜스포머 디코더 아키텍처를 채택했습니다. 디폴트 콘텍스트 길이는 4천 개의 토큰이며, 32K 어휘 사전을 사용하는 토크나이저를 활용합니다. 추가로, 128K 토큰의 콘텍스트 길이를 갖춘 확장 버전인 Phi-3-mini-128K도 있습니다.\n\nPhi-3-small: 70억 개의 파라미터로 훈련된 Phi-3-small은 48조 개의 토큰을 사용합니다. 이 모델은 100K 어휘 사전과 8천 개의 디폴트 콘텍스트 길이를 갖추었습니다. 아키텍처는 32개의 레이어, 32개의 어텐션 헤드, 그리고 4096개의 히든 디멘션으로 이루어져 있습니다. 이 모델은 메모리 사용량을 최적화하기 위해 그룹화된 쿼리 어텐션과 번갈아가며 쓰이는 밀집/희소 어텐션을 활용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPhi-3-medium: 이 미리보기 모델은 140억 개의 매개변수를 자랑하며 4.8조 개의 토큰으로 학습되었습니다. 40개의 레이어, 40개의 어텐션 헤드, 그리고 임베딩 크기는 5120입니다.\n\n## 훈련 방법:\n\n- 훈련 데이터 구성: Phi-3 모델의 훈련 데이터는 신중하게 선별됩니다. 교육 수준별로 분류된 웹 데이터와 합성 LLM 생성 데이터로 구성되며 두 가지 이질적이고 순차적인 단계로 사전 훈련을 거칩니다.\n- 사전 훈련 단계: 제1 단계는 일반 지식과 언어 이해에 중점을 둔 웹 소스를 사용합니다. 제2 단계는 논리 추론 및 특정 기술을 가르치기 위해 제1 단계의 웹 데이터와 합성 데이터를 더 많이 활용합니다.\n- 사후 훈련 단계: 사전 훈련 후, Phi-3-mini는 감독형 세밀 조정 (SFT) 및 직접 선호도 최적화 (DPO)를 거쳤습니다. SFT는 수학, 코딩, 추론, 대화, 모델 신원, 안전 도메인 간에 높은 품질의 데이터를 선별하는 과정을 포함합니다.\n- DPO는 채팅 형식 데이터, 추론, 그리고 책임 있는 AI 노력에 초점을 맞춥니다.\n- 맥락 확장: Phi-3-mini의 맥락 창 크기가 Long Rope 방법론을 사용하여 4k 토큰에서 128k 토큰으로 확장되었습니다. 이 확장은 맥락의 길이가 크게 증가함에도 일관된 성능을 유지합니다.\n- 데이터 최적화: 훈련 데이터는 모델의 규모를 위한 \"데이터 최적\" 지점으로 보정됩니다. 웹 데이터는 지식과 추론의 적절한 균형을 보장하기 위해 필터링됩니다. 특히 작은 모델의 경우 이는 매우 중요합니다.\n- 다른 모델과의 비교: Phi-3의 접근 방식은 이전 작업과 대조적으로, 해당 규모에 대한 데이터 품질에 중점을 두며 컴퓨팅이나 과도한 훈련 방법보다 데이터 최적화를 강조합니다. 벤치마크 비교는 Phi-3가 작은 모델 용량을 위한 최적화를 잘 보여줍니다.\n- Phi-3-medium 미리보기: 140억 개의 매개변수를 가진 Phi-3-medium은 Phi-3-mini와 유사하게 훈련되었지만 더 큰 규모로 이루어집니다. 일부 벤치마크에서는 7B에서 14B 매개변수로의 전환에서 큰 개선이 없어 계속해서 데이터 혼합을 개선 중임을 시사합니다.\n- 사후 향상: 모델은 채팅 능력, 견고성, 그리고 안전성을 향상시키기 위해 감독형 세밀 조정 및 DPO를 통한 선호도 조정을 거칩니다.\n\n## 안전성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPhi-3-mini은 Microsoft의 책임 있는 AI 원칙에 따라 만들어진 AI 모델입니다. 이 프로젝트는 개발 초기부터 안전을 우선시하는 원칙을 중요시하여 만들어졌습니다. 모델이 윤리 기준을 준수하고 잠재적인 피해를 최소화할 수 있는 능력을 보장하기 위해 포괄적인 전략이 채택되었습니다.\n\n모델 학습 후에는, 해당 모델이 책임 있는 AI 기준을 충족하는지 확인하기 위해 면밀한 안전 조정이 이루어집니다. 게다가, Microsoft의 독립된 레드 팀이 Phi-3-mini를 검토하여 강화 및 안전 프로토콜을 강화할 수 있는 부분을 식별합니다.\n\n자동화된 테스팅과 잠재적인 피해의 다양한 범주에 대한 평가는 프로세스의 중요한 부분입니다. 이러한 테스트는 모델의 출력물로부터 발생하는 모든 위험을 감지하고 해결하는 데 목표를 두고 있습니다.\n\n더 나아가, Phi-3-mini는 의견 데이터 세트를 활용하여 응답을 더욱 개선합니다. 특정 테스트 중 확인된 잠재적인 피해 범주에 대응하기 위해 내부에서 생성된 데이터 세트가 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 코드 구현\n\n- 패키지 설치\n\n```js\n !pip install -q -U bitsandbytes\n !pip install -q -U transformers\n !pip install -q -U xformers\n !pip install -q -U peft\n !pip install -q -U accelerate\n !pip install -q -U datasets\n !pip install -q -U trl\n !pip install -q -U einops\n !pip install -q -U nvidia-ml-py3\n !pip install -q -U huggingface_hub\n```\n\n2. 패키지 가져오기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling\nfrom pynvml import *\nimport time, torch\nfrom trl import SFTTrainer\nfrom peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\nfrom peft import AutoPeftModelForCausalLM\n```\n\n3. 데이터셋 불러오기\n\n```python\ndataset = load_dataset(\"b-mc2/sql-create-context\")\ndataset\n```\n\n4. 데이터셋 형식화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndef create_prompt(sample):\n      system_prompt_template = \"\"\"\u003cs\u003e\n            아래는 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n            ### 지시사항: \u003c\u003cuser_question\u003e\u003e\n            ### 데이터베이스 스키마:\n            \u003c\u003cdatabase_schema\u003e\u003e\n            ### 응답:\n            \u003c\u003cuser_response\u003e\u003e\n            \u003c/s\u003e\n            \"\"\"\n      user_message = sample['question']\n      user_response = sample['answer']\n      database_schema = sample['context']\n      prompt_template = system_prompt_template.replace(\"\u003c\u003cuser_question\u003e\u003e\",f\"{user_message}\").replace(\"\u003c\u003cuser_response\u003e\u003e\",f\"{user_response}\").replace(\"\u003c\u003cdatabase_schema\u003e\u003e\",f\"{database_schema} \")\n\n      return {\"inputs\":prompt_template}\n\n\ninstruct_tune_dataset = dataset.map(create_prompt)\nprint(instruct_tune_dataset)\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU 메모리 사용량: {info.used//1024**2} MB.\")\n```\n\n5. 토크나이저와 모델 로드\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n# 토크나이저 로드\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n# fp16로 모델 로드\nmodel = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, device_map={\"\": 0})\nprint(print_gpu_utilization())\n```\n\n6. 모델 추론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 프롬프트 정의\n\n```bash\n    prompt = [\n        \"코코넛 밀크로 만든 치킨 카레 레시피를 작성해주세요.\",\n        \"다음 문장을 프랑스어로 번역해주세요: '나는 빵과 치즈를 좋아해요!'\",\n        \"유명한 20명의 인물을 인용해보세요.\",\n        \"지금 달은 어디에 있나요?\"\n    ]\n\n    # 변수 초기화\n    duration = 0.0\n    total_length = 0\n\n    # 프롬프트 반복\n    for i in range(len(prompt)):\n        # 프롬프트 토큰화 및 GPU로 이동\n        inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n\n        # 입력 텐서 인덱스를 torch.long으로 변환\n        inputs = {k: v.to(torch.long) for k, v in inputs.items()}\n\n        # 시작 시간\n        start_time = time.time()\n\n        # 자동 캐스팅을 사용하여 추론 수행\n        with torch.cuda.amp.autocast(enabled=False):  # 자동 캐스팅 비활성화\n            output = model.generate(**inputs, max_length=500)\n\n        # 소요 시간과 총 길이 계산\n        duration += float(time.time() - start_time)\n        total_length += len(output)\n\n        # 프롬프트당 토큰 속도 계산\n        tok_sec_prompt = round(len(output) / float(time.time() - start_time), 3)\n\n        # 프롬프트당 토큰 속도 출력\n        print(\"프롬프트 --- %s 토큰/초 ---\" % (tok_sec_prompt))\n\n        # 디코드된 출력 출력\n        print(tokenizer.decode(output[0], skip_special_tokens=True))\n\n    # 평균 토큰 속도 계산\n    tok_sec = round(total_length / duration, 3)\n    print(\"평균 --- %s 토큰/초 ---\" % (tok_sec))\n```\n\n9. Fine-tuning되지 않은 Text to SQL\n\n```bash\n    prompt = [\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        각 도시의 역 중 가장 높은 위도를 가진 역순으로 모든 도시를 나열하십시오.\n        데이터베이스 스키마:\n        CREATE TABLE station (city VARCHAR, lat INTEGER)\n        ### 응답:\n        SELECT city, lat FROM station ORDER BY lat DESC;\n        \"\"\",\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        '각 선수가 20점 이상 및 10점 미만을 가지고 있으며 상위 10위 안에 있는 포지션은 무엇입니까?\n        데이터베이스 스키마:\n        CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\n        ### 응답:\n        SELECT POSITION, Points, Ranking\n        FROM player\n        WHERE Points \u003e 20 AND Points \u003c 10 AND Ranking IN (1,2,3,4,5,6,7,8,9,10)\n        \"\"\",\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        노래를 가장 많이 연주한 밴드 맴버의 이름을 찾아보세요.\n        데이터베이스 스키마:\n        CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)\n        ### 응답:\n        SELECT b.firstname\n        FROM Band b\n        JOIN Performance p ON b.id = p.bandmate\n        GROUP BY b.firstname\n        ORDER BY COUNT(*) DESC\n        LIMIT 1;\n        \"\"\"\n    ]\n\n    for i in range(len(prompt)):\n      model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n      start_time = time.time()\n      output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n      duration += float(time.time() - start_time)\n      total_length += len(output)\n      tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n      print(\"프롬프트 --- %s 토큰/초 ---\" % (tok_sec_prompt))\n      print(print_gpu_utilization())\n      print(tokenizer.decode(output, skip_special_tokens=False))\n\n    tok_sec = round(total_length/duration,3)\n    print(\"평균 --- %s 토큰/초 ---\" % (tok_sec))\n\n    # Fine-tuning\n\n    base_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n    tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_eos_token=True, use_fast=True, max_length=250)\n    tokenizer.padding_side = 'right'\n    tokenizer.pad_token = tokenizer.eos_token\n\n    compute_dtype = getattr(torch, \"float16\") # Ampere (또는 최신) GPU를 사용하는 경우 bfloat16로 변경\n    bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=compute_dtype,\n            bnb_4bit_use_double_quant=True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n              base_model_id, trust_remote_code=True, quantization_config=bnb_config, revision=\"refs/pr/23\", device_map={\"\": 0}, torch_dtype=\"auto\", flash_attn=True, flash_rotary=True, fused_dense=True\n    )\n    print(print_gpu_utilization())\n\n    model = prepare_model_for_kbit_training(model)\n```\n\n10. LoRA 매개변수\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\npeft_config = LoraConfig(\n  (lora_alpha = 16),\n  (lora_dropout = 0.05),\n  (r = 16),\n  (bias = \"none\"),\n  (task_type = \"CAUSAL_LM\"),\n  (target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"dense\", \"fc1\", \"fc2\"])\n);\n```\n\n9. Training Parameters\n\n```js\ntraining_arguments = TrainingArguments(\n            output_dir=\"./phi3-results\",\n            save_strategy=\"epoch\",\n            per_device_train_batch_size=4,\n            gradient_accumulation_steps=12,\n            log_level=\"debug\",\n            save_steps=100,\n            logging_steps=25,\n            learning_rate=1e-4,\n            eval_steps=50,\n            optim='paged_adamw_8bit',\n            fp16=True, #change to bf16 if are using an Ampere GPU\n            num_train_epochs=1,\n            max_steps=400,\n            warmup_steps=100,\n            lr_scheduler_type=\"linear\",\n            seed=42)\n```\n\n10. Data Prepare for the training\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ntrain_dataset = instruct_tune_dataset.map(\n  (batched = True),\n  (remove_columns = [\"answer\", \"question\", \"context\"])\n);\ntrain_dataset;\n```\n\n11. Fine-Tuned\n\n```js\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset[\"train\"],\n    #eval_dataset=dataset['test'],\n    peft_config=peft_config,\n    dataset_text_field=\"inputs\",\n    max_seq_length=1024,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False\n)\n\ntrainer.train()\n```\n\n12. Test inference with the fine-tuned adapter\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\";\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, (use_fast = True));\n\ncompute_dtype = getattr(torch, \"float16\");\nbnb_config = BitsAndBytesConfig(\n  (load_in_4bit = True),\n  (bnb_4bit_quant_type = \"nf4\"),\n  (bnb_4bit_compute_dtype = compute_dtype),\n  (bnb_4bit_use_double_quant = True)\n);\nmodel = AutoModelForCausalLM.from_pretrained(\n  base_model_id,\n  (trust_remote_code = True),\n  (quantization_config = bnb_config),\n  (device_map = { \"\": 0 })\n);\nadapter = \"/content/phi3-results/checkpoint-400\";\nmodel = PeftModel.from_pretrained(model, adapter);\n```\n\n13. 수행하기\n\n```js\ndatabase_schema = 'CREATE TABLE station (city VARCHAR, lat INTEGER)'\nuser_question = \"List all the cities in a decreasing order of each city's stations' highest latitude.\"\n\nprompt_template = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{user_question}\nDatabase Schema:\n{database_schema}\n### Response:\n\"\"\"\n\nquestion = \"'What are the positions with both players having more than 20 points and less than 10 points and are in Top 10 ranking\"\ncontext = \"CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\"\n\nprompt_template1 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\ncontext = '''CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)'''\nquestion = \"Find the first name of the band mate that has performed in most songs.\"\n\nprompt_template2 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\nprompt = []\nprompt.append(prompt_template)\nprompt.append(prompt_template1)\nprompt.append(prompt_template2)\n\nfor i in range(len(prompt)):\n  model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n  start_time = time.time()\n  output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n  duration += float(time.time() - start_time)\n  total_length += len(output)\n  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n  print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n  print(print_gpu_utilization())\n  print(tokenizer.decode(output, skip_special_tokens=False))\n\ntok_sec = round(total_length/duration,3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n14. 모델 저장하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport locale\nimport shutil\nfrom huggingface_hub import notebook_login\nfrom google.colab import drive\n\n# Set the preferred encoding to UTF-8\nlocale.getpreferredencoding = lambda: \"UTF-8\"\n\n# Log in to the notebook\nnotebook_login()\n\n# Push the fine-tuned adapter to the Hugging Face Hub\ntrainer.push_to_hub(commit_message=\"fine-tuned adapter\")\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# Move the trained model to Google Drive\nshutil.move('/content/phi3-results', '/content/drive/MyDrive/PHI-3')\n\n# Load the trained model\ntrained_model = AutoPeftModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/checkpoint-400\",\n                                                         low_cpu_mem_usage=True,\n                                                         return_dict=True,\n                                                         torch_dtype=torch.float16,\n                                                         device_map='auto',)\n\n# Merge and unload the trained model\nlora_merged_model = trained_model.merge_and_unload()\n\n# Save the merged model\nlora_merged_model.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\", safe_serialization=True)\n\n# Save the tokenizer for the merged model\ntokenizer.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\")\n\n# Push the merged model to the Hugging Face Hub\nlora_merged_model.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n\n# Push the tokenizer to the Hugging Face Hub\ntokenizer.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n```\n\n15. Perform Inference on Fine-tuned Model\n\n```js\npeft_config = LoraConfig(\n            lora_alpha=16,\n            lora_dropout=0.05,\n            r=16,\n            bias=\"none\",\n            task_type=\"CAUSAL_LM\",\n    )\n\npeft_model_id = \"username/phi3-results\"\nconfig = peft_config.from_pretrained(peft_model_id)\n\nmodel = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n                                             return_dict=True,\n                                             load_in_4bit=True,\n                                             device_map=\"auto\",\n                                             )\n\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n\nmodel = PeftModel.from_pretrained(model, peft_model_id)\n\nprint(model.get_memory_footprint())\n\nfor i in range(len(prompt)):\n    model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n    start_time = time.time()\n    output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n    duration += float(time.time() - start_time)\n    total_length += len(output)\n    tok_sec_prompt = round(len(output)/float(time.time() - start_time), 3)\n    print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n    print(print_gpu_utilization())\n    print(f\"RESPONSE:\\n {tokenizer.decode(output, skip_special_tokens=False)[len(prompt[i]):].split('\u003c/')[0]}\")\n\ntok_sec = round(total_length/duration, 3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n# Conclusion\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자연어 처리(NLP)와 SQL 쿼리 엔진의 결합은 데이터베이스와 상호 작용하는 것을 더 쉽고 효율적으로 만들었습니다. 이전에는 SQL에 대한 심층적인 이해가 필요했기 때문에 많은 사용자들에게 어려움이 있었습니다. 그러나 Mistral 7B와 Microsoft Phi-3와 같은 오픈 소스 대형 언어 모델(LLMs)은 이를 바꿨습니다. 이 모델들은 자연어 쿼리를 구조화된 SQL 쿼리로 신속하게 변환하여, 방대한 SQL 전문 지식이 필요 없게 했습니다.\n\nMistral 7B와 Microsoft Phi-3는 NLP 작업에서 우수한 성능을 발휘하는 탁월한 모델들입니다. 그들은 Grouped-Query Attention과 Sliding Window Attention과 같은 기능을 갖추어 더욱 효율적입니다. 크기가 작은 Microsoft Phi-3도 NLP 성능과 효율성에서 새로운 기준을 세우며, 복잡한 벤치마크에서 더 큰 모델들을 능가합니다.\n\n오픈 소스 LLMs를 고급 분석 플랫폼과 AI 시스템에 통합함으로써 기업은 손쉽게 통찰을 추출할 수 있습니다. 이 기술은 금융, 건강 관리, 전자 상거래와 같은 산업들이 데이터 기반 결정을 내리는 방식을 변화시켰습니다. 이러한 모델들이 다양한 부문에 미치는 영향은 상당하며 혁신과 변혁을 촉진했습니다.\n\nNLP와 SQL의 융합을 통해 오픈 소스 LLMs는 데이터 접근을 민주화시키고 효율성, 생산성, 기업 성공을 촉진했습니다. 이는 데이터 자산의 최대 잠재력을 발휘하도록 허용하여 이해당사자들이 실행 가능한 통찰을 추출하기 쉬워지고, 여러 부문에서 탐구와 혁신의 문화를 육성했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n노트북: phi3\n\n제 이전 📝 글들을 확인해주세요.\n\n# 참고 자료\n\n- https://arxiv.org/pdf/2310.06825.pdf\n- https://artgor.medium.com/paper-review-mistral-7b-6acdf2f3132d\n- https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580\n- https://www.datacamp.com/tutorial/mistral-7b-tutorial\n- https://www.analyticsvidhya.com/blog/2023/11/from-gpt-to-mistral-7b-the-exciting-leap-forward-in-ai-conversations/\n- https://medium.com/@rubentak/mistral-7b-the-best-7-billion-parameter llm-yet-8b0aa03016f9\n- https://clarifai.com/mistralai/completion/models/mistral-7B-Instruc\n- https://iamgeekydude.com/2023/06/02/alpaca-llm-load-model-using-langchain-hf/\n- https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/\n- https://huggingface.co/microsoft/Phi-3-mini-128k-instruct\n","ogImage":{"url":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"},"coverImage":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png","tag":["Tech"],"readingTime":38},{"title":"LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법","description":"","date":"2024-05-18 18:18","slug":"2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit","content":"\nThe Advent of LLMs shows the ability of machines to comprehend natural language. These capabilities have helped engineers to do a lot of amazing things, such as writing code documentation and code reviews, and one of the most common use cases is code generation; GitHub copilot has shown the capability of AI to comprehend engineers’ intention for code generation, such as Python, Javascript, and SQL, though LLM’s comprehension AI could understand what we want to do and generate code accordingly.\n\n# Using LLM to solve Text-to-SQL\n\nBased on the code generation capability of LLMs, many people have started considering using LLMs to solve the long-term hurdle of using natural language to retrieve data from databases, sometimes called “Text-to-SQL.” The idea of “Text-to-SQL” is not new; after the presence of “Retrieval Augmented Generation (RAG)” and the latest LLM models breakthrough, Text-to-SQL has a new opportunity to leverage LLM comprehension with RAG techniques to understand internal data and knowledge.\n\n![Top 4 Challenges using RAG with LLMs to Query Database Text-to-SQL and how to solve it](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# RAG를 사용한 텍스트-SQL의 도전 과제\n\n텍스트-SQL 시나리오에서 사용자는 LLM이 생성한 결과를 신뢰하기 위해 정밀도, 보안 및 안정성을 갖추어야합니다. 그러나 실행 가능하고 정확하며 보안이 제어된 텍스트-SQL 솔루션을 추구하는 것은 간단하지 않습니다. 여기에서는 자연어를 통해 데이터베이스를 쿼리하기 위해 RAG를 사용한 LLM 사용의 네 가지 주요 기술적 도전 과제를 요약해보았습니다: 컨텍스트 수집, 검색, SQL 생성 및 협업.\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_1.png)\n\n## 도전 과제 1: 컨텍스트 수집 도전과제\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 다양한 원본 간 상호 운용성: 다양한 소스, 메타데이터 서비스 및 API 간에 원활하게 검색 및 통합된 정보를 일반화하고 표준화하는 것이 중요합니다.\n- 데이터와 메타데이터의 복잡한 링킹: 이는 데이터를 해당 문서 저장소의 메타데이터와 연결하는 것을 포함합니다. 관련성, 계산 및 집계와 같은 메타데이터, 스키마 및 컨텍스트를 저장하는 것이 포함됩니다.\n\n## 도전 과제 2: 검색 도전과제\n\n- 벡터 저장소의 최적화: 인덱싱 및 청킹과 같은 벡터 저장소를 최적화하기 위한 기술을 개발하고 구현하는 것은 검색 효율성과 정확도 향상에 중요합니다.\n- 의미 검색의 정확도: 도전 과제는 질의 이해의 뉘앙스에 있으며 이는 결과의 정확도에 중대한 영향을 미칠 수 있습니다. 이는 일반적으로 쿼리 재작성, 다시 순위 지정 등과 같은 기술을 포함합니다.\n\n## 도전 과제 3: SQL 생성 도전과제\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- SQL 쿼리의 정확성 및 실행 가능성: 정확하고 실행 가능한 SQL 쿼리를 생성하는 것은 상당한 도전입니다. 이를 위해서는 LLM이 SQL 구문, 데이터베이스 스키마, 그리고 다양한 데이터베이스 시스템의 특정 방언에 대한 깊은 이해가 필요합니다.\n- 쿼리 엔진 방언 적응: 데이터베이스는 종종 SQL 구현에서 고유한 방언과 뉘앙스를 가집니다. 이러한 차이에 적응하고 다양한 시스템 간에 호환되는 쿼리를 생성할 수 있는 LLM을 설계하는 것은 도전의 복잡도를 더 높이는 요소입니다.\n\n## 도전 4: 협업 도전\n\n- 집단 지식 축적: 도전은 다양한 사용자 그룹으로부터 수집된 집단적인 통찰과 피드백을 효과적으로 수집, 통합, 그리고 활용하여 LLM이 검색하는 데이터의 정확성과 관련성을 향상하는 메커니즘을 만드는 데에 있습니다.\n- 접근 제어: 데이터를 검색하는 것에 대한 다음으로 중요한 도전은 존재하는 조직 데이터 접근 정책 및 개인정보 보호 규정이 새로운 LLM 및 RAG 아키텍처에도 적용되도록 보장하는 것입니다.\n\n더 많은 정보를 원하시나요? 각 도전에 대해 미래 게시물에서 자세히 공유할 계획입니다. 알림을 받으려면 Medium에서 팔로우해주세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 어떻게 문제를 해결할 수 있을까요? LLM을 위한 의미론적 레이어.\n\n위의 과제들을 해결하기 위해서, 우리는 LLM과 데이터 소스 사이에 레이어가 필요합니다. 이 레이어를 통해 LLM이 비즈니스 의미론과 메타데이터를 데이터 소스로부터 학습할 수 있게 되며, 이 레이어는 종종 \"의미론적 레이어\"라고 불리는 것이 필요합니다. 의미론적 레이어는 의미론과 데이터 구조 간의 연결을 해결하고, 액세스 제어와 식별 관리를 조정하여 정확한 사용자만이 정확한 데이터에 액세스하도록 보장해야 합니다.\n\nLLM을 위한 의미론적 레이어에는 무엇이 포함되어야 할까요? 여기서 몇 가지 측면으로 일반화해봅시다.\n\n## 데이터 해석 및 표현\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 비즈니스 용어 및 개념: 시맨틱 레이어는 비즈니스 용어와 개념의 정의를 포함합니다. 예를 들어, \"수익\"과 같은 용어는 시맨틱 레이어에 정의되어 있어서 비즈니스 사용자가 BI 도구에서 \"수익\"을 조회할 때 시스템이 어떤 데이터를 검색하고 어떻게 계산할지 정확히 알고 있습니다.\n\n- 데이터 관계: 이것은 서로 다른 데이터 엔티티 간의 관계를 정의합니다. 예를 들어, 고객 데이터가 판매 데이터와 어떻게 관련되는지 또는 제품 데이터가 재고 데이터와 연결되는 방법 등이 있습니다. 이러한 관계는 복잡한 분석을 수행하고 통찰을 얻는 데 중요합니다.\n\n- 계산 및 집계: 시맨틱 레이어에는 종종 미리 정의된 계산 및 집계 규칙이 포함됩니다. 이는 사용자가 예를 들어 금년 매출을 계산하기 위해 복잡한 수식을 작성하는 방법을 알 필요가 없다는 것을 의미합니다. 시맨틱 레이어는 내부 데이터 원본을 기반으로 이러한 작업을 정의 및 규칙에 따라 처리합니다.\n\n## 데이터 액세스 및 보안\n\n- 보안 및 액세스 제어: 이것은 누가 어떤 데이터에 액세스할 수 있는지를 관리할 수도 있습니다. 사용자가 액세스 권한을 부여받은 데이터만 볼 수 있고 분석할 수 있도록 보장하여 데이터 프라이버시를 유지하고 규정을 준수하는 데 중요합니다.\n\n## 데이터 구조 및 조직\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터 소스 매핑: 시맨틱 레이어는 비즈니스 용어와 개념을 실제 데이터 소스에 매핑합니다. 이는 각 비즈니스 용어에 해당하는 데이터베이스 테이블과 열을 지정하고, BI 도구가 올바른 데이터를 검색할 수 있도록 합니다.\n- 다차원 모델: 일부 BI 시스템에서 시맨틱 레이어에는 다차원 모델(예: OLAP 큐브)이 포함되어 복잡한 분석과 데이터 슬라이싱/다이싱이 가능합니다. 이러한 모델은 사용자가 쉽게 탐색하고 분석할 수 있는 차원과 측정 값을 구성합니다.\n\n## 메타데이터\n\n- 메타데이터 관리: 메타데이터를 관리합니다. 이는 데이터에 대한 데이터로서, 데이터 원본, 변환, 데이터 계보 등 데이터를 이해하는 데 도움이 되는 모든 정보가 포함됩니다.\n\n# WrenAI 소개\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_2.png)\n\nWrenAI는 오픈 소스입니다. 데이터, LLM API 및 환경 어디에서든 WrenAI를 배포할 수 있습니다. 직관적인 온보딩 및 사용자 인터페이스가 함께 제공되어 몇 분 안에 데이터소스에서 데이터 모델을 연결하고 구축할 수 있습니다.\n\nWrenAI의 하부에는 이전 섹션에서 언급한 LLM을 위한 \"Wren Engine\"이라는 프레임워크를 개발했습니다. Wren Engine은 GitHub에서도 오픈 소스로 제공됩니다. Wren Engine에 관심이 있다면 댓글을 남겨주시기 바랍니다. 앞으로 나올 글에서 아키텍처와 디자인에 대해 더 자세히 공유할 계획입니다.\n\n## WrenAI에서의 모델링\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 소스와 연결이 완료되면 자동으로 모든 메타데이터를 수집하며 WrenAI UI를 통해 비즈니스 의미론과 관계를 추가할 수 있습니다. 미래의 의미론적 검색을 위해 자동으로 벡터 저장소를 업데이트할 것입니다.\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_3.png)\n\n## 질문하고 따라가기\n\n모델링을 마치고 나면 비즈니스 질문을 시작할 수 있습니다. WrenAI는 가장 관련성 높은 결과 3개를 찾아 제공할 것입니다. 옵션 중 하나를 선택하면 해당 데이터의 출처 및 요약을 단계별 설명으로 제공해 드립니다. 이를 통해 WrenAI가 제안하는 결과를 더 자신 있게 사용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nWrenAI로부터 결과를 받으면 반환된 결과를 기반으로 깊은 통찰이나 분석을 위한 후속 질문을 할 수 있습니다.\n\n![image](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_4.png)\n\n## 지금 GitHub에서 WrenAI를 사용해보고 커뮤니티에 참여해보세요!\n\n👉 GitHub: https://github.com/Canner/WrenAI\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n👉 디스코드: https://discord.gg/5DvshJqG8Z\n","ogImage":{"url":"/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png"},"coverImage":"/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png","tag":["Tech"],"readingTime":8},{"title":"장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini","description":"","date":"2024-05-18 18:15","slug":"2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics","content":"\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBigQuery 워크로드 내에서 Gemini 1.0 Pro (텍스트 전용) 및 Gemini 1.0 Pro Vision (멀티모달) 두 가지 LLM 모델을 통합하는 흥미로운 기술을 시연하겠습니다. 이를 통해 Low-code 생성적 인사이트 생성 경험을 제공할 수 있습니다. BigQuery에서 원격 모델 엔드포인트로 지원되는 모델인 Gemini 1.0 Pro와 같이, 데이터베이스 쿼리 내에서 모델을 호출하기 위해 ML.GENERATE_TEXT 구조를 직접 사용할 수 있습니다. 기본적으로 원격 모델로 사용할 수 없거나 생성적 AI 호출에 더 많은 사용자 정의가 필요한 경우 (또는 데이터베이스 내에서 원격으로 액세스하려는 API가 있는 경우), REMOTE FUNCTIONS 접근 방식을 사용할 수 있습니다. 두 시나리오를 모두 다루기 위해 블로그 글을 2개의 섹션으로 나눠서 설명하겠습니다:\n\n## #1 원격 모델 호출:\n\n- 이 섹션은 SELECT 쿼리에서 ML.GENERATE_TEXT를 사용하여 BigQuery 내에서 Gemini 1.0 Pro를 호출하는 방법을 안내합니다.\n- 모델이 이미 BigQuery의 원격 모델로 사용 가능하고 기본 제공으로 사용하려는 경우에 이 접근 방법을 사용할 수 있습니다. 사용하려는 모델의 상태를 이 설명서에서 확인할 수 있습니다.\n- 안내 사례:\n\n인터넷 아카이브 책 데이터셋(공개적으로 BigQuery에서 사용 가능)에 대한 위치 요약기를 구축하며, BigQuery에서 Gemini 1.0 Pro의 원격 모델을 ML.GENERATE_TEXT 구조를 통해 호출하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_1.png\" /\u003e\n\n## #2 원격 함수 구현:\n\n- 이 섹션에서는 Gemini 1.0 Pro Vision을 구현한 클라우드 함수를 호출하는 방법에 대해 안내합니다. 이 클라우드 함수는 BigQuery에서 원격 함수로 노출됩니다.\n- 사용하려는 모델이 원격 모델로 제공되지 않거나 사용 사례에서 더 많은 유연성 및 사용자 정의가 필요한 경우 이 접근 방식을 사용하십시오.\n- 안내용 사용 사례:\n\n기준 이미지와 테스트 이미지를 비교하는 이미지 유효성 검사기를 구축합니다. 이를 위해 외부 테이블에 테스트 이미지 스샷을 포함하는 데이터 세트를 만들고 Gemini 1.0 Pro Vision에 대해 확인하도록 요청합니다. 이를 위해 Gemini Pro Vision 호출을 구현한 Java 클라우드 함수를 만들고 이를 BigQuery에서 원격 함수로 호출합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_2.png\" /\u003e\n\n# BigQuery\n\nBigQuery은 서버리스, 멀티 클라우드 데이터 웨어하우스로, 바이트부터 페타바이트까지 최소한의 운영 오버헤드로 확장이 가능합니다. 이것은 ML 트레이닝 데이터를 저장하기에 좋은 선택지가 됩니다. 내장된 BigQuery Machine Learning (BQML)과 분석 기능을 통해 SQL 쿼리만 사용하여 노코드 예측을 생성할 수 있습니다. 게다가, 페더레이티드 쿼리로 외부 소스에서 데이터에 접근할 수 있어 복잡한 ETL 파이프라인이 필요하지 않습니다. BigQuery가 제공하는 모든 것에 대해 BigQuery 페이지에서 자세히 읽어볼 수 있습니다. 우리는 텍스트 요약 사례에 사용되는 원격 모델을 호출하기 위해 BigQuery ML의 ML.GENERATE_TEXT 구조를 사용할 것입니다.\n\n우리는 BigQuery를 구조적 및 반구조적 데이터를 분석하는 데 도움이 되는 완전 관리형 클라우드 데이터 웨어하우스로 알고 왔습니다. BigQuery는 비정형 데이터에서 모든 분석 및 ML을 수행할 수 있도록 확장되었습니다. 우리는 이미지 데이터를 저장하기 위해 객체 테이블을 사용할 것이며, Gemini Pro Vision 모델을 사용하여 이미지 유효성을 검증하는 원격 기능 사례에 필요한 데이터를 저장할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데모\n\n이 블로그의 나머지 부분에서는 위에서 설명한 유즈 케이스 섹션에 자세히 기술된 실제 예제로 두 가지 유즈 케이스를 모두 시연하겠습니다. 유즈 케이스별 구현에 들어가기 전에 두 가지 유즈 케이스에 필요한 사전 설정 및 공통 단계를 완료해 봅시다.\n\n# 설정\n\n- Google Cloud Console에서 프로젝트 선택기 페이지에서 Google Cloud 프로젝트를 선택하거나 만듭니다.\n- 클라우드 프로젝트에 청구가 활성화되어 있는지 확인하십시오. 프로젝트에 청구가 활성화되어 있는지 확인하는 방법을 알아보세요.\n- Google Cloud에서 미리 로드된 bq를 실행하는 명령줄 환경인 Cloud Shell을 사용할 것입니다. Cloud 콘솔에서 오른쪽 상단의 'Cloud Shell 활성화'를 클릭하세요.\n- 애플리케이션 구축 및 제공을 위한 지원을 위해서, Duet AI를 활성화해 봅시다. Duet AI Marketplace로 이동하여 API를 활성화하세요. 또는 Cloud Shell 터미널에서 다음 명령을 실행할 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngcloud services enable cloudaicompanion.googleapis.com –project PROJECT_ID\n```\n\n5. 이미 하지 않았다면, 이 구현을 위해 필요한 API를 활성화하세요.\n\nBigQuery, BigQuery Connection, Vertex AI, Cloud Storage APIs\n\ngcloud 명령어 대신 이 링크를 사용하여 콘솔을 통해 진행할 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# BigQuery Dataset과 외부 연결 생성하기\n\nBigQuery 데이터셋은 애플리케이션의 모든 테이블과 객체를 포함하는 컨테이너입니다. BigQuery 연결은 Cloud Function과 상호작용하는 데 사용됩니다. 원격 함수를 생성하려면 BigQuery 연결을 만들어야 합니다. 데이터셋과 연결을 생성하는 방법을 알아보겠습니다.\n\n- Google Cloud Console에서 BigQuery 페이지로 이동한 후 프로젝트 ID 옆에 있는 3개 수직 점 아이콘을 클릭하세요. 나타나는 옵션 중에서 “데이터 집합 만들기”를 선택하세요.\n- “데이터 집합 만들기” 팝업에서 아래와 같이 데이터 집합 ID를 “gemini_bq_fn”로 입력하고 지역 값을 기본 값인 “US (다중 지역…)”으로 설정하세요.\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. BigLake Connection을 사용하면 외부 데이터 원본에 연결할 수 있으면서 세밀한 BigQuery 액세스 제어와 보안을 유지할 수 있습니다. 우리의 경우에는 Vertex AI Gemini Pro API를 사용합니다. 우리는 이 연결을 사용하여 Cloud Function을 통해 BigQuery의 모델에 액세스할 것입니다. 아래 단계를 따라 BigLake Connection을 만들어보세요:\n\na. BigQuery 페이지의 탐색기 창에서 ADD를 클릭하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_4.png)\n\nb. 소스 페이지에서 외부 데이터 원본에 대한 연결을 클릭하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nc. 팝업창에 아래 외부 데이터 원본 세부정보를 입력하고 CREATE CONNECTION을 클릭하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_5.png)\n\nd. 연결이 생성되면, 연결 구성 페이지로 이동하여 액세스 권한 부여를 위한 서비스 계정 ID를 복사하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ne. IAM 및 관리 페이지를 열고 액세스 부여를 클릭한 후 새 주체 탭에 서비스 계정 ID를 입력하고 아래에 표시된 역할을 선택한 다음 저장을 클릭하세요.\n\n![그림](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_7.png)\n\n# Use case #1 Remote Model Invocation\n\n여기서는 Vertex AI Gemini Pro foundation 모델을 기반으로 BigQuery에 모델을 만들 것입니다. 이미 데이터 세트와 연결 설정이 완료되었습니다. 이제 3단계만으로 Gemini Pro 모델의 원격 모델 호출을 시연합니다. SQL 쿼리만 사용하여 LLM 애플리케이션이 가동됩니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 테이블 및 모델 생성\n\n인터넷 아카이브 도서 데이터셋을 예시로 들어서 BigQuery에서 공개로 사용할 수 있도록 소스로 가져왔다고 가정해봅시다.\n\n## BigQuery 테이블 생성\n\n위의 예제로부터 공개적으로 이용 가능한 BigQuery 데이터셋에서 약 50개의 레코드를 보유할 수 있는 테이블을 생성해봅시다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBigQuery SQL 에디터 창에서 다음과 같이 DDL (데이터 정의 언어) 문을 실행해보세요:\n\n```sql\ncreate or replace table gemini_bq_fn.books as (\nselect *\nfrom\nbigquery-public-data.gdelt_internetarchivebooks.1905 limit 50);\n```\n\n이 쿼리는 이전에 생성한 데이터셋에 \"books\" 라는 새로운 테이블을 생성합니다.\n\n## BigQuery 모델 생성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델을 생성하려면 BigQuery SQL 편집기 창에서 다음 DDL을 실행하세요:\n\n```js\nCREATE MODEL `gemini_bq_fn.gemini_remote_model`\nREMOTE WITH CONNECTION `us.gemini-bq-conn`\nOPTIONS(ENDPOINT = 'gemini-pro');\n```\n\n모델이 생성되었음을 확인하고 방금 생성된 모델을 볼 수 있는 옵션이 제공됩니다.\n\n## 새로운 생성 AI 애플리케이션을 테스트해보세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그것이에요! 이제 ML.GENERATE_TEXT 문을 사용하여 새로 생성한 생성 모델을 테스트해 보겠습니다.\n\n```js\nSELECT ml_generate_text_llm_result as Gemini_Response, prompt as Prompt\nFROM ML.GENERATE_TEXT(MODEL `gemini_bq_fn.gemini_remote_model`,\n  (select '텍스트 요약기와 표준화기를 당신은 개발했어요. 주소 정보를 포함한 다음 텍스트에서 표준화하고 하나의 표준화된, 통합된 주소를 출력해야 합니다. 빈 값으로 반환해서는 안 됩니다. 왜냐하면 이 필드의 텍스트에서 합리적인 데이터를 가져오는 방법을 알기 때문이에요: ' ||\nsubstring(locations, 0, 200) as prompt\nfrom `gemini_bq_fn.books`),\nSTRUCT(\n  TRUE AS flatten_json_output));\n```\n\n다음 결과가 표시되어야 합니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_8.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우와! 이렇게 쉽게 BigQuery ML에서 데이터베이스의 원격 모델을 사용할 수 있어요.\n\n이제 다른 Vertex AI 모델을 사용해 빅쿼리 원격 함수를 시도해봅시다. 예를 들어, 빅쿼리에서 원격으로 모델을 사용하는 방법을 더 맞춤화하고 유연하게 사용하고 싶다고 가정해봅시다. 현재 지원되는 모델은 이 문서에서 참조할 수 있어요.\n\n# 사용 사례 #2 원격 함수 구현\n\n여기서는 Gemini 1.0 Pro Vision foundation 모델을 구현하는 Java Cloud Function을 기반으로 빅쿼리에서 함수를 생성할 거에요. 먼저 Gemini 1.0 Pro Vision 모델을 사용해 이미지를 비교하기 위해 Java Cloud Function을 생성하고 배포하고, 그 다음에는 빅쿼리에서 배포된 Cloud Function을 호출하는 원격 함수를 생성할 거에요. 기억해 주세요, 빅쿼리에서의 원격 함수 실행에 대해 동일한 절차를 따를 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Java 클라우드 함수 만들기\n\nGen 2 클라우드 함수를 Java로 생성하여 외부 테이블에 저장된 베이스라인 이미지와 테스트 이미지를 비교하는 기능을 구축할 것입니다. 이 작업은 BigQuery의 테스트 이미지 스크린샷이 포함된 데이터셋을 사용하며 Gemini Pro Vision 모델 (Java SDK)을 이용하여 REST 엔드포인트에 배포됩니다.\n\n# Java 클라우드 함수\n\n- Cloud Shell 터미널을 열고 루트 디렉토리나 기본 작업 공간 경로로 이동합니다.\n- 상태 표시줄의 왼쪽 하단에 있는 Cloud Code 로그인 아이콘을 클릭하고 Cloud Functions을 생성할 Google Cloud 프로젝트를 선택합니다.\n- 다시 아이콘을 클릭하고 이번에는 새 응용 프로그램을 만드는 옵션을 선택합니다.\n- \"새 응용 프로그램 생성\" 팝업에서 Cloud Functions 응용 프로그램을 선택합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image1](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_9.png)\n\n5. Select the \"Java: Hello World\" option from the next pop-up:\n\n![image2](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_10.png)\n\n6. Provide a name for the project in the project path. In this case, it is \"Gemini-BQ-Function\".\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n7. 새로운 Cloud Shell Editor 보기에서 프로젝트 구조가 열린 것을 확인해야합니다:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_11.png)\n\n8. 이제 pom.xml 파일의 `dependencies`...`/dependencies` 태그 안에 필요한 종속성을 추가해주세요.\n\n```xml\n\u003cdependency\u003e\n      \u003cgroupId\u003ecom.google.cloud\u003c/groupId\u003e\n      \u003cartifactId\u003egoogle-cloud-vertexai\u003c/artifactId\u003e\n      \u003cversion\u003e0.1.0\u003c/version\u003e\n   \u003c/dependency\u003e\n\n     \u003cdependency\u003e\n      \u003cgroupId\u003ecom.google.code.gson\u003c/groupId\u003e\n      \u003cartifactId\u003egson\u003c/artifactId\u003e\n      \u003cversion\u003e2.10\u003c/version\u003e\n     \u003c/dependency\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n9. \"HelloWorld.java\" 클래스의 이름을 더 의미 있는 이름인 \"GeminiBigQueryFunction.java\"로 변경하세요. 클래스 이름을 이에 맞게 변경해야 합니다.\n\n10. 아래 코드를 복사하고 파일 \"GeminiBigQueryFunction.Java\"의 플레이스홀더 코드를 대체하세요. Github 레포지토리에서 소스를 참조해주세요.\n\n```js\npackage cloudcode.helloworld;\nimport java.io.BufferedWriter;\nimport com.google.cloud.functions.HttpFunction;\nimport com.google.cloud.functions.HttpRequest;\nimport com.google.cloud.functions.HttpResponse;\nimport com.google.cloud.vertexai.VertexAI;\nimport com.google.cloud.vertexai.api.Blob;\nimport com.google.cloud.vertexai.api.Content;\nimport com.google.cloud.vertexai.generativeai.preview.ContentMaker;\nimport com.google.cloud.vertexai.api.GenerateContentResponse;\nimport com.google.cloud.vertexai.api.GenerationConfig;\nimport com.google.cloud.vertexai.api.Part;\nimport com.google.cloud.vertexai.generativeai.preview.PartMaker;\nimport com.google.cloud.vertexai.generativeai.preview.GenerativeModel;\nimport com.google.cloud.vertexai.generativeai.preview.ResponseStream;\nimport com.google.cloud.vertexai.generativeai.preview.ResponseHandler;\nimport com.google.protobuf.ByteString;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Base64;\nimport java.util.List;\nimport java.util.Arrays;\nimport java.util.Map;\nimport java.util.LinkedHashMap;\nimport com.google.gson.Gson;\nimport com.google.gson.JsonObject;\nimport com.google.gson.JsonArray;\nimport java.util.stream.Collectors;\nimport java.lang.reflect.Type;\nimport com.google.gson.reflect.TypeToken;\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.net.HttpURLConnection;\nimport java.net.URL;\n\n\npublic class GeminiBigQueryFunction implements HttpFunction {\n    private static final Gson gson = new Gson();\n\n\n  public void service(final HttpRequest request, final HttpResponse response) throws Exception {\n    final BufferedWriter writer = response.getWriter();\n   // 요청 본문을 JSON 객체로 가져옵니다.\n    JsonObject requestJson = new Gson().fromJson(request.getReader(), JsonObject.class);\n    JsonArray calls_array = requestJson.getAsJsonArray(\"calls\");\n    JsonArray calls = (JsonArray) calls_array.get(0);\n    String baseline_url = calls.get(0).toString().replace(\"\\\"\", \"\");\n    String test_url = calls.get(1).toString().replace(\"\\\"\", \"\");\n    String prompt_string = calls.get(2).toString().replace(\"\\\"\", \"\");\n    String raw_result = validate(baseline_url, test_url, prompt_string);\n    raw_result = raw_result.replace(\"\\n\",\"\");\n    String trimmed = raw_result.trim();\n    List\u003cString\u003e result_list = Arrays.asList(trimmed);\n    Map\u003cString, List\u003cString\u003e\u003e stringMap = new LinkedHashMap\u003c\u003e();\n    stringMap.put(\"replies\", result_list);\n    // 직렬화\n    String return_value = gson.toJson(stringMap);\n    writer.write(return_value);\n  }\n\n\npublic String validate(String baseline_url, String test_url, String prompt_string) throws IOException{\n  String res = \"\";\n    try (VertexAI vertexAi = new VertexAI(\"YOUR_PROJECT\", \"us-central1\"); ) {\n      GenerationConfig generationConfig =\n          GenerationConfig.newBuilder()\n              .setMaxOutputTokens(2048)\n              .setTemperature(0.4F)\n              .setTopK(32)\n              .setTopP(1)\n              .build();\n    GenerativeModel model = new GenerativeModel(\"gemini-pro-vision\", generationConfig, vertexAi);\n    String context = prompt_string;\n    Content content = ContentMaker.fromMultiModalData(\n     context,\n     PartMaker.fromMimeTypeAndData(\"image/png\", readImageFile(baseline_url)),\n     PartMaker.fromMimeTypeAndData(\"image/png\", readImageFile(test_url))\n    );\n    GenerateContentResponse response = model.generateContent(content);\n     res = ResponseHandler.getText(response);\n  }catch(Exception e){\n    System.out.println(e);\n  }\n  return res;\n}\n\n\n  // 지정된 URL의 이미지 데이터를 읽어옵니다.\n  public static byte[] readImageFile(String url) throws IOException {\n    URL urlObj = new URL(url);\n    HttpURLConnection connection = (HttpURLConnection) urlObj.openConnection();\n    connection.setRequestMethod(\"GET\");\n    int responseCode = connection.getResponseCode();\n    if (responseCode == HttpURLConnection.HTTP_OK) {\n      InputStream inputStream = connection.getInputStream();\n      ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n      byte[] buffer = new byte[1024];\n      int bytesRead;\n      while ((bytesRead = inputStream.read(buffer)) != -1) {\n        outputStream.write(buffer, 0, bytesRead);\n      }\n      return outputStream.toByteArray();\n    } else {\n      throw new RuntimeException(\"Error fetching file: \" + responseCode);\n    }\n  }\n}\n```\n\n11. 이제 Cloud Shell 터미널로 이동하여 아래 명령을 실행하여 클라우드 함수를 빌드하고 배포하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngcloud functions deploy gemini-bq-fn --runtime java17 --trigger-http --entry-point cloudcode.helloworld.GeminiBigQueryFunction --allow-unauthenticated\n```\n\n여기에 결과는 아래와 같은 형식으로 REST URL이 생성됩니다:\n\nhttps://us-central1-YOUR_PROJECT_ID.cloudfunctions.net/gemini-bq-fn\n\n12. 터미널에서 다음 명령을 실행하여 이 클라우드 함수를 테스트해보세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngcloud functions call gemini-bq-fn --region=us-central1 --gen2 --data '{\"calls\":[[\"https://storage.googleapis.com/img_public_test/image_validator/baseline/1.JPG\", \"https://storage.googleapis.com/img_public_test/image_validator/test/2.JPG\", \"PROMPT_ABOUT_THE_IMAGES_TO_GEMINI\"]]}'\n```\n\n임의의 샘플 프롬프트에 대한 응답:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_12.png\" /\u003e\n\n제네릭 Cloud Function을 사용하여 Gemini Pro Vision 모델 구현이 준비되었습니다. 이제 이 엔드포인트를 직접 BigQuery 원격 함수 내에서 BigQuery 데이터에 사용하겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 빅쿼리 오브젝트 테이블 및 원격 함수 만들기\n\n이 데모 애플리케이션에서는 클라우드 스토리지 버킷을 생성해 보겠습니다:\n\n- 클라우드 스토리지 콘솔로 이동하여 생성 버튼을 클릭하여 버킷을 만듭니다.\n- 버킷에 이름을 제공하고 \"demo-bq-gemini-public\"과 같은 이름을 지정한 다음 \"이 버킷에서의 공개 액세스 방지 강화\" 옵션의 선택 해제(공개로 유지)를 기억하세요. 이 데모에서는 이 버킷을 공개 액세스로 설정하고 있지만, 권장하는 방법은 공개 액세스를 방지하고 필요에 따라 특정 서비스 계정에 권한을 부여하는 것입니다.\n- 방금 만든 클라우드 스토리지 버킷의 PERMISSION 탭에서 권한 설정을 보고 변경할 수 있습니다. 원칙을 추가하려면 VIEW BY PRINCIPALS 탭 아래의 GRANT ACCESS를 클릭하고 (특정 계정을 위한) 서비스 계정 ID를 입력하거나 \"allUsers\" (공개 액세스에 대한)를 입력한 후 역할을 \"Storage Object Viewer\"로 설정하고 저장을 클릭합니다.\n- 이제 버킷이 생성되었으므로 OBJECTS 탭으로 이동하여 이미지를 업로드하고 UPLOAD FILES를 클릭하여 업로드하세요.\n- 비교하기 위해 기준 및 테스트 이미지를 업로드하세요.\n\n이 데모를 위해 3개의 객체를 생성하고 기준이고 test1 및 test2를 공개로 사용할 수 있도록 만들었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# BigQuery 객체 테이블 생성\n\nBigQuery에서 외부 객체 테이블을 만들어 생성한 연결 및 데이터셋을 사용하여 버킷의 비구조화된 데이터에 액세스할 수 있습니다. BigQuery 쿼리 에디터 창에서 다음과 같은 DDL(데이터 정의 언어) 문을 실행하세요:\n\n```js\nCREATE OR REPLACE EXTERNAL TABLE `gemini_bq_fn.image_validation`\nWITH CONNECTION `us.gemini-bq-conn`\nOPTIONS(object_metadata=\"SIMPLE\", uris=[\"gs://demo-bq-gemini-public/*.JPG\"]);\n```\n\n이 쿼리는 이전에 만든 데이터셋에 \"image_validation\"이라는 새 객체 테이블을 생성해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# BigQuery 원격 함수 생성\n\nBigQuery에서 Java Cloud Function을 호출하는 원격 함수를 만들어 봅시다. Gemini Pro Vision 모델을 구현한 Java Cloud Function을 호출할 것입니다. 이 함수는 동일한 데이터셋에 만들 것입니다. BigQuery 콘솔의 SQL 편집 창에서 다음 DDL을 실행해 주세요:\n\n```js\nCREATE OR REPLACE FUNCTION `gemini_bq_fn.FN_IMAGE_VALIDATE` (baseline STRING, test STRING, prompt STRING) RETURNS STRING\n  REMOTE WITH CONNECTION `us.gemini-bq-conn`\n  OPTIONS (\n    endpoint = 'https://us-central1-********.cloudfunctions.net/gemini-bq-fn',\n    max_batching_rows = 1\n  );\n```\n\n이렇게 하면 BigQuery에 원격 함수가 생성됩니다. 위의 DDL에는 3개의 매개변수가 있습니다. 처음 두 매개변수는 이전 단계에서 생성된 객체 테이블에 저장된 이미지의 URL입니다. 마지막 매개변수는 모델(Gemini Pro Vision)에 대한 프롬프트입니다. 이 시그니처를 파싱하는 Java Cloud Functions 코드를 참조하시기 바랍니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nGson().fromJson(request.getReader(), JsonObject.class);\nJsonArray calls_array = requestJson.getAsJsonArray(\"calls\");\nJsonArray calls = (JsonArray) calls_array.get(0);\nString baseline_url = calls.get(0).toString().replace(\"\\\"\", \"\");\nString test_url = calls.get(1).toString().replace(\"\\\"\", \"\");\nString prompt_string = calls.get(2).toString();\n```\n\n# BigQuery에서 Gemini 호출하기!\n\n이제 원격 함수가 생성되었으니, 테스트 이미지를 프롬프트와 대조하여 이미지 유효성을 확인하는 원격 함수를 테스트하기 위해 SELECT 쿼리에서 사용해봅시다:\n\n테스트 이미지가 참조와 어떤지 확인하기 위한 쿼리:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nselect gemini_bq_fn.FN_IMAGE_VALIDATE(\n'https://storage.googleapis.com/demo-bq-gemini-public/Baseline.JPG',\nREPLACE(uri, 'gs://', 'https://storage.googleapis.com/') ,\n'전문 이미지 유효성 검사자이며 JSON 결과로 응답할 수 있는 이미지 유효성 검사자입니다. 여기에서 2개의 이미지를 찾을 수 있습니다. 첫 번째 이미지는 기준 이미지이고 두 번째 이미지는 테스트 이미지입니다. 두 번째 이미지가 첫 번째 이미지와 텍스트 측면에서 유사한지 확인하세요. \"YES\" 또는 \"NO\"인 SIMILARITY, 백분율인 SIMILARITY_SCORE, 문자열인 DIFFERENCE_COMMENT 3가지 속성이 포함된 JSON 형식으로만 응답하세요.' ) as IMAGE_VALIDATION_RESULT\nfrom `gemini_bq_fn.image_validation`\nwhere uri like '%TEST1%';\n```\n\n위 쿼리를 TEST1.JPG 및 TEST2.JPG와 함께 시도해보세요. 아래와 유사한 결과를 보게 될 것입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_13.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기준 이미지:\n\n![이미지1](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_14.png)\n\n테스트 이미지:\n\n![이미지2](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_15.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서 확인할 수 있듯이, 두 이미지 모두 Duet AI 클라우드 콘솔 뷰를 가지고 있지만, 두 이미지의 텍스트는 모델에 의해 생성된 JSON 형식에 따라 다릅니다.\n\n# 혜택 및 사용 사례\n\n- 데이터에 GenAI를 적용하세요: 데이터 이동, 중복 및 추가 복잡성이 더 이상 필요하지 않습니다. 동일한 BigQuery 환경 내에서 데이터를 분석하고 인사이트를 생성할 수 있습니다.\n- 향상된 분석: Gemini의 자연어 설명은 데이터에 새로운 이해의 층을 더해주며, SQL 쿼리만을 사용하여 이를 달성할 수 있습니다.\n- 확장성: 이 솔루션은 대규모 데이터셋과 복잡한 분석을 쉽고 Low-Code 방식으로 처리할 수 있습니다.\n\n실제 사례: 금융(시장 트렌드 분석), 소매(고객 감정), 의료(의료 보고서 요약) 등 분석 및 비즈니스 팀이 비교적 적은 노력, 자원 및 익숙한 언어 및 도구를 선택하여 이를 구현할 수 있는 시나리오를 고려해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n축하합니다. Gemini 모델이 BigQuery에 통합되어 데이터 분석을 넘어 데이터 이야기꾼이 되셨습니다. 데이터셋 안에 숨겨진 이야기를 찾아내고 통찰력을 이해하는 방법을 변화시킬 수 있습니다. 지금 실험을 시작하세요! 이 기술을 여러분의 데이터셋에 적용하여 데이터 안에 깔려있는 이야기들을 발견해보세요. BigQuery가 객체 테이블(External Tables)에서 비구조적인 데이터를 지원하므로, 이미지 데이터에 대한 생성적 인사이트를 만들기 위해 Gemini Pro Vision을 사용해보세요. 더 깊은 안내를 위해서 Vertex AI, BigQuery Remote Functions 및 Cloud Functions 문서를 참고하세요. 이 프로젝트의 Github 저장소는 여기에 있습니다. 이 학습으로 어떤 것을 구축하시는지 저에게 알려주세요!\n","ogImage":{"url":"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png"},"coverImage":"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png","tag":["Tech"],"readingTime":25},{"title":"2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들","description":"","date":"2024-05-18 18:13","slug":"2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024","content":"\n## 소프트웨어 개발자가 SQL 및 데이터베이스 개념을 깊이 학습할 수 있는 최고의 온라인 강좌들입니다.\n\n![이미지](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png)\n\n안녕하세요 여러분, SQL과 데이터베이스를 배우고 최고의 Udemy 강좌를 찾고 있다면, 당신이 올바른 곳에 왔습니다.\n\n이전에는 SQL을 배울 수 있는 최적의 위치와 최고의 무료 SQL 강좌를 공유했었는데요, 그 안에는 Udemy나 Coursera 및 다른 웹사이트의 무료 강좌들이 포함되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 초보자와 중급 개발자를 위한 Udemy의 최고의 SQL 강좌를 소개할 것입니다.\n\nSQL은 오랜 시간 동안 중요한 기술 기술이었지만 데이터 과학 및 데이터 분석의 등장으로 인해 데이터의 중요성이 현재 세상에서 더욱 중요해졌습니다.\n\n요즘 회사들 사이에서 데이터 과학 및 분석 직업은 높은 수요가 있으며 사용자들의 대량 데이터 및 기타 정보를 활용하여 이 데이터에 대한 통찰을 얻고 회사의 성장을 위한 더 나은 결정을 내리는 데 중요한 역할을 합니다. 데이터와 관련된 모든 직업이 SQL 언어를 배우는 것을 필요로 한다는 공통점이 있습니다.\n\nSQL은 회사의 데이터를 저장하기 위한 데이터베이스를 구축하고 데이터베이스와 상호 작용하기 위해 SQL 쿼리라고 불리는 명령을 사용하여 정보를 추출하고 데이터 분석 목적을 위해 필요한 정보만 남기기 위해 필터링하는 사람들을 위한 가장 인기 있는 언어입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터베이스는 테이블의 모음이며, 각 테이블에는 데이터를 보유하는 행(row)과 열(column)이 포함되어 있습니다.\n\n이 언어를 배우는 것은 대부분의 다른 언어보다 쉽습니다. 심지어 Python보다도 쉽죠. SQL을 배우는 데 투자한 시간과 비용은 데이터 관련 분야의 취업을 원하는 학생들에게 좋은 투자입니다. 이는 당신을 경쟁자들보다 우위에 서게 할 겁니다.\n\n온라인에서 수천 개의 SQL 코스가 제공되지만, 당신의 시간과 노력을 가치 있게 만들어주는 코스를 찾는 것은 쉽지 않습니다. 이 글에서는 내 검색 결과에 따라 가장 좋은 코스를 제안하겠습니다.\n\n그런데, 만약 급한 대로 배우려 한다면, Udemy의 '15 Days of SQL: The Complete SQL Masterclass 2024' 코스를 참여하는 것을 제안합니다. 이 Udemy의 새 SQL 코스는 실생활 프로젝트에서 SQL을 딱 15일 만에 가르쳐줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_1.png\" /\u003e\n\n# 2024년 소프트웨어 개발자를 위한 최고의 SQL 및 데이터베이스 강좌 6선 - Udemy 및 Coursera 온라인 학습\n\n2024년에 온라인으로 배울 수 있는 최고의 Udemy 강좌 목록입니다. 이 강좌들은 SQL을 사용해 본 적은 있지만 깊이 있는 지식으로 습득하고 싶은 초보자 및 중급 개발자들을 위한 적합한 강좌입니다.\n\n## 1. The Complete SQL Bootcamp 2024: 처음부터 전문가까지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nJose Portilla가 만든 이 강좌에는 41만 명 이상의 수강생이 있습니다. 이 데이터베이스나 이 언어에 이전 경험이 없는 초보자를 위한 이 가이드로 SQL 언어 학습 여정을 시작하는 것을 적극 추천합니다.\n\n이 강좌를 통해 SELECT 및 COUNT와 같은 간단한 SQL 명령어를 데이터베이스에 적용하는 방법, 그리고 GROUP BY 문을 사용하는 방법을 배울 수 있습니다. 또한 이 강좌는 PostgreSQL을 기반으로 하며 PostgreSQL 데이터베이스를 사용합니다.\n\n그런 다음 JOIN 명령어를 사용하여 여러 테이블에서 데이터를 검색하는 방법을 배우고 특정 데이터를 추출하기 위한 일부 고급 SQL 명령어를 익힐 수 있습니다. 마지막으로 PostgreSQL 데이터베이스에서 데이터베이스 및 테이블을 생성하는 방법도 배울 수 있습니다.\n\n여기 이 강좌에 가입할 수 있는 링크가 있습니다 - The Complete SQL Bootcamp 2024: 제로부터 히어로까지 변화하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_2.png\" /\u003e\n\n## 2. The Ultimate MySQL Bootcamp [Udemy Course]\n\n또 한 번 소개할 만한 좋은 강의는 이 최고의 MySQL 부트캠프이다. 이 코스에는 20시간 이상의 비디오 콘텐츠와 26.4만 명의 학생이 참여하고 있다.\n\n먼저 MySQL 데이터베이스의 중요 개념과 해당 환경을 컴퓨터에 설치하는 방법을 이해할 수 있게 될 것이고, 이후 MySQL에서 데이터베이스와 테이블을 생성하는 방법으로 나아갈 것이다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러면 이 데이터베이스에 데이터를 삽입하는 방법과 기타 사항을 배울 것입니다.\n\nSQL 언어에서 CRUD 명령문에 대해 알게 될 것입니다: 생성(Create), 조회(Read), 갱신(Update), 삭제(Delete) 쿼리에 대해 배울 것입니다. 또한 집계 함수에 대해 배우고 논리 연산자의 힘을 탐색할 것입니다.\n\n마지막으로 Node.js와 MySQL 데이터베이스를 사용하여 작은 웹 앱을 만들 것입니다.\n\n이 코스에 참여하기 위한 링크는 여기에 있습니다 — The Ultimate MySQL Bootcamp\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_3.png)\n\n## 3. 데이터 분석 및 비즈니스 인텔리전스를 위한 MySQL\n\n만약 데이터 분석가가 되려고 한다면, 이 강의가 적합할 것입니다. SQL 언어뿐만 아니라 Tableau 소프트웨어와 결합하여 데이터 시각화를 쉽게 할 수 있습니다.\n\n우선 데이터베이스가 어떻게 작동하고 데이터를 저장하는지 이해하고, MySQL을 설치하고 SQL 명령어로 연습을 시작할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSQL의 기본 명령어인 SELECT, INSERT, UPDATE, DELETE 및 집계 함수와 몇 가지 고급 주제를 학습한 후, 마지막으로 Tableau 소프트웨어와 결합하여 데이터 시각화를 수행할 수 있습니다.\n\n이 강좌에 참여하려면 다음 링크를 클릭하세요 — MySQL for Data Analytics and Business Intelligence\n\n[링크](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_4.png)\n\n## 4. SQL 초보자를 위한강좌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 강좌에는 8시간 이상의 비디오 콘텐츠가 포함되어 있으며 MySQL 데이터베이스를 사용하여 시네마 예매 시스템을 만드는 실제 예제를 제공합니다.\n\nSQL 언어를 사용하기 전에 시스템에 MySQL 데이터베이스를 설치하고 주요 및 외래 키, 테이블과 같은 데이터베이스 개념을 이해할 수 있습니다.\n\n이 언어를 사용하여 테이블과 많은 테이블에서 데이터를 선택하고 간단한 SQL 명령을 사용하여 정보를 추출하는 방법을 배우게 됩니다. 데이터베이스 설계 및 데이터베이스 내에서 다양한 관계를 이해하고 시네마 예매 시스템과 같은 프로젝트를 개발합니다.\n\n이 강좌에 가입하려면 여기를 클릭하세요 - SQL for Beginners\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![마크다운](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_5.png)\n\n## 5. 초보를 위한 Microsoft SQL\n\n우리 목록에서 마지막으로 소개하는 이 코스는 마이크로소프트 SQL 서버에서 SQL 언어를 사용하는 방법을 가르쳐 줍니다. 이는 수백만 명의 사용자가 데이터베이스로 사용하고 있는 서비스를 사용하는 데 도움이 될 것입니다.\n\n먼저 간단한 SQL 명령어를 이해하고 적용한 다음, WHERE 절을 사용하여 데이터를 필터링하고 데이터를 정렬하며 여러 테이블에서 데이터를 추출하고 집계 함수를 사용하는 방법을 배울 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 수업에 참여하려면 다음 링크를 클릭해주세요 — Microsoft SQL for Beginners\n\n![Microsoft SQL for Beginners](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_6.png)\n\n## 6. 데이터 과학을 위한 SQL\n\nUdemy를 좋아하지 않거나 Coursera와 같은 인기 있는 학습 플랫폼에서 최고의 SQL 과정을 찾고 있다면, 이 수업을 확인해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 과학을 위한 SQL은 Coursera에서 가장 인기 있는 강좌 중 하나입니다.\n\nSQL의 기본을 마스터하여 데이터 과학자처럼 데이터를 분석할 수 있게 될 것입니다.\n\n이 강좌를 마친 후 여러 종류의 데이터, 문자열과 정수를 사용하고, 기본 및 복잡한 데이터 선택 쿼리를 수행할 수 있으며 SQL의 원리를 이해할 수 있게 될 것입니다.\n\nWomen in Data의 창립자/CEO이자 데이터 과학자인 Sadie St. Lawrence가 이 Coursera 강좌를 가르칩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 코스에 가입하려면 링크를 확인해보세요 — SQL For Data Science\n\n![이미지](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_7.png)\n\n그리고, Coursera 코스가 유용하다고 생각되시나요? 전 세계적으로 유명한 기업과 대학에서 만들어졌기 때문에 그렇습니다. Coursera Plus에 가입하는 것을 추천드립니다. 이 구독 플랜은 Coursera의 가장 인기 있는 강좌, 전문 강의, 프로페셔널 인증, 그리고 가이드 프로젝트에 무제한 액세스를 제공해요. 매년 $399이나 월 단위로 $59이 들지만, 돈을 완전히 가치 있게 쓸 수 있을 거라고 생각해요. 왜냐하면 무제한 인증서를 받을 수 있기 때문이거든.\n\n2024년에 SQL과 데이터베이스를 배우기 위한 최고의 Udemy와 Coursera 온라인 강좌는 여기까지에요. 이 목록에는 SQL 기본 사항과 데이터베이스 기초를 배울 수 있는 수업들, 그리고 MySQL, PostgreSQL, 그리고 Microsoft SQL Server와 같은 인기 데이터베이스를 배울 수 있는 온라인 강좌가 포함되어 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 SQL을 배우는 데 적합한 데이터베이스로 수업을 듣는다는 것을 의미합니다. 이것은 초보자들의 관점에서 매우 중요합니다.\n\nSQL 언어를 배우는 것은 데이터 과학자나 데이터 분석가와 같은 데이터와 관련된 모든 직업의 중요한 부분입니다.\n\n웹 개발자라도 데이터베이스를 사용하여 이 언어를 배우고 프로페셔널하게 사용해야 합니다. 왜냐하면 이것이 당신의 경쟁자들에게 이점을 줄 것이기 때문입니다.\n\n만약 이러한 강좌들을 좋아하지 않고 연습이 가득한 부트캠프 스타일의 강좌를 찾고 있다면 Andrei Negaoie의 Complete SQL and Databases Bootcamp 강좌가 시작하기에 좋은 강좌입니다. 이 강좌는 주요 SQL 개념을 가르치기 위한 연습과 SQL 쿼리가 가득합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고, 2024년에 SQL을 배우는 가장 좋은 방법을 보여주는 ByteByteGo의 멋진 비디오가 여기 있어요!\n\n탐색해볼 수 있는 다른 SQL 및 개발 코스\n\n- JavaScript를 배우기 위한 10가지 최고의 Udemy 코스\n- Python을 배우기 위한 10가지 최고의 Udemy 코스\n- 2024년을 위한 10가지 최고의 Udemy 코스\n- 풀 스택 웹 개발자로 성장하기 위한 10가지 코스\n- 2024년에 TypeScript를 무료로 배울 수 있는 10가지 코스\n- 초보자를 위한 Angular를 배우기 위한 나의 좋아하는 코스\n- 무료로 Ruby 및 Rails를 배울 수 있는 5가지 코스\n- 2024년 React JS 개발자 로드맵\n- 웹 개발자를 위한 PHP 및 MySQL 학습을 위한 5가지 수업\n- 무료로 블록체인 기술을 배울 수 있는 5가지 코스\n- Oracle 및 Microsoft SQL Server 데이터베이스를 배울 수 있는 5가지 코스\n- 초보자를 위한 10가지 Python 웹 개발 코스\n- 풀 스택 개발자 로드맵\n- Servlet, JSP 및 JDBC를 배울 수 있는 무료 강좌 5개\n- Java 및 DevOps 엔지니어를 위한 Docker 무료 코스 5가지\n- 2024년에 JavaScript를 배울 수 있는 13가지 무료 코스\n- Java에서 RESTful 웹 서비스를 배우기 위한 3권의 책 및 강좌\n- 2024년에 Angular를 배울 수 있는 5가지 무료 코스\n- 풀스택 개발자가 배워야 할 10가지 프레임워크\n\n지금까지 이 기사를 읽어주셔서 감사합니다. 만약 SQL을 배우기 위한 이 최고의 Udemy 코스들이 마음에 든다면, 친구들과 동료들과 공유해주세요. 이 목록에는 Udemy의 최고의 MySQL, PostgreSQL 및 Microsoft SQL Server 코스가 포함되어 있습니다. 질문이나 피드백이 있으시면, 댓글을 남겨주세요.\n\n참고: 만약 SQL 및 데이터베이스에 새로 입문한 분이라면, 여행을 시작할 무료 SQL 코스를 찾고 계시다면, 초보자를 위한 무료 SQL 및 데이터베이스 코스도 확인해보세요. 이 코스들은 Udemy 및 Coursera에서 법적으로 무료로 제공되며 SQL 개념, 데이터베이스 기본 개념, SQL 쿼리 작성 방법 등을 배울 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png"},"coverImage":"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png","tag":["Tech"],"readingTime":11},{"title":"ML, 데이터 팀을 위한 Gen AI","description":"","date":"2024-05-18 18:10","slug":"2024-05-18-MLGenAIfordatateams","content":"\n## 고전적인 ML 사용 사례와 Gen AI를 위한 신뢰성 있는 설계 구축\n\nAI와 ML은 대부분의 데이터 팀에게 중요한 주제입니다. 회사들은 AI로 실질적인 영향을 얻고 있으며, 데이터 팀은 이 중심에 있어 자신의 작업을 ROI에 결부시키는 원하는 방법을 얻고 있습니다.\n\n최근 예로, AI가 스웨덴의 '지금 살고 나중에 지불' 핀테크 Klarna를 위해 700명의 정근 연애를 자동화하는 데 도움을 주었습니다. Intercom은 이제 AI 중심의 고객 서비스 플랫폼이 되었으며, 임원들은 Gen AI 사용 사례를 구현하는 데 직접적으로 연관된 OKR을 가지고 있습니다.\n\n이 게시물에서는 데이터 팀에서 일하는 경우 이것이 무슨 의미를 하는지 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데이터 팀에서의 AI 현황\n\nAI는 많이 발전했습니다. 실제로 그렇습니다. 스탠포드 대학의 2024 AI 지수 보고서에 따르면 AI는 이미지 분류, 시각적 추론, 그리고 영어 이해와 같은 여러 벤치마크에서 인간의 성능을 넘어섰다고 합니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요즘에는 ML 및 AI에 대한 수요가 급증하여 많은 데이터 팀이 업무 우선 순위를 재조정하게 되었습니다. 이는 ML 및 AI에서 데이터 팀의 역할에 대한 질문을 답하지 못한 채 남아 있습니다. 저희 경험상 데이터가 소유한 부분과 엔지니어가 소유한 부분 사이의 경계가 여전히 모호한 상황입니다.\n\ndbt가 최근 수천 명의 데이터 실무자를 대상으로 조사한 결과, 데이터 팀이 AI 및 ML에 참여하는 정도에 대한 정보를 얻을 수 있었습니다.\n\nAI 도입의 신호는 있지만, 대부분의 데이터 팀은 아직 일상적인 업무에 AI를 사용하고 있지 않습니다. 현재 응답자 중 1/3만이 오늘날 AI 모델 훈련을 위한 데이터를 관리하고 있습니다.\n\n![그림](/assets/img/2024-05-18-MLGenAIfordatateams_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 곧 변경될 수 있습니다. 55%의 사람들이 곧 AI가 자가 데이터 탐색을 위해 혜택을 누리기를 기대하고 있습니다.\n\n![AI 및 ML use cases](/assets/img/2024-05-18-MLGenAIfordatateams_2.png)\n\n이는 우리가 1,000개 이상의 데이터 팀과 대화한 경험을 반영한 것입니다. 현재의 노력은 주로 데이터 분석을 위한 데이터 준비, 대시보드 유지 및 이해관계자 지원에 집중되어 있지만, AI 및 ML에 투자하고자 하는 욕망이 있습니다.\n\n# AI 및 ML 사용 사례\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nML과 AI가 수십 년 동안 존재해왔다는 것을 알아야 합니다. 최신 AI 모델인 Gen AI 모델은 텍스트에서 SQL 코드를 생성하거나 비즈니스 질문에 자동으로 답변하는 것과 같은 첨단 사용 사례에 가장 적합할 수 있지만, 분류 및 회귀 모델과 같은 더 검증된 방법들도 중요한 목적을 가지고 있습니다.\n\n가장 인기 있는 기술들 중 일부는 다음과 같습니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_3.png)\n\n# 고전적인 머신 러닝 사용 사례\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n대부분의 팀은 아직 전통적인 머신러닝 방법을 사용하지 않고 있습니다. 예를 들어, 분류, 회귀, 이상 감지와 같은 방법들이 있습니다. 이러한 방법들은 특히, 당신이 예측하고자 하는 명확한 결과 (예: 위험한 고객)와 예측 기능 (예: 가입 국가, 나이, 이전 사기)이 명확한 감독 학습에 유용할 수 있습니다.\n\n이러한 시스템들은 종종 설명하기 쉽고, 각 기능의 상대적 중요성을 추출할 수 있어 이를 통해 이유를 설명하기 쉽습니다. 이로써 이해관계자에게 고위험 고객을 거부하는 결정이 내려진 이유를 설명할 수 있게 됩니다.\n\n아래의 머신러닝 시스템은 고객 위험 점수 모델을 강조하며, 새로 가입한 사용자가 고위험 고객인지 거부해야 할 가능성이 얼마나 높은지를 예측합니다.\n\n![image](/assets/img/2024-05-18-MLGenAIfordatateams_4.png)\n\n다양한 소스에서 수집된 원시 데이터를 활용하여 예측 기능을 구축하며, 이는 데이터 과학자의 전문 지식과 모델이 식별한 예상치 못한 패턴을 결합합니다. 핵심 개념은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Sources 및 데이터 마트: 시스템에서 추출된 원시 및 가공되지 않은 데이터로 데이터 과학자가 관련성이 있는 것으로 판단한 것\n- 특성: ML 모델에 공급되는 전처리된 데이터 (예: 대도시의 거리, 나이, 이전 사기)\n- 레이블: 이전 위험한 고객을 기반으로 한 목표 출력 (예/아니오)\n- 트레이닝: 기계 학습 모델에 내부 매개변수나 가중치를 레이블된 예시에 기반하여 조정하여 정확한 예측을 수행할 수 있도록 가르치는 반복적인 프로세스\n- 추론: 트레이닝 단계 이후 새로운, 보이지 않은 데이터에 대해 예측이나 분류를 수행하기 위해 훈련된 기계 학습 모델을 사용하는 것\n\n데이터 팀과의 협업을 통해, 전통적인 ML 작업 흐름의 많은 부분이 데이터 웨어하우스로 이동되어 데이터 소스 및 피처 저장소의 기반이 되는 것을 볼 수 있습니다. 주요 데이터 웨어하우스는 이를 직접 제공하도록 시작했으며(예: BigQuery ML), 미래에는 전체적인 ML 작업 흐름이 데이터 웨어하우스로 완전히 이동할 것을 시사합니다.\n\n전통적인 ML 모델의 성공을 위한 일반적인 도전 과제는 다음과 같습니다:\n\n- 이용 가능한 데이터를 바탕으로 모델이 원하는 결과를 정확하고 적합한 수준으로 예측할 수 있는가\n- 달성된 정확도와 적합도 수준이 비즈니스에 대한 ROI로 충분한가\n- 이 작업을 수행하기 위해 우리가 해야 하는 트레이드 오프는 무엇인가(예: 위험한 고객을 검토하기 위해 더 많은 운영 직원)\n- 모델 유지 및 모니터링에 대한 유지와 모니터링의 비용은 얼마인가\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 차세대 및 Gen AI 사용 사례\n\n최근 몇 년간 차세대 및 특히 Gen AI 사용 사례에 대한 이야기가 소개되었으며 ChatGPT 3의 효율성으로 유명해졌습니다. 이 분야는 새로운 것이며 비즈니스 ROI가 아직 증명되지 않았지만 잠재력은 매우 큽니다.\n\n아래는 데이터 팀을 위해 본 Gen AI 사용 사례 중에서 가장 인기 있는 몇 가지입니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n오늘의 사용 사례는 크게 두 가지 영역으로 그룹화될 수 있어요.\n\n- 비즈니스 가치 향상 — 고객 지원 챗봇에서 간단한 고객 상호 작용을 자동화하거나 고객 답변을 관련 지식 베이스 기사와 매칭하는 등 비즈니스 프로세스를 자동화하거나 최적화합니다.\n- 데이터 팀 생산성 향상 — 근본적인 데이터 워크플로우를 단순화하여 기술에 능통하지 않은 분석가가 ‘텍스트를 SQL로’ 쓸 수 있도록 하거나 비즈니스 이해자가 제시한 자연어 질문에서 답변을 생성함으로써 비즈니스 이해자의 즉각적인 요청을 줄입니다.\n\n아래는 비즈니스에 관련된 특정 데이터 말뭉치를 기반으로 ChatGPT의 사용자 버전을 설정하는 샘플 아키텍처입니다. 시스템은 두 부분으로 구성됩니다: (1) 도메인 데이터의 데이터 적재 및 (2) 실시간으로 질문에 답변할 수 있도록 데이터를 쿼리합니다.\n\n![image](/assets/img/2024-05-18-MLGenAIfordatateams_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예제 정보 검색 시스템 (출처: Langchain)\n\n첫 번째 단계는 문서를 벡터 저장소에 로드하는 것입니다. 이 과정에는 서로 다른 소스에서 데이터를 결합하거나 엔지니어들과 함께 생 데이터를 다루는 것, 그리고 모델이 교육받지 않아도 되는 데이터를 수동으로 제거하는 것(예: 고객 만족도 낮은 지원 응답)이 포함될 수 있습니다.\n\n- 특정 텍스트 말뭉치에서 텍스트로 데이터 소스 로드\n- 전처리하고 텍스트를 작은 조각으로 나누기\n- 단어들의 유사성에 따라 단어의 벡터 공간을 만들기 위해 임베딩 만들기\n- 임베딩을 벡터 저장소에 로드하기\n\n임베딩에 익숙하지 않다면, 단어나 문서의 숫자적 표현이고 이들 사이에 존재하는 의미와 관계를 포착하는 것이다. 아래 코드 스니펫을 실행하면 실제로 무엇인지 볼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nfrom gensim.models import Word2Vec\n# 문장 말뭉치 정의\ncorpus = [\n    \"the cat sat on the mat\",\n    \"the dog barked loudly\",\n    \"the sun is shining brightly\"\n]\n# 문장 토큰화\ntokenized_corpus = [sentence.split() for sentence in corpus]\n# Word2Vec 모델 학습\nmodel = Word2Vec(sentences=tokenized_corpus, vector_size=3, window=5, min_count=1, sg=0)\n# 단어 임베딩 획득\nword_embeddings = {word: model.wv[word].tolist() for word in model.wv.index_to_key}\n# 단어 임베딩 출력\nfor word, embedding in word_embeddings.items():\n    print(f\"{word}: {embedding}\")\n```\n\n도메인 데이터를 벡터 저장소에 입력한 후, 사전에 학습된 LLM을 세밀하게 조정하여 도메인과 관련된 질문에 답변하는 시스템을 확장할 수 있습니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_7.png)\n\n예시 정보 검색 시스템 (출처: Langchain)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사용자는 채팅과 새로운 질문을 결합하여 후속 질문을 할 수 있습니다.\n위의 임베딩 및 벡터 저장소를 사용하여 유사 문서를 찾을 수 있습니다.\n큰 언어 모델(ChatGPT와 같은)을 사용하여 유사 문서를 활용하여 응답을 생성할 수 있습니다.\n\n다행히도 Meta와 Databricks와 같은 기업들이 교육 및 오픈소스 모델을 제공하고 있으므로 (Huggingface는 현재 1000여 개 이상의 Llama 3 오픈소스 모델을 보유하고 있습니다) 자체 모델을 교육시키기 위해 수백만 달러를 소비할 필요가 없습니다. 대신 기존 모델을 데이터로 세밀하게 조정하세요.\n\n위와 같은 LLM(Large Language Model) 기반 시스템의 효과는 그들에게 주어지는 데이터의 품질에 달려 있습니다. 따라서 데이터 전문가들은 여러 소스에서 가져온 가능한 많은 데이터를 피드하는 것이 장려되며, 이들 소스가 어디에서 오는지 추적하고 데이터가 예상대로 흐르는지 확인하는 것이 최우선 과제여야 합니다.\n\nGen AI 모델의 성공을 위한 전형적인 도전 과제는:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 모델을 충분히 훈련할 만한 데이터가 있나요? 개인정보 문제로 사용이 제한되는 데이터가 있나요?\n- 모델이 해석 가능하고 설명 가능해야 하는가요? 예를 들어 고객이나 규제기관을 위해\n- LLM을 훈련하고 세부 조정하는 것에 대한 잠재적 비용은 무엇인가요? 그 혜택이 이 비용을 상회하나요?\n\n# AI와 ML에서 데이터 품질의 중요성\n\n당신의 주요 데이터 전달은 의사 결정에 도움을 주는 BI 대시보드를 위해 무작위 통찰을 제공할 때, 인간이 개입합니다. 인간의 직관과 기대로 인해 데이터 문제나 설명할 수 없는 추세가 종종 발견됩니다 — 그리고 아마도 몇 일 안에 해결됩니다.\n\nML과 AI 시스템은 다릅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nML 시스템이 수백 개 또는 수천 개의 다양한 소스에서 가져온 기능에 의존하는 것은 흔한 일입니다. 간단한 데이터 문제처럼 보일 수 있는 것들 — 누락된 데이터, 중복, 널 값 또는 빈 값, 이상치 — 이들은 비즈니스에 중대한 문제를 일으킬 수 있습니다. 이를 세 가지 다른 방법으로 생각해 볼 수 있습니다.\n\n- 비즈니스 중단 — 모든 사용자 ID가 비어 있는 중대한 오류는 새 사용자 가입 승인 비율이 90% 감소할 수 있습니다. 이러한 유형의 문제는 비용이 많이 들지만 종종 초기에 발견됩니다.\n- 드리프트 또는 '잠재적' 문제 — 이는 고객 분포의 변경이나 특정 세그먼트에 대한 누락된 값을 포함할 수 있으며, 이로 인해 체계적으로 부정확한 예측이 발생할 수 있습니다. 이러한 문제는 발견하기 어려우며, 몇 달 또는 몇 년 동안 지속될 수 있습니다.\n- 체계적인 편향 — Gen AI와 같은 경우, 데이터 수집에 대한 인간의 판단이나 결정으로 편향이 발생할 수 있습니다. 구글의 Gemini 모델에서 발생한 편견과 같이 최근 예들은 이러한 결과가 가져다 줄 수 있는 결과를 강조했습니다.\n\n회귀 모델을 지원하거나 LLM을 위한 새로운 텍스트 말뭉치를 작성 중이더라도, 새로운 모델을 개발하는 연구자가 아닌 한, 업무의 대부분은 데이터 수집 및 전처리에 관련될 것입니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nML 시스템은 모델이 하나의 부분에 불과한 대규모 생태계입니다. — Google on Production ML Systems\n\n일반적으로, 화면 왼쪽에 위치할수록 오류를 모니터링하기 어려울 수 있습니다. 수백 개의 입력 및 원시 소스가 있어서 때로는 데이터 관련 전문가의 통제 영역을 벗어날 수 있으며, 데이터는 수천 가지 방법으로 잘못될 수 있습니다.\n\n![MLGenAIfordatateams_9](/assets/img/2024-05-18-MLGenAIfordatateams_9.png)\n\n모델 성능은 ROC, AUC 및 F1 점수와 같이 잘 알려진 메트릭을 사용하여 간단히 모니터링할 수 있으며, 이러한 메트릭은 모델 성능의 단일 측정 항목을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상류 데이터 품질 문제의 예시\n\n- 결측 데이터: 데이터셋의 불완전하거나 없는 값은 모델이 일반화하고 정확한 예측을 하는 능력에 영향을 미칠 수 있습니다.\n- 일관성 없는 데이터: 서로 다른 소스 또는 시간에 따라 다양한 형식, 단위 또는 표현으로 인한 데이터 변이는 모델 학습 및 추론 중 혼동과 오류를 유발할 수 있습니다.\n- 이상치: 대부분의 관측치와 유별난 점이 큰 데이터의 이상치 또는 특이치는 모델 학습에 영향을 주고 편향적이거나 부정확한 예측을 유발할 수 있습니다.\n- 중복 레코드: 데이터셋에 중복된 항목이 들어 있는 경우 모델의 학습 과정을 왜곡시킬 수 있으며, 모델이 훈련 데이터에서 성능이 우수하지만 새로운, 보지 못한 데이터에서는 성능이 저하될 수 있습니다.\n\n데이터 이동의 예시\n\n- 계절별 제품 선호도: 계절에 따른 고객 선호도의 변화가 전자 상거래 추천에 영향을 미칩니다.\n- 금융 시장 변동: 경제적 사건으로 인한 시장의 급격한 변동이 주식 가격 예측 모델에 영향을 미치는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLLM에 대한 텍스트 데이터의 데이터 품질 문제 예시\n\n- 품질이 낮은 입력 데이터: 챗봇은 정확한 과거 사례 해결을 기반으로 작동합니다. 이 데이터의 정확성에 따라 봇의 효과가 결정되며, 잘못된 정보를 배우는 것을 피해야 합니다. 고객 만족도나 해결 점수가 낮은 답변은 모델이 잘못된 정보를 학습했을 수 있다는 신호일 수 있습니다.\n- 오래된 데이터: 의료 상담 봇은 오래된 정보에 의존할 수 있어서 관련성이 적은 권장 사항을 제공할 수 있습니다. 특정 일자 이전에 작성된 연구는 더 이상 목적에 부합하지 않을 수 있음을 나타낼 수 있습니다.\n\n# 신뢰할 수 있는 머신 러닝 및 인공지능 시스템 구축\n\n우리는 데이터 팀이 소프트웨어 엔지니어링과 비교했을 때 신뢰할 수 있는 데이터 시스템을 제공하는 데 신뢰받지 못한다고 믿습니다. 인공지능 파동은 \"쓰레기를 넣으면 쓰레기가 나온다\" 모델과 그 모든 함의를 기하급수적으로 확장하고 있습니다. 모든 기업이 경쟁 우위를 위한 데이터를 활성화하는 새로운 방법을 찾는 압박 속에 있을 때입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n특정 도구와 시스템이 모델 성능을 모니터링하기 위해 사용되지만, 이러한 도구들은 종종 데이터 웨어하우스의 상위 소스와 데이터 변환을 고려하지 않습니다. 데이터 신뢰성 플랫폼은 이를 위해 구축되었습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-MLGenAIfordatateams_10.png\" /\u003e\n\n# 안정적인 ML 및 AI 시스템 구축을 위한 다섯 가지 요추\n\n고품질의 제품용 ML 및 AI 시스템을 지원하고 유지하기 위해 데이터 팀은 엔지니어들의 최상의 실천 방법을 채택해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![img](/assets/img/2024-05-18-MLGenAIfordatateams_11.png)\n\n- 성실한 테스트 — ML 및 AI 시스템에 공급되는 상위 소스 및 출력이 의도적으로 테스트되어야 함 (이상값, 널 값, 분포 변화, 품질)\n- 소유자 관리 — ML 및 AI 시스템은 명확한 소유자가 할당되어 문제를 통지받고 조치를 취하기를 기대해야 함\n- 사건 처리 — 심각한 문제는 명확한 SLA 및 에스컬레이션 경로를 가진 사건으로 취급되어야 함\n- 데이터 제품 마인드셋 — ML 및 AI 시스템으로 공급되는 전체 가치 사슬을 하나의 제품으로 고려해야 함\n- 데이터 품질 메트릭스 — 데이터 팀은 ML 및 AI 시스템의 가동 시간, 오류, SLA 등 핵심 메트릭을 보고할 수 있어야 함\n\n한 축에만 집중하는 것은 드물게 충분하지 않습니다. 명확한 소유권이 없는 채로 테스트에 과도하게 투자하면 문제가 슬립할 수 있습니다. 소유에 투자하지만 의도적으로 사건을 관리하지 않으면 심각한 문제가 너무 오랫동안 해결되지 않을 수 있습니다.\n\n![img](/assets/img/2024-05-18-MLGenAIfordatateams_12.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중요한 점은 다섯 가지 데이터 신뢰성 기둥을 구현하는 데 성공한다고 해도 문제가 발생하지 않는다는 것이 아니라, 단지 미리 발견할 가능성이 더 높아지고 자신감을 키워 고객에게 시간이 지남에 따라 어떻게 개선되고 있는지 전달할 수 있다는 것입니다.\n\n# 요약\n\n현재 데이터 팀 중 33%만이 AI 및 ML 모델을 지원하지만 대부분은 가까운 미래에 지원할 것으로 예상합니다. 이러한 변화는 데이터 팀이 비즈니스 중요 시스템을 지원하고 소프트웨어 엔지니어처럼 더 많이 일해야 한다는 새로운 세계에 적응해야 한다는 것을 의미합니다.\n\n- 데이터 팀에서의 AI 상황 - AI 시스템은 이미지 분류, 시각적 추론 및 영어 이해와 같은 여러 기준에서 성능이 향상되고 있습니다. 현재 데이터 팀 중 33%가 생산 중인 AI 및 ML을 사용하지만 55%의 팀이 예상됩니다.\n- AI 사용 사례 - 분류 및 회귀에서 Gen AI까지 다양한 ML 및 AI 사용 사례가 있습니다. 각 시스템은 도전적인 과제를 제기하지만 \"고전적인 ML\"과 Gen AI 간의 차이는 명백합니다. 우리는 이를 고전적인 고객 위험 예측 모델과 정보 검색 챗봇을 통해 살펴봤습니다.\n- AI 및 ML 시스템의 데이터 품질 - 데이터 품질은 ML 및 AI 프로젝트의 성공에 가장 중요한 위험 중 하나입니다. AI 및 ML 모델이 종종 수백 개의 데이터 소스에 의존하는데, 문제를 수동으로 감지하는 것은 거의 불가능합니다.\n- 믿을 수 있는 데이터를 위한 다섯 가지 단계 - ML 및 AI 시스템을 지원하고 유지하기 위해 데이터 팀은 엔지니어처럼 더 많이 일해야 합니다. 이에는 지속적인 테스트, 명확한 소유권, 사건 관리 프로세스, 데이터 제품 마인드셋 및 가동 시간 및 SLA와 같은 지표에 대한 보고 능력이 포함됩니다.\n","ogImage":{"url":"/assets/img/2024-05-18-MLGenAIfordatateams_0.png"},"coverImage":"/assets/img/2024-05-18-MLGenAIfordatateams_0.png","tag":["Tech"],"readingTime":15},{"title":"데이터 웨어하우징을 위한 5가지 사이버보안 팁","description":"","date":"2024-05-18 18:08","slug":"2024-05-18-5CybersecurityTipsforDataWarehousing","content":"\n\u003cimg src=\"/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png\" /\u003e\n\n데이터 웨어하우징은 대규모 AI 및 기계 학습 애플리케이션을 훨씬 더 관리하기 쉽게 만듭니다. 모든 것을 한 곳에 가지고 있으면 더 빠르고 정확한 분석이 가능해지지만, 동시에 일부 보안 문제를 야기할 수도 있습니다. 이러한 대규모로 통합된 데이터베이스는 사이버 범죄자들에게 유혹이 되는 대상이므로 면밀한 보호가 필요합니다.\n\n조직 간에도 데이터 웨어하우스 자체가 다양하듯이 특정 보안 시스템도 다양합니다. 그럼에도 불구하고 설정과는 상관없이 몇 가지 모범 사례를 도입해야 합니다. 고려해야 할 다섯 가지 주요 사이버 보안 팁을 소개합니다.\n\n# 1. 데이터 익명화 및 암호화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 창고에서 모든 데이터를 암호화하는 것이 첫 번째 단계입니다. 데이터에 높은 암호화 표준을 적용하면, 해커들이 액세스하더라도 그것이 쓸모없게 만들어질 것입니다. 홀모모르픽 암호화와 같은 새로운 기술은 당신이 데이터를 복호화하기 전에도 암호화된 데이터를 사용할 수 있도록 한 단계 더 나아간 것입니다.\n\n사용하는 데이터 유형에 따라 데이터를 익명화해야 할 수도 있습니다. 이는 개인 식별자를 제거하여 개인 정보 침해를 방지하는 프로세스입니다. 실제 세계의 수치를 합성 데이터로 교체하는 것이 가장 안전한 방법이지만, 데이터가 실제 세계 사람들을 반영해야 하는 경우 역동적 익명화가 좋은 대안입니다.\n\n## 2. 액세스 권한 제한\n\n데이터 창고 사이버 보안의 다음 단계는 사용자의 액세스 권한을 제한하는 것입니다. 이 작업에 접근하는 가장 좋은 방법은 최소 권한 원칙(Least Privilege Principle, PoLP)을 따르는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPoLP(Principle of Least Privilege)는 작업을 올바르게 수행하기 위해 필요한 것만 액세스할 수 있어야 한다고 주장합니다. 기계 학습 모델과 작업하지 않는 직원은 기계 학습 훈련을 위해 구체적으로 데이터 웨어하우스에 액세스할 수 없어야 합니다. 마찬가지로, 데이터 과학자는 급여 데이터를 볼 수 없어야 합니다.\n\n액세스 권한 제한은 두 가지 주요 이점이 있습니다. 첫째, 주어진 데이터 웨어하우스에 영향을 미칠 수 있는 사람 수를 줄임으로써 발생하는 74%의 데이터 침해와 관련된 인적 오류를 최소화합니다. 둘째, 공격자가 한 계정을 침해하면 측면 이동을 최소화합니다.\n\n# 3. 인증 조치 향상\n\n권한 제한은 신뢰할 수 있는 방법으로 누가 누구인지 판별할 수 있을 때에만 효과가 있음을 기억하세요. 따라서, PoLP를 강력한 인증 조치와 함께 실행해야 합니다. 가장 기본적인 수준에서는 다중 요소 인증(MFA)이 시행되어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMFA는 여러 방법으로 실행할 수 있지만, 모든 방법이 동일한 수준의 보안을 제공하는 것은 아닙니다. 예를 들어 SMS 기반 인증은 이메일 인증보다 더 안전합니다. 특정 장치에 액세스가 필요하기 때문입니다. 생체 인증은 암호보다 해킹이 더 어려울 수 있지만, 공격자가 생체 데이터에 액세스하면 변경할 수 없으므로, 민감한 창고에는 이상적이지 않을 수 있습니다.\n\n# 4. 데이터 분류 및 조직화\n\n데이터 웨어하우징 보안에서 놓치기 쉬운 하지만 여전히 중요한 단계는 데이터를 분류하는 것입니다. 조직화는 사이버 보안 문제보다는 작업 문제처럼 보일 수 있지만, 중요한 보안적 영향을 많이 미칩니다.\n\n먼저, 볼 수 없는 것은 안전으로 보호할 수 없습니다. 보안 소프트웨어 사용자의 약 60%가 데이터의 40% 미만만 분석한다고 합니다. 이는 중요한 취약점을 놓칠 수 있거나 침해를 인식하지 못할 수 있음을 의미합니다. 조직의 부재는 시각성을 제한하기 때문에 데이터를 분류하여 그룹으로 구성하여 보다 철저한 취약점 분석과 빠른 사고 대응을 가능하게 해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n분류는 엑세스 권한을 정제하는 데도 도움이 됩니다. 데이터를 사용 또는 민감도에 따라 정렬하면 누가 액세스할 수 있는지 결정하고 해당 정책을 시행하는 데 도움이 됩니다. 또한 행동 생체 인식을 구현할 수 있어 이로 인해 평상시에는 액세스할 수 없는 데이터에 접근하는 경우 경고를 받을 수 있습니다.\n\n# 5. 창고를 면밀히 모니터링하십시오\n\n이러한 변경 사항을 시행한 후 데이터 창고를 지속적으로 모니터링해야 합니다. 어떤 방어 기법도 100% 효과적일 수는 없지만, 신속한 대응은 침해 사건 발생 시 피해를 최소화할 것입니다. 새로운 위협에 대응하거나 실시간 보안 사건에 대응할 수 있는 유일한 방법은 지속적인 모니터링을 통해 가능합니다.\n\n인공지능과 자동화는 여기서 꼭 필요합니다. 24시간 수동 모니터링은 많은 보안 인력이 필요합니다. 대부분의 기관에게는 선택사항이 아닙니다. 세계적으로 노동력 수요가 증가하더라도 사이버 보안 직원은 340만 명이 부족합니다. 자동화된 네트워크 모니터링은 실시간 사건 제한 및 부족한 보안 직원을 보완하기 위한 경고를 제공할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데이터 웨어하우징 보안에 대한 주의가 필요합니다\n\n데이터 웨어하우스는 한 대의 큰 데이터베이스를 보호하는 것이 여러 개의 자원에 분산하는 것보다 쉽기 때문에 보안이 개선됩니다. 그러나 동시에, 그 크기 때문에 눈에 띄는 관심을 끄는 경우가 있습니다, 특히 민감한 정보를 저장하는 경우에는 더욱 그렇습니다.\n\n이러한 위험 요소들을 고려하여 데이터 웨어하우징 사이버 보안은 필수적입니다. 기존의 보안 시스템에 다음 다섯 가지 모범 사례를 통합하여 데이터 웨어하우스를 가능한 한 안전하게 유지하십시오.\n\n최초 게시물: OpenDataScience.com\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nOpenDataScience.com에서 데이터 과학 관련 기사를 더 읽어보세요. 초보자부터 고급 수준까지의 튜토리얼과 안내서를 만나보실 수 있습니다! 매주 목요일마다 최신 소식을 받아보고 싶으시다면 여기를 클릭하여 주간 뉴스레터를 구독해보세요. 또한 Ai+ 트레이닝 플랫폼을 통해 언제 어디서든 데이터 과학을 학습할 수 있습니다. ODSC 이벤트에 참석하고 싶으신가요? 다가오는 이벤트에 대해 더 알아보고 싶으시다면 여기를 클릭해주세요.\n","ogImage":{"url":"/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png"},"coverImage":"/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png","tag":["Tech"],"readingTime":5},{"title":"Delta 테이블을 REST API를 통해 노출하는 방법","description":"","date":"2024-05-18 18:06","slug":"2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs","content":"\n## 델타 테이블을 제공하기 위해 토론 및 테스트된 세 가지 아키텍처\n\n![이미지](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png)\n\n# 1. 소개\n\n메달리온 아키텍처 내의 델타 테이블은 일반적으로 데이터 제품을 생성하는 데 사용됩니다. 이러한 데이터 제품은 데이터 과학, 데이터 분석 및 보고를 위해 사용됩니다. 그러나 데이터 제품을 REST API를 통해 노출하는 것도 일반적인 문제입니다. 이 아이디어는 이러한 API를 더 엄격한 성능 요구 사항을 갖춘 웹 앱에 내장하는 것입니다. 중요한 질문은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데팔타 테이블에서 데이터를 읽는 것이 웹 애플리케이션에 빠르게 서비스할 수 있을까요?\n솔루션을 확장할 수 있는 컴퓨팅 레이어가 필요할까요?\n엄격한 성능 요구 사항을 충족시키기 위한 스토리지 레이어가 필요할까요?\n\n이러한 질문에 대해 심층적으로 다루기 위해 세 가지 아키텍처가 다음과 같이 평가됩니다: 아키텍처 A — API의 라이브러리, 아키텍처 B — 컴퓨팅 레이어 및 아키텍처 C — 스토리지 레이어. 아래 이미지 참조하세요.\n\n![image](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_1.png)\n\n블로그 글의 나머지 부분에서 세 가지 아키텍처에 대한 설명을 제공하고, 배포 및 테스트를 수행한 후 결과를 도출합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 2. 아키텍처 설명\n\n## 2.1 아키텍처 A: DuckDB와 PyArrow를 사용한 API 내 라이브러리\n\n이 아키텍처에서는 API가 직접 델타 테이블에 연결되어 있으며 중간에 계산 레이어가 없습니다. 이는 데이터가 API 자체의 메모리와 계산을 사용하여 분석된다는 것을 의미합니다. 성능을 향상시키기 위해 내장 데이터베이스 DuckDB와 PyArrow의 Python 라이브러리를 사용합니다. 이러한 라이브러리는 API에서 필요한 열만로드되도록 보장합니다.\n\n![이미지](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 아키텍처의 장점은 데이터를 중복으로 만들 필요가 없으며 API와 델탔 테이블 사이에 필요한 레이어가 없다는 것입니다. 이는 구성 요소가 적다는 것을 의미합니다.\n\n이 아키텍처의 단점은 확장하기 어렵고 모든 작업을 API의 컴퓨팅 및 메모리에서 처리해야 한다는 것입니다. 특히 많은 양의 데이터를 분석해야 하는 경우에는 특히 도전적입니다. 이는 많은 레코드, 큰 컬럼 또는 많은 동시 요청에서 나올 수 있습니다.\n\n## 2.2 아키텍처 B: Synapse, Databricks 또는 Fabric을 사용하는 컴퓨팅 레이어\n\n이 아키텍처에서 API는 컴퓨팅 레이어에 연결되고 델탔 테이블에 직접 연결되지 않습니다. 이 컴퓨팅 레이어는 델타 테이블에서 데이터를 가져와 데이터를 분석합니다. 컴퓨팅 레이어는 Azure Synapse, Azure Databricks 또는 Microsoft Fabric일 수 있으며 일반적으로 잘 확장됩니다. 데이터는 컴퓨팅 레이어로 중복되지 않지만 컴퓨팅 레이어에서 캐싱을 적용할 수 있습니다. 이 블로그의 남은 부분에서는 Synapse Serverless로 테스트 되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_3.png)\n\n이 아키텍처의 장점은 데이터를 중복하여 저장할 필요가 없으며 아키텍처가 잘 확장된다는 것입니다. 또한 대규모 데이터 세트를 처리하는 데 사용할 수 있습니다.\n\n이 아키텍처의 단점은 API와 델타 테이블 사이에 추가적인 레이어가 필요하다는 것입니다. 이는 더 많은 이동 부품을 유지 및 보안해야 한다는 의미입니다.\n\n## 2.3 아키텍처 C: Azure SQL이나 Cosmos DB를 사용한 최적화된 저장 레이어\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 아키텍처에서 API는 델타 테이블에 직접 연결되지 않고, 델타 테이블이 복제된 다른 저장 계층에 연결됩니다. 다른 저장 계층은 Azure SQL 또는 Cosmos DB일 수 있습니다. 이 저장 계층은 데이터를 빠르게 검색하기 위해 최적화될 수 있습니다. 이 블로그의 나머지 부분에서는 Azure SQL을 사용하여 테스트를 진행합니다.\n\n![이미지](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_4.png)\n\n이 아키텍처의 장점은 저장 계층이 인덱스, 파티셔닝 및 머티얼라이즈드 뷰를 사용하여 데이터를 빠르게 읽을 수 있도록 최적화될 수 있다는 것입니다. 이는 주로 요청-응답 웹 앱 시나리오에서 요구 사항입니다.\n\n이 아키텍처의 단점은 데이터가 중복되어야 하며 API와 델타 테이블 사이에 추가적인 계층이 필요하다는 것입니다. 이는 더 많은 구성 요소를 유지보수하고 보안해야 한다는 의미입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n블로그의 나머지 부분에서 아키텍처를 배포하고 테스트합니다.\n\n# 3. 아키텍처 배포 및 테스트\n\n## 3.1 아키텍처 배포\n\n아키텍처를 배포하기 위해 이전 장에서 논의한 세 가지 솔루션을 배포하는 GitHub 프로젝트가 생성되었습니다. 해당 프로젝트는 아래 링크에서 확인할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nhttps://github.com/rebremer/expose-deltatable-via-restapi\n```\n\n다음은 GitHub 프로젝트를 실행할 때 배포될 내용입니다:\n\n- 표준 테스트 데이터 세트 WideWorldImporterdDW full에서 시작한 델타 테이블. 테스트 데이터 세트는 50백만 건의 레코드와 22개 열로 구성되어 있으며 1개의 큰 설명 열이 있습니다.\n- 모든 아키텍처: API로 작용하는 Azure Function.\n- 아키텍처 B: 컴퓨팅 계층으로 작용하는 Synapse Serverless.\n- 아키텍처 C: 최적화된 저장 계층으로 작용하는 Azure SQL.\n\n배포된 후 테스트를 실행할 수 있습니다. 다음 단락에서 테스트에 대해 설명하겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.2 테스트 아키텍처\n\n아키텍처를 테스트하기 위해 다양한 유형의 쿼리 및 다른 스케일링을 적용할 것입니다. 다양한 유형의 쿼리는 다음과 같이 설명할 수 있습니다:\n\n- 11개의 작은 열(char, integer, datetime)을 포함하는 20개 레코드를 조회합니다.\n- 각 필드당 500자 이상을 포함하는 큰 설명 열이 포함된 2개 열을 사용하여 20개 레코드를 조회합니다.\n- 그룹별 데이터 집계, having, max, average를 사용한 데이터 집계.\n\n아래에서 쿼리를 설명합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```sql\n-- 쿼리 1: 대형 텍스트 없이 11개 열의 포인트 조회\nSELECT SaleKey, TaxAmount, CityKey, CustomerKey, BillToCustomerKey, SalespersonKey, DeliveryDateKey, Package\nFROM silver_fact_sale\nWHERE CityKey=41749 and SalespersonKey=40 and CustomerKey=397 and TaxAmount \u003e 20\n-- 쿼리 2: 500자 이상의 Description 열\nSELECT SaleKey, Description\nFROM silver_fact_sale\nWHERE CityKey=41749 and SalespersonKey=40 and CustomerKey=397 and TaxAmount \u003e 20\n-- 쿼리 3: 집계\nSELECT MAX(DeliveryDateKey), CityKey, AVG(TaxAmount)\nFROM silver_fact_sale\nGROUP BY CityKey\nHAVING COUNT(CityKey) \u003e 10\n```\n\n다음과 같이 스케일링이 가능합니다:\n\n- 아키텍처 A의 경우, 데이터 처리는 API 자체에서 수행됩니다. 이는 API의 컴퓨트 및 메모리가 앱 서비스 플랜을 통해 사용된다는 것을 의미합니다. SKU Basic(1코어 및 1.75GB 메모리) 및 SKU P1V3 SKU(2코어, 8GB 메모리)로 테스트될 것입니다. 아키텍처 B 및 C의 경우에는 처리가 다른 곳에서 이루어지기 때문에 이러한 정보는 해당하지 않습니다.\n- 아키텍처 B의 경우, Synapse Serverless가 사용됩니다. 스케일링은 자동으로 이루어집니다.\n- 아키텍처 C의 경우, 표준 티어의 Azure SQL 데이터베이스가 125 DTU로 사용됩니다. CityKey에 인덱스가 없는 상태와 CityKey에 인덱스가 있는 상태에서 테스트될 것입니다.\n\n다음 단락에서 결과가 설명됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.3 결과\n\n아키텍처를 배포하고 테스트한 후에는 결과를 얻을 수 있습니다. 다음은 결과 요약입니다:\n\n![Results](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_5.png)\n\n아키텍처 A는 SKU B1로 배포할 수 없습니다. 만약 SKU P1V3가 사용된다면, 컬럼 크기가 크지 않다면 결과는 15초 이내에 계산될 수 있습니다. 모든 데이터를 API 앱 서비스 계획에서 분석한다는 점을 유의하십시오. 너무 많은 데이터가로드되면(많은 행, 큰 컬럼 및/또는 많은 동시 요청으로),이 아키텍처는 확장하기 어려울 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아키텍처 B는 Synapse Serverless를 사용하여 10-15초 내에 작동합니다. 계산은 데이터를 가져와 분석하기 위해 자동으로 조정되는 Synapse Serverless에서 이루어집니다. 성능은 세 가지 유형의 쿼리에 대해 일관되게 유지됩니다.\n\n아키텍처 C는 Azure SQL을 사용할 때 인덱스가 생성되면 가장 잘 작동합니다. 조회 쿼리 1과 2의 경우 API는 대략 1초 내에 응답합니다. 쿼리 3은 전체 테이블 스캔이 필요하며 성능은 다른 솔루션과 거의 동일합니다.\n\n# 3. 결론\n\n중재 아키텍처의 Delta 테이블은 일반적으로 데이터 제품을 생성하는 데 사용됩니다. 이러한 데이터 제품은 데이터 과학, 데이터 분석 및 보고서 작성에 사용됩니다. 그러나 일반적으로 Delta 테이블을 REST API를 통해 노출하는 것도 자주 묻는 질문 중 하나입니다. 이 블로그 포스트에서는 이와 같은 장단점을 갖는 세 가지 아키텍처가 설명되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nArchitecture A: DuckDB 및 PyArrow를 사용하여 API 내 라이브러리를 활용하는 아키텍처입니다.\n이 아키텍처에서는 API가 직접 델타 테이블에 연결되어 중간 계층이 없습니다. 이는 모든 데이터가 메모리에서 분석되고 Azure Function의 연산을 함께 함을 의미합니다.\n\n- 이 아키텍처의 장점은 추가 리소스가 필요하지 않다는 것입니다. 이는 유지 및 보안해야 하는 부분이 적기 때문에 이점으로 작용합니다.\n- 이 아키텍처의 단점은 API 자체에서 모든 데이터를 분석해야 하기 때문에 확장성이 떨어진다는 것입니다. 따라서 소량의 데이터에만 사용해야 합니다.\n\nArchitecture B: Synapse, Databricks 또는 Fabric을 사용한 컴퓨팅 레이어.\n이 아키텍처에서는 API가 컴퓨팅 레이어에 연결됩니다. 이 컴퓨팅 레이어는 델타 테이블에서 데이터를 가져와 분석합니다.\n\n- 이 아키텍처의 장점은 확장성이 좋고 데이터가 중복되지 않습니다. 집계를 수행하며 대량의 데이터를 분석하는 쿼리에 적합합니다.\n- 이 아키텍처의 단점은 조회 쿼리에 일관되게 5초 이내의 응답을 받는 것이 불가능하다는 것입니다. 또한 추가 리소스를 보안 및 유지해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아키텍처 C: Azure SQL 또는 Cosmos DB를 사용한 최적화된 저장 계층입니다.\n\n이 아키텍처에서는 API가 최적화된 저장 계층에 연결됩니다. 델타 테이블이 미리 이 저장 계층으로 복제되며 데이터를 검색하고 분석하는 데 사용됩니다.\n\n- 이 아키텍처의 장점은 인덱스, 파티셔닝, 머티얼라이즈드 뷰를 사용하여 룩업의 빠른 쿼리를 위해 최적화될 수 있다는 것입니다. 이것은 종종 요청-응답 웹 앱에 필요한 요구사항입니다.\n- 이 아키텍처의 단점은 데이터가 다른 저장 계층으로 중복되어 동기화가 유지되어야 한다는 것입니다. 또한 추가 자원을 보안하고 유지해야 합니다.\n\n안타깝게도, 완벽한 해결책은 없습니다. 이 글은 REST API를 통해 델타 테이블을 노출하는 데 가장 적합한 아키텍처를 선택하는 데 도움을 주기 위한 가이드를 제시했습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png"},"coverImage":"/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png","tag":["Tech"],"readingTime":10}],"page":"102","totalPageCount":119,"totalPageGroupCount":6,"lastPageGroup":19,"currentPageGroup":5},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"102"},"buildId":"wOkGEDZCvEs3S_XaNsdwr","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>