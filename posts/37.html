<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/37" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/37" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_buildManifest.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="2024년 데이타브릭스 데이터  AI 서밋에서의 소감들" href="/post/2024-06-19-ReflectionsfromDatabricksDataAISummit2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 데이타브릭스 데이터  AI 서밋에서의 소감들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ReflectionsfromDatabricksDataAISummit2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 데이타브릭스 데이터  AI 서밋에서의 소감들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">2024년 데이타브릭스 데이터  AI 서밋에서의 소감들</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="DSPy와 Amazon Bedrock을 사용하여 견고한 AI 시스템 구축하기" href="/post/2024-06-19-BuildingRobustAISystemswithDSPyandAmazonBedrock"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="DSPy와 Amazon Bedrock을 사용하여 견고한 AI 시스템 구축하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-BuildingRobustAISystemswithDSPyandAmazonBedrock_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="DSPy와 Amazon Bedrock을 사용하여 견고한 AI 시스템 구축하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">DSPy와 Amazon Bedrock을 사용하여 견고한 AI 시스템 구축하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="5개의 무료 엔드 투 엔드 데이터 엔지니어링 프로젝트" href="/post/2024-06-19-5FREEEnd-To-EndDataEngineeringProjects"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="5개의 무료 엔드 투 엔드 데이터 엔지니어링 프로젝트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-5FREEEnd-To-EndDataEngineeringProjects_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="5개의 무료 엔드 투 엔드 데이터 엔지니어링 프로젝트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">5개의 무료 엔드 투 엔드 데이터 엔지니어링 프로젝트</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기" href="/post/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법" href="/post/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Redis를 S3 Express로 재구축하기" href="/post/2024-06-19-RebuildingRedisonS3Express"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Redis를 S3 Express로 재구축하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Redis를 S3 Express로 재구축하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Redis를 S3 Express로 재구축하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다" href="/post/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기" href="/post/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS 인터뷰 질문 DAY_25 90" href="/post/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS 인터뷰 질문 DAY_25 90" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS 인터뷰 질문 DAY_25 90" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS 인터뷰 질문 DAY_25 90</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">27<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁" href="/post/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link posts_-active__YVJEi" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"2024년 데이타브릭스 데이터  AI 서밋에서의 소감들","description":"","date":"2024-06-19 12:18","slug":"2024-06-19-ReflectionsfromDatabricksDataAISummit2024","content":"\n![Reflections from Databricks Data + AI Summit 2024](/assets/img/2024-06-19-ReflectionsfromDatabricksDataAISummit2024_0.png)\n\n# 개요:\n\n2024년 Databricks Data + AI Summit에 참석한 것은 눈을 뜨게 하는 경험이었어요. 놀라운 주제 발표에서부터 분과 세션, 그리고 연구 내용까지 깊게 들여다보며, 이번 세미나는 오늘날의 디지턈 환경에서 높은 품질의 데이터와 AI의 변혁적인 힘을 강조했어요.\n\n이 개인적인 관점에서, 나에게 정말 기억에 남는 이벤트로 만든 몇 가지 주요 포인트와 영감을 주는 이야기들을 탐구해보겠어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 주요 연설:\n\n데이터브릭스는 이러한 연설들이 대부분 자가 마케팅과 자기 홍보에 관한 것이라는 내 생각을 바꿨어.\n\n- 나는 첫 번째 주요 연설에 마음이 없이 참석했어. 시간에 맞춰 도착했음에도 불구하고, 객석에는 16,000명 이상이 참석하여 수용 능력을 초과했어. 두 연설 모두 놀라운 발표와 데모로 이뤄진 롤러코스터 경험이었어 (나는 다음 섹션에서 조금 더 자세히 다룰 거야).\n- 데이터브릭스는 간단하게 유지했고, 그들이 실제 세계와 실제 사용 사례/문제를 해결하려고 했다는 것을 깨달았어. \"쉽게 얻을 수 있는 열매(l﻿ow-hanging fruit)\" 라는 용어를 들어봤어? 데이터 세계의 모든 사람들 — 엔지니어, 데이터 과학자, 분석가, 제품 관리자 및 리더들 — 매일 이러한 문제에 직면해. 그들의 모든 발표와 연설은 이 주제와 일치하며, Gen AI 시대의 기회와 혁신을 강조했어.\n- 대부분의 연설자는 분명히 데이터브릭스 출신이었어. 그들은 유용한 통찰, 새로운 구현 및 산업 트렌드를 공유했어. 몇 명의 다른 기술 기관 출신인 추가적인 중요 인물들로부터 이러한 트렌드가 확인되었어. 가죽 자켓을 입은 록스타 CEO를 포함한 다른 기술 기관 출신 중요 인물들도 포함돼. 내 새로운 조언, 내 3살 아이에게까지 하는 것은 이제 \"고통을 바라\"야!\n\n# 기술적 발표:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDatabricks에서는 상당수의 릴리스가 있었는데, 그중 몇 가지를 발견해서 흥미롭다고 생각했습니다. 몇 개를 소개해 드리겠습니다. 뭔가 놓친 부분이 있을 수 있으니 양해 부탁드립니다.\n\n- 완전히 서버리스: 휴, 정말 감사합니다. 엔지니어의 업무를 훨씬 쉽게 만들어 줍니다. 오랫동안 기다려왔고 유지보수 및 비용 절감 가능성에 흥분하고 있어요!\n- AI BI: 이제 새로 발표된 GA 기능이 제공하는 것을 달성하기 위해 제3자 시각화 도구를 적게 사용할 것이라 확신합니다. 추가 보너스로 제공되는 Genie 기능을 활용하여 NLP를 사용해 제품용으로 준비된 즉석 대시보드를 생성할 수 있습니다!\n- 노코드 파인 튜닝: 데이터의 이 측면에 대해 전문가는 아니지만, 노코드를 사용한 모델 파인 튜닝이 게임 체인저가 될 것이라는 동료 데이터 과학자로부터 흥미로운 확언을 받았습니다!\n- LakeFlow ETL: 이제 다른 도구보다 Databricks를 선호하지 않았던 엔지니어들을 위한 노코드 솔루션입니다. 일괄 처리 또는 스트리밍 데이터의 가져오기를 위해 많은 코드를 작성해야 하는가요? 이제 그럴 필요가 없어졌습니다!\n- LLMOps 및 Mosaic AI 에이전트 프레임워크/평가: MlFlow의 ML 모델 프레임워크가 게임 체인저였다고 생각한다면, 이 기능도 즐길 것입니다. MLOps와 유사한 LLMOps(ML 오퍼레이션)가 공개되었을 때 Databricks는 이 분야에서 각 플랫폼보다 앞서 있다는 것을 증명했습니다.\n- 데이터 거버넌스, 모니터링 및 운영 탐지: 개인적으로 이것은 모든 ETL 도구에 내장되어야 한다고 생각하는 제가 특별히 좋아하는 부분입니다. Lakehouse로 자동화된 방식으로 이를 얼마나 구현했는지에 대해 너무나 흥미롭습니다!\n- Spark 4.0 발표: 현재는 이에 대해 넘어갈 거예요. Spark 3.x에서 제공되는 최신 기능을 모두 사용하지는 않겠다고 자신합니다. 그래도 제공되는 기능을 따르는 것에는 여전히 흥미를 느끼고 있습니다!\n- Unity Catalog OSS: \"마지막이지만 최고의\" 또는 여기에서 맥락을 두기 위해 \"위에 소개된 기능을 즐기고 싶다면 필수\"라고 말할 수 있습니다. Unity 표를 통해 모든 주요 SQL 엔진 및 데이터 형식에 액세스할 수 있습니다. 게임 체인저! 채택은 어려울 수 있지만 Databricks는 필요한 모든 지원을 제공하기 위해 열정적인 것으로 보입니다. 그리고, 'Spark'ing CTO가 라이브 영상에서 Git 리포를 공개한 것도 그만한 멋진 일이었습니다.\n\nLakeFlow 엔지니어링 디렉터와 쿠키 광고에 관한 마케팅 캠페인 제품 관리자의 멋진 데모에 큰 찬사를 보냅니다(실시간 디버깅이 재미있었고 잘 작동해서 기뻤습니다!). 또한 ‘X 배 더 저렴하고/빠르다’와 같은 기능 수준의 KPI가 매우 참신했습니다.\n\n# 특별한 언급 — Compound AI Systems Workshop:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 것들은 키노트 중에 고수준 발표/데모였습니다. 우리가 다 알다시피, \"악마는 세부 사항에 있다\"고 합니다. 그러한 세션 중에서 더 자세히 다루는 유용한 세션들이 몇 가지 있었습니다.\n\n- 모든 세션 또는 최고의 세션을 참석하는 것은 인간적으로 불가능하지만, 많은/대부분은 가상으로도 이용 가능할 것입니다, 이미 제공되고 있지 않다면.\n- 특별히, '워크샵'이라고 명시된 세션 중 어떤 것이라도 참석하시는 것을 강력히 권장합니다. 그리고 또한 7시간 동안 진행되는 세션 중 어떤 것이라도 참석해보세요. 이것이 개인적으로 저에게 가장 깨우침을 주는 경험이었으며 제게 Gen AI 분야의 놀라운 현재 연구자들의 마음에 들어가볼 수 있는 기회를 제공해주었습니다.\n- 영감을 주는 20-30개의 연구 주제 포스터가 있었습니다. 초록문을 차분히 읽거나 작가들의 이야기를 듣거나 심지어 데이터 애호가들로부터의 질문들을 관찰하는 것은 새로운 경지로 나를 인도해주었습니다.\n- 또한 교육, 로봇 공학 등 분야의 선도적인 연설자들이 참석하였으며 Anthropic, DeepMind, OpenAI, Microsoft, LangChain 등 최신 트렌드의 Gen AI 기관에서 온 패널리스트들과 함께 논의가 마무리되었습니다.\n\n# 마지막으로:\n\n가죽자켓을 입은 CEO가 정확하게 지적했습니다 - \"무엇이든 시작해보세요. 이것은 빠르게 움직이는 기차입니다. 지수적인 추세를 기다려보거나 관찰하고 있기 원치 않으실 겁니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저번 주에 이 서밋 전에, 제가 따라가며 읽어본 상대적인 AI 구현을 강화하기 위해 Snowflake가 발표한 멋진 기능들에 대해 알아보았어요. 이 글을 큰 생각과 함께 마무리 짓는군요 — \"다음 단계는 너야, Snowflake. 이미!\"\n\nPS: 서밋을 통해 제게 지지를 보내준 리더, 팀 그리고 조직에게 정말 큰 감사를 표합니다!\n","ogImage":{"url":"/assets/img/2024-06-19-ReflectionsfromDatabricksDataAISummit2024_0.png"},"coverImage":"/assets/img/2024-06-19-ReflectionsfromDatabricksDataAISummit2024_0.png","tag":["Tech"],"readingTime":5},{"title":"DSPy와 Amazon Bedrock을 사용하여 견고한 AI 시스템 구축하기","description":"","date":"2024-06-19 12:16","slug":"2024-06-19-BuildingRobustAISystemswithDSPyandAmazonBedrock","content":"\n## 프롬프트 매직에서 프롬프트 엔지니어링으로 변경\n\n![이미지](/assets/img/2024-06-19-BuildingRobustAISystemswithDSPyandAmazonBedrock_0.png)\n\n인공 지능이 다양한 산업을 혁신하면서, AI 모델을 개발하고 배포하기 위한 견고하고 확장 가능한 도구에 대한 필요성은 이제껏 없었습니다. 이 분야의 주목할만한 발전로는 Stanford의 최신 데이터 과학 도구인 DSpy와 AWS의 기계 학습을 위한 혁신적인 기반인 Amazon Bedrock이 있습니다. 이 블로그 글은 DSpy와 Amazon Bedrock 사이의 특징, 기능 및 독특한 시너지에 대해 파헤치며, 개발자와 데이터 과학자가 AI의 경계를 넓히는 데 어떻게 도움을 주는지 강조합니다.\n\n# DSPy란 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n%pip 설치 dspy-ai\n```\n\nDSPy는 스탠포드 NLP에서 개발한 오픈 소스 라이브러리로, 데이터 과학 워크플로우를 만들고 관리하는 프로세스를 간소화하기 위해 설계되었습니다. 이는 세 가지 핵심 구성 요소인 Signatures, Modules 및 Optimizers을 중심으로 구축되어 있습니다.\n\n## Signatures\n\nDSPy의 서명은 언어 모델(LM) 작업의 입력/출력 동작을 모듈식이고 적응적인 방식으로 정의합니다. Signatures는 길고 취약한 프롬프트에 의존하는 대신, 깨끗하고 재현 가능한 코드를 허용합니다. 서명의 예로는 질문 답변을 위한 `»question -` answer»`나 요약을 위한 `»document -` summary»`가 있습니다. 작업 요구 사항에 따라 서명은 간단하거나 복잡할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 모듈\n\nDSPy의 모듈은 LM 프로그램의 구성 요소입니다. 각 모듈은 chain-of-thought나 retrieval-augmented generation과 같은 특정 프롬프팅 기술을 추상화합니다. 모듈은 다양한 시그니처를 처리할 수 있으며, PyTorch와 같은 프레임워크의 신경망 레이어처럼 더 큰 프로그램으로 구성될 수 있습니다. 이를 통해 유연하고 확장 가능한 프로그램 구성이 가능해집니다.\n\n## 옵티마이저\n\nDSPy의 옵티마이저는 DSPy 프로그램의 매개변수를 세밀하게 조정하여 프로그램의 출력을 최적화합니다. 그들은 기울기 하강법과 이산 최적화 기술의 조합을 사용하여 메트릭을 최대화하거나 일반적으로 프로그램의 출력을 평가하는 함수에 점수를 부여합니다. 다양한 종류의 옵티마이저가 제공되며, 각각 다른 데이터 시나리오와 최적화 요구에 맞게 맞춤화됩니다. 옵티마이저가 가장 잘 작동하도록하려면 일부 학습 입력을 제공해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Amazon Bedrock을 사용하는 방법\n\n## 구성\n\n첫 번째 단계는 DSPy를 구성하여 기본적으로 Amazon Bedrock을 사용하도록 설정하는 것입니다:\n\n```js\nimport dspy\n\nbedrock_haiku = dspy.AWSAnthropic(\n    aws_provider = dspy.Bedrock(region_name=\"us-west-2\"),\n    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n)\ndspy.configure(lm=bedrock_haiku)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLLM 구성이 마무리되었으니 문제 해결을 시작할 수 있어요.\n\n## 서명 및 모듈\n\n공식 DSPy 설명서에서 제안하는 대로 \"DSPy를 사용하는 8 단계\"를 따라서 작업을 정의해 보겠습니다. 처음에는 간단하게 질문과 답변 프로그램을 만들어 보죠. 따라서 우리의 입력은 질문이 되고, 출력은 답변이 될 거예요. 이를 위해 우리의 서명과 모듈을 정의할 수 있습니다:\n\n\\js\nqa = dspy.Predict(\"question -\u003e answer\")\n\\\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 예시에서 예측은 우리의 모듈이며, 예측을 생성하는 것이 목표이며, 서명은 질문 - 답변입니다. 이는 우리가 DSPy에게 질문에서 답변을 찾고 있다는 것을 간결하게 설명하는 줄임표기법입니다. qa를 출력하면 다음 출력이 나타납니다:\n\n```js\nPredict(StringSignature(question -\u003e answer\n    instructions='주어진 필드 `question`으로 `answer` 필드를 생성하십시오.'\n    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n))\n```\n\nDSPy는 질문과 답변이 문자열임을 추론하고, 지시사항에서 강조된 프롬프트를 언어 모델의 입력으로 사용합니다. 타입을 직접 제어할 수도 있습니다:\n\n```js\ndspy.TypedPredictor(\"question:str -\u003e answer:int\")\n\n# 출력\nTypedPredictor(StringSignature(question -\u003e answer\n    instructions='주어진 필드 `question`으로 `answer` 필드를 생성하십시오.'\n    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n    answer = Field(annotation=int required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n))\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nModule Predict에서 정의된 프롬프트를 통해, DSPy는 프롬프트 엔지니어링 프로세스를 반복하고 제어할 수 있는 개념을 소개합니다. 이 클래스를 사용하여 다음 질문에 대한 답변을 생성해보겠습니다:\n\n```js\nqa(question=\"Sergio Mattarella는 누구인가?\").answer\n\n# 출력\n주어진 질문에 대한 답변은 다음과 같습니다:\n질문: Sergio Mattarella는 누구인가?\n답변: Sergio Mattarella는 현재 이탈리아의 대통령입니다. 그는 2015년부터 대통령으로 재직하고 있습니다.\n```\n\n## 서명 및 모듈을 위한 고급 구성\n\n이제 프로그램의 동작을 수정하기 위해 서명과/또는 모듈을 사용자 정의할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ndspy.Modules에 대해 이야기해보겠습니다. 이 라이브러리에서 제공하는 다른 모듈을 사용하거나 사용자 정의 모듈을 만들 수 있습니다:\n\n- dspy.Predict: 기본 예측자입니다. 서명을 수정하지 않습니다. 학습의 주요 형태(즉, 지시 및 데모의 저장 및 LM 업데이트)를 처리합니다.\n- dspy.ChainOfThought: 서명의 응답을 확정하기 전 단계별로 생각하도록 LM에 가르칩니다.\n- dspy.ProgramOfThought: 실행 결과에 따라 응답을 결정할 코드를 출력하도록 LM에 가르칩니다.\n- dspy.ReAct: 주어진 서명을 구현하기 위해 도구를 사용할 수 있는 에이전트입니다.\n- dspy.MultiChainComparison: ChainOfThought에서 여러 출력을 비교하여 최종 예측을 생성할 수 있습니다.\n\n이전 출력인 dspy.Predict와 dspy.ChainOfThought를 비교해보겠습니다. 그러나 질문을 바꿔볼까요:\n\n```js\nquestion = \"True or False: The numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\"\n\npredictor = dspy.Predict(\"question -\u003e answer\")\npredictor(question=question)\n\n# 결과\nPrediction(\n    answer='Question: True of False: The numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\\nAnswer: True. The numbers 17, 9, 10, 12, 13, 4, and 2 add up to 67, which is an even number.'\n)\n\n------\n\ncot = dspy.ChainOfThought(\"question -\u003e answer\")\ncot(question=question)\n\n# 결과\nPrediction(\n    rationale=\"Question: True or False: The numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\\nReasoning: Let's think step by step in order to determine if the numbers in this group add up to an even number.\\n1. We need to add up all the numbers in the group: 17 + 9 + 10 + 12 + 13 + 4 + 2 = 67.\\n2. 67 is an odd number, not an even number.\",\n    answer='False, the numbers in this group do not add up to an even number.'\n)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 출력 결과를 보면, 답변이 다르며, 후자가 올바른 것을 알 수 있습니다. 이는 DSPy가 Chain of Thought (CoT)를 통해 우리가 제공한 프롬프트를 확장하기 때문입니다. CoT를 사용하면 LM(Language Model)에게 답변을 제공하기 전에 \"단계별로\" 추론하도록 강요합니다. 이 근거는 답변에서 제공되며, 더 자세한 지침은 cot.extended_signature에서 확인할 수 있습니다.\n\n```js\ncot.extended_signature\n\n# 출력\nStringSignature(question -\u003e rationale, answer\n    instructions='`question` 필드를 주어 `answer` 필드를 생성하십시오.'\n    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': '질문:', 'desc': '${question}'})\n    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"추론: 정답을 만들기 위해 '단계별로 생각해 봅시다. ${produce the answer}. We ...\", '__dspy_field_type': 'output'})\n    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': '답변:', 'desc': '${answer}'})\n)\n```\n\ndspy.Signature의 경우, 예를 들어 RAG에 매우 유용한 컨텍스트를 소개하려면 축약 표기를 확장할 수 있습니다:\n\n```js\ndspy.Predict(\"context, question -\u003e answer\")\n\n# 출력\nPredict(StringSignature(context, question -\u003e answer\n    instructions='`context`, `question` 필드를 주어 `answer` 필드를 생성하십시오.'\n    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': '컨텍스트:', 'desc': '${context}'})\n    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': '질문:', 'desc': '${question}'})\n    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': '답변:', 'desc': '${answer}'})\n))\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아니면 더 많은 제어를 위해 더 긴 표기를 사용해보세요:\n\n```js\nclass BasicQA(dspy.Signature):\n    \"\"\"문맥에 기반한 짧은 답변으로 질문에 대답합니다\"\"\"\n    context = dspy.InputField()\n    question = dspy.InputField()\n    answer = dspy.OutputField(desc=\"문맥에서 추출된 짧은 답변\")\n\n# 출력\nBasicQA(context, question -\u003e answer\n    instructions='문맥에 기반한 짧은 답변으로 질문에 대답합니다'\n    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': '문맥:', 'desc': '${context}'})\n    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': '질문:', 'desc': '${question}'})\n    answer = Field(annotation=str required=True json_schema_extra={'desc': '문맥에서 추출된 짧은 답변', '__dspy_field_type': 'output', 'prefix': '답변:'})\n)\n```\n\n서명은 TypedPredictor 모듈 덕분에 pydantic 표기를 지원합니다:\n\n```js\nimport dspy\nfrom pydantic import BaseModel, Field\nfrom dspy.functional import TypedPredictor\nfrom datetime import datetime\nfrom textwrap import dedent\n\nclass TravelInformation(BaseModel):\n    origin: str = Field(pattern=r\"^[A-Z]{3}$\")\n    destination: str = Field(pattern=r\"^[A-Z]{3}$\")\n    date: str\n    confidence: float = Field(gt=0, lt=1)\n\nclass TravelSignature(dspy.Signature):\n    \"\"\" 주어진 이메일에서 모든 여행 정보를 추출합니다 \"\"\"\n    email: str = dspy.InputField()\n    flight_information: list[TravelInformation] = dspy.OutputField()\n\npredictor = TypedPredictor(TravelSignature)\npredictor(email=dedent(\"\"\"\n    Amazon Web Services Airlines로 예약해 주셔서 감사합니다.\n    2024년 6월 18일 바리에서 라스베이거스로 가는 XYZ123 편에 예약이 완료되었으며 탑승을 환영합니다.\n    즐거운 여행 되세요.\n\"\"\"))\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 리트리버\n\n프로그램은 dspy.Retrieve 클래스를 확장하여 검색 시스템을 구현할 수도 있습니다. 사용 가능한 리트리버의 최신 목록을 확인하려면 DSPy GitHub 저장소의 dspy.retrievers 모듈을 참조해주세요.\n\nAmazon Bedrock와 함관해서 리트리버를 사용하려면 사용자 정의 SentenceVectorizer 클래스를 만들어야 합니다. 미리 해당 작업을 수행해 두었습니다. (그런데, 이를 DSPy 팀이 공식적으로 구현하길 원하시면 PR #1151에 +1을 부탁드립니다):\n\n```python\nimport boto3\nimport json\nimport numpy as np\nfrom typing import List, Optional\nfrom dsp.modules.sentence_vectorizer import BaseSentenceVectorizer\n\nclass AmazonBedrockVectorizer(BaseSentenceVectorizer):\n    '''\n    이 벡터화기는 텍스트를 임베딩으로 변환하기 위해 Amazon Bedrock API를 사용합니다.\n    '''\n    SUPPORTED_MODELS = [\n        \"amazon.titan-embed-text-v1\", \"amazon.titan-embed-text-v2:0\",\n        \"cohere.embed-english-v3\", \"cohere.embed-multilingual-v3\"\n    ]\n\n    def __init__(\n        self,\n        model_id: str = 'amazon.titan-embed-text-v2:0',\n        embed_batch_size: int = 128,\n        region_name: str = 'us-west-2',\n        aws_access_key_id: Optional[str] = None,\n        aws_secret_access_key: Optional[str] = None,\n    ):\n        self.model_id = model_id\n        self.embed_batch_size = embed_batch_size\n\n        # Bedrock 클라이언트 초기화\n        self.bedrock_client = boto3.client(\n            service_name='bedrock-runtime',\n            region_name=region_name,\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key\n        )\n\n    def __call__(self, inp_examples: List[\"Example\"]) -\u003e np.ndarray:\n        text_to_vectorize = self._extract_text_from_examples(inp_examples)\n        embeddings_list = []\n\n        n_batches = (len(text_to_vectorize) - 1) // self.embed_batch_size + 1\n        for cur_batch_idx in range(n_batches):\n            start_idx = cur_batch_idx * self.embed_batch_size\n            end_idx = (cur_batch_idx + 1) * self.embed_batch_size\n            cur_batch = text_to_vectorize[start_idx: end_idx]\n\n            # Bedrock API Body 구성\n            if self.model_id not in self.SUPPORTED_MODELS:\n                raise Exception(f\"지원하지 않는 모델: {self.model_id}\")\n\n            if self.model_id == \"amazon.titan-embed-text-v1\":\n                if self.embed_batch_size == 1:\n                    body = json.dumps({\"inputText\": cur_batch[0]})\n                else:\n                    raise Exception(f\"모델 {self.model_id}은 배치 크기 1을 전용으로 지원합니다.\")\n            elif self.model_id == \"amazon.titan-embed-text-v2:0\":\n                if self.embed_batch_size == 1:\n                    body = json.dumps({\n                        \"inputText\": cur_batch[0],\n                        \"dimensions\": 512\n                    })\n                else:\n                    raise Exception(f\"모델 {self.model_id}은 배치 크기 1을 전용으로 지원합니다.\")\n            elif self.model_id.startswith(\"cohere.embed\"):\n                body = json.dumps({\n                    \"texts\": cur_batch,\n                    \"input_type\": \"search_document\"\n                })\n            else:\n                raise Exception(\"여기서 어떻게 나타났나요?\")\n\n\n            # Bedrock API 호출\n            response = self.bedrock_client.invoke_model(\n                body=body,\n                modelId=self.model_id,\n                accept='application/json',\n                contentType='application/json'\n            )\n\n            response_body = json.loads(response['body'].read())\n            if self.model_id.startswith(\"cohere.embed\"):\n                cur_batch_embeddings = response_body['embeddings']\n            elif self.model_id.startswith(\"amazon.titan-embed-text\"):\n                cur_batch_embeddings = response_body['embedding']\n            else:\n                raise Exception(f\"아직 구현되지 않았습니다! Amazon Bedrock 문서에서 모델 {self.model_id}의 응답 형식을 확인하세요: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html\")\n            embeddings_list.extend(cur_batch_embeddings)\n\n        embeddings = np.array(embeddings_list, dtype=np.float32)\n        return embeddings\n\n    def _extract_text_from_examples(self, inp_examples: List) -\u003e List[str]:\n        if isinstance(inp_examples[0], str):\n            return inp_examples\n        return [\" \".join([example[key] for key in example._input_keys]) for example in inp_examples]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 코드를 사용하여 선호하는 DSPy 검색기에서 이 클래스를 사용할 수 있습니다:\n\n```js\nfrom dspy.retrieve.faiss_rm import FaissRM\n\ndocument_chunks = [\n    \"...\"\n]\n\nfrm = FaissRM(\n    document_chunks=document_chunks,\n    vectorizer=AmazonBedrockVectorizer(\n        embed_batch_size=128, model_id=\"cohere.embed-english-v3\"\n        # OR:\n        # embed_batch_size=1, model_id=\"amazon.titan-embed-text-v2:0\"\n    )\n)\nprint(frm([\"여기에 질문을 입력하세요\"]))\n```\n\n## 사용자 정의 프로그램\n\n이 지식을 활용하여 프로그램의 동작을 정의하는 사용자 정의 클래스를 정의할 수 있습니다! 예를 들어, RAG 클래스는 다음과 같이 보일 것입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nclass RAG(dspy.Module):\n    def __init__(self, num_passages=3):\n        # 'Retrieve' will use the user's default retrieval settings unless overriden.\n        self.retrieve = dspy.Retrieve(k=num_passages)\n        # 'ChainOfThought' with signature that generates answers given retrieval \u0026 question.\n        self.generate_answer = dspy.ChainOfThought(\"context, question -\u003e answer\")\n\n    def forward(self, question):\n        context = self.retrieve(question).passages\n        return self.generate_answer(context=context, question=question)\n```\n\n이 코드를 실행하기 전에 선호하는 검색기를 구성해야 합니다.\n\n# 결론\n\nDSPy와 Amazon Bedrock은 인공지능(AI) 개발 도구의 진화에서 중요한 발전을 나타냅니다. DSPy의 데이터 과학 능력과 Bedrock의 확장 가능하고 효율적인 모델 관리를 결합하여 개발자와 데이터 과학자는 복잡한 AI 과제에 대처할 강력한 도구 상자를 갖추게 됩니다. 이러한 도구들이 계속 발전함에 따라, 그들은 의심할 여지 없이 AI의 미래를 형성하는 데 중추적인 역할을 할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자세한 정보는 DSPy GitHub 저장소와 Amazon Bedrock 문서를 살펴보세요. 이 흥미로운 분야에서의 미래 업데이트와 진전에 주목해 주세요!\n","ogImage":{"url":"/assets/img/2024-06-19-BuildingRobustAISystemswithDSPyandAmazonBedrock_0.png"},"coverImage":"/assets/img/2024-06-19-BuildingRobustAISystemswithDSPyandAmazonBedrock_0.png","tag":["Tech"],"readingTime":17},{"title":"5개의 무료 엔드 투 엔드 데이터 엔지니어링 프로젝트","description":"","date":"2024-06-19 12:15","slug":"2024-06-19-5FREEEnd-To-EndDataEngineeringProjects","content":"\n이 5개의 프로젝트를 수행함으로써 AWS, GCP 및 Azure를 배울 수 있습니다.\n\n이 프로젝트들은 총 200만 회 이상의 조회수를 갖고 있습니다. 그 이유가 있을 텐데요.\n\n![이미지](/assets/img/2024-06-19-5FREEEnd-To-EndDataEngineeringProjects_0.png)\n\n데이터 엔지니어링은 복잡한 분야로 들릴 수 있지만, 솔직히 말해서 그렇습니다. 하지만 자전거를 타는 것을 배우는 것처럼 연습을 통해 더 쉽고 직관적으로 되는 법이죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시작하거나 기술을 향상시키는 데 도움이 되기 위해, 무료로 작업할 수 있는 멋진 다섯 가지 프로젝트를 골라왔어요. 이 프로젝트들은 어떤 것이든 아니에요; 즐겁고 매력적이며 다양한 주제와 도구를 다루고 있어요. 함께 시작해봐요!\n\n# 1. YouTube 데이터 분석\n\n유튜브 비디오가 인기있는 이유가 궁금했던 적이 있나요? 이 프로젝트에서 실제 유튜브 데이터를 활용하여 그것을 알아볼 수 있어요. 데이터 마법사가 되어야 하는 것은 아니에요. Python이라는 학습이 쉬운 프로그래밍 언어와 큰 데이터를 처리하는데 사용되는 PySpark을 익힐 수 있을 거예요. 또한 데이터를 관리하는 언어인 SQL과 Athena, Glue, Redshift, S3와 같은 다양한 AWS(아마존 웹 서비스) 도구를 사용해볼 수 있어요. 이 도구들은 데이터 세계에서 큰 이름이며, 어떻게 함께 문제를 해결하는지 배울 수 있을 거예요.\n\n개발할 수 있는 기술:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Python 및 PySpark으로 코딩하기\n- 데이터 관리를 위한 기본 SQL\n- 현실 세계 문제의 이해 및 해결\n- 데이터 프로젝트를 위한 AWS 도구 사용\n\n## 2. Airflow를 활용한 Twitter 데이터 파이프라인\n\nTwitter는 데이터의 보고이에요. 이 프로젝트에서는 Twitter 데이터 수집, 처리 및 저장 프로세스를 자동화하는 방법을 배울 거예요. Airflow를 사용하여 이러한 작업을 예약하고 조직화하는 방법을 직접 확인하게 될 거예요. 또한, 이 프로젝트는 Twitter 데이터에 액세스하기 위한 Tweepy 및 데이터 분석을 위한 Python 라이브러리인 Pandas를 소개합니다. 데이터 엔지니어들에게 널리 사용되는 ETL (추출, 변환, 로드) 작업 작성에 익숙해지는 좋은 기회가 될 거예요.\n\n개발할 기술:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Python 프로그래밍\n- Airflow를 사용하여 작업 자동화\n- 데이터 수집 및 분석\n- API 및 클라우드 저장소 사용\n\n## 3. 실시간 주식 시장 분석\n\n주식 시장 트렌드를 실시간으로 예측할 수 있다면 어떨까요? 이 프로젝트는 당신을 그 현실에 더 가깝게 이끌어줍니다. Python과 Kafka(실시간 데이터 스트림 처리 플랫폼)를 사용하여 주식 시장 데이터를 실시간으로 분석하는 애플리케이션을 구축할 것입니다. EC2 인스턴스(서버 유형)에 Kafka를 설정하고 데이터 파이프라인을 생성하는 것이 재미있는 부분입니다. 마법 같은 프로젝트이지만 실용적인 기술에 근거해 있습니다.\n\n개발할 기술:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 실시간 애플리케이션 구축\n- 데이터 스트림을 위한 Kafka 이해\n- 클라우드 서버 설정\n- 실시간 데이터 분석\n\n## 4. GCP에서 Uber 데이터 분석\n\nUber의 데이터는 방대하고 다양하여 분석 프로젝트에 이상적입니다. 원시 데이터를 이해하고 데이터 모델을 작성하며 ETL 작업을 위한 스크립트를 작성하는 방법을 배울 수 있습니다. 이 프로젝트에서는 데이터 파이프라인을 구축하는 현대적인 도구인 mage와 데이터 분석을 위한 SQL도 소개됩니다. 게다가 Google Cloud Platform (GCP)에서 작업하게 되어 선도적인 클라우드 서비스 중 하나인 GCP의 최신 기술 스택을 직접 경험할 수 있습니다.\n\n개발할 수 있는 기술:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터 모델링 및 분석\n- ETL 스크립트 작성 및 자동화\n- SQL 쿼리 작성\n- 클라우드 기반 데이터 도구 사용\n\n# 5. Azure에서 올림픽 데이터 분석\n\n올림픽은 많은 데이터를 생성합니다. 이 프로젝트에서는 이 데이터를 API에서 추출하고 Microsoft의 클라우드 플랫폼인 Azure를 사용하여 분석하는 방법을 배울 수 있습니다. DataBricks와 같은 대용량 데이터용 서비스, 데이터 통합용 DataFactory, 대규모 데이터 분석용 Synapse Analytics 등을 사용할 수 있습니다. 이 프로젝트는 규모에 맞는 데이터 처리 방법을 가르치며 향후 올림픽 전략에 영향을 줄 수 있는 통찰을 제공할 것입니다.\n\n개발할 수 있는 기술:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- API에서 데이터 추출하기\n- 데이터 엔지니어링을 위해 Azure 서비스 사용하기\n- 데이터 처리를 위한 Spark 코드 작성하기\n- SQL을 사용한 고급 데이터 분석\n\n도움이 되었다면 저의 게시물을 팔로우하는 것을 잊지 마세요 :)\n\n관심이 있다면 여기에서 데이터 엔지니어링 기초 과정을 확인할 수 있습니다 —\n\n데이터 엔지니어링/과학/분석/LLM에 관한 놀라운 블로그를 더 많이 게시할 예정입니다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n환영합니다!\n","ogImage":{"url":"/assets/img/2024-06-19-5FREEEnd-To-EndDataEngineeringProjects_0.png"},"coverImage":"/assets/img/2024-06-19-5FREEEnd-To-EndDataEngineeringProjects_0.png","tag":["Tech"],"readingTime":5},{"title":"미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기","description":"","date":"2024-06-19 12:13","slug":"2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs","content":"\n크론 작업, \"백그라운드 작업\" 또는 클라우드워치 이벤트 대신 유연한 일정에 필요한 작업을 수행하는 대체 수단입니다.\n\n많은 소프트웨어 시스템은 작업을 예약할 수 있는 메커니즘이 필요하며, \"크론\" (또는 AWS 클라우드의 클라우드워치 이벤트/예약된 작업) 또는 \"지연 작업\" 시스템은 일반적인 해결책입니다. 그러나 특정 유형의 작업에 대해 꽤 좋거나 분명히 크론보다 나은 대안이 있습니다. 해당 대안은 TTL(생존 기간)이 있는 DynamoDB 레코드 및 람다 함수로 처리된 DynamoDB 스트림을 사용하는 것입니다. 레코드의 TTL이 만료될 때 람다가 트리거되며, 그때 레코드를 필요에 따라 처리할 수 있습니다. 이러한 종류의 작업에는 어떤 작업을 할 수 있을까요? 어떤 작업에서는 잠재적으로 변경 가능하거나 동적이며 또는 \"x 분 후\" 유형의 일정이 필요한 경우가 있습니다. 가능한 고정된 크론 스타일 일정(예: 매주 화요일 정오에 실행) 대신에 유연한 일정을 원하는 작업에 적합합니다. 또한 개별화되거나 희소한 상황에 대해 매우 효율적이고 비용 효율적인 개별 레코드를 기반으로 트리거하는 것이 모든 레코드를 대상으로 프로세스를 실행하는 것보다 우수합니다.\n\n몇 가지 사용 사례 예시:\n\n- 이벤트 전 X일 또는 마감일 이후 X일 후에 메시지를 전송하는 알림 메시지 보내기.\n- X 시간 동안 독자적 상태/상태를 변경하거나 읽지 않은 경우 상태 변경하기.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTTL의 정밀도에 관한 중요한 주의 사항이 있습니다. 아래 중요한 주의 사항 섹션을 참조해주세요.\n\n# 기본 사용법\n\n기본 패턴은 특정 이벤트를 기반으로 DynamoDB 레코드를 생성/업데이트하고, 그 후 미래의 특정 시간에 어떤 일이 발생하길 원할 때입니다. 레코드에 TTL(생존 기간)을 설정하여 그 시점에 만료되도록 하고, 만료되면 DynamoDB가 레코드를 삭제합니다. 그런 다음 DynamoDB 테이블에 스트림을 활성화하고, 해당 삭제 이벤트를 처리할 람다를 스트림에 연결합니다. 람다에는 이 상황에 대한 특정 이벤트만 수신하도록 필터가 있어야 합니다(REMOVE 및 TTL 삭제 vs. 코드 삭제를 구분하는 필드 및 주 키에 대한 필터 설정이 있어야 합니다).\n\n![image](/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 경우 DynamoDB의 추가적인 이점은 이러한 레코드에 대해 PUT을 수행함으로써 이것이 \"업서트\"로 작동한다는 것입니다. 즉, 이를 유지하려면 이미 존재하는 레코드인지 확인하고 TTL을 업데이트하거나 새로운 레코드를 만들 필요가 없습니다 (예를 들어 대부분의 RDBMS에서 해야 하는 작업과 같은).\n\n# 예시\n\n위의 경우 #2를 기준으로 예시를 살펴보겠습니다. 이 경우가 더 복잡하여 이 기술의 장점을 잘 보여줍니다. 장치 읽기를 수신하는 시스템을 상상해보세요. 보통 하루에 한 번씩 읽기가 발생하며, 읽기가 일주일 동안 없는 경우 상태를 업데이트하고 경고를 생성하고자 합니다. 이러한 장치들은 높은 빈도로 읽기가 발생하지 않습니다(이 경우 농업 관수 시스템이거나, 원격 환자 모니터링 장치일 수 있습니다. 즉, 환자가 집에서 매일 혈압을 측정하겠다는 것입니다). 다음을 수행해야 합니다:\n\n- 읽기가 없는 경우 3일 후에 장치 상태를 \"연결 불가\"로 설정\n- 장치 관리자에게 7일 후에 경고를 발생시키고, 10일 후에도 여전히 오프라인인 경우에 다시 경고를 보냅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPUT 메소드를 사용하여 시간 프레임(3, 7, 10일)마다 DynamoDB(DDB) 레코드를 세 개 PUT하면 이를 달성할 수 있습니다. 첫 번째 레코드는 도달할 수 없는 상태를 트리거하기 위한 것이고, 나머지 두 개는 경고를 위한 것입니다. 기기에서 읽기 값을 받을 때마다 이 작업을 수행하는데, 이렇게 함으로써 TTL을 연장합니다 (PUT은 같은 기본 키의 기존 레코드를 덮어씁니다). 그러나 갑자기 몇 일 동안 읽기 값을 받지 못하게 되었을 때, 즉 레코드가 업데이트되지 않았을 때는 우선 3일 항목의 TTL이 만료되어 DynamoDB 스트림으로 REMOVE 이벤트를 보내고, 람다로 전달하여 프로세스를 시작합니다.\n\n그래서 우리는 파티션 키(PK)와 소트 키(SK) 설계가 모두 있는 DDB 기본 키를 사용할 수 있는데, 이는 다음과 같습니다:\n\nPK: DEVICE#`소유자 ID`\n\nSK: `기기 ID`#`이벤트 ID`\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTTL: 유닉스 시대 시간, 초 단위 해상도입니다.\n\n당신의 요구에 따라 추가적인 속성을 갖고 있을 수 있으며, 일반적으로 PK 및 SK의 값에 대한 명시적 속성도 가지고 있습니다. 그렇게 함으로써 PK/SK에서 그 값을 분리해 내지 않아도 됩니다. 예를 들어, OwnerID, DeviceID, EventID와 종종 데브리 책에서 설명한 것처럼 유용한 유형 필드가 있을 것입니다.\n\n게다가, 장치가 더 이상 사용되지 않는 경우, 단순히 PK = DEVICE#`ownerid` 및 디바이스 ID의 begins_with를 사용하는 SK에 대한 DDB 레코드를 모두 삭제하여 이를 처리할 수 있습니다.\n\nDynamoDB 테이블에서 스트림을 활성화하고, 스트림에 람다를 연결하여 이벤트를 처리해야 합니다. AWS 문서 \"DynamoDB Streams\"와 \"AWS Lambda Trigger\"를 참조하세요. 기본적으로 람다는 DynamoDB \"이벤트\"를 모두 받아오게 되므로 삽입, 업데이트 및 삭제를 다루게 됩니다. 여기서 필터링이 필요합니다. 여기서는 최소한 REMOVE(삭제) 이벤트만 필터링하고자 합니다. 필터링은 람다에서 수행할 수 있지만, 이는 소요 비용이 큽니다. 왜냐하면 매번 레코드를 유지하기 위해 이 디자인으로 정기적으로 수행하고 있는 삽입/업데이트가 발생할 때마다 람다가 호출되기 때문입니다. 다행히도 \"Lambda Event Filtering\"을 통해 이벤트와 일치하지 않으면 람다가 호출되지 않도록 할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이벤트 전용 DynamoDB 테이블을 따로 사용한다면, 삭제 이벤트에 대한 필터만 필요합니다. 그러나 테이블 내에 다른 아이템이 있는 경우 (예: 단일 테이블 디자인을 사용하는 경우) 특정 레코드로 제한하기 위해 필터를 추가해야 합니다. 이 경우 PK가 'DEVICE#' 접두사를 가진 레코드만 일치하도록 \"접두사\" 필터를 사용하여 이 작업을 수행할 수 있습니다. AWS의 Lambda 이벤트 필터링을 다룬 이 튜토리얼을 참고하시기 바랍니다. 마지막으로, 반드시 해야 할 중요한 추가 필터링 사항이 있습니다. userIdentity 필드를 확인해야 합니다. DynamoDB Streams 및 Time To Live 문서에서 이에 대해 설명되어 있으며, 필터 구문을 보여줍니다. 예를 들어, Serverless Framework를 사용하는 경우, DynamoDB 스트림을 처리하는 람다는 다음과 같은 이벤트 정의를 갖게 됩니다:\n\n```js\n    events:\n      - stream:\n          type: dynamodb\n          batchSize: 20\n          enabled: true\n          arn:\n            Fn::GetAtt: [DeviceMonitorTable, StreamArn]\n          filterPatterns:\n            - eventName: [REMOVE]\n              dynamodb:\n                Keys:\n                  PK:\n                    S:\n                      - prefix: 'DEVICE#'\n              userIdentity:\n                type:\n                  - Service\n                principalId:\n                  - dynamodb.amazonaws.com\n```\n\n이 필터를 통해 람다가 처리해야 할 이벤트만 받게 됩니다. 그 후, 람다는 받은 레코드에 적절한 처리를 수행합니다 (아마도 이벤트 ID나 레코드 내의 다른 관련 데이터에 기반하여). 그 후에 장치가 계속해서 측정치를 갖지 않는 상태로 유지되거나 시리즈의 다음 DDB 레코드가 TTL에 도달하거나 등의 상황이 발생할 수 있습니다. 장치가 다시 사용되고 모든 레코드가 업데이트되거나 (첫 번째 레코드부터 시작하여 TTL에 도달한 레코드의 수에 따라) 다시 생성될 수 있습니다.\n\n# 중요한 한 가지 주의사항!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 솔루션에서 주의해야 할 중요한 점은 TTL이 정확하지 않고 만료 후 \"만료일로부터 몇 일 이내에\" 발생한다는 것이다. 이 문서에 따르면 정확한 타이밍을 기대하는 중요한 작업에는 사용하지 않는 것이 좋다. 그런데, 실제로, 두 가지 서로 다른 앱에서 확인했을 때, 이 작업은 대개 TTL만료 후 몇 분 안에 트리거된다. 테이블의 사용량에 따라 (즉, 정기 사용은 만료된 레코드의 정기적인 정리를 의미한다) 결정되는 것 같다. 이에 대해 더 나은 정보가 있다면, 의견을 달아주시거나 말씀해주세요!\n\n# 마지막으로\n\n이러한 지연 작업 시스템을 구축하는 것은 크론 스타일 접근 방식으로는 정말 고통스럽습니다. 하루에 한 번 또는 모든 시간 간격을 확실히 포함할 때의 빈도로 크론 작업을 수행해야 하기 때문입니다. 위의 예와 같은 \"일\" 단위 간격의 경우에는 그렇게 나쁘지 않을 수도 있습니다. 그러나 더 정확한 타이밍이 필요한 경우, 그냥 작동하지 않을 수도 있습니다. 게다가, 이러한 이벤트가 발생하는 빈도가 더 드문 경우, 필요 이상으로 크론 작업을 실행할 수도 있습니다. AWS 생태계에 속해 있다면, 저장 실행 작업에 대신 제3자나 패키지를 가져올 경우에 비해 사용하기가 매우 매력적으로 보입니다.\n\n게다가, 타이밍 간격이 구성 가능하면, 이것은 크론 스타일 시스템보다 처리하기가 훨씬 쉽습니다. 여러분의 수용할 수 있는 한계와 지정된 동작에 따라서, 기존 항목을 그대로 둘 수 있고 다음 장치 읽기(또는 DDB 레코드 쓰기를 트리거하는 것)에서 TTL을 간단히 업데이트하거나, 영향을 받는 레코드만 조정할 수도 있습니다(PK+SK 콤보를 사용하여 실제 시간 양에 의존하지 않는 것을 확인하세요. 따라서 저는 SK에서 이 측면을 \"이벤트 ID\"로 지정했습니다. \"3일\" 또는 다른 것이 변할 수 있는 \"3일\" 같은 것 대신 \"alert1\"을 사용할 것입니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 방식은 이벤트 주도 스타일을 제공하며 놀라운 확장성을 제공하고 물론 서버리스 시스템과 잘 어울립니다.\n","ogImage":{"url":"/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png"},"coverImage":"/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png","tag":["Tech"],"readingTime":8},{"title":"AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법","description":"","date":"2024-06-19 12:12","slug":"2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform","content":"\n서버리스 함수는 인프라 걱정 할 필요 없이 DevOps 및 SysOps에게 필수적입니다.\n\n우리는 Amazon Web Services (AWS) 람다 함수를 살펴보고, 어떻게 테라폼을 사용하여 AWS 람다를 배포할 수 있는지 알아볼 것입니다.\n\n![이미지](/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png)\n\n모든 자료에 대한 Github 링크: [https://github.com/batuhan-bulut/terraform-aws-lambda](https://github.com/batuhan-bulut/terraform-aws-lambda)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# AWS Lambda란 무엇인가요?\n\nAWS Lambda를 사용하면 서버에 대해 걱정하지 않고 지원되는 언어로 스크립트를 실행할 수 있습니다. Node.JS, Python, C# 등으로 작성된 코드를 실행할 수 있습니다.\n\nLambda를 사용하면 다음을 수행할 수 있습니다.\n\n- 지역별 EC2 인스턴스 상태 확인\n- AWS CLI를 사용하여 일부 자동화 실행\n- AWS SQS로 작업 예약\n- 기타\n\n이런 가능성들로 AWS Lambda는 데브옵스 및 시스옵스 팀에 매우 중요한 역할을 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS 웹 사이트에서 GUI를 사용하여 AWS Lambda를 쉽게 배포할 수 있어요.\n\n여러 계정이 있고 동일한 Lambda를 다른 지역에 배포해야 한다면 어떻게 할 건가요? 하나씩 Lambda를 배포할까요?\n\n이때 IaC와 Terraform이 게임에 합류해요.\n\n# IaC란? (Infrastructure as Code)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nIaC를 사용하면 우리는 쉽게 환경 (개발, 테스트, 스테이징, 프로덕션 등)을 설정할 수 있어요. 인기 있는 공급 업체들은 요구 사항에 맞는 CDK(Cloud Development Kit)를 가지고 있어요.\n\n## 왜 테라폼이 중요한가요?\n\n예를 들어, AWS에 앱이 있고 (EC2, RDS, Lambda, SQS 등을 사용하는) 다양한 서비스를 사용한다고 가정해봅시다. AWS CDK로 이 애플리케이션을 쉽게 배포할 수 있어요.\n\n그런데 만약 경영진이 Azure, GCP 또는 다른 클라우드 공급업체로 전환하기로 결정한다면 어떻게 될까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS CDK에 대한 지식 대부분은 중요하지 않아요. 왜냐하면 해당 공급업체가 자체 CDK를 가지고 있거든요.\n\n여기서 Terraform이 우리의 워크플로에 합류하는 곳이에요.\n\n# Terraform이란?\n\n지식과 경험을 통해 Terraform을 사용하면 간단한 명령어로 많은 리소스를 관리할 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 문서에서는 Terraform의 AWS 쪽에 중점을 둘 것입니다.\n\n# 불이 켜지면, 카메라 맞춰, 액션!\n\n주의하세요: 이 작업은 AWS 측에 비용을 발생시킬 수 있습니다.\n\n## 우리의 Terraform 코드는 무엇을 할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- IAM 역할 제공\n- IAM 프로필 제공\n- 프로필에 IAM 정책 부착\n- 업로드용 ZIP 파일 생성\n- 람다 함수 생성\n\n이 문서에서는 하드코딩된 값 대신 변수를 사용할 것입니다. 이렇게 하면 다양한 설정으로 동일한 스크립트를 실행할 수 있습니다.\n\n이것은 우리의 terraform/main.tf 파일입니다. 우리 코드의 구조를 담고 있습니다.\n\n```js\nprovider \"aws\" {\n  region = var.region\n}\n\n# AWS Lambda를 위한 IAM 역할\nresource \"aws_iam_role\" \"terraform_lambda_iam_role\" {\nname               = var.terraform_lambda_iam_role.name\nassume_role_policy = var.terraform_lambda_iam_role.assume_role_policy\n}\n\n# 람다를 위한 새로운 정책 생성\nresource \"aws_iam_policy\" \"iam_policy_for_lambda\" {\nname         = \"iam_policy_${var.terraform_lambda_iam_role.name}\"\ndescription  = var.iam_policy_for_lambda.description\npolicy       = var.iam_policy_for_lambda.policy\n}\n\n# IAM 정책을 IAM 역할에 부착\nresource \"aws_iam_role_policy_attachment\" \"attach_iam_policy_to_iam_role\" {\nrole        = aws_iam_role.terraform_lambda_iam_role.name\npolicy_arn  = aws_iam_policy.iam_policy_for_lambda.arn\n}\n\n# Lambda에 업로드할 ZIP 파일 생성\ndata \"archive_file\" \"zip_python_lambda_code\" {\ntype        = \"zip\"\noutput_path = \"${path.module}/python/${var.zip_python_lambda_code.name}.zip\"\nsource_file = \"${path.module}/../${var.zip_python_lambda_code.name}.py\"\n}\n\n# Lambda 함수 생성\nresource \"aws_lambda_function\" \"terraform_lambda\" {\nfilename     = \"${path.module}/python/${var.zip_python_lambda_code.name}.zip\"\nfunction_name  = var.terraform_lambda.name\nrole        = aws_iam_role.terraform_lambda_iam_role.arn\nruntime     = var.terraform_lambda.runtime\nhandler     = \"${var.zip_python_lambda_code.name}.lambda_handler\"\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 코드 블록에서는 terraform/terraform.tf 파일에서 모든 변수를 읽습니다. 동일한 Terraform 파일을 프로덕션, 스테이징 또는 다른 AWS 지역과 같이 다른 환경에 대해 다양한 구성으로 실행할 수 있습니다.\n\n이 변수들을 읽기 위해서는 변수를 정의해야 합니다. “.tf” 파일을 사용하여 변수를 선언할 수 있습니다.\n\n위 코드에 대한 terraform.tf 파일이 다음과 같이 보입니다.\n\n```js\n변수 \"region\" {\n  type = string\n  설명 = \"AWS 지역\"\n  기본 = \"eu-central-1\"\n}\n\n변수 \"zip_python_lambda_code\" {\n  type = map(string)\n  설명 = \"Python 파일의 이름\"\n  기본 = {\n    name = \"index\"\n  }\n}\n\n변수 \"terraform_lambda_iam_role\" {\n  type = map(string)\n  설명 = \"aws_iam_role - terraform_lambda_iam_role 변수\"\n  기본 = {\n    name = \"Lambda-from-terraform\"\n    assume_role_policy = \u003c\u003cEOF\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n   {\n     \"Action\": \"sts:AssumeRole\",\n     \"Principal\": {\n       \"Service\": \"lambda.amazonaws.com\"\n     },\n     \"Effect\": \"Allow\",\n     \"Sid\": \"\"\n   }\n ]\n}\nEOF\n  }\n}\n\n변수 \"iam_policy_for_lambda\" {\n  type = map(string)\n  설명 = \"람다를 위한 IAM 정책\"\n  기본 = {\n    description = \"Terraform으로 생성된 IAM 정책\"\n    policy = \u003c\u003cEOF\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n   {\n     \"Action\": [\n       \"logs:CreateLogGroup\",\n       \"logs:CreateLogStream\",\n       \"logs:PutLogEvents\"\n     ],\n     \"Resource\": \"arn:aws:logs:*:*:*\",\n     \"Effect\": \"Allow\"\n   }\n ]\n}\nEOF\n  }\n}\n\n변수 \"terraform_lambda\" {\n  type = map(string)\n  설명 = \"람다를 위한 변수\"\n  기본 = {\n    name = \"Lambda_Terraform\"\n    runtime = \"python3.12\"\n    handler = \"index.lambda_handler\"\n  }\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 파일에서는 변수와 그 기본 값들을 선언합니다. 테라폼에서는 다양한 유형의 변수를 선언할 수 있어요.\n\n더 많은 정보를 원하신다면 테라폼 문서를 확인해보세요.\n\n코드에 기본 값을 사용하고 싶지 않다면 기본 변수를 덮어쓸 terraform/vars.tfvars 파일을 추가할 수도 있어요. 이 파일의 내용은 일반적으로 \"key = value\" 형식입니다.\n\n여기 .tfvars 파일의 예시가 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nregion = \"us-east-1\"\n\nterraform_lambda= {\n    name = \"Override_Name\"\n    runtime = \"python3.9\"\n    handler = \"override.lambda_handler\"\n}\n```\n\n이렇게 하면 Terraform이 region 및 terraform_lambda 변수의 기본값을 재정의할 것입니다.\n\n참고: 이 예와 같이 terraform_lambda와 같은 객체에서 변수를 변경하려면 객체의 모든 변수를 전달해야 합니다. 그렇지 않으면 오류가 발생합니다.\n\n그리고 루트 폴더에 간단한 Python 앱을 index.py라는 이름으로 추가해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 간단한 Hello 함수\nimport json\n\ndef lambda_handler(event, context):\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Lambda에서 안녕하세요!')\n    }\n```\n\n다음은 폴더가 보이는 예시입니다\n\n\u003cimg src=\"/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_1.png\" /\u003e\n\n# 쇼타임!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n코드를 실행할 준비가 되었습니다.\n\n먼저 테라폼 구성 파일이 포함된 작업 디렉터리를 초기화하기 위해 terraform init 명령을 실행해야 합니다.\n\n```js\n$terraform init\n\n백엔드 초기화 중...\n\n공급자 플러그인 초기화 중...\n- 이전 의존성 락 파일에서 hashicorp/aws의 이전 버전 재사용 중\n- 이전 의존성 락 파일에서 hashicorp/archive의 이전 버전 재사용 중\n- 이전에 설치한 hashicorp/aws v5.54.1 사용 중\n- 이전에 설치한 hashicorp/archive v2.4.2 사용 중\n\n테라폼이 성공적으로 초기화되었습니다!\n\n이제 테라폼을 사용할 수 있습니다. 인프라에 필요한 변경 사항을 볼려면 \"terraform plan\"을 실행해보세요. 이제 모든 테라폼 명령이 작동해야 합니다.\n\n테라폼의 모듈 또는 백엔드 구성을 설정하거나 변경한 경우, 작업 디렉터리를 다시 초기화하려면이 명령을 다시 실행하십시오. 잊어버릴 경우 다른 명령어가 감지하여 필요시 상기시켜줄 것입니다.\n```\n\n이후, 인프라 구조의 변경 사항을 확인하기 위해 terraform plan을 실행할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndata.archive_file.zip_python_lambda_code: 읽는 중...\ndata.archive_file.zip_python_lambda_code: 읽기 완료 소요 시간 0초 [id=111]\n\n테라폼은 선택한 공급업체를 사용하여 다음 실행 계획을 생성했습니다. 자원 작업은 다음 기호로 표시됩니다:\n  + 생성\n\n테라폼은 다음 작업을 수행할 것입니다:\n\n  # aws_iam_policy.iam_policy_for_lambda가 생성됩니다\n  + resource \"aws_iam_policy\" \"iam_policy_for_lambda\" {\n      + arn              = (적용 후 알려짐)\n      + attachment_count = (적용 후 알려짐)\n      + description      = \"테라폼에 의해 생성된 IAM 정책\"\n      + id               = (적용 후 알려짐)\n      + name             = \"iam_policy_Lambda-from-terraform\"\n      + name_prefix      = (적용 후 알려짐)\n      + path             = \"/\"\n      + policy           = jsonencode(\n            {\n              + Statement = [\n                  + {\n                      + Action   = [\n                          + \"logs:CreateLogGroup\",\n                          + \"logs:CreateLogStream\",\n                          + \"logs:PutLogEvents\",\n                        ]\n                      + Effect   = \"Allow\"\n                      + Resource = \"arn:aws:logs:*:*:*\"\n                    },\n                ]\n              + Version   = \"2012-10-17\"\n            }\n        )\n      + policy_id        = (적용 후 알려짐)\n      + tags_all         = (적용 후 알려짐)\n    }\n\n  # aws_iam_role.terraform_lambda_iam_role가 생성됩니다\n  + resource \"aws_iam_role\" \"terraform_lambda_iam_role\" {\n      + arn                   = (적용 후 알려짐)\n      + assume_role_policy    = jsonencode(\n            {\n              + Statement = [\n                  + {\n                      + Action    = \"sts:AssumeRole\"\n                      + Effect    = \"Allow\"\n                      + Principal = {\n                          + Service = \"lambda.amazonaws.com\"\n                        }\n                      + Sid       = \"\"\n                    },\n                ]\n              + Version   = \"2012-10-17\"\n            }\n        )\n      + create_date           = (적용 후 알려짐)\n      + force_detach_policies = false\n      + id                    = (적용 후 알려짐)\n      + managed_policy_arns   = (적용 후 알려짐)\n      + max_session_duration  = 3600\n      + name                  = \"Lambda-from-terraform\"\n      + name_prefix           = (적용 후 알려짐)\n      + path                  = \"/\"\n      + tags_all              = (적용 후 알려짐)\n      + unique_id             = (적용 후 알려짐)\n    }\n\n  # aws_iam_role_policy_attachment.attach_iam_policy_to_iam_role 생성됩니다\n  + resource \"aws_iam_role_policy_attachment\" \"attach_iam_policy_to_iam_role\" {\n      + id         = (적용 후 알려짐)\n      + policy_arn = (적용 후 알려짐)\n      + role       = \"Lambda-from-terraform\"\n    }\n\n  # aws_lambda_function.terraform_lambda 생성됩니다\n  + resource \"aws_lambda_function\" \"terraform_lambda\" {\n      + architectures                  = (적용 후 알려짐)\n      + arn                            = (적용 후 알려짐)\n      + code_sha256                    = (적용 후 알려짐)\n      + filename                       = \"./python/index.zip\"\n      + function_name                  = \"Override_Name\"\n      + handler                        = \"index.lambda_handler\"\n      + id                             = (적용 후 알려짐)\n      + invoke_arn                     = (적용 후 알려짐)\n      + last_modified                  = (적용 후 알려짐)\n      + memory_size                    = 128\n      + package_type                   = \"Zip\"\n      + publish                        = false\n      + qualified_arn                  = (적용 후 알려짐)\n      + qualified_invoke_arn           = (적용 후 알려짐)\n      + reserved_concurrent_executions = -1\n      + role                           = (적용 후 알려짐)\n      + runtime                        = \"python3.9\"\n      + signing_job_arn                = (적용 후 알려짐)\n      + signing_profile_version_arn    = (적용 후 알려짐)\n      + skip_destroy                   = false\n      + source_code_hash               = (적용 후 알려짐)\n      + source_code_size               = (적용 후 알려짐)\n      + tags_all                       = (적용 후 알려짐)\n      + timeout                        = 3\n      + version                        = (적용 후 알려짐)\n    }\n\n계획: 4개 추가, 0개 변경, 0개 제거.\n\n앞서 설명한 변경 사항을 적용시키기 위해 terraform apply를 실행할 수 있습니다.\n\n그 후 콘솔에 성공 메시지가 표시될 것입니다. 이는 모든 리소스가 AWS 측에 생성된 것을 의미합니다. AWS GUI에서 람다 함수를 확인하고 실행하거나 CLI에서 람다 함수를 확인할 수 있습니다.\n\naws lambda list-functions --region us-east-1 | grep Override_Name\n\n\"FunctionName\": \"Override_Name\",\n\"FunctionArn\": \"arn:aws:lambda:us-east-1:11111:function:Override_Name\",\n\"LogGroup\": \"/aws/lambda/Override_Name\"\n```\n","ogImage":{"url":"/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png"},"coverImage":"/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png","tag":["Tech"],"readingTime":14},{"title":"Redis를 S3 Express로 재구축하기","description":"","date":"2024-06-19 12:10","slug":"2024-06-19-RebuildingRedisonS3Express","content":"\n## 느린, 저렴하고 확장 가능한 키-값 저장소\n\n## 느린-저렴 대 빠른-비싼\n\n다년간 \"최고의 데이터베이스\"로 선정된 Redis는 빠르고 신뢰성 있으며 고처리량의 키-값 저장소로 탄생했습니다 (훨씬 더 발전하기 전). 오늘날에도 가장 많이 사용되는 용도는 캐싱입니다 — 사용자를 위해 작고 자주 액세스하는 데이터를 빠르게 저장합니다 (예: 몇 줄의 파이썬 코드로):\n\n```js\n\u003e\u003e\u003e import redis\n\u003e\u003e\u003e r = redis.Redis(host='myhost', port=6379, db=0)\n\u003e\u003e\u003e r.set('userId:10', '1701743088')\nTrue\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 키 기반 쿼리로 나중에 다시 검색하세요:\n\n```js\n\u003e\u003e\u003e r.get('userId:10')\n1701743088\n```\n\n쉽고 빠르죠. Redis의 가치와 비밀은 데이터 전문가들에게 분명히 비밀이 아니며, 비용도 마찬가지입니다. 메모리는 비싸며, 캐시는 클라우드 요금에 빠르게 영향을 줄 수 있습니다. AWS ElasticCache의 25GB(cache.m7g.2xlarge)는 약 500달러 / 월입니다.\n\n다른 한편으로, S3와 같은 객체 저장소는 다른 가격 / 성능 트레이드오프를 약속했습니다. 25GB 저장 비용은 약 0.5달러 / 월이지만, S3 지연 시간(평균 및 테일)은 당신의 응용 프로그램에 심각한 영향을 미칠 수 있습니다. 만약 일관적이고 빠른 작업에 의존하고 있다면요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요즘까지는 아니었지만, S3 익스프레스의 공개로 파레토 프런티어에 또 다른 포인트가 추가되었습니다. \"익스프레스 저장소 클래스는 최대 10배 더 나은 성능을 제공하기 위해 설계되었으며 (...), 가장 자주 액세스하는 데이터에 탁월한 적합성을 갖추고 있습니다.\"\n\n이러한 새로운 기능에 매료되어, 우리는 AWS의 신제품을 테스트하기 위해 Redis와 유사한 키-값 워크로드를 완전히 S3로 백업하는 새로운 인터페이스를 재구성해 보았습니다(적절하게 \"redis3\"라고 합니다). 우리는 이를 프로토타입화하고 테스트하며 오픈소스로 공유했는데, 우리가 배운 것은 이렇습니다: 저장소를 복제하고 스타를 추가하며 함께하세요!\n\n![이미지](/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png)\n\n## Redis3: 개발자 시각\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요즘 데이터 랜드의 모든 사람들이 개발자 경험에 집착하고 있기 때문에, 우리는 redis3를 최종 사용자인 개발자에게 어떻게 보이는지부터 살펴보겠습니다. GET/SET 연산이 실제로 Redis의 핵심 기능이므로, redis-py 명령어를 redis3와 비교하여 시작합니다.\n\n```js\n\u003e\u003e\u003e from redis3 import redis3Client\n\u003e\u003e\u003e r = redis3Client(cache_name='mytestcache', db=0)\n\u003e\u003e\u003e r.set('userId:10', '1701743088')\nTrue\n\u003e\u003e\u003e r.get('userId:10')\n1701743088\n```\n\n알 수 있는 독자들은 이미 알고 계실 것이지만, 위 명령어는 기본적으로 동일합니다: URL 및 포트는 클라이언트 초기화에 없지만 (이유는 아래에서 자세히 설명되어 있습니다. 심지어 GET 및 SET에 대해 동일한 간결한 구문과 의미론을 가지고 있습니다.\n\nRedis3에서는 데이터베이스의 모든 키를 나열하거나 Redis에서의 MSET 및 MGET을 모방할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nkey_list = ['playground_{}'.format(i) for i in range(5)]\nval_list = ['bar_{}'.format(i) for i in range(5)]\nr = my_client.mset(key_list, val_list)\nval_list_back = my_client.mget(key_list)\nassert val_list == val_list_back\n```\n\n그리고 key를 삭제할 수도 있어요 (DEL):\n\n```js\nr = my_client.delete(\"userId:10\");\n```\n\n마지막으로, db 매개변수를 사용하여 키를 자동으로 네임스페이스 할 수 있어요 (물론 16에 제한되지 않아요):\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nr = redis3Client((cache_name = \"mytestcache\"), (db = 133));\n```\n\n## Redis3: 아키텍처\n\n자세히 살펴보면, redis3Client는 boto3 작업을 매우 얇게 래핑한 것입니다. 특히 S3 Express 버킷에 대한 작업을 합니다. 다음과 같이 클라이언트를 초기화합니다:\n\n```js\nr = redis3Client((cache_name = \"mytestcache\"), (db = 0));\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n버킷 redis3-mytestcache -- use1-az5 -- x-s3 를 생성하는 시도를 합니다. 즉, use1-az5 가용 영역에서 명명 규칙을 따르는 익스프레스 버킷을 생성합니다. 그런 다음 db 매개변수가 AWS 폴더 내에 키를 이름 공간으로 사용합니다:\n\n```js\nredis3-mytestcache -- use1-az5 -- x-s3\n    0/\n        my_key_1\n        my_key_2\n    1/\n        my_key_1\n    ...\n```\n\n이 설계에는 일반 캐싱 서버와 비교할 때 몇 가지 장단점이 있습니다. (가격-성능 외에, 이는 다음에 다룹니다):\n\n- 배포, 유지 관리, 이해하는 데 추가 인프라가 필요하지 않습니다.\n- 보안, 연결 및 권한 부여를 IAM 세분성으로 처리할 수 있습니다. 사용자는 예를 들어 새 캐시를 생성할 수 없지만 기존 캐시에서 키를 가져올 수 있는 권한을 가질 수 있습니다. redis3Client는 스크립트 실행 시 적용되는 AWS 권한을 상속하고 존중합니다 (마치 boto3.client('s3') 와 같이);\n- redis3Client는 연결 풀이 필요하지 않으며 공간이 부족해지지 않고 대량 처리를 지원합니다 (결국 S3 이기 때문에!). 최근에는 이 용어가 남발되고 있지만, 여기에는 분명히 \"서버리스 경험\"이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 Redis의 동시성 모델은 이해하기 매우 쉽습니다. 병행성이 많지 않기 때문에 원자 연산 지원이 시스템의 정확성을 보장하는 데 중요합니다. 안타깝게도 S3는 그러한 보장을 제공하지 않습니다. S3는 강력한 쓰기 후 읽기 일관성을 제공하지만(예를 들어 SET 직후에 DB 내용을 나열할 때 유용함), 여전히 INCR과 같은 것을 흉내 내는 방법은 없습니다. 이로 인해 누군가가 이전 my_value를 읽고 있는 동안에도 코드가 해당 값을 증가시키고 다시 저장하는 것을 피할 방법이 없습니다:\n\n```js\nv = GET my_value\nv = v + 1\nSET my_value v\n```\n\n이에 대해 어떤 사람들은 redis3Client MSET 및 MGET 명령어가 잘못된 이름을 가졌으며, Redis 파이프라인으로 보내는 키 목록과 관련된 것보다 원래의 원자적 명령어와 더 유사하다고 주장할 수 있습니다 (사실 이름 짓기와 캐싱을 한다는 것이 컴퓨터 과학에서 가장 어려운 두 가지일이라는 것이 밝혀졌습니다!).\n\n## 빠르고 비교적 저렴한 방법\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리의 파이썬 메소드가 얼마나 좋은지는 중요하지 않아요. 캐시는 빠르고 신뢰할 수 있어야 해요. 저희는 EC2에서 테스트 스크립트를 실행하고, 같은 가용 영역에 위치한 redis3 캐시와 표준 S3 버킷, Redis 인스턴스(그냥 편하게 Redis Labs에서 호스팅해요! ) 결과(초 단위)를 비교해요:\n\n![image](/assets/img/2024-06-19-RebuildingRedisonS3Express_1.png)\n\nRedis보다는 여전히 느리지만, redis3는 실제로 새로운 가격 성능 옵션으로, \"미숙한 S3 캐시\"보다 평균적으로 훨씬 더 빠를 뿐만 아니라 신뢰할 수 있음을 입증했어요(95백분위에서 5배).\n\n공식 가격표를 빠르게 살펴보면, AWS Redis 인스턴스와 비교했을 때 더 분명하게 알 수 있어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-06-19-RebuildingRedisonS3Express_2.png)\n\n1GB의 redis3 캐시는 메모리 지원 캐시보다 훨씬 저렴하게 구입할 수 있습니다 (추가 인프라 및 유지보수를 고려하지 않음).\n\n## 수괴카우보이, 다음에 봐요\n\nS3를 캐시로 사용하는 것은 미친 것처럼 보일 수 있지만, 새로운 익스프레스 버킷을 사용하면 그렇게 보이지 않습니다: Redis가 어디론가 사라지지 않는 한, 객체 스토리지와 데이터 애플리케이션의 상호 진화는 계속해서 새로운 트레이드 오프를 활용하는 흥미로운 패턴을 만들어냅니다. 이 실험을 좋아하셨다면, redis3 클래스를 직접 사용해보고 어떻게 생각하는지 알려주세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로, EC2를 S3 위에 올려 데이터 작업을 수행할 때 무엇이 발생하는지 신경 쓰신다면, Bauplan에 대한 최신 정보를 따르는 것을 잊지 마세요.\n","ogImage":{"url":"/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png"},"coverImage":"/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png","tag":["Tech"],"readingTime":8},{"title":"왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다","description":"","date":"2024-06-19 12:09","slug":"2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain","content":"\n작은 독립적인 서비스들이 각각 완벽하게 자신의 일을 하는 것, 개발자의 낙원 같지 않아요? 하지만 알아요? 가끔, 이건 정말 엄청난 고통일 수 있어요.\n\n저는 이 허세에 홀렸었어요.\n\n우리는 새 시스템을 구축하고 있었는데, '올바른' 방식으로 하겠다고 다짐했어요. 익숙한 거대한 단일체는 밖으로, 작은 마이크로서비스 떼가 들어왔어요. 처음에는 놀랍게 느껴졌어요 — 너무 깨끗하고, 너무 모듈화됐잖아요!\n\n하지만 현실이 닥쳤어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과는, 복잡성이 사라지지 않았습니다; 단지 변했습니다. 이것이 마이크로서비스가 당신의 영혼을 죽일 수 있는 이유입니다:\n\n# 수다스러운 캐시 문제\n\n이전에는 동일한 코드베이스에서 함수를 호출할 수 있었던 것을 기억하시나요? 이제 여러분의 절반 서비스는 네트워크 상에서 수다 떨고 있습니다. 그 중 하나가 성을 내면? 그 난장판을 디버깅하는 데는 행운이 필요할 겁니다.\n\n한 번은 간단했던 함수 호출이 교차 서비스 요청의 끝없는 사가로 변모하고 있습니다. 지연과 관련된 머리 아픔, 네트워크 어딘가에서 뭔가가 고장날까 두려워하는 늘스런 공포의 상태로 변해가고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일렇게 REST API와 메시지 큐를 사용하여 처리할 수 있을 것이라 생각할 수도 있지만, 사실은 그 소중한 밀리초가 누적됩니다. 작은 데이터 조각을 가져와야 하나요? 그것은 네트워크 호출입니다. 간단한 작업을 처리해야 하나요? 또 다른 호출이 필요합니다. 여러분의 시스템은 실제 일을 하는 대신 수다에 더 많은 시간을 낭비합니다.\n\n그런 다음, 불가피한 일이 벌어집니다. 여러분의 서비스 중 하나가 오동작하면 네트워크 타임아웃을 발생시키거나 엉망으로 된 데이터를 뱉어 냅니다. 그 속을 해체하는 과정을 즐기세요. 분산 디버깅은 분실된 양말을 찾는 것처럼 쉽지 않습니다. 각 네트워크 호프는 또 다른 용의자, 여러분의 비통의 근원이 될 수 있는 복잡성의 또 다른 층입니다.\n\n# 배포 지옥\n\n코드를 배포했을 때 직업을 바꾸어 야만한 일이 되려고 하거나 라마 농부가 되고 싶어졌던 기억을 여전히 갖고 계시나요? 네, 그런 날들은 이미 멀리 떠났습니다. 마이크로서비스로, 관리 가능한 프로세스였던 것이 불길한 기분을 내뿜는 다두와 여러 머리를 지닌 괴물로 변모했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n갑자기 어플리케이션 하나가 아니라 십여 개의 작은 괴물을 다루게 되었네요. 각각이 자체 빌드 프로세스, 테스트 슈트 및 신중한 조율이 필요해요. CI/CD 파이프라인은 이렇게 엄청난, 꼬인 루브 골드버그 장치가 되어 새롭고 흥미로운 실패로 매번 고장나는 것처럼 보여요. 잘못된 구성 하나, 맞지 않는 종속성 하나로 모든 것이 터져버릴 수 있어요. 배포 오류와 싸우면서 실제 기능 개발은 멈춰있게 되네요. 코드 복잡성을 운영 복잡성과 바꾸었군요.\n\n# 관찰성 부담\n\n과거 몇몇 전략적으로 배치된 로그 라인으로 무엇이 문제인지 알 수 있던 시절을 기억하시나요? 마이크로서비스로, 그런 시기는 이미 멀리 사라진 기억이 됐어요. 이제는 시스템을 이해하는 데 상당한 투자가 필요할 거예요.\n\n서비스 사이를 건너는 요청을 추적하려면 분산 추적 솔루션이 필요할 건데요. 서비스가 생성하는 로그의 해일을 해석하려면 로그 집계 도구가 기다리고 있어요. 그리고 멋진 대시보드와 경보 시스템을 잊지 마세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n갑자기 예산과 엔지니어링 시간이 시스템이 제대로 작동하는지 확인하는 데 사용되는 것으로 바뀌었네요. 모순적인 점은, 이 모든 복잡성을 더한 결과물로 인해 문제의 근본 원인을 찾기가 이전보다 더 어려워졌다는 느낌을 자주 받습니다. 당신은 가시성의 환상에 큰 대가를 지불하고 있는 것 같습니다.\n\n# 그들은 그리 독립적이지 않아요\n\n마이크로서비스의 전체 약속은 느슨하게 결합되고 서로 교환 가능한 조각들의 아름다운 비전인데, 사실은 종종 많은 허세였던 것으로 밝혀졌어요. 실제로 \"독립적\"인 서비스들이 의외로 얽혀있는 방식으로 복잡해 집니다.\n\n한 서비스의 API를 조정하면 어떤 결과도 없을 것이라고 생각하시나요? 한 번 더 생각해보세요. 숨겨진 가정, 문서화되지 않은 의존성, 그리고 행동의 미묘한 변화들이 불량한 음식 중독과 같이 시스템 전반을 퍼져나갈 수 있습니다. 당신이 알게 모르게, 여러 팀에 걸쳐 다시 작업에 뛰어들어서 왜 이러한 열광을 사들인 걸까 궁금해할 수도 있어요. 민첩성에 대한 약속에 대해 말할 수 없다 — 이제 당신은 아무것도 바꾸기를 두려워할 정도로 두려워하게 되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 단일체만큼 좋은 경우도 있어요\n\n잠시 동안 독단적인 견해를 내려 놓아 보죠. 구성 요소들이 본질적으로 연결되어 있는 작은 프로젝트, 팀 또는 시스템의 경우, 단일체는 생명보호병이 될 수도 있어요. 이는 단순함을 추구하여 유행성을 포기하는 것과도 같아요.\n\n생각해 보세요: 네트워크 지연 문제가 없고, 디버깅이 간단하며 울고 싶지 않게 배포할 수 있는 장점이 있어요. 확실히 성장하면 조금 엉망일 수 있지만, 코드베이스 내 신중한 모듈화로 그것을 완화할 수 있어요. 그리고 솔직히 말하자면, 잘못 설계된 마이크로서비스 시스템이 보잘것없이 퍼져나가는 모습은 그다지 즐겁지 않아요.\n\n나쁜 말 안 하겠습니다. 마이크로서비스가 나쁜 것은 아니에요. 그것들은 대규모 시스템에서 빛을 발하거나, 구성 요소 간에 완전한 독립성이 필요한 경우에 유용해요. 하지만 맹목적으로 트렌드를 따라가서 모든 것을 마이크로서비스로 분리하는 것은 정말로 무분별한 복잡성과 개발자의 탈진으로 이어지는 결과를 초래할 수도 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가끔 \"옛날 방식\"의 단일체가 더 현명한 선택일 수 있습니다. 인프라와 무쟁하기보다는 가치 전달에 집중할 수 있게 해줍니다.\n\n나는 반드시 마이크로서비스를 비판하는 것은 아닙니다. 특히 확장성이 중요한 대규모 복잡한 시스템에서 유용할 수 있습니다. 그러나 기술 세계는 항상 최신 유행을 지나치게 홍보하여 검증된 솔루션을 낡은 것으로 여기게 만드는 나쁜 버릇이 있습니다.\n\n쿨한 것을 하고 있는 친구들이 그렇게 하고 있다고 해서 우리도 모든 애플리케이션을 마이크로서비스로 나누는 것을 맹목적으로 따라갈 필요는 없습니다. 한 발 물러나서 프로젝트의 필요를 정직하게 평가하고, 복잡성 대비가 정말 그만한지 고려해보세요. 잘 설계된 단일체가 작업 부담이 적게 더해도 동일한 기능을 제공할 수 있는 경우에는 왜 그것을 선택하지 않을까요?\n\n마이크로서비스가 디폴트일 필요는 없습니다; 이는 의도적인 결정이어야 합니다. 독단적인 사고를 버리고 더 실용적인 접근 방식을 채택합시다 — 적합한 도구가 승리하는 아키텍처. 가장 유행하는 것이 아니더라도. 아니, 혹시 서면이 잘 갖춰진 단일체의 간결함에 대한 새로운 감사함을 발견할지도 모릅니다.\n","ogImage":{"url":"/assets/img/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain_0.png"},"coverImage":"/assets/img/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain_0.png","tag":["Tech"],"readingTime":5},{"title":"클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기","description":"","date":"2024-06-19 12:08","slug":"2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills","content":"\n2019년에 클라우드 컴퓨팅을 배우기 위한 첫 번째 플랫폼으로 AWS Educate를 이용했어요.\n\n2019년, 인도네시아의 한 석탑 대학에서 물리학 석사 학위를 받은 후, 컴퓨터 과학 전공이 없는 저에게도 기술 산업에서 일할 기회가 있다는 것을 깨달았어요. 그 당시 인도네시아는 스타트업 붐을 경험하고 있었는데, 저의 학부 동기들 중 일부가 이러한 기업에서 직장을 얻은 것을 보았어요. 처음에는 의심이 많았지만 배우기 시작하기로 결심했어요. 그때 한 친구가 인도네시아 정보부가 후원하는 클라우드 컴퓨팅 및 머신 러닝(ML)에 초점을 맞춘 교육 프로그램에 참여하도록 초대했어요. 처음에는 주저했지만, 물리학 외의 분야를 탐험할 수 있는 좋은 기회라고 생각했어요.\n\n선발 과정을 거친 후에 저와 제 친구는 그 프로그램에 선발되었어요. 저희는 분야 전문가들의 지도를 받았죠. 그것이 제 첫 클라우드 컴퓨팅 체험이었고, 저는 AWS Educate를 통해 중요한 클라우드 기초 지식을 실습하면서 배우기 시작했어요.\n\n익숙치 않은 용어로 새로운 클라우드 컴퓨팅을 배우는 것은 꽤 어려웠어요. 교육 기간이 한 달 뿐이었기 때문에 저는 정보를 천천히 받아들이려고 노력했어요. 가장 간단한 개념부터 이해하려고 노력했어요: 가용성, 지연 시간, 내결함성, 데이터베이스, 서버, 네트워킹, 스토리지 등의 클라우드 용어를 이해하는 것부터 시작했어요. 프로그램이 끝나면 우리가 만든 간단한 프로젝트를 발표하고 모두와 함께 졸업을 축하하는 시간을 가졌어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills](/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png)\n\nAWS Educate was the first platform to guide me in learning about cloud computing. Even though it was not as advanced back then, AWS Educate inspired me to continue learning about the cloud, especially as a beginner. The system was well-organized, which made it easier for me to learn in a structured, gradual, and step-by-step manner.\n\n### Traditional AI vs. Generative AI\n\nApart from cloud computing, my friends and I delved into machine learning. Our project focused on finding the best model for a simple case study: hospital readmission. Hospital readmission occurs when patients return to the hospital after being discharged. A high readmission rate signifies lower quality of care. We analyzed data from 130 hospitals in the U.S. After experimenting with different models, we discovered that the random forest model performed best when dealing with large datasets. This approach is known as traditional AI.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n전통적 AI는 입력 데이터를 기반으로 한 특정 작업 및 예측에 초점을 맞춥니다. 구조화된 데이터를 분석하고 패턴을 식별하며 기존 데이터에 기반한 결정을 내리는 데 능숙합니다. 반면에 GPT-3과 같은 생성적 AI는 새로운 콘텐츠 생성을 목적으로 합니다. 방대한 양의 데이터로부터 학습한 패턴을 기반으로 텍스트, 이미지 및 기타 미디어를 생성할 수 있습니다. 전통적 AI는 분류 및 회귀와 같은 작업에 뛰어나지만, 생성적 AI는 새로운 인간과 유사한 콘텐츠를 생성하고 복잡한 문제에 대한 창의적인 해결책을 찾는 데 빛을 발합니다.\n\n![AI](/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_1.png)\n\n전통적 기계 학습 모델은 제공된 데이터를 기반으로 작업을 수행합니다. 순위 매기기, 감정 분석, 이미지 분류 등과 같은 예측을 할 수 있습니다. 그러나 각 모델은 한 가지 작업만 수행할 수 있으며, 이를 성공적으로 수행하려면 모델을 주의 깊게 훈련해야 합니다. 모델이 훈련되는 동안 데이터를 분석하고 패턴을 찾습니다. 그런 다음 이러한 모델은 이러한 패턴을 기반으로 예측을 수행합니다. 전통적 AI는 사용 범위가 매우 제한적하며 (또한 반복적으로 모델링해야 하고 매우 큰 데이터 세트가 필요하기 때문에 복잡할 수 있음), 세계 기업들이 생성적 AI를 개발하기 위해 경쟁을 벌이고 있습니다.\n\n2024년, AWS Educate은 생성적 AI 개요 과정을 소개했습니다. 이전 글에서 \"함께 배우고 싶다\"라고 말했다면, 이 강의를 수강한 적이 있나요? 저는 모든 강의를 마치고 배지를 받았습니다. 여기서 생성적 AI 강좌를 응원하고 싶은 중요한 포인트를 전달하고 싶습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- AI 생성기는 기계 학습 기반 모델에 의해 구동됩니다. 이러한 모델은 콘텐츠를 생성할 수 있습니다. 이 AI 생성 콘텐츠는 편집 가능하며, 필요에 맞게 수정할 수 있습니다.\n- Foundation 모델은 전통적인 기계 학습 모델과 크기, 다양성, 여러 작업을 수행할 수 있는 능력에서 상당히 다릅니다. 이 모델은 라벨이 지정된 데이터를 수집하거나 여러 모델을 별도로 훈련할 필요 없이 여러 작업을 수행할 수 있습니다.\n- 프롬프트 엔지니어링은 모델에 프롬프트를 입력하여 출력으로 표시되는 추론을 생성하는 것을 포함합니다. 그러나 출력물이 만족스럽지 않은 경우 프롬프트를 조정하거나 작업 예제를 제공해야 할 수 있습니다. 프롬프팅은 중요한 기술이 될 것이며, 우리 자신이 올바른 프롬프트를 제공하는 방법을 연습할수록 AI 결과는 더 좋아질 것입니다.\n- 생성적 AI와 관련된 AWS 서비스는 무엇인가요? 다음은 슬라이드입니다.\n\n![이미지](/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_2.png)\n\nAmazon Bedrock\n\n- 설명: Amazon Bedrock은 쉬운 API를 통해 Amazon 및 다른 제공업체의 다양한 대형 언어 모델(LLM)에 액세스할 수 있도록 제공하여 개발자가 모델 인프라를 관리하지 않고 생성적 AI 응용 프로그램을 구축할 수 있게 합니다.\n- 비유: 다양한 작가의 최고의 책이 있는 큰 도서관을 상상해보세요. 필요한 책(모델)을 빌릴 수 있고 사용 후 반납할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아마존 코드위스퍼러\n\n- 설명: 아마존 코드위스퍼러는 AI를 사용하여 개발자가 코드를 작성하는 동안 빠른 코드 제안을 제공하는 도구로, 코드 작성 중에 코드의 맥락에 기반한 스니펫, 함수 및 로직을 제공하여 생산성을 향상시킵니다.\n- 유사성: 자신을 지도해주는 지능적인 비서와 함께 삽시간에 다음 단어나 문장을 제안하는 작가로 생각해 보세요. 이를 통해 더 빨리, 더 부드럽게 쓸 수 있습니다.\n\nAWS 인퍼런티아\n\n- 설명: AWS 인퍼런티아는 AWS의 특수화된 가속기 칩으로, 머신러닝 모델의 추론을 가속화하는 것을 목적으로 설계되었습니다. 추론은 훈련된 모델을 실행하여 예측이나 결정을 내리는 과정을 말합니다.\n- 유사성: 일정한 수학적 문제를 해결하는 데 특별히 설계된 초고속 계산기가 있다고 상상해 보세요. 이를 통해 짧은 시간 내에 많은 문제를 해결할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS Trainium\n\n- 설명: AWS Trainium은 AWS의 전문 가속기 칩으로, 기계 학습 모델의 훈련 속도를 높여 복잡한 AI 모델을 훈련하는 데 필요한 시간과 비용을 줄입니다.\n- 비유: AWS Trainium은 엘리트 선수 훈련을 위한 고급 장비가 갖춰진 개인 체육관처럼 생각해보세요. 이를 통해 효과적으로 훈련하고 더 빨리 최고의 성과를 달성할 수 있습니다.\n\nAmazon SageMaker JumpStart\n\n- 설명: Amazon SageMaker JumpStart는 미리 구축된 솔루션과 사용 준비가 된 모델을 제공하여 기계 학습 애플리케이션 개발을 가속화합니다. 미리 훈련된 모델과 다양한 사용 사례에 대한 튜토리얼 노트북이 포함되어 있습니다.\n- 비유: 테이블을 만들고 싶다고 상상해보세요. 준비가 완료된 모든 부품이 포함된 완전 조립 키트와 단계별 메뉴얼을 받아서 아무것도 잘라내거나 측정할 필요 없이 지침에 따라 진행할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 컴퓨팅 분야에서 학습하고 근무하는 저로서는 AI가 인간을 대체할 수도 있다는 우려가 있었습니다. 그러나 이러한 두려움이 과장되었을 수 있지만, 쉽게 이해할 수 있는 이 강의를 통해 AI가 어떻게 작동하는지 이해하는 것에 가치가 있다고 생각해요. 엔지니어/개발자로서, 이를 통해 우리는 이전보다 빠르게 문제를 해결할 수 있게 되었습니다. AI는 올바르게 활용된다면 우리의 작업을 크게 향상시킬 수 있어요. 이 강의는 입구와 같은 존재이며, 2019년에 클라우드 여정을 시작했지만, 이를 통해 많은 새로운 것들을 배웠습니다.\n\n결론\n\n전통적인 AI 모델은 일반적으로 특정 작업을 위해 구축되고 훈련되며 해당 작업에 맞춤화된 데이터셋으로 구축됩니다. 예를 들어, 얼굴 인식 AI 모델은 다양한 얼굴 이미지를 기반으로 훈련될 것입니다. 이러한 모델들은 특정 작업에서 우수한 성과를 보이지만, 큰 재훈련 없이는 다른 문맥에서의 융통성이 부족합니다. 반면, 생성적 AI의 기초 모델은 다재다능하며 작은 조정만으로 다양한 작업에 적응시킬 수 있습니다. 마치 보편적인 성형이 작은 수정으로 다양한 제품을 만들어내는 것과 비슷하죠.\n\n이어서, AWS Educate의 또 다른 흥미로운 강좌를 추천드리며, 이 강좌는 AWS의 AI 서비스 중 하나인 Amazon Bedrock에 초점을 맞추고 있습니다. 다음은 강좌 수강 방법입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- www.awseducate.com에 방문해주세요.\n- 제네레이티브 아마존 베드락 소개를 선택해주세요.\n- 코스를 약 0.75시간 내에 완료해주세요.\n- 경험을 공유해주세요!\n\n그래서, 클라우드 컴퓨팅에서 AI의 미래를 탐험하고 오늘 당신의 잠재력을 발휘해보세요! 즐거운 학습되세요!\n\n사랑을 담아,\n\nNova Lailatul Rizkiyah\n","ogImage":{"url":"/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png"},"coverImage":"/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png","tag":["Tech"],"readingTime":8},{"title":"AWS 인터뷰 질문 DAY_25 90","description":"","date":"2024-06-19 12:03","slug":"2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS","content":"\n![](/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png)\n\nBelow are some basic AWS interview questions along with the answers.✍\n\n# 1. What is Cloud Computing and what are its features?\n\nCloud computing is a general term for the delivery of hosted computing services and IT resources over the internet with pay-as-you-go pricing.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 컴퓨팅의 특징은 다음과 같습니다:\n\n- 자원 풀링: 클라우드 서비스 제공업체는 다양한 서비스를 제공하는 각각의 다른 클라이언트 사이에서 자원을 공유할 수 있습니다.\n- 넓은 접근성: 클라이언트는 장치와 인터넷 연결이 있는 어디서든 클라우드 데이터에 접근하거나 클라우드로 데이터를 전송할 수 있습니다. 이러한 기능은 조직 전역에서 어디서든 이용 가능하며 인터넷의 도움으로 실현됩니다.\n- 신속한 탄력성: 이 클라우드 기능은 필요에 따라 신속하게 확장하거나 축소할 수 있는 워크로드를 비용 효율적으로 처리할 수 있게 합니다. 사용자가 서버를 요청하면 제공되고 필요 시 바로 확장됩니다.\n- 셀프 서비스 온디맨드: 이는 클라이언트가 서버 가동 시간, 기능 및 할당된 네트워크 저장소를 계속 모니터링할 수 있도록 합니다. 이는 클라우드 컴퓨팅의 기본 기능이며 고객은 자신의 요구에 맞춰 컴퓨팅 능력을 제어할 수도 있습니다.\n- 사용량 측정: 이를 통해 제공자와 고객 모두가 사용된 서비스와 목적을 모니터링하고 보고할 수 있습니다. 이는 청구 모니터링을 돕고 리소스의 최적 이용을 보장합니다.\n\n# 2. 다양한 클라우드 배포 모델은 무엇인가요?\n\n클라우드 배포 모델은 데이터 저장량 및 인프라 액세스 권한에 따라 선택할 수 있는 가상 컴퓨팅 환경으로 작동합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 배포 모델에는 4가지 유형이 있습니다: -\n\n- 공용 클라우드: 이름 그대로 공개적으로 접근 가능합니다. 클라우드의 공개 배포 모델은 성장하고 변동하는 수요를 갖는 조직에 적합합니다. 또한 보안 우려가 낮은 기업들에게 좋은 선택지입니다. 따라서 공개 인터넷에서 네트워킹 서비스, 컴퓨팅 가상화 및 저장소에 대해 클라우드 서비스 제공업체에 요금을 지불합니다.\n- 사설 클라우드: 데이터 센터와 통합되어 내부 IT 팀이 관리합니다. 대체로 외부에 호스팅할 수도 있습니다. 사설 클라우드는 맞춤화가 필요한 특정 조직의 요구를 충족시키는 더 큰 기회를 제공합니다. 비용 효율성 및 데이터 및 자원에 대한 더 큰 제어를 찾는 기업들은 사설 클라우드를 더 적합한 선택으로 여길 것입니다.\n- 하이브리드 클라우드: 두 개 이상의 클라우드 아키텍처를 조합한 형태입니다. 하이브리드 클라우드의 각 모델은 서로 다르게 기능하지만, 하나의 아키텍처의 일부입니다. 더 나아가 클라우드 컴퓨팅 모델의 이 배포 일환으로 내부 또는 외부 제공 업체가 리소스를 제공할 수 있습니다.\n- 커뮤니티 클라우드: 공용 클라우드와 유사한 방식으로 운영됩니다. 유일한 차이점은 특정 목표와 사용 사례를 공유하는 특정 사용자 그룹에만 액세스 권한을 부여한다는 것입니다. 이러한 클라우드 컴퓅팅 배포 모델 유형은 내부적으로 또는 제3자 벤더에 의해 관리 및 호스팅됩니다.\n\n# 3. 클라우드 컴퓨팅의 다양한 유형은 무엇인가요?\n\n클라우드 컴퓨팅에는 인프라스트럭처 서비스(IaaS), 플랫폼 서비스(PaaS) 및 소프트웨어 서비스(SaaS)라는 세 가지 주요 유형이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- IaaS: IaaS는 가상화된 컴퓨팅 자원을 제공하며 가상 머신, 스토리지 및 네트워크와 같은 자원을 인터넷을 통해 제공합니다. 사용자는 인프라에서 실행하는 운영 체제 및 어플리케이션을 제어할 수 있어 더 큰 유연성과 맞춤 설정이 가능합니다.\n- PaaS: PaaS는 개발자가 기반 인프라를 관리하지 않고 애플리케이션을 구축, 배포 및 관리할 수 있는 플랫폼을 제공합니다. 개발 도구, 데이터베이스 및 실행 환경을 포함한 미리 구성된 환경을 제공하여 개발자가 인프라 관리 대신 애플리케이션 개발에 집중할 수 있습니다.\n- SaaS: SaaS는 인터넷을 통해 구독 기반으로 소프트웨어 애플리케이션을 제공합니다. 사용자는 설치나 관리가 필요하지 않고 이러한 애플리케이션에 액세스하고 사용할 수 있습니다. SaaS의 예로는 이메일 서비스, 고객 관리(CRM) 소프트웨어, Google Workspace와 같은 생산성 도구가 있습니다.\n\n# 4. 데이터 센터, 리전, 가용 영역(AZ), 엣지 위치, 로컬 영역, 웨이브렝스 영역은 무엇인가요?\n\n데이터 센터는 복잡한 네트워크, 컴퓨팅 및 스토리지 인프라를 이용하여 애플리케이션 및 데이터에 대한 공유 접근을 제공하는 시설입니다.\n\n리전은 특정 AWS 인프라 세트를 통해 서비스되는 지리적 영역입니다. 각 리전에는 독립된 거리와 독립된 전원 및 냉각으로 서로 격리된 여러 가용 영역이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가용 영역(Availability Zone)은 AWS 지역 내에서 고가용성과 오류 허용성을 제공하기 위해 설계된 격리된 데이터 센터입니다.\n\n에지 위치(Edge Location)는 사용자에게 빠르게 콘텐츠를 전달하기 위해 사용되는 데이터 센터입니다. 사용자에게 가장 가까운 위치에 있는 사이트입니다.\n\n로컬 영역(Local Zone)은 컴퓨팅 및 스토리지 등의 리소스를 사용자에게 더 가까운 여러 위치에 배치할 수 있도록 제공합니다.\n\n파장(Zones)은 개발자가 5G 기기와 사용자에게 초저 지연 시간을 제공하는 애플리케이션을 구축할 수 있도록 합니다. 파장은 표준 AWS 컴퓨팅 및 스토리지 서비스를 통신 사업자의 5G 네트워크 가장자리에 배포합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 5. AWS가 무엇인가요?\n\nAWS는 아마존 웹 서비스(Amazon Web Services)의 약자입니다. AWS는 아마존에서 제공하는 클라우드 컴퓨팅 플랫폼으로, 다양한 종류의 애플리케이션 및 서비스를 유연하고 확장 가능하며 비용 효율적으로 구축하고 배포하는 데 도움이 되는 다양한 클라우드 서비스를 제공합니다.\n\n# 6. 사용한 AWS 서비스 5가지와 사용 사례는 무엇인가요?\n\n- EC2 (Elastic Compute Cloud): EC2는 가상 서버(인스턴스)를 시작하여 애플리케이션을 실행할 수 있는 확장 가능한 클라우드 컴퓨팅 서비스입니다. 인스턴스 유형과 운영 체제를 선택할 수 있어, 웹 애플리케이션 호스팅부터 데이터 처리 작업까지 다양한 사용 사례에 적합합니다.\n- IAM (Identity and Access Management): IAM은 AWS의 신원 관리 서비스입니다. AWS 리소스에 누가 액세스할 수 있고 어떤 작업을 수행할 수 있는지 제어할 수 있습니다. 사용자 계정, 역할 및 권한을 관리하여 AWS 환경의 보안을 보장하는 데 중요합니다.\n- S3 (Simple Storage Service): S3는 저장 및 데이터 검색에 일반적으로 사용되는 확장 가능한 객체 저장 서비스입니다. 이미지, 비디오, 백업과 같은 정적 자산을 저장하는 데 효과적이며, 다른 AWS 서비스와 통합하여 정적 웹 사이트를 호스팅하거나 애플리케이션 데이터를 저장할 수 있습니다.\n- RDS (Relational Database Service): RDS는 MySQL, PostgreSQL, Oracle, SQL Server와 같은 관리형 관계형 데이터베이스를 제공합니다. 애플리케이션 실행, 사용자 데이터 저장, 분석 및 보고용으로 사용됩니다.\n- CloudWatch: CloudWatch는 AWS의 모니터링 및 관측 서비스입니다. 메트릭을 수집하고 추적하며, 로그 파일을 모니터링하고 경보를 설정할 수 있습니다. AWS 리소스의 작동 상태 및 성능에 대한 통찰력을 얻고, 운영 이벤트와 문제에 실시간으로 대응하는 데 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 7. 클라우드 환경으로 로그를 전송하는 데 사용되는 도구들은 무엇인가요?\n\n클라우드 환경으로 로그를 전송하는 데 여러 도구들을 사용할 수 있습니다. 일반적으로 사용되는 도구들은 다음과 같습니다:\n\n- Amazon CloudWatch Logs: CloudWatch Logs는 AWS의 내장 서비스로, 다양한 AWS 리소스 및 애플리케이션에서 로그 데이터를 수집, 모니터링하고 저장할 수 있습니다. AWS 리소스를 구성하여 그들의 로그를 직접 CloudWatch Logs로 전송할 수 있습니다.\n- AWS CloudTrail: AWS CloudTrail은 AWS 계정 내의 API 활동 및 이벤트를 캡처하고 로깅하여 사용자, 서비스 또는 리소스에 의해 수행된 작업을 파악할 수 있게 합니다.\n- Elasticsearch: Elasticsearch는 오픈 소스 검색 및 분석 엔진으로, 로그를 저장, 색인화 및 분석하는 데 사용할 수 있습니다. Logstash 및 Kibana(ELK 스택)과 함께 자주 사용되어 로그 관리 및 분석에 활용됩니다.\n- Fluentd: Fluentd는 다양한 소스에서 로그를 수집하여 클라우드 저장소 또는 분석 플랫폼으로 전송할 수 있는 오픈 소스 데이터 수집기입니다.\n- Logstash: Logstash는 ELK 스택의 일부로, 로그를 수집, 구문 분석 및 변환한 후 저장소 또는 분석 플랫폼으로 전송하는 데 사용됩니다.\n\n# 8. IAM 역할들은 무엇이며, 어떻게 만들고 관리할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS의 IAM(Identity and Access Management) 역할은 신뢰하는 엔터티에 권한을 부여하는 방법입니다. 이러한 엔터티는 AWS 서비스, 응용 프로그램 또는 AWS 계정 또는 외부 AWS 계정 내의 사용자가 될 수 있습니다. 역할은 장기 보안 자격 증명인 액세스 키나 비밀번호 없이 AWS 리소스에 액세스하기 위한 권한 위임을 안전하게 수행하는 방법입니다.\n\nIAM 역할은 귀하를 대신해 AWS 리소스와 상호 작용해야 하는 서비스 및 응용 프로그램에 일반적으로 사용됩니다.\n\n- AWS 관리 콘솔에 로그인: AWS IAM 콘솔로 이동합니다 (console.aws.amazon.com/iam).\n- 역할로 이동: 왼쪽 탐색 창에서 \"역할\"을 선택합니다.\n- 새 역할 생성:\n\n- \"역할 생성\" 버튼을 클릭합니다.\n- 신뢰하는 엔터티 유형을 선택합니다 (예: AWS 서비스, 다른 AWS 계정 또는 SSO 식별 공급자).\n- 역할 목적을 가장 잘 설명하는 사용 사례를 선택합니다. 예를 들어 EC2 인스턴스용 역할을 생성하는 경우, 사용 사례로 \"EC2\"를 선택할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4. 권한 설정:\n\n- 역할에 정책을 연결합니다. 정책은 역할이 수행할 수 있는 작업을 정의합니다. 기존 정책 중 선택하거나 사용자 정의 정책을 생성할 수 있습니다.\n\n5. 이름 지정 및 검토:\n\n- 역할에 이름을 지정하고 선택적으로 태그를 추가하여 조직화를 돕습니다.\n- 역할의 구성을 검토하고 \"역할 생성\"을 클릭합니다.\n- 신뢰 관계 업데이트: 신뢰 관계를 편집하여 누가 또는 무엇이 역할을 가정할 수 있는지 허용하거나 제한할 수 있습니다.\n- 권한 업데이트: 권한을 부여하거나 제거하기 위해 정책을 연결 또는 분리할 수 있습니다. 역할에 필요한 권한이 있는지 확인하고 필요에 맞게 정책을 검토하고 업데이트하는 것이 중요합니다.\n- 역할 삭제: 더 이상 필요하지 않은 역할은 삭제할 수 있습니다. 역할 삭제 시 서비스 및 애플리케이션에 영향을 줄 수 있으니 조심해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 9. 시스템을 다운타임 없이 업그레이드 또는 다운그레이드 하는 방법\n\n시스템을 다운타임 없이 업그레이드 또는 다운그레이드하는 것은 특정 전략과 모베스트 프랙티스를 구현함으로써 가능합니다. 이 고수준 접근 방식을 살펴보겠습니다:\n\n- 로드 밸런서: 로드 밸런서를 설정하여 트래픽을 여러 인스턴스 또는 노드에 분산시켜야 합니다. 이를 통해 업그레이드/다운그레이드 프로세스 중에도 트래픽을 원활하게 리디렉션할 수 있습니다.\n- 다중 환경: 여러 환경(예: 스테이징, 프로덕션)을 생성하여 업그레이드/다운그레이드 프로세스를 실행해야 합니다. 하나를 업그레이드/다운그레이드하는 동안 영향을 받지 않는 환경으로 트래픽을 보내야 합니다.\n- 블루/그린 배포: 새 버전(그린)이 기존 버전(블루)과 함께 배포되는 블루/그린 배포 전략을 구현해야 합니다. 천천히 트래픽을 블루 환경에서 그린 환경으로 전환합니다.\n- 데이터베이스 복제: 데이터베이스 복제 기술을 사용하여 업그레이드/다운그레이드된 버전의 두 번째 인스턴스를 생성해야 합니다. 데이터베이스 변경 사항을 동기화하고 업데이트된 데이터베이스를 사용하도록 응용 프로그램을 다운타임 없이 전환해야 합니다.\n- 롤링 업그레이드: 하나씩 인스턴스 또는 구성 요소를 업데이트하여 전체 프로세스 중에 응용 프로그램이 사용 가능함을 보장하는 롤링 업그레이드를 수행해야 합니다.\n- 헬스 체크 및 모니터링: 시스템의 가용성을 보장하기 위해 헬스 체크를 구현하고 문제가 발견되면 프로세스를 밀접하게 모니터링해야 합니다. 이상이 감지되면 즉시 롤백해야 합니다.\n\n# 10. 인프라스트럭처 코드(Infrastructure as code)란 무엇이며 어떻게 사용하나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인프라스트럭처 코드(IaC)는 기계가 읽을 수 있는 구성 파일이나 스크립트를 사용하여 인프라 자원을 관리하고 프로비저닝하는 실천 방법을 말합니다. 이는 수동 프로세스 대신 소프트웨어 코드로 인프라를 처리하여 버전 관리, 자동화 및 재생산성을 가능하게 합니다.\n\n- 정의: 인프라스트럭처 코드는 원하는 상태의 인프라 자원을 정의하는 구성 파일이나 스크립트를 작성하는 것을 포함합니다. (예: AWS CloudFormation, Terraform, 또는 Ansible과 같은 도구 사용)\n- 자동화: IaC를 통해 인프라의 자동 프로비저닝 및 관리가 가능해지며 수동 구성이 필요 없어지고 인간 에러를 줄일 수 있습니다.\n- 버전 관리: 인프라 코드는 버전 관리 시스템에 버전을 매기고 저장할 수 있어 팀이 협업하고 변경을 추적하며 필요한 경우 이전 버전으로 롤백할 수 있습니다.\n- 재생산성: IaC를 사용하면 인프라를 쉽게 다른 환경으로 복제할 수 있어 개발, 테스트 및 프로덕션 간 불일치를 줄이고 일관성을 유지할 수 있습니다.\n- 확장성: IaC는 프로그래밍적으로 조정할 수 있는 매개변수와 정책을 정의하여 인프라 자원의 확장을 간소화하며 워크로드나 수요 변화를 수용할 수 있습니다.\n\n# 11. 로드 밸런서(load balancer)란 무엇인가요? 귀하의 경험에 따른 각 종류의 밸런서 시나리오를 제시해주세요.\n\n로드 밸런서는 사용자와 서버 그룹 사이에 위치하여 모든 리소스 서버가 공평하게 사용되도록 보장하는 보이지 않는 편의 기기 또는 서비스입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Application Load Balancer (ALB): ALB는 OSI 모델의 애플리케이션 레이어(Layer 7)에서 작동합니다. URL 기반 라우팅, 콘텐츠 기반 라우팅 및 HTTP/HTTPS 프로토콜 지원과 같은 고급 라우팅 기능을 제공합니다.\n- Network Load Balancer (NLB): NLB는 전송 레이어(Layer 4)에서 작동하며 초저지연으로 대량 트래픽을 처리하기 위해 설계되었습니다. TCP, UDP 및 TLS 트래픽에 적합하여 게임 애플리케이션 및 IoT 애플리케이션과 같은 사용 사례에 적합합니다.\n- Classic Load Balancer (CLB): CLB는 AWS에서 제공하는 레거시 로드 밸런서입니다. Layer 4와 Layer 7에서 모두 작동하며 기본적인 로드 밸런싱 기능을 제공합니다.\n\n## 12. 클라우드포메이션(CloudFormation)은 무엇이며 왜 사용됩니까?\n\nAWS CloudFormation은 템플릿을 사용하여 선언적 방식으로 인프라 리소스를 정의하고 프로비저닝할 수 있는 서비스입니다. AWS 리소스의 생성, 구성 및 관리를 자동화하는 방법을 제공합니다.\n\n클라우드포메이션은 배포를 자동화하고 리소스 일관성을 보장하며 스케일링을 관리하고 종속성을 처리하며 AWS 환경에서 변경 관리를 간소화하는 데 사용됩니다. 이는 AWS에서 인프라 자동화 및 관리를 위한 주요 도구입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 13. AWS CloudFormation과 AWS Elastic Beanstalk의 차이점은 무엇인가요?\n\nAWS CloudFormation:\n\n- AWS 인프라를 코드로 정의하고 프로비저닝하는 서비스입니다.\n- JSON 또는 YAML로 템플릿을 작성하여 AWS 리소스와 구성을 지정합니다.\n- EC2 인스턴스, 데이터베이스, 네트워킹 등 포함 전체 인프라 제어에 유용합니다.\n- 복잡한 아키텍처를 지원하며 리소스를 생성하거나 수정할 수 있습니다.\n- 주로 인프라 오케스트레이션과 구성 관리에 사용됩니다.\n\nAWS Elastic Beanstalk:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 웹 애플리케이션을 배포하고 관리하기 위한 Platform as a Service (PaaS)입니다.\n- 개발자는 자신의 애플리케이션 코드를 제공하고 Elastic Beanstalk이 인프라 프로비저닝을 처리합니다.\n- 간소화된 애플리케이션 배포와 확장성에 이상적입니다.\n- 다양한 프로그래밍 언어와 프레임워크를 지원합니다.\n- 인프라 관리에 깊게 개입하지 않고 신속하고 간편한 애플리케이션 호스팅에 최적화되어 있습니다.\n\n# 14. Amazon EC2 인스턴스의 저장 옵션을 나열하세요.\n\n- Amazon Elastic Block Store (EBS)\n- Amazon EC2 인스턴스 스토어\n- Amazon Elastic File System (EFS)\n- Amazon Simple Storage Service (S3)\n- Amazon Glacier\n\n# 15. 클라우드에서 발생할 수 있는 보안 공격 유형은 무엇이 있으며, 이를 최소화하는 방법은 무엇입니까?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 환경에서 여러 보안 공격이 발생할 수 있습니다:\n\n- 미인가된 접근: 공격자가 클라우드 자원과 데이터에 미인가된 접근을 시도할 수 있습니다.\n- 데이터 유출: 민감한 데이터가 클라우드 저장소나 데이터베이스에서 노출되거나 도용될 수 있습니다.\n- 분산 서비스 거부 (DDoS): 공격자가 과도한 트래픽으로 클라우드 인프라를 넘치게 하여 서비스를 이용할 수 없게 할 수 있습니다.\n- 보안이 취약한 API: API의 취약점을 악용하여 미인가된 접근이나 클라우드 자원 조작이 가능합니다.\n- 내부 위협: 특권 있는 접근 권한을 가진 악의적 내부 사용자가 민감한 정보를 남용하거나 유출할 수 있습니다.\n\n이러한 공격을 최소화하기 위해 다음과 같은 보안 모법을 따르세요:\n\n- 강력한 접근 제어를 시행하세요. 강력한 암호, MFA, 최소 특권 원칙을 적용하세요.\n- 이동 중인 데이터와 정지된 데이터를 암호화하세요.\n- 소프트웨어와 시스템을 정기적으로 업데이트하고 패치하세요.\n- 보안 사건을 감지하고 대응하도록 활동을 모니터링하고 로깅하세요.\n- 방화벽 및 침입 탐지/방지 시스템과 같은 네트워크 보안 조치를 시행하세요.\n- 정기적으로 보안 평가와 감사를 수행하세요.\n- 직원들에게 보안 인식 및 모범 사례에 관한 교육을 실시하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 16. EC2 인스턴스 키를 분실했을 때 복구할 수 있을까요?\n\nEC2 인스턴스와 인증에 사용된 키 쌍을 분실한 경우 해당 키를 사용하여 인스턴스에 액세스를 복구하거나 회복할 수 없습니다.\n\n그러나 여러 가지 방법으로 여전히 액세스를 복구할 수 있습니다: -\n\n- 원본 키 쌍 복구: 개인 키의 백업이 있거나 분실한 키를 검색할 수 있다면 키 쌍을 교체함으로써 액세스를 회복할 수 있습니다.\n- 새 EC2 인스턴스 생성: 원본 키 쌍을 복구할 수 없다면 인스턴스의 AMI를 만들고 새 키 쌍으로 새로운 인스턴스를 시작할 수 있습니다.\n- 인스턴스 메타데이터를 통한 액세스 (Linux 인스턴스): 일부 경우, IAM 역할을 갖는 Linux 인스턴스의 경우 인스턴스 메타데이터와 공개 키를 사용하여 인스턴스에 액세스할 수 있을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상호작용 문제를 방지하기 위해 예방적인 키 관리의 중요성과 백업 유지의 중요성을 강조하는 것이 중요합니다.\n\n# 17. 게이트웨이란 무엇인가요?\n\n게이트웨이는 서로 다른 네트워크 간의 입구점 또는 인터페이스로 작용하는 네트워킹 장치나 서비스입니다. 통신과 데이터 전송을 가능하게 하며 브리지나 커넥터로 작동하여 서로 다른 프로토콜이나 아키텍처를 가진 다른 네트워크를 연결합니다.\n\n게이트웨이는 라우팅, 프로토콜 변환, 보안 강화 및 네트워크 트래픽 관리와 같은 다양한 기능을 수행할 수 있습니다. 이러한 기능은 네트워크 간 연결성과 상호 운용성을 가능하게 하며 데이터가 원활하게 흐를 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n게이트웨이는 일반적으로 인터넷 환경에서 사용되며, 로컬 네트워크와 넓은 인터넷 간의 통신을 원활하게 돕는 도구로, 외부 자원 및 서비스에 접속할 수 있도록 합니다.\n\n## 18. Amazon RDS, DynamoDB 및 Redshift의 차이점은 무엇인가요?\n\nAmazon RDS (관계형 데이터베이스 서비스)는 MySQL, PostgreSQL, Oracle 및 SQL Server와 같은 관계형 데이터베이스를 실행하고 확장할 수 있도록 하는 관리형 서비스입니다. 자동화된 백업, 복제 및 패치 관리를 제공합니다.\n\nDynamoDB는 빠르고 원활한 확장 가능성을 제공하는 완전히 관리되는 NoSQL 데이터베이스 서비스로, 저 지연 시간 데이터 액세스를 요구하는 애플리케이션에 이상적입니다. 유연한 스키마 디자인과 수요에 따른 자동 스케일링을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRedshift은 온라인 분석 처리(OLAP)를 위한 최적화된 완전히 관리되는 데이터 웨어하우징 서비스입니다. 대용량 데이터 세트의 고성능 쿼리 및 분석이 가능합니다. Redshift는 데이터 웨어하우징 및 분석 워크로드를 위해 설계되었으며 구조화된 데이터에 대한 SQL 기반 쿼리를 지원합니다.\n\n# 19. 웹 사이트를 S3에 호스팅하는 것을 선호하십니까? 그렇다면 이유가 무엇입니까?\n\n네, S3에 호스팅:\n\n- 비용 효율적: S3에 웹 사이트를 호스팅하는 것은 트래픽이 낮은 정적 웹 사이트의 경우 특히 비용 효율적입니다. 사용한 스토리지 및 데이터 전송에 대해서만 지불하면 됩니다.\n- 확장성: S3는 대량 트래픽을 처리하고 자동으로 확장될 수 있습니다. 소규모에서 중간 규모의 웹 사이트에 적합합니다.\n- 간편한 설정: S3에 정적 웹 사이트를 설정하는 것은 간단하며 AWS는 이 프로세스를 단순화하기 위한 도구를 제공합니다.\n- 보안: S3는 접근 권한에 대한 세밀한 제어를 허용하며 다른 AWS 서비스와 통합하여 추가 보안을 제공할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아니요, S3에 호스팅하지 마세요:\n\n- 동적 콘텐츠: 서버에서 생성된 동적 콘텐츠에 의존하는 웹 사이트의 경우, S3만으로는 적합하지 않습니다. 동적 요청을 처리하기 위해 웹 서버나 서버리스 아키텍처가 필요합니다.\n- 데이터베이스: 사용자 인증, 전자 상거래 기능 또는 콘텐츠 관리를 위해 데이터베이스가 필요한 경우, S3가 최적의 선택이 아닙니다. 더 포괄적인 호스팅 솔루션이 필요합니다.\n- 복잡성: 다양한 기능, 상호 작용 및 데이터베이스를 갖춘 복잡한 웹 사이트의 경우, S3만 사용하면 관리가 복잡해질 수 있으며 다른 호스팅 솔루션이 더 적합할 수 있습니다.\n\n# 20. AWS Lambda란 무엇이며 어떻게 작동합니까?\n\nAWS Lambda는 서버를 프로비저닝하거나 관리하지 않고 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이는 이벤트 기반 모델을 따릅니다. 여러분의 코드는 AWS 서비스 또는 사용자 지정 트리거로부터 발생하는 이벤트에 응답하여 실행됩니다.\n\nLambda 함수는 여러 프로그래밍 언어로 작성될 수 있으며 특정 이벤트를 처리하거나 특정 작업을 수행하기 위해 설계될 수 있습니다.\n\nLambda 함수는 자동으로 확장되며 병렬로 실행될 수 있어 가용성이 높고 효율적인 리소스 활용을 보장합니다. Lambda를 사용하면 코드에서 소비하는 컴퓨팅 시간만 지불하면 됩니다.\n\n# 21. VPC(Virtual Private Cloud) 및 그 구성 요소를 설명해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nVPC은 AWS 계정에 할당된 가상 네트워크로, AWS 클라우드의 논리적으로 격리된 영역을 제공합니다. 이를 통해 IP 주소 할당, 서브넷, 라우팅 테이블, 보안 그룹 및 네트워크 게이트웨이를 포함한 가상 네트워크 환경을 정의할 수 있습니다. VPC의 주요 구성 요소는 다음과 같습니다:\n\n- 서브넷: 자원을 프로비져닝할 수 있는 VPC 내의 IP 주소 세그먼트입니다.\n- 라우팅 테이블: 서브넷과 인터넷 간의 네트워크 트래픽 라우팅 규칙을 정의합니다.\n- 인터넷 게이트웨이: VPC 내의 인스턴스와 인터넷 간의 통신을 가능하게 합니다.\n- NAT 게이트웨이: 프라이빗 서브넷 내의 인스턴스가 안전하게 인터넷에 액세스할 수 있도록 합니다.\n- 보안 그룹: 인스턴스로의 들어오고 나가는 트래픽을 제어하는 가상 방화벽으로 작동합니다.\n- 네트워크 액세스 제어 목록(NACLs): 서브넷 수준에서의 네트워크 보안을 추가로 제어합니다.\n\n# 22. AWS DevOps 도구를 설명하여 클라우드에서 소프트웨어를 빌드하고 배포하는 방법을 설명하세요.\n\n클라우드에서 소프트웨어를 빌드하고 배포하기 위한 AWS DevOps 도구는 다음과 같습니다: -\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- AWS 클라우드 개발 키트: 인기 있는 프로그래밍 언어로 클라우드 애플리케이션 리소스를 모델링하고 프로비저닝하는 오픈 소스 소프트웨어 개발 프레임워크입니다.\n- AWS CodeBuild: 지속적으로 확장 가능한 다수의 빌드를 처리하고 코드를 테스트하는 지속적 인테그레이션 서비스입니다.\n- AWS CodeDeploy: Amazon EC2, AWS Fargate, AWS Lambda 등 선택할 수 있는 온프레미스 서버 중 하나로 소프트웨어 배포를 자동화하는 데 도움을 줍니다.\n- AWS CodePipeline: 지속적인 전달로 수신된 코드를 자동화하여 신속하고 정확한 업데이트를 수행합니다.\n- AWS CodeStar: AWS에서 애플리케이션을 개발, 빌드 및 배포하는 데 도움을 주는 사용자 인터페이스입니다.\n- AWS Device Farm: 다양한 모바일 장치 및 브라우저에서 애플리케이션을 테스트하는 플랫폼으로 작동합니다.\n\n# 23. 아마존의 이주 서비스에서 무엇이 제공됩니까?\n\n아마존은 다양한 이주 서비스를 제공합니다. 그것들은 다음과 같습니다: -\n\n- Amazon 데이터베이스 마이그레이션 서비스 (DMS)는 온프레미스 데이터베이스에서 아마존 웹 서비스 클라우드로 데이터를 매우 빠르게 마이그레이션하는 도구입니다. DMS는 온프레미스 및 클라우드에서 Oracle, SQL Server, MySQL 및 PostgreSQL 같은 RDBMS 시스템을 지원합니다.\n- Amazon 서버 마이그레이션 서비스 (SMS)는 온프레미스 워크로드를 아마존 웹 서비스 클라우드로 마이그레이션하는 데 도움을 줍니다. SMS는 클라이언트 서버 VMWare를 클라우드 기반 아마존 머신 이미지 (AMIs)로 마이그레이션합니다.\n- Amazon Snowball은 저 연결 환경에서 데이터 수집, 기계 학습, 처리 및 저장을 위한 데이터 전송 솔루션입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 24. Amazon에서 제공하는 메시징 서비스는 무엇인가요?\n\nAmazon은 여러 가지 메시징 서비스를 제공합니다. 그것들은 다음과 같습니다:\n\n- Amazon Simple Notification Service (SNS)은 AWS에 의해 완전히 관리되고 보안되며 사용 가능한 메시징 서비스로, 서버리스 애플리케이션, 마이크로서비스 및 분산 시스템을 디커플링하는 데 도움을 줍니다. SNS는 AWS 관리 콘솔이나 명령줄 인터페이스, 또는 소프트웨어 개발 키트에서 몇 분 내에 시작할 수 있습니다.\n- Amazon Simple Queue Service (SQS)는 서버리스 애플리케이션, 마이크로서비스 및 분산 시스템용으로 완전히 관리되는 메시지 대기열입니다. SQS FIFO의 장점은 이러한 종류의 메시징 서비스로 보내는 처리 시 단일 처리 및 정확한 순서를 보장합니다.\n- Amazon Simple Email Service (SES)는 클라우드 고객을 위해 SMTP 인터페이스를 통해 비공식적인, 통지 및 마케팅 대화를 위한 이메일 발송 및 수신 서비스를 제공합니다.\n\n# 25. 서브넷을 만드는 목적은 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n서브넷은 대규모 네트워크를 작은 네트워크로 분할하는 데 사용됩니다. 이는 트래픽을 라우팅하여 혼잡을 줄이며 성능을 크게 향상시킬 수 있습니다.\n\n# Elastic Beanstalk이란?\n\nElastic Beanstalk은 AWS의 오케스트레이션 서비스로, EC2, S3, Simple Notification Service, CloudWatch, 오토스케일링 및 Elastic Load Balancer와 같은 다양한 AWS 응용 프로그램에서 사용됩니다.\n\nAWS Management Console, Git 저장소 또는 통합 개발 환경(IDE)을 사용하여 AWS에 애플리케이션을 배포하는 가장 빠르고 간단한 방법입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 27. 클라우드프론트에서 지오 제약이란 무엇인가요?\n\n지오 제약은 클라우드프론트 웹 유통을 통해 제공되는 콘텐츠에 특정 지리적 위치에 있는 사용자가 액세스하는 것을 방지하는 방법으로, 일반적으로 지오 차단으로도 알려져 있습니다.\n\n# 28. Amazon ElastiCache의 사용 목적은 무엇인가요?\n\nAmazon ElastiCache는 클라우드에서 인메모리 데이터 저장소 또는 캐시를 쉽게 배포, 운영 및 확장할 수 있게 해주는 웹 서비스입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 29. 인스턴스를 중지와 종료하는 것을 구별해보세요.\n\n인스턴스를 중지할 때, 인스턴스는 정상적인 종료를 수행한 후 중지된 상태로 전환됩니다.\n\n인스턴스를 종료할 때, 인스턴스는 정상적인 종료를 수행합니다. 그리고 연결된 Amazon EBS 볼륨은 deleteOnTermination 속성이 false로 설정되어 있지 않는 한 삭제됩니다.\n\n# 30. 인기 있는 데브옵스 도구는 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인기 있는 DevOps 도구는 다음과 같습니다:\n\n- Chef, Puppet, Ansible, 그리고 SaltStack — 배포 및 구성 관리 도구\n- Docker — 컨테이너화 도구\n- Git — 버전 관리 시스템 도구\n- Jenkins — 지속적 통합 도구\n- Nagios — 지속적 모니터링 도구\n- Selenium — 지속적 테스트 도구\n\n# 31. 아마존 클라우드 서치의 기능은 무엇인가요?\n\n아마존 클라우드 서치의 기능은:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 자동완성 제안\n- 부울 검색\n- 전체 텍스트 검색\n- Faceting 용어 부스팅\n- 강조\n- 접두어 검색\n- 범위 검색\n\n**32. AWS의 EBS에서 데이터에 어떻게 액세스하나요?**\n\nAWS의 EBS에서는 그래픽 인터페이스를 통해 데이터에 직접 액세스할 수 없습니다. 이 과정에는 EBS 볼륨을 EC2 인스턴스에 할당하는 과정이 포함됩니다.\n\n여기서, 볼륨이 인스턴스 중 하나와 연결되면(윈도우 또는 유닉스), 해당 볼륨에 데이터를 쓰거나 읽을 수 있습니다. 먼저, 데이터가 있는 볼륨에서 스크린샷을 찍고 이를 활용하여 고유한 볼륨을 작성할 수 있습니다. 여기서, 각 EBS 볼륨은 단일 인스턴스에만 연결될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 33. AWS autoscaling에서 라이프사이클 후크란 무엇인가요?\n\n라이프사이클 후크는 autoscaling 그룹에 추가할 수 있습니다. 이를 통해 autoscaling 그룹이 인스턴스를 종료하고 시작할 때 일시 중지하여 사용자 정의 작업을 수행할 수 있습니다. 모든 오토 스케일링 그룹에는 여러 개의 라이프사이클 후크가 포함되어 있습니다.\n\n## 34. 하이퍼바이저란 무엇인가요?\n\n하이퍼바이저는 가상 머신을 생성하고 실행하는 데 사용되는 소프트웨어입니다. 물리적 하드웨어 리소스를 각 사용자에게 가상적으로 분배하는 플랫폼으로 통합됩니다. 하이퍼바이저에는 Oracle Virtual Box, Oracle VM for x86, VMware Fusion, VMware Workstation 및 Solaris Zones가 포함됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 35. AWS CloudTrail의 역할을 설명해주세요.\n\nAWS CloudTrail는 API 호출의 행동을 모니터링하고 감사하기 위해 설계된 서비스입니다. AWS CloudTrail을 사용하면 사용자는 AWS 인프라를 다루는 작업과 관련된 계정 활동을 모니터링하고 보관할 수 있습니다.\n\n# 36. Amazon Route 53을 설명해주세요.\n\nAmazon Route 53은 확장 가능하고 고가용성을 갖춘 도메인 네임 시스템(DNS)으로 정의됩니다. 이는 개발자와 기업의 이익을 위해 설계되었으며, 인터넷 애플리케이션으로 최종 사용자를 연결하기 위해 이름을 번역하는 가장 신뢰할 수 있고 비용 효율적인 프로세스입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 37. S3 요금을 결정하는 매개변수는 무엇인가요?\n\n아래는 S3 요금을 결정하는 매개변수입니다:\n\n- 전송 가속\n- 요청 횟수\n- 저장 관리\n- 데이터 전송\n- 사용된 저장소\n\n# 38. 다양한 종류의 인스턴스를 말해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 다양한 인스턴스 유형입니다:\n\n- Memory-optimized\n- Accelerated computing\n- Computer-optimized\n- General-purpose\n- Storage optimize\n\n39. RDS에서의 데이터베이스 유형을 나열해보세요.\n\n다음은 RDS에서 지원하는 데이터베이스 유형입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- MYSQL 서버\n- PostgreSQL\n- SQL Server\n- Aurora\n- Oracle\n- MariaDB\n\n## 40. 클라우드워치란 무엇인가요?\n\nAmazon CloudWatch은 메트릭 저장소입니다. 이를 사용하여 애플리케이션, 인프라 및 서비스를 모니터링할 수 있습니다. 또한 알람, 로그 및 이벤트 데이터를 활용하여 자동화된 작업을 수행하고 해결 시간을 단축할 수 있습니다.\n\n## 41. AWS의 키페어란 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n키 쌍은 공개 키와 개인 키로 구성되며, 가상 머신에 대한 안전한 로그인 정보입니다. Amazon EC2는 공개 키를 저장하고, 당신은 개인 키를 가질 수 있습니다.\n\n---\n\n_의견은 언제나 환영합니다._\n\n~페이살 쿠잔\n","ogImage":{"url":"/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png"},"coverImage":"/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png","tag":["Tech"],"readingTime":27},{"title":"파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁","description":"","date":"2024-06-19 12:01","slug":"2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark","content":"\n## 높은 품질과 신뢰할 수 있는 결과를 얻기 위한 변환된 데이터 테스트\n\n이 문서는 Likitha Lokesh와의 협력으로 작성되었습니다.\n\n![이미지](/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png)\n\n## 배경\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 최근 데이터 소프트웨어 프로젝트에 품질 엔지니어로 참여했는데, 여기서는 변환된 데이터에 대한 많은 테스트가 필요했습니다. 이 프로젝트에서는 데이터를 한 Amazon S3 버킷에서 다른 버킷으로 변환하기 위해 AWS Glue를 사용했습니다. 데이터는 Python을 사용하여 PySpark를 통해 변환되었고, 따라서 이러한 변환을 테스트하기 위한 테스트 자동화 프레임워크는 동일한 기술 스택에 의존했지만 Pytest도 추가되어 일관성을 유지하려고 노력했습니다.\n\nPytest, PySpark 및 AWS로 시작하는 방법에 대해 자세히 알아보려면 제 동료 Likitha Lokesh가 작성한 멋진 블로그를 확인해보세요.\n\n## 소개\n\n상기 프로젝트에서 우리 팀은 데이터를 제3자 소프트웨어 도구에서 소화되도록 변환했습니다. 데이터를 성공적으로 가져오기 위해 각 대상 파일에는 요구 사항 목록이 있었습니다. 각 대상 파일은 요구 사항을 충족해야만 소프트웨어가 데이터를 수용하고 데이터가 분석용으로 액세스 가능하지 않을 것이라는 문제를 방지할 수 있었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n목록에 나열된 요구 사항은 소스 파일에서 대상 파일로 데이터를 변환하는 데 필요한 스크립트가 어떻게 보이는지를 팀이 판단하는 데 도움을 주었지만, 모든 대상 파일의 데이터가 모든 요구 사항을 충족할 것을 보장하지는 않았습니다.\n\n데이터의 불일치는 데이터를 분석하거나 다른 목적으로 사용할 때 결과가 왜곡되는 원인이 될 수 있습니다. 이 프로젝트에서는 금융 데이터를 사용했기 때문에 데이터에 대한 신뢰 수준이 절대적으로 중요했습니다.\n\n따라서 다음과 같은 질문이 제기됩니다:\n\n모든 데이터 소프트웨어 프로젝트 솔루션은 일반적으로 맞춤형이 아니지만, 이 프로젝트에서 습득한 몇 가지 기술은 다양한 데이터 관련 프로젝트에서 효율적인 엔지니어링과 사고 과정에 도움이 될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 경험에서 데이터 품질 테스트를 위한 네 가지 주요 요점 목록을 만들었습니다:\n\n- 잘못된 데이터를 기록할 조건부로 단언을 감싸기\n- 공통 데이터 테스트 결정하고 매개변수화하기\n- 알려진 데이터 문제에 대한 Pytest 경고 및 XFail 활용하기\n- 환경 변수를 -E 플래그로 관리하기\n\n이 문서에서 네 가지 요점에 대해 각각 설명하고, 각 요점이 목록에 포함된 이유를 강조하겠습니다.\n\n## 단언을 조건부로 감싸기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n전통 소프트웨어 프로젝트에서 자동화 테스트를 수행할 때, 버그에 대한 가시성은 디버깅 데이터보다 약간 더 명확합니다. 전통적인 소프트웨어 프로젝트나 애플리케이션에서는 앱을 열어 검사하거나 API를 검토할 수 있지만 데이터는 매우 많을 수 있습니다. PySpark에서 데이터 문제에 대한 가시성을 얻기 위한 돋보기는 데이터프레임입니다.\n\n제 프로젝트에서는 .csv 파일의 데이터를 테스트했습니다. 많은 테스트가 동일한 개요를 가지고 있었습니다:\n\n- .csv 파일을 읽어 데이터프레임 만들기\n- 데이터를 분석하기 위해 데이터프레임 메서드 사용(요구 사항에 따라)\n- 단언을 조건부로 래핑하기\n\n가령 파일의 한 열에는 ZIP 코드 데이터가 있고 요구 사항이 각 값이 정확히 5자여야 한다면, 해당 테스트는 다음과 같을 것입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport length\nimport logging\n\ndef test_zipcode_data_length(spark_source, csv_file_path: str):\n\n  ## .csv 파일을 읽고 DataFrame을 생성합니다.\n  dataframe = spark_source.read.csv(csv_file_path)\n\n  ## DF에서 filter 메소드를 사용하여 열 값 분석하고\n  ## (다른 DF를 만듭니다)\n  invalid_rows = dataframe.filter(length(dataframe['Zipcode']) != 5)\n\n  ## 디버깅 및 정확한 위치를 찾기 위해 조건부로 Assertion을 감싸세요\n  if invalid_rows.count() == 0:\n    logging.info(\"예상대로 'Zipcode' 열의 모든 값이 5의 길이와 동일합니다!\")\n    assert True\n  else:\n    logging.error(\"'Zipcode' 열의 값은 모두 5의 길이와 동일해야 하지만\n    예상과 다른 값이 존재합니다!\")\n  ## 요구 조건을 충족시키지 못하는 행이 포함된 필터링된 DF를 출력합니다\n    invalid_rows.show(truncate=False)\n    assert False\n```\n\n참고: 기사 전체에 코드 조각이 많습니다. 테스트 메소드 간 코드 중복을 줄이기 위해 테스트 도우미 함수를 사용하는 것이 best practice이지만, 이 기사의 목적에서는 벗어납니다.\n\n위의 예제에서 볼 수 있듯이, 단순한 True/False 어서션이 아니라 실패 시 적절한 로깅을 위해 조건부로 어서션을 배치하여 데이터가 기대에 충족되지 않을 경우 디버깅 및 특정 데이터 위치를 찾기 위해 필요한 기능이 수행됩니다. 잘못된 행이 포함된 DataFrame은 파일을 소프트웨어가 처리하려면 수정해야 할 데이터 위치를 특정하게 알려줄 수 있습니다.\n\n특정 열마다 모든 값이 정확히 5의 길이여야 하는 경우를 보여준 예제였지만, 테스트의 일반적인 개요/흐름의 원칙은 동일합니다. Assertion을 조건부로 감싸지 않고 다른 옵션은 무엇인가요? 변환된 .csv 파일을 다운로드하고 수동으로 검토하거나 필터링하여 오류 행을 찾을까요? 그것은 매우 흥미로운 옵션이 아닙니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n무엇을 테스트하든간에, 실패의 근본 원인을 빠르게 평가해야 하는 필요성은 항상 품질 테스트 전략의 구성 요소가 될 것입니다. 단언문을 조건문으로 감싸는 것은 그 필요에 대한 해답을 제공합니다. 조건문으로 단언을 감싸는 자동화된 접근은 효율적이며 데이터 관련 문제를 신속하게 다루는 실패 빠른 접근법을 제공합니다. 이 방식은 많은 짐작을 제거하고 시스템/파이프라인의 품질을 유지하거나 개선하는 데 필요한 구체적인 정보를 제공합니다.\n\n## 일반 데이터 테스트를 매개변수화 하기\n\n데이터는 방대하기 때문에 혐이 일 수 있지만, 테스트할 때는 일반적으로 모호함이 적습니다. 요구 사항은 매우 명확하며, 제 경험상 전통적인 소프트웨어 프로젝트보다 수집하기 쉽습니다. 종종 일반적인 데이터 요구 사항은 서로 다른 데이터 세트 간에 겹칠 수 있습니다.\n\n제 프로젝트의 경우, 생성되어야 했던 대상 파일 중 많은 파일들이 서로 다른 파일에 대해 유사한 요구 사항을 가지고 있었으며, 심지어 동일한 파일 내의 다른 열도 동일한 요구 사항을 가졌습니다. 간단히 유지하기 위해 각 파일이 데이터를 포함해야 한다는 요구 사항이 하나 있었는데, 이는 명백한 요구 사항처럼 보일 수 있지만 모든 파일에서 실행할 수 있는 매우 쉽고 빠른 자동화된 테스트이며, 예상치 못한 가장자리 경우의 데이터 변환 시나리오에서 유용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 가장 좋은 방법은 모든 대상 파일마다 동일한 간단한 테스트를 작성하지 않아도 되는 방법이 무엇인가요? 어떻게 코드 재사용성을 최대화할 수 있을까요? 답은 Pytest의 Parametrize 표시를 사용하여 테스트를 매개변수화하는 것이었습니다.\n\n```python\nimport pytest\n\n@pytest.mark.parametrize(VALUES HERE)\ndef test_data_present(spark_source, csv_file_path: str):\n\n  ## .csv 파일을 읽고 DataFrame 생성\n  dataframe = spark_source.read.csv(csv_file_path)\n\n  ## DF가 비어 있지 않은지 확인\n  assert dataframe.first() is not None\n```\n\nPytest의 parametrize 표시를 통해 모든 대상 파일을이 동일한 테스트를 통해 실행하여 생성되는 각 파일에 최소한 어떤 종류의 데이터가 포함되어 있는지 확인할 수 있습니다. 이전 프로젝트에서 추가 쉼표 구분 기호의 데이터 내 포함 또는 고유 데이터 필요 열을 확인할 때 특히 중요한 몇 가지 경우가 있었습니다.\n\n이 경우에 유의해야 할 점은 테스트 시나리오를 정의하는 초기 단계에서 노력이 더 필요할 수 있다는 것입니다. 공통 요구 사항을 찾고 코드를 재사용하는 최상의 전략을 고민하는 것입니다. 그러나 장기적으로 테스트 개발이 지수적으로 가속화될 것입니다. 이 경험에서 배운 점은 요구 사항을 더 잘 이해하고 먼저 이러한 요구 사항의 공통점을 파악해야 한다는 것이었습니다. — 테스트를 개발하기 전에.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요구 사항에 따라 생성 될 다양한 유형의 테스트 계획을 작성합니다. 데이터 유형, uniqueness, formatting, 추가 구분 기호 없음/데이터 내에서 적절한 열 구분이 유효성을 검사하도록 테스트 계획을 분석하고 가능한 한 테스트를 통합하려고 노력합니다. 요구 사항에서 패턴을 파악하고 테스트를 개발하기 전에 더 강력한 계획을 수립하는 것은 개발 속도 및 테스트 실행 속도를 높이는 데 도움이 됩니다.\n\n## 경고 및 XFail 활용\n\n데이터와 상호 작용할 때, 특히 민감한 데이터(예: 금융 데이터)를 사용하는 새 소프트웨어를 개발할 때는 종종 실제 데이터와 상호 작용하기 전에 먼저 낮은 환경에서 (예: 개발/테스트 환경) 시험적으로 개발됩니다. 이 과정은 개발 중에 모든 결함이 해결되는 동안 실제 데이터(프로덕션)를 보호하는 데 도움이 됩니다. 그러나 비프로덕션 환경 데이터의 관리 오류로 인해 데이터 관리가 어려워지고 결과가 왜곡될 수 있습니다.\n\n비프로덕션 환경 데이터의 관리 오류는 해결하기 어렵고 결과를 왜곡시킬 수 있습니다. 다행히도 Pytest에 내장된 두 가지 기능인 Pytest Warnings와 Pytest XFail을 활용하면 알려진 데이터 문제를 테스트하는데 도움을 받을 수 있습니다. 이 두 옵션 중에서 선호도나 권장사항이 없습니다. 상황에 가장 적합한 도구를 선택하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 전문에 나온 제안 중 첫 번째 제안을 이미 구현 중이거나 구현할 예정이라면, 당신은 쉽게 Pytest 경고를 동일한 개념에 임베딩할 수 있습니다. 여기서의 차이점은 거짓 주장 대신 경고가 발생할 것이랍니다. 아래와 같이 보일 거에요:\n\n```js\nimport warnings\nimport logging\n\ndef test_email_data_unique(spark_source, csv_file_path: str):\n\n  ## Read the .csv file and Create a DF\n  dataframe = spark_source.read.csv(csv_file_path)\n\n  ## Use the count method on DF to capture the number of total rows\n  num_rows = dataframe.count()\n\n  ## Use the select method - paired with the distinct and count methods\n  ## on DF to analyze column values for uniqueness\n  num_unique_rows = dataframe.select(dataframe['Email'].distinct().count())\n\n  ## Wrap Assertion in a Conditional and Leverage WARNINGS\n  if num_rows == num_unique_rows:\n    logging.info(\"All of the values in the 'Email' column are unique\n    as expected!\")\n    assert True\n  else:\n  ## Print the rows that don't meet the requirements\n    dataframe.groupBy(dataframe['Email']).count().where(\"count \u003e 1\").drop(\n    \"count\").show(truncate=False)\n  ## Warn instead of fail\n    warnings.warn(UserWarning(\"Some of the data in the 'Email' column is\n    not meeting the uniqueness requirement!\")\n```\n\n품질 엔지니어로서, 빨간색은 주의가 필요한 것을 나타냅니다. 알려진 문제에 대해 경고를 사용하는 가장 좋은 점은 '뉴트럴'에서 출력되기 때문에 \"이것은 알려진 사항이며 즉시 주의가 필요하지 않거나 걱정할 필요가 없습니다\"라는 메시지를 전달해준다는 점이었습니다. 이 메시지는 테스트 스위트를 실행할 때 다른 기여자들에게도 전달되어, 노력을 더이상 메신저로 행동하지 않고 팀의 속도에 집중하는 데 도움이 됩니다.\n\n알려진 데이터 문제를 다룰 수 있는 또 다른 좋은 옵션은 Pytest XFail 표시입니다. Pytest Warnings 능력과 유사하게, 테스트가 실패하면 결과가 빨강색 대신 노란색으로 나올 것입니다. 특히 적용 가능한 경우, 빨간색이 아닌 다른 색상으로 인사를 받는 것이 얼마나 유용한지 이중으로 강조할 수 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 스크린샷을 보면 'XFail'이라는 테스트가 노란색 'x'로 실행되었음을 나타낼 것입니다. 그러나 'XFail' 표시는 테스트의 어설션 섹션에 표시되지 않습니다. 'XFail'은 이전 섹션에서 테스트를 표시하는 방법과 유사하게 함수 상단에 표시됩니다. 아래 'XFail' 구현 내용을 확인해보세요:\n\n```js\nimport pytest\n\n@pytest.mark.xfail(reason=\"알려진 데이터 문제로 임시로 실패하는 것으로 예상됨\")\ndef test_date_format():\n\n## 나머지 테스트 내용\n```\n\n앞서 살펴본 경고 옵션처럼 이 유용한 'XFail' 표시는 품질 엔지니어가 적절한 문서 작성을 하고 동료에게 컨텍스트 정보를 남길 수 있도록 도와줍니다. 'XFail'의 중요한 추가 혜택 중 하나는 'XFail'로 표시된 테스트가 예상대로 실패하는 경우 (즉, 버그 수정이 해결된 경우)에 테스트가 실패하므로 품질 엔지니어는 이제 테스트를 수정/변경해야 한다는 것을 알 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n주의해서 사용해주세요: 특정 프로젝트 요구 사항에 가장 적합한 경우/방법/이유를 고려해주세요. 예상치 못한 데이터의 불일치 사항을 확인한 후에만,\n\n- 실패의 근본 원인을 확인한 후에\n- 팀과 함께 실패의 우선 순위/심각성을 평가한 후에\n\nPytest의 이러한 기능을 활용해볼 수 있습니다.\n\n다른 한편으로, YELLOW 플래그로 특정 테스트를 지정할 수 있는 옵션을 가지고 있는 것은 필요한 자동화된 테스트가 문서화되어 테스트 스위트에 있고, 프로젝트가 제작으로 나아갈수록, 희망컨대 데이터 문제가 더 이상 발생하지 않는 환경에서 접근 가능하게끔 해줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 동적으로 환경 변수 관리하기\n\n네 키 포인트를 마무리하며, 다양한 환경 간 데이터 테스트의 세밀함에 대해 계속 다룰 것입니다. 이 기사의 시작 부분에서는 테스트 중인 데이터가 Amazon S3 버킷에 호스팅되어 있다고 언급했었습니다. 버킷 이름과 경로는 리포지토리의 INI 구성 파일에 나열되어 있었고, 다양한 테스트에 공급되었는데, 그러나 환경에 따라 약간 변경된 버킷 이름이 있었습니다.\n\n```js\n[BUCKET]\nS3 = my-dev-environment-bucket\n\n[PATH]\nFILE-PATH = pathway/to/dev/environment\n```\n\n버킷 이름과 해당 경로의 변종은 각 테스트 세션마다 터미널에서 동적으로 관리할 것이며, 이렇게 해서 Pytest의 -E 플래그가 유용하게 사용되었습니다. 픽스처와 pytest_addoption 함수를 사용하여 원하는 환경을 -E 플래그로 지정하고 표준 Pytest 명령에 따라 각 테스트 실행마다 환경을 전환시킬 수 있었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nINI 파일은 하드 코딩된 변수에서 약간 변형되었지만, 테스트에 전달되는 변수 이름에는 영향을 주지 않았기 때문에 이 조정은 테스트에 매우 낮은 영향을 미쳤습니다. 그런 다음 INI 파일 자체가 각 테스트 실행 중 임시 템플릿이 되었고, 테스트 실행 완료 후 복원되었습니다. 변형은 다음과 같았습니다:\n\n```js\n[BUCKET]\nS3 = my-{env}-environment-bucket\n\n[PATH]\nFILE-PATH = pathway/to/{env}/environment\n```\n\nINI 파일에 대한 이 조정과 테스트 세션 중 파일을 관리하는 몇 가지 방법과 함께, 필요한 환경에 따라 pytest -E=dev 또는 pytest -E=qc 또는 pytest -E=prod와 같은 명령이 되었습니다. 이 변경으로 인해 환경간 전환의 복잜한 점 때문에 버킷 이름이 변하는 것이 매우 간단해졌습니다. 이제 더 이상 특정 환경에서 테스트 실행을 수행하려면 INI 파일의 변수 이름을 변경하는 것을 매번 기억해야 했던 의존성이 없어졌습니다. 액세스 권한이 있는 모든 팀원이 이제 명령줄에서 쉽게 환경 간 전환을 할 수 있습니다.\n\nINI 파일에서 이 유연성을 어떻게 구현하는지에 대해 자세히 알아보려면, 여기에서 내 How-To 기사를 확인해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 마무리 생각\n\n빠르게 복습해보면, 이 글에서 강조한 데이터 품질 테스트의 네 가지 주요 포인트는 다음과 같습니다:\n\n- 로그에 잘못된 데이터를 기록하기 위해 어설션을 조건문으로 래핑\n- 일반적인 데이터 테스트를 결정하고 매개변수화\n- 알려진 데이터 걱정 사항에 대해 Pytest Warnings와 XFail 활용\n- -E 플래그로 환경 변수 관리\n\n이러한 전략들을 통해 변환된 데이터의 품질에 대한 신뢰 수준을 높이는 것이 전반적인 목표입니다. 이러한 포인트들이 유익했고 다음 데이터 프로젝트에서 유용한 팁과 전략을 얻을 수 있었으면 좋겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제안 사항에 대한 피드백을 알고 싶어요. 언제든지 댓글로 의견을 남겨주세요!\n\n#QE4DE\n\n## 자료\n\n- AWS Glue 정보\n- Amazon S3 정보\n- PySpark 문서\n- Pytest 문서\n- Likitha Lokesh의 PySpark, Pytest, Amazon S3 시작하기\n- PySpark 데이터프레임\n- Pytest 파라미터화\n- Pytest 경고\n- Pytest 실패 예상\n- Pytest -E 플래그\n- Taylor Wagner의 INI 파일 변수 조작 방법\n","ogImage":{"url":"/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png"},"coverImage":"/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png","tag":["Tech"],"readingTime":14}],"page":"37","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"37"},"buildId":"T_Nz0g9U1yttYMSEma95P","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>