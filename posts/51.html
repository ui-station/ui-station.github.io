<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/51" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/51" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_buildManifest.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="랜딩 존 디자인하기  디자인 고려 사항 파트 2  쿠버네티스와 GKE Google Cloud 채택 시리즈" href="/post/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="랜딩 존 디자인하기  디자인 고려 사항 파트 2  쿠버네티스와 GKE Google Cloud 채택 시리즈" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="랜딩 존 디자인하기  디자인 고려 사항 파트 2  쿠버네티스와 GKE Google Cloud 채택 시리즈" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">랜딩 존 디자인하기  디자인 고려 사항 파트 2  쿠버네티스와 GKE Google Cloud 채택 시리즈</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">22<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="EKS에 GitOps Argo CD 설정하기" href="/post/2024-05-27-GitOpsArgoCDSetupOnEKS"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="EKS에 GitOps Argo CD 설정하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-GitOpsArgoCDSetupOnEKS_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="EKS에 GitOps Argo CD 설정하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">EKS에 GitOps Argo CD 설정하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="우리가 도커 빌드 시간을 40 줄인 방법" href="/post/2024-05-27-Howwereducedourdockerbuildtimesby40"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="우리가 도커 빌드 시간을 40 줄인 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-Howwereducedourdockerbuildtimesby40_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="우리가 도커 빌드 시간을 40 줄인 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">우리가 도커 빌드 시간을 40 줄인 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Python 스크립트를 가벼운 도커 스케줄러로 조율하기" href="/post/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Python 스크립트를 가벼운 도커 스케줄러로 조율하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Python 스크립트를 가벼운 도커 스케줄러로 조율하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Python 스크립트를 가벼운 도커 스케줄러로 조율하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커 기본 요약 시트" href="/post/2024-05-27-DockerBasicCheatSheet"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커 기본 요약 시트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-DockerBasicCheatSheet_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커 기본 요약 시트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">도커 기본 요약 시트</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커 포트 정말로 노출되는 것은 무엇인가요" href="/post/2024-05-27-DockerPortsWhatAreYouReallyPublishing"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커 포트 정말로 노출되는 것은 무엇인가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-DockerPortsWhatAreYouReallyPublishing_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커 포트 정말로 노출되는 것은 무엇인가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">도커 포트 정말로 노출되는 것은 무엇인가요</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="MERN 스택 애플리케이션 도커화 단계별 가이드" href="/post/2024-05-27-DockerizingaMERNStackApplicationAStep-by-StepGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="MERN 스택 애플리케이션 도커화 단계별 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-DockerizingaMERNStackApplicationAStep-by-StepGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="MERN 스택 애플리케이션 도커화 단계별 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">MERN 스택 애플리케이션 도커화 단계별 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="하이브 메타스토어 HMS 스키마를 유니티 카탈로그로 이관하기" href="/post/2024-05-27-MigrateHivemetastoreHMSSchematoUnityCatalog"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="하이브 메타스토어 HMS 스키마를 유니티 카탈로그로 이관하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-MigrateHivemetastoreHMSSchematoUnityCatalog_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="하이브 메타스토어 HMS 스키마를 유니티 카탈로그로 이관하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">하이브 메타스토어 HMS 스키마를 유니티 카탈로그로 이관하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터브릭스 Q2 로드맵 W2W4" href="/post/2024-05-27-DatabricksQ2RoadmapW2W4"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터브릭스 Q2 로드맵 W2W4" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-DatabricksQ2RoadmapW2W4_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터브릭스 Q2 로드맵 W2W4" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터브릭스 Q2 로드맵 W2W4</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="현재 날짜나 시간을 기준으로 데이터브릭에서 여러 파일을 동적으로 로드하는 방법" href="/post/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="현재 날짜나 시간을 기준으로 데이터브릭에서 여러 파일을 동적으로 로드하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="현재 날짜나 시간을 기준으로 데이터브릭에서 여러 파일을 동적으로 로드하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">현재 날짜나 시간을 기준으로 데이터브릭에서 여러 파일을 동적으로 로드하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">16<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link posts_-active__YVJEi" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"랜딩 존 디자인하기  디자인 고려 사항 파트 2  쿠버네티스와 GKE Google Cloud 채택 시리즈","description":"","date":"2024-05-27 17:25","slug":"2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries","content":"\n마음에 드시는 markdown 형식의 표를 아래에 참조해보세요:\n\n| 구분                      | 설명                                                                         |\n| ------------------------- | ---------------------------------------------------------------------------- |\n| 착륙 지역이란?            | 착륙 지역의 정의 및 필요성에 대해 다룸                                       |\n| 디자인 프로세스 개요      | 착륙 지역 디자인 프로세스 개요 소개                                          |\n| 디자인 고려 사항 카테고리 | 착륙 지역 디자인 시 고려해야 할 7가지 카테고리 및 주요 디자인 결정 사항 소개 |\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 8. Google Kubernetes Engine (GKE)\n\n앞서 이 시리즈에서 말씀드렸듯이, 컨테이너는 훌륭해요! 가벼우며 빠르고 휴대성이 좋으며 쉽게 확장할 수 있어요. 이것들은 마이크로서비스 아키텍처에 잘 어울려요.\n\nGoogle Cloud는 컨테이너를 실행하는 몇 가지 다른 방법을 제공하고 있어요. 그러나 클라우드에서 현대적인 컨테이너 기반 작업을 실행한다면 Kubernetes가 필요하겠죠. 그리고 Google Cloud에서 Kubernetes를 실행한다면 Google Kubernetes Engine을 사용해야 해요.\n\nGKE은 Google의 관리형 Kubernetes 플랫폼이에요. 이를 통해 Google Cloud에서 Kubernetes를 실행할 수 있지만 자체 관리형 Kubernetes보다 여러가지 이점을 제공해요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- GKE는 클러스터를 배포하고 쿠버네티스를 설치하며 노드를 등록하는 것을 처리해줍니다. 새로운 클러스터는 몇 분 안에 배포할 수 있어요!\n- 쿠버네티스 제어 플레인 노드는 완전 관리되며 소비자로부터 완전히 추상화되어 있어요.\n- 호스트는 구글이 투명하게 관리하고 패치하는 견고하고 미리 구성된 컨테이너 용도 OS에서 실행돼요.\n- 구글은 릴리스 채널을 통해 쿠버네티스 업그레이드를 투명하게 관리해줘요.\n- 클러스터는 워크로드 수요를 충족하기 위해 탄탄하게 자동으로 탄력적으로 확장돼요. (관리되는 인스턴스 그룹 및 오토스케일러와 로드 밸런서를 만들 필요 없이!)\n- 비파괴적으로 자동 수리 및 불건전한 클러스터 노드의 교체를 자동으로 수행해줘요.\n- 기본 제공 지역 고가용성.\n- GKE는 Google Cloud Operations에 네이티브로 통합돼 있어서 모니터링, 로깅 및 메트릭스에 쉽게 액세스할 수 있어요.\n- GKE Autopilot으로 클러스터는 기본 제공된 모베스트 프랙티스로 사전구성돼요.\n- GKE Autopilot으로 실행 중인 워크로드에 비용을 지급하게 됩니다. (POD별 청구라고도 함) 클러스터를 배포하는 데 비용을 내야 하는 대신입니다. 이것은 게임 체인저에요!\n- GKE 노드 풀 및 Autopilot에서 계산 클래스로 작업 부하에 필요한 특정 기계 유형을 할당할 수 있어요. 또한 AI/ML 학습과 같이 필요로 하는 워크로드에 GPU를 할당할 수 있어요.\n- 완벽한 Google Anthos 서비스 메시와의 원활한 통합, 스스로 완전 관리 서비스로 제공할 수 있어요.\n\n(참고로, 여기에서 구글 컴퓨트 엔진에서 자체 관리 쿠버네티스 환경을 실행하려는 것이 왜 좋지 않은 아이디어인지 다양한 이유에 대해 다뤘었어요.)\n\n조금 고려해야 할 설계 결정과 최상의 모베스트 프랙티스가 있어요. 이 주제에 대한 시리즈를 진행할 수도 있겠지만 간략하게 여기서 고려 사항을 요약해드릴게요.\n\n## GKE Autopilot 또는 GKE 표준?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![AutoPilot](/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_0.png)\n\n안녕하세요! Autopilot은 기본 클러스터 배포 모드로 이미 장기간 사용되어 왔어요. 이 기능은 다음과 같은 몇 가지 모범 사례를 기본으로 제공합니다:\n\n- 릴리스 채널로의 의무적 등록. 이것은 클러스터가 자동으로 패치되고 유지되며, 오래된 보안 취약한 쿠버네티스 버전을 실행할 수 없다는 것을 의미합니다.\n- 클러스터는 regional로, 클러스터의 고가용성을 보장합니다.\n- 클러스터 자동 스케일링 - GKE가 기본으로 노드 수를 자동으로 조정해 줍니다.\n- 노드 자동 복구가 기본으로 활성화되어 있습니다.\n- 보안 부팅이 있는 shielded 인스턴스로 노드가 구축됩니다.\n- Workload identity가 사전 구성되어 있습니다. 이를 통해 쿠버네티스 서비스 계정이 구글 클라우드 IAM 서비스 계정처럼 작동할 수 있습니다. 따라서, GKE 서비스에서 구글 클라우드 API로의 세분화된 액세스 컨트롤을 제공할 수 있습니다.\n\n그리고 이전에 언급한 것처럼, 실제로 배포되고 실행 중인 파드에 대해 비용을 지불하므로, GKE 클러스터를 비효율적으로 사용하는 국면에서 지출을 낭비하는 일을 피할 수 있습니다. (GKE Standard를 실행할 때 흔히 발생하는 문제입니다.)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n대부분의 경우 Autopilot을 권장합니다. 일부 특정한 경우에는 Standard를 사용하고 싶을 수도 있습니다. 예를 들어:\n\n- TPU와 함께 노드를 배포하고 싶을 때.\n- 특정 버전의 Kubernetes를 실행하고 자동 업그레이드를 사용하지 않으려는 경우. (일반적으로 이는 좋지 않은 아이디어이며, 관리형 서비스를 사용하는 의도를 상쇄시키는 것과도 같습니다.)\n- 구글 Autopilot 허용 목록에 없는 특권있는 팟 (즉, 상승된 권한이 필요한 작업 부하)을 실행하고 싶을 때.\n- 실험적인 작업 부하를 단일 존 클러스터에 배포하고 가용성을 보장할 필요가 없는 경우.\n\n## Multitenant 대 Single Tenant 클러스터?\n\n이것은 이전보다는 덜 검정색과 흰색의 문제입니다. Autopilot 이전에는 답이 명확했습니다: 가능한 한 많은 Multitenant 클러스터를 사용하십시오. 아이디어는 매우 적은 클러스터를 가지고 각 클러스터가 조직 내 다중 테넌트로부터 작업 부하를 호스팅한다는 것입니다. 여기서 테넌트는 일반적으로 조직 내에서 다른 팀들을 의미합니다. 그리고 각 테넌트는 하나 이상의 네임스페이스를 소유하게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n멀티테넌트 GKE 클러스터를 사용하면:\n\n- 관리해야 할 클러스터가 하나뿐이기 때문에 클러스터 관리 부담이 비교적 적습니다.\n- 개별 테넌트/애플리케이션은 클러스터를 프로비저닝할 필요가 없습니다. 기존 클러스터에 작업량을 배포하기만 하면 됩니다.\n- 클러스터 자체의 관리 책임을 클라우드 플랫폼 팀에 위임할 수 있어, 애플리케이션 팀은 GKE 관리 책임을 신경 쓸 필요가 없습니다.\n- 테넌트 간의 격리는 네임스페이스 사용을 통해 달성합니다. 테넌트는 자신의 네임스페이스에 배포합니다.\n\n한편, 많은 수의 소규모 단일 테넌트 GKE(표준) 클러스터가 있는 경우 — 즉, 각 클러스터가 하나의 애플리케이션 서비스를 호스팅하는 경우 — 이는 비용이 많이 소요됩니다:\n\n- 각 애플리케이션이 자체 클러스터를 관리해야 합니다. 이로 인해 각 팀에 상당한 클러스터 관리 부담이 발생합니다.\n- 더불어 높은 가용성을 보장하기 위해 각 클러스터는 지역 전체에 최소 수의 노드를 배포해야 합니다. 단일 테넌트 애플리케이션의 경우, 이는 자주 응용프로그램의 요구 사항보다 훨씬 큰 최소 클러스터 크기에 이르게 됩니다. 결과적으로, 대규모로 과잉 프로비저닝되고 비효율적으로 사용되는 클러스터가 많이 생기게 됩니다. GKE 표준 제품을 사용하면 운영 중인 팟이 아닌 배포한 클러스터에 대한 비용을 지불하므로 많은 현금을 낭비하게 됩니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:440/0*sXXDeW5_LtHqMzi4.gif\" /\u003e\n\nAutopilot을 사용하면 단일 테넌트 클러스터가 많은 영향을 미치지 않습니다:\n\n- 실행 중인 팟만 지불하게 되므로 사용하지 않는 클러스터를 대거 배포하여 자금을 낭비하지 않습니다.\n- 박스에서 사전 구성된 많은 모베스트 프랙티스로 인해 테넌트 당 클러스터 관리 부담이 비교적 적습니다.\n\n마무리로 말씀드리면, 가능한 경우에는 멀티테넌트 GKE Autopilot 클러스터를 사용하는 것이 좋습니다. 특별한 경우에만 단일 테넌트 클러스터를 사용하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n조직에서 편안한 수준으로 배포된 몇 개의 다중 테넌트 클러스터를 설정할 수 있습니다. 예를 들어, 각 사업 라인에 맞춰 다중 테넌트 클러스터를 설정할 수 있습니다.\n\n이전 부분에서 논의한 대로 공유 VPC 디자인을 중심으로 랜딩 존을 구축했다면, 일반적으로 다중 테넌트 GKE 클러스터를 공유 VPC 내에 배포하고 싶을 것입니다. 이는 다음과 같을 수 있습니다:\n\n- \"허브\" VPC에 피어링된 다중 테넌트 GKE가 호스팅되는 공유 VPC\n- 다른 공유 서비스가 호스팅되는 같은 공유 VPC\n\n어쨌든, 플랫폼 팀이 공유 VPC가 있는 호스트 프로젝트와 다중 테넌트 GKE 클러스터가 있는 호스트 프로젝트를 소유하게 될 것입니다. 테넌트는 서비스 프로젝트를 소유하게 됩니다. 그들은 다중 테넌트 클러스터(네임스페이스 내)에 직접 워크로드를 배포할 수 있으며, 비-GKE 리소스를 서비스 프로젝트로 배포할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGoogle Cloud 문서는 이 방법을 다음과 같이 설명합니다:\n\n![Google Cloud](/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_1.png)\n\n## VPC-Native 또는 라우트 기반 클러스터?\n\n라우트 기반 클러스터는 pod 간 트래픽에 대한 VPC 사용자 정의 라우트에 의존하는 클러스터입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nVPC-native 클러스터는 포드 주소 지정을 위해 별칭 IP 주소 범위를 사용하는 클러스터입니다. 이는 포드가 클러스터의 VPC 네트워크 및 연결된 VPC 네트워크 내에서 네이티브로 라우팅될 수 있음을 의미합니다. 포드 주소를 위해 사용자 정의 정적 경로의 구성이 필요하지 않습니다. 네트워크 관리 부담은 비교적 낮습니다.\n\nVPC-native 클러스터는 RFC 1918 IP 범위 밖의 IP 주소를 사용할 수도 있습니다. 이는 많은 포드 IP 주소가 필요할 것으로 예상될 때 유용할 수 있습니다. 예를 들어, GKE는 240.0.0.0/4 CIDR 범위를 노드, 포드 및 서비스에 사용할 수 있어 추가로 2억 6800만 개의 IP 주소를 제공합니다!\n\nGoogle은 VPC-native 클러스터를 권장합니다. 이것은 GKE Autopilot의 기본 설정이며, 2021년에 출시된 버전 1.21.0-gke.1500부터 GKE 표준의 기본 설정이었습니다.\n\n요약하자면: VPC-native 클러스터를 사용하세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 개인 클러스터?\n\n기본적으로 GKE 클러스터는 공개적입니다. 이는 제어 평면과 워커 노드가 공개 IP 주소를 가지고 있음을 의미합니다. 그러나 조직이 개인 클러스터를 생성하는 것이 모법 사례입니다. 이렇게 하면 클러스터를 인터넷에서 격리할 수 있습니다.\n\n개인 클러스터에서는:\n\n- 워커 및 제어 평면 노드는 비공개 IP 주소만 가지고 있으며 인터넷에 노출되지 않습니다. 예를 들어 NodePort 유형의 서비스는 노드가 인터넷 라우팅 가능한 공개 IP 주소를 가지고 있지 않기 때문에 인터넷에서 클라이언트에게 접근할 수 없습니다.\n- 노드는 Google API 및 서비스와 통신하기 위해 Private Google Access를 사용합니다.\n- 인터넷으로의 외부 액세스는 Cloud NAT 또는 Anthos Service Mesh 이그레스 게이트웨이와 같이 구현한 특정 제어를 통해서만 가능합니다.\n- 외부 클라이언트로부터의 들어오는 연결은 외부 서비스를 통해서만 허용됩니다. 일반적으로 다음을 사용합니다: 외부 Ingress를 가진 LoadBalancer 서비스 또는 Anthos Service Mesh 공개 인그레스 게이트웨이.\n- 워커 노드와 GKE 제어 평면 사이의 통신은 제어 평면의 비공개 엔드포인트를 통해 이루어지며, 제어 평면에 액세스해야 하는 추가 네트워크는 승인되어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_2.png\" /\u003e\n\n## 클러스터간 IP 주소 범위 공유\n\nVPC 네이티브 클러스터를 생성할 때, 노드, 파드 및 서비스에 대한 IP 주소를 할당해야 합니다.\n\n- 노드 IP 주소: 클러스터의 노드인 호스트 머신에 사용되는 주소입니다. 클러스터는 노드에 IP 주소를 할당하기 위해 서브넷의 기본 IPv4 범위를 사용합니다. 노드의 크기를 예상하는데 있어, 가장 큰 크기를 기준으로 서브넷의 크기를 설정해야 합니다.\n- 파드 IP 주소: 클러스터는 파드에 IP 주소를 할당할 때 보조 IPv4 주소 범위를 사용합니다. GKE에서 가장 큰 IP 주소 요구사항이며, 각 노드는 많은 수의 파드를 호스트할 수 있습니다. 기본적으로 GKE Autopilot은 노드 당 최대 파드 수를 32개로 설정하고, 각 노드 당 64개의 IP 주소를 허용하여 파드 교체를 허용합니다. Kubernetes는 각 노드에 보조 IP 주소 범위를 할당하여 각 파드에 고유한 IP 주소를 할당합니다. 기본적으로 GKE Autopilot은 /17 보조 서브넷 범위를 할당하므로 32766개의 사용 가능한 파드가 허용됩니다. (이는 약 1000개가 넘는 노드를 가진 클러스터와 동등합니다.)\n- 서비스(ClusterIP) IP 주소: 클러스터는 내부 서비스 주소를 위해 별도의 보조 IP 주소 범위를 사용합니다. 서비스 IP는 ClusterIP 서비스에 할당됩니다; 이는 클러스터 내에서만 접근 가능한 가상 IP 주소입니다. GKE Autopilot에서는 버전 1.27부터 디폴트로 Google 관리 네트워크에서 IP 주소를 할당하며 범위는 34.118.224.0/20입니다. 동일한 범위가 각 클러스터에 할당됩니다. 따라서 각 클러스터마다 4천 개 이상의 서비스 주소가 제공되며, 기관은 GKE 내의 서비스를 위해 IP 주소를 할당하거나 예약할 필요가 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_3.png\" /\u003e\n\n동일한 공유 VPC에서 몇 개의 클러스터를 실행해야 할 수도 있습니다. 예를 들어, 업무별로 클러스터를 정의하고 싶을 수도 있습니다. (이미 언급했듯이, 많은 작은 단독 사용자 클러스터를 갖는 것은 좋지 않은 아이디어입니다.) 이 경우, 같은 서브넷에 호스팅된 클러스터 간에 기본 및 보조 IP 주소 범위를 공유할 수 있습니다. 이것은 하는 것이 좋은 일입니다:\n\n- 클러스터당 서브넷을 할당할 필요가 없습니다.\n- 클러스터당 서브넷 크기를 고려할 필요가 없습니다.\n- 네트워크 관리 오버헤드를 줄일 수 있습니다.\n- IP 주소를 효율적으로 절약하고 IP 주소 고갈 위험을 줄입니다.\n\nVPC에서 클러스터 간에 범위를 공유하기로 결정한다면, 이 점을 주의해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 미리 명명된 서브넷을 정의하세요.\n- 100.64.0.0/10(약 4.2 백만 개의 파드 사용 가능) 및 240.0.0.0/4(약 2억 6천 8백만 개의 파드 사용 가능)와 같은 RFC 1918 프라이빗 CIDR 범위를 사용하는 것을 고려해보세요.\n\n## 릴리스 채널\n\n여기에서는 GKE 클러스터가 업그레이드되고 유지보수되며 패치되는 전략을 결정합니다.\n\n쿠버네티스 버전은 x.y.z 형식으로 표시되며, 여기서 x는 주요 버전, y는 부 버전, z는 패치 버전을 나타냅니다. 일반적으로 매년 세 번에서 네 번의 중요 (주요 또는 부) 쿠버네티스 릴리스가 있으며, 패치 릴리스는 일주일에 한 번씩 발생합니다. 주요 및 부 릴리스는 새로운 기능과 보안 패치를 모두 포함합니다. 특정 부 릴리스는 대략 1년간 지원됩니다. 따라서 언제든지 일반적으로 지원되는 부 릴리스가 약 세 개 있을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_4.png)\n\n내 추천 (그리고 구글의 추천)은 항상 클러스터를 릴리스 채널에 등록하는 것입니다. 릴리스 채널을 사용하면 구글이 클러스터 업그레이드를 관리해줍니다. 워커 노드는 롤링 서지 업그레이드 전략을 사용하여 자동으로 업그레이드되어 워크로드에 미치는 영향을 최소화합니다. 따라서 클러스터 관리자는 클러스터 업그레이드에 시간이나 노력을 들일 필요가 없습니다.\n\nGKE Standard를 사용하면 릴리스 채널을 사용하지 않을 수 있습니다. 이렇게 하려면 클러스터를 특정 버전의 Kubernetes로 유지하고 싶을 때 사용할 수 있습니다. 그러나 제 경험상, 릴리스 채널에 선택적으로 가입하지 않는 기관은 곧 자신들의 취약한 클러스터가 가득한 시스템을 운영하게 됩니다. 그러한 기관들은 큰 패치 문제를 안게 될 것입니다!\n\n![image](/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGKE Autopilot을 사용하면 릴리스 채널을 선택해 사용하지 않을 수 없습니다. (정말 좋은 점이에요!)\n\n(참고로: GKE 컨트롤 플레인 노드는 항상 Google에 의해 업그레이드되며, 이 프로세스를 거부할 방법이 없습니다. 이는 릴리스 채널 등록 여부와 상관없이 해당됩니다.)\n\n선택할 수 있는 세 가지 릴리스 채널이 있습니다:\n\n- 빠른(Rapid) — 오픈 소스 릴리스가 일반적으로 사용 가능한 후 몇 주 후에 Kubernetes 클러스터가 업그레이드됩니다. 이 채널은 가장 최신 기능을 제공하지만 가장 안정성이 낮습니다. 또한, 이 릴리스 채널의 클러스터는 GKE SLA에서 지원되지 않을 것입니다.\n- 보통(Regular) — Kubernetes가 릴리스 후 2~3개월 후에 Rapid에서 실행되고 있는 릴리스 버전으로 업그레이드됩니다. 새로운 기능과 안정성 사이의 균형을 제공합니다. 기본적으로 GKE Autopilot은 노드를 이 릴리스 채널에 등록합니다.\n- 안정(Stable) — Kubernetes가 Regular에서 실행되고 있는 릴리스 버전으로 업그레이드됩니다. 이 릴리스는 커뮤니티에서 약 5~6개월동안 사용 가능한 후 클러스터 노드에 적용됩니다. 이 채널은 가장 검증되었고 가장 안정적일 것이지만 최근 Kubernetes 기능을 제공하지 않을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n새로운 GKE 버전이 릴리스 채널에서 기본 버전이 되면 해당 클러스터는 일반적으로 10일 이내에 업그레이드됩니다.\n\n다음은 릴리스 채널 채용에 대한 일반적인 권장 사항입니다:\n\n- 생산 워크로드는 클러스터의 중요성 및 위험 수용 능력에 따라 Stable 또는 Regular에 등록해야 합니다. 중요한 워크로드는 Stable에 등록하는 것을 권장합니다.\n- 최종 비생산 환경(일반적으로 스테이징, Pre-Prod 또는 UAT 환경)은 생산 환경과 동일한 릴리스 채널에 등록되어야 합니다. 왜냐하면 새로 시도해보지 않은 Kubernetes 버전에서 워크로드가 생산 환경에 배치되는 것을 원치 않기 때문입니다.\n- 상위 비생산 환경(예: Dev 또는 QA)은 이웃한 상위 릴리스 채널에 배포되어야 합니다.\n- 새로운 기능을 실험하려는 개발 환경에서만 빠른 릴리스 채널을 사용해야 합니다. 새로운 기능은 안정적인 릴리스 채널에 몇 달 내에 나타날 것을 기억해주세요.\n\n예시:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_6.png)\n\n릴리스 채널의 한 가지 문제는 클러스터가 언제 업그레이드될지 보장할 수 없다는 것입니다. 최종 비 프로드 환경 및 프로드 환경을 동일한 릴리스 채널(구글에서 권장하는 최상의 방법)에 등록하면 비 프로드 환경이 프로드 환경보다 먼저 업그레이드되도록 보호막을 구현하고 싶을 것입니다. GKE fleets 및 scopes를 사용하면 쉽게 이를 수행할 수 있습니다.\n\n다음은 이러한 배포 순서의 예시입니다:\n\n![이미지](/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 예에서:\n\n- Staging 환경의 GKE 클러스터는 Staging 플리트에 속합니다.\n- Production에 있는 클러스터는 Production 플리트에 속합니다.\n- Staging 및 Production에 있는 모든 클러스터는 Stable 릴리스 채널에 등록되어 있습니다.\n- Production 플리트는 Staging 플리트가 7일간 실행된 후에만 업그레이드됩니다.\n\n## Workload Identity Federation\n\n워크로드 ID 페더레이션은 Kubernetes 서비스 계정이 IAM 서비스 계정으로 작동할 수 있게 합니다. 구성된 Kubernetes 서비스 계정을 사용하는 파드는 Google Cloud API에 액세스할 때 자동으로 IAM 서비스 계정으로 인증합니다. 이를 통해 GKE 애플리케이션 워크로드가 인증되고 허가되어 Google Cloud 서비스에 액세스할 수 있도록 보장할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n오토파일럿 클러스터는 GKE에서 기본적으로 워크로드 ID 연합을 지원합니다.\n\n## 오토스케일링 전략\n\n오토스케일링은 클러스터가 실행 중인 응용 프로그램의 수요를 충족하기 위해 조정할 수 있는 능력을 가리킵니다.\n\nGKE에는 네 가지 스케일링 차원이 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 워크로드는 수요에 따라 가로 방향으로 확장됩니다. Pod를 추가하거나 제거함으로써 관리됩니다. 이는 가로 방향 팟 오토스케일러(HPA)에 의해 관리되며, 수요에 따라 빠르게 확장됩니다. HPA는 CPU 사용률과 같은 표준 메트릭 또는 초당 요청과 같은 사용자 정의 메트릭에 응답합니다.\n- 인프라는 클러스터 노드를 추가하거나 제거함으로써 가로 방향으로 확장됩니다. 이는 예약된 팟을 수용하기 위해 클러스터 자동스케일러(CA)에 의해 예측적으로 관리됩니다. 예를 들어, 새로 생성된 팟을 예약할 노드가 없는 경우, 클러스터 자동스케일러가 새 노드를 만듭니다.\n- 워크로드는 팟 크기를 조절함으로써 세로 방향으로 확장됩니다. 이는 세로 방향 팟 오토스케일러(VPA)에 의해 관리됩니다. VPA는 시간이 경과함에 따라 팟의 CPU 및 메모리 사용률을 모니터링하고 이에 따라 팟 크기를 조정합니다. 이로써 보다 최적화되고 비용 효율적인 팟 크기를 얻을 수 있습니다.\n- 인프라는 가장 효율적인 팟의 바이너리 패킹을 달성하기 위해 최적화된 노드(VM) 사이즈로 노드 풀을 배포하거나 삭제함으로써 세로 방향으로 확장됩니다. 이를 \"노드 자동 프로비저닝\"이라고 하며, 다른 종류의 확장에 비해 상대적으로 느립니다.\n\n아래는 몇 가지 팁입니다:\n\n- GKE Autopilot을 사용할 때는 인프라 자동스케일링 (CA 및 NAP)이 Google에 의해 설정됩니다. 당신은 팟 오토스케일링 구성만 고려하면 됩니다.\n- HPA와 VPA를 동시에 사용하지 마세요. 같은 자원 메트릭으로 HPA와 VPA를 함께 설정하는 것을 피하세요. 예를 들어, CPU 사용률에 대한 HPA와 VPA를 동시에 설정하는 것을 피하세요.\n- 가로와 세로 방향 팟 오토스케일링을 관리하는 다차원 팟 오토스케일러(MPA)를 사용하면 워크로드 확장을 간단히 할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결론적으로:\n\n- GKE 표준 버전을 사용하면 인프라 스케일링과 워크로드(파드) 스케일링을 모두 관리해야 합니다.\n- GKE Autopilot을 사용하면 워크로드 스케일링에만 집중하면 되며, MPA를 사용하여 워크로드 자동 스케일링을 간편하게 할 수 있습니다.\n\n## 인프라 및 워크로드 배포\n\nGoogle은 클러스터 자체를 배포할 때 클라우드 인프라의 경우와 마찬가지로 인프라를 코드로 관리하는 것을 권장합니다(Terraform과 같은). 따라서 클러스터 및 네임스페이스를 배포할 때 IaC를 사용하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n귀하의 작업 로드를 배포하려면 — 배포, 서비스, 작업, StatefufSets, 인그레스, 정책 등 — 선언적 yaml 파일을 사용하여 네이티브 Kubernetes API 호출을 해야 합니다. Helm은 쿠버네티스에서 애플리케이션 배포를 관리하는 데 도움을 줄 수 있습니다.\n\n## GKE 디자인 결정 요약\n\n요약하자면: 고려해야 할 주요 Kubernetes 디자인 결정 사항과 각각에 대한 나의 권장 사항입니다.\n\n- GKE, 또는 스스로 관리하는 방식? 권장 사항: GKE.\n- GKE Autopilot 대 GKE Standard. 권장 사항: Autopilot.\n- 멀티 테넌트 클러스터? 어떤 수준의 클러스터? 권장 사항: 멀티 테넌트.\n- 싱글 테넌트 클러스터를 만들 수 있는 능력. 권장 사항: 예외적으로만.\n- VPC 네이티브 또는 라우트 기반 클러스터? 권장 사항: VPC 네이티브.\n- 프라이빗 클러스터? 권장 사항: 프라이빗 클러스터를 사용하세요.\n- 클러스터 간 IP 주소 범위 공유? 추천 사항: 공유 VPC 내에 몇 개 또는 많은 클러스터가 있다면 이를 수행해야 합니다.\n- 릴리스 채널? 항상 릴리스 채널에 등록하세요. 스테이징 및 프로드 클러스터를 동일한 릴리스 채널에 유지하세요. 클러스터가 올바른 순서로 업그레이드되도록 보장하기 위해 fleets 및 rollout sequences를 사용하세요.\n- Workload identity? 네 — 사용하세요.\n- 오토스케일링 전략? 워크로드 오토스케일링을 지원하기 위해 클러스터 오토스케일러를 사용하세요. GKE Autopilot을 사용할 때 클러스터 오토스케일링은 자동으로 관리됩니다. 워크로드 오토스케일링을 간소화하기 위해 MPA를 사용하세요.\n- 인프라 및 워크로드 배포? 클러스터 배포 및 관리에는 IaC(예: Terraform)를 사용하세요. 애플리케이션 워크로드를 배포하기 위해 선언적 Kubernetes 매니페스트를 사용하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마무리\n\nGKE를 랜딩 존에서 성공적으로 디자인하는 데 고려해야 할 주요 사항들은 여기까지입니다. 다음 파트에서는 LZ 디자인 고려 사항을 완료하고, 로깅 및 모니터링 전략, 요금 청구, 인프라스트럭처 코드 (IaC)와 같은 주제를 다룰 것입니다.\n\n# 떠나시기 전에\n\n- 관심이 있을 것으로 생각되는 분과 공유해주세요. 그들에게 도움이 될 수도 있고, 저에게 정말로 도움이 됩니다!\n- 박수를 부탁드립니다! 여러분은 한 번 이상 박수를 칠 수 있다는 걸 아시나요?\n- 자유롭게 댓글을 남겨주세요 💬.\n- 내 컨텐츠를 놓치지 않으려면 팔로우하고 구독해주세요. 내 프로필 페이지로 이동하여 이 아이콘들을 클릭해주세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_9.png)\n\n# 링크\n\n- Google Cloud의 랜딩 존: 필요성 및 생성 방법\n- Google Cloud의 랜딩 존 디자인\n- GKE Autopilot\n- GKE Autopilot 특권 업무 용 업무\n- GKE 클러스터 구성 옵션\n- 기업용 GKE 멀티 테넌시에 대한 모베스트 프랙티스\n- VPC 네이티브 GKE 클러스터\n- GKE의 프라이빗 클러스터\n- 외부 애플리케이션 로드 밸런서를 위한 GKE Ingress\n- GKE로 이주할 때 IP 주소 계획\n- GKE 네트워크 플래닝 2023 (William Denniss)\n- GKE 릴리스 채널\n- 롤아웃 순서로 GKE 클러스터 업그레이드\n- GKE SLA\n- GKE 자동 확장 (Kaslin Fields)\n- GKE에서 비용 최적화된 애플리케이션에 대한 모베스트 프랙티스\n- GKE를 위한 워크로드 ID 연합\n- Google Cloud 아키텍처 프레임워크\n- 기업용 기초 설계 청사진\n\n# 시리즈 내비게이션\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 시리즈 개요 및 구조\n- 이전: 랜딩 존 설계하기 — 디자인 고려사항 파트 1\n- 다음: 랜딩 존 설계하기 — 디자인 고려사항 파트 3 — 모니터링, 로깅, 빌링 및 라벨링\n","ogImage":{"url":"/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_0.png"},"coverImage":"/assets/img/2024-05-27-DesignyourLandingZoneDesignConsiderationsPart2KubernetesandGKEGoogleCloudAdoptionSeries_0.png","tag":["Tech"],"readingTime":22},{"title":"EKS에 GitOps Argo CD 설정하기","description":"","date":"2024-05-27 17:23","slug":"2024-05-27-GitOpsArgoCDSetupOnEKS","content":"\nArgo CD는 쿠버네티스를 위한 GitOps 지속적 전달 도구로, 응용 프로그램 상태를 Git 저장소와 자동 동기화하고 롤백, 헬스 체크, RBAC 통합, 다중 환경 지원 및 CI/CD 시스템과의 원활한 통합을 가능케 합니다. 우리의 구현에 사용할 Argo CD에 대한 몇 가지 포인트는 다음과 같습니다:\n\n- Git Ops 에이전트 — Argo CD는 Git 저장소에서 업데이트된 코드를 가져와 쿠버네티스 리소스로 직접 배포하는 역할을 합니다. 인프라 구성 및 애플리케이션 업데이트를 한 시스템에서 관리할 수 있습니다.\n- 자동 배포: Argo CD는 응용 프로그램을 지정된 목표 환경에 자동으로 배포합니다. 응용 프로그램 상태를 선언적으로 정의하고, Argo CD가 배포 프로세스를 처리합니다.\n- 다중 클러스터 관리: Argo CD를 사용하면 여러 쿠버네티스 클러스터에서 응용 프로그램을 관리하고 배포할 수 있습니다.\n- 템플릿 지원: Argo CD는 helm과 Kustomize를 사용하여 템플릿 및 구성 관리를 지원합니다.\n- 롤백: Git 저장소에 커밋된 모든 애플리케이션 구성을 어디서든지 롤백할 수 있습니다.\n\nArgo CD에는 많은 기능이 있습니다. 위에서 설명한 기능 중 일부를 우리의 CI/CD 파이프라인에 사용할 것입니다. Argo CD에 대한 자세한 내용은 Argo CD — Declarative GitOps CD for Kubernetes (argo-cd.readthedocs.io)에서 확인할 수 있습니다.\n\n# Argo CD 설치하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아르고 CD는 다음 두 가지 방법을 사용하여 EKS에 설치할 수 있습니다:\n\n## 쿠버네티스 매니페스트를 사용하는 방법:\n\n1. 아르고 CD Git 저장소를 복제하세요:\n\n```js\nC: /\u003egit clone https:/ / github.com / argoproj / argo - cd.git;\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n귀하의 기계에 git을 설치해야 하며, git CLI가 있어야 합니다.\n\nb. 매니페스트를 귀하의 Kubernetes 클러스터에 적용하세요:\n\n```js\nC:/argo-cd\u003e kubectl apply -n argocd -f manifests/install.yaml\n```\n\n## Helm 사용 (권장되는 최상의 방법)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\na. 아르고 CD 헬름 리포지토리 추가:\n\n```js\n  helm repo add argo https://argoproj.github.io/argo-helm\n```\n\nb. Helm 업데이트\n\n```js\nhelm repo update\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nc. 설치\n\nhelm install argocd argo/argo-cd -n argocd\n\n# Argo CD CLI:\n\nArgo CD는 여러 클러스터 추가, 사용자 추가, Argo CD CLI 명령 실행 등 여러 기능 위한 중요한 도구입니다. Argo CD Command Line Interface (CLI)를 설치하는 방법은 운영 체제에 따라 옵션이 조금 다를 수 있습니다. 다음은 CLI를 설치하는 방법입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLinux/macOS\n\n```bash\nbrew install argocd\n```\n\nWindows:\n\n관리자 권한으로 PowerShell을 열어주세요. 아래 명령어를 입력하여 choco를 설치해주세요. 자세한 단계는 https://medium.com/@vikash06.india/part-1-multi-environment-instance-deployment-helm-template-argo-cd-eks-initial-setup-5ce4519184fc에서 확인하실 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nC:/\u003e choco install argocd-cli\n```\n\n```js\nC:/\u003e argocd version\nargocd: v2.9.3+6eba5be\n  BuildDate: 2023-12-01T23:24:09Z\n  GitCommit: 6eba5be864b7e031871ed7698f5233336dfe75c7\n  GitTreeState: clean\n  GoVersion: go1.21.4\n  Compiler: gc\n  Platform: windows/amd64\n```\n\n# Argo CD UI에 액세스하기:\n\nArgo CD UI에는 다음과 같은 방법으로 액세스할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 포트 포워딩\n- 인그레스\n\n## 포트 포워딩:\n\n포트 포워딩은 주로 로컬 머신에서 Argo CD UI를 사용하고자 할 때 사용됩니다\n\n```js\nkubectl port-forward svc/argocd-server -n argocd 8080:443\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼, 브라우저에서 https://localhost:8080을 열어 Argo CD UI에 액세스할 수 있어요.\n\n## ALB Ingress:\n\nEKS에 설치하고 Argo CD를 로드 밸런서로 노출하려면 ALB Ingress가 최적의 옵션입니다(다른 로드 밸런서도 있습니다)\n\n```js\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: argocd-ingress\n  namespace: argocd\n  annotations:\n    alb.ingress.kubernetes.io/actions.ssl-redirect: '{\"Type\": \"redirect\", \"RedirectConfig\":{ \"Protocol\": \"HTTPS\", \"Port\": \"443\", \"StatusCode\": \"HTTP_301\"}'\n    alb.ingress.kubernetes.io/backend-protocol: HTTPS\n    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-east-1:\u003caccount-id\u003e:certificate/\u003ccertificate-id\u003e\n    alb.ingress.kubernetes.io/group.name:  prodalb\n    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    alb.ingress.kubernetes.io/load-balancer-name: shared-load-balacer-name\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/tags: Environment=dev,Team=Cool Product, name=ALB\n      Dev , UsedIN=EKS\n    alb.ingress.kubernetes.io/target-type: ip\n\n  finalizers:\n   - ingress.k8s.aws/resources\n\nspec:\n    ingressClassName: alb\n    rules:\n    - host: argocd.example.net\n      http:\n        paths:\n        - path: /\n          backend:\n            service:\n              name: argocd-server\n              port:\n                number: 443\n          pathType: Prefix\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 예제에서 `account-id`를 귀하의 AWS 계정 ID로, 인증서 ID를 AWS Certificate Manager에서 가져온 인증서 ID로 바꾸세요. 본질적으로 그것은 인증서 ARN입니다. 아직 인증서를 보유하고 있지 않다면 AWS Certificate Manager에서 인증서를 생성하세요. 매우 간단한 과정이며 발급 완료까지 약 5-10분이 소요됩니다. 이 링크를 참조하세요: [링크](https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html)\n\n또한, `alb.ingress.kubernetes.io/group.name`은 여러 네임스페이스에서 동일한 로드 밸런서를 사용하는 경우에 사용됩니다.\n\n```js\nC:\u003e kubectl apply -f argocd-ingress.yaml\n```\n\n위 명령을 실행하면 ALB Ingress 로드 밸런서가 생성됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nargocd.example.io는 브라우저에서 접속 가능합니다. (문제가 발생하면 서브 도메인의 Route 53 A 레코드를 확인해보세요.)\n\nargocd.example.io 또는 localhost:8080(포트 포워드)로 접속하면 아래 페이지가 나타납니다:\n\n![Argo CD 설치 페이지](/assets/img/2024-05-27-GitOpsArgoCDSetupOnEKS_0.png)\n\nArgo CD에 처음으로 로그인하기.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nArgo CD와 인그레스 설정을 설치한 후에는 Argo CD의 기본 비밀번호를 가져와야 합니다. 아래 명령어를 사용할 것입니다.\n\n```js\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n```\n\n위 명령은 Argo CD의 비밀번호를 가져옵니다. 기본적으로 k8s에 저장된 모든 비밀번호는 Secret으로 암호화되어 base64로 저장됩니다. 윈도우 사용자의 경우 때로는 위 명령이 작동하지 않을 수 있으니 PowerShell을 사용하거나 'kubectl -n argocd get secret argocd-initial-admin-secret -o' 명령어로 비밀번호를 가져온 후에 Base64로 복호화해주세요.\n\nargo cd.example.io 또는 localhost:8080(포트 포워드)로 접속할 때, 사용자를 admin으로 설정하고 위 단계에서 가져온 'password'로 로그인해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로그인 후에는 사용자 정보 화면에서 비밀번호를 업데이트할 수 있습니다.\n\n![User Info Screen](/assets/img/2024-05-27-GitOpsArgoCDSetupOnEKS_1.png)\n\n# 사용자 및 RBAC Argo CD 생성\n\nArgo CD 설치 시 기본적으로 관리자 사용자가 생성됩니다. 때로는 사용자를 생성하고 역할을 관리해야 할 때도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nArgo CD를 통해 설치된 인증 및 역할 관리용 Configmaps이 있습니다. 클러스터에서 역할 및 권한 부여를 관리하기 위해 아래 ConfigMap을 찾을 수 있습니다. 아래 명령을 실행하면 K8s의 모든 ConfigMaps이 표시됩니다.\n\n```js\nkubectl get configmaps -n argoccd\n```\n\n결과:\n\n\u003cimg src=\"/assets/img/2024-05-27-GitOpsArgoCDSetupOnEKS_2.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로 우리는 사용자를 만들기 위해 argocd-cm을 사용할 것이고 역할 관리를 위해 argocd-rbac-cm을 사용할 것입니다.\n\n## 사용자 생성:\n\n사용자 관점에서 Argo CD에는 다음과 같은 옵션이 있습니다:\n\n- OIDC 공급자 — 이미 사용 중인 OIDC 공급자(예: Okta, OneLogin, Auth0, Microsoft, Keycloak, Google (G Suite))가 있으면 이 옵션을 사용하세요. 여기서 사용자, 그룹 및 멤버십을 관리합니다.\n- 번들된 Dex OIDC 공급자 — 현재 공급자가 OIDC를 지원하지 않는 경우(예: SAML, LDAP) 또는 Dex의 커넥터 기능(예: GitHub 조직 및 팀을 OIDC 그룹 클레임에 매핑하는 기능)을 활용하려는 경우 이 옵션을 사용하세요.\n- 소규모 팀을 위한 사용자 생성:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```plaintext\nC:\\Users\\vikas\u003ekubectl edit configmap/argocd-cm -n argocd\n```\n\n아래와 같이 출력이되며, 사용자를 \"accounts\" 섹션에 추가하고 후행 앱앤더로 사용자를 추가하세요:\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-cm\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: argocd-cm\n    app.kubernetes.io/part-of: argocd\ndata:\n  # add an additional local user with apiKey and login capabilities\n  #   apiKey - allows generating API keys\n  #   login - allows to login using UI\n  accounts.demouser: apiKey, login\n  # disables user. User is enabled by default\n  accounts.demouser.enabled: \"false\"\n```\n\n\"accounts.demouser.enabled\"은 비밀번호를 활성화하거나 비활성화하는 데 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n새로 추가된 사용자의 비밀번호를 업데이트하려면 Argo CD CLI가 필요합니다. 이미 로컬에 Argo CD CLI를 설치해 두었으며 해당 명령을 실행하기 위해 EKS Argo CD에 연결해야 합니다. Windows 기기의 경우 Environment 변수 ARGOCD_SERVER를 설정해야 하며 URL은 http(ingress 또는 port forward)을 제외한 값을 사용해야 합니다. 다른 방법은 login 명령을 사용하여 Argo CD CLI에 로그인하는 것입니다.\n\n```js\nargocd login \u003cARGOCD_SERVER\u003e --username \u003cUSERNAME\u003e --password \u003cPASSWORD\u003e\n```\n\n새로 생성된 사용자를 확인합니다.\n\n```js\nargocd account list\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사용자 목록이 표시됩니다. 이제 사용자 암호를 업데이트해야 합니다:\n\n```js\n# 만일 당신이 어드민 사용자로서 사용자를 관리 중이라면, \u003ccurrent-user-password\u003e에는 현재 어드민 암호를 입력해주세요.\nargocd account update-password --account \u003cname\u003e --current-password \u003ccurrent-user-password\u003e --new-password \u003cnew-user-password\u003e\n```\n\n위에서 사용자 이름은 구성 맵에 정의되어 있는 demouser이고, current-password는 어드민 사용자의 암호입니다.\n\nhttps://argo-cd.readthedocs.io/en/stable/operator-manual/user-management/#:~:text=Once%20installed%20Argo%20CD%20has,users%20or%20configure%20SSO%20integration.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# RBAC:\n\n위에서 사용자를 만든 후에는 권한 역할을 할당해야 합니다. RBAC는 Argo CD의 일부로 이미 설치된 ConfigMap입니다. 역할 및 인증을 정의하는 데 사용됩니다. 클러스터에서 역할과 권한을 관리하는 ConfigMap을 아래에서 찾을 수 있습니다. 애플리케이션 배포를 변경하고 권한 및 액세스와 관련된 문제가 발생할 때는 항상 아래 ConfigMap을 참고해야 합니다.\n\n아래 명령어를 실행하면 모든 RBAC 세부 정보가 표시됩니다:\n\n```js\nC:\\Users\\vikas\u003ekubectl describe configmap/argocd-rbac-cm -n argocd\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-rbac-cm\n  namespace: argocd\ndata:\n  policy.default: role:readonly\n  policy.csv: |\n    p, role:org-admin, applications, *, */*, allow\n    p, role:org-admin, clusters, get, *, allow\n```\n\n아래 명령어로 구성 맵을 수정할 수 있어요\n\n```bash\nC:\\Users\\vikas\u003ekubectl edit configmap/argocd-rbac-cm -n argocd\n```\n\n이 링크에서 각 정책 파일의 각 속성에 대한 자세한 내용을 찾을 수 있어요 RBAC Configuration — Argo CD — Declarative GitOps CD for Kubernetes (argo-cd.readthedocs.io)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 결론:\n","ogImage":{"url":"/assets/img/2024-05-27-GitOpsArgoCDSetupOnEKS_0.png"},"coverImage":"/assets/img/2024-05-27-GitOpsArgoCDSetupOnEKS_0.png","tag":["Tech"],"readingTime":14},{"title":"우리가 도커 빌드 시간을 40 줄인 방법","description":"","date":"2024-05-27 17:22","slug":"2024-05-27-Howwereducedourdockerbuildtimesby40","content":"\n많은 기업들과 마찬가지로, 저희 회사도 제품에 사용되는 모든 구성 요소에 대한 도커 이미지를 빌드합니다. 시간이 지남에 따라 몇 가지 이미지가 점점 커지고, 또한 CI 빌드 시간이 점점 오래 걸리게 되었습니다. 제 목표는 CI 빌드가 5분을 넘지 않도록 하는 것입니다. 이 아이디어는 커피를 마시기에 이상적인 시간이기 때문에 나왔습니다. 그 시간을 넘어가면, 개발자의 생산성이 떨어지게 됩니다.\n\n생산성이 감소하는 이유는 다음과 같습니다:\n\n- 개발자들은 빌드가 완료되기를 기다려야 하며, 따라서 시간을 낭비합니다.\n- 개발자들은 새로운 작업을 시작하고 나중에 되돌아옵니다. 이는 더 많은 문맥 전환을 요구하며 종종 비효율성으로 이어집니다.\n\n[이미지](/assets/img/2024-05-27-Howwereducedourdockerbuildtimesby40_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블로그 포스트에서는 적용한 2가지 작은 변경 사항을 설명하고, 빌드 시간이 drasctic하게 개선된 결과를 보여드리고 싶습니다. 이러한 개선 사항에 집중하기 전에 Dockerfile 작성에 대한 최상의 실천 방법을 이미 준수하고 있는지 확인하세요.\n\n- 레이어 수를 최소화합니다\n- 멀티 스테이지 빌드를 사용합니다\n- 최소한의 베이스 이미지를 사용합니다\n- …\n\n# Buildkit vs Buildx\n\n먼저 Buildkit과 Buildx에 대해 설명하겠습니다. 이 두 용어는 종종 서로 교차적으로 사용되지만 실제로 동일하지는 않습니다. 이 게시물을 작성하기 전에 나도 두 용어 사이의 차이를 완전히 이해하지 못했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 빌킷\n\n빌킷은 기존의 도커 빌더를 대체하는 개선된 백엔드입니다. 2018년부터 도커와 함께 제공되어 기본 빌더로 설정되었습니다.\n\n다음과 같은 많은 흥미로운 기능을 제공합니다:\n\n- 개선된 캐싱 기능\n- 서로 다른 레이어를 병렬로 빌드\n- 기본 이미지를 지연해서 로드합니다 (≥ 빌킷 0.9)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBuildkit을 사용할 때 docker build 명령의 출력이 더 깔끔하고 구조화된 모습이 빠르게 눈에 띕니다.\n\n23.0 버전보다 오래된 docker 버전을 사용할 때 Buildkit을 사용하는 일반적인 방법은 다음과 같이 Buildkit 인수를 설정하는 것입니다:\n\n```js\nDOCKER_BUILDKIT=1 docker build --platform linux/amd64 . -t someImage:someVersion\nDOCKER_BUILDKIT=1 docker push someImage:someVersion\n```\n\n## Buildx\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n빌드엑스(Buildx)는 도커의 플러그인으로, 도커에서 빌드킷(Buildkit)의 모든 잠재력을 활용할 수 있게 해줍니다. 이것은 빌드킷이 새로운 구성 옵션을 지원하는데, 이를 모두 도커 빌드 명령에 거슬러 호환되는 방식으로 통합하기 어려운 경우에 만들어졌습니다.\n\n이미지를 빌드하는 데 추가로, 빌드엑스는 여러 빌더를 관리하는 것을 지원합니다. CI에서 유용하게 쓰일 수 있으며, 공유 도커 데몬을 수정하지 않고 다른 설정으로 환경을 정의하는 데 도움이 됩니다.\n\n빌드엑스를 시작하는 방법은 다음과 같습니다:\n\n```js\ndocker buildx create --bootstrap --name builder\ndocker buildx use builder\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 원격 캐시의 혜택\n\n빌드를 가속화하는 첫 번째 방법은 이미지를 원격 레지스트리에 캐시하는 것입니다. 이렇게 하면 일반적으로 CI에서 수행되는 빌드와 같이 다른 기계에서 빌드하는 경우에도 빌드 캐시를 활용할 수 있습니다. 이를 해결하기 위해 많은 사람들이 새 이미지 버전을 빌드하기 전에 이미지의 최신 버전을 다운로드했습니다. 이점은 변경되지 않은 레이어를 캐시할 수 있다는 것인데, 처음에 전체 이미지를 다운받는 데 시간이 걸릴 수 있지만 레이어를 재사용할 수 있는 것은 보장할 수 없습니다. 예를 들어, 다음 명령어를 사용했습니다:\n\n```js\ndocker pull someImage:latest || true\ndocker build --platform linux/amd64 . \\\n-t someImage:someVersion \\\n--cache-from someImage:latest\n```\n\nBuildx를 사용하면 캐시 정보를 원격 위치(예: 컨테이너 레지스트리, Blob 스토리지 등)에 저장할 수 있습니다. 빌더는 주어진 레이어가 이미 존재하는지 확인하고, 그렇다면 다시 만들지 않고 재사용합니다. 이를 로컬로 다운로드하지 않고도 수행할 수 있습니다. 이 메커니즘을 활용하기 위해 이전 명령어를 재작성한 것은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ndocker buildx build --platform linux/amd64 . \\\n-t someImage:someVersion --push \\\n--cache-to type=inline,mode=max \\\n--cache-from someImage:somePreviousVersion\n\n\"max\" 모드는 결과 이미지에 사용되지 않는 레이어도 모든 빌드 정보를 저장한다는 것을 의미합니다 (예: 멀티 스테이지 빌드 사용 시). 기본적으로 \"min\" 모드가 사용되며 최종 이미지에 존재하는 레이어에 대한 빌드 정보만 저장합니다.\n\n캐싱의 특수 사례는 캐시 데이터를 \"inline\"으로 저장하는 것이며, 이미지와 함께 캐싱된다는 것을 의미합니다. 이 옵션은 Buildx 없이 Buildkit을 사용할 때도 지원됩니다. 멀티 스테이지 빌드를 사용할 때 시작하기 가장 쉽지만 출력물과 캐시 사이에 명확한 구분을 제공하지 않으며 조심해야 합니다. 캐시 데이터를 \"inline\"으로 저장하는 명령어는 다음과 같습니다:\n\ndocker buildx build --platform linux/amd64 . \\\n-t someImage:someVersion --push \\\n--cache-to type=inline,mode=max \\\n--cache-from someImage:somePreviousVersion\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Docker 이미지에 파일 추가하는 새로운 방법\n\n도커는 Dockerfile 작성을 위한 새로운 구문 버전, 즉 #syntax=docker/dockerfile:1.4를 소개했습니다. 이 버전은 COPY 및 ADD 명령에 대한 추가 링크 옵션을 지원합니다.\n\n이전에 COPY 또는 ADD 명령을 사용할 때 빌더가 새로운 스냅샷을 만들어 새 파일을 기존 파일 시스템과 병합했습니다. 이 작업을 수행하려면 부모 레이어가 모두 존재해야 하는데, 그렇지 않으면 대상 디렉토리가 아직 존재하지 않을 수 있습니다. 최종적으로 이미지(빌드 명령의 결과물)는 각각의 스냅샷 간의 차이를 포함하는 레이어 당 tarball로 구성됩니다.\n\n```js\nFROM baseImage:version\nCOPY binary /opt/\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n링크 옵션을 사용하면 새 파일은 이전 레이어에 의존하지 않고 자체 스냅샷에 넣습니다. 링크된 파일은 자체 tarball에 저장되며 서로 다른 tarball들이 연결되어 파일 시스템에 의존하지 않고 연결됩니다. 다음 이미지에 설명이 나와 있습니다.\n\n![이미지](/assets/img/2024-05-27-Howwereducedourdockerbuildtimesby40_1.png)\n\n```js\n# syntax=docker/dockerfile:1.4\nFROM baseImage:version\nCOPY [--chown=\u003cuser\u003e:\u003cgroup\u003e] [--chmod=\u003cperms\u003e] --link binary /opt/\n```\n\n주요 장점은 파일이 이제 이전 레이어에 의존하지 않는다는 것입니다. 파일이 변경되지 않았다면 이전 레이어가 변경되더라도 레이어를 재사용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한 여러 레이어의 데이터 복사가 이제 병렬로 실행될 수 있기 때문에 빌드 속도를 높일 수도 있습니다.\n\n# 결론\n\n이 블로그 포스트에서는 CI 파이프라인을 최적화한 후 얻은 몇 가지 새로운 통찰을 설명합니다. 전체 도커 빌드 시간을 40% 줄이게 된 두 가지 작은 변경 사항에 대해 논의하겠습니다.\n\n- 빌드 캐시 정보를 원격으로 저장\n- 도커 이미지에 파일을 추가하거나 복사할 때 링크 옵션 사용\n","ogImage":{"url":"/assets/img/2024-05-27-Howwereducedourdockerbuildtimesby40_0.png"},"coverImage":"/assets/img/2024-05-27-Howwereducedourdockerbuildtimesby40_0.png","tag":["Tech"],"readingTime":7},{"title":"Python 스크립트를 가벼운 도커 스케줄러로 조율하기","description":"","date":"2024-05-27 17:21","slug":"2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler","content":"\n\u003cimg src=\"/assets/img/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler_0.png\" /\u003e\n\n안녕하세요,\n\n요즘에 미니 PC를 사서 집에 작은 개인 서버를 세팅해봤어요 — 진짜 게이머 같은 스타일, ㅋㅋㅋ. 이 서버에서 몇 가지 개인 프로젝트를 돌릴 계획이었는데, 그래서 crontab만큼 단순하지 않은 가벼운 Python 스크립트 스케줄러가 필요했어요.\n\n조사를 하다가 Cronicle을 발견했고, Docker에서 실행할 수 있는 프로젝트도 찾았어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler_1.png)\n\n문제는... Cronicle은 기본적으로 셸 및 HTTP 요청 두 가지 유형의 작업만 지원합니다. 셸 스크립트에서 Python을 실행하는 것이 항상 최상의 경험은 아니며 (게다가 이미지에는 Python이 설치되어 있지도 않습니다. Cronicle은 Node.js에서 실행됩니다).\n\n그래서 저는 Python 환경이 설정되고 Cronicle 내부에 사용할 준비가 된 기존 이미지를 기반으로 나만의 도커 이미지를 만들기로 결정했습니다!\n\n```js\nFROM soulteary/cronicle:0.9.46\n\nENV PYTHONUNBUFFERED=1\n\nRUN apk add --no-cache python3 py3-pip\n\nCOPY bin/python-script-plugin.py /opt/cronicle/bin/python-script-plugin.py\nRUN chmod +x /opt/cronicle/bin/python-script-plugin.py\nCOPY config/plugins.pixl /tmp/plugins.pixl\nRUN /opt/cronicle/bin/control.sh import /tmp/plugins.pixl\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n내 플러그인에서는 스크립트뿐만 아니라 작업을 생성할 때 Python 라이브러리, 환경 변수, 실행 매개변수를 구성할 수 있어요. 각 Python \"이벤트\" (Cronicle이 작업/작업을 위한 용어로 사용하는 용어)는 자체 \"런타임\"에서 실행되며, 라이브러리나 환경 변수를 혼합하지 않아 모든 실행에서 무결성을 보장해요.\n\n![이미지](/assets/img/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler_2.png)\n\n개인 프로젝트(또는 소규모/중규모 전문 프로젝트)를 진행 중인 분들을 위해 Cronicle은 놀라운 오케스트레이터 대안이에요. 왜냐하면:\n\n- 작업 실행 일정 짜기 및 연결하기\n- 이메일 알림\n- 작업 실행 로그, 통계, 이력 등에 접근하기 가능해요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler_3.png)\n\nThe link to my repository with the image is [here](repository_link).\nFeel free to access my other repositories, I post a lot of snippets and personal projects that could help you!\n","ogImage":{"url":"/assets/img/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler_0.png"},"coverImage":"/assets/img/2024-05-27-OrchestratingPythonscriptswithalightweightdockerscheduler_0.png","tag":["Tech"],"readingTime":3},{"title":"도커 기본 요약 시트","description":"","date":"2024-05-27 17:20","slug":"2024-05-27-DockerBasicCheatSheet","content":"\n![Docker Basic Cheat Sheet](/assets/img/2024-05-27-DockerBasicCheatSheet_0.png)\n\n# Basic Commands:\n\n## Container Lifecycle:\n\n- docker run: Create and start a container.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ docker run -d --name my_container nginx\n```\n\ndocker start/stop/restart: 컨테이너를 시작, 중지 또는 재시작합니다.\n\n```js\n$ docker stop my_container\n$ docker start my_container\n$ docker restart my_container\n```\n\ndocker ps: 실행 중인 컨테이너 목록을 표시합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ docker ps\n```\n\ndocker ps -a 명령어를 사용하면 모든 컨테이너(중지된 것 포함)를 보여줍니다.\n\n```js\n$ docker ps -a\n```\n\n## 이미지 관리:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도커 풀: 레지스트리에서 이미지를 다운로드합니다.\n\n```js\n$ docker pull ubuntu\n```\n\n도커 빌드: Dockerfile에서 이미지를 빌드합니다.\n\n```js\n$ docker build -t my_image .\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도커 이미지: 모든 로컬 이미지를 목록으로 확인할 수 있어요.\n\n```js\n$ docker images\n```\n\n도커 rmi: 이미지를 삭제할 수 있어요.\n\n```js\n$ docker rmi my_image\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 컨테이너 작업:\n\n## 컨테이너와 상호 작용하기:\n\n도커 exec: 실행 중인 컨테이너에서 명령을 실행합니다.\n\n```js\n$ docker exec -it my_container bash\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도커 첨부: 실행 중인 컨테이너에 연결합니다.\n\n```js\n$ docker attach my_container\n```\n\n도커 로그: 컨테이너 로그를 확인합니다.\n\n```js\n$ docker logs my_container\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 컨테이너 자원 관리:\n\n도커 복사: 컨테이너와 호스트 간 파일 복사.\n\n```js\n$ docker cp file.txt my_container:/path/to/destination\n```\n\n도커 일시정지/재개: 실행 중인 컨테이너를 일시정지하거나 다시 시작합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n$ docker pause my_container\n$ docker unpause my_container\n\ndocker inspect: 디테일한 컨테이너 정보 표시\n\n$ docker inspect my_container\n\n# 네트워킹:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 네트워킹:\n\n도커 네트워크 목록: 사용 가능한 네트워크를 나열합니다.\n\n```js\n$ docker network ls\n```\n\n도커 네트워크 생성: 새 네트워크를 생성합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ docker network create my_network\n```\n\n도커 네트워크 연결/해제: 컨테이너를 네트워크에 연결하거나 연결을 해제합니다.\n\n```js\n$ docker network connect my_network my_container\n$ docker network disconnect my_network my_container\n```\n\n# 볼륨 관리:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 볼륨:\n\n도커 볼륨 목록: 볼륨 목록을 표시합니다.\n\n```js\n$ docker volume ls\n```\n\n도커 볼륨 생성: 볼륨을 생성합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ docker volume create my_volume\n```\n\n도커 볼륨 삭제: 볼륨 제거하기.\n\n```js\n$ docker volume rm my_volume\n```\n\n도커 볼륨 조회: 자세한 볼륨 정보 표시하기.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```sh\n$ docker volume inspect my_volume\n```\n\n# 친절한 영어로 🚀\n\nIn Plain English 커뮤니티에 참여해주셔서 감사합니다! 떠나시기 전에:\n\n- 작가를 박수로 응원하고 팔로우 해주세요 ️👏️️\n- 팔로우해주세요: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼도 방문해주세요: Stackademic | CoFeed | Venture | Cubed\n- PlainEnglish.io에서 더 많은 콘텐츠를 만나보세요\n","ogImage":{"url":"/assets/img/2024-05-27-DockerBasicCheatSheet_0.png"},"coverImage":"/assets/img/2024-05-27-DockerBasicCheatSheet_0.png","tag":["Tech"],"readingTime":6},{"title":"도커 포트 정말로 노출되는 것은 무엇인가요","description":"","date":"2024-05-27 17:18","slug":"2024-05-27-DockerPortsWhatAreYouReallyPublishing","content":"\n## 포트나 보안에 대해서만 하는 것이 아니라, 키보드 뒤에 있는 사람들이 중요해요.\n\n하나의 명령어로 전체 애플리케이션, 환경 및 의존성을 모두 구축하는 것은 꿈 같은 일이에요. Docker가 어떻게 작동하는지 안다면, 응용 프로그램을 안전하게 배포하는 놀라운 도구에요.\n\n하지만 처음 써보는 사람들에게는 방화벽 설정을 모두 우회하고 컨테이너를 공개 인터넷에 노출시키는 일이 무서울 수 있어요. 최근 Docker 네트워킹 문서를 읽다가 페이지에 큰 주황색 경고문을 보고, Docker를 처음 사용했을 때 놀랐던 일을 떠올렸어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사는 도커의 이 특정 문제에 초점을 맞추고 있지만, 제 제기 사항은 실제로 도커와는 별개입니다. 도커가 현재의 방식으로 작동하는 이유는 충분히 타당합니다. 문서화된 정보도 상당히 많이 있습니다. 네트워킹 페이지의 선명한 경고가 있고, 조금 더 깊이 읽어보면 도커와 방화벽이 상호작용하는 내용을 명시적으로 설명하는 단락을 찾을 수 있습니다.\n\n이 기사는 이 문제를 중심으로 한 응답과 주변의 개발자 태도에 대한 제 관찰에 관한 이야기입니다. 제 불평은 소프트웨어 개발 산업이 어떻게 도구를 사용하지만 작동 방식을 이해하지 않는 개발자를 만들기 위해 구성되어 있으며, 그렇게 하면 결국 자신의 발밑을 책임질 때 비판한다는 것입니다.\n\n응용 프로그램을 개발하고 배포하는 데 큰 진입 장벽이 없습니다. 건축물을 지으려면 통과해야 하는 문과 제한이 있습니다. 건축이 시작되기 전에 승인을 받아야 하며 안전, 환경 및 용도 관련 법규를 준수하기 위해 계획이 승인되어야 합니다. 전기, 배관 및 가스와 같은 중요한 시스템들은 특히 규정 준수를 위해 건물이 점검되기 전까지 사용될 수 없습니다. 반면에 소프트웨어를 작성하고 배포하는 것을 아무도 막지 않습니다. 이 자유는 우리의 직업의 장점이지만, 동시에 양날의 검이기도 합니다.\n\n전문적인 세계에서 안전한 응용 프로그램을 보장하기 위해 경험 많은 개발자들로부터의 코드 리뷰, 보안 감사, 침투 테스트 및 다른 점검들이 이상적으로 이루어져야 합니다. 그러나 놀이삼아 응용 프로그램을 작성한 개인 개발자들 중 모든 사람이 이러한 점검을 수행할 노하우를 가지고 있거나 수행해야 한다는 것을 알지 못할 수도 있습니다. 바로 이러한 개발자들을 이 기사에서 다루고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 문제\n\n이 문제를 처음 마주했던 상황을 알려드리겠습니다. 사이드 프로젝트를 위해 공개 데이터 세트로 내 데스크톱에서 작은 MySQL 데이터베이스를 실행했습니다. 데이터베이스는 3306 포트에서 작동 중이었지만 방화벽 설정으로 모든 수신 연결을 차단하였습니다. 데이터를 다운로드하고 원본 소스의 데이터를 업데이트하여 필요한 새로운 데이터를 작업할 수 있도록 로컬 데이터베이스를 갱신하는 작은 Python 스크립트를 실행할 수 있었습니다. 시간이 지남에 따라 MySQL의 설치된 버전에서 Docker 컨테이너로 전환하였습니다. Python 스크립트를 변경하지 않고 계속 동작하게 하기 위해 `docker run` 명령에 `-p 3306:3306` 인수를 추가하기만 했습니다.\n\n특히 Docker 네트워킹 문서에서 이전에 언급한 큰 주황색 경고를 읽었을 때 기억합니다:\n\n“와우, 분명히 중요하군요! 사람들이 읽도록 큰 주황색 경고로 표시되어 다행이에요. 방화벽 설정을 다시 확인해야겠네요.”\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어느 날, 전혀 관련 없는 네트워크 문제를 디버깅하고 있었어요 — 아마도 노트북을 사용해서 Samba 공유를 디버깅하려고 다른 방에 있었던 것 같아요. 데스크톱에서 어떤 포트가 열려 있는지 확인하기 위해 nmap을 실행했는데, 방화벽에 3306번 포트에 대한 연결을 거부하는 명시적인 규칙이 있음에도 불구하고 열려 있다는 것을 발견했을 때 정말 놀랐어요.\n\n다행히 제 경우에는 집 네트워크로만 제한되어 있었어요. 데이터베이스는 비밀번호로 보호되어 있었지만(비록 상대적으로 취약한 비밀번호였지만), 공개 정보만 포함되어 있었어요. 그럼에도 온라인의 전 세계에 데이터를 노출시키는 것에 대해 얼마나 많은 개발자들이 응용 프로그램의 데이터베이스를 포트를 공개적으로 공개하면서 알지 못하고 있는지 생각하니 무서웠어요.\n\n# 아마 저만 그런 것은 아니겠죠?\n\n분명히 나만 문제를 걱정하고 있는 것은 아닌 것 같아요. 이와 비슷한 버그 리포트가 있고, 다양한 플랫폼에 흩어진 토론과 기사들이 있으며, 이 문제를 해결하려는 프로젝트도 있어요. 버그 리포트의 토론들을 읽어보면, 이게 실제로 문제인지에 대한 끝없는 논쟁들을 찾을 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전에 언급한 대로, 나의 불평은 도커가 이렇게 작동하는 것이 아니라, 오히려 이러한 문제와 토론에 대답할 때 많은 사람들이 보이는 경멸적인 태도입니다. 아래 Reddit 댓글은 9년 전에 작성되었지만, 제 주장을 완벽히 보여 줍니다.\n\n그리고\n\n그러한 태도는 건설적이지 않습니다. 평균적인 스스로 가르친 취미 개발자가 응용 프로그램을 배포할 때 보안 모베스트 프랙티스에 능숙하다면 좋겠지만, 현실은 이를 강요할 장벽이나 관문이 없는 세계에서 살고 있다는 것입니다.\n\n# 학습에 대한 부가적인 노트\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n당신이 알지 못하는 것은 당신이 무엇을 모른다는 것입니다.\n\n우리는 피드백을 통해 가장 잘 배웁니다 — 코드를 작성하다가 뭔가 잘못되었다는 걸 바로 알 수 있기 때문에, 그 때 바로 수정하고 동작하는 걸 보는 것은 긍정적인 피드백을 주며, 그 문제를 해결하는 방법에 대한 접근 방식을 강화합니다. 이 즉각적인 피드백 루프는 프로젝트를 시작하고 발생하는 도전에 대처하며 코딩을 배우기 쉽게 만듭니다. 그러나 작성한 코드가 유지보수가 어렵거나 보안에 취약하면, 몇 달이든 몇 년이든 그런 피드백을 얻지 못할 수 있습니다. 그렇기 때문에 보안과 같은 개념은 시행착오를 통해 쉽게 스스로 학습할 수 없습니다.\n\n# 이 구체적인 도커 문제에 대한 해결책\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기 계신 것이면 컨테이너를 보호하는 방법을 찾고 계실 것 같아요. 그렇다면, 지금까지 함께 가지고 머물러 주셔서 감사드려요. 여기 몇 가지 방안이 있어요:\n\n- 최적의 해결책은 실제로 포트를 전혀 공개하지 않는 것이죠. 공개적으로 해당 포트를 노출하고자 할 때가 아니라면요. 컨테이너 간 통신을 위해, 최상의 방법은 해당 트래픽을 위해 특별히 설정된 Docker 네트워크를 구축하고, 컨테이너가 해당 네트워크에 연결되도록 하는 것입니다. 주요 제한 사항은 컨테이너 내부에서 실행 중인 프로세스에는 작동하지 않는다는 것이에요. 모든 어플리케이션이 컨테이너 친화적이지는 않고 때때로 호스트에서 컨테이너에 액세스해야 하는 프로세스를 실행해야 할 수도 있어요.\n- 흔한 제안일 수 있지만, 공식 문서에서 명확히 권장하지 않는 것 중 하나는 /etc/docker/daemon.json에서 iptables를 false로 설정하는 것이에요. 이렇게 하면 Docker가 네트워크 규칙을 추가하지 않기 때문에 컨테이너 내의 네트워킹이 전혀 작동하지 않를 거에요. 이 경로를 선택하려면 규칙을 수동으로 추가해야 해요. 이 작업은 쉬운 편이 아니며 — 제대로 알지 못한다면 — 보안 설정 오류나 반대로 서버에 액세스 권한을 상실할 수도 있어요.\n- 컨테이너 네트워킹을 망가뜨리지 않는 약간 더 나은 방법은 기본 주소 바인딩을 로컬 전용으로 설정하는 것이죠. 이것은 /etc/docker/daemon.json에서 ip를 127.0.0.1로 설정하여 수행할 수 있어요. 사실, 처음부터 이것이 기본 설정이 되었어야 한다고 주장할 수도 있어요. 컨테이너가 호스트 외부에서만 액세스 가능하도록 명시적으로 구성되어야 하는 경우에만 예외적으로 구성되어야 한다고 생각해요. 하지만 그것을 바꾸는 것은 지금과 같이 늦은 시각에선 너무 늦어버린 일이에요. 저는 사용했던 방법인데요, 그러나 이 방법에는 한 가지 단점이 있어요. 이것은 컨테이너의 이식성에 반하는 것이죠. 다른 호스트에서 컨테이너를 실행하려면 설정을 변경해야 하는 것을 기억해야 해요. 이상적으로, 동일한 방식으로 모든 호스트에서 컨테이너가 실행되기를 원할 거에요. 호스트에서 설정을 변경을 기억하지 않으면 안전하지 않아진 컨테이너가 생각만 하고 있기는 좋지 않아요.\n- 일반적인 문제에 대한 최선의 방법은 Docker 명령어와 docker-compose.yml에서 명시적 IP 주소 바인딩을 사용하는 것에 익숙해지는 것이어야 해요. 절대로 -p 3306:3306을 작성하지 않으시고, 대신 -p 127.0.0.1:3306:3306을 작성하는 데 익숙해져야 하며, 실제로 외부로 포트를 노출해야 하는 경우에 대해서 명확하게 설정해야 해요: -p 0.0.0.0:3306:3306. 저는 Docker 네트워크가 선택사항이 아닐 때 채택한 방법이에요.\n\n이제, 내가 대답을 모르는 질문은 다양한 튜토리얼이 데이터베이스를 전세계에 노출하도록 권장하는 문제를 어떻게 해결할지일 거예요.\n\n# 일반 문제에 대한 해결책\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n몇 년째 쓰고 싶었던 이 글은 조금 화제적인 내용이에요. 개발자들의 태도가 저의 속앓이거든요. \"내가 아는 것을 모르면 하는 건 안 된다\"는 게이트키퍼식 마인드는 너무나 흔합니다.\n\n하지만 이 이상한 직업에서 우리 중 많은 사람들이 돈을 벌기 위해 하지만 다른 많은 사람들은 그냥 즐기기 위해 하는 경우도 있어요. 그래서 취미로 하는 보안 노력만으로 어플리케이션을 VPS나 예비 랩탑에 올리는 것에서 많은 흠들이 생기는 게 좀 불안해지죠.\n\n큰 그림에서 해결책은 이렇습니다:\n\n- 뭔가를 만들고 싶어하는 미숙한 개발자를 위해: 계속하세요! 가능한 한 많이 읽으세요. 사용하는 도구의 공식 문서를 건너뛰지 마세요. 많이 흡수하세요. 아직 모르는 것이 있음을 인식하고 배우는 가장 좋은 방법은 계속 새로운 것을 시도하는 것이라는 것을 기억하세요.\n- 널리 사용되는 오픈 소스 도구에 기여하고 있는 숙련된 개발자들에게, 기본 동작에 대한 중요한 설계 결정을 내리는 경우: 문서를 읽지 않을 것으로 예상되는 사람들을 보호하는 의무가 여전히 있음을 기억하세요. 다른 사람들이 써놓은 빠르게 훑어보는 튜토리얼을 의존하는 사람들에게도 말이죠. 우리는 안전한 기본값을 선택할 의무가 있습니다 — Docker에는 이미 늦었을지 모르지만, 다음 도구에는 이 기회를 잡을 수도 있을 겁니다. 우리의 도구가 의도되지 않은 방식으로 사용될 때면 대뜻하지 않고 무례하지 말고, 가르치고 교육의 순간으로 삼아보세요. 아마는 더욱 배울 수도 있죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비슷한 경험이 있나요? 기본적으로 보안에 취약한 방식으로 사용된 다른 도구를 보신 적이 있나요?\n","ogImage":{"url":"/assets/img/2024-05-27-DockerPortsWhatAreYouReallyPublishing_0.png"},"coverImage":"/assets/img/2024-05-27-DockerPortsWhatAreYouReallyPublishing_0.png","tag":["Tech"],"readingTime":8},{"title":"MERN 스택 애플리케이션 도커화 단계별 가이드","description":"","date":"2024-05-27 17:17","slug":"2024-05-27-DockerizingaMERNStackApplicationAStep-by-StepGuide","content":"\nMERN 스택 애플리케이션을 구축하는 것은 도커화 및 여러 환경 관리와 관련해 도전적일 수 있습니다. 도커를 사용하면 애플리케이션을 컨테이너로 패키징하여 다양한 환경 간에 쉽게 이동할 수 있도록 도와줄 수 있습니다.\n\n이 블로그 포스트에서는 Docker와 Docker Compose를 사용하여 MERN 스택 애플리케이션을 컨테이너화하는 과정을 안내해 드리겠습니다. Docker와 Docker Compose는 함께 작동하여 컨테이너화된 애플리케이션의 개발, 배포 및 관리를 간편화하는 데 도움이 되는 두 가지 강력한 도구입니다.\n\nDocker는 애플리케이션과 그 종속성을 표준화된 단위인 컨테이너로 패키징할 수 있는 플랫폼입니다. 이러한 컨테이너는 가볍고 이식성이 있으며, Docker가 설치된 시스템의 기반이 되는 운영 체제에 관계없이 일관되게 실행될 수 있습니다.\n\nDocker Compose는 쉽게 다중 컨테이너 애플리케이션을 정의하고 실행하기 위한 도구입니다. YAML 파일(일반적으로 docker-compose.yml로 명명됨)을 사용하여 애플리케이션의 서비스(컨테이너)와 그들 간의 관계를 구성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시작하기 전에 시스템에 다음 항목이 설치되어 있는지 확인하세요:\n\n- Docker\n- Node.js\n\n그리고 도커와 관련된 기본적인 이해와 명령어가 있는 것으로 가정합니다.\n\n## 단계 1: MERN 애플리케이션 설정하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가정하에 기본적인 MERN 애플리케이션이 다음과 같이 구성되어 있다고 가정하고, 다음과 같은 Dockerfile 및 docker-compose 파일을 만들어야 합니다.\n\nmy-mern-app/\n├── backend/\n│ ├── Dockerfile\n│ ├── package.json\n│ ├── server.js\n├── frontend/\n│ ├── Dockerfile\n│ ├── package.json\n│ ├── public/\n│ ├── src/\n├── docker-compose.yml\n\n## 단계 2: 백엔드와 프론트엔드 도커 파일 설정\n\n백엔드 설정\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 지시사항을 백엔드 도커 파일에 포함해야 합니다.\n\n```js\n# backend/Dockerfile\n\n# 공식 Node.js Alpine 기반 이미지 사용\nFROM node:20.11.1-alpine\n\n# 작업 디렉토리 설정\nWORKDIR /app\n\n# package.json 및 package-lock.json 복사\nCOPY package*.json ./\n\n# 의존성 설치\nRUN npm install\n\n# 나머지 애플리케이션 코드 복사\nCOPY . .\n\n# 실행 중인 앱의 포트 노출\nEXPOSE 5000\n\n# 애플리케이션 실행\nCMD [\"npm\", \"start\"]\n```\n\n컨테이너의 기본 이미지로는 Alpine 리눅스 배포판을 기반으로 한 Node.js 런타임 버전 20.11.1을 사용하고 있습니다. Alpine 이미지는 일반적으로 더 작고 다운로드 속도가 빠릅니다. WORKDIR /app은 컨테이너 내부의 작업 디렉토리를 /app으로 설정합니다. 이후의 모든 명령은 이 디렉토리에서 실행됩니다. COPY package\\*.json ./는 로컬 머신에서 컨테이너로 package.json과 package-lock.json(있는 경우)을 복사합니다. 이 파일들은 종속성을 설치하는 데 사용됩니다.\n\n이는 npm install을 컨테이너 내에서 실행하여 package.json에 지정된 모든 종속성을 설치합니다. COPY . .는 나머지 애플리케이션 코드를 컨테이너의 작업 디렉토리로 복사합니다. EXPOSE 5000은 컨테이너가 실행 중인 포트 5000에서 수신하는 것을 Docker에 알립니다. 이는 내부 포트를 호스트 머신의 외부 포트에 매핑하는 데 유용합니다. CMD [\"npm\", \"start\"]는 컨테이너 시작 시 실행할 명령을 지정합니다. 일반적으로 package.json에 정의된 start 스크립트를 사용하여 서버를 시작하는 npm start를 실행합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프론트엔드 설정\n\n프론트엔드 도커 파일에 아래 지침을 포함해야 합니다.\n\n```js\n# frontend/Dockerfile\n\n# 공식 Node.js Alpine 기반 이미지 사용\nFROM node:20.11.1-alpine\n\n# 작업 디렉토리 설정\nWORKDIR /app\n\n# package.json 및 package-lock.json 복사\nCOPY package*.json ./\n\n# npm이 더 긴 타임아웃을 가지고 캐시를 사용하도록 설정\nRUN npm config set cache /app/.npm-cache --global\nRUN npm config set fetch-retries 10\nRUN npm config set fetch-retry-mintimeout 40000\nRUN npm config set fetch-retry-maxtimeout 220000\n\n# 종속성 설치\nRUN npm install\n\n# 나머지 애플리케이션 코드 복사\nCOPY . .\n\n# 애플리케이션이 실행되는 포트 노출\nEXPOSE 3000\n\n# 애플리케이션 실행\nCMD [\"npm\",\"start\"]\n```\n\n프론트엔드 및 백엔드 애플리케이션용 도커 파일을 설정할 때, 대부분의 지시사항이 매우 유사하다는 것을 알게 될 것입니다. 주요 차이점은 타임아웃 및 캐시 구성에 있습니다. 특정 요구 사항에 따라 추가 단계가 필요할 수도 있고 아닐 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 컨테이너 내의 캐시 디렉토리를 사용하세요 (/app/.npm-cache).\n- 패키지를 가져올 때 재시도 횟수를 늘리세요 (fetch-retries).\n- 패키지를 가져오는 데 걸리는 최소 및 최대 시간을 늘리세요 (fetch-retry-mintimeout 및 fetch-retry-maxtimeout).\n\n이러한 설정은 불안정한 네트워크 환경에서 종속성을 다운로드할 때 신뢰성을 향상시킬 수 있습니다. 인터넷 연결이 제대로 되지 않을 때 도움이 될 수 있어요 :(.\n\n## 단계 3: 도커 컴포즈 설정\n\n루트 도커 컴포즈 파일에 아래 구성을 포함해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# docker-compose.yml\n\nversion: '3.8'\nservices:\nbackend:\nbuild: ./backend\nports: - '5000:5000'\nfrontend:\nbuild: ./frontend\nports: - '3000:3000'\n\n`backend`: 백엔드 서비스를 정의합니다. 백엔드 디렉토리에서 Docker 이미지를 빌드하고 포트 5000으로 매핑합니다. `frontend`: 프론트엔드 서비스를 정의합니다. 프론트엔드 디렉토리에서 Docker 이미지를 빌드하고 포트 3000으로 매핑합니다.\n\n만약 몽고 DB와 같은 추가 서비스를 추가해야 한다면, 다음과 비슷한 추가 서비스를 backend에 의존하도록 추가하면 됩니다.\n\nversion: '3.8'\nservices:\nbackend:\nbuild: ./backend\nports: - '5000:5000'\ndepends_on: - mongo\nmongo:\nimage: mongo:latest\nports: - '27017:27017'\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 단계 4: 애플리케이션 빌드 및 실행\n\n프로젝트 루트에서 다음 명령을 실행하여 애플리케이션을 빌드하고 시작합니다:\n\n```js\ndocker-compose up — build\n```\n\nDocker Compose가 이미지를 빌드하고 컨테이너를 시작합니다. 프론트엔드는 http://localhost:3000에서, 백엔드는 http://localhost:5000에서 접속할 수 있습니다. 참조 코드는 여기에서 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 Docker Compose를 사용하여 MERN 스택 애플리케이션을 성공적으로 Docker화했습니다. 이 설정은 각 구성 요소에 대해 격리된 환경을 제공하여 애플리케이션을 관리하고 배포하기 쉽게합니다. 설정을 더 맞춤화하여 개발 및 프로덕션 요구 사항에 맞게 사용할 수 있습니다.\n\n환영합니다...!\n","ogImage":{"url":"/assets/img/2024-05-27-DockerizingaMERNStackApplicationAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-05-27-DockerizingaMERNStackApplicationAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":7},{"title":"하이브 메타스토어 HMS 스키마를 유니티 카탈로그로 이관하기","description":"","date":"2024-05-27 17:16","slug":"2024-05-27-MigrateHivemetastoreHMSSchematoUnityCatalog","content":"\n\u003cimg src=\"/assets/img/2024-05-27-MigrateHivemetastoreHMSSchematoUnityCatalog_0.png\" /\u003e\n\nHMS에서 Unity Catalog로의 이주 이야기에 오신 것을 환영합니다.\n\n본 글에서는 HMS에서 Unity Catalog로의 이주 과정을 공유하고자 합니다. HMS를 Unity Catalog로 마이그레이션하기 위한 여러 도구들이 있음을 알고 있습니다. 특히 현재 시장에서 인기를 끌고 있는 UCX가 있습니다. 아직 UCX를 탐험해보지는 않았지만, 앞으로 UCX를 살펴볼 예정입니다.\nUCX를 사용해보고 싶다면, https://github.com/databrickslabs/ucx 에서 확인하고 그 경험을 공유해주세요.\n\n본 글의 범위\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 외부 테이블을 Unity 카탈로그로 이주합니다.\n\n이 글에서 다루겠습니다.\n\n- 관리형 테이블을 Unity 카탈로그로 이주합니다.\n  https://medium.com/@data_engineering_0216/migrate-managed-table-to-unity-catalog-ab4dbba9d6aa\n- 뷰를 Unity 카탈로그로 이주합니다.\n  https://medium.com/@data_engineering_0216/migrate-views-from-hive-metastore-to-unity-catalog-7aac5ec1da50\n- 메타데이터 기반 권한 관리\n  https://medium.com/@data_engineering_0216/unity-catalog-permissions-f1e6221cbc68\n- https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/migrate\n\n외부 테이블을 Unity 카탈로그로 이주합니다.\n\n준비물\n\n- 메타스토어 또는 카탈로그 관리자 권한\n- Unity 카탈로그가 활성화된 Databricks 워크스페이스\n- Unity 카탈로그가 활성화된 클러스터\n- Databricks 접근 커넥터\n- 마운트 지점과 동등한 스토리지 자격 증명 및 외부 위치(읽기 및 쓰기 권한 필요)\n- 워크스페이스 또는 클러스터 수준에서 기본 카탈로그 설정: 선택 사항\n  클러스터 구성: spark.databricks.sql.initial.catalog.name gold_dv\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n솔루션을 깊이 살펴보겠습니다. 사용자 정의 Python 함수인 migrate_tables_to_unity_catalog을 살펴봅시다. 이 코드는 외부 테이블을 하나의 (hive_metastore) 카탈로그에서 다른 카탈로그(Unity Catalog)로 동기화하는 함수를 정의합니다.\n\n이 함수는 다음과 같은 매개변수를 사용합니다:\n\n- src_ct_name: 원본 카탈로그의 이름.\n- src_databases: 원본 카탈로그에서 가져온 데이터베이스 사전의 목록.\n- dst_ct_name: 대상 카탈로그의 이름.\n- exclude_databases: 마이그레이션에서 제외할 데이터베이스 이름의 목록.\n- full_reset: 전체 리셋을 수행해야 하는지 여부를 나타내는 부울 플래그.\n\n이 함수는 먼저 src_databases 매개변수에서 데이터베이스 이름 목록을 작성합니다. 제외할 데이터베이스가 있는 경우 해당 데이터베이스를 목록에서 필터링합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼, 각 데이터베이스를 처리하는 process_database 내부 함수를 정의합니다. full_reset이 True 인 경우, 대상 카탈로그의 데이터베이스를 삭제하고 새 데이터베이스를 생성한 후 소스 카탈로그에서 대상 카탈로그로 스키마를 동기화합니다. full_reset이 False 인 경우, 새 데이터베이스를 생성하고 스키마를 동기화합니다. full_reset이 제공되지 않은 경우, 재설정 모드를 요청하는 메시지를 출력합니다.\n\nconcurrent.futures.ThreadPoolExecutor를 사용하여 함수는 각 데이터베이스를 병렬로 처리하도록 제출합니다. 모든 futures가 완료되기를 기다리고 처리 중 발생한 예외를 처리합니다.\n\n이 함수를 사용하려면 필요한 매개변수를 제공하고 함수를 호출해야 합니다.\n\n```python\nimport concurrent.futures\n\n\ndef migrate_tables_to_unity_catalog(src_ct_name, src_databases, dst_ct_name, exclude_databases, full_reset):\n    \"\"\"\n    한 카탈로그에서 다른 카탈로그로 관리되는 모든 테이블을 복사합니다.\n\n    매개변수:\n        src_ct_name (str): 원본 카탈로그의 이름.\n        src_databases (list): 원본 카탈로그에서의 데이터베이스 딕셔너리 목록.\n        dst_ct_name (str): 대상 카탈로그의 이름.\n        exclude_databases (list): 마이그레이션에서 제외할 데이터베이스 이름 목록.\n\n    반환:\n        None\n\n    예외:\n        None\n\n    예시:\n        src_ct_name       = \"hive_metastore\"\n        src_databases     = spark.sql(f\"SHOW DATABASES IN {src_ct_name}\").collect()\n        dst_ct_name       = \"uc_dv\"\n        exclude_databases = [\"poc\", \"temp_tbd\", \"default\"]\n        migrate_managed_tables_to_unity_catalog(src_ct_name, src_databases, dst_ct_name, exclude_databases)\n\n    \"\"\"\n\n    list_of_db = []\n    for db in src_databases:\n        dbName = db['databaseName']\n        list_of_db.append(dbName)\n    if exclude_databases:\n        databases = [x for x in list_of_db if x not in exclude_databases]\n    else:\n        databases = list_of_db\n\n    print(databases)\n\n    def process_database(db, full_reset):\n\n        if full_reset == True:\n            drop_db = f\"DROP DATABASE IF EXISTS {dst_ct_name}.{db} CASCADE\"\n            display(spark.sql(drop_db))\n            create_db = f\"CREATE DATABASE IF NOT EXISTS {dst_ct_name}.{db}\"\n            display(spark.sql(create_db))\n            query = f\"SYNC SCHEMA {dst_ct_name}.{db} from {src_ct_name}.{db}\" # SYNC SCHEMA uc_dv.gold from hive_metastore.clean\n\n            print(query)\n            display(spark.sql(query))\n        elif full_reset == False:\n            create_db = f\"CREATE DATABASE IF NOT EXISTS {dst_ct_name}.{db}\"\n            display(spark.sql(create_db))\n            query = f\"SYNC SCHEMA {dst_ct_name}.{db} from {src_ct_name}.{db}\" # SYNC SCHEMA uc_dv.gold from hive_metastore.clean\n\n            print(query)\n            display(spark.sql(query))\n        else:\n            print(\"재설정 모드를 제공해주세요\")\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        futures = [executor.submit(process_database, db, full_reset) for db in databases]\n        # 모든 futures가 완료되기를 기다림\n        for future in concurrent.futures.as_completed(futures):\n            try:\n                # 각 future의 결과를 가져옴\n                result = future.result()\n            except Exception as e:\n                # 발생한 예외 처리\n                pass\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 코드는 다음 작업을 수행합니다:\n\n```js\nsrc_ct_name       = \"hive_metastore\"\nsrc_databases     = spark.sql(f\"SHOW DATABASES IN {src_ct_name}\").collect()\ndst_ct_name       = \"uc_dv\" #spark.sql(\"SELECT current_catalog()\").collect()[0]['current_catalog()']\nexclude_databases = [\"poc\", \"temp_tbd\", \"default\"]\nfull_reset         = False\n\nmigrate_tables_to_unity_catalog(src_ct_name,src_databases,dst_ct_name,exclude_databases,full_reset)\n```\n\n- \"src_ct_name\" 변수를 정의하여 값 \"hive_metastore\"를 할당합니다.\n- Spark를 사용하여 src_ct_name 카탈로그 내의 데이터베이스 목록을 검색하는 SQL 쿼리를 실행하고 결과를 src_databases 변수에 할당합니다.\n- Spark를 사용하여 현재 카탈로그를 검색하는 SQL 쿼리를 실행하고 결과를 dst_ct_name 변수에 할당합니다.\n- 마이그레이션 프로세스에서 제외될 데이터베이스 이름을 포함하는 \"exclude_databases\" 목록을 정의합니다.\n- 값이 False인 부울 변수 \"full_reset\"을 정의합니다.\n- migrate_tables_to_unity_catalog 함수를 src_ct_name, src_databases, dst_ct_name, exclude_databases 및 full_reset 매개변수로 호출합니다. 이 함수는 소스 카탈로그에서 대상 카탈로그로 테이블을 마이그레이션하는 역할을 합니다.\n\n위의 Python 함수는 hive_metastore의 외부 테이블을 unity Catalog로 몇 분 안에 마이그레이션하는 데 유용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 코드를 Databricks 노트북에 복사하여 Adf나 Databricks 일정으로 매일 실행하면 Unity Catalog로 완전히 마이그레이션할 때까지 도움을 줄 수 있습니다. 예를 들어, hive_metastore에 새 테이블을 추가하면 일정이 자동으로 새로운 테이블을 Unity Catalog에 동기화합니다.\n\nUnity Catalog로의 마이그레이션 여정에 도움이 되기를 바라며, 궁금한 점이 있으시면 언제든지 물어보세요.\n","ogImage":{"url":"/assets/img/2024-05-27-MigrateHivemetastoreHMSSchematoUnityCatalog_0.png"},"coverImage":"/assets/img/2024-05-27-MigrateHivemetastoreHMSSchematoUnityCatalog_0.png","tag":["Tech"],"readingTime":8},{"title":"데이터브릭스 Q2 로드맵 W2W4","description":"","date":"2024-05-27 17:15","slug":"2024-05-27-DatabricksQ2RoadmapW2W4","content":"\n![이미지](/assets/img/2024-05-27-DatabricksQ2RoadmapW2W4_0.png)\n\n# 소개\n\n저는 어떤 이유 때문인지 원래 초대를 놓쳐서 한 주를 뒤처져 이 글을 작성했습니다만, 최신 Databricks 분기 로드맵 웨비나에서 발표된 주요 소식들을 강조하고 싶었습니다. 고객 아카데미 계정을 가지신 분들은 재생 영상을 거기서도 볼 수 있습니다.\n\n# 유니티, 유니티, 유니티\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-27-DatabricksQ2RoadmapW2W4_1.png\" /\u003e\n\n작년 분기 웨비나에서 언급했었지만, Databricks는 플랫폼 내 데이터 거버넌스의 미래로 Unity Catalog에 올인했습니다. 새 작업 영역은 기본적으로 Unity로 활성화되며, 오래된 작업 영역이 더 나은 지원을 위해 이전해야 할 때가 올 것입니다.\n\n몇 달 동안 Unity 이주 작업을 진행해 온 사람으로서 이야기하자면, 그것은 유용하며 상기한 그래픽에 나열된 많은 이점을 제공합니다. 어떤 부분은 때로는 도전적일 수도 있지만 (아마도 과장되었다고 할 수 있을 정도로), 시간이 지남에 따라 그 과정이 더 쉬워질 것이라고 확신합니다.\n\nUnity의 새로운 기능 측면에서 외부 파티션 메타데이터에 대한 더 나은 지원이 곧 추가될 예정이며, 현재보다 Parquet 데이터 액세스 속도를 향상시킬 것입니다. 게다가 기존 계보를 통합하고 싶은 사람들을 위해 BYOL(본인의 계보 가져오기)이라는 개념도 곧 나올 예정입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 대시보드/Databricks SQL\n\n지난 몇 달 동안 Databricks 내의 대시보드는 확실히 새롭게 변화했습니다. 곧 다른 사람들과 대시보드를 공유할 수 있는 기능이 추가될 예정이며, 이를 통해 새로운 사용자를 워크스페이스에 등록하는 데 여러 채널을 통해 지나야 하는 사용자들에게 큰 도움이 될 것입니다. 또한 대시보드는 웹페이지/앱에 플러그인으로 추가될 예정이므로, 더 많은 호환성을 원하는 사용자들을 위한 것입니다.\n\n반면에 Databricks SQL은 몇 가지 좋은 향상이 예정되어 있습니다. SQL 작성의 개념을 도입하여 쿼리와 협업 편집을 위한 Git 통합을 지원할 것입니다. SQL 스크립트는 트랜잭션 수준의 처리 및 루프와 같은 구조 지원을 제공할 것입니다.\n\n저도 이게 아니었군요, 그러나 변형 데이터 유형이 드디어 Databricks에 추가될 예정입니다. JSON 필드 작업을 하는 사람으로써, 이것이 Snowflake에서 큰 도움이 되었고, 여기에도 도입되어 기쁩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 워크플로우/노트북\n\n저는 주로 워크플로우에 Databricks를 사용하기 때문에, 이 섹션이 웨비나에서 나타날 때 놓치지 않아요. Delta Table 업데이트 후 워크플로우를 트리거하고 싶었던 적이 있다면, 테이블 트리거의 개념을 사용하면 이를 쉽게 할 수 있어요. 이제 워크플로우에서 센서의 개념이 더 많이 사용되어 추가 작업 관리 도구에 절대적으로 의존할 필요가 없게 되었다는 것은 좋은 일이에요.\n\n개발자 경험은 DAB를 위한 새로운 VS Code 통합으로 개선될 것이에요. Databricks Connect가 Databricks와 작업을 이끄는 모든 코드 간에 더 원활한 지원을 제공하는 긍정적인 발전이었기 때문에, 자산 번들을 보다 쉽게 개발하고 테스트할 수 있는 능력은 제게 자연스러운 진전 같아요.\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이번에 나오는 새로운 릴리스에 대해 기대되는 것이 많네요. 개발 노력을 계획하기 위해 항상 유익한 세션을 마련해 주셔서 Databricks에게 항상 감사드립니다.\n","ogImage":{"url":"/assets/img/2024-05-27-DatabricksQ2RoadmapW2W4_0.png"},"coverImage":"/assets/img/2024-05-27-DatabricksQ2RoadmapW2W4_0.png","tag":["Tech"],"readingTime":3},{"title":"현재 날짜나 시간을 기준으로 데이터브릭에서 여러 파일을 동적으로 로드하는 방법","description":"","date":"2024-05-27 17:13","slug":"2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour","content":"\nBatch 시스템에서는 여러 번 클라이언트가 이미 추출된 파일을 동일한 경로에 유지하고, 도착한 추출 파일이 Bronze 레이어에 로드되기를 원하는 경우가 많습니다.\n\n따라서 이 경우, 개발자는 디렉토리에 있는 파일 목록 중에서 현재 날짜나 현재 시간에 도착한 파일만 고려하여 해당 파일의 내용을 Bronze 레이어에만 로드할 수 있도록 해야 합니다.\n\n이미지를 보면 오늘 날짜는 2024년 5월 25일임을 알 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2024년 5월 22일에 첫 번째 파일이 도착했습니다.\n2024년 5월 23일에 두 번째 파일이 도착했습니다.\n2024년 5월 24일에 세 번째 파일이 도착했습니다.\n나머지 네 개의 파일은 오늘인 2024년 5월 25일에 도착했습니다.\n\n오늘 도착한 첫 번째 파일 내용은 다음과 같습니다 -\n\n![이미지](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_1.png)\n\n오늘 도착한 두 번째 파일 내용은 다음과 같습니다 -\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Third File](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_3.png)\n\nThe content of the Fourth File arrived today is as follows -\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_4.png\" /\u003e\n\n# 현재 날짜 기반으로 데이터브릭에서 여러 파일 동적으로 로드하는 방법\n\n그래서, 작업은 최근 네 개의 파일을 처리하고 그 네 개 파일의 내용을 브론즈 레이어의 테이블에 추가 모드로 로드하는 것입니다.\n\n단계 1: 브론즈 테이블 생성하기 -\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 다음 \"Spark SQL\" 쿼리를 사용하여 \"practice\"라는 데이터베이스를 생성하십시오 -\n\n```js\n%sql\nUSE hive_metastore;\nCREATE DATABASE IF NOT EXISTS practice\n```\n\n데이터베이스는 Databricks 워크스페이스에 생성됩니다 -\n\n![이미지](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼 다음 \"Spark SQL\" 쿼리를 사용하여 외부 델타 테이블 \"person_bronze\"을 생성하세요 -\n\n```js\n%sql\nCREATE TABLE IF NOT EXISTS hive_metastore.practice.person_bronze\n(\n  FirstName STRING NOT NULL,\n  LastName STRING NOT NULL,\n  City STRING NOT NULL,\n  Company STRING NOT NULL\n)\nLOCATION \"dbfs:/mnt/iobdatabronze/practice-zone/delta-table/person_bronze\"\n```\n\n외부 델타 테이블은 Databricks 워크스페이스의 \"practice\" 데이터베이스 내부에 생성됩니다 -\n\n![image](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n생성된 External Delta Table \"person_bronze\"의 폴더 경로는 제공된 위치에 ADLS에 생성되었습니다-\n\n![image](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_7.png)\n\n단계 2: 현재 날짜인 2024년 5월 25일을 기준으로 Databricks에서 가장 최근 네 개의 파일을 로드하는 Python 코드를 작성해 보겠습니다.\n\n단계 2.1: Python의 \"datetime\" 모듈을 사용하여 \"현재 날짜\"의 값을 가져와, 도착 파일의 이름에 사용된 형식과 일치하도록 \"현재 날짜\"의 값을 포맷팅해 주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport os\nfrom datetime import datetime\nfrom functools import reduce\n\n# Python의 \"datetime\" 모듈을 사용하여 현재 날짜 가져오기\ncurrent_date = datetime.now()\nprint(current_date)\n\n# 현재 날짜의 값을 파일 이름 형식에 맞게 포맷팅하여 출력\nfile_name_date_format = current_date.strftime(\"%Y%m%d\")\nprint(file_name_date_format)\n```\n\n출력 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_8.png\" /\u003e\n\n단계 2.2: 파일이 보관된 ADLS 디렉토리의 \"마운트된 경로\"를 지정합니다.\n그런 다음, 해당 지정된 디렉토리에서 모든 파일을 나열합니다.\n마지막으로, 그 지정된 디렉토리의 파일 이름에 \"현재 날짜\"가 포함된 파일만 걸러내어 Python List에 저장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 파일이 위치한 ADLS 디렉토리의 마운트 경로 지정하기\ndirectory_path = \"/mnt/iobdatalanding/practice-zone/input-files/\"\n\n# 지정된 디렉토리에 있는 모든 파일 나열하기\nall_files = os.listdir(\"/dbfs\" + directory_path)\nprint(all_files)\n\n# 현재 날짜가 파일 이름에 포함된 파일만 필터링하여 Python 리스트에 저장하기\nmatching_files = [matching_file for matching_file in all_files if file_name_date_format in matching_file]\nprint(matching_files)\n```\n\n출력 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_9.png\" /\u003e\n\n단계 2.3: 먼저 \"빈 Python 리스트\"를 생성하세요.\n그런 다음 각 일치하는 파일의 내용을 각각 별도의 DataFrame에 로드하세요.\n마지막으로 각 DataFrame을 이미 생성된 \"Python 리스트\"에 \"객체\"로 추가하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 빈 리스트 생성\nlist_of_dfs = []\n\n# 각 일치하는 파일을 각각 별도의 데이터프레임으로 로드\nfor file_name in matching_files:\n    # 실제 파일 경로 생성\n    file_path = os.path.join(directory_path, file_name)\n    # 각 파일마다 데이터프레임 생성\n    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n    # 각 데이터프레임을 빈 리스트에 객체로서 각각 저장\n    list_of_dfs.append(df)\n\nprint(list_of_dfs)\n```\n\n출력 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_10.png\" /\u003e\n\n2.4단계: 각 데이터프레임의 모든 값들을 단일 데이터프레임으로 연결하고, 각 데이터프레임의 값들이 이제 \"파이썬 리스트\"의 각 객체로 되는 단일 데이터프레임을 생성하기 위해 \"reduce()\" 함수와 \"union()\" 메서드를 사용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 각 데이터프레임의 모든 값을 연결하여 하나의 데이터프레임으로 만들기\n# 이때 각 데이터프레임의 값은 이제 Python List의 각 객체이며 \"reduce()\" 함수를 사용하여 \"union()\" 메서드와 함께 결합합니다.\nfinal_df = reduce(lambda df1, df2: df1.union(df2), list_of_dfs)\ndisplay(final_df)\n```\n\n결과 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_11.png\" /\u003e\n\n따라서 위 이미지에서 오늘 도착한 네 개의 파일에서 모든 레코드의 조합이 포함된 \"final_df\" 데이터프레임이 있음을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n당신이 개발자십에 관심이 있나봐요! 친철한 톤으로 번역해 드리겠습니다.\n\n스텝 2.5: 'final_df' DataFrame의 내용을 Bronze Table \"person_bronze\"에 삽입하세요.\n\n```js\n# 'final_df' DataFrame의 내용을 Bronze Table \"person_bronze\"에 삽입\nfinal_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"hive_metastore.practice.person_bronze\")\n```\n\n다음 \"스파크 SQL\" 쿼리를 사용하여 'person_bronze' Bronze Table에 방금 삽입된 데이터가 있는지 확인하세요 -\n\n```js\n%sql\n-- 'person_bronze' Bronze Table에 데이터가 있는지 확인\nSELECT * FROM hive_metastore.practice.person_bronze;\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n출력 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_12.png\" /\u003e\n\n# 현재 시간을 기반으로 한 Databricks에서 여러 파일 로드하기\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_13.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금은 2024년 5월 25일이고, 현재 시간은 오후 8시입니다. 위 그림에서 볼 수 있듯이, 마지막 두 파일이 \"현재 시간\"인 즉, 8시에 도착했습니다.\n\n그러므로, 마지막 두 파일을 처리하고 그 두 파일의 내용을 브론즈 레이어의 테이블에 추가 모드로 로드하는 작업입니다.\n\n# 현재 날짜 또는 시간에 따라 Databricks에서 여러 파일을 동적으로 로드하는 방법\n\n배치 시스템에서는 고객이 이미 추출된 파일을 도착한 추출된 파일과 동일한 경로에 유지하고 브론즈 레이어에 로드하길 원하는 경우가 많습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서 현재 일 또는 현재 시간에 도착한 파일만 고려하여 디렉터리에있는 파일 목록에서 해당 파일의 내용을 처리하고 브론즈 계층으로 로드하는 개발자의 책임이 있습니다.\n\n![이미지](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_14.png)\n\n오늘은 2024년 5월 25일입니다. 위 이미지에서 볼 수 있듯이 -\n\n첫 번째 파일은 2024년 5월 22일에 도착했습니다.\n두 번째 파일은 2024년 5월 23일에 도착했습니다.\n세 번째 파일은 2024년 5월 24일에 도착했습니다.\n나머지 네 번째 파일은 2024년 5월 25일, 즉 오늘 도착했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n오늘 도착한 첫 번째 파일 내용은 다음과 같습니다 -\n\n![First File](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_15.png)\n\n오늘 도착한 두 번째 파일 내용은 다음과 같습니다 -\n\n![Second File](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_16.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현재 시간에 도착한 첫 번째 파일의 내용은 다음과 같습니다 -\n\n![](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_17.png)\n\n현재 시간에 도착한 두 번째 파일의 내용은 다음과 같습니다 -\n\n![](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_18.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nStep 1: Create a Bronze Table -\n\n이미 첫 번째 부분에서 생성되었습니다.\n\nStep 2: 오늘 현재 시간 기준으로 Databricks에서 마지막 두 파일을로드하는 Python 코드 작성 시작, 즉, 2024년 5월 25일 오후 8시.\n\nStep 2.1: Python의 \"datetime\" 모듈을 사용하여 \"현재 날짜\"의 \"현재 시간\" 값을 가져와서 \"현재 날짜\"의 \"현재 시간\" 값을 적시되어 파일 도착 이름 및 \"날짜\" 및 \"시간\" 부분과 일치하도록 형식화하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nimport os\nfrom datetime import datetime\nfrom functools import reduce\n\n# Python의 \"datetime\" 모듈을 사용하여 현재 날짜의 현재 시간을 가져옵니다.\ncurrent_date_and_time = datetime.now()\nprint(current_date_and_time)\n\n# 현재 시간의 값을 파일 이름의 날짜 및 시간 형식과 일치하도록 형식화합니다.\nfile_name_date_and_hour_format = current_date_and_time.strftime(\"%Y%m%d%H\")\nprint(file_name_date_and_hour_format)\n```\n\n출력 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_19.png\" /\u003e\n\n단계 2.2: 파일이 보관된 ADLS 디렉토리의 \"Mounted Path\"를 지정합니다.\n그런 다음, 해당 지정된 디렉토리에서 모든 파일을 나열합니다.\n마지막으로 해당 지정된 디렉토리의 파일 이름 중 \"현재 날짜\"의 \"현재 시간\"이 있는 파일만 필터링하여 Python List에 저장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 파일이 위치한 ADLS 디렉토리의 마운트 경로를 지정합니다\ndirectory_path = \"/mnt/iobdatalanding/practice-zone/input-files/\"\n\n# 지정된 디렉토리에 있는 모든 파일을 나열합니다\nall_files = os.listdir(\"/dbfs\" + directory_path)\nprint(all_files)\n\n# 현재 날짜의 현재 시간을 파일 이름에 포함하는 파일만 필터링합니다\nmatching_files = [matching_file for matching_file in all_files if file_name_date_and_hour_format in matching_file]\nprint(matching_files)\n```\n\nOutput -\n\n![다이나믹 파일로드 방법](/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_20.png)\n\n단계 2.3: 먼저 \"빈 Python List\"를 생성합니다.\n그런 다음 각 일치하는 파일의 내용을 각각 별도의 DataFrame으로 로드합니다.\n마지막으로, 각 해당 DataFrame을 이미 생성된 \"Python List\"에 \"객체\"로서 추가합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 빈 목록 생성\nlist_of_dfs = []\n\n# 각 일치하는 파일을 각각 별도의 데이터프레임으로 불러오기\nfor file_name in matching_files:\n    # 실제 파일 경로 생성\n    file_path = os.path.join(directory_path, file_name)\n    # 각 파일에 대한 데이터프레임 생성\n    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n    # 각 데이터프레임을 빈 목록에 객체로 각각 저장\n    list_of_dfs.append(df)\n\nprint(list_of_dfs)\n```\n\n출력 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_21.png\" /\u003e\n\n단계 2.4: 각 데이터프레임의 모든 값들을 단일 데이터프레임으로 연결합니다. 각 데이터프레임의 값은 이제 \"Python List\"의 각 객체이며, \"reduce()\" 함수와 \"union()\" 메소드를 사용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 각 DataFrame의 모든 값들을 Python 리스트의 각 객체로 사용하여 하나의 DataFrame으로 결합하십시오. \"reduce()\" 함수를 사용하고 \"union()\" 메서드를 함께 사용하십시오.\n\nfinal_df = reduce(lambda df1, df2: df1.union(df2), list_of_dfs)\ndisplay(final_df)\n\n출력 -\n\n\u003cimg src=\"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_22.png\" /\u003e\n\n따라서 위 이미지에서 현재 시간에 도착한 두 파일의 레코드를 모두 포함하는 \"final_df\" DataFrame을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스텝 2.5: \"final_df\" 데이터프레임의 내용을 첫 번째 부분에 표시된 PySpark 코드를 사용하여 Bronze 테이블 \"person_bronze\"에 삽입합니다.\n\n마지막으로, 첫 번째 부분에 표시된 \"Spark SQL\" 쿼리를 사용하여 방금 삽입한 데이터가 Bronze 테이블 \"person_bronze\"에 있는지 확인하세요.\n","ogImage":{"url":"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_0.png"},"coverImage":"/assets/img/2024-05-27-HowToDynamicallyLoadMultipleFilesinDatabricksBasedonCurrentDateorHour_0.png","tag":["Tech"],"readingTime":16}],"page":"51","totalPageCount":116,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"51"},"buildId":"wfHLuDA3kTGBYfaM5IGXk","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>