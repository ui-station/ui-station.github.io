<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/40" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/40" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/PgdIX9e0tvkvkdAmDT6qR/_buildManifest.js" defer=""></script><script src="/_next/static/PgdIX9e0tvkvkdAmDT6qR/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="시간을 통해 전파하는 역전파  RNN이 학습하는 방법" href="/post/2024-05-18-BackpropagationThroughTimeHowRNNsLearn"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="시간을 통해 전파하는 역전파  RNN이 학습하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="시간을 통해 전파하는 역전파  RNN이 학습하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">시간을 통해 전파하는 역전파  RNN이 학습하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법" href="/post/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2" href="/post/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">30<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="고객 이탈 예측" href="/post/2024-05-18-CUSTOMERCHURNPREDICTION"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고객 이탈 예측" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고객 이탈 예측" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고객 이탈 예측</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="휴머노이드는 여기에 머물러 있을까요" href="/post/2024-05-18-AretheHumanoidsHeretoStay"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="휴머노이드는 여기에 머물러 있을까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="휴머노이드는 여기에 머물러 있을까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">휴머노이드는 여기에 머물러 있을까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="필수 인공지능" href="/post/2024-05-18-EssentialAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="필수 인공지능" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-EssentialAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="필수 인공지능" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">필수 인공지능</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="SLAM을 처음부터 구현해 보기" href="/post/2024-05-18-ImplementSLAMfromscratch"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="SLAM을 처음부터 구현해 보기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-ImplementSLAMfromscratch_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="SLAM을 처음부터 구현해 보기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">SLAM을 처음부터 구현해 보기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="로봇 학습의 현황" href="/post/2024-05-18-TheStateofRobotLearning"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="로봇 학습의 현황" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TheStateofRobotLearning_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="로봇 학습의 현황" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">로봇 학습의 현황</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" href="/post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이 5에서 VSCode 서버 다시 시도하기" href="/post/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이 5에서 VSCode 서버 다시 시도하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이 5에서 VSCode 서버 다시 시도하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">라즈베리 파이 5에서 VSCode 서버 다시 시도하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link posts_-active__YVJEi" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"시간을 통해 전파하는 역전파  RNN이 학습하는 방법","description":"","date":"2024-05-18 19:38","slug":"2024-05-18-BackpropagationThroughTimeHowRNNsLearn","content":"\n\n\n![RNN](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png)\n\n순환 신경망(RNN)은 시계열 및 자연어와 같은 순차 데이터를 처리하는 정규 피드포워드 신경망 변형입니다.\n\n과거 입력 및 출력에서 다음 단계로 정보를 전달할 수 있도록 \"순환\" 뉴런을 추가하여 이를 달성합니다. 아래 다이어그램은 전통적인 RNN을 보여줍니다:\n\n![RNN Diagram](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_1.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n왼쪽에는 반복 뉴런이 있고, 오른쪽에는 시간을 거듭할수록 펼쳐진 반복 뉴런이 있습니다. 이전 실행이 이어지는 계산에 전달되는 방식을 주목해주세요.\n\n이것은 시스템에 어느정도의 \"기억력\"을 추가하여 모델이 이전 시간에 발생한 역사적 패턴을 잡는 데 도움이 됩니다.\n\nY_1을 예측할 때, 반복 뉴런은 X_1의 입력과 이전 시간 단계의 출력인 Y_0을 사용합니다. 이는 Y_0이 Y_1에 직접적인 영향을 미치고, 이는 Y_2에 간접적으로 영향을 미침을 의미합니다.\n\nRNN에 대한 완벽한 소개와 몇 가지 실습 예제를 원하신다면, 이전 포스트를 확인해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이 기사에서는 RNN이 어떻게 학습하는지를 뒷방향 시간으로 이해하자구! \n\n# 역전파란?\n\nBPTT에 대해 들어가기 전에, 일반적인 역전파를 다시 확인하는 것이 중요하다. 역전파는 일반적인 피드포워드 신경망을 훈련하는 데 사용되는 알고리즘이야.\n\n역전파의 본질은 손실 함수를 기반으로 신경망의 각 매개변수를 조정하여 오차를 최소화하려는 것이야. 이 조정은 편도함수와 연쇄법칙을 사용해 이루어져.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\ncompute 그래프를 통해 간단한 예제를 보여드릴게요. compute 그래프는 신경망과 매우 닮은데요.\n\n다음 함수를 살펴보세요:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_2.png)\n\n이것을 compute 그래프로 그릴 수 있습니다. 이는 함수를 시각화하는 방법일 뿐이에요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n`\u003ctable\u003e` 태그를 마크다운 형식으로 변경해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 먼저 p=x-y 및 f=pz에 대한 편미분을 계산할 수 있습니다:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_5.png)\n\n하지만, 어떻게 얻을까요?\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요기서는 chain rule을 사용해요! x에 대한 예시가 있어요:\n\n![chain rule example](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_7.png)\n\n서로 다른 편미분을 결합하면 원하는 표현을 얻을 수 있어요. 그래서 위 예시에서:\n\n![partial derivatives example](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nf에 대한 x의 출력 그라디언트는 z입니다. 이게 말이 되지요. z는 x를 곱하는 유일한 값이기 때문이죠.\n\ny와 z에 대해서도 반복합니다:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_9.png)\n\n이러한 그라디언트들과 그에 해당하는 값들을 계산 그래프에 적어볼 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Gradient Descent Image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_10.png)\n\nGradient descent works by updating the values (x, y, z) by a small amount in the opposite direction of the gradient. The goal of gradient descent is to try and minimize the output function. For example, for x:\n\n![Equation for x](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_11.png)\n\nWhere h is called the learning rate, it decides how much the parameter will get updated. For this case, let’s define h=0.1, so x=3.7.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금 출력 결과는 무엇인가요?\n\n![이미지](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_12.png)\n\n결과가 작아졌죠. 다시 말해, 최소화 중이에요!\n\n이것이 역전파가 어떻게 작동하는지에 대한 직관을 제공해줬으면 좋겠어요. 기본적으로 그것은 그라디언트 강하와 같지만, 연쇄 법칙을 사용하여 상류 그라디언트를 전달한다는 거죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n백프로패게이션에 대한 전문 기사가 있어요. 더 읽고 싶으시면 참고하세요.\n\n# 시간을 통한 역전파란?\n\n## 개요\n\n우리는 방금 백프로패게이션이 그래디언트 강하법이라는 것을 보았습니다. 그러나 우리는 네트워크 층마다 오류(도함수)를 역방향으로 전파하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBPTT은 각 시점에서 역전파를 수행하여 이러한 정의를 확장합니다. 예제를 함께 살펴보겠습니다.\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_13.png)\n\n다음 다이어그램에서:\n\n- Y는 출력 벡터입니다.\n- X는 피처의 입력 벡터입니다.\n- h는 숨겨진 상태입니다.\n- V는 출력을 위한 가중치 행렬입니다.\n- U는 입력을 위한 가중치 행렬입니다.\n- W는 숨겨진 상태를 위한 가중치 행렬입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어떤 시간 t에서 다음은 계산된 출력입니다:\n\n![2024-05-18-BackpropagationThroughTimeHowRNNsLearn_14.png](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_14.png)\n\n여기서 σ는 일반적으로 tanh 또는 sigmoid인 활성화 함수입니다.\n\n우리의 손실 함수가 평균 제곱 오차인 경우를 가정해 봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_15.png)\n\nA_t is the actual value that we want our prediction to equal.\n\n## Backpropagation Through Time\n\nNow, we are in a position to start doing BPTT after this problem has been set up.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n백프로파게이션의 목표는 모델의 가중치와 매개변수를 조정하여 오차를 최소화하는 것입니다. 이것은 가중치와 매개변수에 대한 오차의 편미분을 통해 수행됩니다.\n\n시간 단계 3의 업데이트를 계산해 봅시다.\n\nV 가중치 행렬에 대해:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_16.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요번은 꽤 간단해요. E_3은 Y_3의 함수에요. 그래서 Y_3에 대해 E_3을 미분하고, Y_3을 V에 대해 미분해요. 여기서는 너무 복잡한 일은 없어요.\n\nW 가중 행렬에 대해:\n\n![이미지](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_17.png)\n\n이제 조금 멋진 것들이 나타나네요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 식에서 첫 번째 용어는 비교적 간단합니다. E_3는 Y_3의 함수이며, Y_3는 h_3의 함수이며, h_3는 W의 요소입니다. V 행렬에서 보았던 것과 동일한 프로세스입니다.\n\n그러나 h_2와 h_1에 대한 이전 단계에서도 행렬 W가 사용되었으므로 그 이전 단계에 대한 미분을 고려해야 합니다.\n\nRNN에서 상태 h_3가 이전 상태에 종속되므로 W의 영향을 모든 시간 단계에 걸쳐 고려해야 합니다.\n\nU 가중치 행렬에 대해:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_18.png)\n\nU 행렬에 대한 오류는 W에 대한 것과 매우 유사하며, 다른 점은 숨겨진 상태 h를 U로 미분한다는 점입니다.\n\n숨겨진 상태는 이전 숨겨진 상태와 새 입력의 복합 함수입니다.\n\n## 일반화된 공식\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBPTT는 다음과 같이 일반화될 수 있습니다:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_19.png)\n\n여기서 J는 RNN 내의 임의의 가중치 행렬이며, U, W 또는 V가 될 수 있습니다.\n\nRNN의 총 오차(손실)는 각 시간 스텝에서의 오차인 E_t의 합입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![2024-05-18-BackpropagationThroughTimeHowRNNsLearn_20.png](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_20.png)\n\nAnd, that’s pretty much all there is to training an RNN! However, there is one problem ...\n\n# Exploding \u0026 Vanishing Gradient Problem\n\n## Overview\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRNN의 중요한 문제 중 하나는 사라지는 그래디언트와 폭발하는 그래디언트 문제입니다. 이 문제는 BPTT를 수행할 때 네트워크를 T번 시간 단계만큼 펼치기 때문에 발생합니다. 이로 인해 네트워크는 사실상 T개의 레이어를 갖게 됩니다.\n\n흔히 사용되는 타임스탬프의 수가 많기 때문에, 펼쳐진 네트워크는 보통 아주 깊어집니다. 그래디언트가 역방향으로 전파됨에 따라 지수적으로 증가하거나 감소할 수 있습니다.\n\n이것은 활성화 함수가 일반적으로 tanh 또는 sigmoid인 경우에 발생합니다. 이러한 함수들은 입력을 작은 출력 범위로 압축시킵니다: sigmoid는 0에서 1, tanh는 -1에서 1까지입니다.\n\n이러한 함수의 미분 값은 큰 절댓값 입력에 대해 작고 거의 0에 가깝습니다. RNN과 같이 깊은 네트워크에서 이러한 미분 값이 연쇄 법칙에 사용될 때, 위에서 보았듯이 많은 작은 숫자들이 곱해지게 됩니다. 이는 매우 작은 숫자가 되어 초기 레이어에서 거의 0에 가까운 그래디언트를 생성하게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 수학적 추론\n\n이전 내용을 참고하면, 이전 시간 단계의 다른 숨은 상태에 대한 숨은 상태의 편미분을 계산하는 많은 경우가 있습니다.\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_21.png)\n\n그런 다음 우리의 숨은 상태(시간 단계) 수에 따라 여러 번 곱해집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 Markdown 형식의 텍스트입니다.\n\n![이미지1](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_22.png)\n\n여기에 일어나는 일입니다:\n\n![이미지2](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_23.png)\n\n이제 RNN이 경험하는 기울기 소실과 폭주에 대한 이유를 이해할 수 있습니다. 순차 길이에 따라 기울기가 지수 함수적으로 소실되는 것은 숨은 상태의 편도함수를 반복적으로 곱하기 때문인 체인 규칙 효과입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 문제\n\n만약 그래디언트가 소멸한다면, RNN은 매우 나쁜 장기 기억력을 가지고 있어 과거에서 많은 것을 배울 수 없게 됩니다. 이는 정말 좋지 않은 상황인데, RNN은 순차 데이터를 다룰 수 있도록 메모리를 갖추도록 설계되었기 때문입니다.\n\n이로 인해 그래디언트가 매우 작아지게 되는데, 이는 가중치가 업데이트되는 값도 작아진다는 것을 의미합니다. 따라서 네트워크가 훈련하는 데 시간이 오래 걸리고 더 많은 컴퓨팅 자원을 사용하게 됩니다.\n\n물론, 많은 현명한 사람들이 이 문제를 해결하기 위한 방법을 개발해 왔는데, 다음 글에서 그에 대해 논의할 예정입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 게시물에서는 폭망 경사 문제와 이를 극복하는 데 사용되는 도구에 대해 더 많이 읽을 수 있어요.\n\n# 요약 및 추가적인 생각\n\nRNN은 일반 피드포워드 신경망과 비슷한 알고리즘을 사용하여 학습합니다. 시간을 통한 역전파는 일반적인 역전파와 매우 유사하지만, 각 오류와 가중치 행렬에 대해 해당 가중치 행렬이 사용된 모든 과거의 시간을 고려해야 합니다. 이로 인해 불안정한 경사를 초래할 수 있습니다. RNN은 종종 매우 깊은 구조를 가지므로 도함수를 여러 번 곱하게 되어 초기 레이어에 도달했을 때 그 값을 증가시키거나 감소시킬 수 있습니다.\n\n# 저와 소통해요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- LinkedIn, X(Twitter) 또는 Instagram\n- 기술적인 데이터 과학과 머신 러닝 개념을 배울 수 있는 내 YouTube 채널!\n\n## 참고 및 더 읽을거리\n\n- Stanford RNN CheatSheet\n- Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. Aurélien Géron. 2019년 9월. 출판사: O’Reilly Media, Inc. ISBN: 9781492032649.","ogImage":{"url":"/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png"},"coverImage":"/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png","tag":["Tech"],"readingTime":8},{"title":"LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법","description":"","date":"2024-05-18 19:35","slug":"2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting","content":"\r\n\r\nLSTM을 시계열 예측에 사용할 때, 사람들은 흔히 범할 수 있는 함정에 빠지곤 합니다. 이를 설명하기 위해서는 회귀자와 예측자의 작동 방식을 살펴볼 필요가 있습니다. 예측 알고리즘은 시계열 데이터를 다루는 방법을 아래와 같이 보여줍니다:\r\n\r\n\r\n![How a forecasting algorithm works](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png)\r\n\r\n\r\n한편, 회귀 문제는 다음과 같이 보일 것입니다:\r\n\r\n\r\n![How a regression problem looks](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_1.png)\r\n\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\nLSTM이 회귀기이므로 시계열을 회귀 문제로 변환해야 합니다. 이를 수행하는 여러 방법이 있지만, 이 섹션에서는 창(Window) 및 다중 단계(Multi-Step) 방법에 대해 설명하고, 어떻게 작동하는지와 특히 이를 활용할 때 발생할 수 있는 일반적인 실수를 피하는 방법에 대해 논의할 것입니다.\r\n\r\n창 방법(Window Method)에서, 시계열은 이전 각 시간 단계의 값과 결합되어 창이라고 불리는 가상 특성으로 되어 있습니다. 여기서 창 크기가 3인 창이 있습니다:\r\n\r\n![창 방법 이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_2.png)\r\n\r\n다음 함수는 단일 시계열에서 창 방법 데이터 세트를 생성합니다. 사용자는 이전 값의 수(보통 look back이라고 함)를 선택해야 합니다. 결과 데이터 세트에는 대각선 반복이 있으며, look-back 값에 따라 샘플의 수가 달라집니다:\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n```js\r\ndef window(sequences, look_back):\r\n    X, y = [], []\r\n    for i in range(len(sequences)-look_back-1):\r\n        x = sequences[i:(i+look_back)]\r\n        X.append(x)\r\n        y.append(sequences[i + look_back])\r\n    return np.array(X), np.array(y)\r\n```\r\n\r\n이제 결과를 살펴보겠습니다. 모델을 훈련한 후에는 테스트 세트에서 테스트됩니다. 다양한 소스와 튜토리얼에서는 비슷한 방법을 사용하여 결과를 컴파일하는 것을 제안했습니다. 그러나 나중에 설명할 것처럼 이 방법은 신빙성이 없습니다. 그럼 지금은 코드와 결과가 어떻게 보이는지 살펴보겠습니다:\r\n\r\n```js\r\nlook_back = 3\r\nX, y = window(ts_data, look_back)\r\n\r\n# 훈련-테스트 분할\r\ntrain_ratio = 0.8\r\ntrain_size = int(train_ratio * len(ts_data))\r\nX_train, X_test = X[:train_size-look_back], X[train_size-look_back:]\r\ny_train, y_test = y[:train_size-look_back], y[train_size-look_back:]\r\n\r\n# LSTM 모델 생성 및 훈련\r\nmodel = Sequential()\r\nmodel.add(LSTM(units=72, activation='tanh', input_shape=(look_back, 1)))\r\nmodel.add(Dense(1))\r\nmodel.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mape'])\r\n\r\nmodel.fit(x=X_train, y=y_train, epochs=500, batch_size=18, verbose=2)\r\n\r\n# 예측 생성\r\nforecasts = model.predict(X_test)\r\nlstm_fits = model.predict(X_train)\r\n\r\n# 메트릭스 계산\r\nmape = mean_absolute_percentage_error(y_test, forecasts)\r\nr2 = r2_score(y_train, lstm_fits)\r\n\r\n# 날짜 초기화\r\ndate_range = pd.date_range(start='1990-01-01', end='2023-09-30', freq='M')\r\n\r\n# 맞춤 값에 원래 시계열과 맞추기 위한 비어있는 값 추가\r\nfits = np.full(train_size, np.nan)\r\nfor i in range(train_size-look_back):\r\n    fits[i+look_back] = lstm_fits[i]\r\n\r\n# 실제값, 맞춤값, 예측값 플롯\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[:train_size], fits, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], forecasts, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\nOne Step Forward Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {r2*100:.2f}%\\nMAPE = {mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_3.png\" /\u003e\r\n\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n문제: 결과는 훌륭해 보입니다. 그러나 샘플 테스트 세트를 살펴보면 특이한 결함이 보입니다:\r\n\r\n![이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_4.png)\r\n\r\n예를 들어 y9를 생성하는 데에는 y8이 입력으로 사용되었습니다. 훈련에는 사용되지 않았지만 미래 값을 포함하는 것은 이상합니다. 왜냐하면 우리는 미래의 시점을 예측하고 있기 때문입니다.\r\n\r\n해결책: 직접적으로 이전 값을 예측 값으로 대체하는 반복적 테스트 세트를 사용하면 이 문제를 해결할 수 있습니다. 이러한 배치 방식에서 모델은 자체 예측에 기반을 둔다. 일반적인 예측 알고리즘과 유사합니다.\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n아래 루프에서 다음을 수행합니다:\r\n\r\n```js\r\n# 반복적인 예측 및 대체\r\nfor i in range(len(X_test)):\r\n    forecasts[i] = model.predict(X_test[i].reshape(1, look_back, 1))\r\n    if i != len(X_test)-1:\r\n        X_test[i+1,look_back-1] = forecasts[i]\r\n        for j in range(look_back-1):\r\n            X_test[i+1,j] = X_test[i,j+1]\r\n```\r\n\r\n결과는 완벽하지는 않지만 적어도 정허하다고 할 수 있습니다:\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_6.png\" /\u003e\r\n\r\n다중 단계 방법은 창 방법과 유사하지만 더 많은 대상 단계를 갖습니다. 다음은 두 개의 전방 단계의 샘플입니다:\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_7.png\" /\u003e\r\n\r\n사실, 이 방법에서 사용자는 n_steps_in과 n_steps_out을 선택해야 합니다. 다음 코드는 단순 시계열을 다중 단계 LSTM 훈련을 위해 준비된 데이터 세트로 변환합니다:\r\n\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n```js\r\n# 단변량 시퀀스를 다단계로 샘플링하기\r\ndef split_sequences(sequences, n_steps_in, n_steps_out):\r\n X, y = list(), list()\r\n for i in range(len(sequences)):\r\n     # 해당 패턴의 끝을 찾음\r\n     end_ix = i + n_steps_in\r\n     out_end_ix = end_ix + n_steps_out\r\n     # 시퀀스를 벗어나는지 확인\r\n     if out_end_ix \u003e len(sequences):\r\n         break\r\n     # 패턴의 입력 및 출력 부분 수집\r\n     seq_x, seq_y = sequences[i:end_ix], sequences[end_ix:out_end_ix]\r\n     X.append(seq_x)\r\n     y.append(seq_y)\r\n return np.array(X), np.array(y)\r\n```\r\n\r\n이제, 특성 뿐만 아니라 타겟도 대각선 반복을 가지고 있어 시계열과 비교하려면 그들을 평균화하거나 예측 중 하나를 선택해야 합니다. 아래 코드에서는 첫 번째, 마지막 및 평균 예측의 결과가 생성되며, 그에 이어 플롯이 제시됩니다. 여기서 첫 번째 예측은 한 달 전 예측을 의미하며, 마지막 예측은 12개월 전 예측을 의미합니다.\r\n\r\n```js\r\nn_steps_in = 12\r\nn_steps_out = 12\r\n\r\nX, y = split_sequences(ts_data, n_steps_in, n_steps_out)\r\nX = X.reshape(X.shape[0], X.shape[1], 1)\r\ny = y.reshape(y.shape[0], y.shape[1], 1)\r\n\r\n# 훈련 및 테스트 세트 분리\r\ntrain_ratio = 0.8\r\ntrain_size = int(train_ratio * len(ts_data))\r\nX_train, X_test = X[:train_size-n_steps_in-n_steps_out+1], X[train_size-n_steps_in-n_steps_out+1:]\r\ny_train = y[:train_size-n_steps_in-n_steps_out+1]\r\ny_test = ts_data[train_size:]\r\n\r\n# LSTM 모델 생성 및 훈련\r\nmodel = Sequential()\r\nmodel.add(LSTM(units=72, activation='tanh', input_shape=(n_steps_in, 1)))\r\nmodel.add(Dense(units=n_steps_out))\r\nmodel.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mape'])\r\n\r\nmodel.fit(x=X_train, y=y_train, epochs=500, batch_size=18, verbose=2)\r\n\r\n# 예측 생성\r\nlstm_predictions = model.predict(X_test)\r\nlstm_fitted = model.predict(X_train)\r\n\r\nforecasts = [np.diag(np.fliplr(lstm_predictions), i).mean() for i in range(0, -lstm_predictions.shape[0], -1)]\r\nfits = [np.diag(np.fliplr(lstm_fitted), i).mean() for i in range(lstm_fitted.shape[1]+n_steps_in - 1, -lstm_fitted.shape[0], -1)]\r\nforecasts1 = lstm_predictions[n_steps_out-1:,0]\r\nfits1 = model.predict(X)[:train_size-n_steps_in,0]\r\nforecasts12 = lstm_predictions[:,n_steps_out-1]\r\nfits12 = lstm_fitted[:,n_steps_out-1]\r\n\r\n# Metric\r\nav_mape = mean_absolute_percentage_error(y_test, forecasts)\r\nav_r2 = r2_score(ts_data[n_steps_in:train_size], fits[n_steps_in:])\r\none_mape = mean_absolute_percentage_error(y_test[:-n_steps_out+1], forecasts1)\r\none_r2 = r2_score(ts_data[n_steps_in:train_size], fits1)\r\ntwelve_mape = mean_absolute_percentage_error(y_test, forecasts12)\r\ntwelve_r2 = r2_score(ts_data[n_steps_in+n_steps_out-1:train_size], fits12)\r\n \r\ndate_range = pd.date_range(start='1990-01-01', end='2023-09-30', freq='M')\r\n\r\n# 실제, 적합 결과 및 예측을 플롯\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[:train_size], fits, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], forecasts, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n. LSTM 12 Month Average Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {av_r2*100:.2f}%\\nMAPE = {av_mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[n_steps_in:train_size], fits1, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:-n_steps_out+1], forecasts1, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n LSTM 1 Month in advance Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {one_r2*100:.2f}%\\nMAPE = {one_mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[n_steps_in+n_steps_out-1:train_size], fits12, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], forecasts12, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n LSTM 12 Months in advance Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {twelve_r2*100:.2f}%\\nMAPE = {twelve_mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n\r\n이슈: 창 메서드와 동일한 문제가 여기에도 있습니다:```\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n\r\n![이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_8.png)\r\n\r\n해상도: 창 법과 비슷한 방법을 사용할 수 있습니다. 그러나 n_steps_out을 test_size와 동일하게 선택할 수도 있습니다. 이렇게 하면 테스트 세트가 하나로 축소됩니다:\r\n\r\n![이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_9.png)\r\n\r\n다음 함수는 이를 정확히 수행합니다. 이 함수는 시계열, 학습 크기 및 샘플 수를 사용합니다. 이 버전은 다른 예측 알고리즘과 비교할 수 있기 때문에 comparable로 이름 지었습니다:\r\n\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n```js\r\ndef split_sequences_comparable(sequences, n_samples, train_size):\r\n # 단계\r\n n_steps_out = len(sequences) - train_size\r\n n_steps_in = train_size - n_steps_out - n_samples + 1\r\n # 끝 세트\r\n X_test = sequences[n_samples + n_steps_out - 1:train_size]\r\n X_forecast = sequences[-n_steps_in:]\r\n X, y = list(), list()\r\n for i in range(n_samples):\r\n     # 이 패턴의 끝을 찾습니다\r\n     end_ix = i + n_steps_in\r\n     out_end_ix = end_ix + n_steps_out\r\n     # 패턴의 입력 및 출력 부분을 수집합니다\r\n     seq_x, seq_y = sequences[i:end_ix], sequences[end_ix:out_end_ix]\r\n     X.append(seq_x)\r\n     y.append(seq_y)\r\n return np.array(X), np.array(y), np.array(X_test), np.array(X_forecast), n_steps_in, n_steps_out\r\n```\r\n\r\n이 함수에서는 단계 수가 이미 고정되었기 때문에 샘플 수와 훈련 크기는 사용자가 선택하도록 하고, 최대 가능한 단계 수를 계산하도록 결정했습니다. 아래는 실행된 코드와 그 결과입니다:\r\n\r\n```js\r\nn_samples = 12\r\ntrain_size = 321\r\nX_train, y_train, X_test, X_forecast, n_steps_in, n_steps_out = split_sequences_comparable(ts_data, n_samples, train_size)\r\ny_test = ts_data[train_size:]\r\n\r\n# Reshaping\r\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\r\nX_test = X_test.reshape(X_test.shape[1], X_test.shape[0], 1)\r\ny_train = y_train.reshape(y_train.shape[0], y_train.shape[1])\r\ny_test = y_test.reshape(y_test.shape[1], y_test.shape[0], 1)\r\n\r\n# LSTM 모델 생성 및 훈련\r\nmodel = Sequential()\r\nmodel.add(LSTM(units=154, activation='tanh', input_shape=(n_steps_in, 1)))\r\nmodel.add(Dense(units=n_steps_out))\r\nmodel.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mape'])\r\n\r\nmodel.fit(x=X_train, y=y_train, epochs=500, batch_size=18, verbose=2)\r\n\r\n# 예측\r\nlstm_predictions = model.predict(X_test)\r\npredictions = lstm_predictions.reshape(lstm_predictions.shape[1])\r\nlstm_fitted = model.predict(X_train)\r\nfits = [np.diag(np.fliplr(lstm_fitted), i).mean() for i in range(lstm_fitted.shape[1]+n_steps_in - 1, -lstm_fitted.shape[0], -1)]\r\n\r\n# 메트릭스\r\nmape = mean_absolute_percentage_error(y_test, predictions)\r\nr2 = r2_score(ts_data[n_steps_in:train_size], fits[n_steps_in:])\r\n\r\n# 실제, 적합 및 예측 플롯\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[:train_size], fits, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], predictions, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n12 Sample Comparable LSTM Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {r2*100:.2f}%\\nMAPE = {mape*100:.2f}%\\', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_10.png\" /\u003e\r\n\r\n\r\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\r\n\r\n지금까지 우리가 얻은 결과는 가장 신뢰할만한 것입니다. 그러나 제가 개발한 혁신적인 방법을 사용하면 더 나은 결과를 얻을 수 있습니다. 이 방법은 나중에 시리즈에서 (순환 방법) 자세히 설명하겠습니다. 먼저 LSTM 네트워크의 하이퍼파라미터를 조정하는 방법에 대해 설명하겠습니다.\r\n\r\nLSTM은 모든 시간 단계를 특성으로 집계하기 때문에 시계열 데이터가 모든 이러한 방법에서 손실됩니다. 나중에 시리즈에서 (인코더/디코더 방법) 시계열 입력의 구조를 유지하는 다른 방법을 사용할 것입니다.\r\n\r\n계속 주목해 주세요!","ogImage":{"url":"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png"},"coverImage":"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png","tag":["Tech"],"readingTime":12},{"title":"기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2","description":"","date":"2024-05-18 19:28","slug":"2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2","content":"\n\n\"“Courage to Learn ML”의 새로운 장을 찾아주신 여러분, 환영합니다. 이 시리즈는 복잡한 주제들을 쉽고 재미있게 다루고, 멘토와 학습자 간의 캐주얼 대화처럼 친밀한 분위기를 제공하기 위해 만들어졌습니다. “용기로 방어하다”의 쓰기 스타일에서 영감을 받아 기계 학습에 특히 집중하고 있어요.\n\n이번 시간에는 사라지는 그래디언트와 폭발하는 그래디언트의 어려움을 극복하는 방법에 대해 계속해서 탐구할 거예요. 첫 번째 세그먼트에서 우리는 네트워크 내에서 효율적인 학습을 보장하기 위해 안정적인 그래디언트 유지가 왜 중요한지에 대해 이야기했어요. 불안정한 그래디언트가 우리 네트워크의 심화를 방해할 수 있고 결국 깊은 \"학습\"의 잠재력을 제한할 수 있다는 것을 밝혀냈죠. 이러한 개념을 살려내기 위해 DNN(맛있고 영양가 있는 얹힌 작은 얼음 공장)이라는 소형 아이스크림 공장을 운영하는 비유를 사용하고 수렴한 팩토리 생산 라인을 조율하는 것과 유사한 DNN 훈련을 위한 강력한 전략을 명료하게 보여줬어요.\n\n이제, 두 번째 이야기에서는 각 제안된 솔루션에 대해 더 심층적으로 탐구하며, 아이스크림 공장을 활기차게 만든 것과 같은 명확성과 창의성으로 그들을 살펴볼 거에요. 여기 이번 부분에서 다룰 주제 목록입니다:\n\n- 활성화 함수\n- 가중치 초기화\n- 배치 정규화\n- 실제 적용(개인 경험)\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 활성화 함수\n\n활성화 함수는 우리 \"공장\" 설정의 핵심입니다. 이 함수들은 우리의 DNN 조립 라인 내에서 전방 및 후방 전파를 통해 정보를 전달하는 역할을 합니다. 적절한 활성화 함수를 선택하는 것은 우리의 DNN 조립 라인 및 이에 따라 우리의 DNN 훈련 과정이 원활하게 작동하는 데 중요합니다. 이 부분은 활성화 함수의 장닿과 단점을 간단히 설명하는 것이 아닙니다. 여기서는 다양한 활성화 함수의 생성 배경을 파악하고 종종 간과되는 중요한 질문에 대답하기 위해 Q\u0026A 형식을 사용할 것입니다.\n\n이러한 함수들을 우리 아이스크림 생산 비유의 블렌더로 생각해보세요. 이용 가능한 블렌더 목록을 제공하는 대신, 각각의 혁신과 특정 개선 사항 뒤에 있는 이유를 심층적으로 검토하고 이해하는 데 도움을 드리겠습니다.\n\n## 활성화 함수란 무엇이며, 어떻게 적절한 함수를 선택할 수 있을까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Activation functions](/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png)\n\n활성화 함수는 신경망 모델에 선형 및 비선형 관계를 모두 포착할 수 있는 유연성과 강력함을 부여하는 주요 요소입니다. 로지스틱 회귀와 DNN의 주요 차이점은 이러한 활성화 함수들과 여러 층을 결합하는 데 있습니다. 이들은 NN이 다양한 함수를 근사할 수 있게 합니다. 그러나 이러한 능력은 도전과제와 함께 제공됩니다. 활성화 함수 선택에는 더 주의를 기울여야 합니다. 잘못된 선택은 모델이 특히 역전파 중에 효과적으로 학습하는 것을 막을 수 있습니다.\n\n당신이 당사 DNN 아이스크림 공장의 매니저로 상상해보세요. 당신은 생산 라인을 위해 적절한 활성화 함수(아이스크림 믹서로 생각해보세요)를 섬세하게 선택하고 싶을 것입니다. 즉, 당신의 요구 사항에 가장 적합한 것을 찾는 데 신중을 기울이고 최적의 선택지를 찾아내야 합니다.\n\n따라서 효과적인 활성화 함수를 선택하는 첫 번째 단계는 두 가지 핵심 질문에 대한 대답을 찾는 것입니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 활성화 함수의 선택이 소멸 그래디언트나 폭발 그래디언트와 같은 문제에 어떤 영향을 미치나요? 어떤 기준이 좋은 활성화 함수를 정의하나요?\n\n은닉층에서 활성화 함수를 선택할 때, 주로 소멸 그래디언트와 관련된 문제가 발생합니다. 이는 전통적인 시그모이드 활성화 함수(가장 전통적이고 기본적인 모델)로 거슬러 올라갈 수 있습니다. 시그모이드 함수는 입력값을 확률 범위(0부터 1)에 매핑할 수 있는 능력으로 널리 사용되었습니다. 이는 이진 분류 작업에서 특히 유용합니다. 이 능력 덕분에 연구자들은 예측을 분류하기 위한 확률 임계값을 조정하여 모델의 유연성과 성능을 향상할 수 있었습니다.\n\n그러나 이를 은닉층에 적용하는 것은 주로 소멸 그래디언트 문제를 야기했습니다. 이는 주로 두 가지 주요 요인으로 설명할 수 있습니다:\n\n- 순방향 전파 과정에서 시그모이드 함수는 입력을 0과 1 사이의 매우 좁은 범위로 압축합니다. 한 네트워크가 은닉층에서 활성화 함수로 시그모이드만 사용하는 경우, 여러 층을 거칠수록 이 범위가 더욱 좁아지게 됩니다. 이 압축 효과로 인해 출력의 변동성이 감소하고 양수 값으로의 편향이 도입됩니다. 입력 부호에 관계없이 출력은 0과 1 사이에 유지되기 때문에.\n- 역전파 과정에서 시그모이드 함수의 도함수(종모양 곡선)는 0과 0.25 사이의 값을 생성합니다. 이 작은 범위는 입력을 가로지르는 그래디언트가 여러 층을 통과함에 따라 급속하게 감소할 수 있도록 할 수 있습니다. 이것은 앞선 층 그래디언트가 연속된층의 도함수의 곱으로 이루어지기 때문인데, 이러한 낮은 도함수의 복합 곱은 점점 더 작은 그래디언트를 결과로 가져와서 초기 층에서의 효과적인 학습을 방해합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 제약 사항을 극복하기 위해 이상적인 활성화 함수는 다음과 같은 특성을 보여야 합니다:\n\n- 비선형성. 네트워크가 복잡한 패턴을 포착할 수 있도록 함.\n- 비포화. 함수와 그 도함수가 입력 범위를 과도하게 압축하지 않아서 gradient 소멸을 방지해야 함.\n- 중심이 0인 출력. 함수는 양수 및 음수 출력 둘 다를 허용해야 하며, 각 노드 사이의 평균 출력이 특정 방향으로의 편향을 도입하지 않도록 해야 함.\n- 계산 효율성. 함수와 그 도함수가 계산적으로 간단하여 효율적인 학습을 용이하게 해야 함.\n\n## 이러한 기본 특성들을 고려할 때, 인기있는 활성화 함수들이 기본 모델인 Sigmoid를 어떻게 개선하고 뛰어나게 만드는지 알아봅시다.\n\n이 섹션은 거의 모든 현재 활성화 함수에 대한 일반적인 개요를 제공하려고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 마크다운 형식으로 변경하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nReLU의 고려 사항 중 하나는 선형 세그먼트 간의 급격한 전환으로 인해 x=0에서 미분 불가능하다는 것입니다. 실제로 PyTorch와 같은 프레임워크는 subgradient 개념을 사용하여 이를 해결하며, 종종 x=0에서 도함수를 0.5 또는 [0, 1] 내의 다른 값으로 설정합니다. 이는 보통 정확한 제로 입력이 드물고 데이터의 변동성 때문에 문제가 되지 않습니다.\n\n그래서, ReLU가 여러분에게 적합한 선택일까요? 많은 연구자들은 그렇다고 말합니다. 이는 그 간결함, 효율성 및 주요 DNN 프레임워크의 지원 덕분입니다. 게다가 https://arxiv.org/abs/2310.04564 같은 최근 연구들이 ReLU의 계속된 중요성을 강조하며, ML 분야에서의 부활과 같은 시대를 맞이한다고 강조하고 있습니다.\n\nLeaky ReLUs는 클래식적인 ReLU에 약간의 변화를 준겳이며, ReLU를 더 자세히 살펴보면 몇 가지 문제점이 드러납니다. 음수 입력에 대한 제로 출력으로 이어지는 것은 'dying ReLU' 문제로 이어지며, 뉴런들이 훈련 중 업데이트되지 않게 됩니다. 또한, ReLU는 양수 값을 선호하여 모델에 방향성 편향을 도입할 수 있습니다. 이러한 단점을 극복하면서 ReLU의 이점을 유지하기 위해, 여러 연구자들이 'leaky' ReLU와 같은 여러 변형을 개발했습니다.\n\nLeaky ReLU는 ReLU의 음수 부분을 수정하여 작고 0이 아닌 기울기를 부여합니다. 이 조정은 음수 입력이 작은 음수 출력을 생성하도록하며, 효과적으로 그 외의 0 출력 영역을 '누출'시킵니다. 이 누출의 기울기는 하이퍼파라미터 알파(α)에 의해 제어되며, 전형적으로 뉴런을 활성 유지와 희소성 사이의 균형을 유지하기 위해 0에 가깝게 설정됩니다. 작은 음수 출력을 허용함으로써, Leaky ReLU는 활성 함수의 출력을 0 주변으로 중앙 집중시키고 뉴런이 비활성화되지 않게 하여 'dying ReLU' 문제에 대응합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 하이퍼파라미터로 α를 도입하면 모델 튜닝에 대한 복잡성이 추가됩니다. 이를 관리하기 위해 원본 Leaky ReLU의 변형이 개발되었습니다:\n\n- Randomized Leaky ReLU (RReLU): 이 버전은 훈련 중에 α를 지정된 범위 내에서 무작위로 지정하고 평가 중에는 고정합니다. 무작위성은 모델을 정규화하고 과적합을 방지하는 데 도움이 될 수 있습니다.\n- Parametric Leaky ReLU (PReLU): PReLU는 훈련 중에 α를 학습할 수 있도록 하며, 활성화 함수를 데이터셋의 특정 요구에 맞게 조정할 수 있습니다. 이는 α를 훈련 데이터에 맞게 조정하여 모델 성능을 향상시킬 수 있지만, 과적합의 위험도 증가시킵니다.\n\nLeaky ReLU를 개선한 Exponential Linear Unit (ELU). Leaky ReLU와 ELU는 음의 값을 허용하여 평균 유닛 활성화를 제로에 가깝게 밀어내고 활성화 함수의 활력을 유지하는 데 도움이 됩니다. Leaky ReLU의 문제점은 이 음의 값의 범위를 조절할 수 없다는 것입니다. 이론적으로 이 값들은 작게 유지하려는 의도에도 불구하고 음의 무한대로 확장될 수 있습니다. ELU는 이를 해결하기 위해 비선형 지수 곡선을 비정상적인 입력에 통합하여 음의 출력 범위를 최대 -𝛼(일반적으로 1로 설정되는 새로운 하이퍼파라미터)로 좁히고 제어합니다. 또한 ELU는 매끄러운 함수입니다. 그 지수 요소 덕분에 음과 양 값 사이에서 매끄러운 전환을 가능하게 하며, 입력 값에 대한 잘 정의된 기울기를 보장하여 기울기 기반 최적화에 유리합니다. 이 기능은 ReLU와 Leaky ReLU에서 보이는 미분 불가능 문제를 해결합니다.\n\nSelf-Normalizing 속성을 갖춘 향상된 ELU인 Scaled Exponential Linear Unit (SELU). SELU는 신경망 내에서 제로 평균 및 단위 분산을 유지하도록 설계된 ELU의 확장된 버전입니다. 양의 순입력의 기울기가 1을 초과하도록 고정 스케일 요인 λ(1보다 큰 값)을 통합함으로써 SELU는 하위 레이어의 기울기가 줄어드는 상황에서 기울기를 증폭하여 딥 뉴럴 네트워크에서 자주 발생하는 소멸하는 기울기 문제를 예방하는 데 특히 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSELU에 대해, 매개변수(α 및 λ)는 고정된 값이며 학습할 수 없으므로 조정해야 할 매개변수가 적어 튜닝 과정이 간소화됩니다. SELU 구현에서 이러한 특정 값들을 찾을 수 있습니다.\n\nSELU는 실제로 활성화 함수 세계에서 정교한 \"믹서\"인데요, 특정 요구 사항이 딸려옵니다. 단방향 또는 순차 네트워크에서 가장 효과적이며 RNN, LSTM 또는 건너뛰기 연결을 갖는 아키텍처에서는 그 설계 때문에 그런만큼 성능이 좋지 않을 수 있습니다.\n\nSELU의 자기 정규화 기능을 위해서는 입력 피처가 표준화되어야 합니다. 평균이 0이고 표준 편차가 1인 것이 중요합니다. 또한, 매 숨겨진 레이어의 가중치는 LeCun 정규 초기화를 사용하여 초기화되어야 합니다. 여기서 가중치는 평균이 0이고 분산이 1/fan_in인 정규 분포에서 샘플링됩니다. \"fan_in\"이란 용어가 익숙하지 않다면, 가중치 초기화에 대한 전용 세션에서 설명하겠습니다.\n\n요약하면 SELU의 자기 정규화가 효과적으로 기능하려면 입력 피처가 정규화되고 네트워크 구조가 끊기지 않는 것을 보장해야 합니다. 이 일관성은 네트워크 전체에서 자기 정규화 효과가 유지되도록 도와주며 누출 없이 계속 유지되도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nGELU (Gaussian Error Linear Unit)은 Dropout으로부터 규제 아이디어를 통합한 혁신적인 활성화 함수입니다. 기존 ReLU가 음수 입력에 대해 0을 출력하는 반면, leaky ReLU, ELU 및 SELU는 음수 출력을 허용합니다. 이를 통해 활성화의 평균을 0에 가깝게 이동시켜 편향을 줄이는데 도움을 줍니다. 이는 ReLU와 비슷한 방식으로 편향을 줄이지만 음수 입력을 완전히 0으로 만들지 않고 음의 값을 허용한다는 것을 의미합니다. 그러나 이러한 누출은 \"죽어 가는 ReLU\"의 일부 이점을 잃어버릴 수 있음을 의미합니다. 여기서는 일부 뉴런의 비활성으로 더 sparse하고 일반화된 모델을 얻을 수 있습니다.\n\n죽어 가는 ReLU 및 Dropout의 희소성 이점을 고려할 때, GELU는 여기에 한 발 더 나아간 것입니다. GELU는 0 출력의 특성을 가진 죽어 가는 ReLU를 무작위적인 요소와 결합하여 뉴런이 재활성화될 수 있는 가능성을 열어줍니다. 이 접근은 유익한 희소성을 유지하는 것뿐만 아니라 뉴런 활동을 재도입하여 GELU를 견고한 해결책으로 만듭니다. 이 메커니즘을 완전히 이해하기 위해 GELU의 정의를 자세히 살펴보겠습니다:\n\n![이미지](/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_1.png)\n\nGELU 활성화 함수에서 CDF인 Φ(x) 또는 표준 가우스 누적 분포 함수가 중요한 역할을 합니다. 이 함수는 표준 정규 분포를 따를 때 x보다 작거나 같은 값을 갖는 것으로 나타내는 확률을 나타냅니다. Φ(x)는 음수 입력에 대해 0부터 양수 입력에 대해 1로 매끄럽게 전환되어, 입력의 스케일링을 효과적으로 제어합니다. Dan Hendrycks 외(출처)의 논문에 따르면 뉴런 입력은 배치 정규화를 사용할 때 특히 정규 분포를 따르는 경향이 있어 정규 분포의 사용이 정당화됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 함수의 디자인은 x 값이 줄어들수록 입력이 더 자주 \"떨어지도록\" 허용하여 변환을 확률적이면서 입력 값에 의존적으로 만듭니다. 이 메커니즘은 흔히 사용되는 직선 함수인 f(x) = x를 더 부드럽게 만들어 ReLU 함수와 유사한 형태를 유지하며, 조각별 선형 함수에서 발생하는 갑작스러운 변화를 피합니다. GELU의 가장 중요한 특징 중 하나는 뉴런을 완전히 비활성화할 수 있다는 것으로, 이를 통해 입력 값의 변화에 따라 다시 활성화될 수 있습니다. 이러한 확률적 성질은 입력 값에 의존하지만 완전히 무작위적이지 않아 뉴런이 다시 활성화될 기회를 제공합니다.\n\n아래는 GELU가 ReLU보다 두드러지는 이점이라고 요약할 수 있습니다. GELU는 어떤 입력 값이 양수인지 음수인지에 관계없이 전체 입력 값 범위를 고려합니다. Φ(x) 값이 감소함에 따라 GELU 함수의 출력이 0에 가까워지는 확률이 증가하여 뉴런을 부드럽게 \"떨어뜨리게\" 됩니다. 이 방법은 전형적인 드롭아웃 방식보다 더 정교하며, 무작위적으로 하는 것이 아니라 데이터에 따라 뉴런의 비활성화를 결정하도록 되어 있습니다. 이 방식은 매우 매력적으로 느껴지며, 마치 고급 디저트에 부드러운 크림을 추가하여 조금 더 향상된 미각을 경험하는 것과 같다고 생각합니다.\n\nGELU는 GPT-3, BERT 및 다른 Transformers와 같은 모델에서 효율적이며 언어 처리 작업에서 강력한 성능을 보여 인기 있는 활성화 함수가 되었습니다. 확률적 성질 때문에 계산 위주이지만, 표준 가우스 누적 분포인 Φ(x)의 곡선은 시그모이드와 tanh 함수와 유사합니다. 흥미로운 점은 GELU가 tanh를 사용하거나 x(1.702*x) 공식을 사용하여 근사할 수 있다는 것입니다. 이러한 단순화 가능성에도 불구하고, PyTorch의 GELU 구현은 그러한 근사가 종종 불필요할 정도로 빠르게 진행됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 깊이 들어가기 전에 먼저 정리해보자면,\n\n## ReLU를 검토하고 이로부터 영감받은 다른 활성화 함수가 무엇인지를 살펴보면 어떤 활성화 함수가 좋을지 정확히 알아볼까요?\n\nGünter Klambauer 등의 논문에서 SELU가 소개된 적이 있습니다. 여기서는 효과적인 활성화 함수의 중요한 특성을 강조했는데요.\n\n- 범위: 네트워크 전체의 평균 활성화 수준을 조절하는 데 도움이 되기 위해 음수와 양수 값을 출력해야 합니다.\n- 포화 영역: 도함수가 제로에 가까워지는 영역으로, 하위층의 너무 높은 분산을 안정화하는 데 도움을 줍니다.\n- 증폭 슬로프: 하위 층에서 너무 낮은 분산을 높이기 위해 중요한 기울기가 있어야 합니다.\n- 연속성: 연속적인 곡선은 분산의 변화를 안정화하고 증가시키는 효과를 균형있게 유지하는 고정점을 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한 \"이상적인\" 활성화 함수에 대한 두 가지 추가 기준을 제안하고 싶습니다:\n\n- 비선형성: 이것은 명백하고 필수적입니다. 왜냐하면 선형 함수는 복잡한 패턴을 효과적으로 모델링할 수 없기 때문입니다.\n- 동적 출력: 출력이 제로이고 입력 데이터에 따라 출력을 변경할 수 있는 능력은 동적 뉴런 활성화와 비활성화를 가능하게 합니다. 이렇게 하면 네트워크가 변화하는 데이터 조건에 효율적으로 적응할 수 있습니다.\n\n## 활성화 함수가 음수를 출력하는 이유에 대해 더 직관적인 설명을 부탁드려도 될까요?\n\n활성화 함수를 입력 데이터를 변환하는 블렌더로 생각해 보세요. 일부 재료를 선호하는 블렌더처럼, 활성화 함수는 그들의 본질적인 특성에 따라 편향을 도입할 수 있습니다. 예를 들어, 시그모이드 및 ReLU 함수는 일반적으로 입력과 관계없이 비음수 출력만 나타냅니다. 이는 블렌더가 어떤 재료를 넣어도 항상 동일한 맛을 내는 것과 유사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_3.png)\n\n이 편향을 최소화하려면 부정적이고 긍정적인 값을 출력할 수 있는 활성화 함수를 가지는 것이 좋습니다. 기본적으로 우리는 중심이 제로인 출력을 목표로 합니다. 활성화 함수의 출력을 나타내는 놀이터를 상상해보세요. Sigmoid나 ReLU와 같은 함수로는, 이 놀이터는 부정적인 입력을 무시하거나 제로로 바꾸기 때문에 긍정적인 쪽으로 크게 기울어져 있습니다. Leaky ReLU는 음수 입력이 약간 음수 출력을 생성하도록 허용함으로써 이 놀이터를 균형잡게 시도하지만, 부정적 기울기의 선형 및 상수적 성격 때문에 조정이 미미합니다. 반면에 Exponential Linear Unit (ELU)은 지수 구성 요소로 음수 측면에 더 다이나믹한 밀어넣기를 제공하여, 더 균형 잡힌 상태에 가까워질 수 있도록 돕습니다. 이 균형은 긍정적 및 부정적 업데이트가 훈련에 기여하도록 보장함으로써 신경망에서 건강한 그레이디언트 플로우와 효율적인 학습을 유지하는 데 중요합니다, 단방향 업데이트의 제한을 피하기 위해.\n\n## ReLU와 유사하게 양수 입력을 제로화하는 활성화 함수를 생성할 수 있을까요, min(0, x)를 사용하여 양수 입력을 제로화하는 함수를 선호하는 이유는 무엇인가요?\n\n확실히, ReLU의 양수 값을 제로화하고 음수 값을 그대로 통과시키는 버전을 설계할 수 있습니다. 이것은 기술적으로 실행 가능한데, 중요한 점은 여기서 값의 부호가 아니라 네트워크에 비선형성을 도입하는 것입니다. 이 활성화 함수들이 일반적으로 출력 레이어가 아닌 숨겨진 레이어에서 사용된다는 것을 기억하는 것이 중요합니다. 즉, 이 네트워크 내의 이러한 활성화 함수의 존재는 최종 출력의 부호에 영향을 미치지 않고 이 레이어의 특성에 의해 직접적으로 영향을 받지 않더라도 최종 출력이 여전히 양수와 음수 모두가 될 수 있다는 것을 의미합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n무슨 상황에서든, 네트워크의 가중치와 편향은 출력의 필요한 부호에 맞게 조정될 수 있습니다. 예를 들어, 전통적인 ReLU에서 출력이 1이고 다음 레이어의 가중치가 1이면 출력은 여전히 1로 유지됩니다. 마찬가지로, 제안된 ReLU 변형이 -1을 출력하고 가중치가 -1이면 결과는 여전히 1이 됩니다. 본질적으로, 우리는 출력의 부호보다는 크기에 더 신경을 씁니다.\n\n따라서, ReLU가 부정적인 쪽에서 포화되는 것은 양수 쪽에서 포화되는 것과 근본적으로 다르지 않습니다. 그러나 우리가 영 중심 활성화 함수를 중요시하는 이유는 양수 또는 음수 값에 대한 내재적인 선호도를 방지하여 모델에서 불필요한 편향을 피하기 위한 것입니다. 이 균형은 네트워크 전체에 걸쳐 중립성과 효과적인 학습을 유지하는 데 도움이 됩니다.\n\n## Leaky ReLU와 같은 함수들은 출력을 영 중심 주변에 유지하기 위해 음수값을 출력할 필요가 있습니다. 그렇다면 ELU, SELU, GELU는 왜 음수 입력에 포화되도록 특별히 설계되었을까요?\n\n이를 이해하기 위해, ReLU 뒤에 있는 생물학적 영감을 살펴볼 수 있습니다. ReLU는 생물학적 뉴런을 모방하는데, 이들은 한계값을 가지고 있습니다. 이 한계값을 초과하는 입력은 뉴런을 활성화시키고, 그 이하는 그렇지 않습니다. 활성 및 비활성 상태 간 전환 가능성은 신경 기능에서 중요합니다. ELU, SELU, GELU와 같은 변형을 고려할 때, 이들의 설계가 두 가지 다른 필요에 부합함을 알 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 긍정적 영역: 임계값을 초과하는 신호가 전달될 때 전달되는 원하는 신호를 전송하는 것을 의미합니다.\n- 부정적 영역: 원치 않는 신호를 최소화하거나 걸러내며 대형 부정적 값의 영향을 완화하여 누수하는 게이트처럼 작동합니다.\n\n이러한 기능은 입력에 대한 게이트 역할을 하며, 뉴런의 출력에 영향을 미쳐야 하는 사항과 그렇지 말아야 하는 사항을 관리합니다. 예를 들어, SELU는 다음 두 가지 측면을 구분하여 활용합니다:\n\n- 긍정적 영역: 스케일링 인자 λ (1보다 큼)는 신호를 전달하지 않을 뿐만 아니라 약간 증폭시킵니다. 역전파 중 이 영역의 도함수는 일정하게 유지됩니다 (약 1.0507), 작지만 유용한 기울기를 증가하여 사그라들기 기울기를 희석시키기 위해 사용됩니다.\n- 부정적 영역: 도함수는 0과 λα 사이의 값 사이를 이동합니다 (일반적인 값은 λ ≈ 1.0507 그리고 α ≈ 1.6733), 약 1.7583에 달하는 최대 도함수를 이끌어 냅니다. 여기서 함수는 거의 0에 가깝게 접근하며, 지나치게 큰 기울기를 줄여 폭발 문제를 해결하기 위해 돕습니다.\n\n이 설계는 이러한 활성화 함수들이 유용한 신호를 증가시키면서 잠재적으로 유해한 극단을 억제해 안정적인 학습 환경을 제공할 수 있도록 균형을 맞춘다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n활성화 함수가 게이트로 작용하는 개념은 새로운 아이디어가 아닙니다. 시그모이드 함수가 무엇을 기억하거나 업데이트하거나 잊어버릴지를 결정하는 LSTM과 같은 구조에서 강력한 전례가 있습니다. 이 게이팅 개념은 ReLU의 변형이 특정한 방식으로 설계된 이유를 이해하는 데 도움이 됩니다. 예를 들어 GELU는 표준 정규 분포의 누적 분포 함수(CDF)에서 유도된 스케일 계수를 사용하는 동적 게이트 역할을 합니다. 이 스케일링을 통해 입력의 작은 부분이 0에 가까울 때 통과되도록 하고, 더 큰 양수 값은 대부분 변경되지 않고 통과할 수 있게 합니다. 입력이 다음 레이어에 얼마나 많은 영향을 미치는지 제어함으로써, GELU는 정보 흐름의 효과적인 관리를 용이하게 해주며, 특히 transformer와 같은 구조에서 유용합니다.\n\n언급된 ELU, SELU, 그리고 GELU 모두 음수 측면을 부드럽게 만듭니다. 음수 입력의 부드러운 포화는 큰 음수 값의 영향을 완화하는 것뿐만 아니라, 네트워크가 입력 데이터의 변동에 덜 민감해지도록 만듭니다. 이를 통해 더 안정적인 특징 표현이 이뤄지게 됩니다.\n\n요약하면, 양수인지 음수인지에 상관없이 포화 영역이 구체적으로 중요하지 않습니다. 왜냐하면 이러한 활성화 함수들은 네트워크의 중간 레이어에서 작동하며, 여기서 가중치와 편향이 적절하게 조정될 수 있습니다. 하지만, 한쪽이 신호를 변경하지 않고 전달하거나 심지어 증폭할 수 있도록 허용하는 이러한 함수의 설계가 중요합니다. 이러한 배치는 신호를 조직화하고 효과적인 역전파를 용이하게 도와 전체 네트워크의 성능과 학습 안정성을 향상시킵니다.\n\n## 언제 각 활성화 함수를 선택해야 할까요? 왜 ReLU가 여전히 실무에서 가장 인기 있는 활성화 함수인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n올바른 활성화 함수를 선택하는 데는 계산 리소스, 네트워크 아키텍처의 특정 요구 사항 및 이전 모델로부터의 경험적 증거 등 여러 요소가 관련됩니다.\n\n- 계산 리소스: 충분한 계산 리소스가 있다면 교차 검증을 사용하여 다양한 활성화 함수를 실험해 보는 것이 유익할 수 있습니다. 이를 통해 모델과 데이터셋에 특화된 활성화 함수를 만들 수 있습니다. SELU를 사용할 때 배치 정규화가 필요 없는 경우가 대부분이며, 이는 다른 함수들과 달리 배치 정규화가 필요하지 않아 아키텍처를 간단하게 만들어 줍니다.\n- 경험적 증거: 특정 응용 프로그램에는 특정 함수가 표준으로 사용될 수 있습니다. 예를 들어, 트랜스포머 모델을 훈련시키기 위해 GELU를 선호하는 경우가 많은데, 이는 해당 아키텍처에서 효과적이기 때문입니다. SELU는 자기 정규화 특성과 조절해야 할 하이퍼파라미터가 없다는 장점으로, 훈련 안정성이 핵심인 깊은 네트워크에 특히 유용합니다.\n- 계산 효율성과 간결성: 계산 효율성과 간결성이 중요한 경우, ReLU 및 PReLU, ELU와 같은 변형들이 우수한 선택지입니다. 이들은 매개변수 조정의 필요성을 피하고 모델의 희소성 및 일반화를 지원하여 과적합을 줄이는 데 도움을 줍니다.\n\n더 정교한 함수가 등장했지만, ReLU는 여전히 간결하고 효율적이어서 매우 인기가 있습니다. 구현이 간단하고 이해하기 쉬우며 계산을 복잡하게 하지 않고 비선형성을 소개하는 명확한 방법을 제공합니다. 음수 부분을 제로 처리하는 함수의 능력으로 계산을 단순화하고 계산 속도를 향상시키므로, 특히 대규모 네트워크에서 매우 유리합니다.\n\nReLU의 설계는 음수 활성화를 제로처리하여 모델의 희소성을 기본적으로 증가시키며, 이는 일반화를 개선할 수 있습니다 — 훈련 중심의 과적합이 심각한 문제인 딥 뉴럴 네트워크에서 매우 중요한 요소입니다. 게다가 ReLU는 추가적인 하이퍼파라미터가 필요 없으며, PReLU나 ELU와 같은 함수와 달리 모델 훈련에 추가 복잡성을 도입하지 않습니다. 또한 ReLU가 널리 채택된 상태이므로, 많은 머신러닝 프레임워크와 라이브러리가 이를 위해 특화된 최적화를 제공하여, 많은 개발자에게 실용적인 선택이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약하자면, 새로운 활성화 함수는 특정 시나리오에 특정 이점을 제공하지만, ReLU의 간단함, 효율성, 효과적인 측면의 균형은 많은 응용 프로그램에서 선호하는 선택지가 되고 있습니다. 어떤 활성화 함수를 선택한다 하더라도, 그 특성을 철저히 이해하는 것이 중요하며 모델의 요구 사항과 일치하고 모델 훈련 중 문제 해결을 용이하게 하는 데 필수적입니다.\n\n# 가중치 초기화\n\n그래, 우리는 기욁할 기울기를 안정화시킬 완벽한 활성화 함수를 찾으려는 것을 그만두고, 가중치를 효율적으로 초기화하여 우리의 신경망을 올바르게 설정하는 다른 중요한 측면에 초점을 맞출 시간입니다.\n\n가중치 초기화에 대한 가장 인기 있는 방법들에 대해 자세히 살펴보기 전에, 기본적인 질문을 하나 다루어 보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가중치 초기화는 왜 중요하며 불안정한 그래디언트를 완화하는 데 어떻게 도움이 될까요?\n\n적절한 가중치 초기화는 모델 전체를 따라 정확하게 그래디언트가 흐를 수 있도록 보장합니다. 이는 아이스크림 공장에서 반제품이 전달되는 방식과 유사합니다. 초기 기계 설정이 올바른 것만 중요한 것이 아니라 각 부서가 효율적으로 작동하는 것도 중요합니다.\n\n가중치 초기화는 네트워크를 통해 전진 및 역방향으로 정보가 안정적으로 흐를 수 있도록 목표를 합니다. 너무 크거나 너무 작은 가중치는 문제를 일으킬 수 있습니다. 지나치게 큰 가중치는 전진 패스 중 출력을 지나치게 증가시켜 예측을 과대추정하게 할 수 있습니다. 반면 아주 작은 가중치는 출력을 지나치게 줄일 수 있습니다. 이러한 가중치의 크기는 역전파 중에 중요해집니다. 가중치가 너무 크면 그래디언트가 폭발할 수 있고, 너무 작으면 그래디언트가 사라질 수 있습니다. 이를 이해하여 우리는 출력 및 그래디언트를 무효화하는 영옵션 (zero)과 지나치게 높은 값과 같은 극단적인 초기화를 피합니다. 이 균형 잡힌 접근법은 네트워크의 효과성을 유지하고 불안정한 그래디언트와 관련된 문제를 방지하는 데 도움이 됩니다.\n\n## 가중치를 초기화하는 좋은 방법은 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장 중요한 것은 최적 가중치 초기화는 이미 학습된 가중치를 사용하는 것이 가장 좋습니다. 이미 일부 학습을 거친 가중치를 얻을 수 있다면 손실을 최소화하는 방향으로 진행 중인 이 가중치를 계속 사용하는 것이 이상적입니다.\n\n그러나 처음부터 시작하는 경우 가중치를 초기화하는 방법을 신중하게 고려해야 합니다, 특히 불안정한 기울기를 방지하기 위해. 좋은 가중치 초기화에는 다음을 목표로 하는 것이 중요합니다:\n\n- 극단적인 값은 피해야 합니다. 이전에 논의했던 대로, 가중치는 너무 크거나 작지 않고 0도 아니어야 합니다. 적절히 조절된 가중치는 네트워크 훈련의 전진 및 역진행 중 안정성을 유지하는 데 도움이 됩니다.\n- 대칭을 깨야 합니다. 가중치가 다양한 행동을 하도록 하는 것은 매우 중요합니다. 이렇게 하면 뉴런이 서로 거울에 비친 행동을 하지 않고 동일한 특성만 학습하게 되는 것을 방지합니다. 이러한 차별이 없으면 네트워크가 복잡한 패턴을 모델링하는 능력이 심각하게 제한될 수 있습니다. 각각의 다른 초기 가중치가 각 뉴런이 데이터의 다른 측면을 학습하기 시작하도록 도와줍니다. 이는 아이스크림 공장의 다양한 종류의 생산 라인을 가지고 다양한 맛을 생산할 수 있는 범위를 확대하는 것과 비슷합니다.\n- 손실 표면에서 유리한 위치에 가중치를 배치해야 합니다. 초기 가중치는 모델이 글로벌 최솟값으로 향하는 여정을 더 쉽게 만들기 위해 손실 표면에서 양호한 시작 위치에 모델을 위치시켜야 합니다. 손실 랜드스케이프가 어떻게 보이는지 명확한 그림을 가지고 있지 않기 때문에 가중치 초기화에 약간의 무작위성을 도입하는 것이 유익할 수 있습니다.\n\n모든 가중치를 0으로 설정하는 것이 문제가 되는 이유입니다. 이는 모든 뉴런이 동일하게 행동하고 동일한 속도로 학습하기 때문에 대칭 문제를 발생시킵니다. 다양한 패턴을 효과적으로 포착하지 못하게되는 네트워크의 능력을 제한합니다. ReLU 및 그 변형과 함께 0 가중치는 출력이 0이 되어 학습이 멈추고 모든 뉴런이 비활성화되는 결과를 초래합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 모든 가중치를 작은 무작위 숫자로 초기화해야 하지 않을까요?\n\n가중치를 초기화할 때 작은 무작위 숫자를 사용하는 것은 도움이 될 수 있지만, 종종 충분한 제어가 없을 수 있습니다. 무작위로 할당된 가중치는 너무 작을 수 있어서 기욹기 소멸 문제로 이어질 수 있습니다. 이는 훈련 중 업데이트가 무의미하게 작아져 학습 과정이 정체될 수 있습니다. 또한, 완전히 무작위 초기화는 대칭을 깨는 것을 보장하지 않습니다. 예를 들어, 초기화된 값이 너무 유사하거나 모두 같은 부호를 가지는 경우, 뉴런들도 여전히 너무 유사하게 작동하여 데이터의 다양한 측면을 배우지 못할 수 있습니다.\n\n실무에서는 초기화에 대해 더 구조화된 방법을 사용합니다. 유명한 방법에는 Glorot (또는 Xavier) 초기화, He (또는 Kaiming) 초기화, LeCun 초기화 등이 있습니다. 이러한 기술은 일반적으로 정규 분포나 균일 분포를 기반으로 하지만, 이전 및 다음 레이어의 크기를 고려하여 균형을 제공하는 것으로 조절됩니다. 이는 기울기 소실 또는 폭발의 위험이 없이 효과적인 학습을 촉진합니다.\n\n## 그렇다면, 가중치 초기화에 표준 정규 분포(N(0,1))를 사용하지 않는 이유는 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적인 정규 분포(N(0,1))를 사용하면 무작위화 과정을 어느 정도 제어할 수 있지만, 분산을 효과적으로 제어할 수 없어 최적 가중치 초기화에는 부족합니다. 제로 평균은 가중치가 모두 동일한 부호를 공유하지 않도록 보장하여 대칭을 깨는 데 효과적입니다. 그러나 분산이 1인 것은 문제가 될 수 있습니다.\n\n활성화 함수 입력 𝑍이 가중치에 의존하는 시나리오를 고려해 봅시다. 이전 레이어의 𝑁개 뉴런의 출력을 합산하여 계산된다고 가정해보면, 각각의 가중치는 표준 정규 분포에서 초기화됩니다. 여기서 𝑍도 평균이 0인 정규 분포를 따르지만, 분산은 𝑁이 됩니다. 예를 들어 𝑁=100인 경우, 𝑍의 분산은 100이 되어 너무 크기 때문에 활성화 함수로 입력이 불안정하게 전달되어 역전파 과정에서 그래디언트가 불안정해질 수 있습니다. 아이스크림 공장을 비유하면, 각 기계의 설정에서 오차 허용을 높게 설정하는 것은 품질 관리 부재로 인해 원하는 결과와 크게 벗어나는 최종 제품을 만드는 것과 같습니다.\n\n그렇다면 왜 𝑍의 분산에 신경을 쓸까요? 분산은 𝑍 값의 퍼짐을 제어합니다. 분산이 너무 작으면 𝑍의 출력이 충분히 다양하지 않아 대칭을 깨는 데 효과적이지 못할 수 있습니다. 그러나 너무 큰 분산은 값이 너무 높거나 낮아질 수 있습니다. 시그모이드와 같은 활성화 함수의 경우, 극단적으로 높거나 낮은 입력값은 함수의 포화 극으로 출력을 밀어 넣어 그래디언트 소실 문제를 야기할 수 있습니다.\n\n따라서, 분포에서 무작위로 가중치를 초기화할 때 평균과 분산 둘 다 중요합니다. 효과적으로 대칭을 깨기 위해 평균을 0으로 설정하고, 동시에 분산을 최소화하여 중간 제품(즉, 뉴런 출력)이 너무 크거나 작지 않도록 해야 합니다. 올바른 초기화는 네트워크를 통과하는 정보의 안정된 흐름을 보장하고, 전방 및 역방향으로 효율적인 학습 과정을 유지하며, 그래디언트에 불안전성을 도입하지 않습니다. 신중한 초기화 접근은 효과적이고 견고하게 학습하는 네트워크로 이어질 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 그래서, 신경망의 중간 층에서 출력 값을 제어하기 위해 연속된 층에도 입력으로 사용되는 가중치 초기화에 대해 신중히 선택한 평균과 분산을 사용합니다. 그렇다면, 가장 인기 있는 방법들이 어떻게 이 분산을 제어할 수 있는 걸까요?\n\n가중치를 초기화하는 가장 흔한 방법들을 살펴보기 전에, 𝑍Z의 분산은 가중치 초기화의 분산뿐만 아니라 𝑍Z를 계산하는 데 참여하는 뉴런의 수도 영향을 받는다는 점이 중요합니다. 만약 16개의 뉴런만 사용된다면, 𝑍Z의 분산은 16이 되고, 100개의 뉴런이 사용된다면 100이 됩니다. 이 변동은 가중치가 뽑히는 분포만이 아니라 계산에 기여하는 뉴런의 수, 즉 \"팬-인\"이라고도 불리는 요소에 의해 영향을 받습니다. \"팬-인\"은 뉴런으로 들어오는 입력 연결의 수를 의미하며, 비슷하게 \"팬-아웃\"은 뉴런이 가지는 출력 연결의 수를 나타냅니다.\n\n예시를 통해 설명해드리겠습니다: 신경망의 중간 층에 200개의 뉴런이 있고, 이전 층의 100개 뉴런 및 다음 층의 300개 뉴런과 연결되어 있다고 가정해봅시다. 이 경우, 이 층의 팬-인은 100이고, 팬-아웃은 300입니다.\n\n팬-인과 팬-아웃을 이용하면 가중치 초기화 중 분산을 제어할 수 있는 메커니즘을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 팬-인은 전방 전파 중 현재 레이어의 출력 𝑍의 분산을 조절하는 데 도움을 줍니다.\n- 팬-아웃은 역전파 중 후속 레이어의 가중치가 얼마나 영향을 미치는지 조정합니다.\n\n현재 레이어로 전방 및 역방향에서 공급되는 뉴런의 수를 고려하여, 연구자들은 다양한 초기화 방법들을 아이디어 위에 구축해냈습니다. Lecun, Xavier/Glorot 초기화 및 He/Kaiming 초기화가 이러한 방법들 중 일부입니다. 이러한 방법들의 아이디어는 꽤 유사합니다. 가중치를 생성할 때 균일 분포 또는 정규 분포 중 하나를 사용하고, 분산을 조절하기 위해 팬-인 또는 팬-아웃을 사용합니다. 이 분포들의 평균은 모두 0으로 설정하여 출력 값의 평균을 0으로 만듭니다.\n\n```js\n# 초기화의 다양한 유형\n\n| 초기화          | 활성화 함수             | σ² (정규)  |\n| -------------- | ----------------------------- | --------------- |\n| Xavier/Glorot  | None, tanh, logistic, softmax | 1 / 팬_평균 |\n| He/Kaiming     | ReLU 및 변형                  | 2 / 팬-인    |\n| LeCun          | SELU                          | 1 / 팬-인    |\n```\n\nLecun 초기화는 가중치 분포에 작은 분산을 사용하여 𝑍의 분산을 축소하는 것에 기반합니다. 𝑍의 분산이 팬-인과 각 가중치의 분산의 곱이라면, 𝑍가 분산이 1이 되도록 보장하려면 각 가중치의 분산은 1/팬-인이어야 합니다. 따라서 Lecun 초기화는 가중치를 𝑁(0,1/팬-인)에서 무작위로 선택합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자비에/글로뤼 초기화는 이전 레이어의 가중치(fan-in)의 영향을 고려할 뿐만 아니라 역전파 중 이러한 가중치가 후속 레이어에 미치는 영향(fan-out)도 고려합니다. 순방향 및 역방향 전파 중 분산을 균형있게 유지하기 위해 분산에 대한 공식인 2/(fan_in + fan_out)을 사용하여 가중치를 그려놓을 수 있습니다. 이 때의 분산은 Normal 분포, N(0,2/(fan_in + fan_out)) 또는 Uniform 분포(- sqrt(6/ (fan_in + fan_out)), sqrt(6/ (fan_in + fan_out))) 중에서 선택할 수 있습니다.\n\n희/카이밍 초기화는 ReLU 및 그 변형에 특히 맞추어져 있습니다. ReLU는 음수 입력을 제로로 처리하므로 뉴런 활성화의 절반은 0이 아닌 것으로 예상되며, 이는 분산을 줄이고 그라디언트 소멸을 유발할 수 있습니다. 이에 대비하여 희 초기화는 Lecun 방법에서 사용된 분산을 두 배로 늘리는데, 이를 통해 ReLU를 사용하는 레이어에 필요한 균형을 유지합니다. Leaky ReLU 및 ELU의 경우 약간의 조정이 필요하지만(예: ELU의 경우 2 대신 1.55 배 사용), 원칙은 그라디언트를 안정화하기 위해 분산을 조정하고자 한다는 것입니다. 반면 SELU의 경우 자체 정규화 속성을 활용하기 위해 모든 숨겨진 레이어에 Lecun 초기화를 사용해야 합니다.\n\n이 토론은 PyTorch와 같은 프레임워크에서 가중치 초기화가 어떻게 구현되는지에 대한 흥미로운 측면을 엽니다. 이는 다음과 같은 질문으로 제시될 수 있습니다 —\n\n## PyTorch에서 가중치 초기화는 어떻게 구현되고, 그것이 특별한 이유는 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이토치에서는 선형 레이어의 가중치 초기화에 대한 기본 접근 방식이 르쿤 초기화 방법을 기반으로 합니다. 반면 케라스에서는 기본 초기화 기술로 제비어/글로럿 초기화가 사용됩니다.\n\n그러나 파이토치는 가중치 초기화에 대해 매우 유연한 접근 방식을 제공합니다. 사용자는 모델에서 사용된 다양한 활성화 함수의 특정 요구 사항과 일치하도록 프로세스를 세밀하게 조정할 수 있습니다. 이 세밀한 조정은 두 가지 주요 구성 요소를 고려하여 달성됩니다:\n\n- 모드: 이 구성 요소는 레이어의 입력 연결 수(fan-in) 또는 출력 연결 수(fan-out)에 따라 초기화된 가중치의 분산이 조정되는지를 결정합니다.\n- 게인: 이는 모델에서 사용된 활성화 함수에 따라 초기화된 가중치의 스케일을 조정하는 스케일링 계수입니다. 파이토치는 가중치 초기화 프로세스를 최적화하기 위해 맞춤형 게인 값을 계산하는 torch.nn.init.calculate_gain 함수를 제공합니다.\n\n가중치 초기화 매개변수를 사용자 정의하는 이 유연성을 통해 모델에서 사용된 특정 활성화 함수와 비교 가능하고 호환되는 초기화 접근 방식을 설정할 수 있습니다. 흥미로운 점은 파이토치의 가중치 초기화 구현이 서로 다른 초기화 방법 간의 어떤 관계를 나타낼 수 있는데, 이를 통해 신경망의 전반적인 기능을 향상시키기 위한 초기화 프로세스를 활용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, SELU 활성화 함수에 대한 PyTorch 문서를 검토하면 가중치 초기화의 흥미로운 측면을 발견할 수 있습니다. 문서에는 SELU 활성화와 함께 kaiming_normal 또는 kaiming_normal_을 사용하여 초기화할 때, nonlinearity=`selu` 대신 nonlinearity=`linear`을 선택해야 자가 정규화를 달성할 수 있다고 언급되어 있습니다. 이 세부 사항은 흥미로운데, PyTorch의 기본 Lecun 초기화가 Kaiming 방법을 선형 비선형성에서 gain이 1로 설정했을 때 Lecun 초기화 방법을 효과적으로 복제한다는 점을 강조합니다. 이는 Lecun 초기화가 보다 일반적인 Kaiming 초기화 접근법의 특정 응용이라는 것을 보여줍니다. 마찬가지로, Xavier 초기화 방법은 입력 연결의 수(fan-in)와 출력 연결의 수(fan-out)를 모두 고려하는 Lecun 초기화의 다른 변형으로 볼 수 있습니다.\n\n## 가중치를 분포로부터 초기화할 때 평균과 분산을 신중하게 선택해야 하는 점에 동의합니다. 그러나 왜 초기 가중치를 정규 분포 대신 균일 분포에서 추출하려고 하는지에 대한 이유는 여전히 명확하지 않습니다. 무엇 때문에 한 가지를 다른 것보다 선호하게 되는지 설명해주실 수 있나요?\n\n가중치를 초기화할 때 분포로부터 추출할 때 평균과 분산을 신중하게 선택하는 중요성에 대한 귀하의 주장은 타당합니다. 신경망에서 가중치를 초기화할 때 중요한 고려 사항 중 하나는 정규 분포나 균일 분포 중에서 추출할지 결정하는 것입니다. 명확한 연구 결과를 지지하는 답변이 없지만, 이러한 선택을 하는 이유에는 몇 가지 타당한 이유가 있습니다:\n\n균일 분포는 엔트로피가 가장 높은 분포로, 범위 내의 모든 값이 동등하게 가능성이 있습니다. 이 공정한 접근은 초기화에 어떤 값이 더 잘 작동할지에 대한 사전 지식이 부족할 때 유용할 수 있습니다. 각 잠정적인 가중치 값에 공정하게 대우하고 균일한 확률을 할당합니다. 이는 한정된 정보로 게임에서 모든 팀에 공평하게 건 게임과 비슷합니다 - 선호되는 결과의 가능성을 최대화합니다. 어떤 구체적인 값이 좋은 초기 가중치인지 알 수 없기 때문에 균일 분포를 사용하면 편향되지 않은 시작점을 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한편, 정규 분포는 일반적으로 가중치를 0에 가까운 작은 값으로 초기화하는 것이 더 자주 일어납니다. 초기 가중치가 작을수록 출력의 분산이 줄어들고 학습 중 안정적인 기울기를 유지하는 데 도움이 되기 때문에 작은 초기 가중치가 일반적으로 선호됩니다. 이는 가중치 초기화 방법에서 단위 분산 대신 작은 분산을 선호하는 이유와 유사합니다. 게다가, 시그모이드나 하이퍼볼릭 탄젠트와 같은 특정 활성화 함수는 작은 초기 가중치 값에서 더 나은 성능을 발휘하며 이러한 활성화 함수가 숨겨진 레이어가 아닌 최종 출력 레이어에서만 사용되더라도 그렇습니다.\n\n근본적으로, 균일 분포는 사전 지식이 부족한 상황에서 공평한 시작점을 제공하여 모든 잠재적인 가중치 값들을 동등하게 가능성 있는 것으로 간주합니다. 반면 정규 분포는 0에 가까운 작은 초기 가중치를 선호하여 기울기 안정성을 돕고 시그모이드나 하이퍼볼릭 탄젠트와 같은 특정 활성화 함수와 잘 맞습니다. 이러한 분포 사이의 선택은 종종 다른 신경 아키텍처와 작업에 걸쳐 경험적인 결과에 따라 이루어집니다. 보편적으로 최적의 방법은 존재하지 않지만, 균일 및 정규 분포의 특성을 이해하면 더 많이 발견되고 문제에 특화된 초기화 결정을 할 수 있게 됩니다.\n\n## 우리는 편향 항에 대해서도 이러한 가중치 초기화 방법을 사용합니까? 편향 항을 어떻게 초기화합니까?\n\n좋은 질문입니다. 우리는 편향 항에 대해서는 가중치와 동일한 초기화 기술을 반드시 사용하지는 않습니다. 사실, 편향 값을 모두 간단히 0으로 초기화하는 것이 흔한 실천입니다. 그 이유는 가중치가 각 뉴런이 기본 데이터를 근사하는 함수의 모양을 결정하는 반면, 편향은 각 함수를 위아래로 이동시키는 오프셋 값을 제공하기 때문입니다. 그래서 편향은 가중치가 학습하는 전반적인 형태에 직접적으로 영향을 주지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n초기화의 주요 목표는 대칭을 깨고 가중치 학습에 좋은 시작점을 제공하는 것이므로 편향이 어떻게 초기화되는지에 대해 크게 걱정할 필요가 없습니다. 그들을 모두 0으로 설정하는 것이 일반적으로 충분합니다. 이에 대해 더 자세한 논의는 CS231n 강의 노트에서 찾아볼 수 있습니다.\n\n# 배치 정규화\n\n선택한 활성화 함수와 적절하게 초기화된 가중치로 신경망을 훈련 시작할 수 있습니다 (우리의 미니 아이스크림 공장 생산 라인을 가동시키는 것과 같습니다). 그러나 품질 통제가 필요합니다. 초기에는 물론 훈련 반복 중에도요. 두 가지 주요 기술은 특성 정규화와 배치 정규화입니다.\n\n이전 포스트에서 경사 하강법에 대해 논의한 것처럼, 이러한 기술은 빠른 수렴을 위해 손실 풍경을 재구성합니다. 특성 정규화는 초기 데이터 입력에 이를 적용하며, 배치 정규화는 에폭 사이에 숨겨진 레이어의 입력을 정규화합니다. 두 기술 모두 다른 단계에서 품질 보증 점검을 구현하는 것과 유사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n 배치 정규화는 훈련 중에 각 레이어의 입력을 평균이 0이고 분산이 1인 값으로 정규화하여 내부 공변량 이동을 줄이어 경사 소실/폭발 문제를 완화하는 데 도움을 줍니다. 내부 이동이 발생하는 이유에 대해 생각해 보죠. 각 레이어의 매개변수를 기울기에 기반하여 업데이트하는 과정은 신경망의 각 레이어가 공장의 서로 다른 부서라고 생각할 수 있습니다. 한 부서의 매개변수(또는 설정)를 업데이트할 때마다 다음 부서의 입력이 변경됩니다. 이로 인해 각 레이어마다 새로운 변화에 대한 조정이 필요하며 이를 심층 학습에서 내부 공변량 이동이라고 합니다. 그렇다면 이러한 이동이 자주 발생할 때 어떻게 될까요? 네트워크가 안정화하기 어려워지며 각 레이어의 입력이 계속 변화함에 따라 문제가 발생합니다. 이는 공장의 한 부분에서 지속적인 변화가 제품 품질에 일관성 없이 영향을 미치는 것과 유사합니다. 이는 작업자들을 혼란스럽게 하고 작업 흐름을 망치는 결과를 초래할 수 있습니다.\n\n배치 정규화는 훈련 중 미니 배치 전체에서 각 레이어의 입력을 정규화하여 평균이 0이고 분산이 1인 값으로 설정하는 것을 목표로 합니다. 레이어가 예상할 수 있는 일관된, 통제된 입력 분포를 강요합니다. 공장 비유로 돌아가서, 다음 부서로 전달되기 전 각 부서의 출력에 엄격한 품질 기준을 설정하는 것과 유사합니다. 예를 들어, 베이킹 부서가 일관된 크기와 모양의 아이스크림콘을 생산해야 한다는 규칙을 설정하는 것입니다. 다음 장식 부서는 콘의 변화량을 고려할 필요가 없게 되며, 각 일반화된 콘에 동일한 양의 아이스크림을 추가할 수 있습니다.\n\n정규화를 통해 내부 공변량 이동을 줄이는 것으로 배치 정규화는 훈련 과정 중에 기울기가 엉망이 되는 것을 방지합니다. 레이어들이 신속히 변하는 입력 분포에 계속해서 재조정할 필요가 없어져서 기울기가 더 안정적으로 유지됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한 정규화는 정규화자 역할을 하며 목적 함수 랜드스케이프를 부드럽게 만듭니다. 이를 통해 더 높은 학습 속도를 사용하여 수렴 속도를 높일 수 있습니다. 일반적으로 배치 정규화는 내부 분산 이동을 줄이고 그래디언트를 안정화시키며 목적함수를 정규화하고 훈련 가속화를 가능하게 합니다.\n\n## 배치 정규화를 어떻게 적용해야 하나요? 활성화 함수 이전 또는 이후에 적용해야 하나요? 훈련 및 테스트 중에 어떻게 처리해야 하나요?\n\n배치 정규화는 그래디언트를 안정화시키는 추가 레이어를 통해 DNN을 훈련하는 방식을 실제로 바꿨습니다. DL 영역에서 활성화 함수 이전 또는 이후에 적용해야 하는지에 대한 논쟁이 있습니다. 솔직히 말해서, 이는 모델에 따라 다르며 조금은 실험해 봐야 할 수도 있습니다. 그냥 방법을 일정하게 유지하도록 하고 변경하면 예상치 못한 문제가 발생할 수 있습니다.\n\n훈련 중에 배치 정규화 레이어는 각 미니 배치를 통해 각 차원에 대한 평균과 표준편차를 계산합니다. 이러한 통계량은 출력을 정규화하는 데 사용되어 평균이 0이고 분산이 1임을 보장합니다. 이 프로세스는 입력 분포를 표준 정규 분포로 변환하는 것으로 생각할 수 있습니다. 전체 훈련 데이터 세트를 사용하여 특징 정규화를 하는 것과는 달리 배치 정규화는 각 미니 배치에 기초하여 조정되어 처리되는 데이터에 동적이며 반응성을 가지게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제, 테스트는 다른 이야기입니다. 테스트 데이터에서 평균과 분산을 정규화에 사용하면 안 됩니다. 대신에 이러한 매개변수는 학습된 특징으로 간주되어 훈련 과정에서 유지되어야 합니다. 훈련 중 각 미니 배치는 고유의 평균과 분산을 가지지만, 일반적인 실천 방법은 이러한 값들의 이동 평균을 훈련 단계 동안 사용하는 것입니다. 이를 통해 안정된 추정값을 제공하여 테스트 중에 적용할 수 있게 됩니다. 다른 적은 일반적인 방법은 전체 훈련 데이터 세트를 사용하여 포괄적인 평균과 분산을 계산하는 추가 에포크를 실행하는 방법도 있습니다.\n\nPyTorch로 DNN 프레임워크로 훈련할 때, 조정 가능한 하이퍼파라미터인 γ와 β를 사용할 수 있습니다. 이러한 파라미터를 조정하여 배치 정규화 과정을 세밀하게 조정할 수 있습니다. 일반적으로 기본 설정은 매우 효과적입니다. 그러나 훈련 중에 PyTorch는 분산을 계산하기 위해 편향 추정량을 사용하지만, 테스트 중에 이동 평균을 위해 불편 추정량을 사용합니다. 이러한 조정은 모델이 미처 못 본 조건에서 인구 표준 편차를 더 정확하게 근사하고 모델의 신뢰성을 향상하는 데 도움이 됩니다.\n\n배치 정규화를 올바르게 적용하는 것은 네트워크에서 효율적인 학습에 중요합니다. 네트워크가 잘 학습하는 것뿐만 아니라 다양한 데이터 집합과 테스트 시나리오에서 성능을 유지할 수 있게 합니다. 생산 라인의 각 세그먼트를 정확하게 교정하여 운전을 원활하고 일관되게 유지하는 것으로 생각해보세요.\n\n## 왜 역전파 중에 그래디언트에 직접 배치 정규화를 적용하는 대신 순전파 중에 배치 정규화가 적용되나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적으로 순방향 패스 중 입력 또는 활성화에 배치 정규화를 적용하는 이유가 역전파 중에 기울기 자체에 직접 배치 정규화를 적용하는 것보다 더 일반적입니다.\n\n먼저, 기울기에 배치 정규화를 직접 적용하는 이점을 보여주는 실증적 증거나 실무가 부족합니다. 내부 공변량 이동의 개념은 주로 순방향 패스 중에 발생하며, 계층 입력의 분포가 매개변수 업데이트로 인해 변경됩니다. 따라서, 후속 계층에서 처리되기 전에 이러한 입력을 안정화시키기 위해 이 단계에서 배치 정규화를 적용하는 것이 합리적입니다. 또한, 기울기에 배치 정규화를 직접 적용하는 것은 기울기의 크기와 방향이 나르는 중요한 정보를 왜곡할 수 있습니다. 이는 내재적 의미를 변경하는 방식으로 고객 피드백을 변조하는 것과 유사하며, 이는 미니 아이스크림 공장의 제조 프로세스에 대한 향후 조정을 잘못 이끌 수 있습니다.\n\n그러나, 기울기를 경사 클리핑과 같은 마이너 조정을 하는 것은 일반적으로 허용되며 유익합니다. 이 기법은 기울기를 지나치게 크게 만들지 않고 안전한 범위 내에 유지하여 기울기를 제한하는 도구입니다. 이는 피드백에서 극단적 아웃라이어를 걸러내는 것과 유사하며, 이는 프로세스를 방해할 수 있는 급격한 반응을 방지하면서 전체 피드백의 무결성을 유지하는 데 도움이 됩니다. PyTorch에서는 기울기 노름을 모니터링하는 것이 일반적이며, 기울기가 폭발하기 시작하면 경사 클리핑과 같은 기법을 사용할 수 있습니다. PyTorch는 torch.nn.utils.clip_grad_norm_ 및 torch.nn.utils.clip_grad_value_와 같은 함수를 제공하여 이를 관리할 수 있습니다.\n\n## 직접 정규화 대신 기울기를 클리핑하는 옵션을 언급했습니다. 왜 기울기를 클리핑하는 대신 바닥값을 설정하지 않는지 정확히 선택하는 이유가 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기울기 클리핑은 폭발하는 기울기 문제를 방지하는 데 도움이 되는 간단하면서도 효율적인 기술입니다. 종종 기울기의 최대값을 수동으로 제한합니다. 예를 들어 ReLU 활성화 함수는 상한값을 6으로 설정할 수 있으며, PyTorch에서는 ReLU6로 알려져 있습니다. 이 상한을 설정함으로써, 각 층에서 역전파 과정 중 기울기가 연쇄 법칙에 따라 곱해질 때 값이 지나치게 커지지 않도록 보장합니다. 이러한 클리핑은 기울기가 학습 과정을 방해할 정도로 급격하게 증가하는 것을 방지하여 그 값을 관리 가능한 한도 내에 유지합니다.\n\n한편, 기울기를 억제하는 것은 너무 작아지지 않도록 하기 위해 하한값을 설정하는 것입니다. 그러나 이는 사그라들어 가는 기울기 문제의 근본적인 해결책이 되지는 않습니다. 일부 활성화 함수인 시그모이드나 tanh 같은 경우 입력이 0에서 멀어질수록 기울기 값을 매우 심각하게 축소시키기 때문에 기울기의 사그라들음 문제가 발생합니다. 이는 학습 속도가 극도로 느려지거나 정체되는 매우 작은 기울기 값을 야기합니다. 기울기를 억제해도 해결되지 않는 이유는 문제의 근본이 활성화 함수의 성질에 기인하기 때문입니다. 즉, 단순히 값이 너무 작은데만 있지 않고 활성화 함수가 기울기 값을 압축하는 것에 있습니다. 따라서 사그라드는 기울기 문제를 효과적으로 해결하기 위해서는 네트워크 아키텍처나 활성화 함수 선택을 조정하는 것이 더 유익합니다. 기울기가 사그라들지 않도록 하는 활성화 함수 사용(ReLU같은), ResNet 아키텍처에서 볼 수 있는 스킵 연결 추가, LSTM이나 GRU 같은 RNN에서 게이트 메커니즘을 사용하는 등의 기술을 통해 기울기는 역전파 중 네트워크 전반에 걸쳐 더 건강한 흐름을 보장하여 자연스럽게 사그라드는 것을 방지할 수 있습니다.\n\n요약하면, 기울기 클리핑은 지나치게 큰 기울기를 효과적으로 관리하지만, 하한값을 설정하는 기울기 억제는 지나치게 작은 기울기 문제를 효과적으로 다루지 못합니다. 대신, 사그라드와 관련된 문제를 해결하려면 일반적으로 구조적인 조정이 필요합니다.\n\n#실무에서의 경험(개인 경험)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약할 때, 모든 논의된 방법이 사라지는 그래디언트 문제와 폭주하는 그래디언트 문제를 해결하는 데 유용하다는 것은 명백합니다. 이들은 모두 모델의 학습 과정을 향상시킬 수 있는 실용적인 접근 방법입니다. 이 글을 마무리하며 한 가지 질문으로 마무리하고 싶습니다 -\n\n## 현실은 무엇인가요? 실무에서는 어떤 일반적인 과정이 있나요?\n\n실무에서 좋은 소식은 가능한 모든 해결책을 실험할 필요가 없다는 것입니다. 활성화 함수를 선택할 때, ReLU가 종종 선택되는 것이며 매우 비용 효율적입니다. ReLU는 양의 입력의 크기를 변경하지 않고 전달합니다 (시그모이드나 tanh는 큰 값을 크기와 관계없이 항상 1로 압축합니다) 그리고 계산 및 미분 측면에서 간단합니다. 주요 프레임워크에서 잘 지원되며 dead ReLU 문제를 우려한다면 Leaky ReLU, ELU, SELU, 또는 GELU와 같은 대안을 고려할 수 있지만 일반적으로 시그모이드와 tanh를 피해야 하는 사라지는 그래디언트 문제를 피하기 위해 명확을 지켜야 합니다.\n\n선호되는 활성화 함수인 ReLU로 인해 가중치 초기화가 지나치게 민감하게 작용하는 문제에 대해 덜 걱정해도 됩니다. 시그모이드, tanh 및 SELU와 같은 함수에서 주로 발생하는 문제일 뿐입니다. 대신, 선택한 활성화 함수에 권장되는 가중치 초기화 방법에 집중하는 것이 적당합니다 (예를 들어, ReLU에 대해 He/Kaiming 초기화를 사용하는 이유는 ReLU의 비선형성을 고려하기 때문입니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네트워크에는 항상 배치 정규화를 포함하세요. 활성화 함수 전 또는 후에 적용할지 결정(또는 실험)하고, 모델 전체에서 일관되게 그 선택을 유지하세요. 배치 정규화는 규제 효과와 높은 학습률 사용이 가능해지는 등 여러 가지 이점을 제공합니다. 이는 교육 및 수렴 속도를 높일 수 있습니다.\n\n그래서 어떤 것을 실험해볼 가치가 있을까요? 옵티마이저는 탐구할 가치가 있습니다. 이전 글에서 그라디언트 디센트 및 그 인기 있는 변형 등 다양한 옵티마이저를 논의했습니다. Adam은 빠르지만 과적합을 유발하고 학습률을 너무 빨리 감소시킬 수 있습니다. SGD는 신뢰성이 있고 병렬 컴퓨팅 환경에서 특히 효과적일 수 있습니다. 느릴 수 있지만 모델로부터 최대 성능을 뽑아내려면 확실한 선택입니다. 때로는 RMSprop이 더 나은 대안일 수 있습니다. 저는 Adam으로 시작하여 속도를 이유로 한 후에 더 나은 최소값을 찾고 과적합을 방지하기 위해 후기 에포크에서 SGD로 전환하는 것이 좋은 전략으로 생각합니다.\n\n만약 이 시리즈를 즐기고 계시다면, 상호작용(박수, 댓글 및 팔로우)이 지지뿐만 아니라 시리즈를 이어가는 원동력이자 저의 계속된 공유를 영감받는 기반이 됩니다.\n\n이 시리즈의 다른 게시물:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- ML 학습의 용기: L1 및 L2 정규화 해독하기 (파트 1)\n- ML 학습의 용기: 우도, MLE 및 MAP 해독하기\n- ML 학습의 용기: F1, 재현율, 정밀도 및 ROC 곡선에 대한 심층 탐구\n- ML 학습의 용기: 가장 일반적인 손실 함수에 대한 상세 가이드\n- ML 학습의 용기: 경사 하강법과 인기 있는 옵티마이저에 대한 심층 탐구\n- ML 학습의 용기: 수학적 이론부터 코딩 실무까지 백프로파게이션 설명\n\n## 참고 자료\n\n활성화 함수\n\n- [가우시안 에러 선형 유닛 (GeLU) 설명](https://ml-explained.com/blog/activation-functions-explained#gaussian-error-linear-unit-gelu)\n- [ReLU 활성화 함수](https://www.mldawn.com/relu-activation-function/)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가중치 초기화\n\n- [normal glorot initialization(일반 글로럿 초기화)의 원천](https://datascience.stackexchange.com/questions/102036/where-does-the-normal-glorot-initialization-come-from)\n- [파이토치(PyTorch)에서의 기본 초기화에 대한 명확한 이해](https://discuss.pytorch.org/t/clarity-on-default-initialization-in-pytorch/84696/2)\n\n그래디언트 클리핑\n\n- [파이토치(PyTorch)에서 그래디언트 클리핑 하는 방법](https://stackoverflow.com/questions/54716377/how-to-do-gradient-clipping-in-pytorch)","ogImage":{"url":"/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png"},"coverImage":"/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png","tag":["Tech"],"readingTime":30},{"title":"고객 이탈 예측","description":"","date":"2024-05-18 19:26","slug":"2024-05-18-CUSTOMERCHURNPREDICTION","content":"\n\n이것은 이진 분류 문제이며, 은행 데이터 세트를 사용했습니다. 고객이 은행을 떠날 때에 대한 정보가 포함되어 있으며, 이를 사용하여 미래에 은행을 떠날 가능성이 있는 고객을 예측해야 합니다.\n\n![이미지](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png)\n\n우리는 인공 신경망을 구축할 것입니다. 이러한 문제에 접근하는 단계는 다음과 같습니다 —\n  \n- 특정 라이브러리 가져오기\n- 데이터 세트 로드, 데이터 세트에 대한 가능한 정보 찾기(예: 데이터 세트에 결측값이 있는지, 중복된 값의 존재 여부)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_1.png\" /\u003e\n\n- 고객이 나간 수를 확인하기 위해 동일한 것을 나타내는 이 코드를 사용했습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_2.png\" /\u003e\n\n- 이제 데이터 세트를 분석하고 ('RowNumber', 'CustomerId', 'Surname')와 같은 열이 예측에 큰 영향을 미치지 않으므로 삭제할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![데이터1](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_3.png)\n\n- 추가로, ONE HOT ENCODING을 사용하여 범주형 값들을 변환하겠습니다. get_dummies() 및 (drop_first=True)를 사용하면 지리와 성별에서 다른 하나를 삭제할 수 있습니다(예: 프랑스 및 여성).\n\n![데이터2](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_4.png)\n\n- 모델을 훈련 및 테스트 데이터셋으로 분할합니다.\n- 이제 값들을 스케일링할 것입니다. 'balance'와 'estimated_salary'의 값이 매우 크기 때문에 발생하는 문제를 방지하기 위해 StandardScaler()를 사용합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_5.png\" /\u003e\n\n- 케라스 라이브러리를 사용하여 순차적 모델에 대한 'model' 객체를 만듭니다.\n- 그런 다음 레이어(은닉, 출력)를 추가합니다.\n- 시그모이드 활성화 함수를 사용하고, 입력이 11(탈퇴 제외)인 3개 노드를 갖는 밀집 은닉 레이어를 추가합니다.\n- 출력 레이어를 추가합니다.\n- summary를 확인하면 매개변수(가중치 + 편향)를 제공합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_6.png\" /\u003e\n\n- 이제 모델을 컴파일해야 합니다. 어떤 손실 함수, 옵티마이저를 사용할 것인지 지정해야 합니다. 바이너리 분류 문제이므로 사용되는 손실 함수는 크로스 엔트로피/로그 손실입니다. 다양한 옵티마이저(경사 하강법, 확률적 경사 하강법, RMSprop 등)를 사용할 수 있지만 아담(적응 모멘트 추정)이 잘 작동합니다.\n- 모델을 적합하고 10회 반복(에포크)하며 'history'라는 딕셔너리에 저장합니다. Validation_split은 모델을 훈련하는 지점을 처리하는데 사용됩니다. 예를 들어 8000개의 항목이있는 경우 이를 나누고 2000개의 항목을 제거하며 실행 중에 2000개의 포인트를 동시에 확인하고 정확성을 알려줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Customer Churn Prediction 7](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_7.png)\n\n- 이제 배열 안에 가중치(weights)와 편향(biases)을 얻을 수 있습니다.\n\n![Customer Churn Prediction 8](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_8.png)\n\n- 이제 예측이 나오게 됩니다. 시그모이드 함수를 사용하기 때문에 출력은 (0-1)의 범위에 있을 것입니다, 확률입니다. 우리는 이 확률을 0 또는 1로 변환해야 합니다, 그러기 위해 임계값을 정해야 합니다 (예를 들면 0.5, 만약 확률이 0.5보다 작으면 고객이 은행을 떠나지 않고, 확률이 0.5보다 크면 그들은 은행을 떠날 것입니다.) 임계값은 일반적으로 도표를 통해 결정되지만, 여기서는 추측하고, 0.5로 설정되어 있습니다.\n- 그러면 모델의 정확도 점수를 찾을 준비가 됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_9.png\" /\u003e\n\n- 또한 matplotlib을 사용하여 그래프를 그릴 수 있습니다.\n\n## 참고 — 정확도를 높이기 위해 다음을 증가시킬 수 있습니다:\n\n- epoch의 수를 증가시킴.\n- 은닉층의 활성화 함수를 relu로 설정.\n- 은닉층의 노드 수를 증가시킴.\n- 또는 은닉층의 수를 증가시킴(과적합이 발생할 수 있으므로 적당히).","ogImage":{"url":"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png"},"coverImage":"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png","tag":["Tech"],"readingTime":3},{"title":"휴머노이드는 여기에 머물러 있을까요","description":"","date":"2024-05-18 19:24","slug":"2024-05-18-AretheHumanoidsHeretoStay","content":"\n\n매주 이런 식으로 새로운 업데이트를 내놓는 인간형 회사들을 볼 수 없네요. 옵티머스가 걸을 수 있어요? 디지트가 빈 토트백을 옮겼다구요? 피거도 그렇게 하는군요! 드디어 실제 회사들도 흥미를 느끼기 시작한 것 같아요. 테슬라부터 시작해서 아마존과 BMW에서도 이제는 \"작동 중\"이랍니다. 마치 집과 정원에서 우리에게 한 발짝 떨어진 것 같아요.\n\n하지만 정말로 일하고 있는 걸까요? 보여지는 데모들은 보스턴 다이내믹스의 아틀라스가 파크our을 하는 것만큼 흥미로운 것이 아니라 humanoids가 생산적인 것 같지도 않아요. 그래서 시장이 정말로 흥분한 것일까요? Humanoids가 무언가를 준비하고 있는 걸까요? 저는 두 가지 이유로 humanoids에 흥분해요:\n\n1) 인간형 로봇은 마침내 \"브라운필드\" 문제를 해결할 수도 있어요. 이것이 로봇 솔루션들이 실험 단계에 머무는 주된 이유이기도 하거든요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2) 2023년에 기계 학습은 큰 발전을 이루었습니다. 컴퓨터들이 이번에 처음으로 노력의 스킬을 발휘하여 오픈 월드 환경에서 작동하고 접촉 시키는 것이 가능해졌습니다.\n\n# Greenfield vs. Brownfield\n\n로봇 공학은 아직 큰 산업이 아니며 대부분의 산업은 “Greenfield” 배치로만 성공을 거둡니다. 기존 공정을 개조하는 대신, 공장과 그 제품을 로봇 솔루션 주위에 설계합니다. 이것이 ABB, Fanuc 및 Kuka와 같은 기업들이 수익을 올리는 방식이며 자동차 산업을 위한 생산 라인과 같은 전문 솔루션을 구축합니다. 아마존도 이와 같은 원리로 Kiva 자동화 시스템과 함께 작동하는 건물 구축을 하고 있습니다. 반면, 기존 공정과 통합되는 솔루션 (기존 토지 또는 \"갈색\" 영역에)은 종종 생산적으로 성공하지 못하고 버려지는 경우가 많습니다.\n\n아래 이미지는 이러한 딜레마를 설명합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![2024-05-18-AretheHumanoidsHeretoStay_1.png](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_1.png)\n\n작지만 성공한 커피 사업을 상상해보세요. 이 사업은 역사적으로 분리된 분쇄기, 커피 포트 및 열판을 사용하여 커피를 만들어 왔습니다. 여기에 \"협력 로봇\"이라는 자동화된 과정이 도입됩니다. 이런 로봇은 커피 포트를 열판 위에 놓는 등 일부 작업만 수행할 수 있고, 추가적인 장비들을 필요로 합니다. 이런 해결책은 기존 과정을 준비된 자동화 솔루션으로 교체하는 것이 실제로 쉽고 저렴하게 가능합니다. 에스프레소 메이커만 사면 끝이죠. 수동으로 만든 커피에 집착하는 사람들처럼, 산업 환경에서의 공정은 종종 다른 공정과 깊게 연결되어있어 하류 공정을 변경해야 할 수도 있습니다.\n\n(계속)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 매우 기본적인 작업들 다음에는 조립 작업장을 위한 키트를 생성하고 배포하고, 슈퍼마켓 선반이 깔끔하고 적절히 구비되어 있는지 확인하거나 식기 세척기, 커피 메이커 및 진공 청소기와 같은 가정용 가전제품을 작동하는 등 보다 복잡한 작업을 빠르게 수행하게 될 것입니다.\n\n하지만 또 다른 이점도 있습니다: 전력에 연결되었거나 무선으로 충전 중이라면, 인간형 로봇은 휴식 없이 세 번의 교대 근무를 할 수 있으며, 학습한 모든 것은 즉시 동종 로봇들 모두에게 전달될 수 있습니다. 더욱 좋은 점은, 일단 인간형 로봇이 프로세스에 통합되면, 알고리즘을 통해 작업자들로부터 과도한 정직을 요구하는 Lean 및 Six-Sigma의 모든 기술을 완전히 디지털 방식으로 구현할 수 있게 되어 엄청난 생산성 향상을 이끌어낼 수도 있습니다.\n\n![이미지](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_2.png)\n\n투자자, 기업가 및 과학자들을 흥분하게 만드는 것은 이런 전망이며, 비록 게임이 오래 소요될 지라도요. 그럼에도 불구하고, 2023년에 역사책에 기록된 또 다른 Durchbruch 덕분에 아마도 많은 사람들이 모두 출자하지 않을까 합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 기계 학습이 이끄는 전례 없는 능력\n\n2023년은 ChatGPT의 해였습니다. ChatGPT의 명백한 이점 외에, 트랜스포머 신경망 구조는 텍스트에 국한되지 않고 훨씬 더 강력해졌다는 것이 밝혀졌습니다. 그것은 이미지와 언어를 결합하는 능력으로 인해 기계 학습이 미리 정의된 클래스로의 지도 학습을 벗어나게 하였고, 로봇이 이전에 본 적이없는 물체를 다루도록 허용하였습니다. 예를 들어, \"나사\"라는 물체를 이미지에서 제로샷 방식으로 찾을 수 있는 Owl-VIT [1] 비전-언어 모델이 있습니다. \"나사\"가 무엇이며 어떻게 생겼는지에 대해 명시적으로 학습되지 않고도 가능합니다.\n\n![이미지](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_3.png)\n\n라벨링 및 물체 탐지가 완벽하지는 않지만, 비전 임베딩은 원격 조작된 데모와 결합하여 확산을 사용하여 시각 운동 표현을 학습할 수 있도록 허용합니다[2]. 마치 DallE나 Midjourney에서 이미지를 생성할 때 사용되는 방식과 유사합니다. 로봇은 텍스트를 프롬프트로 변환하는 대신, 센서 관측치를 궤적으로 변환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인간을 훈련시킬 때와 달리 현장에 배치된 로봇이 생산한 경험은 쉽게 다른 로봇으로 전달될 수 있습니다. 여기서 심지어 소수의 인간형 프로토타입만으로도 다양한 제조 및 가정 업무에 대한 전문 지식을 통한 무료롭 처리 양을 만들어낼 수 있습니다. 트랜스포머 모델이 자연스럽게 멀티모달이기 때문에 시각과 텍스트/음성 설명만 적용하는 것이 아니라 촉각적 정보, 소리 또는 진동을 받아들이고, 시맨틱한 구조화 정보와 연결하는 데 도움이 될 것입니다.\n\n대형 언어 모델은 또한 인간 언어와 컴퓨터 코드 사이를 매끄럽게 오가며 소프트웨어 습득 및 인간 피드백을 기반으로 코드를 적절하게 수정할 수도 있을 것입니다. 최근 이 논문[3]과 이 비디오에서 보여준 것처럼, 로봇의 가능성에 대한 \"API\"를 제공받음으로써 ChatGPT는 합리적인 코드를 생성하고 인간 피드백에 따라 조정할 수 있습니다. 인간 지침서, 책 지식 또는 이 두 가지의 조합에서 위와 같은 예시인 전문적인 로봇 임무를 빠르게 학습할 수 있는 능력을 가진 LLM을 인터랙션 훈련을 통해 미세조정함으로써 더 향상시킬 수 있을 것입니다.\n\n# 다음은 무엇일까요?\n\n그래서 우리는 대규모로 인간형 로봇을 배치할 준비가 되어 있고, 곧 더 매력적인 사용 사례들을 보게 되겠죠? 많은 기업들이 하드웨어 중심 접근 방식을 선택하여 동적 보행과 기본 조작이 가능하다는 것을 입증했습니다. 아직은 이 로봇들이 많은 것을 실제로 하거나 더 많은 가치를 창출하지는 못하고 있습니다. 고가치 임무인 자율 키팅, 조립 또는 선반 보충과 같은 임무는 이미 어느 정도 시간이 경과했으며 이전 창업 시절에도 가능했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 비디오에 나오는 산업용 하드웨어와 현재 볼 수 있는 휴머노이드 사이에 중요한 차이가 있습니다. 처음부터 로봇을 만드는 것은 심각한 시스템 공학적 도전이 따르며 현재의 프로토 타입은 안정적인 기지에 장착된 협력 로봇의 0.1mm 정확도에서 현재는 상당히 멀리 떨어져 있을 것으로 보입니다. 관성과 진동을 제어하는 어려운 작업은 물론 토크 감지를 사용하여 이를 가능케하지만 대부분의 휴머노이드는 아직 이 기능이 없는 액추에이터에 의존하지만 저렴한 비용 접근 방식을 택하여 엔지니어링 아츠의 아름다운 로봇이 뻣뻣한 산업 시스템과 유사하다고 할 수 있을 정도의 선택을 했습니다.\n\n따라서 다리가 없는 휴머노이드는?\n\n누구나 로봇이 바로 다리가 필요할 것이라고 믿지 않습니다. 이러한 기업은 고가치의 조작 작업, 훈련 용이성 및 매끄러운 배치에 중점을 둡니다. 이 분야의 초기 사례 중 하나는 Rodney Brook의 \"배터\" (안식을 바라며) 로봇이며 나중에는 그의 한 팔로 된 후속자인 소이어가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBaxter가 슈퍼 저렴한 비용(`$25k에 이중 팔로봇)을 정밀성과 강성으로 바꾸는 지나치게 야 amb 계약의 하드웨어 디자인을 겪던 동안, Sawyer는 보다 전통적인 로봇 드라이브를 사용하여 최소한의 조립물과 기본적인 프로그래밍만으로도 다양한 응용 분야에서 성능을 발휘할 수 있습니다. Sawyer는 아직 몇몇 국가에서 판매 중이지만, 모든 “Cobots”이 겪는 브라운필드 문제에 시달립니다: 작업이 자동화 솔루션이 정당화할만큼 반복적인 경우, 이미 해당 솔루션이 만들어졌으며 상당히 더 나은, 빠르고 저렴할 가능성이 높습니다.\n\n“정체된 상반신” 방식의 또 다른 예는 Giant AI인데, 이는 2023년에 공개되고 (사업을 종료한 채) 잠잠하게 알려진 비디오 시리즈로 나타났습니다:\n\nBaxter와 마찬가지로, Giant의 Universal Worker는 기본 조작에 중점을 둔 정적 솔루션이었습니다. Baxter와 같이, Giant는 모든 하드웨어를 처음부터 개발했으며 힘줄 기반 접근법을 구현하여 (잠재적인) 비용 절감을 굉장한 개발 관리부담과 정확성으로 교환했으며, 제 시간에 진정한 고객 가치를 제공하지 못했습니다.\n\nGiant의 일부 지적재산권은 Sanctuary.ai에서 살아 있으며, 여기서도 상체 민첩성에 중점을 두지만, 유압 구동 재래를 복원함으로써, 로봇이 정밀한 조작부터 무거운 들기까지 다양한 작업 범위에 대처할 수 있도록 해줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 인간 모양은 맞지만 걷지는 않아요?\n\n로봇을 특정 장소에 제한하는 것은 이전에 좋은 생각이 아니었습니다. 왜냐하면 브라운필드 문제를 해결하지 못했기 때문입니다. 동일한 장소에서 상당한 시간을 보내는 로봇은 보다 효율적으로 자동화할 수 있는 작업에 종사하는 것일 가능성이 높습니다. 또한 이동성은 배치의 다양성만을 고려하는 것이 아니라, 로봇이 더 넓은 작업 공간에 대응하고 도구와 부품을 스스로 가져올 수 있게 해줍니다. 그렇다고 해서 즉시 다리가 필요한 건 아닐까요?\n\n회사들은 이 가설을 테스트하기 위해 인간형 상반신과 저렴하고 견고한 구동 장치를 결합해봅니다. 예를 들어, 1X 로보틱스(1X robotics)…\n\n…영상에서 보여지는 것 이상의 작업을 수행하려면 소프트웨어 업데이트 이상이 필요할 것입니다)과 바닥에서 물건을 줍는 능력을 결합한 상반신의 민첩성과 인간의 발자국만 조금 더 큰 바퀴 플랫폼을 함께 사용합니다. 산업용 공동 로봇의 성능을 얻는 것은 여전히 매우 어려울 것이며, 작은 바퀴 기반으로 인해 로봇이 운반할 수 있는 하중이 제한될 것입니다. 이러한 로봇은 따라서 인간과 로봇의 흥미로운 상호 작용을 창출하는 데 굉장히 뛰어난 '페퍼'처럼 많이 능력있지는 않지만, 다리가 달린 플랫폼의 이동성이나 협업 로봇의 일군 능력만큼은 갖춘 것이 아닙니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작은 휠베이스는 동적 안정성을 제한하는 기회를 줄입니다. 이는 Boston Dynamics의 - 극도로 익살스러운 - 핸들 로봇들에서 나타납니다. 이 로봇들은 카운터 웨이트를 움직여 세그웨이와 같은 드라이브 체인에서 균형을 맞춰 다양한 하중 조건에 적응할 수 있습니다.\n\n아마도 주위에 있는 사람들이 이 두 친구 가까이 다가가지 못한 것을 눈치챘을 겁니다. 실제로, 어떠한 형태의 동적 활동도 일반적으로 안전하지 않습니다. 이것이 신뢰할 만한 동적 보행을 시연하는 것이 결핵되는 연결고리이자 많은 데모의 중심 주제인 이유입니다.\n\n# 인간형 로봇 경주에서 우승하기\n\n하지만 이 파도가 줄어들지 않으려면, 인간형 로봇은 가능한 빨리 생산 환경으로 이동해야 합니다. 이는 동시에 어느 정도의 소프트웨어와 하드웨어 혼합을 제공해야만 가능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 기존 설치물, 도구, 및 장치를 쉽게 활용할 수 있는 인간 근로자의 형태 요인,\n- 개방형 세계에 대한 쉬운 범용화와 훈련 가능성을 갖춘 인간 근로자의 기능성,\n- 그리고 최소한의 조작 기술 세트,\n\n몇 가지 특정 사용 사례에 대한 브라운필드 문제를 해결하는 데 충분합니다. 언제나 새로운 하드웨어를 개발하는 것은 일반적으로 좋지 않은 생각입니다. 학습과 교육을 더욱 쉽게 만드는 것이 아니라 어렵게 하는 경우가 많습니다. 인간형 로봇이 고객 가치를 창출하고, 책지식과 시각-촉각적 경험을 결합한 다중 모드 기반 모델을 위한 데이터 기초를 먼저 제공할수록 좋습니다.\n\n# 참고 문헌\n\n[1] Minderer, M., Gritsenko, A., Stone, A., Neumann, M., Weissenborn, D., Dosovitskiy, A., Mahendran, A., Arnab, A., Dehghani, M. and Shen, Z., Simple open-vocabulary object detection with vision transformers. arXiv 2022. arXiv preprint arXiv:2205.06230.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[2] Chi, C., Feng, S., Du, Y., Xu, Z., Cousineau, E., Burchfiel, B. and Song, S., 2023. Diffusion policy: Visuomotor policy learning via action diffusion. arXiv preprint arXiv:2303.04137.\n\n[3] Liang J, Xia F, Yu W, Zeng A, Arenas MG, Attarian M, Bauza M, Bennice M, Bewley A, Dostmohamed A, Fu CK. Learning to Learn Faster from Human Feedback with Language Model Predictive Control. arXiv preprint arXiv:2402.11450. 2024 Feb 18.","ogImage":{"url":"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png"},"coverImage":"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png","tag":["Tech"],"readingTime":7},{"title":"필수 인공지능","description":"","date":"2024-05-18 19:21","slug":"2024-05-18-EssentialAI","content":"\n\n르네상스 시대에는 1480년경 레오나르도 다 빈치가 헬리콥터에 대한 창의적인 개념을 그린 것으로 알려져 있지만, 그 꿈을 상용화되고 신뢰할 수 있는 제품으로 만드는 데에는 별도의 혁명인 산업혁명이 필요했습니다. 마찬가지로, 생성 적 인공지능이 우리 사무실에 딸린 로봇이 딸기를 수확하고 있는 매력적인 오일 페인팅을 선사했지만, 농업 산업에 수익성 있고 신뢰할 수 있는 수확 로봇을 제공하기 위해서는 인공지능에 대해 근본적으로 다른 접근 방식이 필요하다고 믿고 있습니다.\n\n![이미지](/assets/img/2024-05-18-EssentialAI_0.png)\n\n인공지능 르네상스가 도래했습니다\n\n우리 모두가 경험하는 것처럼, 인공지능 르네상스가 왔습니다. “Attention Is All You Need”이라는 위대한 논문이 트랜스포머 모델의 붐을 일으키기 시작했지만, 최초의 대중적인 붐은 ChatGPT 3와 4로 시작되었으며, 그 뒤에는 생성 적 인공지능의 대규모 확장이 이어졌습니다. 이번 주에는 OpenAI의 GPT-4o와 Google Gemini이 실시간 언어 번역, 코드 분석 및 다양한 흥미로운 \"AI 어시스턴트\" 응용 프로그램을 포함한 경이로운 실시간 시연을 선보였습니다. 인간형 로봇도 뜨거운 관심을 받고 있습니다 - 투자자들이 지난 12개월 동안 인공지능 주도의 인간형 로봇에 수십억 달러를 투자했습니다. RT-2 및 RT-X와 같은 프로젝트는 인간형 로봇을 위한 폭넓은 텍스트 - 행동 및 제로샷 학습 응용 프로그램을 꿈꾸고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토르투가에서는 AI 르네상스를 신뢰합니다: 우리는 AI 로봇을 사용하여 과일을 따거나 다른 중요한 농업 서비스를 제공합니다. 또한, 현재의 AI 붐은 실제 현실 자동화의 거대한 경제적 결과로 이끄는 것은 아니라고 믿습니다. 우리가 AI 산업 혁명으로 전환할 때에 이뤄질 것이라고 생각합니다. 다 빈치의 르네상스는 \"공중 나사\"와 같은 혁신과 학습의 폭발을 가져왔지만, 이러한 인상적인 논문상 아이디어들이 실제로 수익 창출 규모에서 이륙할 수 있었던 것은 산업 혁명이 일어날 때였습니다.\n\nAI 르네상스의 문제\n\n대부분의 주요 AI 프로젝트는 “인공 일반 지능”에 대해 구축하고 있습니다. 르네상스처럼, 그들은 다 빈치와 같은 모델을 만들고 있습니다. 그들은 예술가, 건축가, 의사 또는 엔지니어의 역할을 수행할 수 있습니다. 그리고, 그들은 “초심주의” 방법을 사용하여 구축하고 있습니다 — 큰 모델, 큰 훈련 인프라, 큰 팀 및 큰 돈이라는 것을 의미합니다. 이는 대규모 언어 모델(LLMs)과 Foundation 모델에도 적용됩니다. 이들의 훈련 비용은 수천만 달러에서 수억 달러로 증가하고 있으며, 인간형 로봇에서도 마찬가지입니다. 비싼 \"모든 것의 로봇\"을 목표로 삼아서 같은 변압기 기반 강화 학습 방식을 백업하고 있습니다.\n\n최근 OpenAI의 Sam Altman이 말한 것처럼,\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"매년 5억 달러, 50억 달러 또는 500억 달러를 태울지라도 상관없어요. 정말로 상관하지 않아요. 사람들에게 정말 능력있는 도구를 제공하고 이를 활용해 미래를 만들어가도록 하는 것이 정말 좋은 일이라고 생각해요. 여러분과 세계의 모든 다른 사람들의 창의력에 베팅하고 싶어요. 이 문제에 대해 어떻게 대처할지 찾아내기 위해.\n\n막강한 접근법은 AGI를 구축하는 데 맞을 수 있지만, Altman이 가치를 창출될 것으로 가정하는 곳에서, 우리는 많은 노력을 본다는 것을 알아요. 인상적인 프로토타입에서 경제적으로 실현 가능한 제품까지 혁신하는 데는 엄청난 노력이 필요해요. AI 레온아르도 다빈치가 상상한 헬리콥터의 아이디어를 생성한 후, 실제 헬리콥터를 어떻게 만들어야 할까요? 누가 7만 대를 제작하고 판매하며 유지할 것인가요? Tortuga에서는 첫 번째 프로토타입 로봇부터 150대의 저렴하고 특수화된 로봇으로 구성된 상업용 농장 규모의 플릿을 구축했어요. 수백만 개의 딸기를 수확했고, 굉장히 효과적이면서도 저렴한 로봇과 AI/ML 스택을 통해 그렇게 했어요.\n\n우리의 첫 번째 신념은 더 열린, 종합적인 방식으로 혁신하는 것이 가치가 있다는 것이지만, 산업 경제의 기반이 되는 일들을 해결하려고 할 때, 빅 AI는 깊고 구체적이며 반복 가능한 물리적 작업을 해결하려 할 때 덜 효과적이라는 것입니다.\n\n전문화: 르네상스는 산업 혁명이 필요합니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nChatGPT4의 다양한 테스트 결과는 정말 인상적입니다. 마찬가지로 Waymo는 피닉스와 샌프란시스코에서 운영 중입니다. AI 로봇들은 오늘날 현실 세계에서 운전할 수 있습니다. 하지만 3D 물리 세계의 작업은 순수 텍스트나 2차원 도로 시스템의 작업에 비해 자동화하기가 훨씬 더 복잡한 것으로 입증되었습니다. 메타의 주요 AI 과학자인 Yann LeCun은 이 복잡성 차이를 언급했습니다. 현실 세계가 쓰인 세계보다 훨씬 더 복잡하고 \"심층적\"이라고 말했습니다.\n\n토르투가의 맥락에서, 만약 최대주의 AI 휴머노이드인 AI 레오나르도가 ChatGPT4처럼 딸기를 고르는 데 90%의 점수를 얻을 수 있다 해도 충분하지 않습니다. 토륄투가 로봇이 10%의 실수를 하면, 우리는 고객의 수익의 10%를 파괴하고 자동화의 가치에 반대하게 됩니다. 인간은 완벽하지 않습니다. 그래서 우리의 기준은 100%가 아닌 대략 97% 정확도입니다. 그러나 97%는 단순히 \"90%보다 7점 높은 것\"이 아닙니다. 물리적 세계에서는 한 차원 이상 더 어려운 문제입니다. 산업 프로세스에서는 우리 사회의 기초를 이루는 일과 작업들이 매주 수백만 번 실행되어야 하며, 매우 높은 정밀도(95% 이상)로 실행되어야 합니다. 그 이유는 비용, 이윤 및 효율성이 깊게 중요하기 때문입니다.\n\n르네상스 방식의 대규모 AI는 광범위한 기반 모델 기반 접근법을 사용하고 극도로 견고한 데이터셋, 시뮬레이션 환경, 합성 데이터 생성 및 대규모 교육 파이프라인을 사용하여 엣지 케이스와 성능 개선을 위해 큰 비용의 투자주기를 갖습니다. 그러나 거의 모든 로봇 환경에서 특히 농장에서는 매우 미묘하고 동적인 엣지 케이스가 많이 존재합니다. 농장에서는 과일과 식물/농업 구조, 해충, 과일 종류, 그리고 온도, 습도, 햇빛 세기, 바람, 비와 같은 환경 조건과의 상호 작용이 크게 다르고 변하기 때문입니다. 물리학적 모델은 개별 과일이 바람에 흔들리거나 로봇에 닿거나 하나씩 딸릴 때의 상호 작용과 같은 필요한 복잡성을 충분히 전달하지 못하기 때문에 시뮬레이션의 효과는 제한됩니다. 특히 유기적 시스템에 대한 합성 데이터는 우리에게 가장 기본적인 사용 사례를 넘어서는 것이 너무 단순해서 우리에게 혜택을 주지 못합니다. 서로 다른 과일에 대한 견고한 실제 세계 데이터셋은 없고, 현존하는 공개 노력은 우리의 특정 센서, 로봇 구조 또는 인지 방식에 적용되지 않는 \"최소 공통 분모\" 데이터셋입니다. 로봇 공학에서 일반화 학습 접근 방식을 추구하려는 많은 학문적 노력이 있지만, 이러한 도전에 아직까지 좋은 답을 찾지 못했습니다. 이 도전 과제의 섹션에서 다루었던 것처럼요.\n\n이제 두 번째 믿음으로 넘어가봅시다. 인공지능 르네상스는 모든 가능성과 창의성에 대한 것입니다. 그러나 인공지능 산업 혁명은 자원과 전문화에 대해 새롭게 고찰해야 합니다. 저렴하고 확장 가능한 인공지능을 만들기 위한 더 나은 방법은 해결하려는 문제에 대해 더 깊이 파고들어 근본적인 구성 요소들로 줄이고, 그 핵심 문제만 심층적이고 전문화된 방식으로 해결하는 것입니다. 우리는 그것을 꼭 필요한 인공 지능(Essential AI)이라고 부르는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n필수 인공지능: 인공지능 산업혁명을 위한 원칙 세트\n\n필수 인공지능은 세 가지 원칙에 기반을 두고 있습니다:\n\n- 전문화 및 동적입니다. 우리는 동적이지만 구체적인 방법을 사용하여 여러 독립 추론 시스템을 연결하여 특정 지능 로봇 에이전트인 '특정 인공지능'을 만듭니다. 이들 디버들된 모델은 모두 매우 높은 F1 점수를 가지고 있고, 우리의 방식은 각각의 모델에서 정밀도와 재현율 사이의 미묘한 균형을 맞추는 것을 가능하게 합니다. 모델 체인의 정확도에 대한 곱셈 효과에도 불구하고, 움직임 계획 및 생물 환경과의 상호작용만 고려할 때도 전체 품질 값이 97%를 초과합니다. 모델 체이닝을 통해 환각과 블랙박스 효과를 피하고, 각 모델의 재학습 목표가 명확합니다. 보상 학습을 넘어서, 우리의 로봇은 또한 라이브 성능에 대한 피드백을 받아 품질과 성능을 최적화하기 위해 실행할 모델을 결정합니다. 이것은 실제 분야에서 결과를 강화하는 적응적 행동입니다.\n- 자습 및 유연합니다. 우리는 우리의 MLOps 접근 방식에서 빅 에이에이의 최고를 채용하여 특정 모델의 이상치를 자동으로 식별하고 효율적이고 특정한 라벨링 파이프라인을 사용하여 빠르게 다시 훈련시킵니다. 우리는 견고하고 전문화된 Tortuga 데이터를 수집하며, 개발 프로세스에서 가장 효과적인 곳에 시뮬레이션 및 합성 데이터를 적용하며, 실제 세계를 충분히 반영하지 못하는 경우에는 중지합니다. 이는 표준 격리된 특이 케이스뿐만 아니라 새로운 식물 품종 및 새로운 농장 환경과 같은 완전히 새로운 맥락에도 적용되며, 우리 모델의 내장된 이해를 업데이트합니다. 우리는 모든 이를 파트너와 무관한 특정 도구로 수행합니다.\n- 효율적입니다. 특수 모델 체인 방식과 특정하고 동적인 MLOps 도구를 사용하여 우리는 지원 임원의 연봉보다 적은 비용으로 지상 실리콘의 모든 참변 사실 주석을 지원하고, 단지 3명의 엔지니어 지원 스텝으로 모든 모델에 대한 이터레이션을 24시간 이내에 완료할 수 있습니다. 우리는 영원히 변화하는 월계도 툴의 일괄 실행형 생태계를 조합하는 대신, 우리에게 동작하는 매우 집중된 매우 저렴한 시스템 위에 개발함으로써 이를 수행할 수 있습니다. 큰 에이에이 방법보다 수십 배 낮은 비용으로 가능합니다.\n\n우리는 필수 인공지능 로봇들이 현실 세계의 산업 규모 문제를 해결할 것이라 믿으며, 장기간 이 문제에 대한 유일한 올바른 접근 방식일 것이라고 확신합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인공지능 레오나르도 다빈치 휴머노이드 르네상스 로봇은 가정에서 놀라운 자원이 될 수 있습니다. 비서로서, 대화 상대로서. 심지어 창고 환경에서 더 많은 저거량 작업을 해낼 수도 있을지도 모릅니다. 하지만 하루에 수백만 개의 베리를 수확해야 한다면, 산업혁명처럼 생각하고 그 일을 탁월하게 수행하는 비용 효율적인 로봇을 만들어야 합니다. 제대로 된 산업 작업은 우리 사회의 기반을 이루며, 제조업, 농업, 거래 분야에서의 \"지루하고 더러운, 위험한\" 직업들에 대해 Essential AI가 비용과 효율성 면에서 Big AI나 심지어 AGI보다 우월하게 성과를 내게 될 것입니다.\n\n더 많은 정보를 원하신다면, Big AI에 대해 아래의 글을 참고해 보세요:\n\n- 포브스: 트랜스포머가 인공지능을 혁신했다. 그들을 대체할 것은 무엇인가?\n- Cobot의 Brad Porter: 인간이 할 수 있는 로봇을 위한 위대한 인공지능으로 가는 길\n- Jacob Grow: 대형 언어 모델의 경계와 인공지능의 전진 방향","ogImage":{"url":"/assets/img/2024-05-18-EssentialAI_0.png"},"coverImage":"/assets/img/2024-05-18-EssentialAI_0.png","tag":["Tech"],"readingTime":6},{"title":"SLAM을 처음부터 구현해 보기","description":"","date":"2024-05-18 19:19","slug":"2024-05-18-ImplementSLAMfromscratch","content":"\n\nSLAM (Simultaneous Localization and Mapping)을 위한 솔루션을 구현하는 다양한 방법이 있지만, 구현하기 가장 간단한 알고리즘은 Graph SLAM입니다.\n\nGraph SLAM은 로봇공학에서 사용되는 기술로, 로봇의 궤적을 시간에 따라 동시에 추정하고 환경 안의 랜드마크 위치를 노드와 제약조건으로 나타내는 그래프입니다. 그래프는 로봇의 자세 및 랜드마크 위치를 나타내는 노드와 간격을 제약 조건으로 나타내는 에지로 구성됩니다. 제약 조건은 초기 위치, 상대 움직임 및 상대 측정 제약 조건과 같은 것들을 나타냅니다. 그래프를 최적화함으로써, Graph SLAM은 센서 측정을 가장 잘 설명하는 가장 확률적인 궤적과 랜드마크 위치를 찾으려고 합니다.\n\n## 예제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nGraph SLAM으로 파고들기 전에, Graph SLAM을 어떻게 구현할지 탐구하는 과정에서 도움이 될 예제를 소개하겠습니다. 이 예제에서는 하나의 차원적인 세계에서 로봇이 이동하는 상황을 살펴보겠습니다. 로봇의 첫 번째 자세는 시간 단계 t0에서이며, 로봇의 자세는 x=2입니다. 이 위치에서 로봇은 랜드마크 L0(예: 나무)를 보고 거리가 9단위 떨어져 있습니다. 그런 다음 로봇은 5단위만큼 앞으로 이동합니다. 이 시점에서 로봇은 x=7에 있어야 하며 랜드마크는 4단위 떨어져 있어야 합니다. 그러나 시간 단계 t1에서 로봇은 랜드마크까지의 거리를 보거나 측정하지 않습니다. 시간 단계 t1에서의 랜드마크 측정 부재는 센서 오류, 가리개, 또는 다른 이유로 인할 수 있습니다. 마지막으로, 로봇은 3단위 앞으로 이동하고 랜드마크를 1단위로 떨어져서 볼 수 있습니다. 이 시점에서 로봇은 x=10에 있어야 하며 랜드마크는 x=11에 있어야 합니다.\n\n![이미지](/assets/img/2024-05-18-ImplementSLAMfromscratch_1.png)\n\n## 제약 조건\n\nGraph SLAM에서는 세 가지 중요한 유형의 제약 조건이 있습니다. 각각의 제약 조건을 자세히 살펴보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 초기 위치 제약: 초기 위치 제약은 로봇이 환경 속 초기 위치에 대한 지식을 나타냅니다. 이는 로봇의 궤적 추정에 고정된 참조점을 제공합니다. 이 제약은 초기 위치 및 방향 추정을 캡처하기 위해 `x, y, θ`로 표현될 수 있습니다. 이 제약을 그래프에 통합함으로써 로봇의 궤적 추정을 기준으로 잡고 추가적인 제약 최적화를 위한 시작점을 제공할 수 있습니다.\n- 상대 운동 제약: 상대 운동 제약은 연이은 시간 단계 간 로봇의 자세 변화에 대한 정보를 캡처합니다. 이러한 제약은 통상 휠 엔코더 또는 IMU와 같은 오도메트리 센서에서 얻어집니다. 오도메트리 센서는 로봇의 움직임에 대한 추정을 제공하며, 위치 및 방향의 변화와 같은 로봇의 움직임을 제공합니다. 연이은 시간 단계 간 오도메트리 측정을 비교함으로써 로봇의 이동을 기술하는 상대 운동 제약을 유도할 수 있습니다. 이러한 제약은 움직임 추정 값의 불확실성을 포착하는 가우시안 분포로 표현됩니다.\n- 상대 측정 제약: 상대 측정 제약은 환경 속 서로 다른 랜드마크나 특징들 간의 상대 위치 또는 거리에 대한 정보를 캡처합니다. 이 제약은 레이저 거리계 또는 카메라와 같은 센서 측정을 통해 얻어집니다. 예를 들어, 로봇이 랜드마크를 관찰하고 해당 랜드마크까지의 거리를 측정한 경우, 이 정보는 상대 측정 제약으로 사용될 수 있습니다. 이러한 제약은 로봇의 궤적에 상대적으로 랜드마크 위치를 추정하는 데 도움을 줍니다.\n\n그래프 SLAM에서는 이러한 모든 제약을 함께 사용하여 환경과 로봇의 궤적에 대한 그래프 표현을 구축합니다. 그래프는 서로 다른 시간 단계의 로봇 자세와 랜드마크 위치를 나타내는 노드 및 그들 사이의 제약을 나타내는 엣지로 구성됩니다.\n\n이것은 테이블 태그를 마크다운 형식으로 변경한 것입니다.\n\n이미지는 [여기](/assets/img/2024-05-18-ImplementSLAMfromscratch_2.png)에서 확인할 수 있습니다.\n\n우리의 예제에서는 5개의 총 제약이 있습니다: 초기 위치 제약 1개, 상대 운동 제약 2개 및 상대 측정 제약 2개입니다. 4개의 상대 제약은 그래프 내의 엣지로 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 그래프 표현\n\n그래프 SLAM에서 환경과 로봇의 궤적은 그래프 구조를 사용하여 표현됩니다. 그래프는 노드와 엣지로 구성되어 있으며, 노드는 로봇의 포즈(위치 및 방향)를 시간에 따라 다른 지점에서 나타냅니다. 엣지는 이러한 포즈 간의 제약 조건이나 측정값을 나타냅니다.\n\n로봇의 포즈뿐만 아니라 환경에 있는 랜드마크나 특징을 나타내는 노드도 그래프에 포함됩니다. 이러한 랜드마크는 로봇이 인식하고 로컬리제이션 및 맵핑에 사용할 수 있는 객체, 관심 지점 또는 기타 독특한 특징일 수 있습니다.\n\n그래프 표현은 엣지를 통해 로봇의 포즈와 랜드마크를 연결하여 센서로부터 얻은 측정값이나 제약 조건을 나타냅니다. 이러한 측정값에는 거리 측정, 방위 측정 또는 로봇과 랜드마크의 상대적인 위치와 방향에 대한 정보를 제공하는 기타 유형의 센서 데이터가 포함될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 로봇이 현재 자세에서 landmark를 관측한다고 가정해 봅시다. 이 관측은 그래프에서 로봇의 자세 노드와 landmark 노드 사이에 엣지를 생성합니다. 이 엣지는 센서로부터 얻은 측정값을 나타내며, 이를 통해 로봇과 landmark 간의 상대적인 위치와 방향에 대한 정보를 제공합니다.\n\n이러한 측정값을 그래프에 통합함으로써 SLAM 알고리즘은 로봇의 가장 가능성 있는 궤적과 측정값에 의해 적용된 제한 조건을 가장 잘 만족하는 환경 지도를 추정할 수 있습니다. 그래프 최적화 과정은 예측된 측정값과 센서로부터 실제로 얻은 측정값 간의 오차를 최소화하기 위해 그래프 내의 자세와 landmark 위치를 조정하는 것을 포함합니다.\n\n## 행렬과 벡터 표현\n\n그래프 SLAM에서는 로봇의 자세와 landmark 간의 관계를 모델링하기 위해 행렬과 벡터 표현을 사용합니다. 이러한 표현은 SLAM 문제를 해결하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n행렬 표현부터 시작해봅시다. Graph SLAM에서 우리는 정보 행렬이라고 하는 행렬을 만듭니다. 이 행렬은 Ω (오메가)로 표시되며 서로 다른 변수들 간의 제약 조건이나 관계를 나타냅니다. 각 변수는 지도상의 로봇 pose나 landmarke에 해당합니다.\n\n정보 행렬은 정사각 행렬이며, 그 크기는 SLAM 문제에서 변수의 수에 따라 달라집니다. 그래프에 n개의 노드가 있는 Graph SLAM 문제의 경우, n x n 크기의 정보 행렬을 갖게 됩니다. 이 행렬의 요소들은 변수들 간의 관계에 대한 정보를 인코딩합니다. 예를 들어, 두 변수가 높은 상관 관계를 가진 경우, 정보 행렬의 해당 요소는 더 높은 값을 갖게 됩니다.\n\n이제 벡터 표현으로 넘어가 봅시다. Graph SLAM에서 우리는 정보 벡터라고 하는 벡터를 생성합니다. 이것은 ξ (크싸이)로 표시되며, SLAM 문제에서 우리가 한 측정치나 관측치를 나타냅니다. 벡터의 각 요소는 특정 측정치나 관측치에 해당합니다. 그래프에 n개의 노드가 있는 Graph SLAM 문제의 경우, n x 1 크기의 정보 벡터를 갖게 됩니다.\n\n정보 벡터에는 SLAM 문제의 측정치와 변수들과의 관계에 대한 정보가 포함되어 있습니다. 이는 우리가 측정치를 SLAM 문제에 통합하고 로봇 포즈와 랜드마크의 추정치를 업데이트하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 예제에서는 그래프에 4개의 노드가 있으므로 4 x 4 행렬을 초기화합니다. 다음은 정보 행렬입니다:\n\n```js\n// 0으로 채워진 4x4 행렬\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 0  | 0  | 0  | 0  |\n| t1 | 0  | 0  | 0  | 0  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n저희 예제에서는 또한 그래프에 4개의 노드가 있으므로 4 x 1 벡터를 초기화합니다. 다음은 정보 벡터입니다:\n\n```js\n// 0으로 채워진 4x1 벡터\n+---+\n| 0 |\n| 0 |\n| 0 |\n| 0 |\n+---+\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 그래프 SLAM 알고리즘\n\n우리가 정보 행렬과 벡터를 선언하면, 초기 위치 제약을 행렬과 벡터에 적용해야 합니다. 예를 들어, 초기 위치인 2를 사용하여 정보 행렬을 업데이트하려면, 간단한 선형 방정식을 만들 것입니다:\n\n이제 우리의 간단한 선형 방정식과 그 계수 `1,0,0,0;2`를 가지고 t0에 해당하는 행에 추가해봅시다:\n\n```js\n// 오메가 행렬 (결과)\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 1  | 0  | 0  | 0  |\n| t1 | 0  | 0  | 0  | 0  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// Xi vector (결과)\n+---+\n| 2 |\n| 0 |\n| 0 |\n| 0 |\n+---+\n```\n\n일반화하기 위해 여기에 초기 의사 코드가 있습니다:\n\n```js\nvoid GraphSLAM(G, startPose) {\n    // Omega와 Xi 선언\n    Omega = new Matrix(n,n)\n    Xi = new Vector(n)\n\n    // 초기 위치 제약\n    Omega['t0','t0'] = 1\n    Xi['t0'] = startPose\n\n    // 그래프 최적화\n    Mu = GraphOptimization(Omega, Xi, G)\n    return Mu\n}\n```\n\n여기서부터 그래프 최적화에 대해 논의해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 그래프 최적화\n\n그래프의 초기 매트릭스 및 벡터 표현이 준비되면, 그래프 최적화를 수행해야 합니다. 그래프 SLAM에서의 그래프 최적화는 센서 측정을 기반으로 그래프를 반복적으로 업데이트하여 로봇 자세와 랜드마크 위치의 추정치를 개선하는 과정입니다. 이 과정은 측정 업데이트와 상태 업데이트라는 두 가지 주요 단계로 구성됩니다.\n\n- 측정 업데이트: 측정 업데이트 단계에서는 그래프의 엣지를 반복하며 정보 매트릭스에 제약 조건을 추가합니다. 이러한 제약 조건은 센서에서 얻은 측정치(예: 거리 측정 또는 방향 측정)를 나타냅니다.\n- 상태 업데이트: 상태 업데이트 단계에서는 선형 방정식 체계를 해결하여 그래프의 오차를 최소화하는 최적 로봇 자세와 랜드마크 위치를 추정합니다. 이는 정보 매트릭스의 역행렬을 취하고 정보 벡터와 곱하여 수행됩니다.\n\n다음은 그래프 최적화를 위한 고수준의 의사 코드 예시입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nvoid GraphOptimization(Omega, Xi, G) {\n    Omega, Xi = MeasurementUpdate(Omega, Xi, G);\n    Mu = StateUpdate(Omega, Xi);\n    return Mu;\n}\n```\n\n측정 및 상태 업데이트에 대해 더 자세히 알아보겠습니다.\n\n## 측정 업데이트\n\n측정 업데이트에서는 그래프 데이터를 사용하여 정보 행렬 및 벡터 데이터를 정의합니다. Omega는 선형 방정식의 계수를 나타내는 정보 행렬이고, Xi는 해당 방정식의 상수항을 나타내는 정보 벡터입니다. G는 측정치(예: 거리)를 나타내는 엣지 가중치를 포함하는 그래프입니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 모서리는 일련의 선형 방정식을 정의하는 데 도움이 됩니다. 예를 들어, 모서리 t0-t1로 정보 행렬을 업데이트하려면 두 개의 선형 방정식을 만들겠죠:\n\n이제, 첫 번째 선형 방정식과 그 계수 `1,-1,0,0;-5`를 가져와서 t0에 해당하는 행에 추가해봅시다:\n\n```js\n// 오메가 행렬 (결과)\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 2  |-1  | 0  | 0  |\n| t1 | 0  | 0  | 0  | 0  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n```js\n// 시 벡터 (결과)\n+---+\n|-3 |\n| 0 |\n| 0 |\n| 0 |\n+---+\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 두 번째 선형 방정식의 계수인 `-1, 1, 0, 0; 5`를 가져와 t1에 대응하는 열에 추가해 봅시다:\n\n```js\n// 오메가 행렬 (결과)\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 2  |-1  | 0  | 0  |\n| t1 |-1  | 1  | 0  | 5  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n```js\n// 크시 벡터 (결과)\n+---+\n|-3 |\n| 5 |\n| 0 |\n| 0 |\n+---+\n```\n\n일반적인 상황을 이해하기 위해 의사 코드를 보여 드리겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nvoid MeasurementUpdate(Omega, Xi, G) {\n    for each edge:\n        // LinEq 1: src - dst = -weight\n        Omega[edge.src, edge.src] += 1\n        Omega[edge.src, edge.dst] += -1\n        Xi[edge.src] += -edge.weight\n        // LinEq 2: dst - src = weight\n        Omega[edge.dst, edge.dst] += 1\n        Omega[edge.dst, edge.src] += -1\n        Xi[edge.dst] += edge.weight\n    return Omega, Xi\n}\n```\n\n보시다시피, 측정 업데이트 프로세스는 그래프 G의 각 엣지에 대해 반복하는 것을 포함합니다. 각 엣지마다 코드는 두 단계를 수행합니다. 먼저, 엣지의 원본 노드에 해당하는 행에 대한 Omega 및 Xi 값을 업데이트합니다. 그 다음, 엣지의 대상 노드에 해당하는 행에 대한 Omega 및 Xi 값을 업데이트합니다. 두 단계 모두 엣지의 가중치는 두 노드 사이(예: 거리)의 측정을 나타냅니다.\n\n이러한 단계는 측정에 의해 부과된 제약 조건이 Omega 및 Xi 행렬에 올바르게 표현되도록 보장합니다. 모든 엣지를 반복한 후 함수는 업데이트된 Omega 및 Xi 행렬을 반환합니다.\n\n## State Update\n  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 시점에서, Omega와 Xi를 완전히 정의했습니다. 그러니 Mu를 해결하기 위해 방정식 체계를 해결하기만 하면 됩니다:\n\n여기서 Mu는 업데이트된 상태 추정을 나타냅니다. Mu를 구하기 위해서는 단순히 Omega를 역행렬로 변환해야 합니다:\n\n```js\nvoid StateUpdate(Omega, Xi) {\n    Mu = Omega.invert() * Xi\n    return Mu\n}\n```\n\n제공된 의사 코드는, 공분산 행렬(Omega)의 역행렬을 측정 벡터(Xi)로 곱하여 상태를 업데이트합니다. 결과인 Mu는 로봇의 자세 및 랜드마크 위치의 상태 추정을 나타냅니다. 이는 시스템의 상태를 정의하는 모든 변수의 값이 포함된 벡터입니다. 우리의 예시에서, 이는 Mu의 예상 값입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// Mu vector (result)\n+----+\n|  2 |\n|  7 |\n| 10 |\n| 11 |\n+----+\n```\n\n이 예에서 첫 번째 요소는 t0에서 로봇의 위치이며, 두 번째 요소는 t1에서 로봇의 위치이고, 세 번째 요소는 t2에서 로봇의 위치이며, 네 번째 요소는 landmark(L0)의 위치입니다.\n\n## 토론\n\nGraph SLAM 알고리즘은 정확한 답변을 제공하지 않을 수 있지만, 근접한 결과를 제공합니다. SLAM 알고리즘의 결과는 알고리즘에 공급되는 측정값의 품질에 따라 달라집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 내용은 간단한 1차원 예시에 불과했습니다. 이를 쉽게 3차원 공간으로 확장할 수 있고 로봇이 바라보는 방향을 설명하는 추가적인 방향 차원도 포함할 수 있습니다.\n\n만약 SLAM 용어 중 이해되지 않는 것이 있다면, SLAM 개요를 다시 참고해 주세요.\n\n이 글이 마음에 드셨다면, ❤를 눌러 다른 사람들이 이를 발견하는 데 도움을 주세요!","ogImage":{"url":"/assets/img/2024-05-18-ImplementSLAMfromscratch_0.png"},"coverImage":"/assets/img/2024-05-18-ImplementSLAMfromscratch_0.png","tag":["Tech"],"readingTime":9},{"title":"로봇 학습의 현황","description":"","date":"2024-05-18 19:17","slug":"2024-05-18-TheStateofRobotLearning","content":"\n\n## 부분적으로 관찰한, 반 확률적인, 자아 중심적인 관점.\n\n![image](/assets/img/2024-05-18-TheStateofRobotLearning_0.png)\n\n이 글은 내가 Nvidia GTC에서 한 발표에 대한 동반자로, 약간의 스파이스를 더했습니다. 이것은 구글 딥마인드의 의견이 아니며, 제 팀과 동료들의 다양한 관점을 반영하지 않을 수 있습니다.\n\n나는 작성 시점으로 6개월 전에 애틀랜타에서 열린 최근 로봇 학습 회의의 분위기가 자신 있었던 것을 알 수 있었습니다. 내가 7년 전부터 참석한 모든 회의와는 다르게 뭔가 변화의 느낌이 났다. 많은 발표가 실제로 ... 꽤 잘 작동하는 로봇 시스템을 보여줬습니다! 비록 일부 학술적 정의에 따르면 그 한계 내에서 작동했다고 할지라도요. 이전에 커뮤니티가 빨간 블록을 파란 블록 위에 쌓는 것과 같은 간단한 작업에서 고심했던 점에서, 이제 우리는 복잡한 현실 세계 문제에 대해 실질적인 진전을 거둔 시스템들을 보고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자주 농담을 해요. 연구 분야에서의 경력은 실제로 작동하지 않는 것들에 대해 평생을 일하는 것을 의미한다고 말이죠. 그리고 세션 간의 복도 대화 중에 연구자들이 “이제 어떻게 해야 할까요?” 라고 자신에게 물어보는 소리가 들릴 수 있어요. 이는 사실 일이 실제로 잘 작동하고 전체 사업에 대해 “임무 완료” 라고 누구도 부르지 않을 정도로 잘 작동한 것이 아니라, 로봇공학의 진행 속도가 가속화되었음을 깨닫게 되어 연구 방향과 채택된 방법론을 재평가해야 한다는 것을 반영하고 있어요.\n\n우리가 어떻게 그 경로에 이르렀는지 궁금하시다구요? 음, 모든 인공지능 관련 사항과 마찬가지로 GPT로의 이동과 현대 LLM 출현을 2021년경으로 거슬러 올라가 볼 수 있어요. 갑자기 전례없는 추론 능력이 모두의 손끝에 있다는 것처럼 보였고, AGI는 곧 다가온다는 것이었죠. 그때쯤 로봇공학계에도 다른 일이 발생했는데, 대중 언론에는 그렇게 많이 보도되지 않았어요: FOMO가 엄청나게 증가했던 거예요. 로봇공학 또는 더 스타일리시한 이름으로 “실체화된 AI”는 AGI로 가는 길이 되어야 했고, 상황 인지, 현실 세계 기반, 상식적 추론에 대한 진정한 해법이었어요. NLP 커뮤니티가 10년 동안 방치한 것으로도 볼 수 있는 그리 증오 받는 서브필드인 “언어 모델링”이 갑자기 주목을 받자 로봇공학계에 무겁게 작용했어요.\n\n물론, 그들을 이기지 못하면 함께 하라는 말이죠. 그래서 우리도 그렇게 했어요. “로봇공학과 LLMs의 만남”이라는 연구 방향은 매우 얕게 나올 수도 있었어요: 아마 당신이 로봇과 대화를 나누는 데 언어 모델을 사용할 수도 있었겠죠. 또는 로봇이 클링곤 시를 낭독하게 할 수도 있었을 거예요. 그러나 실제로 일어난 일은 제 경력의 가장 큰 놀람이었어요: 연결점이 매우 깊게 생겨나서 오늘까지 우리는 그를 해결하기 시작한 것에 불과해요.\n\nLLMs를 “언어”에 관한 것으로 생각하는 것은 흔한 실수예요. 언어는 LLMs가 주로 사용하는 표면형임은 확실히 맞지만(코드도 마찬가지), LLM의 슈퍼파워는 모두 상식적 추론에 관한 것이에요: LLMs는 “책은 책장에 두어야 하지 욕조에는 넣어두지 말아야 한다”나 “커피를 내리는 방법” 같은 간단한 진리를 알아요. 그것이 실제 세계에서 움직이려는 실체화된 에이전트들에게 중요한 문제인 것이 결국 크게 작용한다는 것은 놀랍지 않아요. 그래서 LLMs가 가장 먼저 영향을 줄 로봇학의 한 부분이 계획에 영향을 받을 것이라는 것은 당연한 일이었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로봇이 어떻게 작동하는지 개념적으로 이해하는 도표를 그리는 것이 도움이 될 수 있습니다. 이 정도로 단순화하면 커뮤니티에서 친구를 많이 사귈 수 있을 것 같진 않지만, \"모든 모델은 틀리지만 어떤 것은 유용하다\"는 정신으로 해석하면 매우 유익한 모습이 나옵니다. 당신의 로봇이 세계의 상태를 인지하고, 그 상태를 계획자에게 보내어 목표와 함께 계획을 세우는 루프를 상상해보세요. 그 계획은 로봇 컨트롤러에 전달되고, 하드웨어를 작동시켜 실행을 담당합니다. 물론 세계는 계속 변하기 때문에 아마도 계획의 처음 단계만 실행되고, 상태 추정이 업데이트되고 로봇이 다음 단계 실행 계획을 수립하고, 이와 같은 일을 반복하게 될 것입니다.\n\n이는 로봇 공학의 주요 분야에 매핑되는 임의적인 스케치로, 상태 추정, 작업 및 동작 계획, 제어와 관련하여 전통적으로 병행 발전해 왔으며, 시스템 수준의 문제가 크게 무시되고 문제가 종종 다른 분야로 던져지는 것으로 이어졌다고 주장하는 사람도 많습니다: 너무나 많은 TAMP 논문들이 완벽한 상태 추정을 당연시하고, 많은 제어 전략들이 실행할 수 없는 계획을 속삭이게 되며, 그 경계를 넘어 그래디언트가 흐를 수 있도록 하는 것에 대해 언급할 필요도 없군요!\n\n그래서 당연히 첫 번째 파장은 계획자 쪽에서 발생했습니다. 아마도 주관적일 수 있지만, 나는 SayCan을 \"아하\" 순간으로 꼽을 것입니다. 커뮤니티가 인지한 것은 계획의 많은 부분을 \"의미 공간\"으로 옮길 수 있다면 기하학 공간이 아닌 곳에서 계획을 수행할 수 있으며, 이를 통해 LLMs를 사용하여 이 작업을 수행할 수 있고, 데이터를 수집하거나 로봇에 특화된 온톨로지를 작성하거나 상징적 추론 엔진을 구축할 필요 없이 그들의 상식 능력의 모든 이점을 누릴 수 있음을 깨달은 순간이었다고 생각합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TheStateofRobotLearning_2.png\" /\u003e\n\n인지와 실행 모두 자연어를 사용하는 인터페이스를 갖게되면 모든 것에 대해 언어를 API로 사용하는 것이 매우 유혹적일 것입니다. 언어에는 많은 장점이 있습니다: 유연하며 해석 가능하며 선택한 추상화 수준으로 사물을 설명할 수 있습니다. 이것은 고정된 API에 대한 거대한 문제였습니다: 예를 들어 자율 주행 자동차에게 세계가 바운딩 박스의 모음처럼 보이는 것은 괜찮을 수 있지만, 사물에 직접 접촉하려고 하면 아마도 더 풍부한 지오메트리와 의미론적 정보가 필요할 것입니다. 혹시 계획자가 인식 모듈이 제공할 유용한 정보를 미리 알지 못할 수도 있습니다. 아마도 양방향 대화가 필요할지도 모릅니다...\n\n이것이 그 여정의 다음 단계로 나아가는데요: 계획자와 인지 시스템이 모두 자연어를 사용하도록합시다. VLM들이 정말 뛰어나게 발전하고 있으니, 이를 활용하여 양방향 대화를 실제 대화로 만들어봅시다. 이것이 Socratic Models의 아이디어입니다. 여기서는 세상의 상태와 그에 대한 행동 방법에 대한 합의를 모델 사이의 대화를 통해 달성할 수 있습니다. Inner Monologue는 주기적인 상태 재추정 및 재계획을 대화의 일부로 만드는 개념을 더 발전시켰습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-TheStateofRobotLearning_3.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로봇 지능의 중추로 LLM이 있다면 새로운 일을 많이 할 수 있습니다. 예를 들어 AutoRT에서는 LLM을 활용하여 수행할 새로운 작업을 꿈꿨는데, 이로 인해 즉시 제기된 질문은 다음과 같습니다: 로봇이 스스로 해야 할 일을 생각한다면, 어떻게 그것들이 안전하고 유익한지를 보장할 수 있을까요? 우리는 LLM을 안전한 개념(“날카로운 물체를 집지 마세요”)으로 유도하거나 더 일반적인 인간 중심 가치를 제시할 수 있습니다. “인간에게 상처를 입히지 마십시오…” 소리가 익숙하신가요? 몇 년 전에 실제 로봇에 아지모프의 로봇 법칙을 구현할 수 있는 상당히 타당한 경로가 있다고 말해주었다면, 믿지 않았을 것입니다. 향후 시간이 이것을 사용할지 여부를 알려줄 것입니다. 헌법 AI를 로봇의 안전 스택의 일부로 사용하는 것이 실용적인지는 앞으로 알게 될 것이지만, 실제 세계에서 이에 대해 이야기하고 평가할 수 있다는 사실은공신입니다.\n\n작동 구성 요소는 어떻게 되나요? 전통적인 로봇 공학의 마지막 요새인 그것조차 LLM 처리를 받을 수 있을까요? LLM이 정말 잘하는 한 가지는 코드 생성입니다. 결국, 컨트롤러 소프트웨어는 정책을 기술한 코드일 뿐입니다. 여기서 코드로 정책이라는 개념이 등장하며, LLM에게 저수준 제어 API를 제시하고 실제 실행할 정책을 설명하도록 할 수 있다는 아이디어가 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-TheStateofRobotLearning_4.png\" /\u003e\n\n코드 LMs는 제로샷에서 아주 잘 작동하는데요, 단지 프롬프트 디자인의 암흑 예술에 능숙해야 합니다. 마이크로소프트 동료들의 초창기 ChatGPT for Robotics 실험에서 사용된 것처럼 대화 전략을 사용하여 프롬프트를 반복하고 향상시킬 수 있습니다. 하지만 더 좋은 점은 제어 행위의 상호 작용을 통해 코드 LM을 세밀하게 조정하고 개선하는 반복적인 과정을 거칠 때입니다. 이것은 우리가 고전적인 모델 예측 제어에 유사하게 언어 모델 예측 제어라고 이름 붙인 것입니다. 이를 통해 모델이 새로운 작업에 대해 더 나은 제로샷 수행뿐만 아니라 사용자 상호 작용에서 더 빨리 학습할 수 있게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여러 LLM이 내부 채팅방에서 소통하는 이미지가 로봇의 중추가 되면, 문제를 세 가지 구성 요소로 인수 분해하는 것이 여전히 유용한지 의문스러울 수 있습니다. 신경망은 서로 고대역폭의 미분 가능한 표현을 통해 통신할 수 있기 때문에, 왜 그것들을 단어로 축소시켜야 할까요? 해석 가능성을 어느 정도 얻을 수는 있지만, 정보 손실은 상당합니다. 예를 들어, 계획자가 여전히 본질적으로 맹목적이라고 상상해 보세요. 이러한 구성 요소를 일부 병합할 수 있을까요? 단순히 끝점 열광 때문이 아니라, 이미 이러한 모델에 내재된 모듈성 덕분에 가능합니다. 서로 다른 transformer 구성 요소가 서로 상호 작용하도록 허용함으로써 신경망 내부에서 '관심사의 분리'를 재현할 수 있기 때문입니다.\n\n이 방향으로 첫 실험이 PaLM-E를 사용하여 인식과 계획을 병합하려고 시도되었습니다.\n\n![이미지](/assets/img/2024-05-18-TheStateofRobotLearning_5.png)\n\n인식 및 계획 모듈을 공동 훈련하면 명확한 향상이 관찰되었으며, 작업 및 실행체에 대한 전이 증거도 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 실험은 계획자를 제외하고 지각과 행동을 합치는 것이었습니다. \"픽셀에서 행동\" 모델이 많이 나왔지만 우리에게 혁신적인 방법은 RT-1이었습니다. TRI의 액션 확산, 버클리의 휴머노이드 트랜스포머, 스탠포드의 ACT와 Octo와 같은 방식으로 최근 몇 달 동안 이 분야에서 많은 일이 벌어졌으며, 성능과 기능성의 폭발을 보는 것은 정말 멋진 일이었습니다.\n\n지금쯤 어디로 향하고 있는지 보이시나요? 반쪽채치런 선택보다 모든 것을 하는 단일 \"로봇 두뇌\"를 훈련하는 것이 더 낫지 않을까요? 이에 대한 우리의 첫 번째 시도는 RT-2이었으며, 여전히 로봇공학 관련 데이터 소스(특히 지각 및 의미적 이해를 위한 인터넷 데이터)를 활용하면서 전체 문제에 대해 공동으로 추론하는 능력이 얼마나 많은 도움을 주는지를 보여주었습니다. Meta의 동료들이 VC-1로 그 방향으로 진행한 또 다른 주목할 만한 한 걸음이었습니다. 다중 모달 모델을 위한 오픈소스 생태계가 번성하고 있으며, 우리가 이러한 모델의 공간 추론 능력을 어디까지 밀어낼 수 있는지 탐구하고 있는 사람들이 많아질 것으로 기대합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 우리는 어디로 가야 할까요? 반지도 학습 혁명은 왔다가 지났어요. RL은 여전히 상처를 핥고 있습니다. 확산 모델이 잘 돌아가고 있으며 오프라인 RL이 부활하고 있습니다. 데이터 효율성이 크게 향상되었음에도 불구하고, \"실제 세계에서 작동\"을 상상할 수 있게 되었지만, sim-to-real 접근에 모든 것을 걸 필요가 없어진 것처럼 보이는 상황에서도 여전히 데이터에 구애받고 있으며, 데이터 수집의 효율성과 다양성을 향상시키는 것이 중요합니다.\n\n오늘날 이 분야에서 가장 큰 긴장감이 있습니다. 한편으로는 교차 존재 모델이 로봇간 능력을 전이하는 데 뛰어나게 작동한다는 것을 보여주고 있습니다. 로봇, 작업 간의 다양성을 높이고 문제에 대해 다양성 중심적인 접근을 취해야 한다는 주장이 있습니다. 다른 한편으로는 \"모두를 지배할 한 가지 형태\"로봇 학습 방식을 원하는 사람이 더 많아지고, 테슬라, 피규어, 1X, 어질리티, Unitree, Sanctuary, Apptronik 등과 같이 억만장자로 유명한 로봇에 투자하는 돈이 늘어나고 있습니다. 후자 방법의 장점은 인간적 존재에서 배우고 인간 공간에 배치될 수 있는 범용 능력이며, 단점은 매우 복잡하고 비싼 하드웨어를 데이터 수집의 중요 경로에 놓게 되어 최종 제품의 경제성에 큰 장벽을 높일 수 있다는 것입니다.\n\n그것은 위험한 내기입니다. 특히 교차 존재 가설이 사실로 드러나고 Aloha, UMI, Stretch(및 Dobb.E), Mobile Aloha 및 Aloha 2와 같은 실험을 본다면 싸구려 로봇 떼가 분야를 완전히 혼란스럽게 만들고 다양한 저렴한 모습에 민첩한 능력을 가져올 수 있습니다. 그러나 이 시점에서 그 베팅 어느 쪽에도 100% 돈을 거는 일은 하지 않겠습니다. 앞으로 수개월은 이 분야가 어디로 가야 하는지에 대한 포문이 될 것입니다. 다양성 대 다양성, 싸구려와 두각을 내며 고급 DOF와 완전한 기능, 더 싸고 철저하게, 단점이 있다.\n\n오늘 우리가 있는 세계는 어느 정도 둘 다입니다. \"범용\" 어림들이 널리 배치되어 있지만, 그들을 가치 있게 만드는 경제학은 잔혹하며, 그것들이 실제로 유용하게 만들기 위해 전용 도구 및 시스템 통합이 필요합니다.\n\n데이터 확장 맥락에서 확신하는 점은 생성 모델이 시뮬레이션의 미래라는 것이며, \"더 나은 시뮬레이터\"뿐만 아니라 3D 및 비디오 생성이 외형뿐만 아니라 물리학 및 공간 관계도 존중하게 만드는 방법을 쫓아야 한다는 것입니다. 날씨 예측부터 단백질 접힘까지 다른 물리학 시뮬레이터 분야마다 생성 모델로 인해 혼란스러워지고 있습니다. 로봇 및 환경의 디지털 복제본을 작성하는 데 몇 시간을 보내는 대신 로봇의 센서를 잡아 \"재생\"을 누르면 가능한 미래를 생성할 수 있다면 시뮬에서 실로ら 릴 체리 뉴스를 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 데이터 확장이 대부분 HRI 문제로 전환되고 있다고 점점 더 확신하게 되고 있습니다. 오늘날 HRI 커뮤니티가 주로 걱정하는 정확한 문제는 아닐 수 있지만; 대부분의 HRI는 최종 사용자가 로봇과 상호 작용하는 부분에 관심을 기울입니다. 새로운 다양한 작업을 설계하고, 데이터를 견고하게 수집하고, 행동을 개선 및 최적화하기 위해 더 나은 HRI 접근 방식이 필요합니다: 모델 및 행동을 훈련시키기 위해 데이터 수집에 필요한 모든 신중한 설계를 최적화하는 것은 최종 사용자가 최종 제품과 상호 작용하기 전에도 이루어져야 합니다. 우리는 실제로 모든 로봇을 눈, 팔, 다리가 있는 챗봇으로 바꿈으로써 HRI 커뮤니티에 새로운 가능성을 제공했습니다.","ogImage":{"url":"/assets/img/2024-05-18-TheStateofRobotLearning_0.png"},"coverImage":"/assets/img/2024-05-18-TheStateofRobotLearning_0.png","tag":["Tech"],"readingTime":8},{"title":"NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기","description":"","date":"2024-05-18 19:15","slug":"2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble","content":"\n\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png\" /\u003e\n\n이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png\" /\u003e\n\n# Prerequisites\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시작하기 전에 다음 구성 요소가 있는지 확인하십시오:\n\n- NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04\n- Intel RealSense Depth Camera (예: D435i)\n- Jetson Nano에 설치된 ROS2 Humble\n- RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블\n- 필요한 패키지를 다운로드하기 위한 인터넷 연결\n\nROS2 RealSense 패키지 설치\n\n```js\nsudo apt install ros-humble-realsense2-camera\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRealSense 노드를 시작해주세요:\n\nRealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:\n\n```python\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='realsense2_camera',\n            executable='realsense2_camera_node',\n            name='realsense2_camera',\n            output='screen',\n            parameters=[{\n                'enable_depth': True,\n                'enable_infra1': True,\n                'enable_infra2': True,\n                'enable_color': True,\n            }],\n        ),\n    ])\n```\n\n란치 파일을 실행하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003ctable\u003e\n    \u003ctr\u003e\n        \u003ctd\u003e![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png)\u003c/td\u003e\n    \u003c/tr\u003e\n\u003c/table\u003e\n\n```js\nros2 launch your_package_name realsense_launch.py\n```\n\nrqt에서 데이터 시각화:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nrqt에 RealSense 데이터 추가하기:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png)\n\n- 새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.\n- 이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n깊이 이미지\n\n![깊이 이미지](https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif)\n\n# 깊이 이미지란?\n\n깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 주요 주제 및 메시지\n\nROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:\n\n- 토픽: /camera/depth/image_raw\n- 메시지 유형: sensor_msgs/Image\n\n## sensor_msgs/Image 메시지\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nsensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:\n\n- header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.\n- height: 이미지의 높이(픽셀 단위).\n- width: 이미지의 너비(픽셀 단위).\n- encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.\n- is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.\n- step: 바이트 단위의 전체 행 길이.\n- data: 바이트 배열로 저장된 실제 픽셀 데이터.\n\n## 깊이 이미지 처리\n\n깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.\n- 장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.\n- 3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.\n\n# 결론\n\n위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.\n\n문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!","ogImage":{"url":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"},"coverImage":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png","tag":["Tech"],"readingTime":4},{"title":"라즈베리 파이 5에서 VSCode 서버 다시 시도하기","description":"","date":"2024-05-18 19:13","slug":"2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5","content":"\n\n\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png\" /\u003e\n\n지난 번에 우리가 이에 대해 이야기했을 때는 Raspberry PI 5가 없었고, VSCode Server의 버전은 4.0.2였습니다. 전체 경험은 성공적이지 못했고, 실제 작업에 적합하지 않았습니다. VSCode가 느리게 실행되었고, 빌드 시간도 더욱 더 걸렸습니다. 특히 러스트와 같은 언어에 대해서는 그러했습니다. 따라서 우리는 더 나은 하드웨어를 기다리는 실험을 종료했습니다. 운좋게도, 오늘 기다리던 하드웨어가 마침내 출시되었습니다: Raspberry PI 5.\n\nRaspberry PI 4보다 최대 세 배 빠른 속도로 벤치마킹된 새로운 Raspberry PI는 개인용 코딩 및 빌딩 워크스테이션으로 강력한 경쟁자가 되리라 약속합니다. 이에 더해 더 많은 RAM, 더 높은 I/O 대역폭 및 더 나은 GPU를 제공하여 모든 것이 성공을 향해 나아가는 것으로 보입니다. 우리는 마침내 우리의 홈 VSCode Server를 가질 수 있을까요? 알아보겠습니다!\n\n## VSCode Server 설치 및 구성하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Trying the VSCode Server again on the Raspberry Pi](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_1.png)\n\nVSCode Server도 업데이트되었습니다. 현재 버전 4.20.0에 도달했습니다. 이번에는 지난 시험한 버전보다 많은 개선 사항을 갖춘 VSCode 1.85.1이 실행됩니다. 그래서 이번에는 이전과 마찬가지로 curl을 사용하여 공식 페이지에서 그것을 받아봅시다. 이번에는 여러분도 이미 알다시피 Fedora가 아직 Raspberry PI 5를 지원하지 않는 커널을 사용하고 있기 때문에 Ubuntu를 위한 Debian 패키지를 사용하겠습니다:\n\n```bash\n#curl -fOL https://github.com/coder/code-server/releases/download/v4.20.0/code-server_4.20.0_arm64.deb\n#sudo apt install ./code-server_4.20.0_arm64.deb\n```\n\n그럼 시작해봅시다!\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_2.png\" /\u003e\n\n설치 후에 우리가 해야 할 일은 잘 알려진 아래 명령어를 실행하여 VSCode 서버를 활성화하는 것뿐입니다:\n\n```js\n#sudo systemctl start code-server@ubuntu\n#sudo systemctl enable code-server@ubuntu\n```\n\n@ubuntu 부분은 서버를 실행할 사용자를 가리킵니다. 이 경우에는 ubuntu인데요, 라즈베리 파이 서버 사용자를 반영하도록 변경해도 상관 없습니다. 서버는 이제 기본 포트 8080에서 실행되지만, ~/config/code-server/config.yaml 파일을 편집하여 해당 포트 및 다른 설정을 변경할 수 있습니다. 예를 들어, 저는 포트를 변경하고 로그인 암호를 제거했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래에서 볼 수 있듯이, 우리는 IP 주소를 변경하여 네트워크의 모든 클라이언트에서 10000번 포트로의 연결을 허용하도록 했습니다. 또한 인증을 비활성화하여 기본 비밀번호에서 변경했습니다. 비밀번호를 추가하려면 다음을 사용합니다:\n\n```js\nbind-addr: 0.0.0.0:10000\nauth: password\npassword: password-hash\ncert: false\n```\n\n비밀번호 해시는 mkpasswd를 사용해서 얻을 수 있습니다. 비밀번호를 입력하라고 요청하며, 해시를 복사하여 위의 비밀번호 필드에 붙여넣습니다. 이것이 모든 구성 단계입니다. 이제 브라우저로 넘어가봅시다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 브라우저에서 Visual Studio Code 실행하기\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_4.png)\n\n위의 스크린샷에서 볼 수 있듯이, 우리가 해야 할 일은 네트워크 내의 어떤 브라우저에서라도 Raspberry PI에 있는 IP 주소로 접근하고, VSCode Server가 실행 중인 올바른 포트인 경우(우리의 경우 10000)를 제공해주면 됩니다. 이제 즉시 브라우저 창을 새로고침하면, Raspberry PI 4에서 VSCode가 훨씬 빠르게로드됩니다. 심지어 이미 LDAP 서버를 포함한 많은 네트워크 서비스가 실행 중이지만요. 터미널을 열고 rust를 설치해봅시다:\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 스크린샷에 나오는 명령어는 rustup을 설치하는 기본 명령어입니다: curl --proto `=https` --tlsv1.2 -sSf https://sh.rustup.rs | sh. 이 명령어는 라즈베리 파이 5 VSCode 서버에 rust를 설정해줍니다:\n\n![라즈베리 파이 5 VSCode 서버 재시도](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_6.png)\n\n라즈베리 파이 5의 와이파이 속도가 향상된 것을 알립니다. Rust를 다운로드하는 과정이 로컬 머신에서 실행하는 것과 더 닮았습니다. 그럼에도 불구하고, 설치 과정은 기대보다 느립니다. 물론, 제 최신 세대 인텔 i7 데스크탑과 비교하면 공평하지 않지만, 이 작은 라즈베리 파이 5도 아직 데스크톱 속도에 도달하기 위해 많은 것을 해야 한다는 것을 보여줍니다. 그럼에도 불구하고, 경험은 실제로 라즈베리 파이보다 빨랐습니다. 3배 빠른가요? 정말 그렇지는 않았지만, 라즈베리 파이 4에서 약 10분 정도 걸릴 작업이 라즈베리 파이 5에서는 약 4분 정도 소요되었습니다. 확실한 향상이었습니다.\n\n하지만, 일반적이고 작은 웹 서버와 같은 몇 가지 종속성을 사용하여 rust 프로젝트를 작성하고 빌드하는 작업을 해보죠. 그러기 위해 우리는 projects라는 새 폴더를 만들어서 브라우저에서 VSCode를 열고 터미널을 실행하여 cargo new web-test --bin을 실행하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_7.png\" /\u003e\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n이제 해당 폴더를 열어 봅시다:\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_8.png\" /\u003e\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n프로젝트를 컴파일해 보겠습니다. 먼저 rust-analyzer 확장 프로그램을 설치하여 VSCode에서 rust 언어를 완전히 지원받을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_9.png)\n\nLLDB 디버거도 설치할 겁니다. 이를 통해 러스트 프로그램을 디버깅할 수 있어요:\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_10.png)\n\n사실, Raspberry PI 4에 비해 VSCode 익스텐션 설치가 훨씬 빠른 것 같아요. 그것들은 로컬 데스크톱에서 설치하는 것과 똑같아요. 전체 경험은 로컬에서 VSCode를 실행하는 것 같아요. 다시 F5를 누르면 다음으로 linker cc를 찾을 수 없다는 에러가 나올 거에요. 그래서 sudo apt install build-essential을 사용해서 build-essential 패키지를 설치해볼까요:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![다운로드 속도가 빠르고 설치 속도는 조금 느립니다. 하지만 라즈베리 파이 5는 여전히 1분 이내에 모든 것을 설치하는 데 성공합니다. 이번에는 F5를 누르면 정말로 프로젝트를 컴파일하고 디버그합니다. 마침내. 러스트 서버를 실행해 봅시다!](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_11.png)\n\n## 작은 러스트 웹 서버 만들기\n\n![다운로드 속도가 빠르고 설치 속도는 조금 느립니다. 하지만 라즈베리 파이 5는 여전히 1분 이내에 모든 것을 설치하는 데 성공합니다. 이번에는 F5를 누르면 정말로 프로젝트를 컴파일하고 디버그합니다. 마침내. 러스트 서버를 실행해 봅시다!](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_12.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금까지 우리는 안정적으로 1%에서 3%의 CPU 사용량과 겨우 1.2GB의 RAM 사용량을 유지하고 있어요. 이라고 느껴질 수 있지만, 라즈베리 파이 5는 8GB의 사용 가능한 RAM을 가지고 있어요. 라즈베리 파이 4에서는 이미 이것이 고난일이었죠:\n\n![이미지1](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_13.png)\n\n그럼, 정적 파일을 제공하는 간단한 웹 서버를 준비해뒀어요:\n\n![이미지2](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_14.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nrust-analyzer가 작업을 수행하는 동안 actix 종속성을 다운로드하고 컴파일하며 소스 코드를 색인화하는 과정에서 4코어 ARM CPU에서 발생하는 전형적인 노동의 결과를 확인할 수 있습니다. 하지만 이는 라즈베리 파이 5가 쉽게 처리할 수 없는 것은 없습니다. 웹 경험은 여전히 부드럽고 자동 완성은 여전히 즉각적으로 응답합니다:\n\n![이미지1](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_15.png)\n\n또한 전형적인 index.html 파일을 준비했습니다:\n\n![이미지2](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_16.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 웹 서버를 구축하고 실행해 보려고 합니다. 우리 손가락을 교차하고 cargo build를 실행해 보세요. actix web 라이브러리는 이미 인상적인 수의 종속성을 필요로 하지만, Raspberry PI 5는 이 모든 것을 빠르게 처리합니다:\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_17.png)\n\n지금 세 분은 꽤 오랜 시간으로 느껴질 수 있지만, 말해 드릴게요. 저는 웹 프로젝트를 만들 때 Raspberry PI 4에서 러스트로 빌드했을 때 쉽게 10분씩 썼습니다. 저에게는 이미 이는 압도적인 승리입니다. 더 구체적인 비교를 해보면, 저의 평균 AMD Ryzen 5 3000 노트북은 이 일을 완료하는 데 약 한 시간 반 정도 걸리는 반면, 동시에 많은 일을 실행 중이기는 하지만요. 하지만, 합당하게 말해서, Raspberry PI 5는 상황을 감안할 때 충분히 좋은 일을 하고 있습니다. 그리고 Raspberry PI 4보다 훨씬 더 훌륭한 일을 합니다.\n\n정말 인상적입니다. Raspberry PI 4는 홈 네트워크 코딩 서버로 사용하기에 적합하지 않았고, 단 몇 분만 지나도 Raspberry PI 5가 이 상황을 어떻게 처리하는지 완전히 만족스럽다고 할 수 있습니다. 대규모 자원을 사용하는 복잡한 빌드 프로세스로 알려진 러스트 프로그램을 빌드하고 실행하는 것은 매우 쉽고 로컬에서 실행하는 것 같은 느낌이 듭니다. 이게 최고의 칭찬이에요. Raspberry PI 4에서 서버가 제한적이고 중단되는 느낌이 들었던 것과는 달리, 이번에는 서버로 인해 제한받거나 방해받는 느낌이 들지 않습니다. 이 실험을 성공으로 인정하고 계속하여 실험을 진행하기 위해 VSCode Server 구동 상태로 두겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 대형 태블릿을 사용하여 코딩 및 이전에 거부되었던 가정 네트워크의 다른 리소스를 활용할 수 있는 훌륭한 시나리오를 열어줍니다. 이 멋진 여정을 함께 해 줘서 감사하고, 다음에 또 만나요!","ogImage":{"url":"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png"},"coverImage":"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png","tag":["Tech"],"readingTime":7}],"page":"40","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"40"},"buildId":"PgdIX9e0tvkvkdAmDT6qR","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>