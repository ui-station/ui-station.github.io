<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/72" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/72" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_buildManifest.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes" href="/post/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">16<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법" href="/post/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기" href="/post/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">32<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요" href="/post/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label=" 쿠버네티스에서 Vault 사용 방법 안내 " href="/post/2024-05-23-AHand-OnGuidetoVaultinKubernetes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt=" 쿠버네티스에서 Vault 사용 방법 안내 " loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt=" 쿠버네티스에서 Vault 사용 방법 안내 " loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl"> 쿠버네티스에서 Vault 사용 방법 안내 </strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이썬 제너레이터 데이터베이스에서 효율적으로 데이터를 가져오는 방법" href="/post/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이썬 제너레이터 데이터베이스에서 효율적으로 데이터를 가져오는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이썬 제너레이터 데이터베이스에서 효율적으로 데이터를 가져오는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">파이썬 제너레이터 데이터베이스에서 효율적으로 데이터를 가져오는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">19<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="컨테이너 세계에서 Runc 대 Crun" href="/post/2024-05-23-RuncvsCrunincontainersworld"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="컨테이너 세계에서 Runc 대 Crun" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-RuncvsCrunincontainersworld_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="컨테이너 세계에서 Runc 대 Crun" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">컨테이너 세계에서 Runc 대 Crun</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커 대 Podman 안전한 오케스트레이션의 새 시대" href="/post/2024-05-23-DockervsPodmanANewErainSecureOrchestration"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커 대 Podman 안전한 오케스트레이션의 새 시대" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커 대 Podman 안전한 오케스트레이션의 새 시대" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">도커 대 Podman 안전한 오케스트레이션의 새 시대</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="러스트 배우기 11부  빌더와 데이터베이스 상호작용" href="/post/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="러스트 배우기 11부  빌더와 데이터베이스 상호작용" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="러스트 배우기 11부  빌더와 데이터베이스 상호작용" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">러스트 배우기 11부  빌더와 데이터베이스 상호작용</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">24<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데브 컨테이너로 Rails 앱을 도커라이즈하기" href="/post/2024-05-23-DockerizeRailsappwithDevContainers"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데브 컨테이너로 Rails 앱을 도커라이즈하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DockerizeRailsappwithDevContainers_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데브 컨테이너로 Rails 앱을 도커라이즈하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데브 컨테이너로 Rails 앱을 도커라이즈하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/61">61</a><a class="link" href="/posts/62">62</a><a class="link" href="/posts/63">63</a><a class="link" href="/posts/64">64</a><a class="link" href="/posts/65">65</a><a class="link" href="/posts/66">66</a><a class="link" href="/posts/67">67</a><a class="link" href="/posts/68">68</a><a class="link" href="/posts/69">69</a><a class="link" href="/posts/70">70</a><a class="link" href="/posts/71">71</a><a class="link posts_-active__YVJEi" href="/posts/72">72</a><a class="link" href="/posts/73">73</a><a class="link" href="/posts/74">74</a><a class="link" href="/posts/75">75</a><a class="link" href="/posts/76">76</a><a class="link" href="/posts/77">77</a><a class="link" href="/posts/78">78</a><a class="link" href="/posts/79">79</a><a class="link" href="/posts/80">80</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"에지 컴퓨팅을 위한 비용 절감을 위한 2-노드 HA Kubernetes","description":"","date":"2024-05-23 14:29","slug":"2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings","content":"\n# Edge computing은 중요합니다\n\n현재 기업들은 머신러닝 및 실시간 애플리케이션과 같은 모든 종류의 워크로드에 대한 엣지 컴퓨팅의 혜택을 인정합니다. 이러한 시나리오에서는 데이터 처리를 로컬에서 수행해야 합니다.\n\n관련 데이터의 양이 많고 네트워크 연결이 제한적일 수 있습니다. 중앙 데이터 센터나 클라우드 컴퓨팅 환경에서 처리 및 분석을 수행하는 동안 빠른 응답 시간을 제공하는 것은 불가능합니다.\n\n엣지 컴퓨팅 사용 사례에서 이러한 소프트웨어 애플리케이션을 실행할 때 높은 가용성이 필수입니다. 단일 노드(단일 CPU, 디스크 등)를 의존하는 것은 완전히 위험합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, 번잡한 패스트푸드 음식점의 포인트 오브 세일 애플리케이션이 클러스터 고장으로 다운되어 하루 매출(이상)을 손해 볼 때를 상상해보세요.\n\n또는 제조공장의 에지 서버가 고장나 IoT 디바이스를 운용 중이며, 생산이 중단될 때를 상상해보세요.\n\n또는 물류 창고에서 드론을 관리하는 컴퓨터 비전 앱이 하드웨어 고장으로 인해 작업자 안전이 위험에 처할 때를 상상해보세요.\n\n# 쿠버네티스에서의 고가용성은 비싸요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n에지 애플리케이션을 위한 고가용성 아키텍처를 구현하려면 일반적으로 사이트당 세 노드로 이동해야 합니다. 이것은 Kubernetes의 기본 키-값 저장소인 etcd가 일관성과 가용성을 보장하려면 최소 세 노드가 필요하기 때문입니다.\n\n빠뜨리기 쉬운 원가\n\n그리고 퀵 서비스 레스토랑 및 소매와 같은 섹터의 에지 배포는 종종 수만 개의 가게로 확장됩니다. 이로 인해 전사적인 세 개 노드 HA용으로 배포하는 비용은 빠르게 누적됩니다: 하드웨어, 케이블 연결, 전원, 그리고 센서 – 모두 중복됩니다!\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png)\n\n# 비용 지출 없는 가용성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 세 개가 아닌 두 개의 엣지 노드를 사용하여 비용 효율적이고 (대부분) 고가용성을 갖는 Kubernetes 클러스터를 제공할 수 있다면 어떨까요?\n\n작년 가을, Spectro Cloud 팀은 이 질문에 대한 답을 찾으려 노력했고 그 과정에서 진전 사항을 블로그와 KubeCon Paris에서의 프레젠테이션을 통해 공유했습니다 (이 때 데모 신이 우리 편은 아니었죠).\n\n오늘은 최신 2 노드 HA 아키텍처를 안내해 드릴 것이며, 이는 제대로 활용된 솔루션이며 제품 규모로 실행되는 엣지 Kubernetes 애플리케이션에 대해 약 33% 비용을 절감하는 해결책입니다!\n\n마지막으로 주의사항이 있습니다: CAP 이론 애호가 여러분을 걱정하며, 브루어의 불가침 제약을 극복했다고 주장하는 사람은 아무도 없습니다. 명확함을 위해 끝까지 읽어주세요...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 솔루션 개요\n\n저희 2노드 HA 아키텍처는 Spectro Cloud의 기존, 검증된 엣지 솔루션을 사용하며 kairos, k3s, kube-vip, harbor 및 system-upgrader-controller를 포함한 오픈 소스 구성 요소 위에 구축됩니다.\n\n저희는 변경불가능하고 A/B 파티션으로 나눈 부팅 가능한 OS 이미지를 통해 솔루션을 배포합니다 (고마워요, Kairos). 저희 이미지에는 Kubernetes 배포 (주로 K3s), 독점적인 Go 에이전트 및 필요에 따라 개별적으로 추가하는 사용자 정의 소프트웨어가 포함됩니다. 모든 구성은 클라우드-컨피그 구문으로 선언적으로 지정되며 클라우드-이닛에 의해 실행됩니다.\n\n엣지 디바이스들은 초기에 등록 모드로 프로비저닝됩니다. 그 후 Spectro Cloud의 Palette 플랫폼이나 로컬 관리 GUI를 통해 클러스터에 추가되어 원하는 부팅 가능한 OS 이미지를 사용하여 설치 모드로 재부팅됩니다. Kubernetes가 온라인으로 되면 Go 에이전트에 의해 애드온이 설치되고 조정됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nImmutable upgrades are performed by streaming a new image to the node (or via USB for air-gapped use cases), writing it to disk, and rebooting from the B partition. If anything goes wrong, we automatically fail back to the A partition with known-stable configuration.\n\nFor two node support, we layered kine and postgresql into our existing edge solution and introduced a handful of additional mechanisms for lifecycle management, including liveness checks, a liveness client and server, and a finite state machine to ensure correctness of the kine endpoint configuration.\n\nAs always, a picture is worth a thousand words:\n\n![Image Description](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 가지 엣지 호스트가 프로비저닝되었습니다: 하나는 리더이고 다른 하나는 팔로워입니다. 양쪽 호스트에는 systemd 서비스로 구성된 Go 에이전트가 포함되어 있으며, 설정 가능한 주기로 지속적으로 살아있음 조정을 실행합니다. 살아있음 조정 루프는 각 호스트의 역할을 수정할 여부와 방법을 결정하는 유한 상태 기계(FSM)입니다.\n\n위 다이어그램은 명확성을 위해 개별적인 Kubernetes 구성 요소를 나타냈지만 실제로는 제어 플레인, kubelet 및 kube-proxy가 각 호스트의 단일 K3s 서버 프로세스에 포함되어 있습니다. 두 K3s 서버 모두 로컬 kine 프로세스의 데이터 저장소 엔드포인트로 http://localhost:2379를 사용하도록 구성되어 있습니다.\n\nKine 및 postgres는 각 호스트에서 systemd를 통해 구성되지만, 리더의 kine 엔드포인트는 로컬호스트의 postgres 프로세스를 가리키고 팔로워의 kine 엔드포인트는 리더의 postgres 프로세스를 가리킵니다.\n\n마지막으로, 두 postgres 프로세스 간에 단방향 논리 복제가 구성되어 있어서 각 호스트의 kine 테이블 내용을 동기화합니다. 두 kine 프로세스가 API 서버 트래픽을 리더로 인바운드하므로 모든 쓰기는 먼저 리더 데이터베이스에 기록된 다음 팔로워로 일관된 방식으로 복제됩니다. 각 호스트에서 부팅 시에 kine 및 k3s를 시작하기 전에 실행되는 한 번 실행되는 systemd 유닛인 kine 엔드포인트 조정기가 논리 복제 구성을 조율하고 kine 프로세스가 올바른 엔드포인트로 구성되어 있는지 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 초기화: 엣지 호스트 메타데이터\n\n시스템이 처음 프로비저닝될 때, 각 호스트는 호스트의 역할 및 주소, 컨트롤 플레인 엔드포인트 및 마지막 수정된 타임스탬프를 포함한 메타데이터 파일(이하 호스트메타로 지칭함)을 초기화합니다. 호스트메타 콘텐츠는 로컬 장치 구성(네트워크 인터페이스) 및 엣지 클러스터 구성의 조합에서 유추됩니다. 이 구성은 Spectro Cloud의 Palette 플랫폼에서 가져오거나 공기차단된 익스포트로부터 로드될 수 있습니다.\n\n```js\n// 호스트메타 예시\nlocalHost:\n  name: host-1\n  address: 10.10.10.1\n  uid: host-1-uid\naltHost:\n  name: host-2\n  address: 10.10.10.2\n  uid: host-2-uid\nleader:\n  name: host-1\n  address: 10.10.10.1\n  uid: host-1-uid\nfollower:\n  name: host-2\n  address: 10.10.10.2\n  uid: host-2-uid\ncontrolPlaneEndpoint: 10.10.10.0\nlastModified: \"Mon Apr 29 18:54:47 2024\"\n```\n\n호스트가 등록 모드에 있거나 특정 센티넬 파일인 /oem/.two-node-pause가 존재하는 경우, 라이브니스 조정은 무시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 센티넬 파일, /oem/.two-node-initialized,은 호스트 메타가 성공적으로 초기화된 후에 생성됩니다. 그 이후에는 엣지 클러스터 구성이 아닌 호스트 메타 파일만을 참조하여 역할 할당 및 상태 전이를 위해 사용됩니다. 이것은 클러스터가 완전히 연결이 끊겨 자체적으로 작동한다는 것을 의미합니다.\n\n## Kine 엔드포인트 조정기\n\nKine 엔드포인트 조정기는 먼저 /oem/.two-node-initialized 파일의 존재 여부를 확인합니다. 이 파일이 존재하지 않는 경우 미리 지정된 로컬 호스트 메타 파일을 가져와 /oem/.two-node-initialized 파일을 생성합니다.\n\n다음으로, 해당 호스트가 팔로워인 경우, 리더에서 발행 및 복제 슬롯 작업을 확인하거나 구성하기 위해 PostgreSQL 작업들의 일련을 수행합니다. 이 작업들은 리더에서 발행 및 팔로워에서 리더의 발행에 대한 구독을 포함합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시스템 상태에 따라 kine-endpoint-reconciler가 엣지 호스트 교체 작업을 수행할 수 있습니다.\n\n마지막으로, 로컬 및 원격 hostMeta 파일이 조정됩니다. 이 파일들이 일치하지 않으면 호스트의 역할이 변경될 수 있습니다. 즉, 승격 또는 강등될 수 있습니다. 이 단계에서 강등이 발생하면 로컬 Kubernetes 데이터베이스를 삭제하고 복제를 다시 구성하는 일련의 PostgreSQL 작업이 실행됩니다. 이는 로컬 Kubernetes 데이터베이스의 전체 동기화를 트리거합니다.\n\nkine-endpoint-reconciler가 완료되면 시스템은 정상 작동 모드로 들어가며 제어가 라이브니스 서비스로 전환됩니다.\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n키네 엔드포인트 조정기가 완료되면, 시스템은 정상 운영 모드로 전환되어 liveness 서비스로 제어가 전환됩니다.\n\n## Liveness reconciliation\n\n각각의 liveness 주기마다, 각 Go 에이전트는 두 개의 hostMeta 파일을 획득합니다. 하나는 로컬 파일 시스템에서 가져오고, 다른 하나는 대체 호스트의 liveness 서버에서 가져옵니다 (대체 호스트가 이용 가능하고 건강한 경우에만 일시적으로 검색됨). 이후 일련의 건강 검사가 실행되고, 결과에 따라 상태 전이가 발생할 수 있습니다:\n\n- 제어 플레인 엔드포인트로의 TCP 연결\n- 대체 호스트의 쿠버네티스 API 서버로의 TCP 연결\n- 대체 호스트에 대한 ICMP 핑\n- 건강 검사 스크립트 (선택사항) — 디스크 이용률, 메모리 압박 등을 확인하는 임의의 쉘 스크립트\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n각 실패한 확인에 대해 카운터가 증가됩니다. 다음 다이어그램은 liveness-service의 조화 흐름을 보여줍니다:\n\n![Image](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_3.png)\n\n## 승급\n\n리더가 다운되고 팔로워의 라이브니스 서비스가 네 번의 건강 확인 실패를 감지하면 승급이 시작됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_4.png)\n\n프로모션 기간 중 팔로워 호스트에서 다음 이벤트 시퀀스가 발생합니다:\n\n- 다음 파일은 역할 변경을 반영하도록 업데이트됩니다:\n  - 로컬 호스트 메타 파일\n  - 다양한 클라우드 초기화 구성 파일\n  - kine 엔드포인트가 localhost를 가리키도록 다시 구성됨\n  - 리더에 대한 논리 복제 구독이 해제됨\n  - k3s 및 kine가 중지됨\n  - 다음 \"등록 해제\" SQL이 실행됨:\n\n```js\nDELETE FROM kine\nWHERE name LIKE '/registry/masterleases%'\nOR name LIKE '/registry/leases/%'\nOR name = '/registry/services/endpoints/default/kubernetes';\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n디폴트 네임스페이스에서 쿠버네티스 서비스의 엔드포인트를 삭제하면 k3s 서버가 손상된 호스트와의 웹소켓 터널을 끊게 됩니다.\n\n게다가, k3s를 다시 시작하면 모든 로컬 컨트롤러의 리소스 리소소르를 빠르게 확보하기 위해 kine 테이블에서 모든 k8s 리스를 삭제합니다.\n\n5. 다음의 \"시퀀스 복구\" SQL이 실행됩니다:\n\n```js\nSELECT setval('kine_id_seq', (SELECT MAX(id) FROM KINE), true);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 작업은 논리 복제 중에 시퀀스 데이터를 복제하지 않기 때문에 필수적입니다. 이 단계를 수행하지 않으면 kine 테이블에 prev_revision ` id로 새로운 행이 삽입되어 kine가 가정하는 키 불변성을 위반하고 데이터베이스 손상을 일으킬 수 있습니다.\n\n6. k3s 및 kine을 다시 시작합니다.\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_5.png)\n\n## Demotion\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n원래 리더였던 호스트가 일시적으로 오프라인 상태가 되면, 팔로워가 리더의 부재를 보완하여 자체를 승격합니다. 그 후 원래 리더가 온라인 상태로 돌아오면, 그의 kine-endpoint-reconciler은 불일치를 감지하고 강등을 시작합니다.\n\n강등 중에는 원래 리더(현재는 팔로워로 지칭함) 호스트에서 다음 일련의 이벤트가 발생합니다:\n\n- 리더(이후 팔로워로 지칭)는 두 호스트의 역할 변경을 반영하도록 다음 파일을 업데이트합니다:\n  - 로컬 호스트 메타\n  - 다양한 클라우드 초기화 구성 파일\n  - kine 엔드포인트를 localhost가 아닌 새 리더를 가리키도록 다시 구성합니다.\n  - 현재 리더의 데이터베이스에 게시물이 생성됩니다(이미 존재하지 않는 경우).\n  - 팔로워는 kine 테이블의 내용을 삭제합니다.\n  - 팔로워는 copy_data = true로 리더의 게시물을 구독하여 전체 kine 테이블을 다시 동기화합니다.\n  - 비활성 복제 슬롯이 이미 있는 경우 사용하고, 그렇지 않으면 리더에 새로운 복제 슬롯이 생성됩니다.\n  - k3s 및 kine이 다시 시작됩니다.\n\n## Edge 호스트 교체\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 두 호스트 중 하나가 영구적으로 손상된 경우(예: 하드 드라이브 고장, NIC 고장 등), 대체 장치가 엣지 사이트로 발송됩니다. 새 장치 부팅 후 저하된 팔로워를 원활하게 대체하며, 그 후 해당 장치를 폐기할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_6.png)\n\n대체 호스트가 부팅되며 클러스터 구성에 액세스하면 현재 리더의 주소 및 현재 팔로워임을 표시합니다. 연결된 환경에서는 클러스터 구성이 팔레트 플랫폼으로부터 가져옵니다. 공기가락된 환경에서는 새 대체 호스트가 \"클러스터 구성 내보내기\"로 미리 초기화됩니다.\n\n대체 호스트의 kine-endpoint-reconciler가 리더의 hostMeta를 요청하고 리더에 의해 팔로워로 간주되지 않음을 확인하고, 대체 API를 통해 리더에게 자신의 존재를 알리게 됩니다. 이로써 리더는 자신의 hostMeta를 업데이트하여 새 호스트를 팔로워로 등록합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로, 대체 호스트는 강등에서 설명한 것과 동일한 방식으로 리더를 구독하며, 이는 리더의 kine 테이블 전체를 복제하게 됩니다.\n\n## 업그레이드\n\n업그레이드 중에는 승급 또는 강등이 없습니다(호스트는 원래의 역할을 유지), 그러나 리더가 다시 부팅하는 동안 필수적인 API 서버 다운 타임이 발생합니다. 다음 표는 업그레이드 중 발생하는 이벤트 순서를 보여줍니다:\n\n![Sequential Events during Upgrade](/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 개의 호스트는 시스템 업그레이드 컨트롤러 계획을 통해 모든 제어 평면 노드를 무작위 순서로 대상으로 업데이트됩니다. 업그레이드를 시작하기 전에 Go 에이전트가 각 호스트의 라이브니스 서비스를 일시 중지시킵니다. 이로써, 리더가 먼저 업그레이드되는 경우에 팔로워가 자신을 승격하지 못하도록합니다. 두 호스트가 모두 업그레이드된 후에는 그들의 라이브니스 서비스가 다시 시작됩니다.\n\n## 대체 업그레이드 흐름\n\n대체 업그레이드 흐름이 가능합니다. 여기서는 먼저 팔로워가 업그레이드되고, 그 후 호스트의 역할이 교환되어(팔로워 승격, 리더 강등) 원래의 리더가 업그레이드되는 흐름이 있습니다. 그러나 이러한 흐름은 매우 복잡하며 오류가 발생할 가능성이 있습니다. 첫째, 강등으로 인해 데이터베이스가 삭제되고 다시 동기화되어야 하므로, 위의 흐름을 선택했습니다.\n\n참고: 더 복잡한 흐름에서는 파드가 다시 균형을 이루는 데 걸리는 시간으로 인해 여전히 다운 타임이 있습니다. 아래 K8s 구성 옵션은 건강하지 않은 노드를 감지하고 해당 노드에서 파드가 추방될 때까지 걸리는 시간을 결정합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```json\nkube-controller-manager-arg:\n- node-monitor-period=5s\n- node-monitor-grace-period=20s\n```\n\n# HA 및 CAP 이론: 우리가 얼마나 잘 했을까요?\n\n소개에서는 CAP 이론과 솔루션의 (대부분) 고가용성에 대해 더 상세히 설명할 것을 약속했습니다. 제가 A\\*P라고 부르는 것입니다:\n\n- 일관성이 최종적으로 일치하기 때문에 일관성을 나타내는 C는 제외합니다.\n- 가용성을 나타내는 A에 별표가 붙는 이유는 프로모션, 강등 및 업그레이드 중에 일부 API 서버 다운타임이 발생하기 때문입니다 (벤치마크에 따르면 평균 4.5분). 그러나 팔로워에 배포된 어떠한 애플리케이션도 완전히 사용 가능할 것입니다. 이 아키텍처로 고가용성을 달성하기 위한 핵심은 모든 애플리케이션이 데몬셋이거나 적어도 하나의 레플리카가 각 노드에서 실행되도록 탑톨로지 분산 제약 조건을 가져야 한다는 것입니다. 롱혼은 상태 있는 애플리케이션을 위해 충돌 일관된 블록 스토리지를 제공하기 위해 쉽게 설치될 수 있습니다.\n- 파티션 허용도를 나타내는 P는 hostMeta의 lastModified 타임스탬프를 사용하여 처리됩니다. 네트워크 분할이 발생한 경우 두 호스트가 자체 프로모션합니다. 분할이 해소되면 가장 최근에 업데이트된 호스트가 \"승리\"합니다. 패배한 호스트는 자신을 강등시키고 승리자의 데이터베이스 내용을 복사합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n의심의 여지없이, 3 노드 Kubernetes 클러스터는 아마도 덜한 아키텍처 복잡성으로 더 강력한 보장을 제공하지만, 규모에 따라 상당한 자본 투자가 필요합니다. 자체 상자 비용 뿐만 아니라 케이블링, 배송, 소프트웨어, 전력 소비 등의 비용도 발생합니다. 비용을 최적화하거나 엣지 컴퓨팅 사용 사례를 고려 중이라면, 2 노드 솔루션이 즉시 비용을 절감하고 중요한 절감을 실현할 수 있을 것입니다.\n\n마지막으로, K3s, kine 및 NATS를 사용한 2 노드 솔루션을 추구하며 한계를 느낀 Synadia 팀으로부터 영감을 받았다는 점을 언급하지 않을 수 없습니다. 그들의 작품은 우리 자신의 계획을 영감주었습니다.\n\n이렇게 멀리까지 읽어주셔서 감사합니다. 궁금한 점이 있으면 직접 tyler@spectrocloud.com 으로 문의하거나 Spectro Cloud 커뮤니티 Slack을 확인해주시기 바랍니다.\n\n그리고 쿠버네티스를 활용한 엣지 컴퓨팅 프로젝트를 진행 중이라면, 당사의 Palette Edge를 살펴보시고 도움이 필요한 부분이 있는지 확인해주시기 바랍니다.\n","ogImage":{"url":"/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png"},"coverImage":"/assets/img/2024-05-23-Two-nodeHAKubernetesforedgecomputingcostsavings_0.png","tag":["Tech"],"readingTime":16},{"title":"Kubernetes에서 애플리케이션 배포, 확장 및 장애 조치 중에 건강 검사를 사용하는 방법","description":"","date":"2024-05-23 14:28","slug":"2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover","content":"\n![Health probes](/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png)\n\n헬스 프로브는 견고한 클러스터를 유지하는 중요한 부분입니다. 프로브를 사용하면 클러스터가 응답 여부를 반복적으로 조사하여 응용 프로그램의 상태를 결정할 수 있습니다.\n\n일련의 헬스 프로브는 클러스터가 다음 작업을 수행하는 능력에 영향을 미칩니다:\n\n- 실패 중인 팟을 자동으로 다시 시작을 시도하여 충돌 방지\n- 건강한 팟에게만 요청을 보내어 장애 극복 및 부하 분산\n- 팟이 실패하는 시기와 이유를 결정하여 모니터링\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 프로브 유형\n\n쿠버네티스는 다음과 같은 프로브를 제공합니다: 시작, 준비 및 활성화. 어플리케이션에 따라 하나 이상의 이러한 유형을 구성할 수 있습니다.\n\n## 준비 프로브\n\n준비 프로브는 어플리케이션이 요청을 처리할 준비가 되어 있는지 확인합니다. 준비 프로브가 실패하면 쿠버네티스가 해당 어플리케이션에 대한 클라이언트 트래픽이 도달하는 것을 방지하기 위해 서비스 리소스에서 포드의 IP 주소를 제거합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n준비성 검사는 애플리케이션에 영향을 미칠 수 있는 일시적 문제를 감지하는 데 도움을 줍니다. 예를 들어, 애플리케이션이 시작될 때 초기 네트워크 연결을 설정하거나 캐시에 파일을 로드하거나 완료하는 데 시간이 걸리는 초기 작업을 수행해야 하기 때문에 애플리케이션이 일시적으로 사용할 수 없을 수 있습니다. 애플리케이션이 가끔은 긴 일괄 작업을 실행해야 할 수도 있어 클라이언트에게 일시적으로 사용할 수 없게 만듭니다.\n\nKubernetes는 애플리케이션이 실패한 후에도 계속해서 검사를 실행합니다. 검사가 다시 성공하면 Kubernetes는 포드의 IP 주소를 서비스 리소스에 다시 추가하고 요청을 다시 해당 포드로 보냅니다.\n\n이러한 경우에 준비성 검사는 일시적 문제를 해결하고 애플리케이션 가용성을 향상시킵니다.\n\n## 생존성 검사\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n준비 프로브와 마찬가지로, 라이브니스 프로브는 응용 프로그램의 수명 동안 호출됩니다. 라이브니스 프로브는 응용 프로그램 컨테이너가 건강한 상태인지를 확인합니다. 응용 프로그램이 라이브니스 프로브에 충분한 횟수로 실패하면 클러스터는 다시 시작 정책에 따라 파드를 다시 시작합니다.\n\n시작 프로브와 달리, 라이브니스 프로브는 응용 프로그램의 초기 시작 프로세스 이후에 호출됩니다. 보통 이 조치는 파드를 다시 시작하거나 다시 만들어서 해결됩니다.\n\n## 시작 프로브\n\n시작 프로브는 응용 프로그램의 시작이 완료된 시점을 결정합니다. 라이브니스 프로브와 달리, 시작 프로브는 성공한 후에도 호출되지 않습니다. 설정 가능한 시간 초과 후에 시작 프로브가 성공하지 않으면, 해당 파드는 다시 시작 정책 값에 기반하여 다시 시작됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앱 시작 시간이 긴 애플리케이션에 스타트업 프로브를 추가하는 것을 고려해보세요. 스타트업 프로브를 사용하면 라이브니스 프로브를 짧고 빠르게 유지할 수 있습니다.\n\n# 테스트 유형\n\n프로브를 정의할 때 수행할 테스트 유형을 다음 중 하나로 지정해야 합니다:\n\nHTTP GET\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n각 번 업된 때는 물고기가 클러스터에게 지정된 HTTP 엔드포인트로 요청을 보냅니다. 요청에 대한 응답이 200에서 399 사이의 HTTP 응답 코드로 오면 테스트는 성공한 것으로 간주됩니다. 다른 응답은 테스트를 실패하게 만듭니다.\n\n컨테이너 명령어\n\n각 번 업된 때는 물고기가 컨테이너에서 지정된 명령어를 실행합니다. 명령이 0의 상태 코드로 종료되면 테스트가 성공합니다. 다른 상태 코드는 테스트에 실패하게 만듭니다.\n\nTCP 소켓\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프로브가 실행될 때마다 클러스터는 컨테이너에 소켓을 열려고 시도합니다. 연결이 수립되어야만 테스트가 성공합니다.\n\n# 시간과 임계값\n\n모든 유형의 프로브에는 시간 변수가 포함되어 있습니다. 주기 초 변수는 프로브가 실행되는 빈도를 정의합니다. 실패 임계값은 프로브 자체가 실패하기 전에 필요한 실패 시도 횟수를 정의합니다.\n\n예를 들어, 실패 임계값이 3이고 주기 초가 5인 프로브는 전체 프로브가 실패하기 전에 최대 세 번 실패할 수 있습니다. 이 프로브 구성을 사용하면 문제가 해결되기 전 10초 동안 문제가 발생할 수 있습니다. 그러나 너무 자주 프로브를 실행하면 리소스를 낭비할 수 있습니다. 프로브를 설정할 때 이러한 값을 고려해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예시 1\n\n```yaml\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-exec\nspec:\n  containers:\n    - name: liveness\n      image: registry.k8s.io/busybox\n      args:\n        - /bin/sh\n        - -c\n        - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600\n      livenessProbe:\n        exec:\n          command:\n            - cat\n            - /tmp/healthy\n        initialDelaySeconds: 5\n        periodSeconds: 5\n```\n\n예시 2\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-app-liveness-pod\nspec:\n  containers:\n    - name: hello-app-container\n      image: gcr.io/google-samples/hello-app:1.0 # 애플리케이션 이미지로 교체하세요\n      ports:\n        - containerPort: 8080 # 애플리케이션의 수신 포트와 일치해야 합니다\n      livenessProbe:\n        httpGet:\n          path: /\n          port: 8080\ninitialDelaySeconds: 15 # 컨테이너가 시작된 후 생존성 프로브가 시작되기까지의 시간(초)\nperiodSeconds: 10 # 프로브를 수행하는 주기(초)\ntimeoutSeconds: 1 # 응답을 기다리는 시간(초)\nfailureThreshold: 3 # 재시작하기 전에 허용되는 실패 횟수\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n오픈쉬프트에서 oc set probe 명령은 배포에 프로브를 추가하거나 수정합니다. 예를 들어, 다음 명령은 front-end라는 배포에 준비 상태 프로브를 추가합니다:\n\n```js\noc set probe deployment/front-end \\\n--readiness \\\n--failure-threshold 6 \\\n--period-seconds 10 \\\n--get-url http://:8080/healthz\n```\n\nset probe 명령은 RHOCP와 oc에만 존재합니다.\n","ogImage":{"url":"/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png"},"coverImage":"/assets/img/2024-05-23-HowKubernetesuseshealthprobesduringapplicationdeploymentscalingandfailover_0.png","tag":["Tech"],"readingTime":6},{"title":"Argo CD 리포지토리를 구조화하는 방법 Application Sets 사용하기","description":"","date":"2024-05-23 14:24","slug":"2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets","content":"\n\u003cimg src=\"/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png\" /\u003e\n\n시리즈의 이전 기사에서는 GitOps 환경을 모델링하고 응용 프로그램을 이 환경 간에 프로모션하는 방법을 설명했습니다. 그 기사는 단일 응용 프로그램과 해당 Kubernetes 리소스에 초점을 맞춰 작성되었습니다. 본 기사에서는 여러 관련 주제를 살펴보겠습니다:\n\n- Argo CD 애플리케이션 매니페스트를 넣는 위치\n- 여러 팀/클러스터/응용 프로그램과 어떻게 작업할 것인지\n- 더 쉬운 관리를 위해 Application Sets를 활용하는 방법\n- 단일 저장소 대신 GitOps 저장소를 분리하는 방법\n\n항상 그렇지만, 우리의 조언은 모범 사례를 따르는 일반적인 권장 사항입니다. 조직에 대한 시작점으로 활용할 수 있지만, 본인의 경우에 더 나은 접근 방식이 있다고 믿는다면, 언제든지 우리가 언급한 패턴을 본인의 환경에 맞게 적용하시기 바랍니다. 예시 저장소는 다음에서 확인할 수 있습니다: https://github.com/kostis-codefresh/many-appsets-demo\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앞선 기사는 매우 일반적이었고 Flux 사용자에게도 적용될 수 있지만, 여기서는 특히 Argo CD와 그 고급 기능에 초점을 맞출 것입니다.\n\n# 매니페스트의 다양한 유형\n\nArgo CD 애플리케이션을 조직하는 방법은 많은 자료와 블로그에서 다뤄지는 인기 있는 주제이며, 사용자들의 지속적인 질문과 토론이 있습니다. 불행히도 대부분의 기존 자료에서 다양한 매니페스트 유형을 혼합하며 응용 프로그램 세트와 그 기능에 대한 언급이 전혀 없습니다. \"매니페스트\"라는 용어는 Argo CD와 GitOps의 경우 오버로딩된 경우도 많습니다. 그래서 먼저 다양한 매니페스트 유형을 정의해봅시다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 카테고리는 Argo CD와 전혀 상관없는 표준 Kubernetes 자원(배포, 서비스, 인그레스, 구성, 시크릿 등)으로, 이러한 자원들은 쿠버네티스 클러스터에서 정의됩니다. 이러한 자원은 어플리케이션이 쿠버네티스 내에서 어떻게 실행되는지를 기술하며, Argo CD가 전혀 없는 로컬 클러스터에 어플리케이션을 설치하는 데 사용될 수 있습니다. 이러한 manifest는 개발자가 새로운 릴리스를 배포하면서 자주 변경되며, 일반적으로 다음과 같은 방법으로 지속적으로 업데이트됩니다:\n\n- 배포 manifest에서 컨테이너 이미지 버전을 업데이트하는 경우 (대부분의 경우 약 80%)\n- 컨테이너 이미지와 함께 configmap이나 시크릿에 대한 구성을 업데이트하는 경우 (대부분의 경우 약 15%)\n- 비즈니스 또는 기술 속성을 세부 조정하기 위해 구성만 업데이트하는 경우 (대부분의 경우 약 5%)\n\n이러한 manifest는 어플리케이션의 상태를 설명하기 때문에 개발자에게 매우 중요하며, 조직 환경(QA/Staging/Production 등)에서 모든 어플리케이션의 상태를 설명하는 데 사용됩니다. 프로모션 기사는 특히 이러한 유형의 manifest에 대해 언급했습니다.\n\n두 번째 카테고리는 Argo CD 어플리케이션 manifest입니다. 이들은 사실의 원천(첫 번째 유형의 manifest)과 해당 어플리케이션의 대상 및 동기화 정책을 참조하는 정책 설정입니다. Argo CD 어플리케이션은 근본적으로 Git 저장소(표준 Kubernetes manifest를 포함하는)와 대상 클러스터 간의 매우 간단한 링크입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_2](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_2.png)\n\n많은 사람들이 생각하는 것과는 달리, 개발자들은 이러한 유형의 manifest로 괴롭힘받길 원하지 않아요. 운영자들에게도 이 유형의 manifest는 한 번 설정하고 나면 그냥 잊어버릴 것입니다. 어플리케이션 세트 manifest 역시 동일한 범주에 속합니다.\n\n세 번째와 네 번째 범주는 첫 번째와 두 번째와 동일하지만, 이번에는 개발자들이 만드는 내부 애플리케이션 대신 인프라 애플리케이션(cert manager, nginx, coredns, prometheus 등)에 대해 이야기합니다.\n\n이 manifest에 대해 개발자의 애플리케이션과 다른 템플릿 시스템을 사용할 수 있습니다. 예를 들어, 준비된 애플리케이션에 대해서는 Helm을 사용하고, 개발자가 만든 애플리케이션에 대해서는 Kustomize를 선택하는 매우 인기 있는 패턴이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 4가지 종류의 manifests로 핵심 포커스는 아래 2가지 카테고리에 대한 것입니다.\n\n- 개발자들은 인프라 manifests에 대해 신경 쓰지 않습니다.\n- 이러한 manifests는 매우 자주 변경되지 않습니다. 보통 해당 구성 요소를 업그레이드하거나 매개 변수를 세밀하게 조정할 때에만 변경됩니다.\n\n여기서 중요한 점은 이 4가지 유형의 manifests가 대상 청중과 무엇보다도 변경 빈도 등 여러 측면에서 서로 다른 요구 사항을 갖고 있다는 것입니다. \"GitOps 리포지토리 구조\"에 대해 이야기할 때, 어떤 카테고리의 manifests에 대해 이야기하는 지 (다수일 경우) 항상 먼저 설명해야 합니다.\n\n# 안티 패턴 1 — 서로 다른 유형의 manifests 혼합\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가장 좋은 방법을 설명하기 전에 장기적으로 문제를 복잡하게 만들 수 있는 몇 가지 안티 패턴에 대해 경고하는 것이 중요합니다.\n\n매니페스트의 중요한 포인트 중 하나는 Kubernetes(카테고리 1)와 Argo CD 리소스(카테고리 2) 사이에 매우 명확한 분리를 가져야 한다는 것입니다. 편리하게, Argo CD에는 두 카테고리를 섞을 수 있게 해주는 여러 기능이 있습니다. 일부 극히 드문 경우에는 필요하지만, 다른 유형의 매니페스트를 섞는 것을 권장하지 않습니다.\n\n간단히 예를 들어, Argo CD는 다음과 같은 구문을 지원합니다:\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-helm-override\n  namespace: argocd\nspec:\n  project: default\n\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    path: my-chart\n\n\n    helm:\n      # 이렇게 하지 말아주세요\n      parameters:\n      - name: \"my-example-setting-1\"\n        value: my-value1\n      - name: \"my-example-setting-2\"\n        value: \"my-value2\"\n        forceString: true # 값이 문자열로 처리되도록 보장\n\n\n      # 이렇게 하지 말아주세요\n      values: |\n        ingress:\n          enabled: true\n          path: /\n          hosts:\n            - mydomain.example.com\n\n\n      # 이렇게 하지 말아주세요\n      valuesObject:\n        image:\n          repository: docker.io/example/my-app\n          tag: 0.1\n          pullPolicy: IfNotPresent\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 매니페스트는 두 가지를 동시에 수행합니다. 주 파일은 Argo 앱(카테고리 2)에 관한 내용이지만, \"helm\" 속성은 실제로 Kubernetes 응용 프로그램(카테고리 1)에 대한 값들을 포함하고 있습니다.\n\n이 매니페스트는 다음과 같이 차트와 동일한 Git 저장소에 있는 값 파일에 모든 매개변수를 넣음으로써 쉽게 수정할 수 있습니다.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-helm-override\n  namespace: argocd\nspec:\n  project: default\n\n\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    path: my-chart\n\n\n    helm:\n      ## 이렇게 하세요 (Git의 값 파일 개별로)\n      valueFiles:\n      - values-production.yaml\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n또한 Helm 어머렐라 차트를 사용하는 경우, 다른 차트를 참조하고 해당 값들을 재정의할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n외부 차트(즉, Git에 저장되지 않은)를 사용하는 것도 가능하지만, 우리가 추천하는 방법은 아닙니다. 제3자 소스에서 외부 차트를 사용하는 것은 보안 및 안정성 측면에서 많은 도전점을 제시합니다.\n\n이상적으로 모든 Helm 차트는 귀하의 통제 하에 있어야 하며 Git에 있어야 합니다. 이렇게 하면 GitOps의 모든 이점을 얻을 수 있습니다.\n\n하지만 때로는 이게 불가능한 경우도 있습니다. 그래서 최후 수단으로만 외부 Helm 차트를 참조하면서 여전히 로컬에 저장된 자체 값을 사용할 수 있습니다. 이 가이드를 작성하는 시점에 이 기능이 베타 버전임을 유의하십시오.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-proper-helm-app\n  namespace: argocd\nspec:\n  sources:\n  - repoURL: 'https://my-chart/helm-charts'\n    chart: my-helm-chart\n    targetRevision: 3.7.1\n    helm:\n      valueFiles:\n      - $values/my-chart-values/values-prod.yaml\n    ## DO THIS (values in Git on their own)\n  - repoURL: 'https://git.example.com/org/value-files.git'\n    targetRevision: dev\n    ref: values\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마찬가지로 Argo CD는 다음을 지원합니다:\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-kustomize-override\n  namespace: argocd\nspec:\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    path: my-app\n\n    # 이렇게 하지 마세요\n    kustomize:\n      namePrefix: prod-\n      images:\n      - docker.io/example/my-app:0.2\n      namespace: custom-namespace\n\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n여기서 Kustomize의 속성들(category 1)이 다시 주 응용 프로그램 매니페스트 (category 2)와 섞입니다. 이를 피하기 위해 Kustomize 값을 웹 애플리케이션 CRD에 하드 코딩하는 대신 오버레이로 저장하는 것이 좋습니다.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-proper-kustomize-app\n  namespace: argocd\nspec:\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: HEAD\n    ## 이렇게 하세요. Kustomize 오버레이에 모든 값을 저장하세요\n    path: my-app/overlays/prod\n\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 여러분의 매니페스트가 올바르게 분할되었는지 이해하기 위한 리트머스 테스트는 다음 질문을 하는 것입니다:\n\n\"만약 개발자가 Kubernetes 리소스에 대해 전문가이지만 Argo CD에 대해서는 전혀 모른다면, 오직 kustomize(또는 Helm)만을 사용하여 자신의 노트북에 애플리케이션을 설치할 수 있을까요?\"\n\n만약 답이 \"아니오\"라면, 그렇다면 여러분은 Kubernetes 매니페스트가 Argo CD 애플리케이션과 어우러져 있는 부분을 찾아내고 강력한 결합을 제거해야 합니다.\n\n매니페스트를 혼합하는 함정에 빠져들어가 있는 기관들을 많이 보았습니다. 대화를 나눌 때 거의 항상, 그 기관들은 이러한 접근 방식이 \"필요하다\"고 생각했던 것입니다. 왜냐하면 그들은 기반이 되는 도구들(Helm/Kustomize)의 능력을 제대로 이해하지 못했기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n귀하의 조직이 Helm과 작업하는 경우, Helm 값 계층이 어떻게 작동하는지, 그리고 Helm 어머니 차트가 어떻게 작동하는지 알아야 합니다. 신중하게 설계된 Helm 값 계층으로 대부분의 일반적인 시나리오를 다룰 수 있습니다. Argo CD의 다중 소스 기능을 사용해야 할 경우에만 사용하세요. 그리고 현재 베타 버전이라는 것을 기억하세요.\n\n귀하의 조직이 Kustomize와 작업하는 경우, 구성 요소(재사용 가능한 블록)의 작동 방식과 모든 다양한 변환기/패치/대체 방법을 알아야 합니다.\n\n나중 장에서 볼 수 있듯이 두 종류의 manifest를 구분하는 것은 좋은 실천 방법입니다. 그러나 이전 섹션에 표시된 표에서는 생명 주기가 다른 것들을 섞는 것이 항상 문제의 원인임을 명백히 알 수 있어야 합니다.\n\n다른 종류의 manifest를 섞는 것에는 여러 가지 다른 도전과제가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 모든 관련 당사자들이 이해하기 어렵게 만듭니다.\n- 매니페스트를 사용하는 사람들(예: 개발자)과 매니페스트를 생성하는 사람들(즉, 관리자/운영자) 사이의 요구사항을 혼란스럽게 합니다.\n- 매니페스트를 특정 Argo CD 기능에 결합시킵니다.\n- 보안 관련 문제를 분리하기가 더 복잡해집니다.\n- 더 많은 부분들을 움직이게 하고 디버깅하기 어려운 시나리오를 야기합니다.\n- 개발자들에 대한 로컬 테스트를 더 어렵게 만듭니다.\n\n참고: 사용하지 말아야 할 다른 Argo CD 기능은 파라미터 오버라이드입니다. 가장 원시적인 형태에서 심지어 GitOps 원칙을 따르지 않습니다. Git에 저장해도 Argo CD와 쿠버네티스 정보가 동일한 위치에 혼합되어 있게 됩니다(카테고리 1 및 카테고리 2 정보 혼합).\n\n# 안티 패턴 2 — 잘못된 추상화 수준에서 작업\n\nArgo CD 애플리케이션 CRD의 목적은 주요 쿠버네티스 매니페스트를 '래퍼' 또는 '포인터'로 작동하는 것입니다. 중요한 것은 쿠버네티스 매니페스트(카테고리 1)와 Argo CD 매니페스트(카테고리 2)가 언제나 보조 역할을 해야 한다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이상적인 경우에는 한 번 Application manifest를 만들어서 어떤 Git 저장소가 어떤 클러스터로 이동하는지 정의하고 이 파일을 다시는 손대지 않는 것이 좋습니다 (이것이 이전 테이블에서 변경 빈도가 \"거의 없음\"인 이유입니다).\n\n안타깝게도 많은 회사들이 실제 쿠버네티스 manifest 대신에 Application CRD를 주 작업 단위로 사용하는 것을 볼 수 있습니다.\n\n전형적인 예로는 CI 프로세스를 사용하여 Application의 \"targetRevision\" (또는 \"path\") 필드를 자동으로 업데이트하는 경우가 있습니다.\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  ## 이렇게 하지 마세요\n  name: my-ever-changing-app\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/example-org/example-repo.git\n    targetRevision: dev\n    ## 이전에는 \"targetRevision: staging\"이었고, 그 이전에는 \"targetRevision: 1.0.0\"였으며,\n    ## 그보다 전에는 \"targetRevision: 1.0.0-rc\" 였습니다.\n    path: my-staging-app\n    ## 이전에는 \"path: my-qa-app\"이었습니다.\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-app\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어플리케이션 CRD를 계속 변경되는 가변 파일로 취급하는 것은 몇 가지 근본적인 문제와 나쁜 관행을 내포하고 있음을 의미합니다. 예를 들어, 대상 리비전 필드를 계속 다른 브랜치로 지정하는 것은 거의 항상 조직이 환경에 대해 브랜치를 사용하고 있는 것을 의미하는데 이는 강력히 권하지 않는 관례입니다.\n\n이것은 또한 Git 리포지토리 자체를 보는 것이 원하는 상태가 무엇인지 명확하게 나타내지 않는다는 것을 의미합니다. 대신, 각 응용 프로그램은 이해하고 전체 그림을 위해 다른 Git 리포지토리와 비교해야 하는 별도의 대상 리비전을 가질 수 있습니다.\n\nArgo CD 어플리케이션은 임의의 응용 프로그램을 실행하는 데 사용할 수 있는 재사용 가능한 상자가 아닙니다. GitOps의 핵심은 어플리케이션이 수행한 이벤트에 대한 명확한 이력을 가지는 것입니다. 하지만 어플리케이션 CRD를 완전히 다른 매니페스트를 가리키는 일반화된 작업 단위로 취급한다면 GitOps의 주요 이점 중 하나를 잃게 됩니다.\n\n대부분의 경우에는 CRD 대신에 백그라운드에 있는 쿠버네티스 매니페스트 자체를 변경해야 합니다. 예를 들어, 어플리케이션 이미지 CRD가 가리키는 쿠버네티스 배포 리소스 위에 정방향으로 새로운 앱 이미지를 가진 브랜치로 대상 리비전 필드를 변경하는 대신에 변경해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 안티패턴 3 — 다른/다중 레벨에서 템플릿 사용하는 것\n\n이전 안티패턴의 친척에 해당하는 것은 Application CRD (카테고리 2)에서 템플릿 기능을 적용하는 것입니다. Helm과 Kustomize는 이미 매우 강력한 도구이며 주요 Kubernetes 매니페스트에 대한 템플릿을 처리할 수 있습니다 (카테고리 1). 그리고 사용 사례가 해당되지 않더라도 사용자 정의 구성 플러그인을 사용하거나 좋아하는 외부 도구로 매니페스트를 사전 렌더링할 수 있습니다.\n\n문제는 사람들이 Application CRD를 템플릿화하려고 시도할 때 시작됩니다. 왜냐하면 그들은 이전 안티패턴에 의해 생성된 문제를 해결하려고 하기 때문입니다.\n\n이곳의 전형적인 예는 일팀이 Helm 차트를 생성하고 해당 Helm 차트가 Kubernetes 매니페스트의 Helm 차트를 가리키는 Application CRD를 포함할 때 발생합니다. 이제 동시에 두 가지 다른 수준에서 Helm 템플릿을 적용하려고 하게 됩니다. 그리고 Argo CD 풋프린트가 커질수록 새로 온 사람들이 매니페스트가 어떻게 구조화되어 있는지 이해하기가 매우 어렵습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nArgo CD에는 Application CRD에 대한 강력한 템플릿 메커니즘이 포함되어 있지 않다는 사실은 이 워크플로우를 권장하지 않음을 강력히 시사해야합니다. 또한 ApplicationSets(다음 항목 참조)이 소개되면서 템플릿을 적용해야 하는 적절한 위치는 개별 Application 파일이 아니라 ApplicationSet입니다.\n\n# 안티패턴 4 — Application Sets를 사용하지 않는 경우\n\n우리는 Application 매니페스트 (카테고리 2)에 대해 많이 이야기했으며 무엇을 하지 말아야 하는지에 대한 내용도 많았습니다. 이 기사의 주된 포인트는 여기에 있습니다. 이상적으로, Application CRD를 전혀 생성할 필요가 없어야합니다.🙂\n\n만약 비트 trivial한 Argo CD 설치가 있다면, 꼭 ApplicationSets가 어떻게 작동하는지 이해하고, 최소한 Git 생성기와 클러스터 생성기를 동시에 결합하는 방법을 공부해야합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어플리케이션 세트는 모든 애플리케이션 매니페스트(카테고리 2)의 생성을 담당할 수 있어요. 예를 들어, 20개의 애플리케이션과 5개의 클러스터가 있다면, Argo CD 애플리케이션을 위한 100가지 조합을 자동으로 생성해줄 수 있는 단일 어플리케이션 세트 파일을 만들 수 있어요.\n\nGitOps 인증에서 가져온 예제가 있어요.\n\n```js\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: cluster-git\nspec:\n  generators:\n    # matrix 'parent' generator\n    - matrix:\n        generators:\n          # Git generator, 'child' #1\n          - git:\n              repoURL: https://github.com/codefresh-contrib/gitops-cert-level-2-examples.git\n              revision: HEAD\n              directories:\n                - path: application-sets/example-apps/*\n          # cluster generator, 'child' #2\n          - clusters: {}\n  template:\n    metadata:\n      name: '{path.basename}-{name}'\n    spec:\n      project: default\n      source:\n        repoURL: https://github.com/codefresh-contrib/gitops-cert-level-2-examples.git\n        targetRevision: HEAD\n        path: '{path}'\n      destination:\n        server: '{server}'\n        namespace: '{path.basename}'\n```\n\n이 생성기는 \"application-sets/example-apps\" 아래의 모든 앱을 Argo CD에 정의된 모든 클러스터에 배포하라고 말해요. 현재 연결된 클러스터 수나 Git 레포지토리에 있는 애플리케이션 수가 얼마나 많든 상관없어요. 어플리케이션 세트 생성기는 가능한 모든 조합을 자동으로 생성하며 새로운 클러스터나 새로운 애플리케이션을 추가할 때도 계속해서 재배포할 거에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nArgo CD Autopilot에 익숙한 분들은 이 패턴을 알아볼 수 있을 것입니다. 이는 모노레포 관점에서의 기본 설정입니다.\n\n애플리케이션 세트가 필요한 기본 템플릿을 지원한다는 점에 유의해주세요. 이를 통해 메인 Kubernetes 매니페스트에는 여전히 Helm/Kustomize를 유지하면서 Application CRD에 대해 어느 정도 유연성을 가질 수 있습니다. 또한 애플리케이션 세트에 대한 Go 템플릿 지원을 놓치지 않도록 주의하세요.\n\n모든 애플리케이션에 대해 하나의 ApplicationSet을 사용해야 하는 것은 아닙니다. 각 애플리케이션의 \"타입\"에 대해 여러 개의 세트를 사용할 수도 있습니다. 여기서 \"타입\"이 의미하는 바는 당신의 경우에 따라 다를 것입니다.\n\n# 최선의 방법 — 세 단계의 구조 사용하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전 섹션에서는 권장하지 않는 몇 가지 방법과 피해야 할 몇 가지 함정을 살펴보았습니다. 이제 우리의 제안하는 해결책에 대해 이야기할 준비가 되었습니다.\n\n시작점은 아래 이미지에 표시된 대로 3단계 구조여야 합니다.\n\n![아이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_3.png)\n\n가장 낮은 수준에서는 응용 프로그램이 실행되는 방식을 정의하는 Kubernetes manifest(매니페스트)가 있습니다(매니페스트의 카테고리 1). 이러한 매니페스트는 Kustomize 또는 Helm 템플릿이며 완전히 자체 포함되어 있어 Argo CD가 없어도 어떤 클러스터에서든 별도로 배포될 수 있습니다. 이 파일들의 구조에 대해서는 프로모션 블로그 게시물에서 자세히 다루었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전 섹션에서 설명한 대로 한 단계 위에는 응용 프로그램 세트가 있습니다. 이들은 주요 Kubernetes 매니페스트를 Argo CD 응용 프로그램(category 2 of manifests)으로 감싸줍니다. 대부분의 경우에는 개별 응용프로그램 CRD(Application CRDs)를 만들 필요 없이 ApplicationSets만 만들면 됩니다.\n\n마지막으로 선택적 구성 요소로, 모든 응용 프로그램 세트를 App-of-App에 그룹화하여 완전히 비어 있는 클러스터에 모든 응용 프로그램을 부트스트래핑할 수 있습니다. 만일 클러스터를 만드는 다른 방법이 있다면(예: terraform/pulumi/crossplane), 이 수준이 항상 필수적이지 않을 수 있습니다.\n\n그게 전부에요!\n\n이 패턴이 얼마나 간단한지에 주목하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 추상화 수준은 단 3개뿐이에요. 4개나 5개를 가진 회사들도 있지만, 그렇게 되면 메탈 모델이 훨씬 복잡해져요.\n- 각 수준은 완전히 독립적이에요. 쿠버네티스 Manifest를 별도로 설치할 수도 있고, 특정 애플리케이션 세트를 선택할 수도 있고, 모든 것을 최상위에서 선택할 수도 있어요. 하지만 선택은 당신의 몫이에요.\n- Helm과 Kustomize는 쿠버네티스 Manifest에서만 한 번 사용돼요. 이것 때문에 템플릿 시스템을 이해하기 정말 쉬워져요.\n\n실제 예시를 살펴봐요. 아래 링크에서 예시 리포지토리를 찾을 수 있어요. https://github.com/kostis-codefresh/many-appsets-demo\n\n![2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_4.png](https://example.com/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_4.png)\n\n여기서 우리는 쿠버네티스 Manifest를 \"apps\" 폴더에, 애플리케이션 세트를 \"appsets\" 폴더에 두기로 선택했어요. 이름이 중요한 건 아니에요. 무슨 일이 일어나고 있는지 명확하게 알면 무엇이든 선택할 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"앱\" 디렉터리에는 표준 Kubernetes 매니페스트가 저장됩니다. 이 예제에서는 Kustomize를 사용하고 있습니다. 각 애플리케이션마다 해당 환경에 대한 오버레이만 있습니다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_5.png)\n\n이 구조에 대한 자세한 내용은 프로모션 블로그 게시물에 설명되어 있습니다.\n\n전체 구조를 살펴보면 각 환경이 \"apps/앱이름/envs/환경이름\" 디렉터리에 배치된다는 점이 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앱세트 폴더에는 모든 애플리케이션 세트가 보관됩니다. 이 간단한 예제에서는 단순한 목록이지만 더 복잡한 예제에서는 조직을 더 잘하기 위해 여기에 폴더도 있을 수 있습니다.\n\n![ArgoCD Repository Structure](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_6.png)\n\n각 애플리케이션 세트는 단순히 Kubernetes 매니페스트에서 정의된 overlays를 언급합니다. 여기에 \"qa\" 앱세트의 예가 있습니다.\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: my-qa-appset\n  namespace: argocd\nspec:\n  goTemplate: true\n  goTemplateOptions: [\"missingkey=error\"]\n  generators:\n    - git:\n      repoURL: https://github.com/kostis-codefresh/many-appsets-demo.git\n      revision: HEAD\n      directories:\n        - path: apps/*/envs/qa\n  template:\n  metadata:\n    name: \"{index .path.segments 1}-{index .path.segments 3}\"\n  spec:\n    # 애플리케이션이 속한 프로젝트입니다.\n    project: default\n\n    # 애플리케이션 매니페스트의 소스\n    source:\n      repoURL: https://github.com/kostis-codefresh/many-appsets-demo.git\n      targetRevision: HEAD\n      path: \"{.path.path}\"\n\n    # 애플리케이션을 배포할 대상 클러스터 및 네임스페이스\n    destination:\n      server: https://kubernetes.default.svc\n      namespace: \"{index .path.segments 1}-{index .path.segments 3}\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 응용 프로그램 설정은 다음과 같이 말합니다:\n\n\"앱 폴더로 이동하십시오. 앱을 포함하는 모든 폴더를 검색하고 하위 폴더 envs/qa가 있는 경우 Argo CD 앱을 생성하십시오.\" 이 앱세트는 \"qa\" 오버레이가 있는 QA 클러스터 앱에만 배포됩니다. 이 오버레이가 없는 앱은 배포되지 않습니다. 앱 폴더를 살펴보면 모든 환경에 모든 앱이 배포되지 않음을 알 수 있습니다. 예를 들어 \"billing\"은 프로덕션에만 배포되고 \"fake-invoices\"는 QA에만 있습니다.\n\n또한 별도의 app-of-apps 매니페스트가 있으며 이것은 단순히 모든 앱 세트를 그룹화하는 데 도움이 됩니다. 이것은 엄격히 필수는 아니지만 빈 클러스터를 처음부터 모두 구성하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예시에서 우리는 딱 한 개의 매니페스트만으로 12개의 애플리케이션을 배포했어요 (이는 애플리케이션 세트가 만드는 조합의 수입니다) 한 번에요.\n\n이 인위적인 데모 저장소는 모든 \"환경\"에 대해 단일 클러스터를 사용합니다. 프로덕션 설정에서는 모든 애플리케이션을 각각의 클러스터(qa/prod/staging)로 분리하기 위해 클러스터 생성기도 사용할 수 있어요.\n\n# Argo CD 애플리케이션의 두 번째 날 운영\n\n그렇다면 이 구조가 최적일까요? 이전 섹션의 데모 저장소를 사용하여 일반적인 시나리오를 살펴보고 얼마나 간단한지 확인해보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전 장에서는 쿠버네티스 매니페스트(카테고리 1)와 Argo CD 매니페스트(카테고리 2)를 분리해야 한다는 주장을 했습니다. 이 결정의 주요 목표는 개발자들의 삶을 쉽게 만들고 공통 시나리오를 돕는 데 있습니다. 개발자를 위해 몇 가지 예시를 살펴보겠습니다:\n\n시나리오 1 — 개발자가 \"invoices\" 앱의 \"qa\" 구성을 검사하고 싶어 합니다.\n\n해결책 1:\n\n```js\ncd apps/invoices\nkustomize build envs/qa\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해당 문제는 한 줄의 명령어로 해결할 수 있으며 Argo CD 설치가 필요하지 않습니다.\n\n시나리오 2 — 개발자가 \"billing\" 앱의 미국과 유럽 간에 어떤 설정이 다른지 이해하려고 합니다.\n\n해결책 2:\n\n```js\ncd apps/billing\nkustomize build envs/prod-eu/\u003e /tmp/eu.yml\nkustomize build envs/prod-us/ \u003e /tmp/us.yml\nvimdiff /tmp/eu.yml /tmp/us.yml\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해결책은 3개의 명령어이며 Argo CD 설치가 필요하지 않습니다.\n\n시나리오 3 — 개발자가 \"orders\" 애플리케이션의 \"qa\" 환경설정을 로컬 클러스터에 설치하려고 합니다.\n\n해결책 3:\n\n```js\ncd apps/orders\nkubectl apply -k -f envs/qa\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다시 한 번, Argo CD 설치가 필요하지 않습니다.\n\n만약 다양한 유형의 manifest를 혼합한다면, 개발자들도 Argo CD를 다뤄야 할 수도 있습니다. Argo CD로 로컬 테스트를 진행하는 것은 Kubernetes 클러스터를 사용하는 것보다 훨씬 복잡합니다.\n\n관리자/운영자들에게도 매우 간단한 일입니다. 대부분의 작업은 클러스터와 어플리케이션의 수에 관계없이 단일 파일/폴더에서 단일 변경만으로 이루어집니다.\n\n예를 들어, 관리자가 \"payments\" 어플리케이션을 QA 환경에 배포하려고 한다고 가정해보겠습니다 (현재는 프로드 환경에서만 실행 중인 상태입니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncd apps/payment/env\nmkdir qa\n\u003cqa를 위한 k8s manifest 생성\u003e\n\u003cArgo CD 동기화를 기다립니다\u003e\n```\n\n관리자가 원하는 모든 작업은 간단한 Git 작업에 해당합니다.\n\n- 기존 애플리케이션을 새 환경에 배포 - Kustomize overlay를 생성합니다. Argo CD 변경은 필요하지 않습니다.\n- 환경에서 애플리케이션 제거 - 해당 Kustomize overlay를 삭제합니다. Argo CD 변경은 필요하지 않습니다.\n- 새로운 애플리케이션 생성 - \"apps\" 폴더 아래 새 폴더에 K8s manifest를 커밋합니다. Argo CD 변경은 필요하지 않습니다.\n- \"integration\"이라는 새로운 환경 생성 - qa를 기반으로 \"integration\" 애플리케이션 세트를 새 파일로 복사/수정합니다. 다음 동기화에서 Argo CD는 \"integration\" 오버레이를 가진 모든 애플리케이션에 대해 새로운 조합을 생성합니다.\n- 새 클러스터 추가 - 클러스터를 Argo CD에 연결하면 해당 클러스터를 참조하는 모든 applicationset이 자동으로 애플리케이션을 해당 클러스터에 배포합니다.\n- 클러스터를 다른 환경으로 이동 - 해당하는 애플리케이션 세트에 새 라벨을 추가/편집하세요.\n\n이곳의 핵심은 명료한 manifest의 분리를 유지하고 있습니다. 개발자들은 Argo CD가 어떤 모델링을 하고 있는지 알 필요 없이 일반 쿠버네티스 리소스와 작업할 수 있으며, 관리자들은 applicationset과 폴더를 사용하여 쉽게 애플리케이션을 환경 간에 이동할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기존 환경에 대한 새로운 클러스터를 빠르게 설정하는 것은 정말 쉽습니다. 해당 클러스터 생성기에 추가하기만 하면 됩니다.\n\n# Monorepo, Monorepo, Monorepo\n\n이전 섹션에서 공유한 예제 저장소는 모든 애플리케이션이 어떤 식으로든 관련이 있다고 가정합니다. 아마도 그것들이 더 큰 애플리케이션의 일부이거나 동일한 팀에서 처리하는 것일지도 모릅니다.\n\n큰 조직에서는 여러 애플리케이션이 있고 완전히 다른 요구 사항과 제약 조건을 가진 여러 팀이 있습니다. 많은 팀이 여러 Git 저장소를 사용할지 또는 모든 애플리케이션에 대해 단일 저장소(monorepo)를 사용할지에 대한 선택에 고민합니다. 물론, 여기에서도 우리만의 권장 사항이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"우선 'Monorepo'가 무엇을 의미하는지를 우리가 정의하는 것이 매우 중요합니다. 왜냐하면 많은 관리자와 개발자와의 토론을 통해 백그라운드에 따라 단어의 의미가 다른 것을 명확하게 알 수 있기 때문입니다.\n\n기본적으로 우리는 사람들이 'monorepo'를 특정 Git 조직 구조로 부르는 3가지 다른 영역을 발견했습니다.\n\n개발자들은 주로 소스 코드를 구성할 때 'monorepo'를 언급합니다. 애플리케이션마다 하나의 저장소를 갖는 대신, 일부 팀은 조직 내 모든 애플리케이션의 소스 코드를 그룹화하는 단일 저장소를 선택합니다. 이 기술은 구글에서 지난 수십 년 동안 인기를 얻었으며 'monorepo'에 대한 대부분의 온라인 자료들은 주로 이 기술에 대해 이야기합니다.\n\n여기서 중요한 점은 이 정의가 소스 코드에만 해당한다는 것입니다. Argo CD는 소스 코드를 다루지 않으므로 이러한 방식에 대해 장단점을 언급하는 자료들은 실제로 Argo CD와 관련이 없습니다. 유감스럽게도, Argo CD를 채택할 때 이러한 유형의 기사를 참고하는 관리자들이 많이 보이며 이들은 Argo CD가 쿠버네티스 매니페스트를 관리하는 맥락에서 이러한 소스 코드 기술이 알맞지 않다는 것을 이해하지 못합니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"모노 리포\"에 대한 두 번째 정의는 소스 코드와 쿠버네티스 매니페스트 및 Argo CD 매니페스트를 동시에 포함하는 Git 저장소를 사람들이 \"모노 리포\"라고 설명하는 경우입니다. 이 기술은 Argo CD와 관련이 있지만, 여러 번 소스 코드와 매니페스트를 분리하는 것을 권장해왔습니다. 이 정의를 전체성을 위해 언급하는 것뿐이며, 몇몇 팀이 \"Argo CD 애플리케이션에 모노 리포를 사용한다\"고 말하는 경우가 있으며, 실제로는 Git 저장소가 매니페스트와 소스 코드를 모두 포함한다는 것을 의미하는 것입니다 (필수적으로 조직 전체에 대한 단일 Git 저장소를 사용하는 것은 아닙니다).\n\n\"모노 리포\"의 세 번째 정의이자 본 문서에서 중요하게 다루는 것은 조직이 모든 Argo CD 애플리케이션을 위한 단일 Git 저장소를 갖는 경우입니다. 이 저장소에는 소스 코드가 없지만, 중요한 점은 완전히 관련이 없는 경우에도 모든 배포된 애플리케이션을 포함한다는 것입니다. 그렇다면 이것이 좋은 방법인가요 아닌가요?\n\n# 최상의 방법 - 팀 당 Git 저장소 사용\n\n지난 섹션의 마지막 정의에 따라 정의된 모노 리포는 Argo CD 애플리케이션이 증가함에 따라 발생하는 여러 가지 확장성 및 성능 문제가 있습니다. Argo CD는 이미 모노 리포를 다루기 위한 여러 메커니즘을 가지고 있지만, 더 많은 팀이 Argo CD를 채택함에 따라 문제를 해결하지 말고, 미리 예방하는 것이 좋습니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n단일 모노리포는 Argo CD 여정을 시작할 때 취할 수 있는 매우 논리적인 결정입니다. 단일 저장소를 갖는 것은 유지 보수와 관측성 측면에서 일을 쉽게 만듭니다. 그러나 장기적으로는 Argo CD가 커밋을 감지하는 방식 뿐만 아니라 Git 저장소가 다양한 워크플로와 충돌 및 재시도를 처리하는 방식에도 제약 사항이 몇 가지 있습니다.\n\n저희의 권장사항은 여러 개의 Git 저장소를 사용하는 것입니다. 이상적으로는 각 팀 또는 각 부서에 하나씩 있어야 합니다. 다시 말해 항상 스스로 질문해야 할 기본 질문은 Git 저장소에 포함된 응용 프로그램이 어떤 방식으로 관련되어 있는지입니다. 그것들이 마이크로 서비스이며 더 큰 응용 프로그램의 일부이거나 단일 팀에서 사용하는 해제된 구성 요소일 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_7.png)\n\n여러 개의 Git 저장소의 장점은 성능과 사용성 측면 모두에서 명백합니다. 특히 개발자들에게는, 다수의 Git 저장소가 선호됩니다. 그들은 자신의 팀에 속하지 않는 응용 프로그램들을 다루지 않고 자신들의 Kubernetes 매니페스트에 집중할 수 있기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 인프라 어플리케이션은 어떻게 할까요?\n\n우리는 Kubernetes manifest(분류 1) 및 Argo CD 리소스(분류 2)에 대해 많이 이야기했습니다. 인프라 어플리케이션(분류 3 및 4)은 어떨까요? 어디에 배치해야 할까요?\n\n인프라 매니페스트를 개발자 어플리케이션과 같은 방식으로 저장할 수 있습니다. 이전 섹션에서 언급한 3단계 구조를 사용하세요. 그러나 반드시 기억해야 할 점은 이 매니페스트를 개발자가 필요한 매니페스트와 혼합해서는 안 된다는 것입니다. 그리고 이들을 분리하는 가장 좋은 방법은 다른 Git 저장소를 갖는 것입니다.\n\n인프라 어플리케이션과 개발자 어플리케이션을 동일한 Git 리포지토리에 혼합하지 마세요. 다시 말하지만, 이것은 Argo CD 성능에 도움이 되는 것뿐만 아니라 개발자를 돕는 좋은 기술입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전 이미지를 업데이트하고 인프라 애플리케이션을 처리하는 팀을 위한 또 다른 Git 저장소를 포함할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_8.png)\n\n이러한 방식으로 팀 내 개발자로서 나는 내가 관심 있는 것만 포함한 Git 저장소를 체크아웃할 수 있습니다. 해당 Argo CD 애플리케이션은 빠르며 이 Git 저장소에 영향을 미치는 CI 시스템 역시 빠릅니다. Git 충돌이 최소화되며 추가적인 보안 제약을 적용하려면 Git 공급 업체에서 제공하는 기존 Git 메커니즘을 사용할 수 있습니다.\n\n많은 애플리케이션과 팀이 있을 경우 어떤 공통 애플리케이션을 공유해야 할 필요성을 느낄 수 있습니다. 이를 처리하는 방법은 여러 가지가 있습니다. 빠른 방법 중 하나는 다른 팀의 매니페스트를 참조하는 Application Set를 사용하는 것입니다. 또 다른 방법은 모든 팀에서 필요로 하는 애플리케이션을 위해 \"공통\" Git 저장소를 사용하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앞으로의 글에서는 Git 서브모듈을 사용하여 두 가지 유형의 매니페스트에 대한 고급 시나리오와 공유 기술을 더 많이 다룰 예정입니다.\n\n# 요약\n\nArgo CD 애플리케이션을 구성하고 관리하기 위해 Application Sets를 활용하는 방법에 대한 포괄적인 안내서가 끝났습니다.\n\n다룬 내용은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 쿠버네티스와 Argo CD manifest의 다른 종류는 무엇인가요?\n- 이러한 manifest의 서로 다른 라이프사이클을 이해하는 것이 합리적한 이유는 무엇인가요?\n- Argo CD 애플리케이션 세트가 어떻게 작동하는지\n- 상호 연결된 애플리케이션 세트의 간단한 3단계 구조를 적용하는 방법은 무엇인가요?\n- 피해야 할 일반적인 함정은 무엇일까요?\n- 인프라 애플리케이션을 다루는 방법은 무엇인가요?\n- 서로 다른 팀을 위해 GitOps 리포지토리를 분할하는 방법은 무엇인가요?\n\nGitOps 리포지토리를 조직하는 방법에 대해 잘 이해하셨길 바라요. Argo CD에 오신 것을 환영합니다 🙂\n\n(Unsplash의 Breno Assis 사진 참고)\n","ogImage":{"url":"/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png"},"coverImage":"/assets/img/2024-05-23-HowtoStructureYourArgoCDRepositoriesUsingApplicationSets_0.png","tag":["Tech"],"readingTime":32},{"title":"기술 원더랜드의 문을 열어보세요 GitOps, 플랫폼 및 AI를 결합해 보세요","description":"","date":"2024-05-23 14:21","slug":"2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI","content":"\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e2024-05-23\u003c/td\u003e\n    \u003ctd\u003eUnlocking your Tech Wonderland by combining GitOps, Platforms, and AI\u003c/td\u003e\n    \u003ctd\u003e0.png\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n지난 몇 년 동안 많은 기술이 등장하고 사라지는 과정을 지켜봤고, 많은 사람들과 기업이 클라우드 네이티브 여정을 함께했습니다. 종종 듣는 말들 중에는 \"왜 쿠버네티스는 복잡한가요?\"와 \"문제 XYZ를 해결할 하나의 해결책만 없는 이유는 무엇인가요?\"라는 것들이 있었습니다. 동시에 플랫폼 엔지니어링과 AI가 현재 떠오르고 있는데, 저는 이 세 가지 주제가 서로 관련이 있다고 생각하기 때문에 함께 자세히 살펴보도록 하겠습니다.\n\n# 쿠버네티스의 등장 및 왜 그것이 복잡한가\n\n쿠버네티스는 응용 프로그램 인프라를 구축하기 위한 플랫폼 오케스트레이터로, 기반이 되는 인프라에 신경 쓰지 않고 기반을 만들도록 돕습니다. 우리가 조명을 비추면 (저는 예전 시스템 엔지니어로서) 익숙한 것들이 많이 보일 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 시스템에서 잘 알려진 운영 절차들을 위한 추상화: Kubernetes에서 객체를 생성할 때, 우리는 과거에 우리가 한 것을 설명만 할 뿐입니다. 예를 들어, 인그레스 객체를 만들 때, 시스템에게 \"이 패턴과 일치하는 트래픽을 이 서비스로 전달하는 역방향 프록시를 구성해주세요\" 라고 말합니다. 파드 객체를 만들 때, 우리는 시스템에게 유닉스 네임스페이스를 생성하고 그 안에 프로세스를 캡슐화하며 환경 변수, 요청, 제한 등을 설정하도록 지시합니다.\n- 컨테이너: 컨테이너 개념은 완전히 새로운 것은 아니며 그 주변에 마법도 없습니다. 우리는 BSD jails로부터 이를 배웠고, OpenVZ나 LXC로 컨테이너를 만들었으며 마침내 Docker로 그 가능성을 확장했습니다.\n- 확장성과 탄력성: 시스템 엔지니어로서, 저는 종종 더 강력하고 확장 가능한 시스템을 만들기 위해 직면했습니다. 과거에 우리는 이를 위해 어떤 모험적인 구성을 만들었고, 많은 사람들은 클러스터 관리자, 부하 분산, 복제 및 하트비트 메커니즘과 맞닥뜨렸을 것입니다. 그들은 일을 잘했지만 구성하기 쉽지 않았고 종종 스스로 문제를 일으켰습니다. 익숙한 느낌이겠죠?\n\n제가 쿠버네티스 여정을 시작했을 때, 과거의 이러한 문제들을 보고 이를 해결해주는 것을 발견했습니다. 예를 들어, 간단한 구성 객체로 서비스를 여러 노드에 분산해서 로드 밸런싱할 수 있고, 수백 개의 노드로 자동으로 확장할 수 있습니다. 사실, 이러한 메커니즘들이 다소 무섭게 느껴질 수 있지만 결국에는 이를 배우고 시스템에 적용하는 것은 매우 간단합니다.\n\n아래 그림은 쿠버네티스로 가능한 자동화의 일부를 보여줍니다. 이 예시는 여러 컴포넌트에 작업 수행을 지시하는 매니페스트를 한 번에 만들 수 있다는 것을 보여줍니다. 이 경우에는 클러스터로의 인그레스 경로 생성, TLS 인증서 발급, 특정 호스트 이름을 위한 DNS 이름 생성 등이 될 것입니다. 물론, 이러한 지점에 도달하기 위해 약간의 구성 작업이 필요하지만 (전에 언급한 예시들보다는 훨씬 적습니다), 결국에는 복잡한 것들을 아주 간단한 방법으로 사용할 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n몇 년 전, Kelsey Hightower가 한 게시물에서 다음과 같이 썼어요:\n\n\"이것이란 암시적으로는 우리가 쿠버네티스를 애플리케이션을 배포하는 데 사용할 수 있다는 것을 의미하지만, 실제로 우리가 플랫폼을 구축하는 데 도움이 되는 플랫폼으로 고려하면 더 많은 것을 얻을 수 있습니다. 이로 인해 다음 질문에 이르게 됩니다:\"\n\n# 문제 XYZ를 해결할 수 있는 하나의 해결책만 있는 이유는 무엇인가요?\n\n쿠버네티스와 클라우드 네이티브 주변에 엄청난 생태계가 형성되었고, 많은 도구들이 사람들이 문제를 해결하는 데 도움을 줬어요. 우리가 그림 1에서 본 것처럼, 인그레스 오브젝트를 통해 들어오는 네트워크 트래픽을 구성하고, 인증서를 요청하거나 쿠버네티스 컨트롤러를 통해 DNS 항목을 구성하는 것은 오늘날 매우 간단해졌어요. 시간이 지남에 따라 많은 도구들이 이 생태계에 합류했고, 종종 사람들은 왜 같은 문제를 해결하는 것처럼 보이는 다양한 도구들이 존재하는지 묻곤 해요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Tech Wonderland](/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_2.png)\n\nG. Hohpe’s book “Cloud Strategy”에서 회사에 가장 적합한 클라우드 공급업체를 찾는 데 관한 인용문을 발견했습니다.\n\n나는 클라우드 네이티브 랜드스케이프에 대해서도 동일하게 생각합니다(도표 2 참조). 다양한 옵션이 있지만 일부는 귀하의 요구 사항(및 전략)에 더 잘 맞을 수 있고 다른 일부는 그렇지 않을 수 있습니다. 예를 들어, 섬세하고 명료한 접근 방식을 따르는 도구를 선택할 수 있지만, 구성하거나 자체 의견을 구현할 수 있도록 지원해주는 도구도 있을 수 있습니다. 또한, 모든 것이 지원에 관한 문제일 수 있습니다. 가장 좋은 커뮤니티 주도형 오픈 소스 프로젝트가 제품마다 24/7 벤더 지원이 필요하다는 회사 정책을 준수해야 하는 경우에는 귀하의 요구 사항과 일치하지 않을 수 있습니다.\n\n우리는 이러한 것들을 끊임없이 진행할 수 있다고 상상할 수 있다고 생각하지만, 랜드스케이프의 각 도구는 더 많은 아이디어를 제공하며 더 많은 옵션을 제공하고(항상 그것들이 필요하지 않을 수 있지만) 귀하의 응용 프로그램에 대한 견고한 플랫폼을 구축하는 데 도움을 줍니다. 이를 통해 내가 좋아하는 이야기의 핵심인 플랫폼 엔지니어링으로 진행하고 싶습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 플랫폼 엔지니어링의 등장\n\n지난 두 섹션에서는 왜 사람들이 쿠버네티스를 복잡하게 생각하는지 (내 의견으로는 그렇지 않다고 생각합니다) 그리고 비슷한 문제를 해결하기 위해 수많은 도구가 있는 이유에 대해 설명했습니다. 이제 이러한 구성 요소들을 함께 조합해서 왜 쿠버네티스 위에 플랫폼을 구축하는 것이 절대적으로 의미가 있는지 알아보겠습니다.\n\n몇 년 전으로 돌아가서 회사들이 쿠버네티스를 채택하기 시작했던 시점에 대해 생각해 봅시다. 어떤 사람들은 새로운 멋진 기술(플랫폼 오케스트레이터)에 대해 들었고 이 기술을 기술 스택에 도입하고 싶어했습니다. 이 기간 동안 kubectl을 사용하여 응용 프로그램을 배포하고, 해당 플랫폼 구성 요소를 설치하고, Helm이라는 패키지 관리자에 대해 배워서 실천을 시작했습니다. 대기업의 경우, 이 일은 많은 기능 팀들에 의해 수행되었을 수 있고, 어느 순간에 회사는 이러한 것들을 함께 두어야 한다고 결정했습니다. 이 시점에서 다음과 같은 질문들에 직면하게 됩니다:\n\n- 어떻게 해야만 할 수 있을까요? 응용 프로그램 A의 리소스 소비가 응용 프로그램 B의 것과 간섭하지 않게 보장할까요?\n- 인그레스 컨트롤러로 ingress-nginx 또는 traefik을 사용해야 할까요? 그리고 누가 리소스를 마이그레이션해야 할까요?\n- 응용 프로그램 팀이 현재 사용 중인 5가지 메커니즘 중에서 선택해야 할 때 어떻게 응용 프로그램을 배포해야 할까요?\n- 개발자로서 클라우드 환경에서 데이터베이스를 사용하고 싶습니다. 어떤 것을 선택해야 할까요? 또 누가 그것을 관리해야 할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n독립적인 응용 프로그램 팀마다 도구 스택에 약간의 노력을 기울였다고 상상해보세요. 대부분의 팀은 그것에 만족하고 있습니다. 그러나 이 방식으로 진행하면 확장이 잘 되지 않을 수 있으므로, 개발팀을 더 쉽게 만들고 제품 관리자를 더 만족시키기 위해 일부 사전 정의된 빌딩 블록을 사용하는 것이 합리적일 수 있습니다. 여러분의 플랫폼 엔지니어링 여정이 시작되었습니다.\n\nMartin Fowler와 Evan Bottcher는 이렇게 플랫폼을 정의합니다:\n\n다음과 같이 관련 부분으로 나눠봅시다:\n\n- 플랫폼은 기반이다: 개발자들의 운영 부담과 기초 작업을 줄이고, 플랫폼에서 제공되는 몇 가지 요소가 개발자들이 직접 만들어야 할 것이라는 점을 원합니다.\n- 셀프 서비스 API: 개발자들은 셀프 서비스 API를 통해 플랫폼을 사용할 수 있어야 합니다. 제 의견으로는 이것이 RESTful API일 수도 있지만, Kubernetes 객체로 구성돼 Git 리포지토리에 커밋되고 승인된 것이라면 안심할 수도 있습니다.\n- 도구: 플랫폼을 사용하는 데 필요한 모든 것\n- 서비스: 개발자들이 제품을 제공하는 데 도움이 되는 플랫폼의 일부인 것들, 예를 들어 시크릿 관리, 데이터베이스, 배달 도구, 메시지 큐잉 등\n- 지식과 지원: 플랫폼을 사용하는 사람들을 돕는 사항 및 서비스\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nIT에서 배운 한가지는 우리가 종종 무언가를 한 번 이상, 때로는 여러 차례 만들어낸다는 것입니다. 많은 경우, 우리는 이전에 만들어둔 인프라를 청사진으로 사용하고 많은 것을 반복합니다. 유감스럽게도, 이는 종종 해결책과 가끔은 유지보수가 잘 되지 않는 것들을 포함합니다. 플랫폼 접근 방식으로 수렴하는 것은 시간이 지남에 따라 개선될 수 있는 패턴 및 템플릿 카탈로그를 구축하는 데 도움이 될 수 있습니다 (각 IaC 템플릿을 버전화된 서비스로 생각해 보세요). 넓은 범위에서 적용될 때 해결책을 줄이는 데 관심 있는 많은 사람들이 있습니다. 플랫폼을 강아지집을 짓는 데 필요한 모든 도구 및 자재를 제공하는 도구 시장으로 생각해 보세요. 더 나아가, 프로젝트를 돕는 영업사원들과 문서가 있을 수 있습니다.\n\n![image](/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_3.png)\n\n플랫폼을 구축할 때 주요 주제 중 하나는 배포 전략입니다. 이는 시작부터 여러 가지 질문을 던지며 여러 가지 방법으로 플랫폼을 결정할 수 있습니다. 예를 들어, 어떤 서비스를 어떤 클라우드에서 제공할 것이며 어떻게 실행할 것인지 등의 질문에 대해 다룰 수 있습니다. 작은 예로, 모든 애플리케이션을 Kubernetes에서 제공하고 데이터베이스와 같은 종속 지원 서비스를 제공 업체의 PaaS 서비스로 사용하고 싶다는 결론에 도달할 수 있습니다. 이로 인해 다음과 같은 플랫폼 관련 솔루션이 나오게 됩니다:\n\n- 플랫폼 기능을 제공하는 방법\n- 애플리케이션 및 인프라 구성요소를 제공하는 방법\n- 솔루션 카탈로그의 첫 부분\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nIaC 솔루션과 소프트웨어를 전달하는 GitOps Controller에 자주 의존하는 편입니다. 이러한 솔루션을 기반으로 몇 가지 더 궁금증이 생길 것입니다. 예를 들어, 비밀 정보는 어떻게 전달할까요? DNS 항목은 어떻게 다룰까요? 버전 관리는 어떻게 진행할까요? 이러한 질문 목록은 끝없이 계속될 수 있으며 어떤 질문은 먼저 나오고 다른 것은 나준히 알려질 것입니다. 배포 전략은 현재 사용 가능한 애플리케이션과 해당 현재 메커니즘에 따라 당연히 달라질 것입니다. 그러나 애플리케이션과 배포 전략을 통해 지금까지 생각하지 못했을지도 모를 여백과 문제점을 찾게 될 것입니다. 하나의 중요한 포인트는 전달할 아티팩트의 유형과 표준화할 수 있는 방법입니다. 예를 들어, 컨테이너를 전달하고 배포 설명에 대한 내부 표준(예: manifests 및 helm charts)이 있는 경우 모든 것이 더 쉬워집니다.\n\n이 모든 과정을 거치면서 플랫폼은 발전하고 해당 구조를 정의하게 될 것입니다. Figure 4는 프로덕션 시스템에서 고려해야 할 내용의 예시를 보여줍니다. 개발자 포털을 통해 템플릿 활용 및 서비스에 대한 통찰력을 얻을 수 있으며 정보를 저장하는 리포지토리, 또한 서비스 인터페이스 및 개발자가 서비스에서 사용할 수 있는 서비스도 포함됩니다.\n\n이러한 플랫폼은 개발자에게 엄청난 가치를 제공할 수 있지만, 이들을 강요하여 그들이 만족하지 않는 프로세스에 밀어 넣어서는 안된다는 점을 명심해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 개발자를 배려하며 과거를 생각해보기\n\n플랫폼을 제공할 때, 주요 이해관계자는 그것을 사용하는 개발자들입니다. 따라서, 그들을 염두에 두고 그들의 의견을 물어보고 플랫폼 사용에 대해 교육해야 합니다. 또한, 사람들이 자신의 도구를 선택하고 이러한 방식으로 것들을 구축한 이유가 있습니다. 이로 인해 플랫폼 구축은 일상적인 해결책이 아니지만 여정에서 도움이 되는 패턴이 있습니다.\n\n- 플랫폼의 일부분으로 사람들을 만들기: 질문에 대한 답변을 얻고 최선을 다해 문제를 해결하고 싶어하는 사람들이 있을 수 있습니다. 사람들은 기술에 대해 이야기하는 것을 좋아하며, 서로 이야기를 나누면 더 나은 해결책을 찾을 수 있습니다.\n- 오픈/내부 소싱: 공유할 수 있는 아티팩트(예: 인프라 템플릿 및 구성)를 만들 때, 이를 회사 내에서 전역적으로 공유하고 다른 팀이 재사용할 수 있도록 하는 것이 유용할 수 있습니다. 이 경우, 모범 사례와 패턴이 수립되어 사람들이 전진하는 데 도움이 될 것입니다. 또한, 사람들은 풀/머지 요청을 제출하고 플랫폼에 기여할 수 있습니다.\n- 커뮤니티 구축: 내부 모임을 개최하고, 플랫폼을 기반으로 한 시스템을 소개하고 성공을 전달하세요. 이렇게 하면 플랫폼이 부각되고 해당 주제에 더 많은 사람들이 끌리게 될 것입니다.\n\n또한, 모든 회사는 각자의 역사, 내부 가치 및 프로세스를 가지고 있습니다. 플랫폼 구축을 시작할 때, 이를 염두에 두고 사람들을 어떻게 차지할지 알아보려고 노력해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# AI에 대해 다루는 제목을 보면서 함께 멋진 것들에 대해 이야기해주셨네요!\n\n그동안 AI와 무슨 상관이 있는지, 그리고 여러분의 여정에서 어떻게 도움을 줄 수 있는지 궁금해하셨을 수도 있습니다. 이 기사의 처음에는 Kubernetes의 복잡성과 왜 일부 사람들이 어려워하는지에 대해 이야기했습니다. Kubernetes와 함께 작업하는 사람들을 돕기 위해 많은 노력이 기울여지고 있지만, 경험 많은 엔지니어조차도 문제를 해결하는 것에 어려움을 겪을 수 있습니다.\n\nKubernetes와 AI 영역에서의 최초 프로젝트 중 하나인 K8sGPT는 Kubernetes 환경의 문제 해결을 돕기 위해 시작되었습니다. 따라서 Kubernetes 클러스터에서 간단한 명령(k8sgpt analyze — explain)을 실행하면, 다양한 AI 제공 업체를 기반으로 한 잘못된 구성과 그 해결책을 찾을 수 있습니다. 또한 Developer Portals인 Backstage에서도 사용될 수 있을 것입니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_5.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 것들은 다양한 다른 도구들과 결합할 수 있습니다. 예를 들어, GitOps 도구를 사용하여 애플리케이션을 전달하고 분석을 실행한 후, 애플리케이션이 제대로 작동하는지 확인할 수 있습니다. 이와 같은 문제를 감지하고 자동으로 해결하기 위한 노력이 이미 있습니다. 내 최근 데모 중 하나에서는 GitOps 컨트롤러를 사용하여 애플리케이션을 배포하고, Keptn을 사용하여 기능을 유효성 검사하고, K8sGPT를 내장하여 배포에서 문제를 찾아내었습니다.\n\n# 요약\n\n본문은 플랫폼이 클라우드 네이티브 여정에서 어떻게 도와줄 수 있는지와 어떤 문제를 해결하는지에 대한 개요를 제공했어요. 시작할 때는 Kubernetes의 복잡성에 대한 대략적인 개요가 있었습니다. 그 후에는 대규모 클라우드 네이티브 생태계에 대해 이야기했고, 모든 것은 플랫폼으로 이어지도록 조합되었습니다. 이 섹션에서 배송 전략에 대해 작업하는 것이 문제를 해결하고(새로운 문제를 찾아내는 것이 가능) 도움이 된다는 것을 배웠습니다. 또한 플랫폼 구축과 표준화는 대부분 사람들에 관한 것이라는 것도 알게 되었습니다. 마지막으로 플랫폼에서의 AI와 Kubernetes의 복잡성을 줄일 수 있는 방법에 대해 알아보았습니다.\n\n# 참고문헌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Hohpe, G. (2020). Cloud Strategy: A Decision-Based Approach to Successful Cloud Migration.\n- CNCF Platforms Working Group. (2023). CNCF Platforms Whitepaper. [https://tag-app-delivery.cncf.io/whitepapers/platforms/](https://tag-app-delivery.cncf.io/whitepapers/platforms/)\n- K8sGPT, [https://k8sgpt.ai](https://k8sgpt.ai)\n- Backstage K8sGPT Plugin, [https://github.com/suxess-it/backstage-plugin-k8sgpt/blob/main/README.md](https://github.com/suxess-it/backstage-plugin-k8sgpt/blob/main/README.md)\n","ogImage":{"url":"/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_0.png"},"coverImage":"/assets/img/2024-05-23-UnlockingyourTechWonderlandbycombiningGitOpsPlatformsandAI_0.png","tag":["Tech"],"readingTime":12},{"title":" 쿠버네티스에서 Vault 사용 방법 안내 ","description":"","date":"2024-05-23 14:19","slug":"2024-05-23-AHand-OnGuidetoVaultinKubernetes","content":"\n## ⇢ 실용적인 예제로 HashiCorp Vault를 사용하여 k8s Secrets 관리하기\n\n![image](/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_0.png)\n\n쿠버네티스 세계에서 API 키, 비밀번호 및 기타 중요 정보와 같은 보안 정보를 관리하는 것은 매우 중요한 작업입니다. 쿠버네티스에는 내장된 보안 정보 관리 메커니즘이 있지만, 모든 조직의 보안 요구 사항을 충족시키지 못할 수도 있는 특정 제한 사항이 있습니다. 예를 들어, 쿠버네티스 보안 정보는 etcd에 저장되며, 이는 휴식 중 암호화되어 있지만, 매우 중요한 정보에 필요한 보안 수준과 접근 제어를 제공하지 못할 수 있습니다.\n\n이때 HashiCorp Vault가 등장합니다. Vault는 중요한 정보를 안전하게 저장하고 관리하기 위해 설계된 도구입니다. 동적 보안 정보, 서비스로의 암호화 및 접근 제어를 위한 견고한 메커니즘을 제공하여, 쿠버네티스 환경에서 보안 정보를 관리하기에 이상적인 솔루션입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 튜토리얼에서는 Helm을 사용하여 쿠버네티스 클러스터에 Vault를 설치하고 구성하는 단계를 안내합니다. 그리고 Pod를 배포하여 Vault에서 비밀을 액세스할 수 있도록합니다. 이 안내서를 마치면 쿠버네티스 클러스터에 작동하는 Vault 설정이 완료되어 응용 프로그램 비밀을 안전하게 관리할 수 있습니다.\n\n# 전제 조건\n\n시작하기 전에 다음 사항을 확인하세요:\n\n- 실행 중인 쿠버네티스 클러스터가 있어야 합니다.\n- 클러스터와 상호 작용하도록 구성된 kubectl이 있어야 합니다.\n- 로컬 머신에 Helm이 설치되어 있어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*jmt8bsoEGeVHv5ZUP7XY_Q.gif\" /\u003e\n\n# 보르트(Namespace) 네임스페이스 생성하기\n\n우선, 보르트(Vault)를 위한 별도의 네임스페이스를 생성해야 합니다. 이렇게 하면 보르트에 특화된 리소스를 독립적으로 관리할 수 있습니다.\n\n```js\n$ kubectl create ns vault\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Vault 설치\n\n우리는 HashiCorp가 제공하는 Helm 차트를 사용하여 Vault의 최신 버전을 설치할 것입니다. 이 작업을 수행하는 두 가지 방법이 있습니다: 1. HashiCorp Helm 리포지토리를 사용하여 직접 Helm 설치 명령어를 실행하거나 2. Helm 차트를 다운로드하여 로컬로 설치하는 방법이 있습니다.\n\n## 1. HashiCorp Helm 리포지토리 추가\n\nHashiCorp Helm 리포지토리를 Helm 구성에 추가해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nhelm repo add hashicorp https://helm.releases.hashicorp.com\n```\n\n## 2. 설치 방법\n\n1. 직접 Helm 설치 실행하기\n\n다음 명령어를 사용하여 HashiCorp 저장소에서 Helm 차트를 사용하여 Vault를 직접 설치할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nhelm install vault hashicorp/vault \\\n       --set='server.dev.enabled=true' \\\n       --set='ui.enabled=true' \\\n       --set='ui.serviceType=LoadBalancer' \\\n       --namespace vault\n```\n\n2. Helm 차트 다운로드 및 설치\n\n대안으로 Helm 차트를 다운로드하고 로컬로 설치할 수 있습니다:\n\n```js\n# Helm 차트 다운로드\nhelm pull hashicorp/vault --untar\n\n# 다운로드한 차트를 사용하여 Vault 설치\nhelm install vault \\\n       --set='server.dev.enabled=true' \\\n       --set='ui.enabled=true' \\\n       --set='ui.serviceType=LoadBalancer' \\\n       --namespace vault \\\n       ./vault-chart\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 설정을 사용하여 UI가 활성화된 Vault를 개발 모드로 설치하고 외부에서 액세스하기 위해 LoadBalancer 서비스를 통해 노출합니다. 이 설정은 테스트 및 개발 목적으로 이상적입니다.\n\n결과:\n\n```js\n$ kubectl get all -n vault\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/vault-0                                 1/1     Running   0          2m39s\npod/vault-agent-injector-8497dd4457-8jgcm   1/1     Running   0          2m39s\n\nNAME                               TYPE           CLUSTER-IP       EXTERNAL-IP    PORT(S)             AGE\nservice/vault                      ClusterIP      10.245.225.169   \u003cnone\u003e         8200/TCP,8201/TCP   2m40s\nservice/vault-agent-injector-svc   ClusterIP      10.245.32.56     \u003cnone\u003e         443/TCP             2m40s\nservice/vault-internal             ClusterIP      None             \u003cnone\u003e         8200/TCP,8201/TCP   2m40s\nservice/vault-ui                   LoadBalancer   10.245.103.246   24.132.59.59   8200:31764/TCP      2m40s\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/vault-agent-injector   1/1     1            1           2m40s\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/vault-agent-injector-8497dd4457   1         1         1       2m40s\n\nNAME                     READY   AGE\nstatefulset.apps/vault   1/1     2m40s\n```\n\n# Vault 구성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이번 단계에서는 Kubernetes 클러스터 내에서 안전하게 비밀을 관리하고 액세스하기 위해 Vault 정책과 인증 방법을 설정할 것입니다. 이 구성은 인증된 애플리케이션만 Vault에서 민감한 데이터를 검색할 수 있도록 보장합니다.\n\n## 1. Vault Pod에 연결하기\n\n설치가 완료된 후 Vault pod에 연결하여 초기 구성을 수행하세요:\n\n```js\nkubectl exec -it vault-0 -- /bin/sh\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2. 정책 생성 및 적용하기\n\n이제 비밀을 읽을 수 있는 정책을 생성하겠습니다. 이 정책은 역할에 첨부되어 특정 Kubernetes 서비스 계정에 액세스 권한을 부여하는 데 사용될 수 있습니다.\n\n정책 파일을 생성하세요:\n\n```js\ncat \u003c\u003cEOF \u003e /home/vault/read-policy.hcl\npath \"secret*\" {\n  capabilities = [\"read\"]\n}\nEOF\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 정책을 적용해주세요:\n\n```js\n# 문법\n$ vault policy write \u003c정책명\u003e /정책/경로/여기에.hcl\n\n# 예시\n$ vault policy write read-policy /home/vault/read-policy.hcl\n```\n\n## 3. Kubernetes 인증 활성화\n\nVault에서 Kubernetes 인증 방법을 활성화하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nvault auth enable kubernetes\n```\n\n## 4. Kubernetes 인증 설정\n\nVault가 Kubernetes API 서버와 통신하도록 구성합니다:\n\n```js\nvault write auth/kubernetes/config \\\n   token_reviewer_jwt=\"$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)\" \\\n   kubernetes_host=https://${KUBERNETES_PORT_443_TCP_ADDR}:443 \\\n   kubernetes_ca_cert=@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 5. 역할 생성\n\n특정 네임스페이스에 있는 쿠버네티스 서비스 계정(vault-serviceaccount)에 위에서 만든 정책을 바인딩하는 역할(vault-role)을 생성합니다. 이를 통해 서비스 계정이 Vault에 저장된 시크릿에 액세스할 수 있게 됩니다:\n\n```js\nvault write auth/kubernetes/role/vault-role \\\n   bound_service_account_names=vault-serviceaccount \\\n   bound_service_account_namespaces=vault \\\n   policies=read-policy \\\n   ttl=1h\n```\n\n여기서 여러 개의 서비스 계정과 네임스페이스를 전달할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```bash\nvault write auth/kubernetes/role/\u003cmy-role\u003e \\\n   bound_service_account_names=sa1, sa2 \\\n   bound_service_account_namespaces=namespace1, namespace2 \\\n   policies=\u003cpolicy-name\u003e \\\n   ttl=1h\n```\n\n# 보안 정보 만들기\n\n이제 Vault에 일부 보안 정보를 만들어 보겠습니다:\n\n우리는 두 가지 방법으로 보안 정보를 만들 수 있어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Vault CLI를 사용하기\n\n## 1. Vault CLI 사용하기\n\n아래 명령어를 사용하여 시크릿을 생성하세요\n\n```js\n$ vault kv put secret/login pattoken=ytbuytbytbf765rb65u56rv\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 명령어를 사용하여 시크릿을 나열하여 비밀을 확인할 수 있습니다:\n\n```js\n$ vault kv list secret\nKeys\n----\nlogin\n```\n\n## 2. Vault UI 사용 방법\n\nVault 네임스페이스에서 서비스를 나열하여 로드 밸런서의 외부 IP를 얻을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ kubectl get svc -n vault\nNAME                       TYPE           CLUSTER-IP       EXTERNAL-IP    PORT(S)             AGE\nvault                      ClusterIP      10.245.139.117   \u003cnone\u003e         8200/TCP,8201/TCP   28h\nvault-agent-injector-svc   ClusterIP      10.245.58.140    \u003cnone\u003e         443/TCP             28h\nvault-internal             ClusterIP      None             \u003cnone\u003e         8200/TCP,8201/TCP   28h\nvault-ui                   LoadBalancer   10.245.11.13     24.123.49.59   8200:32273/TCP      26h\n```\n\n위의 로드밸런서의 외부 IP를 사용하여 Vault UI에 액세스하실 수 있습니다.\n\n예: `external-ip`:8200\n\n제 경우: 24.123.49.59:8200\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_1.png\" /\u003e\n\n이제 토큰 방법을 사용하여 Vault에 로그인할 수 있습니다. 초기에는 Token=root를 사용하여 로그인하십시오.\n\n이제 Vault UI에서 시크릿 대시보드를 사용하여 시크릿을 생성할 수 있습니다.\n\n시크릿 엔진으로 이동하세요 '` 시크릿`\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_2.png\" /\u003e\n\n그런 다음 오른쪽 상단의 \"비밀 생성(Create Secret)\"을 클릭하세요.\n\n\u003cimg src=\"/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_3.png\" /\u003e\n\n이제 비밀을 만들기 위해 원하는 필드를 입력하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 명령어를 사용하여 Vault CLI에서 위의 비밀을 액세스할 수도 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ vault kv list secret\nKeys\n----\nlogin\nmy-first-secret\n```\n\n쿠버네티스 클러스터에 Vault를 성공적으로 설치하고 구성했습니다. 이제 Vault를 사용하여 쿠버네티스에서 실행 중인 응용 프로그램의 비밀을 관리할 수 있습니다.\n\n# 쿠버네티스 Pod에서 비밀 액세스\n\n위 단계를 사용하여 Vault를 설치하고 Vault 역할(vault-role)을 구성하여 서비스 계정(vault-serviceaccount)이 Vault에 저장된 비밀에 액세스할 수 있도록 했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, login과 my-first-secret이라는 키-값 쌍을 가진 두 개의 시크릿을 생성했습니다. 이제 간단한 쿠버네티스 배포를 생성하고 이러한 시크릿에 액세스해 보겠습니다.\n\n먼저, vault 네임스페이스에 vault-serviceaccount라는 서비스 계정을 생성합니다. 이 서비스 계정은 위에서 정의한 \"Role 생성\" 단계에서 정의된 Vault 역할에 대한 권한이 부여됩니다.\n\n아래 매니페스트 파일을 vault-sa.yaml로 저장합니다.\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: vault-serviceaccount\n  labels:\n    app: read-vault-secret\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 명령을 사용하여 위에 제공된 매니페스트를 적용하세요.\n\n```js\nkubectl apply -f vault-sa.yaml\n```\n\n이제 아래 매니페스트 파일을 사용하여 간단한 배포(vault-secret-test-deploy.yaml)를 생성해 봅시다.\n\n이 배포 매니페스트는 Vault에서 시크릿을 안전하게 가져오도록 구성된 Nginx 파드의 단일 레플리카를 생성합니다. Vault 에이전트는 지정된 템플릿에 따라 시크릿인 login 및 my-first-secret을 파드에 주입합니다. 시크릿은 파드 파일 시스템에 저장되어 컨테이너에서 실행 중인 응용 프로그램에서 액세스할 수 있습니다. Vault와 인증하기 위해 필요한 권한을 갖고 있는 vault-serviceaccount 서비스 어카운트가 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어노테이션 섹션을 자세히 살펴보면 그 목적과 기능을 이해할 수 있습니다.\n\n```js\nannotations:\n        vault.hashicorp.com/agent-inject: \"true\"\n        vault.hashicorp.com/agent-inject-status: \"update\"\n        vault.hashicorp.com/agent-inject-secret-login: \"secret/login\"\n        vault.hashicorp.com/agent-inject-template-login: |\n          {- with secret \"secret/login\" -}\n          pattoken={ .Data.data.pattoken }\n          {- end }\n        vault.hashicorp.com/agent-inject-secret-my-first-secret: \"secret/my-first-secret\"\n        vault.hashicorp.com/agent-inject-template-my-first-secret: |\n          {- with secret \"secret/my-first-secret\" -}\n          username={ .Data.data.username }\n          password={ .Data.data.password }\n          {- end }\n        vault.hashicorp.com/role: \"vault-role\"\n```\n\n이러한 어노테이션은 Vault 에이전트를 구성하여 시크릿을 파드 볼륨에 주입하는 데 사용됩니다.\n\n- vault.hashicorp.com/agent-inject: “true”: 이 파드에 대한 Vault 에이전트 주입을 활성화합니다.\n- vault.hashicorp.com/agent-inject-status: “update”: 시크릿 주입 상태가 업데이트되도록 보장합니다.\n- vault.hashicorp.com/agent-inject-secret-login: “secret/login”: Vault에 저장된 secret/login의 시크릿을 주입해야 함을 지정합니다.\n- vault.hashicorp.com/agent-inject-template-login: 주입된 로그인 시크릿의 템플릿을 정의하여 시크릿이 기록될 형식을 지정합니다.\n- vault.hashicorp.com/agent-inject-secret-my-first-secret: “secret/my-first-secret”: Vault에 저장된 secret/my-first-secret의 시크릿을 주입해야 함을 지정합니다.\n- vault.hashicorp.com/agent-inject-template-my-first-secret: 주입된 my-first-secret에 대한 템플릿을 정의하여 시크릿이 기록될 형식을 지정합니다.\n- vault.hashicorp.com/role: “vault-role”: 인증에 사용될 Vault 역할을 지정합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 명령어를 사용하여 pod 볼륨에서 Vault 시크릿을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n$ kubectl exec -it vault-test-84d9dc9986-gcxfv -- sh -c \"cat /vault/secrets/login \u0026\u0026 cat /vault/secrets/my-first-secret\" -n vault\n```\n\n```js\n$ kubectl exec -it vault-test-84d9dc9986-gcxfv -- sh -c \"cat /vault/secrets/login \u0026\u0026 cat /vault/secrets/my-first-secret\" -n vault\n\nDefaulted container \"nginx\" out of: nginx, vault-agent, vault-agent-init (init)\npattoken=ytbuytbytbf765rb65u56rv\nusername=anvesh\npassword=anveshpassword\n```\n\n완료되었습니다! Vault에 시크릿을 성공적으로 생성하고 해당 시크릿을 팟 내에서 활용했습니다.\n\n# 소스 코드\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 텍스트를 한국어로 번역하였습니다.\n\n친구야! 당신을 우리의 GitHub 저장소로 초대합니다. 거기에는 Kubernetes용 소스 코드의 포괄적인 컬렉션이 저장되어 있어요.\n\n또한, 여러분의 피드백과 제안을 환영합니다! 문제가 발생하거나 개선 아이디어가 있다면, 저희의 GitHub 저장소에서 issue를 열어주세요. 🚀\n\n\u003cimg src=\"/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_6.png\" /\u003e\n\n# Connect With Me\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블로그를 유익하게 찾으셨고 AWS, 클라우드 전략, Kubernetes 또는 관련된 모든 주제에 대해 더 깊이 알고 싶다면, LinkedIn에서 연결할 기회를 갖게 되어 기쁩니다. 의미 있는 대화를 나누고 통찰을 공유하며 함께 클라우드 컴퓨팅의 광활한 영역을 탐색해 봅시다.\n\n언제든지 연락 주시거나 생각을 공유하거나 질문을 할 자유가 있습니다. 동적인 분야에서 연결하고 함께 성장하기를 기대합니다!\n\n행복한 배포 되세요! 🚀\n\n행복한 쿠버네팅 되세요! ⎈\n","ogImage":{"url":"/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_0.png"},"coverImage":"/assets/img/2024-05-23-AHand-OnGuidetoVaultinKubernetes_0.png","tag":["Tech"],"readingTime":18},{"title":"파이썬 제너레이터 데이터베이스에서 효율적으로 데이터를 가져오는 방법","description":"","date":"2024-05-23 14:16","slug":"2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases","content":"\n![image](/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_0.png)\n\n# 온디맨드 코스 | 추천\n\n몇몇 독자들이 데이터 엔지니어로 성장하는 데 도움이 될 온디맨드 코스를 요청했습니다. 제가 추천하는 3가지 좋은 자원은 다음과 같습니다:\n\n- 데이터 엔지니어링 나노디그리 (UDACITY)\n- 아파치 카프카 \u0026 아파치 스파크를 이용한 데이터 스트리밍 나노디그리 (UDACITY)\n- 파이스파크를 이용한 스파크 및 파이썬 빅데이터 과정 (UDEMY)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아직 Medium 회원이 아니신가요? Medium이 제공하는 모든 것에 액세스하려면 매월 $5로 가입하는 것을 고려해보세요!\n\n# 소개\n\n데이터 엔지니어로써 우리는 종종 운영 데이터베이스에서 특히 큰 데이터 집합을 가져와서 일련의 변환을 수행한 후에 분석 데이터베이스나 S3 버킷과 같은 클라우드 객체 저장소에 기록해야 하는 상황에 직면합니다.\n\n이 경우 Airflow 인스턴스에서 사용 가능한 메모리의 큰 부분을 사용하여 데이터 팀의 다른 동료들의 작업에 영향을 주지 않고 작업을 수행하는 방법을 찾아야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬 생성기가 메모리 피크를 피하면서 데이터베이스에서 데이터를 효율적으로 가져올 때 사용될 수 있는 좋은 옵션이 될 수 있습니다.\n\n실제로, 본 자습서에서는 생성기를 사용하는 것이 데이터 엔지니어에게 현명한 접근 방식인 두 가지 실용적인 사용 사례를 살펴볼 것입니다. 이를 위해 Docker 컨테이너를 구동하여 실제 엔드 투 엔드 데이터 워크플로를 시뮬레이션하기 위해 세 가지 서비스(포스트그레스 데이터베이스, 주피터 노트북 및 MinIO)를 실행할 것입니다.\n\n# 파이썬에서 생성기의 장점\n\n파이썬에서 표준 함수는 단일 값 계산 후 종료되지만, 생성기는 필요에 따라 일시 중지하고 다시 시작하면서 시간이 지남에 따라 값 시퀀스를 생성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제너레이터는 값을 시퀀스로 생성하기 위해 return 대신 yield 문을 사용하는 특별한 함수입니다. 값은 한 번에 하나씩 생성되며 전체 시퀀스를 메모리에 저장할 필요가 없습니다.\n\n제너레이터 함수가 호출되면 제너레이터에 의해 생성된 값의 시퀀스를 반복할 수 있는 이터레이터 객체가 반환됩니다.\n\n예를 들어, 0부터 입력 변수 n 사이의 숫자들의 제곱을 생성하는 squares_generator(n) 함수를 만들어 봅시다:\n\n```js\ndef squares_generator(n):\n  num = 0\n  while num \u003c n:\n    yield num * num\n    num += 1\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n함수를 호출하면 이터레이터만 반환됩니다:\n\n```js\nsquares_generator(n)\n\n#출력:\n# \u003cgenerator object squares_generator at 0x10653bdd0\u003e\n```\n\n모든 값의 시퀀스를 가져오려면 제너레이터 함수를 루프 안에서 호출해야합니다:\n\n```js\nfor num in squares_generator(5):\n  print(num)\n\n#출력:\n0\n1\n4\n9\n16\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n더 효율적이고 세련된 옵션은 함수 대신 한 줄로 작성된 생성기 표현식을 만드는 것입니다:\n\n```js\nn = 5\ngenerator_exp = (num * num for num in range(n))\n```\n\n이제 값을 next() 메서드를 사용하여 직접 접근할 수 있습니다:\n\n```js\nprint(next(generator_exp)) # 0\nprint(next(generator_exp)) # 1\nprint(next(generator_exp)) # 4\nprint(next(generator_exp)) # 9\nprint(next(generator_exp)) # 16\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리가 볼 수 있듯이, 제너레이터 함수에서 값이 반환되는 방식은 일반적인 파이썬 함수와는 즉각적으로 직관적이지 않습니다. 아마도 그것이 많은 데이터 엔지니어들이 발생해야 할 정도로 제너레이터를 사용하지 않는 이유일 것입니다.\n\n다음 섹션에서 두 가지 일반적인 사용 사례를 설명해보겠습니다.\n\n# 목표 및 설정\n\n이 자습서의 목표는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Postgres DB로부터 데이터를 가져와서 pandas 데이터프레임으로 저장합니다.\n- pandas 데이터프레임을 Parquet 형식으로 S3 버킷에 씁니다.\n\n각 목표는 일반 함수와 제너레이터 함수를 사용하여 모두 달성될 것입니다.\n\n이러한 워크플로우를 시뮬레이션하기 위해 세 가지 서비스가 있는 도커 컨테이너를 실행합니다:\n\n- Postgres DB = 데이터를 가져올 소스 운영 데이터베이스로 사용될 서비스입니다. Docker-compose가 mainDB를 생성하고 transactions이라는 테이블에 5백만 개의 모의 레코드를 삽입하는 작업을 수행합니다. 참고: 이 튜토리얼을 위한 자료를 준비하는 동안, 더 큰 데이터셋을 시뮬레이션하기 위해 5천만 개, 1억 개의 행을 시도해 보았지만 Docker 서비스의 성능에 영향을 미쳤습니다.\n- MinIO = AWS S3 버킷을 시뮬레이션하는 데 사용될 서비스로, awswrangler 패키지를 사용하여 pandas 데이터프레임을 Parquet 형식으로 쓸 때 도움이 될 것입니다.\n- Jupyter Notebook = 익숙한 컴파일러를 통해 Python 코드 조각을 대화식으로 실행하는 데 사용될 서비스입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금까지 설명한 내용을 시각적으로 보여주는 그래프입니다:\n\n![그래프](/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_1.png)\n\n첫 번째 단계로는 프로젝트의 GitHub 리포지토리를 복제하고 해당 폴더로 이동합니다:\n\n```js\ngit clone git@github.com:anbento0490/projects.git \u0026\u0026\ncd fetch_data_with_python_generators\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러면 세 가지 서비스를 시작하는 도커 컴포즈를 실행할 수 있어요:\n\n```js\ndocker compose up -d\n\n[+] Running 5/5\n ⠿ Network shared-network                 Created                                                 0.0s\n ⠿ Container jupyter-notebooks            Started                                                 1.0s\n ⠿ Container minio                        Started                                                 0.7s\n ⠿ Container postgres-db                  Started                                                 0.9s\n ⠿ Container mc                           Started                                                 1.1s\n```\n\n最終적으로 확인할 수 있어요:\n\n- 포스트그레스 데이터베이스에 transactions 테이블이 생성되었고 5백만 개의 레코드가 포함되어 있어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndocker exec -it postgres-db /bin/bash\n\nroot@9632469c70e0:/# psql -U postgres\n\npsql (13.13 (Debian 13.13-1.pgdg120+1))\n도움말을 보려면 \"help\"를 입력하세요.\n\npostgres=# \\c mainDB\n데이터베이스 \"mainDB\"에 사용자 \"postgres\"로 연결되었습니다.\n\nmainDB=# select count(*) from transactions;\n  count\n---------\n 5000000\n(1 로우)\n```\n\n- MinIO UI는 localhost:9001 포트에서 접속할 수 있습니다. 자격 증명을 요청 받을 때 (관리자 및 비밀번호를 입력)를 사용하고 generators-test-bucket이라는 빈 버킷이 생성되었습니다:\n\n![image](/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_2.png)\n\n- Jupyter Notebook UI는 localhost:8889에서 접근할 수 있으며 아래에 토큰을 검색하여 액세스할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```bash\ndocker exec -it jupyter-notebooks /bin/bash\n\nroot@eae08d1f4bf6:~# jupyter server list\n\n현재 실행 중인 서버:\nhttp://eae08d1f4bf6:8888/?token=8a45d846d03cf0c0e4584c3b73af86ba5dk9e83c8ac47ee7 :: /home/jovyan\n```\n\n![Python Generators](/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_3.png)\n\n좋아요! Jupyter에서 몇 가지 코드를 실행할 준비가 모두 끝났어요.\n\n하지만 그 전에 MinIO의 버킷과 상호 작용하려면 새로운 access_key와 secret_access_key를 생성해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_4.png\" /\u003e\n\n알림: MinIO 버킷의 가장 멋진 기능 중 하나는 AWS S3 버킷처럼 상호 작용할 수 있다는 것입니다 (예: boto3, awswrangler 등을 사용하여). 하지만 이러한 기능은 비용이 발생하지 않으며, 로컬 환경에만 존재하므로 비밀을 노출할 걱정이 없습니다. 컨테이너가 중지될 때까지 유지되지 않으므로 데이터가 계속 유지되지 않습니다.\n\n이제 생성기 노트북에서 다음 코드를 실행해 봅시다 (비밀 정보를 꼭 교체해주세요):\n\n```python\nimport psycopg2\nimport pandas as pd\nimport boto3\nimport awswrangler as wr\n\n#######################################################\n######## PG DB에 연결하고 커서 생성 #######\nconnection = psycopg2.connect(user=\"postgres\",\n                              password=\"postgres\",\n                              port=\"5432\",\n                              database=\"mainDB\")\ncursor = connection.cursor()\n\nquery = \"select * from transactions;\"\n\n#######################################################\n######## MINIO 버킷에 연결 ###################\n\nboto3.setup_default_session(aws_access_key_id='your_access_key',\n                            aws_secret_access_key='your_secret_key')\n\nbucket = 'generators-test-bucket'\nfolder_gen = 'data_gen'\nfolder_batch = 'data_batch'\nparquet_file_name = 'transactions'\nbatch_size = 1000000\n\nwr.config.s3_endpoint_url = 'http://minio:9000'\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 mainDB에 연결하고 쿼리를 실행하기 위한 커서를 만듭니다. 또한 generators-test-bucket와 상호 작용하기 위한 기본 세션이 설정됩니다.\n\n# 사용 사례 #1: 데이터베이스에서 읽기\n\n데이터 엔지니어로서 데이터베이스 또는 외부 서비스에서 대규모 데이터 세트를 Python 파이프라인으로 가져올 때, 다음 사항 사이의 균형을 찾아야 합니다:\n\n- 메모리: 한꺼번에 전체 데이터 세트를 가져오면 OOM 오류가 발생하거나 전체 인스턴스/클러스터의 성능에 영향을 줄 수 있습니다.\n- 속도: 행을 하나씩 가져오는 것도 비싼 I/O 네트워크 작업을 초래할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 방법 #1: 일괄적으로 데이터 가져오기\n\n실무에서 자주 사용하는 합리적인 절충안은 사용 가능한 메모리와 데이터 파이프라인의 속도 요구 사항에 따라 배치로 데이터를 가져오는 것입니다:\n\n```js\n# 1.1. 배치를 사용하여 DF 생성\ndef create_df_batch(cursor, batch_size):\n\n    print('생성 중...')\n    colnames = ['transaction_id',\n                'user_id',\n                'product_name',\n                'transaction_date',\n                'amount_gbp']\n\n    df = pd.DataFrame(columns=colnames)\n    cursor.execute(query)\n\n    while True:\n        rows = cursor.fetchmany(batch_size)\n        if not rows:\n            break\n        # 일부 변환\n        batch_df = pd.DataFrame(data = rows, columns=colnames)\n        df = pd.concat([df, batch_df], ignore_index=True)\n\n    print('DF 생성 완료!\\n')\n\n    return df\n```\n\n위 코드는 다음을 수행합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 빈 df를 생성;\n- 쿼리를 실행하고 전체 결과를 커서 객체에 캐싱;\n- while 루프를 초기화하여 매 반복마다 지정된 배치 크기(이 경우 1백만 행)와 동일한 행 수를 가져와 이 데이터를 사용하여 배치\\_df를 생성합니다.\n- 최종적으로 배치\\_df가 주 df에 추가됩니다. 전체 데이터셋이 통과될 때까지 이 프로세스가 반복됩니다.\n\n분명히 말하자면, 이것은 기본적인 예시이며, 단순히 한 번에 한 배치씩 df를 생성하는 것 외에도 while 루프의 일부로 다른 많은 작업(필터링, 정렬, 집계, 데이터를 다른 위치로 쓰기 등)을 수행할 수 있었습니다.\n\n노트북에서 함수를 실행하면 다음과 같이 결과를 얻을 수 있습니다:\n\n```js\n%%time\ndf_batch = create_df_batch(cursor, batch_size)\ndf_batch.head()\n\n결과:\n\n생성 중...\nDF 생성 완료!\n\nCPU 시간: 사용자 9.97초, 시스템: 13.7초, 총: 23.7초\n실제 시간: 25초\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Python Generators](/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_5.png)\n\n## Method #2: Using Generators\n\nA less common -but powerful- strategy for data engineers is to fetch data as a stream using generators:\n\n```python\n# AUXILIARY FUNCTION\ndef generate_dataset(cursor):\n\n    cursor.execute(query)\n\n    for row in cursor.fetchall():\n        # some transformation\n        yield row\n\n# 2.1. CREATE DF USING GENERATORS\ndef create_df_gen(cursor):\n    print('Creating pandas DF using generator...')\n\n    colnames = ['transaction_id',\n                'user_id',\n                'product_name',\n                'transaction_date',\n                'amount_gbp']\n\n    df = pd.DataFrame(data=generate_dataset(cursor), columns=colnames)\n\n    print('DF successfully created!\\n')\n\n    return df\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 코드 스니펫에서는 쿼리를 실행하고 행을 시퀀스로 반환하는 'generate_dataset' 보조 함수를 생성합니다. 이 함수는 'pd.DataFrame()' 절의 데이터 인수에 직접 전달되며, 내부적으로 모든 검색된 레코드를 순회하고 행이 소진될 때까지 요소를 생성합니다.\n\n다시 말하지만, 이 예제는 매우 기본적이며(주로 설명 목적으로), 보조 함수 내에서 어떤 종류의 필터링이나 변환을 수행할 수 있습니다. 함수를 실행하면 다음과 같은 결과가 나옵니다:\n\n```js\n%%time\ndf_gen = create_df_gen(cursor)\ndf_gen.head()\n\n팬더스 데이터프레임 생성 중...\nDF가 성공적으로 생성되었습니다!\n\nCPU 소요 시간: 사용자 9.04초, 시스템 2.1초, 총 11.1초\n실제 시간: 14.4초\n```\n\n\u003cimg src=\"/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_6.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 가지 방법 모두 데이터 프레임이 반환되기 때문에 메모리 사용량이 동일할 것 같지만, 이는 사실이 아닙니다. 데이터 프레임이 생성되는 동안 데이터 처리 방식이 다르기 때문입니다:\n\n- 방법 #1의 경우, 데이터 교환 과정이 다소 비효율적으로 이루어지고 네트워크를 통해 데이터가 교환되어 더 높은 최대 메모리가 발생합니다.\n- 방법 #2의 경우, 필요할 때만 값을 계산하고 하나씩 처리하기 때문에 더 작은 메모리 공간을 사용합니다.\n\n# 사용 사례 #2: 클라우드 객체 저장소에 쓰기\n\n가끔 데이터 엔지니어는 데이터베이스에 저장된 대량의 데이터를 가져와서 이러한 레코드를 외부(예: 규제기관, 감사인, 파트너)와 공유해야 할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일반적인 해결책은 클라우드 객체 저장소를 생성하는 것입니다. 데이터가 전달되어 제 3자(적절한 액세스 권한이 부여된)가 데이터를 읽고 자신의 시스템으로 복사할 수 있게 합니다.\n\n사실, 우리는 데이터가 parquet 형식으로 작성될 버킷인 generators-test-bucket을 생성했습니다. 이는 awswrangler 패키지를 활용하여 데이터가 저장될 것입니다.\n\nawswrangler의 장점은 pandas 데이터프레임과 매우 잘 작동하며 데이터 집합 구조를 유지한 채로 데이터프레임을 parquet 형식으로 변환할 수 있다는 것입니다.\n\n## 방법 #1: 일괄 처리를 사용하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 사용 사례의 경우, 일반적으로 데이터를 일괄적으로 가져와서 쓰는 것이 일반적이며 전체 데이터 집합이 순회될 때까지 계속됩니다 :\n\n```js\n# 1.2 WRITING DF TO MINIO BUCKET IN PARQUET FORMAT USING BATCHES\ndef write_df_to_s3_batch(cursor, bucket, folder, parquet_file_name, batch_size):\n    colnames = ['transaction_id',\n                'user_id',\n                'product_name',\n                'transaction_date',\n                'amount_gbp']\n    cursor.execute(query)\n    batch_num = 1\n    while True:\n        rows = cursor.fetchmany(batch_size)\n        if not rows:\n            break\n        print(f\"Writing DF batch #{batch_num} to S3 bucket...\")\n        wr.s3.to_parquet(df= pd.DataFrame(data = rows, columns=colnames),\n                         path=f's3://{bucket}/{folder}/{parquet_file_name}',\n                         compression='gzip',\n                         mode = 'append',\n                         dataset=True)\n        print('Batch successfully written to S3 bucket!\\n')\n        batch_num += 1\n```\n\nwrite_df_to_s3_batch() 함수를 실행하면 각각 100만 개의 레코드를 포함하는 5개의 파케이 파일이 해당 버킷에 생성됩니다 :\n\n```js\nwrite_df_to_s3_batch(cursor, bucket, folder_batch, parquet_file_name, batch_size)\n\nWriting DF batch #1 to S3 bucket...\nBatch successfully written to S3 bucket!\n\nWriting DF batch #2 to S3 bucket...\nBatch successfully written to S3 bucket!\n\nWriting DF batch #3 to S3 bucket...\nBatch successfully written to S3 bucket!\n\nWriting DF batch #4 to S3 bucket...\nBatch successfully written to S3 bucket!\n\nWriting DF batch #5 to S3 bucket...\nBatch successfully written to S3 bucket!\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_7.png\" /\u003e\n\n## 방법 #2: 제너레이터 사용하기\n\n대안으로, 제너레이터를 활용하여 데이터를 추출하고 버킷에 작성할 수 있습니다. 제너레이터는 데이터를 가져오고 이동하는 동안 메모리 비효율성을 야기하지 않으므로 전체 DataFrame을 한 번에 쓰기를 결정할 수도 있습니다:\n\n```js\n# 2.2 GENERATOR를 사용하여 PARQUET 형식으로 DF를 MINIO 버킷에 쓰기\ndef write_df_to_s3_gen(cursor, bucket, folder, parquet_file_name):\n    print('DF를 S3 버킷에 쓰는 중...')\n\n    colnames = ['transaction_id',\n                'user_id',\n                'product_name',\n                'transaction_date',\n                'amount_gbp']\n\n    wr.s3.to_parquet(df=pd.DataFrame(data=generate_dataset(cursor), columns=colnames),\n             path=f's3://{bucket}/{folder}/{parquet_file_name}',\n             compression='gzip',\n             mode='append',\n             dataset=True)\n    print('데이터가 성공적으로 S3 버킷에 쓰여졌습니다!\\n')\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndef wirte_df_to_s3_gen(cursor, bucket, folder_gen, parquet_file_name):\n\nWriting DF to S3 bucket...\nData successfully written to S3 bucket!\n```\n\n![Python Generators](/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_8.png)\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일반적인 Python 함수보다 직관성이 떨어지는 제너레이터는 메모리를 적게 차지하면서도 좋은 성능을 제공하기 때문에 덜 사용되지만 이점이 많습니다.\n\n실제로 이 자습서에서는 데이터 엔지니어가 Python 제너레이터를 활용해 데이터베이스에서 데이터를 효율적으로 검색하는 방법을 연구하기 위해 세 가지 로컬 서비스(포스트그레스DB, 주피터 노트북, MinIO)를 도커를 통해 구동하여 데이터를 일괄로 처리하는 대신 데이터를 효율적으로 가져올 수 있는 두 가지 실제 예시를 공유했습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_0.png"},"coverImage":"/assets/img/2024-05-23-PythonGeneratorsHowToEfficientlyFetchDataFromDatabases_0.png","tag":["Tech"],"readingTime":19},{"title":"컨테이너 세계에서 Runc 대 Crun","description":"","date":"2024-05-23 14:15","slug":"2024-05-23-RuncvsCrunincontainersworld","content":"\n만약 컨테이너화 기술에 흥미가 있다면, runc에 대해 들어봤을 수도 있어요.\n\n자세한 내용을 설명해 들어가기 전에 컨테이너가 정확히 무엇인지 알려드릴게요.\n\n주로 두 가지 리눅스 커널 모듈, 네임스페이스와 cgroup으로 만들어진 환경 안에서 가상 감옥 또는 격리된 환경을 만들어낸답니다.\n\n- 네임스페이스: 볼 수 있거나 접근할 수 있는 것을 제어합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCgroup: 리소스(예: RAM 및 CPU) 얼마나 사용하는지 확인하는 데 사용됩니다.\n\n![Image](/assets/img/2024-05-23-RuncvsCrunincontainersworld_0.png)\n\n컨테이너 런타임이 무엇인가요?\n\n컨테이너 런타임은 이미 이야기한 컨테이너라고 불리는 격리된 환경을 관리하는 데 도움을 주는 소프트웨어입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRunc과 Crun은 현재 사용되는 두 가지 주요 컨테이너 런타임입니다.\n\n그렇다면 containerd 또는 cri-o란 무엇인가요?\n\n이 둘은 모두 runc 위에서 작동하는 컨테이너 런타임의 추상화된 레이어입니다. 이것들은 컨테이너를 관리하기 위한 프론트 엔드로, 즉 컨테이너를 생성, 제거, 시작 및 중지하는 역할을 담당합니다.\n\n![이미지](/assets/img/2024-05-23-RuncvsCrunincontainersworld_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n크리올(Containerd)과 크라이오(CRI-O)는 둘 다 컨테이너 런타임으로 runc를 사용합니다.\n\n지금까지는 runc와 crun이 무엇인지 알아보았습니다; 이제 차이를 살펴봅시다.\n\n둘 다 컨테이너 런타임이며 컨테이너를 처리하는 데 동일한 작업을 수행합니다.\n\n하지만 차이점은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1. runc은 Go로 작성되었고 crun은 C로 작성되어서 Linux 커널과 더 호환성이 높아요.\n\n2. runc는 도커에 의해 개발되었고 crun은 RedHat에 의해 개발되었어요.\n\n3. crun은 더 가벼워서 메모리 소비가 낮아요. crun은 300K이고 runc는 15M이에요.\n\nPodman은 어떠세요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n포드맨은 컨테이너를 관리하는 데 책임이 있는 crun의 frontend 역할을 하는 도커와 비슷한 유틸리티입니다.\n\n## 요약\n\n![RuncvsCrunincontainersworld_2](/assets/img/2024-05-23-RuncvsCrunincontainersworld_2.png)\n\n결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 것을 사용해야 할까요?\n\n개발 및 프로덕션 환경 모두에서 추가 구성 요소 없이 가볍게 사용할 컨테이너 엔진이 필요하다면 Podman을 선택하세요.\n\n특히 이미지를 생성할 필요가 없는 프로덕션 환경에서는 Podman을 선택하는 것이 좋습니다. 이미지 빌드 구성 요소는 불필요하고 자원을 소비하는 소프트웨어로 간주될 수 있습니다.\n\n그리고 이것이 Docker를 프로덕션 환경에서 사용하지 않아야 하는 또 다른 이유입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 쿠버네티스를 사용 중이라면 cri-o를 선택하세요. 그리고 runc에 만족스럽지 않다면 C 언어로 된 가벼운 런타임을 원한다면 crun으로 런타임을 쉽게 전환할 수 있습니다.\n\nkloudino.com (메디 탈레가니)가 작성함\n","ogImage":{"url":"/assets/img/2024-05-23-RuncvsCrunincontainersworld_0.png"},"coverImage":"/assets/img/2024-05-23-RuncvsCrunincontainersworld_0.png","tag":["Tech"],"readingTime":4},{"title":"도커 대 Podman 안전한 오케스트레이션의 새 시대","description":"","date":"2024-05-23 14:14","slug":"2024-05-23-DockervsPodmanANewErainSecureOrchestration","content":"\n탐구하는 Root vs Rootless Orchestration: 보안 관점에서\n\n안녕하세요, 기술 애호가 여러분! 😊 오늘은 컨테이너 오케스트레이션의 매혹적인 세계로 빠져들어보겠습니다. 이 도구들이 나오기 전에는 개발자들이 수동 배포의 고통, 표준화 부족 (내 컴퓨터에서는 동작하는)으로 인한 복잡하고 오류가 발생하기 쉬운 과정을 겪어야 했습니다. 이러한 기술을 개발한 사람들에게 이해와 감사의 마음을 전해봅시다.\n\n이를 염두에 두고, 우리의 관심을 보안 오케스트레이션의 세계에서 뜨거운 반향을 일으키는 새로운 도구인 Podman으로 돌려봅시다. 이 도구는 특히 안전한 오케스트레이션 분야에서 Docker와 10년간 사랑받아온 기존 강자에 도전하고 있습니다 💪. 이 흥미진진한 발전에 대해 더 깊이 파헤치기 위해 기대해 주세요!\n\n# 🚀 컨테이너 이해: 왜 필요한가부터 어떻게 하는가까지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n컨테이너는 코드, 런타임, 라이브러리 및 시스템 설정을 포함한 응용 프로그램 실행에 필요한 모든 것이 포함된 독립 실행 가능한 패키지입니다.\n\n이는 응용 프로그램이 어디에서 시작하더라도 동일하게 실행된다는 것을 의미합니다. 즉, 당신의 랩탑, 클라우드 서버 또는 동료의 컴퓨터 등 어디에서든 실행할 수 있습니다. 이 일관성은 '내 컴퓨터에서는 작동하는데'라는 오랜 문제를 해결합니다.\n\n컨테이너 오케스트레이션의 핵심은 컨테이너 실행 환경이며, 컨테이너 생성, 관리 및 실행에 도움을 줍니다.\n\n- 컨테이너가 시작되면 실행 환경은 저장소에서 지정된 컨테이너 이미지를 요청합니다. 이 이미지는 응용 프로그램 및 종속성에 대한 청사진 역할을 합니다.\n- 실행 환경은 Linux 네임스페이스를 사용하여 안전하고 분리된 환경을 제공하여 시스템 리소스(CPU, 메모리, 디스크, 네트워크 등)에 대한 독특한 이해를 제공합니다.\n- Linux 커널의 컨트롤 그룹(cgroups)은 리소스 공정한 분배를 보장하며 어떤 컨테이너도 리소스를 독차지하거나 시스템 성능을 저하시키지 않습니다.\n- 한 번에 한 컨테이너가 격리되면 실행 환경은 해당 환경 내에서 프로그램을 실행하여 호스트 시스템과 쉽게 통신합니다.\n- 데몬 프로세스로 작동하는 컨테이너 실행 환경 도구는 리눅스 커널과 상호작용하여 컨테이너를 관리하며, 관리를 위해 루트 액세스가 필요합니다. 이 상호작용은 효율적인 컨테이너 관리에 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n잘 알려진 컨테이너 런타임 중에는 Docker, k8s, nerdctl 등에서 사용되는 containerd와 cri-o가 있습니다.\n\n# 🏆 도커의 지배 속에서 Podman의 부상\n\n\u003cimg src=\"/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_0.png\" /\u003e\n\n컨테이너 관리 세계에서 인기가 Podman으로 변화되고 있으며, 그 이유에는 몇 가지가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Rootless Architecture: 도커와는 달리 루트 액세스가 있는 데몬 프로세스로 작동하는 Podman과 달리, Podman은 루트리스 접근 방식을 채택합니다. 이 기본적인 차이가 Podman의 인기 증진에 상당한 기여를 합니다.\n- 보안 취약점: Docker의 루트 액세스는 파일을 읽고 프로그램을 설치하며 애플리케이션을 편집하는 등 컨테이너를 관리할 수 있게 합니다. 그러나 이는 시스템에 보안 취약점을 도입하여 헤커들로 하여금 유혹적인 대상이 되게 합니다.\n- 해커들의 타깃: 해커가 데몬을 compromise하는 데 성공하면 민감한 데이터에 접근하거나 악성 코드를 실행하거나 컨테이너 구성을 변경하거나 시스템 전체를 다운시킬 가능성이 있습니다.\n- SELinux로 보강된 보안: Docker와는 다르게 Podman은 각 컨테이너를 Security-Enhanced Linux (SELinux) 레이블과 함께 시작하여 보안을 강화합니다.\n- 다른 도구에 의존: 루트리스 접근 방식으로 Podman은 컨테이너를 직접 관리하지 않습니다. 대신 이 아래서 설명하는 다른 도구들을 사용하여 컨테이너 관리를 수행합니다.\n- Buildah: OCI (Open Container Initiative) 호환 컨테이너를 빌드하는 데 사용되는 오픈 소스 리눅스 기반 도구입니다. Buildah는 전체 컨테이너 런타임이나 데몬을 설치하지 않고도 컨테이너를 생성하고 관리할 수 있습니다.\n- Skopeo: 컨테이너 이미지 및 이미지 레지스트리를 사용하여 다양한 작업을 수행하기 위한 명령줄 유틸리티입니다. 전체 이미지를 다운로드하지 않고 원격 레지스트리의 이미지를 검사할 수 있어 컨테이너 작업에 대한 가벼운 솔루션입니다.\n- Systemd: Podman은 설정된 컨테이너 런타임을 호출하여 실행 중인 컨테이너를 생성합니다. 그렇지만 전용 데몬이 없는 Podman은 시스템 및 서비스 관리자인 systemd를 사용하여 업데이트를 수행하고 컨테이너를 백그라운드에서 유지합니다.\n\n# 🔒 Podman의 보안에 대한 행동: Docker에 대한 안전한 대체품\n\n\u003cimg src=\"/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_1.png\" /\u003e\n\n- 주어진 시나리오에서 세 명의 리눅스 사용자인 Bob, Dawg, BadBoy가 생성되었습니다. Bob과 Dawg는 Podman을 사용하여 컨테이너를 생성하며, 이러한 컨테이너들은 각 사용자 네임스페이스 내의 리소스에만 액세스할 수 있습니다. 이러한 설정은 각 컨테이너의 액세스를 해당하는 네임스페이스로 제한하여 보안을 강화합니다.\n- BadBoy는 Docker를 사용하며 루트 액세스를 가지고 있어 호스트 시스템의 모든 리소스에 대한 가시성을 허용합니다. 네임스페이스 밖에 있는 리소스까지도 볼 수 있어 시스템에 잠재적인 공격 가능성을 노출시킵니다. 이에 반해 루트리스 아키텍처인 Podman은 사용자 개별 네임스페이스에만 액세스 권한을 제한하여 보안을 강화합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Podman 설정\n\nPodman을 설정하는 실용적인 예제에 대해 알아보겠습니다. macOS에서 설정을 진행할 것이지만 필요에 따라 다른 환경에서 설정하는 방법에 대한 해당 문서를 참조할 수 있습니다.\n\n- Podman 설치: Homebrew를 이용하여 Podman을 설치하려면 brew install podman을 실행하세요.\n- Podman Machine 초기화: Podman 머신을 초기화하려면 podman machine init을 사용하세요.\n- Podman-Compose 설치: Docker Compose를 Podman으로 실행하는 스크립트인 Podman-Compose를 설치하려면 brew install podman-compose을 사용하세요.\n- Podman-Desktop 설치: Podman에 대한 Docker Desktop과 유사한 경험을 제공하는 Podman-Desktop을 설치하려면 brew install podman-desktop을 사용하세요.\n- Podman 세부 정보 확인: 마지막으로, podman info를 사용하여 Podman의 설치 및 구성 세부사항을 확인할 수 있습니다. 아래는 중요한 몇 가지 필드가 강조된 예시입니다.\n\n```js\nhost:\n  arch: amd64\n  buildahVersion: 1.32.0\n  cgroupControllers:\n  - cpu\n  - io\n  - memory\n  - pids\n  cgroupManager: systemd\n  cgroupVersion: v2\n  ociRuntime:\n    name: crun\n    package: crun-1.12-1.fc39.x86_64\n    path: /usr/bin/crun\n    version: |-\n      crun version 1.12\n      commit: ce429cb2e277d001c2179df1ac66a470f00802ae\n      rundir: /run/user/501/crun\n      spec: 1.0.0\n      +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL\n  os: linux\n  security:\n    apparmorEnabled: false\n    capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT\n    rootless: true\n    seccompEnabled: true\n    seccompProfilePath: /usr/share/containers/seccomp.json\n    selinuxEnabled: true\n  serviceIsRemote: true\nregistries:\n  search:\n  - docker.io\nversion:\n  APIVersion: 4.7.2\n  Built: 1698762721\n  BuiltTime: Tue Oct 31 20:02:01 2023\n  GitCommit: \"\"\n  GoVersion: go1.21.1\n  Os: linux\n  OsArch: linux/amd64\n  Version: 4.7.2\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Podman의 세부 정보를 확인하고 이미지를 검사하며 실행 중인 컨테이너를 관리하는 데 Podman CLI도 사용할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_2.png)\n\n- 아래 제공된 Docker Compose 파일을 사용하여 컨테이너를 시작하려면 다음 명령을 실행하세요: podman compose up -d\n\n```yaml\nservices:\n  postgres:\n    image: postgres\n    restart: always\n    environment:\n      POSTGRES_DB: podman-psql\n      POSTGRES_USER: podman-psql-user\n      POSTGRES_PASSWORD: podman-pass\n    ports:\n      - \"5432:5432\"\n\n  redis:\n    image: \"redis:6.0.14\"\n    restart: always\n    command: redis-server\n    ports:\n      - \"6379:6379\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 다음은 Podman 데스크톱 내에서 실행 중인 컨테이너와 이미지를 검사할 수 있습니다.\n\n![image1](/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_3.png)\n\n![image2](/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_4.png)\n\n# 마지막으로\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n디지턈 시대에는 보안이 매우 중요합니다. 침입이 발생하면 심각한 결과를 가져올 수 있습니다. Docker와 Podman은 각각 강점과 약점을 가지고 있습니다. Podman은 안전한 오케스트레이션의 기초를 바탕으로 만들어졌지만 Docker와 같은 기능(예: Docker Swarm)이 부족할 수 있습니다. 반면 Docker는 사용 편의성을 강조하지만 보안 측면에서는 미흡하다고 여겨집니다.\n\n이 토론이 유익했고 안전한 오케스트레이션에 대한 이해력을 높일 수 있었기를 바랍니다. 이 정보가 유용했다면 더 많은 글을 읽고 싶다면 저를 팔로우해주세요. 즐거운 학습되세요! 🚀\n\n# 참고 자료\n\n- Podman이란? (redhat.com)\n- Podman 설치 | Podman\n- Docker를 대체할 도구 및 그 이유 | mkdev의 프로그래밍 글\n- Alfresco와 함께 Podman 사용하기 — Alfresco Hub\n","ogImage":{"url":"/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_0.png"},"coverImage":"/assets/img/2024-05-23-DockervsPodmanANewErainSecureOrchestration_0.png","tag":["Tech"],"readingTime":8},{"title":"러스트 배우기 11부  빌더와 데이터베이스 상호작용","description":"","date":"2024-05-23 14:11","slug":"2024-05-23-LearningRustPart11BuildersandDatabaseInteraction","content":"\n다음 시리즈로 넘어가보겠습니다; 이 부분에서는 데이터 구조에 빌더 패턴을 구현하는 방법을 살펴보겠습니다. 그런 다음 sqlx와 Postgres를 사용한 데이터베이스 상호작용으로 넘어가겠습니다.\n\n![이미지](/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_0.png)\n\n# Rust 시리즈\n\n부분 1 — 기본 개념\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPart 2 — 메모리\n\nPart 3 — 흐름 제어와 함수\n\nPart 4 — 옵션/결과 및 컬렉션\n\nPart 5 — 트레이트, 제네릭 및 클로저\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제 6부 — 매크로, 반복자 및 파일 처리\n\n제 7부 — 스레드 공유 상태 및 채널\n\n제 8부 — Cargo, 크레이트, 모듈 및 라이브러리\n\n제 9부 — 명령행 인수, 워크스페이스 및 테스팅\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제 10부 — 상자 포인터 및 웹 앱\n\n제 11부 — 빌더와 데이터베이스 상호작용 (이 기사)\n\n# 소개\n\n이것은 러스트 학습 시리즈의 열한 번째 섹션입니다. 이번에는 러스트에서 빌더 패턴을 다룰 것입니다. 이 공통된 패턴은 구조체를 안전하고 투명하게 초기화하는 좋은 방법입니다. 다음으로, 우리는 포스트그레스와 SQLX 프레임워크를 사용하여 데이터베이스에서 CRUD 작업을 수행하는 방법을 살펴볼 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 준비물\n\n이 글의 데이터베이스 부분을 위한 유일한 준비물은 Rust와 Cargo가 설치되어 있고 시스템에 Docker가 설치되어 있는 것입니다. 만약 Docker를 가지고 있지 않지만 로컬 Postgres DB가 이미 설치되어 있거나 다른 서버의 DB에 액세스할 수 있다면 Docker Postgres 설정을 건너뛰고 DB에 연결하기 위한 연결 속성만 수정하면 됩니다.\n\n# 빌더 패턴\n\n빌더 패턴은 복잡한 객체의 구성을 해당 표현에서 분리하는 디자인 패턴입니다. 이 패턴을 사용하면 유효성 검사를 수행하고 기본값으로 대체하며 값을 부분적으로 할당한 후에 항목을 생성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRust로 그 구현하는 방법을 살펴볼 거예요. 이것이 우리의 코드입니다.\n\n```js\n#[derive(Debug)]\nstruct ChargingSession {\n    id: String,\n    watts: u32,\n    vin: String,\n}\n\nstruct ChargingSessionBuilder {\n    id: String,\n    watts: Option\u003cu32\u003e,\n    vin: Option\u003cString\u003e,\n}\n\nimpl ChargingSessionBuilder {\n    fn new(id: \u0026str) -\u003e ChargingSessionBuilder {\n        ChargingSessionBuilder {\n            id: id.to_string(),\n            watts: None,\n            vin: None,\n        }\n    }\n\n    fn watts(mut self, watts: u32) -\u003e ChargingSessionBuilder {\n        self.watts = Some(watts);\n        self\n    }\n\n    fn vin(mut self, vin: \u0026str) -\u003e ChargingSessionBuilder {\n        self.vin = Some(vin.to_string());\n        self\n    }\n\n    fn build(self) -\u003e ChargingSession {\n        ChargingSession {\n            id: self.id,\n            watts: self.watts.unwrap_or_else(|| 0),\n            vin: self.vin.unwrap_or_else(|| \"Unknown\".to_string()),\n        }\n    }\n}\n\nfn main() {\n    // 이것은 ChargingSession을 생성하는 표준적인 방법입니다.\n    let cs_old_way = ChargingSession {\n        id: String::from(\"11111\"),\n        watts: 420,\n        vin: String::from(\"4Y1SL65848Z411439\"),\n    };\n    println!(\"Regular way to create struct: {:?}\", cs_old_way);\n\n    // 빌더를 사용해서 생성하는 방법입니다.\n    let cs = ChargingSessionBuilder::new(\"11111\")\n        .watts(420)\n        .vin(\"4Y1SL65848Z411439\")\n        .build();\n    println!(\"Builder pattern to create struct: {:?}\", cs);\n\n    // ID만 제공하여 생성하는 예시입니다.\n    let cs_lean = ChargingSessionBuilder::new(\"11111\")\n    .build();\n     println!(\"Builder pattern to create struct (default values): {:?}\", cs_lean);\n}\n```\n\n이걸 한 번에 이해하기에 많지만, 단계적으로 진행해 봅시다.\n\n먼저, 충전 세션 정보를 저장하는 구조체를 정의했습니다. 이 시리즈의 이전 예제에서 하나의 필드인 세션용 차량 ID 번호인 vin을 추가했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러면 데이터 구조체와 동일한 필드를 가진 빌더를 위한 구조체를 정의합니다.\n\n빌더는 impl 블록에서 구현되며, id 및 각 추가 필드를 설정하는 함수를 정의하는 새 함수가 있습니다. 그러나 몇 가지 중요한 사항이 있습니다.\n\n- 각 함수는 ChargingSessionBuilder 유형을 반환합니다. 기본적으로 self입니다.\n- 추가 속성 필드에는 mut self를 첫 번째 매개변수로 사용하는 메서드가 있습니다. 이는 이러한 함수 호출의 체이닝을 허용하는 데 중요합니다. 또한 여기에 유효성 검사 논리를 코딩할 수 있습니다.\n- build 함수가 모두 통합되는 곳입니다. 존재하는 값들을 할당하고 나면 기본값을 결정하고 대상 구조체를 생성할 수 있습니다.\n\n이를 통해 빌더 패턴의 우아함과 Rust 내에서의 구현 방법을 살펴보았습니다. 이것이 앱이나 라이브러리에 코드를 구현하는 훌륭한 방법임을 알 수 있기를 바랍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 섹션인 데이터베이스로 넘어가 봅시다.\n\n# 데이터베이스 — sqlx\n\n이 섹션에서는 Rust 프로그램에서 sqlx를 사용하여 데이터베이스 작업을 살펴볼 것입니다. 먼저 일부 설정이 필요합니다.\n\n## 설정\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n새 프로젝트를 시작해봅시다. db_app이라고 이름 짓고, cargo new db_app으로 생성할 수 있어요. 기본 디렉토리에 몇 개의 파일을 생성할 거에요. 첫 번째 파일은 docker-compose.yml이라고 하며 다음 내용이 있어야 합니다. Postgres와 Pgadmin이 노출되는 임의의 포트를 선택했으며, 컴퓨터에 설치된 다른 앱들과 충돌하지 않도록 했어요.\n\n```js\nversion: '3'\nservices:\n  postgres:\n    image: postgres:latest\n    container_name: postgres\n    ports:\n      - '6500:5432'\n    volumes:\n      - postgresDB:/data/postgres\n    env_file:\n      - ./.env\n  pgAdmin:\n    image: dpage/pgadmin4\n    container_name: pgAdmin\n    env_file:\n      - ./.env\n    ports:\n      - \"5050:80\"\nvolumes:\n  postgresDB:\n```\n\n.env이라는 파일이 하나 더 필요하며, 다음 내용이 있어야 해요. 이 파일은 docker-compose 파일과 나중에 Rust 애플리케이션에서 모두 사용할 거에요.\n\n```js\nPOSTGRES_HOST=127.0.0.1\nPOSTGRES_PORT=6500\nPOSTGRES_USER=admin\nPOSTGRES_PASSWORD=password123\nPOSTGRES_DB=charging_session\n\nDATABASE_URL=postgresql://admin:password123@localhost:6500/charging_session?currentSchema=public\n\nPGADMIN_DEFAULT_EMAIL=admin@admin.com\nPGADMIN_DEFAULT_PASSWORD=password123\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 내용과 함께 데이터베이스 사용자, 비밀번호, 그리고 Pgadmin에 대한 연결 정보를 제공해 드렸습니다.\n\n이 두 가지 항목을 만들고 위의 내용을 사용하여 Docker Compose를 사용하여 로컬 DB 인스턴스를 시작할 수 있습니다. 처음에는 항상 전경에서 시작하는 것을 좋아합니다. 이미지 다운로드 및 기타 작업을 하기 때문에 여러분의 컴퓨터 및 네트워크 속도에 따라 시간이 소요될 수 있습니다. docker-compose.yml 및 .env 파일이 있는 디렉토리와 동일한 위치에서 다음을 실행하십시오.\n\n```js\ndocker-compose up\n```\n\n시작된 모든 것을 확인한 후에는 언제든지 -d 스위치를 사용하여 데몬 모드로 시작할 수 있습니다. 완료되면 두 컨테이너가 시작되었는지 확인해 봅시다. 다음과 같이 명령을 실행합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndocker ps\n```\n\n비슷한 결과가 표시됩니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_1.png\" /\u003e\n\n만약 두 개의 컨테이너가 표시되지 않는다면, docker-compose를 실행한 터미널에서 에러를 확인해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 번 이들이 실행되면 DB에 연결해 봅시다. Pgadmin을 포트 5050에서 실행하도록 구성했으니 브라우저에서 http://localhost:5050을 입력하면 pgadmin의 로그인 화면이 표시됩니다. .env 파일에 구성된 자격 증명(관리자@관리자.com/비밀번호123)을 사용하여 pgadmin에 로그인할 수 있습니다. 그런데 아직 데이터베이스에 연결되지 않았습니다. 이를 위해 다음을 실행해야 합니다.\n\n```js\ndocker inspect postgres\n```\n\n출력을 확인하여 \"NetworkSettings\" 섹션으로 이동하고 \"IPAddress\" 속성의 값을 복사합니다. 이 값은 DB에 연결하는 데 사용할 호스트(IP)입니다. 제 컴퓨터에서 이 값은 172.23.0.1 이었습니다.\n\n로그인한 후 \"새 서버 추가\" 버튼을 클릭하고, \"호스트 이름/주소\"로 이전에 복사한 IP 주소를 포함한 필수 자격 증명을 제공하고 \"저장\" 버튼을 클릭하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n서버에 로그인하면 데이터베이스 charging_session을 볼 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_2.png)\n\n잘 했어요. 데이터베이스를 사용할 준비가 되었고 Pgadmin에서 관리할 수 있습니다.\n\n이제 Rust 앱의 종속성을 구성해 봅시다. 처음에는 모두 필요하지 않지만 결국 필요하게 될 것이므로 지금 추가해 두는 것이 좋습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCargo.toml 파일의 종속성 부분을 다음과 같이 수정하세요.\n\n```toml\n[dependencies]\nchrono = { version = \"0.4.31\", features = [\"serde\"] }\ndotenv = \"0.15.0\"\nenv_logger = \"0.10.1\"\nlog = \"0.4.20\"\nserde = { version = \"1.0.193\", features = [\"derive\"] }\nserde_json = \"1.0.108\"\nsqlx = { version = \"0.7.3\", features = [\"runtime-tokio-native-tls\", \"postgres\", \"uuid\", \"chrono\"] }\ntokio = { version = \"1.35.0\", features = [\"macros\", \"rt-multi-thread\"]}\nuuid = { version = \"1.6.1\", features = [\"serde\", \"v4\"] }\n```\n\n다양한 종속성에 대해 활성화된 기능을 검토하는 데도 시간을 할애하는 것이 좋습니다.\n\n다음으로, 필요한 테이블을 만들기 위해 sqlx-cli 마이그레이션 기능을 사용할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우선 명령 줄에서 다음을 실행하여 CLI를 설치해야 합니다.\n\n```js\ncargo install sqlx-cli --no-default-features --features rustls,postgres\n```\n\n그런 다음 마이그레이션 파일을 초기화해야 합니다. 다음과 같이 실행합니다.\n\n```js\nsqlx migrate add initial-tables\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 명령어는 우리가 마이그레이션 스크립트를 작성하기 위해 새 파일 migrations/`timestamp`\\_initial-tables.sql을 생성합니다.\n\n![이미지](/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_3.png)\n\n이 파일을 열고 아래 SQL 문을 추가하여 테이블을 생성하세요.\n\ncreate table locations (\nid bigserial primary key,\nname varchar(255) unique not null\n);\n\ncreate table sessions (\nid bigserial primary key,\nlocation_id bigint not null,\nwatts bigint not null,\nvin varchar(255) not null,\nconstraint fk_location foreign key (location_id) references locations(id) on delete cascade\n);\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 예제에서 사용할 두 개의 테이블 정의입니다. 이 시리즈의 충전 세션에 대한 표준 예제를 확장하여, 충전 장치의 위치를 저장할 locations 테이블을 추가했습니다.\n\n이제 다음을 실행하여 테이블을 생성하세요.\n\n```js\nsqlx migrate run\n```\n\n그러면 즉시 20231212235431/migrate initial-tables (타임스탬프 부분은 달라질 수 있음)과 같은 메시지가 표시됩니다. 이제 Pgadmin에 가서 테이블을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_4.png\" /\u003e\n\n위에서 보듯이 두 개의 테이블이 생성되었고, 문서 목적을 위해 Pgadmin 내에 ERD 다이어그램도 생성했습니다. 이제 초기 설정과 프로젝트 구성을 완료했습니다.\n\n# 데이터베이스 함수\n\n이 섹션에서는 데이터베이스 상호 작용의 다양한 유형과 Rust 구현을 살펴볼 것입니다. 이는 데이터베이스에 연결하는 것으로 시작됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDB에 연결하기\n\n데이터베이스에 연결하는 방법은 PgPoolOptions connect 함수를 통해 연결을 생성하는 것입니다. 우리의 .env 파일에서 데이터베이스 연결 문자열을 읽고 로깅을 구성하며 성공 또는 오류를 기록하는 코드 전체는 아래와 같습니다.\n\n```js\nuse sqlx::{postgres::PgPoolOptions, Pool, Postgres};\nuse dotenv::dotenv;\nuse log::{info, error};\n\n#[tokio::main]\nasync fn main() {\n    if std::env::var_os(\"RUST_LOG\").is_none() {\n        std::env::set_var(\"RUST_LOG\", \"info\");\n    }\n    dotenv().ok();\n    env_logger::init();\n\n    let database_url = std::env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n    let pool = match PgPoolOptions::new()\n        .max_connections(10)\n        .connect(\u0026database_url)\n        .await\n    {\n        Ok(pool) =\u003e {\n            info!(\"✅ 데이터베이스에 연결되었습니다!\");\n            pool\n        }\n        Err(err) =\u003e {\n            error!(\"🔥 데이터베이스 연결에 실패했습니다: {:?}\", err);\n            std::process::exit(1);\n        }\n    };\n}\n```\n\n시작 부분의 #[tokio::main] 매크로를 주목해주세요. 이는 async fn main()을 동기 fn main()로 변환하여 런타임 인스턴스를 초기화하고 async main 함수를 실행하게 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 코드를 실행하면 출력 로깅에서 다음 메시지가 표시됩니다.\n\n[2023-12-13T00:16:42Z INFO db_app] ✅ 데이터베이스에 연결되었습니다!\n\n우리는 데이터베이스에 연결할 수 있습니다. .env 파일에서 구성한 모든 연결 정보를 기억해 주세요. 이 정보는 docker-compose, sqlx-cli, 그리고 우리의 어플리케이션에서 공유되었습니다.\n\n## Inserts\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 연결 풀이 준비되었으니, 우리가 살펴볼 첫 번째 데이터베이스 로직은 삽입입니다. sqlx를 사용하여 삽입하는 방법은 다음과 같습니다.\n\n```rust\nlet insert_result = sqlx::query_as!(\n    Locations,\n    \"INSERT INTO locations (id,name) VALUES (1, 'Location A') RETURNING *\"\n)\n.fetch_one(\u0026pool)\n.await;\n\nmatch insert_result {\n    Ok(location) =\u003e {\n        info!(\"✓Inserted: {:?}\", location);\n    }\n    Err(e) =\u003e {\n        error!(\"Error Insert: {}\", e.to_string())\n    }\n}\n```\n\n이 코드는 하나의 레코드를 삽입할 것입니다. 물론 매개변수를 사용할 수도 있으며, 이는 업데이트를 살펴볼 때 살펴볼 것입니다.\n\n## 질의하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로, 데이터베이스를 조회하는 방법을 살펴보겠습니다.\n\n```js\n    let query_result = sqlx::query_as!(Locations, \"SELECT * FROM Locations\")\n        .fetch_all(\u0026pool)\n        .await;\n    if query_result.is_err() {\n        let message = \"모든 위치를 가져오는 동안 문제가 발생했습니다.\";\n        error!(\"{}{}\", message, query_result.err().unwrap());\n    } else {\n        info!(\"😎 위치에 대한 쿼리 결과 {:?}\", query_result.unwrap());\n    }\n```\n\n이것은 성공적으로 작동했다면 unwrap을 통해 결과에 접근할 수 있는 결과를 반환합니다. 쿼리 내의 이슈가 발생했다면 해당 에러에 접근할 수도 있습니다.\n\n## 업데이트\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 작업은 데이터베이스를 업데이트하는 것입니다. 이는 이전에 삽입한 것과 비슷할 것입니다.\n\n```js\n    let update_result = sqlx::query_as!(\n        Sessions,\n        \"UPDATE sessions SET watts = 415 WHERE id = $1 RETURNING *\",\n        1i64,\n    )\n    .fetch_one(\u0026pool)\n    .await;\n\n    match update_result {\n        Ok(session) =\u003e {\n            info!(\"✓Update: {:?}\", session);\n        }\n        Err(e) =\u003e {\n            error!(\"Error Update: {}\", e.to_string())\n        }\n    }\n```\n\n이 예제에서 주목할 점은 $1이라는 매개변수 자리 표시자를 사용하는 준비된 문(statement)를 사용하고 있다는 것입니다. 그런 다음 SQL 문자열 뒤에 매개변수를 전달합니다.\n\n## Deletes\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로, 데이터베이스에서 레코드를 삭제하는 CRUD 작업을 완료합니다. 우리의 목적은 데이터베이스를 정리하는 데 사용할 것이며, 이렇게 하면 언제든지 응용 프로그램을 실행할 수 있습니다.\n\n```js\nlet rows_deleted = sqlx::query!(\"DELETE from sessions\")\n    .execute(\u0026pool)\n    .await\n    .unwrap()\n    .rows_affected();\n\ninfo!(\"✕ 세션 테이블에서 {}개의 행 삭제됨\", rows_deleted);\n```\n\n여기서는 연산에서처럼 sqlx::query 대신 sqlx::query_as를 사용합니다. 또한 언랩 이후 .rows_affected를 추가하여 삭제된 행 수를 얻습니다.\n\n## 트랜잭션\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```rust\n   let tx = pool.begin().await.expect(\"트랜잭션을 시작할 수 없습니다\");\n\n   // 데이터베이스 작업 수행(데이터 삽입 또는 변경)\n\n   tx.commit().await.expect(\"트랜잭션을 커밋할 수 없습니다\");\n```\n\n커밋을 호출하지 않으면 트랜잭션이 범위를 벗어나면 자동으로 롤백됩니다.\n\n## 완전한 응용 프로그램\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 코드는 우리가 이전에 논의한 모든 다양한 기능이 하나의 애플리케이션에 모두 포함된 완전한 애플리케이션입니다.\n\n```js\nuse dotenv::dotenv;\nuse log::{error, info};\nuse sqlx::{postgres::PgPoolOptions, Pool, Postgres};\n\n#[derive(Debug)]\nstruct Locations {\n    id: i64,\n    name: String,\n}\n\n#[derive(Debug)]\nstruct Sessions {\n    id: i64,\n    location_id: i64,\n    watts: i64,\n    vin: String,\n}\nasync fn insert_into_locations(pool: Pool\u003cPostgres\u003e) {\n    let tx = pool.begin().await.expect(\"Unable to begin transaction\");\n\n    let insert_result = sqlx::query_as!(\n        Locations,\n        \"INSERT INTO locations (id,name) VALUES (1, 'Location A') RETURNING *\"\n    )\n    .fetch_one(\u0026pool)\n    .await;\n\n    match insert_result {\n        Ok(location) =\u003e {\n            info!(\"✓Inserted: {:?}\", location);\n        }\n        Err(e) =\u003e {\n            error!(\"Error Insert: {}\", e.to_string())\n        }\n    }\n    let insert_result = sqlx::query_as!(\n        Locations,\n        \"INSERT INTO locations (id,name) VALUES (2, 'Location B') RETURNING *\"\n    )\n    .fetch_one(\u0026pool)\n    .await;\n\n    match insert_result {\n        Ok(location) =\u003e {\n            info!(\"✓Inserted: {:?}\", location);\n        }\n        Err(e) =\u003e {\n            error!(\"Error Insert: {}\", e.to_string())\n        }\n    }\n\n    tx.commit().await.expect(\"Unable to commit the transaction\");\n}\n\nasync fn insert_into_sessions(pool: Pool\u003cPostgres\u003e) {\n    let tx = pool.begin().await.expect(\"Unable to begin transaction\");\n\n    let insert_result = sqlx::query_as!(\n        Sessions,\n        \"INSERT INTO sessions (id,location_id, watts, vin) VALUES (1, 1, 420, '2FMZA52286BA02033') RETURNING *\"\n    )\n    .fetch_one(\u0026pool)\n    .await;\n\n    match insert_result {\n        Ok(session) =\u003e {\n            info!(\"✓Inserted: {:?}\", session);\n        }\n        Err(e) =\u003e {\n            error!(\"Error Insert: {}\", e.to_string())\n        }\n    }\n    let insert_result = sqlx::query_as!(\n        Sessions,\n        \"INSERT INTO sessions (id,location_id, watts, vin) VALUES (2, 2, 393, '1GMYA52286BA04055') RETURNING *\"\n)\n    .fetch_one(\u0026pool)\n    .await;\n\n    match insert_result {\n        Ok(session) =\u003e {\n            info!(\"✓Inserted: {:?}\", session);\n        }\n        Err(e) =\u003e {\n            error!(\"Error Insert: {}\", e.to_string())\n        }\n    }\n\n    tx.commit().await.expect(\"Unable to commit the transaction\");\n}\n\nasync fn update_sessions(pool: Pool\u003cPostgres\u003e) {\n    let tx = pool.begin().await.expect(\"Unable to begin transaction\");\n\n    let update_result = sqlx::query_as!(\n        Sessions,\n        \"UPDATE sessions SET watts = 415 WHERE id = $1 RETURNING *\",\n        1i64,\n    )\n    .fetch_one(\u0026pool)\n    .await;\n\n    match update_result {\n        Ok(session) =\u003e {\n            info!(\"✓Update: {:?}\", session);\n        }\n        Err(e) =\u003e {\n            error!(\"Error Update: {}\", e.to_string())\n        }\n    }\n\n    tx.commit().await.expect(\"Unable to commit the transaction\");\n}\n\nasync fn clean_db(pool: Pool\u003cPostgres\u003e) {\n    let rows_deleted = sqlx::query!(\"DELETE from sessions\")\n        .execute(\u0026pool)\n        .await\n        .unwrap()\n        .rows_affected();\n\n    info!(\"✕Deleted {} rows from sessions table\", rows_deleted);\n\n    let rows_deleted = sqlx::query!(\"DELETE from locations\")\n        .execute(\u0026pool)\n        .await\n        .unwrap()\n        .rows_affected();\n    info!(\"✕Deleted {} rows from locations table\", rows_deleted);\n}\n\nasync fn query_locations(pool: Pool\u003cPostgres\u003e) {\n    let query_result = sqlx::query_as!(Locations, \"SELECT * FROM Locations\")\n        .fetch_all(\u0026pool)\n        .await;\n    if query_result.is_err() {\n        let message = \"Something bad happened while fetching all locations\";\n        error!(\"{}\", message);\n    } else {\n        info!(\"😎Query Result For Locations {:?}\", query_result);\n    }\n}\n\nasync fn query_sessions(pool: Pool\u003cPostgres\u003e) {\n    let query_result = sqlx::query_as!(Sessions, \"SELECT * FROM Sessions\")\n        .fetch_all(\u0026pool)\n        .await;\n    if query_result.is_err() {\n        let message = \"Something bad happened while fetching all sessions\";\n        error!(\"{}\", message);\n    } else {\n        info!(\"😎Query Result for Sessions {:?}\", query_result);\n    }\n}\n\n#[tokio::main]\nasync fn main() {\n    if std::env::var_os(\"RUST_LOG\").is_none() {\n        std::env::set_var(\"RUST_LOG\", \"info\");\n    }\n    dotenv().ok();\n    env_logger::init();\n\n    let database_url = std::env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n    let pool = match PgPoolOptions::new()\n        .max_connections(10)\n        .connect(\u0026database_url)\n        .await\n    {\n        Ok(pool) =\u003e {\n            info!(\"✅Connection to the database is successful!\");\n            pool\n        }\n        Err(err) =\u003e {\n            error!(\"🔥 Failed to connect to the database: {:?}\", err);\n            std::process::exit(1);\n        }\n    };\n    clean_db(pool.clone()).await;\n\n    insert_into_locations(pool.clone()).await;\n    query_locations(pool.clone()).await;\n\n    insert_into_sessions(pool.clone()).await;\n    query_sessions(pool.clone()).await;\n\n    update_sessions(pool.clone()).await;\n    query_sessions(pool.clone()).await;\n}\n```\n\n위 애플리케이션을 실행한 결과는 다음과 같습니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_5.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위와 같이 데이터베이스 상호작용 토론을 마쳤습니다. sqlx를 사용하여 데이터베이스 작업을 수행하는 방법에 대해 좋은 개요를 제공했을 겁니다.\n\n# 요약\n\n저희 러스트 학습 시리즈의 이 부분을 즐기셨기를 바랍니다. 시리즈 이번 섹션에서는 먼저 러스트에서 객체 생성에 대한 매우 유용한 패턴인 빌더 패턴을 살펴보았습니다. 이는 다른 언어에서 익숙할 수 있지만, 러스트에서 어떻게 구현하는지 살펴보았습니다.\n\n다음으로, 우리는 Rust를 사용하여 데이터베이스인 특히 Postgres와 상호작용하는 방법을 검토했습니다. 우리는 마이그레이션을 실행하고 데이터베이스에 연결하는 방법을 보았으며, 그 후 DB에 대해 여러 가지 CRUD 작업을 수행하는 방법을 살펴보았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n러스트 학습 여정에 함께해줘서 고마워요.\n\n좋은 여행 되세요!\n","ogImage":{"url":"/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_0.png"},"coverImage":"/assets/img/2024-05-23-LearningRustPart11BuildersandDatabaseInteraction_0.png","tag":["Tech"],"readingTime":24},{"title":"데브 컨테이너로 Rails 앱을 도커라이즈하기","description":"","date":"2024-05-23 14:10","slug":"2024-05-23-DockerizeRailsappwithDevContainers","content":"\n![이미지](/assets/img/2024-05-23-DockerizeRailsappwithDevContainers_0.png)\n\n만약 Rails 프로젝트 또는 다른 프레임워크에 대해 Docker를 시도해보려고 망설이고 있다면, 꼭 한 번 시도해보기를 추천합니다. VSCode의 Dev Containers 확장 프로그램을 사용하면 프로세스가 놀랄 만큼 스무스해지고 로컬 개발 과정이 간편해집니다.\n\n이미 CI/CD 파이프라인이나 배포에 Docker를 사용해본 적이 있다면 컨테이너화의 이점에 익숙할 것입니다. 그러나 솔직히 말해서 로컬 개발에 있어서 Docker는 항상 편리하지는 않습니다. 모든 것에 docker 또는 docker-compose 명령을 추가해야 한다는 것은 조금 귀찮은 일일 수 있습니다.\n\n이때 DevContainers가 등장합니다. 이를 통해 로컬 Rails 개발 환경 (및 다른 프레임워크)을 위한 전체 Docker 설정이 간단해집니다. 더 이상 명령줄이 혼잡해지지 않고, 매끄럽고 일관된 개발 경험만을 가져다줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nVSCode에서 개발 컨테이너를 사용하여 Rails를 도커화하는 간단한 튜토리얼을 제공합니다. 또한 도커나 도컴포즈 명령어를 실행할 필요 없이 컨테이너 환경 내에서 작업하는 방법을 안내합니다.\n\n본 튜토리얼에서는 다음을 배울 수 있습니다:\n\n- VSCode 편집기의 DevContainers 확장 프로그램을 사용하여 Docker 컨테이너 내에서 새로운 Rails 프로젝트를 신속하게 생성하는 방법\n- 터미널에서 복잡한 Docker 명령어를 필요로하지 않도록 함\n- 데이터 지속성을 위해 MySQL 데이터베이스 컨테이너를 사용하여 이중 구조 아키텍처 구축\n- Rails와 함께 MySQL을 컨테이너 내에서 실행\n- 멀티 스테이지 도커 파일을 사용하여 개발 및 프로덕션 환경에 대한 이미지 빌드 최적화\n- VSCode 내에서 간편하고 효율적인 Rails 개발 워크플로우 달성\n\n이 글과 관련된 튜토리얼을 통해 Rails 프로젝트에서 Dev Containers를 사용해보기를 고려하게끔 도와드리기를 바랍니다. 개발 프로세스를 최적화하고, 협업을 개선하며, 일관된 환경을 유지하는 환상적인 방법입니다. 즐거운 코딩 되세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 도움이 되었다면, 추가적인 팁과 튜토리얼을 보기 위해 LinkedIn을 팔로우하고 YouTube 채널을 구독해주세요.\n\n## 추가 학습 내용:\n\n- 멀티 스테이지 도커 빌드 배우기\n- DevContainers로 로컬 DevOps 환경 설정하는 방법 배우기\n- VSCode 확장 프로그램 DevContainers\n","ogImage":{"url":"/assets/img/2024-05-23-DockerizeRailsappwithDevContainers_0.png"},"coverImage":"/assets/img/2024-05-23-DockerizeRailsappwithDevContainers_0.png","tag":["Tech"],"readingTime":2}],"page":"72","totalPageCount":120,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"72"},"buildId":"JlBEgQDLGRx6DYlBnT8eD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>