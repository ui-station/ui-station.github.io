<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/72" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/72" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_buildManifest.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="중간여행에서 화제를 모으는 아트워크 만드는 방법 - 6가지 예시" href="/post/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="중간여행에서 화제를 모으는 아트워크 만드는 방법 - 6가지 예시" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="중간여행에서 화제를 모으는 아트워크 만드는 방법 - 6가지 예시" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">중간여행에서 화제를 모으는 아트워크 만드는 방법 - 6가지 예시</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="놀라운, 끊임없이 변화하는 상호작용하는 AI 예술 전시회 HyperCinema가 뉴질랜드에서 공개되었습니다" href="/post/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="놀라운, 끊임없이 변화하는 상호작용하는 AI 예술 전시회 HyperCinema가 뉴질랜드에서 공개되었습니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="놀라운, 끊임없이 변화하는 상호작용하는 AI 예술 전시회 HyperCinema가 뉴질랜드에서 공개되었습니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">놀라운, 끊임없이 변화하는 상호작용하는 AI 예술 전시회 HyperCinema가 뉴질랜드에서 공개되었습니다</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="스타일러 AI 얼굴 킷" href="/post/2024-05-20-StylarAIFaceKit"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="스타일러 AI 얼굴 킷" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-StylarAIFaceKit_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="스타일러 AI 얼굴 킷" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">스타일러 AI 얼굴 킷</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="고급 RAG 08 Self-RAG" href="/post/2024-05-20-AdvancedRAG08Self-RAG"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고급 RAG 08 Self-RAG" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고급 RAG 08 Self-RAG" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고급 RAG 08 Self-RAG</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="OpenAI API를 통해 GPT-4o에 접속하기" href="/post/2024-05-20-AccessingGPT-4oviaOpenAIAPI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="OpenAI API를 통해 GPT-4o에 접속하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="OpenAI API를 통해 GPT-4o에 접속하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">OpenAI API를 통해 GPT-4o에 접속하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="BERT 코드와 함께하는 완벽 가이드" href="/post/2024-05-20-ACompleteGuidetoBERTwithCode"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="BERT 코드와 함께하는 완벽 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="BERT 코드와 함께하는 완벽 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">BERT 코드와 함께하는 완벽 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">54<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="고유명사 인식 노출 - 필수 가이드" href="/post/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고유명사 인식 노출 - 필수 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고유명사 인식 노출 - 필수 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고유명사 인식 노출 - 필수 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기" href="/post/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">22<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어" href="/post/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="용어 해설 AI 시스템 제어하기" href="/post/2024-05-20-GlossaryControllingAISystems"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="용어 해설 AI 시스템 제어하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-GlossaryControllingAISystems_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="용어 해설 AI 시스템 제어하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">용어 해설 AI 시스템 제어하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/61">61</a><a class="link" href="/posts/62">62</a><a class="link" href="/posts/63">63</a><a class="link" href="/posts/64">64</a><a class="link" href="/posts/65">65</a><a class="link" href="/posts/66">66</a><a class="link" href="/posts/67">67</a><a class="link" href="/posts/68">68</a><a class="link" href="/posts/69">69</a><a class="link" href="/posts/70">70</a><a class="link" href="/posts/71">71</a><a class="link posts_-active__YVJEi" href="/posts/72">72</a><a class="link" href="/posts/73">73</a><a class="link" href="/posts/74">74</a><a class="link" href="/posts/75">75</a><a class="link" href="/posts/76">76</a><a class="link" href="/posts/77">77</a><a class="link" href="/posts/78">78</a><a class="link" href="/posts/79">79</a><a class="link" href="/posts/80">80</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"중간여행에서 화제를 모으는 아트워크 만드는 방법 - 6가지 예시","description":"","date":"2024-05-20 21:18","slug":"2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples","content":"\n# 1. 리얼과 가짜를 섞어보세요\n\n![이미지](/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_0.png)\n\n# 2. 실제 세계 물건과 유명 지형을 다른 장소에 배치해보세요\n\n![이미지](/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 3. 사진 조작\n\n![image](/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_2.png)\n\n# 4. 터무니없음\n\n![image](/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 5. 기분이 좋지 않아\n\n![이미지](/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_4.png)\n\n# 6. 파스텔 톤 추가\n\n![이미지](/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_5.png)\n","ogImage":{"url":"/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_0.png"},"coverImage":"/assets/img/2024-05-20-HowtoMakeEyeCatchingArtworkinMidjourney6Examples_0.png","tag":["Tech"],"readingTime":2},{"title":"놀라운, 끊임없이 변화하는 상호작용하는 AI 예술 전시회 HyperCinema가 뉴질랜드에서 공개되었습니다","description":"","date":"2024-05-20 21:15","slug":"2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand","content":"\n저는 HyperCinema의 CTO 인 Gareth Hordyk와 이야기할 기회를 가졌어요. 그는 세계에서 첫 번째로 소개된 \"관객을 영화적 서사의 중심에 위치시키는 라이브 AI 체험\"이라고 소개되는 HyperCinema의 CTO입니다. 우리가 이야기를 시작하자마자, 전문가뿐만 아니라 열정적인 이야기꾼이자 AI에 무언가를 기여하고 있는 사람과 함께 있는 것을 깨달았어요.\n\nGareth는 이전에 Pinewood Studios와 Jim Henson의 Creature Shop에서 로봇 시스템을 만들었던 경험이 있어요. AI 기술을 완전히 받아들인 창의적인 사고와 대화를 나누는 것은 흥미로워요. (우리 둘 다 그냥 \"도구\"로 부르는 일반적인 용어에 만족하지 않고 \"협력자\"로 정의하는 것에 동의했어요.) 산업에서는 AI가 여전히 의심을 받고 있고 대중도 불확실해하고 있는 상황에서, Gareth가 AI 예술에 대한 첫 경험을 하는 방문객이 많다는 점을 언급하며, 좋은 첫 경험이 되도록 하고 싶다고 말했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이미지 목록\n\n웃음. 기쁨. 그것이 성공을 측정하는 방법입니다. 가레스는 때때로 다른 층에서 작업 중일 때 관중들의 기쁨과 놀람의 구호를 듣습니다. 또한, AI 세대의 방향을 결정할 때 팀이 따르는 원칙이기도 합니다. 초기에 그들은 HyperCinema가 참가자들을 안내하는 AI 다중우주의 여정에서 자신들의 버전을 만나게 되는 곳에서 유머, 경이, 그리고 낙관주의의 길로 나아가야 한다는 것을 깨달았습니다.\n\n하지만 저는 스스로를 앞서가고 있습니다! (아마도 Hypercinema의 파편화된 시간들이 전염되었나 봐요). 다중우주? HyperCinema는 무엇인가요?\n\n## HyperCinema: 탄생 이야기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n뉴질랜드 오클랜드를 기반으로 한 HyperCinema는 극장의 거물인 Miles Gregory 박사와 Gladeye 팀이 만들어낸 작품입니다.\n\nMiles는 뉴질랜드와 호주에서 Pop-up Globe를 개척해 크게 화제가 되었습니다. 그 프로젝트는 1614년 실제 셰익스피어 극장의 환상적인 세계들을 아오테아로아(뉴질랜드의 현대 몽골어 이름인 아오테아로아는 국제 독자들을 위한 설명입니다)에 가져다 주었습니다.\n\n한편, Gladeye는 2023년 롤링 스톤에서 발표한 디지털 스토리텔링 프로젝트로 우수한 대화형 미디어에 노미네이트된 크리에이티브 디지털 에이전시입니다. Gladeye의 CEO인 Tarver Graham은 HyperCinema의 공동 창립자이자 공동 크리에이티브 디렉터입니다. Gareth Hordyk는 HyperCinema의 CTO이자 Gladeye의 오퍼레이션 매니저 및 제품 컨설턴트입니다. 이 창의적인 인재들이 함께 작업하며 극적이고 디지털적인 스토리텔링 분야에서의 강점을 살려 HyperCinema 관객들에게 다른 어느 극적 상호작용 경험과도 비슷하지 않은 극장적 경험을 선사할 것입니다.\n\n## AI, 예술, 그리고 멀티버스의 교차점\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 HyperCinema는 무엇인가요? HyperCinema는 AI가 생성한 하이퍼 개인화된 내러티브를 통해 짧은 영화, 이미지, 텍스트 및 오디오를 통해 탐구할 수 있는 대화형 경험입니다.\n\n![이미지](/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_1.png)\n\n이는 선택-당신-모험의 부분과 Night Gallery의 친절한 에피소드의 일부입니다. 여기서 모든 초상화는 자신의 것입니다(다소 역사적인 분위기의 Twilight Zone에서 온 우주적인 1920년대 벨보이들의 것일 수도 있습니다). 이곳은 일어나지 않은 삶을 전시하는 박물관입니다.\n\n![이미지](/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## AI 예술로 초괴도 가속\n\n현재 하이퍼시네마의 시즌은 \"멀티버스에 들어가다\"입니다. Gareth은 다른 주제도 볼 것이라고 암시했습니다; 할로윈은 너무 빨리 지나갔지만, 크리스마스 버스가 곧열날 것일까요? Gareth는 AI 공간에서 당신은 흥분을 느끼며 창조해야 하며, 돌아보지 말고 먼저 내보내야 한다고 관찰했습니다 (그것이 세계 최초의 라이브 AI 경험을 성취한 방식입니다).\n\n이 접근 방식은 저도 강력히 동의하는 부분입니다; AI 예술의 변덕스러운 세계에서는 선발이 되어야 하고, 훌륭한 것을 만들어야 하며, 진보해야 합니다. 아마도 각 맞춤형 작품들은 데이터 보호를 위해 각 맞춤 세션 사이에 삭제되기 때문에, 과거에는 이 정도로 전체적인 아트 컬렉션을 삭제하고 재설정한 갤러리나 그와 같은 특별한 매력이 있는 곳이 있었을까요? 이것은 일시적이지만 일생일대입니다. 예전에는 명화를 주문받기 위해 부유하고 유명하거나 귀족이어야 했지만, 이제 자아반영의 전시회를 거쳐갈 수 있지만, 그 뒤로는 사라집니다.\n\n이러한 빠르게 생성된 AI 걸작 예술품은 당신이 주인공인 것을 보는 다른 이는 없습니다 (여러분의 \"사이드킥\"을 제외하고, 곧 초능력 슈퍼히어로 원형에 대해 이야기할 것입니다). 이 독점성이 자신 중심적인지 아니면 겸손한지는 결정할 수 없습니다 - 당신에 관한 일시적인 갤러리, \"명성은 금방 사라진다\"는 것을 상기시키는 것인가요. 최소한, 당신이 이 짧은 경험을 상품화하려고 결정한다면 기념품 가게가 있습니다! (사진을 찍을 수는 있지만, Eco가 의심 없이 이야기하듯이, 기념품은 초현실 경험의 극치입니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 왜 멀티버스인가요?\n\n더 넓은 의미에서 \"멀티버스\"의 주제는 인공지능이 빠르게 무한한 변형을 반복하는 능력을 축하합니다(\"비나다는 다양성 속의 무한한 조합\"이 떠오릅니다). 모든 AI 예술가가 아는 것처럼, 이미지를 계속 생성하는 것은 중독적입니다. 각각은 다른 가정을 엿볼 수 있게 해줍니다.하지만 종종 설득력 있는 '실제' 장면이다. 지금까지 전 세계에서 150 억 개 이상의 AI 이미지가 생성되었습니다. 일찍부터 사진작가들이 이 기록적인 순간에 이르기까지는 약 150년이 걸렸습니다, 대략 1975년경에.\n\n![이미지](/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_3.png)\n\nHyperCinema는 우리의 현재 모든 정체성, 현실에 관한 논의와 너자신을 중심으로 한 예술적 경험에 모두 포장되어 있습니다. 그러나 여기에... 너가 포함되어 있지 않나요? AI 셀카가 기술적으로 발달한 포스트모던 사회에서 초현실주의의 정점일까요, 사실과 허구 사이의 경계를 흐리게 하는 걸까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_4.png\" /\u003e\n\n저는 모르겠어요, 그러나 이건 한 번 해봐야 할 사진 기회에요 (불가능한 AI 초상화로 예술 갤러리에서 셀카를 찍으면 장 보드리야르의 머리를 놓겠지). 다중 우주 테마는 시대정신과 일치하지만, AI의 창의력과 다양한 변수에 대한 재미난 실험이기도 해요.\n\n## 초현실 변화\n\nHyperCinema는 세 가지 다른 단계에서 진행돼요. 첫 번째는 트립티한 몰입형 프로젝션 공간으로, 참가자들은 자신을 이세계적인 상황에서 4미터 높이에 투사된 모습을 볼 수 있어요. 두 번째는 맞춤형 AI 예술 갤러리이고, 세 번째는 참가자가 자신의 병렬적인 삶을 자세히 소개하는 짧은 전기영화를 감상하는 극장이에요. 주된 참가자는 이 만남 동안 계속해서 “영웅(Hero)”으로 칭해요; 그러나 사진을 찍는 것을 덜 좋아하는 친구인 “조수(Sidekick)”와 함께 이 경험을 공유할 수도 있어요. 다른 참가자들을 마주칠 수도 있지만, 그들 또한 자신만의 다중 우주 여행을 통과하는 지나가는 여행자들이에요. 하지만 다시 한 번, 내가 다시 앞서 나가버렸네요 (계속 변화하는 시간축을 탓해야겠어요!).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n평범한 세계를 벗어나는 데 물리적인 표식이 없는 영웅의 여정은 무엇일까요? HyperCinema에는 신비로운 큐브가 있습니다. 이것에 대해 간단하고 감동적인 느낌이 있습니다. AI와 Marvel은 Jarvis AI부터 Secret Invasion까지 계속해서 등장하고 있죠. HyperCinema가 최고의 영화 시리즈의 트로프를 의도적으로 따르고 있는 걸까요? \"멀티버스\", \"영웅\", \"조수\" 및 \"우주 큐브\"라고 하면요? 이 중에서 심지어 참가자가 우주 비행사로 변신한 후 갓 태어난 아기가 되는 멀티버스 시퀀스도 있습니다. 이는 마치 '엔드게임' 속 한 장면을 떠올리게 합니다.\n\n가레스는 아는 듯이 웃으면서 HyperCinema의 가능성 있는 미래 버전에서 라이선스를 획득한 캐릭터를 중심으로 주제를 구성할 수도 있다고 암시합니다. 제 정기 독자들이 알 것처럼, AI 중심의 맞춤형 엔터테인먼트가 Disney/Marvel과 같은 거대 기업이 AI의 도전에 직면하는 방향이 될 것이라고 작성해 왔습니다. HyperCinema는 그 일부를 맛 볼 수 있게 해줍니다.\n\n## 다시 돌아와서\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모험의 부름을 받은 영웅들은 큐브를 콘솔에 넣고 성격 질문을 응답합니다. 그들의 디지털 프로필 결과는 이 큐브에 저장된다고 하는데, 나는 그게 인공지능 초보자들을 위한 눈꺼풀질에 불과한 것 같다고 의심합니다. 그것은 그들에게 안심감을 주는 물리적인 \"토템\"을 제공하는 것입니다.\n\n나는 이 아이디어를 좋아합니다. 이는 촉감과 인공지능 사이를 흐린다는 점 뿐만 아니라, 그들의 고유한 식별자가 큐브로 다운로드되는 느낌, 그것이 경험 동안 영웅들이 설치물을 활성화하는 데 사용되는 것입니다. 이것은 훌륭한 손길이며, 비록 사기책일지라도 말입니다.\n\n질문서는 이야기를 이끌어가기 위해 사용되며, 당신이 좋아하는 채소와 가지고 싶은 초능력 같은 해밍웨이 질문부터 시작하여 인류에게 가장 큰 위협이 무엇이라고 생각하는 등 더 깊은 존재주의적 질문까지 이어집니다. \"딥 페이크\"라고 대답하는 것이 알고리즘을 자화상의 토속으로 빠지게 할 수 있는 흥미진진한 삽을 상상할 수밖에 없다는 거죠!\n\n성격 프로필 외에도 15장의 사진이 찍힙니다. 인공지능 전문가는 이것을 인공지능을 훈련하기 위한 소규모 데이터 세트에 필요한 대략적인 숫자로 인식할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n약 15분 후에, 개인화 과정이 완료됩니다. 히어로의 시각적 여정은 앞서 말한 미지의 미래(Dreamscapes of Untold Futures)에서 시작하며(크기가 커보이는 프로젝션), 이어서 이상한 즐거움의 살롱(Salon of Uncanny Delights)(갤러리)로 이어지고, 마지막으로 불가능한 역사의 영화관(Cinema of Impossible Histories)(시네마)로 이어집니다.\n\n# 당신의 갤러리\n\n![이미지](/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_5.png)\n\n미술 갤러리에서 당신의 큐브가 녹색으로 빛나며, 당신의 얼굴로 변하는 프레임된 작품의 집단을 변경할 수 있습니다. Gareth는 참가자들이 주변을 돌아다니면서 모든 초상화를 활성화하고자 하거나 - 가능한 많이 - 자신을 반영하고 개인 갤러리를 갖도록 하는 것을 설명합니다(여러 히어로들과 그들의 사이드킥들이 동시에 경험을 즐길 수 있음을 언급할 가치가 있습니다; 사용자의 개인적인 움직임을 통해 사용자 정의 요소가 공간을 통해 활성화됩니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, 각 이미지에는 대체로 어떻게 그 지점에 이르렀는지에 대한 AI 텍스트 생성 설명이 포함되어 있습니다. Gareth는 이러한 안내판이 의외로 인기가 많다고 말했는데, 사람들이 멀티버스 이미지만큼이나 이 배경 이야기의 사진을 찍는다고 합니다.\n\n## 자신만의 \"빙 존 말코비치\" 순간\n\n![이미지](/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_6.png)\n\n다음으로, 영웅은 불가사의한 역사의 영화관에 들어갑니다. 여기서 그들은 멀티버스 콜라주가 특징인 꿈틀거리는 짧은 영화를 보게 됩니다. AI 보이스 오버로 이뤄진 AI 생성 텍스트에서 내려오는 설명으로 이야기됩니다. 이 시퀀스는 거의 예고편의 연속이며, 대체된 삶에 대한 매혹적인 엿보기를 제공합니다. 아마도 가족 식사하는 가족 구성원 모두가 되어 있는 상황 같은 것도 포함할 수 있습니다 (백 투 더 퓨처 파트 II의 장면처럼, 마이클 J. 폭스가 모든 역할을 맡은 경우):\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 당신은 생물학 영화의 어떤 모음을 얻을지 정확히 알 수 없습니다: 장면은 맞춤형이고 확률적이기 때문에 두 번 다를 수 없습니다. Gareth는 HyperCinema의 재생 가능성에 대해 이야기하며, 반복 방문자들이 여정을 다시 경험하기 위해 얼마나 자주 방문하는지에 대한 놀라운 점 중 하나였다고 말합니다. 이것은 신비로운 모순입니다. 왜냐하면 이것은 \"한 강에 두 번째 발을 딛을 수 없다\"는 고대 헤라클리테스의 개념에 공명합니다. 창조의 각 순간은 독특하며, 소프트웨어가 적응합니다. 이 작업은 지속적인 변화 중에 있습니다.\n\nGareth가 멀티미디어 구성 요소를 설명하는 동안, 나는 너무 많은 가능성을 보기 때문에 방해하기 싫어하며, HyperCinema를 탈출 방과 같은 서사가 풍부한 엔터테인먼트로 확장할 생각이 있느냐고 물었습니다. 아직은 아니라고 Gareth가 빛을 발하며 말하자, 나는 그들의 멀티버스에서 파급되는 새로운 방향을 일으켰는지 궁금해합니다.\n\n# 마술 뒤의 마술: HyperCinema가 작동하는 방식\n\n내 독자들이 HyperCinema를 구동하는 핵심 AI 기술과 맞춤형 시네마틱 경험을 만들 때 고려된 메소드(또는 직면한 도전)에 대해 더 알고 싶을 것이다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3차원 인격\n\n먼저, AI 애호가로서, 나는 이 육면체에 대해 뭔가를 발견했어. 상상력에 미치는 미신적인 힘이 그들에게 얼마나 큰 영향을 주는지를 사랑해 — 당신이 자신의 본성을 다운로드하고 물리적으로 소유할 수 있다는 이 아이디어, 마치 비트코인을 위한 하드웨어 고안 보안 지갑처럼 — 그러나 IT Crowd 에피소드에서 Moss가 인터넷이 검은 상자에 빨간 불빛이 들어있다고 여하면서 젠을 속이는 모습을 떠올려보곤 해.\n\n육면체가 정말 \"인격 프로필을 담고 있는가\" 묻자 Gareth는 참가자의 위치를 따라간다는 것을 확인했어. 하지만 여전히, 영웅들은 그것을 이상하고 초자연적인 힘으로 꽉 쥐고 있어. Gareth는 참가자들에게 처음으로 육면체를 건네주면 참가자들이 셀카를 찍기 시작한다고 언급했어. 이 모든 것은 쇼의 일부이고, 나는 공연적이고 연극적인 성분이 존재한다는 것을 떠올리게 돼.\n\n육면체는 세대에게 기능적인가? 아마 아냐. 경험에 필수불가결한가? 절대적으로 그렇지. 나처럼 종굥을 구매할 때, 그 문을 들어서면서 믿음의 중단에 동의해야만 해. 우리가 물어봐야 할 유일한 질문은 앨리스가 원덜랜드에서 스스로에게 묻는 질문과 동일하다 (그게 좋은 주제가 될 것 같아?): \"나는 세상에서 누구인가? 음, 그것이 큰 수수께끼인걸.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_7.png\" /\u003e\n\n## 사진 (불)완전한 맞춤화\n\n전체 경험 뒤에 숨어있는 워크플로에 대해 말하자면, 프로세스의 특허 출원 파트가 있지만, OpenAI에 의해 제공된 파워로 구동됩니다. Gareth는 그 마법이 어떻게 작동하는지에 대해 이해하기 어렵다는 이유로 비밀스럽게 하고 있지만, 각 방문자를 위한 Stable Diffusion의 맞춤형 모델이 포함되어 빠르게 15개의 이미지에 대해 훈련됩니다. 엔드포인트로 이어지는 2000개 이상의 레시피를 책임지는 프롬프트 엔지니어팀이 있으며, 결과물이 표시되기 전에 일부 인간에 의한 결과의 선별도 수행합니다. 결국, 완전히 자율적인 정렬 방향으로 진화할 것으로 예상됩니다. 그러나 가끔 발생하는 장애물이나 환각은 특히 유머러스하거나 '멀티버스'로 설명될 수 있다면 그대로 남겨둡니다.\n\n예를 들어, Gareth는 어떻게 푸른 머리의 주부들이 하루 중 무작정 등장했는지 설명합니다. 모두가 1960년대 AI 마지 심슨 변신을 한 것입니다. 여기서 멀티버스 주제가 AI의 즉흥적 행동과 완벽하게 어울리는 지점 하나가 되어 AI 의사 결정 프로세스의 불투명성 및 비예측성의 매력적인 측면을 강조합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 그것을 Everything Everywhere All at Once와 비교해보며, 핫도그 우주가 인공지능 예술의 실수를 조명하는 데 얼마나 도움이 되었는지 알아보았어.\n\n내 독자들을 위해 더 얻어낸 귀한 정보가 하나 더 있는데(나는 스마우그의 보물 중 하나인 빌보처럼 느껴): 촬영된 15장의 사진은 지난 다섯 년간의 전체 가짜 소셜 미디어 갤러리를 씨앗으로 사용합니다. 암벽등방법, 바닷가 등; 보통 일상생활 — 그리고 이것은 Multiverse를 보기 전에 사용되는 AI 교육 말뭉치로 사용됩니다. 명백히 실제 소셜 미디어 계정은 개인 정보 보호 및 표준화 이유로 사용되지 않습니다. 실제로 나는 이 과정을 단순화하는 데 사용되는 일상적인 사진첩들을 보는 것에 대해 더 흥미를 느끼며, 우리 모두가 코로나19 동안 중요한 사건을 놓치면서 그것들에서 의미를 찾을 것으로 의심합니다.\n\n## Multiverse로부터의 예술적 조언\n\n나는 비상한 AI 예술가들을 위한 조언을 Gareth에게 물어보기도 했어. 새로 나온 이 매체의 한가지 중요성 중 하나인 빠르게 예술을 창작하고 작품을 알리는 것에 대한 조언과 함께 Gareth는 커뮤니티 자원과 튜토리얼을 사용하고 온라인에서 트렌드인 \"완벽한\" 작품과 비교함으로써 좌절하지 말아야 한다는 중요성을 강조했어.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n“창의적인 여정의 일부로서 오류를 받아들이세요,” 그는 조언합니다. 이는 창의성을 촉진하지만 또한 AI의 학습 패턴과 출력물에 신속하게 적응하는 필요성을 강조합니다. 그는 희망하는 예술가들이 불확실성과 종종 예측할 수 없는 AI의 본질에 안락감을 느끼는 것이 중요하다고 강조하기도 합니다.\n\n## 더 많은 세계, 더 많은 선택\n\n나에게 남은 마지막 인상은 낙관주의적인 한가지입니다; AI 예술에 새로운 스타일을 불어 넣었으며 (국제 독자들에게, 여행을 원한다면 오크랜드를 방문하는 가치가 있다), 세계로 펼칠 것이라고 확신합니다. 하이퍼시네마는 NZ에서만 시작할 수 있는 여정입니다. 제 마지막 질문은 가레스가 참여자들이 어떤 경험이나 메시지를 갖고 떠나길 희망하는지 묻는 것입니다. 예상 적으로 AI 기술을 예술적인 것으로 인식할 때 사람들이 더 편안해지도록 하는 데에 대해 어떤 언급이 있을 것으로 기대합니다.\n\n저는 동의하지 않을 수 없습니다. 이는 신기술로 인한 사회적 경험뿐만 아니라 AI의 경이로움에 관한 것이기도 합니다. 기술이 엄청난 속도로 발전하더라도, 인간의 손길, 뉴질랜드 특유의 창의성과 따뜻함이 진정으로 이러한 ‘진정한 가공적인’ 경험을 잊을 수 없게 만드는 것임을 상기시켜줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n호기심 많은 분들을 위해 상호작용하는 라이브 AI 아트를 찾거나 자신과 세상을 새롭게 바라보는 유니크한 시선을 찾고 있다면, HyperCinema는 이제 뉴질랜드 오크랜드 퀸스트리트 131번지에서 12월 23일까지 연장 기간 동안 열려 있습니다.\n\n# Jim the AI Whisperer는 누구인가요?\n\nJim the AI Whisperer는 오리지널하고 매력적인 콘텐츠 작성 방법과 AI 생성기를 사용하여 멋진 시각물을 만드는 방법에 대한 개인 코칭을 제공합니다. 더 알고 싶다면 언제든지 저에게 연락하십시오.\n\n또한 저는 팟캐스트, 인터뷰, AI 프롬프트 세밀 조정, 기업을 위한 프롬프트 라이브러리 및 전문 AI 아트 작업도 가능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Jim the AI Whisperer이 추천하는 관련 기사를 즐겨보실 수 있을 거에요:\n","ogImage":{"url":"/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_0.png"},"coverImage":"/assets/img/2024-05-20-Mind-blowingever-changingInteractiveAIartexhibitionHyperCinemagoesliveinNewZealand_0.png","tag":["Tech"],"readingTime":15},{"title":"스타일러 AI 얼굴 킷","description":"","date":"2024-05-20 21:13","slug":"2024-05-20-StylarAIFaceKit","content":"\nAI는 인간 얼굴을 만드는 데 점점 능숙해지고 있어요. 하지만 복잡한 상황에서는 가끔 실수가 발생할 수 있어요. 대부분의 어플리케이션들에서 그런 경우에는 프롬프트를 다시 실행하는 것뿐이에요. 그런데 그렇게 하면 전혀 예상치 못한 이미지가 생성되기도 해요.\n\n그래서 Stylar AI가 전체적인 얼굴 키트를 만들어 줬다는 것이 좋은 소식이에요 — 세 가지 다른 도구들이 있어요. 이 도구들을 사용하면 문제를 해결하고 얼굴을 다룰 수 있답니다.\n\n실제 사진이나 Stylar에서 생성된 이미지, 다른 AI 어플리케이션에서 가져온 이미지를 사용해서 문제를 해결할 수 있는 Stylar의 얼굴 키트를 활용할 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n**킷에는 세 가지 도구가 포함되어 있습니다: Face Repair(얼굴 수리), Face Swap(얼굴 교체) 및 Face Match(얼굴 일치).**\n\n# Face Repair Tool(얼굴 수리 도구)\n\n![이미지](/assets/img/2024-05-20-StylarAIFaceKit_0.png)\n\n**이름이 말해주는 대로, 이 도구는 얼굴의 렌더링 아티팩트와 문제를 수리합니다. 이 도구에는 자체적인 멋진 창이 있으며, 여는 순간, Stylar AI가 얼굴 영역을 선택하여 수정할 수 있도록 선택 브러시를 활성화합니다.**\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기능에는 Styal에게 이 얼굴을 어떻게 만들고 싶은지 말할 수 있는 별도의 프롬프트 창과 \"원본 얼굴 보존\" 슬라이더가 있습니다.\n\n그 사용법은 명백하고 쉽습니다.\n\n저는 스팀펑크 소녀를 렌더링해보기로 결심했습니다. 원본 이미지에는 좋은 아이디어가 있었지만 품질은 다소 낮았으며, 얼굴은 선글라스에 가려져 있었고, 어떤 이유로 안경 아래에 안경이 있었습니다.\n\n어떤 얼굴을 표시하는 데 한순간이 걸린 후에 약간의 처리 시간이 지난 후에 정말 좋은 결과물을 제시받았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-StylarAIFaceKit_1.png)\n\n이 도구는 사용하기 쉽습니다. 그 말대로 작동하며 굉장히 편리합니다. 이미지 렌더링 및 혼합 아티팩트가 있는 이미지들에 자주 사용하며 사랑합니다.\n\n\"원본 얼굴 보존\" 슬라이더도 유용합니다. 특정 얼굴 특징들을 보존하는 것이 중요할 때는 슬라이더를 높이면 되고, 그렇지 않은 경우에는 작은 값을 사용하면 더 나은, 더 아름다운 결과물을 얻을 수 있습니다.\n\n# 얼굴 스왑 도구\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Stylar AI Face Swap Tool](/assets/img/2024-05-20-StylarAIFaceKit_2.png)\n\n얼굴 스왑 도구를 클릭하면 완전히 미니멀한 창이 표시됩니다. 여기에서 새 얼굴을 업로드할 수 있어요. 그것이 전부에요; Stylar AI가 나머지를 처리할 거예요.\n\n얼굴이 이미지 전체를 지배하는 경우, 환상적인 결과를 기대하지 마세요.\n\n하지만 이미지에서 얼굴이 이미지 크기의 약 30-40% 이하인 경우에는 잘 작동할 거예요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사실, 대부분의 테스트에서 얼굴 교체 도구가 광고대로 작동하여 인상적인 결과물을 제공했습니다.\n\n그리고 컨트롤이나 옵션이 없기 때문에 배울 것이 없어요 — 그냥 사용하면 됩니다.\n\n아래는 얼굴 교체의 예시입니다. 나는 이 이미지를 물감이 튀는 것과 함께 만들었고, 내가 좋아했지만 원본 이미지의 얼굴이 너무 일러스트와 같았어요. 얼굴 교체 후 결과물은 정말 좋아 보입니다.\n\n![Face Swap Example](/assets/img/2024-05-20-StylarAIFaceKit_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 또 다른 예시를 보여드릴게요.\n\n![image](/assets/img/2024-05-20-StylarAIFaceKit_4.png)\n\n그런데 이 도구가 얼굴을 교환하는 데 탁월하게 처리했지만, 이 예시는 이 도구의 조금 특이한 점을 보여줍니다: 때때로 머리 크기를 변경하는 경향이 있어요.\n\n# 얼굴 매치 도구\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![StylarAIFaceKit](/assets/img/2024-05-20-StylarAIFaceKit_5.png)\n\n이 도구는 이미지 간 변환 도구 안에 토글로 위치하고 있습니다. 다른 스타일을 \"영감\" 이미지에 적용할 때 원하는 경우 원본 얼굴을 유지하는 데 목적이 있습니다.\n\n이 도구의 효과에 대해 굉장히 놀랐고 감명을 받았습니다. 활성화되어 있으면 인식 가능한 얼굴을 잘 보존합니다.\n\n이미지 간 변환 도구 안에는 스타일 영향력과 원본 이미지 구조의 강도를 조절하는 두 개의 슬라이더도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그것은 상당히 좋은 제어를 제공하며 새로운 스타일과 원본 이미지 사이의 균형을 찾을 수 있는 가능성을 제공합니다.\n\n물론, 스타일에 따라 결과가 다를 수 있습니다. 과장된 만화 스타일이나 제작한 독특한 스타일과 같은 극단적인 스타일은 얼굴을 덜 알아볼 수 있게 만들지만, 그것은 예상된 바입니다.\n\n그럼에도 불구하고 대부분의 경우에는 아래 이미지들이 보여주는 대로 아주 잘 작동합니다.\n\n![StylarAIFaceKit_6](/assets/img/2024-05-20-StylarAIFaceKit_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 내 얼굴을 어딘가에 테스트하지 않았다면 테스트는 완전하지 않았을 것입니다. 그래서 Stylar의 인공지능 스타일 중 하나를 사용하여 바이킹 이미지를 만들고 나의 얼굴로 바이킹 얼굴을 바꿨어요.\n\n여기 두 이미지가 있어요; 잘 생긴 사람은 나에요.\n\n![내 얼굴 이미지](/assets/img/2024-05-20-StylarAIFaceKit_7.png)\n\nStylar AI에는 얼굴을 다루는 데 도움이 되는 Enhance 도구가 하나 더 있어요. 이 도구는 특별히 얼굴을 다루기 위해 설계된 것은 아니지만 이미지를 미세하게 조정하는 데(얼굴 포함) 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기 있어요. Stylar AI에는 이미지에서 얼굴을 수정, 교체 및 향상하는 멋진, 유용하고 실용적인 도구 세트가 있습니다.\n\n이 도구들은 블로그 포스트 및 마케팅 캠페인에서 브랜드를 대표할 특정 얼굴을 원할 때 유용할 수 있습니다.\n\n이 도구들은 이미지를 복원하고 수정하는 데 도움이 됩니다.\n\n그리고 실제로, 당신은 어디든지 거의 모든 스타일로 자신의 얼굴을 넣을 수 있고, 그것은 재미있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 Stylar로 실험을 하려면 예제 얼굴이나 재미있는 스타일 이미지가 필요하다면 무료로 얻을 수 있어요.\n\nAivaras Grauzinis\n","ogImage":{"url":"/assets/img/2024-05-20-StylarAIFaceKit_0.png"},"coverImage":"/assets/img/2024-05-20-StylarAIFaceKit_0.png","tag":["Tech"],"readingTime":7},{"title":"고급 RAG 08 Self-RAG","description":"","date":"2024-05-20 21:10","slug":"2024-05-20-AdvancedRAG08Self-RAG","content":"\n이 기사는 흔한 시나리오로 시작됩니다: 공개 시험을 보는 경우입니다. 일반적으로 두 가지 전략을 사용합니다:\n\n- 방법 1: 익숙한 주제에 대해서는 빠르게 답변하고, 익숙하지 않은 주제에 대해서는 참고서를 열어서 확인하고, 관련 부분을 빠르게 찾아내어 정리하고 요약한 다음, 시험지에 답변합니다.\n- 방법 2: 모든 주제에 대해 책을 참고합니다. 적절한 부분을 찾아내고, 정리하고 요약한 다음, 시험지에 답변합니다.\n\n분명히 방법 1이 선호되는 방법입니다. 방법 2는 시간이 소비될 수 있고, 관련성 없는 정보나 잘못된 정보가 들어올 수 있어 혼란과 실수를 야기할 수 있습니다. 심지어 처음에 이해한 부분에서도 발생할 수 있습니다.\n\n하지만, 방법 2는 고전적인 RAG 프로세스를 보여주며, 방법 1은 자체 RAG 프로세스를 대표합니다. 이에 대해 이 기사에서 더 자세히 다룰 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 개요\n\n그림 1은 RAG 및 Self-RAG의 주요 프로세스를 비교한 것을 보여줍니다:\n\n![그림](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png)\n\nSelf-RAG는 세 단계로 구성되어 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 필요한 경우 검색: 모델이 검색을 요구하는 경우, 예를 들어 \"미국 주가 이름을 어떻게 얻었습니까?\" (그림 1의 오른쪽 상단)와 같은 쿼리가 있을 때, 모델의 출력에는 [검색] 토큰이 포함됩니다. 이는 쿼리와 관련된 내용을 검색해야 함을 나타냅니다. 반면에 \"최고의 여름 휴가에 대해 에세이를 쓰세요\" (그림 1의 오른쪽 아래)와 같이 물어볼 때, 모델은 검색 없이 직접 답변을 생성하도록 선택합니다.\n- 병렬 생성: 모델은 프롬프트와 검색된 콘텐츠를 모두 사용하여 출력을 생성합니다. 이 과정에서 세 가지 유형의 반영 토큰이 검색된 콘텐츠의 관련성을 나타냅니다.\n- 평가 및 선택: 단계 2에서 생성된 콘텐츠가 평가되고, 최상의 세그먼트가 출력으로 선택됩니다.\n\n상기 모델은 특별히 훈련된 모델이라는 것을 유의하십시오. 이 모델의 훈련 과정은 이 기사의 후반부에서 논의될 것입니다.\n\n# 반영 토큰\n\nSelf-RAG 프레임워크의 RAG와 비교했을 때, Self-RAG 프레임워크의 차이는 생성 중 더 정확한 제어를 위해 반영 토큰을 사용한다는 것입니다. 그림 2에서 보여집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_1.png\" /\u003e\n\n본질적으로, self-RAG는 네 가지 명확한 판단을 내립니다:\n\n- [Retrieve]: 리소스 R로부터 정보를 검색할지를 결정하는 의사결정 과정.\n- [IsREL]: 주어진 데이터 d가 문제 x를 해결하는 데 필요한 정보를 포함하고 있는지를 결정하는 관련성 확인.\n- [IsSUP]: 제공된 응답 y의 내용이 데이터 d로부터 지원되는지를 확인하는 검증 과정.\n- [IsUSE]: 문제 x에 대한 응답 y의 유용성을 평가하는 평가 과정. 결과는 1에서 5까지의 점수로, 5는 가장 높은 유용성을 나타냅니다.\n\nRAG에서 검색은 상태에 관계없이 항상 처음에 수행되는 고정된 과정입니다. 반면 self-RAG는 반사 토큰을 도입하여 LLM을 더 적응적이고 지능적으로 만듭니다. LLM이 텍스트를 생성하다가 불확실성이 발생하는 부분에 도달하면 반사 토큰에서 일시 정지하여 신속하고 정확한 검색을 수행한 후 새로 습득한 정보를 사용하여 생성을 재개합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 코드 설명\n\nself-RAG 프로세스를 직관적으로 이해하기 위해 먼저 코드를 살펴보고 모델의 훈련 과정을 설명하겠습니다.\n\nself-RAG는 오픈 소스이며, Langchain과 LlamaIndex에는 각각의 구현이 있습니다. 우리는 설명을 위해 LlamaIndex의 구현을 참조할 것입니다.\n\n## 환경 설정\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저, 환경을 설정하세요.\n\n```js\n(base) Florian@instance-1:~$ conda create -n llamaindex python=3.11\n\n(base) Florian@instance-1:~$ conda activate llamaindex\n\n\n(llamaindex) Florian@instance-1:~$ pip install llama-index\n\n(llamaindex) Florian@instance-1:~$ pip install huggingface-hub\n\n(llamaindex) Florian@instance-1:~$ huggingface-cli login\n```\n\n설치 후, LlamaIndex의 대응 버전은 다음과 같습니다:\n\n```js\nllama-index                             0.10.20\n\nllama-index-core                        0.10.20.post2\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"여러분의 오픈AI API 키\"\n\nfrom llama_index.core import Document, VectorStoreIndex\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.readers import SimpleDirectoryReader\nfrom pathlib import Path\n\n\n# 옵션: SelfRAGPack 다운로드\n# 첫 실행 시 SelfRAGPack을 다운로드해야 합니다.\n# 다음 실행부터는 이 부분을 주석 처리할 수 있습니다.\nfrom llama_index.core.llama_pack import download_llama_pack\ndownload_llama_pack(\n    \"SelfRAGPack\",\n    \"./self_rag_pack\")\n\nfrom llama_index.packs.self_rag import SelfRAGQueryEngine\n\n# 이전에 다운로드하고 저장한 Llama2 모델이 있는 디렉토리.\ndownload_dir = \"여러분의 다운로드 모델 디렉토리\"\n\n# 테스트 문서 생성\ndocuments = [\n    Document(\n        text=\"남극 얼음 위를 '웨들'이라고 불리는 물개 떼가 지나다녔다. 그들의 턱시도 같은 깃털은 눈 위에서 돋보였다.\"\n    ),\n    Document(\n        text=\"펭귄 중 가장 키가 큰 황제펭귄은 다른 어떤 새보다도 더 깊이 다이빙을 할 수 있어서 500m 이상의 심해까지 다이빙을 합니다.\"\n    ),\n    Document(\n        text=\"펭귄들의 흑백색깔은 위험 방어라는 화장법의 한 종류인 카운터셰이딩입니다. 위에서 보면 펭귄의 검은 등은 바다 심지와 어우러지고, 아래에서는 펭귄의 흰 배는 밝은 표면과 어우러집니다.\"\n    ),\n    Document(\n        text=\"수직 자세이지만, 펭귄은 날지 못하는 조류입니다. 그들의 날개는 지느러미로 진화했기 때문에 수중에서 전문 수영가입니다.\"\n    ),\n    Document(\n        text=\"가장 빠른 펭귄 종류인 젠투 펭귄은 시속 36킬로미터까지 수영할 수 있으며, 수중을 순찰하는 동안 지느러미와 윤곽을 이용해 물을 가르는 식으로 전진합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 집단생활을 하는 조류입니다. 많은 종들이 번식을 위해 수만 마리까지 이를 결성합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 놀랍게도 귀가 우수하며 지저분한 떼 속에서 배우량과 새끼를 식별하는 데 명확한 호출을 의존합니다.\"\n    ),\n    Document(\n        text=\"가장 작은 펭귄 종인 리틀 블루 펭귄은 약 40cm 높이로, 남부 호주와 뉴질랜드 해안가에서 발견됩니다.\"\n    ),\n    Document(\n        text=\"번식 기간 중, 수컷 황제펭귄은 한없이 지속되는 남극 겨울을 버텨내며 몇 달간 급식없이 알을 부화시키는 반면, 암컷은 바다에서 사냥을 합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 그리고 크릴로 이루어져 있으며 이를 수중 다이빙을 통해 잡습니다.\"\n    ),\n]\n\nindex = VectorStoreIndex.from_documents(documents)\n\n# 간단한 리트리버 설정\nretriever = VectorIndexRetriever(\n    index=index,\n    similarity_top_k=10,\n)\n\n\nmodel_path = Path(download_dir) / \"selfrag_llama2_7b.q4_k_m.gguf\"\nquery_engine = SelfRAGQueryEngine(str(model_path), retriever, verbose=True)\n\n# 리트리벌 예시\nresponse = query_engine.query(\"어떤 장르인가요?\")\n\n# 리트리벌 예시\nresponse = query_engine.query(\"가장 작은 펭귄의 키는 얼마인가요?\")\n```\n\n위의 테스트 코드는 다음 결과를 생성했습니다(대부분의 llama_cpp 디버깅 정보가 제거되었습니다):\n\n```js\nModel metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\nUsing fallback chat format: None\n\nllama_print_timings:        load time =    4887.53 ms\nllama_print_timings:      sample time =      11.29 ms /    22 runs   (    0.51 ms per token,  1947.76 tokens per second)\nllama_print_timings: prompt eval time =    4887.46 ms /    24 tokens (  203.64 ms per token,     4.91 tokens per second)\nllama_print_timings:        eval time =    5883.27 ms /    21 runs   (  280.16 ms per token,     3.57 tokens per second)\nllama_print_timings:       total time =   10901.84 ms /    45 tokens\n최종 답변: '오만과 편견'은 제인 오스틴의 로맨스 소설입니다.\nllama_print_timings:        load time =    4887.53 ms\nllama_print_timings:      sample time =      11.74 ms /    20 runs   (    0.59 ms per token,  1703.29 tokens per second)\nllama_print_timings: prompt eval time =    7473.66 ms /    37 tokens (  201.99 ms per token,     4.95 tokens per second)\nllama_print_timings:        eval time =    5414.34 ms /    19 runs   (  284.96 ms per token,     3.51 tokens per second)\nllama_print_timings:       total time =   13076.88 ms /    56 tokens\n입력: ### 지시사항:\n가장 작은 펭귄은 얼마나 키가 큰가요?\n\n### 응답:\n[검색]\u003c문단\u003e펭귄들은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 크릴로 구성되어 있으며 이를 다이빙으로 잡습니다.\"\u003c/문단\u003e\n예측: [관련]가장 작은 펭귄 종류의 키는 종에 따라 달라질 수 있습니다.[지원되지 않음 / 모순][유틸리티:5]\n점수: 1.4213598342974367\n10/10 단락 완료\n\n평가 종료\n최상의 답변 선정: [관련]가\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테스트 코드를 이해하는 핵심은 SelfRAGQueryEngine 클래스의 구현에 있습니다. 이제 이 클래스를 자세히 살펴보겠습니다.\n\n## 클래스 SelfRAGQueryEngine\n\n먼저 생성자입니다. 주로 llama_cpp를 사용하여 Llama2-7B 모델을 로드하기 위해 사용됩니다.\n\n```python\nclass SelfRAGQueryEngine(CustomQueryEngine):\n    \"\"\"간단한 Self RAG 쿼리 엔진.\"\"\"\n\n    llm: Any = Field(default=None, description=\"llm\")\n    retriever: BaseRetriever = Field(default=None, description=\"retriever\")\n    generate_kwargs: Dict = Field(default=None, description=\"llm generation arguments\")\n    verbose: bool = Field(default=True, description=\"Verbose.\")\n\n    def __init__(\n        self,\n        model_path: str,\n        retriever: BaseRetriever,\n        verbose: bool = False,\n        model_kwargs: Dict = None,\n        generate_kwargs: Dict = None,\n        **kwargs: Any,\n    ) -\u003e None:\n        \"\"\"매개변수 초기화.\"\"\"\n        super().__init__(verbose=verbose, **kwargs)\n        model_kwargs = model_kwargs or _MODEL_KWARGS\n        self.generate_kwargs = generate_kwargs or _GENERATE_KWARGS\n        try:\n            from llama_cpp import Llama\n        except ImportError:\n            raise ImportError(_IMPORT_ERROR_MSG)\n        self.llm = Llama(model_path=model_path, verbose=verbose, **model_kwargs)\n        self.retriever = retriever\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 다음으로 쿼리 기능에 대해 설명하겠습니다. 주요 프로세스는 아래 그림 3에 표시되어 있습니다:\n\n![Image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_2.png)\n\n이해를 돕기 위해 주요 부분에는 주석이 달려 있습니다.\n\n```python\n    def custom_query(self, query_str: str) -\u003e Response:\n        \"\"\"커스텀 쿼리 실행.\"\"\"\n        # Llama2 모델을 사용하여 응답을 가져옵니다.\n        response = self.llm(prompt=_format_prompt(query_str), **_GENERATE_KWARGS)\n        answer = response[\"choices\"][0][\"text\"]\n        source_nodes = []\n\n        # 검색이 필요한지 여부를 결정합니다.\n        if \"[Retrieval]\" in answer:\n            if self.verbose:\n                print_text(\"검색이 필요합니다\\n\", color=\"blue\")\n            # 그림 1의 단계 1, 필요한대로 검색합니다.\n            documents = self.retriever.retrieve(query_str)\n            if self.verbose:\n                print_text(f\"받은 문서: {len(documents)}\\n\", color=\"blue\")\n            paragraphs = [\n                _format_prompt(query_str, document.node.text) for document in documents\n            ]\n\n            if self.verbose:\n                print_text(\"평가 시작\\n\", color=\"blue\")\n\n            # 그림 1의 단계 2 및 3, 병렬로 생성하고 평가합니다\n            # (코드에서 병렬화를 구현하지는 않음)\n            critic_output = self._run_critic(paragraphs)\n\n            paragraphs_final_score = critic_output.paragraphs_final_score\n            llm_response_per_paragraph = critic_output.llm_response_per_paragraph\n            source_nodes = critic_output.source_nodes\n\n            if self.verbose:\n                print_text(\"평가 종료\\n\", color=\"blue\")\n\n            # 가장 높은 점수를 받은 답변을 선택하고 반환합니다.\n            best_paragraph_id = max(\n                paragraphs_final_score, key=paragraphs_final_score.get\n            )\n            answer = llm_response_per_paragraph[best_paragraph_id]\n            if self.verbose:\n                print_text(f\"최적 답변 선택: {answer}\\n\", color=\"blue\")\n\n        answer = _postprocess_answer(answer)\n        if self.verbose:\n            print_text(f\"최종 답변: {answer}\\n\", color=\"green\")\n        return Response(response=str(answer), source_nodes=source_nodes)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 코드에서 우리는 그림 1의 모든 세 단계가 표현된 것을 확인할 수 있습니다. 그러나 LlamaIndex의 코드는 병렬 처리를 구현하지 않았습니다. 더 자세한 정보는 관심 있는 독자들이 self.\\_run_critic 함수를 살펴볼 수 있습니다. 해당 함수는 다양한 반사 토큰에 해당하는 점수를 처리합니다.\n\n# Llama2-7B 모델 훈련 방법\n\n이전에 여러 번 Llama2-7B 모델을 사용해왔으니, 이제 어떻게 얻을 지 알아봅시다.\n\n## 훈련 목표\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n훈련 과정에서는 평가 모델 C와 생성 모델 M 두 가지 모델이 필요합니다. 평가 모델 C는 모델 M이 필요로 하는 감독 데이터를 생성합니다.\n\n그러나 추론 과정에서는 모델 M만 사용되며 모델 C는 필요하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 비평가 모델 C\n\n비평가 모델은 반사 토큰을 생성하는 데 훈련됩니다. 이 모델을 사용하는 목적은 작업 출력 오프라인에 반사 토큰을 삽입하여 훈련 말뭉치를 업데이트하는 것입니다.\n\n각 세그먼트의 반사 토큰을 수동으로 주석 달기는 비용이 많이 듭니다. Self-RAG는 GPT-4를 활용하여 각 반사 토큰에 대해 고유한 지침을 할당하여 서로 다른 정의, 입력 및 출력을 가지고 있기 때문에 효율적으로 데이터 주석 작업을 완료합니다. 예를 들어, [검색] 토큰의 지시는 GPT-4가 외부 문서를 통합하는 것이 결과를 향상시킬지를 평가하도록 요청합니다.\n\n훈련 데이터 D_critic를 얻으면 표준 조건부 언어 모델을 기반으로 훈련 목표를 구성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_3.png)\n\n비평가 모델 C는 어떤 언어 모델로도 초기화할 수 있습니다. 예를 들어 생성자와 동일한 모델로 초기화할 수 있습니다. 예를 들면 Llama2-7B와 같은 모델을 사용할 수 있습니다.\n\n## 생성자 모델 M\n\nFigure 4는 훈련 데이터를 수집하는 구체적인 과정을 보여줍니다. 입력-출력 쌍 (x, y)가 주어지면 self-RAG는 검색 및 비평가 모델을 사용하여 원래의 출력 y를 확장하고 지도 데이터를 생성합니다. y의 각 세그먼트 yt에 대해:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_4.png\" /\u003e\n\nFigure 4의 모든 조건 판단은 비평가 모델 C를 통해 실행됩니다. 획득한 훈련 데이터는 Figure 5에 나타나 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_5.png\" /\u003e\n\n훈련 데이터 D_gen을 획득한 후, 다음 토큰 예측 표준 목적 함수를 다음과 같이 구성할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_6.png)\n\nM 생성기는 결과뿐만 아니라 반영 토큰도 예측해야 합니다.\n\n# self-RAG에 대한 나의 인사이트와 생각\n\n일반적으로 self-RAG는 RAG 프로세스를 강화하는 새로운 관점을 제공합니다. 그러나 더 복잡한 훈련 과정이 필요하며 생성 단계 중에 여러 레이블 생성과 판단이 필요하기 때문에 추론 비용이 증가하기 때문에 실시간 성능이 필요한 프로젝트에는 중요한 영향을 줄 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, 이 프레임워크 내에서 최적화할 여지가 많이 있습니다. 더 많은 토론과 혁신을 일으키기 위해 몇 가지 포인트를 공유하겠습니다:\n\n- 반영 토큰을 최적화하는 방법. Self-RAG는 네 가지 반영 토큰을 설계했습니다. [검색] 토큰 외에도 세 가지([IsREL], [IsSUP], [IsUSE])는 특정 유사성이 있습니다. 더 적은 반영 토큰을 사용하거나 다른 의미를 나타내는 반영 토큰을 고려하는 것이 타당한 방향일 수 있습니다.\n- 비평가 모델이 LLM을 사용하는 이유는 무엇인가요? 제 생각에는 [IsUSE]와 같은 토큰이 공통 지식에 많이 의존하기 때문일 수 있습니다. 질의에 대한 답변의 유용성을 판단하는 것은 더 작은 모델이 수행할 수도 있습니다. 그러나 이러한 모델은 일반적인 지식을 부족하게 습득하며 종래의 특정 교육 자료만을 학습합니다. 따라서 비평가 모델로 LLM을 사용하는 것이 합리적일 수 있습니다.\n- 비평가 모델 크기 선택. Self-RAG는 7B 및 13B 모델로 테스트되어 우수한 결과를 얻었습니다. 그러나 만약 더 작은 LLM인 3B로 전환하면 어떤 차이를 관찰할 수 있을까요? 마찬가지로, 더 큰 LLM인 33B로 전환했을 때 얼마나 개선을 기대할 수 있을까요?\n- 인간 피드백을 통한 강화학습(RLHF)을 사용하지 않는 이유는 무엇인가요? 논문에서는 작업 예제를 통해 대상 언어 모델을 학습하는 것을 제안합니다. 이 예제는 비평가 모델에서 오프라인으로 반영 토큰이 추가된 것입니다. 이로 인해 RLHF 대비 훨씬 낮은 교육 비용이 발생합니다. 또한, self-RAG의 반영 토큰은 추론 중 생성을 제어할 수 있게 만들어주며 RLHF는 훈련 중 인간의 선호도 조정에 초점을 두고 있습니다. 그러나 논문에는 RLHF와 관련된 비교 실험 내용이 포함되어 있지 않습니다.\n\n# 결론\n\n본문은 직관적인 예시로 시작하여 Self-RAG의 기본적인 과정을 소개하고 코드 설명을 보완하는 내용을 담고 있습니다. 또한 제 생각과 통찰을 공유하였습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRAG 기술에 관심이 있다면, 내 다른 기사들도 살펴보세요.\n\n또한, 최신 AI 관련 콘텐츠는 내 뉴스레터에서 찾을 수 있어요.\n\n마지막으로, 어떠한 오류나 누락이 있거나 궁금한 사항이 있으시면 댓글 섹션에서 자유롭게 토론해 주세요.\n","ogImage":{"url":"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png"},"coverImage":"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png","tag":["Tech"],"readingTime":17},{"title":"OpenAI API를 통해 GPT-4o에 접속하기","description":"","date":"2024-05-20 21:08","slug":"2024-05-20-AccessingGPT-4oviaOpenAIAPI","content":"\n![image](/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png)\n\n# 소개\n\nOpenAI가 최근에 발표한 GPT-4o는 텍스트, 이미지, 비디오 및 오디오 분석에 강력한 능력을 갖춘 첫 번째 멀티 모달 모델입니다. 이는 생성적 AI 모델의 응용 프로그램을 크게 확장시켰습니다. 이 블로그에서는 현재 텍스트 및 이미지 입력을 지원하는 API를 통해 이 모델을 사용하는 방법을 보여 드리려고 합니다. 모든 기능이 아직 제공되지 않았지만, OpenAI가 곧 출시할 예정입니다.\n\n# 특징\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 일반 텍스트 생성\n- JSON 모드의 텍스트 생성\n- 이미지 이해\n- 함수 호출\n\n초기 설정\n\nOpenAI 시크릿 키로 라이브러리를 설치하고 가져온 후, 환경 변수를 설정해주세요.\n\n```js\npip install --upgrade openai --quiet\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 단계는 OpenAI 클라이언트를 설정하는 것입니다. 이를 위해 먼저 시크릿 키로 환경 변수를 만들어야 합니다. OPENAI_KEY=xyz와 같이 OpenAI 시크릿 키가 저장된 .env 파일을 만들어주세요.\n\n작업이 완료되면 dotenv를 사용하여 키에 액세스할 수 있습니다.\n\n```python\nimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n## API 키 및 모델 이름 설정\nMODEL=\"gpt-4o\"\n\napi_key = os.getenv('OPENAI_KEY')\nclient = OpenAI(api_key=api_key)\n```\n\n일반 텍스트 생성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncompletion = client.chat.completions.create(\n  model=MODEL,\n  messages=[\n    {\"role\": \"system\", \"content\": \"당신은 도움이 되는 조수입니다. 수학 숙제를 돕습니다!\"}, # \u003c-- 모델에 맥락을 제공하는 시스템 메시지입니다\n    {\"role\": \"user\", \"content\": \"안녕하세요! 2+2를 해결할 수 있나요?\"}  # \u003c-- 모델이 응답을 생성할 사용자 메시지입니다\n  ]\n)\n\nprint(\"조수: \" + completion.choices[0].message.content)\n```\n\n출력:\n\n물론이죠! 2 + 2 = 4. 다른 도움이 필요하시면 언제든지 물어보세요!\n\nJson 모드에서 텍스트 생성하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncompletion = client.chat.completions.create(\n  (model = MODEL),\n  (response_format = { type: \"json_object\" }),\n  (messages = [\n    {\n      role: \"system\",\n      content: \"You are a trainer who always responds in JSON\",\n    },\n    { role: \"user\", content: \"Create a weekly workout routine for me\" },\n  ])\n);\n\njson.loads(completion.choices[0].message.content);\n```\n\n출력:\n\n```bash\n'‘workoutRoutine’: '‘week’: 1, ‘days’: '‘Monday’: '‘muscleGroup’: ‘Chest and Triceps’, ‘exercises’: ['‘name’: ‘Bench Press’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Incline Dumbbell Press’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Tricep Dips’, ‘sets’: 3, ‘reps’: 15', '‘name’: ‘Tricep Pushdown’, ‘sets’: 3, ‘reps’: 15']', ‘Tuesday’: '‘muscleGroup’: ‘Back and Biceps’, ‘exercises’: ['‘name’: ‘Pull-Ups’, ‘sets’: 4, ‘reps’: 10', '‘name’: ‘Deadlifts’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Barbell Rows’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Bicep Curls’, ‘sets’: 3, ‘reps’: 15']',\n```\n\n- 이미지 이해\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로컬 이미지 사용하기\n\n```js\nfrom IPython.display import Image, display, Audio, Markdown\nimport base64\n\nIMAGE_PATH = \"triangle.png\"\n\n# 컨텍스트를 위한 이미지 미리보기\ndisplay(Image(IMAGE_PATH))\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_1.png\" /\u003e\n\n```js\n# 이미지 파일 열고 base64 문자열로 인코딩하기\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n\nbase64_image = encode_image(IMAGE_PATH)\n\nresponse = client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"system\", \"content\": \"당신은 Markdown으로 응답하는 유용한 도우미입니다. 내 수학 숙제를 도와주세요!\"},\n        {\"role\": \"user\", \"content\": [\n            {\"type\": \"text\", \"text\": \"삼각형의 면적은 얼마인가요?\"},\n            {\"type\": \"image_url\", \"image_url\": {\n                \"url\": f\"data:image/png;base64,{base64_image}\"}\n            }\n        ]}\n    ],\n    temperature=0.0,\n)\n\nprint(response.choices[0].message.content)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```bash\n삼각형의 면적을 찾기 위해 직갛각 삼각형의 면적을 구하는 공식을 사용할 수 있습니다: \\[ \\text{면적} = \\frac{1}{2} \\times \\text{밑변} \\times \\text{높이} \\] 이 삼각형에서 밑변은 20 cm이고 높이는 15 cm입니다. \\[ \\text{면적} = \\frac{1}{2} \\times 20 \\, \\text{cm} \\times 15 \\, \\text{cm} \\] \\[ \\text{면적} = \\frac{1}{2} \\times 300 \\, \\text{cm}² \\] \\[ \\text{면적} = 150 \\, \\text{cm}² \\] 따라서, 삼각형의 면적은 \\( 150 \\, \\text{cm}² \\)입니다.\n```\n\nURL을 사용하는 예시\n\n```js\nresponse = client.chat.completions.create(\n  (model = MODEL),\n  (messages = [\n    { role: \"system\", content: \"마크다운으로 응답하는 유용한 도우미입니다.\" },\n    {\n      role: \"user\",\n      content: [\n        {\n          type: \"text\",\n          text: \"이 이미지에서 무엇을 보고 무슨 감정이 표현되었는지 설명해주세요.\",\n        },\n        {\n          type: \"image_url\",\n          image_url: {\n            url: \"https://pbs.twimg.com/media/GNeb4-Ua8AAuaKp?format=png\u0026name=small\",\n          },\n        },\n      ],\n    },\n  ]),\n  (temperature = 0.0)\n);\n\nprint(response.choices[0].message.content);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이미지:\n\n![이미지](/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_2.png)\n\n결과:\n\n이 이미지는 웃는 사람을 보여줍니다. 전달되는 감정은 행복이나 만족으로 보입니다. 웃음은 긍정적이고 즐거운 기분을 시사합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기능 호출\n\n```js\n# NBA 게임 점수를 가져 오기 위한 Mock 함수\ndef get_nba_game_score(team):\n    print('get_nba_game_score가 호출되었습니다.')\n    \"\"\"주어진 팀에 대한 NBA 게임의 현재 점수를 가져옵니다.\"\"\"\n    if \"lakers\" in team.lower():\n        return json.dumps({\"team\": \"Lakers\", \"score\": \"102\", \"opponent\": \"Warriors\", \"opponent_score\": \"98\"})\n    elif \"bulls\" in team.lower():\n        return json.dumps({\"team\": \"Bulls\", \"score\": \"89\", \"opponent\": \"Celtics\", \"opponent_score\": \"95\"})\n    else:\n        return json.dumps({\"team\": team, \"score\": \"N/A\", \"opponent\": \"N/A\", \"opponent_score\": \"N/A\"})\n```\n\n필요한 경우 도구를 통해 함수 호출:\n\n```js\ndef function_calling():\n    # 단계 1: 사용자 메시지로 대화를 초기화합니다\n    messages = [{\"role\": \"user\", \"content\": \"레이커스 게임 점수가 어떻게 되나요?\"}]\n\n    # 모델이 사용할 수있는 도구(함수) 정의\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"get_nba_game_score\",\n                \"description\": \"주어진 팀의 NBA 게임의 현재 점수를 가져옵니다.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"team\": {\n                            \"type\": \"string\",\n                            \"description\": \"NBA 팀의 이름, 예: 레이커스, 불스\",\n                        },\n                    },\n                    \"required\": [\"team\"],\n                },\n            },\n        }\n    ]\n\n    # 단계 2: 대화 컨텍스트와 사용 가능한 도구를 모델에게 전송합니다\n    response = client.chat.completions.create(\n        model=MODEL,\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",  # auto가 기본값입니다. 명시적으로 지정해줍니다.\n    )\n\n    # 모델의 응답을 추출합니다.\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls  # 모델이 도구를 호출하도록 요청하는지 확인합니다\n\n    # 단계 3: 모델이 요청한 도구 호출이 있는지 확인합니다\n    if tool_calls:\n        # 사용 가능한 함수 정의\n        available_functions = {\n            \"get_nba_game_score\": get_nba_game_score,\n        }  # 이 예제에서는 함수가 한 개뿐이지만 확장할 수 있습니다\n\n        # 모델의 응답을 대화 기록에 추가합니다\n        messages.append(response_message)\n\n        # 단계 4: 모델에서 요청된 함수를 호출합니다\n        for tool_call in tool_calls:\n            function_name = tool_call.function.name\n            function_to_call = available_functions[function_name]\n            function_args = json.loads(tool_call.function.arguments)\n\n            print(f\"도구 호출: {tool_call}\")\n\n            # 추출 된 인수로 함수를 호출합니다\n            function_response = function_to_call(\n                team=function_args.get(\"team\"),\n            )\n\n            # 함수 응답을 대화 기록에 추가합니다\n            messages.append(\n                {\n                    \"tool_call_id\": tool_call.id,\n                    \"role\": \"tool\",\n                    \"name\": function_name,\n                    \"content\": function_response,\n                }\n            )\n\n        # 단계 5: 업데이트된 기록을 사용하여 대화를 계속합니다\n        second_response = client.chat.completions.create(\n            model=MODEL,\n            messages=messages,\n        )  # 함수 응답을 확인할 수 있는 모델의 새로운 응답을 받습니다\n\n        return second_response\n\n# 대화를 실행하고 결과를 인쇄합니다\nresponse = function_calling()\nprint(response.choices[0].message.content)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n출력:\n\n도구 호출: ChatCompletionMessageToolCall(id='call_k2lcfdlVAcQ8PTUL1uwu3fYz', function=Function(arguments=' \"team\": \"Lakers\" ', name='get_nba_game_score'), type='function') get_nba_game_score 호출됨\n\n현재 레이커스 경기 점수는 레이커스 102, 워리어스 98 입니다.\n\n마무리\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 전체 기사를 읽으셔서 GPT-4o 모델을 활용해 텍스트 생성, JSON 모드, 이미지 이해, 그리고 함수 호출을 OpenAI API를 통해 사용할 준비가 되셨습니다. API에 오디오 및 비디오 지원이 추가되면 다시 블로그를 쓸 계획입니다. 그 때까지 계속 탐험하고 배우세요!\n","ogImage":{"url":"/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png"},"coverImage":"/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png","tag":["Tech"],"readingTime":11},{"title":"BERT 코드와 함께하는 완벽 가이드","description":"","date":"2024-05-20 20:59","slug":"2024-05-20-ACompleteGuidetoBERTwithCode","content":"\n## 역사, 아키텍처, 사전 훈련 및 미세 조정\n\n\"LLMs from Scratch\" 시리즈의 제4부 - 대형 언어 모델을 이해하고 구축하는 완벽한 가이드입니다. 이러한 모델이 어떻게 작동하는지 알아보고 싶다면 아래 내용을 읽어보시기를 권장합니다:\n\n- Prologue: LLMs와 Transformers의 간단한 역사\n- 제1부: 토큰화 - 전체 가이드\n- 제2부: Python에서 처음부터 word2vec으로 단어 임베딩\n- 제3부: Self-Attention으로 Transformer 임베딩 생성\n- 제4부: 코드와 함께 BERT의 완전 가이드 - 역사, 아키텍처, 사전 훈련 및 미세 조정\n\n# 소개\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n버트(Bidirectional Encoder Representations from Transformers)는 구글 AI Language에서 개발한 대규모 언어 모델(Large Language Model, LLM)로, 자연어 처리(Natural Language Processing, NLP) 분야에서 중요한 발전을 이루고 있습니다. 최근 몇 년간 많은 모델이 버트에 영감을 받아 발전하거나 직접적인 개선을 하였는데, RoBERTa, ALBERT, DistilBERT 등이 대표적입니다. 최초의 버트 모델은 OpenAI의 Generative Pre-trained Transformer (GPT) 이후 빠르게 공개되었으며, 둘 다 그 전년에 제안된 Transformer 아키텍처에 기반을 두었습니다. GPT는 자연어 생성(Natural Language Generation, NLG)에 초점을 맞추었지만, 버트는 자연어 이해(Natural Language Understanding, NLU)에 우선순위를 두었습니다. 이 두 개발은 NLP의 지형을 재편하며 기계 학습의 진전에 주목할 만한 이정표로 자리 잡았습니다.\n\n다음 글은 버트의 역사를 살펴보고, 창조 당시의 환경을 자세히 소개할 것입니다. 이를 통해 논문 저자들이 한 아키텍처적 결정 뿐만 아니라 산업 및 취미용 응용 프로그램에서 버트를 훈련하고 세밀 조정하는 방법을 이해할 수 있는 완전한 그림을 제공할 것입니다. 우리는 다이어그램으로 아키텍처를 자세히 살펴보고, 감정 분석 작업을 위해 버트를 세밀 조정하는 코드를 처음부터 작성해볼 것입니다.\n\n# 목차\n\n1 — 버트의 역사 및 주요 기능\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2 - 아키텍처 및 사전 훈련 목표\n\n3 - 감정 분석을 위한 BERT 파인 튜닝\n\n4 - 결론\n\n5 - 더 많은 독해\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1 — BERT의 역사 및 주요 기능\n\nBERT 모델은 다음 네 가지 주요 기능에 의해 정의될 수 있습니다:\n\n- 인코더 전용 구조\n- 사전 훈련 접근 방식\n- 모델 미세 조정\n- 양방향 문맥 활용\n\n이러한 기능 각각은 논문의 저자들이 만든 설계 선택사항이며, 이 모델이 생성된 시기를 고려하여 이해할 수 있습니다. 다음 섹션에서는 이러한 기능 각각을 살펴보고, 이러한 기능이 BERT의 동시대인 Transformer와 GPT에서 영감을 받았거나 그들을 개선하기 위한 것임을 보여줄 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 1.1 — 인코더 전용 아키텍처\n\n2017년 트랜스포머의 등장으로 혁신적인 디자인을 바탕으로 한 새로운 모델을 생산하기 위한 레이스가 시작되었습니다. OpenAI는 2018년 6월 첫 번째로 GPT를 만들어내 역량 있는 NLG를 자랑하며 나중에는 ChatGPT를 구동하는 모델을 발표했습니다. 구글은 이에 4개월 후인 BERT를 공개하여 NLU를 위해 설계된 인코더 전용 모델을 선보였습니다. 이 두 아키텍처 모두 매우 뛰어난 모델을 생산할 수 있지만 수행할 수 있는 작업들은 약간 다를 수 있습니다. 각 아키텍처에 대한 개요는 아래에서 제공됩니다.\n\n디코더 전용 모델:\n\n- 목표: 입력 시퀀스에 대한 새로운 출력 시퀀스 예측\n- 개요: 트랜스포머의 디코더 블록은 인코더에 제공된 입력을 바탕으로 출력 시퀀스를 생성하는 역할을 합니다. 디코더 전용 모델은 인코더 블록을 완전히 생략하고 여러 디코더를 단일 모델에 쌓아 올려 생성됩니다. 이러한 모델은 입력으로 프롬프트를 받아들이고, 다음 가장 확률이 높은 단어를 하나씩 예측함으로써 응답을 생성하는 작업으로 알려진 Next Token Prediction (NTP)이라는 작업을 수행합니다. 그 결과, 디코더 전용 모델은 대화형 챗봇, 기계 번역 및 코드 생성과 같은 NLG 작업에서 뛰어난 성능을 발휘합니다. 이러한 종류의 모델은 ChatGPT에서 구동되는 디코더 전용 모델 (GPT-3.5 및 GPT-4)의 광범위한 사용으로 인해 일반 대중에게 가장 익숙할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인코더 전용 모델:\n\n- 목표: 입력 시퀀스 내의 단어에 대한 예측 수행\n- 개요: Transformer의 인코더 블록은 입력 시퀀스를 수용하고 각 단어(또는 좀 더 구체적으로, 각 토큰)에 대한 풍부한 숫자 벡터 표현을 생성하는 역할을 합니다. 인코더 전용 모델은 디코더를 생략하고 여러 Transformer 인코더를 쌓아 하나의 모델을 생성합니다. 이러한 모델은 프롬프트를 수용하지 않고, 예측을 수행할 입력 시퀀스(예: 시퀀스 내의 빠진 단어를 예측)를 받습니다. 인코더 전용 모델은 새로운 단어 생성을 위해 디코더를 사용하지 않기 때문에 GPT와 같이 대화형 챗봇 애플리케이션에 사용되지 않습니다. 대신, 인코더 전용 모델은 대부분 NLU 작업인 Named Entity Recognition (NER) 및 감성 분석에 주로 사용됩니다. 인코더 블록에서 생성된 풍부한 벡터 표현은 BERT가 입력 텍스트를 심층적으로 이해하는 데 기여합니다. BERT 저자들은 이 구조적 선택이 BERT의 성능을 향상시킬 것이라고 주장했으며, 특히 디코더 전용 구조는 GPT와 비교하여 BERT의 성능을 향상시킬 것이라고 기술했습니다.\n\nTransformer, GPT 및 BERT를 위한 아키텍처 다이어그램:\n\n지금까지 논의한 세 모델에 대한 아키텍처 다이어그램이 아래에 나와 있습니다. 이는 원본 Transformer 논문 \"Attention is All You Need\" [2]의 아키텍처 다이어그램을 적응하여 작성되었습니다. 모델의 인코더 또는 디코더 블록 수는 N으로 표시됩니다. 원래 Transformer에서 인코더와 디코더 각각은 쌓인 6개의 인코더 및 디코더 블록으로 이루어져 있기 때문에, N은 각각 6입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png)\n\n## 1.2 — Pre-training Approach\n\nGPT은 BERT의 개발에 여러 가지 방식으로 영향을 미쳤습니다. 모델이 첫 번째 디코더 전용 변형 모델이었을 뿐만 아니라 GPT는 또한 모델 사전 훈련을 인기 있게 만들었습니다. 사전 훈련은 언어의 넓은 이해를 얻기 위해 단일 대형 모델을 훈련하는 것을 포함하며 이는 단어 사용 및 문법적 패턴과 같은 측면을 아우릅니다. 그 결과, 작업에 중립적인 기본 모델을 생성합니다. 위 다이어그램에서, 기본 모델은 선형 레이어 아래의 구성 요소들로 이루어져 있습니다 (보라색으로 표시됨). 훈련된 후, 이 기본 모델의 복사본은 특정 작업을 해결하기 위해 미세 조정될 수 있습니다. 미세 조정은 선형 레이어만 훈련하는 것을 의미합니다: 작은 피드포워드 신경망으로 종종 분류 헤드 또는 헤드라고 불립니다. 모델의 나머지 부분(즉, 기초 부분)에 있는 가중치와 바이어스는 변경되지 않거나 고정됩니다.\n\n아날로지:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n간략한 비유를 만들어보겠습니다. 감성 분석 작업을 생각해보세요. 여기서 목표는 표현된 감정에 기반하여 텍스트를 긍정 또는 부정으로 분류하는 것입니다. 예를 들어, 어떤 영화 리뷰에서 \"이 영화를 사랑했다\"라는 텍스트는 긍정으로 분류되고, \"이 영화를 싫어했다\"라는 텍스트는 부정으로 분류될 것입니다. 전통적인 언어 모델링 접근 방식에서는 이 작업에 특화된 새로운 아키텍처를 일반적으로 처음부터 학습할 것입니다. 이것은 영화 리뷰를 보여주는 것으로 영어를 처음부터 가르치는 것과 같다고 생각할 수 있습니다. 물론, 이것은 느리고 비용이 많이 들며 많은 학습 예제가 필요합니다. 게다가, 그 결과로 얻는 분류기는 여전히 이 한 가지 작업에만 능숙할 것입니다. 대조적으로, 사전 훈련 접근 방식에서는 범용 모델을 가져와서 이를 감성 분석 작업에 대해 미세 조정합니다. 이것은 이미 영어에 능숙한 사람에게 현재 작업에 익숙해지도록 모자란 수의 영화 리뷰를 보여주는 것으로 생각할 수 있습니다. 아마도 두 번째 접근 방식이 훨씬 더 효율적하다는 것이 직관적일 것입니다.\n\n**사전 훈련에 대한 이전 시도:**\n\n사전 훈련 개념은 OpenAI에 의해 발명된 것이 아니며, 그 이전 몇 년 동안 다른 연구자들에의해 탐구되어왔습니다. 한 가지 주목할만한 예는 Allen Institute의 연구자들이 개발한 ELMo 모델(Embeddings from Language Models)입니다. 이전 시도에도 불구하고, OpenAI의 큰 논문에서처럼 다른 연구자들은 사전 훈련의 효과를 명백하게 입증하지 못했습니다. 그들 자신의 말에 따르면, 팀은 이 발견으로 사전 훈련 패러다임을 앞으로의 언어 모델링에서 우세한 접근 방식으로 확립시켰습니다. 이 추세와 일치하도록, BERT 저자들도 사전 훈련 접근 방식을 완전히 채택했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 1.3 — 모델 파인튜닝\n\n파인튜닝의 장점:\n\n파인튜닝은 오늘날 흔한 일로, 이러한 접근 방식이 주목받기 전 얼마나 최신인지 쉽게 간과하기 쉽습니다. 2018년 이전까지는 각기 다른 NLP 작업을 위해 새로운 모델 아키텍처를 도입하는 것이 일반적했습니다. 훈련을 사전에 시작함으로써 신규 모델 개발에 필요한 훈련 시간과 컴퓨팅 비용이 급격히 감소했을 뿐만 아니라 필요한 훈련 데이터의 양도 줄어들었습니다. 언어 모델을 처음부터 완전히 재설계하고 재훈련하는 대신 제네릭 모델인 GPT를 소량의 작업별 데이터로 파인튜닝함으로써 해당 시간을 분수로 줄일 수 있습니다.\n\n작업에 따라서 분류 헤드를 수정하여 다른 수의 출력 뉴런을 포함시킬 수 있습니다. 이는 감정 분석과 같은 분류 작업에 유용합니다. 예를 들어 BERT 모델의 원하는 출력이 리뷰가 긍정인지 부정인지 예측하는 것이라면, 헤드를 두 개의 출력 뉴런이 있는 형태로 변경할 수 있습니다. 각각의 활성화는 리뷰가 긍정인지 부정인지일 확률을 나타냅니다. 10 클래스로 구성된 다중 분류 작업의 경우, 헤드를 10개의 뉴런을 가진 출력 레이어로 변경할 수 있습니다. 이렇게 함으로써 BERT를 더 다양하게 활용할 수 있어 여러 하류 작업에 기본 모델이 사용될 수 있습니다.\n\nBERT의 파인튜닝:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBERT은 GPT의 발자취를 따르며 사전 훈련/미세 조정 접근 방식을 채택했습니다. 구글은 BERT의 두 가지 버전을 출시했는데, Base와 Large로 하드웨어 제약에 따라 모델 크기를 유저에게 유연하게 제공했습니다. 양쪽 모델 모두 많은 TPUs(텐서 처리 장치)에서 약 4일이 걸렸다고 하는데, BERT Base는 16개의 TPUs에서 훈련되었고 BERT Large는 64개의 TPUs에서 훈련되었습니다. 대부분의 연구자, 취미로 연구하는 사람들 및 산업 실무자들에게는 이 수준의 훈련이 현실적이지 않을 수 있습니다. 그래서 어떤 특정 작업에 기초 모델을 몇 시간 동안 미세 조정하는 아이디어는 훨씬 더 매력적인 대안입니다. 원래 BERT 아키텍처는 다양한 작업과 데이터셋에 걸쳐 수천 번의 미세 조정 이터레이션을 거쳤는데, 이 중 많은 것들이 Hugging Face와 같은 플랫폼에서 공개적으로 다운로드할 수 있습니다.\n\n## 1.4 — 양방향 컨텍스트 사용\n\n언어 모델로, BERT는 이전 단어가 관찰되었을 때 특정 단어가 관측될 확률을 예측합니다. 이 기본적인 측면은 아키텍처와 의도된 작업에 관계없이 모든 언어 모델이 공유하는 것입니다. 그러나 모델이 이러한 확률을 활용하는 것이 모델의 특정 작업에 적합한 행동을 부여합니다. 예를 들어 GPT는 시퀀스에서 다음으로 가장 가능성이 높은 단어를 예측하도록 훈련됩니다. 즉, 모델은 이전 단어가 관찰되었을 때 다음 단어를 예측합니다. 다른 모델들은 감정 분석에 훈련될 수 있고, 긍정적 또는 부정적과 같은 텍스트 라벨을 사용하여 입력 시퀀스의 감정을 예측할 수 있습니다. 텍스트에 대한 어떠한 의미 있는 예측을 하려면 주변 컨텍스트가 이해되어야 합니다. 특히 NLU 작업에서는 BERT가 이러한 이해를 보장하여 양방향성이라는 핵심 특성 중 하나를 통해 우수한 이해를 제공합니다.\n\n양방향성은 아마도 BERT의 가장 중요한 특징인데, NLU 작업에서 BERT의 높은 성능의 중요한 이유이며, 또한 모델의 인코더 전용 아키텍처의 주요 동기입니다. Transformer 인코더의 self-attention 메커니즘은 양방향 컨텍스트를 계산하지만, 이와 같은 것을 할 수 없는 디코더는 단방향 컨텍스트를 생산합니다. BERT 저자들은 GPT의 이 양방향성 부족으로 인해 BERT만큼의 언어 표현 깊이를 달성하지 못한다고 주장했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n양방향성 정의하기:\n\n그렇다면 \"양방향성\"이라는 맥락이 정확히 무엇을 의미할까요? 여기서 양방향성은 입력 시퀀스의 각 단어가 앞뒤 단어(좌측 맥락과 우측 맥락이라고 함)로부터 맥락을 확보할 수 있다는 것을 의미합니다. 기술적인 용어로는 어텐션 메커니즘이 각 단어에 대해 이전 및 이후의 토큰에 주의를 기울일 수 있다고 말합니다. 이를 분해해보면 BERT는 입력 시퀀스 내 단어에 대해서만 예측을 하고 GPT처럼 새로운 시퀀스를 생성하지는 않습니다. 따라서 BERT가 입력 시퀀스 내의 단어를 예측할 때, 모든 주변 단어에서 문맥적 단서를 접목할 수 있습니다. 이는 양방향으로 문맥을 제공하므로 BERT가 보다 정보를 기반으로 한 예측을 할 수 있도록 도와줍니다.\n\n이를 GPT와 같은 디코더 전용 모델과 대조해보면, 여기서 목표는 출력 시퀀스를 생성하기 위해 한 번에 새로운 단어를 예측하는 것입니다. 각 예측된 단어는 이전 단어가 제공한 맥락(좌측 맥락)만 활용할 수 있으며, 그 이후의 단어(우측 맥락)는 아직 생성되지 않았습니다. 그러므로 이러한 모델을 단방향으로 지칭합니다.\n\n![이미지](\"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_1.png\")\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이미지 설명:\n\n위의 이미지는 양방향 컨텍스트를 사용하는 전형적인 BERT 작업과 단방향 컨텍스트를 사용하는 전형적인 GPT 작업의 예시를 보여줍니다. BERT에서는 이 [MASK]로 표시된 가리킨 가림막된 단어를 예측하는 것이 작업입니다. 이 단어는 왼쪽과 오른쪽에 단어가 있기 때문에 양쪽의 단어를 사용하여 컨텍스트를 제공할 수 있습니다. 만약 당신이 인간으로써 이 문장을 왼쪽 또는 오른쪽 컨텍스트만 가지고 읽는다면, 가리킨 가림막된 단어를 본인이 예측하기 어려울 것입니다. 그러나 양방향 컨텍스트를 사용하면 가림막된 단어가 'fishing'이라는 것을 추측하는 것이 훨씬 더 가능해집니다.\n\nGPT의 경우, 목표는 전통적인 NTP 작업을 수행하는 것입니다. 이 경우, 목적은 입력 시퀀스 및 이미 생성된 단어를 기반으로 새로운 시퀀스를 생성하는 것입니다. 입력 시퀀스가 모델에게 시를 쓰라는 지시를 준 상황에서 이미 생성된 단어가 \"Upon a\" 인 것을 고려한다면, 다음 단어는 \"river\"가 될 것으로 예상해볼 수 있습니다. 여러 후보 단어가 있을 때 GPT(언어 모델로서)는 어휘 중 각 단어가 다음에 나타날 가능성을 계산하고 훈련 데이터를 기반으로 가장 가능성이 높은 단어 중 하나를 선택합니다.\n\n## 1.5 — BERT의 한계\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n양방향 모델로서 BERT는 두 가지 주요 단점을 가지고 있습니다:\n\n1. 훈련 시간이 증가합니다:\n\n트랜스포머 기반 모델의 양방향성은 당시 주류였던 좌측에서 우측으로의 문맥 모델에 대한 직접적인 개선으로 제안되었습니다. GPT는 입력 시퀀스에 대한 문맥 정보를 일방적으로만 얻을 수 있기 때문에 단어 사이의 인과 관계에 대해 완전히 파악하지 못했습니다. 그러나 양방향 모델은 단어 간의 인과 관계를 보다 포괄적으로 이해할 수 있으므로 NLU 작업에서 보다 나은 결과를 볼 수 있습니다. 과거에 양방향 모델이 탐구되었지만, 늦은 1990년대의 양방향 RNN과 같은 한계가 있었습니다. 일반적으로 이러한 모델들은 훈련을 위해 더 많은 계산 리소스를 요구하기 때문에 동일한 계산 성능을 달성하기 위해서는 더 큰 단방향 모델을 훈련해야 합니다.\n\n2. 언어 생성 작업에서 성능이 저하됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBERT는 NLU 작업을 해결하기 위해 특별히 설계되었으며, 디코더 및 새로운 시퀀스를 생성하는 능력을 포기하고 인코더 및 입력 시퀀스에 대한 풍부한 이해를 개발하는 것으로 대체했습니다. 결과적으로 BERT는 NER, 감정 분석 등과 같은 NLP 작업 부분에 최적화되어 있습니다. 특히, BERT는 프롬프트를 수용하지 않고 대신 입력 시퀀스를 처리하여 예측을 작성합니다. BERT는 기술적으로 새로운 출력 시퀀스를 생성할 수 있지만, LLM(언어 모델)의 설계적 차이를 인지하고 중대하게 생각해야 합니다. ChatGPT 시대 이후의 LLM들을 생각할 때와 BERT 설계의 현실과의 차이를 인지하는 것이 중요합니다.\n\n## 2 — 아키텍처 및 사전 훈련 목표\n\n### 2.1 — BERT의 사전 훈련 목표 개요\n\n양방향 모델을 훈련시키려면 좌/우 컨텍스트가 모두 예측에 활용되는 작업이 필요합니다. 따라서 저자들은 BERT의 언어 이해를 강화하기 위해 주의 깊게 2가지 사전 훈련 목표를 구성했습니다. 이것들은 Masked Language Model(MLM) 작업과 Next Sentence Prediction(NSP) 작업이었습니다. 각각의 훈련 데이터는 당시 사용 가능한 모든 영어 위키피디아 기사 (25억 단어)와 BookCorpus 데이터셋의 추가 11,038권의 책 (8억 단어)로 구성되었습니다. 초기 데이터는 구체적인 작업에 따라 전처리되어야 했지만, 아래에서 설명한 대로 수행되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2.2 — 마스크된 언어 모델링 (MLM)\n\nMLM 개요:\n\n마스크된 언어 모델링 작업은 양방향 모델을 훈련해야 하는 필요를 직접적으로 해결하기 위해 만들어졌습니다. 이를 위해 모델은 입력 시퀀스의 좌측 문맥과 우측 문맥을 모두 사용하여 예측을 수행하도록 훈련되어야 합니다. 이는 훈련 데이터에서 15%의 단어를 무작위로 마스크하고 BERT를 사용하여 누락된 단어를 예측하도록 훈련함으로써 달성됩니다. 입력 시퀀스에서 마스크된 단어는 [MASK] 토큰으로 대체됩니다. 예를 들어, 책 코퍼스에서 발견된 원시 훈련 데이터 중에 A man was fishing on the river 라는 문장이 있다고 가정해보겠습니다. MLM 작업에 대한 훈련 데이터로 원시 텍스트를 변환할 때, 단어 fishing이 무작위로 마스크되어 [MASK] 토큰으로 대체될 수 있으며, 이는 훈련 입력 A man was [MASK] on the river with target fishing을 제공합니다. 따라서 BERT의 목표는 단일 누락된 단어 fishing을 예측하는 것이며, 누락된 단어가 채워진 입력 시퀀스를 재생산하는 것이 아닙니다. 마스킹 프로세스는 MLM 작업의 훈련 데이터를 작성할 때 모든 가능한 입력 시퀀스(예: 문장)에 반복적으로 적용될 수 있습니다. 이 작업은 이전에 언어학 문헌에서 존재했었으며 Cloze 작업으로 알려져 있습니다.[8] 그러나 기계 학습 맥락에서는 BERT의 인기로 인해 MLM으로 흔히 언급됩니다.\n\n미세 조정과 사전 훈련 간 불일치 완화 방법:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저자들은 그러나 [MASK] 토큰은 훈련 데이터에만 나타나고 라이브 데이터(추론 시간)에는 나타나지 않기 때문에 사전 훈련과 세부 튜닝 간에 불일치가 있을 것이라고 지적했습니다. 이를 완화하기 위해 모든 마스킹된 단어가 [MASK] 토큰으로 대체되는 것은 아닙니다. 저자들은 대신 다음과 같이 설명합니다:\n\n예측 단어와 목표 단어 사이의 오차 계산:\n\nBERT는 BERT Base 및 BERT Large 모두 최대 512개의 토큰을 입력으로 받습니다. 시퀀스에서 최대 토큰 수보다 적은 경우, [PAD] 토큰을 사용하여 패딩이 추가되어 최대 512개에 도달합니다. 출력 토큰 수도 입력 토큰 수와 정확히 일치합니다. 입력 시퀀스의 i 위치에 마스크 토큰이 있는 경우, BERT의 예측은 출력 시퀀스의 i 위치에 있을 것입니다. 훈련 목적으로 다른 모든 토큰은 무시되므로 모델의 가중치 및 편향에 대한 업데이트는 입력 시퀀스의 i 위치에 있는 예측 토큰과 목표 토큰 간의 오차를 기반으로 계산됩니다. 이 오차는 Cross Entropy Loss(음의 로그 우도) 함수를 사용하여 계산됩니다. 이러한 내용은 나중에 보게 될 것입니다.\n\n## 2.3 — 다음 문장 예측 (NSP)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n개요:\n\nBERT의 사전 학습 작업 중 두 번째는 Next Sentence Prediction입니다. 이 작업은 하나의 세그먼트(일반적으로 문장)가 다른 세그먼트를 논리적으로 잇는지 분류하는 것을 목표로 합니다. NSP를 사전 학습 작업으로 선택한 이유는 MLM을 보완하고 BERT의 NLU 능력을 향상시키기 위한 것이며, 저자들은 다음과 같이 설명합니다:\n\nNSP에 대해 사전 학습함으로써, BERT는 채의 흐름에 대한 이해를 발전시킬 수 있으며, 이는 많은 NLU 문제에 유용합니다. 예를 들어 다음과 같은 것들이 있습니다:\n\n- 내용을 바꿔 말한 문장 쌍\n- 추론을 위한 가설-전제 쌍\n- 질문 응답에서 질문-통과 문장 쌍\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBERT에서의 NSP 구현:\n\nNSP의 입력은 첫 번째와 두 번째 세그먼트(표시된 A 및 B)로 구성되며 두 번째 [SEP] 토큰이 있는 [SEP] 토큰으로 구분되고 끝에 두 번째 [SEP] 토큰이 있습니다. BERT는 실제로 NSP를 수행하든 아니든 입력 시퀀스 당 최소한 하나의 [SEP] 토큰을 예상합니다. 이 토큰은 시퀀스의 끝을 나타내며, MLM 작업에 대한 입력의 끝에 이러한 토큰 중 하나가 추가됩니다. 또한, NSP가 포함되지 않은 다른 모든 작업들에 대해서도 동일한 처리가 이루어집니다. NSP는 분류 문제를 형성하며, 출력은 A 세그먼트가 B 세그먼트를 논리적으로 따르는 경우 IsNext에 해당하고, 그렇지 않은 경우 NotNext에 해당합니다. 교육 데이터는 단어 조각(WordPiece) 토크나이저가 50%의 경우에는 다음 문장과 함께 문장을 선택하고, 나머지 50%의 경우에는 무작위 문장을 선택함으로써 어떤 단일 언어 말뭉치에서 쉽게 생성할 수 있습니다.\n\nBERT의 입력 임베딩:\n\nBERT의 입력 임베딩 과정은 위치 인코딩, 세그먼트 임베딩 및 토큰 임베딩 세 단계로 구성됩니다(아래 다이어그램 참조).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위치 인코딩:\n\nTransformer 모델과 마찬가지로 각 토큰의 임베딩에 위치 정보가 주입됩니다. 그러나 Transformer와 달리 BERT의 위치 인코딩은 고정되어 있고 함수에 의해 생성되지 않습니다. 이는 BERT가 BERT 베이스와 BERT 라지의 입력 시퀀스에서 512개의 토큰으로 제한된다는 것을 의미합니다.\n\n세그먼트 임베딩:\n\n각 토큰이 속한 세그먼트를 인코딩하는 벡터도 추가됩니다. MLM 사전 훈련 작업 또는 다른 NSP 작업(단일 [SEP] 토큰만 있는 경우)의 경우 입력의 모든 토큰은 세그먼트 A에 속하는 것으로 간주됩니다. NSP 작업의 경우, 두 번째 [SEP] 이후의 모든 토큰은 세그먼트 B로 표시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n토큰 임베딩:\n\n원래의 Transformer와 마찬가지로 각 토큰에 대해 학습된 임베딩은 위치 및 세그먼트 벡터에 추가되어 BERT에서 자기 주의 메커니즘에 전달되는 최종 임베딩을 만들어 내며 문맥 정보를 추가합니다.\n\n![이미지](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_2.png)\n\n## 2.5 — 특별 토큰\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 이미지에서 볼 수 있었듯이 입력 시퀀스에는 [CLS] (분류) 토큰이 앞에 추가되었습니다. 이 토큰은 전체 입력 시퀀스의 의미론적 의미를 요약하고, BERT가 분류 작업을 수행하는 데 도움이 됩니다. 예를 들어, 감성 분석 작업에서 최종 층의 [CLS] 토큰은 입력 시퀀스의 감정이 긍정적인지 부정적인지 예측 추출하기 위해 분석될 수 있습니다. [CLS] 및 [PAD] 등은 BERT의 특수 토큰 예시입니다. 여기서 BERT의 특수 토큰은 총 다섯 개 있습니다. 아래에 요약을 제공합니다:\n\n- [PAD] (토큰 ID: 0) — 512개 토큰으로 구성된 입력 시퀀스의 총 수를 맞추기 위해 사용되는 패딩 토큰.\n- [UNK] (토큰 ID: 100) — BERT 어휘에 없는 토큰을 나타내기 위해 사용되는 알 수 없는 토큰.\n- [CLS] (토큰 ID: 101) — 분류 토큰으로 기대되는 것은 각 시퀀스의 시작 부분에 나타냅니다. 이러한 토큰은 분류 작업을 위한 클래스 정보를 캡슐화하며, 종합적인 시퀀스 표현으로 생각할 수 있습니다.\n- [SEP] (토큰 ID: 102) — 단일 입력 시퀀스의 두 세그먼트를 구분하는 데 사용되는 구분자 토큰 (예: Next Sentence Prediction). 적어도 입력 시퀀스 당 하나의 [SEP] 토큰이 필요하며, 최대 두 개까지 사용 가능합니다.\n- [MASK] (토큰 ID: 103) — 마스크 토큰은 BERT를 마스킹된 언어 모델링 작업으로 훈련하거나 마스크된 시퀀스에 대한 추론을 수행하는 데 사용됩니다.\n\n## 2.4 — BERT Base와 BERT Large의 아키텍처 비교\n\nBERT Base와 BERT Large는 아키텍처적으로 매우 유사합니다. 두 모델 모두 WordPiece 토크나이저를 사용하여(따라서 앞에서 설명한 동일한 특수 토큰을 사용) 최대 시퀀스 길이가 512 토큰입니다. BERT의 어휘 크기는 30,522이며, 그 중 약 1,000 개의 토큰은 \"사용되지 않은\" 상태를 유지합니다. 사용되지 않은 토큰은 사용자가 전체 토크나이저를 다시 훈련하지 않고 사용자 지정 토큰을 추가할 수 있도록 고의로 비워둡니다. 의료 및 법률 용어와 같은 도메인별 어휘와 함께 작업할 때 유용합니다. BERT Base와 BERT Large는 원래 Transformer의 embedding 차원 (d_model)보다 높은 수를 갖습니다. 이는 모델의 어휘에 대해 학습된 벡터 표현의 크기에 해당합니다. BERT Base의 d_model은 768이며, BERT Large의 d_model은 1024입니다(원래 Transformer의 512를 두 배 증가시킨 값).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 모델은 주로 네 가지 범주에서 차이가 있습니다:\n\n- 인코더 블록의 수, N: 서로 쌓인 인코더 블록의 수입니다.\n- 인코더 블록 당 어텐션 헤드 수: 어텐션 헤드는 입력 시퀀스의 문맥 벡터 임베딩을 계산합니다. BERT는 멀티헤드 어텐션을 사용하므로, 이 값은 인코더 레이어 당 헤드 수를 나타냅니다.\n- 피드포워드 네트워크의 은닉층 크기: 선형 레이어는 고정된 뉴런 수(예: BERT Base의 경우 3072)를 가진 은닉층으로 구성되며, 다양한 크기의 출력 레이어로 이어집니다. 출력 레이어의 크기는 작업에 따라 다릅니다. 예를 들어, 이진 분류 문제는 단지 두 개의 출력 뉴런이 필요하고, 10개 클래스를 가진 다중 클래스 분류 문제는 10개의 뉴런이 필요합니다.\n- 총 매개변수: 모델 내 가중치와 바이어스의 총 수입니다. 당시 수억 개의 모델이 매우 큰 것으로 여겨졌지만, 오늘날 기준에서는 이 값들이 상대적으로 작습니다.\n\n이러한 범주별 BERT Base와 BERT Large간의 비교는 아래 이미지에서 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 3 — 감정 분석을 위한 BERT Feine-Tuning\n\n이 섹션에서는 파이썬을 사용하여 BERT를 세밀 조정하는 실제 예제를 다룹니다. 코드는 작업에 무관한 세밀 조정 파이프라인 형태로, 파이썬 클래스에 구현되어 있습니다. 그런 다음 이 클래스의 객체를 생성하고 이를 사용하여 감정 분석 작업에 대해 BERT 모델을 세밀 조정할 것입니다. 이 클래스는 질문 응답, 개체 인식 등 다른 작업에 대해 BERT를 세밀 조정하는 데 재사용할 수 있습니다. 섹션 3.1에서 3.5는 세밀 조정 과정을 설명하며, 섹션 3.6에서는 전체 파이프라인을 보여줍니다.\n\n## 3.1 — 세밀 조정 데이터 집합 로드 및 전처리\n\n세밀 조정의 첫 번째 단계는 특정 작업에 적합한 데이터 집합을 선택하는 것입니다. 이 예제에서는 스탠퍼드 대학이 제공하는 감정 분석 데이터 세트를 사용할 것입니다. 이 데이터 세트에는 인터넷 영화 데이터베이스 (IMDb)에서 가져온 5만 개의 온라인 영화 리뷰가 포함되어 있으며, 각 리뷰는 긍정적 또는 부정적으로 레이블이 지정되어 있습니다. 스탠퍼드 대학 웹사이트에서 데이터 세트를 직접 다운로드할 수도 있고, Kaggle에서 노트북을 만들어 작업 결과를 다른 사람들과 비교할 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport pandas as pd\n\ndf = pd.read_csv('IMDB Dataset.csv')\ndf.head()\n```\n\n![image](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_4.png)\n\n이제 이전의 NLP 모델과 달리 BERT와 같은 Transformer 기반 모델은 최소한의 전처리가 필요합니다. 불용어(stop words) 및 구두점을 제거하는 단계는 경우에 따라 오히려 역효과를 낼 수 있습니다. 이러한 요소들은 BERT가 입력 문장을 이해하기 위한 중요한 맥락을 제공하기 때문입니다. 그럼에도 불구하고 텍스트를 검사하여 형식 문제나 원치 않는 문자가 있는지 확인하는 것이 여전히 중요합니다. 전반적으로 IMDb 데이터셋은 꽤 깨끗합니다. 그러나 스크래핑 프로세스에서 남은 몇 가지 흔적, 예를 들면 HTML 태그(`\u003cbr /\u003e`)나 불필요한 공백과 같은 것들을 제거해야 합니다.\n\n```js\n# 줄바꿈 태그(\u003cbr /\u003e) 제거\ndf['review_cleaned'] = df['review'].apply(lambda x: x.replace('\u003cbr /\u003e', ''))\n\n# 불필요한 공백 제거\ndf['review_cleaned'] = df['review_cleaned'].replace('\\s+', ' ', regex=True)\n\n# 첫 번째 리뷰의 72자를 비교하여 클리닝 전/후 출력\nprint('클리닝 전:')\nprint(df.iloc[1]['review'][0:72])\n\nprint('\\n클리닝 후:')\nprint(df.iloc[1]['review_cleaned'][0:72])\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nBefore cleaning:\nA wonderful little production. \u003cbr /\u003e\u003cbr /\u003eThe filming technique is very\n\nAfter cleaning:\nA wonderful little production. The filming technique is very unassuming-\n```\n\n감정 인코딩:\n\n전처리의 마지막 단계는 각 리뷰의 감정을 부정인 경우 0 또는 긍정인 경우 1로 인코딩하는 것입니다. 이러한 레이블은 나중에 미세 조정 프로세스에서 분류 헤드를 훈련하는 데 사용될 것입니다.\n\n```js\ndf['sentiment_encoded'] = df['sentiment'].\\\n    apply(lambda x: 0 if x == 'negative' else 1)\ndf.head()\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_5.png\" /\u003e\n\n## 3.2 — 데이터 파인튜닝에 토큰화 적용하기\n\n전처리된 이후, 데이터를 파인튜닝할 수 있도록 토큰화가 진행됩니다. 이 과정은 리뷰 텍스트를 개별 토큰으로 분리하고, [CLS] 및 [SEP] 특수 토큰을 추가하며, 패딩을 처리합니다. 모델에 적합한 토크나이저를 선택하는 것이 중요합니다. 다양한 언어 모델은 서로 다른 토큰화 단계가 필요하기 때문입니다 (예: GPT는 [CLS] 및 [SEP] 토큰을 요구하지 않습니다). 본 가이드에서는 Hugging Face transformers 라이브러리의 BertTokenizer 클래스를 사용할 것입니다. 이 클래스는 BERT 기반 모델과 함께 사용하도록 설계되었습니다. 토큰화가 작동하는 방식에 대한 더 자세한 설명은 본 시리즈의 Part 1을 참조하세요.\n\ntransformers 라이브러리의 Tokenizer 클래스들은 from_pretrained 메서드를 사용하여 사전 훈련된 토크나이저 모델을 간단히 생성할 수 있는 방법을 제공합니다. 이 기능을 사용하려면: 토크나이저 클래스를 가져와서 인스턴스화하고, from_pretrained 메서드를 호출하고, Hugging Face 모델 저장소에 호스팅된 토크나이저 모델 이름을 나타내는 문자열을 전달하면 됩니다. 또는 토크나이저가 요구하는 어휘 파일이 포함된 디렉토리 경로를 전달할 수도 있습니다. 이 예시에서는 모델 저장소에서 사전 훈련된 토크나이저를 사용할 것입니다. BERT를 다룰 때 주요한 옵션은 네 가지가 있으며, 각각 구글의 사전 훈련 토크나이저 어휘를 사용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- bert-base-uncased — BERT의 작은 버전에 대한 어휘 사전으로 대소문자를 구분하지 않습니다 (예: 토큰 Cat과 cat은 동일하게 처리됩니다)\n- bert-base-cased — BERT의 작은 버전에 대한 어휘 사전으로 대소문자를 구분합니다 (예: 토큰 Cat과 cat은 동일하게 처리되지 않습니다)\n- bert-large-uncased — BERT의 큰 버전에 대한 어휘 사전으로 대소문자를 구분하지 않습니다 (예: 토큰 Cat과 cat은 동일하게 처리됩니다)\n- bert-large-cased — BERT의 큰 버전에 대한 어휘 사전으로 대소문자를 구분합니다 (예: 토큰 Cat과 cat은 동일하게 처리되지 않습니다)\n\nBERT Base와 BERT Large는 동일한 어휘 사전을 사용하므로 bert-base-uncased와 bert-large-uncased 사이에는 차이가 없으며, bert-base-cased와 bert-large-cased 사이에도 차이가 없습니다. 다른 모델의 경우에는 이와 같지 않을 수 있으므로 확실하지 않을 경우 동일한 토크나이저와 모델 크기를 사용하는 것이 가장 좋습니다.\n\n대소문자 사용 여부 선택:\n\n대소문자 사용 여부를 선택하는 것은 데이터셋의 특성에 따라 달라집니다. IMDb 데이터셋은 인터넷 사용자가 작성한 텍스트를 포함하고 있으며 대문자 사용에 일관성이 없는 경우가 있을 수 있습니다. 예를 들어 일부 사용자는 예상대로 대문자를 생략하거나 강조를 위해 대문자를 사용할 수 있습니다. 이러한 이유로 대소문자를 무시하고 bert-base-uncased 토크나이저 모델을 사용하기로 결정했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 상황에서는 케이스를 고려하여 성능상의 이점을 볼 수 있습니다. 여기 예제 중 하나는 Named Entity Recognition 작업에서, 즉 사람, 조직, 위치 등을 텍스트에서 식별하는 것이 목표인 경우입니다. 이 경우 대문자의 존재는 단어가 누군가의 이름인지 아니면 장소인지를 식별하는 데 매우 도움이 될 수 있어서, 이 상황에서는 bert-base-cased를 선택하는 것이 더 적절할 수 있습니다.\n\nMarkdown 형식으로 표를 변경합니다.\n\n```js\nfrom transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nprint(tokenizer)\n```\n\n```js\nBertTokenizer(\n  (name_or_path = \"bert-base-uncased\"),\n  (vocab_size = 30522),\n  (model_max_length = 512),\n  (is_fast = False),\n  (padding_side = \"right\"),\n  (truncation_side = \"right\"),\n  (special_tokens = {\n    unk_token: \"[UNK]\",\n    sep_token: \"[SEP]\",\n    pad_token: \"[PAD]\",\n    cls_token: \"[CLS]\",\n    mask_token: \"[MASK]\",\n  }),\n  (clean_up_tokenization_spaces = True)\n),\n  (added_tokens_decoder = {\n    0: AddedToken(\n      \"[PAD]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    100: AddedToken(\n      \"[UNK]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    101: AddedToken(\n      \"[CLS]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    102: AddedToken(\n      \"[SEP]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    103: AddedToken(\n      \"[MASK]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n  });\n```\n\n인코딩 프로세스: 텍스트를 토큰으로 변환하여 토큰 ID로 변환하기.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로, 토크나이저를 사용하여 정제된 파인 튜닝 데이터를 인코딩할 수 있어요. 이 과정은 각 리뷰를 토큰 ID들의 텐서로 변환할 거예요. 예를 들어, 리뷰인 'I liked this movie'는 다음 단계를 통해 인코딩되어요:\n\n1. 리뷰를 소문자로 변환하기 (우리가 'bert-base-uncased'를 사용하고 있으니)\n\n2. 리뷰를 'bert-base-uncased' 어휘에 따라 개별 토큰으로 분리하기: [`i`, `liked`, `this`, `movie`]\n\n3. BERT가 기대하는 특수 토큰을 추가하기: [`[CLS]`, `i`, `liked`, `this`, `movie`, `[SEP]`]\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 병합된 토큰을 bert-base-uncased 어휘에 따라 해당 토큰 ID로 변환합니다. (예: [CLS] - 101, i - 1045 등)\n\nBertTokenizer 클래스의 encode 메서드는 위 과정을 사용하여 텍스트를 인코딩하고, PyTorch 텐서, Tensorflow 텐서 또는 NumPy 배열로 된 토큰 ID의 텐서를 반환할 수 있습니다. 반환 텐서의 데이터 유형은 return_tensors 인자를 사용하여 지정할 수 있으며, 각각 pt, tf, np 값을 취합니다.\n\n```js\n# 샘플 입력 문장을 인코딩합니다\nsample_sentence = 'I liked this movie'\ntoken_ids = tokenizer.encode(sample_sentence, return_tensors='np')[0]\nprint(f'Token IDs: {token_ids}')\n\n# 특수 토큰이 추가된 토큰 ID를 토큰으로 다시 변환하여 확인합니다\ntokens = tokenizer.convert_ids_to_tokens(token_ids)\nprint(f'Tokens   : {tokens}')\n```\n\n```js\nToken IDs: [ 101 1045 4669 2023 3185  102]\nTokens   : ['[CLS]', 'i', 'liked', 'this', 'movie', '[SEP]']\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTruncation and Padding:\n\nBERT Base 및 BERT Large는 정확히 512토큰의 입력 시퀀스를 처리하기 위해 설계되었습니다. 그러나 입력 시퀀스가 이 제한에 맞지 않는 경우 어떻게 해야 할까요? 그 답은 Truncation과 Padding입니다! Truncation은 특정 길이 이상의 어떠한 토큰도 간단히 제거하여 토큰 수를 줄입니다. encode 메서드에서 truncation을 True로 설정하고 모든 인코딩된 시퀀스에 길이 제한을 부여할 max_length 인수를 지정할 수 있습니다. 이 데이터 세트의 여러 항목은 512토큰 제한을 초과하므로 여기서 max_length 매개변수가 모든 리뷰에서 가능한 가장 많은 텍스트를 추출하기 위해 512로 설정되었습니다. 리뷰가 512토큰을 초과하는 경우가 없다면 max_length 매개변수를 설정하지 않고 남기면 모델의 최대 길이로 기본 설정됩니다. 또는 Feine-Tuning 중에 학습 시간을 줄이기 위해 512보다 작은 최대 길이를 여전히 강제로 지정할 수 있지만 모델 성능의 손실이 발생합니다. (대부분이 그렇지만) 512토큰보다 짧은 리뷰의 경우 패딩 토큰이 추가되어 인코딩된 리뷰가 512토큰으로 확장됩니다. 이렇게 설정하는 방법에 대해서는 패딩 매개변수를 max_length로 설정하면 됩니다. encode 매서드에 대한 자세한 내용은 Hugging Face 문서를 참조하십시오 [10].\n\n```js\nreview = df[\"review_cleaned\"].iloc[0];\n\ntoken_ids = tokenizer.encode(\n  review,\n  (max_length = 512),\n  (padding = \"max_length\"),\n  (truncation = True),\n  (return_tensors = \"pt\")\n);\n\nprint(token_ids);\n```\n\n```js\ntensor([\n  [\n    101,\n    2028,\n    1997,\n    1996,\n    2060,\n    15814,\n    2038,\n    3855,\n    2008,\n    2044,\n    3666,\n    2074,\n    1015,\n    11472,\n    2792,\n    2017,\n    1005,\n    2222,\n    2022,\n    13322,\n\n    ...0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n  ],\n]);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAttention Mask을 encode_plus와 함께 사용하기:\n\n위의 예제는 데이터셋에서 첫 번째 리뷰의 인코딩을 보여줍니다. 이 리뷰에는 119개의 패딩 토큰이 포함되어 있습니다. 현재 상태로 fine-tuning에 사용된다면, BERT는 패딩 토큰에 주의를 기울일 수 있어 성능이 떨어질 수 있습니다. 이를 해결하기 위해 입력에서 특정 토큰(이 경우 패딩 토큰)을 무시하도록 BERT에 지시하는 attention mask를 적용할 수 있습니다. 위의 코드를 수정하여 encode_plus 메소드를 사용하면 이러한 attention mask를 생성할 수 있습니다. encode_plus 메소드는 표준 encode 메소드 대신 사용되며 Batch Encoder(허깅페이스의 용어)라고 불리는 딕셔너리가 반환됩니다. 이 딕셔너리는 다음과 같은 key를 포함합니다:\n\n- input_ids — 표준 encode 메소드로부터 반환된 동일한 토큰 ID\n- token_type_ids — 문장 A (id = 0)와 문장 B (id = 1)를 구분하는 데 사용되는 세그먼트 ID(예: Next Sentence Prediction과 같은 문장 쌍 작업)\n- attention_mask — 특정 토큰이 attention 과정에서 무시되어야 하는지 (0을 의미) 아니면 무시되어서는 안 되는지 (1을 의미) 나타내는 0과 1의 리스트\n\n```js\nreview = df[\"review_cleaned\"].iloc[0];\n\nbatch_encoder = tokenizer.encode_plus(\n  review,\n  (max_length = 512),\n  (padding = \"max_length\"),\n  (truncation = True),\n  (return_tensors = \"pt\")\n);\n\nprint(\"Batch encoder keys:\");\nprint(batch_encoder.keys());\n\nprint(\"\\nAttention mask:\");\nprint(batch_encoder[\"attention_mask\"]);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n벡터 인코더 키:\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n\n주의 마스크:\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n\n                                      ...\n\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])\n\n모든 리뷰 인코딩:\n\n토큰화 단계의 마지막 단계는 데이터 세트의 모든 리뷰를 인코딩하고 토큰 ID 및 해당하는 주의 마스크를 텐서로 저장하는 것입니다.\n\n```python\nimport torch\n\n토큰 ID = []\n주의 마스크 = []\n\n# 각 리뷰 인코딩\nfor review in df['review_cleaned']:\n    batch_encoder = tokenizer.encode_plus(\n        review,\n        max_length = 512,\n        padding = 'max_length',\n        truncation = True,\n        return_tensors = 'pt')\n\n    token_ids.append(batch_encoder['input_ids'])\n    attention_masks.append(batch_encoder['attention_mask'])\n\n# 토큰 ID 및 주의 마스크 목록을 PyTorch 텐서로 변환\n토큰 ID = torch.cat(토큰 ID, dim=0)\n주의 마스크 = torch.cat(주의 마스크, dim=0)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.3 — 트레인 및 검증 데이터로더 생성하기\n\n이제 각 리뷰가 인코딩되었으므로 데이터를 훈련 세트와 검증 세트로 분할할 수 있습니다. 검증 세트는 피니튜닝 프로세스의 효과를 평가하는 데 사용될 것이며, 프로세스 중에 성능을 지속적으로 모니터링할 수 있도록 합니다. 에폭이 진행됨에 따라 손실이 감소하고 모델 정확도가 증가할 것으로 예상됩니다. 에폭이란 트레인 데이터를 전부 한 번 통과하는 것을 의미합니다. BERT 저자들은 플레튜닝을 위해 2~4 에폭을 권장하며, 이는 분류 헤더가 모든 리뷰를 2~4번 보게 됨을 의미합니다.\n\n데이터를 분할하기 위해, SciKit-Learn의 model_selection 패키지에서 제공하는 train_test_split 함수를 사용할 수 있습니다. 이 함수는 분할할 데이터셋, 테스트 세트(또는 우리의 경우에는 검증 세트)로 할당할 아이템의 비율, 그리고 데이터를 무작위로 섞을지에 대한 옵션 인수를 필요로 합니다. 재현성을 위해 무작위로 섞는 매개변수를 False로 설정할 것입니다. 테스트 크기에는 0.1이라는 작은 값(10%에 해당)을 선택할 것입니다. 모델을 평가하고 수행을 정확히 파악하기 위해 충분한 데이터를 사용하는 것과 모델을 훈련하고 성능을 향상시키는 데 충분한 데이터를 유지하는 것 사이에 균형을 유지하는 것이 중요합니다. 따라서 0.1과 같은 작은 값이 종종 선호됩니다. 토큰 ID, 어텐션 마스크, 라벨을 분리한 후, 훈련 및 검증 텐서를 PyTorch TensorDatasets에 함께 그룹화할 수 있습니다. 그런 다음 이 TensorDatasets를 배치로 분할하여 훈련 및 검증용 PyTorch DataLoader 클래스를 생성할 수 있습니다. BERT 논문에서는 16 또는 32의 배치 크기를 권장합니다(즉, 모델에 16개의 리뷰와 해당 감정 라벨을 제시하고 분류 헤더에서 가중치와 바이어스를 다시 계산하기 전에). DataLoader를 사용하면 병렬 처리를 활용하여 피니튜닝 프로세스 중에 데이터를 효율적으로 모델로 로드할 수 있으며, 다중 CPU 코어를 활용할 수 있습니다.\n\n```js\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\n\nval_size = 0.1\n\n# 토큰 ID 분할\ntrain_ids, val_ids = train_test_split(\n                        token_ids,\n                        test_size=val_size,\n                        shuffle=False)\n\n# 어텐션 마스크 분할\ntrain_masks, val_masks = train_test_split(\n                            attention_masks,\n                            test_size=val_size,\n                            shuffle=False)\n\n# 라벨 분할\nlabels = torch.tensor(df['sentiment_encoded'].values)\ntrain_labels, val_labels = train_test_split(\n                                labels,\n                                test_size=val_size,\n                                shuffle=False)\n\n# 데이터로더 생성\ntrain_data = TensorDataset(train_ids, train_masks, train_labels)\ntrain_dataloader = DataLoader(train_data, shuffle=True, batch_size=16)\nval_data = TensorDataset(val_ids, val_masks, val_labels)\nval_dataloader = DataLoader(val_data, batch_size=16)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.4 — BERT 모델 인스턴스화\n\n다음 단계는 미세 조정할 사전 훈련된 BERT 모델을 로드하는 것입니다. 우리는 이전과 마찬가지로 Hugging Face 모델 저장소에서 모델을 가져올 수 있습니다. Hugging Face에는 이미 분류 헤드가 연결된 여러 버전의 BERT가 있어 이 프로세스가 매우 편리합니다. 미리 구성된 분류 헤드를 가진 일부 모델의 예는 다음과 같습니다:\n\n- BertForMaskedLM\n- BertForNextSentencePrediction\n- BertForSequenceClassification\n- BertForMultipleChoice\n- BertForTokenClassification\n- BertForQuestionAnswering\n\n물론, PyTorch 또는 Tensorflow에서 headless BERT 모델을 가져와 직접 분류 헤드를 만들 수도 있습니다. 그러나 우리의 경우에는 이미 필요한 선형 레이어를 포함하는 BertForSequenceClassification 모델을 가져와 사용할 수 있습니다. 이 선형 레이어는 무작위 가중치와 바이어스로 초기화되며, 미세 조정 중에 훈련될 것입니다. BERT Base는 768개의 임베딩 차원을 사용하므로, 숨겨진 레이어에는 모델의 최종 인코더 블록에 연결된 768개의 뉴런이 포함되어 있습니다. 출력 뉴런의 수는 num_labels 인수에 의해 결정되며, 고유한 감정 레이블의 수와 일치합니다. IMDb 데이터셋은 긍정과 부정만 포함하므로 num_labels 인수가 2로 설정됩니다. 중립 또는 혼합과 같은 레이블을 포함하여 보다 복잡한 감정 분석을 수행하려면 num_labels 값을 쉽게 조절할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ntransformers 패키지에서 BertForSequenceClassification을 가져옵니다.\n\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased',\n    num_labels=2)\n```\n\n## 3.5 — Optimizer, Loss Function, 및 Scheduler 인스턴스화\n\nOptimizer:\n\n분류 head가 학습 데이터의 일괄 처리를 만나면, 선형 레이어의 가중치와 바이어스를 업데이트하여 그 입력에 대한 모델 성능을 향상시킵니다. 여러 배치와 여러 epoch 동안, 이러한 가중치와 바이어스가 최적값으로 수렴하도록 하는 것이 목표입니다. 각 가중치와 바이어스에 필요한 변경 사항을 계산하기 위해 옵티마이저가 필요하며, PyTorch의 `optim` 패키지에서 가져올 수 있습니다. Hugging Face는 자신들의 예제에서 AdamW 옵티마이저를 사용하므로, 여기서도 이 옵티마이저를 사용할 것입니다 [13].\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n손실 함수:\n\n옵티마이저는 분류 헤드의 가중치 및 편향에 대한 변경이 손실 함수에 어떤 영향을 미칠지 결정함으로써 작동합니다. 이 손실 함수라 불리는 점수 함수에 대한 손실은 PyTorch의 nn 패키지에서 쉽게 가져올 수 있습니다. 언어 모델은 일반적으로 교차 엔트로피 손실 함수(음의 로그 우도 함수라고도 함)를 사용하며, 따라서 여기에서는 이 손실 함수를 사용할 것입니다.\n\n스케줄러:\n\n학습 속도라 불리는 매개변수는 분류 헤드의 가중치와 편향에 대한 변경의 크기를 결정하는 데 사용됩니다. 초기 배치와 에포크에서는 무작위로 초기화된 매개변수가 상당한 조정이 필요할 수 있으므로 큰 변경이 유용할 수 있습니다. 그러나 학습이 진행됨에 따라 가중치와 편향이 향상되면서 큰 변경이 역효과적일 수 있습니다. 스케줄러는 학습 과정이 계속되는 동안 학습 속도를 점차 감소시켜 각 가중치 및 편향에 대한 각 최적화 단계에서 발생하는 변경 크기를 줄이도록 설계되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nfrom torch.optim import AdamW\nimport torch.nn as nn\nfrom transformers import get_linear_schedule_with_warmup\n\nEPOCHS = 2\n\n# Optimizer\noptimizer = AdamW(model.parameters())\n\n# Loss function\nloss_function = nn.CrossEntropyLoss()\n\n# Scheduler\nnum_training_steps = EPOCHS * len(train_dataloader)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps)\n```\n\n## 3.6 — Fine-Tuning Loop\n\nCUDA를 사용하여 GPU 활용:\n\nNVIDIA에서 만든 CUDA(Compute Unified Device Architecture)는 과학 및 공학 분야의 응용 프로그램 성능을 향상시키기 위한 컴퓨팅 플랫폼입니다 [14]. PyTorch의 cuda 패키지를 사용하면 Python에서 CUDA 플랫폼을 활용하여 머신 러닝 모델을 훈련할 때 GPU를 사용할 수 있습니다. torch.cuda.is_available 명령을 사용하여 GPU의 가용성을 확인할 수 있습니다. GPU가 없는 경우 코드는 가속 계산을 위해 그래픽 처리 장치 (GPU)를 사용할 수 없도록 기본 설정됩니다. 이후의 코드 스니펫에서는 PyTorch Tensor.to 메서드를 사용하여 텐서(모델 가중치 및 편향 등이 포함됨)를 더 빠른 계산을 위해 GPU로 이동합니다. 장치가 cpu로 설정된 경우 텐서가 이동되지 않고 코드에 영향을 미치지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# GPU 사용 가능 여부 확인하여 빠른 학습 시간을 위한 준비\n\nif torch.cuda.is_available():\ndevice = torch.device('cuda:0')\nelse:\ndevice = torch.device('cpu')\n\n학습 프로세스는 두 개의 for 루프를 통해 이루어집니다: 각 epoch마다 프로세스를 반복하는 외부 루프(모델이 모든 학습 데이터를 여러 번 보게하는 역할)와 각 배치마다 손실 계산 및 최적화 단계를 반복하는 내부 루프가 있습니다. 학습 루프를 설명하기 위해 아래 단계를 고려해 보세요. 학습 루프의 코드는 Chris McCormick과 Nick Ryan의 훌륭한 블로그 글[15]에서 적용되었으며 매우 추천합니다.\n\n각 epoch에 대해:\n\n1. 모델을 train 모드로 변경합니다. 모델 객체의 train 메서드를 사용하여 모델이 평가 모드일 때와는 다르게 작동하도록 합니다. 특히 batchnorm과 dropout 레이어와 함께 작업할 때 유용합니다. 이전에 BertForSequenceClassification 클래스의 소스 코드를 살펴봤다면, 분류 헤드에 실제로 dropout 레이어가 포함되어 있는 것을 보았을 겁니다. 따라서 fine-tuning 시에 training 및 evaluation 모드를 올바르게 구분해야 합니다. 이러한 종류의 레이어는 학습 중에만 활성화되어야 하며 추론 중에는 활성화되지 않아야 합니다. 따라서 학습과 추론을 위해 서로 다른 모드로 전환할 수 있는 기능은 유용한 기능입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 에포크 시작 시 훈련 손실을 0으로 설정하세요. 이것은 이후 에포크에서 모델의 훈련 데이터 손실을 추적하는 데 사용됩니다. 훈련이 성공적이라면 각 에포크마다 손실이 감소해야 합니다.\n\n각 배치에 대해:\n\nBERT 저자들의 권장에 따라, 각 에포크의 훈련 데이터를 배치로 나누세요. 각 배치마다 훈련 프로세스를 반복하세요.\n\n3. 가능한 경우 토큰 ID, 어텐션 마스크 및 레이블을 GPU로 이동하여 처리 속도를 높이세요. 그렇지 않으면 이러한 데이터는 CPU에 유지됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4. 이 루프의 이전 반복에서 계산된 그래디언트를 재설정하기 위해 zero_grad 메서드를 호출하세요. PyTorch에서 기본 동작이 아닌 이유가 명확하지 않을 수 있지만, 이는 Recurrent Neural Networks와 같은 모델이 반복 사이에 그래디언트를 재설정해선 안 되는 이유로 제안됩니다.\n\n5. 배치를 모델에 전달하여 로짓(현재의 분류기 가중치와 편향에 기반한 예측)과 손실을 계산하세요.\n\n6. 에폭별 총 손실을 증가시키세요. 모델에서 손실이 PyTorch 텐서로 반환되므로 `item` 메서드를 사용하여 부동 소수점 값을 추출하세요.\n\n7. 모델에 역전파를 수행하고 분류기 헤드를 통해 손실을 전파하세요. 이를 통해 모델은 배치에 대한 성능을 향상시키기 위해 가중치와 편향을 조정해야 하는지를 결정할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n8. 모델이 폭발하는 그래디언트 문제를 겪지 않도록 그래디언트를 1.0보다 크게 만들지 마세요.\n\n9. 역전파에 따라 오차 표면 방향으로 옵티마이저를 호출하여 한 단계씩 진행하세요.\n\n각 배치 훈련 후:\n\n10. 에포크에서의 평균 손실과 소요 시간을 계산하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nfor epoch in range(0, EPOCHS):\n\n    model.train()\n    training_loss = 0\n\n    for batch in train_dataloader:\n\n        batch_token_ids = batch[0].to(device)\n        batch_attention_mask = batch[1].to(device)\n        batch_labels = batch[2].to(device)\n\n        model.zero_grad()\n\n        loss, logits = model(\n            batch_token_ids,\n            token_type_ids = None,\n            attention_mask=batch_attention_mask,\n            labels=batch_labels,\n            return_dict=False)\n\n        training_loss += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    average_train_loss = training_loss / len(train_dataloader)\n\n외부 루프 내에서 검증 단계가 수행되므로 각 epoch마다 평균 검증 손실을 계산합니다. epoch 숫자가 증가함에 따라 검증 손실이 감소하고 분류기 정확도가 증가할 것으로 기대됩니다. 검증 프로세스 단계는 아래에 설명되어 있습니다.\n\n에포크의 검증 단계:\n\n11. evaluation 메서드를 사용하여 모델을 평가 모드로 전환합니다. 이렇게 하면 드롭아웃 레이어가 비활성화됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n12. 검증 손실을 0으로 설정하세요. 이 값은 후속 에포크에서 모델의 검증 데이터에 대한 손실을 추적하는 데 사용됩니다. 학습이 성공적이었다면 손실은 각 에포크마다 감소해야 합니다.\n\n13. 검증 데이터를 배치로 나누세요.\n\n각 배치에 대해:\n\n14. 사용 가능한 경우 토큰 ID, 어텐션 마스크 및 레이블을 GPU로 이동하여 처리 속도를 높이세요. 그렇지 않으면 이러한 값들은 CPU에 유지됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n15. 여기서는 최적화 단계를 수행하지 않고 추론만 할 것이기 때문에 모델이 그라디언트를 계산하지 않도록 no_grad 메서드를 호출하세요.\n\n16. 배치를 모델에 전달하여 로짓(현재 분류기의 가중치와 편향을 기반으로 한 예측)와 손실을 계산하세요.\n\n17. 모델에서 로짓과 레이블을 추출하여 CPU로 이동하세요 (이미 CPU에 있지 않은 경우).\n\n18. 손실을 증가시키고 검증 데이터로더의 실제 레이블에 기반하여 정확도를 계산하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n19. 손실 및 정확도의 평균을 계산하세요.\n\n```js\n    model.eval()\n    val_loss = 0\n    val_accuracy = 0\n\n    for batch in val_dataloader:\n\n        batch_token_ids = batch[0].to(device)\n        batch_attention_mask = batch[1].to(device)\n        batch_labels = batch[2].to(device)\n\n        with torch.no_grad():\n            (loss, logits) = model(\n                batch_token_ids,\n                attention_mask = batch_attention_mask,\n                labels = batch_labels,\n                token_type_ids = None,\n                return_dict=False)\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = batch_labels.to('cpu').numpy()\n        val_loss += loss.item()\n        val_accuracy += calculate_accuracy(logits, label_ids)\n\n    average_val_accuracy = val_accuracy / len(val_dataloader)\n```\n\n위의 코드 스니펫의 끝에서 calculate_accuracy 함수를 사용하고 있지만 아직 정의하지 않았으니, 이제 정의해 보겠습니다. 모델의 검증 세트에서의 정확도는 옳은 예측의 비율로 주어집니다. 따라서 모델에 의해 생성된 로짓 값, 즉 변수 logits에 저장된 값을 사용할 수 있고, 이를 NumPy의 argmax 함수를 이용할 수 있습니다. argmax 함수는 배열에서 가장 큰 요소의 인덱스를 반환합니다. 텍스트 I liked this movie에 대한 로짓이 [0.08, 0.92]인 경우, 0.08은 텍스트가 부정일 확률을 나타내고 0.92는 텍스트가 긍정일 확률을 나타내므로 argmax 함수는 인덱스 1을 반환할 것입니다. 모델은 텍스트가 부정보다 긍정일 가능성이 더 높다고 판단합니다. 그런 다음 해당 레이블을 Section 3.3(19번째 줄)에서 이미 인코딩한 labels 텐서와 비교하면 됩니다. 로짓 변수에는 배치(총 16개)의 모든 리뷰에 대한 긍정 및 부정 확률 값이 포함되므로 모델의 정확도는 최대 16개의 옳은 예측 중 계산됩니다. 위의 코드는 val_accuracy 변수가 각 정확도 점수를 기록하고, 검증을 마친 후에 모델의 검증 데이터에 대한 평균 정확도를 결정하기 위해 나누는 것을 보여줍니다.\n\n```js\ndef calculate_accuracy(preds, labels):\n    \"\"\" 모델 예측과 실제 레이블의 정확도를 계산합니다.\n\n    매개변수:\n        preds (np.array): 모델의 예측된 레이블\n        labels (np.array): 실제 레이블\n\n    반환값:\n        정확도 (float): 올바른 예측의 백분율로 정확도가 반환됩니다.\n    \"\"\"\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n    return accuracy\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.7 — 완벽한 파인튜닝 파이프라인\n\n그렇게 해서 우리는 파인튜닝의 설명을 마쳤습니다! 아래 코드는 위의 모든 것을 하나의 재사용 가능한 클래스로 가져와서 BERT를 사용하는 모든 NLP 작업에 사용할 수 있습니다. 데이터 전처리 단계는 작업에 따라 다르기 때문에 이는 파인튜닝 클래스 밖으로 뺐습니다.\n\nIMDb 데이터셋을 이용한 감정 분석을 위한 데이터 전처리 함수:\n\n```python\ndef preprocess_dataset(path):\n    \"\"\" 불필요한 문자를 제거하고 감정 레이블을 인코딩합니다.\n\n    필요한 전처리 유형은 데이터셋에 따라 변경됩니다. IMDb 데이터셋의 경우, 리뷰 텍스트에는 스크래핑 과정에서 남아 있는 HTML 줄 바꿈 태그 (\u003cbr/\u003e)와 일부 불필요한 공백이 있습니다. 이를 제거합니다. 마지막으로, \"부정\"에 대한 감정 값을 0으로, \"긍정\"에 대한 감정 값을 1로 인코딩합니다. 이 메서드는 데이터셋 파일에 \"review\" 및 \"sentiment\" 헤더가 포함되어 있다고 가정합니다.\n\n    매개변수:\n        path (str): 감정 분석 데이터셋을 포함하는 데이터셋 파일의 경로입니다. 파일 구조는 다음과 같아야 합니다:\n            리뷰 텍스트를 담은 \"review\" 열과, ground truth 레이블을 담은 \"sentiment\" 열이 하나씩 있는 한 열인 파일입니다.\n            레이블 옵션은 \"부정\"과 \"긍정\"이어야 합니다.\n\n    반환:\n        df_dataset (pd.DataFrame): self.dataset 경로에서 로드한 원시 데이터가 있는 DataFrame입니다. \"review\"와 \"sentiment\" 열 외에도 다음이 포함됩니다:\n            - review_cleaned: \"review\" 열의 사본이고 HTML 줄 바꿈 태그와 불필요한 공백이 제거된 컬럼\n            - sentiment_encoded: \"sentiment\" 열의 사본이며 \"부정\" 값을 0으로 매핑하고 \"긍정\" 값을 1로 매핑한 컬럼\n\n\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n작업에 중립적인 파인튜닝 파이프라인 클래스:\n\n\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom transformers import (\n    BertForSequenceClassification,\n    BertTokenizer,\n    get_linear_schedule_with_warmup)\n\n\nclass FineTuningPipeline:\n\n    def __init__(\n            self,\n            dataset,\n            tokenizer,\n            model,\n            optimizer,\n            loss_function = nn.CrossEntropyLoss(),\n            val_size = 0.1,\n            epochs = 4,\n            seed = 42):\n\n        self.df_dataset = dataset\n        self.tokenizer = tokenizer\n        self.model = model\n        self.optimizer = optimizer\n        self.loss_function = loss_function\n        self.val_size = val_size\n        self.epochs = epochs\n        self.seed = seed\n\n        # Check if GPU is available for faster training time\n        if torch.cuda.is_available():\n            self.device = torch.device('cuda:0')\n        else:\n            self.device = torch.device('cpu')\n\n        # Perform fine-tuning\n        self.model.to(self.device)\n        self.set_seeds()\n        self.token_ids, self.attention_masks = self.tokenize_dataset()\n        self.train_dataloader, self.val_dataloader = self.create_dataloaders()\n        self.scheduler = self.create_scheduler()\n        self.fine_tune()\n\n    def tokenize(self, text):\n        \"\"\" Tokenize input text and return the token IDs and attention mask.\n\n        Tokenize an input string, setting a maximum length of 512 tokens.\n        Sequences with more than 512 tokens will be truncated to this limit,\n        and sequences with less than 512 tokens will be supplemented with [PAD]\n        tokens to bring them up to this limit. The datatype of the returned\n        tensors will be the PyTorch tensor format. These return values are\n        tensors of size 1 x max_length where max_length is the maximum number\n        of tokens per input sequence (512 for BERT).\n\n...\n\n\n감정 분석을 위한 클래스 사용 예 (IMDb 데이터셋):\n\n# 매개변수 초기화\ndataset = preprocess_dataset('IMDB Dataset Very Small.csv')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased',\nnum_labels=2)\noptimizer = AdamW(model.parameters())\n\n# 클래스를 사용하여 모델을 파인튜닝\nfine_tuned_model = FineTuningPipeline(\n    dataset=dataset,\n    tokenizer=tokenizer,\n    model=model,\n    optimizer=optimizer,\n    val_size=0.1,\n    epochs=2,\n    seed=42\n)\n\n# 유효성 검사 데이터셋을 사용하여 일부 예측 수행\nmodel.predict(model.val_dataloader)\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 4 — 결론\n\n이 글에서는 BERT의 여러 측면을 탐색했습니다. BERT의 창시 시점의 배경, 모델 아키텍처의 자세한 분석 및 감성 분석을 사용하여 시업 무관한 미세 조정 파이프라인 작성을 포함했습니다. BERT는 가장 초기의 LLM 중 하나임에도 불구하고, 오늘날에도 여전히 중요하며 연구 및 산업 분야에서 응용 프로그램을 발전시키고 있습니다. BERT를 이해하고 NLP 분야에 미치는 영향을 이해하면 최신 고품질 모델을 다루는 데 튼실한 기반을 다질 수 있습니다. 미세 조정 및 사전 훈련이 LLM의 지배적 패러다임으로 유지되고 있으므로, 이 글이 여러분의 프로젝트에 적용해 가며 가치 있는 통찰을 제공했기를 바랍니다!\n\n# 5 — 추가 자료\n\n[1] J. Devlin, M. Chang, K. Lee, and K. Toutanova, BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2019), North American Chapter of the Association for Computational Linguistics\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[2] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, Attention is All You Need (2017), Advances in Neural Information Processing Systems 30 (NIPS 2017)\n\n[3] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer, Deep contextualized word representations (2018), Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)\n\n[4] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever (2018), Improving Language Understanding by Generative Pre-Training,\n\n[5] Hugging Face, Fine-Tuned BERT Models (2024), HuggingFace.co\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 논문 및 참고 자료 목록\n\n- M. Schuster 및 K. K. Paliwal, Bidirectional recurrent neural networks (1997), IEEE Signal Processing 트랜잭션 45\n\n- Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba 및 S. Fidler, Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books (2015), 2015 IEEE International Conference on Computer Vision (ICCV)\n\n- L. W. Taylor, “Cloze Procedure”: A New Tool for Measuring Readability (1953), Journalism Quarterly, 30(4), 415–433.\n\n- Hugging Face, Pre-trained Tokenizers (2024) HuggingFace.co\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[10] Hugging Face, Pre-trained Tokenizer Encode Method (2024) HuggingFace.co\n\n[11] T. Vo, PyTorch DataLoader: Features, Benefits, and How to Use it (2023) SaturnCloud.io\n\n[12] Hugging Face, Modelling BERT (2024) GitHub.com\n\n[13] Hugging Face, Run Glue, GitHub.com\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[14] NVIDIA, CUDA Zone (2024), Developer.NVIDIA.com\n\n[15] C. McCormick and N. Ryan, BERT Fine-tuning (2019), McCormickML.com\n```\n","ogImage":{"url":"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png"},"coverImage":"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png","tag":["Tech"],"readingTime":54},{"title":"고유명사 인식 노출 - 필수 가이드","description":"","date":"2024-05-20 20:57","slug":"2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide","content":"\n![NamedEntityRecognitionUnmaskedTheEssentialGuide](/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png)\n\n## 소개\n\n알겠어요, 상상해보세요— 정보를 처리하고 싶은 기사, 저널 및 블로그의 산더미가 많이 있습니다. 이제 이 데이터에 작업할 기회가 커뮤니티에 도움이 될 것이라고 생각해보세요. 하지만 이 데이터를 즉시 공유하고 싶지는 않을 것입니다. 왜냐하면 사람들의 동의 없이 공유하면 안 되는 개인 정보가 포함될 수도 있기 때문입니다.\n\n모든 사람으로부터 허락을 받는 것은 현실적이지 않기 때문에 당신은 자신의 기술을 사용하여 FERPA 가이드라인에 따라 개인 정보를 숨기기로 결정합니다. 회사들이 분석이나 데모 목적으로 외부에서 공유할 때 데이터를 가리는 것은 흔한 일이며, 숫자 데이터의 경우 더 쉽습니다. 여기서는 텍스트 데이터를 사용하여 동일한 작업을 하려고 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금 여기서는 텍스트 데이터에 대해 이야기하고 있으므로 자연어 처리(NLP) 기술 중 하나를 적용할 것입니다. 그 기술은 Named Entity Recognition (NER)로, 숨겨진 데이터 보물을 찾아내는 신뢰할 수 있는 NLP 탐정입니다. 여기서 목적은 개인 정보를 식별하는 것입니다.\n\n이제 NER이 어떻게 작동하는지, NER 메커니즘의 개념, NER을 구현하는 방법, 선택할 수 있는 해결책 접근 방식 및 그 이유, 그리고 Python에서 이 문제에 대한 해결책을 구현하는 방법에 대해 더 자세히 살펴봅시다.\n\n## Named Entity Recognition (NER): 기술적 분해\n\n간단히 말해, NER은 컴퓨터에게 텍스트 내에서 특정 '개체'를 식별하는 것입니다. 이 경우에는 개인 식별 정보(PII)를 의미합니다. 프로그램에 하이라이터 세트를 제공하는 것과 유사하게 생각해보세요. 이름, 장소, 회사, 대학, 학생 ID, 이메일 주소 또는 개인을 식별할 수 있는 것들을 각각 나타내는 하이라이터가 있다고 상상해보세요. 이제 NER이 어떻게 작동하는지 간단히 살펴보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Rule-based Systems: 예전 방식입니다. 우리는 \"이름은 일반적으로 대문자로 시작합니다.\"와 같은 수기 작성 규칙을 만듭니다. 기본적인 경우에는 잘 작동하지만 굉장히 복잡해질 수 있습니다. 또한 많은 규칙이 있다면 더럽고 혼란스러워질 수 있습니다.\n- Machine Learning Approach: 통계 모델은 대규모 데이터 세트에서 학습합니다. 여러분의 NER 시스템에 많은 예제를 보여주는 것처럼 생각해보세요. 모델이 스스로 패턴을 찾을 수 있도록 합니다. 이것이 모든 것에 대한 머신 러닝이 작동하는 방식입니다. 그러나 텍스트 데이터에 대한 성능 문제가 발생할 수 있습니다.\n- Deep Learning Superstars: 신경망은 텍스트, 이미지 및 비디오 데이터 관련 문제에 대한 가장 유명한 방법론입니다. 우리가 하는 것과 유사한 복잡한 언어를 다룹니다. 이러한 모델은 맥락을 이해하여 매우 정확합니다. 이곳의 유일한 조건은 많은 양의 데이터를 사용해야 한다는 것입니다. 그렇지 않으면 모델은 대부분의 학습 데이터를 기억하게 됩니다 (과적합). 이를 제어하는 기술은 있지만, 여전히 많은 데이터 집합에서 가장 잘 작동합니다.\n\n## 자세한 기술: NER 뒤의 두뇌\n\nNER은 다양한 기술을 활용할 수 있음을 확인했습니다. 각각의 장점을 가진 기술에 대해 자세히 알아봅시다:\n\n- Conditional Random Fields (CRFs):\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNER 시스템을 위치를 인식하도록 가르치고 있다고 상상해보세요. \"10 Made UP Street, London, UK.\"와 같은 주소 예시를 보여줍니다. CRF는 이를 뛰어넘는 데 뛰어납니다. 왜냐하면 단어들과 그들 사이의 관계에 대해 전체 시퀀스를 고려하기 때문입니다. 숫자를 따르는 \"London\"과 도시를 따르는 \"UK\"를 이어받으면 이것은 강한 위치 엔티티를 시사합니다. 이러한 이유로, CRF는 맥락이 매우 중요한 NER과 같은 작업에 강력합니다.\n\nTDS에서 이에 대한 수학적 이론인 CRF를 설명한 Nikos Kafritsas의 훌륭한 기사를 읽어보세요.\n\n2. LSTM 네트워크 (Long Short-Term Memory):\n\n텍스트에서 사람 이름을 식별하고자 한다고 가정해봅시다. LSTMs는 RNN 이후에 크게 발명되었습니다. 왜냐하면 특별한 능력을 갖고 있기 때문입니다 — 기억! 네, 그들은 기억이나 맥락을 가지고 예측할 수 있습니다. CRF가 (현재 단어만 고려하는) 반면, LSTMs는 이전 단어를 기억하고 맥락을 잃지 않는 특성이 있습니다. 이것은 NER에 중요합니다. 왜냐하면 이것이 회사인 Apple인지 과일인 Apple인지를 이해하는 데 도움이 될 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또 다른 예시를 살펴보죠: \"Dr. Smith is a renowned cardiologist\"라는 문장에서 LSTM은 \"Dr.\"이라는 칭호를 기억하고 그 맥락을 사용하여 \"Smith\"를 사람 이름으로 올바르게 분류할 수 있습니다.\n\n실제 세계 예시를 보겠습니다: 사람들이 언급된 기사를 기반으로 분류하는 뉴스 분류기 모델을 만든다고 상상해보세요. LSTM 기반 NER 시스템이 \"Barack Obama\"나 \"Elon Musk\"와 같은 엔티티를 정확하게 식별할 수 있습니다. 이들의 이름이 복잡한 문장 안에 나타나고 분류되어 있더라도 말이죠. 훌륭한 구현 방법이죠, 그렇죠?\n\nRian Dolphin의 LSTM에 대한 포괄적인 소개 기사를 읽어보세요.\n\n3. Transformers:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n트랜스포머는 현재 자연어 처리의 핫한 주제이며, 개체명 인식(NER)도 예왌이 아닙니다. 이러한 모델은 특정 세부사항에 모든 주의를 집중하는 것과 같이 주의 메커니즘을 사용합니다. 그들이 하는 것은 전체 문장 전반에 걸쳐 관련 단어에 주의를 기울이는 것입니다. 인간이 처음 보는 텍스트를 읽는 것처럼 상상해보세요. 여기저기 훑어보면서 (스포트라이트처럼) 각 부분에 마음을 집중하고 의미를 파악하는 것입니다. 이 기술을 통해 그들은 복잡한 관계를 이해하고 미비한 개체조차 식별할 수 있습니다.\n\n예를 들어, \"Acme Corp의 CEO가 캘리포니아를 기반으로 새 제품 출시를 발표했습니다.\" 라는 문장을 생각해보세요. 트랜스포머 기반 NER 시스템은 \"CEO\"와 \"Acme Corp\"에 주의를 기울일 수 있습니다. 이들이 여러 단어로 분리되어 있는데도요. 그런 다음 이 주의를 사용하여 \"Acme Corp\"를 조직으로 올바르게 분류할 수 있습니다.\n\n이 능력은 트랜스포머를 의료 연구 논문에서 의학 용어를 식별하거나 소셜 미디어 데이터에서 특정 제품명을 식별하는 것과 같은 작업에 이상적으로 만들어줍니다.\n\n제임스 브릭스의 기사 \"NER with Transformers and Spacy\"를 읽어보세요. 그리고 아직 '주의'에 대해 궁금하다면, 아륀 사르카의 \"Attention과 Transformers에 대한 이해 - 파트 1\"이라는 기사부터 읽어보는 것도 좋은 시작입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기본을 넘어선 발전 기술\n\nNER의 세계는 끊임없이 진화하고 있습니다. 주목해야 할 몇 가지 흥미로운 발전 사항을 소개합니다:\n\n- 양방향 LSTM(BiLSTM): 이들은 LSTM을 더욱 강력하게 만든 버전으로, 텍스트를 앞뒤로 처리합니다. 이로 인해 더 깊은 맥락을 이해할 수 있습니다. 이 기법에는 단점이 있습니다. 앞뒤로 문장을 모두 입력하기 때문에 예측이 어렵습니다. 그러나 시스템은 맥락에 대해 알고 있습니다.\n- 명명된 엔티티 구별(NED): 다시 말해, \"Apple\"이라는 단어를 본다고 상상해 봅시다. 이것이 기술 거대 기업을 가리키는 것인지 아니면 과일을 가리키는 것인지 구분해야 합니다. NER은 NED와 결합하여 콘텍스트에서 가장 가능성이 높은 의미를 식별할 수 있습니다.\n\n이러한 기술을 이해하고 최신 발전 사항을 파악함으로써, 텍스트 데이터에서 가치 있는 개인 정보를 발굴하고 연구 노력을 지원하는 데 NER의 힘을 활용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## NER 작업 실습: 프로젝트 코드 미리보기\n\n손을 더럽혀 볼 시간이에요! 만약 Python과 훌륭한 spaCy 라이브러리를 사용한다고 가정해봅시다:\n\nPython\n\n```js\npython -m spacy download en_core_web_trf\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\npip install spacy\npip install nltk\n```\n\n```js\nimport spacy\nfrom spacy import displacy\nimport nltk  # NLTK를 추가 작업에 사용할 예정\nfrom nltk.corpus import stopwords  # NLTK 활용 예시\n\n# 강력한 사전 훈련된 NER 모델 로드 (필요에 따라 조정)\nnlp = spacy.load(\"en_core_web_trf\")\n\n# 분석할 텍스트 정의\ntext = \"\"\"\nJane Doe, a researcher at Stanford University, recently published a paper on\nNatural Language Processing.  Dr. John Smith from MIT will be collaborating on the\nproject.  They can be reached at jane.doe@stanford.edu and john_smith@mit.edu.\n\"\"\"\n\n# NER로 텍스트 처리\ndoc = nlp(text)\n\n# 식별된 엔티티 출력\nprint(\"식별된 엔티티:\")\nfor entity in doc.ents:\n    print(entity.text, entity.label_)\n\n# NER 결과 시각화\ndisplacy.render(doc, style=\"ent\", jupyter=True)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서 확인할 수 있듯이 NER은 이름과 조직을 완벽하게 식별할 수 있었지만 이메일 주소를 놓쳤습니다. 이 현상이 발생한 이유를 살펴보고 어떻게 수정할 수 있는지 알아봅시다.\n\n이메일 주소를 놓치는 이유\n\n- NER 모델 한계: 표준 NER 모델은 일반적으로 이름, 조직, 위치 등과 같은 범주로 훈련됩니다. 몇 가지 이메일 패턴을 잡아낼 수 있을 수 있지만 이것이 주된 강점이 아닙니다. 따라서 이 경우에는 그것을 놓쳤습니다.\n- 이메일 주소의 복잡성: 이메일 형식은 놀랍도록 다양할 수 있습니다. \"Gmail 및 Yahoo\"와 같이 간단한 것들은 인식될 수 있지만 더 복잡한 패턴은 놓칠 수 있습니다. 예를 들어 gmail ID를 잡아낼 수 있지만 특정 조직별 ID를 놓칠 수 있습니다. 다시 말해, 이 경우에 발생한 것과 같습니다.\n\n이유를 알고 있지만, 문제를 어떻게 수정할지에 더 초점을 맞출 수 있을 것입니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다섯가지 기술 중 하나를 사용하여 작업을 개인화하고 해결합시다:\n\n- 정규 표현식 (Regex): 정규 표현식을 사용하여 이메일 주소에 일치하는 특정 패턴을 작성할 수 있습니다. 이 기술은 예전부터 개발되어 많이 사용되고 있습니다. 이를 프로그래밍에서 패턴을 인식하기 위한 어렵게 코딩된 것으로 생각할 수 있습니다. 다음은 기본적인 예제입니다:\n\n```js\nimport re\n\nemail_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\nemails = re.findall(email_regex, text)\nprint(emails)\n```\n\n- 전문 라이브러리 사용: email_validator와 같은 라이브러리를 사용할 수 있습니다. 이러한 라이브러리들은 이메일 식별 및 유효성 검사에 전념하고 있습니다. 이메일을 유효성 검사하는 것이 당신의 경우라면 이 옵션을 사용할 수 있습니다.\n- NER 모델 개선: 기존 모델을 세밀하게 조정하여 이메일 주소 예제를 추가 엔티티 유형으로 제공할 수 있습니다. 그러나 이 작업에는 더 많은 데이터와 복잡한 모델 훈련이 필요합니다. BERT 등과 같은 사전 훈련된 모델을 사용하는 것도 포함됩니다. 다시 한번, James Briggs의 'NER with Transformers and Spacy' 라는 글을 읽어보세요. 이 글은 roBERTA를 세밀하게 조정하고 spaCy를 사용하는 방법에 대해 이야기합니다. 이 옵션을 확실하게 이해하실 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 방법을 선택하여 시연하고 코드에 구현해 보겠습니다. 이메일 추출을 위한 섹션을 아래와 같이 추가할 수 있습니다:\n\nPython\n\n```js\nimport re\n\nemail_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\nemails = re.findall(email_regex, text)\nprint(\"찾은 이메일:\", emails)\n```\n\n결과\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_2.png\" /\u003e\n\n가장 적합한 방법 선택하기\n\n이상적인 해결책은 프로젝트의 특정성에 따라 다릅니다:\n\n- 간단한 이메일 + 정확도: 정규식(Regex)이 충분할 것으로 예상됩니다.\n- 복잡한 이메일 + 신뢰성: 전문 이메일 유효성 검사 라이브러리가 가장 안전합니다.\n- NER 재학습: 다른 엔티티의 NER 정확도가 중요하고 이메일 중심 데이터가 많이 있는 경우, 모델을 다시 학습시키는 것이 장기적인 해결책이 될 수 있습니다. 당신이 상상한 대로, BERT 사전 훈련된 모델을 파인튜닝하여 사용하는 등의 멋진 기술을 사용할 수 있습니다. 이를 사용하기 전 고려해야 할 중요한 점은:\n\n- 데이터: 파인튜닝을 위해서는 상당량의 레이블이 지정된 데이터가 필요합니다. 데이터가 제한적인 경우, 다른 기술(예: 정규식)이 처음에는 더 실용적일 수 있습니다.\n- 복잡성: 파인튜닝은 설정 및 계산 리소스가 정규식이나 기본 라이브러리보다 많이 필요할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## NER 스킬을 강화할 수 있는 리소스들\n\n- spaCy: 훌륭한 NER 지원을 갖춘 우수한 NLP 라이브러리 (https://spacy.io/).\n- NLTK: 클래식한 NLP 툴킷 (https://www.nltk.org/).\n- Stanford CoreNLP: 강력한 NLP 도구 모음 (https://stanfordnlp.github.io/CoreNLP/)\n\n앞으로의 길\n\nNER은 아직 핫한 연구 분야입니다 — 복잡한 관계를 이해하고 사용자 정의 엔티티를 식별하며 다국어로 작동하는 모델에 대비하세요! 이 기술은 우리 주변의 방대한 텍스트에서 정보를 추출하고 활용하는 방식을 혁신하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 작성자 소개\n\n친애하는 독자 여러분, 저는 이 주제에 열정적이며 데이터 과학 주제와 생각거리 글에 대해 쓰는 것을 즐깁니다. 가장 중요한 것은 피드백을 받을 준비가 되어 있다는 것입니다!\n\n여러분의 의견을 알고 싶습니다. 이 글이 어떤 식으로든 도움이 되었거나 피드백이 있다면 망설이지 마시고 남겨주세요! 또한, 이 주제에 대한 추가 설명이 필요하다면 언제든지 댓글을 남겨 주세요. 저는 여기서 해결하려고 하거나 다른 글을 쓸 것입니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n내 정보에 대해 더 알고 싶다면, 이곳에 내 소개 글이 있어:\n\n함께 얘기 나눠보자...\n","ogImage":{"url":"/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png"},"coverImage":"/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png","tag":["Tech"],"readingTime":12},{"title":"텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기","description":"","date":"2024-05-20 20:54","slug":"2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics","content":"\n\"집중하고 있니?\" \"집중하고 있니?\" 이 두 문장은 같은 의미인가요? 기사를 읽고 알고리즘의 답변을 찾아보세요!\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png)\n\n두 개의 텍스트를 비교하는 것은 보편적이고 중요한 작업이라고 보는 경우가 많습니다. 고객 서비스에서 AI 시스템은 동의어적 의미를 이해하여 인간 대화의 유동성을 반영하는 응답을 생성할 수 있어야 합니다. 예를 들어, \"비밀번호를 어떻게 복구할 수 있나요?\" 또는 \"비밀번호를 잊었어요. 다시 로그인하는 방법이 뭐에요?\"와 같은 질문은 의미가 유사하며 동일한 응답을 요구합니다. 게다가, 고객 상호작용 중에 대리인이 계약이나 제안에 대한 정보를 정확하게 전달하는지 확인해야 하는 경우가 종종 있습니다. 또한, 검색 엔진이나 Stack Overflow와 같은 플랫폼에서 이전에 질문이 제기되었는지 알아내야 할 필요가 있습니다. 본질적으로 텍스트 유사성을 빠르게 계산할 수 있는 능력은 효율성 향상과 고객 관계 향상의 기초가 됩니다.\n\n인간은 의미론적 및 문법적 관계를 본성적으로 쉽게 이해하지만, 기계는 같은 작업을 수행하는 데 더 복잡한 도전에 직면합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저, 유사성을 더 구체적으로 정의해 봅시다: 유사성은 두 데이터 객체가 얼마나 다르거나 비슷한지를 측정한 것입니다. 거리가 짧을수록 객체들은 높은 수준의 유사성을 갖는다고 말하며, 그 반대도 마찬가지입니다.\n\n텍스트 유사성은 두 텍스트 조각이 어휘적으로(사용된 단어)와 의미론적으로(단어의 의미) 얼마나 가까운지를 나타냅니다. 예를 들어, \"병이 비어 있습니다\"와 \"병 안에는 아무 것도 없습니다\"라는 문장은 의미론적으로는 동일하지만 어휘적으로는 다릅니다.\n\n기계가 텍스트 유사성을 계산할 수 있도록하기 위해, 먼저 기계의 언어인 숫자를 기반으로 한 언어를 사용해야 합니다.\n\n그러므로, 텍스트 유사성을 평가하는 핵심 단계 중 하나는 텍스트를 벡터로 변환하는 것입니다. 벡터는 공간에서 크기와 방향을 나타내는 숫자 요소이기도 합니다. 이 프로세스는 텍스트 벡터화 또는 텍스트 인코딩이라고 알려져 있습니다. 유사성을 평가하기 위한 후속 단계는 이러한 벡터들 간의 거리를 측정하는 것입니다. 이 거리를 계산하는 데 선택된 측정 항목이 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 텍스트를 임베딩하고 거리를 계산하는 다양한 기술의 장단점을 포괄적으로 탐구하여 귀하의 요구에 맞는 최적의 조합을 찾을 수 있는 포괄적인 안내서를 제공합니다.\n\n자세히 들어가기 전에 이 기사의 상위 수준 색인으로 볼 수 있는 다음 그림을 살펴보겠습니다.\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_1.png)\n\n텍스트 표현은 4가지의 주요 방법으로 군집화될 수 있습니다: 문자 기반, 의미론적 텍스트 일치, 말뭉치 기반(말뭉치는 언어 분석에 사용되는 텍스트 문서의 집합을 가리킵니다), 및 그래프 구조입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n문자열 거리는 길이 거리, 분포 거리 및 의미적 거리로 나뉠 수 있습니다.\n\n우리는 위 그림에서 볼드 처리된 주제들에 대해서만 다룰 것입니다. 가장 쉬운 방법부터 가장 복잡한 방법까지 시작하겠습니다.\n\n## 문자열 기반 텍스트 표현\n\n### 자카드 유사도\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자카드 유사도, 또는 교집합 오버 유니온이라고도 알려지고, 두 개의 텍스트의 유사성을 측정하는 방법으로, 공통 단어의 개수를 전체 단어 수로 나눈 비율로 표현됩니다.\n\n다음과 같은 수식으로 설명됩니다:\n\n앞서 언급한 두 문장을 고려해 봅시다:\n\n- A: 병은 비어 있습니다\n- B: 병 안에는 아무것도 없습니다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_2.png)\n\n자카드 유사도에 따르면, 문장 A와 B는 달리 의미를 가지고 있습니다. 이는 단순히 문장을 리터럴 레벨에서 비교하기 때문입니다.\n\n자카드 유사도는 쉽게 계산할 수 있지만 의미적 관계를 포착하지 못하므로, 텍스트에서 사용된 단어를 비교하는 것이 필수적이지 않은 이상 권장되지 않습니다.\n\n자카드 유사도에 따르면, 문장 A와 B는 달리 의미를 가지고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n표 태그를 Markdown 형식으로 변경하겠습니다.\n\n# Corpus based text representation\n\n앞서 언급한 대로, 단어가 숫자로 표현되는 방식은 유사성을 평가하는 데 중요합니다. 이제 텍스트 표현을 위한 다양한 기술을 탐색해보겠습니다.\n\n## Bag of words\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBag of words 기반 기술은 단어의 순서와 관계없이 문서를 단어들의 조합으로 나타냅니다. 이 가족 중에서 가장 간단한 방법은 원핫 인코딩입니다.\n\n원핫 인코딩에 따르면 고유 단어의 총 수만큼의 크기를 가진 벡터가 생성됩니다. 각 단어의 값은 해당하는 인덱스에 1이 할당되고 나머지는 0입니다.\n\n이는 말뭉치의 다양성이 적고 데이터 간 의미 및 통계적 관계를 나타내는 필요가 없는 상황에서 일반적으로 사용됩니다. 큰 문서의 경우, 방대하고 희소한 벡터로 이어질 수 있습니다.\n\n조금 더 세련된 방법은 TF-IDF (단어 빈도-역문서 빈도)입니다. 이는 빈도가 높은 단어는 중요성이나 의미가 적다는 아이디어에 기반합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수학적으로 말하면:\n\nTF = 문서에 단어가 나타나는 횟수 / 문서 내 전체 단어 수\n\nIDF = log(N/n)\n\n여기서 N은 전체 문서 수이고, n은 대상 용어가 나타나는 문서 수입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n0s를 제거하려면 모든 문서에 단어가 있는 경우 TF\\*IDF 곱에 1을 더하므로, 벡터의 0은 단어의 부재를 나타냅니다.\n\n예제를 통해 이해해 봅시다. 다음과 같은 문장들을 고려해 보겠습니다:\n\n- He is Walter\n- He is William\n- He isn’t Peter or September\n\nTF 벡터는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- [0.33, 0.33, 0.33]\n- [0.33, 0.33, 0.33]\n- [0.20, 0.20, 0.20, 0.20, 0.20]\n\n이제 IDF 점수를 계산해 봅시다.\n\n- \"He\": Log(3/3) = 0,\n- \"is\": Log(3/2) = 0.1761,\n- \"or, Peter, ..\": Log(3/1) = 0.4771 ..\n\n결과 벡터는:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- [1. , 1.1761 , 1.4771 , 0. , 0. , 0. , 0. , 0.],\n- [1. , 1.1761 , 0. , 1.4771 , 0. , 0. , 0. , 0.],\n- [1. , 0. , 0. , 0. , 1.4771 , 1.4771, 1.4771 , 1.4771]\n\n이 방법은 통계적 관계를 가치화하지만 의미론적 관계를 대변하지 않고, 긴 문서에 적합하지 않습니다. 이는 고차원 벡터로 이어집니다.\n\n일반적으로, 대부분의 단어 가방 접근 방식은 의미론적 관계를 중요시하지 않고, 큰 문서에 대해 데이터 희소성으로 이어질 수 있습니다. 따라서, 텍스트 표현에 대한 복잡한 기술인 단어 임베딩 중 하나로 분류될 수 있는 더 복잡한 기술에 대해 심층적으로 살펴보겠습니다.\n\n## 창 기반 방법\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 방법은 통계적 관계를 중요시하지만 의미론적 관계를 나타내지는 않고, 긴 문서에는 적합하지 않습니다. 따라서 고차원 벡터로 이어질 수 있습니다.\n\n일반적으로 단어 가방 접근 방식 중 대부분은 의미적 관계를 중요시하지 않을 수 있고, 대규모 문서의 데이터 희소성으로 이어질 수 있습니다. 그러니 텍스트 표현에 대해 더 복잡한 기법으로 다양한 단어 표현 기술 중 하나로 분류될 수 있는 기법을 자세히 살펴보도록 하겠습니다.\n\n## Word2Vec\n\nW2V는 미리 훈련된 두 개의 레이어로 이루어진 신경망입니다. W2V 방식은 기계 학습에서 흔히 사용되는 속임수를 사용합니다: 단일 숨겨진 레이어를 가진 신경망이 특정 작업을 수행하도록 훈련되지만 최종 작업에 사용되지는 않습니다. 실제로 목표는 숨겨진 레이어의 가중치를 학습하는 것뿐입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nW2V는 두 가지 사전 훈련 모델을 가지고 있어요: 연속 단어 주머니 (Continuous Bag Of Words, CBOW)와 스킵-그램.\n\n![이미지](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_3.png)\n\n사진에서 볼 수 있듯이, CBOW에서는 대상 단어에 인접한 단어가 입력으로 주어지고 대상 단어를 예측하는 작업을 하며, 스킵-그램에서는 대상 단어가 입력으로 주어지고 이웃하는 단어들을 출력으로 예측해야 합니다. 이웃 단어로 고려할 단어 수를 \"윈도우 크기\"라고 하며, 이는 알고리즘의 매개변수입니다 (윈도우 크기의 일반적인 값은 5일 수 있어요).\n\n임베딩이 어떻게 생성되는지 이해하기 위해, 스킵-그램에 집중해봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n훈련 작업의 첫 번째 단계는 문서에 있는 단어들을 인코딩하는 것인데, 일반적으로 이는 원핫인코딩 방식으로 수행됩니다.\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_4.png)\n\n출력은 코퍼스에 있는 단어 수와 동일한 길이의 단일 벡터이며, 각 요소는 입력 단어의 이웃 단어가 될 가능성을 나타냅니다.\n\n만약 두 단어가 매우 유사한 문맥을 가진다면, 주변에 같은 단어들이 있을 가능성이 높다는 것을 의미하며, 모델은 이러한 단어들에 대해 유사한 결과를 생성하여야 합니다. 네트워크가 이를 달성하는 방법 중 하나는 단어 벡터가 유사하도록 하는 것입니다. 그러므로 두 단어가 유사한 문맥을 보여줄 때, 네트워크는 이러한 단어들에 대해 유사한 단어 벡터를 모으도록 자극을 받게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 종류의 네트워크를 비교해 보면, CBOW는 문법적 관계 학습에 뛰어나지만 Skip-gram은 의미적 관계를 파악하는 데 좀 더 우수합니다. 예를 들어, CBOW는 복수형과 같이 형태적으로 유사한 단어에 초점을 맞추지만 Skip-gram은 형태적으로 다른데 의미적으로 관련 있는 단어를 고려합니다. 게다가, Skip-gram은 빈번한 단어의 과적합에 덜 민감하며, 단어 하나만을 입력으로 사용하기 때문에 최적의 성능을 위한 문서 요구 사항 측면에서 더 효율적입니다.\n\nW2V 임베딩은 Spacy나 Genism에서 구현됩니다.\n\n이 접근법은 고차원 문제를 해결하고 의미론적 및 문법적 관계를 고려하지만, 단어의 맥락을 고려하지 않는 한계가 있어서 다의성의 경우 성능이 떨어질 수 있습니다. 예를 들어, \"current\"라는 단어는 다음 두 문장에서 각각 다른 의미를 가집니다:\n\n- 현재 사안 프로그램입니다.\n- 시내는 다리 아래로 빨리 흐릅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nW2V 방법에 따르면 세계의 현재 상태는 하나의 표현만을 갖게 될 것입니다.\n\n맥락 모델은 해당 문서의 모든 단어의 순서를 고려하여 대상 단어를 포함하는데 사용됩니다.\n\n자연어 처리 세계에서 가장 중요한 알고리즘 중 하나를 탐색해봅시다: BERT.\n\n## BERT\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n알고리즘에 대한 간결한 개요를 제공하겠습니다. 아키텍처 및 훈련의 중요 측면을 강조하여 문맥적 임베딩의 성취를 이해하는 데 필요한 것을 설명하겠습니다. BERT를 보다 자세히 탐구하려면 이 글의 마지막에 링크된 추가 자료를 참고하시기를 권합니다.\n\nBERT는 Bidirectional Encoder Representation from Transformers의 약자입니다. 이름에서 알 수 있듯이 BERT 아키텍처는 transformers를 기반으로 하며 실제로 양방향 언어 transformers를 사용하여 언어 표현을 합니다.\n\nBERT는 두 가지 다른 작업을 위해 사전 훈련되었습니다: Masked Language Modelling (MLM) 및 Next Sentence Prediction (NSP).\n\n첫 번째 작업인 MLM부터 시작해 보겠습니다. 말뭉치에 있는 단어 중 15%가 \"마스킹\"되었다고 가정됩니다. 이들 중에서:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 단어의 80%가 가리킨 토큰 [MASK]로 대체됩니다.\n- 10%는 무작위 단어로 대체됩니다.\n- 10%는 바뀌지 않은 채로 남겨집니다.\n\n해당 작업은 마스킹된 단어를 예측하는 것입니다. 특히 각 토큰을 마스킹하는 방식은 모형에 매우 중요합니다:\n\n- 단어를 토큰 [MASK]로 대체하면 일반 토큰을 제공하는 대신 주변 텍스트에서만 토큰을 추론할 수 있도록 합니다.\n- 샘플링된 단어를 텍스트 내에서 무작위 단어로 대체하고 예측을 강화하면 모형이 잘못된 토큰에 대응하는 강건함을 향상시킵니다. 모형은 예상치 못한 또는 맥락을 벗어난 단어를 효과적으로 다룰 수 있도록 합니다.\n- 샘플링된 단어를 바꾸지 않고 예측하면 모형이 텍스트의 원래 의미론적 및 구문 구조를 유지합니다. 모형은 잘못된 맥락에 대처하는 강건함을 향상시킵니다.\n\n이 세 가지 마스킹 단어 방식의 결합은 모형을 다양한 NLP 작업에서 강건하고 다재다능하게 만들어줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 번째 과제인 NSP는 문장 간의 관계를 학습하는 데 초점을 맞춥니다: 코퍼스 내 문장 쌍의 50%에 대해 두 번째 문장이 실제로 다음 문장인 경우가 있고, 나머지 쌍에 대해서는 두 번째 문장이 무작위로 선택된 문장입니다. 첫 번째 경우는 \"isNext\"로 레이블이 지정되고, 두 번째 경우는 \"NotNext\"로 레이블이 지정됩니다. 이 과제는 올바른 레이블을 예측하도록 하는 것으로, BERT가 문장 간 관계(예: 질문과 답변)를 학습할 수 있게 합니다.\n\nBERT 모델의 훈련 과정에서 Masked Language Model(MLM) 및 Next Sentence Prediction(NSP) 구성 요소는 함께 훈련되어, 이 두 전략에서 발생하는 결합 손실 함수를 최소화하도록 하고 올바른 레이블을 예측합니다.\n\nBERT의 강점은 이러한 작업을 수행하기 위해 입력 모델을 어떻게 모델링하는지에 있습니다.\n\n각 입력 임베딩은 3가지 임베딩의 조합으로 이루어져 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 위치 임베딩: 문장 내 단어의 위치를 표현하는 데 사용되는 임베딩입니다. 이러한 요소들은 Transformer의 제약을 해결하기 위해 도입되었는데, 순환 신경망과 달리 순차적 정보를 포착하는 능력이 없는 Transformer의 한계를 극복하기 위해 도입되었습니다.\n- 세그먼트 임베딩: 문장 쌍을 식별하는 임베딩입니다. BERT는 모델이 두 문장을 구분할 수 있도록 첫 번째 문장과 두 번째 문장에 대해 고유한 임베딩을 학습합니다. 아래 그림에서 EA로 표시된 모든 토큰은 문장 A에 속하며, EB도 비슷하게 문장 B에 속합니다.\n- 토큰 임베딩: 첫 번째 문장의 시작 부분에 [CLS] 토큰이 삽입되고, 각 문장의 끝 부분에는 [SEP] 토큰이 삽입됩니다.\n\n위 3가지 임베딩을 합산하여 각 입력을 얻습니다.\n\n\u003cimg src=\"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_5.png\" /\u003e\n\n미리 학습된 후, 모델은 특정 말뭉치에서 세밀하게 튜닝될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사전 훈련된 BERT의 버전은 분류(감성 분석), 질의응답, Named Entity Recognition과 같은 특정 작업에 사용할 수 있습니다. 그러나 저희는 임베딩 기법 중 한 가지로 이 알고리즘을 언급했기 때문에, 어떻게 이를 이용하는지 간단히 설명하겠습니다. 이 응용 프로그램의 아이디어는 W2V에 언급된 것과 유사합니다. 사실, 우리는 사전 훈련된 목적으로 그 모델을 사용하지 않습니다. BERT 베이스 모델은 12개의 트랜스포머 인코더 레이어를 사용하며, 각 레이어에서 각 토큰의 출력을 단어 임베딩으로 사용할 수 있습니다. 경험적인 연구를 바탕으로, 저자들은 매우 효과적인 접근 방식은 마지막 4개 레이어의 출력을 합하는 것임을 결정했습니다. BERT를 사용한 임베딩은 Hugging Face의 오픈 소스 라이브러리를 사용하여 Python에서 쉽게 구현할 수 있습니다. 이 라이브러리는 BERT를 PyTorch 또는 TensorFlow에서 사용할 수 있도록 제공합니다.\n\n# 거리 측정 방법\n\n지금까지 우리의 탐구는 텍스트 유사도를 측정하는 한 가지 방법(자카드 유사도)과 텍스트를 벡터로 변환하는 여러 기술에만 집중해 왔습니다. 소개에서 언급했듯이, 단어를 벡터로 변환하는 것은 유사도를 평가하기 위한 예비 단계에 불과하며, 거리 측정 방법의 계산이 필요합니다. 다음 섹션에서는 이러한 거리 측정 방법에 대해 포괄적으로 검토할 것입니다.\n\n## 길이 거리 측정 방법\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n길이 거리 측정 방법에 따르면, 거리는 텍스트의 수치적 특성을 이용하여 측정됩니다. 그 중 가장 인기 있는 측정 방법은 확실히 유클리드 거리입니다.\n\n유클리드 거리\n\n유클리드 거리는 두 점 사이의 거리를 계산하기 위해 피타고라스의 정리를 사용합니다.\n\n길이가 n인 두 벡터를 고려해 보면, 유클리드 거리는 다음 공식으로 설명됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 이미지에서 확인할 수 있습니다:\n\n![이미지1](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_6.png)\n\n두 벡터 간의 거리 d가 클수록 유사도 점수가 낮아지고 그 반대도 마찬가지입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n유클리드 거리에는 몇 가지 제한이 있습니다. 먼저, 비교할 대상이 없다면 이해하기 어려운 값이 계산됩니다. 이 문제를 해결하기 위해 거리를 정규화할 수 있지만, 가장 잘 알려진 공식\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_8.png)\n\n은 이상치의 영향을 매우 민감하게 받습니다.\n\n둘째, 유클리드 거리는 텍스트의 크기에 강하게 영향을 받기 때문에 희소 벡터(예: 원핫 인코딩으로 생성된 벡터)와는 잘 작동하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n코사인 유사도\n\n코사인 유사도는 두 벡터의 유사성을 측정하는 것으로, 벡터 사이의 각도의 코사인을 측정합니다. 두 점 사이의 거리를 측정하는 대신 두 벡터가 같은 방향으로 향하는지 확인합니다. 따라서 이는 벡터의 크기에 영향을 받지 않습니다.\n\n코사인 유사도는 다음과 같은 공식을 통해 계산됩니다:\n\n```js\n\\[ \\text{cosine similarity} = \\frac{{\\textbf{A} \\cdot \\textbf{B}}}{{\\lVert \\textbf{A} \\rVert \\times \\lVert \\textbf{B} \\rVert}} \\]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_10.png\" /\u003e\n\n벡터의 영향을 받아 이러한 지표를 비교하는 것에 대한 의미를 더 잘 이해해 봅시다.\n\n두 개의 논문을 비교해보자고 가정해보겠습니다. 한 쪽은 정치와 관련된 것이고, 다른 한 쪽은 스포츠와 관련된 것이라고 가정해보겠습니다. \"야구\"라는 단어가 논문 1에 논문 2보다 더 많이 나오는 경우, 유클리드 거리에 따르면, 논문 1이 스포츠와 관련이 더 있습니다. 그러나 논문 1이 그냥 논문 2보다 더 길었을 수도 있습니다. 결과적으로 논문 2가 논문 1보다 스포츠와 더 관련된 경우도 있을 수 있습니다.\n\n대부분의 텍스트 유사성 사용 사례들은 길이에 민감하지 않습니다. 따라서 일반적으로 코사인 유사도가 유클리드 거리보다 선호됩니다. 유클리드 거리가 선호될 수 있는 사용 사례는 길이에 민감한 표절 탐지입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 의미적 거리\n\n텍스트 간에 공통된 단어가 많지 않은 상황에서는, 길이나 분포에 의존하는 거리 측정으로 유도된 유사성은 비교적 낮게 나타날 수 있습니다. 이러한 경우 의미적 거리 계산을 선택하는 것이 좋습니다.\n\n이를 위한 주요 방법은 Word Mover's Distance로, 이는 텍스트 간의 의미적 근접성을 결정하는 데 도움을 줍니다.\n\nWord mover's distance\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n단어 이동 거리는 두 텍스트 문서 간에 유사성을 정의하는데, 한 문서의 임베드된 단어가 다른 문서의 임베드된 단어에 도달하기 위해 이동해야 하는 최소 거리를 나타냅니다. 따라서 유사성의 측정은 운송 문제가 됩니다: 텍스트1을 텍스트2로 운송하는 비용을 최소화합니다.\n\n단어 이동 거리는 확률 분포 간 유사성을 측정하는 최적화 문제인 Earth Mover's Distance에서 비롯되었습니다. 이는 한 분포를 다른 분포로 변환하는 비용을 고려하여 유사성을 측정합니다.\n\nWMD를 계산하기 위한 첫 번째 단계는 정규화된 Bag of Words로의 단어 임베딩입니다. 둘째, 유클리드 거리가 계산되고 마지막으로 최적화 문제가 계산됩니다. 최적화 문제의 목적 함수는 한 문서에서 다른 문서로 이동하는 데 필요한 거리를 최소화하는 것이며, \"질량\"의 총량이 보존되어야 한다는 제약조건이 따릅니다. 다시 말해, 제약 조건은 두 문서의 전체 내용이 고려되고 한 단어에서 다른 단어로 이동하는 과정에서 어떤 단어도 중복되거나 손실되지 않도록 보장합니다.\n\n긴 문서에 대해 특히 계산 비용이 많이 드는 WMD는 모든 단어의 존재 여부를 사용하는 방법으로, 순서에 상관없이 문법적인 변경사항에 강하지 않습니다. 그러나 단어의 유사성을 임베딩 공간에서 고려하기 때문에 공통 단어가 거의 없는 문서에 대해서는 매우 효과적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n![이미지](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_11.png)\n\n의미론적 유사성을 측정하는 것은 자연어 처리 세계에서 가장 복잡한 도전 중 하나입니다. 텍스트 유사성 측정의 공간을 탐험하면 각각 독특한 장단점이 있는 다양한 방법을 발견할 수 있습니다.\n\n문자열 기반 방법은 간단하고 구현하기 쉽지만 의미 관계를 다루지 않습니다. 그에 반해 말뭉치 기반 방법은 더 복잡하지만 의미적이고 통계적인 관계를 중요시하며 여러 언어에 대해 다재다능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n거리 측정에 관한 것은 일부가 길이에 민감하고, 다른 일부는 분포에 의존하거나 의미에 중점을 둡니다. 이러한 측정 방법과 텍스트 표현의 조합은 무한합니다.\n\n계속 발전하는 이 환경에서 완벽한 모델을 찾는 노력이 계속되는 중에도, 하나의 진리는 명확히 남아 있습니다: 최적의 방법을 선택하는 것은 각 사용 사례의 고유한 요구 사항과 깊은 관련이 있습니다. 우리가 앞으로 나아가면서, 표현학습과 거리 계산 사이의 시너지는 계속 발전하는 텍스트 벡터의 길을 열어주며, 의미 유사성에 대한 우리의 이해력에 새 시대를 열어줍니다.\n\n# 참고문헌\n\n[1] Qiu, Xipeng, 등. \"자연어 처리를 위한 사전 훈련된 모델: 설문.\" Science China Technological Sciences 63.10 (2020): 1872-1897.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Goldberg, Yoav, and Omer Levy. \"word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method.\" arXiv preprint arXiv:1402.3722 (2014).\n- Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint arXiv:1810.04805 (2018).\n- Wang, Jiapeng, and Yihong Dong. \"Measurement of text similarity: a survey.\" Information 11.9 (2020): 421.\n- Kusner, Matt, et al. \"From word embeddings to document distances.\" International conference on machine learning. PMLR, 2015.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[6] [Online]. Available: [Newscatcher API - Ultimate Guide to Text Similarity with Python](https://www.newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python).\n\n[7] McCormick, Chris. “Word2vec tutorial-the skip-gram model.” Apr-2016. [Online]. Available: [Word2vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model) (2016).\n","ogImage":{"url":"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png"},"coverImage":"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png","tag":["Tech"],"readingTime":22},{"title":"번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어","description":"","date":"2024-05-20 20:52","slug":"2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore","content":"\n안녕하세요! Bend에 대해 들어보셨나요?\n\n아직 안 들어보셨나요? 이 이야기를 읽고 있다면 아직 늦지 않으십니다.\n\n몇 시간 전에 Bend라는 GitHub 저장소를 발견했어요. 'Bend — 대규모 병렬 처리를 지원하는 고수준 프로그래밍 언어'라는 제목이 붙어 있었죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBend는 병렬 계산을 수행하는 방식을 영원히 변경하려는 고수준 프로그래밍 언어입니다.\n\n세계를 바꾼다고 약속한 언어가 많았다는 건 알고 있어요. 하지만 Bend는 실제로 그럴 수도 있어요!\n\nBend가 약속하는 좋은 부분을 알아보기 전에 병렬 계산에 대해 조금 배워볼까요?\n\n# 병렬 계산 - 최소의 시간으로 최대의 일을 하는 기술\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n컴퓨터 프로그램은 기본적으로 작업을 하나씩 차례대로 실행합니다.\n\n이는 프로세서 코어에 의해 한 번에 한 가지 명령을 실행하는 단일 스레드에 의존하기 때문입니다.\n\n이 간단한 방식은 순차 계산이라고 합니다.\n\n이로 인해 프로그램 내부의 명령 흐름이 예측 가능하고 디버깅하기 쉬워집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나, 이것은 또한 모든 명령어가 실행을 시작하기 전에 이전 명령어가 끝날 때까지 기다려야 한다는 것을 의미합니다.\n\n현대 컴퓨팅 시대에 있어서 대부분의 프로세서가 여러 코어로 구성되어 있기 때문에, 병렬 연산이라는 다른 접근 방식을 사용하여 지수적으로 빠르게 만들 수 있습니다.\n\n프로그램 내의 많은 명령어들이 여러 스레드를 사용하여 동시에 실행됨으로써 프로그램 전체의 실행 시간을 줄일 수 있습니다.\n\n# 하지만, 병렬 연산을 올바르게 수행하는 것은 어려울 수 있습니다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n병렬 계산을 다룬 적이 있는 분이라면, 그것을 올바르게 처리하는 것이 정말 악몽이라고 동의할 것입니다.\n\n동시에 공유 리소스에 접근하는 여러 스레드는 경합 상태를 유발해 완전히 예상치 못한 결과로 이어질 수 있습니다.\n\n또는, 좋지 않은 날이면 두 개 이상의 스레드가 서로가 차지한 리소스를 대기하고 끝없이 기다리는 데드락에 갇힐 수도 있습니다.\n\n이러한 문제는 Python 라이브러리인 threading과 multiprocessing이나 Go의 WaitGroup, Mutex, RWMutex와 같은 동기화 기본 요소를 이용한 Goroutines 등으로 해결되었지만, 이들의 구현은 숙련하기 어렵습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCUDA 및 Metal은 각각 NVIDIA 및 Apple GPU에서 병렬 계산을 활성화하는 몇 가지 다른 프로그래밍 모델입니다. 그러나 이를 다루는 대부분의 사람들은 (정직하다면) 그것을 완벽히 이해하는 데 얼마나 어려운 작업인지 말해 줄 것입니다.\n\n그럼에도 불구하고 남아 있는 의문은 —\n\n병렬 계산을 쉽게 할 수 있는 새로운 사람들에게 좋은 대안이 없는 걸까요?\n\n# Bend가 구해줄게요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n단순히 Python처럼 쉽게 느껴지도록 작성된 언어인 Bend는 아마도 우리를 이 비통으로부터 구출해 줄 수 있는 사랑스러운 언어일지도 모르겠어요.\n\n그 철학은 웃기게 간단합니다 —\n\nBend는 기본적으로 코드를 병렬로 실행하기 때문에, 다중 코어 CPU 또는 GPU와 작업하기 위해 CUDA를 배우는 데 수년을 보내야 할 필요가 없어요.\n\n## 하지만, Bend는 어떻게 이것이 가능하게 만드는 걸까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBend은 매우 병렬 실행을 위해 설계된 강력한 계산 프레임워크인 HVM2 또는 Higher-order Virtual Machine 2에 의해 구동됩니다.\n\nPython과 같은 고수준 언어로 작성된 프로그램을 HVM2로 컴파일하면 GPU에서 빠르게 실행할 수 있습니다!\n\nHVM2는 1997년 Yves Lafont가 고안한 병렬 컴퓨테이션 모델인 Interaction Combinators를 기반으로 하며, 그래프 기반 구조를 사용합니다.\n\n이 모델에서 각 계산은 그래프로 시각화됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 그래프들에서 각 노드는 조합자(Combinator)입니다.\n\n조합자는 이 모델의 기본 구성 요소로 작용하는 고차 함수입니다.\n\n각 조합자마다 다른 조합자와의 상호 작용 방식을 결정하는 간단한 규칙 세트가 있습니다. 예를 들어 —\n\n- Identity Combinator는 인수를 변경하지 않고 반환합니다.\n- Constant Combinator는 두 개의 인수를 사용하고 첫 번째 것을 반환합니다(두 번째 것을 무시), 등등.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래프에서 각 엣지는 이 결합자들 간의 연결을 나타냅니다.\n\n이러한 결합자들이 상호작용할 때(엣지에서 시사하는 대로), 그들은 각자의 규칙에 따라 변환되어 결과를 돌려줍니다.\n\n상호작용 결합자 모델에서 가장 훌륭한 부분은 이들의 그래프 구조가 프로그램 내의 다른 계산을 서로 다른 코어(즉, 병렬로)에서 처리할 수 있게 한다는 것입니다.\n\n그리고 이것이 이 모델을 강력하게 만드는 요소입니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nHVM2은 고수준 언어로 작성된 프로그램을 대상으로 하는 저수준 컴파일러이며 직접 사용하기 위한 것은 아닙니다.\n\n재귀 합을 구현하려면 다음과 같이 읽을 수 있습니다.\n\n```js\n@main = a\n  \u0026 @sum ~ (28 (0 a))\n\n@sum = (?(((a a) @sum__C0) b) b)\n\n@sum__C0 = ({c a} ({$([*2] $([+1] d)) $([*2] $([+0] b))} f))\n  \u0026! @sum ~ (a (b $(:[+] $(e f))))\n  \u0026! @sum ~ (c (d e))\n```\n\n하지만 걱정하지 마세요. Bend는 우리의 삶을 쉽게 만들기 위해 이 암호화된 HVM2와 인터페이스를 맺기 위해 작성된 사람이 읽을 수 있는 언어입니다. 함께 작업을 병렬로 처리할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Bend 사용 방법\n\nBend는 러스트 프로그래밍 언어로 작성되었으므로, 첫 번째 단계는 Rust nightly를 설치하고, 그 다음으로 HVM2와 Bend를 함께 설치하는 것입니다.\n\n```js\ncargo +nightly install hvm\ncargo +nightly install bend-lang\n```\n\n안타깝게도, 현재 Windows에서는 작동하지 않기 때문에 (나처럼) WSL2를 해결책으로 사용해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 Bend 코드를 작성합니다.\n\n```js\n# sorter.bend\n\n# Sorting Network = just rotate trees!\ndef sort(d, s, tree):\n  switch d:\n    case 0:\n      return tree\n    case _:\n      (x,y) = tree\n      lft   = sort(d-1, 0, x)\n      rgt   = sort(d-1, 1, y)\n      return rots(d, s, lft, rgt)\n\n# Rotates sub-trees (Blue/Green Box)\ndef rots(d, s, tree):\n  switch d:\n    case 0:\n      return tree\n    case _:\n      (x,y) = tree\n      return down(d, s, warp(d-1, s, x, y))\n\n# Swaps distant values (Red Box)\ndef warp(d, s, a, b):\n  switch d:\n    case 0:\n      return swap(s + (a \u003e b), a, b)\n    case _:\n      (a.a, a.b) = a\n      (b.a, b.b) = b\n      (A.a, A.b) = warp(d-1, s, a.a, b.a)\n      (B.a, B.b) = warp(d-1, s, a.b, b.b)\n      return ((A.a,B.a),(A.b,B.b))\n\n# Propagates downwards\ndef down(d,s,t):\n  switch d:\n    case 0:\n      return t\n    case _:\n      (t.a, t.b) = t\n      return (rots(d-1, s, t.a), rots(d-1, s, t.b))\n\n# Swaps a single pair\ndef swap(s, a, b):\n  switch s:\n    case 0:\n      return (a,b)\n    case _:\n      return (b,a)\n\n# Testing\n# -------\n\n# Generates a big tree\ndef gen(d, x):\n  switch d:\n    case 0:\n      return x\n    case _:\n      return (gen(d-1, x * 2 + 1), gen(d-1, x * 2))\n\n# Sums a big tree\ndef sum(d, t):\n  switch d:\n    case 0:\n      return t\n    case _:\n      (t.a, t.b) = t\n      return sum(d-1, t.a) + sum(d-1, t.b)\n\n# Sorts a big tree\ndef main:\n  return sum(18, sort(18, 0, gen(18, 0)))\n```\n\n이것은 공식 저장소에서 가져온 예시로, 병렬 정렬 알고리즘인 Bitonic Merge Sort를 구현한 것입니다.\n\n이 알고리즘은 병렬로 실행할 수 있는 분할 정복 방식을 사용하므로 Bend는 병렬로 실행할 것입니다 (Bend의 철학을 기억하시나요?)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로, 이 명령어를 사용하여 sorter.bend 프로그램을 실행합니다 —\n\n```js\nbend run sorter.bend # 러스트 해석기(순차 실행) 사용\nbend run-c sorter.bend # C 해석기(병렬 실행) 사용\nbend run-cu sorter.bend # CUDA 해석기(대규모 병렬 실행) 사용\n```\n\n마지막 명령어는 기기의 GPU를 자동으로 사용하며, 세부 사항을 자세히 다룰 필요가 없습니다.\n\n또한 최대 성능을 위해 Bend 파일을 독립적인 C/CUDA 파일로 컴파일할 수 있지만, 이러한 명령어는 아직 성숙하지 않을 수 있으며 오류를 발생시킬 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBend는 아직 초기 단계에 있지만 매우 유망해보입니다.\n\n다음 섹션의 자원들은 더 많이 배우고 개발에 참여하는 데 도움을 줄 것입니다. 한번 보세요!\n\n즐거운 병렬 처리!\n\n# 더 많이 알아보기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Bend의 GitHub 저장소\n- Bend를 처음부터 배우기\n- Higher-order Virtual Machine 2 (HVM2)의 GitHub 저장소\n- HVM 작동 방식 블로그 포스트\n- HVM 작동 방식 비디오 설명\n- Y. Lafont에 의한 상호 작용 결합 연구 논문\n- Blend의 모기업인 Higher Order Company 웹 사이트\n\n저의 작업과 계속 연락하고 싶다면 이메일 목록 링크를 확인하세요 —\n","ogImage":{"url":"/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png"},"coverImage":"/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png","tag":["Tech"],"readingTime":10},{"title":"용어 해설 AI 시스템 제어하기","description":"","date":"2024-05-20 20:51","slug":"2024-05-20-GlossaryControllingAISystems","content":"\n## 장난기 많은 해독자들\n\n![이미지](/assets/img/2024-05-20-GlossaryControllingAISystems_0.png)\n\n요즘 AI 제어 시스템에 대한 많은 이야기가 나오고 있는데, 그에 이어서 불가피하게 숨통을 헤친 것들이 많아지고 있어요(인터넷 덕분이죠). 공간을 명료하게 만드는 데 도움을 주기 위해 여러 용어를 수집하고, 각 용어에 대한 짧은 설명을 도출해내는 것을 최대한 노력했어요. 그리고 그것들을 그 구성 요소들로 분해해보려고 노력해봤어요:\n\n- 따뜻한 색상: 소프트웨어가 아닌 것\n- 차가운 색상: 소프트웨어\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n노랑: 교육\n주황: 연구\n빨강: 정책/규정\n\n청색: 제품 측면(제품 내부 기능)\n하늘색: 사용자 측면(사용자 능력 향상 도구)\n\n이 57개 항목 중에서 모두 전문가가 될 수 없으니, 약간 틀릴 수밖에 없습니다. 그렇게 많이는 아니지만요 — 사실 확인에 최선을 다하였습니다. 하지만 인간이기 때문에, 제가 미묘한 부분을 잘못 이해했을 경우에는 저에게 토마토를 던지지 말아주시고, 부드럽게 알려주시면 감사하겠습니다. 흥미가 있다면 알파벳으로 정렬된 목록도 아래 텍스트로 제공되었습니다.\n\n그러나 색깔로 구분한 것을 보면 뭔가 흥미로운 점을 알아채셨나요? 핵심 단어를 따라가보세요, 그것들이 관심, 노력 및 투자가 이루어지는 곳과 일치하는 것 같습니다. 그런 식으로 읽으면, 제품 측면이 아닌 인간 측면에 도구를 구축하는 노력이 충분하지 않은 것으로 보입니다. 기술적이지 않은 인간 의사 결정자 및 그들의 조직이 복잡한 기술의 방향을 조정하는 것을 개선할 수 있는 정도보다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n정말 아무것도 없이 순수한 마음만으로 복잡한 기술을 책임있게 다룰 수 있다고 믿는 건가요? 우리가 그런 능력을 갖추기 위해 긴급히 도구를 만들어야 하는 거 아닌가요?\n\n# 알파벳 순 글로시\n\n- AI 책임성 — AI 개발자와 사용자가 자신들의 시스템이 미치는 영향에 대해 책임을 지는 메커니즘을 수립하는 것. [소프트웨어(규칙/정책): 80%, 소프트웨어(연구): 20%]\n- AI 정렬 — 인간의 가치와 의도와 일치하는 AI 시스템의 목표와 행동을 개발하는 것. [소프트웨어(연구): 80%, 소프트웨어(제품): 20%]\n- AI 감사 — AI 시스템을 적합성, 안전성, 도덕적 고려 사항에 대해 평가하고 모니터링하는 것. [소프트웨어(규칙/정책): 70%, 소프트웨어(제품): 30%]\n- 증강지능 — 인간 능력을 대체하는 대신 AI를 통해 향상시키기. [소프트웨어(사용자): 60%, 소프트웨어(제품): 30%]\n- AI 벤치마킹 — AI 시스템을 비교하고 평가하기 위한 표준화된 측정 항목 및 테스트 수립. [소프트웨어(연구): 60%, 소프트웨어(규칙/정책): 40%]\n- AI 편향 완화 — AI 시스템의 편향을 식별하고 줄이는 기술과 방법으로 공정하고 공평한 결과를 보장. [소프트웨어(제품): 70%, 소프트웨어(연구): 30%]\n- AI 능력 구축 — 효율적으로 AI 시스템을 만들고 관리하기 위해 필요한 기술과 지식을 개발. [소프트웨어(교육): 70%, 소프트웨어(제품): 30%]\n- AI 인증 — AI 시스템의 안전성, 신뢰성 및 준수를 인증하기 위한 프로세스 및 표준 수립. [소프트웨어(규칙/정책): 60%, 소프트웨어(제품): 40%]\n- 인지 컴퓨팅 — 복잡한 문제 해결과 의사 결정에서 인간의 사고 과정을 시뮬레이션하는 데 AI 사용. [소프트웨어(제품): 70%, 소프트웨어(사용자): 30%]\n- AI 준수 — AI 시스템이 관련 법률, 규정 및 산업 표준을 준수하도록 보장. [소프트웨어(규칙/정책): 80%, 소프트웨어(제품): 20%]\n- AI 제어 시스템 — AI 시스템의 행동과 작업을 제어하기 위해 설계된 메커니즘. [소프트웨어(제품): 60%, 소프트웨어(연구): 40%]\n  ...\n\n[중략]\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 읽어 주셔서 감사합니다!\n\n저에게서 의사 결정 지능에 대해 배우고 싶으신가요? 무료 강좌 링크가 여기 있어요:\n","ogImage":{"url":"/assets/img/2024-05-20-GlossaryControllingAISystems_0.png"},"coverImage":"/assets/img/2024-05-20-GlossaryControllingAISystems_0.png","tag":["Tech"],"readingTime":3}],"page":"72","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"72"},"buildId":"T_Nz0g9U1yttYMSEma95P","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>