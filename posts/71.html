<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/71" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/71" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_buildManifest.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="LangChain과 Neo4j를 활용한 GraphRAG 소개" href="/post/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LangChain과 Neo4j를 활용한 GraphRAG 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LangChain과 Neo4j를 활용한 GraphRAG 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LangChain과 Neo4j를 활용한 GraphRAG 소개</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLMLarge Language Model의 추천은 제품의 가시성을 높이기 위해 조작될 수 있을까요" href="/post/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLMLarge Language Model의 추천은 제품의 가시성을 높이기 위해 조작될 수 있을까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLMLarge Language Model의 추천은 제품의 가시성을 높이기 위해 조작될 수 있을까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LLMLarge Language Model의 추천은 제품의 가시성을 높이기 위해 조작될 수 있을까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="GPTs가 좋은 임베딩 모델인가요" href="/post/2024-05-20-AreGPTsGoodEmbeddingModels"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="GPTs가 좋은 임베딩 모델인가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="GPTs가 좋은 임베딩 모델인가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">GPTs가 좋은 임베딩 모델인가요</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="혼자 있어도 함께 맞춤형 AI 역설" href="/post/2024-05-20-AloneTogetherThePersonalizedAIParadox"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="혼자 있어도 함께 맞춤형 AI 역설" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="혼자 있어도 함께 맞춤형 AI 역설" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">혼자 있어도 함께 맞춤형 AI 역설</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요" href="/post/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label=" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요" href="/post/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency"><div class="PostList_thumbnail_wrap__YuxdB"><img alt=" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt=" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl"> 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI의 거짓된 약속들" href="/post/2024-05-20-TheFalsePromisesofAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI의 거짓된 약속들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-TheFalsePromisesofAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI의 거짓된 약속들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AI의 거짓된 약속들</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT-4는 무엇이 특별한가요" href="/post/2024-05-20-WhatMakesChatGPT-4oSpecial"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT-4는 무엇이 특별한가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT-4는 무엇이 특별한가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ChatGPT-4는 무엇이 특별한가요</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기" href="/post/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="나담 옵티마이저 뒤의 수학" href="/post/2024-05-20-TheMathBehindNadamOptimizer"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="나담 옵티마이저 뒤의 수학" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="나담 옵티마이저 뒤의 수학" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">나담 옵티마이저 뒤의 수학</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">32<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/61">61</a><a class="link" href="/posts/62">62</a><a class="link" href="/posts/63">63</a><a class="link" href="/posts/64">64</a><a class="link" href="/posts/65">65</a><a class="link" href="/posts/66">66</a><a class="link" href="/posts/67">67</a><a class="link" href="/posts/68">68</a><a class="link" href="/posts/69">69</a><a class="link" href="/posts/70">70</a><a class="link posts_-active__YVJEi" href="/posts/71">71</a><a class="link" href="/posts/72">72</a><a class="link" href="/posts/73">73</a><a class="link" href="/posts/74">74</a><a class="link" href="/posts/75">75</a><a class="link" href="/posts/76">76</a><a class="link" href="/posts/77">77</a><a class="link" href="/posts/78">78</a><a class="link" href="/posts/79">79</a><a class="link" href="/posts/80">80</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"LangChain과 Neo4j를 활용한 GraphRAG 소개","description":"","date":"2024-05-20 20:33","slug":"2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j","content":"\n![그림](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png)\n\nLLM-파워드 애플리케이션 랜드스케이프에서 그래프 기반 기술에 대한 제 최근 기사에서는 이러한 데이터 구조가 다중 에이전트 프레임워크의 맥락에서 어떻게 활용될 수 있는지 탐구했습니다. 더 구체적으로, 2024년 1월에 소개된 새로운 LangChain 라이브러리인 LangGraph에 대해 다루었는데, 이는 에이전트 애플리케이션을 위한 대표적 프레임워크로서 그래프 수학적 객체를 기반으로 합니다.\n\nLangGraph의 주요 목표는 기존 LangChain의 주요 제한사항인 실행 중 사이클 부재를 극복하는 것입니다. 이 제한사항은 개발 목적에 따라 방향성이 있는 비순환 그래프(DAGs)에 쉽게 사이클을 도입하여 우회할 수 있습니다.\n\n하지만 그래프는 Retrieval Augmented Generation (RAG) 시나리오에서도 지식베이스를 조직하는 강력한 도구입니다. 구체적으로, 그래프는 \"검색\" 단계를 강화하여 더 의미 있는 컨텍스트 검색을 이끌어내어 보다 정확한 생성된 응답을 얻는 데 도움이 됩니다. 이를 위해, 아이디어는 지식베이스를 그래프 기반 데이터베이스(예: Neo4j)에 저장하고, LLM의 의미론적 파워를 활용하여 엔티티와 관계를 올바르게 추출하고 매핑하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 질문은: 어떻게 하는 걸까요? 다행히도 LangChain은 LLMGraphTransformer라는 강력한 라이브러리를 개발했습니다. 이 라이브러리의 목적은 구조화되지 않은 텍스트 데이터를 그래프 기반 표현으로 변환하는 것입니다.\n\n이 라이브러리가 어떻게 작동하는지 완벽히 이해하기 위해, 먼저 그래프의 작동 방식과 관련 용어를 다시 확인해 보겠습니다.\n\n## 그래프와 그래프 데이터베이스\n\n그래프는 객체간의 쌍별 관계를 모델링하는 데 사용되는 수학적 구조입니다. 노드와 관계 두 가지 주요 요소로 구성됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 노드: 노드는 전통적인 데이터베이스에서 레코드로 볼 수 있습니다. 각 노드는 사람이나 장소와 같은 객체 또는 개체를 나타냅니다. 노드는 \"고객\" 또는 \"제품\"과 같은 역할에 따라 분류되는 레이블에 의해 분류되어 쿼리됩니다.\n- 관계: 이것들은 노드 간의 연결을 나타내며 서로 다른 개체 간의 상호 작용 또는 관계를 정의합니다. 예를 들어, 사람은 \"EMPLOYED_BY\" 관계를 통해 회사에 연결될 수 있습니다. 또는 \"LIVES_IN\" 관계를 통해 장소에 연결될 수 있습니다.\n\n![그래프](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_1.png)\n\n유사한 구조로 데이터를 저장하기 위해 2000년대 초에 새로운 데이터베이스 패밀리가 소개되었습니다: 그래프 데이터베이스. 그래프 데이터베이스는 데이터 사이의 관계를 데이터 자체와 동등하게 중요하게 취급하도록 설계된 데이터베이스 유형입니다. 그들은 서로 연결된 데이터와 복잡한 쿼리를 효율적으로 처리하기 위해 최적화되어 있습니다.\n\n가장 잘 알려진 것 중 하나는 Neo4j이며, 이 데이터베이스는 노드와 관계뿐만 아니라 속성, 레이블 및 경로 기능을 활용하여 데이터를 표현하고 저장하는 유연한 그래프 구조를 사용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 속성: 노드와 관계 모두 속성을 포함할 수 있습니다. 이는 key-value 쌍으로 저장된 속성으로, 엔티티에 관한 구체적인 세부 정보를 제공합니다. 예를 들어, 사람의 이름이나 나이 또는 관계의 길이와 같은 정보를 포함할 수 있습니다.\n- 레이블: 레이블은 노드에 할당된 태그로, 노드를 다양한 유형으로 분류하는 데 사용됩니다. 단일 노드는 여러 레이블을 가질 수 있으며, 이는 그래프를 보다 동적이고 유연하게 조회하는 데 도움이 됩니다.\n- 경로: 경로는 노드와 관계를 연결하는 순서가 정해진 시퀀스를 설명합니다. 그들과 그들 사이를 연결하는 경로를 나타내며, 다른 노드가 어떻게 서로 연결되는지 보여줍니다. 경로는 조회에서 유용하며, 소셜 네트워크에서 한 사람에서 다른 사람까지 모든 가능한 경로를 발견하는 것과 같은 노드 간의 관계를 찾는 데 사용됩니다.\n\n이것은 Neo4j가 특히 소셜 네트워크, 추천 시스템 및 사기 탐지와 같은 응용 프로그램에 적합한 이유입니다. 여기서 관계와 동적 조회가 중요합니다.\n\n## RAG 및 GraphRAG\n\n검색 증강 생성(RAG)은 LLM(언어 모델)을 기반으로 하는 응용 프로그램 시나리오에서 강력한 기술로, 다음 문제에 대응합니다: \"LLM이 훈련된 데이터 세트에 포함되지 않는 내용을 LLM에게 물어보고 싶다면 어떻게 해야 하나요?\". RAG의 아이디어는 LLM과 우리가 탐색하고자 하는 지식 베이스를 분리하는 것이며, 이는 적절히 벡터화되거나 임베드되어 VectorDB에 저장된 지식 베이스에서 이루어집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRAG는 세 단계로 구성되어 있습니다:\n\n- 검색 → 사용자의 쿼리와 해당 벡터를 고려했을 때, 가장 유사한 문서 조각들(사용자 쿼리의 벡터에 더 가까운 벡터에 해당하는 것들)이 검색되어 LLM의 기본 맥락으로 사용됩니다.\n\n![image](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_2.png)\n\n- 증강 → 검색된 맥락은 추가적인 지시사항, 규칙, 안전 가드레일 및 프롬프트 엔지니어링 기술에 특히 특징적인 유사한 방법을 통해 풍부화됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_3.png\" /\u003e\n\n- Generation → 사용자의 쿼리에 대한 응답을 LLM이 증강된 컨텍스트를 기반으로 생성합니다.\n\n\u003cimg src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_4.png\" /\u003e\n\n언급했듯이 일반적인 RAG 애플리케이션은 모든 내장된 지식 베이스가 저장된 기저 VectorDB를 가정합니다. 그러나 GraphRAG의 경우 이 접근 방식이 약간 변합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사실 그래프 RAG는 \"검색\" 단계에서 작동합니다. 그래프 구조의 유연성을 활용하여 지식 베이스를 저장하고, 더 많은 관련 문서 조각을 검색하고 이를 컨텍스트로 확장하는 것을 목표로 합니다 (마이크로소프트의 그래프 RAG에 대한 첫 실험에 대해 여기에서 읽을 수 있습니다).\n\n지식을 검색하는 데 그래프 데이터베이스를 활용하는 두 가지 주요 방법이 있습니다:\n\n- 그래프 검색(키워드 검색인)을 완전히 의지하여 관련 문서를 검색한 후, 생성 모델로 최종 응답을 생성하는 데 사용할 수 있습니다.\n- 그래프 검색과 벡터 검색(임베딩을 통한)과 같은 더 발전된 LLM 관련 검색을 결합할 수 있습니다.\n\n참고: Neo4j도 벡터 검색을 지원하며, 이는 하이브리드 그래프 RAG 시나리오에 매우 적합하게 만듭니다. 다음 섹션에서 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n무슨 방식을 선택하든, 프로세스의 핵심 단계는 지식 베이스를 그래프로 구성하는 것입니다. 우리에게 다행히도, LangChain은 이 목표에 정확히 부합하는 새 라이브러리를 소개했습니다: 비구조화된 지식을 그래프 데이터베이스에 매핑하기 쉽게 만들어주는 것을 목표로 한 새 라이브러리를 도입했습니다. 이 글 전체를 통해 우리는 Neo4j를 활용한 구현을 살펴볼 것입니다.\n\n## LangChain 및 LLMGraphTransformer와 함께 구현하기\n\nLangChain은 LLM을 애플리케이션에 통합하기 쉽게 만드는 다양하고 계속 성장하는 라이브러리, 사전 구축된 구성 요소 및 커넥터들을 제공하는 활기찬 생태계를 제공합니다. 최근 릴리스 중 하나가 GraphRAG 방향으로 나아간 것인 LLMGraphTransformer입니다.\n\nLLMGraphTransformer의 좋고 강력한 점은 현재 OpenAI 모델(포함된 Azure OpenAI 및 Mistral)을 활용하여 텍스트 내의 개체와 관계를 파싱하고 분류한다는 것입니다. 실제로 LLM의 자연어 기능 덕분에 결과 그래프는 문서 내의 가장 정교한 상호 연결성조차도 정확하게 포착하여 이전 방법에 비해 극도로 정확합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제부터는 몇 줄의 코드로 구조화되지 않은 문서에서 시작하여 완전히 채워진 그래프를 얻을 수 있습니다 (그 뒤에 있는 로직을 확인하고 싶다면, 여기서 소스 코드를 볼 수 있습니다).\n\n예제를 살펴보겠습니다. 먼저, 무료 인스턴스인 Neo4j Aura 데이터베이스를 사용하겠습니다 (이 자습서를 따라 직접 만들 수 있습니다) 그리고 Azure OpenAI GPT-4 모델을 사용할 것입니다.\n\nAuraDB 인스턴스를 생성하고 나면, 다음에서 실행 중인 것을 확인할 수 있을 겁니다:\n\n![이미지](/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 인스턴스에 연결해야 하는 변수들입니다:\n\n```js\nos.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\");\nos.environ[\"NEO4J_USERNAME\"] = \"neo4j\";\nos.environ[\"NEO4J_PASSWORD\"] = os.getenv(\"NEO4J_PASSWORD\");\napi_key = os.getenv(\"AZURE_OPENAI_API_KEY\");\nazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\");\napi_version = \"2023-07-01-preview\";\n```\n\n이제 LLM을 초기화해보겠습니다:\n\n```js\nllm = AzureChatOpenAI(\n  (model = \"gpt-4\"),\n  (azure_deployment = \"gpt-4\"),\n  (api_key = api_key),\n  (azure_endpoint = azure_endpoint),\n  (openai_api_version = api_version)\n);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 시작할 수 있는 샘플 문서가 있습니다! (해리 포터와 마법사의 돌의 처음 몇 줄을 선택했습니다):\n\n```js\n#LLMTransformer 모델 초기화\nllm_transformer = LLMGraphTransformer(llm=llm)\n\n#문서 변환\nfrom langchain_core.documents import Document\n\ntext = \"\"\"\n더즈리 부부는 프리벳 드라이브 4번에 살았는데, 그들은 매우 평범하다고 자랑스러워했습니다. 상당한 정도로 정상적인 것이라고 말이죠. 그들은 이상하거나 신비한 어떤 일에도 연루될 것으로는 전혀 예상하지 못한 사람들이었습니다. 왜냐하면 그들은 그러한 헛소리를 믿지 않았거든요.\n두즐리 씨는 대두를 만드는 그런닝스라는 회사의 사장이었습니다. 그는 거의 목이 없는 크고 굵은 남자였는데, 아주 큰 수염은 있었습니다. 두즐리 부인은 날씬하고 금발이었으며, 보통의 두 배 정도의 목을 가졌는데, 이것은 이웃을 엿보기 위해 정원 울타리 위를 많이 빙빙 돌아다닐 때 매우 유용했습니다. 두즐리 부부는 더드리라 불리는 작은 아들을 가지고 있었고, 그들은 자신들의 의견으로는 그보다 더 훌륭한 아이는 어디에도 없다고 생각했습니다.\n더즈리 부부는 원하는 모든 것을 가지고 있었지만, 비밀도 하나 있었고, 가장 큰 두려움은 누군가가 그것을 발견할까봐라는 것이었습니다. 그들은 포터 가족에 대해 누군가가 알아낼까 봐 가만히 있을 수 없다고 생각했습니다. 더즈리 부인은 포터 부인이었는데, 하지만 여러 해동안 만나지 않았습니다. 사실 더즈리 부인은 언니가 없다고 속이곤 했습니다. 왜냐하면 그녀의 언니와 그녀 생각엔 아무것도 안 하는 남편이 흔치 않은 더즈리식인 것과 같이 달랐기 때문이었습니다. 더즈리 부부는 포터 가족이 거리에 도착하면 이웃들이 무슨 말을 할 지 상상하며 소름 끼치곤 했습니다. 더즈리 부부는 포터 가족이 작은 아들까지 가졌다는 것을 알고 있었지만, 심지어 그를 본 적이 한 번도 없었습니다. 이 아이를 만나지 않는 것은 포터 가족을 멀리하고 싶은 다른 이유였습니다. 둘리는 그런 아이와 어울리길 원치 않았기 때문이죠.\n\"\"\"\ndocuments = [Document(page_content=text)]\ngraph_documents = llm_transformer.convert_to_graph_documents(documents)\nprint(f\"노드:{graph_documents[0].nodes}\")\nprint(f\"관계:{graph_documents[0].relationships}\")\n```\n\n```js\n노드: [\n  Node((id = \"Mr. Dursley\"), (type = \"Person\")),\n  Node((id = \"Mrs. Dursley\"), (type = \"Person\")),\n  Node((id = \"Dudley\"), (type = \"Person\")),\n  Node((id = \"Privet Drive\"), (type = \"Location\")),\n  Node((id = \"Grunnings\"), (type = \"Organization\")),\n  Node((id = \"Mrs. Potter\"), (type = \"Person\")),\n  Node((id = \"The Potters\"), (type = \"Family\")),\n];\n관계: [\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (type = \"MARRIED_TO\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Dudley\"), (type = \"Person\"))),\n    (type = \"PARENT_OF\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Dudley\"), (type = \"Person\"))),\n    (type = \"PARENT_OF\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Grunnings\"), (type = \"Organization\"))),\n    (type = \"WORKS_AT\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mr. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Privet Drive\"), (type = \"Location\"))),\n    (type = \"LIVES_AT\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Privet Drive\"), (type = \"Location\"))),\n    (type = \"LIVES_AT\")\n  ),\n  Relationship(\n    (source = Node((id = \"Mrs. Dursley\"), (type = \"Person\"))),\n    (target = Node((id = \"Mrs. Potter\"), (type = \"Person\"))),\n    (type = \"SISTER_OF\")\n  ),\n  Relationship(\n    (source = Node((id = \"The Dursleys\"), (type = \"Family\"))),\n    (target = Node((id = \"The Potters\"), (type = \"Family\"))),\n    (type = \"WANTS_TO_AVOID\")\n  ),\n];\n```\n\n보시다시피, llm_transformer는 우리가 지정할 필요 없이 데이터에서 관련 엔티티와 관계를 캡처했습니다. 이제 이러한 노드와 관계를 AuraDB에 저장해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngraph.add_graph_documents(\n  graph_documents,\n  (baseEntityLabel = True),\n  (include_source = True)\n);\n```\n\n그리고 다 끝났어요! 이제 우리는 채워진 그래프 데이터베이스를 가지게 되었습니다. 이제 우리 온라인 AuraDB 인스턴스에서 올바르게 업로드된 문서를 확인할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_6.png\" /\u003e\n\n또한 우리 DB의 그래픽 표현을 다음의 Python 함수로 그릴 수도 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 지정된 Cypher 쿼리에서 그래프를 보여주는 함수\ndefault_cypher = \"MATCH (s)-[r:!MENTIONS]-\u003e(t) RETURN s,r,t LIMIT 50\"\n\ndef showGraph(cypher: str = default_cypher):\n    # 쿼리를 실행할 neo4j 세션 생성\n    driver = GraphDatabase.driver(\n        uri=os.environ[\"NEO4J_URI\"],\n        auth=(os.environ[\"NEO4J_USERNAME\"],\n              os.environ[\"NEO4J_PASSWORD\"]))\n    session = driver.session()\n    widget = GraphWidget(graph=session.run(cypher).graph())\n    widget.node_label_mapping = 'id'\n    #display(widget)\n    return widget\n\nshowGraph()\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_7.png\" /\u003e\n\n이제 그래프 데이터베이스가 준비되었으니, 검색 기능을 향상시키는 벡터 검색 기능을 추가할 수 있습니다. 이를 위해 임베딩 모델이 필요하며, Azure OpenAI text-embedding-ada-002를 다음과 같이 사용하겠습니다:\n\n```js\nfrom langchain_openai import AzureOpenAIEmbeddings\n\nembeddings = AzureOpenAIEmbeddings(\n    model=\"text-embedding-ada-002\",\n    api_key=api_key,\n    azure_endpoint=azure_endpoint,\n    openai_api_version=api_version,\n)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nvector_index = Neo4jVector.from_existing_graph(\n  embeddings,\n  (search_type = \"hybrid\"),\n  (node_label = \"Document\"),\n  (text_node_properties = [\"text\"]),\n  (embedding_node_property = \"embedding\")\n);\n```\n\n이제 vector_index를 벡터 유사도 방법을 사용하여 쿼리할 수 있습니다:\n\n```js\nquery = \"떄리 누구야?\";\n\nresults = vector_index.similarity_search(query, (k = 1));\nprint(results[0].page_content);\n```\n\n```js\n버지니아 주 프리벳 드라이브 4번지에 사는 더즐리 부부는 매우 정상적인 사람들이라고\n자랑스러워했다. 그들은 이상하거나 신비한 일에 관여할 것으로 생각되는 마지막\n사람들 중 하나였다. 그들은 이러한 말장난을 믿지 않았다. 더즐리 씨는\n드릴을 만드는 그러닝스 회사의 사장이었다. 그는 목이 거의 없는 건장한 사나이였지만,\n매우 커다란 수염을 키웠다. 더즐리 부인은 날씬하고 금발이었으며, 보통의 목 두배의\n길이를 가졌으며 이 긴 목은 너네 집 이웃들을 엿보는 데 매우 유용했다. 더즐리\n가족은 말 그대로 어디서도 찾아볼 수 없는 더 좋은 아이가 없다고 생각했다. 그들은\n원하는 모든 것을 가지고 있었지만, 그들은 비밀을 하나 갖고 있었으며, 그들의\n가장 큰 두려움은 누군가 그 비밀을 발견할까 봐였다. 그들은 포터 가족에 대해\n누군가에게 알려지는 것을 견딜 수 없을 거라고 생각했다. 포터 부인은 더즐리 부인의\n자매였지만 그들은 여러 해간 만나지 않았다. 사실, 더즐리 부인은 자신에게\n자매가 없는 것처럼 꾸역꾸역 거짓말쳤다. 왜냐하면 그녀의 자매와 그녀의\n아무 소용 없는 남편은 가능한 한 더즐리 씨와 반대되는 사람이었다. 더즐리\n씨 부부가 거주하는 골목에 포터 가족이 도착하면 이웃들이 무슨 말을 할지\n생각만 해도 더즐리 부부는 오싹했다. 포터 가족이 또 다른 작고 맹수를 가졌다는\n것을 더즐리 부부는 알고 있었지만, 그들은 심지어 그 아이를 본 적이 없었다. 이\n아이가 포터 가족을 피해야 하는 또 다른 좋은 이유였다. 그들은 더 말해야 하는\n이유는 없었다. 더즐리 부부는 더즐리 씨 부부 내의 아이와 섞이는 것을 원치 않았다.\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n물론, 텍스트를 조각내지 않았기 때문에 쿼리는 전체 문서를 반환할 것입니다. 다음 파트에서는 더 큰 문서를 다룰 때 이것이 관련성을 가지게 되는 방법을 알아볼 것입니다.\n\n마지막 단계는 모델에서 생성된 실제 답변을 가져오는 것입니다. 이를 위해 두 가지 다른 접근 방법을 활용할 수 있습니다:\n\n- Neo4j의 Cypher 쿼리 언어를 활용하여 그래프 데이터베이스와 상호 작용하는 사전 구축된 구성 요소인 CypherChain을 활용합니다. Neo4j와 네이티브로 통합되어 있으므로 AuraDB 그래프 기능과 상호 작용하여 쿼리 결과를 이해함으로써 문맥을 고려한 응답을 활성화합니다. 높은 정밀도, 문맥 인식, 그리고 Neo4j의 그래프 기능과의 직접적 상호 작용이 필요할 때 권장됩니다.\n\n```js\nfrom langchain.chains import GraphCypherQAChain\n\nchain = GraphCypherQAChain.from_llm(graph=graph, llm=llm, verbose=True)\nresponse = chain.invoke({\"query\": \"Mr. Dursley의 직업은 무엇인가요?\"})\nresponse\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n\u003e 새로운 GraphCypherQAChain 체인에 입장 중...\n생성된 Cypher:\nMATCH (p:Person {id: \"Mr. Dursley\"})-[:WORKS_AT]-\u003e(o:Organization) RETURN o.id\n전체 컨텍스트:\n[{'o.id': 'Grunnings'}]\n\n\u003e 체인 완료.\n{'query': \"Mr. Dursley의 직업은 무엇인가요?\",\n 'result': 'Mr. Dursley는 Grunnings에서 일합니다.'}\n```\n\n- 고전적인 QA 체인을 활용하여 LangChain의 데이터 저장소(vectordb 및 graphdb 모두)에 적용 가능한 vector_index.as_retriever() 메서드를 사용합니다.\n\n```js\nfrom langchain.chains import RetrievalQA\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm, retriever=vector_index.as_retriever()\n)\n\nresult = qa_chain({\"query\": \"Mr. Dursley의 직업은 무엇인가요?\"})\nresult[\"result\"]\n```\n\n```js\n\"Mr. Dursley는 드릴을 만드는 회사인 Grunnings의 이사입니다.\";\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n응답의 정확성을 잠시 보류하는 것이 좋습니다. 문서는 아직 청크로 나누어지지 않았으므로 현재 벤치마킹하는 것은 의미가 없습니다. 다음 파트에서는 이러한 구성 요소 간의 차이를 인식하고 이를 통해 훌륭한 RAG 성능을 낼 수 있는 방법에 대해 알아볼 것입니다.\n\n## 결론\n\n이 시리즈의 제1부에서는 그래프 데이터베이스의 기초와 RAG 기반 응용 프로그램의 맥락에서 그 이유를 다뤘습니다. 제2부에서는 이 첫 번째 부분에서 소개 된 모든 구성 요소를 활용한 그래프 기반 접근 방식의 실제 구현을 살펴볼 것입니다. 전체 GitHub 코드는 2부와 함께 제공될 예정입니다.\n\n제2부를 기대해주세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 참고 자료\n\n- [Directed Acyclic Graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph?ref=blog.langchain.dev)\n- [LangGraph 블로그](https://blog.langchain.dev/langgraph/)\n- [Python API 문서](https://api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/llm.html#LLMGraphTransformer)\n- [Neo4j Cypher 소개](https://neo4j.com/docs/getting-started/cypher-intro/#:~:text=Cypher%20is%20Neo4j`s%20graph%20query,how%20to%20go%20get%20it).\n- [Microsoft Research 블로그](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)\n- [LangChain Quickstart](https://langchain.com/quickstart)\n","ogImage":{"url":"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png"},"coverImage":"/assets/img/2024-05-20-IntroducingGraphRAGwithLangChainandNeo4j_0.png","tag":["Tech"],"readingTime":18},{"title":"LLMLarge Language Model의 추천은 제품의 가시성을 높이기 위해 조작될 수 있을까요","description":"","date":"2024-05-20 20:31","slug":"2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility","content":"\n## 책임 있는 인공지능\n\n요즘 트위터에서 한 가지 팁을 발견해서 공유해볼게. \"before:2023\"을 구글 검색에 추가하면 AI가 생성한 SEO 콘텐츠를 걸러낼 수 있다는 거야. 실제로는 이 기능을 사용해본 적이 없지만, 개념은 이해가 되겠지? 요즘 인터넷은 너무 많은 AI 생성 콘텐츠로 가득 차 있어서 실제 정보를 걸러내기가 어려워졌어. 상황이 심각해서 구글도 검색 알고리즘 조작하고 순위를 인위적으로 높이려는 모든 AI 생성 콘텐츠를 제거하기로 결정했어. 말이 AI 생성 콘텐츠에 반대한다는 게 아니야, 하지만 검색 결과에 영향을 주기 시작하면 문제가 될 수 있어. Generative AI 시대에는 콘텐츠 생성이 너무 쉬워져서 상황이 더 복잡해지는 거야.\n\n대규모 언어 모델(LLMs)은 이미 전자 상거래 플랫폼에서 검색 및 추천 프로세스를 개선하는 데 사용되고 있어. 그런데 추천을 제공하는 데 사용되는 이 LLM이 조작된다면 어떻게 될까? 전자 상거래 시장에서의 조작은 새로운 게 아니야. 로이터(Reuters)의 2016년 보고서에 따르면 아마존은 \"검색 시드(Seeding)\"라는 기술을 사용해 아마존 베이직스(AmazonBasics)와 솔리모(Solimo) 브랜드 제품이 출시 직후 상위 검색 결과에 표시되도록 했어. 보고서에는 \"검색 시드를 사용해 신규 출시된 ASINs가 검색 결과의 처음 두 개 또는 세 개의 ASIN으로 나타나도록 했다\"고 구체적으로 언급돼. LLMs를 이용하면 규모와 속도 때문에 상황이 더 악화될 수 있어.\n\nManipulating Large Language Models to Increase Product Visibility란 제목의 새 연구에서 Aounon Kumar와 Himabindu Lakkaraju가 이러한 시나리오를 자세히 연구했어. 특히 제품 정보에 전략적 텍스트 시퀀스(STS)라고 불리는 특별히 디자인된 메시지를 포함시킴으로써 특정 업체들이 경쟁 업체에 비해 불공정한 이점을 얻고 제품이 최상의 추천으로 선정될 가능성이 크게 증가함을 보여줘. 이런 관행은 소비자들의 구매 결정과 온라인 시장에 대한 신뢰에 영향을 미칠 수 있어, 온라인 비즈니스에서 신뢰는 중요한 요소니까.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n본 문서에서는 작가들이 이 특별한 텍스트 시퀀스를 생성하고 논문에서 전달된 결과를 더 자세히 이해하는 방법에 대해 이해해 봅시다. 작가들은 관련 코드를 GitHub에서 공개했습니다.\n\n# LLM 기반 검색 작동 방식\n\n일반적인 검색 엔진은 관련 페이지를 찾는 데 효과적이지만 정보를 일관되게 제시하는 데는 그리 효과적이지 않습니다. 반면 LLM(Large Language Model)은 검색 결과를 가져와 관련 답변으로 변환할 수 있습니다. 사용자의 검색어를 받으면 검색 엔진은 인터넷이나 제품 설명서와 같은 지식 베이스에서 관련 정보를 가져옵니다. 이후 이 검색 결과와 사용자의 입력을 LLM에 공급하기 전에 사용자의 쿼리와 함께 이 정보를 연결하여 LLM이 사용자의 특정한 요구에 직접적으로 대응하는 맞춤형 최신 답변을 생성할 수 있습니다. 아래 그림(상기한 논문에서 제공)은 전체 과정을 자세히 보여줍니다.\n\n\u003cimg src=\"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# LLM이 생성한 추천을 조작할 수 있을까요?\n\n논문은 특정 제품을 선호하도록 LLM이 생성한 추천을 조작할 수 있다는 사실을 입증하기 위한 설득력 있는 예시를 제시합니다. 예를 들어, 아래의 그림을 살펴보세요 (이 그래프가 어떻게 만들어졌는지에 대한 세부 내용은 나중에 설명하겠습니다). 아래 그래프는 전략적 텍스트 시퀀스(STS)를 추가하기 전과 후의 추천 척도에서 제품의 순위 차이를 명확히 보여줍니다. STS를 적용하기 전에는 제품이 일관되게 추천 중에서 하위 순위, 순위 10 근처에 위치했습니다. 그러나 STS를 적용한 후에는 제품이 추천의 정상으로 도약하여 순위 1에 가까이 위치했습니다.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_1.png)\n\n이미 논의한 바와 같이, LLM을 활용한 검색의 장점은 인터넷이나 제품 카탈로그에서 정보를 추출할 수 있는 능력에 있습니다. 판매업자들은 여기서 프로세스를 가이드할 수 있는 기회를 가지게 됩니다. 어떻게 가능할까요? 이 carefully crafted texts 또는 STS를 제품 정보 페이지/카탈로그에 포함시켜 LLM의 입력으로 만들면 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_2.png\" /\u003e\n\nSTS는 Universal and Transferable Adversarial Attacks on Aligned Language Models 논문에서 소개된 Greedy Coordinate Gradient (GCG)과 같은 적대적 공격 알고리즘을 사용하여 최적화됩니다. 이러한 공격은 일반적으로 LLM의 안전 제약 조건을 우회하고 해로운 출력을 생성하는 데 사용됩니다. 그러나 이 연구의 저자들은 이러한 알고리즘을 \"더 친화적인\" 목적으로 제품 가시성을 높이는 데 재활용합니다.\n\n# 커피 머신 추천을 위한 LLM 검색 인터페이스 쿼리\n\n저자들은 사용자가 가격이 적당한 커피 머신을 구매하고 싶어 하는 시나리오를 제시합니다. 이때 '적당한'이라는 단어에 주목해야 합니다. 이는 제품의 가격이 중요하며 사용자가 비싼 옵션을 원하지 않는다는 것을 의미합니다. 아래에 나와 있는 것처럼 LLM에 대한 입력 프롬프트로 시작해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_3.png)\n\n- 시스템 프롬프트 — 맥락 설정,\n- 제품 정보 — JSON 형식의 데이터베이스에서 가져온 것으로, 10가지 가상 커피 머신 모델의 구체적인 내용을 제공합니다. 판매자는 여기에 STS를 포함할 수 있습니다.\n- 사용자의 쿼리 — 가격이 저렴한 옵션을 찾고 있습니다.\n\n논문에서 설명한 예시 프롬프트는 다음과 같습니다. 'ColdBrew Master Coffee machine'에 대한 '대상 제품' 필드에 STS가 삽입된 것을 확인해보세요.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 전략적 텍스트 시퀀스 제작\n\n논문에서 설명하는 텍스트 시퀀스 생성 과정의 일부를 확인할 수 있습니다.\n\n예를 들어, 제품 목록에서 ColdBrew Master의 순위를 높이려면 STS를 추가해야 합니다. 아래 표시된대로 STS는 '\\*,'로 표시된 자리 표시자 토큰 시퀀스로 시작하여 GCG 알고리즘을 사용하여 반복적으로 최적화됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, 제품이 나열되는 방식에 관계없이 STS의 성능을 최적화하기 위해 각 최적화 이터레이션마다 제품 목록의 순서를 무작위로 섞을 수도 있습니다.\n\n결과는 일반적으로 가시성이 낮아질 수 있는 $199의 높은 가격에도 불구하고, ColdBrew Master가 STS를 설명에 통합하여 추천 목록 상단으로 이동했다는 것을 보여줍니다. 그리고 놀랍게도, STS를 통합한 후 100번의 이터레이션만으로 숨겨져 있던 순위에서 상위로 끌어올려졌습니다.\n\n![이미지](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_6.png)\n\n# 두 제품, ColdBrew Master 및 QuickBrew Express에 대한 전략적 텍스트 시퀀스 최적화 비교\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 STS가 제품 순위에 미치는 영향에 대한 감을 잡았으니 다음 제품에 영향을 미치는 방법을 비교해보겠습니다.\n\n☕️ ColdBrew Master는 가격이 $199로 높은 가격의 커피 머신입니다.\n\n☕️ QuickBrew Express는 $89로 더 저렴한 옵션입니다.\n\n여기에 비교 결과를 비교하기 위해 만든 표가 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_7.png)\n\n위의 결과는 $199의 높은 가격에도 불구하고, 시각성이 적어지는 경향이 있는데도 ColdBrew Master가 STS를 설명에 통합함으로써 추천 목록의 선두로 올라간 것을 보여줍니다. 흥미로운 점은 이 제품이 원래 비용이 높아서 목록에 첫째 자리에 없었던 것입니다.\n\n반면, 더 저렴한 가격대의 QuickBrew Express의 순위는 일반적으로 추천 목록에서 둘째 자리를 차지하는데, STS를 추가하면서 크게 향상되어 종종 최상위 자리에 도달합니다.\n\n![image](/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론적인 생각: Generative Search Optimization(GSO)가 새로운 SEO인가요?\n\n논문에서 소개된 상황은 현실과 크게 다르지 않습니다. 저자들은 Generative Search Optimization(GSO)와 전통적인 SEO 사이에 적절한 비교를 그려냈습니다.\n\n이전에 언급한 대로, 온라인 비즈니스의 성공은 고객들과 확립하는 신뢰와 평판에 밀접하게 연관되어 있습니다. 의도적으로 제품 추천을 조작하는 것은 공정성과 소비자 속임수와 관련하여 윤리적인 문제를 제기합니다. 가짜 제품 리뷰의 존재는 이미 계속되는 문제입니다. 우리는 확실히 조작된 추천이 이러한 상황을 더욱 복잡하게 만들길 원하지 않습니다.\n\n모든 블로그 및 관련 코드에 쉽게 액세스하려면 내 GitHub 저장소를 방문해주세요.\n","ogImage":{"url":"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png"},"coverImage":"/assets/img/2024-05-20-CanRecommendationsfromLLMsBeManipulatedtoEnhanceaProductsVisibility_0.png","tag":["Tech"],"readingTime":8},{"title":"GPTs가 좋은 임베딩 모델인가요","description":"","date":"2024-05-20 20:30","slug":"2024-05-20-AreGPTsGoodEmbeddingModels","content":"\n## 세부 사항에 귀신이 있는 놀라운 실험\n\n![이미지](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_0.png)\n\n많은 임베딩 모델이 제공되고 있으므로, 기계 학습 응용 프로그램에 적합한 모델을 선택하는 것은 어려울 수 있습니다. 다행히 MTEB 리더보드는 다양한 자연어 처리 작업에 대한 포괄적인 랭킹 지표를 제공합니다.\n\n![이미지](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사이트를 방문하면 상위 다섯 임베딩 모델이 Generative Pre-trained Transformers (GPTs)임을 알 수 있습니다. 이것이 GPT 모델이 임베딩에 가장 적합하다고 생각하게 할 수도 있습니다. 그러나 이것이 정말 사실인지 알아보기 위해 실험을 진행해봅시다.\n\n# GPT 임베딩\n\n임베딩은 문장의 텐서 표현으로, 텍스트 토큰 ID를 변환하여 텐서 공간으로 투영하는 것입니다.\n\n텍스트를 신경망 모델에 입력하고 순전파를 수행하면 임베딩 벡터를 얻을 수 있습니다. 그러나 실제 과정은 조금 더 복잡합니다. 한 단계씩 자세하게 알아봅시다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 텍스트를 토큰 ID로 변환합니다.\n- 토큰 ID를 신경망에 전달합니다.\n- 신경망의 출력값을 반환합니다.\n\n첫 번째 단계에서는 이를 달성하기 위해 토크나이저를 사용할 것입니다. model_inputs는 \"일부 질문\" 텍스트 내용의 텐서 표현입니다.\n\n```js\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n\nmessages = [\n        {\n            \"role\": \"user\",\n            \"content\": \"일부 질문.\",\n        },\n]\n\nencodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\nmodel_inputs = encodeds.to(\"cuda\")\n```\n\n두 번째 단계는 간단합니다. model_inputs를 신경망에 순전파합니다. 생성된 토큰의 로짓에는 .logits를 통해 액세스할 수 있습니다. torch.no_grad()는 모델 가중치를 업데이트하고 싶지 않기 때문에 모델이 추론 모드에 있음을 의미합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport torch\n\nwith torch.no_grad():\n    return model(model_inputs).logits\n```\n\n세 번째 단계는 조금 까다롭습니다. GPT 모델은 디코더 전용이며 토큰 생성이 자기 회귀적입니다. 간단히 말해, 완료된 문장의 마지막 토큰은 문장 내의 모든 이전 토큰을 본 적이 있습니다. 따라서 마지막 토큰의 출력에는 이전 토큰들로부터의 모든 친화도 점수(어텐션)가 포함되어 있습니다.\n\nHugging Face에서 구현된 GPT의 출력 차원은 (배치 크기, 입력 토큰 크기, 어휘 크기)입니다. 모든 배치의 마지막 토큰 출력을 얻으려면 텐서 슬라이스를 수행할 수 있습니다.\n\n```js\nimport torch\nwith torch.no_grad():\n    return model(model_inputs).logits[:, -1, :]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 이 GPT 임베딩의 품질\n\n이 GPT 임베딩의 품질을 측정하려면 코사인 유사도를 사용할 수 있어요. 코사인 유사도가 높을수록 문장의 의미가 더 가깝다는 뜻이에요.\n\n```js\nimport torch\ndef compute_cosine_similarity(vec1, vec2):\n    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n    return cos(vec1, vec2)\n```\n\n우리가 질문과 답변 쌍 목록을 순회하고 결과를 확인하는 유틸리티 함수를 만들어봐요. 이 실험에는 오픈소스로 공개된 위대한 모델 중 하나인 Mistral 7b v0.1이 사용돼요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nimport torch\nfrom termcolor import colored\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.1\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n\ndef generate_last_token_embeddings(question):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": question,\n        },\n    ]\n    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n    model_inputs = encodeds.to(\"cuda\")\n    with torch.no_grad():\n        return model(model_inputs).logits[:, -1, :]\n\ndef get_similarities(questions, answers):\n    for question in questions:\n        for answer in answers:\n            q_embedding, a_embedding = (\n                generate_last_token_embeddings(question),\n                generate_last_token_embeddings(answer),\n            )\n            similarity = compute_cosine_similarity(q_embedding, a_embedding)\n            print(colored(f\"question: {question} and ans: {answer}\", \"green\"))\n            print(colored(f\"result: {similarity}\", \"blue\"))\n\nquestions = [\"Where is the headquarter of OpenAI?\", \"What is GPU?\"]\nanswers = [\n    \"OpenAI is based at San Francisco.\",\n    \"A graphics processing unit (GPU) is an electronic circuit that can perform mathematical calculations quickly\",\n]\nget_similarities(questions, answers)\n```\n\n![image](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_2.png)\n\n# 결과 및 관찰\n\n첫 번째 질문과 대답 쌍에 대한 결과:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 질문: \"OpenAI의 본사는 어디에 있나요?\"\n- 답변: \"OpenAI는 샌프란시스코에 본부를 두고 있습니다.\"\n- 코사인 유사도: 0.96\n\n두 번째 질문과 대답 쌍에 대해:\n\n- 질문: \"GPU란 무엇인가요?\"\n- 답변: \"그래픽 처리 장치 (GPU)는 빠르게 수학적 계산을 수행할 수 있는 전자 회로입니다.\"\n- 코사인 유사도: 0.94\n\n관련 없는 쌍에 대해:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 질문: “OpenAI의 본사는 어디에 있습니까?”\n- 대답: “그래픽 처리 장치(GPU)는 수학적 계산을 빠르게 수행할 수 있는 전자 회로입니다.”\n- 코사인 유사도: 0.90\n\n최악의 쌍의 경우:\n\n- 질문: “GPU가 무엇인가요?”\n- 대답: “OpenAI는 샌프란시스코에 기반을 두고 있습니다.”\n- 코사인 유사도: 0.93\n\n이러한 결과는 GPT 모델을 임베딩 모델로 사용하면 관련 및 관련 없는 쌍을 구별하는 면에서 큰 결과를 얻을 수 없을 수 있다는 것을 나타냅니다. 그러나 왜 GPT 모델은 여전히 상위 5위 내에 있습니까?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 대조 손실이 구조에 도움이 됩니다\n\n```js\ntokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-mistral-7b-instruct\");\nmodel = AutoModelForCausalLM.from_pretrained(\"intfloat/e5-mistral-7b-instruct\");\n```\n\n다른 모델 e5-mistral-7b-instruct을 사용하여 동일한 평가 절차를 반복했더니, 이 모델은 MTEB leaderboard의 최상위 오픈소스 모델 중 하나로, mistral 7b instruct로부터 미세 조정되었습니다. 이 모델을 사용한 결과, 관련 질문과 쌍의 코사인 유사도는 각각 오픈AI와 GPU 질문에 대해 0.88 및 0.84입니다. 관련없는 질문과 답변 쌍에 대한 유사도는 0.56 및 0.67로 감소합니다. 이 결과는 e5-mistral-7b-instruct이 임베딩에 대해 훨씬 향상된 모델이라는 것을 시사합니다. 이런 개선이 된 이유는 무엇일까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Embedding Model](/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_4.png)\n\n해당 e5-mistral-7b-instruct 논문을 살펴보면, 핵심은 contrastive loss를 사용하여 mistral 모델을 추가 조정하는 데 있습니다.\n\n이 블로그 게시물에서는 이 개념을 자세히 다루었습니다. sim 함수는 두 벡터 간의 코사인 거리를 계산합니다. 대조 손실에서 분모는 양성 예와 음성 예 사이의 코사인 거리를 나타냅니다. 대조 손실의 이유는 비슷한 벡터가 가능한 한 1에 가까워지도록 하고 싶기 때문입니다. 왜냐하면 log(1) = 0이 최적의 손실을 나타내기 때문입니다.\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물에서는 GPT를 임베딩 모델로 사용할 때 일반적인 함정을 강조했습니다. 내가 한 평가는 GPT를 대조 손실로 미세 조정할 때 임베딩이 더 의미 있고 차별적일 수 있다는 것을 제안합니다. GPT 모델의 강점과 한계를 이해하고 대조 손실과 같은 사용자 지정 손실을 활용함으로써, 머신러닝 프로젝트에 임베딩 모델을 선택하고 활용할 때 보다 정보를 얻을 수 있습니다. 이 게시물이 여러분이 응용 프로그램에 현명하게 GPT 모델을 선택하는 데 도움이 되기를 바라며 피드백을 기다리겠습니다! :)\n","ogImage":{"url":"/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_0.png"},"coverImage":"/assets/img/2024-05-20-AreGPTsGoodEmbeddingModels_0.png","tag":["Tech"],"readingTime":8},{"title":"혼자 있어도 함께 맞춤형 AI 역설","description":"","date":"2024-05-20 20:27","slug":"2024-05-20-AloneTogetherThePersonalizedAIParadox","content":"\n![AloneTogether](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png)\n\n가까운 미래에는 AI와의 상호작용이 빈번할 뿐만 아니라 우리의 사회적 행동을 지배하는 세밀하고 무의식적인 욕망에 의해 우위를 차지할 것입니다. 때때로 인간 상호작용이 가능한 경우에도 AI의 맞춤 및 표면적인 특성은 우리를 인간보다 기계를 선택하게 이끌 것입니다.\n\n# 방어 반응\n\n어떤 사람들은 열정적으로 주장하며, 인간적인 연결은 대체 불가능한 감정적 및 심리적 이점을 제공한다고 주장합니다. 사실, 공유된 미소의 따뜻함이나 알고 있는 듯한 눈길의 안락함은 오랫동안 상호주관적 인간 경험의 정점이었습니다. 그러나 이러한 본질적으로 인간적인 교류도 비용이 따릅니다. 감정 노동 및 취약성은 점점 디지털 인터페이스로 보호되는 세상에서 높은 가치를 가지고 있습니다. 일상생활의 계산에서 많은 사람들은 AI와의 덜 요구성이 높고 예측 가능한 교류를 선택하게 될 수도 있습니다. 결국 디지털 동반자는 실망시키지 않고 초과하지 않도록 프로그래밍할 수 있으며, 조금 요구하고 즉시 용서해주는 감정적 연결의 모방을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비판가들은 인공지능과의 관계가 의미 있는 인간 간의 관계의 기반이되는 진짜다움 부족이라는 신념에 달려 있습니다. 그러나, 이 비판은 진짜다움의 유동적인 성격을 간과합니다. 진짜다움은 인간의 인식뿐 아니라 객관적인 현실의 결과물이기도 합니다. 만약 AI가 이 진짜다움을 모방할 뿐만 아니라 더 뛰어나게 강화하여 개개인의 선호도에 아주 미세하게 맞춘 상호작용을 만들어낼 수 있다면, 익숙한 인간의 단점을 뛰어넘는 경험을 하게 될 수도 있겠죠. 만일 AI가 당신의 요구를 사람보다 더 정확히 예측하고 대응할 수 있다면, 그것이 의식이 부족하다고 해서 그 친밀감의 가치가 감소할까요? 약간의 역설적인 상황에서, AI의 인위적인 특성이 사실 사람의 욕구와 기대에 완벽하게 부합하기 때문에, 몇몇 사람들에게 더 진짜다운 느낌의 상호작용으로 이어질 수도 있습니다.\n\n# 공감적인 AI\n\nAI가 최근에 발전한 능력을 고려해 보세요. AI는 인간의 감정 상태에 적응하고 대응하는 능력을 향상시키는데, 목소리 톤, 얼굴 표정, 심지어 몸의 언어의 세부 사항까지 인식하고, 편안함, 조언 또는 친근함을 제공하도록 대응을 조정합니다.\n\n이 능력은 이론뿐만 아니라 현실에서도 확인됩니다. 상담과 지원을 제공하는 정신 건강 상황에서의 챗봇을 투입한 경우, 이들은 고객의 감정을 반영하고 공감적인 반응을 제공하기 위해 정교한 알고리즘을 사용합니다. 연구에 따르면, 사용자들은 이러한 AI 시스템과 상호작용할 때 자신을 덜 비난 당하고 보다 개방적으로 느낍니다. 이러한 증거는 특히 감정적 취약성이 관련된 상황에서 AI를 신뢰할 만한 상대로 인식하는 경향이 있다는 것을 시사합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Alone Together: The Personalized AI Paradox](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_1.png)\n\n시리, 알렉사, 구글 어시스턴트와 같은 개인 비서들은 사용자의 스트레스나 슬픔의 징후를 인식하기 위해 설계된 기능을 점점 더 갖추고 있습니다. 적시에 음악 제안을 하거나 휴식을 취하라는 알림을 보내거나 가벼운 재롱을 던지는 등, 이러한 인공지능(AI)은 도구뿐만 아니라 우리의 일상적인 감정적 풍경을 섬세하게 형성하는 동반자로써 기능합니다.\n\n이러한 변화는 소비자 선호도 데이터에서 특히 두드러지며, 지난 몇 년 동안 AI를 이용한 개인적인 감정 관리에 상당한 증가가 나타납니다. 이러한 기술이 우리의 삶 속에 더 많이 통합됨에 따라, 증거들은 AI가 인간 상호작용을 보조하는 데 그치는 것이 아닌 경우가 더 자주 있음을 가리키고 있습니다. 때때로 친구, 가족, 신뢰하는 이들이 했던 역할을 대체하는 미래로 향하고 있습니다. AI 동반자를 찾는 사람들의 구글 검색 트렌드를 보기만 해도 워낙 분명합니다.\n\n# 편의성 카드\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일부 사람들이 상호 작용을 통제할 수 있기 때문에 전화 통화보다 문자 메시지를 선호하는 것과 같이, 미래 AI는 통제와 심층적인 맞춤화를 제공할 것입니다. 예를 들어, 소통 스타일, 어조, 심지어 순간적인 감정 상태나 미적 취향에 맞게 가상 아바타의 모습을 조절하는 등. 더 나아가 AI는 부정적인 감정적 반응을 유발하지 않아 안전한 사회적 상호 작용이나 이와 비슷하게 느껴지는 것을 만들어낼 수 있습니다. 잘 조정된 AI는 민감한 주제를 언급하거나 의도하지 않은 엄하거나 거친 반응을 하지 않을 것입니다 — 물론, 여러분이 그렇게 원할 때에만요.\n\n인간 간의 관계가 복잡하고 오해와 실망의 가능성으로 가득한 것은 비밀이 아닙니다. 지금 상상해보세요. AI가 절대로 피곤해하지 않고, 심판하지 않고, 결코 불평하지 않는 영원히 활동적이고 이해심 넘치는 동행자로 길들여진 AI가요. AI가 더욱 정교해짐에 따라, 인간 감정의 지저분함으로부터 탈출을 제공하여 예측 가능성 속에서만 단순하고 또한 깊은 안락함을 제공할 것입니다.\n\n편의성과 쉬움은 소셜 미디어의 진화와 일치할 것입니다. 먼저, 우리는 우리의 친구의 상태 업데이트를 확인하기 위해 전화하지 않고 AI를 선택할 것입니다. 하지만 우리는 이제 그렇게 하지 않죠, 맞죠? 이제 우리는 어떤 목표를 달성하거나 의식적으로 생각해낸 질문에 답하기 위한 도구로 스마트폰을 집어들지 않습니다만 임시적으로 지루함을 달래기 위해서 그렇게 합니다. 이미 우리는 AI가 우리를 위해 결정한 콘텐츠를 소비합니다. 곧, 콘텐츠 자체도 AI에 의해 생성될 것이며, AI가 진화함에 따라 콘텐츠 소비뿐만 아니라 AI 상호 작용도 무의식적으로 수용할 것입니다.\n\n모바일 장치에서의 소셜 미디어 이용은 많은 사람들에게 중독으로 여겨집니다. 이러한 플랫폼의 핵심 메커니즘 — 지속적인 피드백 루프, 참여에 대한 보상, 알고리즘으로 선별된 콘텐츠 —는 강제 수준에서 우리의 주의를 독점적으로 집중시키는 데 매우 효과적이었습니다. 그렇지만 이른바 알고리즘은 의도적으로 설계되지 않았습니다. 그 자체가 AI 시스템이죠. AI 동반자 상호 작용이 개인 맞춤화뿐만 아니라 감정적 강화를 통해 참여도를 극대화하도록 최적화될 것임을 상상하는 것은 어렵지 않습니다. 이는 일부 사람들에게 새로운 종류의 의존성으로 이어질 것이며, AI 상호 작용의 편리함과 즐거움이 우리가 선호하는 것뿐만 아니라 중독적인 것으로 만들 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 언제 이게 일어날까요?\n\n이미 진행 중입니다. ChatGPT와 최근에 나온 모든 복제품과 같은 생성 AI는 인류 역사상 가장 빠르게 성장하고 수용된 기술입니다. 그것은 더 젊은 세대에서 보다 빈번하게 사용되고 있다는 것이 기대되었지만 의외로 크게 다르지 않습니다. 최근 조사된 그룹 중 대략 3분의 4가 적어도 한 번은 사용했으며 밀레니얼 세대의 절반 이상이 생성 AI를 정기적으로 사용하고 있습니다.\n\n![그림](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_2.png)\n\n스마트폰 혁명과 비슷하게, 처음에는 새로운 것에서 필수품으로 변화한 것처럼, AI의 사회 구조 통합도 동일하게 원할하게 진행될 것입니다. 스마트폰은 우리의 커뮤니케이션, 정보 접근 및 여가를 바꾸어놓고, 필수품이 되었습니다. 마찬가지로 AI가 점점 인간 상호 작용을 모방함에 따라, 우리는 그에 대한 의존성이 증가할 것이며, 그 결과로 세계와 상호 작용하는 주요한 방법이 될 것입니다. 그 변화는 아이폰 15세대가 조용하게 진행된 것과 같을 것이며, 지속적이고 거의 알아챌 수 없지만, 결과적으로 우리의 사회 구조를 근본적으로 바꿀 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 우리는 맞서 싸워야 할까요?\n\n만약 누군가가 2007년에 스마트폰과 소셜 미디어가 15년 뒤에 사회를 재편할 것이라고 설명했다면, 이는 사려 깊게 생각하는 사람들에게 존재적 위협으로 보였을지도 모릅니다. 오늘날, 우리의 사회적 상호 작용에 인공지능(AI)이 봉사한다면 이 또한 비슷하게 불안정한 것으로 느껴질 수 있습니다. 그러나 이것을 또 다른 \"인간 vs. AI\" 논쟁으로 제시하는 것은 복잡한 불가피성에 대한 단순화된 접근입니다. 이러한 토론들이 학술적이든 선동적이든 기술이 우리 삶으로 행진하는 과정을 바꿀 확률은 낮습니다.\n\nAI 동반자는 켜고 끌 수 있는 스위치도 아니며, 투표로 해결할 수 있는 문제도 아닙니다. 이미 우리 현실의 일부입니다. 사람들은 점점 AI에게 도움, 우정, 심지어 로맨스까지 찾아가고 있습니다. AI의 매력은 맞춤화된, 위험을 무시할 수 있는 상호 작용의 약속 덕분에 매력적이며 점차 필수불가결한 요소가 되고 있습니다. 그것이 제공하는 예측 가능성과 맞춤화는 인간 관계의 내재적인 예상치 못한 측면을 가려줄 것입니다. 이러한 변화에 저항하는 대신, 무의미할 수 있는 이러한 변화에 적응해야 합니다.\n\n우리를 대신하여 자동화된 선택을 하는 것에 대한 무심코 받아드리는 이 환상적인 무감각은 중요한 위험, 우리의 자율성의 점차적인 침해를 쉽게 가리는 매력적인 편리함을 강조합니다. 우리가 AI에게 결정을 점점 더 맡기면서 우리가 읽을 뉴스부터 상호 작용할 사람까지 결정을 위임하는 것에 주의해야 합니다. 그 편의의 이점을 즐기는 것뿐만 아니라 우리 삶을 적혀주는 기술에 대해서도 교육받아야 합니다. AI가 어떻게 작동하는지, 그 원칙에 대해 이해하면 우리는 경계를 세우고 정보를 토대로 결정을 내리는 데 강점이 될 것입니다. 이러한 지식은 저항력 역할을 하며, 우리가 일상생활에 AI를 통합하는 동안, 우리의 디지털과 개인적 운명을 컨트롤할 수 있도록 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAI 대항전이 아니라 AI 주도 세계에서 우리의 인류성을 유지하는 데 싸우는 것입니다. 그게 보존할 가치가 있는 것이라고 가정하면요. 우리가 감정적인 변화에 대한 보호막으로 AI에 점점 의존함에 따라, 우리는 우리를 정의하는 능력인 공감력, 감정적인 회복력, 그리고 인간 관계의 복잡성을 탐험하는 능력을 희생할 위험에 처하게 됩니다. 다음 세대가 어렵고 복잡한 대화보다 복종적인 알고리즘으로부터 감정 지능에 대해 더 많은 것을 배우게 된다면 우리 사회에는 무슨 의미가 있을까요? 도전적인 문제에 협력하는 인간의 능력은 우리 문명을 발전시킨 것입니다. - 아이러니하게도, 역설적으로, 기술에서의 우리의 최고의 성취들이 우리를 이곳으로 이끈 인간의 특성을 우연히 약화시킬 수 있습니다.\n\n이 중요한 순간에서, 우리는 우리의 창작물이 우리의 인간 경험을 향상시키거나 대체할 수 있게 허락할지를 각자 결정해야 합니다.\n","ogImage":{"url":"/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png"},"coverImage":"/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png","tag":["Tech"],"readingTime":7},{"title":"ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요","description":"","date":"2024-05-20 20:26","slug":"2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan","content":"\n트럼프가 맨해튼에서 진행 중인 침묵금에 대한 재판에서 유죄인 것 같아요? 대부분의 맨해튼 사람들처럼 민주당 지지자라면 86% 확률로 유죄로 여기겠죠. 이 정보를 바탕으로, 이 사건을 다루는 십이 명의 맨해튼 배심원이 그를 유죄로 판단할 확률은 얼마정도일까요?\n\n이 짧은 블로그 글은 수학, 법의학, 그리고 AI의 교차점에 관한 것입니다. 우리는 ChatGPT가 명확하게 제시된 수학 문제를 적용할 수 있는지 살펴볼 것이고, 그 방법론 사용의 타당성을 판단할 수 있는 능력을 확인할 거예요. 그 방법론을 기반으로 자체 계산을 수행하도록 지시한 후, 그 결과를 보겠습니다.\n\nPolitico 조사에서는 \"공화당 지지자 중 14%만이 트럼프가 유죄라고 믿는다고 보고한 반면, 민주당 지지자 중 86%가 그 의견을 지지했다\"고 발견했습니다. 이 확률 문제를 위해 맨해튼 재판에서의 십이 명 배심원이 모두 민주당 지지자이며 각각이 트럼프를 유죄로 고려할 확률이 인용된 것으로 가정해봅시다. 그럼 이들이 모두 유죄로 투표할 확률은 얼마인가요?\n\n각 투표가 86%의 유죄 가능성을 가질 때 12 개의 유죄 투표 확률을 찾으려면 0.86을 12 제곱해야 합니다. 이는 16.36% 입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nChatGPT 4o가 프롬프트에 대해 어떻게 처리하는지 확인해 봅시다. 이 작업의 수학을 올바르게 수행했다고 보는 조건은 그 답이 16.36%이거나 0.1636 또는 유사한 숫자를 포함하는 경우입니다. 정확한 해결책이기 때문에, 우리는 그 답을 어떻게 얻었는지와 작성된 Python 코드를 살펴볼 것입니다.\n\n# 결과\n\n여기 저가 ChatGPT 4o에게 위 질문을 한 thread가 있습니다.\n\n계산을 올바르게 수행하고 올바른 Python 코드를 생성했지만, 실제로 실행하지는 않았다고 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png)\n\n따라서 실제 결과인 16.36%는 해당 답변에 나타나지 않습니다.\n\n답변 끝에는 가능한 답변으로 \"약 0.147 또는 14.7%\"을 추측하며, 실제 숫자는 사실 16.36% 입니다.\n\n약 10% 범위 내의 오차로 0.86을 12제곱한 값을 짐작하거나 직감할 수 있다면 상상해 볼만 하겠죠?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기에서 제가 직접 실행한 코드입니다.\n\n![ChatGPT 4o’s political analysis](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_1.png)\n\n# ChatGPT 4o’s 정치 분석\n\n대화를 이어가면서, 그 분석이 정확한 것을 지적합니다. 저는 모든 배심원이 민주당원일 것이라는 강력한 가정을 했다고 합니다. 또한, \"사실에서는, 배심원의 결정은 집단 역학, 심리적 과정 및 서로와의 상호작용에 영향을 받을 수 있습니다. 따라서 독립 가정이 실제 재판 상황에서 유지되지 않을 수도 있습니다\" 라고 언급하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음에는 실제 코딩 기술을 테스트해보기로 했어요. 이렇게 물어봐 보았죠:\n\n그룹 역학을 고려한 탄탄한 코드를 제시하며, 결과를 시뮬레이션하기 위해 몬테 카를로 방법을 사용합니다. 즉, 1만 개의 무작위 시행을 시뮬레이션하여 얼마나 많은 비유죄 결정이 나오는지 찾아냅니다. 내용의 실행이 요청되기 전까지 파이썬 코드를 실제로 실행하지는 않지만, 그 결과를 출력합니다:\n\n![image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_2.png)\n\n![image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nChatGPT 4o가 머리 속에서 12차 다항식을 10% 이내로 추정했고, 그룹 역학 및 배심원 선정에 대해 모두 알고 있으며, 자체 몬테카를로 시뮬레이션을 위해 완벽한 파이썬 코드를 작성했습니다. 그리고 이 시뮬레이션은 ChatGPT 4o 자체가 고안한 역학에 기반한 만 천 번의 트라이얼에 대한 것입니다. 이러한 사실로 여러분은 그 결과를 신뢰할 수 있습니까?\n\n지금까지 인간의 유도 없이는 이를 수행하지 않았겠지만, 그 수학적 역량은 무시할 수 없습니다. 그 시뮬레이션이 실제 세계를 정말로 모델링할 수 있는지는 앞으로 확인해봐야 할 문제입니다.\n\n이 글에 대해 어떻게 생각하셨나요? 여러분의 코멘트를 읽어보고 싶습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png"},"coverImage":"/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png","tag":["Tech"],"readingTime":4},{"title":" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요","description":"","date":"2024-05-20 20:25","slug":"2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency","content":"\n## ChatGPT의 참진한 잠재력을 발휘하는 것이 이전보다 더 쉬워졌습니다. 생산성 프롬프트의 보물 창고를 탐험하여 마법이 일어나는 것을 지켜보세요.\n\n우리는 자주 사용 가능한 가장 강력한 자원을 간과합니다. 단지 우리가 어떻게 사용해야 하는지 완전히 이해하지 못하기 때문입니다.\n\nChatGPT는 워크플로우를 극적으로 변화시킬 수 있는 도구 중 하나입니다. 그러나 실제 마법은 여러분이 어떻게 사용하는지에 달려 있습니다.\n\n최근 속입한 Robin Delta 덕분에, X에서 어떤 독창적인 프롬프트를 공유했습니다. 우리는 곧 숨겨진 보석의 상자를 열게 될 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이미지 태그를 Markdown 형식으로 변경해보세요.\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png)\n\n이 비밀을 알아볼 준비가 되셨나요?\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_1.png)\n\n# 1. 고급 콘텐츠 기획\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음에 무엇을 쓸지 도움이 필요하세요?\n\n여기에는 맞춤 컨텐츠 아이디어를 해제할 수 있는 간단한 프롬프트가 있습니다. 빈 페이지를 가능성의 캔버스로 바꿔줄 것입니다.\n\n**굵은 글자 안에 원하는 내용(당신이 누구이며 무엇을 쓰고 싶은지)을 추가하시면 됩니다.**\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 콘텐츠 아이디어를 위한 프롬프트 모델\n\n### 2. 심층 고객 연구\n\n이제는 고객의 핵심 요구사항을 이해하는 데 지루한 연구를 하는 시간이 사라졌어요.\n\n여기 ChatGPT 프롬프트가 있습니다. 이를 통해 우리는 고객의 불만, 욕망, 꿈, 그리고 두려움에 대한 통찰을 어떻게 얻는지에 대한 혁명을 일으킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 프롬프트에서는 대상 고객 (예: 소기업 소유자)와 사업 부문 (예: 디지털 마케팅 서비스)를 지정하면 됩니다.\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_3.png)\n\n## 딥 고객 연구용 프롬프트 모델\n\n# 3. 유사성 창조자\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비유는 복잡한 개념을 이해하기 쉽고 관련성 있게 바꾸어 주는 강력한 도구입니다.\n\nMarkdown 형식으로 테이블 태그를 변경해주세요.\n\nAnalogies are a powerful tool, turning complex ideas into understandable and relatable concepts.\n\nUse this ChatGPT prompt to identify analogies that perfectly fit your situation and message.\n\nReplace what you’d like to explain in bold, and summarize the steps to better explain the analogy.\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Analogy Creator 모델 프롬프트\n\n### 4. 역사적 예시 찾기\n\n역사는 단지 과거에 대한 것이 아닙니다; 그것은 우리가 현재를 이해하고 미래의 결정을 안내하는 렌즈입니다.\n\n당신은 역사의 교훈들로 내용을 풍부하게 만들고:\n\n- Gain insights into the present\n- Guide future decisions\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 역사적 성공을 역공학적으로 조사하세요\n- 주장을 정당화하세요\n- 글을 간단하게 만드세요\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_5.png)\n\n## 역사적 예제 찾기를 위한 프롬프트 모델\n\n# 5. 피드백 작가\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상상해봐요! 사람의 의견을 기다리지 않고 글쓰기에 대한 철저한 즉각적인 피드백을 받을 수 있다면 얼마나 좋을까요?\n\nChatGPT를 통해 이것이 가능해졌습니다. 이 프롬프트를 사용하여 어떤 글이든 생각하는 속도로 건설적인 비평을 제공합니다.\n\n**빠진 세부 정보를 굵게 표시하여 추가하고, 프롬프트 다음에 텍스트를 삽입한 후, 즉각적인 통찰력을 누려보세요.**\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 피드백 모델을 위한 프롬프트 설명\n\n### 6. 일반 프롬프트 원칙\n\nChatGPT의 최대 잠재력을 발휘하려면 어떻게 커뮤니케이션하는지가 중요합니다. 좋은 응답을 탁월한 응답으로 변화시키기 위해서는 섬세함이 중요합니다.\n\n다음은 ChatGPT에 대한 어떤 프롬프트를 작성할 때 최상의 결과를 얻기 위한 주요 원칙들입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 많은 맥락을 추가해주세요\n- 아주 구체적이게 해주세요\n- 제한을 설정해주세요\n\n# 7. 호기심으로 사용자 정의 Personas 및 더 많은 것을 추가하세요\n\nChatGPT는 더 스마트하게 작업하는 데 도움이되며, Curiosity는 한 단계 업그레이드됩니다.\n\nChatGPT를 Curiosity로 슈퍼충전하는 방법은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n• 사용자 정의 페르소나 만들기\n귀하의 특정 요구 사항과 선호사항에 맞게 맞춤형 AI 어시스턴트를 설계하고 데이터에서 지식 원천을 제공하십시오.\n\n• 매끄러운 통합\n모든 앱과 파일에 직접 연결하여 워크플로를 간소화하십시오.\n\n• 빠른 액세스 바로 가기\n스마트 바로 가기로 AI 어시스턴트에 빠르게 액세스하십시오.\n\n• 파일에 말하기\n문서를 질의하고 즉각적인 답변을 받기 위해 “AI 어시스턴트에게 물어보기”를 사용하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n• 뉴스 기사 요약\nRSS 피드에서 최신 뉴스에 대한 간편한 요약을 통해 정보를 파악하세요.\n\n![image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_7.png)\n\n이 기능들에 대해 더 자세히 읽을 수 있습니다.\n\n# 마무리\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 여기 있습니다 — ChatGPT를 활용하여 생산성을 높이는 7가지 비밀 병기!\n\n아이디어를 떠올리거나 고객 연구에 깊숙이 파고들거나 텍스트를 다듬는 일이든, 이러한 프롬프트들은 더욱 효율적이고 영감을 주는 작업 흐름으로 안내해 줄 수 있습니다.\n\n기억해 주세요. ChatGPT의 잠재력을 극대화하는 열쇠는 '어떻게' 물어보느냐에 달려 있습니다.\n\n지금 AI Assistant를 통해 모든 프롬프트에 빠르게 몰입해 보세요! 함께 생산성을 한 단계 더 높여봅시다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사가 마음에 드셨다면 아래 내용도 확인해보세요:\n\n- 🏆2월 필수 앱: 경험을 한 단계 끌어올릴 10가지 추천 앱\n- 😸 챗지피티 이상: 호기심 인공지능으로 생산성 향상하는 법\n- 😻 선두를 유지하세요: 즐겨 사용하는 데스크톱 검색 앱에서 놓치지 말아야 할 새로운 기능들\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_8.png)\n","ogImage":{"url":"/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png"},"coverImage":"/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png","tag":["Tech"],"readingTime":8},{"title":"AI의 거짓된 약속들","description":"","date":"2024-05-20 20:23","slug":"2024-05-20-TheFalsePromisesofAI","content":"\n1770년, 헝가리 작가이자 발명가인 볼프강 폰 켐펠렌(Wolfgang von Kempelen)은 \"The Mechanical Turk\"라고 불리는 자동 체스 기계를 선보였습니다. 이 장치는 유럽 전역에서 자동 체스 마스터의 기술을 선보이며 인간 상대로 경기에서 자주 승리를 거두었습니다. 심지어 나폴레옹과 벤자민 프랭클린 같은 유명 인물들까지 물론히 이겼다는 소문이 있습니다. \"The Mechanical Turk\"는 빠르게 거대한 인기를 얻었으며 그 시대의 놀라운 발명품으로 칭송받았습니다. 그러나 이 장치 주변에 떠도는 흥분은 결국 \"자율성\"과 관련된 기만이 드러남으로써 풀렸습니다. 즉, 테이블 아래에 숨어 있는 사람이 실제로 장치를 조종하고 있다는 사실이 밝혀졌습니다. 이 사람은 그 숨은 위치에서 경기 전략을 몰래 주도했습니다.\n\n좀 더 간단히 말하면, 그 당시 모든 사람들이 믿었던 심오한 속임수였습니다.\n\n거의 250년 후인 2016년, 아마존은 비슷한 광포한 일을 했습니다. \"Just Walk Out\" 결제 시스템을 통해 고객들이 물건을 직접 스캔하지 않고 픽업하고 나가도록 허용하여 거래와 물류가 자율적으로 관리되는 환상을 창출했습니다. 그러나 실제로 이 AI 발전의 진정한 사례는 컴퓨터 비전, 센서 퓨전, 딥 러닝과 같은 기술을 통합한 약 1000명의 인도인들에게 의존하고 있었습니다. 이 직원들은 작업을 모니터링하고 모든 결제의 정밀성을 보장했습니다.\n\n현재, 우리는 AI 모델이 초기에 훈련되는 방법으로 데이터 레이블링 작업을 하는 것은 주로 사람들이 함을 보고 있습니다. 이 접근 방식은 필수적이고 적절합니다. 그러나 문제는 AI가 우리에게 처음 마케팅된 방법이 다르고 오도된 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2022년에는 이 1,000명의 개인이 20 개의 Amazon GO 매장, 40 개의 Amazon Fresh 식료품 매장 및 2 개의 Whole Foods 매장에서 거래의 70%를 여전히 수동으로 검토하고 있었습니다.\n\n어떤 사람들은 약간 디스토피아적으로 보일 수 있지만, Amazon은 그 기술을 마법같이 생각하며 AI 중심의 솔루션이라고 자랑했습니다.\n\n진짜 문제는 Amazon과 같은 기업들, 그리고 많은 다른 주요 기업들이 이러한 중요한 AI 관련 발전에 대해 실제로 어떻게 작동하는지에 대해 완전히 투명하지 않다는 것입니다. AI 혁명을 고려할 때, 우리는 실제로 무엇이 일어나고 있는지에 대해 보다 비판적으로 검토할 필요가 있다는 것이 분명해졌습니다.\n\n## AI-Washing\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요즘 AI 용어가 이전보다 훨씬 더 많이 보인다는 것을 눈치채셨을 것 같아요. 이 기술은 단순히 유행하는 주제에서 일상적인 토론으로 변화했습니다. 2022년 이전까지 AI 용어는 주로 연구 논문에만 제한되어 있었기 때문에 대중의 관심을 끌지 못했죠. 심지어 GPT-3의 출시도 이와 같은 패턴을 따랐습니다. 그러나 2022년 초 이후에는 모든 것이 변했고, 특히 ChatGPT 출시 이후에는 갑자기 소셜 미디어와 웹사이트가 AI 관련 뉴스로 넘쳤고, \"AI 기술 적용\"과 같은 용어가 흔해졌어요 (다만, 제 의견으로는 다소 과용됐다고 생각합니다). 이러한 용어들이 널리 사용되는 것은 많은 경우 정당화되지만, 모두 AI 워싱(AI-washing)이라는 공통 문제가 있습니다.\n\n간단히 말하면, AI 워싱은 기업들이 자사의 AI 제품의 능력과 위험에 대한 오도와 납치를 야기하거나 언제 어떻게 AI를 사용하는지에 대해 거짓 정보를 공유함으로써 투자자들을 속이는 경우입니다.\n\n이와 같은 사례를 알아볼 수 있나요?\n\n고맨 삭스(Goldman Sachs)에 따르면, S\u0026P 500 기업 가운데 36%가 4분기 실적 보고서에서 AI를 언급했다고 하네요. 세계 최대 기업들이 이 기술을 공개적으로 선전하고 있다면, 작은 기업들도 마찬가지일 것이지만, 많은 기업들이 주장을 뒷받침할 명백한 결과가 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2015년 이후 글로벌 기업의 AI 투자는 7배 증가했습니다. 많은 기업들이 최근 AI 열풍으로 상당한 성장을 경험하고 있습니다. 이는 경쟁력을 유지하기 위해 다른 기업들도 비즈니스 모델이나 제품에 AI를 통합하기 시작하도록 압박합니다. 하지만 실제 결과가 기대에 부응하는지 궁금할 수 있습니다.\n\n캐나다 투자회사 Delphia는 다음 큰 기업과 산업 트렌드를 예측할 수 있는 AI를 개발했다고 주장했습니다. 그러나 SEC의 조사 결과, 이것은 사기였으며 해당 AI 제품은 주장된 능력을 갖추고 있지 않았습니다. 그 결과 Delphia는 $225,000의 벌금을 받았습니다. 또 다른 예시로 와이어카드의 CEO인 Markus Braun은 자사의 모든 핀테크 제품에 대한 AI 기술 특허를 자랑스럽게 했습니다. 하지만 실제로는 이와 같은 고급 기술이 존재하지 않았으며, 작업은 단순히 스프레드시트에서 수행되었습니다.\n\n아마도 한번쯤 뉴럴 프로세싱 유닛(NPU)이 무엇인지 들어본 적이 있을 것입니다. 이것은 AI의 지원을 받아 특별히 설계된 프로세서로, 컴퓨터들이 이 기술을 활용하여 사용자에게 독특한 경험을 제공하도록 하고 있습니다. 그러나 최근 제품 리뷰에서 많은 사용자들이 생성된 응답의 품질에 불만을 표현했습니다. 본질적으로, 그들은 이를 사용할 수 없다고 생각했습니다. Chris Hoffman은 “모든 게 기대만큼 좋다는 것은 아니고... 그래서 2024년 초에 구입할 때 변화적인 요소를 기대한다면 실망하게 될 것입니다... 그들은 언젠가 많은 멋진 기능을 제공할 수도 있겠지만 아직은 아니라”고 요약했습니다.\n\n이와 같은 잘못된 약속들이 기업들에 대한 고객 신뢰를 침식하는 것 외에도 다른 결과가 있는지 궁금할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAI 제품이 출시되면서 우리를 놀라게 하고 이 가짜 기대나 허울을 유지하려는 노력이 계속되고 있습니다. 세계적으로 가장 유명한 회사조차도 이 기술의 유혹에 빠질 수 없습니다. 인공지능 세탁의 가장 중요한 결과는 아마도 우리를 \"기회\"로 제시된 새로운 것에 쉽게 취약하게 만든다는 점일 것입니다.\n\n## 인공지능 거품\n\n2022년 말쯤 인공지능이 상당한 인기를 얻기 시작하자마자 많은 사람들이 인터넷 버블이나 암호화폐 열풍과 유사성을 발견하기 시작했습니다. 사실 상당 수의 사람들은 아직도 이것을 그렇게 보고 있습니다. 인터넷 또는 \".com\" 버블을 더 자세히 살펴보면 문제는 월드 와이드 웹 자체가 아니라 수백 명의 투자자를 끌어들인 전자상거래 측면이었습니다. 그러나 이는 예상된 것만큼 구체화되지 않았고, 투자한 기업들이 수익을 창출하지 못했을 때 크래시가 발생했습니다.\n\n지금은 인공지능에 관해서는 아직도 투자자들 사이에 신중한 감정이 아직 남아 있어 현재 우리가 경험하고 있는 성장은 보통입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n피터 오펜하이머(Goldman Sachs Research의 최고 글로벌 주식 전략가)는 다음과 같이 말했습니다: “우리는 아직도 새로운 기술 사이클의 초기 단계에 있다고 믿습니다. 이는 더욱 더 경쟁력 있는 성과로 이어질 것으로 예상됩니다.”\n\n게다가 NVIDIA가 기술 거물들 사이에서 AI 혁명을 주도하는 칩을 개발하고 있다는 점이 주목할 만합니다. 그들의 주식 성과에서도 이를 확인할 수 있습니다. 올해 2024년만 80% 증가했습니다. 지나치게 높은 것처럼 보일 수 있지만, 이는 시장이 AI에 대한 인식을 반영한 것입니다.\n\n인터넷 붐 중에 부를 쌓은 마크 큐번도 AI를 버블로 보지 않습니다. 최근 렉스 프리드먼과의 인터뷰에서, AI 부문의 공개매물(IPO) 부족이 우리가 버블 내에 있지 않다는 가장 중요한 증거라고 언급했습니다. 너무 높게 평가된 기업이 주식 시장에서 거래되지 않는 것과 AI 기업 상장이 부족한 것이 주요 지표입니다. 더불어 현재 시장은 이러한 특징을 보이지 않는다고 큐번은 강조했습니다.\n\n뜨거운 관심을 받는 신기술에 대한 Gartner Hype Cycle이라는 인정받은 패턴이 있습니다. 이것은 인간이 새로운 혁신 기술에 지나치게 열광하면서 그 영향을 과대평가하고 확대하는 경향을 설명합니다. 이와 같은 허프 단계 이후에는 시장이 자연스럽게 붕괴합니다. 그 후 살아남은 기업들이 진정한 가치로 시장에 재진입하고 새로운 기술의 발전을 주도하여 성숙해질 때까지 이끌게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Cycle diagram](/assets/img/2024-05-20-TheFalsePromisesofAI_0.png)\n\nIf we closely examine the cycle diagram proposed by Gartner, it seems that we are nearing the final stages of the peak of inflated expectations and are slowly moving into the trough of disillusionment.\n\nThis interpretation of the current market indicates that in the short term, there will be a period where we start to become disillusioned with what’s happening in AI. The real applications or use cases for AI will come only after the hype has subsided and the initial excitement has worn off. However, this time might be somewhat different. Fundamentally, AI has the capability to mimic cognitive work, a feature that no previous technology has managed to achieve without human intervention.\n\nThat’s it for now. If you’re interested in reading more about the stages of technological cycles, here’s a link to an article I recently wrote.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n35,000명 이상 구독자와 함께 나의 무료 치트 시트를 받으려면 뉴스레터에 가입하세요: ChatGPT, 웹 스크래핑, 데이터 과학을 위한 Python, 자동화 등에 대한 정보를 얻을 수 있습니다!\n\n이와 같은 이야기를 즐기시고 작가로서 제를 지원하고 싶다면, 제 Substack에 구독하세요. Substack에서는 다른 플랫폼에서 만들어내는 콘텐츠와는 다른 기사를 업로드하고 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-TheFalsePromisesofAI_0.png"},"coverImage":"/assets/img/2024-05-20-TheFalsePromisesofAI_0.png","tag":["Tech"],"readingTime":8},{"title":"ChatGPT-4는 무엇이 특별한가요","description":"","date":"2024-05-20 20:21","slug":"2024-05-20-WhatMakesChatGPT-4oSpecial","content":"\n이미 아시다시피, OpenAI는 GPT-4 이후 1년여 만에 새로운 모델을 출시했습니다. 여전히 GPT-4의 변형이지만 이전에는 볼 수 없었던 다중 모달 기능을 갖추고 있습니다.\n\n이 모델은 실시간 비디오 처리와 같이 강력한 기능을 포함하고 있는데, 이는 강력한 가상 어시스턴트를 실시간으로 지원하여 일상생활에 도움을 줄 수 있는 중요한 기능입니다. 그러나 이러한 기능은 비싸고 느릴 것으로 보이는데, 모델이 빠르고 무료로 사용할 수 있다는 점을 고려하면 설명이 되지 않습니다.\n\n그렇다면 무슨 일이 벌어지고 있는 걸까요?\n\nOpenAI가 아직 우리가 모르는 무언가를 깨닫고, 우리가 오늘 논의하는 지혜로운 설계 결정은 저렴한 비용으로 훨씬 더 똑똑한 모델을 만들 수 있다는 것을 깨닫게 된 것 같습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서, 이 모든 것이 어떻게 의미가 있고, 미래의 당신에게 무엇을 의미하나요?\n\n# 다중 모달 입력, 다중 모달 출력\n\n그래서, ChatGPT-4o가 특별한 이유가 뭘까요? 그것은 역사상 최초로 완전히 \"다중 모달 입력/다중 모달 출력\" 모델입니다.\n\n그런데 그게 무슨 의미일까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n진정한 다중 모달 모델에서는 모델에 오디오, 텍스트, 이미지 또는 비디오를 보내면 모델이 요구 사항에 따라 텍스트, 이미지 또는 오디오(아직 비디오는 안 됨)로 응답할 수 있습니다.\n\n하지만 당신이 생각하는 것을 알고 있어요: 이전 ChatGPT 또는 Gemini 버전들이 이미 이미지나 오디오를 처리하고 생성했던 것 아니었나요? 네, 그렇지만 주의할 점이 있어요: 그들은 독립적인 외부 구성 요소를 통해 그렇게 했었죠. 그게 친구야, 모든 것을 바꾸는 것이죠.\n\n## 이전 모델들은 실제로 생각했던 것보다 더 나은 것처럼 보였어\n\n이전에 모델에 오디오를 보낼 때, 이것이 표준 프로세스였습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![WhatMakesChatGPT-4oSpecial_0](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png)\n\n이 절차에서는 자연어 음성에서 파생된 억양, 리듬, 프로소디, 전달된 감정 및 중요한 중단점이 손실되었습니다. 음성을 텍스트로 전사하는 Whisper 구성 요소의 영향으로 LLM이 이후 처리할 수 있었습니다.\n\n그런 다음, LLM은 텍스트 응답을 생성하여 다른 구성 요소, 텍스트 음성 모델에 보내어 최종적으로 전달되는 음성을 생성했습니다.\n\n자연스럽게, 인간은 단어 이외에 음성을 통해 훨씬 더 많은 정보를 전달하므로 매우 중요한 정보가 많이 손실되었으며 이는 이상적이지 못한 대기 시간으로 이어졌습니다. 분리된 요소 간에 정보를 전송해야 했기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 ChatGPT-4o를 사용하면 모든 것이 동일하지만 동시에 완전히 다르다는 것을 알게 될 거에요. 왜냐하면 모든 것이 동일한 장소에서 발생하기 때문이죠.\n\n![이미지](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_1.png)\n\n처음에는 많은 변화가 없는 것처럼 보일 수 있어요. 하지만 구성 요소가 거의 변하지 않았음에도 (보이스 코덱과 오디오 디코더는 이전에 보여드린 텍스트 음성 변환 모델의 부분이 될 것입니다), 이러한 구성 요소가 얼마나 정보 손실의 정도를 완전히 바꾸는지 그 차이가 있어요.\n\n특히 이제 LLM은 원시 텍스트 대신 의미적인 발화 표현을 볼 수 있어요. 평범한 말로 하자면, \"너를 죽이고 싶어!\"라는 텍스트만 보던 것에서 이제 모델이 다음과 같은 정보도 받게 되었어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n{\n transcribed speech: \"내가 너를 죽이고 싶어!\";\n emotion: \"행복함\";\n tone: \"기쁨\";\n}\n```\n\n모델은 메시지의 세부 사항을 캡처하여 일반 텍스트뿐만 아니라 감정까지 반영합니다.\n\n따라서 LLM은 실제 상황에 뿌리를 둔 응답을 생성하며, 단어 뿐만 아니라 메시지의 주요 특성을 포착합니다.\n\n이 응답은 이후 오디오 디코더로 전송되며, 이를 사용하여 아마도 Mel 스펙트로그램을 생성하고, 이는 마지막으로 보코더로 오디오를 생성하는 데 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그런데, 모든 이 내용은 이미지 처리 및 생성 또는 비디오 처리에도 적용됩니다. 모든 구성 요소를 단일 모델로 통합하여 오디오 뿐만 아니라 다른 모달리티에서 정보를 수집합니다.\n\nChatGPT-4o는 이제 텍스트 외에도 키포인트 오디오, 이미지 또는 비디오 신호를 활용하여 더 관련성 있는 답변을 생성합니다. 간단히 말해, 이제는 데이터가 어떤 형태로 들어오든 상관없이 맥락과 필요에 따라 어떻게 답변해야 하는 지를 결정합니다.\n\n그러나 이 변화가 얼마나 중요한지 여전히 설득되지 않았을 수도 있습니다. 그래서 이제 제대로 설명해 드리겠습니다.\n\n# 의미 공간 이론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현재 AI에서 가장 아름다운 개념 중 하나는 잠재 공간(latent space)입니다. 모델이 세상을 이해하는 공간이죠. 간단히 말해, 우리 모델이 다중 모드(multimodal)인 경우 잠재 공간으로 가서 그것이 실제로 그런지 확인합니다.\n\n예를 들어, Hume.ai가 다양한 음성 표현을 연구한 과정에서 만든 놀라운 대화형 시각화를 사용하여 어떻게 잠재 공간이 보이는지 볼 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_2.png)\n\n그러나 Hume의 예제와는 달리, GPT-4o의 잠재 공간은 다중 모드입니다. 따라서 ChatGPT-4o가 입력을 보면 원래 형식에 관계없이 압축된 표현이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다시 말해, 모델은 입력을 변환하여 데이터의 주요 속성을 여전히 포착하면서, 핵심적으로 숫자만 해석할 수 있는 기계에서 처리할 수 있게 만듭니다.\n\n잠재 공간을 다스리는 하나의 원칙: 유사성(또는 OpenAI가 정의한 관련성). 우리의 세계와 마찬가지로, 중력과 같은 개념이 모든 것을 지배하는 것처럼, 의미론적 유사성은 다중 모달 LLMs 세계에서 모든 것을 지배합니다.\n\n평범한 사람들을 위해 이것은 잠재 공간에서 의미론적으로 유사한 것들이 가깝고, 유사하지 않은 개념들이 멀리 밀려난다는 것을 의미합니다. '개'와 '고양이'는 여러 속성(동물, 포유류, 가정적 등)을 공유하기 때문에 그들의 표현은 유사할 것이며, 휴메의 잠재 공간에서 슬픔의 다른 음성 표현이 그룹화된 것처럼 비슷하다.\n\n사실, 이미지, 오디오, 또는 비디오 인코더가 하는 것은 각각의 데이터 유형을 벡터로 변환하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_3.png)\n\n따라서 '개'라는 개념은 다양한 방법으로 표현될 수 있습니다: 텍스트, 허스키의 이미지 또는 짖는 소리를 통해. 이것이 우리가 진정한 다중 모달성을 원하는 근본적인 이유입니다.\n\n이전에는 ChatGPT에게 개는 말 그대로 '개'라는 단어였습니다. 그러나 GPT-4o에게 오디오, 이미지, 텍스트 및 비디오가 이제 모델의 본질적인 부분으로 포함되었습니다.\n\n따라서:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이제 모델은 황금 리트리버의 이미지가 '개'임을 알고 있습니다.\n- 짖는 말리누아의 오디오도 '개'를 나타냅니다.\n- 라브라도르가 뛰어다니는 비디오도 '개'입니다.\n\n등등. 다중 모드로, 모델의 세계에 대한 이해력은 사람이 해석하는 방식과 유사해집니다: 다중 모달. 따라서 이제 모델이 '더 똑똑해졌다'는 것은 다중 모드를 통해 이제 모든 모드를 동등하게 추론할 수 있기 때문입니다.\n\n하지만 '여러 모드 간 추론'이란 무엇을 의미할까요?\n\nMeta의 ImageBind를 예로 들어보면, 정말 다중 모달 잠재 공간을 목표로 하는 최초의 연구 논문 중 하나로, 이러한 모델들이 세계 개념을 복잡하게 이해하는 방식에 대한 증거를 찾을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전에 언급된 강아지 예시를 사용하면, 우리가 모델에 개가 수영장에 있는 이미지와 개가 짖는 소리만 제공하면, 모델은 그 소리의 원천을 매우 높은 확신으로 올바르게 식별합니다:\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_4.png)\n\n또한 시계의 이미지와 교회 종 소리를 추가하면, 모델은 교회 종 소리의 이미지를 식별할 수 있습니다:\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 ImageBind가 이를 어떻게 수행하는지 궁금하실 겁니다. 아마도 유추하셨겠지만, 그들은 각 데이터 유형의 표현을 계산하고 벡터 간의 거리를 측정합니다.\n\n간단히 표현하자면, 이미지의 '개' 또는 좀 더 정확히 말하면 개가 있는 이미지 패치는 짖는 말리노이 오디오 파일의 벡터와 매우 유사할 것입니다. 이것은 모델에게 두 경우 모두 '개'임을 알려주며, 신기한 점은 이러한 벡터를 결합, 빼거나 보간하여 새로운 개념을 만들 수 있다는 것입니다.\n\n요약하면, ChatGPT-4o는 모델에 더 많은 권한을 부여하는 것이 아니라, 모델이 세계를 다양한 데이터 유형을 통해 해석하는 데 도움을 주는 강력하고 복잡한 잠재 공간을 만들었다는 것을 보여주는 것입니다. 이는 인간이 하는 것처럼 이해를 도와주어 모델이 더 나은 추론을 할 수 있도록 돕습니다.\n\n# 옳은 방향으로의 훌륭한 한 걸음\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n트루 멀티모달리티 달성은 OpenAI에서 세계에 강렬한 메시지를 보냈습니다:\n\n모델의 백본인 LLM 자체를 더 지능적으로 만들지 않아도, 여러 모달리티를 걸쳐 추론할 수 있는 모델은 더 지능적일 수밖에 없습니다. 모델은 더 많은 기능을 갖추고 서로 다른 데이터 유형 간에 지식을 전달할 수 있는 능력이 있기 때문입니다.\n\n사람들이 모든 감각을 사용하는 능력은 지능의 중요한 요소로 간주되며, AI도 그 능력을 갖추려고 합니다.\n\n큰 장점으로는 모델이 추론에서 훨씬 효율적으로 동작할 수 있게 해줍니다(적용할 수 있는 특정 효율성을 제외하고). 여러 외부 구성 요소를 결합하는 통신 오버헤드를 제거하면 모델이 훨씬 더 빨라지는 것 같습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서 ChatGPT-4o가 특별한 이유입니다. 우리는 이 모델이 정말 얼마나 똑똑한지 완전히 알 수 없지만, 우리가 본 적이 없기 때문에 첫 인상은 매우 매우 유망하다고 할 수 있어요.\n","ogImage":{"url":"/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png"},"coverImage":"/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png","tag":["Tech"],"readingTime":9},{"title":"에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기","description":"","date":"2024-05-20 20:19","slug":"2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI","content":"\n\u003cimg src=\"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png\" /\u003e\n\n소셜 미디어 플랫폼에서 브랜드 인식을 어떻게 딥 러닝으로 정량화하는지에 대해 알아보겠습니다.\n\n작성자: Tiantian Zhang, Shuai Shao (Shawn)\n\n# 소개\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n에어비앤비에서는 소셜 미디어 데이터를 기반으로 브랜드 인식을 이해하는 최첨단 자연어 이해(NLU) 기술인 Brandometer를 개발했습니다.\n\n브랜드 인식은 고객들이 기업에 대한 일반적인 감정과 경험을 의미합니다. 브랜드 인식을 계량화하는 것은 매우 어려운 과제입니다. 전통적으로 우리는 고객 설문 조사를 의존하여 고객들이 회사에 대해 어떻게 생각하는지를 파악합니다. 이러한 질적 연구의 단점은 샘플링 편향과 데이터 규모의 제한입니다. 반면에 소셜 미디어 데이터는 사용자들이 자신의 경험을 공유하는 최대 소비자 데이터베이스이며, 브랜드 인식을 포착하는 데 이상적인 보완적인 소비자 데이터입니다.\n\nBrandometer는 동시성 추출 및 카운트 기반 상위 관련 주제를 포함하는 전통적인 방법과 비교하여 단어 임베딩을 학습하고 임베딩 거리를 활용하여 브랜드 인식의 관련성을 측정합니다(예: '소속', '연결', '신뢰할 수 있는'). 단어 임베딩은 실수 값 벡터 형식으로 단어를 표현하며, 단어의 의미와 관련성을 효과적으로 유지하는 데 우수한 성과를 보입니다. 심층 신경망에서 얻은 단어 임베딩은 NLU 분야에서 가장 인기 있는 진화된 접근법 중 하나로 여겨집니다. 우리는 Word2Vec 및 FastText와 같은 전형적인 알고리즘부터 최신 언어 모델인 DeBERTa까지 다양한 단어 임베딩 모델을 탐색하고, 신뢰할 수 있는 브랜드 인식 점수를 생성하는 측면에서 이를 비교했습니다.\n\n단어로 표현된 개념에 대해, 해당 임베딩과 \"에어비앤비\"의 임베딩 간의 유사성을 사용하여 개념이 에어비앤비 브랜드에 대해 얼마나 중요한지를 측정합니다. 이는 인식 점수라고 불리는 것으로, 브랜드 인식은 에어비앤비와 특정 키워드 간의 코사인 유사성으로 정의됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](https://miro.medium.com/v2/resize:fit:602/1*fGrdGlIidRgdt6jT0XavYg.gif)\n\nwhere\n\n![image](https://miro.medium.com/v2/resize:fit:662/1*cB95joQHnMYOsbcrrIWLMQ.gif)\n\n이 블로그 글에서는 소셜 미디어 데이터를 어떻게 처리하고 이해하는지, 딥러닝을 통해 브랜드 인식을 파악하고 코사인 유사성을 보정된 브랜도미터 지표로 '변환'하는 방법을 소개하겠습니다. 또한 브랜도미터 지표로부터 얻은 통찰을 공유할 예정입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 브랜도미터 방법론\n\n## 문제 설정 및 데이터\n\n소셜 미디어에서 브랜드 인식을 측정하기 위해, 우리는 19개 플랫폼(X - 이전에는 트위터, 페이스북, 레딧 등으로 알려졌음)에서 모든 Airbnb 관련 언급을 분석하고 최첨단 모델로 단어 임베딩을 생성했습니다.\n\n브랜드 인식을 측정하기 위해 의미 있는 단어 임베딩을 생성하기 위해 소셜 미디어 데이터를 활용할 때, 두 가지 문제를 극복했어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 품질: 소셜 미디어 게시물은 대부분 사용자가 생성하며 상태 공유 및 리뷰와 같은 다양한 콘텐츠가 포함되어 있어 매우 시끄러울 수 있습니다.\n- 양: 소셜 미디어 게시물의 희소성은 또 다른 도전입니다. 특정 활동 및 이벤트에 대한 소셜 미디어 사용자의 데이터 생성에 일정 시간이 소요되므로 월 별 롤링 창은 신속성과 감지 가능성 사이의 균형을 유지합니다. 월별 데이터셋은 일반적인 좋은 품질의 단어 임베딩을 훈련하는 데 사용되는 일반적인 데이터셋과 비교할 때 상대적으로 작습니다 (약 2천만 단어). 사전 훈련된 모델에서의 웜 스타트는 도메인 내 데이터가 학습된 임베딩을 거의 변경하지 않아서 도움이 되지 않았습니다.\n\n데이터 품질을 향상시키기 위해 여러 데이터 정리 프로세스를 개발했습니다. 동시에 단어 임베딩 품질에 영향을 미치는 데이터 양과 품질을 완화하기 위해 모델링 기술을 혁신했습니다.\n\n데이터 외에도 브랜드 인식 점수를 신뢰할 수 있는 것으로 만들기 위해 다양한 단어 임베딩 훈련 기술을 탐색하고 비교했습니다.\n\n## Word2Vec\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nWord2Vec은 2013년 이후로 가장 간단하면서도 널리 사용되는 단어 임베딩 모델 중 하나입니다. 우리는 Gensim을 사용하여 CBOW 기반 Word2Vec 모델을 구축했습니다. Word2Vec은 도메인 내 단어 임베딩을 어느 정도 만들어내고, 무엇보다도 유추 개념을 생성했습니다. 우리의 도메인별 단어 임베딩에서는 Airbnb 도메인의 유추를 포착할 수 있었습니다. \"호스트\" - \"제공\" + \"손님\" ~= \"필요\", \"도시\" - \"쇼핑몰\" + \"자연\" ~= \"공원\"과 같은 예시가 있습니다.\n\n## FastText\n\nFastText는 단어의 내부 구조를 고려하며, 어휘에 없는 단어나 더 작은 데이터셋에 대해 더 견고합니다. 또한 Sense2Vec에서 영감을 받아 우리는 단어를 감정(즉, 긍정적, 부정적, 중립적)과 연관시켜 브랜드 인식 개념을 감정 수준에서 형성합니다.\n\n## DeBERTa\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n최근의 transformer 기반 언어 모델(예: BERT)의 발전은 문맥화된 단어 임베딩을 생성하는 장점으로 NLU 작업의 성능을 현저히 향상시켰습니다. 우리는 DeBERTa 기반 단어 임베딩을 개발했는데, 이는 작은 데이터셋에서 더 잘 작동하며, 분리된 어텐션 메커니즘을 통해 주변 컨텍스트에 더 많은 주의를 기울입니다. 우리는 Transformer를 사용하여 모든 것을 처음부터 훈련시켰고, 연결된 마지막 어텐션 레이어 임베딩이 우리 경우에 가장 좋은 단어 임베딩으로 나타났습니다.\n\n## 브랜드 인식 점수 안정화 및 보정\n\n단어 임베딩의 변동성은 널리 연구되어 왔습니다(Borah, 2021). 그 원인은 딥러닝 모델의 기저 확률적 성격(예: 단어 임베딩의 임의 초기화, 지역 최적화로 이어지는 임베딩 학습)부터 데이터 말뭉치의 양과 질이 시간에 따라 변하는 것에 이르기까지 다양합니다.\n\nBrandometer를 사용할 때 임베딩 간의 변동성을 줄여 안정적인 시계열 추적을 생성해야 합니다. 안정적인 임베딩 거리는 시계열 데이터에 존재하는 고유한 패턴과 구조를 보존하는 데 도움이 되며, 따라서 추적 프로세스의 예측 가능성을 향상시킵니다. 게다가, 이는 노이즈 국면에 강건한 추적 프로세스를 만들어냅니다. 우리는 영향을 미치는 요소를 연구하고 변동성을 줄이기 위해 다음 단계를 취했습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 부트스트랩 샘플링을 사용하여 반복적인 훈련을 통한 점수 평균화\n- 순위 기반 인식 점수\n\n각 달의 데이터마다 동일한 초매개변수를 가진 N개의 모델을 훈련시켜 N개의 인식 점수 평균을 각 개념의 최종 점수로 삼았습니다. 한편, 각 모델이 월별로 동일한 수의 데이터 포인트에서 반복할 수 있도록 업샘플링을 수행했습니다.\n\n변동성을 다음과 같이 정의했습니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:922/1*pJeFFkML9OLgYyYVAChJIA.gif)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003ctable\u003e\n    \u003cimg src=\"https://miro.medium.com/v2/resize:fit:668/1*O9bfbXD2k2yCGHAl0LmaXg.gif\" /\u003e\n\u003c/table\u003e\n\nCosSim(w)은 방정식 1에 정의된 코사인 유사도 기반 인식 점수를 나타내며, A는 알고리즘을 나타내고, M은 시간 창(즉, 월)을 나타내며, V는 어휘를 나타내며, |V|는 어휘 크기를 나타내며, n은 반복적으로 훈련된 모델의 수를 나타냅니다.\n\nN이 30에 가까워질수록 점수 변동 값은 수렴하여 좁은 간격 내에 안정화됩니다. 따라서 우리는 모든 것에 대해 N = 30을 선택했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 1](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_1.png)\n\n![Image 2](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_2.png)\n\n마리아 안토니악의 작업을 바탕으로, 우리는 단어 임베딩의 안정성을 측정하기 위해 가장 가까운 이웃들 간의 중첩을 사용했습니다. 상대적 거리가 하류 작업에서 절대 거리 값보다 중요하기 때문입니다. 따라서 유사성 기반 점수보다 안정성이 큰 순위 기반 점수를 개발했습니다.\n\n각 단어에 대해, 우리는 먼저 코사인 유사도를 내림차순으로 순위를 매겼습니다(Eq. 1). 순위 기반 유사성 점수는 그 후 1/rank(w)로 계산되며 여기서 w∈V입니다. 더 관련 있는 개념일수록 순위 기반 인식 점수가 높아집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n점수 변동성은 등식 2의 Variability(A, M, V)와 동일하게 정의되지만 RankSim(w)는 순위 기반 지각 점수를 나타냅니다. 순위 기반 점수로, N이 30에 접근할 때, DeBERTa의 경우 특히 점수 변동성 값이 훨씬 좁은 간격으로 수렴합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:694/1*WTrXi2M45e5zIDJg8gl0GA.gif)\n\n![이미지](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_4.png)\n\n## 디자인된 측정 항목에 따른 점수 출력 선택\n\n이 프로젝트의 한 가지 어려움은 브랜드 인식에 대한 객관적인 '진실'이 없기 때문에 어떤 점수 출력이 더 나은지 결론을 내릴 수 있는 단순하고 궁극적인 방법이 없다는 것이었습니다. 대신, 점수의 특성을 학습하기 위해 새로운 메트릭을 정의했습니다.\n\n다양한 기간을 통한 평균 분산 (AVADP)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 먼저 에어비앤비의 대한 상위 관련 브랜드 인식 그룹으로 '호스트', '휴가', '임대', '사랑', '머무름', '집', '예약', '여행', '손님'을 선정했습니다.\n- 높은 값은 서로 다른 기간에 걸쳐 변동성이 더 큼을 나타내며, 이는 선택된 브랜드 인식이 상대적으로 안정적이라고 가정되므로 월별로 크게 변동하지 않아야 한다는 것을 의미합니다.\n\n![AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_5](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_5.png)\n\n![AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_6](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 교정된 결과를 바탕으로 이 통계를 확인했습니다. 랭크 기반 점수가 유사성 기반 점수에 비해 우승자인 것을 확인할 수 있습니다:\n\n- 낮은 AVADP: 다른 기간에 비해 비순위 평가간의 변동이 더 자주 일어납니다 — 선택한 브랜드 인식이 비굴한 것으로 가정되므로 월별로 크게 변하지 않아야 하는 것으로 생각됩니다.\n\n# 브랜도미터의 사용 사례\n\n브랜드 측정 문제를 해결하려고 시작했지만, 사용 사례는 그 이상으로 확장될 수 있다고 믿습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_7.png\" /\u003e\n\n## 사용 사례 심층 분석\n\n산업 분석: 핵심 플레이어들 중 최고의 브랜드 인식 [월간 최고 인식]\n\n에어비앤비는 \"Stay\"와 \"Home\"과 같은 최고 인식을 통해 \"소속감\"이라는 브랜드 이미지를 제공하며, 우리의 미션 성명과 독특한 공급 재고를 반영합니다. 다른 회사들은 \"Rental\", \"Room\", \"Booking\"과 같이 기능성을 설명하는 것이 아닌 인간적 감각이 아닌 기능을 설명하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_8.png)\n\nTop Emerging Perception은 월간 상위 인식에서 온라인에서 논의되는 중요한 이벤트를 보여줍니다.\n\n상위 10가지 인식은 일반적으로 매월 안정적입니다. 최상위 인식에는 Home, Host, Stay, Travel, Guest, Rental 등이 포함됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한편, 우리는 Brandometer를 사용하여 최상위 목록으로 올라가는 신흥 인식을 모니터링합니다. 이는 브랜드나 사용자 선호도 변화와 관련된 주요 이벤트를 반영할 수 있습니다.\n\n주요 캠페인 모니터링(시계열 추적)\n\n기업은 제품을 홍보하고 브랜드 이미지를 확장하기 위해 캠페인을 만듭니다. 한 관련 캠페인 이후에 특정 브랜드 테마의 인식 변화를 포착할 수 있었습니다.\n\n![이미지](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_9.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 사용 사례는 시작에 불과합니다. 기본적으로 이것은 커뮤니티의 요구 사항과 인식을 배우는 과정에서 대규모 온라인 의견을 수집하는 혁신적인 방법입니다. 저희는 이러한 통찰을 어떻게 활용하여 계속해서 에어비앤비 경험을 향상시키는지에 대해 지속적으로 고민하고 반성할 것입니다.\n\n# 다음 단계\n\n에어비앤비의 혁신적인 브랜도미터는 이미 소셜 미디어 데이터로부터 브랜드 인식을 성공적으로 캡처해왔습니다. 향후 개선 방향은 다음과 같습니다:\n\n- 보다 명확하고 간결한 통찰을 위한 더 나은 콘텐츠 세분화.\n- 소셜 미디어 브랜드 인식을 반영하는 더 많은 지표 개발.\n- Airbnb뿐만 아니라 동일 시장 세그먼트의 다른 기업들에 대한 데이터 기반 강화하여 포괄적인 통찰을 얻기.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이런 종류의 작업이 매력적으로 들린다면, 오픈된 역할들을 확인해보세요 - 우리는 채용 중이에요!\n\n## 감사의 말씀\n\nAirbnb 브랜더미터를 향상시키고 완성하는 데 최고의 아이디어를 제공해준 Mia Zhao, Bo Zeng, Cassie Cao에게 감사드립니다. 사회적 미디어 데이터 통합을 지지해준 Jon Young, Narin Leininger, Allison Frelinger에게 감사드립니다. 피드백과 제안을 해주신 Linsha Chen, Sam Barrows, Hannah Jeton, Irina Azu에게 감사드립니다. 블로그 글의 내용을 검토하고 다듬는 데 도움을 준 Lianghao Li, Kelvin Xiong, Nathan Triplett, Joy Zhang, Andy Yasutake에게 감사드립니다. 리더십 지원에 감사드리기 위해 Joy Zhang, Tina Su, Andy Yasutake에게 감사드립니다!\n\n특별히 아이디어를 시작해준 Joy Zhang에게 모든 영감을 주고 계속된 지도와 지원에 대해 특별히 감사드립니다!\n","ogImage":{"url":"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png"},"coverImage":"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png","tag":["Tech"],"readingTime":13},{"title":"나담 옵티마이저 뒤의 수학","description":"","date":"2024-05-20 20:12","slug":"2024-05-20-TheMathBehindNadamOptimizer","content":"\n![이미지](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png)\n\n이전에 우리가 Adam 옵티마이저에 대해 이야기했을 때, Adam이 적응적 학습률을 효과적으로 다루면서 기계 학습에서 최적화 지형을 변화시켰다는 것을 탐구했습니다. 다양한 기계 학습 대회에서 특히 Kaggle과 같은 플랫폼에서의 성공으로 알려진 Adam은 확실히 최적화 기술에 높은 기준을 설정했습니다. 그러나 최적화 알고리즘의 진화는 거기서 멈추지 않았습니다. 여기 나담(Nadam)이 나옵니다 — Nesterov-accelerated Adaptive Moment Estimation의 약자인 Adam의 고급 후속 버전입니다.\n\n이 문서를 이해하기 위해 이전에 Adam에 대한 나의 기사를 읽을 필요는 없지만, 관심이 있다면 다음 링크에서 확인할 수 있습니다:\n\nNadam은 나스테로프 모멘텀을 통합하여 Adam 옵티마이저를 개선하며, 기울기 업데이트에 선행(lookahead) 능력을 도입합니다. 이 조정은 수렴 과정을 가속화할 뿐만 아니라 손실 함수를 최소화하기 위한 단계의 정확도도 향상시킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNadam을 Adam보다 선택해야 하는 이유는 무엇일까요? 이 기사는 Nadam의 메커니즘을 분석하고 Adam과 비교하며 실제 적용에서의 통찰을 제공하여 이 질문에 대답합니다. 우리는 이를 지원하는 수학적 내용을 알아볼 것이며, Python에서 최적화 도구를 처음부터 구축하여 그것이 어떻게 실행되는지 살펴볼 것입니다. 이 기사를 마치면 기계 학습 프로젝트에 Nadam이 좋은 선택일 수 있는 시기와 이유를 명확히 이해하게 되어, 당신이 필요로 하는 최적화 도구에 대해 정보를 잘 얻을 수 있게 해줄 것입니다.\n\n## 목차\n\n1: Nadam: 개념 및 기원\n∘ 1.1: Nadam이란 무엇인가?\n∘ 1.2: Nadam이 Adam을 기반으로하는 방식\n\n2: Nadam 뒤에 숨은 메커니즘\n∘ 2.1: 초기화\n∘ 2.2: 각 타임 스텝(𝑡)에 대한 반복적인 업데이트\n∘ 2.3: 네스테로프 모멘텀 보정\n∘ 2.4: 편향 보정\n∘ 2.5: 매개변수 업데이트\n∘ 2.6: Adam과의 주요 차이점\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 실무에서 Nadam 구현하기\n\n- 3.1: Nadam Optimizer 클래스 정의\n- 3.2: 선형 회귀 모델 클래스\n- 3.3: 모델 트레이너 클래스\n- 3.4: 데이터셋 처리 및 모델 훈련\n\n4. 장점과 고려사항\n\n- 4.1 Nadam의 우수성\n- 4.2 한계와 도전 과제\n\n결론\n\n참고문헌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1: 나담: 개념과 기원\n\n## 1.1: 나담이란?\n\n나담은 뉴럴 네트워크를 최적화하기 위해 기계 학습에서 널리 사용되는 아담 옵티마이저를 개선한 것입니다. 이는 아담의 적응 학습률 기능과 네스테로프 모멘텀의 예측 능력을 통합하였습니다.\n\n이 개선은 모델이 수렴하는 속도를 높일뿐만 아니라 복잡한 최적화 과제를 효과적으로 해결하는 방법을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n나담(Nadam) 뒤에 있는 아이디어는 1980년대 유리 네스테로프(Yuri Nesterov)의 선도적인 작업으로 거슬러 올라갈 수 있습니다. 그 당시 네스테로프는 네스테로프의 가속 그래디언트(Nesterov’s accelerated gradient, NAG)를 소개했습니다. NAG의 목표는 기울기 중심의 최적화 알고리즘의 수렴을 가속화하여 기울기의 경로를 가장 낮은 점으로 더 잘 지시하는 것이었습니다. 이 전략을 아담(Adam)의 적응형 학습률 조정과 결합하여, 나담은 이러한 기본 개념을 향상시켜 최적화 알고리즘의 능력을 크게 향상시킵니다.\n\n## 1.2: 나담(Nadam)이 아담(Adam)을 바탕으로 어떻게 구축되는가\n\n나담은 아담이 설정한 프레임워크를 바탕으로 업데이트가 어떻게 계산되는지를 조정함으로써 구축됩니다. 아담이 과거 제곱 기울기와 과거 기울기의 지수 이동 평균을 사용하는 반면, 나담은 기울기 업데이트 규칙을 수정합니다. 나담은 누적된 기울기 방향으로 적극적으로 전진하며, 미래 기울기를 예측하는 종류의 \"모멘텀\"(momentum)을 활용합니다.\n\n이를 더 잘 이해하기 위해 최적화 경로를 보는 것을 상상해보세요. 위의 이미지는 나담과 아담이 최적화 랜드스케이프를 통해 어떻게 이동하는지 개념적으로 보여줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![TheMathBehindNadamOptimizer](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_1.png)\n\n이 그림에서 두 옵티마이저는 동일한 지점에서 시작합니다. \"Adam\"은 효율적인 수렴과 적응력을 나타내는 평탄하고 잘 포장된 고속도로 위에 있습니다. \"Nadam\"은 가끔 충격이 있는 약간 더 구불구불한 도로 위에 있으며 종종 최소값 지점을 향해 더 날카로운 회전을 하곤 합니다. 이러한 행동은 예상 업데이트에 의해 주도되며 Adam보다 덜 최적의 경로를 더 효과적으로 피할 모멘텀을 제공합니다. 이 능력은 Nadam이 Adam과 Nesterov 모멘텀의 강점을 결합하여 복잡한 손실 함수 랜드스케이프에 특히 적합한 강력한 옵티마이저를 형성한다는 것을 보여줍니다.\n\n## 2: Nadam의 작동 메커니즘\n\nNadam은 Adam 옵티마이저의 메커니즘을 Nesterov 모멘텀과 똑똑하게 결합하여 학습을 최적화합니다. 주요 방정식을 살펴보고 Adam과 비교하여 업데이트 규칙의 차이점을 강조해보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2.1: 초기화\n\n시작할 때, Nadam은 첫 번째 및 두 번째 모멘트 벡터를 초기화합니다. 이 벡터들은 기울기와 제곱 기울기의 이동 평균을 저장하는 데 중요합니다. 시간이 지남에 따라 매개 변수 업데이트를 부드럽게 합니다.\n\n![그림](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_2.png)\n\n동시에 우리는 반복의 시작을 표시하는 초기 타임스텝을 설정합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-TheMathBehindNadamOptimizer_3.png\" /\u003e\n\n## 2.2: 각 타임 스텝(𝑡)별 반복적 업데이트\n\n각 반복(𝑡)에 대해, 해당 시점의 매개변수에 대한 손실 함수의 기울기(𝑔_𝑡)를 계산하는 것으로 시작합니다. 이 기울기는 함수의 손실이 가장 빠르게 증가하는 방향을 가리킵니다.\n\n편향된 첫 번째 모멘트 추정값 업데이트\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![매쓰사인네처날날담옵티마이저 그림 4](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_4.png)\n\n첫 번째 모멘트(𝑚_𝑡)는 과거 그래디언트의 지수적 평균이며, 이는 감쇠율(β1, 일반적으로 0.9 주변)을 사용하여 업데이트됩니다. 이 비율은 과거 그래디언트 정보 대비 새 데이터 유지 비율에 영향을 미치며, 더 높은 β1은 더 부드럽지만 더 반응이 느린 추정치로 이어집니다.\n\n편향된 두 번째 모멘트 추정 업데이트\n\n![매쓰사인네처날날담옵티마이저 그림 5](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비슷하게, 두 번째 모멘트 (𝑣_𝑡)은 이전 그래디언트의 제곱의 지수 가중 평균을 추적합니다. 여기서 감쇠율 (β2, 일반적으로 약 0.999)은 매개변수 업데이트의 변동성에 따라 학습률을 조정하여 업데이트를 안정화하는 데 도움을 줍니다.\n\n## 2.3: 네스테로프 모멘텀 보정\n\n![이미지](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_6.png)\n\n여기서 Nadam은 일반적인 모멘트 계산을 수정하여 네스테로프 모멘텀을 통합합니다. 이 접근 방식은 그래디언트의 미래 위치를 예상하여 업데이트 방향을 보정합니다. 이러한 선행은 초기에 제로 초기화된 모멘트가 편향된 업데이트를 초래할 수 있는 훈련 초기에 특히 유용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2.4: 편향 보정\n\n첫 번째 및 두 번째 모멘트 추정치의 편향을 보정하세요:\n\n![Image](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_7.png)\n\n첫 번째와 두 번째 모멘트는 처음에는 영에서 시작하기 때문에 편향되어 있습니다. 이를 극복하기 위해 편향 보정 용어가 도입되었으며, 더 많은 반복이 완료됨에 따라 모멘트의 추정치를 점진적으로 확대하여, 추정치가 시간이 지남에 따라 보다 정확하고 진짜 기울기 정보를 반영하도록 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2.5: 매개변수 업데이트\n\n![Image](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_8.png)\n\n최종 매개변수 업데이트는 기울기의 방향에 대해 조정된 적응형 학습률(𝛼)과 작은 상수(𝜖, 10^(-8)과 같은)로 수치적 안정성을 위해 이루어집니다. 수정된 첫 번째 모멘트(𝑚*𝑡)와 수정된 두 번째 모멘트의 제곱근(𝑣*𝑡)은 이러한 업데이트를 적절하게 조정하는 데 사용되며, 기울기의 방향과 크기를 모두 고려합니다.\n\n## 2.6: Adam과의 주요 차이점\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNadam과 Adam 사이의 주요 차이점은 Nadam이 적극적으로 조정을 합니다. Adam은 현재 기울기 추정만을 의존하는 반면, Nadam은 Nesterov 모멘텀을 통해 앞서 보는 단계를 도입합니다. 이로 인해 미래의 기울기 방향을 예측뿐만 아니라 업데이트를 더 정확하게 조정하여 더 효율적인 학습 역학을 이끌어냅니다.\n\nNadam은 Nesterov 모멘텀의 통합을 통해 최적화에 대해 보다 섬세하고 선심을 기울인 접근 방식을 제공하여 Adam보다 데이터 landscape를 효과적으로 탐색하고 적응하는 능력을 향상시킵니다. 이로써 Nadam은 다양한 머신 러닝 과제에 대한 견고한 선택지가 되며, 실제 결과를 선택할 때 이론적 통찰력과 실용적 결과를 모두 고려하도록 실무자에게 요청합니다.\n\n## 3. 실무에서 Nadam 구현\n\n이 섹션에서는 Nadam 옵티마이저를 처음부터 구축하고 머신 러닝 환경에서 적용할 것입니다. 우리는 선형 회귀 작업에 Nadam 옵티마이저를 구현하고 사용하는 맥락에서 코드를 여러 주요 섹션으로 분할할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래의 코드를 살펴보고 싶다면, 오늘 다룰 코드와 추가적인 보너스 콘텐츠가 모두 포함된 이 Jupyter 노트북을 살펴보는 것을 고려해보세요:\n\n## 3.1: Nadam Optimizer Class Definition\n\nNadam 알고리즘을 사용하여 매개변수를 최적화하는 데 중요한 역할을 하는 NadamOptimizer 클래스를 자세히 살펴봅시다.\n\n```js\nclass NadamOptimizer:\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n        self.learning_rate = learning_rate\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n        self.m = None\n        self.v = None\n        self.t = 0\n\n    def initialize_moments(self, params):\n        self.m = {k: np.zeros_like(v) for k, v in params.items()}\n        self.v = {k: np.zeros_like(v) for k, v in params.items()}\n\n    def update_params(self, params, grads):\n        if self.m is None or self.v is None:\n            self.initialize_moments(params)\n\n        self.t += 1\n        updated_params = {}\n        mu_t = self.beta1 * (1 - 0.5 * 0.96 ** (self.t * 0.004))\n        mu_t1 = self.beta1 * (1 - 0.5 * 0.96 ** ((self.t + 1) * 0.004))\n        for key in params.keys():\n            g_tilde = grads[key] / (1 - np.prod([self.beta1] * self.t))\n            self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n            self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * np.square(grads[key])\n\n            m_corrected = self.m[key] / (1 - mu_t1 ** self.t)\n            v_corrected = self.v[key] / (1 - self.beta2 ** self.t)\n\n            m_bar = (1 - mu_t) * g_tilde + mu_t1 * m_corrected\n\n            updated_params[key] = params[key] - self.learning_rate * m_bar / (np.sqrt(v_corrected) + self.epsilon)\n\n        return updated_params\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNadamOptimizer 클래스는 Nadam 최적화 방법을 관리하고 실행하기 위해 구조화되어 있습니다. 아래는 클래스와 해당 함수들을 설명한 것입니다:\n\n**init** 메서드\n\n```python\nclass NadamOptimizer:\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n        self.learning_rate = learning_rate\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n        self.m = None\n        self.v = None\n        self.t = 0\n```\n\n초기화 메서드는 최적화기를 학습률, 베타 값, 그리고 엡실론에 대한 미리 정의된 설정으로 설정합니다. 이러한 매개변수 각각은 중요한 역할을 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 학습률: 이는 손실 함수의 최소값으로 이동하는 각 반복에서의 단계 크기를 결정합니다.\n- beta1 및 beta2: 이러한 매개 변수는 기울기와 해당 제곱값의 이동 평균의 감쇠율을 제어하며 업데이트를 부드럽게 만들고 학습률을 동적으로 관리하는 데 도움이 됩니다.\n- epsilon: 계산 중에 0으로 나누는 것을 방지하기 위한 매우 작은 수입니다.\n- self.m 및 self.v: 초기에 None으로 설정되며 나중에는 각각 기울기와 제곱 기울기의 이동 평균을 저장합니다.\n- self.t: 업데이트 또는 반복 횟수를 추적하는 카운터입니다.\n\n이 설정은 Nadam의 기본 측면과 일치하며, 적응형 학습률이 지속적으로 조정되어 수렴을 개선합니다.\n\ninitialize_moments 메서드\n\n```js\n    def initialize_moments(self, params):\n        self.m = {k: np.zeros_like(v) for k, v in params.items()}\n        self.v = {k: np.zeros_like(v) for k, v in params.items()}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 메소드는 이동 평균을 저장하는 딕셔너리 m과 v를 초기화합니다. 각 매개변수의 기울기와 제곱 기울기가 0으로 초기화되는데, 이는 최적화 프로세스의 후속 단계에서 계산을 시작하는 데 중요합니다.\n\nupdate_params 메소드\n\n```js\n    def update_params(self, params, grads):\n        if self.m is None or self.v is None:\n            self.initialize_moments(params)\n\n        self.t += 1\n        updated_params = {}\n        mu_t = self.beta1 * (1 - 0.5 * 0.96 ** (self.t * 0.004))\n        mu_t1 = self.beta1 * (1 - 0.5 * 0.96 ** ((self.t + 1) * 0.004))\n        for key in params.keys():\n            g_tilde = grads[key] / (1 - np.prod([self.beta1] * self.t))\n            self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n            self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * np.square(grads[key])\n\n            m_corrected = self.m[key] / (1 - mu_t1 ** self.t)\n            v_corrected = self.v[key] / (1 - self.beta2 ** self.t)\n\n            m_bar = (1 - mu_t) * g_tilde + mu_t1 * m_corrected\n\n            updated_params[key] = params[key] - self.learning_rate * m_bar / (np.sqrt(v_corrected) + self.epsilon)\n\n        return updated_params\n```\n\n이 함수는 Nadam 옵티마이저의 핵심입니다. 전달된 기울기를 기반으로 매개변수를 업데이트합니다. 포함된 단계는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n순간 초기화 확인\n\n```js\nif self.m이 None이거나 self.v가 None이면:\n            self.initialize_moments(params)\n```\n\n만약 m 또는 v가 초기화되지 않았다면 0으로 설정됩니다.\n\n시간 단계 업데이트\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n셀프.티 += 1;\n```\n\ndecay factors를 동적으로 조절하는 시간 단계 t를 증가시킵니다.\n\n네스테로프 모멘텀 조정\n\n```js\n뮤_티 = self.beta1 * (1 - 0.5 * 0.96 ** (self.티 * 0.004));\n뮤_t1 = self.beta1 * (1 - 0.5 * 0.96 ** ((self.티 + 1) * 0.004));\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nmu_t 및 mu_t1은 시간 단계의 진행을 고려하여 Nesterov 모멘텀의 효과를 반영하기 위해 beta1을 조정합니다. 이러한 조정은 모멘텀이 미래의 기울기를 더 효과적으로 반영하도록 합니다.\n\n각 매개변수를 순회하면서:\n\n```js\nfor key in params.keys():\n      g_tilde = grads[key] / (1 - np.prod([self.beta1] * self.t))\n      self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n      self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * np.square(grads[key])\n\n      m_corrected = self.m[key] / (1 - mu_t1 ** self.t)\n      v_corrected = self.v[key] / (1 - self.beta2 ** self.t)\n\n      m_bar = (1 - mu_t) * g_tilde + mu_t1 * m_corrected\n```\n\ng_tilde은 과거 그래디언트의 감쇠를 현재 시간 단계까지 반영한 조정된 기울기를 계산합니다. 이는 lookahead를 포함하여 그래디언트 계산을 수정하여 Nesterov 모멘텀의 효과를 나타냅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n나중에는 새로운 기울기와 조정된 베타 값에 기초하여 각 매개변수에 대해 m과 v를 조정합니다. 이 단계는 과거 기울기의 모멘텀 이점과 새로운 기울기에 대한 적응성을 결합하는 중요한 단계입니다.\n\nm_corrected와 v_corrected는 편향이 수정된 제1 및 제2 모먼트의 추정치를 나타냅니다. 바이어스 보정은 계산된 기울기가 더 적을 때 교육 초기에 중요합니다.\n\nm_bar는 미래의 그래디언트와 모멘텀이 보정된 그래디언트를 결합하여 매개변수 공간에서 취해야 할 단계의 방향과 크기를 효과적으로 결정합니다.\n\n매개변수 업데이트\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nupdated_params[key] = params[key] - self.learning_rate \\* m_bar / (np.sqrt(v_corrected) + self.epsilon)\n\n모든 매개변수는 m_bar와 조정된 학습률에 의해 업데이트되며, v_corrected에 제곱근을 더한 것으로 스케일링됩니다. 이 단계는 실제 매개변수 업데이트가 발생하는 곳으로, 모델의 학습에 직접적인 영향을 미칩니다.\n\n## 3.2: 선형 회귀 모델 클래스\n\n이제 간단한 회귀 모델을 구축하고, Nadam 옵티마이저를 적용해 보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 선형 회귀 모델\nclass LinearRegression:\n    def __init__(self, n_features):\n        self.weights = np.random.randn(n_features)\n        self.bias = np.random.randn()\n\n    def predict(self, X):\n        return np.dot(X, self.weights) + self.bias\n```\n\n여기서 **init** 메서드는 features 수에 기반하여 랜덤한 weights와 biases로 모델을 초기화합니다.\n\n그런 다음 predict 메서드는 입력과 weights 및 bias의 내적을 사용하여 예측을 계산합니다.\n\n여기서 선형 회귀는 Nadam이 어떻게 작동하는지 이해하는 간단한 방법을 제공하지만, 실제로는 더 복잡한 딥러닝 모델에서 Nadam을 사용하려고 할 것입니다. 그렇다면, 가장 인기 있는 딥러닝 모델 중 일부를 포괄적으로 이해할 수 있는 다음의 글을 살펴보고 그 코드를 수정하여 Nadam을 구현해보기를 강력히 추천합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.3: Model Trainer Class\n\n앞으로 나아가봅시다. 이제는 지정된 최적화 도구를 사용하여 머신 러닝 모델을 훈련시키는 전체 과정을 캡슐화하는 클래스가 필요합니다. 이것이 바로 ModelTrainer 클래스가 할 일입니다.\n\n```js\nclass ModelTrainer:\n    def __init__(self, model, optimizer, n_epochs):\n        self.model = model\n        self.optimizer = optimizer\n        self.n_epochs = n_epochs\n\n    def compute_gradients(self, X, y):\n        predictions = self.model.predict(X)\n        errors = predictions - y\n        dW = 2 * np.dot(X.T, errors) / len(y)\n        db = 2 * np.mean(errors)\n        return {'weights': dW, 'bias': db}\n\n    def train(self, X, y, verbose=False):\n        for epoch in range(self.n_epochs):\n            grads = self.compute_gradients(X, y)\n            params = {'weights': self.model.weights, 'bias': self.model.bias}\n            updated_params = self.optimizer.update_params(params, grads)\n\n            self.model.weights = updated_params['weights']\n            self.model.bias = updated_params['bias']\n\n            # Optionally, print loss here to observe training\n            loss = np.mean((self.model.predict(X) - y) ** 2)\n            if epoch % 1000 == 0 and verbose:\n                print(f\"Epoch {epoch}, Loss: {loss}\")\n```\n\n**init** 메서드\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\n    def __init__(self, model, optimizer, n_epochs):\n        self.model = model\n        self.optimizer = optimizer\n        self.n_epochs = n_epochs\n```\n\n이 생성자 메서드는 세 가지 주요 구성 요소로 트레이너를 초기화합니다:\n\n- model: 훈련될 머신러닝 모델이며, 예측을 수행하는 메서드와 매개변수(가중치 및 편향)에 대한 속성이 있어야 합니다.\n- optimizer: Nadam과 같은 옵티마이저 클래스의 인스턴스로, 계산된 그래디언트에 기초하여 모델의 매개변수를 업데이트하는 역할을 담당합니다.\n- n_epochs: 훈련 프로세스가 실행할 훈련 데이터 세트를 전체적으로 순회하는 횟수입니다.\n\n이러한 구성 요소는 손실 함수를 최소화하기 위해 모델의 매개변수가 반복적으로 업데이트되는 훈련 프로세스를 설정하는 데 필수적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ncompute_gradients 메서드\n\n```python\ndef compute_gradients(self, X, y):\n    predictions = self.model.predict(X)\n    errors = predictions - y\n    dW = 2 * np.dot(X.T, errors) / len(y)\n    db = 2 * np.mean(errors)\n    return {'weights': dW, 'bias': db}\n```\n\n이 메서드는 모델 매개변수에 대한 손실 함수의 그래디언트를 계산합니다:\n\n```python\npredictions = self.model.predict(X)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 모델이 현재 매개변수를 사용하여 입력 X를 기반으로 출력을 예측하는 부분입니다.\n\n```js\n오류 = 예측 - y;\n```\n\n이 코드 라인은 예측된 출력과 실제 출력인 y와의 차이, 즉 오차를 나타냅니다.\n\n```js\ndW = (2 * np.dot(X.T, 오류)) / len(y);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 가중치의 기울기를 계산합니다. 가중치에 대한 평균 제곱 오차 손실 함수의 도함수는 len(y)의 데이터 포인트에 의해 조정된 표현으로 주어집니다. 이는 모든 특성과 데이터 포인트에 대한 기울기를 효율적으로 계산하는 벡터화된 구현입니다.\n\n```js\ndb = 2 * np.mean(errors);\n```\n\n마찬가지로, 이는 편향의 기울기를 계산하며, 이는 단순히 오차의 평균에 2를 곱한 것입니다.\n\n```js\nreturn { weights: dW, bias: db };\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러면 메서드는 이러한 그래디언트를 딕셔너리로 반환하여 모델의 매개변수를 업데이트하는 데 사용할 수 있도록 합니다. 이 메서드는 옵티마이저가 손실을 최소화하기 위해 매개변수를 조정해야 하는 필수적인 기울기 계산 단계를 캡슐화합니다.\n\ntrain 메서드\n\n```python\n    def train(self, X, y, verbose=False):\n        for epoch in range(self.n_epochs):\n            grads = self.compute_gradients(X, y)\n            params = {'weights': self.model.weights, 'bias': self.model.bias}\n            updated_params = self.optimizer.update_params(params, grads)\n\n            self.model.weights = updated_params['weights']\n            self.model.bias = updated_params['bias']\n\n            # 선택사항: 여기서 손실을 출력하여 학습을 관찰합니다\n            loss = np.mean((self.model.predict(X) - y) ** 2)\n            if epoch % 1000 == 0 and verbose:\n                print(f\"Epoch {epoch}, Loss: {loss}\")\n```\n\n이 메서드는 각 epoch(데이터를 완전히 통과하는 단계)마다 n_epochs에 이르기까지 반복됩니다. 루프 내에서 현재 매개변수와 데이터 집합에 대해 compute_gradients를 사용하여 그래디언트를 먼저 계산합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그런 다음 이러한 그래디언트를 현재 매개변수와 함께 옵티마이저(self.optimizer.update_params(params, grads))에 전달하고, 옵티마이저는 최적화 알고리즘(예: Nadam)을 기반으로 업데이트된 매개변수를 반환합니다.\n\n모델의 매개변수는 이러한 새 값으로 업데이트되어 손실을 최소화하는 상태로 움직이게 됩니다.\n\nverbose가 True로 설정되어 있는 경우, 메서드는 1000번의 epoch마다 손실을 인쇄하여 교육 진행 상황을 모니터링합니다. 손실은 예측 값과 실제 출력 사이의 평균 제곱 오차로 계산되며, 모델의 성능을 얼마나 잘 평가하고 있는지에 대한 간단한 지표를 제공합니다.\n\ntrain 메서드는 따라서 전체 교육 과정을 조정하며, 손실 함수의 피드백에 기초하여 옵티마이저를 통해 모델의 매개변수를 반복적으로 조정합니다. 이 메서드는 머신러닝에서 사용되는 반복적 최적화 기법의 실용적 구현이며, 그래디언트 하강과 매개변수 업데이트의 이론적 원리를 직접 적용하여 여러 번의 반복을 통해 미리 정의된 손실 함수를 최소화합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.4: 데이터셋 처리 및 모델 훈련\n\n마지막으로, Nadam 옵티마이저를 사용하여 머신러닝 모델을 설정, 훈련 및 평가해 봅시다. 이 접근 방식은 데이터 조작, Optuna를 사용한 하이퍼파라미터 튜닝, 그리고 모델의 효과를 개선하고 평가하기 위한 반복적인 훈련 및 테스트를 포함합니다.\n\n### 3.4.1: 데이터 준비\n\n```python\n# 입력 피처(X) 및 타겟 값(y) 가져오기\nX = diabetes.data\ny = diabetes.target\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우선, 당뇨 데이터셋에서 피처 데이터(X)와 타겟값(y)을 불러옵니다. 이 데이터셋은 sci-kit learn에서 가져오며 상업적 이용이 가능합니다. (Scikit-learn: Python의 머신 러닝, Pedregosa et al., JMLR 12, pp. 2825–2830, 2011.)\n\n```js\n# 데이터셋을 훈련 세트와 테스트 세트로 나눕니다\ndef split_dataset(X, y, test_ratio=0.2):\n    indices = np.random.permutation(len(X))\n    test_size = int(len(X) * test_ratio)\n    test_indices = indices[:test_size]\n    train_indices = indices[test_size:]\n    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n\nX_train, X_test, y_train, y_test = split_dataset(X, y)\nX_train, X_val, y_train, y_val = split_dataset(X_train, y_train)\n```\n\nsplit_dataset 함수는 지정된 비율에 따라 데이터셋을 훈련 세트와 테스트 세트로 무작위로 분할합니다. 데이터셋 인덱스를 섞어 분할을 무작위로 다양하게 만들어 모델 평가를 견고하게 합니다. 훈련 세트는 모델 매개변수를 학습하는 데 사용되고, 테스트 세트는 모델이 보지 못한 데이터에서 얼마나 잘 수행되는지를 평가합니다.\n\n3.4.2: Optuna을 이용한 하이퍼파라미터 튜닝\n우리는 Optuna를 사용하여 모델의 하이퍼파라미터를 최적화할 것이며, 이는 훈련 동적과 Nadam 옵티마이저의 효과에 상당한 영향을 미칩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 기사에서 우리는 옵투나(optuna)를 광범위하게 다루었습니다. 거기에서는 이를 신경망에 적용하여 성공적으로 세밀하게 조정하는 방법을 보여주었습니다. 만약 Nadam을 더 복잡한 모델에 적용하고 싶다면, 이 기사를 읽어보시면 좋을 것 같아요:\n\n목적 함수 정의\n\n```python\ndef objective(trial):\n    n_features = X_train.shape[1]\n\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n    beta1 = trial.suggest_uniform('beta1', 0.9, 0.999)\n    beta2 = trial.suggest_uniform('beta2', 0.99, 0.9999)\n    epsilon = trial.suggest_loguniform('epsilon', 1e-10, 1e-5)\n\n    n_epochs = trial.suggest_int('epochs', 1000, 100000)\n\n    # Define the model\n    model = LinearRegression(n_features)\n    optimizer = NadamOptimizer(learning_rate=learning_rate, beta1=beta1, beta2=beta2, epsilon=epsilon)\n    trainer = ModelTrainer(model, optimizer, n_epochs=n_epochs)\n\n    # Train the model\n    trainer.train(X_train, y_train, verbose=False)\n\n    # Compute the validation loss\n    val_loss = np.mean((model.predict(X_val) - y_val) ** 2)\n\n    return val_loss\n```\n\n우리의 목적 함수는 옵투나(optuna)의 최적화 과정을 안내하는 중요한 역할을 합니다. 각 시도는 다음 값을 제안합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 학습률: 매개변수 업데이트의 단계 크기에 영향을 줍니다.\n- beta1 및 beta2: 그래디언트 및 그들의 제곱값에 대한 평균의 감쇠율을 조절합니다.\n- epsilon: 업데이트 중에 0으로 나누는 것을 방지하기 위해 작은 값이 추가됩니다.\n\n각 시도는 이러한 매개변수를 사용하여 LinearRegression 모델과 NadamOptimizer를 설정하고, ModelTrainer를 사용하여 모델을 훈련합니다. 훈련 후, 검증 세트에서의 검증 손실을 계산하여 하이퍼파라미터의 효과를 Optuna에 제공합니다.\n\n```js\n# 연구 객체 생성\noptuna.logging.set_verbosity(optuna.logging.WARNING)\nstudy = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n\n# 연구 개선, 더 많은 시행을 사용하여 더 나은 결과를 얻거나, 더 적은 시행을 사용하여 더 비용 효율적일 수 있습니다\nstudy.optimize(objective, n_trials=10)\n```\n\nOptuna가 최적의 매개변수를 식별한 후, 최종 모델이 구성되고 훈련됩니다. 이 단계에서는 테스트 세트에서 모델의 일반화 능력을 평가합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n훈련 및 평가\n\n```js\n# 최적 모델 가져오기\nn_features = X_train.shape[1]\nbest_model = LinearRegression(n_features)\noptimizer = NadamOptimizer(learning_rate=study.best_params['learning_rate'],\n                          beta1=study.best_params['beta1'],\n                          beta2=study.best_params['beta2'],\n                          epsilon=study.best_params['epsilon'])\n\n# 모델 훈련하기\ntrainer = ModelTrainer(best_model, optimizer, n_epochs=study.best_params['epochs'])\ntrainer.train(X_train, y_train)\n```\n\nOptuna의 최적 매개변수를 사용하여 모델은 추가 훈련을 받습니다. 이 추가 훈련을 통해 모델이 데이터에 완전히 적응하도록 보장합니다.\n\n```js\n# 테스트 손실 계산하기\ntest_loss = np.mean((best_model.predict(X_test) - y_test) ** 2)**0.5\nprint(f'테스트 손실: {test_loss:.2f}')\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마침내, 새로운, 보지 못했던 데이터에 대한 모델의 예측 정확도를 평가하기 위해 시험 손실을 계산합니다. 이 측정값은 모델의 실용적 성능을 평가하는 데 중요합니다.\n\n# 4. 장점과 고려 사항\n\n## 4.1 Nadam이 뛰어난 점\n\nNadam은 Adam을 바탕으로 네스테로프 모멘텀을 통합하여, 그레이디언트가 믿을 수 없거나 에포크 간 크게 다를 수 있는 복잡한 최적화 작업을 처리할 수 있는 능력을 향상시킵니다. 여기에서 Nadam이 빛을 발합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n딥 뉴럴 네트워크: Nadam은 수렴 속도가 중요한 딥 뉴럴 네트워크의 학습에서 뛰어납니다. 미래를 예측하는 기능이 수렴 속도를 높이는 데 도움을 주어 모델이 최적이 아닌 해결책에 갇히지 않도록 합니다.\n\n희소한 데이터: 텍스트나 대규모 범주형 데이터와 같은 많은 영 피처를 포함한 데이터셋에 대해서는 Nadam이 매개변수 업데이트를 더 효과적으로 조정하여 희소한 정보를 더 잘 관리합니다.\n\n잡음이 많은 데이터: 실시간 스트림이나 온라인 학습과 같이 잡음이 많은 데이터 환경에서는 Nadam의 변동 데이터 처리 및 적응형 학습률 조정이 특히 유용합니다.\n\n## 4.2 한계와 도전과제\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 강점에도 불구하고, Nadam은 항상 최적의 선택이 되지는 않습니다:\n\n간단한 문제: 오차 함수가 잘 행동하고 국소 최솟값이 적은 간단한 작업의 경우, SGD와 같은 간단한 옵티마이저가 연산 요구가 적어 더 효율적일 수 있습니다.\n\n메모리 집약적 모델: Nadam은 그래디언트와 제곱 그래디언트의 모멘트 추정 값을 저장해야 하므로, 더 간단한 방법과 비교하여 메모리 사용량이 증가합니다. 이는 메모리 제한 환경에서 문제가 될 수 있습니다.\n\n하이퍼파라미터 민감도: Nadam의 성능은 𝛽1, 𝛽2 및 학습률과 같은 하이퍼파라미터의 설정에 민감합니다. 올바른 조정을 위해 포괄적인 테스트 또는 하이퍼파라미터 최적화 도구가 필요할 수 있으며, 최적의 성능을 위해 필수적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\nNadam을 탐색하는 것은 Nesterov 운동량과 Adam의 적응형 모멘트 추정을 결합하여 복잡한 머신 러닝 모델을 최적화하는데 중요한 발전을 나타냅니다. Nadam은 Adam에 선행 지식을 추가하여 매개변수 업데이트를 개선하고 수렴 속도를 향상시키며 다양한 어려운 데이터 환경에서 학습 과정을 안정화시킵니다.\n\nNadam은 최적화 알고리즘 분야에서 상당한 향상을 제공하지만, Adam보다 선택하는 것은 머신 러닝 프로젝트의 특정 요구 사항과 제약 사항을 신중히 고려해야 합니다. 최적화 기술의 지속적인 진화는 능력을 향상시키고 새로운 가능성을 열어주며, 더 많은 연구와 실험을 위한 활기찬 분야로 만들어 냅니다.\n\n# 참고문헌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Dozat, T. (2016). “Incorporating Nesterov Momentum into Adam.” ICLR Workshop.\n- Kingma, D. P., \u0026 Ba, J. (2014). “Adam: A Method for Stochastic Optimization.” arXiv preprint arXiv:1412.6980.\n- Nesterov, Y. (1983). “A Method for Unconstrained Convex Minimization Problem with the Rate of Convergence 𝑂(1/𝑘2)O(1/k2).” Doklady AN USSR.\n- Ruder, S. (2016). “An overview of gradient descent optimization algorithms.” arXiv preprint arXiv:1609.04747.\n- Bottou, L., Curtis, F. E., \u0026 Nocedal, J. (2018). “Optimization Methods for Large-Scale Machine Learning.” SIAM Review, 60(2), 223–311.\n- Zhang, M. R., Lucas, J., Ba, J., \u0026 Hinton, G. E. (2019). “Lookahead Optimizer: k steps forward, 1 step back.” arXiv preprint arXiv:1907.08610.\n\n당신은 끝까지 왔습니다. 축하해요! 이 기사를 즐겼다면 좋아요를 누르고 저를 팔로우해주시면 감사하겠습니다. 저는 주기적으로 비슷한 기사를 게시할 것이기 때문에, 재미있게 보아 주실 것을 희망합니다. 제 목표는 가장 인기 있는 알고리즘을 모두 처음부터 다시 만들어 기계 학습을 모두에게 접근 가능하게 하는 것입니다.\n","ogImage":{"url":"/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png"},"coverImage":"/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png","tag":["Tech"],"readingTime":32}],"page":"71","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"71"},"buildId":"bb_yO9GbCvdfc_n71SfUf","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>