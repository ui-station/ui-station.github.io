<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/90" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/90" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/-dPCbnM2yhdKNgXe92VJV/_buildManifest.js" defer=""></script><script src="/_next/static/-dPCbnM2yhdKNgXe92VJV/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="고객 이탈 예측" href="/post/2024-05-18-CUSTOMERCHURNPREDICTION"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고객 이탈 예측" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고객 이탈 예측" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고객 이탈 예측</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="휴머노이드는 여기에 머물러 있을까요" href="/post/2024-05-18-AretheHumanoidsHeretoStay"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="휴머노이드는 여기에 머물러 있을까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="휴머노이드는 여기에 머물러 있을까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">휴머노이드는 여기에 머물러 있을까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="필수 인공지능" href="/post/2024-05-18-EssentialAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="필수 인공지능" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-EssentialAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="필수 인공지능" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">필수 인공지능</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="SLAM을 처음부터 구현해 보기" href="/post/2024-05-18-ImplementSLAMfromscratch"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="SLAM을 처음부터 구현해 보기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-ImplementSLAMfromscratch_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="SLAM을 처음부터 구현해 보기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">SLAM을 처음부터 구현해 보기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="로봇 학습의 현황" href="/post/2024-05-18-TheStateofRobotLearning"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="로봇 학습의 현황" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TheStateofRobotLearning_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="로봇 학습의 현황" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">로봇 학습의 현황</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" href="/post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이 5에서 VSCode 서버 다시 시도하기" href="/post/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이 5에서 VSCode 서버 다시 시도하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이 5에서 VSCode 서버 다시 시도하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">라즈베리 파이 5에서 VSCode 서버 다시 시도하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이 웹사이트 만들기" href="/post/2024-05-18-CreatingaRaspberryPIWebsite"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이 웹사이트 만들기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이 웹사이트 만들기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">라즈베리 파이 웹사이트 만들기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이로 쿠버네티스 클러스터 구축 가이드" href="/post/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이로 쿠버네티스 클러스터 구축 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이로 쿠버네티스 클러스터 구축 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">라즈베리 파이로 쿠버네티스 클러스터 구축 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="러스트 앱을 여러 아키텍처용으로 크로스 컴파일하기" href="/post/2024-05-18-Cross-compileyourRustappformultiplearchitectures"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="러스트 앱을 여러 아키텍처용으로 크로스 컴파일하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-Cross-compileyourRustappformultiplearchitectures_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="러스트 앱을 여러 아키텍처용으로 크로스 컴파일하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">러스트 앱을 여러 아키텍처용으로 크로스 컴파일하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/81">81</a><a class="link" href="/posts/82">82</a><a class="link" href="/posts/83">83</a><a class="link" href="/posts/84">84</a><a class="link" href="/posts/85">85</a><a class="link" href="/posts/86">86</a><a class="link" href="/posts/87">87</a><a class="link" href="/posts/88">88</a><a class="link" href="/posts/89">89</a><a class="link posts_-active__YVJEi" href="/posts/90">90</a><a class="link" href="/posts/91">91</a><a class="link" href="/posts/92">92</a><a class="link" href="/posts/93">93</a><a class="link" href="/posts/94">94</a><a class="link" href="/posts/95">95</a><a class="link" href="/posts/96">96</a><a class="link" href="/posts/97">97</a><a class="link" href="/posts/98">98</a><a class="link" href="/posts/99">99</a><a class="link" href="/posts/100">100</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"고객 이탈 예측","description":"","date":"2024-05-18 19:26","slug":"2024-05-18-CUSTOMERCHURNPREDICTION","content":"\n이것은 이진 분류 문제이며, 은행 데이터 세트를 사용했습니다. 고객이 은행을 떠날 때에 대한 정보가 포함되어 있으며, 이를 사용하여 미래에 은행을 떠날 가능성이 있는 고객을 예측해야 합니다.\n\n![이미지](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png)\n\n우리는 인공 신경망을 구축할 것입니다. 이러한 문제에 접근하는 단계는 다음과 같습니다 —\n\n- 특정 라이브러리 가져오기\n- 데이터 세트 로드, 데이터 세트에 대한 가능한 정보 찾기(예: 데이터 세트에 결측값이 있는지, 중복된 값의 존재 여부)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_1.png\" /\u003e\n\n- 고객이 나간 수를 확인하기 위해 동일한 것을 나타내는 이 코드를 사용했습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_2.png\" /\u003e\n\n- 이제 데이터 세트를 분석하고 ('RowNumber', 'CustomerId', 'Surname')와 같은 열이 예측에 큰 영향을 미치지 않으므로 삭제할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![데이터1](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_3.png)\n\n- 추가로, ONE HOT ENCODING을 사용하여 범주형 값들을 변환하겠습니다. get_dummies() 및 (drop_first=True)를 사용하면 지리와 성별에서 다른 하나를 삭제할 수 있습니다(예: 프랑스 및 여성).\n\n![데이터2](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_4.png)\n\n- 모델을 훈련 및 테스트 데이터셋으로 분할합니다.\n- 이제 값들을 스케일링할 것입니다. 'balance'와 'estimated_salary'의 값이 매우 크기 때문에 발생하는 문제를 방지하기 위해 StandardScaler()를 사용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_5.png\" /\u003e\n\n- 케라스 라이브러리를 사용하여 순차적 모델에 대한 'model' 객체를 만듭니다.\n- 그런 다음 레이어(은닉, 출력)를 추가합니다.\n- 시그모이드 활성화 함수를 사용하고, 입력이 11(탈퇴 제외)인 3개 노드를 갖는 밀집 은닉 레이어를 추가합니다.\n- 출력 레이어를 추가합니다.\n- summary를 확인하면 매개변수(가중치 + 편향)를 제공합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_6.png\" /\u003e\n\n- 이제 모델을 컴파일해야 합니다. 어떤 손실 함수, 옵티마이저를 사용할 것인지 지정해야 합니다. 바이너리 분류 문제이므로 사용되는 손실 함수는 크로스 엔트로피/로그 손실입니다. 다양한 옵티마이저(경사 하강법, 확률적 경사 하강법, RMSprop 등)를 사용할 수 있지만 아담(적응 모멘트 추정)이 잘 작동합니다.\n- 모델을 적합하고 10회 반복(에포크)하며 'history'라는 딕셔너리에 저장합니다. Validation_split은 모델을 훈련하는 지점을 처리하는데 사용됩니다. 예를 들어 8000개의 항목이있는 경우 이를 나누고 2000개의 항목을 제거하며 실행 중에 2000개의 포인트를 동시에 확인하고 정확성을 알려줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Customer Churn Prediction 7](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_7.png)\n\n- 이제 배열 안에 가중치(weights)와 편향(biases)을 얻을 수 있습니다.\n\n![Customer Churn Prediction 8](/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_8.png)\n\n- 이제 예측이 나오게 됩니다. 시그모이드 함수를 사용하기 때문에 출력은 (0-1)의 범위에 있을 것입니다, 확률입니다. 우리는 이 확률을 0 또는 1로 변환해야 합니다, 그러기 위해 임계값을 정해야 합니다 (예를 들면 0.5, 만약 확률이 0.5보다 작으면 고객이 은행을 떠나지 않고, 확률이 0.5보다 크면 그들은 은행을 떠날 것입니다.) 임계값은 일반적으로 도표를 통해 결정되지만, 여기서는 추측하고, 0.5로 설정되어 있습니다.\n- 그러면 모델의 정확도 점수를 찾을 준비가 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_9.png\" /\u003e\n\n- 또한 matplotlib을 사용하여 그래프를 그릴 수 있습니다.\n\n## 참고 — 정확도를 높이기 위해 다음을 증가시킬 수 있습니다:\n\n- epoch의 수를 증가시킴.\n- 은닉층의 활성화 함수를 relu로 설정.\n- 은닉층의 노드 수를 증가시킴.\n- 또는 은닉층의 수를 증가시킴(과적합이 발생할 수 있으므로 적당히).\n","ogImage":{"url":"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png"},"coverImage":"/assets/img/2024-05-18-CUSTOMERCHURNPREDICTION_0.png","tag":["Tech"],"readingTime":4},{"title":"휴머노이드는 여기에 머물러 있을까요","description":"","date":"2024-05-18 19:24","slug":"2024-05-18-AretheHumanoidsHeretoStay","content":"\n매주 이런 식으로 새로운 업데이트를 내놓는 인간형 회사들을 볼 수 없네요. 옵티머스가 걸을 수 있어요? 디지트가 빈 토트백을 옮겼다구요? 피거도 그렇게 하는군요! 드디어 실제 회사들도 흥미를 느끼기 시작한 것 같아요. 테슬라부터 시작해서 아마존과 BMW에서도 이제는 \"작동 중\"이랍니다. 마치 집과 정원에서 우리에게 한 발짝 떨어진 것 같아요.\n\n하지만 정말로 일하고 있는 걸까요? 보여지는 데모들은 보스턴 다이내믹스의 아틀라스가 파크our을 하는 것만큼 흥미로운 것이 아니라 humanoids가 생산적인 것 같지도 않아요. 그래서 시장이 정말로 흥분한 것일까요? Humanoids가 무언가를 준비하고 있는 걸까요? 저는 두 가지 이유로 humanoids에 흥분해요:\n\n1. 인간형 로봇은 마침내 \"브라운필드\" 문제를 해결할 수도 있어요. 이것이 로봇 솔루션들이 실험 단계에 머무는 주된 이유이기도 하거든요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 2023년에 기계 학습은 큰 발전을 이루었습니다. 컴퓨터들이 이번에 처음으로 노력의 스킬을 발휘하여 오픈 월드 환경에서 작동하고 접촉 시키는 것이 가능해졌습니다.\n\n# Greenfield vs. Brownfield\n\n로봇 공학은 아직 큰 산업이 아니며 대부분의 산업은 “Greenfield” 배치로만 성공을 거둡니다. 기존 공정을 개조하는 대신, 공장과 그 제품을 로봇 솔루션 주위에 설계합니다. 이것이 ABB, Fanuc 및 Kuka와 같은 기업들이 수익을 올리는 방식이며 자동차 산업을 위한 생산 라인과 같은 전문 솔루션을 구축합니다. 아마존도 이와 같은 원리로 Kiva 자동화 시스템과 함께 작동하는 건물 구축을 하고 있습니다. 반면, 기존 공정과 통합되는 솔루션 (기존 토지 또는 \"갈색\" 영역에)은 종종 생산적으로 성공하지 못하고 버려지는 경우가 많습니다.\n\n아래 이미지는 이러한 딜레마를 설명합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-18-AretheHumanoidsHeretoStay_1.png](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_1.png)\n\n작지만 성공한 커피 사업을 상상해보세요. 이 사업은 역사적으로 분리된 분쇄기, 커피 포트 및 열판을 사용하여 커피를 만들어 왔습니다. 여기에 \"협력 로봇\"이라는 자동화된 과정이 도입됩니다. 이런 로봇은 커피 포트를 열판 위에 놓는 등 일부 작업만 수행할 수 있고, 추가적인 장비들을 필요로 합니다. 이런 해결책은 기존 과정을 준비된 자동화 솔루션으로 교체하는 것이 실제로 쉽고 저렴하게 가능합니다. 에스프레소 메이커만 사면 끝이죠. 수동으로 만든 커피에 집착하는 사람들처럼, 산업 환경에서의 공정은 종종 다른 공정과 깊게 연결되어있어 하류 공정을 변경해야 할 수도 있습니다.\n\n(계속)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 매우 기본적인 작업들 다음에는 조립 작업장을 위한 키트를 생성하고 배포하고, 슈퍼마켓 선반이 깔끔하고 적절히 구비되어 있는지 확인하거나 식기 세척기, 커피 메이커 및 진공 청소기와 같은 가정용 가전제품을 작동하는 등 보다 복잡한 작업을 빠르게 수행하게 될 것입니다.\n\n하지만 또 다른 이점도 있습니다: 전력에 연결되었거나 무선으로 충전 중이라면, 인간형 로봇은 휴식 없이 세 번의 교대 근무를 할 수 있으며, 학습한 모든 것은 즉시 동종 로봇들 모두에게 전달될 수 있습니다. 더욱 좋은 점은, 일단 인간형 로봇이 프로세스에 통합되면, 알고리즘을 통해 작업자들로부터 과도한 정직을 요구하는 Lean 및 Six-Sigma의 모든 기술을 완전히 디지털 방식으로 구현할 수 있게 되어 엄청난 생산성 향상을 이끌어낼 수도 있습니다.\n\n![이미지](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_2.png)\n\n투자자, 기업가 및 과학자들을 흥분하게 만드는 것은 이런 전망이며, 비록 게임이 오래 소요될 지라도요. 그럼에도 불구하고, 2023년에 역사책에 기록된 또 다른 Durchbruch 덕분에 아마도 많은 사람들이 모두 출자하지 않을까 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 기계 학습이 이끄는 전례 없는 능력\n\n2023년은 ChatGPT의 해였습니다. ChatGPT의 명백한 이점 외에, 트랜스포머 신경망 구조는 텍스트에 국한되지 않고 훨씬 더 강력해졌다는 것이 밝혀졌습니다. 그것은 이미지와 언어를 결합하는 능력으로 인해 기계 학습이 미리 정의된 클래스로의 지도 학습을 벗어나게 하였고, 로봇이 이전에 본 적이없는 물체를 다루도록 허용하였습니다. 예를 들어, \"나사\"라는 물체를 이미지에서 제로샷 방식으로 찾을 수 있는 Owl-VIT [1] 비전-언어 모델이 있습니다. \"나사\"가 무엇이며 어떻게 생겼는지에 대해 명시적으로 학습되지 않고도 가능합니다.\n\n![이미지](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_3.png)\n\n라벨링 및 물체 탐지가 완벽하지는 않지만, 비전 임베딩은 원격 조작된 데모와 결합하여 확산을 사용하여 시각 운동 표현을 학습할 수 있도록 허용합니다[2]. 마치 DallE나 Midjourney에서 이미지를 생성할 때 사용되는 방식과 유사합니다. 로봇은 텍스트를 프롬프트로 변환하는 대신, 센서 관측치를 궤적으로 변환합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인간을 훈련시킬 때와 달리 현장에 배치된 로봇이 생산한 경험은 쉽게 다른 로봇으로 전달될 수 있습니다. 여기서 심지어 소수의 인간형 프로토타입만으로도 다양한 제조 및 가정 업무에 대한 전문 지식을 통한 무료롭 처리 양을 만들어낼 수 있습니다. 트랜스포머 모델이 자연스럽게 멀티모달이기 때문에 시각과 텍스트/음성 설명만 적용하는 것이 아니라 촉각적 정보, 소리 또는 진동을 받아들이고, 시맨틱한 구조화 정보와 연결하는 데 도움이 될 것입니다.\n\n대형 언어 모델은 또한 인간 언어와 컴퓨터 코드 사이를 매끄럽게 오가며 소프트웨어 습득 및 인간 피드백을 기반으로 코드를 적절하게 수정할 수도 있을 것입니다. 최근 이 논문[3]과 이 비디오에서 보여준 것처럼, 로봇의 가능성에 대한 \"API\"를 제공받음으로써 ChatGPT는 합리적인 코드를 생성하고 인간 피드백에 따라 조정할 수 있습니다. 인간 지침서, 책 지식 또는 이 두 가지의 조합에서 위와 같은 예시인 전문적인 로봇 임무를 빠르게 학습할 수 있는 능력을 가진 LLM을 인터랙션 훈련을 통해 미세조정함으로써 더 향상시킬 수 있을 것입니다.\n\n# 다음은 무엇일까요?\n\n그래서 우리는 대규모로 인간형 로봇을 배치할 준비가 되어 있고, 곧 더 매력적인 사용 사례들을 보게 되겠죠? 많은 기업들이 하드웨어 중심 접근 방식을 선택하여 동적 보행과 기본 조작이 가능하다는 것을 입증했습니다. 아직은 이 로봇들이 많은 것을 실제로 하거나 더 많은 가치를 창출하지는 못하고 있습니다. 고가치 임무인 자율 키팅, 조립 또는 선반 보충과 같은 임무는 이미 어느 정도 시간이 경과했으며 이전 창업 시절에도 가능했습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 비디오에 나오는 산업용 하드웨어와 현재 볼 수 있는 휴머노이드 사이에 중요한 차이가 있습니다. 처음부터 로봇을 만드는 것은 심각한 시스템 공학적 도전이 따르며 현재의 프로토 타입은 안정적인 기지에 장착된 협력 로봇의 0.1mm 정확도에서 현재는 상당히 멀리 떨어져 있을 것으로 보입니다. 관성과 진동을 제어하는 어려운 작업은 물론 토크 감지를 사용하여 이를 가능케하지만 대부분의 휴머노이드는 아직 이 기능이 없는 액추에이터에 의존하지만 저렴한 비용 접근 방식을 택하여 엔지니어링 아츠의 아름다운 로봇이 뻣뻣한 산업 시스템과 유사하다고 할 수 있을 정도의 선택을 했습니다.\n\n따라서 다리가 없는 휴머노이드는?\n\n누구나 로봇이 바로 다리가 필요할 것이라고 믿지 않습니다. 이러한 기업은 고가치의 조작 작업, 훈련 용이성 및 매끄러운 배치에 중점을 둡니다. 이 분야의 초기 사례 중 하나는 Rodney Brook의 \"배터\" (안식을 바라며) 로봇이며 나중에는 그의 한 팔로 된 후속자인 소이어가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBaxter가 슈퍼 저렴한 비용(`$25k에 이중 팔로봇)을 정밀성과 강성으로 바꾸는 지나치게 야 amb 계약의 하드웨어 디자인을 겪던 동안, Sawyer는 보다 전통적인 로봇 드라이브를 사용하여 최소한의 조립물과 기본적인 프로그래밍만으로도 다양한 응용 분야에서 성능을 발휘할 수 있습니다. Sawyer는 아직 몇몇 국가에서 판매 중이지만, 모든 “Cobots”이 겪는 브라운필드 문제에 시달립니다: 작업이 자동화 솔루션이 정당화할만큼 반복적인 경우, 이미 해당 솔루션이 만들어졌으며 상당히 더 나은, 빠르고 저렴할 가능성이 높습니다.\n\n“정체된 상반신” 방식의 또 다른 예는 Giant AI인데, 이는 2023년에 공개되고 (사업을 종료한 채) 잠잠하게 알려진 비디오 시리즈로 나타났습니다:\n\nBaxter와 마찬가지로, Giant의 Universal Worker는 기본 조작에 중점을 둔 정적 솔루션이었습니다. Baxter와 같이, Giant는 모든 하드웨어를 처음부터 개발했으며 힘줄 기반 접근법을 구현하여 (잠재적인) 비용 절감을 굉장한 개발 관리부담과 정확성으로 교환했으며, 제 시간에 진정한 고객 가치를 제공하지 못했습니다.\n\nGiant의 일부 지적재산권은 Sanctuary.ai에서 살아 있으며, 여기서도 상체 민첩성에 중점을 두지만, 유압 구동 재래를 복원함으로써, 로봇이 정밀한 조작부터 무거운 들기까지 다양한 작업 범위에 대처할 수 있도록 해줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 인간 모양은 맞지만 걷지는 않아요?\n\n로봇을 특정 장소에 제한하는 것은 이전에 좋은 생각이 아니었습니다. 왜냐하면 브라운필드 문제를 해결하지 못했기 때문입니다. 동일한 장소에서 상당한 시간을 보내는 로봇은 보다 효율적으로 자동화할 수 있는 작업에 종사하는 것일 가능성이 높습니다. 또한 이동성은 배치의 다양성만을 고려하는 것이 아니라, 로봇이 더 넓은 작업 공간에 대응하고 도구와 부품을 스스로 가져올 수 있게 해줍니다. 그렇다고 해서 즉시 다리가 필요한 건 아닐까요?\n\n회사들은 이 가설을 테스트하기 위해 인간형 상반신과 저렴하고 견고한 구동 장치를 결합해봅니다. 예를 들어, 1X 로보틱스(1X robotics)…\n\n…영상에서 보여지는 것 이상의 작업을 수행하려면 소프트웨어 업데이트 이상이 필요할 것입니다)과 바닥에서 물건을 줍는 능력을 결합한 상반신의 민첩성과 인간의 발자국만 조금 더 큰 바퀴 플랫폼을 함께 사용합니다. 산업용 공동 로봇의 성능을 얻는 것은 여전히 매우 어려울 것이며, 작은 바퀴 기반으로 인해 로봇이 운반할 수 있는 하중이 제한될 것입니다. 이러한 로봇은 따라서 인간과 로봇의 흥미로운 상호 작용을 창출하는 데 굉장히 뛰어난 '페퍼'처럼 많이 능력있지는 않지만, 다리가 달린 플랫폼의 이동성이나 협업 로봇의 일군 능력만큼은 갖춘 것이 아닙니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n작은 휠베이스는 동적 안정성을 제한하는 기회를 줄입니다. 이는 Boston Dynamics의 - 극도로 익살스러운 - 핸들 로봇들에서 나타납니다. 이 로봇들은 카운터 웨이트를 움직여 세그웨이와 같은 드라이브 체인에서 균형을 맞춰 다양한 하중 조건에 적응할 수 있습니다.\n\n아마도 주위에 있는 사람들이 이 두 친구 가까이 다가가지 못한 것을 눈치챘을 겁니다. 실제로, 어떠한 형태의 동적 활동도 일반적으로 안전하지 않습니다. 이것이 신뢰할 만한 동적 보행을 시연하는 것이 결핵되는 연결고리이자 많은 데모의 중심 주제인 이유입니다.\n\n# 인간형 로봇 경주에서 우승하기\n\n하지만 이 파도가 줄어들지 않으려면, 인간형 로봇은 가능한 빨리 생산 환경으로 이동해야 합니다. 이는 동시에 어느 정도의 소프트웨어와 하드웨어 혼합을 제공해야만 가능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 기존 설치물, 도구, 및 장치를 쉽게 활용할 수 있는 인간 근로자의 형태 요인,\n- 개방형 세계에 대한 쉬운 범용화와 훈련 가능성을 갖춘 인간 근로자의 기능성,\n- 그리고 최소한의 조작 기술 세트,\n\n몇 가지 특정 사용 사례에 대한 브라운필드 문제를 해결하는 데 충분합니다. 언제나 새로운 하드웨어를 개발하는 것은 일반적으로 좋지 않은 생각입니다. 학습과 교육을 더욱 쉽게 만드는 것이 아니라 어렵게 하는 경우가 많습니다. 인간형 로봇이 고객 가치를 창출하고, 책지식과 시각-촉각적 경험을 결합한 다중 모드 기반 모델을 위한 데이터 기초를 먼저 제공할수록 좋습니다.\n\n# 참고 문헌\n\n[1] Minderer, M., Gritsenko, A., Stone, A., Neumann, M., Weissenborn, D., Dosovitskiy, A., Mahendran, A., Arnab, A., Dehghani, M. and Shen, Z., Simple open-vocabulary object detection with vision transformers. arXiv 2022. arXiv preprint arXiv:2205.06230.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[2] Chi, C., Feng, S., Du, Y., Xu, Z., Cousineau, E., Burchfiel, B. and Song, S., 2023. Diffusion policy: Visuomotor policy learning via action diffusion. arXiv preprint arXiv:2303.04137.\n\n[3] Liang J, Xia F, Yu W, Zeng A, Arenas MG, Attarian M, Bauza M, Bennice M, Bewley A, Dostmohamed A, Fu CK. Learning to Learn Faster from Human Feedback with Language Model Predictive Control. arXiv preprint arXiv:2402.11450. 2024 Feb 18.\n","ogImage":{"url":"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png"},"coverImage":"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png","tag":["Tech"],"readingTime":10},{"title":"필수 인공지능","description":"","date":"2024-05-18 19:21","slug":"2024-05-18-EssentialAI","content":"\n르네상스 시대에는 1480년경 레오나르도 다 빈치가 헬리콥터에 대한 창의적인 개념을 그린 것으로 알려져 있지만, 그 꿈을 상용화되고 신뢰할 수 있는 제품으로 만드는 데에는 별도의 혁명인 산업혁명이 필요했습니다. 마찬가지로, 생성 적 인공지능이 우리 사무실에 딸린 로봇이 딸기를 수확하고 있는 매력적인 오일 페인팅을 선사했지만, 농업 산업에 수익성 있고 신뢰할 수 있는 수확 로봇을 제공하기 위해서는 인공지능에 대해 근본적으로 다른 접근 방식이 필요하다고 믿고 있습니다.\n\n![이미지](/assets/img/2024-05-18-EssentialAI_0.png)\n\n인공지능 르네상스가 도래했습니다\n\n우리 모두가 경험하는 것처럼, 인공지능 르네상스가 왔습니다. “Attention Is All You Need”이라는 위대한 논문이 트랜스포머 모델의 붐을 일으키기 시작했지만, 최초의 대중적인 붐은 ChatGPT 3와 4로 시작되었으며, 그 뒤에는 생성 적 인공지능의 대규모 확장이 이어졌습니다. 이번 주에는 OpenAI의 GPT-4o와 Google Gemini이 실시간 언어 번역, 코드 분석 및 다양한 흥미로운 \"AI 어시스턴트\" 응용 프로그램을 포함한 경이로운 실시간 시연을 선보였습니다. 인간형 로봇도 뜨거운 관심을 받고 있습니다 - 투자자들이 지난 12개월 동안 인공지능 주도의 인간형 로봇에 수십억 달러를 투자했습니다. RT-2 및 RT-X와 같은 프로젝트는 인간형 로봇을 위한 폭넓은 텍스트 - 행동 및 제로샷 학습 응용 프로그램을 꿈꾸고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n토르투가에서는 AI 르네상스를 신뢰합니다: 우리는 AI 로봇을 사용하여 과일을 따거나 다른 중요한 농업 서비스를 제공합니다. 또한, 현재의 AI 붐은 실제 현실 자동화의 거대한 경제적 결과로 이끄는 것은 아니라고 믿습니다. 우리가 AI 산업 혁명으로 전환할 때에 이뤄질 것이라고 생각합니다. 다 빈치의 르네상스는 \"공중 나사\"와 같은 혁신과 학습의 폭발을 가져왔지만, 이러한 인상적인 논문상 아이디어들이 실제로 수익 창출 규모에서 이륙할 수 있었던 것은 산업 혁명이 일어날 때였습니다.\n\nAI 르네상스의 문제\n\n대부분의 주요 AI 프로젝트는 “인공 일반 지능”에 대해 구축하고 있습니다. 르네상스처럼, 그들은 다 빈치와 같은 모델을 만들고 있습니다. 그들은 예술가, 건축가, 의사 또는 엔지니어의 역할을 수행할 수 있습니다. 그리고, 그들은 “초심주의” 방법을 사용하여 구축하고 있습니다 — 큰 모델, 큰 훈련 인프라, 큰 팀 및 큰 돈이라는 것을 의미합니다. 이는 대규모 언어 모델(LLMs)과 Foundation 모델에도 적용됩니다. 이들의 훈련 비용은 수천만 달러에서 수억 달러로 증가하고 있으며, 인간형 로봇에서도 마찬가지입니다. 비싼 \"모든 것의 로봇\"을 목표로 삼아서 같은 변압기 기반 강화 학습 방식을 백업하고 있습니다.\n\n최근 OpenAI의 Sam Altman이 말한 것처럼,\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"매년 5억 달러, 50억 달러 또는 500억 달러를 태울지라도 상관없어요. 정말로 상관하지 않아요. 사람들에게 정말 능력있는 도구를 제공하고 이를 활용해 미래를 만들어가도록 하는 것이 정말 좋은 일이라고 생각해요. 여러분과 세계의 모든 다른 사람들의 창의력에 베팅하고 싶어요. 이 문제에 대해 어떻게 대처할지 찾아내기 위해.\n\n막강한 접근법은 AGI를 구축하는 데 맞을 수 있지만, Altman이 가치를 창출될 것으로 가정하는 곳에서, 우리는 많은 노력을 본다는 것을 알아요. 인상적인 프로토타입에서 경제적으로 실현 가능한 제품까지 혁신하는 데는 엄청난 노력이 필요해요. AI 레온아르도 다빈치가 상상한 헬리콥터의 아이디어를 생성한 후, 실제 헬리콥터를 어떻게 만들어야 할까요? 누가 7만 대를 제작하고 판매하며 유지할 것인가요? Tortuga에서는 첫 번째 프로토타입 로봇부터 150대의 저렴하고 특수화된 로봇으로 구성된 상업용 농장 규모의 플릿을 구축했어요. 수백만 개의 딸기를 수확했고, 굉장히 효과적이면서도 저렴한 로봇과 AI/ML 스택을 통해 그렇게 했어요.\n\n우리의 첫 번째 신념은 더 열린, 종합적인 방식으로 혁신하는 것이 가치가 있다는 것이지만, 산업 경제의 기반이 되는 일들을 해결하려고 할 때, 빅 AI는 깊고 구체적이며 반복 가능한 물리적 작업을 해결하려 할 때 덜 효과적이라는 것입니다.\n\n전문화: 르네상스는 산업 혁명이 필요합니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nChatGPT4의 다양한 테스트 결과는 정말 인상적입니다. 마찬가지로 Waymo는 피닉스와 샌프란시스코에서 운영 중입니다. AI 로봇들은 오늘날 현실 세계에서 운전할 수 있습니다. 하지만 3D 물리 세계의 작업은 순수 텍스트나 2차원 도로 시스템의 작업에 비해 자동화하기가 훨씬 더 복잡한 것으로 입증되었습니다. 메타의 주요 AI 과학자인 Yann LeCun은 이 복잡성 차이를 언급했습니다. 현실 세계가 쓰인 세계보다 훨씬 더 복잡하고 \"심층적\"이라고 말했습니다.\n\n토르투가의 맥락에서, 만약 최대주의 AI 휴머노이드인 AI 레오나르도가 ChatGPT4처럼 딸기를 고르는 데 90%의 점수를 얻을 수 있다 해도 충분하지 않습니다. 토륄투가 로봇이 10%의 실수를 하면, 우리는 고객의 수익의 10%를 파괴하고 자동화의 가치에 반대하게 됩니다. 인간은 완벽하지 않습니다. 그래서 우리의 기준은 100%가 아닌 대략 97% 정확도입니다. 그러나 97%는 단순히 \"90%보다 7점 높은 것\"이 아닙니다. 물리적 세계에서는 한 차원 이상 더 어려운 문제입니다. 산업 프로세스에서는 우리 사회의 기초를 이루는 일과 작업들이 매주 수백만 번 실행되어야 하며, 매우 높은 정밀도(95% 이상)로 실행되어야 합니다. 그 이유는 비용, 이윤 및 효율성이 깊게 중요하기 때문입니다.\n\n르네상스 방식의 대규모 AI는 광범위한 기반 모델 기반 접근법을 사용하고 극도로 견고한 데이터셋, 시뮬레이션 환경, 합성 데이터 생성 및 대규모 교육 파이프라인을 사용하여 엣지 케이스와 성능 개선을 위해 큰 비용의 투자주기를 갖습니다. 그러나 거의 모든 로봇 환경에서 특히 농장에서는 매우 미묘하고 동적인 엣지 케이스가 많이 존재합니다. 농장에서는 과일과 식물/농업 구조, 해충, 과일 종류, 그리고 온도, 습도, 햇빛 세기, 바람, 비와 같은 환경 조건과의 상호 작용이 크게 다르고 변하기 때문입니다. 물리학적 모델은 개별 과일이 바람에 흔들리거나 로봇에 닿거나 하나씩 딸릴 때의 상호 작용과 같은 필요한 복잡성을 충분히 전달하지 못하기 때문에 시뮬레이션의 효과는 제한됩니다. 특히 유기적 시스템에 대한 합성 데이터는 우리에게 가장 기본적인 사용 사례를 넘어서는 것이 너무 단순해서 우리에게 혜택을 주지 못합니다. 서로 다른 과일에 대한 견고한 실제 세계 데이터셋은 없고, 현존하는 공개 노력은 우리의 특정 센서, 로봇 구조 또는 인지 방식에 적용되지 않는 \"최소 공통 분모\" 데이터셋입니다. 로봇 공학에서 일반화 학습 접근 방식을 추구하려는 많은 학문적 노력이 있지만, 이러한 도전에 아직까지 좋은 답을 찾지 못했습니다. 이 도전 과제의 섹션에서 다루었던 것처럼요.\n\n이제 두 번째 믿음으로 넘어가봅시다. 인공지능 르네상스는 모든 가능성과 창의성에 대한 것입니다. 그러나 인공지능 산업 혁명은 자원과 전문화에 대해 새롭게 고찰해야 합니다. 저렴하고 확장 가능한 인공지능을 만들기 위한 더 나은 방법은 해결하려는 문제에 대해 더 깊이 파고들어 근본적인 구성 요소들로 줄이고, 그 핵심 문제만 심층적이고 전문화된 방식으로 해결하는 것입니다. 우리는 그것을 꼭 필요한 인공 지능(Essential AI)이라고 부르는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n필수 인공지능: 인공지능 산업혁명을 위한 원칙 세트\n\n필수 인공지능은 세 가지 원칙에 기반을 두고 있습니다:\n\n- 전문화 및 동적입니다. 우리는 동적이지만 구체적인 방법을 사용하여 여러 독립 추론 시스템을 연결하여 특정 지능 로봇 에이전트인 '특정 인공지능'을 만듭니다. 이들 디버들된 모델은 모두 매우 높은 F1 점수를 가지고 있고, 우리의 방식은 각각의 모델에서 정밀도와 재현율 사이의 미묘한 균형을 맞추는 것을 가능하게 합니다. 모델 체인의 정확도에 대한 곱셈 효과에도 불구하고, 움직임 계획 및 생물 환경과의 상호작용만 고려할 때도 전체 품질 값이 97%를 초과합니다. 모델 체이닝을 통해 환각과 블랙박스 효과를 피하고, 각 모델의 재학습 목표가 명확합니다. 보상 학습을 넘어서, 우리의 로봇은 또한 라이브 성능에 대한 피드백을 받아 품질과 성능을 최적화하기 위해 실행할 모델을 결정합니다. 이것은 실제 분야에서 결과를 강화하는 적응적 행동입니다.\n- 자습 및 유연합니다. 우리는 우리의 MLOps 접근 방식에서 빅 에이에이의 최고를 채용하여 특정 모델의 이상치를 자동으로 식별하고 효율적이고 특정한 라벨링 파이프라인을 사용하여 빠르게 다시 훈련시킵니다. 우리는 견고하고 전문화된 Tortuga 데이터를 수집하며, 개발 프로세스에서 가장 효과적인 곳에 시뮬레이션 및 합성 데이터를 적용하며, 실제 세계를 충분히 반영하지 못하는 경우에는 중지합니다. 이는 표준 격리된 특이 케이스뿐만 아니라 새로운 식물 품종 및 새로운 농장 환경과 같은 완전히 새로운 맥락에도 적용되며, 우리 모델의 내장된 이해를 업데이트합니다. 우리는 모든 이를 파트너와 무관한 특정 도구로 수행합니다.\n- 효율적입니다. 특수 모델 체인 방식과 특정하고 동적인 MLOps 도구를 사용하여 우리는 지원 임원의 연봉보다 적은 비용으로 지상 실리콘의 모든 참변 사실 주석을 지원하고, 단지 3명의 엔지니어 지원 스텝으로 모든 모델에 대한 이터레이션을 24시간 이내에 완료할 수 있습니다. 우리는 영원히 변화하는 월계도 툴의 일괄 실행형 생태계를 조합하는 대신, 우리에게 동작하는 매우 집중된 매우 저렴한 시스템 위에 개발함으로써 이를 수행할 수 있습니다. 큰 에이에이 방법보다 수십 배 낮은 비용으로 가능합니다.\n\n우리는 필수 인공지능 로봇들이 현실 세계의 산업 규모 문제를 해결할 것이라 믿으며, 장기간 이 문제에 대한 유일한 올바른 접근 방식일 것이라고 확신합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인공지능 레오나르도 다빈치 휴머노이드 르네상스 로봇은 가정에서 놀라운 자원이 될 수 있습니다. 비서로서, 대화 상대로서. 심지어 창고 환경에서 더 많은 저거량 작업을 해낼 수도 있을지도 모릅니다. 하지만 하루에 수백만 개의 베리를 수확해야 한다면, 산업혁명처럼 생각하고 그 일을 탁월하게 수행하는 비용 효율적인 로봇을 만들어야 합니다. 제대로 된 산업 작업은 우리 사회의 기반을 이루며, 제조업, 농업, 거래 분야에서의 \"지루하고 더러운, 위험한\" 직업들에 대해 Essential AI가 비용과 효율성 면에서 Big AI나 심지어 AGI보다 우월하게 성과를 내게 될 것입니다.\n\n더 많은 정보를 원하신다면, Big AI에 대해 아래의 글을 참고해 보세요:\n\n- 포브스: 트랜스포머가 인공지능을 혁신했다. 그들을 대체할 것은 무엇인가?\n- Cobot의 Brad Porter: 인간이 할 수 있는 로봇을 위한 위대한 인공지능으로 가는 길\n- Jacob Grow: 대형 언어 모델의 경계와 인공지능의 전진 방향\n","ogImage":{"url":"/assets/img/2024-05-18-EssentialAI_0.png"},"coverImage":"/assets/img/2024-05-18-EssentialAI_0.png","tag":["Tech"],"readingTime":7},{"title":"SLAM을 처음부터 구현해 보기","description":"","date":"2024-05-18 19:19","slug":"2024-05-18-ImplementSLAMfromscratch","content":"\nSLAM (Simultaneous Localization and Mapping)을 위한 솔루션을 구현하는 다양한 방법이 있지만, 구현하기 가장 간단한 알고리즘은 Graph SLAM입니다.\n\nGraph SLAM은 로봇공학에서 사용되는 기술로, 로봇의 궤적을 시간에 따라 동시에 추정하고 환경 안의 랜드마크 위치를 노드와 제약조건으로 나타내는 그래프입니다. 그래프는 로봇의 자세 및 랜드마크 위치를 나타내는 노드와 간격을 제약 조건으로 나타내는 에지로 구성됩니다. 제약 조건은 초기 위치, 상대 움직임 및 상대 측정 제약 조건과 같은 것들을 나타냅니다. 그래프를 최적화함으로써, Graph SLAM은 센서 측정을 가장 잘 설명하는 가장 확률적인 궤적과 랜드마크 위치를 찾으려고 합니다.\n\n## 예제\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGraph SLAM으로 파고들기 전에, Graph SLAM을 어떻게 구현할지 탐구하는 과정에서 도움이 될 예제를 소개하겠습니다. 이 예제에서는 하나의 차원적인 세계에서 로봇이 이동하는 상황을 살펴보겠습니다. 로봇의 첫 번째 자세는 시간 단계 t0에서이며, 로봇의 자세는 x=2입니다. 이 위치에서 로봇은 랜드마크 L0(예: 나무)를 보고 거리가 9단위 떨어져 있습니다. 그런 다음 로봇은 5단위만큼 앞으로 이동합니다. 이 시점에서 로봇은 x=7에 있어야 하며 랜드마크는 4단위 떨어져 있어야 합니다. 그러나 시간 단계 t1에서 로봇은 랜드마크까지의 거리를 보거나 측정하지 않습니다. 시간 단계 t1에서의 랜드마크 측정 부재는 센서 오류, 가리개, 또는 다른 이유로 인할 수 있습니다. 마지막으로, 로봇은 3단위 앞으로 이동하고 랜드마크를 1단위로 떨어져서 볼 수 있습니다. 이 시점에서 로봇은 x=10에 있어야 하며 랜드마크는 x=11에 있어야 합니다.\n\n![이미지](/assets/img/2024-05-18-ImplementSLAMfromscratch_1.png)\n\n## 제약 조건\n\nGraph SLAM에서는 세 가지 중요한 유형의 제약 조건이 있습니다. 각각의 제약 조건을 자세히 살펴보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 초기 위치 제약: 초기 위치 제약은 로봇이 환경 속 초기 위치에 대한 지식을 나타냅니다. 이는 로봇의 궤적 추정에 고정된 참조점을 제공합니다. 이 제약은 초기 위치 및 방향 추정을 캡처하기 위해 `x, y, θ`로 표현될 수 있습니다. 이 제약을 그래프에 통합함으로써 로봇의 궤적 추정을 기준으로 잡고 추가적인 제약 최적화를 위한 시작점을 제공할 수 있습니다.\n- 상대 운동 제약: 상대 운동 제약은 연이은 시간 단계 간 로봇의 자세 변화에 대한 정보를 캡처합니다. 이러한 제약은 통상 휠 엔코더 또는 IMU와 같은 오도메트리 센서에서 얻어집니다. 오도메트리 센서는 로봇의 움직임에 대한 추정을 제공하며, 위치 및 방향의 변화와 같은 로봇의 움직임을 제공합니다. 연이은 시간 단계 간 오도메트리 측정을 비교함으로써 로봇의 이동을 기술하는 상대 운동 제약을 유도할 수 있습니다. 이러한 제약은 움직임 추정 값의 불확실성을 포착하는 가우시안 분포로 표현됩니다.\n- 상대 측정 제약: 상대 측정 제약은 환경 속 서로 다른 랜드마크나 특징들 간의 상대 위치 또는 거리에 대한 정보를 캡처합니다. 이 제약은 레이저 거리계 또는 카메라와 같은 센서 측정을 통해 얻어집니다. 예를 들어, 로봇이 랜드마크를 관찰하고 해당 랜드마크까지의 거리를 측정한 경우, 이 정보는 상대 측정 제약으로 사용될 수 있습니다. 이러한 제약은 로봇의 궤적에 상대적으로 랜드마크 위치를 추정하는 데 도움을 줍니다.\n\n그래프 SLAM에서는 이러한 모든 제약을 함께 사용하여 환경과 로봇의 궤적에 대한 그래프 표현을 구축합니다. 그래프는 서로 다른 시간 단계의 로봇 자세와 랜드마크 위치를 나타내는 노드 및 그들 사이의 제약을 나타내는 엣지로 구성됩니다.\n\n이것은 테이블 태그를 마크다운 형식으로 변경한 것입니다.\n\n이미지는 [여기](/assets/img/2024-05-18-ImplementSLAMfromscratch_2.png)에서 확인할 수 있습니다.\n\n우리의 예제에서는 5개의 총 제약이 있습니다: 초기 위치 제약 1개, 상대 운동 제약 2개 및 상대 측정 제약 2개입니다. 4개의 상대 제약은 그래프 내의 엣지로 표시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 그래프 표현\n\n그래프 SLAM에서 환경과 로봇의 궤적은 그래프 구조를 사용하여 표현됩니다. 그래프는 노드와 엣지로 구성되어 있으며, 노드는 로봇의 포즈(위치 및 방향)를 시간에 따라 다른 지점에서 나타냅니다. 엣지는 이러한 포즈 간의 제약 조건이나 측정값을 나타냅니다.\n\n로봇의 포즈뿐만 아니라 환경에 있는 랜드마크나 특징을 나타내는 노드도 그래프에 포함됩니다. 이러한 랜드마크는 로봇이 인식하고 로컬리제이션 및 맵핑에 사용할 수 있는 객체, 관심 지점 또는 기타 독특한 특징일 수 있습니다.\n\n그래프 표현은 엣지를 통해 로봇의 포즈와 랜드마크를 연결하여 센서로부터 얻은 측정값이나 제약 조건을 나타냅니다. 이러한 측정값에는 거리 측정, 방위 측정 또는 로봇과 랜드마크의 상대적인 위치와 방향에 대한 정보를 제공하는 기타 유형의 센서 데이터가 포함될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, 로봇이 현재 자세에서 landmark를 관측한다고 가정해 봅시다. 이 관측은 그래프에서 로봇의 자세 노드와 landmark 노드 사이에 엣지를 생성합니다. 이 엣지는 센서로부터 얻은 측정값을 나타내며, 이를 통해 로봇과 landmark 간의 상대적인 위치와 방향에 대한 정보를 제공합니다.\n\n이러한 측정값을 그래프에 통합함으로써 SLAM 알고리즘은 로봇의 가장 가능성 있는 궤적과 측정값에 의해 적용된 제한 조건을 가장 잘 만족하는 환경 지도를 추정할 수 있습니다. 그래프 최적화 과정은 예측된 측정값과 센서로부터 실제로 얻은 측정값 간의 오차를 최소화하기 위해 그래프 내의 자세와 landmark 위치를 조정하는 것을 포함합니다.\n\n## 행렬과 벡터 표현\n\n그래프 SLAM에서는 로봇의 자세와 landmark 간의 관계를 모델링하기 위해 행렬과 벡터 표현을 사용합니다. 이러한 표현은 SLAM 문제를 해결하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n행렬 표현부터 시작해봅시다. Graph SLAM에서 우리는 정보 행렬이라고 하는 행렬을 만듭니다. 이 행렬은 Ω (오메가)로 표시되며 서로 다른 변수들 간의 제약 조건이나 관계를 나타냅니다. 각 변수는 지도상의 로봇 pose나 landmarke에 해당합니다.\n\n정보 행렬은 정사각 행렬이며, 그 크기는 SLAM 문제에서 변수의 수에 따라 달라집니다. 그래프에 n개의 노드가 있는 Graph SLAM 문제의 경우, n x n 크기의 정보 행렬을 갖게 됩니다. 이 행렬의 요소들은 변수들 간의 관계에 대한 정보를 인코딩합니다. 예를 들어, 두 변수가 높은 상관 관계를 가진 경우, 정보 행렬의 해당 요소는 더 높은 값을 갖게 됩니다.\n\n이제 벡터 표현으로 넘어가 봅시다. Graph SLAM에서 우리는 정보 벡터라고 하는 벡터를 생성합니다. 이것은 ξ (크싸이)로 표시되며, SLAM 문제에서 우리가 한 측정치나 관측치를 나타냅니다. 벡터의 각 요소는 특정 측정치나 관측치에 해당합니다. 그래프에 n개의 노드가 있는 Graph SLAM 문제의 경우, n x 1 크기의 정보 벡터를 갖게 됩니다.\n\n정보 벡터에는 SLAM 문제의 측정치와 변수들과의 관계에 대한 정보가 포함되어 있습니다. 이는 우리가 측정치를 SLAM 문제에 통합하고 로봇 포즈와 랜드마크의 추정치를 업데이트하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저희 예제에서는 그래프에 4개의 노드가 있으므로 4 x 4 행렬을 초기화합니다. 다음은 정보 행렬입니다:\n\n```js\n// 0으로 채워진 4x4 행렬\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 0  | 0  | 0  | 0  |\n| t1 | 0  | 0  | 0  | 0  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n저희 예제에서는 또한 그래프에 4개의 노드가 있으므로 4 x 1 벡터를 초기화합니다. 다음은 정보 벡터입니다:\n\n```js\n// 0으로 채워진 4x1 벡터\n+---+\n| 0 |\n| 0 |\n| 0 |\n| 0 |\n+---+\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 그래프 SLAM 알고리즘\n\n우리가 정보 행렬과 벡터를 선언하면, 초기 위치 제약을 행렬과 벡터에 적용해야 합니다. 예를 들어, 초기 위치인 2를 사용하여 정보 행렬을 업데이트하려면, 간단한 선형 방정식을 만들 것입니다:\n\n이제 우리의 간단한 선형 방정식과 그 계수 `1,0,0,0;2`를 가지고 t0에 해당하는 행에 추가해봅시다:\n\n```js\n// 오메가 행렬 (결과)\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 1  | 0  | 0  | 0  |\n| t1 | 0  | 0  | 0  | 0  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n// Xi vector (결과)\n+---+\n| 2 |\n| 0 |\n| 0 |\n| 0 |\n+---+\n```\n\n일반화하기 위해 여기에 초기 의사 코드가 있습니다:\n\n```js\nvoid GraphSLAM(G, startPose) {\n    // Omega와 Xi 선언\n    Omega = new Matrix(n,n)\n    Xi = new Vector(n)\n\n    // 초기 위치 제약\n    Omega['t0','t0'] = 1\n    Xi['t0'] = startPose\n\n    // 그래프 최적화\n    Mu = GraphOptimization(Omega, Xi, G)\n    return Mu\n}\n```\n\n여기서부터 그래프 최적화에 대해 논의해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 그래프 최적화\n\n그래프의 초기 매트릭스 및 벡터 표현이 준비되면, 그래프 최적화를 수행해야 합니다. 그래프 SLAM에서의 그래프 최적화는 센서 측정을 기반으로 그래프를 반복적으로 업데이트하여 로봇 자세와 랜드마크 위치의 추정치를 개선하는 과정입니다. 이 과정은 측정 업데이트와 상태 업데이트라는 두 가지 주요 단계로 구성됩니다.\n\n- 측정 업데이트: 측정 업데이트 단계에서는 그래프의 엣지를 반복하며 정보 매트릭스에 제약 조건을 추가합니다. 이러한 제약 조건은 센서에서 얻은 측정치(예: 거리 측정 또는 방향 측정)를 나타냅니다.\n- 상태 업데이트: 상태 업데이트 단계에서는 선형 방정식 체계를 해결하여 그래프의 오차를 최소화하는 최적 로봇 자세와 랜드마크 위치를 추정합니다. 이는 정보 매트릭스의 역행렬을 취하고 정보 벡터와 곱하여 수행됩니다.\n\n다음은 그래프 최적화를 위한 고수준의 의사 코드 예시입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nvoid GraphOptimization(Omega, Xi, G) {\n    Omega, Xi = MeasurementUpdate(Omega, Xi, G);\n    Mu = StateUpdate(Omega, Xi);\n    return Mu;\n}\n```\n\n측정 및 상태 업데이트에 대해 더 자세히 알아보겠습니다.\n\n## 측정 업데이트\n\n측정 업데이트에서는 그래프 데이터를 사용하여 정보 행렬 및 벡터 데이터를 정의합니다. Omega는 선형 방정식의 계수를 나타내는 정보 행렬이고, Xi는 해당 방정식의 상수항을 나타내는 정보 벡터입니다. G는 측정치(예: 거리)를 나타내는 엣지 가중치를 포함하는 그래프입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n각 모서리는 일련의 선형 방정식을 정의하는 데 도움이 됩니다. 예를 들어, 모서리 t0-t1로 정보 행렬을 업데이트하려면 두 개의 선형 방정식을 만들겠죠:\n\n이제, 첫 번째 선형 방정식과 그 계수 `1,-1,0,0;-5`를 가져와서 t0에 해당하는 행에 추가해봅시다:\n\n```js\n// 오메가 행렬 (결과)\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 2  |-1  | 0  | 0  |\n| t1 | 0  | 0  | 0  | 0  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n```js\n// 시 벡터 (결과)\n+---+\n|-3 |\n| 0 |\n| 0 |\n| 0 |\n+---+\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 두 번째 선형 방정식의 계수인 `-1, 1, 0, 0; 5`를 가져와 t1에 대응하는 열에 추가해 봅시다:\n\n```js\n// 오메가 행렬 (결과)\n     + -- + -- + -- + -- +\n     | t0 | t1 | t2 | L0 |\n+ -- + -- + -- + -- + - -+\n| t0 | 2  |-1  | 0  | 0  |\n| t1 |-1  | 1  | 0  | 5  |\n| t2 | 0  | 0  | 0  | 0  |\n| L0 | 0  | 0  | 0  | 0  |\n```\n\n```js\n// 크시 벡터 (결과)\n+---+\n|-3 |\n| 5 |\n| 0 |\n| 0 |\n+---+\n```\n\n일반적인 상황을 이해하기 위해 의사 코드를 보여 드리겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nvoid MeasurementUpdate(Omega, Xi, G) {\n    for each edge:\n        // LinEq 1: src - dst = -weight\n        Omega[edge.src, edge.src] += 1\n        Omega[edge.src, edge.dst] += -1\n        Xi[edge.src] += -edge.weight\n        // LinEq 2: dst - src = weight\n        Omega[edge.dst, edge.dst] += 1\n        Omega[edge.dst, edge.src] += -1\n        Xi[edge.dst] += edge.weight\n    return Omega, Xi\n}\n```\n\n보시다시피, 측정 업데이트 프로세스는 그래프 G의 각 엣지에 대해 반복하는 것을 포함합니다. 각 엣지마다 코드는 두 단계를 수행합니다. 먼저, 엣지의 원본 노드에 해당하는 행에 대한 Omega 및 Xi 값을 업데이트합니다. 그 다음, 엣지의 대상 노드에 해당하는 행에 대한 Omega 및 Xi 값을 업데이트합니다. 두 단계 모두 엣지의 가중치는 두 노드 사이(예: 거리)의 측정을 나타냅니다.\n\n이러한 단계는 측정에 의해 부과된 제약 조건이 Omega 및 Xi 행렬에 올바르게 표현되도록 보장합니다. 모든 엣지를 반복한 후 함수는 업데이트된 Omega 및 Xi 행렬을 반환합니다.\n\n## State Update\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 시점에서, Omega와 Xi를 완전히 정의했습니다. 그러니 Mu를 해결하기 위해 방정식 체계를 해결하기만 하면 됩니다:\n\n여기서 Mu는 업데이트된 상태 추정을 나타냅니다. Mu를 구하기 위해서는 단순히 Omega를 역행렬로 변환해야 합니다:\n\n```js\nvoid StateUpdate(Omega, Xi) {\n    Mu = Omega.invert() * Xi\n    return Mu\n}\n```\n\n제공된 의사 코드는, 공분산 행렬(Omega)의 역행렬을 측정 벡터(Xi)로 곱하여 상태를 업데이트합니다. 결과인 Mu는 로봇의 자세 및 랜드마크 위치의 상태 추정을 나타냅니다. 이는 시스템의 상태를 정의하는 모든 변수의 값이 포함된 벡터입니다. 우리의 예시에서, 이는 Mu의 예상 값입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n// Mu vector (result)\n+----+\n|  2 |\n|  7 |\n| 10 |\n| 11 |\n+----+\n```\n\n이 예에서 첫 번째 요소는 t0에서 로봇의 위치이며, 두 번째 요소는 t1에서 로봇의 위치이고, 세 번째 요소는 t2에서 로봇의 위치이며, 네 번째 요소는 landmark(L0)의 위치입니다.\n\n## 토론\n\nGraph SLAM 알고리즘은 정확한 답변을 제공하지 않을 수 있지만, 근접한 결과를 제공합니다. SLAM 알고리즘의 결과는 알고리즘에 공급되는 측정값의 품질에 따라 달라집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 내용은 간단한 1차원 예시에 불과했습니다. 이를 쉽게 3차원 공간으로 확장할 수 있고 로봇이 바라보는 방향을 설명하는 추가적인 방향 차원도 포함할 수 있습니다.\n\n만약 SLAM 용어 중 이해되지 않는 것이 있다면, SLAM 개요를 다시 참고해 주세요.\n\n이 글이 마음에 드셨다면, ❤를 눌러 다른 사람들이 이를 발견하는 데 도움을 주세요!\n","ogImage":{"url":"/assets/img/2024-05-18-ImplementSLAMfromscratch_0.png"},"coverImage":"/assets/img/2024-05-18-ImplementSLAMfromscratch_0.png","tag":["Tech"],"readingTime":13},{"title":"로봇 학습의 현황","description":"","date":"2024-05-18 19:17","slug":"2024-05-18-TheStateofRobotLearning","content":"\n## 부분적으로 관찰한, 반 확률적인, 자아 중심적인 관점.\n\n![image](/assets/img/2024-05-18-TheStateofRobotLearning_0.png)\n\n이 글은 내가 Nvidia GTC에서 한 발표에 대한 동반자로, 약간의 스파이스를 더했습니다. 이것은 구글 딥마인드의 의견이 아니며, 제 팀과 동료들의 다양한 관점을 반영하지 않을 수 있습니다.\n\n나는 작성 시점으로 6개월 전에 애틀랜타에서 열린 최근 로봇 학습 회의의 분위기가 자신 있었던 것을 알 수 있었습니다. 내가 7년 전부터 참석한 모든 회의와는 다르게 뭔가 변화의 느낌이 났다. 많은 발표가 실제로 ... 꽤 잘 작동하는 로봇 시스템을 보여줬습니다! 비록 일부 학술적 정의에 따르면 그 한계 내에서 작동했다고 할지라도요. 이전에 커뮤니티가 빨간 블록을 파란 블록 위에 쌓는 것과 같은 간단한 작업에서 고심했던 점에서, 이제 우리는 복잡한 현실 세계 문제에 대해 실질적인 진전을 거둔 시스템들을 보고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자주 농담을 해요. 연구 분야에서의 경력은 실제로 작동하지 않는 것들에 대해 평생을 일하는 것을 의미한다고 말이죠. 그리고 세션 간의 복도 대화 중에 연구자들이 “이제 어떻게 해야 할까요?” 라고 자신에게 물어보는 소리가 들릴 수 있어요. 이는 사실 일이 실제로 잘 작동하고 전체 사업에 대해 “임무 완료” 라고 누구도 부르지 않을 정도로 잘 작동한 것이 아니라, 로봇공학의 진행 속도가 가속화되었음을 깨닫게 되어 연구 방향과 채택된 방법론을 재평가해야 한다는 것을 반영하고 있어요.\n\n우리가 어떻게 그 경로에 이르렀는지 궁금하시다구요? 음, 모든 인공지능 관련 사항과 마찬가지로 GPT로의 이동과 현대 LLM 출현을 2021년경으로 거슬러 올라가 볼 수 있어요. 갑자기 전례없는 추론 능력이 모두의 손끝에 있다는 것처럼 보였고, AGI는 곧 다가온다는 것이었죠. 그때쯤 로봇공학계에도 다른 일이 발생했는데, 대중 언론에는 그렇게 많이 보도되지 않았어요: FOMO가 엄청나게 증가했던 거예요. 로봇공학 또는 더 스타일리시한 이름으로 “실체화된 AI”는 AGI로 가는 길이 되어야 했고, 상황 인지, 현실 세계 기반, 상식적 추론에 대한 진정한 해법이었어요. NLP 커뮤니티가 10년 동안 방치한 것으로도 볼 수 있는 그리 증오 받는 서브필드인 “언어 모델링”이 갑자기 주목을 받자 로봇공학계에 무겁게 작용했어요.\n\n물론, 그들을 이기지 못하면 함께 하라는 말이죠. 그래서 우리도 그렇게 했어요. “로봇공학과 LLMs의 만남”이라는 연구 방향은 매우 얕게 나올 수도 있었어요: 아마 당신이 로봇과 대화를 나누는 데 언어 모델을 사용할 수도 있었겠죠. 또는 로봇이 클링곤 시를 낭독하게 할 수도 있었을 거예요. 그러나 실제로 일어난 일은 제 경력의 가장 큰 놀람이었어요: 연결점이 매우 깊게 생겨나서 오늘까지 우리는 그를 해결하기 시작한 것에 불과해요.\n\nLLMs를 “언어”에 관한 것으로 생각하는 것은 흔한 실수예요. 언어는 LLMs가 주로 사용하는 표면형임은 확실히 맞지만(코드도 마찬가지), LLM의 슈퍼파워는 모두 상식적 추론에 관한 것이에요: LLMs는 “책은 책장에 두어야 하지 욕조에는 넣어두지 말아야 한다”나 “커피를 내리는 방법” 같은 간단한 진리를 알아요. 그것이 실제 세계에서 움직이려는 실체화된 에이전트들에게 중요한 문제인 것이 결국 크게 작용한다는 것은 놀랍지 않아요. 그래서 LLMs가 가장 먼저 영향을 줄 로봇학의 한 부분이 계획에 영향을 받을 것이라는 것은 당연한 일이었어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로봇이 어떻게 작동하는지 개념적으로 이해하는 도표를 그리는 것이 도움이 될 수 있습니다. 이 정도로 단순화하면 커뮤니티에서 친구를 많이 사귈 수 있을 것 같진 않지만, \"모든 모델은 틀리지만 어떤 것은 유용하다\"는 정신으로 해석하면 매우 유익한 모습이 나옵니다. 당신의 로봇이 세계의 상태를 인지하고, 그 상태를 계획자에게 보내어 목표와 함께 계획을 세우는 루프를 상상해보세요. 그 계획은 로봇 컨트롤러에 전달되고, 하드웨어를 작동시켜 실행을 담당합니다. 물론 세계는 계속 변하기 때문에 아마도 계획의 처음 단계만 실행되고, 상태 추정이 업데이트되고 로봇이 다음 단계 실행 계획을 수립하고, 이와 같은 일을 반복하게 될 것입니다.\n\n이는 로봇 공학의 주요 분야에 매핑되는 임의적인 스케치로, 상태 추정, 작업 및 동작 계획, 제어와 관련하여 전통적으로 병행 발전해 왔으며, 시스템 수준의 문제가 크게 무시되고 문제가 종종 다른 분야로 던져지는 것으로 이어졌다고 주장하는 사람도 많습니다: 너무나 많은 TAMP 논문들이 완벽한 상태 추정을 당연시하고, 많은 제어 전략들이 실행할 수 없는 계획을 속삭이게 되며, 그 경계를 넘어 그래디언트가 흐를 수 있도록 하는 것에 대해 언급할 필요도 없군요!\n\n그래서 당연히 첫 번째 파장은 계획자 쪽에서 발생했습니다. 아마도 주관적일 수 있지만, 나는 SayCan을 \"아하\" 순간으로 꼽을 것입니다. 커뮤니티가 인지한 것은 계획의 많은 부분을 \"의미 공간\"으로 옮길 수 있다면 기하학 공간이 아닌 곳에서 계획을 수행할 수 있으며, 이를 통해 LLMs를 사용하여 이 작업을 수행할 수 있고, 데이터를 수집하거나 로봇에 특화된 온톨로지를 작성하거나 상징적 추론 엔진을 구축할 필요 없이 그들의 상식 능력의 모든 이점을 누릴 수 있음을 깨달은 순간이었다고 생각합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TheStateofRobotLearning_2.png\" /\u003e\n\n인지와 실행 모두 자연어를 사용하는 인터페이스를 갖게되면 모든 것에 대해 언어를 API로 사용하는 것이 매우 유혹적일 것입니다. 언어에는 많은 장점이 있습니다: 유연하며 해석 가능하며 선택한 추상화 수준으로 사물을 설명할 수 있습니다. 이것은 고정된 API에 대한 거대한 문제였습니다: 예를 들어 자율 주행 자동차에게 세계가 바운딩 박스의 모음처럼 보이는 것은 괜찮을 수 있지만, 사물에 직접 접촉하려고 하면 아마도 더 풍부한 지오메트리와 의미론적 정보가 필요할 것입니다. 혹시 계획자가 인식 모듈이 제공할 유용한 정보를 미리 알지 못할 수도 있습니다. 아마도 양방향 대화가 필요할지도 모릅니다...\n\n이것이 그 여정의 다음 단계로 나아가는데요: 계획자와 인지 시스템이 모두 자연어를 사용하도록합시다. VLM들이 정말 뛰어나게 발전하고 있으니, 이를 활용하여 양방향 대화를 실제 대화로 만들어봅시다. 이것이 Socratic Models의 아이디어입니다. 여기서는 세상의 상태와 그에 대한 행동 방법에 대한 합의를 모델 사이의 대화를 통해 달성할 수 있습니다. Inner Monologue는 주기적인 상태 재추정 및 재계획을 대화의 일부로 만드는 개념을 더 발전시켰습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-TheStateofRobotLearning_3.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로봇 지능의 중추로 LLM이 있다면 새로운 일을 많이 할 수 있습니다. 예를 들어 AutoRT에서는 LLM을 활용하여 수행할 새로운 작업을 꿈꿨는데, 이로 인해 즉시 제기된 질문은 다음과 같습니다: 로봇이 스스로 해야 할 일을 생각한다면, 어떻게 그것들이 안전하고 유익한지를 보장할 수 있을까요? 우리는 LLM을 안전한 개념(“날카로운 물체를 집지 마세요”)으로 유도하거나 더 일반적인 인간 중심 가치를 제시할 수 있습니다. “인간에게 상처를 입히지 마십시오…” 소리가 익숙하신가요? 몇 년 전에 실제 로봇에 아지모프의 로봇 법칙을 구현할 수 있는 상당히 타당한 경로가 있다고 말해주었다면, 믿지 않았을 것입니다. 향후 시간이 이것을 사용할지 여부를 알려줄 것입니다. 헌법 AI를 로봇의 안전 스택의 일부로 사용하는 것이 실용적인지는 앞으로 알게 될 것이지만, 실제 세계에서 이에 대해 이야기하고 평가할 수 있다는 사실은공신입니다.\n\n작동 구성 요소는 어떻게 되나요? 전통적인 로봇 공학의 마지막 요새인 그것조차 LLM 처리를 받을 수 있을까요? LLM이 정말 잘하는 한 가지는 코드 생성입니다. 결국, 컨트롤러 소프트웨어는 정책을 기술한 코드일 뿐입니다. 여기서 코드로 정책이라는 개념이 등장하며, LLM에게 저수준 제어 API를 제시하고 실제 실행할 정책을 설명하도록 할 수 있다는 아이디어가 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-TheStateofRobotLearning_4.png\" /\u003e\n\n코드 LMs는 제로샷에서 아주 잘 작동하는데요, 단지 프롬프트 디자인의 암흑 예술에 능숙해야 합니다. 마이크로소프트 동료들의 초창기 ChatGPT for Robotics 실험에서 사용된 것처럼 대화 전략을 사용하여 프롬프트를 반복하고 향상시킬 수 있습니다. 하지만 더 좋은 점은 제어 행위의 상호 작용을 통해 코드 LM을 세밀하게 조정하고 개선하는 반복적인 과정을 거칠 때입니다. 이것은 우리가 고전적인 모델 예측 제어에 유사하게 언어 모델 예측 제어라고 이름 붙인 것입니다. 이를 통해 모델이 새로운 작업에 대해 더 나은 제로샷 수행뿐만 아니라 사용자 상호 작용에서 더 빨리 학습할 수 있게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여러 LLM이 내부 채팅방에서 소통하는 이미지가 로봇의 중추가 되면, 문제를 세 가지 구성 요소로 인수 분해하는 것이 여전히 유용한지 의문스러울 수 있습니다. 신경망은 서로 고대역폭의 미분 가능한 표현을 통해 통신할 수 있기 때문에, 왜 그것들을 단어로 축소시켜야 할까요? 해석 가능성을 어느 정도 얻을 수는 있지만, 정보 손실은 상당합니다. 예를 들어, 계획자가 여전히 본질적으로 맹목적이라고 상상해 보세요. 이러한 구성 요소를 일부 병합할 수 있을까요? 단순히 끝점 열광 때문이 아니라, 이미 이러한 모델에 내재된 모듈성 덕분에 가능합니다. 서로 다른 transformer 구성 요소가 서로 상호 작용하도록 허용함으로써 신경망 내부에서 '관심사의 분리'를 재현할 수 있기 때문입니다.\n\n이 방향으로 첫 실험이 PaLM-E를 사용하여 인식과 계획을 병합하려고 시도되었습니다.\n\n![이미지](/assets/img/2024-05-18-TheStateofRobotLearning_5.png)\n\n인식 및 계획 모듈을 공동 훈련하면 명확한 향상이 관찰되었으며, 작업 및 실행체에 대한 전이 증거도 있었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 실험은 계획자를 제외하고 지각과 행동을 합치는 것이었습니다. \"픽셀에서 행동\" 모델이 많이 나왔지만 우리에게 혁신적인 방법은 RT-1이었습니다. TRI의 액션 확산, 버클리의 휴머노이드 트랜스포머, 스탠포드의 ACT와 Octo와 같은 방식으로 최근 몇 달 동안 이 분야에서 많은 일이 벌어졌으며, 성능과 기능성의 폭발을 보는 것은 정말 멋진 일이었습니다.\n\n지금쯤 어디로 향하고 있는지 보이시나요? 반쪽채치런 선택보다 모든 것을 하는 단일 \"로봇 두뇌\"를 훈련하는 것이 더 낫지 않을까요? 이에 대한 우리의 첫 번째 시도는 RT-2이었으며, 여전히 로봇공학 관련 데이터 소스(특히 지각 및 의미적 이해를 위한 인터넷 데이터)를 활용하면서 전체 문제에 대해 공동으로 추론하는 능력이 얼마나 많은 도움을 주는지를 보여주었습니다. Meta의 동료들이 VC-1로 그 방향으로 진행한 또 다른 주목할 만한 한 걸음이었습니다. 다중 모달 모델을 위한 오픈소스 생태계가 번성하고 있으며, 우리가 이러한 모델의 공간 추론 능력을 어디까지 밀어낼 수 있는지 탐구하고 있는 사람들이 많아질 것으로 기대합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 우리는 어디로 가야 할까요? 반지도 학습 혁명은 왔다가 지났어요. RL은 여전히 상처를 핥고 있습니다. 확산 모델이 잘 돌아가고 있으며 오프라인 RL이 부활하고 있습니다. 데이터 효율성이 크게 향상되었음에도 불구하고, \"실제 세계에서 작동\"을 상상할 수 있게 되었지만, sim-to-real 접근에 모든 것을 걸 필요가 없어진 것처럼 보이는 상황에서도 여전히 데이터에 구애받고 있으며, 데이터 수집의 효율성과 다양성을 향상시키는 것이 중요합니다.\n\n오늘날 이 분야에서 가장 큰 긴장감이 있습니다. 한편으로는 교차 존재 모델이 로봇간 능력을 전이하는 데 뛰어나게 작동한다는 것을 보여주고 있습니다. 로봇, 작업 간의 다양성을 높이고 문제에 대해 다양성 중심적인 접근을 취해야 한다는 주장이 있습니다. 다른 한편으로는 \"모두를 지배할 한 가지 형태\"로봇 학습 방식을 원하는 사람이 더 많아지고, 테슬라, 피규어, 1X, 어질리티, Unitree, Sanctuary, Apptronik 등과 같이 억만장자로 유명한 로봇에 투자하는 돈이 늘어나고 있습니다. 후자 방법의 장점은 인간적 존재에서 배우고 인간 공간에 배치될 수 있는 범용 능력이며, 단점은 매우 복잡하고 비싼 하드웨어를 데이터 수집의 중요 경로에 놓게 되어 최종 제품의 경제성에 큰 장벽을 높일 수 있다는 것입니다.\n\n그것은 위험한 내기입니다. 특히 교차 존재 가설이 사실로 드러나고 Aloha, UMI, Stretch(및 Dobb.E), Mobile Aloha 및 Aloha 2와 같은 실험을 본다면 싸구려 로봇 떼가 분야를 완전히 혼란스럽게 만들고 다양한 저렴한 모습에 민첩한 능력을 가져올 수 있습니다. 그러나 이 시점에서 그 베팅 어느 쪽에도 100% 돈을 거는 일은 하지 않겠습니다. 앞으로 수개월은 이 분야가 어디로 가야 하는지에 대한 포문이 될 것입니다. 다양성 대 다양성, 싸구려와 두각을 내며 고급 DOF와 완전한 기능, 더 싸고 철저하게, 단점이 있다.\n\n오늘 우리가 있는 세계는 어느 정도 둘 다입니다. \"범용\" 어림들이 널리 배치되어 있지만, 그들을 가치 있게 만드는 경제학은 잔혹하며, 그것들이 실제로 유용하게 만들기 위해 전용 도구 및 시스템 통합이 필요합니다.\n\n데이터 확장 맥락에서 확신하는 점은 생성 모델이 시뮬레이션의 미래라는 것이며, \"더 나은 시뮬레이터\"뿐만 아니라 3D 및 비디오 생성이 외형뿐만 아니라 물리학 및 공간 관계도 존중하게 만드는 방법을 쫓아야 한다는 것입니다. 날씨 예측부터 단백질 접힘까지 다른 물리학 시뮬레이터 분야마다 생성 모델로 인해 혼란스러워지고 있습니다. 로봇 및 환경의 디지털 복제본을 작성하는 데 몇 시간을 보내는 대신 로봇의 센서를 잡아 \"재생\"을 누르면 가능한 미래를 생성할 수 있다면 시뮬에서 실로ら 릴 체리 뉴스를 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 데이터 확장이 대부분 HRI 문제로 전환되고 있다고 점점 더 확신하게 되고 있습니다. 오늘날 HRI 커뮤니티가 주로 걱정하는 정확한 문제는 아닐 수 있지만; 대부분의 HRI는 최종 사용자가 로봇과 상호 작용하는 부분에 관심을 기울입니다. 새로운 다양한 작업을 설계하고, 데이터를 견고하게 수집하고, 행동을 개선 및 최적화하기 위해 더 나은 HRI 접근 방식이 필요합니다: 모델 및 행동을 훈련시키기 위해 데이터 수집에 필요한 모든 신중한 설계를 최적화하는 것은 최종 사용자가 최종 제품과 상호 작용하기 전에도 이루어져야 합니다. 우리는 실제로 모든 로봇을 눈, 팔, 다리가 있는 챗봇으로 바꿈으로써 HRI 커뮤니티에 새로운 가능성을 제공했습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-TheStateofRobotLearning_0.png"},"coverImage":"/assets/img/2024-05-18-TheStateofRobotLearning_0.png","tag":["Tech"],"readingTime":10},{"title":"NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기","description":"","date":"2024-05-18 19:15","slug":"2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble","content":"\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png\" /\u003e\n\n이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png\" /\u003e\n\n# Prerequisites\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시작하기 전에 다음 구성 요소가 있는지 확인하십시오:\n\n- NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04\n- Intel RealSense Depth Camera (예: D435i)\n- Jetson Nano에 설치된 ROS2 Humble\n- RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블\n- 필요한 패키지를 다운로드하기 위한 인터넷 연결\n\nROS2 RealSense 패키지 설치\n\n```js\nsudo apt install ros-humble-realsense2-camera\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRealSense 노드를 시작해주세요:\n\nRealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:\n\n```python\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='realsense2_camera',\n            executable='realsense2_camera_node',\n            name='realsense2_camera',\n            output='screen',\n            parameters=[{\n                'enable_depth': True,\n                'enable_infra1': True,\n                'enable_infra2': True,\n                'enable_color': True,\n            }],\n        ),\n    ])\n```\n\n란치 파일을 실행하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003ctable\u003e\n    \u003ctr\u003e\n        \u003ctd\u003e![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png)\u003c/td\u003e\n    \u003c/tr\u003e\n\u003c/table\u003e\n\n```js\nros2 launch your_package_name realsense_launch.py\n```\n\nrqt에서 데이터 시각화:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nrqt에 RealSense 데이터 추가하기:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png)\n\n- 새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.\n- 이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n깊이 이미지\n\n![깊이 이미지](https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif)\n\n# 깊이 이미지란?\n\n깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 주요 주제 및 메시지\n\nROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:\n\n- 토픽: /camera/depth/image_raw\n- 메시지 유형: sensor_msgs/Image\n\n## sensor_msgs/Image 메시지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nsensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:\n\n- header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.\n- height: 이미지의 높이(픽셀 단위).\n- width: 이미지의 너비(픽셀 단위).\n- encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.\n- is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.\n- step: 바이트 단위의 전체 행 길이.\n- data: 바이트 배열로 저장된 실제 픽셀 데이터.\n\n## 깊이 이미지 처리\n\n깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.\n- 장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.\n- 3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.\n\n# 결론\n\n위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.\n\n문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!\n","ogImage":{"url":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"},"coverImage":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png","tag":["Tech"],"readingTime":6},{"title":"라즈베리 파이 5에서 VSCode 서버 다시 시도하기","description":"","date":"2024-05-18 19:13","slug":"2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5","content":"\n\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png\" /\u003e\n\n지난 번에 우리가 이에 대해 이야기했을 때는 Raspberry PI 5가 없었고, VSCode Server의 버전은 4.0.2였습니다. 전체 경험은 성공적이지 못했고, 실제 작업에 적합하지 않았습니다. VSCode가 느리게 실행되었고, 빌드 시간도 더욱 더 걸렸습니다. 특히 러스트와 같은 언어에 대해서는 그러했습니다. 따라서 우리는 더 나은 하드웨어를 기다리는 실험을 종료했습니다. 운좋게도, 오늘 기다리던 하드웨어가 마침내 출시되었습니다: Raspberry PI 5.\n\nRaspberry PI 4보다 최대 세 배 빠른 속도로 벤치마킹된 새로운 Raspberry PI는 개인용 코딩 및 빌딩 워크스테이션으로 강력한 경쟁자가 되리라 약속합니다. 이에 더해 더 많은 RAM, 더 높은 I/O 대역폭 및 더 나은 GPU를 제공하여 모든 것이 성공을 향해 나아가는 것으로 보입니다. 우리는 마침내 우리의 홈 VSCode Server를 가질 수 있을까요? 알아보겠습니다!\n\n## VSCode Server 설치 및 구성하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Trying the VSCode Server again on the Raspberry Pi](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_1.png)\n\nVSCode Server도 업데이트되었습니다. 현재 버전 4.20.0에 도달했습니다. 이번에는 지난 시험한 버전보다 많은 개선 사항을 갖춘 VSCode 1.85.1이 실행됩니다. 그래서 이번에는 이전과 마찬가지로 curl을 사용하여 공식 페이지에서 그것을 받아봅시다. 이번에는 여러분도 이미 알다시피 Fedora가 아직 Raspberry PI 5를 지원하지 않는 커널을 사용하고 있기 때문에 Ubuntu를 위한 Debian 패키지를 사용하겠습니다:\n\n```bash\n#curl -fOL https://github.com/coder/code-server/releases/download/v4.20.0/code-server_4.20.0_arm64.deb\n#sudo apt install ./code-server_4.20.0_arm64.deb\n```\n\n그럼 시작해봅시다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_2.png\" /\u003e\n\n설치 후에 우리가 해야 할 일은 잘 알려진 아래 명령어를 실행하여 VSCode 서버를 활성화하는 것뿐입니다:\n\n```js\n#sudo systemctl start code-server@ubuntu\n#sudo systemctl enable code-server@ubuntu\n```\n\n@ubuntu 부분은 서버를 실행할 사용자를 가리킵니다. 이 경우에는 ubuntu인데요, 라즈베리 파이 서버 사용자를 반영하도록 변경해도 상관 없습니다. 서버는 이제 기본 포트 8080에서 실행되지만, ~/config/code-server/config.yaml 파일을 편집하여 해당 포트 및 다른 설정을 변경할 수 있습니다. 예를 들어, 저는 포트를 변경하고 로그인 암호를 제거했습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래에서 볼 수 있듯이, 우리는 IP 주소를 변경하여 네트워크의 모든 클라이언트에서 10000번 포트로의 연결을 허용하도록 했습니다. 또한 인증을 비활성화하여 기본 비밀번호에서 변경했습니다. 비밀번호를 추가하려면 다음을 사용합니다:\n\n```js\nbind-addr: 0.0.0.0:10000\nauth: password\npassword: password-hash\ncert: false\n```\n\n비밀번호 해시는 mkpasswd를 사용해서 얻을 수 있습니다. 비밀번호를 입력하라고 요청하며, 해시를 복사하여 위의 비밀번호 필드에 붙여넣습니다. 이것이 모든 구성 단계입니다. 이제 브라우저로 넘어가봅시다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 브라우저에서 Visual Studio Code 실행하기\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_4.png)\n\n위의 스크린샷에서 볼 수 있듯이, 우리가 해야 할 일은 네트워크 내의 어떤 브라우저에서라도 Raspberry PI에 있는 IP 주소로 접근하고, VSCode Server가 실행 중인 올바른 포트인 경우(우리의 경우 10000)를 제공해주면 됩니다. 이제 즉시 브라우저 창을 새로고침하면, Raspberry PI 4에서 VSCode가 훨씬 빠르게로드됩니다. 심지어 이미 LDAP 서버를 포함한 많은 네트워크 서비스가 실행 중이지만요. 터미널을 열고 rust를 설치해봅시다:\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 스크린샷에 나오는 명령어는 rustup을 설치하는 기본 명령어입니다: curl --proto `=https` --tlsv1.2 -sSf https://sh.rustup.rs | sh. 이 명령어는 라즈베리 파이 5 VSCode 서버에 rust를 설정해줍니다:\n\n![라즈베리 파이 5 VSCode 서버 재시도](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_6.png)\n\n라즈베리 파이 5의 와이파이 속도가 향상된 것을 알립니다. Rust를 다운로드하는 과정이 로컬 머신에서 실행하는 것과 더 닮았습니다. 그럼에도 불구하고, 설치 과정은 기대보다 느립니다. 물론, 제 최신 세대 인텔 i7 데스크탑과 비교하면 공평하지 않지만, 이 작은 라즈베리 파이 5도 아직 데스크톱 속도에 도달하기 위해 많은 것을 해야 한다는 것을 보여줍니다. 그럼에도 불구하고, 경험은 실제로 라즈베리 파이보다 빨랐습니다. 3배 빠른가요? 정말 그렇지는 않았지만, 라즈베리 파이 4에서 약 10분 정도 걸릴 작업이 라즈베리 파이 5에서는 약 4분 정도 소요되었습니다. 확실한 향상이었습니다.\n\n하지만, 일반적이고 작은 웹 서버와 같은 몇 가지 종속성을 사용하여 rust 프로젝트를 작성하고 빌드하는 작업을 해보죠. 그러기 위해 우리는 projects라는 새 폴더를 만들어서 브라우저에서 VSCode를 열고 터미널을 실행하여 cargo new web-test --bin을 실행하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_7.png\" /\u003e\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n이제 해당 폴더를 열어 봅시다:\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_8.png\" /\u003e\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n프로젝트를 컴파일해 보겠습니다. 먼저 rust-analyzer 확장 프로그램을 설치하여 VSCode에서 rust 언어를 완전히 지원받을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_9.png)\n\nLLDB 디버거도 설치할 겁니다. 이를 통해 러스트 프로그램을 디버깅할 수 있어요:\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_10.png)\n\n사실, Raspberry PI 4에 비해 VSCode 익스텐션 설치가 훨씬 빠른 것 같아요. 그것들은 로컬 데스크톱에서 설치하는 것과 똑같아요. 전체 경험은 로컬에서 VSCode를 실행하는 것 같아요. 다시 F5를 누르면 다음으로 linker cc를 찾을 수 없다는 에러가 나올 거에요. 그래서 sudo apt install build-essential을 사용해서 build-essential 패키지를 설치해볼까요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![다운로드 속도가 빠르고 설치 속도는 조금 느립니다. 하지만 라즈베리 파이 5는 여전히 1분 이내에 모든 것을 설치하는 데 성공합니다. 이번에는 F5를 누르면 정말로 프로젝트를 컴파일하고 디버그합니다. 마침내. 러스트 서버를 실행해 봅시다!](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_11.png)\n\n## 작은 러스트 웹 서버 만들기\n\n![다운로드 속도가 빠르고 설치 속도는 조금 느립니다. 하지만 라즈베리 파이 5는 여전히 1분 이내에 모든 것을 설치하는 데 성공합니다. 이번에는 F5를 누르면 정말로 프로젝트를 컴파일하고 디버그합니다. 마침내. 러스트 서버를 실행해 봅시다!](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_12.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금까지 우리는 안정적으로 1%에서 3%의 CPU 사용량과 겨우 1.2GB의 RAM 사용량을 유지하고 있어요. 이라고 느껴질 수 있지만, 라즈베리 파이 5는 8GB의 사용 가능한 RAM을 가지고 있어요. 라즈베리 파이 4에서는 이미 이것이 고난일이었죠:\n\n![이미지1](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_13.png)\n\n그럼, 정적 파일을 제공하는 간단한 웹 서버를 준비해뒀어요:\n\n![이미지2](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_14.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nrust-analyzer가 작업을 수행하는 동안 actix 종속성을 다운로드하고 컴파일하며 소스 코드를 색인화하는 과정에서 4코어 ARM CPU에서 발생하는 전형적인 노동의 결과를 확인할 수 있습니다. 하지만 이는 라즈베리 파이 5가 쉽게 처리할 수 없는 것은 없습니다. 웹 경험은 여전히 부드럽고 자동 완성은 여전히 즉각적으로 응답합니다:\n\n![이미지1](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_15.png)\n\n또한 전형적인 index.html 파일을 준비했습니다:\n\n![이미지2](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_16.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 웹 서버를 구축하고 실행해 보려고 합니다. 우리 손가락을 교차하고 cargo build를 실행해 보세요. actix web 라이브러리는 이미 인상적인 수의 종속성을 필요로 하지만, Raspberry PI 5는 이 모든 것을 빠르게 처리합니다:\n\n![이미지](/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_17.png)\n\n지금 세 분은 꽤 오랜 시간으로 느껴질 수 있지만, 말해 드릴게요. 저는 웹 프로젝트를 만들 때 Raspberry PI 4에서 러스트로 빌드했을 때 쉽게 10분씩 썼습니다. 저에게는 이미 이는 압도적인 승리입니다. 더 구체적인 비교를 해보면, 저의 평균 AMD Ryzen 5 3000 노트북은 이 일을 완료하는 데 약 한 시간 반 정도 걸리는 반면, 동시에 많은 일을 실행 중이기는 하지만요. 하지만, 합당하게 말해서, Raspberry PI 5는 상황을 감안할 때 충분히 좋은 일을 하고 있습니다. 그리고 Raspberry PI 4보다 훨씬 더 훌륭한 일을 합니다.\n\n정말 인상적입니다. Raspberry PI 4는 홈 네트워크 코딩 서버로 사용하기에 적합하지 않았고, 단 몇 분만 지나도 Raspberry PI 5가 이 상황을 어떻게 처리하는지 완전히 만족스럽다고 할 수 있습니다. 대규모 자원을 사용하는 복잡한 빌드 프로세스로 알려진 러스트 프로그램을 빌드하고 실행하는 것은 매우 쉽고 로컬에서 실행하는 것 같은 느낌이 듭니다. 이게 최고의 칭찬이에요. Raspberry PI 4에서 서버가 제한적이고 중단되는 느낌이 들었던 것과는 달리, 이번에는 서버로 인해 제한받거나 방해받는 느낌이 들지 않습니다. 이 실험을 성공으로 인정하고 계속하여 실험을 진행하기 위해 VSCode Server 구동 상태로 두겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 대형 태블릿을 사용하여 코딩 및 이전에 거부되었던 가정 네트워크의 다른 리소스를 활용할 수 있는 훌륭한 시나리오를 열어줍니다. 이 멋진 여정을 함께 해 줘서 감사하고, 다음에 또 만나요!\n","ogImage":{"url":"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png"},"coverImage":"/assets/img/2024-05-18-TryingtheVSCodeServeragainontheRaspberryPI5_0.png","tag":["Tech"],"readingTime":10},{"title":"라즈베리 파이 웹사이트 만들기","description":"","date":"2024-05-18 19:11","slug":"2024-05-18-CreatingaRaspberryPIWebsite","content":"\n아래는 메인 시리즈 \"Hackable Lego Train\"의 미니 파트입니다.\n\n다음은 메인 시리즈를 확인할 수 있는 링크입니다:\n\nHackable Lego Train | Part 1 | Stux | 작성자: Stux | 2024년 5월 | Medium\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_1.png\" /\u003e\n\n프로젝트의 아이디어는 열차 해킹을 시뮬레이션하고 운영 기술 환경에서 취약한 애플리케이션과 관련된 전반적인 사이버 위험을 보여주는 것입니다.\n\n그러니까 PI에 간단한 웹사이트를 만든 방법에 대해 설명해드릴게요.\n\n전체적인 단계는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 새로운 OS(Kali)로 Pi 이미지 다시 만들기\n- Pi에서 SSH 활성화\n- 웹 사이트를 위한 폴더 디렉토리 생성\n- 웹 사이트를 위한 파일 구성\n- 웹 사이트에 로깅 추가\n\n시작해 보세요!\n\n주 컴퓨터에서 라즈베리 파이 이미지 소프트웨어를 다운로드하고 설치하세요.\n\n라즈베리 파이 OS — 라즈베리 파이\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Creating a Raspberry PI Website Image 2](/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_2.png)\n\n라즈베리 파이에 Kali를 설치하고 싶었어요.\n\n- 저는 Kali를 잘 알고 있고 손에 익숙해요.\n- 이 프로젝트 이외에도 네트워크 침투 분야에서 다른 계획이 있어요.\n- 어차피 해킹 프로젝트니까 나에게 가장 쉽게 만들어야겠죠 :)\n\n![Creating a Raspberry PI Website Image 3](/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n호스트 컴퓨터에 PI SD 카드를 넣어주세요. 그리고 카드에 Kali를 WRITE해주세요.\n\n작업이 끝나면 SD 카드를 PI에 다시 넣고 부팅해주세요.\n\n원하는 방식으로 Kali를 설정하고 따라가보세요.\n\n로그인하세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서부터는 SSH를 사용해서 작업을 계속합니다. 그래서 셸 명령어에 익숙하신 것 같아요.\n\n![CreatingaRaspberryPIWebsite_4](/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_4.png)\n\n새 시스템에 SSH로 접속한 후, 먼저 웹사이트 디렉토리 구조를 만들고 싶어요.\n\n![CreatingaRaspberryPIWebsite_5](/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 제 예시입니다:\n\n```js\nbig_cabooses/\n│\n├── static/\n│   └── css/\n│       └── styles.css\n│   └── images/\n│       └── background.jpg\n├── templates/\n│   └── index.html\n├── app.py\n└── train_schedule.py\n```\n\napp.py 파일을 편집하여 다음 내용을 추가하십시오:\n\n```js\nfrom flask import Flask, render_template\nfrom train_schedule import get_train_schedule\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    schedule = get_train_schedule()\n    return render_template('index.html', schedule=schedule)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndef get_train_schedule():\n    return [\n        {\"time\": \"07:00 AM\", \"train\": \"천년비행선\", \"destination\": \"타투인\"},\n        {\"time\": \"09:00 AM\", \"train\": \"데스스타\", \"destination\": \"엔도어\"},\n        {\"time\": \"11:00 AM\", \"train\": \"X-윙\", \"destination\": \"야빈 4\"},\n        {\"time\": \"01:00 PM\", \"train\": \"TIE 전투기\", \"destination\": \"호스\"},\n        {\"time\": \"03:00 PM\", \"train\": \"제국 셔틀\", \"destination\": \"코르서캔트\"},\n        {\"time\": \"05:00 PM\", \"train\": \"슬레이브 1\", \"destination\": \"카미노\"},\n        {\"time\": \"07:00 PM\", \"train\": \"나부 스타파이터\", \"destination\": \"나부\"},\n    ]\n```\n\ntemplates/index.html 수정:\n\n```html\n\u003c!DOCTYPE html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"UTF-8\" /\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /\u003e\n    \u003ctitle\u003eBig Cabooses\u003c/title\u003e\n    \u003clink\n      rel=\"stylesheet\"\n      href=\"{{ url_for('static', filename='css/styles.css') }}\"\n    /\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003cdiv class=\"background\"\u003e\u003c/div\u003e\n    \u003cdiv class=\"content\"\u003e\n      \u003ch1\u003eBig Cabooses 열차 일정\u003c/h1\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth\u003e시간\u003c/th\u003e\n            \u003cth\u003e열차\u003c/th\u003e\n            \u003cth\u003e목적지\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          {% for entry in schedule %}\n          \u003ctr\u003e\n            \u003ctd\u003e{{ entry.time }}\u003c/td\u003e\n            \u003ctd\u003e{{ entry.train }}\u003c/td\u003e\n            \u003ctd\u003e{{ entry.destination }}\u003c/td\u003e\n          \u003c/tr\u003e\n          {% endfor %}\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nstatic/css/styles.css 파일에 다음 내용을 입력해주세요:\n\n```js\nbody, html {\n    height: 100%;\n    margin: 0;\n    font-family: Arial, sans-serif;\n}\n\n.background {\n    position: absolute;\n    top: 0;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    background-image: url(\"../images/background.jpg\");\n    background-size: cover;\n    background-position: center;\n    z-index: -1;\n    opacity: 0.5;\n}\n\n.content {\n    position: relative;\n    z-index: 1;\n    padding: 20px;\n    background-color: rgba(255, 255, 255, 0.8);\n    border-radius: 10px;\n    max-width: 600px;\n    margin: auto;\n    top: 50%;\n    transform: translateY(-50%);\n    text-align: center;\n}\n\ntable {\n    width: 100%;\n    border-collapse: collapse;\n}\n\nth, td {\n    padding: 10px;\n    border: 1px solid #ddd;\n    text-align: left;\n}\n\nth {\n    background-color: #f2f2f2;\n}\n```\n\nstatic/background.jpg의 경로에 매력적인 배경 이미지를 업로드해주세요.\n\nChatGPT를 이용하여 스스로 이미지를 만들 수 있게 위해서 돈을 지불했어요. 여러분도 자금이 있으시다면 강력히 추천합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n웹사이트를 시작하세요!\n\n```js\nsudo python3 app.py\n```\n\n브라우저를 열고 127.0.0.1:5000으로 이동하세요\n\nBUTTT!!!!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 로깅을 추가하고 내부 네트워크의 다른 컴퓨터에서 액세스할 수 있는 기능을 추가하길 원해요.\n\n이를 위해 하나 해야 할 일은 우리의 app.py 파일을 변경하는 것뿐입니다:\n\n```js\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True)\n```\n\n반드시 \"host=\"에 PI의 IP를 넣어 주세요!!!!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 웹 사이트에 로그 파일을 기록하려고 합니다. app.py 파일에 이 모든 내용을 추가해 보겠습니다:\n\n```python\nfrom flask import Flask, render_template\nfrom train_schedule import get_train_schedule\nimport logging\n\napp = Flask(__name__)\n\n# 로깅 설정\nlogging.basicConfig(filename='app.log', level=logging.DEBUG,\n                    format='%(asctime)s %(levelname)s %(name)s %(threadName)s : %(message)s')\n\n@app.route('/')\ndef home():\n    app.logger.info(\"홈 페이지에 접근했습니다.\")\n    schedule = get_train_schedule()\n    return render_template('index.html', schedule=schedule)\n\n@app.route('/error')\ndef error():\n    app.logger.error(\"이것은 오류 예제입니다.\")\n    return \"오류 예제\", 500\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True)\n```\n\n이제 /big-cabooses/ 메인 디렉토리에 app.log라는 파일이 생기게 됩니다.\n\n그런 다음, 간단한 접속 로그가 포함된 스타워즈 테마의 레고 기차 웹 사이트를 만들었습니다. 함께 빌드하는 과정을 즐겼습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 질문이든 하시거나 도움이 필요하시면 언제든지 메시지를 보내주세요. 즐겁게 즐기세요! 이것을 하면서 몇 번 굳었지만, 마침내 성공적으로 해냈고 결과물을 좋아합니다. -Stux\n","ogImage":{"url":"/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_0.png"},"coverImage":"/assets/img/2024-05-18-CreatingaRaspberryPIWebsite_0.png","tag":["Tech"],"readingTime":9},{"title":"라즈베리 파이로 쿠버네티스 클러스터 구축 가이드","description":"","date":"2024-05-18 19:08","slug":"2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis","content":"\n몇 년 전에 라즈베리 파이에서 Kubernetes 클러스터를 세팅했었어요. 당시 라즈베리 파이의 ARM 아키텍처는 몇 가지 어려움을 야기했죠. ARM을 지원하는 애플리케이션을 찾는 건 어려운 과제였는데, 그래서 필요한 애플리케이션과 컨테이너를 직접 빌드해야 했던 적이 많았어요.\n\n그런데 그 이후로 상황이 크게 개선되었어요! 새로운 64비트 라즈베리 파이 OS의 등장과 ARM의 저렴함으로 클라우드 배포에 많이 사용되는 산업에서의 인기 상승으로, 라즈베리 파이 클러스터 구축이 훨씬 간단해졌어요. 저는 클러스터를 다시 구축하기로 결정했고, 64비트 OS 및 최신 버전의 Kubernetes와 Docker로 업데이트했어요.\n\n여러분이 자체 라즈베리 파이 Kubernetes 클러스터를 설정하는 방법에 대한 가이드를 작성했어요. 집에서 클러스터를 구축하는 여정에 유용하길 바랍니다! 🚀\n\n# 요구 사항\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클러스터를 설정하기 위해서는 하드웨어가 필요합니다. 필요한 것들은 다음과 같아요:\n\n- 라즈베리 파이(저는 4 모델 B를 사용했어요)\n- SD 카드 1장 / 라즈베리 파이\n- 이더넷 케이블 1개 / 라즈베리 파이\n- 라우터 및/또는 네트워크 스위치\n- USB 허브\n- (선택 사항) 케이스\n\n이 안내서는 Kubernetes 1.26.6, Docker 24.0.2 및 라즈베리 파이 Lite(64비트) 불자이에 맞춰 작성되었어요.\n\n# OS 설정\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 단계는 모든 Raspberry Pi에 OS를 설정해야 합니다. 그렇지 않으면 Raspberry Pi는 기본적으로 부팅할 시스템이 없습니다.\n\nRaspberry Pi Imager를 다운로드하십시오. 이 편리한 애플리케이션은 Raspberry Pi의 다운로드와 플래싱에 사용됩니다. 이 가이드에서는 Raspberry Pi OS (Debian의 파생 버전)의 64비트 헤드리스 버전을 사용할 것입니다.\n\n최신 Raspberry Pi와 호환되는지 확인한 후에 SD 카드를 플래싱해야 합니다.\n\n![Raspberry Pi Imager](/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSD 카드를 선택하고 OS를 플래싱하기 시작하세요. 모든 SD 카드에 대해 이 작업을 완료할 때까지 반복해주세요.\n\n## SSH 활성화 및 기본 사용자 생성\n\n각 Pi를 원격으로 구성할 수 있게끔 SSH를 설정해야 합니다.\n\nSSH를 활성화하려면 SD 카드의 부트 파티션에 확장자 없이 ssh라는 빈 파일을 생성하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로그인 사용자를 설정하기 위해, SD 카드의 부팅 파티션에 userconf라는 파일을 생성하세요. 이 파일은 'name':'encrypted-password'로 구성된 텍스트 한 줄을 포함해야 합니다. 로그인 사용자로 노드를 사용했지만 원하는 대로 사용하셔도 됩니다.\n\nencrypted-password를 생성하려면 다음 명령을 OpenSSL과 함께 실행하세요:\n\n```js\necho '{password}' | openssl passwd -6 -stdin\n```\n\n파일을 저장하고 SD 카드를 제거하세요. 그리고 라즈베리 파이에 SD 카드를 삽입하고 전원을 켜세요. 개인 네트워크의 라우터나 네트워크 스위치에 연결되어 있는지 확인하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 첫 번째 부팅 및 초기 구성\n\n라즈베리 파이의 IP를 얻어야 합니다. 이를 위해 라우터를 확인할 수 있습니다. 제 경우, OpenWrt를 사용하며 DHCP 설정에서 기억하기 쉬운 정적 IP를 만듭니다.\n\n![image](/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_1.png)\n\n첫 번째 노드에 SSH로 연결합니다. 이 노드는 클러스터의 제어 평면을 실행하는 마스터 노드가 됩니다. 라즈베리 파이로 터널링한 후에 설정을 시작할 수 있습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 명령어를 사용하여 사용자를 sudo 그룹에 추가해주세요.\n\n```js\nsudo usermod -aG sudo node\n```\n\n이제 rasp-config를 업데이트하여 node 사용자로 자동 부팅하도록 설정해봅시다.\n\n```js\nsudo raspi-config\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*XG-oT3YeryzngA-Xv3JY9w.gif)\n\n“System Options” → “Boot / Auto Login” 으로 이동하여 “Console Autologin”을 선택해주세요.\n\n# Docker \u0026 Kubernetes 초기 설정\n\n기본적으로 cgroup 메모리 옵션이 비활성화되어 있으므로 Docker가 메모리 사용량을 제한할 수 있도록 업데이트해야 합니다. /boot/cmdline.txt를 열고 cgroup_enable=memory cgroup_memory=1을 추가해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 우리의 apt 저장소를 업데이트하고 Kubernetes 저장소를 포함시킬 차례입니다.\n\n```js\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\necho \"deb http://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list\nsudo apt update \u0026\u0026 sudo apt upgrade -y\n```\n\nDocker 설치:\n\n```js\ncurl -sSL https://get.docker.com | sh\nsudo usermod -aG docker node\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nKubernetes 1.20부터는 dockershim이 폐기되고 있습니다. Mirantis에서 제공하는 cri-dockerd라는 클러스터용 오픈 소스 CRI를 사용할 수 있습니다. cri-dockerd를 설치하고 서비스를 설정하려면 다음 명령을 실행하세요:\n\n```js\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.4/cri-dockerd-0.3.4.arm64.tgz\ntar -xvzf cri-dockerd-0.3.4.arm64.tgz\nsudo mv cri-dockerd/cri-dockerd /usr/bin/cri-dockerd\nsudo chmod +x /usr/bin/cri-dockerd\nwget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.service\nwget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.socket\nsudo mv cri-docker.service /etc/systemd/system/\nsudo mv cri-docker.socket /etc/systemd/system/\nsudo systemctl enable cri-docker.service\nsudo systemctl enable cri-docker.socket\nsudo systemctl start cri-docker.service\nsudo systemctl start cri-docker.socket\n```\n\nKubernetes 스케줄러를 위해 노드에서 swap을 비활성화하는 것이 권장됩니다.\n\n```js\nsudo apt-get update \u0026\u0026 sudo apt-get install dphys-swapfile \u0026\u0026 sudo dphys-swapfile swapoff \u0026\u0026 sudo dphys-swapfile uninstall \u0026\u0026 sudo systemctl disable dphys-swapfile\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 cri-dockerd 설정에 문제가 발생하면, 이 안내서를 확인해보세요. 처음에 작성했을 때와 달라진 사항이 있을 수 있어요.\n\n마지막으로, Kubernetes를 설치해봅시다!\n\n```js\nsudo apt install -y kubelet=1.26.6-00 kubeadm=1.26.6-00 kubectl=1.26.6-00\nsudo apt-mark hold kubelet kubeadm kubectl\n```\n\n이 가이드에서는 모든 것이 1.26.6에서 작동하는지 테스트했어요. 1.24 이전 버전은 정상적으로 작동하지 않을 거예요. 이러한 패키지를 업데이트되지 않도록 표시할 거에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n차선으로, 랜처 랩스에서 만든 k3s는 가벼운 옵션으로 좋은 선택일 것입니다. 그 중 일부 장점은 작은 실행 파일 크기, 매우 낮은 자원 요구 사항 및 ARM용으로 최적화되어 있다는 것입니다. 이 가이드에서는 이를 테스트해보지 않았지만, 이후에 비슷한 설정이 될 것으로 생각합니다.\n\n이제 클러스터를 초기화할 시간입니다. 이를 위해 InitConfiguration 및 ClusterConfiguration 설정이 포함된 파일을 만들겠습니다.\n\n```js\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: {token}\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 10.0.0.100\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///var/run/cri-dockerd.sock\n  imagePullPolicy: IfNotPresent\n  name: node-0\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nnetworking:\n  podSubnet: \"10.244.0.0/16\" # --pod-network-cidr\n```\n\n이 파일에는 마스터 노드의 설정이 포함되어 있습니다. criSocket이 cri-dockerd를 사용하고, 나중에 네트워크 CIDR을 설정해두었음을 주목하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 노드에서 제어 평면을 초기화하려면 다음을 실행하세요.\n\n```js\nsudo kubeadm init --config kubeadm-config.yaml\n```\n\n이 명령은 새 노드를 클러스터에 추가하는 설정 및 kube-config를 설정하는 방법을 보여줍니다.\n\n명령에서 지시하는 방법에 따라 kube-config를 설정하고, 워크스테이션에 kube-config와 가입 명령을 복사하고 저장하세요. 나중에 필요할 것이니까요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 클러스터 네트워킹\n\n이제 클러스터에서 네트워킹을 설정해야 합니다. Pod들이 노드 간에 서로 통신할 수 있도록 하려면 네트워크 플러그인 (CNI 또는 컨테이너 네트워크 인터페이스로도 불림)이 필요합니다.\n\n네트워크 플러그인은 IP 주소 할당, DNS 해결 및 네트워크 격리와 같은 기능을 Pod에 제공합니다.\n\n우리는 이를 위해 Flannel을 사용할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마스터 노드에서 다음을 실행해 주세요.\n\n```js\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml\n```\n\n그게 다에요! 이제 마스터 노드가 완료되었으니, 클러스터에 새 노드를 추가하기 시작할 수 있어요. 이전에 출력된 조인 명령을 기억하고 있나요? 이제 그것이 필요할 거에요.\n\n# 클러스터에 새로운 노드 추가하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클러스터에 새 노드를 추가하는 것은 꽤 간단합니다. 많은 노드를 추가하는 경우에는 tmux와 같은 도구를 사용하여 세션 명령을 다중화하는 것이 좋습니다.\n\n\"첫 번째 부팅 및 초기 설정\"을 완료하고 \"도커 및 쿠버네티스 초기 설정\"을 진행하세요. 서로 다른 Kubernetes 구성 요소를 설치하는 단계 이후에 작업을 중지하세요. 이 시점에서 이전에 실행한 kubeadm join 명령을 실행해야 합니다. cri-socket 및 node-name 옵션을 포함하여 실행해 주세요.\n\n```js\nsudo kubeadm join 10.0.0.100:6443 --token {token} --discovery-token-ca-cert-hash {hash} --cri-socket unix:///var/run/cri-dockerd.sock --node-name {name}\n```\n\n이제 마스터 노드에서 클러스터를 모니터링하고 모든 노드가 클러스터에 가입하는지 확인하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n\u003e kubectl get nodes를 watch합니다.\n이제 귀하의 클러스터가 사용할 준비가 되었습니다! 그러나 SSH를 통해가 아닌 워크스테이션에서 액세스하고 싶을 것입니다. 컴퓨터에서 이전에 설정한 kube-config를 설정할 수 있습니다.\n\n기본 kube-config는 관리자 권한을 부여하며 다른 사람과 공유해서는 안됩니다.\n\n먼저 프로필에 구성을 내보냅니다.\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nexport KUBECONFIG=~/.kube/config\n```\n\n컨텍스트 설정:\n\n```js\nkubectl config use-context kubernetes-admin@kubernetes\n```\n\n이제 원격으로 클러스터에 액세스할 수 있어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n\u003e kubectl cluster-info\n쿠버네티스 제어 평면이 https://10.0.0.100:6443 에서 실행 중입니다.\nCoreDNS이 https://10.0.0.100:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy 에서 실행 중입니다.\n\n더 많은 디버깅 및 진단을 위해 'kubectl cluster-info dump'를 사용하세요.\n```\n\n# 도구 설정\n\n이제 밴자이라 클러스터를 일반에서 멋지게 업그레이드해 봅시다. 새 응용 프로그램을 쉽게 배포하고 클러스터를 모니터링할 수 있는 몇 가지 널리 사용되는 도구를 설정해 보겠습니다. 여기서 ArgoCD, Prometheus 및 Grafana 설치 방법을 안내하겠습니다! 이 세 가지 오픈소스 프로젝트가 우리의 클러스터를 다음 수준으로 끌어올립니다.\n\n계속하기 전에, 이러한 도구들에 대한 모든 설정 변경 사항을 추적하기 위한 원격 git 저장소를 만들어 보시기를 권장합니다. 특히 ArgoCD를 사용할 때, 각 도구나 추가 응용 프로그램을 배포할 때마다 거기를 통해 추가합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# ArgoCD\n\n각 도구에 대해 Helm을 리소스 템플릿팅 도구로 사용할 것입니다. 최신 버전(또는 적어도 Helm v3)을 설치하고 ArgoCD 저장소를 추가해 봅시다.\n\n```js\nhelm repo add argo https://argoproj.github.io/argo-helm\n```\n\nValues 파일을 생성하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\nserver:\n  serviceType: NodePort\n  httpNodePort: 30080\n  httpsNodePort: 30443\n```\n\n이 파일은 차트의 설정 중 하나를 재정의하는 데 사용할 수 있습니다. 이 경우에는 서비스를 ClusterIP 대신 NodePort로 실행하도록 변경하고 있습니다. 이렇게 하면 클러스터에서 지정한 포트를 외부에서 엑세스할 수 있도록 하여 리버스 프록시를 사용하지 않고도 개인 네트워크에서 해당 서비스에 액세스할 수 있습니다.\n\n서비스를 설치하십시오.\n\n```js\nhelm install argocd -n argocd -f values.yaml argo/argocd\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼 관리자 사용자의 기본 암호를 가져와야 합니다.\n\n```js\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n```\n\nOpenWrt를 사용하고 있기 때문에 클러스터에 호스트 이름 항목을 설정하고 https://cluster.home:30443에서 로그인 페이지에 액세스할 수 있습니다.\n\n![그림](/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nArgoCD에 로그인하고, 곧 돌아올게요.\n\n![image](/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_3.png)\n\n# Prometheus\n\n우리는 클러스터에 대한 정보 수집을 위해 타임 시리즈 메트릭 서버로 Prometheus를 사용할 거에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n설치하기 전에 Prometheus가 쿼리 데이터를 저장할 지속적인 볼륨을 설정해야 합니다. 집 클러스터에서는 예비 USB 드라이브를 사용하기로 결정했지만 원하는 것을 연결하여 사용할 수 있습니다.\n\n마스터 노드에서 볼륨을 설정한 단계는 다음과 같습니다. 우리의 볼륨을 위한 경로를 만들고 실수를 막기 위해 변경 사항을 반영해야 할 fstab의 백업을 만듭니다.\n\n```js\nsudo mkdir /mnt/usb\nsudo cp /etc/fstab /etc/fstab.bak\n```\n\n장치를 연결한 다음 fstab을 변경 내용과 함께 수정합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n/dev/sda1 /mnt/usb vfat defaults,uid=youruid,gid=yourgid,dmask=002,fmask=113 0 0\n\n이제 우리 노드 사용자의 사용자 및 그룹 설정으로 장치를 마운트합니다.\n\nsudo mount -o uid=youruid,gid=yourgid,dmask=002,fmask=113 /dev/sdX1 /mnt/usb\n\n이제 우리는 PersistentVolume과 PersistentVolumeChain을 가진 Kubernetes 자원을 생성하려고 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: prometheus-usb-pv\n  labels:\n    type: local\nspec:\n  storageClassName: manual\n  capacity:\n    storage: {device의 크기}Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  hostPath:\n    path: \"/mnt/usb\"\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: prometheus-usb-pvc\nspec:\n  storageClassName: manual\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: {device의 크기}Gi\n```\n\n만약 git 리포지토리를 사용 중이라면, 이 파일들을 template 디렉토리 안에 새로운 Helm Chart에 위치시켜주세요. 다음 단계를 따라 계속 진행해봐요.\n\n이제 프로메테우스와 함께 차트를 설정해봅시다.\n\n```bash\nhelm create prometheus\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nChart.yaml에 Prometheus subchart를 종속성으로 추가해주세요.\n\n```yaml\ndependencies:\n  - name: prometheus\n    version: 22.7.0\n    repository: https://prometheus-community.github.io/helm-charts\n```\n\n이제 새 PV 및 PVC를 사용하도록 구성을 설정하고, 일부 권한을 수정하고 서버를 마스터 노드에만 배포하도록 확인할 수 있습니다.\n\n```yaml\nprometheus:\n  alertmanager:\n    enabled: false\n  prometheus-pushgateway:\n    enabled: false\n  configmapReload:\n    prometheus:\n      enabled: false\n  server:\n    nodeSelector:\n      kubernetes.io/hostname: { master node }\n    securityContext:\n      runAsUser: { userid }\n      runAsNonRoot: true\n      runAsGroup: { groupid }\n      fsGroup: { fsid }\n    persistentVolume:\n      enabled: true\n      existingClaim: \"prometheus-usb-pvc\"\n      volumeName: \"prometheus-usb-pv\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일부 추가 서비스를 비활성화합니다. 예를 들어 alertmanager, pushgateway, 그리고 configmapreload가 이에 해당합니다. 필요한 경우 다른 시간에 이를 활성화할 수 있습니다. 비정상적으로 행동하는 경우 알림을 받을 수 있는 유용한 도구인 Alert Manager입니다.\n\n이제 ArgoCD로 돌아가 \"새 앱\"을 만들어보겠습니다. Prometheus라는 이름의 앱을 만들고 깃 레포지토리를 소스로 추가하고 경로를 선택하세요. Grafana도 나중에 이 작업을 해야하므로 서로 다른 경로에 유지하세요.\n\n![Image](/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_4.png)\n\n생성한 사용자 정의 설정을 설정할 값 파일을 선택한 다음 앱을 생성하세요. 수동으로 동기화하도록 지정한 경우 동기화가 필요할 때 이를 수행해야 합니다. 이것은 업그레이드할 때 사용하거나 수동으로 릴리스하고자 할 때 유용합니다. 그 외에는 홈 프로젝트에 가장 적합한 CD용 자동 동기화 방법이 유용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Grafana](https://miro.medium.com/v2/resize:fit:1400/1*Ice0ZJGARkN6BdzAl1nGDQ.gif)\n\n마찬가지로 Prometheus와 비슷하게, git 레포지토리에서 새로운 Helm 차트를 생성하는 것부터 시작해보세요.\n\n```js\nhelm create grafana\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n헬름 리포지토리를 추가해주세요.\n\n```js\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n```\n\n리포지토리를 통해 차트를 업데이트하세요.\n\n```js\ndependencies:\n  - name: grafana\n    version: 6.57.4\n    repository: https://grafana.github.io/helm-charts\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nvalues.yaml 파일을 추가해주세요.\n\n```js\ngrafana: service: enabled: true;\ntype: NodePort;\nnodePort: 30180;\n```\n\n그런 다음 이전과 같이 ArgoCD를 통해 Grafana를 추가해주세요. 동기화를 진행하고 이제 두 개가 모두 실행 중이어야 합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_5.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGrafana를 사용하려면 관리자 비밀번호를 먼저 얻어야 합니다.\n\n```js\nkubectl get secret --namespace monitoring grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n```\n\n출력에서 나온 관리자 사용자 이름과 비밀번호로 로그인해주세요.\n\n![이미지](/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 Prometheus 데이터 원본을 추가해 보겠습니다. Prometheus 서비스 URL은 모니터링을 설정한 네임스페이스인 클러스터에서 http://prometheus-server.monitoring.svc.cluster.local로 접근할 수 있습니다. \"Administration\" → \"Data sources\" → \"Add new data source\" 아래로 이동한 다음 URL을 추가하고 \"Save \u0026 Test\"를 클릭하여 확인할 수 있습니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*VphOqjzSh30E4dKrnf2Q2A.gif)\n\n만약 우리 클러스터의 상태를 간단히 확인하고 싶다면 Grafana Labs에서 제공하는 대시보드를 사용할 수 있습니다. 이를 통해 우리 클러스터에서 사용되는 리소스에 대한 간단한 뷰를 확인할 수 있을 것입니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*AIw7esBCtaz5koK_uJTU-w.gif)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 다음 단계\n\n## 사용자 정의 Docker 이미지\n\n당신의 클러스터를 운영하는 중요한 단계로, 공개 Docker.io 레지스트리에 없는 컨테이너나 사용자 정의 컨테이너를 배포할 수 있게 됩니다. 클러스터에 많은 컨테이너를 배포할 계획이라면, 무료 티어 Docker Hub의 제한을 피하기 위해 개인 컨테이너 레지스트리를 설정하는 것을 권장합니다. 이는 GCP의 Artifacts Repository와 같은 클라우드 공급업체나 Harbor와 같은 오픈 소스 docker 저장소로 구현할 수 있습니다.\n\n## 클러스터 자동화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 안내서는 교육 목적이나 소규모 개인 클러스터를 관리할 때 이상적인 Kubernetes 클러스터 설정에 대한 수동 방법을 제공합니다. 그러나 프로덕션 클러스터를 배포하거나 이 안내서의 범위를 벗어나는 작업을 수행할 경우, Ansible과 같은 자동화 도구를 활용하는 것을 권장합니다. 이렇게하면 더 효율적이고 확장 가능하며 관리하기 쉬운 배포가 가능합니다.\n\n# 결론\n\nKubernetes 클러스터를 설정하는 것은 쉽지 않을 수 있지만 한 번 완료되면 일반적인 독립형 서버를 뛰어넘는 확장 가능한 환경을 제공하는 장점이 있습니다.\n\nRaspberry Pi는 비용이 저렴하고 전력 소비가 낮은 옵션이지만, 더 큰 응용 프로그램에 대한 확장성이 여전히 제한되어 있습니다. Kubernetes 클러스터의 장점은 동일한 하드웨어만 실행하는 것에 제한받지 않는다는 것입니다. 새로운 노드를 추가함으로써 다양한 하드웨어를 혼합하여 필요에 맞게 Raspberry Pi나 서버와 같은 다양한 하드웨어를 조합할 수 있습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그것이 좋은 시작점이 되었기를 바랍니다. 읽어 주셔서 감사합니다!\n","ogImage":{"url":"/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_0.png"},"coverImage":"/assets/img/2024-05-18-AGuidetoBuildingaKubernetesClusterwithRaspberryPis_0.png","tag":["Tech"],"readingTime":23},{"title":"러스트 앱을 여러 아키텍처용으로 크로스 컴파일하기","description":"","date":"2024-05-18 19:07","slug":"2024-05-18-Cross-compileyourRustappformultiplearchitectures","content":"\n\u003cimg src=\"/assets/img/2024-05-18-Cross-compileyourRustappformultiplearchitectures_0.png\" /\u003e\n\nRust는 앱 개발을 위한 포맷부터 문서 작성까지 포괄적인 도구를 갖춘 신속하고 견고한 언어입니다. 그러나 컴파일된 언어이므로 다양한 아키텍처 간 호환성을 보장하기 위해 추가적인 노력이 필요합니다. 다행히 Rust는 이를 개발자들을 위해 간소화했습니다. 오늘은 Rust로 기본적인 HTTP 서버 애플리케이션을 작성하고 ARMv7 프로세서용으로 크로스 컴파일하여 네트워크 연결을 통해 STM32MP1 보드에 배포하는 방법에 대해 살펴볼 것입니다.\n\n# 준비물\n\n크로스 컴파일 작업을 시작하기 전에, 특정 사전 준비물이 갖추어져 있어야 합니다. 계속 진행하기 전에 다음 사항을 확인하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Rust이 컴퓨터에 설치되어 있습니다.\n- 당신은 싱글보드 컴퓨터 또는 컴퓨터와 다른 아키텍처를 가진 장치를 사용하고 있습니다. (저는 STM32MP1을 사용하지만 라즈베리파이, 비글본 또는 다른 장치를 사용할 수 있습니다)\n- 싱글보드 컴퓨터에서 리눅스 배포판이 실행 중입니다.\n- 당신은 보드의 IP 주소를 알고 있으며 SSH를 통해 연결할 수 있는 능력을 가지고 있습니다.\n\n# 안녕하세요, 새로운 Arch!\n\n먼저 Rust 프로젝트가 포함될 디렉토리를 생성합니다. 가장 간단한 방법은 원하는 이름으로 빈 폴더를 수동으로 생성한 다음 (예: mkdir hello-new-arch), 해당 폴더로 이동하여 cargo init --bin을 실행하는 것입니다. 이 명령은 실행 가능한 (바이너리) \"hello new arch\" 애플리케이션을 위한 모든 필요한 소스 파일을 생성합니다. 터미널에서 cargo run으로 앱을 컴파일하고 실행하면 모든 것이 잘 작동하면 터미널에 \"Hello, world!\" 메시지가 출력됩니다.\n\n이제 백그라운드에서 실행되는 간단한 HTTP 서버를 생성할 준비가 되었습니다. Rust는 이 작업을 수행하기 위한 여러 우수한 옵션을 제공합니다. 저는 이 작업을 수행하기 위해 Axum을 선호합니다. 이는 이전 프로젝트에서의 경험과 Tokio 비동기 런타임 팀과의 관련성으로 인해입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 Cargo.toml 파일에 필요한 종속성을 추가해야 합니다.\n\n```js\n[package]\nname = \"hello-new-arch\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\naxum = \"0.7.2\"\ntokio = { version = \"1.35.0\", features = [\"full\"] }\n```\n\n다음으로 Axum GitHub 저장소에서 'hello-world' 예제 애플리케이션을 복제합니다. 그 후에는 작은 수정만 필요합니다.\n\n저희가 가장 크게 변경하는 부분은 127.0.0.1:3000에 바인딩하는 대신에 실제로 물리적 네트워크 인터페이스 상에서 노출되지 않는 루프백 주소인 0.0.0.0:3000에 바인딩한다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 이제 로컬에서 cargo run을 통해 다시 실행하고 모든 것이 잘 작동하면 터미널에 \"listening on...\" 메시지를 볼 수 있습니다. 그런 다음 브라우저 탭을 열어 http://localhost:3000/으로 이동하여 \"Hello from another architecture!\" 헤더가 포함된 페이지가 제공되는지 확인합니다.\n\n# 크로스 컴파일 단계!\n\n현재, 우리 앱을 보드에 업로드하려고 하면 실행할 수 없다는 것을 알게 될 것입니다. 이 문제는 우리 프로그램이 보드의 아키텍처와 호환되지 않는 x86 프로세서용으로 컴파일되었기 때문에 발생합니다.\n\nRust를 크로스 컴파일하려면 보드에서 사용 중인 아키텍처를 확인해야 합니다. 한 번 결정되면, 현재 Rust 툴체인에 적합한 타겟 플랫폼을 설치해야 합니다. Rust는 Tier1, Tier2 및 Tier3 수준으로 분류된 많은 아키텍처에 대한 광범위한 지원을 제공합니다. 이러한 티어 간의 차이점에 대한 포괄적인 이해를 위해 문서를 참조하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, 제 STM32MP1 보드에는 ARMv7 32비트 프로세서가 탑재되어 있습니다. 공식 Rust 책에 따르면, 이 구성을 위한 필수 대상은 armv7-unknown-linux-gnueabihf입니다. 대략적으로, 선택한 대상 구성 요소는 다음과 같은 의미를 갖습니다:\n\n- armv7: 대상 프로세서에 사용할 아키텍처인 ARM v7\n- unknown: 사용할 서브 아키텍처; 여기서는 기본 옵션을 의미함\n- linux: 대상 운영 체제\n- gnueabihf: 대상 ABI; gnu는 실행 중에 일부 기능에 GNU C 라이브러리(이른바 libc로도 알려짐)를 의존한다는 것을 의미하며, hf는 하드웨어 부동 소수점 연산을 지원한다는 것을 의미함\n\n이 특정 대상을 위해 Rust를 구성하려면 다음 명령을 실행하세요:\n\n```js\nrustup target add armv7-unknown-linux-gnueabihf\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 이 명령어를 사용하여 교차 컴파일을 시도해 봅시다:\n\n```js\ncargo build --release --target=armv7-unknown-linux-gnueabihf\n```\n\n그러나 잠시 후에 다음과 유사한 오류가 발생할 가능성이 있습니다:\n\n```js\nerror: linking with `cc` failed: exit code: 1\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2진 파일이 성공적으로 컴파일되었지만 링킹 실패가 발생했습니다. 이 문제가 발생하는 이유는 우리 개발 머신에서 Cargo가 x86 바이너리나 호스트 시스템의 특정 아키텍처를 위해 구성된 cc 및 ld에 의존하기 때문입니다. 이로 인해 ARM 바이너리를 조립할 필요한 지식이 부족합니다. 이 작업에 더 적합한 링커를 사용하도록 Cargo를 안내해야 합니다. 또한 ARM 아키텍처와 관련된 컴파일 또는 링크 작업을 처음 시도하는 경우 필요한 도구를 아직 설치하지 않았을 가능성이 높습니다. 이 문제를 해결하려면 Ubuntu에서 다음 명령을 사용하십시오:\n\n```js\nsudo apt install gcc-arm-linux-gnueabihf\n```\n\n이제 ARM에 적합한 링커와 컴파일러를 설치하고, 'arm-linux-gnueabihf-gcc' 명령어를 호출하여 테스트해보겠습니다(인수 없이 호출하면 즉시 종료됨).\n\n그러나 Cargo가 바이너리의 링킹 단계에서 이를 활용하도록하려면 안내가 필요합니다. 이를 위해 ./.cargo/config라는 새 파일을 만들어 다음 내용을 입력해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[target.armv7-unknown-linux-gnueabihf]\nlinker = \"arm-linux-gnueabihf-gcc\"\n\n이렇게 하면 ARM-specific 버전의 gcc를 사용하여 armv7-unknown-linux-gnueabihf Rust target을 위해 컴파일된 이진 파일을 링킹하는데 cargo가 지시됩니다.\n\n## http-server를 시도해봅시다\n\n좋아요, 이제 보드의 아키텍처에 맞는 올바른 컴파일 설정을 성공적으로 설정했으니, 여러 단계를 고려하여 프로세스를 간소화하기 위해 셸 파일을 스크립팅하는 것이 좋겠네요. 이 스크립트는 배포 워크플로를 자동화하여 실행을 더 쉽게 할 것입니다. 동일한 디렉토리에 deploy.rs라는 이름의 텍스트 파일을 생성하고 다음 콘텐츠를 추가합니다. 각 명령어의 기능에 대한 명확성을 위해 주석도 추가했어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러면 chmod +x ./deploy.rs와 같은 명령으로 스크립트를 실행 가능하게 만들어 줍니다. 그러면 ./deploy를 통해 직접 실행할 수 있습니다. 이제 바로 시도해 볼 수 있고, 만약 deploy 스크립트에 매개변수를 올바르게 작성했다면, 서버에서 \"listening on 'your board ip address'\"라는 로그 라인을 마침내 볼 수 있게 됩니다. 이는 서버가 최종적으로 대상 보드에서 올바르게 실행되고 있음을 의미합니다!\n\n웹 서버에 액세스하려면 브라우저 탭을 열고 http://'your_board_ip_address':3000으로 이동하면 됩니다. 이제 이 익숙한 웹 페이지가 보드에서 직접 제공되고 있습니다. 접근성을 확인하기 위해 다른 기기(같은 네트워크에 연결된 스마트폰 등)에서 접속을 시도할 수 있습니다.\n\n이 프로그램이 프로덕션에 즉시 적합한 것은 아닙니다. SSH 세션을 종료한 후에도 계속 작동되도록 보장하려면 지속적인 실행을 지원하는 시스템을 구현해야 할 수도 있습니다. 이러한 개선 사항 및 조정 사항은 향후 기사에서 다룰 수도 있습니다.\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n관찰해 보았을 때, 크로스 컴파일은 인내와 해당 하드웨어에 대한 이해가 필요합니다. 그러나 러스트의 생태계와 관련 도구를 활용하면, 처음에 예상했던 것보다 덜 어려울 수 있습니다. 독자 여러분, 감사합니다!\n","ogImage":{"url":"/assets/img/2024-05-18-Cross-compileyourRustappformultiplearchitectures_0.png"},"coverImage":"/assets/img/2024-05-18-Cross-compileyourRustappformultiplearchitectures_0.png","tag":["Tech"],"readingTime":7}],"page":"90","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"90"},"buildId":"-dPCbnM2yhdKNgXe92VJV","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>