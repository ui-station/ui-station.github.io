<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/90" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/90" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_buildManifest.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기" href="/post/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트" href="/post/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터브릭스 리퀴드 클러스터링" href="/post/2024-05-20-DatabricksLiquidClustering"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터브릭스 리퀴드 클러스터링" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-DatabricksLiquidClustering_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터브릭스 리퀴드 클러스터링" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터브릭스 리퀴드 클러스터링</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 인프라 및 대형 언어 모델" href="/post/2024-05-20-DataInfraandLargeLanguageModel"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 인프라 및 대형 언어 모델" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-DataInfraandLargeLanguageModel_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 인프라 및 대형 언어 모델" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터 인프라 및 대형 언어 모델</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Netflix의 미디어 랜드스케이프 진화 321에서 클라우드 스토리지 최적화로" href="/post/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Netflix의 미디어 랜드스케이프 진화 321에서 클라우드 스토리지 최적화로" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Netflix의 미디어 랜드스케이프 진화 321에서 클라우드 스토리지 최적화로" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Netflix의 미디어 랜드스케이프 진화 321에서 클라우드 스토리지 최적화로</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="DevOps 웃고 배우고 반복하기 - Bhavesh" href="/post/2024-05-20-DevOpsLaughLearnRepeatByBhavesh"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="DevOps 웃고 배우고 반복하기 - Bhavesh" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-DevOpsLaughLearnRepeatByBhavesh_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="DevOps 웃고 배우고 반복하기 - Bhavesh" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">DevOps 웃고 배우고 반복하기 - Bhavesh</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="5가지 재미있는 AWS 프로젝트를 배우는 법" href="/post/2024-05-20-5FunProjectstolearnAWS"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="5가지 재미있는 AWS 프로젝트를 배우는 법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-5FunProjectstolearnAWS_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="5가지 재미있는 AWS 프로젝트를 배우는 법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">5가지 재미있는 AWS 프로젝트를 배우는 법</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">40<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="아마존 S3 프리사인드 URL 활용 방법" href="/post/2024-05-20-HowtoutilizeAmazonS3presignedURLs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="아마존 S3 프리사인드 URL 활용 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="아마존 S3 프리사인드 URL 활용 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">아마존 S3 프리사인드 URL 활용 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="쿠버네티스 시크릿을 암호화하는 방법" href="/post/2024-05-20-HowtoEncryptKubernetesSecrets"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="쿠버네티스 시크릿을 암호화하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-HowtoEncryptKubernetesSecrets_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="쿠버네티스 시크릿을 암호화하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">쿠버네티스 시크릿을 암호화하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년 게임 업계의 지속적인 리소그린드에 대해 무슨 일이 일어나고 있을까요" href="/post/2024-05-20-Whatsupwiththeconstantgaminglayoffsin2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 게임 업계의 지속적인 리소그린드에 대해 무슨 일이 일어나고 있을까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-Whatsupwiththeconstantgaminglayoffsin2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 게임 업계의 지속적인 리소그린드에 대해 무슨 일이 일어나고 있을까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">2024년 게임 업계의 지속적인 리소그린드에 대해 무슨 일이 일어나고 있을까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/81">81</a><a class="link" href="/posts/82">82</a><a class="link" href="/posts/83">83</a><a class="link" href="/posts/84">84</a><a class="link" href="/posts/85">85</a><a class="link" href="/posts/86">86</a><a class="link" href="/posts/87">87</a><a class="link" href="/posts/88">88</a><a class="link" href="/posts/89">89</a><a class="link posts_-active__YVJEi" href="/posts/90">90</a><a class="link" href="/posts/91">91</a><a class="link" href="/posts/92">92</a><a class="link" href="/posts/93">93</a><a class="link" href="/posts/94">94</a><a class="link" href="/posts/95">95</a><a class="link" href="/posts/96">96</a><a class="link" href="/posts/97">97</a><a class="link" href="/posts/98">98</a><a class="link" href="/posts/99">99</a><a class="link" href="/posts/100">100</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Azure Data Factory에서 Databricks 작업 클러스터에 동적 태그 적용하기","description":"","date":"2024-05-20 17:01","slug":"2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory","content":"\n아래는 Markdown 형식으로 변경한 텍스트입니다.\n\n![이미지](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png)\n\n최근 몇 명의 고객이 Databricks 노트북 액티비티를 Azure Data Factory에서 실행할 때, 노트북을 실행할 작업 클러스터에 동적으로 태그를 설정하는 방법에 대해 물어봤어요.\n\n다행히도 Azure Data Factory의 매개변수와 동적 콘텐츠 기능 덕분에 해결책을 상당히 쉽게 찾을 수 있어요.\n\n# Prerequisites\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Azure Databricks 워크스페이스에 액세스 권한, Azure Data Factory 인스턴스, 그리고 워크스페이스에서 작업을 만들고 실행할 수 있는 능력이 있다고 가정합니다.\n\n# 링크드 서비스를 매개변수화하기\n\n- Azure Data Factory에서 새로운 Azure Databricks 링크드 서비스를 만듭니다.\n- 편집기의 매개변수 섹션에 동적으로 지정하고자 하는 각 태그 값에 대해 매개변수를 추가하세요. 이 예시에서는 CustomTag라는 매개변수를 추가하고 기본값을 설정했습니다.\n\n![이미지](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 클러스터 사용자 정의 태그 섹션에서 태그 이름을 추가하고 값 필드를 선택하세요. 텍스트 상자 아래에 동적 콘텐츠를 추가할 링크가 나타납니다. 이를 클릭해주세요:\n\n![Cluster custom tags](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_2.png)\n\n4. 'Pipeline Expression Builder' 패널이 열립니다. 하단에는 이전에 생성한 'ClusterTag' 매개변수가 파라미터 목록에 있을 겁니다. 이 매개변수를 클릭하여 파이프라인 표현식에 삽입하세요. 확인을 클릭해주세요.\n\n![ClusterTag parameter](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. 클러스터의 나머지를 보통대로 구성하세요.\n\n최종 연결된 서비스 구성은 다음과 같아야 합니다.\n\n![Linked Service Configuration](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_4.png)\n\n# 파라미터에 동적 값을 바인딩하세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 우리가 연결된 서비스에서 태그 값에 대한 매개변수를 갖고 있으므로 해당 연결된 서비스를 사용하는 각 활동에 대해 값을 바인딩할 수 있습니다.\n\n- 새로운 Databricks 노트북 활동을 만듭니다.\n- 활동 구성 패널에서 Azure Databricks 탭을 참고하면 Linked Service 속성에 우리가 만든 매개변수가 포함되어 있음을 알 수 있습니다:\n\n![Linked Service Properties](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_5.png)\n\n3. 여기에는 세 가지 옵션이 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이 속성값을 비워두면 클러스터는 태그의 값에 이전에 설정한 기본값을 사용합니다.\n- 이곳에 정적 값을 지정할 수 있으며, 이 값은 태그의 값으로 매개변수를 통해 전달됩니다.\n- 다시 동적 콘텐츠 옵션을 사용하여 이 매개변수에 대한 표현식을 제공할 수 있습니다. 전체 ADF 파이프라인으로 전달되는 매개변수, 파이프라인 자체의 이름, 파이프라인이 트리거된 날짜 또는 다른 활동의 출력값일 수 있습니다.\n\n이 튜토리얼에서는 여기에 정적 값만 할당하겠습니다:\n\n![image](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_6.png)\n\n참고로 만일 우리 파이프라인에 여러 활동이 있다면, 각 활동에 대해 이 속성에 고유한 값을 할당할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수동으로 이 파이프라인을 실행한 후에는 Azure Databricks의 작업 클러스터로 사용자 정의 동적 태그 값이 전파된 것을 볼 수 있습니다:\n\n![동적 태그 적용 예시](/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_7.png)\n\n이 태그는 클러스터에서 사용되는 Azure VM에도 전파되어, Azure 포털의 Azure 비용 관리 도구에서 청구 및 감사 목적으로 사용할 수 있습니다.\n\n이제 Databricks 시스템 테이블에서 이 태그를 조회하여 클러스터와 관련 청구 사용 내역을 찾을 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식의 테이블입니다.\n\n| 파일 이름                                                                     | 경로                                                                                      |\n| ----------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |\n| 2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_8.png | /assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_8.png |\n| 2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_9.png | /assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_9.png |\n\n이 내용이 Databricks에서의 컴퓨팅 및 파이프라인의 가시성 관리에 도움이 되기를 바랍니다. 피드백은 언제나 환영합니다!\n","ogImage":{"url":"/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png"},"coverImage":"/assets/img/2024-05-20-ApplyingDynamicTagsToDatabricksJobClustersinAzureDataFactory_0.png","tag":["Tech"],"readingTime":6},{"title":"모든 데이터 엔지니어를 위한 필수 PySpark 차트 시트","description":"","date":"2024-05-20 16:59","slug":"2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers","content":"\n## 모든 Pyspark 스크립트 작성을 수정하고, 시간을 절약한 상태로 현명하게 연습하세요.\n\n\"일을 맹목적으로 끝내는 것보다는 최적의 효율성과 효과적인 방법으로 실행하는 것이 중요합니다.\"\n\n여기 제공된 치트 시트는 PySpark의 주요 측면을 신속하게 검토하고, 인터뷰 준비 또는 Databricks나 Python 기반 코딩 환경과 같은 다양한 플랫폼에서 데이터 분석 작업에 대비할 수 있게 돕습니다.\n\n이 도구를 이용하면 PySpark 및 관련 프레임워크에 필수적인 중요한 변환 기술 및 데이터 분석 방법론을 신속하게 검토할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 시작해봅시다\n\nPySpark를 사용하여 변환 작업이나 데이터 분석 작업을 시작하기 전에 Spark 세션을 설정하는 것이 중요합니다. 이 초기 단계는 Spark 프레임워크 내에서 코드 실행의 기반을 제공합니다. 더 중요한 것은 후속 작업을 위한 기반을 구축하고 Spark 기능과 원활하게 상호 작용할 수 있도록 합니다.\n\n먼저 의도한 작업에 필요한 모듈을 가져와야 하며, 모든 중요한 구성 요소가 사용 가능하도록 보장해야 합니다. 이 기본 절차를 준수함으로써 개발자와 데이터 전문가는 PySpark의 강력한 기능을 활용하여 데이터 처리와 분석 작업을 원활하게 수행할 수 있습니다.\n\n## 시작해봅시다!!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import types\nfrom pyspark.sql.types import SparkType, StructField, StringType, IntegerType, DataType\nfrom pyspark.sql.functions import col, date, year, time, sum, avg, upper, count, Broadcast, expr\nfrom pyspark.sql import window\nfrom pyspark.sql import functions as F\n\nspark = SparkSession.builder.appName(\"application\").getOrCreate()\n\n# read any file as given either csv, excel, parquet, or Avro any format of data\n\ndata = spark.read.csv(\"filePath\", header=True, inferschema=True) # if we want given data types as it is\nschema = StructType([StructField(\"id\", IntegerType), StructField(\"name\", StringType),\nStructField(\"dept\", StringType)]) # if we want our required data types then we use this\n\n# also for better performance of executions we will be using our custom schema rather depending on inferschema\n\nLet’s kickstart our PySpark application by first creating a Spark Session, the entry point to PySpark functionality.\n\nWe’ll then proceed with performing various transformations and analyses on sample data.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n데이터 = [(1, 'mahi', 100), (2, 'mahendra', 200), (3, 'harish', 300), (4, 'desh', 400)]\n\n스키마 = ['id', 'name', 'salary']\n# 데이터 프레임 생성\ndf = spark.createDataFrame(data, schema)\ndf.head()\ndf.show()\ndisplay(df)\n```\n\n![image](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png)\n\nPySpark에서 윈도우 함수를 사용하여 급여의 누적 합을 계산할 수 있습니다.\n\n```js\na = Window().orderBy(\"id\");\n누적_합 = df.withColumn(\"cumulative_sum\", sum(\"salary\").over(a));\n결과 = cumulative_sum.orderBy(\"id\");\n결과.show();\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\na = Window().orderBy('id')\n누적합 = df.withColumn(\"누적합\", avg(\"salary\").over(a))\n결과 = 누적합.orderBy('id')\n결과.show()\n```\n\n![이미지](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_1.png)\n\n```python\nemp=[(1,'마히', 100,1),(2,'마헨드라', 200,2),(3,'하리쉬',300,3),\n(4,'데시',400,4)]\n\n스키마=['id', 'name', 'salary', 'dept_id']\n# 데이터 프레임 생성\ndf=spark.createDataFrame(data,schema)\ndf.head()\ndf.show()\ndisplay(df)\n\ndept=[(1,'인사'),(2,'영업'),(3,'데이터 분석'),(4,'IT')]\n스키마=['dept_id', 'department']\n부서=spark.createDataFrame(dept,schema)\ndisplay(부서)\n```\n\n![이미지](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n공통 속성인 dept_id를 사용하여 두 개의 데이터 프레임을 결합해 봅시다. 예시를 들어보겠습니다:\n\n```js\ndf = employee\n  .join(department, \"dept_id\", \"inner\")\n  .select(\"id\", \"name\", \"salary\", \"department\");\ndisplay(df);\n```\n\n```js\ndf = employee.join(department, \"dept_id\", \"right\").select(\"name\", \"department\");\ndisplay(df);\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_3.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서는 다양한 PySpark 변환, 액션 및 기능에 대해 상세히 설명하겠습니다. 실행 가능한 코드 예제와 함께 다룰 예정이에요.\n\n기본적인 변환인 필터링 및 그룹화부터 창 함수와 같은 고급 기술까지 다양한 작업을 다룰 거에요.\n\n각 코드 조각은 개념을 포괄적으로 이해할 수 있도록 설명하는 문장과 함께 제공됩니다.\n\n데이터 조작 작업부터 시작하여 PySpark 데이터 프레임을 사용하여 데이터 필터링, 선택 및 집계를 살펴보겠습니다. 그 후에는 조인, 정렬 및 창 함수와 같은 변환을 통해 다수의 테이블에서 데이터를 조작하고 분석하는 방법을 살펴볼 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, 우리는 샘플 데이터셋을 활용하여 모델 학습과 평가를 통해 머신러닝 작업을 지원하는 Pyspark을 소개할 것입니다.\n\n이 치트 시트를 통해 각 코드 스니펫은 해당 개념의 실제 시연을 제공하여 빠른 참고와 이해를 돕게 됩니다.\n\n이 예제를 따라가며 사용자들은 Pyspark 능력을 향상시키고 데이터 엔지니어링 및 데이터 과학 인터뷰나 실제 데이터 처리 작업에 대비할 수 있습니다.\n\n## 필터링, 선택, 집계, 그룹화 및 정렬 조건:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndf = orders.join(products, \"order_id\", \"inner\") # 어떤 조인 적용\ndf.join(df2, '공통 열').groupBy('표시할 열').count().orderBy(desc('count'))\n\n\ndf1=df.groupBy(\"cust_id\").agg(sum(\"amount\").alias(\"bill\")) # 그룹화 함수 적용 및 집계 조건을 지정\n\ndf.groupBy(\"col1\").agg(count(\"col2\").alias(\"count\"),\n                          sum(\"col2\").alias(\"sum\"),\n                          max(\"col2\").alias(\"maximum\"),\n                          min(\"col2\").alias(\"minimum\"),\n                          avg(\"col2\").alias(\"average\")).show()\n\n\ndf.drop(\"column_name1\", \"column_name2\", \"column_name3\") # 열 삭제\ndf.drop(col(\"column_name\")) # 다른 열 삭제 방법\n\ndf.createOrReplaceTempView(\"원하는 이름 지정\") # 데이터 프레임을 테이블로 변환\n\ndf.orderBy(F.desc(\"column_name\")).first() # 특정 열(예: 급여)의 내림차순 첫 번째 행 반환\ndf.orderBy(col(\"column_name\").desc()).first() # 가장 높은 값을 반환하는 또 다른 방법\ndf.orderBy(col(\"column_name\").desc()).limit(5) # 상위 5개의 값을 반환\n\n# 원하는 열에 필터 적용\ndf.filter(df.column_name==값).show()\n\n# 필터링된 결과와 함께 필요한 열 선택\ndf.select(\"column1\", \"column2\", \"column3\").where(col(\"any column\")==\"any value\")\ndf.select(\"column1\").where(col(\"column1\")\u003e 값).show(5)\ndf.sort(\"원하는 열 이름\")\n\n# 열 이름 변경\ndf.withcolumn Renamed(\"기존 열 이름\", \"원하는 열 이름으로 변경\")\n```\n\nPySpark는 데이터 프레임 내에서 날짜 속성을 추출하고 조작하는 편리한 방법을 제공하며, 사용자가 연도, 월, 일과 같은 다양한 기준으로 통찰력을 얻을 수 있도록 합니다.\n\n또한, 이러한 속성들은 오름차순이나 내림차순으로 정렬하여 분석과 시각화를 용이하게 할 수 있습니다.\n\n## 날짜 열에서 일, 월, 연도 추출하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데이터 프레임에서 연도, 월, 일 세부 정보 추출하기\n\ndf.select(year(\"date column\").distinct().orderBy(year(\"date column\")).show()\ndf.select(month(\"date column\").distinct().orderBy(month(\"date column\")).show()\ndf.select(day(\"date column\").distinct().orderBy(day(\"date column\")).show()\n\ndf.withColumn(\"orderyear\", year(\"df.date column\"))\ndf.withColumn(\"ordermonth\", month(\"df.date column\"))\ndf.withColumn(\"orderday\", day(\"df.date column\"))\ndf.withColumn(\"orderquarter\", quarter(\"df.date column\"))\n\n특정 열에서 null 값을 필터링하고 그 다음에 지정된 순서로 그룹화 작업을 수행하기 위해 조건을 적용할 수 있습니다.\n\ndf.select(\"column name we want to retrieve\").where(col(\"column name we want to retrieve\").isNotNull())\\\n.groupBy(\"column name we want to retrieve\").count().orderBy(\"count\", ascending=False).show(10)\n\n## 함수 작성하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndf.write.format(\"CSV\").mode(\"overwrite\").save(\"원하는 파일 저장 경로\");\ndf.write.format(\"CSV\").mode(\"append\").save(\"원하는 파일 저장 경로\");\ndf.write.format(\"Parquet\").mode(\"overwrite\").save(\"원하는 파일 저장 경로\");\ndf.write.format(\"parquet\").mode(\"append\").save(\"원하는 파일 저장 경로\");\n```\n\n## 윈도우 함수:\n\n```js\nwind_a=Window.partitionBy(\"col1\").orderBy(\"col2\").rangeBetween(Window.unboundedpreceeding, 0)\n\ndf_w_coloumn= df.withColumn(\"col_sum\", F.sum(\"salary\").over(wind_a) #롤링 합계 또는 누적 합계:\n\n\n#행 번호\na=Window.orderBy(\"date_column\") #예시로 날짜 열을 고려하였지만 원하는 열을 선택할 수 있습니다\nsales_data=df.withColumn(\"row_number\", row_number().over(a))\n\n#순위\nb=Window.partitionBy(\"date\").orderBy(\"sales\")\nsales_data=df.withColumn(\"sales_rank\", rank() over(b))\n\n#조밀한 순위\nb=Window.partitionBy(\"date\").orderBy(\"sales\")\nsales_data=df.withColumn(\"sales_dense_rank\", desne_rank() over(b))\n\n\n#지연\nc=Window.partitionBy(\"Item\").orderBy(\"date\") #예시 열을 고려하여 원하는 열을 선택할 수 있습니다\nsales_data=df.withColumn(\"pre_sales\", lag(col(\"sales\"),1).over(c))\n\n\n#리드\nd=Window.partitionBy(\"Item\").orderBy(\"date\") #예시 열을 고려하여 원하는 열을 선택할 수 있습니다\nsales_data=df.withColumn(\"next_sales\", lead(col(\"sales\"),1).over(d))\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사는 데이터 엔지니어링 면접에 대비하는 개인들에게 가치 있는 도구로 작용하며, Databricks 플랫폼을 위해 구체적으로 맞춘 PySpark 함수와 수식들에 대한 간결하면서 포괄적인 요람을 제공합니다.\n\n구조화된 레이아웃과 각 예제와 함께 제공되는 자세한 설명으로, 본 자료는 독자들이 10분만 투자하여 주요 개념들을 효율적으로 검토하고 숙지할 수 있도록 도와줍니다.\n\n이러한 기본 기능들을 숙달함으로써 희망하는 데이터 엔지니어들은 자신감을 키우고 다양한 면접 상황을 쉽게 해결할 수 있는 준비를 갖추게 되며, 이를 통해 더욱 흥미로운 데이터 엔지니어링 직무를 얻을 성공 기회를 극대화할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래에서 데이터 엔지니어 인터뷰를 준비하는 데 도움이 되는 몇 가지 더 많은 기사를 찾을 수 있습니다.\n\n- SQL 사용 사례 - 데이터 엔지니어 인터뷰\n- 데이터 엔지니어 인터뷰에서 가장 일반적으로 묻는 빅데이터(Apache Spark) 개념\n- 데이터 엔지니어 인터뷰를 위한 Python 코딩 문제 제1부 (쉬운 난이도)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제 소중한 내용을 더 많이 공유할 수 있도록 함성 소리로 응원해주신다면 감사하겠습니다.\n\n저를 팔로우하고 구독하여 제 소식을 즉시 받아보세요.\n\n감사합니다 :)\n","ogImage":{"url":"/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png"},"coverImage":"/assets/img/2024-05-20-TheEssentialPySparkCheatSheetforAllDataEngineers_0.png","tag":["Tech"],"readingTime":12},{"title":"데이터브릭스 리퀴드 클러스터링","description":"","date":"2024-05-20 16:57","slug":"2024-05-20-DatabricksLiquidClustering","content":"\n이전에 데이터 레이크하우스 세계에서 데이터 분할의 끊임없는 도전에 대한 동적 해결책이 있는지 궁금했나요?\n\n음, 저는 궁금했어요! 그럼 함께 이야기해보죠.\n\n## 고정된 데이터 레이아웃의 도전\n\n다음 그래프를 살펴보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![DatabricksLiquidClustering](/assets/img/2024-05-20-DatabricksLiquidClustering_0.png)\n\n이 그래프는 연도별 테이블 행 수를 예측하고 데이터 분포에서 상당한 치우침을 보여줍니다. 이 치우침은 소비자가 쿼리에서 연도 열을 자주 필터로 사용하기 때문에 특히 관련이 있습니다.\n\n이 테이블은 생성 시 year 및 month 열을 사용하여 파티션으로 설정되었습니다. 이것이 바로이 테이블을 위한 DDL의 형태입니다.\n\n```js\n%sql\nCREATE TABLE kaggle_partitioned (\n  year_month STRING,\n  exp_imp TINYINT,\n  hs9 SMALLINT,\n  Customs SMALLINT,\n  Country BIGINT,\n  quantity BIGINT,\n  value BIGINT,\n  year STRING,\n  month STRING\n) USING delta PARTITIONED BY (year, month);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기 문제가 있어요. 테이블의 전체 데이터 중 약 83%가 2개의 파티션에 있습니다.\n\n![이미지](/assets/img/2024-05-20-DatabricksLiquidClustering_1.png)\n\n위의 정보를 바탕으로 테이블이 너무 적게 파티셔닝되었는지, 아니면 너무 많이 파티셔닝되었는지 어떻게 생각하시나요?\n\n이 테이블의 데이터 분포를 더 깊게 살펴보겠습니다. 다음 차트는 연간 행 수의 월별 분할을 보여줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![데이터 분포의 그림적 표현](/assets/img/2024-05-20-DatabricksLiquidClustering_2.png)\n\n더 자세히 데이터 분포를 나타낸 그림을 살펴보면, 2020년 3월에 가장 많은 데이터가 있고, 그 뒤를 이어서 1월과 2월이, 다른 달들은 더 작은 파티션으로 이어지고 있습니다.\n\n그래서, 테이블이 과분할되었는지? 아니면 과소분할되었는지? 아니면 둘 다인가요?\n\n다음 그림이 어떤 연관성이 있나요? 무슨 의미를 전달하나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-DatabricksLiquidClustering_3.png\" /\u003e\n\n현재 파티셔닝 전략대로,\n\n- 2020–03과 같은 파티션의 경우, 한 시간치 데이터를 쿼리하기 위해 많은 양의 데이터를 읽어야 할 지도 모릅니다.\n- 반면에 다른 극단적인 상황에서는, 적은 양의 데이터를 가진 고객을 위한 쿼리를 수행하기 위해 여러 파티션을 가로질러 많은 작은 파일을 스캔해야 할 수도 있습니다.\n- 마지막으로, 테이블을 주/일/월 단위로 다시 파티셔닝해야 할 경우, 전체 테이블을 다시 작성해야 합니다. 또 다시요!\n\n이제 우리 테이블에서 데이터 쓰기 시나리오를 논의해 봅시다. 제 생각에는 이미지가 제 의견을 요약해 주고 있으므로 글로 다시 작성할 필요는 없을 것 같아요 ;)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-DatabricksLiquidClustering_4.png\" /\u003e\n\n지금! 이 기사의 맨 첫 줄을 한 번 더 반복합시다!\n\n데이터 레이크하우스 세계에서 데이터 파티셔닝의 끊임없는 도전에 대한 동적 솔루션이 있는지 궁금했던 적이 있나요?\n\n리퀴드 클러스터링이 등장했습니다! 데이터 레이아웃 결정을 간소화하고 쿼리 성능을 향상시키며, 지속적인 모니터링 및 조정을 요구하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서 어떻게 하는 건가요?\n\n- 빠름: 튜닝된 분할 테이블과 유사한 쓰기 및 읽기 속도\n- 자체 튜닝: 과다 및 부족한 분할을 피함\n- 점진적: 새 데이터의 자동 부분 클러스터링\n- 스쿠 내성: 일관된 파일 크기와 낮은 쓰기 증폭\n- 유연함: 클러스터링 열을 변경하고 싶나요? 문제 없어요!\n- 더 나은 병행성: 테이블에서 행 수준의 병행성 활성화\n\n좀 더 자세히 이해해 보겠습니다. 이전에 보여드린 샘플 레이아웃 다이어그램을 사용할 거예요.\n\n![다이어그램](/assets/img/2024-05-20-DatabricksLiquidClustering_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요렇게 Liquid Clustering이 어떻게 도와주는지 확인해보세요! Liquid Clustering은 군집화와 파일 크기의 효율적인 균형을 이룹니다.\n\n![Liquid Clustering](/assets/img/2024-05-20-DatabricksLiquidClustering_6.png)\n\n작은 파티션을 자동으로 처리할 뿐만 아니라, 큰 파티션에서 시간별 데이터만 가져오려면 더 효율적인 쿼리를 위해 더 나눌 수 있습니다.\n\n![Liquid Clustering](/assets/img/2024-05-20-DatabricksLiquidClustering_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n실제로 보여드릴게요! 여기 파티션된 테이블의 파일 크기 분포입니다.\n\n![이미지](/assets/img/2024-05-20-DatabricksLiquidClustering_8.png)\n\n이 파티션된 테이블에서 클러스터된 테이블을 생성해보겠습니다. CTAS를 사용할 거에요.\n\n```js\nCREATE TABLE kaggle_clustered CLUSTER BY(year, month) AS\nSELECT\n  *\nFROM\n  kaggle_partitioned;\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 군집 테이블의 파일 크기 분포도가 여기 있어요.\n\n![file size distribution](/assets/img/2024-05-20-DatabricksLiquidClustering_9.png)\n\n작은 파일 대부분이 통합되어 더 최적화된 파일이 생성된 것이 명백하게 나타나네요.\n\n액체 클러스터링은 일부/게으른 클러스터링을 활용하여 효율적으로 적재를 돕습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그걸 어떻게 이해하는지 알아봅시다.\n\n- 2021-01은 제가 파티션 테이블에 데이터가 없는 파티션입니다.\n- 해당 날짜 범위의 데이터를 적재하기 시작하면, 모든 고객을 포함하는 파일이 생성됩니다.\n- 데이터 집합이 증가함에 따라, Liquid Clustering은 고객을 위한 파일을 분할하기 시작합니다.\n- 분할 작업은 가끔 작은 파일로 나누어지지만, 테이블 유지 관리는 이 작은 파일을 자동으로 큰 파일로 병합하여 읽기 성능에 영향을 미치지 않도록 합니다.\n\n# 그래서! 테이블에서 어떻게 사용하나요?\n\n첫 번째로! 클러스터링은 파티셔닝이나 ZORDER와 호환되지 않으며, Databricks 클라이언트가 테이블의 데이터에 대한 모든 레이아웃 및 최적화 작업을 관리해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 리퀴드 클러스터링을 사용하여 델타 테이블을 생성하는 방법을 살펴보겠습니다.\n\n```js\n--빈 테이블 생성하기\nCREATE TABLE table1(col0 int, col1 string) USING DELTA CLUSTER BY (col0);\n\n\n--CTAS 문 사용하기\nCREATE EXTERNAL TABLE table2 CLUSTER BY (col0) --테이블 이름 뒤에 클러스터링을 지정하고, 서브쿼리에는 사용하지 않기\nLOCATION 'table_location' AS\nSELECT\n  *\nFROM\n  table1;\n\n\n--구성 복사를 위해 LIKE 문 사용하기\nCREATE TABLE table3 LIKE table1;\n```\n\n# 클러스터링을 트리거하는 방법\n\n간단히 테이블에 OPTIMIZE 명령을 사용하면 됩니다. 아래 예시를 참고하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n테이블 이름을 최적화하세요;\n```\n\n리퀴드 클러스터링은 증분 방식으로 작동합니다. 따라서 클러스터링해야 하는 데이터를 수용하기 위해서만 데이터가 다시 작성됩니다. 클러스터링 키를 갖는 데이터 파일이 클러스터링해야 하는 데이터와 일치하지 않는 경우 재작성되지 않습니다.\n\n데이터를 클러스터링하고 최상의 성능을 얻기 위해 정기적으로 최적화 작업을 실행해야 합니다. 리퀴드 클러스터링은 증분 방식이므로 대부분의 클러스터링된 테이블의 최적화 작업이 빠르게 실행됩니다.\n\n# 리퀴드 클러스터링은 무엇에 사용되나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDatabricks 문서에 따르면, 모든 새로운 Delta 테이블에는 리퀴드 클러스터링을 사용하는 것이 권장됩니다. 클러스터링이 유용한 시나리오의 예시는 다음과 같습니다:\n\n- 높은 카디널리티 열을 기반으로 자주 필터링되는 테이블.\n- 데이터 분포에서 상당한 불균형이 있는 테이블.\n- 빠르게 성장하여 유지보수와 조정 노력이 필요한 테이블.\n- 동시에 쓰기 요구사항이 있는 테이블.\n- 시간이 지남에 따라 액세스 패턴이 변경되는 테이블.\n- 전형적인 파티션 키가 테이블에 너무 많거나 너무 적은 파티션을 남길 수 있는 테이블.\n\n## 리퀴드 클러스터링 사용 시 고려해야 할 사항\n\n- 클러스터링 키로 수집된 통계가 있는 열만 지정할 수 있습니다. 기본적으로 Delta 테이블의 처음 32열에는 통계가 수집됩니다.\n- 최대 4개의 열을 클러스터링 키로 지정할 수 있습니다.\n- 구조화된 스트리밍 워크로드는 라이트 시 클러스터링을 지원하지 않습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-DatabricksLiquidClustering_0.png"},"coverImage":"/assets/img/2024-05-20-DatabricksLiquidClustering_0.png","tag":["Tech"],"readingTime":9},{"title":"데이터 인프라 및 대형 언어 모델","description":"","date":"2024-05-20 16:53","slug":"2024-05-20-DataInfraandLargeLanguageModel","content":"\n데이터 인프라 산업, CRM 및 사이버 보안 산업은 언제나 전 세계에서 소프트웨어 부문 중 상위 세 분야 중 하나였습니다. (가트너 2023: 데이터 인프라 15%, CRM 14%, 사이버 보안 10%). 데이터 인프라 분야에서는 Oracle과 같은 거물 기업이 3000억 달러 이상의 가치를 지니고 있습니다. 또한 Snowflake, Databricks, MongoDB와 같은 신생 기술 스택, 포괄적인 제품 포트폴리오를 갖춘 세 가지 주요 클라우드 제공업체와 함께 수백 개의 데이터베이스가 DB-Engines.com에 의해 모니터링되고 있습니다.\n\n지난 5년 동안 데이터 인프라는 클라우드 네이티브 기술을 수용하는 데 중점을 두었다면, 앞으로 5년은 대형 언어 모델의 변혁적인 힘을 받아들이는 데 중점을 둘 것입니다.\n\n# Snowflake CEO 변경\n\n2024년 2월 28일, Snowflake는 회계 연도의 제4 분기 재무 결과를 발표했습니다. 실망스러운 전체 연간 지침을 제공한 후, 회사는 미국 데이터 인프라 산업을 충격받게 할 또 다른 소식을 발표했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n미국 소프트웨어 역사상 가장 전설적인 CEO 중 한 명인 프랭크 슬룻만이 Snowflake의 CEO로서 사임을 발표했습니다. 새 CEO는 Neeva의 인도계 창업자 인 스리다르 라마스와미입니다. 스리다르는 지난해 Neeva를 Snowflake에 판매한 후 Snowflake에 합류했고, 모든 새 AI 관련 비즈니스를 감독하는 Snowflake의 AI SVP로 임명되었습니다. 단 년 만에 매각되었던 회사의 창업자에서 상위 회사의 새 CEO로 전환했습니다.\n\nSnowflake CFO 마이클 스카르펠리는 수익 보고서 이후 일주일 뒤 투자자 통화에서 \"저희는 프랭크의 퇴임 소식을 수요일에 (수익 보고서를 발표한 날)\"만 알게 된 사실을 언급했습니다. 그리고 \"그 동안 프랭크가 이사회와 스리다르와 더 많은 시간을 보낸 것으로 보아, 그는 프랭크의 후임자가 될 수 있을 것이라 여겼습니다.\" 스카르펠리는 프랭크와 오래된 친구이며, 둘은 함께 ServiceNow에서 황금 콤비를 이루었으며, 함께 Snowflake로 합류하기 전에 두 사람은 모두 몬태나 주 보즈만에 거주하고 있어, 저희처럼 놀라실지 모르겠습니다.\n\nSnowflake의 천사 투자자이자 창업 CEO 마이크 스페이서도 프랭크의 사임에 대해 다음과 같이 언급했습니다:\n\n- 스페이서와 두 창업자가 Snowflake를 공동 창업할 때, 제품이 제공될 때 CEO로서 사임할 것을 합의했습니다.\n- CEO로서 사임한 후, 스페이서가 다음 CEO로 마이크로소프트의 밥 머글리아를 데려왔고, 제품을 시장에 내놓고 비즈니스 모델을 확립하는 단계에 중점을 둔 \"명확한 업그레이드\"라고 평가했습니다.\n- 이후 이사회는 다음 큰 도전이 공개 상장하고 확장하는 것인 것을 깨닫고, 회사 전체에 높은 강도와 긴급함을 전파할 수 있는 프랭크 슬룻만을 찾아내어 성장을 가속화하고 최종적으로 회사를 공개시켰습니다.\n- 스페이서와 슬룻만 모두 스리다르가 Snowflake의 다음 세대 리더로 가장 적절한 지도자라고 믿습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCEO 교체는 칼을 바꾸는 것과 같아요. LLM이 주도하는 데이터 인프라의 다가오는 시대에는, Frank가 Snowflake를 위한 가장 적합한 CEO가 아닐 수도 있어요. 이것이 Mike Speiser를 설득했는데, 그는 각 CEO 교체에서 좋은 결과를 보았기 때문에 Sridhar가 다음 단계에 더 적합할 수도 있다고 믿게 되었어요.\n\n나중에 Sridhar는 Snowflake뿐만 아니라 세 대형 클라우드 제공업체가 그를 자신들의 AI 리더로 초대했다고 언급했지만, Sridhar는 최종적으로 Snowflake를 선택했어요. Sridhar는 데이터베이스, LLM 및 경영의 복합 기술 세트를 갖춘 희귀한 재능이에요. 데이터베이스 관련 분야의 박사 학위를 보유하고 있으며, Google에서 10,000명 이상의 팀을 이끈 'Google 광고의 왕'으로서 Meta보다 추천 알고리즘에서 뒤처지지 않고 추월하도록 도왔어요. 그는 나중에 AI 검색 회사 Neeva를 설립했어요.\n\n이것이 데이터 인프라 산업이 LLM 시대의 결정적 전투 이전으로 급속히 밀려들고 있다는 것을 생각하게 해줘요. 이번 전투의 도래에 절박함을 느끼는 기업들만이 Frank와 같은 이전 시대의 훌륭한 지도자를 교체할 결정을 내릴 것이에요.\n\n이 변화는 단순히 Snowflake의 선택일 뿐만 아니라 많은 소프트웨어 회사들이 내릴 결정일 수 있어요. AI 배경을 갖춘 CEO는 어디에 AI에 투자해야 하는지 명확히 이해할 수 있고, 어떤 제품과 기술 능력을 보충해야 하는지, 이 사업을 운영하기 위한 적절한 인재를 찾을 수 있는 곳을 알 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n선점자 이점, 시간은 아무도 기다려주지 않아요. 다음 섹션에서 이에 대해 더 깊이 파고들어보겠습니다.\n\n# 데이터 인프라에서 수익을 올리는 방법: 교육 파이프라인에 진입함으로써\n\n작년 Q1에 시작된 AI 붐으로 인해 데이터 인프라 기업이 혜택을 받기 시작한 이야기는 스노우플레이크(Snowflake)와 몽고디비(MongoDB) 같은 주요 기업들에게 명확한 AI 수익 기여로 이어지지 않았습니다.\n\n몽고디비의 2023년 Q4 실적 보고서에서, 기업은 이번에 처음으로 전통적인 데이터 인프라 기업들이 이 분야에서 아직 큰 수익을 내지 못한 이유에 대해 설명했습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터 인프라 기업은 대형 언어 모델 (LLM) 영역에서 모델 학습, 미세 조정 및 추론 세 가지 계층에 참여할 수 있습니다.\n- MongoDB의 기존 기술 스택은 주로 후자 두 계층 (미세 조정 및 추론)과 관련이 있지만, 현재 고객 사용 사례를 기반으로 하면 대다수의 고객이 여전히 첫 번째 계층 (모델 학습)에 있습니다.\n- 고객이 세 번째 계층 (추론)으로 이동할 때까지, 중요한 AI 수익이 MongoDB로 흘러들지 않을 것입니다.\n\n이것은 데이터 인프라 분야의 현재 상업적 현실을 반영합니다. 학습 기술 스택에 관여한 새로운 세대의 데이터 인프라 기업만이 이 분야에서 수익을 얻었습니다. 일반적으로 ETL/특성 엔지니어링, 데이터 레이크, 벡터 데이터베이스, 학습 최적화 프레임워크, 그리고 전통적인 기계 학습에서 자주 사용되는 라이프사이클 관리 및 실험 추적 도구를 포함합니다. Databricks, Pinecone 및 Zilliz, Myscale과 같은 중국 기업을 비롯한 이러한 새로운 세대의 도구들이 이미 AI 학습에서 첫 번째 돈을 벌어들였습니다.\n\n![image](/assets/img/2024-05-20-DataInfraandLargeLanguageModel_0.png)\n\n이전 Relit 블로그 게시물에서 언급된대로, 그들의 대형 언어 모델은 Databricks의 기술 스택과 함께 세 대 주요 클라우드 제공업체의 인프라를 많이 활용하여 모델 학습 프로세스를 완료했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Databricks — 검증된 솔루션으로 지난 10년을 보냈습니다\n\nDatabricks은 가장 주목받는 새로운 세대의 데이터 인프라 플레이어 중 하나입니다.\n\n최근 공개된 비즈니스 데이터에 따르면:\n\n- Databricks는 2023년에 16억 달러의 매출을 달성했으며, 연간 약 55%의 성장을 이룩했습니다.\n- 16억 달러의 매출은 경쟁사인 Snowflake의 60% 미만이지만, Databricks의 매출 모델은 Snowflake와 다릅니다. Databricks는 SQL Serverless 제품뿐만 아니라, 클라우드 제공업체의 컴퓨팅 및 저장 서비스를 번들로 제공하여 소프트웨어 수익과 클라우드 제공업체의 마진을 모두 확보합니다. 또한, Databricks의 다른 제품 대부분은 소프트웨어 가치만을 판매합니다.\n- 더 합리적인 비교는 총 마진입니다. 클라우드 제공업체의 매출을 제외한 경우, Databricks의 총 마진은 Snowflake의 약 65%에 해당하며, 빠른 성장을 고려했을 때, Databricks의 마진은 2023년 제 4 분기에 약 70%로 Snowflake의 마진에 가까워졌습니다 (이는 Databricks의 높은 마진 소프트웨어 비즈니스 비중을 반영합니다).\n- 추세를 살펴보면, Databricks는 2023년에 매출 성장을 가속화했으며, 2024년에도 성장률이 60%까지 가속화될 것으로 예상됩니다. 이를 뒷받침하는 증거로, Databricks는 2023년 제 4 분기에 거의 100%의 연간 예약 성장을 기록했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDatabricks의 현재 성공에 비해, 지난 10년간의 개발은 원활하지 않았습니다. 이는 검증 과정을 거치는 10년의 여정이었습니다.\n\nDatabricks는 오픈 소스 Spark에서 시작하여 후에 대표 제품인 Delta Lake으로 데이터 레이크를 확장했습니다:\n\n- Spark는 Databricks의 초기 제품이자 현재 핵심 제공품으로, 기계 학습과 데이터 엔지니어링을 지원하는 플랫폼으로 처음에 위치했습니다.\n- 딥러닝 붐이 일어나기 전까지 Spark는 거의 모든 기계 학습 작업을 처리할 수 있었지만, 딥러닝의 부상으로 인해 Spark는 더 이상 주류 기계 학습 플랫폼이 되지 않았습니다. TensorFlow 이후 PyTorch가 주류가 되었습니다.\n- 독립적인 기계 학습 플랫폼 이상으로, Spark는 데이터 엔지니어링 분야를 지배하며 가장 주류인 ETL 도구가 되었고, Databricks에게 ETL/기능 엔지니어링을 통한 대용량 언어 모델 시대로 가는 열쇠를 제공했습니다.\n\n다른 대표 제품 Delta Lake도 Databricks를 가장 큰 상업용 데이터 레이크 서비스 제공업체로 만들었습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 머신 러닝 데이터를 처리할 때는 대량의 구조화되지 않은 데이터가 필요하며, 데이터 레이크가 가장 비용 효율적인 저장 방법이 되었습니다.\n- 그러나 스노우플레이크가 거대한 시장 기회와 더 쉽게 이해할 수 있는 데이터 웨어하우스 개념으로 급속히 성장함에 따라, 데이브릭스는 그림자를 드리운 채로 남아 있었습니다.\n- \"보다 맛있는\" 데이터 웨어하우스 사업을 잡기 위해 데이브릭스는 레이크하우스 컨셉을 제안했습니다.\n- 데이브릭스 역시 고객에게 더 많은 자율성을 부여하여 고객이 큰 부피로 인해 구름에서 큰 할인을 받을 수 있는 매우 큰 고객들에게 매우 친숙합니다.\n- 데이브릭스 SQL은 스노우플레이크에 비해 높은 계산량의 복잡한 시나리오에서 데이터 웨어하우스 능력의 고유한 결함으로 인해 성능 대 가격 비율이 다소 떨어집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDatabricks는 개발 과정에서 여러 가지 어려움을 겪었지만 결국 승리를 거뒀습니다. 오랫동안 홍보되어온 Spark와 Lakehouse 제품은 대규모 언어 모델 시대에 대한 주요 무기가 되었습니다.\n\n- 현재 단계에서 기술 스택의 완성도와 플랫폼 기능성(목표를 종단-to-종단으로 구현하는 능력)은 단일 기능의 우수한 성능보다 중요합니다.\n- 대규모 언어 모델 시대에 비정형 데이터 처리의 폭발적인 성장에서 Delta Lake + Databricks Spark는 비정형 데이터 처리의 황금 콤보가 되어 ETL/Feature Engineering 워크로드의 상당 부분을 차지하게 되었습니다.\n- 기계 학습 분야에서의 포괄적인 노하우를 통해 MosaicML을 인수한 후, Databricks는 세 주요 클라우드 및 NVIDIA 이후 또 다른 풀스택 대규모 언어 모델 훈련 플랫폼이 되어, 거의 마지막 퍼즐 조각을 완성하게 되었습니다.\n- 그리고 2024년에 Snowflake이 오픈 포맷을 완전히 받아들이고 고객이 자체 저장로드를 사용할 수 있도록 하는 것으로 Lakehouse 경로를 완전히 수용함에 따라, Lakehouse가 빅데이터 시대의 주류가 되었습니다. 호수나 창고에서 들어오든, 궁극적인 해결책은 Lakehouse가 될 것입니다.\n\n# Snowflake의 따라잡기 계획\n\n언제나 비정형 데이터와 기계 학습에 중점을 둔 Databricks와 달리, Snowflake의 경로는 더 다양했으며, 기계 학습 분야에는 상대적으로 적은 투자를 한 다고 말할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSnowflake의 공동 창업자인 Benoit Dageville은 2023년 이전에 Unistore와 Snowpark에 중점을 둔 Snowflake의 기술 로드맵을 책임지고 있습니다. 먼저 Unistore에 대해 논의해 봅시다:\n\n- Unistore는 HTAP와 유사한 제품으로, 하단에 KV 스토어 디자인이 있습니다. Benoit은 이 제품이 Snowflake이 대규모 데이터베이스 (OLTP) 영역으로의 시장 기회 확대에 도움이 될 것으로 기대했습니다. 그러나 KV 스토어 디자인 때문에 Oracle과 같은 주류 OLTP와 직접적으로 경쟁할 수는 없으며, 주로 OLAP가 주력이고 OLTP가 보조인 기업들이 채택할 수 있는 솔루션이 적합합니다.\n- Unistore를 구현하는 기술적 어려움도 상당히 높으며, 데이터 웨어하우스에 약하지만 Snowflake의 고품질 데이터 처리와 안정성에 대한 요구 또한 엄청나게 높습니다. 한편, HTAP도 새로운 기술 솔루션이며, HTAP 선구자들은 이 분야에서 벽을 만나고 있어 HTAP 비즈니스 모델이 증명되었는지 여부를 확신할 수 없게 만듭니다.\n\nUnistore와 비교하여 Snowpark의 논리는 더 직관적입니다:\n\n- Snowpark는 더 간소화된 제품 논리를 갖고 있습니다. 고객이 데이터를 Snowflake에 적재할 때 ETL 처리를 수행해야 하며, 과거의 주류 처리 방법은 Open-Source Spark와 Databricks Spark였습니다. 이제 Snowflake의 네이티브 ETL 도구인 Snowpark를 사용하면 고객은 전송 비용을 절감할 수 있으며 기능적인 차이가 없어 고객이 Snowpark로 전환하여 비용 효율성을 높이는 것이 자연스러운 선택이어야 합니다.\n- Open-Source Spark(주로 AWS 고객들 사이에서 EMR 제품으로 판매되는 제품)과 비교하여, Snowpark의 비용 효율성 이점은 매우 명확합니다. 그러나 최적화된 상업용 제품인 Databricks Spark와 비교하면, Snowpark는 이미 Snowflake 제품을 사용 중인 고객들을 위해 데이터 처리에 더 초점을 맞추고 있습니다.\n- Snowpark는 데이터 엔지니어링 작업을 신속하게 따라잡을 수 있고 기술적 장벽도 높지 않습니다. 그러나 머신러닝 영역에서는 아직 많은 작업이 남아 있으며, 특히 Spark의 오픈소스 이점에 직면하여 Snowpark는 특정 전통적인 산업을 위한 머신러닝 기능을 제공하는데 초점을 맞추고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스노우파크가 2022년 말에 상용화된 이후, 수익 규모는 Databricks의 ETL 수익의 약 5~10%로 빠르게 성장하고 있어요. Databricks의 경쟁 제품인 Databricks SQL과 비교하면, 그 규모는 Databricks SQL의 약 1/3 수준으로, 출시 시기도 Databricks SQL보다 1년 뒤입니다.\n\n스노우파크는 Snowflake가 대형 언어 모델 시대에 진입하기 위한 열쇠를 제공했고, Snowflake의 미래 대형 모델 지원 제품은 모두 스노우파크를 중심으로 구축될 것입니다:\n\n- 스노우파크는 비정형 데이터를 처리할 수 있는 능력을 Snowflake에 제공하여 대형 언어 모델 시대에서 ETL 및 피처 엔지니어링 요구를 충족할 수 있게 했습니다.\n- 스노우파크를 더 발전시킴으로써, Snowflake는 Iceberg 오픈 포맷을 지원하기 시작했고, 이는 Snowflake가 더 많은 비정형 데이터를 유치하고 완전한 Lakehouse 솔루션을 구축하는 기초가 되었습니다.\n- 동시에 Snowflake는 Snowpark 컨테이너 서비스를 출시했고, 이는 Snowflake의 주요 업무로 자리 잡았습니다. GPU Workloads를 Snowflake로 가져오며 컨테이너 서비스에서 모델을 Fine-tune하고 배포할 수 있게 했습니다.\n\nSridhar가 Snowflake에 합류한 후, 그는 새 제품 Cortex에 집중하기도 했다요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Cortex는 대화 및 관련 분석을 위한 제품을 주로 하는 새 투자인 Mistral AI를 포함한 Snowflake를 위해 외부 대규모 언어 모델 파트너를 가져왔어요.\n- Cortex에는 Document AI와 Databricks의 LakehouseIQ와 유사한 Snowflake Copilot도 포함되어 있어요. Text2SQL 및 지식베이스에 대한 솔루션을 제공합니다.\n- Sridhar는 이전 회사 Neeva에서 사용한 RAG-Vector Search 솔루션을 Cortex로 통합하고, Snowflake에 벡터 스토리지 및 처리 능력을 곧 추가할 예정이에요. 미래에는 더 많은 컨테이너 서비스 고객을 지원하여 컨테이너 서비스에서 직접 모델을 배포하고 추론할 수 있도록 해줄 거예요.\n\nSridhar는 Snowflake가 부족한 점을 잘 알고 있고 투자해야 할 노력을 알고 있어요. 이는 Snowflake가 DeepSpeed의 창업자와 그 핵심 팀을 빼앗는 것에서도 확인할 수 있어요:\n\n- Snowflake의 CFO는 후속 커뮤니케이션에서 DeepSpeed로부터 빼앗은 5명의 연간 비용이 2000만 달러였다고 언급했어요. \"놀랍게도 높고, 너무 비싸고 뛰어납니다.\"\n- 그러나 Sridhar는 Snowflake가 최고의 타겟인 MosaicML과 같이 훌륭한 대상을 찾을 수 있어야 한다는 것을 잘 알고 있어요. 그들을 인수할 수 없는 경우 직접 인사할 필요가 있어요. DeepSpeed 팀은 지금 가장 인기 있는 대규모 언어 모델 훈련/추론 프레임워크로 거의 최상의 선택이에요.\n- Frank 시대에는 상상조차 할 수 없었지만, 새 CEO의 탑-다운 추진 아래에서만 실현할 수 있었던 높은 비용과 \"올드 가드\"의 회사 의도를 이해하는 데 어려움이 있었어요.\n\nCEO 교체 후, Snowflake는 \"All in AI\" 전략을 취하고 모든 제품이 AI를 중심으로 한 것으로 나타났어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n회사의 주요 사업이 데이터 웨어하우징인 회사에서 AI를 하는 것은 두 번째 스타트업을 하는 것과 같습니다. 하지만 Snowflake는 아직 멀은 길이 남아 있어요.\n\n# MongoDB의 RAG 이야기\n\nDatabricks와 Snowflake와 달리 MongoDB는 분석 쪽이 아니며, 제품은 OLTP에서 비즈니스 데이터의 흐름과 저장을 지원하는 데 더 중점을 두고 있어요.\n\n2023년 초에는 MongoDB가 데이터 인프라 공간에서 최고의 타깃이었는데, 당시 시장 논리는 다음과 같았습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 몽고DB는 문서 데이터베이스를 기반으로 개발되어서 데이터 구조에 대한 과도한 고려 없이 데이터를 먼저 수용하고, 그런 다음 매우 높은 사용 편의성으로 데이터를 처리할 수 있습니다.\n- 대규모 언어 모델의 교육과 추론은 많은 비구조화 데이터를 사용하며, 몽고DB의 주요 제품은 반구조화 및 비구조화 데이터를 저장, 읽기, 쓰기 및 쿼리하기 위한 것입니다.\n- 교육 측면에서 몽고DB는 비구조화 데이터의 저장 매체로 사용될 수 있으며, 이는 고객의 기술 스택에서 몽고DB의 중요성을 더욱 높일 수 있습니다.\n- 몽고DB에는 자체 벡터 데이터베이스를 구축하고 모델 추론 측면에 진입할 기회가 있습니다.\n- 더 많은 LLM 응용 프로그램은 더 많은 앱을 의미하며, 이는 LLM 워크플로우에서 반드시 MDB를 사용하지는 않지만, 여전히 챗봇 채팅 기록과 전통 OLTP 워크로드를 저장하기 위해 몽고DB가 필요합니다.\n\n몽고DB는 2023년 제1분기에 Hugging Face와 Tekion과 같은 잘 알려진 기업을 포함한 200개의 새로운 AI 고객을 확보하면서 협력했습니다. 그러나 이후 분기에는 몽고DB가 AI 고객 정보를 더 이상 공개하지 않았습니다.\n\n몽고DB의 주요 관심사는 주로 추론 측면에 집중되어 있으며, 이로 인해 최근 분기에 대형 모델 시나리오가 교육 단계에 여전히 머물러 추론 단계에 진입하지 않았다는 것을 언급해도 매출 기여도가 미미한 것입니다.\n\n추론 측면에서 몽고DB의 기회를 조사하는 것:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이전 두 회사와 비교했을 때, 추론 측면에서 데이터 애플리케이션 및 API 레이어에 더 중점을 둔 MongoDB는 엔드 유저에게 서비스를 제공할 수 있으며, 이는 OLTP 포지셔닝과 밀접하게 관련되어 있습니다.\n- MongoDB의 Atlas Vector Search 서비스는 2024년 초에 가장 먼저 GA 및 상용화된 벡터 검색 기능을 제공했습니다.\n- 기존 고객들을 대상으로 전통 기술 스택이 더 신뢰성 있을 수 있으며, 특히 RAG 요구 사항이 아직 초기 단계에 있고 대규모로 확장되지 않은 경우, MongoDB의 벡터 검색 서비스가 이미 요구 사항을 충족시킬 수 있습니다.\n\n하지만 다른 RAG 솔루션과 비교하면, MongoDB는 여전히 추론 개발 초기 단계에 있습니다:\n\n- 대량 데이터 양과 높은 동시성을 갖는 시나리오에서, MongoDB는 아직 인공지능 기반 벡터 데이터베이스보다 뒤쳐지고 있습니다(주로 MongoDB의 벡터 데이터베이스 엔진 알고리즘의 축적이 이러한 전문화된 벡터 데이터베이스와 비교해 약하며, 추론 시나리오가 확대될수록 엔진 기능에 대한 요구사항도 상당히 증가할 것).\n- 새로운 세대의 RAG 방법은 밀집 임베딩과 벡터 데이터베이스를 결합하기 때문에 전통적인 BM25에 대해 매우 높은 수준의 요구사항이 있으며, 이 부분에서 MongoDB의 솔루션이 Elastic보다 못할 수도 있습니다.\n- MongoDB에는 아직 많은 기능적 격차가 남아 있습니다.\n\n# 세계에는 엔드투엔드 기술 스택이 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 표에는 세 회사의 LLM 진척 상황이 나와 있습니다. 첫 번째는 교육 분야입니다:\n\n- Databricks는 완전한 프로세스 교육 기술 스택을 갖추고, MosaicML을 통해 마지막 퍼즐 조각을 채웠습니다. 그러나 여전히 대규모 모델 훈련에서 공용 클라우드에 한 발짝 뒤처지고 있습니다.\n- Snowflake는 현재 노트북, 데이터 레이크, 모델 훈련 최적화 및 MLFlow 레이어에서 상당한 차이가 있어 보완 작업 중이며, 현재는 고객이 컨테이너 서비스에서 세밀 조정을 수행할 수 있도록 하는 데 보다 집중하고 있습니다.\n- MongoDB는 추론 쪽에 초점을 맞추어 기본적으로 교육에 개입하지 않습니다.\n- Databricks의 RAG 솔루션이 아직 공개 베타 상태이며, 원 스탑 추론 능력이 아직 갖춰지지 않았지만 올해 중에 완료될 것으로 예상됩니다.\n- Snowflake의 Snowpark ML 및 RAG 솔루션이 또한 공개 베타 상태이며, 컨테이너 서비스 데이터 응용프로그램에서 추론 배포에 대한 미래 지원이 더 있으며, 이는 챗봇 및 기업 지식베이스와 같은 시나리오일 수 있습니다.\n- MongoDB는 세밀 조정 및 컨테이너에는 관여하지 않지만, 최종 사용자를 위한 RAG 솔루션이 더 중시되며, 보다 폭넓은 고객 기반을 대상으로 합니다.\n\n기술 선도 기업들은 이미 세 가지 큰 클라우드 및 다양한 AI-네이티브 플랫폼의 LLM 기술 스택을 채택하고 있으며, 세 회사에 대한 미래의 주요 증가 기회는 전통적인 기업 시나리오입니다:\n\n- 전통 기업의 경우, 종단 간 기술 스택이 매우 중요합니다. LLM 인재 부족 시대의 고객은 최고의 LLM 팀을 구축할 수 없으므로 교육/추론 프로세스가 간단할수록 좋습니다.\n- 전통 기업은 또한 LLM 예산을 늘리고 있습니다. 이는 고객 서비스와 같은 시나리오에 대해 오픈 소스 모델을 교육하거나 다른 써드파티 소프트웨어 응용 프로그램 솔루션을 구매하는 것을 통해 이루어질 수 있습니다.\n- 그러나 역사적으로 초기 응용 솔루션 제공 업체는 자체 내장 데이터 인프라를 제공할 수 있지만, 생태계가 통합되면 고객은 모든 써드파티 솔루션을 지원하기 위해 자체 데이터 인프라를 사용할 가능성이 더 높습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 전투는 새로운 장을 여는 새로운 시작이기도 합니다\n\n지난 몇 년간 데이터 인프라 주변의 경쟁은 언제나 다음을 초점으로 했습니다: 클라우드 아키텍처 또는 온프레미스 아키텍처, 레이크 또는 데이터 웨어하우스, NoSQL TP 또는 SQL TP.\n\n이제 LLM에 의해 주도되는 새로운 데이터 인프라 수요로 인해, 이제는 다음과 같은 질문이 되었습니다:\n\n- 그들은 가능한 한 빨리 새로운 제품을 만들어 추가적인 시장을 확보할 수 있을까요?\n- 새로운 제품을 만들 수 없고 LLM 팀을 영입하지 못한다면, 영원히 뒤처지고 예전 제품에서도 점유율을 잃을 것인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서 우리는 Snowflake과 같은 기업이 AI에 올인하기 위해 CEO를 대체하는 움직임을 보게 됩니다.\n\nDatabricks와 Snowflake 이외의 다른 회사가 MosaicML을 인수하거나 DeepSpeed 팀을 영입할 수 있을지 상상하기 어렵습니다. 새로운 LLM 인재들은 주요 데이터베이스 기업에만 끌릴 수 있으며, 이는 오픈 소스, 온프레미스, 그리고 남은 데이터베이스와의 격차를 더 확대할 수 있습니다.\n\n이것은 싸움이지만, 더 큰 점증적 기회일 것으로 보입니다.\n\n6월의 연간 제품 이벤트에서 이러한 기업들이 새로운 제품을 대거 선보일 것입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터브릭스는 Vector 검색 및 컨테이너 서비스 솔루션을 GA할 수 있습니다.\n- Snowflake는 Cortex 기능, 컨테이너 서비스, SnowparkML, 노트북, Iceberg, Streamlit 솔루션을 GA할 수 있으며, 진행 속도가 빠르다면 Vector 검색도 GA할 수 있습니다.\n- MongoDB를 포함한 각 회사는 RAG 기능을 지속적으로 개선하며 시간과의 경쟁을 벌이고 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-DataInfraandLargeLanguageModel_0.png"},"coverImage":"/assets/img/2024-05-20-DataInfraandLargeLanguageModel_0.png","tag":["Tech"],"readingTime":18},{"title":"Netflix의 미디어 랜드스케이프 진화 321에서 클라우드 스토리지 최적화로","description":"","date":"2024-05-20 16:50","slug":"2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization","content":"\nby Esha Palta Vinay Kawade Ankur Khetrapal Meenakshi Jindal Peijie Hu Dongdong Wu Avinash Dathathri\n\n# 소개\n\nNetflix는 매년 다양한 콘텐츠를 제작합니다. 각 콘텐츠 제작 단계에서 넷플릭스는 다양한 콘텐츠 자산(이미지 시퀀스, 비디오, 텍스트 등)을 다양한 제작에서 확보합니다. 이러한 자산은 나중에 안전하게 Amazon S3 스토리지 서비스에 저장됩니다. 이 데이터의 상당 부분은 제작 중에 일시적으로 액세스되며 해당 콘텐츠 출시 시까지만 사용됩니다. 대부분의 자산은 해당 콘텐츠가 출시될 때까지 활성 또는 '핫' 스토리지 계층에만 유지되는 것이 목적입니다. 이 블로그에서는 사용자 액세스 패턴을 활용하여 스토리지의 효율성과 비용 효과를 스마트하게 최적화하는 방법을 탐색할 것입니다. 본 탐사에서는 다양한 AWS 스토리지 계층에 맞게 맞춤형 아카이브 및 삭제 전략의 비용 효율성을 명확히 검토하는 수명 주기 정책의 비용 분석에 대해 다루어볼 것입니다.\n\n# Netflix의 콘텐츠 제작 및 스토리지 관행 개요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n콘텐츠 제작의 다이내믹한 환경에서 전통 스튜디오들은 시험된 3/2/1 규칙에 오랜 기간 동참해왔습니다. 이 전략은 최소 두 가지 다른 유형의 미디어에 저장된 원본 카메라 영상과 오디오의 세 개 복사본 유지 및 한 개의 백업을 오프사이트에 보관하는 방식을 포함하고 있습니다.\n\n제작 라이프사이클의 활동적인 부서로 들어가 미디어 저장 및 백업 규모를 이해해보겠습니다. LTO 테이프 백업은 제작 및 후반 제작 라이프사이클 동안 지속적으로 존재합니다.\n\n![Production workflow](/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 번 미디어가 카메라와 사운드 녹음기에서 추출되면, 디스크 파일로 변환되어 편집, 사운드 및 음악, 시각 효과 (VFX) 및 이미지 완성을 포함한 각 부서별 도구를 사용하여 조작됩니다. 이 미디어는 이 프로세스의 각 단계와 단계마다 포괄적인 백업 루틴을 거칩니다. 물리적 백업 및 아카이브를 기반으로 한 이 방법은 우연한 삭제, 공급 업체별 오류 및 자연 재해의 잠재적 위험을 줄이기 위해 설계되었습니다. 데이터 손실이 기획 및 촬영 단계에서 상당한 비용 손실로 이어질 수 있음을 명확히 인식하여 이러한 백업 프로세스의 중요성을 보여주고 있습니다.\n\n현대 클라우드 스토리지 시스템의 등장은 스토리지 관행에서 패러다임 전환이라는 것을 알려줍니다. AWS S3와 같은 플랫폼은 11 9 이상의 내구성, 복원력 및 가용성을 자랑하는 높은 내구성을 제공합니다. 이 발전은 Netflix와 같은 미디어 회사가 데이터 아카이빙 및 삭제 정책과 같은 도구를 활용하여 그들의 스토리지 방법론을 재정의할 수 있도록 했습니다. 현장에서 촬영된 카메라와 사운드 시스템에서 캡처된 미디어는 인접한 데이터 센터 시설로부터 직접 Netflix의 클라우드 스토리지로 업로드되며, 백업이 필요하지 않습니다. 이 업로드 이후, 데일리, 편집, 시각 효과 및 이미지 완성과 같은 다양한 단계가 다운로드되어 수정되고, 최종 데이터 버전이 클라우드 스토리지로 전송될 수 있습니다. 이 구조는 콘텐츠 제작에 부합된 추적, 접근, 제어 및 확장성을 용이하게 합니다.\n\n또한, 데이터 수명 주기 정책과 통합함으로써 저장 비용 절감과 데이터 관리를 위한 에너지 수요 감소, 이에 따라 탄소 발자국을 줄일 수 있습니다. 이러한 관행을 실행함으로써 기업은 에너지 소비를 줄이고, 결과적으로 환경 영향을 줄이면서 운영 효율성과 비용 효율성을 높일 수 있습니다.\n\n이러한 전략을 도입하는 조직은 지속가능성에 기여하며, 데이터 성장을 더 효과적으로 관리할 수 있는 민첩성과 준비성을 높일 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 사용자 액세스 패턴 활용\n\n넷플릭스의 미디어 콘텐츠 Orchestration의 핵심에는 중앙 집중식 자산 관리 플랫폼 (AMP)이 있습니다. 이 강력한 시스템은 제작 및 후기 단계에서 제작된 모든 미디어 자산을 지속하고 발견하는 데 전념되어 있습니다. 이 중앙 집중식 허브는 광범위한 미디어 콘텐츠 라이브러리의 관리와 접근성을 간소화하는 데 도움이 됩니다. 또한 우리는 소중한 통찰력을 추출하고 미디어 자산의 사용 및 액세스 패턴에 대한 상세한 보고서를 생성할 수 있습니다. 이 대국적인 시각은 콘텐츠가 어떻게 활용되는지에 대한 우리의 이해를 높이며, 정보에 기반한 의사 결정을 위한 기초를 마련합니다.\n\n우리의 가설을 검증하기 위해, 발매 후 다양한 간격에서 사용자 및 애플리케이션에 의한 자산 액세스 속도를 조사했습니다. 조사 결과는 의미 있는 것들을 드러내었으며, 연관된 제목이 발매된 후 자산 사용량이 상당히 감소한다는 것을 밝혔습니다. 액세스 패턴의 인사이트:\n\n![](/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFif 2: 타이틀 발매 전후 자산 접근 패턴\n\n이 트렌드는 여러 자산 유형에 걸쳐 상당히 일관성있게 발견되었습니다. 런칭 이후 자산에 대한 접근이 드물기 때문에 저장 비용을 최적화할 수 있는 매력적인 기회가 발생합니다. 예를 들어, 자산은 초기 런칭 후 6개월 후에 아카이브로 이동될 수 있습니다. 이 정책은 시간이 지남에 따라 더 많은 데이터를 축적함으로써 더 지능적으로 발전하고 정확도를 키울 수 있도록 설계되었습니다.\n\n런칭 이후 자산에 대한 액세스가 매우 드문 점을 감안하면, 아카이브 준비가 된 자산을 AWS Glacier 스토리지로 이전할 수 있는 중요한 기회가 있습니다. AWS Glacier는 월간 저장 비용의 60% 낮은 비용으로 3-5시간 검색 시간을 제공합니다.\n\n# 기회 규모\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저희의 가설은 보관 자산을 더 저렴한 저장 공간에 보관한다면 비용 절감 가능성이 매우 크다는 것입니다. 저희의 재무 및 데이터 파트너들은 현재 데이터 규모, 성장률, 그리고 미래 비즈니스 사용 사례를 기반으로 서로 다른 모델과 추정치를 개발하는 데 도움을 주었습니다.\n\n![Fig 3: 미디어 스토리지 비용 분석](/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_2.png)\n\n상태 쿼: 계속해서 진행한다면, 예상 비용 부담이 급격히 증가할 것으로 예상됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n단기적으로는 사용되지 않는 자산을 보관하여 비용 효율적인 S3 Glacier 유연한 검색 스토리지로 이전하는 것이 50% 이상의 절감을 가져올 것입니다.\n\n장기적으로는 자산과 타이틀 라이프사이클의 다양한 단계(제작, 후기, 출시 이후 단계 등)에서 다양한 유형의 자산에 더 세부적인 라이프사이클 정책을 적용한다면 더 많은 절감을 이룰 수 있습니다.\n\n# 데이터 라이프사이클 전략\n\n데이터의 저장 계층을 결정하는 방법은 무엇일까요? 데이터 라이프사이클 관리의 첫 단계로 사용 패턴에 의존하는 간단한 전략을 선택했습니다. 사용에 근거한 이 접근은 단순하지만 상당한 가치를 제공합니다. 이 전략은 서비스에 프로그램이 출시된 후 특정 기간이 지난 후 자산을 낮은 비용의 아카이브 저장소로 이전하는 것을 포함하고 있습니다. 동시에 출시 후 임시 데이터는 정리되어 저장 리소스를 최적화하고 비용을 최소화합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 저장소 라이프사이클 관리 옵션 평가\n\n저희 콘텐츠 중심 도메인에서는 Amazon S3가 광범위한 미디어 콘텐츠를 호스팅하는 기반 역할을 합니다. 하지만 우리는 기본적인 것을 넘어서 S3 상에 견고하고 높은 확장성을 갖춘 저장소 인프라 계층을 구축했습니다. 이 복잡한 프레임워크는 우리의 거대한 미디어 파일을 안전하고 효율적으로 저장, 정리, 추적하며 글로벌 분산 스튜디오의 요구를 충족시키기 위해 설계되었습니다.\n\n자산 아카이빙 프로세스는 미래 참조를 위해 필요하지만 정기적으로 접근되지 않는 데이터를 기존의 고에너지를 사용하는 주 저장소 환경에서 더 에너지 효율적이고 저비용 아카이브로 전략적으로 이동하는 것을 포함합니다. 이 아카이빙 정책은 에너지 소비를 줄이고 고성능 저장 장치의 수명을 연장하는 데 기여합니다. 반대로, 삭제 정책은 오래된 또는 중복된 데이터를 체계적으로 삭제하고 저장 공간 요구 사항을 최적화하며 데이터 센터의 에너지 소비를 낮출 것을 목표로 합니다.\n\n아카이빙 솔루션을 찾는 동안 우리는 AWS S3의 Intelligent Tiering을 평가했습니다. S3 Intelligent Tiering은 탁월한 기본 제품이지만, 우리가 원하는 데이터에 대한 사용자 정의 세밀한 조정 기능이 부족합니다. 접근 패턴 통계로부터 우리는 포스트 프로덕션 단계의 여러 플레이어가 우리 데이터에 접근하는 방법에 대한 훨씬 더 풍부하고 상세한 데이터 세트를 얻었습니다. 이 지식을 활용하여 S3 Intelligent Tiering이 더 저렴한 저장 등급으로 객체를 이동하는 데 30일 감시를 기다리는 대신 보다 저렴한 저장 등급으로 페타바이트의 데이터를 적극적으로 아카이브할 수 있습니다. 우리는 또한 이 지식을 활용하여 데이터를보다 적극적으로 삭제하고 더 많이 절약할 수 있었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nS3 위에 위치한 저장소 인프라레이어는 두 가지 입력을 기반으로 다른 저장 클래스 간에 데이터를 이동할 수 있습니다.\n\n- 엔드 유저 클라이언트 애플리케이션에서 지정한 정책.\n- 접근 패턴 통계에서 유도한 정책.\n\n# 저장소 라이프사이클 서비스 아키텍처\n\n넷플릭스의 저장소 라이프사이클 관리 아키텍처를 간단히 살펴봅시다. 넷플릭스의 콘텐츠 생성을 고려할 때, 자산은 제작 중에 생성된 미디어 파일 집합을 나타냅니다. 고수준에서 저장소 라이프사이클 아키텍처는 다음 구성 요소로 구성되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Netflix's Media Landscape Evolution](/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_3.png)\n\n**Fig 4: Storage Lifecycle Manager Architecture**\n\n- **자산 관리 플랫폼**: Netflix에서 생산 및 후생산 단계의 미디어 자산 메타데이터를 저장하고 관리합니다. 자산 당 파일 수는 1개부터 1백만 개까지 다양합니다.\n- **정책 관리자**: 자산 및 임시 미디어 파일을 포함한 저장 객체의 라이프사이클 정책을 관리합니다. 이 서비스는 파일 저장을 효율적으로 관리하기 위해 다양한 정책 기반 자동 및 임시 작업을 지원합니다.\n- **콘텐츠 드라이브(Content Drive)**: 기존 파일 시스템 인터페이스를 사용하여 방대한 자산을 추적, 저장, 조직화, 관리하고 액세스 및 전송을 효과적으로 제어하기 위한 중앙화된 안전한 고도로 확장 가능한 솔루션을 제공합니다. 콘텐츠 드라이브는 미디어 파일의 상태에 대한 진리의 궁극적인 원천입니다. 임시로부터 우선순위가 높은 미디어 자산까지 다양한 미디어 자산은 시간이 지나거나 다른 버전에서 중요성을 갖습니다. 콘텐츠 드라이브는 데이터를 통해 우리의 이해를 높여주며, 자산 접근 패턴, 생산 관련 파일 수, 파일 크기 및 사용자 상호작용에 대한 통찰력을 제공합니다. 이 정보의 풍부함으로 생산 자산에 라이프사이클 정책을 정의하고 첨부하여 저장 풋프린트와 비용을 최적화할 수 있습니다.\n- **저장 라이프사이클 관리자**: 저장 라이프사이클 작업을 처리하고 조정하는데 사용되는 워크플로를 처리합니다. 주요 워크플로는 다음과 같습니다:\n  - Content Drive에 의해 관리되는 파일의 아카이빙을 AWS 아카이브 저장 계층으로 이동\n  - 아카이브된 파일의 복원. 파일은 다시 아카이빙되기 전에 특정 기간 동안 S3 표준 계층에서 사용 가능합니다.\n  - Content Drive에 의해 관리되는 파일의 삭제. 이것은 완전 삭제입니다.\n- **S3 객체 관리자**: 미디어 작업을 최적화하기 위해 S3 상에 구축된 추상화 계층입니다.\n\n이 게시물에서는 몇 가지 구성 요소를 높은 수준으로 다루고 다음 블로그 시리즈에서 자세한 아키텍처와 흐름을 다뤄 보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 디자인 원칙\n\n- 확장성\n\n- 수십억 개의 파일을 처리할 수 있도록 설계되었으며, 모든 저장 객체가 아카이브하거나 삭제 대상이 될 수 있습니다.\n- 쇼 종료 후 대규모 아카이빙과 같은 시나리오를 다룰 수 있는 쓰러러닝 허드 요청을 관리할 수 있습니다.\n\n2. 내구성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 저장 메타데이터의 데이터 무결성을 보장하고 안티 엔트로피 메커니즘을 활용합니다.\n- 적어도 한 번의 활동 보고를 보장하여 신뢰성을 강화합니다.\n\n3. 내구성\n\n- 재시도 메커니즘을 포함한 아카이브/복원/제거 작업에 대한 보장을 제공합니다.\n- 하루에 수천만 개의 파일 삭제 요구를 처리할 수 있는 기능으로 발전합니다.\n\n4. 보안\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 지정된 응용 프로그램만 라이프사이클 작업을 트리거할 수 있도록 인가하여 안전한 환경을 유지합니다.\n\n자산 라이프사이클 작업은 다음과 같습니다:\n\n- 클라우드 응용 프로그램은 자산을 저장 백엔드에 업로드합니다.\n- 제품 관리자와 응용 프로그램 소유자는 데이터 라이프사이클 정책을 정의하기 위해 Policy Manager API를 사용합니다. 해당 정책은 자산 유형에 적용되며, 예를 들어 제목 발매일로부터 180일 후에 일시적 자산을 삭제하거나 제작 후 30일 후에 최종 자산을 아카이브하는 등의 정책을 정의합니다.\n- 정책 관리자는 자산에 대한 정책을 만들고 관리할 수 있습니다. 정책 엔진은 정책 정의를 평가하고 어떤 자산이 라이프사이클 작업의 대상이 되는지 판단합니다. 이후 정책 실행 워커에 대한 작업을 대기열에 추가합니다. 정책 실행 워커는 Content Drive를 대상으로 아카이브/복원/삭제와 같은 작업을 예약(생성)합니다.\n- 정책 실행 시, Content Drive는 저장소 라이프사이클 관리자와의 라이프사이클 작업 실행을 예약합니다.\n- 모든 라이프사이클 작업은 저장소 라이프사이클 관리자에 지속됩니다.\n- 저장소 라이프사이클의 각 인스턴스에 대해 관리자는 실행할 자산을 평가하고 Content Drive에 실행 라이프사이클 이벤트를 전송합니다. Content Drive는 미디어 파일에 대한 충돌 작업 요청을 처리하기 위해 메타데이터 상태를 업데이트하며, 각 작업의 대상이 되는 자산 목록을 수집하고 이를 저장소 라이프사이클 관리자로 전송합니다.\n- 필요한 처리량을 달성하기 위해 비동기 작업은 클러스터의 모든 노드에 균등하게 분산되며, 특정 작업을 처리하는 노드가 하나뿐입니다. 작업을 공유함으로써 병렬성을 달성하고, 이 솔루션은 데이터베이스 트랜잭션 충돌을 피하기도 합니다. Kafka를 사용하여 비동기 작업을 \"소유\"하는 노드로 이동합니다. Kafka의 리더 선출은 클러스터 전체에 균등하게 소유권을 설정하는 데 사용됩니다. Kafka는 최소 한 번의 메시징과 내구성 보장을 제공합니다.\n- 저장소 라이프사이클 관리자는 S3 Object Manager를 사용하여 동시에 객체를 다른 저장 티어로 이동/삭제하고 비동기 완료/실패 이벤트를 기다립니다.\n- 저장소 라이프사이클 관리자는 작업 완료를 모니터링하고 작업 완료 이벤트를 생성합니다. 실패한 이벤트는 작업 상태를 실패로 반영하기 전에 여러 번 다시 시도됩니다.\n- S3 Object Manager는 작업 완료 이벤트를 처리하고 미디어 파일/폴더에 대한 메타데이터 상태 업데이트로 변환한 후 미디어 자산에 대한 라이프사이클 변경 완료 이벤트를 생성합니다. 스튜디오 응용 프로그램은 저장소 관리자에서 생성된 완료 이벤트에 가입하고 업무 업데이트를 최종 사용자에게 보냅니다.\n\n# 저장소 아카이빙 통계\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저장 수명주기 관리를 위해 Policy manager와 함께 생산 환경에서 자동화 작업을 시작했습니다. 이렇게 생긴 저장 수명주기 대시보드의 중요한 예시 몇 가지가 있습니다:\n\n![그림 5: 하루에 아카이브된 파일 수(백만 단위)](/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_4.png)\n\n![그림 6](/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFig 6: Files Archived in a backfill job\n\n# Netflix의 저장소 수명주기 진화\n\n기존의 사용 패턴 및 콘텐츠 저장 및 보존 복잡성을 고려하여, Netflix는 많은 미디어 자산을 효율적이고 비용 효율적이며 지속 가능하게 관리하는 방법을 개척하려고 합니다. 곧 우리는 정책 관리자를 개선하여 모든 미디어 저장소 자산 및 임시 파일에 대한 데이터 수명주기 정책을 자동화할 계획입니다. 이 전략적인 움직임은 운영 효율성을 향상시키고 콘텐츠 관리 분야의 기술 발전을 선도하기 위한 저희의 약속과 일치합니다. 장기적으로는 데이터 수명주기 관리 솔루션을 자동화하고 확장하며, 우리의 목표는 충돌과 우선순위 뿐만 아니라 Netflix의 하이브리드 저장소의 데이터 수명주기 관리도 처리할 수 있는 정책 관리자를 개선하는 것입니다.\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시스템화된 데이터 라이프사이클 관리는 높은 효율성, 비용 효율성 및 확장 가능한 저장 솔루션을 제공하기 위해 반드시 고려되어야 합니다. 이는 클라우드 또는 하이브리드 저장소를 위한 새로운 워크플로우의 설계나 아키텍처에 포함되어야 합니다.\n\nNetflix에서 전형적인 실사 제작은 후속 제작 단계에서 단독으로 20,000개에서 80,000개의 에셋을 도출할 수 있으며, 이는 수백 테라바이트에 달하는 데이터량으로 이어집니다. 에셋 라이프사이클 정책에 따라 저렴한 저장 계층으로 아카이빙하여 약 70%의 비용 절감을 달성할 수 있습니다.\n\n초기 단계에서의 성공을 고려할 때, 우리는 시스템의 능력을 향상시키고 있으며, 저장 계층과 정책 관리 계층을 모두 포함하여 두 가지 측면에서 에셋 라이프사이클 정책을 확대하고 있습니다:\n\n- 제목 수명주기의 다른 단계에서 생성된 다양한 유형의 에셋에 대한 범위를 확장합니다.\n- 완전한 라이프사이클을 정의하고 아카이빙되었을 수도, 아닐 수도 있는 에셋을 정리합니다.\n- 정책 관리자를 확장하여 온프레미스, NFS, FSX, EBS 등 하이브리드 저장 환경의 데이터 계층화 및 라이프사이클 관리를 지원합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 감사의 말\n\nVinod Viswanathan, Sera Leggett, Obi-Ike Nwoke, Yolanda Cheung, Olof Johansson, Shailesh Birari, Patrick Prothro, Gregory Almond, John Zinni, Chantel Yang, Vikram Singh, Emily Shaw, Abi Kandasamy, Zile Liao, Jessica Gutierrez, Shunfei Chen 같은 멋진 동료들에게 특별히 감사드립니다.\n\n# 용어\n\nLTO: Linear Tape-Open의 약자로, 백업, 아카이빙 및 데이터 전송에 주로 사용되는 기술입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nVFX: 비주얼 이펙트의 약자로, 라이브 액션 미디어를 위해 비디오나 이미지를 수정하는 것을 포함합니다.\n\nOCF: 오리지널 카메라 푸티지의 약자로, 필름 카메라에 의해 처음으로 촬영된 원본이며 편집되지 않은 콘텐츠를 나타냅니다.\n","ogImage":{"url":"/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_0.png"},"coverImage":"/assets/img/2024-05-20-NetflixsMediaLandscapeEvolutionFrom321toCloudStorageOptimization_0.png","tag":["Tech"],"readingTime":15},{"title":"DevOps 웃고 배우고 반복하기 - Bhavesh","description":"","date":"2024-05-20 16:49","slug":"2024-05-20-DevOpsLaughLearnRepeatByBhavesh","content":"\n안녕하세요, 저는 클라우드 솔루션 아키텍트가 되기를 희망하는 바베시 아난드파라입니다. 대학생들과 마찬가지로, 이 새로운 기술에 압도당하고 완전히 탐험하는 데 어려움을 겪었습니다.\n\n그래서 저는 데브옵스를 탐험하고 제 학습 과정을 Medium 블로그 시리즈를 통해 문서화해보려고 합니다.\n\n이 아이디어는 이러한 개념을 정말로 잘 파악한 다음, 제 고유한 말로 설명하는 것입니다.\n\n매우 중요한 참고사항:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 DevOps를 시작하려는데 압도당하는 느낌이 들거나 항상 시작하고 싶었지만 어려움을 겪었다면, 학생의 시각에서 컨셉에 대한 아이디어를 얻기 위해 따라해 볼 수 있어요.\n\nDevOps에 뛰어들기 전에 시스템 디자인의 기본 개념을 이해하는 것이 중요하다고 생각해요.\n\n저는 대학생을 위해 초보자 친화적인 시스템 디자인 시리즈를 준비했어요. 이를 읽고 시스템 디자인의 기본에 대해 알아보세요.\n\n내용:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금 시스템 디자인 시리즈를 준비하고 있어요. 기대해주세요! 곧 이 시리즈를 시작할 거에요! 😉\n","ogImage":{"url":"/assets/img/2024-05-20-DevOpsLaughLearnRepeatByBhavesh_0.png"},"coverImage":"/assets/img/2024-05-20-DevOpsLaughLearnRepeatByBhavesh_0.png","tag":["Tech"],"readingTime":2},{"title":"5가지 재미있는 AWS 프로젝트를 배우는 법","description":"","date":"2024-05-20 16:45","slug":"2024-05-20-5FunProjectstolearnAWS","content":"\n![Image](/assets/img/2024-05-20-5FunProjectstolearnAWS_0.png)\n\n# 소개\n\nAmazon Web Services (AWS)를 배우는 여정에 돌입하면 흥미롭고 보람찬 시간을 보낼 수 있습니다. AWS를 배우면 클라우드 컴퓨팅 기술을 향상시키고 다양한 가능성을 경험할 수 있습니다. 학습 경험을 더욱 흥미롭게 만들기 위해 AWS의 다양성을 보여주는 5가지 재미있는 프로젝트를 소개합니다. 이를 통해 실제 문제에 대한 해결책을 배포하는 경험을 쌓을 수 있습니다.\n\n# 프로젝트 #1 — Amazon S3에 정적 웹사이트 시작하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 텍스트를 친절한 톤으로 한국어로 번역해 드리겠습니다.\n\n저렴하고 효율적인 방법으로 웹 사이트를 호스팅하는 방법을 발견하세요. Amazon S3에 정적 사이트를 배포하여 핵심 AWS 서비스를 소개하는 이상적인 기회입니다. S3 버킷을 만들어 단순성과 확장성을 활용하고, CDN으로 Amazon CloudFront를 사용하여 전 세계적으로 접근성을 향상시킵니다. Amazon Route 53으로 도메인을 원활하게 관리하고, 안전한 HTTPS 연결을 위해 AWS Certificate Manager를 통해 SSL/TLS 보안을 구현하여 웹 사이트의 최적 성능과 안전성을 보장하세요.\n\n## S3 버킷 만들기\n\n- AWS 관리 콘솔로 이동합니다.\n- S3로 이동하여 \"버킷 생성\"을 클릭합니다.\n- 고유한 버킷 이름을 입력하고 지역을 선택한 후 \"다음\"을 클릭합니다.\n- \"옵션 구성\" 페이지에서 \"다음\"을 클릭합니다.\n- \"권한 설정\" 페이지에서 필요 시 버킷 정책을 구성할 수 있습니다. 검토를 위해 \"다음\"을 클릭한 후 \"버킷 만들기\"를 클릭합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\naws s3api create-bucket --bucket YOUR_UNIQUE_BUCKET_NAME --region YOUR_REGION\n```\n\n## S3 버킷에 웹사이트 업로드하기\n\n- 새로 생성한 S3 버킷을 엽니다.\n- \"업로드\" 버튼을 클릭하고 웹사이트 파일을 모두 선택합니다.\n- 파일이 공개적으로 접근 가능하도록 설정되었는지 확인합니다. 각 파일을 선택하고 \"작업\"을 클릭한 후 \"공개\"를 선택하여 설정할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\naws s3 sync YOUR_LOCAL_WEBSITE_DIRECTORY s3://YOUR_UNIQUE_BUCKET_NAME --acl public-read\n```\n\n## S3 버킷에서 정적 웹 사이트 호스팅 활성화하기\n\n- S3 버킷으로 이동한 후 “속성” 탭을 클릭합니다.\n- “정적 웹 사이트 호스팅”을 클릭합니다.\n- “이 버킷을 웹 사이트 호스팅에 사용”을 선택합니다.\n- “인덱스 문서”를 원하는 HTML 파일로 설정합니다 (예: index.html) 그리고 옵션으로 \"오류 문서\"를 설정할 수 있습니다.\n- 변경 사항을 저장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\naws s3 웹사이트 s3://당신의_고유한_버킷_이름 --index-document index.html\n```\n\n## Amazon CloudFront 배포 구성\n\n- CloudFront 콘솔로 이동합니다.\n- \"배포 생성\"을 클릭합니다.\n- \"웹\" 배포를 선택합니다.\n- 다음 구성을 설정합니다:\n\n- 원본 도메인 이름: 드롭다운에서 S3 버킷을 선택합니다.\n- 기본 루트 오브젝트: 주 HTML 파일로 설정합니다 (예: index.html).\n- 기타 설정은 기본 설정을 유지하거나 요구에 맞게 조정합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. \"배포 생성\"을 클릭하세요.\n\n또는\n\n```js\nimport boto3\n\ncloudfront_client = boto3.client('cloudfront')\n\ndistribution_config = {\n    'CallerReference': '고유한 호출 참조 번호',\n    'Origins': {\n        'Quantity': 1,\n        'Items': [\n            {\n                'Id': 'S3-origin',\n                'DomainName': '당신의_고유한_버킷_이름.s3.amazonaws.com',\n                'S3OriginConfig': {\n                    'OriginAccessIdentity': ''\n                }\n            }\n        ]\n    },\n    'DefaultCacheBehavior': {\n        'TargetOriginId': 'S3-origin',\n        'ForwardedValues': {\n            'QueryString': False,\n            'Cookies': {'Forward': 'none'},\n            'Headers': {'Quantity': 0}\n        },\n        'TrustedSigners': {'Enabled': False, 'Quantity': 0},\n        'ViewerProtocolPolicy': 'allow-all',\n        'MinTTL': 0\n    },\n    'Comment': '당신의 CloudFront 배포 코멘트',\n    'Enabled': True\n}\n\nresponse = cloudfront_client.create_distribution(DistributionConfig=distribution_config)\ndistribution_id = response['Distribution']['Id']\n\nprint(f\"CloudFront Distribution ID: {distribution_id}\")\n```\n\n## Amazon Route 53을 업데이트하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Route 53 콘솔로 이동하세요.\n- 아직 호스팅된 존이 없다면 도메인을 위한 새로운 호스팅된 존을 만드세요.\n- 호스팅된 존을 위해 제공된 네 개의 네임서버를 확인하세요.\n- 도메인 등록기의 설정에서 Route 53에서 제공한 네임서버로 업데이트하세요.\n\n## AWS Certificate Manager (ACM)를 사용하여 SSL/TLS 인증서 가져오기\n\n- ACM 콘솔로 이동하세요.\n- \"인증서 요청\"을 클릭하세요.\n- 도메인 이름을 입력하고 소유권을 확인하기 위한 지침을 따르세요.\n- 확인이 완료되면 새로운 CloudFront 배포를 만들 옵션을 선택하세요.\n- 이전에 만든 CloudFront 배포를 선택하고 인증서 요청을 완료하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport boto3\n\nacm_client = boto3.client('acm')\n\ncertificate_arn = acm_client.request_certificate(\n    DomainName='yourdomain.com',\n    ValidationMethod='DNS'\n)['CertificateArn']\n\nprint(f\"Certificate ARN: {certificate_arn}\")\n```\n\n## SSL/TLS 사용하도록 CloudFront 배포 업데이트\n\n- CloudFront 콘솔로 이동합니다.\n- 배포를 선택하고 \"수정\"을 클릭합니다.\n- \"일반\" 탭에서 \"뷰어 프로토콜 정책\"을 \"HTTP를 HTTPS로 리디렉션\"으로 변경합니다.\n- 변경 사항을 저장합니다.\n\nOR\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncloudfront_client = boto3.client(\"cloudfront\");\n\ncloudfront_client.update_distribution(\n  (DistributionConfig = {\n    DistributionConfig: {\n      DefaultCacheBehavior: {\n        ViewerProtocolPolicy: \"redirect-to-https\",\n      },\n    },\n    Id: \"YOUR_CLOUDFRONT_DISTRIBUTION_ID\",\n    IfMatch: \"your-distribution-config-if-match\",\n  })\n);\n```\n\n## 변경 사항 전파 대기\n\n변경 사항이 전파되는 데 시간이 걸릴 수 있습니다. 완료되면 CloudFront를 통해 전 세계적으로 HTTPS를 통해 사용자 정의 도메인을 통해 정적 웹 사이트에 액세스할 수 있습니다.\n\n축하합니다! Amazon S3에 정적 웹 사이트를 성공적으로 배포했고, 전 세계적인 콘텐츠 전달을 위해 CloudFront를 구성하고, Route 53을 통해 DNS를 설정하고, ACM을 통해 SSL/TLS를 구성했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 프로젝트 # 2 — 클라우드포메이션을 사용하여 아마존 EC2 웹 서버 시작하기\n\n이 프로젝트에서는 AWS 클라우드포메이션을 사용하여 아마존 EC2에 웹 서버를 배포하는 방법을 살펴보겠습니다. 클라우드포메이션을 사용하면 우리가 인프라를 코드로 정의하여 리소스를 생성하고 관리하는 프로세스를 자동화할 수 있습니다. 마지막에는 간단한 웹 페이지를 제공하는 실행 중인 EC2 인스턴스를 갖게 될 것입니다.\n\n## AWS 계정 설정\n\nAWS 계정이 있는지 확인하세요. 계정이 없는 경우 여기에서 가입할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 클라우드포메이션 템플릿 생성\n\nec2-web-server-template.yml이라는 파일을 만드세요. 이 YAML 파일에 클라우드포메이션 템플릿이 포함될 것입니다.\n\n```yaml\nAWSTemplateFormatVersion: \"2010-09-09\"\nResources:\n  MyEC2Instance:\n    Type: \"AWS::EC2::Instance\"\n    Properties:\n      ImageId: \"ami-xxxxxxxxxxxxxxxxx\" # 원하는 Amazon Machine Image (AMI)을 지정하세요\n      InstanceType: \"t2.micro\"\n      KeyName: \"your-key-pair\" # 키페어를 지정하세요\n      SecurityGroupIds:\n        - sg-xxxxxxxxxxxxxxxxx # 보안 그룹 ID를 지정하세요\n      UserData:\n        Fn::Base64: !Sub |\n          #!/bin/bash\n          echo \"Hello from your EC2 instance!\" \u003e /var/www/html/index.html\n          yum install -y httpd\n          service httpd start\n          chkconfig httpd on\n```\n\nami-xxxxxxxxxxxxxxxxx, your-key-pair, sg-xxxxxxxxxxxxxxxxx를 원하는 값으로 대체하세요. UserData 스크립트는 Apache를 설치하고 웹 서버를 시작합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드포메이션 템플릿은 아마존 EC2 인스턴스를 웹 서버로 프로비저닝합니다. 이는 AMI(아마존 머신 이미지), 인스턴스 유형, 키페어 및 보안 그룹과 같은 인스턴스 속성을 정의합니다. 게다가 UserData 스크립트를 사용하여 Apache를 설치하고 웹 서버를 시작하며 기본 HTML 페이지를 만들어 EC2 기반의 작동하는 웹 서버를 시작하기 위한 완전한 구성을 제공합니다.\n\n## 클라우드포메이션 스택 배포\n\n옵션 1: AWS 관리 콘솔\n\n- AWS 관리 콘솔에 로그인합니다.\n- 클라우드포메이션 서비스를 엽니다.\n- \"스택 생성\"을 클릭합니다.\n- \"템플릿 파일 업로드\"를 선택하고 ec2-web-server-template.yml 파일을 업로드합니다.\n- \"다음\"을 클릭합니다.\n- 스택 이름을 지정합니다(예: EC2WebServerStack).\n- 다음 페이지를 계속 클릭하여 기본 설정을 유지합니다.\n- 설정을 검토하고 \"스택 생성\"을 클릭합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n옵션 2: AWS CLI\n\n- 터미널을 열고 AWS CLI가 설치되어 있는지 확인하세요.\n- 다음 명령을 실행하여 CloudFormation 스택을 생성하세요:\n\n```js\naws cloudformation create-stack --stack-name EC2WebServerStack --template-body file://ec2-web-server-template.yml\n```\n\n## 웹 서버 액세스\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 스택을 만들었으면 AWS 관리 콘솔의 EC2 서비스로 이동하세요.\n- 새로 만든 EC2 인스턴스를 찾으세요.\n- 해당 인스턴스의 퍼블릭 IP 또는 퍼블릭 DNS를 확인하세요.\n- 웹 브라우저를 열고 주소 표시줄에 퍼블릭 IP 또는 DNS를 입력하세요.\n\n“Hello from your EC2 instance!” 메시지가 표시되면 웹 서버가 실행 중임을 나타냅니다.\n\n여기까지입니다! AWS CloudFormation을 사용하여 웹 서버로 Amazon EC2 인스턴스를 성공적으로 생성하였습니다.\n\n# 프로젝트 # 3 — S3 버킷에 대한 CI/CD 파이프라인 추가\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프로젝트 # 1에서 생성한 S3 버킷에 대한 CI/CD 파이프라인을 추가해 봅시다.\n\n## AWS CodeBuild 프로젝트 생성\n\nAWS CodeBuild는 Amazon Web Services (AWS)에서 제공하는 완전 관리형 지속적 통합 및 지속적 배포 (CI/CD) 서비스입니다. CodeBuild는 소프트웨어 개발 프로젝트의 빌드, 테스트, 배포 프로세스를 자동화하여 응용 프로그램의 빌드 및 릴리스 단계를 단순화합니다.\n\nAWS CodeBuild 프로젝트를 생성하려면 AWS Management Console, AWS CLI 또는 AWS SDK를 사용할 수 있습니다. AWS CLI를 사용한 예시는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\naws codebuild create-project --name YourCodeBuildProjectName \\\n  --source \"type=NO_SOURCE\" \\\n  --artifacts \"type=NO_ARTIFACTS\" \\\n  --environment \"type=LINUX_CONTAINER,image=aws/codebuild/standard:5.0,computeType=BUILD_GENERAL1_SMALL\" \\\n  --service-role YourCodeBuildServiceRoleArn \\\n  --region YourRegion\n```\n\n실제 값을 지정하여 YourCodeBuildProjectName, YourCodeBuildServiceRoleArn, YourRegion과 같은 자리 표시자를 대체하세요. 이 예제는 소스나 artifact 설정 없이 Linux 컨테이너 이미지를 사용하여 간단한 CodeBuild 프로젝트를 생성합니다. 프로젝트 요구 사항에 따라 소스, artifact, 환경 및 필요한 경우 다른 매개변수를 지정하여 구성을 조정하세요.\n\n지정한 서비스 역할(YourCodeBuildServiceRoleArn)이 빌드 프로세스에서 필요로 하는 리소스에 액세스할 수 있는 권한이 있는지 확인하세요. 이것은 예시입니다. 원하는 역할 이름으로 YourCodeBuildServiceRoleName을 대체하세요:\n\n```js\naws iam create-role \\\n  --role-name YourCodeBuildServiceRoleName \\\n  --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n          \"Service\": \"codebuild.amazonaws.com\"\n        },\n        \"Action\": \"sts:AssumeRole\"\n      }\n    ]\n  }'\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## AWS CodeStar 프로젝트 설정하기\n\nAWS CodeStar는 AWS에서 애플리케이션의 개발 및 배포를 가속화하는 완전히 관리되는 서비스입니다. 이는 소스 코드 관리, 빌드 및 배포를 포함한 다양한 개발 작업을 관리하고 자동화하는 통합 플랫폼을 제공합니다. CodeStar를 사용하면 팀은 신속하게 지속적 통합/지속적 배포 (CI/CD) 파이프라인을 설정하고 프로젝트에 대해 더 효율적으로 협업할 수 있습니다.\n\nAWS CodeStar 프로젝트의 초기 구성을 설정하여 프로젝트 소스 코드 저장소 및 관련 설정에 대한 필수 정보를 제공해 보겠습니다.\n\nMarkdown 형식에 맞게 아래 AWS CodeStar 프로젝트 설정 표를 활용해 주세요.\n\n```bash\naws codestar create-project \\\n  --name YourCodeStarProject \\\n  --id YourCodeStarProjectID \\\n  --description \"Your CodeStar Project Description\" \\\n  --repository YourRepository \\\n  --repository-url YourRepositoryURL \\\n  --code  {\n    \"BranchName\": \"main\",\n    \"Repository\": {\n      \"CodeCommit\": {\n        \"Name\": \"YourCodeCommitRepositoryName\"\n      }\n    }\n  } \\\n  --region YourRegion\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS CLI 명령어 aws codestar create-project은 AWS CodeStar 프로젝트를 생성하는 데 사용됩니다. 이 예제에서는 해당 명령어가 프로젝트 이름(YourCodeStarProject), 프로젝트 ID(YourCodeStarProjectID), 설명, 소스 코드 저장소 이름(YourRepository), 저장소 URL(YourRepositoryURL) 및 주요 브랜치 이름(main) 및 CodeCommit 저장소 이름(YourCodeCommitRepositoryName)과 같은 코드 관련 세부 정보를 지정합니다. 또한 명령어는 CodeStar 프로젝트가 생성될 AWS 지역(YourRegion)을 지정합니다.\n\n## S3 Bucket을 CodeStar 프로젝트에 연결\n\n```js\naws codestar create-deployment-pipeline \\\n  --pipeline-name YourPipelineName \\\n  --pipeline-settings file://pipeline-settings.json \\\n  --output json \\\n  --region YourRegion\n```\n\nAWS CLI 명령어 aws codestar create-deployment-pipeline은 AWS CodeStar에 배포 파이프라인을 생성합니다. 이는 파이프라인 이름(YourPipelineName), JSON 파일(pipeline-settings.json)에서 파이프라인 설정을 가져와서(output json) 지정하며, 결과 형식을 JSON으로 지정하고 AWS 지역을 YourRegion으로 지정합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```json\n{\n  \"pipeline\": {\n    \"stages\": [\n      {\n        \"name\": \"Source\",\n        \"actions\": [\n          {\n            \"actionTypeId\": {\n              \"category\": \"Source\",\n              \"owner\": \"AWS\",\n              \"provider\": \"YourSourceProvider\",\n              \"version\": \"1\"\n            },\n            \"name\": \"SourceAction\",\n            \"configuration\": {\n              \"Branch\": \"main\",\n              \"OutputArtifactFormat\": \"CODEBUILD_CLONE_REF\"\n            }\n          }\n        ]\n      },\n      {\n        \"name\": \"Beta\",\n        \"actions\": [\n          {\n            \"actionTypeId\": {\n              \"category\": \"Build\",\n              \"owner\": \"AWS\",\n              \"provider\": \"CodeBuild\",\n              \"version\": \"1\"\n            },\n            \"name\": \"BuildAction\",\n            \"configuration\": {\n              \"ProjectName\": \"YourCodeBuildProject\"\n            }\n          }\n        ]\n      },\n      {\n        \"name\": \"Prod\",\n        \"actions\": [\n          {\n            \"actionTypeId\": {\n              \"category\": \"Deploy\",\n              \"owner\": \"AWS\",\n              \"provider\": \"S3\",\n              \"version\": \"1\"\n            },\n            \"name\": \"DeployAction\",\n            \"configuration\": {\n              \"BucketName\": \"YourS3BucketName\",\n              \"Extract\": \"true\"\n            }\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n실제 값으로 YourSourceProvider, YourCodeBuildProject, 그리고 YourS3BucketName과 같은 자리 표시자를 대체하세요. 이 구성은 소스, 빌드, 그리고 배포 작업을 포함하는 간단한 세 단계 파이프라인을 나타냅니다. 사용 사례와 요구 사항에 따라 조정하십시오.\n\nYourSourceProvider는 일반적으로 사용 중인 버전 관리 시스템 또는 소스 코드 저장소 제공업체를 가리킵니다. 일반적인 소스 제공자에는 AWS CodeCommit, GitHub, Bitbucket 등이 포함됩니다. 다음은 소스 제공자로 CodeCommit을 사용하는 예시입니다:\n\n```json\n\"Source\": {\n  \"type\": \"CODECOMMIT\",\n  \"location\": \"YourCodeCommitRepositoryName\"\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nYourCodeCommitRepositoryName을 실제 CodeCommit 리포지토리 이름으로 바꿔주세요. GitHub을 사용한다면, 아래와 같이 설정할 수 있어요:\n\n```js\n\"Source\": {\n  \"type\": \"GITHUB\",\n  \"location\": \"https://github.com/yourusername/yourrepository\",\n  \"gitCloneDepth\": 1\n}\n```\n\nhttps://github.com/yourusername/yourrepository을 사용자의 GitHub 리포지토리 URL로 대체해주세요.\n\n## AWS CodePipeline 구성하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS CodePipeline은 빌드, 테스트 및 배포 프로세스의 단계를 자동화하는 완전 관리형 지속적 통합 및 지속적 전달(CI/CD) 서비스입니다. 애플리케이션의 워크플로우를 정의하고 시각화할 수 있어 코드 변경사항이 소스에서 프로덕션까지 원활하게 이동할 수 있는 경로를 제공합니다.\n\n```js\naws codepipeline create-pipeline \\\n  --pipeline-name YourPipelineName \\\n  --role-arn YourIAMRoleARN \\\n  --output json \\\n  --region YourRegion\n```\n\n## 파이프라인 테스트\n\n웹사이트 코드를 변경하고 저장소에 커밋합니다. 파이프라인은 코드 변경을 자동으로 감지하고 빌드를 트리거하며 업데이트된 코드를 S3 버킷으로 배포합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 프로젝트 # 4 — AWS Lambda를 사용하여 Amazon CloudWatch 메트릭을 CSV 파일로 게시\n\nAWS Lambda를 사용하여 Amazon CloudWatch 메트릭을 CSV 파일로 게시하는 것은 몇 가지 단계를 거쳐 이루어집니다. 람다 함수를 작성하고 권한을 구성하며 CloudWatch 메트릭을 가져와 CSV 파일에 저장하는 코드를 작성하는 과정이 포함됩니다.\n\n## AWS Lambda를 위한 IAM 역할 생성\n\n```js\n# 신뢰 정책 문서 생성 (trust-policy.json)\necho '{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}' \u003e trust-policy.json\n\n# IAM 역할 생성\naws iam create-role \\\n  --role-name YourRoleName \\\n  --assume-role-policy-document file://trust-policy.json\n\n# AWSLambdaBasicExecutionRole 정책을 역할에 부착\naws iam attach-role-policy \\\n  --role-name YourRoleName \\\n  --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 명령을 실행한 후 Lambda 실행을 위한 필수 권한을 가진 IAM 역할인 YourRoleName이 생성됩니다. 이 명령을 실행하려면 AWS CLI가 설치되어 있고 이 명령을 실행할 필요한 권한이 구성되어 있어야 합니다.\n\n## 람다 함수 생성\n\nlambda_function.py라는 파일을 만들어 다음 코드를 붙여넣어 CloudWatch 메트릭을 검색하고 CSV 파일에 저장한 후 S3 버킷에 저장합니다. YourNamespace 및 YourMetricName과 같은 자리 표시자를 구체적인 CloudWatch 네임스페이스와 메트릭 이름으로 교체해 주세요.\n\n```js\nimport boto3\nimport csv\nfrom datetime import datetime, timedelta\n\ndef lambda_handler(event, context):\n    # CloudWatch 클라이언트 설정\n    cloudwatch = boto3.client('cloudwatch')\n\n    # S3 클라이언트 설정\n    s3 = boto3.client('s3')\n\n    # CSV 파일 및 작성자 설정\n    csv_columns = ['MetricName', 'Timestamp', 'Value']\n    csv_data = []\n\n    # CloudWatch 매개변수 정의\n    namespace = 'YourNamespace'\n    metric_name = 'YourMetricName'\n    start_time = datetime.utcnow() - timedelta(days=1)\n    end_time = datetime.utcnow()\n    period = 300  # 5분 간격\n\n    # CloudWatch 메트릭 가져오기\n    response = cloudwatch.get_metric_data(\n        MetricDataQueries=[\n            {\n                'Id': 'm1',\n                'MetricStat': {\n                    'Metric': {\n                        'Namespace': namespace,\n                        'MetricName': metric_name,\n                    },\n                    'Period': period,\n                    'Stat': 'Average',\n                    'Unit': 'Count',\n                },\n                'ReturnData': True,\n            },\n        ],\n        StartTime=start_time,\n        EndTime=end_time,\n    )\n\n    # CSV 데이터 준비\n    for result in response['MetricDataResults'][0]['Timestamps']:\n        csv_data.append({\n            'MetricName': metric_name,\n            'Timestamp': result['Timestamp'].strftime('%Y-%m-%d %H:%M:%S'),\n            'Value': result['Value'],\n        })\n\n    # CSV 데이터를 S3 버킷에 작성\n    s3_bucket = 'your-s3-bucket-name'\n    s3_key = 'cloudwatch_metrics.csv'\n\n    s3.put_object(\n        Bucket=s3_bucket,\n        Key=s3_key,\n        Body='\\n'.join([','.join(map(str, row.values())) for row in csv_data]),\n        ContentType='text/csv'\n    )\n\n    print(f\"S3 버킷에 저장된 CSV 파일: s3://{s3_bucket}/{s3_key}\")\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 배포 패키지를 만듭니다 (Python 코드가 lambda_function.py 파일에 있는 것으로 가정)\nzip deployment-package.zip lambda_function.py\n\n# 람다 함수를 만듭니다\naws lambda create-function \\\n  --function-name YourFunctionName \\\n  --runtime python3.8 \\\n  --role arn:aws:iam::YourAWSAccountID:role/YourRoleName \\\n  --handler lambda_function.lambda_handler \\\n  --zip-file fileb://deployment-package.zip\n```\n\n람다 함수와 관련된 IAM 역할에 CloudWatch 권한을 추가하려면 다음 명령어를 사용할 수 있습니다:\n\n```js\naws iam attach-role-policy \\\n  --role-name YourRoleName \\\n  --policy-arn arn:aws:iam::aws:policy/CloudWatchReadOnlyAccess\n```\n\n이 명령은 CloudWatchReadOnlyAccess 정책을 지정된 IAM 역할에 첨부하여 필요한 권한을 부여합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 람다 함수 테스트\n\n- 람다 콘솔의 \"테스트\" 버튼을 클릭하여 함수를 수동으로 트리거하세요.\n- 오류나 문제가 있는지 확인하기 위해 CloudWatch Logs 및 람다 콘솔을 확인하세요.\n\n## CloudWatch Events 설정 (선택 사항)\n\nAmazon CloudWatch Events는 사용자가 시스템 이벤트에 응답하고 AWS 환경에서 워크플로우를 자동화할 수 있는 완전 관리형 서비스입니다. 다양한 AWS 서비스에서 이벤트를 다른 대상(예: AWS 람다 함수 또는 SNS 토픽)으로 라우팅하는 확장 가능하고 유연한 방법을 제공하여 이벤트 중심 아키텍처를 구축할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS CLI를 사용하여 CloudWatch Events를 설정하려면 다음 명령어를 사용할 수 있어요. 이를 통해 일정한 기간(예: 매일)에 람다 함수를 트리거하는 규칙을 만들 수 있습니다.\n\n```js\n# 규칙 생성\naws events put-rule \\\n  --name YourRuleName \\\n  --schedule-expression \"rate(1 day)\"\n\n# 람다 함수를 규칙의 대상으로 추가\naws events put-targets \\\n  --rule YourRuleName \\\n  --targets \"Id\"=\"1\",\"Arn\"=\"arn:aws:lambda:your-region:your-account-id:function:YourFunctionName\"\n\n# 규칙 활성화\naws events enable-rule --name YourRuleName\n```\n\n이 명령어들은 다음을 수행합니다:\n\n- 매일 규칙을 트리거하는 스케줄 표현을 가진 CloudWatch Events 규칙을 생성합니다.\n- 람다 함수를 규칙의 대상으로 추가합니다.\n- 규칙을 활성화하여 활성화합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCloudWatch Events로 Lambda 함수를 트리거할 수 있는 필요한 권한을 가지고 있는지 확인해주세요.\n\n```js\n# Lambda 함수의 실제 이름으로 YourFunctionName을 교체해주세요.\nlambda_function_name=\"YourFunctionName\"\n\n# Lambda 함수에 연결된 현재 IAM 역할 가져오기\nlambda_role_arn=$(aws lambda get-function-configuration --function-name $lambda_function_name --query 'Role' --output text)\n\n# AWSLambdaRole 정책을 Lambda 역할에 연결하기\naws iam attach-role-policy \\\n  --role-name ${lambda_role_arn##*/} \\\n  --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaRole\n```\n\n이 스크립트는 다음 작업을 수행합니다:\n\n- Lambda 함수에 현재 연결된 IAM 역할을 가져옵니다.\n- Lambda 역할에 AWSLambdaRole 정책을 연결합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 프로젝트 # 5 — AWS Amplify를 사용하여 간단한 React 웹 애플리케이션 배포하기\n\n## 전제 조건\n\n- AWS 계정: AWS 계정이 설정되어 있는지 확인하세요.\n- 로컬 컴퓨터에 Node.js와 npm이 설치되어 있어야 합니다.\n- AWS CLI가 설치되고 AWS 자격 증명으로 구성되어 있어야 합니다.\n\n## React 애플리케이션 설정하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCreate React App을 사용하여 새 React 애플리케이션을 만들어보세요:\n\n```js\nnpx create-react-app my-react-app\ncd my-react-app\n```\n\n## AWS Amplify\n\nAWS Amplify는 풀스택 웹 및 모바일 애플리케이션을 빌드하고 배포하는 프로세스를 간소화하는 포괄적인 개발 플랫폼입니다. 사용자 인증, API 통합, 저장, 호스팅과 같은 작업을 단순화하는 일련의 도구와 서비스를 제공합니다. Amplify를 통해 개발자들은 최소한의 구성으로 다양한 AWS 서비스를 활용하여 확장 가능하고 안전한 애플리케이션을 빠르게 만들 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAmplify 프로젝트를 초기화하기 전에, Amplify CLI가 설치되어 있는지 확인해주세요. 다음 명령어를 사용하여 전역으로 설치할 수 있습니다:\n\n```js\nnpm install -g @aws-amplify/cli\n```\n\n이제 터미널에서 React 애플리케이션의 루트 디렉토리로 이동한 후 아래 명령어를 실행해주세요:\n\n```js\namplify init\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n`amplify init` 명령어는 Amplify 프로젝트 설정을 초기화하고 여러 프롬프트를 통해 안내해줍니다:\n\n- 프로젝트에 이름을 입력하세요: 프로젝트에 고유한 이름을 제공하세요.\n- 환경 선택: 기본 환경(일반적으로 dev)을 선택하세요.\n- 기본 편집기 선택: 선호하는 코드 편집기를 선택하세요.\n- 빌드 중인 앱 유형 선택: React 애플리케이션에 대해 javascript를 선택하세요.\n- 사용 중인 JavaScript 프레임워크 선택: react를 선택하세요.\n- 소스 디렉토리 경로: 기본값(src)을 유지하세요.\n- 배포 디렉토리 경로: 기본값(build)을 유지하세요.\n- 빌드 명령어: 기본값(npm run-script build)을 유지하세요.\n- 시작 명령어: 기본값(npm run-script start)을 유지하세요.\n\n이러한 세부 정보를 제공한 후에 Amplify는 프로젝트를 초기화하고 필요한 구성 파일 및 디렉토리를 설정합니다.\n\n## Amazon Cognito를 사용한 인증\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아마존 코그니토는 AWS가 완전히 관리하는 서비스로, 안전한 사용자 식별 및 액세스 관리를 제공합니다. 이는 개발자가 웹 및 모바일 앱에 사용자 가입, 로그인 및 액세스 제어를 쉽게 추가할 수 있게 해줍니다. 다중 인증 및 소셜 신원 연합과 같은 기능을 통해 아마존 코그니토는 견고한 인증 및 권한 부여 메커니즘의 구현을 간편화합니다.\n\n초기화 이후, amplify add 명령을 사용하여 인증, API, 저장소 및 호스팅과 같은 백엔드 서비스를 추가할 수 있습니다. 예를 들어, 인증을 추가하려면 다음을 실행하십시오:\n\n```js\namplify add auth\n```\n\n인증 제공자 및 고급 설정을 포함한 인증 설정을 구성하려면 프롬프트를 따르세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n백엔드 서비스를 구성한 후 다음 명령을 사용하여 클라우드에 배포하십시오:\n\n```js\namplify push\n```\n\nAmplify는 배포할 변경 사항에 대한 요약을 제시할 것입니다. 프로젝트에 필요한 AWS 리소스를 프로비저닝하기 위해 배포를 확인하십시오.\n\nAmplify 프로젝트를 확인하고 관리하기 위해 다음 명령을 사용하여 Amplify 콘솔을 열어보세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\namplify console\n```\n\n이 명령을 실행하면 기본 웹 브라우저에서 Amplify Console이 열리며, 배포된 서비스를 모니터링하고 관리할 수 있는 시각적 인터페이스가 제공됩니다.\n\n## API를 위한 AWS AppSync 설정\n\nAWS AppSync는 확장 가능하고 안전한 GraphQL API 개발을 간소화하는 관리형 서비스입니다. 개발자는 AppSync를 사용하여 애플리케이션을 다양한 데이터 원본에 쉽게 연결할 수 있으며, DynamoDB, Lambda 또는 HTTP 데이터 소스를 포함한 AWS 서비스에 연결할 수 있습니다. AppSync는 실시간 데이터 동기화 및 오프라인 기능을 제공하여, 반응성 있고 협업을 위한 애플리케이션을 구축하는 데 효율적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n터미널을 열고 다음 명령을 실행하여 Amplify CLI를 사용하여 새 API를 추가하세요:\n\n```js\namplify add api\n```\n\n- API 유형으로 GraphQL을 선택하세요.\n- API에 이름을 제공하세요.\n- 권한 유형을 선택하세요. 간단하게 API 키를 선택하시면 됩니다.\n- 스키마 및 리졸버와 같은 추가 설정을 구성하세요.\n\nAmplify CLI는 GraphQL 스키마를 편집하도록 안내할 것입니다. amplify/backend/api/'API_NAME'/schema 디렉토리에서 생성된 schema.graphql 파일을 열고 GraphQL 스키마를 정의하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAPI를 구성한 후 다음 명령을 사용하여 배포하십시오:\n\n```js\namplify push\n```\n\n- Amplify에서 GraphQL API를 위한 코드를 생성하고 싶은지 물어볼 것입니다. GraphQL 작업을 위한 코드를 생성할지 선택할 수 있으며, 이는 API와 상호작용하기 위해 프로젝트에 필요한 파일을 생성합니다.\n- 배포를 계속하고 싶은지 확인하십시오.\n\nAmplify는 AWS에서 AppSync API, DynamoDB 테이블(필요한 경우), 관련 IAM 역할을 포함하여 필요한 리소스를 프로비저닝할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n배포가 완료되면 AWS AppSync 콘솔에서 새로 만들어진 API를 살펴볼 수 있습니다. 다음 명령을 실행하여 콘솔을 열 수 있습니다:\n\n```js\namplify console api\n```\n\n이 명령을 실행하면 AWS AppSync 콘솔이 기본 웹 브라우저에서 열립니다. 여기에서 GraphQL 스키마를 볼 수 있고 추가 설정을 구성하거나 내장된 쿼리 편집기를 사용하여 API를 테스트할 수 있습니다.\n\nReact 애플리케이션에서 API를 사용하려면 필요한 종속성을 설치하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nnpm install aws-amplify @aws-amplify/ui-react\n```\n\nReact 앱에서 Amplify를 설정하려면 다음과 같이 하세요:\n\n```js\n// src/index.js\nimport Amplify from \"aws-amplify\";\nimport config from \"./aws-exports\";\nAmplify.configure(config);\n```\n\n이제 React 컴포넌트에서 생성된 GraphQL 작업을 사용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n// React 컴포넌트 예시\nimport { API } from 'aws-amplify';\n\nasync function fetchData() {\n  try {\n    const result = await API.graphql({ query: /* 여러분의 GraphQL 쿼리 */ });\n    console.log(result);\n  } catch (error) {\n    console.error(error);\n  }\n}\n```\n\nAWS AppSync를 API에 성공적으로 설정하고 배포하였으며 React 애플리케이션을 Amplify를 사용하여 API와 상호작용하도록 연결하였습니다.\n\n## 데이터베이스로 Amazon DynamoDB 설정\n\nAmazon DynamoDB는 AWS에서 제공하는 완전히 관리되는 NoSQL 데이터베이스 서비스로, 높은 성능과 확장 가능한 응용 프로그램을 위해 설계되었습니다. 데이터에 대한 낮은 지연 시간 액세스와 함께 처리량 및 스토리지의 신속하고 자동적인 확장을 제공합니다. DynamoDB는 문서 및 키-값 데이터 모델을 모두 지원하며 작은 응용 프로그램부터 대규모로 분산된 글로벌 시스템까지 다양한 사용 사례에 적합합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n터미널에서 다음 명령을 실행하여 Amplify 프로젝트에 새로운 DynamoDB 테이블을 추가하세요:\n\n```js\namplify add storage\n```\n\n- 스토리지 유형으로 NoSQL 데이터베이스를 선택하세요.\n- NoSQL 데이터베이스로 Amazon DynamoDB를 선택하세요.\n- 테이블 이름을 지정하세요.\n- 테이블의 기본 키를 정의하세요. 예를 들어, 문자열 형식의 id를 파티션 키로 사용할 수 있습니다.\n\nAmplify는 추가적인 DynamoDB 테이블 설정을 구성하도록 안내할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 인덱스 추가: 응용 프로그램의 쿼리 요구 사항에 따라 전역 또는 로컬 보조 인덱스를 추가할 수 있습니다.\n- 고급 설정 지정: 읽기 및 쓰기 용량 단위와 같은 추가 구성을 설정하거나 기본 값을 사용할 수 있습니다.\n\nDynamoDB 테이블을 구성한 후 AWS 클라우드에 DynamoDB 테이블을 프로비저닝하려면 변경 사항을 배포하십시오:\n\n```js\namplify push\n```\n\n알림을 받으면 배포를 확인하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금 DynamoDB가 설정되어 있습니다. React 애플리케이션에서 이에 접근할 수 있습니다. Amplify는 자동으로 DynamoDB 테이블을 위한 일련의 GraphQL 변이 및 쿼리를 생성합니다. 이들은 프로젝트의 src/graphql 디렉토리에서 찾을 수 있습니다. 예를 들어 Todo 테이블을 추가한 경우, createTodo, updateTodo와 같은 변이 및 listTodos와 같은 쿼리가 있을 수 있습니다.\n\n생성된 쿼리 및 변이를 사용하여 React 컴포넌트에서 DynamoDB와 상호 작용할 수 있습니다:\n\n```js\n// 예시: 새 Todo 생성\nimport { API, graphqlOperation } from \"aws-amplify\";\n\nasync function createTodo() {\n  const todoDetails = {\n    name: \"새로운 할 일\",\n    description: \"새 할 일에 대한 설명\",\n  };\n\n  try {\n    const result = await API.graphql(\n      graphqlOperation(createTodo, { input: todoDetails })\n    );\n    console.log(\"할 일이 생성되었습니다:\", result.data.createTodo);\n  } catch (error) {\n    console.error(\"할 일 생성 중 에러 발생:\", error);\n  }\n}\n```\n\nAWS Management Console에서 DynamoDB 테이블을 살펴볼 수도 있습니다. 다음 명령어를 실행하여 DynamoDB 콘솔을 열 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\namplify console storage\n```\n\n이 명령은 기본 웹 브라우저에서 DynamoDB 콘솔을 열어서 DynamoDB 테이블을 확인하고 관리할 수 있게 해줍니다.\n\nAmplify 프로젝트에 Amazon DynamoDB를 성공적으로 설정하고 React 애플리케이션에 통합했습니다. 이제 생성된 GraphQL 작업을 사용하여 DynamoDB 테이블에서 CRUD 작업을 수행할 수 있습니다.\n\n## Amazon S3 및 CloudFront 설정하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n터미널에서 다음 명령어를 실행하여 Amplify 프로젝트에 호스팅을 추가하세요:\n\n```js\namplify add hosting\n```\n\n- 호스팅 서비스로 Amazon S3와 Amazon CloudFront를 선택하세요.\n- 호스팅 환경에 이름을 제공하세요.\n- 인덱스 및 오류 문서와 같은 추가 설정을 구성하세요.\n\n호스팅 환경을 구성한 후, 필요한 S3 버킷 및 CloudFront 배포를 생성하기 위해 배포하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\namplify publish\n```\n\n물어볼 때 배포를 확인하세요.\n\n파일 저장을 위해 Amazon S3를 사용하려면(Amazon S3에서 사용자 업로드를 저장하는 등) Amplify 프로젝트 설정을 수정해야 합니다. 프로젝트의 src 디렉터리에 있는 aws-exports.js 파일을 열어 다음 구성을 추가하세요:\n\n```js\n// aws-exports.js\n\nconst awsmobile = {\n  ...\n  storage: {\n    AWSS3: {\n      bucket: '당신의-s3-버킷-이름',\n      region: '당신의-지역',\n    },\n  },\n};\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n`your-s3-bucket-name`을 고유한 S3 버킷 이름으로, `your-region`을 S3 버킷을 생성할 AWS 지역으로 변경해주세요.\n\nS3 및 CloudFront를 설정하면 React 애플리케이션에서 정적 자산을 제공하고 파일을 호스팅하며 콘텐츠 전달에 활용할 수 있습니다.\n\n예를 들어, S3에 파일을 업로드하는 방법은 다음과 같습니다:\n\n```js\n// 예시: 파일을 S3에 업로드하기\nimport { Storage } from \"aws-amplify\";\n\nasync function uploadFile(file) {\n  try {\n    await Storage.put(\"파일경로\", file, {\n      contentType: \"image/jpeg\", // 파일 유형에 따라 콘텐츠 유형을 조정하세요\n    });\n    console.log(\"파일이 성공적으로 업로드되었습니다!\");\n  } catch (error) {\n    console.error(\"파일 업로드 중 오류 발생:\", error);\n  }\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS Management Console에서 S3 버킷을 탐색할 수도 있습니다. 다음 명령을 실행하여 S3 콘솔을 열 수 있습니다:\n\n```js\namplify console storage\n```\n\n기본 웹 브라우저에서 이 명령을 실행하면 S3 콘솔이 열리며 S3 버킷에 있는 파일을 볼 수 있고 관리할 수 있습니다.\n\n호스팅 환경을 배포한 후, Amplify는 CloudFront 배포 URL을 제공합니다. Amplify 콘솔이나 amplify publish를 실행한 후 출력에서 이 URL을 찾을 수 있습니다. 이 CloudFront URL을 사용하여 전 세계에 배포된 React 애플리케이션에 액세스할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아마존 S3와 CloudFront를 Amplify 프로젝트에 설정하여 스토리지 및 콘텐츠 전달을 성공적으로 구축했습니다. React 애플리케이션이 호스팅되고 정적 자원이 효율적으로 CloudFront를 통해 전달됩니다.\n\n## React 애플리케이션에 Amplify 통합하기\n\n터미널에서 React용 필수 Amplify 라이브러리를 설치하세요:\n\n```js\nnpm install aws-amplify @aws-amplify/ui-react\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n당신의 React 애플리케이션에서는 Amplify를 구성하기 위해 다음 코드를 애플리케이션의 진입점에 추가하세요 (일반적으로 src/index.js 또는 src/index.tsx):\n\n```js\n// src/index.js\n\nimport React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport Amplify from \"aws-amplify\";\nimport awsConfig from \"./aws-exports\"; // 프로젝트에 이 파일이 존재하는지 확인하세요\n\nAmplify.configure(awsConfig);\n\nReactDOM.render(\n  \u003cReact.StrictMode\u003e\n    {/* 여러분의 주 애플리케이션 컴포넌트 */}\n  \u003c/React.StrictMode\u003e,\n  document.getElementById(\"root\")\n);\n```\n\nAmplify는 일반적인 인증 흐름을 위한 미리 제작된 UI 컴포넌트를 제공합니다. 이러한 컴포넌트를 React 애플리케이션에 통합하여 사용자 인증을 할 수 있습니다. 예를 들어, withAuthenticator를 사용하여 주 애플리케이션 컴포넌트를 감쌀 수 있습니다:\n\n```js\n// src/App.js\n\nimport React from \"react\";\nimport { withAuthenticator } from \"@aws-amplify/ui-react\";\n\nfunction App() {\n  return (\n    \u003cdiv\u003e\n      \u003ch1\u003eYour React App\u003c/h1\u003e\n      {/* 여러분의 앱 콘텐츠 */}\n    \u003c/div\u003e\n  );\n}\n\nexport default withAuthenticator(App, { includeGreetings: true });\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앱에 인증 기능을 추가하게 됩니다. 회원 가입, 로그인 및 로그아웃과 같은 기능이 포함됩니다.\n\n인증된 사용자에 대한 정보에 액세스하려면 Amplify에서 제공하는 Auth 모듈을 사용할 수 있습니다:\n\n```js\n// 예: 사용자 정보에 액세스\nimport { Auth } from \"aws-amplify\";\n\nasync function getUserInfo() {\n  try {\n    const user = await Auth.currentAuthenticatedUser();\n    console.log(\"인증된 사용자:\", user);\n  } catch (error) {\n    console.error(\"사용자 정보 가져오기 오류:\", error);\n  }\n}\n```\n\nAmplify는 인증 이상의 다양한 기능을 제공합니다. API 상호 작용, 저장소 및 실시간 데이터 동기화와 같은 기능이 포함되어 있습니다. Amplify 문서에서 이러한 기능을 살펴볼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로컬에서 React 애플리케이션을 실행하여 Amplify와의 통합을 테스트해보세요:\n\n```js\nnpm start\n```\n\n애플리케이션에 만족하면 다음 명령어를 사용하여 클라우드에 배포하세요:\n\n```js\namplify publish\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nReact 애플리케이션을 구성된 Amplify 서비스와 함께 AWS에 배포할 것입니다.\n\n축하합니다! Amplify를 React 애플리케이션에 성공적으로 통합하여 인증과 다른 Amplify 서비스에 액세스하는 기능을 활성화했습니다. 이제 AWS Amplify 능력이 원할하게 통합된 앱을 배포할 준비가 되었습니다.\n\n# 결론\n\n다섯 가지 프로젝트는 AWS의 다양한 능력을 탐험하고 공유하는 경로로서 선별한 컬렉션입니다. 이 여정을 마칠 때, AWS의 다양한 성격을 이해할 뿐만 아니라 효과적으로 그 능력을 활용할 자신감까지 얻으실 것입니다.\n","ogImage":{"url":"/assets/img/2024-05-20-5FunProjectstolearnAWS_0.png"},"coverImage":"/assets/img/2024-05-20-5FunProjectstolearnAWS_0.png","tag":["Tech"],"readingTime":40},{"title":"아마존 S3 프리사인드 URL 활용 방법","description":"","date":"2024-05-20 16:44","slug":"2024-05-20-HowtoutilizeAmazonS3presignedURLs","content":"\n블롭 객체를 안전하게 저장하는 것은 중요합니다. AWS S3는 이를 위한 우수한 해결책을 제공합니다. 여러 언어로 제공되는 사용자 친화적인 SDK를 통해 파일을 업로드하고 다운로드하는 과정이 간단해집니다. 그러나 민감한 계정 자격 증명에 접속해야 하는 경우가 발생할 수 있습니다. 이런 상황에서 사전 서명된 URL은 귀중한 해결책으로 나타납니다. 이 URL은 AWS S3 버킷 리소스에 일시적으로 접속할 수 있는 수단을 제공하여 비밀 키를 직접 삽입할 필요가 없어집니다. 이 URL은 데이터 무결성을 보호하면서 보안을 보장하는 안전하고 일시적인 접근을 가능케 합니다.\n\n본 글에서는 파일을 업로드하고 다운로드하는 용도로 사전 서명된 URL을 사용하는 방법을 설명하여 AWS S3를 효과적으로 활용하면서 데이터 보안의 실천을 유지할 수 있도록 돕고 있습니다.\n\n# 사용 사례\n\n다음은 사전 서명된 URL을 활용할 수 있는 여러 사용 사례입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 일시적 액세스를 통한 다운로드 링크: 사전 서명된 GET URL을 생성하여 S3 버킷에서 특정 파일을 다운로드하는 데 일시적인 액세스를 제공할 수 있습니다. 이를 통해 AWS 자격 증명을 노출시키지 않고 다른 사람들과 파일을 안전하게 공유할 수 있습니다.\n- 일시적 슬롯을 통한 업로드 링크: 비슷하게, 사전 서명된 PUT URL은 S3 버킷으로 파일을 업로드하는 데 일시적인 액세스를 제공하는 데 사용할 수 있습니다. 이를 통해 사용자들이 직접 AWS 자격 증명에 접근할 필요없이 파일을 안전하게 업로드할 수 있습니다.\n- 가상 머신 보안: 부팅할 때 가상 머신에 사전 서명된 POST 정책을 삽입하여 지정된 조건하에 여러 파일을 S3 버킷에 안전하게 업로드할 수 있습니다. 이 접근 방식은 민감한 AWS 자격 증명이 가상 머신에 저장되지 않도록 보안을 강화합니다.\n- HTML 폼으로 직접 파일 업로드: HTML 폼에 사전 서명된 POST 정책을 삽입하여 백엔드 서버를 프록시로 사용하지 않고 S3 버킷으로의 직접 파일 업로드를 허용할 수 있습니다. 이를 통해 업로드 프로세스를 간소화하고 서버 측 처리를 줄일 수 있습니다.\n\nAWS S3 사전 서명된 URL을 사용하면 PUT 또는 POST 정책을 사용하여 단일 또는 여러 파일을 업로드할 수 있습니다. 다수의 파일을 다운로드할 수 있는 정책을 생성하는 것은 불가능합니다. 이 경우에는 여러 개의 사전 서명된 GET URL을 생성해야 합니다.\n\n[2024-05-20-HowtoutilizeAmazonS3presignedURLs_0.png](/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_0.png)\n\n단일 파일을 다운로드하거나 업로드하기 위해, 파일 업로드가 필요한 구성 요소가 필요할 때 외부 서비스로부터 사전 서명된 URL을 동적으로 요청할 수 있는 풀 기반 아키텍처가 탁월합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image1](/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_1.png)\n\nConversely, for scenarios such as uploading using HTML form or running specific jobs within a virtual machine, a push-based approach presents a straightforward solution. Here, the initiation of the presigned POST policy aligns with the document creation or VM startup process. By injecting a policy during these events, we empower the source to autonomously upload files and minimize external dependencies.\n\n![image2](/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_2.png)\n\n# How-to guide\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬 boto 패키지를 사용하여 미리 서명된 URL을 생성하고 사용하는 방법을 보여드립니다. 간단한 인터페이스를 제공하는 AWS S3 클라이언트입니다.\n\n```js\nimport os\n\nimport boto3\nfrom botocore.client import Config\n\nACCESS_KEY = os.getenv(\"ACCESS_KEY\")\nSECRET_KEY = os.getenv(\"SECRET_KEY\")\nregion = \"eu-central-1\"\n\ns3_client = boto3.client(\n    's3',\n    aws_access_key_id=ACCESS_KEY,\n    aws_secret_access_key=SECRET_KEY,\n    config=Config(signature_version='s3v4'),\n    region_name=region,\n)\n```\n\n물론 AWS S3 클라우드에도 액세스해야합니다. 이전 포스트 중 하나에서 IAM 계정 및 S3 버킷을 생성하는 방법을 설명했습니다. 이 포스트는 AWS S3 업로드에 대한 자동화 테스트에 관한 것입니다.\n\n# Presigned POST policy\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n미리 서명된 POST URL에서는 여러 파일을 업로드할 수 있는 정책을 구성합니다. 다음을 정의할 수 있습니다:\n\n- S3 버킷 파일이 저장될 위치 — bucket_name\n- 정책의 유효 기간 — ExpiresIn\n- 추가로 허용할 폼 필드 — Fields\n- 추가 조건 세트 — Conditions (예: 파일의 허용 확장자, 파일 이름의 허용 접두사)\n\n우리의 예시에서는 정책이 생성 시간으로부터 1분(60초) 후에 만료될 것이라고 지정합니다. 또한 mytest/ 문자열로 시작하는 키를 가진 파일만 허용합니다. Amazon S3에서 키(객체 이름이라고도 함)는 버킷 내 객체의 고유 식별자로 사용됩니다. 이것은 본질적으로 버킷의 네임스페이스 내 객체의 전체 경로를 나타냅니다. 이 구성은 testjorzel 버킷 내 mytest 폴더로 파일을 업로드할 수 있도록 허용합니다.\n\n```js\nimport requests\n\nbucket_name = \"testjorzel\"\nprefix = \"mytest/\"\nobject_name = prefix + \"${filename}\"\npresigned_post = s3_client.generate_presigned_post(\n    bucket_name,\n    object_name,\n    Fields=None,\n    Conditions=[[\"starts-with\", \"$key\", prefix]],\n    ExpiresIn=expiration,\n)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저희 사전 서명된 POST 정책은 다음과 같이 보입니다:\n\n```js\n{\n    'url': 'https://testjorzel.s3.amazonaws.com/',\n    'fields': {\n        'key': 'mytest/${filename}',\n        'x-amz-algorithm': 'AWS4-HMAC-SHA256',\n        'x-amz-credential': 'AKIAU5USI2VZ3RIF3L5V/20240403/eu-central-1/s3/aws4_request',\n        'x-amz-date': '20240403T201346Z',\n        'policy': 'eyJleHBpcmF0aW9uIjogIjIwMjQtMDQtMDNUMjE6MTM6NDZaIiwgImNvbmRpdGlvbnMiOiBbWyJzdGFydHMtd2l0aCIsICIka2V5IiwgIm15dGVzdC8iXSwgeyJidWNrZXQiOiAidGVzdGpvcnplbCJ9LCBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAibXl0ZXN0LyJdLCB7IngtYW16LWFsZ29yaXRobSI6ICJBV1M0LUhNQUMtU0hBMjU2In0sIHsieC1hbXotY3JlZGVudGlhbCI6ICJBS0lBVTVVU0kyVlozUklGM0w1Vi8yMDI0MDQwMy9ldS1jZW50cmFsLTEvczMvYXdzNF9yZXF1ZXN0In0sIHsieC1hbXotZGF0ZSI6ICIyMDI0MDQwM1QyMDEzNDZaIn1dfQ==',\n        'x-amz-signature': '672ca05236f727190841b102a73e4d3298b5821b5afbc62cbfba2dad6128c74c'\n    }\n}\n```\n\n이는 일반적인 URL과 POST 요청과 함께 전달해야 하는 인증 필드 세트로 구성되어 있습니다(requests.post 함수).\n\n```js\nimport requests\n\ndef upload_file(filepath, object_name, policy):\n    with open(filepath, 'rb') as f:\n        files = {'file': (filepath, f)}\n        fields = policy['fields']\n        fields['key'] = object_name\n        http_response = requests.post(policy['url'], data=fields, files=files)\n    print(f'File: {object_name} uploaded, HTTP status code: {http_response.status_code}, text: {http_response.text}')\n\nfilepath = \"test.txt\"\nupload_file(filepath, 'mytest/post_test1.txt', presigned_post)\nupload_file(filepath, 'mytest/post_test2.txt', presigned_post)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ntest.txt 파일은 하나의 줄로 구성된 간단한 텍스트 파일입니다: My test put/get/post. POST 요청이 성공하면 결과는 내용이없는 204 응답 코드여야 합니다. 이는 파일이 성공적으로 업로드되었음을 의미합니다.\n\n```js\nFile: mytest/post_test1.txt uploaded, HTTP status code: 204,\ntext:\n\nFile: mytest/post_test2.txt uploaded, HTTP status code: 204,\ntext:\n```\n\n우리는 S3 클라우드의 testjorzel 버킷 내용을 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n`Markdown` 형식으로 변경된 테이블:\n\n| 파일 이름      | 결과 코드 | 메시지       | 요청 ID          | 호스트 ID                                                                    |\n| -------------- | --------- | ------------ | ---------------- | ---------------------------------------------------------------------------- |\n| post_test1.txt | 200       | -            | -                | -                                                                            |\n| post_test2.txt | 200       | -            | -                | -                                                                            |\n| post_test3.txt | 403       | AccessDenied | 3GZ7Q2XYK4R9190H | CAL0rRroo8PjDPvXEKhAa5XB/FKwf0k+dm00Kwr95ri2yaN+Hr/qZgzmnH4Fs/Jmnt45rMBidY8= |\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n파일 test/post_test4.txt가 업로드되었습니다. HTTP 상태 코드: 403,\n텍스트: \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\n\u003cError\u003e\u003cCode\u003eAccessDenied\u003c/Code\u003e\u003cMessage\u003e정책에 따라 무효함: 정책 조건 실패: [\"starts-with\", \"$key\", \"mytest/\"]\u003c/Message\u003e\u003cRequestId\u003e4AKJZREYX4YD17VF\u003c/RequestId\u003e\u003cHostId\u003eWLz45xZYd7dSgSIi/6SWtWuzPPYF2aCI1oeX8P+RxTdFskeAM6c7g0VH0OwJRVDIEBSmUS8qDnw=\u003c/HostId\u003e\u003c/Error\u003e\n```\n\n# GET을 위한 사전 서명 된 URL\n\nS3 버킷에 파일이 있다고 가정하고(예: post_test1.txt), 사전 서명된 GET URL을 생성할 수 있습니다.\n\n```js\nbucket_name = \"testjorzel\";\nprefix = \"mytest/\";\npresigned_get = s3_client.generate_presigned_url(\n  \"get_object\",\n  (Params = {\n    Bucket: bucket_name,\n    Key: \"mytest/post_test1.txt\",\n  }),\n  (ExpiresIn = 60)\n);\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 URL은 쿼리 문자열에 추가 필드를 포함한 문자열이어야 합니다:\n\n```js\nhttps://testjorzel.s3.amazonaws.com/mytest/post_test1.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAU5USI2VZ3RIF3L5V%2F20240403%2Feu-central-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20240403T203856Z\u0026X-Amz-Expires=60\u0026X-Amz-SignedHeaders=host\u0026X-Amz-Signature=25b531d9eb1ed01afcaaa1ce61fddf36720833e04a239d0ab0c6fa78ce308fa1\n```\n\n이를 사용하여 파일을 다운로드할 수 있습니다 (request.get을 실행함).\n\n```js\nimport requests\n\ndef download_file(url):\n    response_get = requests.get(url)\n    print(f\"다운로드, HTTP 코드: {response_get.status_code}, 내용: '{response_get.text}'\")\n    with open(\"presigned_get.txt\", mode=\"wb\") as file:\n        file.write(response_get.content)\n\ndownload_file(presigned_get)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파일은 저희 디스크에 presigned_get.txt 이름으로 저장되어야 하며, 응답은 다음과 같아야 합니다:\n\n```js\n다운로드, HTTP 코드: 200, 내용: 'My test put/get/post'\n```\n\n# PUT을 위한 Presigned URL\n\n마지막 케이스는 단일 파일을 업로드하기 위한 presigned PUT URL을 생성하는 것입니다 (키: mytest/presigned_put.txt 아래). GET과 비슷하게 동작할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nbucket_name = \"testjorzel\";\nprefix = \"mytest/\";\npresigned_put = s3_client.generate_presigned_url(\n  \"put_object\",\n  (Params = {\n    Bucket: bucket_name,\n    Key: prefix + \"presigned_put.txt\",\n  }),\n  (ExpiresIn = 60)\n);\n```\n\nThe `presigned_put` will also be a string:\n\n[https://testjorzel.s3.amazonaws.com/mytest/presigned_put.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAU5USI2VZ3RIF3L5V%2F20240403%2Feu-central-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20240403T204459Z\u0026X-Amz-Expires=60\u0026X-Amz-SignedHeaders=host\u0026X-Amz-Signature=ed117f655fc007d1572618474b9fc96f1a1820ec705317a6954c6a78730fd769](https://testjorzel.s3.amazonaws.com/mytest/presigned_put.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAU5USI2VZ3RIF3L5V%2F20240403%2Feu-central-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20240403T204459Z\u0026X-Amz-Expires=60\u0026X-Amz-SignedHeaders=host\u0026X-Amz-Signature=ed117f655fc007d1572618474b9fc96f1a1820ec705317a6954c6a78730fd769)\n\nNow we can upload a file using `requests.put` function.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport requests\n\nfilepath = \"test.txt\"\n\ndef upload_file(filepath, presigned_put):\n    with open(filepath, 'rb') as f:\n        response_put = requests.put(presigned_put, data=f)\n        print(f\"파일 업로드, HTTP 상태 코드: {response_put.status_code}, 내용: '{response_put.text}'\")\n\nupload_file(filepath, presigned_put)\n```\n\n위 코드의 실행 결과는:\n\n```js\n파일 업로드, HTTP 상태 코드: 200, 내용: ''\n```\n\n이 파일은 'testjorzel' 버킷에서 찾을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_4.png\" /\u003e\n\n# 결론\n\n이 짧은 가이드에서 우리는 Amazon S3의 사전 서명된 URL의 다양성을 탐구하고, 해당 사용법을 파이썬으로 실제 예제를 통해 보여주었습니다. 단일 파일 및 여러 파일에 대해 둘 다 수행할 수 있는 방법을 보여주었으며, 이는 AWS 자격 증명을 응용 프로그램에 포함시키지 않거나 사용자에게 민감한 AWS 자격 증명을 공유하지 않고 S3에서 파일 업로드 또는 다운로드를 활성화하고자 하는 시나리오에서 특히 유용합니다.\n\n이 주제를 다룬 코드베이스는 여기에서 찾을 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_0.png"},"coverImage":"/assets/img/2024-05-20-HowtoutilizeAmazonS3presignedURLs_0.png","tag":["Tech"],"readingTime":13},{"title":"쿠버네티스 시크릿을 암호화하는 방법","description":"","date":"2024-05-20 16:42","slug":"2024-05-20-HowtoEncryptKubernetesSecrets","content":"\n쿠버네티스 시크릿은 Kubernetes 클러스터에서 실행되는 애플리케이션에서 필요한 비밀 정보를 저장하고 관리하는 메커니즘입니다.\n\n- 민감한 데이터를 응용 프로그램 코드와 분리하여 보관합니다.\n- 시크릿을 생성, 업데이트 및 처리하기 위해 Kubernetes API를 통해 관리됩니다.\n- 시크릿 액세스를 제한하는 구성 가능한 액세스 정책이 있습니다.\n- 볼륨 내의 파일로 노출되거나 환경 변수로 포드에 노출됩니다.\n\n# 시크릿 암호화의 중요성 :\n\n- etcd에서 암호화되지 않은 시크릿은 데이터베이스가 침해당한 경우에 접근할 수 있습니다.\n- 구성이 잘못된 리소스를 통해 실수로 노출될 수 있는 위험이 있습니다.\n- 스토리지 액세스 권한이 있는 관리자 및 사용자가 액세스할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 암호화의 장점 :\n\n- 복호화 키 없이 비밀을 읽을 수 없게 만듭니다.\n- 규정 준수를 통해 데이터 보호 요구 사항 충족을 돕습니다.\n- 암호화된 데이터는 키 없이는 쓸모 없어서 침해로부터의 피해를 줄입니다.\n- 네트워크 전송 중 가로채기를 방지합니다.\n\n# Kubernetes Secrets의 예시 :\n\n- 비밀번호: 데이터베이스 자격 증명, 애플리케이션 로그인 비밀번호 또는 다른 형태의 사용자 인증 비밀번호입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 예시: MySQL 데이터베이스 비밀번호.\n\n2. API 키: 외부 서비스 및 API에 인증하고 액세스하기 위한 토큰.\n\n- 예시: 구글 맵스 API 키, Stripe API 키.\n\n3. SSH 키: 서버에 안전한 셸 액세스에 사용되는 키.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 예시: 원격 Git 저장소에 액세스하는 개인 SSH 키.\n\n4. TLS 인증서: 안전한 HTTPS 연결 설정에 사용되는 인증서.\n\n- 예시: 웹 서버용 SSL/TLS 인증서.\n\n5. OAuth 토큰: OAuth 흐름에서 권한 부여에 사용되는 토큰.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 예시: GitHub 또는 Google과 같은 타사 API에 액세스 토큰입니다.\n\n7. Docker 레지스트리 자격 증명: 개인 Docker 레지스트리에 액세스하기 위한 자격 증명입니다.\n\n- 예시: Docker Hub 또는 기타 컨테이너 레지스트리의 사용자 이름과 비밀번호입니다.\n\n8. 암호화 키: 데이터를 암호화하고 해독하는 데 사용되는 키입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 예시: 데이터를 안전하게 보관하기 위해 사용되는 AES 암호화 키.\n\n# 쿠버네티스에서 Secrets 사용법:\n\n- 환경 변수: Secrets는 컨테이너 내에서 환경 변수로 노출될 수 있습니다.\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: mypod\nspec:\n  containers:\n    - name: mycontainer\n      image: myimage\n      env:\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: db_password\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 볼륨 마운트: 시크릿은 컨테이너 내에서 파일로 마운트될 수 있어요.\n\n```js\napiVersion: v1\nkind: Pod\nmetadata:\n  name: mypod\nspec:\n  containers:\n  - name: mycontainer\n    image: myimage\n    volumeMounts:\n    - name: secret-volume\n      mountPath: \"/etc/secrets\"\n  volumes:\n  - name: secret-volume\n    secret:\n      secretName: mysecret\n```\n\n# 쿠버네티스 시크릿의 암호화 유형:\n\n- 암호화 철자: 무엇을 의미하며 왜 중요한지 설명합니다.\n- 전송 중 암호화: 시크릿이 전송 중에 암호화되도록 보장하는 방법에 간단히 언급합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 암호화 구성 파일 만들기:\n\n이 파일은 암호화 공급자와 암호화에 사용되는 키를 지정합니다.\n\n```js\napiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n  - resources:\n    - secrets\n    providers:\n    - aescbc:\n        keys:\n        - name: key1\n          secret: \u003cbase64-encoded-secret\u003e\n    - identity: {}\n```\n\n# Encryption Key 생성하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n256비트 암호화 키를 Base64로 인코딩하세요. 다양한 도구를 사용하여 이 작업을 수행할 수 있습니다. OpenSSL을 사용하여 다음과 같이 수행할 수 있습니다:\n\n```js\nhead -c 32 /dev/urandom | base64\n```\n\n생성된 키로 구성 파일에서 `base64-encoded-secret`을(를) 교체하세요.\n\n# 암호화 구성 적용하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAPI 서버 Manifest 파일을 수정해야 합니다. 일반적으로 /etc/kubernetes/manifests/kube-apiserver.yaml 경로에 위치합니다. 다음과 같이 API 서버 Manifest 파일을 수정해주세요.\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-apiserver\n  namespace: kube-system\nspec:\n  containers:\n    - name: kube-apiserver\n      command:\n        - kube-apiserver\n        # 다른 플래그들...\n        - --encryption-provider-config=/path/to/encryption-config.yaml\n```\n\n암호화 구성 파일이 모든 제어 평면 노드의 지정된 경로에서 액세스 가능한지 확인해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# API 서버 재시작:\n\nAPI 서버는 새 구성을 적용하고 비밀을 안전하게 암호화하기 시작할 것입니다.\n\n# 암호화 확인:\n\n비밀이 정상적으로 암호화되고 있는지 확인하려면:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 테스트 비밀 정보 만들기:\n\n```js\nkubectl create secret generic test-secret --from-literal=key1=supersecret\n```\n\n- etcd 확인: etcd 데이터에 직접 액세스하시면서 (일반적으로 프로덕션에서 피해야 하는 직접적인 etcd 쿼리를 수행하므로 주의하세요). 데이터가 암호화되어 있는지 확인하기 위해 etcdctl 도구를 사용하세요.\n\n```js\nETCDCTL_API=3 etcdctl get /registry/secrets/default/test-secret --prefix --key-file=\u003cpath-to-key-file\u003e --cert-file=\u003cpath-to-cert-file\u003e --cacert=\u003cpath-to-ca-cert\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 암호화 키 회전:\n\n보안을 강화하기 위해 주기적으로 암호화 키를 회전하세요.\n\n- 새 키 추가: 새 키를 목록 상단에 업데이트된 암호화 구성 파일에 추가하세요.\n- 비밀 정보 재암호화: 새 키로 모든 비밀 정보를 재암호화하세요.\n\n```js\nkubectl get secrets --all-namespaces -o json | kubectl replace -f -\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이전 키 제거: 모든 비밀을 재암호화한 후, 구성에서 이전 키를 제거하십시오.\n\n# Kubernetes Secrets을 암호화하는 것은 클러스터 내의 민감한 데이터를 안전하게 보호하는 데 중요합니다. Kubernetes Secrets를 암호화하는 다양한 방법은 다음과 같습니다:\n\n## 1. 내장된 메커니즘을 사용하여 정지 상태의 Secrets 암호화\n\nKubernetes은 정지 상태의 Secrets를 암호화하는 내장 지원을 제공합니다. 이는 가장 간단한 방법이며 API 서버를 암호화 제공자로 구성하는 것이 포함됩니다. 이것이 수행하는 방법은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 단계:\n\n- 암호화 구성 파일 만들기:\n\n```js\napiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n- resources:\n  - secrets\n  providers:\n  - aescbc:\n      keys:\n      - name: key1\n        secret: \u003cbase64-encoded-key\u003e\n  - identity: {}\n```\n\n2. API 서버에서 암호화 구성 지정: kube-apiserver 매니페스트를 편집하십시오 (보통 /etc/kubernetes/manifests/kube-apiserver.yaml에 위치함).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```plaintext\n--encryption-provider-config=/path/to/encryption-config.yaml\n```\n\n3. API 서버 재시작: 매니페스트를 업데이트한 후에는 kube-apiserver가 자동으로 재시작되어 비밀을 암호화하기 시작합니다.\n\n## 2. 외부 키 관리 서비스(KMS) 사용\n\n보안을 강화하기 위해 Kubernetes는 AWS KMS, Google Cloud KMS 또는 HashiCorp Vault와 같은 외부 키 관리 서비스와 통합할 수 있습니다. 이 방법을 사용하면 Kubernetes가 외부 시스템을 사용하여 키 관리를 수행할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 단계:\n\n- KMS 프로바이더 구성:\n\n  - AWS KMS의 경우: AWS KMS 프로바이더 플러그인을 사용하고 암호화 구성 파일을 해당대로 구성합니다.\n  - Google Cloud KMS의 경우: GCP KMS 프로바이더 플러그인을 사용하고 암호화 구성 파일을 구성합니다.\n  - HashiCorp Vault의 경우: Vault를 구성하여 키를 관리하고 Vault 프로바이더를 설정합니다.\n\n2. Encryption Configuration 파일 업데이트:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\napiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n  - resources:\n      - secrets\n    providers:\n      - kms:\n          name: \u003cprovider-name\u003e\n          endpoint: \u003ckms-endpoint\u003e\n          cachesize: 1000\n      - identity: {}\n```\n\n3. API 서버 구성 업데이트:\n\n```bash\n--encryption-provider-config=/path/to/encryption-config.yaml\n```\n\n4. API 서버 재시작: API 서버가 새 구성을 사용하도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3. 커스텀 암호화 제공자를 사용하여 시크릿 암호화\n\n더 많은 제어를 필요로 하는 경우, 커스텀 암호화 제공자를 구현할 수 있습니다. 이 방법은 커스텀 암호화 플러그인을 작성하고 배포하는 과정을 포함합니다.\n\n## 단계:\n\n- 커스텀 프로바이더 개발: 요구 사항에 기반하여 암호화 및 복호화 로직을 구현합니다.\n- 커스텀 프로바이더 배포: 커스텀 프로바이더가 API 서버에서 접근 가능하도록 합니다.\n- 암호화 구성 설정:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\napiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n  - resources:\n      - secrets\n    providers:\n      - custom:\n          name: \u003ccustom-provider-name\u003e\n          endpoint: \u003ccustom-provider-endpoint\u003e\n      - identity: {}\n```\n\n4. API 서버 업데이트:\n\n```bash\n--encryption-provider-config=/path/to/encryption-config.yaml\n```\n\n5. API 서버 재시작: 구성 변경을 적용하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 4. 응용 프로그램 수준에서 비밀을 암호화하는 방법\n\n데이터를 안전하게 보관하기 위해 데이터를 안전하게 저장하는 대신 또는 그 외에 데이터를 Kubernetes Secrets에 저장하기 전에 응용 프로그램 수준에서 데이터를 암호화할 수 있습니다. 이 방법은 응용 프로그램이 암호화 및 복호화를 처리해야 합니다.\n\n## 단계:\n\n- 응용 프로그램에서 암호화 구현: Kubernetes Secret을 만들기 전에 민감한 데이터를 암호화하는 라이브러리나 도구를 사용합니다.\n- Kubernetes Secret으로 암호화된 데이터 저장: Secret에 저장된 데이터는 이미 암호화되어 있습니다.\n- 응용 프로그램에서 데이터 복호화: 응용 프로그램이 Secret을 검색할 때 데이터를 사용하기 전에 데이터를 복호화해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 5. Sealed Secrets 사용하기\n\nSealed Secrets는 비트나미에서 개발한 프로젝트로, Git 저장소에 암호화된 비밀을 저장할 수 있게 해줍니다.\n\n## 단계:\n\n- kubeseal 설치: kubeseal CLI 도구를 설치합니다.\n- Secret 암호화: kubeseal을 사용하여 쿠버네티스 Secret에서 SealedSecret을 생성합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nkubectl create secret generic mysecret --from-literal=username=myuser --from-literal=password=mypass -o yaml --dry-run=client \u003e mysecret.yaml\nkubeseal \u003c mysecret.yaml \u003e mysealedsecret.yaml\n```\n\n3. SealedSecret 적용: SealedSecret 매니페스트를 클러스터에 적용합니다.\n\n```js\nkubectl apply -f mysealedsecret.yaml\n```\n\n4. 런타임에서 Controller 복호화: 클러스터의 Sealed Secrets 컨트롤러가 시크릿을 복호화하고 실제 시크릿 리소스를 생성합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 6. SOPS(비밀 작업) 사용하기\n\nSOPS는 Kubernetes 시크릿 매니페스트를 암호화하는 데 사용할 수 있는 도구입니다.\n\n## 단계:\n\n- SOPS 설치: SOPS CLI 도구를 설치합니다.\n- 시크릿 매니페스트 암호화: Kubernetes 시크릿 매니페스트를 작성하고 SOPS를 사용하여 암호화합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nsops --encrypt --kms arn:aws:kms:region:account-id:key/key-id secret.yaml \u003e encrypted-secret.yaml\n```\n\n3. Apply the Encrypted Secret: 클러스터에 암호화된 매니페스트를 적용하세요.\n\n```js\nkubectl apply -f encrypted-secret.yaml\n```\n\n4. Decrypt at Runtime: CI/CD 파이프라인이나 애플리케이션 로직 내에서 런타임에 시크릿을 복호화하는 데 SOPS를 사용하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 방법들은 귀하의 인프라 및 보안 요구사항에 따라 다양한 수준의 보안과 유연성을 제공합니다. Kubernetes Secrets에 대한 암호화를 구현하면, 클러스터 내에서 민감한 데이터가 수명 주기 전체에 걸쳐 보호되도록 할 수 있습니다.\n\n# 이 안내서가 도움이 되었다면 👏 버튼을 클릭해주세요.\n\n더 많은 학습을 위해 팔로우 해주세요 😊\n\n특정 주제에 궁금한 점이 있으시면, 개인적인 메모나 댓글을 남겨주세요. 궁금해하는 내용을 탐험하는 데 도움을 드리겠습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 소중한 시간을 내어 지식을 향상시키기 위해 노력하셔서 감사합니다!\n","ogImage":{"url":"/assets/img/2024-05-20-HowtoEncryptKubernetesSecrets_0.png"},"coverImage":"/assets/img/2024-05-20-HowtoEncryptKubernetesSecrets_0.png","tag":["Tech"],"readingTime":15},{"title":"2024년 게임 업계의 지속적인 리소그린드에 대해 무슨 일이 일어나고 있을까요","description":"","date":"2024-05-20 16:40","slug":"2024-05-20-Whatsupwiththeconstantgaminglayoffsin2024","content":"\n![이미지](/assets/img/2024-05-20-Whatsupwiththeconstantgaminglayoffsin2024_0.png)\n\n2027년까지 게임 산업은 2820억 달러에 달하는 가치를 가질 예정입니다. 그런데 주요 게임 배급사들에서 지속적으로 보고되는 대규모 인원 감축에 뭐가 일어나고 있는 건지요?\n\n소니가 최근 많은 직원들을 대대적으로 해고한 최신의 게임 거대기업이 되었습니다. 이번 주에 900명의 직원이 해고되었는데, 소니는 놓친 판매 목표와 주식 가격 100억 달러의 급락을 해고의 동기로 지목했습니다.\n\n그 전에 EA, Microsoft, Epic, Sega, 그리고 Twitch는 2023년 동안 총 10,500명의 직원들을 해고한 적이 있었다고 신뢰할 수 있는 인원 감축 추적기에 따르면. 2024년 시작 90일이 되자 이미 이 숫자는 6,000명의 직원에 도달했고, 위기라는 단어가 분석가들 사이에서 등장하기 시작했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n보드 게임이 대유행하면서 팬데믹으로 인한 외출 자제의 이유가 줄어들었다기보다 게임 업계 리더들은 게임이 팬데믹 기간 동안 눈부신 성공을 거두어 이 상황에 이르게 된 것이라는 데에 일치한다는 점에 동의하는 경향이 있습니다.\n\n잠정사이 극에 차 있던 외로운 사람들이 문닫혀 게임으로 회피하면서 경이로운 참여 수준은 다음 몇 년 동안 업계 성장에 대한 비현실적인 예상을 지원하기로 알려졌습니다.\n\n그러나 사로잡힌 관객이 없으면 축출했던 수익 예상에 비해 출판사 고용 폭발로 인한 무거운 급여 지급은 지속하기 어려워졌습니다. 당시에는 잠재적인 후퇴에 대비한 경계 조치가 없는 낙관적인 숫자였다고 돌아보면 그림자가 된다.\n\n몇 년이 지난 지금, 게임 사업 관계자들에게 현실은 그리 유치하지 않습니다. 2023년 게임 투자가 주요한 최저점을 기록했으며, 소니는 PS5 판매 대상을 크게 미달했으며, 미국의 수익은 4% 감소한 것으로 알려져 있습니다 — 무한한 이익이 기대되었던 것과는 크게 달라진 결과입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"‘이제는 믿기 힘들지만, 당시 문화적 대화는 이러한 이익이 계속 유지될 것이라는 믿음에 의해 주도되었다’고 컴퓨터 산업 교수 레인 누니가 설명했습니다.\n\n‘팬데믹 기간 동안 이러한 급증에 대한 많은 미디어 관심은 스트리밍 시간이나 벌어들인 돈에 대한뿐만 아니라 모든 이것이 계속될 것이라는 집단 착각에 기여했다’고 그는 말했습니다.\n\n현실이 여러 해 뒤에 조금씩 드러나기 시작할 때 AAA 및 인디 개발자들은 재무를 균형잡는 빠르고 효과적인 수단으로 직원을 줄이고 있습니다. 지난 달만에 Microsoft가 Activision Blizzard 직원 1,900명을 해고하고 Discord가 직원의 17%를 해고하며 Unity가 전체 직원의 1/4를 해고했습니다.\n\n이 지점에 이르게 한 것은 지나치게 많은 인원 채용 뿐만 아니라, 충분하지 않은 점도 있습니다. 게임 발행사들에게는 항상 직원이 일회용으로 여겨졌으며, 게임 업계에서 오랫동안 활동한 대다수는 프로젝트마다 살아남기 위해 뛰놀며, 실제 고용 안정성이 전혀 없는 삶에 익숙할 것입니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비용이 품질이 향상된 제품에 대한 수요로 인해 뛰어오르면 벤처 자본이 신중한 투자자들로부터 소진되거나 새로운 기술 트렌드가 예상치 못하게 실패할 때 — 아니, 클라우드 게임 — 중복은 최고 관리자들에게 탈출구로 여겨집니다.\n\n2024년의 산업 현장에서는 위에 열거한 모든 것과 맞닥뜨린다고 합니다. 특히, 대출을 위한 상승하는 이자율과 운영 자금 조달을 위해 롤링 부채를 사용함이 경제적으로 도전적이라고 할 수 있습니다. 인플레이션은 모두에게 영향을 미칩니다.\n\n업계의 용서하지 않는 성격의 대표적 사례가 현재 진행 중이기도 합니다. 10년에 걸친 개발 노력 끝에 유비소프트의 '첫 번째 AAAA 게임'으로 소개되었던 Skull and Bones는 이미 무자비한 2억 달러의 비용에 제대로 미쳐하지 못할 운명입니다.\n\n리뷰 사이트에서 주어진 지루한 평가로 인해 출시된 이번 실패작은 이전의 해적 게임인 Assassin's Creed: Black Flag와 Sea of Thieves에 대한 관심을 다시 불러일으키기만 했습니다. 심지어 Assassin's Creed 같은 사랑받는 시리즈에 추가 요소를 넣어도 성공을 보장할 수 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다시 넓은 시야를 가져오면, 게임 배급사들로부터 갑자기 해고를 당한 사람들을 위해 격려하는 기초적 노력들이 있습니다.\n\n일자리를 구하는 데 많은 경쟁이 있더라도 산업 내 선한 사람들은 새로운 고용주들과 개발자들을 연결하는 포럼 및 소셜 미디어 페이지를 운영하고 있습니다. Amir Satvat의 '구직자 워크북'과 전용 LinkedIn 페이지는 커뮤니티에 큰 도움이 되고 있습니다.\n\n더 나아가, 점차 증가하는 개발자들의 단결이 게임 업계의 고용 및 해고에 대한 주기적인 태도를 개선하기 위한 희망으로 결성되고 있습니다. 어제 소니에서 대규모 퇴사가 이뤄졌기 때문에 이 분야에서의 노력들은 의심할 여지가 없이 가속화될 것입니다.\n\n최종적으로 소비자들로부터 더 많은 주의를 받을 필요가 있는 것이 아닌지, 이런 식의 '지도자들의 결정'을 고려해 볼 때가 아닌지도 모릅니다. 게임의 생명줄로써, 이러한 실천 방식은 허용 가능하거나 당연한 것으로 여겨질 수 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제이미 왷츠가 Thred를 위해 작성했습니다.\n","ogImage":{"url":"/assets/img/2024-05-20-Whatsupwiththeconstantgaminglayoffsin2024_0.png"},"coverImage":"/assets/img/2024-05-20-Whatsupwiththeconstantgaminglayoffsin2024_0.png","tag":["Tech"],"readingTime":4}],"page":"90","totalPageCount":119,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"90"},"buildId":"GsgRekSb--BvxYwv9FPn6","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>