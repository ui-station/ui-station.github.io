<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/43" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/43" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/PgdIX9e0tvkvkdAmDT6qR/_buildManifest.js" defer=""></script><script src="/_next/static/PgdIX9e0tvkvkdAmDT6qR/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="AI와 가정 자동화 편의성, 안전 및 에너지 효율 향상" href="/post/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI와 가정 자동화 편의성, 안전 및 에너지 효율 향상" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI와 가정 자동화 편의성, 안전 및 에너지 효율 향상" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AI와 가정 자동화 편의성, 안전 및 에너지 효율 향상</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="지금 기술 세계에서 일어나고 있는 가장 어리석은 프로젝트" href="/post/2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="지금 기술 세계에서 일어나고 있는 가장 어리석은 프로젝트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="지금 기술 세계에서 일어나고 있는 가장 어리석은 프로젝트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">지금 기술 세계에서 일어나고 있는 가장 어리석은 프로젝트</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리파이를 와이파이 라우터로 변신해보세요" href="/post/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리파이를 와이파이 라우터로 변신해보세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리파이를 와이파이 라우터로 변신해보세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">라즈베리파이를 와이파이 라우터로 변신해보세요</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="나의 여정과 트리스트럼 샨디 역설" href="/post/2024-05-18-MyJourneyandtheTristramShandyParadox"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="나의 여정과 트리스트럼 샨디 역설" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MyJourneyandtheTristramShandyParadox_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="나의 여정과 트리스트럼 샨디 역설" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">나의 여정과 트리스트럼 샨디 역설</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정" href="/post/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="메이테이어 언어의 기계 번역 앱 및 웹 페이지" href="/post/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="메이테이어 언어의 기계 번역 앱 및 웹 페이지" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="메이테이어 언어의 기계 번역 앱 및 웹 페이지" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">메이테이어 언어의 기계 번역 앱 및 웹 페이지</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요" href="/post/2024-05-18-DataEngineeringisforEngineersNOT"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" href="/post/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">32<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" href="/post/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" href="/post/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">19<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link posts_-active__YVJEi" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"AI와 가정 자동화 편의성, 안전 및 에너지 효율 향상","description":"","date":"2024-05-18 18:36","slug":"2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY","content":"\n\n## AI-POWERED SMART HOMES: THE FUTURE OF LIVING IS HERE\n\n![image](/assets/img/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY_0.png)\n\nIn recent years, the integration of Artificial Intelligence (AI) with home automation technologies has revolutionized the way we live. Smart homes, powered by AI, offer unprecedented levels of convenience, safety, and energy efficiency. This article delves into the various smart home technologies driven by AI and explores the myriad benefits they bring to modern living.\n\nConvenience: Simplifying Everyday Life\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 파워가 장착된 가정 자동화 시스템은 루틴 작업을 자동화하고 가정 기기를 원활하게 제어함으로써 우리의 삶을 더 편리하게 만들기 위해 설계되었습니다.\n\n스마트 어시스턴트\n아마존 알렉사, 구글 어시스턴트, 애플의 시리와 같은 기기들은 가정 자동화의 중앙 허브로 자리 잡았습니다. 이러한 AI 기반 어시스턴트는 사용자가 간편한 음성 명령을 통해 조명, 온도 조절기, 잠금장치 등을 제어할 수 있도록 해줍니다. 예를 들어, 침대에 누웠을 때 알렉사에게 조명을 끄도록 요청하거나, 소파를 떠나지 않고 온도 조절기를 조정할 수 있습니다.\n\n자동 일정 설정\nAI 시스템은 사용자의 선호도와 루틴을 학습하여 작업을 자동화합니다. 예를 들어, Nest Learning Thermostat과 같은 스마트 온도 조절기는 사용자의 일정에 맞게 적응하여 하루 내내 최적 수준의 온도로 조절되어 수동 개입 없이도 운영됩니다. 마찬가지로, 스마트 조명 시스템은 자연광 수준 및 일일 패턴에 따라 조절할 수 있습니다.\n\n안전: 가정과 사랑하는 사람 보호\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI는 고급 모니터링, 실시간 경고 및 지능적인 분석을 통해 주거 보안을 강화합니다.\n\n![AI와 홈 자동화가 편의, 안전 및 에너지 효율성을 증진하는 이미지](/assets/img/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY_1.png)\n\n**스마트 보안 카메라**\nRing 및 Nest 등의 AI 기반 보안 카메라는 움직임 감지, 얼굴 인식 및 실시간 알림과 같은 기능을 제공합니다. 이러한 카메라는 사람, 동물 또는 물체를 구별할 수 있어 오진 경보를 줄이고 잠재적 침입자에 대한 정확한 경고를 제공할 수 있습니다.\n\n**지능형 도어벨**\nRing Video Doorbell과 같은 AI가 장착된 스마트 도어벨은 주택 소유주가 스마트폰을 통해 원격으로 방문객을 보고 듣고 말할 수 있도록 합니다. 이 장치는 익숙한 얼굴을 인식하고, 생소한 사람이 문 앞에 있을 때 알려줄 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n응급 감지 시스템\nAI 기술을 활용한 연기 감지기와 누출 센서는 화재와 물 누수에 대한 조기 경보를 제공합니다. Nest Protect 연기 감지기와 같은 이 장치는 폰으로 경고를 보내고 화재나 수해로의 전파를 막기 위해 HVAC 시스템과 같은 연결된 장치를 자동으로 차단할 수 있습니다.\n\n에너지 효율성: 소비와 비용 절감\n\n![이미지](/assets/img/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY_2.png)\n\nAI 기술을 활용한 스마트 홈 기술은 에너지 절약에 크게 기여하여 유틸리티 요금을 낮추고 탄소 발자국을 줄이는데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스마트 서모스탯\nAI 기술을 활용한 서모스탯은 당신의 일정과 선호도를 학습하여 에너지 소비를 줄이기 위해 난방 및 냉방을 최적화합니다. Ecobee SmartThermostat과 같은 장치는 센서와 AI 알고리즘을 사용하여 집에 없을 때 에너지를 낭비하지 않으면서 편안함을 유지합니다.\n\n지능형 조명\nPhilips Hue와 같은 스마트 조명 시스템은 낮과 밤, 인원 유무 및 자연광 수준에 따라 밝기와 색상을 조절합니다. AI는 비사용 중인 공간의 조명을 끄는 등 에너지를 더욱 절약할 수 있습니다.\n\n에너지 모니터링 시스템\n가정용 에너지 관리 시스템(HEMS)은 AI를 활용하여 장치 간 에너지 사용량을 모니터링하고 분석합니다. Sense와 같은 시스템은 어떤 가전제품이 가장 많은 전력을 소비하는지 식별하여 에너지 효율성을 향상시키기 위한 통찰력과 권고 사항을 제공할 수 있습니다.\n\n마무리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI를 활용한 가정 자동화 기술은 우리 집을 지능적이고 반응적인 환경으로 변화시키며 편의성을 향상시키고 안전성을 높이며 에너지 효율을 증진시키고 있습니다. 이러한 기술이 계속 발전함에 따라 스마트 홈의 미래는 더 큰 혁신을 약속하며, 우리의 삶을 더 편안하고 안전하며 지속 가능하게 만들어 줄 것입니다. AI를 가정 자동화에 적용함으로써 일상적인 작업을 단순화하는 뿐만 아니라 더 효율적이고 안전한 생활 공간을 조성하는 데 기여합니다.\n\n![이미지](/assets/img/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY_3.png)\n\n#AI #가정자동화 #스마트홈 #편의 #안전 #에너지효율 #스마트기기 #IoT #홈보안 #에너지관리 #스마트조명 #음성비서 #홈모니터링 #자동화된생활 #가정을위한기술 #SandraKoh #NovelleCollagen\n\nBK 한\n사라의 헬시파이\n팜씨/플라잉맘\n고희연 (Epigenneur)\n타잇 렝 앙\n안젤라 두","ogImage":{"url":"/assets/img/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY_0.png"},"coverImage":"/assets/img/2024-05-18-AIANDHOMEAUTOMATIONENHANCINGCONVENIENCESAFETYANDENERGYEFFICIENCY_0.png","tag":["Tech"],"readingTime":4},{"title":"지금 기술 세계에서 일어나고 있는 가장 어리석은 프로젝트","description":"","date":"2024-05-18 18:35","slug":"2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow","content":"\n\n![2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow_0](/assets/img/2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow_0.png)\n\n작년 동안 우리는 수많은 AI 프로젝트가 등장하고 있다는 것을 목격했습니다. 물론, OpenAI의 ChatGPT가 있죠. 그 다음으로는 Claude, Anthropic, Google의 Bard 등의 사본들이 있습니다. 마지막으로, Replika나 Meta가 요즘 무엇을 하고 있는지와 같은 이상한 것들이 있습니다. 현재까지 모두가 \"오래된\" 노트북과 모바일 기기에서 작동하는 디지털 제품들로, 조금 지루한 것 같네요.\n\n인류는 AI와 물리 세계에서 상호 작용하기 위해 전용 하드웨어를 구축하기 시작할 때 진정한 혁신을 볼 것입니다. 우리는 모든 것을 아는 신을 만들었으니, 이제는 그들에게 물리적인 형태를 줘야 합니다. 최종 형태가 우리의 형상일 것임을 알지만 (어떤 iRobot?), 그 이전에는 무엇이 올까요? 이미 많이 쓰여진 Humane의 700불짜리 \"Pin\"? Meta의 스마트 안경? Johny Hive와 OpenAI가 지금 10억 달러 투자금으로 작업 중인 무엇이든? 무엇이든, 사실, 그것이 Rewind 펜던트처럼 보일 일은 없다는 것을 알고 있습니다.\n\n# Rewind Pendant: 현재 기술 세계에서 일어나는 가장 어리석은 프로젝트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRewind은 현재 소프트웨어를 판매하고 있는 회사입니다. 이 소프트웨어는 노트북에서 보거나 듣거나 말하는 모든 것을 기록합니다. 2023년 10월, 그들의 CEO는 The Pendant를 출시한다고 발표했습니다. 이는 검은 실린더가 달린 작은 목걸이로, 내부에는 마이크가 달려 있습니다. 핵심 원칙은 간단합니다. The Pendant는 모든 대화를 기록하고, 전사하고, 암호화한 후, 사용자의 핸드폰에 저장하여 사용자가 지금까지 한 모든 대화를 검토할 수 있게 합니다.\n\n완벽한 기억. 당신의 손끝에서.\n\n녹음기를 만드는 것은 어렵지 않습니다. 그래서 Pendant는 선주문 가격으로 60달러에만 판매됩니다. 새로운 점은 사용자를 위해 데이터를 효율적으로 저장하고 검색하고 되새겨주는 앱과 연결된 AI 기술입니다.\n\n많은 분들이 눈치채셨을 것이지만, 이는 말 그대로 로우테크 블랙 미러 에피소드입니다. \"The Entire History of You\"에서는 \"Grains\"가 생물학적으로 사람들이 보고 듣는 모든 것을 기록하고, \"The Pendant\"는 마이크를 통해 대화를 기록합니다. 그리고 \"Grains\"가 개인이 기억을 완벽하게 다시 보는 것을 허용하는 반면, \"The Pendant\"는 그저 대화를 전사하고 저장하여 나중에 검토할 수 있도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow_1.png\" /\u003e\n\n우리가 일단 본론으로 들어가 봅시다. The Pendant는 디스트피아식 악몽입니다. 누구나 언제 어디서나 모든 말을 녹음할 수 있는 능력(중요한 것은 쉽게 다시 찾을 수 있다는 것)은 동의, 개인 정보 침해 및 이러한 녹음의 잠재적 남용에 대해 많은 의문을 제기합니다.\n\n누군가가 The Pendant를 착용하고 기업 파티에 참석하는 상황을 상상해보십시오. 다른 참가자들이 알지 못하는 사이 The Pendant는 행사 중에 이야기되는 모든 말을 녹음하고 있습니다. 그 다음 날, The Pendant 착용자는 악의를 품은 제3자들과 정확한 대화들을 전달할 수 있습니다. 그 대화에는 민감한 비즈니스 전략, 독점 정보 또는 귀여운 소문이 포함될 수 있습니다. 이 시나리오는 해킹이나 더 나쁜 상황으로 인해 제3자가 녹음물에 무단으로 접근하는 경우 훨씬 더 놀라운 것이 됩니다(리와인드는 공식 소환에 따라 협조할 것이라고 말합니다).\n\n이를 생각해보세요. 우리가 하는 말 중 상당수는 녹음되고 어떻게든 누출되면 좋지 않을 것입니다. 풍문의 세계는 사실상 사라질 것입니다. 누구도 신뢰받지 못할 것이며 왜냐하면 모두가 선을 착용하고 있을 것이기 때문입니다. 또는 chatGPT가 말했듯이, \"The Pendant는 모든 대화가 저장되어 세밀하게 조사될 수 있기 때문에 신뢰와 의사소통의 역학을 바꿀 수 있습니다.\" 이 모든 상황에서 유일하게 즐거운 결과는 사우나 회의가 크게 부활할 것이다는 것입니다; 개인 정보를 보장하기 위한 유일한 방법은 모두가 벗은 상태로 있음을 확인하는 것이 될 것입니다. 그것이 평등에 큰 도움이 될 것이라고 확신합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당연히, The Pendant 웹 사이트는 “우리는 개인 정보 보호를 최우선으로 하며, 다른 사람이 동의 없이 녹음되지 않도록하는 기능을 제공합니다.”라고 말합니다. 그러나 다른 내용은 작성되지 않았습니다. 더 자세한 설명이 없으면 이 명세는 가치가 없어집니다. 개인 정보 보호 문제를 해결하는 유일한 방법은 녹음을 위해 구두 동의가 필요하고, 고유한 음성 서명과 연결되어야 한다는 것입니다. 일부 알고리즘은 이를 수행할 수 있지만, 여러 질문들이 발생할 것입니다. 예를 들어, 동의가 없는 경우 얼마나 자주 그리고 빨리 녹음이 삭제되는지? 나중에 동의하고 대화를 검색할 수 있는가? 음성 서명은 어디에 저장되는가? 사람들의 목소리에 대한 딥페이크는 얼마나 정확한가? 작은 소프트웨어 회사에 대한 알아야 할 질문이 많이 있군요.\n\n내 말인데, 내 아기의 첫 말이 “AI 스타트업에서 내 데이터 사용에 동의합니다”가 됐으면 그것은 싫어요.\n\nThe Pendant는 생산성 도구로서 마케팅되고 있습니다. 일부 감정 노동을 줄이기 위해 사용할 수 있을 것으로 보입니다: 장보기 목록을 말로 말하기, 특히 중요한 대화 부분을 나중에 검토할 수 있도록 책갈피를 걸기, 회의록 기록하기… 등등. 하지만 저는 계속 의심스럽습니다.\n\n생산적이기 위한 큰 부분은 대화 뒤에 일어나는 사고입니다. 사실, 1시간 진행된 회의 후에 3가지 이상의 결론을 내기가 어려울 정도로 어려울 때도 있습니다. 전체 대화를 검토하는 대신 주요 인용구와 생각이 담긴 작은 노트북을 가지고 있는 것이 문제를 해결하고 생산성을 줄이는 것이 아닙니다. 전문적인 회의록 작성자를 믿어요, The Pendant는 사람들의 불안과 놓치고 있는 것을 두려워하고 있는 것을 이용하려는 것뿐이지만 실제로는 문제를 찾는 솔루션일 뿐입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 이 아이디어를 완전히 묻어버릴 또 다른 두 가지 이유가 있습니다:\n\n- 기억을 잊는 것은 좋은 일입니다. 사실, 우리 뇌는 종종 과거 사건들을 덜 고통스럽게 만들어 주어서 우리에게 친절을 베푸는 경우도 있습니다 (그 기억이 완전히 사라지지 않는 한). 챗봇이 \"내 결혼에서 잘못된 점은 무엇인가요?\"와 같은 영원한 질문에 정확한 답변을 제공할 수도 있지만... 우리는 그러한 정보를 원할까요?\n- 사람들이 기억 보존을 위해 점점 더 기술에 의존하면, 우리는 자연적인 기억 과정과 개인적인 경험의 전통적인 개념을 훼방할 수도 있습니다.\n\n미국 시민권 자유연합의 시니어 정책 분석가인 제이 스탠리는 최근 인터뷰에서 가장 적절하게 말했습니다: \"사람들은 자신이 들은 모든 것을 기록하면 자신이 가진 모든 기억처럼 엄청난 기억력을 갖게 되어 든든하게 느낄 수도 있지만, 실제로는 권력을 박탈당하고 역효과를 일으킬 수도 있습니다.\"\n\n오브, 스피어, 그리고 이제 펜던트까지. 우리가 어떻게해서 YA 소설 속으로 빨려 들어간 걸까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기술은 모든 것이 마찰을 줄이는 데 관한 것입니다. Spotify, Uber, Netflix... 대부분의 기업들보다 그것을 더 잘 해냈습니다. 하지만 때로는 삶 속에서 약간의 마찰이 건강하다고 느낄 때도 있습니다. 예를 들어, 주변 사람을 녹음하기 위해 주머니에서 iPhone을 꺼내는 행위는 우리에게 제일 큰 프라이버시 보호자가 될 수 있습니다.\n\n미래에는 기술이 마찰을 줄이는 데에 그치는 것이 아니라 세상 속에 존재하는 것에 더 중점을 두어야 한다고 믿습니다. 하드웨어가 최대한 언발하게 되고 우리가 현재 순간에 집중할 수 있도록 하는 데에 열망해야 합니다.\n\n이 펜던트는 그것을 이루지 않을 것입니다. 그리고 그 장비를 착용하는 사람은 사회적으로 냉대를 받을 것으로 예상합니다. 잘 가요. 번창하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사는 원본으로 wearedevelopers.com에 작성되었습니다. 유럽의 개발자 중심 취업 플랫폼입니다.\n\n# 한 가지 더\n\n내 글을 지원해 주시기 위해 댓글을 남겨주세요. 읽고 답변하는 걸 좋아해요! 단, 못된 댓글은 제 마음을 상하게 해요. 제 글을 놓치지 마세요. Medium이나 제 블로그에서 뉴스레터를 구독하시면 됩니다.","ogImage":{"url":"/assets/img/2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow_0.png"},"coverImage":"/assets/img/2024-05-18-TheDumbestProjecthappeningintheTechWorldrightnow_0.png","tag":["Tech"],"readingTime":5},{"title":"라즈베리파이를 와이파이 라우터로 변신해보세요","description":"","date":"2024-05-18 18:33","slug":"2024-05-18-TurnyourRaspberryPiintoaWiFiRouter","content":"\n\nRaspberry Pi를 무선 액세스 포인트로 설정하는 방법\n\n![이미지](/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_0.png)\n\nRaspberry Pi를 무선 액세스 포인트로 설정하는 방법을 보여 드리겠습니다. 기본적으로 다른 장치가 연결할 수 있는 무선 \"라우터\"로 Raspberry Pi를 변환하는 방법을 안내해 드리겠습니다. 이를 통해 생성된 무선 액세스 포인트를 설정하여 연결된 장치에 인터넷 액세스를 제공(공유)하는 방법도 안내해 드리겠습니다.\n\n![이미지](/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 이렇게 하였습니다\n\n라즈베리 파이 설정을 위한 링크에 들어가 보세요. 설정이 완료되면 라즈베리 파이로 Wi-Fi 핫스팟을 만들기 시작해 봅시다.\n\n# 단계 1:\n\n일반적으로 라즈베리 파이를 업데이트하여 최신 버전을 보유하도록 합니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nsudo apt-get update\nsudo apt-get upgrade\n\n\n# STEP-2:\n\n라즈베리 파이가 액세스 포인트로 작동하려면 액세스 포인트로 작동하기 위한 소프트웨어 패키지가 필요합니다.\n\n아래 명령어는 라즈베리 파이를 무선 액세스 포인트로 설정할 수 있게 해주는 소프트웨어를 설치하고, AP에 연결된 장치에 네트워크 주소를 할당하는 데 도움을 주는 소프트웨어를 설치합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo apt install hostapd\nsudo apt install dnsmasq\n```\n\n마지막으로, netfilter-persistent와 그 플러그인 iptables-persistent를 설치해주세요. 이 유틸리티는 방화벽 규칙을 저장하고 Raspberry Pi 부팅 시에 복원하는 데 도움이 됩니다.\n\n```js\nsudo DEBIAN_FRONTEND=noninteractive apt install -y netfilter-persistent iptables-persistent\n```\n\n다음 단계로 이동하기 전에 Raspberry Pi를 다시 부팅해주세요.\n  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```md\nsudo reboot\n```\n\n# STEP-3:\n\nRaspberry Pi는 독립 와이어리스 네트워크를 실행하고 관리합니다. 또한 와이어리스 및 이더넷 네트워크 간 경로를 제공하여 와이어리스 클라이언트에게 인터넷 액세스를 제공합니다. Raspberry Pi를 서버로 설정하기 위해서는 와이어리스 포트에 고정 IP 주소를 할당해야 합니다. 이 작업은 dhcpcd 구성 파일을 편집하여 수행할 수 있습니다. dhcpcd.conf 파일을 편집하려면 아래 명령을 실행하세요.\n\n```md\nsudo nano /etc/dhcpcd.conf\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\ndhcpcd.conf 파일 끝으로 이동하여 다음 라인들을 추가해주세요.\n\n```js\ninterface wlan0\n    static ip_address=192.168.4.1/24\n    nohook wpa_supplicant\n```\n\n![이미지](/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_2.png)\n\n# STEP-4:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라즈베리 파이에서 한 네트워크에서 다른 네트워크로 트래픽이 흐를 수 있도록 하려면 다음 명령을 사용하여 파일을 생성하고 아래 내용을 입력하세요:\n\n```js\nsudo nano /etc/sysctl.d/routed-ap.conf\n```\n\n파일 내용:\n\n```js\n# IPv4 라우팅 활성화\nnet.ipv4.ip_forward=1\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 경로를 추가하여 호스트가 네트워크 192.168.4.0/24로 LAN 및 인터넷으로 이동할 수 있도록하는 설정입니다.\n\n이 프로세스는 Raspberry Pi에 한 개의 방화벽 규칙을 추가하여 구성됩니다.\n\n```js\nsudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 현재 IPv4 및 IPv6 방화벽 규칙을 netfilter-persistent 서비스를 통해 부팅 시 로드할 수 있도록 다음 명령을 사용하여 저장하세요.\n\n```js\nsudo netfilter-persistent save\n```\n\n# 단계-5:\n\nDHCP 및 DNS 서비스는 dnsmasq에서 제공됩니다. 기본 구성 파일은 모든 가능한 구성 옵션의 템플릿 역할을 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기본 설정 파일의 이름을 변경하고 새 파일을 편집해보세요\n\n```js\nsudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig\nsudo nano /etc/dnsmasq.conf\n```\n\n다음을 파일에 추가하고 저장하세요,\n\n```js\ninterface=wlan0\ndhcp-range=192.168.4.2,192.168.4.20,255.255.255.0,24시간\ndomain=wlan\naddress=/gw.wlan/192.168.4.1\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 코드 블록 안에 있는 내용을 실행하여 라즈베리파이의 WiFi 라디오가 차단되지 않도록 할 수 있습니다:\n\n```js\nsudo rfkill unblock wlan\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 설정은 부팅 시 자동으로 복원됩니다. 액세스 포인트 소프트웨어 구성에서 적절한 국가 코드를 정의할 것입니다.\n\n# 단계-6:\n\n새로운 무선 네트워크를 위한 다양한 매개변수를 추가하기 위해 /etc/hostapd/hostapd.conf에 있는 호스팅 설정 파일을 만들어 주세요.\n\n```js\ncountry_code=IN\ninterface=wlan0\nssid=네트워크이름\nhw_mode=g\nchannel=7\nmacaddr_acl=0\nauth_algs=1\nignore_broadcast_ssid=0\nwpa=2\nwpa_passphrase=암호\nwpa_key_mgmt=WPA-PSK\nwpa_pairwise=TKIP\nrsn_pairwise=CCMP\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참고: `country_code`는 컴퓨터가 올바른 무선 주파수를 사용하도록 구성합니다. 두 글자 ISO 3166-1 국가 코드 목록은 위키피디아에서 확인할 수 있습니다.\n\n- SSID: 여러분의 SSID (제 경우 네트워크 이름)\n\n- PWD: 여러분의 비밀번호 (제 경우 비밀번호)\n\n![이미지](/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRaspberry Pi에 적용한 변경 사항을 적용하려면 시스템을 다시 시작하세요.\n\n```js\nsudo systemctl reboot\n```\n\n시스템이 다시 켜지면 Raspberry Pi에서 만든 무선 액세스 포인트에 연결하여 인터넷에 액세스할 수 있게 될 것입니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_6.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n읽어 주셔서 감사합니다. 피드백과 코멘트는 언제나 환영합니다.\n\n# GEEKY BAWA\n\n## 새로운 기술을 탐구하고 멋진 경험을 하는 것을 좋아하는 어리석은 Geek예요.\n\n# 다른 블로그도 재밌게 둘러보세요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 내 유튜브 채널도 한번 확인해보세요\n\n만약 연락하고 싶으시거나 좋은 농담을 알고 계시다면 트위터나 링크드인을 통해 연락해 주세요.\n\n독자 여러분 감사합니다!😄 🙌\n\n트위터와 링크드인에서 저와 소통해 보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 기사와 참고 자료를 확인하러 시간 내어보세요. 제 글을 알림받으려면 저를 팔로우해주세요.\n\n# Vaibhav Hariramani가 진심을 담아 제작했습니다.\n\n- 이 글을 즐기셨다면 미디엄에서 더 많은 글을 읽어보세요!\n- 더 많은 콘텐츠를 원하시면 캐글에서 저를 팔로우하세요!\n- 링크드인에서 연락해주세요.\n- 협업에 관심이 있으세요?\n- 제 웹사이트를 확인해보세요.\n- 다른 웹사이트도 함께 확인해보세요.\n\n# 저희를 태그하지 말고는 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이 블로그가 도움이 되었다면 친구들과 공유하고, 저희를 언급하는 것을 잊지 마세요. 그리고 Linkedin, Instagram, Facebook, Twitter, Github에서도 공유하는 것을 잊지 마세요.\n\n# 추가 자료\n\n이 자료들에 대해 더 배우고 싶다면 아래 나의 쓴 글들을 참고하세요:-\n\n- Medium\n- geeky Traveller\n- Blogs\n- Youtube\n- 이메일: vaibhav.hariramani01@gmail.com\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 더 바이브하브 하리라마니 앱 다운로드\n\n# 더 바이브하브 하리라마니 앱 (최신 버전)\n\n더 바이브하브 하리라마니 앱 다운로드는 안드로이드 스튜디오 및 웹 뷰로 개발된 사이트의 자습서, 프로젝트, 블로그 및 브이로그를 포함하고 있습니다. 안드로이드 기기에 설치해보세요.\n\n# 저를 팔로우해주세요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마크다운 형식으로 테이블 태그를 변경해주세요.\n\n| Linkedin | Instagram | Facebook | Twitter | Github |\n|---------|-----------|---------|-------|--------|\n| Happy coding ❤️ |","ogImage":{"url":"/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_0.png"},"coverImage":"/assets/img/2024-05-18-TurnyourRaspberryPiintoaWiFiRouter_0.png","tag":["Tech"],"readingTime":6},{"title":"나의 여정과 트리스트럼 샨디 역설","description":"","date":"2024-05-18 18:32","slug":"2024-05-18-MyJourneyandtheTristramShandyParadox","content":"\n\n18세기 소설인 로렌스 스턴의 \"The Life and Opinions of Tristram Shandy, Gentleman\"은 자신의 삶의 모든 세부사항을 기록하려고 노력하는 남자를 다룹니다. 사건에 대해 쓰는 데 인생을 살아가는 것보다 더 많은 시간이 걸려 뒤처지기 시작하며, 절대 완료될 수 없는 계속 커지는 백로그를 만들어 냅니다.\n\n익숙하게 느껴지나요?\n\n![이미지](/assets/img/2024-05-18-MyJourneyandtheTristramShandyParadox_0.png)\n\n트리스트럼 샨디로서 쓴 로렌스 스턴은 이 역설을 뛰어난 방식으로 포착해 냈습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 내 이야기는 어떤 연관이 있을까?\n\n인터넷은 항상 변화하는데, 새로운 정보, 트렌드, 그리고 도구가 매일 등장합니다. 팽팽하게 채워 나가고 있는 테이블 태그를 마크다운 포맷으로 바꾸려면 어떻게 해야 할까요?\n\n트리스트럼 샨디와 같이, 저는 모든 것을 문서화하려고 노력했지만 쓰면 쓸수록 더 많은 내용이 채워져 가는 것 같아요.\n\n시간은 흘러가고 있는데 들어오는 일이 나가는 일보다 많아요. 항상 위기를 감지하고 있는 것 같은데, 결국 표면만 긁어 본 것 같다는 것을 깨닫게 돼요.\n\n진전을 이루려고 하지만 찾고, 정리하고, 다시 시도하는 사이클에 갇힌 쥐처럼 느껴지네요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n트리스트럼 샌디는 자신의 삶을 문서화하는 데 압도됐다. 시간이 글을 쓰는 속도보다 더 빨리 흘러가기 때문에 따라잡기 불가능하다는 것을 알았다.\n\n인터넷을 연구하고 정리하려는 것도 똑같은 느낌이다.\n\n![이미지](/assets/img/2024-05-18-MyJourneyandtheTristramShandyParadox_1.png)\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 이야기는 지속적인 변화의 도전을 보여줍니다.\n\n트리스트럼 샨디(Tristram Shandy)에게는 인생을 문서화하기에 시간이 빠르게 지나갔습니다. 저에게는 온라인 정보를 계속해서 따라가려는 것도 마찬가지죠.\n\n두 가지 모두 불가능한 일이죠.\n\n이젠 끝없는 데이터를 조직하고 수집하는 것을 멈추고, 그것을 효과적으로 활용하는 방향으로 나아가 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당신도 이 사이클에 갇혔나요? 트리스트럼 샌디 패러독스가 당신에게 공감되는지 궁금해요.\n\n저와 소통하고 싶다면 가입해주세요!","ogImage":{"url":"/assets/img/2024-05-18-MyJourneyandtheTristramShandyParadox_0.png"},"coverImage":"/assets/img/2024-05-18-MyJourneyandtheTristramShandyParadox_0.png","tag":["Tech"],"readingTime":2},{"title":"MRS Technologies 2023 하계 인턴십 프로그램 - 포괄적인 여정","description":"","date":"2024-05-18 18:30","slug":"2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney","content":"\n\n기술 분야에서 인턴십은 청년들을 전문가 생활로 이끄는 발판입니다. 그러나 대부분의 인턴들은 기초 프로젝트에 갇혀 실제 세계에서의 경험을 놓치곤 합니다. 이 추세와는 달리, MRS Technologies는 작년에 다른 길을 선택하여 2022년도 인턴십 프로그램을 통해 풍부한 학습 기회를 제공했습니다. 인턴들은 실무 경험을 쌓고 최소 실현 가능 제품(MVP)을 선정하는데 주도적 역할을 하였습니다. 이 접근 방식은 커뮤니티로부터 높은 칭찬을 받았습니다. 이 경험은 졸업 전에 취직 기회를 얻는 데 도움이 되었으며, 프로그램의 깊은 영향력을 보여주었습니다.\n\n올해 관심이 폭발적으로 증가하여 13,500여 건의 열정적인 지원서가 접수되었습니다. 프로그램의 본질은 훈련을 집중적인 여섯 주 동안으로 압축하여 더 크고 열정적인 15명의 인턴 팀을 구성하여 슈퍼 차지하였습니다. 목표는 명확했습니다: 이 짧은 기간 안에 견고한 최소 실현 가능 제품(MVP)을 만들어 손쉬운 학습과 팀워크에서 새로운 기준을 세우는 것입니다.\n\nMRS Technologies의 CTO로써, 이 인턴십 프로그램은 나에게 특별한 자리를 차지하고 있습니다. 내 마음을 다하여 내일의 리더를 가꾸기 위해 최선을 다하며 성장시키고 있습니다. 이 블로그는 올해 프로그램의 주요 하이라이트를 통해 이 프로그램의 강한 실전 학습에 중점을 둔 세계 최고의 인턴십 프로그램 중 하나로 손꼽히는 이유를 보여줄 것입니다.\n\n# 1) 2023년 인턴십 프로그램의 비젼 - 기업가 정신을 일으키다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMRS 인턴십 프로그램의 핵심은 현실적인 기업가 정신의 본질에 직접 뛰어 들 수 있는 스타트업 분위기를 재현하는 데 있습니다. 보통의 인턴십과는 달리, 이 여정은 24시간 7일간의 과제, 학습 및 성장의 혼합으로 변모하여 매일이 도전, 학습 및 성장의 철저한 경험으로 됩니다. 아이디어를 최소 실행 가능 제품(MVP)으로 구현하기 위해 필요한 노력을 직접 체험하면서, 시계 소리에 성공적인 기업가의 세계의 무몰개한 속도가 반영됩니다. 이 프로그램은 모든 인턴이 기업가처럼 생각하고 행동하게 만드는 것을 목표로 하며, 성공은 노력과 지혜로 와야 한다는 것을 교훈으로 받아들이는 것이 중요합니다.\n\n# 2) 압도적인 반응 - 13,500건 이상 지원서 중 선정:\n\n2023년 MRS 인턴십 프로그램 발표는 학생들 사회에서 깊은 울림을 주었으며, 저희가 받은 13,500건 이상의 지원서 수를 반영했습니다. 이러한 관심의 파도는 숫자뿐만 아니라, 다양한 학위 및 전문 분야에서 이어지는 지원자들로 확장되었습니다. 이 섹션에 포함된 자세한 그래프는 이 분포를 생동감 있게 묘사하며, 이 프로그램의 광범위한 영향력과 매력을 강조합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3) 선발 기준 및 최종 선발 과정:\n\n선발 단계는 강력한 MVP를 만들기에 적합한 후보자를 찾기 위해 30일에 걸친 철저한 과정이었습니다. 핵심은 기초 개념을 잘 이해하고 있으며, 열정적이고 협력을 할 의지가 있는 개인을 선발하는 데 집중했습니다. 애플리케이션 카테고리는 다양했으며, Frontend부터 Cloud 개발, UI/UX 디자인, 모바일 애플리케이션 개발, 프로젝트 관리, 임베디드 개발 및 기술 문서 작성 스킬을 포함했습니다.\n\n선발을 위한 기준은 엄격했지만 공정했으며, 의사 소통 능력, 태도, 이전 기술 경험, 성격 및 수행한 프리랜서 또는 자원 봉사 활동을 평가했습니다. 약 150명의 초기 후보자들로부터, 최종 인턴 15명으로 결린 최종 코호트는 각자가 독특한 가치를 지닌 인재로, 실용적인 학습, 혁신 및 팀워크 여정에 돌입할 준비가 되어 있었습니다.\n\n이 신중한 과정은 광범위한 지원자 풀에서 가장 유망한 후보자들을 선발하도록 도왔으며, 프로그램의 학습과 성과를 위한 높은 기준을 보장했습니다. 이 철저하고 필수적인 선발 과정은 MRS 인턴십 프로그램 2023의 고수준의 학습과 성과 유지에 대한 우리의 결연한 헌신을 강조합니다. 이 엄격한 선발은 각 참가자의 미래 전문가 활동을 통해 울림이 남을 것으로 믿는 흥미진진하고 풍부하며 생산적인 여정을 준비했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3) 인턴십 프로그램의 톤 설정하기 - 첫째 날:\n\n어떠한 학생에게도 인턴십의 첫 날은 중요합니다. 기존의 지루한 경험에 실망했던 많은 사람들을 고려하여, MRS Technologies에서는 기대치를 첫단추부터 달리기 위해 노력하고 있습니다.\n\n![인턴십 이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_1.png)\n\n우리의 여정은 첫날의 조직적인 온보딩으로 시작되었는데, 각 인턴은 계정을 설정하고 업무 영역에 소개되었습니다. 그 후로는 우리 회사의 혁신적인 정신의 상징이 되는 혁신적인 프로젝트들을 엿볼 수 있는 층별 회사 투어가 인사팀이 이끄는 확장된 형태로 이어졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n투어를 따라 멘토와 함께하는 세션으로 에너지가 높아졌어요. 각 멘토가 자신을 소개하고 경험을 공유하며, 인턴들이 일상 업무와 프로젝트 목표를 이끌어나가는 데 중요한 역할을 강조했어요. 이 대화로 인턴들 사이에 기대감이 생기며, 존경과 협력의 초기 유대감이 형성되었어요.\n\n![이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_2.png)\n\n이 세션은 만남뿐만 아니라 성장을 격려하고 협력적인 환경을 약속하는 것이었어요. 이 멘토십 프레임워크를 통해 MRS Technologies는 배우고 전문가로 성장하는 푸른 토양으로 빛이 났어요.\n\n그날의 하이라이트는 제가 진행한 마음을 나누는 세션이었어요. 저는 전문 경력, 프로그램의 본질과 기대치, 그리고 이 특별한 경험으로부터 최대 이득을 얻는 데 대한 몇 가지 지혜를 공유했어요. 이 프로그램을 통해 자신의 경력을 형성하는 데 전례없는 기회임을 강조하며, 전문적인 가르침을 제공했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하루가 마무리되었습니다. 영감을 주는 일이 있었죠. 이제는 명확한 비전과 증진된 목적 의식으로 조정된 사고를 갖고, 변화의 여정에 도전할 준비가 돼 있습니다.\n\n### 4) 집중 교육 및 멘토십:\n\nMRS 인턴십 프로그램은 지식을 제공하고 호기심을 자극하며 지속적인 학습을 장려하기 위해 설계된 철저한 훈련 단계로, 기술과 소프트 스킬에 능숙한 다재다능한 인물을 육성하는 것을 목표로 했습니다. 제가 이끈 다양한 워크샵에 참여하여, 주제는 전통적인 범위를 넘어 시스템 디자인부터 효과적인 팀 협업, 초점, 명상, 정신건강의 중요성을 이해하는 등 다양한 주제를 포괄했습니다. 회사 전문가들이 워크샵을 이끌며 프로그램 전체 조직의 다양한 참여를 보장하였으며, 이는 우리 인턴들에게 학습 경험을 증폭시켰습니다.\n\n교육 모듈은 인턴에게 종합적인 기술 세트를 갖게끔 설계된 기술 및 비기술적 워크샵을 조심스럽게 조합한 것이었습니다. 몇 가지 주목할 만한 사례는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 브랜드 및 Figma 소개\n- 인간 심리학과 사용자 경험\n- WebFlow에서 웹사이트 구축\n- 스타트업, 타당성 분석, 비즈니스 모델 및 MVP\n- 클라우드 컴퓨팅, AWS 및 AWS Amplify 소개\n- 단위 테스팅(자동화된 테스트) 소개\n- 정신 건강 및 감정 지능\n- 재무 101 및 소득세 신고 방법\n- 이력서 작성\n- 효율적인 LinkedIn 활용\n- 임베디드 시스템 및 사물인터넷(IoT)에 대한 워크샵 시리즈\n- 프로젝트 관리 및 스크럼 프레임워크 등\n\n감정 지능 워크샵은 매우 호응이 좋았습니다. 우리 강사 라하트 자바이드는 수치스러운 문제인 수치심과 죄책감 유발을 다루면서 트리거와 침투적인 생각에 대해 명확히 알려주었습니다.\n\n창업 정신은 훈련의 중요한 측면이었으며, 스타트업 생태계를 이해하는 데 중점을 둔 여러 워크샵이 제공되었습니다. 이 세션에서는 타당성 분석, 아이디어 선택 및 비즈니스 모델 구축을 다루어 새로운 시각을 가질 수 있도록 견고한 기반을 제공했습니다. 기존의 틀을 벗어나 생각하도록 인턴들에게 기업가적 사고의 불꽃을 일으키고, 혁신을 상상하고 이끌도록 장려하는 것이 목적이었습니다.\n\n# 5) 임베디드 시스템과 사물인터넷(IoT) 교육:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 인턴십 프로그램에서는 내장 시스템과 사물 인터넷(IoT)에 대한 철저한 교육에 중점을 두고 있습니다. 이 특별한 교육은 저희 회사의 숙련된 강사들과 시니어 임베디드 팀 멤버들이 직접 진행하여, 풍부한 실습 경험을 제공합니다. 계획은 시장 관련 주제를 철저히 다루도록 구성되어 있어, 인턴들에게 인턴십 및 이후의 전문적인 노력을 위한 단단한 기반을 제공합니다.\n\n![Training Image 3](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_3.png)\n\n교육은 이론 이상으로 인턴들을 실제, 실습 경험으로 이끕니다. 이 교육의 핵심은 오늘날에 필수적인 클라우드와의 안전한 통신에 대해 배우는 것입니다. 이는 소프트웨어와 하드웨어를 결합한 흥미로운 프로젝트에 참여하는 데 도움이 되므로 중요합니다.\n\n![Training Image 4](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 철저한 교육을 통해 MRS에서 인턴은 견고한 최소 우선 제품(MVP)을 만들 준비가 되었으며, 앞으로의 경력을 위한 준비를 충분히 했습니다.\n\n# 6) 혁신 장려: 인턴들이 MVP 선택을 이끄는 중:\n\nMRS 인턴십 프로그램은 mGreens를 개발하는 중인 인턴이 식물 애호가들의 건강한 성장을 자동화하는 데 도움을 주는 MVP로 선도하는 동안 혁신적인 탐험의 길을 열었습니다.\n\n![이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n핵심 아이디어는 IoT 노드를 만들어 식물과 완벽하게 통합되며 주변 온도, 토양 온도, 습도, 그리고 토양 수분과 같은 다양한 요인을 세심하게 모니터링할 수 있는 것이었습니다. 이 지능형 노드는 각 식물에 맞는 최적 조건에서의 이탈을 감지하고, 사용자에게 즉각적으로 물 주기 또는 선풍기 가동과 같은 교정 조치를 취하도록 경고하는 방식으로 설계되었습니다. 따라서 이 플랫폼은 식물 목록을 표시하여 사용자가 건강하거나 관리가 필요한 식물을 구분해 줄 수 있었습니다.\n\n![Image](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_6.png)\n\n개발 단계에 착수하며 소프트웨어 및 하드웨어 팀은 자발적으로 협력하여 mGreens 비전을 실현했습니다. 짧은 기간 내에 프로젝트를 완료하기 위해 팀이 밤낮 없이 협업하는 모습을 보았습니다. 임베디드 팀은 ESP32와 여러 센서를 사용하여 IoT 노드를 개발하고, 내구성과 설치 편의를 위해 사용자 정의 3D 프린팅 케이스에 수납했습니다. 이 하드웨어 스위트는 원하는 임계 값에서 벗어날 때 실시간 경고를 보내도록 설계되었습니다. 이는 AWS 클라우드 서비스를 사용한 백엔드 시스템을 통해 이루어졌습니다.\n\nUI/UX 팀은 브랜딩을 담당하며 Figma를 사용해 시각적으로 매력적인 인터페이스를 만들었고, 기술 팀은 백엔드로 AWS, 웹앱 개발로 React, 데스크톱 기반의 관리 포털로 QT를 활용했습니다. 또한 Android 모바일 앱과 WebFlow 마케팅 웹사이트를 개발했는데, 이는 프로그램 중에 UI/UX 팀이 4주도 안 되어서 개발한 것입니다. 소프트웨어에는 주요 식물에 대한 최적 값이 포함된 데이터베이스도 포함되어 있어 사용자들이 농작물을 모니터할 수 있는 기반을 제공하며, 숙련된 사용자들은 고유한 요구사항에 따라 임계 값을 수정할 수 있는 유연성도 가지고 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 우리 인턴들이 만든 멋진 사진 몇 장이 있어요.  \n\n\n![Image 7](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_7.png)\n\n![Image 8](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_8.png)\n\n![Image 9](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_9.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_10.png)\n\n![Image 2](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_11.png)\n\n![Image 3](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_12.png)\n\n# 7) Retrospective Meeting with Interns and Mentors\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMRS 인턴십 프로그램의 결론은 모든 인턴과 멘토가 참석한 회고 회의로 마무리되었습니다. 각 인턴은 지난 몇 주 동안의 여정을 5분간의 내러티브로 소개하며 자신의 경험을 나누었습니다. 그들의 말은 학습, 우정, 지식 향상을 위한 지속적 노력이 담긴 여정을 보여주었습니다.\n\n인턴들 다음으로 각 멘토는 자신의 인사이트와 경험을 공유했습니다. 그들은 인턴의 진전과 함께 극복한 독특한 어려움을 주목했습니다. 방안은 감사함과 공유된 성취감으로 넘쳤으며 회의실 안의 모두에게 울려퍼졌습니다.\n\n마지막으로 CTO로서, 저는 그들의 여정에 대한 생각과 앞으로의 방향성을 나눴습니다. 인턴들이 이 소중한 경험을 마지막 학년과 전문가 생활로 나아가면서 어떻게 활용할 수 있는지에 대해 논의했습니다. 이 대화는 인턴들을 위한 도로를 제공하고, 얻은 지식과 기술이 실제 세계에서 어떻게 활용될 수 있는지 상상하도록 도왔습니다. 이는 희망, 야망, 그리고 기술 세계에서 의미 있는 흔적을 남기고자 하는 공동의 꿈으로 가득한 따뜻한 세션이었습니다. 순간의 감정적 깊이가 느껴지며, 성장, 팀워크, 혁신의 여정을 완벽하게 마무리하는 모습을 보여주었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_14.png)\n\n# 8) 업적을 기념하며: 최종 발표 및 폐회식\n\nMRS 인턴십 프로그램의 여정은 최종 발표 및 폐회식을 통해 업적을 축하하며 화려하게 마무리되었습니다. 이 자리에는 모든 멘토, 워크샵 강사, 인턴들, 그리고 MRS Technologies와 MTronic Pakistan의 C급 리더십이 참석했습니다.\n\n참석자들로 붐볐던 이번 세션은 각 인턴이 진지한 발표로 시작하여 프로젝트에서의 역할, MVP에 기여한 부분, 프로그램 중의 개인적 경험, 그리고 좋아했던 워크샵과 멘토에 관해 따뜻한 이야기를 나누었습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n열정적인 노력과 혁신의 결과물을 보여주며 MVP의 자세한 데모가 발표되면서 분위기는 흥분으로 넘쳤어요. 인턴들이 참여자들을 놀라게 한 mGreens에 대한 매력적인 데모 비디오를 선보여 방 안에 기쁨과 자부심이 가득했던 특별한 순간이 있었어요.\n\n이어서 MRS Technologies의 CEO 인 Dr. Mansoor Shaukat과 MTronic Pakistan의 최고 경영 책임자인 와카스 칼릴이 프로그램에 대한 경탄과 감사의 뜻을 나누었어요. 와카스 칼릴은 연설 중 다수의 창업 기업과의 폭넓은 경험에도 불구하고 이처럼 철저하고 영향력 있는 프로그램을 다른 어디서도 경험하지 못했다고 말씀했어요.\n\n이후에는 CxOs가 인턴들에게 인턴십 완수 증명서, 멘토에게 인정 증명서, 워크숍 강사에게 감사 증명서를 수여했어요. 이 행동은 이 풍부한 여정에 참여한 개인 각각의 끈기와 우수한 노력을 인정하고 귀추를 상징합니다.\n\n이식은 Abdullah Umer에게 특별한 \"리더십상\"을 수여하며 절묘한 리더십과 프로그램 전체를 통틀어 뛰어난 성과를 인정받았어요. 이상의 시상은 인턴십 프로그램 동안 여러 명의 개인이 모니터링한 KPI를 기반으로 수여되었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_15.png](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_15.png)\n\n하루를 단축하며 그룹 사진을 찍고 사소한 대화를 나누는 동안 감정, 동료애, 그리고 성취감을 나누며 방 안은 들뜬 분위기로 넘쳤습니다. 미소, 웃음소리, 그리고 작별 인사가 MRS 인턴십 프로그램 2023을 통해 각 참가자가 걸어온 보상적이고 변화적인 여정의 본질을 담아냈습니다.\n\n# 선발되지 않은 동료들은 어떨까요?\n\n선발되지 않은 분들을 위해 그들에게는 단순한 신청 상태 통지 이상을 제공했습니다. 앞날을 안내하기 위해 상세한 이메일을 작성했습니다. 프로그램에 합격하지 못했더라도, 이 이메일은 LinkedIn 네트워킹, 블로깅과 콘텐츠 제작, 개인 브랜딩과 같은 중요 영역에 초점을 맞추는 데 도움이 되었습니다. 이를 통해 역경을 겪더라도, 그들이 전문 경력을 이어 나갈 명확한 방향을 가지도록 돕는 것이 목표였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n2023년 MRS 인턴십은 혁신적인 기술 시야의 실제 측면으로의 환상적인 여정으로 나타났습니다. 신입사원들을 기술 산업에 대비하는 좋은 모범 사례를 세우면서 훌륭한 예를 보여주었습니다. 이제 경험을 쌓은 각 인턴은 스타트업 문화 속에서 매끄럽게 녹아들며 도전을 극복하고 해결책을 찾아가며 전문적인 우정을 통해 성장했습니다. 모든 문제 해결, 모든 불일치 해소, 그리고 모든 프로젝트 완료는 전통적인 수업이 제공할 수 있는 것 이상으로 기술 세계에 대한 이해를 쌓게 해주었습니다.\n\n우리의 접근 방식은 다르다 - 우리는 기본적인 작업을 할당하는 전형적인 방식에서 벗어났습니다. 대신, 우리는 인턴을 의미 있는 프로젝트의 핵심으로 밀어넣어 현실적인 도전과 해결책을 이해하도록 돕았습니다. 실제 프로젝트를 통한 실무 경험은 단지 전문계에 발을 딛기 전에 체크할 상자일 뿐인 것보다 풍부한 경험으로 만들어 주었습니다.\n\n인턴들이 배우기 위해 노력하는 것이 아니라 뛰어나기 위해 보이는 열정과 결단력, 멘토들의 지식을 공유하기 위한 헌신, 그리고 결과적으로 나타난 혁신적인 프로젝트들이 모두 2023년 MRS 인턴십 프로그램의 성공에 대해 많은 이야기를 전합니다. 올해의 프로그램을 마무리하면서 다음 집단이 어떤 성과를 이룰지에 대한 기대가 쌓이기 시작합니다. 업데이트를 위해 MRS 여름 인턴십 페이지를 주시해 주시길 바랍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 많은 정보를 원하거나 가이던스가 필요하다면, LinkedIn에서 저와 연락해주세요. 모든 지망 기술 전문가들을 위해 더 많은 학습, 혁신, 그리고 밝은 미래가 되길 바라겠습니다!\n\n![image](/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_16.png)","ogImage":{"url":"/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_0.png"},"coverImage":"/assets/img/2024-05-18-MRSTechnologiesSummersInternshipProgram2023AComprehensiveJourney_0.png","tag":["Tech"],"readingTime":11},{"title":"메이테이어 언어의 기계 번역 앱 및 웹 페이지","description":"","date":"2024-05-18 18:28","slug":"2024-05-18-MachinetranslationappsandwebsofMeiteilanguage","content":"\n\n![2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png)\n\n메이테이어, 또는 매니푸리어로도 알려진 메이테이어 언어는 매니푸르 주, 아사름 주의 공용어일 뿐만 아니라 인도 공화국의 헌법적 언어이기도 하며, 트리푸라 주의 문학적, 학술적인 공용어로 인정받고 있습니다. 이 언어는 다양한 기계 번역 앱과 웹에서 지원되지만, 어떤 것이 가장 정확한지 선택하는 것은 쉬운 일이 아닙니다. 흠... 소소한 조사를 해 봅시다!\n\n한 가지 유의할 점은 메이테이어가 매니푸리어, 미티, 미테이, 메이테일론, 미티론, 칸글레이 등 다양한 이름으로 알려져 있다는 것입니다. 따라서 서로 다른 앱과 웹사이트에서는 이러한 인기 있는 동의어 중 하나가 사용될 수 있습니다. 그러니 한 가지 이름을 입력했는데 찾을 수 없다면, 잠시 다시 확인해 보세요! 그렇게 어려운 일은 아닙니다!\n\n여기서는 실험을 목적으로 \"매니푸르는 멋진 곳입니다.\"라는 문장을 사용합니다. 이 문장이 모든 앱과 웹에서 번역에 사용될 것입니다. 일부는 메이테이 메이에크 문자 (mni-Mtei), 또는 벵골 문자 (mni-Beng), 또는 라틴 문자 (mni-Latn)을 사용합니다. 여기서 \"mni\"은 \"매니푸리어\"를 나타내고 다른 코드 단어는 각각의 문자체계를 참조합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 구글 번역 ???\n\n![이미지](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_1.png)\n\n구글 번역은 메이테이어 언어에 메이테이 마예크 문자체계를 사용합니다. 고급 용어에 대한 단어의 경우 구글 번역은 주로 번역하는 대신 음역합니다. 위 이미지에서 구글은 \"마니푸르는 멋진 장소입니다\"를 \"ꯃꯅꯤꯄꯨꯔ ꯑꯁꯤ ꯑꯉꯀꯄꯥ ꯃꯐꯝ ꯑꯃꯅꯤ꯫\" (manipur asi angakapa mapham amani)로 번역하고 있습니다. 여기서 맞춤법 오류가 발견되며, 이는 해당 언어에서 더 많은 경우에 자주 발생합니다. 그러나 문장 구조 표현 방법은 중간 수준입니다.\n\n평가한다면 5점 중 3.5점을 받을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Microsoft Translator 리뷰\n\n![마이크로소프트 트랜스레이터](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_2.png)\n\n마이크로소프트 트랜스레이터는 영어에서 매니푸리어로 번역할 때 나란히 메테이 마예크 문자와 라틴 문자를 사용하지만 매니푸리어에서 영어로 번역할 때는 라틴 문자를 사용할 수 없습니다. 다양한 어휘 사용에서 우수한 성능을 발휘합니다. 맞춤법 오류가 거의 없는 것으로 나타납니다. \"Manipur is a wonderful place\"이 \"ꯃꯅꯤꯄꯨꯔ ꯑꯁꯤ ꯌꯥꯝꯅ ꯐꯖꯕ ꯃꯐꯝ ꯑꯃꯅꯤ꯫\" (manipur asi yaamna phajaba mapham amani.)로 번역됩니다. 정확성은 완벽하진 않지만 여전히 꽤 양호합니다.\n\n평가하면 5점 만점에 4점을 줄 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## ???\n\n\u003cimg src=\"/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_3.png\" /\u003e\n\nBhashini은 인도 정부의 프로젝트로, 메이테이어 언어에는 Meetei Mayek 스크립트를 사용합니다. 이 알고리즘은 인도 정부와 협력하여 개발된 IIT 매드라스의 AI 기술 플랫폼인 AI4Bharat (인공 지능-인도를 위한)에서 사용됩니다. Bhashini는 메이테이어 언어에 대해 남성과 여성 음성 출력 기술을 모두 제공합니다. 일부 맞춤법 오류가 있습니다. 번역 정확도는 Microsoft Translator와 거의 동일하여 상당히 좋습니다.\n\n여기서 \"Manipuri is a wonderful place\"라는 문구를 \"ꯃꯅꯤꯄꯨꯔ ꯑꯁꯤ ꯐꯖꯔꯕ ꯃꯐꯝ ꯑꯃꯅꯤ ꯫\" (manipur asi phajaraba mapham amani.)로 번역합니다. 문구는 다른 번역 앱 및 웹과 달리 독특합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 평가해야 한다면 5점 만점에 4점을 줄 것입니다.\n\n## Glosbe 번역 ???\n\n![이미지](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_4.png)\n\nGlosbe 번역은 메이테이어 언어에 대해 벵골 문자를 사용합니다. 번역 정확도는 상당히 좋고 맞춤법 실수는 드물게 발생합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 \"Manipur is a wonderful place\"는 \"মনিপুর অসি য়াম্না ফবা মফম অমনি।\" (manipur asi yaamna phaba mapham amani.)로 번역됩니다. 완벽하지는 않지만 언어 어휘의 이해 수준에 맞게 사용됩니다.\n\n평가한다면, 5점 중 4점을 얻을 것입니다.\n\n## 현대기계번역 ???\n\n![이미지](/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현대적인 MT는 메이테이어어를 번역할 때 벵골어 스크립트를 사용합니다. 2024년 중반 기준으로 번역 정확도는 상당히 낮지만 이전보다 크게 개선 중입니다. 맞춤법 실수는 단어 선택 오류에 비해 적습니다. 대부분의 문장 번역 결과는 정확도가 떨어지지만, 단어 번역에 대해서는 꽤 좋습니다.\n\n여기서 \"Manipur is a wonderful place\"는 \"মনিপুর অসি য়াম্না নুংঙাইবা মফম অমনি ।\" (manipur asi yaamna nungngaiba mapham amani.)로 번역됩니다. 관련된 단어가 사용되었지만, 이 간단한 짧은 문장에서도 완벽하게 번역되지는 못합니다.\n\n평가할 경우, 5점 중 2점을 받을 것입니다.\n\n## 그 외 ???\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 번역 서비스가 많이 있습니다. Bing AI의 Copilot, ELRA 카탈로그 등이 있어요.\n\nMeitei 언어로 Copilot of Bing AI는 매우 불규칙합니다. 때때로 벵골어 스크립트를 사용하고 때로는 Meitei 스크립트를 사용하며 때로는 라틴 스크립트를 사용하며 때로는 완전히 번역에 실패하기도 해요. Manipuri로 다음을 번역해 주세요: ... ... ... 와 같이 말하고 영어로 문장이나 단어를 입력해 주면 돼요. Manipuri에서 영어로 역변환은 2024년 중반 기준으로 작동하지 않는 것처럼 보여요.\n\n평가해야 한다면, 5점 만점에 2점을 줄 것입니다.\n\n이것은 Meitei 언어에 대해 가장 널리 사용되는 기계 번역 앱과 웹 중 일부에 대한 소개에 불과해요. 평가는 제 개인적인 의견이며 제 관찰에 기반하며 다른 사람들과 차이가 있을 수도 있어요. Meitei 언어의 언어 애호가, 학습자 및 학생들에게 이 작은 정보 조각이 어느 정도 도움이 되기를 바래요. 응원합니다! :-)","ogImage":{"url":"/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png"},"coverImage":"/assets/img/2024-05-18-MachinetranslationappsandwebsofMeiteilanguage_0.png","tag":["Tech"],"readingTime":4},{"title":"데이터 엔지니어링은 엔지니어를 위한 것입니다  아니에요","description":"","date":"2024-05-18 18:24","slug":"2024-05-18-DataEngineeringisforEngineersNOT","content":"\n\n## 글을 쓰는 사람이 데이터 엔지니어링도 배울 수 있을 거라고 생각해요.\n\n\"이게 무슨 일이죠.\"\n\n처음 데이터 엔지니어링 업무를 맡았을 때 나는 이렇게 생각했어요. 하지만 얼마 후, 우리가 하나씩 위키피디아에서 집어낼 몇 가지 숫자를 가져오는 것이 첫 번째 단계였다는 것을 깨달았죠.\n\n파이썬에서 작업을 해주셔야겠다고 말씀하셔야 했던 첫 번째 어려움이 있었어요! 즉, 데이터를 수동으로 가져오는 날이 끝났다는 거죠. 인내심을 가지고 자신에게 이런 말을 해보세요. 괜찮아, 이 일 잘 할 수 있어요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문제: 사회과학 졸업생이 데이터 엔지니어링을 능숙하게 수행할 수 있을까요? 자동화된 데이터 파이프라인을 구축하고 안전하게 클라우드에 보관할 수 있을까요?\n\n귀무가설: 엔지니어는 생업으로 글을 쓰는 사람만큼 데이터 엔지니어링을 할 수 있습니다.\n\n이 가설을 기각해야 할까요? 내 직감은 \"예\"라고 말했습니다. IT 비전문가인 나 같은 사람이 그렇게 할 수는 없을 것 같아요.\n\n대안 가설은 아마도 이렇게 할 수 있을 것 같아요: 생업으로 글쓰는 사람도 엔지니어처럼 데이터 엔지니어링을 배울 수 있다면요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 시작해요...\n\n## 우리 비즈니스 케이스\n\n이 작업은 주로 전기 이동성에 관련된 사업을 하는 \"Gans\" 회사를 위한 데이터베이스를 생성하는 것을 포함하고 있습니다. 특정 시간에 충분한 이동성 단위를 제공하기 위해 날씨 요소를 기반으로 수요를 측정하기 위한 데이터 과학자를 필요로 합니다.\n\n회사의 주요 사업은 독일에서 스쿠터를 대여하는 것이기 때문에 비가 오거나 눈이 오는 경우에는 일반적으로 수요가 줄어들게 됩니다. 비나 눈이 예보된 경우, 임시 수요도 증가할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n따라서, 현재 과제는 도시와 날씨 정보로 채워진 간단한 SQL 데이터베이스를 구축하는 것입니다. 회사의 운영 부서는 매일이 이 데이터베이스에 액세스하여 이동 가능 차량의 지리적 가용성에 관한 판단을 내릴 수 있을 것입니다.\n\n나중에 데이터베이스는 관광객 방문 예상 등을 제공하기 위해 공공 교통 도착 정보(예: 항공편, 기차, 또는 버스 API 사용)가 포함될 수 있습니다. 이들은 회사의 잠재적 고객 중 일부입니다.\n\n다음은 날씨와 항공편 API를 포함한 지도 프로젝트의 모습입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 날씨 데이터 통합만 다루고 나중에 전송 부분은 나중에 개선할 것입니다.\n\n시작하기 전에 Python에서 필요한 모든 라이브러리를 가져와야 합니다:\n\n```python\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nfrom pytz import timezone\n```\n\n## 웹 스크래핑 101: HTML 코드를 가져오는 방법?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 다른 테이블과 관련하는 주요 테이블로 작용하는 도시 정보가 포함된 테이블을 만들어야 합니다. 이 테이블은 주기적으로 업데이트할 필요가 없는 정적 테이블이 될 것입니다. 이 테이블을 \"cities_info\"라고 부를 것입니다.\n\n각 도시에 대해 고유한 도시 ID, 도시 이름, 독일의 소속 주(State), 위도 및 경도가 포함된 5개 열이 있을 것입니다. 각 도시에 대한 이 정보는 영어 위키피디아 사이트에서 스크래핑하여 얻을 수 있습니다. 예산이 허용한다면, 신뢰할 수 있는 데이터와 방법론적 정보가 포함된 도시의 API를 구매할 수 있습니다. 이 프로젝트에서는 위키피디아를 사용하여 스크래핑 기술을 연습할 것입니다.\n\n처음에는 각 웹사이트마다 HTML 코드를 수동으로 내보내고 Vs Code에 복사해야 한다는 생각이 압도적이었습니다. 그러나 다행히 파이썬의 \"requests\" 라이브러리를 사용하면 자동으로 수행할 수 있음을 알게 되어 안도했습니다:\n\n```js\nimport requests\nberlin_url = \"https://en.wikipedia.org/wiki/Berlin\"\nberlin_response = requests.get(berlin_url)\nberlin_soup = BeautifulSoup(berlin_response.content, 'html.parser')\nprint(berlin_soup.prettify)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬: 1 - 나: 0\n\n## 루프와 함수\n\n이터레이션의 성배입니다. 이들 없이는 동일한 코드를 재생산하고 다른 URL에 동시에 적용할 수 없습니다. 이것이 웹 스크레이핑을 자동화하는 열쇠입니다.\n\n여기에는 각 위키피디아 사이트의 HTML 코드를 검색하기 위해 사용한 루프의 예시가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ncities_list = [\"Berlin\", \"Hamburg\", \"Munich\", \"Cologne\", \"Frankfurt\"]\n\nfor city in cities_list:\n  url = f\"https://www.wikipedia.org/wiki/{city}\"   # url을 f 문자열로 변환하여 도시를 변수로 넣어 해당 도시에서 다른 도시로 변경됨\n  response = requests.get(url)          # 위키백과 페이지의 모든 내용을 가져와 response에 저장\n  city_soup = BeautifulSoup(response.content, 'html.parser')\n```\n\n지금은 함수가 무서워서 최대한 피하고 있어요 😅\n\n파이썬: 1,000 — 나: 0\n\n## HTML에서 무엇을 접근하나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nHTML에서 \"p 태그\"라는 것이 있어요. 이를 액세스하는 데 유용합니다. 다음 코드를 사용하여 그렇게 할 수 있어요:\n\n```js\nprint(soup.p)   # 첫 번째 p 태그 자체에 접근\nprint(soup.p.string)  # 첫 번째 p 태그와 관련된 문자열에 접근\n```\n\n```js\nfor child in soup.div:  # 1번째 div에서 각 자식을 찾아서 인쇄하는 예제\n    print(child)\n```\n\n## Python에서 데이터프레임 및 SQL에서 해당 테이블 만들기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nHTML 및 웹 스크래핑 기술을 연마한 후, 첫 두 테이블에 필요한 모든 정보를 얻기 위해 이 루프를 만들었어요.\n\n첫 번째 데이터프레임은 정적 인덱스로 작동할 것이고 (즉, 정보를 정기적으로 업데이트할 필요가 없어요): cities_info\n\n```js\ncities_list = [\"베를린\", \"함부르크\", \"뮌헨\", \"쾰른\", \"프랑크푸르트\"]\nstates = []\nlatitudes = []\nlongitudes = []\n\nfor city in cities_list:\n  url = f\"https://www.wikipedia.org/wiki/{city}\"   \n  city_soup = BeautifulSoup(response.content, 'html.parser')    # (위키백과 사이트의 내용을 city_soup 변수에 저장하는) 내용을 구문 분석합니다.\n\n  # 도시가 속한 주를 검색합니다\n  if city not in [\"함부르크\", \"베를린\"]:         # 베를린의 경우 일반적인 .find 공식도 작동할 거예요! 주 섹션이 없는 \"함부르크\"만이 예외에요\n    city_state = city_soup.find(\"table\", class_=\"vcard\").find(string=\"주\").find_next(\"td\").get_text()  # 다른 주 이름을 가진 도시에 대한 주를 검색합니다\n  else:\n    city_state = city     # 함부르크와 베를린의 경우, 동명의 도시 이름을 가져올 거예요\n  states.append(city_state)\n\n  # 각 도시의 위도를 검색하여 위도 열에 추가합니다\n  city_latitude = city_soup.find(class_=\"latitude\").get_text()\n  latitudes.append(city_latitude)  \n\n   # 각 도시의 경도를 검색하여 경도 열에 추가합니다\n  city_longitude = city_soup.find(class_=\"longitude\").get_text()\n  longitudes.append(city_longitude)  \n\ncities_info_non_rel = pd.DataFrame({         # 이것이 cities_info 데이터프레임이에요\n    \"도시 이름\": cities_list,\n    \"독일 주\": states,\n    \"위도\": latitudes,\n    \"경도\": longitudes\n})  \n\ndisplay(cities_info_non_rel)    # 표시하면 테이블이 더 예쁘게 보여요\n```\n\n또한, 연간 한 번씩 업데이트될 것으로 예상되는 인구 데이터를 포함하는 두 번째 데이터프레임도 생성했어요: cities_population\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\n/***************************\n환경 설정\n***************************/\n\n-- 데이터베이스가 이미 있는 경우 삭제\nDROP DATABASE IF EXISTS gans;\n\n-- 데이터베이스 생성\nCREATE DATABASE gans;\n\n-- 데이터베이스 사용\nUSE gans;\n\n\n/***************************\n첫 번째 테이블 생성\n***************************/\n\n-- 'cities_info' 테이블 생성\nCREATE TABLE cities_info (\n    cities_id INT AUTO_INCREMENT, -- 도시마다 자동으로 생성된 ID\n    city_name VARCHAR(255) NOT NULL, -- 도시 이름\n    german_state VARCHAR(255) NOT NULL, -- 주 이름\n    latitude VARCHAR(255) NOT NULL, -- 위도 좌표\n    longitude VARCHAR(255) NOT NULL, -- 경도 좌표\n    PRIMARY KEY (cities_id) -- 각 도시를 고유하게 식별하기 위한 기본 키\n    );\n\n\n/***************************\n두 번째 테이블 생성\n***************************/ \n\nCREATE TABLE cities_population (\n    cities_id INT,\n    population INT, -- 인구수\n    year_data_retrieved INT, -- 인구 데이터를 검색한 해당 년도\n    FOREIGN KEY (cities_id) REFERENCES cities_info(cities_id)\n);\n```\n\n이제 Python에서 데이터를 첫 번째 SQL 테이블로 전송합니다:```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nschema = \"gans\"     # 데이터베이스 이름\nhost = \"xxx.x.x.x\"\nuser = \"root\"               # 사용자 이름\npassword = \"xxxx\"           # SQL 암호 직접 지정 또는 다른 노트북에서 가져오기 (\"from xxxfile import my_password\")\nport = 3306\n\nconnection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'    \n# 이건 파이썬 노트북을 SQL Workbench에 연결하는 방법이에요\n```\n\n```js\ncities_info_non_rel.to_sql('cities_info',   # 파이썬에서 SQL로 데이터를 보내는 방법\n                  if_exists='append',       # 덮어쓰지 않고 기존 데이터에 추가하기 위함\n                  con=connection_string,    # SQL Workbench에 연결할 때 필요한 인자\n                  index=False)    \n```\n\n첫 번째 시도는 로컬에서 이루어졌습니다. 나중에 Google Cloud Platform 인스턴스를 추가하면 \"host\" 필드를 편집하여 이 데이터를 클라우드에 직접 전송할 수 있습니다.\n\nSQL에 첫 번째 테이블이 생성되면 cities_info에 포함된 데이터를 검색하여 두 번째 cities_population 데이터 프레임에서 해당 cities_id 열을 인덱스로 사용할 수 있습니다:```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ncities_info = pd.read_sql(\"cities_info\", con=connection_string)   # 이 코드는 SQL에 저장된 정보를 \"읽어옵니다\"\ncities_info\n```\n\n다음은 cities_info의 모습입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_1.png\" /\u003e\n\n두 번째 데이터프레임의 내용을 SQL로 넣기 전에, 새로 생성된 cities_id 열을 사용하여 cities_populations 데이터프레임에 추가해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 칼럼 순서를 재조정하고, 이제 cities_populations 데이터프레임에 cities_id 칼럼이 있기 때문에 더 이상 city_name 칼럼이 필요하지 않으므로 삭제했습니다:\n\n```js\n# 다른 인구 데이터프레임에 cities_id 칼럼을 추가합니다\ncities_population[\"cities_id\"] = cities_info_non_rel[\"cities_id\"]\ncities_population\n\n# city_name 칼럼은 더 이상 필요하지 않기 때문에 삭제하고 칼럼 순서를 바꿔 더 직관적으로 만듭니다\ncities_population = cities_population[[\"cities_id\", \"population\", \"year_data_retrieved\"]]\ncities_population\n```\n\n그리고 제 두 번째 데이터프레임이 있습니다. 이 데이터프레임은 일부 동적입니다(데이터가 때때로 업데이트됩니다. 예: 연간 한 번):\n\n![데이터 엔지니어링은 엔지니어를 위한 것](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_2.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당분간은, 다음 해까지 업데이트되지 않을 동적이 아닌 cities_population 테이블로 간주하겠습니다.\n\n이제 우리는 로컬 SQL 인스턴스로 내용을 푸시할 준비가 되었습니다:\n\n```js\n# 두 번째 테이블 내용을 SQL로 푸시합니다\ncities_population.to_sql('cities_population',   # 이렇게 하면 Python에서 SQL로 푸시합니다\n                  if_exists='append',       # 덮어쓰기를 원하지 않으므로, 기존 데이터에만 데이터를 추가합니다\n                  con=connection_string,    # con은 sql workbench에 연결하기 위해 필요한 인자입니다\n                  index=False)    \n```\n\nSQL에서 모든 것을 실행하고 \"역공학\" 기능을 사용하면, 우리의 스키마의 가장 초기 버전을 얻을 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_3.png\" /\u003e\n\n우리는 학습 곡선 속으로 더 깊이 파고들고 있어요.\n\n다음 단계: API를 데이터베이스에 통합하기. 지구상의 모든 데이터 과학자의 본질이라고 할 수 있죠.\n\nAI가 따라잡기 전에 어떻게 해야 할지 배워야겠네요! (또는 외계인이 그들의 데이터 요구를 어떻게 처리하는지를 보일 때까지) 👽\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 날씨 API 사용하기\n\n이 프로젝트의 세 번째 큰 단계는 현재 존재하는 데이터 저장소에서 날씨 데이터를 추출하고 SQL 데이터베이스에 통합하는 것입니다. 이러한 저장소들은 API를 통해 접근할 수 있습니다. API는 Application Programming Interface의 약자로, 서로 다른 소프트웨어 응용 프로그램 간에 통신할 수 있도록 하는 규칙과 프로토콜의 집합입니다.\n\n이를 위해 우리는 openweathermap.org 웹사이트를 사용할 것입니다. 이 사이트를 통해 전 세계 어느 위치의 무료 날씨 예보에도 접근할 수 있습니다. 우리는 5일 날씨 예보 API를 사용할 것이며, 3시간 간격의 예보 데이터를 포함합니다: [https://openweathermap.org/forecast5](https://openweathermap.org/forecast5)\n\n이제 우리 프로젝트의 핵심 작업에 직면했습니다: 우리가 원하는 날씨 데이터를 검색하고 SQL 데이터베이스로 전송하기 위한 필요한 코드를 작성하는 것입니다. 수십 시간 동안 고군분투한 결과, 가장 관련성 있는 날씨 데이터를 추출하기 위한 이 코드를 개발해냈습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef get_weather_data(cities):\n  # 클라우드에서 작업할 예정이므로 컴퓨터는 어디에 있을지 모릅니다 - 컴퓨터 시간대를 우리 지역 시간대로 수정합시다.\n  berlin_timezone = timezone(\"Europe/Berlin\")\n  API_key = \"7e5623c79f102b6c08b15c8hjib4cc9l\"    # 이것은 실제 값이 아닙니다.\n  weather_items = []\n\n  for city in cities:\n    url = (f\"http://api.openweathermap.org/data/2.5/forecast?q={city}\u0026appid={API_key}\u0026units=metric\")\n    response = requests.get(url)\n    json = response.json()\n\n    # 예보를 작성한 시간을 알기 위해 검색 시간을 추가했습니다.\n    retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    # 이제 우리의 관련 데이터베이스에서 데이터를 사용하므로, 도시는 도시 이름이 아닌 도시 ID를 반영해야 합니다.\n    city_id = cities_info.loc[cities_info[\"city_name\"] == city, \"city_id\"].values[0]  # 여기에서 값들을 검색해야 하며, 그렇지 않으면 시리즈를 보여줍니다.\n\n    for item in json[\"list\"]:\n        weather_item = {\n            # 여러 도시를 고려할 때 정보를 명확히 알 수 있게 도시 이름을 추가했습니다.\n            \"city_id\": city_id,\n            \"forecast_time\": item.get(\"dt_txt\", None),\n            \"temperature\": item[\"main\"].get(\"temp\", None),\n            \"feels_like\": item[\"main\"].get(\"feels_like\", None),\n            \"forecast\": item[\"weather\"][0].get(\"main\", None),\n            \"humidity\": item[\"main\"].get(\"humidity\", None),\n            \"rain_in_last_3h\": item.get(\"rain\", {}).get(\"3h\", 0),\n            \"risk_of_rain\": item[\"pop\"],\n            \"snow_in_last_3h\": item.get(\"snow\", {}).get(\"3h\", 0),      \n            \"wind_speed\": item[\"wind\"].get(\"speed\", None),\n            \"data_retrieved_at\": retrieval_time\n        }\n\n        weather_items.append(weather_item)\n  \n  weather_df = pd.DataFrame(weather_items)\n  weather_df[\"forecast_time\"] = pd.to_datetime(weather_df[\"forecast_time\"])\n  weather_df[\"data_retrieved_at\"] = pd.to_datetime(weather_df[\"data_retrieved_at\"])\n  weather_df[\"snow_in_last_3h\"] = pd.to_numeric(weather_df[\"snow_in_last_3h\"], downcast=\"float.\")\n\n  return weather_df\n\nweather_df = get_weather_data([\"Berlin\", \"Hamburg\", \"Munich\", \"Cologne\", \"Frankfurt\"])\nweather_df     # 함수를 사용하여 새로운 데이터프레임 생성\n```\n\n날씨 데이터프레임 및 테이블의 중요 기능 중 하나는 데이터 검색 시간을 기록하는 열을 포함해야 한다는 것입니다. 이를 통해 필터링 및 일정한 기간 후 자동으로 이전 데이터가 삭제되도록 SQL에서 프로시저나 함수를 작성하거나 만들 수 있습니다. 이는 데이터 일관성 목적으로 날씨와 데이터 검색 시간이 항상 예보에 대한 날짜/시간과 다른 것임을 항상 인식할 수 있도록 하기 위한 것입니다.\n\n이것이 Python에서 새로운 날씨 데이터프레임이 보이는 방식입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_4.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일단 날씨 데이터프레임 구조를 가지고 있었을 때, SQL에서 날씨 테이블을 생성하는 작업을 시작했습니다:\n\n```js\n/***************************\n날씨 테이블을 생성합니다\n***************************/ \n\nCREATE TABLE weather (\n    city_id INT,\n    forecast_time datetime,\n    temperature float,\n    feels_like float,\n    forecast VARCHAR(255) NOT NULL,\n    humidity INT,\n    rain_in_last_3h FLOAT,\n    risk_of_rain FLOAT,\n    snow_in_last_3h FLOAT,\n    wind_speed FLOAT,\n    data_retrieved_at DATETIME,\n    FOREIGN KEY (city_id) REFERENCES cities_info(city_id)\n    );\n\n-- TRUNCATE TABLE weather;   -- 테이블이 너무 커지고 데이터가 오래되었을 때 모든 행을 지워야 할 수도 있습니다\n```\n\n이것은 엔지니어링을 통해 역 공학을 거쳐 업데이트된 SQL 스키마입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_5.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 지역에서 전역으로\n\n우리의 코드를 클라우드에 올리기 전에, 날씨 데이터 검색 코드가 로컬에서 작동하는지 확인해야 합니다. Python으로 코드를 작성한 후, 로컬 SQL 인스턴스로 전송해보겠습니다:\n\n```python\nweather_df.to_sql(\"weather\",          \n                  if_exists='append',      \n                  con=connection_string,\n                  index=False)    \n```\n\n만약 새 데이터가 우리의 SQL 테이블에 추가된다면, 작동하는 것입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬을 통해 로컬 데이터를 입력한 후 SQL 날씨 테이블이 어떻게 보이는지는 다음과 같습니다:\n\n![Weather Table](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_6.png)\n\n## Google Cloud Platform 통합\n\n로컬에서 코드가 작동하는 것을 확인하면, 이제 클라우드에 올려보는 시간입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n구글 클라우드 플랫폼(GCP) 계정을 열고 클라우드 인스턴스를 설정해야 합니다. 여기서는 자세히 다루지는 않겠지만 MySQL을 사용한 좋은 단계별 설명을 찾을 수 있습니다: https://support.google.com/appsheet/answer/10107301?hl=en\n\n제게 가장 중요한 단계 중 하나는 파이썬 노트북에서 로컬 IP 호스트를 구글 IP 호스트로 변경하는 것이었습니다. 구체적으로, 데이터를 SQL로 전송하는 코드 블록에서 변경했습니다:\n\n```js\nschema = \"gans\"         # 데이터베이스 이름\nhost = \"XX.XXX.XX.XX\"   # 로컬 호스트:\"xxx.x.x.x\" (클라우드로 변경하기 전)\nuser = \"root\"           # 사용자 이름 (가이드 참조)\npassword = \"XXXX\"       # 비밀번호 직접 입력하거나 다른 노트북에서 가져옵니다 (\"from xxxfile import my_password\")\nport = 3306\n\nconnection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'     # 이 부분이 파이썬 노트북을 SQL 워크벤치에 연결하는 역할을 합니다\n```\n\n이렇게 함으로써, 이전에 생성한 정적 테이블을 클라우드에 자동으로 업로드하고 파이썬에서 코드를 다시 실행하지 않고 이미 존재하는 SQL 테이블에 데이터를 채울 수 있었습니다. 아니면 적어도 파이썬에서 코드를 다시 실행할 필요가 없습니다. 혹은 새로운 비동적 테이블(도시 정보 및 도시 인구)을 업데이트하기로 결정할 때까지입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 프로젝트의 목적으로, Python에서 이 두 표를 GCP로 업로드하려면 호스트 IP를 변경하는 것으로 충분합니다. 또 다른 방법은 두 표를 만드는 코드를 클라우드에 업로드하는 것입니다. 이 경우, 우리는 클라우드에 동적 표 날씨를 만들고 채우는 코드만 올릴 것입니다.\n\nGCP의 \"Cloud Functions\" 필드에 함수를 만든 후 여러 번의 시행착오 끝에 코드가 마침내 작동했습니다:\n\n![cloud_function_image](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_7.png)\n\n하지만 코드가 작동하기 전에 클라우드 인스턴스에 함수를 연결해야합니다. 아래 단계를 따라야합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_8.png\" /\u003e\n\n작업이 잘되었는지 어떻게 알 수 있을까요? 가장 좋은 소식은 다음과 같이 보입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_9.png\" /\u003e\n\n로컬에서 테스트한 코드와 비교해 상당한 수정이 필요했습니다. 최종 코드는 이렇게 보입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport functions_framework\nimport pandas as pd\nimport sqlalchemy\nimport requests  \nfrom pytz import timezone\nfrom datetime import datetime \n\n@functions_framework.http\ndef insert(request):\n  connection_string = connection()\n  insert_into_weather(connection_string)\n  return 'Data successfully added'\n\ndef connection():\n  connection_name = \"flying-dove-416317:europe-west1:wbs-mysql-db\"    # this is not a real one\n  db_user = \"root\"\n  db_password = \"xxxx\"   # fill in with your SQL password\n  schema_name = \"gans\"\n\n  driver_name = 'mysql+pymysql'\n  query_string = {\"unix_socket\": f\"/cloudsql/{connection_name}\"}\n\n  db = sqlalchemy.create_engine(\n      sqlalchemy.engine.url.URL(\n          drivername = driver_name,\n          username = db_user,\n          password = db_password,\n          database = schema_name,\n          query = query_string,\n      )\n  )\n  return db\n\n\n# HERE STARTS THE WEATHER DATA RETRIEVAL FUNCTION:\n\ndef extract_city(connection_string):\n    return pd.read_sql(\"cities_info\", con=connection_string)\n\ndef get_weather_data(cities_df):\n  berlin_timezone = timezone(\"Europe/Berlin\")\n  API_key = \"7e5623c79f102b6c08b15c8hjib4cc9l\"    # this is not a real one\n  weather_items = []\n    \n  for city in cities_df[\"city_name\"]:\n    url = (f\"http://api.openweathermap.org/data/2.5/forecast?q={city}\u0026appid={API_key}\u0026units=metric\")\n    response = requests.get(url)\n    json = response.json()\n\n    # Added the time retrieved so we know when the forecast was made\n    retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    # As we are now using the data from our relational database, the city should reflect the city_id and not the city name\n    city_id = cities_df.loc[cities_df[\"city_name\"] == city, \"city_id\"].values[0]  # here we need to retrieve the values, otherwise it shows us the series\n\n    for item in json[\"list\"]:\n        weather_item = {\n            # Added the city name, so the information is clear when looking at multiple cities\n            \"city_id\": city_id,\n            \"forecast_time\": item.get(\"dt_txt\", None),\n            \"temperature\": item[\"main\"].get(\"temp\", None),\n            \"feels_like\": item[\"main\"].get(\"feels_like\", None),\n            \"forecast\": item[\"weather\"][0].get(\"main\", None),\n            \"humidity\": item[\"main\"].get(\"humidity\", None),\n            \"rain_in_last_3h\": item.get(\"rain\", {}).get(\"3h\", 0),\n            \"risk_of_rain\": item[\"pop\"],\n            \"snow_in_last_3h\": item.get(\"snow\", {}).get(\"3h\", 0),      \n            \"wind_speed\": item[\"wind\"].get(\"speed\", None),\n            \"data_retrieved_at\": retrieval_time\n        }\n\n        weather_items.append(weather_item)\n  \n  weather_df = pd.DataFrame(weather_items)\n  weather_df[\"forecast_time\"] = pd.to_datetime(weather_df[\"forecast_time\"])\n  weather_df[\"data_retrieved_at\"] = pd.to_datetime(weather_df[\"data_retrieved_at\"])\n  weather_df[\"snow_in_last_3h\"] = pd.to_numeric(weather_df[\"snow_in_last_3h\"], downcast=\"float\")\n\n  return weather_df\n\ndef insert_into_weather(connection_string):\n  cities_df = extract_city(connection_string)\n  weather_df = get_weather_data(cities_df)    # we create the new dataframe using the function\n  weather_df.to_sql(\"weather\", \n            if_exists=\"append\",\n            con=connection_string,\n            index=False)\n```\n\n## Lessons learned from making our code cloud-worthy\n\n### 1. Dependencies:\n\nWe need to add the right dependencies to the `requirements.txt` file. This was one of the main initial reasons preventing our code from working properly. It is important to note that some libraries are already uploaded on GCP by default and should not be included in the `.txt` file, but still need to be added as a library in our source code, e.g.:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom pytz import timezone\nfrom datetime import datetime\n```\n\n만약 배포를 시도한 후에 빨간 배너 에러가 발생한다면, 대부분의 경우 requirements.txt 파일에 명시되어 있지 않은 라이브러리를 import하는 것이 원인일 수 있습니다:\n\n![image](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_10.png)\n\nrequirements 섹션에서는 Python 모듈이 아닌 패키지만 추가해야 합니다. 미리 알려드리자면, 여기 Python 모듈들의 종합 목록이 있습니다: [Python 모듈 목록](https://docs.python.org/3/py-modindex.html)```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 유용한 팁은 코드에서 사용 중인 모든 외부 라이브러리를 출력하는 것입니다. 노트북에서 함수를 호출한 후에는 다음을 실행해야 합니다:\n\n```js\nprint('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))\n```\n\n그런 다음 적절한 종속성으로 requirements.txt에 직접 복사하여 붙여넣을 수 있습니다:\n\n![이미지](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 프로젝트를 위해 필요한 의존성은 다음과 같습니다 .txt 파일:\n\n```js\nfunctions-framework==3.*\nSQLAlchemy==1.4.37\nPyMySQL==1.0.2\npandas==1.5.2\nrequests==2.31.0\n```\n\n## 2. 연결 코드 테스트\n\n데이터 검색 함수를 추가하기 전에 연결 코드가 작동하는지 먼저 테스트하는 것이 좋습니다. 이렇게 하면 문제가 연결 설정에 있는지 아닌지 확인할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로컬 스크립트를 GCP로 이동할 때 좋은 시작 방법은 \"더미\" 함수를 만들고 테스트하는 것입니다. 예를 들어:\n\n```js\nimport functions_framework\nimport pandas as pd\nimport sqlalchemy\n\n@functions_framework.http\ndef insert(request):\n  connection_string = connection()\n  insert_into_test_table(connection_string)\n  return 'Data successfully added'\n\ndef connection():\n  connection_name = \"YOUR_DB_CON_NAME\"  # 변경해주세요\n  db_user = \"root\"                      # 변경\n  db_password = \"YOUR_PASSWORD\"         # 변경\n  schema_name = \"test_schema\"           # 변경\n\n  driver_name = 'mysql+pymysql'\n  query_string = {\"unix_socket\": f\"/cloudsql/{connection_name}\"}\n\n  db = sqlalchemy.create_engine(\n      sqlalchemy.engine.url.URL(\n          drivername = driver_name,\n          username = db_user,\n          password = db_password,\n          database = schema_name,\n          query = query_string,\n      )\n  )\n  return db\n\ndef insert_into_test_table(con_str):\n  data = {'FirstName': ['Function', 'Test'],\n          'City': ['Cloud', 'Complete']}\n  df = pd.DataFrame(data)\n  df.to_sql(name=\"test_table\", con=con_str, if_exists='append', index=False)\n```\n\n이 간단한 함수가 작동하면 연결이 작동하는 것이고, 할 일은 실제 코드를 추가하고 통합하는 것뿐입니다.\n\n다음 오류가 발생하면 우리의 코드에 문제가 있음을 가정할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3. 우리 실제 코드의 문제점\n\n내 코드를 온라인에 올릴 때 실수한 주요한 부분은 \"더미\" 템플릿을 기반으로 코드를 조정하고 실제로 정의되지 않은 \"insert_into_weather\" 함수를 \"@functions_framework.http\" 아래에서 호출했다는 것이었습니다.\n\n이 함수를 추가한 후에도 코드가 작동하지 않았습니다. 이는 필요한 도시를 수동으로 명명했기 때문에 도시 정보 데이터프레임에서 이미 가져오는 대신에 도시 이름을 수동으로 지정해서 오는 점과 관련이 있었습니다. 그래서 나는 먼저 \"extract_city\"라는 또 다른 함수를 추가해야 했고, 이 함수가 로컬에서 작동하는 것을 확인 후에 코드를 온라인에 배포해야 했습니다.\n\n도시 이름을 얻기 위해 cities_info 테이블을 사용한 후에, 도시 이름을 추출하지 않은 전 반복문을 업데이트하지 않은 다른 실수를 했습니다. 이제 도시 이름을 이전에 목록에서 가져오지 않고 데이터프레임에서 가져와야 했고, 이전 인수로는 도시 이름을 찾지 못했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 마지막 단계\n\n우리 프로젝트를 완전히 기능적이고 자동화하기 위해 주기적으로 실행할 함수를 예약해야 합니다. GCP의 \"Cloud Scheduler\" 메뉴를 사용하면 상당히 쉽습니다.\n\n이를 위해 \"작업 예약\"을 하고 몇 가지 매개변수를 제공하고 빈도를 설정해야 합니다(매주 한 번 또는 Cron 표현식을 사용하여 특정 시간에 특정 요일에 실행하도록 설정). 이렇게 하면 해당 시간에 함수가 실행되어 SQL 테이블에 필요한 데이터를 채웁니다. 예를 들어, 여기서는 매주 월요일 오후 3시에 실행되도록 설정했습니다:\n\n![이미지](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_12.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSQL에서 작동하는지 확인할 수 있어요:\n\n![image](/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_13.png)\n\n첫 번째 SQL-to-Python-to-GCP 프로젝트와 작별하기 전에, 무료 크레딧을 소비하지 않도록 GCP 계정에서 데이터를 삭제해야 해요. 이는 클라우드 인스턴스, 함수 및 예약된 작업을 포함해요.\n\n# 끝\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글을 쓰면서 SQL, Python 및 클라우드 컴퓨팅을 결합한 매우 기본적인 데이터베이스를 구축하는 방법을 배웠어요.\n\n이 프로젝트를 시작할 때 구글 클라우드 플랫폼 또는 다른 클라우드 컴퓨팅 플랫폼에 대해 전혀 알지 몰랐어요. 서버, 호스트, 인스턴스 또는 소프트웨어 연결에 대해 아무것도 모르고 있었어요 (지금도요). SQL과 Python의 기본적인 지식만 있었어요.\n\n이렇게 초보자로 시작했을 때, 자동화된 데이터베이스를 생성하고 주기적으로 가치 있는 데이터로 채우는 일이 너무 어려울 것이라고 회의적이었어요. 이제 내가 할 수 있다는 것을 알게 되었어요!\n\n앞으로의 계획은 다른 API에서 데이터를 가져와 GCP 기능에 결합하여 더 완전하고 유용한 최종 제품을 만들고 싶어해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n글을 쓰는 사람이라고 하더라도 데이터 엔지니어링을 소프트웨어 엔지니어만큼 잘 할 수는 없을 지도 모르겠어요. 하지만 우리는 기초를 배우고 거기서부터 성장할 수 있죠.\n\n# Stackademic 🎓\n\n끝까지 읽어주셔서 감사합니다. 떠나시기 전에:\n\n- 저자를 클랩하시고 팔로우해주시면 감사하겠습니다! 👏\n- 우리를 팔로우해주세요 X | LinkedIn | YouTube | Discord\n- 다른 플랫폼에서도 만나보세요: In Plain English | CoFeed | Venture | Cubed\n- 더 많은 콘텐츠는 Stackademic.com에서 확인하세요","ogImage":{"url":"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png"},"coverImage":"/assets/img/2024-05-18-DataEngineeringisforEngineersNOT_0.png","tag":["Tech"],"readingTime":23},{"title":"오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기","description":"","date":"2024-05-18 18:19","slug":"2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM","content":"\n\n# 소개\n\n데이터 활용의 동적인 풍경에서는 데이터베이스와 손쉽게 상호 작용할 수 있는 능력이 중요합니다. 전통적으로 이 상호 작용은 구조화된 쿼리 언어(SQL)에 대한 심층적인 이해가 필요하여 많은 사용자들에게 진입 장벽이 되었습니다. 그러나 자연어 처리(NLP)를 SQL 쿼리 엔진에 적용하여 이 풍경이 변화되었으며, 이를 통해 사용자들이 자연어 명령을 사용하여 데이터베이스와 소통할 수 있게 되었습니다. 이 첨단 기술은 인간의 언어를 SQL 쿼리로 순조롭게 번역하여 데이터를 검색하고 조작하는 방식을 혁신하고 있습니다.\n\n자연어 처리(NLP)에서 Mistral 7B 및 Microsoft Phi-3과 같은 모델은 주요 역할을 하며 성능과 효율성의 경계를 재정의하고 있습니다.\n\nMistral 7B는 NLP 작업에서 뛰어난 성능과 정밀도로 높이 평가 받고 있습니다. 그룹화된 쿼리 어텐션(GQA) 및 슬라이딩 윈도우 어텐션(SWA)과 같은 혁신적인 기능들을 갖춘 Mistral 7B는 수학 및 코드 생성을 포함한 다양한 벤치마크에서 우수한 성과를 거두고 있습니다. Code-Llama 7B의 코딩 능력에 가까워짐과 동시에 NLP 발전에서의 중요성을 강조하며 다양한 분야에서 우수성을 유지하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPhi-3 는 작은 언어 모델(SLMs) 분야에서의 Microsoft의 최신 혁신으로, AI의 풍경을 변화시키는 대단한 제품입니다. Phi-3-mini, Phi-3-small 및 Phi-3-medium으로 구성된 이 모델군은 간결한 구성으로 뛰어난 성능을 제공합니다. 38억 개의 파라미터를 자랑하는 Phi-3-mini는 더 큰 모델들과 견줄 만한 성능을 발휘하면서도 스마트폰에서 효율적으로 동작합니다. Phi-3의 성공 뒤에는 견고함, 안전성 및 대화 능력을 중시하는 정교하게 선별된 학습 데이터셋이 있습니다. Phi-3-small 및 Phi-3-medium은 Phi-3의 능력을 더욱 확장하여 다양한 응용 분야에 대응합니다. 정교하게 설계된 아키텍처와 학습 방법을 통해 Phi-3은 AI 기술의 큰 발전을 상징하며, 다양한 생성형 AI 작업에 대한 우수한 성능과 효율성을 약속합니다.\n\nNLP와 SQL의 교차점을 탐색하여 Mistral 7B와 Microsoft Phi-3의 활용에 대해 알아봅니다. 이러한 모델들은 자연어 쿼리를 구조화된 SQL 쿼리로 원활하게 변환하여 데이터베이스 쿼리 작업에서 향상된 효율성과 정확도를 제공합니다.\n\n![](/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png)\n\n# 학습 목표\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 블로그 포스트에서는 오픈 소스 Mistral 7B 모델을 NL2SQL 작업에 활용하는 복잡성을 탐색할 것입니다. 또한 NL2SQL 애플리케이션을 위해 모델을 맞춤화하고 훈련하는 방법에 대해 논의할 것입니다. 기사의 나머지 부분은 다음과 같은 내용을 다룹니다.\n\n# 동기부여\n\n오픈 소스 LLMs를 활용하면 자연어 명령을 SQL 쿼리로 변환하는 복잡한 프로세스를 실행할 수 있습니다. 이 혁신적인 기술은 사용자가 수동 쿼리 작성 없이 데이터 요구 사항을 자연스럽게 표현하도록 자동화하며, 이로써 사용자의 입력을 분석하고 의미론적으로 정확한 SQL 쿼리를 생성하는 복잡한 알고리즘과 대규모 언어 모델이 활용됩니다. 이는 변환 프로세스를 간소화시키고 광범위한 사용자들에게 광범위한 SQL 지식이 없어도 데이터를 이용할 수 있게 합니다. 오픈 소스 LLMs는 편리함을 제공하며 데이터 접근성과 운영 효율성을 크게 향상시킵니다. SQL 전문 지식의 장벽을 제거함으로써 이 기술은 데이터 접근성을 민주화시키고 각 분야의 사용자들이 데이터를 검색하고 통찰을 얻는 데 도움을 줍니다. 실시간 통찰을 찾는 비즈니스 분석가나 데이터 집합을 탐색하는 일반 사용자를 위한 것이든, 자연어 명령의 직관적인 성격은 데이터 검색을 간단하게 합니다.\n\n또한 이러한 모델에서 내재된 자동화는 쿼리 실행을 가속화하여 전반적인 효율성과 생산성을 높입니다. 오픈 소스 LLMs의 영향력은 광범위하며 다양한 산업 전반에 혁신과 변화를 격려합니다. 이 기술은 재무, 건강 관리 및 전자 상거래 분야와 같이 데이터 주도적 의사 결정이 중요한 분야에서 이해하기 쉬운 인사이트를 추출할 수 있도록 이해권자를 돕습니다. 더 나아가, 고급 분석 플랫폼과 인공 지능 시스템과의 통합을 통해 조직을 데이터 주도적 우수성으로 이끕니다. 탐구 문화를 육성하고 데이터 상호작용을 간소화함으로써 오픈 소스 LLMs는 데이터 자산의 모든 잠재력을 발휘함으로써 산업 전반에 혁신과 성장을 촉진합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1. NL2SQL을 위한 사전 훈련 모델 (Mistral 7B)\n\nMistral AI가 개발한 70억 개의 파라미터를 가진 언어 모델인 Mistral 7B는 인공 지능 분야에서 강력한 모델로 빠르게 인기를 얻고 있습니다.\n\n- 기본 모델로 위치 지정된 Mistral 7B는 자연어 처리에서 중요한 역할을 하는 가장 중요한 구조적 모델로 자리 잡았으며 대규모 언어 모델 환경 내에서 필수적인 코어 빌딩 블록의 중요성을 보여줍니다.\n- 건축적 접근 방식으로 차별화된 Mistral 7B는 빠른 추론을 위해 그룹화된 쿼리 어텐션 (GQA)과 긴 시퀀스를 효율적으로 처리하기 위한 슬라이딩 윈도우 어텐션 (SWA)과 같은 혁신적인 기능을 활용하여 우수한 성능을 발휘합니다.\n- 주로 영어에 초점을 맞추지만 코딩 능력도 갖춘 Mistral 7B는 특히 다른 모델들보다 더 넓은 컨텍스트에서 텍스트를 이해하고 생성할 수 있는 높은 문맥 윈도우를 가지고 있어 두각을 나타냅니다.\n- 73억 개의 파라미터로 인상적인 Mistral 7B는 최신 언어 모델을 대표하는데, Apache 2.0 라이센스 하에 제한 없이 사용할 수 있습니다.\n- Mistral 7B는 모든 평가된 벤치마크에서 최고의 오픈 13B 모델 (Llama-2)보다 우수한 성과를 거두며 최고의 34B 모델 (Llama-1)보다 추론평가, 수학 및 코드 생성에서 뛰어난 성능을 보여줍니다.\n- Mistral-7B는 Llama2-13B보다 우수한 성능을 보이며 CodeLlama-7B와 경쟁력 있는 성과를 보이며 특히 추론, 수학 및 코드 생성 벤치마크에서 뛰어납니다.\n- 더 큰 모델들에 비해 크기는 작지만, Mistral 7B는 텍스트 요약, 분류, 텍스트 완성 및 코드 완성을 포함한 다양한 자연어 작업에서 우수한 성과를 거둡니다.\n- 이 모델이 자연어 쿼리를 구조화된 SQL 명령어로 변환하는 효과를 탐색하여 능력을 자세히 살펴봅시다.\n\n## Sliding Window Attention\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Mistral 7B은 전통적인 주의 메커니즘에서 발생하는 도전에 효과적으로 대처할 수 있는 슬라이딩 윈도우 어텐션(Sliding Window Attention, SWA) 메커니즘을 포함하고 있습니다. 전자는 토큰 수가 증가함에 따라 추론 중 지연 시간이 증가하고 처리량이 감소할 수 있으며, 시퀀스 길이와 메모리와 관련된 연산이 이차적으로 증가하고 메모리가 선형적으로 증가할 수 있습니다. 반면에 SWA는 각 토큰의 주의를 이전 레이어의 W개 토큰을 최대한으로 제한하여 주어진 윈도우 크기 W를 넘어서 주의를 확장합니다.\n- SWA는 트랜스포머의 계층 구조를 활용하여 위치 i의 숨겨진 상태가 입력 레이어의 토큰을 W x k 토큰까지 액세스할 수 있도록 지원합니다. 최종 레이어에서 W = 4096의 윈도우 크기로, SWA는 이론적으로 대략 131K 토큰의 주의 범위를 달성할 수 있습니다. 실제적으로 W = 4096 및 FlashAttention과 xFormers의 최적화 기법을 사용하여, 16K 토큰 시퀀스의 경우 바닐라 주의 기준에 비해 주목할만한 2배의 속도 향상이 가능합니다. 따라서, SWA는 주의 메커니즘의 성능을 혁신적으로 향상시킬 수 있는 강력하고 효율적인 접근 방식입니다.\n\n### b. 롤링 버퍼 캐시\n\n- 롤링 버퍼 캐시를 구현함으로써, Mistral 7B는 고정된 주의 범위를 전략적으로 사용하여 캐시 크기를 효과적으로 제어합니다. 이 캐시는 W로 표시된 고정된 크기로, 캐시 내에서 특정 시간 단계 i에서 시간 단계 i mod W에 키와 값들을 효율적으로 저장합니다. 시퀀스가 진행되고 i가 W를 초과할 때, 캐시는 롤링 버퍼 메커니즘을 사용하여 이전 값들을 덮어쓰고 무한정으로 확장되는 것을 방지합니다. W = 3으로 설명된 이 접근 방식은 32k 토큰 시퀀스에 대해 8배의 캐시 메모리 사용량 감소를 실현함으로써, 모델의 품질을 희생하지 않고 달성합니다. 고정된 주의 범위는 효율적인 메모리 이용을 보장할 뿐만 아니라 Mistral 7B가 길이가 다른 시퀀스를 처리하는 데에 원활하게 기능하는 데에 기여합니다.\n\n### c. 사전 채움 및 청크 분할\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 시퀀스 생성 과정에서는 문맥 정보에 기반하여 순차적으로 토큰을 예측하는데, (k, v) 캐시를 사용하여 효율적으로 최적화됩니다. 알려진 프롬프트로 미리 채워진 캐시를 활용하여 효율성을 높입니다. 긴 프롬프트를 관리하기 위해 지정된 윈도우 크기를 사용하여 작은 청크로 나누고, 각 청크를 사용하여 캐시를 미리 채웁니다. 이 전략적 접근 방식은 시퀀스 생성 프로세스 중 캐시 내부 및 현재 청크 전체에서 주의력을 계산하는 것을 포함합니다. 이 방법을 활용함으로써 Mistral 7B는 시퀀스 생성의 효율성을 향상시키며, 캐시에 저장된 미리 알려진 프롬프트를 효율적으로 활용하여 각 예측된 토큰을 이전 토큰과 조화롭게 정렬합니다.\n- 언어 모델의 동적인 환경에서 Mistral 7B의 등장은 성능과 효율성 면에서 큰 도약을 의미합니다. 포괄적인 평가 파이프라인을 통해 Mistral 7B는 자신의 능력을 입증하며, 이전 제품인 Llama 2 7B 및 Llama 2 13B뿐만 아니라 Llama 1 34B와 같은 핵심 벤치마크에서 뛰어난 성능을 보여줌으로써 뛰어난 경쟁력을 나타냅니다.\n- Mistral 7B의 우월성은 모든 측정 항목에 걸쳐 명백히 드러나며, 해당 분야의 선도주자로서의 지위를 재확인합니다. 다양한 벤치마크에 대한 면밀한 재평가 과정은 Mistral 7B의 탁월한 능력을 일관되게 입증하며, 경쟁사를 뒤로 남깁니다.\n\n## 크기 및 효율성 분석\n\n- Mistral 7B의 매력 중요 요소 중 하나는 혁신적인 \"동등한 모델 크기\" 계산 방식을 통한 효율성입니다. 추론, 이해 및 STEM 추론 등에서 평가한 결과, Mistral 7B는 세 배 이상 크기의 Llama 2 모델과 동등한 성능을 보여줍니다. 이 효율성은 과도한 매개변수 부담 없이 뛰어난 결과를 제공할 수 있는 Mistral 7B의 능력을 입증합니다.\n- Mistral 7B의 효율성을 더 자세히 살펴보면, 평가 결과에서 지식 압축에 대한 흥미로운 통찰력을 확인할 수 있습니다. 지식 벤치마크에서 1.9배 낮은 압축률을 달성하지만, 이는 Mistral 7B의 의도적으로 제한된 매개변수 수에 기인합니다. 이 제한은 저장된 지식 양을 제한하지만, Mistral 7B는 집중하고 효과적으로 매개변수를 활용하여 보상합니다.\n\n# 평가의 차이점\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n불일치 사항을 투명하게 다루면서, 평가 규정의 변화를 유의하는 것이 중요합니다. 어떤 벤치마크에서는 Llama 2의 MBPP와 Mistral 7B의 평가 결과 사이에 차이가 발생합니다. TriviaQA에서 손으로 검증된 데이터를 사용하는 것이 Mistral 7B의 성능 지표의 신뢰성에 기여하는 강건한 평가 과정을 확인하게 됩니다.\n\n# 데이터셋\n\n아래 열로 구성된 구조 데이터베이스를 사용할 계획입니다. 다음 테이블에서 다양한 검색을 수행할 것입니다.\n\n```js\ntransaction = [\n        \"transaction_id\",\n        \"transaction_amount\",\n        \"transaction_date\",\n        \"transaction_type\",\n        \"transaction_status\",\n        \"transaction_description\",\n        \"transaction_source_account\",\n        \"transaction_destination_account\",\n        \"transaction_currency\",\n        \"transaction_fee\"\n    ]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 코드 구현\n\n- 패키지 설치하기\n\n```js\n!pip install git+https://github.com/huggingface/transformers.git \n!pip install deepspeed --upgrade\n!pip install accelerate\n!pip install sentencepiece\n!pip install langchain\n!pip install torch\n!pip install bitsandbytes\n``` \n\n2. 패키지 불러오기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport os\nimport re\nimport torch\nfrom difflib import SequenceMatcher\nfrom langchain.chains import LLMChain\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n```\n\n3. 모델 불러오기\n\n```js\nbase_model = LlamaForCausalLM.from_pretrained(\n     \"mistralai/Mistral-7B-Instruct-v0.1\",\n     load_in_8bit=True,\n     device_map='auto',\n    )\ntokenizer = LlamaTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\npipe = pipeline(\n        \"text-generation\",\n        model=base_model,\n        tokenizer=tokenizer,\n        max_length=500,\n        temperature=0.3,\n        top_p=0.95,\n        repetition_penalty=1.2\n    )\nlocal_llm = HuggingFacePipeline(pipeline=pipe)\n```\n\n4. SequenceMatcher\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 Python 함수는 difflib 모듈의 SequenceMatcher 클래스를 활용하여 쿼리와 지정된 사전의 열 이름 간의 유사도 점수를 계산하여 쿼리 이해력과 대체를 향상시킵니다.\n\n```js\ndef find_columns_match(question, input_dict):\ntry:\n  question_list = re.split(r'\\s|,|\\.', question)\n  for index, string2 in enumerate(question_list):\n    for string1 in input_dict.get('table1_columns'):\n      score = SequenceMatcher(None,string1.lower(), string2.lower()).ratio()*100\n      if score \u003e 91:\n        question_list[index] = string1 + \",\"\n  return \" \".join(question_list)\n  \nexcept:\n return question\n```\n\n이 Python 함수 query_generator은 제공된 테이블명, 열 목록 및 질문에 기반하여 SQL 쿼리를 생성합니다. 이는 템플릿 문자열을 활용하여 쿼리 생성 프로세스를 구조화하며, 테이블 명, 열 목록 및 질문에 대한 자리 표시자를 포함합니다. 그런 다음 PromptTemplate 객체를 사용하여 이러한 자리 표시자를 채워넣고 LLMChain을 통해 대형 언어 모델 (LLM)과 상호 작용하여 SQL 쿼리를 생성합니다. 마지막으로 생성된 SQL 쿼리를 출력합니다.\n\n```js\ndef query_generator(tble, cols, question):\n\n  template = \"\"\"Generate a SQL query using the following table name: {Table}, and columns as a list: {Columns}, to answer the following question:\n  {question}.\n  \n  Output Query:\n  \n  \"\"\"\n  \n  prompt = PromptTemplate(template=template, input_variables=[\"Table\", \"question\", \"Columns\"])\n  \n  llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n  \n  response = llm_chain.run({\"Table\": tble, \"question\": question, \"Columns\": cols})\n  print(response)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 표\n\n\ntransaction = [\n        \"transaction_id\",\n        \"transaction_amount\",\n        \"transaction_date\",\n        \"transaction_type\",\n        \"transaction_status\",\n        \"transaction_description\",\n        \"transaction_source_account\",\n        \"transaction_destination_account\",\n        \"transaction_currency\",\n        \"transaction_fee\"\n    ]\n\n    inputs = [\"transaction_id가 10인 경우 transaction_amount, transaction_date, transaction_type,transaction_description을 검색하는 SQL 쿼리 생성\",\n             \"transaction_status가 'completed'인 경우 transaction_id, transaction_date, transaction_type, transaction_source_account을 검색하는 SQL 쿼리 생성\",\n             \"transaction_type 및 평균 transaction_amount의 개수를 검색하고 transaction_type로 정렬하는 SQL 쿼리 생성\",\n             \"각 소스 계정별 총 거래 금액 목록을 검색하고 총 거래 금액을 내림차순으로 정렬하는 SQL 쿼리 생성\",\n             \"각 거래 유형별 최대 거래 금액을 검색하고 거래 유형으로 정렬하는 SQL 쿼리 생성\"]\n\n    for input in inputs:\n        query_generator(\"transaction\",transaction ,question=find_columns_match(input,transaction))\n\n\n# 응답\n\n- 다음과 같은 테이블 이름을 사용하고 컬럼을 나열한 리스트를 사용하여 SQL 쿼리를 생성하십시오: transaction 및 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’], 다음 질문에 대한 응답을 위해 SQL 쿼리를 생성하십시오: (‘transaction_id가 10인 경우 transaction_amount, transaction_date, transaction_type,transaction_description을 검색하는 SQL 쿼리 생성’).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n출력 쿼리: \n\n  SELECT transaction_amount, transaction_date, transaction_type, transaction_description FROM transaction WHERE transaction_id = 10;\n```\n\n2. 다음과 같은 테이블 이름인 transaction과 열 목록인 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’]을 사용하여 다음 질문에 대한 SQL 쿼리를 생성하십시오:\n(‘transaction_status가 ‘completed’인 경우 transaction_id, transaction_date, transaction_type, transaction_source_account를 검색하는 SQL 쿼리를 생성하십시오’).\n\n```js\n출력 쿼리:\n  SELECT transaction_id, transaction_date, transaction_type, transaction_source_account FROM transaction WHERE transaction_status = 'completed'\n```\n\n3. 다음과 같은 테이블 이름인 transaction과 열 목록인 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’]을 사용하여 다음 질문에 대한 SQL 쿼리를 생성하십시오:\n(‘transaction_type의 count와 평균 transaction_amount를 가져오고 transaction_type으로 정렬하십시오’).```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n결과 쿼리:\n\n  SELECT transaction_type, AVG(transaction_amount) AS avg_transaction_amount, COUNT(*) AS total_count\n  FROM transaction\n  GROUP BY transaction_type\n  ORDER BY transaction_type;\n```\n\n4. 다음 테이블 이름과 열 목록을 사용하여 SQL 쿼리를 생성하십시오: transaction 및 열: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], 다음 질문에 답하십시오:\n(‘리스트에서 각 소스 계정의 총 거래 금액을 내림차순으로 정렬하여 조회하는 SQL 쿼리를 생성하세요’).\n\n```js\n결과 쿼리:\n\n       SELECT transaction_source_account, SUM(transaction_amount) AS TotalTransactionAmount\n        FROM transaction\n        GROUP BY transaction_source_account\n        ORDER BY TotalTransactionAmount DESC;\n```\n\n5. 다음 테이블 이름과 열 목록을 사용하여 SQL 쿼리를 생성하십시오: transaction 및 열: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], 다음 질문에 답하십시오:\n(‘각 거래 유형의 최대 거래 금액을 찾아 거래 유형으로 정렬하는 SQL 쿼리를 생성하세요’).```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n출력 쿼리:\n\n   SELECT transaction_type, MAX(transaction_amount) AS max_transaction_amount\n   FROM transaction\n   GROUP BY transaction_type\n   ORDER BY transaction_type;\n```\n\n일반적인 추출은 효과적이지만, 연구 결과, 데이터를 세부 조정하여 LLM을 수행하면 우수한 결과를 얻을 수 있습니다. 세밀 조정 접근법을 채용해 봅시다.\n\n# 2 Fine-tune NL2SQL with Phi-3\n\nPhi-3를 만나보세요, Microsoft의 최신 오픈 AI 모델의 주요 성과입니다. Phi-3-mini, Phi-3-small 및 Phi-3-medium을 통해, 이 작은 언어 모델 (SLM)의 Phi-3 패밀리는 AI 모델의 세계를 혁신하도록 설계되었습니다. 38억 개의 파라미터를 사용하고 33조 개의 토큰으로 훈련된 Phi-3-mini는 높은 성능을 발휘하며 Mixtral 8x7B 및 GPT-3.5와 같은 큰 모델과 같은 성능을 보여줍니다. 게다가, 이 모델은 스마트폰 장치에서 효율적으로 작동할 수 있습니다. Phi-3의 성공은 훈련 데이터셋에 기인합니다. Phi-2의 데이터셋의 진화된 버전입니다. 상세히 걸러낸 웹 데이터 및 합성 입력을 통해 이러한 모델은 강도, 안전 및 대화 능력에 우선순위를 두어 다양한 응용프로그램에 적합합니다. 7B 및 14B 파라미터를 가진 Phi-3-small 및 Phi-3-medium은 효율 유지와 함께 Phi-3의 기능을 더욱 향상시키도록 설계되었습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Phi 3 Architecture and Evaluation\n\nPhi-3 패밀리는 품질과 비용을 균형있게 유지하도록 설계된 다양한 모델을 제공하여 생성형 AI 애플리케이션을 개발하는 고객을 위한 옵션을 제공합니다.\n\nPhi-3-mini: 이 모델은 38억 개의 파라미터를 갖추고 33조 개의 토큰으로 이루어진 광범위한 데이터셋을 기반으로 훈련되었습니다. 32개의 레이어, 32개의 어텐션 헤드, 그리고 3072개의 히든 디멘션을 갖는 트랜스포머 디코더 아키텍처를 채택했습니다. 디폴트 콘텍스트 길이는 4천 개의 토큰이며, 32K 어휘 사전을 사용하는 토크나이저를 활용합니다. 추가로, 128K 토큰의 콘텍스트 길이를 갖춘 확장 버전인 Phi-3-mini-128K도 있습니다.\n\nPhi-3-small: 70억 개의 파라미터로 훈련된 Phi-3-small은 48조 개의 토큰을 사용합니다. 이 모델은 100K 어휘 사전과 8천 개의 디폴트 콘텍스트 길이를 갖추었습니다. 아키텍처는 32개의 레이어, 32개의 어텐션 헤드, 그리고 4096개의 히든 디멘션으로 이루어져 있습니다. 이 모델은 메모리 사용량을 최적화하기 위해 그룹화된 쿼리 어텐션과 번갈아가며 쓰이는 밀집/희소 어텐션을 활용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPhi-3-medium: 이 미리보기 모델은 140억 개의 매개변수를 자랑하며 4.8조 개의 토큰으로 학습되었습니다. 40개의 레이어, 40개의 어텐션 헤드, 그리고 임베딩 크기는 5120입니다.\n\n## 훈련 방법:\n\n- 훈련 데이터 구성: Phi-3 모델의 훈련 데이터는 신중하게 선별됩니다. 교육 수준별로 분류된 웹 데이터와 합성 LLM 생성 데이터로 구성되며 두 가지 이질적이고 순차적인 단계로 사전 훈련을 거칩니다.\n- 사전 훈련 단계: 제1 단계는 일반 지식과 언어 이해에 중점을 둔 웹 소스를 사용합니다. 제2 단계는 논리 추론 및 특정 기술을 가르치기 위해 제1 단계의 웹 데이터와 합성 데이터를 더 많이 활용합니다.\n- 사후 훈련 단계: 사전 훈련 후, Phi-3-mini는 감독형 세밀 조정 (SFT) 및 직접 선호도 최적화 (DPO)를 거쳤습니다. SFT는 수학, 코딩, 추론, 대화, 모델 신원, 안전 도메인 간에 높은 품질의 데이터를 선별하는 과정을 포함합니다.\n- DPO는 채팅 형식 데이터, 추론, 그리고 책임 있는 AI 노력에 초점을 맞춥니다.\n- 맥락 확장: Phi-3-mini의 맥락 창 크기가 Long Rope 방법론을 사용하여 4k 토큰에서 128k 토큰으로 확장되었습니다. 이 확장은 맥락의 길이가 크게 증가함에도 일관된 성능을 유지합니다.\n- 데이터 최적화: 훈련 데이터는 모델의 규모를 위한 \"데이터 최적\" 지점으로 보정됩니다. 웹 데이터는 지식과 추론의 적절한 균형을 보장하기 위해 필터링됩니다. 특히 작은 모델의 경우 이는 매우 중요합니다.\n- 다른 모델과의 비교: Phi-3의 접근 방식은 이전 작업과 대조적으로, 해당 규모에 대한 데이터 품질에 중점을 두며 컴퓨팅이나 과도한 훈련 방법보다 데이터 최적화를 강조합니다. 벤치마크 비교는 Phi-3가 작은 모델 용량을 위한 최적화를 잘 보여줍니다.\n- Phi-3-medium 미리보기: 140억 개의 매개변수를 가진 Phi-3-medium은 Phi-3-mini와 유사하게 훈련되었지만 더 큰 규모로 이루어집니다. 일부 벤치마크에서는 7B에서 14B 매개변수로의 전환에서 큰 개선이 없어 계속해서 데이터 혼합을 개선 중임을 시사합니다.\n- 사후 향상: 모델은 채팅 능력, 견고성, 그리고 안전성을 향상시키기 위해 감독형 세밀 조정 및 DPO를 통한 선호도 조정을 거칩니다.\n\n## 안전성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPhi-3-mini은 Microsoft의 책임 있는 AI 원칙에 따라 만들어진 AI 모델입니다. 이 프로젝트는 개발 초기부터 안전을 우선시하는 원칙을 중요시하여 만들어졌습니다. 모델이 윤리 기준을 준수하고 잠재적인 피해를 최소화할 수 있는 능력을 보장하기 위해 포괄적인 전략이 채택되었습니다.\n\n모델 학습 후에는, 해당 모델이 책임 있는 AI 기준을 충족하는지 확인하기 위해 면밀한 안전 조정이 이루어집니다. 게다가, Microsoft의 독립된 레드 팀이 Phi-3-mini를 검토하여 강화 및 안전 프로토콜을 강화할 수 있는 부분을 식별합니다.\n\n자동화된 테스팅과 잠재적인 피해의 다양한 범주에 대한 평가는 프로세스의 중요한 부분입니다. 이러한 테스트는 모델의 출력물로부터 발생하는 모든 위험을 감지하고 해결하는 데 목표를 두고 있습니다.\n\n더 나아가, Phi-3-mini는 의견 데이터 세트를 활용하여 응답을 더욱 개선합니다. 특정 테스트 중 확인된 잠재적인 피해 범주에 대응하기 위해 내부에서 생성된 데이터 세트가 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 코드 구현\n\n- 패키지 설치\n\n```js\n !pip install -q -U bitsandbytes\n !pip install -q -U transformers\n !pip install -q -U xformers\n !pip install -q -U peft\n !pip install -q -U accelerate\n !pip install -q -U datasets\n !pip install -q -U trl\n !pip install -q -U einops\n !pip install -q -U nvidia-ml-py3\n !pip install -q -U huggingface_hub\n```\n\n2. 패키지 가져오기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling\nfrom pynvml import *\nimport time, torch\nfrom trl import SFTTrainer\nfrom peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\nfrom peft import AutoPeftModelForCausalLM\n```\n\n3. 데이터셋 불러오기\n\n```python\ndataset = load_dataset(\"b-mc2/sql-create-context\")\ndataset\n```\n\n4. 데이터셋 형식화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef create_prompt(sample):\n      system_prompt_template = \"\"\"\u003cs\u003e\n            아래는 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n            ### 지시사항: \u003c\u003cuser_question\u003e\u003e\n            ### 데이터베이스 스키마:\n            \u003c\u003cdatabase_schema\u003e\u003e\n            ### 응답:\n            \u003c\u003cuser_response\u003e\u003e\n            \u003c/s\u003e\n            \"\"\"\n      user_message = sample['question']\n      user_response = sample['answer']\n      database_schema = sample['context']\n      prompt_template = system_prompt_template.replace(\"\u003c\u003cuser_question\u003e\u003e\",f\"{user_message}\").replace(\"\u003c\u003cuser_response\u003e\u003e\",f\"{user_response}\").replace(\"\u003c\u003cdatabase_schema\u003e\u003e\",f\"{database_schema} \")\n\n      return {\"inputs\":prompt_template}\n\n\ninstruct_tune_dataset = dataset.map(create_prompt)\nprint(instruct_tune_dataset)\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU 메모리 사용량: {info.used//1024**2} MB.\")\n```\n\n5. 토크나이저와 모델 로드\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n# 토크나이저 로드\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n# fp16로 모델 로드\nmodel = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, device_map={\"\": 0})\nprint(print_gpu_utilization())\n```\n\n6. 모델 추론\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n# 프롬프트 정의\n\n\n```bash\n    prompt = [\n        \"코코넛 밀크로 만든 치킨 카레 레시피를 작성해주세요.\",\n        \"다음 문장을 프랑스어로 번역해주세요: '나는 빵과 치즈를 좋아해요!'\",\n        \"유명한 20명의 인물을 인용해보세요.\",\n        \"지금 달은 어디에 있나요?\"\n    ]\n\n    # 변수 초기화\n    duration = 0.0\n    total_length = 0\n\n    # 프롬프트 반복\n    for i in range(len(prompt)):\n        # 프롬프트 토큰화 및 GPU로 이동\n        inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n\n        # 입력 텐서 인덱스를 torch.long으로 변환\n        inputs = {k: v.to(torch.long) for k, v in inputs.items()}\n\n        # 시작 시간\n        start_time = time.time()\n\n        # 자동 캐스팅을 사용하여 추론 수행\n        with torch.cuda.amp.autocast(enabled=False):  # 자동 캐스팅 비활성화\n            output = model.generate(**inputs, max_length=500)\n\n        # 소요 시간과 총 길이 계산\n        duration += float(time.time() - start_time)\n        total_length += len(output)\n\n        # 프롬프트당 토큰 속도 계산\n        tok_sec_prompt = round(len(output) / float(time.time() - start_time), 3)\n\n        # 프롬프트당 토큰 속도 출력\n        print(\"프롬프트 --- %s 토큰/초 ---\" % (tok_sec_prompt))\n\n        # 디코드된 출력 출력\n        print(tokenizer.decode(output[0], skip_special_tokens=True))\n\n    # 평균 토큰 속도 계산\n    tok_sec = round(total_length / duration, 3)\n    print(\"평균 --- %s 토큰/초 ---\" % (tok_sec))\n```\n\n9. Fine-tuning되지 않은 Text to SQL\n\n```bash\n    prompt = [\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        각 도시의 역 중 가장 높은 위도를 가진 역순으로 모든 도시를 나열하십시오.\n        데이터베이스 스키마:\n        CREATE TABLE station (city VARCHAR, lat INTEGER)\n        ### 응답:\n        SELECT city, lat FROM station ORDER BY lat DESC;\n        \"\"\",\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        '각 선수가 20점 이상 및 10점 미만을 가지고 있으며 상위 10위 안에 있는 포지션은 무엇입니까?\n        데이터베이스 스키마:\n        CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\n        ### 응답:\n        SELECT POSITION, Points, Ranking\n        FROM player\n        WHERE Points \u003e 20 AND Points \u003c 10 AND Ranking IN (1,2,3,4,5,6,7,8,9,10)\n        \"\"\",\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        노래를 가장 많이 연주한 밴드 맴버의 이름을 찾아보세요.\n        데이터베이스 스키마:\n        CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)\n        ### 응답:\n        SELECT b.firstname\n        FROM Band b\n        JOIN Performance p ON b.id = p.bandmate\n        GROUP BY b.firstname\n        ORDER BY COUNT(*) DESC\n        LIMIT 1;\n        \"\"\"\n    ]\n\n    for i in range(len(prompt)):\n      model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n      start_time = time.time()\n      output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n      duration += float(time.time() - start_time)\n      total_length += len(output)\n      tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n      print(\"프롬프트 --- %s 토큰/초 ---\" % (tok_sec_prompt))\n      print(print_gpu_utilization())\n      print(tokenizer.decode(output, skip_special_tokens=False))\n\n    tok_sec = round(total_length/duration,3)\n    print(\"평균 --- %s 토큰/초 ---\" % (tok_sec))\n\n    # Fine-tuning\n\n    base_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n    tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_eos_token=True, use_fast=True, max_length=250)\n    tokenizer.padding_side = 'right'\n    tokenizer.pad_token = tokenizer.eos_token\n\n    compute_dtype = getattr(torch, \"float16\") # Ampere (또는 최신) GPU를 사용하는 경우 bfloat16로 변경\n    bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=compute_dtype,\n            bnb_4bit_use_double_quant=True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n              base_model_id, trust_remote_code=True, quantization_config=bnb_config, revision=\"refs/pr/23\", device_map={\"\": 0}, torch_dtype=\"auto\", flash_attn=True, flash_rotary=True, fused_dense=True\n    )\n    print(print_gpu_utilization())\n\n    model = prepare_model_for_kbit_training(model)\n```\n\n10. LoRA 매개변수\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\npeft_config = LoraConfig(\n            lora_alpha=16,\n            lora_dropout=0.05,\n            r=16,\n            bias=\"none\",\n            task_type=\"CAUSAL_LM\",\n          target_modules=[\n            'q_proj',\n            'k_proj',\n            'v_proj',\n            'dense',\n            'fc1',\n            'fc2',\n        ])\n```\n\n9. Training Parameters\n\n```js\ntraining_arguments = TrainingArguments(\n            output_dir=\"./phi3-results\",\n            save_strategy=\"epoch\",\n            per_device_train_batch_size=4,\n            gradient_accumulation_steps=12,\n            log_level=\"debug\",\n            save_steps=100,\n            logging_steps=25,\n            learning_rate=1e-4,\n            eval_steps=50,\n            optim='paged_adamw_8bit',\n            fp16=True, #change to bf16 if are using an Ampere GPU\n            num_train_epochs=1,\n            max_steps=400,\n            warmup_steps=100,\n            lr_scheduler_type=\"linear\",\n            seed=42)\n```\n\n10. Data Prepare for the training\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntrain_dataset = instruct_tune_dataset.map(batched=True, remove_columns=['answer', 'question', 'context'])\ntrain_dataset\n```\n\n11. Fine-Tuned\n\n```js\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset[\"train\"],\n    #eval_dataset=dataset['test'],\n    peft_config=peft_config,\n    dataset_text_field=\"inputs\",\n    max_seq_length=1024,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False\n)\n\ntrainer.train()\n```\n\n12. Test inference with the fine-tuned adapter\n \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n\ncompute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=True,\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n          base_model_id, trust_remote_code=True, quantization_config=bnb_config, device_map={\"\": 0}\n)\nadapter = \"/content/phi3-results/checkpoint-400\"\nmodel = PeftModel.from_pretrained(model, adapter)\n```\n\n13. 수행하기\n\n```js\ndatabase_schema = 'CREATE TABLE station (city VARCHAR, lat INTEGER)'\nuser_question = \"List all the cities in a decreasing order of each city's stations' highest latitude.\"\n\nprompt_template = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{user_question}\nDatabase Schema:\n{database_schema}\n### Response:\n\"\"\"\n\nquestion = \"'What are the positions with both players having more than 20 points and less than 10 points and are in Top 10 ranking\"\ncontext = \"CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\"\n\nprompt_template1 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\ncontext = '''CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)'''\nquestion = \"Find the first name of the band mate that has performed in most songs.\"\n\nprompt_template2 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\nprompt = []\nprompt.append(prompt_template)\nprompt.append(prompt_template1)\nprompt.append(prompt_template2)\n\nfor i in range(len(prompt)):\n  model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n  start_time = time.time()\n  output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n  duration += float(time.time() - start_time)\n  total_length += len(output)\n  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n  print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n  print(print_gpu_utilization())\n  print(tokenizer.decode(output, skip_special_tokens=False))\n\ntok_sec = round(total_length/duration,3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n14. 모델 저장하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport locale\nimport shutil\nfrom huggingface_hub import notebook_login\nfrom google.colab import drive\n\n# Set the preferred encoding to UTF-8\nlocale.getpreferredencoding = lambda: \"UTF-8\"\n\n# Log in to the notebook\nnotebook_login()\n\n# Push the fine-tuned adapter to the Hugging Face Hub\ntrainer.push_to_hub(commit_message=\"fine-tuned adapter\")\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# Move the trained model to Google Drive\nshutil.move('/content/phi3-results', '/content/drive/MyDrive/PHI-3')\n\n# Load the trained model\ntrained_model = AutoPeftModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/checkpoint-400\",\n                                                         low_cpu_mem_usage=True,\n                                                         return_dict=True,\n                                                         torch_dtype=torch.float16,\n                                                         device_map='auto',)\n\n# Merge and unload the trained model\nlora_merged_model = trained_model.merge_and_unload()\n\n# Save the merged model\nlora_merged_model.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\", safe_serialization=True)\n\n# Save the tokenizer for the merged model\ntokenizer.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\")\n\n# Push the merged model to the Hugging Face Hub\nlora_merged_model.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n\n# Push the tokenizer to the Hugging Face Hub\ntokenizer.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n```\n\n15. Perform Inference on Fine-tuned Model\n\n```js\npeft_config = LoraConfig(\n            lora_alpha=16,\n            lora_dropout=0.05,\n            r=16,\n            bias=\"none\",\n            task_type=\"CAUSAL_LM\",\n    )\n\npeft_model_id = \"username/phi3-results\"\nconfig = peft_config.from_pretrained(peft_model_id)\n\nmodel = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n                                             return_dict=True,\n                                             load_in_4bit=True,\n                                             device_map=\"auto\",\n                                             )\n\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n\nmodel = PeftModel.from_pretrained(model, peft_model_id)\n\nprint(model.get_memory_footprint())\n\nfor i in range(len(prompt)):\n    model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n    start_time = time.time()\n    output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n    duration += float(time.time() - start_time)\n    total_length += len(output)\n    tok_sec_prompt = round(len(output)/float(time.time() - start_time), 3)\n    print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n    print(print_gpu_utilization())\n    print(f\"RESPONSE:\\n {tokenizer.decode(output, skip_special_tokens=False)[len(prompt[i]):].split('\u003c/')[0]}\")\n\ntok_sec = round(total_length/duration, 3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n# Conclusion\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자연어 처리(NLP)와 SQL 쿼리 엔진의 결합은 데이터베이스와 상호 작용하는 것을 더 쉽고 효율적으로 만들었습니다. 이전에는 SQL에 대한 심층적인 이해가 필요했기 때문에 많은 사용자들에게 어려움이 있었습니다. 그러나 Mistral 7B와 Microsoft Phi-3와 같은 오픈 소스 대형 언어 모델(LLMs)은 이를 바꿨습니다. 이 모델들은 자연어 쿼리를 구조화된 SQL 쿼리로 신속하게 변환하여, 방대한 SQL 전문 지식이 필요 없게 했습니다.\n\nMistral 7B와 Microsoft Phi-3는 NLP 작업에서 우수한 성능을 발휘하는 탁월한 모델들입니다. 그들은 Grouped-Query Attention과 Sliding Window Attention과 같은 기능을 갖추어 더욱 효율적입니다. 크기가 작은 Microsoft Phi-3도 NLP 성능과 효율성에서 새로운 기준을 세우며, 복잡한 벤치마크에서 더 큰 모델들을 능가합니다.\n\n오픈 소스 LLMs를 고급 분석 플랫폼과 AI 시스템에 통합함으로써 기업은 손쉽게 통찰을 추출할 수 있습니다. 이 기술은 금융, 건강 관리, 전자 상거래와 같은 산업들이 데이터 기반 결정을 내리는 방식을 변화시켰습니다. 이러한 모델들이 다양한 부문에 미치는 영향은 상당하며 혁신과 변혁을 촉진했습니다.\n\nNLP와 SQL의 융합을 통해 오픈 소스 LLMs는 데이터 접근을 민주화시키고 효율성, 생산성, 기업 성공을 촉진했습니다. 이는 데이터 자산의 최대 잠재력을 발휘하도록 허용하여 이해당사자들이 실행 가능한 통찰을 추출하기 쉬워지고, 여러 부문에서 탐구와 혁신의 문화를 육성했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노트북: phi3\n\n제 이전 📝 글들을 확인해주세요.\n\n# 참고 자료\n\n- https://arxiv.org/pdf/2310.06825.pdf\n- https://artgor.medium.com/paper-review-mistral-7b-6acdf2f3132d\n- https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580\n- https://www.datacamp.com/tutorial/mistral-7b-tutorial\n- https://www.analyticsvidhya.com/blog/2023/11/from-gpt-to-mistral-7b-the-exciting-leap-forward-in-ai-conversations/\n- https://medium.com/@rubentak/mistral-7b-the-best-7-billion-parameter llm-yet-8b0aa03016f9\n- https://clarifai.com/mistralai/completion/models/mistral-7B-Instruc\n- https://iamgeekydude.com/2023/06/02/alpaca-llm-load-model-using-langchain-hf/\n- https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/\n- https://huggingface.co/microsoft/Phi-3-mini-128k-instruct","ogImage":{"url":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"},"coverImage":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png","tag":["Tech"],"readingTime":32},{"title":"LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법","description":"","date":"2024-05-18 18:18","slug":"2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit","content":"\n\nThe Advent of LLMs shows the ability of machines to comprehend natural language. These capabilities have helped engineers to do a lot of amazing things, such as writing code documentation and code reviews, and one of the most common use cases is code generation; GitHub copilot has shown the capability of AI to comprehend engineers’ intention for code generation, such as Python, Javascript, and SQL, though LLM’s comprehension AI could understand what we want to do and generate code accordingly.\n\n# Using LLM to solve Text-to-SQL\n\nBased on the code generation capability of LLMs, many people have started considering using LLMs to solve the long-term hurdle of using natural language to retrieve data from databases, sometimes called “Text-to-SQL.” The idea of “Text-to-SQL” is not new; after the presence of “Retrieval Augmented Generation (RAG)” and the latest LLM models breakthrough, Text-to-SQL has a new opportunity to leverage LLM comprehension with RAG techniques to understand internal data and knowledge. \n\n![Top 4 Challenges using RAG with LLMs to Query Database Text-to-SQL and how to solve it](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# RAG를 사용한 텍스트-SQL의 도전 과제\n\n텍스트-SQL 시나리오에서 사용자는 LLM이 생성한 결과를 신뢰하기 위해 정밀도, 보안 및 안정성을 갖추어야합니다. 그러나 실행 가능하고 정확하며 보안이 제어된 텍스트-SQL 솔루션을 추구하는 것은 간단하지 않습니다. 여기에서는 자연어를 통해 데이터베이스를 쿼리하기 위해 RAG를 사용한 LLM 사용의 네 가지 주요 기술적 도전 과제를 요약해보았습니다: 컨텍스트 수집, 검색, SQL 생성 및 협업.\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_1.png)\n\n## 도전 과제 1: 컨텍스트 수집 도전과제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 다양한 원본 간 상호 운용성: 다양한 소스, 메타데이터 서비스 및 API 간에 원활하게 검색 및 통합된 정보를 일반화하고 표준화하는 것이 중요합니다.\n- 데이터와 메타데이터의 복잡한 링킹: 이는 데이터를 해당 문서 저장소의 메타데이터와 연결하는 것을 포함합니다. 관련성, 계산 및 집계와 같은 메타데이터, 스키마 및 컨텍스트를 저장하는 것이 포함됩니다.\n\n## 도전 과제 2: 검색 도전과제\n\n- 벡터 저장소의 최적화: 인덱싱 및 청킹과 같은 벡터 저장소를 최적화하기 위한 기술을 개발하고 구현하는 것은 검색 효율성과 정확도 향상에 중요합니다.\n- 의미 검색의 정확도: 도전 과제는 질의 이해의 뉘앙스에 있으며 이는 결과의 정확도에 중대한 영향을 미칠 수 있습니다. 이는 일반적으로 쿼리 재작성, 다시 순위 지정 등과 같은 기술을 포함합니다.\n\n## 도전 과제 3: SQL 생성 도전과제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- SQL 쿼리의 정확성 및 실행 가능성: 정확하고 실행 가능한 SQL 쿼리를 생성하는 것은 상당한 도전입니다. 이를 위해서는 LLM이 SQL 구문, 데이터베이스 스키마, 그리고 다양한 데이터베이스 시스템의 특정 방언에 대한 깊은 이해가 필요합니다.\n- 쿼리 엔진 방언 적응: 데이터베이스는 종종 SQL 구현에서 고유한 방언과 뉘앙스를 가집니다. 이러한 차이에 적응하고 다양한 시스템 간에 호환되는 쿼리를 생성할 수 있는 LLM을 설계하는 것은 도전의 복잡도를 더 높이는 요소입니다.\n\n## 도전 4: 협업 도전\n\n- 집단 지식 축적: 도전은 다양한 사용자 그룹으로부터 수집된 집단적인 통찰과 피드백을 효과적으로 수집, 통합, 그리고 활용하여 LLM이 검색하는 데이터의 정확성과 관련성을 향상하는 메커니즘을 만드는 데에 있습니다.\n- 접근 제어: 데이터를 검색하는 것에 대한 다음으로 중요한 도전은 존재하는 조직 데이터 접근 정책 및 개인정보 보호 규정이 새로운 LLM 및 RAG 아키텍처에도 적용되도록 보장하는 것입니다.\n\n더 많은 정보를 원하시나요? 각 도전에 대해 미래 게시물에서 자세히 공유할 계획입니다. 알림을 받으려면 Medium에서 팔로우해주세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 어떻게 문제를 해결할 수 있을까요? LLM을 위한 의미론적 레이어.\n\n위의 과제들을 해결하기 위해서, 우리는 LLM과 데이터 소스 사이에 레이어가 필요합니다. 이 레이어를 통해 LLM이 비즈니스 의미론과 메타데이터를 데이터 소스로부터 학습할 수 있게 되며, 이 레이어는 종종 \"의미론적 레이어\"라고 불리는 것이 필요합니다. 의미론적 레이어는 의미론과 데이터 구조 간의 연결을 해결하고, 액세스 제어와 식별 관리를 조정하여 정확한 사용자만이 정확한 데이터에 액세스하도록 보장해야 합니다.\n\nLLM을 위한 의미론적 레이어에는 무엇이 포함되어야 할까요? 여기서 몇 가지 측면으로 일반화해봅시다.\n\n## 데이터 해석 및 표현\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 비즈니스 용어 및 개념: 시맨틱 레이어는 비즈니스 용어와 개념의 정의를 포함합니다. 예를 들어, \"수익\"과 같은 용어는 시맨틱 레이어에 정의되어 있어서 비즈니스 사용자가 BI 도구에서 \"수익\"을 조회할 때 시스템이 어떤 데이터를 검색하고 어떻게 계산할지 정확히 알고 있습니다.\n\n- 데이터 관계: 이것은 서로 다른 데이터 엔티티 간의 관계를 정의합니다. 예를 들어, 고객 데이터가 판매 데이터와 어떻게 관련되는지 또는 제품 데이터가 재고 데이터와 연결되는 방법 등이 있습니다. 이러한 관계는 복잡한 분석을 수행하고 통찰을 얻는 데 중요합니다.\n\n- 계산 및 집계: 시맨틱 레이어에는 종종 미리 정의된 계산 및 집계 규칙이 포함됩니다. 이는 사용자가 예를 들어 금년 매출을 계산하기 위해 복잡한 수식을 작성하는 방법을 알 필요가 없다는 것을 의미합니다. 시맨틱 레이어는 내부 데이터 원본을 기반으로 이러한 작업을 정의 및 규칙에 따라 처리합니다.\n\n## 데이터 액세스 및 보안\n\n- 보안 및 액세스 제어: 이것은 누가 어떤 데이터에 액세스할 수 있는지를 관리할 수도 있습니다. 사용자가 액세스 권한을 부여받은 데이터만 볼 수 있고 분석할 수 있도록 보장하여 데이터 프라이버시를 유지하고 규정을 준수하는 데 중요합니다.\n\n## 데이터 구조 및 조직\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 데이터 소스 매핑: 시맨틱 레이어는 비즈니스 용어와 개념을 실제 데이터 소스에 매핑합니다. 이는 각 비즈니스 용어에 해당하는 데이터베이스 테이블과 열을 지정하고, BI 도구가 올바른 데이터를 검색할 수 있도록 합니다.\n- 다차원 모델: 일부 BI 시스템에서 시맨틱 레이어에는 다차원 모델(예: OLAP 큐브)이 포함되어 복잡한 분석과 데이터 슬라이싱/다이싱이 가능합니다. 이러한 모델은 사용자가 쉽게 탐색하고 분석할 수 있는 차원과 측정 값을 구성합니다.\n\n## 메타데이터\n\n- 메타데이터 관리: 메타데이터를 관리합니다. 이는 데이터에 대한 데이터로서, 데이터 원본, 변환, 데이터 계보 등 데이터를 이해하는 데 도움이 되는 모든 정보가 포함됩니다.\n\n# WrenAI 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_2.png)\n\nWrenAI는 오픈 소스입니다. 데이터, LLM API 및 환경 어디에서든 WrenAI를 배포할 수 있습니다. 직관적인 온보딩 및 사용자 인터페이스가 함께 제공되어 몇 분 안에 데이터소스에서 데이터 모델을 연결하고 구축할 수 있습니다.\n\nWrenAI의 하부에는 이전 섹션에서 언급한 LLM을 위한 \"Wren Engine\"이라는 프레임워크를 개발했습니다. Wren Engine은 GitHub에서도 오픈 소스로 제공됩니다. Wren Engine에 관심이 있다면 댓글을 남겨주시기 바랍니다. 앞으로 나올 글에서 아키텍처와 디자인에 대해 더 자세히 공유할 계획입니다.\n\n## WrenAI에서의 모델링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 소스와 연결이 완료되면 자동으로 모든 메타데이터를 수집하며 WrenAI UI를 통해 비즈니스 의미론과 관계를 추가할 수 있습니다. 미래의 의미론적 검색을 위해 자동으로 벡터 저장소를 업데이트할 것입니다.\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_3.png)\n\n## 질문하고 따라가기\n\n모델링을 마치고 나면 비즈니스 질문을 시작할 수 있습니다. WrenAI는 가장 관련성 높은 결과 3개를 찾아 제공할 것입니다. 옵션 중 하나를 선택하면 해당 데이터의 출처 및 요약을 단계별 설명으로 제공해 드립니다. 이를 통해 WrenAI가 제안하는 결과를 더 자신 있게 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWrenAI로부터 결과를 받으면 반환된 결과를 기반으로 깊은 통찰이나 분석을 위한 후속 질문을 할 수 있습니다.\n\n![image](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_4.png)\n\n## 지금 GitHub에서 WrenAI를 사용해보고 커뮤니티에 참여해보세요!\n\n👉 GitHub: https://github.com/Canner/WrenAI\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n👉 디스코드: https://discord.gg/5DvshJqG8Z","ogImage":{"url":"/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png"},"coverImage":"/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png","tag":["Tech"],"readingTime":6},{"title":"장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini","description":"","date":"2024-05-18 18:15","slug":"2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics","content":"\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBigQuery 워크로드 내에서 Gemini 1.0 Pro (텍스트 전용) 및 Gemini 1.0 Pro Vision (멀티모달) 두 가지 LLM 모델을 통합하는 흥미로운 기술을 시연하겠습니다. 이를 통해 Low-code 생성적 인사이트 생성 경험을 제공할 수 있습니다. BigQuery에서 원격 모델 엔드포인트로 지원되는 모델인 Gemini 1.0 Pro와 같이, 데이터베이스 쿼리 내에서 모델을 호출하기 위해 ML.GENERATE_TEXT 구조를 직접 사용할 수 있습니다. 기본적으로 원격 모델로 사용할 수 없거나 생성적 AI 호출에 더 많은 사용자 정의가 필요한 경우 (또는 데이터베이스 내에서 원격으로 액세스하려는 API가 있는 경우), REMOTE FUNCTIONS 접근 방식을 사용할 수 있습니다. 두 시나리오를 모두 다루기 위해 블로그 글을 2개의 섹션으로 나눠서 설명하겠습니다:\n\n## #1 원격 모델 호출:\n\n- 이 섹션은 SELECT 쿼리에서 ML.GENERATE_TEXT를 사용하여 BigQuery 내에서 Gemini 1.0 Pro를 호출하는 방법을 안내합니다.\n- 모델이 이미 BigQuery의 원격 모델로 사용 가능하고 기본 제공으로 사용하려는 경우에 이 접근 방법을 사용할 수 있습니다. 사용하려는 모델의 상태를 이 설명서에서 확인할 수 있습니다.\n- 안내 사례:\n\n인터넷 아카이브 책 데이터셋(공개적으로 BigQuery에서 사용 가능)에 대한 위치 요약기를 구축하며, BigQuery에서 Gemini 1.0 Pro의 원격 모델을 ML.GENERATE_TEXT 구조를 통해 호출하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_1.png\" /\u003e\n\n## #2 원격 함수 구현:\n\n- 이 섹션에서는 Gemini 1.0 Pro Vision을 구현한 클라우드 함수를 호출하는 방법에 대해 안내합니다. 이 클라우드 함수는 BigQuery에서 원격 함수로 노출됩니다.\n- 사용하려는 모델이 원격 모델로 제공되지 않거나 사용 사례에서 더 많은 유연성 및 사용자 정의가 필요한 경우 이 접근 방식을 사용하십시오.\n- 안내용 사용 사례:\n\n기준 이미지와 테스트 이미지를 비교하는 이미지 유효성 검사기를 구축합니다. 이를 위해 외부 테이블에 테스트 이미지 스샷을 포함하는 데이터 세트를 만들고 Gemini 1.0 Pro Vision에 대해 확인하도록 요청합니다. 이를 위해 Gemini Pro Vision 호출을 구현한 Java 클라우드 함수를 만들고 이를 BigQuery에서 원격 함수로 호출합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_2.png\" /\u003e\n\n# BigQuery\n\nBigQuery은 서버리스, 멀티 클라우드 데이터 웨어하우스로, 바이트부터 페타바이트까지 최소한의 운영 오버헤드로 확장이 가능합니다. 이것은 ML 트레이닝 데이터를 저장하기에 좋은 선택지가 됩니다. 내장된 BigQuery Machine Learning (BQML)과 분석 기능을 통해 SQL 쿼리만 사용하여 노코드 예측을 생성할 수 있습니다. 게다가, 페더레이티드 쿼리로 외부 소스에서 데이터에 접근할 수 있어 복잡한 ETL 파이프라인이 필요하지 않습니다. BigQuery가 제공하는 모든 것에 대해 BigQuery 페이지에서 자세히 읽어볼 수 있습니다. 우리는 텍스트 요약 사례에 사용되는 원격 모델을 호출하기 위해 BigQuery ML의 ML.GENERATE_TEXT 구조를 사용할 것입니다.\n\n우리는 BigQuery를 구조적 및 반구조적 데이터를 분석하는 데 도움이 되는 완전 관리형 클라우드 데이터 웨어하우스로 알고 왔습니다. BigQuery는 비정형 데이터에서 모든 분석 및 ML을 수행할 수 있도록 확장되었습니다. 우리는 이미지 데이터를 저장하기 위해 객체 테이블을 사용할 것이며, Gemini Pro Vision 모델을 사용하여 이미지 유효성을 검증하는 원격 기능 사례에 필요한 데이터를 저장할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 데모\n\n이 블로그의 나머지 부분에서는 위에서 설명한 유즈 케이스 섹션에 자세히 기술된 실제 예제로 두 가지 유즈 케이스를 모두 시연하겠습니다. 유즈 케이스별 구현에 들어가기 전에 두 가지 유즈 케이스에 필요한 사전 설정 및 공통 단계를 완료해 봅시다.\n\n# 설정\n\n- Google Cloud Console에서 프로젝트 선택기 페이지에서 Google Cloud 프로젝트를 선택하거나 만듭니다.\n- 클라우드 프로젝트에 청구가 활성화되어 있는지 확인하십시오. 프로젝트에 청구가 활성화되어 있는지 확인하는 방법을 알아보세요.\n- Google Cloud에서 미리 로드된 bq를 실행하는 명령줄 환경인 Cloud Shell을 사용할 것입니다. Cloud 콘솔에서 오른쪽 상단의 'Cloud Shell 활성화'를 클릭하세요.\n- 애플리케이션 구축 및 제공을 위한 지원을 위해서, Duet AI를 활성화해 봅시다. Duet AI Marketplace로 이동하여 API를 활성화하세요. 또는 Cloud Shell 터미널에서 다음 명령을 실행할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```\n```js\ngcloud services enable cloudaicompanion.googleapis.com –project PROJECT_ID\n```\n\n5. 이미 하지 않았다면, 이 구현을 위해 필요한 API를 활성화하세요.\n\nBigQuery, BigQuery Connection, Vertex AI, Cloud Storage APIs\n\ngcloud 명령어 대신 이 링크를 사용하여 콘솔을 통해 진행할 수도 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# BigQuery Dataset과 외부 연결 생성하기\n\nBigQuery 데이터셋은 애플리케이션의 모든 테이블과 객체를 포함하는 컨테이너입니다. BigQuery 연결은 Cloud Function과 상호작용하는 데 사용됩니다. 원격 함수를 생성하려면 BigQuery 연결을 만들어야 합니다. 데이터셋과 연결을 생성하는 방법을 알아보겠습니다.\n\n- Google Cloud Console에서 BigQuery 페이지로 이동한 후 프로젝트 ID 옆에 있는 3개 수직 점 아이콘을 클릭하세요. 나타나는 옵션 중에서 “데이터 집합 만들기”를 선택하세요.\n- “데이터 집합 만들기” 팝업에서 아래와 같이 데이터 집합 ID를 “gemini_bq_fn”로 입력하고 지역 값을 기본 값인 “US (다중 지역…)”으로 설정하세요. \n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. BigLake Connection을 사용하면 외부 데이터 원본에 연결할 수 있으면서 세밀한 BigQuery 액세스 제어와 보안을 유지할 수 있습니다. 우리의 경우에는 Vertex AI Gemini Pro API를 사용합니다. 우리는 이 연결을 사용하여 Cloud Function을 통해 BigQuery의 모델에 액세스할 것입니다. 아래 단계를 따라 BigLake Connection을 만들어보세요:\n\na. BigQuery 페이지의 탐색기 창에서 ADD를 클릭하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_4.png)\n\nb. 소스 페이지에서 외부 데이터 원본에 대한 연결을 클릭하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nc. 팝업창에 아래 외부 데이터 원본 세부정보를 입력하고 CREATE CONNECTION을 클릭하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_5.png)\n\nd. 연결이 생성되면, 연결 구성 페이지로 이동하여 액세스 권한 부여를 위한 서비스 계정 ID를 복사하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\ne. IAM 및 관리 페이지를 열고 액세스 부여를 클릭한 후 새 주체 탭에 서비스 계정 ID를 입력하고 아래에 표시된 역할을 선택한 다음 저장을 클릭하세요.\n\n![그림](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_7.png)\n\n# Use case #1 Remote Model Invocation\n\n여기서는 Vertex AI Gemini Pro foundation 모델을 기반으로 BigQuery에 모델을 만들 것입니다. 이미 데이터 세트와 연결 설정이 완료되었습니다. 이제 3단계만으로 Gemini Pro 모델의 원격 모델 호출을 시연합니다. SQL 쿼리만 사용하여 LLM 애플리케이션이 가동됩니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 테이블 및 모델 생성\n\n인터넷 아카이브 도서 데이터셋을 예시로 들어서 BigQuery에서 공개로 사용할 수 있도록 소스로 가져왔다고 가정해봅시다.\n\n## BigQuery 테이블 생성\n\n위의 예제로부터 공개적으로 이용 가능한 BigQuery 데이터셋에서 약 50개의 레코드를 보유할 수 있는 테이블을 생성해봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBigQuery SQL 에디터 창에서 다음과 같이 DDL (데이터 정의 언어) 문을 실행해보세요:\n\n```sql\ncreate or replace table gemini_bq_fn.books as (\nselect *\nfrom\nbigquery-public-data.gdelt_internetarchivebooks.1905 limit 50);\n```\n\n이 쿼리는 이전에 생성한 데이터셋에 \"books\" 라는 새로운 테이블을 생성합니다.\n\n## BigQuery 모델 생성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델을 생성하려면 BigQuery SQL 편집기 창에서 다음 DDL을 실행하세요:\n\n```js\nCREATE MODEL `gemini_bq_fn.gemini_remote_model`\nREMOTE WITH CONNECTION `us.gemini-bq-conn`\nOPTIONS(ENDPOINT = 'gemini-pro');\n```\n\n모델이 생성되었음을 확인하고 방금 생성된 모델을 볼 수 있는 옵션이 제공됩니다.\n\n## 새로운 생성 AI 애플리케이션을 테스트해보세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그것이에요! 이제 ML.GENERATE_TEXT 문을 사용하여 새로 생성한 생성 모델을 테스트해 보겠습니다.\n\n```js\nSELECT ml_generate_text_llm_result as Gemini_Response, prompt as Prompt\nFROM ML.GENERATE_TEXT(MODEL `gemini_bq_fn.gemini_remote_model`,\n  (select '텍스트 요약기와 표준화기를 당신은 개발했어요. 주소 정보를 포함한 다음 텍스트에서 표준화하고 하나의 표준화된, 통합된 주소를 출력해야 합니다. 빈 값으로 반환해서는 안 됩니다. 왜냐하면 이 필드의 텍스트에서 합리적인 데이터를 가져오는 방법을 알기 때문이에요: ' ||\nsubstring(locations, 0, 200) as prompt\nfrom `gemini_bq_fn.books`),\nSTRUCT(\n  TRUE AS flatten_json_output));\n```\n\n다음 결과가 표시되어야 합니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_8.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우와! 이렇게 쉽게 BigQuery ML에서 데이터베이스의 원격 모델을 사용할 수 있어요.\n\n이제 다른 Vertex AI 모델을 사용해 빅쿼리 원격 함수를 시도해봅시다. 예를 들어, 빅쿼리에서 원격으로 모델을 사용하는 방법을 더 맞춤화하고 유연하게 사용하고 싶다고 가정해봅시다. 현재 지원되는 모델은 이 문서에서 참조할 수 있어요.\n\n# 사용 사례 #2 원격 함수 구현\n\n여기서는 Gemini 1.0 Pro Vision foundation 모델을 구현하는 Java Cloud Function을 기반으로 빅쿼리에서 함수를 생성할 거에요. 먼저 Gemini 1.0 Pro Vision 모델을 사용해 이미지를 비교하기 위해 Java Cloud Function을 생성하고 배포하고, 그 다음에는 빅쿼리에서 배포된 Cloud Function을 호출하는 원격 함수를 생성할 거에요. 기억해 주세요, 빅쿼리에서의 원격 함수 실행에 대해 동일한 절차를 따를 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Java 클라우드 함수 만들기\n\nGen 2 클라우드 함수를 Java로 생성하여 외부 테이블에 저장된 베이스라인 이미지와 테스트 이미지를 비교하는 기능을 구축할 것입니다. 이 작업은 BigQuery의 테스트 이미지 스크린샷이 포함된 데이터셋을 사용하며 Gemini Pro Vision 모델 (Java SDK)을 이용하여 REST 엔드포인트에 배포됩니다.\n\n# Java 클라우드 함수\n\n- Cloud Shell 터미널을 열고 루트 디렉토리나 기본 작업 공간 경로로 이동합니다.\n- 상태 표시줄의 왼쪽 하단에 있는 Cloud Code 로그인 아이콘을 클릭하고 Cloud Functions을 생성할 Google Cloud 프로젝트를 선택합니다.\n- 다시 아이콘을 클릭하고 이번에는 새 응용 프로그램을 만드는 옵션을 선택합니다.\n- \"새 응용 프로그램 생성\" 팝업에서 Cloud Functions 응용 프로그램을 선택합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image1](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_9.png)\n\n5. Select the \"Java: Hello World\" option from the next pop-up:\n\n![image2](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_10.png)\n\n6. Provide a name for the project in the project path. In this case, it is \"Gemini-BQ-Function\".\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n7. 새로운 Cloud Shell Editor 보기에서 프로젝트 구조가 열린 것을 확인해야합니다:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_11.png)\n\n8. 이제 pom.xml 파일의 `dependencies`...`/dependencies` 태그 안에 필요한 종속성을 추가해주세요.\n\n```xml\n\u003cdependency\u003e\n      \u003cgroupId\u003ecom.google.cloud\u003c/groupId\u003e\n      \u003cartifactId\u003egoogle-cloud-vertexai\u003c/artifactId\u003e\n      \u003cversion\u003e0.1.0\u003c/version\u003e\n   \u003c/dependency\u003e\n\n     \u003cdependency\u003e\n      \u003cgroupId\u003ecom.google.code.gson\u003c/groupId\u003e\n      \u003cartifactId\u003egson\u003c/artifactId\u003e\n      \u003cversion\u003e2.10\u003c/version\u003e\n     \u003c/dependency\u003e\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n9. \"HelloWorld.java\" 클래스의 이름을 더 의미 있는 이름인 \"GeminiBigQueryFunction.java\"로 변경하세요. 클래스 이름을 이에 맞게 변경해야 합니다.\n\n10. 아래 코드를 복사하고 파일 \"GeminiBigQueryFunction.Java\"의 플레이스홀더 코드를 대체하세요. Github 레포지토리에서 소스를 참조해주세요.\n\n```js\npackage cloudcode.helloworld;\nimport java.io.BufferedWriter;\nimport com.google.cloud.functions.HttpFunction;\nimport com.google.cloud.functions.HttpRequest;\nimport com.google.cloud.functions.HttpResponse;\nimport com.google.cloud.vertexai.VertexAI;\nimport com.google.cloud.vertexai.api.Blob;\nimport com.google.cloud.vertexai.api.Content;\nimport com.google.cloud.vertexai.generativeai.preview.ContentMaker;\nimport com.google.cloud.vertexai.api.GenerateContentResponse;\nimport com.google.cloud.vertexai.api.GenerationConfig;\nimport com.google.cloud.vertexai.api.Part;\nimport com.google.cloud.vertexai.generativeai.preview.PartMaker;\nimport com.google.cloud.vertexai.generativeai.preview.GenerativeModel;\nimport com.google.cloud.vertexai.generativeai.preview.ResponseStream;\nimport com.google.cloud.vertexai.generativeai.preview.ResponseHandler;\nimport com.google.protobuf.ByteString;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Base64;\nimport java.util.List;\nimport java.util.Arrays;\nimport java.util.Map;\nimport java.util.LinkedHashMap;\nimport com.google.gson.Gson;\nimport com.google.gson.JsonObject;\nimport com.google.gson.JsonArray;\nimport java.util.stream.Collectors;\nimport java.lang.reflect.Type;\nimport com.google.gson.reflect.TypeToken;\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.net.HttpURLConnection;\nimport java.net.URL;\n\n\npublic class GeminiBigQueryFunction implements HttpFunction {\n    private static final Gson gson = new Gson();\n\n\n  public void service(final HttpRequest request, final HttpResponse response) throws Exception {\n    final BufferedWriter writer = response.getWriter();\n   // 요청 본문을 JSON 객체로 가져옵니다.\n    JsonObject requestJson = new Gson().fromJson(request.getReader(), JsonObject.class);\n    JsonArray calls_array = requestJson.getAsJsonArray(\"calls\");\n    JsonArray calls = (JsonArray) calls_array.get(0);\n    String baseline_url = calls.get(0).toString().replace(\"\\\"\", \"\");\n    String test_url = calls.get(1).toString().replace(\"\\\"\", \"\");\n    String prompt_string = calls.get(2).toString().replace(\"\\\"\", \"\");\n    String raw_result = validate(baseline_url, test_url, prompt_string);\n    raw_result = raw_result.replace(\"\\n\",\"\");\n    String trimmed = raw_result.trim();\n    List\u003cString\u003e result_list = Arrays.asList(trimmed);\n    Map\u003cString, List\u003cString\u003e\u003e stringMap = new LinkedHashMap\u003c\u003e();\n    stringMap.put(\"replies\", result_list);\n    // 직렬화\n    String return_value = gson.toJson(stringMap);\n    writer.write(return_value);\n  }\n\n\npublic String validate(String baseline_url, String test_url, String prompt_string) throws IOException{\n  String res = \"\";\n    try (VertexAI vertexAi = new VertexAI(\"YOUR_PROJECT\", \"us-central1\"); ) {\n      GenerationConfig generationConfig =\n          GenerationConfig.newBuilder()\n              .setMaxOutputTokens(2048)\n              .setTemperature(0.4F)\n              .setTopK(32)\n              .setTopP(1)\n              .build();          \n    GenerativeModel model = new GenerativeModel(\"gemini-pro-vision\", generationConfig, vertexAi);\n    String context = prompt_string;    \n    Content content = ContentMaker.fromMultiModalData(\n     context,\n     PartMaker.fromMimeTypeAndData(\"image/png\", readImageFile(baseline_url)),\n     PartMaker.fromMimeTypeAndData(\"image/png\", readImageFile(test_url))\n    );\n    GenerateContentResponse response = model.generateContent(content);\n     res = ResponseHandler.getText(response);\n  }catch(Exception e){\n    System.out.println(e);\n  }\n  return res;\n}\n\n\n  // 지정된 URL의 이미지 데이터를 읽어옵니다.\n  public static byte[] readImageFile(String url) throws IOException {\n    URL urlObj = new URL(url);\n    HttpURLConnection connection = (HttpURLConnection) urlObj.openConnection();\n    connection.setRequestMethod(\"GET\");\n    int responseCode = connection.getResponseCode();\n    if (responseCode == HttpURLConnection.HTTP_OK) {\n      InputStream inputStream = connection.getInputStream();\n      ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n      byte[] buffer = new byte[1024];\n      int bytesRead;\n      while ((bytesRead = inputStream.read(buffer)) != -1) {\n        outputStream.write(buffer, 0, bytesRead);\n      }\n      return outputStream.toByteArray();\n    } else {\n      throw new RuntimeException(\"Error fetching file: \" + responseCode);\n    }\n  }\n}\n```\n\n11. 이제 Cloud Shell 터미널로 이동하여 아래 명령을 실행하여 클라우드 함수를 빌드하고 배포하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ngcloud functions deploy gemini-bq-fn --runtime java17 --trigger-http --entry-point cloudcode.helloworld.GeminiBigQueryFunction --allow-unauthenticated\n```\n\n여기에 결과는 아래와 같은 형식으로 REST URL이 생성됩니다:\n\nhttps://us-central1-YOUR_PROJECT_ID.cloudfunctions.net/gemini-bq-fn\n\n12. 터미널에서 다음 명령을 실행하여 이 클라우드 함수를 테스트해보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ngcloud functions call gemini-bq-fn --region=us-central1 --gen2 --data '{\"calls\":[[\"https://storage.googleapis.com/img_public_test/image_validator/baseline/1.JPG\", \"https://storage.googleapis.com/img_public_test/image_validator/test/2.JPG\", \"PROMPT_ABOUT_THE_IMAGES_TO_GEMINI\"]]}'  \n```\n\n임의의 샘플 프롬프트에 대한 응답:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_12.png\" /\u003e\n\n제네릭 Cloud Function을 사용하여 Gemini Pro Vision 모델 구현이 준비되었습니다. 이제 이 엔드포인트를 직접 BigQuery 원격 함수 내에서 BigQuery 데이터에 사용하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 빅쿼리 오브젝트 테이블 및 원격 함수 만들기\n\n이 데모 애플리케이션에서는 클라우드 스토리지 버킷을 생성해 보겠습니다:\n\n- 클라우드 스토리지 콘솔로 이동하여 생성 버튼을 클릭하여 버킷을 만듭니다.\n- 버킷에 이름을 제공하고 \"demo-bq-gemini-public\"과 같은 이름을 지정한 다음 \"이 버킷에서의 공개 액세스 방지 강화\" 옵션의 선택 해제(공개로 유지)를 기억하세요. 이 데모에서는 이 버킷을 공개 액세스로 설정하고 있지만, 권장하는 방법은 공개 액세스를 방지하고 필요에 따라 특정 서비스 계정에 권한을 부여하는 것입니다.\n- 방금 만든 클라우드 스토리지 버킷의 PERMISSION 탭에서 권한 설정을 보고 변경할 수 있습니다. 원칙을 추가하려면 VIEW BY PRINCIPALS 탭 아래의 GRANT ACCESS를 클릭하고 (특정 계정을 위한) 서비스 계정 ID를 입력하거나 \"allUsers\" (공개 액세스에 대한)를 입력한 후 역할을 \"Storage Object Viewer\"로 설정하고 저장을 클릭합니다.\n- 이제 버킷이 생성되었으므로 OBJECTS 탭으로 이동하여 이미지를 업로드하고 UPLOAD FILES를 클릭하여 업로드하세요.\n- 비교하기 위해 기준 및 테스트 이미지를 업로드하세요.\n\n이 데모를 위해 3개의 객체를 생성하고 기준이고 test1 및 test2를 공개로 사용할 수 있도록 만들었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# BigQuery 객체 테이블 생성\n\nBigQuery에서 외부 객체 테이블을 만들어 생성한 연결 및 데이터셋을 사용하여 버킷의 비구조화된 데이터에 액세스할 수 있습니다. BigQuery 쿼리 에디터 창에서 다음과 같은 DDL(데이터 정의 언어) 문을 실행하세요:\n\n```js\nCREATE OR REPLACE EXTERNAL TABLE `gemini_bq_fn.image_validation`\nWITH CONNECTION `us.gemini-bq-conn`\nOPTIONS(object_metadata=\"SIMPLE\", uris=[\"gs://demo-bq-gemini-public/*.JPG\"]);\n```\n\n이 쿼리는 이전에 만든 데이터셋에 \"image_validation\"이라는 새 객체 테이블을 생성해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# BigQuery 원격 함수 생성\n\nBigQuery에서 Java Cloud Function을 호출하는 원격 함수를 만들어 봅시다. Gemini Pro Vision 모델을 구현한 Java Cloud Function을 호출할 것입니다. 이 함수는 동일한 데이터셋에 만들 것입니다. BigQuery 콘솔의 SQL 편집 창에서 다음 DDL을 실행해 주세요:\n\n```js\nCREATE OR REPLACE FUNCTION `gemini_bq_fn.FN_IMAGE_VALIDATE` (baseline STRING, test STRING, prompt STRING) RETURNS STRING\n  REMOTE WITH CONNECTION `us.gemini-bq-conn`\n  OPTIONS (\n    endpoint = 'https://us-central1-********.cloudfunctions.net/gemini-bq-fn',\n    max_batching_rows = 1\n  );\n```\n\n이렇게 하면 BigQuery에 원격 함수가 생성됩니다. 위의 DDL에는 3개의 매개변수가 있습니다. 처음 두 매개변수는 이전 단계에서 생성된 객체 테이블에 저장된 이미지의 URL입니다. 마지막 매개변수는 모델(Gemini Pro Vision)에 대한 프롬프트입니다. 이 시그니처를 파싱하는 Java Cloud Functions 코드를 참조하시기 바랍니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nGson().fromJson(request.getReader(), JsonObject.class);\nJsonArray calls_array = requestJson.getAsJsonArray(\"calls\");\nJsonArray calls = (JsonArray) calls_array.get(0);\nString baseline_url = calls.get(0).toString().replace(\"\\\"\", \"\");\nString test_url = calls.get(1).toString().replace(\"\\\"\", \"\");\nString prompt_string = calls.get(2).toString();\n```\n\n# BigQuery에서 Gemini 호출하기!\n\n이제 원격 함수가 생성되었으니, 테스트 이미지를 프롬프트와 대조하여 이미지 유효성을 확인하는 원격 함수를 테스트하기 위해 SELECT 쿼리에서 사용해봅시다:\n\n테스트 이미지가 참조와 어떤지 확인하기 위한 쿼리:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nselect gemini_bq_fn.FN_IMAGE_VALIDATE(\n'https://storage.googleapis.com/demo-bq-gemini-public/Baseline.JPG',\nREPLACE(uri, 'gs://', 'https://storage.googleapis.com/') ,\n'전문 이미지 유효성 검사자이며 JSON 결과로 응답할 수 있는 이미지 유효성 검사자입니다. 여기에서 2개의 이미지를 찾을 수 있습니다. 첫 번째 이미지는 기준 이미지이고 두 번째 이미지는 테스트 이미지입니다. 두 번째 이미지가 첫 번째 이미지와 텍스트 측면에서 유사한지 확인하세요. \"YES\" 또는 \"NO\"인 SIMILARITY, 백분율인 SIMILARITY_SCORE, 문자열인 DIFFERENCE_COMMENT 3가지 속성이 포함된 JSON 형식으로만 응답하세요.' ) as IMAGE_VALIDATION_RESULT\nfrom `gemini_bq_fn.image_validation`\nwhere uri like '%TEST1%';  \n```\n\n위 쿼리를 TEST1.JPG 및 TEST2.JPG와 함께 시도해보세요. 아래와 유사한 결과를 보게 될 것입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_13.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기준 이미지:\n\n![이미지1](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_14.png)\n\n테스트 이미지:\n\n![이미지2](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_15.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 확인할 수 있듯이, 두 이미지 모두 Duet AI 클라우드 콘솔 뷰를 가지고 있지만, 두 이미지의 텍스트는 모델에 의해 생성된 JSON 형식에 따라 다릅니다.\n\n# 혜택 및 사용 사례\n\n- 데이터에 GenAI를 적용하세요: 데이터 이동, 중복 및 추가 복잡성이 더 이상 필요하지 않습니다. 동일한 BigQuery 환경 내에서 데이터를 분석하고 인사이트를 생성할 수 있습니다.\n- 향상된 분석: Gemini의 자연어 설명은 데이터에 새로운 이해의 층을 더해주며, SQL 쿼리만을 사용하여 이를 달성할 수 있습니다.\n- 확장성: 이 솔루션은 대규모 데이터셋과 복잡한 분석을 쉽고 Low-Code 방식으로 처리할 수 있습니다.\n\n실제 사례: 금융(시장 트렌드 분석), 소매(고객 감정), 의료(의료 보고서 요약) 등 분석 및 비즈니스 팀이 비교적 적은 노력, 자원 및 익숙한 언어 및 도구를 선택하여 이를 구현할 수 있는 시나리오를 고려해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n축하합니다. Gemini 모델이 BigQuery에 통합되어 데이터 분석을 넘어 데이터 이야기꾼이 되셨습니다. 데이터셋 안에 숨겨진 이야기를 찾아내고 통찰력을 이해하는 방법을 변화시킬 수 있습니다. 지금 실험을 시작하세요! 이 기술을 여러분의 데이터셋에 적용하여 데이터 안에 깔려있는 이야기들을 발견해보세요. BigQuery가 객체 테이블(External Tables)에서 비구조적인 데이터를 지원하므로, 이미지 데이터에 대한 생성적 인사이트를 만들기 위해 Gemini Pro Vision을 사용해보세요. 더 깊은 안내를 위해서 Vertex AI, BigQuery Remote Functions 및 Cloud Functions 문서를 참고하세요. 이 프로젝트의 Github 저장소는 여기에 있습니다. 이 학습으로 어떤 것을 구축하시는지 저에게 알려주세요!","ogImage":{"url":"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png"},"coverImage":"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png","tag":["Tech"],"readingTime":19}],"page":"43","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"43"},"buildId":"PgdIX9e0tvkvkdAmDT6qR","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>