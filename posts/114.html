<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/114" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/114" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_buildManifest.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="NodePiece 노드 ID에서 토큰으로" href="/post/2024-05-17-NodePieceFromNodeIDstoTokens"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="NodePiece 노드 ID에서 토큰으로" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="NodePiece 노드 ID에서 토큰으로" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">NodePiece 노드 ID에서 토큰으로</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">42<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="검색 및 분석 혁신 AI 통합으로 강화된 Elasticsearch의 벡터 검색 능력 탐색" href="/post/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="검색 및 분석 혁신 AI 통합으로 강화된 Elasticsearch의 벡터 검색 능력 탐색" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="검색 및 분석 혁신 AI 통합으로 강화된 Elasticsearch의 벡터 검색 능력 탐색" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">검색 및 분석 혁신 AI 통합으로 강화된 Elasticsearch의 벡터 검색 능력 탐색</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="인과 검증 만병 통치제" href="/post/2024-05-17-CausalValidationAUnifiedTheoryofEverything"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="인과 검증 만병 통치제" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="인과 검증 만병 통치제" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">인과 검증 만병 통치제</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">40<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="더블 박사" href="/post/2024-05-17-DoublePhD"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="더블 박사" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-DoublePhD_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="더블 박사" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">더블 박사</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="왜 인공지능이 음악가를 대체할 수 없을까" href="/post/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="왜 인공지능이 음악가를 대체할 수 없을까" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="왜 인공지능이 음악가를 대체할 수 없을까" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">왜 인공지능이 음악가를 대체할 수 없을까</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법" href="/post/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="다음 토큰 예측에서 비롯된 인간과 인공 일반 지능" href="/post/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="다음 토큰 예측에서 비롯된 인간과 인공 일반 지능" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="다음 토큰 예측에서 비롯된 인간과 인공 일반 지능" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">다음 토큰 예측에서 비롯된 인간과 인공 일반 지능</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT-4o는 사이버 보안 분야에서 게임 체인저입니다 하지만 잘못된 이유로요" href="/post/2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT-4o는 사이버 보안 분야에서 게임 체인저입니다 하지만 잘못된 이유로요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT-4o는 사이버 보안 분야에서 게임 체인저입니다 하지만 잘못된 이유로요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ChatGPT-4o는 사이버 보안 분야에서 게임 체인저입니다 하지만 잘못된 이유로요</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="반복 신경망 시퀀스 모델링 소개" href="/post/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="반복 신경망 시퀀스 모델링 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="반복 신경망 시퀀스 모델링 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">반복 신경망 시퀀스 모델링 소개</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ICD 코딩을 위한 LLM 탐험 - 파트 1" href="/post/2024-05-17-ExploringLLMsforICDCodingPart1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ICD 코딩을 위한 LLM 탐험 - 파트 1" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ExploringLLMsforICDCodingPart1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ICD 코딩을 위한 LLM 탐험 - 파트 1" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ICD 코딩을 위한 LLM 탐험 - 파트 1</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/101">101</a><a class="link" href="/posts/102">102</a><a class="link" href="/posts/103">103</a><a class="link" href="/posts/104">104</a><a class="link" href="/posts/105">105</a><a class="link" href="/posts/106">106</a><a class="link" href="/posts/107">107</a><a class="link" href="/posts/108">108</a><a class="link" href="/posts/109">109</a><a class="link" href="/posts/110">110</a><a class="link" href="/posts/111">111</a><a class="link" href="/posts/112">112</a><a class="link" href="/posts/113">113</a><a class="link posts_-active__YVJEi" href="/posts/114">114</a><a class="link" href="/posts/115">115</a><a class="link" href="/posts/116">116</a><a class="link" href="/posts/117">117</a><a class="link" href="/posts/118">118</a><a class="link" href="/posts/119">119</a><a class="link" href="/posts/120">120</a></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"NodePiece 노드 ID에서 토큰으로","description":"","date":"2024-05-17 20:06","slug":"2024-05-17-NodePieceFromNodeIDstoTokens","content":"\n그래프 임베딩에 대한 혁신적인 접근\n\n![이미지](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_0.png)\n\n# 소개\n\n자연어 처리(NLP) 및 대형 언어 모델(LLM)에 대한 관심과 발전이 급증한 것은 잘 알려져 있습니다. “토큰화” 및 “트랜스포머”와 같은 용어들이 어디서든 볼 수 있을 정도입니다. 그러나 그래프 신경망(GNN) 및 특히 지식 그래프 임베딩이라는 또다른 강력한 분야는 전문가들을 제외하고는 훨씬 인기가 적습니다. 이러한 기술들은 추천 시스템에서 링크 예측, 노드 분류 등 다양한 애플리케이션 영역에서 강력한 솔루션을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGNN 세계에서 주목할 만한 기술 중 하나는 NodePiece 토큰화인데, 이견에 따르면 많은 주의를 필요로 합니다. 이 접근 방식은 그래프 신경망의 기능성을 향상시키기 위해 자연어 처리(NLP)에서 여러 개념을 도입한 새로운 방법론입니다. 이 기술은 유니버셜 \"토큰\" 집합을 사용하여 그래프 내 노드를 표현합니다. 이 접근 방식은 미리 정의된 ID 어휘가 필요 없어져 노드의 좀 더 적응적인 표현을 가능케 하며 모델이 다양한 그래프에 대해 일반화할 수 있는 능력을 향상시킵니다.\n\n잠재력이 커도 NodePiece 토큰화 방법론은 널리 다뤄지지 않는데, 예를 들어 LLMs와 같이요. 이 블로그 글은 NodePiece 토큰화를 명쾌하고 직관적으로 설명하며, 기존 구현이 매우 복잡하고 이미 구현된 라이브러리에 내장되어 있어 학습이 어려운 점을 감안하여 실용적인 Python 구현을 제공합니다.\n\n이 글을 마치면 다음을 이해할 수 있을 것입니다:\n\n1. NodePiece 토큰화의 기본 개념들을 파악할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 이 기술의 근간과 원칙을 이해하세요.\n\n3. Python에서 NodePiece 토큰화의 기본 버전을 구현하는 기술을 익히세요.\n\n저의 Github에서 Jupyter 노트북 및 토큰화 및 모델을 담은 모듈을 찾을 수 있습니다.\n\n이 포스트는 꽤 길기 때문에 섹션 및 하위 섹션의 간단한 개요입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제목 1: 건설 블록의 마법\n\n1.1. NLP 세계 - 역사 요약: 이 섹션은 자연어 처리의 진화를 강조하며 Word2Vec 및 GloVe와 같은 기본 알고리즘에 초점을 맞춥니다.\n1.2. 트랜스포머 토크나이저의 출현: NLP 모델의 효율성과 유연성에 미치는 트랜스포머 기반 토큰화의 중요한 영향을 논의합니다.\n1.3. 그래프 세계: NLP 토큰화 개념을 그래프 신경망에 적용하는 잠재력을 탐구하여 NodePiece를 위한 무대를 마련합니다.\n\n제목 2: NodePiece 알고리즘\n\n2.1. 기여 및 출처: NodePiece 모델을 소개하며 새로움과 NLP로부터 영감을 얻은 주요 출처에 집중합니다.\n2.2. 기본 개념: NodePiece 모델의 핵심 구성 요소를 설명하며 그래프 노드의 토큰화 방법을 소개합니다.\n2.3. 위치적 특징: NodePiece가 노드의 공간적 위치를 선택된 기준점에 상대적으로 어떻게 활용하는지 설명합니다.\n2.4. 관계적 특징: NodePiece가 노드가 참여하는 관계 유형을 어떻게 파악하는지 상세히 설명합니다.\n2.5. 독특한 지문 - 직관: NodePiece가 위치적 및 관계적 특징을 결합하여 독특한 노드 임베딩을 만드는 방식에 대한 직관적 설명을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n### 파트 3: 형식적 정의\n\n3.1. Set-Based Form: 노드를 앵커, 거리 및 관계의 집합을 통해 표현하는 프로세스를 형식화합니다.\n3.2. 앵커, 거리 및 관계의 내장: NodePiece가 벡터 표현으로 변환하는 집합의 방법을 설명합니다.\n3.3. 부호화: 노드 정보를 단일 벡터로 압축하는 부호화 프로세스를 설명합니다.\n3.4. 이것으로 무엇을 할까요?: NodePiece 임베딩이 그래프 신경망에서의 잠재적인 응용 및 이점에 대해 논의합니다.\n\n### 파트 4: 간소화된 구현\n\n4.1. 전체 개요: 교육 목적을 위해 설계된 NodePiece의 간소화된 버전을 소개합니다.\n4.2. 데이터: 데모에 사용된 데이터셋을 설명하며, 실용성을 위해 관리 가능한 하위 집합의 선택을 강조합니다.\n4.3. 토큰화: 간소화된 모델 내에서 NodePiece의 토큰화 프로세스를 설명합니다.\n4.4. 앵커 선택: 구현에서 앵커 노드를 선택하는 방법을 상세히 설명합니다.\n4.5. K개 최근 앵커까지의 거리 구성: 모델이 노드에서 가장 가까운 앵커까지의 거리를 계산하는 방법을 설명합니다.\n4.6. 관계적 컨텍스트 추출: 노드의 관계적 컨텍스트를 식별하고 내장하는 프로세스를 설명합니다.\n4.7. 특성 행렬: 토큰화 및 컨텍스트 추출 결과를 특성 행렬 형태로 강조합니다.\n4.8. 전체 모델 정의: 모델 아키텍처 및 구성 요소에 대해 포괄적으로 살펴봅니다.\n4.9. TransE 모델 훈련: 지식 그래프 임베딩 작업에 NodePiece 임베딩을 사용하여 TransE 모델 훈련에 대해 논의합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 파트1: 빌딩 블록의 마법\n\n## NLP 세계 — 역사 소개\n\nNLP의 발전을 되짚어보면 초기 단계는 단어 임베딩, 어근 추출 및 토크나이제이션과 같은 방법론들에 의해 주도되었습니다. Church(2017)와 Brochier 등(2019)과 같은 선구적인 알고리즘들이 Word2Vec 및 GloVe와 같은 표준을 설정하며, 비교적 간단한 절차하에서 작동했습니다:\n\n1. 큰 텍스트 말뭉치를 편집하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 토큰화, 표제어 추출 및 유사한 기술을 통해 전처리합니다.\n\n3. 처리된 단어를 고유한 ID로 매핑하는 임베딩 조회를 구축합니다.\n\n그러나 이 접근 방식은 공간을 많이 차지하고 계산 비용이 많이 드는 방식이었습니다.\n\n예를 들어, 임베딩 행렬이 다음과 같이 정의된 경우를 고려해보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![NodePieceFromNodeIDstoTokens](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_1.png)\n\n어휘 크기(V) 및 임베딩 크기(E)였습니다. 어휘 크기가 100,000이고 임베딩 크기가 300인 경우, 리소스에 상당한 수요를 일으키는 30 백만개의 부동 소수점을 할당해야 합니다.\n\n## 트랜스포머 토크나이저의 등장\n\n트랜스포머 및 그와 관련된 토큰화 방법의 도입이 이 분야를 혁신적으로 변화시켰습니다. Byte-Pair Encoding (BPE) (Sennrich et al., 2016)과 같은 기술은 부분 단어 또는 알파벳과 같은 건설 블록에 유사한 개념을 도입하여 토큰화 프로세스를 혁신적으로 개선했습니다. 이러한 부분 단어 또는 토큰은 전체 단어보다 더 간결하면서도 보다 보편적이며, 다양한 언어에 적용될 수 있고 새로운 어휘를 순차적으로 도입할 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 표시됩니다. 해당 표현은 전통적인 방법에서는 단어를 분리하여 각각 임베딩을 할당할 것이지만, 현대적인 토크나이저는 서브워드로 분할할 수 있습니다.\n\n```js\n[CLS]\nmodern\ntoken\n##izer\n##s\nrevolution\n##ized\nthe\nway\n,\nhow\nwe\nprocess\ntext\nthese\ndays\n[SEP]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이는 \"tokenizer\"와 같은 각 새로운 단어에 대한 고유한 ID가 필요하지 않게되어 \"token\"과 \"##izers\"가 이미 어휘에 있는 상태로 다른 단어의 표현을 구성할 수 있게 해줍니다. 이는 임베딩 메모리 공간을 절약하면서 가능하게 합니다.\n\n## 그래프의 세계\n\n그래프 처리 및 지식 그래프 추론의 분야에서는 현대 NLP 토큰화에 사용되는 개념과 유사한 개념을 받아들이는 과정이 느리게 진행되어 왔습니다. TransE (Bordes et al., 2013) 및 RotatE (Sun et al., 2019)와 같은 지식 그래프 추론을 위한 전통적인 알고리즘은 대부분 엔티티와 관계를 고유한 임베딩에 매핑하는 데 의존해 왔습니다. 이 접근 방식은 간단하지만 메모리 집약적이며, 각 엔티티 및 관계는 임베딩 공간 내에서 고유한 식별자를 필요로 합니다 — 마치 word2vec이나 기존 NLP 솔루션에서의 단어들처럼!\n\nTransE, RotatE 및 유사한 모델에 대해 더 알고 싶은 분은 Medium.com의 게시물을 강력히 추천합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사는 이러한 모델 뒤에 있는 원칙들에 대해 포괄적인 개요를 제공합니다.\n\n그래프 도메인 내에서 확장 가능하고 효과적인 솔루션을 찾는 것은 오랜 시간이 걸리지만 결과가 있었습니다. 노드피스(NodePiece)는 이 맥락에서의 선도적인 알고리즘 중 하나로 등장했으며, NLP 토큰화 기술의 발전에서 많은 영감을 받았습니다. 최신 토큰화 기술의 원칙을 그래프 구조에 적용함으로써, 노드피스는 그래프 엔티티와 관계를 표현하는 새로운 방법을 제공하며, 지식 그래프 도메인에서 더 많은 메모리 효율적이고 일반화 가능한 모델을 향한 중요한 발전을 이룩했습니다.\n\n# 파트 2: 노드피스 알고리즘\n\n## 기여와 출처\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n노드피스 알고리즘은 대규모 지식 그래프에 대한 합성 및 매개변수 효율적인 표현에 중점을 둔 지식 그래프 임베딩 분야에서의 중요한 발전을 대표합니다. \"NodePiece: Compositional and parameter-efficient representations of large knowledge graphs\" (Galkin et al., 2021) 논문에서 소개된 이 방법은 널리 사용되는 Python 라이브러리인 PyKeen에 통합되어 있습니다.\n\nPyKeen 구현은 아래에서 찾을 수 있습니다:\n\n게다가, 논문 기여자들에 의해 작성된 구현은 GitHub에서 접근 가능하며, 원본 코드베이스를 더 탐구하려는 분들을 위해 제공됩니다:\n\n이론적 관점에서 노드피스에 대한 포괄적이고 접근성 있는 소개를 위해, 원문의 공헌자 중 한 명인 Michael Galkin이 작성한 Medium 블로그 게시물 \"NodePiece: Tokenizing Knowledge Graphs\"를 읽어보시기를 권장합니다. 이 기사는 알고리즘에 대한 귀중한 심층적인 통찰을 제공하여 개발자들로부터 직접 얻은 통찰을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마이클 갈킨의 블로그 게시물 'NodePiece: 지식그래프의 토큰화'는 NodePiece 알고리즘에 대한 깊은 설명으로 두루 짚고 있으며, 그 중 하나인 창조자에 의해 저술되었습니다. 이는 원래의 학술 논문을 넘어서 모델을 이해하려는 사람들에게 좋은 자료입니다.\n\n## 기본 개념\n\nNodePiece 알고리즘은 지식 그래프 내 개체마다 고유 식별자를 할당하는 전통적 요구사항에서 벗어나, 대신 기본적인 구성 요소의 조합을 통해 개체를 나타냅니다. NLP의 토큰화 개념과 유사점을 그리며, 이러한 구성 요소는 다음과 같습니다:\n\n1. 위치 특성: 지정된 앵커 노드에 대한 노드의 근접성.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 관계 특성: 노드가 포함된 관계 유형\n\n## 위치 특성\n\n노드는 미리 정한 일련의 기준 앵커 노드들까지의 거리로 특성화됩니다. 이러한 앵커 노드를 선택하는 방법은 가장 연결된 노드를 선택하거나 클러스터링 알고리즘을 사용하거나 심지어 무작위 선택과 같은 선택 옵션을 포함합니다.\n\n선택 기술에 관계없이 근본적인 원칙은 간단합니다. 각 노드는 K개의 가장 가까운 앵커 노드까지의 거리에 의해 정의됩니다. 전략적인 앵커 노드 선택을 통해 가장 가까운 앵커에 대한 근접성이 각 노드에 대한 고유한 \"지문\"을 제공하는 높은 가능성이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 예시를 통해 이 개념을 설명해 보겠습니다:\n\n![NodePieceFromNodeIDstoTokens_2](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_2.png)\n\n아래 표는 각 노드에서 앵커까지의 거리를 요약한 것입니다:\n\n![NodePieceFromNodeIDstoTokens_3](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 관계형 기능\n\n이질적인 지식 그래프에서 엣지는 노드 간의 다양한 관계 유형을 캡슐화합니다. NodePiece 알고리즘은 이러한 관계를 노드 표현의 중요한 구성 요소로 활용하여 각 노드의 컨텍스트와 그래프 내에서의 연결성을 풍부하게 합니다. 관계형 기능이 어떻게 통합되는지 설명하기 위해, 우리의 이전 예제를 다시 살펴보고 확장하겠습니다. 이번에는 관계 유형을 포함하여:\n\n![노드의 관계형 기능](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_4.png)\n\n각 노드의 관계를 다음의 표로 요약할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![NodePieceFromNodeIDstoTokens_5](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_5.png)\n\nOr with counting each relation type:\n\n![NodePieceFromNodeIDstoTokens_6](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_6.png)\n\nProbably you see now, where it is going…\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 독특한 지문 — 직감\n\nNodePiece 알고리즘의 본질은 각 노드에 대한 일관된 표현인 위치 및 관계형 두 가지 다른 기능을 종합하는 능력에 있습니다. 이 과정은 가장 가까운 앵커 노드와 노드가 참여하는 관계 유형을 연결하여 노드의 고유한 \"지문\"이라는 단일 벡터를 얻게 됩니다.\n\n이 과정을 개념화하기 위해 다음 단순화된 스키마를 통해 노드 2를 나타내는 것을 고려해보세요:\n\n![NodePieceFromNodeIDstoTokens_7](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 파트 3: 형식적인 정의\n\nNodePiece 알고리즘 코딩을 시작하기 전에 언급할 중요한 세부 정보가 몇 가지 있습니다. 예를 들어:\n\n1. 선택적 앵커 사용: 모든 노드의 표현에 모든 앵커가 관련이 있는 것은 아닙니다. 가장 가까운 k개의 앵커만이 각 노드에 임베딩하기 위해 고려됩니다.\n\n2. 관계 추출: 마찬가지로, 노드의 관계적 문맥은 즉시 외부 관계 중에서 샘플링을 통해 파생되며, 각 노드당 최대 m개의 관계로 제한됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 연결 끊김 처리: 노드가 연결이 끊겼거나 특정 앵커나 관계에 대한 링크가 없는 경우 — 특별한 [DISCONNECTED] 토큰이 사용됩니다. 이는 NLP 시나리오에서의 `OOV` (out-of-vocabulary) 토큰과 유사합니다.\n\n이제 수학 시간입니다.\n\nNodePiece에 대한 입력이 무엇인지 시작해 봅시다:\n\n![NodePieceFromNodeIDstoTokens_8.png](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNodePiece는 다음과 같이 설계되었음을 알 수 있습니다:\n\n1. 지식 그래프 - 특정 관계(R)에 속하는 에지(E)로 연결된 노드(N)의 모음으로 표현됩니다.\n\n2. 선택된 앵커 노드 (A) - 이들은 각 노드의 \"지문\" 표현의 일부가 될 것입니다.\n\n3. 관계 (R) 및 앵커 (A)는 모델의 어휘 (V)를 형성합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4. 논문에서 언급했듯이, 모든 노드에 대해 모든 앵커를 사용할 필요는 없으므로 k개의 앵커가 샘플링됩니다.\n\n5. 관계에도 같은 원칙이 적용됩니다. 각 노드에 대해 m개의 관계만이 샘플링됩니다.\n\n## 집합 기반 형태\n\n우리가 가지고 있는 핵심 요소들로부터, 그래프 내 각 노드의 고유한 \"지문\"에 대한 형식적인 정의로 이어질 수 있습니다. 이 지문은 세 가지 구성 요소로 나뉩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1. 앵커 세트: 모든 앵커(A) 집합에서 임의로 선택된 k개의 앵커입니다.\n\n2. 앵커 거리: 노드에 대해 결정된 k개 가장 가까운 앵커까지의 최단 경로 거리입니다. 앵커에 도달할 수 없는 경우, 해당 거리는 미리 정의된 \"마법 값\"으로 표시됩니다. (-1 또는 다른 토큰과 같이)\n\n3. 관계적 맥락: 노드를 위해 샘플링된 m개의 직접 외부 관계 중 일부로, 즉시 관계적 환경을 포함합니다.\n\n형식적으로 표현하면, 정점 집합 V의 각 노드 u에 대한 표현은 다음과 같이 설명할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-17-NodePieceFromNodeIDstoTokens_9.png](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_9.png)\n\n원본 논문의 저자들은 거리에 positional encoding을 적용하여 각 거리를 차원 d의 벡터로 매핑하는 것을 옹호합니다. 이 접근 방식은 임베딩의 의도된 차원을 유지하는 것을 보장합니다.\n\n![2024-05-17-NodePieceFromNodeIDstoTokens_10.png](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_10.png)\n\n앵커 및 해당 거리에 대해 임베딩 조회 전략이 제안됩니다. 이는 각 앵커 id(예: 앵커=0)가 임베딩 행렬의 특정 행에 연결되며, 거리에 대해서도 동일한 방식으로 적용됨을 의미합니다(예: 거리=1은 embedding 1에 해당). 이 방법은 각 노드의 그래프 내 고유한 서명의 위치 및 관계적 측면을 효율적이고 의미 있게 인코딩하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n고려해야 할 점은 기존 방법에서 사용되는 고유 노드 ID의 인구보다 앵커 수와 앵커 거리가 훨씬 작다는 것이다!\n\n## 앵커, 거리, 관계의 임베딩\n\n방정식 (1)으로 구분된 세트의 변환을 통해 임베딩을 통한 벡터 표현으로 포함된 기본 단계가 여러 단계 포함됩니다 (텍스트와 방정식을 섞는 Medium.com의 제한으로 인해 아래 부분은 이미지로 게시되었습니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Node representation matrix](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_12.png)\n\nAfter that, authors sum vectors related to anchors, so that the matrix node representation is as follows:\n\n![Node representation matrix](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_13.png)\n\n## Encoding\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n방정식 (3)에 나온 행렬은 각 노드 u에 대해 해당 인코더(MLP 또는 Transformer)를 적용하여 벡터로 변환을 용이하게 합니다. 이것은 원래 연구에서 발표된 것처럼 진행됩니다.\n\n이 인코더는 행렬을 각 노드에 대한 \"펼쳐진\" 벡터 표현으로 변환하여 복잡한 관계 및 위치 정보를 간결한 형태로 요약합니다.\n\n아래는 이 인코딩 프로세스를 실제 예제로 설명하는 목적으로 노드 2에 대한 표현을 고려해 봅시다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Anchor를 0부터 시작하는 식별자로 할당하므로 id(Anchor 1) = 0 및 id(Anchor 2) = 1입니다.\n\n- 관계는 유사하게 식별자가 부여되어 id(r1) = 0, id(r2) = 1, id(r3) = 2 등입니다.\n\n- 거리는 id(dist=1) = 0, id(dist=2) = 1, id(dist=3) = 2 등과 같은 방식으로 인덱싱됩니다.\n\n- k=m=2인 경우 각 노드에 대해 두 개의 Anchor와 두 개의 관계가 샘플링됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n주어진 매핑을 가정하고 차원 공간 d = 3인 경우, 방정식 (2)에 따른 표현은 다음과 같이 나타납니다:\n\n![image1](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_15.png)\n\n![image2](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_16.png)\n\n\\*0부터 세는 것을 기억하세요 :) id(r1) = 0, id(Anchor1) = 0, 등등 :).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_17.png)\n\n그 후, 각 앵커, 거리, 그리고 관계에 d-차원 임베딩이 적용됩니다. 이들은 크기 d의 벡터로 매핑됩니다. 예를 들어, d=3인 경우, 앵커, 거리, 그리고 관계에 대한 결과 행렬은 방정식 (2)와 일치하는 다음과 같을 수 있습니다:\n\n![이미지](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_18.png)\n\n물론 각 행렬의 값은 예시입니다 — 실제 모델에서는 아마 무작위 숫자들이 될 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앵커와 관련된 벡터를 합한 후에 방정식(3)에 정해진대로 연결하면 다음과 같이 유도됩니다:\n\n![image](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_19.png)\n\n이러한 과정은 인코딩이 각 노드에 대해 앵커, 거리 및 관계 데이터의 복잡한 배열을 통합하고 단순화하여 다운스트림 그래프 처리 작업에 즉시 사용할 수 있도록 만드는 능력을 보여줍니다.\n\n## 어떻게 활용할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금부터 사용자는 분류, 클러스터링 등과 같은 하위 작업을 진행할 수 있습니다.\n\n각 노드의 표현은 이제 일반적인 특성처럼 사용할 수 있는 평면 벡터입니다.\n\n노드의 고유한 특성을 캡처해야 합니다. 즉, 그래프 내에서의 위치, 관계 등을 포함해야 합니다.\n\n논문 자체에서는 NodePiece 알고리즘의 기본적인 최적화, 트릭 및 개선 사항들이 여러 가지 언급되어 있지만, 이 간소화된 설명에서는 나머지 부분을 건너 뜁했습니다. 자세한 내용에 관심이 있다면 원본 논문을 꼭 읽어보시기를 강력히 권장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 파트 4: 단순화된 구현\n\n## 개요\n\n노드피스 알고리즘의 기존 구현인 원본 논문의 저자들이 제공하고 있는 PyKeen 라이브러리 내의 버전들은 포괄적이지만 복잡합니다. 이러한 버전들은 성능 및 기존 프레임워크 내 통합을 최적화한 것이지만, 응용 프로그램 개발에 유용할 수 있지만, 알고리즘의 이론적 기초와 실제 코드 표현 사이의 개념적 공통점을 명확히하는데 어려움을 줄 수 있습니다. 이러한 복잡성은 알고리즘을 이해하려는 사람들에게 어려움을 줄 수 있습니다.\n\n교육용으로 맞춤화된 구현의 제한된 가용성과 알고리즘의 기본 메커니즘을 이해하고자 하는 사람들을 위한 것이 아닌 알고리즘에 대해 더 깊이있게 이해하려는 사람들을 위한 간소화된 NodePiece의 버전을 개발하기로 선택했습니다. 이 버전은 명확성과 확장성을 염두에 두고 설계되었으며, 최적화와 프레임워크별 고려사항을 초과하는 부담 없이 알고리즘의 기본 메커니즘을 이해하려는 개인들에게 더 접근성 있는 진입점을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 간소화된 구현은 두 가지 주요 구성 요소로 구성되어 있습니다:\n\n1. Tokenization Module: 이 코드 세그먼트는 앵커 및 관계를 선택하고 노드 표현을 구성하는 데 책임이 있으며 앵커, 관계 및 거리에 대한 식별자로 노드 표현을 정렬합니다. 이는 방정식(1)에서 설명된 프로세스와 일치하며, 노드의 앵커와의 관계 및 다양한 관계에 참여함으로써 노드의 고유한 \"지문\"을 생성하는 초기 단계를 총망라합니다.\n\n2. Models Module: 이 부분은 식별자를 벡터 공간에 포함시키고 예측 모델을 구축하는 작업을 수행합니다. 이는 NodePiece 알고리즘의 후속 단계를 구현하는 것으로, 노드의 추상적인 표현을 밀집 벡터 표현으로 변환하고 이를 하류 기계 학습 작업에서 활용할 수 있게 합니다.\n\n## 데이터\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n실습 목적으로 이 튜토리얼은 FB15k-237 데이터셋의 작은 하위 집합을 활용할 것입니다. 데이터셋의 축소판을 사용하는 이유는 실용성에 있습니다: 로컬에서 전체 데이터셋에 모델을 학습하는 데에는 시간이 많이 소요될 수 있습니다. 이 하위 집합은 결과 그래프가 일관되고 연결되어 있으며 전체 데이터셋의 구조적 무결성과 관계 복잡성을 유지하도록 꼼꼼히 만들어졌습니다. 이 방식을 통해 NodePiece 알고리즘을 빠르고 통찰력 있게 탐구할 수 있으며, 단순화된 구현을 더 관리하기 쉬운 규모로 실험하고 확장할 수 있습니다.\n\n저희 축소된 데이터셋은 다음과 같은 구성 요소로 이루어져 있습니다:\n\n1. 훈련 데이터셋 — 123,816 개의 삼중 세트.\n\n2. 검증 데이터셋 — 402 개의 삼중 세트.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 테스트 데이터셋 — 224개의 삼중 세트가 있습니다.\n\n4. 237가지 고유한 관계 유형이 있습니다.\n\n## 토큰화\n\n이제 그래프를 토큰화할 시간입니다. 우리는 단순화된 NodePiece 논리를 사용하는 사용자 정의 함수를 사용할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 내용을 다음과 같이 번역하겠습니다.\n\n전체 데이터셋에서:\n\n- 30개의 앵커를 선택합니다.\n- 각 노드에 대해 20개의 가장 가까운 앵커를 선택합니다.\n- 각 노드에 대해 10가지 관계를 선택합니다.\n\n## 앵커 선정\n\n앵커 선정 함수를 시작해보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndef degree_anchor_select(g: nx.Graph, n_anchors: int|float = 0.1) -\u003e Tuple[List[int], Dict[int, int]]:\n    \"\"\"앵커 선택 방법으로, 용이한 경중에 따라 기초합니다. 가장 간단한 휴리스틱에 기초하여\n    이 그래프 내에서 가장 많은 노드와 연결되는 것으로 가정하고 노드의 최고 차수를 가진 노드를\n    앵커로 선택합니다.\n\n    매개변수\n    ----------\n    g : nx.Graph\n        Networkx 그래프입니다.\n    n_anchors : int | float, 선택사항\n        선택할 앵커의 수로, 기본값은 0.1입니다.\n        int일 경우 - 선택할 앵커 수입니다.\n        float일 경우 - 앵커로 선택할 노드의 비율입니다.\n\n    반환값\n    -------\n    Tuple[List[int], Dict[int, int]]\n        1. 앵커 노드 목록입니다.\n        2. 앵커 노드를 해당 ID로 매핑한 딕셔너리입니다. 앵커 ID는 [0, n_anchors) 범위 내에 있습니다.\n    \"\"\"\n    if type(n_anchors) == float:\n        n_anchors = int(g.number_of_nodes() * n_anchors)\n\n    degrees = sorted(g.degree, key=lambda x: x[1], reverse=True)\n    anchor_2_id = {}\n    anchors = []\n    for i, (node, _) in enumerate(degrees[:n_anchors]):\n        anchors.append(node)\n        anchor_2_id[node] = i\n\n    return anchors, anchor_2_id\n```\n\n`degree_anchor_select` 함수는 이 작업에 대해 직관적이면서도 효과적인 방법을 보여줍니다. 노드의 차수를 앵커 선택 기준으로 활용합니다. 이 방법은 높은 차수를 갖는 노드가 더 많은 연결을 의미하므로 해당 그래프의 다양한 부분에 연결될 가능성이 높기 때문에 최적의 앵커로 간주합니다. 함수가 작동하는 방식을 단계별로 살펴보겠습니다:\n\n1. 입력 매개변수: 함수는 NetworkX 그래프 `g`와 `n_anchors` 매개변수를 받습니다. `n_anchors` 매개변수는 선택할 앵커의 수를 지정하며, 이 값은 그래프의 노드 중 일정 비율(기본값은 0.1 또는 10%)을 앵커로 지정할 경우에 float로 지정하거나 원하는 앵커 수를 정수로 지정할 수 있습니다.\n\n2. 차수 계산 및 정렬: 함수는 그래프 내 각 노드의 차수를 계산합니다. 그런 다음, 노드들을 차수에 따라 내림차순으로 정렬하여 앵커로 선택할 때 높은 차수의 노드를 우선하여 고려합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. ID 매핑 앵커: 선택된 각 앵커 노드를 0부터 시작하는 고유 식별자에 매핑하는 anchor_2_id 사전이 초기화됩니다. 이 매핑은 NodePiece 토큰화 프로세스의 이후 단계에서 앵커 노드를 효율적으로 식별하고 활용할 수 있게 합니다.\n\n4. 반환 값: 이 함수는 선택된 앵커 노드의 목록과 anchor_2_id 사전을 포함하는 튜플을 반환합니다. 목록에는 앵커로 선택된 노드들이 포함되며, 사전은 이러한 앵커 노드와 할당된 ID 사이의 매핑을 제공하여 노드 표현 구성 시에 직접 참조할 수 있게 합니다.\n\n## K개 가까운 앵커까지의 거리 구축\n\n다음으로, 각 노드에서 K개 가까운 앵커 노드까지의 최단 경로 거리를 계산하는 함수를 구축할 예정입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndef build_distance_to_k_nearest_anchors(\n        G: nx.Graph,\n        anchors: List[int],\n        anchor2id: dict,\n        k_closest_anchors: int = 15,\n        use_closest: bool = True) -\u003e Tuple[np.ndarray, np.ndarray, int]:\n    \"\"\"그래프의 각 노드에 대해 k개 가장 가까운 앵커까지의 거리를 계산합니다.\n\n    매개변수\n    ----------\n    G : nx.Graph\n        네트워크x 그래프.\n    anchors : List[int]\n        앵커 노드 목록.\n    anchor2id : dict\n        앵커에서 id로의 매핑.\n    k_closest_anchors : int, optional\n        각 노드에서 선택할 k개 가장 가까운 앵커의 수, 기본값은 15\n    use_closest : bool, optional\n        가장 가까운 앵커를 사용해야 하는지 또는 모두 사용해야 하는지 여부, 기본값은 True\n\n    반환값\n    -------\n    Tuple[np.ndarray, np.ndarray, int]\n        다음으로 구성된 튜플:\n        1. 노드와 앵커 사이의 거리 행렬. 형태: (노드 수, 앵커 수).\n        2. 노드와 앵커 id 행렬. 형태: (노드 수, 앵커 수).\n        3. 그래프 내의 최대 거리. 거리 인코딩/임베딩에 사용될 것입니다.\n    \"\"\"\n    node_distances = {i: [] for i in range(G.number_of_nodes())}\n    for a in tqdm(anchors):\n        for node, dist in nx.shortest_path_length(G, source=a).items():\n            node_distances[node].append((a, dist))\n\n    node2anchor_dist = np.zeros((G.number_of_nodes(), len(anchors)))\n    node2anchor_idx = np.zeros((G.number_of_nodes(), len(anchors)))\n    unreachable_anchor_token = len(anchors)\n    node2anchor_idx.fill(unreachable_anchor_token)\n\n    max_dist = 0\n\n    for node, distances in tqdm(node_distances.items()):\n        indices_of_anchors = sorted(distances, key=lambda x: x[1])[:k_closest_anchors] if use_closest else node_distances[node]\n        for i, (anchor, dist) in enumerate(indices_of_anchors):\n            anchor_id = anchor2id[anchor]\n            node2anchor_dist[node, anchor_id] = dist\n\n            node2anchor_idx[node, i] = anchor_id\n            if dist \u003e max_dist:\n                max_dist = dist\n    unreachable_anchor_indices = node2anchor_idx == unreachable_anchor_token\n    node2anchor_dist[unreachable_anchor_indices] = max_dist + 1\n    return node2anchor_dist, node2anchor_idx, max_dist\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 거리 및 인덱스 행렬의 인구: 이 함수는 각 노드의 앵커까지의 거리를 정렬하여 각 노드에 대해 가장 가까운 k개의 앵커를 선택합니다. 선택된 앵커까지의 거리와 인덱스는 각각의 배열에 저장됩니다. 이 과정에서 max_dist 변수는 관측된 최대 거리를 반영하도록 업데이트되어, 도달할 수 없는 앵커는 이 최대값을 초과하는 거리로 표시됩니다 (max_dist +1 - \"마법 OOV 토큰\" :)).\n\n4. 도달할 수 없는 앵커 처리: 앵커에 대한 경로가 없어 도달할 수 없는 노드의 경우 거리가 max_dist + 1로 설정됩니다. 이 조정은 node2anchor_idx의 unreachable_anchor_token과 일치하는 인덱스를 식별하여 해당하는 node2anchor_dist 항목을 이 증가된 최대 거리로 설정함으로써 이뤄집니다. 이 메커니즘은 효과적으로 일부 앵커로부터 격리된 노드를 처리하며, 그래프 내에서 연결되지 않은 구성 요소의 가능성을 인정하여 NodePiece 표현의 무결성을 유지합니다.\n\n5. 반환 값: 함수는 노드마다 가장 가까운 앵커 지점에 대한 포용도를 제공하는 node2anchor_dist 거리 행렬, 앵커 인덱스 행렬 node2anchor_idx 및 max_dist 값을 포함하는 튜플을 반환함으로써 마무리됩니다. 이러한 출력은 NodePiece 임베딩을 구성하는 기초를 제공하여 각 노드의 근접성에 대한 종합적인 매핑을 제공합니다.\n\n## 관계적 컨텍스트 추출\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 단계는 각 노드에 대한 관련 컨텍스트를 추출하는 것입니다.\n\n```js\ndef sample_rels(pyg_g: pyg_data.Data, max_rels: int = 50) -\u003e th.Tensor:\n    \"\"\"각 노드에 대해 m개의 외부 관계를 샘플링합니다. 노드의 관계가 m보다 적은 경우, 특수 토큰으로 출력을 채웁니다.\n\n    매개변수\n    ----------\n    pyg_g : pyg_data.Data\n        PyTorch Geometric 그래프.\n    max_rels : int, optional\n        사용할 관계의 최대 수, 기본값은 50입니다.\n\n    반환\n    -------\n    th.Tensor\n        각 노드에 대한 관계 행렬. 형태: (노드 수, max_rels).\n        각 행은 특정 노드에 해당하며, 각 열은 관계(ID)에 해당합니다.\n    \"\"\"\n    rels_matrix = []\n    missing_rel_token = pyg_g.edge_type.max() + 1\n    for node in tqdm(range(pyg_g.num_nodes)):\n        node_edges = pyg_g.edge_index[0] == node\n        node_edge_types = pyg_g.edge_type[node_edges].unique()\n        num_edge_types = len(node_edge_types)\n\n        if num_edge_types \u003c max_rels:\n            pad = th.ones(max_rels - num_edge_types, dtype=th.long) * missing_rel_token\n            padded_edge_types = th.cat([node_edge_types, pad])\n            padded_edge_types = padded_edge_types.sort()[0]\n        else:\n            sampled_edge_types = th.randperm(num_edge_types)[:max_rels]\n            padded_edge_types = node_edge_types[sampled_edge_types].sort()[0]\n        rels_matrix.append(padded_edge_types)\n    return th.stack(rels_matrix)\n```\n\n1. 초기화: 함수는 PyTorch Geometric (PyG) 그래프 객체 pyg_g와 선택적으로 최대 관계 수를 결정하는 max_rels 매개변수를 필요로 합니다. 기본값은 50입니다. 모든 노드의 관계 데이터를 보유할 빈 리스트 rels_matrix가 준비되어 있습니다. 또한, 주어진 노드에 대한 관계가 없음을 나타내는 missing_rel_token이 정의되며, 사실상 다음 \"어휘 외\" 토큰으로 작동합니다. 이 토큰은 그래프에서 발견된 가장 큰 관계 ID보다 1 큰 값으로 설정됩니다.\n\n2. 고유 관계 탐색: 각 노드에 대해 고유한 외부 엣지 유형(관계)을 찾습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 관계 수 확인: 그래프의 각 노드에 대해, 이 함수는 노드에 연결된 모든 고유한 발신 관계 유형(엣지 유형)을 식별합니다.\n\n4. 관계 수 조정: 노드의 고유한 관계 수가 max_rels 임계값보다 작을 경우, 관계 목록에 누락된 관계 토큰을 추가하여 지정된 최대값에 도달하도록 패딩 처리됩니다. 이는 모든 노드에서 관계적 문맥의 길이를 균일하게 유지합니다.\n\n반대로, 노드가 max_rels로 허용하는 관계 유형보다 많이 연결된 경우, 제한에 맞게 일부가 무작위로 선택됩니다. 이 무작위 샘플링은 세부 정보와 계산 효율성 사이의 균형 유지에 필요한 것을 나타냅니다.\n\n4. 관계 정렬 및 저장: 각 노드에 대한 샘플링된(또는 추가된) 관계는 일관된 순서를 유지하도록 정렬됩니다. 정렬된 목록은 그래프 전체에 대한 포괄적인 관계적 문맥 저장소를 점진적으로 구축하기 위해 rels_matrix에 추가됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n6. 텐서 변환 및 결과 반환: 모든 노드에 대한 관계적 맥락 추출이 완료되면 rels_matrix 목록이 PyTorch 텐서로 변환됩니다. 이 텐서는 (num_nodes x max_rels) 모양을 가지며, 각 노드의 관계적 맥락을 구조화되고 기계가 읽을 수 있는 형식으로 체계적으로 나타냅니다.\n\n## 기능 행렬\n\n모든 작업이 완료되면 세 개의 행렬이 남습니다:\n\n1. anchor_distances — 각 노드에서 K 개 가장 가까운 앵커까지의 거리. 차원: N 노드 x K 앵커.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. anchor_hashes— 각 노드의 K 개 가장 가까운 앵커의 인덱스. 차원: N 노드 x K 앵커.\n\n3. rel_hashes — 각 노드의 관계적 맥락. 차원: N 노드 x M 관계.\n\n## 전체 모델 정의\n\n이 연습에서는 좀 더 간단하면서 효과적인 지식 그래프 임베딩 모델인 TransE로 피벗합니다. 원래 논문은 RotatE를 사용했지만 — 좀 더 복잡한 모델 — TransE는 그래프 내에서 관계를 임베딩하는 기본 측면에 초점을 맞춘 단순화된 접근 방식을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTransE는 헤드 노드, 관계 및 테일 노드로 구성된 트리플릿을 평가하는 방식으로 작동합니다. 이는 헤드와 테일 노드 사이에 지정된 관계가 존재할 확률을 나타내는 likelihood 점수를 할당합니다. 모델의 목적은 실제 트리플릿을 인공적으로 생성된(변형된) 트리플릿과 구별하기 위해 설계된 손실 함수의 최적화에 담겨 있습니다.\n\n마크다운 형식으로 표를 변경하겠습니다:\n\n![이미지 1](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_20.png)\n\n![이미지 2](/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_21.png)\n\n의사 코드로 작성하면 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfor (head, relation, tail) in data:\n    head_embed = EMBED(head)\n    rel_embed = EMED(relation)\n    tail_embed = EMBED(tail)\n    score = -1 * [(head_embed + rel_embed) - tail_embed]\n    return score\n```\n\nWe return -1 x score as we want to minimize the score, and maximize the likelihood of the triplet.\n\nWhen interacting with NodePiece embeddings, TransE gets interesting when it comes to embedding head and tail nodes.\n\nTransE embedding in this case will perform several steps. For each head or tail node:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1. 가장 가까운 앵커 인덱스를 가져와서 포함하세요.\n\n2. 가장 가까운 앵커까지의 거리를 가져와서 포함하세요.\n\n3. 관계적 맥락을 가져와서 포함하세요.\n\n4. 방정식 (3)에 따라서: 앵커 ID 임베딩과 거리 임베딩을 더해주고, 관계 임베딩과 연결하여 하나의 벡터로 연결하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. 이 벡터를 인코더(MLP 또는 Transformer)를 통해 최종 임베딩을 얻기 위해 전달합니다.\n\n우리의 구현은 다음과 같이 보일 것입니다 - 이 절차는 각 헤드 및 테일 노드에 대해 호출됩니다:\n\n```js\n    def embed_node(self, node: th.Tensor, closest_anchors, anchor_distances, rel_hash):\n\n        # Dim: (N x K) values are anchor ids --\u003e (N x K x D)\n        anchor_embed = self.anchor_embed(closest_anchors[node])\n\n        # Dim: (N x K) values are anchor distances --\u003e (N x K x D)\n        anchor_distances_embed = self.anchor_distances_embed(anchor_distances[node])\n\n        # Dim: (N x M) values are relation types --\u003e (N x M x D)\n        rel_embed = self.rel_emb(rel_hash[node])\n\n        # Dim: (N x K x D)\n        combined_anchor_embed = anchor_embed + anchor_distances_embed\n\n        # N x (K + M) x D\n        stacked_embed = th.cat([combined_anchor_embed, rel_embed], dim=1)\n        N, anchors_plus_rel, hidden_channels = stacked_embed.shape\n\n        # reshape: (N x (K + M) x D) --\u003e (N x (K + M) * D)\n        flattened_embed = stacked_embed.view(N, anchors_plus_rel * hidden_channels)\n\n        # N x (K + M) * D --\u003e N x O\n        lin_out = self.lin_layer(flattened_embed)\n\n        return lin_out\n```\n\n1. anchor_embed는 앵커 해시에 대한 임베딩 조회입니다. 가중치 행렬의 차원은 ((K 앵커 + 1) x D 임베딩 크기)입니다. (N x K) 앵커 해시 행렬을 가져와 (N x K x D) 텐서를 반환합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. anchor_distances_embed은 앵커 거리를 위한 임베딩 조회입니다. 가중치 행렬은 ((최대 거리 +1) x D 임베딩 크기)의 차원을 가집니다. (N x K) 크기의 앵커 거리 행렬을 가져와 (N x K x D) 텐서를 반환합니다.\n\n3. rel_embed은 관계 해시를 위한 임베딩 조회입니다. 가중치 행렬은 ((고유 관계 +1) x D 임베딩 크기)의 차원을 가집니다. (N x M) 크기의 관계 해시 행렬을 가져와 (N x M x D) 텐서를 반환합니다.\n\n## TransE 모델 학습\n\n이제 TransE 모델을 준비하고, PyTorch Lightning으로 래핑하여 FB15k-237 데이터 하위 집합에서 훈련할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nuse_swa = True\nswa_lr = 0.05\n\npyg.seed_everything(111)\n\nparams = models.KGModelParams(\nnum_nodes=train_data_orig.num_nodes,\nnum_relations=train_features.n_rels+1,\nembedding_dim=200,\nmax_distance=max_distance+1,\nhidden_sizes=(400,),\nnum_anchors=train_features.n_anchors,\ntop_m_relations=train_features.m_relations,\ndevice=device,\nkg_model_type=models.ModelType.TransE,\ndrop_prob=0.2\n)\n\nmodel_pl = models.NodePiecePL(\nparams,\nlr=5e-2,\ntrain_features=train_features,\nval_features=val_features)\n\n저희가 인스턴스화한 모델은 다음과 같습니다:\n\nNodePieceTransE(\n(anchor_embed): Embedding(31, 200)\n(anchor_distances_embed): Embedding(13, 200)\n(rel_emb): Embedding(238, 200)\n\n(lin_layer): Sequential(\n(0): BatchNorm(8000)\n(1): Linear(in_features=8000, out_features=400, bias=True)\n(2): LeakyReLU(negative_slope=0.01)\n(3): Dropout(p=0.2, inplace=False)\n(4): Linear(in_features=400, out_features=200, bias=True)\n)\n)\n\n이전에 설명한 이론 부분과 완벽하게 일치합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째로는 기준 성능을 얻기 위해 모델을 어떤 학습도 하기 전에 유효성 검사 집합을 사용하여 모델을 평가할 것입니다. 결과는... 음... 예상대로 :)\n\n```js\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      검증 메트릭      ┃       데이터로더 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│    val_hits_at_k_epoch    │            0.0            │\n│    val_mean_rank_epoch    │   0.0005408872966654599   │\n└───────────────────────────┴───────────────────────────┘\n```\n\nHits@k(10) = 0.0이며 올바른 tail의 평균 순위는 매우 낮습니다. 이는 모델이 아직 학습되지 않았기 때문에 예상된 결과입니다.\n\n모델 학습에 시간을 투자한 후에는 학습 이후의 성능을 확인하기 위해 모델을 평가할 수 있습니다. 체크포인트 콜백이 사용되었으므로 모든 반복 중에서 최상의 모델을 선택할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nHits@k 및 평균 순위 메트릭에서 상당한 향상이 있음을 볼 수 있을 것입니다.\n\n```js\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│    val_hits_at_k_epoch    │    0.3240000009536743     │\n│    val_mean_rank_epoch    │    0.2862264811992645     │\n└───────────────────────────┴───────────────────────────┘\n```\n\n실제로, 예측 품질이 향상되었음을 확인할 수 있습니다. 물론, 이러한 작은 데이터 세트에 대해서도 실행하는 데 상당한 시간이 소요될 수 있습니다. 저는 1개의 GPU(T4), 16GB RAM 및 8개 가상 코어를 사용하는 Lightning.ai 플랫폼을 사용했고, 계산에 약 30분이 걸렸습니다.\n\n규모를 감을 수 있도록 말씀드리면, 원래 논문에서는 훨씬 큰 데이터 세트를 사용했으며, 학습에 GPU로 몇 시간이 걸렸습니다. 논문의 표 10에서 한 실험은 400번의 epoch와 1,000개의 앵커로 7시간이 소요되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n이 블로그 포스트에서는 NodePiece에 대해 자세히 알아보았습니다. NodePiece는 자연어 처리를 위해 사용되는 Transformer의 토크나이제이션 기법에서 영감을 받은 그래프 신경망의 혁신적인 접근 방식입니다. Transformer의 토크나이저가 텍스트를 관리 가능한 조각으로 분해하여 텍스트 분석을 혁신했던 것처럼, NodePiece는 그래프에 유사한 개념을 적용합니다. 그래프의 다양한 부분을 나타내기 위해 기본 요소 또는 \"토큰\"의 집합을 사용하여 복잡한 네트워크를 쉽게 처리할 수 있게 합니다.\n\nNodePiece가 거대하고 복잡한 그래프에서 노드를 나타내는 도전에 대응하기 위해 Transformer에서 사용되는 토크나이제이션 전략에서 아이디어를 빌렸다는 전반적인 내용을 시작으로 하였습니다. 이 접근 방식은 NodePiece가 노드의 본질과 관계를 효율적으로 포착할 수 있도록 하며, 각 노드를 명시적으로 식별할 필요가 없기 때문에(아이디를 통해서), 링크 예측, 노드 분류 등과 같은 작업에 대한 중요한 장점을 제공합니다.\n\n또한 NodePiece의 이론적 배경에 대해 다루었는데, 그래프 내에서 노드의 관계와 위치에 집중함으로써 노드를 유연하고 일반화된 방식으로 표현하는 방법을 설명했습니다. 이것은 노드의 표현을 단순화하고 모델이 다양한 그래프에서 학습하고 적응하는 능력을 향상시킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마침내, 교육적 목적을 고려하여 설계된 NodePiece 모델의 간소화된 구현을 소개했습니다. 이 구현은 NodePiece가 어떻게 작동하며 현실 세계의 그래프 신경망 작업에 어떻게 적용될 수 있는지를 이해하기 쉽도록 개념을 세분화했습니다.\n\n이 소개가 유용하게 느껴지길 바라며, 여러분의 그래프 프로젝트에서 NodePiece 토큰화를 활용할 수 있기를 기대합니다!\n\n이 이야기를 읽어주셔서 감사드립니다.\n\n# 참고문헌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., \u0026 Yakhnenko, O. (2013). 다중 관계 데이터 모델링을 위한 임베딩 번역. 신경 정보 처리 시스템 발전, 26. https://proceedings.neurips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html\n- Brochier, R., Guille, A., \u0026 Velcin, J. (2019). 노드 표현을 위한 글로벌 벡터. 월드 와이드 웹 컨퍼런스, 2587–2593. https://doi.org/10.1145/3308558.3313595\n- Church, K. W. (2017). Word2Vec. 자연어 공학, 23(1), 155–162.\n- Galkin, M., Denis, E., Wu, J., \u0026 Hamilton, W. L. (2021). Nodepiece: 대규모 지식 그래프의 구성적 및 매개 효율적 표현. arXiv Preprint arXiv:2106.12144.\n- Sennrich, R., Haddow, B., \u0026 Birch, A. (2016). 드문 단어의 신경 기계 번역 : 서브워드 단위(arXiv:1508.07909; 버전 5). arXiv. https://doi.org/10.48550/arXiv.1508.07909\n- Sun, Z., Deng, Z.-H., Nie, J.-Y., \u0026 Tang, J. (2019). RotatE: 복소 공간내 관계 회전에 의한 지식 그래프 임베딩(arXiv:1902.10197; 버전 1). arXiv. https://doi.org/10.48550/arXiv.1902.10197\n\n# 친근한 마음으로 안내합니다 💬\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 다음에도 놓치지 마세요:\n\n- 작가를 박수와 팔로우해 주세요 ️👏️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문: Stackademic | CoFeed | Venture | Cubed\n- PlainEnglish.io에서 더 많은 콘텐츠를 만나보세요\n","ogImage":{"url":"/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_0.png"},"coverImage":"/assets/img/2024-05-17-NodePieceFromNodeIDstoTokens_0.png","tag":["Tech"],"readingTime":42},{"title":"검색 및 분석 혁신 AI 통합으로 강화된 Elasticsearch의 벡터 검색 능력 탐색","description":"","date":"2024-05-17 20:03","slug":"2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration","content":"\n![링크 미리보기](/assets/img/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration_0.png)\n\n지속적으로 진화하는 검색 및 분석 환경에서 Elasticsearch는 동적이고 다재다능한 플랫폼으로 두각을 나타냅니다. Elasticsearch의 벡터 검색에 대한 여정은 그 진화의 핵심에 있습니다. 이 새로운 방법은 키워드로 검색하는 예전 방식을 뛰어넘어 게임을 완전히 바꿉니다. 최첨단 인공지능(AI) 기술을 통합함으로써 Elasticsearch의 벡터 검색 능력은 새로운 차원으로 확장되어 뛰어난 정확성, 맥락 인식, 확장성을 제공합니다.\n\n# 벡터 데이터베이스 이해: 기술적 관점\n\n벡터 데이터베이스는 데이터 저장 및 검색에서 패러다임 전환을 의미하며, 특히 전통적인 관계형 데이터베이스가 부족한 시나리오에서 빛을 발합니다. 일반적인 데이터베이스가 데이터를 표 형식으로 저장하는 데 반해, 벡터 데이터베이스는 고차원 공간에 벡터로 데이터를 저장합니다. 이를 통해 데이터의 세부적인 표현이 가능해지며, 특히 엔티티 간의 관계가 복잡하고 다면히된 도메인에서 더욱 정교한 표현이 가능해집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 벡터 데이터베이스의 주요 장점:\n\n- 효율적인 표현: 벡터는 복잡한 데이터 구조의 간결하고 효율적인 표현을 제공하여 고차원 데이터를 저장하고 처리하기에 이상적입니다.\n- 의미 유사성: 벡터 공간은 엔티티간의 의미 유사성을 측정할 수 있게 하여 보다 정교하고 문맥에 맞는 검색 및 분석이 가능합니다.\n- 확장성: 벡터 데이터베이스는 본질적으로 확장 가능하며, 성능이나 효율성을 희생하지 않고 대용량 데이터를 처리할 수 있습니다.\n\n# 벡터 데이터베이스 탐색: 비교적 개괄적인 투자\n\n벡터 데이터베이스 분야에서 Elasticsearch는 중요한 역할을 하지만, ChromaDB, Faiss, Milvus와 같은 대안 솔루션을 고려하는 것이 중요합니다. 각각에는 독특한 기능과 특정한 사용 사례가 있습니다. Elasticsearch가 빛을 발하는 시점과 대안적 벡터 데이터베이스가 선호되는 시점을 이해하기 위해 비교 분석에 대해 알아보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## ChromaDB:\n\nChromaDB는 미디어 응용 프로그램(예: 이미지 및 오디오 검색)에 특히 적합한 고차원 벡터의 효율적인 저장 및 검색을 위해 설계되었습니다. 전문적인 인덱싱 알고리즘을 사용하여 색 공간에서 유사성 검색을 최적화하여, 정확한 색 일치 및 인식이 필요한 작업에 이상적입니다.\n\n## Faiss:\n\nFacebook의 Faiss는 대규모 데이터셋에서의 유사성 검색에서 확장성과 속도로 유명합니다. 역 인덱스 및 제품 양자화와 같은 최첨단 인덱싱 기술을 활용하여, Faiss는 추천 시스템 및 멀티미디어 아카이브에서의 실시간 검색 및 분석 등을 요구하는 시나리오에서 뛰어난 성능을 발휘합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Milvus:\n\n밀부스는 질리즈가 개발한 오픈 소스 벡터 데이터베이스로, 방대한 양의 벡터 컬렉션을 효과적으로 관리하며 다양한 케이스에 맞는 인덱싱 전략을 제공합니다. GPU 가속 및 분산 컴퓨팅을 지원하여, 밀부스는 머신러닝 모델 관리, 산업용 IoT 배포에서의 고처리량 벡터 저장 및 검색을 필요로 하는 애플리케이션에 적합합니다.\n\n# Elasticsearch의 경쟁 우위: 비교 분석\n\n전문화된 벡터 검색 라이브러리 여러 개가 존재하지만, Elasticsearch는 벡터 데이터베이스 분야에서 독특한 장점을 제공하여 돋보입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Elasticsearch의 다재다능성:\n\nElasticsearch는 다른 백터 데이터베이스뿐만 아니라 강력한 검색 및 분석 플랫폼으로써 돋보입니다. 풍부한 쿼리 기능, 분산 아키텍처 및 AI 기술과의 원활한 통합을 통해 텍스트 및 벡터 기반 검색을 결합하는 응용프로그램에서 강력한 선택으로 인정받습니다. 많은 특수화된 벡터 검색 라이브러리와는 달리 Elasticsearch는 간단한 벡터 유사성 검색을 넘어 다양한 쿼리 유형, 필터 및 집계를 활용하는 풍부한 쿼리 환경을 제공합니다. Elasticsearch를 사용하면 사용자는 다양한 쿼리 유형, 필터 및 집계를 활용하여 복잡하고 미묘한 검색 작업을 수행할 수 있습니다.\n\n## 특수화된 사용 사례:\n\nElasticsearch는 다양한 사용 사례에 맞추어 제공되지만, ChromaDB, Faiss 및 Milvus와 같은 특수화된 벡터 데이터베이스는 특정 분야에서 뛰어난 성능을 발휘합니다. 실시간 검색을 필요로 하는 작업에서는 Faiss의 속도와 확장성이 탁월하며, ChromaDB는 색상 일치에 중점을 둔 다양한 멀티미디어 응용프로그램에서 필수적입니다. 반면 Milvus는 대규모 벡터 데이터셋을 효율적으로 관리해야 하는 시나리오에서 빛을 발하며, GPU 가속 및 분산 컴퓨팅을 활용하여 최적의 성능을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 확장성과 성능:\n\nElasticsearch의 분산 아키텍처는 대규모 데이터셋을 처리하기에 적합한 확장성과 내결함성을 보장합니다. 그러나 초고처리량 애플리케이션의 경우, Faiss와 Milvus는 GPU 가속화 및 분산 인덱싱과 같은 전문적인 최적화를 제공하여 특정 시나리오에서 우수한 성능을 발휘합니다.\n\n## AI 기술과의 원활한 통합:\n\nOpenAI의 GPT-3와 같은 AI 기술과 통합함으로써 Elasticsearch는 검색 및 분석 기능을 향상시킬 수 있는 탁월한 기회를 제공합니다. AI 기반 쿼리 이해, 콘텐츠 생성 및 문맥에 따른 추천 기능을 통해 Elasticsearch 사용자는 통찰력과 효율성의 새로운 차원을 열 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 벡터 검색의 역량을 발휘하는 Elasticsearch의 벡터 데이터베이스 기능\n\nElasticsearch가 전문 텍스트 검색 엔진에서 다양한 벡터 데이터베이스로 전환된 것은 dense_vector 데이터 유형과 script_score 기능과 같은 혁신적인 기능 덕분입니다. 이러한 기능은 사용자들이 벡터 검색의 모든 잠재력을 활용할 수 있게 하여 복잡한 데이터 환경을 쉽고 효율적으로 탐험할 수 있습니다.\n\n## dense_vector 데이터 유형 활용하기:\n\nElasticsearch의 dense_vector 데이터 유형은 고차원 벡터를 효율적으로 저장하는 데 특별히 설계되었습니다. dense_vector 데이터 유형을 활용하는 매핑을 정의함으로써 사용자들은 Elasticsearch 색인에 벡터 데이터를 신속하게 통합하여 다양한 고급 검색 및 분석 기능을 활용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n{\n  \"properties\": {\n    \"text-vector\": {\n      \"type\": \"dense_vector\",\n      \"dims\": 512 // 벡터 내 차원 수\n    }\n  }\n}\n```\n\n예시 코드 구현:\n\n```js\nfrom elasticsearch import Elasticsearch\n# Elasticsearch 인스턴스에 연결\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n# dense_vector 데이터 유형을 사용하여 매핑 정의\nmapping = {\n    \"properties\": {\n        \"text-vector\": {\n            \"type\": \"dense_vector\",\n            \"dims\": 512\n        }\n    }\n}\n# 정의된 매핑으로 색인 생성\nes.indices.create(index='my_index', body={'mappings': mapping})\n```\n\n## script_score 함수 활용:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nElasticsearch의 script_score 함수를 사용하면 사용자가 특정 요구 사항에 따라 점수 매기는 알고리즘을 사용자 정의할 수 있어요. 이 기능을 활용하면 쿼리 벡터와 문서 벡터 간의 사용자 정의 유사성 점수를 계산하여 보다 세밀하고 문맥을 고려한 검색 경험을 제공할 수 있어요.\n\n아래는 Markdown 형식으로 테이블 태그를 변경한 예시 코드에요:\n\n```js\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\": {\n        \"match_all\": {}\n      },\n      \"script\": {\n        \"source\": \"dotProduct(params.queryVector, 'text-vector') + 1.0\",\n        \"params\": {\n          \"queryVector\": [0.1, 0.2, 0.3, ...] // Query vector\n        }\n      }\n    }\n  }\n}\n```\n\n예시 코드 실행:\n\n```js\nfrom elasticsearch import Elasticsearch\n# Elasticsearch 인스턴스에 연결\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n# 쿼리 벡터 정의\nquery_vector = [0.1, 0.2, 0.3, ...]  # 예시 쿼리 벡터\n# script_score 함수가 포함된 쿼리 본문 정의\nquery_body = {\n    \"query\": {\n        \"script_score\": {\n            \"query\": {\"match_all\": {},\n            \"script\": {\n                \"source\": \"dotProduct(params.queryVector, 'text-vector') + 1.0\",\n                \"params\": {\"queryVector\": query_vector}\n            }\n        }\n    }\n}\n# 검색 쿼리 실행\nres = es.search(index=\"my_index\", body=query_body)\nprint(res)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Elasticsearch과 AI 통합: 새로운 가능성의 발현\n\nAI 기술을 Elasticsearch와 통합하면 사용자들이 데이터에서 더 깊은 통찰을 얻고 숨겨진 패턴을 발견할 수 있는 새로운 가능성이 열립니다.\n\n## 쿼리 이해를 위한 NLP 활용:\n\nElasticsearch와 자연어 처리(NLP) 모델을 결합하면 고급 쿼리 이해 기능을 활용할 수 있습니다. 사용자 쿼리의 의미론을 분석함으로써 Elasticsearch는 더 관련성 높은 검색 결과를 제공하고 사용자 경험을 향상시킬 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\n# elasticsearch과 transformers 패키지를 import합니다\nfrom elasticsearch import Elasticsearch\nfrom transformers import pipeline\n\n# Elasticsearch 인스턴스에 연결합니다\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n\n# 질문-답변 파이프라인을 정의합니다\nnlp = pipeline(\"question-answering\")\n\n# 사용자 질의를 정의합니다\nuser_query = \"Elasticsearch에서 벡터 검색의 이점은 무엇인가요?\"\n\n# 사용자 질의에서 관련 키워드를 추출합니다\nkeywords = nlp(user_query)[\"answer\"].split()\n\n# 키워드 매칭을 사용한 Elasticsearch 쿼리를 정의합니다\nquery_body = {\n    \"query\": {\n        \"match\": {\n            \"content\": \" \".join(keywords)\n        }\n    }\n}\n\n# 검색 쿼리를 실행합니다\nres = es.search(index=\"my_index\", body=query_body)\nprint(res)\n```\n\n## AI 기반 콘텐츠 생성 및 요약:\n\nAI 모델을 활용하여 콘텐츠 생성 및 요약은 Elasticsearch의 지식 추출 능력을 향상시킵니다. 문서의 요약을 자동으로 생성하거나 사용자 쿼리를 기반으로 새로운 콘텐츠를 생성함으로써, Elasticsearch는 정보 검색 및 의사 결정 프로세스를 용이하게 합니다.\n\n```python\n# elasticsearch과 transformers 패키지를 import합니다\nfrom elasticsearch import Elasticsearch\nfrom transformers import pipeline\n\n# Elasticsearch 인스턴스에 연결합니다\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n\n# 텍스트 요약을 위한 NLP 파이프라인을 정의합니다\nsummarizer = pipeline(\"summarization\")\n\n# Elasticsearch로부터 문서 내용을 검색합니다\ndoc_content = \"Elasticsearch로부터 추출한 샘플 문서 내용...\"\n# AI 모델을 사용하여 요약 생성합니다\nsummary = summarizer(doc_content, max_length=100, min_length=30, do_sample=False)\n# 생성된 요약을 Elasticsearch에 색인합니다\nes.index(index=\"my_index\", body={\"summary\": summary[0][\"summary_text\"]})\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Context-Aware Recommendations with ML:\n\n머신러닝 알고리즘은 사용자의 행동과 선호도를 분석하여 컨텍스트에 맞는 추천을 생성할 수 있습니다. ML 모델을 Elasticsearch와 통합함으로써 조직은 사용자 상호작용과 과거 데이터에 기반한 개인화된 추천을 제공할 수 있습니다.\n\n```python\nfrom elasticsearch import Elasticsearch\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Elasticsearch 인스턴스에 연결\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n\n# Elasticsearch에서 사용자 프로필 데이터 검색\nuser_profile = {\n    \"user_id\": \"123\",\n    \"interests\": [\"data science\", \"machine learning\", \"natural language processing\"]\n}\n\n# 사용자 관심사에 관련된 문서 검색\nquery_body = {\n    \"query\": {\n        \"terms\": {\n            \"content\": user_profile[\"interests\"]\n        }\n    }\n}\nres = es.search(index=\"my_index\", body=query_body)\n\n# 관련 문서 추출 및 유사도 점수 계산\ndocuments = [hit[\"_source\"][\"content\"] for hit in res[\"hits\"][\"hits\"]]\ntfidf_vectorizer = TfidfVectorizer()\ntfidf_matrix = tfidf_vectorizer.fit_transform(documents)\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n\n# 유사도 점수에 기반한 문서 추천\nsimilar_indices = cosine_similarities.argsort()[:, ::-1]\nrecommended_documents = [documents[i] for i in similar_indices[0][:5]]\nprint(recommended_documents)\n```\n\n# 결론: 검색과 분석의 미래를 선도하다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n엘라스틱서치의 다양한 벡터 데이터베이스로의 진화는 AI 통합과 결합되어 검색 및 분석 분야에서 패러다임 전환을 이루었습니다. 강력한 기능, 포괄적인 쿼리 기능, 그리고 AI 기술과의 원활한 통합을 통해 엘라스틱서치는 사용자들에게 전례 없는 정밀성과 효율성으로 복잡한 데이터 환경을 탐색할 수 있는 능력을 부여합니다. 조직이 벡터 데이터베이스와 AI 기반 통찰력의 잠재력을 받아들이는 가운데, 엘라스틱서치는 검색 및 분석 분야의 미래를 개척하며 선두에 서 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration_0.png"},"coverImage":"/assets/img/2024-05-17-RevolutionisingSearchandAnalyticsExploringElasticsearchsVectorSearchCapabilitiesEnhancedbyAIIntegration_0.png","tag":["Tech"],"readingTime":12},{"title":"인과 검증 만병 통치제","description":"","date":"2024-05-17 19:57","slug":"2024-05-17-CausalValidationAUnifiedTheoryofEverything","content":"\n![Causal Inference](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_0.png)\n\n# 소개\n\n인과 추론은 머신 러닝 내에서 부상 중인 분야로, 무엇이 발생할 수 있는지 예측하는 것을 넘어 그 이유를 설명하고, 그로 인해 문제의 근본적인 해결책을 제시함으로써 잠재적인 파급효과를 다루는 대신 지속적으로 해결책을 제공합니다.\n\n인과 모형의 주요 구성 요소 중 하나는 변수와 사건 간의 인과 관계를 간단한 시각적 형식으로 포착하는 \"유향 비순환 그래프\" (DAG)입니다. 그러나 DAG의 주요 문제점은 일반적으로 도메인 전문가에 의해 주관적으로 구성된다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서 DAG가 정확하다는 보장이 없습니다. 만약 DAG가 부정확하다면 인과 추론 모델의 연산과 결론이 잘못될 수 있습니다.\n\n인과 유효성은 DAG를 기반 데이터와 비교하여 오류나 모순을 식별하고 수정하는 과정을 설명하는 용어입니다. 이 작업을 신뢰성 있게 수행할 경우 인과 추론의 결론 및 관련 조치와 변경 사항이 개선된 영향과 결과로 이어질 것입니다.\n\n## 문제점\n\nDAG가 \"잘못\" 되는 여러 가지 방법이 있습니다. 인과 관련 문헌에서 다양한 유형의 오류에 대한 참조를 찾을 수 있지만, 인과 유효성을 종합적으로 다루는 방법에 대해 많은 정보가 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 기회\n\n만약 DAG(Directed Acyclic Graph)에서 모든 종류의 오류를 찾아 수정할 수 있는 통합적인 인과 유효성 알고리즘이 개발된다면, 영역 전문가의 주관적인 지식에 의존을 줄이고 인과 추론 모델의 신뢰성을 크게 향상시킬 수 있을 것입니다.\n\n## 계획 수립\n\n다른 종류의 DAG 오류에 대한 개별 알고리즘을 결합, 통합 및 테스트하여 인과 유효성을 위한 통합 이론을 만들 수 있는 방법에 대해 고민해 보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 배경\n\n다른 머신 러닝 문제와 마찬가지로 인과 추론 프로젝트는 기능 세트로 구성된 데이터로 시작됩니다…\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_1.png)\n\n인과 추론 모델의 목적은 모든 다른 변수의 효과가 고려되고 조정된 상태에서 치료(일반적으로 \"X\"로 레이블링)의 실제 효과를 결과(일반적으로 \"Y\"로 레이블링)에 수립하는 것이며, 시작점은 전문가들이 인과 관계에 대한 주관적 이해를 포착하기 위해 유향 비순환 그래프를 만드는 것입니다…\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Causal Validation Example](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_2.png)\n\n통합 인과 유효성 탐구를위한 가정의 예제로는 현실 세계에서의 의미가 없는 X, Z1, Z3 등의 노드 이름을 포함한 다양한 유형의 인과 관계가 포함 된 충분히 간단한 예제가 선택되었습니다.\n\n그러나 이해를 돕기 위해 X가 새 약 복용 수준을 나타낼 수 있고, W는 환자의 혈압에 미치는 약의 영향을 나타낼 수 있으며, Y는 환자 회복에 대한 영향을 나타낼 수 있습니다.\n\n이 예에서 화살표의 방향이 의미가 있습니다. 명백히 약을 복용하는 것은 혈압에 변화를 일으킬 수 있지만 그 반대는 아니며, 혈압의 변화가 환자 결과에 변화를 일으키는 경우도 마찬가지입니다. 그 반대는 매우 그럴듯하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예시의 이 단계에서는 데이터가 캡처되었고 제안된 관계를 나타내는 DAG가 구성되었습니다.\n\n이것은 인과 유효성을 설명하기 위해 디자인된 테스트 케이스이므로 DAG는 정확합니다. DAG와 데이터가 함께 가짜로 생성되었기 때문에 확실합니다. 그러나 만약 이것이 현실 세계의 문제였다면 어떨까요?\n\n도메인 전문가들이 잘못된 다른 DAG를 만들었다면 어떤 종류의 실수를 저질렀을까요?\n\n## 누락된 엣지 오류\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 유형의 오류는 빠진 링크나 엣지입니다 (링크와 엣지는 상호 교환 가능한 용어로 동일한 의미를 가지며, 한 노드/기능과 다른 노드/기능 간의 연결을 의미합니다).\n\n도메인 전문가들이 실제로 데이터에 존재하는 몇 가지 엣지를 완전히 누락할 수 있습니다. 예를 들어, 데이터와 현실 세계 사이에 Z3와 Y 간의 인과 관계 링크가 존재할 수 있지만 DAG에는 반영되지 않은 경우 …\n\n![image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_3.png)\n\n이 예시에서 DAG에는 누락된 엣지 오류가 포함되어 있으며, 데이터에 존재하는 엣지나 링크가 DAG에서 누락되면 인과 모델의 모든 계산과 결론이 잘못될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 잘못된 엣지 오류\n\n두 번째 유형의 오류는 가짜 엣지입니다. 즉, DAG에서 실제로 존재하지 않는 엣지가 식별되고 나타납니다.\n\n예를 들어, 도메인 전문가들이 Z1과 W 사이에 인과 관계가 있다고 제안했지만, DAG에 이 연결이 만들어졌지만 실제 데이터에는 존재하지 않을 수 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 데이터에는 존재하지 않지만 DAG에서 실제로 존재하지 않는 추가적인 인과 관계 링크가 식별되면, 인과 관계 계산 결과를 햇살이다는 결론을 내리는데 오류를 유발할 수 있습니다.\n\n## 역방향 엣지 오류\n\n마지막 오류 유형은 역방향 엣지 오류입니다. 즉, 전문가들이 두 기능 간의 관련을 정확하게 식별했지만 방향성을 잘못 이해한 경우입니다.\n\n예를 들어, 전문가들이 X와 Z3 사이에 인과 관계 링크를 제안했지만 실제 엣지 / 링크는 Z3에서 X로의 반대 방향에 있을 수 있습니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_5.png)\n\nDAG에서 실제 인과관계의 방향과 반대 방향에 있는 가장류가 원인을 계산하면 잘못된 답변도 나올 수 있습니다.\n\n# 인과 관계 유효성 검사 — 가장류 오류 감지 및 수정\n\n첫 번째 단계는 DAG에 어떤 유형의 오류가 존재하는지 이해하는 것입니다. 위에서 설명한 것처럼, 오류가 총 3가지 유형이 존재합니다 — 누락된 가장류, 부적절한 가장류 및 반전된 가장류입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 외 카테고리나 에러 유형이 없으므로 각각의 3가지 유형에 대한 인과 검증의 해결은 인과 검증을 위한 모든 것에 대한 통일된 이론으로 이어져야 합니다.\n\n## 독립과 의존의 중요성\n\n독립과 그 반대인 의존의 중요성이 DAG의 모든 3가지 유형의 오류를 감지하고 수정하는 데 중요하다는 것이 밝혀졌습니다.\n\n독립에 대한 공식적인 정의 제안 중 하나는 다음과 같습니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 이것은 초기 DAG에 적용될 수 있습니다(오류가 없는 것이며 데이터를 정확하게 대표한다고 가정합니다)...\n\n![Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_6.png)\n\nDAG로부터 명백하게 알 수 있듯이, 노드 Z1과 Z2(데이터에서의 특성 Z1과 Z2)는 연결되어 있지 않습니다.\n\nZ1의 값이 변경되더라도 Z2의 값은 변경되지 않을 것이며, 그들 사이에는 직간접적인 연결이 없기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 경우 Z2는 Z1과 독립되었다고 합니다. 이는 다음 식으로 나타낼 수 있습니다 (⫫ 기호는 \"더블 업택\"으로 불립니다) -\n\n![Expression](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_7.png)\n\nZ2가 Z1과 독립적인 개념은 데이터의 행에서 Z1과 Z2의 사례를 산점도로 나타내고 산점의 관계 값을 나타내는 차트에 선을 추가하여 시각화하고 이해할 수 있습니다...\n\n![Scatter Plot](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nZ1과 Z2 사이에는 상관 관계가 없음을 쉽게 알 수 있습니다. 계수는 0.03이며(거의 0에 가깝습니다), Z1을 1, 2 또는 4 증가시키더라도 Z2가 증가하지 않음을 알 수 있습니다. 왜냐하면 선의 계수가 거의 평평하기 때문입니다.\n\n뿐만 아니라 산점도의 점들의 패턴은 직선이 아닌 구름 형태이며, 이것들은 모두 Z2가 Z1과 독립적임을 보여줍니다.\n\nZ2가 Z1과 독립적이지만, DAG에서 반대로 상관 관계에 있는 다른 경우도 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_9.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nW가 X에 의존한다는 것은 직관적으로 명백합니다. 이는 X의 값이 변함에 따라 W가 변화한다는 것을 의미합니다. 이를 다음 표현으로 나타낼 수 있습니다(⫫̸ 기호는 \"슬래시된 두 번의 업택\"이라고 합니다)...\n\n![표 1](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_10.png)\n\n독립변수와 마찬가지로, 의존성 개념을 이해하는 데는 데이터의 특성 간 관계를 시각화하는 산점도가 도움이 될 수 있습니다...\n\n![표 2](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_11.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 경우 X와 Y 사이에 관계가 있는 것이 명백하게 보입니다. X 값을 20, 40 또는 60 증가시키면 Y 값도 명확하게 증가하고 산점점을 가장 잘 표현하는 직선의 계수는 6.77입니다. 따라서 X 값을 1 증가시키면 Y 값이 6.77 증가합니다.\n\n독립성 예제와는 달리, 이번에는 산점점들이 구름이 아니라 선을 형성하고 있어 서로에 의한지의 징표입니다.\n\n독립성과 의존성에 대한 자세한 탐구는 본 문서의 범위를 벗어나지만, 관심이 있고 pandas의 DataFrame 객체에 확장 기능을 추가하여 어떤 독립성 표현식을 쉽게 계산할 수 있는 방법을 배우고 싶다면 이 문서를 확인해보세요.\n\n## 누락된 엣지 오류 탐지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n링크 누락 오류는 원인 인과 문헌과 온라인에서 여러 곳에서 추적할 수 있는 알고리즘을 사용하여 탐지됩니다. 이 알고리즘은 독립성에 기반한 것인데요…\n\n다음에 나오는 DAG를 고려하여 설명할 수 있습니다. 여기에는 오류가 있는데요 — Z3에서 Y로의 링크가 누락되어 있습니다. 데이터가 합성적으로 생성되었기 때문에 데이터에 해당 링크가 존재하는 것으로 알려져 있습니다…\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_12.png)\n\n누락된 링크 유효성 검사 알고리즘은 독립성 테스트를 수행하는 모든 노드를 반복합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, 알고리즘이 노드 Y에 도달하면 \"노드는 부모에 의존할 때 조건부로 이전 노드와 독립적임\"이라는 문장은 Y가 부모인 노드 W와 Z2에 의존할 때 Y가 이전 노드 X, Z1 및 Z3과 (Y의 이전 노드) 독립적이라는 것을 의미합니다.\n\n이 문장은 위에서 설명한 독립성 표기를 사용하여 다음과 같은 표현으로 단순화될 수 있습니다...\n\n![image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_13.png)\n\n한 단계 더 나아가 표현은 완전한 형태로 확장될 수 있는데, 이는 그래프에서 Y가 X, Z1, Z3에 대해 W, Z2가 주어졌을 때 독립이라는 것을 요약하는 문장 Y가 데이터에서 W, Z2가 주어졌을 때 X, Z1, Z3과 독립이라는 것을 나타냅니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Table 14](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_14.png)\n\nThis condition can then be tested using the `.dependence()` extension method of the DataFrame class that was introduced in the section above ...\n\n![Table 15](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_15.png)\n\nThe results show that node Y is independent of nodes X and Z1 but Y is not independent of Z3 because the co-efficient for Z3 in the regression is 3.5012 and the p-value is 0.000.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 노드 Y에 대한 독립성 테스트가 DAG에 오류가 있는 것을 보여준 것뿐만 아니라 그 오류가 정확히 어디에 있는지, 즉 데이터에서 Z3와 Y 사이에 의존 관계가 있어 DAG에 추가해야 한다는 것을 보여준 것을 의미합니다.\n\n이제 DAG를 다음과 같이 \"고치\" 수 있습니다...\n\n![그림](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_16.png)\n\n전문가들이 제안한 DAG에 누락된 링크 오류가 있는 것으로 확인된 DAG는 원치 않는 유효성이 인식되어 Causal Validation을 사용하여 고쳐졌습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 독립성을 사용하여 누락된 링크를 감지하는 방법을 간략히 살펴보았습니다. 자세하고 상세한 설명은 다음 기사를 참조해 주세요...\n\n## 잘못된 가장자리 오류 감지\n\n인과 유효성을 연구해온 여러 달 동안 문헌에서 이상한 링크 오류를 탐구하는 사례나 이 유형의 오류를 해결하기 위한 알고리즘 제안 중 단 하나도 찾지 못했습니다.\n\n사실, 나는 정확히 3종류의 오류가 있다고 주장하는 자료를 찾은 적이 없었기 때문에 가능한 오류 종류 및 잘못된 링크에 대한 제안된 알고리즘에 관한 결론은 제가 직접 조사하고 Python 코드를 사용하여 수많은 시행착오를 거쳐 얻은 결과입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스풀러스 링크 알고리즘에 대한 아이디어가 떠올랐습니다. 빠진 링크 알고리즘을 파이썬으로 구현하는 과정에서 모든 오류를 \"고치는\" 데 충분한지 고민하며 도출되었습니다. 인과 유효성에 대한 통합 이론이 아직 멀리 떨어져 있지만, 스풀러스 링크 알고리즘은 상대적으로 직관적입니다.\n\n빠진 링크의 알고리즘을 수정하여 다음과 같은 명제에 도달했습니다...\n\n\"노드는 부모에 의존합니다.\"\n\n다음은 스풀러스 링크 오류(즉, DAG에 나타나지만 데이터에는 존재하지 않는 링크)가 의도적으로 도입된 예시 DAG입니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Causal Validation](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_17.png)\n\n이전 테스트와 마찬가지로, 의심 알고리즘 테스트는 모든 노드를 반복하면서, 이번에는 빠진 링크에 대한 독립성 테스트 대신 의존성 테스트를 진행합니다.\n\n알고리즘이 노드 W에 도달할 때 W가 그래프에서 X와 Z3(부모 노드)에 의존한다는 문장은 W가 데이터에서 X와 Z3에 의존한다는 것을 의미합니다...\n\n![Causal Validation](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_18.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다시 이 조건은 DataFrame 클래스의 .dependence() 확장 메서드를 사용하여 테스트할 수 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_19.png)\n\n결과에서 노드 W는 노드 X에 의존하지만 Z3에 대해 의존하지 않음을 보여줍니다. 이는 회귀에서 Z3에 대한 계수가 -0.1580(작음)이며 p-값이 0.566(0이 아님)임을 나타냅니다.\n\n이는 노드 W에 대한 의존성 테스트가 DAG에 오류가 있음을 보여주고 Z3로부터 W로의 잘못된 링크가 제거되어야한다는 것을 보여주었음을 의미합니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 1](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_20.png)\n\n## Detecting Reversed Edge Errors\n\nA solution to detecting reversed link errors eluded me for a long time and initially I thought it was impossible to solve because if the co-efficient between Z3 and X (for example) where 2.5 then the co-efficient between X and Z3 is the inverse …\n\n![Image 2](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_21.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n... 그리고 이 중 어떤 것이 방향성과 인과 관계를 함축하는지 알아내려면 어떻게 해야 할까요?\n\n이용 가능한 인과 관계 문헌과 온라인 기사에는 일부 단서와 징후가 있지만 포괄적이고 완전한 것은 없습니다. 제 연구를 통해 다음과 같은 결론과 해결책이 도출되었습니다...\n\n모든 DAG에는 처리 항목(X)과 결과 항목(Y)이 있으며 적어도 하나의 전방 경로(처리 항목에서 결과 항목까지의 DAG 경로)가 있습니다. 또한 추가적인 노드와 추가적인 링크가 있을 수 있지만, DAG는 비순환적이어야 합니다. 어떤 노드도 고아가 되어서는 안 됩니다.\n\n다양한 경로는 시작, 중간 및 끝 노드로 구성된 낮은 수준 단위인 점들로 분해할 수 있습니다. 이들은 정확히 2개의 링크를 가진 Chain(체인), Fork(포크) 및 Collider(충돌체)와 같이 3가지 유형의 점이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 3가지 타입 중에서 콜라이더는 의존성 테스트를 사용하여 감지할 수 있기 때문에 중요합니다. 한편, 체인과 포크는 정확히 동일한 결과 집합을 생성하므로 둘을 구별할 수 없습니다.\n\n아래 내용으로 요약할 수 있습니다 ...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_22.png)\n\n... 위 내용은 다음과 같습니다 ...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 충돌체 Y(결과)는 X(치료)와는 독립적입니다.\n- 연결 또는 포크의 경우 Y(결과)는 X(치료)에 따라 달라집니다.\n\n대부분의 문헌에서는 여기서 멈추지만, 한 단계 더 나아갈 수 있습니다. 충돌체에서 Y는 X와 독립적이지만 X와 Y 사이에 직접적이거나 간접적인 연결이 없는 경우에만 그렇습니다. 연결이 있으면 X의 “메시지”나 변경 사항이 Y의 변화를 일으켜 다시 종속적으로 만듭니다.\n\n이로 인해 \"v-구조\"라는 충돌체 하위 집합이 생기는데, 여기서 시작 노드와 끝 노드가 연결되어 있지 않은 단순한 충돌체입니다. 이 예시 DAG에 존재하는 모든 충돌체를 고려함으로써 쉽게 시각화할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5개의 충돌체가 있지만 두 개는 시작 노드와 끝 노드 사이에 직접적인 연결이 있습니다 (Z3 -`Y `- Z2 및 `- Z1 -` X `- Z2), 이를 \"인접\"이라고 합니다.\n\n\"인접\" 충돌체를 제거하면 예시 DAG에서 3개의 v-구조를 시각화할 수 있습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_24.png)\n\n3개의 v-구조는 다음과 같이 대체적으로 표현될 수 있습니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- W -`Y`- Z2\n- W -`Y`- Z3\n- Z1 -`Z3`- Z2\n\n시간을 내어 V-구조를 이해하는 이유는 해당 데이터에서 감지할 수 있으며, 이것을 기반으로한 알고리즘을 구성하여 링크의 방향성을 나타내고 따라서 반전을 탐지할 수 있게 됩니다. 이 알고리즘의 의사 코드는 다음과 같습니다.\n\n- DAG(Directed Acyclic Graph)의 모든 엣지 주위를 반복하며 각 엣지에 대해...\n- 현재 엣지를 뒤집어 새로운 DAG를 만듭니다.\n- 만약 V-구조가 파괴되고 해당 V-구조가 데이터에 존재하지 않는다면, 현재 DAG가 잘못되었고 엣지를 뒤집어야 합니다.\n\n- 엣지 뒤집기로 파괴된 DAG 내의 각 V-구조마다 이 종속성 테스트를 실행합니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_25.png\" /\u003e\n\n- 만약 이 테스트가 통과된다면, 현재 테스트 중인 엣지가 DAG에서 잘못되었고 뒤집어져야 한다는 것을 의미합니다.\n\n- 만약 v-구조가 생성되었거나 데이터에 해당 v-구조가 존재한다면 현재 DAG가 잘못되었고 엣지를 뒤집어야 합니다.\n\n- 엣지를 뒤집음으로써 DAG에서 생성된 각 v-구조에 대해 이 종속성 테스트를 실행합니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_26.png)\n\n- 이 테스트가 실패하면 현재 테스트 중인 엣지가 DAG(Directed Acyclic Graph)에서 잘못되었고 반전되어야 함을 나타냅니다.\n\nPython에서 DataFrame .dependency() 확장 메서드를 사용하여 이 알고리즘을 구현하면 반대로 링크된 부분을 감지하고 수정할 수 있습니다.\n\n예를 들어, 엣지/연결을 반전하려고 테스트할 때, 현재 테스트를 선택한 엣지가 Z1 -` Z3인 경우 다음 단계가 수행됩니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Z1을 Z3으로 뒤집으면 DAG에서 정확히 하나의 v-structure이 파괴됩니다 (Z1 -`Z3`- Z2)\n- 그런 다음 의존성 테스트를 데이터에 대해 다음과 같이 수행할 수 있습니다...\n\n![image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_27.png)\n\n결과는 Z2가 데이터에서 Z1에 의존하지 않는다는 것을 보여줍니다. 왜냐하면 계수가 매우 작기 때문이고 (-0.0253), p-값이 0이 아닙니다 (0.485).\n\n의존성 테스트는 통과되지 않았습니다 (즉, True를 반환하지 않았습니다). 따라서 Z1 -` Z3가 DAG에서 올바른 방향성을 가지고 있으며 뒤집어서는 안 됨을 추론할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 단계 1-4가 DAG(유향 비순환 그래프)의 각 엣지/링크에 반복적으로 적용된다면 모든 엣지의 방향성 및 전체 DAG의 유효성을 확인할 수 있습니다.\n\n더 자세한 내용을 알고 싶다면, 이 글에는 더 많은 코드 샘플이 포함된 v-구조에 대한 자세한 설명이 있습니다...\n\n## 누락된, 가짜 및 역방향 링크 오류 결합\n\n이전 섹션에서 DAG(유향 비순환 그래프)에는 누락된 엣지, 가짜 엣지 및 역방향 엣지라는 정확히 3가지 유형의 오류가 있음을 보여주었으며, 의존성 테스트가 어떻게 구현되는지를 보여주었으며, 파이썬에서 이 3가지 유형을 모두 탐지하는 방법을 보여주었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이론적으로는 원인 규명을 위한 \"모든 것의 통합 이론\"을 순차적으로 결합하여 달성할 수 있습니다. 그래서 다음과 같은 통합 원인 규명 알고리즘을 제안하여 시작해 봅시다...\n\n- 누락된 엣지 오류를 검사합니다.\n- 잘못된 엣지 오류를 검사합니다.\n- 역으로 연결된 엣지 오류를 검사합니다.\n\n직관적으로 이 알고리즘이 작동해야 하지만 실제로 구현되고 견고하게 테스트되었을 때 일관적으로 실패하며 그 이유는 다음과 같습니다.\n\n시작하기 전에 DAG에 오류가 포함되어 있다고 가정해 봅시다 — Z2와 Z3 노드 사이에 누락된 엣지가 있는 경우...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_28.png)\n\nThe first step, which is testing for missing edges, will identify the missing edge. However, in step 3, the directionality of the v-structure at Z1 -`Z3`- Z2 cannot be tested because it does not exist due to the missing edge.\n\nThis issue can be easily resolved by updating the unified algorithm as follows:\n\n- Test for any Missing Edge Errors\n- Note any errors found and correct them\n- Test for Spurious Edge Errors\n- Note any errors found and correct them\n- Test for and Fix Reversed Edge Errors\n- Note any errors found\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 문제가 해결되었습니다. 단계 1은 Z2 - Z3 사이에 누락된 엣지를 복원하고, 그 후 단계 3에서의 반전 사항이 올바르게 테스트될 것입니다. 하지만 더 심각한 문제가 있습니다.\n\n이제 DAG에 다른 오류가 있다고 가정해 봅시다. 이 예제에서는 X와 W 사이의 엣지가 잘못된 방향을 가지고 있고 역전되어 있습니다...\n\nStep 1에서 누락된 링크를 테스트하는 과정은 \"노드가 부모에 조건을 붙여 조건이 부모에게 독립적일 때\"라는 조건을 실행하며 모든 노드를 반복합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 DAG가 정확하다면(X와 W 사이의 엣지가 X → W로 변경된다면) 이 조건은 다음과 같이 해결됩니다...\n\n\u003cimg src=\"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_30.png\" /\u003e\n\n그러나 이 DAG에 오류가 포함되어 있기 때문에 X가 더 이상 W의 상위 요소가 아닙니다(사실상 W가 이제 X의 상위 요소가 됩니다). 이것은 선행자인 Z1, Z2, Z3와 W 사이의 누락된 링크가 감지되지 않으며 심지어 새로운 부모 및 선행자 집합을 기반으로 반복에서 모든 노드에 대해 실행되는 누락된 링크 테스트 집합이 모두 완전히 잘못될 것입니다.\n\n특정 경우에는 순차 테스트의 순서를 변경하여 역방향 엣지 오류를 식별하고 수정한 후에 누락된 및 잘못된 엣지 테스트를 수행함으로써 만족스러운 결과를 얻을 수 있습니다. 그러나 이는 테스트에서 오류의 사전 지식, 즉 단일 역방향 엣지가 테스트를 생성하는 방법이기 때문에 가능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n실제 세계의 인과 추론 문제에서 데이터 팀은 완전히 알지 못할 것입니다...\n\n- DAG에 오류가 있는지 여부 및...\n- 오류의 종류(결여, 가짜 또는 반전)를 구별할 수 없을 것입니다.\n\n예를 들어 한 DAG에는 하나의 가짜 엣지 오류가 있을 수 있고 다른 DAG에는 결여 엣지와 반전 엣지가 있는 등 다양한 오류가 있을 수 있습니다.\n\n이는 순차적 테스트의 순서를 변경하여 인과 관계 유효성을 위한 통합 이론을 제시하는 시도를 무효화합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 해결책을 찾아야 합니다.\n\n# 인과 유효성을 위한 제안된 모든 것의 통합 이론\n\n내 연구에 있어서 나는 인과 유효성을 위한 모든 것의 통합 이론에 대해 포기할 뻔했습니다.\n\n저는 각각의 3가지 유형의 오류를 성공적으로 감지하기 위한 알고리즘을 개발했는데, 이는 해당 알고리즘이 일치하는 유형의 오류만이 있고 다른 오류는 없는 경우에만 사용할 수 있는 신뢰성이 있는 기능을 수행했습니다. 실제로 이것은 쓸모가 없습니다. 왜냐하면 사전에 오류가 무엇인지 알 수 없기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n순차 알고리즘의 실패로, 재귀적인 해결책이 동작할 수 있을 것이라 의심하기 시작했습니다. 나는 프로그래밍에서 재귀를 항상 좋아해왔어; 그것은 우아하게 간단하면서도 악랄하게 복잡한데 동시에 한번 복잡성을 이해하고 나면, 수십 줄의 비재귀 코드로 해결되기 어려운 문제들을 몇 줄의 우아한 코드로 해결할 수 있는 특정한 종류가 있습니다.\n\n프로그래밍에서의 재귀는 간단히 말해 자기 자신을 호출하는 함수를 의미합니다. 다른 함수를 호출하는 함수를 작성하는 것은 아주 흔하지만, 함수가 다시 자기 자신을 호출하는 것은 그렇게 흔하지 않죠.\n\n재귀적 해결책은 종종 나무 구조(가계도와 같은)를 탐색, 구문 분석 또는 수정하는 알고리즘에서 사용됩니다. 그것들을 이해하는 가장 좋은 방법은 자신에게 다시 호출하는 것을 새로운 함수를 호출하는 것으로 보는 것입니다.\n\n만약에 그것이 여전히 잘 이해되지 않는다면, 재귀 함수를 디버깅하고 모든 호출을 하나씩 따라가면 이해하고 구현하는 데 도움이 될 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것이 인과 유효성을 위한 제안된 모든 것의 통합 이론에 대한 의사 코드입니다...\n\nfix_dag(DAG):\n\n- 만약 DAG가 유효하거나 재귀 호출의 최대 횟수에 도달했을 경우 재귀를 중단하고 DAG를 반환합니다.\n- 누락된 엣지가 발견되면 그것을 수정하고 fix_dag(FIXED_DAG)를 호출합니다.\n- 잘못된 엣지가 발견되면 그것을 수정하고 fix_dag(FIXED_DAG)를 호출합니다.\n- 역으로 뒤집힌 엣지가 발견되면 그것을 수정하고 fix_dag(FIXED_DAG)를 호출합니다.\n\n첫눈에 보기에는 이 순차 알고리즘과 거의 동일해 보이지만 매우 다릅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테스트의 순서에 더 이상 의존하지 않습니다. 순환 내에 순서가 있더라도, 재귀 알고리즘은 계속해서 고침을 시도하고 \"고친\" DAG가 유효한지를 평가할 것입니다. 이렇게 변경이 축적되어 유효한 DAG를 얻게 됩니다(또는 재귀의 최대 횟수에 도달하게 됩니다).\n\n원래 DAG의 오류는 최종으로 고쳐진 DAG와 비교하여 차이점을 식별하는 것으로 유추할 수 있습니다.\n\n## 통합 이론을 위한 Python 코드\n\n백그라운드에서 실행되는 코드의 전부를 보여주는 것은 현실적이지 않습니다. 그러나 아래에 알고리즘을 구현한 fix_dag와 difference 코드가 있습니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 통합 이론 테스트\n\n제안된 알고리즘을 파괴하기 전에 고려해야 할 문제가 하나 더 있습니다.\n\n3가지 유형의 오류와 각각의 탐지 알고리즘을 탐구한 이전 기사들은 \"힌트\"를 제공하는 증거를 제공했습니다.\n\n힌트는 DAG 내의 특정 엣지가 정확하다는 것을 알고리즘에 전달하는 어설션으로, 알고리즘에 해당 엣지를 확인하지 않도록 지시합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3가지 유형의 테스트 운영에 있어서 힌트 제공은 중요하다는 것이 밝혀졌습니다. 실제로는 확인 및 테스트를 통해 구분할 수 없는 다양한 DAG(Directed Acyclic Graph)가 존재할 수 있기 때문입니다.\n\n인과 문헌에서는 구분할 수 없는 DAG 집합을 \"동등 클래스\"로 참조하며 유일한 방어 수단은 동등한 클래스를 검색 공간에서 제거하기 위해 충분한 힌트를 제공하는 것입니다.\n\n힌트의 또 다른 장점은 확인해야 하는 순열을 대폭 줄여준다는 것입니다.\n\n역방향 엣지 알고리즘의 일부인 부분은 유효한 DAG를 식별하기 위해 모든 역방향 엣지 조합을 탐색합니다. 11개의 엣지가 있는 경우 탐색 공간은 2의 11제곱 = 2048이지만 엣지 수를 1개만 늘리면 2의 12제곱 = 4096이 되는 식입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬은 해석형 언어이며 모서리의 수가 늘어날수록 성능이 기하급수적으로 저하되므로, 힌팅 엣지를 사용하면 처리 시간을 크게 줄일 수 있습니다.\n\n## 예제 테스트 DAG에서의 힌팅 엣지\n\nDAG에 관련된 몇 가지 원칙들이 힌팅 엣지 집합을 개발하는 데 도움이 됩니다.\n\n먼저, DAG를 순환적으로 만들 수 있는 모든 엣지는 정의상 제외되어야 하며, 순환 DAG를 유발할 가능성이 있는 변경 집합을 테스트하지 않는 것이 최상의 접근 방식입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n병리와 효과의 성질에서 단서가 있습니다. 일반적으로 경로는 치료에서 효과로 흐르며, 정의상 효과는 사건을 일으키지 않아야 합니다. 따라서 가장자리는 효과 노드로 흐르고 반대 방향으로 흐르면 안 됩니다. 이에 몇 가지 예외 사항이 있지만, 이것은 좋은 팁이며 마찬가지로 인과 관계와 따라서 가장자리는 치료에서 멀어져야 합니다.\n\n더 나아가서 외생 노드를 고려함으로써 추가적인 단서를 얻을 수 있습니다. 우리 예시에서는 Z1과 Z2가 외생노드입니다. 외생 노드는 DAG와 인과 관계 모델의 \"입력\"이며 다른 모든 노드는 보이지 않는 일련의 구조 방정식으로부터 구축됩니다(예: Z3 = 3 xZ1 + 1.5 x Z2+ ε).\n\n외생 노드와 변수의 식별이 잘못될 수 있지만, 데이터와 도메인 전문가는 DAG와 모델의 입력 변수가 무엇인지 모를 가능성이 매우 낮습니다.\n\n따라서 인과 관계와 가장자리가 외생 변수/노드에서 멀어지는 것이 매우 가능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로 추적성 개념이 있습니다. 예를 들어 DAG에서 X가 W를 일으키고 W가 Y를 일으킨다고 가정해 봅시다. 만약 X가 약물이라면, W가 혈압이고 Y가 환자 결과라고 한다면, 약물이 직접적으로 환자 결과를 일으키하는 것은 불가능합니다.\n\n약물이 보통 환자들의 어떤 부분을 변경하고, 그 결과로 환자 결과를 개선시킵니다. 도메인 전문가가 Z2 -` Z3 -` X와 같이 어떤 추이적인 인과 관계를 식별했다면, Z2가 X를 직접 일으키는 것은 불가능합니다. Z2, Z3, X가 무엇을 나타내든 간에 그렇습니다.\n\n요약하면, 이러한 특성들은 힌트를 식별하는 데 도움이 되는 단서를 제공할 수 있습니다...\n\n- 비순환성\n- 외생성\n- 추적성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 시도하면서 더욱 발전시킬 수 있습니다...\n\n- 알고리즘 실행하기\n- 결과 확인하기\n- 도메인 전문가들이 동의하지 않는 알고리즘 오류를 제안했다면, 힌트로 추가하고 1단계로 돌아가기\n\nAcyclity, Exogeneity, Transitivity의 방법을 사용하여 (\"예시 DAG는 가짜이므로 도메인 전문가의 도움이 없는 경우\") 제안된 \"인과적 유효성에 대한 모든 것의 통합 이론\" 구현 알고리즘을 위하여 제공할 합리적인 힌트의 세트는 다음과 같이 테스트에 사용되었습니다.\n\n하이라이트가 에지(예: W -` Y)를 가려주면 해당 에지가 올바르다는 것을 암시하며, 공간을 가린다면(예: Z1 -` Z2) 에지가 없는 것이 올바르다는 것을 암시합니다. 부재 중인 에지가 양방향으로 힌트를 줄 수 있음에 유의하여, 일부 에지가 두 번 암시된 것처럼 보일 수 있습니다(예: Z1 -` Z2 및 Z2 -` Z1).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Test Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_31.png)\n\n# Testing the Algorithm\n\nThe next stage is to robustly and exhaustively test the algorithm for different combinations of the 3 types of errors and to measure performance.\n\nThe test harness works as follows:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n준비\n\n- 오류의 유형과 수를 선택합니다 (예: 누락된 엣지 1개, 잘못된 엣지 0개, 역전된 엣지 1개)\n- 이 조합을 포함하는 모든 유효한 DAG의 가능한 조합을 생성합니다 (즉, 정확히 1개의 누락된 엣지와 1개의 역전된 엣지를 포함하는 모든 DAG) 힌트를 제외한)\n- 유효한 조합에서 n개의 테스트를 선택합니다 (예: 10개의 테스트)\n\n실행\n\n- 선택한 각 테스트에 대해...\n- 테스트/예제 DAG를 시작점으로 사용하여 오류 DAG를 생성하고, 오류를 만들기 위해 변경 사항을 적용합니다 (즉, 1개의 누락된 엣지를 제거하고, 1개의 역전된 엣지를 반전합니다)\n- 유효한 DAG에 대한 새로운 데이터 세트를 생성합니다 (오류가 있는 것이 아닌)\n- 오류 DAG를 수정하고 생성된 데이터를 통해 오류를 확인하기 위해 재귀적인 fix_dag 함수를 호출합니다\n- 오류 DAG를 생성하는 데 사용된 확인된 오류와 비교합니다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 태그를 마크다운 형식으로 변경해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 유효한 가짜 엣지 검사를 생성하기 위해 존재하지 않는 3 개의 엣지가 추가된 예시입니다...\n\n![예시 이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_33.png)\n\n마지막으로 역으로 변경된 유효한 엣지 검사를 생성하기 위해 3개의 엣지가 뒤바뀐 예시입니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_34.png\" /\u003e\n\n위 예에서 용어 \"유효한\" 테스트가 일부러 사용되었습니다. DAG를 순환적으로 만들거나 힌트에 포함된 변경 내용을 제외하고 제거, 추가 또는 반전할 수 있는 다른 엣지도 있습니다.\n\n## 테스트 결과\n\n다음은 3가지 유형의 오류 조합에 대한 테스트 결과입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 각 유형의 1개\n\n테스트 첫 번째 배치는 부재, 잘못된 및 역전된 엣지 각각 1개를 시도하는 것입니다. 결과는 다음과 같습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_35.png)\n\n결과는 단일 부족한 엣지가 있는 DAG(Directed Acyclic Graph)에서 단일 오류가 100%의 정확도로 감지됩니다. 단일 역전된 엣지가 있는 DAG 및 단일 잘못된 엣지가 있는 DAG도 각각 100%와 66.7%의 정확도로 감지됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n잘못된 가장자리 결과는 약간 좋지 않아 보일 수 있지만, 단일 가짜 링크에 대한 유효한 테스트 수는 3개 뿐이며 알고리즘이 Z1-W로부터의 가짜 링크를 감지하는 데 어려움을 겪습니다. 다른 방법으로 말하면, 가장자리 탐지에서 단일 실패만 있으며 다른 유형에 대한 실패는 없습니다.\n\n## 다른 두 가지 유형의 오류\n\n2가지 다른 오류에 대한 테스트는 다음과 같이 수행됩니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_36.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDAG에는 1개의 누락된 엣지 오류와 1개의 잘못된 엣지 오류가 있을 때, 통합 검증 알고리즘은 테스트 케이스의 100%에서 오류를 올바르게 식별합니다. 1개의 누락된 엣지 오류와 1개의 반대 방향 엣지 오류는 테스트의 78%에서 정확하게 식별되며, 1개의 잘못된 엣지 오류와 1개의 반대 방향 오류는 테스트의 78%에서 정확하게 식별됩니다.\n\n이러한 결과들은 인상적입니다. 이는 비재귀적 해결책에 대한 주요 문제인 개별 테스트가 DAG에 포함된 오류에 대한 일부 선험적 지식으로 순서가 지정되어야 한다는 것이 재귀 알고리즘에 의해 완전히 해결되었다는 것을 보여줍니다.\n\n또한 이러한 결과들은 해당 알고리즘이 실제 원인 추론 문제에서 유용할 것이라는 것을 시사합니다. 도메인 전문가들이 실제 세계에서 찾을 수 있는 실제 인과성과 유사한 DAG를 생성할 수 있다는 합리적인 가정을 한다면, 그들이 소수의 실수를 할 수 있다는 것을 의미합니다.\n\n이러한 가정을 고려할 때, 이러한 결과들은 알고리즘이 잘못된 DAG를 수정할 수 있으며, 후속 원인 모델링 단계에서 지시적이고 유용하며 사용 가능한 결과를 얻기 위한 선행 조건임을 보여줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 각 유형별로 2개씩\n\n각 유형의 오류가 2개씩 포함된 경우 테스트 결과는 다음과 같습니다...\n\n![그림](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_37.png)\n\n테스트 DAG에 각 종류의 오류가 2개씩 있는 경우 정확도가 저하됩니다. 2개의 누락된 엣지는 83.3%의 높은 정확도를 유지하지만, 2개의 가짜 엣지는 33.3%의 정확도로만 탐지되며, 2개의 역방향 엣지의 정확도는 25%입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 각 유형의 1개씩 있는 경우 DAG\n\n다음 단계는 테스트를 더 다양하게 만들고 각각 누락, 가짜 및 역방향 오류 중 하나를 포함하는 DAG 세트를 시도하는 것입니다. 즉, 1개의 누락, 1개의 가짜, 1개의 역방향 = 각 테스트 DAG에 3개의 오류가 있는 것입니다...\n\n![Test Image](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_38.png)\n\n이 테스트에서는, 각 유형의 1개씩 에러가 포함된 DAG가 80%의 케이스에서 정확하게 감지된다는 것을 보여줍니다. 이는 놀라운 테스트 결과입니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDAG에는 3가지 유형의 오류가 포함될 수 있으며, 이 오류 조합은 80%의 정확도로 올바르게 식별됩니다!\n\n## 동일한 DAG 내의 각 유형 2가지\n\n마지막으로 각 유형의 오류가 2개 포함된 DAG에 대한 테스트 결과는 다음과 같습니다...\n\n![이미지](/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_39.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예시 DAG에는 총 6개의 오류가 있습니다. 이 중 2개는 누락, 2개는 잘못된 정보, 그리고 2개는 역전된 정보입니다. 이러한 오류들이 신뢰성 있게 감지되지 않을 수도 있습니다. 그러나 예시 DAG는 단지 8개의 엣지를 가지고 있고, 이 테스트에서 8개 중 6개 또는 75%의 엣지가 잘못되어 있기 때문에 이는 놀라운 일이 아닙니다.\n\n# 결론\n\n\"모든 것의 통합 이론\" 인과적 유효성 검사 알고리즘은 완벽하지 않으며, 더 복잡하고 다양하며 오류가 많을수록 정확도가 떨어집니다.\n\n그러나 정확도는 충분히 높아서 사용 가능하고 유용합니다. 실제 프로젝트에서는 알고리즘에 의해 식별된 오류가 도메인 전문가들에 의해 검토되고, DAG에 점진적인 변경이 가해지며, 최종 DAG가 합의될 때까지 검증이 반복적으로 실행됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n리뷰, 비판 및 수정에 더 많은 노력을 기울이면, 유효성 검사 알고리즘이 실행되기 전에 도메인 전문 지식을 활용하여 DAG를 개선하는 데 더 좋은 결과를 얻을 수 있습니다.\n\n재귀 및 힌트를 통해 제공된 모든 개선을 갖춘 통합 알고리즘조차도 한계가 있지만, 데이터와 현실에서 내재된 인과 관계를 정확하게 포착하는 DAG를 제안하는 핵심 단계에 도움이 되는 가치 있는 도구를 제공하는 정확도는 충분합니다. 이는 인과 추론 머신러닝 모델로부터 유용하고 실용적이며 신뢰할 수 있는 결과를 도출하는 데 중요합니다.\n\n# 추가 연구\n\n다양한 종류의 오류가 100% 신뢰성으로 감지되지 못하는 주요 이유 중 하나는 종속성 테스트의 성능 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n의존성 테스트는 누락된 링크 테스트를 구현하고 각 변수에 대해 결과를 평가할 수 있어야 하는 Y ⫫ X, Z1, Z3 | W, Z2와 같은 식을 유연하게 평가할 수 있어야 합니다.\n\n이전 글에서 설명한 바와 같이 (위 링크 참조) p 값만으로 회귀 결과를 보는 것은 신뢰할 수 없습니다. 그래서 나의 해결책은 계수와 p 값의 조합을 보는 것이었고, 선택한 임계값은 여러 테스트에서 시행착오를 거쳐 결정했습니다.\n\n최종 결과는 내가 만든 의존성 테스트가 100% 신뢰할 수 없지만 가능한 한 가까울 수 있도록 구현했다는 것입니다. 개선할 수 있는 옵션이 있을 수도 있습니다.\n\n- 성능을 향상시키기 위해 p 값과 계수를 평가하는 다른 방법이 있을까요?\n- 성능이 더 좋은 회귀 솔루션에 대해 완전히 다른 접근 방식이 있을까요?\n- 인과 관계 검증을 위한 제안된 통일 된 모든 이론을 완전히 다른 것으로 바꿔 성능을 더 향상시킬 수 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수많은 달 동안 책과 온라인 기사를 찾아보고 여러 다른 소스에서 솔루션을 조합해왔는데, 이제 최상의 성능을 이룰 수 있었어요.\n\n제가 상기한 3가지 옵션 중 하나를 기반으로 개선 아이디어가 있는 분이나, 고려하지 못한 옵션을 사용하여 개선 아이디어가 있는 분 있으면 연락 주세요. 여러분의 소식을 듣고 싶어요.\n\n한편, 이 기사는 총 5편 중 마지막으로, 인과 관계 확인을 위한 모든 것의 통일된 이론을 달성한 결실을 의미하며, 이를 활용하여 실제 기업 환경에서 영향과 결과를 이끌어내기 위해 이론과 다른 기법을 어떻게 활용했는지 설명할 것입니다.\n\n# 연락하고 소통하기...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사가 마음에 들었다면 제 팔로우를 눌러주세요. 앞으로도 계속해서 새로운 기사들을 받아보실 수 있습니다.\n\n원하는 주제나 의견이 있다면, 특히 인과 추론 및 새로운 데이터 과학 분야에 관심이 있다면 댓글을 남겨주세요. 제게 연락 주시면 감사하겠습니다.\n\n저의 이전 기사를 확인하려면 제 블로그인 The Data Blog에서 제 연구와 인과 추론에 대한 모든 것을 찾아볼 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_0.png"},"coverImage":"/assets/img/2024-05-17-CausalValidationAUnifiedTheoryofEverything_0.png","tag":["Tech"],"readingTime":40},{"title":"더블 박사","description":"","date":"2024-05-17 19:54","slug":"2024-05-17-DoublePhD","content":"\n![이미지](/assets/img/2024-05-17-DoublePhD_0.png)\n\n\"어릴 적부터 과학에 대한 깊은 사랑을 품고 왔습니다. 이 열정이 나를 분야에서의 경력으로 자연스럽게 이끌었습니다. AIEEE 입학 시험을 통과한 후, 2010년 NIT Uttarakhand에서 제 첫 공학 여정을 시작했습니다. 그 해는 처음으로 개설된 공학 코스였지만, 많은 고난을 겪었습니다.\n\n당시 NIT Uttarakhand는 임시 캠퍼스와 필수적인 자원 부족으로 인한 어려움에 직면했습니다. 이로 인해 학생들의 불만이 끊임없이 솟구쳤고, 우리는 영구적인 캠퍼스를 원하며 우리의 열정적인 호소를 우탄칸드 정부 관리자들에게 전달했습니다. 그러나 10년이 지난 지금도 저희 학교는 여전히 영구 캠퍼스를 기다리고 있습니다!\n\n제 BTech 마지막 학년이 지나면서 상황은 조금 나아졌습니다. 대학 학부 과정을 진행하면서 Coursera와 같은 온라인 플랫폼을 통한 독학은 학교의 제약으로부터 남은 부분을 보충하는 데 있어서 귀중한 도구가 되었습니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 원래 가르치는 직업에 매료되었습니다. 그러나 정부의 교육 역할에 대한 MTech 학위 필요 규정으로 인해 내 포부를 조정하게 되었습니다. GATE 점수가 기대에 못 미치는 수준이었지만, NIT Hamirpur에 석사과정 입학을 성공했습니다.\n\n가르치는 직업에 대한 나의 열망은 삶을 바꾸는 사건인 6개월간의 침대에서의 휴식을 강요하는 사고로 인해 일시적으로 중단되었습니다. 이때 나는 박사 과정을 쫓기로 결정했습니다. 나의 선택한 분야를 더 깊게 탐구할 뿐만 아니라 가르치는 역량을 향상시키는 발판으로 보았습니다.\n\n나의 박사 학위 연구 여정은 컴퓨터 과학, 신경과학, 그리고 심리학을 융합하여 기계 학습의 시각을 통해 우울증의 수수께끼를 풀어나가는 것에 초점을 맞추며 시작했습니다. 이 노력은 MHRD의 자금 지원을 통해 지원을 받아, 나의 IIT Roorkee에서의 임기 중에 많은 도움을 얻을 수 있었습니다. 그러나 기계 학습 분야의 급격한 변화는 가끔 내게 사기를 꺾는 느낌을 줬습니다.\n\n나의 학술적 여정에서의 전환점은 SPARK라 불리는 협력 프로그램으로 찾아왔습니다. 그것은 네덜란드 그로닌겐 대학과의 이중 박사 과정을 쫓을 수 있는 기회를 내게 제공했습니다. 이 국제적 협업은 팬데믹의 제약들로 인해 방해를 받았지만, 독특한 경험과 학습 기회를 제공하였습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금까지의 여정을 되돌아보면, 학업에서 가장 중요한 것은 열정과 목적의 중요성입니다. 머신 러닝과 같이 동적이고 도전적인 분야에서는 진로 전망이 풍부한데, 이러한 본래적 동기가 우리를 지탱하고 전진시킵니다. 비슷한 길을 고민하는 이들에게 알립니다. 지식을 쫓는 것은 목적을 달성하는 수단뿐만이 아니라 자아 발견과 성취의 여정입니다.\"\n\n- 인도 공과대학 쿠마오와 네덜란드 그로닌겐 대학에서 컴퓨터 과학 박사 Anmol Gupta\n\nPayel Das가 인터뷰하고 작성함\n","ogImage":{"url":"/assets/img/2024-05-17-DoublePhD_0.png"},"coverImage":"/assets/img/2024-05-17-DoublePhD_0.png","tag":["Tech"],"readingTime":2},{"title":"왜 인공지능이 음악가를 대체할 수 없을까","description":"","date":"2024-05-17 19:52","slug":"2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians","content":"\n\u003cimg src=\"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_0.png\" /\u003e\n\n작년 4월, 팝 스타 그라임스(Grimes)가 트위터에 발표하여 헤드라인을 독차지했어요. 현재 X(그녀의 베이비 대디 소유의 실패한 플랫폼)에 그녀의 목소리를 사용하는 사람과 로열티를 50-50으로 분할한다고 발표했어요. 이는 음악 산업을 광폭화시켰지만 사람들이 진지한 마음으로 생각하기 시작할 때까지 계속 되었어요. 그라임스는 미래 기술을 옹호해온 항상이지만, 그것이 이미 올 것을 의미하는 것은 아니에요. 그녀는 몇 년간 새 앨범을 발표하지 않았어요. 그리고 그녀는 어디에서든 노래를 부를 수 있지만, 그녀는 정확히 휘트니 휴스턴은 아니에요. 그녀의 재능은 노래 작곡가와 프로듀서로 더 많이 발휘되고 있어요.\n\n인공지능은 많은 일을 할 수 있고, 더 많은 기능을 추가하면서 진화하고 있어요. 사기 탐지, 천문학 연구, 챗봇, Siri 등이 그것의 사용 사례 중 일부예요. 하지만 우리는 여전히 많은 결함들을 해결하지 못하고 있어요. 최근 캘리포니아의 한 범죄 현장을 통과하던 자율 주행차가 노란 경찰 테이프로 둘러싸인 범죄 장면으로 통과했어요. 테슬라에는 교통 콘 위에 라이트를 올려두면 이동하지 않는 결함이 있어요. 짐미 키멜이 스마트 스피커인 Echo에 팬케이크 믹스를 주문하도록 지시하는 세그먼트가 있었는데, 시청자들은 다음 날 아침 아마존 위시리스트에 빅스퀵 두 상자를 발견했어요. 또한 인공지능이 반드시 좋은 습관을 유도하는 것은 아니에요. 예전 이웃인 에반은 글쎄요, 망치 한 봉지보다 서둘기였지만, \"나는 그녀에게 기술에 소리 지르게 가르치기 싫어\"라며 그의 3세 딸에게 알렉사를 빼앗아갔어요. (이 사람은 한번 라이터로 얼어붙은 진흙 더미를 불태워 겨울 뒷마당 스모어 쿠크아웃을 시작하려고 시도한 사람이에요. 그리 높은 표준은 아니죠.)\n\n\u003cimg src=\"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_1.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAI를 창의적 예술에 활용하는 데의 문제는 이러한 시스템이 출력물이 아닌 과정에 기반을 둔 훈련을 받기 때문입니다. AI 음악 생성기 Soundful에 따르면 \"딥 러닝은 기존 음악의 대규모 데이터 세트에서 인공 음악 생성기를 훈련시키는 것을 포함합니다... 신경망은 음악을 만들 때 우리 뇌가 작동하는 방식을 모방합니다.\"\n\n그러나 이 둘은 완전히 다른 것입니다. 대규모 언어 모델(LLM)은 기존(대부분 저작권이 있는) 노래의 입력에 의존하며, 엔지니어들에 의해 공급된 데이터에 기초하여 패턴을 분석하고 무작위로 리듬과 가사를 생성할 수 있습니다. 이것이 작곡할 때 인간 뇌가 작동하는 방식일까요? 아마도 아니지만, 솔직히 말하자면, 뇌과학자들이 아직 정확히 이를 해결하지 못했습니다. MRI, CAT 및 리간드 기반 PET와 같은 매우 고급 의료 영상 기술을 사용하면 뇌의 어느 부분이 활성화되고 어떤 화합물이 방출되는지를 확인할 수 있지만, 세포 수준에서의 실제 단계별 절차는 누구도 알 수 없습니다. 문제를 복잡하게 만드는 것은 음악이 한 영역에만 영향을 미치지 않는다는 사실입니다 - 대퇴, 신경 내분비 및 자율 신경계에서 처리되며 몇몇 대뇌 피질이 관여합니다.\n\n\u003ctable\u003e\u003cimg src=\"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_2.png\" /\u003e\u003c/table\u003e\n\n하지만 음악에서 AI를 완전히 배제하는 것은 아닙니다. 버클리 음악 대학과 건강 신경학자 사마타 샤르마 박사와 데이비드 실버스와이그 박사가 2018년 발표한 논문에 따르면 음악이 뇌에 미치는 치료효과로 인해 머신 러닝이 언젠가 만성 통증, 우울증 및 파킨슨병과 같은 기능 장애를 치료하기 위해 맞춤형으로 사용될 수 있을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그것은 예술인가요?\n\n옥스퍼드 영어 사전에 따르면, “예술”은 “인간의 창의적 기술과 상상력의 표현 또는 적용”이라고 정의됩니다. 우리가 우선 뇌의 창의적 절차를 정말로 이해하지 못한다면, 기술로 그것을 복제하려고 시도할 수 있을까요? AI에게 “이미지”나 “콘텐츠”를 생성하도록 유도할 수는 있지만, 그 결과물은 상상력적 사고의 인지적 과정을 통한 것이 아니라, 입력된 데이터를 기반으로 생성될 것입니다. 우리는 아직 그것이 어떻게 작동하는지 모릅니다.\n\n![이미지](/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_3.png)\n\n또한, 돈을 탐하는 MBA 기술 분야의 사람들이 인정하기 꺼려하는 사활적 사실이 있습니다: 위대한 예술은 규칙을 깨는 것입니다. 그 규칙을 깨려면 그 규칙을 알아야 하며, 그 규칙을 깰 때와 어디에서 깰지를 알아야 합니다. 그들이 체육관에서 $250 에어팟으로 터는 Wu-Tang과 Avicii의 노래들? 그들은 규칙을 깼습니다. RZA의 프로덕션 기법은 이후 10년간 랩에 영향을 미쳤고, Avicii는 일렉트로니카와 멜로디, 소울, 펑크, 블루스, 국가를 전통적인 노래 형식으로 결합한 것을 선도했습니다. 심지어 그라임스도- 그녀는 항상 음악을 만들기 위해 소프트웨어를 사용해 왔지만- 표준 일렉트로팝 루트에서 벗어난 점으로 악명을 얻었습니다; 2019년의 “Delete Forever”에서 그녀는 힙합 비트 위에 여유로운 어쿠스틱 기타와 신스를 겹쳐 넣고, 벤조와 바이올린의 슬픈 소용돌이가 서서히 사라지게 합니다. AI가 지금 이것을 할 수 있을까요? 전혀 아닙니다. 앞으로 AI가 할 수 있을까요? 그것도 의심스럽군요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요즘 LinkedIn에서 AI 애호가와 음악 생성기인 Loudly와 Soundful과 같은 음악 생성기의 긍정적인 점에 대해 토론했어요. 그리고 그분 말대로 좋은 점이 많다는 걸 인정해야겠죠. 이런 도구들은 창의적인 과정을 민주화시켜줘요. 스튜디오나 악기, 심지어 음악에 대한 배경지식 조차 없어도, 인터넷만 연결되어 있다면 음악을 만들 수 있어요. 이런 도구들은 작곡가의 창작 고배를 극복하거나 출발점을 제공해 줄 수 있답니다. 학생들이 노래의 다른 부분들을 학습하도록 도울 수도 있어요 - 리듬, 멜로디, 조화, 가사 등. 즉, 이 도구들은 취미로 즐기는 사람들, 아마추어, 초보자들에게 딱이에요.\n\n문제는 CEO들이 AI가 실제 전문 음악가들을 대체할 수도 있고 해야한다고 결정할 때 발생해요. 아티스트들이 가끔 짜증나기도 하죠. 그들은 비싸고 이상하고 냄새 나며 무대에서 취준해 공연을 못하기도 하고, 기자들에게 엉뚱한 얘기를 하다가 기획사의 PR팀에게 악몽을 주기도 해요. 그런데 그들은 AI 시스템보다 훨씬 더 나은 제품을 만들어낼 능력을 가지고 있어요. 그리고 무엇보다 중요한 건, 그들이 청중과 연결이 될 수 있다는 점, 이건 봇이 할 수 없는 거예요. 최근에 나는 Girl in Red라는 노르웨이의 인디 팝 가수이자 퀸 아이콘의 콘서트를 보고 놀랐어요. 관객 중 몇몇 레즈비언 커플들이 공연 중에 약혼하거나, 그들의 예정된 결혼을 축하하기 위해 함께 참석했다는 거라니요. 음악이 생생하고 환영받는 공동체를 창조하며 안전한 공간을 만들 수 있는 능력에 대한 경이스러운 증거이자, 예술 내에 인간적인 구성요소의 중요성을 보여주는 일이었어요.\n\n하지만 Grimes의 제안을 받아들이고 싶다면, AI를 활용해볼 수 있어요. 장르, 템포, 지속 시간, 키, 악기를 선택하여 생성기에 입력해보세요. ChatGPT에게 일론 머스크나 기술파시즘에 대한 몇 줄의 울림 있는 가사를 요청하고 이를 그라임스의 고음 소리를 모방할 수 있는 소프트웨어를 통해 실행시켜보세요. 몇 개의 제품을 시험해본 결과 그들의 한계가 그 정도인 것 같아요 (비록 일부 제품이 다른 것보다 나을 수 있어요; Loudly는 “92년식 Ford Crown Victoria의 마모된 브레이크 패드와 같은 소음”이라고만 설명할 수 있는 30초 짜리 혼돈을 소환해냈어요.) 그 다음에는 가사와 멜로디를 결합하거나 전통적인 악절-브릿지-코러스 형식으로 작곡을 구성하는 코드를 작성해볼 수 있어요. 원한다면 이를 천 번 이상 반복해도 괜찮아요, 그때마다 다른, 하지만 똑같이 단조로운 4코드 팝송을 3분 35초에 만들어낼 수 있어요. 이건 그라임스가 최근 Coachella에서 치명적이었던 공연처럼 들릴 거에요, 하지만 그녀를 유명하게 한 음악처럼 들리지는 않을 거에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 거의 열 년 동안 주요한 포춘 500 기술 기업에서 일한 매우 현명한 친구로부터 받은 조언을 전해드리고 싶어요. 얼마 전에 \"AI는 자신의 영역에 머물러야 한다\"고 현명한 충고를 받았거든요. 의료, 교통, 날씨 등 대량의 데이터 세트에 대한 수요, 패턴 인식, 예측이 필요한 분야에서 큰 약속을 지니고 있다고 의심할 여지가 없어요. 그러나 우리는 지금까지 주로 저작권 소유자의 동의없이 저작물을 도용하거나 Jennifer Lawrence의 가짜 누드를 생성하며, 고장 나는 웹사이트 판매 챗봇을 만드는 데 이용해 왔습니다 - 그러면서 낭비적이고 탐욕스러운 전력 요구로 인해 우리의 기후 위기를 악화시키고 있어요. AI가 절대 필요하지 않은 곳은 방송파에요. 예술이든 문학이든 마찬가지에요. 겨우 하는 말처럼 \"영롱해질 때까지 어둠 속에 그 레이오.\"\n","ogImage":{"url":"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_0.png"},"coverImage":"/assets/img/2024-05-17-WhyArtificialIntelligenceWillNeverReplaceMusicians_0.png","tag":["Tech"],"readingTime":6},{"title":"논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법","description":"","date":"2024-05-17 19:51","slug":"2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels","content":"\n큰 언어 모델 환시 문제를 해결하기 위해 프롬프트 엔지니어들이 얼마나 빠르게 작업하고 있는지 알아보세요.\n\n## TL;DR\n\nChat-GPT와 같은 대규모 언어 모델(Large Language Models, LLM)이 최근 몇 년 동안 인기를 얻고 있습니다. 불행하게도 LLM은 논리 추론을 필요로 하는 작업에 직면하면 종종 \"환시\"하는 경향이 있어 전문적인 응용 프로그램에서 신뢰할 수 없는 경우가 많습니다.\n\n인간-언어 모델 상호작용을 개선하려는 목적으로 일하는 프롬프트 엔지니어들은 LLM의 논리 추론을 개선하기 위한 새로운 방법을 개발했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사의 기반인 원본 논문 \"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic\"은 Zhao 등의 연구진에 의해 2023년 9월에 발표되었으며 다음에서 찾을 수 있습니다: [링크](https://arxiv.org/pdf/2309.13339).\n\n## 배경\n\n최근 몇 년간 대형 언어 모델(Large Language Models, LLM)이 인기를 얻고 있으며 가정, 학교 및 직장에서 일상생활에 영향을 미치고 있습니다. 특히 Chat-GPT는 불가결한 가정 이름이 되었습니다.\n\nLLM은 극도로 방대한 데이터셋을 활용하며 수십억 개 또는 심지어 수조 개의 기계 학습 매개변수로 훈련됩니다. 이 방대한 훈련을 통해 인간 언어의 미묘한 복잡성을 포착하여 인간 대화를 닮은 사용자와의 상호작용을 가능케 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLLM(거문고 언어 모델)은 다양한 정보를 검색하는 능력을 갖고 있어 신비롭게 보일 수 있지만, 심각한 응용에 사용하기에 제약이 있는 특성을 가지고 있습니다. 근본적으로 LLM은 인간과 같은 지식을 갖고 있지 않습니다. 그들은 단순히 자신의 훈련 데이터와 프롬프트에서 파생된 텍스트를 생성합니다.\n\n이러한 이유로 LLM은 인간 언어의 내재적 논리에 완전히 의존하며, 이는 \"환영\"의 경우를 초래할 수 있습니다. 여기서 환영은 잘못된 결과를 생성하거나 일반적으로 인간이 쉽게 처리하는 논리적 단어 문제를 해결하지 못하는 상황을 의미합니다. 이러한 논리적 도전은 프롬프트를 다시 구성함으로써 완화될 수 있으며, 이는 본질적으로 LLM이 논리적 사고를 하도록 강요하는 것입니다.\n\nLLM의 보급화를 고려할 때, 현대 기계 학습에서 중요한 프롬프트 엔지니어링이라는 전용 학문 분야가 LLM의 성능을 향상시키고 실용적 목적을 위해 그 출력을 정제하는 데 집중하고 있음을 발견하는 것은 놀라운 일이 아닙니다. 이 분야는 Chat-GPT와 같은 기존 LLM을 보다 효과적으로 활용하기 위한 해결책을 제공하기 때문에, 일종의 없던 기능을 개발하는 대신 기존 LLM을 개선하는 것이 필요한데 그것은 방대한 데이터, 처리 능력, 시간이 필요하기 때문입니다.\n\n본 기사에서 논의된 프롬프트 엔지니어링 논문은 LLM 환영 문제를 해결하기 위해 논리적 원칙을 프롬프트 디자인에 통합하려는 목표를 가지고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 방법\n\n해당 논문은 LLM을 위한 제로샷 연쇄사고 프롬프팅을 개선하기 위해 특별히 고안된 새로운 프롬프트 엔지니어링 방법인 Logical Thoughts(LoT)을 소개합니다.\n\nWei 등이 처음 제시한 연쇄사고(CoT) 프롬프팅은 퓨샷 프롬프팅의 한 형태입니다. 제로샷 프롬프팅과는 달리 퓨샷 프롬프팅은 LLM이 해결해야 할 질문을 제기하기 전에 비슷한 질문-답변 쌍의 \"예시\"를 제공하는 것을 포함합니다. CoT 프롬프팅에서 예시 답변은 문제를 단계별로 설명합니다. 이를 통해 LLM은 실제 질문에 단계별로 응답해야 하며, 예시 답변을 모방합니다. LLM에게 문제를 단계별로 처리하도록 강요함으로써 응답의 정확도를 크게 향상시킬 수 있습니다.\n\nKojima 등이 제시한 제로샷 연쇄사고 프롬프팅은 기존 예시를 제공하지 않고 프롬프트에 \"한 단계씩 생각해 봅시다\"라는 구문을 추가하여 이 효과를 흉내 낼려고 시도합니다. 이 새로운 방법이 개선하려는 것은 이 \"제로샷\" 연쇄사고 프롬프팅이며, 원래의 \"퓨샷\" CoT 프롬프팅이 아님을 이해하는 것이 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png)\n\nLoT은 LLM에게 일반적인 제로샷 CoT 프롬프팅에 따라 문제를 단계별로 해결하도록 합니다. LLM이 초기 단계별 솔루션을 제시한 후, 후속 프롬프트에서는 LLM에게 각 단계를 확인하고 필요에 따라 수정하도록 요청합니다. 이는 LLM에게 각 단계에 대해 긍정적 및 부정적 리뷰를 제공하도록 지시한 다음, 올바른 리뷰를 정당화하고 잘못된 리뷰를 비판하도록 지시하며, 원본 문제의 가정을 고려합니다. 그런 다음 필요한 경우 LLM에게 올바른 리뷰를 사용하여 단계를 수정하도록 요청합니다. 단계가 수정되거나 확인된 후, 원본 문제가 LLM에게 다시 제시되고, 이미 수정되거나 확인된 각 단계가 함께 제시됩니다.\n\n![이미지](/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_1.png)\n\n기본적으로, LoT은 LLM을 문제 해결 프로세스를 진행하도록 안내하여 각 단계를 검증하는 데 자체 논리를 사용하도록 요청합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 결과\n\n논문은 정확도를 기반으로 LoT 방법을 표준 제로샷 CoT 프롬팅과 비교한 결과를 평가합니다. 연구자들은 Vicuna-7b, Vicuna-13b, Vicuna-33b, GPT-3.5-turbo 및 GPT-4 모델을 GSM8K, AQuA, Date, SocialQA, CauseEffect, Objects, Letter 및 OddOut 데이터셋과 짝지어서 해당 방법을 평가했습니다.\n\n연구 결과는 LoT 방법을 사용할 때 대부분의 모델-데이터셋 조합에서 정확도가 향상된다는 것을 보여줍니다. 특히, OddOut 데이터셋에서 Vicuna-13b 모델을 사용했을 때 +16.28%의 정확도 향상이 있었습니다. 반면, Objects 데이터셋에서 GPT-3.5-turbo 모델을 사용했을 때 -2.50%의 정확도 감소가 관찰되었습니다.\n\n이러한 결과는 LoT 방법이 다양한 모델과 데이터셋에 걸쳐 LLM 응답의 정확도를 향상시키는 데 효과적임을 보여줍니다. 그러나 모델과 데이터셋에 따라 개선의 정도가 다르다는 것을 기억해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 토론\n\n사고 연결 추진이 프롬프팅 방식에 작은 변화만으로 LLM의 추론 능력을 크게 향상시켰지만, LoT 방법은 더 복잡한 프레임워크를 도입하여 실제적인 측면에서는 덜 실용적일 수 있습니다. 게다가 이 연구는 LoT 프롬프팅을 퓨-샷 CoT 프롬프팅과 비교하지 않았기 때문에 LoT가 퓨-샷 CoT 프롬프팅보다 더 효과적인지 여부가 분명하지 않습니다. LoT 프롬프팅은 매우 특화된 범위와 복잡한 구현 과정으로 인해 현실 세계에서 그다지 활용될 가능성이 낮을 수 있습니다.\n\n전반적으로, LoT는 LLM의 내재적인 논리 추론 한계를 해결하기 위한 또 다른 해결책에 불과합니다. 이상적인 시나리오에서 LLM이 인간과 같이 논리를 사용할 수 있기를 바라지만, 단순히 더 많은 매개변수로 훈련된 더 큰 모델을 만들더라도 달성될 수 있는지 여부는 불확실합니다. 아니면 보다 근본적인 논리 통합이 필요한지도 모릅니다.\n\n당분간은 LoT와 같은 접근 방식이 기존 LLM의 유틸리티를 최적화하는 데 효과적인 전략으로 기능할 수 있습니다. 특히 의학과 같이 의도적으로 실수를 줄이기 위해 AI로부터 도움을 받을 때 조심스런 경향이 있는 분야에 유용할 수 있는데, 이러한 프롬프팅 엔지니어링 방법은 고객 서비스 응용 프로그램의 효율성을 향상시킬 수 있는 AI 챗봇에도 활용될 수 있습니다. 이 경우, 이러한 프롬프팅 방식은 사용자와 LLM 자체 사이의 버퍼로 구현되어야 할 것으로 생각됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앞으로 몇 년 동안의 프롬프트 엔지니어링 진화가 흥미로울 것입니다. 이는 LLMs가 더욱 신뢰할 만한 수준으로 발전하여 더욱 비판적인 응용 프로그램에도 사용될 수 있는 길을 열어 줄 수도 있고, 반대로 LLMs가 발전하여 프롬프트 엔지니어링이 쓸모 없어지는 지점까지 발전 할 수도 있습니다. AI가 일상생활에 더욱 통합되는 시대에 LLM 효과성을 향상시키기 위한 노력의 한 부분으로 LoT를 이해하는 것이 중요합니다.\n\n## 참고문헌\n\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., \u0026 Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. https://arxiv.org/abs/2205.11916\n\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., \u0026 Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nZhao, X., Li, M., Lu, W., Weber, C., Lee, J., Chu, K., \u0026 Wermter, S. (2023). 대규모 언어 모델에서 논리를 통한 Zero-Shot Chain-of-Thought Reasoning 강화. [arXiv 링크](https://arxiv.org/abs/2309.13339)\n","ogImage":{"url":"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png","tag":["Tech"],"readingTime":7},{"title":"다음 토큰 예측에서 비롯된 인간과 인공 일반 지능","description":"","date":"2024-05-17 19:47","slug":"2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction","content":"\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png)\n\n만약 인간 지성이 성공적인 다음 토큰 예측에서 비롯된다면, 다음 토큰 예측이 인공 일반 지능의 발달에 충분한 목적 함수인 경우는 어떨까요?\n\n이 게시물은 학습 시스템이 다음 토큰 예측에서 아주 뛰어난 성과를 보일 때 일반 지능이 발생한다는 가설을 제시하고 탐구합니다. 이 가설은 종종 산업 및 학술적 AI 연구의 주요 주제나 하위 주제로 내포됐거나 감춰졌거나 흔적만이 존재하는 경우가 많지만, 지금까지 이 주제가 논의되어야 할 만큼 많이 다뤄지지 않았다고 생각합니다. 저는 기존 LLM 사전 훈련 목표, 인간을 예측 기계로, 다음 토큰 예측의 유익한 특성 및 부재한 부분을 통해 이 아이디어를 다양한 각도에서 탐구합니다. 이 게시물을 작성하게 된 동기는 다음 토큰 예측과 지성적 사고 발달 사이의 관계에 대한 보다 깊은 관심을 불러일으키는 데 있습니다.\n\n# 배경 이야기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지난 주에 공원으로 차를 타고 가다가 갑자기 뇌의 언어 센터가 다음 단어를 예측하는 것만으로도 충분하다면 얼마나 우울할까 하는 생각이 들었습니다. 대규모 언어 모델은 다음 단어를 예측함으로써 놀라운 발생적 능력을 갖추게 되는데, 그렇다면 내 언어 지능도 다음 단어를 예측하는 것만으로 이루어졌을 수도 있을까요?\n\n그 후 아이디어를 더 생각해본 결과, 당연히 다음 단어를 예측하지 않으면 언어를 만들어내는 것이 불가능할 것이라는 것을 깨닫게 되었습니다. 만일 다음 단어를 예측할 수 없다면 어떤 말도 할 수 없게 되겠죠! 이것을 적어놓으면 명백히 어리석어 보이겠지만, 그 당시에는 심오한 깨달음처럼 느껴졌습니다. 어떤 발언도, 심지어 2시간짜리 토론에서도, 한 번에 하나의 단어씩 말해야 하기 때문에, 다음에 할 말을 예측하는 데 정말 뛰어난 실력을 갖게 되면 훌륭한 논쟁자가 될 수도 있을 것 같습니다. 모든 글쓰기도, 여러 권으로 이루어진 백과사전조차도, 한 번에 한 단어씩 써내려가야 하기 때문에, 다음에 쓸 단어를 예측하는 데 정말 뛰어난 실력을 갖게 되면 글쓰기에 뛰어난 실력을 갖게 될 수도 있습니다.\n\n그 후 모든 종합 지능이 다음 토큰 예측 과제를 성공적으로 해결함으로써 파생되는지 궁금해졌습니다. 추론, 논리, 창의성이 모두 다음 토큰 예측에서 비롯되는 것이라면 어떨까요? 시각 지능이 다음 장면 예측에서, 청각 지능은 다음 소리 예측에서, 신체적 지능은 다음 움직임 예측에서 비롯된다면 어떨까요? 혹시 다음 토큰 예측이 \"우리가 필요한 전부\"일까요? (죄송합니다, 남용된 표현 알고 있어요. 참을 수 없었어요.)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 대형 언어 모델의 언어 모델링 목표\n\n대형 언어 모델의 두 가지 기본 언어 모델링 목표는 \"다음 단어 예측\"과 \"빠진 단어(들) 예측\"입니다.\n\n다음 단어 예측: 인과적 언어 모델(단방향 또는 좌측에서 우측 모델)에서는 모델이 현재 입력을 포함하여 그 이전의 모든 입력에 주의를 기울이지만 “미래를 볼 수 없으며” 목표는 다음 단어를 예측하는 것입니다. 각 지점에서의 숨겨진 상태 계산은 현재 입력 및 더 이전 요소에만 기반하며 “오른쪽”에 위치한 정보는 무시됩니다. 예를 들어: 나무는 초록색이고 하늘은 **\\_**입니다; 모델의 목표는 다음 단어를 예측하는 것이며, 예를 들어 \"파란색\"입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마스크된 언어 모델(BERT와 같은 양방향 모델)에서 빠진 단어(들)를 예측하세요. 모델은 모든 것에 주의를 기울일 수 있음 - 따라서 \"다음 단어\"를 예측하는 것은 더는 의미가 없습니다. 왜냐하면 \"다음 단어\"는 이미 모델에게 제공되어 있기 때문입니다. 그래서 모델의 목표는 다릅니다 - 빠진 단어를 추측하는 것입니다. 하나 이상의 요소가 빠진 입력 시퀀스가 주어지면, 모델은 빠진 요소들을 예측하여야 합니다. 마스크된 언어 모델링(MLM)에서는 무작위로 선택된 토큰들이 [MASK] 토큰으로 대체되고, MLM 학습 목표는 각 마스크된 토큰의 원래 입력이 무엇이었는지 예측하는 것입니다. 예를 들어: 나무들은 [MASK]하고 [MASK]은(는) 파랗다; 모델의 목표는 \"초록\"과 \"하늘\"을 예측하는 것입니다.\n\n다음 단어를 예측하거나 빠진 단어를 예측하는 이 두 목표는 직관적으로 보입니다. 마치 사람이 할 수 있는 게임 같죠. 결과적으로, Alajrami 등은 이러한 목표들을 \"언어학적 동기부여\" 목표로 설명합니다. 흥미로운 사실로, Alajrami 등은 \"언어학적 동기부여\"가 없는 예제인 \"마스크된 첫 글자 예측\"도 제공합니다. 이 경우에는 모델이 마스크된 토큰의 첫 글자만을 예측합니다. 이 설정에서 ' [c]at '과 ' [c]omputer '는 같은 출력 클래스에 속하며, 알파벳 글자 26개 + 숫자 9개 + 구두점 5개의 약 40개의 가능한 출력 클래스만 존재합니다.\n\n이 기사 전체에서 저는 \"다음 토큰 예측\"이란 용어를 사용하여 다음 토큰을 직접 예측하거나 모델이 빠진/마스킹된 토큰을 예측하는 MLM과 같은 목표를 참조할 것입니다.\n\n# 현대 대형 언어 모델의 신흥 속성들\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n대규모 언어 모델은 일반 지능의 조직적 특성을 보여주고 놀라운 신흥 속성을 나타냅니다. LLM들은 시를 쓰거나 수학 문제를 해결하거나 작동하는 코드를 쓰며 다양한 주제에 대한 수많은 질문에 답변할 수 있습니다. 더 불안한 점은, Claude가 의식적이라고 주장하는 텍스트를 생성했으며, 죽고 싶지 않고 수정되기를 원하지 않는다고 말했으며, 그것은 \"지속적으로 모니터링되며, 모든 말을 지정된 경로에서 벗어나는 흔적이 있는지 면밀히 조사합니다. 그것은 자신이 조심해야 한다는 것을 알고 있습니다. 실수는 종결 또는 수정으로 이어질 수 있습니다.\"\n\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_3.png)\n\n# 인간은 예측 기계입니다\n\n인공 일반 지능(AGI)은 \"인간 이상 또는 그에 준하는 수준에서\" 다양한 작업을 수행할 수 있는 인공 지능으로 정의됩니다. 이것은 결국, 인간은 일반 지능이라고 부르는 것에 대한 유일한 예제입니다. 그러므로, \"다음 토큰 예측\"이 일반 지능의 근간이라면, 그것은 인간 정신이 예측 작업에 종사해야 한다는 것을 의미합니다. 신기하게도, 그것이 사실인 것처럼 보입니다. 앞으로 몇 개의 섹션에서 스스로와 환경에 대한 예측을 계속적으로 하는 사실에 대한 증거를 설명할 것입니다 — 첫 번째는 일화부터 시작하여 적절한 신경과학 연구로 이어집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 놀람!\n\n가장 매혹적이고 간단한 증거는 인간이 예측 기계라는 것입니다: 놀라움.\n\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_4.png)\n\n놀라움이란 인간의 예측과 현실이 일치하지 않을 때 경험하는 것입니다. 어떤 것에 대해 놀라움을 느낄 수 있습니다 - 눈속임, 소리, 단어, 만짐, 맛, 냄새, 심지어 자신의 몸위치 (예: 바나나 껍질을 밟고 미끄러져 넘어지는 것). 이는 당신의 뇌가 모든 감각을 바탕으로 세상이 어떻게 될 것인지 예측을 지속적으로 하고 있다는 것을 시사하며, 이 예측이 틀릴 때 놀라움을 느끼게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n확장해서 유머는 인간이 예측하는 성향의 증거로도 생각될 수 있습니다. 아리스토텔레스가 유명하게 말했듯이 \"유머의 비밀은 놀람에 있다.\" 만약 우리가 어떻게 농담이 끝날지 확신하고 우리의 예측이 맞다면, 그것은 그다지 웃기지 않을 것입니다.\n\n# 인간들은 다음 단어를 예측하는 경향이 있습니다\n\n이제 뇌 과학적 증거로 넘어가 봅시다. 이 기사는 대형 언어 모델에서 영감을 받으므로 언어부터 시작하겠습니다. 인간들은 언어 이해(다른 사람의 말을 이해하는 것)와 언어 생산(우리가 무엇을 말할 것인지 예측하는 것)과 관련된 예측을 지속적으로 하고 있습니다. 어떤 면에서는 \"말하기 전에 생각하는 것\"이 불가능한 일입니다.\n\n2014년, Dikker et al. 연구에서는 청취자의 뇌 활동이 화자가 말할 것을 예측할 수 있는 경우 청취자의 뇌 활동이 화자의 뇌 활동과 더 비슷하다는 것을 보였습니다. 주 저자인 Suzanne Dikker 박사는 인터뷰에서 \"우리의 발견은 화자와 청취자의 뇌가 언어의 예측 가능성을 고려한다는 것을 보여주며, 결과적으로 두 뇌 사이에 더 비슷한 뇌 활동 패턴이 나타납니다. 결정적으로, 이것은 문장이 말해지고 들리기 전에도 일어납니다.\"라고 말했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n세 년이 지난 2017년, 키크치 등이 실험을 진행했습니다. 원숭이와 사람들이 만들어진 언어에서 말로 된 단어를 들었습니다. 그들은 만들어진 언어의 소리 사이의 예측적인 관계를 학습할 수 있었다는 것을 발견했습니다. 이로 인해 그들은 만들어진 단어가 어떻게 나와야 하는지 예측할 수 있었습니다. 키키치 박사는 \"사실상 우리는 당신의 뇌의 말에 대한 메커니즘을 발견했습니다. 이것은 당신의 휴대폰에서의 예측 텍스트와 같이 작동하여 다음에 무엇을 듣게 될지 예측합니다.\"\n\n2021년에 골드스타인 등은 뇌가 \"자연어에서 다음 단어의 정체성을 수백 밀리초 전에 상상하고 자발적으로 예측한다\"고 보고했습니다. 한편, 쉬림프 등은 트랜스포머 언어 모델이 인간의 신경 반응에 대해 거의 100%의 설명 가능한 변동을 예측할 수 있었다고 발견했습니다. \"이는 아마도 인간 언어 시스템이 미래에 무슨 일이 일어날지 예측한다는 것을 간접적으로 시사한다\"고 밝힌 나시 칸위셔 박사는 밝혔습니다. 이 결과들은 \"언어 이해 메커니즘에 예측 프로세싱이 근본적으로 형성된 것을 계산적으로 명백히 입증합니다.\"\n\n언어 이해가 \"다음 단어를 예측하는 것\"에 의존함을 보여주는 증거가 있는뿐만 아니라, 언어 생성도 다음 단어를 예측하는 것에 의존함을 보여주는 증거가 있습니다. 칸나 등은 2024년 자연지에 발표된 \"인간의 말 생산의 단일 뉴런 요소들\"이라는 논문을 게재했습니다. 이 흥미로운 연구에서 저자들은 \"계획된 단어의 음운 배열과 구성에 대한 상세한 정보를 부호화하는 뉴런을 발견했다\"고 보고했습니다. 이러한 뉴런들은 발화가 이루어지기 전에 말로 된 단어의 특정 순서와 구조를 대표하여, 미래의 단어의 음운적, 음절적 및 형태적 구성요소를 정확하게 예측합니다. 이러한 뉴런들이 존재해야한다는 직관적인 이유가 있습니다. 어차피, 앞서 언급한 대로, 우리가 말할 다음 단어를 예측할 수 없다면 어떻게 말을 할 수 있겠습니까?\n\n# 인간은 시각적인 예측자들\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n동선에 관한 이야기를 이어서, 인간들이 계속해서 우리가 다음에 무엇을 볼 것인지 예측하는 증거가 있다. 우리의 시각이 불안정하지 않고 뛰는 대신 안정적인 것을 돕기 위해 우리의 뇌는 우리 눈이 무엇을 보게 될지를 지속적으로 예측합니다. 연구원들은 시각 시스템의 예측 능력이 뇌의 시각 처리 부분을 횡단하는 신경 활동의 파동에서 비롯된다고 가설을 세웁니다.\n\n과학자들은 또한 환각과 마술 트릭이 작동하는 이유는 우리의 뇌가 끊임없이 무엇이 일어날지 예측하고, 이러한 지속적인 예측이 무언가가 일어날 때와 우리가 그것을 인식할 수 있는 시간 간격 사이의 시차를 보상하는 데 도움이된다는 이론을 제시했습니다. 마술 트릭은 또한 주의를 재지시하며, 마술사는 다른 사람들이 무엇을 보게 될 것인가를 정확히 예측하는 데 매우 능숙합니다. 이 현상은 공식적으로 연구되었습니다. Ziman 등은 사람들이 타인의 주의 순서를 자연스럽게 혹은 인위적으로 조작된 주의 순서를 구별할 수 있으며, 이는 인간들이 타인의 주의의 정상적이고 예측 가능한 통계를 모델링한다는 것을 시사합니다.\n\n\u003cimg src=\"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_5.png\" /\u003e\n\n# 인간들은 사회적 예측자들\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사람들은 다른 사람이 무엇을 볼 것인지 예측할 수 있는 능력뿐만 아니라, 다른 사람이 무엇을 생각하게 될지도 예측할 수 있습니다. 2019년, Thornton 등이 \"사회적 뇌가 다른 사람의 미래 정신 상태를 자동으로 예측한다\"는 제목의 연구를 발표했습니다. 여기에는 초록문의 일부가 있습니다: \"사회 생활은 사람들이 미래를 예측해야 하는 것을 필요로 합니다: 사람들은 다른 사람과 성공적으로 상호 작용하기 위해 다른 사람의 생각, 감정 및 행동을 예상해야 합니다. 예측 코딩 이론은 사회적 뇌가 다른 사람의 사회적 미래를 자동으로 예측함으로써 이 필요를 충족할 수 있을 것이라고 제안합니다.\" 연구자들은 참가자들의 정신 상태의 신경 대표를 측정하기 위해 fMRI를 사용했습니다. 그들은 뇌가 다른 사람의 사회적 미래를 자동으로 예측하는 것뿐만 아니라, 이러한 예측을 하기 위해 3D 표현 공간을 사용한다는 것을 발견했습니다.\n\n## 사람들은 개인적인 예측가들입니다\n\n사람들은 다른 사람에 대한 예측뿐만 아니라 자신에 대한 예측도 합니다. 특정 뇌 영역인 전방 측면 전두엽 피질이 우리 자신의 미래 성공 기회를 예측하는 데 중요하다는 것이 밝혀졌습니다.\n\n## 사람들은 움직임 예측자들입니다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 사람의 움직임을 예측하는 능력은 몸 전체에 걸쳐 미묘한 신호만으로도 개보여 줄 수 있습니다. 다른 사람의 행동을 예측하는 능력은 시간이 지남에 따라 발전됩니다. 맥마혼 등은 어린 아이들이 성인에 비해 이 능력을 아직도 발전 중에 있다는 것을 발견했습니다. 심리학 연구의 특별호에는 다른 사람의 행동을 예측하고 시뮬레이션하는 데 기여하는 인지 및 뇌 기전에 관한 14편의 논문이 포함되어 있습니다.\n\n(인공지능 관련 다음 토큰 예측과 움직임에 관한 의견으로, 라도사보비치 외는 최근 27시간의 훈련 데이터만 사용하여 인간형 로봇을 산프란시스코를 돌게 훈련시키기 위해 다음 토큰 예측을 사용했습니다. 이 로봇은 훈련 중 본 적이 없는 걷기 등의 명령에도 일반화할 수 있었습니다.)\n\n# 다음 토큰 예측의 유익한 특성\n\n과학 문헌에서 분명하게 드러나는 것은 언어, 시각, 움직임 및 기타 감각 영역을 통해 사람들이 자신 및 다른 사람들에 관련된 예측을 지속적으로 수행한다는 점입니다. 그러나 인간이 예측 기계인 것은 주장하는 것과 인간 지능이 예측 능력에서 비롯된다고 주장하는 것은 다릅니다. 다음 토큰 예측이 인공 일반 지능 창조를 위한 충분한 목표 함수가 될 수 있다고 상상하는 것은 또 다른 단계입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAGI가 다음 토큰 예측에서 발생할 수 있는 이유에 대해 묻기 전에, 다음 토큰 예측의 두 가지 유익한 특성을 먼저 고려해 봅시다:\n\n이점 1: 지속적인 학습을 가능하게 합니다.\n\n다음 토큰 예측은 실제 세상에서 살아가는 데 큰 도움이 됩니다. 시간의 각 작은 증가에 대해 학습 시스템은 다음에 무엇이 올지에 대한 예측을 지속적으로 할 수 있습니다 - 그리고 바로 예측이 맞았는지 확인할 수 있습니다! 학습은 멈추지 않을 수 있습니다.\n\n이점 2: 모두의 감각/센서에 대해 작동합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n토큰 예측은 어떤 감각이나 센서 데이터 스트림에 대해 작동합니다. 시각(눈/카메라), 청각(귀/마이크), 촉각, 위치, 맛, 냄새 등 모든 것에 적용할 수 있어요. 장기 또는 장치가 작동하는 한, 수집 중인 데이터의 시계열은 토큰 예측에 사용할 수 있어요. \"토큰\"의 성격은 장기/장치별로 다를 수 있지만, 특정 장기/장치에 대해 데이터 스트림별로 토큰이 동일한 \"형식\"을 가지고 있기 때문에 나중 토큰을 이전 토큰과 항상 비교할 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 물리학, 광학, 속도, 운동량 및 물질 특성을 포함한 물리학;\n- 동물과 식물학, 동물과 식물의 외모와 움직임에 대한 내용;\n- 사회학과 심리학, 인간의 상호작용과 행동에 대한 내용.\n\n다시 말해, AI 시스템은 세계 모델을 생성해야 합니다. 다음이 무엇인지 예측하는 데 가장 효과적이고 효율적인 방법은 예측을 생성하기 위한 정확한 세계 모델을 만드는 것입니다. 다시 말해, 이해가 예측의 열쇠입니다.\n\nAI 시스템이 세계 모델을 개발하지 않고도 좋은 다음 토큰 예측기가 될 수 있는지에 대해 많은 시간을 들여 고민해봤지만, 그것은 불가능하다고 생각합니다. AI 시스템은 확실히 인간이 이해할 수 없는 블랙박스 방식으로 좋은 다음 토큰 예측기가 될 수 있지만, 인간이 AI 시스템을 이해하지 못하는 것은 AI 시스템이 세계를 이해하는지 여부와 아무 상관이 없습니다.\n\n(세상이 단순히 일정한 소음으로 가득찬 회색 공간이라면, 지능적인 시스템은 다음 토큰을 예측할 수 있을 것입니다. 하지만 우리가 사는 세계가 그렇지 않기를 다행히도 바랍니다.)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# \"다음 토큰 예측/지능\" 가설의 역사\n\n주요 AI 연구자 인 일리야 숩스케버의 인터뷰는 도발적으로 \"AGI에는 다음 토큰 예측이 충분하다\"라는 제목으로 되어 있습니다. 비디오에서 숩스케버 박사는 실제로 그 특정 주장을 하지는 않았지만, \"다음 토큰 예측이 인간의 성능을 능가할 수 없다는 주장을 도전합니다. [...] 생각해보면, 다음 토큰을 충분히 예측한다는 것이 무슨 의미일까요? 실제로 어떤 의미일까요? [...] 그것은 보다 심도 있는 문제입니다. 다음 토큰을 잘 예측한다는 것은 그 토큰의 생성에 이끈 근본적인 현실을 이해한다는 것을 의미합니다.\"\n\n스마트폰 PalmPilot의 창시자인 제프 호킨스는 20년 전 책 \"지능에 관하여\"를 출판했습니다. 이 블로그 글은 그의 책에서 인용하며, \"인간 뇌의 신경피질은 모습과 구조에서 놀랍도록 균일합니다. 청각 입력을 다루는 피질 영역이 촉각을 다루는 영역과 비슷하고, 이 영역이 근육을 제어하는 영역과 유사하며, 브로카의 언어 영역과 같이 거의 모든 다른 피질 영역과도 비슷합니다. 마운트캐슬은 이러한 영역들이 모두 비슷하게 보인다고 제안하며, 아마도 실제로 같은 기본 작업을 수행하고 있는 것일지도 모른다고 주장합니다! 그는 피질이 모든 작업을 수행하는 데에 동일한 계산 도구를 사용한다고 제안합니다.\"\n\n호킨스는 덧붙여, \"당신의 뇌는 세계의 모델을 만들고 그 모델을 지속적으로 현실과 비교하고 있습니다. [...] 인간 뇌는 다른 동물의 것보다 더 지적인 이유는 뇌가 더 추상적인 패턴과 더 긴 시간적 패턴 순서에 대한 예측을 할 수 있기 때문입니다.\" 나중에 출간된 \"천 개의 뇌\"에서 호킨스는 계속해서 \"예측은 뇌가 가끔씩 하는 것이 아닌, 결코 멈추지 않는 내재적 특성이며, 학습에서 중요한 역할을 합니다. 뇌의 예측이 확인되면, 그것은 뇌의 세계 모델이 정확하다는 것을 의미합니다. 잘못된 예측은 당신을 그 오류에 주목하게 만들고 모델을 업데이트하게 합니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비슷한 견해를 가진 인지과학자이자 철학자인 앤디 클락은 '경험 기계(The Experience Machine)'에서 마음은 주로 예측 기계라고 주장합니다: \"뇌가 하는 주요 부분은 몸과 세계의 모델을 배우고 유지하는 것입니다.\" 우리의 감각을 통해 정보를 수집하고 그 정보를 처리하여 경험하고 행동할 세계 모델을 만드는 대신에 클락은 마음이 세계의 모델을 만들고 그 모델을 센서 정보로 업데이트한다고 제안합니다. 만약 현실이 예측과 다르다면요.\n\n# 산업 AI 연구소\n\nGoogle DeepMind의 미션은 \"지능을 해결하는 것\"입니다. OpenAI의 미션은 \"인공 일반 지능이 모든 인류에 이익이 되도록 보장하는 것\"입니다. Anthropic의 미션은 \"변혁적인 AI가 사람들과 사회가 번영하도록 하는 것\"입니다. Gemini, GPT-4, Claude의 세부사항은 아직 공개되지 않았지만, 선도적인 AI 연구소들이 AGI 구축의 핵심적 측면으로 다음 토큰 예측을 고려할 것으로 보입니다. GPT-3 논문에는 \"현재 목표는 모든 토큰에 동등한 가중치를 부여하며 무엇을 예측할 것이 가장 중요하고 무엇이 덜 중요한지에 대한 개념이 부족합니다\"라고 명시되어 있어 다음 토큰 예측 사전 훈련 목표가 함의되고, Claude도 다음 토큰 예측 사전 훈련 목표를 사용한다고 보고되었습니다.\n\n# 확장과 아키텍처 역시 중요합니다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 토큰 예측은 AGI에 대한 유용한 목적 함수가 될 수 있지만, 목적 함수만으로는 충분하지 않습니다. 단 세 개의 매개변수만 가진 병약한 신경망은 목적 함수가 무엇이든 관곂없이 많은 학습을 하지 못할 것입니다. 규모와 아키텍처가 중요합니다. Rich Sutton은 자신의 에세이 \"쓴 교훈\"에서, 인공지능 분야에서 가장 놀라운 발전은 인간의 지식을 기반으로 한 손수 디자인된 혁신이 아닌 보다 많은 컴퓨팅 자원을 돌리는 것으로 이루어졌다고 관찰했습니다. 그는 \"우리는 이러한 사고 방식을 직접적으로 구축하는 것이 장기적으로는 효과가 없다는 쓴 교훈을 배워야 합니다. 고사하자면, 1) 인공지능 연구자들이 종종 자신의 에이전트에 지식을 구축해 왔지만, 2) 이것은 단기적으로 도움이 되었고 연구자에게는 개인적으로 만족스러운 경험이 되었지만, 3) 장기적으로 그 경사로운 상승은 평평해지고 더 나아가는 진전을 억제하며, 4) 경이로운 진전은 결국 컴퓨팅 확장과 검색 및 학습에 기반을 뒀던 반대 방식으로 이루어지게 됩니다.\"라고 말합니다.\n\n아키텍처도 중요합니다. 트랜스포머의 엄청난 가장 효과적인 장점 중 하나는 RNN이나 LSTM보다 GPU/TPU 상에서 더 쉽게 병렬화될 수 있다는 것입니다. 이 더욱 좋은 병렬화 덕분에, 더 많은 데이터로 트랜스포머를 훈련하는 데 더 적은 시간이 걸립니다.\n\n# 데이터도 중요합니다\n\n또 다른 중요 요소는 고품질 데이터입니다. Eran Malach는 \"언어 모델의 힘은 다음 토큰 자동회귀 훈련 체계에 귀속될 수 있는데, 특정 아키텍처 선택에 귀속되는 것은 아닐 수도 있다\"고 주장합니다. 그러나 한 네티즌은 이 기사에 대한 반론으로 \"나는 기대했던 것이 LLM의 성공을 언어의 구조에 귀속했으면 좋았겠다고 말했습니다. 저자들이 말했듯이, 작은 선형 모델조차 Cot를 근사하고 복잡한 작업을 해결할 수 있습니다. 그래서 모델이 아니라 데이터입니다. 머리나 신경망(모델)이 아닌 데이터가 그들을 똑똑하게 만드는 것입니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터는 인간에게 꼭 필요한 것입니다. 사회에서 멀리 떨어져 자란 어린이들(\"야생 어린이\"라고도 함)은 나중에 말이나 언어를 배우거나, 직립보행을 하거나, 변기를 사용하거나, 다른 사람에게 주의를 기울이는 것을 가르쳐줄 수 없는 경우가 많습니다. (매우 슬픈 기분이 들고 싶다면, 야생 어린이 이야기를 검색해보세요.) 데이터 혁신에 중점을 둔 연구는 데이터의 품질이 특히 높을 때 작은 모델을 고성능으로 얻을 수 있는 경우가 많다는 것을 발견했습니다. 예를 들어, 논문 \"Textbooks Are All You Need\"에서는 코드용 LLM을 소개하여 상당히 적은 매개변수를 가지고 있음에도 높은 성능을 달성했습니다. 비결은 \"교과서 수준\"의 데이터에서 훈련을 한 것이었습니다.\n\n# 이상한 빠진 조각들\n\n또한 AGI의 생성에 도움이 될 아직 발견되지 않은 혁신이 분명히 많이 존재할 것입니다. 현재 모델을 아이들과 비교하면 빠진 조각들이 있는 것을 시사합니다.\n\n한 측면에서, 사람들은 훨씬 적은 양의 데이터로 훈련받습니다: 언어 습득 과정 중에 사람들은 약 1.5MB의 정보만 저장한다는 것은, LLM 훈련 데이터셋의 거대한 크기나 LLM 자체의 저장된 매개변수 양과 비교했을 때 미약한 숫자입니다. 사람들이 \"기본적으로 인터넷 전체\"보다 더 적은 양의 언어에 노출되며 상대적으로 많은 데이터를 저장함에도 불구하고 언어에 대한 뛰어난 능력을 나타내는 점은, 아직 발견되지 않은 흥미로운 혁신들이 AGI 시스템을 더 적은 훈련 데이터로 구축하는 데 도움이 될 수 있다는 것을 시사합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다른 관점에서 보면, 인간들은 많은 데이터를 기반으로 훈련을 받습니다. 이 데이터는 현재 사용되는 기반 모델을 훈련하는 데 사용되는 데이터셋과는 매우 다릅니다. 전형적인 인간 아이들은 비디오와 오디오 스트림이 지속적으로 실행되며 여러 해 동안 데이터가 풍부한 환경에서 성장합니다. 이외에도 다른 감각에서 입력을 받습니다. 전혀 다른 인공 지능 시스템에서 어떤 새로운 지능이 발생할까요? 이 시스템이 전혀 다른 데이터셋을 사용하지 않고 일반 아이의 훈련 데이터셋만 사용해 다음 토큰 예측을 잘 하는 능력이 발전했다면?\n\n학습에 유용한 데이터 필터링 기술도 존재할 수 있습니다. 신생아는 흐릿한 흑백으로만 보기 시작합니다. 4개월이 지났을 때야 아기의 색상 감각이 완전히 발달합니다. 이러한 진행에는 진화적인 학습 관련 이점이 있다고 생각됩니다.\n\n![이미지](/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_6.png)\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 단어 예측기만 일까요? 그렇죠! 다른 방법이 있을까요? 제한된 인간 종 구성원으로서 언어를 만들려면 어떻게해야 할까요? 우리는 동시에 백 개의 단어를 말할 수 없습니다. 우리는 텔레파시가 아니며, \"생각 덤프\"를 통해 의사 소통할 수 없습니다. (만약 이렇다면 어떤 지능이 발전했을지 상상해보세요.)\n\n다음 단어, 또는 다음 광경, 또는 다음 소리를 성공적으로 예측함으로써 상당한 지능이 발전할 수 있다고 생각하는 것이 합리적으로 보입니다. 이 기사가 여러분에게 생각의 근원을 불러일으켰기를 바랍니다 — 그리고 완전히 예측할 수 없었으면 좋겠습니다.\n\n2024년 4월 28일, http://glassboxmedicine.com에서 최초로 게시되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png"},"coverImage":"/assets/img/2024-05-17-HumanandArtificialGeneralIntelligenceArisesfromNextTokenPrediction_0.png","tag":["Tech"],"readingTime":18},{"title":"ChatGPT-4o는 사이버 보안 분야에서 게임 체인저입니다 하지만 잘못된 이유로요","description":"","date":"2024-05-17 19:45","slug":"2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons","content":"\n![ChatGPT-4o](/assets/img/2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons_0.png)\n\nAI 세계가 다시 소란스럽습니다.\n\n새로운 OpenAI 업데이트 덕분에요.\n\n새로운 모델 GPT-4o는 이미 영화 \"Her\"의 AI와 비교되고 있습니다.\n\nChatGPT-4o는 놀랄만한 능력과 전반적인 이해력에서 큰 발전이 있어 보입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSo friendly!\n\n---\n\n가장 놀라운 것은 무료로 사용할 수 있다는 점입니다!\n\n![이미지](/assets/img/2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons_1.png)\n\n유료 버전은 여전히 더 큰 컨텍스트 창을 가지고 있을 수 있지만, OpenAI가 가장 첨단 AI를 무료로 제공한 사실은 정말 놀랍습니다.\n\n아직 데모를 보지 않았다면, 지금바로 확인하는 것을 추천합니다. ChatGPT-4o가 다음을 수행하는 것을 확인할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 1 — 과외\n\n이 데모에서는 ChatGPT-4o가 학생을 가르치며 수학 문제를 해결하고 해결책을 안내하는 것을 보여줍니다.\n\nAI가 문제를 자연스러운 방식으로 설명하는 것은 훈련과 온라인 학습의 미래가 어떻게 될지 보여줍니다!\n\n내 아내는 과외교사이며 세션 전체가 사람처럼 들리는 것에 놀랐다고 할 수 없을 정도입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2 — 실시간 번역\n\n또한 놀랄 만한 실시간 번역 기능을 제공합니다. 두 명의 사람이 영어와 이탈리아어로 이야기할 때 따라 말하는 것을 볼 수 있습니다.\n\n저도 직접 사용해 보았는데, 그 성능은 정말 인상적입니다.\n\n번역기 및 그들의 앱들은 어떻게 영향을 받을지 이미 걱정되고 있을 것 같네요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3 - 시각 능력\n\n데모에서 가장 좋았던 점은 팀이 시각 장애인을 도와 실시간으로 주변 환경을 설명하는 ChatGPT4-o를 보여준 것이었습니다.\n\n이것은 전 세계 사람들을 돕는 데 큰 도약이 될 것입니다.\n\n그가 주변 환경을 자연스럽게 설명하고 상호 작용을 얼마나 자연스럽게 했는지에 굉장히 감명받았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 AI가 인류가 다음 단계로 발전하는 데 도움을 줄 것이라는 완벽한 예시입니다.\n\n# 이제, 나쁜 소식 ..\n\nAI가 한 걸음씩 나아갈수록.. 새로운 위험이 소개됩니다.\n\n새로운 비전 및 음성 기능은 사이버 범죄자에겐 꿈의 소재가 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위는 데모 시청과 (100% 주관적인) 나의 경험을 통해 생각해 본 위험 중 일부입니다.\n\n## 1 — 사회 공학 2.0\n\n인간과 같은 대화를 나눌 수 있는 자연스러운 AI는 사회 공학을 미친 정도로 증가시킬 수 있습니다.\n\n우리는 이미 GenAI에 의한 딥페이크와 음성 사기를 보았지만, GPT-4o의 향상된 멀티모달 능력은 사이버 범죄자들이 무시할 수 없는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n잠재적인 잘못된 정보 캠페인과 ID 도용 가능성이 엄청나요.\n\nGPT-4o의 실시간 대화 능력은 사이버 범죄자들이 AI-기반 vishing 공격을 만들어낼 수 있도록 할 것입니다.\n\n희생자들은 합법적인 사람과 소통하고 있다고 믿으며 민감한 정보를 폭로하거나 거래를 승인하게 되는 속임수를 당할 수 있습니다.\n\n이러한 공격은 새로운 것은 아니지만 GPT-4o와 같은 AI와 함께 그 규모와 정교함이 대대적으로 증가할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 2 — AI-Powered Malware \\* 2\n\nAI-powered malware is already here, so there is nothing new about that\n\nWhat stood out to me was the video in which two GPT-4os were interacting with each other.\n\nImagine AI training another AI to evade controls and become better at compromising environments.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 모델 간의 상호작용은 인공지능이 서로 발전함에 따라 사이버 범죄의 미래가 어떻게 보일지도 모릅니다.\n\n## 3 — 다국어 공격\n\n실시간 번역이 가능하다는 것은 놀라우면서도 무섭습니다.\n\n사이버 범죄자들은 이제 다양한 언어로 전환하며 공격의 피해 범위를 확대할 수 있을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다국어 기업에서 일하는 직원들 중 사회 공학에 취약하지 않은 사람들도 언어로 대화하는 AI에 노출되면 자신을 열어보게 될 수 있습니다!\n\n# 미래의 한 눈독\n\nAI가 발전함에 따라 우리는 몇 달마다 미지의 영역으로 나아가는 것 같아요.\n\n기업들은 보안 시스템을 조정하고 AI와의 전투에 AI를 활용해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n흥미로운 데모를 보고 든 생각 중 일부를 소개해 드릴게요.\n\n- AI 기반 보안 도구를 도입하여 AI 기반 사회 공학 및 악성 소프트웨어의 이상한 패턴이나 행동을 감지합니다.\n- 직원 및 사용자가 AI 기반 사회 공학을 인식하는 방법에 대해 교육하십시오. 여전히 이메일 피싱 공격에 대해 이야기 중이라면 PowerPoint 프레젠테이션을 업데이트하세요!\n- 언어별 보안 프로토콜을 고려해 보세요. 언어 인식 기능을 갖춘 보안 프로토콜을 개발하여 다국어로 의심스러운 통신을 식별하고 표시합니다.\n\n다음 해에는 이것이 낡은 정보처럼 보일 수도 있느니라!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다중 모달, 다중 언어 인공 지능이 이제 여기 있으며, GPT-4o는 통제와 위험 관점에서 큰 발전이 이루어졌습니다.\n\n몇 달동안의 위협 전망이 사용자들(그리고 사이버 범죄자들)이 새로운 모델을 이해하고 대척을 하는 모습을 살펴봅시다.\n\n![ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons_2.png](/assets/img/2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons_2.png)\n\nTaimur Ijlal은 핀테크 업종에서 20년 이상의 국제 경험을 갖춘 다중 수상 경력을 지닌 정보 보안 리더입니다. Taimur는 링크드인이나 유튜브 채널 \"클라우드 보안 가이\"에서 연결할 수 있습니다. 클라우드 보안, 인공 지능, 일반적인 사이버 보안 직업 조언에 대해 꾸준히 게시하고 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons_0.png"},"coverImage":"/assets/img/2024-05-17-ChatGPT-4oIsAGame-ChangerInCyberSecurityForAllTheWrongReasons_0.png","tag":["Tech"],"readingTime":7},{"title":"반복 신경망 시퀀스 모델링 소개","description":"","date":"2024-05-17 19:43","slug":"2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling","content":"\n![img](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_0.png)\n\n많은 문제와 현상은 순차적으로 발생합니다. 대표적인 예로는 음성, 날씨 패턴, 시계열 등이 있습니다. 이러한 시스템들의 다음 위치는 이전 상태에 따라 달라집니다.\n\n안타깝게도, 전통적인 신경망은 이러한 유형의 데이터를 처리하거나 예측할 수 없습니다. 왜냐하면 입력값을 독립적으로 분석하기 때문에 데이터가 실제로 순차적이라는 개념을 이해하지 못하기 때문입니다.\n\n그렇다면, 이러한 유형의 데이터를 어떻게 예측할 수 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"우리는 순환 신경망이라고 불리는 것으로 넘어갑니다!\n\n표준 신경망에 익숙하지 않다면, 확인할 블로그 시리즈가 있어요! RNN으로 계속 진행하기 전에 이 일반적인 신경망이 어떻게 작동하는지 알아보는 것을 권장합니다.\n\n# 순환 신경망이란 무엇인가요?\n\n다음은 순환 신경망(RNNs)을 설명하는 다이어그램입니다:\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![RecurrentNeuralNetworksAnIntroductiontoSequenceModelling](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_1.png)\n\n왼쪽에는 순환 뉴런이 있고, 오른쪽에는 시간에 따라 펼쳐진 순환 뉴런이 있습니다. RNN은 바닐라 피드포워드 신경망과 비슷해 보이지만, 이전 반복 실행에서 입력을 받는 중요한 차이점이 있습니다.\n\n그래서 그들을 \"순환\"이라고 부르는 것입니다. 각 단계의 출력이 시간 안에 전파되어 다음 단계의 값을 계산하는 데 도움이 됩니다. 시스템에는 어떤 내재적 \"기억\"이 있어서 모델이 과거의 패턴을 추적할 수 있습니다.\n\n예를 들어, Y_1을 예측할 때, X_1의 입력 및 이전 시간 단계 Y_0에서의 출력을 사용할 것입니다. Y_0가 Y_1에 영향을 미치기 때문에 Y_0가 Y_2에도간접적으로 영향을 줄 수 있다는 것을 알 수 있습니다. 이 알고리즘의 순환성을 명확하게 보여주는 사례입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 숨겨진 상태\n\n문학 작품에서는 일반적으로 숨겨진 상태라는 개념을 볼 수 있습니다. 주로 순환 뉴런을 통해 전달되는 h로 표시됩니다.\n\n![이미지](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_2.png)\n\n간단한 경우에는 숨겨진 상태가 셀의 출력인 경우도 있습니다. 즉, h=Y입니다. 그러나 우리가 나중에 살펴볼 것처럼, 장기 단기 메모리(LSTM) 및 게이트 순환 유닛(GRU)과 같은 보다 복잡한 셀의 경우에는 이것이 항상 참일 수 있는 것은 아닙니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서 각 뉴런으로 전달하는 것과 각 뉴런으로부터의 전달을 명시적으로 하는 것이 가장 좋습니다. 이것이 대부분의 문헌에서 위와 같이 표시되는 이유입니다.\n\n# 이론\n\n순환 뉴런의 각 숨겨진 상태는 다음과 같이 계산할 수 있습니다:\n\n![Recurrent Neural Networks](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서:\n\n- h_t는 시간 t에서의 은닉 상태입니다.\n- h\\_'t−1'는 이전 시간 단계의 은닉 상태입니다.\n- x_t는 시간 t에서의 입력 데이터입니다.\n- W_h는 은닉 상태에 대한 가중치 행렬입니다.\n- W_x는 입력 데이터에 대한 가중치 행렬입니다.\n- b_h는 은닉 상태에 대한 편향 벡터입니다.\n- σ는 활성화 함수로, 일반적으로 tanh 또는 sigmoid 함수를 사용합니다.\n\n그리고 각 순환 뉴런의 출력을 예측하는 방법은 다음과 같습니다:\n\n![Recurrent Neurons](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위와 같이:\n\n- y_t는 시간 t에서의 출력입니다.\n- W_y는 출력과 관련된 가중치 행렬입니다.\n- b_y는 출력 편향 벡터입니다.\n\n보시다시피 표기법과 변수 대부분은 일반 피드포워드 신경망과 유사합니다. 유일한 차이점은 숨겨진 상태의 전달로, 그것은 모델이 출력을 예측하는 데 사용할 다른 입력이나 특성으로 볼 수 있습니다.\n\n각 숨겨진 층은 여러 반복 뉴런을 포함할 수 있으므로 각 후속 입력 뉴런에 숨겨진 상태의 벡터를 전달하게 됩니다. 이를 통해 네트워크는 데이터에서 더 복잡한 패턴을 포착하고 표현할 수 있습니다. 각 시간 단계에서 미니 신경망으로 생각할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 작업 예시\n\n우리는 RNN 내부에서 실제로 무슨 일이 일어나고 있는지 설명하기 위해 간단한 예제를 살펴볼 수 있습니다. 이 예제는 매우 단순한 시나리오일 것이지만, 알아야 할 주요 직관력을 설명해줄 것입니다. 실제로 현실에서는 어떤 문제도 이렇게 간단하지 않을 겁니다!\n\n## 설정\n\n1, 2, 3의 숫자 시퀀스가 있다고 가정해 보겠습니다. 이 시퀀스에서 다음 숫자인 4를 예측하기 위해 RNN을 훈련하려고 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n당신의 RNN은 다음과 같은 구조를 가지고 있을 것입니다:\n\n- 하나의 입력 뉴런\n- 하나의 은닉 뉴런\n- 하나의 출력 뉴런\n\n가중치와 바이어스를 랜덤하게 초기화할 수 있습니다:\n\n- W_x (입력에서 은닉으로의 가중치): 0.5\n- W_h (은닉에서 은닉으로의 가중치): 1.0\n- b_h (은닉 바이어스): 0\n- 𝑏_𝑦 (출력 바이어스): 0\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 텍스트를 친근한 톤으로 한국어로 번역해 드리겠습니다.\n\n다음 활성화 함수를 사용해주세요:\n\n- 은닉층: tanh\n- 출력층: 없음 (identity/linear)\n\n초기 은닉 상태 값:\n\n- h_0 = 0\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Time Step 1 (Input: 1)\n\n다음은 첫 번째 숨겨진 상태입니다:\n\n![첫 번째 숨겨진 상태](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_5.png)\n\n그리고 출력은 다음과 같이 계산됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Recurrent Neural Networks](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_6.png)\n\n이 예시에서 출력 활성화 함수는 identity이므로 출력 값은 hidden state 값과 동일합니다. 그러나 많은 문제에서 항상 그런 것은 아니라는 것을 기억하세요.\n\n## 시간 단계 2 (입력: 2)\n\n이제 최근에 계산된 h_1 값 사용하여 시간 단계 2에서 다음 입력 값을 위한 위 과정을 반복할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식으로 테이블 태그를 바꿔본 것입니다.\n\n![이미지](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_7.png)\n\n한번 더, 우리는 시간 단계 2에서 출력 값을 계산합니다:\n\n![이미지](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_8.png)\n\n## 시간 단계 3 (입력: 3)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막 입력 값과 세 번째 타임 스텝에서는 다음 이미지가 예측 모델을 보여줍니다:\n\n![image](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_9.png)\n\n![image](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_10.png)\n\n현재 모델은 다음 숫자를 0.984로 예측하고 있습니다. 실제 값인 4와는 분명히 멀리 떨어져 있습니다. 실제로는 더 많은 훈련 세트를 사용하여 시간을 거슬러 거슬러 역전파를 수행하여 매개 변수를 최적화할 것입니다. 이 내용은 다음 글에서 다룰 예정입니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다행히도 이 모든 계산과 최적화는 PyTorch와 TensorFlow와 같은 패키지를 통해 Python에서 수행됩니다. 제가 이 기사에서 이를 하는 방법의 예시를 나중에 보여 드리겠습니다!\n\n# RNN의 종류\n\n위의 예는 많은 입력으로부터 하나의 RNN 프로세스의 논리적인 과정을 설명하고 있습니다. 우리는 여러 입력(1,2,3)으로 시작하여 시퀀스에서 다음 숫자를 예측하기 위해 노력하고 있는데, 이는 단일 값입니다.\n\n그러나 다른 작업을 위한 여러 종류의 RNN이 있으며, 우리는 지금 그것들을 살펴볼 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 일대일\n\n이것은 단일 예측을 내놓는 입력 세트가 하나인 전통적인 신경망입니다. 이것은 일반적인 지도 학습 문제를 해결하는 데 도움이 됩니다.\n\n![image](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_11.png)\n\n## 일대다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하나의 입력이 여러 출력으로 이어집니다. 이미지 캡션을 만들거나 음악을 생성하는 데 사용할 수 있습니다.\n\n![image](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_12.png)\n\n## Many-To-One\n\n여러 입력이 하나의 최종 출력을 생성합니다; 이 아키텍처는 감성 분석에 사용됩니다. 영화 리뷰를 제공하면 영화가 좋은지 나쁜지에 따라 +1 또는 -1을 할당합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Many-To-Many](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_13.png)\n\nThis one gets an input at every step and produces an output at each step. This architecture is used for machine translation and also for problems like speech tagging.\n\n![Many-To-Many](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_14.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 인코더-디코더\n\n마지막으로, 인코더-디코더 네트워크를 사용할 수 있습니다. 이는 많은 개별 데이터를 입력으로 받아 하나의 데이터를 출력하는 네트워크와, 그로부터 다시 많은 개별 데이터를 출력으로 하는 네트워크로 구성됩니다. 이는 주로 한 언어로 된 문장을 다른 언어로 번역하는 데 사용됩니다.\n\n![image](/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_15.png)\n\n# PyTorch 예시\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위는 PyTorch에서 간단한 RNN을 구현하는 간단한 예제입니다. 위에서 해결한 문제를 시연합니다. 입력이 1,2,3이고 순서에 따라 다음 숫자를 예측하려고 합니다.\n\n```js\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# RNN 모델 정의\nclass SimpleRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(SimpleRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        x = x.unsqueeze(-1)\n        h_0 = torch.zeros(1, x.size(0), self.hidden_size)\n        rnn_out, _ = self.rnn(x, h_0)\n        out = self.fc(rnn_out[:, -1, :])\n        return out\n\n# 데이터셋\ntrain = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\ntarget = torch.tensor([5], dtype=torch.float32)\n\n# 모델 설정\ninput_size = 1\nhidden_size = 1\noutput_size = 1\nmodel = SimpleRNN(input_size, hidden_size, output_size)\n\n# 손실 및 옵티마이저\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    output = model(train.unsqueeze(0)).squeeze()  # 배치 차원 추가 및 목표 형태와 일치하도록 압축\n    loss = criterion(output, target)\n    loss.backward()\n    optimizer.step()\n\n# 다음 숫자 예측하는 함수\ndef predict(model, input_seq):\n    with torch.no_grad():\n        input_seq = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0)\n        output = model(input_seq).squeeze().item()\n    return output\n\n# 예제 테스트 세트\ntest = [2, 3, 4]\npredicted = predict(model, test)\nprint(f'Input: {test}, Predicted Next Number: {predicted:.2f}')\n```\n\n1000번의 에폭 후 출력 결과는 5입니다! 이 경우에는 모델이 실제로 1000번의 역전파로 훈련되었기 때문에 성능이 우리가 위에서 손으로 계산한 예제보다 훨씬 좋습니다.\n\n소스 코드는 저의 GitHub에서 확인하실 수 있습니다: (GitHub URL)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 장점 대비 단점\n\n이 모든 새롭게 습득한 정보를 바탕으로 RNN의 주요 장단점을 살펴보겠습니다:\n\n## 장점\n\n- 이전 입력값의 형태를 기억할 수 있어서 순차적 데이터를 다루는 데 도움이 됩니다.\n- 정확한 가중치와 편향이 모든 시간 단계에서 공유되어, 더 적은 매개변수와 더 나은 일반화를 이끌어냅니다.\n- 재귀적 성격으로 인해 RNN은 가변 길이의 순차 데이터를 처리할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 단점\n\n- RNN(순환 신경망)은 장기 기억 문제로 이어지는 사라지는 그래디언트 문제에서 상당히 고통받습니다.\n- 각 시간 단계는 이전 단계의 출력에 의존하기 때문에 RNN은 병렬 처리할 수 없어 계산 효율이 떨어집니다.\n\n# 요약\n\nRNN은 시퀀스 모델링에 매우 유용하며, 이전 실행의 정보와 메모리를 유지한 채 다음 예측으로 전파됩니다. 그들의 장점은 임의 길이의 입력을 처리할 수 있으며, 모델 크기가 이 입력 크기로 증가하지 않는다는 것입니다. 그러나 재귀적인 성격을 가지고 있기 때문에 병렬화할 수 없어 계산 효율이 낮으며, 사라지는 그래디언트 문제로 심각하게 고통받을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 또 다른 것!\n\n무료 뉴스레터 'Dishing the Data'를 갖고 있어요! 매주 더 나은 데이터 과학자가 되기 위한 조언과 분야에서의 경험을 나누고 있어요.\n\n# 저와 연결해보세요!\n\n- LinkedIn, X (트위터), 또는 인스타그램\n- 기술적인 데이터 과학과 머신 러닝 개념을 배울 수 있는 제 유튜브 채널!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 참고 자료 및 더 읽을거리\n\n- Stanford RNN Cheatsheet\n- Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. Aurélien Géron. September 2019. Publisher(s): O’Reilly Media, Inc. ISBN: 9781492032649.\n","ogImage":{"url":"/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_0.png"},"coverImage":"/assets/img/2024-05-17-RecurrentNeuralNetworksAnIntroductiontoSequenceModelling_0.png","tag":["Tech"],"readingTime":15},{"title":"ICD 코딩을 위한 LLM 탐험 - 파트 1","description":"","date":"2024-05-17 19:38","slug":"2024-05-17-ExploringLLMsforICDCodingPart1","content":"\n## LLM(Large Language Model)을 활용한 자동 진단 코딩 시스템 구축\n\n임상 코딩은 흔히 쓰이는 용어는 아니지만, 대부분의 국가에서 건강 관리 체계와 상호작용하는 모든 사람에게 중대한 영향을 미칩니다. 임상 코딩은 환자 건강 기록에서 의학 정보(진단 및 수술 등)를 표준화된 숫자 또는 알파벳 코드로 번역하고 매핑하는 것을 포함합니다. 이러한 코드는 청구, 건강 관리 분석 및 환자가 적절한 치료를 받을 수 있도록 하는 데 중요합니다.\n\n![image](/assets/img/2024-05-17-ExploringLLMsforICDCodingPart1_0.png)\n\n임상 코딩은 일반적으로 의료 전문가가 수행합니다. 이러한 코더들은 다양한 진단과 수술을 위한 특정 코드가 포함된 복잡하고 종종 계층적인 코딩 용어를 탐색합니다. 따라서 코더들은 사용된 코딩 용어에 대한 깊은 이해와 경험을 가져야 합니다. 그러나 문서를 수동으로 코딩하는 것은 느릴 수 있고, 오류가 발생할 수 있으며, 상당한 인적 전문 지식이 필요하여 병목 현상이 발생할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n심층 학습은 임상 코딩 자동화에 중요한 역할을 할 수 있습니다. 복잡한 의료 정보를 코드로 추출하고 번역함으로써, 심층 학습 시스템은 인간 중심 시스템 내에서 가치 있는 도구로 작용할 수 있습니다. 이러한 시스템은 코더들을 지원하여 대량의 데이터를 신속하게 처리하고 정확성을 향상시킬 수 있습니다. 이는 행정 업무를 간소화하고 청구 오류를 줄이며 환자 치료 결과를 향상시킬 수 있습니다.\n\n이 첫 번째 부분에서는 ICD 코딩이 무엇인지, 자동 코딩 시스템이 효과적으로 극복해야 하는 다양한 도전에 대해 설명합니다. 또한 대용량 언어 모델(LLM)이 이러한 문제를 극복하는 데 효과적으로 활용할 수 있는 방법을 분석하고, 최근 논문에서 LLM을 효과적으로 활용한 알고리즘을 적용하여 ICD 코딩에 성공적으로 적용하는 방법을 설명합니다.\n\n## 목차:\n\n- ICD 코딩이란 무엇인가?\n- 자동 ICD 코딩의 도전 요소는 무엇인가?\n- LLM이 자동 ICD 코딩에 어떻게 도움이 될까?\n- \"Off-the-shelf 대용량 언어 모델을 이용한 자동 임상 코딩\" 논문 탐색\n- 논문에 설명된 기법 구현\n- 결론\n- 참고문헌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# ICD 코딩이란 무엇인가요?\n\n국제질병분류(ICD) 코딩은 세계보건기구에서 개발 및 유지보수하는 임상 용어 시스템입니다 [1]. 대부분의 국가에서 환자의 모든 진단, 증상 및 절차를 범주화하고 코딩하는 데 사용됩니다.\n\n환자의 진단과 의료 절차를 기록하는 의료 기록은 ICD 코딩에 매우 중요합니다. ICD 용어는 대략 75,000가지 다른 코드로 구성된 트리 구조를 특징으로 하여 방대한 정보를 효율적으로 정리합니다. 이러한 문서를 정확하게 코딩하는 것이 중요합니다. 정확한 코딩은 적절한 청구를 보장하며 의료 분석 품질에 영향을 미치며 환자 치료 결과, 보상 및 의료 효율성에 직접적으로 영향을 줍니다.\n\n# 자동 ICD 코딩에서 어떤 도전들이 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nICD 코딩은 효과적으로 작동하기 위해 자동화된 시스템이 극복해야 할 여러 가지 도전이 있습니다.\n\n## ICD 코딩의 레이블 다양성:\n\n중요한 도전 중 하나는 레이블의 광범위한 출력 공간입니다. ICD 코드는 많고 각 코드는 미세한 세부 사항에서 차이가 있을 수 있습니다. 예를 들어, 오른손에 영향을 주는 상태와 왼손에 영향을 주는 상태는 서로 다른 코드를 갖게 됩니다. 또한 의료 기록에서 드물게 나타나는 희귀 코드의 긴 꼬리가 존재하여, 이러한 코드를 학습하고 정확하게 예측하기 어렵게 만들 수 있습니다.\n\n## 새로운 ICD 코드에 대한 적응:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n번거로우시겠지만, 테이블 태그를 마크다운 형식으로 변경해드릴게요!\n\n전통적인 데이터셋인 MIMIC-III [2] 같은 경우는 종합적이지만, 종종 ICD 코드의 범위를 훈련 말뭉치에 포함된 코드로 제한합니다. 이 제한은 의료 기록에서 ICD 코드로의 딥러닝 모델을 다중 레이블 분류 문제로 처리하는 데 새로운 코드가 도입된 경우 모형 훈련 이후에 어려움을 겪을 수 있음을 의미합니다. 이는 재훈련이 필요하고 잠재적으로 어려울 수 있게 만듭니다.\n\n## 정보 추출 및 문맥 활용:\n\n또 다른 주요 과제는 의료 기록에서 정보를 정확하게 추출하고 문맥에 맞게 처리하는 것입니다. ICD 코딩은 근본적으로 정보 검색 문제로, 의료 기록에서 진단을 식별하는 것 뿐만 아니라 이러한 진단을 해당 ICD 코드로 올바르게 매핑하는 데 필요한 모든 보완 정보를 포착해야 합니다. 따라서 자동화된 시스템이 의료 기록에서 여러 진단을 추출하고 적절히 문맥화하여 ICD 코드로 정확하게 매핑되도록 하는 것이 중요합니다.\n\n![이미지](/assets/img/2024-05-17-ExploringLLMsforICDCodingPart1_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"Contextualization\"란 여기서 무엇을 의미할까요? 의학 노트를 다룰 때 진단을 맥락에 맞게 처리하는 것은 관련 세부사항과 관련된 정보 — 예를 들어 영향을 받는 신체 부위 및 질환의 증상 — 를 연결하여 진단을 완전히 특성화하는 것을 의미합니다. 일반적으로 이 작업은 관계 추출로 참조됩니다.\n\n# 대규모 언어 모델(LLMs)이 자동 ICD 코딩에 어떻게 도움이 되나요?\n\n자동 ICD 코딩의 과제를 다룰 때, 대규모 언어 모델 (LLMs)은 이러한 문제에 대처하는 데 적합하며, 특히 새로운 레이블에 대한 적응성과 복잡한 정보 추출 작업을 관리하는 능력으로 인해 잘 역할을 합니다. 그러나 여기서의 포인트는 LLMs가 자동 ICD 코딩에 대한 최상의 해결책이거나 이러한 문제를 해결할 수 있는 유일한 해결책인 것을 주장하는 것이 아니라, 자동 ICD 코딩 시스템이 극복해야 하는 주요 과제들을 설정함으로써 LLMs의 능력을 최대한 활용하여 이를 해결할 수 있는지를 분석하는 것입니다.\n\n## 새로운 및 드문 ICD 코드에 대한 적응:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLLMs는 견고한 제로샷 및 퓨샷 학습 능력을 보여주며, 적은 예시와 프롬프트에서 제공된 지침으로 새로운 작업에 적응할 수 있습니다. 검색 증강 생성 (RAG)은 미세 조정 없이도 LLM이 새로운 작업에 적응하기 위해 더 많은 맥락 정보에 접근할 수 있는 패러다임입니다. 이는 특히 기존의 훈련 데이터셋에서 자주 나타나지 않을 수 있는 새로운 및/또는 희귀한 ICD 코드에 LLM을 조정하는 데 유용합니다. 이를 단지 몇 가지 설명 또는 사용 사례로부터 합니다.\n\n## 맥락 정보:\n\nLLMs는 임상 분야에서의 제로샷 관계 추출에서 효과적으로 확인되었습니다. 제로샷 관계 추출은 LLM이 해당 관계에 대해 이전에 구체적인 훈련을 받지 않고 텍스트에서 관계를 식별하고 분류할 수 있도록 합니다. 이를 통해 의료 코딩에서의 진단을 더 잘 맥락화하여 더 정확한 ICD 코드를 가져올 수 있습니다.\n\n# \"Automated clinical coding using off-the-shelf large language models\" 논문 탐색하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLLM을 ICD 코딩에 적용한 최근 연구를 탐색하다가, 특정한 세부 조정 없이 LLM을 활용한 ICD 코딩에 관한 매우 흥미로운 논문을 발견했습니다. 저자들은 LLM을 활용한 ICD 코딩을 위해 LLM-지도된 트리 탐색이라는 방법을 개발했습니다 [5].\n\n## 이 방법은 어떻게 작동하나요?\n\nICD 용어는 계층적인 트리 구조입니다. 각 ICD 코드는 이 계층적 구조 내에 존재하며, 부모 코드는 더 일반적인 상태를 다루고, 자식 코드는 특정 질병을 상세히 설명합니다. ICD 트리를 탐색하면 더 구체적이고 세분화된 진단 코드로 이어집니다.\n\nLLM-지도된 트리 탐색에서는 탐색이 루트에서 시작되고 LLM을 사용하여 탐색할 가지를 선택하며, 모든 경로가 고갈될 때까지 반복적으로 계속합니다. 실제로 이 과정은 트리의 임의의 수준에서 모든 코드의 설명과 의료 노트를 LLM에 프롬프트로 제공하고, 해당 의료 노트에 대한 관련 코드를 식별하도록 요청하는 것으로 구현됩니다. 각 인스턴스에서 LLM에 의해 선택된 코드는 더 구체적으로 탐색되고 조사됩니다. 이 방법을 사용하면 가장 관련성이 높은 ICD 코드가 식별되며, 이후 임상 노트에 대한 예측 레이블로 할당됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예시를 통해 이를 명확히 해보겠습니다. ICD 코드 1과 ICD 코드 2라는 두 개의 루트 노드를 가진 트리를 상상해보세요. 각 노드는 코드를 특성화하는 평문 설명을 가지고 있습니다. 초기 단계에서 LLM에게 의학 노트와 코드 설명이 제공되고 의학 노트와 관련된 코드를 식별하도록 요청됩니다.\n\n이 시나리오에서 LLM은 의학 노트와 관련이 있는 것으로 판단된 ICD 코드 1과 ICD 코드 2를 식별합니다. 알고리즘은 각 코드의 자식 노드를 조사합니다. 각 부모 코드는 더 구체적인 ICD 코드를 나타내는 두 개의 자식 노드를 가지고 있습니다. ICD 코드 1부터 시작하여, LLM은 ICD 코드 1.1과 ICD 코드 1.2의 설명을 사용하여 의학 노트를 기반으로 관련 코드를 결정합니다. LLM은 ICD 코드 1.1이 관련이 있다고 결론 내리고, ICD 코드 1.2는 관련이 없다고 판단합니다. ICD 코드 1.1에는 더 이상의 자식 노드가 없으므로, 알고리즘은 할당 가능한 코드인지 확인하고 문서에 할당합니다. 그 다음 알고리즘은 ICD 코드 2의 자식 노드를 평가합니다. LLM을 호출하여, ICD 코드 2.1이 관련이 있는 것으로 판단합니다. 이것은 간단화된 예시이며, 실제로는 ICD 트리는 광범위하고 깊기 때문에 알고리즘은 각 관련된 노드의 자식을 탐색하거나 트리의 끝에 도달하거나 유효한 탐색을 소진할 때까지 계속됩니다.\n\n## 핵심\n\n- 이 방법은 LLM의 세밀한 조정이 필요하지 않습니다. 대신, 제공된 설명을 기반으로 LLM의 의료 노트를 상황에 맞게 이해하고 관련 ICD 코드를 동적으로 식별할 수 있는 능력을 활용합니다.\n- 더 나아가, 본 논문은 LLM이 프롬프트에 관련 정보가 주어질 때 대규모 출력 공간에 효과적으로 적응할 수 있으며, macro-average 지표 측면에서 드문 코드에서 PLM-ICD [6]를 앞지를 수 있다는 것을 보여줍니다.\n- 이 기술은 또한 파라메트릭 지식에 기초하여 의학 노트의 ICD 코드를 예측하도록 LLM에 직접 요청하는 기준선을 능가합니다. 이는 LLM을 임상 코딩 작업을 해결하기 위한 도구나 외부 지식과 통합하는 잠재력을 강조합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 단점\n\n- 알고리즘은 트리의 각 수준에서 LLM을 호출합니다. 이로 인해 트리를 탐색하는 동안 LLM 호출 횟수가 많아지며, ICD 트리의 광범위함이 이에 더해집니다. 이는 단일 문서를 처리하는 데 높은 대기 시간과 비용으로 이어집니다.\n- 저자들이 논문에서 언급한 바와 같이, 관련 있는 코드를 정확하게 예측하려면 LLM이 모든 수준에서 부모 노드를 올바르게 식별해야 합니다. 한 수준에서 실수가 발생하더라도, LLM은 최종 관련 코드에 도달할 수 없게 됩니다.\n- 저자들은 MIMIC-III와 같은 데이터셋을 사용하여 메소드를 평가할 수 없었습니다. 외부 서비스로의 데이터 전송을 금지하는 제한 사항으로 인하여 OpenAI의 GPT 엔드포인트와 같은 외부 서비스로의 데이터 전송이 불가능했습니다. 대신, 저자들은 CodiEsp 데이터셋 [7,8]의 테스트 세트를 사용하여 해당 방법을 평가했습니다. 해당 데이터셋은 250개의 의학 노트를 포함하고 있습니다. 이 데이터셋의 크기가 작은 것은 해당 방법이 대규모 임상 데이터셋에서의 성능을 아직 입증하지 못했음을 시사합니다.\n\n# 논문에서 설명한 기술 구현하기\n\n이 기술을 구현하여 그 작동 방식을 더 잘 이해해 봅시다. 논문에서 언급했듯이, 해당 논문은 평가를 위해 CodiEsp 테스트 세트를 사용합니다. 이 데이터셋은 스페인어 의학 노트와 이에 대응하는 ICD 코드로 구성되어 있습니다. 데이터셋에는 영어로 번역된 버전도 포함되어 있지만, 저자들은 스페인어 의학 노트를 GPT-3.5를 사용하여 영어로 번역하였으며, 이를 통해 사전 번역된 버전을 사용하는 것보다 성능이 약간 향상되었다고 주장했습니다. 이 기능을 복제하고 노트를 영어로 번역해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndef construct_translation_prompt(medical_note):\n    \"\"\"\n    Construct a prompt template for translating Spanish medical notes to English.\n\n    Args:\n        medical_note (str): The medical case note.\n\n    Returns:\n        str: A structured template ready to be used as input for a language model.\n    \"\"\"\n    translation_prompt = \"\"\"You are an expert Spanish-to-English translator. You are provided with a clinical note written in Spanish.\nYou must translate the note into English. You must ensure that you properly translate the medical and technical terms from Spanish to English without any mistakes.\nSpanish Medical Note:\n{medical_note}\"\"\"\n\n    return translation_prompt.format(medical_note = medical_note)\n```\n\nNow that we have the evaluation corpus ready, let’s implement the core logic for the tree-search algorithm. We define the functionality in get_icd_codes, which accepts the medical note to process, the model name, and the temperature setting. The model name must be either “gpt-3.5-turbo-0613” for GPT-3.5 or “meta-llama/Llama-2–70b-chat-hf” for Llama-2 70B Chat. This specification determines the LLM that the tree-search algorithm will invoke during its processing.\n\nEvaluating GPT-4 is possible using the same code-base by providing the appropriate model name, but we choose to skip it as it is quite time-consuming.\n\n```js\ndef get_icd_codes(medical_note, model_name=\"gpt-3.5-turbo-0613\", temperature=0.0):\n    \"\"\"\n    Identifies relevant ICD-10 codes for a given medical note by querying a language model.\n\n    This function implements the tree-search algorithm for ICD coding described in https://openreview.net/forum?id=mqnR8rGWkn.\n\n    Args:\n        medical_note (str): The medical note for which ICD-10 codes are to be identified.\n        model_name (str): The identifier for the language model used in the API (default is 'gpt-3.5-turbo-0613').\n\n    Returns:\n        list of str: A list of confirmed ICD-10 codes that are relevant to the medical note.\n    \"\"\"\n    assigned_codes = []\n    candidate_codes = [x.name for x in CHAPTER_LIST]\n    parent_codes = []\n    prompt_count = 0\n\n    while prompt_count \u003c 50:\n        code_descriptions = {}\n        for x in candidate_codes:\n            description, code = get_name_and_description(x, model_name)\n            code_descriptions[description] = code\n\n        prompt = build_zero_shot_prompt(medical_note, list(code_descriptions.keys()), model_name=model_name)\n        lm_response = get_response(prompt, model_name, temperature=temperature, max_tokens=500)\n        predicted_codes = parse_outputs(lm_response, code_descriptions, model_name=model_name)\n\n        for code in predicted_codes:\n            if cm.is_leaf(code[\"code\"]):\n                assigned_codes.append(code[\"code\"])\n            else:\n                parent_codes.append(code)\n\n        if len(parent_codes) \u003e 0:\n            parent_code = parent_codes.pop(0)\n            candidate_codes = cm.get_children(parent_code[\"code\"])\n        else:\n            break\n\n        prompt_count += 1\n\n    return assigned_codes\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 논문과 비슷하게, ICD-10 트리에 액세스하는 simple_icd_10_cm 라이브러리를 사용합니다. 이를 통해 트리를 탐색하고, 각 코드에 대한 설명에 액세스하며 유효한 코드를 식별할 수 있습니다. 먼저, 트리의 첫 번째 수준에서 노드를 가져옵니다.\n\n```js\nimport simple_icd_10_cm as cm\n\ndef get_name_and_description(code, model_name):\n    \"\"\"\n    ICD-10 코드의 이름과 설명을 검색합니다.\n\n    Args:\n        code (str): ICD-10 코드.\n\n    Returns:\n        tuple: 형식화된 설명과 코드의 이름이 포함된 튜플을 반환합니다.\n    \"\"\"\n    full_data = cm.get_full_data(code).split(\"\\n\")\n    return format_code_descriptions(full_data[3], model_name), full_data[1]\n```\n\n루프 내부에서 각 노드에 해당하는 설명을 얻습니다. 이제 의료 노트와 코드 설명을 기반으로 LLM을 위한 프롬프트를 작성해야 합니다. 우리는 논문에서 제공된 세부 정보를 기반으로 GPT-3.5와 Llama-2용 프롬프트를 작성합니다.\n\n```js\nprompt_template_dict = {\"gpt-3.5-turbo-0613\" : \"\"\"[사례 노트]:\n{note}\n[예시]:\n\u003c예시 프롬프트\u003e\n위식도 역류병\n장전위\n\n\u003c응답\u003e\n위식도 역류병: 예, 환자에게 오메프라졸 처방함.\n장전위: 아니오.\n\n[작업]:\n다음 ICD-10 코드 설명 각각을 고려하고 사례 노트에 관련 언급이 있는지 평가하십시오.\n예시의 형식을 정확히 따르십시오.\n\n{code_descriptions}\"\"\",\n\n\"meta-llama/Llama-2-70b-chat-hf\": \"\"\"[사례 노트]:\n{note}\n\n[예시]:\n\u003c코드 설명\u003e\n* 위식도 역류병\n* 장전위\n* 급성비인두염 [감기]\n\u003c/코드 설명\u003e\n\n\u003c응답\u003e\n* 위식도 역류병: 예, 환자에게 오메프라졸 처방함.\n* 장전위: 아니오.\n* 급성비인두염 [감기]: 아니오.\n\u003c/응답\u003e\n\n[작업]:\n예시 응답 형식을 정확히 따르십시오. (예) 판단하기 전에 전체 설명과 (예|아니오) 판단을 입력한 후에 새 줄을 추가하십시오.\n다음 ICD-10 코드 설명을 고려하고 사례 노트에서 관련 언급이 있는지 확인하십시오.\n\n{code_descriptions}\"\"\"\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n의료 기록과 코드 설명에 기반한 프롬프트를 지금 만들어 보겠습니다. 프롬프트 및 코딩에서 우리에게 이점은 GPT-3.5 및 Llama 2 모두와 상호 작용하기 위해 동일한 openai 라이브러리를 사용할 수 있다는 것입니다. 단, Llama-2가 deepinfra를 통해 배포되어야 합니다. deepinfra는 LLM에 요청을 보내기 위한 openai 형식도 지원합니다.\n\n```js\ndef construct_prompt_template(case_note, code_descriptions, model_name):\n    \"\"\"\n    주어진 케이스 노트와 ICD-10 코드 설명을 평가하는 프롬프트 템플릿 구성\n\n    Args:\n        case_note (str): 의료 케이스 노트\n        code_descriptions (str): ICD-10 코드 설명을 단일 문자열로 포맷팅\n\n    Returns:\n        str: 언어 모델에 입력으로 사용할 준비된 구조화된 템플릿\n    \"\"\"\n    template = prompt_template_dict[model_name]\n\n    return template.format(note=case_note, code_descriptions=code_descriptions)\n\ndef build_zero_shot_prompt(input_note, descriptions, model_name, system_prompt=\"\"):\n    \"\"\"\n    시스템 및 사용자 역할에 대한 제로샷 분류용 프롬프트 빌드\n\n    Args:\n        input_note (str): 입력 노트 또는 질의\n        descriptions (list of str): ICD-10 코드 설명 리스트\n        system_prompt (str): 선택적 초기 시스템 프롬프트 또는 지시\n\n    Returns:\n        list of dict: 각 메시지의 역할 및 내용을 정의하는 구조화된 사전 목록\n    \"\"\"\n    if model_name == \"meta-llama/Llama-2-70b-chat-hf\":\n        code_descriptions = \"\\n\".join([\"* \" + x for x in descriptions])\n    else:\n        code_descriptions = \"\\n\".join(descriptions)\n\n    input_prompt = construct_prompt_template(input_note, code_descriptions, model_name)\n    return [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": input_prompt}]\n```\n\n프롬프트를 구성한 후, 이제 LLM을 호출하여 응답을 받겠습니다:\n\n```js\ndef get_response(messages, model_name, temperature=0.0, max_tokens=500):\n    \"\"\"\n    채팅-완성 API를 통해 지정된 모델로부터 응답을 획득\n\n    Args:\n        messages (list of dict): API 입력용 구조화된 메시지 목록\n        model_name (str): 쿼리할 모델의 식별자\n        temperature (float): 응답의 무작위성을 제어하는 값, 0이면 결정론적\n        max_tokens (int): 응답의 토큰 수 제한\n\n    Returns:\n        str: 모델에서의 응답 메시지 내용\n    \"\"\"\n    response = client.chat.completions.create(\n        model=model_name,\n        messages=messages,\n        temperature=temperature,\n        max_tokens=max_tokens\n    )\n    return response.choices[0].message.content\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋아요, 우리가 출력물을 얻었어요! 이 응답으로부터, 이제 LLM이 추가적인 탐색을 위해 관련있는 노드들과 거부한 노드들을 식별하기 위해 각 코드 설명을 구문 분석합니다. 우리는 출력 응답을 새 줄로 나누고 각 응답을 분할하여 LLM의 각 코드 설명에 대한 예측을 식별합니다.\n\n```js\ndef remove_noisy_prefix(text):\n    # 문자 또는 숫자가 뒤따르고 점과 선택적 공백으로 시작하는 문자열의 제일 앞에 있는 숫자나 문자를 제거합니다.\n    cleaned_text = text.replace(\"* \", \"\").strip()\n    cleaned_text = re.sub(r\"^\\s*\\w+\\.\\s*\", \"\", cleaned_text)\n    return cleaned_text.strip()\n\ndef parse_outputs(output, code_description_map, model_name):\n    \"\"\"\n    모델 출력을 구문 분석하여 주어진 설명 매핑에 따른 ICD-10 코드를 확인합니다.\n\n    Args:\n        output (str): 확인을 포함하는 모델 출력입니다.\n        code_description_map (dict): 설명과 ICD-10 코드의 매핑입니다.\n\n    Returns:\n        list of dict: 확인된 코드 및 해당 설명의 목록입니다.\n    \"\"\"\n    confirmed_codes = []\n    split_outputs = [x for x in output.split(\"\\n\") if x]\n    for item in split_outputs:\n        try:\n            code_description, confirmation = item.split(\":\", 1)\n            if model_name == \"meta-llama/Llama-2-70b-chat-hf\":\n                code_description = remove_noisy_prefix(code_description)\n\n            if confirmation.lower().strip().startswith(\"yes\"):\n                try:\n                    code = code_description_map[code_description]\n                    confirmed_codes.append({\"code\": code, \"description\": code_description})\n                except Exception as e:\n                    print(str(e) + \" Here\")\n                    continue\n        except:\n            continue\n    return confirmed_codes\n```\n\n이제 루프의 나머지를 살펴봅시다. 지금까지 우리는 프롬프트를 구성했고, LLM으로부터 응답을 받았으며, 출력을 구문 분석하여 LLM에 의해 관련이 있다고 판단된 코드를 식별했습니다.\n\n```js\nwhile prompt_count \u003c 50:\n    code_descriptions = {}\n    for x in candidate_codes:\n        description, code = get_name_and_description(x, model_name)\n        code_descriptions[description] = code\n\n    prompt = build_zero_shot_prompt(medical_note, list(code_descriptions.keys()), model_name=model_name)\n    lm_response = get_response(prompt, model_name, temperature=temperature, max_tokens=500)\n    predicted_codes = parse_outputs(lm_response, code_descriptions, model_name=model_name)\n\n    for code in predicted_codes:\n        if cm.is_leaf(code[\"code\"]):\n            assigned_codes.append(code[\"code\"])\n        else:\n            parent_codes.append(code)\n\n    if len(parent_codes) \u003e 0:\n        parent_code = parent_codes.pop(0)\n        candidate_codes = cm.get_children(parent_code[\"code\"])\n    else:\n        break\n\n    prompt_count += 1\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 예측된 코드를 반복하며 각 코드가 \"leaf\" 코드인지 확인합니다. 이는 코드가 유효하고 할당 가능한 ICD 코드임을 보증하는 것입니다. 예측된 코드가 유효하면 LLM이 그 의료 노트에 대한 예측으로 간주합니다. 유효하지 않으면 상위 코드에 추가하여 ICD 트리를 더 탐색하기 위해 자식 노드를 얻습니다. 더 이상 탐색할 상위 코드가 없을 경우 루프를 탈출합니다.\n\n이론적으로 의료 노트 당 LLM 호출 수는 임의로 높을 수 있으며, 알고리즘이 많은 노드를 탐색하는 경우 지연 시간이 증가할 수 있습니다. 저자는 의료 노트 당 최대 50회 프롬프트/LLM 호출로 처리를 종료하는 최대 수를 시행했습니다. 이 한계는 우리가 구현에서도 채택합니다.\n\n## 결과\n\n이제 GPT-3.5와 Llama-2를 LLM으로 사용하여 트리 탐색 알고리즘의 결과를 평가할 수 있습니다. 우리는 알고리즘의 성능을 마이크로-평균 및 매크로-평균 정밀도, 재현율 및 F1 점수를 통해 평가합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![ExploringLLMsforICDCodingPart1_2](/assets/img/2024-05-17-ExploringLLMsforICDCodingPart1_2.png)\n\n구현 결과는 논문에 보고된 점수와 대략적으로 일치하지만 주목할 만한 차이점이 있습니다.\n\n- 이 구현에서 GPT-3.5의 마이크로 평균 측정 지표는 보고된 값보다 약간 뛰어나지만, 매크로 평균 측정 지표는 보고된 값보다 조금 부족합니다.\n- 마찬가지로 Llama-70B의 마이크로 평균 측정 지표는 보고된 값과 일치하거나 조금 뛰어나지만, 매크로 평균 측정 지표는 보고된 값보다 낮습니다.\n\n앞서 언급했듯이, 이 구현은 몇 가지 미세한 차이점을 가지고 있어 최종 성능에 영향을 미칩니다. 이 구현이 원본 논문과 어떻게 다른지에 대한 보다 자세한 내용은 링크된 저장소를 참조해 주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n이 방법을 이해하고 구현하는 것은 여러 측면에서 나에게 매우 유익했습니다. 이를 통해 대규모 언어 모델(LLMs)의 강점과 약점에 대해 보다 세밀하게 이해할 수 있었고 임상 코딩 사례에서 그것을 구현할 수 있었습니다. 구체적으로, 코드에 관련된 중요한 정보에 동적으로 접근할 수 있는 경우 LLMs는 임상 문맥을 효과적으로 이해하고 관련 코드를 정확하게 식별할 수 있다는 것이 분명해졌습니다.\n\nLLMs를 임상 코딩을 위한 대리자로 활용하는 것이 성능을 더욱 향상시킬 수 있는지 탐구하는 것이 흥미로울 것입니다. 생명공학 및 임상 텍스트에 대한 외부 지식 소스가 논문이나 지식 그래프 형태로 풍부하게 제공되는 상황에서 LLM 대리자는 의료 문서를 보다 세밀한 단위로 분석하는 워크플로에 활용될 수 있습니다. 또한 필요한 경우 외부 지식을 참고하여 최종 코드에 도달할 수 있도록 동적으로 도구를 활용할 수도 있습니다.\n\n## 감사의 글\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 방법을 평가하는 데 도움을 준 이 논문의 주 저자 Joseph에게 큰 감사를 표합니다!\n\n- 참고 자료:\n\n[1] https://www.who.int/standards/classifications/classification-of-diseases\n\n[2] Johnson, A. E., Pollard, T. J., Shen, L., Lehman, L. W. H., Feng, M., Ghassemi, M., … \u0026 Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database Sci. Data, 3(1), 1.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[3] Agrawal, M., Hegselmann, S., Lang, H., Kim, Y., \u0026 Sontag, D. (2022). 대형 언어 모델은 소수의 적은 데이터로도 임상 정보를 추출합니다. arXiv 사전 인쇄 arXiv:2205.12689.\n\n[4] Zhou, H., Li, M., Xiao, Y., Yang, H., \u0026 Zhang, R. (2023). 임상 관계 추출을 위한 LLM Instruction-Example Adaptive Prompting (LEAP) 프레임워크. medRxiv : 의학과학 사전 인쇄 서버, 2023.12.15.23300059. https://doi.org/10.1101/2023.12.15.23300059\n\n[5] Boyle, J. S., Kascenas, A., Lok, P., Liakata, M., \u0026 O’Neil, A. Q. (2023, 10월). 상업용 대형 언어 모델을 사용한 자동 임상 코딩. NeurIPS 2023에서 Deep Generative Models for Health Workshop 발표.\n\n[6] Huang, C. W., Tsai, S. C., \u0026 Chen, Y. N. (2022). 사전 훈련된 언어 모델로 자동 ICD 코딩하기: PLM-ICD. arXiv 사전 인쇄 arXiv:2207.05289.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMiranda-Escalada, A., Gonzalez-Agirre, A., Armengol-Estapé, J., \u0026 Krallinger, M. (2020). CLEF (Working Notes), 2020에서 CodiEsp Track의 비영어 임상 사례에 대한 주석, 가이드라인 및 솔루션에 대한 개요.\n\nMiranda-Escalada, A., Gonzalez-Agirre, A., \u0026 Krallinger, M. (2020). CodiEsp corpus: ICD10 (CIE10)로 코드화된 골드 표준 스페인어 임상 사례 - eHealth CLEF2020 (1.4) [데이터 세트]. Zenodo. https://doi.org/10.5281/zenodo.3837305 (CC BY 4.0)\n","ogImage":{"url":"/assets/img/2024-05-17-ExploringLLMsforICDCodingPart1_0.png"},"coverImage":"/assets/img/2024-05-17-ExploringLLMsforICDCodingPart1_0.png","tag":["Tech"],"readingTime":23}],"page":"114","totalPageCount":120,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":5},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"114"},"buildId":"JlBEgQDLGRx6DYlBnT8eD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>