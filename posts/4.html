<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/4" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/4" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_buildManifest.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="Docker, Uptime Kuma, 그리고 Traefik을 사용하여 웹사이트 모니터링 하는 방법" href="/post/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Docker, Uptime Kuma, 그리고 Traefik을 사용하여 웹사이트 모니터링 하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Docker, Uptime Kuma, 그리고 Traefik을 사용하여 웹사이트 모니터링 하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Docker, Uptime Kuma, 그리고 Traefik을 사용하여 웹사이트 모니터링 하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="스프링 부트 마이크로서비스 도커라이징 방법 단계별 가이드" href="/post/2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="스프링 부트 마이크로서비스 도커라이징 방법 단계별 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="스프링 부트 마이크로서비스 도커라이징 방법 단계별 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">스프링 부트 마이크로서비스 도커라이징 방법 단계별 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Poetry로 초고속 Python Docker 빌드 하는 방법 " href="/post/2024-06-23-BlazingfastPythonDockerbuildswithPoetry"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Poetry로 초고속 Python Docker 빌드 하는 방법 " loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-BlazingfastPythonDockerbuildswithPoetry_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Poetry로 초고속 Python Docker 빌드 하는 방법 " loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Poetry로 초고속 Python Docker 빌드 하는 방법 </strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="저렴한 날씨 관측소와 기존 장비로 개인 DevOps 스타일 날씨 대시보드 만드는 방법" href="/post/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="저렴한 날씨 관측소와 기존 장비로 개인 DevOps 스타일 날씨 대시보드 만드는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="저렴한 날씨 관측소와 기존 장비로 개인 DevOps 스타일 날씨 대시보드 만드는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">저렴한 날씨 관측소와 기존 장비로 개인 DevOps 스타일 날씨 대시보드 만드는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="GitLab에서 Docker를 사용하여 Playwright 테스트 실행하는 방법" href="/post/2024-06-23-RunningPlaywrighttestswithDockeronGitLab"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="GitLab에서 Docker를 사용하여 Playwright 테스트 실행하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="GitLab에서 Docker를 사용하여 Playwright 테스트 실행하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">GitLab에서 Docker를 사용하여 Playwright 테스트 실행하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Alpine, Distroless, 아니면 Scratch 도커 이미지 선택 가이드" href="/post/2024-06-23-alpinedistrolessorscratch"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Alpine, Distroless, 아니면 Scratch 도커 이미지 선택 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-alpinedistrolessorscratch_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Alpine, Distroless, 아니면 Scratch 도커 이미지 선택 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Alpine, Distroless, 아니면 Scratch 도커 이미지 선택 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="전체 구성 Compose 파일 쉽게 설정하는 방법" href="/post/2024-06-23-TheWholeShebangComposeFiles"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="전체 구성 Compose 파일 쉽게 설정하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-TheWholeShebangComposeFiles_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="전체 구성 Compose 파일 쉽게 설정하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">전체 구성 Compose 파일 쉽게 설정하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">43<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년 최신 AWS API Gateway 사용 방법 및 기능 완벽 가이드" href="/post/2024-06-23-AWSAPIGateway"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 최신 AWS API Gateway 사용 방법 및 기능 완벽 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-AWSAPIGateway_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 최신 AWS API Gateway 사용 방법 및 기능 완벽 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">2024년 최신 AWS API Gateway 사용 방법 및 기능 완벽 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS에서 이벤트 기반 아키텍처에 분산 회로 차단기 적용 방법" href="/post/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS에서 이벤트 기반 아키텍처에 분산 회로 차단기 적용 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS에서 이벤트 기반 아키텍처에 분산 회로 차단기 적용 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS에서 이벤트 기반 아키텍처에 분산 회로 차단기 적용 방법</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS Glue CI CD 간소화하는 방법" href="/post/2024-06-23-StreamliningAWSGlueCICD"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS Glue CI CD 간소화하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-StreamliningAWSGlueCICD_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS Glue CI CD 간소화하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS Glue CI CD 간소화하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">12 hours ago</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link posts_-active__YVJEi" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Docker, Uptime Kuma, 그리고 Traefik을 사용하여 웹사이트 모니터링 하는 방법","description":"","date":"2024-06-23 00:46","slug":"2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_0.png\" /\u003e\n\n# 소개\n\n이 문서에서는 Docker/Docker Swarm을 사용하여 로컬 PC 또는 서버에서 웹사이트 모니터링을 설정하는 방법을 보여드리려고 합니다. prometheus, node-exporter, 또는 graphana와 같이 복잡한 모니터링 스택 대신에 NodeJs와 Vue로 작성된 가벼운 대안인 Uptime Kuma를 소개할 예정입니다.\n\n이 프로젝트는 오픈 소스로 GitHub에서 찾을 수 있습니다: https://github.com/louislam/uptime-kuma\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 대안을 사용하게 된 중요한 속성들은 다음과 같아요:\n\n- UI가 아주 멋져요!\n- Docker/Docker Swarm을 사용한 아주 쉬운 설정\n- 매우 간편한 구성\n- Discord, Slack, 이메일 (SMTP) 등을 통한 알림. 전체 목록을 보려면 여기를 클릭하세요.\n\n# 준비 사항\n\nUptime Kuma를 서버 또는 로컬 머신에서 실행하려면 환경을 준비해야 해요. 저는 Traefik을 Docker Swarm에서 실행되는 리버스 프록시로 실행하여 Docker Compose로 배포하는 것을 좋아해요. Traefik을 사용하면 단일 Compose 파일을 만들어서 서비스를 배포하고 도메인에 대한 Let's Encrypt 인증서를 자동으로 발급할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 두 가지 전제 조건을 간단히 설명한 후, Uptime Kuma를 배포하는 방법을 보여드릴 거에요.\n\n## Docker\n\nDocker는 다양한 종류의 애플리케이션을 개발하고 배포하며 실행하기 위해 널리 사용되는 플랫폼이에요. 이를 통해 인프라를 애플리케이션에서 분리하여 한 기계에서 다른 기계로 소프트웨어를 빠르게 전달할 수 있게 해줘요.\n\nDocker를 사용하여 소프트웨어를 구현하면 흔한 \"내 컴퓨터에서는 작동하는데\" 같은 인프라 문제를 효과적으로 해결할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n'img' 태그를 Markdown 형식으로 변경해주세요.\n\n\n![](/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_1.png)\n\n시스템이나 서버에 Docker를 설치하려면 docker.com의 공식 튜토리얼을 따라 진행하세요.\n\n로컬 머신에 Uptime Kuma만 호스팅하고 싶고 Windows를 사용하며 Docker Desktop을 설치할 수 없다면 이 가이드를 따라 진행할 수 있습니다:\n\n## Traefik\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTraefik이란 무엇인가요?\n\nTraefik은 도커 환경에서 배포된 서비스로 들어오는 요청을 전달하는 데 사용됩니다. 또한 Traefik이 관리하는 모든 도메인에 대해 자동으로 Let’s Encrypt SSL 인증서를 생성할 수 있는 기능이 있습니다.\n\n도커 환경에서 로컬 Traefik 서비스를 설정하려면 이 도커 Compose 파일을 다운로드하고 다음 명령어를 실행하면 됩니다:\n\n1. Traefik에서 사용되는 외부 네트워크를 생성하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. 필요한 변수 내보내기\n\n3. 컨테이너 시작하기\n\n트라픽 대시보드에 접속하려면 https://dashboard.yourdomain.de 로 이동하고 다음으로 로그인하세요:\n\n```js\nusername: devadmin\npassword: devto\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도커 스웜 모드 환경에서 Traefik을 배포하는 방법은 다음과 같습니다. 이 도커 Compose 파일을 다운로드하고 1단계와 2단계를 수행한 후 다음과 같이 배포하면 됩니다:\n\nTraefik에 대한 깊은 이해를 얻으려면 다음 기사에서 도커 내에서 배포하는 방법과 도커 스웜 모드 내에서 배포하는 방법을 읽어보실 수 있습니다.\n\n# Docker를 사용하여 Uptime Kuma 배포하기\n\nUptime Kuma를 배포하는 방법은 세 가지 환경에서 가능합니다: 로컬에서 도커로, 도커와 Traefik을 사용하여 서버에서, 그리고 도커를 실행하는 서버 클러스터에서 Traefik과 함께.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 로컬 Docker 환경에서 배포하기\n\nUptime Kuma를 테스트하는 가장 쉬운 방법은 새로운 Docker Compose 파일을 만들어 다음 내용을 붙여넣어 자신의 장치에서 로컬로 실행하는 것입니다.\n\n이 Docker Compose 파일은 공식 Uptime Kuma 이미지를 사용하여 포트를 1337로 매핑하고 Uptime Kuma의 데이터 폴더를 저장하기 위해 공유 폴더를 사용합니다.\n\n폴더로 이동하여 Docker Compose 파일을 실행하려면 다음과 같이 실행하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 명령이 완료되면 https://localhost:1337/을 열어 Uptime Kuma 인스턴스에 액세스할 수 있습니다.\n\n## Traefik을 사용하여 Docker/Docker Swarm으로 원격으로 배포\n\n고유한 서버를 실행하고 Docker를 사용하여 단일 서버를 실행하거나 Docker의 스웜 모드로 서버 클러스터를 실행하고 있는 경우 Docker Compose 파일을 업데이트해야 합니다.\n\n당신이 나의 튜토리얼에 설명된대로 Traefik 인스턴스를 설정했다고 가정하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새로운 Docker Compose 파일을 만들고 다음 내용을 붙여넣으세요:\n\n이 Docker Compose 파일을 배포하기 전에 Traefik을 위한 것처럼 도메인을 내보내야 합니다:\n\n다른 설정을 필요에 맞게 조정하세요(Domain, container_name, network 및 volumes) 그리고 Uptime Kuma를 배포하세요:\n\nTraefik을 사용하는 Docker in Docker Swarm 모드의 경우,이 Compose 파일을 사용하여 데이터를 저장하고 싶은 노드에 monitor이름의 새로운 노드 레이블을 작성하고 PRIMARY_DOMAIN을 내보낸 후 아래 명령어로 배포하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n몇 초/분 후에 Uptime Kuma가 성공적으로 배포되어서 https://monitor.PRIMARY_DOMAIN/에서 인스턴스에 액세스할 수 있게 됩니다.\n\n# Uptime Kuma 구성\n\nUptime Kuma가 성공적으로 배포된 후 처음으로 액세스하면 안전한 관리자 비밀번호를 구성해야 합니다.\n\n작업을 완료하신 후에는 이 버튼을 눌러 첫 번째 모니터를 추가해보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_2.png](/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_2.png)\n\n새로운 UI가 나타나며 특정 동작을 정의할 수 있습니다:\n\n![2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_3.png](/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_3.png)\n\n이제 첫 번째 모니터를 만들었으므로, Discord, 이메일 또는 기타 어떤 유형의 알림도 구성해야 합니다. 모니터가 예상대로 작동하지 않을 때마다 알림을 받게 됩니다. 이 과정은 보통 매우 쉽고 다음으로 설명될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 디스코드 알림 설정하기 (그리고 슬랙, 팀즈)\n\n디스코드 알림 (또는 팀즈, 슬랙)을 활성화하려면 Uptime Kuma가 경고를 보낼 서버와 채널에 대한 디스코드 (또는 팀즈, 슬랙) 웹훅이 필요합니다. 디스코드에서는 이를 '서버 설정 - 통합 - 웹훅 생성'을 통해 얻을 수 있습니다. 웹훅을 만든 후에 해당 웹훅 URL을 복사합니다. 팀즈나 슬랙에서도 거의 비슷하게 작동해야 합니다.\n\n그런 다음, 모니터를 편집하고 \"알림 설정\"을 누릅니다. 나타나는 대화 상자에서 디스코드 (또는 팀즈, 슬랙)을 선택하고 친숙한 이름을 지어주고 웹훅 URL을 붙여넣습니다. 디스코드의 경우 UI는 다음과 같이 보이어야 합니다:\n\n![디스코드 설정 화면](/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**테이블 태그를 Markdown 형식으로 변경하면 됩니다.**\n\n기존 모니터에도 적용하거나 새로운 모니터의 기본 설정으로 지정할 수 있습니다.\n\n## 이메일 알림 설정하기\n\n만약 디스코드, 팀즈, 또는 슬랙 알림을 원치 않는다면, 이메일 알림을 생성할 수도 있습니다. 설정하기 위해 이메일 계정의 호스트명, 포트, 사용자명, 비밀번호, 보내는/받는 이메일, 그리고 인증 방법 (StartTLS 또는 SSL)이 필요합니다. 또한 새로운 모니터의 기본 설정으로 지정하거나 기존 모니터에 추가할 수도 있습니다.\n\n# 마지막으로\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 Uptime Kuma를 로컬 또는 Docker 또는 Docker Swarm 환경에 Traefik 역방향 프록시와 함께 설치하는 방법을 보여드렸어요. 이 가벼운 도구는 설정이 쉽고 다양한 구성 옵션을 제공하기 때문에 어떤 웹사이트든 감시하는 데 아주 좋아요. 소프트웨어 개발자나 블로그 호스터라면 Uptime Kuma를 추천드릴게요. 이를 통해 서비스나 블로그가 제대로 작동하는지 확인할 수 있어요.\n\n이 튜토리얼은 여기까지에요. 이제 설정할 수 있을 거에요. 여전히 궁금한 점이 있다면 댓글 섹션에 질문해 주세요.\n\n이 기사를 즐겁게 읽었다면 소중한 생각을 댓글로 남겨주십시오! 피드백을 듣고 싶어요.\n\n누구에게든 이 기사를 공유하고 제 개인 블로그, LinkedIn, Twitter 및 GitHub에서 연락해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글은 제 블로그에도 게재되었습니다: [https://www.paulsblog.dev/use-docker-uptime-kuma-and-traefik-to-monitor-your-website/](https://www.paulsblog.dev/use-docker-uptime-kuma-and-traefik-to-monitor-your-website/)","ogImage":{"url":"/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_0.png"},"coverImage":"/assets/img/2024-06-23-UseDockerUptimeKumaandTraefikToMonitorYourWebsite_0.png","tag":["Tech"],"readingTime":6},{"title":"스프링 부트 마이크로서비스 도커라이징 방법 단계별 가이드","description":"","date":"2024-06-23 00:44","slug":"2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide","content":"\n\n\n![이미지](/assets/img/2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide_0.png)\n\n현대 소프트웨어 개발 환경에서, 마이크로서비스 아키텍처는 확장성, 유연성 및 유지 보수성 때문에 상당한 인기를 얻었습니다. 선도적인 컨테이너화 플랫폼인 Docker는 각 서비스를 위한 격리된 환경을 제공하여 지속적인 통합 및 배포 (CI/CD)를 용이하게 하고, 서로 다른 환경에서 일관된 동작을 보장함으로써 이 아키텍처를 보완합니다. 이 글에서는 마이크로서비스의 도커화 과정을 안내하며, 주요 개념, 모범 사례 및 실용적인 단계를 강조할 것입니다.\n\n# 마이크로서비스란?\n\n마이크로서비스 아키텍처는 거대한 단일 응용 프로그램을 작은, 독립적인 서비스로 분해하여 개발, 배포 및 확장이 독립적으로 가능한 아키텍처입니다. 각 마이크로서비스는 특정 기능을 담당하고 다른 서비스와 API를 통해 통신합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Microservices에 Docker를 사용하는 이유?\n\nDocker 컨테이너는 Microservices에 다음과 같은 많은 이점을 제공합니다:\n\n- 격리성: 각 Microservice는 자체 컨테이너에서 실행되어 프로세스와 리소스를 격리합니다.\n- 일관성: Docker 컨테이너는 개발, 테스트 및 프로덕션 환경에서 응용 프로그램이 동일하게 작동함을 보장합니다.\n- 이식성: Docker 이미지는 Docker를 지원하는 모든 플랫폼에서 실행할 수 있습니다.\n- 확장성: 컨테이너는 수요에 따라 쉽게 확장하거나 축소할 수 있습니다.\n- 간편한 CI/CD: Docker는 CI/CD 파이프라인과 잘 통합되어 자동 빌드, 테스트 및 배포를 가능하게 합니다.\n\n# 준비 사항\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Docker 및 Docker Compose에 대한 기본적인 이해도\n- 로컬에서 설정된 Spring Boot 마이크로서비스 프로젝트\n- 공식 Docker 웹사이트에서 다운로드할 수 있는 본인의 컴퓨터에 Docker가 설치되어 있어야 합니다.\n\n# Spring Boot 마이크로서비스를 Docker화하는 단계\n\n- 각 마이크로서비스에 대해 Dockerfile 작성\n\n각 Spring Boot 마이크로서비스에 대해 프로젝트의 루트 디렉토리에 Dockerfile을 생성해야 합니다. 다음은 Spring Boot 애플리케이션을 위한 Dockerfile 예시입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n쿠폰 서비스용:\n\n```js\n# 공식 OpenJDK 런타임을 부모 이미지로 사용\nFROM openjdk:17-alpine\n\n# JAR 파일을 컨테이너로 복사\nADD target/couponservice-0.0.1-SNAPSHOT.jar couponservice-0.0.1-SNAPSHOT.jar\n\n# 애플리케이션 실행\nENTRYPOINT [ \"java\",\"-jar\",\"couponservice-0.0.1-SNAPSHOT.jar\" ]\n```\n\n상품 서비스용:\n\n```js\n# 공식 OpenJDK 런타임을 부모 이미지로 사용\nFROM openjdk:17-alpine\n\n# JAR 파일을 컨테이너로 복사\nADD target/productservice-0.0.1-SNAPSHOT.jar productservice-0.0.1-SNAPSHOT.jar\n\n# 애플리케이션 실행\nENTRYPOINT [ \"java\",\"-jar\",\"productservice-0.0.1-SNAPSHOT.jar\" ]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. 다음 명령을 사용하여 메이븐을 통해 두 개의 마이크로서비스를 빌드하세요:\n\n```js\nmvn clean package -DskipTests\n```\n\n3. 도커 이미지 빌드하기\n\n도커 파일을 포함하는 디렉토리로 이동한 후 도커 이미지를 빌드하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n도커 build -f Dockerfile -t coupon_app .\n```\n\n```js\n도커 build -f Dockerfile -t product_app .\n```\n\n4. 데이터베이스 연결을 위한 MySQL 컨테이너 설정합니다.\n\n```js\n도커 run -d -p 6666:3306 --name=docker-mysql --env=\"MYSQL_ROOT_PASSWORD=test1234\" --env=\"MYSQL_DATABASE=mydb\" mysql\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 다음 명령어를 사용하여 Docker 이미지를 실행하십시오:\n\n- MySQL 이미지를 실행하고 단일 명령어로 쿼리를 실행하십시오.\n\n```js\ndocker exec -i docker-mysql mysql -uroot -ptest1234 mydb \u003ctables.sql\n```\n\n2. 다음 명령어를 사용하여 두 마이크로서비스를 실행하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n도커 실행 -t --name=coupon-app --link docker-mysql:mysql -p 10555:9091 coupon_app\n```\n\n```js\n도커 실행 -t --link docker-mysql:mysql --link coupon-app:coupon_app -p 10666:9090 product_app\n```\n\n6. Postman을 사용하여 애플리케이션 테스트하기.\n\n엔드포인트를 호출하여 Postman을 사용하여 애플리케이션을 테스트할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide_1.png\" /\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide_2.png\" /\u003e\n\n데모에 사용된 마이크로서비스의 소스 코드는 제 GitHub 저장소에서 확인하실 수 있습니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSpring Boot 마이크로서비스를 도커화하면 개발, 배포 및 확장 프로세스를 간편하게 만들 수 있어요. 각 마이크로서비스를 위한 도커 파일을 만들고 도커의 환경 일관성 및 격리 기능을 활용함으로써 견고하고 확장 가능한 마이크로서비스 아키텍처를 구축할 수 있어요. 이 안내서에 나온 단계에 따라 Spring Boot 마이크로서비스를 도커화하고 컨테이너화의 모든 잠재력을 활용해 보세요.","ogImage":{"url":"/assets/img/2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-06-23-HowtoDockerizeSpringBootMicroservicesAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":4},{"title":"Poetry로 초고속 Python Docker 빌드 하는 방법 ","description":"","date":"2024-06-23 00:42","slug":"2024-06-23-BlazingfastPythonDockerbuildswithPoetry","content":"\n\n## 느린 번거로운 도커 빌드를 원활한 작업으로 바꿀 수 있는 방법\n\n![image](/assets/img/2024-06-23-BlazingfastPythonDockerbuildswithPoetry_0.png)\n\n프로젝트의 도커 이미지를 빌드하는 것은 일반적으로 재현 가능하고 결정론적인 방식으로 종속성을 설치하는 작업을 포함합니다. 파이썬 커뮤니티에서 Poetry는 이를 달성하기 위한 가장 확실한 도구 중 하나입니다. 그러나 도커 빌드에서 Poetry를 최적으로 활용하지 않으면 성능이 저하되고 긴 빌드 시간으로 개발자 생산성이 저하될 수 있습니다.\n\n본 문서는 이미 Poetry와 도커, 특히 도커 레이어 캐싱 작동 방식에 대해 익숙한 독자들을 가정하고 있으며 빌드를 최적화하기 위한 방법을 찾고 있는 독자를 위해 작성되었습니다. 이 글은 각 최적화의 영향을 이해할 수 있도록 순진한 해결책부터 최적화된 해결책까지 구조화되어 있습니다. 소개는 여기까지, 이제 몇 개의 Dockerfile을 살펴보겠습니다! 💪\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 0. 프로젝트 구조\n\n우리는 이야기할 작은 프로젝트를 사용해 볼까요? 그 이름은 제가 본 산 중에서 최고인 알나푸르나 산으로 임의로 지었습니다 ⛰ 극소 프로젝트 구성은 pyproject.toml, 관련된 poetry.lock, 코드 및 Dockerfile을 포함할 것입니다.\n\n```js\n.\n├── Dockerfile\n├── README.md\n├── annapurna\n│   ├── __init__.py\n│   └── main.py\n├── poetry.lock\n└── pyproject.toml\n```\n\n단순함을 위해, 유명한 fastapi 웹 서버를 poetry add fastapi를 통해 설치하고, 제 프로젝트에서 일반적으로 사용하는 몇 가지 린터들을 설치해보았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n[tool.poetry]\nname = \"annapurna\"\nversion = \"1.0.0\"\ndescription = \"\"\nauthors = [\"Riccardo Albertazzi \u003cmy@email.com\u003e\"]\nreadme = \"README.md\"\n\n[tool.poetry.dependencies]\npython = \"^3.11\"\n\nfastapi = \"^0.95.1\"\n\n\n[tool.poetry.group.dev.dependencies]\nblack = \"^23.3.0\"\nmypy = \"^1.2.0\"\nruff = \"^0.0.263\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n\n\n## 1. The naive approach 😐\n\nWhat our Docker build needs to do is having Python and Poetry installed, getting our code, installing the dependencies and setting the project’s entrypoint. This is exactly what we are doing in here:\n\n```dockerfile\nFROM python:3.11-buster\n\nRUN pip install poetry\n\nCOPY . .\n\nRUN poetry install\n\nENTRYPOINT [\"poetry\", \"run\", \"python\", \"-m\", \"annapurna.main\"]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 간단한 Dockerfile은 일을 해내고, 단순한 `docker build .` 명령으로 이미 동작하는 이미지를 얻을 수 있습니다. 실제로 이것은 자습서와 오픈 소스 프로젝트에서 보게 되는 전형적인 Dockerfile로, 이해하기 쉽기 때문입니다. 그러나 프로젝트가 성장하면 번거로운 빌드와 거대한 Docker 이미지로 이끌게 될 것입니다. 저의 결과 Docker 이미지는 실제로 1.1GB입니다! 우리가 볼 최적화는 캐싱을 활용하고 최종 이미지 크기를 줄이는 방향으로 이루어집니다.\n\n## 2. 워밍업 🚶\n\n워밍업을 위한 몇 가지 개선 사항부터 시작해봅시다:\n\n- Poetry 버전을 고정하세요. Poetry는 마이너 버전 간에 중요한 변경 사항이 포함될 수 있으므로 새 버전이 출시될 때 빌드가 갑자기 실패하지 않도록 하려면 로컬에서 사용 중인 버전과 동일한 버전으로 명확히 고정해야 합니다.\n- 필요한 데이터만 COPY하세요. 이렇게 하면 예를 들어 로컬 가상 환경(.venv에 위치)의 불필요한 복사를 피할 수 있습니다. README.md 파일이 없으면 Poetry가 경고를 표시할 것이지만(저는 이 선택을 공유하지 않습니다), 따라서 비어있는 파일을 생성합니다. 로컬 파일을 복사할 수도 있지만 수정할 때마다 Docker 레이어 캐싱을 효과적으로 방지하게 됩니다.\n- 개발 의존성을 설치하지 마세요. 실제로 프로덕션 환경에서는 린터(linters)와 테스트 스위트(test suites)가 필요하지 않으므로 `poetry install --without dev`로 개발 의존성을 설치하지 마세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```Dockerfile\nFROM python:3.11-buster\n\nRUN pip install poetry==1.4.2\n\nWORKDIR /app\n\nCOPY pyproject.toml poetry.lock ./\nCOPY annapurna ./annapurna\nRUN touch README.md\n\nRUN poetry install --without dev\n\nENTRYPOINT [\"poetry\", \"run\", \"python\", \"-m\", \"annapurna.main\"]\n```\n\n이로써 이미 1.1GB에서 959MB로 줄었습니다. 그리 많지는 않지만, 성실하게 작업한 결과네요.\n\n# 3. Poetry 캐시 정리 🧹\n\n기본적으로 Poetry는 다운로드한 패키지를 캐시하여 이후의 설치 명령에 재사용할 수 있게 합니다. 하지만 우리는 Docker 빌드에서 이를 신경쓰지 않아도 됩니다 (그렇죠?) 그래서 중복 저장소를 제거할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 시는 --no-cache 옵션도 지원하므로 왜 사용하지 않는 걸까요? 나중에 이에 대해 알아보겠죠 ;)\r\n- 캐시 폴더를 제거할 때는 동일한 RUN 명령어에서 수행해야 합니다. 별도의 RUN 명령어에서 수행하면 캐시는 이전 Docker 레이어 (poetry install을 포함하는 레이어)의 일부로 남아 있어서 최적화가 무용지물이 될 수 있습니다.\n\n이 작업을 수행하는 동안 빌드의 결정적 특성을 더 강화하기 위해 몇 가지 Poetry 환경 변수를 설정합니다. 그 중에서도 가장 논란이 되는 것은 POETRY_VIRTUALENVS_CREATE=1입니다. 도커 컨테이너 내에서 가상 환경을 만들고 싶은 이유가 뭘까요? 솔직히 이 플래그를 비활성화하는 것보다 이 솔루션을 선호합니다. 이 플래그를 비활성화하는 것보다 환경이 가능한 한 격리되고, 무엇보다도 설치가 시스템 Python이나 심지어 Poetry 자체와 충돌하지 않도록 해줍니다.\n\n```js\nFROM python:3.11-buster\n\nRUN pip install poetry==1.4.2\n\nENV POETRY_NO_INTERACTION=1 \\\n    POETRY_VIRTUALENVS_IN_PROJECT=1 \\\n    POETRY_VIRTUALENVS_CREATE=1 \\\n    POETRY_CACHE_DIR=/tmp/poetry_cache\n\nWORKDIR /app\n\nCOPY pyproject.toml poetry.lock ./\nCOPY annapurna ./annapurna\nRUN touch README.md\n\nRUN poetry install --without dev \u0026\u0026 rm -rf $POETRY_CACHE_DIR\n\nENTRYPOINT [\"poetry\", \"run\", \"python\", \"-m\", \"annapurna.main\"]\n```\n\n# 4. Installing dependencies before copying code 👏\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금까지 잘 진행되고 있지만,\nDocker 빌드가 여전히 매우 고통스러운 문제를 겪고 있어요: 코드를 수정할 때마다 의존성을 다시 설치해야 합니다! 이것은 우리가 코드를 COPY(이것이 Poetry가 프로젝트를 설치하는 데 필요한 것)하기 전에 RUN poetry install 명령을 실행하기 때문입니다. Docker 레이어 캐싱이 작동하는 방식 때문에 COPY 레이어가 무효화될 때마다 다음 레이어도 다시 빌드해야 합니다. 프로젝트가 점점 커질수록 코드 한 줄을 변경하더라도 매우 지루하고 빌드 시간이 길어질 수 있습니다.\n\n해답은 Poetry에 가상 환경을 빌드하는 데 필요한 최소한의 정보를 제공하고 나중에 코드베이스를 COPY 하는 것입니다. 이를 위해 --no-root 옵션을 사용하여 현재 프로젝트를 가상 환경에 설치하지 않도록 지시할 수 있어요.\n\n\nFROM python:3.11-buster\n\nRUN pip install poetry==1.4.2\n\nENV POETRY_NO_INTERACTION=1 \\\n    POETRY_VIRTUALENVS_IN_PROJECT=1 \\\n    POETRY_VIRTUALENVS_CREATE=1 \\\n    POETRY_CACHE_DIR=/tmp/poetry_cache\n\nWORKDIR /app\n\nCOPY pyproject.toml poetry.lock ./\nRUN touch README.md\n\nRUN poetry install --without dev --no-root \u0026\u0026 rm -rf $POETRY_CACHE_DIR\n\nCOPY annapurna ./annapurna\n\nRUN poetry install --without dev\n\nENTRYPOINT [\"poetry\", \"run\", \"python\", \"-m\", \"annapurna.main\"]\n\n\n이제 애플리케이션 코드를 수정해보세요. 마지막 3개의 레이어만 다시 계산되는 것을 볼 수 있어요. 빌드가 엄청나게 빨라졌죠! 🚀\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 가상 환경에서 프로젝트를 설치하려면 추가적인 실행할 `poetry install --without dev` 명령이 필요합니다. 이는 사용자 정의 스크립트를 설치하는 데 유용할 수 있습니다. 프로젝트에 따라 이 단계가 필요하지 않을 수도 있습니다. 어쨌든, 이미 프로젝트 종속성이 설치되어 있기 때문에 이 계층 실행은 매우 빠를 것입니다.\n\n# 5. 다중 단계 Docker 빌드 사용 🏃‍♀\n\n지금까지 빌드는 빠르지만 여전히 큰 Docker 이미지가 생성됩니다. 이 문제를 해결하기 위해 다중 단계 빌드를 사용할 수 있습니다. 최적화는 올바른 작업에 대해 올바른 베이스 이미지를 사용함으로써 달성됩니다:\n\n- Python buster는 개발 의존성이 포함된 큰 이미지이며, 이를 사용하여 가상 환경을 설치할 것입니다.\n- Python slim-buster는 Python을 실행하는 데 필요한 최소한의 종속성만 포함된 작은 이미지이며, 우리 애플리케이션을 실행하는 데 사용할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다단계 빌드를 통해 한 단계에서 다른 단계로 정보를 전달할 수 있습니다. 특히 구축 중인 가상 환경입니다. 주목해 주세요:\n\n- 실행 단계에는 심지어 Poetry가 설치되어 있지 않습니다. 사실 Python 응용 프로그램이 가상 환경이 구축된 후에 실행하는 데 불필요한 종속성이에요. 환경 변수 (예: VIRTUAL_ENV 변수)를 조정하여 Python이 올바른 가상 환경을 인식하도록 만들어주기만 하면 돼요.\n- 간단하게 말씀드리면, 장난감 프로젝트에는 필요 없으므로 두 번째 설치 단계 (RUN poetry install --without dev)를 제거했어요. 하지만 실행 이미지에 여전히 한 번의 명령어로 추가할 수 있어요: RUN pip install poetry \u0026\u0026 poetry install --without dev \u0026\u0026 pip uninstall poetry.\n\nDockerfile이 복잡해지면 새로운 빌드 백엔드인 Buildkit을 사용하는 것도 제안드려요. 빠르고 안전한 빌드를 원한다면 그것을 사용하는 게 좋아요.\n\n```js\nDOCKER_BUILDKIT=1 docker build --target=runtime .\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n# 빌더 이미지, 가상 환경을 구축하는 데 사용됨\r\nFROM python:3.11-buster as builder\r\n\r\nRUN pip install poetry==1.4.2\r\n\r\nENV POETRY_NO_INTERACTION=1 \\\r\n    POETRY_VIRTUALENVS_IN_PROJECT=1 \\\r\n    POETRY_VIRTUALENVS_CREATE=1 \\\r\n    POETRY_CACHE_DIR=/tmp/poetry_cache\r\n\r\nWORKDIR /app\r\n\r\nCOPY pyproject.toml poetry.lock ./\r\nRUN touch README.md\r\n\r\nRUN poetry install --without dev --no-root \u0026\u0026 rm -rf $POETRY_CACHE_DIR\r\n\r\n# 실행 이미지, 가상 환경만 실행하는 용도로 사용\r\nFROM python:3.11-slim-buster as runtime\r\n\r\nENV VIRTUAL_ENV=/app/.venv \\\r\n    PATH=\"/app/.venv/bin:$PATH\"\r\n\r\nCOPY --from=builder ${VIRTUAL_ENV} ${VIRTUAL_ENV}\r\n\r\nCOPY annapurna ./annapurna\r\n\r\nENTRYPOINT [\"python\", \"-m\", \"annapurna.main\"]\r\n\n\r\n결과는? 런타임 이미지가 6배나 작아졌어요! 6배나! ` 1.1 GB에서 170 MB로 줄었어요.\r\n\r\n# 6. Buildkit 캐시 마운트 ⛰\r\n\r\n이미 작은 Docker 이미지와 코드 변경 시 빠른 빌드를 얻었는데, 더 얻을 수 있는 게 있을까요? 음… 의존성이 변경되었을 때도 빠른 빌드를 얻을 수 있어요 😎\r\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 최종 팁은 다른 기능들과 비교했을 때 상대적으로 최근에 도입된 것이기 때문에 많은 사람들이 알지 못합니다. 이 기능은 Buildkit 캐시 마운트를 활용하며, 기본적으로 Buildkit에게 캐싱 목적으로 폴더를 마운트하고 관리하도록 지시합니다. 흥미로운 점은 이러한 캐시가 빌드 간에 지속될 것이라는 것입니다!\n\n이 기능을 Poetry 캐시와 연결하면 (이젠 왜 캐싱을 유지하길 원했는지 알겠죠?) 사실상 빌드할 때마다 의존성 캐시를 얻게 됩니다. 동일한 환경에서 여러 번 이미지를 빌드할 때 의존성 빌드 단계가 빠르게 완료될 것입니다.\n\nPoetry 캐시가 설치 후에 지워지지 않는 점에 유의해야 합니다. 이렇게 함으로써 캐시를 저장하고 빌드 간에 다시 사용할 수 있게 됩니다. 빌드된 이미지에 관리된 캐시를 영속화하지 않을 것이므로 (게다가 런타임 이미지도 아닙니다.) 이것은 괜찮은 접근입니다.\n\n```js\nFROM python:3.11-buster as builder\n\nRUN pip install poetry==1.4.2\n\nENV POETRY_NO_INTERACTION=1 \\\n    POETRY_VIRTUALENVS_IN_PROJECT=1 \\\n    POETRY_VIRTUALENVS_CREATE=1 \\\n    POETRY_CACHE_DIR=/tmp/poetry_cache\n\nWORKDIR /app\n\nCOPY pyproject.toml poetry.lock ./\nRUN touch README.md\n\nRUN --mount=type=cache,target=$POETRY_CACHE_DIR poetry install --without dev --no-root\n\nFROM python:3.11-slim-buster as runtime\n\nENV VIRTUAL_ENV=/app/.venv \\\n    PATH=\"/app/.venv/bin:$PATH\"\n\nCOPY --from=builder ${VIRTUAL_ENV} ${VIRTUAL_ENV}\n\nCOPY annapurna ./annapurna\n\nENTRYPOINT [\"python\", \"-m\", \"annapurna.main\"]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 최적화의 단점은 무엇일까요? 현재 Buildkit은 캐시 마운트가 매우 CI 친화적이지 않습니다. 왜냐하면 Buildkit은 캐시의 저장 위치를 제어할 수 없기 때문입니다. Buildkit 저장소에서 가장 투표를 많이 받은 오픈 GitHub 이슈라니 놀라운 일이네요 😄\n\n# 요약\n\n이미지를 몇 분 만에 1GB로 만드는 간단하지만 형편없는 Dockerfile을 최적화된 버전으로 변경하여 몇 초 만에 몇 백 MB의 이미지를 생성하는 방법을 살펴보았습니다. 모든 최적화는 주로 몇 가지 Docker 빌드 매니피스를 활용합니다:\n\n- 계층을 작게 유지하여 복사하고 설치하는 항목의 양을 최소화합니다.\n- Docker 레이어 캐싱을 활용하고 캐시 미스를 최대한 줄입니다.\n- 느리게 변경되는 것(프로젝트 의존성)은 빠르게 변경되는 것(애플리케이션 코드)보다 먼저 빌드해야 합니다.\n- Docker 다단계 빌드를 사용하여 런타임 이미지를 최대한 가볍게 만듭니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬 프로젝트를 Poetry로 관리할 때 이러한 원칙을 적용하는 방법을 안내드렸는데, 이와 유사한 원칙은 다른 종속성 관리자(PDM 등) 및 다른 언어에도 적용할 수 있습니다.\n\n빌드가 빨라지고 용량이 작아지는 것을 보고 기쁨의 눈물을 흘리시기를 바랍니다. 추가로 알고 계신 Docker 관련 팁이 있으면 댓글에 남겨주세요! 👋","ogImage":{"url":"/assets/img/2024-06-23-BlazingfastPythonDockerbuildswithPoetry_0.png"},"coverImage":"/assets/img/2024-06-23-BlazingfastPythonDockerbuildswithPoetry_0.png","tag":["Tech"],"readingTime":9},{"title":"저렴한 날씨 관측소와 기존 장비로 개인 DevOps 스타일 날씨 대시보드 만드는 방법","description":"","date":"2024-06-23 00:39","slug":"2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard","content":"\n\n# 최종 결과\n\n시각적으로 매력적인 부분부터 시작해 보겠습니다. 아마 여러분을 여기로 인도한 것이 이것일 것입니다. 여기 제 대시보드의 모습입니다...\n\n# 레이아웃\n\n내 홈랩에는 이를 가능하게 하기 위해 많은 부품들이 움직이고 있습니다. 여러분의 버전은 더 간단할 수 있습니다. 제 경우에는 이렇게 작동했습니다. 후속 섹션에서 각 구성 요소를 자세히 살펴보겠지만, 세부 사항에 들어가기 전에 10,000피트 상에서 시작하는 게 낫다고 생각했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_0.png\" /\u003e\n\n# 하드웨어\n\n여기에는 내 홈 네트워킹 장비를 제외한 내가 사용 중인 하드웨어가 있습니다. 이 프로젝트를 위해 명시적으로 구입한 것은 날씨 센서뿐이며, 그 외의 모든 것은 이미 가지고 있었습니다.\n\n- 날씨 센서 — WS2032 날씨 관측소\n$40~85 미국 달러, 사이트에 따라 다름. 저는 rtl_433 프로젝트를 발견했고 이 장치가 지원되고 있다는 이유로 이를 선택했습니다.\n- 라디오 수신기 — RTL-SDR USB 라디오 수신기\n$30 미국 달러, 아마존에서 구입. 날씨 관측소에서 433MHz 라디오 신호를 수신하기 위해 사용됩니다. 이전 프로젝트에서 이미 가지고 있던 것입니다.\n- Home Assistant를 실행할 장비 — Home Assistant Blue\n더 이상 판매되지 않지만 Home Assistant Yellow나 라즈베리 파이를 고려해보세요.\n- Grafana와 InfluxDB를 실행할 장비 — Synology NAS DSM 918+\n더 최신 모델이 있으며, 도커 컨테이너를 Home Assistant와 같은 하드웨어에서 실행할 수도 있습니다. NAS에서 이 두 가지를 실행했는데 NAS에 더 많은 저장 공간이 있었기 때문입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 날씨 관측소 설정하기\n\n![이미지](https://miro.medium.com/v2/resize:fit:1280/1*BzJX0ldpzm-RtlqcEJO9KQ.gif)\n\n이 단계는 가장 쉽게 진행된 것일지도 모릅니다. WS2032의 조립은 두 개의 AA 건전지와 몇 개의 나사로 꽤 직관적이었습니다. 가격 대비, 홀 효과 센서로 보이는 것들이 사용되어 남풍과 해풍 구성 요소의 위치와 회전 속도를 감지하는 데 사용됩니다. 온도 및 습도 센서는 건전지를 보관하는 중앙 코어에 내장되어 있으며, 이 조립은 직사광선이 직접 비치지 않도록 차단되어 있으며 층층이 쌓인 린 디자인의 열로 냉각됩니다. 그들은 중앙 코어가 물에 젖지 않으면서 여전히 주변의 레이드를 얻을 수 있게하는 층층이 쌓인 디자인으로 보호합니다. 이 설정의 가장 어려운 부분은 정중앙 방향이 위에 나열되어 있는 바람 피리와 일치시키는 것이었습니다. 그러나 장치에서 오는 읽기를 본 후, 정밀도가 45º로 제한되어 있기 때문에 나침반과의 정렬은 매우 용서되는 것 같습니다. WS2032에는 실내용 LCD 표시 장치가 함께 제공되며, 이 장치를 통해 센서가 작동하고 대략적으로 정확한 데이터를 제공하는지 확인할 수 있었습니다.\n\n# 홈 어시스턴트 설정하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nHA(Home Assistant)의 전체 설정 튜토리얼은 안내하지 않겠어요. 이미 시작하는 데 도움이 되는 많은 좋은 자료들이 있거든요. 이 섹션에서 다룰 내용은 이미 구동 중인 Home Assistant 인스턴스에 필요한 변경 사항들이에요.\n\n## 하지만, RTL-SDR에 대한 간단한 소개부터\n\n날씨 관측소가 설치되어 데이터를 전송하기 시작했으니, 해당 데이터를 수신할 무언가를 설정할 차례입니다. rtl_433은 여러 가지 센서로부터의 데이터를 파싱하기 위해 만들어진 오픈 소스 프로젝트로, 가장 흔한 주파수인 433 MHz를 통해 데이터를 송수신하는 RF(라디오 주파수) 신호들을 해석합니다. 기타 주파수도 지원합니다.\n\nRF를 사용하는 장치들은 Bluetooth, WiFi, ZigBee, Z-Wave, 또는 Thread 대신 사용되며, 종종 보다 저렴하거나 오래되어 있으며 초기에는 최신 스마트 홈에 통합되도록 설계된 것은 아닐 수 있습니다. 가스 또는 수도계, 누수 탐지기, 심지어 자동차의 타이어 압력 센서와 같은 것들이 rtl_433을 사용하여 감지 및 파싱될 수 있습니다. rtl_433는 주로 여러 가지 USB 라디오 수신기인 소프트웨어 정의 라디오(SDR)를 사용하도록 작성되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n디지털 TV의 발명으로 하드웨어를 디코딩하는 저렴한 칩셋이 등장했습니다. 그 중 하나인 RealTek의 RTL2832U (일반적으로 RTL로 줄여짐)은 여러 무선 주파수를 서비스할 수 있는 해킹이 가능했고, 디지털 무전기 해커들은 컴퓨터로 경찰 및 공항 대역과 같은 것들을 수신할 수 있었고 그렇게 RTL-SDR 운동이 시작되었습니다.\n\n그런 이야기가 우리를 rtl_433로 이끕니다. 이 프로젝트는 RF 신호를 수신하고 그 데이터를 구문 분석하는 것을 목표로 하며, 그중 WS2032 날씨 관측소를 포함합니다.\n\n## rtl_433 설정 방법\n\n만약 이미 Home Assistant가 실행 중이라면 - 특히 Home Assistant OS 배포가 가능케 하는 환경에서는 \"애드온\"이라 불리는 Docker 컨테이너의 다른 이름 이 커뮤니티에서는 - RF 장치를 Home Assistant로 쉽게 가져오는 방법은 세 가지 추가 기능을 실행하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Mosquitto - 가장 간단한 설정은 인기있는 MQTT 브로커인 이 공식 애드온을 사용하는 것입니다. 이 애드온을 사용하면 다른 두 애드온이 이미 이를 사용하도록 구성되어 있습니다. 그렇지 않으면 기존의 MQTT 브로커를 가리키도록 두 다른 애드온을 사용자 정의해야 합니다. MQTT 설명은 이 문서의 범위를 벗어납니다만, TL;DR은 이것이 사물 인터넷(IoT) 장치들에서 널리 사용되는 메시징 플랫폼이라는 것입니다. \n- rtl_433 - 이 애드온은 RTL-SDR 장치와 USB를 통해 연결하고 RF 데이터를 감지하고 파싱하여 MQTT 메시지로 변환한 후 해당 메시지를 브로커의 특정 주제로 보내는 역할을 합니다. 이는 표준적인 애드온이 아니기 때문에 제 인스턴스에이 애드온을 추가하기 위해서는 먼저 GitHub 사용자 pbkhrv의 rtl_433 애드온 저장소를 추가해야 했습니다. 해당 저장소의 README에는 설치 방법이 포함되어 있습니다. \n- rtl_433 Home Assistant MQTT Auto Discovery - 기본적으로 Home Assistant에서 MQTT 통합을 켰더라도 모든 MQTT 메시지를 자동으로 읽고 스마트 홈 장치로 전환하지는 않습니다. 하지만 Home Assistant는 스마트 장치에 의해 Home Assistant 전용으로 사용되는 특별한 MQTT 메시지를 지원하여 이를 자동으로 Home Assistant에 추가하여 제어할 수 있습니다. 이 애드온은 rtl_433 애드온에서 오는 MQTT 메시지를 감지하고 MQTT를 통해 Home Assistant에 자동 발견 메시지를 보내는 역할을 합니다. 이 애드온은 앞서 구성한 전체 rtl_433 애드온 저장소의 일부로 제공됩니다. 마지막 단계는 이 저장소를 사용하여 애드온을 설치하는 것뿐입니다. 헷갈리셨나요? HA에 애드온 저장소를 추가하는 것은 설치할 수 있는 새로운 애드온 인덱스를 추가하는 것과 같습니다. Home Assistant에서 사용 가능한 애드온으로 이제 설치해야 합니다.\n\n여기서 마지막 단계는 이미 하지 않았다면 Home Assistant와 MQTT 통합을 활성화하고 Mosquitto 애드온을 가리키도록 하는 것입니다. Mosquitto 애드온의 README에서 이 설정에 대해 다루고 있지만, 명시적으로 언급하고자 했습니다. \n\n이 시점에서 Home Assistant로 데이터가 흘러들어가고 있어야 합니다. 개발자 도구 패널에 들어가서 States 탭에서 ws2032를 검색해보세요. 다음과 같은 내용을 보게 될 것입니다(단, 이름은 자세하고 \"_mph\" 엔티티는 제가 직접 사용자 정의했습니다). \n\n\u003cimg src=\"/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 엔티티 사용자 정의\n\n위 예시에서 보듯이, 배터리 읽기가 아마도 rtl_433 컨테이너에 의해 자동으로 발견되는 것 중 유사한 것 이외에는 여러분이 볼 수 있는 것과 가장 근접할 것입니다. HA 대시보드에 엔티티를 추가할 때 예쁘게 꾸미기 위해 각 엔티티로 이동하고 친숙한 이름 및 아이콘을 사용자 정의했습니다. 이렇게 하면 번거롭지 않게 카드에 엔티티를 빠르게 추가할 수 있습니다.\n\n다음은 이러한 사용자 정의가 적용된 내 HA 대시보드의 전형적인 카드입니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_2.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWS2032로부터 나온 풍속과 돌풍 속도 측정값은 km/h로 되어 있는데, 저는 미국인이라 mph로 변환하여 표시하고 싶었습니다. 따라서 그들의 값을 영미 단위로 변환하는 두 개의 템플릿 엔티티를 만들었습니다. 또한 풍향 측정값을 도에서 기본 나침반 방향으로 변환하는 세 번째 엔티티도 만들었습니다.\n\n## 커스텀 HA 대시보드 및 카드\n\nInfluxDB와 Grafana에 착수하기 전에, 이제 수집된 데이터를 사용할 수 있도록 Home Assistant를 설정했습니다. 몇 가지 예시를 보여드리겠습니다:\n\n이젠 제가 흥미를 느끼기 시작했습니다. 더 알고 싶어졌죠...\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 홈 어시스턴트의 러블레이스 프론트엔드가 처리할 수 있는 방법 이상으로 데이터를 슬라이스합니다.\n- 장기 트렌드를 분석하기 위해 데이터를 영구히 보관합니다.\n\n그래서 나는 가능한 한 오랫동안 데이터를 저장할 수 있도록 이 모든 데이터를 기록하기 위해 InfluxDB를 설정하는 시간이 된 것을 깨닫게 되었고, Grafana를 통해 모두 시각화하기로 했습니다.\n\n# InfluxDB 및 Grafana 설정\n\n가장 빠르게 시작하려면 InfluxDB를 홈 어시스턴트 애드온으로 설치하고 Grafana를 홈 어시스턴트 애드온으로 설치할 수 있습니다. 나는 Synology NAS에서 두 가지를 모두 실행하고 있고, 이 글을 쓰는 시점에서 InfluxDB 2.5.1 및 Grafana 9.2.6을 Docker Hub에서 제공하는 공식 Docker 이미지를 사용하여 도커 컨테이너로 실행하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nInfluxDB를 실행한 후에 집을 나타내는 조직과 Home Assistant의 데이터를 보관할 버킷을 만들었어요. 또한 Home Assistant가 사용할 API 토큰 하나와 Grafana가 사용할 다른 API 토큰 두 개를 생성했어요.\n\n## Home Assistant를 InfluxDB에 연결하기\n\nHome Assistant에는 모든 이벤트를 InfluxDB로 보내는 기본 지원이 있어요. 그래서 날씨 대시보드를 만들 뿐만 아니라 Grafana에서 액세스할 수 있는 많은 데이터도 있을 거예요. 이 이벤트 흐름을 HA에서 InfluxDB로 활성화하려면 Home Assistant의 configuration.yaml 파일에 조금의 YAML을 추가하세요.\n\n```js\ninfluxdb:\n  api_version: 2\n  ssl: false\n  host: nas.iot.jaxzin.com\n  port: 8086\n  token: !secret influxdb_token\n  organization: 8d2a3be3fdc94fa2\n  bucket: fallen-leaf\n  tags:\n    source: HA\n  tags_attributes:\n    - friendly_name\n  default_measurement: units\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## InfluxDB를 Grafana에 데이터 소스로 추가하기\n\n저는 Flux 쿼리 언어를 사용하고 싶었는데, 초기 조사 결과로 알 수 있었듯이 강력한 함수형 언어입니다. 다음 섹션에서 Flux에 대해 자세히 살펴보겠습니다.\n\n## Wind Rose 플러그인 설치\n\n저는 기본 Grafana 설치에 포함되지 않았지만 꼭 필요했던 시각화 유형인 바람 장미를 사용하고 싶었습니다. Grafana에는 몇 가지 바람 장미 플러그인이 있지만, 저는 spectraphilic의 windrose 플러그인을 사용하기로 했습니다. 설치 지침은 README에 있으며, Grafana Docker 지침에는 사용자 정의 플러그인을 추가하는 방법이 설명되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Dashboard Image](/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_3.png)\n\n# 대시보드 만들기\n\n이제 재미있고 약간 압도되는 부분, 커스텀 Grafana 대시보드를 만드는 것인데, 이는 Flux를 배우고 원하는 모습을 어떻게 구현할지 찾기 위해 많이 구글링하는 과정이 필요합니다.\n\n## 바람의 장미\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n행복한 소식입니다! spectraphilic이 Grafana 플러그인의 README에 Flux 예제를 포함해 주었어요. 그래서 바람 장미를 위한 Flux 쿼리 작성에 빠르게 시작할 수 있었고 효과적으로 진행했어요. 이 예제에서는 WS2032에서 풍향...\\_wd 및 풍속...\\_ws 데이터를 결합하는 방법을 보여줍니다.\n\n위 코드는 \"fallen-leaf\" 버킷에서 \"entity_id\"가 \"ws2032_28817_wd\"이거나 \"ws2032_28817_ws\"인 필드를 가진 데이터 중 \"value\" 필드를 가진 데이터를 선택합니다. 선택한 데이터를 ${period} 주기로 평균을 계산하고 결과 값을 동일한 타임스탬프를 기준으로 row에 배치합니다. 그리고 두 값이 모두 있는 행만 남기고, \"ws2032_28817_wd\" 컬럼을 \"direction\", \"ws2032_28817_ws\" 컬럼을 \"speedKmps\"로 이름을 변경합니다. 속도를 km/s로 변환하고, 필요한 열만 남기며, 각 창에 대해 첫 번째 행을 샘플링합니다.\n\n결과는 시간, 방향 및 속도 세 가지 열로 구성된 데이터 테이블입니다. 바람 장미 시각화는 이 데이터를 사용하여 속도를 방향별로 묶어낸 후, WS2032의 해상도가 8개 방향이므로 장미를 8개의 \"케이크 조각\"만 사용하도록 구성했습니다.\n\n이미지는 개인용 DevOps 스타일 날씨 대시보드로 저렴한 기상 관측소와 이미 있는 물품을 활용한 경험을 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 통계 기간을 위한 대시보드 변수 추가\n\n다른 시각화로 넘어가기 전에, 데이터의 다른 범위를 선택하는 것보다 더 많은 유연성을 원했어요. 바람 데이터는 정말 소음이 많기 때문에 선택된 시간 범위 내에서 샘플링 기간을 쉽게 변경할 수도 있었으면 좋겠어요. 이 샘플링 기간은 평균, 최대, 최소 또는 백분위 등의 통계를 계산할 때 사용될 거예요. 그래서 바람 속도나 방향을 시간별 또는 일별로 나누어 볼 수도 있겠죠. 이를 수행하기 위해 Window Period를 위한 사용자 정의 변수를 대시보드에 추가해야 했어요. 나중의 Flux 쿼리에서 $'period'로 참조되는 것을 보게 될 거예요.\n\n## 바람 속도를 열지도로 표현\n\n한동안 바람 속도 기록의 다양한 시각화를 고민했어요. 한 차트에 돌풍과 바람 속도를 보여주고 싶었고, 속도의 최소, 평균 및 최대 라인을 사용하여 변동 속도를 보다 잘 보여주기 위해 이 시각화 결과물에 결정했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 태그를 Markdown 형식으로 변경하십시오.\n\n\n\u003cimg src=\"/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_5.png\" /\u003e\n\n이 효과를 얻으려면 기본적으로 5 세트의 데이터가 필요합니다. 그래프아나와 Flux 쿼리를 사용하면 5개의 쿼리를 실행하는 것만큼 간단하지만(효율적이지는 않을 수 있습니다).\n\n```js\n// 풍속: 최대, 평균, 최소\nfrom(bucket: \"fallen-leaf\")\n  |\u003e range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |\u003e filter(fn: (r) =\u003e r[\"entity_id\"] == \"ws2032_28817_ws_mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_measurement\"] == \"mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_field\"] == \"value\")\n  |\u003e keep(columns: [\"_time\",\"_value\", \"value\", \"_field\"])\n  |\u003e set(key:\"_field\", value:\"max\")\n  |\u003e aggregateWindow(every: ${period}, fn: max, createEmpty: true)\n  |\u003e yield(name: \"max\")\n\nfrom(bucket: \"fallen-leaf\")\n  |\u003e range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |\u003e filter(fn: (r) =\u003e r[\"entity_id\"] == \"ws2032_28817_ws_mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_measurement\"] == \"mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_field\"] == \"value\")\n  |\u003e keep(columns: [\"_time\",\"_value\", \"value\", \"_field\"])\n  |\u003e set(key:\"_field\", value:\"mean\")\n  |\u003e aggregateWindow(every: ${period}, fn: mean, createEmpty: true)\n  |\u003e yield(name: \"mean\")\n\nfrom(bucket: \"fallen-leaf\")\n  |\u003e range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |\u003e filter(fn: (r) =\u003e r[\"entity_id\"] == \"ws2032_28817_ws_mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_measurement\"] == \"mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_field\"] == \"value\")\n  |\u003e keep(columns: [\"_time\",\"_value\", \"value\", \"_field\"])\n  |\u003e set(key:\"_field\", value:\"min\")\n  |\u003e aggregateWindow(every: ${period}, fn: min, createEmpty: true)\n  |\u003e yield(name: \"min\")\n\n// 돌풍 속도: 최대 및 평균\nfrom(bucket: \"fallen-leaf\")\n  |\u003e range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |\u003e filter(fn: (r) =\u003e r[\"entity_id\"] == \"ws2032_28817_gs_mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_measurement\"] == \"mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_field\"] == \"value\")\n  |\u003e keep(columns: [\"_time\",\"_value\", \"value\", \"_field\"])\n  |\u003e set(key:\"_field\", value:\"max (gust)\")\n  |\u003e aggregateWindow(every: ${period}, fn: max, createEmpty: true)\n  |\u003e yield(name: \"max_g\")\n\nfrom(bucket: \"fallen-leaf\")\n  |\u003e range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |\u003e filter(fn: (r) =\u003e r[\"entity_id\"] == \"ws2032_28817_gs_mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_measurement\"] == \"mph\")\n  |\u003e filter(fn: (r) =\u003e r[\"_field\"] == \"value\")\n  |\u003e keep(columns: [\"_time\",\"_value\", \"value\", \"_field\"])\n  |\u003e set(key:\"_field\", value:\"mean (gust)\")\n  |\u003e aggregateWindow(every: ${period}, fn: mean, createEmpty: true)\n  |\u003e yield(name: \"mean_g\")\n```\n\n그러나 여전히 마음에 들지 않았습니다. 노이즈가 있는 데이터를 시각화하는 것 같지 않았습니다. 따라서 히트맵 시각화를 시도해보았고, 풍속의 분산을 보여주면서도 풍속이 대부분 어디에 집중되어 있는지 쉽게 파악할 수 있는 것으로 생각됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_6.png)\n\n```js\nfrom(bucket: \"fallen-leaf\")\n  |\u003e range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |\u003e filter(fn: (r) =\u003e r[\"entity_id\"] == \"ws2032_28817_ws\")\n  |\u003e filter(fn: (r) =\u003e r[\"_measurement\"] == \"km/h\")\n  |\u003e filter(fn: (r) =\u003e r[\"_field\"] == \"value\")\n  |\u003e map(fn: (r) =\u003e ({r with _value: r._value * 0.618}))\n  |\u003e keep(columns: [\"_time\",\"_value\", \"value\", \"_field\"])\n```\n\n차트 하나에 바람과 돌풍 속도를 함께 표시할 수 없어서 두 개를 함께 유지했어요. 더 나은 해결책을 찾을 때까지는 이렇게 유지할 거예요.\n\n## 퍼센타일을 사용한 윈드 방향의 의사 토폴로지 차트\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n바람 방향 데이터가 정말 소란스럽기 때문에 통계의 힘을 활용하여 소음 속에서 신호를 찾을 수 있는 시각화를 만들어 보고 싶었습니다. 그래서 각 백분위를 각각의 선으로 그려볼까? 데이터의 방향을 보여주면서 분산을 더 잘 파악할 수 있을까? (참고로, 이것은 위의 히트맵을 활용하기 전에 생각한 것으로, 이 곳에도 좋은 해결책일 수 있습니다).\n\n하지만 각 백분위에 대해 21가지 다른 쿼리를 입력하고 싶지 않았습니다. 각 백분위를 계산하는 동적 Flux 쿼리를 만들 수 있을까요? 이 쿼리를 위해 도움을 요청하기 위해 Flux 포럼을 찾아다니던 중이었고, 최종 쿼리는 다음과 같습니다.\n\n```js\nimport \"experimental/array\"\n\n// 주어진 범위 내 모든 풍향 데이터 가져오기\n// 이는 data라는 함수를 정의하는 것으로, 나중에 여러 번 호출할 것입니다.\ndata = () =\u003e from(bucket: \"fallen-leaf\")\n  |\u003e range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |\u003e filter(fn: (r) =\u003e r[\"entity_id\"] == \"ws2032_28817_wd\")\n  |\u003e filter(fn: (r) =\u003e r[\"_field\"] == \"value\")\n  |\u003e filter(fn: (r) =\u003e r[\"_measurement\"] == \"°\")\n  |\u003e map(fn: (r) =\u003e ({r with _value: r._value * 400.0/360.0})) // 360을 400으로 매핑하여 Grafana에서 기본 방향이 y축 레이블로 표시될 수 있도록 함\n  |\u003e aggregateWindow( // 8방위 방향은 그다지 세분화되지 않습니다. 데이터를 세분화하고 평균을 구합시다.\n    every: duration(v: int(v: ${period}) / 12),\n    fn: mean\n  )\n\n// 계산하려는 백분위\np = [1,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,99]\n\n// 함수 'q' 정의: 'data'를 호출하고 한 백분위 'v'를 계산함\nq = (v) =\u003e {\n  d = data ()\n    |\u003e aggregateWindow(\n        column: \"_value\",\n        every: ${period},\n        fn: (column, tables=\u003c-) =\u003e tables |\u003e quantile(q: float(v: v)/100.0, column: column),\n    )\n    |\u003e set(key: \"_field\", value: \"p${if v \u003c 10 then \"0\" else \"\"}${v}\")\n  return d\n}\n\n// 원하는 각 백분위에 대해 'q'를 호출하고 결과를 연결함\nunion(tables:  p \n  |\u003e array.map(fn: (x) =\u003e (  q(v: x))))\n  |\u003e keep(columns: [\"_time\", \"_field\", \"_value\"])\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n와우, 함수형 프로그래밍 언어는 정말 강력할 수 있죠! 이 구문을 좋아하고 몇 줄의 코드로 21개의 데이터 세트를 가져올 수 있었던 것이 정말 좋았어요. influxData의 Jay Clifford에게 이 쿼리를 작성하는 데 도움을 준 것에 대해 큰 감사를 전해요.\n\n## 색상 및 스타일 사용자 정의\n\n이제 데이터를 가졌지만 기본적으로 Grafana Time Series 시각화는 무지개 색상으로 된 선으로 표시돼요. 중앙값(즉, p50)을 더 밝은 실선으로 강조하고 다른 백분위수는 대시 선으로 표시하고 싶었어요. 또한 중앙값을 기준으로 위와 아래를 강조하기 위해 일부 배경을 채우고 싶었어요.\n\n이러한 사용자 정의의 해답은 Grafana 오버라이드입니다. 두 개의 선 사이를 채우려면, 데이터 시리즈의 더 높은 부분에서  \"아래로 채우기\"라는 새 속성 오버라이드를 선택하고 낮은 데이터 시리즈를 선택하세요. 이제 시각화에는 두 시리즈 사이에 동적 배경 채우기가 포함될 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 table 태그를 Markdown 형식으로 변경했고, 이번에는 그 위에 정규식 오버라이드를 사용하여 필드 이름이 p[0-4]\\d(즉, p01-p49)인 줄은 보라색으로, p[5-9]\\d|p5[1-9] (즉, p51-p99)인 줄은 초록색으로 칠하도록 설정했습니다.\n\n중앙값을 강조하기 위해 줄을 기본적으로 점선으로 설정하고, p50 줄에 대한 오버라이드를 추가하여 선 스타일, 색상 및 두께를 사용자 정의했어요.\n\n## 각도 대신 나침반 방향으로 생각하기\n\n여기서 작업이 거의 끝났지만, 측정값 및 y-축이 여전히 각도로 되어 있었습니다. 그러나 바람 방향을 고려할 때 나는 기본 (N, E, S, W) 및 중간 (NE, SE, SW, NW) 방향으로 생각하고 있었기 때문에 시각화가 그것을 반영하도록 변경하고 싶었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 값 매핑\n\n시계열 시각화는 숫자 값을 다른 값으로 매핑할 수 있는 기능이 있습니다. 이는 기본적으로 기본 및 서수 방향과 같은 간단한 텍스트를 포함합니다. 특정 값을 매핑하거나 범위 또는 정규식을 사용한 매핑의 더 복잡한 정의를 사용할 수 있습니다. 이 매핑은 데이터 포인트 위에 마우스를 올렸을 때 툴팁에 표시되는 값을 영향을 미칩니다. 또한 y-축에 표시되는 값에도 영향을 줍니다. 그래서 나는 각도 범위를 나침반 방향으로 매핑했습니다.\n\n## 임계값\n\n다른 것 중에서 내가 주목한 것은 x/y 그래프에서 카디널 방향과 같은 방향과 가까운 값이 어디에 있는지 시각적으로 판단하기 어려웠다는 점이었습니다. 그래서 나는 이 네 가지 방향의 각각에 수평 점선 형태의 지시자를 그래프에 추가하기로 했습니다. 이러한 유형의 수평 지시자 추가는 임계값이라고 하며, 그냥 수평선을 추가하는 것보다 강력합니다. 임계값은 값에 따라 선의 색상을 지정하거나 배경을 채울 수 있습니다. 따라서 나는 카디널 방향에 대한 임계값을 추가하여 선과 배경을 표시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터 변환을 통해 y-축 레이블 수정하기\n\n(Grafana의 기대에 맞추기 위해)\n\n모든 것이 잘 보였지만, y-축에 360º의 최대값을 추가했을 때 N, E, S, W의 임계값이 명확하게 표시되지 않았어요. 여러 포럼을 찾아보다가, 90º, 180º, 270º 및 360º과 같은 이 비슷하지만 끝나지 않는 숫자들을 y-축에 레이블링하는 것이 어려울 것이라고 점점 희망을 잃고 있었죠. 100º, 200º, 300º 등의 레이블링을 하려는 것 같아요. 그래서 영감이 스쳤어요. 이미 표시된 값을 매핑하고 있었는데, 원래의 각도 값을 Grafana의 예상에 맞게 조정하고 빠른 조치로 문제를 해결할 수 있을까요? 그래서 이 코드 라인이 존재하는 이유입니다.\n\n```js\n...\n|\u003e map(fn: (r) =\u003e ({r with _value: r._value * 400.0/360.0}))\n...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN, E, S, W를 0, 100, 200, 300 및 400(N)으로 다시 매핑하면 y-축이 기본적으로 언급하는 기준치를 나타낼 수 있도록 설정할 수 있었어요. 데이터가 이제 더이상 0º에서 360º까지가 아니어도 스크린 표시에는 큰 영향이 없어요. 하지만 생 데이터를 살펴보면 360º 이상의 값이 보이면 조금 이상할 수도 있어요.\n\n# 다음 단계는?\n\n- 바람 데이터와 그릴 온도 상관 시키기\n그래서 날씨 관측소를 산 이유가 있어요! 추수감사절 때 그릴에 칠한 칠면조를 연기로 익혔는데 바람이 그릴 온도에 정말 영향을 미친다는 것을 알았어요 (내 MEATER+로 Home Assistant를 통해 추적했어요). 그래서 호기심이 생겨 날씨 관측소를 샀어요. 역사적인 그릴 온도와 바람 속도를 상호 참조하는 대시보드를 만들고 싶어요.\n- 강우 센서 추가 및 습도 센서 수리\n이제 더 많은 데이터를 원해요! 그리고 습도 센서가 때때로 오작동하는 것 같아서 더 신뢰할 수 있게 할 수 있는지 조사해야 해요.\n- 광량 센서 추가\n얼마 전부터 실외 밝기를 사용해서 실내 조명을 조절하고 싶었어요. 온도 시각화에 태양 고도를 추가한 것처럼, 대쉬보드에서 광량도 흥미로운 데이터 포인트일 수 있다고 상상할 수 있어요. 내 집의 조명 개수와 야외 광량 사이에 상관 관계가 있을까요? 아마도 있지만 증거를 보고 싶어요.\n- 계속 조정하기!\n끊임없는 실험의 공간이 될 것 같아요.\n- 이 프로젝트에서 배운 것을 내 직장에 적용하기\n나는 DevOps 팀의 엔지니어 관리자로 일하는 날 개인 자동화 프로젝트들을 많이 활용해서 무언가 새로운 것을 배우는 테스트베드로 사용해요. Grafana의 강력함과 InfluxDB와 같은 데이터 소스를 추상화하지 않고 각각의 쿼리 언어를 활용하는 점이 정말 강력하다는 것을 알게 되었어요.","ogImage":{"url":"/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_0.png"},"coverImage":"/assets/img/2024-06-23-HowIturnedacheapweatherstationandawholelotofthingsIalreadyownintoapersonalDevOps-styleweatherdashboard_0.png","tag":["Tech"],"readingTime":17},{"title":"GitLab에서 Docker를 사용하여 Playwright 테스트 실행하는 방법","description":"","date":"2024-06-23 00:38","slug":"2024-06-23-RunningPlaywrighttestswithDockeronGitLab","content":"\n\n![이미지](/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_0.png)\n\n안녕하세요 여러분, 이 글에서는 도커를 사용하여 Playwright를 설치하고 GitLab에서 실행하는 방법을 설명하겠습니다. Trendyol 프로젝트의 설치 과정 중에 직면한 일부 어려움들도 함께 공유할 것입니다.\n\n시작하기 전에 Playwright에 대한 기본 정보와 프로젝트 설치 단계에 대한 기본 사항은 생략할 예정이니 참고해 주세요.\n\n# 문제점\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시작하기 전에, 왜 우리가 도커 이미지에서 테스트를 실행하는지 설명하는 것이 중요합니다. 저희 프로젝트에서는 브랜치별 테스팅을 진행하고 있는데요, 그것은 스프린트 동안 개발 중인 기능 브랜치에 대해 테스트를 실행한다는 것을 의미합니다. 이 기능 브랜치는 테스트 프로젝트 이미지와 함께 풀되어 도커 컨테이너에서 실행되며, 그 후 해당 실행 애플리케이션에 대해 테스트를 실행합니다. 아래에 프로세스를 설명하는 스크린샷과 플로우차트를 포함하였습니다.\n\n![이미지 링크](/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_1.png)\n\n위의 이미지에서 보듯이, 테스트 자동화 단계에서 개발된 브랜치를 풀고, 개발 중인 격리 환경에서 해당 애플리케이션을 실행합니다. 그런 다음 실행 중인 애플리케이션에 대해 테스트를 수행합니다. 이 새로운 개발이 아무 문제를 발생시키지 않았다고 확신을 갖게 되면, 병합 요청을 올리는 과정으로 나아갑니다.\n\n![이미지 링크](/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 설치\n\n처음에 언급했듯이 설치 과정은 건너뜁니다. 도움이 필요하면 이 문서를 참조해 주세요. Playwright를 설치한 후에는 프로젝트가 다음과 같이 보일 것입니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_3.png\" /\u003e\n\n로컬에서 테스트를 실행하려면 컴퓨터에 Docker를 설치해야 합니다. 이 링크에서 설치할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 프로젝트에 Docker 추가하기\n\n이를 실현하기 위해서는 프로젝트에 Dockerfile을 포함시키고 그 단계들을 구성해야 합니다.\n\n![Docker 이미지](/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_4.png)\n\n```js\nFROM mcr.microsoft.com/playwright:v1.44.0-jammy\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci\n\nCOPY . .\n\nCMD [\"npx\", \"playwright\", \"test\"]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사의 대상은 Docker에 대해 처음 접하는 사람부터 Docker 전문가까지 다양합니다. 모두가 명확히 이해할 수 있도록 한 줄씩 설명하겠습니다.\n\n- 먼저, 우리는 테스트를 실행하는 데 필요한 모든 것을 포함하는 공식 Playwright 이미지를 가져옵니다.\n- 프로젝트를 설치하기 위해 컨테이너 내부에 디렉토리를 만듭니다.\n- 작업 디렉토리에 package.json 및 package-lock.json 파일을 복사하여 프로젝트를 올바르게 초기화합니다.\n- 필요한 파일을 복사한 후, \"npm ci\"를 실행하여 프로젝트를 컨테이너에 설치합니다.\n- 프로젝트를 설치한 후에는 테스트 파일, 구성 파일 등 추가 파일을 컨테이너에 복사합니다.\n- 마지막 단계는 Playwright 테스트를 실행하는 명령을 실행하는 것입니다.\n\n참고: Docker에서 npm 패키지를 사용할 때 다른 예제에서 발견할 수 있는 것과 달리 \"npm install\" 대신 \"npm ci\"를 사용하는 것이 권장됩니다. 일부 불필요한 단계를 건너뛸 수 있기 때문입니다.\n\n# 로컬에서 테스트 실행\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로컬에서 테스트하려면 먼저 Docker를 시작하고 프로젝트 루트에 생성한 도커 파일을 빌드해야 합니다. VS Code 터미널을 사용하여 다음 명령을 사용하여 도커 파일을 빌드합니다. \"docker build -t playwright-demo .\"\n\n![이미지](/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_5.png)\n\n참고: Playwright의 퀵스타트 폴더 \"tests-examples\"를 제거했습니다. 불필요한 테스트 예제 실행을 피하기 위함입니다.\n\n이미지가 성공적으로 빌드되면 \"docker run -it — rm playwright-demo\"으로 실행 준비가 완료됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_6.png\" /\u003e\n\n프로젝트에 테스트를 추가하여 프로세스를 가속화했습니다. 지금 확인해보면 테스트 실행이 완료된 것을 확인할 수 있습니다.\n\n# Gitlab-ci.yml 구성\n\n프로젝트에 gitlab-ci.yml 파일을 추가하고 이를 구성하여 파이프라인에서 테스트를 실행해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```YAML\n기본값:\n  이미지: docker:24.0.5\n  서비스:\n    - docker:24.0.5-dind\n\n변수:\n  DOCKER_HOST: tcp://docker:2376\n  DOCKER_TLS_CERTDIR: \"/certs\"\n  DOCKER_DRIVER: overlay2\n  DOCKER_BUILDKIT: '1'\n  FF_USE_FASTZIP: \"true\"\n  ARTIFACT_COMPRESSION_LEVEL: \"fast\"\n  CACHE_COMPRESSION_LEVEL: \"fast\"\n\n단계:\n  - 빌드\n  - 테스트\n\n빌드:\n  stage: 빌드\n  before_script:\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login $CI_REGISTRY -u $CI_REGISTRY_USER --password-stdin\n  script:\n    - docker pull $CI_REGISTRY_IMAGE:latest || true\n    - docker build \n      --cache-from $CI_REGISTRY_IMAGE:latest\n      --tag $CI_REGISTRY_IMAGE:latest \n      --build-arg BUILDKIT_INLINE_CACHE=1 \n      \".\"\n    - docker push $CI_REGISTRY_IMAGE:latest\n\n테스트:\n  stage: 테스트\n  before_script:\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login $CI_REGISTRY -u $CI_REGISTRY_USER --password-stdin\n    - mkdir playwright-report\n    - mkdir test-results\n  script:\n    - docker run --ipc=host --name playwright-tests $CI_REGISTRY_IMAGE:latest\n  after_script:\n    - docker cp playwright-tests:app/playwright-report/. playwright-report\n    - docker cp playwright-tests:app/test-results/. test-results\n  allow_failure: false\n  artifacts:\n    when: 항상\n    paths:\n      - playwright-report\n      - test-results\n    expire_in: 1 주\n``` \n\n우리는 Docker 이미지를 정의합니다. 이 섹션 끝에서 몇 가지 중요한 사항을 주목해야 합니다.\n\n변수 섹션에서는 주로 Docker 및 그 캐싱 메커니즘과 관련된 변수를 정의하여 이미지를 가져오는 시간을 단축하는 데 도움이 됩니다.\n\n파이프라인의 초기 단계에서는 \"before_script\" 섹션 내에서 docker에 로그인하여 이미지를 가져옵니다. Gitlab 이미지 레지스트리에 이미지가 있는 경우에는 캐시에서 가져옵니다. 그렇지 않으면 로컬로 빌드한 다음 미래 빌드를 가속화하기 위해 이미지 레지스트리에 푸시합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테스트 단계에서는 Docker에 로그인하고 우리의 테스트 결과를 Docker 이미지에서 Gitlab 아티팩트로 전송하기 위해 두 개의 폴더를 생성합니다. 스크립트 섹션에서는 우리의 이미지를 실행하고, 마지막으로 아티팩트 섹션에서 테스트 폴더의 경로를 지정합니다.\n\n중요 참고 사항: 프로젝트 설정 중에 Docker 버전과 Node.js가 충돌하는 특이한 문제가 발생했습니다. 이전 버전의 Docker를 사용하면 Playwright를 실행할 때 예기치 않은 오류가 발생할 수 있습니다. 따라서 프로젝트를 초기화할 때 최신 버전의 Docker 및 Playwright 이미지를 사용하는 것이 권장됩니다.\n\n# Gitlab 파이프라인에서 테스트 실행\n\n변경 사항을 GitLab에 푸시하면 파이프라인에서 이와 유사한 내용이 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_7.png\" /\u003e\n\n실행된 파이프라인에서 테스트 단계를 클릭하면 결과에서 비슷한 로그를 볼 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_8.png\" /\u003e\n\n# 보고서에 접근하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n보고서에 액세스하려면 페이지 우측 하단에 있는 \"찾아보기\" 버튼을 클릭하여 프로젝트 자료를 확인하세요.\n\n![이미지](/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_9.png)\n\n자료에서 \"playwright-report\" 하위에 있는 HTML 보고서를 찾을 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_10.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n필요하다면 여기서 GitLab 저장소를 찾을 수 있어요.\n\n읽어 주셔서 감사합니다! 이 글을 가능한 한 간단하게 유지하기 위해 노력했어요. 유용하게 찾으셨으면 좋겠어요. 자유롭게 댓글을 남겨주세요. 다음 글에서 만나요! 👋","ogImage":{"url":"/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_0.png"},"coverImage":"/assets/img/2024-06-23-RunningPlaywrighttestswithDockeronGitLab_0.png","tag":["Tech"],"readingTime":6},{"title":"Alpine, Distroless, 아니면 Scratch 도커 이미지 선택 가이드","description":"","date":"2024-06-23 00:36","slug":"2024-06-23-alpinedistrolessorscratch","content":"\n\n저는 최근 온라인 부티크 샘플 앱의 4개 Golang 앱을 알파인에서 스크래치로 이주했어요. 그런 과정에서 배운 멋진 것들이 있습니다.\n\n알파인은 우리의 컨테이너화된 애플리케이션의 컨테이너 이미지 크기를 줄이는 데 인기 있는 이미지입니다. 그로 인해 보안 상태도 개선됩니다(공격 표면이 적고 CVE가 적습니다).\n\n하지만 이것만으로 충분하지는 않아요. 알파인에는 아직 취약점이 있는 패키지가 포함되어 있고, busybox와 wget이 있어서 프로덕션 환경에 적합하지 않은 것이죠.\n\n알파인보다 더 나은 것을 할 수 있을까요? 그럼! distroless가 도움이 될 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 많고 더 나은 것을 할 수 있을까요? 네! scratch가 도움이 될 수 있어요.\n\n이 세 가지 이미지 간의 차이를 살펴봅시다.\n\n이를 위해 Kelsey Hightower의 helloworld 앱을 사용하고 scratch를 사용하여 테스트해보겠지만, 알파인 및 distroless로도 테스트를 수행할 거에요.\n\n```js\nFROM golang:1.22\nWORKDIR /go/src/github.com/kelseyhightower/app/\nCOPY . .\nRUN CGO_ENABLED=0 GOOS=linux go build .\n\n# FROM alpine\n# FROM gcr.io/distroless/static\n# FROM cgr.dev/chainguard/static\nFROM scratch\nCOPY --from=0 /go/src/github.com/kelseyhightower/app/helloworld .\nENTRYPOINT [\"/helloworld\"]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 크기\n\n다양한 변형의 컨테이너 이미지를 빌드한 후에 이제 크기를 비교해봅시다:\n\n```js\nREPOSITORY   TAG          IMAGE ID       CREATED          SIZE\nhelloworld   alpine       2c2991efd7cd   7 minutes ago    14.4MB\nhelloworld   distroless   08308f5bc54d   16 minutes ago   9.03MB\nhelloworld   chainguard   eaa8a9d18fef   8 seconds ago    7.79MB\nhelloworld   scratch      287ad0140c46   32 minutes ago   7.04MB\n```\n\n모두 매우 가벼우며 작습니다. Alpine은 더 크며, 더 많은 패키지를 제공하기 때문에 Scratch보다 두 배 더 큽니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 블로그 포스트인 \"이미지 크기는 핵심이 아니다\"는 이미지 크기에만 집중해서는 안 된다는 이유를 설명합니다. 작은 컨테이너 이미지를 가지는 것은 종종 성능이 더 우수하고 보안 수준이 높다는 좋은 신호입니다.\n\n# 패키지\n\n이제 빌드된 이 컨테이너 이미지에 포함된 패키지를 비교해 보겠습니다. 이를 위해 syft를 사용해 봅시다.\n\n알파인 (17 개 패키지):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n이름                    버전               유형        \nalpine-baselayout       3.4.3-r2              apk          \nalpine-baselayout-data  3.4.3-r2              apk          \nalpine-keys             2.4-r1                apk          \napk-tools               2.14.0-r5             apk          \nbusybox                 1.36.1-r15            apk          \nbusybox-binsh           1.36.1-r15            apk          \nca-certificates-bundle  20230506-r0           apk          \nhelloworld              (devel)               go-module    \nlibc-utils              0.7.2-r5              apk          \nlibcrypto3              3.1.4-r5              apk          \nlibssl3                 3.1.4-r5              apk          \nmusl                    1.2.4_git20230717-r4  apk          \nmusl-utils              1.2.4_git20230717-r4  apk          \nscanelf                 1.3.7-r2              apk          \nssl_client              1.36.1-r15            apk          \nstdlib                  go1.22.2              go-module    \nzlib                    1.3.1-r0              apk\n```\n\ndistroless (5 개):\n\n```js\n이름        버전          유형        \nbase-files  12.4+deb12u5     deb          \nhelloworld  (devel)          go-module    \nnetbase     6.4              deb          \nstdlib      go1.22.2         go-module    \ntzdata      2024a-0+deb12u1  deb\n```\n\nchainguard (7 개):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n이름                    버전                    유형        \n알파인-베이스레이아웃-데이터  3.6.4-r0                 apk          \n알파인-키               2.4-r1                   apk          \n알파인-릴리스            3.20.0_alpha20240329-r0  apk          \nCA-인증서 번들         20240226-r0              apk          \n헬로우월드              (개발 중)                  go-모듈    \n표준 라이브러리          go1.22.2                 go-모듈    \n시간대 데이터            2024a-r1                 apk\n```\n\n기본 (2 개의 패키지):\n\n```js\n이름        버전   유형        \n헬로우월드  (개발 중)   go-모듈    \n표준      go1.22.2  go-모듈\n```\n\n우리는 이제 이들을 우리의 필요에 맞게 현명하게 사용할 수 있어요. 사용하는 프로그래밍 언어에 따라 무엇이 들어있는지 정확히 알아야 하는 것이 정말 멋지고 중요하죠?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# CVEs\n\n불필요한 종속성과 패키지의 수를 줄이면 유지 보수 시간과 관련된 CVEs 업데이트로부터 오는 피로를 줄일 수 있어요.\n\n만약 trivy와 같은 도구를 사용한다면, 이 블로그 글을 작성할 때 alpine만 CVEs가 있는 것을 확인할 수 있어요:\n\n```js\nhelloworld:alpine (alpine 3.19.1)\n=================================\nTotal: 2 (UNKNOWN: 0, LOW: 2, MEDIUM: 0, HIGH: 0, CRITICAL: 0)\n\n|  라이브러리 | 취약점 | 심각도 | 상태 | 설치된 버전 | 수정된 버전 | 제목 |\n|----------|----------|--------|------|-----------------|-----------------|------------------------------------------------------------------|\n| libcrypto3 | CVE-2024-2511 | LOW | fixed | 3.1.4-r5 | 3.1.4-r6 | openssl: Unbounded memory growth with session handling in TLSv1.3 |\n| | | | | | | [자세히 보기](https://avd.aquasec.com/nvd/cve-2024-2511) |\n| libssl3 | | | | | | |\n| | | | | | | |\n| | | | | | | |\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예시에서는 낮은 수준의 보안이지만 그래도 중요합니다. 여전히 자신의 앱 패키지의 CVEs를 다루어야 하므로 기본 이미지에서 이를 제거하는 것은 항상 큰 이점입니다.\n\n# 더 많은 보안\n\n다음 명령어를 사용하여 모두를 특권 없이 실행하는 것은 어려움이 없습니다. 모두 성공적으로 작동합니다:\n\n```js\ndocker run \\\n    -d \\\n    -p 8080:8080 \\\n    --read-only \\\n    --cap-drop=ALL \\\n    --user=65532 \\\n    CONTAINER_IMAGE\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 docker exec 또는 kubectl exec를 실행할 수 있는 유일한 컨테이너 이미지는 alpine 이미지입니다. 다른 이미지들은 셸을 갖고 있지 않기 때문에 이 작업을 허용하지 않습니다. 보안적인 측면에서 셸이 없는 것은 보안 포지션을 개선하는 좋은 실천법이죠 (다시 말해, 공격 표면을 줄입니다).\n\n# 이것으로 마치겠습니다!\n\n만약 정적으로 컴파일된 Golang 또는 Rust 앱을 사용한다면, scratch를 사용하세요. ca-certificates나 tzdata와 같은 것이 필요하다면 gcr.io/distroless/static 또는 cgr.dev/chainguard/static을 선택하세요.\n\n이것이 바로 쿠버네티스 프로젝트가 이미 4년간 진행해 온 작업입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 libc가 필요하다면 gcr.io/distroless/base-nossl 또는 libssl이 포함된 gcr.io/distroless/base를 사용할 수 있어요.\n\n또한 Java, .NET, Python 등 다른 유형의 앱을 위한 더 많은 컨테이너 이미지들도 있어요.\n\ndistroless 주변에서 더 많은 노력들도 있어요:\n\n- Chainguard는 중요한 역할을 하는데, 그들은 많은 distroless 이미지를 가지고 있어요.\n- RedHat은 UBI Micro를 가지고 있어요.\n- Ubuntu는 Chiseled을 가지고 있어요 — 이제 Microsoft가 dotnet 컨테이너 이미지와 함께 포함시켰어요. 예를 들어, 저는 이 컨테이너와 다른 컨테이너를 alpine에서 chiseled로 마이그레이션 했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, 클러스터 내에서 배포하는 외부 컨테이너에는 distroless flavor를 요청하십시오. 예를 들어, Jib를 사용하는 경우, 이제 distroless를 기본으로 사용합니다. Istio의 경우 Istio 사이드카 프록시에 distroless를 선택적으로 사용할 수 있습니다.\n\ndistrolesss를 사용하면 컨테이너에 대한 디버깅 기능이 제거됩니다(쉘 없음, 패키지 관리자 없음, wget/curl 없음). 하지만 생산 환경에서 디버그 모드로 진입하는 것은 좋지 않은 실천 방법입니다(잠재적 해커에게 더 많은 도구를 제공하기 때문입니다). 대신에 kubernetes debug 또는 initContainers와 같은 기능을 사용할 수도 있습니다. 필요한 경우에는요.\n\n# 리소스\n\n- scratch for checkout, frontend, productcatalog and shipping by mathieu-benoit · Pull Request #2512 · GoogleCloudPlatform/microservices-demo (github.com)\n- Is Your Container Image Really Distroless? | Docker\n- erickduran/docker-distroless-poc: A simple Proof of Concept of a vulnerable web app using a distroless image and Python. (github.com)\n- Chiselled Ubuntu containers: the benefits of combining Distroless and Ubuntu | Ubuntu\n- Why I Will Never Use Alpine Linux Ever Again | by Martin Heinz | Better Programming","ogImage":{"url":"/assets/img/2024-06-23-alpinedistrolessorscratch_0.png"},"coverImage":"/assets/img/2024-06-23-alpinedistrolessorscratch_0.png","tag":["Tech"],"readingTime":7},{"title":"전체 구성 Compose 파일 쉽게 설정하는 방법","description":"","date":"2024-06-23 00:30","slug":"2024-06-23-TheWholeShebangComposeFiles","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-TheWholeShebangComposeFiles_0.png\" /\u003e\n\n요즘 Docker 및 컨테이너에 대해 많이 쓰고 가르치고 있습니다. 내 컨텐츠를 소비하고 피드백을 제공해 주시는 여러분들에게 매우 감사합니다. 여러분의 의견을 듣고 다음 주제는 당연히 Docker Compose입니다. 왜냐하면 이제 여러분은 자신의 컨테이너 이미지를 만들고 실행하는 방법을 알고 있으므로, 다음으로 논리적으로 남은 일은 복잡한 멀티 컨테이너 애플리케이션을 만들고 그 모든 것을 단일 소프트웨어로 관리하는 것입니다.\n\n# Docker Compose: 그게 뭔데, 왜 필요한가요?\n\n공식 문서에서 더 많은 정보를 확인할 수 있지만, 간단히 말하면 다음과 같습니다: Docker를 사용하여 컨테이너, 이미지, 볼륨 등을 관리합니다. docker run을 실행하면 기본적으로 단일 컨테이너를 실행하는 것입니다. 만약 첫 번째 컨테이너와 상호 작용하는 두 번째 컨테이너를 시작하려면 docker run을 다시 실행해야 하며, 볼륨 및 네트워크를 별도로 처리하여 서로를 보고 통신할 수 있도록 해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도커 컴포즈는 도커 위에 래퍼를 제공하여 이 모든 것을 추상화합니다 (맞아요! 도커 컴포즈는 단순히 도커를 위한 고수준 CLI입니다). 실제로 대부분의 옵션이 docker run 하위 명령어에서 사용 가능한 옵션들과 매우 유사한 방식으로 명명됩니다.\n\n도커 컴포즈를 사용하면 YAML 파일인 컴포즈 파일을 통해 컨테이너(도커 컴포즈 세계에서는 서비스라고 불립니다... 단지 스웜 모드에서도 컴포즈 파일을 사용할 수 있기 때문에... 다른 글에서 설명할 예정), 볼륨 및 네트워크를 포함한 모든 것을 선언적으로 정의할 수 있습니다. 이렇게 하면 멀티 컨테이너 애플리케이션을 관리해야 할 때, 이 compose 파일만 건드리고 나머지는 도커 컴포즈가 모두 처리하도록 할 수 있습니다.\n\n# 컴포즈 파일\n\n우선, 멀티 컨테이너 애플리케이션을 올바르게 운영하려면 컴포즈 파일을 작성하는 방법을 익혀야 하므로 도커 컴포즈 CLI에 대해서는 다른 글에서 다룰 예정입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도커의 구성 파일 관련 문서는 매우 완벽하지만, 저는 실용주의와 경험으로부터 배우는 것을 중요하게 생각하는 사람이라서 모든 Compose 파일 옵션을 손질하고 명료한 설명과 실제 예시를 담아내려고 합니다. 여기서 시작해봅시다!\n\n참고 1: 이 기사를 작성하는 시점에서 최신 버전인 v3의 Compose 파일 명세에 대한 옵션과 스키마만 다룰 예정입니다. 그러니 걱정하지 마세요.\n\n참고 2: 각 옵션에 대해 일반적으로 사용되는 방법에 대한 설명과 예시만 제공할 것이며, 특정 옵션 매개변수를 사용해본 적이 없는 경우에는 \"일반적이지 않음\"으로 간주할 것입니다. 어떤 옵션의 적은 사용 방법 및 일반적이지 않은 매개변수를 더 자세히 알고 싶다면 공식 문서를 참조해주세요.\n\n예시에 들어가기 전에, 모든 구성 파일은 작성하는 현재의 파일 스키마를 나타내는 키워드 version으로 시작됩니다. 앞서 말한대로, 저희는 최신 (버전: \"3\")을 사용할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 빌드\n\n기본적으로 Docker Compose로 무언가를 시작할 때, Docker 이미지 또는 Dockerfile을 제공할 수 있습니다. 해당 컨테이너를 시작하기 전에 Docker가 이미지를 직접 빌드하도록 하고 싶다면 수동으로 이미지를 빌드하지 않고도 이 옵션을 사용할 수 있습니다.\n\n예를 들어:\n\n```js\n$ cat \u003eDockerfile \u003c\u003cEOF\n# 이것은 Dockerfile입니다\nFROM ubuntu\nCMD [\"echo\", \"Hello Medium readers\"]\n# Dockerfile 끝\nEOF\n$\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  my-test-container:\n    build: .\nEOF\n$\n$ docker-compose up \n디폴트 드라이버를 사용하여 \"mediumcom_default\" 네트워크 생성 중\nmy-test-container 빌드 중\nDocker 데몬으로 빌드 컨텍스트 보내는 중  1.337MB\n단계 1/2 : FROM ubuntu\n ---\u003e ba6acccedd29\n단계 2/2 : CMD [\"echo\", \"Hello Medium readers\"]\n ---\u003e 캐시 사용 중\n ---\u003e 6c8b22fa650c\n성공적으로 빌드되었습니다 6c8b22fa650c\nmediumcom_my-test-container:latest로 성공적으로 태깅되었습니다\nmediumcom_my-test-container_1 생성 중 ... 완료\nmediumcom_my-test-container_1에 연결 중\nmy-test-container_1  | Hello Medium readers\nmediumcom_my-test-container_1는 코드 0으로 종료됨\n$ \n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n보시다시피, Docker Compose는 Docker에게 도커파일(컴포즈 파일과 동일한 경로에 위치)로부터 이미지를 빌드하도록 지시하고, 그 후에 자동으로 컨테이너를 시작했습니다.\n\n참고: 일반적으로 docker build와 함께 사용하는 일부 옵션들(빌드 인자 전달, Dockerfile의 경로 및 이름 지정 등)도 여기에서 사용할 수 있습니다. 자세한 내용은 문서를 확인해주세요.\n\n## 이미지\n\n어플리케이션을 실행할 때마다 Docker 이미지를 빌드할 필요는 없겠죠... 그렇게 하면 불편하겠죠. 따라서 이미지를 미리 빌드하거나 간단히 컨테이너 이미지를 지정하면 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 이전 예제의 Dockerfile과 다음의 compose 파일을 살펴보세요:\n\n```js\n$ # 이전 예제 정리하기 위함\n$ # 이제부터 각 예제에서 다음 명령 실행해주세요\n$ docker-compose down -v --remove-orphans   \n$\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    build: .\n  second:\n    image: hello-world\nEOF\n$ # Dockerfile이 변경되지 않았기 때문에 첫 번째 이미지가 다시 빌드되지 않습니다\n$ docker-compose up    \n네트워크 \"mediumcom_default\" 생성 중\nmediumcom_first_1  ... 생성됨\nmediumcom_second_1 ... 생성됨\nmediumcom_second_1, mediumcom_first_1에 연결 중\nfirst_1   | Hello Medium readers\nsecond_1  | \nsecond_1  | Hello from Docker!\nsecond_1  | This message shows that your installation appears to be working correctly.\nsecond_1  | \nsecond_1  | To generate this message, Docker took the following steps:\nsecond_1  |  1. The Docker client contacted the Docker daemon.\nsecond_1  |  2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\nsecond_1  |     (amd64)\nsecond_1  |  3. The Docker daemon created a new container from that image which runs the\nsecond_1  |     executable that produces the output you are currently reading.\nsecond_1  |  4. The Docker daemon streamed that output to the Docker client, which sent it\nsecond_1  |     to your terminal.\nsecond_1  | \nsecond_1  | To try something more ambitious, you can run an Ubuntu container with:\nsecond_1  |  $ docker run -it ubuntu bash\nsecond_1  | \nsecond_1  | Share images, automate workflows, and more with a free Docker ID:\nsecond_1  |  https://hub.docker.com/\nsecond_1  | \nsecond_1  | For more examples and ideas, visit:\nsecond_1  |  https://docs.docker.com/get-started/\nsecond_1  | \nmediumcom_second_1이 코드 0으로 종료됨\nmediumcom_first_1이 코드 0으로 종료됨\n```\n\n여기서 보듯이, 이제 하나의 Compose 파일과 하나의 docker-compose 명령을 사용하여 동일한 다중 컨테이너 애플리케이션 내에서 병렬로 2개의 컨테이너를 실행했습니다. 하나의 컨테이너는 \"Hello Medium readers\"라고 말하는 사용자 지정 Docker 이미지를 사용했고, 다른 하나는 Docker Hub에서 \"hello-world\" 이미지를 가져와 자체 Hello World 메시지를 출력했습니다.\n\n## 명령\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이를 통해 컨테이너의 명령을 정의할 수 있습니다. 따라서 Docker 이미지에 entrypoint가 정의되어 있으면 이 명령이 해당 entrypoint의 인수가 됩니다. 예시:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu\n    command: echo \"I am at your command!\"\nEOF\n$ docker-compose up\nCreating network \"mediumcom_default\" with the default driver\nCreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | I am at your command!\nmediumcom_first_1 exited with code 0\n```\n\n아주 간단하지요?\n\n## entrypoint\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이름에서 알 수 있듯이 해당 기능은 컨테이너의 엔트리포인트를 재정의하게 해줍니다. 예를 들어, 컨테이너가 echo 실행 파일로 실행되도록 하려면 다음과 같이 작성할 수 있어요:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu\n    entrypoint: [\"echo\"]\n    command: \"I am just an arg\"\nEOF\n$ docker-compose up\nCreating network \"mediumcom_default\" with the default driver\nCreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | I am just an arg\nmediumcom_first_1 exited with code 0\n```\n\n간단하지요? 그리고 command 대 entrypoint 등에 대해 궁금해 한다면 당신만이 아닙니다. 이것은 매우 일반적인 혼란 포인트입니다. 다른 기사 \"전부 다: Dockerfiles\"에서 이에 대해 이야기했어요. 간단히 말해서, 저는 이 두 옵션을 조율할 때 필요한 치트 시트를 제공합니다: https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact\n\n## cap_add\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 컨테이너에 추가 기능이 필요한 경우, 다음과 같이 추가할 수 있어요:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu:14.04\n    command: ip link add dummy0 type dummy\n    cap_add:\n     - NET_ADMIN\nEOF\n$ docker-compose up\nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nmediumcom_first_1 exited with code 0\n```\n\n이제 위와 같은 컨테이너를 실행하려고 하지만 기능이 없는 경우, 에러가 발생할 거예요:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu:14.04\n    command: ip link add dummy0 type dummy\nEOF\n$ docker-compose up\nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | RTNETLINK answers: Operation not permitted\nmediumcom_first_1 exited with code 2\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## cap_drop\n\ncap_add의 정 반대입니다. 컨테이너에서 기능을 제거하는 데 사용됩니다. 예를 들어 슈퍼 권한이 부여된 컨테이너가 있다고 가정해보겠습니다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu:14.04\n    command: ip link add dummy0 type dummy\n    cap_add:\n     - ALL\nEOF\n$ docker-compose up\nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nmediumcom_first_1 exited with code 0\n```\n\n그러나 호스트 네트워크 스택을 관리하려고 하지 않는다면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sh\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu:14.04\n    command: ip link add dummy0 type dummy\n    cap_add:\n     - ALL\n    cap_drop:\n     - NET_ADMIN\nEOF\n$ docker-compose up\nmediumcom_first_1 컨테이너를 다시 생성하는 중... 완료\nmediumcom_first_1에 연결 중\nfirst_1 | RTNETLINK 답변: 작업을 수행할 수 없습니다\nmediumcom_first_1은 코드 2로 종료됨\n```\n\n## cgroup_parent\n\ncgroup에 대해 처음이라면 이곳에 관한 짧은 좋은 기사가 있습니다. 간단히 말해, Linux 커널은 제어 그룹 (cgroups)을 통해 프로세스별로 시스템 리소스의 사용량을 엄격하게 제어할 수 있는 기능을 제공합니다. Docker에서는 이를 통해 컨테이너가 특정 리소스를 얼마나 사용할 수 있는지 제어할 수 있습니다. 기본적으로 컨테이너는 가능한 많은 리소스를 사용하려고 시도할 것입니다:\n\n```sh\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu\n    command: sleep 30\nEOF\n$ docker-compose up -d \n기본 드라이버로 네트워크 \"root_default\"를 생성 중\nroot_first_1 컨테이너 생성 중... 완료\n$ docker inspect root_first_1 --format '{.HostConfig.CgroupParent}'\n$\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n보시는 대로, 기본적으로 컨테이너에 할당된 제어 그룹이 없습니다. 하지만 우리가 할당할 수 있습니다. 심지어 우리 자신의 것을 할당할 수도 있습니다:\n\n```js\n$ cgcreate -g cpu:test-cgroup-medium\n$ ls /sys/fs/cgroup/cpu\ncgroup-limit           cgroup.sane_behavior  cpu.shares    cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  release_agent  test-cgroup-medium\ncgroup.clone_children  cpu.cfs_period_us     cpu.stat      cpuacct.usage_all     cpuacct.usage_percpu_user  docker              system.slice   user.slice\ncgroup.procs           cpu.cfs_quota_us      cpuacct.stat  cpuacct.usage_percpu  cpuacct.usage_sys          notify_on_release   tasks\n```\n\n그리고 이 옵션을 사용함으로써 이 컨테이너에서 CPU 사용량을 엄격하게 제어할 수 있게 될 것입니다. cgroup \"cpu:test-cgroup-medium\"을 통해:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu\n    command: sleep 30\n    cgroup_parent: \"cpu:test-cgroup-medium\"\nEOF\n$ docker-compose up -d \nRecreating root_first_1 ... done\n$ docker inspect root_first_1 --format '{.HostConfig.CgroupParent}'\ncpu:test-cgroup-medium\n$\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## container_name\n\n이 옵션에 대해 로켓 과학같은 것은 없습니다. 이 옵션은 Docker Compose 배포에서 생성된 컨테이너의 이름을 고정하는 데 사용됩니다.\n\n이전에 언급한 바와 같이, 기본적으로 Docker Compose는 컨테이너에 접미사를 추가하며 이는 Docker Compose 프로젝트의 이름과 일치합니다 (프로젝트 이름을 명시적으로 지정하지 않는 경우 Docker Compose가 현재 경로를 기본값으로 삼습니다).\n\n따라서 Docker Compose의 이 동작을 재정의하고 생성된 컨테이너에 자체적으로 정의한 사용자 정의 이름을 지정하려면 container_name을 사용할 수 있습니다. 예시:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ubuntu\n    container_name: my-own-container-name\nEOF\n$ docker-compose up\n기본 드라이버로 \"mediumcom_default\" 네트워크 생성 중\nmy-own-container-name 생성 완료\nmy-own-container-name에 연결 중\nmy-own-container-name에서 코드 0으로 종료됨\n```\n\nP.S.: 네, 궁금해하실 수도 있지만, 이 Docker Compose 배포 내의 다른 컨테이너들은 컨테이너 이름에 의해 서로에게 도달할 수 있습니다. 예:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 5\n    container_name: my-own-container-name\n  second:\n    image: alpine\n    command: ping -c 1 my-own-container-name\nEOF\n$ docker-compose up\nmy-own-container-name을 다시 생성 중... 완료\nmediumcom_second_1 생성 중... 완료\nmediumcom_second_1, my-own-container-name에 연결 중\nsecond_1  | my-own-container-name(172.18.0.3) 핑 중: 56 data bytes\nsecond_1  | 64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.743 ms\nsecond_1  | \nsecond_1  | --- my-own-container-name 핑 통계 ---\nsecond_1  | 전송된 패킷: 1, 수신된 패킷: 1, 패킷 손실: 0%\nsecond_1  | 왕복 최소/평균/최대 시간 = 0.743/0.743/0.743 ms\nmediumcom_second_1이 코드 0으로 종료됨\nmy-own-container-name이 코드 0으로 종료됨\n```\n\n## depends_on\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 말하자면, 아니요, 이 옵션은 컨테이너 애플리케이션의 시작 순서를 제어할 수 있게 해주지 않아요! 많은 사람들이 하는 실수죠. 하지만 생각해보세요… 당신의 컨테이너는 내부에서 하나 이상의 프로세스를 실행하고 있기 때문에, Docker(컨테이너를 관리하는 주체)가 해당 컨테이너 내부에서 실행 중인 애플리케이션/프로세스의 비즈니스 로직을 완벽히 이해하고 있다고 가정하는 것은 순진한 판단일 거예요.\n\n이것은 미묘한 차이가 있지만, 이 옵션이 하는 일은 대신에 Docker Compose에게 컨테이너를 시작하고 중지할 때의 순서를 명시하는 것뿐이에요.\n\n예시:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    depends_on:\n     - second\n  second:\n    image: alpine\n    depends_on:\n     - first\nEOF\n$ docker-compose up\nCreating network \"mediumcom_default\" with the default driver\nCreating mediumcom_second_1 ... done\nCreating mediumcom_first_1  ... done\nAttaching to mediumcom_second_1, mediumcom_first_1\nmediumcom_second_1 exited with code 0\nmediumcom_first_1 exited with code 0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n봐요! 두 번째에 의존하는 첫 번째 컨테이너가 먼저 시작되므로, 두 번째 컨테이너가 먼저 시작됩니다. 그리고 멈출 때도 마찬가지 — 먼저 의존하는 첫 번째가 있기 때문에 두 번째가 마지막으로 내려갑니다!\n\n```js\n$ docker-compose down\nmediumcom_first_1  ... 삭제됨\nmediumcom_second_1 ... 삭제됨\nmediumcom_default 네트워크 제거됨\n```\n\n추신: 만약 혼돈을 즐긴다면, 두 번째도 첫 번째에 의존하도록 만들었다면 어떻게 될까요? 😝 걱정 마세요, Docker는 똑똑해서 다음과 같은 메시지를 보여줄 거예요:\n\n## 볼륨\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도커 볼륨에 대해 자세히 설명하지 않을 거예요. 이 주제는 꽤 크거든요. 단지 컨테이너 애플리케이션에서 데이터를 관리할 수 있는 4가지 방법이 있다는 것만 말씀드릴게요:\n\n- 컨테이너의 쓰기 가능한 레이어 내에 모든 데이터를 유지합니다 (볼륨 없음)\n- 호스트와 컨테이너 사이에 마운트 지점을 만듭니다 (바인드 마운트)\n- 컨테이너의 수명주기와 독립적으로 데이터를 호스팅하고 관리하는 전용 도커 리소스를 생성합니다 (볼륨)\n- 성능을 최적화하기 위해 데이터를 영구 저장하지 않고 메모리에 유지합니다 (tmpfs).\n\n이렇게 말씀드린 바와 같이 Compose 파일에서 이러한 타입의 볼륨을 모두 관리할 수 있어요. 지금까지 모든 예제는 컨테이너의 쓰기 가능한 레이어를 사용했지만, 나머지 3가지 데이터 관리 옵션을 다음과 같이 사용할 수 있어요:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: ls /\n    volumes:\n     - /:/my-hostfs\n     - my-volume:/my-volume\n     - type: tmpfs\n       target: /my-tmpfs\nvolumes:\n  my-volume:\nEOF\n$ docker-compose up\nCreating network \"test_default\" with the default driver\nCreating volume \"test_my-volume\" with default driver\nCreating test_first_1 ... done\nAttaching to test_first_1\nfirst_1  | bin\nfirst_1  | dev\nfirst_1  | etc\nfirst_1  | home\nfirst_1  | lib\nfirst_1  | media\nfirst_1  | mnt\nfirst_1  | my-hostfs\nfirst_1  | my-tmpfs\nfirst_1  | my-volume\nfirst_1  | opt\nfirst_1  | proc\nfirst_1  | root\nfirst_1  | run\nfirst_1  | sbin\nfirst_1  | srv\nfirst_1  | sys\nfirst_1  | tmp\nfirst_1  | usr\nfirst_1  | var\ntest_first_1 exited with code 0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기에 세 가지 다른 유형의 마운트가 한꺼번에 나왔어요. 그런데 알아두셨나요? 제가 3가지 다른 구문을 사용했어요... 선호하는 것이나 마운트에 가장 적합한 것을 선택할 수 있어요 (여기에서 더 자세히 읽을 수 있어요).\n\n추가로, tmpfs도 전용 옵션을 통해 설정할 수 있어요... 예제를 보려면 다음 섹션을 읽어보세요.\n\n## tmpfs\n\n이미 이전 섹션에서 설명했지만, 알아두시면 좋아요. 이는 컨테이너를 위한 비영구적 마운트 포인트를 설정하는 또 다른 간단한 방법일 뿐이에요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sh\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: ls /\n    tmpfs: /my-tmpfs\nEOF\n$ docker-compose up\nmediumcom_first_1 컨테이너 다시 생성 중... 완료\nmediumcom_first_1에 첨부 중\nfirst_1  | bin\nfirst_1  | dev\nfirst_1  | etc\nfirst_1  | home\nfirst_1  | lib\nfirst_1  | media\nfirst_1  | mnt\nfirst_1  | my-tmpfs\nfirst_1  | opt\nfirst_1  | proc\nfirst_1  | root\nfirst_1  | run\nfirst_1  | sbin\nfirst_1  | srv\nfirst_1  | sys\nfirst_1  | tmp\nfirst_1  | usr\nfirst_1  | var\nmediumcom_first_1가 코드 0으로 종료됨\n```\n\n## 디바이스\n\n그 이름에서 알 수 있듯이, 이 옵션은 컨테이너가 시스템 디바이스를 관리하기 위한 액세스 권한을 부여합니다. 이 것이 일반적인 바인드-마운트와 어떻게 다른지 궁금할 것입니다. 단순히 디바이스를 컨테이너에 바인드-마운트할 수 있지 않을까요? 음, 그렇고 그렇지 않습니다... 컨테이너가 해당 디바이스를 어떻게 사용하는지에 따라 다릅니다. 디바이스 파일은 일반 파일 및 디렉토리와 약간 다르며 (/dev 폴더 아래에서 일반 파일처럼 보이지만), 디바이스 파일은 디바이스 드라이버 및 물리 디바이스로의 인터페이스를 제공하므로 더 세분화된 액세스 제어가 있습니다. 이는 cgroups를 통해 관리되며(여기에서 더 읽을 수 있습니다).\n\n요약하면, 컨테이너가 특권 모드에서 실행되지 않는 경우에도 이 옵션을 통해 특정 디바이스 파일에 대한 컨테이너 액세스를 부여할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 컴퓨터에 웹캠이 연결되어 있다고 가정해 봅시다.\n\n```bash\n$ lsusb -s 001:003\nBus 001 Device 003: ID 046d:0826 Logitech, Inc. HD Webcam C525\n```\n\n그리고 컨테이너 내부에서 웹캠을 사용하여 사진을 찍고 싶어합니다. 다음 시나리오를 고려해보세요:\n\n- 먼저, 옵션을 적용하지 않고 컨테이너 내부에서 웹캠에 액세스해보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ccordeiro/fswebcam:armv7l\n    command: fswebcam -r 640x480 --jpeg 85 -D 1 picture.jpg\nEOF\n$ docker-compose up\n네트워크 \"tmp_default\"를 기본 드라이버로 생성중\ntmp_first_1 를 생성중... 완료\ntmp_first_1 에 연결중\nfirst_1  | --- /dev/video0 열기 중...\nfirst_1  | stat: 해당 파일 또는 디렉터리가 없습니다\nfirst_1  | tmp_first_1이 코드 0으로 종료되었습니다\n```\n\n…그러나 분명히 컨테이너에는 어떤 장치도 보이지 않습니다…\n\n- 두 번째로, 장치 파일을 바인드 마운트해 봅시다\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ccordeiro/fswebcam:armv7l\n    command: fswebcam -r 640x480 --jpeg 85 -D 1 picture.jpg\n    volumes:\n     - /dev/video0:/dev/video0\nEOF\n$ docker-compose up\ntmp_first_1 재생성중... 완료\ntmp_first_1 에 연결중\nfirst_1  | --- /dev/video0 열기 중...\nfirst_1  | v4l2 모듈 시도 중...\nfirst_1  | 기기 열기 실패: /dev/video0\nfirst_1  | 열기: 작업을 허용하지 않습니다\nfirst_1  | v4l1 모듈 시도중...\nfirst_1  | 기기 열기 실패: /dev/video0\nfirst_1  | 열기: 작업을 허용하지 않습니다\nfirst_1  | /dev/video0을 읽을 수 있는 소스 모듈을 찾을 수 없습니다.\nfirst_1  | tmp_first_1이 코드 0으로 종료되었습니다\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n…음, 컨테이너는 보이지만 접근할 수 있는 권한이 없네요.\n\n- 마지막으로 장치를 사용해 봅시다\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: ccordeiro/fswebcam:armv7l\n    command: fswebcam -r 640x480 --jpeg 85 -D 1 picture.jpg\n    devices:\n     - /dev/video0:/dev/video0\nEOF\n$ docker-compose up\nRecreating tmp_first_1 ... done\nAttaching to tmp_first_1\nfirst_1  | --- Opening /dev/video0...\nfirst_1  | Trying source module v4l2...\nfirst_1  | /dev/video0 opened.\nfirst_1  | No input was specified, using the first.\nfirst_1  | Delaying 1 seconds.\nfirst_1  | --- Capturing frame...\nfirst_1  | Captured frame in 0.00 seconds.\nfirst_1  | --- Processing captured image...\nfirst_1  | Setting output format to JPEG, quality 85\nfirst_1  | Writing JPEG image to 'picture.jpg'.\nfirst_1  | tmp_first_1 exited with code 0\n```\n\n그리고 성공입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## network_mode\n\nDocker의 네트워킹 시스템은 네트워킹 드라이버에 기반하고 있는 것을 알고 계실 것입니다. 이 옵션을 사용하여 컨테이너가 실행되어야 하는 네트워크 모드를 지정할 수 있습니다.\n\n예를 들어, 기본 브릿지 네트워크에 1개의 컨테이너를, 호스트 네트워크에 1개의 컨테이너를, 첫 번째 컨테이너와 동일한 네트워크에 1개의 컨테이너를, 그리고 어떤 네트워크도 없는 상태로 1개의 컨테이너를 배포하려고 합니다. 아래는 이를 수행하는 방법입니다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sh -c 'ifconfig eth0 \u0026\u0026 sleep 5'\n    network_mode: bridge\n  second:\n    image: alpine\n    command: ifconfig eth0\n    network_mode: host\n  third:\n    image: alpine\n    command: ifconfig eth0\n    depends_on:\n     - first\n    network_mode: service:first\n  fourth:\n    image: alpine\n    command: ifconfig eth0\n    network_mode: none\nEOF\n$ docker-compose up\nCreating mediumcom_first_1  ... done\nCreating mediumcom_fourth_1 ... done\nCreating mediumcom_second_1 ... done\nCreating mediumcom_third_1  ... done\nAttaching to mediumcom_second_1, mediumcom_fourth_1, mediumcom_first_1, mediumcom_third_1\nfirst_1   | eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02  \nfirst_1   |           inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0\n...\nfourth_1  | ifconfig: eth0: error fetching interface information: Device not found\n...\nsecond_1  | eth0      Link encap:Ethernet  HWaddr 02:50:00:00:00:01  \nsecond_1  |           inet addr:192.168.65.3  Bcast:192.168.65.255  Mask:255.255.255.0\n...\nthird_1   | eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02  \nthird_1   |           inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0\n...\nmediumcom_fourth_1 exited with code 1\nmediumcom_second_1 exited with code 0\nmediumcom_third_1 exited with code 0\nmediumcom_first_1 exited with code 0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 무슨 일이 있었나요? 이를 간단히 살펴보겠습니다:\n\n- 첫 번째 컨테이너는 브리지 모드로 들어가서 자체 eth0 개인 네트워크 인터페이스를 할당 받았습니다(IP 172.17.0.2로, Docker 브리지 서브넷의 일부입니다).\n- 두 번째 컨테이너는 호스트 모드로 들어가서 호스트와 동일한 네트워크 수준에서 실행되므로 호스트의 모든 네트워킹 인터페이스를 볼 수 있습니다.\n- 세 번째 컨테이너는 첫 번째 것과 동일한 네트워크를 받았습니다.\n- 네 번째 컨테이너는 네트워크가 없어 eth0 인터페이스를 찾지 못하여 실패했습니다.\n\n## 네트워크\n\n이제 위에서 언급한 옵션을 활용하여, 컨테이너를 사용자 정의 네트워크에 연결하려면 어떻게 해야 하나요(기존 네트워크 또는 새로 생성한 것 중)? 그럴 때는 networks를 사용하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ docker network create cjdc-test\n0f5e35bf6b8d396c45c19545540957fbc5fa15ba1ca0e5fbca4add3802c7db6d\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 30\n    networks:\n     - new-net\n  second:\n    image: alpine\n    command: sleep 30\n    networks:\n     - cjdc-test\nnetworks:\n  new-net:\n  cjdc-test:\n    external: true\n    name: cjdc-test\nEOF\n$ docker-compose up -d\nCreating network \"mediumcom_new-net\" with the default driver\nCreating mediumcom_second_1 ... done\nCreating mediumcom_first_1  ... done\n$ docker inspect --format '{.NetworkSettings.Networks}' mediumcom_first_1\nmap[mediumcom_new-net:0xc0004d8f00]\n$ docker inspect --format '{.NetworkSettings.Networks}' mediumcom_second_1\nmap[cjdc-test:0xc0003e8f00]\n```\n\n## dns\n\nIt basically lets you define a custom DNS server for your container. Example:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: cat /etc/resolv.conf\n    dns: 1.2.3.4\n    network_mode: bridge\nEOF\n$ docker-compose up\nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | nameserver 1.2.3.4\nmediumcom_first_1 exited with code 0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주의: 사용자 정의 네트워크에서는 DNS 옵션이 기본적으로 동작하지 않으므로 브릿지 네트워크가 필요합니다.\n\n## dns_search\n\n여기에서 사용자 맞춤 DNS 검색 도메인을 설정할 수 있습니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: cat /etc/resolv.conf\n    dns_search: my.custom.dns\n    network_mode: bridge\nEOF\n$ docker-compose up \nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | search my.custom.dns\nfirst_1  | nameserver 192.168.65.5\nmediumcom_first_1 exited with code 0\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## env_file\n\n일반적으로 컨테이너 환경을 하나씩 설정하는 데 익숙할 수 있지만, 한 번에 이 작업을 수행하도록 대신 파일을 사용할 수 있습니다:\n\n```js\n$ cat \u003emy-env \u003c\u003cEOF\nVAR1=value\nMY_VAR_FROM_FILE=1\nFOO=BAR\nEOF\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: env\n    env_file:\n     - my-env\nEOF\n$ docker-compose up \nmediumcom_first_1 다시 만들기 ... 완료\nmediumcom_first_1에 연결\nfirst_1  | PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nfirst_1  | HOSTNAME=157e34e4fc64\nfirst_1  | VAR1=value\nfirst_1  | MY_VAR_FROM_FILE=1\nfirst_1  | FOO=BAR\nfirst_1  | HOME=/root\nmediumcom_first_1 코드 0으로 종료\n```\n\n## environment\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이를 통해 컴포즈 파일에서 컨테이너의 환경 변수를 하나씩 직접 설정할 수 있습니다.\n\n이 방법을 사용하여 env_file 옵션을 통해 로드되는 변수를 재정의할 수도 있습니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: env\nEOF\n$ docker-compose up \nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nfirst_1  | HOSTNAME=68e909013198\nfirst_1  | NEW_VAR=yes\nfirst_1  | HOME=/root\nmediumcom_first_1 exited with code 0\n``` \n\n## 노출\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도커파일과 유사하게, 이 옵션은 컨테이너의 포트를 표시하고 다른 연결된 컨테이너에서 사용할 수 있도록 합니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 20\n    expose:\n     - 9876\nEOF\n$ docker-compose up -d\nRecreating mediumcom_first_1 ... done\n$ docker ps\nCONTAINER ID   IMAGE     COMMAND      CREATED          STATUS          PORTS      NAMES\n3be377f4bf6c   alpine    \"sleep 20\"   18 seconds ago   Up 16 seconds   9876/tcp   mediumcom_first_1\n```\n\n## external_links\n\n옵션을 건너뛰어야 합니다. 왜냐하면 1) 이것은 레거시 옵션이기 때문에, 그리고 2) 동일한 결과를 얻기 위해 네트워크를 사용할 수 있습니다(즉, 컨테이너를 외부 네트워크에 포함되어 있지 않은 다른 컨테이너에 연결할 수 있습니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## extra_hosts\n\n이 기능은 컨테이너의 /etc/hosts 파일에 새 항목을 추가할 수 있게 해줍니다. 예를 들어, 컨테이너가 \"localhost\"가 아닌 다른 이름으로 스스로를 호출하도록 하고 싶다면 다음과 같이 할 수 있습니다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sh -c 'cat /etc/hosts; ping me -c 1'\n    extra_hosts:\n     - \"myself:127.0.0.1\"\n     - \"me:127.0.0.1\"\nEOF\n$ docker-compose up \nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | 127.0.0.1 localhost\nfirst_1  | ::1 localhost ip6-localhost ip6-loopback\nfirst_1  | fe00::0 ip6-localnet\nfirst_1  | ff00::0 ip6-mcastprefix\nfirst_1  | ff02::1 ip6-allnodes\nfirst_1  | ff02::2 ip6-allrouters\nfirst_1  | 127.0.0.1 myself\nfirst_1  | 127.0.0.1 me\nfirst_1  | 172.22.0.2 01d566c4380a\nfirst_1  | PING me (127.0.0.1): 56 data bytes\nfirst_1  | 64 bytes from 127.0.0.1: seq=0 ttl=64 time=1.192 ms\nfirst_1  | \nfirst_1  | --- me ping statistics ---\nfirst_1  | 1 packets transmitted, 1 packets received, 0% packet loss\nfirst_1  | round-trip min/avg/max = 1.192/1.192/1.192 ms\nmediumcom_first_1 exited with code 0\r\n```\n\n## healthcheck\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당연히, 이것은 도커 파일 옵션과 매우 유사하게 작동합니다. 도커가 컨테이너가 \"healthy(건강한)\"인지 아닌지 평가하는 데 사용할 수 있는 사용자 정의 확인을 만들 수 있습니다.\n\n그러니까, /tmp에 medium.txt라는 파일이 있을 때만 우리 컨테이너가 건강한 것으로 간주됩니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sh -c 'touch /tmp/NOT_MY_FILE; sleep 10'\n    healthcheck:\n      test: \"[ -f /tmp/medium.txt ]\"\n      # run asap\n      interval: 1s\n      timeout: 5s\n      retries: 1\n      start_period: 0s\n  second:\n    image: alpine\n    command: sh -c 'touch /tmp/medium.txt; sleep 10'\n    healthcheck:\n      test: \"[ -f /tmp/medium.txt ]\"\n      # run asap\n      interval: 1s\n      timeout: 5s\n      retries: 1\n      start_period: 0s\nEOF\n$ docker-compose up -d\nRecreating mediumcom_first_1 ... done\nCreating mediumcom_second_1  ... done\n$ docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS                     PORTS     NAMES\nb8804cbb440d   alpine    \"sh -c 'touch /tmp/N…\"   4 seconds ago   Up 2 seconds (unhealthy)             mediumcom_first_1\n604a6880f3c6   alpine    \"sh -c 'touch /tmp/m…\"   4 seconds ago   Up 2 seconds (healthy)               mediumcom_second_1\n```\n\n그런데 여기서 볼 수 있듯이, 처음 것은 건강하지 않지만 두 번째는 건강하다고 나옵니다. 필요한 파일이 올바른 위치에 존재하기 때문입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 초기화\n\n이를 통해 Docker에게 컨테이너에 대한 init를 사용할지 여부를 알릴 수 있습니다. 참일 경우, Docker는 tini 기반의 docker-init이라는 init을 사용할 것입니다. 차이를 살펴봅시다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: ps -a\n    init: false\nEOF\n$ docker-compose up \nmediumcom_first_1 다시 생성 중... 완료\nmediumcom_first_1에 참여 중\nfirst_1  | PID   USER     TIME  COMMAND\nfirst_1  |     1 root      0:00 ps -a\nmediumcom_first_1은 코드 0으로 종료됨\n```\n\n그러나 초기화를 활성화하면 이와 같은 프로세스 래퍼를 얻게 되며, 이는 PID 1로 추가 기능이 있는 경우 (이 경우에는 docker-init)입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: ps -a\n    init: true\nEOF\n$ docker-compose up\nStarting mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | PID   USER     TIME  COMMAND\nfirst_1  |     1 root      0:00 /sbin/docker-init -- ps -a\nfirst_1  |     8 root      0:00 ps -a\nmediumcom_first_1 exited with code 0\n\n\n## 격리\n\n리눅스의 경우, 이 옵션은 항상 기본값으로 설정됩니다. 윈도우의 경우 더 많은 옵션이 있지만, 아쉽게도 여러분을 위한 예제를 실행할 윈도우 머신이 없습니다 😛 윈도우 사용자분들 죄송해요!\n\n## 레이블\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n콘테이너에 레이블을 설정할 수 있는 이 옵션의 이름처럼:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 10\n    labels:\n     - \"foo=bar\"\nEOF\n$ docker-compose up -d\nRecreating mediumcom_first_1 ... done\n$ docker ps --filter 'label=foo=bar'\nCONTAINER ID   IMAGE     COMMAND      CREATED          STATUS         PORTS     NAMES\n94e844176d76   alpine    \"sleep 10\"   30 seconds ago   Up 7 seconds             mediumcom_first_1\n```\n\n## 링크\n\n외부 링크에 대한 내용은 과거의 옵션을 건너뛰겠습니다. 컨테이너 간 통신은 사용자 정의 네트워크로 쉽게 설정할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 로깅\n\n실제로 이 옵션이 매우 중요하다고 생각해요. 대부분의 사용자들은 보통 컨테이너 애플리케이션 로그의 크기가 계속해서 커지고 있다는 사실에 충분한 주의를 기울이지 않습니다. 호스트 공간이 시간이 지남에 따라 가득 차지 않기를 원한다면, 다른 애플리케이션과 마찬가지로, 애플리케이션이 로그를 기록하는 방식도 제어해야 합니다. Docker를 통해 이 로깅 옵션을 사용하여 컨테이너 애플리케이션의 stdout 로그를 제어할 수 있습니다. 로깅 종류 뿐만 아니라 로깅 크기 제한 및 로테이션 매개변수도 제어할 수 있습니다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sh -c 'while true; do echo `date`; done'\n    logging:\n      options:\n        max-size: \"50k\"\n        max-file: \"10\"\nEOF\n$ docker-compose up -d\ntmp_first_1을 다시 생성 중... 완료됨\n$ docker ps -f 'name=tmp_first_1'\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS     NAMES\n2ea63dd32607   alpine    \"sh -c 'while true; …\"   2 minutes ago   Up 2 minutes             tmp_first_1\n$ \n$ du -h /var/lib/docker/containers/2ea63dd32607*/*log*\n20K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.1\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.2\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.3\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.4\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.5\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.6\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.7\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.8\n52K /var/lib/docker/containers/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60/2ea63dd32607ea5c5b3238ed4da2233a049c41422cfff96b6a2e45c818f96f60-json.log.9\r\n```\n\n그러니까 이 예제에서 볼 수 있듯이, Docker는 최대 10개의 로그 파일만 유지하고, 그 크기가 우리가 원하는 50 Kibibytes(= 52K)를 초과하지 않는 것을 확인할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## PID\n\n요청 시, 컨테이너가 호스트와 PID 주소 공간을 공유할 수 있도록 설정할 수 있습니다. 이를 가능하게 하는 옵션은 다음과 같습니다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: ps -a\n    pid: \"host\"\n  second:\n    image: alpine\n    command: ps -a\nEOF\n$ docker-compose up \nCreating network \"mediumcom_default\" with the default driver\nCreating mediumcom_second_1 ... done\nCreating mediumcom_first_1  ... done\nAttaching to mediumcom_second_1, mediumcom_first_1\nsecond_1  | PID   USER     TIME  COMMAND\nsecond_1  |     1 root      0:00 ps -a\nfirst_1   | PID   USER     TIME  COMMAND\nfirst_1   |     1 root      0:07 /sbin/init\nfirst_1   |     2 root      0:00 [kthreadd]\nfirst_1   |     3 root      0:00 [rcu_gp]\nfirst_1   |     4 root      0:00 [rcu_par_gp]\nfirst_1   |     6 root      0:00 [kworker/0:0H-ev]\nfirst_1   |     8 root      0:00 [mm_percpu_wq]\nfirst_1   |     9 root      0:00 [rcu_tasks_rude_]\nfirst_1   |    10 root      0:00 [rcu_tasks_trace]\nfirst_1   |    11 root      0:22 [ksoftirqd/0]\nfirst_1   |    12 root      0:10 [rcu_sched]\nfirst_1   |    13 root      0:07 [migration/0]\nfirst_1   |    15 root      0:00 [cpuhp/0]\nfirst_1   |    16 root      0:00 [cpuhp/1]\n...\n```\n\n이것은 컨테이너 내에서 호스트 프로세스를 관리하고(포함하여 종료)할 수 있다는 의미이므로 이 옵션을 사용할 때 주의해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 포트\n\n가장 인기 있는 옵션 중 하나인 이 기능을 사용하면 컨테이너 내부의 포트를 호스트로 게시할 수 있습니다 (컨테이너가 이미 \"호스트\" 모드에서 실행 중이지 않은 경우).\n\n예를 들어, 다음과 같이 게시하려는 경우를 생각해 봅시다:\n- 포트 3000을 임의의 포트로\n- 포트 범위 3005부터 3010까지\n- 로컬호스트의 포트 80을 포트 80으로만\n- 모든 호스트 인터페이스의 포트 443을 포트 443으로\n- 호스트의 포트 3011을 UDP만을 사용하여 포트 9876로\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 10\n    ports:\n     - 3000\n     - 3005-3010\n     - 127.0.0.1:80:80\n     - 443:443\n     - 9876:3011/udp\nEOF\n$ docker-compose up -d\n중복 컨테이너 \"mediumcom_second_1\"를 제거하는 중\nmediumcom_first_1이 시작되었습니다. ... 완료\n$ docker ps --format '{.Ports}'\n127.0.0.1:80-\u003e80/tcp, 0.0.0.0:443-\u003e443/tcp, 0.0.0.0:61290-\u003e3000/tcp, 0.0.0.0:61292-\u003e3005/tcp, 0.0.0.0:61293-\u003e3006/tcp, 0.0.0.0:61294-\u003e3007/tcp, 0.0.0.0:61295-\u003e3008/tcp, 0.0.0.0:61296-\u003e3009/tcp, 0.0.0.0:61291-\u003e3010/tcp, 0.0.0.0:9876-\u003e3011/udp\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 프로필\n\n\"프로필\"은 컴포즈 파일 내에서 역할을 분리할 수 있는 멋진 제어 메커니즘입니다. 우리가 컴포즈 파일 내에서 일부 컨테이너가 매우 특정한 설정하에서만 실행되거나 필요할 때만 실행되도록 원한다고 가정해 봅시다 (즉, \"프로필\"이라고도 함). 이것이 할 수 있는 것입니다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: nginx\n  second:\n    image: alpine\n    command: wget http://first\n    profiles: [\"debug\"]\nEOF\n$ docker-compose up -d\n네트워크 \"mediumcom_default\"를 기본 드라이버로 생성 중\nmediumcom_first_1 생성 완료\n$ # 보세요? nginx 컨테이너만 시작되었습니다. 이제 \"debug\"를 활성화해 봅시다\n$ docker-compose --profile debug up \nmediumcom_first_1 is up-to-date\nmediumcom_second_1 생성 완료\nmediumcom_first_1, mediumcom_second_1에 첨부\nsecond_1  | first(172.26.0.2:80)에 연결 중\nsecond_1  | 'index.html' 저장 중\nsecond_1  | index.html           100% |********************************|   615  0:00:00 남음\nsecond_1  | 'index.html' 저장됨\nfirst_1   | /docker-entrypoint.sh: /docker-entrypoint.d/가 비어 있지 않으므로 구성을 시도할 것입니다\n(first_이하 생략)\nmediumcom_second_1이 코드 0으로 종료됨\n```\n\n## 재시작\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨테이너의 재시작 정책을 정의하는 방법입니다 (no, always, unless-stopped, on-failure 중 하나를 선택).\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    restart: on-failure\n    command: sleep 4\n  second:\n    image: alpine\n    command: echo Hi `date`\n    restart: always\nEOF\n$ docker-compose up \nCreating network \"mediumcom_default\" with the default driver\nCreating mediumcom_first_1  ... done\nCreating mediumcom_second_1 ... done\nAttaching to mediumcom_first_1, mediumcom_second_1\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nmediumcom_second_1 exited with code 0\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nmediumcom_second_1 exited with code 0\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nmediumcom_second_1 exited with code 0\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nsecond_1  | Hi Tue Feb 1 17:21:11 CET 2022\nmediumcom_first_1 exited with code 0\r\n```\n\n## 보안 설정\n\n이 옵션을 사용하면 컨테이너의 SELinux 레이블을 제어할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```bash\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 30\n    security_opt:\n     - label:user:USER\n  second:\n    image: alpine\n    command: sleep 30\nEOF\n$ docker inspect mediumcom_first_1 --format '{ .Id }: SecurityOpt={ .HostConfig.SecurityOpt }'\n2808e4b2ac6a6870b372ecf06da5ce0217efdd6d14df16cef4b332e1d4fb9b6a: SecurityOpt=[label:user:USER]\n$ \n$ docker inspect mediumcom_second_1 --format '{ .Id }: SecurityOpt={ .HostConfig.SecurityOpt }'\ned4c417b27257cc9f793d5d3dad94672074859dba90effddd0cde49f12dd4115: SecurityOpt=\u003cno value\u003e\n```\n\n## stop_grace_period\n\n기본적으로 Docker는 SIGTERM을 수신한 후 10초 내에 컨테이너가 자연스럽게 중지되지 않으면 컨테이너를 강제로 종료합니다 (예: docker stop으로 컨테이너를 의도적으로 중지시킨 후). 이 시간 간격을 stop grace period라고 하며 구성할 수 있습니다.\n\n```bash\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sh -c 'while true; do sleep 5 \u0026 done'\n  second:\n    image: alpine\n    command: sh -c 'while true; do sleep 5 \u0026 done'\n    stop_grace_period: 1s\nEOF\n$ docker-compose up -d\nRecreating mediumcom_first_1  ... done\nRecreating mediumcom_second_1 ... done\n$ time docker stop mediumcom_first_1\nmediumcom_first_1\nreal 0m10.847s\nuser 0m0.205s\nsys 0m0.092s\n$ time docker stop mediumcom_second_1\nmediumcom_second_1\nreal 0m1.883s\nuser 0m0.192s\nsys 0m0.105s\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## stop_signal\n\n앞서 언급한 옵션에서 SIGTERM이 도커 컨테이너를 중지하는 기본 신호임을 이미 알았을 것입니다. 그러나 여러분은 `docker stop`이 컨테이너 응용 프로그램으로 원하는 사용자 정의 신호를 전송하도록 변경할 수 있습니다:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 60\n    stop_signal: SIGUSR1\nEOF\n$ docker-compose up -d\nCreating network \"mediumcom_default\" with the default driver\nCreating mediumcom_first_1 ... done\n$ docker inspect mediumcom_first_1 --format '{.Config.StopSignal}'\nSIGUSR1\n```\n\n## sysctls\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 옵션은 컨테이너의 네임스페이스된 커널 매개변수를 런타임에서 구성할 수 있게 합니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 60\n    sysctls:\n      net.core.somaxconn: 1024\n      net.ipv4.tcp_syncookies: 0\nEOF\n$ docker-compose up -d\n네트워크 \"mediumcom_default\" 생성 중, 기본 드라이버로 설정\nmediumcom_first_1 생성 중... 완료\n$ docker inspect mediumcom_first_1 --format '{json .HostConfig.Sysctls}'\n{\"net.core.somaxconn\": \"1024\", \"net.ipv4.tcp_syncookies\": \"0\"}\n```\n\n## ulimits\n\n컨테이너의 기본 ulimits를 재정의할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 60\n    ulimits:\n      nproc: 65535\n      nofile:\n        soft: 20000\n        hard: 40000\nEOF\n$ docker-compose up -d\nRecreating mediumcom_first_1 ... done\n$ docker inspect mediumcom_first_1 --format '{json .HostConfig.Ulimits}'\n[{\"Name\":\"nproc\",\"Hard\":65535,\"Soft\":65535},{\"Name\":\"nofile\",\"Hard\":40000,\"Soft\":20000}]\n```\n\n## userns_mode\n\n너무 깊게 파고들지 않고 Docker 데몬에서 사용자 네임스페이스를 활성화한 경우, 단일 컨테이너에서 사용자 네임스페이스를 비활성화하게 하는 옵션입니다. `userns_mode: \"host\"`를 사용하면 됩니다.\n\n## user\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨테이너 응용프로그램이 특정 사용자로 실행되도록 하려면 어떻게 하시겠습니까?\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: whoami\n    user: nobody\nEOF\n$ docker-compose up \nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | nobody\nmediumcom_first_1 exited with code 0\n```\n\n## working_dir\n\n도커 파일에서 본 적이 있을 것입니다. 이를 사용하면 컨테이너의 랜딩 경로(PWD)를 재정의할 수 있습니다. 이를 통해 엔트리포인트와 명령이 절대 경로를 사용하지 않는 경우에도 동작을 변경할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: pwd\n    working_dir: /my/custom/medium/dir\nEOF\n$ docker-compose up \nmediumcom_first_1 컨테이너 다시 생성 중... 완료\nmediumcom_first_1에 연결 중\nfirst_1  | /my/custom/medium/dir\nmediumcom_first_1 코드 0으로 종료됨\n```\n\n## 도메인 이름\n\n당신의 컨테이너는 호스트명과 도메인명을 가지고 있다는 것을 아시죠. 호스트 모드가 아닐 때, 호스트명은 컨테이너의 ID와 동일하며, 도메인명은 예상대로 없을 것입니다. 도메인명을 설정하려면 다음과 같이 하세요:\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: hostname -f\n    domainname: cristovaocordeiro.medium.com\nEOF\n$ docker-compose up\nmediumcom_first_1 컨테이너 다시 생성 중... 완료\nmediumcom_first_1에 연결 중\nfirst_1  | 6e900c697939.cristovaocordeiro.medium.com\nmediumcom_first_1 코드 0으로 종료됨\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 호스트이름\n\n당연히 도메인 이름을 설정할 수 있다면 컨테이너의 호스트 이름도 설정할 수 있습니다. 이렇게 하면 기본적으로 제공되는 \"충격적인\" ID 형식 대신 호스트 이름을 사용할 수 있습니다 😜\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: hostname -f\n    hostname: test-container\nEOF\n$ docker-compose up \nRecreating mediumcom_first_1 ... done\nAttaching to mediumcom_first_1\nfirst_1  | test-container\nmediumcom_first_1 exited with code 0\r\n```\n\n## ipc\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨테이너의 프로세스 간 통신을 관리할 수 있습니다(성능 조정 목적). 이 옵션을 통해 컨테이너의 IPC 네임스페이스를 설정할 수 있습니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: sleep 30\n    ipc: shareable\nEOF\n$ docker inspect mediumcom_first_1 --format '{json .HostConfig.IpcMode}'\n\"shareable\"\n```\n\n## mac_address\n\n원하는 컨테이너에 사용자 정의 MAC 주소를 설정할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\n버전: \"3\"\n서비스:\n  first:\n    이미지: alpine\n    명령: ifconfig eth0\n    mac_address: 00:ab:cd:12:34:56\nEOF\n$ docker-compose up \nmediumcom_first_1 컨테이너 다시 생성 중... 완료\nmediumcom_first_1에 연결 중\nfirst_1  | eth0 Link encap:Ethernet  HWaddr 00:AB:CD:12:34:56  \nfirst_1  | inet addr:172.29.0.2 Bcast:172.29.255.255 Mask:255.255.0.0\nfirst_1  | UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\nfirst_1  | RX packets:2 errors:0 dropped:0 overruns:0 frame:0\nfirst_1  | TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\nfirst_1  | collisions:0 txqueuelen:0 \nfirst_1  | RX bytes:200 (200.0 B)  TX bytes:0 (0.0 B)\nfirst_1  | \nmediumcom_first_1가 코드 0으로 종료됨\n```\n\n## 특권적\n\n위에서 \"특권적\" 컨테이너 상태를 몇 번 다뤘습니다. 간단히 말하면, (!!) 확실히 확신이 있고 컨테이너에 가능한 모든 기능을 부여하고 싶다면 (따라서 호스트 장치 및 기타 자원에 액세스 할 수 있음), 이 옵션을 사용할 수 있습니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\n버전: \"3\"\n서비스:\n  first:\n    이미지: alpine\n    명령: sh -c 'ls /dev/ | wc -l'\n  second:\n    이미지: alpine\n    명령: sh -c 'ls /dev/ | wc -l'\n    특권적: true\nEOF\n$ docker-compose up \nmediumcom_first_1 컨테이너 다시 생성 중... 완료\nmediumcom_second_1 컨테이너 다시 생성 중... 완료\nmediumcom_first_1에 연결 중, mediumcom_second_1에 연결 중\nfirst_1  | 15\nsecond_1  | 150\nmediumcom_first_1가 코드 0으로 종료됨\nmediumcom_second_1가 코드 0으로 종료됨\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 읽기 전용\n\n컨테이너를 실행할 때 읽기 전용 이미지 레이어 위에 쓰기 가능한 레이어가 생성된다는 사실을 알고 계실 겁니다. 그러나 이 쓰기 가능한 레이어를 읽기 전용으로 바꿀 수도 있습니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: touch /tmp/test\n  second:\n    image: alpine\n    command: touch /tmp/test\n    read_only: true\nEOF\n$ docker-compose up \nmediumcom_first_1  ... done\nmediumcom_second_1 ... done\nmediumcom_first_1, mediumcom_second_1에 연결 중\nsecond_1  | touch: /tmp/test: 읽기 전용 파일 시스템\nmediumcom_first_1 코드 0으로 종료\nmediumcom_second_1 코드 1로 종료\n```\n\n## shm_size\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨테이너가 사용할 수 있는 공유 메모리 양을 지정할 수 있습니다.\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    command: df -h /dev/shm\n    shm_size: 123M\nEOF\n$ docker-compose up \nmediumcom_first_1 컨테이너를 다시 생성 중... 완료\nmediumcom_first_1에 연결 중\nfirst_1  | 파일 시스템                크기      사용함 사용 가능함 사용률 마운트된 위치\nfirst_1  | shm                     123.0M         0    123.0M   0% /dev/shm\nmediumcom_first_1은 코드 0으로 종료됨\n```\n\n## stdin_open\n\n이는 docker run의 -i에 해당합니다. 이를 사용하여 호스트와 컨테이너 간 상호작용이 가능한 인터랙티브 세션을 만들 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```bash\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    stdin_open: true\nEOF\n$ docker-compose up -d\nRecreating mediumcom_first_1 ... done\n$ docker attach mediumcom_first_1 \necho Hello, I am sending commands to the container\nHello, I am sending commands to the container\nexit\n```\n\n위와 같이 컨테이너와 상호 작용하고 있지만 호스트와 컨테이너 사이에 실제로 터미널 세션이 없습니다... 간단히 말해서 파이프일 뿐입니다.\n\n## tty\n\n이것은 도커 실행에서의 -t와 동등합니다. 컨테이너에 가상 tty를 할당하고 stdin_open과 결합할 때 유용합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ cat \u003edocker-compose.yml \u003c\u003cEOF\nversion: \"3\"\nservices:\n  first:\n    image: alpine\n    stdin_open: true\n    tty: true\nEOF\n$ docker-compose up -d\nmediumcom_first_1 컨테이너를 다시 생성합니다... 완료\n$ docker attach mediumcom_first_1 \n/ # echo now this is a real terminal\nnow this is a real terminal\n/ # sleep 5\n^C\n/ # echo $?\n130\n/ # exit\n```\n\n이제 우리는 실제 터미널과 상호 작용하는 세션을 가지고 있습니다. 컨테이너 안에서 원하는 일을 할 수 있어요.\n\n우와... 정말 긴 기사였죠. 죄송합니다. 밝은 면에서 말하면, 여러 기사를 넘나들며 다양한 컴포즈 파일 옵션이 무엇을 하는지 찾아보지 않아도 되겠죠?\n\n스웜 모드에서 서비스에 특정한 옵션(변수 치환 및 확장 필드 같은 고유한 구조적 노하우)을 일부 뺐습니다. 이것들은 선택 사항이며, 다른 기사에서 다룰 수 있어요. \n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 테이블 태그를 마크다운 형식으로 변경해드렸습니다.","ogImage":{"url":"/assets/img/2024-06-23-TheWholeShebangComposeFiles_0.png"},"coverImage":"/assets/img/2024-06-23-TheWholeShebangComposeFiles_0.png","tag":["Tech"],"readingTime":43},{"title":"2024년 최신 AWS API Gateway 사용 방법 및 기능 완벽 가이드","description":"","date":"2024-06-23 00:28","slug":"2024-06-23-AWSAPIGateway","content":"\n\n## AWS API Gateway를 효과적으로 사용하는 필수 팁\n\n![AWS API Gateway](/assets/img/2024-06-23-AWSAPIGateway_0.png)\n\n# 소개\n\n모놀리식 또는 마이크로서비스 아키텍처를 사용하더라도 API에 접근하기 위한 중앙 진입점은 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기업에서는 비즈니스의 다른 부분에 작업을 수행하는 여러 팀이 있고, 각 팀은 다른 애플리케이션에 서비스를 노출하기 위해 API를 구현합니다.\n\n시간이 지나면서 조직의 아키텍처에 대한 포괄적인 시각 없이, API 진입점, 트래픽 관리, 보안, 그리고 이러한 제어를 구현하기 위한 규칙이 없다는 문제에 직면할 수 있습니다. 이러한 도전은 특히 인터넷을 통해 상호 작용이 발생할 때 특히 어렵습니다.\n\n본 문서는 HTTP 기반 애플리케이션 상호 작용에서의 일반적인 도전 과제를 강조하고, API 게이트웨이가 이러한 문제에 대해 어떻게 대응할 수 있는지에 대해 살펴봅니다. 구체적으로 AWS API 게이트웨이 사용에 중점을 두고 구현하기 전에 알아야 할 사항에 대해 설명하겠습니다.\n\n# API 게이트웨이가 왜 필요한가\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현대 소프트웨어 아키텍처는 클라이언트가 데이터를 사용하고 생성하는 방법을 제어하고 동시에 보호 기술을 구현하는 인프라 요소가 필요합니다.\n\n이 토론에서 자주 물들어 있는 질문은 API 게이트웨이가 이 보호와 분할을 구현하는 유일한 해결책인가요? 확실한 대답은 아니에요.\n\n역 프록시나 로드 밸런서를 사용할 수 있지만 네트워킹과 관련한 여러 이유로 API 게이트웨이가 선호됩니다.\n\nAPI 게이트웨이는 OSI 모델의 응용 계층(레이어 7)에서 작동하여 기본 SSL 종료나 백엔드 인스턴스 간 요청 분배 이상의 고급 기능을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAPI Gateway 솔루션은 인증 및 권한 부여, 속도 제한/쓰로틀링, 액세스 로깅, HTTP 프로토콜에 대한 자세한 내용, 회로 차단기 구현 등과 같은 책임을 통합합니다.\n\nAPI Gateway를 네트워킹 아키텍처에서 DMZ와 비교할 수 있습니다.\n\n클라우드 컴퓨팅이 급부상함에 따라 소프트웨어 아키텍처 프로토타입은 레고 블록을 사용하여 구축하는 것과 같습니다. 핵심은 요구 사항과 기술을 기존 자원과 도구로 결합하는 것입니다.\n\n인터넷을 통해 API를 노출시키기 위해 여러 솔루션을 유지하고 싶지 않다면, API Gateway가 최선의 방법입니다. AWS를 사용하고 하드 제한이 문제가 되지 않는다면, AWS API Gateway가 강력한 선택입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음에는 귀하의 요구 사항에 가장 가까운 옵션을 선택하는 방법에 대해 더 자세히 설명하겠습니다.\n\n# 어떤 종류의 API 게이트웨이가 필요할까요?\n\n좋은 시작점은 AWS API Gateway 문서를 읽는 것입니다. 여기에서 REST API와 HTTP API 간의 선택 사항에 대한 자세한 내용을 찾을 수 있습니다.\n\n본 문서에서 읽을 수 있는 것과 똑같은 내용을 설명할 의도는 없지만, 리전별, 엣지, 또는 프라이빗 API 게이트웨이와 같은 엔드포인트 유형에 대한 개념을 깊이 이해하는 것의 중요성을 강조하고 싶습니다. REST API 또는 HTTP API 인스턴스에서 사용할 수 있는 각 유형에 대해 알아보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인스턴스 유형에 대한 간단한 설명은 다음과 같습니다:\n\n- 보안, 관리 및 인증 기능이 더 필요하고 수요가 지리적으로 분산되어 있다면 (인터넷을 통해) REST API 인스턴스를 사용하세요(엣지 최적화, REST API의 기본 값).\n- 동일 지리적 지역 내에서 API Gateway를 내부적으로 사용하고 수요가 낮다면 HTTP API 인스턴스(지역)를 사용하세요.\n- VPC 내에서 사용하는 경우 VPC 엔드포인트를 통해 REST API 인스턴스를 사용하세요.\n\n실제 예제를 통해 엣지 최적화 또는 지역 AWS API Gateway 인스턴스를 선택하는 차이를 보여주는 것이 중요합니다.\n\n저는 PetStore 예제를 사용하여 미국 동부 버지니아 (us-east-1) 지역에 두 개의 AWS API Gateway 인스턴스를 생성했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-AWSAPIGateway_1.png)\n\n첫 번째 인스턴스(ID w43fgx5wk6)는 엣지 최적화되었고, 두 번째 인스턴스(ID 16hx5blsm5)는 리전 최적화되었습니다.\n\nAWS API 게이트웨이 설명서에 따르면 엣지 최적화는 \n\n또한, 이 정보를 HTTP 헤더 응답을 검사하여 확인할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![AWS API Gateway](/assets/img/2024-06-23-AWSAPIGateway_2.png)\n\nx-amz-cf-pop 헤더는 예약된 HTTP 헤더이며, 이를 검사하여 엣지 최적화된 AWS API Gateway를 확인할 수 있습니다.\n\n이 ID들과 관련이 있는 POP (Points of Presence) 목록에 대해 더 많은 정보가 필요합니다. 하지만 구체적으로 링크에서 ID G1G51-P2를 발견했습니다.\n\n![AWS API Gateway](/assets/img/2024-06-23-AWSAPIGateway_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지역 인스턴스를 분석하면이 유형의 인스턴스가 POP을 통과하지 않는 것을 확인할 수 있습니다.\n\n![AWS API Gateway](/assets/img/2024-06-23-AWSAPIGateway_4.png)\n\n## 각각의 지연 시간은 무엇인가요?\n\n먼저, 각 AWS 지역과 관련된 지연 시간을 이해해야합니다. 이 측정을 위해 https://clients.amazonworkspaces.com/Health.html을 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-AWSAPIGateway_5.png\" /\u003e\n\n위의 이미지를 보면 가장 가까운 지역은 남아메리카(상파울루)입니다. 이 정보를 기반으로 지리적으로 분산된 지연 시간을 확인하여 엣지 최적화된 AWS API 게이트웨이 인스턴스와 지역별 인스턴스의 장점을 비교할 수 있습니다.\n\n측정을 위해 저는 인터넷을 통해 전 세계의 다른 지역에서 클라이언트 경험 액세스를 시뮬레이션하는 데 사용되는 Pingdown을 사용합니다.\n\n지연 시간을 비교하기 위해 북아메리카, 남아메리카 및 아시아에서 엣지 최적화된 인스턴스 및 지역별 인스턴스에 액세스를 시뮬레이션했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 이미지는 엣지 최적화 인스턴스 (w43fgx5wk6)에 대한 결과를 보여줍니다.\n\n![AWS API Gateway](/assets/img/2024-06-23-AWSAPIGateway_6.png)\n\n북미와 라틴 아메리카 사이의 응답 시간에 주목해 주시기 바랍니다. 두 지역 간의 거리를 고려할 때, 약 20ms 차이는 미미합니다.\n\n아시아의 경우 응답 시간이 상당히 높으며, 숫자를 더 자세히 조사해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 이미지는 이전에 제시된 것과 유사하며, AWS 지역 간의 내 지연 시간을 보여줍니다. 특히, 도쿄까지의 지연 시간은 732밀리초입니다.\n\n![이미지](/assets/img/2024-06-23-AWSAPIGateway_7.png)\n\n도쿄에서 시작된 요청으로 PetStore API를 호출하는 PingDown과 비교했을 때, 도쿄에서 미국 동부 버지니아 북부까지의 지연 시간이 760밀리초임을 확인할 수 있습니다. 흥미롭게도, 도쿄에서 버지니아까지의 지연 시간은 남아메리카에서 도쿄까지의 지연 시간과 유사합니다.\n\n![이미지](/assets/img/2024-06-23-AWSAPIGateway_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n28ms의 델타에서 주요 포인트는 대부분의 시간이 네트워크 왕복 시간에 소비된다는 것입니다. 이러한 숫자들은 다양한 위치에서 아시아로의 요청 지연 시간에 대한 소중한 통찰을 제공합니다.\n\n싱가포르, 홍콩, 시드니 등 아시아의 다른 위치들은 더 나은 지연 시간 값을 보여줍니다. 여기서 중요한 점은 아메리카에서 아시아로의 요청은 적어도 이 간단한 예에서 더 높은 지연 시간 패널티가 부과된다는 것입니다. 기반 시설과 API 배포를 계획할 때 이 정보를 염두에 두세요.\n\n지역별 인스턴스에 관한 이미지는 다음과 같습니다.\n\n![이미지](/assets/img/2024-06-23-AWSAPIGateway_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n북미(로컬 API Gateway 인스턴스가 실행 중인 곳)에서 멀어질수록 미리측된 밀리초 증가가 더 두드러집니다. 지연 시간은 북미에서 라틴 아메리카, 그리고 아시아로 이동함에 따라 거의 두 배로 증가하는 것 같습니다.\n\n이 분석 결과, 지역 또는 엣지 최적화된 AWS API Gateway 인스턴스 중에서 선택하는 것이 솔루션의 성능에 상당한 영향을 미친다는 것을 보여줍니다.\n\n중요한 주의 사항은 테스트 기간의 시간 창이 아주 짧다는 것입니다. 이러한 숫자를 제시하는 목적은 시간이 흐름에 따라 다양한 이유로 상당히 달라질 수 있는 파트너의 경험에 대한 지연 시간 영향을 설명하기 위한 구체적인 데이터를 제공하는 것입니다.\n\n이 관점은 중요하지만 AWS API Gateway를 효과적으로 사용하기 위해서는 다른 특성들을 이해해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 어떤 요구 사항이 있나요?\n\nAWS 문서에서 속한 제한에 관한 부분을 읽을 때 중요합니다. 특히, 제한을 증가 요청할 수 없는 제한에 대한 부분이요. AWS API Gateway의 경우, 여기에서 이러한 제한을 확인할 수 있어요.\n\n귀하의 경우에 관련된 특정 제한 사항은 다를 수 있기 때문에, 사용 가능한 제한 사항과 귀하의 요구 사항을 신중히 맞추어 정보를 얻을 수 있도록 하는 것이 중요해요.\n\n고려해야 할 주요 제한 사항은 다음과 같아요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 할당량은 문서에 따라 증가될 수 있지만, 귀하의 계정과 지역에 있는 모든 AWS API Gateway 인스턴스를 고려하여 10K RPS의 양에 주의를 기울이고 싶습니다.\n\n고려해야 할 또 다른 점은 문서에서 할당량이 증가될 수 있다고 명시되어 있지만, 이를 쉽거나 싸게 처리하기 어려울 수 있습니다. 어떤 경우에는 AWS 지원팀이 요청을 정당화하고 해당 지역에서 서비스에 영향을 미치지 않도록 보장하기 위해 상세 증거를 요청할 수 있습니다.\n\nAWS API Gateway REST API 인스턴스의 최대 타임아웃은 대략 29초입니다. 대부분의 API 통신에는 충분합니다. 그러나 장기 실행이 포함된 경우 해당 제한을 염두에 두시기 바랍니다.\n\n최근 AWS는 타임아웃을 증가시킬 수 있는 가능성을 발표했지만, 이는 계정 수준의 쓰로틀 할당량 제한을 감소시키는 데에 처벌이 따릅니다. 문서에서는 쓰로틀링 할당량이 얼마나 감소할 지 명시되어 있지 않지만, 이는 중요한 고려 사항입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRPS는 동일한 계정 및 지역의 모든 API 게이트웨이 인스턴스의 요청 합계를 계산하는 것과 같이 API 키도 동일한 규칙을 따릅니다. 그러나 중요한 차이점은 API 키의 수를 늘릴 수 없으며, 모든 인스턴스 사이에서 공유되는 API 키의 하드 제한이 10K개이다.\n\n이 할당량에 대한 주요 포인트는 쓰로틀링과의 직접적인 관련성입니다. 쓰로틀링은 다양한 특성이 있으며, 제가 요약해 보겠습니다.\n\n쓰로틀링은 계정 수준에 적용될 수 있습니다.\n\n이전에 언급한대로, 계정 수준의 쓰로틀링은 모든 AWS API 게이트웨이 인스턴스의 초당 요청을 제한하기 위해 초당 모든 요청을 합계하여 적용됩니다. 이 쓰로틀링에 대해 우리는 제어할 수 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클라이언트별로 쓰로틀링을 적용하는 유일한 방법은 클라이언트를 API 키와 연관시키는 것입니다. 프로덕션 환경에서 1만 개의 API 키를 활성화하는 것은 불가능하지 않은 것으로 보입니다. 서로 다른 기준에 맞게 API 키를 관리할 수 있으므로 한 클라이언트나 클라이언트와 엔드포인트에 API 키를 사용할 수 있습니다.\n\n이러한 API 키를 쓰로틀링 제한과 연관시키는 중요한 점은 사용 계획 내에서 사용해야 한다는 것입니다.\n\n사용 계획의 할당량은 계정과 지역당 300개로 제한됩니다. 이 할당량은 증가시킬 수 있지만, 이러한 과정은 어려울 수 있고 AWS 지원팀에 상세 정보를 제공해야 할 수도 있습니다.\n\nAWS API Gateway 인스턴스를 프로토타입으로 만들어 클라이언트, 클라이언트-엔드포인트 또는 다른 전략별 API 키를 사용하려면 할당량을 초과하지 않도록 사용 계획과 API 키를 구현하고 연관시키는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 의견으로는 API 게이트웨이의 관련 기능으로 인해 클라이언트 당 쓰로틀링을 구현해야한다는 이 제한이 가장 어려운 것으로 생각됩니다. 따라서 이 제한이 솔루션에 영향을 미치지 않도록 주의하시기 바랍니다.\n\nAWS API 게이트웨이 인터페이스에서 API 키를 조회하거나 검색하려면 1만 개의 API 키에 도달하면 속도가 매우 느려질 것입니다. 반드시 관리용 API를 사용하여 이를 조회해야 할 것입니다.\n\n마지막으로, 관리용 API의 할당량이 매우 제한적이므로 이 제한도 주의 깊게 확인하셔야 합니다.\n\n# 제약사항은 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특정 제약 사항은 다음과 같은 유형의 제한 사항을 만날 경우 파트너들과의 갈등을 야기할 수 있습니다:\n\n- 감사를 위해 요청과 응답을 저장해야 할 경우, CloudWatch에 저장할 수 있는 페이로드 크기 제한이 문제를 일으킬 수 있습니다. 이 경우 AWS API Gateway 외부에서 이 감사를 구현해야 할 수도 있습니다.\n\n- RFC 3986 (통합 자원 식별자-URI)에 따르면 세미콜론은 특정 목적을 위해 예약된 문자입니다. URI에 세미콜론이나 파이프(|)가 포함되면 요청 처리가 복잡해질 수 있습니다.\n\n- REST API의 AWS API Gateway의 기본 설정은 \"백엔드 통합에 전달하기 전에 URL 인코딩된 요청 매개 변수를 디코딩(decoding)\"하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 특별한 문제는 여러분의 파트너가 URL 인코딩을 구현해야 한다는 것입니다. 이를 역방향 프록시를 사용하여 해결하려고 하면 어려움을 겪을 수 있습니다. 이 상황을 피하기 위해 AWS Lambda@Edge와 CloudFront를 사용할 수 있지만, 과도한 엔지니어링에 주의해야 합니다.\n\n역방향 프록시 시나리오를 모의하기 위해 edge-optimized API Gateway와 URL https://w43fgx5wk6.execute-api.us-east-1.amazonaws.com/test를 사용했습니다. beeceptor.com을 사용하여 외부 역방향 프록시를 정의했는데, 다음과 같이 구성했습니다:\n\n![이미지](/assets/img/2024-06-23-AWSAPIGateway_10.png)\n\nhttps://apigateway.free.beeceptor.com/pets를 호출하면 결과가 이렇게 나옵니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-23-AWSAPIGateway_11.png)\n\n특정 상황에서 확인해야 할 다른 제약 사항이 있습니다. 결정을 내리기 전에 api-gateway-known-issues에서 더 많은 정보를 읽어보세요.\n\n# 결론\n\n여기서는 AWS API Gateway를 사용하기 전에 공부하고 이해해야 할 중요한 요점을 설명했습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS API Gateway은 제품 환경에서 사용할 수 있는 견고한 솔루션이에요. 어떤 솔루션을 채택하기 전에 요구 사항을 이해하는 것이 중요해요. AWS API Gateway를 사용하기로 결정하는 것도 마찬가지죠.\n\n계정 당 및 리전 당 10K RPS와 관련된 할당량은 많은 경우에 적합하지만, 언제 아키텍처의 수명이 끝날지 예상하고 항상 준비해두는 것이 중요해요.\n\n이러한 통찰력이 AWS API Gateway를 효과적으로 사용하는 데 도움이 되기를 바라요.","ogImage":{"url":"/assets/img/2024-06-23-AWSAPIGateway_0.png"},"coverImage":"/assets/img/2024-06-23-AWSAPIGateway_0.png","tag":["Tech"],"readingTime":9},{"title":"AWS에서 이벤트 기반 아키텍처에 분산 회로 차단기 적용 방법","description":"","date":"2024-06-23 00:26","slug":"2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS","content":"\n\n\n![image](\"https://miro.medium.com/v2/resize:fit:1280/1*gGh7HhACzjtw6wplLPUyQQ.gif\")\n\n# 소개\n\n저는 이벤트 기반 아키텍처에서 이벤트 실패를 처리하는 방법에 대해 발표 자료를 준비하고 있었습니다. 어느 순간에 이를 설명할 때 회로 차단기가 필요한 이유에 대해 깊이 들어가게 되었습니다. 제 프로젝트에서 Elasticache를 기반으로 한 사용자 정의 구현을 사용했다는 것을 깨달았습니다. 그들을 설정하는 더 \"가벼운\" 방법에 대해 고민하기 시작했을 때, 서버리스 아키텍처에서 회로 차단기를 설정하는 메커니즘이 없다는 것을 깨달았습니다. 좀 더 연구해보고 이 주제에 대한 제 생각을 공유하려고 합니다.\n\n## 왜 서버리스가 특별한가요?\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n서킷 브레이커는 상태를 가지고 있습니다. 호출하기 전에 해당 상태를 확인하고 모든 요청을 추적해야 합니다. 왜냐하면 서킷 브레이커를 단일 호출 기반이 아니라 실패율(RATE) 기준으로 열기 때문입니다.\n\n우리는 람다 인스턴스 전체에 분산된 상태 대신 단일 위치에 상태를 추적해야 합니다. 다시 처음으로 돌아가 봅시다.\n\n# 왜 서킷 브레이커가 필요한가요?\n\n## 시나리오\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이벤트 처리를 상상해보세요. 여기서는 대기열에서 작업을 가져와서 제3자로부터 데이터를 로드한 다음 데이터에 대해 \"무언가\"를 수행합니다. 이제 이 데이터를 DynamoDB 테이블에 지속시키기로 했다고 가정해 봅시다.\n\n![이미지](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_0.png)\n\n## 모든 것이 실패할 때\n\n어느 날, 우리의 3rd 파티가 좋지 않은 날을 보내서 실패하기 시작할 수도 있습니다. 그 순간, 그것은 완벽할 것이고 모두가 우리가 예의 바르게 3rd 파티 시스템을 사용하는 데 존경을 기울이면 좋을 것입니다. 우리는 그들이 많은 압박을 받고 있다는 것을 알았으므로 그들에게 계속해서 요청을 보내지 않는 것이 좋을 것입니다. 돈과 자원, 그리고 SRE 팀 멤버들의 신경을 아끼게 되겠죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](https://miro.medium.com/v2/resize:fit:1280/1*d6R2_OewGnnrbMdLNLht8A.gif)\n\n## 그럼 우리가 할 수 있는 것은 무엇일까요? 백오프 아이디어\n\n첫 번째 떠오르는 아이디어는 소비자들에게 백오프 전략을 적용하는 것입니다. 받은 메시지와 실패한 메시지의 가시성 제한 시간을 변경할 수 있습니다. 여기 명심해야 할 몇 가지 중요한 점이 있습니다:\n\n- 최대 지연 시간 값을 설정하는 것,\n- 그리고 지터를 적용하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같은 메시지를 받았다고 가정하고 있다면, ChangeMessageVisibility API를 사용하여 간단히 처리할 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_1.png)\n\n우리는 메시지의 처리 시도 횟수에 대한 정보를 포함하고 있는 ApproximateReceiveCount 값을 추출하고, 이를 기반으로 백오프와 지터를 계산할 수 있습니다. 아래 스니펫과 같이요.\n\n다음으로, 각 레코드의 receiptHandle을 사용하여 AWS SQS SDK를 이용해 시각성 제한 시간을 변경해야 합니다. 아래 코드 스니펫처럼요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결과\n\n백오프는 메시지를 확장된 간격으로 다시 시도합니다. 이를 통해 루프에서 항상 같은 메시지를 처리하지 않고, 제3자 시스템에 호흡 공간을 줄 수 있어서 그 사이에 좋아질 것을 희망할 수 있습니다. 또한, 최대 재시도가 제한된 경우 죽은 편지 대기열을 저장할 수 있습니다.\n\n자랑스럽게 여겨질 수 있고, 자신을 칭찬할 수 있지만, 우리는 크게 변하지 않았습니다. 심각한 중단이 있을 경우 AWS는 SQS 소비자 호출을 제한할 수 있지만, 고 처리량 시스템의 경우 3rd party 시스템 관점에서는 여전히 같은 상황에 있습니다.\n\n더 심각한 문제는 이 모든 람다 호출에 돈을 쓰고 있으며, 우리의 제3자 시스템이 다운된 경우 호출은 우리의 타임아웃만큼 느려져 많은 비용이 발생할 수 있습니다. 이를 어떻게 방지할 수 있을까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 회로 차단기 이용하기\n\n회로 차단기는 전기 회로의 회로 차단기처럼 작동합니다. 문제를 감지하면 차단이 되어 더 이상 요청이 전달되지 않습니다. 서드 파티 시스템이 다시 온라인 상태가 되면 회로를 닫고 싶습니다.\n\n그 현지 조사는 \"정찰\" 요청을 보내면서 반 열린 상태로 수행됩니다. 이 요청은 회로 차단기 뒤에 있는 시스템이 여전히 다운된 상태인지 확인하는 작은 그룹으로, 시스템이 다운된 경우 회로는 열린 상태를 유지하고 다시 작동하면 회로를 닫고 평상시로 돌아갑니다.\n\n아래 애니메이션을 살펴보시면 더 이해하기 쉬울 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래의 다이어그램을 확인하면 프로세스에 대해 여전히 헷갈리는 부분이 있을 수 있습니다.\n\n![다이어그램](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_2.png)\n\n# 게임의 서버리스 상태\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n서버에서는 크게 문제가 되지 않습니다. 회로 차단 장치 구현 중 하나를 사용할 수 있으니 걱정 마세요. 서버에 상태를 로컬로 저장합니다. 물론 모든 인스턴스가 동기화되지는 않겠지만, 보통 큰 문제가 되지는 않습니다. 서버리스의 경우 상황은 매우 다릅니다. 많은 인스턴스가 있고, 각 작은 인스턴스 간에 상태를 전달할 수 없습니다.\n\n이곳에서 주요 고려 사항은 무엇인가요?\n\n- 솔루션의 복잡성\n- 읽기 작업 전에 상태를 검사해야 하므로 솔루션 비용\n- 작업 후 호출 결과를 지속\n\n서버리스 공간에서 대다수 사용자에게 쉽게 작동할 수 있는 솔루션을 고민 중입니다. 일반적으로 저는 Circuit Breaker 상태를 Elasticache에 저장합니다. 왜냐하면 존재하고, 속도가 매우 빠르며 – 사용자 정의 구현 외에 – 사용하기 쉽기 때문입니다. 반면에 모든 서버리스 시스템이 VPC에서 실행되고 심한 부하를 겪지는 않는다는 것을 이해하고 있습니다. 그렇지만 여기서 가장 흥미로운 부분이 \"고부하\"입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인터넷에서 발견된 구현 방법들과 제가 생각해낸 것에 대해 살펴보겠습니다.\n\n# 일반적인 옵션: Jeremy Daly의 클래식\n\n서킷 브레이커에 관한 거의 모든 기사가 Jeremy Daly의 기사를 언급합니다... 그러니 시작해보죠.\n\n![이미지](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 사용 중이고 방금 말한 패턴입니다. 중앙 집중식 저장소에 상태를 가진 클래식 회로 차단기일 뿐입니다. 훌륭하게 작동하며 실전 검증을 받았습니다. 분산 시스템에서 회로 차단기를 설정하는 가장 좋은 방법이라고 믿습니다. 다음을 제공합니다:\n\n- 여러 CB를 지원하는 매우 세분화된 솔루션\n- 로직이 코드에 있기 때문에 대체값을 반환할 수 있습니다.\n- 어떤 이벤트 소스 매핑 및 호출 유형과도 사용할 수 있습니다.\n\n이 패턴은 Elasticache를 필요로 하므로 일반적으로 VPC도 필요합니다. VPC에서 솔루션을 구축하고 싶지 않다면 어떻게 할까요?\n\n## 비-VPC 변형\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDynamoDB 고려 사항\n저자는 비-VPC 람다와 함께 DynamoDB를 사용할 수도 있다고 언급합니다. 고수준 시스템에서 이 옵션을 고려할 가치가 있을까요? 물론, 이것은 귀하의 규모에 달려 있습니다. 왜냐하면:\n\n- 파티션당 1000 WCU 제한 - 따라서 1000 RPS 이상의 회로 차단기 상태를 유지하는 데 꼼수를 사용해야 합니다 (Tycko Franklin에게 그것을 지적해 준 것을 칭찬합니다)\n- 회로 차단기 유지의 비용은 고처럼 높을 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_4.png)\n\n대안적 접근 방식? Momento!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMomento를 사용하면 람다 함수를 VPC에 넣을 필요가 없고 동시에 비용을 절약할 수 있습니다. 또한 매우 확장 가능하고 저지연 솔루션이기도 합니다.\n\n![2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_5.png](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_5.png)\n\n## 주의할 점\n\n잘못된 구현\n인터넷을 뒤져본 결과 잘못된 구현이 많은 것 같습니다. 제가 잘못된 부분이 있다면 지적해주세요. 가장 인기 있는 구현조차도 분산 시스템에서 단일 인스턴스의 상태를 덮어씌우기 때문에 많은 문제를 야기할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n구현: https://github.com/gunnargrosch/circuitbreaker-lambda\n\n잘못된 정보 소스입니다\nSSM 및 헬스 체크 상태를 사용하라는 제안을 봤는데, 해당 구현에 들어가기 전 꼭 모든 호출 전에 SSM을 확인하지 말아주세요. 비용이 많이 발생할 수 있어요. 그러나 어떤 해결책은 있습니다. 아래 링크된 스레드를 살펴보세요.\n\n# ESM Circuit Breaker Patterns\n\n일부 회로 차단 방식은 이전 패턴만큼 범용적이지 않으며 ESM (이벤트 소스 매핑)으로 실행되는 이벤트 컨슈머에 특화되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Christoph Gerkens의 전문화된 ESM 회로 차단기\n\n이 문서는 흥미로운 아이디어를 다루고 있습니다. 계획은 SQS Consumer ESM을 회로 차단기로 사용하는 것입니다. 우리는 ESM 상태를 활성화/비활성화하여 회로를 열고 닫을 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_6.png)\n\n\"Half Open\" 상태와 \"스카웃 요청\"을 보낼 때, 작성자는 \"Trial Message Poller\"라는 추가 람다를 사용하는 것을 제안합니다. 이 람다는 큐에서 메시지 중 하나를 읽어 SQS Consumer 람다로 보냅니다. 결과에 따라 회로를 닫을지 열어둘지 결정하게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 우리의 람다에서 아무것도 할 필요가 없으며, 그것은 완전히 그 로직에서 분리되어 있다는 점에서 훌륭합니다.\n\n비용\n상점이 없으므로 저렴해야 할 텐데요, 맞죠? 저자는 고해상도 메트릭 사용을 권장합니다. 미처리 드리프트가 몇 분 동안 지속되는 차단기 문제를 피하려면 꼭 필요합니다. 동의합니다만, 여기서는 고처리량 처리 렌즈를 통해 보는 것이기도 합니다.\n\n이 경우 많은 메트릭을 수집하면 비용이 많이 들 수 있고, 이러한 메트릭을 저장하는 것은 신중하게 처리해야 합니다. PutMetricData API는 1000번의 호출당 0.01달러로 상당히 비싸니, EMF로 전환하는 것을 고려해볼 수 있습니다. 그 가격표와 매 호출 후 이벤트 추적을 고려하면 상태 저장과 함께 적절한 차단기를 사용하는 것이 더 저렴할 수 있다. 미리 계산해보세요.\n\n복잡성\n\"시험 메시지 폴러\"은 추가 복잡성을 도입하며 저는 유지하고 싶어하는 것이 아닙니다. 이것은 전체 솔루션과 결합돼 있어야 하며 다른 유형의 트리거와 재사용할 수 없습니다. SQS에서도 시각 제한 또는 부분 실패로 인한 잠재적인 문제가 있다고 상상할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n잠재적인 메시지 손실\n메시지가 대기열에서로드되지 않고 장기적이고 심각한 서드파티 오류의 경우, 우리는 메시지를 잃을 수 있습니다. 네, 메시지가 maxReceiveCount에 도달하지 않고 rententionPeriod가 경과하면 메시지가 데드 레터 대기열로 이동되지 않습니다.\n\n## 간소화된 ESM 회로 차단기\n\nChristoph Gerken의 논문에서 영감을 받아, 저는 그 구조적 패턴을 간소화하는 것을 고려했습니다.\n\n이 원리는 전체 회로 차단기 상태를 CloudWatch 경보 상태에 반영하고 이를 회로의 상태로 사용하는 것에 기반합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Screenshot](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_7.png)\n\n원본 글에 정의된 메트릭(호출 및 오류를 사용하여 실패율을 계산)은 기본적으로 무료로 고해상도로 제공되므로 우리는 이를 사용하여 실패율을 추적하고 10초 간격으로 경보를 정의할 수 있습니다. (이 솔루션은 여러분의 요구에 따라 어떤 경보라도 기반으로 작동할 수 있으며, ESM 관리자는 다양한 경보의 변경 사항을 듣고 있어야 합니다.)\n\nHalf-open 상태는 Step Functions를 통해 관리할 필요가 없습니다. CloudWatch 경보의 INSUFFICIENT_DATA 상태를 사용할 수 있습니다. 여기에는 한 가지 단점이 있습니다 — half-open 기간은 큐에서 가져온 단일 메시지 대신 SQS 소비자가 사용한 메시지의 제한된 샘플을 기반으로 합니다. 또한, TreatMissingData: missing을 사용하는 것이 중요합니다.\n\n```js\nFailureRateAlarm:\n  Type: AWS::CloudWatch::Alarm\n  Properties:\n    Metrics:\n      - Expression: \"100 * errors / MAX([errors, invocations])\"\n        Id: \"failureRate\"\n        Label: \"failureRate\"\n        ReturnData: true\n      - Id: \"errors\"\n        MetricStat:\n          Metric:\n            MetricName: Errors\n            Namespace: AWS/Lambda\n            Dimensions:\n              - Name: FunctionName\n                Value: !Ref YourFunction\n          Period: 10\n          Stat: Sum\n        ReturnData: false\n      - Id: \"invocations\"\n        MetricStat:\n          Metric:\n            MetricName: Invocations\n            Namespace: AWS/Lambda\n            Dimensions:\n              - Name: FunctionName\n                Value: !Ref YourFunction\n          Period: 10\n          Stat: Sum\n        ReturnData: false\n    EvaluationPeriods: 5\n    DatapointsToAlarm: 3\n    TreatMissingData: missing\n    Threshold: 80\n    ComparisonOperator: GreaterThanOrEqualToThreshold\n```\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상태 관리\n알람이 트리거되면 회로가 열리며 람다 호출이 발생하지 않습니다. 그럼 알람은 INSUFFICIENT_DATA 상태로 전환됩니다. 그 후에는 큐의 제한된 동시성 처리를 통해 \"스카웃 요청\"을 보낼 수 있으며, 실패한 후에는 처리가 성공적으로 이루어진 후에 서킷을 열거나 닫을 수 있습니다.\n\n![image](/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_8.png)\n\n기본 AWS 람다 메트릭을 사용할 경우, 새로운 접근 방식을 절약할 수 있지만, 이전 옵션에서의 \"메시지 손실 가능성\" 문제에 여전히 취약합니다.\n\n구현\nESM을 활성화하고 비활성화하는 것은 쉽습니다. 유일하게 누락된 것은 ESM에 메타데이터를 추가할 수 있는 옵션이었습니다. 해당 기능이 누락되었으므로 스택에 매개변수로 추가해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 구현은 go로 작성되었고 일부 사용자 지정 instrumentation 및 OTEL 통합이 되어 있어요. 하지만 여기 스니펫에서처럼 간단한 것을 사용할 수도 있어요.\n\n내 구현은 SQS를 기반으로 하고 있지만 모든 다양한 이벤트 주도형 ESMs 구성에 적응시킬 수 있어요. 작은 사용자 정의 후처리 후 반-열린 상태로 커스터마이즈된 구성을 이용해요.\n\n테스트\n해당 솔루션은 여러 다른 알람 구성을 이용해 FIS로 테스트했어요. 아래에서는 예제 알람 상태 전이의 동작을 확인할 수 있어요.\n\n이 접근 방식은 반-열린 상태로 이동하는 빈도를 제어하는 유연성이 부족하지만, 코드에 액세스할 수 없거나 람다 핸들러에 복잡성을 추가하고 싶지 않은 경우에는 좋아요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 요약\n\n분산 시스템에서 서킷 브레이커를 올바르게 구현하는 것은 매우 어려울 수 있으며 고려해야 할 다양한 트레이드오프와 접근 방식이 많이 있습니다. 경우에 따라 분산된 서킷 브레이커가 전혀 필요하지 않을 수도 있습니다. 예를 들어, 작은 람다 소비자 풀의 경우에는 서킷 상태 메모리가 충분할 수도 있습니다.\n\n만약 당신의 케이스에 해당하지 않는다면, 이 글이 당신에게 결정을 도와주거나 구현 중 고려해야 할 사항에 대한 아이디어를 제공해 줄 수 있기를 바랍니다. 아래에서는 당신을 위한 결정 트리를 만들어 보았습니다. 전통적인 접근 방식이 여전히 최선이라고 믿지만 ESM 기반 서킷 브레이커의 사용 사례도 볼 수 있습니다.\n\n해당 주제에 대해 토의하고 싶다면, #believeinserverless 커뮤니티에 가입하여 이곳에서 커뮤니티와 논의할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시간 내어 주셔서 감사합니다! 이 주제에 대한 여러분의 생각을 듣고 싶습니다! 연락을 주세요:\n\n## 부가 설명\n\n또 다른 접근법\n이곳에서 읽을 수 있는 Sheen Brisals가 시도한 Circuit Breakers with retries 및 archiving events에 대한 접근법: [https://sbrisals.medium.com/amazon-eventbridge-archive-replay-events-in-tandem-with-a-circuit-breaker-c049a4c6857f](https://sbrisals.medium.com/amazon-eventbridge-archive-replay-events-in-tandem-with-a-circuit-breaker-c049a4c6857f) 또는 여기서 저자가 아이디어를 제시하는 동영상을 시청하세요(멋진 이야기입니다):","ogImage":{"url":"/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_0.png"},"coverImage":"/assets/img/2024-06-23-DistributedCircuitBreakersinEvent-DrivenArchitecturesonAWS_0.png","tag":["Tech"],"readingTime":10},{"title":"AWS Glue CI CD 간소화하는 방법","description":"","date":"2024-06-23 00:23","slug":"2024-06-23-StreamliningAWSGlueCICD","content":"\n\n## 포괄적인 청사진\n\n끊임없이 변화하는 데이터 관리 환경에서, 생 데이터를 실행 가능한 통찰로 변환하는 것은 전 세계 비즈니스에게 중요합니다. AWS Glue는 바로 이를 위한 AWS 내의 서비스로, 추출(Extract), 변환(Transform), 로드(Load) 작업에 특화된 서비스입니다.\n\nGlue는 본질적으로 전통적으로 복잡하고 시간이 많이 소요되는 ETL 작업을 간편화하여 핵심 작업을 자동화하고 중요 인프라를 추상화하며 직관적인 인터페이스를 제공합니다.\n\n그러나 대부분의 클라우드 서비스와 마찬가지로 Glue ETL 작업의 테스트, 배포, 조정에는 코드 버전 관리, 의존성 관리, 인프라 설정 및 액세스 제어 등의 복잡성이 포함되어 여러 도전 과제가 발생합니다. 이러한 도전 과제를 해결하기 위해서는 AWS Glue에 특화된 잘 구조화된 CI/CD 전략이 필요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 블로그 포스트는 이러한 전략을 탐구합니다. 구체적으로, 우리는 AWS Glue CI/CD 워크플로우를 최적화하고 자동화하기 위해 설계된 포괄적인 청사진을 살펴봅니다. 이는 동반 GitHub 저장소를 통해 이용할 수 있습니다.\n\n# GitHub 저장소 개요\n\n이 청사진의 GitHub 저장소는 집단 학습 과정을 통해 생산되었으며, 주요 컨셉의 예시를 제공합니다. Glue 기반 데이터 레이크 구현의 출발점으로 활용하고 있으며, 데이터 엔지니어들의 교육을 가속화하고 팀원들과 함께 다양한 배포 접근 방식을 검증하는 데 도움이 됩니다. 이는 다음과 같이 구성되어 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\naws-glue-ci-cd-blueprint\n├──.github/\n   └──workflows/ (CI/CD configurations)\n├──infrastructure/\n   └──environments/ (deployment environment configurations)\n      └──dev/\n      └──prod/\n      └──qa/\n      └──staging/\n   └──modules/ (reusable infrastructure components)\n      └──athena/\n      └──core/\n      └──glue/\n├──src/ (ETL code written in Python)\n├──tests/ (unit tests for the Python code)\n├──...\r\n```\n\n주요 구성 요소와 프레임워크는 다음과 같습니다:\n\n- 지속적 통합/지속적 전달: GitHub Actions\n- 인프라스트럭처 코드: Terraform\n- 코드 품질 보증 (Python): Unittest + Pytest, Black 및 Flake8\n\n이 설계도를 활용하기 위해 도구를 숙달하는 것보다 개념을 잘 이해하는 것이 중요하다는 점을 강조할 가치가 있습니다. 예를 들어, GitHub Actions 코드는 쉽게 GitLab CI로 변환할 수 있습니다. Terraform과 AWS Cloud Formation에도 동일하게 적용되며, 선택한 프로그래밍 언어와 QA 도구에도 물론 그와 같이 적용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 청사진 시작하기\n\n아래 이미지를 살펴보세요. 인프라 및 Python 코드를 위한 두 개의 수영선이 있음을 알 수 있습니다. 이러한 코드 조각들은 데이터 파이프라인 개발 수명주기 동안 서로 다른 사람이 다루거나 적어도 구분된 시기에 처리되는 경험을 보여주고 있기 때문에 우리는 이들을 별도로 다루기로 결정했습니다. 일반적인 경험에 따르면 인프라는 어떤 ETL 작업을 배포하기 전에 프로비저닝되어야 합니다.\n\n![image](/assets/img/2024-06-23-StreamliningAWSGlueCICD_1.png)\n\n## 자동화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현대 데이터 팀은 데이터 파이프라인을 개발, 유효성 검사 및 전달하는 데 다른 환경을 사용합니다. 이 환경은 클라우드에서 실행되며 많은 연결된 리소스에 의존합니다. 자동화 없이 이러한 환경 간에 리소스 구성을 복제하는 것은 거의 불가능합니다. 그렇지만 청사진은 인프라 및 코드 품질 보증을 위한 자동화 안내를 제공합니다.\n\nIaC 측면에서 Terraform은 데이터 파이프라인과 관련된 모든 AWS 리소스를 설정하는 역할을 맡습니다. 예를 들어, S3 버킷, 최소 권한 IAM 역할, Glue 작업, 워크플로, 데이터 카탈로그를 공급하는 크롤러 및 Athena를 위한 잘 정의된 IAM 정책 등이 있습니다.\n\nETL 코드에 대해 단위 테스트, 형식, 및 린트 체크는 새로운 커밋이 Pull Requests에 푸시되거나 dev 및 main 브랜치로 병합될 때마다 실행되어 파이프라인을 깨뜨릴 수 있는 변경을 방지합니다. 그리고 모든 것이 잘 진행된다면 코드는 적절한 위치로 배포됩니다.\n\nGitHub에서 실행되는 단계는 GitHub Actions를 통해 구성됩니다. 자세한 내용은 aws-glue-ci-cd-blueprint/.github/workflows를 참조해 주세요; on-iac-로 시작하는 파일은 IaC의 CI/CD에 속하며 on-으로 시작하는 파일은 Python 코드의 CI/CD에 속합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여전히 개발자들은 특히 개발 환경(“배포 전략” 섹션에 설명된)을 사용할 때 Terraform, AWS CLI 및 품질 보증 명령을 로컬에서 실행할 수 있습니다.\n\n## 테스트\n\nTerraform 구성에는 세 가지 유형의 확인이 적용되며, 그 중 하나라도 실패하는 경우 인프라 배포 파이프라인이 즉시 중지됩니다 (참조용으로 iac-pr-against-dev.yaml 참조):\n\n- 스타일 확인: terraform fmt -check\n- 코드 정확성: terraform validate\n- 실행 계획 실현 가능성: terraform plan\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬 코드에는 세 가지 유형의 체크가 적용되며, 실패 시 배포 파이프라인을 중단합니다 (참고용: on-pr-against-dev.yaml):\n\n- 단위 테스트: pytest\n- 스타일 체크: black --check ./src ./tests\n- 린터: flake8 ./src ./tests\n\n## 배포 전략\n\n아래에 설명된 네 가지 환경을 다루는 청사진입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-StreamliningAWSGlueCICD_2.png)\n\n프로젝트 요구 사항에 따라 모든 환경을 사용하는 것은 과도할 수 있지만, 적어도 개발 및 프로덕션 환경을 갖는 것이 좋습니다. 이렇게 하면 개발자와 사용자 경험을 더 향상시킬 수 있습니다.\n\n## 사용 지침\n\n주의: 이 부분에서 설명된 실습 가이드를 처음 사용하는 경우, 도구에 대한 전문 지식에 따라 몇 시간이 걸릴 수 있습니다. 그러나 블루프린트에 익숙해지는 것은 가치가 있습니다. 더 짧은 전달 주기 및 더 높은 품질 기준의 혜택은 몇 차례 상호 작용 후에 옵니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개념적 개요를 이해한 후에 블루프린트로 놀아보려 합니다. 저희는 Glue 작업을 설정할 것입니다. 해당 작업은 `awsglue-datasets` 공개 S3 버킷에서 `examples/us-legislators/all/persons.json` 파일을 지정하신 개인 버킷으로 복사할 것입니다. 그 다음 단계에서 Crawler가 테이블을 검사하고 데이터 카탈로그 항목을 생성할 것입니다. 이 작업 흐름은 간단하지만 시연 목적으로 충분합니다. 이미지 3는 Terraform 모듈, AWS 리소스 및 그들 간의 관계를 설명합니다.\n\n![image](/assets/img/2024-06-23-StreamliningAWSGlueCICD_3.png)\n\n다음을 전제로 합니다:\n\n- `aws-glue-ci-cd-blueprint` 리포지토리의 `main` 및 `dev` 브랜치를 복사하셨습니다.\n- 로컬 환경에 Terraform 및 AWS CLI가 설치되어 있습니다.\n- Glue, IAM 및 S3에 대한 관리 권한이 있는 것으로 가정합니다. 그렇지 않으면 다음 단계를 따를 때 도움이 필요할 수 있습니다. Athena 접근 권한이 있다면 더 좋습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테라폼은 생성하는 모든 AWS 리소스에 dev|qa|staging|prod 접미사를 추가합니다. 이렇게 함으로써 네 개의 배포 환경을 하나의 계정에서 구성할 수 있습니다. 이는 교육 목적에 적합하지만 적어도 운영 환경은 별도로 존중받고 적절히 관리되는 계정에서 사용되어야 합니다.\n\n이제 몇 가지 수동 단계가 필요합니다... 다음 권한 정책을 가진 IAM 사용자가 필요합니다:\n\n- AmazonS3FullAccess\n- AWSKeyManagementServicePowerUser\n- AWSGlueConsoleFullAccess\n- IAMFullAccess\n- kms:EnableKeyRotation 및 kms:EnableKeyDeletion을 실행할 수 있는 사용자 정의 정책\n\n이 사용자는 로컬 개발 환경에서 테라폼과 AWS CLI에서만 사용될 예정이므로 콘솔 액세스가 필요하지 않습니다. 이 사용자를 위해 액세스 키를 생성하고 해당 ID 및 비밀을 안전하게 보관하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTerraform 상태 파일을 저장하기 위한 S3 Bucket도 필요합니다. infrastructure/environments/*/provider.tf 파일을 확인하면 glue-ci-cd-terraform 버킷이 블루프린트를 위해 구성되어 있다는 것을 알 수 있으니, 이 파일들을 업데이트해주세요.\n\n또한, infrastructure/environments/*/variables.tf 파일에서 다음 버킷들을 위한 다른 이름을 설정해주세요: data_bucket_name, glue_assets_bucket_name, glue_scripts_bucket_name, athena_query_results_bucket_name. 이름만 제공하면, Terraform이 버킷을 생성할 것입니다.\n\n이제 보여주는 시간입니다! 리포지토리 루트 폴더에서 터미널에서 다음 명령어를 실행하세요:\n\n```js\nexport AWS_ACCESS_KEY_ID=\u003c당신의-액세스-키-ID\u003e\nexport AWS_SECRET_ACCESS_KEY=\u003c당신의-비밀-액세스-키\u003e\n\nexport TF_VAR_aws_access_key=$AWS_ACCESS_KEY_ID\nexport TF_VAR_aws_secret_key=$AWS_SECRET_ACCESS_KEY\n\ncd infrastructure/environments/dev/\nterraform init\nterraform plan\nterraform apply\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n샘플 ETL 파이프라인 인프라를 구성하는 약 20개의 AWS 리소스가 개발 환경(dev 접미사)에서 생성됩니다. 이에는 S3 버킷, IAM 정책 및 역할, Glue 작업, 데이터베이스, 크롤러 및 워크플로우가 포함됩니다.\n\n개발자 설정을 마무리하기 위해 ETL 코드를 스크립트 버킷에 복사해주세요:\n\n```js\ncd ../../..\naws s3 sync --delete ./src s3://\u003cYOUR-GLUE-SCRIPTS-BUCKET\u003e\n```\n\n그런 다음 AWS 콘솔에서 Glue 워크플로우 페이지로 이동하여 glue-ci-cd-us-legislators-dev를 선택합니다. 워크플로를 실행하고 완료될 때까지 약 10분 정도 기다려주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n아래 Markdown 형식의 표를 참조하세요.\n\n![이미지](/assets/img/2024-06-23-StreamliningAWSGlueCICD_4.png)\n\n데이터 버킷을 확인하고 원본 데이터가 JSON 형식으로 저장된 bronze 폴더를 찾으세요. 또한 Parquet 형식으로 데이터가 저장된 silver 폴더도 있습니다. JSON에서 Parquet으로 변환하는 것이 샘플 파이프라인의 한 단계입니다. Glue Workflow에는 silver 테이블을 검토하는 크롤러가 있으며 관련된 데이터 카탈로그 항목을 생성합니다.\n\n![이미지](/assets/img/2024-06-23-StreamliningAWSGlueCICD_5.png)\n\n마지막 단계는 CI/CD를 위해 GitHub 저장소를 구성하는 것입니다. 저장소 설정 페이지로 이동하여 환경을 선택하세요. quality-assurance, staging, production 세 개의 환경을 만드세요. 각각에 대해 AWS_ACCOUNT_ID 비밀 및 AWS_REGION 및 GLUE_SCRIPTS_S3_BUCKET 변수를 설정하세요. 여기에서는 GitHub Action 실행기가 특정 IAM 역할을 가정하기 때문에 액세스 키나 시크릿을 제공해야 할 필요가 없다는 점을 주목하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCI/CD YAML 파일 중 하나를 다시 확인하고 GitHub Action 러너가 GlueCICDGitHubActionsServiceRole을 가정하는지 확인해주세요. 이 IAM 역할은 아직 AWS 계정에 생성되지 않았으므로 이를 생성하고 Amazon Web Services에서 OpenID Connect 구성 지침을 따라 설정을 완료하세요. 이전에 생성된 IAM 사용자에 부여된 동일한 권한을 부여해주세요.\n\n작업을 완료하면 “배포 전략” 섹션에 설명된 규칙에 따라 나머지 세 개 환경에서 자동화 및 품질 체크를 활용할 수 있습니다. 스크립트를 변경하고 파이프라인에 새 단계를 추가하며, 저장소에 풀 리퀘스트를 생성하고 이를 dev 브랜치로 병합한 뒤 dev를 main에 병합하여 결과를 확인해주세요. 또한 CI/CD 실행 예제를 참조하기 위해 블루프린트 저장소를 참고할 수도 있습니다.\n\n![AWS GlueCICD](/assets/img/2024-06-23-StreamliningAWSGlueCICD_6.png)\n\n# 도전과 고려 사항\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제공된 청사진은 AWS Glue CI/CD 파이프라인을 간소화하기 위한 유용한 자원을 제공하지만, 항상 개선할 부분이 있습니다. 앞으로 진행할 때 극복하고자 하는 주요 장벽은 다음과 같습니다:\n\n- 다중 개발 및 QA 환경 지원. 현재는 개발 및 품질 보증 환경이 각각 하나씩만 있어 대규모 팀에 대해 동시성 문제를 발생시킬 수 있습니다. 더 나은 해결책은 각 엔지니어마다 하나의 개발 환경 및 각 Pull Request에 대해 하나의 QA 환경을 지원하는 것입니다.\n- 데이터 품질 기능. DataOps는 데이터에 대해 적용된 단순한 DevOps 이상을 의미합니다. 현재 청사진은 처음 릴리스된 Glue 데이터 파이프라인용 DevOps일 뿐입니다. 자동으로 데이터 품질 점검을 설정하는 것이 DataOps 범주로 승격하는 데 도움이 될 것입니다.\n- 통합 테스트. 유닛 테스트는 Python 코드에 대해 잘 작동하지만, ETL 파이프라인은 일반적으로 단위 테스트에 적합하지 않은 SQL 문에 의존합니다. 통합 또는 시스템 테스트 지원을 추가하는 것이 적절할 것입니다.\n\n# 결론\n\n데이터 관리의 동적 영역에서 AWS Glue의 ETL 프로세스를 용이하게 하는 역할은 조직이 데이터의 잠재력을 효과적으로 활용할 수 있도록 하는 중요한 힘으로 남아 있습니다. 이 탐험을 통해 AWS Glue 작업에 대한 CI/CD 관리의 내재적인 도전 과제를 극복하기 위한 포괄적인 청사진을 소개하면서 이러한 복잡성에 직면하는 것을 목표로 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n변화를 받아들이는 것은 때로는 시간과 노력을 투자하는 것이 필요합니다. 사용 설명서에 상세히 설명된 실습 단계들은 특히 이 도구에 익숙하지 않은 사람들에게는 시간이 좀 걸릴 수 있습니다. 그러나 걱정하지 마세요, 이 노력의 결실은 처음 투자한 가치가 충분히 있을 것입니다.\n\n글을 마무리하며, 데이터 민첩성 여정에 참여하실 것을 초대합니다. GitHub 저장소를 살펴보고, 구현 세부사항에 익숙해지고, 이 원칙을 프로젝트 요구에 맞게 적용해 보세요. 도움이 필요하시면 언제든지 연락 주세요.\n\n귀하의 데이터 프로젝트가 효율성과 성공으로 가득하길 기원합니다!","ogImage":{"url":"/assets/img/2024-06-23-StreamliningAWSGlueCICD_0.png"},"coverImage":"/assets/img/2024-06-23-StreamliningAWSGlueCICD_0.png","tag":["Tech"],"readingTime":9}],"page":"4","totalPageCount":98,"totalPageGroupCount":5,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"4"},"buildId":"o1YmnmSuZvAX2O4TI9r41","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>