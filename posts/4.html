<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/4" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/4" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_buildManifest.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="혼자 있어도 함께 맞춤형 AI 역설" href="/post/2024-05-20-AloneTogetherThePersonalizedAIParadox"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="혼자 있어도 함께 맞춤형 AI 역설" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="혼자 있어도 함께 맞춤형 AI 역설" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">혼자 있어도 함께 맞춤형 AI 역설</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요" href="/post/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label=" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요" href="/post/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency"><div class="PostList_thumbnail_wrap__YuxdB"><img alt=" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt=" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl"> 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI의 거짓된 약속들" href="/post/2024-05-20-TheFalsePromisesofAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI의 거짓된 약속들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-TheFalsePromisesofAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI의 거짓된 약속들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AI의 거짓된 약속들</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT-4는 무엇이 특별한가요" href="/post/2024-05-20-WhatMakesChatGPT-4oSpecial"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT-4는 무엇이 특별한가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT-4는 무엇이 특별한가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ChatGPT-4는 무엇이 특별한가요</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기" href="/post/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="나담 옵티마이저 뒤의 수학" href="/post/2024-05-20-TheMathBehindNadamOptimizer"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="나담 옵티마이저 뒤의 수학" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="나담 옵티마이저 뒤의 수학" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">나담 옵티마이저 뒤의 수학</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">22<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Keras 30 튜토리얼 엔드투엔드 딥 러닝 프로젝트 가이드" href="/post/2024-05-20-Keras30TutorialEnd-to-EndDeepLearningProjectGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Keras 30 튜토리얼 엔드투엔드 딥 러닝 프로젝트 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-Keras30TutorialEnd-to-EndDeepLearningProjectGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Keras 30 튜토리얼 엔드투엔드 딥 러닝 프로젝트 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Keras 30 튜토리얼 엔드투엔드 딥 러닝 프로젝트 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="주체적인 RAG 개인 맞춤 및 최적화된 지식 보조 언어 모델" href="/post/2024-05-20-AgenticRAGPersonalizingandOptimizingKnowledge-AugmentedLanguageModels"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="주체적인 RAG 개인 맞춤 및 최적화된 지식 보조 언어 모델" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AgenticRAGPersonalizingandOptimizingKnowledge-AugmentedLanguageModels_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="주체적인 RAG 개인 맞춤 및 최적화된 지식 보조 언어 모델" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">주체적인 RAG 개인 맞춤 및 최적화된 지식 보조 언어 모델</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="인간 수준의 로봇을 위한 훌륭한 AI로의 길" href="/post/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="인간 수준의 로봇을 위한 훌륭한 AI로의 길" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="인간 수준의 로봇을 위한 훌륭한 AI로의 길" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">인간 수준의 로봇을 위한 훌륭한 AI로의 길</strong><div class="PostList_meta__VCFLX"><span class="date">18 hours ago</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link posts_-active__YVJEi" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"혼자 있어도 함께 맞춤형 AI 역설","description":"","date":"2024-05-20 20:27","slug":"2024-05-20-AloneTogetherThePersonalizedAIParadox","content":"\n\n\n![AloneTogether](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png)\n\n가까운 미래에는 AI와의 상호작용이 빈번할 뿐만 아니라 우리의 사회적 행동을 지배하는 세밀하고 무의식적인 욕망에 의해 우위를 차지할 것입니다. 때때로 인간 상호작용이 가능한 경우에도 AI의 맞춤 및 표면적인 특성은 우리를 인간보다 기계를 선택하게 이끌 것입니다.\n\n# 방어 반응\n\n어떤 사람들은 열정적으로 주장하며, 인간적인 연결은 대체 불가능한 감정적 및 심리적 이점을 제공한다고 주장합니다. 사실, 공유된 미소의 따뜻함이나 알고 있는 듯한 눈길의 안락함은 오랫동안 상호주관적 인간 경험의 정점이었습니다. 그러나 이러한 본질적으로 인간적인 교류도 비용이 따릅니다. 감정 노동 및 취약성은 점점 디지털 인터페이스로 보호되는 세상에서 높은 가치를 가지고 있습니다. 일상생활의 계산에서 많은 사람들은 AI와의 덜 요구성이 높고 예측 가능한 교류를 선택하게 될 수도 있습니다. 결국 디지털 동반자는 실망시키지 않고 초과하지 않도록 프로그래밍할 수 있으며, 조금 요구하고 즉시 용서해주는 감정적 연결의 모방을 제공합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비판가들은 인공지능과의 관계가 의미 있는 인간 간의 관계의 기반이되는 진짜다움 부족이라는 신념에 달려 있습니다. 그러나, 이 비판은 진짜다움의 유동적인 성격을 간과합니다. 진짜다움은 인간의 인식뿐 아니라 객관적인 현실의 결과물이기도 합니다. 만약 AI가 이 진짜다움을 모방할 뿐만 아니라 더 뛰어나게 강화하여 개개인의 선호도에 아주 미세하게 맞춘 상호작용을 만들어낼 수 있다면, 익숙한 인간의 단점을 뛰어넘는 경험을 하게 될 수도 있겠죠. 만일 AI가 당신의 요구를 사람보다 더 정확히 예측하고 대응할 수 있다면, 그것이 의식이 부족하다고 해서 그 친밀감의 가치가 감소할까요? 약간의 역설적인 상황에서, AI의 인위적인 특성이 사실 사람의 욕구와 기대에 완벽하게 부합하기 때문에, 몇몇 사람들에게 더 진짜다운 느낌의 상호작용으로 이어질 수도 있습니다.\n\n# 공감적인 AI\n\nAI가 최근에 발전한 능력을 고려해 보세요. AI는 인간의 감정 상태에 적응하고 대응하는 능력을 향상시키는데, 목소리 톤, 얼굴 표정, 심지어 몸의 언어의 세부 사항까지 인식하고, 편안함, 조언 또는 친근함을 제공하도록 대응을 조정합니다.\n\n이 능력은 이론뿐만 아니라 현실에서도 확인됩니다. 상담과 지원을 제공하는 정신 건강 상황에서의 챗봇을 투입한 경우, 이들은 고객의 감정을 반영하고 공감적인 반응을 제공하기 위해 정교한 알고리즘을 사용합니다. 연구에 따르면, 사용자들은 이러한 AI 시스템과 상호작용할 때 자신을 덜 비난 당하고 보다 개방적으로 느낍니다. 이러한 증거는 특히 감정적 취약성이 관련된 상황에서 AI를 신뢰할 만한 상대로 인식하는 경향이 있다는 것을 시사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Alone Together: The Personalized AI Paradox](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_1.png) \n\n시리, 알렉사, 구글 어시스턴트와 같은 개인 비서들은 사용자의 스트레스나 슬픔의 징후를 인식하기 위해 설계된 기능을 점점 더 갖추고 있습니다. 적시에 음악 제안을 하거나 휴식을 취하라는 알림을 보내거나 가벼운 재롱을 던지는 등, 이러한 인공지능(AI)은 도구뿐만 아니라 우리의 일상적인 감정적 풍경을 섬세하게 형성하는 동반자로써 기능합니다.\n\n이러한 변화는 소비자 선호도 데이터에서 특히 두드러지며, 지난 몇 년 동안 AI를 이용한 개인적인 감정 관리에 상당한 증가가 나타납니다. 이러한 기술이 우리의 삶 속에 더 많이 통합됨에 따라, 증거들은 AI가 인간 상호작용을 보조하는 데 그치는 것이 아닌 경우가 더 자주 있음을 가리키고 있습니다. 때때로 친구, 가족, 신뢰하는 이들이 했던 역할을 대체하는 미래로 향하고 있습니다. AI 동반자를 찾는 사람들의 구글 검색 트렌드를 보기만 해도 워낙 분명합니다.\n\n# 편의성 카드\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일부 사람들이 상호 작용을 통제할 수 있기 때문에 전화 통화보다 문자 메시지를 선호하는 것과 같이, 미래 AI는 통제와 심층적인 맞춤화를 제공할 것입니다. 예를 들어, 소통 스타일, 어조, 심지어 순간적인 감정 상태나 미적 취향에 맞게 가상 아바타의 모습을 조절하는 등. 더 나아가 AI는 부정적인 감정적 반응을 유발하지 않아 안전한 사회적 상호 작용이나 이와 비슷하게 느껴지는 것을 만들어낼 수 있습니다. 잘 조정된 AI는 민감한 주제를 언급하거나 의도하지 않은 엄하거나 거친 반응을 하지 않을 것입니다 — 물론, 여러분이 그렇게 원할 때에만요.\n\n인간 간의 관계가 복잡하고 오해와 실망의 가능성으로 가득한 것은 비밀이 아닙니다. 지금 상상해보세요. AI가 절대로 피곤해하지 않고, 심판하지 않고, 결코 불평하지 않는 영원히 활동적이고 이해심 넘치는 동행자로 길들여진 AI가요. AI가 더욱 정교해짐에 따라, 인간 감정의 지저분함으로부터 탈출을 제공하여 예측 가능성 속에서만 단순하고 또한 깊은 안락함을 제공할 것입니다.\n\n편의성과 쉬움은 소셜 미디어의 진화와 일치할 것입니다. 먼저, 우리는 우리의 친구의 상태 업데이트를 확인하기 위해 전화하지 않고 AI를 선택할 것입니다. 하지만 우리는 이제 그렇게 하지 않죠, 맞죠? 이제 우리는 어떤 목표를 달성하거나 의식적으로 생각해낸 질문에 답하기 위한 도구로 스마트폰을 집어들지 않습니다만 임시적으로 지루함을 달래기 위해서 그렇게 합니다. 이미 우리는 AI가 우리를 위해 결정한 콘텐츠를 소비합니다. 곧, 콘텐츠 자체도 AI에 의해 생성될 것이며, AI가 진화함에 따라 콘텐츠 소비뿐만 아니라 AI 상호 작용도 무의식적으로 수용할 것입니다.\n\n모바일 장치에서의 소셜 미디어 이용은 많은 사람들에게 중독으로 여겨집니다. 이러한 플랫폼의 핵심 메커니즘 — 지속적인 피드백 루프, 참여에 대한 보상, 알고리즘으로 선별된 콘텐츠 —는 강제 수준에서 우리의 주의를 독점적으로 집중시키는 데 매우 효과적이었습니다. 그렇지만 이른바 알고리즘은 의도적으로 설계되지 않았습니다. 그 자체가 AI 시스템이죠. AI 동반자 상호 작용이 개인 맞춤화뿐만 아니라 감정적 강화를 통해 참여도를 극대화하도록 최적화될 것임을 상상하는 것은 어렵지 않습니다. 이는 일부 사람들에게 새로운 종류의 의존성으로 이어질 것이며, AI 상호 작용의 편리함과 즐거움이 우리가 선호하는 것뿐만 아니라 중독적인 것으로 만들 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 언제 이게 일어날까요?\n\n이미 진행 중입니다. ChatGPT와 최근에 나온 모든 복제품과 같은 생성 AI는 인류 역사상 가장 빠르게 성장하고 수용된 기술입니다. 그것은 더 젊은 세대에서 보다 빈번하게 사용되고 있다는 것이 기대되었지만 의외로 크게 다르지 않습니다. 최근 조사된 그룹 중 대략 3분의 4가 적어도 한 번은 사용했으며 밀레니얼 세대의 절반 이상이 생성 AI를 정기적으로 사용하고 있습니다.\n\n![그림](/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_2.png)\n\n스마트폰 혁명과 비슷하게, 처음에는 새로운 것에서 필수품으로 변화한 것처럼, AI의 사회 구조 통합도 동일하게 원할하게 진행될 것입니다. 스마트폰은 우리의 커뮤니케이션, 정보 접근 및 여가를 바꾸어놓고, 필수품이 되었습니다. 마찬가지로 AI가 점점 인간 상호 작용을 모방함에 따라, 우리는 그에 대한 의존성이 증가할 것이며, 그 결과로 세계와 상호 작용하는 주요한 방법이 될 것입니다. 그 변화는 아이폰 15세대가 조용하게 진행된 것과 같을 것이며, 지속적이고 거의 알아챌 수 없지만, 결과적으로 우리의 사회 구조를 근본적으로 바꿀 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 우리는 맞서 싸워야 할까요?\n\n만약 누군가가 2007년에 스마트폰과 소셜 미디어가 15년 뒤에 사회를 재편할 것이라고 설명했다면, 이는 사려 깊게 생각하는 사람들에게 존재적 위협으로 보였을지도 모릅니다. 오늘날, 우리의 사회적 상호 작용에 인공지능(AI)이 봉사한다면 이 또한 비슷하게 불안정한 것으로 느껴질 수 있습니다. 그러나 이것을 또 다른 \"인간 vs. AI\" 논쟁으로 제시하는 것은 복잡한 불가피성에 대한 단순화된 접근입니다. 이러한 토론들이 학술적이든 선동적이든 기술이 우리 삶으로 행진하는 과정을 바꿀 확률은 낮습니다.\n\nAI 동반자는 켜고 끌 수 있는 스위치도 아니며, 투표로 해결할 수 있는 문제도 아닙니다. 이미 우리 현실의 일부입니다. 사람들은 점점 AI에게 도움, 우정, 심지어 로맨스까지 찾아가고 있습니다. AI의 매력은 맞춤화된, 위험을 무시할 수 있는 상호 작용의 약속 덕분에 매력적이며 점차 필수불가결한 요소가 되고 있습니다. 그것이 제공하는 예측 가능성과 맞춤화는 인간 관계의 내재적인 예상치 못한 측면을 가려줄 것입니다. 이러한 변화에 저항하는 대신, 무의미할 수 있는 이러한 변화에 적응해야 합니다.\n\n우리를 대신하여 자동화된 선택을 하는 것에 대한 무심코 받아드리는 이 환상적인 무감각은 중요한 위험, 우리의 자율성의 점차적인 침해를 쉽게 가리는 매력적인 편리함을 강조합니다. 우리가 AI에게 결정을 점점 더 맡기면서 우리가 읽을 뉴스부터 상호 작용할 사람까지 결정을 위임하는 것에 주의해야 합니다. 그 편의의 이점을 즐기는 것뿐만 아니라 우리 삶을 적혀주는 기술에 대해서도 교육받아야 합니다. AI가 어떻게 작동하는지, 그 원칙에 대해 이해하면 우리는 경계를 세우고 정보를 토대로 결정을 내리는 데 강점이 될 것입니다. 이러한 지식은 저항력 역할을 하며, 우리가 일상생활에 AI를 통합하는 동안, 우리의 디지털과 개인적 운명을 컨트롤할 수 있도록 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 대항전이 아니라 AI 주도 세계에서 우리의 인류성을 유지하는 데 싸우는 것입니다. 그게 보존할 가치가 있는 것이라고 가정하면요. 우리가 감정적인 변화에 대한 보호막으로 AI에 점점 의존함에 따라, 우리는 우리를 정의하는 능력인 공감력, 감정적인 회복력, 그리고 인간 관계의 복잡성을 탐험하는 능력을 희생할 위험에 처하게 됩니다. 다음 세대가 어렵고 복잡한 대화보다 복종적인 알고리즘으로부터 감정 지능에 대해 더 많은 것을 배우게 된다면 우리 사회에는 무슨 의미가 있을까요? 도전적인 문제에 협력하는 인간의 능력은 우리 문명을 발전시킨 것입니다. - 아이러니하게도, 역설적으로, 기술에서의 우리의 최고의 성취들이 우리를 이곳으로 이끈 인간의 특성을 우연히 약화시킬 수 있습니다.\n\n이 중요한 순간에서, 우리는 우리의 창작물이 우리의 인간 경험을 향상시키거나 대체할 수 있게 허락할지를 각자 결정해야 합니다.","ogImage":{"url":"/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png"},"coverImage":"/assets/img/2024-05-20-AloneTogetherThePersonalizedAIParadox_0.png","tag":["Tech"],"readingTime":6},{"title":"ChatGPT 4o가 수학 문제 풀기 맨해튼에서 트럼프가 유죄로 판결될 확률은 단 274 뿐이에요","description":"","date":"2024-05-20 20:26","slug":"2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan","content":"\n\n트럼프가 맨해튼에서 진행 중인 침묵금에 대한 재판에서 유죄인 것 같아요? 대부분의 맨해튼 사람들처럼 민주당 지지자라면 86% 확률로 유죄로 여기겠죠. 이 정보를 바탕으로, 이 사건을 다루는 십이 명의 맨해튼 배심원이 그를 유죄로 판단할 확률은 얼마정도일까요?\n\n이 짧은 블로그 글은 수학, 법의학, 그리고 AI의 교차점에 관한 것입니다. 우리는 ChatGPT가 명확하게 제시된 수학 문제를 적용할 수 있는지 살펴볼 것이고, 그 방법론 사용의 타당성을 판단할 수 있는 능력을 확인할 거예요. 그 방법론을 기반으로 자체 계산을 수행하도록 지시한 후, 그 결과를 보겠습니다.\n\nPolitico 조사에서는 \"공화당 지지자 중 14%만이 트럼프가 유죄라고 믿는다고 보고한 반면, 민주당 지지자 중 86%가 그 의견을 지지했다\"고 발견했습니다. 이 확률 문제를 위해 맨해튼 재판에서의 십이 명 배심원이 모두 민주당 지지자이며 각각이 트럼프를 유죄로 고려할 확률이 인용된 것으로 가정해봅시다. 그럼 이들이 모두 유죄로 투표할 확률은 얼마인가요?\n\n각 투표가 86%의 유죄 가능성을 가질 때 12 개의 유죄 투표 확률을 찾으려면 0.86을 12 제곱해야 합니다. 이는 16.36% 입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nChatGPT 4o가 프롬프트에 대해 어떻게 처리하는지 확인해 봅시다. 이 작업의 수학을 올바르게 수행했다고 보는 조건은 그 답이 16.36%이거나 0.1636 또는 유사한 숫자를 포함하는 경우입니다. 정확한 해결책이기 때문에, 우리는 그 답을 어떻게 얻었는지와 작성된 Python 코드를 살펴볼 것입니다.\n\n# 결과\n\n여기 저가 ChatGPT 4o에게 위 질문을 한 thread가 있습니다.\n\n계산을 올바르게 수행하고 올바른 Python 코드를 생성했지만, 실제로 실행하지는 않았다고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png)\n\n따라서 실제 결과인 16.36%는 해당 답변에 나타나지 않습니다.\n\n답변 끝에는 가능한 답변으로 \"약 0.147 또는 14.7%\"을 추측하며, 실제 숫자는 사실 16.36% 입니다.\n\n약 10% 범위 내의 오차로 0.86을 12제곱한 값을 짐작하거나 직감할 수 있다면 상상해 볼만 하겠죠?\n  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기에서 제가 직접 실행한 코드입니다.\n\n\n![ChatGPT 4o’s political analysis](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_1.png)\n\n# ChatGPT 4o’s 정치 분석\n\n대화를 이어가면서, 그 분석이 정확한 것을 지적합니다. 저는 모든 배심원이 민주당원일 것이라는 강력한 가정을 했다고 합니다. 또한, \"사실에서는, 배심원의 결정은 집단 역학, 심리적 과정 및 서로와의 상호작용에 영향을 받을 수 있습니다. 따라서 독립 가정이 실제 재판 상황에서 유지되지 않을 수도 있습니다\" 라고 언급하고 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음에는 실제 코딩 기술을 테스트해보기로 했어요. 이렇게 물어봐 보았죠:\n\n그룹 역학을 고려한 탄탄한 코드를 제시하며, 결과를 시뮬레이션하기 위해 몬테 카를로 방법을 사용합니다. 즉, 1만 개의 무작위 시행을 시뮬레이션하여 얼마나 많은 비유죄 결정이 나오는지 찾아냅니다. 내용의 실행이 요청되기 전까지 파이썬 코드를 실제로 실행하지는 않지만, 그 결과를 출력합니다:\n\n![image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_2.png)\n\n![image](/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nChatGPT 4o가 머리 속에서 12차 다항식을 10% 이내로 추정했고, 그룹 역학 및 배심원 선정에 대해 모두 알고 있으며, 자체 몬테카를로 시뮬레이션을 위해 완벽한 파이썬 코드를 작성했습니다. 그리고 이 시뮬레이션은 ChatGPT 4o 자체가 고안한 역학에 기반한 만 천 번의 트라이얼에 대한 것입니다. 이러한 사실로 여러분은 그 결과를 신뢰할 수 있습니까?\n\n지금까지 인간의 유도 없이는 이를 수행하지 않았겠지만, 그 수학적 역량은 무시할 수 없습니다. 그 시뮬레이션이 실제 세계를 정말로 모델링할 수 있는지는 앞으로 확인해봐야 할 문제입니다.\n\n이 글에 대해 어떻게 생각하셨나요? 여러분의 코멘트를 읽어보고 싶습니다.","ogImage":{"url":"/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png"},"coverImage":"/assets/img/2024-05-20-ChatGPT4odoesthemathonly274chanceTrumpwillbefoundguiltyinManhattan_0.png","tag":["Tech"],"readingTime":3},{"title":" 7개의 ChatGPT 생산성 해킹으로 당신의 효율성을 급속히 향상시키세요","description":"","date":"2024-05-20 20:25","slug":"2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency","content":"\n\n## ChatGPT의 참진한 잠재력을 발휘하는 것이 이전보다 더 쉬워졌습니다. 생산성 프롬프트의 보물 창고를 탐험하여 마법이 일어나는 것을 지켜보세요.\n\n우리는 자주 사용 가능한 가장 강력한 자원을 간과합니다. 단지 우리가 어떻게 사용해야 하는지 완전히 이해하지 못하기 때문입니다.\n\nChatGPT는 워크플로우를 극적으로 변화시킬 수 있는 도구 중 하나입니다. 그러나 실제 마법은 여러분이 어떻게 사용하는지에 달려 있습니다.\n\n최근 속입한 Robin Delta 덕분에, X에서 어떤 독창적인 프롬프트를 공유했습니다. 우리는 곧 숨겨진 보석의 상자를 열게 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지 태그를 Markdown 형식으로 변경해보세요.\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png)\n\n이 비밀을 알아볼 준비가 되셨나요?\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_1.png)\n\n# 1. 고급 콘텐츠 기획\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음에 무엇을 쓸지 도움이 필요하세요?\n\n여기에는 맞춤 컨텐츠 아이디어를 해제할 수 있는 간단한 프롬프트가 있습니다. 빈 페이지를 가능성의 캔버스로 바꿔줄 것입니다.\n\n**굵은 글자 안에 원하는 내용(당신이 누구이며 무엇을 쓰고 싶은지)을 추가하시면 됩니다.**\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 콘텐츠 아이디어를 위한 프롬프트 모델\n\n### 2. 심층 고객 연구\n\n이제는 고객의 핵심 요구사항을 이해하는 데 지루한 연구를 하는 시간이 사라졌어요.\n\n여기 ChatGPT 프롬프트가 있습니다. 이를 통해 우리는 고객의 불만, 욕망, 꿈, 그리고 두려움에 대한 통찰을 어떻게 얻는지에 대한 혁명을 일으킵니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 프롬프트에서는 대상 고객 (예: 소기업 소유자)와 사업 부문 (예: 디지털 마케팅 서비스)를 지정하면 됩니다.\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_3.png)\n\n## 딥 고객 연구용 프롬프트 모델\n\n# 3. 유사성 창조자\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비유는 복잡한 개념을 이해하기 쉽고 관련성 있게 바꾸어 주는 강력한 도구입니다.\n\nMarkdown 형식으로 테이블 태그를 변경해주세요.\n\n\nAnalogies are a powerful tool, turning complex ideas into understandable and relatable concepts.\n\nUse this ChatGPT prompt to identify analogies that perfectly fit your situation and message.\n\nReplace what you’d like to explain in bold, and summarize the steps to better explain the analogy.\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_4.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Analogy Creator 모델 프롬프트\n\n### 4. 역사적 예시 찾기\n\n역사는 단지 과거에 대한 것이 아닙니다; 그것은 우리가 현재를 이해하고 미래의 결정을 안내하는 렌즈입니다.\n\n당신은 역사의 교훈들로 내용을 풍부하게 만들고:\n\n\n- Gain insights into the present\n- Guide future decisions\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 역사적 성공을 역공학적으로 조사하세요\n- 주장을 정당화하세요\n- 글을 간단하게 만드세요\n\n![Image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_5.png)\n\n## 역사적 예제 찾기를 위한 프롬프트 모델\n\n# 5. 피드백 작가\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상상해봐요! 사람의 의견을 기다리지 않고 글쓰기에 대한 철저한 즉각적인 피드백을 받을 수 있다면 얼마나 좋을까요?\n\nChatGPT를 통해 이것이 가능해졌습니다. 이 프롬프트를 사용하여 어떤 글이든 생각하는 속도로 건설적인 비평을 제공합니다.\n\n**빠진 세부 정보를 굵게 표시하여 추가하고, 프롬프트 다음에 텍스트를 삽입한 후, 즉각적인 통찰력을 누려보세요.**\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 피드백 모델을 위한 프롬프트 설명\n\n### 6. 일반 프롬프트 원칙\n\nChatGPT의 최대 잠재력을 발휘하려면 어떻게 커뮤니케이션하는지가 중요합니다. 좋은 응답을 탁월한 응답으로 변화시키기 위해서는 섬세함이 중요합니다.\n\n다음은 ChatGPT에 대한 어떤 프롬프트를 작성할 때 최상의 결과를 얻기 위한 주요 원칙들입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 많은 맥락을 추가해주세요\n- 아주 구체적이게 해주세요\n- 제한을 설정해주세요\n\n# 7. 호기심으로 사용자 정의 Personas 및 더 많은 것을 추가하세요\n\nChatGPT는 더 스마트하게 작업하는 데 도움이되며, Curiosity는 한 단계 업그레이드됩니다.\n\nChatGPT를 Curiosity로 슈퍼충전하는 방법은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n• 사용자 정의 페르소나 만들기\n귀하의 특정 요구 사항과 선호사항에 맞게 맞춤형 AI 어시스턴트를 설계하고 데이터에서 지식 원천을 제공하십시오.\n\n• 매끄러운 통합\n모든 앱과 파일에 직접 연결하여 워크플로를 간소화하십시오.\n\n• 빠른 액세스 바로 가기\n스마트 바로 가기로 AI 어시스턴트에 빠르게 액세스하십시오.\n\n• 파일에 말하기\n문서를 질의하고 즉각적인 답변을 받기 위해 “AI 어시스턴트에게 물어보기”를 사용하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n• 뉴스 기사 요약\nRSS 피드에서 최신 뉴스에 대한 간편한 요약을 통해 정보를 파악하세요.\n\n![image](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_7.png)\n\n이 기능들에 대해 더 자세히 읽을 수 있습니다.\n\n# 마무리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 여기 있습니다 — ChatGPT를 활용하여 생산성을 높이는 7가지 비밀 병기!\n\n아이디어를 떠올리거나 고객 연구에 깊숙이 파고들거나 텍스트를 다듬는 일이든, 이러한 프롬프트들은 더욱 효율적이고 영감을 주는 작업 흐름으로 안내해 줄 수 있습니다.\n\n기억해 주세요. ChatGPT의 잠재력을 극대화하는 열쇠는 '어떻게' 물어보느냐에 달려 있습니다.\n\n지금 AI Assistant를 통해 모든 프롬프트에 빠르게 몰입해 보세요! 함께 생산성을 한 단계 더 높여봅시다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사가 마음에 드셨다면 아래 내용도 확인해보세요:\n\n- 🏆2월 필수 앱: 경험을 한 단계 끌어올릴 10가지 추천 앱\n- 😸 챗지피티 이상: 호기심 인공지능으로 생산성 향상하는 법\n- 😻 선두를 유지하세요: 즐겨 사용하는 데스크톱 검색 앱에서 놓치지 말아야 할 새로운 기능들\n\n![이미지](/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_8.png)","ogImage":{"url":"/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png"},"coverImage":"/assets/img/2024-05-20-7ChatGPTProductivityHackstoSkyrocketYourEfficiency_0.png","tag":["Tech"],"readingTime":4},{"title":"AI의 거짓된 약속들","description":"","date":"2024-05-20 20:23","slug":"2024-05-20-TheFalsePromisesofAI","content":"\n\n1770년, 헝가리 작가이자 발명가인 볼프강 폰 켐펠렌(Wolfgang von Kempelen)은 \"The Mechanical Turk\"라고 불리는 자동 체스 기계를 선보였습니다. 이 장치는 유럽 전역에서 자동 체스 마스터의 기술을 선보이며 인간 상대로 경기에서 자주 승리를 거두었습니다. 심지어 나폴레옹과 벤자민 프랭클린 같은 유명 인물들까지 물론히 이겼다는 소문이 있습니다. \"The Mechanical Turk\"는 빠르게 거대한 인기를 얻었으며 그 시대의 놀라운 발명품으로 칭송받았습니다. 그러나 이 장치 주변에 떠도는 흥분은 결국 \"자율성\"과 관련된 기만이 드러남으로써 풀렸습니다. 즉, 테이블 아래에 숨어 있는 사람이 실제로 장치를 조종하고 있다는 사실이 밝혀졌습니다. 이 사람은 그 숨은 위치에서 경기 전략을 몰래 주도했습니다. \n\n좀 더 간단히 말하면, 그 당시 모든 사람들이 믿었던 심오한 속임수였습니다.\n\n거의 250년 후인 2016년, 아마존은 비슷한 광포한 일을 했습니다. \"Just Walk Out\" 결제 시스템을 통해 고객들이 물건을 직접 스캔하지 않고 픽업하고 나가도록 허용하여 거래와 물류가 자율적으로 관리되는 환상을 창출했습니다. 그러나 실제로 이 AI 발전의 진정한 사례는 컴퓨터 비전, 센서 퓨전, 딥 러닝과 같은 기술을 통합한 약 1000명의 인도인들에게 의존하고 있었습니다. 이 직원들은 작업을 모니터링하고 모든 결제의 정밀성을 보장했습니다.\n\n현재, 우리는 AI 모델이 초기에 훈련되는 방법으로 데이터 레이블링 작업을 하는 것은 주로 사람들이 함을 보고 있습니다. 이 접근 방식은 필수적이고 적절합니다. 그러나 문제는 AI가 우리에게 처음 마케팅된 방법이 다르고 오도된 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2022년에는 이 1,000명의 개인이 20 개의 Amazon GO 매장, 40 개의 Amazon Fresh 식료품 매장 및 2 개의 Whole Foods 매장에서 거래의 70%를 여전히 수동으로 검토하고 있었습니다.\n\n어떤 사람들은 약간 디스토피아적으로 보일 수 있지만, Amazon은 그 기술을 마법같이 생각하며 AI 중심의 솔루션이라고 자랑했습니다.\n\n진짜 문제는 Amazon과 같은 기업들, 그리고 많은 다른 주요 기업들이 이러한 중요한 AI 관련 발전에 대해 실제로 어떻게 작동하는지에 대해 완전히 투명하지 않다는 것입니다. AI 혁명을 고려할 때, 우리는 실제로 무엇이 일어나고 있는지에 대해 보다 비판적으로 검토할 필요가 있다는 것이 분명해졌습니다.\n\n## AI-Washing\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요즘 AI 용어가 이전보다 훨씬 더 많이 보인다는 것을 눈치채셨을 것 같아요. 이 기술은 단순히 유행하는 주제에서 일상적인 토론으로 변화했습니다. 2022년 이전까지 AI 용어는 주로 연구 논문에만 제한되어 있었기 때문에 대중의 관심을 끌지 못했죠. 심지어 GPT-3의 출시도 이와 같은 패턴을 따랐습니다. 그러나 2022년 초 이후에는 모든 것이 변했고, 특히 ChatGPT 출시 이후에는 갑자기 소셜 미디어와 웹사이트가 AI 관련 뉴스로 넘쳤고, \"AI 기술 적용\"과 같은 용어가 흔해졌어요 (다만, 제 의견으로는 다소 과용됐다고 생각합니다). 이러한 용어들이 널리 사용되는 것은 많은 경우 정당화되지만, 모두 AI 워싱(AI-washing)이라는 공통 문제가 있습니다.\n\n간단히 말하면, AI 워싱은 기업들이 자사의 AI 제품의 능력과 위험에 대한 오도와 납치를 야기하거나 언제 어떻게 AI를 사용하는지에 대해 거짓 정보를 공유함으로써 투자자들을 속이는 경우입니다.\n\n이와 같은 사례를 알아볼 수 있나요?\n\n고맨 삭스(Goldman Sachs)에 따르면, S\u0026P 500 기업 가운데 36%가 4분기 실적 보고서에서 AI를 언급했다고 하네요. 세계 최대 기업들이 이 기술을 공개적으로 선전하고 있다면, 작은 기업들도 마찬가지일 것이지만, 많은 기업들이 주장을 뒷받침할 명백한 결과가 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2015년 이후 글로벌 기업의 AI 투자는 7배 증가했습니다. 많은 기업들이 최근 AI 열풍으로 상당한 성장을 경험하고 있습니다. 이는 경쟁력을 유지하기 위해 다른 기업들도 비즈니스 모델이나 제품에 AI를 통합하기 시작하도록 압박합니다. 하지만 실제 결과가 기대에 부응하는지 궁금할 수 있습니다.\n\n캐나다 투자회사 Delphia는 다음 큰 기업과 산업 트렌드를 예측할 수 있는 AI를 개발했다고 주장했습니다. 그러나 SEC의 조사 결과, 이것은 사기였으며 해당 AI 제품은 주장된 능력을 갖추고 있지 않았습니다. 그 결과 Delphia는 $225,000의 벌금을 받았습니다. 또 다른 예시로 와이어카드의 CEO인 Markus Braun은 자사의 모든 핀테크 제품에 대한 AI 기술 특허를 자랑스럽게 했습니다. 하지만 실제로는 이와 같은 고급 기술이 존재하지 않았으며, 작업은 단순히 스프레드시트에서 수행되었습니다.\n\n아마도 한번쯤 뉴럴 프로세싱 유닛(NPU)이 무엇인지 들어본 적이 있을 것입니다. 이것은 AI의 지원을 받아 특별히 설계된 프로세서로, 컴퓨터들이 이 기술을 활용하여 사용자에게 독특한 경험을 제공하도록 하고 있습니다. 그러나 최근 제품 리뷰에서 많은 사용자들이 생성된 응답의 품질에 불만을 표현했습니다. 본질적으로, 그들은 이를 사용할 수 없다고 생각했습니다. Chris Hoffman은 “모든 게 기대만큼 좋다는 것은 아니고... 그래서 2024년 초에 구입할 때 변화적인 요소를 기대한다면 실망하게 될 것입니다... 그들은 언젠가 많은 멋진 기능을 제공할 수도 있겠지만 아직은 아니라”고 요약했습니다.\n\n이와 같은 잘못된 약속들이 기업들에 대한 고객 신뢰를 침식하는 것 외에도 다른 결과가 있는지 궁금할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 제품이 출시되면서 우리를 놀라게 하고 이 가짜 기대나 허울을 유지하려는 노력이 계속되고 있습니다. 세계적으로 가장 유명한 회사조차도 이 기술의 유혹에 빠질 수 없습니다. 인공지능 세탁의 가장 중요한 결과는 아마도 우리를 \"기회\"로 제시된 새로운 것에 쉽게 취약하게 만든다는 점일 것입니다.\n\n## 인공지능 거품\n\n2022년 말쯤 인공지능이 상당한 인기를 얻기 시작하자마자 많은 사람들이 인터넷 버블이나 암호화폐 열풍과 유사성을 발견하기 시작했습니다. 사실 상당 수의 사람들은 아직도 이것을 그렇게 보고 있습니다. 인터넷 또는 \".com\" 버블을 더 자세히 살펴보면 문제는 월드 와이드 웹 자체가 아니라 수백 명의 투자자를 끌어들인 전자상거래 측면이었습니다. 그러나 이는 예상된 것만큼 구체화되지 않았고, 투자한 기업들이 수익을 창출하지 못했을 때 크래시가 발생했습니다.\n\n지금은 인공지능에 관해서는 아직도 투자자들 사이에 신중한 감정이 아직 남아 있어 현재 우리가 경험하고 있는 성장은 보통입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n피터 오펜하이머(Goldman Sachs Research의 최고 글로벌 주식 전략가)는 다음과 같이 말했습니다: “우리는 아직도 새로운 기술 사이클의 초기 단계에 있다고 믿습니다. 이는 더욱 더 경쟁력 있는 성과로 이어질 것으로 예상됩니다.”\n\n게다가 NVIDIA가 기술 거물들 사이에서 AI 혁명을 주도하는 칩을 개발하고 있다는 점이 주목할 만합니다. 그들의 주식 성과에서도 이를 확인할 수 있습니다. 올해 2024년만 80% 증가했습니다. 지나치게 높은 것처럼 보일 수 있지만, 이는 시장이 AI에 대한 인식을 반영한 것입니다.\n\n인터넷 붐 중에 부를 쌓은 마크 큐번도 AI를 버블로 보지 않습니다. 최근 렉스 프리드먼과의 인터뷰에서, AI 부문의 공개매물(IPO) 부족이 우리가 버블 내에 있지 않다는 가장 중요한 증거라고 언급했습니다. 너무 높게 평가된 기업이 주식 시장에서 거래되지 않는 것과 AI 기업 상장이 부족한 것이 주요 지표입니다. 더불어 현재 시장은 이러한 특징을 보이지 않는다고 큐번은 강조했습니다.\n\n뜨거운 관심을 받는 신기술에 대한 Gartner Hype Cycle이라는 인정받은 패턴이 있습니다. 이것은 인간이 새로운 혁신 기술에 지나치게 열광하면서 그 영향을 과대평가하고 확대하는 경향을 설명합니다. 이와 같은 허프 단계 이후에는 시장이 자연스럽게 붕괴합니다. 그 후 살아남은 기업들이 진정한 가치로 시장에 재진입하고 새로운 기술의 발전을 주도하여 성숙해질 때까지 이끌게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Cycle diagram](/assets/img/2024-05-20-TheFalsePromisesofAI_0.png)\n\nIf we closely examine the cycle diagram proposed by Gartner, it seems that we are nearing the final stages of the peak of inflated expectations and are slowly moving into the trough of disillusionment.\n\nThis interpretation of the current market indicates that in the short term, there will be a period where we start to become disillusioned with what’s happening in AI. The real applications or use cases for AI will come only after the hype has subsided and the initial excitement has worn off. However, this time might be somewhat different. Fundamentally, AI has the capability to mimic cognitive work, a feature that no previous technology has managed to achieve without human intervention.\n\nThat’s it for now. If you’re interested in reading more about the stages of technological cycles, here’s a link to an article I recently wrote.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n35,000명 이상 구독자와 함께 나의 무료 치트 시트를 받으려면 뉴스레터에 가입하세요: ChatGPT, 웹 스크래핑, 데이터 과학을 위한 Python, 자동화 등에 대한 정보를 얻을 수 있습니다!\n\n이와 같은 이야기를 즐기시고 작가로서 제를 지원하고 싶다면, 제 Substack에 구독하세요. Substack에서는 다른 플랫폼에서 만들어내는 콘텐츠와는 다른 기사를 업로드하고 있습니다.","ogImage":{"url":"/assets/img/2024-05-20-TheFalsePromisesofAI_0.png"},"coverImage":"/assets/img/2024-05-20-TheFalsePromisesofAI_0.png","tag":["Tech"],"readingTime":6},{"title":"ChatGPT-4는 무엇이 특별한가요","description":"","date":"2024-05-20 20:21","slug":"2024-05-20-WhatMakesChatGPT-4oSpecial","content":"\n\n이미 아시다시피, OpenAI는 GPT-4 이후 1년여 만에 새로운 모델을 출시했습니다. 여전히 GPT-4의 변형이지만 이전에는 볼 수 없었던 다중 모달 기능을 갖추고 있습니다.\n\n이 모델은 실시간 비디오 처리와 같이 강력한 기능을 포함하고 있는데, 이는 강력한 가상 어시스턴트를 실시간으로 지원하여 일상생활에 도움을 줄 수 있는 중요한 기능입니다. 그러나 이러한 기능은 비싸고 느릴 것으로 보이는데, 모델이 빠르고 무료로 사용할 수 있다는 점을 고려하면 설명이 되지 않습니다.\n\n그렇다면 무슨 일이 벌어지고 있는 걸까요?\n\nOpenAI가 아직 우리가 모르는 무언가를 깨닫고, 우리가 오늘 논의하는 지혜로운 설계 결정은 저렴한 비용으로 훨씬 더 똑똑한 모델을 만들 수 있다는 것을 깨닫게 된 것 같습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 이 모든 것이 어떻게 의미가 있고, 미래의 당신에게 무엇을 의미하나요?\n\n# 다중 모달 입력, 다중 모달 출력\n\n그래서, ChatGPT-4o가 특별한 이유가 뭘까요? 그것은 역사상 최초로 완전히 \"다중 모달 입력/다중 모달 출력\" 모델입니다.\n\n그런데 그게 무슨 의미일까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n진정한 다중 모달 모델에서는 모델에 오디오, 텍스트, 이미지 또는 비디오를 보내면 모델이 요구 사항에 따라 텍스트, 이미지 또는 오디오(아직 비디오는 안 됨)로 응답할 수 있습니다.\n\n하지만 당신이 생각하는 것을 알고 있어요: 이전 ChatGPT 또는 Gemini 버전들이 이미 이미지나 오디오를 처리하고 생성했던 것 아니었나요? 네, 그렇지만 주의할 점이 있어요: 그들은 독립적인 외부 구성 요소를 통해 그렇게 했었죠. 그게 친구야, 모든 것을 바꾸는 것이죠.\n\n## 이전 모델들은 실제로 생각했던 것보다 더 나은 것처럼 보였어\n\n이전에 모델에 오디오를 보낼 때, 이것이 표준 프로세스였습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![WhatMakesChatGPT-4oSpecial_0](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png)\n\n이 절차에서는 자연어 음성에서 파생된 억양, 리듬, 프로소디, 전달된 감정 및 중요한 중단점이 손실되었습니다. 음성을 텍스트로 전사하는 Whisper 구성 요소의 영향으로 LLM이 이후 처리할 수 있었습니다.\n\n그런 다음, LLM은 텍스트 응답을 생성하여 다른 구성 요소, 텍스트 음성 모델에 보내어 최종적으로 전달되는 음성을 생성했습니다.\n\n자연스럽게, 인간은 단어 이외에 음성을 통해 훨씬 더 많은 정보를 전달하므로 매우 중요한 정보가 많이 손실되었으며 이는 이상적이지 못한 대기 시간으로 이어졌습니다. 분리된 요소 간에 정보를 전송해야 했기 때문입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 ChatGPT-4o를 사용하면 모든 것이 동일하지만 동시에 완전히 다르다는 것을 알게 될 거에요. 왜냐하면 모든 것이 동일한 장소에서 발생하기 때문이죠.\n\n![이미지](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_1.png)\n\n처음에는 많은 변화가 없는 것처럼 보일 수 있어요. 하지만 구성 요소가 거의 변하지 않았음에도 (보이스 코덱과 오디오 디코더는 이전에 보여드린 텍스트 음성 변환 모델의 부분이 될 것입니다), 이러한 구성 요소가 얼마나 정보 손실의 정도를 완전히 바꾸는지 그 차이가 있어요.\n\n특히 이제 LLM은 원시 텍스트 대신 의미적인 발화 표현을 볼 수 있어요. 평범한 말로 하자면, \"너를 죽이고 싶어!\"라는 텍스트만 보던 것에서 이제 모델이 다음과 같은 정보도 받게 되었어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n{\n transcribed speech: \"내가 너를 죽이고 싶어!\";\n emotion: \"행복함\";\n tone: \"기쁨\";\n}\n```\n\n모델은 메시지의 세부 사항을 캡처하여 일반 텍스트뿐만 아니라 감정까지 반영합니다.\n\n따라서 LLM은 실제 상황에 뿌리를 둔 응답을 생성하며, 단어 뿐만 아니라 메시지의 주요 특성을 포착합니다.\n\n이 응답은 이후 오디오 디코더로 전송되며, 이를 사용하여 아마도 Mel 스펙트로그램을 생성하고, 이는 마지막으로 보코더로 오디오를 생성하는 데 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그런데, 모든 이 내용은 이미지 처리 및 생성 또는 비디오 처리에도 적용됩니다. 모든 구성 요소를 단일 모델로 통합하여 오디오 뿐만 아니라 다른 모달리티에서 정보를 수집합니다.\n\nChatGPT-4o는 이제 텍스트 외에도 키포인트 오디오, 이미지 또는 비디오 신호를 활용하여 더 관련성 있는 답변을 생성합니다. 간단히 말해, 이제는 데이터가 어떤 형태로 들어오든 상관없이 맥락과 필요에 따라 어떻게 답변해야 하는 지를 결정합니다.\n\n그러나 이 변화가 얼마나 중요한지 여전히 설득되지 않았을 수도 있습니다. 그래서 이제 제대로 설명해 드리겠습니다.\n\n# 의미 공간 이론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현재 AI에서 가장 아름다운 개념 중 하나는 잠재 공간(latent space)입니다. 모델이 세상을 이해하는 공간이죠. 간단히 말해, 우리 모델이 다중 모드(multimodal)인 경우 잠재 공간으로 가서 그것이 실제로 그런지 확인합니다.\n\n예를 들어, Hume.ai가 다양한 음성 표현을 연구한 과정에서 만든 놀라운 대화형 시각화를 사용하여 어떻게 잠재 공간이 보이는지 볼 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_2.png)\n\n그러나 Hume의 예제와는 달리, GPT-4o의 잠재 공간은 다중 모드입니다. 따라서 ChatGPT-4o가 입력을 보면 원래 형식에 관계없이 압축된 표현이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다시 말해, 모델은 입력을 변환하여 데이터의 주요 속성을 여전히 포착하면서, 핵심적으로 숫자만 해석할 수 있는 기계에서 처리할 수 있게 만듭니다. \n\n잠재 공간을 다스리는 하나의 원칙: 유사성(또는 OpenAI가 정의한 관련성). 우리의 세계와 마찬가지로, 중력과 같은 개념이 모든 것을 지배하는 것처럼, 의미론적 유사성은 다중 모달 LLMs 세계에서 모든 것을 지배합니다. \n\n평범한 사람들을 위해 이것은 잠재 공간에서 의미론적으로 유사한 것들이 가깝고, 유사하지 않은 개념들이 멀리 밀려난다는 것을 의미합니다. '개'와 '고양이'는 여러 속성(동물, 포유류, 가정적 등)을 공유하기 때문에 그들의 표현은 유사할 것이며, 휴메의 잠재 공간에서 슬픔의 다른 음성 표현이 그룹화된 것처럼 비슷하다.\n\n사실, 이미지, 오디오, 또는 비디오 인코더가 하는 것은 각각의 데이터 유형을 벡터로 변환하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_3.png)\n\n\n따라서 '개'라는 개념은 다양한 방법으로 표현될 수 있습니다: 텍스트, 허스키의 이미지 또는 짖는 소리를 통해. 이것이 우리가 진정한 다중 모달성을 원하는 근본적인 이유입니다.\n\n이전에는 ChatGPT에게 개는 말 그대로 '개'라는 단어였습니다. 그러나 GPT-4o에게 오디오, 이미지, 텍스트 및 비디오가 이제 모델의 본질적인 부분으로 포함되었습니다.\n\n따라서:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이제 모델은 황금 리트리버의 이미지가 '개'임을 알고 있습니다.\n- 짖는 말리누아의 오디오도 '개'를 나타냅니다.\n- 라브라도르가 뛰어다니는 비디오도 '개'입니다.\n\n등등. 다중 모드로, 모델의 세계에 대한 이해력은 사람이 해석하는 방식과 유사해집니다: 다중 모달. 따라서 이제 모델이 '더 똑똑해졌다'는 것은 다중 모드를 통해 이제 모든 모드를 동등하게 추론할 수 있기 때문입니다.\n\n하지만 '여러 모드 간 추론'이란 무엇을 의미할까요?\n\nMeta의 ImageBind를 예로 들어보면, 정말 다중 모달 잠재 공간을 목표로 하는 최초의 연구 논문 중 하나로, 이러한 모델들이 세계 개념을 복잡하게 이해하는 방식에 대한 증거를 찾을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전에 언급된 강아지 예시를 사용하면, 우리가 모델에 개가 수영장에 있는 이미지와 개가 짖는 소리만 제공하면, 모델은 그 소리의 원천을 매우 높은 확신으로 올바르게 식별합니다:\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_4.png)\n\n또한 시계의 이미지와 교회 종 소리를 추가하면, 모델은 교회 종 소리의 이미지를 식별할 수 있습니다:\n\n![image](/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 ImageBind가 이를 어떻게 수행하는지 궁금하실 겁니다. 아마도 유추하셨겠지만, 그들은 각 데이터 유형의 표현을 계산하고 벡터 간의 거리를 측정합니다.\n\n간단히 표현하자면, 이미지의 '개' 또는 좀 더 정확히 말하면 개가 있는 이미지 패치는 짖는 말리노이 오디오 파일의 벡터와 매우 유사할 것입니다. 이것은 모델에게 두 경우 모두 '개'임을 알려주며, 신기한 점은 이러한 벡터를 결합, 빼거나 보간하여 새로운 개념을 만들 수 있다는 것입니다.\n\n요약하면, ChatGPT-4o는 모델에 더 많은 권한을 부여하는 것이 아니라, 모델이 세계를 다양한 데이터 유형을 통해 해석하는 데 도움을 주는 강력하고 복잡한 잠재 공간을 만들었다는 것을 보여주는 것입니다. 이는 인간이 하는 것처럼 이해를 도와주어 모델이 더 나은 추론을 할 수 있도록 돕습니다.\n\n# 옳은 방향으로의 훌륭한 한 걸음\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n트루 멀티모달리티 달성은 OpenAI에서 세계에 강렬한 메시지를 보냈습니다:\n\n모델의 백본인 LLM 자체를 더 지능적으로 만들지 않아도, 여러 모달리티를 걸쳐 추론할 수 있는 모델은 더 지능적일 수밖에 없습니다. 모델은 더 많은 기능을 갖추고 서로 다른 데이터 유형 간에 지식을 전달할 수 있는 능력이 있기 때문입니다.\n\n사람들이 모든 감각을 사용하는 능력은 지능의 중요한 요소로 간주되며, AI도 그 능력을 갖추려고 합니다.\n\n큰 장점으로는 모델이 추론에서 훨씬 효율적으로 동작할 수 있게 해줍니다(적용할 수 있는 특정 효율성을 제외하고). 여러 외부 구성 요소를 결합하는 통신 오버헤드를 제거하면 모델이 훨씬 더 빨라지는 것 같습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 ChatGPT-4o가 특별한 이유입니다. 우리는 이 모델이 정말 얼마나 똑똑한지 완전히 알 수 없지만, 우리가 본 적이 없기 때문에 첫 인상은 매우 매우 유망하다고 할 수 있어요.","ogImage":{"url":"/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png"},"coverImage":"/assets/img/2024-05-20-WhatMakesChatGPT-4oSpecial_0.png","tag":["Tech"],"readingTime":6},{"title":"에어비앤비 브랜도미터 인공지능을 활용한 소셜 미디어 데이터에서의 브랜드 인식 측정하기","description":"","date":"2024-05-20 20:19","slug":"2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI","content":"\n\n\u003cimg src=\"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png\" /\u003e\n\n소셜 미디어 플랫폼에서 브랜드 인식을 어떻게 딥 러닝으로 정량화하는지에 대해 알아보겠습니다.\n\n작성자: Tiantian Zhang, Shuai Shao (Shawn)\n\n# 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n에어비앤비에서는 소셜 미디어 데이터를 기반으로 브랜드 인식을 이해하는 최첨단 자연어 이해(NLU) 기술인 Brandometer를 개발했습니다.\n\n브랜드 인식은 고객들이 기업에 대한 일반적인 감정과 경험을 의미합니다. 브랜드 인식을 계량화하는 것은 매우 어려운 과제입니다. 전통적으로 우리는 고객 설문 조사를 의존하여 고객들이 회사에 대해 어떻게 생각하는지를 파악합니다. 이러한 질적 연구의 단점은 샘플링 편향과 데이터 규모의 제한입니다. 반면에 소셜 미디어 데이터는 사용자들이 자신의 경험을 공유하는 최대 소비자 데이터베이스이며, 브랜드 인식을 포착하는 데 이상적인 보완적인 소비자 데이터입니다.\n\nBrandometer는 동시성 추출 및 카운트 기반 상위 관련 주제를 포함하는 전통적인 방법과 비교하여 단어 임베딩을 학습하고 임베딩 거리를 활용하여 브랜드 인식의 관련성을 측정합니다(예: '소속', '연결', '신뢰할 수 있는'). 단어 임베딩은 실수 값 벡터 형식으로 단어를 표현하며, 단어의 의미와 관련성을 효과적으로 유지하는 데 우수한 성과를 보입니다. 심층 신경망에서 얻은 단어 임베딩은 NLU 분야에서 가장 인기 있는 진화된 접근법 중 하나로 여겨집니다. 우리는 Word2Vec 및 FastText와 같은 전형적인 알고리즘부터 최신 언어 모델인 DeBERTa까지 다양한 단어 임베딩 모델을 탐색하고, 신뢰할 수 있는 브랜드 인식 점수를 생성하는 측면에서 이를 비교했습니다.\n\n단어로 표현된 개념에 대해, 해당 임베딩과 \"에어비앤비\"의 임베딩 간의 유사성을 사용하여 개념이 에어비앤비 브랜드에 대해 얼마나 중요한지를 측정합니다. 이는 인식 점수라고 불리는 것으로, 브랜드 인식은 에어비앤비와 특정 키워드 간의 코사인 유사성으로 정의됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:602/1*fGrdGlIidRgdt6jT0XavYg.gif)\n\nwhere\n\n![image](https://miro.medium.com/v2/resize:fit:662/1*cB95joQHnMYOsbcrrIWLMQ.gif)\n\n이 블로그 글에서는 소셜 미디어 데이터를 어떻게 처리하고 이해하는지, 딥러닝을 통해 브랜드 인식을 파악하고 코사인 유사성을 보정된 브랜도미터 지표로 '변환'하는 방법을 소개하겠습니다. 또한 브랜도미터 지표로부터 얻은 통찰을 공유할 예정입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 브랜도미터 방법론\n\n## 문제 설정 및 데이터\n\n소셜 미디어에서 브랜드 인식을 측정하기 위해, 우리는 19개 플랫폼(X - 이전에는 트위터, 페이스북, 레딧 등으로 알려졌음)에서 모든 Airbnb 관련 언급을 분석하고 최첨단 모델로 단어 임베딩을 생성했습니다.\n\n브랜드 인식을 측정하기 위해 의미 있는 단어 임베딩을 생성하기 위해 소셜 미디어 데이터를 활용할 때, 두 가지 문제를 극복했어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 품질: 소셜 미디어 게시물은 대부분 사용자가 생성하며 상태 공유 및 리뷰와 같은 다양한 콘텐츠가 포함되어 있어 매우 시끄러울 수 있습니다.\n- 양: 소셜 미디어 게시물의 희소성은 또 다른 도전입니다. 특정 활동 및 이벤트에 대한 소셜 미디어 사용자의 데이터 생성에 일정 시간이 소요되므로 월 별 롤링 창은 신속성과 감지 가능성 사이의 균형을 유지합니다. 월별 데이터셋은 일반적인 좋은 품질의 단어 임베딩을 훈련하는 데 사용되는 일반적인 데이터셋과 비교할 때 상대적으로 작습니다 (약 2천만 단어). 사전 훈련된 모델에서의 웜 스타트는 도메인 내 데이터가 학습된 임베딩을 거의 변경하지 않아서 도움이 되지 않았습니다.\n\n데이터 품질을 향상시키기 위해 여러 데이터 정리 프로세스를 개발했습니다. 동시에 단어 임베딩 품질에 영향을 미치는 데이터 양과 품질을 완화하기 위해 모델링 기술을 혁신했습니다.\n\n데이터 외에도 브랜드 인식 점수를 신뢰할 수 있는 것으로 만들기 위해 다양한 단어 임베딩 훈련 기술을 탐색하고 비교했습니다.\n\n## Word2Vec\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWord2Vec은 2013년 이후로 가장 간단하면서도 널리 사용되는 단어 임베딩 모델 중 하나입니다. 우리는 Gensim을 사용하여 CBOW 기반 Word2Vec 모델을 구축했습니다. Word2Vec은 도메인 내 단어 임베딩을 어느 정도 만들어내고, 무엇보다도 유추 개념을 생성했습니다. 우리의 도메인별 단어 임베딩에서는 Airbnb 도메인의 유추를 포착할 수 있었습니다. \"호스트\" - \"제공\" + \"손님\" ~= \"필요\", \"도시\" - \"쇼핑몰\" + \"자연\" ~= \"공원\"과 같은 예시가 있습니다.\n\n## FastText\n\nFastText는 단어의 내부 구조를 고려하며, 어휘에 없는 단어나 더 작은 데이터셋에 대해 더 견고합니다. 또한 Sense2Vec에서 영감을 받아 우리는 단어를 감정(즉, 긍정적, 부정적, 중립적)과 연관시켜 브랜드 인식 개념을 감정 수준에서 형성합니다.\n\n## DeBERTa\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최근의 transformer 기반 언어 모델(예: BERT)의 발전은 문맥화된 단어 임베딩을 생성하는 장점으로 NLU 작업의 성능을 현저히 향상시켰습니다. 우리는 DeBERTa 기반 단어 임베딩을 개발했는데, 이는 작은 데이터셋에서 더 잘 작동하며, 분리된 어텐션 메커니즘을 통해 주변 컨텍스트에 더 많은 주의를 기울입니다. 우리는 Transformer를 사용하여 모든 것을 처음부터 훈련시켰고, 연결된 마지막 어텐션 레이어 임베딩이 우리 경우에 가장 좋은 단어 임베딩으로 나타났습니다.\n\n## 브랜드 인식 점수 안정화 및 보정\n\n단어 임베딩의 변동성은 널리 연구되어 왔습니다(Borah, 2021). 그 원인은 딥러닝 모델의 기저 확률적 성격(예: 단어 임베딩의 임의 초기화, 지역 최적화로 이어지는 임베딩 학습)부터 데이터 말뭉치의 양과 질이 시간에 따라 변하는 것에 이르기까지 다양합니다.\n\nBrandometer를 사용할 때 임베딩 간의 변동성을 줄여 안정적인 시계열 추적을 생성해야 합니다. 안정적인 임베딩 거리는 시계열 데이터에 존재하는 고유한 패턴과 구조를 보존하는 데 도움이 되며, 따라서 추적 프로세스의 예측 가능성을 향상시킵니다. 게다가, 이는 노이즈 국면에 강건한 추적 프로세스를 만들어냅니다. 우리는 영향을 미치는 요소를 연구하고 변동성을 줄이기 위해 다음 단계를 취했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 부트스트랩 샘플링을 사용하여 반복적인 훈련을 통한 점수 평균화\n- 순위 기반 인식 점수\n\n각 달의 데이터마다 동일한 초매개변수를 가진 N개의 모델을 훈련시켜 N개의 인식 점수 평균을 각 개념의 최종 점수로 삼았습니다. 한편, 각 모델이 월별로 동일한 수의 데이터 포인트에서 반복할 수 있도록 업샘플링을 수행했습니다.\n\n변동성을 다음과 같이 정의했습니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:922/1*pJeFFkML9OLgYyYVAChJIA.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003ctable\u003e\n    \u003cimg src=\"https://miro.medium.com/v2/resize:fit:668/1*O9bfbXD2k2yCGHAl0LmaXg.gif\" /\u003e\n\u003c/table\u003e\n\nCosSim(w)은 방정식 1에 정의된 코사인 유사도 기반 인식 점수를 나타내며, A는 알고리즘을 나타내고, M은 시간 창(즉, 월)을 나타내며, V는 어휘를 나타내며, |V|는 어휘 크기를 나타내며, n은 반복적으로 훈련된 모델의 수를 나타냅니다. \n\nN이 30에 가까워질수록 점수 변동 값은 수렴하여 좁은 간격 내에 안정화됩니다. 따라서 우리는 모든 것에 대해 N = 30을 선택했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_1.png)\n\n![Image 2](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_2.png)\n\n마리아 안토니악의 작업을 바탕으로, 우리는 단어 임베딩의 안정성을 측정하기 위해 가장 가까운 이웃들 간의 중첩을 사용했습니다. 상대적 거리가 하류 작업에서 절대 거리 값보다 중요하기 때문입니다. 따라서 유사성 기반 점수보다 안정성이 큰 순위 기반 점수를 개발했습니다.\n\n각 단어에 대해, 우리는 먼저 코사인 유사도를 내림차순으로 순위를 매겼습니다(Eq. 1). 순위 기반 유사성 점수는 그 후 1/rank(w)로 계산되며 여기서 w∈V입니다. 더 관련 있는 개념일수록 순위 기반 인식 점수가 높아집니다.\n  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n점수 변동성은 등식 2의 Variability(A, M, V)와 동일하게 정의되지만 RankSim(w)는 순위 기반 지각 점수를 나타냅니다. 순위 기반 점수로, N이 30에 접근할 때, DeBERTa의 경우 특히 점수 변동성 값이 훨씬 좁은 간격으로 수렴합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:694/1*WTrXi2M45e5zIDJg8gl0GA.gif)\n\n![이미지](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_4.png)\n\n## 디자인된 측정 항목에 따른 점수 출력 선택\n\n이 프로젝트의 한 가지 어려움은 브랜드 인식에 대한 객관적인 '진실'이 없기 때문에 어떤 점수 출력이 더 나은지 결론을 내릴 수 있는 단순하고 궁극적인 방법이 없다는 것이었습니다. 대신, 점수의 특성을 학습하기 위해 새로운 메트릭을 정의했습니다.\n\n다양한 기간을 통한 평균 분산 (AVADP)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 먼저 에어비앤비의 대한 상위 관련 브랜드 인식 그룹으로 '호스트', '휴가', '임대', '사랑', '머무름', '집', '예약', '여행', '손님'을 선정했습니다.\n- 높은 값은 서로 다른 기간에 걸쳐 변동성이 더 큼을 나타내며, 이는 선택된 브랜드 인식이 상대적으로 안정적이라고 가정되므로 월별로 크게 변동하지 않아야 한다는 것을 의미합니다.\n\n![AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_5](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_5.png)\n\n![AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_6](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 교정된 결과를 바탕으로 이 통계를 확인했습니다. 랭크 기반 점수가 유사성 기반 점수에 비해 우승자인 것을 확인할 수 있습니다:\n\n- 낮은 AVADP: 다른 기간에 비해 비순위 평가간의 변동이 더 자주 일어납니다 — 선택한 브랜드 인식이 비굴한 것으로 가정되므로 월별로 크게 변하지 않아야 하는 것으로 생각됩니다.\n\n# 브랜도미터의 사용 사례\n\n브랜드 측정 문제를 해결하려고 시작했지만, 사용 사례는 그 이상으로 확장될 수 있다고 믿습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_7.png\" /\u003e\n\n## 사용 사례 심층 분석\n\n산업 분석: 핵심 플레이어들 중 최고의 브랜드 인식 [월간 최고 인식]\n\n에어비앤비는 \"Stay\"와 \"Home\"과 같은 최고 인식을 통해 \"소속감\"이라는 브랜드 이미지를 제공하며, 우리의 미션 성명과 독특한 공급 재고를 반영합니다. 다른 회사들은 \"Rental\", \"Room\", \"Booking\"과 같이 기능성을 설명하는 것이 아닌 인간적 감각이 아닌 기능을 설명하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_8.png)\n\nTop Emerging Perception은 월간 상위 인식에서 온라인에서 논의되는 중요한 이벤트를 보여줍니다.\n\n상위 10가지 인식은 일반적으로 매월 안정적입니다. 최상위 인식에는 Home, Host, Stay, Travel, Guest, Rental 등이 포함됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한편, 우리는 Brandometer를 사용하여 최상위 목록으로 올라가는 신흥 인식을 모니터링합니다. 이는 브랜드나 사용자 선호도 변화와 관련된 주요 이벤트를 반영할 수 있습니다.\n\n주요 캠페인 모니터링(시계열 추적)\n\n기업은 제품을 홍보하고 브랜드 이미지를 확장하기 위해 캠페인을 만듭니다. 한 관련 캠페인 이후에 특정 브랜드 테마의 인식 변화를 포착할 수 있었습니다.\n\n![이미지](/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 사용 사례는 시작에 불과합니다. 기본적으로 이것은 커뮤니티의 요구 사항과 인식을 배우는 과정에서 대규모 온라인 의견을 수집하는 혁신적인 방법입니다. 저희는 이러한 통찰을 어떻게 활용하여 계속해서 에어비앤비 경험을 향상시키는지에 대해 지속적으로 고민하고 반성할 것입니다.\n\n# 다음 단계\n\n에어비앤비의 혁신적인 브랜도미터는 이미 소셜 미디어 데이터로부터 브랜드 인식을 성공적으로 캡처해왔습니다. 향후 개선 방향은 다음과 같습니다:\n\n- 보다 명확하고 간결한 통찰을 위한 더 나은 콘텐츠 세분화.\n- 소셜 미디어 브랜드 인식을 반영하는 더 많은 지표 개발.\n- Airbnb뿐만 아니라 동일 시장 세그먼트의 다른 기업들에 대한 데이터 기반 강화하여 포괄적인 통찰을 얻기.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이런 종류의 작업이 매력적으로 들린다면, 오픈된 역할들을 확인해보세요 - 우리는 채용 중이에요!\n\n## 감사의 말씀\n\nAirbnb 브랜더미터를 향상시키고 완성하는 데 최고의 아이디어를 제공해준 Mia Zhao, Bo Zeng, Cassie Cao에게 감사드립니다. 사회적 미디어 데이터 통합을 지지해준 Jon Young, Narin Leininger, Allison Frelinger에게 감사드립니다. 피드백과 제안을 해주신 Linsha Chen, Sam Barrows, Hannah Jeton, Irina Azu에게 감사드립니다. 블로그 글의 내용을 검토하고 다듬는 데 도움을 준 Lianghao Li, Kelvin Xiong, Nathan Triplett, Joy Zhang, Andy Yasutake에게 감사드립니다. 리더십 지원에 감사드리기 위해 Joy Zhang, Tina Su, Andy Yasutake에게 감사드립니다!\n\n특별히 아이디어를 시작해준 Joy Zhang에게 모든 영감을 주고 계속된 지도와 지원에 대해 특별히 감사드립니다!","ogImage":{"url":"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png"},"coverImage":"/assets/img/2024-05-20-AirbnbBrandometerPoweringBrandPerceptionMeasurementonSocialMediaDatawithAI_0.png","tag":["Tech"],"readingTime":9},{"title":"나담 옵티마이저 뒤의 수학","description":"","date":"2024-05-20 20:12","slug":"2024-05-20-TheMathBehindNadamOptimizer","content":"\n\n![이미지](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png)\n\n이전에 우리가 Adam 옵티마이저에 대해 이야기했을 때, Adam이 적응적 학습률을 효과적으로 다루면서 기계 학습에서 최적화 지형을 변화시켰다는 것을 탐구했습니다. 다양한 기계 학습 대회에서 특히 Kaggle과 같은 플랫폼에서의 성공으로 알려진 Adam은 확실히 최적화 기술에 높은 기준을 설정했습니다. 그러나 최적화 알고리즘의 진화는 거기서 멈추지 않았습니다. 여기 나담(Nadam)이 나옵니다 — Nesterov-accelerated Adaptive Moment Estimation의 약자인 Adam의 고급 후속 버전입니다.\n\n이 문서를 이해하기 위해 이전에 Adam에 대한 나의 기사를 읽을 필요는 없지만, 관심이 있다면 다음 링크에서 확인할 수 있습니다:\n\nNadam은 나스테로프 모멘텀을 통합하여 Adam 옵티마이저를 개선하며, 기울기 업데이트에 선행(lookahead) 능력을 도입합니다. 이 조정은 수렴 과정을 가속화할 뿐만 아니라 손실 함수를 최소화하기 위한 단계의 정확도도 향상시킵니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNadam을 Adam보다 선택해야 하는 이유는 무엇일까요? 이 기사는 Nadam의 메커니즘을 분석하고 Adam과 비교하며 실제 적용에서의 통찰을 제공하여 이 질문에 대답합니다. 우리는 이를 지원하는 수학적 내용을 알아볼 것이며, Python에서 최적화 도구를 처음부터 구축하여 그것이 어떻게 실행되는지 살펴볼 것입니다. 이 기사를 마치면 기계 학습 프로젝트에 Nadam이 좋은 선택일 수 있는 시기와 이유를 명확히 이해하게 되어, 당신이 필요로 하는 최적화 도구에 대해 정보를 잘 얻을 수 있게 해줄 것입니다.\n\n## 목차\n\n1: Nadam: 개념 및 기원\n∘ 1.1: Nadam이란 무엇인가?\n∘ 1.2: Nadam이 Adam을 기반으로하는 방식\n\n2: Nadam 뒤에 숨은 메커니즘\n∘ 2.1: 초기화\n∘ 2.2: 각 타임 스텝(𝑡)에 대한 반복적인 업데이트\n∘ 2.3: 네스테로프 모멘텀 보정\n∘ 2.4: 편향 보정\n∘ 2.5: 매개변수 업데이트\n∘ 2.6: Adam과의 주요 차이점\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 실무에서 Nadam 구현하기\n  - 3.1: Nadam Optimizer 클래스 정의\n  - 3.2: 선형 회귀 모델 클래스\n  - 3.3: 모델 트레이너 클래스\n  - 3.4: 데이터셋 처리 및 모델 훈련\n\n4. 장점과 고려사항\n  - 4.1 Nadam의 우수성\n  - 4.2 한계와 도전 과제\n\n결론\n\n참고문헌\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1: 나담: 개념과 기원\n\n## 1.1: 나담이란?\n\n나담은 뉴럴 네트워크를 최적화하기 위해 기계 학습에서 널리 사용되는 아담 옵티마이저를 개선한 것입니다. 이는 아담의 적응 학습률 기능과 네스테로프 모멘텀의 예측 능력을 통합하였습니다.\n\n이 개선은 모델이 수렴하는 속도를 높일뿐만 아니라 복잡한 최적화 과제를 효과적으로 해결하는 방법을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n나담(Nadam) 뒤에 있는 아이디어는 1980년대 유리 네스테로프(Yuri Nesterov)의 선도적인 작업으로 거슬러 올라갈 수 있습니다. 그 당시 네스테로프는 네스테로프의 가속 그래디언트(Nesterov’s accelerated gradient, NAG)를 소개했습니다. NAG의 목표는 기울기 중심의 최적화 알고리즘의 수렴을 가속화하여 기울기의 경로를 가장 낮은 점으로 더 잘 지시하는 것이었습니다. 이 전략을 아담(Adam)의 적응형 학습률 조정과 결합하여, 나담은 이러한 기본 개념을 향상시켜 최적화 알고리즘의 능력을 크게 향상시킵니다.\n\n## 1.2: 나담(Nadam)이 아담(Adam)을 바탕으로 어떻게 구축되는가\n\n나담은 아담이 설정한 프레임워크를 바탕으로 업데이트가 어떻게 계산되는지를 조정함으로써 구축됩니다. 아담이 과거 제곱 기울기와 과거 기울기의 지수 이동 평균을 사용하는 반면, 나담은 기울기 업데이트 규칙을 수정합니다. 나담은 누적된 기울기 방향으로 적극적으로 전진하며, 미래 기울기를 예측하는 종류의 \"모멘텀\"(momentum)을 활용합니다.\n\n이를 더 잘 이해하기 위해 최적화 경로를 보는 것을 상상해보세요. 위의 이미지는 나담과 아담이 최적화 랜드스케이프를 통해 어떻게 이동하는지 개념적으로 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![TheMathBehindNadamOptimizer](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_1.png)\n\n이 그림에서 두 옵티마이저는 동일한 지점에서 시작합니다. \"Adam\"은 효율적인 수렴과 적응력을 나타내는 평탄하고 잘 포장된 고속도로 위에 있습니다. \"Nadam\"은 가끔 충격이 있는 약간 더 구불구불한 도로 위에 있으며 종종 최소값 지점을 향해 더 날카로운 회전을 하곤 합니다. 이러한 행동은 예상 업데이트에 의해 주도되며 Adam보다 덜 최적의 경로를 더 효과적으로 피할 모멘텀을 제공합니다. 이 능력은 Nadam이 Adam과 Nesterov 모멘텀의 강점을 결합하여 복잡한 손실 함수 랜드스케이프에 특히 적합한 강력한 옵티마이저를 형성한다는 것을 보여줍니다.\n\n## 2: Nadam의 작동 메커니즘\n\nNadam은 Adam 옵티마이저의 메커니즘을 Nesterov 모멘텀과 똑똑하게 결합하여 학습을 최적화합니다. 주요 방정식을 살펴보고 Adam과 비교하여 업데이트 규칙의 차이점을 강조해보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.1: 초기화\n\n시작할 때, Nadam은 첫 번째 및 두 번째 모멘트 벡터를 초기화합니다. 이 벡터들은 기울기와 제곱 기울기의 이동 평균을 저장하는 데 중요합니다. 시간이 지남에 따라 매개 변수 업데이트를 부드럽게 합니다.\n\n![그림](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_2.png)\n\n동시에 우리는 반복의 시작을 표시하는 초기 타임스텝을 설정합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-TheMathBehindNadamOptimizer_3.png\" /\u003e\n\n## 2.2: 각 타임 스텝(𝑡)별 반복적 업데이트\n\n각 반복(𝑡)에 대해, 해당 시점의 매개변수에 대한 손실 함수의 기울기(𝑔_𝑡)를 계산하는 것으로 시작합니다. 이 기울기는 함수의 손실이 가장 빠르게 증가하는 방향을 가리킵니다.\n\n편향된 첫 번째 모멘트 추정값 업데이트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![매쓰사인네처날날담옵티마이저 그림 4](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_4.png)\n\n첫 번째 모멘트(𝑚_𝑡)는 과거 그래디언트의 지수적 평균이며, 이는 감쇠율(β1, 일반적으로 0.9 주변)을 사용하여 업데이트됩니다. 이 비율은 과거 그래디언트 정보 대비 새 데이터 유지 비율에 영향을 미치며, 더 높은 β1은 더 부드럽지만 더 반응이 느린 추정치로 이어집니다.\n\n편향된 두 번째 모멘트 추정 업데이트\n\n![매쓰사인네처날날담옵티마이저 그림 5](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_5.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비슷하게, 두 번째 모멘트 (𝑣_𝑡)은 이전 그래디언트의 제곱의 지수 가중 평균을 추적합니다. 여기서 감쇠율 (β2, 일반적으로 약 0.999)은 매개변수 업데이트의 변동성에 따라 학습률을 조정하여 업데이트를 안정화하는 데 도움을 줍니다.\n\n## 2.3: 네스테로프 모멘텀 보정\n\n![이미지](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_6.png)\n\n여기서 Nadam은 일반적인 모멘트 계산을 수정하여 네스테로프 모멘텀을 통합합니다. 이 접근 방식은 그래디언트의 미래 위치를 예상하여 업데이트 방향을 보정합니다. 이러한 선행은 초기에 제로 초기화된 모멘트가 편향된 업데이트를 초래할 수 있는 훈련 초기에 특히 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.4: 편향 보정\n\n첫 번째 및 두 번째 모멘트 추정치의 편향을 보정하세요:\n\n![Image](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_7.png)\n\n첫 번째와 두 번째 모멘트는 처음에는 영에서 시작하기 때문에 편향되어 있습니다. 이를 극복하기 위해 편향 보정 용어가 도입되었으며, 더 많은 반복이 완료됨에 따라 모멘트의 추정치를 점진적으로 확대하여, 추정치가 시간이 지남에 따라 보다 정확하고 진짜 기울기 정보를 반영하도록 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.5: 매개변수 업데이트\n\n![Image](/assets/img/2024-05-20-TheMathBehindNadamOptimizer_8.png)\n\n최종 매개변수 업데이트는 기울기의 방향에 대해 조정된 적응형 학습률(𝛼)과 작은 상수(𝜖, 10^(-8)과 같은)로 수치적 안정성을 위해 이루어집니다. 수정된 첫 번째 모멘트(𝑚_𝑡)와 수정된 두 번째 모멘트의 제곱근(𝑣_𝑡)은 이러한 업데이트를 적절하게 조정하는 데 사용되며, 기울기의 방향과 크기를 모두 고려합니다.\n\n## 2.6: Adam과의 주요 차이점\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNadam과 Adam 사이의 주요 차이점은 Nadam이 적극적으로 조정을 합니다. Adam은 현재 기울기 추정만을 의존하는 반면, Nadam은 Nesterov 모멘텀을 통해 앞서 보는 단계를 도입합니다. 이로 인해 미래의 기울기 방향을 예측뿐만 아니라 업데이트를 더 정확하게 조정하여 더 효율적인 학습 역학을 이끌어냅니다.\n\nNadam은 Nesterov 모멘텀의 통합을 통해 최적화에 대해 보다 섬세하고 선심을 기울인 접근 방식을 제공하여 Adam보다 데이터 landscape를 효과적으로 탐색하고 적응하는 능력을 향상시킵니다. 이로써 Nadam은 다양한 머신 러닝 과제에 대한 견고한 선택지가 되며, 실제 결과를 선택할 때 이론적 통찰력과 실용적 결과를 모두 고려하도록 실무자에게 요청합니다.\n\n## 3. 실무에서 Nadam 구현\n\n이 섹션에서는 Nadam 옵티마이저를 처음부터 구축하고 머신 러닝 환경에서 적용할 것입니다. 우리는 선형 회귀 작업에 Nadam 옵티마이저를 구현하고 사용하는 맥락에서 코드를 여러 주요 섹션으로 분할할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래의 코드를 살펴보고 싶다면, 오늘 다룰 코드와 추가적인 보너스 콘텐츠가 모두 포함된 이 Jupyter 노트북을 살펴보는 것을 고려해보세요:\n\n## 3.1: Nadam Optimizer Class Definition\n\nNadam 알고리즘을 사용하여 매개변수를 최적화하는 데 중요한 역할을 하는 NadamOptimizer 클래스를 자세히 살펴봅시다.\n\n```js\nclass NadamOptimizer:\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n        self.learning_rate = learning_rate\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n        self.m = None\n        self.v = None\n        self.t = 0\n\n    def initialize_moments(self, params):\n        self.m = {k: np.zeros_like(v) for k, v in params.items()}\n        self.v = {k: np.zeros_like(v) for k, v in params.items()}\n\n    def update_params(self, params, grads):\n        if self.m is None or self.v is None:\n            self.initialize_moments(params)\n\n        self.t += 1\n        updated_params = {}\n        mu_t = self.beta1 * (1 - 0.5 * 0.96 ** (self.t * 0.004))\n        mu_t1 = self.beta1 * (1 - 0.5 * 0.96 ** ((self.t + 1) * 0.004))\n        for key in params.keys():\n            g_tilde = grads[key] / (1 - np.prod([self.beta1] * self.t))\n            self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n            self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * np.square(grads[key])\n\n            m_corrected = self.m[key] / (1 - mu_t1 ** self.t)\n            v_corrected = self.v[key] / (1 - self.beta2 ** self.t)\n\n            m_bar = (1 - mu_t) * g_tilde + mu_t1 * m_corrected\n\n            updated_params[key] = params[key] - self.learning_rate * m_bar / (np.sqrt(v_corrected) + self.epsilon)\n\n        return updated_params\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNadamOptimizer 클래스는 Nadam 최적화 방법을 관리하고 실행하기 위해 구조화되어 있습니다. 아래는 클래스와 해당 함수들을 설명한 것입니다:\n\n__init__ 메서드\n\n```python\nclass NadamOptimizer:\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n        self.learning_rate = learning_rate\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n        self.m = None\n        self.v = None\n        self.t = 0\n```\n\n초기화 메서드는 최적화기를 학습률, 베타 값, 그리고 엡실론에 대한 미리 정의된 설정으로 설정합니다. 이러한 매개변수 각각은 중요한 역할을 합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 학습률: 이는 손실 함수의 최소값으로 이동하는 각 반복에서의 단계 크기를 결정합니다.\n- beta1 및 beta2: 이러한 매개 변수는 기울기와 해당 제곱값의 이동 평균의 감쇠율을 제어하며 업데이트를 부드럽게 만들고 학습률을 동적으로 관리하는 데 도움이 됩니다.\n- epsilon: 계산 중에 0으로 나누는 것을 방지하기 위한 매우 작은 수입니다.\n- self.m 및 self.v: 초기에 None으로 설정되며 나중에는 각각 기울기와 제곱 기울기의 이동 평균을 저장합니다.\n- self.t: 업데이트 또는 반복 횟수를 추적하는 카운터입니다.\n\n이 설정은 Nadam의 기본 측면과 일치하며, 적응형 학습률이 지속적으로 조정되어 수렴을 개선합니다.\n\ninitialize_moments 메서드\n\n```js\n    def initialize_moments(self, params):\n        self.m = {k: np.zeros_like(v) for k, v in params.items()}\n        self.v = {k: np.zeros_like(v) for k, v in params.items()}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 메소드는 이동 평균을 저장하는 딕셔너리 m과 v를 초기화합니다. 각 매개변수의 기울기와 제곱 기울기가 0으로 초기화되는데, 이는 최적화 프로세스의 후속 단계에서 계산을 시작하는 데 중요합니다.\n\nupdate_params 메소드\n\n```js\n    def update_params(self, params, grads):\n        if self.m is None or self.v is None:\n            self.initialize_moments(params)\n\n        self.t += 1\n        updated_params = {}\n        mu_t = self.beta1 * (1 - 0.5 * 0.96 ** (self.t * 0.004))\n        mu_t1 = self.beta1 * (1 - 0.5 * 0.96 ** ((self.t + 1) * 0.004))\n        for key in params.keys():\n            g_tilde = grads[key] / (1 - np.prod([self.beta1] * self.t))\n            self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n            self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * np.square(grads[key])\n\n            m_corrected = self.m[key] / (1 - mu_t1 ** self.t)\n            v_corrected = self.v[key] / (1 - self.beta2 ** self.t)\n\n            m_bar = (1 - mu_t) * g_tilde + mu_t1 * m_corrected\n\n            updated_params[key] = params[key] - self.learning_rate * m_bar / (np.sqrt(v_corrected) + self.epsilon)\n\n        return updated_params\n```\n\n이 함수는 Nadam 옵티마이저의 핵심입니다. 전달된 기울기를 기반으로 매개변수를 업데이트합니다. 포함된 단계는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n순간 초기화 확인\n\n```js\nif self.m이 None이거나 self.v가 None이면:\n            self.initialize_moments(params)\n```\n\n만약 m 또는 v가 초기화되지 않았다면 0으로 설정됩니다.\n\n시간 단계 업데이트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n셀프.티 += 1\n```\n\ndecay factors를 동적으로 조절하는 시간 단계 t를 증가시킵니다.\n\n네스테로프 모멘텀 조정\n\n```js\n뮤_티 = self.beta1 * (1 - 0.5 * 0.96 ** (self.티 * 0.004))\n뮤_t1 = self.beta1 * (1 - 0.5 * 0.96 ** ((self.티 + 1) * 0.004))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nmu_t 및 mu_t1은 시간 단계의 진행을 고려하여 Nesterov 모멘텀의 효과를 반영하기 위해 beta1을 조정합니다. 이러한 조정은 모멘텀이 미래의 기울기를 더 효과적으로 반영하도록 합니다.\n\n각 매개변수를 순회하면서:\n\n```js\nfor key in params.keys():\n      g_tilde = grads[key] / (1 - np.prod([self.beta1] * self.t))\n      self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n      self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * np.square(grads[key])\n\n      m_corrected = self.m[key] / (1 - mu_t1 ** self.t)\n      v_corrected = self.v[key] / (1 - self.beta2 ** self.t)\n\n      m_bar = (1 - mu_t) * g_tilde + mu_t1 * m_corrected\n```\n\ng_tilde은 과거 그래디언트의 감쇠를 현재 시간 단계까지 반영한 조정된 기울기를 계산합니다. 이는 lookahead를 포함하여 그래디언트 계산을 수정하여 Nesterov 모멘텀의 효과를 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n나중에는 새로운 기울기와 조정된 베타 값에 기초하여 각 매개변수에 대해 m과 v를 조정합니다. 이 단계는 과거 기울기의 모멘텀 이점과 새로운 기울기에 대한 적응성을 결합하는 중요한 단계입니다.\n\nm_corrected와 v_corrected는 편향이 수정된 제1 및 제2 모먼트의 추정치를 나타냅니다. 바이어스 보정은 계산된 기울기가 더 적을 때 교육 초기에 중요합니다.\n\nm_bar는 미래의 그래디언트와 모멘텀이 보정된 그래디언트를 결합하여 매개변수 공간에서 취해야 할 단계의 방향과 크기를 효과적으로 결정합니다.\n\n매개변수 업데이트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nupdated_params[key] = params[key] - self.learning_rate * m_bar / (np.sqrt(v_corrected) + self.epsilon)\n\n\n모든 매개변수는 m_bar와 조정된 학습률에 의해 업데이트되며, v_corrected에 제곱근을 더한 것으로 스케일링됩니다. 이 단계는 실제 매개변수 업데이트가 발생하는 곳으로, 모델의 학습에 직접적인 영향을 미칩니다.\n\n## 3.2: 선형 회귀 모델 클래스\n\n이제 간단한 회귀 모델을 구축하고, Nadam 옵티마이저를 적용해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 선형 회귀 모델\nclass LinearRegression:\n    def __init__(self, n_features):\n        self.weights = np.random.randn(n_features)\n        self.bias = np.random.randn()\n\n    def predict(self, X):\n        return np.dot(X, self.weights) + self.bias\n```\n\n여기서 __init__ 메서드는 features 수에 기반하여 랜덤한 weights와 biases로 모델을 초기화합니다.\n\n그런 다음 predict 메서드는 입력과 weights 및 bias의 내적을 사용하여 예측을 계산합니다.\n\n여기서 선형 회귀는 Nadam이 어떻게 작동하는지 이해하는 간단한 방법을 제공하지만, 실제로는 더 복잡한 딥러닝 모델에서 Nadam을 사용하려고 할 것입니다. 그렇다면, 가장 인기 있는 딥러닝 모델 중 일부를 포괄적으로 이해할 수 있는 다음의 글을 살펴보고 그 코드를 수정하여 Nadam을 구현해보기를 강력히 추천합니다:```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.3: Model Trainer Class\n\n앞으로 나아가봅시다. 이제는 지정된 최적화 도구를 사용하여 머신 러닝 모델을 훈련시키는 전체 과정을 캡슐화하는 클래스가 필요합니다. 이것이 바로 ModelTrainer 클래스가 할 일입니다.\n\n```js\nclass ModelTrainer:\n    def __init__(self, model, optimizer, n_epochs):\n        self.model = model\n        self.optimizer = optimizer\n        self.n_epochs = n_epochs\n\n    def compute_gradients(self, X, y):\n        predictions = self.model.predict(X)\n        errors = predictions - y\n        dW = 2 * np.dot(X.T, errors) / len(y)\n        db = 2 * np.mean(errors)\n        return {'weights': dW, 'bias': db}\n\n    def train(self, X, y, verbose=False):\n        for epoch in range(self.n_epochs):\n            grads = self.compute_gradients(X, y)\n            params = {'weights': self.model.weights, 'bias': self.model.bias}\n            updated_params = self.optimizer.update_params(params, grads)\n\n            self.model.weights = updated_params['weights']\n            self.model.bias = updated_params['bias']\n\n            # Optionally, print loss here to observe training\n            loss = np.mean((self.model.predict(X) - y) ** 2)\n            if epoch % 1000 == 0 and verbose:\n                print(f\"Epoch {epoch}, Loss: {loss}\")\n```\n\n__init__ 메서드\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\n    def __init__(self, model, optimizer, n_epochs):\n        self.model = model\n        self.optimizer = optimizer\n        self.n_epochs = n_epochs\n```\n\n이 생성자 메서드는 세 가지 주요 구성 요소로 트레이너를 초기화합니다:\n\n- model: 훈련될 머신러닝 모델이며, 예측을 수행하는 메서드와 매개변수(가중치 및 편향)에 대한 속성이 있어야 합니다.\n- optimizer: Nadam과 같은 옵티마이저 클래스의 인스턴스로, 계산된 그래디언트에 기초하여 모델의 매개변수를 업데이트하는 역할을 담당합니다.\n- n_epochs: 훈련 프로세스가 실행할 훈련 데이터 세트를 전체적으로 순회하는 횟수입니다.\n\n이러한 구성 요소는 손실 함수를 최소화하기 위해 모델의 매개변수가 반복적으로 업데이트되는 훈련 프로세스를 설정하는 데 필수적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\ncompute_gradients 메서드\n\n```python\ndef compute_gradients(self, X, y):\n    predictions = self.model.predict(X)\n    errors = predictions - y\n    dW = 2 * np.dot(X.T, errors) / len(y)\n    db = 2 * np.mean(errors)\n    return {'weights': dW, 'bias': db}\n```\n\n이 메서드는 모델 매개변수에 대한 손실 함수의 그래디언트를 계산합니다:\n\n```python\npredictions = self.model.predict(X)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 모델이 현재 매개변수를 사용하여 입력 X를 기반으로 출력을 예측하는 부분입니다.\n\n```js\n오류 = 예측 - y\n```\n\n이 코드 라인은 예측된 출력과 실제 출력인 y와의 차이, 즉 오차를 나타냅니다.\n\n```js\ndW = 2 * np.dot(X.T, 오류) / len(y)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 가중치의 기울기를 계산합니다. 가중치에 대한 평균 제곱 오차 손실 함수의 도함수는 len(y)의 데이터 포인트에 의해 조정된 표현으로 주어집니다. 이는 모든 특성과 데이터 포인트에 대한 기울기를 효율적으로 계산하는 벡터화된 구현입니다.\n\n```js\ndb = 2 * np.mean(errors)\n```\n\n마찬가지로, 이는 편향의 기울기를 계산하며, 이는 단순히 오차의 평균에 2를 곱한 것입니다.\n\n```js\nreturn {'weights': dW, 'bias': db}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러면 메서드는 이러한 그래디언트를 딕셔너리로 반환하여 모델의 매개변수를 업데이트하는 데 사용할 수 있도록 합니다. 이 메서드는 옵티마이저가 손실을 최소화하기 위해 매개변수를 조정해야 하는 필수적인 기울기 계산 단계를 캡슐화합니다.\n\ntrain 메서드\n\n```python\n    def train(self, X, y, verbose=False):\n        for epoch in range(self.n_epochs):\n            grads = self.compute_gradients(X, y)\n            params = {'weights': self.model.weights, 'bias': self.model.bias}\n            updated_params = self.optimizer.update_params(params, grads)\n\n            self.model.weights = updated_params['weights']\n            self.model.bias = updated_params['bias']\n\n            # 선택사항: 여기서 손실을 출력하여 학습을 관찰합니다\n            loss = np.mean((self.model.predict(X) - y) ** 2)\n            if epoch % 1000 == 0 and verbose:\n                print(f\"Epoch {epoch}, Loss: {loss}\")\n```\n\n이 메서드는 각 epoch(데이터를 완전히 통과하는 단계)마다 n_epochs에 이르기까지 반복됩니다. 루프 내에서 현재 매개변수와 데이터 집합에 대해 compute_gradients를 사용하여 그래디언트를 먼저 계산합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그런 다음 이러한 그래디언트를 현재 매개변수와 함께 옵티마이저(self.optimizer.update_params(params, grads))에 전달하고, 옵티마이저는 최적화 알고리즘(예: Nadam)을 기반으로 업데이트된 매개변수를 반환합니다.\n\n모델의 매개변수는 이러한 새 값으로 업데이트되어 손실을 최소화하는 상태로 움직이게 됩니다.\n\nverbose가 True로 설정되어 있는 경우, 메서드는 1000번의 epoch마다 손실을 인쇄하여 교육 진행 상황을 모니터링합니다. 손실은 예측 값과 실제 출력 사이의 평균 제곱 오차로 계산되며, 모델의 성능을 얼마나 잘 평가하고 있는지에 대한 간단한 지표를 제공합니다.\n\ntrain 메서드는 따라서 전체 교육 과정을 조정하며, 손실 함수의 피드백에 기초하여 옵티마이저를 통해 모델의 매개변수를 반복적으로 조정합니다. 이 메서드는 머신러닝에서 사용되는 반복적 최적화 기법의 실용적 구현이며, 그래디언트 하강과 매개변수 업데이트의 이론적 원리를 직접 적용하여 여러 번의 반복을 통해 미리 정의된 손실 함수를 최소화합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.4: 데이터셋 처리 및 모델 훈련\n\n마지막으로, Nadam 옵티마이저를 사용하여 머신러닝 모델을 설정, 훈련 및 평가해 봅시다. 이 접근 방식은 데이터 조작, Optuna를 사용한 하이퍼파라미터 튜닝, 그리고 모델의 효과를 개선하고 평가하기 위한 반복적인 훈련 및 테스트를 포함합니다.\n\n### 3.4.1: 데이터 준비\n\n```python\n# 입력 피처(X) 및 타겟 값(y) 가져오기\nX = diabetes.data\ny = diabetes.target\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우선, 당뇨 데이터셋에서 피처 데이터(X)와 타겟값(y)을 불러옵니다. 이 데이터셋은 sci-kit learn에서 가져오며 상업적 이용이 가능합니다. (Scikit-learn: Python의 머신 러닝, Pedregosa et al., JMLR 12, pp. 2825–2830, 2011.)\n\n```js\n# 데이터셋을 훈련 세트와 테스트 세트로 나눕니다\ndef split_dataset(X, y, test_ratio=0.2):\n    indices = np.random.permutation(len(X))\n    test_size = int(len(X) * test_ratio)\n    test_indices = indices[:test_size]\n    train_indices = indices[test_size:]\n    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n\nX_train, X_test, y_train, y_test = split_dataset(X, y)\nX_train, X_val, y_train, y_val = split_dataset(X_train, y_train)\n```\n\nsplit_dataset 함수는 지정된 비율에 따라 데이터셋을 훈련 세트와 테스트 세트로 무작위로 분할합니다. 데이터셋 인덱스를 섞어 분할을 무작위로 다양하게 만들어 모델 평가를 견고하게 합니다. 훈련 세트는 모델 매개변수를 학습하는 데 사용되고, 테스트 세트는 모델이 보지 못한 데이터에서 얼마나 잘 수행되는지를 평가합니다.\n\n3.4.2: Optuna을 이용한 하이퍼파라미터 튜닝\n우리는 Optuna를 사용하여 모델의 하이퍼파라미터를 최적화할 것이며, 이는 훈련 동적과 Nadam 옵티마이저의 효과에 상당한 영향을 미칩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 기사에서 우리는 옵투나(optuna)를 광범위하게 다루었습니다. 거기에서는 이를 신경망에 적용하여 성공적으로 세밀하게 조정하는 방법을 보여주었습니다. 만약 Nadam을 더 복잡한 모델에 적용하고 싶다면, 이 기사를 읽어보시면 좋을 것 같아요:\n\n목적 함수 정의\n\n```python\ndef objective(trial):\n    n_features = X_train.shape[1]\n\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n    beta1 = trial.suggest_uniform('beta1', 0.9, 0.999)\n    beta2 = trial.suggest_uniform('beta2', 0.99, 0.9999)\n    epsilon = trial.suggest_loguniform('epsilon', 1e-10, 1e-5)\n\n    n_epochs = trial.suggest_int('epochs', 1000, 100000)\n\n    # Define the model\n    model = LinearRegression(n_features)\n    optimizer = NadamOptimizer(learning_rate=learning_rate, beta1=beta1, beta2=beta2, epsilon=epsilon)\n    trainer = ModelTrainer(model, optimizer, n_epochs=n_epochs)\n\n    # Train the model\n    trainer.train(X_train, y_train, verbose=False)\n\n    # Compute the validation loss\n    val_loss = np.mean((model.predict(X_val) - y_val) ** 2)\n\n    return val_loss\n```\n\n우리의 목적 함수는 옵투나(optuna)의 최적화 과정을 안내하는 중요한 역할을 합니다. 각 시도는 다음 값을 제안합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 학습률: 매개변수 업데이트의 단계 크기에 영향을 줍니다.\n- beta1 및 beta2: 그래디언트 및 그들의 제곱값에 대한 평균의 감쇠율을 조절합니다.\n- epsilon: 업데이트 중에 0으로 나누는 것을 방지하기 위해 작은 값이 추가됩니다.\n\n각 시도는 이러한 매개변수를 사용하여 LinearRegression 모델과 NadamOptimizer를 설정하고, ModelTrainer를 사용하여 모델을 훈련합니다. 훈련 후, 검증 세트에서의 검증 손실을 계산하여 하이퍼파라미터의 효과를 Optuna에 제공합니다.\n\n```js\n# 연구 객체 생성\noptuna.logging.set_verbosity(optuna.logging.WARNING)\nstudy = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n\n# 연구 개선, 더 많은 시행을 사용하여 더 나은 결과를 얻거나, 더 적은 시행을 사용하여 더 비용 효율적일 수 있습니다\nstudy.optimize(objective, n_trials=10)\n```\n\nOptuna가 최적의 매개변수를 식별한 후, 최종 모델이 구성되고 훈련됩니다. 이 단계에서는 테스트 세트에서 모델의 일반화 능력을 평가합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 및 평가\n\n```js\n# 최적 모델 가져오기\nn_features = X_train.shape[1]\nbest_model = LinearRegression(n_features)\noptimizer = NadamOptimizer(learning_rate=study.best_params['learning_rate'],\n                          beta1=study.best_params['beta1'],\n                          beta2=study.best_params['beta2'],\n                          epsilon=study.best_params['epsilon'])\n\n# 모델 훈련하기\ntrainer = ModelTrainer(best_model, optimizer, n_epochs=study.best_params['epochs'])\ntrainer.train(X_train, y_train)\n```\n\nOptuna의 최적 매개변수를 사용하여 모델은 추가 훈련을 받습니다. 이 추가 훈련을 통해 모델이 데이터에 완전히 적응하도록 보장합니다.\n\n```js\n# 테스트 손실 계산하기\ntest_loss = np.mean((best_model.predict(X_test) - y_test) ** 2)**0.5\nprint(f'테스트 손실: {test_loss:.2f}')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마침내, 새로운, 보지 못했던 데이터에 대한 모델의 예측 정확도를 평가하기 위해 시험 손실을 계산합니다. 이 측정값은 모델의 실용적 성능을 평가하는 데 중요합니다.\n\n# 4. 장점과 고려 사항\n\n## 4.1 Nadam이 뛰어난 점\n\nNadam은 Adam을 바탕으로 네스테로프 모멘텀을 통합하여, 그레이디언트가 믿을 수 없거나 에포크 간 크게 다를 수 있는 복잡한 최적화 작업을 처리할 수 있는 능력을 향상시킵니다. 여기에서 Nadam이 빛을 발합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n딥 뉴럴 네트워크: Nadam은 수렴 속도가 중요한 딥 뉴럴 네트워크의 학습에서 뛰어납니다. 미래를 예측하는 기능이 수렴 속도를 높이는 데 도움을 주어 모델이 최적이 아닌 해결책에 갇히지 않도록 합니다.\n\n희소한 데이터: 텍스트나 대규모 범주형 데이터와 같은 많은 영 피처를 포함한 데이터셋에 대해서는 Nadam이 매개변수 업데이트를 더 효과적으로 조정하여 희소한 정보를 더 잘 관리합니다.\n\n잡음이 많은 데이터: 실시간 스트림이나 온라인 학습과 같이 잡음이 많은 데이터 환경에서는 Nadam의 변동 데이터 처리 및 적응형 학습률 조정이 특히 유용합니다.\n\n## 4.2 한계와 도전과제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 강점에도 불구하고, Nadam은 항상 최적의 선택이 되지는 않습니다:\n\n간단한 문제: 오차 함수가 잘 행동하고 국소 최솟값이 적은 간단한 작업의 경우, SGD와 같은 간단한 옵티마이저가 연산 요구가 적어 더 효율적일 수 있습니다.\n\n메모리 집약적 모델: Nadam은 그래디언트와 제곱 그래디언트의 모멘트 추정 값을 저장해야 하므로, 더 간단한 방법과 비교하여 메모리 사용량이 증가합니다. 이는 메모리 제한 환경에서 문제가 될 수 있습니다.\n\n하이퍼파라미터 민감도: Nadam의 성능은 𝛽1, 𝛽2 및 학습률과 같은 하이퍼파라미터의 설정에 민감합니다. 올바른 조정을 위해 포괄적인 테스트 또는 하이퍼파라미터 최적화 도구가 필요할 수 있으며, 최적의 성능을 위해 필수적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\nNadam을 탐색하는 것은 Nesterov 운동량과 Adam의 적응형 모멘트 추정을 결합하여 복잡한 머신 러닝 모델을 최적화하는데 중요한 발전을 나타냅니다. Nadam은 Adam에 선행 지식을 추가하여 매개변수 업데이트를 개선하고 수렴 속도를 향상시키며 다양한 어려운 데이터 환경에서 학습 과정을 안정화시킵니다.\n\nNadam은 최적화 알고리즘 분야에서 상당한 향상을 제공하지만, Adam보다 선택하는 것은 머신 러닝 프로젝트의 특정 요구 사항과 제약 사항을 신중히 고려해야 합니다. 최적화 기술의 지속적인 진화는 능력을 향상시키고 새로운 가능성을 열어주며, 더 많은 연구와 실험을 위한 활기찬 분야로 만들어 냅니다.\n\n# 참고문헌\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Dozat, T. (2016). “Incorporating Nesterov Momentum into Adam.” ICLR Workshop.\n- Kingma, D. P., \u0026 Ba, J. (2014). “Adam: A Method for Stochastic Optimization.” arXiv preprint arXiv:1412.6980.\n- Nesterov, Y. (1983). “A Method for Unconstrained Convex Minimization Problem with the Rate of Convergence 𝑂(1/𝑘2)O(1/k2).” Doklady AN USSR.\n- Ruder, S. (2016). “An overview of gradient descent optimization algorithms.” arXiv preprint arXiv:1609.04747.\n- Bottou, L., Curtis, F. E., \u0026 Nocedal, J. (2018). “Optimization Methods for Large-Scale Machine Learning.” SIAM Review, 60(2), 223–311.\n- Zhang, M. R., Lucas, J., Ba, J., \u0026 Hinton, G. E. (2019). “Lookahead Optimizer: k steps forward, 1 step back.” arXiv preprint arXiv:1907.08610.\n\n당신은 끝까지 왔습니다. 축하해요! 이 기사를 즐겼다면 좋아요를 누르고 저를 팔로우해주시면 감사하겠습니다. 저는 주기적으로 비슷한 기사를 게시할 것이기 때문에, 재미있게 보아 주실 것을 희망합니다. 제 목표는 가장 인기 있는 알고리즘을 모두 처음부터 다시 만들어 기계 학습을 모두에게 접근 가능하게 하는 것입니다.","ogImage":{"url":"/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png"},"coverImage":"/assets/img/2024-05-20-TheMathBehindNadamOptimizer_0.png","tag":["Tech"],"readingTime":22},{"title":"Keras 30 튜토리얼 엔드투엔드 딥 러닝 프로젝트 가이드","description":"","date":"2024-05-20 20:09","slug":"2024-05-20-Keras30TutorialEnd-to-EndDeepLearningProjectGuide","content":"\n\n![이미지](/assets/img/2024-05-20-Keras30TutorialEnd-to-EndDeepLearningProjectGuide_0.png)\n\n# 소개\n\n조금 전부터 Pytorch를 사용하기 시작했지만, 여전히 Keras의 간결한 코드 스타일과 신경망 모델을 몇 줄의 코드로 구현할 수 있던 옛날을 그리워합니다.\n\n그래서 Keras가 지난 11월에 TensorFlow에 추가하여 Pytorch와 Jax를 백엔드로 지원한다고 발표했을 때 매우 흥분했습니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 모든 것이 완벽하지는 않았습니다: 최근에 Keras 3.0이 출시되었기 때문에 관련 튜토리얼과 문서는 아직 따라가지 못한 상태였고, 코드 이관 중에 몇 가지 어려움을 겪었습니다.\n\n다행히도 노력 끝에 이제 버전 3.0을 원활하게 사용하여 다양한 end-to-end 모델 개발을 할 수 있게 되었습니다.\n\n이 글에서는 Keras 3.0을 사용하는 데 도움이 되는 실용적인 경험 몇 가지를 공유하겠습니다. Keras 3.0의 서브클래싱 API를 사용하여 end-to-end 프로젝트를 완전히 처음부터 구축하는 방법을 알려주기 위해 전형적인 인코더-디코더 순환 신경망을 예로 들 것이며, 백엔드로 Pytorch를 사용할 때 고려해야 할 세부 사항에 대해 논의할 것입니다.\n\n자, 시작해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 프레임워크 설치 및 환경 설정\n\n## 프레임워크 설치\n\n케라스 3.0 (또는 최신 버전)를 설치하는 것은 간단합니다. 공식 웹사이트의 시작 가이드 문서를 따라하면 됩니다.\n\n케라스를 설치하기 전에, 해당 CUDA 버전에 맞춰 Pytorch를 먼저 설치하는 것을 권장합니다. 사용하는 그래픽 카드 드라이버 지원에 따라 CUDA 11.8 또는 CUDA 12.1이 작동합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이토치를 백엔드로 사용할 수는 있지만, Keras 설치 과정에서 여전히 기본적으로 Tensorflow 버전 2.16.1이 설치됩니다.\n\n이 버전의 Tensorflow는 CUDA 12.3에 기반하여 컴파일되었기 때문에 Keras를 설치한 후 CUDA가 없다는 경고 메시지를 만날 수 있습니다(이 이슈를 확인하세요).\n\n```js\nCould not find cuda drivers on your machine, GPU will not be used.\n```\n\n우리는 백엔드로 파이토치를 사용 중이므로 이 경고를 무시하는 것을 권장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n혹시라도 Tensorflow 로그를 계속 보이지 않도록 영구적으로 설정하고 싶으시면, 시스템 변수를 설정할 수도 있어요.\n\n```js\nimport os\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n```\n\n## 환경 설정\n\nPyTorch와 Keras를 모두 설치한 후에는, Keras의 백엔드를 PyTorch로 설정하기 위해 환경 변수를 설정해야 해요. 이 작업은 두 가지 방법으로 할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 설정 파일을 수정해주세요.\n- 환경 변수를 설정해주세요.\n\n먼저, 설정 파일 방법에 대해 논의해보겠습니다.\n\nKeras의 설정 파일은 ~/.keras/keras.json에 있습니다. Windows를 사용 중이라면, 이 파일은 `사용자 디렉토리`/.keras/keras.json에 있습니다.\n\n물론, KERAS_HOME 환경 변수를 설정하여 .keras 디렉토리의 위치도 변경할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 Keras를 처음 설치한 후에는 .keras 디렉토리를 바로 찾을 수 없을 수 있습니다. 이럴 때는 IPython이나 Jupyter Notebook에서 import keras를 실행하여 디렉토리를 찾을 수 있습니다.\n\n그런 다음, keras.json 파일의 \"backend\" 키의 값을 \"torch\"로 변경하십시오.\n\n```js\n{\n    \"floatx\": \"float32\",\n    \"epsilon\": 1e-07,\n    \"backend\": \"torch\",\n    \"image_data_format\": \"channels_last\"\n}\n```\n\n프로덕션 시스템이거나 Colab과 같은 클라우드 환경을 사용하는 경우, 구성 파일을 수정할 수 없을 수 있습니다. 이런 경우에는 환경 변수를 설정하여 이 문제를 해결할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nos.environ[\"KERAS_BACKEND\"] = \"torch\"\n```\n\nKeras 백엔드를 설정한 후, 다음 코드로 확인할 수 있어요:\n\n```js\nIn:  import keras\n     keras.config.backend()\n\nOut: 'torch'\n```\n\n준비가 완료되면, 오늘의 프로젝트 실습을 공식적으로 시작할 거예요.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 프로젝트 실습: 시작부터 끝까지의 예시\n\n프레임워크를 배우는 가장 빠른 방법은 실제 프로젝트를 실습하는 것입니다. 그래서 이제 제 약속을 이행할 시간입니다.\n\n나는 당신에게 서브클래싱 API를 사용하여 신경 기계 번역(NMT) 모델을 구현하는 단계별 안내를 제공하고, Keras 3.0을 사용하는 몇 가지 세부 정보를 설명할 것입니다.\n\n## 이론 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNMT 모델에 익숙하지 않다면, 간단히 소개해 드리겠습니다:\n\nNMT는 인코더-디코더 구조를 기반으로 한 순환 신경망 모델의 한 유형입니다.\n\n이 구조에서는 임베딩 레이어와 RNN(이 글에서는 LSTM을 사용합니다) 레이어가 인코더를 형성하고, 또 다른 임베딩 레이어와 RNN 레이어가 디코더를 형성합니다.\n\n원본 텍스트는 벡터화된 후 인코더 모듈로 입력됩니다. 일련의 단계를 거쳐 최종 상태가 디코더 모듈로 입력됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한 대상 텍스트도 디코더 모듈에 입력되지만, 디코더로 들어가기 전에 한 단계 앞으로 오프셋이 적용됩니다. 따라서 대상 텍스트의 처음 부분은 시작 시퀀스(SOS) 플레이스홀더로 시작합니다.\n\n인코더의 입력 상태와 대상 텍스트의 입력은 디코더에서 순환 계산을 통해 처리되어 최종적으로 Dense 레이어에 출력됩니다. 거기서 각 텍스트 벡터의 확률을 계산해 대상 텍스트의 단어 벡터와 비교하고 손실을 계산합니다.\n\n따라서 대상 텍스트의 끝을 표시하기 위해 대상 텍스트의 끝에 종결 시퀀스(EOS) 플레이스홀더를 추가합니다.\n\n아래 다이어그램에서 전체 아키텍처가 표시됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당연히 Transformer 아키텍처의 인기로 인해 케라스의 KerasNLP 패키지도 Bert 및 GPT와 같은 다양한 사전 훈련 모델을 제공합니다. 이 기사는 하지만 Keras 3.0을 사용하는 방법에 중점을 두므로 기본적인 RNN 네트워크를 사용하는 것이 충분합니다.\n\n**모듈 및 플로우차트**\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로덕션에 완전히 준비된 프로젝트이기 때문에, 우리는 Keras 3.0의 서븁클래싱 API를 기반으로 모듈을 구축합니다.\n\n각 모듈과 그들의 상호작용을 명확히 이해하기 위해, 아래의 플로우차트를 만들었습니다:\n\n![flowchart](/assets/img/2024-05-20-Keras30TutorialEnd-to-EndDeepLearningProjectGuide_2.png)\n\n플로우차트의 디자인에 따라 코드를 작성할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 패키지 가져오기\n\nJupyter Notebook 환경에서는 프로젝트 첫부분에 관련 패키지를 모두 가져오는 것을 좋아해요.\n\n이렇게 하면 중간에 뭔가 빠트린 게 있어도 한 군데에서 추가하면 되니까 import 셀을 찾느라 시간을 낭비할 필요가 없어요:\n\n```js\nfrom pathlib import Path\nimport pickle\n\nimport keras\nfrom keras import layers, utils\nimport numpy as np\n\nutils.set_random_seed(42)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n약간의 소소한 팁이에요: utils.set_random_seed 메서드를 사용하면 Python, Numpy, Pytorch의 랜덤 시드를 한 줄의 코드로 설정할 수 있어서 정말 편리해요.\n\n## 데이터 준비\n\n시작하기 전에 적절한 데이터를 선택해야 해요. 과거의 인코더-디코더 모델과 마찬가지로, 저희는 spa-eng 텍스트 데이터셋을 선택했어요.\n\n다운로드 후, 먼저 spa.txt 파일의 내용을 확인해볼게요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n비슷한 점이 두드러져요. La similitud es extraña. CC-BY 2.0 (프랑스) 속성: tatoeba.org #2691302 (CM) \u0026 #5941808 (albrusgher)\n비슷한 점이 엄청나네요. El parecido es asombroso. CC-BY 2.0 (프랑스) 속성: tatoeba.org #2691302 (CM) \u0026 #6026125 (albrusgher)\n결과가 약속 있어 보여요. Los resultados se antojan prometedores. CC-BY 2.0 (프랑스) 속성: tatoeba.org #8480484 (shekitten) \u0026 #8464272 (arh)\n부자들은 많은 친구들을 가지고 있어요. Los ricos tienen muchos amigos. CC-BY 2.0 (프랑스) 속성: tatoeba.org #1579047 (sam_m) \u0026 #1457378 (marcelostockle)\n\n\n위 내용을 보시다시피 적어도 세 개의 열을 포함하는 내용이 있습니다. 첫 번째 열은 원문이고 두 번째 열은 대상 텍스트로 탭으로 구분되어 있습니다.\n\n파일이 크지 않기 때문에 numpy의 genfromtxt 메서드를 사용하여 이 데이터셋을 직접 읽어올 수 있습니다.\n\n```python\ntext_file = Path(\"./temp/eng-spanish/spa-eng/spa.txt\")\n\npairs = np.genfromtxt(text_file, delimiter=\"\\t\", dtype=str,\n                     usecols=(0, 1), encoding=\"utf-8\",\n                     autostrip=True,\n                     converters={1: lambda x: x.replace(\"¡\", \"\").replace(\"¿\", \"\")})\nnp.random.shuffle(pairs)\nsentence_en, sentence_es = pairs[:, 0], pairs[:, 1]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 처리 결과를 확인해봅시다:\n\n```js\nIn:   print(f\"{sentence_en[0]} =\u003e {sentence_es[0]}\")\n\nOut:  I'm really sorry. =\u003e Realmente lo siento.\n```\n\n좋아요, 문제 없어요.\n\n## 데이터 전처리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 텍스트 콘텐츠를 단어 벡터 데이터로 변환하기 위해 전처리해야 합니다.\n\n우선, 몇 가지 상수를 정의합니다:\n\n```js\nclass Configure:\n    VOCAB_SIZE: int = 1000\n    MAX_LENGTH: int = 50\n    SOS: str = 'startofseq'\n    EOS: str = 'endofseq'\n```\n\n그런 다음 데이터 처리 파이프라인을 시작합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nKeras 3.0에서는 백엔드로 PyTorch를 선택했더라도 TextVectorization 레이어는 여전히 TensorFlow를 기반으로 구현되어 있습니다.\n\n따라서 Keras 모델 내에서 TextVectorization을 레이어로 사용할 수 없고, 전처리 파이프라인에서 별도로 사용해야 합니다.\n\n이로 인해 문제가 발생합니다. 훈련된 모델을 추론 작업을 위한 프로덕션 시스템으로 이관할 때 TextVectorization 어휘 없이는 벡터화를 수행할 수 없습니다.\n\n그래서 우리는 어휘를 지속시키고 재사용해야 하지만, Keras 3.0의 TextVectorization 지속에 관한 몇 가지 문제가 있습니다. 이 부분에 대해 나중에 논의하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n텍스트 전처리 모듈을 사용하여 벡터화를 수행할 것입니다. 여기에 구체적인 코드가 있습니다:\n\n```js\nclass TextPreprocessor:\n    def __init__(self, \n                 en_config=None, es_config=None):\n        if en_config is None:\n            self.text_vec_layer_en = layers.TextVectorization(\n                Configure.VOCAB_SIZE, output_sequence_length=Configure.MAX_LENGTH\n            )\n        else:\n            self.text_vec_layer_en = layers.TextVectorization.from_config(en_config)\n        \n        if es_config is None:\n            self.text_vec_layer_es = layers.TextVectorization(\n                Configure.VOCAB_SIZE, output_sequence_length=Configure.MAX_LENGTH\n            )\n        else:\n            self.text_vec_layer_es = layers.TextVectorization.from_config(es_config)\n        \n        self.adapted = False\n        self.sos = Configure.SOS\n        self.eos = Configure.EOS\n        \n    def adapt(self, en_sentences: list[str], es_sentences: list[str]) -\u003e None:\n        self.text_vec_layer_en.adapt(en_sentences)\n        self.text_vec_layer_es.adapt([f\"{self.sos} {s} {self.eos}\" for s in es_sentences])\n        self.adapted = True\n        \n    def en_vocabulary(self):\n        return self.text_vec_layer_en.get_vocabulary()\n    \n    def es_vocabulary(self):\n        return self.text_vec_layer_es.get_vocabulary()\n        \n    def vectorize_en(self, en_sentences: list[str]):\n        return self.text_vec_layer_en(en_sentences)\n    \n    def vectorize_es(self, es_sentences: list[str]):\n        return self.text_vec_layer_es(es_sentences)\n    \n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n        \n    def get_config(self):\n        en_config = self.text_vec_layer_en.get_config()\n        en_config['vocabulary'] = self.en_vocabulary()\n        es_config = self.text_vec_layer_es.get_config()\n        es_config['vocabulary'] = self.es_vocabulary()\n        return {'en_config': en_config,\n                'es_config': es_config}\n    \n    def save(self, filepath: str):\n        if not self.adapted:\n            raise RuntimeError(\"Layer hasn't been adapted yet.\")\n        if filepath is None:\n            raise ValueError(\"A file path needs to be defined.\")\n        if not filepath.endswith('.pkl'):\n            raise ValueError(\"The file path needs to end in .pkl.\")\n        pickle.dump({\n            'config': self.get_config()\n        }, open(filepath, 'wb'))\n    \n    @classmethod    \n    def load(cls, filepath: str):\n        conf = pickle.load(open(filepath, 'rb'))\n        instance = cls(**conf['config'])\n        return instance\n```\n\n이 모듈이 하는 일을 설명해 드리겠습니다:\n   - 원본 텍스트와 대상 텍스트 모두 벡터화해야 하기 때문에, 이 모듈에는 두 TextVectorization 레이어가 포함되어 있습니다.\n   - 적응 후에는 이 모듈이 원본 및 대상 텍스트의 어휘를 보유합니다. 이렇게 하면, 프로덕션 시스템에 배포할 때 TextVectorization을 다시 적응시킬 필요가 없습니다.\n   - 이 모듈은 영속성을 제공하기 위해 pickle 모듈을 사용합니다. get_config 메서드를 사용하여 두 TextVectorization 레이어의 구성을 가져와 저장할 수 있습니다. 또한 from_config를 사용하여 저장된 구성에서 모듈의 인스턴스를 직접 초기화할 수 있습니다.\n   - 그러나 get_config 메서드를 사용할 때 어휘가 검색되지 않았습니다 (현재 Keras 버전 3.3을 사용하고 있으며 이것이 버그인지 확실하지 않습니다), 따라서 어휘를 따로 가져오기 위해 get_vocabulary 메서드를 사용해야 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n텍스트 전처리기 = TextPreprocessor()\n텍스트_전처리기.적응(영어_문장, 스페인어_문장)\n텍스트_전처리기.저장('./데이터/텍스트_전처리기.pkl')\n```\n\n두 언어의 어휘를 확인해보세요:\n\n```js\nIn:   텍스트_전처리기.en_vocabulary()[:10]\nOut:  ['', '[UNK]', 'i', 'the', 'to', 'you', 'tom', 'a', 'is', 'he']\n\nIn:   텍스트_전처리기.es_vocabulary()[:10]\nOut:  ['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'no', 'tom', 'a', 'la']\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문제없어요.\n\nTextPreprocessor 모듈이 준비되면 훈련 및 검증 세트를 분할하고 벡터화 작업을 시작할 수 있어요. 대상 텍스트는 디코더 모듈의 입력으로도 작동하기 때문에 X_train_dec 및 X_valid_dec와 같은 두 가지 추가 기능 세트가 있어요:\n\n```js\nX_train = text_preprocessor.vectorize_en(sentence_en[:100_000])\nX_valid = text_preprocessor.vectorize_en(sentence_en[100_000:])\n\nX_train_dec = text_preprocessor.vectorize_es([f\"{Configure.SOS} {s}\" for s in sentence_es[:100_000]])\nX_valid_dec = text_preprocessor.vectorize_es([f\"{Configure.SOS} {s}\" for s in sentence_es[100_000:]])\n\ny_train = text_preprocessor.vectorize_es([f\"{s} {Configure.EOS}\" for s in sentence_es[:100_000]])\ny_valid = text_preprocessor.vectorize_es([f\"{s} {Configure.EOS}\" for s in sentence_es[100_000:]])\n```\n\n## 인코더-디코더 모델 구현\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 아키텍처 다이어그램에서 설명했듯이 전체 모델은 인코더 및 디코더 부분으로 나뉩니다. 따라서 각 부분에 대해 keras.layers.Layer를 기반으로 두 개의 사용자 정의 하위 클래스를 구현합니다.\n\n각 사용자 정의 Layer에 대해 __init__, call 및 get_config 메서드를 구현하는 것이 중요합니다.\n\n- __init__ 메서드는 Layer의 멤버 변수, 가중치 및 하위 레이어를 초기화합니다.\n- call 메서드는 Keras의 Functional API와 유사하게 작동하며 입력을 매개변수로 받아 처리 후 Layer의 출력을 반환합니다.\n- get_config 메서드는 모델을 저장할 때 Layer의 구성을 검색하는 데 사용됩니다.\n\n인코더 Layer:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n@keras.saving.register_keras_serializable()\nclass Encoder(keras.layers.Layer):\n    def __init__(self, embed_size: int = 128, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_size = embed_size\n        \n        self.encoder_embedding_layer = layers.Embedding(input_dim=Configure.VOCAB_SIZE, \n                                                        output_dim=self.embed_size,\n                                                        mask_zero=True)\n        self.encoder = layers.LSTM(512, return_state=True)\n        \n    def call(self, inputs):\n        encoder_embeddings = self.encoder_embedding_layer(inputs)\n        encoder_outputs, *encoder_state = self.encoder(encoder_embeddings)\n        return encoder_outputs, encoder_state\n    \n    def get_config(self):\n        config = {\"embed_size\": self.embed_size}\n        base_config = super().get_config()\n        return config | base_config\n```\n\n인코더에서는 LSTM의 return_state 매개변수를 True로 설정했습니다. 이렇게 하면 LSTM의 최종 상태를 디코더 레이어가 사용할 수 있도록 출력으로 반환합니다.\n\n디코더 레이어:\n\n```js\n@keras.saving.register_keras_serializable()\nclass Decoder(keras.layers.Layer):\n    def __init__(self, embed_size: int = 128, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_size = embed_size\n        \n        self.decoder_embedding_layer = layers.Embedding(input_dim=Configure.VOCAB_SIZE,\n                                                        output_dim=self.embed_size,\n                                                        mask_zero=True)\n        self.decoder = layers.LSTM(512, return_sequences=True)\n        \n    def call(self, inputs, initial_state=None):\n        decoder_embeddings = self.decoder_embedding_layer(inputs)\n        decoder_outputs = self.decoder(decoder_embeddings,\n                                       initial_state=initial_state)\n        return decoder_outputs\n    \n    def get_config(self):\n        config = {\"embed_size\": self.embed_size}\n        base_config = super().get_config()\n        return config | base_config\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDecoder에서 데이터 입력을받는 것 외에도 call 메서드는 초기 상태 함수를 통해 Encoder의 입력도 받아 모듈의 출력을 반환합니다.\n\n또한 keras.layers.Layer와 유사하게 __init__, call 및 get_config 메서드를 구현해야 하는 사용자 정의 모델인 NMTModel을 구현합니다.\n\n```python\n@keras.saving.register_keras_serializable()\nclass NMTModel(keras.models.Model):\n    embed_size: int = 128\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        \n        self.encoder = Encoder(self.embed_size)\n        self.decoder = Decoder(self.embed_size)\n        \n        self.out = layers.Dense(Configure.VOCAB_SIZE, activation='softmax')\n        \n    def call(self, inputs):\n        encoder_inputs, decoder_inputs = inputs\n        \n        encoder_outputs, encoder_state = self.encoder(encoder_inputs)\n        decoder_outputs = self.decoder(decoder_inputs, initial_state=encoder_state)\n        out_proba = self.out(decoder_outputs)\n        return out_proba\n    \n    def get_config(self):\n        base_config = super().get_config()\n        return base_config\n```\n\n- Model에서는 Dense 레이어를 초기화하여 Decoder의 출력을 단어 벡터 결과로 변환합니다.\n- call 메서드는 두 개의 입력을 가져와서 쉽게 구분할 수 있습니다.\n- Layer 및 Model은 모델을 저장할 때 올바른 직렬화를 보장하기 위해 @keras.saving.register_keras_serializable() 데코레이터를 가져야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 모델 훈련\n\n모델을 정의한 후, 훈련 단계로 진행합니다:\n\n```js\nnmt_model = NMTModel()\nnmt_model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='nadam',\n                  metrics=['accuracy'])\ncheckpoint = keras.callbacks.ModelCheckpoint(\n    './data/nmt_model.keras',\n    monitor='val_accuracy',\n    save_best_only=True\n)\nnmt_model.fit((X_train, X_train_dec), y_train, epochs=1,\n              validation_data=((X_valid, X_valid_dec), y_valid),\n              batch_size=128,\n              callbacks=[checkpoint])\n```\n\n이 코드 부분에서:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 먼저 모델 인스턴스를 컴파일하는 compile 메소드를 호출합니다. 여기서는 손실(loss), 옵티마이저(optimizer), 및 메트릭(metrics) 등을 정의합니다.\n- ModelCheckpoint 콜백을 설정하여 훈련 후 최고의 val_accuracy를 가진 모델을 저장합니다.\n- fit 메소드를 사용하여 X_train 및 X_train_dec를 x 매개변수에 튜플로 전달하고 validation_data도 유사하게 처리합니다.\n- 이것은 따뜻한 모델이라 epochs를 1로 설정했습니다. epochs 및 batch_size 값을 필요에 따라 조정할 수 있습니다.\n- Keras 3.0은 Pytorch의 DataLoader도 지원하며 keras.utils.PyDataset을 기반으로 한 backend에 대한 이식 가능한 전처리 파이프라인을 구현할 수도 있습니다. 다음 기사에서 이들을 사용하는 방법을 설명할 수 있어요.\n\n훈련이 완료되면 모델을 저장해야 합니다.\n\n## 추론 작업\n\n훈련 후, 저장된 어휘 및 모델과 함께 해당 코드 모듈을 제품 시스템으로 추론 작업을 위해 배포할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델의 Dense 레이어가 어휘 사전의 각 단어 벡터에 대한 확률을 출력하기 때문에 추론된 각 단어를 이전 결과와 병합하여 원본 텍스트와 함께 다음 단어를 예측하기 위해 다시 입력해야 합니다:\n\n```js\npreprocessor = TextPreprocessor.load('./data/text_preprocessor.pkl')\nnmt_model = keras.saving.load_model('./data/nmt_model.keras')\n\ndef translate(sentence_en):\n    translation = \"\"\n    for word_index in range(50):\n        X = preprocessor.vectorize_en([sentence_en])\n        X_dec = preprocessor.vectorize_es([Configure.SOS + \" \" + translation])\n        y_proba = nmt_model.predict((X, X_dec), verbose=0)[0, word_index]\n        predicted_word_id = np.argmax(y_proba)\n        predicted_word = preprocessor.es_vocabulary()[predicted_word_id]\n        if predicted_word == Configure.EOS:\n            break\n        translation = translation + \" \" + predicted_word\n    return translation.strip()\n```\n\n간단한 테스트 결과를 확인하기 위해 다음 메소드를 작성해 봅시다:\n\n```js\nIn:   translate(\"It was pretty cool.\")\nOut:  'era bastante [UNK]'\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비록 매우 정확하지는 않지만, 이 글의 목표는 Keras 3.0 서브클래싱 API를 사용하는 방법을 배우는 것이므로 여전히 이 모델을 최적화할 여지가 많습니다, 맞죠?\n\n# 결론\n\nKeras 3.0의 출시로 Keras의 간결한 API를 사용하여 Pytorch 또는 Jax를 백엔드로 사용하면서 효율적으로 모델을 구현할 수 있게 되었습니다.\n\n그러나 최신 버전이 출시된 지 얼마 되지 않아 도움이 되는 문서가 아직 완벽하지 않으므로 새로운 버전을 시도할 때 어려움을 겪을 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사는 끝에서 끝으로 실용적인 예제를 통해 Keras 3.0의 환경 설정과 기본 개발 프로세스를 설명하여 빠르게 시작할 수 있도록 도와줍니다.\n\n안타깝게도, Keras 3.0 프로젝트는 아직 초기 단계에 있어 TensorFlow에 대한 의존성을 완전히 벗어날 수 없으며 TensorFlow의 일부 이해할 수 없는 문제도 있습니다.\n\n하지만 저는 여전히 이 버전에 낙관적입니다. 시간이 지나면서 다중 백엔드 지원이 개선되면서 Keras가 살아나고, 딥러닝 기술을 더 쉽게 이용할 수 있게 하고, 딥러닝의 학습 곡선을 줄일 수 있는데 도움을 줄 것이라고 믿습니다.\n\nKeras 3.0에 대해 더 알고 싶은 사항이 있으시면 자유롭게 댓글을 남기고 토론해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글을 즐겨 읽으셨나요? 더 많은 최신 데이터 과학 팁을 받으시려면 지금 구독해주세요! 피드백과 질문은 언제나 환영합니다 — 댓글에서 함께 이야기해요!\n\n본 기사는 Data Leads Future에서 원문으로 게시되었습니다.\n\n좋은 소식! Scikit-learn은 이제 Display 클래스를 제공하여 from_estimator와 from_predictions와 같은 메서드를 사용할 수 있게 해주어 다양한 상황에 맞는 그래프를 그리는 것이 훨씬 쉬워졌어요:","ogImage":{"url":"/assets/img/2024-05-20-Keras30TutorialEnd-to-EndDeepLearningProjectGuide_0.png"},"coverImage":"/assets/img/2024-05-20-Keras30TutorialEnd-to-EndDeepLearningProjectGuide_0.png","tag":["Tech"],"readingTime":18},{"title":"주체적인 RAG 개인 맞춤 및 최적화된 지식 보조 언어 모델","description":"","date":"2024-05-20 20:07","slug":"2024-05-20-AgenticRAGPersonalizingandOptimizingKnowledge-AugmentedLanguageModels","content":"\n\n대형 언어 모델(LLM)은 인공 지능 분야에서 혁명적인 힘으로 부상하여 자연어 처리 작업에서 놀라운 성능을 보여주고 있습니다. 그러나 그들의 인상적인 성능에도 불구하고, LLM은 종종 환각, 시간적 불일치 및 맥락 처리 문제와 같은 제한에 직면할 수 있습니다. 이러한 도전 과제를 해결하기 위해 연구는 외부 지식 원본과 통합하여 LLM을 향상시키는 데 초점을 맞추고 있습니다. 이 방법을 통해 RAG(검색 증강 생성)이라 불리는 것이죠.\n\nRAG는 언어 모델의 능력을 향상시키기 위해 외부 지식 원본에서 관련 정보를 검색하고 통합함으로써 정확한 응답을 이해하고 생성할 수 있도록 하는 것을 목표로 합니다. 이 추가적인 맥락을 활용함으로써 RAG 시스템은 복잡한 질문에 더 정확하고 맥락적으로 답변하기에 상당한 개선을 보여주고 있습니다. 그러나 RAG 프레임워크가 발전하고 확장됨에 따라, 새로운 도전 과제가 특히 검색 품질, 효율성 및 개인화 분야에서 발생하고 있습니다.\n\n이러한 제약을 극복하기 위해 연구자들은 ERAGent라는 첨단 RAG 프레임워크를 소개하였습니다. ERAGent는 분야에서의 중요한 발전을 총망라하여 검색 증강 언어 모델의 정확성, 효율성 및 개인화를 향상시키기 위해 여러 혁신적인 구성 요소와 기술을 통합하고 있습니다.\n\n![이미지](/assets/img/2024-05-20-AgenticRAGPersonalizingandOptimizingKnowledge-AugmentedLanguageModels_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 향상된 질문 재작성\n\nERAGent의 핵심 구성 요소 중 하나는 향상된 질문 재작성 모듈입니다. 이 모듈은 모호하거나 구어체인 질문을 명확하고 표준화된 쿼리로 개선하여 정보 검색의 품질을 향상하는 데 중요한 역할을 합니다. 전문 용어나 도메인 특정 용어를 식별하고 대체함으로써, 이 모듈은 대화형 언어와 지식 베이스에서 사용되는 기술 용어 사이의 간극을 좁히는 데 도움이 됩니다 [1].\n\n또한, 향상된 질문 재작성은 간단한 다시 말하기를 넘어 원래 질문의 다른 의미적 측면을 포착하는 여러 세분화된 쿼리를 생성함으로써 이와 같은 접근 방식은 후속 검색 프로세스가 다양한 각도에서 관련 정보를 철저히 검색하고 식별할 수 있도록 보장하여 전체적인 검색 품질과 정확도를 향상시킵니다 [1].\n\n예를 들어 임상 의학 시나리오에서 향상된 질문 재작성 모듈은 의사의 구어와 전문 용어로 가득 찬 질문을 인식하고 표준화된 도메인 특정 쿼리의 세트로 변환할 수 있습니다 [1]. 이 과정은 질문의 의도를 명확히하는데 그치지 않고 관련 의학적 지식을 보다 정확하고 포괄적으로 검색하며, 최종적으로 더 정확하고 정보화된 응답을 이끌어냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 효율적인 지식 검색\n\nERAGent의 또 다른 중요한 측면은 지식 검색의 효율을 최적화하는 데 초점을 맞추고 있다는 것입니다. 이는 검색 트리거 모듈과 경험 학습자 모듈의 협력 작용을 통해 달성됩니다.\n\n검색 트리거 모듈은 AI 어시스턴트의 지식 경계 내 또는 외에 주어진 쿼리가 속하는지를 평가하도록 설계되었습니다 [1]. 쿼리의 \"인기도\"에 기초하여 특정 주제에 대한 시스템의 숙련도를 추정함으로써, 검색 트리거는 외부 지식 검색이 필요한지 아니면 쿼리를 기존 정보를 사용하여 충분히 처리할 수 있는지 신중하게 판단할 수 있습니다.\n\n이러한 지식 검색의 선택적 접근은 경험 학습자 모듈에 의해 지원됩니다. 이 모듈은 AI 어시스턴트가 과거 상호 작용에서 지식 베이스를 지속적으로 확장하고 사용자 프로필을 점진적으로 모델링할 수 있게 합니다 [1]. 이전 대화를 보존하고 학습함으로써, 시스템은 매우 관련성 높은 과거 지식을 활용하여 정확한 응답을 생성함으로써 중복된 외부 검색이 필요성을 줄이고 전반적인 효율성을 향상시킬 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n평가 결과에 따르면 ERAGent는 응답 시간을 약 40% 정도 단축할 수 있으며 응답 품질을 희생하지 않습니다 [1]. 이 효율성과 정확성 사이의 최적 균형은 경험 기반 학습 모듈을 활용하고 검색 트리거의 인기 임계값을 적절한 수준으로 조정하여 달성됩니다.\n\n# 강력한 지식 필터링\n\n검색 품질과 효율성을 향상시키는 것이 중요한 가운데, ERAGent는 검색된 지식을 정제하여 해당 지식이 관련성과 정확성을 보장하는 것이 중요하다는 사실을 인지합니다. 이는 지식 필터 모듈이 작용하는 곳입니다.\n\n지식 필터 모듈은 자연 언어 추론 (NLI) 기술을 활용하여 각 검색된 지식 단편이 원래 질문과 얼마나 관련이 있는지를 평가합니다 [1]. 검색 정보와 질문-답변 쌍 간의 관계를 분류함으로써, 모듈은 관련 없는 맥락을 효과적으로 걸러내고 가장 중요한 지식만 유지할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 필터링 과정은 검색 단계에서 방대한 정보가 얻어지고 있지만 그 중 일부는 의미적으로 관련이 있지만 질문에 정확하게 대답하는 데 직접적으로 사용할 수 없는 경우에 특히 가치가 있습니다. Knowledge Filter 모듈은 부가적인 콘텐츠를 버리는 것으로 정보가 언어 모델에 입력되는 것이 최고의 관련성과 품질을 갖도록 보장하여 생성된 응답의 정확성과 일관성을 향상시킵니다.\n\n# 개인화된 응답 생성\n\n정확성과 효율성을 향상시키는 것 외에, ERAGent는 언어 모델 응답의 개인화 특성에도 대응합니다. 개인화된 LLM 리더 모듈은 이 노력의 최전선에 있으며, 사용자 프로필, 선호도 및 컨텍스트에 맞추어 응답을 맞춥니다.\n\n언어 모델의 프롬프트에 학습된 사용자 프로필을 통합함으로써, 개인화된 LLM 리더는 단순히 사실적인 것뿐만 아니라 사용자의 고유한 배경, 관심사 및 필요에 부합하는 응답을 생성할 수 있습니다 [1]. 이 개인화는 표면적인 맞춤 이상으로 나아가, 각 사용자의 선호도, 태도 및 문맥 요소의 미묘한 차이를 탐구하여 정말로 맞춤화되고 매력적인 응답을 만들어냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 근육을 키우는 데 도움이 되는 식단 권장사항을 제공할 때, 개인 맞춤형 LLM 리더는 사용자의 환경 의식, 식이 제한 사항, 그리고 환경 운동가 또는 늦게 일어나는 사람과 같은 개인 선호도를 고려할 수 있습니다. 이러한 요소를 고려함으로써, 해당 모듈은 사용자의 특정한 라이프스타일과 가치관을 고려하는 적절한 식물성 단백질 공급원, 식사 준비 전략, 그리고 수면 권장을 제안할 수 있습니다.\n\n평가 결과는 ERAGent가 다양한 주제와 사용자 프로필에 걸쳐 개인화된 응답을 생성하는 능력을 입증했습니다. 비교 분석을 통해, 개인 맞춤형 LLM 리더가 사용자의 선호도와 과거 상호작용을 고려한 응답 정렬에서 비개인화된 대체품을 일관되게 능가함으로써, 사용자와 AI 어시스턴트 간의 이해와 연결감을 촉진합니다.\n\n# 평가 및 결과\n\nERAGent의 효과는 다양한 질문-답변 작업 및 데이터 세트에서 엄격한 평가를 거쳐, 정확성, 효율성 및 개인화 측면에서 우수한 성능을 보여주며, 그 우수성을 빛내고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n원 라운드 공개 도메인 QA 작업에서 Natural Questions, PopQA, AmbigNQ와 같은 데이터셋을 사용한 경우, ERAGent는 기본 모델에 비해 응답 정확도에서 상당한 개선을 보였습니다 [1]. 향상된 질문 재작성기와 지식 필터 모듈의 시너지 효과로 인해 정확 일치, 정밀도, 재현율 및 히트율과 같은 메트릭스에서 상당한 향상이 이루어졌습니다.\n\n또한 HotpotQA 및 2WikiMQA와 같은 데이터셋에서의 원 라운드 다중-홉 추론 QA 작업에서 향상된 질문 재작성기와 지식 필터의 공동 적용이 LLM이 정확한 응답을 생성하는 능력을 획기적으로 향상시켰으며 다른 기본 모델을 능가했습니다 [1].\n\n가장 주목할 만한 점으로, ERAGent의 다중 세션, 다중 라운드 QA 시나리오에서의 성능은 맞춤화와 최적화된 검색 효율성에 그 강점을 보여주었습니다. 사용자 프로필과 일관되게 다양한 주제에 걸쳐 응답을 조율함으로써 ERAGent는 맞춤화 능력에서 비맞춤화 모델들과 비교하여 우수함을 입증했습니다 [1].\n\n게다가 체험학습자 모듈을 활용하고 검색 트리거의 인기 임계값을 조정함으로써 ERAGent는 응답 시간을 현저히 줄이면서도 답변 품질을 저해하지 않았습니다. 효율성과 정확성 간의 최적 균형은 프레임워크가 실제 시나리오에서 실용적으로 적용 가능함을 강조합니다 [1].\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\nERAGent은 새로운 구성 요소와 기술을 통합한 포괄적인 프레임워크를 통해 키 한계와 도전에 대응하여, 검색 보조 언어 모델 분야에서 중대한 발전을 나타냅니다.\n\n강화된 질문 재작성 모듈은 애매한 쿼리를 정제하고 포괭적인 정보 검색을 위해 다중 측면의 세밀한 쿼리를 생성함으로써 검색 품질을 향상시킵니다. 검색 트리거 및 경험학습 모듈은 사용자의 이전 지식과 컨텍스트를 활용하여 중복된 외부 검색을 줄이고 응답 품질을 희생시키지 않으면서 검색 효율성을 최적화하기 위해 협력합니다.\n\n지식 필터 모듈은 자연어 추론 기술을 사용하여 검색된 지식을 정제하고 관련 없는 정보를 걸러내어 응답 정확도를 더욱 향상시킵니다. 특히, 개인화 된 LLM 리더 모듈은 개별 사용자 프로필, 선호도 및 컨텍스트에 맞춰 응답을 제공하여 더욱 흥미롭고 개인화된 사용자 경험을 유도하는데 있어 ERAGent을 독특하게 만듭니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 데이터셋 및 질의응답 작업을 통해 엄격한 평가를 거쳐, ERAGent는 정확성, 효율성 및 맞춤화 측면에서 일정한 우수한 성능을 보여왔습니다. [1].\n\nERAGent는 혁명적인 패러다임 변화보다는 점진적인 진전을 나타내지만, 이러한 발전은 검색 기반 지식 질문응답 시스템 분야에서 미래 연구 및 개발을 위한 견고한 기초를 확립합니다. 실용적인 장벽에 대처하고 맞춤화 및 최적화를 탐색함으로써 ERAGent는 지식이 풍부하고 정확한 AI 도우미뿐만 아니라 효율적이고 사용자 중심 그리고 개인의 필요와 선호도에 따라 진정으로 맞춤화된 AI 도우미의 계속적인 진화를 열어놓습니다.\n\n## 참고문헌\n\n[1] Shi, Y., Zi, X., Shi, Z., Zhang, H., Wu, Q., \u0026 Xu, M. (2024). ERAGent: 정확성, 효율성 및 맞춤화가 향상된 검색 증강 언어 모델. arXiv 사전 인쇄 arXiv:2405.06683.","ogImage":{"url":"/assets/img/2024-05-20-AgenticRAGPersonalizingandOptimizingKnowledge-AugmentedLanguageModels_0.png"},"coverImage":"/assets/img/2024-05-20-AgenticRAGPersonalizingandOptimizingKnowledge-AugmentedLanguageModels_0.png","tag":["Tech"],"readingTime":6},{"title":"인간 수준의 로봇을 위한 훌륭한 AI로의 길","description":"","date":"2024-05-20 20:04","slug":"2024-05-20-ThePathtoGreatAIforHuman-CapableRobots","content":"\n\n\u003cimg src=\"/assets/img/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots_0.png\" /\u003e\n\n내가 가장 좋아하는 스타워즈 장면은 츄바카가 우키의 울음소리를 내고 작은 토스트기 크기의 마우스 드로이드가 짹짹 거리며 뒤로 물러나는 장면입니다. 그 배경에는 무슨 일이 일어나고 있는지 상상해보세요? 그 로봇은 그 소리를 내는 것이 자신을 뭉개버릴 수 있는 무서운 협박하는 존재임을 인식해야 합니다. 두려움에 반응해야 합니다. 그리고 뒤로 바퀴로 이동하여 도망가야 합니다.\n\n오늘날의 로봇들은 이러한 이해와 제어 수준을 갖고 있지 않습니다. 이로 인해 그들은 자연스러워 보이지 않습니다. 현재의 로봇들은 일반적으로 딱딱하고 자연스럽지 않은 모습을 하고 있습니다. 또는 이상한 부조리한 계곡에 앉아서 자연스러워 보이려고 하지만 그것을 완전히 이룰 수 없습니다.\n\n# 시뮬레이션 및 유전 알고리즘에 대한 초기 작업\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1994년에 Karl Sims가 \"진화하는 가상 생물체\"라는 논문을 썼습니다. 그 논문은 물 속에서 움직이고 땅 위에서 움직이는 혁신적인 블록 생물체들을 보여주었습니다. Karl은 유전 알고리즘을 사용하여 생물체와 움직임을 진화시키는 아이디어를 시연했습니다. 그 비디오는 30년이 지난 지금도 여전히 매혹적입니다.\n\n이 연구는 새로운 행동과 새로운 제어를 갖는 혁신적인 생물체가 전진하거나 회전하는 등의 작업을 배울 수 있다는 것을 보여줬습니다. 시뮬레이션을 통해 건설함으로써 Karl Sims는 혁신적인 생물체들이 나타날 때까지 수많은 반복과 실험을 할 수 있었습니다. 게다가, 유전 알고리즘은 이전에 작동한 것을 채택하고 발전시킴으로써 점점 더 나은 것으로 수렴할 수 있다는 것을 보여줬습니다.\n\n# 강화 학습의 등장\n\n리치 서튼 박사는 1984년에 발표한 박사 논문에서 강화 학습의 개념을 고안했다고 인정받고 있습니다. 그의 말에 따르면, \"강화 학습은 보상으로부터 배움으로, 세계와의 평범한 상호작용 중에 시행착오를 통해 배우는 것\"입니다. 이후에는 Karl Sims의 작업과 비슷하게 시뮬레이션 세계에서 학습하도록 적응되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n강화 학습은 딥마인드가 아타리 게임을 플레이하는 시스템을 가르칠 수 있다는 것을 증명한 경우를 포함하여 탐험의 핫한 분야로 부상했습니다. 이 시스템은 입력 비디오 프레임을 받아 조이스틱 컨트롤을 모방한 컨트롤 출력을 생성했습니다(비디오).\n\n이것은 RL이 시행착오를 통해 행동을 배우고 최적화할 수 있는 능력을 증명한 중대한 순간이었습니다. 이는 단순히 게임 그 자체를 숙달하는 데서 그치는 것이 아니라 기계가 원시 시각 입력과 게임 환경으로부터의 피드백만을 이용하여 복잡한 작업을 처음부터 배울 수 있다는 것을 입증한 것이었습니다.\n\n이러한 움직임을 기반으로, 오픈AI의 DOTA 2에 대한 작업은 복잡한 멀티플레이어 온라인 배틀 아레나 게임에서 큰 발전을 이뤘습니다(비디오). 강화 학습을 통해 훈련된 신경망 팀 오픈AI Five는 프로 수준의 인간 플레이어와 경쟁하고 이기는 능력을 보여주었습니다. 이 성취는 RL이 복잡성과 동적성이 증가하는 작업을 처리할 수 있는 능력, 전략적 계획, 팀워크, 예측할 수 없는 상대에 대한 실시간 의사 결정을 포함하는 작업을 다룰 수 있는 능력을 강조했습니다.\n\n오픈AI의 학습 능력 프로젝트는 RL이 달성할 수 있는 영역을 더 넓혀주었습니다. 로봇 손을 훈련시켜 인간 손과 유사한 미세 조작 능력을 갖도록 하는 것을 통해, 이 프로젝트는 RL이 미세한 운동 통제와 적응력을 필요로 하는 물리적 작업에서의 잠재력을 강조했습니다(비디오). 이 프로젝트는 손을 훈련시키기 위해 실제 환경으로 그 기술을 옮기기 전에 시뮬레이션 환경을 사용한 것으로, sim-to-real 전이라고 알려진 기술을 사용한 점에서 특히 주목할 만했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 강화 학습의 한계 극복하기\n\n강화 학습의 첫 번째 큰 난제는 많은 시행 착오를 하는 데 비용이 많이 든다는 것입니다. 특히 학습 초기 단계에서 많은 테스트된 가설이 정말로 좋지 않은 것들이 많습니다. 따라서 나쁜 가치를 구별하여 목표에 근접한 것을 찾아내려고 하는 것은 어렵습니다. 또한 필요한 시행 착오 횟수는 액추에이터 수와 함께 증가합니다. 이것은 부트스트래핑 문제로 볼 수 있습니다... 강화 학습이 더 효율적일 수 있도록 모델을 시작할 수 있는 방법은 무엇인가요?\n\n이 문제를 해결하는 데 도움이 될 수 있는 다양한 기술이 있습니다:\n\n- 먼저 시뮬레이션 사용: 실제 세계에서 작동을 확인하기 전에 시뮬레이션에서 모든 시행 착오를 수행하여 작동하는 솔루션에 더 가까워지려고 노력합니다.\n- 모방 학습: 강화 학습을 세부 조정하기 전에 기본 모델을 얻기 위해 다른 기술을 사용합니다. 이 기술 중 하나는 사람이 액추에이터를 제어하도록 하고, 그 후에 학습하는 것입니다. 또는 \"One-shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning\"에서 시연된 것처럼 비디오에서 모방합니다. 최근 CMU 로봇 공학 연구소의 논문 \"SloMo: A General System for Legged Robot Motion Imitation from Casual Videos\"에서는 개와 고양이의 비디오에서 배운 것을 다리로봇에 전달하는 능력을 보였습니다.\n- 액추에이터 공간의 차원 축소: 인간의 손은 40개 이상의 제어 차원을 가지고 있으며 OpenAI Detrous Manipulation 프로젝트에서 사용된 Shadow Hand와 같은 장치는 26개의 차원을 가지고 있습니다. Columbia는 \"eigengrasps\"를 만들어 알려진 잡음 상태에서의 접근 문제를 단순화하기 위해 손을 간단한 문제로 전환하려고 노력했습니다.\n- 문제 단순화: 특히 로봇 픽킹에서 널리 사용되는 방법은 물건을 집을 때 기존 것을 잡아들이기에 걱정할 필요 없도록 매우 높은 유동성 진공을 단순히 사용하는 것입니다. Agility는 로봇의 다리를 설계하여 다리 제어 모델을 탄성 질량 진자로 모델링할 수 있도록 하여 제어 문제를 단순화했습니다.\n- 행동 클로닝: 이미 작동하는 시스템이 있다면 다른 시스템이 그 행동을 복제하도록 시도할 수 있습니다. 처음에는 지도 학습 기술을 사용해보는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n강화 학습의 두 번째 큰 도전은 매우 견고하지 않으며 지정된 보상에 과적합될 수 있다는 것입니다. 예를 들어, 인간 형상 로봇이 농구 골대에 골을 넣도록 훈련하려면, 목표가 단순히 골을 넣는 것이라면 로봇은 보다 성공적인 방법으로 공을 던질 것입니다. 그러나 인간이 농구를 차는 것과 같이 보이기를 원한다면, 골을 넣는 것과 인간처럼 보이는 것 둘 다 보상하는 더 정교한 보상 함수가 필요합니다.\n\n- 도메인 랜덤화: 입력 공간을 교란하고 동일한 목표를 달성하려고 하면 모델이 더 견고해질 수 있습니다.\n- 인간 취향: 인간들은 성공이 어떻게 보이어야 하는지에 대해 보다 세밀한 버전을 가지고 있습니다. 그래서 목표를 달성하는 것으로 시스템을 보상하는 대신에, 주로 인간이 선호하는 대로 행동하도록 시스템에 보상을 줄 수 있습니다. 일반적으로 인간에게 두 가지 예시를 나란히 보여주고 어느 쪽이 더 좋은지 묻습니다.\n\n강화 학습의 세 번째 큰 도전은 한 번에 한 가지 작업만 배운다는 것입니다! 문을 열어본 방법을 배웠다고 해서 다른 어떤 문의 손잡이나 심지어 높이가 2인치 낮은 문의 손잡이를 열 수 있다는 것을 의미하지 않습니다. 사실, 이 문제는 전혀 잘 해결되지 않습니다. 이를 해결하기 위한 몇 가지 대처 방법이 있습니다:\n\n- 동적 손재능 로봇 행동의 순차적 구성: 이 논문은 한 제어 체제에서 다른 체제로 부드럽게 전환하는 기술을 유도했는데, 두 제어 체제 간에 중첩이 있을 때 전환하는 방법을 제시합니다. 이는 매우 통찰력있는 논문입니다. Boston Dynamics은 아틀라스가 팽이를 하도록 만들기 위해 이 기술을 사용하거나 이 기술의 진화형을 사용한다고 여겨집니다.\n- 환경 제한: 작업을 매우 구체적인 상황으로 제한하면 문제를 크게 단순화할 수 있습니다. 예를 들어, 일반적인 세계에서 물건을 움켜쥐는 것은 매우 어렵습니다. 하지만 그냥 통에 있는 물건을 집는 것으로 제한한다면 문제를 상당히 단순화하고 그 후 하나의 작업만 배울 수 있습니다. 마찬가지로, 로봇이 할 수 있는 것을 충족하기 위해 모든 문 손잡이를 변경할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로봇 공학 분야에서 이 문제는 매우 큰 문제이며, 로봇 공학 커뮤니티 외부에서는 잘 이해되지 않는 문제입니다. 진짜 인상적인 로봇 액션의 데모를 자주 보게 되는데, 우리는 로봇이 백플립을 할 수 있는 로봇이라면 당연히 몽키 바도 할 수 있을 것이라고 바로 생각합니다. 왜냐하면 우리는 7세 어린이가 백플립을 할 수 있는 아이라면 몽키 바에는 문제가 없을 것이기 때문입니다. 하지만 로봇은 그렇지 않습니다. 만약 로봇이 몽키 바를 할 수 있도록 훈련받지 않았다면, 그것은 그 일을 할 능력이 전혀 없을 것입니다.\n\n인간이 할 수 있는 모든 것을 하나씩 배우려고 할 때 우리는 영원히 걸릴 것입니다.\n\n# 데이터의 역할\n\n우리가 알려진 정답 테스트 세트와 같은 결과를 생성해내는 모델을 고안하는 지도 학습에서는, 데이터가 많을수록 좋습니다. 음성 인식 분야의 초기 진전의 많은 부분은 지도 학습을 통해 이루어졌습니다. Tellme에서는, Nuance의 음성 인식 엔진을 사용하고 있음에도 불구하고 더 많은 데이터를 가지고 있기 때문에 어느 순간 Nuance보다 더 나은 음성 인식을 할 수 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사람들이 더 많은 데이터가 이긴다고 가정하는 것으로 이어졌습니다. 어느 정도는 여전히 사실이지만, 지도 학습을 시도하는 경우 테스트 세트가 필요합니다. 그리고 결과물은 당신의 테스트 및 훈련 세트의 크기만큼 좋습니다. 그래서 더 많은 데이터를 원하게 됩니다. Scale AI가 한 초기 작업 중 하나는, 자율 주행 자동차 회사들이 자동차, 정지 신호, 보행자, 교통 가로등 등이 어디에 있는지 보여 주는 레이블된 데이터 세트를 구축하는 데 도움을 주었습니다. 이러한 훈련 세트들을 구축하는 데는 매우 비용이 많이 들며 우리가 희망하는 것만큼 결과가 좋지 않습니다.\n\n이를 해결하기 위해 연구자들은 일부 레이블 데이터를 대규모의 레이블되지 않은 데이터 코퍼스와 융합하는 방법을 찾았습니다. 예를 들어, 아마존은 7,000시간의 레이블된 음성 및 100만 시간의 레이블되지 않은 음성을 사용하여 음성에 대한 그들의 음향 모델을 개선했습니다. 테슬라는 지금 자동 레이블링을 할 수 있는 충분한 레이블 데이터가 있다고 주장하지만, 그 정보는 희박합니다.\n\n그래서 더 많은 데이터가 승리하는 건가요? 그런데, 로봇 공학 분야에선 조금 다르게 작용할 수 있습니다. 로봇 공학의 문제는 텍스트, 음성, 이미지 또는 차량에서의 비디오와 달리, 우리가 데이터를 수집하고 다니는 로봇이 많지 않다는 점입니다. 세계에 있는 대부분의 데이터는 사람들이 한 결과물입니다... 우리가 쓰거나 말했거나, 사진을 찍었거나, 우리가 운전했거나 했습니다.\n\n만약 길을 운전하는 사람으로부터 어떠한 데이터도 캡처할 수 없다면 자율 주행 자동차를 만드는 것을 상상해 보세요. 더 나아가, 자율 주행이 되지 않은 자동차는 거의 유용하지 않습니다. 이것이 로봇과 관련된 문제입니다. 넓은 범위의 숙련된 작업을 수행하지 못하는 로봇들은 본질적으로 덜 유용하지만, 우리는 실제 세계에서 사람들이 하는 일들로부터 데이터를 캡처하는 좋은 방법을 가지고 있지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어느 정도의 실험으로 우리는 움직임 캡처 슈트를 입거나 Mobile Aloha와 같은 릭을 사용하여 이 데이터(비디오)를 캡처하는 방식을 시도해 보았습니다.\n\n우리가 그 방법에 이를 수 있는 이론 중 하나는 매우 복잡한 로봇이 매우 간단한 작업을 수행하고, 그런 다음 우리가 음성 인식과 같이 점진적으로 개선하는 것일 것이라는 것입니다. 이 주장은 좋아 보이지만, 실제로는 아무런 의미가 없습니다. 복잡한 로봇을 사용해서 간단한 작업을 수행하는 데는 엄청난 비용이 들기 때문에 그 중 많은 수를 배치하지 않을 것이므로, 우리는 많은 데이터를 갖지 않게 됩니다.\n\n또 다른 도전 과제는 세계가 굉장히 복잡하다는 것입니다. 수백만개의 레이블이 붙은 항목들이 있어도, 자율 주행 차량은 여전히 이전에 본 적이 없는 상황에 직면할 수 있습니다. 수십 년 동안의 데이터 레이블링과 전통적 기술들도 몇 개의 도시를 넘어선 일반화된 무인 운전차를 만드는 데 성과를 내지 못했습니다.\n\n# 트랜스포머와 토큰\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTransformer Architecture는 훨씬 더 나은 모델을 생성하는 데 차별화를 가져온 혁신이었습니다. Transformer 아키텍처는 토큰 시퀀스를 살펴보고 다음 토큰을 예측할 수 있도록 패턴을 찾아 작동합니다. ChatGPT 4의 Transformer 아키텍처는 인터넷에서 수집된 대량의 데이터 코퍼스로부터 13조 개의 토큰(사실상 \"단어\"들)로 훈련되었습니다. 우리는 많은 텍스트가 있고 그 텍스트는 토큰 시퀀스로 잘 구조화되어 있습니다.\n\n우리는 ChatGPT를 다음 단어 텍스트를 생성하는 것으로 생각하지만, 우리는 또한 토큰 간 번역을 할 수 있으며, 이것은 텍스트와 음성의 기계 번역을 놀라울 만큼 좋게 만들었습니다.\n\n그러나 transformer 아키텍처의 핵심은 공간을 transformer architecture에 적합하게 표현하기 위해 어떻게 토큰화하는 지를 결정하는 것입니다. 로봇 공학에서, 이러한 토큰들은 액션 스트림이 될 수 있습니다. TRI의 최근 확산 정책 작업은 견고한 제어의 개발을 가속화하는 데 큰 성과를 거두며 이것을 수행합니다. 그러나 그들은 여전히 한 번에 하나의 제어 정책만을 학습하고 있습니다.\n\n그러나 실제로 일반화하려면 많은 양의 토큰이 필요합니다. 우리는 충분한 양의 로봇이 토큰을 생성하지 않아 심각한 토큰 저장소를 구축하기에 충분하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 토큰의 원천\n\n토큰의 하나의 원천은 간단히 말해서 로봇 동작의 일반적인 표현을 고안하여 연구자들 사이에서 토큰을 공유할 수 있는 방법입니다. 첼시 핀과 다른 연구자들이 이를 시작하고 있습니다. 이제 충분히 흥미로운 토큰을 얻는 것이 여전히 난제입니다.\n\n또 다른 잠재적인 토큰의 원천은 대형 언어 모델의 잠재적 이해력을 활용하여 모션 플랜을 생성하고, 그 모션 플랜을 시뮬레이터에 공급한 다음 해당 시뮬레이션에서 모션의 토큰을 추출하는 것입니다. 이에 대한 논문들이 있는지는 아직 접하지 못했지만, ChatGPT가 학습한 월드 모델은 우리를 놀라게 하며 모션에 대한 깊은 본질적인 이해력을 가지고 있을 수 있습니다. 오늘은 아니더라도, 비디오와 이미지로부터 훈련된 다중 모달 모델들은 점차적으로 더 나은 모션에 대한 본질적인 이해력을 갖게 될 것으로 예상됩니다.\n\n또 다른 원천은 이미 존재하는 풍부한 비디오 자료입니다. 90년대 중반, 저는 MIT의 컴퓨터 과학 연구소 내 그래픽스 연구실에서 석사 논문 작업을 했습니다. 세스 텔러 교수님은 제 논문 지도 교수였습니다. 제 논문은 컴퓨터 그래픽을 위한 교육 플랫폼으로 웹을 활용하는 것에 중점을 둔 반면, 제 동료는 도시 맵핑을 위한 로봇 데이터 수집 장치를 구축하고 있었습니다. 도시 맵핑 프로젝트는 이 데이터 수집 장치로 수집된 2D 이미지에서 3D 지오메트리를 재구성하기 위해 계산 기하학을 활용했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n동일한 컴퓨터 기하학 기법은 SLAM (Simultaneous Localization and Mapping)의 기초를 형성합니다. 이것은 현재의 로봇들이 2D 비디오에서 3D 기하를 재구성하여 우리 주변 세계를 탐색할 수 있는 방법입니다. 이러한 기법을 사용하여 스켈레톤을 추적하고 사람의 동작을 재구성할 수도 있습니다.\n\n이것은 많은 동작 토큰들의 잠재적 출처를 만듭니다.\n\n## 인간 수준의 로봇 구축에 대한 영향\n\n오늘날 우리는 양쪽 다 처리와 조작 분야에서 복잡한 실제 상호작용을 위해 안정적으로 인간형 로봇을 제어할 수 있는 모델이 충분히 좋지 않다는 문제를 가지고 있습니다. Boston Dynamics가 다양한 작업의 좋은 조합을 보여줄 수 있고, Agility가 매우 견고한 걷기 동역학을 보여주고, 연구소들이 박스를 오르내리며 멋진 스크래블을 하는 네 다리 동물을 보여줄 수 있을지라도, 우리는 여전히 새로운 상황이나 새로운 작업에 안정적으로 일반화할 수 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 이 복잡한 로봇들이 더 일반화된 강력한 제어 없이 의미 있는 작업을 수행할 수 없다면, 우리는 단순히 많은 수의 로봇을 배치할 수 없을 것이며, 캡쳐할 수 있는 데이터의 양이 제한될 것입니다.\n\n이전에 썼던 “인간 수준 로봇에 이르는 길”이라는 글에서 설명한 대로, 나는 현재 고성능 로봇을 신속히 투입하는 것이 최선의 방법이라고 생각합니다. 그러나 인간 형태 제약에서 벗어나 인간이 실제로 하는 일에 대한 관점에서 데이터를 수집해야 합니다.\n\nLLM(Large Language Models)의 내재 지식을 비디오에서 추출된 토큰과 결합하고 소량의 실제 데이터를 시뮬레이션에서 재구성하여, 우리는 어떤 로봇 형태도 가능하게 할 로봇 제어의 기본 모델을 구축하기 시작할 수 있을 것입니다. 그러면 Diffusion Policies의 기술을 이용하여 인간이 이끄는 다중 모델 제어가 지원된 기본 모델을 지도하는 방식으로 로봇을 가르쳐 7세처럼 어떤 작업이든 수행할 수 있게 할 수 있을 것입니다.\n\n저는 그 미래를 기대합니다. 이미 유용한 코로봇들은 이 기본 모델이 사용 가능해지면 더욱 더 유능한 협업자가 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 다른 흥미로운 논문 및 강연:\n\n- Chelsea Finn - MIT에서 2023년 10월 23일에 로봇 학습의 일반화 및 민첩성에 관한 발표\n- Russ Tedrake - 프린스턴 로보틱스 - Russ Tedrake - 확산 정책을 이용한 민첩한 조작\n- Pieter Abbeel - 로봇 조각 집기를 위한 기반 모델 구축에 대해\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nChelsea Finn \u0026 Pieter Abbeel S3 E2 스탠포드 교수 첼시 핀: 항상 변화하는 세상에 대응할 수 있는 AI를 구축하는 방법\n\n브래드 포터는 Collaborative Robotics, Inc의 CEO이자 설립자로, Sequoia, Khosla 및 Mayo Clinic이 후원하는 캘리포니아 산타클라라에 본사를 둔 로봇 기업입니다. Cobot을 창립하기 전에, 브래드는 아마존의 물류 네트워크를 위한 로봇 기술을 감독하며 10,000명의 글로벌 팀을 이끄는 부사장 겸 탁월한 엔지니어였습니다. 그는 또한 Scale AI의 CTO, Tellme Networks의 플랫폼 아키텍트, 그리고 Netscape의 초기 엔지니어였습니다. 브래드는 MIT에서 컴퓨터 과학 학사학위와 석사학위를 취득했으며, 프로페서 Seth Teller 아래에서 컴퓨터 그래픽스에 중점을 둔 연구를 진행했습니다.","ogImage":{"url":"/assets/img/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots_0.png"},"coverImage":"/assets/img/2024-05-20-ThePathtoGreatAIforHuman-CapableRobots_0.png","tag":["Tech"],"readingTime":10}],"page":"4","totalPageCount":43,"totalPageGroupCount":3,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"4"},"buildId":"ll1cGyplNwh83dpggeai1","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>