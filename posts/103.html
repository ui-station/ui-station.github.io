<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/103" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/103" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_buildManifest.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" href="/post/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">38<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" href="/post/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" href="/post/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">25<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들" href="/post/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ML, 데이터 팀을 위한 Gen AI" href="/post/2024-05-18-MLGenAIfordatateams"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ML, 데이터 팀을 위한 Gen AI" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MLGenAIfordatateams_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ML, 데이터 팀을 위한 Gen AI" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ML, 데이터 팀을 위한 Gen AI</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 웨어하우징을 위한 5가지 사이버보안 팁" href="/post/2024-05-18-5CybersecurityTipsforDataWarehousing"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 웨어하우징을 위한 5가지 사이버보안 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 웨어하우징을 위한 5가지 사이버보안 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터 웨어하우징을 위한 5가지 사이버보안 팁</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Delta 테이블을 REST API를 통해 노출하는 방법" href="/post/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Delta 테이블을 REST API를 통해 노출하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Delta 테이블을 REST API를 통해 노출하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Delta 테이블을 REST API를 통해 노출하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Power BI 최적화 차원 모델링에서 서로간키의 필요성" href="/post/2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Power BI 최적화 차원 모델링에서 서로간키의 필요성" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Power BI 최적화 차원 모델링에서 서로간키의 필요성" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Power BI 최적화 차원 모델링에서 서로간키의 필요성</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="YouTube 데이터 파이프라인 구축하기 Docker 컨테이너에서 Airflow 사용하기" href="/post/2024-05-18-YoutubeDataPipelineusingAirflowinDockerContainer"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="YouTube 데이터 파이프라인 구축하기 Docker 컨테이너에서 Airflow 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-YoutubeDataPipelineusingAirflowinDockerContainer_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="YouTube 데이터 파이프라인 구축하기 Docker 컨테이너에서 Airflow 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">YouTube 데이터 파이프라인 구축하기 Docker 컨테이너에서 Airflow 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI로 기후 변화를 고칠 수 있을까 데이터 전문가의 견해" href="/post/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI로 기후 변화를 고칠 수 있을까 데이터 전문가의 견해" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI로 기후 변화를 고칠 수 있을까 데이터 전문가의 견해" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AI로 기후 변화를 고칠 수 있을까 데이터 전문가의 견해</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/101">101</a><a class="link" href="/posts/102">102</a><a class="link posts_-active__YVJEi" href="/posts/103">103</a><a class="link" href="/posts/104">104</a><a class="link" href="/posts/105">105</a><a class="link" href="/posts/106">106</a><a class="link" href="/posts/107">107</a><a class="link" href="/posts/108">108</a><a class="link" href="/posts/109">109</a><a class="link" href="/posts/110">110</a><a class="link" href="/posts/111">111</a><a class="link" href="/posts/112">112</a><a class="link" href="/posts/113">113</a><a class="link" href="/posts/114">114</a><a class="link" href="/posts/115">115</a><a class="link" href="/posts/116">116</a><a class="link" href="/posts/117">117</a><a class="link" href="/posts/118">118</a><a class="link" href="/posts/119">119</a><a class="link" href="/posts/120">120</a></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"오픈 소스 LLM을 활용한 자연어를 SQL 쿼리로 변환하기","description":"","date":"2024-05-18 18:19","slug":"2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM","content":"\n# 소개\n\n데이터 활용의 동적인 풍경에서는 데이터베이스와 손쉽게 상호 작용할 수 있는 능력이 중요합니다. 전통적으로 이 상호 작용은 구조화된 쿼리 언어(SQL)에 대한 심층적인 이해가 필요하여 많은 사용자들에게 진입 장벽이 되었습니다. 그러나 자연어 처리(NLP)를 SQL 쿼리 엔진에 적용하여 이 풍경이 변화되었으며, 이를 통해 사용자들이 자연어 명령을 사용하여 데이터베이스와 소통할 수 있게 되었습니다. 이 첨단 기술은 인간의 언어를 SQL 쿼리로 순조롭게 번역하여 데이터를 검색하고 조작하는 방식을 혁신하고 있습니다.\n\n자연어 처리(NLP)에서 Mistral 7B 및 Microsoft Phi-3과 같은 모델은 주요 역할을 하며 성능과 효율성의 경계를 재정의하고 있습니다.\n\nMistral 7B는 NLP 작업에서 뛰어난 성능과 정밀도로 높이 평가 받고 있습니다. 그룹화된 쿼리 어텐션(GQA) 및 슬라이딩 윈도우 어텐션(SWA)과 같은 혁신적인 기능들을 갖춘 Mistral 7B는 수학 및 코드 생성을 포함한 다양한 벤치마크에서 우수한 성과를 거두고 있습니다. Code-Llama 7B의 코딩 능력에 가까워짐과 동시에 NLP 발전에서의 중요성을 강조하며 다양한 분야에서 우수성을 유지하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPhi-3 는 작은 언어 모델(SLMs) 분야에서의 Microsoft의 최신 혁신으로, AI의 풍경을 변화시키는 대단한 제품입니다. Phi-3-mini, Phi-3-small 및 Phi-3-medium으로 구성된 이 모델군은 간결한 구성으로 뛰어난 성능을 제공합니다. 38억 개의 파라미터를 자랑하는 Phi-3-mini는 더 큰 모델들과 견줄 만한 성능을 발휘하면서도 스마트폰에서 효율적으로 동작합니다. Phi-3의 성공 뒤에는 견고함, 안전성 및 대화 능력을 중시하는 정교하게 선별된 학습 데이터셋이 있습니다. Phi-3-small 및 Phi-3-medium은 Phi-3의 능력을 더욱 확장하여 다양한 응용 분야에 대응합니다. 정교하게 설계된 아키텍처와 학습 방법을 통해 Phi-3은 AI 기술의 큰 발전을 상징하며, 다양한 생성형 AI 작업에 대한 우수한 성능과 효율성을 약속합니다.\n\nNLP와 SQL의 교차점을 탐색하여 Mistral 7B와 Microsoft Phi-3의 활용에 대해 알아봅니다. 이러한 모델들은 자연어 쿼리를 구조화된 SQL 쿼리로 원활하게 변환하여 데이터베이스 쿼리 작업에서 향상된 효율성과 정확도를 제공합니다.\n\n![](/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png)\n\n# 학습 목표\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블로그 포스트에서는 오픈 소스 Mistral 7B 모델을 NL2SQL 작업에 활용하는 복잡성을 탐색할 것입니다. 또한 NL2SQL 애플리케이션을 위해 모델을 맞춤화하고 훈련하는 방법에 대해 논의할 것입니다. 기사의 나머지 부분은 다음과 같은 내용을 다룹니다.\n\n# 동기부여\n\n오픈 소스 LLMs를 활용하면 자연어 명령을 SQL 쿼리로 변환하는 복잡한 프로세스를 실행할 수 있습니다. 이 혁신적인 기술은 사용자가 수동 쿼리 작성 없이 데이터 요구 사항을 자연스럽게 표현하도록 자동화하며, 이로써 사용자의 입력을 분석하고 의미론적으로 정확한 SQL 쿼리를 생성하는 복잡한 알고리즘과 대규모 언어 모델이 활용됩니다. 이는 변환 프로세스를 간소화시키고 광범위한 사용자들에게 광범위한 SQL 지식이 없어도 데이터를 이용할 수 있게 합니다. 오픈 소스 LLMs는 편리함을 제공하며 데이터 접근성과 운영 효율성을 크게 향상시킵니다. SQL 전문 지식의 장벽을 제거함으로써 이 기술은 데이터 접근성을 민주화시키고 각 분야의 사용자들이 데이터를 검색하고 통찰을 얻는 데 도움을 줍니다. 실시간 통찰을 찾는 비즈니스 분석가나 데이터 집합을 탐색하는 일반 사용자를 위한 것이든, 자연어 명령의 직관적인 성격은 데이터 검색을 간단하게 합니다.\n\n또한 이러한 모델에서 내재된 자동화는 쿼리 실행을 가속화하여 전반적인 효율성과 생산성을 높입니다. 오픈 소스 LLMs의 영향력은 광범위하며 다양한 산업 전반에 혁신과 변화를 격려합니다. 이 기술은 재무, 건강 관리 및 전자 상거래 분야와 같이 데이터 주도적 의사 결정이 중요한 분야에서 이해하기 쉬운 인사이트를 추출할 수 있도록 이해권자를 돕습니다. 더 나아가, 고급 분석 플랫폼과 인공 지능 시스템과의 통합을 통해 조직을 데이터 주도적 우수성으로 이끕니다. 탐구 문화를 육성하고 데이터 상호작용을 간소화함으로써 오픈 소스 LLMs는 데이터 자산의 모든 잠재력을 발휘함으로써 산업 전반에 혁신과 성장을 촉진합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 1. NL2SQL을 위한 사전 훈련 모델 (Mistral 7B)\n\nMistral AI가 개발한 70억 개의 파라미터를 가진 언어 모델인 Mistral 7B는 인공 지능 분야에서 강력한 모델로 빠르게 인기를 얻고 있습니다.\n\n- 기본 모델로 위치 지정된 Mistral 7B는 자연어 처리에서 중요한 역할을 하는 가장 중요한 구조적 모델로 자리 잡았으며 대규모 언어 모델 환경 내에서 필수적인 코어 빌딩 블록의 중요성을 보여줍니다.\n- 건축적 접근 방식으로 차별화된 Mistral 7B는 빠른 추론을 위해 그룹화된 쿼리 어텐션 (GQA)과 긴 시퀀스를 효율적으로 처리하기 위한 슬라이딩 윈도우 어텐션 (SWA)과 같은 혁신적인 기능을 활용하여 우수한 성능을 발휘합니다.\n- 주로 영어에 초점을 맞추지만 코딩 능력도 갖춘 Mistral 7B는 특히 다른 모델들보다 더 넓은 컨텍스트에서 텍스트를 이해하고 생성할 수 있는 높은 문맥 윈도우를 가지고 있어 두각을 나타냅니다.\n- 73억 개의 파라미터로 인상적인 Mistral 7B는 최신 언어 모델을 대표하는데, Apache 2.0 라이센스 하에 제한 없이 사용할 수 있습니다.\n- Mistral 7B는 모든 평가된 벤치마크에서 최고의 오픈 13B 모델 (Llama-2)보다 우수한 성과를 거두며 최고의 34B 모델 (Llama-1)보다 추론평가, 수학 및 코드 생성에서 뛰어난 성능을 보여줍니다.\n- Mistral-7B는 Llama2-13B보다 우수한 성능을 보이며 CodeLlama-7B와 경쟁력 있는 성과를 보이며 특히 추론, 수학 및 코드 생성 벤치마크에서 뛰어납니다.\n- 더 큰 모델들에 비해 크기는 작지만, Mistral 7B는 텍스트 요약, 분류, 텍스트 완성 및 코드 완성을 포함한 다양한 자연어 작업에서 우수한 성과를 거둡니다.\n- 이 모델이 자연어 쿼리를 구조화된 SQL 명령어로 변환하는 효과를 탐색하여 능력을 자세히 살펴봅시다.\n\n## Sliding Window Attention\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Mistral 7B은 전통적인 주의 메커니즘에서 발생하는 도전에 효과적으로 대처할 수 있는 슬라이딩 윈도우 어텐션(Sliding Window Attention, SWA) 메커니즘을 포함하고 있습니다. 전자는 토큰 수가 증가함에 따라 추론 중 지연 시간이 증가하고 처리량이 감소할 수 있으며, 시퀀스 길이와 메모리와 관련된 연산이 이차적으로 증가하고 메모리가 선형적으로 증가할 수 있습니다. 반면에 SWA는 각 토큰의 주의를 이전 레이어의 W개 토큰을 최대한으로 제한하여 주어진 윈도우 크기 W를 넘어서 주의를 확장합니다.\n- SWA는 트랜스포머의 계층 구조를 활용하여 위치 i의 숨겨진 상태가 입력 레이어의 토큰을 W x k 토큰까지 액세스할 수 있도록 지원합니다. 최종 레이어에서 W = 4096의 윈도우 크기로, SWA는 이론적으로 대략 131K 토큰의 주의 범위를 달성할 수 있습니다. 실제적으로 W = 4096 및 FlashAttention과 xFormers의 최적화 기법을 사용하여, 16K 토큰 시퀀스의 경우 바닐라 주의 기준에 비해 주목할만한 2배의 속도 향상이 가능합니다. 따라서, SWA는 주의 메커니즘의 성능을 혁신적으로 향상시킬 수 있는 강력하고 효율적인 접근 방식입니다.\n\n### b. 롤링 버퍼 캐시\n\n- 롤링 버퍼 캐시를 구현함으로써, Mistral 7B는 고정된 주의 범위를 전략적으로 사용하여 캐시 크기를 효과적으로 제어합니다. 이 캐시는 W로 표시된 고정된 크기로, 캐시 내에서 특정 시간 단계 i에서 시간 단계 i mod W에 키와 값들을 효율적으로 저장합니다. 시퀀스가 진행되고 i가 W를 초과할 때, 캐시는 롤링 버퍼 메커니즘을 사용하여 이전 값들을 덮어쓰고 무한정으로 확장되는 것을 방지합니다. W = 3으로 설명된 이 접근 방식은 32k 토큰 시퀀스에 대해 8배의 캐시 메모리 사용량 감소를 실현함으로써, 모델의 품질을 희생하지 않고 달성합니다. 고정된 주의 범위는 효율적인 메모리 이용을 보장할 뿐만 아니라 Mistral 7B가 길이가 다른 시퀀스를 처리하는 데에 원활하게 기능하는 데에 기여합니다.\n\n### c. 사전 채움 및 청크 분할\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 시퀀스 생성 과정에서는 문맥 정보에 기반하여 순차적으로 토큰을 예측하는데, (k, v) 캐시를 사용하여 효율적으로 최적화됩니다. 알려진 프롬프트로 미리 채워진 캐시를 활용하여 효율성을 높입니다. 긴 프롬프트를 관리하기 위해 지정된 윈도우 크기를 사용하여 작은 청크로 나누고, 각 청크를 사용하여 캐시를 미리 채웁니다. 이 전략적 접근 방식은 시퀀스 생성 프로세스 중 캐시 내부 및 현재 청크 전체에서 주의력을 계산하는 것을 포함합니다. 이 방법을 활용함으로써 Mistral 7B는 시퀀스 생성의 효율성을 향상시키며, 캐시에 저장된 미리 알려진 프롬프트를 효율적으로 활용하여 각 예측된 토큰을 이전 토큰과 조화롭게 정렬합니다.\n- 언어 모델의 동적인 환경에서 Mistral 7B의 등장은 성능과 효율성 면에서 큰 도약을 의미합니다. 포괄적인 평가 파이프라인을 통해 Mistral 7B는 자신의 능력을 입증하며, 이전 제품인 Llama 2 7B 및 Llama 2 13B뿐만 아니라 Llama 1 34B와 같은 핵심 벤치마크에서 뛰어난 성능을 보여줌으로써 뛰어난 경쟁력을 나타냅니다.\n- Mistral 7B의 우월성은 모든 측정 항목에 걸쳐 명백히 드러나며, 해당 분야의 선도주자로서의 지위를 재확인합니다. 다양한 벤치마크에 대한 면밀한 재평가 과정은 Mistral 7B의 탁월한 능력을 일관되게 입증하며, 경쟁사를 뒤로 남깁니다.\n\n## 크기 및 효율성 분석\n\n- Mistral 7B의 매력 중요 요소 중 하나는 혁신적인 \"동등한 모델 크기\" 계산 방식을 통한 효율성입니다. 추론, 이해 및 STEM 추론 등에서 평가한 결과, Mistral 7B는 세 배 이상 크기의 Llama 2 모델과 동등한 성능을 보여줍니다. 이 효율성은 과도한 매개변수 부담 없이 뛰어난 결과를 제공할 수 있는 Mistral 7B의 능력을 입증합니다.\n- Mistral 7B의 효율성을 더 자세히 살펴보면, 평가 결과에서 지식 압축에 대한 흥미로운 통찰력을 확인할 수 있습니다. 지식 벤치마크에서 1.9배 낮은 압축률을 달성하지만, 이는 Mistral 7B의 의도적으로 제한된 매개변수 수에 기인합니다. 이 제한은 저장된 지식 양을 제한하지만, Mistral 7B는 집중하고 효과적으로 매개변수를 활용하여 보상합니다.\n\n# 평가의 차이점\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n불일치 사항을 투명하게 다루면서, 평가 규정의 변화를 유의하는 것이 중요합니다. 어떤 벤치마크에서는 Llama 2의 MBPP와 Mistral 7B의 평가 결과 사이에 차이가 발생합니다. TriviaQA에서 손으로 검증된 데이터를 사용하는 것이 Mistral 7B의 성능 지표의 신뢰성에 기여하는 강건한 평가 과정을 확인하게 됩니다.\n\n# 데이터셋\n\n아래 열로 구성된 구조 데이터베이스를 사용할 계획입니다. 다음 테이블에서 다양한 검색을 수행할 것입니다.\n\n```js\ntransaction = [\n  \"transaction_id\",\n  \"transaction_amount\",\n  \"transaction_date\",\n  \"transaction_type\",\n  \"transaction_status\",\n  \"transaction_description\",\n  \"transaction_source_account\",\n  \"transaction_destination_account\",\n  \"transaction_currency\",\n  \"transaction_fee\",\n];\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 코드 구현\n\n- 패키지 설치하기\n\n```js\n!pip install git+https://github.com/huggingface/transformers.git\n!pip install deepspeed --upgrade\n!pip install accelerate\n!pip install sentencepiece\n!pip install langchain\n!pip install torch\n!pip install bitsandbytes\n```\n\n2. 패키지 불러오기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport os\nimport re\nimport torch\nfrom difflib import SequenceMatcher\nfrom langchain.chains import LLMChain\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom transformers import LlamaTokenizer, LlamaForCausalLM, pipeline\n```\n\n3. 모델 불러오기\n\n```js\nbase_model = LlamaForCausalLM.from_pretrained(\n  \"mistralai/Mistral-7B-Instruct-v0.1\",\n  (load_in_8bit = True),\n  (device_map = \"auto\")\n);\ntokenizer = LlamaTokenizer.from_pretrained(\n  \"mistralai/Mistral-7B-Instruct-v0.1\"\n);\npipe = pipeline(\n  \"text-generation\",\n  (model = base_model),\n  (tokenizer = tokenizer),\n  (max_length = 500),\n  (temperature = 0.3),\n  (top_p = 0.95),\n  (repetition_penalty = 1.2)\n);\nlocal_llm = HuggingFacePipeline((pipeline = pipe));\n```\n\n4. SequenceMatcher\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 Python 함수는 difflib 모듈의 SequenceMatcher 클래스를 활용하여 쿼리와 지정된 사전의 열 이름 간의 유사도 점수를 계산하여 쿼리 이해력과 대체를 향상시킵니다.\n\n```js\ndef find_columns_match(question, input_dict):\ntry:\n  question_list = re.split(r'\\s|,|\\.', question)\n  for index, string2 in enumerate(question_list):\n    for string1 in input_dict.get('table1_columns'):\n      score = SequenceMatcher(None,string1.lower(), string2.lower()).ratio()*100\n      if score \u003e 91:\n        question_list[index] = string1 + \",\"\n  return \" \".join(question_list)\n\nexcept:\n return question\n```\n\n이 Python 함수 query_generator은 제공된 테이블명, 열 목록 및 질문에 기반하여 SQL 쿼리를 생성합니다. 이는 템플릿 문자열을 활용하여 쿼리 생성 프로세스를 구조화하며, 테이블 명, 열 목록 및 질문에 대한 자리 표시자를 포함합니다. 그런 다음 PromptTemplate 객체를 사용하여 이러한 자리 표시자를 채워넣고 LLMChain을 통해 대형 언어 모델 (LLM)과 상호 작용하여 SQL 쿼리를 생성합니다. 마지막으로 생성된 SQL 쿼리를 출력합니다.\n\n```js\ndef query_generator(tble, cols, question):\n\n  template = \"\"\"Generate a SQL query using the following table name: {Table}, and columns as a list: {Columns}, to answer the following question:\n  {question}.\n\n  Output Query:\n\n  \"\"\"\n\n  prompt = PromptTemplate(template=template, input_variables=[\"Table\", \"question\", \"Columns\"])\n\n  llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n\n  response = llm_chain.run({\"Table\": tble, \"question\": question, \"Columns\": cols})\n  print(response)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 표\n\ntransaction = [\n\"transaction_id\",\n\"transaction_amount\",\n\"transaction_date\",\n\"transaction_type\",\n\"transaction_status\",\n\"transaction_description\",\n\"transaction_source_account\",\n\"transaction_destination_account\",\n\"transaction_currency\",\n\"transaction_fee\"\n]\n\n    inputs = [\"transaction_id가 10인 경우 transaction_amount, transaction_date, transaction_type,transaction_description을 검색하는 SQL 쿼리 생성\",\n             \"transaction_status가 'completed'인 경우 transaction_id, transaction_date, transaction_type, transaction_source_account을 검색하는 SQL 쿼리 생성\",\n             \"transaction_type 및 평균 transaction_amount의 개수를 검색하고 transaction_type로 정렬하는 SQL 쿼리 생성\",\n             \"각 소스 계정별 총 거래 금액 목록을 검색하고 총 거래 금액을 내림차순으로 정렬하는 SQL 쿼리 생성\",\n             \"각 거래 유형별 최대 거래 금액을 검색하고 거래 유형으로 정렬하는 SQL 쿼리 생성\"]\n\n    for input in inputs:\n        query_generator(\"transaction\",transaction ,question=find_columns_match(input,transaction))\n\n# 응답\n\n- 다음과 같은 테이블 이름을 사용하고 컬럼을 나열한 리스트를 사용하여 SQL 쿼리를 생성하십시오: transaction 및 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’], 다음 질문에 대한 응답을 위해 SQL 쿼리를 생성하십시오: (‘transaction_id가 10인 경우 transaction_amount, transaction_date, transaction_type,transaction_description을 검색하는 SQL 쿼리 생성’).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n출력 쿼리:\n\n  SELECT transaction_amount, transaction_date, transaction_type, transaction_description FROM transaction WHERE transaction_id = 10;\n```\n\n2. 다음과 같은 테이블 이름인 transaction과 열 목록인 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’]을 사용하여 다음 질문에 대한 SQL 쿼리를 생성하십시오:\n   (‘transaction_status가 ‘completed’인 경우 transaction_id, transaction_date, transaction_type, transaction_source_account를 검색하는 SQL 쿼리를 생성하십시오’).\n\n```js\n출력 쿼리:\n  SELECT transaction_id, transaction_date, transaction_type, transaction_source_account FROM transaction WHERE transaction_status = 'completed'\n```\n\n3. 다음과 같은 테이블 이름인 transaction과 열 목록인 [‘transaction_id’, ‘transaction_amount’, ‘transaction_date’, ‘transaction_type’, ‘transaction_status’, ‘transaction_description’, ‘transaction_source_account’, ‘transaction_destination_account’, ‘transaction_currency’, ‘transaction_fee’]을 사용하여 다음 질문에 대한 SQL 쿼리를 생성하십시오:\n   (‘transaction_type의 count와 평균 transaction_amount를 가져오고 transaction_type으로 정렬하십시오’).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n결과 쿼리:\n\n  SELECT transaction_type, AVG(transaction_amount) AS avg_transaction_amount, COUNT(*) AS total_count\n  FROM transaction\n  GROUP BY transaction_type\n  ORDER BY transaction_type;\n```\n\n4. 다음 테이블 이름과 열 목록을 사용하여 SQL 쿼리를 생성하십시오: transaction 및 열: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], 다음 질문에 답하십시오:\n   (‘리스트에서 각 소스 계정의 총 거래 금액을 내림차순으로 정렬하여 조회하는 SQL 쿼리를 생성하세요’).\n\n```js\n결과 쿼리:\n\n       SELECT transaction_source_account, SUM(transaction_amount) AS TotalTransactionAmount\n        FROM transaction\n        GROUP BY transaction_source_account\n        ORDER BY TotalTransactionAmount DESC;\n```\n\n5. 다음 테이블 이름과 열 목록을 사용하여 SQL 쿼리를 생성하십시오: transaction 및 열: ['transaction_id', 'transaction_amount', 'transaction_date', 'transaction_type', 'transaction_status', 'transaction_description', 'transaction_source_account', 'transaction_destination_account', 'transaction_currency', 'transaction_fee'], 다음 질문에 답하십시오:\n   (‘각 거래 유형의 최대 거래 금액을 찾아 거래 유형으로 정렬하는 SQL 쿼리를 생성하세요’).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n출력 쿼리:\n\n   SELECT transaction_type, MAX(transaction_amount) AS max_transaction_amount\n   FROM transaction\n   GROUP BY transaction_type\n   ORDER BY transaction_type;\n```\n\n일반적인 추출은 효과적이지만, 연구 결과, 데이터를 세부 조정하여 LLM을 수행하면 우수한 결과를 얻을 수 있습니다. 세밀 조정 접근법을 채용해 봅시다.\n\n# 2 Fine-tune NL2SQL with Phi-3\n\nPhi-3를 만나보세요, Microsoft의 최신 오픈 AI 모델의 주요 성과입니다. Phi-3-mini, Phi-3-small 및 Phi-3-medium을 통해, 이 작은 언어 모델 (SLM)의 Phi-3 패밀리는 AI 모델의 세계를 혁신하도록 설계되었습니다. 38억 개의 파라미터를 사용하고 33조 개의 토큰으로 훈련된 Phi-3-mini는 높은 성능을 발휘하며 Mixtral 8x7B 및 GPT-3.5와 같은 큰 모델과 같은 성능을 보여줍니다. 게다가, 이 모델은 스마트폰 장치에서 효율적으로 작동할 수 있습니다. Phi-3의 성공은 훈련 데이터셋에 기인합니다. Phi-2의 데이터셋의 진화된 버전입니다. 상세히 걸러낸 웹 데이터 및 합성 입력을 통해 이러한 모델은 강도, 안전 및 대화 능력에 우선순위를 두어 다양한 응용프로그램에 적합합니다. 7B 및 14B 파라미터를 가진 Phi-3-small 및 Phi-3-medium은 효율 유지와 함께 Phi-3의 기능을 더욱 향상시키도록 설계되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Phi 3 Architecture and Evaluation\n\nPhi-3 패밀리는 품질과 비용을 균형있게 유지하도록 설계된 다양한 모델을 제공하여 생성형 AI 애플리케이션을 개발하는 고객을 위한 옵션을 제공합니다.\n\nPhi-3-mini: 이 모델은 38억 개의 파라미터를 갖추고 33조 개의 토큰으로 이루어진 광범위한 데이터셋을 기반으로 훈련되었습니다. 32개의 레이어, 32개의 어텐션 헤드, 그리고 3072개의 히든 디멘션을 갖는 트랜스포머 디코더 아키텍처를 채택했습니다. 디폴트 콘텍스트 길이는 4천 개의 토큰이며, 32K 어휘 사전을 사용하는 토크나이저를 활용합니다. 추가로, 128K 토큰의 콘텍스트 길이를 갖춘 확장 버전인 Phi-3-mini-128K도 있습니다.\n\nPhi-3-small: 70억 개의 파라미터로 훈련된 Phi-3-small은 48조 개의 토큰을 사용합니다. 이 모델은 100K 어휘 사전과 8천 개의 디폴트 콘텍스트 길이를 갖추었습니다. 아키텍처는 32개의 레이어, 32개의 어텐션 헤드, 그리고 4096개의 히든 디멘션으로 이루어져 있습니다. 이 모델은 메모리 사용량을 최적화하기 위해 그룹화된 쿼리 어텐션과 번갈아가며 쓰이는 밀집/희소 어텐션을 활용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPhi-3-medium: 이 미리보기 모델은 140억 개의 매개변수를 자랑하며 4.8조 개의 토큰으로 학습되었습니다. 40개의 레이어, 40개의 어텐션 헤드, 그리고 임베딩 크기는 5120입니다.\n\n## 훈련 방법:\n\n- 훈련 데이터 구성: Phi-3 모델의 훈련 데이터는 신중하게 선별됩니다. 교육 수준별로 분류된 웹 데이터와 합성 LLM 생성 데이터로 구성되며 두 가지 이질적이고 순차적인 단계로 사전 훈련을 거칩니다.\n- 사전 훈련 단계: 제1 단계는 일반 지식과 언어 이해에 중점을 둔 웹 소스를 사용합니다. 제2 단계는 논리 추론 및 특정 기술을 가르치기 위해 제1 단계의 웹 데이터와 합성 데이터를 더 많이 활용합니다.\n- 사후 훈련 단계: 사전 훈련 후, Phi-3-mini는 감독형 세밀 조정 (SFT) 및 직접 선호도 최적화 (DPO)를 거쳤습니다. SFT는 수학, 코딩, 추론, 대화, 모델 신원, 안전 도메인 간에 높은 품질의 데이터를 선별하는 과정을 포함합니다.\n- DPO는 채팅 형식 데이터, 추론, 그리고 책임 있는 AI 노력에 초점을 맞춥니다.\n- 맥락 확장: Phi-3-mini의 맥락 창 크기가 Long Rope 방법론을 사용하여 4k 토큰에서 128k 토큰으로 확장되었습니다. 이 확장은 맥락의 길이가 크게 증가함에도 일관된 성능을 유지합니다.\n- 데이터 최적화: 훈련 데이터는 모델의 규모를 위한 \"데이터 최적\" 지점으로 보정됩니다. 웹 데이터는 지식과 추론의 적절한 균형을 보장하기 위해 필터링됩니다. 특히 작은 모델의 경우 이는 매우 중요합니다.\n- 다른 모델과의 비교: Phi-3의 접근 방식은 이전 작업과 대조적으로, 해당 규모에 대한 데이터 품질에 중점을 두며 컴퓨팅이나 과도한 훈련 방법보다 데이터 최적화를 강조합니다. 벤치마크 비교는 Phi-3가 작은 모델 용량을 위한 최적화를 잘 보여줍니다.\n- Phi-3-medium 미리보기: 140억 개의 매개변수를 가진 Phi-3-medium은 Phi-3-mini와 유사하게 훈련되었지만 더 큰 규모로 이루어집니다. 일부 벤치마크에서는 7B에서 14B 매개변수로의 전환에서 큰 개선이 없어 계속해서 데이터 혼합을 개선 중임을 시사합니다.\n- 사후 향상: 모델은 채팅 능력, 견고성, 그리고 안전성을 향상시키기 위해 감독형 세밀 조정 및 DPO를 통한 선호도 조정을 거칩니다.\n\n## 안전성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPhi-3-mini은 Microsoft의 책임 있는 AI 원칙에 따라 만들어진 AI 모델입니다. 이 프로젝트는 개발 초기부터 안전을 우선시하는 원칙을 중요시하여 만들어졌습니다. 모델이 윤리 기준을 준수하고 잠재적인 피해를 최소화할 수 있는 능력을 보장하기 위해 포괄적인 전략이 채택되었습니다.\n\n모델 학습 후에는, 해당 모델이 책임 있는 AI 기준을 충족하는지 확인하기 위해 면밀한 안전 조정이 이루어집니다. 게다가, Microsoft의 독립된 레드 팀이 Phi-3-mini를 검토하여 강화 및 안전 프로토콜을 강화할 수 있는 부분을 식별합니다.\n\n자동화된 테스팅과 잠재적인 피해의 다양한 범주에 대한 평가는 프로세스의 중요한 부분입니다. 이러한 테스트는 모델의 출력물로부터 발생하는 모든 위험을 감지하고 해결하는 데 목표를 두고 있습니다.\n\n더 나아가, Phi-3-mini는 의견 데이터 세트를 활용하여 응답을 더욱 개선합니다. 특정 테스트 중 확인된 잠재적인 피해 범주에 대응하기 위해 내부에서 생성된 데이터 세트가 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 코드 구현\n\n- 패키지 설치\n\n```js\n !pip install -q -U bitsandbytes\n !pip install -q -U transformers\n !pip install -q -U xformers\n !pip install -q -U peft\n !pip install -q -U accelerate\n !pip install -q -U datasets\n !pip install -q -U trl\n !pip install -q -U einops\n !pip install -q -U nvidia-ml-py3\n !pip install -q -U huggingface_hub\n```\n\n2. 패키지 가져오기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling\nfrom pynvml import *\nimport time, torch\nfrom trl import SFTTrainer\nfrom peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\nfrom peft import AutoPeftModelForCausalLM\n```\n\n3. 데이터셋 불러오기\n\n```python\ndataset = load_dataset(\"b-mc2/sql-create-context\")\ndataset\n```\n\n4. 데이터셋 형식화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndef create_prompt(sample):\n      system_prompt_template = \"\"\"\u003cs\u003e\n            아래는 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n            ### 지시사항: \u003c\u003cuser_question\u003e\u003e\n            ### 데이터베이스 스키마:\n            \u003c\u003cdatabase_schema\u003e\u003e\n            ### 응답:\n            \u003c\u003cuser_response\u003e\u003e\n            \u003c/s\u003e\n            \"\"\"\n      user_message = sample['question']\n      user_response = sample['answer']\n      database_schema = sample['context']\n      prompt_template = system_prompt_template.replace(\"\u003c\u003cuser_question\u003e\u003e\",f\"{user_message}\").replace(\"\u003c\u003cuser_response\u003e\u003e\",f\"{user_response}\").replace(\"\u003c\u003cdatabase_schema\u003e\u003e\",f\"{database_schema} \")\n\n      return {\"inputs\":prompt_template}\n\n\ninstruct_tune_dataset = dataset.map(create_prompt)\nprint(instruct_tune_dataset)\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU 메모리 사용량: {info.used//1024**2} MB.\")\n```\n\n5. 토크나이저와 모델 로드\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n# 토크나이저 로드\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n# fp16로 모델 로드\nmodel = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, device_map={\"\": 0})\nprint(print_gpu_utilization())\n```\n\n6. 모델 추론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 프롬프트 정의\n\n```bash\n    prompt = [\n        \"코코넛 밀크로 만든 치킨 카레 레시피를 작성해주세요.\",\n        \"다음 문장을 프랑스어로 번역해주세요: '나는 빵과 치즈를 좋아해요!'\",\n        \"유명한 20명의 인물을 인용해보세요.\",\n        \"지금 달은 어디에 있나요?\"\n    ]\n\n    # 변수 초기화\n    duration = 0.0\n    total_length = 0\n\n    # 프롬프트 반복\n    for i in range(len(prompt)):\n        # 프롬프트 토큰화 및 GPU로 이동\n        inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n\n        # 입력 텐서 인덱스를 torch.long으로 변환\n        inputs = {k: v.to(torch.long) for k, v in inputs.items()}\n\n        # 시작 시간\n        start_time = time.time()\n\n        # 자동 캐스팅을 사용하여 추론 수행\n        with torch.cuda.amp.autocast(enabled=False):  # 자동 캐스팅 비활성화\n            output = model.generate(**inputs, max_length=500)\n\n        # 소요 시간과 총 길이 계산\n        duration += float(time.time() - start_time)\n        total_length += len(output)\n\n        # 프롬프트당 토큰 속도 계산\n        tok_sec_prompt = round(len(output) / float(time.time() - start_time), 3)\n\n        # 프롬프트당 토큰 속도 출력\n        print(\"프롬프트 --- %s 토큰/초 ---\" % (tok_sec_prompt))\n\n        # 디코드된 출력 출력\n        print(tokenizer.decode(output[0], skip_special_tokens=True))\n\n    # 평균 토큰 속도 계산\n    tok_sec = round(total_length / duration, 3)\n    print(\"평균 --- %s 토큰/초 ---\" % (tok_sec))\n```\n\n9. Fine-tuning되지 않은 Text to SQL\n\n```bash\n    prompt = [\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        각 도시의 역 중 가장 높은 위도를 가진 역순으로 모든 도시를 나열하십시오.\n        데이터베이스 스키마:\n        CREATE TABLE station (city VARCHAR, lat INTEGER)\n        ### 응답:\n        SELECT city, lat FROM station ORDER BY lat DESC;\n        \"\"\",\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        '각 선수가 20점 이상 및 10점 미만을 가지고 있으며 상위 10위 안에 있는 포지션은 무엇입니까?\n        데이터베이스 스키마:\n        CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\n        ### 응답:\n        SELECT POSITION, Points, Ranking\n        FROM player\n        WHERE Points \u003e 20 AND Points \u003c 10 AND Ranking IN (1,2,3,4,5,6,7,8,9,10)\n        \"\"\",\n        \"\"\"\n        다음은 작업을 설명하는 지시사항입니다. 요청을 적절히 완료하는 응답을 작성하십시오.\n        ### 지시사항 :\n        노래를 가장 많이 연주한 밴드 맴버의 이름을 찾아보세요.\n        데이터베이스 스키마:\n        CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)\n        ### 응답:\n        SELECT b.firstname\n        FROM Band b\n        JOIN Performance p ON b.id = p.bandmate\n        GROUP BY b.firstname\n        ORDER BY COUNT(*) DESC\n        LIMIT 1;\n        \"\"\"\n    ]\n\n    for i in range(len(prompt)):\n      model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n      start_time = time.time()\n      output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n      duration += float(time.time() - start_time)\n      total_length += len(output)\n      tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n      print(\"프롬프트 --- %s 토큰/초 ---\" % (tok_sec_prompt))\n      print(print_gpu_utilization())\n      print(tokenizer.decode(output, skip_special_tokens=False))\n\n    tok_sec = round(total_length/duration,3)\n    print(\"평균 --- %s 토큰/초 ---\" % (tok_sec))\n\n    # Fine-tuning\n\n    base_model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n\n    tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_eos_token=True, use_fast=True, max_length=250)\n    tokenizer.padding_side = 'right'\n    tokenizer.pad_token = tokenizer.eos_token\n\n    compute_dtype = getattr(torch, \"float16\") # Ampere (또는 최신) GPU를 사용하는 경우 bfloat16로 변경\n    bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=compute_dtype,\n            bnb_4bit_use_double_quant=True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n              base_model_id, trust_remote_code=True, quantization_config=bnb_config, revision=\"refs/pr/23\", device_map={\"\": 0}, torch_dtype=\"auto\", flash_attn=True, flash_rotary=True, fused_dense=True\n    )\n    print(print_gpu_utilization())\n\n    model = prepare_model_for_kbit_training(model)\n```\n\n10. LoRA 매개변수\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\npeft_config = LoraConfig(\n  (lora_alpha = 16),\n  (lora_dropout = 0.05),\n  (r = 16),\n  (bias = \"none\"),\n  (task_type = \"CAUSAL_LM\"),\n  (target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"dense\", \"fc1\", \"fc2\"])\n);\n```\n\n9. Training Parameters\n\n```js\ntraining_arguments = TrainingArguments(\n            output_dir=\"./phi3-results\",\n            save_strategy=\"epoch\",\n            per_device_train_batch_size=4,\n            gradient_accumulation_steps=12,\n            log_level=\"debug\",\n            save_steps=100,\n            logging_steps=25,\n            learning_rate=1e-4,\n            eval_steps=50,\n            optim='paged_adamw_8bit',\n            fp16=True, #change to bf16 if are using an Ampere GPU\n            num_train_epochs=1,\n            max_steps=400,\n            warmup_steps=100,\n            lr_scheduler_type=\"linear\",\n            seed=42)\n```\n\n10. Data Prepare for the training\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ntrain_dataset = instruct_tune_dataset.map(\n  (batched = True),\n  (remove_columns = [\"answer\", \"question\", \"context\"])\n);\ntrain_dataset;\n```\n\n11. Fine-Tuned\n\n```js\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset[\"train\"],\n    #eval_dataset=dataset['test'],\n    peft_config=peft_config,\n    dataset_text_field=\"inputs\",\n    max_seq_length=1024,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False\n)\n\ntrainer.train()\n```\n\n12. Test inference with the fine-tuned adapter\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nbase_model_id = \"microsoft/Phi-3-mini-4k-instruct\";\ntokenizer = AutoTokenizer.from_pretrained(base_model_id, (use_fast = True));\n\ncompute_dtype = getattr(torch, \"float16\");\nbnb_config = BitsAndBytesConfig(\n  (load_in_4bit = True),\n  (bnb_4bit_quant_type = \"nf4\"),\n  (bnb_4bit_compute_dtype = compute_dtype),\n  (bnb_4bit_use_double_quant = True)\n);\nmodel = AutoModelForCausalLM.from_pretrained(\n  base_model_id,\n  (trust_remote_code = True),\n  (quantization_config = bnb_config),\n  (device_map = { \"\": 0 })\n);\nadapter = \"/content/phi3-results/checkpoint-400\";\nmodel = PeftModel.from_pretrained(model, adapter);\n```\n\n13. 수행하기\n\n```js\ndatabase_schema = 'CREATE TABLE station (city VARCHAR, lat INTEGER)'\nuser_question = \"List all the cities in a decreasing order of each city's stations' highest latitude.\"\n\nprompt_template = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{user_question}\nDatabase Schema:\n{database_schema}\n### Response:\n\"\"\"\n\nquestion = \"'What are the positions with both players having more than 20 points and less than 10 points and are in Top 10 ranking\"\ncontext = \"CREATE TABLE player (POSITION VARCHAR, Points INTEGER, Ranking INTEGER)\"\n\nprompt_template1 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\ncontext = '''CREATE TABLE Songs (SongId VARCHAR); CREATE TABLE Band (firstname VARCHAR, id VARCHAR); CREATE TABLE Performance (bandmate VARCHAR)'''\nquestion = \"Find the first name of the band mate that has performed in most songs.\"\n\nprompt_template2 = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction:\n{question}\nDatabase Schema:\n{context}\n### Response:\n\"\"\"\n\nprompt = []\nprompt.append(prompt_template)\nprompt.append(prompt_template1)\nprompt.append(prompt_template2)\n\nfor i in range(len(prompt)):\n  model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n  start_time = time.time()\n  output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n  duration += float(time.time() - start_time)\n  total_length += len(output)\n  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n  print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n  print(print_gpu_utilization())\n  print(tokenizer.decode(output, skip_special_tokens=False))\n\ntok_sec = round(total_length/duration,3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n14. 모델 저장하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport locale\nimport shutil\nfrom huggingface_hub import notebook_login\nfrom google.colab import drive\n\n# Set the preferred encoding to UTF-8\nlocale.getpreferredencoding = lambda: \"UTF-8\"\n\n# Log in to the notebook\nnotebook_login()\n\n# Push the fine-tuned adapter to the Hugging Face Hub\ntrainer.push_to_hub(commit_message=\"fine-tuned adapter\")\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# Move the trained model to Google Drive\nshutil.move('/content/phi3-results', '/content/drive/MyDrive/PHI-3')\n\n# Load the trained model\ntrained_model = AutoPeftModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/checkpoint-400\",\n                                                         low_cpu_mem_usage=True,\n                                                         return_dict=True,\n                                                         torch_dtype=torch.float16,\n                                                         device_map='auto',)\n\n# Merge and unload the trained model\nlora_merged_model = trained_model.merge_and_unload()\n\n# Save the merged model\nlora_merged_model.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\", safe_serialization=True)\n\n# Save the tokenizer for the merged model\ntokenizer.save_pretrained(\"/content/drive/MyDrive/PHI-3/phi3-results/lora_merged_model\")\n\n# Push the merged model to the Hugging Face Hub\nlora_merged_model.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n\n# Push the tokenizer to the Hugging Face Hub\ntokenizer.push_to_hub(repo_id=\"\", commit_message=\"merged model\")\n```\n\n15. Perform Inference on Fine-tuned Model\n\n```js\npeft_config = LoraConfig(\n            lora_alpha=16,\n            lora_dropout=0.05,\n            r=16,\n            bias=\"none\",\n            task_type=\"CAUSAL_LM\",\n    )\n\npeft_model_id = \"username/phi3-results\"\nconfig = peft_config.from_pretrained(peft_model_id)\n\nmodel = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n                                             return_dict=True,\n                                             load_in_4bit=True,\n                                             device_map=\"auto\",\n                                             )\n\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n\nmodel = PeftModel.from_pretrained(model, peft_model_id)\n\nprint(model.get_memory_footprint())\n\nfor i in range(len(prompt)):\n    model_inputs = tokenizer(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n    start_time = time.time()\n    output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=10, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n    duration += float(time.time() - start_time)\n    total_length += len(output)\n    tok_sec_prompt = round(len(output)/float(time.time() - start_time), 3)\n    print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n    print(print_gpu_utilization())\n    print(f\"RESPONSE:\\n {tokenizer.decode(output, skip_special_tokens=False)[len(prompt[i]):].split('\u003c/')[0]}\")\n\ntok_sec = round(total_length/duration, 3)\nprint(\"Average --- %s tokens/seconds ---\" % (tok_sec))\n```\n\n# Conclusion\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자연어 처리(NLP)와 SQL 쿼리 엔진의 결합은 데이터베이스와 상호 작용하는 것을 더 쉽고 효율적으로 만들었습니다. 이전에는 SQL에 대한 심층적인 이해가 필요했기 때문에 많은 사용자들에게 어려움이 있었습니다. 그러나 Mistral 7B와 Microsoft Phi-3와 같은 오픈 소스 대형 언어 모델(LLMs)은 이를 바꿨습니다. 이 모델들은 자연어 쿼리를 구조화된 SQL 쿼리로 신속하게 변환하여, 방대한 SQL 전문 지식이 필요 없게 했습니다.\n\nMistral 7B와 Microsoft Phi-3는 NLP 작업에서 우수한 성능을 발휘하는 탁월한 모델들입니다. 그들은 Grouped-Query Attention과 Sliding Window Attention과 같은 기능을 갖추어 더욱 효율적입니다. 크기가 작은 Microsoft Phi-3도 NLP 성능과 효율성에서 새로운 기준을 세우며, 복잡한 벤치마크에서 더 큰 모델들을 능가합니다.\n\n오픈 소스 LLMs를 고급 분석 플랫폼과 AI 시스템에 통합함으로써 기업은 손쉽게 통찰을 추출할 수 있습니다. 이 기술은 금융, 건강 관리, 전자 상거래와 같은 산업들이 데이터 기반 결정을 내리는 방식을 변화시켰습니다. 이러한 모델들이 다양한 부문에 미치는 영향은 상당하며 혁신과 변혁을 촉진했습니다.\n\nNLP와 SQL의 융합을 통해 오픈 소스 LLMs는 데이터 접근을 민주화시키고 효율성, 생산성, 기업 성공을 촉진했습니다. 이는 데이터 자산의 최대 잠재력을 발휘하도록 허용하여 이해당사자들이 실행 가능한 통찰을 추출하기 쉬워지고, 여러 부문에서 탐구와 혁신의 문화를 육성했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n노트북: phi3\n\n제 이전 📝 글들을 확인해주세요.\n\n# 참고 자료\n\n- https://arxiv.org/pdf/2310.06825.pdf\n- https://artgor.medium.com/paper-review-mistral-7b-6acdf2f3132d\n- https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580\n- https://www.datacamp.com/tutorial/mistral-7b-tutorial\n- https://www.analyticsvidhya.com/blog/2023/11/from-gpt-to-mistral-7b-the-exciting-leap-forward-in-ai-conversations/\n- https://medium.com/@rubentak/mistral-7b-the-best-7-billion-parameter llm-yet-8b0aa03016f9\n- https://clarifai.com/mistralai/completion/models/mistral-7B-Instruc\n- https://iamgeekydude.com/2023/06/02/alpaca-llm-load-model-using-langchain-hf/\n- https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/\n- https://huggingface.co/microsoft/Phi-3-mini-128k-instruct\n","ogImage":{"url":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png"},"coverImage":"/assets/img/2024-05-18-NaturalLanguagetoSQLQueryusinganOpenSourceLLM_0.png","tag":["Tech"],"readingTime":38},{"title":"LLM을 사용하여 데이터베이스를 쿼리하는 동안 RAG를 사용하는 데 마주하는 주요 4가지 문제 및 해결 방법","description":"","date":"2024-05-18 18:18","slug":"2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit","content":"\nThe Advent of LLMs shows the ability of machines to comprehend natural language. These capabilities have helped engineers to do a lot of amazing things, such as writing code documentation and code reviews, and one of the most common use cases is code generation; GitHub copilot has shown the capability of AI to comprehend engineers’ intention for code generation, such as Python, Javascript, and SQL, though LLM’s comprehension AI could understand what we want to do and generate code accordingly.\n\n# Using LLM to solve Text-to-SQL\n\nBased on the code generation capability of LLMs, many people have started considering using LLMs to solve the long-term hurdle of using natural language to retrieve data from databases, sometimes called “Text-to-SQL.” The idea of “Text-to-SQL” is not new; after the presence of “Retrieval Augmented Generation (RAG)” and the latest LLM models breakthrough, Text-to-SQL has a new opportunity to leverage LLM comprehension with RAG techniques to understand internal data and knowledge.\n\n![Top 4 Challenges using RAG with LLMs to Query Database Text-to-SQL and how to solve it](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# RAG를 사용한 텍스트-SQL의 도전 과제\n\n텍스트-SQL 시나리오에서 사용자는 LLM이 생성한 결과를 신뢰하기 위해 정밀도, 보안 및 안정성을 갖추어야합니다. 그러나 실행 가능하고 정확하며 보안이 제어된 텍스트-SQL 솔루션을 추구하는 것은 간단하지 않습니다. 여기에서는 자연어를 통해 데이터베이스를 쿼리하기 위해 RAG를 사용한 LLM 사용의 네 가지 주요 기술적 도전 과제를 요약해보았습니다: 컨텍스트 수집, 검색, SQL 생성 및 협업.\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_1.png)\n\n## 도전 과제 1: 컨텍스트 수집 도전과제\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 다양한 원본 간 상호 운용성: 다양한 소스, 메타데이터 서비스 및 API 간에 원활하게 검색 및 통합된 정보를 일반화하고 표준화하는 것이 중요합니다.\n- 데이터와 메타데이터의 복잡한 링킹: 이는 데이터를 해당 문서 저장소의 메타데이터와 연결하는 것을 포함합니다. 관련성, 계산 및 집계와 같은 메타데이터, 스키마 및 컨텍스트를 저장하는 것이 포함됩니다.\n\n## 도전 과제 2: 검색 도전과제\n\n- 벡터 저장소의 최적화: 인덱싱 및 청킹과 같은 벡터 저장소를 최적화하기 위한 기술을 개발하고 구현하는 것은 검색 효율성과 정확도 향상에 중요합니다.\n- 의미 검색의 정확도: 도전 과제는 질의 이해의 뉘앙스에 있으며 이는 결과의 정확도에 중대한 영향을 미칠 수 있습니다. 이는 일반적으로 쿼리 재작성, 다시 순위 지정 등과 같은 기술을 포함합니다.\n\n## 도전 과제 3: SQL 생성 도전과제\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- SQL 쿼리의 정확성 및 실행 가능성: 정확하고 실행 가능한 SQL 쿼리를 생성하는 것은 상당한 도전입니다. 이를 위해서는 LLM이 SQL 구문, 데이터베이스 스키마, 그리고 다양한 데이터베이스 시스템의 특정 방언에 대한 깊은 이해가 필요합니다.\n- 쿼리 엔진 방언 적응: 데이터베이스는 종종 SQL 구현에서 고유한 방언과 뉘앙스를 가집니다. 이러한 차이에 적응하고 다양한 시스템 간에 호환되는 쿼리를 생성할 수 있는 LLM을 설계하는 것은 도전의 복잡도를 더 높이는 요소입니다.\n\n## 도전 4: 협업 도전\n\n- 집단 지식 축적: 도전은 다양한 사용자 그룹으로부터 수집된 집단적인 통찰과 피드백을 효과적으로 수집, 통합, 그리고 활용하여 LLM이 검색하는 데이터의 정확성과 관련성을 향상하는 메커니즘을 만드는 데에 있습니다.\n- 접근 제어: 데이터를 검색하는 것에 대한 다음으로 중요한 도전은 존재하는 조직 데이터 접근 정책 및 개인정보 보호 규정이 새로운 LLM 및 RAG 아키텍처에도 적용되도록 보장하는 것입니다.\n\n더 많은 정보를 원하시나요? 각 도전에 대해 미래 게시물에서 자세히 공유할 계획입니다. 알림을 받으려면 Medium에서 팔로우해주세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 어떻게 문제를 해결할 수 있을까요? LLM을 위한 의미론적 레이어.\n\n위의 과제들을 해결하기 위해서, 우리는 LLM과 데이터 소스 사이에 레이어가 필요합니다. 이 레이어를 통해 LLM이 비즈니스 의미론과 메타데이터를 데이터 소스로부터 학습할 수 있게 되며, 이 레이어는 종종 \"의미론적 레이어\"라고 불리는 것이 필요합니다. 의미론적 레이어는 의미론과 데이터 구조 간의 연결을 해결하고, 액세스 제어와 식별 관리를 조정하여 정확한 사용자만이 정확한 데이터에 액세스하도록 보장해야 합니다.\n\nLLM을 위한 의미론적 레이어에는 무엇이 포함되어야 할까요? 여기서 몇 가지 측면으로 일반화해봅시다.\n\n## 데이터 해석 및 표현\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 비즈니스 용어 및 개념: 시맨틱 레이어는 비즈니스 용어와 개념의 정의를 포함합니다. 예를 들어, \"수익\"과 같은 용어는 시맨틱 레이어에 정의되어 있어서 비즈니스 사용자가 BI 도구에서 \"수익\"을 조회할 때 시스템이 어떤 데이터를 검색하고 어떻게 계산할지 정확히 알고 있습니다.\n\n- 데이터 관계: 이것은 서로 다른 데이터 엔티티 간의 관계를 정의합니다. 예를 들어, 고객 데이터가 판매 데이터와 어떻게 관련되는지 또는 제품 데이터가 재고 데이터와 연결되는 방법 등이 있습니다. 이러한 관계는 복잡한 분석을 수행하고 통찰을 얻는 데 중요합니다.\n\n- 계산 및 집계: 시맨틱 레이어에는 종종 미리 정의된 계산 및 집계 규칙이 포함됩니다. 이는 사용자가 예를 들어 금년 매출을 계산하기 위해 복잡한 수식을 작성하는 방법을 알 필요가 없다는 것을 의미합니다. 시맨틱 레이어는 내부 데이터 원본을 기반으로 이러한 작업을 정의 및 규칙에 따라 처리합니다.\n\n## 데이터 액세스 및 보안\n\n- 보안 및 액세스 제어: 이것은 누가 어떤 데이터에 액세스할 수 있는지를 관리할 수도 있습니다. 사용자가 액세스 권한을 부여받은 데이터만 볼 수 있고 분석할 수 있도록 보장하여 데이터 프라이버시를 유지하고 규정을 준수하는 데 중요합니다.\n\n## 데이터 구조 및 조직\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터 소스 매핑: 시맨틱 레이어는 비즈니스 용어와 개념을 실제 데이터 소스에 매핑합니다. 이는 각 비즈니스 용어에 해당하는 데이터베이스 테이블과 열을 지정하고, BI 도구가 올바른 데이터를 검색할 수 있도록 합니다.\n- 다차원 모델: 일부 BI 시스템에서 시맨틱 레이어에는 다차원 모델(예: OLAP 큐브)이 포함되어 복잡한 분석과 데이터 슬라이싱/다이싱이 가능합니다. 이러한 모델은 사용자가 쉽게 탐색하고 분석할 수 있는 차원과 측정 값을 구성합니다.\n\n## 메타데이터\n\n- 메타데이터 관리: 메타데이터를 관리합니다. 이는 데이터에 대한 데이터로서, 데이터 원본, 변환, 데이터 계보 등 데이터를 이해하는 데 도움이 되는 모든 정보가 포함됩니다.\n\n# WrenAI 소개\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_2.png)\n\nWrenAI는 오픈 소스입니다. 데이터, LLM API 및 환경 어디에서든 WrenAI를 배포할 수 있습니다. 직관적인 온보딩 및 사용자 인터페이스가 함께 제공되어 몇 분 안에 데이터소스에서 데이터 모델을 연결하고 구축할 수 있습니다.\n\nWrenAI의 하부에는 이전 섹션에서 언급한 LLM을 위한 \"Wren Engine\"이라는 프레임워크를 개발했습니다. Wren Engine은 GitHub에서도 오픈 소스로 제공됩니다. Wren Engine에 관심이 있다면 댓글을 남겨주시기 바랍니다. 앞으로 나올 글에서 아키텍처와 디자인에 대해 더 자세히 공유할 계획입니다.\n\n## WrenAI에서의 모델링\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 소스와 연결이 완료되면 자동으로 모든 메타데이터를 수집하며 WrenAI UI를 통해 비즈니스 의미론과 관계를 추가할 수 있습니다. 미래의 의미론적 검색을 위해 자동으로 벡터 저장소를 업데이트할 것입니다.\n\n![이미지](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_3.png)\n\n## 질문하고 따라가기\n\n모델링을 마치고 나면 비즈니스 질문을 시작할 수 있습니다. WrenAI는 가장 관련성 높은 결과 3개를 찾아 제공할 것입니다. 옵션 중 하나를 선택하면 해당 데이터의 출처 및 요약을 단계별 설명으로 제공해 드립니다. 이를 통해 WrenAI가 제안하는 결과를 더 자신 있게 사용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nWrenAI로부터 결과를 받으면 반환된 결과를 기반으로 깊은 통찰이나 분석을 위한 후속 질문을 할 수 있습니다.\n\n![image](/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_4.png)\n\n## 지금 GitHub에서 WrenAI를 사용해보고 커뮤니티에 참여해보세요!\n\n👉 GitHub: https://github.com/Canner/WrenAI\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n👉 디스코드: https://discord.gg/5DvshJqG8Z\n","ogImage":{"url":"/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png"},"coverImage":"/assets/img/2024-05-18-Top4ChallengesusingRAGwithLLMstoQueryDatabaseText-to-SQLandhowtosolveit_0.png","tag":["Tech"],"readingTime":8},{"title":"장소 LLM 통찰 구조화 및 비구조화 데이터 분석을 위한 BigQuery, Gemini","description":"","date":"2024-05-18 18:15","slug":"2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics","content":"\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBigQuery 워크로드 내에서 Gemini 1.0 Pro (텍스트 전용) 및 Gemini 1.0 Pro Vision (멀티모달) 두 가지 LLM 모델을 통합하는 흥미로운 기술을 시연하겠습니다. 이를 통해 Low-code 생성적 인사이트 생성 경험을 제공할 수 있습니다. BigQuery에서 원격 모델 엔드포인트로 지원되는 모델인 Gemini 1.0 Pro와 같이, 데이터베이스 쿼리 내에서 모델을 호출하기 위해 ML.GENERATE_TEXT 구조를 직접 사용할 수 있습니다. 기본적으로 원격 모델로 사용할 수 없거나 생성적 AI 호출에 더 많은 사용자 정의가 필요한 경우 (또는 데이터베이스 내에서 원격으로 액세스하려는 API가 있는 경우), REMOTE FUNCTIONS 접근 방식을 사용할 수 있습니다. 두 시나리오를 모두 다루기 위해 블로그 글을 2개의 섹션으로 나눠서 설명하겠습니다:\n\n## #1 원격 모델 호출:\n\n- 이 섹션은 SELECT 쿼리에서 ML.GENERATE_TEXT를 사용하여 BigQuery 내에서 Gemini 1.0 Pro를 호출하는 방법을 안내합니다.\n- 모델이 이미 BigQuery의 원격 모델로 사용 가능하고 기본 제공으로 사용하려는 경우에 이 접근 방법을 사용할 수 있습니다. 사용하려는 모델의 상태를 이 설명서에서 확인할 수 있습니다.\n- 안내 사례:\n\n인터넷 아카이브 책 데이터셋(공개적으로 BigQuery에서 사용 가능)에 대한 위치 요약기를 구축하며, BigQuery에서 Gemini 1.0 Pro의 원격 모델을 ML.GENERATE_TEXT 구조를 통해 호출하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_1.png\" /\u003e\n\n## #2 원격 함수 구현:\n\n- 이 섹션에서는 Gemini 1.0 Pro Vision을 구현한 클라우드 함수를 호출하는 방법에 대해 안내합니다. 이 클라우드 함수는 BigQuery에서 원격 함수로 노출됩니다.\n- 사용하려는 모델이 원격 모델로 제공되지 않거나 사용 사례에서 더 많은 유연성 및 사용자 정의가 필요한 경우 이 접근 방식을 사용하십시오.\n- 안내용 사용 사례:\n\n기준 이미지와 테스트 이미지를 비교하는 이미지 유효성 검사기를 구축합니다. 이를 위해 외부 테이블에 테스트 이미지 스샷을 포함하는 데이터 세트를 만들고 Gemini 1.0 Pro Vision에 대해 확인하도록 요청합니다. 이를 위해 Gemini Pro Vision 호출을 구현한 Java 클라우드 함수를 만들고 이를 BigQuery에서 원격 함수로 호출합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_2.png\" /\u003e\n\n# BigQuery\n\nBigQuery은 서버리스, 멀티 클라우드 데이터 웨어하우스로, 바이트부터 페타바이트까지 최소한의 운영 오버헤드로 확장이 가능합니다. 이것은 ML 트레이닝 데이터를 저장하기에 좋은 선택지가 됩니다. 내장된 BigQuery Machine Learning (BQML)과 분석 기능을 통해 SQL 쿼리만 사용하여 노코드 예측을 생성할 수 있습니다. 게다가, 페더레이티드 쿼리로 외부 소스에서 데이터에 접근할 수 있어 복잡한 ETL 파이프라인이 필요하지 않습니다. BigQuery가 제공하는 모든 것에 대해 BigQuery 페이지에서 자세히 읽어볼 수 있습니다. 우리는 텍스트 요약 사례에 사용되는 원격 모델을 호출하기 위해 BigQuery ML의 ML.GENERATE_TEXT 구조를 사용할 것입니다.\n\n우리는 BigQuery를 구조적 및 반구조적 데이터를 분석하는 데 도움이 되는 완전 관리형 클라우드 데이터 웨어하우스로 알고 왔습니다. BigQuery는 비정형 데이터에서 모든 분석 및 ML을 수행할 수 있도록 확장되었습니다. 우리는 이미지 데이터를 저장하기 위해 객체 테이블을 사용할 것이며, Gemini Pro Vision 모델을 사용하여 이미지 유효성을 검증하는 원격 기능 사례에 필요한 데이터를 저장할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데모\n\n이 블로그의 나머지 부분에서는 위에서 설명한 유즈 케이스 섹션에 자세히 기술된 실제 예제로 두 가지 유즈 케이스를 모두 시연하겠습니다. 유즈 케이스별 구현에 들어가기 전에 두 가지 유즈 케이스에 필요한 사전 설정 및 공통 단계를 완료해 봅시다.\n\n# 설정\n\n- Google Cloud Console에서 프로젝트 선택기 페이지에서 Google Cloud 프로젝트를 선택하거나 만듭니다.\n- 클라우드 프로젝트에 청구가 활성화되어 있는지 확인하십시오. 프로젝트에 청구가 활성화되어 있는지 확인하는 방법을 알아보세요.\n- Google Cloud에서 미리 로드된 bq를 실행하는 명령줄 환경인 Cloud Shell을 사용할 것입니다. Cloud 콘솔에서 오른쪽 상단의 'Cloud Shell 활성화'를 클릭하세요.\n- 애플리케이션 구축 및 제공을 위한 지원을 위해서, Duet AI를 활성화해 봅시다. Duet AI Marketplace로 이동하여 API를 활성화하세요. 또는 Cloud Shell 터미널에서 다음 명령을 실행할 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngcloud services enable cloudaicompanion.googleapis.com –project PROJECT_ID\n```\n\n5. 이미 하지 않았다면, 이 구현을 위해 필요한 API를 활성화하세요.\n\nBigQuery, BigQuery Connection, Vertex AI, Cloud Storage APIs\n\ngcloud 명령어 대신 이 링크를 사용하여 콘솔을 통해 진행할 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# BigQuery Dataset과 외부 연결 생성하기\n\nBigQuery 데이터셋은 애플리케이션의 모든 테이블과 객체를 포함하는 컨테이너입니다. BigQuery 연결은 Cloud Function과 상호작용하는 데 사용됩니다. 원격 함수를 생성하려면 BigQuery 연결을 만들어야 합니다. 데이터셋과 연결을 생성하는 방법을 알아보겠습니다.\n\n- Google Cloud Console에서 BigQuery 페이지로 이동한 후 프로젝트 ID 옆에 있는 3개 수직 점 아이콘을 클릭하세요. 나타나는 옵션 중에서 “데이터 집합 만들기”를 선택하세요.\n- “데이터 집합 만들기” 팝업에서 아래와 같이 데이터 집합 ID를 “gemini_bq_fn”로 입력하고 지역 값을 기본 값인 “US (다중 지역…)”으로 설정하세요.\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. BigLake Connection을 사용하면 외부 데이터 원본에 연결할 수 있으면서 세밀한 BigQuery 액세스 제어와 보안을 유지할 수 있습니다. 우리의 경우에는 Vertex AI Gemini Pro API를 사용합니다. 우리는 이 연결을 사용하여 Cloud Function을 통해 BigQuery의 모델에 액세스할 것입니다. 아래 단계를 따라 BigLake Connection을 만들어보세요:\n\na. BigQuery 페이지의 탐색기 창에서 ADD를 클릭하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_4.png)\n\nb. 소스 페이지에서 외부 데이터 원본에 대한 연결을 클릭하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nc. 팝업창에 아래 외부 데이터 원본 세부정보를 입력하고 CREATE CONNECTION을 클릭하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_5.png)\n\nd. 연결이 생성되면, 연결 구성 페이지로 이동하여 액세스 권한 부여를 위한 서비스 계정 ID를 복사하세요:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ne. IAM 및 관리 페이지를 열고 액세스 부여를 클릭한 후 새 주체 탭에 서비스 계정 ID를 입력하고 아래에 표시된 역할을 선택한 다음 저장을 클릭하세요.\n\n![그림](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_7.png)\n\n# Use case #1 Remote Model Invocation\n\n여기서는 Vertex AI Gemini Pro foundation 모델을 기반으로 BigQuery에 모델을 만들 것입니다. 이미 데이터 세트와 연결 설정이 완료되었습니다. 이제 3단계만으로 Gemini Pro 모델의 원격 모델 호출을 시연합니다. SQL 쿼리만 사용하여 LLM 애플리케이션이 가동됩니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 테이블 및 모델 생성\n\n인터넷 아카이브 도서 데이터셋을 예시로 들어서 BigQuery에서 공개로 사용할 수 있도록 소스로 가져왔다고 가정해봅시다.\n\n## BigQuery 테이블 생성\n\n위의 예제로부터 공개적으로 이용 가능한 BigQuery 데이터셋에서 약 50개의 레코드를 보유할 수 있는 테이블을 생성해봅시다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBigQuery SQL 에디터 창에서 다음과 같이 DDL (데이터 정의 언어) 문을 실행해보세요:\n\n```sql\ncreate or replace table gemini_bq_fn.books as (\nselect *\nfrom\nbigquery-public-data.gdelt_internetarchivebooks.1905 limit 50);\n```\n\n이 쿼리는 이전에 생성한 데이터셋에 \"books\" 라는 새로운 테이블을 생성합니다.\n\n## BigQuery 모델 생성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델을 생성하려면 BigQuery SQL 편집기 창에서 다음 DDL을 실행하세요:\n\n```js\nCREATE MODEL `gemini_bq_fn.gemini_remote_model`\nREMOTE WITH CONNECTION `us.gemini-bq-conn`\nOPTIONS(ENDPOINT = 'gemini-pro');\n```\n\n모델이 생성되었음을 확인하고 방금 생성된 모델을 볼 수 있는 옵션이 제공됩니다.\n\n## 새로운 생성 AI 애플리케이션을 테스트해보세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그것이에요! 이제 ML.GENERATE_TEXT 문을 사용하여 새로 생성한 생성 모델을 테스트해 보겠습니다.\n\n```js\nSELECT ml_generate_text_llm_result as Gemini_Response, prompt as Prompt\nFROM ML.GENERATE_TEXT(MODEL `gemini_bq_fn.gemini_remote_model`,\n  (select '텍스트 요약기와 표준화기를 당신은 개발했어요. 주소 정보를 포함한 다음 텍스트에서 표준화하고 하나의 표준화된, 통합된 주소를 출력해야 합니다. 빈 값으로 반환해서는 안 됩니다. 왜냐하면 이 필드의 텍스트에서 합리적인 데이터를 가져오는 방법을 알기 때문이에요: ' ||\nsubstring(locations, 0, 200) as prompt\nfrom `gemini_bq_fn.books`),\nSTRUCT(\n  TRUE AS flatten_json_output));\n```\n\n다음 결과가 표시되어야 합니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_8.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우와! 이렇게 쉽게 BigQuery ML에서 데이터베이스의 원격 모델을 사용할 수 있어요.\n\n이제 다른 Vertex AI 모델을 사용해 빅쿼리 원격 함수를 시도해봅시다. 예를 들어, 빅쿼리에서 원격으로 모델을 사용하는 방법을 더 맞춤화하고 유연하게 사용하고 싶다고 가정해봅시다. 현재 지원되는 모델은 이 문서에서 참조할 수 있어요.\n\n# 사용 사례 #2 원격 함수 구현\n\n여기서는 Gemini 1.0 Pro Vision foundation 모델을 구현하는 Java Cloud Function을 기반으로 빅쿼리에서 함수를 생성할 거에요. 먼저 Gemini 1.0 Pro Vision 모델을 사용해 이미지를 비교하기 위해 Java Cloud Function을 생성하고 배포하고, 그 다음에는 빅쿼리에서 배포된 Cloud Function을 호출하는 원격 함수를 생성할 거에요. 기억해 주세요, 빅쿼리에서의 원격 함수 실행에 대해 동일한 절차를 따를 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Java 클라우드 함수 만들기\n\nGen 2 클라우드 함수를 Java로 생성하여 외부 테이블에 저장된 베이스라인 이미지와 테스트 이미지를 비교하는 기능을 구축할 것입니다. 이 작업은 BigQuery의 테스트 이미지 스크린샷이 포함된 데이터셋을 사용하며 Gemini Pro Vision 모델 (Java SDK)을 이용하여 REST 엔드포인트에 배포됩니다.\n\n# Java 클라우드 함수\n\n- Cloud Shell 터미널을 열고 루트 디렉토리나 기본 작업 공간 경로로 이동합니다.\n- 상태 표시줄의 왼쪽 하단에 있는 Cloud Code 로그인 아이콘을 클릭하고 Cloud Functions을 생성할 Google Cloud 프로젝트를 선택합니다.\n- 다시 아이콘을 클릭하고 이번에는 새 응용 프로그램을 만드는 옵션을 선택합니다.\n- \"새 응용 프로그램 생성\" 팝업에서 Cloud Functions 응용 프로그램을 선택합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image1](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_9.png)\n\n5. Select the \"Java: Hello World\" option from the next pop-up:\n\n![image2](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_10.png)\n\n6. Provide a name for the project in the project path. In this case, it is \"Gemini-BQ-Function\".\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n7. 새로운 Cloud Shell Editor 보기에서 프로젝트 구조가 열린 것을 확인해야합니다:\n\n![이미지](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_11.png)\n\n8. 이제 pom.xml 파일의 `dependencies`...`/dependencies` 태그 안에 필요한 종속성을 추가해주세요.\n\n```xml\n\u003cdependency\u003e\n      \u003cgroupId\u003ecom.google.cloud\u003c/groupId\u003e\n      \u003cartifactId\u003egoogle-cloud-vertexai\u003c/artifactId\u003e\n      \u003cversion\u003e0.1.0\u003c/version\u003e\n   \u003c/dependency\u003e\n\n     \u003cdependency\u003e\n      \u003cgroupId\u003ecom.google.code.gson\u003c/groupId\u003e\n      \u003cartifactId\u003egson\u003c/artifactId\u003e\n      \u003cversion\u003e2.10\u003c/version\u003e\n     \u003c/dependency\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n9. \"HelloWorld.java\" 클래스의 이름을 더 의미 있는 이름인 \"GeminiBigQueryFunction.java\"로 변경하세요. 클래스 이름을 이에 맞게 변경해야 합니다.\n\n10. 아래 코드를 복사하고 파일 \"GeminiBigQueryFunction.Java\"의 플레이스홀더 코드를 대체하세요. Github 레포지토리에서 소스를 참조해주세요.\n\n```js\npackage cloudcode.helloworld;\nimport java.io.BufferedWriter;\nimport com.google.cloud.functions.HttpFunction;\nimport com.google.cloud.functions.HttpRequest;\nimport com.google.cloud.functions.HttpResponse;\nimport com.google.cloud.vertexai.VertexAI;\nimport com.google.cloud.vertexai.api.Blob;\nimport com.google.cloud.vertexai.api.Content;\nimport com.google.cloud.vertexai.generativeai.preview.ContentMaker;\nimport com.google.cloud.vertexai.api.GenerateContentResponse;\nimport com.google.cloud.vertexai.api.GenerationConfig;\nimport com.google.cloud.vertexai.api.Part;\nimport com.google.cloud.vertexai.generativeai.preview.PartMaker;\nimport com.google.cloud.vertexai.generativeai.preview.GenerativeModel;\nimport com.google.cloud.vertexai.generativeai.preview.ResponseStream;\nimport com.google.cloud.vertexai.generativeai.preview.ResponseHandler;\nimport com.google.protobuf.ByteString;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Base64;\nimport java.util.List;\nimport java.util.Arrays;\nimport java.util.Map;\nimport java.util.LinkedHashMap;\nimport com.google.gson.Gson;\nimport com.google.gson.JsonObject;\nimport com.google.gson.JsonArray;\nimport java.util.stream.Collectors;\nimport java.lang.reflect.Type;\nimport com.google.gson.reflect.TypeToken;\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.net.HttpURLConnection;\nimport java.net.URL;\n\n\npublic class GeminiBigQueryFunction implements HttpFunction {\n    private static final Gson gson = new Gson();\n\n\n  public void service(final HttpRequest request, final HttpResponse response) throws Exception {\n    final BufferedWriter writer = response.getWriter();\n   // 요청 본문을 JSON 객체로 가져옵니다.\n    JsonObject requestJson = new Gson().fromJson(request.getReader(), JsonObject.class);\n    JsonArray calls_array = requestJson.getAsJsonArray(\"calls\");\n    JsonArray calls = (JsonArray) calls_array.get(0);\n    String baseline_url = calls.get(0).toString().replace(\"\\\"\", \"\");\n    String test_url = calls.get(1).toString().replace(\"\\\"\", \"\");\n    String prompt_string = calls.get(2).toString().replace(\"\\\"\", \"\");\n    String raw_result = validate(baseline_url, test_url, prompt_string);\n    raw_result = raw_result.replace(\"\\n\",\"\");\n    String trimmed = raw_result.trim();\n    List\u003cString\u003e result_list = Arrays.asList(trimmed);\n    Map\u003cString, List\u003cString\u003e\u003e stringMap = new LinkedHashMap\u003c\u003e();\n    stringMap.put(\"replies\", result_list);\n    // 직렬화\n    String return_value = gson.toJson(stringMap);\n    writer.write(return_value);\n  }\n\n\npublic String validate(String baseline_url, String test_url, String prompt_string) throws IOException{\n  String res = \"\";\n    try (VertexAI vertexAi = new VertexAI(\"YOUR_PROJECT\", \"us-central1\"); ) {\n      GenerationConfig generationConfig =\n          GenerationConfig.newBuilder()\n              .setMaxOutputTokens(2048)\n              .setTemperature(0.4F)\n              .setTopK(32)\n              .setTopP(1)\n              .build();\n    GenerativeModel model = new GenerativeModel(\"gemini-pro-vision\", generationConfig, vertexAi);\n    String context = prompt_string;\n    Content content = ContentMaker.fromMultiModalData(\n     context,\n     PartMaker.fromMimeTypeAndData(\"image/png\", readImageFile(baseline_url)),\n     PartMaker.fromMimeTypeAndData(\"image/png\", readImageFile(test_url))\n    );\n    GenerateContentResponse response = model.generateContent(content);\n     res = ResponseHandler.getText(response);\n  }catch(Exception e){\n    System.out.println(e);\n  }\n  return res;\n}\n\n\n  // 지정된 URL의 이미지 데이터를 읽어옵니다.\n  public static byte[] readImageFile(String url) throws IOException {\n    URL urlObj = new URL(url);\n    HttpURLConnection connection = (HttpURLConnection) urlObj.openConnection();\n    connection.setRequestMethod(\"GET\");\n    int responseCode = connection.getResponseCode();\n    if (responseCode == HttpURLConnection.HTTP_OK) {\n      InputStream inputStream = connection.getInputStream();\n      ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n      byte[] buffer = new byte[1024];\n      int bytesRead;\n      while ((bytesRead = inputStream.read(buffer)) != -1) {\n        outputStream.write(buffer, 0, bytesRead);\n      }\n      return outputStream.toByteArray();\n    } else {\n      throw new RuntimeException(\"Error fetching file: \" + responseCode);\n    }\n  }\n}\n```\n\n11. 이제 Cloud Shell 터미널로 이동하여 아래 명령을 실행하여 클라우드 함수를 빌드하고 배포하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngcloud functions deploy gemini-bq-fn --runtime java17 --trigger-http --entry-point cloudcode.helloworld.GeminiBigQueryFunction --allow-unauthenticated\n```\n\n여기에 결과는 아래와 같은 형식으로 REST URL이 생성됩니다:\n\nhttps://us-central1-YOUR_PROJECT_ID.cloudfunctions.net/gemini-bq-fn\n\n12. 터미널에서 다음 명령을 실행하여 이 클라우드 함수를 테스트해보세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngcloud functions call gemini-bq-fn --region=us-central1 --gen2 --data '{\"calls\":[[\"https://storage.googleapis.com/img_public_test/image_validator/baseline/1.JPG\", \"https://storage.googleapis.com/img_public_test/image_validator/test/2.JPG\", \"PROMPT_ABOUT_THE_IMAGES_TO_GEMINI\"]]}'\n```\n\n임의의 샘플 프롬프트에 대한 응답:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_12.png\" /\u003e\n\n제네릭 Cloud Function을 사용하여 Gemini Pro Vision 모델 구현이 준비되었습니다. 이제 이 엔드포인트를 직접 BigQuery 원격 함수 내에서 BigQuery 데이터에 사용하겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 빅쿼리 오브젝트 테이블 및 원격 함수 만들기\n\n이 데모 애플리케이션에서는 클라우드 스토리지 버킷을 생성해 보겠습니다:\n\n- 클라우드 스토리지 콘솔로 이동하여 생성 버튼을 클릭하여 버킷을 만듭니다.\n- 버킷에 이름을 제공하고 \"demo-bq-gemini-public\"과 같은 이름을 지정한 다음 \"이 버킷에서의 공개 액세스 방지 강화\" 옵션의 선택 해제(공개로 유지)를 기억하세요. 이 데모에서는 이 버킷을 공개 액세스로 설정하고 있지만, 권장하는 방법은 공개 액세스를 방지하고 필요에 따라 특정 서비스 계정에 권한을 부여하는 것입니다.\n- 방금 만든 클라우드 스토리지 버킷의 PERMISSION 탭에서 권한 설정을 보고 변경할 수 있습니다. 원칙을 추가하려면 VIEW BY PRINCIPALS 탭 아래의 GRANT ACCESS를 클릭하고 (특정 계정을 위한) 서비스 계정 ID를 입력하거나 \"allUsers\" (공개 액세스에 대한)를 입력한 후 역할을 \"Storage Object Viewer\"로 설정하고 저장을 클릭합니다.\n- 이제 버킷이 생성되었으므로 OBJECTS 탭으로 이동하여 이미지를 업로드하고 UPLOAD FILES를 클릭하여 업로드하세요.\n- 비교하기 위해 기준 및 테스트 이미지를 업로드하세요.\n\n이 데모를 위해 3개의 객체를 생성하고 기준이고 test1 및 test2를 공개로 사용할 수 있도록 만들었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# BigQuery 객체 테이블 생성\n\nBigQuery에서 외부 객체 테이블을 만들어 생성한 연결 및 데이터셋을 사용하여 버킷의 비구조화된 데이터에 액세스할 수 있습니다. BigQuery 쿼리 에디터 창에서 다음과 같은 DDL(데이터 정의 언어) 문을 실행하세요:\n\n```js\nCREATE OR REPLACE EXTERNAL TABLE `gemini_bq_fn.image_validation`\nWITH CONNECTION `us.gemini-bq-conn`\nOPTIONS(object_metadata=\"SIMPLE\", uris=[\"gs://demo-bq-gemini-public/*.JPG\"]);\n```\n\n이 쿼리는 이전에 만든 데이터셋에 \"image_validation\"이라는 새 객체 테이블을 생성해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# BigQuery 원격 함수 생성\n\nBigQuery에서 Java Cloud Function을 호출하는 원격 함수를 만들어 봅시다. Gemini Pro Vision 모델을 구현한 Java Cloud Function을 호출할 것입니다. 이 함수는 동일한 데이터셋에 만들 것입니다. BigQuery 콘솔의 SQL 편집 창에서 다음 DDL을 실행해 주세요:\n\n```js\nCREATE OR REPLACE FUNCTION `gemini_bq_fn.FN_IMAGE_VALIDATE` (baseline STRING, test STRING, prompt STRING) RETURNS STRING\n  REMOTE WITH CONNECTION `us.gemini-bq-conn`\n  OPTIONS (\n    endpoint = 'https://us-central1-********.cloudfunctions.net/gemini-bq-fn',\n    max_batching_rows = 1\n  );\n```\n\n이렇게 하면 BigQuery에 원격 함수가 생성됩니다. 위의 DDL에는 3개의 매개변수가 있습니다. 처음 두 매개변수는 이전 단계에서 생성된 객체 테이블에 저장된 이미지의 URL입니다. 마지막 매개변수는 모델(Gemini Pro Vision)에 대한 프롬프트입니다. 이 시그니처를 파싱하는 Java Cloud Functions 코드를 참조하시기 바랍니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nGson().fromJson(request.getReader(), JsonObject.class);\nJsonArray calls_array = requestJson.getAsJsonArray(\"calls\");\nJsonArray calls = (JsonArray) calls_array.get(0);\nString baseline_url = calls.get(0).toString().replace(\"\\\"\", \"\");\nString test_url = calls.get(1).toString().replace(\"\\\"\", \"\");\nString prompt_string = calls.get(2).toString();\n```\n\n# BigQuery에서 Gemini 호출하기!\n\n이제 원격 함수가 생성되었으니, 테스트 이미지를 프롬프트와 대조하여 이미지 유효성을 확인하는 원격 함수를 테스트하기 위해 SELECT 쿼리에서 사용해봅시다:\n\n테스트 이미지가 참조와 어떤지 확인하기 위한 쿼리:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nselect gemini_bq_fn.FN_IMAGE_VALIDATE(\n'https://storage.googleapis.com/demo-bq-gemini-public/Baseline.JPG',\nREPLACE(uri, 'gs://', 'https://storage.googleapis.com/') ,\n'전문 이미지 유효성 검사자이며 JSON 결과로 응답할 수 있는 이미지 유효성 검사자입니다. 여기에서 2개의 이미지를 찾을 수 있습니다. 첫 번째 이미지는 기준 이미지이고 두 번째 이미지는 테스트 이미지입니다. 두 번째 이미지가 첫 번째 이미지와 텍스트 측면에서 유사한지 확인하세요. \"YES\" 또는 \"NO\"인 SIMILARITY, 백분율인 SIMILARITY_SCORE, 문자열인 DIFFERENCE_COMMENT 3가지 속성이 포함된 JSON 형식으로만 응답하세요.' ) as IMAGE_VALIDATION_RESULT\nfrom `gemini_bq_fn.image_validation`\nwhere uri like '%TEST1%';\n```\n\n위 쿼리를 TEST1.JPG 및 TEST2.JPG와 함께 시도해보세요. 아래와 유사한 결과를 보게 될 것입니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_13.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기준 이미지:\n\n![이미지1](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_14.png)\n\n테스트 이미지:\n\n![이미지2](/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_15.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서 확인할 수 있듯이, 두 이미지 모두 Duet AI 클라우드 콘솔 뷰를 가지고 있지만, 두 이미지의 텍스트는 모델에 의해 생성된 JSON 형식에 따라 다릅니다.\n\n# 혜택 및 사용 사례\n\n- 데이터에 GenAI를 적용하세요: 데이터 이동, 중복 및 추가 복잡성이 더 이상 필요하지 않습니다. 동일한 BigQuery 환경 내에서 데이터를 분석하고 인사이트를 생성할 수 있습니다.\n- 향상된 분석: Gemini의 자연어 설명은 데이터에 새로운 이해의 층을 더해주며, SQL 쿼리만을 사용하여 이를 달성할 수 있습니다.\n- 확장성: 이 솔루션은 대규모 데이터셋과 복잡한 분석을 쉽고 Low-Code 방식으로 처리할 수 있습니다.\n\n실제 사례: 금융(시장 트렌드 분석), 소매(고객 감정), 의료(의료 보고서 요약) 등 분석 및 비즈니스 팀이 비교적 적은 노력, 자원 및 익숙한 언어 및 도구를 선택하여 이를 구현할 수 있는 시나리오를 고려해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n축하합니다. Gemini 모델이 BigQuery에 통합되어 데이터 분석을 넘어 데이터 이야기꾼이 되셨습니다. 데이터셋 안에 숨겨진 이야기를 찾아내고 통찰력을 이해하는 방법을 변화시킬 수 있습니다. 지금 실험을 시작하세요! 이 기술을 여러분의 데이터셋에 적용하여 데이터 안에 깔려있는 이야기들을 발견해보세요. BigQuery가 객체 테이블(External Tables)에서 비구조적인 데이터를 지원하므로, 이미지 데이터에 대한 생성적 인사이트를 만들기 위해 Gemini Pro Vision을 사용해보세요. 더 깊은 안내를 위해서 Vertex AI, BigQuery Remote Functions 및 Cloud Functions 문서를 참고하세요. 이 프로젝트의 Github 저장소는 여기에 있습니다. 이 학습으로 어떤 것을 구축하시는지 저에게 알려주세요!\n","ogImage":{"url":"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png"},"coverImage":"/assets/img/2024-05-18-In-PlaceLLMInsightsBigQueryGeminiforStructuredUnstructuredDataAnalytics_0.png","tag":["Tech"],"readingTime":25},{"title":"2024년 소프트웨어 개발자를 위한 내가 가장 좋아하는 SQL과 데이터베이스 강좌들","description":"","date":"2024-05-18 18:13","slug":"2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024","content":"\n## 소프트웨어 개발자가 SQL 및 데이터베이스 개념을 깊이 학습할 수 있는 최고의 온라인 강좌들입니다.\n\n![이미지](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png)\n\n안녕하세요 여러분, SQL과 데이터베이스를 배우고 최고의 Udemy 강좌를 찾고 있다면, 당신이 올바른 곳에 왔습니다.\n\n이전에는 SQL을 배울 수 있는 최적의 위치와 최고의 무료 SQL 강좌를 공유했었는데요, 그 안에는 Udemy나 Coursera 및 다른 웹사이트의 무료 강좌들이 포함되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 초보자와 중급 개발자를 위한 Udemy의 최고의 SQL 강좌를 소개할 것입니다.\n\nSQL은 오랜 시간 동안 중요한 기술 기술이었지만 데이터 과학 및 데이터 분석의 등장으로 인해 데이터의 중요성이 현재 세상에서 더욱 중요해졌습니다.\n\n요즘 회사들 사이에서 데이터 과학 및 분석 직업은 높은 수요가 있으며 사용자들의 대량 데이터 및 기타 정보를 활용하여 이 데이터에 대한 통찰을 얻고 회사의 성장을 위한 더 나은 결정을 내리는 데 중요한 역할을 합니다. 데이터와 관련된 모든 직업이 SQL 언어를 배우는 것을 필요로 한다는 공통점이 있습니다.\n\nSQL은 회사의 데이터를 저장하기 위한 데이터베이스를 구축하고 데이터베이스와 상호 작용하기 위해 SQL 쿼리라고 불리는 명령을 사용하여 정보를 추출하고 데이터 분석 목적을 위해 필요한 정보만 남기기 위해 필터링하는 사람들을 위한 가장 인기 있는 언어입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터베이스는 테이블의 모음이며, 각 테이블에는 데이터를 보유하는 행(row)과 열(column)이 포함되어 있습니다.\n\n이 언어를 배우는 것은 대부분의 다른 언어보다 쉽습니다. 심지어 Python보다도 쉽죠. SQL을 배우는 데 투자한 시간과 비용은 데이터 관련 분야의 취업을 원하는 학생들에게 좋은 투자입니다. 이는 당신을 경쟁자들보다 우위에 서게 할 겁니다.\n\n온라인에서 수천 개의 SQL 코스가 제공되지만, 당신의 시간과 노력을 가치 있게 만들어주는 코스를 찾는 것은 쉽지 않습니다. 이 글에서는 내 검색 결과에 따라 가장 좋은 코스를 제안하겠습니다.\n\n그런데, 만약 급한 대로 배우려 한다면, Udemy의 '15 Days of SQL: The Complete SQL Masterclass 2024' 코스를 참여하는 것을 제안합니다. 이 Udemy의 새 SQL 코스는 실생활 프로젝트에서 SQL을 딱 15일 만에 가르쳐줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_1.png\" /\u003e\n\n# 2024년 소프트웨어 개발자를 위한 최고의 SQL 및 데이터베이스 강좌 6선 - Udemy 및 Coursera 온라인 학습\n\n2024년에 온라인으로 배울 수 있는 최고의 Udemy 강좌 목록입니다. 이 강좌들은 SQL을 사용해 본 적은 있지만 깊이 있는 지식으로 습득하고 싶은 초보자 및 중급 개발자들을 위한 적합한 강좌입니다.\n\n## 1. The Complete SQL Bootcamp 2024: 처음부터 전문가까지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nJose Portilla가 만든 이 강좌에는 41만 명 이상의 수강생이 있습니다. 이 데이터베이스나 이 언어에 이전 경험이 없는 초보자를 위한 이 가이드로 SQL 언어 학습 여정을 시작하는 것을 적극 추천합니다.\n\n이 강좌를 통해 SELECT 및 COUNT와 같은 간단한 SQL 명령어를 데이터베이스에 적용하는 방법, 그리고 GROUP BY 문을 사용하는 방법을 배울 수 있습니다. 또한 이 강좌는 PostgreSQL을 기반으로 하며 PostgreSQL 데이터베이스를 사용합니다.\n\n그런 다음 JOIN 명령어를 사용하여 여러 테이블에서 데이터를 검색하는 방법을 배우고 특정 데이터를 추출하기 위한 일부 고급 SQL 명령어를 익힐 수 있습니다. 마지막으로 PostgreSQL 데이터베이스에서 데이터베이스 및 테이블을 생성하는 방법도 배울 수 있습니다.\n\n여기 이 강좌에 가입할 수 있는 링크가 있습니다 - The Complete SQL Bootcamp 2024: 제로부터 히어로까지 변화하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_2.png\" /\u003e\n\n## 2. The Ultimate MySQL Bootcamp [Udemy Course]\n\n또 한 번 소개할 만한 좋은 강의는 이 최고의 MySQL 부트캠프이다. 이 코스에는 20시간 이상의 비디오 콘텐츠와 26.4만 명의 학생이 참여하고 있다.\n\n먼저 MySQL 데이터베이스의 중요 개념과 해당 환경을 컴퓨터에 설치하는 방법을 이해할 수 있게 될 것이고, 이후 MySQL에서 데이터베이스와 테이블을 생성하는 방법으로 나아갈 것이다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러면 이 데이터베이스에 데이터를 삽입하는 방법과 기타 사항을 배울 것입니다.\n\nSQL 언어에서 CRUD 명령문에 대해 알게 될 것입니다: 생성(Create), 조회(Read), 갱신(Update), 삭제(Delete) 쿼리에 대해 배울 것입니다. 또한 집계 함수에 대해 배우고 논리 연산자의 힘을 탐색할 것입니다.\n\n마지막으로 Node.js와 MySQL 데이터베이스를 사용하여 작은 웹 앱을 만들 것입니다.\n\n이 코스에 참여하기 위한 링크는 여기에 있습니다 — The Ultimate MySQL Bootcamp\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_3.png)\n\n## 3. 데이터 분석 및 비즈니스 인텔리전스를 위한 MySQL\n\n만약 데이터 분석가가 되려고 한다면, 이 강의가 적합할 것입니다. SQL 언어뿐만 아니라 Tableau 소프트웨어와 결합하여 데이터 시각화를 쉽게 할 수 있습니다.\n\n우선 데이터베이스가 어떻게 작동하고 데이터를 저장하는지 이해하고, MySQL을 설치하고 SQL 명령어로 연습을 시작할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSQL의 기본 명령어인 SELECT, INSERT, UPDATE, DELETE 및 집계 함수와 몇 가지 고급 주제를 학습한 후, 마지막으로 Tableau 소프트웨어와 결합하여 데이터 시각화를 수행할 수 있습니다.\n\n이 강좌에 참여하려면 다음 링크를 클릭하세요 — MySQL for Data Analytics and Business Intelligence\n\n[링크](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_4.png)\n\n## 4. SQL 초보자를 위한강좌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 강좌에는 8시간 이상의 비디오 콘텐츠가 포함되어 있으며 MySQL 데이터베이스를 사용하여 시네마 예매 시스템을 만드는 실제 예제를 제공합니다.\n\nSQL 언어를 사용하기 전에 시스템에 MySQL 데이터베이스를 설치하고 주요 및 외래 키, 테이블과 같은 데이터베이스 개념을 이해할 수 있습니다.\n\n이 언어를 사용하여 테이블과 많은 테이블에서 데이터를 선택하고 간단한 SQL 명령을 사용하여 정보를 추출하는 방법을 배우게 됩니다. 데이터베이스 설계 및 데이터베이스 내에서 다양한 관계를 이해하고 시네마 예매 시스템과 같은 프로젝트를 개발합니다.\n\n이 강좌에 가입하려면 여기를 클릭하세요 - SQL for Beginners\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![마크다운](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_5.png)\n\n## 5. 초보를 위한 Microsoft SQL\n\n우리 목록에서 마지막으로 소개하는 이 코스는 마이크로소프트 SQL 서버에서 SQL 언어를 사용하는 방법을 가르쳐 줍니다. 이는 수백만 명의 사용자가 데이터베이스로 사용하고 있는 서비스를 사용하는 데 도움이 될 것입니다.\n\n먼저 간단한 SQL 명령어를 이해하고 적용한 다음, WHERE 절을 사용하여 데이터를 필터링하고 데이터를 정렬하며 여러 테이블에서 데이터를 추출하고 집계 함수를 사용하는 방법을 배울 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 수업에 참여하려면 다음 링크를 클릭해주세요 — Microsoft SQL for Beginners\n\n![Microsoft SQL for Beginners](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_6.png)\n\n## 6. 데이터 과학을 위한 SQL\n\nUdemy를 좋아하지 않거나 Coursera와 같은 인기 있는 학습 플랫폼에서 최고의 SQL 과정을 찾고 있다면, 이 수업을 확인해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 과학을 위한 SQL은 Coursera에서 가장 인기 있는 강좌 중 하나입니다.\n\nSQL의 기본을 마스터하여 데이터 과학자처럼 데이터를 분석할 수 있게 될 것입니다.\n\n이 강좌를 마친 후 여러 종류의 데이터, 문자열과 정수를 사용하고, 기본 및 복잡한 데이터 선택 쿼리를 수행할 수 있으며 SQL의 원리를 이해할 수 있게 될 것입니다.\n\nWomen in Data의 창립자/CEO이자 데이터 과학자인 Sadie St. Lawrence가 이 Coursera 강좌를 가르칩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 코스에 가입하려면 링크를 확인해보세요 — SQL For Data Science\n\n![이미지](/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_7.png)\n\n그리고, Coursera 코스가 유용하다고 생각되시나요? 전 세계적으로 유명한 기업과 대학에서 만들어졌기 때문에 그렇습니다. Coursera Plus에 가입하는 것을 추천드립니다. 이 구독 플랜은 Coursera의 가장 인기 있는 강좌, 전문 강의, 프로페셔널 인증, 그리고 가이드 프로젝트에 무제한 액세스를 제공해요. 매년 $399이나 월 단위로 $59이 들지만, 돈을 완전히 가치 있게 쓸 수 있을 거라고 생각해요. 왜냐하면 무제한 인증서를 받을 수 있기 때문이거든.\n\n2024년에 SQL과 데이터베이스를 배우기 위한 최고의 Udemy와 Coursera 온라인 강좌는 여기까지에요. 이 목록에는 SQL 기본 사항과 데이터베이스 기초를 배울 수 있는 수업들, 그리고 MySQL, PostgreSQL, 그리고 Microsoft SQL Server와 같은 인기 데이터베이스를 배울 수 있는 온라인 강좌가 포함되어 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 SQL을 배우는 데 적합한 데이터베이스로 수업을 듣는다는 것을 의미합니다. 이것은 초보자들의 관점에서 매우 중요합니다.\n\nSQL 언어를 배우는 것은 데이터 과학자나 데이터 분석가와 같은 데이터와 관련된 모든 직업의 중요한 부분입니다.\n\n웹 개발자라도 데이터베이스를 사용하여 이 언어를 배우고 프로페셔널하게 사용해야 합니다. 왜냐하면 이것이 당신의 경쟁자들에게 이점을 줄 것이기 때문입니다.\n\n만약 이러한 강좌들을 좋아하지 않고 연습이 가득한 부트캠프 스타일의 강좌를 찾고 있다면 Andrei Negaoie의 Complete SQL and Databases Bootcamp 강좌가 시작하기에 좋은 강좌입니다. 이 강좌는 주요 SQL 개념을 가르치기 위한 연습과 SQL 쿼리가 가득합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고, 2024년에 SQL을 배우는 가장 좋은 방법을 보여주는 ByteByteGo의 멋진 비디오가 여기 있어요!\n\n탐색해볼 수 있는 다른 SQL 및 개발 코스\n\n- JavaScript를 배우기 위한 10가지 최고의 Udemy 코스\n- Python을 배우기 위한 10가지 최고의 Udemy 코스\n- 2024년을 위한 10가지 최고의 Udemy 코스\n- 풀 스택 웹 개발자로 성장하기 위한 10가지 코스\n- 2024년에 TypeScript를 무료로 배울 수 있는 10가지 코스\n- 초보자를 위한 Angular를 배우기 위한 나의 좋아하는 코스\n- 무료로 Ruby 및 Rails를 배울 수 있는 5가지 코스\n- 2024년 React JS 개발자 로드맵\n- 웹 개발자를 위한 PHP 및 MySQL 학습을 위한 5가지 수업\n- 무료로 블록체인 기술을 배울 수 있는 5가지 코스\n- Oracle 및 Microsoft SQL Server 데이터베이스를 배울 수 있는 5가지 코스\n- 초보자를 위한 10가지 Python 웹 개발 코스\n- 풀 스택 개발자 로드맵\n- Servlet, JSP 및 JDBC를 배울 수 있는 무료 강좌 5개\n- Java 및 DevOps 엔지니어를 위한 Docker 무료 코스 5가지\n- 2024년에 JavaScript를 배울 수 있는 13가지 무료 코스\n- Java에서 RESTful 웹 서비스를 배우기 위한 3권의 책 및 강좌\n- 2024년에 Angular를 배울 수 있는 5가지 무료 코스\n- 풀스택 개발자가 배워야 할 10가지 프레임워크\n\n지금까지 이 기사를 읽어주셔서 감사합니다. 만약 SQL을 배우기 위한 이 최고의 Udemy 코스들이 마음에 든다면, 친구들과 동료들과 공유해주세요. 이 목록에는 Udemy의 최고의 MySQL, PostgreSQL 및 Microsoft SQL Server 코스가 포함되어 있습니다. 질문이나 피드백이 있으시면, 댓글을 남겨주세요.\n\n참고: 만약 SQL 및 데이터베이스에 새로 입문한 분이라면, 여행을 시작할 무료 SQL 코스를 찾고 계시다면, 초보자를 위한 무료 SQL 및 데이터베이스 코스도 확인해보세요. 이 코스들은 Udemy 및 Coursera에서 법적으로 무료로 제공되며 SQL 개념, 데이터베이스 기본 개념, SQL 쿼리 작성 방법 등을 배울 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png"},"coverImage":"/assets/img/2024-05-18-MyFavoriteSQLandDatabaseCoursesforSoftwareDevelopersin2024_0.png","tag":["Tech"],"readingTime":11},{"title":"ML, 데이터 팀을 위한 Gen AI","description":"","date":"2024-05-18 18:10","slug":"2024-05-18-MLGenAIfordatateams","content":"\n## 고전적인 ML 사용 사례와 Gen AI를 위한 신뢰성 있는 설계 구축\n\nAI와 ML은 대부분의 데이터 팀에게 중요한 주제입니다. 회사들은 AI로 실질적인 영향을 얻고 있으며, 데이터 팀은 이 중심에 있어 자신의 작업을 ROI에 결부시키는 원하는 방법을 얻고 있습니다.\n\n최근 예로, AI가 스웨덴의 '지금 살고 나중에 지불' 핀테크 Klarna를 위해 700명의 정근 연애를 자동화하는 데 도움을 주었습니다. Intercom은 이제 AI 중심의 고객 서비스 플랫폼이 되었으며, 임원들은 Gen AI 사용 사례를 구현하는 데 직접적으로 연관된 OKR을 가지고 있습니다.\n\n이 게시물에서는 데이터 팀에서 일하는 경우 이것이 무슨 의미를 하는지 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데이터 팀에서의 AI 현황\n\nAI는 많이 발전했습니다. 실제로 그렇습니다. 스탠포드 대학의 2024 AI 지수 보고서에 따르면 AI는 이미지 분류, 시각적 추론, 그리고 영어 이해와 같은 여러 벤치마크에서 인간의 성능을 넘어섰다고 합니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요즘에는 ML 및 AI에 대한 수요가 급증하여 많은 데이터 팀이 업무 우선 순위를 재조정하게 되었습니다. 이는 ML 및 AI에서 데이터 팀의 역할에 대한 질문을 답하지 못한 채 남아 있습니다. 저희 경험상 데이터가 소유한 부분과 엔지니어가 소유한 부분 사이의 경계가 여전히 모호한 상황입니다.\n\ndbt가 최근 수천 명의 데이터 실무자를 대상으로 조사한 결과, 데이터 팀이 AI 및 ML에 참여하는 정도에 대한 정보를 얻을 수 있었습니다.\n\nAI 도입의 신호는 있지만, 대부분의 데이터 팀은 아직 일상적인 업무에 AI를 사용하고 있지 않습니다. 현재 응답자 중 1/3만이 오늘날 AI 모델 훈련을 위한 데이터를 관리하고 있습니다.\n\n![그림](/assets/img/2024-05-18-MLGenAIfordatateams_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 곧 변경될 수 있습니다. 55%의 사람들이 곧 AI가 자가 데이터 탐색을 위해 혜택을 누리기를 기대하고 있습니다.\n\n![AI 및 ML use cases](/assets/img/2024-05-18-MLGenAIfordatateams_2.png)\n\n이는 우리가 1,000개 이상의 데이터 팀과 대화한 경험을 반영한 것입니다. 현재의 노력은 주로 데이터 분석을 위한 데이터 준비, 대시보드 유지 및 이해관계자 지원에 집중되어 있지만, AI 및 ML에 투자하고자 하는 욕망이 있습니다.\n\n# AI 및 ML 사용 사례\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nML과 AI가 수십 년 동안 존재해왔다는 것을 알아야 합니다. 최신 AI 모델인 Gen AI 모델은 텍스트에서 SQL 코드를 생성하거나 비즈니스 질문에 자동으로 답변하는 것과 같은 첨단 사용 사례에 가장 적합할 수 있지만, 분류 및 회귀 모델과 같은 더 검증된 방법들도 중요한 목적을 가지고 있습니다.\n\n가장 인기 있는 기술들 중 일부는 다음과 같습니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_3.png)\n\n# 고전적인 머신 러닝 사용 사례\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n대부분의 팀은 아직 전통적인 머신러닝 방법을 사용하지 않고 있습니다. 예를 들어, 분류, 회귀, 이상 감지와 같은 방법들이 있습니다. 이러한 방법들은 특히, 당신이 예측하고자 하는 명확한 결과 (예: 위험한 고객)와 예측 기능 (예: 가입 국가, 나이, 이전 사기)이 명확한 감독 학습에 유용할 수 있습니다.\n\n이러한 시스템들은 종종 설명하기 쉽고, 각 기능의 상대적 중요성을 추출할 수 있어 이를 통해 이유를 설명하기 쉽습니다. 이로써 이해관계자에게 고위험 고객을 거부하는 결정이 내려진 이유를 설명할 수 있게 됩니다.\n\n아래의 머신러닝 시스템은 고객 위험 점수 모델을 강조하며, 새로 가입한 사용자가 고위험 고객인지 거부해야 할 가능성이 얼마나 높은지를 예측합니다.\n\n![image](/assets/img/2024-05-18-MLGenAIfordatateams_4.png)\n\n다양한 소스에서 수집된 원시 데이터를 활용하여 예측 기능을 구축하며, 이는 데이터 과학자의 전문 지식과 모델이 식별한 예상치 못한 패턴을 결합합니다. 핵심 개념은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Sources 및 데이터 마트: 시스템에서 추출된 원시 및 가공되지 않은 데이터로 데이터 과학자가 관련성이 있는 것으로 판단한 것\n- 특성: ML 모델에 공급되는 전처리된 데이터 (예: 대도시의 거리, 나이, 이전 사기)\n- 레이블: 이전 위험한 고객을 기반으로 한 목표 출력 (예/아니오)\n- 트레이닝: 기계 학습 모델에 내부 매개변수나 가중치를 레이블된 예시에 기반하여 조정하여 정확한 예측을 수행할 수 있도록 가르치는 반복적인 프로세스\n- 추론: 트레이닝 단계 이후 새로운, 보이지 않은 데이터에 대해 예측이나 분류를 수행하기 위해 훈련된 기계 학습 모델을 사용하는 것\n\n데이터 팀과의 협업을 통해, 전통적인 ML 작업 흐름의 많은 부분이 데이터 웨어하우스로 이동되어 데이터 소스 및 피처 저장소의 기반이 되는 것을 볼 수 있습니다. 주요 데이터 웨어하우스는 이를 직접 제공하도록 시작했으며(예: BigQuery ML), 미래에는 전체적인 ML 작업 흐름이 데이터 웨어하우스로 완전히 이동할 것을 시사합니다.\n\n전통적인 ML 모델의 성공을 위한 일반적인 도전 과제는 다음과 같습니다:\n\n- 이용 가능한 데이터를 바탕으로 모델이 원하는 결과를 정확하고 적합한 수준으로 예측할 수 있는가\n- 달성된 정확도와 적합도 수준이 비즈니스에 대한 ROI로 충분한가\n- 이 작업을 수행하기 위해 우리가 해야 하는 트레이드 오프는 무엇인가(예: 위험한 고객을 검토하기 위해 더 많은 운영 직원)\n- 모델 유지 및 모니터링에 대한 유지와 모니터링의 비용은 얼마인가\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 차세대 및 Gen AI 사용 사례\n\n최근 몇 년간 차세대 및 특히 Gen AI 사용 사례에 대한 이야기가 소개되었으며 ChatGPT 3의 효율성으로 유명해졌습니다. 이 분야는 새로운 것이며 비즈니스 ROI가 아직 증명되지 않았지만 잠재력은 매우 큽니다.\n\n아래는 데이터 팀을 위해 본 Gen AI 사용 사례 중에서 가장 인기 있는 몇 가지입니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n오늘의 사용 사례는 크게 두 가지 영역으로 그룹화될 수 있어요.\n\n- 비즈니스 가치 향상 — 고객 지원 챗봇에서 간단한 고객 상호 작용을 자동화하거나 고객 답변을 관련 지식 베이스 기사와 매칭하는 등 비즈니스 프로세스를 자동화하거나 최적화합니다.\n- 데이터 팀 생산성 향상 — 근본적인 데이터 워크플로우를 단순화하여 기술에 능통하지 않은 분석가가 ‘텍스트를 SQL로’ 쓸 수 있도록 하거나 비즈니스 이해자가 제시한 자연어 질문에서 답변을 생성함으로써 비즈니스 이해자의 즉각적인 요청을 줄입니다.\n\n아래는 비즈니스에 관련된 특정 데이터 말뭉치를 기반으로 ChatGPT의 사용자 버전을 설정하는 샘플 아키텍처입니다. 시스템은 두 부분으로 구성됩니다: (1) 도메인 데이터의 데이터 적재 및 (2) 실시간으로 질문에 답변할 수 있도록 데이터를 쿼리합니다.\n\n![image](/assets/img/2024-05-18-MLGenAIfordatateams_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예제 정보 검색 시스템 (출처: Langchain)\n\n첫 번째 단계는 문서를 벡터 저장소에 로드하는 것입니다. 이 과정에는 서로 다른 소스에서 데이터를 결합하거나 엔지니어들과 함께 생 데이터를 다루는 것, 그리고 모델이 교육받지 않아도 되는 데이터를 수동으로 제거하는 것(예: 고객 만족도 낮은 지원 응답)이 포함될 수 있습니다.\n\n- 특정 텍스트 말뭉치에서 텍스트로 데이터 소스 로드\n- 전처리하고 텍스트를 작은 조각으로 나누기\n- 단어들의 유사성에 따라 단어의 벡터 공간을 만들기 위해 임베딩 만들기\n- 임베딩을 벡터 저장소에 로드하기\n\n임베딩에 익숙하지 않다면, 단어나 문서의 숫자적 표현이고 이들 사이에 존재하는 의미와 관계를 포착하는 것이다. 아래 코드 스니펫을 실행하면 실제로 무엇인지 볼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nfrom gensim.models import Word2Vec\n# 문장 말뭉치 정의\ncorpus = [\n    \"the cat sat on the mat\",\n    \"the dog barked loudly\",\n    \"the sun is shining brightly\"\n]\n# 문장 토큰화\ntokenized_corpus = [sentence.split() for sentence in corpus]\n# Word2Vec 모델 학습\nmodel = Word2Vec(sentences=tokenized_corpus, vector_size=3, window=5, min_count=1, sg=0)\n# 단어 임베딩 획득\nword_embeddings = {word: model.wv[word].tolist() for word in model.wv.index_to_key}\n# 단어 임베딩 출력\nfor word, embedding in word_embeddings.items():\n    print(f\"{word}: {embedding}\")\n```\n\n도메인 데이터를 벡터 저장소에 입력한 후, 사전에 학습된 LLM을 세밀하게 조정하여 도메인과 관련된 질문에 답변하는 시스템을 확장할 수 있습니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_7.png)\n\n예시 정보 검색 시스템 (출처: Langchain)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사용자는 채팅과 새로운 질문을 결합하여 후속 질문을 할 수 있습니다.\n위의 임베딩 및 벡터 저장소를 사용하여 유사 문서를 찾을 수 있습니다.\n큰 언어 모델(ChatGPT와 같은)을 사용하여 유사 문서를 활용하여 응답을 생성할 수 있습니다.\n\n다행히도 Meta와 Databricks와 같은 기업들이 교육 및 오픈소스 모델을 제공하고 있으므로 (Huggingface는 현재 1000여 개 이상의 Llama 3 오픈소스 모델을 보유하고 있습니다) 자체 모델을 교육시키기 위해 수백만 달러를 소비할 필요가 없습니다. 대신 기존 모델을 데이터로 세밀하게 조정하세요.\n\n위와 같은 LLM(Large Language Model) 기반 시스템의 효과는 그들에게 주어지는 데이터의 품질에 달려 있습니다. 따라서 데이터 전문가들은 여러 소스에서 가져온 가능한 많은 데이터를 피드하는 것이 장려되며, 이들 소스가 어디에서 오는지 추적하고 데이터가 예상대로 흐르는지 확인하는 것이 최우선 과제여야 합니다.\n\nGen AI 모델의 성공을 위한 전형적인 도전 과제는:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 모델을 충분히 훈련할 만한 데이터가 있나요? 개인정보 문제로 사용이 제한되는 데이터가 있나요?\n- 모델이 해석 가능하고 설명 가능해야 하는가요? 예를 들어 고객이나 규제기관을 위해\n- LLM을 훈련하고 세부 조정하는 것에 대한 잠재적 비용은 무엇인가요? 그 혜택이 이 비용을 상회하나요?\n\n# AI와 ML에서 데이터 품질의 중요성\n\n당신의 주요 데이터 전달은 의사 결정에 도움을 주는 BI 대시보드를 위해 무작위 통찰을 제공할 때, 인간이 개입합니다. 인간의 직관과 기대로 인해 데이터 문제나 설명할 수 없는 추세가 종종 발견됩니다 — 그리고 아마도 몇 일 안에 해결됩니다.\n\nML과 AI 시스템은 다릅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nML 시스템이 수백 개 또는 수천 개의 다양한 소스에서 가져온 기능에 의존하는 것은 흔한 일입니다. 간단한 데이터 문제처럼 보일 수 있는 것들 — 누락된 데이터, 중복, 널 값 또는 빈 값, 이상치 — 이들은 비즈니스에 중대한 문제를 일으킬 수 있습니다. 이를 세 가지 다른 방법으로 생각해 볼 수 있습니다.\n\n- 비즈니스 중단 — 모든 사용자 ID가 비어 있는 중대한 오류는 새 사용자 가입 승인 비율이 90% 감소할 수 있습니다. 이러한 유형의 문제는 비용이 많이 들지만 종종 초기에 발견됩니다.\n- 드리프트 또는 '잠재적' 문제 — 이는 고객 분포의 변경이나 특정 세그먼트에 대한 누락된 값을 포함할 수 있으며, 이로 인해 체계적으로 부정확한 예측이 발생할 수 있습니다. 이러한 문제는 발견하기 어려우며, 몇 달 또는 몇 년 동안 지속될 수 있습니다.\n- 체계적인 편향 — Gen AI와 같은 경우, 데이터 수집에 대한 인간의 판단이나 결정으로 편향이 발생할 수 있습니다. 구글의 Gemini 모델에서 발생한 편견과 같이 최근 예들은 이러한 결과가 가져다 줄 수 있는 결과를 강조했습니다.\n\n회귀 모델을 지원하거나 LLM을 위한 새로운 텍스트 말뭉치를 작성 중이더라도, 새로운 모델을 개발하는 연구자가 아닌 한, 업무의 대부분은 데이터 수집 및 전처리에 관련될 것입니다.\n\n![이미지](/assets/img/2024-05-18-MLGenAIfordatateams_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nML 시스템은 모델이 하나의 부분에 불과한 대규모 생태계입니다. — Google on Production ML Systems\n\n일반적으로, 화면 왼쪽에 위치할수록 오류를 모니터링하기 어려울 수 있습니다. 수백 개의 입력 및 원시 소스가 있어서 때로는 데이터 관련 전문가의 통제 영역을 벗어날 수 있으며, 데이터는 수천 가지 방법으로 잘못될 수 있습니다.\n\n![MLGenAIfordatateams_9](/assets/img/2024-05-18-MLGenAIfordatateams_9.png)\n\n모델 성능은 ROC, AUC 및 F1 점수와 같이 잘 알려진 메트릭을 사용하여 간단히 모니터링할 수 있으며, 이러한 메트릭은 모델 성능의 단일 측정 항목을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상류 데이터 품질 문제의 예시\n\n- 결측 데이터: 데이터셋의 불완전하거나 없는 값은 모델이 일반화하고 정확한 예측을 하는 능력에 영향을 미칠 수 있습니다.\n- 일관성 없는 데이터: 서로 다른 소스 또는 시간에 따라 다양한 형식, 단위 또는 표현으로 인한 데이터 변이는 모델 학습 및 추론 중 혼동과 오류를 유발할 수 있습니다.\n- 이상치: 대부분의 관측치와 유별난 점이 큰 데이터의 이상치 또는 특이치는 모델 학습에 영향을 주고 편향적이거나 부정확한 예측을 유발할 수 있습니다.\n- 중복 레코드: 데이터셋에 중복된 항목이 들어 있는 경우 모델의 학습 과정을 왜곡시킬 수 있으며, 모델이 훈련 데이터에서 성능이 우수하지만 새로운, 보지 못한 데이터에서는 성능이 저하될 수 있습니다.\n\n데이터 이동의 예시\n\n- 계절별 제품 선호도: 계절에 따른 고객 선호도의 변화가 전자 상거래 추천에 영향을 미칩니다.\n- 금융 시장 변동: 경제적 사건으로 인한 시장의 급격한 변동이 주식 가격 예측 모델에 영향을 미치는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLLM에 대한 텍스트 데이터의 데이터 품질 문제 예시\n\n- 품질이 낮은 입력 데이터: 챗봇은 정확한 과거 사례 해결을 기반으로 작동합니다. 이 데이터의 정확성에 따라 봇의 효과가 결정되며, 잘못된 정보를 배우는 것을 피해야 합니다. 고객 만족도나 해결 점수가 낮은 답변은 모델이 잘못된 정보를 학습했을 수 있다는 신호일 수 있습니다.\n- 오래된 데이터: 의료 상담 봇은 오래된 정보에 의존할 수 있어서 관련성이 적은 권장 사항을 제공할 수 있습니다. 특정 일자 이전에 작성된 연구는 더 이상 목적에 부합하지 않을 수 있음을 나타낼 수 있습니다.\n\n# 신뢰할 수 있는 머신 러닝 및 인공지능 시스템 구축\n\n우리는 데이터 팀이 소프트웨어 엔지니어링과 비교했을 때 신뢰할 수 있는 데이터 시스템을 제공하는 데 신뢰받지 못한다고 믿습니다. 인공지능 파동은 \"쓰레기를 넣으면 쓰레기가 나온다\" 모델과 그 모든 함의를 기하급수적으로 확장하고 있습니다. 모든 기업이 경쟁 우위를 위한 데이터를 활성화하는 새로운 방법을 찾는 압박 속에 있을 때입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n특정 도구와 시스템이 모델 성능을 모니터링하기 위해 사용되지만, 이러한 도구들은 종종 데이터 웨어하우스의 상위 소스와 데이터 변환을 고려하지 않습니다. 데이터 신뢰성 플랫폼은 이를 위해 구축되었습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-MLGenAIfordatateams_10.png\" /\u003e\n\n# 안정적인 ML 및 AI 시스템 구축을 위한 다섯 가지 요추\n\n고품질의 제품용 ML 및 AI 시스템을 지원하고 유지하기 위해 데이터 팀은 엔지니어들의 최상의 실천 방법을 채택해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![img](/assets/img/2024-05-18-MLGenAIfordatateams_11.png)\n\n- 성실한 테스트 — ML 및 AI 시스템에 공급되는 상위 소스 및 출력이 의도적으로 테스트되어야 함 (이상값, 널 값, 분포 변화, 품질)\n- 소유자 관리 — ML 및 AI 시스템은 명확한 소유자가 할당되어 문제를 통지받고 조치를 취하기를 기대해야 함\n- 사건 처리 — 심각한 문제는 명확한 SLA 및 에스컬레이션 경로를 가진 사건으로 취급되어야 함\n- 데이터 제품 마인드셋 — ML 및 AI 시스템으로 공급되는 전체 가치 사슬을 하나의 제품으로 고려해야 함\n- 데이터 품질 메트릭스 — 데이터 팀은 ML 및 AI 시스템의 가동 시간, 오류, SLA 등 핵심 메트릭을 보고할 수 있어야 함\n\n한 축에만 집중하는 것은 드물게 충분하지 않습니다. 명확한 소유권이 없는 채로 테스트에 과도하게 투자하면 문제가 슬립할 수 있습니다. 소유에 투자하지만 의도적으로 사건을 관리하지 않으면 심각한 문제가 너무 오랫동안 해결되지 않을 수 있습니다.\n\n![img](/assets/img/2024-05-18-MLGenAIfordatateams_12.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중요한 점은 다섯 가지 데이터 신뢰성 기둥을 구현하는 데 성공한다고 해도 문제가 발생하지 않는다는 것이 아니라, 단지 미리 발견할 가능성이 더 높아지고 자신감을 키워 고객에게 시간이 지남에 따라 어떻게 개선되고 있는지 전달할 수 있다는 것입니다.\n\n# 요약\n\n현재 데이터 팀 중 33%만이 AI 및 ML 모델을 지원하지만 대부분은 가까운 미래에 지원할 것으로 예상합니다. 이러한 변화는 데이터 팀이 비즈니스 중요 시스템을 지원하고 소프트웨어 엔지니어처럼 더 많이 일해야 한다는 새로운 세계에 적응해야 한다는 것을 의미합니다.\n\n- 데이터 팀에서의 AI 상황 - AI 시스템은 이미지 분류, 시각적 추론 및 영어 이해와 같은 여러 기준에서 성능이 향상되고 있습니다. 현재 데이터 팀 중 33%가 생산 중인 AI 및 ML을 사용하지만 55%의 팀이 예상됩니다.\n- AI 사용 사례 - 분류 및 회귀에서 Gen AI까지 다양한 ML 및 AI 사용 사례가 있습니다. 각 시스템은 도전적인 과제를 제기하지만 \"고전적인 ML\"과 Gen AI 간의 차이는 명백합니다. 우리는 이를 고전적인 고객 위험 예측 모델과 정보 검색 챗봇을 통해 살펴봤습니다.\n- AI 및 ML 시스템의 데이터 품질 - 데이터 품질은 ML 및 AI 프로젝트의 성공에 가장 중요한 위험 중 하나입니다. AI 및 ML 모델이 종종 수백 개의 데이터 소스에 의존하는데, 문제를 수동으로 감지하는 것은 거의 불가능합니다.\n- 믿을 수 있는 데이터를 위한 다섯 가지 단계 - ML 및 AI 시스템을 지원하고 유지하기 위해 데이터 팀은 엔지니어처럼 더 많이 일해야 합니다. 이에는 지속적인 테스트, 명확한 소유권, 사건 관리 프로세스, 데이터 제품 마인드셋 및 가동 시간 및 SLA와 같은 지표에 대한 보고 능력이 포함됩니다.\n","ogImage":{"url":"/assets/img/2024-05-18-MLGenAIfordatateams_0.png"},"coverImage":"/assets/img/2024-05-18-MLGenAIfordatateams_0.png","tag":["Tech"],"readingTime":15},{"title":"데이터 웨어하우징을 위한 5가지 사이버보안 팁","description":"","date":"2024-05-18 18:08","slug":"2024-05-18-5CybersecurityTipsforDataWarehousing","content":"\n\u003cimg src=\"/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png\" /\u003e\n\n데이터 웨어하우징은 대규모 AI 및 기계 학습 애플리케이션을 훨씬 더 관리하기 쉽게 만듭니다. 모든 것을 한 곳에 가지고 있으면 더 빠르고 정확한 분석이 가능해지지만, 동시에 일부 보안 문제를 야기할 수도 있습니다. 이러한 대규모로 통합된 데이터베이스는 사이버 범죄자들에게 유혹이 되는 대상이므로 면밀한 보호가 필요합니다.\n\n조직 간에도 데이터 웨어하우스 자체가 다양하듯이 특정 보안 시스템도 다양합니다. 그럼에도 불구하고 설정과는 상관없이 몇 가지 모범 사례를 도입해야 합니다. 고려해야 할 다섯 가지 주요 사이버 보안 팁을 소개합니다.\n\n# 1. 데이터 익명화 및 암호화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 창고에서 모든 데이터를 암호화하는 것이 첫 번째 단계입니다. 데이터에 높은 암호화 표준을 적용하면, 해커들이 액세스하더라도 그것이 쓸모없게 만들어질 것입니다. 홀모모르픽 암호화와 같은 새로운 기술은 당신이 데이터를 복호화하기 전에도 암호화된 데이터를 사용할 수 있도록 한 단계 더 나아간 것입니다.\n\n사용하는 데이터 유형에 따라 데이터를 익명화해야 할 수도 있습니다. 이는 개인 식별자를 제거하여 개인 정보 침해를 방지하는 프로세스입니다. 실제 세계의 수치를 합성 데이터로 교체하는 것이 가장 안전한 방법이지만, 데이터가 실제 세계 사람들을 반영해야 하는 경우 역동적 익명화가 좋은 대안입니다.\n\n## 2. 액세스 권한 제한\n\n데이터 창고 사이버 보안의 다음 단계는 사용자의 액세스 권한을 제한하는 것입니다. 이 작업에 접근하는 가장 좋은 방법은 최소 권한 원칙(Least Privilege Principle, PoLP)을 따르는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPoLP(Principle of Least Privilege)는 작업을 올바르게 수행하기 위해 필요한 것만 액세스할 수 있어야 한다고 주장합니다. 기계 학습 모델과 작업하지 않는 직원은 기계 학습 훈련을 위해 구체적으로 데이터 웨어하우스에 액세스할 수 없어야 합니다. 마찬가지로, 데이터 과학자는 급여 데이터를 볼 수 없어야 합니다.\n\n액세스 권한 제한은 두 가지 주요 이점이 있습니다. 첫째, 주어진 데이터 웨어하우스에 영향을 미칠 수 있는 사람 수를 줄임으로써 발생하는 74%의 데이터 침해와 관련된 인적 오류를 최소화합니다. 둘째, 공격자가 한 계정을 침해하면 측면 이동을 최소화합니다.\n\n# 3. 인증 조치 향상\n\n권한 제한은 신뢰할 수 있는 방법으로 누가 누구인지 판별할 수 있을 때에만 효과가 있음을 기억하세요. 따라서, PoLP를 강력한 인증 조치와 함께 실행해야 합니다. 가장 기본적인 수준에서는 다중 요소 인증(MFA)이 시행되어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMFA는 여러 방법으로 실행할 수 있지만, 모든 방법이 동일한 수준의 보안을 제공하는 것은 아닙니다. 예를 들어 SMS 기반 인증은 이메일 인증보다 더 안전합니다. 특정 장치에 액세스가 필요하기 때문입니다. 생체 인증은 암호보다 해킹이 더 어려울 수 있지만, 공격자가 생체 데이터에 액세스하면 변경할 수 없으므로, 민감한 창고에는 이상적이지 않을 수 있습니다.\n\n# 4. 데이터 분류 및 조직화\n\n데이터 웨어하우징 보안에서 놓치기 쉬운 하지만 여전히 중요한 단계는 데이터를 분류하는 것입니다. 조직화는 사이버 보안 문제보다는 작업 문제처럼 보일 수 있지만, 중요한 보안적 영향을 많이 미칩니다.\n\n먼저, 볼 수 없는 것은 안전으로 보호할 수 없습니다. 보안 소프트웨어 사용자의 약 60%가 데이터의 40% 미만만 분석한다고 합니다. 이는 중요한 취약점을 놓칠 수 있거나 침해를 인식하지 못할 수 있음을 의미합니다. 조직의 부재는 시각성을 제한하기 때문에 데이터를 분류하여 그룹으로 구성하여 보다 철저한 취약점 분석과 빠른 사고 대응을 가능하게 해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n분류는 엑세스 권한을 정제하는 데도 도움이 됩니다. 데이터를 사용 또는 민감도에 따라 정렬하면 누가 액세스할 수 있는지 결정하고 해당 정책을 시행하는 데 도움이 됩니다. 또한 행동 생체 인식을 구현할 수 있어 이로 인해 평상시에는 액세스할 수 없는 데이터에 접근하는 경우 경고를 받을 수 있습니다.\n\n# 5. 창고를 면밀히 모니터링하십시오\n\n이러한 변경 사항을 시행한 후 데이터 창고를 지속적으로 모니터링해야 합니다. 어떤 방어 기법도 100% 효과적일 수는 없지만, 신속한 대응은 침해 사건 발생 시 피해를 최소화할 것입니다. 새로운 위협에 대응하거나 실시간 보안 사건에 대응할 수 있는 유일한 방법은 지속적인 모니터링을 통해 가능합니다.\n\n인공지능과 자동화는 여기서 꼭 필요합니다. 24시간 수동 모니터링은 많은 보안 인력이 필요합니다. 대부분의 기관에게는 선택사항이 아닙니다. 세계적으로 노동력 수요가 증가하더라도 사이버 보안 직원은 340만 명이 부족합니다. 자동화된 네트워크 모니터링은 실시간 사건 제한 및 부족한 보안 직원을 보완하기 위한 경고를 제공할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 데이터 웨어하우징 보안에 대한 주의가 필요합니다\n\n데이터 웨어하우스는 한 대의 큰 데이터베이스를 보호하는 것이 여러 개의 자원에 분산하는 것보다 쉽기 때문에 보안이 개선됩니다. 그러나 동시에, 그 크기 때문에 눈에 띄는 관심을 끄는 경우가 있습니다, 특히 민감한 정보를 저장하는 경우에는 더욱 그렇습니다.\n\n이러한 위험 요소들을 고려하여 데이터 웨어하우징 사이버 보안은 필수적입니다. 기존의 보안 시스템에 다음 다섯 가지 모범 사례를 통합하여 데이터 웨어하우스를 가능한 한 안전하게 유지하십시오.\n\n최초 게시물: OpenDataScience.com\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nOpenDataScience.com에서 데이터 과학 관련 기사를 더 읽어보세요. 초보자부터 고급 수준까지의 튜토리얼과 안내서를 만나보실 수 있습니다! 매주 목요일마다 최신 소식을 받아보고 싶으시다면 여기를 클릭하여 주간 뉴스레터를 구독해보세요. 또한 Ai+ 트레이닝 플랫폼을 통해 언제 어디서든 데이터 과학을 학습할 수 있습니다. ODSC 이벤트에 참석하고 싶으신가요? 다가오는 이벤트에 대해 더 알아보고 싶으시다면 여기를 클릭해주세요.\n","ogImage":{"url":"/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png"},"coverImage":"/assets/img/2024-05-18-5CybersecurityTipsforDataWarehousing_0.png","tag":["Tech"],"readingTime":5},{"title":"Delta 테이블을 REST API를 통해 노출하는 방법","description":"","date":"2024-05-18 18:06","slug":"2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs","content":"\n## 델타 테이블을 제공하기 위해 토론 및 테스트된 세 가지 아키텍처\n\n![이미지](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png)\n\n# 1. 소개\n\n메달리온 아키텍처 내의 델타 테이블은 일반적으로 데이터 제품을 생성하는 데 사용됩니다. 이러한 데이터 제품은 데이터 과학, 데이터 분석 및 보고를 위해 사용됩니다. 그러나 데이터 제품을 REST API를 통해 노출하는 것도 일반적인 문제입니다. 이 아이디어는 이러한 API를 더 엄격한 성능 요구 사항을 갖춘 웹 앱에 내장하는 것입니다. 중요한 질문은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데팔타 테이블에서 데이터를 읽는 것이 웹 애플리케이션에 빠르게 서비스할 수 있을까요?\n솔루션을 확장할 수 있는 컴퓨팅 레이어가 필요할까요?\n엄격한 성능 요구 사항을 충족시키기 위한 스토리지 레이어가 필요할까요?\n\n이러한 질문에 대해 심층적으로 다루기 위해 세 가지 아키텍처가 다음과 같이 평가됩니다: 아키텍처 A — API의 라이브러리, 아키텍처 B — 컴퓨팅 레이어 및 아키텍처 C — 스토리지 레이어. 아래 이미지 참조하세요.\n\n![image](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_1.png)\n\n블로그 글의 나머지 부분에서 세 가지 아키텍처에 대한 설명을 제공하고, 배포 및 테스트를 수행한 후 결과를 도출합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 2. 아키텍처 설명\n\n## 2.1 아키텍처 A: DuckDB와 PyArrow를 사용한 API 내 라이브러리\n\n이 아키텍처에서는 API가 직접 델타 테이블에 연결되어 있으며 중간에 계산 레이어가 없습니다. 이는 데이터가 API 자체의 메모리와 계산을 사용하여 분석된다는 것을 의미합니다. 성능을 향상시키기 위해 내장 데이터베이스 DuckDB와 PyArrow의 Python 라이브러리를 사용합니다. 이러한 라이브러리는 API에서 필요한 열만로드되도록 보장합니다.\n\n![이미지](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 아키텍처의 장점은 데이터를 중복으로 만들 필요가 없으며 API와 델탔 테이블 사이에 필요한 레이어가 없다는 것입니다. 이는 구성 요소가 적다는 것을 의미합니다.\n\n이 아키텍처의 단점은 확장하기 어렵고 모든 작업을 API의 컴퓨팅 및 메모리에서 처리해야 한다는 것입니다. 특히 많은 양의 데이터를 분석해야 하는 경우에는 특히 도전적입니다. 이는 많은 레코드, 큰 컬럼 또는 많은 동시 요청에서 나올 수 있습니다.\n\n## 2.2 아키텍처 B: Synapse, Databricks 또는 Fabric을 사용하는 컴퓨팅 레이어\n\n이 아키텍처에서 API는 컴퓨팅 레이어에 연결되고 델탔 테이블에 직접 연결되지 않습니다. 이 컴퓨팅 레이어는 델타 테이블에서 데이터를 가져와 데이터를 분석합니다. 컴퓨팅 레이어는 Azure Synapse, Azure Databricks 또는 Microsoft Fabric일 수 있으며 일반적으로 잘 확장됩니다. 데이터는 컴퓨팅 레이어로 중복되지 않지만 컴퓨팅 레이어에서 캐싱을 적용할 수 있습니다. 이 블로그의 남은 부분에서는 Synapse Serverless로 테스트 되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_3.png)\n\n이 아키텍처의 장점은 데이터를 중복하여 저장할 필요가 없으며 아키텍처가 잘 확장된다는 것입니다. 또한 대규모 데이터 세트를 처리하는 데 사용할 수 있습니다.\n\n이 아키텍처의 단점은 API와 델타 테이블 사이에 추가적인 레이어가 필요하다는 것입니다. 이는 더 많은 이동 부품을 유지 및 보안해야 한다는 의미입니다.\n\n## 2.3 아키텍처 C: Azure SQL이나 Cosmos DB를 사용한 최적화된 저장 레이어\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 아키텍처에서 API는 델타 테이블에 직접 연결되지 않고, 델타 테이블이 복제된 다른 저장 계층에 연결됩니다. 다른 저장 계층은 Azure SQL 또는 Cosmos DB일 수 있습니다. 이 저장 계층은 데이터를 빠르게 검색하기 위해 최적화될 수 있습니다. 이 블로그의 나머지 부분에서는 Azure SQL을 사용하여 테스트를 진행합니다.\n\n![이미지](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_4.png)\n\n이 아키텍처의 장점은 저장 계층이 인덱스, 파티셔닝 및 머티얼라이즈드 뷰를 사용하여 데이터를 빠르게 읽을 수 있도록 최적화될 수 있다는 것입니다. 이는 주로 요청-응답 웹 앱 시나리오에서 요구 사항입니다.\n\n이 아키텍처의 단점은 데이터가 중복되어야 하며 API와 델타 테이블 사이에 추가적인 계층이 필요하다는 것입니다. 이는 더 많은 구성 요소를 유지보수하고 보안해야 한다는 의미입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n블로그의 나머지 부분에서 아키텍처를 배포하고 테스트합니다.\n\n# 3. 아키텍처 배포 및 테스트\n\n## 3.1 아키텍처 배포\n\n아키텍처를 배포하기 위해 이전 장에서 논의한 세 가지 솔루션을 배포하는 GitHub 프로젝트가 생성되었습니다. 해당 프로젝트는 아래 링크에서 확인할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nhttps://github.com/rebremer/expose-deltatable-via-restapi\n```\n\n다음은 GitHub 프로젝트를 실행할 때 배포될 내용입니다:\n\n- 표준 테스트 데이터 세트 WideWorldImporterdDW full에서 시작한 델타 테이블. 테스트 데이터 세트는 50백만 건의 레코드와 22개 열로 구성되어 있으며 1개의 큰 설명 열이 있습니다.\n- 모든 아키텍처: API로 작용하는 Azure Function.\n- 아키텍처 B: 컴퓨팅 계층으로 작용하는 Synapse Serverless.\n- 아키텍처 C: 최적화된 저장 계층으로 작용하는 Azure SQL.\n\n배포된 후 테스트를 실행할 수 있습니다. 다음 단락에서 테스트에 대해 설명하겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.2 테스트 아키텍처\n\n아키텍처를 테스트하기 위해 다양한 유형의 쿼리 및 다른 스케일링을 적용할 것입니다. 다양한 유형의 쿼리는 다음과 같이 설명할 수 있습니다:\n\n- 11개의 작은 열(char, integer, datetime)을 포함하는 20개 레코드를 조회합니다.\n- 각 필드당 500자 이상을 포함하는 큰 설명 열이 포함된 2개 열을 사용하여 20개 레코드를 조회합니다.\n- 그룹별 데이터 집계, having, max, average를 사용한 데이터 집계.\n\n아래에서 쿼리를 설명합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```sql\n-- 쿼리 1: 대형 텍스트 없이 11개 열의 포인트 조회\nSELECT SaleKey, TaxAmount, CityKey, CustomerKey, BillToCustomerKey, SalespersonKey, DeliveryDateKey, Package\nFROM silver_fact_sale\nWHERE CityKey=41749 and SalespersonKey=40 and CustomerKey=397 and TaxAmount \u003e 20\n-- 쿼리 2: 500자 이상의 Description 열\nSELECT SaleKey, Description\nFROM silver_fact_sale\nWHERE CityKey=41749 and SalespersonKey=40 and CustomerKey=397 and TaxAmount \u003e 20\n-- 쿼리 3: 집계\nSELECT MAX(DeliveryDateKey), CityKey, AVG(TaxAmount)\nFROM silver_fact_sale\nGROUP BY CityKey\nHAVING COUNT(CityKey) \u003e 10\n```\n\n다음과 같이 스케일링이 가능합니다:\n\n- 아키텍처 A의 경우, 데이터 처리는 API 자체에서 수행됩니다. 이는 API의 컴퓨트 및 메모리가 앱 서비스 플랜을 통해 사용된다는 것을 의미합니다. SKU Basic(1코어 및 1.75GB 메모리) 및 SKU P1V3 SKU(2코어, 8GB 메모리)로 테스트될 것입니다. 아키텍처 B 및 C의 경우에는 처리가 다른 곳에서 이루어지기 때문에 이러한 정보는 해당하지 않습니다.\n- 아키텍처 B의 경우, Synapse Serverless가 사용됩니다. 스케일링은 자동으로 이루어집니다.\n- 아키텍처 C의 경우, 표준 티어의 Azure SQL 데이터베이스가 125 DTU로 사용됩니다. CityKey에 인덱스가 없는 상태와 CityKey에 인덱스가 있는 상태에서 테스트될 것입니다.\n\n다음 단락에서 결과가 설명됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 3.3 결과\n\n아키텍처를 배포하고 테스트한 후에는 결과를 얻을 수 있습니다. 다음은 결과 요약입니다:\n\n![Results](/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_5.png)\n\n아키텍처 A는 SKU B1로 배포할 수 없습니다. 만약 SKU P1V3가 사용된다면, 컬럼 크기가 크지 않다면 결과는 15초 이내에 계산될 수 있습니다. 모든 데이터를 API 앱 서비스 계획에서 분석한다는 점을 유의하십시오. 너무 많은 데이터가로드되면(많은 행, 큰 컬럼 및/또는 많은 동시 요청으로),이 아키텍처는 확장하기 어려울 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아키텍처 B는 Synapse Serverless를 사용하여 10-15초 내에 작동합니다. 계산은 데이터를 가져와 분석하기 위해 자동으로 조정되는 Synapse Serverless에서 이루어집니다. 성능은 세 가지 유형의 쿼리에 대해 일관되게 유지됩니다.\n\n아키텍처 C는 Azure SQL을 사용할 때 인덱스가 생성되면 가장 잘 작동합니다. 조회 쿼리 1과 2의 경우 API는 대략 1초 내에 응답합니다. 쿼리 3은 전체 테이블 스캔이 필요하며 성능은 다른 솔루션과 거의 동일합니다.\n\n# 3. 결론\n\n중재 아키텍처의 Delta 테이블은 일반적으로 데이터 제품을 생성하는 데 사용됩니다. 이러한 데이터 제품은 데이터 과학, 데이터 분석 및 보고서 작성에 사용됩니다. 그러나 일반적으로 Delta 테이블을 REST API를 통해 노출하는 것도 자주 묻는 질문 중 하나입니다. 이 블로그 포스트에서는 이와 같은 장단점을 갖는 세 가지 아키텍처가 설명되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nArchitecture A: DuckDB 및 PyArrow를 사용하여 API 내 라이브러리를 활용하는 아키텍처입니다.\n이 아키텍처에서는 API가 직접 델타 테이블에 연결되어 중간 계층이 없습니다. 이는 모든 데이터가 메모리에서 분석되고 Azure Function의 연산을 함께 함을 의미합니다.\n\n- 이 아키텍처의 장점은 추가 리소스가 필요하지 않다는 것입니다. 이는 유지 및 보안해야 하는 부분이 적기 때문에 이점으로 작용합니다.\n- 이 아키텍처의 단점은 API 자체에서 모든 데이터를 분석해야 하기 때문에 확장성이 떨어진다는 것입니다. 따라서 소량의 데이터에만 사용해야 합니다.\n\nArchitecture B: Synapse, Databricks 또는 Fabric을 사용한 컴퓨팅 레이어.\n이 아키텍처에서는 API가 컴퓨팅 레이어에 연결됩니다. 이 컴퓨팅 레이어는 델타 테이블에서 데이터를 가져와 분석합니다.\n\n- 이 아키텍처의 장점은 확장성이 좋고 데이터가 중복되지 않습니다. 집계를 수행하며 대량의 데이터를 분석하는 쿼리에 적합합니다.\n- 이 아키텍처의 단점은 조회 쿼리에 일관되게 5초 이내의 응답을 받는 것이 불가능하다는 것입니다. 또한 추가 리소스를 보안 및 유지해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아키텍처 C: Azure SQL 또는 Cosmos DB를 사용한 최적화된 저장 계층입니다.\n\n이 아키텍처에서는 API가 최적화된 저장 계층에 연결됩니다. 델타 테이블이 미리 이 저장 계층으로 복제되며 데이터를 검색하고 분석하는 데 사용됩니다.\n\n- 이 아키텍처의 장점은 인덱스, 파티셔닝, 머티얼라이즈드 뷰를 사용하여 룩업의 빠른 쿼리를 위해 최적화될 수 있다는 것입니다. 이것은 종종 요청-응답 웹 앱에 필요한 요구사항입니다.\n- 이 아키텍처의 단점은 데이터가 다른 저장 계층으로 중복되어 동기화가 유지되어야 한다는 것입니다. 또한 추가 자원을 보안하고 유지해야 합니다.\n\n안타깝게도, 완벽한 해결책은 없습니다. 이 글은 REST API를 통해 델타 테이블을 노출하는 데 가장 적합한 아키텍처를 선택하는 데 도움을 주기 위한 가이드를 제시했습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png"},"coverImage":"/assets/img/2024-05-18-HowtoExposeDeltaTablesviaRESTAPIs_0.png","tag":["Tech"],"readingTime":10},{"title":"Power BI 최적화 차원 모델링에서 서로간키의 필요성","description":"","date":"2024-05-18 18:05","slug":"2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling","content":"\n![Surrogate Key](/assets/img/2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling_0.png)\n\n# 문제 설명\n\n최근에 나는 대체키를 조합키 대신 사용하는 것을 연구하는 업무를 맡았습니다. 지금까지 우리 팀은 레코드를 고유하게 나타내고 차원과 사실을 차원 모델에 연결하는 데 조합 키를 사용했습니다. 조합 키는 작업을 수행했지만 Power BI 측에서 쿼리 실행 시간이 만족스럽지 않았습니다. 조인이 오랜 시간이 걸렸는데 그 이유는 조합된 키의 열 크기가 큰 것입니다. Power BI에서는 대규모 관계(키) 열이있을 때 쿼리가 훨씬 느리게 실행됩니다.\n\n내 목표는 Power BI에서 쿼리 실행 시간을 줄일 방법을 찾는 것이었습니다. 차원과 사실을 결합하기 위해 대체 키를 조합 키로 교체하는 것은 제가 자세히 탐색한 대안 중 하나였습니다. 이 기사에서는 대체 키의 정의, 목적 및 구현하는 대안 방법에 대해 안내하겠습니다. 실용적인 예제는 PySpark에서 보여집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 대리 키란 무엇인가요?\n\n남들의 말을 바꾸는 대신, 관계형 데이터베이스의 맥락에서 대리 키 및 다른 유형의 키를 다루는 이 글을 참고해보세요.\n\n내가 대리 키를 정의하는 방식은 이러하다. 대리 키는 인공적이며 비즈니스나 현실 세계와 관련이 없으며 어떠한 비즈니스 개념과도 연결되지 않는다. 레코드를 고유하게 식별하는 데 도움이 되는 고유성을 가지고 있으며 대부분 (항상은 아니지만) 정수 형태이다.\n\n아래 직원 테이블에서 직원 ID 열이 대리 키의 예시입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Surrogate Key](/assets/img/2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling_1.png)\n\n서로게이트 키는 여러 가지 이유로 존재합니다. 하나의 명확한 답변은 해당 테이블에 자연 키의 명백한 후보가 없고 레코드를 고유하게 식별하기 위해 (서로게이트 키라고도 함) 가짜 키를 생성해야하는 경우입니다.\n\n두 번째 명백한 이유는 시간의 시험을 견디는 능력입니다. 이 이유는 데이터 웨어하우스 디자인의 맥락에서 더 관련이 있습니다. 기본 키로 자연 키에 의존하는 것은 데이터베이스 수준에서 시간이 지남에 따라 변경 사항에 취약해질 수 있습니다.\n\n구글의 주식 심볼을 예로 들 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n원래 구글 주식의 종류는 GOOG 주식 심볼을 가지고 있었습니다. 2014년 4월, 회사는 GOOGLE 주식 심볼 아래 새로운 주식 종류를 만들었습니다. 데이터베이스 디자인에서 구글 주식을 나타내는 주요 키로 원래 GOOG 심볼을 사용하고 있다면, 이 변경 사항을 반영하기 위해 적절한 수정을 해야 할 것입니다. Kimball (1998)은 이를 정확히 이유로 자연 키를 사용하는 것을 지양해야 한다고 주장했습니다. 그는 트랜잭션 데이터베이스의 자연 키는 \"생산의 지시에 따라 생성, 형식화, 업데이트, 삭제, 재활용 및 재사용\"되기 때문에 트랜잭션 데이터베이스 수준에서 발생하는 변경 사항에 지속적으로 의존해야 한다고 설명했습니다.\n\n대리 키의 세 번째 이유는 쿼리 성능이 더 좋다는 것입니다. 이는 특히 데이터 웨어하우스의 맥락에서 맞닿은 사실입니다. 차원 모델은 차원과 사실 사이에서 많은 조인을 수행해야 한다. 수치 (일반적으로 정수 또는 smallint)인 대리 키를 사용하여 조인하는 것은 문자열로 이루어진 자연 키나 복합 키로 조인하는 것보다 빠릅니다. 이 이유에 대해 더 자세히 알아보려면 여기를 읽어보세요.\n\n# 대리 키 생성의 대체 방법\n\n대리 키 구현에 대한 제 연구로 결과적으로 대리 키를 생성하는 주요 방법은 두 가지라고 결론내렸습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 가지 방법은 단조 증가하는 정수를 생성하는 전통적인 함수를 통해 정수를 만드는 것입니다. 이 함수는 테이블의 고유한 값에 대해 정수를 생성합니다.\n\n다른 대안은 암호 해싱 함수를 사용하는 것입니다. 해싱 함수는 데이터 자체에 대해 고유한 값을 생성하며, \"동일한 입력 집합은 항상 동일한 출력 집합을 생성한다\"는 의미입니다(Connors, 2022). 해싱 함수의 몇 가지 예는 crc32, md5, sha1/ sha2 등이 있습니다.\n\n이 두 가지 방법을 PySpark에서 어떻게 구현하는지 살펴봅시다.\n\n## 단조 증가하는 정수\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n쇼핑 목록에 제품 목록과 제품이 목록에 추가된 타임스탬프가 있는 테이블이 있다고 상상해보세요.\n\n| Product   | Timestamp           |\n| --------- | ------------------- |\n| Product A | 2024-09-15 10:30:00 |\n| Product B | 2024-09-15 11:45:00 |\n| Product C | 2024-09-15 13:20:00 |\n\n제품 차원의 서로 다른 키를 생성하려면 monotonically_increasing_id() 함수를 사용해야 합니다. 이 함수를 적용하기 전에 제품 목록이 고유한지 확인해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 제품 테이블은 바나나와 빵이 2일에 나누어서 입력되어서 두 번씩 나타납니다. 따라서 단계는 제품 열만 선택한 다음, 값을 고유하게 만들고 monotonically_increasing_id() 함수를 적용하는 것입니다.\n\n한 가지 더 고려해야 할 사항은 테이블에 NULL 값이 있는지 여부입니다. 이를 함수를 적용하기 전에 필터링해야 합니다. NULL 값에 대한 대체 키 ID를 부여하고 싶지 않다면 필터링을 해야 합니다.\n\n```js\nfrom pyspark.sql.functions import monotonically_increasing_id, col\n\n#clean\ndf_select=df.select(\n  col('product')\n  )\ndf_distinct=df_select.distinct()\n\n#monotonically_increasing_id 함수를 사용하여 대체 키 생성\ndf_sk=df_distinct.withColumn(\n  \"surrogate_key\",\n  monotonically_increasing_id()\n  )\n```\n\n출력 결과는 다음과 같을 것입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling_3.png)\n\n모노토닉하게 증가하는 정수는 결정론적이 아니며, 동일한 값 목록에 대해 이 기능을 실행해도 항상 동일한 대리 키가 할당되지는 않습니다. 예를 들어, 사과는 항상 ID 1이 할당되는 것은 아닙니다. 대리 키의 유지보수는 따라서 몇 가지 추가 작업이 필요할 수 있습니다.\n\n이를 해결하는 한 가지 방법은 사실보다 차원을 먼저 로드하는 것입니다. 저의 팀에서 구현한 방법은 먼저 대리 키를 사용하여 차원을 생성한 다음 사실에서 차원을 사용하여 대리 키를 조회하는 것입니다. 이는 차원과 사실의 참조 무결성을 보장합니다.\n\n## 해싱 함수\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해싱 함수에 대한 내 연구는 그들이 무엇인지 이해하고 대체 키 생성을 위한 전통적인 함수들이 언제 선호되는지를 이해하는 데 국한되어 있었습니다. 따라서 해싱 함수들 간의 차이점이나 그들을 어떻게 구현하는지에 대해 자세히 다루지는 않겠습니다. PySpark에서 구현 측면을 다루는 이 Medium 기사를 발견했습니다.\n\n나는 해싱 함수를 선택하지 않은 이유는 해싱 함수를 사용하여 생성된 대체 키들이 종종 더 긴 문자열 값을 갖기 때문입니다. 나가 해결하려고 하는 문제는 Power BI에서 조인의 쿼리 성능을 개선하는 것이었습니다. 긴 합성 키를 해싱 함수에 의해 생성된 긴 키로 바꾸는 것은 나의 문제에 적합한 해결책이 아니었습니다.\n\n하지만 해싱 함수를 매력적으로 만드는 것은 해싱 함수를 통해 생성된 대체 키들이 상기에서 논의된 단조증가 정수보다 유지하기가 훨씬 더 쉽고 (그리고 덜 복잡)이라는 점입니다. 해싱 함수는 결정론적이기 때문에 동일한 입력 세트는 항상 동일한 출력을 생성합니다. 이상적으로는 차원 및 사실을 병렬로 대체 키를 생성할 수 있습니다.\n\n# 요약\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 Power BI에서 쿼리 성능을 향상시키는 데 중점을 두며, 차원 모델의 컴포지트 키에 대한 효율적인 대안으로서 대리키의 사용을 탐색했습니다.\n\n비즈니스 의미를 가지지 않는 고유 식별자인 대리키는 데이터 웨어하우스에서 차원과 사실 사이의 관계 관리를 크게 최적화할 수 있습니다.\n\n우리는 이러한 키를 생성하는 다양한 방법을 탐구했습니다. PySpark에서 실용적인 예제를 통해 각 접근 방식의 이점과 고려 사항을 고려하여 데이터 아키텍처 요구에 맞는 올바른 전략을 선택하는 데 도움이 될 수 있도록 안내했습니다.\n\n# 자원\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n| Author          | Title                                                                    | Year  | Source        |\n| --------------- | ------------------------------------------------------------------------ | ----- | ------------- |\n| Ben             | Database Keys: The Complete Guide (Surrogate, Natural, Composite \u0026 More) | 2022  | Database Star |\n| Connor, Dave    | Surrogate Keys In dbt: Integers or Hashes?                               | 2022  | dbt           |\n| Kimball, R.     | Surrogate Keys                                                           | 1998  | Kimball Group |\n| Stiglich, Peter | Performance Benefits of Surrogate Keys in Dimensional Models             | ----- | EWS Solutions |\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n| 저자            | 제목                                                  | 출판연도 | 출처                                   |\n| --------------- | ----------------------------------------------------- | -------- | -------------------------------------- |\n| Wikstrom, Max   | Power BI Data Types In Relationships- Does It Matter? | 2022     | Data, Business Intelligence and Beyond |\n| Zaman, Ahmed Uz | PySpark Hash Functions: A Comprehensive Guide         | 2023     | Medium                                 |\n","ogImage":{"url":"/assets/img/2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling_0.png"},"coverImage":"/assets/img/2024-05-18-SpeedingUpPowerBITheCaseforSurrogateKeysinDimensionalModeling_0.png","tag":["Tech"],"readingTime":9},{"title":"YouTube 데이터 파이프라인 구축하기 Docker 컨테이너에서 Airflow 사용하기","description":"","date":"2024-05-18 18:03","slug":"2024-05-18-YoutubeDataPipelineusingAirflowinDockerContainer","content":"\n그게 많은 양이겠죠! 조금씩 나눠서 살펴봐요.\n\n![YoutubeDataPipeline](/assets/img/2024-05-18-YoutubeDataPipelineusingAirflowinDockerContainer_0.png)\n\n## 사용 사례: —\n\n상상해봐요! 성장하는 YouTube 채널을 운영하는 콘텐츠 크리에이터라고 상상해봐요. 시청자들의 댓글과 답글을 통해 시청자를 이해하는 것은 귀중한 통찰력을 제공할 수 있어요. 그러나 수많은 동영상의 댓글을 수동으로 분류하는 것은 지칠 수 있죠. 이 프로세스를 자동화할 수 있는 방법이 있다면 어떨까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 제안된 해결책: —\n\n위의 그림을 보시면, YouTube 비디오에서 댓글과 답글을 추출하기 위한 자동화된 솔루션을 안내해 드리겠습니다. 이 과정에는 여러 가지 주요 구성 요소가 포함됩니다:\n\n— YouTube 데이터 API용 Python 라이브러리: YouTube 데이터 API와 상호 작용하기 위해 Python 라이브러리를 사용하여 댓글과 답글을 프로그래밍 방식으로 가져올 수 있습니다.\n\n— 작업 관리를 위한 Airflow: 데이터 추출 및 처리 작업을 체계적으로 관리하기 위해 Apache Airflow를 Docker 컨테이너 내에서 사용할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터 저장을 위한 AWS S3: 마지막으로, boto3 라이브러리를 사용하여 처리된 데이터를 AWS S3에 저장하게 됩니다. 나중에 쉽게 액세스하고 분석할 수 있습니다.\n\n이 솔루션은 추출 프로세스를 자동화하는 데 그치지 않고 데이터가 구성되어 안전하게 저장되어 나중에 깊이 있는 분석을 위해 준비되어 있음을 보장합니다. 이제 이 워크플로우를 설정하고 실행하는 자세한 내용을 살펴보겠습니다.\n\n## 구현\n\n구현은 주로 두 가지 작업으로 구성되어 있습니다. 첫 번째는 인프라 구축, 두 번째는 코드 작업입니다. 그래서 이제 인프라 설정을 먼저 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n도커 데스크톱을 설치해보세요 — https://www.docker.com/get-started/\n\n머신에 도커를 설치한 후에는 다음 명령어를 확인하여 설치가 성공적으로 이루어졌는지 확인하세요.\n\n```js\ndocker --version\nDocker version 20.10.23, build 7155243\n```\n\n최신 apache/airflow 이미지를 받아보세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```sh\n도커 pull apache/airflow\n```\n\n다음 명령어를 사용하여 아파치 에어플로우 컨테이너를 시작하세요.\n\n```sh\n도커 run -p 8080:8080 -v /Users/local_user/airflow/dags:/opt/airflow/dags -v /Users/local_user/airflow/creds:/home/airflow/.aws -d apache/airflow standalone\n```\n\nAWS 자격 증명을 생성하여 원격 s3 버킷과 통신하여 날짜를 쓸 수 있습니다. 다음 링크를 통해 생성하세요 — 루트 사용자를 위한 액세스 키 생성하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nconfig\n\n```json\n[default]\nregion = ap-south-1\n```\n\ncredentials\n\n```json\n[default]\naws_access_key_id = AKIB******AXPCMO\naws_secret_access_key = 4D7HkaIBsqu***********+0AT2a8j\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지역 사용자의 경우 두 파일을 로컬 머신의 /Users/local_user/airflow/creds/ 폴더로 복사해주세요. 이렇게 함으로써 이 파일들이 컨테이너에서 /home/airflow/.aws/ 경로에 마운트되도록 할 수 있습니다.\n\n도커 데스크톱 애플리케이션을 열고 Airflow 컨테이너를 선택해주세요. 컨테이너 내에서 standalone_admin_password.txt 파일을 찾아주세요. 이 파일을 열고 Airflow 포털에 로그인하기 위한 비밀번호를 복사해주세요.\n\n![이미지](/assets/img/2024-05-18-YoutubeDataPipelineusingAirflowinDockerContainer_1.png)\n\n웹 브라우저를 열고 `http://localhost:8080` 주소로 이동해주세요. username에 admin을 입력하고 이전 단계에서 복사한 비밀번호로 로그인해주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n`aws_write_utility.py` 파일을 만들 때 평소처럼 진행하시면 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport boto3\nimport json\nimport uuid\n\ndef write_json_to_s3(json_data, bucket_name, key_name):\n\n    # S3 클라이언트 초기화\n    s3 = boto3.client('s3')\n\n    # JSON 데이터를 바이트로 변환\n    json_bytes = json.dumps(json_data).encode('utf-8')\n\n    # JSON 데이터를 S3에 쓰기\n    s3.put_object(Bucket=bucket_name, Key=key_name, Body=json_bytes)\n\n\ndef generate_uuid():\n    \"\"\"UUID와 유사한 문자열 생성.\"\"\"\n    return str(uuid.uuid4())\n```\n\nyoutube_comments.py\n\n```js\n# -*- coding: utf-8 -*-\n\n# youtube.commentThreads.list를 위한 샘플 Python 코드\n# 이 코드 샘플을 로컬에서 실행하는 방법은 다음 링크를 참고하세요:\n# https://developers.google.com/explorer-help/code-samples#python\n\nimport os\n\nimport googleapiclient.discovery\nimport aws_write_utility\nfrom aws_write_utility import write_json_to_s3\n\ndef start_process():\n    # 로컬에서 실행 시 OAuthlib의 HTTPS 확인 비활성화\n    # 제품 환경에서는 이 옵션을 활성화하지 마세요.\n    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n\n    api_service_name = \"youtube\"\n    api_version = \"v3\"\n    DEVELOPER_KEY = \"AIzaS*****************PiwBdaP_IE\"\n\n    youtube = googleapiclient.discovery.build(\n        api_service_name, api_version, developerKey=DEVELOPER_KEY)\n\n    request = youtube.commentThreads().list(\n        part=\"snippet,replies\",\n        videoId=\"r_K*****PKU\"\n    )\n    response = request.execute()\n\n    process_comments(response)\n\n\ndef process_comments(response_items):\n\n    # 예시 S3 버킷 및 키 이름\n    bucket_name = 'youtube-comments-analysis'\n    key_name = 'data/{}.json'.format(aws_write_utility.generate_uuid())\n\n    comments = []\n    for comment in response_items['items']:\n        author = comment['snippet']['topLevelComment']['snippet']['authorDisplayName']\n        comment_text = comment['snippet']['topLevelComment']['snippet']['textOriginal']\n        publish_time = comment['snippet']['topLevelComment']['snippet']['publishedAt']\n        comment_info = {'author': author, 'comment': comment_text, 'published_at': publish_time}\n        comments.append(comment_info)\n    print(f'총 {len(comments)}개의 댓글 처리 완료.')\n    write_json_to_s3(comments, bucket_name, key_name)\n```\n\nyoutube_dag.py\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom youtube_comments import start_process\n\n# 기본 인수 정의\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'start_date': datetime(2024, 5, 16),\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# DAG 객체 생성\ndag = DAG(\n    'youtube_python_operator_dag',\n    default_args=default_args,\n    description='Python 함수를 호출하는 간단한 DAG',\n    schedule_interval=timedelta(days=1),\n)\n\n# PythonOperator 작업 생성\npython_task = PythonOperator(\n    task_id='my_python_task',\n    python_callable=start_process,\n    dag=dag,\n)\n\n# 작업 간 의존성 정의\npython_task\n\n# DAG 등록\ndag\n```\n\n위의 .py 파일을 로컬 머신의 /Users/local_user/airflow/dags로 복사하세요. 이렇게 함으로써 컨테이너 내의 경로 /opt/airflow/dags로 마운트됩니다.\n\n좋아요!!\n\n이제 Airflow에서 DAG 페이지를 새로고침하세요. 위의 DAG가 표시될 것입니다. 실행해보고 문제가 있는지 로그를 확인해보세요. 녹색으로 변하면 작업이 완료된 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 구현은 AWS EC2 인스턴스에 Airflow를 설정하여 수행할 수도 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-YoutubeDataPipelineusingAirflowinDockerContainer_0.png"},"coverImage":"/assets/img/2024-05-18-YoutubeDataPipelineusingAirflowinDockerContainer_0.png","tag":["Tech"],"readingTime":8},{"title":"AI로 기후 변화를 고칠 수 있을까 데이터 전문가의 견해","description":"","date":"2024-05-18 18:01","slug":"2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd","content":"\n![image](/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_0.png)\n\n기후 변화는 짜증나는 주제입니다. 정치인들은 그에 대해 의미 있는 조치를 취하기에 열의를 보이지 않습니다. 대부분의 사람들은 우리와 같은 힘없는 존재로 느껴지며 어떻게 도울지 모릅니다.\n\n그럼에도 불구하고, 기후 변화는 일어나고 있으며 아마도 가속화되고 있습니다(이 블로그 게시물의 데이터에서 나중에 확인하겠지요). 우리는 매 여름이 지난 여름보다 더 덥다는 세계에 살고 있는 것 같군요.\n\n처음으로 태어난 세대로서 가끔씩 심각하게 생각할 때가 있습니다. 미래 기후 대재앙을 겪게 될 자녀들을 이 세상에 데리고 오는 것이 공정한 일인지에 대해 🤔. 한편, 어떤 사람들은 우리를 (우리로부터) 구해 줄 수 있는 초지능 AI에 기대를 걸어 놓고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 문제에 대한 명확성을 얻기 위해 기후 변화에 관한 가장 중요한 데이터 지점들을 수집했습니다. 그리고 이 블로그 포스트에서는 데이터 관련 열광적인 사람의 시각을 통해 현재 상황을 함께 공유하겠습니다 📈.\n\n시작해봅시다!\n\n👉 참고: 이 블로그 포스트의 비디오 버전을 시청하거나 제 Youtube 채널에서 데이터 보고서를 확인할 수도 있습니다:\n\n# 펼쳐지는 기후 이야기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 온실 효과\n\n2023년은 1850년 이후 기록된 가장 더운 해로, 이는 이례적인 해였습니다. 사실, 일부 데이터 세트가 제안하는 바에 따르면, 연간 평균 기온이 산업화 이전 기준 기간을 1.5°C 이상 초과하는 것은 이번이 처음입니다. 만약 이 용어가 익숙하지 않다면, 산업화 이전 시기는 1880년부터 1900년까지의 기준 기간입니다.\n\n이것이 그냥 이상 현상이거나 엘니뇨가 이 이례적으로 더운 해를 일으켰다고 주장할 수도 있습니다. 하지만 다음 그래프에서 볼 수 있듯이, 지난 4년 동안 평균 기온에서 매우 확고한 상승 추세를 볼 수 있습니다.\n\n![그래프](/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파리협정 아래에서 많은 국가들이 장기적인 지구 온난화를 1.5°C(2.7°F) 이상으로 제한하려는 포부적인 목표를 세웠습니다. 이 목표는 많은 연도에 걸친 기후 상태를 기반으로 하기 때문에 1.5°C를 초과하는 단일 연도는 자동으로 이 목표를 위반한 것으로 간주되지 않습니다. 그러나 이것은 파리협정 목표를 초과하고 온클유어(Codesphere)글로벌 sandbox를 얼마나 가까이 왔는지에 대한 뚜렷한 경고 신호입니다.\n\n인간들이 대기 중에 더 많은 이산화탄소를 방출하면, 기후 온난화가 다음 10년 동안 정기적으로 1.5°C를 초과할 가능성이 높습니다.\n\n아래 그래프를 보면 대기 중 CO2 수준이 과거 백만 년 동안 어떤 시점에서도 점선 위로 올라가지 않았음을 알 수 있습니다. 그리고 빨간색으로 튀어나오는 이 스파이크는 지난 70년을 대표합니다. 나로서는 확실히 그 위에 앉고 싶지 않네요!\n\n![그래프 이미지](/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지난 백 년 동안의 이산화탄소 배출 증가는 대부분 화석 연료 사용과 산업에 기인한다고 볼 수 있습니다. 다시 말해, 인간의 활동입니다.\n\n![Image](/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_3.png)\n\n기후 변화에 관한 정부간 기후변화협약 합동 심의 보고서에 따르면, 2030년까지 약속된 국가별 기여(NDCs)는 2030년대 초반에 온도가 1.5°C 상승할 것으로 나타났습니다. 만약 그게 사실이라면, 이세기 말까지 온도 상승을 2.0°C 이하로 유지하려고 노력할지도 모릅니다.\n\n기온 상승으로 인해 더위가 심한 지역은 더 덥게, 비가 많이 오는 지역은 더 많이 비가 오게 되며, 극한 기상 현상의 위험성과 강도는 크게 증가할 것으로 예상됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1.5°C 온난화 시, 지구 인구의 약 14%가 매 5년마다 적어도 한 번은 심한 폭염에 노출될 것으로 예상됩니다. 그러나 2°C 온난화 시, 해당 비율은 37%까지 늘어납니다. 극한 폭염 또한 보편화될 것으로 예상되며, 2°C 온난화 시에는 일부 국가에서 매년 치명적인 폭염이 발생할 수 있습니다.\n\n2°C를 넘는 온난화는 모든 극단적인 상황을 더욱 심각하게 만들 것으로 예상되며, 빈발하는 허리케인, 가뭄 및 산불이 포함됩니다. 더 많은 생태계가 심한 압력에 시달리게 될 것이며, 일부는 간단히 살아남지 못할 것입니다.\n\n인류에게는 먹을 음식을 생산해내기 어려워질 수도 있다는 의미입니다. 많은 사람들이 이주할 수 있고, 이는 국가를 불안정하게 만들 수 있습니다.\n\n## 녹는 얼음과 높아지는 바다수준\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n극단적인 날씨를 한쪽에 두고 또 다른 큰 문제가 있습니다: 극지방의 녹는 얼음입니다. 위 문제는 위성 자료와 지상 관측을 통해 모니터링할 수 있습니다.\n\n21세기 초부터 남극과 그린란드 빙하는 질량이 감소했습니다.\n\n![image](/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_4.png)\n\n남극과 그린란드 빙하는 지구의 물 중에서 99% 이상을 차지합니다. 이 둘이 완전히 녹는다면, 예상된 바다 수위 상승은 67.4미터 (223피트)에 이를 것으로 추정됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서, 우리는 멸망했을까요? 기후 종말은 피할 수 없을까요? 인공지능은 어떨까요? 우리를 구할 수 있을까요?\n\n자, 이제 인공지능이 우리가 기후 변화와 싸우는 데 어떻게 도움을 줄 수 있는지에 대해 이야기해 봅시다!\n\n## 인공지능이 기후 변화 대응을 돕는 방법\n\n2023년과 2024년에는 인공지능 개발에서 엄청난 발전이 있었습니다. GPT4, Gemini, 그리고 많은 오픈 소스 언어 모델들이 대중에게 공개되면서 기후 변화 대응을 함께 할 수 있게 되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAI는 아직 새로운 기후 정책을 작성하고 시행할 수는 없습니다만 (아직), 정치인들이 그런 것을 허용하지 않을지도 모르겠군요. 그러면 여러분이 궁금해할 수도 있는데, AI가 실제로 우리가 많은 기후 문제에 대처하는 데 어떻게 도움을 줄 수 있을까요?\n\nAI는 가장 기본적인 수준에서 우리가 무슨 일이 벌어지고 있는지 이해하는 데 도움을 줄 수 있고 문제를 인정하는 데 도움이 될 수 있습니다. 제 연구에서 본 AI의 주요 활용은 다음과 같은 범주에 속합니다:\n\n- 모니터링;\n- 예측;\n- 최적화.\n\n## 온실가스 (GHG)의 실시간 모니터링을 향해\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기후 추적은 인공 지능과 기계 학습을 활용하여 전 세계적으로 온실 가스 배출량을 계산하는 이니셔티브로, 실시간 정확도를 향한 발전을 목표로 합니다. 이는 위치와 원천별 온실 가스 배출량에 대한 강력하고 무료이면서 독립적인 개요를 제공합니다. 저의 고향인 베트남 남부를 살펴보면, 석유 및 가스 분야에서 많은 배출량을 볼 수 있어 놀라지 않습니다. 또한 호치민 시 공항 주변에서 배출량이 집중되어 있는 것을 확인할 수 있습니다. 이 데이터는 Climate Trace 웹사이트에서 다운로드하여 자신의 연구에 활용할 수 있습니다. 정말 놀라운 일이죠!\n\n## 인공 지능이 빙산을 사람보다 10,000배 빨리 맵핑합니다\n\n또한, 연구자들은 위성 이미지에서 남극 빙산의 규모를 빠르고 정확하게 맵핑하고 모니터링하는 데 신경망 모델을 활용해왔습니다. 이는 빙산이 해양으로 녹는 양을 정량화하는 데 중요합니다.\n\n위성 이미지에서는 빙산, 해빙, 구름이 모두 하얗게 보여서 실제 빙산을 식별하기 어려운 경우가 많습니다. 그러나 신경망 모델은 이 작업을 훨씬 더 정확하고 효율적으로 처리합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## AI를 활용한 쓰레기 재활용\n\nAI도 쓰레기 관리를 더 효율적으로 만들고 있어요. 쓰레기는 메탄의 큰 배출원이며 상당 수의 이산화탄소 배출을 담당하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n물체 감지를 위해 머신 러닝 시스템을 사용하여 한 스타트업이 2022년에 67가지 종류의 쓰레기 범주에서 320억 개의 폐기물 항목을 추적했습니다. 회사는 회수할 수 있는 재료의 평균량으로 86톤을 식별했지만, 이 재료는 폐기물 처리장에 보내지고 있습니다. 전 세계의 대형 슈퍼마켓도 수요를 예측하고 이를 통해 폐기물을 줄이기 위해 AI를 사용하고 있습니다.\n\n## AI가 바다를 청소하고 있습니다\n\n네덜란드의 환경 단체인 The Ocean Cleanup은 바다로부터 플라스틱 오염물을 제거하는 데 도움을 주기 위해 AI와 다른 기술을 사용하고 있습니다.\n\n물체를 감지하는 신경망 알고리즘은 해당 조직이 원격 지역에 있는 해양 폐기물의 상세지도를 작성하는 데 도와주고 있습니다. 이 해양 폐기물은 그 후 수거 및 제거될 수 있으며, 이는 이전의 트롤러 및 항공기를 사용한 청소 방법보다 효율적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 인공지능이 기후 재해를 예측하는 데 도움을 줍니다\n\n인공지능 모델은 온도와 기후 재해를 더 정확하게 예측하는 데 도움이 되었습니다. GraphCast라는 AI 모델은 10일간의 기상 예측을 제공하는 것뿐만 아니라 극단적인 기상 현상에 대한 빠른 경보도 제공합니다. 이 모델은 태풍의 경로를 예측하고 홍수 위험과 관련된 대기 강과 극한 온도의 발생을 예측할 수 있습니다. 이는 생명을 구할 수 있는 잠재력이 있다는 것을 의미합니다.\n\n지금까지 저는 AI가 주로 기계 학습 도구로 사용되어왔다고 느꼈고, AI가 자체적으로 새로운 해결책을 만드는 데 사용되는 것을 보지 못했습니다. 앞으로, 만약 우리가 인공 일반 지능을 갖게 된다면, 이러한 종류의 AI가 더 많은 일을 할 수도 있을 것입니다.\n\n# 어떻게 인공지능이 상황을 악화시키고 있는지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 몇몇 회의론자들(source 1, source 2)은 AI가 \"행성을 구하는 데 도움이 될 것\"에 너무 낭만적으로 생각해서는 안 된다고 생각합니다. 그들은 인공 지능이 기후 위기 해결에 도움이 될 것이라는 주장이 잘못되었다고 믿습니다.\n\nGPT4와 Gemini 같은 모델은 훈련하고 실행하는 데 엄청난 양의 에너지가 필요합니다.\n\n![image](/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_5.png)\n\nAI 모델의 탄소 발자국을 정확하게 계산하는 것도 어렵습니다. 왜냐하면 OpenAI나 Google과 같은 기업들은 보통 자신들의 모델에 대한 상세 명세를 게시하지 않기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가장 간단한 형태로, AI 모델의 탄소 발자국은 모델을 훈련하는 데 필요한 에너지에 쿼리의 수와 각 쿼리가 필요로 하는 에너지를 더한 것과 같습니다. 이 모든 것은 하드웨어의 에너지 효율성에 의해 곱해질 것입니다.\n\n탄소 발자국 = (전기 에너지 훈련 + 쿼리 수 × 전기 에너지 추론) × CO2e 데이터 센터/KWh,\n\n여기서 CO2e 데이터 센터는 데이터 센터의 CO2 효율성을 의미합니다.\n\n대부분의 기업은 AI 모델을 제공하는 데 (추론 수행) 훈련하는 것보다 훨씬 더 많은 에너지를 사용합니다. 실제로, 에너지의 90%가 제공하는 데 사용된다고 추정됩니다. AI의 전기 수요는 산업과 발걸음을 맞추기 위해 데이터 센터의 2배 증설이 필요하다는 의미입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n미국에서는 AI가 막대한 양의 전력을 필요로 하기 때문에 에너지 수요를 충족하기 위해 여전히 오래된 석탄 발전소가 필요합니다. 정말 무서운 일이죠!\n\nOpenAI와 Google과 같은 기업은 자사 모델의 환경 영향을 일반적으로 공개하지 않습니다. 현재까지는 추측과 예측만 있습니다. 나는 대규모 AI 모델에 대한 환경 영향 보고가 규제되어야 한다고 생각합니다.\n\n# 지난 수십 년간의 추이\n\n최근 몇 년간 화석 연료의 증가 추세가 있는지 확인하기 위해 지난 10년간의 에너지 소비를 더 자세히 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n풍력 및 태양 에너지와 같은 재생 에너지 생산을 더 싸고 매력적으로 만드는 기술들도 있습니다. 많은 사람들이 친환경적인 솔루션을 선호하면서 전기 자동차가 많은 유럽 국가에서 일상적인 것으로 자리 잡았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모든 것이 잘되었다는 것을 의미하는 것은 아니며, AI 모델의 발전이 환경에 눈에 띄는 피해를 일으킨 적이 없다는 것은 아닙니다. 이것은 앞으로 몇 년 동안 더 명백하게 관찰될 수 있을 것으로 예상됩니다.\n\n# 결론\n\n우리가 본 바와 같이, 우리가 조심하지 않으면 AI는 이중날을 수도 있습니다. 현재는 혜택이 비용을 상쇄하는지에 대해 명확한 증거가 충분하지 않습니다.\n\n한편, 데이터는 우리가 아무것도 하지 않으면 기후 변화가 어떻게 진행될지 명백하게 보여줍니다. 그러나 우리는 해결책과 인간의 창의력에 한이 없음을 보았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n많은 개인, 스타트업, 그리고 기관들이 기후 위험의 다양한 측면을 해결하기 위해 노력하고 있어요.\n\n이것이 저에게 매우 긍정적인 느낌을 줍니다. 세상을 바꾸고 싶다면, 먼저 변화가 가능하다고 믿어야 하며 어떤 문제도 해결하기에는 너무 크지 않다고 생각해야 합니다. 더 많은 젊은 사람들이 영향력 있는 자리로 진출하면서 기후 변화를 우선순위로 삼고 새로운 해결책에 열을 올리고 있어요. 기대를 해봅니다. 수 년 후에는 인공지능이 우리에게 미래 기후를 위한 중요한 한걸음을 내딛도록 도와줄 것이며, 혜택이 실제로 비용을 상회할 것이라고 믿어요.\n\n더 많은 정보를 찾고 싶다면, 아래의 Datalore 노트북에 있는 데이터 보고서를 확인해보세요!\n\n# 데이터 소스\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1. 1850년부터 1900년까지의 전 세계 평균 기온(ºC)\n\n- Met Office: [링크](https://climate.metoffice.cloud/temperature.html#datasets)\n\n2. 지난 800,000년 동안 대기 중 CO2 수준\n\n- 모든 연구: [링크](https://www.ncei.noaa.gov/access/paleo-search/study/17975)\n- 수정된 코어 CO2 데이터 800,000–현재까지(2001): 남극 빙하 코어 수정된 복합 및 개별 코어 CO2 데이터\n- 2002년부터 2023년까지의 기간에는 여기에서 사용 가능한 현대 계기 데이터를 사용해야 합니다: [링크](https://climate.nasa.gov/vital-signs/carbon-dioxide/)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 세계 온실 가스 배출\n\n- [ourworldindata.org/greenhouse-gas-emissions](https://ourworldindata.org/greenhouse-gas-emissions)\n\n4. 국가별 석탄, 석유 및 가스 소비\n\n- [ourworldindata.org/fossil-fuels](https://ourworldindata.org/fossil-fuels)\n- 석탄 소비에 대한 정보: [ourworldindata.org/grapher/coal-consumption-per-capita?tab=chart\u0026country=High-income+countries~Upper-middle-income+countries~Lower-middle-income+countries](https://ourworldindata.org/grapher/coal-consumption-per-capita?tab=chart\u0026country=High-income+countries~Upper-middle-income+countries~Lower-middle-income+countries)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. Antarctic 및 Greenland 빙하의 녹는 얼음 시트: 1992-2020 IPCC AR6를 위한 빙하량 균형\n\n- [https://ramadda.data.bas.ac.uk/repository/entry/show?entryid=77b64c55-7166-4a06-9def-2e400398e452](https://ramadda.data.bas.ac.uk/repository/entry/show?entryid=77b64c55-7166-4a06-9def-2e400398e452)\n- [https://www.epa.gov/climate-indicators/climate-change-indicators-ice-sheets](https://www.epa.gov/climate-indicators/climate-change-indicators-ice-sheets)\n\n6. LLMs 훈련 비용\n\n- [https://tinyml.substack.com/p/the-carbon-impact-of-large-language](https://tinyml.substack.com/p/the-carbon-impact-of-large-language)\n- [https://www.statista.com/statistics/1384418/co2-emissions-when-training-llm-models/](https://www.statista.com/statistics/1384418/co2-emissions-when-training-llm-models/)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nhttps://blog.jetbrains.com에 원래 게시되었습니다. 2024년 4월 10일.\n","ogImage":{"url":"/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_0.png"},"coverImage":"/assets/img/2024-05-18-CanAIFixClimateChangePerspectiveofaDataNerd_0.png","tag":["Tech"],"readingTime":15}],"page":"103","totalPageCount":120,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":5},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"103"},"buildId":"JlBEgQDLGRx6DYlBnT8eD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>