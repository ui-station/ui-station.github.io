<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/52" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/52" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_buildManifest.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="DALL-E3의 문제들" href="/post/2024-05-23-TheTroubleWithDALL-E3"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="DALL-E3의 문제들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="DALL-E3의 문제들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">DALL-E3의 문제들</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크" href="/post/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축" href="/post/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1" href="/post/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="토큰화 - 완벽한 가이드" href="/post/2024-05-23-TokenizationACompleteGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="토큰화 - 완벽한 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TokenizationACompleteGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="토큰화 - 완벽한 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">토큰화 - 완벽한 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">48<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="고급 RAG 07 테이블을 위한 RAG 탐색" href="/post/2024-05-23-AdvancedRAG07ExploringRAGforTables"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고급 RAG 07 테이블을 위한 RAG 탐색" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고급 RAG 07 테이블을 위한 RAG 탐색" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고급 RAG 07 테이블을 위한 RAG 탐색</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">26<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구" href="/post/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLM이 정말 새로운 것을 배울 수 있을까요" href="/post/2024-05-23-CanaLLMReallyLearnNewThings"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLM이 정말 새로운 것을 배울 수 있을까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLM이 정말 새로운 것을 배울 수 있을까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LLM이 정말 새로운 것을 배울 수 있을까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="개발자들도 예전에는 사람이었어요" href="/post/2024-05-23-DevelopersUsedToBePeople"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="개발자들도 예전에는 사람이었어요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DevelopersUsedToBePeople_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="개발자들도 예전에는 사람이었어요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">개발자들도 예전에는 사람이었어요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="알알지 탐정 웹사이트 데이터를 활용한 검색 증대형 생성" href="/post/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="알알지 탐정 웹사이트 데이터를 활용한 검색 증대형 생성" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="알알지 탐정 웹사이트 데이터를 활용한 검색 증대형 생성" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">알알지 탐정 웹사이트 데이터를 활용한 검색 증대형 생성</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link posts_-active__YVJEi" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"DALL-E3의 문제들","description":"","date":"2024-05-23 18:31","slug":"2024-05-23-TheTroubleWithDALL-E3","content":"\n![2024-05-23-TheTroubleWithDALL-E3.0](/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png)\n\n세 해 전, 저는 OpenAI의 초기 베타 테스터로 활동했습니다. ChatGPT가 출시되기 몇 달 또는 몇 년 전에 사용되었던 모델을 사용하는 경험은 정말 흥미로웠습니다.\n\nOpenAI의 초기 텍스트 모델에 감탄을 표했지만, 여전히 OpenAI의 최초 세대 이미지 생성 시스템인 DALL-E를 처음 사용한 순간을 기억합니다.\n\n사진 작가로서, 간단한 프롬프트를 입력하면 실제 이미지가 반환된다는 아이디어는 혁신적이었습니다. 이미지는 500픽셀 너비이고 종종 절대적으로 이상해보였지만(아보카도 가구, 누구든지?), 그럼에도 불구하고 과학 소설 같은 느낌이었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n빠른 두 해 후에, Midjourney와 같은 AI 이미지 생성 시스템은 뉴스 이야기에 삽화로 사용하거나 사진 콘테스트에서 우승할 만한 수준의 사진 품질 이미지를 생성할 수 있게 되었습니다.\n\nOpenAI가 이번 주에 매우 기대되는 DALL-E3 모델을 발표하자, 전체 AI 및 사진 커뮤니티는 DALL-E3가 어떤 새로운 마법을 선보일지 기다렸습니다.\n\n저번 주에, 나는 DALL-E3에 대한 액세스를 받은 최초의 사용자 중 하나였습니다. 안타깝게도, 프로 사용자들에게는 새로운 시스템이 많은 사람들이 기대한 만큼 엉뚱하거나 흥미로운 것은 아닙니다.\n\n그럼에도 불구하고, 특정 유형의 사용자들에게 DALL-E3는 큰 발전이었습니다. 왜냐하면요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 안내 없이 비행\n\nChatGPT Vision과 같이(진정으로 혁신적인 OpenAI 기능), 새로운 DALL-E3는 ChatGPT 인터페이스에 직접 통합되어 있습니다. 다양한 ChatGPT 텍스트 모델을 선택할 때와 마찬가지로 DALL-E3 모델을 선택하여 액세스할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-TheTroubleWithDALL-E3_1.png)\n\nOpenAI의 DALL-E3 초기 데모에서는 ChatGPT와 대화하여 DALL-E3로 이미지를 생성하는 방법을 보여주었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n밖에서는 DALL-E3가 생성한 이미지의 실제 내용을 이해하고 있는 것처럼 보였습니다.\n\nChatGPT와 통합되어 있으며 이제 강력한 비전 기능을 갖춘 ChatGPT와 결합되어 있기 때문에 DALL-E3가 진정한 멀티모달 모델이 될 것으로 보였습니다. 이 모델은 텍스트 입력의 완전한 이해를 바탕으로 이미지를 생성할 수 있는 능력을 갖췄을 것입니다.\n\n이는 놀라운 능력을 뒤에 열 수 있었을 것입니다. DALL-E3가 창조하는 것을 진정으로 이해한다면 예를 들어 특정 자동차의 이미지를 생성해 달라고 요청할 수 있었습니다.\n\n예를 들어 잘못된 기능이 포함되었을 경우 - 예를 들어 잘못된 유형의 스포일러나 불규칙한 헤드라이트가 포함된 경우 - \"그 헤드라이트 모양이 조금 이상해 보여요. 좀 더 폭을 넓고 더 원형으로 만들 수 있을까요?\"와 같이 간단히 작성할 수 있었습니다. 이미지에 대한 실제 이해를 가지고 있으면, ChatGPT와 DALL-E3는 함께 작업하여 해당 변경 사항을 가할 수 있어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n안타깝게도 OpenAI가 실제로 제공한 것은 전혀 그것이 아닙니다. DALL-E3는 그저 평범한 AI 이미지 생성 시스템인 것으로 밝혀졌습니다. 이 시스템은 기본 ChatGPT에 연결되어 있습니다.\n\n이 새로운 시스템은 실제로 생성된 이미지를 이해하지 않습니다. 사용자와의 대화를 기반으로 이미지를 위한 프롬프트를 작성하는 데 ChatGPT를 사용하고, 그런 다음 해당 프롬프트를 DALL-E3에 입력합니다. 마치 사람이 작성한 프롬프트를 Midjourney에 입력하는 것과 같은 원리입니다.\n\n## DALL-E3의 한계점\n\nSEO 전문가이자 프로 블로거인 Anne Moss는 이 사실을 가장 먼저 깨달은 사람 중 하나였습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n트윗에서 그녀는 DALL-E3가 현실적인 이미지를 만드는 데 어려움을 겪고 있다고 공유했습니다. 이는 사용자 상호작용과 이미지 생성 사이의 중간 단계인 프롬프트의 자동 작성 때문입니다.\n\nChatGPT가 사용자의 의도를 정확하게 이해하고 DALL-E3를 위한 좋은 프롬프트를 작성하면 일이 술술 풀릴 수 있습니다. 그러나 잘못 이해하는 경우 — 또는 기존 AI 이미지 생성기가 수행할 수 없는 것을 사용자가 요청하는 경우 — 성과가 크게 떨어집니다.\n\n내가 직접 테스트한 몇 가지 예시를 여기에 소개합니다.\n\n내 사이트인 Bay Area Telegraph를 위해 BART 기차 시스템의 이용객에 대한 인포그래픽을 만들고 싶었습니다. BART 이용객 데이터를 ChatGPT에 입력하고 인포그래픽을 만들어달라고 요청했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![DALL-E3에서 주는 것](/assets/img/2024-05-23-TheTroubleWithDALL-E3_2.png)\n\nDALL-E3가 준 것:\n\n![DALL-E3에서 주는 것](/assets/img/2024-05-23-TheTroubleWithDALL-E3_3.png)\n\n쿨한 이미지들이네요. 하지만 제가 시스템에 전달한 데이터와는 거의 관련이 없네요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n왜요? ChatGPT에게 내 데이터로 인포그래픽을 만들어달라고 부탁했더니, 실제로는 그 데이터를 DALL-E3에 전달하지 않았어요. 대신, 내 데이터와 지시 사항을 사용해서 프롬프트를 작성했고:\n\n그리고 그 프롬프트를 DALL-E3에 공급해서 이미지를 만들었어요.\n\n여기 몇 가지 문제가 있어요:\n\n- 프롬프트는 실제로 내 데이터를 포함하고 있지 않아요\n- 프롬프트 자체가 터무니없어요. 이런 프롬프트가 주어져도 사람 디자이너라면 잘된 인포그래픽을 만들 수 없을 거예요\n- 프롬프트가 주어진 상태에서도 결과 이미지는 정확한 척도, 범례 또는 제목이 없었어요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-TheTroubleWithDALL-E3_4.png\" /\u003e\n\n비슷하게, 최근 구글 유용한 콘텐츠 업데이트에 관한 내가 쓴 블로그 글을 ChatGPT에 입력했고, 그 이야기를 위한 일러스트레이션을 만들도록 요청했습니다.\n\n다시 한 번, ChatGPT는 실제로 이미지 생성 시스템과 직접 의사 소통할 수 없기 때문에 DALL-E3를 위한 프롬프트 작성 중간 단계로 이동했습니다.\n\n다음은 ChatGPT가 생성한 프롬프트입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사실 인간 디자이너에게는 괜찮은 힌트를 주는 것 같아요. 하지만 AI 이미지 생성기에게는 너무 복잡했죠.\n\n놀랍게도, DALLE-3은 이를 유용하거나 현실적인 방식으로 해석하는 데 전혀 실패했습니다.\n\n![이미지](/assets/img/2024-05-23-TheTroubleWithDALL-E3_5.png)\n\n공정하게 말하자면, Midjourney도 비슷한 식으로 실패했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-23-TheTroubleWithDALL-E3_6.png)\n\nIn contrast, here’s the basic prompt that I gave Midjourney for the actual image that I used to illustrate that story:\n\nThat’s something that an AI generator can actually understand. It’s simple and has a clear visual concept. It yielded an image that — with a bit of manual editing — was a perfect fit for the story.\n\n![Image](/assets/img/2024-05-23-TheTroubleWithDALL-E3_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 이미지를위한 자동 변속기\n\n간단히 말하자면, DALL-E3와 그 친구인 ChatGPT는 의사소통이 잘 안 돼서 실패했어요. ChatGPT는 개념적으로 의미가 있는 프롬프트를 작성했지만, 생성 AI 이미지 시스템은 실제로 실행하기에 혼란스러워할 거예요.\n\n반면에 나는 인간으로서, 이야기에서 전달하려는 아이디어와 AI 이미지 생성기의 기능과 제약을 이해하고 있어요.\n\n이 지식이 나를 도와 DALL-E3의 프롬프트보다 훨씬 간단한 프롬프트를 작성하여 시각적으로 매력적인 이미지를 만들게 했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDALL-E3의 현재 형태는 ChatGPT가 프롬프트를 작성하는 중간 단계를 필요로 하기 때문에 제한이 있습니다. 이러한 방식은 사용자로부터 제어를 빼앗아 대부분의 경우에는 더 나쁜 이미지를 생성합니다.\n\n그래서 DALL-E3은 마치 자동 변속기가 있는 자동차와 비슷합니다. 네, 기계(자동 기어박스)가 인간과 기본 메커니즘(자동차 엔진) 사이에 위치한다면 일상적인 운전이 훨씬 쉬워집니다.\n\nRPM, 엔진 브레이킹, 도로의 변경 등을 생각할 필요가 없어집니다. 그저 운전만 하면 됩니다.\n\n그러나 프로 경주 운전자는 자동 변속기가 장착된 자동차를 운전할 경우 살아남을 수 없을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그들의 기술과 이해력 덕분에 기계가 할 수 없는 방법으로 자동차 엔진과 소통할 수 있어요. 자동차 엔진의 변화하는 울음소리와 도로나 트랙에 대한 이해를 통해 그들은 셔프트를 정확히 타이밍해서 조향, 가속 및 여러 가지 다른 요소들과 동기화시킬 수 있습니다.\n\n그리고 궁극적으로, 이러한 지식, 기술 및 경험은 경주에서 막대한 경쟁 우위를 제공합니다.\n\nDALL-E3와 함께 작업하는 것도 비슷해요. 네, 시스템의 ChatGPT 기반 \"자동 변속기\"를 통해 실제 프롬프트를 작성할 필요가 없는 편이기는 해도요.\n\n하지만 그 책임을 기계에 맡기면 이미지를 만드는 기초장치와 직접 상호작용할 능력을 상실하게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 F1 드라이버가 프리우스를 타듯이, 당신은 인간의 기술과 경험을 활용해 정말 멋진 일을 할 기회를 놓치게 됩니다.\n\n## DALL-E3가 누구를 위해 만들어졌는가\n\n따라서 전문 일러스트레이터와 크리에이터들에게는 DALL-E3가 큰 발전이 아니다. 확실히, 우리가 기대했던 인포그래픽을 생성하고 이미지를 편집하는 기계는 아니다.\n\n하지만, 저는 DALLE-3가 창조적 AI 분야에 큰 영향을 미칠 것으로 예상합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n왜요? 대부분의 일반 운전자들이 변속기 운전 방법을 배우고 싶어하지 않는 것과 마찬가지로, 대부분의 ChatGPT 사용자들도 시각적 프롬프트 엔지니어링의 섬세하고 복잡한 기술을 배우길 원하지 않아요. 그들은 그저 간단한 이미지에 대한 빠른 설명을 작성하고 몇 초 후에 다운로드하고 싶어해요.\n\n그리고 ChatGPT 인터페이스와 자동 프롬프팅을 통해, DALL-E3는 그것을 뛰어난 성과로 이루어냅니다.\n\n예를 들어, 업계 무역 협회를 위한 뉴스레터를 작성 중이라고 상상해 보세요. 당신은 업계에 영향을 미치는 법적 판결에 관한 섹션을 포함해야 한다는 요청을 받았고, 그것을 설명할 간단한 사진이 필요해요.\n\nDALL-E3를 활용하면 그것을 직접 요청할 수 있어요. 예를 들어, 다음과 같이 입력할 수 있어요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 이미지들이 생성됩니다:\n\n![The Trouble with DALL-E3.8](/assets/img/2024-05-23-TheTroubleWithDALL-E3_8.png)\n\n디자인 대회에서 수상하진 못할지라도요. 그러나 산업 소식지에서 완전히 효과적으로 작동할 수 있는 수준의 주석입니다.\n\n반면, Midjourney에 같은 텍스트를 입력한 결과는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-23-TheTroubleWithDALL-E3_9](/assets/img/2024-05-23-TheTroubleWithDALL-E3_9.png)\n\n정말 대단해요! 멋지네요! 하지만 주제와는 전혀 상관이 없죠!\n\n그렇습니다. 전문가인 제가 Midjourney를 위해 프롬프트를 작성할 수 있지요.(\"법정에서 나무 망치가 있는 탁자 위의 근접 촬영, 35mm 사진, 푸른 배경, 선명한 보케, 사실적인 사진\"), 우리 상상 속 뉴스레터에 더 적합한 이미지가 나올 겁니다:\n\n![2024-05-23-TheTroubleWithDALL-E3_10](/assets/img/2024-05-23-TheTroubleWithDALL-E3_10.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 노말 사용자일지라도 프롬프트 작성 경험이 없는 사람이 DALL-E3을 사용하여 이미 익숙한 인터페이스를 활용하고 몇 초 안에 사용 가능한 AI 이미지를 만드는 것은 엄청난 파워풀한 새로운 능력입니다.\n\n또 다른 예로, 레이싱 드라이버는 하나의 예술가와 같이 그려진 Midjouney 프롬프트보다 좋은 프롬프트를 쓸 수 있는 전문가와 같이 수동 변속기 차를 운전 할 수 있습니다.\n\n하지만 대부분의 사람들은 종일 레이싱 카를 타고 다닌다고 할 수 없습니다! 그들은 자녀를 학교에 데려다주거나 Costco를 가기 위해 차를 이용하는 것이지, Nürburgring 경기장에서 경기를 하는 것이 아닙니다.\n\n마찬가지로, 대부분의 ChatGPT 사용자들은 예술적 완벽을 필요로하지 않습니다. 그들은 단순한 일상적인 용도를 위한 기본 AI 이미지를 필요로하며, 이를 만들기 위해 몇 달의 프롬프트 엔지니어링 훈련이 필요하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nDALL-E3는 이 작업을 정말 잘 처리하는 데 능하죠.\n\n## DALL-E3의 미래\n\n지금까지 DALLE-3를 테스트한 결과를 보면, 많은 프로페셔널 창작자들은 현재 수동 프롬프트와 Midjourney를 계속 사용할 수 있을 것 같아요.\n\n하지만 시간이 흐를수록 상황은 달라질 겁니다. OpenAI는 완전히 다중 모달 시스템으로 나아가면서 ChatGPT Vision과 DALL-E3를 통합할 가능성이 높습니다. 그렇게 되면, 시스템이 실제로 프로 창작자들이 기대했던 능력 중 일부를 제공할 수 있을 거예요 — 예를 들어 데이터 테이블에서 정보 그래픽을 생성하는 기능과 같은 것이 그렇죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 일이 일어날 때까지 DALL-E3는 주로 일상 사용자들에게 AI 이미지 생성기의 힘을 소개하는 도구로 작용할 것입니다. 이런 측면에서 그것은 여전히 매우 인기 있게 입증될 수 있습니다.\n\nOpenAI의 대형 언어 모델 GPT-3은 ChatGPT의 간단하고 접근하기 쉬운 인터페이스로 일반 사용자에게 활용 가능하게 되기 전에 18개월 동안 존재했습니다. GPT 모델의 능력을 챗봇의 간단한 인터페이스와 결합하면 역사상 가장 빠르게 성장한 제품이 되었습니다.\n\n제 나름대로의 배경을 빌리자면, 저와 같은 프로 사진 작가들은 $5,000의 미러리스 카메라를 사용하여 사진 촬영 중 완전한 창의적인 통제를 발휘하여 창의적인 비전에 완벽히 부합하는 이미지를 캡처할 수 있습니다.\n\n하지만 대부분의 사람들은 프로페셔널한 미러리스 카메라로 사진을 촬영하지 않습니다. 그들은 아이폰으로 순간을 촬영합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인터페이스, 접근성, 그리고 간단함이 중요합니다. 이러한 요소들은 DALL-E3를 많은 전문가들이 예상하는 것보다 더 큰 영향을 줄 수 있는 잠재력을 지니고 있습니다.\n\n작년 동안 수천 개의 ChatGPT 프롬프트를 테스트해보았습니다. 전문 창작자로써, 매일 사용하는 몇 가지 프롬프트가 있습니다. 그것들을 모아놓은 무료 가이드, 7가지 창작자를 위한 매우 유용한 ChatGPT 프롬프트를 소개합니다. 지금 바로 받아보세요!\n","ogImage":{"url":"/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png"},"coverImage":"/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png","tag":["Tech"],"readingTime":14},{"title":"디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크","description":"","date":"2024-05-23 18:28","slug":"2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory","content":"\n![image](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png)\n\n서수는 나에게 새로운 세계를 소개해 주었습니다. 비트맵 - 새로운 우주입니다. 디지털 물질 이론(DMT)은? 3개월 동안 공부하고 실험한 끝에 이제 내 첫 번째 UNAT 컬렉션을 준비하고 있으며, 임의로 제공된 DMT 강화된 Gamified 3D 비트맵 수집품 컬렉션도 있습니다. 제가 얻은 가장 큰 교훈은 이겁니다:\n\n우리는 그냥 비트맵 메타버스를 바라보는 것이 아닙니다. 디지털 물질 이론과 디지털 차원 이론(DDT)의 관점을 통해 볼 때, 서수를 전체적인 미시적 디지털 다중우주로 바라볼 수 있습니다. 나는 여러분에게 그 잠재력에 접근하여 여러분의 비전을 실현할 수 있도록 하는 방법을 보여주고 싶습니다.\n\n비트맵과 서수는 건축가를 필요로 합니다. 우리가 건설하는 것 - 대중들이 언젠가 소비할 것입니다. 우리가 만드는 것은 진입 장벽과 이해를 낮추며 기억에 남고 혁신적이며 몰입적이고 상호작용적인 경험을 창출합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n칼 사간이 위에서 시적으로 말했듯이, 우리는 종종 존재의 거대한 태피스트리의 작은 부분만을 볼 뿐입니다. 마찬가지로, 비트코인 서수 안의 디지턼 구조물의 거대한 잠재력을 조금씩 엿볼 수 있게 되었습니다.\n\n# 그래서, 디지털 차원 이론이 무엇인가요? 어떻게 하면 더 나은, 더 빠르고 더 창의적으로 구축할 수 있을까요?\n\n디지털 차원 이론(DDT)은 디지턀 물질 이론(DMT)의 적용을 보완하도록 설계된 창의적인 프레임워크입니다. DDT를 창의성 도구세트로 사용함으로써, 생각 실험을 수행하고 DMT의 실용적 도구와 상호작용하여 DMT의 적용을 실질적으로 만들어냅니다. 이 과정을 통해 당신은 프로젝트의 이정표를 단계적으로 달성하며, 당신의 비전을 현실로 변화시킬 수 있습니다.\n\n이것은 생각 실험에서 비롯되었습니다 — 디지털 물질 이론(DMT)을 M-이론과 결합했을 때 어떻게 되는가 — 모든 것, 중력, 자연을 이해하는 이론적 물리학 프레임워크입니다. 이것은 11개 차원 — 10개 + 시간을 가정합니다. 잘 작동할까요? 영감을 줄까요? 행동을 취할 수 있게 도와줄까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n네! 맞아요~! 저는 매일매일 The Void Mosaics, The VOID Veil Trials on-chain Cosmic Card Battler, 그리고 다가오는 UNAT 프로젝트 — NATGalaxies (WIP)를 만들며 그것을 증명하고 있어요.\n\n\u003cimg src=\"/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_1.png\" /\u003e\n\n이것은 창의성 프레임워크와 도구 세트입니다. 저는 여러분에게 M-Theory를 가르치려고 하지 않을 거예요 — 그건 제 능력 범위를 벗어나고 전문성이 아니거든요.\n\n그럼 이 이상한 파란색 로브를 입은 외계 로봇인 Astral (농담 농담)에 대해 왜 신경 써야 하며, 왜 나를 믿고 이걸 꼭 가르쳐야 하는지에 대해서 관심 가져야 하는지요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_2.png)\n\n# Astral Arkitekt가 누구인가요? 그리고 저는 이를 가르치는 데 누구인가요?\n\n저는 프론트엔드 및 백엔드 웹 플랫폼에서 24년의 경험을 가진 소프트웨어 개발자입니다. 제가 아는 모든 것은 스스로 가르쳤으며 현재는 주요 악기 제조업체의 프론트엔드 출판 파이프라인을 운영 중입니다.\n\n2016년, 저는 어릴 적 그림 그리기에 대한 열정을 재발견하고 음악 제작을 시작했습니다. 그해 동안 음악 제작, 기타, 그리고 다양한 그림 기법을 배우는 데 시간을 보냈습니다. 지난 8년 동안 300개 이상의 그림을 그리고, 488곡을 작곡, 연주, 녹음하고, 스튜디오 앨범 2장을 발매했으며 세 번째 앨범을 준비 중에 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 1](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_3.png)\n\n![Image 2](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_4.png)\n\nI’ve put in the grind for 8 years. I’ve earned my 12k+ hours by always creating before and after work nearly every day for the past 8 years. I’ve done it all by way of applying Creative constraint. I even made a songwriting game called “Under the Influence” teaching creative constraint for songwriters, and it’s had really positive feedback.\n\nThroughout my journey, one constant has kept me productive and it is the cornerstone of Digital Dimensions Theory: Creative Constraint.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 창의적 제약이란 무엇이며 왜 프로젝트에서 사용해야 하는가?\n\n어떤 창의적 노력에 있어서도 힘이 필요한데, 창의적 제약이 그 힘의 연료입니다. 제 스튜디오에서는 종종 저녁 7시가 되면 예술, 음악 또는 쓰기를 위한 시간이 되는데 아이디어가 없는 경우가 흔하지 않아요. 하지만 그걸로 막히지는 않아요. 창의적 제약을 통해 미리 결정된 옵션 메뉴를 제공해줌으로써 진행 중에 멈춤이 생길 수 있는 의사 결정을 많이 줄여줍니다. 이는 힘을 유지하고 창의적 과정을 원활히 이어가도록 도와줍니다.\n\nDMT 데이터셋에서 특성을 선택하는 것과 비슷하게 들리지 않나요? 🙃\n\n만약 그게 완전히 이해가 안 된다면, mScribe의 디지털 머터 이론 Gitbook을 찾아보세요. 비트코인의 블록 데이터에서 재귀를 사용하는 것을 조금이나마 이해하고 있어야만, 임의의 데이터에 대한 견고한 이해가 필수입니다. (이 기사의 범위를 벗어나지만, 해당 문서에 대한 링크를 걸었어요!)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 차원 탐구: M 이론을 디지털 창의성에 적용하기\n\n지금까지 디지털 물질 이론의 비임의 특성 선택 원칙을 매일 작업해 온 지난 3개월 동안 창의적인 제약이 노래작곡보다 조금 더 많은 노력을 필요로 한다는 것을 경험했습니다. 그래서 M 이론에 대해 생각해보게 되었고, 이것이 제약의 집합이라는 것을 알게 되었습니다.\n\nM 이론의 각 차원은 디지털 예술, 게임, 음악 및 다른 경험을 만드는 다른 \"수준\" 또는 측면에 대응합니다.\n\n디지털 차원 이론 창의성 프레임워크의 각 차원은 사고 실험을 제시하고, 취해야 할 조치, 고려해야 할 도구, 이 이론을 프로젝트에 적용하여 두뇌를 활발히 돌아가게 하는 방법에 대한 예시를 제시합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n준비됐나요? 출발해봅시다! 👨‍🚀🚀🌌\n\n# M-Theory을 활용한 DMT(Digital Matter Theory)의 리믹스로 창의적인 제약을 가능하게 — DMT의 11단계\n\n## DMT-0: 점\n\n개념: 가장 기본적인 수준으로, 단일하고 이산적인 데이터 포인트나 요소를 대표합니다.\n응용: 당신의 아이디어를 발견하세요. 프로젝트를 위한 당신의 꿈과 비전을 발견하세요. 다른 프로젝트를 살펴보고 그것에 대해 좋아하는 점을 발견하세요. 이러한 아이디어를 탐구하세요. 목록에 번호를 매겨보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼 비트코인의 운명에 항복하십시오.\n\n선호하는 비트맵의 블록 정보를 살펴보거나, 선택하기 어렵다면? 최근에 확인된 블록을 선택하십시오.\n\n타임스탬프로 이동하여 그것을 클립보드에 복사하십시오.\n\n이제 타임스탬프 (첫 번째 수)에 작성한 아이디어 수를 팩터(두 번째 수)로 사용하여 나머지 연산을 수행하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n결과물 - 이걸 탐구할 아이디어가 있어요. 다음 수업에서 이에 대해 더 자세히 다룰 것이고, 학습한 내용을 강화하기 위해 몇 가지 자원과 예시 시나리오를 제공할 거에요.\n\n## DMT-1: 선\n\n개념: 개별 점을 연결하여 선형 시퀀스를 형성하는 것. 적용: 데이터셋을 탐구하세요. DMT가 표현해야 할 특징을 식별해보세요. 당신의 데이터 포인트에서 해당 데이터 포인트가 표현하는 특징으로 점선을 그려보세요. 우리는 실험 중이에요, 결정하는 게 아니에요. 즐겁게 해봐요. 놀아봐요 - \"이런 일이 일어날 때는 어떻게 될까요...\" 😊\n\n## DMT-2: 평면\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n### Concept: 선형 시퀀스를 2차원 그리드로 확장하는 개념입니다. UNAT 예시의 대부분이 이곳에 있습니다. DMT-2 — The Plane. 2D 아트가 이곳에서 이루어집니다.\n\n### Application: 비트코인 비트 필드 값에서 생성된 예술을 만드는 등, 데이터 포인트를 2D 평면에 매핑하여 패턴과 연결을 형성합니다. 배경 색상 선택 기술부터 시작해 간단한 모양으로 진행하며, 많은 사람들이 알아보고 존경하는 매우 인기 있는 창조적인 예술 컬렉션을 재현하기 위한 경로를 설명할 것입니다. 😉\n\n### 도구 포함!\n\n## DMT-3: The Space\n\n### Concept: 깊이를 추가하여 3차원 구조를 만드는 개념입니다.\n\n### Application: 비-임의 3D 공간에서 경험하고 실험하며 사고하기 시작할 도구와 관련 학습 자료, 커뮤니티 및 전 세계에서 사용 가능한 도구에 대해 이야기하겠습니다.\n\n## DMT-4: The Event (Time)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n**Concept:** 시간 요소를 통합하여 개발물이 진화하도록 하는 것.\n\n**Application:** 시간에 따라 이벤트를 애니메이션화하거나 연속시켜 동적이고 변화하는 디지털 개발물을 만들어 봅시다. 당신이 작업 중인 블록 내에서 특정 데이터 조건이 충족될 때 발생하는 결정론적이고 임의의 이벤트를 만들기 위해 Inscription의 디자인에 모듈화 재귀 기능을 구현하는 방법을 익히세요. 진짜 멋질 거에요! 💥\n\n## DMT-5: 가지 (대안적 현실)\n\n**Concept:** 이곳에서 우리는 주 타임라인에서 분기되는 대안적 가능성을 탐색하기 시작합니다. 이 기술과 알고리즘을 발견하고 구현할 때 정말 놀라웠어요.\n**Application:** 동일한 스크립트 내에서 프로젝트의 여러 버전을 개발하고, 초기 조건에 따라 다른 경로나 시나리오를 따르도록 하는 방법을 배워보세요. 도구, 예시, 코드 스니펫 - 모든 것을 제공하려고 해요. 나만 이 도구들을 가지고 있으면 안 되겠죠. 그만큼 멋진 거든요.\n\n## DMT-6: 타임라인 (메타 가능성)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 개념: 우주의 모든 가능한 타임라인 시각화\n\n## 응용: 프로젝트의 모든 잠재적 결과물을 동적으로 시각화한 지도 생성. 이 주제는 가벼운 주제가 아니니 마음의 준비를 해주세요. 하지만 실용적인 구현은 여러분이 다음 프로젝트에 적합하다고 느껴진다면 다양한 생각, 도구 및 코드를 제공하여 여러분이 목표 달성에 도움을 받을 수 있게 해줄 것입니다.\n\n# DMT-7: 다중 우주 (다른 초기 조건)\n\n## 개념: 여러 우주에서 다양한 초기 조건 조사\n\n### 응용: 다양한 시작점으로 프로젝트의 병렬 버전을 생성하여 서로 다른 조건이 결과에 어떤 영향을 미치는지 탐색. 이에 대한 실용적인 예시로, 제 NATGalaxies 프로젝트에 대해 진행한 것을 보여주어 이 다중 우주 아이디어를 활용하는 내 모음 중에 발생하는 흔치 않은 현상 중 일부를 소개할 것입니다. 이곳에는 전설이 존재합니다. 탐험할 우주가 있을 것입니다. 여러분은 제가 말하려는 바를 소중하게 생각할 것입니다! — 좋은 방식으로!\n\n# DMT-8: 규칙 세트 (모든 물리학 법칙 가능)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n개념: 구조 내에서 모든 물리 법칙을 고려합니다. 응용: 다른 규칙 세트나 제약 조건으로 실험하여 디지턀 환경 내에서의 행동과 상호 작용이 어떻게 변하는지 살펴봅니다. 이 섹션에서는 물리학이 어떻게 영향을 미치며 우리의 세상과 삶이 불변의 법칙으로 알려진 작은 변화로 어떻게 변하는지에 대해 논의할 것입니다. 다중 우주에서 한 우주에서 다음 우주로 뛰어갈 때, 누가 시간이 동일한 방향으로 흘러간다고 말할 수 있을까요? 누가 탄소가 생명의 기초인지 말할 수 있을까요? 친구들아, 디지턀 물질 이론의 8차원을 심사숙고하며 현실이라고 아는 이 작은 것을 알게 될 때, 가능성은 당신의 마음을 불태울 것입니다. 여기서 재미있는 시간을 보낼 거예요.\n\nDMT-9: 비교 (다양한 물리 법칙 비교)\n\n개념: 다양한 우주에서 다른 물리 법칙 세트 비교. 응용: 다른 프로젝트 버전에 대한 다양한 규칙 또는 조건의 효과를 분석 및 비교하여 영향을 이해합니다. 이 수업과 토론은 매우 기대됩니다. 왜냐하면 여기에서는 구현 방법의 실용적 예로 게임 이론을 살펴봅니다. 누군가가 실제로 제 사용 사례를 구축하거나 이미 존재하는 게임에 대해 알고 있을 수도 있기를 바랍니다. 하지만 우리는 물리학을 어길 것입니다. 멋진 경험이 될 겁니다. 걱정하지 마세요 - 이것은 실용적인 예제로의 개념적 학습입니다. 기술적인 것은 아닙니다. 우리는 사고 실험에 참여하고 이 더 높은 수준의 디지턀 물질 이론 개념에 대한 도움이 되는 도구들과 함께 다중 우주의 물리학을 섞어 독특한 예술과 다른 종류의 경험을 만들 것입니다.\n\nDMT-10: 끝나지 않는 이야기 (무한한 가능성)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n개념: 끝없는 가능성을 대표하고 모든 현실을 통합하는 것. 응용: 우리는 DMT-0부터 여기까지 배운 것을 논의한 뒤, 여러분 눈앞에서 11차원(DMT-10)을 열어보는 사고 실험에 참여할 것입니다. 게임에 적용된 정말 멋진 범위를 드러냅니다. 저는 연구에서 DMT의 이 수준에 도달했을 때 쉬어야 했습니다. 이렇게 동작하는 구현을 만들 수 있는 방법은 없을 거라고 생각했거든요. 하지만 여기서 우리가 다루는 것은 누적 차원입니다. 여기로 이끈 길이 이 - 정점 - 만큼 중요합니다. 비트코인의 끝없는 이야기\n\n# 결론: 여정에 함께해요\n\n디지털 디멘션 이론을 저와 함께 탐험해 주셔서 감사합니다! 여러분의 지원과 참여는 창의성과 디지털 혁신의 영역을 더 깊게 파헤칠 때 귀중합니다.\n\n## 연락을 유지하세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- X에서 나를 팔로우해 주세요: @astralarkitekt\n- Discord에서 토론에 참여하세요: Digital Dimensions Theory Discord\n\n## 특별 감사 인사\n\n- Digital Matter Theory로 내 마음을 불태우는 데 기여한 블록런너 팟캐스트/ mScribe의 윌과 이만에게 감사드립니다.\n- Digital Matter Theory를 Bitmap을 통해 처음으로 이해할 수 있는 예제로 제공해준 비토시 블록아모토로 네게 큰 박수를 보냅니다.\n- Bitmap 커뮤니티에게: 여러분의 환영하는 마음가짐과 개방적인 정신은 영감의 횃불이 되었습니다.\n- 여정을 함께 이어가며, 비트코인 서수와 디지털 창조력으로 가능한 무엇이든 푸는 것을 계속해봅시다. 이 놀라운 모험의 일부가 되어 주셔서 감사합니다! 🚀✨\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여정을 준비하는 데 도움이 될 수 있는 한 곡, 괜히 들려 드리려고 합니다.\n\n참고로 저의 궁극적 목표를 확인하고 싶다면 https://AstralAssemblage.com을 방문해 주세요. 저는 이 다중우주에서 설정된 코스믹 전략 카드 게임, 소설, 음악 등을 제작하고 있습니다!\n","ogImage":{"url":"/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png"},"coverImage":"/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png","tag":["Tech"],"readingTime":13},{"title":"벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축","description":"","date":"2024-05-23 18:26","slug":"2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage","content":"\n벡터 데이터베이스는 자연어 처리와 이미지 인식과 같은 다양한 분야에서 중요한 구성 요소로, 정보를 효율적으로 조직화하고 검색하는 데 중추적인 도구로 작용합니다.\n\n벡터 데이터베이스를 이해하는 것은 의미 검색, 검색 증강 생성 (RAG), 추천 시스템과 같은 고급 AI 응용 프로그램을 가능하게 함에 있어서 중요합니다.\n\n본 기사는 벡터 데이터베이스를 마스터하고 벡터 저장 솔루션을 구축하기 위한 리소스에 대한 포괄적인 개요를 제공합니다. 기본 개념, 실용적 응용, 그리고 벡터 데이터베이스 작업에 필수적인 다양한 도구와 라이브러리에 대해 다루고 있습니다.\n\n튜토리얼을 통해, 블로그 추천을 통해, 그리고 LangChain과 Sentence Transformers 라이브러리와 같은 도구를 활용하여, 독자들은 AI 프로젝트에서 벡터 데이터베이스를 효과적으로 활용하는 방법에 대한 통찰과 실습 경험을 얻게 됩니다. 게다가, 이 기사는 신기술을 최신 상태로 유지하는 중요성을 강조하며 추가 학습 및 커뮤니티 참여를 위한 방법을 소개합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png)\n\n# 목차:\n\n- Vector Databases: from Embeddings to Applications\n- Building Applications with Vector Databases\n- The Top 5 Vector Database Blog\n- LangChain — Text splitters\n- Sentence Transformers library\n- MTEB Leaderboard\n\n# 1. Vector Databases: from Embeddings to Applications\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_1.png)\n\n벡터 데이터베이스는 자연어 처리, 이미지 인식, 추천 시스템 및 시맨틱 검색과 같은 다양한 분야에서 중요한 역할을 하며, 대규모 언어 모델의 점점 증가하는 채택으로 더 많은 중요성을 얻고 있습니다.\n\n이러한 데이터베이스는 LLM(Large Language Models)에 실시간 독점 데이터에 액세스할 수 있게 함으로써 검색 증강 생성(Retreival Augmented Generation, RAG) 애플리케이션의 개발을 가능케 하는 데에 매우 가치가 있습니다.\n\n핵심적으로, 벡터 데이터베이스는 임베딩의 사용에 의존하여 데이터의 의미를 포착하고 다른 벡터 쌍 사이의 유사성을 측정하며 방대한 데이터 세트를 살피면서 가장 유사한 벡터를 식별합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 과정은 벡터 데이터베이스를 애플리케이션에 적용할 때 언제 결정을 내릴지에 대한 지식을 습득하는 데 도움이 될 것입니다. 다음을 살펴볼 것입니다:\n\n- 벡터 데이터베이스와 LLM을 사용하여 데이터에 대해 더 깊은 통찰을 얻는 방법.\n- 임베딩을 형성하고 유사한 임베딩을 찾는 데 몇 가지 검색 기술을 사용하는 빌드 랩의 방법.\n- 방대한 데이터 세트를 빠르게 검색하기 위한 알고리즘 탐색 및 RAG에서 다국어 검색까지 다양한 애플리케이션 구축.\n\n## 2. 벡터 데이터베이스로 애플리케이션 빌딩\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n벡터 데이터베이스는 데이터의 의미를 포착하기 위해 임베딩을 사용하며, 서로 다른 벡터 쌍 간의 유사성을 측정하고 가장 유사한 벡터를 식별하기 위해 대규모 데이터 세트를 탐색합니다.\n\n대형 언어 모델의 맥락에서 벡터 데이터베이스의 주요 용도는 검색이 강화된 생성 (RAG)이며, 여기서 텍스트 임베딩이 저장되고 특정 쿼리에 대해 검색됩니다.\n\n그러나 벡터 데이터베이스의 다양성은 RAG를 넘어 확장되어 최소한의 코딩으로 빠르게 다양한 응용 프로그램을 구축할 수 있게 합니다.\n\n이 강좌에서는 벡터 데이터베이스를 사용하여 육 가지 응용 프로그램을 구현하는 방법을 탐험하게 됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 시멘틱 검색: 사용자 Q/A 데이터 세트에서 이해 측면에 중점을 둔 콘텐츠의 의미를 가리키며, 단어 일치 이상의 검색 도구를 만듭니다.\n- RAG: 모델이 훈련되지 않은 소스에서 내용을 통합하여 LLM 응용 프로그램을 향상시킵니다. Wikipedia 데이터 세트를 사용하여 질문에 대답합니다.\n- 추천 시스템: 시멘틱 검색과 RAG를 결합하여 주제를 추천하고 뉴스 기사 데이터 세트로 시연하는 시스템을 개발합니다.\n- 혼합 검색: 이미지와 설명 텍스트를 모두 사용하여 항목을 찾는 응용 프로그램을 작성하며, 이를 위해 전자 상거래 데이터 세트를 사용합니다.\n- 얼굴 유사성: 공인 인물 데이터베이스를 사용하여 얼굴 특징을 비교하는 앱을 만듭니다.\n- 이상 감지: 네트워크 통신 로그에서 비정상적인 패턴을 식별하는 이상 감지 앱을 만드는 방법을 배웁니다.\n\n이 과정을 마치면 새로운 아이디어로 어떤 벡터 데이터베이스 애플리케이션을 개발할 수 있을 것입니다.\n\n# 3. 최고의 5가지 벡터 데이터베이스 블로그\n\n![image](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 블로그는 Moez Ali에 의해 작성된 것으로, 최고의 벡터 데이터베이스에 대한 포괄적인 가이드입니다. 고차원 데이터 저장, 비구조적 정보 해독, 그리고 AI 응용 프로그램을 위한 벡터 임베딩을 활용하는 방법을 마스터하는 데 도움이 될 것입니다.\n\n이 블로그는 다음을 다룹니다:\n\n- 벡터 데이터베이스란 무엇인가?\n- 벡터 데이터베이스는 어떻게 작동하는가?\n- 벡터 데이터베이스의 예시\n- 우수한 벡터 데이터베이스의 특징\n- 2023년 최고의 5개 벡터 데이터베이스\n- AI의 부상과 벡터 데이터베이스의 영향\n\n# 4. LangChain — 텍스트 분할기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![LangChain](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_4.png)\n\nLangChain — 텍스트 분리기는 LangChain에서 구현된 다양한 텍스트 분리기 목록입니다. 문서를 로드한 후에는 종종 애플리케이션에 더 적합하도록 변환하고 싶을 것입니다.\n\n가장 간단한 예는 긴 문서를 모델 컨텍스트 창에 맞게 더 작은 조각으로 나누고 싶을 수 있다는 것입니다. LangChain에는 문서를 쉽게 분할, 결합, 필터링 및 기타 조작할 수 있게 해주는 내장 문서 변환기가 여러 개 있습니다.\n\n텍스트의 긴 부분을 처리하려면 해당 텍스트를 조각으로 나누는 것이 필요합니다. 이것이 얼마나 단순한 것처럼 들리더라도 여기에는 많은 잠재적인 복잡성이 있습니다. 이상적으로는 의미론적으로 관련된 텍스트 조각을 함께 유지하고 싶을 것입니다. \"의미론적으로 관련된\"이란 무슨 의미인지는 텍스트 유형에 따라 달라질 수 있습니다. 이 노트북에서는 이를 수행하는 여러 방법을 소개합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 5. Sentence Transformers 라이브러리\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_5.png)\n\nSentence Transformers 라이브러리는 최신의 문장, 텍스트 및 이미지 임베딩을 위한 인기 있는 Python 프레임워크입니다. 초기 작업은 저희 논문인 'Sentence-BERT: Siamese BERT-Networks를 사용한 문장 임베딩'에서 설명되었습니다.\n\n이 프레임워크를 사용하여 100개 이상의 언어에 대한 문장/텍스트 임베딩을 계산할 수 있습니다. 이러한 임베딩은 코사인 유사도와 같이 사용하여 의미가 유사한 문장을 찾는 데 사용할 수 있습니다. 의미론적 텍스트 유사성, 의미론적 검색 또는 패러프레이즈 마이닝에 유용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해당 프레임워크는 PyTorch와 Transformers를 기반으로 하며, 다양한 작업에 튜닝된 미리 학습된 모델의 큰 컬렉션을 제공합니다. 또한, 모델을 쉽게 세밀 조정할 수 있습니다.\n\n## 6. MTEB 리더보드\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_6.png)\n\nMTEB 리더보드는 임베딩 모델을위한 리더보드이며, 다양한 임베딩 모델을 비교하여 사용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 만약 이 글을 좋아하시고 저를 지원하고 싶으시면 다음을 확인해주세요:\n\n- 👏 이야기에 박수를 보내주세요 (50번 박수) - 그러면 이 기사를 주목할 수 있습니다\n- To Data \u0026 Beyond 뉴스레터를 구독해주세요\n- 제 Medium 페이지를 팔로우해주세요\n- 📰 제 Medium 프로필에서 더 많은 콘텐츠를 확인해주세요\n- 🔔 저를 팔로우해주세요: LinkedIn | Youtube | GitHub | Twitter\n\n## To Data \u0026 Beyond 뉴스레터를 구독하여 제 글을 미리 보고 전체로 읽어보세요:\n\n## 데이터 과학과 AI 분야에서 새로운 경력을 시작하고 방법을 모르는가요? 데이터 과학 멘토링 세션과 장기적인 경력 멘토링을 제공하고 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 멘토링 세션: [링크](https://lnkd.in/dXeg3KPW)\n- 장기 멘토링: [링크](https://lnkd.in/dtdUYBrM)\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_7.png)\n","ogImage":{"url":"/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png"},"coverImage":"/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png","tag":["Tech"],"readingTime":8},{"title":"마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1","description":"","date":"2024-05-23 18:24","slug":"2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1","content":"\n![image](/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png)\n\n이 글에서는 우리만의 모델, LLM (Large Language Model)을 세밀하게 조정하여 자연어 텍스트에서 유효한 SQL 쿼리를 작성할 수 있는 기능을 추가할 것입니다.\n\n한 단계씩 살펴보겠습니다.\n\n- 소개\n  - 사전 훈련된 모델 선택\n  - 입력/출력 형식\n- 데이터셋 준비\n  - 정리 작업 진행\n  - 하위 집합 생성\n- (계속되는 내용은 Part 2에서)\n- 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 소개\n\n요즘, 트랜스포머 기반 모델이 자연어 처리 분야에서 많은 문제를 해결하고 있어요. 잘 알려진 예시로는 GPT, LLAMA, Mistral 등이 있습니다. 이 모델들은 특정 자연어 처리 문제를 해결하기 위해 입력으로 프롬프트를 사용합니다.\n\n![이미지](/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_1.png)\n\n## 사전 학습된 모델 선택\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n미리 훈련된 모델을 사용하여 시작해 보세요. 미리 훈련된 모델의 정의는 무엇일까요?\n\n미리 훈련된 모델은 수천만 개 또는 수십억 개의 토큰을 사용하여 \"다음 단어 예측\" 목적으로 훈련된 모델입니다. 이 훈련 과정동안, 문장 내 단어의 구조와 의미를 학습합니다.\n\n이 작업에서는 미러소프트/파이2 미리 훈련된 모델을 사용할 것입니다. 이 모델은 1.4 조 토큰으로 훈련되었으며, 27 억 개의 파라미터를 갖추고 있습니다. 이 모델은 SLM(작은 언어 모델)로 간주될 수 있습니다.\n\n이 유형의 미리 훈련된 모델은 앞선 맥락을 기반으로 새로운 토큰을 생성할 수 있는 능력을 갖고 있습니다. 이 모델은 독립적인 질문, QA, 채팅 형식, 그리고 코드 생성과 같은 다양한 용도에 사용될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 모델을 QA 스타일로 텍스트2SQL 생성을 위해 미세 조정할 예정입니다.\n\n## 입력/출력 형식\n\n|            |               |\n| ---------- | ------------- |\n| **input**  | User question |\n| **output** | SQL query     |\n\n질문은 다음과 같습니다: LLM은 사용자 질문에서 어떻게 SQL을 생성할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인간이라도 할 수 없어요. 적어도 테이블 구조에 대한 정보와 샘플 데이터가 필요한데, 그럼에도 불구하고 질문에 대한 SQL 쿼리를 해결할 수 있을 거에요.\n\nLLM과 유사하게, 어떤 맥락을 제공해야 해요. 따라서 우리의 입력은 (맥락) + (사용자 질문)이고, LLM이 우리를 위해 SQL을 생성할 거에요.\n\n그러니 데이터셋 수집 및 준비를 시작해 보고, 그 다음으로 세밀하게 조정해 봐요.\n\n# 데이터셋 준비\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n잠시 찾아보니 huggingface의 “gretelai/synthetic_text_to_sql” 데이터셋을 찾았어요. 제가 찾고 있던 작업에 가장 적합한 것 같아요. 데이터셋에 대해 더 많은 정보를 얻으려면 링크를 클릭해주세요.\n\n```python\nfrom datasets import Dataset, load_dataset\n\n# 데이터셋 불러오고 원치 않는 열 제거하기\ndataset = load_dataset(\"gretelai/synthetic_text_to_sql\") \\\n    .remove_columns(['domain_description', 'sql_complexity_description',\n                     'sql_task_type_description', 'sql_explanation', 'sql_task_type'])\n\ndataset\n```\n\n```python\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 100000\n    })\n    test: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 5851\n    })\n})\n```\n\n```python\ndataset['train'][0]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터셋이 무엇인지 감을 잡기 위해 하나의 샘플을 살펴봅시다. 여기서 우리는 \"sql_context,\" \"sql_prompt,\" 그리고 \"sql\" 필드를 사용할 것입니다.\n\n- sql_context: 테이블 생성 및 삽입 문장\n- sql_prompt: 사용자 쿼리\n- sql: 대상 쿼리\n\n(sql_context + sql_prompt)가 입력이 되고, (sql)이 대상 생성이 됩니다.\n\n```js\n{'id': 5097,\n 'domain': 'forestry',\n 'sql_complexity': 'single join',\n 'sql_prompt': '각 영업사원이 판매한 총 목재 양을 영업사원별로 정렬하여 나타내시오.',\n 'sql_context': \"CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\",\n 'sql': 'SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;'}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 정리를 해봅시다\n\n이 데이터셋은 합성 데이터입니다. 유효하지 않은 문맥이나 SQL 쿼리를 가질 수 있습니다. 이러한 레코드를 찾아 제거해봅시다. 쓰레기를 넣으면 쓰레기가 나온다는 말이죠.\n\n다음 조건에 따라 유효한 데이터를 확인할 것입니다:\n\n- SQL 문맥과 SQL 쿼리는 SQL Lite 데이터베이스에 유효해야 합니다.\n- 테이블은 샘플 레코드를 가져야 합니다.\n- SQL 쿼리를 실행한 후에 결과를 얻을 수 있어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport sqlite3\n\ndef check_all_tables_have_values(row, debug=False):\n\n    # 테이블에 레코드가 있어야 함\n    if row['sql_context'].find('INSERT INTO') == -1:\n        return False\n\n    try:\n        db = sqlite3.connect(\":memory:\")\n        cur = db.cursor()\n        cur.executescript(row['sql_context'])\n        res = cur.execute(row['sql']).fetchall()\n        if debug: print(res)\n        # print(res, len(res))\n        return len(res) \u003e 0\n    except:\n        # print(\"Error while run query\")\n        return False\n\ndataset = dataset.filter(lambda x : check_all_tables_have_values(x))\ndataset\n```\n\n```js\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 53478\n    })\n    test: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 3133\n    })\n})\n```\n\n보시다시피 데이터의 약 46%가 제거되었습니다. 이것은 SQL Lite와 호환되지 않거나 데이터가 없을 수 있습니다.\n\n## 하위 집합 만들기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼,이 초기 실험을 위한 데이터셋이 훨씬 큽니다. 이를 위해 그 중 일부를 만들어 보겠습니다.\n\n다음과 같이 14개 도메인과 3가지 SQL 복잡성 수준으로 데이터셋을 만들 것입니다:\n\n```js\nSELECTED_SQL_COMPLEXITY = ['basic SQL', 'aggregation','single join']\n\nSELECTED_DOMAINS = [\n    \"technology\", \"sports\", \"logistics\", \"space\", \"energy\",\n    \"finance\", \"agriculture\", \"justice\", \"retail\", \"media\",\n    \"education\", \"healthcare\", \"fashion\", \"music\"\n]\n\ndef filter_by_sql_task_type_and_domains(row):\n    return row['sql_complexity'] in SELECTED_SQL_COMPLEXITY \\\n         and row['domain'] in SELECTED_DOMAINS\n\ndataset = dataset.filter(lambda x : filter_by_sql_task_type_and_domains(x))\ndataset\n```\n\n```js\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 6713\n    })\n    test: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 408\n    })\n})\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_3.png\" /\u003e\n\n여기에는 14개의 도메인 데이터셋이 있으며, 각 도메인은 훈련 데이터에 적어도 300개의 샘플이 있습니다. SQL 복잡성은 \"기본 SQL\"의 50%, \"단일 조인\"의 20%, 그리고 \"집계\"의 30%로 분포됩니다.\n\n# (계속, 파트 2로 이어집니다)\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 문서에서는 SLM이 무엇인지 알아보고 fine-tuning을 통해 Text2SQL 작업을 어떻게 해결할 것인지에 대한 아이디어를 얻게 됩니다.\n\n데이터셋에 대해 작업을 진행했으며, 다음 (제2부) 글에서 실제 fine-tuning 프로세스를 수행할 것입니다.\n","ogImage":{"url":"/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png"},"coverImage":"/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png","tag":["Tech"],"readingTime":9},{"title":"토큰화 - 완벽한 가이드","description":"","date":"2024-05-23 18:17","slug":"2024-05-23-TokenizationACompleteGuide","content":"\n## 바이트 페어 인코딩, 워드피스 등과 같은 것들과 함께 Python 코드!\n\n“LLMs from Scratch” 시리즈 중 제1부 — 대형 언어 모델을 이해하고 구축하는 완벽한 안내서입니다. 이 모델이 어떻게 작동하는지 더 자세히 알아보고 싶다면 다음을 읽어보는 것을 권장합니다:\n\n- 프롤로그: 대형 언어 모델의 간단한 역사\n- 파트 1: 토크나이제이션 — 완벽한 안내서\n- 파트 2: Python에서 워드투벡으로부터 스크래치로 단어 임베딩\n- 파트 3: 코드로 설명하는 셀프 어텐션\n- 파트 4: 코드로 이해하는 BERT의 완벽한 안내서\n\n![이미지](/assets/img/2024-05-23-TokenizationACompleteGuide_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이 콘텐츠가 도움이 되었다면, 아래 방법으로 저를 지원해주십시오:\n\n- 기사에 Clap(박수)을 보내세요\n- 저를 Medium이나 LinkedIn에서 팔로우하여 향후 게시물에 대한 업데이트를 받으세요\n\n## 서두\n\n대형 언어 모델 (LLM)은 2022년 11월 OpenAI의 ChatGPT가 출시된 이후 매우 인기를 얻었습니다. 그 이후로 이러한 언어 모델의 사용이 급증했으며, HuggingFace의 Transformer 라이브러리와 PyTorch와 같은 라이브러리의 도움을 받았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 모든 이들 준비하고 있는 완제품 도구들로 인해, 기본 수준에서 무슨 일이 일어나고 있는지 추상화하는 것이 쉽습니다. 그 결과로 많은 온라인 튜토리얼들이 당신이 자체 모델을 생성할 때 '무엇'을 알려주고 '왜'는 알려주지 않는 경우가 많습니다. 이 기사 시리즈는 이를 해결하고자 합니다. '처음부터 LLMs 만들기'는 대형 언어 모델을 구성하는 구성 요소를 분해하고, 내부 작동 방식을 설명합니다. 그의 목표는 다음과 같습니다:\n\n- 수학의 직관적 이해를 포함한, LLMs가 어떻게 작동하는지의 기본적인 이해 구축\n- 각 구성 요소가 어떻게 작동하는지를 보여주며, Python에서 처음부터 구현 방법을 보여줌\n- 불필요한 추상화를 줄이기 위해 가급적이면 최소한의 라이브러리 사용\n\n말이 다 되었으니, 시작해보겠습니다.\n\n# 토크나이저란 무엇인가?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자연어 처리 문제는 텍스트 데이터를 사용하는데, 기계가 즉시 이해하기 어렵습니다. 컴퓨터가 언어를 처리하려면 먼저 텍스트를 숫자 형식으로 변환해야 합니다. 이 프로세스는 토크나이저라는 모델에 의해 주로 두 단계로 수행됩니다.\n\n단계 1: 입력 텍스트를 토큰으로 분할\n\n토크나이저는 먼저 텍스트를 가져와 단어, 단어 부분 또는 개별 문자가 될 수 있는 작은 조각으로 나눕니다. 이러한 작은 텍스트 조각을 토큰이라고 합니다. 스탠포드 NLP 그룹은 토큰을 더 엄격하게 정의합니다.\n\n단계 2: 각 토큰에 식별자 할당\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n토크나이저가 텍스트를 토큰으로 분리한 후, 각 토큰에 토큰 ID라고 불리는 정수 번호를 할당할 수 있습니다. 예를 들어, \"cat\"이라는 단어가 15라는 값으로 할당될 수 있고, 따라서 입력 텍스트의 모든 cat 토큰은 숫자 15로 표시됩니다. 텍스트 토큰을 숫자 표현으로 교체하는 과정을 인코딩이라고 합니다. 비슷하게, 인코딩된 토큰을 다시 텍스트로 변환하는 과정을 디코딩이라고 합니다.\n\n단일 숫자를 사용하여 토큰을 표현하는 것에는 단점이 있다는 것을 알 수 있습니다. 그래서 이러한 코드들은 단어 임베딩을 생성하기 위해 추가로 처리되며, 이것은 이 시리즈의 다음 기사의 주제입니다.\n\n# 토큰화 방법\n\n텍스트를 토큰으로 나누는 세 가지 주요 방법이 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 단어 기반\n- 문자 기반\n- 부분어 기반\n\n## 단어 기반 토크나이저:\n\n단어 기반 토크나이제이션은 세 가지 토큰화 방법 중 가장 간단한 방법입니다. 여기서 토크나이저는 문장을 단어로 분할하는데 각 공백 문자를 기준으로 나눕니다(때로는 '화이트스페이스 기반 토큰화'라고도 함) 또는 유사한 규칙 세트(구두점 기반 토큰화, 트리뱅크 토큰화 등)에 따라 분할할 수도 있습니다 [12].\n\n예를 들어, 다음과 같은 문장:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n고양이들은 멋지지만, 개들이 더 좋아요!\n\n띄어쓰기 문자로 분할하면:\n\n[`Cats`, `are`, `great,`, `but`, `dogs`, `are`, `better!`]\n\n또는 구두점과 공백을 기준으로 분할하면:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[`Cats`, `are`, `great`, `,`, `but`, `dogs`, `are`, `better`, `!`]\n\n위 간단한 예제를 통해 분할을 결정하는 데 사용하는 규칙이 중요하다는 것을 분명히 이해할 수 있습니다. 공백 접근 방식은 잠재적으로 희귀한 토큰 `better!`를 제공하며, 두 번째 분할은 덜 희귀한 토큰 `better`와 `!`을 생성합니다. 문장부호를 완전히 제거하지 않도록 주의해야 합니다. 문장부호에는 매우 구체적인 의미가 있을 수 있기 때문입니다. 그 중 하나는 ‘작은따옴표(apostrophe)’입니다. 작은따옴표는 단수와 소유 형태를 구별할 수 있습니다. 예를 들어 “book's”는 책의 속성을 가리키며 “the book's spine is damaged”와 같이 사용되고, “books”는 여러 권의 책을 가리킵니다.\n\n토큰을 생성한 후, 각 토큰에 번호를 할당할 수 있습니다. 토큰 생성기가 이미 본 토큰을 생성할 때 다음에 볼 토큰은 그 단어에 지정된 번호를 간단히 할당할 수 있습니다. 예를 들어 위 문장에서 `great`가 1이라는 값으로 할당된 경우, 이후의 `great` 단어는 모두 1의 값으로 할당됩니다.\n\n단어 기반 토크나이저의 장단점:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n워드 기반 방법으로 생성된 토큰들은 각각 의미론적 및 문맥 정보를 포함하고 있어 많은 정보를 담고 있습니다. 그러나 이 방법의 가장 큰 단점 중 하나는 매우 유사한 단어가 완전히 다른 토큰으로 처리된다는 것입니다. 예를 들어, cat과 cats 간의 연결은 존재하지 않으며, 이들은 별개의 단어로 처리됩니다. 이는 많은 단어를 포함하는 대규모 응용 프로그램에서 문제가 될 수 있습니다. 모델 어휘의 가능한 토큰 수가 매우 커질 수 있기 때문입니다. 영어는 약 17만 단어가 있으며, 각 단어에 대한 복수형이나 과거형과 같은 다양한 문법 형태를 포함하면 폭발적인 어휘 문제가 발생할 수 있습니다. TransformerXL 토크나이저가 사용하는 공백 기반 분할은 어휘 크기가 25만 개를 초과하도록 이끌었습니다.\n\n이 문제를 해결하는 한 가지 방법은 모델이 학습할 수 있는 토큰 수에 하드 리미트를 부여하는 것입니다(예: 1만). 이는 가장 빈도가 높은 1만개의 토큰을 벗어나는 모든 단어를 어휘 외로 처리하고, 숫자 값 대신 UNKNOWN 토큰 값을 할당하는 것입니다(UNK로 축약되기도 합니다). 이는 많은 알려지지 않은 단어가 있는 경우에 성능에 영향을 줄 수 있지만, 데이터에 대부분의 일반적인 단어가 포함된 경우에는 적합한 타협안이 될 수 있습니다.\n\n장점 요약:\n\n- 간단한 방법\n- 각 토큰에 저장된 높은 정보량\n- 주로 일반적인 단어를 포함하는 데이터셋과 잘 작동하는 어휘 크기 제한 가능\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요약:\n\n- 비슷한 단어에 대해 별도의 토큰이 생성됩니다 (예: cat과 cats)\n- 매우 큰 어휘를 만들 수 있습니다.\n- 어휘를 제한하면 드문 단어가 많은 데이터셋에서 성능이 크게 저하될 수 있습니다.\n\n## 문자 기반 토크나이저:\n\n문자 기반 토크나이제이션은 글자, 숫자 및 구두점과 같은 특수 문자를 포함하여 텍스트를 각 문자 단위로 분할합니다. 이는 영어 언어를 단어 기반 접근법에서 필요한 17만 개 이상의 어휘 대신 약 256개의 토큰으로 표현할 수 있도록 어휘 크기를 크게 줄입니다 [5]. 중국어 및 일본어와 같은 동아시아 언어도 자신들의 문자 시스템에서 수천 개의 고유 문자를 포함하지만 어휘 크기가 크게 축소될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n문자 기반 토크나이저에서는 다음과 같은 문장을 아래와 같이 변환할 수 있습니다:\n\n[`C`, `a`, `t`, `s`, ` `, `a`, `r`, `e`, ` `, `g`, `r`, `e`, `a`, `t`, `,`, ` `, `b`, `u`, `t`, ` `, `d`, `o`, `g`, `s`, ` `, `a`, `r`, `e`, ` `, `b`, `e`, `t`, `t`, `e`, `r`, `!`]\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n캐릭터 기반 토크나이저의 장단점:\n\n단어 기반 방법과 비교할 때, 캐릭터 기반 접근 방식은 훨씬 작은 어휘 크기를 가지며, 많은 수의 OOV(Out-Of-Vocabulary) 토큰을 생성하지 않는다. 심지어 맞춰 쓰인 단어들이 아닌 오타가 있는 단어들조차도 토큰화할 수 있다는 장점이 있습니다(다만 해당 단어의 올바른 형태와는 다르게 토큰화됩니다). 또한, 빈도 기반 어휘 제한 때문에 단어가 즉시 제거되는 것을 방지합니다.\n\n하지만 이 접근 방식에는 몇 가지 단점도 있습니다. 먼저, 캐릭터 기반 방법으로 생성된 단일 토큰에 저장된 정보량은 매우 적습니다. 이는 단어 기반 방식의 토큰과 달리 의미론적이거나 문맥적인 의미가 캡처되지 않기 때문입니다(특히, 알파벳 기반 언어인 영어와 같은 언어에서). 마지막으로 이 방식은 입력 텍스트를 인코딩하기 위해 많은 수의 숫자가 필요하기 때문에, 언어 모델에 투입할 수 있는 토큰화된 입력의 크기에 제약이 생깁니다.\n\n장점 요약:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 어휘 크기가 작음\n- 철자가 틀린 단어를 제거하지 않음\n\n단점 요약:\n\n- 각 토큰에 저장되는 정보량이 적으며, 알파벳 기반의 글쓰기 체계에서는 문맥적 또는 의미적 의미가 거의 없음\n- 언어 모델에 입력되는 크기가 제한되며, 텍스트를 토큰화하는 데 필요한 숫자가 훨씬 더 많아짐 (단어 기반 접근 방식과 비교했을 때)\n\n## Subword-Based Tokenizers:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n서브워드 기반 토큰화는 단어 기반 및 문자 기반 방법의 이점을 모두 활용하면서 그들의 단점을 최소화하려는 목표를 가지고 있어요. 서브워드 기반 방법은 단어 내에서 텍스트를 분할하여 의미 있는 토큰을 생성하려는 시도를 통해 중간 지점을 취하고 있어요, 심지어 그것들이 완전한 단어가 아니더라도요. 예를 들어, 토큰 ing와 ed는 문법적인 의미를 가지고 있지만 그 자체로 완전한 단어는 아니에요.\n\n이 방법은 단어 기반 방법보다 작은 어휘 크기를 갖게 하지만, 문자 기반 방법보다 큰 어휘 크기를 갖게 해요. 또한 매 토큰 내에 저장된 정보 양도 두 가지 이전 방법으로 생성된 토큰 사이에 위치하게 되요. 서브워드 접근 방식은 다음 두 지침을 사용해요:\n\n- 자주 사용되는 단어를 서브워드로 분리하지 말고 전체 토큰으로 저장해야 함\n- 드물게 사용되는 단어를 서브워드로 분리해야 함\n\n드물게 사용되는 단어만 분리함으로써 활용어나 복수형 등이 그 구성 요소로 분해되는 기회를 주면서 토큰 사이의 관계를 보존하게 돼요. 예를 들어 cat은 데이터셋에서 매우 흔한 단어지만 cats는 덜 흔할 수 있어요. 이 경우 cats는 cat과 s로 분리되어, cat은 이제 다른 모든 cat 토큰과 동일한 값을 갖게 되고, s는 다른 값을 갖게 됩니다. 이는 복수성의 의미를 인코딩할 수 있다는 것이에요. 또 다른 예시로는 단어 토큰화인데요, 이는 루트 단어 토큰과 접미사 ization으로 분할될 수 있어요. 이 방법은 구문 및 의미 유사성을 보존할 수 있습니다. 이러한 이유로, 서브워드 기반 토큰화기는 현재 많은 NLP 모델에서 널리 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 정규화 및 사전 토크나이제이션\n\n토크나이제이션 과정에서는 사전 처리 및 사후 처리 단계가 필요한데, 이 모든 것이 토크나이제이션 파이프라인을 이룹니다. 이것은 로우 텍스트를 토큰으로 변환하는 데 필요한 일련의 조치들을 설명합니다. 이 파이프라인의 단계는 다음과 같습니다:\n\n- 정규화\n- 사전 토큰화\n- 모델\n- 후 처리\n\n여기서 토큰화 방법(서브워드 기반, 문자 기반 등)은 모델 단계에서 이루어집니다 [7]. 이 섹션에서는 서브워드 기반 토큰화 방식을 사용하는 토크나이저에 대해 각 단계를 다룰 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중요한 알림: 토큰화 파이프라인의 모든 단계는 Hugging Face의 토크나이저 및 트랜스포머 라이브러리와 같은 라이브러리에서 토크나이저를 사용할 때 자동으로 사용자 대신 처리됩니다. 전체 파이프라인은 Tokenizer라는 단일 객체에 의해 수행됩니다. 이 섹션은 대부분의 사용자가 NLP 작업을 수행할 때 직접 처리할 필요가 없는 코드 내부 작업에 대해 다룹니다. 나중에는 토크나이저 라이브러리의 기본 토크나이저 클래스를 사용자 정의하는 단계도 제시되어 필요한 경우 특정 작업용으로 토크나이저를 목적에 맞게 만들 수 있습니다.\n\n## 정규화 방법\n\n정규화는 텍스트를 토큰으로 분할하기 전에 정리하는 과정입니다. 이 과정에는 각 문자를 소문자로 변환하거나 문자에서 강세 기호를 제거하는 단계(예: é가 e가 됨), 불필요한 공백을 제거하는 것 등이 포함됩니다. 예를 들어, 문자열 ThÍs is áN ExaMPlé sÉnteNCE는 정규화 후에는 this is an example sentence가 됩니다. 서로 다른 정규화기는 서로 다른 단계를 수행하며, 사용 사례에 따라 유용할 수 있습니다. 예를 들어, 일부 상황에서는 대소문자나 강세 기호를 유지해야 할 수도 있습니다. 선택한 정규화기에 따라이 단계에서 다양한 효과를 얻을 수 있습니다.\n\nHugging Face의 tokenizers.normalizers 패키지에는 대규모 모델의 일부로서 다양한 토큰화기에서 사용되는 여러 기본 정규화기가 포함되어 있습니다. 아래는 NFC 유니코드, 소문자 및 BERT 정규화기입니다. 이들은 예제 문장에 다음과 같은 효과를 보여줍니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- NFC: 대문자를 변환하지 않거나 악센트를 제거하지 않습니다.\n- Lower: 대문자를 변환하지만 악센트를 제거하지 않습니다.\n- BERT: 대문자를 변환하고 악센트를 제거합니다.\n\n```js\nfrom tokenizers.normalizers import NFC, Lowercase, BertNormalizer\n\n# 정규화할 텍스트\ntext = 'ThÍs is  áN ExaMPlé     sÉnteNCE'\n\n# 정규화 객체 인스턴스화\nNFCNorm = NFC()\nLowercaseNorm = Lowercase()\nBertNorm = BertNormalizer()\n\n# 텍스트 정규화\nprint(f'NFC:   {NFCNorm.normalize_str(text)}')\nprint(f'Lower: {LowercaseNorm.normalize_str(text)}')\nprint(f'BERT:  {BertNorm.normalize_str(text)}')\n```\n\n```js\nNFC:   ThÍs is  áN ExaMPlé     sÉnteNCE\nLower: thís is  án examplé     séntence\nBERT:  this is  an example     sentence\n```\n\n위의 정규화기들은 Hugging Face transformers 라이브러리에서 가져올 수 있는 토크나이저 모델에서 사용됩니다. 아래 코드 셀은 Tokenizer.backend_tokenizer.normalizer를 통해 점 표기법(dot notation)을 사용하여 정규화기에 액세스하는 방법을 보여줍니다. 서로 다른 정규화 방법을 강조하기 위해 일부 비교를 보여줍니다. 이 예시들에서는 FNet 정규화기만 불필요한 공백을 제거합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom transformers import FNetTokenizerFast, CamembertTokenizerFast, \\\n                         BertTokenizerFast\n\n# Text to normalize\ntext = 'ThÍs is  áN ExaMPlé     sÉnteNCE'\n\n# Instantiate tokenizers\nFNetTokenizer = FNetTokenizerFast.from_pretrained('google/fnet-base')\nCamembertTokenizer = CamembertTokenizerFast.from_pretrained('camembert-base')\nBertTokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n\n# Normalize the text\nprint(f'FNet Output:      \\\n    {FNetTokenizer.backend_tokenizer.normalizer.normalize_str(text)}')\n\nprint(f'CamemBERT Output: \\\n    {CamembertTokenizer.backend_tokenizer.normalizer.normalize_str(text)}')\n\nprint(f'BERT Output:      \\\n    {BertTokenizer.backend_tokenizer.normalizer.normalize_str(text)}')\n```\n\n```js\nFNet Output:      ThÍs is áN ExaMPlé sÉnteNCE\nCamemBERT Output: ThÍs is  áN ExaMPlé     sÉnteNCE\nBERT Output:      this is  an example     sentence\n```\n\n## Pre-Tokenization Methods\n\nThe pre-tokenization step is the first splitting of the raw text in the tokenization pipeline. The split is performed to give an upper bound to what the final tokens could be at the end of the pipeline. That is, a sentence can be split into words in the pre-tokenization step, then in the model step some of these words may be split further according to the tokenization method (e.g. subword-based). So the pre-tokenized text represents the largest possible tokens that could still remain after tokenization.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n정규화와 마찬가지로이 단계를 수행하는 여러 가지 방법이 있습니다. 예를 들어, 문장은 매 공백, 모든 공백 및 일부 구두점 또는 매 공백 및 모든 구두점을 기준으로 분할될 수 있습니다.\n\n아래 셀은 기본 Whitespacesplit 프리 토크나이저와 Hugging Face 토크나이저의 pre_tokenizers 패키지에서 약간 더 복잡한 BertPreTokenizer 간의 비교를 보여줍니다. 공백 프리 토크나이저의 출력은 구두점을 그대로 두고 이웃하는 단어에 여전히 붙어 있는 것을 보여줍니다. 예를 들어, \"includes:\"는 이 경우에는 단일 단어로 처리됩니다. 반면 BERT 프리 토크나이저는 구두점을 개별 단어로 취급합니다 [8].\n\n```js\nfrom tokenizers.pre_tokenizers import WhitespaceSplit, BertPreTokenizer\n\n# 텍스트 정규화\ntext = (\"this sentence's content includes: characters, spaces, and \" \\\n        \"punctuation.\")\n\n# 프리 토큰화된 출력을 표시하는 도우미 함수 정의\ndef print_pretokenized_str(pre_tokens):\n    for pre_token in pre_tokens:\n        print(f'\"{pre_token[0]}\", ', end='')\n\n# 프리 토크나이저 인스턴스화\nwss = WhitespaceSplit()\nbpt = BertPreTokenizer()\n\n# 텍스트를 프리 토큰화\nprint('Whitespace Pre-Tokenizer:')\nprint_pretokenized_str(wss.pre_tokenize_str(text))\n\nprint('\\n\\nBERT Pre-Tokenizer:')\nprint_pretokenized_str(bpt.pre_tokenize_str(text))\n```\n\n```js\nWhitespace Pre-Tokenizer:\n\"this\", \"sentence's\", \"content\", \"includes:\", \"characters,\", \"spaces,\",\n\"and\", \"punctuation.\",\n\nBERT Pre-Tokenizer:\n\"this\", \"sentence\", \"'\", \"s\", \"content\", \"includes\", \":\", \"characters\",\n\",\", \"spaces\", \",\", \"and\", \"punctuation\", \".\",\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n정규화 방법들과 마찬가지로 GPT-2와 ALBERT (A Lite BERT) 토크나이저와 같은 일반적인 토크나이저에서 사전 토큰화 방법을 직접 호출할 수 있습니다. 이들은 위에서 보여진 표준 BERT 사전 토큰화 방법과 약간 다른 방식을 사용합니다. 토큰을 분할할 때 공백 문자를 제거하지 않고 특수 문자로 대체합니다. 그 결과, 공백 문자를 처리할 때 무시할 수 있지만 필요할 경우 원래 문장을 검색할 수 있습니다. GPT-2 모델은 Ġ 문자를 사용하며, 이는 위에 점을 찍은 대문자 G가 특징입니다. ALBERT 모델은 밑줄 문자를 사용합니다.\n\n```python\nfrom transformers import AutoTokenizer\n\n# 사전 토큰화할 텍스트\ntext = (\"this sentence's content includes: characters, spaces, and \" \\\n        \"punctuation.\")\n\n# 사전 토큰화 객체 생성\nGPT2_PreTokenizer = AutoTokenizer.from_pretrained('gpt2').backend_tokenizer \\\n                    .pre_tokenizer\n\nAlbert_PreTokenizer = AutoTokenizer.from_pretrained('albert-base-v1') \\\n                      .backend_tokenizer.pre_tokenizer\n\n# 텍스트를 사전 토큰화\nprint('GPT-2 사전 토크나이저:')\nprint_pretokenized_str(GPT2_PreTokenizer.pre_tokenize_str(text))\nprint('\\n\\nALBERT 사전 토크나이저:')\nprint_pretokenized_str(Albert_PreTokenizer.pre_tokenize_str(text))\n```\n\n```python\nGPT-2 사전 토크나이저:\n\"this\", \"Ġsentence\", \"'s\", \"Ġcontent\", \"Ġincludes\", \":\", \"Ġcharacters\", \",\",\n\"Ġspaces\", \",\", \"Ġand\", \"Ġpunctuation\", \".\"\n\nALBERT 사전 토크나이저:\n\"▁this\", \"▁sentence's\", \"▁content\", \"▁includes:\", \"▁characters,\", \"▁spaces,\",\n\"▁and\", \"▁punctuation.\"\n```\n\n위의 예제 문장에 대한 BERT 사전 토큰화 단계 결과를 수정 없이 출력한 내용이 아래에 나와 있습니다. 반환된 객체는 원본 입력 텍스트에서 문자열의 시작 및 끝 색인을 포함하는 파이썬 리스트입니다. 문자열의 시작 색인은 포함되며, 끝 색인은 배타적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom tokenizers.pre_tokenizers import WhitespaceSplit, BertPreTokenizer\n\n# Pre-tokenizer 인스턴스 생성\ntext = (\"this sentence의 내용은: characters, spaces, 그리고 \" \\\n        \"punctuation이 포함되어 있습니다.\")\nbpt = BertPreTokenizer()\nbpt.pre_tokenize_str(text)\n```\n\n```js\n[\n  (\"this\", (0, 4)),\n  (\"sentence\", (5, 13)),\n  (\"'\", (13, 14)),\n  (\"s\", (14, 15)),\n  (\"content\", (16, 23)),\n  (\"includes\", (24, 32)),\n  (\":\", (32, 33)),\n  (\"characters\", (34, 44)),\n  (\",\", (44, 45)),\n  (\"spaces\", (46, 52)),\n  (\",\", (52, 53)),\n  (\"and\", (54, 57)),\n  (\"punctuation\", (58, 69)),\n  (\".\", (69, 70)),\n];\n```\n\n# 서브워드 토큰화 방법\n\n토큰화 파이프라인의 모델 단계는 토큰화 방법이 사용되는 곳입니다. 이전에 설명한대로 여기서 선택할 수 있는 옵션은: 단어 기반, 문자 기반, 서브워드 기반입니다. 서브워드 기반 방법이 일반적으로 선호되는데, 이 방법들은 단어 기반 및 문자 기반 접근법의 한계를 극복하기 위해 설계되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n트랜스포머 모델에는 하위 단어 기반 토큰화를 구현하는 데 일반적으로 사용되는 세 가지 토크나이저 방법이 있습니다. 이 방법들은 다음과 같습니다:\n\n- 바이트 페어 인코딩 (BPE)\n- 워드피스\n- 유니그램\n\n각각의 방법은 빈도가 낮은 단어를 더 작은 토큰으로 분리하기 위해 약간 다른 기술을 사용합니다. BPE 및 워드피스 알고리즘의 구현 방법도 여기에 소개되어 있어서 접근 방식 사이의 유사점과 차이점을 강조하는 데 도움이 될 것입니다.\n\n## 바이트 페어 인코딩\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n바이트 페어 인코딩 알고리즘은 GPT 및 GPT-2 모델 (OpenAI), BART (Lewis et al.) 및 기타 많은 트랜스포머 모델에서 발견되는 일반적으로 사용되는 토크나이저입니다 [9-10]. 이 알고리즘은 원래 텍스트 압축 알고리즘으로 설계되었지만, 언어 모델의 토큰화 작업에 매우 효과적으로 작동한다는 것이 밝혀졌습니다. BPE 알고리즘은 텍스트 문자열을 참조 말뭉치(토큰화 모델을 훈련하는 데 사용되는 텍스트)에서 빈번히 나타나는 부분 단어 단위로 분해합니다 [11]. BPE 모델은 다음과 같이 훈련됩니다:\n\n## 단계 1) 말뭉치 작성\n\n입력 텍스트는 정규화 및 사전 토큰화 모델에 제공되어 깨끗한 단어를 생성합니다. 단어는 BPE 모델에 제공되어 각 단어의 빈도를 결정하고, 이 빈도를 단어와 함께 목록인 말뭉치에 저장합니다.\n\n## 단계 2) 어휘 작성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n말뭉치에서 단어들은 개별 문자로 분해되어 \"어휘(vocabulary)\"라는 비어있는 목록에 추가됩니다. 알고리즘은 어떤 문자 쌍을 함께 병합할 수 있는지를 결정할 때마다 이 어휘에 계속 추가합니다.\n\n단계 3) 문자 쌍의 빈도 찾기\n\n그런 다음, 말뭉치의 각 단어에 대해 문자 쌍의 빈도가 기록됩니다. 예를 들어, 단어 \"cats\"는 문자 쌍 \"ca\", \"at\", \"ts\"를 가집니다. 이와 같은 방식으로 모든 단어가 검사되어 전역 빈도 카운터에 기여합니다. 따라서 토큰 중에서 어떤 ca가 발견되는 경우, ca 쌍에 대한 빈도 카운터가 증가합니다.\n\n단계 4) 병합 규칙 작성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n각 문자 쌍의 빈도가 알려진 경우, 가장 빈번한 문자 쌍이 어휘에 추가됩니다. 어휘는 이제 토큰 내의 모든 개별 문자와 가장 빈번한 문자 쌍으로 구성됩니다. 또한 모델이 사용할 수있는 병합 규칙이 제공됩니다. 예를 들어 모델이 ca가 가장 빈번한 문자 쌍이라는 것을 학습하면, 모델은 말뭉친 c와 a의 모든 인접 인스턴스를 ca로 병합해 ca를 제공합니다. 이제 이를 나머지 단계의 단일 문자 ca로 취급할 수 있습니다.\n\n단계 5) 단계 3과 4 반복\n\n그런 다음 단계 3과 4를 반복하여 더 많은 병합 규칙을 찾고 어휘에 더 많은 문자 쌍을 추가합니다. 이 프로세스는 교육 시작 시 지정된 대상 크기에 도달 할 때까지 계속됩니다.\n\nBPE 알고리즘이 교육되었으므로 (즉, 모든 병합 규칙이 찾아졌다), 모델은 모든 텍스트를 토큰화하기 위해 모든 단어를 각 문자로 분할하고, 그런 다음 병합 규칙에 따라 병합하여 사용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 표는 마크다운 형식으로 변경하겠습니다.\n\n아래는 BPE 알고리즘의 Python 구현입니다. 위에서 설명한 단계를 따르고 있습니다. 그 후에는 이 모델을 장난감 데이터세트에서 훈련하고 몇 가지 예제 단어에서 테스트합니다.\n\n```py\nclass TargetVocabularySizeError(Exception):\n    def __init__(self, message):\n        super().__init__(message)\n\nclass BPE:\n    '''Byte Pair Encoding tokenizer의 구현.'''\n\n    def calculate_frequency(self, words):\n        ''' 주어진 단어 목록에서 각 단어의 빈도를 계산합니다.\n\n            문자열로 저장된 단어 목록을 받아서, 각 단어의 빈도를 나타내는 정수를 값을 가진 튜플의 목록을 반환합니다.\n\n            매개변수:\n                words (list): 어떠한 순서로든 단어들(문자열)의 목록입니다.\n\n            반환값:\n                corpus (list[tuple(str, int)]): 단어 목록의 각 단어를 나타내는 첫 번째 요소가 문자열이고,\n                  두 번째 요소가 목록에서 단어의 빈도를 나타내는 정수인 튜플의 목록입니다.\n        '''\n        freq_dict = dict()\n\n        for word in words:\n            if word not in freq_dict:\n                freq_dict[word] = 1\n            else:\n                freq_dict[word] += 1\n\n        corpus = [(word, freq_dict[word]) for word in freq_dict.keys()]\n\n        return corpus\n\n    # 나머지 코드 생략\n```\n\nBPE 알고리즘은 '고양이'에 관한 몇 가지 단어가 포함된 장난감 데이터세트에서 훈련됩니다. 토크나이저의 목표는 데이터세트의 단어의 가장 유용하고 의미 있는 하위 단위를 결정하여 토큰으로 사용하는 것입니다. 검사 결과, 'cat', 'eat', 'ing' 등의 단위가 유용한 하위 단위가 될 것임이 분명합니다.\n\n21개의 대상 어휘 크기로 토크나이저를 실행하면(이는 5회 병합만 필요합니다), 위에서 언급한 모든 원하는 하위 단위를 포착하는 데 충분합니다. 더 큰 데이터세트의 경우 대상 어휘도 훨씬 더 높아지겠지만, 이는 BPE 토크나이저가 얼마나 강력한지를 보여줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# Training set\nwords = ['cat', 'cat', 'cat', 'cat', 'cat',\n         'cats', 'cats',\n         'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat',\n         'eating', 'eating', 'eating',\n         'running', 'running',\n         'jumping',\n         'food', 'food', 'food', 'food', 'food', 'food']\n\n# Instantiate the tokenizer\nbpe = BPE()\nbpe.train(words, 21)\n\n# Print the corpus at each stage of the process, and the merge rule used\nprint(f'INITIAL CORPUS:\\n{bpe.corpus_history[0]}\\n')\nfor rule, corpus in list(zip(bpe.merge_rules, bpe.corpus_history[1:])):\n    print(f'NEW MERGE RULE: Combine \"{rule[0]}\" and \"{rule[1]}\"')\n    print(corpus, end='\\n\\n')\n```\n\n```js\nINITIAL CORPUS:\n[(['c', 'a', 't'], 5), (['c', 'a', 't', 's'], 2), (['e', 'a', 't'], 10),\n(['e', 'a', 't', 'i', 'n', 'g'], 3), (['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"a\" and \"t\"\n[(['c', 'at'], 5), (['c', 'at', 's'], 2), (['e', 'at'], 10),\n(['e', 'at', 'i', 'n', 'g'], 3), (['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"e\" and \"at\"\n[(['c', 'at'], 5), (['c', 'at', 's'], 2), (['eat'], 10),\n(['eat', 'i', 'n', 'g'], 3), (['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"c\" and \"at\"\n[(['cat'], 5), (['cat', 's'], 2), (['eat'], 10), (['eat', 'i', 'n', 'g'], 3),\n(['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"i\" and \"n\"\n[(['cat'], 5), (['cat', 's'], 2), (['eat'], 10), (['eat', 'in', 'g'], 3),\n(['r', 'u', 'n', 'n', 'in', 'g'], 2), (['j', 'u', 'm', 'p', 'in', 'g'], 1),\n(['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"in\" and \"g\"\n[(['cat'], 5), (['cat', 's'], 2), (['eat'], 10), (['eat', 'ing'], 3),\n(['r', 'u', 'n', 'n', 'ing'], 2), (['j', 'u', 'm', 'p', 'ing'], 1),\n(['f', 'o', 'o', 'd'], 6)]\n```\n\n크게 작은 데이터셋으로 BPE 알고리즘을 학습했으므로 이제 예제 단어를 토큰화하는 데 사용할 수 있습니다. 아래 셀은 토크나이저가 이전에 본 단어들 및 이전에 보지 못한 단어들을 토큰화하는 데 사용되는 것을 보여줍니다. 토크나이저는 동사 접미사 \"ing\"을 학습했으므로 이를 토큰으로 분리할 수 있습니다. 이 때문에 훈련 데이터에는 'eat'이 포함되어 있어 'eat'이 중요한 토큰임을 학습했습니다. 그러나 모델은 'run'과 'ski'라는 단어를 본 적이 없기 때문에 이를 성공적으로 토큰화하지 못합니다. 이는 토크나이저를 훈련시킬 때 다양하고 광범위한 훈련 세트의 중요성을 강조합니다.\n\n```js\nprint(bpe.tokenize(\"eating\"));\nprint(bpe.tokenize(\"running\"));\nprint(bpe.tokenize(\"skiing\"));\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n[\"먹\", \"어\", \"•\", \"ᆼ\"][(\"\", \"ᄂ\", \"ᄂ\", \"•\", \"ᆼ\")][(\"\", \"스\", \"키\", \"•\", \"ᆼ\")];\n```\n\nBPE 토크나이저는 훈련 데이터에 나타난 문자만 인식할 수 있습니다. 예를 들어, 위의 훈련 데이터에는 고양이에 대해 이야기할 때 필요한 문자만 포함되어 있어서 z가 필요하지 않았습니다. 따라서 해당 토크나이저 버전은 z 문자를 어휘에 포함시키지 않으며, 실제 데이터를 토큰화할 때 해당 문자를 알 수 없는 토큰으로 변환합니다 (실제로, 오류 처리가 없어 모델이 알 수 없는 토큰을 생성하도록 지시하는 기능도 없으므로 모델이 충돌할 것이지만, 제품화된 모델에서는 이런 일이 발생할 수 있습니다).\n\nGPT-2 및 RoBERTa에서 사용되는 BPE 토크나이저는 이 문제가 없으며 코드 내에 한 가지 속임수가 있습니다. Unicode 문자를 기반으로 훈련 데이터를 분석하는 대신, 문자의 바이트를 분석합니다. 이를 Byte-Level BPE라고 하며, 소규모 기본 어휘를 사용하여 모델이 볼 수 있는 모든 문자를 토큰화할 수 있게 합니다.\n\n## WordPiece\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nWordPiece는 구글이 개발한 토큰화 방법으로, 그들의 중요한 BERT 모델 및 이로부터 파생된 모델들인 DistilBERT 및 MobileBERT에서 사용됩니다.\n\nWordPiece 알고리즘의 전체 세부 내용은 공개되지 않았기 때문에 여기서 제시하는 방법론은 Hugging Face에 의해 제시된 해석을 기반으로 합니다. WordPiece 알고리즘은 BPE와 유사하지만 병합 규칙을 결정하는 데 다른 지표를 사용합니다. 가장 빈도가 높은 문자 쌍을 선택하는 대신 각 쌍에 대해 점수가 계산되고, 가장 높은 점수를 가진 쌍이 병합될 문자를 결정합니다. WordPiece는 다음과 같이 훈련됩니다.\n\n단계 1) 말뭉치 구축\n\n다시 한 번 입력 텍스트는 정규화 및 사전 토큰화 모델에 제공되어 깨끗한 단어를 생성합니다. 단어는 WordPiece 모델에 제공되어 각 단어의 빈도를 결정하고, 이 번호를 단어와 함께 \"말뭉치\"라고 불리는 리스트에 저장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n단계 2) 어휘 구성\n\nBPE와 같이 코퍼스에서 단어를 개별 문자로 분해한 후, 단어들은 비어 있는 어휘 목록에 추가됩니다. 그러나 이번에는 단순히 각 개별 문자를 저장하는 대신, 두 개의 # 기호가 사용되어 문자가 단어의 시작에서 발견되었는지 또는 단어의 중간/끝에서 발견되었는지를 표시하는 마커로 사용됩니다. 예를 들어, 단어 cat은 BPE에서 [`c`, `a`, `t`]로 분할되지만 WordPiece에서는 [`c`, `##a`, `##t`]로 나타납니다. 이 시스템에서는 단어의 시작에서의 c와 단어의 중간 또는 끝에서의 ##c가 다르게 처리됩니다. 알고리즘은 매번 어떤 문자 쌍을 함께 병합할 수 있는지 결정할 때마다 이 어휘에 추가됩니다.\n\n단계 3) 인접 문자 쌍의 쌍 점수 계산\n\nBPE 모델과 달리, 이번에는 각 문자 쌍에 대해 점수가 계산됩니다. 먼저, 코퍼스에서 각 인접 문자 쌍을 식별하고, `c##a`, ##a##t 등이 계산됩니다. 그리고 빈도가 계산됩니다. 각 문자의 빈도도 결정됩니다. 이러한 값들을 알면, 다음 공식에 따라 쌍 점수를 계산할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Tokenization Guide](/assets/img/2024-05-23-TokenizationACompleteGuide_1.png)\n\n이 메트릭은 함께 자주 나타나지만 개별적으로나 다른 문자와 자주 나타나지 않는 문자에 더 높은 점수를 할당합니다. 이것이 WordPiece와 BPE 사이의 주된 차이점인데, BPE는 개별 문자의 전체 빈도를 고려하지 않습니다.\n\n단계 4) 병합 규칙 생성\n\n높은 점수는 자주 함께 나타나는 문자 쌍을 나타냅니다. 즉, c##a가 높은 쌍 점수를 가지면 c와 a가 말뭉치에서 함께 자주 나타나고 개별적으로는 그리 자주 나타나지 않는 것입니다. BPE와 마찬가지로, 병합 규칙은 가장 높은 점수를 가진 문자 쌍에 의해 결정됩니다. 이번에는 빈도가 점수를 결정하는 대신 쌍 점수로 결정됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 단계 5) 단계 3과 4를 반복합니다.\n\n그런 다음 단계 3과 4를 반복하여 더 많은 병합 규칙을 찾고 어휘에 더 많은 문자 쌍을 추가합니다. 이 프로세스는 교육의 시작 부분에서 지정된 목표 크기에 도달할 때까지 계속됩니다.\n\n아래는 이전에 작성한 BPE 모델을 상속하는 WordPiece의 구현입니다.\n\n```js\nclass WordPiece(BPE):\n\n    def add_hashes(self, word):\n        ''' 단어의 각 문자에 # 기호 추가\n\n            문자열로 된 단어를 받아서 처음을 제외한 각 문자에 # 기호를 추가합니다.\n            결과를 반환하며 각 요소가 처음 문자만 일반 문자이고 나머지는 # 기호가\n            앞에 붙은 문자인 리스트로 반환합니다.\n\n            인수:\n                word (str): # 기호를 추가할 단어\n\n            반환값:\n                hashed_word (list): # 기호를 추가한 문자의 목록\n        '''\n        hashed_word = [word[0]]\n\n        for char in word[1:]:\n            hashed_word.append(f'##{char}')\n\n        return hashed_word\n\n\n    def create_merge_rule(self, corpus):\n        ''' 병합 규칙을 만들어 self.merge_rules 목록에 추가합니다.\n\n            인수:\n                corpus (list[tuple(list, int)]): 단어 목록에서 단어의 개별 문자\n                    (또는 나중 반복에서 단어의 하위단어)를 표현하는 요소 및 단어\n                    빈도를 나타내는 정수를 두 번째 요소로 하는 튜플의 목록\n\n            반환값:\n                없음\n        '''\n        pair_frequencies = self.find_pair_frequencies(corpus)\n        char_frequencies = self.find_char_frequencies(corpus)\n        pair_scores = self.find_pair_scores(pair_frequencies, char_frequencies)\n\n        highest_scoring_pair = max(pair_scores, key=pair_scores.get)\n        self.merge_rules.append(highest_scoring_pair.split(','))\n        self.vocabulary.append(highest_scoring_pair)\n\n\n    def create_vocabulary(self, words):\n        ''' 단어 목록에서 고유 문자 목록을 생성합니다.\n\n            BPE 알고리즘과 달리 각 문자를 일반적으로 저장하는 대신 단어의 시작\n            문자 (표시되지 않음)와 단어의 중간 또는 끝에 있는 문자('##'로 표시)를\n            구분합니다. 예를 들어, 단어 'cat'은 ['c', '##a', '##t']로 분할됩니다.\n\n            인수:\n                words (list): 입력 텍스트의 단어를 포함하는 문자열의 목록\n\n            반환값:\n                vocabulary (list): 입력 단어 목록의 모든 고유 문자 목록\n        '''\n        vocabulary = set()\n        for word in words:\n            vocabulary.add(word[0])\n            for char in word[1:]:\n                vocabulary.add(f'##{char}')\n\n        # 나중에 추가할 수 있도록 목록으로 변환\n        vocabulary = list(vocabulary)\n        return vocabulary\n\n\n    def find_char_frequencies(self, corpus):\n        ''' 코퍼스에서 각 문자의 빈도수를 찾습니다.\n\n            코퍼스를 순환하고 문자의 빈도수를 계산합니다.\n            'c'와 '##c'는 서로 다른 문자임에 유의하세요.\n            'c'는 단어의 시작 문자를 나타내고, '##c'는 단어의 중간 또는 끝을\n            나타냅니다. 각 문자 쌍을 키로, 해당 빈도를 값으로 하는 사전 반환합니다.\n\n            인수:\n                corpus (list[tuple(list, int)]): 단어 목록에서 단어의 개별 문자\n                    (또는 나중 반복에서 단어의 하위단어)를 표현하는 요소 및 단어\n                    빈도를 나타내는 정수를 두 번째 요소로 하는 튜플의 목록\n\n            반환값:\n                char_frequencies (dict): 입력 코퍼스의 문자 및 해당 빈도수를\n                    키와 값으로 하는 사전\n        '''\n        char_frequencies = dict()\n\n        for word, word_freq in corpus:\n            for char in word:\n                if char in char_frequencies:\n                    char_frequencies[char] += word_freq\n                else:\n                    char_frequencies[char] = word_freq\n\n        return char_frequencies\n\n\n    def find_pair_scores(self, pair_frequencies, char_frequencies):\n        ''' 코퍼스에서 각 문자 쌍에 대한 쌍 점수를 찾습니다.\n\n            pair_frequencies 사전을 순환하고 코퍼스에서 각 인접 문자 쌍의 쌍\n            점수를 계산합니다. 점수를 사전에 저장하고 반환합니다.\n\n            인수:\n                pair_frequencies (dict): 코퍼스에서 인접 문자 쌍을 키로, 각\n                    쌍 빈도수를 값으로 하는 사전\n\n                char_frequencies (dict): 코퍼스에서 문자를 키로, 해당 빈도수를\n                    값으로 하는 사전\n\n            반환값:\n                pair_scores (dict): 입력 코퍼스의 인접 문자 쌍을 키로, 해당\n                    쌍 점수를 값으로 하는 사전\n        '''\n        pair_scores = dict()\n\n        for pair in pair_frequencies.keys():\n            char_1 = pair.split(',')[0]\n            char_2 = pair.split(',')[1]\n            denominator = (char_frequencies[char_1] * char_frequencies[char_2])\n            score = (pair_frequencies[pair]) / denominator\n            pair_scores[pair] = score\n\n        return pair_scores\n\n\n    def get_merged_chars(self, char_1, char_2):\n        ''' 가장 높은 점수의 쌍을 병합하고 self.merge 메서드에 반환합니다.\n\n            필요에 따라 # 기호를 제거하고 가장 높은 점수의 쌍을 병합한 후\n            병합된 문자를 self.merge 메서드에 반환합니다.\n\n            인수:\n                char_1 (str): 가장 높은 점수의 쌍에서 첫 번째 문자\n                char_2 (str): 가장 높은 점수의 쌍에서 두 번째 문자\n\n            반환값:\n                merged_chars (str): 병합된 문자\n        '''\n        if char_2.startswith('##'):\n            merged_chars = char_1 + char_2[2:]\n        else:\n            merged_chars = char_1 + char_2\n\n        return merged_chars\n\n\n    def initialize_corpus(self, words):\n        ''' 각 단어를 문자로 분할하고 단어 빈도수를 계산합니다.\n\n            입력 단어 목록의 각 단어를 모든 문자로 분할합니다. 각 단어에 대해\n            분할된 단어를 튜플의 첫 번째 요소로 리스트로 저장합니다.\n            단어의 빈도수는 정수로 튜플의 두 번째 요소로 저장합니다.\n            이 작업을 수행한 후 결과인 'corpus' 목록 반환합니다.\n\n            인수:\n                없음\n\n            반환값:\n                corpus (list[tuple(list, int)]): 단어 목록에서 단어의 개별 문자\n                    (또는 나중 반복에서 단어의 하위단어)를 표현하는 요소와 단어\n                    목록에서 해당 단어의 빈도수를 나타내는 정수를 표시하는\n                    두 번째 요소로 하는 튜플의 목록\n        '''\n        corpus = self.calculate_frequency(words)\n        corpus = [(self.add_hashes(word), freq) for (word, freq) in corpus]\n        return corpus\n\n    def tokenize(self, text):\n        ''' 텍스트를 토큰 목록으로 만듭니다.\n\n            인수\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nWordPiece 알고리즘은 BPE 알고리즘에 주어진 장난감 데이터세트와 동일한 데이터세트로 아래에서 훈련됩니다. 이번에 학습한 토큰은 매우 다른 것을 알 수 있습니다. WordPiece는 문자가 서로 더 자주 함께 나타나는 경우를 선호하며, 그래서 데이터세트에 함께만 존재하고 홀로 존재하지 않는 'm'과 'p'는 즉시 병합됩니다. 여기서 이 아이디어는 모델이 문자를 병합함으로써 무엇이 손실되는지 고려하도록 강요하는 것입니다. 즉, 이러한 문자들이 항상 함께 있는가요? 그렇다면, 전혀 하나의 단위로 명백하게 병합되어야 합니다. 또는, 코퍼스에서 문자가 매우 빈번한가요? 그렇다면, 문자는 그냥 일반적이며 데이터세트 안에서 풍부하게 나타나므로 다른 토큰 옆에 나타날 것입니다.\n\n```js\nwp = WordPiece()\nwp.train(words, 30)\n\nprint(f'INITIAL CORPUS:\\n{wp.corpus_history[0]}\\n')\nfor rule, corpus in list(zip(wp.merge_rules, wp.corpus_history[1:])):\n    print(f'NEW MERGE RULE: Combine \"{rule[0]}\" and \"{rule[1]}\"')\n    print(corpus, end='\\n\\n')\n```\n\n```js\n초기 코퍼스:\n[(['c', '##a', '##t'], 5), (['c', '##a', '##t', '##s'], 2),\n(['e', '##a', '##t'], 10), (['e', '##a', '##t', '##i', '##n', '##g'], 3),\n(['r', '##u', '##n', '##n', '##i', '##n', '##g'], 2),\n(['j', '##u', '##m', '##p', '##i', '##n', '##g'], 1),\n(['f', '##o', '##o', '##d'], 6)]\n\nNEW MERGE RULE: \"##m\"과 \"##p\" 병합\n[(['c', '##a', '##t'], 5), (['c', '##a', '##t', '##s'], 2),\n(['e', '##a', '##t'], 10), (['e', '##a', '##t', '##i', '##n', '##g'], 3),\n(['r', '##u', '##n', '##n', '##i', '##n', '##g'], 2),\n(['j', '##u', '##mp', '##i', '##n', '##g'], 1),\n(['f', '##o', '##o', '##d'], 6)]\n\n(이하 생략)\n```\n\n이제 WordPiece 알고리즘이 훈련되었으므로(즉, 모든 병합 규칙이 발견되었으므로), 모델은 모든 텍스트를 토큰화하기 위해 각 단어를 모든 문자로 분리한 다음 문자열의 처음부분에 대해 알려진 토큰을 찾을 수 있는 최대 토큰을 찾아서, 나머지 부분은 찾을 수 있는 최대 토큰을 찾는 방식으로 사용할 수 있습니다. 이 과정은 더 이상 훈련 데이터로부터 알려진 토큰과 일치하지 않을 때까지 반복되며, 따라서 문자열의 남은 부분은 최종 토큰으로 취합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n학습 데이터가 제한적이지만, 모델은 여전히 유용한 토큰을 학습했습니다. 그러나 많은 추가 학습 데이터가 필요함을 명백히 알 수 있습니다. 이 토크나이저를 유용하게 만들기 위해 더 많은 학습 데이터가 필요합니다. 예시 문자열에 대한 성능을 테스트할 수 있습니다. 예시로 'jumper' 단어로 시작해보겠습니다. 먼저 문자열은 ['jump', 'er']로 분리됩니다. 왜냐하면 jump는 단어의 시작에서 발견할 수 있는 가장 큰 토큰이기 때문입니다. 다음으로 er 문자열은 각각의 문자 e와 r로 나뉩니다.\n\n```js\nprint(wp.tokenize(\"jumper\"));\n```\n\n```js\n[\"jump\", \"e\", \"r\"];\n```\n\n## 단일 토큰화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nUnigram 토크나이저는 BPE와 WordPiece와 다른 방식으로 작동합니다. 큰 어휘로 시작하여 원하는 크기에 도달할 때까지 반복적으로 줄여나갑니다.\n\nUnigram 모델은 각 단어 또는 문자의 확률을 고려하는 통계적 방법을 사용합니다. 예를 들어, \"Cats are great but dogs are better\"라는 문장은 [`Cats`, `are`, `great`, `but`, `dogs`, `are`, `better`] 또는 [`C`, `a`, `t`, `s`, `_a`, `r`, `e`, `_g`,`r`, `e`, `a`, `t`, `_b`, `u`, `t`, `_d`, `o`, `g`, `s` `_a`, `r`, `e`, `_b`, `e`, `t`, `t`, `e`, `r`]로 분할될 수 있습니다. 문장이 문자로 분할된 경우, 새로운 단어의 시작을 나타내기 위해 각 문자의 시작 부분에 밑줄이 추가됩니다.\n\n이러한 목록의 각 요소는 토큰 t로 간주될 수 있으며, t1, t2, ..., tn의 일련의 토큰이 발생할 확률은 다음과 같습니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-TokenizationACompleteGuide_2.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nUnigram 모델은 다음 단계를 통해 훈련됩니다:\n\n단계 1) 코퍼스 구성\n\n언제나처럼 입력 텍스트는 정규화 및 사전 토크나이제이션 모델에 전달되어 깨끗한 단어가 생성됩니다. 그런 다음 단어들은 Unigram 모델에 전달되어 각 단어의 빈도를 결정하고, 이 숫자를 단어와 함께 코퍼스라는 목록에 저장합니다.\n\n단계 2) 어휘 구성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nUnigram 모델의 어휘 크기는 매우 크게 시작되고, 원하는 크기에 도달할 때까지 반복적으로 감소합니다. 초기 어휘를 구성하려면 말뭉치에서 가능한 모든 부분 문자열을 찾습니다. 예를 들어, 말뭉치의 첫 번째 단어가 'cats'인 경우, 부분 문자열 ['c', 'a', 't', 's', 'ca', 'at', 'ts', 'cat', 'ats']이 어휘에 추가됩니다.\n\n3단계) 각 토큰의 확률 계산\n\n토큰의 확률은 말뭉치에서 토큰의 발생 횟수를 찾아 총 토큰 발생 횟수로 나누어 근사적으로 계산됩니다.\n\n![이미지](/assets/img/2024-05-23-TokenizationACompleteGuide_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4단계) 단어의 모든 가능한 세분화 찾기\n\n학습 말뭉치에서 단어가 cat인 경우를 고려해보겠습니다. 이는 다음과 같이 세분화될 수 있습니다:\n\n[`c`, `a`, `t`]\n\n[`ca`, `t`]\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[`c`, `at`]\n\n[`cat`]\n\n단계 5) 말뭉치에서 발생 가능한 각 세분화의 근사 확률 계산\n\n위의 방정식들을 결합하면 각 토큰 시리즈에 대한 확률을 얻을 수 있습니다. 예를 들어, 이것은 다음과 같이 보일 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-TokenizationACompleteGuide_4.png\" /\u003e\n\n가장 높은 확률 점수를 가진 세그먼트 [`c`, `at`]가 사용되어 단어를 토크나이즈했습니다. 따라서 단어 cat은 [`c`, `at`]으로 토큰화됩니다. 단어가 긴 경우 토큰화시 단어 내 여러 곳에서 분할이 발생할 수 있습니다. 예를 들어 [`token`, `iza`, tion] 또는 [`token`, `ization`] 같은 경우도 있을 수 있습니다.\n\n6단계) 손실 계산\n\n손실이란 모델의 점수를 나타내며, 중요한 토큰이 어휘에서 제거되면 손실이 크게 증가하지만 중요하지 않은 토큰이 제거되면 손실은 크게 증가하지 않습니다. 모델에서 각 토큰을 제거했을 때 손실이 얼마나 되는지 계산하여, 어휘 중에서 가장 쓸모없는 토큰을 찾을 수 있습니다. 훈련 세트 말뭉치에서 가장 유용한 토큰만 남도록 어휘 크기가 감소할 때까지 반복적으로 수행할 수 있습니다. 손실은 다음과 같이 주어집니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Tokenization Guide](/assets/img/2024-05-23-TokenizationACompleteGuide_5.png)\n\n필요한 양만큼 문자가 제거되어 어휘를 원하는 크기로 줄일 때, 교육은 완료되고 모델을 사용하여 단어를 토큰화할 수 있습니다.\n\n## BPE, WordPiece 및 Unigram 비교\n\n학습 세트 및 토큰화해야 할 데이터에 따라 어떤 토크나이저가 다른 것보다 더 잘 작동할 수 있습니다. 언어 모델에 대한 토크나이저를 선택할 때, 특정 사용 사례에 사용된 학습 세트를 실험하여 최상의 결과를 얻는 것이 가장 좋을 수 있습니다. 그러나 이 세 가지 토크나이저의 일반적인 경향에 대해 논의하는 것이 유용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n세 가지 중에서 BPE가 현재 언어 모델 토크나이저로 가장 인기 있는 선택인 것으로 보입니다. 그러나 변화가 빠르게 일어나는 이 분야에서는 앞으로 변동이 있을 수 있습니다. 사실, SentencePiece와 같은 다른 서브워드 토크나이저들이 최근에 훨씬 더 인기를 얻고 있습니다.\n\nWordPiece는 BPE와 Unigram에 비해 더 많은 단어 토큰을 생성하는 것으로 보입니다. 그러나 모델 선택과 관계 없이 어휘 크기가 커질수록 모든 토크나이저가 더 적은 토큰을 생성하는 것으로 보입니다.\n\n최종적으로, 토크나이저의 선택은 모델과 함께 사용하려는 데이터셋에 따라 다릅니다. 안전한 선택은 BPE 또는 SentencePiece를 시도하고, 그 이후에 실험하는 것일 수 있습니다.\n\n## 후처리\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n토큰화 파이프라인의 마지막 단계는 후처리입니다. 여기서 필요한 경우 출력에 최종 수정을 가할 수 있습니다. BERT는 이 단계를 사용하여 두 가지 추가 토큰을 추가하는 데 유명합니다:\n\n- [CLS] - 이 토큰은 `classification`를 나타내며 입력 텍스트의 시작을 표시하는 데 사용됩니다. 이는 BERT에서 필요한 것인데, 이 토큰의 이름에서 알 수 있듯이 이를 사용하여 분류 작업이 수행되었기 때문입니다. 분류 작업에 사용되지 않을 때도 모델에서 여전히 이 토큰을 예상합니다.\n- [SEP] - 이 토큰은 `separation`을 나타내며 입력에서 문장을 분리하는 데 사용됩니다. BERT가 수행하는 많은 작업에 유용하며, 동일한 프롬프트에서 동시에 여러 지시사항을 처리할 때도 사용됩니다.\n\n# Python 라이브러리의 토크나이저\n\nHugging Face는 Python을 포함한 여러 프로그래밍 언어에서 사용할 수 있는 토크나이저 라이브러리를 제공합니다. 이 라이브러리에는 사용자가 사전 훈련된 모델을 사용할 수 있는 일반 Tokenizer 클래스가 포함되어 있으며, 전체 목록은 Hugging Face 웹사이트에서 확인할 수 있습니다. 게다가, 라이브러리에는 사용자가 자체 데이터로 훈련할 수 있는 네 가지 사전 제작되지만 미학습된 모델도 포함되어 있습니다. 이는 특정 유형의 문서에 튜닝된 특정 토크나이저를 작성하는 데 유용합니다. 아래 셀은 Python에서 사전 훈련된 및 미학습된 토크나이저를 사용하는 예시를 보여줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프리트레인 토크나이저 사용하기\n\n토크나이저 라이브러리를 사용하면 프리트레인 토크나이저를 쉽게 사용할 수 있습니다. Tokenizer 클래스를 가져와서 from_pretrained 메소드를 호출하고 사용할 토크나이저의 모델 이름을 전달하면 됩니다. 모델의 목록은 [16]에서 확인할 수 있습니다.\n\n```js\nfrom tokenizers import Tokenizer\n\ntokenizer = Tokenizer.from_pretrained('bert-base-cased')\n```\n\n토크나이저 학습하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n원하는 토큰 만들기되지만 미학습 토크나이저를 사용하려면 tokenizers 라이브러리에서 원하는 모델을 가져와서 모델 클래스의 인스턴스를 만들면 됩니다. 위에서 설명한대로 라이브러리에는 네 가지 모델이 포함되어 있습니다:\n\n- BertWordPieceTokenizer - 유명한 Bert 토크나이저인 WordPiece를 사용합니다.\n- CharBPETokenizer - 원래의 BPE(BPE)\n- ByteLevelBPETokenizer - BPE의 바이트 레벨 버전\n- SentencePieceBPETokenizer - SentencePiece에서 사용하는 BPE 구현과 호환되는 버전\n\n모델을 학습하려면 train 메서드를 사용하고 학습 데이터가 포함된 파일의 경로(또는 파일 경로 목록)를 전달하면 됩니다. 학습을 마치면 모델은 encode 메서드를 사용하여 일부 텍스트를 토큰화하는 데 사용할 수 있습니다. 마지막으로 학습된 토크나이저는 save 메서드를 사용하여 저장할 수 있으므로 학습을 다시 수행할 필요가 없습니다. 아래는 Hugging Face Tokenizers GitHub 페이지에서 제공되는 예제를 수정한 예시 코드입니다 [17].\n\n```js\n# 토크나이저 가져오기\nfrom tokenizers import BertWordPieceTokenizer, CharBPETokenizer, \\\n                       ByteLevelBPETokenizer, SentencePieceBPETokenizer\n\n# 모델 인스턴스화\ntokenizer = CharBPETokenizer()\n\n# 모델 학습\ntokenizer.train(['./path/to/files/1.txt', './path/to/files/2.txt'])\n\n# 텍스트 토큰화\nencoded = tokenizer.encode('I can feel the magic, can you?')\n\n# 모델 저장\ntokenizer.save('./path/to/directory/my-bpe.tokenizer.json')\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n토크나이저 라이브러리는 이전 섹션에서 보여주었던 것과 같이 처음부터 전체 모델을 구현할 필요 없이 매우 빠르게 사용자 정의 토크나이저를 만들 수 있는 구성 요소도 제공합니다. 아래 셀에는 Hugging Face GitHub 페이지 [17]에서 가져온 예시가 표시되어 있습니다. 해당 예시에서는 토크나이저의 사전 토크나이제이션 및 디코딩 단계를 사용자 정의하는 방법을 보여줍니다. 이 경우, 사전 토크나이제이션 단계에서 접두어 공백이 추가되었고, 디코더로는 ByteLevel 디코더가 선택되었습니다. Hugging Face 문서 [18]에는 사용자 정의 옵션의 전체 목록이 제공됩니다.\n\n```js\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, \\\n                       processors\n\n# 토크나이저 초기화\ntokenizer = Tokenizer(models.BPE())\n\n# 사전 토크나이제이션 및 디코딩 사용자 정의\ntokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\ntokenizer.decoder = decoders.ByteLevel()\ntokenizer.post_processor = processors.ByteLevel(trim_offsets=True)\n\n# 그리고 학습\ntrainer = trainers.BpeTrainer(\n    vocab_size=20000,\n    min_frequency=2,\n    initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\n)\ntokenizer.train([\n    \"./path/to/dataset/1.txt\",\n    \"./path/to/dataset/2.txt\",\n    \"./path/to/dataset/3.txt\"\n], trainer=trainer)\n\n# 그리고 저장\ntokenizer.save(\"byte-level-bpe.tokenizer.json\", pretty=True)\n```\n\n# 결론\n\n토큰화 파이프라인은 언어 모델의 중요한 부분이며, 어떤 종류의 토크나이저를 사용할지 결정할 때 신중한 고려가 필요합니다. 요즘에는 Hugging Face와 같은 라이브러리의 개발자들이 우리를 대신하여 많은 이러한 결정을 내려주고 있습니다. 이를 통해 사용자는 빠르게 사용자 지정 데이터로 언어 모델을 학습하고 사용할 수 있습니다. 그러나 토큰화 방법에 대한 탄탄한 이해는 모델을 미세 조정하고 다양한 데이터셋에서 추가 성능을 얻는 데 귀중합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 참고 자료\n\n[1] 표지 이미지 — Stable Diffusion Web\n\n[2] 토큰 정의 — Stanford NLP 그룹\n\n[3] 단어 토크나이저 — Towards Data Science\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- [4] TransformerXL 논문 — ArXiv\n\n- [5] Tokenizers — Hugging Face\n\n- [6] 단어 기반, 서브워드, 문자 기반 토크나이저 — Towards Data Science\n\n- [7] 토큰화 파이프라인 — Hugging Face\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\\[8\\] Pre-tokenizers — Hugging Face\n\n\\[9\\] Language Models are Unsupervised Multitask Learners — OpenAI\n\n\\[10\\] BART Model for Text Autocompletion in NLP — Geeks for Geeks\n\n\\[11\\] Byte Pair Encoding — Hugging Face\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[12] WordPiece 토큰화 — Hugging Face\n\n[13] 두 분 NLP — 토큰화 방법론의 분류 — Medium\n\n[14] 서브워드 토크나이저 비교 — Vinija AI\n\n[15] BERT가 단어 맥락 관계를 배우는 데 어떻게 Attention 메커니즘과 Transformer를 활용하는가 — Medium\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[16] 사전 훈련된 모델 목록 — Hugging Face\n\n[17] Hugging Face Tokenizers 라이브러리 — GitHub\n\n[18] 사전 토크나이제이션 문서 — Hugging Face\n","ogImage":{"url":"/assets/img/2024-05-23-TokenizationACompleteGuide_0.png"},"coverImage":"/assets/img/2024-05-23-TokenizationACompleteGuide_0.png","tag":["Tech"],"readingTime":48},{"title":"고급 RAG 07 테이블을 위한 RAG 탐색","description":"","date":"2024-05-23 18:13","slug":"2024-05-23-AdvancedRAG07ExploringRAGforTables","content":"\nRAG를 구현하는 것은 도전적인 과제를 제공하는데, 특히 비구조화된 문서의 테이블을 효과적으로 구문 분석하고 이해하는 부분이 그 중요한 부분입니다. 특히 스캔된 문서나 이미지 형식의 문서에서는 이 작업이 특히 어려울 수 있습니다. 이러한 도전 과제에는 적어도 다음 세 가지 측면이 있습니다:\n\n- 스캔된 문서 또는 이미지 문서의 복잡성, 다양한 구조, 비텍스트 요소의 포함 및 필기 및 인쇄된 내용의 결합과 같은 특징들은 테이블 정보를 정확하게 자동 추출하는 데 도전을 제공합니다. 부정확한 구문 분석은 테이블 구조를 손상시킬 수 있으며, 불완전한 테이블을 포함하는 것은 테이블의 의미 정보를 포착하지 못할 뿐만 아니라 RAG 결과를 손상시킬 수 있습니다.\n- 테이블 캡션을 추출하고 해당 테이블에 효과적으로 연결하는 방법.\n- 테이블의 의미 정보를 효과적으로 저장하기 위한 색인 구조를 설계하는 방법.\n\n이 기사는 RAG 내에서 테이블을 관리하는 주요 기술을 소개한 후 일부 기존 오픈 소스 솔루션을 검토한 다음 새로운 솔루션을 제안하고 구현하는 방법을 제시합니다.\n\n# 주요 기술\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 테이블 구문 분석\n\n이 모듈의 주요 기능은 정형화되지 않은 문서나 이미지에서 테이블 구조를 정확하게 추출하는 것입니다.\n\n추가 기능: 해당하는 테이블 캡션을 추출하고, 개발자가 해당 테이블 캡션을 테이블과 관련 짓기 편리하도록 하는 것이 가장 좋습니다.\n\n제 현재 이해에 따르면, Figure 1에 나타난 것처럼 여러 가지 방법이 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png)\n\n(a). 다중 모달 LLM(예: GPT-4V)을 활용하여 각 PDF 페이지에서 표를 식별하고 정보를 추출합니다.\n\n- 입력: 이미지 형식의 PDF 페이지\n- 출력: JSON 또는 다른 형식의 표. 다중 모달 LLM이 표 데이터를 추출하지 못하는 경우 이미지를 요약하고 요약본을 반환해야 합니다.\n\n(b). Table Transformer와 같은 전문적인 표 감지 모델을 활용하여 표 구조를 식별합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 입력: 이미지로 된 PDF 페이지\n- 출력: 이미지로 된 테이블\n\n(c). 오픈 소스 프레임워크인 unstructured 등을 사용하여 객체 검출 모델을 활용하세요(unstructured의 테이블 검출 과정은 이 기사에 자세히 기재되어 있습니다). 이러한 프레임워크를 사용하면 전체 문서의 철저한 구문 분석과 구문 분석 결과로부터 테이블 관련 콘텐츠의 추출이 가능합니다.\n\n- 입력: PDF 또는 이미지 형식의 문서\n- 출력: 문서 전체의 구문 분석 결과로부터 얻은 테이블을 일반 텍스트 또는 HTML 형식으로\n\n(d). Nougat, Donut 등의 end-to-end 모델을 사용하여 전체 문서를 구문 분석하고 테이블 관련 콘텐츠를 추출하세요. 이 접근 방식은 OCR 모델을 필요로하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 입력: PDF 또는 이미지 형식의 문서\n- 출력: 전체 문서의 구문 분석 결과를 통해 얻은 LaTeX 또는 JSON 형식의 표\n\n언급할 가치가 있는 것은 표 정보를 추출하는 방법에 관계없이 표 캡션을 포함해야 합니다. 대부분의 경우 표 캡션은 문서나 논문 작성자가 표에 대해 간단히 설명한 것으로, 전체 표를 크게 요약할 수 있습니다.\n\n위에서 언급한 네 가지 방법 중 (d) 방법은 표 캡션을 쉽게 검색할 수 있습니다. 개발자에게는 이 방법이 유용한데, 표 캡션을 표와 연관시킬 수 있도록 해주기 때문입니다. 이 내용은 다음 실험에서 자세히 설명될 것입니다.\n\n## 색인 구조\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n색인 구조에 따라 해결책은 대략 다음 카테고리로 나뉩니다:\n\n(e). 이미지 형식의 색인 표만 있는 경우.\n\n(f). 일반 텍스트 또는 JSON 형식의 색인 표만 있는 경우.\n\n(g). LaTeX 형식의 색인 표만 있는 경우.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n### (h). 테이블 요약만 색인화합니다.\n\n### (i). 작은 부터 큰 또는 문서 요약 색인 구조, Figure 2에 나와 있는 것처럼.\n\n- 작은 청크의 내용은 테이블의 각 행 정보 또는 테이블 요약일 수 있습니다.\n- 큰 청크의 내용은 이미지 형식, 일반 텍스트 형식 또는 LaTeX 형식의 테이블일 수 있습니다.\n\n![Figure 2](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서 논의한 대로 Table summary는 일반적으로 LLM을 사용하여 생성됩니다:\n\n- 입력: 이미지 형식, 텍스트 형식 또는 LaTeX 형식의 테이블\n- 출력: 테이블 요약\n\n## Table Parsing, Indexing 또는 RAG가 필요하지 않은 algorithms\n\n일부 알고리즘은 테이블 파싱이 필요하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n(j). 관련 이미지(PDF 페이지)와 사용자 쿼리를 VQA 모델(예: DAN 등)이나 멀티모달 LLM에 보내고 답변을 받습니다.\n\n- 색인할 내용: 이미지 형식의 문서\n- VQA 모델이나 멀티모달 LLM에 전송되는 내용: 쿼리 + 해당 이미지 페이지\n\n(k). 관련 텍스트 형식의 PDF 페이지와 사용자 쿼리를 LLM에 보내고, 그런 다음 답변을 받습니다.\n\n- 색인할 내용: 텍스트 형식의 문서\n- LLM에 전송되는 내용: 쿼리 + 해당 텍스트 형식의 페이지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n(l) 사용자의 쿼리와 관련 이미지(PDF 페이지), 텍스트 청크를 다중 모달 LLM(예: GPT-4V 등)에 보내고 답변을 직접 반환합니다.\n\n- 색인할 콘텐츠: 이미지 형식의 문서 및 텍스트 형식의 문서 청크\n- 다중 모달 LLM에 보내는 콘텐츠: 쿼리 + 문서의 이미지 형식 + 해당하는 텍스트 청크\n\n또한, 다음은 색인이 필요하지 않은 몇 가지 방법입니다. 그림 3과 그림 4에서 보듯이:\n\n![image](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n(m). 먼저, 문서의 모든 표를 이미지 형태로 변환하기 위해 (a)부터 (d) 범주 중 하나의 방법을 적용하세요. 그런 다음 모든 표 이미지와 사용자 질의를 멀티모달 LLM(예: GPT-4V 등)에 직접 전송하여 답변을 받아보세요.\n\n- 색인할 내용: 없음\n- 멀티모달 LLM에 전송될 내용: 질의 + 모든 변환된 표(이미지 형태)\n\n![표 이미지](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_3.png)\n\n(n). (m)에서 추출된 이미지 형식의 표를 사용하여 OCR 모델을 이용해 표 안의 모든 텍스트를 인식한 후, 표 안의 모든 텍스트와 사용자 질의를 LLM에 직접 전송하여 답변을 받아보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 색인할 콘텐츠: 없음\n- LLM에 보내지는 콘텐츠: 사용자 쿼리 + 모든 테이블 내용(텍스트 형식)\n\n익명의 사실을 공유하자면, 일부 방법은 RAG 프로세스에 의존하지 않습니다:\n\n- 첫 번째 방법은 LLM을 사용하지 않으며, 특정 데이터세트에서 학습하며 모델(예: BERT와 유사한 트랜스포머)이 TAPAS와 같은 테이블 이해 작업을 더 잘 지원하도록 합니다.\n- 두 번째 방법은 LLM을 사용하며, 사전 학습, 파인 튜닝 방법 또는 프롬프트를 사용하여 LLM이 GPT4Table과 같은 테이블 이해 작업을 수행할 수 있도록 합니다.\n\n# 기존 오픈 소스 솔루션\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전 섹션에서는 RAG의 테이블에 대한 주요 기술을 요약하고 분류했습니다. 이 글이 구현하는 해결책을 제안하기 전에 오픈 소스 솔루션 중 일부를 탐색해보겠습니다.\n\nLlamaIndex는 네 가지 방법을 제안했는데, 처음 세 가지는 다중 모달 모델을 사용합니다.\n\n- 관련 이미지(PDF 페이지)를 검색하여 이를 GPT-4V에 보내 쿼리에 대답하도록 합니다.\n- 각 PDF 페이지를 이미지로 간주하고, 각 페이지에 대해 이미지 추론을 수행하도록 GPT-4V에게 맡깁니다. 이미지 추론을 위한 텍스트 벡터 저장소 인덱스를 작성합니다. 이미지 추론 벡터 저장소에 대한 답변을 쿼리로 가져옵니다.\n- 테이블 트랜스포머를 사용하여 검색된 이미지에서 테이블 정보를 잘라내고, 이러한 잘린 이미지를 GPT-4V에 보내 쿼리 응답을 받습니다.\n- 잘려진 테이블 이미지에 OCR을 적용하고 데이터를 GPT4/GPT-3.5로 보내어 쿼리에 답변을 받습니다.\n\n이 글의 분류에 따르면:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이 기사에서의 (j) 항목과 유사한 첫 번째 방법은 테이블 구문 분석이 필요하지 않습니다. 그러나 결과는 이미지에 정답이 있더라도 올바른 답을 내놓지 못하는 것을 보여줍니다.\n- 두 번째 방법은 테이블 구문 분석을 포함하며 (a) 항목과 일치합니다. 색인된 콘텐츠는 GPT-4V의 결과에 따라 테이블 콘텐츠 또는 요약이며, 이는 (f) 또는 (h)에 해당할 수 있습니다. 이 방법의 단점은 GPT-4V가 이미지에서 테이블을 식별하고 내용을 추출하는 능력이 불안정하다는 것이며, PDF 형식에서 발생하는 테이블, 텍스트 및 다른 이미지가 혼합된 경우에 특히 해당됩니다.\n- 세 번째 방법은 (m) 항목과 유사하며 색인이 필요하지 않습니다.\n- 네 번째 방법은 (n) 항목과 유사하며 또한 색인이 필요하지 않습니다. 결과는 이미지에서 테이블 정보를 추출하는 능력이 없어 잘못된 답변이 생성된다고 나타냅니다.\n\n테스트 결과, 세 번째 방법이 전반적으로 가장 효과적인 것으로 나타났습니다. 그러나 제 테스트에 따르면 세 번째 방법은 테이블을 감지하는 데 어려움을 겪고, 특히 테이블 제목을 올바르게 병합하는 것조차 어렵다는 것을 보여줍니다.\n\nLangchain은 일부 솔루션을 제안했습니다. Semi-structured RAG의 주요 기술은 다음과 같습니다:\n\n- 테이블 구문 분석은 비구조적을 사용하며, 이는 (c) 항목에 해당합니다.\n- 색인 방법은 문서 요약 색인이며, 이는 (i) 항목에 해당합니다. 작은 청크 콘텐츠: 테이블 요약, 큰 청크 콘텐츠: 원시 테이블 콘텐츠(텍스트 형식).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 그림 5에 나타난 대로:\n\n![Figure 5](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_4.png)\n\n반구조화 및 멀티 모달 RAG는 세 가지 해결책을 제안하며, 아키텍처는 아래 그림 6에 나와 있습니다.\n\n![Figure 6](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n옵션 1은 이 기사의 (l) 범주와 유사합니다. 멀티모달 임베딩(예: CLIP)을 사용하여 이미지와 텍스트를 임베드하고 유사성 검색을 통해 둘 다 검색하며, 생 이미지 및 청크를 멀티모달 LLM에게 전달하여 답변 합성을 수행합니다.\n\n옵션 2은 이미지로부터 텍스트 요약을 생성하는 멀티모달 LLM(예: GPT-4V, LLaVA, 또는 FUYU-8b)을 활용합니다. 그런 다음 텍스트를 임베드하고 검색하여 텍스트 청크를 LLM에게 전달하여 답변 합성을 합니다.\n\n- 테이블 파싱은 구조화되지 않은 것을 사용합니다. 이는 범주 (d)입니다.\n- 색인 구조는 문서 요약 인덱스(범주 (i))이며, 작은 청크 내용: 테이블 요약, 큰 청크 내용: 텍스트 형식의 테이블\n\n옵션 3은 이미지로부터 텍스트 요약을 생성하기 위해 멀티모달 LLM(예: GPT-4V, LLaVA, 또는 FUYU-8b)를 사용합니다. 그런 다음 이미지 요약을 임베드하고 검색하여 원본 이미지에 대한 이미지 요약과 함께 반환하고, 원본 이미지 및 텍스트 청크를 멀티모달 LLM에게 전달하여 답변 합성을 수행합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 제안된 솔루션\n\n이 글은 주요 기술 및 기존 솔루션을 요약, 분류 및 논의하였습니다. 이를 기반으로 다음과 같은 솔루션을 제안합니다. 간단히 말해서 Re-ranking 및 query rewriting과 같은 RAG 모듈은 생략되었습니다.\n\n![Figure 7](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_6.png)\n\n- 테이블 파싱: Nougat(catogery (d))를 사용합니다. 제 테스트에 따르면, 이는 테이블 감지가 unstructured(catogery (c))보다 더 효과적입니다. 게다가 Nougat은 테이블 캡션을 잘 추출하여 테이블과 연결하는 데 매우 편리합니다.\n- 문서 요약 인덱스 구조(catogery (i)): 작은 청크의 내용에는 테이블 요약이, 큰 청크의 내용에는 LaTeX 형식의 해당 테이블과 텍스트 형식의 테이블 캡션이 포함됩니다. 이를 다중 벡터 검색기를 사용하여 구현합니다.\n- 테이블 요약 획득 방법: 테이블과 테이블 캡션을 LLM에 보내 요약을 받습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 방법의 장점은 테이블을 효율적으로 구문 분석하면서 테이블 요약과 테이블 간의 관계를 포괄적으로 고려한다는 것입니다. 또한, 멀티모달 LLM이 필요하지 않아 비용을 절감할 수 있습니다.\n\n## Nougat의 원칙\n\nNougat은 도넛 아키텍처를 바탕으로 개발되었습니다. Figure 8에서 보여지듯이 OCR 관련 입력이나 모듈이 필요하지 않고 네트워크를 통해 텍스트를 인식합니다.\n\n![Nougat Principle](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n누가(Nougat)가 수식을 분석하는 능력이 인상적이에요. 테이블 분석에도 능숙해요. 더불어, 테이블 캡션을 연결하여 보여줄 수 있어 편하지요. 그림 9에서 보여졌듯이요:\n\n![Figure 9](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_8.png)\n\n수많은 논문을 테스트한 결과, 테이블 캡션이 항상 테이블 다음 줄에 고정되어 있는 것을 발견했어요. 이 일관성은 우연이 아님을 시사하며, 그래서 누가(Nougat)가 이 효과를 달성하는 방법에 관심이 있어요.\n\n중간 결과가 없는 엔드 투 엔드 모델이므로, 훈련 데이터에 많이 의존할 것으로 예상됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 누가(Nougat)는 이전 파싱 도구에서 어려웠던 부분인 수식 및 표와 같은 부분을 정확하게 LaTeX 소스 코드로 파싱할 수 있습니다.\n- 누가(Nougat)의 파싱 결과는 마크다운과 유사한 반구조화된 문서입니다.\n- 쉽게 표 제목을 얻고 해당 표와 편리하게 연결할 수 있습니다.\n\n단점:\n\n- 누가(Nougat)의 파싱 속도가 느리기 때문에 대규모 배포에 도전이 될 수 있습니다.\n- 누가(Nougat)는 과학 논문을 기반으로 학습되었기 때문에 비슷한 구조의 문서에서 뛰어난 성능을 발휘합니다. 그러나 비라틴 문자 텍스트 문서에서는 성능이 떨어집니다.\n- 누가(Nougat) 모델은 한 번에 한 페이지의 과학 논문만을 학습하며, 다른 페이지에 대한 지식이 부족합니다. 이로 인해 파싱된 콘텐츠에 일관성이 없을 수 있습니다. 따라서, 인식 효과가 좋지 않다면 PDF를 개별 페이지로 나누고 하나씩 파싱하는 것을 고려해야 합니다.\n- 이중 칼럼 논문에서의 표 파싱은 단일 칼럼 논문과 같이 효과적이지 않을 수 있습니다.\n\n## 코드 구현\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 관련 Python 패키지를 설치해주세요.\n\n```js\npip install langchain\npip install chromadb\npip install nougat-ocr\n```\n\n설치를 완료한 후, Python 패키지의 버전을 확인할 수 있습니다.\n\n```js\nlangchain                                0.1.12\nlangchain-community                      0.0.28\nlangchain-core                           0.1.31\nlangchain-openai                         0.0.8\nlangchain-text-splitters                 0.0.1\n\nchroma-hnswlib                           0.7.3\nchromadb                                 0.4.24\n\nnougat-ocr                               0.1.17\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n환경을 설정하고 라이브러리를 가져와주세요:\n\n```js\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPEN_AI_KEY\"\n\nimport subprocess\nimport uuid\n\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain.retrievers.multi_vector import MultiVectorRetriever\nfrom langchain.storage import InMemoryStore\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_core.documents import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.runnables import RunnablePassthrough\n```\n\nAttention Is All You Need 논문을 YOUR_PDF_PATH로 다운로드하고, nougat을 실행하여 PDF 파일을 구문 분석하고 해당 결과로부터 LaTex 형식의 표 및 텍스트 형식의 표 캡션을 얻어주세요. 첫 실행 시 필요한 모델 파일이 다운로드됩니다.\n\n```js\ndef june_run_nougat(file_path, output_dir):\n    # nougat을 실행하고 결과를 Mathpix Markdown으로 저장합니다.\n    cmd = [\"nougat\", file_path, \"-o\", output_dir, \"-m\", \"0.1.0-base\", \"--no-skipping\"]\n    res = subprocess.run(cmd)\n    if res.returncode != 0:\n        print(\"nougat 실행 중 오류가 발생했습니다.\")\n        return res.returncode\n    else:\n        print(\"작업 완료!\")\n        return 0\n\ndef june_get_tables_from_mmd(mmd_path):\n    f = open(mmd_path)\n    lines = f.readlines()\n    res = []\n    tmp = []\n    flag = \"\"\n    for line in lines:\n        if line == \"\\\\begin{table}\\n\":\n            flag = \"BEGINTABLE\"\n        elif line == \"\\\\end{table}\\n\":\n            flag = \"ENDTABLE\"\n\n        if flag == \"BEGINTABLE\":\n            tmp.append(line)\n        elif flag == \"ENDTABLE\":\n            tmp.append(line)\n            flag = \"CAPTION\"\n        elif flag == \"CAPTION\":\n            tmp.append(line)\n            flag = \"MARKDOWN\"\n            print('-' * 100)\n            print(''.join(tmp))\n            res.append(''.join(tmp))\n            tmp = []\n\n    return res\n\nfile_path = \"YOUR_PDF_PATH\"\noutput_dir = \"YOUR_OUTPUT_DIR_PATH\"\n\nif june_run_nougat(file_path, output_dir) == 1:\n    import sys\n    sys.exit(1)\n\nmmd_path = output_dir + '/' + os.path.splitext(file_path)[0].split('/')[-1] + \".mmd\"\ntables = june_get_tables_from_mmd(mmd_path)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n함수 june_get_tables_from_mmd은 Figure 10에 표시된 mmd 파일에서 'table'부터 'table'까지의 모든 내용 및 'table' 다음 줄을 추출하는 데 사용됩니다.\n\n![이미지](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_9.png)\n\n표 캡션을 표 아래에 배치해야 하거나 표가 'table'로 시작하고 'end'로 끝나야 한다는 것을 명시하는 공식 문서가 발견되지 않았다는 점을 유의하십시오. 따라서 june_get_tables_from_mmd는 휴리스틱입니다.\n\nPDF에서 표를 구문 분석한 결과는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n표 1: 다양한 레이어 유형에 대한 최대 경로 길이, 레이어당 복잡성 및 최소 순차 작업 수가 표시됩니다.\n\n표 2: Transformer가 영어-독일어 및 영어-프랑스어 newstest2014 테스트에서 이전 최신 모델보다 더 우수한 BLEU 점수를 달성하며 훈련 비용이 줄어드는 것을 보여줍니다.\n\n표 3: Transformer 아키텍처의 변형이 나열되어 있으며, 기본 모델 정보와 영어-독일어 번역 개발 세트 newstest2013에서의 모든 메트릭스가 제공됩니다.\n\n표 4: Transformer가 영어 구성 구문 분석에 잘 일반화되며, WSJ 23 섹션의 결과가 제시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_10.png\" /\u003e\n\n다중 벡터 리트리버를 사용하여 문서 요약 색인 구조를 구축해보세요.\n\n```js\n# 자식 청크를 색인화하는 데 사용할 벡터스토어\nvectorstore = Chroma(collection_name = \"summaries\", embedding_function = OpenAIEmbeddings())\n\n# 상위 문서를 위한 저장소 레이어\nstore = InMemoryStore()\nid_key = \"doc_id\"\n\n# 리트리버 (시작할 때는 빈 상태)\nretriever = MultiVectorRetriever(\n    vectorstore = vectorstore,\n    docstore = store,\n    id_key = id_key,\n    search_kwargs={\"k\": 1} # 요청된 결과의 수가 색인 요소보다 큰 4이므로, n_results = 1로 업데이트하겠습니다\n)\n\n# 테이블 추가\ntable_ids = [str(uuid.uuid4()) for _ in tables]\nsummary_tables = [\n    Document(page_content = s, metadata = {id_key: table_ids[i]})\n    for i, s in enumerate(table_summaries)\n]\nretriever.vectorstore.add_documents(summary_tables)\nretriever.docstore.mset(list(zip(table_ids, tables)))\n```\n\n모든 준비가 되었습니다. 간단한 RAG 파이프라인을 구축하고 쿼리를 수행해보세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 프롬프트 템플릿\n템플릿 = \"\"\"다음 콘텍스트를 기반으로 질문에 답하세요. 이는 텍스트와 테이블을 포함할 수 있으며 LaTeX 형식의 테이블과 일반 텍스트 형식의 테이블 캡션을 포함합니다:\n{context}\n질문: {question}\n\"\"\"\n프롬프트 = ChatPromptTemplate.from_template(템플릿)\n\n# LLM\n모델 = ChatOpenAI(temperature = 0, model = \"gpt-3.5-turbo\")\n\n\n# 간단한 RAG 파이프라인\n체인 = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | 프롬프트\n    | 모델\n    | StrOutputParser()\n)\n\n\nprint(체인.invoke(\"when layer type is Self-Attention, what is the Complexity per Layer?\"))  # 테이블 1에 관한 쿼리\n\nprint(체인.invoke(\"Which parser performs worst for BLEU EN-DE\"))  # 테이블 2에 관한 쿼리\n\nprint(체인.invoke(\"Which parser performs best for WSJ 23 F1\"))  # 테이블 4에 관한 쿼리\n```\n\n아래는 실행 결과입니다. 여러 질문이 정확히 답변되었음을 보여주는데, 이는 도표 12에 나와 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_11.png\" /\u003e\n\n전체 코드는 아래와 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPEN_AI_KEY\"\n\nimport subprocess\nimport uuid\n\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain.retrievers.multi_vector import MultiVectorRetriever\nfrom langchain.storage import InMemoryStore\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_core.documents import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.runnables import RunnablePassthrough\n\n\ndef june_run_nougat(file_path, output_dir):\n    # Run Nougat and store results as Mathpix Markdown\n    cmd = [\"nougat\", file_path, \"-o\", output_dir, \"-m\", \"0.1.0-base\", \"--no-skipping\"]\n    res = subprocess.run(cmd)\n    if res.returncode != 0:\n        print(\"Error when running nougat.\")\n        return res.returncode\n    else:\n        print(\"Operation Completed!\")\n        return 0\n\ndef june_get_tables_from_mmd(mmd_path):\n    f = open(mmd_path)\n    lines = f.readlines()\n    res = []\n    tmp = []\n    flag = \"\"\n    for line in lines:\n        if line == \"\\\\begin{table}\\n\":\n            flag = \"BEGINTABLE\"\n        elif line == \"\\\\end{table}\\n\":\n            flag = \"ENDTABLE\"\n\n        if flag == \"BEGINTABLE\":\n            tmp.append(line)\n        elif flag == \"ENDTABLE\":\n            tmp.append(line)\n            flag = \"CAPTION\"\n        elif flag == \"CAPTION\":\n            tmp.append(line)\n            flag = \"MARKDOWN\"\n            print('-' * 100)\n            print(''.join(tmp))\n            res.append(''.join(tmp))\n            tmp = []\n\n    return res\n\nfile_path = \"YOUR_PDF_PATH\"\noutput_dir = \"YOUR_OUTPUT_DIR_PATH\"\n\nif june_run_nougat(file_path, output_dir) == 1:\n    import sys\n    sys.exit(1)\n\nmmd_path = output_dir + '/' + os.path.splitext(file_path)[0].split('/')[-1] + \".mmd\"\ntables = june_get_tables_from_mmd(mmd_path)\n\n\n# Prompt\nprompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\\nGive a concise summary of the table or text. The table is formatted in LaTeX, and its caption is in plain text format: {element}  \"\"\"\nprompt = ChatPromptTemplate.from_template(prompt_text)\n\n# Summary chain\nmodel = ChatOpenAI(temperature = 0, model = \"gpt-3.5-turbo\")\nsummarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n# Get table summaries\ntable_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\nprint(table_summaries)\n\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(collection_name = \"summaries\", embedding_function = OpenAIEmbeddings())\n\n# The storage layer for the parent documents\nstore = InMemoryStore()\nid_key = \"doc_id\"\n\n# The retriever (empty to start)\nretriever = MultiVectorRetriever(\n    vectorstore = vectorstore,\n    docstore = store,\n    id_key = id_key,\n    search_kwargs={\"k\": 1} # Solving Number of requested results 4 is greater than number of elements in index..., updating n_results = 1\n)\n\n# Add tables\ntable_ids = [str(uuid.uuid4()) for _ in tables]\nsummary_tables = [\n    Document(page_content = s, metadata = {id_key: table_ids[i]})\n    for i, s in enumerate(table_summaries)\n]\nretriever.vectorstore.add_documents(summary_tables)\nretriever.docstore.mset(list(zip(table_ids, tables)))\n\n\n# Prompt template\ntemplate = \"\"\"Answer the question based only on the following context, which can include text and tables, there is a table in LaTeX format and a table caption in plain text format:\n{context}\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\n# LLM\nmodel = ChatOpenAI(temperature = 0, model = \"gpt-3.5-turbo\")\n\n# Simple RAG pipeline\nchain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\nprint(chain.invoke(\"when layer type is Self-Attention, what is the Complexity per Layer?\"))  # Query about table 1\n\nprint(chain.invoke(\"Which parser performs worst for BLEU EN-DE\"))  # Query about table 2\n\nprint(chain.invoke(\"Which parser performs best for WSJ 23 F1\"))  # Query about table 4\n```\n\n# 결론\n\n이 글에서는 RAG 프로세스 중 표 처리를 위한 주요 기술과 기존 솔루션을 논의하고 구현과 함께 해결책을 제안합니다.\n\n이 문서에서는 표를 파싱하는 데 nougat을 사용합니다. 그러나 더 빠르고 효과적인 파싱 도구가 있다면 nougat을 대체 고려할 것입니다. 우리의 도구에 대한 태도는 먼저 올바른 아이디어를 가지고, 그런 다음 도구를 찾아 실현하는 것에 있으며, 특정 도구에 의존하는 대신입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 모든 테이블 콘텐츠를 LLM에 입력합니다. 그러나 실제 시나리오에서는 표가 LLM 콘텍스트 길이를 초과하는 경우를 고려해야 합니다. 이 문제를 효과적인 청킹 방법을 사용하여 해결할 수 있습니다.\n\nRAG 기술에 관심이 있다면, 다른 기사들도 확인해보세요.\n\n그리고 최신 AI 관련 콘텐츠는 제 뉴스레터에서 찾을 수 있습니다.\n\n마지막으로, 이 기사에 오류나 누락된 내용이 있다면, 또는 궁금한 점이 있으면 댓글 섹션에서 언급해 주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 친근한 어조로 번역한 내용 🚀\n\nIn Plain English 커뮤니티에 참여해 주셔서 감사합니다! 그 전에:\n\n- 저희 작가를 박수로 응원하고 팔로우해 주세요️👏️\n- 저희를 팔로우하세요: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼도 방문해 보세요: Stackademic | CoFeed | Venture | Cubed\n- 더 많은 콘텐츠를 만나실 수 있습니다: PlainEnglish.io\n","ogImage":{"url":"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png"},"coverImage":"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png","tag":["Tech"],"readingTime":26},{"title":"RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구","description":"","date":"2024-05-23 18:11","slug":"2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential","content":"\n![RAG Technology](/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png)\n\n대형 언어 모델(LLM)은 자연어 처리(NLP)를 혁신적으로 변화시켰습니다. 기계가 이전에는 인간만 할 수 있었던 작업을 수행할 수 있게 했습니다. 그러나 대규모 학습 데이터셋에 대한 의존 및 새로운 도메인에 적응하는 어려움을 포함한 제한 사항이 존재합니다. 검색 증강 생성(RAG) 기술은 더 다재다능하고 효율적인 NLP 프레임워크를 위해 정보 검색과 LLM 강점을 결합한 해결책으로 등장했습니다.\n\n소개\n\n풍부한 텍스트 데이터로 학습된 LLM의 등장은 NLP를 변혁했습니다. 이러한 모델은 인간과 유사한 품질의 텍스트를 생성하고 언어를 번역하며 창의적인 콘텐츠를 작성하고 질문에 정보적으로 답할 수 있습니다. 그러나 놀라운 능력을 가지고 있지만, LLM은 제한 사항을 직면하고 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터 의존성: 최신 정보를 유지하고 특정 도메인에 적응하는 것은 대규모 훈련 데이터 세트에 의존하기 때문에 어려울 수 있습니다.\n- 계산 비용: LLM(대형 언어 모델)을 훈련하고 배포하는 것은 계산적으로 비용이 많이 들 수 있어서, 리소스가 제한된 연구자와 실무자들의 접근성이 제한될 수 있습니다.\n\n**검색-증가 생성 (RAG)이 나타나다**\n\n이러한 제한 사항을 해결하기 위해, 연구자들은 RAG를 개발했습니다. RAG는 LLM의 강점을 정보 검색과 결합하여 보다 다재다능하고 효율적인 NLP 프레임워크를 만드는 새로운 접근 방법입니다. RAG는 정보 검색의 힘을 활용하여 LLM이 외부 지식원에 액세스하여 다음을 강화할 수 있습니다:\n\n- 실시간 정보에 접근하고 처리하여 최신 응답을 제공합니다.\n- 사용자 맥락과 선호도에 기반한 맞춤형 추천 및 출력 생성합니다.\n- 지식 기반이나 문서 저장소를 간단히 변경함으로써 새로운 도메인에 적응합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRAG 아키텍처\n\nRAG는 두 가지 주요 구성 요소로 구성되어 있습니다:\n\n- 검색 모듈:\n  - 지식 베이스 또는 문서 저장소에서 관련 정보를 식별합니다. 이는 텍스트 문서, 데이터베이스 또는 웹 아카이브와 같은 방대한 컬렉션일 수 있습니다.\n  - BM25, TF-IDF 또는 언어 모델 (예: Sentence-BERT)과 같은 검색 알고리즘을 사용하여 사용자 쿼리를 기반으로 지식 베이스를 검색합니다.\n  - 쿼리와 관련이 있는 문서를 순위별로 정렬합니다.\n- 생성 모듈:\n  - 검색된 문서를 생성 프로세스에 대한 맥락으로 활용합니다. 이러한 맥락은 벡터 표현이거나 핵심 구를 또는 문장 세트일 수 있습니다.\n  - 검색된 문서에서 유도된 맥락을 사용자 쿼리와 함께 고려하여 응답을 생성하는 데 LLM 모델 (예: GPT-3, BERT)을 활용합니다.\n  - 도메인별 데이터셋에 대해 LLM을 세밀하게 조정하면 응답의 관련성을 더욱 향상시킬 수 있습니다.\n\nRAG 워크플로우\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRAG 워크플로우는 세 단계 프로세스를 따릅니다:\n\n- 검색: 사용자의 쿼리는 벡터 표현으로 변환되어 지식 베이스에서 관련 정보를 검색하는 데 사용됩니다.\n- 컨텍스트 생성: 검색된 문서는 쿼리와 관련된 주요 정보를 캡처하는 생성 프로세스를 위한 컨텍스트를 생성하는 데 사용됩니다.\n- 생성: LLM 모델은 사용자의 쿼리와 구성된 컨텍스트를 기반으로 응답을 생성합니다.\n\nRAG의 장점\n\nRAG는 전통적인 LLM 접근 방식보다 여러 가지 장점을 제공합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 실시간 정보 접근: 외부 정보 소스에 실시간으로 접근하고 처리하여 최신 응답을 보장합니다.\n- 맞춤형 추천 및 결과물: 사용자 컨텍스트와 선호도에 기반한 맞춤형 추천과 결과물을 생성합니다.\n- 비용 효율성: 새로운 작업이나 도메인에 대한 지속적인 LLM 재교육이 필요하지 않아 전통적인 LLM 방법보다 비용 효율적입니다.\n- 도메인 적응: 지식베이스나 문서 저장소를 간단히 변경하여 새로운 도메인에 쉽게 적응합니다.\n\nRAG의 응용\n\nRAG는 다양한 분야에서 다양한 잠재적인 응용 프로그램을 제공합니다:\n\n- 법률 연구 및 문서 분석: 효율적인 법률 문서 검색 및 분석을 통해 관련 정보를 식별합니다.\n- 맞춤형 학습: 교육과 자료를 개인 학생의 필요에 맞게 조정하여 맞춤형 학습 경험을 제공합니다.\n- 보고서 생성과 분석: 다양한 소스에서 자동 보고서 생성 및 데이터 분석을 자동화합니다.\n- 고객 서비스: 고객의 상황을 이해하고 관련 정보 및 지원을 제공하여 맞춤형 고객 서비스를 제공합니다.\n- 리스크 관리와 사기 분석: 다양한 소스에서 대량의 데이터를 분석하여 잠재적인 위험과 사기를 식별합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRAG 대 Model Fine-tuning\n\nRAG와 Model Fine-tuning 중 어떤 것을 선택할지는 여러 요소에 따라 다릅니다:\n\n- 외부 데이터 필요성: LLM에서 사용 가능한 외부 데이터에 중요한 경우, RAG가 선호되는 옵션이 될 수 있습니다.\n- 모델 성능: 작업에 대해 LLM의 성능에 만족했다면, Model Fine-tuning이 더 효율적인 접근 방법일 수 있습니다.\n- 지속적인 개선: LLM 성능의 지속적인 개선이 필요한 경우, Fine-tuning과 RAG의 결합이 최적일 수 있습니다.\n\n기술적 고려 사항\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n최적 RAG 성능을 위한 몇 가지 기술적 고려 사항이 있습니다:\n\n- 지식 베이스 또는 문서 저장소:\n  - 데이터 선택 및 정제: 명명된 엔티티 인식 (NER) 및 주제 모델링과 같은 기술을 활용하여 지식 베이스/저장소 내에서 관련 정보를 식별하고 분류합니다.\n  - 정기적인 업데이트 및 유지관리: 데이터 원본을 정기적으로 업데이트하고 유지하여 정보의 정확성과 시기적 성을 보장합니다.\n  - 사용자 피드백 메커니즘: 사용자 피드백 메커니즘을 통합하여 데이터 내의 잠재적인 편향이나 부정확성을 식별하고 해결합니다.\n- 검색 알고리즘:\n  - 알고리즘 선택: BM25, TF-IDF 또는 언어 모델(Sentence-BERT 등)과 같은 다양한 검색 알고리즘을 탐색하여 작업 및 데이터 특성에 최적화된 알고리즘을 찾습니다. 선택할 때 쿼리 복잡도, 문서 관련성 및 검색 속도와 같은 요소를 고려합니다.\n  - 알고리즘 튜닝: 선택한 검색 알고리즘을 가중 체계나 관련성 임계값과 같은 매개변수를 조정하여 작업에 최적화된 성능을 달성합니다.\n- 생성 모델:\n  - LLM 세밀 조정: 적합한 LLM 아키텍처(생성형 vs. 식별형)를 선택하는 것 외에도 도메인이나 작업에 맞게 조정된 데이터셋에서 LLM을 세밀 조정합니다. 이를 통해 모델이 검색된 문맥에 관련된 응답을 생성하는 능력이 향상될 수 있습니다.\n  - 프롬프트 엔지니어링: 검색된 정보와 사용자 쿼리에 기반하여 정보를 제공하고 일관성 있는 응답을 생성하는 데 LLM을 안내하는 효과적인 프롬프트를 만듭니다.\n- RAG 시스템 평가:\n  - 자동 메트릭: BLEU 점수, ROUGE 점수 또는 Meteor와 같은 자동 메트릭을 활용하여 생성된 응답의 유창성과 문법적 정확성을 평가합니다.\n  - 인간 평가: 자동 메트릭뿐만 아니라 인간 평가 연구를 실시하여 생성된 응답의 정보 전달, 관련성 및 전반적인 품질을 사용자 관점에서 평가합니다.\n\nRAG의 미래 방향\n\nRAG 기술이 계속 발전함에 따라, 더 많은 진전을 위한 유망한 연구 분야가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Explainable AI (XAI): RAG 시스템이 결과물에 도달하는 방법을 설명하는 기술을 개발하여 사용자 신뢰를 촉진하고 잠재적인 오류를 해결하는 데 도움을 줍니다.\n- RAG 시스템을 위한 평생 학습: RAG 모델이 시간이 지남에 따라 지속적으로 학습하고 적응하는 방법을 탐구하여 새로운 정보를 통합하고 장거리 재훈련 없이 성능을 향상시킵니다.\n- 다른 NLP 작업과의 통합: RAG와 다른 NLP 작업(질문 응답, 요약 및 감정 분석 등)을 통합하기 위한 기술을 개발합니다.\n- 응용 분야 확대: RAG의 새로운 응용 분야(의료, 교육 및 금융 등)를 탐색합니다.\n\n결론\n\nRAG 기술은 LLM의 성능을 크게 향상시키고 주요 제약 사항 중 일부를 해결할 수 있는 잠재력을 가지고 있습니다. LLM의 강점을 정보 검색과 결합함으로써 RAG는 더 다양하고 효율적인 NLP 프레임워크를 가능하게 합니다. RAG 기술이 성숙해짐에 따라 NLP 분야에서 더 많은 혁신적인 응용 프로그램과 발전을 기대할 수 있습니다.\n\n이 글은 2021년 이후 InterProbe의 소프트웨어 개발팀 리더로 활동 중인 Ertan Kabakci가 작성했습니다. 그의 주요 관심 분야는 그래프, GraphQL, 분산 시스템, 빅 데이터 분석 및 인공 지능입니다.\n","ogImage":{"url":"/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png"},"coverImage":"/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png","tag":["Tech"],"readingTime":7},{"title":"LLM이 정말 새로운 것을 배울 수 있을까요","description":"","date":"2024-05-23 18:09","slug":"2024-05-23-CanaLLMReallyLearnNewThings","content":"\n## 인공지능|LLMS|미세 튜닝|\n\n\u003cimg src=\"/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_0.png\" /\u003e\n\n대형 언어 모델 (LLMs)은 방대한 텍스트 말뭉치에서 훈련되어 많은 사실적 지식을 습득합니다. 이러한 지식은 그들의 매개변수에 내재되어 필요할 때 사용될 수 있습니다. 이러한 모델의 지식은 훈련의 끝에 \"결정\"됩니다. 사전 훈련이 끝나면 모델은 사실상 학습을 멈춥니다.\n\n그 후, 모델은 정렬되거나 지시 튜닝을 받아 이 지식을 최상으로 활용하고 사용자의 질문에 더 자연스럽게 응답하는 방법을 배울 수 있습니다. 때로는 모델의 지식이 충분하지 않을 수 있습니다. 왜냐하면 이 질문은 일반적이며 관심 영역에 맞게 맞춰져 있지 않을 수 있기 때문입니다. 모델은 RAG를 통해 외부 메모리에 접근할 수 있지만, 새로운 도메인에 모델을 적응시키는 데 미세 튜닝을 통해 장점을 얻을 수 있다고 여겨집니다. 일반적으로 이 미세 튜닝은 인간 주석자나 다른 LLM들이 작성한 입력을 사용하여 실시됩니다. 이 단계에서 모델은 추가적인 사실적 지식을 만나 매개변수에 통합합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n실제로, 기계적인 수준에서는 이러한 상호작용이 어떻게 일어나는지 정말로 알지 못합니다. 게다가 일부에 따르면, 이 새로운 지식에 노출되는 것이 모델이 환각을 경험하게 할 수도 있습니다. 이는 모델이 이전에 보유한 지식에 근거하지 않는 사실을 생성하도록 훈련되어 있기 때문입니다(또는 모델의 이전 지식과 충돌할 수도 있습니다). 게다가 앞서 본 것처럼 모델은 훈련 코퍼스에서 덜 빈번한 엔티티(예: 이전 코퍼스에서 덜 빈번한 엔티티)에 대해 어려움을 겪을 수 있습니다.\n\n따라서, 최근에 발표된 연구는 모델이 새로운 지식을 통해 미세 조정되는 과정에서 무슨 일이 일어나는지 분석하는 데 관심을 가졌습니다.\n\n저자들은 모델이 미세 조정을 거치고 새로운 지식을 습득한 후 반응이 어떻게 변하는지에 대해 자세히 조사했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저, 그들은 세밀한 조정 후 예시를 위한 지식 수준으로 분류하려고 노력했습니다. 새로운 예시는 모델의 지식과 일치하지 않을 수 있는 지식을 내재적으로 갖고 있습니다. 예시는 알려진 것일 수도 있고 알려지지 않은 것일 수도 있습니다. 알려진 경우에도 고도로 알려진 지식, 어느 정도 알려진 지식 또는 약하게 알려진 지식을 보유하고 있을 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_2.png)\n\n저자들은 이 데이터셋으로 모델 (PaLM 2-M) 을 세밀하게 조정하였습니다. 세밀한 조정을 위한 각 예시는 인과적 지식 (주어, 관계, 목적어)으로 구성되어 있습니다. 이를 통해 모델이 이 지식을 특정 질문 (예: \"파리는 어디에 위치하나요?\")과 실제 정답 (예: \"프랑스\")으로 질의할 수 있습니다. 즉, 그들은 모델에 새로운 지식을 제공하고 이러한 삼중체를 질문 (질문-응답 쌍)으로 재구성하여 지식을 검증합니다. 이들은 이 모든 예시를 위에서 논의한 범주로 나누고 그 결과를 평가했습니다.\n\n저자들은 모델을 세밀하게 조정하고 환청을 테스트하기로 결정했습니다. 그들에게 알려지지 않은 사실의 높은 비율은 성능 저하를 초래한다고 판단하였으며 (이는 긴 세밀한 조정 시간으로 보상받을 수 없습니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_3.png\" /\u003e\n\n사실, 여러 번 에포크로 훈련하는 것은 해로운 효과를 초래할 수 있습니다. 이전 연구에 따르면 더 많은 에포크는 성능 저하로 이어지는 것으로 나타났습니다 (과적합으로 이어질 수 있음). 저자들은 이 효과가 알려지지 않은 사실 비율이 높을수록 증가한다고 합니다.\n\n저자들은 알려지지 않은 사실이 에포크 수가 적을 때 거의 중립적인 효과를 보이지만, 에포크 수가 많을 때 성능을 해친다고 합니다. 따라서, 알려지지 않은 예는 해로울 수 있지만, 그들의 부정적인 영향은 대부분 나중의 훈련 단계에서 실현됩니다. 저자들은 그런 예제들을 핏하는 과정을 연구합니다. 도표는 미세 조정 기간에 대한 데이터 집합 예제의 알려진 부분과 알려지지 않은 부분의 훈련 정확도를 나타냅니다. 모델이 알려지지 않은 예를 나중 단계에서 배운다는 것을 알 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_4.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저자들은 정확도와 알려진 및 알려지지 않은 예제 간의 관골을 양적으로 측정할 수 있는지, 그리고 선형인지 의문을 제기합니다. 결과는 알려지지 않은 예제가 성능에 해를 끼치고, 알려진 예제는 그것을 향상시키는 강력한 선형 관련이 있다는 것을 보여줄 것입니다 (이 선형 회귀의 연관 계수는 거의 같습니다).\n\n![이미지](/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_5.png)\n\n게다가, 이 미세 조정은 특정 케이스에서의 성능을 넘어서 모델 지식에 광범위한 영향을 미칩니다. 저자들은 Out-of-Distribution (OOD) 테스트 세트를 사용하여 알려지지 않은 예제가 OOD 성능에 해를 끼친다는 것을 보여줍니다. 저자들에 따르면 환각의 발생과도 관련이 있습니다.\n\n재미있는 결과는 최상의 결과가 매우 잘 알려진 예제와 함께 얻어지는 것이 아니라 아마도 알려진 예제와 함께 얻어진다는 것입니다. 다시 말해, 이러한 예제들은 모델이 이전 지식을 더 잘 활용할 수 있게 합니다 (너무 잘 알려진 사실은 모델에 유용한 영향을 미치지 않습니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 6](/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_6.png)\n\n그에 반해, 알려지지 않은 사실과 약하게 알려진 사실은 모델의 성능에 해를 끼치며, 이 하락은 환각 증가에서 유도된 것입니다.\n\n따라서 저자들에 따르면, 이 알려지지 않은 지식은 성능에 해를 끼칠 수 있으며 (따라서 미세 조정은 거의 무용한 것으로 만듭니다). 이 알려지지 않은 지식을 \"I don't know\"로 표시하여 이 피해를 줄일 수 있다고 초기 결과에 따르면 추정됩니다.\n\n![Image 7](/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 글을 요약하면, 모델은 파인튜닝 중에 알 수 없는 지식을 받을 경우 손상될 수 있습니다. 게다가, 이 성능 하락은 환각증 증가와 관련이 있습니다. 반면, 알 수 있는 예시는 긍정적인 효과가 있을 수 있습니다. 따라서, 이는 모델이 새로운 지식을 통합하는 데 어려움을 겪는 것을 보여줍니다. 다시 말해, 모델이 배운 것과 새로운 지식을 어떻게 사용하는지 사이에 충돌이 있을 수 있습니다. 이는 조정 및 지시 파인튜닝과 관련이 있을 수 있습니다 (불행히도 이에 대한 연구는 이 연구에서 다루지 않았습니다).\n\n한편, 특정 도메인 지식을 가진 모델을 사용하고 싶다면, 이 연구는 RAG를 사용하는 것이 좋다는 것을 제안합니다. 반면, \"알 수 없음\"으로 표시된 결과는 파인튜닝의 제약을 극복하기 위한 다른 전략이 있다는 것을 의미합니다.\n\n알 수 있는 사실이 실제로 유익하다는 사실은 안심스럽습니다. 오늘날의 모델은 방대한 양의 텍스트로 훈련됩니다. 이는 많은 지식을 많이 보았다는 것을 의미합니다. 따라서 파인튜닝 데이터셋에 있는 사실 중 많은 것은 이미 모델의 알고 있는 요소일 수 있으며 모델에 해를 끼치지 않을 수 있습니다 (아마도 일부만 알 수 없을 것입니다).\n\n어쨌든, 이 연구는 흥미로우며 파인튜닝과 새로운 지식과 기존 지식 간의 충돌이 어떻게 해소되는지에 대해 여전히 명확하지 않은 요소가 있다는 것을 보여줍니다. 이는 항상 파인튜닝 전후 모델의 결과를 테스트하는 이유 중 하나입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 어떻게 생각하세요? 포인트 파인튜닝 후 환각증이 증가했나요?\n\n# 흥미로운 정보였다면:\n\n다른 기사를 찾아볼 수 있고, LinkedIn에서 연락하거나 저에게 연락할 수 있습니다. 주간 업데이트되는 머신 러닝 및 인공 지능 뉴스를 포함하는 이 저장소를 확인해보세요. 협업과 프로젝트에 관심이 있고 LinkedIn에서 저에게 연락할 수 있습니다. 또한 새 이야기를 게시할 때 알림을 받기 위해 무료로 구독할 수도 있습니다.\n\n여기 저의 GitHub 저장소 링크가 있습니다. 여기서 머신 러닝, 인공 지능 및 기타 관련 자료 및 코드를 모아두고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또는 최근에 작성한 제 논문 중 하나에 관심이 있을 수 있습니다:\n\n# 참고 자료\n\n본 문서를 작성하는 데 참고한 주요 참고 자료 목록을 아래에 제시합니다. 각 논문의 저자 이름만 인용하였습니다.\n\n- 황, 2023, 대규모 언어 모델에서 환각에 대한 조사: 원칙, 분류, 도전과 공개 질문, 링크\n- 레오가오, 2021, 행동 복제의 미적정성, 링크\n- 게크만, 2024, 새로운 지식 기반에서 언어 모델 미세 조정이 환각을 유발하는가?, 링크\n","ogImage":{"url":"/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_0.png"},"coverImage":"/assets/img/2024-05-23-CanaLLMReallyLearnNewThings_0.png","tag":["Tech"],"readingTime":7},{"title":"개발자들도 예전에는 사람이었어요","description":"","date":"2024-05-23 18:07","slug":"2024-05-23-DevelopersUsedToBePeople","content":"\n## AI | 소프트웨어 개발\n\n미래에는 손주들에게 젊을 때 IBM 개발자였다고 설명할 수 있다고 상상해 볼 수 있습니다.\n\n한때 \"컴퓨터\"란 용어가 사람들, 계산을 하는 사람들을 가리켰던 것처럼, \"개발자\"의 역할도 곧 아마 AI, 대형언어모델(Large Language Models 또는 LLMs), 양자 컴퓨팅의 조합으로 완전히 기계에 의해 수행될 것이라고 믿습니다.\n\nAI의 위험성에 대한 많은 글이 쓰여져 왔습니다. 컴퓨팅에서 AI의 새로운 패러다임으로의 전환에 대한 것입니다. 저는 이러한 변화가 기술과 발견의 자연스러운 진행이며 심오한 성장의 기회이며 두려워할 것이 아니라고 믿습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 새로운 발전이든 불확실성과 두려움이 따른다는 것을 기억해주셔야 해요. 하지만 이는 동시에 자기 성찰, 성장, 진화의 기회이기도 합니다. 그래서, 한 숨을 깊게 들이마시고, 두려움을 살펴보고, 우리가 성장해야 할 부분을 찾아내며, 함께 큰일을 해내봐요.\n\n우리의 전환을 이해하기 위해서는 우리가 오늘의 개발자로 발전하기까지의 컴퓨팅 역할의 진화를 되돌아봐야 하고, 이러한 역할이 고급 기술의 도래와 함께 다시 어떻게 변화할지 알아봐야 해요.\n\n# 역사적 맥락과 전환\n\n## 기억하세요 — 컴퓨터는 직위였던 때\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n세기의 변곡점에서, 수학을 잘한다면 몇 가지 직업 옵션이 있었습니다. 수학을 정말 잘한다면, 인간 컴퓨터로 직업에 들어갈 수 있었죠. 이 직업에서는 수학적, 과학적 또는 공학적 목적으로 숫자와 복잡한 계산을 수동으로 처리했습니다.\n\n아마도 어딘가의 실험실에서 혼자 이를 하고 있을 리는 없었을 거에요; 아니죠, 여러분은 아마도 한 팀의 일원이 되었을 겁니다. 때로는 서로 다른 여러 인간 컴퓨터 팀의 일원이 되어 함께 계산을 하며 오차율을 줄이고 정확한 결과를 얻기 위해 노력했을 겁니다.\n\n재미있어 보일 수도 있겠죠? 어쩌면 그렇겠지만, 크게 그렇진 않다고 생각해요.\n\n더욱 그런 점은, 그 당시 여성들이 수학적 기술을 활용하는 몇 안 되는 기술적인 역할 중 하나였습니다. 만약 그 시기에 여성들이 과학 커뮤니티에서 동등하게 인정받았다면 얼마나 많은 업적이 있었을지 상상해 볼 수 있겠죠? 하지만 그건 다른 시간에 이야기할 이야기죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n컴퓨터는 스타일과 직업을 의미했습니다.\n\n## 컴퓨터 프로그래머를 만나보세요\n\n전기 기계식 컴퓨팅 기계가 등장했을 때, 이 새로운 기계를 제어하는 데 더 적합한 사람은 누구나 아니었을까요? 이전에 수동으로 이 작업을 맡은 사람들이 그 역할을 맡게 되었습니다.\n\n새로운 기술이 등장하면서 새로운 기술들이 필요해졌습니다. 기계에게 수행해야 할 작업을 나타내는 지침을 통해 기계와 소통할 방법이 필요했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n언어가 필요했습니다. 명령을 사용하여 기기의 여러 측면을 제어하는 기계 언어, 이러한 명령의 결과는 의도된 계산입니다.\n\n컴퓨팅 기계를 도구로 사용하는 사람들은 엔지니어나 과학자의 요구를 기계가 수행할 수 있는 작업으로 번역하여 이 기기의 모국어를 구사하는 법을 익혀야 했습니다.\n\n## 프로그래밍의 진화\n\n컴퓨팅 작업이 더 잘 이해되면 표준화가 가능해져 일반 컴퓨터 언어로 변환되어 컴퓨터를 제어해야 하는 원시 기계 언어로 먼저 변환해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시간이 흘러가면서 프로그래밍 아이디어와 개념이 성장하면서, 고수준 명령과 저수준 기계어 사이의 거리가 더 멀어지며, 컴퓨터 프로그래머들은 정보와 아이디어를 자유롭게 생성 및 교환하고 효율적이고 정확한 기계 코드로 그러한 아이디어를 번역할 수 있는 명령 컴파일러에 의존할 수 있게 되었습니다.\n\n컴파일러 프로그래머는 기계어에 대한 견고한 지식과 동시에 일반 프로그래밍 언어의 필요를 알고 있어야 했습니다. 컴퓨터 프로그래머는 자신이 선택한 언어를 사용하여 고수준 명령을 만들어, 그것이 컴파일러 프로그래머의 작업에 의해 (희망적으로!) 해석되어 그 후 목표 하드웨어에서 실행되는 것이었습니다.\n\n다양한 전문 언어, 컴파일러 및 하드웨어 플랫폼이 등장했습니다. AI 및 LLM이 개발되고 고수준 개발자에게 소개되면서, 고수준 상호작용과 저수준 명령 사이에 더 많은 거리가 생겼습니다.\n\n개발자는 곧 일상적인 구두로 시스템에게 명령해 지정된 입력을 받아들이고 원하는 출력을 생성하는 코드를 생성하도록 요청할 수 있었으며, 그러한 출력을 개발자가 완성 중인 다른 작업과 통합하거나 원하는 출력을 위해 하드웨어에서 직접 실행할 수 있었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 미래: 개발자 프로그래밍\n\n## 개발자 프로그래머가 되기\n\n프롬프트 엔지니어링은 개발자 프로그래밍의 선행 단계로 볼 수 있습니다. 프롬프트 엔지니어링에서 개발자는 일반적인 패턴과 프로세스에 대한 지식을 통해 LLM 시스템으로부터 필요한 텍스트, 코드 또는 데이터 응답을 유도할 수 있는 텍스트 프롬프트를 만듭니다. LLM을 이용해본 사람이라면 아실 것이지만, 때로는 정확한 결과를 얻기 위해 여러 차례의 프롬프트 반복이 필요할 수 있습니다.\n\nLLM을 사용하여 솔루션을 만들거나 코드를 작성하는 개발자는 필요한 결과를 얻을 때까지 많은 버전의 코드를 실행할 수 있으며, 원하는 결과를 얻으면 가까운 결과이거나 약간의 수정이 필요한 것으로 판단하거나, 완전히 쓸모없다고 판단하여 새로운 접근을 위해 버릴 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자 그럼, 코드를 개발하는 사람은 누구일까요?\n\n현재 이러한 노력들은 대부분 임시 방편 방식으로 이루어지고 있으며, 프로세스나 패턴, 입력이나 출력에 대한 일반적인 표준이 존재하지 않습니다. 때로는 한 명은 인간이고 다른 한 명은 기계인 두 명의 개발자가 있는 것 같습니다.\n\n간단한 단계로, 개발자 프로그래머의 영역으로 진입할 것입니다.\n\n우리가 원하는 것의 세부 사항과 원하는 방식을 나타내고, 하위 수준 시스템이 원하는 결과를 렌더링하는 데 필요한 제품을 생성하도록 하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n현재 프로그래머로서, 아마도 다음과 같은 기술을 가지고 계실 것입니다:\n\n- 언어\n- 패턴\n- 아키텍처\n- 테스팅\n- 보안\n\n## 목록에 '듣기' 추가하기\n\n이와 동등하게 중요한, 또는 최고 중요한 것은, 제가 생각하기에 프로그래머는 인간(그리고 기계)들과 대화를 듣고 문제 해결에 완전히 집중할 수 있는 기술, 실시간 피드백을 이해하고, 자신이 창출한 결과를 이해해야 한다고 말씀 드릴게요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저희가 저수준 작업을 AI 시스템으로 완료하는 패러다임으로 이동하면서, 기계 개발자로서 우리의 기술도 가르침, 듣기, 이해 듣기 방향으로 전환되어야 합니다.\n\n## 개발자 프로그래머로서 대표 셰프 역할\n\n우리는 아이들의 이야기 작가와 비슷한 저수준 창조 패턴에서 벗어나게 될 것입니다. 거기서는 이야기가 섬세하게 제작되고 정확한 간단한 단어 선택에 귀중한 주의를 기울여 청중에 의해 직접 읽히는 것처럼 이야기가 만들어집니다. 대신 우리는 대표 셰프와 유사한 패턴으로 이동할 것입니다. 즉, 원하는 맛, 질감, 일관성을 가진 요리를 지식을 통해 창조할 수 있게 될 것입니다. 그리고 표준적인 요리 패턴, 과정 및 재료 상호작용의 지식 전달을 통해 창조할 수 있을 것입니다.\n\n대표 셰프는 요리 과정에 대한 심층적인 지식(조리 기술, 칼 사용 기술, 확보 등)을 가지고 있습니다. 또한 음식의 재료 상호작용(예를 들어 산성 또는 온도의 영향)과 잘 알려진 조합 및 관계(예를 들어, Florentine이라는 용어는 아마 시금치와 모르네 소스가 포함되어 있을 것이라는 것, 그리고 모르네는 홀란데이즈와 베어네즈와의 관계를 가지고 있다는 것)을 이해하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n푸짐한 음식 설명을 통해 주방장이 소품 셰프에게 원하는 요리를 만들도록 충분한 정보를 전달할 수 있어요. 이는 맛과 질감에 기대되는 품질을 얻을 수 있도록 도와 줄거에요.\n\n주방장은 당신 개발자에요. 소품 셰프의 경험, 배경, 그리고 개성에 따라 결과물의 변화가 있을 수 있지만, 요리의 성판은 1.) 주방장의 심도 있고 지식 있는 안내 능력, 그리고 듣기를 이해하는 능력과 2.) 소품 셰프의 훈련, 경험, 그리고 배경에 달려 있어요.\n\n물론, 소품 셰프는 듣기능력이 있어야 하지만, 듣기를 이해하는 주방장의 뛰어난 능력이 의사소통을 보장할 것이에요.\n\n같은 관점은 API 통합, 단위 테스트, 보안 표준 등의 기본 프로세스에 대한 깊은 지식, UI 구현, 오류 처리, 성능 및 하드웨어 제약 조건과 같은 재료 상호 작용, 그리고 잘 알려진 산업 표준 조합 (하드웨어, 시스템 아키텍처, 보안 아키텍처, 컨테이너)을 통해 기계 개발자에게 필요한 소프트웨어 결과를 올바르게 전달할 수 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 경우에 소프트웨어 결과물은 예상된 형태와 기능을 갖춘 소프트웨어입니다. 그리고 주방장이 음식을 나가기 전에 모두 확인하는 것처럼 고객에게 궁극적인 책임을 지는 것처럼, 개발자도 소프트웨어를 스튜디오를 떠나기 전에 모두 확인하고 코드 품질에 대한 궁극적인 책임을 지게 될 것입니다.\n\n## 그래서, 훌륭한 개발자 프로그래머란?\n\n마음에 드는 음악가에 대한 Zoltan Kodály의 견해에 찬사를 보내며, 나는 훌륭한 개발자 프로그래머에 대한 유사한 요구 사항을 제안합니다.\n\n## 변화가 오고 있습니다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리가 사용할 공학, 언어 및 청취 기술은 이미 갖추고 있습니다. 변해야 할 가장 중요한 것은 우리의 시각과 태도입니다.\n\n이것은 우리가 공학을 생각하고 문제를 해결하는 방식에 있습니다.\n\n우리는 새로운 도구, 발명품 및 폭발적인 혁신을 어떻게 활용할 수 있을까요? 그리고 우리가 일부인 기술의 진화와 큰 그림을 어떻게 생각해야 할까요?\n\n우리는 충분히 크게 생각하고 있나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n사람들은 손수 계산을 하는 사람들 중 일부가 첫 번째 전기기계 계산기를 위한 소프트웨어 프로그램을 작성했습니다. 소프트웨어 개발자들이 기계 개발자를 사용하여 소프트웨어를 만드는 데 처음으로 신임을 받을 것입니다.\n\n그들이 가져야 할 기술은 무엇일까요?\n\n어떠한 변화라도, 자기반성은 우리가 더 잘 이해할 수 있도록 돕고, 두려움이 아닌 지식으로 앞지르며, 결국 모두를 더 나은 사람으로 만들어줍니다.\n\n변화를 환영하세요. 변화가 다가오고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제 이야기를 읽어주셔서 감사합니다! 마음에 들었다면, 이것도 한번 읽어보세요:\n","ogImage":{"url":"/assets/img/2024-05-23-DevelopersUsedToBePeople_0.png"},"coverImage":"/assets/img/2024-05-23-DevelopersUsedToBePeople_0.png","tag":["Tech"],"readingTime":9},{"title":"알알지 탐정 웹사이트 데이터를 활용한 검색 증대형 생성","description":"","date":"2024-05-23 18:03","slug":"2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata","content":"\n이 기사는 하버드의 AC215 가을 2023 과정의 최종 프로젝트의 일환으로 제작되었습니다.\n\n- 프로젝트 Github 저장소\n- 비디오\n\n저자: Ian Kelk, Alyssa Lutservitz, Nitesh Kumar, Mandy Wong\n\n![](/assets/img/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n대형 언어 모델 (LLM)인 GPT-3.5는 일반적으로 알려진 주제에 대한 질문에는 능숙하게 대답할 수 있음이 증명되었습니다. 그 주제들은 모델이 풍부한 양의 훈련 데이터를 받은 것으로 예상됩니다. 그러나, 그들이 훈련을 받지 않은 데이터가 포함된 주제에 대한 질문을 받을 때, 그들은 종종 그 지식을 갖고 있지 않다고 말하거나, 더 나쁜 경우에는 그럴듯한 답변을 허구로 만들어냅니다.\n\nLLM을 사용하여 회사의 제품 및 서비스에 대해 연구하기는 보통 불가능합니다. 제품 및 서비스를 직접 비교하기 위해서는 모델이 훈련을 받았던 것보다 최근의 데이터가 필요합니다. 우리가 해결하고자 하는 문제는 회사에 대한 최신 정보와 그들의 웹사이트 정보와 일치하는 정보를 얻는 방법을 찾는 것입니다.\n\n또한, 이 과정에 대한 이전에 다뤄지지 않았을 것으로 예상되는 이정표를 충족시키기 위해, GPT-3.5가 답변이 금융적인 성격일 수 있다고 할 때 BERT 모델을 세밀하게 조정하여 금융 감성 분석을 수행합니다.\n\n# 제안된 해결책\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 한계를 해결하는 두 가지 주요 방법이 있습니다: 세밀조정(fine-tuning)과 검색 증강 생성(RAG).\n\n세밀조정은 모델을 학습률을 크게 줄여서 사용자의 데이터를 계속하여 훈련시키는 과정입니다. 새롭게 얻은 지식은 모델 가중치에 캡슐화됩니다. 그러나 세밀조정은 모델의 복사본 및 해당 비용을 사용하고 호스팅해야 한다는 점, 그리고 \"치명적인 망각\"이라는 위험(이전에 배운 정보를 잊어버리는 현상)도 있습니다.\n\n반면 RAG는 주로 포함된 텍스트의 임베딩의 벡터 저장소를 활용한 지식 소스를 사용합니다. 쿼리의 예측된 임베딩을 벡터 저장소의 임베딩과 비교함으로써, 우리는 LLM을 위한 적절한 프롬프트를 형성할 수 있어서 그것이 그의 문맥 안에 맞고 질문에 답할 정보를 포함합니다.\n\n# 우리의 해결책에는 세 가지 주요 구성 요소가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 웹 사이트에서 스크랩 된 데이터를 사용하는 챗봇은 'ssitemap.xml' 파일에서 가져온 데이터를 사용합니다. 이 파일은 검색 엔진에 사이트의 모든 스크랩 가능한 링크를 안내하는 것이 목적입니다. 이는 검색 엔진보다 더 구체적이고 통찰력 있는 방법으로 사용됩니다. LLM(언어 모델)는 질문에 답변할 때 이 맥락만 사용해야 하며, 자체 훈련 데이터를 삽입하거나 답변을 가공해서는 안 됩니다. 모델이 분명히 알고 있을 것으로 예상되는 \"김 카다시안은 누구인가요?\"와 같은 질문으로 이를 간단히 테스트할 수 있으며, 모델이 \"제공된 맥락 안에 답변되지 않았다\"고 회신하도록 보장해야 합니다.\n- API를 통한 비동기 호출을 통해 애플리케이션에서 웹 사이트를 실시간으로 스크랩하는 기능.\n- LLM에서 중요한 결과물에 대한 금융 감성 분석. GPT-3.5의 프롬프트의 일부로, 응답이 금융적인 경우를 묻습니다. 이 경우, 세밀하게 미세 조정된 BERT 모델이 호출되어 응답을 분류하고, 확률 플롯과 적절히 귀여운, 저작권 위반이 아닌 버트 퍼펫이 표시됩니다.\n\n# RAG 구성 요소\n\nRAG를 이해하기 위해 단순화 된 비유를 사용해보겠습니다. 한 사람이 받을 수있는 두 가지 유형의 시험 문제가 있습니다. 첫 번째는 사실에 대한 간단한 요청입니다:\n\n- 프랑스의 수도는 무엇인가요?\n- 에베레스트 산을 처음으로 등반한 사람은 누구인가요?\n- 캐나다가 영국으로부터 독립을 얻은 연도는 언제인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 질문에 답변하는 데 특별한 기술이 필요하지 않습니다. 적절한 참고 자료가 있는 사람은 올바른 답변을 찾아볼 수 있습니다.\n\n![image](/assets/img/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata_1.png)\n\n다른 유형의 질문은 학습된 기술이 필요한 질문입니다. 해당 주제에 대한 교과서를 숨기고 있더라도 상관없는 질문이며 연습하고 공부하지 않은 경우 만족스럽게 대답할 수 없습니다. 예를 들어:\n\n- 독일어로 시를 쓰세요.\n- 첫 백만 개의 소수를 계산하는 컴퓨터 프로그램을 작성하세요.\n- 베토벤 스타일의 심포니를 작곡하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수학 교과서들로 둘러싸인 채로 있어도, 그 중에 반복해서 보던 책 안에 페르마의 마지막 정리가 있지 않다면 페르마의 마지막 정리를 증명할 수는 없을 거에요!\n\n![이미지](/assets/img/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata_2.png)\n\n대형 언어 모델의 세계에서 RAG는 사기가 쉬운 첫 번째 유형의 문제를 해결하는 데 사용됩니다. 미세 조정은 모델이 실제로 학습해야만 문제를 해결할 수 있는 두 번째 유형의 문제를 해결하는 데 사용됩니다. RAG는 더 쉬워요—모델을 다시 교육시킬 필요가 없고, 모델의 내부 작업을 다룰 필요가 없으며, 모델이 \"사기\"를 할 데이터를 쉽게 조절할 수 있어요. 흥미로운 점은, 이 방법이 또한 모델이 \"환각하는\" 양을 크게 줄여준다는 거예요—때에 따라 충분한 훈련 데이터를 바탕으로 픽션 같지만 타당한 답변을 창조하는 대형 언어 모델의 일반적인 문제 중 하나에요. RAG의 유일한 어려운 부분은 모델에 주어질 적절한 데이터를 찾는 것이에요; 모델은 얼마나 많이 자극을 받을 수 있는지에 제한이 있고, 500페이지짜리 역사 교과서는 너무 길어요.\n\nRAG가 작동하는 기본 개념은 아래와 같아요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터 정리: 위의 만화 속 작은 사람처럼 교과서로 둘러싸여 있다고 상상해보세요. 우리는 이 책들을 각각 작은 조각으로 나누어—하나는 양자 물리학에 대한 것이고, 또 다른 하나는 우주 탐사에 관한 것일 수 있습니다. 이러한 각 조각 또는 문서는 벡터를 만들기 위해 처리됩니다. 이는 마치 도서관에서 그 정보 덩어리를 바로 가리키는 주소와 같은 것입니다.\n- 벡터 생성: 이러한 조각들은 임베딩 모델을 통해 전달됩니다. 이는 정보의 의미를 포착하는 수백 개 또는 수천 개의 숫자로 이루어진 벡터 표현을 만드는 모델의 한 유형입니다. 이 모델은 각 조각에 고유한 벡터를 할당합니다—컴퓨터가 이해할 수 있는 고유한 인덱스를 만든 것과 같습니다.\n- 질의: LLM에게 대답할 수 없는 질문을 하고 싶을 때, 먼젓거로 \"AI 규제 분야의 최신 개발은 무엇인가요?\"와 같은 프롬프트를 제공하여 시작합니다.\n- 검색: 이 프롬프트는 임베딩 모델을 통해 통과되어 벡터로 변환됩니다. 이는 자신의 의미를 기반으로 고유한 검색어를 얻는 것이며, 그 키워드의 정확한 일치뿐만 아니라 의미에 기반한 검색어를 얻는 것입니다. 시스템은 이 검색어를 사용하여 질문과 관련된 가장 관련성 있는 조각을 찾기 위해 벡터 데이터베이스를 검색합니다.\n- 컨텍스트 추가: 가장 관련성 있는 조각은 컨텍스트로 제공됩니다. 이는 질문하기 전에 참조 자료를 제공하는 것과 비슷한데, 우리는 LLM에게 조언을 제공합니다: \"이 정보를 사용하여 다음 질문에 대답하십시오.\" LLM에게 제공되는 프롬프트는이 배경 정보로 확장되지만 사용자가 이를 볼 수는 없습니다. 이 복잡성은 뒷면에서 처리됩니다.\n- 답변 생성: 마침내, 이 새로운 정보를 갖춘 LLM은 방금 검색한 데이터를 품은 응답을 생성하여 질문에 대답합니다. 이러한 방식으로 답변하는 것은 마치 이미 그 답을 알고 있던 것처럼 느껴집니다.\n\n우리는 이 목표를 달성하기 위해 \"Weaviate\"라는 벡터 저장소 위에 애플리케이션을 구축했습니다. 우리는 파이썬에서 웹 스크래퍼를 구축하여 주어진 웹 사이트의 sitemap.xml을 크롤하도록하였습니다. 이는 검색 엔진이 사이트를 크롤할 수 있도록 사용되는 페이지 목록입니다. 인터넷 웹사이트의 끝없는 다양성 때문에 약간의 도전이 되었다는 것이 밝혀졌습니다.\n\n# 스크래퍼 구성 요소\n\n우리의 웹 스크래퍼는 현대 웹 아키텍처의 많은 도전을 처리하도록 구축되었으며, 전통적인 스크래핑 방법으로 종종 놓치는 데이터를 캡처하고, 스크래핑 활동을 실시간으로 웹 애플리케이션으로 스트리밍합니다. 이 엔드포인트는 웹 데이터를 가져 오고, 여러 단계의 저장 및 처리로 전환하고, 결과적으로 벡터 저장소에 즉각 색인화하기 위해 설계된 솔루션의 중요한 데이터 수집 단계를 나타냅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스크레이퍼는 먼저 PythonBeautifulSoup 라이브러리를 사용하여 HTML 및 CSS 내용을 걸러냅니다. 그러나 일부 현대 웹사이트는 동적 콘텐츠 생성을 위해 JavaScript에 의존하므로, 순전히 HTTP 요청에 의존하는 표준 스크레이핑 방법에 장애물을 제공합니다. 스크레이핑 시스템은 Selenium WebDriver를 활용하여 이 문제를 해결합니다. 이 도구는 '헤드리스'(화면 없이 실행되는) 브라우저인 Google Chrome을 통해 웹 페이지와의 실제 사용자 상호작용을 모방하는 기능을 제공합니다. 이를 통해 동적 콘텐츠 로딩을 완전히 지원합니다. 스크레이퍼가 직접 HTTP 요청을 통해 데이터를 추출하는 초기 노력이 무효화되었거나 일정 임계값 이하의 데이터를 가져오는 경우 Selenium이 사용됩니다. 이 기술은 스크레이퍼가 정적 페이지 로드를 통해 사용할 수 없는 콘텐츠에 성공적으로 액세스할 수 있도록 보장합니다.\n\n스크레이퍼는 불필요한 요소인 이미지와 같은 것들을 우회하여 오버헤드를 줄이고 빠른 처리를 가능케 합니다. 데이터를 수집한 후에는, 제어를 돌려 받아 데이터를 필터링하고 HTML에서 텍스트를 추출하는 BeautifulSoup로 돌아갑니다.\n\n데이터 추출 후에, 데이터는 직렬화되어 Google Cloud Storage에 CSV 파일로 저장되어 데이터의 백업으로 기능합니다. 추출된 데이터는 이후 조감도 라이브러리인 LlamaIndex를 통해 Weaviate에 쪼개져서 삽입되며, 여기서 벡터 저장소 인덱스에 추가됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 오케스트레이션\n\n데이터가 수집된 후에 어떤 일이 발생하는지 좀 더 자세히 살펴봅시다. 이 데이터를 벡터 스토어에 삽입하기 위해 수행해야 할 작업이 있습니다. 이러한 단계들은 위에서 요약 수준으로 언급되었지만, 구체적으로는 다음과 같은 단계들이 필요합니다.\n\n- 각 수집된 웹사이트를 가져와서 청크(chunk)로 분리합니다. 이 청크의 길이는 검색 프로세스가 얼마나 잘 작동하는지에 큰 영향을 미칩니다.\n- 각 청크에 대해 OpenAI의 텍스트 임베딩-ada-002 모델을 사용하여 임베딩 벡터를 생성합니다. Weaviate와 LlamaIndex는 이 모델을 기본적으로 통합하고 있습니다.\n- 이 임베딩 벡터와 텍스트 청크를 Weaviate 벡터 스토어에 삽입합니다.\n\n모델에 프롬프트할 때 검색 단계:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 텍스트 임베딩-ada-002을 통해 프롬프트를 가져와 임베딩을 얻습니다.\n- 그 임베딩을 사용하여 프롬프트에 대답해야 할 청크를 찾은 후, 그 청크를 쿼리에 선행하고 GPT-3.5로 보냅니다.\n\n문서의 청킹은 어느 정도 예술미가 있습니다. GPT-3.5는 최대 문맥 길이가 4,096토큰 또는 약 3,000단어입니다. 이는 모델이 처리할 수 있는 총 양을 나타냅니다 - 3,000단어 길이의 문맥을 갖는 프롬프트를 만들면, 모델은 응답을 생성할 충분한 공간이 없을 것입니다. 현실적으로, GPT-3.5에 약 2,000단어 이상으로 프롬프트를 지정해서는 안됩니다. 이는 데이터에 따라 청크 크기를 위한 트레이드 오프가 있다는 것을 의미합니다.\n\n더 작은 chunk_size 값으로 설정할수록, 반환된 텍스트는 보다 상세한 텍스트 청크를 생성하지만, 텍스트에서 멀리 떨어져 있는 정보를 놓칠 위험이 있습니다. 반면, 더 큰 chunk_size 값은 상단 청크에 필요한 모든 정보를 포함할 가능성이 높아 더 나은 응답 품질을 보장하지만, 정보가 텍스트 전체에 분산되어 있는 경우 중요한 섹션을 놓칠 수 있습니다.\n\n이 트레이드 오프가 어떻게 작동하는지 설명하기 위해 최근 테슬라 사이버트럭 출시 이벤트를 사용한 몇 가지 예를 살펴보겠습니다. 트럭의 일부 모델은 2024년에 출시될 예정입니다. 그러나 RWD만 탑재된 최저가 모델은 2025년까지 출시되지 않을 것입니다. RAG에 사용된 텍스트의 형식과 청킹에 따라 모델의 응답이 이 사실을 만나지 못할 수도 있습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 이미지에서 파란색은 일치 항목이 발견되어 청크가 반환된 위치를 나타내며, 회색 상자는 청크가 검색되지 않았음을 나타냅니다. 또한 빨간색 텍스트는 관련 텍스트가 존재하지만 검색되지 않았음을 나타냅니다. 짧은 청크가 성공적으로 작동하는 예시를 살펴보겠습니다:\n\n위의 이미지에서 왼쪽에 있는 텍스트는 RWD가 2025년에 출시될 것이라는 내용이 단락으로 구분되어 있지만 질의와 일치하는 관련 텍스트를 가지고 있습니다. 두 개의 짧은 청크를 검색하는 방법이 더 잘 작동하는 이유는 모든 정보를 포착하기 때문입니다. 오른쪽에서은 검색기가 단일 청크만 검색하기 때문에 추가 정보를 반환할 공간이 없어 모델이 잘못된 정보를 제공합니다.\n\n그러나 항상 그런 것은 아닙니다. 때로는 질문에 대한 진정한 답변을 포함하는 텍스트와 강력한 일치하지 않을 때 더 긴 청크가 더 잘 작동합니다. 더 긴 청크가 성공하는 예시를 살펴보겠습니다:\n\n몇 번의 실험 끝에, 우리는 1,000 토큰 길이의 청크를 사용하고 GPT-3.5를 촉발시키기 위해 두 개의 청크를 검색하기로 결정했습니다. GPT-3.5는 4,096 컨텍스트 길이를 처리할 수 있기 때문에 적절한 응답을 위한 충분한 공간을 남겨둘 것으로 예상됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프로젝트를 처음 시작할 때는 chunking, indexing, 그리고 데이터 검색을 직접 수행하여 매우 잘 작동되었습니다. Weaviate에서 쿼리 언어로 사용하는 GraphQL을 배우는 데는 학습 곡선이 있었습니다.\n\n![이미지](/assets/img/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata_4.png)\n\nLlamaIndex와 같은 라이브러리를 사용하는 장점은 이러한 조율을 추상화하여 다른 벡터 스토어로 교체할 수 있는 기회를 제공한다는 것입니다 (Weaviate는 Milvus, Qdrant, Pinecone과 같은 많은 경쟁사가 있으며, 계속해서 새로운 경쟁사들이 등장하고 있습니다). LlamaIndex를 사용하면 향후 보다 복잡한 RAG 구현(예: 트리 구조 데이터 및 재귀적 프롬프팅)을 실험할 수도 있습니다. 그러나 이러한 새로운 라이브러리 사용은 적절한 문서의 부재와 같은 도전을 안겨주었습니다. 그들의 도움 자료 대부분은 예제로 이루어져 있었는데, 이 예제들이 우리의 사용 사례에 부합하지 않으면 Discord에서 개발자들에게 질문하거나 소스 코드를 직접 읽는 것 외에는 다른 선택지가 없었습니다.\n\n# BERT 구성요소\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델 호스팅 요구 사항을 충족하기 위해, BERT 모델을 세밀 조정하고 훈련한 후 Google Vertex에서 파이프라인을 통해 호스팅했습니다. 이 모델을 응용 프로그램에 추가하면 실제로 GPT-3.5로 활용하여 답변과 함께 플래그를 반환하고 해당 답변이 금융적인 것으로 판단되는지 여부를 알 수 있습니다. 그럴 때마다, 우리는 적절히 유머러스하면서도 저작권을 침해하지 않는 버트 퍼펫과 모델이 반환한 확률 플롯을 표시할 수 있습니다.\n\nBERT 모델의 세밀 조정 과정은 데이터뿐만 아니라 기술적인 구성에 관한 것이었습니다. 이 모델에게 텍스트 내에서 금융적 감정을 구별하는 기술을 가르치는 것이 목표였는데, 이는 복잡한 금융 뉴스에서 통찰력을 필요로 하는 사람들에게 유용한 기술입니다. 이러한 기사에서의 감정은 상냥하고 즉각적으로 드러나지 않을 수 있기 때문에, 특별히 세밀하게 조정된 모델을 활용하여 비전문가에게 밑바탕에 깔린 감정의 분명한 지표를 제공하는 것이 중요합니다.\n\n우리가 BERT 모델을 훈련시킬 때는 금융 문구은행 데이터셋을 사용했습니다. 이 데이터셋은 금융에 능통한 사람들이 감정으로 레이블이 지정된 문장들로 구성되어 있습니다. 그러나 이러한 데이터셋에서 흥미로운 문제가 발생합니다: 어노테이터 간의 합의 수준의 변동에 따른 차이점은 모델의 학습과 그에 따른 예측에 암묵적으로 영향을 줄 수 있습니다.\n\n이러한 데이터셋을 사용하여 BERT 모델을 세밀하게 조정했을 때 (어노테이터 간 100%, 75%, 66%, 50% 합의를 대표하는 데이터셋 포함), 어노테이터들이 동의하는 정도가 더 높을수록 훈련된 모델이 더 좋아 보였습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수상한 거 아니에요? 모델이 더 높은 합의를 보일수록 실제로 더 나은 결과를 내놓는다는 것이 아니라, 높은 합의 수준은 금융 보고서가 간단히 분류하기 쉬운 것을 의미한다는 것입니다.\n\n높은 합의가 모델을 명확한 감정만 인식하도록 편향시킬 수 있고, 때로는 복잡한 금융 텍스트에서 현실인 미묘한 감정을 놓쳐버릴 수도 있기 때문에 상상하기 어렵지 않습니다.\n\n이 문제를 해결하기 위해, 우리는 데이터의 편향을 해소하기로 결심했습니다. 우리는 모든 감정의 명료성 수준이 공정하게 대표되도록 훈련 및 테스트 분할을 구성하는 것을 목표로 삼았습니다. 이를 위해 데이터 분할 과정을 주의 깊게 프로그래밍하고, 무작위 섞기, 계층 샘플링, 그리고 균형 잡힌 분할을 위한 검증 및 테스트 세트 생성과 같은 추가 단계를 거쳤습니다. 이렇게 함으로써, 우리는 모델이 단순히 분명한 감정 데이터에서만 잘 작동하는 위험을 완화하고, 대신 금융 텍스트의 현실적인 혼합을 처리할 수 있도록 보장했습니다.\n\n편향 해소 후, 보다 균형있는 접근 방식을 사용하여 모델을 평가하자, 흥미로운 추세가 나타났습니다. 75% 주석 작성자 합의로 교육된 모델이 가장 높은 F1 점수를 보였는데, 초기 결과에서 벗어나는 것으로 나타났습니다. 우리가 의심했던 대로, 최상의 데이터셋은 실제로 완전한 주석자 합의와 논란을 유발하는 좀 더 복잡한 금융 보고서 사이에서의 타협이었던 것 같습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 모든 것을 결합하기\n\n애플리케이션 아키텍처는 FastAPI 서비스와 Nginx를 통해 연결된 프론트엔드 컨테이너로 구성됩니다. FastAPI 서비스는 특정 작업에 대한 스트리밍 응답을 처리하는 여러 엔드포인트를 호스팅하며, 스트리밍 응답을 사용하여 쿼리를 관리하고 웹 사이트 주소를 나열하고 특정 웹 사이트의 타임스탬프를 검색하고 주어진 쿼리에 대한 URL 및 금융 플래그를 가져오며, Vertex AI의 Prediction API를 활용하여 감성 분석에 사용하고 효과적인 사이트맵 스크래핑을 위해 입력을 처리합니다.\n\n프론트엔드는 HTML과 JavaScript로 구축되어 동기식 및 비동기식 함수를 사용하는 단일 페이지 애플리케이션으로 만들어졌습니다. CSS로 스타일이 지정되어 있으며, 로딩 인디케이터 및 슬라이딩 패널용 여러 가지 효과를 사용하고, Google의 Material Design 라이브러리를 사용하여 현대적인 텍스트 입력란과 버튼을 만듭니다.\n\n우리는 OpenAI의 DALL-E 3를 사용하여 30개의 서로 다른 저작권 침해가 없는 Bert 이미지를 생성했습니다. 이 중에는 긍정적, 부정적, 중립적 감정 각각 10개씩이 포함되어 있습니다. 프론트엔드는 발견된 감정에 따라 해당 감정 이미지 중 하나를 무작위로 선택하여 표시하고 클래스와 함께 표시합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n진행 및 각 단계 완료 상황의 실시간 업데이트가 사이트맵 스크래핑 프로세스 중에 클라이언트에게 제공됩니다. Nginx는 게이트웨이로 작동하여 적절한 엔드포인트로 요청을 효율적으로 라우팅하여 일관된 반응성 있는 사용자 경험을 보장합니다.\n\n# 배포\n\nRAG Detective 앱은 Ansible을 사용하여 자동화 및 재현성에 따라 배포됩니다. 배포 프로세스에는 필요한 Google Cloud Platform (GCP) API 활성화, GCP 서비스 계정 설정, 필요한 소프트웨어가 포함된 Docker 컨테이너 생성이 포함됩니다. Ansible playbook은 Docker 컨테이너를 빌드하고 GCR에 푸시하여 Google Cloud Registry (GCR)에 컨테이너를 만들고 푸시하며, GCP에서 컴퓨트 인스턴스 (VM) 서버를 생성하고 해당 구성으로 인스턴스를 구성하고 인스턴스 내에서 Docker 컨테이너를 설정하는 데 사용됩니다. 이 프로세스는 컴퓨트 인스턴스에 웹 서버로 Nginx를 구성함으로써 Docker 컨테이너에 대한 올바른 설정 및 액세스를 보장합니다.\n\n스케일링에는 Kubernetes를 사용합니다. Ansible playbook은 Kubernetes 클러스터를 생성하고 배포합니다. 이 단계에는 GCR에 Docker 컨테이너 빌드 및 푸시, Kubernetes 클러스터 생성이 포함됩니다. 증가된 수요 발생 시 스케일링 프로세스에는 GKE가 클러스터에 더 많은 노드를 자동으로 추가하는 노드 스케일링 및 쿠버네티스 수평 팟 자동스케일러가 관여하며 자원 활용률에 따라 팟 복제 수를 수정합니다. 로드 밸런싱은 Kubernetes Services 및 GKE가 Google Cloud Load Balancer와 통합되어 들어오는 트래픽을 고르게 분배하여 달성됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n원하는 것 중 하나는 Weaviate 인스턴스가 다른 컨테이너와 함께 확장되지 않으며, 데이터베이스 확장 구현은 이 코스의 범위를 벗어나고 별도의 과학이 필요하다는 점입니다. Weaviate를 확장하기 위해 수평 확장이 주요 방법으로, 클러스터에 더 많은 노드를 추가하여 작업 부하를 균등하게 분산하는 것이 중요합니다. 이에 더하여 부하 분산을 위해 로드 밸런싱이 있으며, 이는 들어오는 요청을 이용 가능한 노드에 골고루 분배하는 데 도움이 됩니다. 데이터 샤딩도 가능하며, 데이터가 여러 노드에 파티션으로 분할되어 쿼리를 효율적으로 처리할 수 있습니다. 쿠버네티스를 사용하여 Weaviate 인스턴스의 확장 및 관리를 자동화할 수도 있어 시스템이 성장하여 증가하는 요구 사항을 충족하는 동시에 견고하고 효율적으로 유지될 수 있도록 할 수 있습니다.\n\n# 배운 점\n\n시스템 및 운영에 대해 몇 가지 중요한 교훈을 얻었습니다:\n\n- 인증은 큰 어려움 요소가 될 수 있습니다. 처음으로 무언가를 배포할 때마다 Google Cloud, Google Vertex 또는 OpenAI가 제대로 인증되지 않았거나 잘못된 권한을 가지고 있는 문제가 발생했습니다. 인증 및 시크릿 관리에 대한 숙달은 AI 제품의 운영에 숙련될 수 있는 주요 구성 요소입니다. (dotenv와 같은 라이브러리 사용이 유용하다는 것을 발견했습니다.)\n- GPT 모델은 선구자적입니다. LLM 답변에 대해 자신의 BERT 모델을 호출할지 결정하기 위해, 답변이 금융 관련인지 나타내는 플래그를 반환하도록 요청했습니다. 초기에는 플래그를 생성한 다음 답변을 생성하도록 했지만, GPT 모델은 텍스트를 생성하는 과정 중이어도 텍스트를 생성하기 전에는 분류할 수 없다는 사실을 깨달았습니다. 모델의 스트리밍 응답 끝에 플래그를 이동하는 것이 다소 까다로웠지만 더 잘 작동합니다. 한 가지 알아둬야 할 점은 GPT-3.5가 GPT-4보다 추론에서 훨씬 떨어지며, GPT-4가 하지 않는 오류를 자주 범한다는 것입니다.\n- 새로운 라이브러리를 사용할 때는 자신의 책임 하에 사용해야 합니다. Weaviate만 사용하여 작동하는 프로토 타입이 있음에도 불구하고, 보다 고급 RAG 아키텍처를 사용하기 위해 LlamaIndex를 사용했습니다. 적절한 라이브러리 참조 부재로 문서는 예제 코드로 가득하지만, 소스 코드를 자세히 살펴보아야만 할 일이 여러 차례 발생했습니다. 이 프로젝트를 계속해서 복잡한 RAG 방법을 추가해 나갈 수 있으며, 이는 LlamaIndex의 사용을 정당화할 뿐만 아니라 쿼리에 더 나은 응답을 제공할 것입니다.\n- 새로운 라이브러리를 사용하려면 Discord 챗을 확인해야 합니다. 보통 라이브러리 저자들은 문서가 떨어지거나 제대로 되어 있지 않을 때 Discord에서 활동적이며, 고민할 때 직접 안내를 제공해 줄 수 있습니다.\n- 데이터셋은 평범하게 숨겨진 편향을 담고 있을 수 있습니다. 우리는 financial_phrasebank 데이터셋을 사용했는데, 앞서 말한 바와 같이, 보다 큰 주석자 합의는 더 좋은 모델로 이어진 이유가 숨겨져 있었습니다. 데이터를 통해 보이는 듯한 단순한 경로를 선택할 때 항상 주의해야 합니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 해당 프로젝트에 대한 이미지입니다.\n\n이 프로젝트는 매우 현대적인 문제에 대한 매우 현대적인 솔루션을 활용한 재미있는 프로젝트였습니다. 클라우드에서 모델을 훈련 및 배포하거나 자체 RAG 아키텍처를 만드는 경험은 수업 시간을 보내는 훌륭한 방법이었습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata_0.png"},"coverImage":"/assets/img/2024-05-23-RAGDetectiveRetrievalAugmentedGenerationwithwebsitedata_0.png","tag":["Tech"],"readingTime":17}],"page":"52","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"52"},"buildId":"bb_yO9GbCvdfc_n71SfUf","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>