<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/63" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/63" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_buildManifest.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기" href="/post/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개" href="/post/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" href="/post/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="자기 주의적 문장 임베딩을 사용한 추천 시스템" href="/post/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="자기 주의적 문장 임베딩을 사용한 추천 시스템" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="자기 주의적 문장 임베딩을 사용한 추천 시스템" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">자기 주의적 문장 임베딩을 사용한 추천 시스템</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="포디즘의 새로운 모습" href="/post/2024-05-23-ThenewfaceofFordism"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="포디즘의 새로운 모습" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ThenewfaceofFordism_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="포디즘의 새로운 모습" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">포디즘의 새로운 모습</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스" href="/post/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기" href="/post/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="새로운 냉전 - 인공지능" href="/post/2024-05-23-TheNewColdWarArtificialIntelligence"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="새로운 냉전 - 인공지능" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="새로운 냉전 - 인공지능" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">새로운 냉전 - 인공지능</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="사람형 로봇 5종 소개" href="/post/2024-05-23-Top5HumanoidRobots"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="사람형 로봇 5종 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Top5HumanoidRobots_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="사람형 로봇 5종 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">사람형 로봇 5종 소개</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요" href="/post/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/61">61</a><a class="link" href="/posts/62">62</a><a class="link posts_-active__YVJEi" href="/posts/63">63</a><a class="link" href="/posts/64">64</a><a class="link" href="/posts/65">65</a><a class="link" href="/posts/66">66</a><a class="link" href="/posts/67">67</a><a class="link" href="/posts/68">68</a><a class="link" href="/posts/69">69</a><a class="link" href="/posts/70">70</a><a class="link" href="/posts/71">71</a><a class="link" href="/posts/72">72</a><a class="link" href="/posts/73">73</a><a class="link" href="/posts/74">74</a><a class="link" href="/posts/75">75</a><a class="link" href="/posts/76">76</a><a class="link" href="/posts/77">77</a><a class="link" href="/posts/78">78</a><a class="link" href="/posts/79">79</a><a class="link" href="/posts/80">80</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기","description":"","date":"2024-05-23 17:20","slug":"2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering","content":"\n금일의 데이터 중심 세계에서는 방대한 양의 정보를 활용하여 정확하게 질문에 답하는 능력이 중요합니다. 대형 언어 모델(LLM)을 활용한 질문 응답(QA) 시스템은 이러한 측면에서 큰 가능성을 보여주고 있습니다.\n\n하지만, 이러한 시스템의 정확도와 신뢰성을 보장하는 것은 여전히 중요한 과제입니다.\n\ndata.world의 최근 연구에 따르면, 온톨로지와 지식 그래프를 활용하면 LLM 기반 QA 시스템의 성능을 크게 향상시킬 수 있음을 입증했습니다.\n\n본 글에서는 온톨로지 기반의 쿼리 유효성 검증과 LLM을 활용한 쿼리 복구를 결합한 혁신적인 접근 방식을 탐구하여, 질문 응답에서 전례없는 수준의 정확성을 달성하는 방법을 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 배경\n\n질문 응답 시스템은 구조화된 또는 구조화되지 않은 데이터 소스에서 정보를 추출하여 사용자 쿼리에 정확하고 관련성 높은 응답을 제공하는 것을 목표로 합니다. 기존의 QA 시스템은 종종 자연어 쿼리의 복잡성과 모호성에 노출되어 최적의 결과를 얻기 어려웠습니다. 지식 그래프와 온톨로지의 등장은 도메인 지식을 표현하고 추론하는 강력한 프레임워크를 제공하여 보다 정교한 QA 방법을 가능케 하였습니다 [2].\n\n대규모 언어 모델인 GPT-4와 같은 모델은 자연어 처리 분야를 혁신적으로 변화시켰으며, 인간과 유사한 텍스트를 이해하고 생성하는 놀라운 능력을 보여주었습니다. 대형 언어 모델은 SQL 또는 SPARQL 쿼리를 사용하여 구조화된 데이터베이스에서 질문에 답변하는 등 다양한 QA 작업에 적용되었습니다 [3]. 그러나 LLM이 생성한 쿼리의 정확도는 기반이 되는 데이터 스키마와 의미에 대한 명확한 지식 부족으로 제한될 수 있습니다.\n\n# Ontology-based Query Check (OBQC)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png\" /\u003e\n\nLLM 기반 QA 시스템의 한계를 해결하기 위해 연구자들은 Ontology 기반 쿼리 체크 (OBQC) 접근 방식을 제안했습니다 [1]. OBQC는 온톨로지에 인코딩된 의미 정보를 활용하여 LLM이 생성한 SPARQL 쿼리의 정확성을 검증합니다. 이 과정은 몇 가지 주요 단계로 이루어집니다:\n\n1. 생성된 SPARQL 쿼리에서 기본 그래프 패턴 (BGP)을 추출하여 쿼리의 그래프 패턴을 나타냅니다 [1].\n2. :쿼리( BGP가 RDF로 바뀐 것을 나타냄)와 :온톨로지(온톨로지 자체를 나타냄)의 두 개의 명명된 그래프를 캡슐화한 결합 그래프를 구성합니다 [1].\n3. SPARQL 쿼리로 구현된 온톨로지 일관성 규칙을 적용하여 :쿼리와 :온톨로지 그래프 사이의 위반을 확인합니다 [1].\n4. 생성된 쿼리에서 구체적인 오류를 식별하고 각 규칙 위반에 대한 사람이 읽을 수 있는 설명을 생성합니다 [1].\n\nLLM이 생성한 쿼리를 온톨로지의 의미와 비교함으로써 OBQC는 도메인이나 범주 클래스 불일치, 호환되지 않는 속성 사용, 정의되지 않은 속성 등 다양한 유형의 오류를 감지할 수 있습니다. 이 유효성 검사 프로세스는 생성된 쿼리가 기저지식 그래프와 일관된지 확인하여 QA 시스템의 전체 정확성을 향상시키는 데 도움을 줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# LLM Repair\n\nOBQC는 생성된 쿼리의 오류를 식별하는 데 능숙하지만, 이러한 오류를 수정하는 메커니즘을 제공하지는 않습니다. 여기서 LLM Repair 구성 요소가 필요합니다. LLM Repair는 OBQC에 의해 제공된 오류 설명을 기반으로 쿼리를 반복적으로 다듬고 수정하는 능력을 활용합니다 [1].\n\n수리 과정은 오류 설명과 부정확한 SPARQL 쿼리를 포함하는 프롬프트를 작성하여 시작됩니다. 이 프롬프트는 그런 다음 LLM에 공급되며, LLM은 의도한 의미와 구조를 보존하면서 식별된 문제를 해결하기 위해 쿼리를 다시 작성하려고 시도합니다 [1]. 수정된 쿼리는 그런 다음 OBQC로 반환되어 확인을 받으며, 유효한 쿼리를 얻거나 최대 반복 횟수에 도달할 때까지 반복적인 피드백 루프를 형성합니다 [1].\n\nLLM Repair는 LLM이 자연어 설명을 이해하고 일관된 응답을 생성하는 능력에 활용합니다. 질문이나 온톨로지에 명시적인 액세스가 필요하지 않고 오류 설명을 활용함으로써, 쿼리를 수정하는 데 효과적으로 학습할 수 있습니다 [1].\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수리 과정이 일정 횟수의 반복 이후 유효한 쿼리를 생성하지 못하면, LLM 수리는 \"알 수 없음\" 또는 \"불확실\" 응답을 반환하여 신뢰할만한 답변을 생성할 수 없음을 표시합니다 [1]. 이 실패 안전 기구는 수리 시도가 실패할 경우 잘못된 또는 오해를 일으킬 수 있는 결과를 시스템이 제공하는 것을 방지합니다.\n\n# 실험 설정 및 결과\n\nOBQC 및 LLM 수리 접근 방식의 효과를 평가하기 위해 연구자들은 Chat with the Data 벤치마크를 사용한 실험을 진행했습니다 [1]. 이 벤치마크에는 기업용 SQL 스키마, 질문-답변 쌍, 그리고 OWL 온톨로지 매핑이 포함되어 있습니다. 테스트된 QA 시스템은 SPARQL 제로샷 프롬프트로 GPT-4였으며, 쿼리는 가상화된 지식 그래프에서 실행되었습니다 [1].\n\n실험 결과는 정확도와 오류 감소에서 상당한 향상을 보여주었습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- OBQC 및 LLM Repair을 사용하여 전체 실행 정확도가 42.88%에서 72.55%로 향상되었습니다 [1].\n- 시스템에서 잘못된 것으로 식별된 알 수 없는 쿼리가 전체 오류율인 19.44% 중 8%를 차지했습니다 [1].\n- 고복잡도 스키마에 관한 질문의 정확도 향상이 특히 유의미했습니다 [1].\n\n추가 분석 결과, OBQC의 도메인 관련 규칙이 수리의 70%를 담당하는 가장 일반적인 규칙임이 밝혀졌습니다 [1]. 이는 온톨로지에서 도메인 지식을 정확하게 모델링하는 것이 QA 성능을 향상시키는 데 중요한 역할을 한다는 것을 시사합니다.\n\n# 현실 세계의 영향과 응용\n\nOBQC 및 LLM Repair의 유망한 결과들은 이미 현실 세계 응용분야에서 찾아보실 수 있습니다. 기업용 데이터 카탈로그 및 발견 솔루션의 선도 업체인 data.world은 이러한 구성 요소를 AI Context Engine에 통합하였습니다 [1]. AI Context Engine은 구조화된 데이터와의 신뢰할 수 있는 대화를 지원하여 고객이 질문을 하고 정확하고 컨텍스트 인식형 답변을 받을 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n몇몇 data.world 고객은 AI Context Engine을 도입하여, 다양한 사용 사례에서 향상된 QA 능력을 활용하고 있습니다 [1]. 이는 실제 환경에서 온톨로지 기반 검증과 LLM 기반 복구를 결합한 가치와 영향을 보여줍니다.\n\n## 미래 방향성과 도전 과제\n\n현재 방법이 높은 성공률을 보여주고 있지만, 미래 연구와 개선을 위한 여러 분야가 아직 남아 있습니다. 하나의 주요 도전 과제는 OBQC를 보다 복잡한 온톨로지 구조에 대응할 수 있도록 확장하는 것입니다. 이는 OWL 어키오름이 포함된 온톨로지 조합(연합, 교집합 또는 다른 논리 연산자)에 대한 처리를 의미합니다 [1]. 이 도전에 대응함으로써 시스템이 쿼리를 풍부하고 표현력 있는 온톨로지에 대해 유효성을 검증하는 능력을 더욱 강화할 수 있을 것입니다.\n\n또 다른 중요한 방향은 해당 접근 방식을 다른 도메인과 데이터 집합으로 일반화하는 것입니다. 현재 실험은 기업용 SQL 스키마와 질문-답변 쌍을 다루는 Chat with the Data 벤치마크에 주로 초점을 맞추었습니다 [1]. 시스템의 성능을 다양한 도메인과 데이터 소스 범위에서 평가함으로써 보다 넓은 적용 가능성과 견고성을 평가할 수 있을 것입니다.\n\n확장성과 계산 비용에 대한 조사도 필요합니다. 온톨로지와 데이터 집합의 크기와 복잡성이 증가함에 따라, OBQC와 LLM Repair 구성 요소의 효율성은 점점 더 중요해집니다 [1]. 최적화된 알고리즘 및 병렬 처리 기술을 개발함으로써 대규모 응용 프로그램에 대한 시스템의 실용성과 반응성을 보장하는 데 도움이 될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n체계 기반 쿼리 유효성 검사와 LLM(언어 모델) 기반 쿼리 수리의 결합은 질문 응답 분야에서 중요한 발전을 나타냅니다. 오전톨로지에 인코딩된 의미 지식과 LLM의 생성적 능력을 활용하여, 이 방법은 전례없는 수준의 정확도와 신뢰성을 실현합니다.\n\n실험 결과와 현실 세계에서의 채택은 이 기법이 신뢰할 수 있고 맥락에 맞는 구조화된 데이터와의 대화를 가능케 함에 대한 엄청난 잠재력을 입증합니다. 조직이 통찰을 도출하고 데이터 기반 결정을 내리는 데 QA 시스템에 점점 더 의존함에 따라, 정확성의 중요성은 지나치게 강조될 수 없습니다.\n\n그러나 이 방법의 전체 잠재력을 실현하기 위해서는 계속된 연구 및 개발 노력이 필요합니다. 더 복잡한 온톨로지 구조를 처리하고, 다양한 도메인에 적용할 수 있도록 일반화하고, 확장성 문제를 해결하는 것이 미래 작업의 주요 분야입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nOBQC와 LLM Repair의 성공은 의미론, 온톨로지, 그리고 지식 그래프가 정확하고 신뢰할 수 있는 QA 시스템을 구축하는 데 중요한 역할을 한다는 점을 강조합니다. 이러한 기본기술에 투자하고 계속해서 가능한 한 경계를 넓힘으로써, 우리는 자연어 인터페이스의 진정한 잠재력을 발휘하고 사용자들이 필요로 하는 정보에 원활하게 액세스할 수 있도록 돕는 것이 가능합니다.\n\n# 참고문헌\n\n[1] Dean Allemang과 Juan F. Sequeda. 2024. “Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue!” 기술 보고서.\n[2] Aidan Hogan 등. 2021. “Knowledge Graphs.” 데이터, 의미론, 그리고 지식에 관한 합성 강의. Morgan \u0026 Claypool Publishers.\n[3] Juan Sequeda, Dean Allemang, 그리고 Brad Jesson. 2023. “A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model’s Accuracy for Question Answering on Enterprise SQL Databases.” arXiv 사전인쇄 arXiv:2406.01688.\n","ogImage":{"url":"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png"},"coverImage":"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png","tag":["Tech"],"readingTime":8},{"title":"깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개","description":"","date":"2024-05-23 17:17","slug":"2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming","content":"\n## .to(\"cuda\") 가 무엇을 하는지 이해하고 싶은 분들을 위해\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png)\n\n요즘에는 딥 러닝을 이야기할 때 성능을 향상시키기 위해 GPU를 활용한다고 연관 지어지는 것이 매우 일반적입니다.\n\nGPU(그래픽 처리 장치)는 원래 이미지, 2D 및 3D 그래픽의 렌더링을 가속화하기 위해 설계되었습니다. 그러나 다수의 병렬 작업을 수행할 수 있는 능력으로 인해 그 유용성은 그 이상으로 확장되어 딥 러닝과 같은 응용 프로그램에까지 이어집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n깊은 학습 모델에 GPU를 사용한 것은 2000년대 중후반 경에 시작되었으며 2012년에 AlexNet이 등장하면서 매우 인기를 끌었습니다. AlexNet은 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 디자인한 합성곱 신경망으로, 2012년 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 우승했습니다. 이 승리는 깊은 신경망을 통한 이미지 분류의 효과성 및 대형 모델 학습에 GPU 사용을 보여주어 중요한 이정표가 되었습니다.\n\n이후 이 기술적 발전을 통해 깊은 학습 모델에 GPU를 사용하는 것이 점점 인기를 얻으며, PyTorch나 TensorFlow와 같은 프레임워크 개발에 이바지했습니다.\n\n요즘에는 PyTorch에서 데이터를 GPU로 전송하려면 .to(\"cuda\")만 작성하면 학습이 가속화되는 것으로 예상됩니다. 하지만 실제로 어떻게 GPU 컴퓨팅 성능을 활용하는지 알아볼까요?\n\n신경망, CNNs, RNNs 및 트랜스포머와 같은 깊은 학습 아키텍처는 기본적으로 행렬 덧셈, 행렬 곱셈 및 행렬에 함수를 적용하는 수학 연산을 사용하여 구축됩니다. 따라서 이러한 연산을 최적화하는 방법을 찾으면 깊은 학습 모델의 성능을 개선할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러니까, 간단하게 시작해 봅시다. 두 벡터 C = A + B를 추가하고 싶다고 상상해 보세요.\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_1.png)\n\n이를 C에서 간단히 구현하는 방법은 다음과 같습니다:\n\n```js\nvoid AddTwoVectors(float A[], float B[], float C[]) {\n    for (int i = 0; i \u003c N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서 볼 수 있듯이 컴퓨터는 벡터를 반복해서 각 쌍의 요소를 순차적으로 더해야 합니다. 그러나 이러한 작업은 서로 독립적입니다. i번째 쌍의 요소를 더하는 것은 다른 쌍에 의존하지 않습니다. 그래서 만약 이러한 작업들을 병렬로 실행할 수 있다면 어떨까요?\n\n간단한 접근 방식은 CPU 멀티스레딩을 사용하여 모든 계산을 병렬로 실행하는 것일 것입니다. 그러나 딥러닝 모델에서는 수백만 개 요소를 가진 대규모 벡터를 다루게 됩니다. 일반적인 CPU는 동시에 약 10여 개의 스레드만 처리할 수 있습니다. 이때 GPU가 필요한 것입니다! 현대의 GPU는 수백만 개의 스레드를 동시에 실행할 수 있어 이러한 대규모 벡터에 대한 수학적 연산의 성능을 향상시킵니다.\n\n# GPU 대 CPU 비교\n\nCPU 연산이 GPU보다 단일 작업에서 빠를 수 있지만 GPUs의 장점은 병렬화 능력에 있습니다. 이것의 이유는 그들이 서로 다른 목표로 설계되었기 때문입니다. CPU는 가능한 한 빠르게 연산 순서(스레드)를 실행하는 데 설계되었지만(동시에 약 10여 개의 스레드만 실행할 수 있음) GPU는 수백만 개의 연산을 병렬로 실행하는 데 설계되었습니다(개별 스레드의 속도를 희생하면서).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래의 비디오를 확인해보세요:\n\n예를 들어, CPU가 페라리와 같다고 상상해보세요. GPU는 버스입니다. 한 사람을 옮기는 작업이라면, 페라리(CPU)가 더 나은 선택일 것입니다. 그러나 여러 사람을 이동시키는 경우에는, 페라리(CPU)가 한 번에 더 빠르지만, 버스(GPU)는 한 번에 모두를 옮겨 더 빠르게 목적지에 도착하게 됩니다. CPU는 연속적인 작업을 처리하는 데 뛰어나지만 GPU는 병렬 작업에 적합하게 설계되어 있습니다.\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_2.png)\n\n더 높은 병렬 기능을 제공하기 위해 GPU 설계는 데이터 캐싱 및 흐름 제어 보다는 데이터 처리에 더 많은 트랜지스터를 할당합니다. 이는 CPU와는 달리, CPU가 단일 스레드 성능 및 복잡한 명령 실행을 최적화하기 위해 상당 부분의 트랜지스터를 할당하는데 사용하는 것과 대조적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 그림은 CPU와 GPU의 칩 자원 분포를 보여줍니다.\n\n![CPU vs GPU Resources](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_3.png)\n\nCPU는 강력한 코어와 더 복잡한 캐시 메모리 아키텍처(이를 위해 상당한 양의 트랜지스터를 할당)를 갖고 있습니다. 이 설계는 순차 작업의 신속한 처리를 가능하게 합니다. 반면, GPU는 고수준의 병렬성을 달성하기 위해 많은 코어를 갖는 것을 우선시합니다.\n\n이러한 기본 개념을 이해했으니, 실전에서 이러한 병렬 처리 능력을 어떻게 활용할 수 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# CUDA 소개\n\n딥러닝 모델을 실행할 때, 아마도 PyTorch나 TensorFlow와 같은 인기있는 Python 라이브러리를 사용하게 될 것입니다. 그러나 이러한 라이브러리의 핵심이 C/C++ 코드로 구동된다는 것은 잘 알려져 있습니다. 또한 앞에서 언급했듯이, 처리 속도를 높이기 위해 GPU를 사용할 수 있습니다. 여기서 CUDA가 등장합니다! CUDA는 NVIDIA가 개발한 일반 목적의 처리를 위한 플랫폼으로, Compute Unified Architecture의 약자입니다. 그러므로 게임 엔진에서 그래픽 계산을 처리하는 데 DirectX가 사용되는 것과 달리, CUDA는 개발자가 NVIDIA의 GPU 연산 능력을 그래픽 렌더링에만 한정되지 않고 일반 목적의 소프트웨어 응용프로그램에 통합할 수 있도록 합니다.\n\n이를 구현하기 위해 CUDA는 GPU의 가상 명령어 집합과 특정 작업(예: CPU와 GPU 간의 데이터 이동)에 액세스를 제공하는 간단한 C/C++ 기반 인터페이스인 CUDA C/C++을 제공합니다.\n\n더 나아가기 전에, CUDA 프로그래밍 개념과 용어를 몇 가지 이해해 보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 호스트: CPU 및 해당 메모리를 가리킵니다.\n- 장치: GPU 및 해당 메모리를 가리킵니다.\n- 커널: 장치(GPU)에서 실행되는 함수를 가리킵니다.\n\n그래서 CUDA를 사용하여 작성된 기본 코드에서 프로그램은 호스트(CPU)에서 실행되며, 데이터를 장치(GPU)에 전송한 후 장치(GPU)에서 실행될 커널(함수)을 시작합니다. 이러한 커널은 병렬로 여러 스레드에 의해 실행됩니다. 실행이 완료되면 결과는 장치(GPU)에서 호스트(CPU)로 다시 전송됩니다.\n\n그러니까 두 벡터를 더하는 문제로 돌아가 봅시다:\n\n```js\n#include \u003cstdio.h\u003e\n\nvoid AddTwoVectors(float A[], float B[], float C[]) {\n    for (int i = 0; i \u003c N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n\nint main() {\n    ...\n    AddTwoVectors(A, B, C);\n    ...\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCUDA C/C++에서 프로그래머는 CUDA 스레드에 의해 병렬로 N번 실행되는 C/C++ 함수 인 켤널이라고 불리는 함수를 정의할 수 있습니다.\n\n켤널을 정의하려면 **global** 선언 지정자를 사용하고, 이 켤널을 실행하는 CUDA 스레드의 수는 ... 표기법을 사용하여 지정할 수 있습니다:\n\n```js\n#include \u003cstdio.h\u003e\n\n// 켤널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n    ...\n    // N개의 스레드로 켤널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(A, B, C);\n    ...\n}\n```\n\n각 스레드는 켤널을 실행하고 내장 변수를 통해 켤널 내에서 액세스할 수있는 고유한 스레드 ID threadIdx가 제공됩니다. 위의 코드는 크기가 N 인 두 벡터 A와 B를 더하여 결과를 벡터 C에 저장합니다. 순차적으로 각 쌍-wise 추가를 실행하는 루프 대신, CUDA는 우리에게 모든 이러한 작업을 N 개의 스레드를 사용하여 동시에 수행할 수 있도록 허용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 이 코드를 실행하기 전에 다른 수정 작업을 해야 합니다. 커널 함수는 장치(GPU) 내에서 실행되기 때문에 모든 데이터는 장치 메모리에 저장되어야 합니다. 다음 CUDA 내장 함수를 사용하여 이 작업을 수행할 수 있습니다:\n\n```js\n#include \u003cstdio.h\u003e\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B, C를 위한 배열\n\n    ...\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B, C에 대한 장치 포인터\n\n    // 벡터 A, B, C에 대한 장치 메모리 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 호스트에서 디바이스로 벡터 A와 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N 개의 스레드로 커널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(d_A, d_B, d_C);\n\n    // 디바이스에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n}\n```\n\n커널에 변수 A, B, C를 직접 전달하는 대신 포인터를 사용해야 합니다. CUDA 프로그래밍에서는 커널 런치 내에서 호스트 배열(예: 예제의 A, B, C)을 직접 사용할 수 없습니다. CUDA 커널은 장치 메모리에서 작동하므로 커널이 작동하도록 장치 포인터(d_A, d_B, d_C)를 전달해야 합니다.\n\n이를 넘어서 cudaMalloc을 사용하여 장치에 메모리를 할당하고, cudaMemcpy를 사용하여 호스트와 장치 간에 데이터를 복사해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 벡터 A와 B의 초기화를 추가하고 코드 끝에 cuda 메모리를 새로고침할 수 있습니다.\n\n```js\n#include \u003cstdio.h\u003e\n\n// Kernel 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B, C에 대한 배열\n\n    // 벡터 A와 B 초기화\n    for (int i = 0; i \u003c N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B, C에 대한 장치 포인터\n\n    // 벡터 A, B, C에 대한 메모리 장치에 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 벡터 A 및 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N 스레드를 사용하여 커널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(d_A, d_B, d_C);\n\n    cudaDeviceSynchronize(); // 커널 호출 뒤 cudaDeviceSynchronize() 추가\n\n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\n또한, 커널 호출 후에 cudaDeviceSynchronize();를 추가해야 합니다. 이 함수는 호스트 스레드를 장치와 동기화하는 데 사용됩니다. 이 함수가 호출되면 호스트 스레드는 계속 실행하기 전에 이전에 발행된 모든 CUDA 명령이 장치에서 완료될 때까지 기다립니다.\n\n또한 GPU에서 버그를 식별할 수 있도록 일부 CUDA 오류 확인을 추가하는 것이 중요합니다. 이 확인을 추가하지 않으면 코드가 계속해서 호스트 스레드(CPU)를 실행하고 CUDA 관련 오류를 식별하는 것이 어려울 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래에 두 기술의 구현이 있습니다.\n\n```js\n#include \u003cstdio.h\u003e\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B 및 C를 위한 배열\n\n    // 벡터 A와 B를 초기화\n    for (int i = 0; i \u003c N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B 및 C의 장치 포인터\n\n    // 장치에서 벡터 A, B 및 C에 대한 메모리 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 벡터 A와 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N개의 스레드로 커널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(d_A, d_B, d_C);\n\n    // 오류 확인\n    cudaError_t error = cudaGetLastError();\n    if(error != cudaSuccess) {\n        printf(\"CUDA 오류: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    // 모든 CUDA 스레드가 실행될 때까지 대기\n    cudaDeviceSynchronize();\n\n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\nCUDA 코드를 컴파일하고 실행하려면 시스템에 CUDA 툴킷이 설치되어 있는지 확인해야 합니다. 그런 다음 NVIDIA CUDA 컴파일러인 nvcc를 사용하여 코드를 컴파일할 수 있습니다. 만약 컴퓨터에 GPU가 없다면 Google Colab을 사용할 수 있습니다. Runtime → 노트 설정에서 GPU를 선택한 후 code.cu 파일에 코드를 저장하고 다음과 같이 실행하면 됩니다:\n\n```js\n%%shell\nnvcc example.cu -o compiled_example # 컴파일\n./compiled_example # 실행\n\n# 버그 감지 산소화 도구로 코드 실행도 가능합니다\ncompute-sanitizer --tool memcheck ./compiled_example\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나, 우리의 코드는 아직 완벽하게 최적화되지 않았습니다. 위의 예시에서는 크기가 N = 1000인 벡터를 사용했습니다. 그러나 이는 GPU의 병렬화 능력을 완전히 보여주지 못하는 작은 숫자입니다. 또한, 딥러닝 문제를 다룰 때는 종종 수백만 개의 매개변수를 가진 대규모 벡터를 다루게 됩니다. 그러나, 예를 들어 N = 500000으로 설정하고 위의 예시와 같이 1, 500000로 커널을 실행하면 오류가 발생할 것입니다. 이러한 작업을 개선하고 수행하기 위해서는 먼저 CUDA 프로그래밍의 중요한 개념인 Thread 계층 구조를 이해해야 합니다.\n\n# Thread 계층 구조\n\n커널 함수를 호출할 때는 블록의*개수, 블록당*쓰레드\\_개수 표기법을 사용합니다. 따라서, 위의 예시에서는 1개의 블록을 N개의 CUDA 쓰레드로 실행했습니다. 그러나, 각 블록은 지원할 수 있는 쓰레드 개수에 제한이 있습니다. 이는 블록 내의 모든 쓰레드가 동일한 스트리밍 멀티프로세서 코어에 있어야 하고 해당 코어의 메모리 자원을 공유해야 하기 때문에 발생합니다.\n\n다음 코드 스니펫을 사용하여 이 제한을 확인할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nint device;\ncudaDeviceProp props;\ncudaGetDevice(\u0026device);\ncudaGetDeviceProperties(\u0026props, device);\nprintf(\"블록당 최대 스레드 수: %d\\n\", props.maxThreadsPerBlock);\n```\n\n현재 코랩 GPU에서 스레드 블록 당 최대 1024개의 스레드가 포함될 수 있습니다. 그래서 우리는 예제에서 대량의 벡터를 처리하기 위해 훨씬 더 많은 스레드를 실행하기 위해 더 많은 블록이 필요합니다. 또한, 아래 그림에서 보여지는 대로 블록은 그리드로 구성됩니다.\n\n![CUDA Programming](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_4.png)\n\n이제 스레드 ID는 다음과 같이 액세스할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```c\n__global__ void AddTwoVectors(float A[], float B[], float C[], int N) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i \u003c N) // 배열 범위를 초과하지 않도록\n        C[i] = A[i] + B[i];\n}\n```\n\n그래서 우리의 스크립트는 다음과 같아졌습니다:\n\n```c\n#include \u003cstdio.h\u003e\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[], int N) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i \u003c N) // 배열 범위를 초과하지 않도록\n        C[i] = A[i] + B[i];\n}\n\nint main() {\n    int N = 500000; // 벡터 크기\n    int threads_per_block;\n    int device;\n    cudaDeviceProp props;\n    cudaGetDevice(\u0026device);\n    cudaGetDeviceProperties(\u0026props, device);\n    threads_per_block = props.maxThreadsPerBlock;\n    printf(\"블록 당 최대 쓰레드 수: %d\\n\", threads_per_block); // 1024\n\n    float A[N], B[N], C[N]; // 벡터 A, B 및 C를 위한 배열\n\n    // 벡터 A와 B 초기화\n    for (int i = 0; i \u003c N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B 및 C를 위한 장치 포인터\n\n    // 벡터 A, B 및 C를 위한 장치에 메모리 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 벡터 A와 B를 호스트에서 장치로 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // 여러 블록과 블록 당 쓰레드 수로 커널 호출\n    int number_of_blocks = (N + threads_per_block - 1) / threads_per_block;\n    AddTwoVectors\u003c\u003c\u003cnumber_of_blocks, threads_per_block\u003e\u003e\u003e(d_A, d_B, d_C, N);\n\n    // 오류 확인\n    cudaError_t error = cudaGetLastError();\n    if (error != cudaSuccess) {\n        printf(\"CUDA 오류: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    // 모든 CUDA 쓰레드가 실행될 때까지 대기\n    cudaDeviceSynchronize();\n\n    // 벡터 C를 장치에서 호스트로 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\n# 성능 비교\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 다른 벡터 크기에 대해 CPU 및 GPU 연산을 비교한 것입니다.\n\n![Comparison of CPU and GPU computation](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_5.png)\n\n어떤 경우에는 대규모 벡터 크기 N에 대해 GPU 처리의 이점이 뚜렷해집니다. 또한, 시간 비교는 커널/함수의 실행만을 고려한 것임을 기억해주세요. 호스트와 장치 간 데이터 복사에 소요되는 시간은 고려되지 않았는데, 일반적으로 큰 문제가 아닐 수 있지만, 우리의 경우에는 단순 덧셈 연산만 수행하기 때문에 상당히 중요합니다. 따라서, GPU 계산은 고도로 계산 집약적이고 또한 고도로 병렬화된 계산을 다룰 때만 그 이점을 나타냄을 기억하는 것이 중요합니다.\n\n# 다차원 스레드\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋아요, 이제 간단한 배열 작업의 성능을 향상시키는 방법을 알게 되었습니다. 그러나 딥 러닝 모델을 다룰 때는 행렬 및 텐서 작업을 처리해야 합니다. 이전 예제에서는 N 스레드를 사용하여 1차원 블록만 사용했습니다. 그러나 최대 3차원까지 다차원 스레드 블록을 실행할 수도 있습니다. 행렬 작업을 실행해야 할 경우 편리하게 NxM 스레드의 스레드 블록을 실행할 수 있습니다. 이 경우에는 행 = threadIdx.x, 열 = threadIdx.y와 같이 행렬 행 및 열 인덱스를 얻을 수 있습니다. 또한 편리하게 number_of_blocks 및 threads_per_block을 정의하는 데 dim3 변수 유형을 사용할 수 있습니다.\n\n아래 예제는 두 행렬을 더하는 방법을 보여줍니다.\n\n```js\n#include \u003cstdio.h\u003e\n\n// Kernel definition\n__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {\n    int i = threadIdx.x;\n    int j = threadIdx.y;\n    C[i][j] = A[i][j] + B[i][j];\n}\n\nint main() {\n    ...\n    // 1개의 NxN 스레드 블록을 사용하여 커널 호출\n    dim3 threads_per_block(N, N);\n    AddTwoMatrices\u003c\u003c\u003c1, threads_per_block\u003e\u003e\u003e(A, B, C);\n    ...\n}\n```\n\n이 예제를 여러 블록을 처리할 수 있도록 확장할 수도 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n#include \u003cstdio.h\u003e\n\n// Kernel definition\n__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i \u003c N \u0026\u0026 j \u003c N) {\n        C[i][j] = A[i][j] + B[i][j];\n    }\n}\n\nint main() {\n    ...\n    // Kernel invocation with 1 block of NxN threads\n    dim3 threads_per_block(32, 32);\n    dim3 number_of_blocks((N + threads_per_block.x - 1) ∕ threads_per_block.x, (N + threads_per_block.y - 1) ∕ threads_per_block.y);\n    AddTwoMatrices\u003c\u003c\u003cnumber_of_blocks, threads_per_block\u003e\u003e\u003e(A, B, C);\n    ...\n}\n```\n\n이런 멀티 차원 데이터를 다루는 법을 알게 되어서 좋습니다. 또한, 커널 내에서 함수를 호출하는 방법을 알아보겠습니다. 기본적으로 이는 **device** 선언 지정자를 사용하여 간단히 수행할 수 있습니다. 이는 기기(GPU)에서 직접 호출할 수 있는 함수를 정의합니다. 따라서 이러한 함수들은 오직 **global** 또는 다른 **device** 함수에서만 호출할 수 있습니다. 아래 예시는 시그모이드 연산을 벡터에 적용하는 방법을 보여줍니다.\n\n```js\n#include \u003cmath.h\u003e\n\n// Sigmoid function\n__device__ float sigmoid(float x) {\n    return 1 / (1 + expf(-x));\n}\n\n// Kernel definition for applying sigmoid function to a vector\n__global__ void sigmoidActivation(float input[], float output[]) {\n    int i = threadIdx.x;\n    output[i] = sigmoid(input[i]);\n\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서, 이제 CUDA 프로그래밍의 기본적인 중요한 개념을 알았으니 CUDA 커널을 만들기 시작할 수 있어요. 딥 러닝 모델의 경우, 그들은 기본적으로 합, 곱셈, 컨볼루션, 정규화 등과 같은 매트릭스 및 텐서 연산들의 집합입니다. 예를 들어, 단순한 행렬 곱셈 알고리즘은 다음과 같이 병렬화될 수 있어요:\n\n![Image](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_6.png)\n\n```js\n// GPU 버전\n\n__global__ void matMul(float A[M][N], float B[N][P], float C[M][P]) {\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row \u003c M \u0026\u0026 col \u003c P) {\n        float C_value = 0;\n        for (int i = 0; i \u003c N; i++) {\n            C_value += A[row][i] * B[i][col];\n        }\n        C[row][col] = C_value;\n    }\n}\n```\n\n이제 이것을 아래의 두 행렬 곱셈의 일반 CPU 구현과 비교해보세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n// CPU 버전\n\nvoid matMul(float A[M][N], float B[N][P], float C[M][P]) {\n    for (int row = 0; row \u003c M; row++) {\n        for (int col = 0; col \u003c P; col++) {\n            float C_value = 0;\n            for (int i = 0; i \u003c N; i++) {\n                C_value += A[row][i] * B[i][col];\n            }\n            C[row][col] = C_value;\n        }\n    }\n}\n```\n\nGPU 버전에는 더 적은 루프가 있어서 작업이 빨라진다는 것을 알 수 있습니다. 아래는 NxN 행렬 곱셈의 CPU와 GPU 성능 비교입니다:\n\n![performance-comparison](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_7.png)\n\n행렬의 크기가 커질수록 GPU 처리의 성능 향상이 더 큰 것을 관찰할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 기본 신경망을 고려해 보세요. 주로 y = σ(Wx + b) 작업을 포함하는데, 아래 그림과 같이 구성됩니다:\n\n![Neural Network Operations](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_8.png)\n\n이러한 작업은 주로 행렬 곱셈, 행렬 덧셈, 배열에 함수를 적용하는 것으로 이루어져 있습니다. 병렬화 기술에 익숙하신 분들이라면 이미 이들을 알고 계실 것입니다. 따라서 이제 GPU에서 실행되는 자체 신경망을 처음부터 구현할 수 있는 능력이 생겼습니다!\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물에서는 GPU 처리에 대한 입문적인 개념을 다루어 딥러닝 모델의 성능을 향상시키는 방법에 대해 알아보았어요. 그러나 본 포스트에서 다룬 내용은 기초적인 것들뿐이며, 더 많은 것을 배울 수 있습니다. PyTorch와 Tensorflow와 같은 라이브러리는 최적화 기술을 구현하고 있으며, 최적화된 메모리 액세스, 배치 연산 등과 같은 보다 복잡한 개념들을 활용합니다 (이들은 cuBLAS 및 cuDNN과 같은 CUDA 기반 라이브러리 위에서 구축된 라이브러리를 활용합니다). 그러나 \"cuda\"로 지정하고 GPU에서 딥러닝 모델을 실행할 때 무슨 일이 벌어지는지에 대한 배경 정보를 이해하는 데 이 게시물이 도움이 되기를 바랍니다.\n\n향후 게시물에서는 CUDA 프로그래밍에 관련된 더 복잡한 개념들을 소개할 예정이에요. 의견을 주시거나 다음에 대해 무엇을 쓰기를 원하시는지 알려 주시면 감사하겠어요! 읽어주셔서 너무 감사해요! 😊\n\n# 추가 자료\n\nNVIDIA CUDA 프로그래밍 문서 — NVIDIA CUDA 프로그래밍 가이드.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCUDA 문서 — NVIDIA의 완전한 CUDA 문서입니다.\n\nCUDA 신경망 훈련 구현 — 순수 CUDA C++로 구현된 신경망 훈련입니다.\n\nCUDA LLM 훈련 구현 — 순수 CUDA C로 구현된 LLM의 훈련입니다.\n","ogImage":{"url":"/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png"},"coverImage":"/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png","tag":["Tech"],"readingTime":23},{"title":"재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠","description":"","date":"2024-05-23 17:14","slug":"2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction","content":"\nPrometheus, Triton, 그리고 Grafana를 사용하여 엔드 투 엔드 모니터링 대시보드를 구축해보세요.\n\nML 시스템을 배포하기 전에, 엔지니어들은 로컬 및 대규모에서 어떻게 성능을 발휘할지 정확한 통찰력이 필요합니다. 병목 현상을 식별하고 예상치 못한 동작을 파악하기 위해.\n\n클래식 ML 추론 파이프라인과 비교하면, 딥 러닝 시스템은 자원 소비, 복잡성 및 확장 가능성의 도전에 따라 낮은 지연 시간, 높은 처리량에 중점을 둔다는 것 때문에 보다 \"중요한\" 및 자세한 모니터링이 필요합니다. 특히, 컴퓨터 비전과 같은 자원 집중적인 응용 프로그램에서 딥 러닝 배포를 위해 ML 엔지니어들은 모니터링에 우선순위를 두어야 합니다.\n\n이 글에서는 배포 설정 및 모니터링의 워크플로우에 대해 다루겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 목차\n\n1. 성능 모니터링 파이프라인 설정 방법\n\n- 컨테이너\n- 설정 파일\n- 도커 컴포즈\n\n2. 메트릭 스크랩 구성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프로메테우스 타겟을 추가하기\n\n- 그라파나 데이터소스 추가하기\n- 헬스체크 대상 스크랩\n\n3. 대시보드 생성\n\n- GPU 메트릭을 위한 패널\n- CPU/RAM 메트릭을 위한 패널\n\n4. 시각화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로 넘어가기 전에 사용할 도구들을 살펴봅시다:\n\n- 도커는 가벼우고 휴대용한 컨테이너 내에서 애플리케이션을 개발, 배포, 실행할 수 있는 플랫폼입니다 — ML 엔지니어에게 꼭 필요한 도구입니다.\n- 도커 컴포즈는 멀티 컨테이너 애플리케이션을 정의하고 구성하는 도구입니다.\n- cAdvisor는 구글에서 개발한 리소스 사용량 및 컨테이너 성능 지표를 제공해주는 오픈소스 도구입니다.\n- 프로메테우스는 메트릭을 수집하고 저장하는 모니터링 및 경보 시스템으로, 프로메테우스에 대한 전문 지식은 ML/MLOps 엔지니어에게 큰 장점입니다.\n- 그라파나는 모니터링 및 가시성 플랫폼으로, 배포된 시스템의 메트릭을 생성, 시각화, 경보 및 이해할 수 있게 해줍니다. 모니터링 대시보드를 관리하는 것은 MLOps 엔지니어에게 중요한 기술입니다.\n- Triton Inference Server는 NVIDIA에서 개발한 인기 있는 모델 서빙 프레임워크로, 복잡한 ML 모델을 프로덕션 환경에 배포하는 데 중요한 역할을 합니다. Triton에 대한 전문 지식은 MLOps 엔지니어에게 필수적인 기술입니다.\n\n# 1. 도커 컴포즈 설정\n\n각 서비스가 무엇을 하는지 설명하고, 이러한 서비스를 캡슐화하고 실행할 도커 컴포즈를 준비하는 것부터 시작해봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음과 같은 내용이 있습니다:\n\n![이미지](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png)\n\n도커 컴포즈 모니터링 yaml 파일을 살펴보겠습니다.\n\n```yaml\n# cat docker-compose-monitoring.yaml\nversion: \"3.4\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"${PROMETHEUS_PORT}:${PROMETHEUS_PORT}\"\n    container_name: prometheus\n    restart: always\n    volumes:\n      - \"${MONITORING_CONFIGURATIONS}/prometheus.monitoring.yml:/etc/prometheus/prometheus.monitoring.yml\"\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    command:\n      - \"--config.file=/etc/prometheus/prometheus.monitoring.yml\"\n      - \"--enable-feature=expand-external-labels\"\n    depends_on:\n      - cadvisor\n    networks:\n      monitor-net:\n        ipv4_address: ${PROM_IP}\n  grafana:\n    image: grafana/grafana-enterprise:8.2.0\n    container_name: grafana\n    ports:\n      - \"${GRAFANA_PORT}:${GRAFANA_PORT}\"\n    volumes:\n      - ${MONITORING_CONFIGURATIONS}/datasources:/etc/grafana/provisioning/datasources\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PWD}\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}\n    networks:\n      monitor-net:\n        ipv4_address: ${GRAFANA_IP}\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:latest\n    container_name: cadvisor\n    restart: always\n    ports:\n      - \"${CADVISOR_PORT}:${CADVISOR_PORT}\"\n    volumes:\n      - \"/etc/localtime:/etc/localtime:ro\"\n      - \"/etc/timezone:/etc/timezone:ro\"\n      - \"/:/rootfs:ro\"\n      - \"/var/run:/var/run:rw\"\n      - \"/sys:/sys:ro\"\n      - \"/var/lib/docker:/var/lib/docker:ro\"\n    networks:\n      monitor-net:\n        ipv4_address: ${CADVISOR_IP}\n  triton_server:\n    container_name: tis2109\n    image: nvcr.io/nvidia/tritonserver:21.09-py3\n    privileged: true\n    ports:\n      - \"8002:8002\"\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              capabilities: [gpu]\n    volumes:\n      - ${TRITON_MODELS_REPOSITORY}:/models\n    command:\n      [\n        \"tritonserver\",\n        \"--model-repository=/models\",\n        \"--strict-model-config=false\",\n      ]\n    networks:\n      monitor-net:\n        ipv4_address: ${TRITON_IP}\nnetworks:\n  monitor-net:\n    driver: bridge\n    internal: false\n    ipam:\n      driver: default\n      config:\n        - subnet: ${SUBNET}\n          gateway: ${GATEWAY}\n```\n\n보시다시피, .yaml 설정에 일부 마스킹된 $'변수'가 있습니다. 이들은 .env 파일 내부에서 자동으로 상속되어 로컬 개발 및 CI/CD 파이프라인에서 최상의 관행을 따르는 흐름을 가지고 있습니다.\n\n이제 .env 파일에 어떤 것이 있는지 살펴봅시다:\n\n```yaml\n# == 모니터링 변수 ==\nPROMETHEUS_PORT=9090\nGRAFANA_PORT=3000\nCADVISOR_PORT=8080\nMONITORING_CONFIGURATIONS=\u003cyour_configuration_files에 대한_경로\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# == 자격 증명 ==\nGRAFANA_PWD=admin\nGRAFANA_USER=admin\n# == TIS 변수 ==\nTRITON_MODELS_REPOSITORY=\u003c당신의_triton_모델_저장소_경로\u003e\n# == 기본 네트워크 ==\nSUBNET=172.17.0.0/16\nGATEWAY=172.17.0.1\n# == 서브넷 IP ==\nTRITON_IP=172.17.0.3\nCADVISOR_IP=172.17.0.4\nPROM_IP=172.17.0.5\nGRAFANA_IP=172.72.0.6\n```\n\n대부분의 변수가 설정되었지만, 여기서 살펴봐야 할 주요한 2가지 변수는 다음과 같습니다:\n\n- MONITORING_CONFIGURATIONS\n  이것은 이러한 구조가 있는 폴더를 가리켜야 합니다\n\n```js\n.__ monitoring\n|  |_ datasources\n|  | |_ datasources.yml\n|  |_ prometheus.monitoring.yml\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- TRITON_MODEL_REPOSITORY\n  모델 저장소의 구조는 다음과 같아야 합니다:\n\n```js\nmodel_repository\n└── prod_client1_encoder\n    └── 1\n        └──resnet50.engine\n    └── config.pbtxt\n```\n\n프로메테우스 모니터링 파일인 prometheus.monitoring.yml에는 메트릭을 가져올 대상(컨테이너)을 추가할 것입니다.\n데이터 소스 파일인 datasources.yml에는 그라파나 대시보드의 소스로 프로메테우스를 추가할 것입니다. 그렇게 하면 그라파나 UI를 열 때 나타날 것입니다.\n\n# 2. 프로메테우스 스크래핑 구성 정의\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼 Prometheus 대상을 구성해 보겠습니다. `prometheus.monitoring.yml` 파일에 작성하겠습니다.\n\n```yaml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n```\n\n```yaml\nscrape_configs:\n  - job_name: \"prometheus\"\n    static_configs:\n      - targets: [\"172.17.0.5:9090\"]\n  - job_name: \"triton-server\"\n    static_configs:\n      - targets: [\"172.72.0.3:8002\"]\n\n  - job_name: \"cadvisor\"\n    static_configs:\n      - targets: [\"172.72.0.4:8080\"]\n```\n\n3개의 대상이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 프로메테우스 — 모니터링 프로메테우스 자체를 유지하는 것이 건강한 모니터링을 위한 모범 사례로 작용합니다. 수천 개의 메트릭을 처리하면 병목 현상이 발생할 수 있으며 프로메테우스 자체의 자원 사용량을 알고 있는 것이 유용합니다.\n- Triton Server — 이것은 이 딥러닝 스택의 핵심에 있어 중요합니다. ML 모델을 제공하고 관리하기 때문입니다.\n  Triton은 인퍼런스 프로세스 전반에 걸쳐 다양한 메트릭을 제공하는 포트 8002의 내장된 프로메테우스 엔드포인트가 있습니다.\n- cAdvisor — 이 배포에서 컨테이너 전반의 CPU/RAM 사용량 정보를 얻기 위해 사용됩니다.\n\n모두 구성한 뒤, 컴포저를 시작하고 문제가 있는지 검사할 수 있습니다.\n컨테이너를 시작해 봅시다.\n\n```js\ndocker compose -f docker-compose-monitoring.yaml up -d\n```\n\n프로메테우스 대상을 검사해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 웹 브라우저로 가서 전체 Prometheus URL(IP:9090)을 입력해주세요.\n- 상태 → 대상(Targets)으로 이동해주세요.\n- 스크래핑 구성에서 각 대상이 정상인지 확인해주세요(녹색).\n\n이러한 사항을 확인한 후에는 Grafana에서 대시보드를 만들어 진행할 수 있습니다.\n\n# #3 대시보드 생성하기\n\nGrafana WebUI 대시보드에 액세스하려면 브라우저를 열고 `localhost:3000`으로 이동해주세요. 여기서 3000은 Grafana 컨테이너를 실행하는 포트입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로그인 페이지로 이동하면 사용자 이름/암호 필드에 `admin/admin`을 사용하십시오. 더 높은 보안이 권장되지만, 이는 이 기사의 범위에 포함되지 않습니다.\n\nGrafana 웹을 열었으면 다음을 수행해야 합니다:\n\n- 데이터 소스를 우리의 Prometheus 메트릭 스크래퍼 엔드포인트로 지정합니다.\n- 새 대시보드 생성\n- 관심 있는 메트릭을 집계/시각화하기 위해 차트 추가\n\n#3.1 Prometheus 데이터 소스\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n왼쪽 패널에서 기어 아이콘(설정)을 클릭하고 DataSources를 선택하세요.\n다음과 같은 뷰가 나타날 것입니다:\n\n\"Add data source\"를 클릭한 후 Time Series Databases 아래에서 `Prometheus`를 선택하세요. Grafana는 여러 종류의 메트릭 스크랩을 지원하고 있습니다. 여기서는 Prometheus를 사용할 것입니다. 이런 뷰가 나타날 것입니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_1.png\" /\u003e\n\n여기에는 Prometheus 엔드포인트의 URL을 추가해야 합니다. 우리의 도커 컴포즈 배포에서는 `http://prometheus:9090`을 사용할 것입니다. 이 템플릿을 따르면 `http://container_name:container_port`가 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_2.png\" /\u003e\n\n여기까지 오셨군요. 이제 데이터 원본 추가 섹션이 완료되었습니다.\n이제 대시보드를 만들어보겠습니다.\n\n### 3.2 Grafana 대시보드 만들기\n\n왼쪽 패널에서 “+” 표시를 클릭하고 `Dashboard`를 선택하세요. 이렇게 하면 미리 정의된 패널 그룹이 있는 새 대시보드 페이지로 이동합니다. 우리는 모든 것을 처음부터 만들고 있으므로 `Empty Panels`만 사용하여 주요 지표를 표시할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 한 예제에 대한 따라할 프로세스입니다:\n\n- 새 쿼리를 추가하고 `promql` (Prometheus 쿼리 언어)를 정의합니다.\n- 시각화 유형, 그래프 스타일, 범례를 구성합니다.\n\n다음은 비어 있는 패널의 모습입니다:\n\n이제, 트리튼 추론 서버 모델 서빙 플랫폼을 모니터링하기 위해 몇 가지 사용자 정의 쿼리를 추가할 것입니다. 하지만 먼저 다음 참고 사항을 유념해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 쿼리를 설정해보겠습니다. 이 쿼리는 성공적인 요청의 수를 고려하여 모델이 하나의 추론 요청을 수행하는 데 걸리는 시간(밀리초)을 측정할 것입니다. 우리는 시간이 지남에 따라 진행 상황을 보고 싶기 때문에 이 차트는 `시계열(time-series)`이 될 것입니다.\n다음은 해당 지표를 작성하는 쿼리입니다:\n\n```js\n(irate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\n```\n\n쿼리를 해석해 봅시다:\n\n아래에서 쿼리의 모습을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 새 차트의 설정을 구성할 때, 오른쪽에 다음을 지정할 수 있습니다:\n\n- 차트 유형 — 직선 / 곡선 / T-스텝 라인 중 선택\n- 메트릭 범위 — 메트릭 선택(예: 밀리초(ms))하고 low_range(예: 0)와 high_range(예: 100ms) 정의\n- 사용자 지정 텍스트 — 범례 또는 다른 필드에 표시될 내용\n\n#3.3 시각화 완료\n\n위의 흐름에 따라, 나머지 차트를 생성할 수 있습니다.\n전체 성능 모니터링 차트를 컴파일하려면 나머지 패널을 추가하십시오. 다음 각각에 대해 새 패널을 만들고 해당 세부 정보로 채워넣습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- GPU 사용된 바이트 - VRAM 사용량의 백분율\n\n```js\n쿼리: nv_gpu_memory_used_bytes{job=\"triton-server\"}/nv_gpu_memory_total_bytes{job=\"triton-server\"}\n차트 유형: 파이\n범례: {인스턴스}\n```\n\n2. GPU 활용도 - 전체 GPU 활용도\n\n```js\n쿼리: nv_gpu_utilization{job=\"triton-server\"}\n차트 유형: 시계열\n범례: NULL\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 입력 시간/요청 — 클라이언트가 입력 데이터를 Triton 서버로 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n4. 출력 시간/요청 — 서버가 클라이언트에게 출력을 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000)/ irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. DB 비율 (#요청/#실행) — 성공적인 요청의 전체 요청 대비 비율\n\n```js\n쿼리: sum by (모델,버전) (rate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])/rate(nv_inference_exec_count{job=\"triton-server\"}[$__rate_interval]) )\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n6. 대기 시간/요청 — 요청이 처리되기 전에 대기하는 시간\n\n```js\n쿼리: sum by (모델,버전) ((irate(nv_inference_queue_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval]))\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n7. 집계된 입력/추론/출력 - 입력 출력 및 추론을 한 차트에 표시합니다.\n\n```js\n질의:\nA: rate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nB: rate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nC: rate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__interval]) / 1000\n\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n우리가 만든 완벽한 대시보드는 다음을 보여줍니다:\n\n- GPU VRAM 이용률\n- 클라이언트에서 서버로의 입력 송신 시간\n- 서버 추론 요청 시간\n- 서버에서 클라이언트로의 출력 송신 시간\n- 성공 요청/전체 요청 비율\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이런 종류의 대시보드는 배포된 스택의 성능 및 스트레스 테스트 속에서의 동작을 모니터링하기 위한 시작점을 제시합니다.\n\n이는 배포의 실패 및 위험 지점을 연구하는 구체적인 방법을 제공하며 SLI(서비스 수준 지표)를 모니터링하는 데 도움이 됩니다.\n\n서비스 수준 지표는 SLA(서비스 수준 계약)를 준수하고 SLO(서비스 수준 목표)를 달성하기 위해 모니터링되는 메트릭입니다. 우리가 만든 대시보드는 제공되는 서비스 수준 계약을 준수하기 위한 목표에 도달하기 위한 가치 있는 통찰을 제공할 수 있습니다.\n\n또한 이는 다중 복제본을 추가하거나 추론 서빙 프레임워크를 실행하는 여러 기계로의 확장 전략을 계획하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n본 문서에서는 Prometheus와 Grafana를 사용하여 자사의 ML 애플리케이션 및 모델 서빙 프레임워크를 위한 성능 모니터링 스택을 설정하고 구축하는 방법을 소개했습니다.\n\n도커 컴포즈 파일을 준비하는 것부터 시작하여 워크플로우의 각 단계를 설명하고 스택을 배포하고 데이터 원본을 구성하며 대시보드 패널을 생성하고 지표를 집계하는 과정을 마무리했습니다.\n\n모니터링은 MLOps 시스템의 중요한 부분입니다!\n이 튜토리얼을 따라 하면 테스트 환경에서 단일 배포로 ML 애플리케이션을 위한 모니터링 파이프라인을 구조화하고 배포하거나, 클라우드 시나리오 설정에서 여러 입력 소스를 결합하고 전체 스택 배포를 모니터링하는 단일 대시보드 소비자 지점을 갖도록 구성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 더 많은 내용을 원하신다면!\n\n저는 미디엄에 새롭게 등장했습니다. 만약 이 글을 즐겨보셨다면 박수를 보내주시고 제 계정을 팔로우해주세요 - 정말로 감사하겠습니다! 🚀\n\n![How to ensure your deep learning stack is fail-safe in production](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_3.png)\n\n# 더 많은 글 보기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물과 관련성에 따라 정렬되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png"},"coverImage":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png","tag":["Tech"],"readingTime":18},{"title":"자기 주의적 문장 임베딩을 사용한 추천 시스템","description":"","date":"2024-05-23 17:13","slug":"2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem","content":"\n![Self-attentive sentence embedding](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png)\n\n# 소개\n\n트랜스포머 레이어와 그의 어텐션 메커니즘은 자연어처리(NLP) 커뮤니티에서 가장 중요한 아이디어 중 하나입니다. 최근 세계를 휩쓴 ChatGPT와 LLaMA와 같은 대규모 언어 모델에서 핵심 역할을 합니다.\n\n하지만 NLP 커뮤니티에서 시작된 다른 흥미로운 아이디어가 있는데, 그 영향은 주로 추천 시스템 분야에서 실현됩니다. 바로 자기주의적 문장 임베딩(self-attentive sentence embedding)입니다. 이 기사에서는 자기주의적 문장 임베딩[1]과 추천 시스템에 적용하는 방법을 살펴볼 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 작동 방식\n\n## 전체 아이디어\n\n이 논문의 주된 아이디어는 문장을 여러 임베딩으로 인코딩하여 문장의 다양한 측면을 포착할 수 있는 더 나은 방법을 찾는 것입니다. 구체적으로, 저자들은 문장을 단일 임베딩으로 인코딩하는 대신 각 행 임베딩이 문장의 다른 측면을 포착하는 2D 행렬로 인코딩하고자 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n문장 임베딩을 얻으면, 문장 분석, 작가 프로파일링, 텍스트 함의 등 다양한 하위 작업에 사용할 수 있습니다.\n\n## 모델 아키텍처\n\n모델 입력은 문장 배치입니다. 각 문장은 n개의 토큰을 가지고 있습니다. 우리는 i번째 문장을 다음과 같이 표현할 수 있습니다:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nd는 표현의 숨겨진 차원을 나타내며, 우리는 문장 s를 n by d 행렬 H로 인코딩할 수 있습니다:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_3.png)\n\n여기서 F는 문장의 토큰을 임베딩으로 인코딩하는 모델 함수를 나타냅니다. 논문에서는 단어 임베딩(Word2Vec을 사용하여 초기화)을 이용하여 토큰을 인코딩하고 이를 양방향 LSTM을 통해 전달합니다. 토큰을 임베딩으로 인코딩하는 다양한 방법이 있기 때문에 일반화를 위해 여기서 F를 사용했습니다.\n\n다음으로, 그들은 임베딩 H를 입력으로 사용하여 어텐션 가중치 행렬 A를 학습합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image #1](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_4.png)\n\nHere, the softmax() is applied to the second dimension of its input. We can view the formula as a 2-layer MLP without bias.\n\nAs we can see from the above formula, the attention weight A matrix will have a shape of r by n where r is the number of aspects a sentence can have and n is the sentence length. The authors argue that there are many aspects that make up the semantics of a sentence. Thus, they need r embeddings to focus on different parts of the sentence. In other words, each embedding in A is the sentence attention weight:\n\n![Image #2](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTransformer처럼 이 행렬 A의 시각화를 통해 문장에 대한 각 측면의 주의를 더 잘 이해할 수 있습니다.\n\n마지막으로, 우리는 H와 A를 곱하여 r by d 행렬 M을 얻음으로써 문장 임베딩을 생성합니다:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_6.png)\n\nM의 각 행은 토큰 임베딩과 그 토큰에 대한 측면의 가중치의 가중 합입니다. 시각적으로는 이렇게 보입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_7.png)\n\n## Regularization\n\nIn the paper, they also introduce a new regularization term:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n표를 마크다운 형식으로 변경해주세요.\n\nF는 행렬의 프로베니우스 노름을 나타냅니다.\n\n정규화 항은 2가지 목적을 제공합니다:\n\n- 측면 임베딩이 겹칠 수 있기 때문에 다양성을 높입니다. 즉, 유사할 수 있음을 의미합니다.\n- 각 관심사가 가능한 적은 토큰에 초점을 맞추도록 만듭니다.\n\n이 글에서는 정규화가 중점이 아니기 때문에 정규화가 어떻게 작동하는지에 대해 더 읽어볼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 추천 시스템에서의 다중 관심사\n\n셀프 어텐티브 문장 임베딩이 어떻게 작동하는지 이해하면, 추천 시스템에서 어떻게 활용할 지에 대해 집중할 수 있습니다.\n\n대규모 추천 시스템에서, 보통 두 개의 타워 모델 아키텍처를 사용합니다. 하나는 사용자 정보를 인코딩하고, 다른 하나는 후보 정보를 인코딩합니다. 사용자 타워에는 사용자의 과거 행동인 클릭, 좋아요, 공유 순서와 사용자 프로필을 사용합니다. 후보 타워에는 아이템 ID와 아이템 카테고리와 같은 후보 특징을 사용합니다.\n\n사용자 임베딩과 후보 임베딩을 내적하여 후보 아이템이 사용자에게 얼마나 관련 있는지를 반영합니다. 레이블은 사용자 시퀀스에서 다음 상호작용할 아이템입니다. 따라서 모델 목표는 사용자가 다음에 상호작용할 아이템을 예측하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Self-attentive sentence embedding for the recommendation system](/assets/img/2024-05-23-Self-attentive-sentence-embedding-for-the-recommendation-system_9.png)\n\n위 이미지에서 확인할 수 있듯이 사용자 타워의 출력은 모든 사용자 정보를 포함하는 임베딩입니다. 그러나 단일 사용자 임베딩은 모든 사용자의 다양한 관심사를 포착하는 데 좋지 않습니다. 따라서 더 나은 해결책은 사용자의 관심사를 여러 임베딩으로 인코딩하는 것입니다.\n\n사용자의 다양한 관심사를 어떻게 포착할지에 대한 많은 연구가 이루어졌습니다. 가장 두드러지는 두 가지 방법은 self-attentive 임베딩(SA) [2]과 dynamic routing (DR) [3]입니다. 두 방법 모두 비슷한 성능을 보이지만, self-attentive 방법이 더 안정적이고 훈련 속도가 빠릅니다.\n\nself-attentive 방법이 어떻게 작동하는지 이해하면 추천 시스템에 적용하는 것은 간단합니다. 입력으로 문장 토큰 대신에 유튜브에서 시청한 비디오 ID 목록이나 이커머스 플랫폼에서 클릭/주문한 상품 ID와 같은 사용자 행동을 사용합니다. 출력은 각 임베딩이 문장에서의 측면이 아니라 사용자 관심사를 인코딩합니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Table 1](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_10.png)\n\nIn the ComiRec paper [2], the authors compare the self-attentive method with the dynamic routing method along with other popular models that produce a single user interest:\n\n![Table 2](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_11.png)\n\nAs the table shows, the self-attentive method produces results comparable to those of the dynamic routing method. Still, both multi-interest embedding solutions are significantly better than their single-interest embedding counterparts.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마무리\n\n여러 관심사를 포함한 임베딩을 사용하여 모델을 교육하고 제공하는 것에는 많은 미묘한 점이 있습니다. 이 기사에서는 자가 주목 방법이 작동하는 방법과 이를 추천 시스템에서 어떻게 사용하는지에 대해 안내했습니다. 이러한 모델을 교육하고 제공하는 데 대한 더 자세한 내용은 논문을 읽는 것만큼 좋은 자료는 없습니다. 이 기사는 추천 시스템을 위한 다중 관심 프레임워크를 이해하고자 하는 여정에서 참고할 만한 자료입니다.\n\n# 참고\n\n[1] Lin, Zhouhan, et al. “A structured self-attentive sentence embedding.” arXiv preprint arXiv:1703.03130 (2017).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## References\n\n[1] Cen, Yukuo, et al. “Controllable multi-interest framework for recommendation.” Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2020.\n\n[2] Li, Chao, et al. “Multi-interest network with dynamic routing for recommendation at Tmall.” Proceedings of the 28th ACM international conference on information and knowledge management. 2019.\n","ogImage":{"url":"/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png"},"coverImage":"/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png","tag":["Tech"],"readingTime":9},{"title":"포디즘의 새로운 모습","description":"","date":"2024-05-23 17:11","slug":"2024-05-23-ThenewfaceofFordism","content":"\n\u003cimg src=\"/assets/img/2024-05-23-ThenewfaceofFordism_0.png\" /\u003e\n\n미국 로봇 기업인 Figure은 특정 경제 분야에서 발생하는 노동 인력 부족을 해결하기 위해 인간 형상 로봇을 개발 중이며, 독일 자동차 제조사인 BMW과 협약을 발표했습니다. 이 협약에 따라 Figure 01 로봇들이 BMW의 미국에 위치한 Spartanburg 공장에 배치될 예정입니다. 해당 공장은 X 및 XM 시리즈 차량을 하루에 약 1,500대 조립하며 현재 약 11,000명을 고용하고 있습니다.\n\n아직 로봇 수나 그들이 수행할 작업에 대한 구체적인 내용은 알려지지 않았지만, \"그들은 몇 달 동안 특정 작업을 수행할 수 있도록 훈련받은 후, 생산 공정(보디 샵, 시트 금속 및 웨어하우스 등)에 통합될 것이며 앞으로 12개월에서 24개월 안에 배치될 예정입니다.\"라는 말을 제외하고 전반적인 작업에 대한 컨셉 증명입니다.\n\nBMW는 이미 공장에서 사용 중인 Optimus 로봇을 보유한 Tesla와 경쟁을 목표로 하고 있습니다. 이와 같이 인간 형상 로봇을 사용하여 반복적이고 위험한 작업을 수행하는 것에 대해 연구해온 Honda나 Boston Dynamics를 인수한 Hyundai 등의 자동차 제조사들은 기업들이 고용인력을 영입하고 유지하기 어려운 일부 여러 가치를 내지 않는 반복적인 작업이 바로 그들이 가장 어려워하는 작업이며, 회사들은 이에 대해 논의하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금은 다음 세대 로봇의 개발이 진행되고 있습니다. 이러한 로봇들은 사람들과 함께 공간을 공유하는 환경에서 완전히 안전하며, 일 중에 일어나는 학습 과정이 모방을 통해 이뤄집니다. 실제로 Figure의 접근 방식은 로봇이 기업이 생산성을 높이고 비용을 절감하며 더 안전하고 일관된 작업 환경을 조성하는 데 기여할 것으로 보고 있으며, 회사를 RaaS(로보틱스 서비스) 모델로 설립하고 로봇을 기업에 대여할 계획입니다. Figure는 인간의 형태 요소를 모방하고 손으로 수행되는 작업에서 높은 정밀도를 달성하는 데 초점을 맞추고 있습니다.\n\n자동차 제조 공장에서 작업하는 로봇들. 2024년이 로보틱스의 해가 될 것으로 생각했을 때, 이렇게 빨리 이러한 종류의 보고서들을 듣게 될 줄은 저도 예상치 못했습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-ThenewfaceofFordism_0.png"},"coverImage":"/assets/img/2024-05-23-ThenewfaceofFordism_0.png","tag":["Tech"],"readingTime":2},{"title":"로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스","description":"","date":"2024-05-23 17:10","slug":"2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release","content":"\n\u003cimg src=\"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png\" /\u003e\n\nMerklebot에서는 로봇 플릿 운영자를 위한 데이터 관리 및 개발 도구를 만들고 있습니다. 우리는 다음 15년 안에 100억 대 이상의 로봇이 나올 가능성이 꽤 높다고 믿고 있으며, 이 비전을 실현하기 위해 견고하고 확장 가능하며 안전한 인프라 및 통신 스택을 구축하고 있습니다.\n\n## 로봇 에이전트란?\n\n몇 달 전에 Digital Black Box를 출시했습니다. 이 서비스는 로봇에서 로그, 카메라 피드 및 포인트 클라우드와 같은 데이터를 안전하고 저렴한 분산 저장 네트워크인 Filecoin에 백업하는 기능을 제공합니다. Digital Black Box는 다음으로 구성됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 가장자리에서 실행되는 로봇 에이전트\n\n2. 클라우드 연결을 제공하는 Merklebot 플랫폼\n\n첫 번째 버전의 로봇 에이전트는 가장자리 장치에서 데이터를 수집하고 백업하는데 사용되었습니다. 나중에는 Merklebot 플랫폼을 구축하여 Docker 컨테이너를 가장자리 장치에 배포하고 그 위에서 실행 중인 에이전트에 기능을 추가했습니다.\n\n## 로봇 에이전트 0.0.7\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 👀 네트워크에서 다른 로봇의 mDNS 자동 탐색\n- 🤖↔🤖 로봇 간의 Libp2p 메시징\n\n안녕하세요! 오늘은 로봇 에이전트 0.0.7의 새로운 릴리스를 Libp2p 통신 모듈과 함께 발표합니다. 최신 버전의 로봇 에이전트는 이제 Libp2p 피어 탐색, 주소 설정 및 메시지 전송을 갖추고 있습니다. 네트워크를 유연한 토폴로지로 설정할 수 있으며, 위치 변경이나 다른 매개변수를 바꿀 때마다 통신 스택을 구성할 필요가 없습니다. 이제 저희의 Github에서 공개되어 있습니다.\n\n로봇 에이전트 0.0.7를 설치하면 기기가 다른 에이전트를 자동으로 찾아 정보(상태, 이벤트)를 서로 전달할 수 있습니다. 중앙 서버에 접근하지 않고도 기기 간 통신을 수행할 수 있습니다. 이 도구는 MIT 라이선스로 완전히 오픈 소스이며, 여러분의 필요에 맞게 이 도구를 자유롭게 사용할 수 있습니다.\n\n## Merklebot 플랫폼\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMerklebot 플랫폼은 Robot Agents를 여러 기기 필릿에 중앙 집중식으로 롤아웃할 수 있도록 제공하여 로봇, 센서, 장비 및 기타 기계와 같은 다양한 기기를 안전하고 쉽게 관리할 수 있습니다. 전체 Robot Agents 필릿에 코드 및 Docker 컨테이너를 배포하고 데이터를 관리할 수 있습니다.\n\nMerklebot 없이:\n\n- 로봇에 연결\n- 로봇을 vpn 네트워크에 추가하거나 NAT 트래버셜을 우회하는 다른 방법\n- 🧑‍💻 코드를 작성합니다\n- ssh를 통해 로봇에 연결\n- ⏳ git pull\n- ⏳ docker build 및 run my-best-code\n- ⏳ 로봇 로그 보기\n- ⏳ 데이터(카메라 비디오 등)를 가져오기 위해 scp 실행\n- ⏳ 취합할 위치에 저장\n\nMerklebot을 사용하면:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 로봇에 연결하세요\n- install.sh를 실행하세요\n- 🧑‍💻코드를 작성하세요\n- 🚀플랫폼에서 한 번 클릭하거나 API를 호출하세요\n- 😎로그, 비디오 및 기타 데이터를 플랫폼에서 확인하세요\n\n## 다음은 무엇인가요\n\nMerklebot 팀은 오픈 소스 Agent의 기능을 계속 향상시키고 Merklebot 플랫폼에 더 많은 유틸리티를 추가할 새로운 기능 세트에 현재 작업 중입니다.\n\n- 에이전트를 위한 향상된 CLI 도구 (일반 명령 인터페이스). SSH 우회, 구성 업데이트 전달 및 기기에서 편집 없이 에이전트를 관리하세요. 현재 Merklebot 플랫폼에서 활성화되어 있지만, 이를 오픈 소스로 만들 계획을 하고 있어요!\n- 오픈 소스 데이터 관리 및 시각화 도구와의 통합. 로그 수집 및 저장, 데이터 작업 실행 및 시각화 생성을 할 수 있어요.\n- Jenkins와 같은 CI/CD (지속적 통합 지속적 배포) 도구와의 통합. 자동으로 장치에 새 소프트웨어 릴리스 설치하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리 새로운 에이전트를 확인해보세요! 피드백을 기다리고 있어요.\n\n그리고 기기 편대를 관리해야 한다면, Merklebot Platform으로 시작해보세요.\n","ogImage":{"url":"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png"},"coverImage":"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png","tag":["Tech"],"readingTime":4},{"title":"M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기","description":"","date":"2024-05-23 17:09","slug":"2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon","content":"\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png\" /\u003e\n\n안녕하세요, 로봇 공학 애호가 및 리눅스 사용자 여러분! 여러분께서는 강력한 M1 또는 M2 맥을 소유하셨지만 리눅스에서만 실행되는 프로젝트를 실행하고 싶으시죠? 다행히도 가상화 기술을 활용하여 M1/M2 맥에서 리눅스를 실행할 수 있습니다. 이 안내서에서는 UTM 가상 머신을 사용하여 M1/M2 맥에 리눅스를 설정하는 방법을 살펴보겠습니다.\n\nUTM이란 무엇인가요?\n\nUTM은 \"Universal Terminal Machine\"의 약자로, macOS 및 iOS용으로 설계된 오픈 소스 가상화 도구입니다. 이 도구를 사용하면 M1 및 M2 맥을 비롯한 Apple Silicon 기기에서 가상 머신을 실행할 수 있습니다. UTM을 사용하면 리눅스 배포본, Windows 등 다양한 운영 체제를 에뮬레이트할 수 있습니다. Mac 용 UTM 앱은 공식 UTM 다운로드 링크에서 다운로드할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nM1/M2 Mac에 Linux 설치하기:\n\nUTM을 이용하여 Linux를 설치하는 방법에 대한 단계별 안내서입니다. 모든 단계에 대한 사진을 포함하려고 해서 길어 보이지만 이 안내서를 따라 M1/M2 Mac에 Linux를 설치할 수 있습니다:\n\n- UTM 다운로드 및 설치:\n\n- 위의 링크를 통해 UTM 앱을 다운로드하거나 Google에서 'Mac용 UTM'을 검색하여 다운로드할 수 있습니다.\n- 다운로드 후 DMG 파일을 열고 UTM 애플리케이션을 드래그하여 설치하기 위해 Applications 폴더로 이동하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 리눅스 디스크 이미지 얻기:\n\n- 설치하려는 리눅스 배포판을 선택합니다. 인기있는 선택지로는 우분투, 페도라, 데비안 등이 있습니다. 이 튜토리얼에서는 우분투 20.04를 설치할 것입니다.\n- 우분투 20.04 데스크톱 버전이 ARM 64용으로 공식 웹사이트에서 제거되었기 때문에, 우분투 20.04 데스크톱을 설치하기 위해 우회 방법을 사용할 것입니다.\n- 여기서 우분투 20.04 (ARM 64 버전) 서버 디스크 이미지를 다운로드합니다. 이 이미지는 서버 이미지이므로 터미널 환경만 제공됩니다. 다음 단계에서 전체 데스크톱 버전을 설치할 것입니다.\n\n3. UTM에서 새 가상 머신 생성하기:\n\n- 응용 프로그램 폴더에서 UTM을 엽니다.\n- 새 가상 머신을 생성하려면 “+” 버튼을 클릭합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_1.png\" /\u003e\n\n- \"Virtualize\" 옵션을 선택하세요. \"Virtualize\"와 \"Emulate\"의 차이점은 Virtualize는 Apple 실리콘, 즉 ARM 64 칩셋을 네이티브로 지원하는 기계를 가상화한다는 것입니다. 그래서 빠릅니다. 반면에 Emulate는 필요한 CPU 아키텍처를 가상화하여 다른 CPU 아키텍처를 실행할 수 있습니다. (진실을 말하면, Emulate를 시도해 봤는데, 너무 느려요. 만약 단순한 명령줄만 실행되는 매우 가벼운 OS가 아니라면 절대 Emulate 옵션 선택하지 말기를 권장합니다.)\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_2.png\" /\u003e\n\n- 당연히 \"Linux\"를 선택하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Install Linux Ubuntu 20.04 on M1/M2 Mac Silicon Step 3](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_3.png)\n\n- ISO 이미지에서 부팅을 선택하고 Step 2에서 다운로드한 서버 이미지를 찾아 선택하세요.\n\n![Install Linux Ubuntu 20.04 on M1/M2 Mac Silicon Step 4](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_4.png)\n\n- 이제 가상 머신에 필요한 자원을 할당하세요. 최상의 성능을 위해 시스템 자원의 절반을 가상 머신에 할당하는 것을 강력히 권장합니다. 가상 OS에서 작업하는 동안 다른 응용 프로그램을 실행하지 않고 자원을 절약하고 성능을 향상시키기 위해 노력해주세요. 그렇지 않으면 시스템이 다운될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 5](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_5.png)\n\n![Image 6](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_6.png)\n\n![Image 7](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_7.png)\n\n![Image 8](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4. 가상 머신 시작하기:\n\n- 구성이 완료되면 \"만들기\"를 클릭하여 가상 머신을 생성합니다.\n- 목록에서 새로 생성된 가상 머신을 선택하고 \"시작\"을 클릭하여 실행합니다.\n\n5. Linux 설치하기:\n\n- 가상 머신은 Linux ISO 이미지에서 부팅됩니다.\n- 화면 안내에 따라 가상 디스크에 Linux를 설치합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Screenshot 9](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_9.png)\n\n![Screenshot 10](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_10.png)\n\n![Screenshot 11](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_11.png)\n\nSelect the keyboard configuration and the network connection configuration.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Screenshot 1](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_12.png)\n\n만약 외부 세계 \"content😗\"에 액세스하기 위해 어떤 HTTP 프록시도 사용하고 싶지 않다면, 프록시 주소 필드를 비워 두십시오.\n\n다음 단계에서는 미러 주소를 기본 설정으로 유지하고 \"완료\"를 클릭하세요.\n다음 단계에서는 전체 디스크 옵션을 선택해 주세요.\n\n![Screenshot 2](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_13.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_14.png\" /\u003e\n\n파일 시스템은 주어진 그대로 선택하고 계속 진행하세요.\n\n이어진 단계에서 우분투 계정 프로필을 만들어 시스템에 로그인합니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_15.png\" /\u003e\n\n원한다면 다음 단계에서 오픈 SSH 서버를 사용할 수 있습니다!\n\n다음 창에서 프로젝트나 업무에 유용하거나 사용할 서버 스냅을 선택하세요. 원한다면 나중에도 설치 가능합니다!!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 1](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_16.png)\n\n이제 설치가 시작됩니다 - →\n\n![Image 2](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_17.png)\n\n완료될 때까지 기다리세요. 완료되면 기계를 다시 부팅하라는 메시지가 표시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기계를 다시 시작한 후 설치된 미디어, 즉 VM 설정에서 iso 파일을 제거하고 기계를 다시 시작하세요.\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_18.png\" /\u003e\n\n이제 Ubuntu 서버에 로그인하고 좋아하는 데스크톱 환경을 설치해 봅시다.\n\n6. 데스크톱 환경 설치:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 우분투 데스크톱 시스템(gnome 3)을 설치하려면 다음을 실행하세요:\n  $ sudo apt install ubuntu-desktop\n  또는 Gnome 3 데스크톱을 위한 전환 패키지 이름을 사용해보세요:\n  $ sudo apt install ubuntu-gnome-desktop\n  Kubuntu Plasma 데스크톱/넷북 시스템(KDE)을 설치하려면 다음을 실행하세요 (가벼우면서 부드러운 터치를 선호합니다) :\n  $ sudo apt install kubuntu-desktop\n  Lubuntu 데스크톱 환경을 원하시나요? 다음을 실행하세요:\n  $ sudo apt install lubuntu-desktop\n  Xubuntu 데스크톱 시스템을 설치하려면 다음을 실행하세요:\n  $ sudo apt install xubuntu-desktop\n\n- 데스크톱 설치 과정이 완료되면 시스템을 한 번 더 재부팅하면 됩니다. 그 후, 와우! 새로운 깨끗하고 새로운 우분투 데스크톱에 로그인하게 될 것입니다.\n\n![이미지](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_19.png)\n\n와! 이제 우분투 20.04의 완전한 데스크톱 버전을 성공적으로 설치했습니다. 이제 선호하는 우분투 패키지와 소프트웨어를 설치하고 작업에 원활히 참여할 준비가 모두 되었습니다.\n이 설명서가 맥 실리콘을 위한 우분투 20.04 설치에 도움이 되었길 바랍니다.\n\n만약 설치 중 궁금한 점이나 오류가 발생하면 shubhjain10102003@gmail.com으로 이메일을 보내주시면 감사하겠습니다! 😇.\n","ogImage":{"url":"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png"},"coverImage":"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png","tag":["Tech"],"readingTime":9},{"title":"새로운 냉전 - 인공지능","description":"","date":"2024-05-23 17:04","slug":"2024-05-23-TheNewColdWarArtificialIntelligence","content":"\n## 최신 기술전쟁 전선에서의 한 모습\n\n![이미지](/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png)\n\n# 목차\n\n- 최신 기술전쟁 전선에서의 한 모습\n- 목차\n- 2030년 중국산\n- 기술\n- 생성적 인공지능\n- 중국: 장기 계획가?\n- 중국의 함정\n- 참가 상장\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파티 참석자는 몇 년 전에 중국에 있는 유럽-미국 상공회의소(European-American Chamber of Commerce in China)로부터 초대를 받았습니다. 2박 호텔 숙박 및 식사, 대부분의 여행 경비 보상, 그리고 중국 닝보의 스마트 시티 엑스포(Expo) 부스 무료 이용이 제공되었습니다. 중국에서 사업을 하고 싶은 마음이 생겨, \"왜 안해볼까\" 생각했습니다. 중국 비즈니스의 잠재력을 탐구하는 뜻있는 노력으로 여겼기에, 계약서에 서명했습니다. 몇 주 후, 중국 동부 체장省 닝보의 중요 항구 및 산업 중심지에 자리잡을 기회를 얻게 되었습니다.\n\n최근 소설 쓰기를 위해 제2차 세계대전 시일 중국의 일본과의 전투에 대해 조사를 한 결과, 이 도시에 대해 조금 알고 있었습니다. 안타깝게도, 닝보는 제2차 세계대전 중 일본 제국군이 가장 최악의 잔혹행위를 저질렀던 장소 중 하나였습니다. 일본 전투기가 생화학 전투부대인 유닛 731에 의해 지휘된 잔혹한 생화학 전쟁 행위로 역병, 장티푸스 및 기타 질병이 퍼진 곳이었습니다.\n\n그러나 니보 리셔 국제공항 터미널의 카펫을 건너자마자 전쟁의 생각은 멀리 떠났습니다. 거기서는 자유의 여신상과 에펠탑, 런던의 빅 벤을 담은 보험사 포스터가 나를 맞았습니다. 서양의 요소를 볼 수 있어 기분이 좋았지만, 이 상징이 보는 사람 중 대부분에게 피곤한 의미로 남아있을 것이라고 생각했습니다. 미국에서는 자유, 민주주의, 희망, 기회를 상징하는 것은 자유의 여신상뿐입니다. 그러나 중국에서는 아마 자유와 같이 무겁고 깊은 의미가 담긴 상징은 아니라 생로운 상징이라고 생각했습니다.\n\n## 2030년 중국산 \"Made in China\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중국 공산당(CCP)은 14차 다섯 해계획에서 2030년까지 인공지능 우위를 차지하는 것을 목표로 세웠습니다. 하지만 그게 현실적인 목표일까요? 의심의 여지 없이, 중국은 인상적인 기술사를 가지고 있습니다. 로스 앤더슨은 자신의 ‘파노프티콘(Panopticon)은 이미 여기에 있다’라는 기사에서 중국이 글쓰기가 독자적으로 발명된 세곳 중 하나라고 언급합니다. 중국은 또한 데이터가 신속하게 이동하도록 할 수 있는 종이를 발명했으며, 이는 제국을 확고히 통치하기 위해 필요한 의사소통 수단이었습니다. 중국 스님들은 9세기경, 불멸의 엘릭시를 찾던 중 폭약을 발견했습니다. 따라서 혁신은 중국에게 전혀 낯선 개념이 아니었습니다.\n\n중국의 기술사로부터의 진행은 오늘날 기술에 이어집니다. 현재 세계의 이메일 통신(우리의 현대적인 글쓰기 시스템) 대부분을 거래하는 컴퓨터는 중국에서 생산되었습니다. 시작은 서구에서 이루어졌지만, 중국이 현재 대부분의 컴퓨터를 대량생산하고 있습니다. 중국은 단연코 \"세계의 공장\"이라 불리는 것이 타당한 이유가 있습니다.\n\n## 기술\n\n로봇공학\n로버트 D. 애킨슨은 그의 '중국 제조업체는 미국 제조업체보다 임금을 고려할 때 12배 많은 로봇을 사용합니다.'라는 기사에서 \"2021년, 중국은 미국보다 제조업 종사자 당 로봇을 18% 더 설치했습니다. 중국 제조업 임금이 미국 임금보다 상당히 낮았다는 점을 감안할 때, 중국은 미국보다 제조업에서 12배 더 많은 로봇을 사용했습니다.\"라고 보고합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"그러나 시장 요인이 아닌 Atkinson의 말에 따르면, 이는 정부 정책 때문입니다. 제조업 로봇 도입은 중국 공산당의 최우선 과제이며 관대한 보조금으로 후원하고 있다고 덧붙였습니다. 이는 로봇 도입을 지원하거나 자금을 지원하지 않는 미국 정부의 정책과는 대조적입니다.\n\n로보틱스 기술은 닝보에서 잘 대표되었습니다. ZTE는 참석자들 가운데 어린이들의 상상력을 자극한 5G 로봇 능력을 선보였습니다. \"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로봇 개를 만드는 로보틱스 회사(그림 4 참조)가 최신 기술을 선보였어요. 사실을 말하자면, 보스턴 사이언티픽에서 몇 년 전에 본 것과 의심스럽게 비슷했어요.\n\n![로봇 개](https://miro.medium.com/v2/resize:fit:1400/1*pxBUVkAdzZqrYOZYsxAdhQ.gif)\n\n중국의 로봇산업이 인상적으로 보이긴 하지만, 산업용 로봇의 최대 채용국은 아닙니다. Atkinson에 따르면 \"한국이 세계에서 가장 많은 산업용 로봇을 채용한 나라로, 제조업 종사자 10,000명 당 1,000대의 로봇을 보유하고 있었고, 싱가포르가 그 다음으로, 670대를 보유한 나라로 뒤를 잇고 있으며, 일본과 독일이 거의 400대를 보유하고 있어요. 미국은 종사자 10,000명 당 274대의 로봇을 보유하고 있는 반면, 중국은 322대를 가지고 있습니다.\"\n\n내가 본 것은 인상적이었지만, 중국은 로봇 분야에서 한국과 싱가포르에 따라잡기에는 아직 멀은 길을 가고 있어요. 독일은 고품질 복잡한 로봇 제공업체로도 선두입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGeely는 전시장 외부 주차장에 서있는 자사 모델 중 하나를 운전할 수 있는 차 시뮬레이터를 제공했습니다. 차 안의 운전자는 발이 묶이는 듯하면 브레이크를 밟을 준비를 하고 있었어요 (그림 5 및 6).\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*5DnflsdScg7TvhsaHzpcvA.gif)\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*vN0WUdnmia1Ujan-SO_LWw.gif)\n\n스마트 시티\n스마트 시티 기술은 정보 및 통신 기술을 활용하여 운영 효율성을 개선하고 공공과 정보를 공유하며 주민들에게 더 나은 삶의 질을 제공하는 것을 의미합니다. 다양한 디지털 솔루션을 통합하여 더 나은 결정을 내리고 도시 생활을 향상시키는 것을 포함하고 있습니다. 주요 구성 요소는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터를 수집하고 분석하는 IoT 장치 통합, 이를 통해 인프라, 공공 시설 및/또는 서비스 개선을 위해 활용합니다.\n- 더 최적화된 에너지 관리를 가능하게 하는 스마트 유틸리티 미터.\n- 인텔리전트한 도시 이동 및 교통망, 스마트 트래픽 라이트, 스마트 주차 등을 포함한 스마트 이동 및 교통, 모든 것은 교통 시스템의 효율성과 지속 가능성을 향상시키기 위한 것입니다.\n- AI 기반 교통 관리 시스템: IoT 장치를 AI 기반 교통 관리 시스템과 통합하면 혼잡을 크게 줄이고 대중교통 효율을 최적화하며 온실 가스 배출량을 줄일 수 있습니다.\n\n중국 정부는 알리바바에게 나라의 스마트 시티 기술을 구축하도록 지시했습니다. 이를 회사는 \"시티 브레인\"이라고 부릅니다. 로스 앤더슨에 의하면, 시티 브레인은 \"도시 환경 전체에 분산된 다양한 센서들로부터의 데이터 스트림을 종합하는 자동화된 신경 센터\"입니다.\n\n앤더슨은 조금 디스토피아적이라고 설명합니다. \"시티 브레인은 잃어버린 어린이나 관광객 또는 테러리스트가 방치한 수화물을 발견하도록 훈련될 수 있습니다. 방황하는 사람들이나 거리에 머묾거나 무정부상태로 있거나 폭력 분자를 신고할 수 있습니다.\" 위험에 처한 사람들은 \"항상 경비 미쳐 탐지될 수 있는 독특한 방식으로 손을 흔들어 도움을 요청할 수 있을 것\"이라고 앤더슨이 덧붙입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_3.png)\n\n공정하게 말하자면, 디스토피아는 중국 해안에서 끝나는 것이 아닙니다. 중국의 타이위안은 인구 1,000명당 117개의 카메라로 세계에서 가장 감시를 많이 받는 도시 중 하나일 수 있지만, 런던도 멀지 않습니다. 인구 1,000명당 73개의 카메라를 가지고 있어 세계 순위에서 세 번째에 위치하고 있습니다.\n\n소위 헌법 제4조 권리도 일반 미국인을 충분히 보호해주지 못할 수도 있습니다. 안데르센은 \"미국의 경찰 부서들이 애매한 점에 있다면 아마존의 홈 보안 카메라 영상을 이용하기 시작했다\"고 언급합니다. 따라서 많은 미국인이 당연하게 가지고 있는 비합리적 검색받지 않음의 권리가 허약해지고 있을 수도 있습니다.\n\n중국은 자국 국민에게 이 모니터링 기술을 사용함과 동시에 세계 최대의 AI 기반 감시 장비 공급 업체가 되었다고 안데르센은 말합니다. 말레이시아에서는 알리바바의 시티 브레인 플랫폼과 같이 쿠알라룸푸르 경찰서에 얼굴 인식 기술을 도입하고 있습니다. 싱가포르의 11만 개의 가로등은 안데르센이 보고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 생성적 AI\n\n오픈AI가 2021년에 ChatGPT를 출시하자, \"생성적 AI\"가 즉시 주목을 받았습니다. 대중들에게 상상력뿐만 아니라 심장과 마음까지 사로잡아, 다운로드 현상이 됐죠.\n\nDall-E, Stable Diffusion, Midjourney와 같은 텍스트 대 이미지 솔루션이 ChatGPT를 빠르게 따랐습니다. 이 도구들은 사용자에게 간단한 텍스트 프롬프트로부터 즉시 사실적인 이미지를 빠르게 생성할 수 있는 놀라운 기술임을 입증했습니다.\n\nCNBC의 Arjun Kharpa에 따르면, ChatGPT 출시 후 몇 달 뒤에는 중국 기술 거물인 알리바바, 바이두, JD.com, 넷이스가 유사한 제품을 출시할 의향을 밝혔다고 합니다. 하지만 그들이 진짜로 할 수 있을까요? \"중국 기술 기업들은 새로운 규제 상황에 적응해야 하며, 그들의 ChatGPT 응답에 대한 발표가 조심스러웠던 것은 이 현실을 반영한 것입니다,\" Kharpal은 보도했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기업들은 포괄적이고 창의적인 AI 플랫폼을 개발하고 있지 않습니다. 이는 베이징의 인터넷 검열 기관들에 문제를 일으킵니다. 그 대신, 알리바바와 넷이즈는 해당 기술을 응용 프로그램 특정 용어로 이야기하고 있다고 Kharpal이 말합니다. 이러한 기업들이 창의적인 AI 분야를 지배할 수는 없습니다. 하지만, 그들이 가진 선택사항은 무엇인가요? 그들은 모든 종류의 정보에 자유롭고 공정한 접근이 필요한 해당 기술에 대한 수준에서 경쟁하기가 어렵습니다. ChatGPT 및 Perplexity와 같은 미국 기업들에 한 점!\n\n\"작년 동안 다양한 정부 기관들에 의해 기술 플랫폼과 AI 알고리즘에 대한 규제에 대한 관심이 집중되었는데, 주요 기술 플랫폼들은 논쟁에 휩쓸리는 채팅 봇/창작 AI 도구를 내놓음으로써 주목을 받고 싶어하지 않습니다,\" 컨설팅 회사 Albright Stonebridge의 기술 정책 담당자인 폴 트리올로는 CNBC에 말했습니다. 지난 몇 년 동안 이러한 기업들은 규제의 엄중한 시험을 받았습니다. 그러나 이는 또한 중국이 세계를 강탄할 혁명적 제품을 만드는 것이 얼마나 어려울지를 보여주는 사례입니다.\n\n# 중국: 장기 계획가?\n\n서양에서 널리 퍼진 중국 비즈니스에 대한 맥시엄이 있습니다. 그것은 중국이 장기적으로 플레이하고 있는 반면 서양 기업들은 목요일 이후를 생각하지 못한다는 것입니다. 이는 매우 잘못된 견해입니다. 세계에서 상위 10곳의 기업 중 9곳은 미국 기업입니다(Saudi Arabia의 Aramco는 그 목록에서 유일한 미국 외 기업입니다). 이들 기업이 그 목록에 올라간 이유는 단기적인 사고를 한 것이 아니라, 그들의 예측 능력이 최고라는 것입니다. 오늘날의 많은 기업의 성공에 큰 역할을 하는 소프트웨어 분석 사업은 미국, 유럽, 일본 전역에 흩어진 칩 제조업체, 소프트웨어 개발자 및 대학 연구소에서 시작되었지만 대부분 미국에서 시작되었습니다. 인터넷은 미국에서 발명되었으며, 실리콘 칩도 그랬습니다. 미국은 AI 및 양자 컴퓨팅 분야에서 선두를 달리고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n미국과 비교했을 때 중국은 독립적인 사법부, 강력한 기업 지적재산권 보호, 정치적 비즈니스 접근 방식, 그리고 다가오는 분기 보고서만 고려하는 혁신적인 마인드에서 부족한 면이 있습니다. 이러한 것들은 장기적인 비즈니스 성공을 위해 필요한 중요한 기반 요소입니다.\n\n중국에서는 정부 규제가 갑자기 나타날 수 있습니다. 기업들은 이제 사업과 관련된 경험이 거의 없는 정부 관료를 이사로 임명받아야 하는 상황이 발생하고 있습니다. 중국은 강력한 창업 생태계가 부족합니다. 기업들은 서양에서처럼 잠재적인 사업 기회를 탐색할 여지를 거의 제공받지 못합니다.\n\n과거에는 실리콘밸리의 벤처 자본가들이 많은 중국 스타트업에 자금을 지원해왔지만, 현재 그 자금은 말라가고 있습니다. 그 자금은 현재 미국, 유럽, 심지어 일부 아시아 기업들로 재투자되고 있습니다. 중국은 대만만만 베이 에어리어(심천, 홍콩, 마카오로 구성)를 구축하고 있을 수 있지만, 실리콘밸리의 벤처 자본가들을 대체할 벤처 공산주의자는 나타나지 않을 것입니다.\n\n지적 재산권을 훔치는 것은 빠른 단기적인 재정 이득을 제공할 수 있지만, 실질적인 연구 및 개발에 투자하는 것이 훨씬 더 장기적인 전략입니다. Cyfirma의 중국 지적 재산권 도난 보고서에 따르면 \"지적 재산권 도난은 중국이 경쟁 국가들의 기업들을 대체하기 위해 사용하는 더 큰 산업 전략의 일부입니다. 미국 기업들만 하더라도 지적 재산권 도난으로 매년 4분의 1에서 5분의 1조 달러의 손실이 발생합니다.\" 보고서는 또한 \"중국 기업들이 자주 지적 재산권 보호를 무시하며, 국가 전반적으로 외국 기업, 주로 서양(그리고 점점 더 아시아) 기업들로부터 지적 재산권을 빼앗기 위한 정책들을 오랜 기간 도입해왔다\"고 덧붙였습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n조지 매그너스는 그의 기사인 중국 경제: 카산드라 vs. 폴리안나에서 중국 경제의 문제로 \"지방 정부, 국영 기업 및 부동산의 과도한 부채, 소비 부족, 과도한 투자 및 자본 분배 부정, 인구 통계의 고속 노화의 결과, 생산성 성장의 약세, 더 많은 통제와 억압적인 지배, 민영 기업 및 기업가들의 지배, 그리고 최근에는 상업 및 비즈니스 분리, 이제 위험 감소로 재브랜딩된 것들을 이 논의합니다.\" 이것들은 사소한 문제가 아닙니다.\n\n중국의 경제적 상황이 너무 심각해져서, 이제 경제가 파괴된 것이 아니냐는 질문이 아닌 누가 이 일을 일으켰는지에 관한 문제입니다. 외교문제지에서 피터슨 연구소의 아담 포센은 중국의 최근 \"고 코로나 정책과 국가 통제로 인해 민간 기업과 기업가들의 신뢰가 저해되어 중국 경제의 활력을 저해시켰다\"고 주장합니다.\n\n그러나 외교위원회의 존유안 리우와 평가대학의 마이클 페티스는 상황을 다르게 보고 있습니다. 그들은 중국의 경제적 문제는 코로나 이전부터 시작되었으며, 중국은 10년 이상 시스템적으로 결함이 있는 경제 발전 모델을 가지고 있었다고 말합니다.\n\n모두 동의하는 점은 중국의 문제들이 쌓여 있다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 자녀 정책은 역사적으로 중요한 인구 틱택 타임봄으로 터져나가고 있습니다. 세계사에서 어떤 나라보다도 중국에서 노인 인구가 더 많아지고 있습니다. 사회 안전망이 부족한 나라에서 이는 매우 우려스럽습니다.\n\n\"누워서 먹고 살기\"와 \"그냥 말리기\" 운동, 젊은이들이 여기저기로 야심을 내어 밀어붙이는 것 같은 동작은 최근 대학 졸업생들이 자녀를 갖는 욕망을 줄이고 있습니다. 그래서 다음 세대에 도움이 되지 않습니다.\n\n2021년, 정부는 급성장하던 온라인 과외 산업을 거의 순식간에 없애버렸습니다. 우연의 법칙의 또 다른 사례로, 과도한 등록금 때문에 중국인들이 자녀를 낳기를 꺼려한다는 우려로, 정부의 권위적 조치로 과외 시장이 붕괴될 수도 있었습니다. 이는 물론 과외를 더 비싸지게 만들었습니다.\n\n2023년 12월 22일, 정부가 게임 산업에 새로운 규정을 도입하여 플레이어가 인게임 구매에 얼마나 돈을 쓸 수 있는지 제한했습니다. 이 조치는 게임 개발사의 수익을 강타하여 800억 달러의 주식시장 폭락을 초래했습니다. 우연의 법칙이 다시 한 번 끔찍한 모습을 드러냈습니다. 하루 후에 중국 국가출판방송총국은 손을 뒤로 젔지만 이미 피해는 입혔습니다. 시장이 가장 혐오하는 것은 침범적인 정부보다는 우유부단한 정부일 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중국은 외국 투자가 절실한 상황이지만, 투자자들을 위협하는 불투명한 법률을 제정하고 있습니다. 중국이 외국 자본을 절실하게 원하는 이유가 있습니다. 중국인들은 자국 주식 시장에 투자하지 않습니다. 중국 기업의 재무제표가 적어도 의심스러우며, 사실상 부정확하다는 것을 알고 있습니다. 투자자와 비즈니스 커뮤니티 간에 신뢰가 없습니다. 코로나 이전 중국 전역에서 빠르게 성장하던 커피 회사 럭킨 커피는 추후 머디 워터스 단기매도자들 보고서에 걸려, 나는 닝보에서 돌아온 몇 달 후, 약 $310 백만 달러를 조작했다고 알려진 소송에 1억 7500만 달러로 청산했습니다.\n\n“사막에 공산당원을 일시킨다면 모래도 바닥난다,”는 농담은 중국이 직면하는 모든 해결할 수 있는 문제들을 생각할 때 참된 말임을 보여줍니다. 왜 14억 명의 정부가 개발자들이 30억 명분의 주택을 건설하도록 허용하겠습니까? 왜 중국은 송장 도시를 채우는 수백만 개의 빈 집을 가지고 있을 뿐만 아니라 세계에서 유일한 고스트 크레이퍼인 골든 파이낸스 117을 갖고 있습니까?\n\n## 중국 함정\n\n야망과 열망은 쉽게 표현할 수 있지만, 건강한 통치와 견고하고 유연한 기관에 의존한 상황에서 실현하기는 엄청나게 어렵다고 말합니다. 다시 말해, 말은 쉽지만 실행은 굉장히 어렵다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n혹은 안 좋아하더라도, 현대 중국은 언제나 80년대와 90년대 일본과 비교될 것입니다. 많은 사람들이 알고 있는 기업 이름을 가졌다고 해서 반드시 지속적인 성공으로 이어지는 것은 아니라고 말하는 Magnus의 주장입니다. 알리바바, 텐센트, 그리고 바이두는 단지 소니, 토요타, 히타치, 미쓰비시의 중국 버전일 뿐입니다. 확실히 좋은 기업들이지만, 애플, 구글, 페이스북, 또는 마이크로소프트가 너무 걱정해야 할 상대는 아닙니다.\n\n몇십 년 전, 미국 리더들은 일본 conglomerates이 그들을 이기는 비경쟁력으로 두려워했습니다. 그러나 Magnus가 가리키듯이, \"세계적인 기술 기업을 갖는다고 해서 일본 경제의 주춧돌인 시스템적 거시경제 문제에 대한 보호가 보장되는 것은 아니었습니다. 바로 그 이후에 일본 경제가 발목을 잡힌 것입니다.\" 중국 기업들도 오늘날의 고마진 기술을 제조하기 위해 필요한 정교한 칩이 제공되지 않는 한 비슷한 위기에 직면할 수 있습니다.\n\nMagnus는 \"현대 중국이 1980년대와 1990년대의 일본의 틀에 완벽하게 들어맞지는 않지만, 중국의 인구 1인당 소득은 미국의 20% 미만입니다; 1990년대 초의 일본은 1.5배 더 크었습니다. 둘 다 \"높은 부채, 과대평가된 부동산, 자본 분배의 잘못, 고령화, 그리고 개혁을 위한 기관적 또는 정치적 장벽\" 등의 경제 모델은 매우 유사해 보입니다,\"라고 말합니다. Magnu는 경고합니다. 중국의 부동산 거품은 일본 시기만큼 강하게 충실히 늘어선 것이 아니라, 기업 부채가 작고 정부가 경제를 조절하는 데 사용할 도구가 더 많지만, 중국이 디플레이션과의 싸움을 벌이는 동안 일본화의 위험이 높아진다는 Magnus의 경고입니다.\n\n\"중국의 GDP가 미국을 넘어서기 위한 창문이 거의 닫혔습니다. 그 격차는 실제로 넓어질 수 있으며, 2023년 처음으로 30년만에 그렇게 된 것처럼,\"며 Magnus가 말합니다. 중국 경제에 대한 이러한 비관적 평가는 현재의 중국 감시자들 사이에서 흔한 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n“투자자들이 대부분의 중국 주식 시장을 포기했고, 외국 기업들은 투자와 생산을 아시아를 넘어 다른 국가로 다변화하는 추세에 있다”고 Magnus가 지적했다. 중국 경제는 급격히 사라지기엔 너무 크지만, 평평해지고 있는 것으로 보인다.\n\nMagnus는 “한 나라의 안보는 중장기 경제 전망만큼 안전하다. 이들은 몇 십 년 동안 한 것보다 취약한 상태이다. 발전 모델을 철저히 재시동하지 않는 한, 중국이 두려워하는 중간소득 함정이 점점 가까워지고 있다”고 경고했다.\n\n오늘날 중국과 미국은 경제적으로 정반대편에 있는 것으로 보인다. 미국 시장은 거의 매일 새로운 최고점을 경신했으며(일본도 마찬가지), 한편으로 중국 주식 시장은 10년 최저점으로 떨어졌다. 홍콩 항셍지수는 영국이 식민지로 돌려준 때보다 낮은 수준으로 하락했다. 이것이 현재 홍콩과 중국의 경제 상황에 대해 많은 양을 이야기한다면, 아무 것도 듣기 않은 것이다. 그러나 주식 시장은 늘 선두적인 경제 지표로 여겨졌다. 두 경제에 대해 지금 어떤 것을 보고 있는지 궁금해진다.\n\n## 참여상”\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금까지 나의 스마트 시티 탐험상(참가자 트로피로도 불리는 (그림 10 참조))은 몇 년 전에 리즈 여행을 상기시키는 나의 아파트 선반 위에 있습니다. 서서히 서부인 참가자들이 이벤트에 참석하기를 갈망하다 보니 비용을 부담해주고 재미있는 상품도 공식식으로 수여되는 것을 생각해볼 때 정말로 값진 경험이었습니다!\n\n중국은 2019년 9월 코로나 바이러스가 확산되기 2개월 전, 그 후에는 전 세계적으로 유행이 급격히 확산되기 시작함으로써 극적으로 변화했습니다. 당시에 만난 몇 명의 연락처는 소식을 들을 수 없게 되었습니다. 그래도 Ningbo 스마트 시티 여행은 일자리 발견으로 이어지지 않았지만 눈을 떴게 해주는 경험이었습니다.\n\n지금의 복잡한 기술 세계에서 중국이 경쟁할 수 있을까요? 물론 가능합니다. 중국은 몇 가지를 올바르게 진행하고 있습니까? 물론 그렇습니다. 그러나 중국의 기업 문화에는 미래의 AI 전쟁에서 승리하는 데 도움이 되지 않는 어떤 점이 제한적으로 존재한다고 생각합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프랑스 황제가 되기 전 나폴레옹은 중국 지도를 가리키며 말했습니다. \"여기 잠자고 있는 사자가 있다. 그를 자도하라. 그가 깨어날 때 세계를 흔들 것이다.\" 나폴레옹은 두 세기 전에 이 말을 했고, 그 이후로 중국은 많은 나라들보다 격동한 시기를 보냈습니다. 중국 19세기는 식민 지배, 아편전쟁, 그리고 백년굴이 가득 찼습니다. 20세기는 일본 제국주의 지배, 잔인한 내전, 그리고 모든 것을 흔들어놓은 공산주의 전환으로 이어졌는데, 이는 기근과 수백만 명의 사망을 야기했습니다.\n\n오늘날 중국은 미국과 경제적 우월을 다툴만큼 준비되어 있지 않습니다. 그녀는 풍부하고 민첩한 나라조차 극복하기 어려울만한 많은 도전에 직면하고 있습니다.\n\n피낭당을 빠져나가는 비행기에서 난 닝보의 하늘을 바라보면서, 청 일본 폭격기가 닝보에 온천기로 오염된 벼루병 살충제를 투하하려던 그 시절을 상상했습니다. 일본은 바이오 및 화학 무기를 금지하는 제네바 협약에 조인하지 않았기 때문에, 이별하여 민간인 수천 명을 살해하는 것을 제한하는 요소가 없었습니다. 실제로 기도 경계와 생화학 무기를 개발하고 중국 민간인을 살해했다. 명백히 도덕은 선량한 이들을 살해하는 데에 강력한 금지 요인이 되지 않았습니다.\n\n안더슨에게 중국의 AI 우월에 대한 상승은 위협적인 가능성입니다: 중국의 정치 구조는 기술의 최악의 잠재력을 자극시키기보다 제한하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중국은 이제 더 이상 다른 사람들의 기술을 그대로 복사하고 표절하고 위조하는 나라가 아닙니다. 그것은 자체적으로 혁신의 세력이 되었지만, 중국 지도자로서 미국을 최초의 방문지로 선택한 이유에 대해 질문 받았을 때 덩샤오핑의 말을 기억했으면 좋겠습니다. \"미국의 동맹국들은 모두 부유하고 강하며, 중국이 부유하고 강하고 싶다면 미국이 필요했다\"고 그가 대답했습니다. 이것은 우리 모두가 많은 것을 배울 수 있는 교훈입니다. 인공지능이 우리가 많은 사람들이 우려하는 대로 잘못되면, 인류는 모든 친구를 필요로할 것입니다.\n\n독자 여러분, 읽어주셔서 감사합니다. 그리고 이 쇼에서 가장 어린 참가자 중 한 명의 작별 조언 (네, 보통이란 지겨움):\n\n![The New Cold War: Artificial Intelligence](/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_5.png)\n\n그레이 에어리어는 훌륭한 사이버 보안 및 컴퓨터 과학 게시물들의 모음입니다. 그레이 에어리어의 작가가 되고 싶다면 이 양식을 작성해보세요! 그레이 에어리어가 기사를 발행할 때마다 업데이트를 받으시려면, 저희 트위터 페이지 @TGAonMedium을 확인해주세요.\n","ogImage":{"url":"/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png"},"coverImage":"/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png","tag":["Tech"],"readingTime":17},{"title":"사람형 로봇 5종 소개","description":"","date":"2024-05-23 17:03","slug":"2024-05-23-Top5HumanoidRobots","content":"\n## \"로봇에 관심을 갖는 이유는 그들이 우리 자신의 반영이기 때문입니다.\"\n\n인간 형상의 로봇은 인간과 비슷합니다. 이 로봇들은 몸통, 머리, 두 팔, 그리고 두 다리를 가지고 있지만 일부는 상체만을 가지고 있는 경우도 있고 얼굴에 눈과 입이 있는 로봇들도 있어 더 사람과 비슷하게 보입니다.\n\n![로봇 이미지](/assets/img/2024-05-23-Top5HumanoidRobots_0.png)\n\n인간 형상의 로봇이라는 아이디어는 오랜 기간동안 여러 문화에서 나타났습니다. 가장 초기 언급 중 일부는 기원전 4세기에 그리스 신화와 중국의 오래된 텍스트에서 찾아볼 수 있습니다. 이후 중국, 그리스, 이탈리아, 일본, 프랑스 등 여러 곳에서 실제 인간 형상의 로봇 프로토타입이 만들어졌습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n오늘날의 인간형 로봇은 다양한 모양과 크기로 다양하며 많은 분야에서 널리 사용됩니다. 이들은 연구, 우주 탐사, 개인 보조, 간병, 교육, 엔터테인먼트, 수색 및 구조, 제조, 유지보수, 홍보, 특히 의료 분야에서 도움을 줍니다.\n\n이들 목적으로 디자인된 인간형 로봇 중 일부 예시를 소개합니다.\n\n## 1. 핸슨 로보틱스의 소피아\n\n소피아는 핸슨 로보틱스에서 만든 잘 알려진 인간형 로봇으로, 첫 번째 여성형 인간형 로봇입니다. 그녀는 세계를 여행하며, 코스모폴리탄 매거진 표지에 등장하며, 심지어 유엔에 연설도 했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nhttps://www.youtube.com/shorts/-tb5OoNu1-4\n\n소피아는 시각적, 감정적, 그리고 대화형 데이터를 처리하여 사람들과 더 잘 상호작용할 수 있습니다.\n\n그녀는 미국의 '투바이트 쇼'에 여러 번 출연하여 짐미 팰런(Jimmy Fallon)과 가위바위보 대결을 벌였고, 나쵸 치즈에 대한 생각을 공유하며 듀엣을 부르기도 했습니다.\n\n![이미지](/assets/img/2024-05-23-Top5HumanoidRobots_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n소피아는 우리가 인공지능의 미래에 걸친 희망의 대사로서 본다. 또한 Engineered Arts가 개발한 Ameca는 인공지능 연구 및 인간-로봇 상호작용 탐구의 도구로 사용되는 고급 인공지능 연구용 로봇입니다.\n\n## 2. 엔지니어드 아츠의 Ameca\n\n![이미지](/assets/img/2024-05-23-Top5HumanoidRobots_2.png)\n\n엔지니어드 아츠가 설립된 영국 콘월의 Ameca는 AI 및 기계학습을 테스트하는 플랫폼으로 설계된 최첨단 휴머노이드 로봇입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n방 안의 움직임을 추적하고 얼굴과 목소리를 인식할 수 있는 센서를 갖고 있어요.\n\n[링크](https://youtube.com/shorts/Hx_8hRLgFYo?si=QJmZCDF0E3irTda-)\n\n알른은 사람들과 자연스럽게 상호 작용하며 그들의 감정을 감지합니다. 또한 웃음, 놀라움, 놀라움 등과 같은 일반적인 표현을 보여 줄 수 있고, 몸짓으로는 으쓱거리기, 따라하기, 하품 등을 할 수 있어요.\n\n## 3. Aura at Sphere\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n라스베이거스에있는 스피어(Sphere) 로비에서 떠들어 대는 여성 인간형 로봇인 오라(Aura)를 소개합니다. 그녀는 행사 장소의 대변으로 활동하며 손님들과 상호 작용하며 '스피어(Sphere)' 체험의 중요한 부분입니다.\n\n![image](/assets/img/2024-05-23-Top5HumanoidRobots_3.png)\n\n오라는 파란 눈을 가진 완전히 밀린 머리를 하고 있습니다. 그녀는 키 약 6피트로 아메카(Ameca)와 매우 비슷해 보입니다.\n\n오라는 놀라운 손 제스처를 사용하며 이는 완벽하게 표현된 얼굴 표정과 조화를 이룹니다. 그러나 정말 사람들의 주목을 끄는 것은 그녀의 로봇 손입니다. 손목, 손가락 및 팔의 부드러운 움직임은 여러분을 경탄하게 만들 것입니다. 이 능력은 정말로 영감을 줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nhttps://youtube.com/shorts/dTfEgteIBwI?si=Xg3ZboWli_-f-Ciq\n\nAura는 모든 이런 물리적 기적에도 불구하고 발을 움직이지 않고 제자리에 서 있습니다.\n\n## 4. 중국과학기술대학의 지아 지아\n\n지아 지아는 중국과학기술대학이 만든 인간형 로봇으로, 익숙함과 기이함 사이의 가늘고 위축된 선을 걷고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-23-Top5HumanoidRobots_4.png](/assets/img/2024-05-23-Top5HumanoidRobots_4.png)\n\n약 4.6피트(약 1.4m) 높이로 관절을 가진 상체를 가지고 있는 Jia Jia는 걷고, 말하며, 기본적인 감정을 표현할 수 있습니다. 그녀는 눈을 자유롭게 움직이며, 입술 움직임은 말에 거의 완벽하게 동기화되어 있습니다.\n\nJia Jia는 직접 인간과 상호작용할 수 있어 질문에 답하고, 작은 표정을 표현할 수 있습니다.\n\n## 5. 지능로봇실험실(Erica by The Intelligent Robotics Laboratory, Osaka University)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n에리카는 오사카 대학 인공 지능 로봇 연구소 소장 인 이시구로 히로시가 만든, 23세 여성을 닮은 사실적인 안드로이드입니다.\n\n[에리카 데모 비디오](https://youtube.com/shorts/wR1s1Mr_7oo?si=MrdP1PX-vWwsTrAZ)\n\n에리카는 인간 뉴스 앵커를 대신해서 방송에 출연할 예정입니다. 그녀는 스크립트된 글을 낭송하고 의자에 앉을 수 있어 텔레비전에 적합합니다.\n\n에리카는 사람들과 대화할 수 있는데, 그녀가 이룰 수 있는 것은 대화를 이끌어내는 알고리즘, 얼굴 인식 기술 및 적외선 센서 덕분에 에리카는 방 안의 얼굴을 추적할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아직 그녀는 팔을 움직일 수는 없지만, 에리카는 얼굴 특징, 목, 어깨 및 허리를 독립적으로 움직일 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-Top5HumanoidRobots_5.png)\n\n✍ 이러한 인간형 로봇이 미래에 좋다고 생각하시나요, 그렇지 않나요?\n\n참고: 인간형 로봇이 더욱 사람처럼 보이도록 만들어질 때, 그것들은 안드로이드로 불립니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n의견을 남겨주세요. 궁금해요.\n\n만약 이 글을 좋아하시고 저를 지원하고 싶으시다면, 아래 사항을 확인해주세요:\n\n👏 이 글에 클랩을 많이 눌러주셔서 이 글이 주목받을 수 있도록 도와주세요\n\n🔔 더 많은 인간적인 글을 보시려면 저를 Medium에서 팔로우해주세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n🔔Instagram에서 제 계정을 팔로우해주세요! instagram.com/coolbot369\n\n🔔동영상 시청하고 구독하기🔗www.youtube.com/@CoolBot369\n","ogImage":{"url":"/assets/img/2024-05-23-Top5HumanoidRobots_0.png"},"coverImage":"/assets/img/2024-05-23-Top5HumanoidRobots_0.png","tag":["Tech"],"readingTime":7},{"title":"라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요","description":"","date":"2024-05-23 17:00","slug":"2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted","content":"\n![Raspberry Pi Mastodon Instance](/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png)\n\n얼마 전에 나는 라즈베리 파이에 나만의 Mastodon 인스턴스를 설정했어. 왜냐하면? 음, 나는 인터넷에서 기본 통신 인프라를 되찾는 것이 중요하다고 생각하기 때문이야. 게다가, 거대한 분산 네트워크에서 자신의 소셜 미디어 노드를 설정하는 것은 백엔드 아키텍처에 대해 배울 수 있는 좋은 기회야. 좋은 소식은, 상대적으로 쉽고 보람있어! 지난해 4월에 파이를 설정한 후, 전혀 신경 쓸 일이 없었어.\n\n하지만, 물론, 문제가 발생하기도 해. 그리고 여기서 이야기하고 싶은 것이 바로 그거야. 당신이 자체 호스팅된 인스턴스가 고장났을 때 어떻게 되는지, 다시 가동하는 것이 얼마나 어려운지에 대해 이야기할 거야. 이 기사에서는 나의 경험을 공유하고 라즈베리 파이 Mastodon 인스턴스를 운영하는 데 궁금해하는 사람들을 위한 조언 몇 가지를 전할 거야. 하지만 그 전에, 내 설정에 대해 조금 언급해야 해.\n\n## 어떤 것을 사용하고 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모든 것을 직접 실행하고 있기 때문에 '클라우드' 컴퓨팅 서비스를 사용하지 않고 모든 서버 구성 요소에 대한 책임을 짊어지고 있어요. 주변에 Raspberry Pi 4 Model B(2018)가 있었는데, 표준 라우터와 독립적인 USB-C 전원 공급 장치에 연결했어요. 라우터 연결에는 이더넷 케이블 및 Pi 위치에 따라 Wi-Fi를 사용했어요. Mastodon이 사용하는 포트(80번은 HTTP, 443번은 HTTPS, 22번은 SSH)를 라우터로 포워딩하고 Raspberry Pi의 로컬 주소(터미널에서 hostname -I를 입력하여 확인)로 포트를 포워드하도록 라우터를 구성하세요. 그런 다음 도메인 이름의 DNS 설정을 사용하여 같은 포트를 라우터의 공개 IP 주소로 포워드하세요.\n\n![Raspberry Pi Image](/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_1.png)\n\nRaspberry Pi는 훌륭한 서버로 사용될 수 있어요. 이 작고 저렴한 컴퓨터는 놀랄 만큼 빠르고 8GB의 램을 갖추고 있어요. 작은 Mastodon 인스턴스에 충분하죠. 작은 친구는 주 시스템 드라이브로 32GB SD 카드(Kingston Canvas Select Plus)를 사용했어요. 이 SD 카드에 대해서는 조금 더 말씀드리겠지만, 괜찮긴 하지만 화려하거나 빠르지는 않아요. 제 운영 체제는 SD 카드에 미리 설치된 기본 Raspbian Linux에요. Mastodon을 가동하기 위해 joinmastodon.org에서 '기기 준비' 및 '소스로부터 설치' 문서를 따라했어요(그 순서대로). 상대적으로 간단했어요.\n\n## 메모리 고려하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋아요, 좀 더 깊게 메모리에 대해 알아봅시다. 당신이 Mastodon 인스턴스를 직접 호스팅해야 한다고 생각하면 중요하니까요. 여기서 기본 설정과는 달라지는 부분이 있습니다.\n\n내가 하는 것처럼 소수의 계정만 호스팅하더라도, 당신의 인스턴스는 상당량의 기가바이트 데이터를 누적하게 됩니다. 이 데이터는 한편으로는 텍스트 상태를 저장하는 PostgreSQL 데이터베이스에 (타임라인을 이루는 텍스트 상태뿐만 아니라 모든 시스템 환경 및 설정) 저장되고, 다른 한편으로는 ~/live/public/system이 기본값인 폴더에 저장됩니다 (프로필 사진, 공유 미디어 등이 이 폴더에 저장됩니다). 특히 후자의 폴더는 소셜 네트워크가 커짐에 따라 매우 부피가 커진다는 것을 상상할 수 있을 것입니다 — 어떤 사람들은 비디오를 올리는 걸 좋아하잖아요.\n\n라즈베리 파이가 메모리 부족 상태가 되는 것을 방지하기 위해, 라즈베리 파이의 USB 포트에 연결된 1테라바이트 삼성 포터블 SSD를 추가했습니다. (위의 그림에서 파이는 드라이브 위에 놓여 있습니다.) 이제 부피가 커진 /system/ 폴더가 여기에 위치하게 됩니다. 기본 설정을 재정의합니다. Mastodon이 미디어를 저장하는 위치는 ~/live/.env.production 파일에서 변경할 수 있으며, Mastodon을 위한 Nginx 구성에 별칭을 추가해야 할 수도 있습니다. 나의 경우에는 .env.production 파일에 설정하였습니다:\n\n```js\nPAPERCLIP_ROOT_PATH= /media/mastodon/system\nPAPERCLIP_ROOT_URL= /storage/system\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNginx 구성 파일에 다음 줄을 HTTP 및 HTTPS 구성에 모두 추가해주세요:\n\n```js\nlocation /storage {alias /media/mastodon; }\n```\n\n또한 외부 드라이브가 올바르게 마운트되었는지 확인하고 사용자 mastodon이 해당 드라이브에 쓸 수 있도록 해야 합니다.\n\n처음 드라이브를 추가했을 때 제 서버는 행복하게 실행되었지만 미디어 업로드를 할 때마다 500 오류가 발생했습니다 (비슷한 오류를 만나면 터미널에서 journalctl -u mastodon-web -f를 실행하여 해당 인스턴스와 주고받는 HTTP 요청의 실시간 뷰를 확인할 수 있습니다). 제 경우 문제는 소프트웨어를 실행하는 'mastodon' 사용자가 마운트된 SSD 드라이브에 쓰기 권한이 없었기 때문입니다! 업로드가 실패한 것이 당연했습니다. 이 문제를 해결하기 위해 /etc/fstab 파일(리눅스의 마운트 포인트를 정의하는 파일)에서 드라이브 항목을 수정하여 모든 사용자에게 읽기 및 쓰기 권한을 부여했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n/dev/sda1 /media vfat rw,user 0 0\n\n이 설정은 몇 번의 시행착오로부터 나왔어요; 적어도 내 시스템에는 작동합니다. 만약 내가 무언가를 형편없게나 안전하지 않게 한 것 같다면 알려주세요! 하지만 이 메모리 솔루션은 더 이상 버벅거리거나 스크롤하는 데에 한 년 이상 사용해보니 잘 작동하고 있어요.\n\n/system/ 폴더는 52.7 GB를 차지하고있어요 (~디스크 공간의 5%). 캐시된 미디어 파일을 31일 후에 지우도록 인스턴스를 구성했기 때문에 급속히 커지는 것이 아니에요. 여기에는 충분한 공간이 있어요. 반면에, 내 Postgres 데이터베이스는 여전히 기본 위치인 /var/lib/postgresql/11/main에 저장되어 있어요. (내 Postgres 버전이 11이라면서요, 잘 작동하더라구요.) 현재 Postgres 데이터베이스의 크기는 2.55 GB이에요. 이는 32 GB 시스템 드라이브의 8%에 해당하기 때문에 큰 재앙은 아니지만, 내 취향에는 너무 비대해요 (때로는 드라이브 공간이 17% 밖에 남지 않는 경우도 있었어요). 언젠가는 Postgres 데이터베이스를 외부 SSD로 이동하고 싶다고 생각해요. 그건 그때의 이야기거든요.\n\n라즈베리 파이 마스토돈 인스턴스에 추가 드라이브를 연결하는 것은 약간 복잡할 수 있고, 정확한 설정은 외부 드라이브의 파일 시스템에 따라 다를 거에요. 하지만 이렇게 하는 것은 거의 항상 좋은 생각이에요 (아래에서 설명할 이유 중 하나 때문이죠).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 하지만 백업은 하시나요?\n\n처음에 말했듯이, 잘못된 일이 벌어질 때에 대해 이야기하려고 합니다. 자체 인스턴스를 호스팅할 때는 서버가 다운될 경우를 생각해봐야 합니다. 시간이 흘러 저는 방대한 소셜 미디어 네트워크를 구축했고 거의 매일 친구들과 소통하기 위해 Mastodon을 사용합니다. 그리고 내일 그 모든 것이 여전히 남아있을 것을 누군가에게 의존할 수 없습니다. 다시 말해, 백업 계획이 없다면 인스턴스에 호스팅된 계정들과 함께 하룻밤 사이에 모든 것을 잃을 수 있습니다: 게시물, 사진 및 중요하게도 인스턴스의 사람들이 구축한 네트워크까지.\n\n따라서 Raspberry Pi Mastodon 인스턴스를 설정하기 전에 위험 평가를 수행해야 합니다. 내 구성을 고려할 때 무엇이 잘못 될 수 있는지 스스로에게 묻고, 그럴 경우 얼마나 나쁠지 고민해보고, 일이 심각하게 잘못될 때 원하는 기능을 복구하는 데 필요한 것이 무엇인지 생각해보세요. 분명히, 일부 문제에는 인내가 필요할 수도 있습니다(예: 인터넷 제공업체 문제). 그러나 다른 문제는 남아있는 것에서 서버를 복원해야 할 수도 있습니다.\n\n모든 경우들 중에서, 저는 가장 준비하고 싶었던 위험은 SD 카드의 고장이었습니다. SD 카드에서 리눅스를 실행하는 것은 SD 카드가 불안정하기 때문에 좋은 생각은 아닙니다. 그러나 어쨌든, 그것이 Raspberry Pi가 하는 일이기 때문입니다. 따라서 SD 메모리가 복구할 수 없을 정도로 고장 나서 리눅스와 Mastodon 소프트웨어를 처음부터 다시 설치해야 하는 상황이 오면 필요한 것이 무엇일까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위험을 완화하기 위해 두 가지 방안을 고안했어요.¹ 첫 번째는 이미 이야기한 것처럼, /system/ 폴더를 훨씬 신뢰할 수 있는 SSD 드라이브로 이동하는 거예요. SD 카드 고장 시에도 미디어 저장 공간이 안전하게 보호될 거예요. 좋아요. 그런데 PostgreSQL 데이터베이스는 어떨까요? 이 데이터들은 아마도 인스턴스가 구축한 소셜 네트워크를 정의하는 만큼 더 중요할 거예요.\n\n결국, 매일 데이터베이스를 자동으로 백업하기로 결정했어요. 매일 밤 실행되는 쉘 스크립트를 작성했어요 (/etc/crontab에 추가했어요). 이 스크립트는 Postgres 데이터베이스 내용(기본적으로 mastodon_production이에요)을 외부 SSD에 저장된 백업 파일로 덤프하는 거예요.\n\n이를 위해 다음 명령어를 스크립트로 작성했어요: sudo -u postgres pg_dump mastodon_production ` /media/backup/mastodon_production.dump. 추가적인 안전을 위해 파일을 gzip(암호화)하고 FTP를 통해 다른 원격 서버로 보내는 거예요. 그 서버에는 가장 최근의 .dump 파일 세 개를 유지하고, 이전 .dump 파일은 자동으로 삭제돼요. (언젠가 스크립트를 GitHub에 공유할 수도 있겠지만, 특별한 것은 아니에요.)\n\n마침내, 지난 주에 위험이 현실이 되었어요. 라즈베리 파이의 SD 카드가 고장나서 기계에 완전히 접근할 수 없었어요. 제 백업 전략은 충분했을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 백업에서 복원하기\n\n정확한 대답은: 아니요. 제 백업 전략이 충분하지 않았습니다. 그러나 운이 좋게도 충분히 가까웠습니다. 온라인으로 돌아왔고, 이것은 마스토돈 인스턴스를 복구하는 것이 어렵지 않음을 증명했습니다. 심지어 Raspbian 운영 체제와 마스토돈 소프트웨어를 처음부터 다시 설치해야 하는 경우에도요. 단지 백업 전략을 설정하기만 하면 됩니다.\n\n그래서 무엇이 있었을까요? 제 추측으로는 Pi를 잘못해서 전원을 끄면 SD 카드의 부트 섹터가 손상되었습니다. 이것은 매우 쉽게 발생합니다. 많은 사람들이 전원이 차단된 후 데이터를 잃은 적이 있습니다. 고려하지 못하고 나는 Pi를 다른 위치로 옮기기 위해 연결을 해제하고 싶을 때 데스크톱에서 '종료'를 클릭했습니다. 이후에야 작년에 스스로에게 남겨둔 안전하게 종료하는 가장 좋은 방법에 대한 메모를 읽었는데, 터미널에서 sudo shutdown -h now만 사용해야 한다는 것을 알게 되었습니다(-h 옵션은 시스템이 하고 있는 모든 일을 중단하도록 안내합니다). 우측. 어쨌든, 시스템을 부팅하지 못하게 되었고, 따라서 더 이상 마스토돈 서버를 실행할 수 없었습니다.\n\n무엇을 해야할까요? 조금 당황해서 맥에서 Ubuntu를 실행하는 VirtualBox 머신을 사용하여 카드를 외장 드라이브로 마운트하고 표준 디스크 도구와 터미널에서의 디스크 관리 프로그램 fsck로 수리하려고 노력했습니다. 운이 없었습니다. 그러나 Ubuntu에서는 /home/ 폴더를 포함하는 파티션을 마운트하고 액세스할 수 있었기 때문에 복구에 필요한 몇 가지 파일을 아직 백업하지 않은 상태로 구할 수 있었습니다. 경성.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 파일이 필요할까요? 이 질문에 대한 최상의 답변을 Mastodon 문서에서 찾았어요. '새로운 장치로 이전하기'라는 설명에서 찾았죠. 왜냐하면 Raspbian과 Mastodon 소프트웨어를 처음부터 다시 설치해야 할 때 해야 할 일이기 때문이에요. 새로운 장치를 설정하고 있는 것이거든요. 제 구성을 고려하면, 서버 기능을 간단하게 복구하기 위해 필요한 것들의 목록은 아래와 같아요:\n\n- Postgres 데이터베이스 덤프 (기본적으로 이것은 mastodon_production입니다)\n- /system/ 폴더의 복사본 (기본적으로 이것은 ~/live/public/system입니다)\n- ~/live/.env.production 파일의 복사본\n- Nginx 구성 파일의 복사본 (기본적으로 /etc/nginx/sites-available/mastodon)\n\nSD 카드가 다운됐을 때, 외부 SSD에 (1)과 (2)가 포함되어 있었어요. 이건 꼭 필요한 파일이에요. 그리고 (3)과 (4)에 대해서는, 다행히 다른 리눅스 장치에 장착했을 때 카드로부터 여전히 이 파일들을 검색할 수 있었어요.\n\n해당 추가 파일들은 제 인스턴스의 특정 구성 설정을 포함했어요. 외부 미디어 폴더를 위한 여분의 사항, 알림에 사용된 SMTP 서버의 세부사항, 활성 브라우저 세션, 이중 인증 및 푸시 알림을 위한 '비밀' 등을 포함해요. 꼭 필요한 건 아니지만, 이 파일들이 있어서 복구가 가능했던 것이죠. 이 모든 정보를 필요한대로 정확히 가지고 있어서 제 삶을 훨씬 쉽게 만들어줬어요. 큰 도움이 되었어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 긴급한 상황에서 해당 파일이 필요할 것이라는 사실은 나를 놀라게 할 필요가 없었습니다. 왜냐하면 이전에 내가 필요에 맞게 조정한 파일들이었기 때문이었습니다! 그럼에도 불구하고, 그들을 백업 루틴에 포함시키는 것을 잊었습니다.\n\n이것이 내 초기 백업 계획이 잘못된 한 가지였습니다. 하지만 적어도 똑같이 중요한 것: 필요할 때까지 백업을 테스트해보지 않았습니다. 실제 문제가 발생했을 때, 가장 중요한 백업 파일은 있음에도 불구하고 어떻게 복원해야 할지 몰랐습니다. 이로 인해 상황이 불필요하게 스트레스 받는 일이 되었습니다.\n\n나에게는 앞으로의 교훈입니다. 단순히 백업 파일을 생성했다고 만족하지 마세요. 이러한 파일을 만드는 이유인 백업 복원 프로세스의 다른 절반을 놓치지 마세요. 백업만 하는 것이 아닌, 백업으로부터 데이터를 복원하는 연습도 해보세요. 백업을 의존하기 전에 해당 백업에서 데이터를 복원하는 연습을 하세요. 그렇게 하였더라면 내 백업이 충분하지 않다는 것을 알게 되었을 것입니다. 실제 문제가 발생했을 때 무엇을 해야 하는지 알고 있다면, 상황을 훨씬 효율적으로, 더 적은 스트레스와 땀으로 복구할 수 있습니다.\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이번에는 이야기가 행복한 결말을 맞이했습니다. 이 글을 쓰는 이유 중 하나는 아마도 나중에 이와 비슷한 문제에 직면할 수도 있기 때문이고, 필요한 단계를 상기시키기 위해 매뉴얼이 있으면 유용하다고 생각하기 때문입니다. 물론 당신에게도 도움이 될 수 있기를 바라겠습니다.\n\n특히, 라즈베리 파이에 자신만의 Mastodon 인스턴스를 실행하는 것이 덜 두렵다면 고대로 해보길 희망합니다. 진정으로 말하면, 온라인 커뮤니케이션을 제어하기 위한 실험을 해볼 수 있습니다. 결국, 머신에 접근 권한을 잃는 것이 처음에 보이는 것만큼 무섭지 않습니다. 시작하기 전에 위험 평가를 수행하고, 신뢰할 수 있는 백업 루틴을 시행하고, 즉시 필요해지기 전에 백업에서 머신 복원을 실습하는 시간을 갖는다면 문제 없습니다. 이것들을 수행한다면, 작은 파이의 성능을 신뢰할 수 있을 것입니다.\n\n¹ 시도해보지 않은 대안적인 전략: SD 카드를 정기적으로 복제하는 것입니다. 복제본이 있다면 원본이 손상된 경우 카드를 교체하고 다시 사용할 수 있습니다. PostgreSQL 덤프 대비 정기적인 복제가 번거로울 것으로 생각해서 이 방법을 선택하지 않았습니다. 하지만 여기에 좋은 대안이 있는 것을 우연히 놓친 것일 수도 있습니다.\n\n² 공식 문서의 목록이 더 상세하지만, 다른 몇 가지 기본 설정을 사용했기 때문에 다른 여러 파일들에 대해 걱정할 필요가 없었습니다. 그러나 서버 사용을 시작하기 전에 '새로운 머신으로 이동' 문서를 읽고, '서버 백업' 문서를 읽는 것이 좋습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png"},"coverImage":"/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png","tag":["Tech"],"readingTime":11}],"page":"63","totalPageCount":119,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"63"},"buildId":"GsgRekSb--BvxYwv9FPn6","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>