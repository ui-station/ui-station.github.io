<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/64" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/64" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_buildManifest.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" href="/post/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="자기 주의적 문장 임베딩을 사용한 추천 시스템" href="/post/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="자기 주의적 문장 임베딩을 사용한 추천 시스템" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="자기 주의적 문장 임베딩을 사용한 추천 시스템" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">자기 주의적 문장 임베딩을 사용한 추천 시스템</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="포디즘의 새로운 모습" href="/post/2024-05-23-ThenewfaceofFordism"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="포디즘의 새로운 모습" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ThenewfaceofFordism_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="포디즘의 새로운 모습" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">포디즘의 새로운 모습</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스" href="/post/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기" href="/post/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="새로운 냉전 - 인공지능" href="/post/2024-05-23-TheNewColdWarArtificialIntelligence"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="새로운 냉전 - 인공지능" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="새로운 냉전 - 인공지능" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">새로운 냉전 - 인공지능</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="사람형 로봇 5종 소개" href="/post/2024-05-23-Top5HumanoidRobots"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="사람형 로봇 5종 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Top5HumanoidRobots_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="사람형 로봇 5종 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">사람형 로봇 5종 소개</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요" href="/post/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Splunk 인덱서로 PI 웹 로그 보내기" href="/post/2024-05-23-SendingPIWebLogstoSplunkIndexer"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Splunk 인덱서로 PI 웹 로그 보내기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Splunk 인덱서로 PI 웹 로그 보내기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Splunk 인덱서로 PI 웹 로그 보내기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="로컬 LLM 및 다양한 시스템에서 VLM 실행 시 처리량 성능 비교" href="/post/2024-05-23-ComparingThroughputPerformanceofRunningLocalLLMsandVLMondifferentsystems"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="로컬 LLM 및 다양한 시스템에서 VLM 실행 시 처리량 성능 비교" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ComparingThroughputPerformanceofRunningLocalLLMsandVLMondifferentsystems_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="로컬 LLM 및 다양한 시스템에서 VLM 실행 시 처리량 성능 비교" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">로컬 LLM 및 다양한 시스템에서 VLM 실행 시 처리량 성능 비교</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/61">61</a><a class="link" href="/posts/62">62</a><a class="link" href="/posts/63">63</a><a class="link posts_-active__YVJEi" href="/posts/64">64</a><a class="link" href="/posts/65">65</a><a class="link" href="/posts/66">66</a><a class="link" href="/posts/67">67</a><a class="link" href="/posts/68">68</a><a class="link" href="/posts/69">69</a><a class="link" href="/posts/70">70</a><a class="link" href="/posts/71">71</a><a class="link" href="/posts/72">72</a><a class="link" href="/posts/73">73</a><a class="link" href="/posts/74">74</a><a class="link" href="/posts/75">75</a><a class="link" href="/posts/76">76</a><a class="link" href="/posts/77">77</a><a class="link" href="/posts/78">78</a><a class="link" href="/posts/79">79</a><a class="link" href="/posts/80">80</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠","description":"","date":"2024-05-23 17:14","slug":"2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction","content":"\nPrometheus, Triton, 그리고 Grafana를 사용하여 엔드 투 엔드 모니터링 대시보드를 구축해보세요.\n\nML 시스템을 배포하기 전에, 엔지니어들은 로컬 및 대규모에서 어떻게 성능을 발휘할지 정확한 통찰력이 필요합니다. 병목 현상을 식별하고 예상치 못한 동작을 파악하기 위해.\n\n클래식 ML 추론 파이프라인과 비교하면, 딥 러닝 시스템은 자원 소비, 복잡성 및 확장 가능성의 도전에 따라 낮은 지연 시간, 높은 처리량에 중점을 둔다는 것 때문에 보다 \"중요한\" 및 자세한 모니터링이 필요합니다. 특히, 컴퓨터 비전과 같은 자원 집중적인 응용 프로그램에서 딥 러닝 배포를 위해 ML 엔지니어들은 모니터링에 우선순위를 두어야 합니다.\n\n이 글에서는 배포 설정 및 모니터링의 워크플로우에 대해 다루겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 목차\n\n1. 성능 모니터링 파이프라인 설정 방법\n\n- 컨테이너\n- 설정 파일\n- 도커 컴포즈\n\n2. 메트릭 스크랩 구성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프로메테우스 타겟을 추가하기\n\n- 그라파나 데이터소스 추가하기\n- 헬스체크 대상 스크랩\n\n3. 대시보드 생성\n\n- GPU 메트릭을 위한 패널\n- CPU/RAM 메트릭을 위한 패널\n\n4. 시각화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로 넘어가기 전에 사용할 도구들을 살펴봅시다:\n\n- 도커는 가벼우고 휴대용한 컨테이너 내에서 애플리케이션을 개발, 배포, 실행할 수 있는 플랫폼입니다 — ML 엔지니어에게 꼭 필요한 도구입니다.\n- 도커 컴포즈는 멀티 컨테이너 애플리케이션을 정의하고 구성하는 도구입니다.\n- cAdvisor는 구글에서 개발한 리소스 사용량 및 컨테이너 성능 지표를 제공해주는 오픈소스 도구입니다.\n- 프로메테우스는 메트릭을 수집하고 저장하는 모니터링 및 경보 시스템으로, 프로메테우스에 대한 전문 지식은 ML/MLOps 엔지니어에게 큰 장점입니다.\n- 그라파나는 모니터링 및 가시성 플랫폼으로, 배포된 시스템의 메트릭을 생성, 시각화, 경보 및 이해할 수 있게 해줍니다. 모니터링 대시보드를 관리하는 것은 MLOps 엔지니어에게 중요한 기술입니다.\n- Triton Inference Server는 NVIDIA에서 개발한 인기 있는 모델 서빙 프레임워크로, 복잡한 ML 모델을 프로덕션 환경에 배포하는 데 중요한 역할을 합니다. Triton에 대한 전문 지식은 MLOps 엔지니어에게 필수적인 기술입니다.\n\n# 1. 도커 컴포즈 설정\n\n각 서비스가 무엇을 하는지 설명하고, 이러한 서비스를 캡슐화하고 실행할 도커 컴포즈를 준비하는 것부터 시작해봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음과 같은 내용이 있습니다:\n\n![이미지](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png)\n\n도커 컴포즈 모니터링 yaml 파일을 살펴보겠습니다.\n\n```yaml\n# cat docker-compose-monitoring.yaml\nversion: \"3.4\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"${PROMETHEUS_PORT}:${PROMETHEUS_PORT}\"\n    container_name: prometheus\n    restart: always\n    volumes:\n      - \"${MONITORING_CONFIGURATIONS}/prometheus.monitoring.yml:/etc/prometheus/prometheus.monitoring.yml\"\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    command:\n      - \"--config.file=/etc/prometheus/prometheus.monitoring.yml\"\n      - \"--enable-feature=expand-external-labels\"\n    depends_on:\n      - cadvisor\n    networks:\n      monitor-net:\n        ipv4_address: ${PROM_IP}\n  grafana:\n    image: grafana/grafana-enterprise:8.2.0\n    container_name: grafana\n    ports:\n      - \"${GRAFANA_PORT}:${GRAFANA_PORT}\"\n    volumes:\n      - ${MONITORING_CONFIGURATIONS}/datasources:/etc/grafana/provisioning/datasources\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PWD}\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}\n    networks:\n      monitor-net:\n        ipv4_address: ${GRAFANA_IP}\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:latest\n    container_name: cadvisor\n    restart: always\n    ports:\n      - \"${CADVISOR_PORT}:${CADVISOR_PORT}\"\n    volumes:\n      - \"/etc/localtime:/etc/localtime:ro\"\n      - \"/etc/timezone:/etc/timezone:ro\"\n      - \"/:/rootfs:ro\"\n      - \"/var/run:/var/run:rw\"\n      - \"/sys:/sys:ro\"\n      - \"/var/lib/docker:/var/lib/docker:ro\"\n    networks:\n      monitor-net:\n        ipv4_address: ${CADVISOR_IP}\n  triton_server:\n    container_name: tis2109\n    image: nvcr.io/nvidia/tritonserver:21.09-py3\n    privileged: true\n    ports:\n      - \"8002:8002\"\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              capabilities: [gpu]\n    volumes:\n      - ${TRITON_MODELS_REPOSITORY}:/models\n    command:\n      [\n        \"tritonserver\",\n        \"--model-repository=/models\",\n        \"--strict-model-config=false\",\n      ]\n    networks:\n      monitor-net:\n        ipv4_address: ${TRITON_IP}\nnetworks:\n  monitor-net:\n    driver: bridge\n    internal: false\n    ipam:\n      driver: default\n      config:\n        - subnet: ${SUBNET}\n          gateway: ${GATEWAY}\n```\n\n보시다시피, .yaml 설정에 일부 마스킹된 $'변수'가 있습니다. 이들은 .env 파일 내부에서 자동으로 상속되어 로컬 개발 및 CI/CD 파이프라인에서 최상의 관행을 따르는 흐름을 가지고 있습니다.\n\n이제 .env 파일에 어떤 것이 있는지 살펴봅시다:\n\n```yaml\n# == 모니터링 변수 ==\nPROMETHEUS_PORT=9090\nGRAFANA_PORT=3000\nCADVISOR_PORT=8080\nMONITORING_CONFIGURATIONS=\u003cyour_configuration_files에 대한_경로\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# == 자격 증명 ==\nGRAFANA_PWD=admin\nGRAFANA_USER=admin\n# == TIS 변수 ==\nTRITON_MODELS_REPOSITORY=\u003c당신의_triton_모델_저장소_경로\u003e\n# == 기본 네트워크 ==\nSUBNET=172.17.0.0/16\nGATEWAY=172.17.0.1\n# == 서브넷 IP ==\nTRITON_IP=172.17.0.3\nCADVISOR_IP=172.17.0.4\nPROM_IP=172.17.0.5\nGRAFANA_IP=172.72.0.6\n```\n\n대부분의 변수가 설정되었지만, 여기서 살펴봐야 할 주요한 2가지 변수는 다음과 같습니다:\n\n- MONITORING_CONFIGURATIONS\n  이것은 이러한 구조가 있는 폴더를 가리켜야 합니다\n\n```js\n.__ monitoring\n|  |_ datasources\n|  | |_ datasources.yml\n|  |_ prometheus.monitoring.yml\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- TRITON_MODEL_REPOSITORY\n  모델 저장소의 구조는 다음과 같아야 합니다:\n\n```js\nmodel_repository\n└── prod_client1_encoder\n    └── 1\n        └──resnet50.engine\n    └── config.pbtxt\n```\n\n프로메테우스 모니터링 파일인 prometheus.monitoring.yml에는 메트릭을 가져올 대상(컨테이너)을 추가할 것입니다.\n데이터 소스 파일인 datasources.yml에는 그라파나 대시보드의 소스로 프로메테우스를 추가할 것입니다. 그렇게 하면 그라파나 UI를 열 때 나타날 것입니다.\n\n# 2. 프로메테우스 스크래핑 구성 정의\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼 Prometheus 대상을 구성해 보겠습니다. `prometheus.monitoring.yml` 파일에 작성하겠습니다.\n\n```yaml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n```\n\n```yaml\nscrape_configs:\n  - job_name: \"prometheus\"\n    static_configs:\n      - targets: [\"172.17.0.5:9090\"]\n  - job_name: \"triton-server\"\n    static_configs:\n      - targets: [\"172.72.0.3:8002\"]\n\n  - job_name: \"cadvisor\"\n    static_configs:\n      - targets: [\"172.72.0.4:8080\"]\n```\n\n3개의 대상이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 프로메테우스 — 모니터링 프로메테우스 자체를 유지하는 것이 건강한 모니터링을 위한 모범 사례로 작용합니다. 수천 개의 메트릭을 처리하면 병목 현상이 발생할 수 있으며 프로메테우스 자체의 자원 사용량을 알고 있는 것이 유용합니다.\n- Triton Server — 이것은 이 딥러닝 스택의 핵심에 있어 중요합니다. ML 모델을 제공하고 관리하기 때문입니다.\n  Triton은 인퍼런스 프로세스 전반에 걸쳐 다양한 메트릭을 제공하는 포트 8002의 내장된 프로메테우스 엔드포인트가 있습니다.\n- cAdvisor — 이 배포에서 컨테이너 전반의 CPU/RAM 사용량 정보를 얻기 위해 사용됩니다.\n\n모두 구성한 뒤, 컴포저를 시작하고 문제가 있는지 검사할 수 있습니다.\n컨테이너를 시작해 봅시다.\n\n```js\ndocker compose -f docker-compose-monitoring.yaml up -d\n```\n\n프로메테우스 대상을 검사해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 웹 브라우저로 가서 전체 Prometheus URL(IP:9090)을 입력해주세요.\n- 상태 → 대상(Targets)으로 이동해주세요.\n- 스크래핑 구성에서 각 대상이 정상인지 확인해주세요(녹색).\n\n이러한 사항을 확인한 후에는 Grafana에서 대시보드를 만들어 진행할 수 있습니다.\n\n# #3 대시보드 생성하기\n\nGrafana WebUI 대시보드에 액세스하려면 브라우저를 열고 `localhost:3000`으로 이동해주세요. 여기서 3000은 Grafana 컨테이너를 실행하는 포트입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로그인 페이지로 이동하면 사용자 이름/암호 필드에 `admin/admin`을 사용하십시오. 더 높은 보안이 권장되지만, 이는 이 기사의 범위에 포함되지 않습니다.\n\nGrafana 웹을 열었으면 다음을 수행해야 합니다:\n\n- 데이터 소스를 우리의 Prometheus 메트릭 스크래퍼 엔드포인트로 지정합니다.\n- 새 대시보드 생성\n- 관심 있는 메트릭을 집계/시각화하기 위해 차트 추가\n\n#3.1 Prometheus 데이터 소스\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n왼쪽 패널에서 기어 아이콘(설정)을 클릭하고 DataSources를 선택하세요.\n다음과 같은 뷰가 나타날 것입니다:\n\n\"Add data source\"를 클릭한 후 Time Series Databases 아래에서 `Prometheus`를 선택하세요. Grafana는 여러 종류의 메트릭 스크랩을 지원하고 있습니다. 여기서는 Prometheus를 사용할 것입니다. 이런 뷰가 나타날 것입니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_1.png\" /\u003e\n\n여기에는 Prometheus 엔드포인트의 URL을 추가해야 합니다. 우리의 도커 컴포즈 배포에서는 `http://prometheus:9090`을 사용할 것입니다. 이 템플릿을 따르면 `http://container_name:container_port`가 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_2.png\" /\u003e\n\n여기까지 오셨군요. 이제 데이터 원본 추가 섹션이 완료되었습니다.\n이제 대시보드를 만들어보겠습니다.\n\n### 3.2 Grafana 대시보드 만들기\n\n왼쪽 패널에서 “+” 표시를 클릭하고 `Dashboard`를 선택하세요. 이렇게 하면 미리 정의된 패널 그룹이 있는 새 대시보드 페이지로 이동합니다. 우리는 모든 것을 처음부터 만들고 있으므로 `Empty Panels`만 사용하여 주요 지표를 표시할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 한 예제에 대한 따라할 프로세스입니다:\n\n- 새 쿼리를 추가하고 `promql` (Prometheus 쿼리 언어)를 정의합니다.\n- 시각화 유형, 그래프 스타일, 범례를 구성합니다.\n\n다음은 비어 있는 패널의 모습입니다:\n\n이제, 트리튼 추론 서버 모델 서빙 플랫폼을 모니터링하기 위해 몇 가지 사용자 정의 쿼리를 추가할 것입니다. 하지만 먼저 다음 참고 사항을 유념해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 쿼리를 설정해보겠습니다. 이 쿼리는 성공적인 요청의 수를 고려하여 모델이 하나의 추론 요청을 수행하는 데 걸리는 시간(밀리초)을 측정할 것입니다. 우리는 시간이 지남에 따라 진행 상황을 보고 싶기 때문에 이 차트는 `시계열(time-series)`이 될 것입니다.\n다음은 해당 지표를 작성하는 쿼리입니다:\n\n```js\n(irate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\n```\n\n쿼리를 해석해 봅시다:\n\n아래에서 쿼리의 모습을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 새 차트의 설정을 구성할 때, 오른쪽에 다음을 지정할 수 있습니다:\n\n- 차트 유형 — 직선 / 곡선 / T-스텝 라인 중 선택\n- 메트릭 범위 — 메트릭 선택(예: 밀리초(ms))하고 low_range(예: 0)와 high_range(예: 100ms) 정의\n- 사용자 지정 텍스트 — 범례 또는 다른 필드에 표시될 내용\n\n#3.3 시각화 완료\n\n위의 흐름에 따라, 나머지 차트를 생성할 수 있습니다.\n전체 성능 모니터링 차트를 컴파일하려면 나머지 패널을 추가하십시오. 다음 각각에 대해 새 패널을 만들고 해당 세부 정보로 채워넣습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- GPU 사용된 바이트 - VRAM 사용량의 백분율\n\n```js\n쿼리: nv_gpu_memory_used_bytes{job=\"triton-server\"}/nv_gpu_memory_total_bytes{job=\"triton-server\"}\n차트 유형: 파이\n범례: {인스턴스}\n```\n\n2. GPU 활용도 - 전체 GPU 활용도\n\n```js\n쿼리: nv_gpu_utilization{job=\"triton-server\"}\n차트 유형: 시계열\n범례: NULL\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 입력 시간/요청 — 클라이언트가 입력 데이터를 Triton 서버로 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n4. 출력 시간/요청 — 서버가 클라이언트에게 출력을 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000)/ irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. DB 비율 (#요청/#실행) — 성공적인 요청의 전체 요청 대비 비율\n\n```js\n쿼리: sum by (모델,버전) (rate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])/rate(nv_inference_exec_count{job=\"triton-server\"}[$__rate_interval]) )\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n6. 대기 시간/요청 — 요청이 처리되기 전에 대기하는 시간\n\n```js\n쿼리: sum by (모델,버전) ((irate(nv_inference_queue_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval]))\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n7. 집계된 입력/추론/출력 - 입력 출력 및 추론을 한 차트에 표시합니다.\n\n```js\n질의:\nA: rate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nB: rate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nC: rate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__interval]) / 1000\n\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n우리가 만든 완벽한 대시보드는 다음을 보여줍니다:\n\n- GPU VRAM 이용률\n- 클라이언트에서 서버로의 입력 송신 시간\n- 서버 추론 요청 시간\n- 서버에서 클라이언트로의 출력 송신 시간\n- 성공 요청/전체 요청 비율\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이런 종류의 대시보드는 배포된 스택의 성능 및 스트레스 테스트 속에서의 동작을 모니터링하기 위한 시작점을 제시합니다.\n\n이는 배포의 실패 및 위험 지점을 연구하는 구체적인 방법을 제공하며 SLI(서비스 수준 지표)를 모니터링하는 데 도움이 됩니다.\n\n서비스 수준 지표는 SLA(서비스 수준 계약)를 준수하고 SLO(서비스 수준 목표)를 달성하기 위해 모니터링되는 메트릭입니다. 우리가 만든 대시보드는 제공되는 서비스 수준 계약을 준수하기 위한 목표에 도달하기 위한 가치 있는 통찰을 제공할 수 있습니다.\n\n또한 이는 다중 복제본을 추가하거나 추론 서빙 프레임워크를 실행하는 여러 기계로의 확장 전략을 계획하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n본 문서에서는 Prometheus와 Grafana를 사용하여 자사의 ML 애플리케이션 및 모델 서빙 프레임워크를 위한 성능 모니터링 스택을 설정하고 구축하는 방법을 소개했습니다.\n\n도커 컴포즈 파일을 준비하는 것부터 시작하여 워크플로우의 각 단계를 설명하고 스택을 배포하고 데이터 원본을 구성하며 대시보드 패널을 생성하고 지표를 집계하는 과정을 마무리했습니다.\n\n모니터링은 MLOps 시스템의 중요한 부분입니다!\n이 튜토리얼을 따라 하면 테스트 환경에서 단일 배포로 ML 애플리케이션을 위한 모니터링 파이프라인을 구조화하고 배포하거나, 클라우드 시나리오 설정에서 여러 입력 소스를 결합하고 전체 스택 배포를 모니터링하는 단일 대시보드 소비자 지점을 갖도록 구성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 더 많은 내용을 원하신다면!\n\n저는 미디엄에 새롭게 등장했습니다. 만약 이 글을 즐겨보셨다면 박수를 보내주시고 제 계정을 팔로우해주세요 - 정말로 감사하겠습니다! 🚀\n\n![How to ensure your deep learning stack is fail-safe in production](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_3.png)\n\n# 더 많은 글 보기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물과 관련성에 따라 정렬되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png"},"coverImage":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png","tag":["Tech"],"readingTime":18},{"title":"자기 주의적 문장 임베딩을 사용한 추천 시스템","description":"","date":"2024-05-23 17:13","slug":"2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem","content":"\n![Self-attentive sentence embedding](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png)\n\n# 소개\n\n트랜스포머 레이어와 그의 어텐션 메커니즘은 자연어처리(NLP) 커뮤니티에서 가장 중요한 아이디어 중 하나입니다. 최근 세계를 휩쓴 ChatGPT와 LLaMA와 같은 대규모 언어 모델에서 핵심 역할을 합니다.\n\n하지만 NLP 커뮤니티에서 시작된 다른 흥미로운 아이디어가 있는데, 그 영향은 주로 추천 시스템 분야에서 실현됩니다. 바로 자기주의적 문장 임베딩(self-attentive sentence embedding)입니다. 이 기사에서는 자기주의적 문장 임베딩[1]과 추천 시스템에 적용하는 방법을 살펴볼 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 작동 방식\n\n## 전체 아이디어\n\n이 논문의 주된 아이디어는 문장을 여러 임베딩으로 인코딩하여 문장의 다양한 측면을 포착할 수 있는 더 나은 방법을 찾는 것입니다. 구체적으로, 저자들은 문장을 단일 임베딩으로 인코딩하는 대신 각 행 임베딩이 문장의 다른 측면을 포착하는 2D 행렬로 인코딩하고자 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n문장 임베딩을 얻으면, 문장 분석, 작가 프로파일링, 텍스트 함의 등 다양한 하위 작업에 사용할 수 있습니다.\n\n## 모델 아키텍처\n\n모델 입력은 문장 배치입니다. 각 문장은 n개의 토큰을 가지고 있습니다. 우리는 i번째 문장을 다음과 같이 표현할 수 있습니다:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nd는 표현의 숨겨진 차원을 나타내며, 우리는 문장 s를 n by d 행렬 H로 인코딩할 수 있습니다:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_3.png)\n\n여기서 F는 문장의 토큰을 임베딩으로 인코딩하는 모델 함수를 나타냅니다. 논문에서는 단어 임베딩(Word2Vec을 사용하여 초기화)을 이용하여 토큰을 인코딩하고 이를 양방향 LSTM을 통해 전달합니다. 토큰을 임베딩으로 인코딩하는 다양한 방법이 있기 때문에 일반화를 위해 여기서 F를 사용했습니다.\n\n다음으로, 그들은 임베딩 H를 입력으로 사용하여 어텐션 가중치 행렬 A를 학습합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image #1](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_4.png)\n\nHere, the softmax() is applied to the second dimension of its input. We can view the formula as a 2-layer MLP without bias.\n\nAs we can see from the above formula, the attention weight A matrix will have a shape of r by n where r is the number of aspects a sentence can have and n is the sentence length. The authors argue that there are many aspects that make up the semantics of a sentence. Thus, they need r embeddings to focus on different parts of the sentence. In other words, each embedding in A is the sentence attention weight:\n\n![Image #2](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nTransformer처럼 이 행렬 A의 시각화를 통해 문장에 대한 각 측면의 주의를 더 잘 이해할 수 있습니다.\n\n마지막으로, 우리는 H와 A를 곱하여 r by d 행렬 M을 얻음으로써 문장 임베딩을 생성합니다:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_6.png)\n\nM의 각 행은 토큰 임베딩과 그 토큰에 대한 측면의 가중치의 가중 합입니다. 시각적으로는 이렇게 보입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_7.png)\n\n## Regularization\n\nIn the paper, they also introduce a new regularization term:\n\n![image](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n표를 마크다운 형식으로 변경해주세요.\n\nF는 행렬의 프로베니우스 노름을 나타냅니다.\n\n정규화 항은 2가지 목적을 제공합니다:\n\n- 측면 임베딩이 겹칠 수 있기 때문에 다양성을 높입니다. 즉, 유사할 수 있음을 의미합니다.\n- 각 관심사가 가능한 적은 토큰에 초점을 맞추도록 만듭니다.\n\n이 글에서는 정규화가 중점이 아니기 때문에 정규화가 어떻게 작동하는지에 대해 더 읽어볼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 추천 시스템에서의 다중 관심사\n\n셀프 어텐티브 문장 임베딩이 어떻게 작동하는지 이해하면, 추천 시스템에서 어떻게 활용할 지에 대해 집중할 수 있습니다.\n\n대규모 추천 시스템에서, 보통 두 개의 타워 모델 아키텍처를 사용합니다. 하나는 사용자 정보를 인코딩하고, 다른 하나는 후보 정보를 인코딩합니다. 사용자 타워에는 사용자의 과거 행동인 클릭, 좋아요, 공유 순서와 사용자 프로필을 사용합니다. 후보 타워에는 아이템 ID와 아이템 카테고리와 같은 후보 특징을 사용합니다.\n\n사용자 임베딩과 후보 임베딩을 내적하여 후보 아이템이 사용자에게 얼마나 관련 있는지를 반영합니다. 레이블은 사용자 시퀀스에서 다음 상호작용할 아이템입니다. 따라서 모델 목표는 사용자가 다음에 상호작용할 아이템을 예측하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Self-attentive sentence embedding for the recommendation system](/assets/img/2024-05-23-Self-attentive-sentence-embedding-for-the-recommendation-system_9.png)\n\n위 이미지에서 확인할 수 있듯이 사용자 타워의 출력은 모든 사용자 정보를 포함하는 임베딩입니다. 그러나 단일 사용자 임베딩은 모든 사용자의 다양한 관심사를 포착하는 데 좋지 않습니다. 따라서 더 나은 해결책은 사용자의 관심사를 여러 임베딩으로 인코딩하는 것입니다.\n\n사용자의 다양한 관심사를 어떻게 포착할지에 대한 많은 연구가 이루어졌습니다. 가장 두드러지는 두 가지 방법은 self-attentive 임베딩(SA) [2]과 dynamic routing (DR) [3]입니다. 두 방법 모두 비슷한 성능을 보이지만, self-attentive 방법이 더 안정적이고 훈련 속도가 빠릅니다.\n\nself-attentive 방법이 어떻게 작동하는지 이해하면 추천 시스템에 적용하는 것은 간단합니다. 입력으로 문장 토큰 대신에 유튜브에서 시청한 비디오 ID 목록이나 이커머스 플랫폼에서 클릭/주문한 상품 ID와 같은 사용자 행동을 사용합니다. 출력은 각 임베딩이 문장에서의 측면이 아니라 사용자 관심사를 인코딩합니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Table 1](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_10.png)\n\nIn the ComiRec paper [2], the authors compare the self-attentive method with the dynamic routing method along with other popular models that produce a single user interest:\n\n![Table 2](/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_11.png)\n\nAs the table shows, the self-attentive method produces results comparable to those of the dynamic routing method. Still, both multi-interest embedding solutions are significantly better than their single-interest embedding counterparts.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마무리\n\n여러 관심사를 포함한 임베딩을 사용하여 모델을 교육하고 제공하는 것에는 많은 미묘한 점이 있습니다. 이 기사에서는 자가 주목 방법이 작동하는 방법과 이를 추천 시스템에서 어떻게 사용하는지에 대해 안내했습니다. 이러한 모델을 교육하고 제공하는 데 대한 더 자세한 내용은 논문을 읽는 것만큼 좋은 자료는 없습니다. 이 기사는 추천 시스템을 위한 다중 관심 프레임워크를 이해하고자 하는 여정에서 참고할 만한 자료입니다.\n\n# 참고\n\n[1] Lin, Zhouhan, et al. “A structured self-attentive sentence embedding.” arXiv preprint arXiv:1703.03130 (2017).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## References\n\n[1] Cen, Yukuo, et al. “Controllable multi-interest framework for recommendation.” Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2020.\n\n[2] Li, Chao, et al. “Multi-interest network with dynamic routing for recommendation at Tmall.” Proceedings of the 28th ACM international conference on information and knowledge management. 2019.\n","ogImage":{"url":"/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png"},"coverImage":"/assets/img/2024-05-23-Self-attentivesentenceembeddingfortherecommendationsystem_0.png","tag":["Tech"],"readingTime":9},{"title":"포디즘의 새로운 모습","description":"","date":"2024-05-23 17:11","slug":"2024-05-23-ThenewfaceofFordism","content":"\n\u003cimg src=\"/assets/img/2024-05-23-ThenewfaceofFordism_0.png\" /\u003e\n\n미국 로봇 기업인 Figure은 특정 경제 분야에서 발생하는 노동 인력 부족을 해결하기 위해 인간 형상 로봇을 개발 중이며, 독일 자동차 제조사인 BMW과 협약을 발표했습니다. 이 협약에 따라 Figure 01 로봇들이 BMW의 미국에 위치한 Spartanburg 공장에 배치될 예정입니다. 해당 공장은 X 및 XM 시리즈 차량을 하루에 약 1,500대 조립하며 현재 약 11,000명을 고용하고 있습니다.\n\n아직 로봇 수나 그들이 수행할 작업에 대한 구체적인 내용은 알려지지 않았지만, \"그들은 몇 달 동안 특정 작업을 수행할 수 있도록 훈련받은 후, 생산 공정(보디 샵, 시트 금속 및 웨어하우스 등)에 통합될 것이며 앞으로 12개월에서 24개월 안에 배치될 예정입니다.\"라는 말을 제외하고 전반적인 작업에 대한 컨셉 증명입니다.\n\nBMW는 이미 공장에서 사용 중인 Optimus 로봇을 보유한 Tesla와 경쟁을 목표로 하고 있습니다. 이와 같이 인간 형상 로봇을 사용하여 반복적이고 위험한 작업을 수행하는 것에 대해 연구해온 Honda나 Boston Dynamics를 인수한 Hyundai 등의 자동차 제조사들은 기업들이 고용인력을 영입하고 유지하기 어려운 일부 여러 가치를 내지 않는 반복적인 작업이 바로 그들이 가장 어려워하는 작업이며, 회사들은 이에 대해 논의하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금은 다음 세대 로봇의 개발이 진행되고 있습니다. 이러한 로봇들은 사람들과 함께 공간을 공유하는 환경에서 완전히 안전하며, 일 중에 일어나는 학습 과정이 모방을 통해 이뤄집니다. 실제로 Figure의 접근 방식은 로봇이 기업이 생산성을 높이고 비용을 절감하며 더 안전하고 일관된 작업 환경을 조성하는 데 기여할 것으로 보고 있으며, 회사를 RaaS(로보틱스 서비스) 모델로 설립하고 로봇을 기업에 대여할 계획입니다. Figure는 인간의 형태 요소를 모방하고 손으로 수행되는 작업에서 높은 정밀도를 달성하는 데 초점을 맞추고 있습니다.\n\n자동차 제조 공장에서 작업하는 로봇들. 2024년이 로보틱스의 해가 될 것으로 생각했을 때, 이렇게 빨리 이러한 종류의 보고서들을 듣게 될 줄은 저도 예상치 못했습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-ThenewfaceofFordism_0.png"},"coverImage":"/assets/img/2024-05-23-ThenewfaceofFordism_0.png","tag":["Tech"],"readingTime":2},{"title":"로봇 공학의 미래를 위한 P2P 통신 로봇 에이전트 007 릴리스","description":"","date":"2024-05-23 17:10","slug":"2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release","content":"\n\u003cimg src=\"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png\" /\u003e\n\nMerklebot에서는 로봇 플릿 운영자를 위한 데이터 관리 및 개발 도구를 만들고 있습니다. 우리는 다음 15년 안에 100억 대 이상의 로봇이 나올 가능성이 꽤 높다고 믿고 있으며, 이 비전을 실현하기 위해 견고하고 확장 가능하며 안전한 인프라 및 통신 스택을 구축하고 있습니다.\n\n## 로봇 에이전트란?\n\n몇 달 전에 Digital Black Box를 출시했습니다. 이 서비스는 로봇에서 로그, 카메라 피드 및 포인트 클라우드와 같은 데이터를 안전하고 저렴한 분산 저장 네트워크인 Filecoin에 백업하는 기능을 제공합니다. Digital Black Box는 다음으로 구성됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 가장자리에서 실행되는 로봇 에이전트\n\n2. 클라우드 연결을 제공하는 Merklebot 플랫폼\n\n첫 번째 버전의 로봇 에이전트는 가장자리 장치에서 데이터를 수집하고 백업하는데 사용되었습니다. 나중에는 Merklebot 플랫폼을 구축하여 Docker 컨테이너를 가장자리 장치에 배포하고 그 위에서 실행 중인 에이전트에 기능을 추가했습니다.\n\n## 로봇 에이전트 0.0.7\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 👀 네트워크에서 다른 로봇의 mDNS 자동 탐색\n- 🤖↔🤖 로봇 간의 Libp2p 메시징\n\n안녕하세요! 오늘은 로봇 에이전트 0.0.7의 새로운 릴리스를 Libp2p 통신 모듈과 함께 발표합니다. 최신 버전의 로봇 에이전트는 이제 Libp2p 피어 탐색, 주소 설정 및 메시지 전송을 갖추고 있습니다. 네트워크를 유연한 토폴로지로 설정할 수 있으며, 위치 변경이나 다른 매개변수를 바꿀 때마다 통신 스택을 구성할 필요가 없습니다. 이제 저희의 Github에서 공개되어 있습니다.\n\n로봇 에이전트 0.0.7를 설치하면 기기가 다른 에이전트를 자동으로 찾아 정보(상태, 이벤트)를 서로 전달할 수 있습니다. 중앙 서버에 접근하지 않고도 기기 간 통신을 수행할 수 있습니다. 이 도구는 MIT 라이선스로 완전히 오픈 소스이며, 여러분의 필요에 맞게 이 도구를 자유롭게 사용할 수 있습니다.\n\n## Merklebot 플랫폼\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMerklebot 플랫폼은 Robot Agents를 여러 기기 필릿에 중앙 집중식으로 롤아웃할 수 있도록 제공하여 로봇, 센서, 장비 및 기타 기계와 같은 다양한 기기를 안전하고 쉽게 관리할 수 있습니다. 전체 Robot Agents 필릿에 코드 및 Docker 컨테이너를 배포하고 데이터를 관리할 수 있습니다.\n\nMerklebot 없이:\n\n- 로봇에 연결\n- 로봇을 vpn 네트워크에 추가하거나 NAT 트래버셜을 우회하는 다른 방법\n- 🧑‍💻 코드를 작성합니다\n- ssh를 통해 로봇에 연결\n- ⏳ git pull\n- ⏳ docker build 및 run my-best-code\n- ⏳ 로봇 로그 보기\n- ⏳ 데이터(카메라 비디오 등)를 가져오기 위해 scp 실행\n- ⏳ 취합할 위치에 저장\n\nMerklebot을 사용하면:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 로봇에 연결하세요\n- install.sh를 실행하세요\n- 🧑‍💻코드를 작성하세요\n- 🚀플랫폼에서 한 번 클릭하거나 API를 호출하세요\n- 😎로그, 비디오 및 기타 데이터를 플랫폼에서 확인하세요\n\n## 다음은 무엇인가요\n\nMerklebot 팀은 오픈 소스 Agent의 기능을 계속 향상시키고 Merklebot 플랫폼에 더 많은 유틸리티를 추가할 새로운 기능 세트에 현재 작업 중입니다.\n\n- 에이전트를 위한 향상된 CLI 도구 (일반 명령 인터페이스). SSH 우회, 구성 업데이트 전달 및 기기에서 편집 없이 에이전트를 관리하세요. 현재 Merklebot 플랫폼에서 활성화되어 있지만, 이를 오픈 소스로 만들 계획을 하고 있어요!\n- 오픈 소스 데이터 관리 및 시각화 도구와의 통합. 로그 수집 및 저장, 데이터 작업 실행 및 시각화 생성을 할 수 있어요.\n- Jenkins와 같은 CI/CD (지속적 통합 지속적 배포) 도구와의 통합. 자동으로 장치에 새 소프트웨어 릴리스 설치하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리 새로운 에이전트를 확인해보세요! 피드백을 기다리고 있어요.\n\n그리고 기기 편대를 관리해야 한다면, Merklebot Platform으로 시작해보세요.\n","ogImage":{"url":"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png"},"coverImage":"/assets/img/2024-05-23-P2PCommunicationfortheFutureofRoboticsRobotAgent007Release_0.png","tag":["Tech"],"readingTime":4},{"title":"M1 M2 Mac 실리콘에 LinuxUbuntu 2004 설치하기","description":"","date":"2024-05-23 17:09","slug":"2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon","content":"\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png\" /\u003e\n\n안녕하세요, 로봇 공학 애호가 및 리눅스 사용자 여러분! 여러분께서는 강력한 M1 또는 M2 맥을 소유하셨지만 리눅스에서만 실행되는 프로젝트를 실행하고 싶으시죠? 다행히도 가상화 기술을 활용하여 M1/M2 맥에서 리눅스를 실행할 수 있습니다. 이 안내서에서는 UTM 가상 머신을 사용하여 M1/M2 맥에 리눅스를 설정하는 방법을 살펴보겠습니다.\n\nUTM이란 무엇인가요?\n\nUTM은 \"Universal Terminal Machine\"의 약자로, macOS 및 iOS용으로 설계된 오픈 소스 가상화 도구입니다. 이 도구를 사용하면 M1 및 M2 맥을 비롯한 Apple Silicon 기기에서 가상 머신을 실행할 수 있습니다. UTM을 사용하면 리눅스 배포본, Windows 등 다양한 운영 체제를 에뮬레이트할 수 있습니다. Mac 용 UTM 앱은 공식 UTM 다운로드 링크에서 다운로드할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nM1/M2 Mac에 Linux 설치하기:\n\nUTM을 이용하여 Linux를 설치하는 방법에 대한 단계별 안내서입니다. 모든 단계에 대한 사진을 포함하려고 해서 길어 보이지만 이 안내서를 따라 M1/M2 Mac에 Linux를 설치할 수 있습니다:\n\n- UTM 다운로드 및 설치:\n\n- 위의 링크를 통해 UTM 앱을 다운로드하거나 Google에서 'Mac용 UTM'을 검색하여 다운로드할 수 있습니다.\n- 다운로드 후 DMG 파일을 열고 UTM 애플리케이션을 드래그하여 설치하기 위해 Applications 폴더로 이동하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 리눅스 디스크 이미지 얻기:\n\n- 설치하려는 리눅스 배포판을 선택합니다. 인기있는 선택지로는 우분투, 페도라, 데비안 등이 있습니다. 이 튜토리얼에서는 우분투 20.04를 설치할 것입니다.\n- 우분투 20.04 데스크톱 버전이 ARM 64용으로 공식 웹사이트에서 제거되었기 때문에, 우분투 20.04 데스크톱을 설치하기 위해 우회 방법을 사용할 것입니다.\n- 여기서 우분투 20.04 (ARM 64 버전) 서버 디스크 이미지를 다운로드합니다. 이 이미지는 서버 이미지이므로 터미널 환경만 제공됩니다. 다음 단계에서 전체 데스크톱 버전을 설치할 것입니다.\n\n3. UTM에서 새 가상 머신 생성하기:\n\n- 응용 프로그램 폴더에서 UTM을 엽니다.\n- 새 가상 머신을 생성하려면 “+” 버튼을 클릭합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_1.png\" /\u003e\n\n- \"Virtualize\" 옵션을 선택하세요. \"Virtualize\"와 \"Emulate\"의 차이점은 Virtualize는 Apple 실리콘, 즉 ARM 64 칩셋을 네이티브로 지원하는 기계를 가상화한다는 것입니다. 그래서 빠릅니다. 반면에 Emulate는 필요한 CPU 아키텍처를 가상화하여 다른 CPU 아키텍처를 실행할 수 있습니다. (진실을 말하면, Emulate를 시도해 봤는데, 너무 느려요. 만약 단순한 명령줄만 실행되는 매우 가벼운 OS가 아니라면 절대 Emulate 옵션 선택하지 말기를 권장합니다.)\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_2.png\" /\u003e\n\n- 당연히 \"Linux\"를 선택하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Install Linux Ubuntu 20.04 on M1/M2 Mac Silicon Step 3](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_3.png)\n\n- ISO 이미지에서 부팅을 선택하고 Step 2에서 다운로드한 서버 이미지를 찾아 선택하세요.\n\n![Install Linux Ubuntu 20.04 on M1/M2 Mac Silicon Step 4](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_4.png)\n\n- 이제 가상 머신에 필요한 자원을 할당하세요. 최상의 성능을 위해 시스템 자원의 절반을 가상 머신에 할당하는 것을 강력히 권장합니다. 가상 OS에서 작업하는 동안 다른 응용 프로그램을 실행하지 않고 자원을 절약하고 성능을 향상시키기 위해 노력해주세요. 그렇지 않으면 시스템이 다운될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 5](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_5.png)\n\n![Image 6](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_6.png)\n\n![Image 7](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_7.png)\n\n![Image 8](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n4. 가상 머신 시작하기:\n\n- 구성이 완료되면 \"만들기\"를 클릭하여 가상 머신을 생성합니다.\n- 목록에서 새로 생성된 가상 머신을 선택하고 \"시작\"을 클릭하여 실행합니다.\n\n5. Linux 설치하기:\n\n- 가상 머신은 Linux ISO 이미지에서 부팅됩니다.\n- 화면 안내에 따라 가상 디스크에 Linux를 설치합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Screenshot 9](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_9.png)\n\n![Screenshot 10](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_10.png)\n\n![Screenshot 11](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_11.png)\n\nSelect the keyboard configuration and the network connection configuration.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Screenshot 1](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_12.png)\n\n만약 외부 세계 \"content😗\"에 액세스하기 위해 어떤 HTTP 프록시도 사용하고 싶지 않다면, 프록시 주소 필드를 비워 두십시오.\n\n다음 단계에서는 미러 주소를 기본 설정으로 유지하고 \"완료\"를 클릭하세요.\n다음 단계에서는 전체 디스크 옵션을 선택해 주세요.\n\n![Screenshot 2](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_13.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_14.png\" /\u003e\n\n파일 시스템은 주어진 그대로 선택하고 계속 진행하세요.\n\n이어진 단계에서 우분투 계정 프로필을 만들어 시스템에 로그인합니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_15.png\" /\u003e\n\n원한다면 다음 단계에서 오픈 SSH 서버를 사용할 수 있습니다!\n\n다음 창에서 프로젝트나 업무에 유용하거나 사용할 서버 스냅을 선택하세요. 원한다면 나중에도 설치 가능합니다!!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image 1](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_16.png)\n\n이제 설치가 시작됩니다 - →\n\n![Image 2](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_17.png)\n\n완료될 때까지 기다리세요. 완료되면 기계를 다시 부팅하라는 메시지가 표시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기계를 다시 시작한 후 설치된 미디어, 즉 VM 설정에서 iso 파일을 제거하고 기계를 다시 시작하세요.\n\n\u003cimg src=\"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_18.png\" /\u003e\n\n이제 Ubuntu 서버에 로그인하고 좋아하는 데스크톱 환경을 설치해 봅시다.\n\n6. 데스크톱 환경 설치:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 우분투 데스크톱 시스템(gnome 3)을 설치하려면 다음을 실행하세요:\n  $ sudo apt install ubuntu-desktop\n  또는 Gnome 3 데스크톱을 위한 전환 패키지 이름을 사용해보세요:\n  $ sudo apt install ubuntu-gnome-desktop\n  Kubuntu Plasma 데스크톱/넷북 시스템(KDE)을 설치하려면 다음을 실행하세요 (가벼우면서 부드러운 터치를 선호합니다) :\n  $ sudo apt install kubuntu-desktop\n  Lubuntu 데스크톱 환경을 원하시나요? 다음을 실행하세요:\n  $ sudo apt install lubuntu-desktop\n  Xubuntu 데스크톱 시스템을 설치하려면 다음을 실행하세요:\n  $ sudo apt install xubuntu-desktop\n\n- 데스크톱 설치 과정이 완료되면 시스템을 한 번 더 재부팅하면 됩니다. 그 후, 와우! 새로운 깨끗하고 새로운 우분투 데스크톱에 로그인하게 될 것입니다.\n\n![이미지](/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_19.png)\n\n와! 이제 우분투 20.04의 완전한 데스크톱 버전을 성공적으로 설치했습니다. 이제 선호하는 우분투 패키지와 소프트웨어를 설치하고 작업에 원활히 참여할 준비가 모두 되었습니다.\n이 설명서가 맥 실리콘을 위한 우분투 20.04 설치에 도움이 되었길 바랍니다.\n\n만약 설치 중 궁금한 점이나 오류가 발생하면 shubhjain10102003@gmail.com으로 이메일을 보내주시면 감사하겠습니다! 😇.\n","ogImage":{"url":"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png"},"coverImage":"/assets/img/2024-05-23-InstallLinuxUbuntu2004onM1M2MacSilicon_0.png","tag":["Tech"],"readingTime":9},{"title":"새로운 냉전 - 인공지능","description":"","date":"2024-05-23 17:04","slug":"2024-05-23-TheNewColdWarArtificialIntelligence","content":"\n## 최신 기술전쟁 전선에서의 한 모습\n\n![이미지](/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png)\n\n# 목차\n\n- 최신 기술전쟁 전선에서의 한 모습\n- 목차\n- 2030년 중국산\n- 기술\n- 생성적 인공지능\n- 중국: 장기 계획가?\n- 중국의 함정\n- 참가 상장\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파티 참석자는 몇 년 전에 중국에 있는 유럽-미국 상공회의소(European-American Chamber of Commerce in China)로부터 초대를 받았습니다. 2박 호텔 숙박 및 식사, 대부분의 여행 경비 보상, 그리고 중국 닝보의 스마트 시티 엑스포(Expo) 부스 무료 이용이 제공되었습니다. 중국에서 사업을 하고 싶은 마음이 생겨, \"왜 안해볼까\" 생각했습니다. 중국 비즈니스의 잠재력을 탐구하는 뜻있는 노력으로 여겼기에, 계약서에 서명했습니다. 몇 주 후, 중국 동부 체장省 닝보의 중요 항구 및 산업 중심지에 자리잡을 기회를 얻게 되었습니다.\n\n최근 소설 쓰기를 위해 제2차 세계대전 시일 중국의 일본과의 전투에 대해 조사를 한 결과, 이 도시에 대해 조금 알고 있었습니다. 안타깝게도, 닝보는 제2차 세계대전 중 일본 제국군이 가장 최악의 잔혹행위를 저질렀던 장소 중 하나였습니다. 일본 전투기가 생화학 전투부대인 유닛 731에 의해 지휘된 잔혹한 생화학 전쟁 행위로 역병, 장티푸스 및 기타 질병이 퍼진 곳이었습니다.\n\n그러나 니보 리셔 국제공항 터미널의 카펫을 건너자마자 전쟁의 생각은 멀리 떠났습니다. 거기서는 자유의 여신상과 에펠탑, 런던의 빅 벤을 담은 보험사 포스터가 나를 맞았습니다. 서양의 요소를 볼 수 있어 기분이 좋았지만, 이 상징이 보는 사람 중 대부분에게 피곤한 의미로 남아있을 것이라고 생각했습니다. 미국에서는 자유, 민주주의, 희망, 기회를 상징하는 것은 자유의 여신상뿐입니다. 그러나 중국에서는 아마 자유와 같이 무겁고 깊은 의미가 담긴 상징은 아니라 생로운 상징이라고 생각했습니다.\n\n## 2030년 중국산 \"Made in China\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중국 공산당(CCP)은 14차 다섯 해계획에서 2030년까지 인공지능 우위를 차지하는 것을 목표로 세웠습니다. 하지만 그게 현실적인 목표일까요? 의심의 여지 없이, 중국은 인상적인 기술사를 가지고 있습니다. 로스 앤더슨은 자신의 ‘파노프티콘(Panopticon)은 이미 여기에 있다’라는 기사에서 중국이 글쓰기가 독자적으로 발명된 세곳 중 하나라고 언급합니다. 중국은 또한 데이터가 신속하게 이동하도록 할 수 있는 종이를 발명했으며, 이는 제국을 확고히 통치하기 위해 필요한 의사소통 수단이었습니다. 중국 스님들은 9세기경, 불멸의 엘릭시를 찾던 중 폭약을 발견했습니다. 따라서 혁신은 중국에게 전혀 낯선 개념이 아니었습니다.\n\n중국의 기술사로부터의 진행은 오늘날 기술에 이어집니다. 현재 세계의 이메일 통신(우리의 현대적인 글쓰기 시스템) 대부분을 거래하는 컴퓨터는 중국에서 생산되었습니다. 시작은 서구에서 이루어졌지만, 중국이 현재 대부분의 컴퓨터를 대량생산하고 있습니다. 중국은 단연코 \"세계의 공장\"이라 불리는 것이 타당한 이유가 있습니다.\n\n## 기술\n\n로봇공학\n로버트 D. 애킨슨은 그의 '중국 제조업체는 미국 제조업체보다 임금을 고려할 때 12배 많은 로봇을 사용합니다.'라는 기사에서 \"2021년, 중국은 미국보다 제조업 종사자 당 로봇을 18% 더 설치했습니다. 중국 제조업 임금이 미국 임금보다 상당히 낮았다는 점을 감안할 때, 중국은 미국보다 제조업에서 12배 더 많은 로봇을 사용했습니다.\"라고 보고합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"그러나 시장 요인이 아닌 Atkinson의 말에 따르면, 이는 정부 정책 때문입니다. 제조업 로봇 도입은 중국 공산당의 최우선 과제이며 관대한 보조금으로 후원하고 있다고 덧붙였습니다. 이는 로봇 도입을 지원하거나 자금을 지원하지 않는 미국 정부의 정책과는 대조적입니다.\n\n로보틱스 기술은 닝보에서 잘 대표되었습니다. ZTE는 참석자들 가운데 어린이들의 상상력을 자극한 5G 로봇 능력을 선보였습니다. \"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로봇 개를 만드는 로보틱스 회사(그림 4 참조)가 최신 기술을 선보였어요. 사실을 말하자면, 보스턴 사이언티픽에서 몇 년 전에 본 것과 의심스럽게 비슷했어요.\n\n![로봇 개](https://miro.medium.com/v2/resize:fit:1400/1*pxBUVkAdzZqrYOZYsxAdhQ.gif)\n\n중국의 로봇산업이 인상적으로 보이긴 하지만, 산업용 로봇의 최대 채용국은 아닙니다. Atkinson에 따르면 \"한국이 세계에서 가장 많은 산업용 로봇을 채용한 나라로, 제조업 종사자 10,000명 당 1,000대의 로봇을 보유하고 있었고, 싱가포르가 그 다음으로, 670대를 보유한 나라로 뒤를 잇고 있으며, 일본과 독일이 거의 400대를 보유하고 있어요. 미국은 종사자 10,000명 당 274대의 로봇을 보유하고 있는 반면, 중국은 322대를 가지고 있습니다.\"\n\n내가 본 것은 인상적이었지만, 중국은 로봇 분야에서 한국과 싱가포르에 따라잡기에는 아직 멀은 길을 가고 있어요. 독일은 고품질 복잡한 로봇 제공업체로도 선두입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGeely는 전시장 외부 주차장에 서있는 자사 모델 중 하나를 운전할 수 있는 차 시뮬레이터를 제공했습니다. 차 안의 운전자는 발이 묶이는 듯하면 브레이크를 밟을 준비를 하고 있었어요 (그림 5 및 6).\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*5DnflsdScg7TvhsaHzpcvA.gif)\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*vN0WUdnmia1Ujan-SO_LWw.gif)\n\n스마트 시티\n스마트 시티 기술은 정보 및 통신 기술을 활용하여 운영 효율성을 개선하고 공공과 정보를 공유하며 주민들에게 더 나은 삶의 질을 제공하는 것을 의미합니다. 다양한 디지털 솔루션을 통합하여 더 나은 결정을 내리고 도시 생활을 향상시키는 것을 포함하고 있습니다. 주요 구성 요소는 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 데이터를 수집하고 분석하는 IoT 장치 통합, 이를 통해 인프라, 공공 시설 및/또는 서비스 개선을 위해 활용합니다.\n- 더 최적화된 에너지 관리를 가능하게 하는 스마트 유틸리티 미터.\n- 인텔리전트한 도시 이동 및 교통망, 스마트 트래픽 라이트, 스마트 주차 등을 포함한 스마트 이동 및 교통, 모든 것은 교통 시스템의 효율성과 지속 가능성을 향상시키기 위한 것입니다.\n- AI 기반 교통 관리 시스템: IoT 장치를 AI 기반 교통 관리 시스템과 통합하면 혼잡을 크게 줄이고 대중교통 효율을 최적화하며 온실 가스 배출량을 줄일 수 있습니다.\n\n중국 정부는 알리바바에게 나라의 스마트 시티 기술을 구축하도록 지시했습니다. 이를 회사는 \"시티 브레인\"이라고 부릅니다. 로스 앤더슨에 의하면, 시티 브레인은 \"도시 환경 전체에 분산된 다양한 센서들로부터의 데이터 스트림을 종합하는 자동화된 신경 센터\"입니다.\n\n앤더슨은 조금 디스토피아적이라고 설명합니다. \"시티 브레인은 잃어버린 어린이나 관광객 또는 테러리스트가 방치한 수화물을 발견하도록 훈련될 수 있습니다. 방황하는 사람들이나 거리에 머묾거나 무정부상태로 있거나 폭력 분자를 신고할 수 있습니다.\" 위험에 처한 사람들은 \"항상 경비 미쳐 탐지될 수 있는 독특한 방식으로 손을 흔들어 도움을 요청할 수 있을 것\"이라고 앤더슨이 덧붙입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_3.png)\n\n공정하게 말하자면, 디스토피아는 중국 해안에서 끝나는 것이 아닙니다. 중국의 타이위안은 인구 1,000명당 117개의 카메라로 세계에서 가장 감시를 많이 받는 도시 중 하나일 수 있지만, 런던도 멀지 않습니다. 인구 1,000명당 73개의 카메라를 가지고 있어 세계 순위에서 세 번째에 위치하고 있습니다.\n\n소위 헌법 제4조 권리도 일반 미국인을 충분히 보호해주지 못할 수도 있습니다. 안데르센은 \"미국의 경찰 부서들이 애매한 점에 있다면 아마존의 홈 보안 카메라 영상을 이용하기 시작했다\"고 언급합니다. 따라서 많은 미국인이 당연하게 가지고 있는 비합리적 검색받지 않음의 권리가 허약해지고 있을 수도 있습니다.\n\n중국은 자국 국민에게 이 모니터링 기술을 사용함과 동시에 세계 최대의 AI 기반 감시 장비 공급 업체가 되었다고 안데르센은 말합니다. 말레이시아에서는 알리바바의 시티 브레인 플랫폼과 같이 쿠알라룸푸르 경찰서에 얼굴 인식 기술을 도입하고 있습니다. 싱가포르의 11만 개의 가로등은 안데르센이 보고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 생성적 AI\n\n오픈AI가 2021년에 ChatGPT를 출시하자, \"생성적 AI\"가 즉시 주목을 받았습니다. 대중들에게 상상력뿐만 아니라 심장과 마음까지 사로잡아, 다운로드 현상이 됐죠.\n\nDall-E, Stable Diffusion, Midjourney와 같은 텍스트 대 이미지 솔루션이 ChatGPT를 빠르게 따랐습니다. 이 도구들은 사용자에게 간단한 텍스트 프롬프트로부터 즉시 사실적인 이미지를 빠르게 생성할 수 있는 놀라운 기술임을 입증했습니다.\n\nCNBC의 Arjun Kharpa에 따르면, ChatGPT 출시 후 몇 달 뒤에는 중국 기술 거물인 알리바바, 바이두, JD.com, 넷이스가 유사한 제품을 출시할 의향을 밝혔다고 합니다. 하지만 그들이 진짜로 할 수 있을까요? \"중국 기술 기업들은 새로운 규제 상황에 적응해야 하며, 그들의 ChatGPT 응답에 대한 발표가 조심스러웠던 것은 이 현실을 반영한 것입니다,\" Kharpal은 보도했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기업들은 포괄적이고 창의적인 AI 플랫폼을 개발하고 있지 않습니다. 이는 베이징의 인터넷 검열 기관들에 문제를 일으킵니다. 그 대신, 알리바바와 넷이즈는 해당 기술을 응용 프로그램 특정 용어로 이야기하고 있다고 Kharpal이 말합니다. 이러한 기업들이 창의적인 AI 분야를 지배할 수는 없습니다. 하지만, 그들이 가진 선택사항은 무엇인가요? 그들은 모든 종류의 정보에 자유롭고 공정한 접근이 필요한 해당 기술에 대한 수준에서 경쟁하기가 어렵습니다. ChatGPT 및 Perplexity와 같은 미국 기업들에 한 점!\n\n\"작년 동안 다양한 정부 기관들에 의해 기술 플랫폼과 AI 알고리즘에 대한 규제에 대한 관심이 집중되었는데, 주요 기술 플랫폼들은 논쟁에 휩쓸리는 채팅 봇/창작 AI 도구를 내놓음으로써 주목을 받고 싶어하지 않습니다,\" 컨설팅 회사 Albright Stonebridge의 기술 정책 담당자인 폴 트리올로는 CNBC에 말했습니다. 지난 몇 년 동안 이러한 기업들은 규제의 엄중한 시험을 받았습니다. 그러나 이는 또한 중국이 세계를 강탄할 혁명적 제품을 만드는 것이 얼마나 어려울지를 보여주는 사례입니다.\n\n# 중국: 장기 계획가?\n\n서양에서 널리 퍼진 중국 비즈니스에 대한 맥시엄이 있습니다. 그것은 중국이 장기적으로 플레이하고 있는 반면 서양 기업들은 목요일 이후를 생각하지 못한다는 것입니다. 이는 매우 잘못된 견해입니다. 세계에서 상위 10곳의 기업 중 9곳은 미국 기업입니다(Saudi Arabia의 Aramco는 그 목록에서 유일한 미국 외 기업입니다). 이들 기업이 그 목록에 올라간 이유는 단기적인 사고를 한 것이 아니라, 그들의 예측 능력이 최고라는 것입니다. 오늘날의 많은 기업의 성공에 큰 역할을 하는 소프트웨어 분석 사업은 미국, 유럽, 일본 전역에 흩어진 칩 제조업체, 소프트웨어 개발자 및 대학 연구소에서 시작되었지만 대부분 미국에서 시작되었습니다. 인터넷은 미국에서 발명되었으며, 실리콘 칩도 그랬습니다. 미국은 AI 및 양자 컴퓨팅 분야에서 선두를 달리고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n미국과 비교했을 때 중국은 독립적인 사법부, 강력한 기업 지적재산권 보호, 정치적 비즈니스 접근 방식, 그리고 다가오는 분기 보고서만 고려하는 혁신적인 마인드에서 부족한 면이 있습니다. 이러한 것들은 장기적인 비즈니스 성공을 위해 필요한 중요한 기반 요소입니다.\n\n중국에서는 정부 규제가 갑자기 나타날 수 있습니다. 기업들은 이제 사업과 관련된 경험이 거의 없는 정부 관료를 이사로 임명받아야 하는 상황이 발생하고 있습니다. 중국은 강력한 창업 생태계가 부족합니다. 기업들은 서양에서처럼 잠재적인 사업 기회를 탐색할 여지를 거의 제공받지 못합니다.\n\n과거에는 실리콘밸리의 벤처 자본가들이 많은 중국 스타트업에 자금을 지원해왔지만, 현재 그 자금은 말라가고 있습니다. 그 자금은 현재 미국, 유럽, 심지어 일부 아시아 기업들로 재투자되고 있습니다. 중국은 대만만만 베이 에어리어(심천, 홍콩, 마카오로 구성)를 구축하고 있을 수 있지만, 실리콘밸리의 벤처 자본가들을 대체할 벤처 공산주의자는 나타나지 않을 것입니다.\n\n지적 재산권을 훔치는 것은 빠른 단기적인 재정 이득을 제공할 수 있지만, 실질적인 연구 및 개발에 투자하는 것이 훨씬 더 장기적인 전략입니다. Cyfirma의 중국 지적 재산권 도난 보고서에 따르면 \"지적 재산권 도난은 중국이 경쟁 국가들의 기업들을 대체하기 위해 사용하는 더 큰 산업 전략의 일부입니다. 미국 기업들만 하더라도 지적 재산권 도난으로 매년 4분의 1에서 5분의 1조 달러의 손실이 발생합니다.\" 보고서는 또한 \"중국 기업들이 자주 지적 재산권 보호를 무시하며, 국가 전반적으로 외국 기업, 주로 서양(그리고 점점 더 아시아) 기업들로부터 지적 재산권을 빼앗기 위한 정책들을 오랜 기간 도입해왔다\"고 덧붙였습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n조지 매그너스는 그의 기사인 중국 경제: 카산드라 vs. 폴리안나에서 중국 경제의 문제로 \"지방 정부, 국영 기업 및 부동산의 과도한 부채, 소비 부족, 과도한 투자 및 자본 분배 부정, 인구 통계의 고속 노화의 결과, 생산성 성장의 약세, 더 많은 통제와 억압적인 지배, 민영 기업 및 기업가들의 지배, 그리고 최근에는 상업 및 비즈니스 분리, 이제 위험 감소로 재브랜딩된 것들을 이 논의합니다.\" 이것들은 사소한 문제가 아닙니다.\n\n중국의 경제적 상황이 너무 심각해져서, 이제 경제가 파괴된 것이 아니냐는 질문이 아닌 누가 이 일을 일으켰는지에 관한 문제입니다. 외교문제지에서 피터슨 연구소의 아담 포센은 중국의 최근 \"고 코로나 정책과 국가 통제로 인해 민간 기업과 기업가들의 신뢰가 저해되어 중국 경제의 활력을 저해시켰다\"고 주장합니다.\n\n그러나 외교위원회의 존유안 리우와 평가대학의 마이클 페티스는 상황을 다르게 보고 있습니다. 그들은 중국의 경제적 문제는 코로나 이전부터 시작되었으며, 중국은 10년 이상 시스템적으로 결함이 있는 경제 발전 모델을 가지고 있었다고 말합니다.\n\n모두 동의하는 점은 중국의 문제들이 쌓여 있다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 자녀 정책은 역사적으로 중요한 인구 틱택 타임봄으로 터져나가고 있습니다. 세계사에서 어떤 나라보다도 중국에서 노인 인구가 더 많아지고 있습니다. 사회 안전망이 부족한 나라에서 이는 매우 우려스럽습니다.\n\n\"누워서 먹고 살기\"와 \"그냥 말리기\" 운동, 젊은이들이 여기저기로 야심을 내어 밀어붙이는 것 같은 동작은 최근 대학 졸업생들이 자녀를 갖는 욕망을 줄이고 있습니다. 그래서 다음 세대에 도움이 되지 않습니다.\n\n2021년, 정부는 급성장하던 온라인 과외 산업을 거의 순식간에 없애버렸습니다. 우연의 법칙의 또 다른 사례로, 과도한 등록금 때문에 중국인들이 자녀를 낳기를 꺼려한다는 우려로, 정부의 권위적 조치로 과외 시장이 붕괴될 수도 있었습니다. 이는 물론 과외를 더 비싸지게 만들었습니다.\n\n2023년 12월 22일, 정부가 게임 산업에 새로운 규정을 도입하여 플레이어가 인게임 구매에 얼마나 돈을 쓸 수 있는지 제한했습니다. 이 조치는 게임 개발사의 수익을 강타하여 800억 달러의 주식시장 폭락을 초래했습니다. 우연의 법칙이 다시 한 번 끔찍한 모습을 드러냈습니다. 하루 후에 중국 국가출판방송총국은 손을 뒤로 젔지만 이미 피해는 입혔습니다. 시장이 가장 혐오하는 것은 침범적인 정부보다는 우유부단한 정부일 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중국은 외국 투자가 절실한 상황이지만, 투자자들을 위협하는 불투명한 법률을 제정하고 있습니다. 중국이 외국 자본을 절실하게 원하는 이유가 있습니다. 중국인들은 자국 주식 시장에 투자하지 않습니다. 중국 기업의 재무제표가 적어도 의심스러우며, 사실상 부정확하다는 것을 알고 있습니다. 투자자와 비즈니스 커뮤니티 간에 신뢰가 없습니다. 코로나 이전 중국 전역에서 빠르게 성장하던 커피 회사 럭킨 커피는 추후 머디 워터스 단기매도자들 보고서에 걸려, 나는 닝보에서 돌아온 몇 달 후, 약 $310 백만 달러를 조작했다고 알려진 소송에 1억 7500만 달러로 청산했습니다.\n\n“사막에 공산당원을 일시킨다면 모래도 바닥난다,”는 농담은 중국이 직면하는 모든 해결할 수 있는 문제들을 생각할 때 참된 말임을 보여줍니다. 왜 14억 명의 정부가 개발자들이 30억 명분의 주택을 건설하도록 허용하겠습니까? 왜 중국은 송장 도시를 채우는 수백만 개의 빈 집을 가지고 있을 뿐만 아니라 세계에서 유일한 고스트 크레이퍼인 골든 파이낸스 117을 갖고 있습니까?\n\n## 중국 함정\n\n야망과 열망은 쉽게 표현할 수 있지만, 건강한 통치와 견고하고 유연한 기관에 의존한 상황에서 실현하기는 엄청나게 어렵다고 말합니다. 다시 말해, 말은 쉽지만 실행은 굉장히 어렵다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n혹은 안 좋아하더라도, 현대 중국은 언제나 80년대와 90년대 일본과 비교될 것입니다. 많은 사람들이 알고 있는 기업 이름을 가졌다고 해서 반드시 지속적인 성공으로 이어지는 것은 아니라고 말하는 Magnus의 주장입니다. 알리바바, 텐센트, 그리고 바이두는 단지 소니, 토요타, 히타치, 미쓰비시의 중국 버전일 뿐입니다. 확실히 좋은 기업들이지만, 애플, 구글, 페이스북, 또는 마이크로소프트가 너무 걱정해야 할 상대는 아닙니다.\n\n몇십 년 전, 미국 리더들은 일본 conglomerates이 그들을 이기는 비경쟁력으로 두려워했습니다. 그러나 Magnus가 가리키듯이, \"세계적인 기술 기업을 갖는다고 해서 일본 경제의 주춧돌인 시스템적 거시경제 문제에 대한 보호가 보장되는 것은 아니었습니다. 바로 그 이후에 일본 경제가 발목을 잡힌 것입니다.\" 중국 기업들도 오늘날의 고마진 기술을 제조하기 위해 필요한 정교한 칩이 제공되지 않는 한 비슷한 위기에 직면할 수 있습니다.\n\nMagnus는 \"현대 중국이 1980년대와 1990년대의 일본의 틀에 완벽하게 들어맞지는 않지만, 중국의 인구 1인당 소득은 미국의 20% 미만입니다; 1990년대 초의 일본은 1.5배 더 크었습니다. 둘 다 \"높은 부채, 과대평가된 부동산, 자본 분배의 잘못, 고령화, 그리고 개혁을 위한 기관적 또는 정치적 장벽\" 등의 경제 모델은 매우 유사해 보입니다,\"라고 말합니다. Magnu는 경고합니다. 중국의 부동산 거품은 일본 시기만큼 강하게 충실히 늘어선 것이 아니라, 기업 부채가 작고 정부가 경제를 조절하는 데 사용할 도구가 더 많지만, 중국이 디플레이션과의 싸움을 벌이는 동안 일본화의 위험이 높아진다는 Magnus의 경고입니다.\n\n\"중국의 GDP가 미국을 넘어서기 위한 창문이 거의 닫혔습니다. 그 격차는 실제로 넓어질 수 있으며, 2023년 처음으로 30년만에 그렇게 된 것처럼,\"며 Magnus가 말합니다. 중국 경제에 대한 이러한 비관적 평가는 현재의 중국 감시자들 사이에서 흔한 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n“투자자들이 대부분의 중국 주식 시장을 포기했고, 외국 기업들은 투자와 생산을 아시아를 넘어 다른 국가로 다변화하는 추세에 있다”고 Magnus가 지적했다. 중국 경제는 급격히 사라지기엔 너무 크지만, 평평해지고 있는 것으로 보인다.\n\nMagnus는 “한 나라의 안보는 중장기 경제 전망만큼 안전하다. 이들은 몇 십 년 동안 한 것보다 취약한 상태이다. 발전 모델을 철저히 재시동하지 않는 한, 중국이 두려워하는 중간소득 함정이 점점 가까워지고 있다”고 경고했다.\n\n오늘날 중국과 미국은 경제적으로 정반대편에 있는 것으로 보인다. 미국 시장은 거의 매일 새로운 최고점을 경신했으며(일본도 마찬가지), 한편으로 중국 주식 시장은 10년 최저점으로 떨어졌다. 홍콩 항셍지수는 영국이 식민지로 돌려준 때보다 낮은 수준으로 하락했다. 이것이 현재 홍콩과 중국의 경제 상황에 대해 많은 양을 이야기한다면, 아무 것도 듣기 않은 것이다. 그러나 주식 시장은 늘 선두적인 경제 지표로 여겨졌다. 두 경제에 대해 지금 어떤 것을 보고 있는지 궁금해진다.\n\n## 참여상”\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금까지 나의 스마트 시티 탐험상(참가자 트로피로도 불리는 (그림 10 참조))은 몇 년 전에 리즈 여행을 상기시키는 나의 아파트 선반 위에 있습니다. 서서히 서부인 참가자들이 이벤트에 참석하기를 갈망하다 보니 비용을 부담해주고 재미있는 상품도 공식식으로 수여되는 것을 생각해볼 때 정말로 값진 경험이었습니다!\n\n중국은 2019년 9월 코로나 바이러스가 확산되기 2개월 전, 그 후에는 전 세계적으로 유행이 급격히 확산되기 시작함으로써 극적으로 변화했습니다. 당시에 만난 몇 명의 연락처는 소식을 들을 수 없게 되었습니다. 그래도 Ningbo 스마트 시티 여행은 일자리 발견으로 이어지지 않았지만 눈을 떴게 해주는 경험이었습니다.\n\n지금의 복잡한 기술 세계에서 중국이 경쟁할 수 있을까요? 물론 가능합니다. 중국은 몇 가지를 올바르게 진행하고 있습니까? 물론 그렇습니다. 그러나 중국의 기업 문화에는 미래의 AI 전쟁에서 승리하는 데 도움이 되지 않는 어떤 점이 제한적으로 존재한다고 생각합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프랑스 황제가 되기 전 나폴레옹은 중국 지도를 가리키며 말했습니다. \"여기 잠자고 있는 사자가 있다. 그를 자도하라. 그가 깨어날 때 세계를 흔들 것이다.\" 나폴레옹은 두 세기 전에 이 말을 했고, 그 이후로 중국은 많은 나라들보다 격동한 시기를 보냈습니다. 중국 19세기는 식민 지배, 아편전쟁, 그리고 백년굴이 가득 찼습니다. 20세기는 일본 제국주의 지배, 잔인한 내전, 그리고 모든 것을 흔들어놓은 공산주의 전환으로 이어졌는데, 이는 기근과 수백만 명의 사망을 야기했습니다.\n\n오늘날 중국은 미국과 경제적 우월을 다툴만큼 준비되어 있지 않습니다. 그녀는 풍부하고 민첩한 나라조차 극복하기 어려울만한 많은 도전에 직면하고 있습니다.\n\n피낭당을 빠져나가는 비행기에서 난 닝보의 하늘을 바라보면서, 청 일본 폭격기가 닝보에 온천기로 오염된 벼루병 살충제를 투하하려던 그 시절을 상상했습니다. 일본은 바이오 및 화학 무기를 금지하는 제네바 협약에 조인하지 않았기 때문에, 이별하여 민간인 수천 명을 살해하는 것을 제한하는 요소가 없었습니다. 실제로 기도 경계와 생화학 무기를 개발하고 중국 민간인을 살해했다. 명백히 도덕은 선량한 이들을 살해하는 데에 강력한 금지 요인이 되지 않았습니다.\n\n안더슨에게 중국의 AI 우월에 대한 상승은 위협적인 가능성입니다: 중국의 정치 구조는 기술의 최악의 잠재력을 자극시키기보다 제한하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n중국은 이제 더 이상 다른 사람들의 기술을 그대로 복사하고 표절하고 위조하는 나라가 아닙니다. 그것은 자체적으로 혁신의 세력이 되었지만, 중국 지도자로서 미국을 최초의 방문지로 선택한 이유에 대해 질문 받았을 때 덩샤오핑의 말을 기억했으면 좋겠습니다. \"미국의 동맹국들은 모두 부유하고 강하며, 중국이 부유하고 강하고 싶다면 미국이 필요했다\"고 그가 대답했습니다. 이것은 우리 모두가 많은 것을 배울 수 있는 교훈입니다. 인공지능이 우리가 많은 사람들이 우려하는 대로 잘못되면, 인류는 모든 친구를 필요로할 것입니다.\n\n독자 여러분, 읽어주셔서 감사합니다. 그리고 이 쇼에서 가장 어린 참가자 중 한 명의 작별 조언 (네, 보통이란 지겨움):\n\n![The New Cold War: Artificial Intelligence](/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_5.png)\n\n그레이 에어리어는 훌륭한 사이버 보안 및 컴퓨터 과학 게시물들의 모음입니다. 그레이 에어리어의 작가가 되고 싶다면 이 양식을 작성해보세요! 그레이 에어리어가 기사를 발행할 때마다 업데이트를 받으시려면, 저희 트위터 페이지 @TGAonMedium을 확인해주세요.\n","ogImage":{"url":"/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png"},"coverImage":"/assets/img/2024-05-23-TheNewColdWarArtificialIntelligence_0.png","tag":["Tech"],"readingTime":17},{"title":"사람형 로봇 5종 소개","description":"","date":"2024-05-23 17:03","slug":"2024-05-23-Top5HumanoidRobots","content":"\n## \"로봇에 관심을 갖는 이유는 그들이 우리 자신의 반영이기 때문입니다.\"\n\n인간 형상의 로봇은 인간과 비슷합니다. 이 로봇들은 몸통, 머리, 두 팔, 그리고 두 다리를 가지고 있지만 일부는 상체만을 가지고 있는 경우도 있고 얼굴에 눈과 입이 있는 로봇들도 있어 더 사람과 비슷하게 보입니다.\n\n![로봇 이미지](/assets/img/2024-05-23-Top5HumanoidRobots_0.png)\n\n인간 형상의 로봇이라는 아이디어는 오랜 기간동안 여러 문화에서 나타났습니다. 가장 초기 언급 중 일부는 기원전 4세기에 그리스 신화와 중국의 오래된 텍스트에서 찾아볼 수 있습니다. 이후 중국, 그리스, 이탈리아, 일본, 프랑스 등 여러 곳에서 실제 인간 형상의 로봇 프로토타입이 만들어졌습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n오늘날의 인간형 로봇은 다양한 모양과 크기로 다양하며 많은 분야에서 널리 사용됩니다. 이들은 연구, 우주 탐사, 개인 보조, 간병, 교육, 엔터테인먼트, 수색 및 구조, 제조, 유지보수, 홍보, 특히 의료 분야에서 도움을 줍니다.\n\n이들 목적으로 디자인된 인간형 로봇 중 일부 예시를 소개합니다.\n\n## 1. 핸슨 로보틱스의 소피아\n\n소피아는 핸슨 로보틱스에서 만든 잘 알려진 인간형 로봇으로, 첫 번째 여성형 인간형 로봇입니다. 그녀는 세계를 여행하며, 코스모폴리탄 매거진 표지에 등장하며, 심지어 유엔에 연설도 했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nhttps://www.youtube.com/shorts/-tb5OoNu1-4\n\n소피아는 시각적, 감정적, 그리고 대화형 데이터를 처리하여 사람들과 더 잘 상호작용할 수 있습니다.\n\n그녀는 미국의 '투바이트 쇼'에 여러 번 출연하여 짐미 팰런(Jimmy Fallon)과 가위바위보 대결을 벌였고, 나쵸 치즈에 대한 생각을 공유하며 듀엣을 부르기도 했습니다.\n\n![이미지](/assets/img/2024-05-23-Top5HumanoidRobots_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n소피아는 우리가 인공지능의 미래에 걸친 희망의 대사로서 본다. 또한 Engineered Arts가 개발한 Ameca는 인공지능 연구 및 인간-로봇 상호작용 탐구의 도구로 사용되는 고급 인공지능 연구용 로봇입니다.\n\n## 2. 엔지니어드 아츠의 Ameca\n\n![이미지](/assets/img/2024-05-23-Top5HumanoidRobots_2.png)\n\n엔지니어드 아츠가 설립된 영국 콘월의 Ameca는 AI 및 기계학습을 테스트하는 플랫폼으로 설계된 최첨단 휴머노이드 로봇입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n방 안의 움직임을 추적하고 얼굴과 목소리를 인식할 수 있는 센서를 갖고 있어요.\n\n[링크](https://youtube.com/shorts/Hx_8hRLgFYo?si=QJmZCDF0E3irTda-)\n\n알른은 사람들과 자연스럽게 상호 작용하며 그들의 감정을 감지합니다. 또한 웃음, 놀라움, 놀라움 등과 같은 일반적인 표현을 보여 줄 수 있고, 몸짓으로는 으쓱거리기, 따라하기, 하품 등을 할 수 있어요.\n\n## 3. Aura at Sphere\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n라스베이거스에있는 스피어(Sphere) 로비에서 떠들어 대는 여성 인간형 로봇인 오라(Aura)를 소개합니다. 그녀는 행사 장소의 대변으로 활동하며 손님들과 상호 작용하며 '스피어(Sphere)' 체험의 중요한 부분입니다.\n\n![image](/assets/img/2024-05-23-Top5HumanoidRobots_3.png)\n\n오라는 파란 눈을 가진 완전히 밀린 머리를 하고 있습니다. 그녀는 키 약 6피트로 아메카(Ameca)와 매우 비슷해 보입니다.\n\n오라는 놀라운 손 제스처를 사용하며 이는 완벽하게 표현된 얼굴 표정과 조화를 이룹니다. 그러나 정말 사람들의 주목을 끄는 것은 그녀의 로봇 손입니다. 손목, 손가락 및 팔의 부드러운 움직임은 여러분을 경탄하게 만들 것입니다. 이 능력은 정말로 영감을 줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nhttps://youtube.com/shorts/dTfEgteIBwI?si=Xg3ZboWli_-f-Ciq\n\nAura는 모든 이런 물리적 기적에도 불구하고 발을 움직이지 않고 제자리에 서 있습니다.\n\n## 4. 중국과학기술대학의 지아 지아\n\n지아 지아는 중국과학기술대학이 만든 인간형 로봇으로, 익숙함과 기이함 사이의 가늘고 위축된 선을 걷고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-23-Top5HumanoidRobots_4.png](/assets/img/2024-05-23-Top5HumanoidRobots_4.png)\n\n약 4.6피트(약 1.4m) 높이로 관절을 가진 상체를 가지고 있는 Jia Jia는 걷고, 말하며, 기본적인 감정을 표현할 수 있습니다. 그녀는 눈을 자유롭게 움직이며, 입술 움직임은 말에 거의 완벽하게 동기화되어 있습니다.\n\nJia Jia는 직접 인간과 상호작용할 수 있어 질문에 답하고, 작은 표정을 표현할 수 있습니다.\n\n## 5. 지능로봇실험실(Erica by The Intelligent Robotics Laboratory, Osaka University)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n에리카는 오사카 대학 인공 지능 로봇 연구소 소장 인 이시구로 히로시가 만든, 23세 여성을 닮은 사실적인 안드로이드입니다.\n\n[에리카 데모 비디오](https://youtube.com/shorts/wR1s1Mr_7oo?si=MrdP1PX-vWwsTrAZ)\n\n에리카는 인간 뉴스 앵커를 대신해서 방송에 출연할 예정입니다. 그녀는 스크립트된 글을 낭송하고 의자에 앉을 수 있어 텔레비전에 적합합니다.\n\n에리카는 사람들과 대화할 수 있는데, 그녀가 이룰 수 있는 것은 대화를 이끌어내는 알고리즘, 얼굴 인식 기술 및 적외선 센서 덕분에 에리카는 방 안의 얼굴을 추적할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아직 그녀는 팔을 움직일 수는 없지만, 에리카는 얼굴 특징, 목, 어깨 및 허리를 독립적으로 움직일 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-Top5HumanoidRobots_5.png)\n\n✍ 이러한 인간형 로봇이 미래에 좋다고 생각하시나요, 그렇지 않나요?\n\n참고: 인간형 로봇이 더욱 사람처럼 보이도록 만들어질 때, 그것들은 안드로이드로 불립니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n의견을 남겨주세요. 궁금해요.\n\n만약 이 글을 좋아하시고 저를 지원하고 싶으시다면, 아래 사항을 확인해주세요:\n\n👏 이 글에 클랩을 많이 눌러주셔서 이 글이 주목받을 수 있도록 도와주세요\n\n🔔 더 많은 인간적인 글을 보시려면 저를 Medium에서 팔로우해주세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n🔔Instagram에서 제 계정을 팔로우해주세요! instagram.com/coolbot369\n\n🔔동영상 시청하고 구독하기🔗www.youtube.com/@CoolBot369\n","ogImage":{"url":"/assets/img/2024-05-23-Top5HumanoidRobots_0.png"},"coverImage":"/assets/img/2024-05-23-Top5HumanoidRobots_0.png","tag":["Tech"],"readingTime":7},{"title":"라즈베리 파이 마스토돈 인스턴스 백업은 잘 정리되어 있나요","description":"","date":"2024-05-23 17:00","slug":"2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted","content":"\n![Raspberry Pi Mastodon Instance](/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png)\n\n얼마 전에 나는 라즈베리 파이에 나만의 Mastodon 인스턴스를 설정했어. 왜냐하면? 음, 나는 인터넷에서 기본 통신 인프라를 되찾는 것이 중요하다고 생각하기 때문이야. 게다가, 거대한 분산 네트워크에서 자신의 소셜 미디어 노드를 설정하는 것은 백엔드 아키텍처에 대해 배울 수 있는 좋은 기회야. 좋은 소식은, 상대적으로 쉽고 보람있어! 지난해 4월에 파이를 설정한 후, 전혀 신경 쓸 일이 없었어.\n\n하지만, 물론, 문제가 발생하기도 해. 그리고 여기서 이야기하고 싶은 것이 바로 그거야. 당신이 자체 호스팅된 인스턴스가 고장났을 때 어떻게 되는지, 다시 가동하는 것이 얼마나 어려운지에 대해 이야기할 거야. 이 기사에서는 나의 경험을 공유하고 라즈베리 파이 Mastodon 인스턴스를 운영하는 데 궁금해하는 사람들을 위한 조언 몇 가지를 전할 거야. 하지만 그 전에, 내 설정에 대해 조금 언급해야 해.\n\n## 어떤 것을 사용하고 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모든 것을 직접 실행하고 있기 때문에 '클라우드' 컴퓨팅 서비스를 사용하지 않고 모든 서버 구성 요소에 대한 책임을 짊어지고 있어요. 주변에 Raspberry Pi 4 Model B(2018)가 있었는데, 표준 라우터와 독립적인 USB-C 전원 공급 장치에 연결했어요. 라우터 연결에는 이더넷 케이블 및 Pi 위치에 따라 Wi-Fi를 사용했어요. Mastodon이 사용하는 포트(80번은 HTTP, 443번은 HTTPS, 22번은 SSH)를 라우터로 포워딩하고 Raspberry Pi의 로컬 주소(터미널에서 hostname -I를 입력하여 확인)로 포트를 포워드하도록 라우터를 구성하세요. 그런 다음 도메인 이름의 DNS 설정을 사용하여 같은 포트를 라우터의 공개 IP 주소로 포워드하세요.\n\n![Raspberry Pi Image](/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_1.png)\n\nRaspberry Pi는 훌륭한 서버로 사용될 수 있어요. 이 작고 저렴한 컴퓨터는 놀랄 만큼 빠르고 8GB의 램을 갖추고 있어요. 작은 Mastodon 인스턴스에 충분하죠. 작은 친구는 주 시스템 드라이브로 32GB SD 카드(Kingston Canvas Select Plus)를 사용했어요. 이 SD 카드에 대해서는 조금 더 말씀드리겠지만, 괜찮긴 하지만 화려하거나 빠르지는 않아요. 제 운영 체제는 SD 카드에 미리 설치된 기본 Raspbian Linux에요. Mastodon을 가동하기 위해 joinmastodon.org에서 '기기 준비' 및 '소스로부터 설치' 문서를 따라했어요(그 순서대로). 상대적으로 간단했어요.\n\n## 메모리 고려하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋아요, 좀 더 깊게 메모리에 대해 알아봅시다. 당신이 Mastodon 인스턴스를 직접 호스팅해야 한다고 생각하면 중요하니까요. 여기서 기본 설정과는 달라지는 부분이 있습니다.\n\n내가 하는 것처럼 소수의 계정만 호스팅하더라도, 당신의 인스턴스는 상당량의 기가바이트 데이터를 누적하게 됩니다. 이 데이터는 한편으로는 텍스트 상태를 저장하는 PostgreSQL 데이터베이스에 (타임라인을 이루는 텍스트 상태뿐만 아니라 모든 시스템 환경 및 설정) 저장되고, 다른 한편으로는 ~/live/public/system이 기본값인 폴더에 저장됩니다 (프로필 사진, 공유 미디어 등이 이 폴더에 저장됩니다). 특히 후자의 폴더는 소셜 네트워크가 커짐에 따라 매우 부피가 커진다는 것을 상상할 수 있을 것입니다 — 어떤 사람들은 비디오를 올리는 걸 좋아하잖아요.\n\n라즈베리 파이가 메모리 부족 상태가 되는 것을 방지하기 위해, 라즈베리 파이의 USB 포트에 연결된 1테라바이트 삼성 포터블 SSD를 추가했습니다. (위의 그림에서 파이는 드라이브 위에 놓여 있습니다.) 이제 부피가 커진 /system/ 폴더가 여기에 위치하게 됩니다. 기본 설정을 재정의합니다. Mastodon이 미디어를 저장하는 위치는 ~/live/.env.production 파일에서 변경할 수 있으며, Mastodon을 위한 Nginx 구성에 별칭을 추가해야 할 수도 있습니다. 나의 경우에는 .env.production 파일에 설정하였습니다:\n\n```js\nPAPERCLIP_ROOT_PATH= /media/mastodon/system\nPAPERCLIP_ROOT_URL= /storage/system\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nNginx 구성 파일에 다음 줄을 HTTP 및 HTTPS 구성에 모두 추가해주세요:\n\n```js\nlocation /storage {alias /media/mastodon; }\n```\n\n또한 외부 드라이브가 올바르게 마운트되었는지 확인하고 사용자 mastodon이 해당 드라이브에 쓸 수 있도록 해야 합니다.\n\n처음 드라이브를 추가했을 때 제 서버는 행복하게 실행되었지만 미디어 업로드를 할 때마다 500 오류가 발생했습니다 (비슷한 오류를 만나면 터미널에서 journalctl -u mastodon-web -f를 실행하여 해당 인스턴스와 주고받는 HTTP 요청의 실시간 뷰를 확인할 수 있습니다). 제 경우 문제는 소프트웨어를 실행하는 'mastodon' 사용자가 마운트된 SSD 드라이브에 쓰기 권한이 없었기 때문입니다! 업로드가 실패한 것이 당연했습니다. 이 문제를 해결하기 위해 /etc/fstab 파일(리눅스의 마운트 포인트를 정의하는 파일)에서 드라이브 항목을 수정하여 모든 사용자에게 읽기 및 쓰기 권한을 부여했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n/dev/sda1 /media vfat rw,user 0 0\n\n이 설정은 몇 번의 시행착오로부터 나왔어요; 적어도 내 시스템에는 작동합니다. 만약 내가 무언가를 형편없게나 안전하지 않게 한 것 같다면 알려주세요! 하지만 이 메모리 솔루션은 더 이상 버벅거리거나 스크롤하는 데에 한 년 이상 사용해보니 잘 작동하고 있어요.\n\n/system/ 폴더는 52.7 GB를 차지하고있어요 (~디스크 공간의 5%). 캐시된 미디어 파일을 31일 후에 지우도록 인스턴스를 구성했기 때문에 급속히 커지는 것이 아니에요. 여기에는 충분한 공간이 있어요. 반면에, 내 Postgres 데이터베이스는 여전히 기본 위치인 /var/lib/postgresql/11/main에 저장되어 있어요. (내 Postgres 버전이 11이라면서요, 잘 작동하더라구요.) 현재 Postgres 데이터베이스의 크기는 2.55 GB이에요. 이는 32 GB 시스템 드라이브의 8%에 해당하기 때문에 큰 재앙은 아니지만, 내 취향에는 너무 비대해요 (때로는 드라이브 공간이 17% 밖에 남지 않는 경우도 있었어요). 언젠가는 Postgres 데이터베이스를 외부 SSD로 이동하고 싶다고 생각해요. 그건 그때의 이야기거든요.\n\n라즈베리 파이 마스토돈 인스턴스에 추가 드라이브를 연결하는 것은 약간 복잡할 수 있고, 정확한 설정은 외부 드라이브의 파일 시스템에 따라 다를 거에요. 하지만 이렇게 하는 것은 거의 항상 좋은 생각이에요 (아래에서 설명할 이유 중 하나 때문이죠).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 하지만 백업은 하시나요?\n\n처음에 말했듯이, 잘못된 일이 벌어질 때에 대해 이야기하려고 합니다. 자체 인스턴스를 호스팅할 때는 서버가 다운될 경우를 생각해봐야 합니다. 시간이 흘러 저는 방대한 소셜 미디어 네트워크를 구축했고 거의 매일 친구들과 소통하기 위해 Mastodon을 사용합니다. 그리고 내일 그 모든 것이 여전히 남아있을 것을 누군가에게 의존할 수 없습니다. 다시 말해, 백업 계획이 없다면 인스턴스에 호스팅된 계정들과 함께 하룻밤 사이에 모든 것을 잃을 수 있습니다: 게시물, 사진 및 중요하게도 인스턴스의 사람들이 구축한 네트워크까지.\n\n따라서 Raspberry Pi Mastodon 인스턴스를 설정하기 전에 위험 평가를 수행해야 합니다. 내 구성을 고려할 때 무엇이 잘못 될 수 있는지 스스로에게 묻고, 그럴 경우 얼마나 나쁠지 고민해보고, 일이 심각하게 잘못될 때 원하는 기능을 복구하는 데 필요한 것이 무엇인지 생각해보세요. 분명히, 일부 문제에는 인내가 필요할 수도 있습니다(예: 인터넷 제공업체 문제). 그러나 다른 문제는 남아있는 것에서 서버를 복원해야 할 수도 있습니다.\n\n모든 경우들 중에서, 저는 가장 준비하고 싶었던 위험은 SD 카드의 고장이었습니다. SD 카드에서 리눅스를 실행하는 것은 SD 카드가 불안정하기 때문에 좋은 생각은 아닙니다. 그러나 어쨌든, 그것이 Raspberry Pi가 하는 일이기 때문입니다. 따라서 SD 메모리가 복구할 수 없을 정도로 고장 나서 리눅스와 Mastodon 소프트웨어를 처음부터 다시 설치해야 하는 상황이 오면 필요한 것이 무엇일까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위험을 완화하기 위해 두 가지 방안을 고안했어요.¹ 첫 번째는 이미 이야기한 것처럼, /system/ 폴더를 훨씬 신뢰할 수 있는 SSD 드라이브로 이동하는 거예요. SD 카드 고장 시에도 미디어 저장 공간이 안전하게 보호될 거예요. 좋아요. 그런데 PostgreSQL 데이터베이스는 어떨까요? 이 데이터들은 아마도 인스턴스가 구축한 소셜 네트워크를 정의하는 만큼 더 중요할 거예요.\n\n결국, 매일 데이터베이스를 자동으로 백업하기로 결정했어요. 매일 밤 실행되는 쉘 스크립트를 작성했어요 (/etc/crontab에 추가했어요). 이 스크립트는 Postgres 데이터베이스 내용(기본적으로 mastodon_production이에요)을 외부 SSD에 저장된 백업 파일로 덤프하는 거예요.\n\n이를 위해 다음 명령어를 스크립트로 작성했어요: sudo -u postgres pg_dump mastodon_production ` /media/backup/mastodon_production.dump. 추가적인 안전을 위해 파일을 gzip(암호화)하고 FTP를 통해 다른 원격 서버로 보내는 거예요. 그 서버에는 가장 최근의 .dump 파일 세 개를 유지하고, 이전 .dump 파일은 자동으로 삭제돼요. (언젠가 스크립트를 GitHub에 공유할 수도 있겠지만, 특별한 것은 아니에요.)\n\n마침내, 지난 주에 위험이 현실이 되었어요. 라즈베리 파이의 SD 카드가 고장나서 기계에 완전히 접근할 수 없었어요. 제 백업 전략은 충분했을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 백업에서 복원하기\n\n정확한 대답은: 아니요. 제 백업 전략이 충분하지 않았습니다. 그러나 운이 좋게도 충분히 가까웠습니다. 온라인으로 돌아왔고, 이것은 마스토돈 인스턴스를 복구하는 것이 어렵지 않음을 증명했습니다. 심지어 Raspbian 운영 체제와 마스토돈 소프트웨어를 처음부터 다시 설치해야 하는 경우에도요. 단지 백업 전략을 설정하기만 하면 됩니다.\n\n그래서 무엇이 있었을까요? 제 추측으로는 Pi를 잘못해서 전원을 끄면 SD 카드의 부트 섹터가 손상되었습니다. 이것은 매우 쉽게 발생합니다. 많은 사람들이 전원이 차단된 후 데이터를 잃은 적이 있습니다. 고려하지 못하고 나는 Pi를 다른 위치로 옮기기 위해 연결을 해제하고 싶을 때 데스크톱에서 '종료'를 클릭했습니다. 이후에야 작년에 스스로에게 남겨둔 안전하게 종료하는 가장 좋은 방법에 대한 메모를 읽었는데, 터미널에서 sudo shutdown -h now만 사용해야 한다는 것을 알게 되었습니다(-h 옵션은 시스템이 하고 있는 모든 일을 중단하도록 안내합니다). 우측. 어쨌든, 시스템을 부팅하지 못하게 되었고, 따라서 더 이상 마스토돈 서버를 실행할 수 없었습니다.\n\n무엇을 해야할까요? 조금 당황해서 맥에서 Ubuntu를 실행하는 VirtualBox 머신을 사용하여 카드를 외장 드라이브로 마운트하고 표준 디스크 도구와 터미널에서의 디스크 관리 프로그램 fsck로 수리하려고 노력했습니다. 운이 없었습니다. 그러나 Ubuntu에서는 /home/ 폴더를 포함하는 파티션을 마운트하고 액세스할 수 있었기 때문에 복구에 필요한 몇 가지 파일을 아직 백업하지 않은 상태로 구할 수 있었습니다. 경성.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 파일이 필요할까요? 이 질문에 대한 최상의 답변을 Mastodon 문서에서 찾았어요. '새로운 장치로 이전하기'라는 설명에서 찾았죠. 왜냐하면 Raspbian과 Mastodon 소프트웨어를 처음부터 다시 설치해야 할 때 해야 할 일이기 때문이에요. 새로운 장치를 설정하고 있는 것이거든요. 제 구성을 고려하면, 서버 기능을 간단하게 복구하기 위해 필요한 것들의 목록은 아래와 같아요:\n\n- Postgres 데이터베이스 덤프 (기본적으로 이것은 mastodon_production입니다)\n- /system/ 폴더의 복사본 (기본적으로 이것은 ~/live/public/system입니다)\n- ~/live/.env.production 파일의 복사본\n- Nginx 구성 파일의 복사본 (기본적으로 /etc/nginx/sites-available/mastodon)\n\nSD 카드가 다운됐을 때, 외부 SSD에 (1)과 (2)가 포함되어 있었어요. 이건 꼭 필요한 파일이에요. 그리고 (3)과 (4)에 대해서는, 다행히 다른 리눅스 장치에 장착했을 때 카드로부터 여전히 이 파일들을 검색할 수 있었어요.\n\n해당 추가 파일들은 제 인스턴스의 특정 구성 설정을 포함했어요. 외부 미디어 폴더를 위한 여분의 사항, 알림에 사용된 SMTP 서버의 세부사항, 활성 브라우저 세션, 이중 인증 및 푸시 알림을 위한 '비밀' 등을 포함해요. 꼭 필요한 건 아니지만, 이 파일들이 있어서 복구가 가능했던 것이죠. 이 모든 정보를 필요한대로 정확히 가지고 있어서 제 삶을 훨씬 쉽게 만들어줬어요. 큰 도움이 되었어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 긴급한 상황에서 해당 파일이 필요할 것이라는 사실은 나를 놀라게 할 필요가 없었습니다. 왜냐하면 이전에 내가 필요에 맞게 조정한 파일들이었기 때문이었습니다! 그럼에도 불구하고, 그들을 백업 루틴에 포함시키는 것을 잊었습니다.\n\n이것이 내 초기 백업 계획이 잘못된 한 가지였습니다. 하지만 적어도 똑같이 중요한 것: 필요할 때까지 백업을 테스트해보지 않았습니다. 실제 문제가 발생했을 때, 가장 중요한 백업 파일은 있음에도 불구하고 어떻게 복원해야 할지 몰랐습니다. 이로 인해 상황이 불필요하게 스트레스 받는 일이 되었습니다.\n\n나에게는 앞으로의 교훈입니다. 단순히 백업 파일을 생성했다고 만족하지 마세요. 이러한 파일을 만드는 이유인 백업 복원 프로세스의 다른 절반을 놓치지 마세요. 백업만 하는 것이 아닌, 백업으로부터 데이터를 복원하는 연습도 해보세요. 백업을 의존하기 전에 해당 백업에서 데이터를 복원하는 연습을 하세요. 그렇게 하였더라면 내 백업이 충분하지 않다는 것을 알게 되었을 것입니다. 실제 문제가 발생했을 때 무엇을 해야 하는지 알고 있다면, 상황을 훨씬 효율적으로, 더 적은 스트레스와 땀으로 복구할 수 있습니다.\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이번에는 이야기가 행복한 결말을 맞이했습니다. 이 글을 쓰는 이유 중 하나는 아마도 나중에 이와 비슷한 문제에 직면할 수도 있기 때문이고, 필요한 단계를 상기시키기 위해 매뉴얼이 있으면 유용하다고 생각하기 때문입니다. 물론 당신에게도 도움이 될 수 있기를 바라겠습니다.\n\n특히, 라즈베리 파이에 자신만의 Mastodon 인스턴스를 실행하는 것이 덜 두렵다면 고대로 해보길 희망합니다. 진정으로 말하면, 온라인 커뮤니케이션을 제어하기 위한 실험을 해볼 수 있습니다. 결국, 머신에 접근 권한을 잃는 것이 처음에 보이는 것만큼 무섭지 않습니다. 시작하기 전에 위험 평가를 수행하고, 신뢰할 수 있는 백업 루틴을 시행하고, 즉시 필요해지기 전에 백업에서 머신 복원을 실습하는 시간을 갖는다면 문제 없습니다. 이것들을 수행한다면, 작은 파이의 성능을 신뢰할 수 있을 것입니다.\n\n¹ 시도해보지 않은 대안적인 전략: SD 카드를 정기적으로 복제하는 것입니다. 복제본이 있다면 원본이 손상된 경우 카드를 교체하고 다시 사용할 수 있습니다. PostgreSQL 덤프 대비 정기적인 복제가 번거로울 것으로 생각해서 이 방법을 선택하지 않았습니다. 하지만 여기에 좋은 대안이 있는 것을 우연히 놓친 것일 수도 있습니다.\n\n² 공식 문서의 목록이 더 상세하지만, 다른 몇 가지 기본 설정을 사용했기 때문에 다른 여러 파일들에 대해 걱정할 필요가 없었습니다. 그러나 서버 사용을 시작하기 전에 '새로운 머신으로 이동' 문서를 읽고, '서버 백업' 문서를 읽는 것이 좋습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png"},"coverImage":"/assets/img/2024-05-23-TheRaspberryPiMastodonInstanceDoYouHaveYourBackupsSorted_0.png","tag":["Tech"],"readingTime":11},{"title":"Splunk 인덱서로 PI 웹 로그 보내기","description":"","date":"2024-05-23 16:58","slug":"2024-05-23-SendingPIWebLogstoSplunkIndexer","content":"\n\u003cimg src=\"/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_0.png\" /\u003e\n\n이것은 메인 시리즈 \"Hackable LEGO Train\"의 작은 부분이 될 예정입니다.\n\n다음이 메인 시리즈입니다:\n\n[Hackable Lego Train | Part 1 | Stux | by Stux | May, 2024 | Medium](https://medium.com/)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사의 주요 포인트:\n\n- Kali Purple 다운로드\n- Kali Purple 설치\n- \"웹 서버\"에서 앱 로그 파일을 가져오기 위한 Cron 작업 설정\n- Kali-Purple에 Splunk Universal Forwarder 설치\n- 웹 로그를 주요 Splunk 인덱서로 전송\n\n부가 사항: 이전에 작성한 기사를 따랐다고 가정합니다. 이미 라즈베리 파이와 Python 웹 사이트가 작동하고 로그를 기록 중이어야 합니다. 또한 이는 공개 웹 사이트가 아니므로 모든 것이 내부 네트워크에 있습니다. 대부분의 경우 \"IP-링\"은 동일한 서브넷에 있으며 네트워킹을 많이 구성할 필요가 없었습니다.\n\n![이미지](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n참고: 물리적 PI가 SCP를 통해 로그를 Host B (Virtual Kali-Purple)로 전송하고 있습니다. Host B는 Splunk Universal Forwarder가 실행되고 있어 로그를 Host A (물리적 Windows) Splunk Indexer로 전송하고 있습니다.\n\n시작해봅시다!\n\n## Kali Purple\n\nKali Purple을 다음 사이트에서 다운로드하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nKali Linux 2023.1 릴리스 (칼리 보라 \u0026 파이썬 변경 사항) | Kali Linux 블로그\n\n![image](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_2.png)\n\n새 운영 체제를 다운로드하고 설치한 후에 일할 수 있게 됩니다.\n\n제가 전체 네트워크를 실행하는 데 VMware Workstation을 사용했습니다. 가능하다면 여러분도 이를 추천합니다. 하지만 더 저렴한 옵션이 많이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cspan\u003e/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_3.png\u003c/span\u003e\n\n그래서, 이 시점에서 우리는 다음을 가지고 있습니다:\n\n- Kali Linux가 실행되는 Raspberry PI\n- Python 웹 앱이 실행되는 Raspberry PI\n- 로그를 파일에 기록하는 \"access\" 로그\n- Kali Purple가 우리 네트워크의 다른 곳에서 자체 컴퓨터(가상)로 실행 중\n\n# Kali-Purple + PI 로그 파일 전송\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n**참고:** Kali Purple로 로그를 보내는 이유는 라즈베리파이에 Splunk UF가 작동하지 않아서 새 Linux 배포판을 재설치한 것입니다(문제 해결). 따라서 나중에 라즈베리파이 OS 기본 설정에서 작동할 수 있습니다.\n\n크론 작업을 실행하여 로그 파일을 가져올 때마다 매번 암호를 입력해야 하는 번거로움이 없도록 하려고 합니다. 또한 코드 어디에도 암호를 하드코딩하고 싶지 않습니다.\n\n- SSH 키 생성: 두 대의 컴퓨터 간에 암호 없는 인증을 위해 SSH 키가 설정되어 있는지 확인합니다.\n- 스크립트 생성: SCP 작업을 수행할 스크립트를 작성합니다.\n- 크론 작업 설정: 원하는 주기로 스크립트를 실행할 크론 작업을 구성합니다.\n\n다음과 같이 진행할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 단계 1: SSH 키 생성하기 (아직 설정되지 않은 경우)\n\nKali-Purple (192.168.184.133)에서:\n\n```js\nssh-keygen -t rsa\nssh-copy-id stux@192.168.12.194\n```\n\n# 단계 2: SCP 스크립트 생성하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 코드를 한국어로 친근하게 번역해 드리겠습니다:\n\n스크립트를 만들어주세요 (예: /home/youruser/scp_pull_log.sh):\n\n```bash\n#!/bin/bash\n\n# 변수 정의\nREMOTE_USER=\"stux\"\nREMOTE_IP=\"192.168.12.194\"\nREMOTE_FILE=\"/home/stux/big-caboose/app.log\"\nLOCAL_DIR=\"/var/log/\"\nLOCAL_FILE=\"app.log\"\n\n# SCP 실행\nscp ${REMOTE_USER}@${REMOTE_IP}:${REMOTE_FILE} ${LOCAL_DIR}${LOCAL_FILE}\n```\n\n스크립트를 실행 가능하게 만들어주세요:\n\n```bash\nchmod +x /home/youruser/scp_pull_log.sh\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 단계 3: 크론 작업 설정하기\n\n첫 번째 기계에서 사용자의 크론탭을 편집하십시오:\n\n```js\ncrontab - e;\n```\n\n![이미지](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 라인을 추가하여 cron 작업을 예약합니다 (예: 매 시간마다 실행되도록):\n\n```js\n0 * * * * /home/youruser/scp_pull_log.sh\n```\n\n# Kali-Purple Splunk Universal Forwarder 구성\n\nSplunk Universal Forwarder를 다운로드하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSplunk Downloads 페이지를 방문하여 Linux 배포판에 맞는 버전을 다운로드하세요. 또한, 링크가 있다면 wget을 사용하여 직접 다운로드할 수도 있습니다.\n\n계정을 만들어야 합니다.\n\n```js\nwget -O splunkforwarder-\u003cversion\u003e-Linux-x86_64.tgz \"https://download.splunk.com/products/universalforwarder/releases/\u003cversion\u003e/linux/splunkforwarder-\u003cversion\u003e-Linux-x86_64.tgz\"\n```\n\n![이미지](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스플렁크 유니버설 포워더를 설치하세요:\n\n```js\ntar -xvf splunkforwarder-\u003cversion\u003e-Linux-x86_64.tgz -C /opt\ncd /opt/splunkforwarder/bin\n./splunk start --accept-license\n```\n\n\u003cimg src=\"/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_6.png\" /\u003e\n\n# 단계 2: 스플렁크 유니버설 포워더 설정\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSplunk Indexer를 설정해보세요:\n\n```js\n./splunk add forward-server 192.168.12.172:9997 -auth admin:changeme\n```\n\n모니터링할 디렉토리를 추가해보세요:\n\n```js\n./splunk add monitor /var/log/\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n부팅할 때 Splunk Forwarder를 시작하도록 설정하십시오:\n\n```sh\n./splunk enable boot-start\n```\n\n# 입력/출력 파일 구성\n\n# inputs.conf\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 파일은 포워더가 모니터링하고 전달해야 하는 데이터를 지정하는 데 사용됩니다.\n\n$SPLUNK_HOME/etc/system/local/ 디렉터리에 위치한 inputs.conf 파일을 생성하거나 편집하십시오.\n\n```js\nsudo vi /opt/splunkforwarder/etc/system/local/inputs.conf\n```\n\n다음 내용을 추가하여 /var/log/ 디렉터리를 모니터링하십시오:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[monitor:///var/log/]\ndisabled = false\nindex = default\nsourcetype = log\n\n## outputs.conf\n\n이 파일은 포워더가 데이터를 전송해야 하는 대상을 지정하는 데 사용됩니다.\n\n$SPLUNK_HOME/etc/system/local/에 위치한 outputs.conf 파일을 만들거나 편집하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nsudo vi /opt/splunkforwarder/etc/system/local/outputs.conf\n\n다음 내용을 추가하여 데이터를 192.168.12.172로 전송하도록 설정하세요:\n\n[tcpout]\ndefaultGroup = default-autolb-group\n\n[tcpout:default-autolb-group]\nserver = 192.168.12.172:9997\n\n[tcpout-server://192.168.12.172:9997]\n\nSplunk UF를 다시 시작하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```shell\ncd /opt/splunkforwarder/bin\nsudo ./splunk restart\n```\n\n# 단계 3: Splunk 인덱서에서 입력 구성\n\nSplunk 인덱서(192.168.12.172)에서:\n\n참고: 이 단계에 대해 더 자세히 설명은 아래에 제공됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스플렁크 웹 인터페이스에 로그인하세요.\n\n![이미지](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_7.png)\n\n설정으로 이동하여 `데이터 입력` \u003e `전달된 데이터` \u003e `새 전달된 데이터 입력`으로 이동하세요.\n\n![이미지](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n새 데이터 입력을 로그로부터 전송하는 데이터 포워더를 구성하는 지시에 따르세요.\n\n![이미지1](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_9.png)\n\n![이미지2](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_10.png)\n\n# 단계 4: 구성 확인\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Universal Forwarder(192.168.184.133)에서:\n\n```js\n./splunk list forward-server\n```\n\n색인기(192.168.12.172)가 목록에 나열되어 활성화되어 있는지 확인해야 합니다.\n\n# Windows에서 Splunk Enterprise 설정 - 호스트 A\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 단계 1: Splunk Enterprise 다운로드 및 설치\n\nSplunk Enterprise 다운로드:\n\n- Splunk 다운로드 페이지에 방문합니다.\n- Windows 버전을 선택하고 설치 프로그램을 다운로드합니다.\n\nSplunk Enterprise 설치:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 다운로드한 설치 프로그램을 실행하세요.\n- 설치 마법사 지시에 따르세요. 사용권 계약에 동의하고 설치 디렉토리를 선택해야 합니다.\n- 관리자 사용자 이름과 암호를 설정하세요.\n\n# 단계 2: Splunk Enterprise 시작 및 로그인\n\nSplunk Enterprise 시작:\n\n- 설치 후 Splunk Enterprise가 자동으로 시작됩니다. 그렇지 않은 경우 수동으로 시작할 수 있습니다. Splunk 설치 디렉토리로 이동하여 splunk.exe start를 실행하세요. (예: C:\\Program Files\\Splunk\\bin)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSplunk 웹 인터페이스에 로그인하세요:\n\n- 웹 브라우저를 열고 http://localhost:8000 으로 이동하세요.\n- 설치 중에 설정한 admin 자격 증명으로 로그인하세요.\n\n# 단계 3: Splunk Enterprise 데이터 수신 설정\n\nSplunk Enterprise에서 데이터 수신 활성화합니다 (위에서 언급한 이미지와 함께):\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 설정으로 이동하여 `전달 및 수신` 수신 구성 ` 새 수신 포트를 구성하세요.\n- 포트 9997 (또는 원하는 다른 포트)를 추가하세요.\n\n구성 저장:\n\n- 설정을 저장하여 Splunk Enterprise가 전달자로부터 수신되는 데이터를 포트 9997에서 수신하도록 설정하세요.\n\n- 인덱서(192.168.12.172)에서:\n- 인덱서 로그를 확인하거나 Splunk 웹 인터페이스에서 데이터를 검색하여 Universal Forwarder로부터 데이터를 수신 중인지 확인하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image 1](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_11.png)\n\nOr:\n\n![image 2](/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_12.png)\n\nWe now have a PI website logging data, Kali-Purple using SCP at a regular interval pulling the log and finally sending the log via Splunk UF to the Splunk Indexer. We can now monitor all traffic from the website.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 내용을 친근한 톤으로 한국어로 번역하면 다음과 같습니다.\n\n다음 단계는 더 취약한 웹사이트를 만들고(그래서 우리가 해킹할 수 있게) 포트 접속, 더 나은 웹 로그, 보안 이벤트 로그 등 전반적인 PI 로그를 더 상세하게 추가하는 것입니다.\n\n읽어 주셔서 감사합니다. 다른 누군가도 시도 중에 문제가 발생하면 부디 연락해 주세요. 제가 도와드릴 수 있는 대로 도와드리고 가능한 한 많은 조언을 제공할 테니까요! 즐기면서 진행하세요! — 스툭스\n","ogImage":{"url":"/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_0.png"},"coverImage":"/assets/img/2024-05-23-SendingPIWebLogstoSplunkIndexer_0.png","tag":["Tech"],"readingTime":14},{"title":"로컬 LLM 및 다양한 시스템에서 VLM 실행 시 처리량 성능 비교","description":"","date":"2024-05-23 16:57","slug":"2024-05-23-ComparingThroughputPerformanceofRunningLocalLLMsandVLMondifferentsystems","content":"\n데이터 엔지니어로서, 저는 몇 가지 생성적 AI 모델을 시험해 보고 로컬에서 모델을 설치/실행하는 것에 매혹을 느낍니다. Large Language Model (LLM)과 Vision-Language Model (VLM)은 가장 흥미로운 모델입니다. OpenAI는 ChatGPT 웹사이트와 모바일 앱을 제공합니다. Microsoft는 Windows 11 Copilot을 우리가 사용할 수 있도록 만들었습니다. 그러나 우리는 어떤 데이터가 인터넷으로 전송되고 그들의 데이터베이스에 저장되는지를 제어할 수 없습니다. 그들의 시스템은 오픈 소스가 아니며, 마치 신비로운 검은 상자와 같습니다.\n\n일부 관대한 회사(Meta 및 Mistral AI 같은) 또는 개인들이 자신들의 모델을 오픈 소스로 공개하고, 적극적인 커뮤니티가 도구를 단계별로 구축하여 우리가 집 컴퓨터에서 LLM과 VLM을 쉽게 실행할 수 있도록 도와줍니다. Raspberry Pi 5와 8GB RAM은 이 기사에서 시험되었습니다 (Raspberry Pi에서 로컬 LLM 및 VLM 실행). 이는 신용 카드 크기의 소형 Single Board Computer (SBC)입니다. 나는 더 저렴한 컴퓨터 장비/솔루션이나 가상 머신을 찾아 성능을 시험해보고, 돈을 지불하는 대가에 좋은 가치를 제공하거나 심지어 일반 대중에게도 제공하도록 하고 싶습니다. 고려해야 할 사항은 텍스트 출력 속도, 텍스트 출력 품질 및 비용입니다.\n\n생성된 내용을 평가하는 작업은 다른 연구 기관에서 수행됩니다. 예를 들어, 이 기사에서 mistral-7b가 llama2-13b보다 지식, 추론 및 이해력에서 능가한다고 언급됩니다. https://mistral.ai/news/announcing-mistral-7b/. 그래서 나는 LLM 테스트에 mistral과 llama2를 포함했습니다.\n\nOllama는 현재 macOS, Linux 및 Windows의 WSL2에서 실행할 수 있습니다. WSL2에서 메모리 사용량 및 CPU 사용량을 제어하기 어렵기 때문에 WSL2의 테스트를 제외하였습니다. 생태계에서는 여러 LLM과 VLM 모델을 다운로드할 수 있습니다. 그래서 여러 시스템에서 다양한 AI 모델을 테스트하기 위해 Ollama를 벤치마킹 테스트 베드로 사용합니다. 설치는 매우 간단합니다. 터미널에서 다음을 실행하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncurl https://ollama.ai/install.sh | sh\n```\n\n저는 Ollama LLMs에서 생성된 토큰/초의 처리량을 테스트하는 도구를 개발했습니다. 이 코드(ollama-benchmark)는 Python3로 작성되었으며 MIT 라이선스 하에 오픈 소스로 공개되어 있습니다. 추가해야 할 기능이 더 있거나 수정해야 할 버그가 있다면 알려주세요. 텍스트 출력 품질을 측정하기 어려울 수 있으므로 이 실험에서는 텍스트 출력 속도에 초점을 맞춥니다. (더 높은 토큰/초가 좋음)\n\n테스트에 사용된 기계 또는 VM의 기술 사양\n\n- 8GB RAM이 장착된 Raspberry Pi 5 (Ubuntu 23.10 64비트 운영 체제) 쿼드코어 64비트 Arm CPU\n- Windows 11 랩탑 호스트에 설치된 VMware Player 17.5를 통해 4코어 프로세서와 8GB RAM이 장착된 Ubuntu 23.10 64비트 운영 체제\n- Windows 11 데스크톱 호스트에 설치된 VMware Player 17.5를 통해 8코어 프로세서와 16GB RAM이 장착된 Ubuntu 23.10 64비트 운영 체제\n- Apple Mac mini (Apple M1 칩) (macOS Sonoma 14.2.1 운영 체제) 8코어 CPU(성능 코어 4개, 효율성 코어 4개), 8코어 GPU, 16GB RAM\n- NVIDIA T4 GPU (Ubuntu 23.10 64비트 운영 체제), 8 vCPU, 16GB RAM\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비교를 더 효과적으로 하기 위해 Raspberry Pi 5에 우분투 23.10 64비트 운영체제가 설치되었습니다. 아래 비디오에서 운영체제 설치 단계를 따를 수 있습니다.\n\nOllama 웹사이트 llama2 모델 페이지에는 다음과 같은 내용이 언급되어 있습니다.\n\n## 메모리 요구 사항\n\n- 7b 파라미터 모델은 일반적으로 적어도 8GB의 RAM이 필요합니다.\n- 13b 파라미터 모델은 일반적으로 적어도 16GB의 RAM이 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 테스트할 모델\n\n- mistral:7b (LLM)\n- llama2:7b (LLM), llama2:13b (LLM)\n- llava:7b, llava:13b (이미지에서 텍스트로, 이미지로부터 질의응답) (VLM)\n\n메모리 제약 사항을 고려하여, 서로 다른 기기에서 성능을 테스트하고 싶은 모델입니다.\n\n샘플 프롬프트 예시는 benchmark.yml에 저장되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\nversion: 1.0\nmodeltypes:\n  - type: instruct\n    models:\n      - model: mistral:7b\n    prompts:\n      - prompt: 달걀빵을 처음부터 굽는 방법을 단계별 가이드를 작성해주세요.\n        keywords: 요리, 레시피\n      - prompt: 다음 문제를 해결하는 파이썬 함수를 개발하세요. 수도쿠 게임\n        keywords: 파이썬, 수도쿠\n      - prompt: 경제 위기에 관한 대화를 나누는 두 캐릭터의 대화를 만들어주세요.\n        keywords: 대화\n      - prompt: 숲에 용갈퀴가 살고 있습니다. 이야기를 계속해주세요.\n        keywords: 문장 완성\n      - prompt: 미국 시애틀로 4명을 위한 항공편을 예약하고 싶습니다.\n        keywords: 항공편 예약\n```\n\n각 라운드마다 5가지 다른 프롬프트가 사용되어 출력 토큰 수를 평가합니다. 이 5가지 수의 평균이 기록됩니다. 저는 처음으로 라즈베리 파이 5를 실행했고, 여기에 기록된 동영상이 있습니다.\n\n다양한 모델의 시스템별 토큰 속도에 대한 벤치마크 요약\n\n## AI 모델 (LLMs 및 VLM) 추론 처리량 성능 결과에 대한 생각\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 위의 동영상에서 확인할 수 있듯이, 계산 활용은 주로 GPU 코어 및 GPU VRAM에서 발생합니다.\n- 추론을 더 빨리 실행하려면 강력한 GPU를 선택하세요.\n- 사람과 AI 모델 간의 편안한 상호작용은 초당 7토큰의 처리량이 필요합니다 (예시는 비디오 5에서 제공됨). 대부분의 사람이 따라갈 수 없는 13토큰의 속도는 비디오 6에서 보여주었습니다.\n- 미래 OS 중 Copilot이라는 AI 지원이 내장된 OS는 최소 16GB RAM이 필요할 것입니다. AI의 출력은 의미가 있는 것이며 신뢰성이 있어야 하며, 너무 빠르지도, 너무 느리지도 않아야 합니다. 이 부분은 Microsoft가 발표한 소식과 일치합니다: (Microsoft, AI PC용 RAM으로 16GB를 기본 설정 — 해당 기기에는 40 TOPS의 AI 계산 능력이 필요하다고 보도).\n\n## 결론\n\nLLM을 로컬에서 실행함으로써 데이터 보안과 개인 정보 보호를 강화할 수 있을 뿐만 아니라, 전문가, 개발자 및 열정가들을 위한 무한한 가능성을 열어줍니다. 이 처리량 성능 기준에 따라, Raspberry Pi 5를 LLM 추론 기계로 사용하지 않겠습니다. 왜냐하면 너무 느리기 때문입니다. LLM과 VLM을 Apple Mac mini M1 (16GB RAM)에서 실행하는 것이 충분합니다. LLM 추론을 더 빠르게 실행하려면 강력한 기계가 필요하다면 GPU가 탑재된 클라우드 VM을 임대하세요.\n\n책임 성명: 저는 Ollama나 Raspberry Pi, Apple, Google과 관련이 없습니다. 모든 의견과 견해는 제 개인적인 것이며 어떤 조직도 대표하지 않습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-ComparingThroughputPerformanceofRunningLocalLLMsandVLMondifferentsystems_0.png"},"coverImage":"/assets/img/2024-05-23-ComparingThroughputPerformanceofRunningLocalLLMsandVLMondifferentsystems_0.png","tag":["Tech"],"readingTime":6}],"page":"64","totalPageCount":120,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"64"},"buildId":"JlBEgQDLGRx6DYlBnT8eD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>