<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/22" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/22" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_buildManifest.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기" href="/post/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법" href="/post/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Redis를 S3 Express로 재구축하기" href="/post/2024-06-19-RebuildingRedisonS3Express"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Redis를 S3 Express로 재구축하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Redis를 S3 Express로 재구축하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Redis를 S3 Express로 재구축하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다" href="/post/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기" href="/post/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS 인터뷰 질문 DAY_25 90" href="/post/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS 인터뷰 질문 DAY_25 90" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS 인터뷰 질문 DAY_25 90" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS 인터뷰 질문 DAY_25 90</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁" href="/post/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS 프로젝트 시간 예측 그건 그냥 제안일 뿐이에요" href="/post/2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS 프로젝트 시간 예측 그건 그냥 제안일 뿐이에요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS 프로젝트 시간 예측 그건 그냥 제안일 뿐이에요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS 프로젝트 시간 예측 그건 그냥 제안일 뿐이에요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="구글 드라이브를 무료 클라우드 저장 공간 솔루션으로 활용하여 머신 러닝 데이터 동기화를 자동화하는 방법" href="/post/2024-06-19-HowdidIuseGoogleDriveasafreecloudstoragesolutiontoautomatesyncingmyMachineLearningdata"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="구글 드라이브를 무료 클라우드 저장 공간 솔루션으로 활용하여 머신 러닝 데이터 동기화를 자동화하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-HowdidIuseGoogleDriveasafreecloudstoragesolutiontoautomatesyncingmyMachineLearningdata_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="구글 드라이브를 무료 클라우드 저장 공간 솔루션으로 활용하여 머신 러닝 데이터 동기화를 자동화하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">구글 드라이브를 무료 클라우드 저장 공간 솔루션으로 활용하여 머신 러닝 데이터 동기화를 자동화하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="퀘스트 3용으로 제작된 18가지 혼합 현실 게임을 소개합니다" href="/post/2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="퀘스트 3용으로 제작된 18가지 혼합 현실 게임을 소개합니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="퀘스트 3용으로 제작된 18가지 혼합 현실 게임을 소개합니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">퀘스트 3용으로 제작된 18가지 혼합 현실 게임을 소개합니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link posts_-active__YVJEi" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"미래 예약된 지연 크론 작업 처리를 위해 DynamoDB Streams 사용하기","description":"","date":"2024-06-19 12:13","slug":"2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs","content":"\n\n크론 작업, \"백그라운드 작업\" 또는 클라우드워치 이벤트 대신 유연한 일정에 필요한 작업을 수행하는 대체 수단입니다.\n\n많은 소프트웨어 시스템은 작업을 예약할 수 있는 메커니즘이 필요하며, \"크론\" (또는 AWS 클라우드의 클라우드워치 이벤트/예약된 작업) 또는 \"지연 작업\" 시스템은 일반적인 해결책입니다. 그러나 특정 유형의 작업에 대해 꽤 좋거나 분명히 크론보다 나은 대안이 있습니다. 해당 대안은 TTL(생존 기간)이 있는 DynamoDB 레코드 및 람다 함수로 처리된 DynamoDB 스트림을 사용하는 것입니다. 레코드의 TTL이 만료될 때 람다가 트리거되며, 그때 레코드를 필요에 따라 처리할 수 있습니다. 이러한 종류의 작업에는 어떤 작업을 할 수 있을까요? 어떤 작업에서는 잠재적으로 변경 가능하거나 동적이며 또는 \"x 분 후\" 유형의 일정이 필요한 경우가 있습니다. 가능한 고정된 크론 스타일 일정(예: 매주 화요일 정오에 실행) 대신에 유연한 일정을 원하는 작업에 적합합니다. 또한 개별화되거나 희소한 상황에 대해 매우 효율적이고 비용 효율적인 개별 레코드를 기반으로 트리거하는 것이 모든 레코드를 대상으로 프로세스를 실행하는 것보다 우수합니다.\n\n몇 가지 사용 사례 예시:\n\n- 이벤트 전 X일 또는 마감일 이후 X일 후에 메시지를 전송하는 알림 메시지 보내기.\n- X 시간 동안 독자적 상태/상태를 변경하거나 읽지 않은 경우 상태 변경하기.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTTL의 정밀도에 관한 중요한 주의 사항이 있습니다. 아래 중요한 주의 사항 섹션을 참조해주세요.\n\n# 기본 사용법\n\n기본 패턴은 특정 이벤트를 기반으로 DynamoDB 레코드를 생성/업데이트하고, 그 후 미래의 특정 시간에 어떤 일이 발생하길 원할 때입니다. 레코드에 TTL(생존 기간)을 설정하여 그 시점에 만료되도록 하고, 만료되면 DynamoDB가 레코드를 삭제합니다. 그런 다음 DynamoDB 테이블에 스트림을 활성화하고, 해당 삭제 이벤트를 처리할 람다를 스트림에 연결합니다. 람다에는 이 상황에 대한 특정 이벤트만 수신하도록 필터가 있어야 합니다(REMOVE 및 TTL 삭제 vs. 코드 삭제를 구분하는 필드 및 주 키에 대한 필터 설정이 있어야 합니다).\n\n![image](/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 경우 DynamoDB의 추가적인 이점은 이러한 레코드에 대해 PUT을 수행함으로써 이것이 \"업서트\"로 작동한다는 것입니다. 즉, 이를 유지하려면 이미 존재하는 레코드인지 확인하고 TTL을 업데이트하거나 새로운 레코드를 만들 필요가 없습니다 (예를 들어 대부분의 RDBMS에서 해야 하는 작업과 같은). \n\n# 예시\n\n위의 경우 #2를 기준으로 예시를 살펴보겠습니다. 이 경우가 더 복잡하여 이 기술의 장점을 잘 보여줍니다. 장치 읽기를 수신하는 시스템을 상상해보세요. 보통 하루에 한 번씩 읽기가 발생하며, 읽기가 일주일 동안 없는 경우 상태를 업데이트하고 경고를 생성하고자 합니다. 이러한 장치들은 높은 빈도로 읽기가 발생하지 않습니다(이 경우 농업 관수 시스템이거나, 원격 환자 모니터링 장치일 수 있습니다. 즉, 환자가 집에서 매일 혈압을 측정하겠다는 것입니다). 다음을 수행해야 합니다:\n\n- 읽기가 없는 경우 3일 후에 장치 상태를 \"연결 불가\"로 설정\n- 장치 관리자에게 7일 후에 경고를 발생시키고, 10일 후에도 여전히 오프라인인 경우에 다시 경고를 보냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPUT 메소드를 사용하여 시간 프레임(3, 7, 10일)마다 DynamoDB(DDB) 레코드를 세 개 PUT하면 이를 달성할 수 있습니다. 첫 번째 레코드는 도달할 수 없는 상태를 트리거하기 위한 것이고, 나머지 두 개는 경고를 위한 것입니다. 기기에서 읽기 값을 받을 때마다 이 작업을 수행하는데, 이렇게 함으로써 TTL을 연장합니다 (PUT은 같은 기본 키의 기존 레코드를 덮어씁니다). 그러나 갑자기 몇 일 동안 읽기 값을 받지 못하게 되었을 때, 즉 레코드가 업데이트되지 않았을 때는 우선 3일 항목의 TTL이 만료되어 DynamoDB 스트림으로 REMOVE 이벤트를 보내고, 람다로 전달하여 프로세스를 시작합니다.\n\n그래서 우리는 파티션 키(PK)와 소트 키(SK) 설계가 모두 있는 DDB 기본 키를 사용할 수 있는데, 이는 다음과 같습니다:\n\nPK: DEVICE#`소유자 ID`\n\nSK: `기기 ID`#`이벤트 ID`\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTTL: 유닉스 시대 시간, 초 단위 해상도입니다.\n\n당신의 요구에 따라 추가적인 속성을 갖고 있을 수 있으며, 일반적으로 PK 및 SK의 값에 대한 명시적 속성도 가지고 있습니다. 그렇게 함으로써 PK/SK에서 그 값을 분리해 내지 않아도 됩니다. 예를 들어, OwnerID, DeviceID, EventID와 종종 데브리 책에서 설명한 것처럼 유용한 유형 필드가 있을 것입니다.\n\n게다가, 장치가 더 이상 사용되지 않는 경우, 단순히 PK = DEVICE#`ownerid` 및 디바이스 ID의 begins_with를 사용하는 SK에 대한 DDB 레코드를 모두 삭제하여 이를 처리할 수 있습니다.\n\nDynamoDB 테이블에서 스트림을 활성화하고, 스트림에 람다를 연결하여 이벤트를 처리해야 합니다. AWS 문서 \"DynamoDB Streams\"와 \"AWS Lambda Trigger\"를 참조하세요. 기본적으로 람다는 DynamoDB \"이벤트\"를 모두 받아오게 되므로 삽입, 업데이트 및 삭제를 다루게 됩니다. 여기서 필터링이 필요합니다. 여기서는 최소한 REMOVE(삭제) 이벤트만 필터링하고자 합니다. 필터링은 람다에서 수행할 수 있지만, 이는 소요 비용이 큽니다. 왜냐하면 매번 레코드를 유지하기 위해 이 디자인으로 정기적으로 수행하고 있는 삽입/업데이트가 발생할 때마다 람다가 호출되기 때문입니다. 다행히도 \"Lambda Event Filtering\"을 통해 이벤트와 일치하지 않으면 람다가 호출되지 않도록 할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이벤트 전용 DynamoDB 테이블을 따로 사용한다면, 삭제 이벤트에 대한 필터만 필요합니다. 그러나 테이블 내에 다른 아이템이 있는 경우 (예: 단일 테이블 디자인을 사용하는 경우) 특정 레코드로 제한하기 위해 필터를 추가해야 합니다. 이 경우 PK가 'DEVICE#' 접두사를 가진 레코드만 일치하도록 \"접두사\" 필터를 사용하여 이 작업을 수행할 수 있습니다. AWS의 Lambda 이벤트 필터링을 다룬 이 튜토리얼을 참고하시기 바랍니다. 마지막으로, 반드시 해야 할 중요한 추가 필터링 사항이 있습니다. userIdentity 필드를 확인해야 합니다. DynamoDB Streams 및 Time To Live 문서에서 이에 대해 설명되어 있으며, 필터 구문을 보여줍니다. 예를 들어, Serverless Framework를 사용하는 경우, DynamoDB 스트림을 처리하는 람다는 다음과 같은 이벤트 정의를 갖게 됩니다:\n\n```js\n    events:\n      - stream:\n          type: dynamodb\n          batchSize: 20\n          enabled: true\n          arn:\n            Fn::GetAtt: [DeviceMonitorTable, StreamArn]\n          filterPatterns:\n            - eventName: [REMOVE]\n              dynamodb:\n                Keys:\n                  PK:\n                    S:\n                      - prefix: 'DEVICE#'\n              userIdentity: \n                type: \n                  - Service\n                principalId:\n                  - dynamodb.amazonaws.com\n```\n\n이 필터를 통해 람다가 처리해야 할 이벤트만 받게 됩니다. 그 후, 람다는 받은 레코드에 적절한 처리를 수행합니다 (아마도 이벤트 ID나 레코드 내의 다른 관련 데이터에 기반하여). 그 후에 장치가 계속해서 측정치를 갖지 않는 상태로 유지되거나 시리즈의 다음 DDB 레코드가 TTL에 도달하거나 등의 상황이 발생할 수 있습니다. 장치가 다시 사용되고 모든 레코드가 업데이트되거나 (첫 번째 레코드부터 시작하여 TTL에 도달한 레코드의 수에 따라) 다시 생성될 수 있습니다.\n\n# 중요한 한 가지 주의사항!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 솔루션에서 주의해야 할 중요한 점은 TTL이 정확하지 않고 만료 후 \"만료일로부터 몇 일 이내에\" 발생한다는 것이다. 이 문서에 따르면 정확한 타이밍을 기대하는 중요한 작업에는 사용하지 않는 것이 좋다. 그런데, 실제로, 두 가지 서로 다른 앱에서 확인했을 때, 이 작업은 대개 TTL만료 후 몇 분 안에 트리거된다. 테이블의 사용량에 따라 (즉, 정기 사용은 만료된 레코드의 정기적인 정리를 의미한다) 결정되는 것 같다. 이에 대해 더 나은 정보가 있다면, 의견을 달아주시거나 말씀해주세요!\n\n# 마지막으로\n\n이러한 지연 작업 시스템을 구축하는 것은 크론 스타일 접근 방식으로는 정말 고통스럽습니다. 하루에 한 번 또는 모든 시간 간격을 확실히 포함할 때의 빈도로 크론 작업을 수행해야 하기 때문입니다. 위의 예와 같은 \"일\" 단위 간격의 경우에는 그렇게 나쁘지 않을 수도 있습니다. 그러나 더 정확한 타이밍이 필요한 경우, 그냥 작동하지 않을 수도 있습니다. 게다가, 이러한 이벤트가 발생하는 빈도가 더 드문 경우, 필요 이상으로 크론 작업을 실행할 수도 있습니다. AWS 생태계에 속해 있다면, 저장 실행 작업에 대신 제3자나 패키지를 가져올 경우에 비해 사용하기가 매우 매력적으로 보입니다.\n\n게다가, 타이밍 간격이 구성 가능하면, 이것은 크론 스타일 시스템보다 처리하기가 훨씬 쉽습니다. 여러분의 수용할 수 있는 한계와 지정된 동작에 따라서, 기존 항목을 그대로 둘 수 있고 다음 장치 읽기(또는 DDB 레코드 쓰기를 트리거하는 것)에서 TTL을 간단히 업데이트하거나, 영향을 받는 레코드만 조정할 수도 있습니다(PK+SK 콤보를 사용하여 실제 시간 양에 의존하지 않는 것을 확인하세요. 따라서 저는 SK에서 이 측면을 \"이벤트 ID\"로 지정했습니다. \"3일\" 또는 다른 것이 변할 수 있는 \"3일\" 같은 것 대신 \"alert1\"을 사용할 것입니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방식은 이벤트 주도 스타일을 제공하며 놀라운 확장성을 제공하고 물론 서버리스 시스템과 잘 어울립니다.","ogImage":{"url":"/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png"},"coverImage":"/assets/img/2024-06-19-UsingDynamoDBStreamstoHandleFutureScheduledDelayedCronJobs_0.png","tag":["Tech"],"readingTime":6},{"title":"AWS에서 Terraform을 사용하여 Lambda 함수를 배포하는 방법","description":"","date":"2024-06-19 12:12","slug":"2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform","content":"\n\n서버리스 함수는 인프라 걱정 할 필요 없이 DevOps 및 SysOps에게 필수적입니다.\n\n우리는 Amazon Web Services (AWS) 람다 함수를 살펴보고, 어떻게 테라폼을 사용하여 AWS 람다를 배포할 수 있는지 알아볼 것입니다.\n\n![이미지](/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png)\n\n모든 자료에 대한 Github 링크: [https://github.com/batuhan-bulut/terraform-aws-lambda](https://github.com/batuhan-bulut/terraform-aws-lambda)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AWS Lambda란 무엇인가요?\n\nAWS Lambda를 사용하면 서버에 대해 걱정하지 않고 지원되는 언어로 스크립트를 실행할 수 있습니다. Node.JS, Python, C# 등으로 작성된 코드를 실행할 수 있습니다.\n\nLambda를 사용하면 다음을 수행할 수 있습니다.\n- 지역별 EC2 인스턴스 상태 확인\n- AWS CLI를 사용하여 일부 자동화 실행\n- AWS SQS로 작업 예약\n- 기타\n\n이런 가능성들로 AWS Lambda는 데브옵스 및 시스옵스 팀에 매우 중요한 역할을 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS 웹 사이트에서 GUI를 사용하여 AWS Lambda를 쉽게 배포할 수 있어요.\n\n여러 계정이 있고 동일한 Lambda를 다른 지역에 배포해야 한다면 어떻게 할 건가요? 하나씩 Lambda를 배포할까요?\n\n이때 IaC와 Terraform이 게임에 합류해요.\n\n# IaC란? (Infrastructure as Code)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nIaC를 사용하면 우리는 쉽게 환경 (개발, 테스트, 스테이징, 프로덕션 등)을 설정할 수 있어요. 인기 있는 공급 업체들은 요구 사항에 맞는 CDK(Cloud Development Kit)를 가지고 있어요.\n\n## 왜 테라폼이 중요한가요?\n\n예를 들어, AWS에 앱이 있고 (EC2, RDS, Lambda, SQS 등을 사용하는) 다양한 서비스를 사용한다고 가정해봅시다. AWS CDK로 이 애플리케이션을 쉽게 배포할 수 있어요.\n\n그런데 만약 경영진이 Azure, GCP 또는 다른 클라우드 공급업체로 전환하기로 결정한다면 어떻게 될까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS CDK에 대한 지식 대부분은 중요하지 않아요. 왜냐하면 해당 공급업체가 자체 CDK를 가지고 있거든요.\n\n여기서 Terraform이 우리의 워크플로에 합류하는 곳이에요.\n\n# Terraform이란?\n\n지식과 경험을 통해 Terraform을 사용하면 간단한 명령어로 많은 리소스를 관리할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 문서에서는 Terraform의 AWS 쪽에 중점을 둘 것입니다.\n\n# 불이 켜지면, 카메라 맞춰, 액션!\n\n주의하세요: 이 작업은 AWS 측에 비용을 발생시킬 수 있습니다.\n\n## 우리의 Terraform 코드는 무엇을 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- IAM 역할 제공\n- IAM 프로필 제공\n- 프로필에 IAM 정책 부착\n- 업로드용 ZIP 파일 생성\n- 람다 함수 생성\n\n이 문서에서는 하드코딩된 값 대신 변수를 사용할 것입니다. 이렇게 하면 다양한 설정으로 동일한 스크립트를 실행할 수 있습니다.\n\n이것은 우리의 terraform/main.tf 파일입니다. 우리 코드의 구조를 담고 있습니다.\n\n```js\nprovider \"aws\" {\n  region = var.region\n}\n\n# AWS Lambda를 위한 IAM 역할\nresource \"aws_iam_role\" \"terraform_lambda_iam_role\" {\nname               = var.terraform_lambda_iam_role.name\nassume_role_policy = var.terraform_lambda_iam_role.assume_role_policy\n}\n\n# 람다를 위한 새로운 정책 생성\nresource \"aws_iam_policy\" \"iam_policy_for_lambda\" {\nname         = \"iam_policy_${var.terraform_lambda_iam_role.name}\"\ndescription  = var.iam_policy_for_lambda.description\npolicy       = var.iam_policy_for_lambda.policy\n}\n\n# IAM 정책을 IAM 역할에 부착\nresource \"aws_iam_role_policy_attachment\" \"attach_iam_policy_to_iam_role\" {\nrole        = aws_iam_role.terraform_lambda_iam_role.name\npolicy_arn  = aws_iam_policy.iam_policy_for_lambda.arn\n}\n\n# Lambda에 업로드할 ZIP 파일 생성\ndata \"archive_file\" \"zip_python_lambda_code\" {\ntype        = \"zip\"\noutput_path = \"${path.module}/python/${var.zip_python_lambda_code.name}.zip\"\nsource_file = \"${path.module}/../${var.zip_python_lambda_code.name}.py\"\n}\n\n# Lambda 함수 생성\nresource \"aws_lambda_function\" \"terraform_lambda\" {\nfilename     = \"${path.module}/python/${var.zip_python_lambda_code.name}.zip\"\nfunction_name  = var.terraform_lambda.name\nrole        = aws_iam_role.terraform_lambda_iam_role.arn\nruntime     = var.terraform_lambda.runtime\nhandler     = \"${var.zip_python_lambda_code.name}.lambda_handler\"\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드 블록에서는 terraform/terraform.tf 파일에서 모든 변수를 읽습니다. 동일한 Terraform 파일을 프로덕션, 스테이징 또는 다른 AWS 지역과 같이 다른 환경에 대해 다양한 구성으로 실행할 수 있습니다.\n\n이 변수들을 읽기 위해서는 변수를 정의해야 합니다. “.tf” 파일을 사용하여 변수를 선언할 수 있습니다.\n\n위 코드에 대한 terraform.tf 파일이 다음과 같이 보입니다.\n\n```js\n변수 \"region\" {\n  type = string\n  설명 = \"AWS 지역\"\n  기본 = \"eu-central-1\"\n}\n\n변수 \"zip_python_lambda_code\" {\n  type = map(string)\n  설명 = \"Python 파일의 이름\"\n  기본 = {\n    name = \"index\"\n  }\n}\n\n변수 \"terraform_lambda_iam_role\" {\n  type = map(string)\n  설명 = \"aws_iam_role - terraform_lambda_iam_role 변수\"\n  기본 = {\n    name = \"Lambda-from-terraform\"\n    assume_role_policy = \u003c\u003cEOF\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n   {\n     \"Action\": \"sts:AssumeRole\",\n     \"Principal\": {\n       \"Service\": \"lambda.amazonaws.com\"\n     },\n     \"Effect\": \"Allow\",\n     \"Sid\": \"\"\n   }\n ]\n}\nEOF\n  }\n}\n\n변수 \"iam_policy_for_lambda\" {\n  type = map(string)\n  설명 = \"람다를 위한 IAM 정책\"\n  기본 = {\n    description = \"Terraform으로 생성된 IAM 정책\"\n    policy = \u003c\u003cEOF\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n   {\n     \"Action\": [\n       \"logs:CreateLogGroup\",\n       \"logs:CreateLogStream\",\n       \"logs:PutLogEvents\"\n     ],\n     \"Resource\": \"arn:aws:logs:*:*:*\",\n     \"Effect\": \"Allow\"\n   }\n ]\n}\nEOF\n  }\n}\n\n변수 \"terraform_lambda\" {\n  type = map(string)\n  설명 = \"람다를 위한 변수\"\n  기본 = {\n    name = \"Lambda_Terraform\"\n    runtime = \"python3.12\"\n    handler = \"index.lambda_handler\"\n  }\n}\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 파일에서는 변수와 그 기본 값들을 선언합니다. 테라폼에서는 다양한 유형의 변수를 선언할 수 있어요.\n\n더 많은 정보를 원하신다면 테라폼 문서를 확인해보세요.\n\n코드에 기본 값을 사용하고 싶지 않다면 기본 변수를 덮어쓸 terraform/vars.tfvars 파일을 추가할 수도 있어요. 이 파일의 내용은 일반적으로 \"key = value\" 형식입니다.\n\n여기 .tfvars 파일의 예시가 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nregion = \"us-east-1\"\n\nterraform_lambda= {\n    name = \"Override_Name\"\n    runtime = \"python3.9\"\n    handler = \"override.lambda_handler\"\n}\n```\n\n이렇게 하면 Terraform이 region 및 terraform_lambda 변수의 기본값을 재정의할 것입니다.\n\n참고: 이 예와 같이 terraform_lambda와 같은 객체에서 변수를 변경하려면 객체의 모든 변수를 전달해야 합니다. 그렇지 않으면 오류가 발생합니다.\n\n그리고 루트 폴더에 간단한 Python 앱을 index.py라는 이름으로 추가해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 간단한 Hello 함수\nimport json\n\ndef lambda_handler(event, context):\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Lambda에서 안녕하세요!')\n    }\n```\n\n다음은 폴더가 보이는 예시입니다\n\n\u003cimg src=\"/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_1.png\" /\u003e\n\n# 쇼타임!\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드를 실행할 준비가 되었습니다.\n\n먼저 테라폼 구성 파일이 포함된 작업 디렉터리를 초기화하기 위해 terraform init 명령을 실행해야 합니다.\n\n```js\n$terraform init\n\n백엔드 초기화 중...\n\n공급자 플러그인 초기화 중...\n- 이전 의존성 락 파일에서 hashicorp/aws의 이전 버전 재사용 중\n- 이전 의존성 락 파일에서 hashicorp/archive의 이전 버전 재사용 중\n- 이전에 설치한 hashicorp/aws v5.54.1 사용 중\n- 이전에 설치한 hashicorp/archive v2.4.2 사용 중\n\n테라폼이 성공적으로 초기화되었습니다!\n\n이제 테라폼을 사용할 수 있습니다. 인프라에 필요한 변경 사항을 볼려면 \"terraform plan\"을 실행해보세요. 이제 모든 테라폼 명령이 작동해야 합니다.\n\n테라폼의 모듈 또는 백엔드 구성을 설정하거나 변경한 경우, 작업 디렉터리를 다시 초기화하려면이 명령을 다시 실행하십시오. 잊어버릴 경우 다른 명령어가 감지하여 필요시 상기시켜줄 것입니다.\n```\n\n이후, 인프라 구조의 변경 사항을 확인하기 위해 terraform plan을 실행할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndata.archive_file.zip_python_lambda_code: 읽는 중...\ndata.archive_file.zip_python_lambda_code: 읽기 완료 소요 시간 0초 [id=111]\n\n테라폼은 선택한 공급업체를 사용하여 다음 실행 계획을 생성했습니다. 자원 작업은 다음 기호로 표시됩니다:\n  + 생성\n\n테라폼은 다음 작업을 수행할 것입니다:\n\n  # aws_iam_policy.iam_policy_for_lambda가 생성됩니다\n  + resource \"aws_iam_policy\" \"iam_policy_for_lambda\" {\n      + arn              = (적용 후 알려짐)\n      + attachment_count = (적용 후 알려짐)\n      + description      = \"테라폼에 의해 생성된 IAM 정책\"\n      + id               = (적용 후 알려짐)\n      + name             = \"iam_policy_Lambda-from-terraform\"\n      + name_prefix      = (적용 후 알려짐)\n      + path             = \"/\"\n      + policy           = jsonencode(\n            {\n              + Statement = [\n                  + {\n                      + Action   = [\n                          + \"logs:CreateLogGroup\",\n                          + \"logs:CreateLogStream\",\n                          + \"logs:PutLogEvents\",\n                        ]\n                      + Effect   = \"Allow\"\n                      + Resource = \"arn:aws:logs:*:*:*\"\n                    },\n                ]\n              + Version   = \"2012-10-17\"\n            }\n        )\n      + policy_id        = (적용 후 알려짐)\n      + tags_all         = (적용 후 알려짐)\n    }\n\n  # aws_iam_role.terraform_lambda_iam_role가 생성됩니다\n  + resource \"aws_iam_role\" \"terraform_lambda_iam_role\" {\n      + arn                   = (적용 후 알려짐)\n      + assume_role_policy    = jsonencode(\n            {\n              + Statement = [\n                  + {\n                      + Action    = \"sts:AssumeRole\"\n                      + Effect    = \"Allow\"\n                      + Principal = {\n                          + Service = \"lambda.amazonaws.com\"\n                        }\n                      + Sid       = \"\"\n                    },\n                ]\n              + Version   = \"2012-10-17\"\n            }\n        )\n      + create_date           = (적용 후 알려짐)\n      + force_detach_policies = false\n      + id                    = (적용 후 알려짐)\n      + managed_policy_arns   = (적용 후 알려짐)\n      + max_session_duration  = 3600\n      + name                  = \"Lambda-from-terraform\"\n      + name_prefix           = (적용 후 알려짐)\n      + path                  = \"/\"\n      + tags_all              = (적용 후 알려짐)\n      + unique_id             = (적용 후 알려짐)\n    }\n\n  # aws_iam_role_policy_attachment.attach_iam_policy_to_iam_role 생성됩니다\n  + resource \"aws_iam_role_policy_attachment\" \"attach_iam_policy_to_iam_role\" {\n      + id         = (적용 후 알려짐)\n      + policy_arn = (적용 후 알려짐)\n      + role       = \"Lambda-from-terraform\"\n    }\n\n  # aws_lambda_function.terraform_lambda 생성됩니다\n  + resource \"aws_lambda_function\" \"terraform_lambda\" {\n      + architectures                  = (적용 후 알려짐)\n      + arn                            = (적용 후 알려짐)\n      + code_sha256                    = (적용 후 알려짐)\n      + filename                       = \"./python/index.zip\"\n      + function_name                  = \"Override_Name\"\n      + handler                        = \"index.lambda_handler\"\n      + id                             = (적용 후 알려짐)\n      + invoke_arn                     = (적용 후 알려짐)\n      + last_modified                  = (적용 후 알려짐)\n      + memory_size                    = 128\n      + package_type                   = \"Zip\"\n      + publish                        = false\n      + qualified_arn                  = (적용 후 알려짐)\n      + qualified_invoke_arn           = (적용 후 알려짐)\n      + reserved_concurrent_executions = -1\n      + role                           = (적용 후 알려짐)\n      + runtime                        = \"python3.9\"\n      + signing_job_arn                = (적용 후 알려짐)\n      + signing_profile_version_arn    = (적용 후 알려짐)\n      + skip_destroy                   = false\n      + source_code_hash               = (적용 후 알려짐)\n      + source_code_size               = (적용 후 알려짐)\n      + tags_all                       = (적용 후 알려짐)\n      + timeout                        = 3\n      + version                        = (적용 후 알려짐)\n    }\n\n계획: 4개 추가, 0개 변경, 0개 제거.\n\n앞서 설명한 변경 사항을 적용시키기 위해 terraform apply를 실행할 수 있습니다.\n\n그 후 콘솔에 성공 메시지가 표시될 것입니다. 이는 모든 리소스가 AWS 측에 생성된 것을 의미합니다. AWS GUI에서 람다 함수를 확인하고 실행하거나 CLI에서 람다 함수를 확인할 수 있습니다.\n\naws lambda list-functions --region us-east-1 | grep Override_Name \n\n\"FunctionName\": \"Override_Name\",\n\"FunctionArn\": \"arn:aws:lambda:us-east-1:11111:function:Override_Name\",\n\"LogGroup\": \"/aws/lambda/Override_Name\"","ogImage":{"url":"/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png"},"coverImage":"/assets/img/2024-06-19-HowtodeployLambdafunctiononAWSusingTerraform_0.png","tag":["Tech"],"readingTime":11},{"title":"Redis를 S3 Express로 재구축하기","description":"","date":"2024-06-19 12:10","slug":"2024-06-19-RebuildingRedisonS3Express","content":"\n\n## 느린, 저렴하고 확장 가능한 키-값 저장소\n\n## 느린-저렴 대 빠른-비싼\n\n다년간 \"최고의 데이터베이스\"로 선정된 Redis는 빠르고 신뢰성 있으며 고처리량의 키-값 저장소로 탄생했습니다 (훨씬 더 발전하기 전). 오늘날에도 가장 많이 사용되는 용도는 캐싱입니다 — 사용자를 위해 작고 자주 액세스하는 데이터를 빠르게 저장합니다 (예: 몇 줄의 파이썬 코드로):\n\n```js\n\u003e\u003e\u003e import redis\n\u003e\u003e\u003e r = redis.Redis(host='myhost', port=6379, db=0)\n\u003e\u003e\u003e r.set('userId:10', '1701743088')\nTrue\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 키 기반 쿼리로 나중에 다시 검색하세요:\n\n```js\n\u003e\u003e\u003e r.get('userId:10')\n1701743088\n```\n\n쉽고 빠르죠. Redis의 가치와 비밀은 데이터 전문가들에게 분명히 비밀이 아니며, 비용도 마찬가지입니다. 메모리는 비싸며, 캐시는 클라우드 요금에 빠르게 영향을 줄 수 있습니다. AWS ElasticCache의 25GB(cache.m7g.2xlarge)는 약 500달러 / 월입니다.\n\n다른 한편으로, S3와 같은 객체 저장소는 다른 가격 / 성능 트레이드오프를 약속했습니다. 25GB 저장 비용은 약 0.5달러 / 월이지만, S3 지연 시간(평균 및 테일)은 당신의 응용 프로그램에 심각한 영향을 미칠 수 있습니다. 만약 일관적이고 빠른 작업에 의존하고 있다면요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요즘까지는 아니었지만, S3 익스프레스의 공개로 파레토 프런티어에 또 다른 포인트가 추가되었습니다. \"익스프레스 저장소 클래스는 최대 10배 더 나은 성능을 제공하기 위해 설계되었으며 (...), 가장 자주 액세스하는 데이터에 탁월한 적합성을 갖추고 있습니다.\"\n\n이러한 새로운 기능에 매료되어, 우리는 AWS의 신제품을 테스트하기 위해 Redis와 유사한 키-값 워크로드를 완전히 S3로 백업하는 새로운 인터페이스를 재구성해 보았습니다(적절하게 \"redis3\"라고 합니다). 우리는 이를 프로토타입화하고 테스트하며 오픈소스로 공유했는데, 우리가 배운 것은 이렇습니다: 저장소를 복제하고 스타를 추가하며 함께하세요!\n\n![이미지](/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png)\n\n## Redis3: 개발자 시각\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요즘 데이터 랜드의 모든 사람들이 개발자 경험에 집착하고 있기 때문에, 우리는 redis3를 최종 사용자인 개발자에게 어떻게 보이는지부터 살펴보겠습니다. GET/SET 연산이 실제로 Redis의 핵심 기능이므로, redis-py 명령어를 redis3와 비교하여 시작합니다.\n\n```js\n\u003e\u003e\u003e from redis3 import redis3Client\n\u003e\u003e\u003e r = redis3Client(cache_name='mytestcache', db=0)\n\u003e\u003e\u003e r.set('userId:10', '1701743088')\nTrue\n\u003e\u003e\u003e r.get('userId:10')\n1701743088\n```\n\n알 수 있는 독자들은 이미 알고 계실 것이지만, 위 명령어는 기본적으로 동일합니다: URL 및 포트는 클라이언트 초기화에 없지만 (이유는 아래에서 자세히 설명되어 있습니다. 심지어 GET 및 SET에 대해 동일한 간결한 구문과 의미론을 가지고 있습니다.\n\nRedis3에서는 데이터베이스의 모든 키를 나열하거나 Redis에서의 MSET 및 MGET을 모방할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nkey_list = ['playground_{}'.format(i) for i in range(5)]\nval_list = ['bar_{}'.format(i) for i in range(5)]\nr = my_client.mset(key_list, val_list)\nval_list_back = my_client.mget(key_list)\nassert val_list == val_list_back\n```\n\n그리고 key를 삭제할 수도 있어요 (DEL):\n\n```js\nr = my_client.delete('userId:10')\n```\n\n마지막으로, db 매개변수를 사용하여 키를 자동으로 네임스페이스 할 수 있어요 (물론 16에 제한되지 않아요):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nr = redis3Client(cache_name='mytestcache', db=133)\n```\n\n## Redis3: 아키텍처\n\n자세히 살펴보면, redis3Client는 boto3 작업을 매우 얇게 래핑한 것입니다. 특히 S3 Express 버킷에 대한 작업을 합니다. 다음과 같이 클라이언트를 초기화합니다:\n\n```js\nr = redis3Client(cache_name='mytestcache', db=0)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n버킷 redis3-mytestcache -- use1-az5 -- x-s3 를 생성하는 시도를 합니다. 즉, use1-az5 가용 영역에서 명명 규칙을 따르는 익스프레스 버킷을 생성합니다. 그런 다음 db 매개변수가 AWS 폴더 내에 키를 이름 공간으로 사용합니다:\n\n```js\nredis3-mytestcache -- use1-az5 -- x-s3\n    0/\n        my_key_1\n        my_key_2\n    1/\n        my_key_1\n    ...\n```\n\n이 설계에는 일반 캐싱 서버와 비교할 때 몇 가지 장단점이 있습니다. (가격-성능 외에, 이는 다음에 다룹니다):\n\n- 배포, 유지 관리, 이해하는 데 추가 인프라가 필요하지 않습니다.\n- 보안, 연결 및 권한 부여를 IAM 세분성으로 처리할 수 있습니다. 사용자는 예를 들어 새 캐시를 생성할 수 없지만 기존 캐시에서 키를 가져올 수 있는 권한을 가질 수 있습니다. redis3Client는 스크립트 실행 시 적용되는 AWS 권한을 상속하고 존중합니다 (마치 boto3.client('s3') 와 같이);\n- redis3Client는 연결 풀이 필요하지 않으며 공간이 부족해지지 않고 대량 처리를 지원합니다 (결국 S3 이기 때문에!). 최근에는 이 용어가 남발되고 있지만, 여기에는 분명히 \"서버리스 경험\"이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 Redis의 동시성 모델은 이해하기 매우 쉽습니다. 병행성이 많지 않기 때문에 원자 연산 지원이 시스템의 정확성을 보장하는 데 중요합니다. 안타깝게도 S3는 그러한 보장을 제공하지 않습니다. S3는 강력한 쓰기 후 읽기 일관성을 제공하지만(예를 들어 SET 직후에 DB 내용을 나열할 때 유용함), 여전히 INCR과 같은 것을 흉내 내는 방법은 없습니다. 이로 인해 누군가가 이전 my_value를 읽고 있는 동안에도 코드가 해당 값을 증가시키고 다시 저장하는 것을 피할 방법이 없습니다:\n\n```js\nv = GET my_value\nv = v + 1\nSET my_value v\n```\n\n이에 대해 어떤 사람들은 redis3Client MSET 및 MGET 명령어가 잘못된 이름을 가졌으며, Redis 파이프라인으로 보내는 키 목록과 관련된 것보다 원래의 원자적 명령어와 더 유사하다고 주장할 수 있습니다 (사실 이름 짓기와 캐싱을 한다는 것이 컴퓨터 과학에서 가장 어려운 두 가지일이라는 것이 밝혀졌습니다!).\n\n## 빠르고 비교적 저렴한 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 파이썬 메소드가 얼마나 좋은지는 중요하지 않아요. 캐시는 빠르고 신뢰할 수 있어야 해요. 저희는 EC2에서 테스트 스크립트를 실행하고, 같은 가용 영역에 위치한 redis3 캐시와 표준 S3 버킷, Redis 인스턴스(그냥 편하게 Redis Labs에서 호스팅해요! ) 결과(초 단위)를 비교해요:\n\n![image](/assets/img/2024-06-19-RebuildingRedisonS3Express_1.png)\n\nRedis보다는 여전히 느리지만, redis3는 실제로 새로운 가격 성능 옵션으로, \"미숙한 S3 캐시\"보다 평균적으로 훨씬 더 빠를 뿐만 아니라 신뢰할 수 있음을 입증했어요(95백분위에서 5배).\n\n공식 가격표를 빠르게 살펴보면, AWS Redis 인스턴스와 비교했을 때 더 분명하게 알 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-19-RebuildingRedisonS3Express_2.png)\n\n1GB의 redis3 캐시는 메모리 지원 캐시보다 훨씬 저렴하게 구입할 수 있습니다 (추가 인프라 및 유지보수를 고려하지 않음).\n\n## 수괴카우보이, 다음에 봐요\n\nS3를 캐시로 사용하는 것은 미친 것처럼 보일 수 있지만, 새로운 익스프레스 버킷을 사용하면 그렇게 보이지 않습니다: Redis가 어디론가 사라지지 않는 한, 객체 스토리지와 데이터 애플리케이션의 상호 진화는 계속해서 새로운 트레이드 오프를 활용하는 흥미로운 패턴을 만들어냅니다. 이 실험을 좋아하셨다면, redis3 클래스를 직접 사용해보고 어떻게 생각하는지 알려주세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, EC2를 S3 위에 올려 데이터 작업을 수행할 때 무엇이 발생하는지 신경 쓰신다면, Bauplan에 대한 최신 정보를 따르는 것을 잊지 마세요.","ogImage":{"url":"/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png"},"coverImage":"/assets/img/2024-06-19-RebuildingRedisonS3Express_0.png","tag":["Tech"],"readingTime":5},{"title":"왜 당신의 마이크로서비스 아키텍처가 아마도 지나치게 복잡한 지에 대해 그리고 어떻게 다시 단일체를 사랑하게 되었는지 알아보겠습니다","description":"","date":"2024-06-19 12:09","slug":"2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain","content":"\n\n작은 독립적인 서비스들이 각각 완벽하게 자신의 일을 하는 것, 개발자의 낙원 같지 않아요? 하지만 알아요? 가끔, 이건 정말 엄청난 고통일 수 있어요.\n\n저는 이 허세에 홀렸었어요.\n\n우리는 새 시스템을 구축하고 있었는데, '올바른' 방식으로 하겠다고 다짐했어요. 익숙한 거대한 단일체는 밖으로, 작은 마이크로서비스 떼가 들어왔어요. 처음에는 놀랍게 느껴졌어요 — 너무 깨끗하고, 너무 모듈화됐잖아요!\n\n하지만 현실이 닥쳤어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과는, 복잡성이 사라지지 않았습니다; 단지 변했습니다. 이것이 마이크로서비스가 당신의 영혼을 죽일 수 있는 이유입니다:\n\n# 수다스러운 캐시 문제\n\n이전에는 동일한 코드베이스에서 함수를 호출할 수 있었던 것을 기억하시나요? 이제 여러분의 절반 서비스는 네트워크 상에서 수다 떨고 있습니다. 그 중 하나가 성을 내면? 그 난장판을 디버깅하는 데는 행운이 필요할 겁니다.\n\n한 번은 간단했던 함수 호출이 교차 서비스 요청의 끝없는 사가로 변모하고 있습니다. 지연과 관련된 머리 아픔, 네트워크 어딘가에서 뭔가가 고장날까 두려워하는 늘스런 공포의 상태로 변해가고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일렇게 REST API와 메시지 큐를 사용하여 처리할 수 있을 것이라 생각할 수도 있지만, 사실은 그 소중한 밀리초가 누적됩니다. 작은 데이터 조각을 가져와야 하나요? 그것은 네트워크 호출입니다. 간단한 작업을 처리해야 하나요? 또 다른 호출이 필요합니다. 여러분의 시스템은 실제 일을 하는 대신 수다에 더 많은 시간을 낭비합니다.\n\n그런 다음, 불가피한 일이 벌어집니다. 여러분의 서비스 중 하나가 오동작하면 네트워크 타임아웃을 발생시키거나 엉망으로 된 데이터를 뱉어 냅니다. 그 속을 해체하는 과정을 즐기세요. 분산 디버깅은 분실된 양말을 찾는 것처럼 쉽지 않습니다. 각 네트워크 호프는 또 다른 용의자, 여러분의 비통의 근원이 될 수 있는 복잡성의 또 다른 층입니다.\n\n# 배포 지옥\n\n코드를 배포했을 때 직업을 바꾸어 야만한 일이 되려고 하거나 라마 농부가 되고 싶어졌던 기억을 여전히 갖고 계시나요? 네, 그런 날들은 이미 멀리 떠났습니다. 마이크로서비스로, 관리 가능한 프로세스였던 것이 불길한 기분을 내뿜는 다두와 여러 머리를 지닌 괴물로 변모했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n갑자기 어플리케이션 하나가 아니라 십여 개의 작은 괴물을 다루게 되었네요. 각각이 자체 빌드 프로세스, 테스트 슈트 및 신중한 조율이 필요해요. CI/CD 파이프라인은 이렇게 엄청난, 꼬인 루브 골드버그 장치가 되어 새롭고 흥미로운 실패로 매번 고장나는 것처럼 보여요. 잘못된 구성 하나, 맞지 않는 종속성 하나로 모든 것이 터져버릴 수 있어요. 배포 오류와 싸우면서 실제 기능 개발은 멈춰있게 되네요. 코드 복잡성을 운영 복잡성과 바꾸었군요.\n\n# 관찰성 부담\n\n과거 몇몇 전략적으로 배치된 로그 라인으로 무엇이 문제인지 알 수 있던 시절을 기억하시나요? 마이크로서비스로, 그런 시기는 이미 멀리 사라진 기억이 됐어요. 이제는 시스템을 이해하는 데 상당한 투자가 필요할 거예요.  \n\n서비스 사이를 건너는 요청을 추적하려면 분산 추적 솔루션이 필요할 건데요. 서비스가 생성하는 로그의 해일을 해석하려면 로그 집계 도구가 기다리고 있어요. 그리고 멋진 대시보드와 경보 시스템을 잊지 마세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n갑자기 예산과 엔지니어링 시간이 시스템이 제대로 작동하는지 확인하는 데 사용되는 것으로 바뀌었네요. 모순적인 점은, 이 모든 복잡성을 더한 결과물로 인해 문제의 근본 원인을 찾기가 이전보다 더 어려워졌다는 느낌을 자주 받습니다. 당신은 가시성의 환상에 큰 대가를 지불하고 있는 것 같습니다.\n\n# 그들은 그리 독립적이지 않아요\n\n마이크로서비스의 전체 약속은 느슨하게 결합되고 서로 교환 가능한 조각들의 아름다운 비전인데, 사실은 종종 많은 허세였던 것으로 밝혀졌어요. 실제로 \"독립적\"인 서비스들이 의외로 얽혀있는 방식으로 복잡해 집니다.\n\n한 서비스의 API를 조정하면 어떤 결과도 없을 것이라고 생각하시나요? 한 번 더 생각해보세요. 숨겨진 가정, 문서화되지 않은 의존성, 그리고 행동의 미묘한 변화들이 불량한 음식 중독과 같이 시스템 전반을 퍼져나갈 수 있습니다. 당신이 알게 모르게, 여러 팀에 걸쳐 다시 작업에 뛰어들어서 왜 이러한 열광을 사들인 걸까 궁금해할 수도 있어요. 민첩성에 대한 약속에 대해 말할 수 없다 — 이제 당신은 아무것도 바꾸기를 두려워할 정도로 두려워하게 되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단일체만큼 좋은 경우도 있어요\n\n잠시 동안 독단적인 견해를 내려 놓아 보죠. 구성 요소들이 본질적으로 연결되어 있는 작은 프로젝트, 팀 또는 시스템의 경우, 단일체는 생명보호병이 될 수도 있어요. 이는 단순함을 추구하여 유행성을 포기하는 것과도 같아요.\n\n생각해 보세요: 네트워크 지연 문제가 없고, 디버깅이 간단하며 울고 싶지 않게 배포할 수 있는 장점이 있어요. 확실히 성장하면 조금 엉망일 수 있지만, 코드베이스 내 신중한 모듈화로 그것을 완화할 수 있어요. 그리고 솔직히 말하자면, 잘못 설계된 마이크로서비스 시스템이 보잘것없이 퍼져나가는 모습은 그다지 즐겁지 않아요.\n\n나쁜 말 안 하겠습니다. 마이크로서비스가 나쁜 것은 아니에요. 그것들은 대규모 시스템에서 빛을 발하거나, 구성 요소 간에 완전한 독립성이 필요한 경우에 유용해요. 하지만 맹목적으로 트렌드를 따라가서 모든 것을 마이크로서비스로 분리하는 것은 정말로 무분별한 복잡성과 개발자의 탈진으로 이어지는 결과를 초래할 수도 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가끔 \"옛날 방식\"의 단일체가 더 현명한 선택일 수 있습니다. 인프라와 무쟁하기보다는 가치 전달에 집중할 수 있게 해줍니다.\n\n나는 반드시 마이크로서비스를 비판하는 것은 아닙니다. 특히 확장성이 중요한 대규모 복잡한 시스템에서 유용할 수 있습니다. 그러나 기술 세계는 항상 최신 유행을 지나치게 홍보하여 검증된 솔루션을 낡은 것으로 여기게 만드는 나쁜 버릇이 있습니다.\n\n쿨한 것을 하고 있는 친구들이 그렇게 하고 있다고 해서 우리도 모든 애플리케이션을 마이크로서비스로 나누는 것을 맹목적으로 따라갈 필요는 없습니다. 한 발 물러나서 프로젝트의 필요를 정직하게 평가하고, 복잡성 대비가 정말 그만한지 고려해보세요. 잘 설계된 단일체가 작업 부담이 적게 더해도 동일한 기능을 제공할 수 있는 경우에는 왜 그것을 선택하지 않을까요?\n\n마이크로서비스가 디폴트일 필요는 없습니다; 이는 의도적인 결정이어야 합니다. 독단적인 사고를 버리고 더 실용적인 접근 방식을 채택합시다 — 적합한 도구가 승리하는 아키텍처. 가장 유행하는 것이 아니더라도. 아니, 혹시 서면이 잘 갖춰진 단일체의 간결함에 대한 새로운 감사함을 발견할지도 모릅니다.","ogImage":{"url":"/assets/img/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain_0.png"},"coverImage":"/assets/img/2024-06-19-WhyYourMicroservicesArchitectureisProbablyOverkillAndHowILearnedtoLovetheMonolithAgain_0.png","tag":["Tech"],"readingTime":4},{"title":"클라우드 컴퓨팅에서 AI 마스터하기 혁신과 실용적인 기술 활용하기","description":"","date":"2024-06-19 12:08","slug":"2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills","content":"\n\n2019년에 클라우드 컴퓨팅을 배우기 위한 첫 번째 플랫폼으로 AWS Educate를 이용했어요.\n\n2019년, 인도네시아의 한 석탑 대학에서 물리학 석사 학위를 받은 후, 컴퓨터 과학 전공이 없는 저에게도 기술 산업에서 일할 기회가 있다는 것을 깨달았어요. 그 당시 인도네시아는 스타트업 붐을 경험하고 있었는데, 저의 학부 동기들 중 일부가 이러한 기업에서 직장을 얻은 것을 보았어요. 처음에는 의심이 많았지만 배우기 시작하기로 결심했어요. 그때 한 친구가 인도네시아 정보부가 후원하는 클라우드 컴퓨팅 및 머신 러닝(ML)에 초점을 맞춘 교육 프로그램에 참여하도록 초대했어요. 처음에는 주저했지만, 물리학 외의 분야를 탐험할 수 있는 좋은 기회라고 생각했어요.\n\n선발 과정을 거친 후에 저와 제 친구는 그 프로그램에 선발되었어요. 저희는 분야 전문가들의 지도를 받았죠. 그것이 제 첫 클라우드 컴퓨팅 체험이었고, 저는 AWS Educate를 통해 중요한 클라우드 기초 지식을 실습하면서 배우기 시작했어요.\n\n익숙치 않은 용어로 새로운 클라우드 컴퓨팅을 배우는 것은 꽤 어려웠어요. 교육 기간이 한 달 뿐이었기 때문에 저는 정보를 천천히 받아들이려고 노력했어요. 가장 간단한 개념부터 이해하려고 노력했어요: 가용성, 지연 시간, 내결함성, 데이터베이스, 서버, 네트워킹, 스토리지 등의 클라우드 용어를 이해하는 것부터 시작했어요. 프로그램이 끝나면 우리가 만든 간단한 프로젝트를 발표하고 모두와 함께 졸업을 축하하는 시간을 가졌어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills](/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png)\n\nAWS Educate was the first platform to guide me in learning about cloud computing. Even though it was not as advanced back then, AWS Educate inspired me to continue learning about the cloud, especially as a beginner. The system was well-organized, which made it easier for me to learn in a structured, gradual, and step-by-step manner.\n\n### Traditional AI vs. Generative AI\n\nApart from cloud computing, my friends and I delved into machine learning. Our project focused on finding the best model for a simple case study: hospital readmission. Hospital readmission occurs when patients return to the hospital after being discharged. A high readmission rate signifies lower quality of care. We analyzed data from 130 hospitals in the U.S. After experimenting with different models, we discovered that the random forest model performed best when dealing with large datasets. This approach is known as traditional AI.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전통적 AI는 입력 데이터를 기반으로 한 특정 작업 및 예측에 초점을 맞춥니다. 구조화된 데이터를 분석하고 패턴을 식별하며 기존 데이터에 기반한 결정을 내리는 데 능숙합니다. 반면에 GPT-3과 같은 생성적 AI는 새로운 콘텐츠 생성을 목적으로 합니다. 방대한 양의 데이터로부터 학습한 패턴을 기반으로 텍스트, 이미지 및 기타 미디어를 생성할 수 있습니다. 전통적 AI는 분류 및 회귀와 같은 작업에 뛰어나지만, 생성적 AI는 새로운 인간과 유사한 콘텐츠를 생성하고 복잡한 문제에 대한 창의적인 해결책을 찾는 데 빛을 발합니다.\n \n![AI](/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_1.png)\n\n전통적 기계 학습 모델은 제공된 데이터를 기반으로 작업을 수행합니다. 순위 매기기, 감정 분석, 이미지 분류 등과 같은 예측을 할 수 있습니다. 그러나 각 모델은 한 가지 작업만 수행할 수 있으며, 이를 성공적으로 수행하려면 모델을 주의 깊게 훈련해야 합니다. 모델이 훈련되는 동안 데이터를 분석하고 패턴을 찾습니다. 그런 다음 이러한 모델은 이러한 패턴을 기반으로 예측을 수행합니다. 전통적 AI는 사용 범위가 매우 제한적하며 (또한 반복적으로 모델링해야 하고 매우 큰 데이터 세트가 필요하기 때문에 복잡할 수 있음), 세계 기업들이 생성적 AI를 개발하기 위해 경쟁을 벌이고 있습니다.\n\n2024년, AWS Educate은 생성적 AI 개요 과정을 소개했습니다. 이전 글에서 \"함께 배우고 싶다\"라고 말했다면, 이 강의를 수강한 적이 있나요? 저는 모든 강의를 마치고 배지를 받았습니다. 여기서 생성적 AI 강좌를 응원하고 싶은 중요한 포인트를 전달하고 싶습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- AI 생성기는 기계 학습 기반 모델에 의해 구동됩니다. 이러한 모델은 콘텐츠를 생성할 수 있습니다. 이 AI 생성 콘텐츠는 편집 가능하며, 필요에 맞게 수정할 수 있습니다.\n- Foundation 모델은 전통적인 기계 학습 모델과 크기, 다양성, 여러 작업을 수행할 수 있는 능력에서 상당히 다릅니다. 이 모델은 라벨이 지정된 데이터를 수집하거나 여러 모델을 별도로 훈련할 필요 없이 여러 작업을 수행할 수 있습니다.\n- 프롬프트 엔지니어링은 모델에 프롬프트를 입력하여 출력으로 표시되는 추론을 생성하는 것을 포함합니다. 그러나 출력물이 만족스럽지 않은 경우 프롬프트를 조정하거나 작업 예제를 제공해야 할 수 있습니다. 프롬프팅은 중요한 기술이 될 것이며, 우리 자신이 올바른 프롬프트를 제공하는 방법을 연습할수록 AI 결과는 더 좋아질 것입니다.\n- 생성적 AI와 관련된 AWS 서비스는 무엇인가요? 다음은 슬라이드입니다.\n\n![이미지](/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_2.png)\n\nAmazon Bedrock\n\n- 설명: Amazon Bedrock은 쉬운 API를 통해 Amazon 및 다른 제공업체의 다양한 대형 언어 모델(LLM)에 액세스할 수 있도록 제공하여 개발자가 모델 인프라를 관리하지 않고 생성적 AI 응용 프로그램을 구축할 수 있게 합니다.\n- 비유: 다양한 작가의 최고의 책이 있는 큰 도서관을 상상해보세요. 필요한 책(모델)을 빌릴 수 있고 사용 후 반납할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아마존 코드위스퍼러\n\n- 설명: 아마존 코드위스퍼러는 AI를 사용하여 개발자가 코드를 작성하는 동안 빠른 코드 제안을 제공하는 도구로, 코드 작성 중에 코드의 맥락에 기반한 스니펫, 함수 및 로직을 제공하여 생산성을 향상시킵니다.\n- 유사성: 자신을 지도해주는 지능적인 비서와 함께 삽시간에 다음 단어나 문장을 제안하는 작가로 생각해 보세요. 이를 통해 더 빨리, 더 부드럽게 쓸 수 있습니다.\n\nAWS 인퍼런티아\n\n- 설명: AWS 인퍼런티아는 AWS의 특수화된 가속기 칩으로, 머신러닝 모델의 추론을 가속화하는 것을 목적으로 설계되었습니다. 추론은 훈련된 모델을 실행하여 예측이나 결정을 내리는 과정을 말합니다.\n- 유사성: 일정한 수학적 문제를 해결하는 데 특별히 설계된 초고속 계산기가 있다고 상상해 보세요. 이를 통해 짧은 시간 내에 많은 문제를 해결할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS Trainium\n\n- 설명: AWS Trainium은 AWS의 전문 가속기 칩으로, 기계 학습 모델의 훈련 속도를 높여 복잡한 AI 모델을 훈련하는 데 필요한 시간과 비용을 줄입니다.\n- 비유: AWS Trainium은 엘리트 선수 훈련을 위한 고급 장비가 갖춰진 개인 체육관처럼 생각해보세요. 이를 통해 효과적으로 훈련하고 더 빨리 최고의 성과를 달성할 수 있습니다.\n\nAmazon SageMaker JumpStart\n\n- 설명: Amazon SageMaker JumpStart는 미리 구축된 솔루션과 사용 준비가 된 모델을 제공하여 기계 학습 애플리케이션 개발을 가속화합니다. 미리 훈련된 모델과 다양한 사용 사례에 대한 튜토리얼 노트북이 포함되어 있습니다.\n- 비유: 테이블을 만들고 싶다고 상상해보세요. 준비가 완료된 모든 부품이 포함된 완전 조립 키트와 단계별 메뉴얼을 받아서 아무것도 잘라내거나 측정할 필요 없이 지침에 따라 진행할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클라우드 컴퓨팅 분야에서 학습하고 근무하는 저로서는 AI가 인간을 대체할 수도 있다는 우려가 있었습니다. 그러나 이러한 두려움이 과장되었을 수 있지만, 쉽게 이해할 수 있는 이 강의를 통해 AI가 어떻게 작동하는지 이해하는 것에 가치가 있다고 생각해요. 엔지니어/개발자로서, 이를 통해 우리는 이전보다 빠르게 문제를 해결할 수 있게 되었습니다. AI는 올바르게 활용된다면 우리의 작업을 크게 향상시킬 수 있어요. 이 강의는 입구와 같은 존재이며, 2019년에 클라우드 여정을 시작했지만, 이를 통해 많은 새로운 것들을 배웠습니다.\n\n결론\n\n전통적인 AI 모델은 일반적으로 특정 작업을 위해 구축되고 훈련되며 해당 작업에 맞춤화된 데이터셋으로 구축됩니다. 예를 들어, 얼굴 인식 AI 모델은 다양한 얼굴 이미지를 기반으로 훈련될 것입니다. 이러한 모델들은 특정 작업에서 우수한 성과를 보이지만, 큰 재훈련 없이는 다른 문맥에서의 융통성이 부족합니다. 반면, 생성적 AI의 기초 모델은 다재다능하며 작은 조정만으로 다양한 작업에 적응시킬 수 있습니다. 마치 보편적인 성형이 작은 수정으로 다양한 제품을 만들어내는 것과 비슷하죠.\n\n이어서, AWS Educate의 또 다른 흥미로운 강좌를 추천드리며, 이 강좌는 AWS의 AI 서비스 중 하나인 Amazon Bedrock에 초점을 맞추고 있습니다. 다음은 강좌 수강 방법입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- www.awseducate.com에 방문해주세요.\n- 제네레이티브 아마존 베드락 소개를 선택해주세요.\n- 코스를 약 0.75시간 내에 완료해주세요.\n- 경험을 공유해주세요!\n\n그래서, 클라우드 컴퓨팅에서 AI의 미래를 탐험하고 오늘 당신의 잠재력을 발휘해보세요! 즐거운 학습되세요!\n\n사랑을 담아,\n\nNova Lailatul Rizkiyah","ogImage":{"url":"/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png"},"coverImage":"/assets/img/2024-06-19-MasteringAIinCloudComputingEmbraceInnovationandPracticalSkills_0.png","tag":["Tech"],"readingTime":6},{"title":"AWS 인터뷰 질문 DAY_25 90","description":"","date":"2024-06-19 12:03","slug":"2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS","content":"\n\n\n![](/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png)\n\nBelow are some basic AWS interview questions along with the answers.✍\n\n# 1. What is Cloud Computing and what are its features?\n\nCloud computing is a general term for the delivery of hosted computing services and IT resources over the internet with pay-as-you-go pricing.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클라우드 컴퓨팅의 특징은 다음과 같습니다:\n\n- 자원 풀링: 클라우드 서비스 제공업체는 다양한 서비스를 제공하는 각각의 다른 클라이언트 사이에서 자원을 공유할 수 있습니다.\n- 넓은 접근성: 클라이언트는 장치와 인터넷 연결이 있는 어디서든 클라우드 데이터에 접근하거나 클라우드로 데이터를 전송할 수 있습니다. 이러한 기능은 조직 전역에서 어디서든 이용 가능하며 인터넷의 도움으로 실현됩니다.\n- 신속한 탄력성: 이 클라우드 기능은 필요에 따라 신속하게 확장하거나 축소할 수 있는 워크로드를 비용 효율적으로 처리할 수 있게 합니다. 사용자가 서버를 요청하면 제공되고 필요 시 바로 확장됩니다.\n- 셀프 서비스 온디맨드: 이는 클라이언트가 서버 가동 시간, 기능 및 할당된 네트워크 저장소를 계속 모니터링할 수 있도록 합니다. 이는 클라우드 컴퓨팅의 기본 기능이며 고객은 자신의 요구에 맞춰 컴퓨팅 능력을 제어할 수도 있습니다.\n- 사용량 측정: 이를 통해 제공자와 고객 모두가 사용된 서비스와 목적을 모니터링하고 보고할 수 있습니다. 이는 청구 모니터링을 돕고 리소스의 최적 이용을 보장합니다.\n\n# 2. 다양한 클라우드 배포 모델은 무엇인가요?\n\n클라우드 배포 모델은 데이터 저장량 및 인프라 액세스 권한에 따라 선택할 수 있는 가상 컴퓨팅 환경으로 작동합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클라우드 배포 모델에는 4가지 유형이 있습니다: -\n\n- 공용 클라우드: 이름 그대로 공개적으로 접근 가능합니다. 클라우드의 공개 배포 모델은 성장하고 변동하는 수요를 갖는 조직에 적합합니다. 또한 보안 우려가 낮은 기업들에게 좋은 선택지입니다. 따라서 공개 인터넷에서 네트워킹 서비스, 컴퓨팅 가상화 및 저장소에 대해 클라우드 서비스 제공업체에 요금을 지불합니다.\n- 사설 클라우드: 데이터 센터와 통합되어 내부 IT 팀이 관리합니다. 대체로 외부에 호스팅할 수도 있습니다. 사설 클라우드는 맞춤화가 필요한 특정 조직의 요구를 충족시키는 더 큰 기회를 제공합니다. 비용 효율성 및 데이터 및 자원에 대한 더 큰 제어를 찾는 기업들은 사설 클라우드를 더 적합한 선택으로 여길 것입니다.\n- 하이브리드 클라우드: 두 개 이상의 클라우드 아키텍처를 조합한 형태입니다. 하이브리드 클라우드의 각 모델은 서로 다르게 기능하지만, 하나의 아키텍처의 일부입니다. 더 나아가 클라우드 컴퓨팅 모델의 이 배포 일환으로 내부 또는 외부 제공 업체가 리소스를 제공할 수 있습니다.\n- 커뮤니티 클라우드: 공용 클라우드와 유사한 방식으로 운영됩니다. 유일한 차이점은 특정 목표와 사용 사례를 공유하는 특정 사용자 그룹에만 액세스 권한을 부여한다는 것입니다. 이러한 클라우드 컴퓅팅 배포 모델 유형은 내부적으로 또는 제3자 벤더에 의해 관리 및 호스팅됩니다.\n\n# 3. 클라우드 컴퓨팅의 다양한 유형은 무엇인가요?\n\n클라우드 컴퓨팅에는 인프라스트럭처 서비스(IaaS), 플랫폼 서비스(PaaS) 및 소프트웨어 서비스(SaaS)라는 세 가지 주요 유형이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- IaaS: IaaS는 가상화된 컴퓨팅 자원을 제공하며 가상 머신, 스토리지 및 네트워크와 같은 자원을 인터넷을 통해 제공합니다. 사용자는 인프라에서 실행하는 운영 체제 및 어플리케이션을 제어할 수 있어 더 큰 유연성과 맞춤 설정이 가능합니다.\n- PaaS: PaaS는 개발자가 기반 인프라를 관리하지 않고 애플리케이션을 구축, 배포 및 관리할 수 있는 플랫폼을 제공합니다. 개발 도구, 데이터베이스 및 실행 환경을 포함한 미리 구성된 환경을 제공하여 개발자가 인프라 관리 대신 애플리케이션 개발에 집중할 수 있습니다.\n- SaaS: SaaS는 인터넷을 통해 구독 기반으로 소프트웨어 애플리케이션을 제공합니다. 사용자는 설치나 관리가 필요하지 않고 이러한 애플리케이션에 액세스하고 사용할 수 있습니다. SaaS의 예로는 이메일 서비스, 고객 관리(CRM) 소프트웨어, Google Workspace와 같은 생산성 도구가 있습니다.\n\n# 4. 데이터 센터, 리전, 가용 영역(AZ), 엣지 위치, 로컬 영역, 웨이브렝스 영역은 무엇인가요?\n\n데이터 센터는 복잡한 네트워크, 컴퓨팅 및 스토리지 인프라를 이용하여 애플리케이션 및 데이터에 대한 공유 접근을 제공하는 시설입니다.\n\n리전은 특정 AWS 인프라 세트를 통해 서비스되는 지리적 영역입니다. 각 리전에는 독립된 거리와 독립된 전원 및 냉각으로 서로 격리된 여러 가용 영역이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가용 영역(Availability Zone)은 AWS 지역 내에서 고가용성과 오류 허용성을 제공하기 위해 설계된 격리된 데이터 센터입니다.\n\n에지 위치(Edge Location)는 사용자에게 빠르게 콘텐츠를 전달하기 위해 사용되는 데이터 센터입니다. 사용자에게 가장 가까운 위치에 있는 사이트입니다.\n\n로컬 영역(Local Zone)은 컴퓨팅 및 스토리지 등의 리소스를 사용자에게 더 가까운 여러 위치에 배치할 수 있도록 제공합니다.\n\n파장(Zones)은 개발자가 5G 기기와 사용자에게 초저 지연 시간을 제공하는 애플리케이션을 구축할 수 있도록 합니다. 파장은 표준 AWS 컴퓨팅 및 스토리지 서비스를 통신 사업자의 5G 네트워크 가장자리에 배포합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 5. AWS가 무엇인가요?\n\nAWS는 아마존 웹 서비스(Amazon Web Services)의 약자입니다. AWS는 아마존에서 제공하는 클라우드 컴퓨팅 플랫폼으로, 다양한 종류의 애플리케이션 및 서비스를 유연하고 확장 가능하며 비용 효율적으로 구축하고 배포하는 데 도움이 되는 다양한 클라우드 서비스를 제공합니다.\n\n# 6. 사용한 AWS 서비스 5가지와 사용 사례는 무엇인가요?\n\n- EC2 (Elastic Compute Cloud): EC2는 가상 서버(인스턴스)를 시작하여 애플리케이션을 실행할 수 있는 확장 가능한 클라우드 컴퓨팅 서비스입니다. 인스턴스 유형과 운영 체제를 선택할 수 있어, 웹 애플리케이션 호스팅부터 데이터 처리 작업까지 다양한 사용 사례에 적합합니다.\n- IAM (Identity and Access Management): IAM은 AWS의 신원 관리 서비스입니다. AWS 리소스에 누가 액세스할 수 있고 어떤 작업을 수행할 수 있는지 제어할 수 있습니다. 사용자 계정, 역할 및 권한을 관리하여 AWS 환경의 보안을 보장하는 데 중요합니다.\n- S3 (Simple Storage Service): S3는 저장 및 데이터 검색에 일반적으로 사용되는 확장 가능한 객체 저장 서비스입니다. 이미지, 비디오, 백업과 같은 정적 자산을 저장하는 데 효과적이며, 다른 AWS 서비스와 통합하여 정적 웹 사이트를 호스팅하거나 애플리케이션 데이터를 저장할 수 있습니다.\n- RDS (Relational Database Service): RDS는 MySQL, PostgreSQL, Oracle, SQL Server와 같은 관리형 관계형 데이터베이스를 제공합니다. 애플리케이션 실행, 사용자 데이터 저장, 분석 및 보고용으로 사용됩니다.\n- CloudWatch: CloudWatch는 AWS의 모니터링 및 관측 서비스입니다. 메트릭을 수집하고 추적하며, 로그 파일을 모니터링하고 경보를 설정할 수 있습니다. AWS 리소스의 작동 상태 및 성능에 대한 통찰력을 얻고, 운영 이벤트와 문제에 실시간으로 대응하는 데 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 7. 클라우드 환경으로 로그를 전송하는 데 사용되는 도구들은 무엇인가요?\n\n클라우드 환경으로 로그를 전송하는 데 여러 도구들을 사용할 수 있습니다. 일반적으로 사용되는 도구들은 다음과 같습니다:\n\n- Amazon CloudWatch Logs: CloudWatch Logs는 AWS의 내장 서비스로, 다양한 AWS 리소스 및 애플리케이션에서 로그 데이터를 수집, 모니터링하고 저장할 수 있습니다. AWS 리소스를 구성하여 그들의 로그를 직접 CloudWatch Logs로 전송할 수 있습니다.\n- AWS CloudTrail: AWS CloudTrail은 AWS 계정 내의 API 활동 및 이벤트를 캡처하고 로깅하여 사용자, 서비스 또는 리소스에 의해 수행된 작업을 파악할 수 있게 합니다.\n- Elasticsearch: Elasticsearch는 오픈 소스 검색 및 분석 엔진으로, 로그를 저장, 색인화 및 분석하는 데 사용할 수 있습니다. Logstash 및 Kibana(ELK 스택)과 함께 자주 사용되어 로그 관리 및 분석에 활용됩니다.\n- Fluentd: Fluentd는 다양한 소스에서 로그를 수집하여 클라우드 저장소 또는 분석 플랫폼으로 전송할 수 있는 오픈 소스 데이터 수집기입니다.\n- Logstash: Logstash는 ELK 스택의 일부로, 로그를 수집, 구문 분석 및 변환한 후 저장소 또는 분석 플랫폼으로 전송하는 데 사용됩니다.\n\n# 8. IAM 역할들은 무엇이며, 어떻게 만들고 관리할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS의 IAM(Identity and Access Management) 역할은 신뢰하는 엔터티에 권한을 부여하는 방법입니다. 이러한 엔터티는 AWS 서비스, 응용 프로그램 또는 AWS 계정 또는 외부 AWS 계정 내의 사용자가 될 수 있습니다. 역할은 장기 보안 자격 증명인 액세스 키나 비밀번호 없이 AWS 리소스에 액세스하기 위한 권한 위임을 안전하게 수행하는 방법입니다.\n\nIAM 역할은 귀하를 대신해 AWS 리소스와 상호 작용해야 하는 서비스 및 응용 프로그램에 일반적으로 사용됩니다.\n\n- AWS 관리 콘솔에 로그인: AWS IAM 콘솔로 이동합니다 (console.aws.amazon.com/iam).\n- 역할로 이동: 왼쪽 탐색 창에서 \"역할\"을 선택합니다.\n- 새 역할 생성:\n\n- \"역할 생성\" 버튼을 클릭합니다.\n- 신뢰하는 엔터티 유형을 선택합니다 (예: AWS 서비스, 다른 AWS 계정 또는 SSO 식별 공급자).\n- 역할 목적을 가장 잘 설명하는 사용 사례를 선택합니다. 예를 들어 EC2 인스턴스용 역할을 생성하는 경우, 사용 사례로 \"EC2\"를 선택할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. 권한 설정:\n\n- 역할에 정책을 연결합니다. 정책은 역할이 수행할 수 있는 작업을 정의합니다. 기존 정책 중 선택하거나 사용자 정의 정책을 생성할 수 있습니다.\n\n5. 이름 지정 및 검토:\n\n- 역할에 이름을 지정하고 선택적으로 태그를 추가하여 조직화를 돕습니다.\n- 역할의 구성을 검토하고 \"역할 생성\"을 클릭합니다.\n- 신뢰 관계 업데이트: 신뢰 관계를 편집하여 누가 또는 무엇이 역할을 가정할 수 있는지 허용하거나 제한할 수 있습니다.\n- 권한 업데이트: 권한을 부여하거나 제거하기 위해 정책을 연결 또는 분리할 수 있습니다. 역할에 필요한 권한이 있는지 확인하고 필요에 맞게 정책을 검토하고 업데이트하는 것이 중요합니다.\n- 역할 삭제: 더 이상 필요하지 않은 역할은 삭제할 수 있습니다. 역할 삭제 시 서비스 및 애플리케이션에 영향을 줄 수 있으니 조심해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 9. 시스템을 다운타임 없이 업그레이드 또는 다운그레이드 하는 방법\n\n시스템을 다운타임 없이 업그레이드 또는 다운그레이드하는 것은 특정 전략과 모베스트 프랙티스를 구현함으로써 가능합니다. 이 고수준 접근 방식을 살펴보겠습니다:\n\n- 로드 밸런서: 로드 밸런서를 설정하여 트래픽을 여러 인스턴스 또는 노드에 분산시켜야 합니다. 이를 통해 업그레이드/다운그레이드 프로세스 중에도 트래픽을 원활하게 리디렉션할 수 있습니다.\n- 다중 환경: 여러 환경(예: 스테이징, 프로덕션)을 생성하여 업그레이드/다운그레이드 프로세스를 실행해야 합니다. 하나를 업그레이드/다운그레이드하는 동안 영향을 받지 않는 환경으로 트래픽을 보내야 합니다.\n- 블루/그린 배포: 새 버전(그린)이 기존 버전(블루)과 함께 배포되는 블루/그린 배포 전략을 구현해야 합니다. 천천히 트래픽을 블루 환경에서 그린 환경으로 전환합니다.\n- 데이터베이스 복제: 데이터베이스 복제 기술을 사용하여 업그레이드/다운그레이드된 버전의 두 번째 인스턴스를 생성해야 합니다. 데이터베이스 변경 사항을 동기화하고 업데이트된 데이터베이스를 사용하도록 응용 프로그램을 다운타임 없이 전환해야 합니다.\n- 롤링 업그레이드: 하나씩 인스턴스 또는 구성 요소를 업데이트하여 전체 프로세스 중에 응용 프로그램이 사용 가능함을 보장하는 롤링 업그레이드를 수행해야 합니다.\n- 헬스 체크 및 모니터링: 시스템의 가용성을 보장하기 위해 헬스 체크를 구현하고 문제가 발견되면 프로세스를 밀접하게 모니터링해야 합니다. 이상이 감지되면 즉시 롤백해야 합니다.\n\n# 10. 인프라스트럭처 코드(Infrastructure as code)란 무엇이며 어떻게 사용하나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인프라스트럭처 코드(IaC)는 기계가 읽을 수 있는 구성 파일이나 스크립트를 사용하여 인프라 자원을 관리하고 프로비저닝하는 실천 방법을 말합니다. 이는 수동 프로세스 대신 소프트웨어 코드로 인프라를 처리하여 버전 관리, 자동화 및 재생산성을 가능하게 합니다.\n\n- 정의: 인프라스트럭처 코드는 원하는 상태의 인프라 자원을 정의하는 구성 파일이나 스크립트를 작성하는 것을 포함합니다. (예: AWS CloudFormation, Terraform, 또는 Ansible과 같은 도구 사용)\n- 자동화: IaC를 통해 인프라의 자동 프로비저닝 및 관리가 가능해지며 수동 구성이 필요 없어지고 인간 에러를 줄일 수 있습니다.\n- 버전 관리: 인프라 코드는 버전 관리 시스템에 버전을 매기고 저장할 수 있어 팀이 협업하고 변경을 추적하며 필요한 경우 이전 버전으로 롤백할 수 있습니다.\n- 재생산성: IaC를 사용하면 인프라를 쉽게 다른 환경으로 복제할 수 있어 개발, 테스트 및 프로덕션 간 불일치를 줄이고 일관성을 유지할 수 있습니다.\n- 확장성: IaC는 프로그래밍적으로 조정할 수 있는 매개변수와 정책을 정의하여 인프라 자원의 확장을 간소화하며 워크로드나 수요 변화를 수용할 수 있습니다.\n\n# 11. 로드 밸런서(load balancer)란 무엇인가요? 귀하의 경험에 따른 각 종류의 밸런서 시나리오를 제시해주세요.\n\n로드 밸런서는 사용자와 서버 그룹 사이에 위치하여 모든 리소스 서버가 공평하게 사용되도록 보장하는 보이지 않는 편의 기기 또는 서비스입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Application Load Balancer (ALB): ALB는 OSI 모델의 애플리케이션 레이어(Layer 7)에서 작동합니다. URL 기반 라우팅, 콘텐츠 기반 라우팅 및 HTTP/HTTPS 프로토콜 지원과 같은 고급 라우팅 기능을 제공합니다.\n- Network Load Balancer (NLB): NLB는 전송 레이어(Layer 4)에서 작동하며 초저지연으로 대량 트래픽을 처리하기 위해 설계되었습니다. TCP, UDP 및 TLS 트래픽에 적합하여 게임 애플리케이션 및 IoT 애플리케이션과 같은 사용 사례에 적합합니다.\n- Classic Load Balancer (CLB): CLB는 AWS에서 제공하는 레거시 로드 밸런서입니다. Layer 4와 Layer 7에서 모두 작동하며 기본적인 로드 밸런싱 기능을 제공합니다.\n\n## 12. 클라우드포메이션(CloudFormation)은 무엇이며 왜 사용됩니까?\n\nAWS CloudFormation은 템플릿을 사용하여 선언적 방식으로 인프라 리소스를 정의하고 프로비저닝할 수 있는 서비스입니다. AWS 리소스의 생성, 구성 및 관리를 자동화하는 방법을 제공합니다.\n\n클라우드포메이션은 배포를 자동화하고 리소스 일관성을 보장하며 스케일링을 관리하고 종속성을 처리하며 AWS 환경에서 변경 관리를 간소화하는 데 사용됩니다. 이는 AWS에서 인프라 자동화 및 관리를 위한 주요 도구입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 13. AWS CloudFormation과 AWS Elastic Beanstalk의 차이점은 무엇인가요?\n\nAWS CloudFormation:\n\n- AWS 인프라를 코드로 정의하고 프로비저닝하는 서비스입니다.\n- JSON 또는 YAML로 템플릿을 작성하여 AWS 리소스와 구성을 지정합니다.\n- EC2 인스턴스, 데이터베이스, 네트워킹 등 포함 전체 인프라 제어에 유용합니다.\n- 복잡한 아키텍처를 지원하며 리소스를 생성하거나 수정할 수 있습니다.\n- 주로 인프라 오케스트레이션과 구성 관리에 사용됩니다.\n\nAWS Elastic Beanstalk:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 웹 애플리케이션을 배포하고 관리하기 위한 Platform as a Service (PaaS)입니다.\n- 개발자는 자신의 애플리케이션 코드를 제공하고 Elastic Beanstalk이 인프라 프로비저닝을 처리합니다.\n- 간소화된 애플리케이션 배포와 확장성에 이상적입니다.\n- 다양한 프로그래밍 언어와 프레임워크를 지원합니다.\n- 인프라 관리에 깊게 개입하지 않고 신속하고 간편한 애플리케이션 호스팅에 최적화되어 있습니다.\n\n# 14. Amazon EC2 인스턴스의 저장 옵션을 나열하세요.\n\n- Amazon Elastic Block Store (EBS)\n- Amazon EC2 인스턴스 스토어\n- Amazon Elastic File System (EFS)\n- Amazon Simple Storage Service (S3)\n- Amazon Glacier\n\n# 15. 클라우드에서 발생할 수 있는 보안 공격 유형은 무엇이 있으며, 이를 최소화하는 방법은 무엇입니까?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클라우드 환경에서 여러 보안 공격이 발생할 수 있습니다:\n\n- 미인가된 접근: 공격자가 클라우드 자원과 데이터에 미인가된 접근을 시도할 수 있습니다.\n- 데이터 유출: 민감한 데이터가 클라우드 저장소나 데이터베이스에서 노출되거나 도용될 수 있습니다.\n- 분산 서비스 거부 (DDoS): 공격자가 과도한 트래픽으로 클라우드 인프라를 넘치게 하여 서비스를 이용할 수 없게 할 수 있습니다.\n- 보안이 취약한 API: API의 취약점을 악용하여 미인가된 접근이나 클라우드 자원 조작이 가능합니다.\n- 내부 위협: 특권 있는 접근 권한을 가진 악의적 내부 사용자가 민감한 정보를 남용하거나 유출할 수 있습니다.\n\n이러한 공격을 최소화하기 위해 다음과 같은 보안 모법을 따르세요:\n\n- 강력한 접근 제어를 시행하세요. 강력한 암호, MFA, 최소 특권 원칙을 적용하세요.\n- 이동 중인 데이터와 정지된 데이터를 암호화하세요.\n- 소프트웨어와 시스템을 정기적으로 업데이트하고 패치하세요.\n- 보안 사건을 감지하고 대응하도록 활동을 모니터링하고 로깅하세요.\n- 방화벽 및 침입 탐지/방지 시스템과 같은 네트워크 보안 조치를 시행하세요.\n- 정기적으로 보안 평가와 감사를 수행하세요.\n- 직원들에게 보안 인식 및 모범 사례에 관한 교육을 실시하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 16. EC2 인스턴스 키를 분실했을 때 복구할 수 있을까요?\n\nEC2 인스턴스와 인증에 사용된 키 쌍을 분실한 경우 해당 키를 사용하여 인스턴스에 액세스를 복구하거나 회복할 수 없습니다.\n\n그러나 여러 가지 방법으로 여전히 액세스를 복구할 수 있습니다: -\n\n- 원본 키 쌍 복구: 개인 키의 백업이 있거나 분실한 키를 검색할 수 있다면 키 쌍을 교체함으로써 액세스를 회복할 수 있습니다.\n- 새 EC2 인스턴스 생성: 원본 키 쌍을 복구할 수 없다면 인스턴스의 AMI를 만들고 새 키 쌍으로 새로운 인스턴스를 시작할 수 있습니다.\n- 인스턴스 메타데이터를 통한 액세스 (Linux 인스턴스): 일부 경우, IAM 역할을 갖는 Linux 인스턴스의 경우 인스턴스 메타데이터와 공개 키를 사용하여 인스턴스에 액세스할 수 있을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상호작용 문제를 방지하기 위해 예방적인 키 관리의 중요성과 백업 유지의 중요성을 강조하는 것이 중요합니다.\n\n# 17. 게이트웨이란 무엇인가요?\n\n게이트웨이는 서로 다른 네트워크 간의 입구점 또는 인터페이스로 작용하는 네트워킹 장치나 서비스입니다. 통신과 데이터 전송을 가능하게 하며 브리지나 커넥터로 작동하여 서로 다른 프로토콜이나 아키텍처를 가진 다른 네트워크를 연결합니다.\n\n게이트웨이는 라우팅, 프로토콜 변환, 보안 강화 및 네트워크 트래픽 관리와 같은 다양한 기능을 수행할 수 있습니다. 이러한 기능은 네트워크 간 연결성과 상호 운용성을 가능하게 하며 데이터가 원활하게 흐를 수 있도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n게이트웨이는 일반적으로 인터넷 환경에서 사용되며, 로컬 네트워크와 넓은 인터넷 간의 통신을 원활하게 돕는 도구로, 외부 자원 및 서비스에 접속할 수 있도록 합니다.\n\n## 18. Amazon RDS, DynamoDB 및 Redshift의 차이점은 무엇인가요?\n\nAmazon RDS (관계형 데이터베이스 서비스)는 MySQL, PostgreSQL, Oracle 및 SQL Server와 같은 관계형 데이터베이스를 실행하고 확장할 수 있도록 하는 관리형 서비스입니다. 자동화된 백업, 복제 및 패치 관리를 제공합니다.\n\nDynamoDB는 빠르고 원활한 확장 가능성을 제공하는 완전히 관리되는 NoSQL 데이터베이스 서비스로, 저 지연 시간 데이터 액세스를 요구하는 애플리케이션에 이상적입니다. 유연한 스키마 디자인과 수요에 따른 자동 스케일링을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRedshift은 온라인 분석 처리(OLAP)를 위한 최적화된 완전히 관리되는 데이터 웨어하우징 서비스입니다. 대용량 데이터 세트의 고성능 쿼리 및 분석이 가능합니다. Redshift는 데이터 웨어하우징 및 분석 워크로드를 위해 설계되었으며 구조화된 데이터에 대한 SQL 기반 쿼리를 지원합니다.\n\n# 19. 웹 사이트를 S3에 호스팅하는 것을 선호하십니까? 그렇다면 이유가 무엇입니까?\n\n네, S3에 호스팅:\n\n- 비용 효율적: S3에 웹 사이트를 호스팅하는 것은 트래픽이 낮은 정적 웹 사이트의 경우 특히 비용 효율적입니다. 사용한 스토리지 및 데이터 전송에 대해서만 지불하면 됩니다.\n- 확장성: S3는 대량 트래픽을 처리하고 자동으로 확장될 수 있습니다. 소규모에서 중간 규모의 웹 사이트에 적합합니다.\n- 간편한 설정: S3에 정적 웹 사이트를 설정하는 것은 간단하며 AWS는 이 프로세스를 단순화하기 위한 도구를 제공합니다.\n- 보안: S3는 접근 권한에 대한 세밀한 제어를 허용하며 다른 AWS 서비스와 통합하여 추가 보안을 제공할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아니요, S3에 호스팅하지 마세요:\n\n- 동적 콘텐츠: 서버에서 생성된 동적 콘텐츠에 의존하는 웹 사이트의 경우, S3만으로는 적합하지 않습니다. 동적 요청을 처리하기 위해 웹 서버나 서버리스 아키텍처가 필요합니다.\n- 데이터베이스: 사용자 인증, 전자 상거래 기능 또는 콘텐츠 관리를 위해 데이터베이스가 필요한 경우, S3가 최적의 선택이 아닙니다. 더 포괄적인 호스팅 솔루션이 필요합니다.\n- 복잡성: 다양한 기능, 상호 작용 및 데이터베이스를 갖춘 복잡한 웹 사이트의 경우, S3만 사용하면 관리가 복잡해질 수 있으며 다른 호스팅 솔루션이 더 적합할 수 있습니다.\n\n# 20. AWS Lambda란 무엇이며 어떻게 작동합니까?\n\nAWS Lambda는 서버를 프로비저닝하거나 관리하지 않고 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이는 이벤트 기반 모델을 따릅니다. 여러분의 코드는 AWS 서비스 또는 사용자 지정 트리거로부터 발생하는 이벤트에 응답하여 실행됩니다.\n\nLambda 함수는 여러 프로그래밍 언어로 작성될 수 있으며 특정 이벤트를 처리하거나 특정 작업을 수행하기 위해 설계될 수 있습니다.\n\nLambda 함수는 자동으로 확장되며 병렬로 실행될 수 있어 가용성이 높고 효율적인 리소스 활용을 보장합니다. Lambda를 사용하면 코드에서 소비하는 컴퓨팅 시간만 지불하면 됩니다.\n\n# 21. VPC(Virtual Private Cloud) 및 그 구성 요소를 설명해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVPC은 AWS 계정에 할당된 가상 네트워크로, AWS 클라우드의 논리적으로 격리된 영역을 제공합니다. 이를 통해 IP 주소 할당, 서브넷, 라우팅 테이블, 보안 그룹 및 네트워크 게이트웨이를 포함한 가상 네트워크 환경을 정의할 수 있습니다. VPC의 주요 구성 요소는 다음과 같습니다:\n\n- 서브넷: 자원을 프로비져닝할 수 있는 VPC 내의 IP 주소 세그먼트입니다.\n- 라우팅 테이블: 서브넷과 인터넷 간의 네트워크 트래픽 라우팅 규칙을 정의합니다.\n- 인터넷 게이트웨이: VPC 내의 인스턴스와 인터넷 간의 통신을 가능하게 합니다.\n- NAT 게이트웨이: 프라이빗 서브넷 내의 인스턴스가 안전하게 인터넷에 액세스할 수 있도록 합니다.\n- 보안 그룹: 인스턴스로의 들어오고 나가는 트래픽을 제어하는 가상 방화벽으로 작동합니다.\n- 네트워크 액세스 제어 목록(NACLs): 서브넷 수준에서의 네트워크 보안을 추가로 제어합니다.\n\n# 22. AWS DevOps 도구를 설명하여 클라우드에서 소프트웨어를 빌드하고 배포하는 방법을 설명하세요.\n\n클라우드에서 소프트웨어를 빌드하고 배포하기 위한 AWS DevOps 도구는 다음과 같습니다: -\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- AWS 클라우드 개발 키트: 인기 있는 프로그래밍 언어로 클라우드 애플리케이션 리소스를 모델링하고 프로비저닝하는 오픈 소스 소프트웨어 개발 프레임워크입니다.\n- AWS CodeBuild: 지속적으로 확장 가능한 다수의 빌드를 처리하고 코드를 테스트하는 지속적 인테그레이션 서비스입니다.\n- AWS CodeDeploy: Amazon EC2, AWS Fargate, AWS Lambda 등 선택할 수 있는 온프레미스 서버 중 하나로 소프트웨어 배포를 자동화하는 데 도움을 줍니다.\n- AWS CodePipeline: 지속적인 전달로 수신된 코드를 자동화하여 신속하고 정확한 업데이트를 수행합니다.\n- AWS CodeStar: AWS에서 애플리케이션을 개발, 빌드 및 배포하는 데 도움을 주는 사용자 인터페이스입니다.\n- AWS Device Farm: 다양한 모바일 장치 및 브라우저에서 애플리케이션을 테스트하는 플랫폼으로 작동합니다.\n\n# 23. 아마존의 이주 서비스에서 무엇이 제공됩니까?\n\n아마존은 다양한 이주 서비스를 제공합니다. 그것들은 다음과 같습니다: -\n\n- Amazon 데이터베이스 마이그레이션 서비스 (DMS)는 온프레미스 데이터베이스에서 아마존 웹 서비스 클라우드로 데이터를 매우 빠르게 마이그레이션하는 도구입니다. DMS는 온프레미스 및 클라우드에서 Oracle, SQL Server, MySQL 및 PostgreSQL 같은 RDBMS 시스템을 지원합니다.\n- Amazon 서버 마이그레이션 서비스 (SMS)는 온프레미스 워크로드를 아마존 웹 서비스 클라우드로 마이그레이션하는 데 도움을 줍니다. SMS는 클라이언트 서버 VMWare를 클라우드 기반 아마존 머신 이미지 (AMIs)로 마이그레이션합니다.\n- Amazon Snowball은 저 연결 환경에서 데이터 수집, 기계 학습, 처리 및 저장을 위한 데이터 전송 솔루션입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 24. Amazon에서 제공하는 메시징 서비스는 무엇인가요?\n\nAmazon은 여러 가지 메시징 서비스를 제공합니다. 그것들은 다음과 같습니다:\n\n- Amazon Simple Notification Service (SNS)은 AWS에 의해 완전히 관리되고 보안되며 사용 가능한 메시징 서비스로, 서버리스 애플리케이션, 마이크로서비스 및 분산 시스템을 디커플링하는 데 도움을 줍니다. SNS는 AWS 관리 콘솔이나 명령줄 인터페이스, 또는 소프트웨어 개발 키트에서 몇 분 내에 시작할 수 있습니다.\n- Amazon Simple Queue Service (SQS)는 서버리스 애플리케이션, 마이크로서비스 및 분산 시스템용으로 완전히 관리되는 메시지 대기열입니다. SQS FIFO의 장점은 이러한 종류의 메시징 서비스로 보내는 처리 시 단일 처리 및 정확한 순서를 보장합니다.\n- Amazon Simple Email Service (SES)는 클라우드 고객을 위해 SMTP 인터페이스를 통해 비공식적인, 통지 및 마케팅 대화를 위한 이메일 발송 및 수신 서비스를 제공합니다.\n\n# 25. 서브넷을 만드는 목적은 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n서브넷은 대규모 네트워크를 작은 네트워크로 분할하는 데 사용됩니다. 이는 트래픽을 라우팅하여 혼잡을 줄이며 성능을 크게 향상시킬 수 있습니다.\n\n# Elastic Beanstalk이란?\n\nElastic Beanstalk은 AWS의 오케스트레이션 서비스로, EC2, S3, Simple Notification Service, CloudWatch, 오토스케일링 및 Elastic Load Balancer와 같은 다양한 AWS 응용 프로그램에서 사용됩니다.\n\nAWS Management Console, Git 저장소 또는 통합 개발 환경(IDE)을 사용하여 AWS에 애플리케이션을 배포하는 가장 빠르고 간단한 방법입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 27. 클라우드프론트에서 지오 제약이란 무엇인가요?\n\n지오 제약은 클라우드프론트 웹 유통을 통해 제공되는 콘텐츠에 특정 지리적 위치에 있는 사용자가 액세스하는 것을 방지하는 방법으로, 일반적으로 지오 차단으로도 알려져 있습니다.\n\n# 28. Amazon ElastiCache의 사용 목적은 무엇인가요?\n\nAmazon ElastiCache는 클라우드에서 인메모리 데이터 저장소 또는 캐시를 쉽게 배포, 운영 및 확장할 수 있게 해주는 웹 서비스입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 29. 인스턴스를 중지와 종료하는 것을 구별해보세요.\n\n인스턴스를 중지할 때, 인스턴스는 정상적인 종료를 수행한 후 중지된 상태로 전환됩니다.\n\n인스턴스를 종료할 때, 인스턴스는 정상적인 종료를 수행합니다. 그리고 연결된 Amazon EBS 볼륨은 deleteOnTermination 속성이 false로 설정되어 있지 않는 한 삭제됩니다.\n\n# 30. 인기 있는 데브옵스 도구는 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인기 있는 DevOps 도구는 다음과 같습니다:\n\n- Chef, Puppet, Ansible, 그리고 SaltStack — 배포 및 구성 관리 도구\n- Docker — 컨테이너화 도구\n- Git — 버전 관리 시스템 도구\n- Jenkins — 지속적 통합 도구\n- Nagios — 지속적 모니터링 도구\n- Selenium — 지속적 테스트 도구\n\n# 31. 아마존 클라우드 서치의 기능은 무엇인가요?\n\n아마존 클라우드 서치의 기능은:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 자동완성 제안\n- 부울 검색\n- 전체 텍스트 검색\n- Faceting 용어 부스팅\n- 강조\n- 접두어 검색\n- 범위 검색\n\n**32. AWS의 EBS에서 데이터에 어떻게 액세스하나요?**\n\nAWS의 EBS에서는 그래픽 인터페이스를 통해 데이터에 직접 액세스할 수 없습니다. 이 과정에는 EBS 볼륨을 EC2 인스턴스에 할당하는 과정이 포함됩니다.\n\n여기서, 볼륨이 인스턴스 중 하나와 연결되면(윈도우 또는 유닉스), 해당 볼륨에 데이터를 쓰거나 읽을 수 있습니다. 먼저, 데이터가 있는 볼륨에서 스크린샷을 찍고 이를 활용하여 고유한 볼륨을 작성할 수 있습니다. 여기서, 각 EBS 볼륨은 단일 인스턴스에만 연결될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 33. AWS autoscaling에서 라이프사이클 후크란 무엇인가요?\n\n라이프사이클 후크는 autoscaling 그룹에 추가할 수 있습니다. 이를 통해 autoscaling 그룹이 인스턴스를 종료하고 시작할 때 일시 중지하여 사용자 정의 작업을 수행할 수 있습니다. 모든 오토 스케일링 그룹에는 여러 개의 라이프사이클 후크가 포함되어 있습니다.\n\n## 34. 하이퍼바이저란 무엇인가요?\n\n하이퍼바이저는 가상 머신을 생성하고 실행하는 데 사용되는 소프트웨어입니다. 물리적 하드웨어 리소스를 각 사용자에게 가상적으로 분배하는 플랫폼으로 통합됩니다. 하이퍼바이저에는 Oracle Virtual Box, Oracle VM for x86, VMware Fusion, VMware Workstation 및 Solaris Zones가 포함됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 35. AWS CloudTrail의 역할을 설명해주세요.\n\nAWS CloudTrail는 API 호출의 행동을 모니터링하고 감사하기 위해 설계된 서비스입니다. AWS CloudTrail을 사용하면 사용자는 AWS 인프라를 다루는 작업과 관련된 계정 활동을 모니터링하고 보관할 수 있습니다.\n\n# 36. Amazon Route 53을 설명해주세요.\n\nAmazon Route 53은 확장 가능하고 고가용성을 갖춘 도메인 네임 시스템(DNS)으로 정의됩니다. 이는 개발자와 기업의 이익을 위해 설계되었으며, 인터넷 애플리케이션으로 최종 사용자를 연결하기 위해 이름을 번역하는 가장 신뢰할 수 있고 비용 효율적인 프로세스입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 37. S3 요금을 결정하는 매개변수는 무엇인가요?\n\n아래는 S3 요금을 결정하는 매개변수입니다:\n\n- 전송 가속\n- 요청 횟수\n- 저장 관리\n- 데이터 전송\n- 사용된 저장소\n\n# 38. 다양한 종류의 인스턴스를 말해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 다양한 인스턴스 유형입니다:\n\n- Memory-optimized\n- Accelerated computing\n- Computer-optimized\n- General-purpose\n- Storage optimize\n\n39. RDS에서의 데이터베이스 유형을 나열해보세요.\n\n다음은 RDS에서 지원하는 데이터베이스 유형입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- MYSQL 서버\n- PostgreSQL\n- SQL Server\n- Aurora\n- Oracle\n- MariaDB\n\n## 40. 클라우드워치란 무엇인가요?\n\nAmazon CloudWatch은 메트릭 저장소입니다. 이를 사용하여 애플리케이션, 인프라 및 서비스를 모니터링할 수 있습니다. 또한 알람, 로그 및 이벤트 데이터를 활용하여 자동화된 작업을 수행하고 해결 시간을 단축할 수 있습니다.\n\n## 41. AWS의 키페어란 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n키 쌍은 공개 키와 개인 키로 구성되며, 가상 머신에 대한 안전한 로그인 정보입니다. Amazon EC2는 공개 키를 저장하고, 당신은 개인 키를 가질 수 있습니다.\n\n---\n\n*의견은 언제나 환영합니다.*\n\n~페이살 쿠잔","ogImage":{"url":"/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png"},"coverImage":"/assets/img/2024-06-19-DAY_2590INTERVIEWQUESTIONSONAWS_0.png","tag":["Tech"],"readingTime":18},{"title":"파이테스트Pytest와 파이스파크PySpark를 사용한 데이터 품질 유효성 검사를 위한 4가지 팁","description":"","date":"2024-06-19 12:01","slug":"2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark","content":"\n\n## 높은 품질과 신뢰할 수 있는 결과를 얻기 위한 변환된 데이터 테스트\n\n이 문서는 Likitha Lokesh와의 협력으로 작성되었습니다.\n\n![이미지](/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png)\n\n## 배경\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 최근 데이터 소프트웨어 프로젝트에 품질 엔지니어로 참여했는데, 여기서는 변환된 데이터에 대한 많은 테스트가 필요했습니다. 이 프로젝트에서는 데이터를 한 Amazon S3 버킷에서 다른 버킷으로 변환하기 위해 AWS Glue를 사용했습니다. 데이터는 Python을 사용하여 PySpark를 통해 변환되었고, 따라서 이러한 변환을 테스트하기 위한 테스트 자동화 프레임워크는 동일한 기술 스택에 의존했지만 Pytest도 추가되어 일관성을 유지하려고 노력했습니다.\n\nPytest, PySpark 및 AWS로 시작하는 방법에 대해 자세히 알아보려면 제 동료 Likitha Lokesh가 작성한 멋진 블로그를 확인해보세요.\n\n## 소개\n\n상기 프로젝트에서 우리 팀은 데이터를 제3자 소프트웨어 도구에서 소화되도록 변환했습니다. 데이터를 성공적으로 가져오기 위해 각 대상 파일에는 요구 사항 목록이 있었습니다. 각 대상 파일은 요구 사항을 충족해야만 소프트웨어가 데이터를 수용하고 데이터가 분석용으로 액세스 가능하지 않을 것이라는 문제를 방지할 수 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n목록에 나열된 요구 사항은 소스 파일에서 대상 파일로 데이터를 변환하는 데 필요한 스크립트가 어떻게 보이는지를 팀이 판단하는 데 도움을 주었지만, 모든 대상 파일의 데이터가 모든 요구 사항을 충족할 것을 보장하지는 않았습니다.\n\n데이터의 불일치는 데이터를 분석하거나 다른 목적으로 사용할 때 결과가 왜곡되는 원인이 될 수 있습니다. 이 프로젝트에서는 금융 데이터를 사용했기 때문에 데이터에 대한 신뢰 수준이 절대적으로 중요했습니다.\n\n따라서 다음과 같은 질문이 제기됩니다:\n\n모든 데이터 소프트웨어 프로젝트 솔루션은 일반적으로 맞춤형이 아니지만, 이 프로젝트에서 습득한 몇 가지 기술은 다양한 데이터 관련 프로젝트에서 효율적인 엔지니어링과 사고 과정에 도움이 될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 경험에서 데이터 품질 테스트를 위한 네 가지 주요 요점 목록을 만들었습니다:\n\n- 잘못된 데이터를 기록할 조건부로 단언을 감싸기\n- 공통 데이터 테스트 결정하고 매개변수화하기\n- 알려진 데이터 문제에 대한 Pytest 경고 및 XFail 활용하기\n- 환경 변수를 -E 플래그로 관리하기\n\n이 문서에서 네 가지 요점에 대해 각각 설명하고, 각 요점이 목록에 포함된 이유를 강조하겠습니다.\n\n## 단언을 조건부로 감싸기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전통 소프트웨어 프로젝트에서 자동화 테스트를 수행할 때, 버그에 대한 가시성은 디버깅 데이터보다 약간 더 명확합니다. 전통적인 소프트웨어 프로젝트나 애플리케이션에서는 앱을 열어 검사하거나 API를 검토할 수 있지만 데이터는 매우 많을 수 있습니다. PySpark에서 데이터 문제에 대한 가시성을 얻기 위한 돋보기는 데이터프레임입니다.\n\n제 프로젝트에서는 .csv 파일의 데이터를 테스트했습니다. 많은 테스트가 동일한 개요를 가지고 있었습니다:\n\n- .csv 파일을 읽어 데이터프레임 만들기\n- 데이터를 분석하기 위해 데이터프레임 메서드 사용(요구 사항에 따라)\n- 단언을 조건부로 래핑하기\n\n가령 파일의 한 열에는 ZIP 코드 데이터가 있고 요구 사항이 각 값이 정확히 5자여야 한다면, 해당 테스트는 다음과 같을 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport length\nimport logging\n\ndef test_zipcode_data_length(spark_source, csv_file_path: str):\n\n  ## .csv 파일을 읽고 DataFrame을 생성합니다.\n  dataframe = spark_source.read.csv(csv_file_path)\n\n  ## DF에서 filter 메소드를 사용하여 열 값 분석하고 \n  ## (다른 DF를 만듭니다)\n  invalid_rows = dataframe.filter(length(dataframe['Zipcode']) != 5)\n\n  ## 디버깅 및 정확한 위치를 찾기 위해 조건부로 Assertion을 감싸세요\n  if invalid_rows.count() == 0:\n    logging.info(\"예상대로 'Zipcode' 열의 모든 값이 5의 길이와 동일합니다!\")\n    assert True\n  else:\n    logging.error(\"'Zipcode' 열의 값은 모두 5의 길이와 동일해야 하지만 \n    예상과 다른 값이 존재합니다!\")\n  ## 요구 조건을 충족시키지 못하는 행이 포함된 필터링된 DF를 출력합니다\n    invalid_rows.show(truncate=False)\n    assert False\n```\n\n참고: 기사 전체에 코드 조각이 많습니다. 테스트 메소드 간 코드 중복을 줄이기 위해 테스트 도우미 함수를 사용하는 것이 best practice이지만, 이 기사의 목적에서는 벗어납니다.\n\n위의 예제에서 볼 수 있듯이, 단순한 True/False 어서션이 아니라 실패 시 적절한 로깅을 위해 조건부로 어서션을 배치하여 데이터가 기대에 충족되지 않을 경우 디버깅 및 특정 데이터 위치를 찾기 위해 필요한 기능이 수행됩니다. 잘못된 행이 포함된 DataFrame은 파일을 소프트웨어가 처리하려면 수정해야 할 데이터 위치를 특정하게 알려줄 수 있습니다.\n\n특정 열마다 모든 값이 정확히 5의 길이여야 하는 경우를 보여준 예제였지만, 테스트의 일반적인 개요/흐름의 원칙은 동일합니다. Assertion을 조건부로 감싸지 않고 다른 옵션은 무엇인가요? 변환된 .csv 파일을 다운로드하고 수동으로 검토하거나 필터링하여 오류 행을 찾을까요? 그것은 매우 흥미로운 옵션이 아닙니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n무엇을 테스트하든간에, 실패의 근본 원인을 빠르게 평가해야 하는 필요성은 항상 품질 테스트 전략의 구성 요소가 될 것입니다. 단언문을 조건문으로 감싸는 것은 그 필요에 대한 해답을 제공합니다. 조건문으로 단언을 감싸는 자동화된 접근은 효율적이며 데이터 관련 문제를 신속하게 다루는 실패 빠른 접근법을 제공합니다. 이 방식은 많은 짐작을 제거하고 시스템/파이프라인의 품질을 유지하거나 개선하는 데 필요한 구체적인 정보를 제공합니다.\n\n## 일반 데이터 테스트를 매개변수화 하기\n\n데이터는 방대하기 때문에 혐이 일 수 있지만, 테스트할 때는 일반적으로 모호함이 적습니다. 요구 사항은 매우 명확하며, 제 경험상 전통적인 소프트웨어 프로젝트보다 수집하기 쉽습니다. 종종 일반적인 데이터 요구 사항은 서로 다른 데이터 세트 간에 겹칠 수 있습니다.\n\n제 프로젝트의 경우, 생성되어야 했던 대상 파일 중 많은 파일들이 서로 다른 파일에 대해 유사한 요구 사항을 가지고 있었으며, 심지어 동일한 파일 내의 다른 열도 동일한 요구 사항을 가졌습니다. 간단히 유지하기 위해 각 파일이 데이터를 포함해야 한다는 요구 사항이 하나 있었는데, 이는 명백한 요구 사항처럼 보일 수 있지만 모든 파일에서 실행할 수 있는 매우 쉽고 빠른 자동화된 테스트이며, 예상치 못한 가장자리 경우의 데이터 변환 시나리오에서 유용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 가장 좋은 방법은 모든 대상 파일마다 동일한 간단한 테스트를 작성하지 않아도 되는 방법이 무엇인가요? 어떻게 코드 재사용성을 최대화할 수 있을까요? 답은 Pytest의 Parametrize 표시를 사용하여 테스트를 매개변수화하는 것이었습니다.\n\n```python\nimport pytest\n\n@pytest.mark.parametrize(VALUES HERE)\ndef test_data_present(spark_source, csv_file_path: str):\n\n  ## .csv 파일을 읽고 DataFrame 생성\n  dataframe = spark_source.read.csv(csv_file_path)\n\n  ## DF가 비어 있지 않은지 확인\n  assert dataframe.first() is not None\n```\n\nPytest의 parametrize 표시를 통해 모든 대상 파일을이 동일한 테스트를 통해 실행하여 생성되는 각 파일에 최소한 어떤 종류의 데이터가 포함되어 있는지 확인할 수 있습니다. 이전 프로젝트에서 추가 쉼표 구분 기호의 데이터 내 포함 또는 고유 데이터 필요 열을 확인할 때 특히 중요한 몇 가지 경우가 있었습니다.\n\n이 경우에 유의해야 할 점은 테스트 시나리오를 정의하는 초기 단계에서 노력이 더 필요할 수 있다는 것입니다. 공통 요구 사항을 찾고 코드를 재사용하는 최상의 전략을 고민하는 것입니다. 그러나 장기적으로 테스트 개발이 지수적으로 가속화될 것입니다. 이 경험에서 배운 점은 요구 사항을 더 잘 이해하고 먼저 이러한 요구 사항의 공통점을 파악해야 한다는 것이었습니다. — 테스트를 개발하기 전에.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요구 사항에 따라 생성 될 다양한 유형의 테스트 계획을 작성합니다. 데이터 유형, uniqueness, formatting, 추가 구분 기호 없음/데이터 내에서 적절한 열 구분이 유효성을 검사하도록 테스트 계획을 분석하고 가능한 한 테스트를 통합하려고 노력합니다. 요구 사항에서 패턴을 파악하고 테스트를 개발하기 전에 더 강력한 계획을 수립하는 것은 개발 속도 및 테스트 실행 속도를 높이는 데 도움이 됩니다.\n\n## 경고 및 XFail 활용\n\n데이터와 상호 작용할 때, 특히 민감한 데이터(예: 금융 데이터)를 사용하는 새 소프트웨어를 개발할 때는 종종 실제 데이터와 상호 작용하기 전에 먼저 낮은 환경에서 (예: 개발/테스트 환경) 시험적으로 개발됩니다. 이 과정은 개발 중에 모든 결함이 해결되는 동안 실제 데이터(프로덕션)를 보호하는 데 도움이 됩니다. 그러나 비프로덕션 환경 데이터의 관리 오류로 인해 데이터 관리가 어려워지고 결과가 왜곡될 수 있습니다.\n\n비프로덕션 환경 데이터의 관리 오류는 해결하기 어렵고 결과를 왜곡시킬 수 있습니다. 다행히도 Pytest에 내장된 두 가지 기능인 Pytest Warnings와 Pytest XFail을 활용하면 알려진 데이터 문제를 테스트하는데 도움을 받을 수 있습니다. 이 두 옵션 중에서 선호도나 권장사항이 없습니다. 상황에 가장 적합한 도구를 선택하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 전문에 나온 제안 중 첫 번째 제안을 이미 구현 중이거나 구현할 예정이라면, 당신은 쉽게 Pytest 경고를 동일한 개념에 임베딩할 수 있습니다. 여기서의 차이점은 거짓 주장 대신 경고가 발생할 것이랍니다. 아래와 같이 보일 거에요:\n\n```js\nimport warnings\nimport logging\n\ndef test_email_data_unique(spark_source, csv_file_path: str):\n\n  ## Read the .csv file and Create a DF\n  dataframe = spark_source.read.csv(csv_file_path)\n\n  ## Use the count method on DF to capture the number of total rows\n  num_rows = dataframe.count()\n\n  ## Use the select method - paired with the distinct and count methods\n  ## on DF to analyze column values for uniqueness\n  num_unique_rows = dataframe.select(dataframe['Email'].distinct().count())\n\n  ## Wrap Assertion in a Conditional and Leverage WARNINGS\n  if num_rows == num_unique_rows:\n    logging.info(\"All of the values in the 'Email' column are unique \n    as expected!\")\n    assert True\n  else:\n  ## Print the rows that don't meet the requirements\n    dataframe.groupBy(dataframe['Email']).count().where(\"count \u003e 1\").drop(\n    \"count\").show(truncate=False)\n  ## Warn instead of fail\n    warnings.warn(UserWarning(\"Some of the data in the 'Email' column is\n    not meeting the uniqueness requirement!\")\n```\n\n품질 엔지니어로서, 빨간색은 주의가 필요한 것을 나타냅니다. 알려진 문제에 대해 경고를 사용하는 가장 좋은 점은 '뉴트럴'에서 출력되기 때문에 \"이것은 알려진 사항이며 즉시 주의가 필요하지 않거나 걱정할 필요가 없습니다\"라는 메시지를 전달해준다는 점이었습니다. 이 메시지는 테스트 스위트를 실행할 때 다른 기여자들에게도 전달되어, 노력을 더이상 메신저로 행동하지 않고 팀의 속도에 집중하는 데 도움이 됩니다.\n\n알려진 데이터 문제를 다룰 수 있는 또 다른 좋은 옵션은 Pytest XFail 표시입니다. Pytest Warnings 능력과 유사하게, 테스트가 실패하면 결과가 빨강색 대신 노란색으로 나올 것입니다. 특히 적용 가능한 경우, 빨간색이 아닌 다른 색상으로 인사를 받는 것이 얼마나 유용한지 이중으로 강조할 수 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 스크린샷을 보면 'XFail'이라는 테스트가 노란색 'x'로 실행되었음을 나타낼 것입니다. 그러나 'XFail' 표시는 테스트의 어설션 섹션에 표시되지 않습니다. 'XFail'은 이전 섹션에서 테스트를 표시하는 방법과 유사하게 함수 상단에 표시됩니다. 아래 'XFail' 구현 내용을 확인해보세요:\n\n```js\nimport pytest\n\n@pytest.mark.xfail(reason=\"알려진 데이터 문제로 임시로 실패하는 것으로 예상됨\")\ndef test_date_format():\n\n## 나머지 테스트 내용\n```\n\n앞서 살펴본 경고 옵션처럼 이 유용한 'XFail' 표시는 품질 엔지니어가 적절한 문서 작성을 하고 동료에게 컨텍스트 정보를 남길 수 있도록 도와줍니다. 'XFail'의 중요한 추가 혜택 중 하나는 'XFail'로 표시된 테스트가 예상대로 실패하는 경우 (즉, 버그 수정이 해결된 경우)에 테스트가 실패하므로 품질 엔지니어는 이제 테스트를 수정/변경해야 한다는 것을 알 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주의해서 사용해주세요: 특정 프로젝트 요구 사항에 가장 적합한 경우/방법/이유를 고려해주세요. 예상치 못한 데이터의 불일치 사항을 확인한 후에만,\n\n- 실패의 근본 원인을 확인한 후에\n- 팀과 함께 실패의 우선 순위/심각성을 평가한 후에\n\nPytest의 이러한 기능을 활용해볼 수 있습니다.\n\n다른 한편으로, YELLOW 플래그로 특정 테스트를 지정할 수 있는 옵션을 가지고 있는 것은 필요한 자동화된 테스트가 문서화되어 테스트 스위트에 있고, 프로젝트가 제작으로 나아갈수록, 희망컨대 데이터 문제가 더 이상 발생하지 않는 환경에서 접근 가능하게끔 해줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 동적으로 환경 변수 관리하기\n\n네 키 포인트를 마무리하며, 다양한 환경 간 데이터 테스트의 세밀함에 대해 계속 다룰 것입니다. 이 기사의 시작 부분에서는 테스트 중인 데이터가 Amazon S3 버킷에 호스팅되어 있다고 언급했었습니다. 버킷 이름과 경로는 리포지토리의 INI 구성 파일에 나열되어 있었고, 다양한 테스트에 공급되었는데, 그러나 환경에 따라 약간 변경된 버킷 이름이 있었습니다.\n\n```js\n[BUCKET]\nS3 = my-dev-environment-bucket\n\n[PATH]\nFILE-PATH = pathway/to/dev/environment\n```\n\n버킷 이름과 해당 경로의 변종은 각 테스트 세션마다 터미널에서 동적으로 관리할 것이며, 이렇게 해서 Pytest의 -E 플래그가 유용하게 사용되었습니다. 픽스처와 pytest_addoption 함수를 사용하여 원하는 환경을 -E 플래그로 지정하고 표준 Pytest 명령에 따라 각 테스트 실행마다 환경을 전환시킬 수 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nINI 파일은 하드 코딩된 변수에서 약간 변형되었지만, 테스트에 전달되는 변수 이름에는 영향을 주지 않았기 때문에 이 조정은 테스트에 매우 낮은 영향을 미쳤습니다. 그런 다음 INI 파일 자체가 각 테스트 실행 중 임시 템플릿이 되었고, 테스트 실행 완료 후 복원되었습니다. 변형은 다음과 같았습니다:\n\n```js\n[BUCKET]\nS3 = my-{env}-environment-bucket\n\n[PATH]\nFILE-PATH = pathway/to/{env}/environment\n```\n\nINI 파일에 대한 이 조정과 테스트 세션 중 파일을 관리하는 몇 가지 방법과 함께, 필요한 환경에 따라 pytest -E=dev 또는 pytest -E=qc 또는 pytest -E=prod와 같은 명령이 되었습니다. 이 변경으로 인해 환경간 전환의 복잜한 점 때문에 버킷 이름이 변하는 것이 매우 간단해졌습니다. 이제 더 이상 특정 환경에서 테스트 실행을 수행하려면 INI 파일의 변수 이름을 변경하는 것을 매번 기억해야 했던 의존성이 없어졌습니다. 액세스 권한이 있는 모든 팀원이 이제 명령줄에서 쉽게 환경 간 전환을 할 수 있습니다.\n\nINI 파일에서 이 유연성을 어떻게 구현하는지에 대해 자세히 알아보려면, 여기에서 내 How-To 기사를 확인해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 마무리 생각\n\n빠르게 복습해보면, 이 글에서 강조한 데이터 품질 테스트의 네 가지 주요 포인트는 다음과 같습니다:\n\n- 로그에 잘못된 데이터를 기록하기 위해 어설션을 조건문으로 래핑\n- 일반적인 데이터 테스트를 결정하고 매개변수화\n- 알려진 데이터 걱정 사항에 대해 Pytest Warnings와 XFail 활용\n- -E 플래그로 환경 변수 관리\n\n이러한 전략들을 통해 변환된 데이터의 품질에 대한 신뢰 수준을 높이는 것이 전반적인 목표입니다. 이러한 포인트들이 유익했고 다음 데이터 프로젝트에서 유용한 팁과 전략을 얻을 수 있었으면 좋겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제안 사항에 대한 피드백을 알고 싶어요. 언제든지 댓글로 의견을 남겨주세요!\n\n#QE4DE\n\n## 자료\n\n- AWS Glue 정보\n- Amazon S3 정보\n- PySpark 문서\n- Pytest 문서\n- Likitha Lokesh의 PySpark, Pytest, Amazon S3 시작하기\n- PySpark 데이터프레임\n- Pytest 파라미터화\n- Pytest 경고\n- Pytest 실패 예상\n- Pytest -E 플래그\n- Taylor Wagner의 INI 파일 변수 조작 방법","ogImage":{"url":"/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png"},"coverImage":"/assets/img/2024-06-19-4TipsforDataQualityValidationswithPytestandPySpark_0.png","tag":["Tech"],"readingTime":10},{"title":"AWS 프로젝트 시간 예측 그건 그냥 제안일 뿐이에요","description":"","date":"2024-06-19 12:00","slug":"2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion","content":"\n\nAWS 프로젝트 지침을 따르는 것은 할머니의 전설적인 초콜릿 칩 쿠키 레시피를 따르는 것과 같아. 낡은 인덱스 카드에는 \"12분 동안 굽다\"고 적혀 있을지도 모르지만, 우리는 다들 할머니가 영혼으로 측정한 게 분량 컵이 아니란 걸 알아. 클라우드에서 무언가를 구축할 때는 항상 제안된 시간보다 오래 코드 속에 팔 다쳐 있을 수밖에 없어.\n\n이런 이유로 나, 당신의 클라우드 전문가이자 친구인 쉐이가 여기 있어서 조언하려고 해: 그 프로젝트 시간 추정치는 실은 지침일 뿐이지, 신약의 진리는 아니라는 거야.\n\n특히 머신 러닝에 관한 이야기일 때 말이야!\n\n![/assets/img/2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion_0.png]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 목표는 머신러닝에 초점을 맞춘 클라우드 어드보케이트가 되는 것입니다. 그래서 매일 한 프로젝트를 다루고 그 달콤한 (가끔은 조금 탄) 여정을 문서화하고 있어요.\n\n오늘의 프로젝트? 머신러닝 모델을 실시간 추론 엔드포인트에 배포하는 것이죠.\n\n![image](/assets/img/2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion_1.png)\n\n쉽죠? 이게요, 상상해보세요: 재료 구비는 끝났지만, 그런데 여러분이 하나 중요한 재료를 놓치고 있는 걸 깨달았다는 거죠 — 이해력!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 제 빵 만들기 경험에서 배운 것들이 있어요:\n\n- 콘솔 변화: 할머니가 가끔 가장 좋아하는 주걱을 숨기는 것처럼, AWS 도구들은 종종 콘솔에서 자리를 옮기곤 해요. 한 분 동안 \"엔드포인트 생성\"이 여기 있었던 걸 분명 보았다고 생각하더니도 이젠 사라진 것 같아요! 걱정 마세요, 여기서 아마존 Q(AWS 내장 AI 챗봇)가 당신의 가장 친한 친구가 됩니다. 결국 그 빠진 도구는 전혀 다른 페이지에 숨어 있었던 거예요! 와, 여기 있네요! 이 예상치 못한 우회로로 +15분을 더하면 됩니다.\n- 문서 작성은 장식하기와 같아요: 제는 메모를 작성하고 어리버리한 비유를 만들며 다이어그램을 그리는 것을 좋아해요. 이것은 마치 과자에 장식을 하는 것 같아요 – 이런 방식으로 제가 더 잘 기억하고 전체 과정을 더 재미있게 만들어요! 하지만 장식하는 것처럼, 문서 작성은 프로젝트에 추가로 +30분이 걸려요. . . 어쨌든\n- 혼란스러운 개념? 심층 탐구 시간! 가끔 기술 용어가 전혀 이해가 되지 않을 때가 있어요. 그럴 땐 제 비밀 무기인 ChatGPT를 꺼내볼게요. 이 도구는 복잡한 개념을 예시 사용 사례와 함께 작은 조각으로 나눠줘요. 추가로 +45분을 더하게 되죠! (진짜로, 때로는 가장 좋은 학습이 호기심의 토끼 굴 속에서 일어나요).\n\n\n\u003cimg src=\"/assets/img/2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion_2.png\" /\u003e\n\n\n최종 판정: 성공, 그리고 여분의 시간 한 잔 같이요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로젝트가 마침내 성공을 거두었어요! 내 모델을 배포했고, 많은 것을 배웠으며, 애매한 클라우드 개념을 이해하는 새로운 방법을 발견하기도 했어요. 하지만 여기서 중요한 점은 이겁니다: 프로젝트가 예상 시간보다 오래 걸린다고 좌절하지 마세요. 뜻밖의 학습 모험을 포용하고, 기억하세요, 가장 맛있는 쿠키(그리고 가장 멋진 머신 러닝 프로젝트)은 종종 좀 더 구워야 할 때 더 맛있어져요.\n\n그래서 다음에 AWS 프로젝트 예상을 보게 된다면, 한 줌의 소금과 미소와 함께 받아들이세요. 예상치 못한(그리고 교육적인) 경험이 기다리고 있을지도 몰라요!\n\nInstagram/TikTok에서 더 많은 콘텐츠를 만나보세요:\n\n@ShaeInTheCloud\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLinkedIn:\n\n[데샤이 리다 프로필](https://www.linkedin.com/in/deshae-lyda/)\n\n#MachineLearning #AWS #CloudDeveloperAdvocate #CloudEngineer","ogImage":{"url":"/assets/img/2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion_0.png"},"coverImage":"/assets/img/2024-06-19-ThoseAWSProjectTimeEstimatesHoneyThatsJustaSuggestion_0.png","tag":["Tech"],"readingTime":3},{"title":"구글 드라이브를 무료 클라우드 저장 공간 솔루션으로 활용하여 머신 러닝 데이터 동기화를 자동화하는 방법","description":"","date":"2024-06-19 11:59","slug":"2024-06-19-HowdidIuseGoogleDriveasafreecloudstoragesolutiontoautomatesyncingmyMachineLearningdata","content":"\n\nGoogle Drive은 문서와 미디어를 저장하는 데 탁월한 도구이지만, 상상해보세요: 어떻게 하면 앱의 데이터를 저장하는 데 사용할 수 있을까요? 네, 저도 구름에 멀티플레이어 게임 데이터를 안전하고 무료로 저장하는 방법을 고민하고 있었습니다. 이 기사에서는 기계 학습을 위해 게임 데이터를 Google Drive에 저장한 방법에 대해 설명하겠습니다.\n\n![이미지가 여기에 표시됩니다.](/assets/img/2024-06-19-HowdidIuseGoogleDriveasafreecloudstoragesolutiontoautomatesyncingmyMachineLearningdata_0.png)\n\n📢 안녕하세요, 이 기사에서 언급된 서비스 중 어느 것도 스폰서로서 제작되지 않았습니다. 제가 애플리케이션에서 직접 사용해보며 개발자로서의 경험을 공유하고자 합니다.\n\n📢 이 기사는 구글 서비스와의 인증을 위해 서비스 계정을 사용하는 데 어느 정도 익숙한 것으로 가정합니다. 서비스 계정 및 해당 링크를 통해 어떻게 생성하는지에 대해 더 알아볼 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 🤔 왜 구글 드라이브를 사용하게 된 걸까요?\n\n\"The Strategists\"의 승자를 예측하기 위한 머신 러닝 모델을 개발하는 도중, 모든 게임 데이터를 로컬 머신에 저장했습니다. 그 당시에는 그 방식이 합리적으로 느껴졌지만, 도커를 사용하여 게임을 컨테이너화하고 클라우드에 배포하기 시작하면서 몇 가지 의문이 생겼습니다.\n\n훈련된 모델을 도커 이미지에 포함해야 할까요? 게임을 한 번씩 진행할 때마다 모델을 다시 훈련하기 때문에 게임 데이터를 도커 이미지에 포함해야 할까요? 게임 데이터를 도커 이미지에 저장하는 것이 안전한 일일까요? 이러한 질문들을 고민하면서, 보안 위험이 있기 때문에 모델과 게임 데이터를 함께 도커 이미지에 포함시키지 말아야겠다는 결론에 도달했습니다.\n\n그래도 \"The Strategists\"를 배포할 때, 모든 게임 데이터와 예측 모델을 백엔드 도커 이미지에 포장해서 배포했습니다. 배포된 컨테이너에서 주기적으로 새로운 게임 데이터를 추출하는 아이디어도 고안했었죠. 이미 알 수 있겠지만, 이는 확장 가능한 해결책이 아니었습니다. 배포 단계에서 모델을 포장하지 않고 프로그래밍적으로 게임 데이터를 다운로드하고 업로드하며 훈련된 모델을 내보내야 한다는 것을 알았습니다. 그렇다면 어떻게 해야 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이번 사용 사례에서는 Amazon S3 및 Google Cloud Storage와 같은 서비스를 탐색해 보았어요. 이전 글을 읽은 분들은 저의 의도를 알 거예요. 요금을 청구하지 않는 서비스를 찾았고, 호기심 많은 개발자로서 Google Drive를 사용하기로 결정했어요. Google Drive API를 사용해보고 싶었는데, 이는 Google Drive를 애플리케이션의 데이터 저장소로 사용하기 위한 기능을 프로토타입화하는 완벽한 기회였어요.\n\nGoogle Drive를 사용하여 프로덕션에 준비된 애플리케이션을 개발하는 것은 표준 산업 관행이 아니라는 점을 강조해야 해요. Amazon S3와 같은 서비스는 오브젝트 잠금 및 ID 및 액세스 관리를 포함한 더 넓은 범위의 기능을 제공해요. 게다가, Google Drive의 무료 계층은 15GB의 저장 공간으로 제한되어 있어요.\n\n# 🛠️ 게임 데이터 동기화 구현은 어떻게 이루어졌을까요?\n\n우선, 제가 어떻게 게임 데이터를 동기화하는지에 대해 이야기해볼게요. 제 로컬 설정에서는 The Strategists의 머신 러닝 워크플로를 설명해서 서버 시작 시 모델을 훈련시킨 다음, SpringBoot 기반의 백엔드 서비스는 각 게임 세션 후에 다시 훈련시켰어요. 이 훈련은 플레이어 투자 패턴을 CSV 파일로 내보낸 다음, 예측 모델 디렉토리에 게임 상태를 내보낸 후에 발생했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 내보내기 디렉토리에는 내보낸 CSV 파일이 모두 저장되어 있었기 때문에 훈련 스크립트는 이 데이터를 모두 로드하고 해당 데이터를 사용하여 모델을 훈련했습니다. 첫 번째 과제는 서버가 시작될 때 이 디렉토리를 채우는 것이었습니다. 훈련 스크립트가 예측 모델을 내보내기 위한 작업이 가능하도록 하려면 구글 드라이브 폴더에 있는 기존 CSV 파일을 업로드했습니다. 이 \"Downloads\" 폴더는 이제 게임 서버에서 사용 가능한 게임 데이터를 찾기 위해 참조되는 진실의 원천으로 제공됩니다.\n\n이 과제에 대처하기 위해 \"Downloads\" 폴더에서 이 CSV 파일들을 다운로드하는 Python 유틸리티를 아래 스니펫처럼 작성했습니다. 실제 코드는 여기에서 확인할 수 있습니다.\n\n```js\n# Google 서비스에 연결하기 위한 서버 자격 증명 생성\ncredentials = Credentials.from_service_account_file(filename=\"\u003cSERVICE_ACCOUNT_FILE의_경로\u003e\")\n\n# Google 드라이브 서비스 초기화\nservice = discovery.build(\"drive\", \"v3\", credentials=credentials)\n\n# \"Downloads\" 폴더에 있는 모든 CSV 파일 나열\nall_csv_files, page_token = [], None\nwhile True:\n\n  # 현재 페이지 토큰에 대해 csv 파일 나열\n  response = (\n    service.files().list(\n      q=f\"(mimeType='text/csv') and ('\u003cDOWNLOADS_폴더_ID\u003e' in parents)\",\n      spaces=\"drive\",\n      fields=\"nextPageToken, files(id, name)\",\n      pageToken=page_token\n    ).execute()\n  )\n\n  # 리스트에 csv 파일 추가\n  csv_files, page_token = response.get(\"files\", []), response.get(\"nextPageToken\", None)\n  all_csv_files.extend(csv_files)\n\n  # 더 많은 csv 파일이 있는지 확인\n  if page_token is None:\n    break\n\n# 나열된 모든 csv 파일 다운로드\nfor i, csv_file in enumerate(all_csv_files):\n\n  # csv 파일 메타데이터 가져오기\n  csv_file_id, csv_file_name = csv_file.get(\"id\"), csv_file.get(\"name\")\n  \n  # csv 파일 바이트 가져오기\n  csv_bytes = io.BytesIO()\n  downloader = MediaIoBaseDownload(file, request)\n  downloaded = False\n  while downloaded is False:\n    status, downloaded = downloader.next_chunk()\n\n  # 파일 내용 저장\n  export_file_path = os.path.join(\"\u003c데이터_디렉토리\u003e\", csv_file_name)\n  with open(export_file_path, \"wb\") as csv:\n    csv.write(csv_bytes.getvalue())\n```\n\n구글 서비스 계정의 이메일 주소가 최소한 \"뷰어\" 권한으로 이 CSV 파일에 액세스할 수 있도록 이 \"Downloads\" 폴더를 공유하도록 반드시 확인해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 다운로드 문제를 해결했으니, 이제 새 CSV 파일을 Google 드라이브에 업로드하는 방법을 구현하기 시작했습니다. 이를 위해 \"Uploads\"라는 폴더를 만들었고, CSV 파일의 다운로드와 업로드를 위해 별도의 폴더를 유지했습니다. 새 CSV 파일이 다운로드 폴더로 이동하기 전에 먼저 제가 확인할 수 있도록 했습니다.\n\n다음 코드 조각은 이 \"Upload\" 폴더로 CSV 파일을 업로드한 방법입니다. 실제 코드는 여기에서 확인하실 수 있습니다.\n\n```js\n# 모든 로컬 csv 파일 나열\nlocal_csv_files = []\nfor file_name in os.listdir(\"\u003cDATA_DIRECTORY\u003e\"):\n  if file_name.endswith(\".csv\"):\n    local_csv_files.append(file_name)\n\n# 나열된 모든 로컬 csv 파일 다운로드\nfor i, local_csv_file in enumerate(local_csv_files):\n\n  # 업로드할 CSV 파일을 업로드 폴더에 업로드\n  local_csv_file_path = os.path.join(\"\u003cDATA_DIRECTORY\u003e\", local_csv_file)\n  mimeType = \"text/csv\"\n\n  body = {\n    \"name\": local_csv_file,\n    \"mimeType\": mimeType,\n    \"parents\": [\"\u003cUPLOADS_FOLDER_ID\u003e\"]\n  }\n  media = MediaFileUpload(local_csv_file_path, mimetype=mimeType)\n  file = service.files().create(body=body, media_body=media, fields=\"id\")\n```\n\n스크립트가 새 CSV 파일을 업로드할 수 있도록 Google 서비스 계정 이메일 주소에 적어도 \"편집자\" 권한으로 이 \"Uploads\" 폴더를 공유해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실제 코드 구현에서는 서버 데이터 디렉토리에 있는 CSV 파일만 다운로드했습니다. 업로드에 대해선 \"다운로드\" 또는 \"업로드\" 구글 드라이브 폴더에 이미 존재하지 않은 CSV 파일만 업로드했습니다.\n\n이 기사가 여러분이 응용 프로그램의 무료 클라우드 저장소로 Google 드라이브를 어떻게 사용하는지 이해하는 데 도움이 되었으면 좋겠습니다. The Strategists의 개발을 계속 따르고 싶다면 제 블로그를 구독해보세요. 프로젝트에 기여하는 것을 고려해주시고, 다음 링크를 통해 GitHub의 프로젝트 저장소에 액세스할 수 있습니다.\n\n제 포트폴리오를 확인해보세요. 시간 내어 이 기사를 읽어주셔서 감사합니다.","ogImage":{"url":"/assets/img/2024-06-19-HowdidIuseGoogleDriveasafreecloudstoragesolutiontoautomatesyncingmyMachineLearningdata_0.png"},"coverImage":"/assets/img/2024-06-19-HowdidIuseGoogleDriveasafreecloudstoragesolutiontoautomatesyncingmyMachineLearningdata_0.png","tag":["Tech"],"readingTime":6},{"title":"퀘스트 3용으로 제작된 18가지 혼합 현실 게임을 소개합니다","description":"","date":"2024-06-19 11:57","slug":"2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay","content":"\n\n## 사이드퀘스트가 추천하는 당신을 위한 최고의 혼합 현실 게임: MR-ready Quest 3에서 즐기세요!\n\n![2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay_0.png](/assets/img/2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay_0.png)\n\n메타 퀘스트 3이 퀘스트 2보다 한층 더 놀라운 점 중 하나는 완전한 컬러 패스스루(full-color passthrough) 및 이로 인해 제공할 수 있는 혼합/증강 현실 경험입니다. 실제로, 이는 일반적으로 보다 강력하며, 이 강력함을 확인하고 싶다면 이 목록의 20개 무료 VR 게임을 확인해보세요!\n\n하지만, 퀘스트 3의 크게 향상된 혼합 현실을 활용하기 위해 당신이 지금 당장 SideQuest에서 시도할 수 있는 최고의 18개 MR 경험 목록을 만들었습니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1. Track Craft\n\nTrack Craft는 RC 레이싱과 스팅팅이 혼합된 독특한 Mixed Reality 경험을 즐기세요! 새로운 트랙과 차량을 잠금 해제하여 차고에 추가하고, 내장된 도전 과제와 타임 트라이얼에 도전하고, 직관적인 트랙 편집기를 사용하여 자신의 실제 게임 공간을 RC 천국으로 변신시킬 수도 있습니다!\n\nTrack Craft는 매우 세련된 MR 즐거움이며 실제로 2023 인디 스포트라이트에서 다루었는데, 이를 이 기사의 끝에서 시청할 수 있습니다!\n\n## [Track Craft 다운로드하기!]\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2. CoasterMania\n\n**CoasterMania**로 당신의 거실을 극한의 테마파크로 변신하세요!\n\n**Track Craft**와 마찬가지로 **CoasterMania**는 집 안 공간에서 꿈꾸던 롤러 코스터를 디자인하고 형태를 만들 수 있는 전례없는 창의적인 옵션을 제공합니다. 그리고 나서 그 차에 올라타서 당신이 만든 코스터를 체험할 수 있습니다. 이 게임은 현재 초기 액세스 단계에 있지만, 업데이트는 계속해서 빠르게 제공될 예정이니, 개발자들에게 귀중한 피드백을 SideQuest에서 꼭 남겨주세요.\n\n## [CoasterMania 다운로드하기!]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3. Cubism\n\nCubism의 점점 어려워지는 퍼즐들로 두뇌를 도전하고 즐거움을 느껴보세요. 완전한 핸드 트래킹 지원, 라이트와 다크 모드, 두 개의 캠페인, 지역 퍼즐 편집기를 통해, 이 공간 퍼즐 보석과 함께 아담 새비지와 함께 하루의 '첫 커피를 마시게 될 때' 두뇌를 활성화하세요. Cubism는 SideQuest에서 시작된 최초의 게임 중 하나이며, 공식 메타 스토어로 진출하여 엄청난 인기를 끌고 있으니 계속해서 소개해 주는 것에 열정적입니다!\n\n## [Cubism 다운로드]\n\n# 4. Puzzling Places\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVR로 즐기는 신선한 3D 직소퍼즐링이 'Puzzling Places'로 등장했습니다. 이것은 외부 세계를 잊고 마음을 단련시키는 뛰어난 방법으로, 자세한 사진촬영 스캔을 통해 정성스럽게 재현된 21개의 멋진 실제 세계 퍼즐 중 하나로 도망가 보세요. 각 퍼즐은 여러 난이도로 제공되어 직소퍼즐 실력을 테스트할 수 있습니다. 이것은 SideQuest에서 공식 스토어로 이동한 또 하나의 공을 드리는 제목이며, 여러분의 시간을 100% 충분히 가치 있는 시간으로 만들어 줄 것입니다.\n\n## [Puzzling Places 다운로드하기]\n\n# 5. Dungeon Maker\n\n'Dungeon Maker'로 '바닥이 용암이다'를 더 진보된 수준으로 가져오세요. 이 앱은 투과 모드에서 자신만의 맞춤 던전을 만들고 함정, 함정, 적들, 용암 통행 및 기타 도전 과제를 설정할 수 있습니다. 그리고 가장 중요한 것은: 완전히 무료로 즐길 수 있습니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## [던전 메이커 무료로 받으세요!]\n\n# 6. 미라클 풀\n\n미라클 풀은 혼합 현실의 가장 훌륭한 예 중 하나로, 집 안 공간에 실제와 같은 크기의 가상 풀 테이블을 가져왔습니다. 그 위엔 마치 진짜처럼 보이는 텍스처가 있어, 진짜 것인 줄 알았을 정도입니다. 뿐만 아니라 만족스러운 물리학과 현실적인 게임 플레이로, 미라클 풀은 VR에서 풀을 즐기는 최고의 방법입니다!\n\n## [미라클 풀 다운로드하기!]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 7. 히트스트림\n\n히트스트림은 여가 시간에 단독 개발자가 만든 것이며, 즐겁고 빠르며 치열한 운동뿐만 아니라 MR이 체험을 더 높이는 데 사용될 수 있는 훌륭한 예시입니다. 땀을 흘리면서 운동을 즐길 때 어떤 것에 부딪힐 걱정도 없습니다!\n\n## [무료 데모 플레이!]\n\n## [히트스트림 다운로드!]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 8. 피아노 비전\n\n우리는 2023 인디 스포트라이트에 피아노 비전도 포함했는데, 이 앱은 SideQuest에서 가장 우수한 음악 앱 중 하나로 한 번 더 인정받아야 합니다! 최고 수준의 MR 기능과 핸드 트래킹 기능을 갖추고 있어, 새로운 피아노 스킬을 배우거나 초보자로서 건반을 연주해 보고 싶다면, 피아노 비전이 당신을 훌륭하게 만졌습니다.\n\n## [피아노 비전 다운로드하기!]\n\n# 9. 공간 작전\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n재미있고 열정적이며 완전 무료로 즐길 수 있어요—단지 Quest 3 부대를 가져와서 강렵한 FPS 액션에 대비하세요. Spatial Ops는 혼합 현실로 완전히 이루어진 멀티플레이 도시 전투터로 어떠한 실제 공간을도 온전히 바꿀 수 있어요. 인상적인 MR 기술을 최대한 활용할 수 있는 충분히 넓은 지역을 선택해보세요!\n\n## [Spatial Ops를 무료로 받아보세요!]\n\n# 10. Smash Drums\n\n다른 인기있는 SideQuest의 탈출 ‘smash’ 히트곡인 Smash Drums은 무대에서 드럼 연주의 즐거움을 당신의 거실에서 느낄 수 있게 해줘요. 현재 46곡의 클래식 트랙과 곧 추가될 더 많은 곡을 함께 드럼 연주할 수 있는 Smash Drums은 Quest 3의 MR 능력을 완전히 활용한 훌륭한 리듬 게임입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## [스매시 드럼 받기!]\n\n# 11. 장난감 몬스터\n\n장난감 몬스터는 손 추적과 혼합 현실을 염두에 두고 처음부터 만들어진 독창적인 타워 방어 게임입니다. MR에서 식물 대 좀비를 생각해보세요. 이런 비교를 할 때 기대되는 매력, 디테일, 다채로운 게임플레이가 모두 있습니다!\n\n## [장난감 몬스터 받기!]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 12. Spacefolk City\n\nSpacefolk City은 마치 전통적인 우주 도시 건설 시뮬레이션의 재치있는 그래픽으로 вas킨릴를 끌어들입니다 - 이제 MR에서도 즐길 수 있습니다! 자유롭게 떠다니는 도시의 위치를 조절하여 당신의 방에서 그를 즐길 수 있어요. 자유와 도전의 균형을 즐길 수 있어 계속해서 더 돌아오게 될 겁니다!\n\n## [Spacefolk City 다운로드하기!]\n\n# 13. Eleven Table Tennis\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 현실 세계의 탁구를 좋아한다면 Eleven Table Tennis가 딱 맞는 게임입니다. 물리 엔진이 훌륭하고 만족스럽습니다. MR 업데이트로 액션을 집 안으로 가져왔습니다! 다른 플레이어와 온라인 대결이 가능하거나 실력 있는 AI와 연습 모드에서 대결할 수 있어 여기에서 많은 즐길 거리가 있습니다.\n\n## [이븐 탁구 게임 다운로드]\n\n# 14. 더 우즐스\n\n만약 레밍스를 좋아한다면 우즐스도 즐길 수 있고, 퀘스트 3에서 혼합 현실을 시도하고 싶은 사람에겐 보석 같은 게임입니다. 기즐모이드를 신비한 지형과 나의 집 안으로 안내하여 승리로 이끌어 주세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금으로서는 위즐즈는 무료로 플레이할 수 있어요!\n\n## [위즐즈 무료로 받기!]\n\n# 15. FPS 향상현실\n\nFPS 향상현실은 퀘스트 2에서 훌륭했지만 퀘스트 3의 훨씬 우수한 MR 기능으로 인해 정말 자신을 찾아냈습니다. 당신의 집이 전쟁터로 변하면 다양한 무기와 몰입형 커버 시스템을 이용해 AI 적들과의 전투를 벌일 수 있어요. 미래에는 온라인 PvP도 예정되어 있어요...\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## [FPS 향상된 현실을 경험하세요!]\n\n# 16. 고릴라질라: 맥시멈 램페이지\n\n고릴라질라는 당신의 거실을 번화한 대도시로 변신시켜주는 대성공 MR 게임입니다! \n\n퀘스트 3용으로 최적화되어 있어 특정 거대 고릴라로 변신하여 가상 도시를 파괴하고 싶다면 이 게임은 확실한 히트작입니다...\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## [고릴라질라 게임을 만나보세요!]\n\n# 17. Deisim\n\nDeisim은 SideQuest에서 공식 스토어로 진출한 대히트 중 하나이며 지금, 혼합 현실에서 Deisim을 플레이할 수 있습니다!\n\n당신의 창조물을 살려내고, 사람들을 이끄는 것, 그리고 자신만의 공간에서 건물을 세우는 등 당신이 우상화되길 원하는 욕망을 충족하세요. 혹시 당신의 거실에서요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDeisim은 이전에도 좋았지만, 이 MR 업데이트로 더욱 멋지게 변했어요!\n\n## [Deisim 다운로드하기!]\n\n# 18. MR Chess\n\n![이미지](/assets/img/2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컴퓨터와 대결하거나 친구들과 함께 MR Chess에서 체스 실력을 겨루세요!\n\n가장 뚜렷한 특징은 혼합 현실에서 실체 체스판 또는 가상 체스판을 사용할 수 있는 능력입니다. 진정으로 자신만의 방식으로 플레이할 수 있도록 합니다. 가상으로 선택하면 만족스러운 햅틱 피드백이 디지털적인 느낌을 물리학적으로 느낄 수 있게 해주고, 실체 체스판을 선택하면 상대방의 말들이 디지털적으로 실체 체스말과 함께 나타납니다. 정말 똑똑한 기능이에요!\n\n## [Get MR Chess!]\n\n# 2023 SideQuest Indie Spotlight\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 목록에 소개된 몇 가지 게임은 2023년 말에 우리의 인디 스폿라이트에 포함되었습니다. 이는 독립적인 타이틀들의 성취나 미래 가능성을 인정하고자 하는 쇼케이스였어요.\n\n지금 바로 플레이할 수 있는 놀라운 인디 타이틀로 가득한 전체 스폿라이트를 확인해보세요:\n\n# SideQuest 소개\n\nSideQuest는 독립적인 VR 커뮤니티를 대표합니다. 전 세계의 개발자와 플레이어들이 함께 창작하고 공유하며 사랑하는 가상현실 앱들에 대해 흥분할 수 있는 곳이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개발자들(우리와 같은)은 공식 상점에 도달하는 과정에서 메커니즘과 모드를 자유롭게 실험할 수 있고, 플레이어들은 실제로 모든 것이 한곳에 모인 멋진 VR 세계에서 수천 개의 앱을 안전하게 탐험할 수 있어요.\n\n제한이 필요할까요?\n\n[SIDEQUEST 여기서 가져오기]\n\n[BANTER 다운로드: 우리의 무료 소셜 VR 게임]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n서민수님의 SideQuest🚀 계속 진행하도록 해요...\n\n웹사이트 | 페이스북 | 트위터 | 인스타그램 | 틱톡 | 레딧 | 미디엄 | 디스코드 | 링크드인 | 연구 클럽 | 수다방","ogImage":{"url":"/assets/img/2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay_0.png"},"coverImage":"/assets/img/2024-06-19-18MixedRealityGamesForQuest3YouNeedToPlay_0.png","tag":["Tech"],"readingTime":6}],"page":"22","totalPageCount":98,"totalPageGroupCount":5,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"22"},"buildId":"o1YmnmSuZvAX2O4TI9r41","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>