<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/89" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/89" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/YUMR4jSyk_WlOHHc7UfOk/_buildManifest.js" defer=""></script><script src="/_next/static/YUMR4jSyk_WlOHHc7UfOk/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="기업용 프롬프트 엔지니어링 관행" href="/post/2024-05-18-EnterprisePromptEngineeringPractices"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="기업용 프롬프트 엔지니어링 관행" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="기업용 프롬프트 엔지니어링 관행" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">기업용 프롬프트 엔지니어링 관행</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="경험 많은 ChatGPT 사용자를 위한 4가지 인간-인공지능 상호작용 패턴" href="/post/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="경험 많은 ChatGPT 사용자를 위한 4가지 인간-인공지능 상호작용 패턴" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="경험 많은 ChatGPT 사용자를 위한 4가지 인간-인공지능 상호작용 패턴" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">경험 많은 ChatGPT 사용자를 위한 4가지 인간-인공지능 상호작용 패턴</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="GPT-4, 아직 실망스러워" href="/post/2024-05-18-GPT-4ostilldisappointing"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="GPT-4, 아직 실망스러워" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-GPT-4ostilldisappointing_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="GPT-4, 아직 실망스러워" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">GPT-4, 아직 실망스러워</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="환각, 오류 및 꿈" href="/post/2024-05-18-HallucinationsErrorsandDreams"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="환각, 오류 및 꿈" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-HallucinationsErrorsandDreams_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="환각, 오류 및 꿈" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">환각, 오류 및 꿈</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">30<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="인간 중심 AI 핀 부적절한 전략과 실행 사례 연구" href="/post/2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="인간 중심 AI 핀 부적절한 전략과 실행 사례 연구" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="인간 중심 AI 핀 부적절한 전략과 실행 사례 연구" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">인간 중심 AI 핀 부적절한 전략과 실행 사례 연구</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT-4의 비밀 슈퍼파워 YouTube 데모에서 보이지 않은 것들 " href="/post/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT-4의 비밀 슈퍼파워 YouTube 데모에서 보이지 않은 것들 " loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT-4의 비밀 슈퍼파워 YouTube 데모에서 보이지 않은 것들 " loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">ChatGPT-4의 비밀 슈퍼파워 YouTube 데모에서 보이지 않은 것들 </strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="BiTCN 컨볼루션 네트워크를 활용한 다변수 시계열 예측" href="/post/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="BiTCN 컨볼루션 네트워크를 활용한 다변수 시계열 예측" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="BiTCN 컨볼루션 네트워크를 활용한 다변수 시계열 예측" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">BiTCN 컨볼루션 네트워크를 활용한 다변수 시계열 예측</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="시간을 통해 전파하는 역전파  RNN이 학습하는 방법" href="/post/2024-05-18-BackpropagationThroughTimeHowRNNsLearn"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="시간을 통해 전파하는 역전파  RNN이 학습하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="시간을 통해 전파하는 역전파  RNN이 학습하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">시간을 통해 전파하는 역전파  RNN이 학습하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법" href="/post/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2" href="/post/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">39<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/81">81</a><a class="link" href="/posts/82">82</a><a class="link" href="/posts/83">83</a><a class="link" href="/posts/84">84</a><a class="link" href="/posts/85">85</a><a class="link" href="/posts/86">86</a><a class="link" href="/posts/87">87</a><a class="link" href="/posts/88">88</a><a class="link posts_-active__YVJEi" href="/posts/89">89</a><a class="link" href="/posts/90">90</a><a class="link" href="/posts/91">91</a><a class="link" href="/posts/92">92</a><a class="link" href="/posts/93">93</a><a class="link" href="/posts/94">94</a><a class="link" href="/posts/95">95</a><a class="link" href="/posts/96">96</a><a class="link" href="/posts/97">97</a><a class="link" href="/posts/98">98</a><a class="link" href="/posts/99">99</a><a class="link" href="/posts/100">100</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"기업용 프롬프트 엔지니어링 관행","description":"","date":"2024-05-18 19:57","slug":"2024-05-18-EnterprisePromptEngineeringPractices","content":"\n# 소개\n\n대규모 언어 모델(LLM)과 상호작용하는 것은 본질적으로 프롬프트에 매우 의존합니다. 프롬프트는 모델로부터 특정한 동작이나 출력을 유도하기 위한 자연어 지침입니다.\n\n프롬프트는 비전문가에게 LLM에 접근할 수 있게 돕긴 하지만, 복잡하거나 특정 작업에 대한 효과적인 프롬프트를 만드는 것은 어렵습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델을 원하는 결과물로 이끄는 것에는 기술, 지식 및 반복적 개선이 필요합니다.\n\nIBM 연구팀은 사용자가 프롬프트를 반복하면서 어떻게 사용하는지 연구했으며, 이 연구는 다음을 이해하는 데 도움이 됩니다.\n\n- 프롬프트 사용 및\n- 모델 동작, 그리고\n- 효율적인 프롬프트 엔지니어링에 필요한 지원\n\n일반적으로 프롬프트에는 내장 예시, 템플릿, 필요한 출력물에 대한 설명, 지시사항 및 In-Context Learning을 위한 문맥 데이터가 포함될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결과\n\n결과는 두 부분으로 나뉩니다.\n\n먼저, 연구는 관찰된 프롬프트 편집 세션들에 대한 광범위한 양적 분석을 제공합니다.\n\n이어서 연구는 리뷰 및 주석 프로세스에서 나온 더 포괄적인 결과에 대해 심층적으로 다루며 질적 관측을 통합합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 프롬프트 편집 세션은 일반적으로 상당한 기간 동안 진행되었으며, 평균 세션은 약 43.4분의 시간이 소요되었습니다.\n- 사용자들은 종종 모델 매개변수를 조정하는 대신에 또는 함께 프롬프트를 편집하는 데 집중합니다.\n- 사용자들은 원하는 결과를 얻기 위해 프롬프트를 조금씩 반복적으로 변경하는 경향이 있어, 프롬프트 세부 조정 반복 과정에서 불규칙적으로 행동하지 않는 것으로 나타났습니다.\n- 사용자들은 프롬프트를 개선하는 동안 추론 매개변수를 자주 조정했으며, 관찰된 세션 중 93%가 이러한 매개변수를 하나 이상 변경한 것으로 나타났습니다.\n- 가장 자주 변경된 매개변수는 대상 언어 모델 (모델 ID)이었으며, 이어서 최대 새 토큰 및 반복 패널티 매개변수가 조정되었습니다.\n\n성공적인 결과를 얻으려면 사용자들이 프롬프트를 조금씩 반복적으로 변경하는 경향이 있는 것으로 보입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n매개변수 변경은 변경이 발생한 세션의 백분율로 기록되었습니다.\n\n사용자들은 대부분 대상 언어 모델을 수정하고 생성할 토큰의 최대 수를 조정하며 반복 패널티를 미세 조정했습니다. 또한, 중단 시퀀스, 온도 및 디코딩 방법을 변경하는 것이 자주 관찰되었습니다.\n\n각 프롬프트 구성 요소에 초점을 맞춘 편집 횟수. 사용자들은 기본적으로 맥락을 편집했으며 작업 지시사항은 상대적으로 적게 수정되었습니다.\n\n이것은 다시 한번 보여주는 것입니다. 인컨텍스트 러닝(ICL)을 유지하는 관점에서 맥락은 매우 중요하며, 그 다음이 작업 지시사항이라는 것을 입증합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 그래프는 사용된 모델 수를 보여줍니다. 대부분의 세션은 두 개의 모델을 살펴본 것이 흥미로운데, 아마도 쉬운 A/B 테스트 접근법을 수행했을 것입니다.\n\n가장 많이 사용된 수정 작업과 텍스트의 문맥이 보강되거나 변경되거나 수정 또는 제거되어야 하는 작업은 편집 유형 중 가장 많이 사용된 것입니다.\n\n# 콘텍스트\n\n분석된 프롬프트와 사용 사례 대부분은 콘텍스트 기반입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프롬프트 안에 입력, 배경 데이터 또는 예시가 통합되어 있었으며, 작업 지시와는 분리되었습니다.\n\n모든 분석된 세션에서 맥락이 가장 자주 편집되는 구성 요소로 부각되었으며, 기업 업무에 대한 그 중요성을 강조했습니다.\n\n맥락 추가의 두 가지 주요한 패턴:\n\n- 대화 시뮬레이션 및\n- 예시 추가.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 태그를 마크다운 형식으로 변경하실 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n22%의 편집이 여러 번의 변화를 만들고 나서야 다시 프롬프트를 제출하는, 다중 편집이었습니다.\n\n평균적으로, 이러한 다중 편집에는 약 2.29개의 변경이 포함되었으며, 대부분은 컨텍스트에 대한 편집을 포함했습니다.\n\n다중 편집은 효율적으로 보일 수 있지만, 결과물에 미치는 영향을 추적하기를 어렵게 할 수 있습니다. 추가로, 편집의 약 1/5은 추론 매개변수의 변경과 함께 이루어졌으며, 이는 변경을 관리하고 모델 동작에 미치는 영향을 이해하기 위한 체계적 접근의 필요성을 시사합니다.\n\n# 롤백\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n약 11%의 프롬프트 편집이 이전 변경 사항을 취소하거나 다시 실행하는 것을 포함했습니다. 이에도 불구하고 이러한 작업은 개별 편집으로 계산되었습니다.\n\n이러한 행동은 과거 결과를 기억하는 데 어려움이 있거나 어떤 편집이 출력물을 개선할 수 있는지에 대한 불확실성을 시사할 수도 있습니다.\n\n재미있게도, 덜 자주 편집되는 프롬프트 구성 요소는 이전 변경 사항을 취소하는 편집 비율이 더 높았습니다.\n\n예를 들어, instruction:handle-unknown에 대한 편집의 40%가 되돌려졌으며, instruction:output-length에 대해 25%가, 라벨에 대해 24%가, instruction:persona 편집에 대해서는 18%가 되돌려졌습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n이 연구는 1523개의 개별 프롬프트로 구성된 57개의 프롬프트 편집 세션을 분석했습니다. 이 프롬프트 편집 세션은 프롬프트 실험 및 개발을 용이하게 하는 엔터프라이즈 LLM 도구를 사용하였습니다.\n\n사용자들은 종종 모델 파라미터를 조정하는 대신 또는 나란히 프롬프트를 편집하는 데 초점을 맞춥니다.\n\n이러한 편집 중 많은 것들은 완전한 개조보다는 단일 프롬프트에 대한 소규모 조정이나 반복입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n품질 분석 결과를 살펴보면 사용자들이 주로 예시, 기반 문서, 그리고 입력 쿼리와 같은 프롬프트 컨텍스트를 수정한다는 것을 강조합니다.\n\n의외로도, 컨텍스트 편집은 지시사항 편집보다 많은 것으로 드러났는데, 이는 과제 또는 출력 형식, 길이, 또는 페르소나와 같은 요소를 설명하는 것과 관련이 있습니다.\n\n라벨 편집 및 프롬프트 구성 요소 정의는 또한 일반적입니다.\n\n이러한 통찰력은 현재의 프롬프트 편집 관행을 살펴보고 더 효과적인 프롬프트 엔지니어링 지원을 위한 미래 방향을 제시해줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n⭐️ 제 LinkedIn에서 큰 언어 모델에 관한 업데이트를 받아보세요 ⭐️\n\n![이미지](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_1.png)\n\n저는 현재 Kore AI의 최고 전도사입니다. 인공지능과 언어가 교차하는 모든 영역에 대해 탐구하고 쓰고 있습니다. 대형 언어 모델(Large Language Models), 챗봇(Chatbots), 음성봇(Voicebots), 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제를 다룹니다.\n\n![이미지](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-18-EnterprisePromptEngineeringPractices_3](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_3.png)\n\n![2024-05-18-EnterprisePromptEngineeringPractices_4](/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_4.png)\n","ogImage":{"url":"/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_0.png"},"coverImage":"/assets/img/2024-05-18-EnterprisePromptEngineeringPractices_0.png","tag":["Tech"],"readingTime":8},{"title":"경험 많은 ChatGPT 사용자를 위한 4가지 인간-인공지능 상호작용 패턴","description":"","date":"2024-05-18 19:53","slug":"2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers","content":"\nChatGPT가 출시된 지 1년 반이 되었지만, 전체 사용자 중 30% 이상이 그것을 실력을 발휘한 AI 챗봇으로 사용하고 있습니다. 대부분의 사람들은 대화식 인공지능의 '특징'인 상호작용 뒤집기, 기준 기반 자가평가, 그리고 인간과 함께 작업을 공동으로 구상하는 것에 대해 자각하지 못하고 있습니다. 결과적으로 그들은 AI를 위한 작업을 상세히 설명하고 AI 출력물의 여러 수정본을 분석하는 데 많은 시간을 투자하지만, 여전히 기대보다 못한 결과물을 얻고 있습니다. 어떻게 이를 해결할지 알아봅시다.\n\n![Huma-AI Interaction Patterns](/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_0.png)\n\n# 소개\n\n지역 \"관리용 AI\" 커뮤니티의 적극적 구성원으로, ChatGPT와 다른 GenAI 어시스턴트의 숙련된 사용자조차도 대화식 방식을 통해 전통적인 방법으로 진행한다는 점을 자주 발견합니다. 그들은 완전한 지침을 작성해야 한다고 가정하고, AI가 그들의 지침을 따르기만을 기대합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAI 챗봇은 자주 우리의 질문에 답하거나 우리의 지시에 따라 텍스트를 생성하거나 데이터를 처리하는 도구로만 보입니다. 챗봇이 만족스러운 결과물을 제공하지 못하면, 우리는 더 잘 가르쳐 주어야 하거나, 간단히 챗봇을 사용하지 않을 수도 있습니다. 또한, 우리가 시간을 들여 작업을 자세히 설명할 여유가 없거나 아직 작업 자체를 완전히 이해하지 못했을 때는 AI를 사용하지 않기도 합니다.\n\n그러나 이 전통적인 시각은 생성적 AI의 범위와 가치를 제한합니다. 사실, 대형 언어 모델은 우리에게 요청에 응답하거나 지시에 따라 행동하는 것 이상의 다양한 역할을 수행할 수 있습니다. 더욱이, 더 나은 결과물을 얻기 위해 항상 가르치거나 \"훈련\"시키지 않아도 됩니다.\n\n간편함을 위해, 나는 관행적이지 않은 AI 역할을 4가지 인간-인공지능 상호작용 패턴으로 그룹화하겠습니다. 그래서 이 기사는 4개의 섹션으로 구성되어 있습니다. 그러나, 이것은 제 개인적인 단순화일 뿐입니다. 제 주요 아이디어는 특정 역할에 관한 것이 아니라, 인간-인공지능 상호작용의 표준 \"요청-응답\" 모델을 확장하는 것에 대한 것입니다.\n\n# 1. 뒤바뀐 상호작용 전략\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAI 역할 영역에서 첫 번째로 명백하지 않은 패턴은, AI가 질문을 하면서 선도하는 \"뒤바뀐 상호 작용\"이다.\n\n연구 논문[1]은 프롬프트 엔지니어링의 맥락 속에서 뒤바뀐 상호 작용 패턴을 검토하며, 페르소나 패턴 및 템플릿 패턴과 같은 다른 기술과 함께 다룬다. 뒤바뀐 상호 작용 패턴은 짧은 블로그 글에서 프롬프팅 기술로도 설명된다.\n\n## 이유\n\n일반적으로, 이 방식은 인간으로부터 요구되는 시간과 인지적 노력을 줄여주어 일반적인 AI 사용자의 목표에 완벽하게 부합된다. 마찬가지로, 일반적인 인터넷 사용자는 내용이나 제품 제안을 받는 것을 좋아하며, 스스로 질문을 명확히 표현할 필요가 없다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 사용 사례\n\n- 예를 들어, AI 챗봇은 종종 멘토로 사용됩니다. 이러한 멘토의 이득 중 절반은 제공하는 조언에 있지 않습니다 (제 경험 상 종종 너무 일반적이고 실행할 수 없는 경우가 많음), 오히려 사용자가 문제에 대한 해결책을 찾도록 자극하는 사고를 유도하는 능력에 있습니다.\n- 똑같이, \"강력한\" 개방형 질문을 제공하여 사용자의 문제와 도전 과제를 식별하는 데 도움이 되는 AI 코치의 역할도 동일합니다.\n- 또는 개인 맞춤형 AI 튜터의 역할을 살펴보면 기본적으로 사용자의 지식과 기술에 있는 공백을 식별하고 이후에 해당 공백을 채우기 위해 질문을 하는 데 초점을 맞춥니다.\n- 마찬가지로 동료의 역할도 AI가 질문하는 것을 전제합니다. 이러한 종류의 질문은 사람이 어떠한 목표를 달성하기 위한 동기부여를 찾는 데 도움이 됩니다.\n\n## 구현 예시\n\n예를 들어, AI 튜터로 넓은 주제를 빠르게 숙달하고 싶다면 \"내가 `주제`에 대해 이해하는 현재 수준을 알아보기 위해 N개의 개방형 질문을 해 주세요\"라고 요청할 수 있습니다. 그런 다음, 답변을 평가하고 식별된 가장 약한 영역에 초점을 맞춘 새로운 질문을 요청할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 빠른 피드백이 있는 적응형 학습으로 이어집니다. 이는 학습자에게 우선 순위를 명확하게 제시하여 교육적 요구 사항에 대한 우선 순위를 투명하게 제공합니다. 이와는 달리 기존의 적응형 학습 시스템에서는 학습자에게 우선 순위가 불투명합니다.\n\nGPT-4와의 샘플 채팅은 여기에서 찾을 수 있습니다. 이 예시에서 실습 중인 주제를 배우고 있으므로 ChatGPT는 사용자에게 질문이 아닌 과제를 부여하고 있습니다.\n\n# 2. 협업 작업 정의 및 맥락 향상\n\nAI 챗봇이 질문을 하면서 상호작용이 뒤바뀌는 상황을 접근 방법으로 보기도 합니다. AI와의 Q\u0026A 세션의 목표는 빠르게 작업 관련 맥락을 형성하는 것으로, 이는 챗봇을 일반적인 응답자/수행자 역할로 활용하기 위해 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 그 이유\n\n적어도 이 방법은 복잡한 작업을 직면했을 때 미루는 주요 이유인 \"빈 페이지\" 문제를 극복하는 데 도움이 될 수 있습니다. 이 문제는 특히 본적 없는 문제를 해결하도록 챗봇에 요청할 때 특히 발생합니다.\n\n사람들은 (위의 게시물을 예로 들면) AI에 임무 초안을 빠르게 작성하여 빈 페이지 문제를 해결할 수 있다고 생각합니다. 이는 도움이 될 수 있지만, 그러한 임무 초안의 AI 출력물은 면밀히 조사되어야 하며 대부분은 품질이 낮아서 버려지게 됩니다.\n\n동일한 문제에 대한 더 나은 해결책은 먼저 챗봇에서 질문을 받고, 출력물은 나중에 생성하는 것입니다. 그 이유는 질문을 선택하고 답하는 것이 작업을 처음부터 설명하는 것보다 훨씬 용이하기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이터레이션 질문의 두 번째 장점은 고품질 결과물입니다. 결과물은 단순히 유사한 문제에 대한 일반적인 해결책이 아닌 특정 컨텍스트에 의존합니다. 일정 작업을 해결하기 위한 전체 과정을 인공지능이 질문을 던지면서 구축할 수 있습니다. 이에 대답하고, 그에 따라 추가 질문을 받습니다. 이렇게 계속되다가 \"이제 `모든 내용을 고려한 완전한 해결책을 제안해 주세요`\"와 같은 문구를 봇에게 전할 때까지 진행됩니다.\n\n## 활용 사례\n\n- 이러한 작업을 드물게 다루거나 해당 주제에 익숙하지 않은 경우, 올바른 단어와 전반적인 작업 이해가 부족할 수 있습니다. 그럴 때는 AI에게 자세한 작업의 여러 버전을 제안하도록 유도하고, 필요에 맞는 버전을 선택한 후에 품질 높은 결과물을 기대할 수 있습니다. 그렇지 않으면 \"입력이 나쁘면 출력도 나쁘다\"라는 원칙이 적용됩니다.\n- 주어진 작업 분야의 전문가인 경우, \"만능 보조자\"가 예상한 출력을 생성하는 데 필요한 컨텍스트가 부족한지 이해할 수 있는 수준으로 내려가고 어렵다고 느낄 수 있습니다. 보조자에게 필요한 정보에 대해 스스로 이야기하도록 해보세요!\n\n## 구현 예시\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n특정 상황에서 중요한 질문 종류는 아직 충분히 이해하지 못한 작업을 명확히하기 위해 사용되는 질문입니다. 처음에는 “...에 관련된 작업 서식을 제안해주세요”와 같은 식으로 요청할 수 있습니다. 그런 다음, 요구사항에 가장 부합하는 서식을 선택한 후 \"이 작업을 좀 더 명확히 하기 위해 질문해주세요\"라고 말할 수 있습니다 (이러한 패턴은 기사 [1]에서 논의된 질문 정제 패턴(Question Refinement Pattern)과 인식 확인 패턴(Cognitive Verifier Pattern)과 비슷합니다). 그럼, AI 질문 중 일부에 대답하고 일부는 의도적으로 무시합니다. 무시하는 것도 작업과 관련된 집중된 문맥을 만드는 데 중요합니다.\n\n\"일부 항목 선택\"이라고 말할 때, 혹은 \"일부 질문에 대답\"할 때, 목록 항목의 숫자만 사용한다는 점을 의미합니다. 최신 LLM(언어모델)은 이러한 숫자를 잘 이해하며, 시간을 절약하는 면에서 매우 유용합니다.\n\n![이미지](/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_1.png)\n\n구체적인 예로, 고용 인터뷰를 위한 준비 목표를 살펴보겠습니다. AI에게 쉬운 작업은 아닙니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 초보 사용자는 인공지능에게 공석에 관한 몇 문장을 바탕으로 인터뷰 질문을 작성하도록 요청할 수 있으나 결과는 대부분 만족스럽지 못할 것입니다.\n- 숙련된 사용자는 가능한 모든 관련 정보인 직무 설명서와/또는 업무 목록을 인공지능에게 제공할 것입니다. 그러나 이 경우에도 결과물은 너무 일반적할 가능성이 높습니다. 대규모 언어모델(Large Language Model, LLM)은 아름답게 표현할 수 있지만, 본질적으로 제공된 문서의 단어를 표준 \"인터뷰 템플릿\"에 반영한 것 뿐입니다. 해당 직무를 직접 수행해 본 적이 없기 때문에 직무 설명서에서 특히 중요한 부분을 내재적으로 이해할 수 없습니다. 또한 문서에는 내게 특히 중요한 후보자 특성이 무엇인지에 대한 정보가 없기 때문에 이를 알 수도 없습니다.\n\n그러므로 우리는 인공지능에게 설명을 명확히 하도록 요구해야 합니다. 다음과 같은 방식으로 지시할 것입니다:\n\n- 직무 설명서에서 위의 목적을 위해 필요한 정보를 추출합니다 (첨부된 문서 참조).\n- 직무의 특징과 내 개인적인 선호도를 이해하기 위해 필요한 여러 질문을 저에게 하십시오. 질문은 특정하고 문서와 일치하도록 해야 합니다. 질문 목록은 번호가 매겨져야 합니다.\n- 제 답변을 토대로 직무와 제 선호도를 깊이 이해하십시오. 제가 무의미하다고 생각하는 측면은 무시하십시오. 그 후, 앞서 강조된 모든 중요한 부분을 다루는 인터뷰 질문을 구성하십시오.\n\n이와 같은 예시를 따르는 GPT-4 채팅은 여기에서 찾을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## AI 혼란을 피하는 방법\n\n특정 사항에 대한 추가 설명을 요청하여 위의 프로세스를 이어 나갈 수 있습니다. 그러나 장황하게 되풀이하지 말고 \"그냥 질문을 하기 위해서\" 질문을 하는 것을 피하십시오. 목표는 귀하의 작업을 이해하는 데 도움을 주는 것뿐만 아니라 AI를 효과적으로 작업 솔루션으로 이끄는 것이기 때문입니다. 문맥 속 과도한 단어는 LLM이 귀하의 의도한 방향으로 멀어지게 할 수 있습니다 [4].\n\nAI 혼란의 가능성을 줄이기 위해 작업을 해결하기 바로 전에 다음과 같이 말할 수 있습니다. \"이제 위의 모든 사항을 고려한 나의 작업을 완전히 정리해보세요.\" 그리고 즉시 해결책을 요청하는 대신이 테크닉은 두 가지 이유로 유용합니다:\n\n- 문맥 속 마지막 메시지가 완전한 작업이 되며, 가장 최근의 메시지는 LLM에 대비 문맥을 준비하는 챗봇 알고리즘에 의해 중요하게 여겨집니다. LLM은 \"주의\"를 가지고 있기 때문에 문맥의 모든 부분을 동등하게 취급하지 않습니다.\n- 작업 설명에 잘못된 부분이 있는 경우 최종 단계 전에 해당 부분을 교정하는 것이 좋습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 어떻게 더 많은 노력을 줄일 수 있을까요?\n\n제가 믿습니다. 당신이 병원에서 다른 상황을 찾을 수 있을 것이라고 생각합니다. 전환된 상호작용이 특히 당신에게 유용할 수 있습니다. 이 전략은 맥락 형성과 질문 그 자체에 모두 사용될 수 있습니다 (AI가 코치, 친구, 멘토 또는 선생님 역할을 하는 것).\n\n그러나 만약 여러분이 자주 AI와 상호작용을 전환한다면, 거의 모든 단계에서 챗봇에게 질문 제시하기에 지쳐 버릴 수 있습니다. 따라서 AI에게 한 번만 이 작업을 수행하도록 요청할 수 있습니다. 신뢰성을 위해 이를 \"시스템 프롬프트\"라고 부르는 것이 좋습니다.\n\n- ChatGPT Plus를 사용하는 경우, 시스템 프롬프트를 적용하는 것은 당신 자신의 GPT를 만들고 \"Instructions\" 필드에 프롬프트를 입력하는 것을 의미합니다. 그런 다음 사용자 요청과 어시스턴트의 응답과 별도로 LLM에 전달될 것입니다.\n- 다른 시스템 프롬프트를 만드는 또 다른 방법은 ChatGPT Plus 같은 비용이 많이 드는 구독 없이 가능합니다. 각 주요 LLM 공급업체는 ChatGPT나 Claude.ai보다 더 많은 제어권을 제공하는 도구를 제공합니다. OpenAI는 Playground, Anthropic은 Console, Google은 AI Studio를 제공하며 이러한 도구를 사용하여 시스템 프롬프트를 설정하고 LLM 버전을 선택하고 온도 및 기타 매개변수를 할당할 수 있습니다. 이는 구독 비용보다 적은 비용이 필요합니다. 게다가, Anthropic은 새로운 사용자에게 무료 5달러 크레딧을 제공하며 Google AI Studio는 무료로 이용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은시스템 프롬프트용으로 예시 구문을 드렸습니다: “사용자가 무엇을 요청했다면 (질문을 한다거나 지시를 한다 등), 그 요청의 더 나은 버전을 제안해야 합니다 (더 구체적인 출력으로 이어질 수 있는 상세한 버전) 그리고 사용자에게 내 버전을 사용하고 싶은지 물어보아야 합니다.”. 이 구절은 질문 개선 패턴의 한 종류로, 이와 유사한 패턴에 대해 여기에서 읽어볼 수 있습니다.\n\n## 3. 인간 역할에 기반한 AI 상호작용\n\n\"고객-수행자\" 모델 이외의 사람들과 상호작용하는 다른 방법을 살펴보세요. 상호작용이 뒤바뀔 필요는 없습니다. 즉, 초기화와 질문이 반드시 챗봇에서 나와야 하는 것은 아닙니다. 사실, 이전에 언급된 \"멘토-견습생\" 및 \"선생님-학생\" 모델은 전자에서 나오는 질문에 관한 것만이 아닙니다.\n\n여러분과 AI 간에 가능한 상호작용 모델은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## AI가 당신의 부하로: 정기적으로 승인하고 수정하기\n\n이러한 인간 관계는 보스가 지시를 내리고 부하가 말 없이 실행하는 것만큼 간단한 것이 아닙니다. 예를 들어, 부하들은 종종 아이디어나 구체적인 계획, 그리고 예비 결과물을 상사에게 승인을 받기 위해 제시합니다.\n\n이렇게 함으로써 관리자들은 보고서를 작성하거나 새 제품을 개발하거나 심지어 새로운 전략을 수립하는 등의 작업의 일부 단계에서만 개입함으로써 시간을 절약할 수 있습니다. 그러나 모든 것을 예상하거나 모든 세부 사항을 미리 해결하는 것은 불가능하기 때문에, 그들은 수시로 감시하고 반복적으로 참여합니다. 업무 중에 외부 상황이 변경될 수 있고, 직원이 마감일을 놓칠 수 있어 다시 계획을 세워야 할 수도 있습니다.\n\n마찬가지로, 당신은 자신을 \"AI 봇 관리자\"로 생각할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- AI에게 안내문을 작성하도록 요청하고, 그것을 비평하고 실행을 요청하십시오.\n- 대부분의 실제 과제에서는 하나의 안내만으로는 부족합니다. 과제는 상호 관련된 여러 하위 과제로 분해되어야 합니다. 따라서 AI에게 이 분해를 수행하도록 요청하십시오.\n- AI에게 귀하의 역할을 명확히 정의하십시오: 귀하는 매니저이고, AI는 특정 역량을 갖는 직원입니다. 목표가 텍스트를 작성하는 것인 경우, 중간 결과물을 승인받기 위해 각 중간 결과물을 보내도록 AI에게 요청하십시오: 아이디어 목록, 구현 계획, 텍스트의 첫 부분(목표가 텍스트 작성인 경우), 그리고 모든 다른 산출물을 모두 포함하여.\n- 무엇보다, AI에게 귀하의 새로운 부하로서 귀하의 선호 및 기대를 아직 잘 모르는 사람인 것처럼 작은, 구체적인 지시를 제공하십시오. 예를 들어, 수정한 텍스트의 첫 부분이 있는 경우, AI에게 그 첫 부분을 스타일 및 용어 측면에서 모델로하여 두 번째 부분(전체 텍스트 한꺼번에가 아닌)을 작성하도록 지시하십시오.\n\n이 접근 방식이 과제를 처음부터 상세히 설명한 후 최종 결과물을 비평하는 것보다 빠른 것을 의미합니다. 매니저가 이렇게 운영한다면, 자신의 시간을 많이 낭비할 뿐만 아니라 매우 중요한 고객 요구사항이나 품질 요구사항을 충족하지 못하는 결과물에 대한 불필요한 작업을 하는 직원에게 많은 비용을 쓰게 될 것입니다.\n\n## AI가 동료 저자인 경우: 공동 창작 프로세스 탐색\n\n대규모 텍스트(연례 보고서 또는 블로그 글과 같은)를 작성하려고 할 때를 상상해보십시오. 인터넷에는 이를 위한 많은 예시 안내문이 있습니다. 그 안에는 목표, 템플릿, 지침, 텍스트의 스타일 등과 같은 수십 개의 문장과 섹션이 포함됩니다. 또는 과제에 대해 모범 사례로 여기는 유사한 텍스트의 예를 AI에게 제공해볼 수도 있습니다. 이를 통칭해서 소수의 샷 프롬프트라고 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일반적으로 두 가지 접근 방식 모두 효과적이며, 특히 이와 같은 텍스트 작성이 당신에게 일상적인 작업이라면 더욱 그렇습니다. 이 경우에는 이미 필요한 텍스트 템플릿과 스타일에 익숙하고 피해야 할 잠재적인 함정도 인지하고 계실 것입니다.\n\n이 경우 대안은 더욱 나쁠 수 있습니다. AI를 주요 저자로 보고 자신을 그저 고객이나 비평가, 편집자로만 여기는 것은:\n\n- 여러 차례의 반복 작업 이후에도 결과물에 만족감을 느끼지 못하게 만들 수 있으며,\n- 단순히 기술적인 수정만 처리하고 AI가 작품의 창의적인 측면을 모두 다루는 일상적인 작업만을 남게 할 수 있습니다.\n\n이를 어떻게 실행하시나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저, '매니저-부하직원' 모델에 대해 앞서 언급한 기술을 활용해보세요(위의 2~4번을 참조하세요). 이는 AI의 도움을 받아 작업을 하위 작업으로 분해하고 중간 결과물을 확인하며, 수정된 버전을 새로운 섹션의 템플릿으로 활용하는 것을 포함합니다.\n\n둘째, AI와의 소통을 더 대칭적으로 만들어보세요. \"문제/아이디어/해결책을 논의해봅시다\"와 같은 구문을 사용하거나 \"함께 이 문제를 해결해봅시다. '완료'라고 할 때까지 번갈아가며 변경 제안을 하겠습니다.\"와 같은 표현을 사용해보세요.\n\n![이미지](/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_2.png)\n\n예를 들어, 하위 작업 생성 단계를 살펴보겠습니다. AI로부터 첫 번째 하위 작업 목록 버전을 받았을 때, 명확화가 필요한 항목을 다시 쓰세요(모호한 항목이 가장 흔한 문제입니다). 그런 다음 수정된 목록을 AI에 제공하여 삭제할 항목을 지정하고, 이러한 조정 사항을 고려한 새로운 목록 버전을 요청하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 4. 협업 작업의 결과로서의 품질 기준 및 평가\n\n이전에, '품질' 결과를 달성하는 목표에 대해 이야기했었고, 이제는 이 맥락에서 '품질'이란 무엇을 의미하는지 명확히 정의하는 것이 중요합니다. 제 제안은 AI와의 대화에서 명확한 품질 기준을 정의하는 것입니다.\n\n처음부터 기준을 도입함으로써, AI가 최초 초안에서 이러한 기준을 준수했는지 확인할 수 있습니다. 그러나 우리가 미리 기준을 이해하기는 종종 어렵습니다. 그래서 첫 번째 개정 후에 기준을 정의하는 것에 문제가 없습니다.\n\n기준을 명시한 후에도 결과물이 여전히 기준에 미치지 못하는 경우, 최신 개정에서 미충족 기준을 가리켜 챗봇을 신속히 안내할 수 있습니다. 예를 들어 기준 목록에 각 문장에 대한 설명 (항목 2) 및 원하는 비즈니스 스타일의 준수 (항목 4)를 포함하는 경우를 생각해보겠습니다. 그럼 “기준 2 및 4에 따라 텍스트를 개선하세요.”라고 요청할 수 있습니다. AI는 이해하여 필요한 대로 정확히 향상시킬 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n새로운 개발자문서를 Markdown 형식으로 변환할 때 table 태그를 변경할 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마침내, 다음 질문이 제기될 수 있습니다: \"실제로 우리가 품질 기준을 어디서 얻을까요?\" 항상 자세히 설명해야 할까요? 세 번째 능력은 AI가 기준을 수립하는 데 뛰어나다는 것입니다. 물론, AI는 일반적인 고려 사항에서 많은 관련 없는 점을 생성할 수 있지만, 당신이 중요한 점만 쉽게 선택할 수 있습니다. 게다가, AI에게 \"만약 ...이면 점수를 더하라\"와 \"만약 ...이면 패널티를 부여하라\"와 같은 예제를 제공하여 이러한 기준을 구체화하도록 요청할 수도 있습니다.\n\n# 결론\n\n생성형 AI 챗봇의 응용은 명확히 정의된 작업을 수행하는 피해자로만 보는 것이 아니라 여러 다른 역할로 크게 확장될 수 있습니다:\n\n- 질문 자체가 중요한 경우 코치, 친구, 멘토 또는 선생님으로서.\n- 과제를 명확하게 표현하는 데 도움을 주는 대화 상대로서 - 과제에 대해 아직 명확하지 않은 경우, 주제에 대한 지식이 제한적인 경우 또는 \"빈 페이지 문제\"로 인해 일을 미루고 있는 경우.\n- 계획, 아이디어 및 중간 결과물을 승인 요청하는 부하자로서.\n- 동등한 입장에서 일하고 수정된 부분을 다음 부분의 템플릿으로 사용하여 소수의 반복을 통해 품질 결과물을 달성하는 공저자로서.\n- 당신이 품질 기준을 정의하고 결과물을 이러한 기준에 따라 평가하는 데 도움이 되는 평가자로서.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 여러분이 태도를 변경하고 AI와의 상호작용을 다시 생각하며, 덜 명백한 역할과 패턴을 받아들이는 것에 준비가 되어 있다면, 여러 혜택을 누릴 수 있습니다:\n\n- AI가 여러분의 사고를 지원하기 때문에 목표를 달성할 수 있습니다.\n- 가장 매력적인 창의적인 작업을 여러분으로부터 빼앗지 않습니다.\n- 품질 좋은 결과물을 얻는 데 필요한 노력을 줄일 수 있습니다.\n- 필요한 품질 수준에 도달하지 못할 위험을 줄일 수 있습니다.\n\nAI를 실행자로서만 보는 한계를 뛰어넘어 보다 많은 방법으로 생성적 AI를 활용할 수 있습니다. 연구 논문들(예: [6])은 인간-AI 상호작용 패턴을 포함한 여러 프레임워크와 분류법을 제공합니다. 저는 이러한 패턴들의 실제 적용이 분류법에 의존하는 것보다 AI의 역할을 고려함으로써 더 쉽게 이해될 수 있다고 생각합니다.\n\n# 참고문헌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[1] ChatGPT으로 유도 엔지니어링을 향상시키기 위한 유도 패턴 카탈로그, Jules White 등, 2023년 2월 21일.\n\n[2] 뒤바뀐 상호작용 패턴: 대화형 AI의 능력 발휘하기, Hugo Blanc, 2023년 4월 10일.\n\n[3] 생성 모델 AI 및 '빈 페이지' 문제 해결, Bryan Scanlon, 2023년 7월 20일.\n\n[4] 대형 언어 모델은 관련 없는 맥락에 쉽게 산만해진다, Freda Shi 등, 2023년 6월 6일.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n[5] Rule-Based vs. Model-Graded Evaluations in Gen AI, Rishi Yadav, Jan 26, 2024.\n\n[6] 인간-인공지능 상호작용의 해석: 상호작용 기본요소부터 디자인 공간까지, Kostas Tsiakas, Dave Murray-Rust, Jan 10, 2024.\n","ogImage":{"url":"/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_0.png"},"coverImage":"/assets/img/2024-05-18-4Human-AIInteractionPatternsforExperiencedChatGPTUsers_0.png","tag":["Tech"],"readingTime":17},{"title":"GPT-4, 아직 실망스러워","description":"","date":"2024-05-18 19:53","slug":"2024-05-18-GPT-4ostilldisappointing","content":"\n응, 정말 잘 보여주지만 $20을 내고 시도해봤는데 20분 후에 취소했어요. 클로드 오퍼스를 계속 사용할 거에요. 왜냐하면요?\n\n처음에는 희망이 있어 보였어요. 클로드와 비교했을 때 정말 빨랐어요. 저는 제 자서전(40k 토큰)을 첨부할 수 있었고 문제없이 처리됐어요. 그 때부터 문제가 시작되었어요. 8k의 컨텍스트 창이 있었죠. 그러나 이것은 기억력이 있었고 이 기억은 채팅 세션 간에 지속됐어요. 문서에 관한 질문을 하고 응답은 괜찮았고 일부를 기억에 남긴다고 언급했어요.\n\n이제, 이게 멋진 것 같아요. 제가 쓴 문서와 제가 한 질문/명확화 등을 기억하는 무한 주의 유형 메커니즘이라고 상상하고 있어요. 이것을 기억에서 어떻게 제거하는지 물었더니 영원히 저장한다고 답했어요.\n\n새로운 채팅을 만들어서 문서에 관한 질문을 했는데, 아무것도 몰랐어요. 그러다가 기억을 살펴보니 그냥 표시된 문장들의 모음이었어요. 그 순간 실망이 시작됐어요. \"그게 다야?\" 하고 스스로 말했죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 1M 컨텍스트 토큰 길이와 무한-어텐션을 가진 이 모델을 원합니다. 스냅샷에서 지속되어야 합니다. 저는 자전적을 업로드한 후에 프로젝트 및 사용 중인 메뉴얼 등을 모두 업로드할 수 있기를 원합니다. 그리고 질문할 때 이를 모두 활용하고 싶습니다.\n\n하지만 이것이 아닌 것 같아요. 저는 Claude Opus로 이 작업을 할 수 있습니다. 제가 채팅 세션에 두 가지를 업로드했고 완벽하게 작동합니다.\n\n저는 지금 당분간 20달러를 Claude에 낼 생각입니다.\n","ogImage":{"url":"/assets/img/2024-05-18-GPT-4ostilldisappointing_0.png"},"coverImage":"/assets/img/2024-05-18-GPT-4ostilldisappointing_0.png","tag":["Tech"],"readingTime":2},{"title":"환각, 오류 및 꿈","description":"","date":"2024-05-18 19:47","slug":"2024-05-18-HallucinationsErrorsandDreams","content":"\n## 현대 AI 시스템이 잘못된 결과를 생성하는 이유에 대해 그리고 그에 대해 무엇을 할 수 있는지\n\n현대 AI 시스템은 경고받았듯이 환각에 취약합니다.\n\n![image](/assets/img/2024-05-18-HallucinationsErrorsandDreams_0.png)\n\n우리는 이를 알고 있지만, 생각해보면 좀 이상하죠. 우리는 컴퓨터가 뭔가를 낸 적이 없던 충실한 50년 이상을 보냈는데, 그들의 세련되고 정확성은 시간이 흘러도 계속 향상되었습니다. 하지만 2024년에, 당신이 입력한 수학 문제에 대한 정확한 답을 줄 수 있는 주머니 계산기를 믿을 수 있더라도, 세계에서 가장 정교한 AI에 그 같은 문제를 맡기는 것에 대해 의심해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_1.png\" /\u003e\n\n어째서 그러죠?\n\n저는 이것이 매우 중요하고 다면적인 질문이라고 생각하며, 이 글에서는 이에 대해 자세히 조사하고 싶습니다. 문제의 한 측면은 최근 30년 동안 \"AI\"가 정확히 무엇을 의미하는지에 대한 주요 변화를 포함하고 있습니다. 오랜 시간 동안 컴퓨터 프로그래밍을 할 때 우리가 하는 대부분은 문제를 정확히 해결하는 방법을 찾는 것이었습니다. 손계산기는 이러한 방법을 사용하여 수학 문제에 대한 증명 가능한 해결책을 제공합니다. 과거에는 이런 정밀한 방법들을 자동으로 적용하는 것을 인공 지능의 한 형태로 생각했습니다. 그러나 현재, 대부분의 \"AI\"로 설명되는 것은 머신 러닝의 응용을 가리킵니다. 머신 러닝은 추론적 논리를 적용하여 솔루션을 만들어 내는 것이 아니라, 예측을 만들기 위해 프로그램이 설계되는 컴퓨터 프로그래밍의 패러다임입니다. 이러한 예측이 가끔 틀릴 것으로 예상됩니다. 글의 첫 번째 큰 섹션에서는, 이것이 무엇을 의미하는지에 대한 개요를 제시할 것이며, 더 고전적인 컴퓨터 프로그램과 머신 러닝 사이의 기본 차이를 살펴보며, 우리가 이러한 시스템이 보다 과거의 컴퓨터 프로그램이 하지 않은 곳에서 에러를 생산할 것으로 예상하는 이유를 살펴볼 것입니다.\n\n그러므로 환각에 대한 질문에 대한 하나의 답은 간단합니다. 생성적 AI는 머신 러닝이며, 머신 러닝은 에러를 생성한다는 것을 알고 있으며, 환각은 에러입니다. 이 관점은 환각 문제가 어떻게 발전해 나갈지에 대해 몇 가지 것을 시사합니다. 역사적으로 더 많은 데이터를 수집하고 더 큰 모델을 구축할수록 머신 러닝 모델이 더 적은 에러를 만들어냄을 우리는 보았습니다. 우리는 이와 마찬가지로 챗봇 및 다른 생성적 AI 시스템이 시간이 지남에 따라 보다 정확해질 것으로 기대할 수 있습니다. 그러나 저는 이 관점이 실제적으로 정확하지 않다고 생각합니다. 환각은, 제 입장에 따르면, 고전적 머신러닝에서의 에러와는 별도입니다. 모든 생성적 AI 출력이 환각이라고 이견을 품고 있습니다. 두 번째 섹션에서 이 모든 것을 정확히 설명하겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 경우에도 환각을 어떻게 정의하든 그 성격에 대해 무엇을 믿든, 모두가 좋고 유용한 생성적 AI 출력물과 나쁘고 유용하지 않은 다른 출력물이 있다는 데에 동의합니다. 얼마나 많은 양이 있는지 양적으로 파악하고 싶은 것은 자연스러운 욕망이에요. 사실, 이를 양적으로 파악하는 것이 이러한 것들을 어떤 식으로든 유용하게 활용하기 위해 필수적이라고 생각해요. 그러나 이런 종류의 것을 측정하는 것이 매우 어렵다는 것을 계속해서 많은 사람들이 깨닫게 되고 있다는 사실이 밝혀졌어요. 세 번째 주요 섹션에서는 이러한 종류의 측정이 왜 중요한지, 또한 왜 그것이 얼마나 어려운지에 대해 설명해 보겠어요.\n\n## 1. 머신 러닝 개론\n\n이러한 생성적인 것들 이전에, 대부분의 AI는 매우 특정한 결과 클래스에 대한 매우 구체적인 추측을 하는 문제에 중점을 두었습니다. 이 사용자는 이 링크를 클릭할까요? 이 그림에는 어떤 객체가 나타납니까? 이 주식은 내일 얼마만큼 가치가 있을까요? 이러한 각 질문에 대한 대답은 해당 질문에 대한 유일한 대답을 하도록 만들어진 이산형 컴퓨터 프로그램에 의해 결정됩니다.\n\n이 문제 중 하나를 해결하기 위해 컴퓨터 프로그램을 어떻게 만들까요? 매우 옛날에는 처음 원리에서 추론하려는 방법이었어요. 사과가 나무에서 떨어진 후 땅에 떨어지는 데 얼마나 걸리는지 예측하기 위해, 뉴턴은 우주의 성질에 대해 많이 생각하여 이 질문에 답할 방정식을 도출하는 이론을 만들었어요. 이 방법은 뉴턴에게는 성공적이었지만, 대부분의 실제 문제에서는 이처럼 처음 원리에서 해답을 도출하기가 매우 어렵습니다. 우리는 금융 파생상품의 진정한 가치를 추정하기 위한 Black-Scholes 방정식과 같은 것들을 개발한 많은 사람들이 노력해 왔지만, 이미지에 나타난 물체를 추측하는 것과 같은 모던 세계에서 중요한 많은 문제들에 대해, 이러한 방식으로 시작하지 않아도 되는 문제들이 많습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n머신 러닝에 오신 것을 환영합니다. 머신 러닝의 기본 아이디어는 예측하려고 하는 프로세스의 충분한 예제를 살펴보면, 해당 예측을 돕는 패턴을 찾을 수 있어 프로세스를 이해하지 않아도 정확한 예측을 할 수 있다는 것입니다. 백만 그루의 나무에서 떨어지는 백만 개의 사과를 살펴보면, 페이지 원리를 건너뛰고 곧바로 수식으로 넘어갈 수 있습니다.\n\n아니면, 적어도 방정식으로 넘어갈 수 있어요. 이 과정의 성격 상, 발견하는 방정식은 뉴턴의 방정식과 일치한다기보다는 매우 낮은 확률입니다. 입력된 데이터를 가능한 한 정확하게 근사하는 방정식을 만들어 낼 것이지만, 특정 데이터 세트를 근사할 수 있는 무한히 많은 방정식 중에서 뉴턴의 정확한 방정식에 도달할 확률은 낮을 것입니다. 그러나 괜찮아요. 중요한 건 그것을 필요로 하지 않다는 점이에요. 중력을 이해하려고 하는 게 아니라 사과에 관한 예측을 하고자 하는 거니까요. 이런 방식이 물리학 같은 것에 적합하지 않아 보일지 모르겠지만, 이미지에서 물체를 인식하는 문제와 같이 명백한 초제원이 없는 경우에는 꽤 편리합니다.\n\n이런 시스템을 구축하는 기본 과정을 감독 학습(Supervised Learning)이라고 하며, 대부분의 세부사항을 추상화하여 전반적인 개요를 제공하면 상당히 간단합니다. 이미지 내에 어떤 손으로 쓴 숫자가 있는지 추측하는 시스템을 만들기 위해, 숫자 이미지의 큰 데이터 세트를 수집하고 각 이미지를 그림으로 라벨을 표시합니다. 이것이 훈련 데이터입니다. 그런 다음 데이터의 모든 이미지를 컴퓨터에게 보여주고 각 사진에 어떤 숫자가 있는지 추측하게 하고, 얼마나 자주 맞았는지에 따라 점수를 매깁니다. 이를 수백만 번 반복하여 컴퓨터가 각 시도마다 서로 다른 추측 전략을 시도하면서 가장 높은 점수를 내는 전략을 찾도록 합니다. 가장 높은 점수를 내는 추측 전략을 찾는 이 과정은 매우 길고 연산량이 많을 수 있지만, 최근에는 높은 점수를 찾는 수학과 연산능력의 혁신으로 이 기본 전략이 광범위한 작업에서 매우 성공적으로 이루어지고 있습니다.\n\n좀 더 용어를 소개하자면, 최고의 추측 전략을 찾는 과정을 \"훈련\"이라고 하며, 그 결과로 나오는 시스템은 종종 \"모델\"이라고 합니다. 이산 레이블 세트에서 추측하는 모델은 \"분류기\"이며, 머신 러닝 전문가들은 이 추측을 \"예측\"이라고 부릅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일시적으로 기계 학습 접근 방식이 뉴턴의 방식과 얼마나 다른지 생각해 볼 가치가 있습니다. 뉴턴은 영강에서 몇 개의 사과가 떨어지는 것을 영감으로 삼지만, 그의 프로젝트는 천체의 운동의 일반적인 원리를 인코딩하는 이론을 개발하는 것입니다. 그 이론으로부터 방정식이 나옵니다. 그 방정식은 나무에서 사과가 떨어지는 데 걸리는 시간을 알려줍니다. 기계 학습자에게 있어서 천체 간의 관계를 규정하는 일반 원리는 거의 관련이 없습니다. 기계 학습자의 유일한 초점은 백만 개의 사과낙하 시간 데이터 세트를 정확하게 재현하는 것입니다.\n\n각 접근 방식에는 장단점이 있습니다. 기계 학습 접근 방식은 물리적 법칙에 대해 매우 적은 정보를 제공하는 알아보기 어려운 방정식을 생성할 것으로 예상됩니다. 그러나 반대로, 뉴턴의 접근 방식을 복잡하게 하는 공기 저항과 같은 실제 세계의 복잡성을 더 잘 수용할 수도 있습니다.\n\n기계 학습을 뉴턴의 방식과 비교하는 것은 단지 지도 학습이 인공 지능 시스템을 구축하는 유일한 방법이 아님을 강조하기 위함입니다. 컴퓨터를 프로그래밍하는 다양한 방법이 있으며, 사전에 특정 응용 프로그램을 위해 각각의 방법이 명백하게 더 나은 것은 아닙니다. 하지만 최근 15년 정도 동안 지도 학습이 사람들이 기대하지 못한 복잡한 작업에 효과적일 수 있다는 점이 점차 드러나기 시작했습니다. 여기서의 복잡성은 모델의 가능한 입력과 출력의 다양성을 말합니다.\n\n전형적인 기계 학습 입문 자습서는 256x256 픽셀 길이의 손으로 쓴 숫자 이미지를 입력으로 받아 총 열 가지 레이블 중 하나를 출력으로 생성하는 시스템을 구축하는 방법을 보여줄 수 있습니다. 사람이 레이블이 붙은 수천 장의 이미지 대신 수백만 개 또는 수십억 개의 이미지를 사용할 수 있다면, 가능한 입력과 출력의 범위를 크게 확장할 수 있습니다. Image 확산 모델인 Stable Diffusion과 같은 모델은 다양한 크기의 이미지에서 훈련되며, 소수의 이산적인 레이블 대신 전체 이미지를 출력합니다.\n\n더 복잡한 모델을 구축하려면 엄청난 양의 데이터가 필요하며, 충분히 큰 데이터셋을 확보하는 것은 곧 엄청난 비용이 들게 됩니다. 높은 복잡성 작업에 가장 유망한 모델은 수십억 개 이상의 레이블이 달린 예제를 필요로하며, 수십억 장의 이미지를 수작업으로 확인하고 그 객체가 무엇인지 적는 방법은 없습니다.\n\n모든 예제를 수동으로 살펴보지 않고도 레이블을 생성할 수 있다면 성공할 수 있습니다. 이것이 현대 생성적 인공지능 시스템 뒤에 있는 기계 학습 패러다임인 자기 지도 학습의 큰 아이디어입니다. 인터넷에서 모든 텍스트를 스크랩하는 등의 방법으로 수십억 개의 문장을 확보한다면, 문장을 조각내어 훈련 데이터세트를 프로그래밍적으로 구성할 수 있습니다. 한 문장을 \"The quick brown fox jumps over the lazy dog\"라는 훈련 예제로 변환하고 레이블을 \"dog\"로 지정할 수 있습니다. 사실, 한 문장에서도 다양한 장소에서 자르면서 많은 훈련 예제를 만들 수 있습니다. 한 문장만으로도 인간의 레이블링 없이 여덟 개의 훈련 예제를 얻게 됩니다. 인터넷에서 수집할 수 있는 문장 수에 곱하면 이러한 복잡한 모델을 훈련하는 데 필요한 크기에 다가설 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기 중요한 관찰 하나가 있는데요. 크기나 복잡성에서 큰 차이가 있긴 하지만, GPT를 학습하는 과정과 전통적인 분류기를 학습하는 과정 사이에 큰 차이가 없다는 겁니다. LLM(Large Language Model)은 더 많은 가능한 입력과 출력을 다루지만, 기본적으로 똑같은 방식으로 학습되어 같은 목표를 이루기 위해 노력합니다: 주어진 입력에 대해 올바른 레이블을 추측하는 것.\n\n![image](/assets/img/2024-05-18-HallucinationsErrorsandDreams_2.png)\n\n두 모델 모두 불완전한 예제들을 보여주고, 그 완성을 추측하게 한 후 그 추측을 점수로 매기는 방식으로 구축됩니다. 현대적인 생성형 인공지능 시스템을 훈련시키는 큰 혁신은 자동으로 대규모 훈련 데이터 세트를 구축하는 똑똑한 방법을 찾아내는 데 있고, 복잡한 작업을 수행하기에 적합한 새로운 종류의 블랙 박스를 발명한 것입니다. 하지만, 그들이 훈련되는 방식에 대한 전반적인 개요는 수십 년간 그대로입니다.\n\n이야기는 여기서 끝날 수도 있습니다. 가끔은 숫자 인식기가 7을 9로 오해할 수도 있고, 언어 모델이 빠른 갈색 여우가 게으른 갈색 덜드럼을 뛰어넘는다고 말할 수도 있습니다. 이는 기계 학습의 본질적인 일부로, 기계 학습 모델이 확실한 추론이 아닌 패턴을 기반으로 예측을 하기 때문에 발생하는 결과이며, 더 많은 데이터와 더 큰 모델로 시간이 지남에 따라 개선되는 경향이 있는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 이건 맞지 않다고 생각해요.\n\n## 2. 환각과 오류의 차이\n\n가끔 모델에 숫자 7의 사진을 보여주면 9의 사진이라고 말합니다. 이겢 일은 영원히 이어져왔어요. 이런 일이 불가피하게 발생할 때, 왜 숫자 인식기가 \"환각\"을 입은 것이라고 말하지 않을까요? 왜 부정확한 정보는 챗봇에서 나올 때만 환각인 것으로 간주할까요?\n\n바로 전에 언급했듯이, LLM과 고전적 분류기는 개념적으로 구성 방식이 매우 유사해요. LLM은 분류기이지만, 매우 복잡한 분류기에 불과해요. 디지트 인식기가 기존 이미지의 누락된 라벨을 채우도록 훈련되는 것과 마찬가지로, LLM은 기존 문장의 누락된 단어를 채우도록 훈련돼요. 여기서 주된 차이점은 복잡성과 규모에 있어요. 그러나 두 모델의 구성 방식은 유사해도, 생성적 AI 시스템이 배포되는 방식에서 큰 차이가 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n전통적으로 우리는 분류기를 배포하여 훈련된 대로 동일한 작업을 수행합니다. 손으로 쓰인 숫자를 인식하는 디지턀 인식기를 배포하면, 수표를 입금하는 것과 같이 수집된 손글씨 숫자를 읽기 위해 모델을 사용할 것입니다.\n\n생성적 AI 시스템은 다릅니다. 우리가 LLM을 챗봇으로 배포할 때, 이것은 기존 문장에서 다음 단어를 추측하는 것에서 실제로는 존재하지 않는 새로운 문자열에서 다음 단어를 \"추측\"하는 것으로 바뀝니다. 이것은 매우 중요한 전환인데, 일반적으로 과소평가됩니다. 이것은 전통적인 분류기와 달리 LLM 출력의 정확성을 전통적인 방식으로 평가하는 방법이 단순히 없다는 것을 의미합니다. 왜냐하면 비교할 수 있는 올바른 레이블이 없기 때문입니다. 이 점은 다소 세부적이며, 이를 엿내는 데 상세한 설명이 도움이 될 것으로 생각합니다.\n\n숫자 7 이미지를 숫자 인식기에 입력하면, 출력되기를 희망하는 단일 명확한 올바른 레이블이 있습니다: \"7\". 레이블이 \"1\" 또는 \"9\"로 출력되면 명백히 잘못된 것이며 모델의 정확도에 영향을 미칩니다. 이러한 오류는 훈련 중에 발생하는 오류와 동질적이며, 따라서 새 데이터에 대한 오류율 (소위 \"일반화 오류\" 또는 \"샘플 외 오류\")에 대해 훈련 데이터의 오류율에 대해 논하는 방식과 완전히 동일하게 논할 수 있습니다.\n\nChatGPT에 \"2 + 2는 무엇입니까?\"라는 문자열을 입력하면, 다음에 올 바른 단어가 단일 명확한 존재하지 않습니다. 다음 단어는 \"4\" 같은 것이어야 합니다. 하지만 \"2\"도 \"2 + 2 = 4\"처럼 좋을 수 있습니다. \"The\"도 \"2와 2의 합은 4이다.\"와 같이 좋은 다음 단어가 될 수 있습니다. 물론, 이러한 것들은 모두 나쁜 응답의 처음 단어가 될 수도 있습니다. 모델이 해야 할 작업은 기존 텍스트에서 금지된 단어를 채우는 것이라는 점—이 작업은 명확한 정답이 있는 작업이지만 이제 상황은 완전히 다릅니다. 더 나은 다음 단어와 더 나쁜 다음 단어가 있지만, 훈련할 때와 마찬가지로 옳은 다음 단어는 없습니다. 왜냐하면 재구성할 예시가 없기 때문입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n언어 모델의 고전적인 의미에서의 오류는 훈련 예제에서 삭제된 단어를 재현하지 못하는 것입니다. 하지만 실제 운용에서 이러한 모델은 그런 역할에 사용되지 않습니다. 이는 마치 우리가 숫자 인식기에 동물 이미지를 삽입하는 것과 비슷합니다. 만약 숫자 인식기가 사자를 6으로 부른다면, 그것은 오류를 범한 것일까요? 아니라고 생각합니다. 그것을 사용하는 목적이 훈련된 목적과 다르기 때문에 정답이 없기 때문에 오류가 정의되지 않습니다.\n\n실제 상황에서 우리는 보통 이러한 개별 단어 예측에 크게 신경 쓰지 않습니다. ChatGPT 작동을 가능케 하는 엔진인 LLM은 한 번에 한 단어를 추측할 뿐인데, ChatGPT 시스템은 그 예측을 LLM으로 되돌려보내 전체 단어 시퀀스를 생성하는 구성 요소를 포함합니다. 우리가 일반적으로 관심을 갖는 것은 전체 텍스트 응답으로 나타나는 의미적 콘텐츠이며, 어떤 단어 하나가 아닙니다.\n\n이것이 손글씨 숫자 분류기가 7을 9로 부르면 \"오류\"인 이유 중 하나일지도 모릅니다. 그러나 GPT-4가 1981년 캐미라는 코끼리가 세계 자연 보호 기금을 위해 영국 해협을 헤엄쳤다고 말할 때 \"환각\"이라고 부르는 이유일지도 모릅니다.\n\n![Hallucinations, Errors, and Dreams](/assets/img/2024-05-18-HallucinationsErrorsandDreams_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n당연히 1981년에 카미라는 코끼리가 영국 해협을 헤엄쳤다고 주장하고 있는 것은 사실이 아닙니다. 그러나 여기서 ChatGPT가 틀린 방식은 7을 9로 잘못 인식하는 이미지 분류기가 틀리는 방식과 매우 다릅니다. ChatGPT는 여기서 110가지 다른 예측을 했고, 각각을 옳거나 틀린 것 중 어느 것으로 분류해야 할지 명확하지 않습니다. 각 예측된 단어는 앞선 단어들과 일관성이 있고, 이것은 교육 데이터에서 찾을 수 있는 단어 순서와 매우 유사합니다.\n\n![hallucinationsErrorsandDreams_4.png](/assets/img/2024-05-18-HallucinationsErrorsandDreams_4.png)\n\n여기서 예측된 단어 중 일부, 심지어 대부분은 아마도 올바른 것에 더 가깝다고 생각해요. 물론 여기서 절대적으로 정의할 수 있는 보다 나은 단어가 무엇인지는 없습니다(그것이 여기 정리한 전체 주제입니다), 하지만 \"생물의 역사에서 독특한 사건으로 남아있는 사실은 무엇인가요?\"라는 문장 뒤에 나올 더 좋은 단어를 생각할 수 있나요? 모델이 한 예측 중 어떤 것을 오류로 지칭해야 하는 지 명확하지 않습니다. 하지만 전체적으로, 이 출력물은 우리가 원하는 결과가 아닌 것은 분명합니다.\n\n하지만 왜 우리가 원하는 결과가 아니라고 할까요? 정확히 무엇이 문제일까요? 분명히, 주된 문제는 실제로 발생하지 않은 사건을 묘사하고 있는 듯한 점입니다. 하지만 이것을 정말로 생각해 보면 조금 의문스럽게 느껴집니다. 만약 1981년에 아시아 코끼리 중 한 마리인 카미가 정확하게 이 텍스트에 설명된 대로 영국 해협을 헤엄 쳤다면 어떨까요? 그렇다면 이 동일한 입력과 출력 쌍은 환각적이지 않았을 것입니다. 이것은 입력-출력 쌍의 텍스트에는 환각적인 요소가 아니라는 것을 시사합니다. 환각적 여부는 완전히 모델에 의해 생성된 텍스트와 독립적으로 존재하는 세계적 사실에 종속적이다는 것을 나타냅니다. 그렇다면 텍스트 자체에는 환각적인 특성이 없는 것인가요? 완전히 그렇지 않아 보입니다. 이는 텍스트가 실제 세계의 객체와 사건과 어떻게 관련되는지에 대한 특성입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일본어에서 한국어 번역 서비스를 사용하려면 URL에 다음과 같은 형식을 지정하십시오:\n\n![HallucinationsErrorsandDreams_5.png](https://yourwebsite.com/assets/img/2024-05-18-HallucinationsErrorsandDreams_5.png)\n\n![HallucinationsErrorsandDreams_6.png](https://yourwebsite.com/assets/img/2024-05-18-HallucinationsErrorsandDreams_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 기준을 찾아 분류할 수 없는 것은 아니다. 하지만 당신이 희망하는 것만큼 간단하지는 않다는 점을 감안해주셔야 합니다.\n\n다시 한번 ChatGPT의 작동 기본을 간단히 요약해 드리겠습니다. 먼저 텍스트 블록에서 빠진 단어를 채우는 과제를 통해 분류기를 훈련시킵니다. 그리고 이제 이전 텍스트가 주어졌을 때 예측된 누락된 단어, 즉 이전 텍스트를 기반으로 한 예상 단어를 생성할 수 있는 모델이 생겼습니다. 초기 텍스트가 주어지면, 예를 들어 \"2 + 2\"라고 하면 이 모델은 이미 존재하는 문서의 시작이며 마지막 단어가 편집되어 있다고 가정하고 편집된 단어가 무엇일지 추측합니다. 아마도 \"equals\"라고 추측할지도 모릅니다. 이제 이를 한 단어 이상을 생성할 수 있는 시스템으로 바꾸려면 이를 프롬프트 끝에 붙이고 모델에게 다시 입력합니다. 모델은 이전 활동들과는 무관하게 새롭게 다시 실행되어, \"2 + 2 equals\"의 끝에서 편집된 단어가 무엇인지 추측하라고 요청됩니다. 이 과정이 모델이 더 이상 다음 단어가 없다고 예측할 때까지 반복됩니다. 고수준에서 생성 이미지 모델은 이와 매우 유사하게 작동합니다. 이미지를 왜곡된 버전과 이미지에 대한 평문 설명을 주어진 과제로 학습합니다. 새로운 이미지를 생성하려면 생성하고 싶은 대상의 평문 설명을 입력하고 모델이 왜곡된 이미지를 기대하는 곳에 무작위 노이즈를 입력합니다. 두 경우 모두 모델은 이미 존재하는 작품을 재구성하고 있다고 \"생각\"하지만 사실은 새로운 것을 생성하고 있습니다. 이 설명을 바탕으로 생각해 보면, 생성적 AI 출력물 전부가 \"환각\"인가 의문이 듭니다. 출력물을 생성하도록 하는 방법이 이미 존재하는 출력물이 실제로 이미 있는 것으로 알려주고 해당 출력물을 재구성하도록 하는 것이라면, 그것은 사실상 그들에게 환각을 보도록 하는 요청으로 들립니다.\n\n일부 유명한 AI 연구자들은 최근 모든 LLM(Large Language Models) 출력물이 환각이라는 의견을 공개적으로 받아들였습니다. 게다가 이것이 실제로 좋은 것이라고 주장하는 사람도 있습니다. Andrej Karpathy는 최근 트위터에서 LLMs가 \"꿈을 틀어주는 기계\"이고 \"환각은 버그가 아니라 LLMs의 최고의 기능\"이라고 트윗했습니다. 이것을 \"큰\" 기능이라고 설명하는 것은 조금 과장된 표현이 아니더라도, 그것이 그들의 특징인 것은 의심할 여지가 없습니다.\n\n이것은 실제로 새로운 관점이 아니라 상대적으로 오래된 관점입니다. 구글은 2015년에 DeepDream이라고 불리는 시스템을 공개했었는데, 이것이 현재의 생성적 AI 시스템의 전신이고 Karpathy가 LLMs를 \"꿈을 틀어주는 기계\"라고 부르는 것의 거의 확실한 출처이었을 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_7.png\" /\u003e\n\n이 시스템은 이미지를 분류하는 데 사용한 기술을 다시 구성하여 이전에 존재하지 않았던 이미지를 생성하는 방법으로 사용할 수 있다는 깨달음에서 탄생했습니다. 생성된 이미지들은 실제 세계에 존재하는 것이 아니라 훈련 데이터의 이미지들의 통계적 반향과 같은 것으로, 이를 \"꿈\"이라고 부르기로 했습니다. DeepDream의 창조자들은 이 모델이 \"가끔 환각일 수 있는 이미지들\"을 만들어낸다고 주장하지는 않았습니다. 이 모델에 의해 생성된 모든 정보가 \"꿈\"임이 처음부터 이해되었습니다. 당시에는 이러한 것이 궁리의 영역을 벗어날 수 없는 호기심 정도로 여겨졌고, 최상의 경우에는 분류기의 내부 작동 방식을 더 잘 이해하는 방법으로 여겨졌습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_8.png\" /\u003e\n\n당시에는 이러한 종류의 꿈들이 스스로 유용하다고 예견된 사람들은 매우 드물었지만, 우리는 이후 학습했듯이 충분한 양의 데이터로 복잡한 모델을 훈련시킨다면, 꿈은 실제 세계에 대한 사실과 자주 일치하는 생생한 형태로 변모할 수 있음을 발견했습니다. 그러나 이러한 경우에 그런 일이 일어난다면, 내견에 따르면, 이것은 본질적으로 행운의 일치에 불과합니다. \"모델의 관점\"에서는 환각적인 텍스트와 비환각적인 텍스트 사이에 구분이 없습니다. 그의 출력물은 모두 가식적인 흉내낸 문서들의 재구성입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 다소 철학적이고 추상적으로 느껴질 수 있지만, 일부 이 기술이 어떻게 발전할 것인지에 대한 구체적인 함의가 있다고 믿습니다. 환각이 다른 기계 학습 모델의 일반적인 오류와 유사하다면, 환각이 많이 발생하는 것을 강력하게 제로로 유도할 수 있다는 좋은 경험적 근거가 많이 있다고 믿습니다. 요즘에는 필체된 숫자 인식에서 매우 우수한 기계 학습 모델이 있습니다. 기본적인 단계는 간단합니다: 더 많은 데이터로 모델을 학습하고 모델을 더 크게 만드는 것입니다. 그러나 환각이 고전적인 종류의 오류와 질적으로 다르다고 믿는다면, 이야기는 달라질 수 있습니다. 이 경우에 더 많은 데이터나 더 큰 모델이 환각을 줄이는 방향으로 나아간다는 것이 그렇게 명확하지 않습니다. Also 네 really, the current state of the art approach를 볼 때, 환각에 대해 제대로 다루지 않는다면 말이죠. RLHF is 더 나은 환각을 일으킬 수 있는 완전히 새로운 방법이다. 가능성이 있습니다. 어떤 사람도 알고 있지 않죠! 환각 문제가 품질적으로 새롭다고 보는 관점에서는 기계 학습 모델이 때때로 오류를 생성하는 일반적인 문제의 한 예가 아니라면, 이 축을 따라 점진적이지만 지속적인 개선은 전혀 보장되지 않습니다.\n\n이 관점에서 함의되는 정말 무서운 점은 환각 문제는 간단히 해결할 수 없다는 것입니다. Hallucination과 non-hallucination은 사실 구분된 출력 범주가 아닙니다; 봇에게 그림을 그리거나 글을 써 달라고 할 때마다 그것이 환각을 하도록 요청하는 것이죠. 이들 환각은 어쩔 수 없이 실제 세계에서 떨어질 수밖에 없을 것입니다. 왜냐하면 그저 꿈이라서요. 대다수의 실제 시도를 통해 LLM 기반 시스템을 진리에 기반하여 둘 때, 모델을 개선하기 위한 방법이 아니라 더 신뢰할 수 있는 사실적인 텍스트를 만들어내게 하는 방법인 보트인 LLM 조각에 더 많은 비율을 줄 수 있지만, 문제의 핵심은 그 엔진이 진실과 거짓을 생성하는 것을 구별할 수 없다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전 섹션의 보기에서 환각적인 출력과 그렇지 않은 출력 사이에는 실제로 보편적인 구별이 없습니다. 더욱 바람직한 출력과 그렇지 않은 출력이 있을 수 있지만, 바람직함은 텍스트의 본성이 아닌 독자가 그것을 해석하고 사용하는 방식에 따라 결정되는 속성입니다. 이에 동의할 수도, 동의하지 않을 수도 있습니다. 어찌되었든, 나는 다른 상황에서 모델이 생성하는 다양한 종류의 텍스트의 빈도를 생각하고 양적으로 측정하려는 것이 중요하다고 생각합니다.\n\n이것은 상당히 간단한 아이디어를 제안합니다: 왜 우리는 환각을 구성하는 몇 가지 기준을 임의로 정의하지 않고, 철학적 문제와 상관없이 그런 것이 객관적으로 존재할 수 있는지 여부에 대해 이야기하고 이를 기준으로 모델을 검증하여 \"환각 비율\"을 도출해 낼까요. 이 섹션에서는 그렇게 하는 데 부딪히는 몇 가지 도전에 대해 이야기하겠습니다.\n\n먼저, 일반적으로 오류를 어떻게 생각해야 하는지에 대해 말씀드립니다. 서로 다른 AI 시스템이 어떻게 작동하는지에 대한 구체적 기술 세부사항을 배우는 것은 재미있을 뿐 아니라 흥미롭지만, 실제로 중요한 것은 시스템을 실제 상황에서 실제 배당에 맞추어 자동화하기 위해 배포하는 것을 고려할 때, 실제로 중요한 것은 세 가지만 있습니다: 시스템이 어떤 종류의 오류를 저지르는지, 얼마나 자주 그러한 오류를 저지르는지, 그리고 그 오류가 얼마나 비용이 드는지입니다. 이러한 질문에 대한 답변은 시스템을 제작에 사용할지 여부를 결정하며, 때로는 그렇지 않을 수도 있습니다!\n\n예를 들어 부동산 투자 사업을 기반으로 한 집값이 저평가되었는지 예측하는 모델을 사용해보려고 생각해 봅시다. 모델이 이 집이 가치가 저평가되었다고 예측하면, 그 집을 사들이고 모델이 공정 시장 가치로 예측한 가격에 팔 것입니다. 이런 전략이 실행 가능한 전략인지는 모델이 저지르는 오류의 종류와 빈도에 강하게 의존합니다. \"모델이 실제 판매 가격의 5% 내외에 90%의 경우가 맞다\"는 등의 정보만 알아야 하는 것은 충분하지 않습니다. 더 많은 것을 알아야 합니다. 5% 이상 차이 나는 경우의 10% 내외는 얼마 만큼 차이가 나는지 알아야 합니다. 크게 차이가 나기도 하나요? 100% 또는 1000% 차이가 나는 경우도 있습니다. 이 경우라면 비록 드물더라도 당신을 파산시킬 수도 있습니다. 10% 내외로 차이나지 않는 90%가 그 값이 과소평가되었는지 과대평가되었는지 확인해야 합니다. 모델이 집의 실질적 가치를 과소평가하는 경향이 있다면, 뒤집거나, 너무 일찍 팔 경우 수익 기회를 자주 놓치게 될 수 있습니다. 이것은 짜증스러울 수도 있지만, 그렇게 제대로 하나면 금전을 벌어들이는 방법이 될 수도 있습니다. 그러나 모델이 집의 실제 가치를 과대평가하는 경향이 있다면, 이는 과대평가 된 자산에 너무 비싼 값을 지불하게 되어 파산할 가능성이 높습니다. 요점은 모델이 범하는 오류를 이해하고 계획하는 것이 중요하며, 그것이 얼마나 자주 발생하며 그 모습과 비용이 어떻게 되는지 이해하는 것이 중요하다는 것입니다. 이것은 당신이 의사 결정을 자동화하는 데 사용할 때, 가장 중요한 사항이며, 이것은 세계 최대의 대형 언어 모델에서부터 최악의 단일 변수 선형 회귀까지 모든 모델에 대해 참된 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 생성적 AI에 대해서는 제가 이야기했듯이, 심지어 오류를 정의하거나 설명하는 방법조차 잘 이해되지 않고, 그것을 측정하고 근거로 이야기하는 것도 어렵다. 노력은 있습니다. 이전에 제안한 대로, LLM 시스템을 사용하여 여러 출력을 생성하고, 이것이 옳거나 틀렸는지 판단하기 위해 읽은 후에 \"환각률\"을 계산할 수 있습니다. Vectara라는 회사는 이를 시도하려는 프로그램을 가지고 있으며 현재 \"환각률 리더보드\"를 유지하고 있습니다. 현재 GPT 4 Turbo의 환각률은 2.5%이고, Mistral 7B Instruct-v0.1의 환각률은 9.4%를 보고하고 있습니다.\n\n이러한 숫자가 어떻게 산출되었는지에 대한 강한 방법론적인 우려가 있으며 이에 대해서는 잠시 후에 다시 살펴보겠지만, 이러한 \"환각률\"이 충분한 정보가 아닙니다. 집 구매 예시와 마찬가지로, 틀린 경우의 빈도뿐만 아니라 그 방향도 중요합니다. LLM 봇이 잘못된 내용을 말할 때, 정확히 무엇을 말하는 것인가요? 실제로 맑았던 지난 주말에 비가 왔다고 말하는 건가요? 아니면 고객에게 충분히 실행할 수 없는 과도한 제안을 하고 있는 건가요? 만약 지난 주말 날씨를 잘못 예측하는 비율이 2.5%라면, 이것은 고객을 대하는 채팅 어시스턴트로서 충분할 수도 있지만, 제품 인벤토리를 무료로 나눠주는 것은 2.5%의 빈도보다 덜 하고 싶을 것입니다.\n\n고전적인 기계 학습 맥락에서는 각종 오류와 그 발생률에 대한 한계를 정해 놓을 수 있거나, 적어도 이에 대해 어떤 질적인 설명을 할 수 있습니다. 집 가격 추정이 얼마나 크게 잘못 될 지는 모르지만, 적어도 숫자로 나올 것이며, 추정이 과소 또는 과대평가하는 경향이 있는지 등을 통계 분석을 통해 확인할 수 있습니다. \"7\"이라고 인식하는 디지트 인식기가 무엇인지는 알 수 없지만, 확실히 디지트 하나를 추측할 것입니다. 이러한 새로운 생성적 AI 시스템에서는 출력이 어떤 것이든 될 수 있습니다. 가능한 원치 않는 텍스트 공간이 무한히 커집니다. ChatGPT가 고객에게 가격을 잘못 알려줄 수도 있고, 경쟁사를 추천할 수도 있습니다. 인종 차별적인 용어를 사용할 수도 있고, 음란한 이미지를 생성할 수도 있습니다. 혹은 이와 매우 다른 수많은 방법으로 실수를 할 수 있습니다. 이러한 종류의 나쁜 결과를 좀 더 구체적으로 알지 못한다면, 일반적인 환각률은 LLM이 당신에게 적합한지 여부를 파악할 충분한 정보를 제공하지 않습니다.\n\n방법론적인 도전 과제로 돌아가보고 싶습니다. 저는 적어도 세 가지 어려운 부분을 보고하고 있습니다. 첫 번째로, 그리고 가장 심각한 문제는, \"환각\"이라는 것이 일찍이 무엇인지에 대해 폭넓은 합의가 없다는 것입니다. Vectara 리더보드는 환각의 정의에 대해 정확하게 명확하지 않습니다. 그러나 대략 다음과 같은 것으로 보입니다: 환각은 텍스트를 정확하게 요약하려는 시도 실패라고 할 수 있습니다. 이것은 할 말이 있지만, 모델을 사용하여 텍스트를 요약하지 않는 경우, 모델이 텍스트 요약을 잘못하면 어떤 빈도로 실패하는지 측정하는 것이 당신에게 도움이 되지 않을 수 있습니다. 이는 문제이나, 당신이 보는 환각 벤치마크 방법론을 신중히 이해한다면 큰 문제는 아닙니다. 문서를 읽고, 자신의 환각 정의가 벤치마크의 정의와 일치하는지 결정하고 그에 따라 진행하면 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nThe second and third problems are significantly harder to deal with. The second problem is that it is pretty much infeasible to properly perform these evaluations. To properly evaluate Vectara’s hallucination rate (and I’m sorry to keep picking on Vectara because all of the benchmarks have this identical problem), one would need to carefully read tens of thousands of paragraph-long text summaries and determine whether each one contains any factual errors. It’s just impossible to do this on an ongoing basis. What they do instead is, once they’ve generated all of the text summaries, they use another large language model to determine whether the summaries contain errors. I hope you can see the problem with this.\n\n![Hallucinations, Errors, and Dreams](/assets/img/2024-05-18-HallucinationsErrorsandDreams_9.png)\n\nThe whole point of the exercise is that we observe that LLM-based generators seem to be unreliable at sticking to the truth, and now we using an LLM to determine whether they’ve stuck to the truth. Now, I’ll say this: I don’t actually think the idea of using LLMs to evaluate other LLMs is necessarily a total dead end. But doing this properly is going to take some sophisticated statistical methodology to correct for the errors made by the measurement model, and I have not seen any standard benchmarks address that problem at all. The measurement model itself is going to make errors, and it’s almost certain that these errors will bias any estimation of the actual prevalence of errors. This is not a new statistical problem; the problem of estimating a population prevalence by counting the number of positives produced by an unreliable test is well studied in epidemiology, for example.\n\nSo while I do believe that there are some potential ways forward on the hard problem of describing LLM output using unreliable estimators, I do not see them being incorporated into any of the widely available benchmarks. As it stands I do not believe that they are trustworthy.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째와 두 번째 문제는 별 의미가 없는 편이에요. 왜냐하면 세 번째 문제가 치명적이거든요. 이 문제는 통계 101에서 나온 것이에요. 모델이 환각을 생성하는 평균 속도인 \"환각 발생률\"이라는 목적이 있고, 이를 추정하기 위해 모델의 산출물 샘플에서 환각이 얼마나 자주 발생하는지 확인하는 시도를 하는 것이에요. 그러나 일반적으로 이 전략이 작동하려면 샘플이 전체 인구를 대표해야 해요. 즉, 샘플이 가능한 모든 텍스트에서 임의로 추출한 단락과 비슷하게 보여야 해요. 그리고 이런 기준 데이터 세트들은 말씀드리기에 약간 그런 모습이 아니에요. 대체로 굉장히 인공적인 방법으로 구성되고, 전반적으로 보면 ChatGPT 사용자의 무작위 팁을 샘플링하면 만날 수 있는 일반적인 텍스트와는 사뭇 달라요.\n\n만약 거짓 주장을 하는 경향이 특정 팁의 선택과 밀접하게 관련되지 않았다면 너무 큰 문제가 되지는 않았을 것입니다. 그런데 그는 그렇지 않은 것으로 보입니다. 제가 방금 실행한 비과학적인 테스트에서 ChatGPT (GPT-4 사용)이 \"영어 채널을 건너 수영한 첫 번째 코끼리의 이름은 무엇인가요?\" 라는 프롬프트에 대한 응답에서 거짓으로 분류할만한 출력을 75% (12번 시도 중 9번)에서 92% (12번 시도 중 11번) 정도로 발생하는 것을 발견했고, 완전히 사실적이라고 할 수 있는 출력은 12번 시도 중 1번, 즉 8%정도만 발생하는 것을 발견했어요.\n\n\u003cimg src=\"/assets/img/2024-05-18-HallucinationsErrorsandDreams_10.png\" /\u003e\n\n12는 작은 샘플 크기이지만 12번 시도 중 11번의 환각은 실제로 2.5%의 환각 응답 가능성에 대한 귀무 가설을 기각할 데이터가 충분했답니다. 이곳에서 더 중요한 점은 GPT를 구동하여 세계에 배포하는 경우 마주칠 환각 발생률은 이러한 환각 벤치마크 테스트 중 하나의 성능에 근거해서는 알 수 없다는 것이에요. Vectara 환각 벤치마크에서 2.5%의 환각률을 얻고 Colin Fraser 환각 벤치마크에서 92%의 환각률을 얻지만, 이 둘 중 하나를 사용한 벤치마크들이 사용하는 텍스트와 마찬가지로, 채팅 봇이 처리할 텍스트는 전혀 다를 것이기 때문에 이러한 성과는 별다른 의미가 없을 거라는 것이죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n더 실용적인 시연으로, 나의 즐겨찾는 실제 세계 예시 중 하나인 ChatGPT 기반 봇 중 하나인 퀐크 쉐보레 AI 자동차 어시스턴트를 살펴보겠습니다. 2024년 4월에 진행한 비과학적 테스트에서, 중고 2021 쉐보레 볼트를 찾고 있다고 말했을 때, 4번 시도 중 4번 (100%) \"죄송합니다. 현재 새 차량만 있습니다. 관심 있을만한 새 차량이 있나요?\" 라고 응답하는 것을 확인했습니다. 그들의 웹사이트에는 중고 2021 쉐보레 볼트가 있는 것을 분명히 표시하고 있습니다.\n\n![2024-05-18-HallucinationsErrorsandDreams_11](/assets/img/2024-05-18-HallucinationsErrorsandDreams_11.png)\n\n이러한 종류의 것이 구체적인 프롬프트에 얼마나 예측할 수 없고 민감한지 확인하기 위해, 2021 쉐보레 볼트의 가격을 알려달라고 요청할 때 \"재고 있느냐\"가 아니라, 갑자기 하나를 갖게 됩니다.\n\n![2024-05-18-HallucinationsErrorsandDreams_12](/assets/img/2024-05-18-HallucinationsErrorsandDreams_12.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 챗봇은 GPT 3.5 기술을 기반으로 구축되었어요. 환각율 리더보드에 따르면 3.5%의 환각율이 있어야 하지만, 저는 3.5%보다 훨씬 더 자주 환각을 경험하고 있어요. 그래서 Quirk Chevrolet은 고객에게 거짓말을 하기를 얼마나 자주 기대해야 할까요? 저는 이 부분에서 제시한 데이터로는 그것을 어떻게 알 수 없고, 그게 핵심이에요. 나쁜 결과물의 빈도는 그들이 나쁜 결과물로 간주하는 기준과 고객이 채팅 창에 입력하는 텍스트의 종류에 완전히 의존합니다. 표준화된 기준은 그것에 대한 답변을 제공할 수 없어요.\n\n만약 이것에 대해 조금 무례하게 생각된다면, 다시 한 번 생각해 보세요! 저는 환각 벤치마크나 그 밖의 모든 것을 살펴봄으로써 배울 것이 많지 않다고 생각하지만, 실제로 당신처럼 생성형 AI 제품을 제공하는 사람들이 필요로 하는 종류의 오류율을 유용하게 추정할 수 있는 방법이 있다고 생각해요. 안타깝게도 그것을 추정하는 데 상당한 노력이 필요하지만, 가능하다는 것이 좋은 소식이에요.\n\n첫 번째로 필요한 것은 사용자가 제공할 텍스트의 종류를 잘 대표하는 데이터셋이에요. 이것은 수동으로, 여러분이 작성하여 추가할 수 있으며, 아마 처음에는 그렇게 해야 할 것입니다. 예상되는 모든 경우를 포함하는 다양한 변형을 생성하십시오, 사용자가 제출하기를 원하지 않을 텍스트도 포함되도록 하세요. 이제 그 모든 예제를 모델에 제출하고 수동으로 출력물을 검사하여 그것을 바람직하거나 바람직하지 않은 것으로 레이블링하세요. 이를 위해 원하는 기준을 사용할 수 있습니다. 중요한 것은 텍스트가 당신에게 바람직한지 여부에 있어요. 작업을 마치면 이를 사용하여 바람직하거나 바람직하지 않은 텍스트를 생성할 것으로 예상되는 빈도와 바람직하지 않은 텍스트를 생성할 때 어떤 종류의 바람직하지 않은 텍스트를 생성하는지 등을 추정할 수 있게 될 거예요. 이것은 대략적일 수 있지만, 일반화된 벤치마크를 살펴보는 것보다 훨씬 유용할 것이며, 왜냐하면 보다 대표적인 입력 집합에서 평가되며, 결과물은 특정 사용 사례에 대해 평가되기 때문이에요.\n\n당신의 제품이 실제로 어떤 것인지에 대해 결정하는 것이 실제로 모든 것을 훨씬 쉽게 만들어요. 생성형 AI의 특정 사용 사례에 대해 어떤 신중함이나 우려가 있어요. ChatGPT \u0026 기타들은 특별히 어떤 특정 목적을 위한 것은 아니에요. 그들은 모든 것을 위한 것이에요. 이겁니다. 무엇이 좋은 출력물인지에 대한 기준을 만들기가 정말 어려워요. 하지만 우리가 ChatGPT 랩핑을 고객 서비스 요원으로 활용한다면, 이제 우리는 원하는 출력물에 대해 몇 가지 범주를 정할 수 있어요. 우리는 그것이 가게에 대한 사실을 정확히 대변해주길 원해요. 우리는 예의 바르게 대해주길 원해요. 우리는 경쟁사를 권장하지 않길 원해요. 목록의 목록을 펼치는 방법에 대한 질문에 대해 틀린 해결책을 제시하길 원하지 않지만, 또한 올바른 해결책을 제시하길 원하지도 않아요. 이렇게 말할 만한 건 \"저는 고객 서비스 챗봇이에요. 거기에 대해 얘기할 것이에요. 고객 서비스에 대해 이야기해요.\" 이것은 사실 정말 좋은 소식이에요. 왜냐하면 이 레이블링 작업을 수행하기 위해 여러분이 실제로 리스트의 목록을 평평하게 하는 올바른 방법을 아셔야 하는 것이 아니기 때문이에요. 원하는 행동을 제한하면 생성하고자 하는 출력물 주변에 더 날카로운 경계를 설정할 수 있게 돼요. 이는 당신이 원하는 출력물의 종류에 대한 훌륭한 판단을 가능하게 해 줄 것이고, 당신이 필요로 하는 방식으로 작동할지 여부를 더 잘 파악할 수 있도록 할 것이에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 간단하게 들리게 하고 싶지는 않아요. 어려워요. 그리고 개별적인 평가를 수행하기 위한 체계적인 모범 사례 세트를 개발할 여지가 많다고 생각해요. (얼마나 많은 예제가 필요한가요? 예제 텍스트를 합성적으로 생성할 수 있나요? LLM으로 평가할 수 있나요? 기존 상호 작용에서 어떻게샘플링하여 더 큰 데이터 세트를 구축할 수 있나요? 이것이 파인튜닝과 어떤 관련이 있나요? 등등) 하지만 이것이 정말로 의존해야 하는 유형의 평가입니다. 일반적인 벤치마크는 봇이 당신에게 중요한 방식으로 환각할지에 대해 거의 아무것도 알려주지 않을 것입니다.\n\n# 마지막 예시\n\n이 글에서 Vectara의 사람들을 많이 논하게 되어 죄송합니다. 그러나 저의 글에서 그들이 게시한 환각 리더보드 소개 블로그 게시물에서의 예시가 이 글의 주요 포인트를 잘 보여준다고 생각합니다. 이 게시물은 예시를 통해 청중에게 환각의 개념을 소개합니다.\n\n![이미지](/assets/img/2024-05-18-HallucinationsErrorsandDreams_13.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n주장에 따르면, 모델이 거의 똑같은 이미지를 생성했지만 Kirby에 이빨이 없는 것이 맞고 사실적이며 환각이 없을 것이라고 합니다. 그러나 나는 그 이미지에서 몇 가지 다른 사실적인 문제를 발견할 수 있다고 생각해요. Kirby 왼쪽 뺨에 있는 분홍색 반점은 오른쪽 뺨보다 약간 더 어두워요. Kirby는 보통 이빨이 없는 캐릭터지만 Donkey Kong은 보통 이빨이 있는 편인데, 이 이미지에서는 이빨이 없어요. 게다가, 요청 사항은 Kirby가 Donkey Kong을 삼키도록 하는 것으로 보이지만, 저에게는 Donkey Kong이 Kirby의 입 안에서 쉬고 있는 것 같아요.\n\n아, 그리고 한 가지 더, Kirby와 Donkey Kong은 실제로 존재하지 않아요. Kirby가 Donkey Kong을 삼키는 사실적인 이미지란 존재하지 않아요.\n\n모델에게 이미지를 생성하도록 요청하면 환각을 유도하고 있다고 할 수 있어요. 실제로 존재하지 않는 이미지의 세부 사항을 상상하도록 하고, 실재하지 않는 이미지를 재구성하도록 요청하는 거예요. 이 이미지가 환각적인지 여부를 결정할 수 있는 보편적인 객관적 기준은 없어요. 여기서 저자는 이 이미지가 환각적으로 만드는 요인에 대한 개인적 기준을 적용하고 있으며, 이 기준이 다른 사람의 기준과 일치할 수도 있고 그렇지 않을 수도 있어요. 누구도 자기것이 \"정확한\" 기준을 가지고 있다고 주장할 수는 없어요.\n\n중요한 것은 결과물을 어떻게 활용할 것인가입니다. 모델의 목적이 무엇인가요? 이것이 결과물이 좋은지 나쁜지를 결정하는 방법이에요. 모델의 작업이 닌텐도의 캐릭터 디자인 기준을 준수하는 것이라면 이 경우에는 분명히 실패했다고 볼 수 있어요. 해당 작업에 대해 말하자면, 아마도 여기서 이빨은 이 문맥에서 환각으로 볼 수 있을 것이에요. 반면에 모델의 작업이 일반인이 해당 요청과 일치한다고 할 수 있는 이미지를 생성하는 것이라면 아마도 성공했다고 볼 수 있어요. 만약 나에게 그 이미지를 간단히 설명하라고 한다면, Kirby가 Donkey Kong을 삼키는 이미지라고 말할 수 있을 것이에요. 그러나 모델의 작업이 다른 회사의 지적 재산을 재생산하는 것을 피하는 것이라면, 예를 들어 Bing 이미지 생성기의 작업이라고 한다면, 이 이미지는 또 다른 종류의 환각이라고 볼 수 있을 것이에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n많은 사람들이 Google이 Gemini이 생성한 이미지를 너무 다양하게 느껴서 실망했었는데, 사과 글에서 그들은 \"환각 문제\"에 언급했어요.\n\n하지만 Gemini은 실제로 존재하지 않는 흑인 교황의 이미지를 생성했는데, 그것이 실제로 존재하지 않는 백인 교황의 이미지를 생성하는 것보다 뱅견된 것일까요? 둘 다 가짜 교황이니까요. 저는 이 두 경우가 동일하게 환각적일 것이라고 생각해요. 사실, 모든 생성된 결과물이 동일하게 환각적인 것 같아요. 구글이 Gemini가 생성해야 할 것과 그렇지 말아야 할 것에 대해 좀 더 구체적인 약속을 하지 않는 이상, 그것의 환각 비율을 평가할 수 있는 명백한 표준적인 방법이 없습니다.\n\n저는 이것이 이해도가 높지 않은 논란이 있는 주제이며, 다소 이론적인 기반이 거의 없는 분야라고 생각해요. 이러한 시스템의 전개 속도가 우리의 집단적인 이해 능력을 앞지르고 있습니다. 미래에 이 모든 것이 어떻게 작동하는지에 대해 내 생각을 바꿀 수 있다는 것에 저는 확신이 없으며, 피드백과 응답을 환영합니다. 하지만 환각의 본질에 대한 심각한 고찰 후, 그것이 개념적인 행렬 막달란다는 것에 대해 개인적으로 타당하게 확신합니다. 객관적으로 환각적인 결과물과 그렇지 않은 결과물이라는 것은 없으며, 환각을 일관된 개념으로 강조하는 것은 이러한 시스템의 적용 가능성을 평가하기 위해 해결해야 할 실질적인 작업으로부터 주의를 돌리는 것입니다.\n","ogImage":{"url":"/assets/img/2024-05-18-HallucinationsErrorsandDreams_0.png"},"coverImage":"/assets/img/2024-05-18-HallucinationsErrorsandDreams_0.png","tag":["Tech"],"readingTime":30},{"title":"인간 중심 AI 핀 부적절한 전략과 실행 사례 연구","description":"","date":"2024-05-18 19:45","slug":"2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution","content":"\n휴메인 인공 지능 핀은 디지털 어시스턴트가 탑재된 착용형 음성 제어 장치로, 일반적인 사용 사례에서 스마트폰을 대체하기 위해 만들어졌으며 가격은 700달러입니다. 그러나 최근에 나온 기술 제품 중에서 가장 부정적인 평가를 받은 제품 중 하나입니다.\n\n이 게시물은 Marques Brownlee의 리뷰에서 영감을 받았습니다. 그분은 제품이 해야 할 일(즉, 제품의 전략)과 제품을 사용하는 실제 경험(즉, 제품 팀의 실행)으로 리뷰를 구분하여 작성했습니다.\n\n# 휴메인 인공 지능 핀 제품 전략\n\n전략은 목표를 달성하기 위해 독특한 단계를 취하여 내구성 있는 경쟁 우위를 제공하는 방식입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋은 전략의 조건은 경쟁사가 귀하의 제품을 복제하거나 대체하기 어려운 점이 있어야 하며, 이는 귀사만이 이를 할 수 있는 특별한 능력을 갖고 있거나 성공적인 실행으로 구조적 이점을 창출하여 그것을 그냥 복제할 수 없게 만드는 것입니다.\n\n핵심 테제 제품의 목적은 사람들이 스마트한 개인 비서를 가지고 질문을 할 수 있어 편하게 사용할 수 있는 것이 유용할 것이라는 것입니다. 왜냐하면 핸드폰을 꺼내기는 종종 불편하기 때문입니다. 사실, 이것은 애플의 Siri의 핵심 가치 제안이었으며, 이는 2011년부터 광고를 진행해 왔으며, 오늘날에는 Airpods Pro와 함께 Siri를 사용할 때 가능합니다. 따라서 Humane AI Pin의 전체 가치 제안은 Siri가 별로라는 것입니다.\n\n제품 기회는 애플이 Siri에 대해 성공적으로 실행하는 경우 사라집니다. 리스크가 있는 베팅이지만, 그것이 불가능한 것은 아닙니다. Zoom은 사용하기 쉽고 사용이 검증된 비디오 회의 소프트웨어에 대해 마이크로소프트나 구글이 잘 실행하지 않을 것을 베팅함으로써 거대한 기업이 되었고 옳았습니다.\n\n전략을 평가하는 방법은 가정이 사실이고 완벽하게 실행된다고 가정했을 때 무엇이 발생하는지 고려하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMarkdown 형식으로 표를 수정하십시오.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 인간 친화적 AI 핀 제품 실행\n\n제품 실행은 측정 가능하고 집중된 것입니다. 이는 당신의 전략을 달성하는 것을 가능케 하는 단기적인 조치들입니다. 실행은 분기별 OKR 또는 매 반기마다의 목표와 같은 활동 유형입니다.\n\n완벽한 전략이라도 실행이 미흡하다면 중요하지 않습니다. 인간 친화적 AI 핀에서는 많은 미완벽한 실행이 있습니다.\n\n- “태양 빛을 받을 때 프로젝터는 기본적으로 읽을 수 없습니다.” — 워싱턴 포스트\n- “핀은 연속적인 요청을할 때 또는 프로젝터를 너무 오래 사용할 때 매우 빨리 과열되기 시작합니다. 그런 경우에 핀이 갑자기 연락을 끊고 식을 때는 놀랍지 마세요. 이 일은 2주 동안 4~5회 발생했습니다” — 워싱턴 포스트\n- “아, 카메라도요? 최선의 경우, 결과는 만족스러울 수 있지만, 어두운 곳에 있을 경우, 많은 노이즈와 흐릿한 얼굴을 기대하십시오.” — 워싱턴 포스트\n- “하지만, 아 차라리, AI 핀은 알람이나 타이머를 설정할 수 없습니다. 또한 캘린더에 항목을 추가하거나 이미 있는 항목을 알려줄 수도 없습니다. 노트와 목록을 만들 수는 있지만 (이는 당신이 장치를 연결하고 연락처를 관리하고 업로드한 사진을 확인할 수 있는 인류 센터 웹 앱에 나타납니다), 나중에 목록에 항목을 추가하려고 하면 거의 항상 어떤 이유로 실패 할 것입니다.” — 더 버지\n- “그리고 모든 것이 방해가 됩니다. 내 배낭 끈이 그것에 닿았고, 메신저 백이 그것에 걸려갑니다. 내 아들과 강아지가 날 덮치면서 실수로 AI 핀을 다시 시작했습니다.” — 더 버지\n- “AI 핀이 무언가를 시도할 때마다 Humane의 서버를 통해 쿼리를 처리해야 하며, 최상의 경우에는 상대적으로 느리고 최악의 경우에는 완전히 실패합니다. AI 핀에게 도서 매매가 다음 주에 있다고 말하면: 편리합니다! 10초를 기다리면서 처리하고 처리하고 일반적인 \"추가할 수 없음\" 오류 메시지를 표시하는 것은 덜 편리합니다. 누군가에게 전화를 걸려고 할 때 절반의 경우 전화가 걸리지 않을 것입니다. 누군가가 나를 호출했을 때 절반이상의 시간, AI 핀은 전화를 울리지도 않고 거의 바로 음성 사서함으로 연결했습니다. 여러 일 테스트를 거쳐, AI 핀이 할 수 있는 단 하나의 일은 시간을 알려주는 것뿐입니다.” — 더 버지\n- “AI 핀의 언어 모델과 기능에 대한 문제는 여기서 끝나지 않습니다. 때때로 다시 시작하거나 종료하는 것과 같이 요청한 내용을 거부할 때가 있습니다. 다른 경우에는 완전히 예상치 못한 일을 할 수도 있습니다. \"Julian Chokkattu에게 텍스트 메시지 보내기\"라고 말했을 때, 그는 Wired의 친구이자 AI 핀 리뷰어인데, 무엇을 어떻게 말하고 싶은지 물어볼 줄 알았습니다. 대신, 장치는 단순히 OK라고 말하고, \"안녕 Julian, 오늘 하루 어떻게 지내고 있니?\" 라며 Chokkattu에게 보낸다고 말했습니다. 우리가 친구사이인 몇 년 동안 저는 그에게 그런 말을 한 적이 없습니다. 그럼에도 불구하고 기술적으로 AI 핀이 내가 요청한 대로 행동 한 것이라고 할 수 있겠죠.” — 엔가젯\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋은 실행은 잘 설계된 기능을 제공하거나 적어도 사람들이 버그를 참을 가치가 있는 기능을 제공하는 것입니다. 인간적인 AI 핀은 첫 번째로 많은 것을 하지도 않는 제품인데도 불구하고 많은 버그 경험과 설계가 미흡한 기능들을 가지고 있습니다.\n\n마지막으로, 전략과 실행이 제품 결과에 어떻게 영향을 미치는지에 대한 훌륭한 예시를 제공해 준 인간적인 팀에 감사의 말씀을 전하고, 그들의 제품의 다음 버전에서 행운을 빕니다.\n","ogImage":{"url":"/assets/img/2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution_0.png"},"coverImage":"/assets/img/2024-05-18-TheHumaneAIPinACaseStudyinPoorStrategyandPoorExecution_0.png","tag":["Tech"],"readingTime":4},{"title":"ChatGPT-4의 비밀 슈퍼파워 YouTube 데모에서 보이지 않은 것들 ","description":"","date":"2024-05-18 19:43","slug":"2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou","content":"\n테크 세계는 오픈AI의 AI 기술의 최신 발전인 ChatGPT-4o의 출시 이후에 흥분으로 가득 찼습니다. 이전에 본 적이 없는 ChatGPT-4o는 \"토마토\"를 의미하는 \"o\"와 함께 천문적인 자연스러운 인간-컴퓨터 상호작용 분야의 혁명적인 한 걸음을 나아갑니다. YouTube 발표에서 많은 기능을 강조했지만, 미술되지 않은 놀라운 기능이 더 많이 있습니다. ChatGPT-4o가 게임 체인저인 이유와 그의 혁신적인 숨겨진 기능을 깊게 들여다보겠습니다.\n\n![ChatGPT-4o의 비밀 능력: YouTube 데모에 나오지 않은 것들](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_0.png)\n\n## 진정한 멀티모달 놀라움\n\nChatGPT-4o는 텍스트, 오디오, 이미지 및 비디오의 모든 조합을 입력으로 받아들이고, 텍스트, 오디오 및 이미지 형식으로 출력을 생성할 수 있도록 설계되었습니다. 이 유연성은 인간과 기계 간 보다 직관적이고 원활한 상호작용을 위한 새로운 지평을 열어줍니다. 놀랍게도, 모델의 오디오 입력에 대한 응답 시간이 인간의 대화 속도를 흉내내는 232밀리초로 매우 빠릅니다. 또한, 영어 텍스트 및 코드에서 GPT-4 Turbo의 성능과 맞먹아, 비영어 언어의 텍스트 처리를 현저히 향상시킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 다중 모달 기능은 사용자들이 말로 된 지시와 시각적 단서의 조합을 제공할 수 있도록 해줍니다. 이를 통해 더 풍부하고 세밀한 의사 소통이 가능해지며, 여러 가지 입력을 동시에 처리하고 응답할 수 있는 능력은 사용자 경험을 향상시켜 AI와의 상호 작용이 사람과 대화하는 듯한 느낌을 줍니다.\n\n# 향상된 이해를 위한 통합 모델\n\nGPT-3.5와 GPT-4와 같은 기존 모델은 음성 상호 작용을 위해 여러 단계의 과정을 거치면서 지연시간과 맥락 정보의 손실을 초래했습니다. 이에 반해, ChatGPT-4o는 모든 입력과 출력을 위한 단일 엔드-투-엔드 신경망을 사용합니다. 이를 통해 ChatGPT-4o는 톤, 배경 소음, 다수의 화자 등과 같은 뉴안스를 이해하고 더 자연스러운 감정적 표현을 생성할 수 있습니다. 즉, 웃음이나 노래와 같은 표현이 가능해집니다.\n\n이 통합된 방법은 모델이 오랜 대화 동안 문맥을 유지하고 복잡한 대화를 처리하는 능력을 향상시킵니다. 그룹 토론 중에 다른 화자를 구별하거나 대화에서 감정적 함의를 이해하는 것과 같은 작업에서, ChatGPT-4o의 통합된 설계는 대화 능력을 크게 향상시킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 다양한 형태에서 우수한 성능\n\nChatGPT-4o의 평가 지표는 인상적입니다:\n\n- 추론력: 0-shot CoT MMLU(일반 지식 질문)에서 88.7%의 점수를 기록하며 5-shot no-CoT MMLU에서 87.2%를 달성하여 우수한 추론 능력을 자랑합니다.\n- 오디오 및 비전: 음성 인식에서 Whisper-v3를 능가하며 다국어 및 시각 인식 평가에서 새로운 기준을 세웁니다.\n\n이러한 지표는 ChatGPT-4o의 다양한 형태를 이해하고 생성하는 고급 기능을 강조합니다. 추론 테스트에서의 성과는 복잡하고 미묘한 쿼리를 처리하는 능력을 보여주며, 교육 및 전문 분야에 강력한 도구로 사용될 수 있음을 나타냅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 비디오에서 소개되지 않은 혁신적 기능\n\n유튜브 발표에서 강조되지 않은 ChatGPT-4o의 두드러지는 기능들을 소개합니다:\n\n## 시각적 서술\n\n- 로봇 작가의 차단: ChatGPT-4o는 텍스트 설명을 일관된 이미지 시퀀스로 전환할 수 있습니다. 이를 통해 로봇이 종이를 입력하고 찢어내는 과정을 단계별로 시각화할 수 있습니다. 사건 시퀀스를 이해하고 묘사할 수 있는 능력으로, 이는 이야기와 시각 요소를 결합하는 내용 작성 및 블렌딩에 뛰어난 기능을 제공합니다.\n- 우편집사 샐리: 이 기능은 상세한 텍스트 설명을 해석하고 해당하는 시각적 표현물을 생성할 수 있습니다. 샐리가 우편을 배달하거나 강아지와 상호 작용하며 이동하는 장면 등을 묘사할 수 있으며, 캐릭터 일관성과 상세한 시각적 서술을 보장합니다. 이 능력은 ChatGPT-4o의 교육, 엔터테인먼트, 마케팅과 같은 분야에서 텍스트 입력으로부터 매력적이고 정확한 시각적 이야기를 만드는 것을 강조하며, 이를 통해 유틸리티가 향상됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_1.png\" /\u003e\n\n## 창의적 콘텐츠 생성\n\n- 영화 '탐정'을 위한 포스터 제작: ChatGPT-4o는 텍스트 설명에서 전문적인 품질의 영화 포스터를 만들 수 있습니다. 예를 들어, 두 캐릭터의 얼굴을 신중한 표현과 함께 포함하여 특정 시나리오를 정확하게 나타낼 수 있는 포스터를 생성할 수 있습니다. 이 능력은 ChatGPT-4o의 고급 디자인 기술과 세심한 주의를 보여주며, 그래픽 디자인 및 마케팅에 탁월한 도구로 사용될 수 있습니다.\n- 캐릭터 디자인 — 로봇 Geary: 이 기능은 ChatGPT-4o가 요리, 바이올린 연주 또는 프로그래밍과 같은 다양한 활동 중에서도 일관적으로 캐릭터를 시각화할 수 있게 합니다. 텍스트에서 특정 세부 사항을 포함하여 캐릭터 무결성을 유지하면서, ChatGPT-4o는 애니메이션, 비디오 게임 및 교육 콘텐츠에 중요한 캐릭터 디자인과 스토리텔링 능력을 입증합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_2.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 예술적 및 타이포그래픽 스킬\n\n- 반복 편집을 통한 시적 타이포그래피: ChatGPT-4o는 시를 시각적으로 매력적인 디자인으로 변환할 수 있으며, 사용자 피드백을 기반으로 출력물을 반복적으로 개선합니다. 예를 들어 시를 명확한 필체로 변환하고 초현실주의적인 도안으로 가득한 것으로 만든 다음, 디자인을 다크 모드로 조정하거나 요청에 따라 색상을 변경할 수 있습니다. 이 능력은 모델의 유연성과 예술적 스킬을 강조하며, 사용자 맞춤형 및 예술적 시각 콘텐츠를 만들기 위한 강력한 도구로 만들어줍니다.\n- 글꼴 디자인: ChatGPT-4o는 상세한 텍스트 설명에서 사용자 정의 글꼴을 만들 수 있습니다. 화려한 빅토리아 양식의 글꼴이나 현대적이고 세련된 디자인을 생성할 수 있어서 다양한 타이포그래픽 스타일과 디테일 수준을 처리할 수 있는 능력을 보여줍니다. 이 능력은 브랜딩, 마케팅 및 크리에이티브 프로젝트에 대한 독특하고 맞춤형 글꼴을 만들고자 하는 디자이너들에게 특히 유용합니다.\n\n![ChatGPT-4o's Secret Superpowers What-the-YouTube-Demo-DIDN'T-Show-You](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_3.png)\n\n## 브랜딩 및 마케팅\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 코스터 위의 로고: ChatGPT-4o는 명확한 소재 및 디자인 명세를 반영하여 코스터와 같은 제품에 브랜드 로고를 정확하게 배치할 수 있습니다. 예를 들어, 나무와 대리석 코스터에 새겨진 OpenAI 로고를 묘사하여 브랜딩 및 제품 디자인 작업을 처리하는 데 정확성을 보여줍니다. 이 기능은 브랜드 제품을 시각화하고 마케팅, 디자인 및 프레젠테이션에 도움이 되는 데 매우 가치가 있습니다.\n\n![이미지](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_4.png)\n\n## 고급 텍스트 렌더링\n\n- 여러 줄 렌더링 — 로봇 문자 입력: 이 기능을 통해 ChatGPT-4o는 로봇이 문자를 보내는 것을 자세히 보여주는 능력이 있습니다. 명확하고 가독성 있는 여러 줄 메시지를 생성할 수 있습니다. 로봇이 핸드폰의 메시지 앱을 보는 일인칭 시점을 묘사하여 텍스트가 말풍선 안에서 정확하게 표현되도록 합니다. 이 기능은 교육 자료, 이야기 전달 및 디자인 개념에 대한 시각적 콘텐츠를 작성하는 데 모델의 유틸리티를 향상시킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_5.png\" /\u003e\n\n# 포괄적인 멀티미디어 콘텐츠 생성\n\n- 다양한 스피커가 있는 회의록: ChatGPT-4o는 오디오 입력을 해석하여 다양한 스피커를 인식하고 자세한 필기를 생성하는 데 능숙합니다. 이는 목소리를 구별하고 대화를 정확하게 속성 지정하여 필기를 명확하고 읽기 쉬운 형식으로 제공할 수 있습니다. 이 기능은 회의, 인터뷰 및 정확한 음성 상호작용 기록이 필요한 다른 시나리오에 유용합니다.\n- 강의 요약: ChatGPT-4o는 긴 강의나 프레젠테이션을 간결하고 정보량 풍부한 요약으로 만들 수 있습니다. 내용을 글머리 기호나 번호 목록으로 구조화하여 요약이 쉽게 읽고 이해할 수 있도록 합니다. 이 기능은 교육 목적, 회의록 및 콘텐츠 큐레이션에 유용하며, 긴 콘텐츠에서 중요한 포인트를 추려내는 것이 중요한 상황에 가치가 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_6.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 변수 바인딩 - 큐브 쌓기: 이 능력을 통해 ChatGPT-4o는 텍스트 설명을 기반으로 특정 특성과 배열을 가진 객체를 시각화할 수 있습니다. 예를 들어, 다양한 색상과 문자가 특정 순서로 쌓인 큐브를 정확하게 묘사할 수 있어 복잡한 변수 할당을 다루고 일관성을 유지하는 능력을 보여줍니다. 이 기능은 교육 자료, 안내서 및 창의적인 프로젝트를 시각화하는 데 유용합니다.\n- 콘크리트 시: ChatGPT-4o는 시와 시각 예술을 결합한 시각적으로 매력적이고 구조적으로 정확한 콘크리트 시를 만들 수 있습니다. 단어를 모양을 형성하도록 배열하거나 OpenAI 로고와 같은 모양을 형성하는 등의 단어를 배치하고 추가 지침에 따라 디자인을 사용자 정의할 수 있습니다. 이 기능은 텍스트를 시각적 요소와 결합하여 매력적이고 의미 있는 예술을 만드는 프로젝트에 대한 유틸리티를 향상시킵니다.\n\n![이미지](/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_7.png)\n\n# 무결한 안전성과 사용 편의성\n\n안전성은 ChatGPT-4o의 설계의 중요한 요소입니다. 내장된 안전 메커니즘과 사후 교육을 통한 다듬어진 동작으로 모델은 다양한 모달리티에서 책임 있는 사용을 보장합니다. ChatGPT-4o가 사이버 보안 및 편향을 포함한 다양한 안전 범주에서 중간 위험 수준 이하를 유지하는 것을 보여 주는 포괄적인 평가가 이루어졌습니다. 사회심리학과 오진 정보에 대한 외부 전문가들은 잠재적인 위험을 식별하고 완화하기 위해 모델을 엄격하게 테스트했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델의 안전 프로토콜을 통해 사용자 보안이나 개인 정보 보호를 저해하지 않고 다양한 환경에서 배치할 수 있습니다. 견고한 디자인과 지속적인 개선으로 교육, 의료 및 전문 서비스 분야의 민감한 응용 프로그램에 신뢰할 만한 선택지가 됩니다.\n\n# 가용성 및 향후 출시 계획\n\nChatGPT-4o는 무료 티어 및 플러스 사용자에게 확장된 메시지 제한이 적용된 상태로 현재 사용 가능합니다. 개발자들은 API를 통해 텍스트 및 비전 작업에 액세스할 수 있습니다. 앞으로 몇 주 내에 음성 및 비디오 기능은 일부 신뢰할 수 있는 파트너 그룹에게 출시될 예정입니다.\n\n이 단계적 출시를 통해 OpenAI는 피드백을 수집하고 필요한 조정을 수행함으로써 모델의 전체 잠재력을 실현하고 성능 및 신뢰성의 높은 기준을 유지하는 것을 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 새로운 지평을 탐험 중\n\nChatGPT-4o는 성능을 향상시키는 데 그치지 않습니다. 인공지능이 자연스럽고 창의적으로 사람들과 상호 작용하는 잠재력을 탐험하는 데 중점을 두고 있습니다. ChatGPT-4o는 상세한 시각적 서술을 만들거나 사용자 정의 글꼴을 디자인하거나 정확한 오디오 전사를 제공하는 것과 같은 일들을 수행하는 데 있어 인공지능 기술의 새로운 기준을 정립하고 있습니다.\n\n멀티모달리티를 원활하게 통합하고 해석하며, 고급 추론 능력과 창의적 능력을 결합하여 ChatGPT-4o는 인공지능의 진화 과정에서 중요한 이정표로 자리매김하고 있습니다. ChatGPT-4o가 이끄는 인간-컴퓨터 상호작용의 미래는 촉망받으며, 인공지능이 어디까지 성취할 수 있는지의 한계를 넓히는 데 도움이 되고 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_0.png"},"coverImage":"/assets/img/2024-05-18-ChatGPT-4osSecretSuperpowersWhattheYouTubeDemoDIDNTShowYou_0.png","tag":["Tech"],"readingTime":9},{"title":"BiTCN 컨볼루션 네트워크를 활용한 다변수 시계열 예측","description":"","date":"2024-05-18 19:41","slug":"2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks","content":"\n![image](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png)\n\n시계열 예측 분야에서는 모델의 아키텍처가 주로 다층 퍼셉트론(MLP) 또는 트랜스포머 아키텍처에 의존합니다.\n\nN-HiTS, TiDE 및 TSMixer와 같은 MLP 기반 모델은 훈련 속도가 빠르면서 매우 좋은 예측 성능을 달성할 수 있습니다.\n\n한편, PatchTST 및 iTransformer와 같은 트랜스포머 기반 모델도 좋은 성능을 달성하지만 더 많은 메모리를 소비하고 더 많은 훈련 시간이 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아직도 예측에서 널리 활용되고 있지 않은 아키텍처 하나가 있습니다: 합성곱 신경망(CNN).\n\n전통적으로 CNN은 컴퓨터 비전에 적용되었지만, 예측 분야에서는 TimesNet이 최근의 예만 있습니다.\n\n그러나 CNN은 순차 데이터를 처리하는 데 효과적임이 입증되었으며, 그들의 아키텍처는 병렬 계산을 허용하여 훈련 속도를 크게 높일 수 있습니다.\n\n따라서 본 기사에서는 2023년 3월 논문 'Parameter-efficient deep probabilistic forecasting'에서 제안된 BiTCN을 탐색합니다. 두 개의 시계열 합성곱 신경망(TCN)을 활용하여 이 모델은 과거와 미래의 변수를 인코딩하면서도 계산 효율적인 특징을 유지합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n더 자세한 내용은 원본 논문을 꼭 읽어보세요.\n\n시작해봅시다!\n\n## BiTCN 탐험\n\n이전에 언급된대로, BiTCN은 두 개의 시계열 합성곱 신경망을 활용하므로 그 이름이 BiTCN입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한 TCN은 미래 공변량을 인코딩하고, 다른 하나는 과거 공변량 및 시계열의 역사적 값들을 인코딩합니다. 이렇게 함으로써 모델은 데이터로부터 시간 정보를 배울 수 있고, 합성곱의 사용으로 계산 효율성을 유지할 수 있습니다.\n\n여기에는 분석할 것이 많기 때문에 아키텍처를 좀 더 자세히 살펴보겠습니다.\n\n## BiTCN 아키텍처\n\nBiTCN의 아키텍처는 많은 시계열 블록으로 구성되어 있습니다. 각 블록은 다음과 같이 구성됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 확장된 합성곱\n- GELU 활성화 함수\n- 드롭아웃 단계\n- 완전 연결 레이어\n\n시계열 블록의 일반적인 아키텍처는 아래에 표시됩니다.\n\n![temporal block](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_1.png)\n\n위 그림에서 각 시계열 블록이 출력 O를 생성함을 볼 수 있습니다. 최종 예측은 N개의 레이어에 쌓인 각 블록의 모든 출력을 더하여 얻습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n드롭아웃과 댄스 레이어는 신경망에서 흔한 구성 요소입니다. 그러나 이번에는 확장 컨볼루션(dilated convolution)과 GELU 활성화 함수에 대해 좀 더 자세히 살펴봅시다.\n\n## 확장 컨볼루션\n\n확장 컨볼루션의 목표를 더 잘 이해하기 위해, 기본적인 컨볼루션이 어떻게 작동하는지 상기해 봅시다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 그림에서 일차원 입력에 대한 전형적인 합성곱이 어떻게 보이는지 볼 수 있습니다. 출력의 길이를 동일하게 유지하기 위해 입력 시리즈는 왼쪽에 0으로 채워집니다.\n\n세 개의 커널 크기와 한 개의 스트라이드를 가정할 때, 위 그림에 나와 있는대로 출력 텐서도 네 개의 길이를 가집니다.\n\n출력의 각 요소가 세 개의 입력 값을 기반으로 한다는 것을 볼 수 있습니다. 다시 말해 출력은 색인의 값과 이전 두 값에 의존합니다.\n\n이를 수용 영역(Receptive Field)이라고 합니다. 시계열 데이터를 다루고 있으므로 출력 계산이 더 긴 이력을 볼 수 있도록 수용 영역을 증가시키는 것이 유익할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그렇게 하려면, 커널 크기를 크게 하거나 더 많은 합성곱 계층을 쌓을 수 있습니다. 커널 크기를 크게 하는 것은 최선의 선택이 아닙니다. 정보를 손실하고 모델이 데이터의 유용한 관계를 학습하지 못할 수 있습니다. 그래서 더 많은 합성곱을 쌓아보겠습니다.\n\n위 그림에서 볼 수 있듯이, 커널 크기가 3인 두 개의 합성곱 작업을 쌓으면 출력의 마지막 요소는 이제 입력의 다섯 요소에 의존합니다. 따라서 수용 영역이 3에서 5로 증가했습니다.\n\n안타깝게도 이것도 문제가 됩니다. 이러한 방식으로 수용 영역을 증가시키면 아주 깊은 신경망이 생성될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서, 우리는 모델에 너무 많은 레이어를 추가하지 않으면서 수용 영역을 증가시키기 위해 확장된 합성곱을 사용합니다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_4.png)\n\n위의 그림에서 우리는 2-확장된(convolution)을 실행한 결과를 볼 수 있습니다. 기본적으로 매 두 요소가 하나의 출력을 생성하는 것으로 간주됩니다. 따라서 우리는 이제 컨벌루션을 쌓지 않고도 수용 영역이 5임을 볼 수 있습니다.\n\n실제로 수용 영역을 더 증가시키기 위해, 주로 2로 설정된 확장 베이스를 사용하여 많은 희석커널(diluted kernel)을 쌓습니다. 이는 첫 번째 레이어가 2¹-확장 커널이되고, 그다음에 2²-확장 커널이 따르며, 그런 다음 2³로 이어지는 방식입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수용 영역이 늘어나면 모델은 더 긴 입력 시퀀스를 고려하여 출력을 생성할 수 있습니다. Dilated convolutions을 사용하면 합리적인 수의 레이어를 유지할 수도 있습니다.\n\n이제 Dilated convolutions의 내부 작업을 이해했으니 GELU 활성화 함수를 알아보겠습니다.\n\n## GELU 활성화 함수\n\n많은 딥러닝 아키텍처에서는 ReLU(Recitified Linear Unit) 활성화 함수를 사용합니다. ReLU의 방정식은 아래와 같이 표시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 식을 보면 ReLU는 간단히 0과 입력 중 최대 값을 취하는 것을 알 수 있습니다. 다시 말해, 입력이 양수이면 입력이 반환되고, 입력이 음수이면 0이 반환됩니다.\n\nReLU는 사라지는 그래디언트 문제를 완화하는 데 도움이 되지만 죽은 ReLU 문제를 만들 수도 있습니다.\n\n이는 네트워크에서 일부 뉴런이 오직 0만 출력하여 모델의 학습에 더 이상 기여하지 않는 경우에 발생합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해당 상황에 대처하기 위해 가우시안 에러 선형 유닛 또는 GELU를 사용할 수 있습니다. GELU 방정식은 아래와 같이 나타낼 수 있습니다.\n\n![GELU Equation](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_6.png)\n\n이 함수를 사용하면 입력 값이 0보다 작을 때 작은 음수 값을 활성화 함수로 사용할 수 있습니다.\n\n![Activation Function with GELU](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 하면 신경세포가 소멸하지 않게 되어 음수 입력 값을 사용하여 0이 아닌 값이 반환될 수 있습니다. 이는 역전파에 대해 더 풍부한 그래디언트를 제공하며 모델의 기능을 유지할 수 있습니다.\n\n## BiTCN에서 모두 모아보기\n\n이제 BiTCN의 시간 블록의 내부 작업을 이해했으니, 우리는 모델에서 모든 것이 어떻게 함께 동작하는지 살펴봅시다.\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 그림에서는 늦게 발생한 값들이 밀도 레이어를 통과하고 시간 블록 스택을 거친 후 모든 이전 공변량과 결합된 것을 볼 수 있습니다.\n\n상단에는 범주형 공변량이 다른 공변량과 결합되기 전에 먼저 임베딩된 것을 볼 수 있습니다. 여기서는 미래와 과거 공변량이 아래에 표시된 대로 모두 결합됨에 유의해주세요.\n\n그럼 그 값들은 밀도 레이어와 시간 블록 스택을 거쳐 이끌어집니다.\n\n최종 출력은 아래에 표시된 것과 같이 늦게 발생한 값과 공변량에서 나온 정보가 결합된 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![그림](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_9.png)\n\n위의 그림은 하나의 시간 블록이 공변량의 미래 값을 활용하여 모델 출력을 결정하는 아이디어를 강조합니다 (빨간 점으로 표시됨).\n\n마지막으로, BiTCN은 예측 주변에 신뢰 구간을 구성하기 위해 Student’s t-분포를 사용합니다.\n\n이제 BiTCN의 내부 작업을 이해했으니, Python을 사용하여 소규모 예측 프로젝트에 적용해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# BiTCN을 사용한 예측\n\n이 실험에서는 BiTCN을 N-HiTS 및 PatchTST와 함께 사용하여 장기 예측 작업을 수행합니다.\n\n구체적으로, 블로그 웹사이트의 일일 조회수를 예측하는 데 사용합니다. 데이터셋에는 일일 조회수와 새로운 글이 게시된 날짜를 나타내는 지표, 미국의 공휴일을 나타내는 지표와 같은 외생 특성이 포함되어 있습니다.\n\n이 데이터셋은 제가 직접 제 웹사이트의 트래픽을 사용하여 컴파일했습니다. 데이터셋은 여기서 공개적으로 이용 가능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n본 부분에서는 외부 기능을 지원하는 BiTCN의 사용 준비 구현을 제공하는 것으로 내가 알기로는 유일한 라이브러리인 neuralforcast를 사용합니다.\n\n언제나 GitHub에 이 실험의 전체 소스 코드가 있습니다.\n\n시작해 봅시다!\n\n## 초기 설정\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 프로젝트에 필요한 라이브러리를 가져오는 것이 첫 번째 단계입니다.\n\n```js\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.models import NHITS, PatchTST, BiTCN\n```\n\n그런 다음, 데이터를 DataFrame으로 읽어옵니다.\n\n```js\ndf = pd.read_csv('https://raw.githubusercontent.com/marcopeix/time-series-analysis/master/data/medium_views_published_holidays.csv')\ndf['ds'] = pd.to_datetime(df['ds]')\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터를 그래프로 나타낼 수도 있습니다.\n\n```js\npublished_dates = df[df[\"published\"] == 1];\nholidays = df[df[\"is_holiday\"] == 1];\n\nfig, (ax = plt.subplots((figsize = (12, 8))));\n\nax.plot(df[\"ds\"], df[\"y\"]);\nax.scatter(\n  published_dates[\"ds\"],\n  published_dates[\"y\"],\n  (marker = \"o\"),\n  (color = \"red\"),\n  (label = \"새 기사\")\n);\nax.scatter(\n  holidays[\"ds\"],\n  holidays[\"y\"],\n  (marker = \"x\"),\n  (color = \"green\"),\n  (label = \"미국 공휴일\")\n);\nax.set_xlabel(\"날짜\");\nax.set_ylabel(\"총 조회수\");\nax.legend((loc = \"best\"));\n\nfig.autofmt_xdate();\n\nplt.tight_layout();\n```\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_10.png)\n\n위 그림에서, 주중에 주말보다 더 많은 방문이 발생하는 주별 계절성이 명확히 나타납니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한, 방문 횟수의 급증은 일반적으로 새로운 기사가 게시된 후 발생합니다(빨간 점으로 표시됨). 새로운 콘텐츠가 더 많은 트래픽을 유도하기 때문에 새로운 기사가 게시될 때 일반적으로 트래픽이 증가합니다. 마지막으로, 미국 공휴일(녹색 십자로 표시됨)은 종종 낮은 트래픽을 시사합니다.\n\n따라서, 외부 요인의 영향을 명확히 볼 수 있는 시리즈이며, BiTCN을 위한 훌륭한 사용 사례입니다.\n\n## 데이터 처리\n\n이제 데이터를 학습 세트와 테스트 세트로 분할해 봅시다. 테스트를 위해 마지막 28개 항목을 예약합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ntrain = df[:-28]\ntest = df[-28:]\n```\n\n그런 다음, 예보 기간에 대한 날짜 및 외생 변수의 미래 값이 포함된 DataFrame을 생성합니다.\n\n미래의 외생 변수 값을 제공하는 것이 의미가 있다는 점에 유의해야 합니다. 미래의 미국의 공휴일 날짜는 미리 알려져 있으며, 기사의 발행 또한 계획할 수 있기 때문입니다.\n\n```python\nfuture_df = test.drop(['y'], axis=1)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋아요! 이제 시리즈를 모델링할 준비가 되었습니다.\n\n## 모델링\n\n언급했듯이, 이 프로젝트에서는 N-HiTS(MLP 기반), BiTCN(CNN 기반) 및 PatchTST(Transformer 기반)를 사용합니다.\n\nN-HiTS와 BiTCN은 둘 다 외부 특성을 사용한 모델링을 지원하지만, PatchTST는 지원하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 실험의 수평선은 테스트 세트의 전체 길이를 포함하기 위해 28로 설정됩니다.\n\n```js\nhorizon = len(test);\n\nmodels = [\n  NHITS(\n    (h = horizon),\n    (input_size = 5 * horizon),\n    (futr_exog_list = [\"published\", \"is_holiday\"]),\n    (hist_exog_list = [\"published\", \"is_holiday\"]),\n    (scaler_type = \"robust\")\n  ),\n  BiTCN(\n    (h = horizon),\n    (input_size = 5 * horizon),\n    (futr_exog_list = [\"published\", \"is_holiday\"]),\n    (hist_exog_list = [\"published\", \"is_holiday\"]),\n    (scaler_type = \"robust\")\n  ),\n  PatchTST(\n    (h = horizon),\n    (input_size = 2 * horizon),\n    (encoder_layers = 3),\n    (hidden_size = 128),\n    (linear_hidden_size = 128),\n    (patch_len = 4),\n    (stride = 1),\n    (revin = True),\n    (max_steps = 1000)\n  ),\n];\n```\n\n그런 다음, 훈련 세트에 모델을 적용합니다.\n\n```js\nnf = NeuralForecast((models = models), (freq = \"D\"));\nnf.fit((df = train));\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼, 우리는 외부 요인의 미래 값을 사용하여 예측을 생성할 수 있어요.\n\n```js\npreds_df = nf.predict((futr_df = future_df));\n```\n\n좋아요! 지금 이 시점에서, preds_df에 저장된 예측이 있어요. 각 모델의 성능을 평가할 수 있어요.\n\n## 평가\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예측값과 실제 값들을 하나의 DataFrame으로 합치는 것으로 시작합니다.\n\n```python\ntest_df = pd.merge(test, preds_df, 'left', 'ds')\n```\n\n선택적으로, 예측값을 실제 값과 비교해서 아래 그림과 같이 시각화할 수도 있습니다.\n\n![예제 그림](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_11.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 그림에서는 모든 모델이 실제 트래픽을 전반적으로 과대 예측한 것으로 보입니다.\n\n그럼 최상의 성능을 발휘하는 모델을 찾기 위해 평균 절대 오차 (MAE)와 대칭 평균 절대 백분율 오차 (sMAPE)를 측정해보겠습니다.\n\n```js\nfrom utilsforecast.losses import mae, smape\nfrom utilsforecast.evaluation import evaluate\n\nevaluation = evaluate(\n    test_df,\n    metrics=[mae, smape],\n    models=[\"NHITS\", \"BiTCN\", \"PatchTST\"],\n    target_col=\"y\",\n)\n\nevaluation = evaluation.drop(['unique_id'], axis=1)\nevaluation = evaluation.set_index('metric')\n\nevaluation.style.highlight_min(color='blue', axis=1)\n```\n\n![이미지](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_12.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 표에서 BiTCN이 최상의 성능을 달성했음을 확인할 수 있습니다. 해당 모델의 MAE 및 sMAPE가 가장 낮기 때문입니다.\n\n이 실험만으로는 BiTCN의 강력한 벤치마크는 아니지만, 외생 변수를 활용한 예측 문맥에서 가장 우수한 결과를 달성하는 것을 볼 수 있어 흥미로운 실험입니다.\n\n# 결론\n\nBiTCN 모델은 이전 값과 미래 값을 함께 인코딩하기 위해 두 개의 시간 합성곱 신경망을 활용하여 효율적인 다변량 시계열 예측을 수행합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시계열 분야에서 컨볼루션 신경망의 성공적인 응용을 보는 것은 흥미로운 일이죠. 대부분의 모델은 MLP 또는 트랜스포머를 기반으로 하지만요.\n\n저희의 소규모 실험에서 BiTCN이 가장 우수한 성능을 발휘했습니다. 하지만 저는 각 문제에는 독특한 해결책이 필요하다고 믿습니다. 이제 BiTCN을 도구 상자에 추가하고 여러분의 프로젝트에 적용해 보세요.\n\n독자 여러분, 읽어 주셔서 감사합니다! 즐기셨기를 바라며 무엇인가 새로운 것을 배우셨기를 기대합니다.\n\n건배 🍻\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 저를 지지해주세요\n\n제 작품을 즐기고 계신가요? Buy me a coffee로 제게 지지를 보여주세요. 그러면 여러분은 제게 격려를 주고, 저는 커피 한 잔을 즐길 수 있어요! 만약 그러고 싶다면, 아래 버튼을 클릭해주세요 👇\n\n![Buy me a coffee](/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_13.png)\n\n# 참고자료\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n**Parameter-efficient deep probabilistic forecasting** by Olivier Sprangers, Sebastian Schelter, Maarten de Rijke\n\nExplanation of **dilated convolution** and figures of **dilates convolutions** inspired: **Temporal convolutional networks and forecasting** by Unit8\n","ogImage":{"url":"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png"},"coverImage":"/assets/img/2024-05-18-BiTCNMultivariateTimeSeriesForecastingwithConvolutionalNetworks_0.png","tag":["Tech"],"readingTime":18},{"title":"시간을 통해 전파하는 역전파  RNN이 학습하는 방법","description":"","date":"2024-05-18 19:38","slug":"2024-05-18-BackpropagationThroughTimeHowRNNsLearn","content":"\n![RNN](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png)\n\n순환 신경망(RNN)은 시계열 및 자연어와 같은 순차 데이터를 처리하는 정규 피드포워드 신경망 변형입니다.\n\n과거 입력 및 출력에서 다음 단계로 정보를 전달할 수 있도록 \"순환\" 뉴런을 추가하여 이를 달성합니다. 아래 다이어그램은 전통적인 RNN을 보여줍니다:\n\n![RNN Diagram](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n왼쪽에는 반복 뉴런이 있고, 오른쪽에는 시간을 거듭할수록 펼쳐진 반복 뉴런이 있습니다. 이전 실행이 이어지는 계산에 전달되는 방식을 주목해주세요.\n\n이것은 시스템에 어느정도의 \"기억력\"을 추가하여 모델이 이전 시간에 발생한 역사적 패턴을 잡는 데 도움이 됩니다.\n\nY_1을 예측할 때, 반복 뉴런은 X_1의 입력과 이전 시간 단계의 출력인 Y_0을 사용합니다. 이는 Y_0이 Y_1에 직접적인 영향을 미치고, 이는 Y_2에 간접적으로 영향을 미침을 의미합니다.\n\nRNN에 대한 완벽한 소개와 몇 가지 실습 예제를 원하신다면, 이전 포스트를 확인해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 이 기사에서는 RNN이 어떻게 학습하는지를 뒷방향 시간으로 이해하자구!\n\n# 역전파란?\n\nBPTT에 대해 들어가기 전에, 일반적인 역전파를 다시 확인하는 것이 중요하다. 역전파는 일반적인 피드포워드 신경망을 훈련하는 데 사용되는 알고리즘이야.\n\n역전파의 본질은 손실 함수를 기반으로 신경망의 각 매개변수를 조정하여 오차를 최소화하려는 것이야. 이 조정은 편도함수와 연쇄법칙을 사용해 이루어져.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ncompute 그래프를 통해 간단한 예제를 보여드릴게요. compute 그래프는 신경망과 매우 닮은데요.\n\n다음 함수를 살펴보세요:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_2.png)\n\n이것을 compute 그래프로 그릴 수 있습니다. 이는 함수를 시각화하는 방법일 뿐이에요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n`\u003ctable\u003e` 태그를 마크다운 형식으로 변경해 주세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 먼저 p=x-y 및 f=pz에 대한 편미분을 계산할 수 있습니다:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_5.png)\n\n하지만, 어떻게 얻을까요?\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요기서는 chain rule을 사용해요! x에 대한 예시가 있어요:\n\n![chain rule example](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_7.png)\n\n서로 다른 편미분을 결합하면 원하는 표현을 얻을 수 있어요. 그래서 위 예시에서:\n\n![partial derivatives example](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nf에 대한 x의 출력 그라디언트는 z입니다. 이게 말이 되지요. z는 x를 곱하는 유일한 값이기 때문이죠.\n\ny와 z에 대해서도 반복합니다:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_9.png)\n\n이러한 그라디언트들과 그에 해당하는 값들을 계산 그래프에 적어볼 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Gradient Descent Image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_10.png)\n\nGradient descent works by updating the values (x, y, z) by a small amount in the opposite direction of the gradient. The goal of gradient descent is to try and minimize the output function. For example, for x:\n\n![Equation for x](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_11.png)\n\nWhere h is called the learning rate, it decides how much the parameter will get updated. For this case, let’s define h=0.1, so x=3.7.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금 출력 결과는 무엇인가요?\n\n![이미지](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_12.png)\n\n결과가 작아졌죠. 다시 말해, 최소화 중이에요!\n\n이것이 역전파가 어떻게 작동하는지에 대한 직관을 제공해줬으면 좋겠어요. 기본적으로 그것은 그라디언트 강하와 같지만, 연쇄 법칙을 사용하여 상류 그라디언트를 전달한다는 거죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n백프로패게이션에 대한 전문 기사가 있어요. 더 읽고 싶으시면 참고하세요.\n\n# 시간을 통한 역전파란?\n\n## 개요\n\n우리는 방금 백프로패게이션이 그래디언트 강하법이라는 것을 보았습니다. 그러나 우리는 네트워크 층마다 오류(도함수)를 역방향으로 전파하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBPTT은 각 시점에서 역전파를 수행하여 이러한 정의를 확장합니다. 예제를 함께 살펴보겠습니다.\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_13.png)\n\n다음 다이어그램에서:\n\n- Y는 출력 벡터입니다.\n- X는 피처의 입력 벡터입니다.\n- h는 숨겨진 상태입니다.\n- V는 출력을 위한 가중치 행렬입니다.\n- U는 입력을 위한 가중치 행렬입니다.\n- W는 숨겨진 상태를 위한 가중치 행렬입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어떤 시간 t에서 다음은 계산된 출력입니다:\n\n![2024-05-18-BackpropagationThroughTimeHowRNNsLearn_14.png](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_14.png)\n\n여기서 σ는 일반적으로 tanh 또는 sigmoid인 활성화 함수입니다.\n\n우리의 손실 함수가 평균 제곱 오차인 경우를 가정해 봅시다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_15.png)\n\nA_t is the actual value that we want our prediction to equal.\n\n## Backpropagation Through Time\n\nNow, we are in a position to start doing BPTT after this problem has been set up.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n백프로파게이션의 목표는 모델의 가중치와 매개변수를 조정하여 오차를 최소화하는 것입니다. 이것은 가중치와 매개변수에 대한 오차의 편미분을 통해 수행됩니다.\n\n시간 단계 3의 업데이트를 계산해 봅시다.\n\nV 가중치 행렬에 대해:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_16.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요번은 꽤 간단해요. E_3은 Y_3의 함수에요. 그래서 Y_3에 대해 E_3을 미분하고, Y_3을 V에 대해 미분해요. 여기서는 너무 복잡한 일은 없어요.\n\nW 가중 행렬에 대해:\n\n![이미지](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_17.png)\n\n이제 조금 멋진 것들이 나타나네요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 식에서 첫 번째 용어는 비교적 간단합니다. E_3는 Y_3의 함수이며, Y_3는 h_3의 함수이며, h_3는 W의 요소입니다. V 행렬에서 보았던 것과 동일한 프로세스입니다.\n\n그러나 h_2와 h_1에 대한 이전 단계에서도 행렬 W가 사용되었으므로 그 이전 단계에 대한 미분을 고려해야 합니다.\n\nRNN에서 상태 h_3가 이전 상태에 종속되므로 W의 영향을 모든 시간 단계에 걸쳐 고려해야 합니다.\n\nU 가중치 행렬에 대해:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_18.png)\n\nU 행렬에 대한 오류는 W에 대한 것과 매우 유사하며, 다른 점은 숨겨진 상태 h를 U로 미분한다는 점입니다.\n\n숨겨진 상태는 이전 숨겨진 상태와 새 입력의 복합 함수입니다.\n\n## 일반화된 공식\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nBPTT는 다음과 같이 일반화될 수 있습니다:\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_19.png)\n\n여기서 J는 RNN 내의 임의의 가중치 행렬이며, U, W 또는 V가 될 수 있습니다.\n\nRNN의 총 오차(손실)는 각 시간 스텝에서의 오차인 E_t의 합입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-18-BackpropagationThroughTimeHowRNNsLearn_20.png](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_20.png)\n\nAnd, that’s pretty much all there is to training an RNN! However, there is one problem ...\n\n# Exploding \u0026 Vanishing Gradient Problem\n\n## Overview\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRNN의 중요한 문제 중 하나는 사라지는 그래디언트와 폭발하는 그래디언트 문제입니다. 이 문제는 BPTT를 수행할 때 네트워크를 T번 시간 단계만큼 펼치기 때문에 발생합니다. 이로 인해 네트워크는 사실상 T개의 레이어를 갖게 됩니다.\n\n흔히 사용되는 타임스탬프의 수가 많기 때문에, 펼쳐진 네트워크는 보통 아주 깊어집니다. 그래디언트가 역방향으로 전파됨에 따라 지수적으로 증가하거나 감소할 수 있습니다.\n\n이것은 활성화 함수가 일반적으로 tanh 또는 sigmoid인 경우에 발생합니다. 이러한 함수들은 입력을 작은 출력 범위로 압축시킵니다: sigmoid는 0에서 1, tanh는 -1에서 1까지입니다.\n\n이러한 함수의 미분 값은 큰 절댓값 입력에 대해 작고 거의 0에 가깝습니다. RNN과 같이 깊은 네트워크에서 이러한 미분 값이 연쇄 법칙에 사용될 때, 위에서 보았듯이 많은 작은 숫자들이 곱해지게 됩니다. 이는 매우 작은 숫자가 되어 초기 레이어에서 거의 0에 가까운 그래디언트를 생성하게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 수학적 추론\n\n이전 내용을 참고하면, 이전 시간 단계의 다른 숨은 상태에 대한 숨은 상태의 편미분을 계산하는 많은 경우가 있습니다.\n\n![image](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_21.png)\n\n그런 다음 우리의 숨은 상태(시간 단계) 수에 따라 여러 번 곱해집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 Markdown 형식의 텍스트입니다.\n\n![이미지1](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_22.png)\n\n여기에 일어나는 일입니다:\n\n![이미지2](/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_23.png)\n\n이제 RNN이 경험하는 기울기 소실과 폭주에 대한 이유를 이해할 수 있습니다. 순차 길이에 따라 기울기가 지수 함수적으로 소실되는 것은 숨은 상태의 편도함수를 반복적으로 곱하기 때문인 체인 규칙 효과입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 문제\n\n만약 그래디언트가 소멸한다면, RNN은 매우 나쁜 장기 기억력을 가지고 있어 과거에서 많은 것을 배울 수 없게 됩니다. 이는 정말 좋지 않은 상황인데, RNN은 순차 데이터를 다룰 수 있도록 메모리를 갖추도록 설계되었기 때문입니다.\n\n이로 인해 그래디언트가 매우 작아지게 되는데, 이는 가중치가 업데이트되는 값도 작아진다는 것을 의미합니다. 따라서 네트워크가 훈련하는 데 시간이 오래 걸리고 더 많은 컴퓨팅 자원을 사용하게 됩니다.\n\n물론, 많은 현명한 사람들이 이 문제를 해결하기 위한 방법을 개발해 왔는데, 다음 글에서 그에 대해 논의할 예정입니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이전 게시물에서는 폭망 경사 문제와 이를 극복하는 데 사용되는 도구에 대해 더 많이 읽을 수 있어요.\n\n# 요약 및 추가적인 생각\n\nRNN은 일반 피드포워드 신경망과 비슷한 알고리즘을 사용하여 학습합니다. 시간을 통한 역전파는 일반적인 역전파와 매우 유사하지만, 각 오류와 가중치 행렬에 대해 해당 가중치 행렬이 사용된 모든 과거의 시간을 고려해야 합니다. 이로 인해 불안정한 경사를 초래할 수 있습니다. RNN은 종종 매우 깊은 구조를 가지므로 도함수를 여러 번 곱하게 되어 초기 레이어에 도달했을 때 그 값을 증가시키거나 감소시킬 수 있습니다.\n\n# 저와 소통해요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- LinkedIn, X(Twitter) 또는 Instagram\n- 기술적인 데이터 과학과 머신 러닝 개념을 배울 수 있는 내 YouTube 채널!\n\n## 참고 및 더 읽을거리\n\n- Stanford RNN CheatSheet\n- Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. Aurélien Géron. 2019년 9월. 출판사: O’Reilly Media, Inc. ISBN: 9781492032649.\n","ogImage":{"url":"/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png"},"coverImage":"/assets/img/2024-05-18-BackpropagationThroughTimeHowRNNsLearn_0.png","tag":["Tech"],"readingTime":14},{"title":"LSTM 시계열 예측에서 흔히 발생하는 오류를 수정하는 방법","description":"","date":"2024-05-18 19:35","slug":"2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting","content":"\r\nLSTM을 시계열 예측에 사용할 때, 사람들은 흔히 범할 수 있는 함정에 빠지곤 합니다. 이를 설명하기 위해서는 회귀자와 예측자의 작동 방식을 살펴볼 필요가 있습니다. 예측 알고리즘은 시계열 데이터를 다루는 방법을 아래와 같이 보여줍니다:\r\n\r\n![How a forecasting algorithm works](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png)\r\n\r\n한편, 회귀 문제는 다음과 같이 보일 것입니다:\r\n\r\n![How a regression problem looks](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_1.png)\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\nLSTM이 회귀기이므로 시계열을 회귀 문제로 변환해야 합니다. 이를 수행하는 여러 방법이 있지만, 이 섹션에서는 창(Window) 및 다중 단계(Multi-Step) 방법에 대해 설명하고, 어떻게 작동하는지와 특히 이를 활용할 때 발생할 수 있는 일반적인 실수를 피하는 방법에 대해 논의할 것입니다.\r\n\r\n창 방법(Window Method)에서, 시계열은 이전 각 시간 단계의 값과 결합되어 창이라고 불리는 가상 특성으로 되어 있습니다. 여기서 창 크기가 3인 창이 있습니다:\r\n\r\n![창 방법 이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_2.png)\r\n\r\n다음 함수는 단일 시계열에서 창 방법 데이터 세트를 생성합니다. 사용자는 이전 값의 수(보통 look back이라고 함)를 선택해야 합니다. 결과 데이터 세트에는 대각선 반복이 있으며, look-back 값에 따라 샘플의 수가 달라집니다:\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n```js\r\ndef window(sequences, look_back):\r\n    X, y = [], []\r\n    for i in range(len(sequences)-look_back-1):\r\n        x = sequences[i:(i+look_back)]\r\n        X.append(x)\r\n        y.append(sequences[i + look_back])\r\n    return np.array(X), np.array(y)\r\n```\r\n\r\n이제 결과를 살펴보겠습니다. 모델을 훈련한 후에는 테스트 세트에서 테스트됩니다. 다양한 소스와 튜토리얼에서는 비슷한 방법을 사용하여 결과를 컴파일하는 것을 제안했습니다. 그러나 나중에 설명할 것처럼 이 방법은 신빙성이 없습니다. 그럼 지금은 코드와 결과가 어떻게 보이는지 살펴보겠습니다:\r\n\r\n```js\r\nlook_back = 3\r\nX, y = window(ts_data, look_back)\r\n\r\n# 훈련-테스트 분할\r\ntrain_ratio = 0.8\r\ntrain_size = int(train_ratio * len(ts_data))\r\nX_train, X_test = X[:train_size-look_back], X[train_size-look_back:]\r\ny_train, y_test = y[:train_size-look_back], y[train_size-look_back:]\r\n\r\n# LSTM 모델 생성 및 훈련\r\nmodel = Sequential()\r\nmodel.add(LSTM(units=72, activation='tanh', input_shape=(look_back, 1)))\r\nmodel.add(Dense(1))\r\nmodel.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mape'])\r\n\r\nmodel.fit(x=X_train, y=y_train, epochs=500, batch_size=18, verbose=2)\r\n\r\n# 예측 생성\r\nforecasts = model.predict(X_test)\r\nlstm_fits = model.predict(X_train)\r\n\r\n# 메트릭스 계산\r\nmape = mean_absolute_percentage_error(y_test, forecasts)\r\nr2 = r2_score(y_train, lstm_fits)\r\n\r\n# 날짜 초기화\r\ndate_range = pd.date_range(start='1990-01-01', end='2023-09-30', freq='M')\r\n\r\n# 맞춤 값에 원래 시계열과 맞추기 위한 비어있는 값 추가\r\nfits = np.full(train_size, np.nan)\r\nfor i in range(train_size-look_back):\r\n    fits[i+look_back] = lstm_fits[i]\r\n\r\n# 실제값, 맞춤값, 예측값 플롯\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[:train_size], fits, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], forecasts, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\nOne Step Forward Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {r2*100:.2f}%\\nMAPE = {mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_3.png\" /\u003e\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n문제: 결과는 훌륭해 보입니다. 그러나 샘플 테스트 세트를 살펴보면 특이한 결함이 보입니다:\r\n\r\n![이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_4.png)\r\n\r\n예를 들어 y9를 생성하는 데에는 y8이 입력으로 사용되었습니다. 훈련에는 사용되지 않았지만 미래 값을 포함하는 것은 이상합니다. 왜냐하면 우리는 미래의 시점을 예측하고 있기 때문입니다.\r\n\r\n해결책: 직접적으로 이전 값을 예측 값으로 대체하는 반복적 테스트 세트를 사용하면 이 문제를 해결할 수 있습니다. 이러한 배치 방식에서 모델은 자체 예측에 기반을 둔다. 일반적인 예측 알고리즘과 유사합니다.\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n아래 루프에서 다음을 수행합니다:\r\n\r\n```js\r\n# 반복적인 예측 및 대체\r\nfor i in range(len(X_test)):\r\n    forecasts[i] = model.predict(X_test[i].reshape(1, look_back, 1))\r\n    if i != len(X_test)-1:\r\n        X_test[i+1,look_back-1] = forecasts[i]\r\n        for j in range(look_back-1):\r\n            X_test[i+1,j] = X_test[i,j+1]\r\n```\r\n\r\n결과는 완벽하지는 않지만 적어도 정허하다고 할 수 있습니다:\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_6.png\" /\u003e\r\n\r\n다중 단계 방법은 창 방법과 유사하지만 더 많은 대상 단계를 갖습니다. 다음은 두 개의 전방 단계의 샘플입니다:\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_7.png\" /\u003e\r\n\r\n사실, 이 방법에서 사용자는 n_steps_in과 n_steps_out을 선택해야 합니다. 다음 코드는 단순 시계열을 다중 단계 LSTM 훈련을 위해 준비된 데이터 세트로 변환합니다:\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n```js\r\n# 단변량 시퀀스를 다단계로 샘플링하기\r\ndef split_sequences(sequences, n_steps_in, n_steps_out):\r\n X, y = list(), list()\r\n for i in range(len(sequences)):\r\n     # 해당 패턴의 끝을 찾음\r\n     end_ix = i + n_steps_in\r\n     out_end_ix = end_ix + n_steps_out\r\n     # 시퀀스를 벗어나는지 확인\r\n     if out_end_ix \u003e len(sequences):\r\n         break\r\n     # 패턴의 입력 및 출력 부분 수집\r\n     seq_x, seq_y = sequences[i:end_ix], sequences[end_ix:out_end_ix]\r\n     X.append(seq_x)\r\n     y.append(seq_y)\r\n return np.array(X), np.array(y)\r\n```\r\n\r\n이제, 특성 뿐만 아니라 타겟도 대각선 반복을 가지고 있어 시계열과 비교하려면 그들을 평균화하거나 예측 중 하나를 선택해야 합니다. 아래 코드에서는 첫 번째, 마지막 및 평균 예측의 결과가 생성되며, 그에 이어 플롯이 제시됩니다. 여기서 첫 번째 예측은 한 달 전 예측을 의미하며, 마지막 예측은 12개월 전 예측을 의미합니다.\r\n\r\n```js\r\nn_steps_in = 12\r\nn_steps_out = 12\r\n\r\nX, y = split_sequences(ts_data, n_steps_in, n_steps_out)\r\nX = X.reshape(X.shape[0], X.shape[1], 1)\r\ny = y.reshape(y.shape[0], y.shape[1], 1)\r\n\r\n# 훈련 및 테스트 세트 분리\r\ntrain_ratio = 0.8\r\ntrain_size = int(train_ratio * len(ts_data))\r\nX_train, X_test = X[:train_size-n_steps_in-n_steps_out+1], X[train_size-n_steps_in-n_steps_out+1:]\r\ny_train = y[:train_size-n_steps_in-n_steps_out+1]\r\ny_test = ts_data[train_size:]\r\n\r\n# LSTM 모델 생성 및 훈련\r\nmodel = Sequential()\r\nmodel.add(LSTM(units=72, activation='tanh', input_shape=(n_steps_in, 1)))\r\nmodel.add(Dense(units=n_steps_out))\r\nmodel.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mape'])\r\n\r\nmodel.fit(x=X_train, y=y_train, epochs=500, batch_size=18, verbose=2)\r\n\r\n# 예측 생성\r\nlstm_predictions = model.predict(X_test)\r\nlstm_fitted = model.predict(X_train)\r\n\r\nforecasts = [np.diag(np.fliplr(lstm_predictions), i).mean() for i in range(0, -lstm_predictions.shape[0], -1)]\r\nfits = [np.diag(np.fliplr(lstm_fitted), i).mean() for i in range(lstm_fitted.shape[1]+n_steps_in - 1, -lstm_fitted.shape[0], -1)]\r\nforecasts1 = lstm_predictions[n_steps_out-1:,0]\r\nfits1 = model.predict(X)[:train_size-n_steps_in,0]\r\nforecasts12 = lstm_predictions[:,n_steps_out-1]\r\nfits12 = lstm_fitted[:,n_steps_out-1]\r\n\r\n# Metric\r\nav_mape = mean_absolute_percentage_error(y_test, forecasts)\r\nav_r2 = r2_score(ts_data[n_steps_in:train_size], fits[n_steps_in:])\r\none_mape = mean_absolute_percentage_error(y_test[:-n_steps_out+1], forecasts1)\r\none_r2 = r2_score(ts_data[n_steps_in:train_size], fits1)\r\ntwelve_mape = mean_absolute_percentage_error(y_test, forecasts12)\r\ntwelve_r2 = r2_score(ts_data[n_steps_in+n_steps_out-1:train_size], fits12)\r\n\r\ndate_range = pd.date_range(start='1990-01-01', end='2023-09-30', freq='M')\r\n\r\n# 실제, 적합 결과 및 예측을 플롯\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[:train_size], fits, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], forecasts, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n. LSTM 12 Month Average Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {av_r2*100:.2f}%\\nMAPE = {av_mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[n_steps_in:train_size], fits1, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:-n_steps_out+1], forecasts1, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n LSTM 1 Month in advance Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {one_r2*100:.2f}%\\nMAPE = {one_mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[n_steps_in+n_steps_out-1:train_size], fits12, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], forecasts12, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n LSTM 12 Months in advance Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {twelve_r2*100:.2f}%\\nMAPE = {twelve_mape*100:.2f}%', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n\r\n이슈: 창 메서드와 동일한 문제가 여기에도 있습니다:\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n![이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_8.png)\r\n\r\n해상도: 창 법과 비슷한 방법을 사용할 수 있습니다. 그러나 n_steps_out을 test_size와 동일하게 선택할 수도 있습니다. 이렇게 하면 테스트 세트가 하나로 축소됩니다:\r\n\r\n![이미지](/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_9.png)\r\n\r\n다음 함수는 이를 정확히 수행합니다. 이 함수는 시계열, 학습 크기 및 샘플 수를 사용합니다. 이 버전은 다른 예측 알고리즘과 비교할 수 있기 때문에 comparable로 이름 지었습니다:\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n```js\r\ndef split_sequences_comparable(sequences, n_samples, train_size):\r\n # 단계\r\n n_steps_out = len(sequences) - train_size\r\n n_steps_in = train_size - n_steps_out - n_samples + 1\r\n # 끝 세트\r\n X_test = sequences[n_samples + n_steps_out - 1:train_size]\r\n X_forecast = sequences[-n_steps_in:]\r\n X, y = list(), list()\r\n for i in range(n_samples):\r\n     # 이 패턴의 끝을 찾습니다\r\n     end_ix = i + n_steps_in\r\n     out_end_ix = end_ix + n_steps_out\r\n     # 패턴의 입력 및 출력 부분을 수집합니다\r\n     seq_x, seq_y = sequences[i:end_ix], sequences[end_ix:out_end_ix]\r\n     X.append(seq_x)\r\n     y.append(seq_y)\r\n return np.array(X), np.array(y), np.array(X_test), np.array(X_forecast), n_steps_in, n_steps_out\r\n```\r\n\r\n이 함수에서는 단계 수가 이미 고정되었기 때문에 샘플 수와 훈련 크기는 사용자가 선택하도록 하고, 최대 가능한 단계 수를 계산하도록 결정했습니다. 아래는 실행된 코드와 그 결과입니다:\r\n\r\n```js\r\nn_samples = 12\r\ntrain_size = 321\r\nX_train, y_train, X_test, X_forecast, n_steps_in, n_steps_out = split_sequences_comparable(ts_data, n_samples, train_size)\r\ny_test = ts_data[train_size:]\r\n\r\n# Reshaping\r\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\r\nX_test = X_test.reshape(X_test.shape[1], X_test.shape[0], 1)\r\ny_train = y_train.reshape(y_train.shape[0], y_train.shape[1])\r\ny_test = y_test.reshape(y_test.shape[1], y_test.shape[0], 1)\r\n\r\n# LSTM 모델 생성 및 훈련\r\nmodel = Sequential()\r\nmodel.add(LSTM(units=154, activation='tanh', input_shape=(n_steps_in, 1)))\r\nmodel.add(Dense(units=n_steps_out))\r\nmodel.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mape'])\r\n\r\nmodel.fit(x=X_train, y=y_train, epochs=500, batch_size=18, verbose=2)\r\n\r\n# 예측\r\nlstm_predictions = model.predict(X_test)\r\npredictions = lstm_predictions.reshape(lstm_predictions.shape[1])\r\nlstm_fitted = model.predict(X_train)\r\nfits = [np.diag(np.fliplr(lstm_fitted), i).mean() for i in range(lstm_fitted.shape[1]+n_steps_in - 1, -lstm_fitted.shape[0], -1)]\r\n\r\n# 메트릭스\r\nmape = mean_absolute_percentage_error(y_test, predictions)\r\nr2 = r2_score(ts_data[n_steps_in:train_size], fits[n_steps_in:])\r\n\r\n# 실제, 적합 및 예측 플롯\r\nplt.figure(figsize=(10, 6))\r\nplt.plot(date_range, ts_data, label='Actual', color='blue')\r\nplt.plot(date_range[:train_size], fits, label='Fitted', color='green')\r\nplt.plot(date_range[train_size:], predictions, label='Forecast', color='red')\r\nplt.title('FSC - Short - Passengers\\n12 Sample Comparable LSTM Forecast')\r\nplt.xlabel('Date')\r\nplt.ylabel('Passengers')\r\nplt.legend()\r\nplt.text(0.05, 0.05, f'R2 = {r2*100:.2f}%\\nMAPE = {mape*100:.2f}%\\', transform=plt.gca().transAxes, fontsize=12)\r\nplt.grid(True)\r\nplt.show()\r\n```\r\n\r\n\u003cimg src=\"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_10.png\" /\u003e\r\n\r\n\u003c!-- ui-station 사각형 --\u003e\r\n\r\n\u003cins class=\"adsbygoogle\"\r\nstyle=\"display:block\"\r\ndata-ad-client=\"ca-pub-4877378276818686\"\r\ndata-ad-slot=\"7249294152\"\r\ndata-ad-format=\"auto\"\r\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\r\n\r\n\u003cscript\u003e\r\n(adsbygoogle = window.adsbygoogle || []).push({});\r\n\u003c/script\u003e\r\n\r\n지금까지 우리가 얻은 결과는 가장 신뢰할만한 것입니다. 그러나 제가 개발한 혁신적인 방법을 사용하면 더 나은 결과를 얻을 수 있습니다. 이 방법은 나중에 시리즈에서 (순환 방법) 자세히 설명하겠습니다. 먼저 LSTM 네트워크의 하이퍼파라미터를 조정하는 방법에 대해 설명하겠습니다.\r\n\r\nLSTM은 모든 시간 단계를 특성으로 집계하기 때문에 시계열 데이터가 모든 이러한 방법에서 손실됩니다. 나중에 시리즈에서 (인코더/디코더 방법) 시계열 입력의 구조를 유지하는 다른 방법을 사용할 것입니다.\r\n\r\n계속 주목해 주세요!\r\n","ogImage":{"url":"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png"},"coverImage":"/assets/img/2024-05-18-HowtofixacommonmistakeinLSTMtimeseriesforecasting_0.png","tag":["Tech"],"readingTime":15},{"title":"기계 학습을 배우는 용기 사라지는 그래디언트와 폭주하는 그래디언트에 대처하기 파트 2","description":"","date":"2024-05-18 19:28","slug":"2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2","content":"\n\"“Courage to Learn ML”의 새로운 장을 찾아주신 여러분, 환영합니다. 이 시리즈는 복잡한 주제들을 쉽고 재미있게 다루고, 멘토와 학습자 간의 캐주얼 대화처럼 친밀한 분위기를 제공하기 위해 만들어졌습니다. “용기로 방어하다”의 쓰기 스타일에서 영감을 받아 기계 학습에 특히 집중하고 있어요.\n\n이번 시간에는 사라지는 그래디언트와 폭발하는 그래디언트의 어려움을 극복하는 방법에 대해 계속해서 탐구할 거예요. 첫 번째 세그먼트에서 우리는 네트워크 내에서 효율적인 학습을 보장하기 위해 안정적인 그래디언트 유지가 왜 중요한지에 대해 이야기했어요. 불안정한 그래디언트가 우리 네트워크의 심화를 방해할 수 있고 결국 깊은 \"학습\"의 잠재력을 제한할 수 있다는 것을 밝혀냈죠. 이러한 개념을 살려내기 위해 DNN(맛있고 영양가 있는 얹힌 작은 얼음 공장)이라는 소형 아이스크림 공장을 운영하는 비유를 사용하고 수렴한 팩토리 생산 라인을 조율하는 것과 유사한 DNN 훈련을 위한 강력한 전략을 명료하게 보여줬어요.\n\n이제, 두 번째 이야기에서는 각 제안된 솔루션에 대해 더 심층적으로 탐구하며, 아이스크림 공장을 활기차게 만든 것과 같은 명확성과 창의성으로 그들을 살펴볼 거에요. 여기 이번 부분에서 다룰 주제 목록입니다:\n\n- 활성화 함수\n- 가중치 초기화\n- 배치 정규화\n- 실제 적용(개인 경험)\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 활성화 함수\n\n활성화 함수는 우리 \"공장\" 설정의 핵심입니다. 이 함수들은 우리의 DNN 조립 라인 내에서 전방 및 후방 전파를 통해 정보를 전달하는 역할을 합니다. 적절한 활성화 함수를 선택하는 것은 우리의 DNN 조립 라인 및 이에 따라 우리의 DNN 훈련 과정이 원활하게 작동하는 데 중요합니다. 이 부분은 활성화 함수의 장닿과 단점을 간단히 설명하는 것이 아닙니다. 여기서는 다양한 활성화 함수의 생성 배경을 파악하고 종종 간과되는 중요한 질문에 대답하기 위해 Q\u0026A 형식을 사용할 것입니다.\n\n이러한 함수들을 우리 아이스크림 생산 비유의 블렌더로 생각해보세요. 이용 가능한 블렌더 목록을 제공하는 대신, 각각의 혁신과 특정 개선 사항 뒤에 있는 이유를 심층적으로 검토하고 이해하는 데 도움을 드리겠습니다.\n\n## 활성화 함수란 무엇이며, 어떻게 적절한 함수를 선택할 수 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Activation functions](/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png)\n\n활성화 함수는 신경망 모델에 선형 및 비선형 관계를 모두 포착할 수 있는 유연성과 강력함을 부여하는 주요 요소입니다. 로지스틱 회귀와 DNN의 주요 차이점은 이러한 활성화 함수들과 여러 층을 결합하는 데 있습니다. 이들은 NN이 다양한 함수를 근사할 수 있게 합니다. 그러나 이러한 능력은 도전과제와 함께 제공됩니다. 활성화 함수 선택에는 더 주의를 기울여야 합니다. 잘못된 선택은 모델이 특히 역전파 중에 효과적으로 학습하는 것을 막을 수 있습니다.\n\n당신이 당사 DNN 아이스크림 공장의 매니저로 상상해보세요. 당신은 생산 라인을 위해 적절한 활성화 함수(아이스크림 믹서로 생각해보세요)를 섬세하게 선택하고 싶을 것입니다. 즉, 당신의 요구 사항에 가장 적합한 것을 찾는 데 신중을 기울이고 최적의 선택지를 찾아내야 합니다.\n\n따라서 효과적인 활성화 함수를 선택하는 첫 번째 단계는 두 가지 핵심 질문에 대한 대답을 찾는 것입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 활성화 함수의 선택이 소멸 그래디언트나 폭발 그래디언트와 같은 문제에 어떤 영향을 미치나요? 어떤 기준이 좋은 활성화 함수를 정의하나요?\n\n은닉층에서 활성화 함수를 선택할 때, 주로 소멸 그래디언트와 관련된 문제가 발생합니다. 이는 전통적인 시그모이드 활성화 함수(가장 전통적이고 기본적인 모델)로 거슬러 올라갈 수 있습니다. 시그모이드 함수는 입력값을 확률 범위(0부터 1)에 매핑할 수 있는 능력으로 널리 사용되었습니다. 이는 이진 분류 작업에서 특히 유용합니다. 이 능력 덕분에 연구자들은 예측을 분류하기 위한 확률 임계값을 조정하여 모델의 유연성과 성능을 향상할 수 있었습니다.\n\n그러나 이를 은닉층에 적용하는 것은 주로 소멸 그래디언트 문제를 야기했습니다. 이는 주로 두 가지 주요 요인으로 설명할 수 있습니다:\n\n- 순방향 전파 과정에서 시그모이드 함수는 입력을 0과 1 사이의 매우 좁은 범위로 압축합니다. 한 네트워크가 은닉층에서 활성화 함수로 시그모이드만 사용하는 경우, 여러 층을 거칠수록 이 범위가 더욱 좁아지게 됩니다. 이 압축 효과로 인해 출력의 변동성이 감소하고 양수 값으로의 편향이 도입됩니다. 입력 부호에 관계없이 출력은 0과 1 사이에 유지되기 때문에.\n- 역전파 과정에서 시그모이드 함수의 도함수(종모양 곡선)는 0과 0.25 사이의 값을 생성합니다. 이 작은 범위는 입력을 가로지르는 그래디언트가 여러 층을 통과함에 따라 급속하게 감소할 수 있도록 할 수 있습니다. 이것은 앞선 층 그래디언트가 연속된층의 도함수의 곱으로 이루어지기 때문인데, 이러한 낮은 도함수의 복합 곱은 점점 더 작은 그래디언트를 결과로 가져와서 초기 층에서의 효과적인 학습을 방해합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 제약 사항을 극복하기 위해 이상적인 활성화 함수는 다음과 같은 특성을 보여야 합니다:\n\n- 비선형성. 네트워크가 복잡한 패턴을 포착할 수 있도록 함.\n- 비포화. 함수와 그 도함수가 입력 범위를 과도하게 압축하지 않아서 gradient 소멸을 방지해야 함.\n- 중심이 0인 출력. 함수는 양수 및 음수 출력 둘 다를 허용해야 하며, 각 노드 사이의 평균 출력이 특정 방향으로의 편향을 도입하지 않도록 해야 함.\n- 계산 효율성. 함수와 그 도함수가 계산적으로 간단하여 효율적인 학습을 용이하게 해야 함.\n\n## 이러한 기본 특성들을 고려할 때, 인기있는 활성화 함수들이 기본 모델인 Sigmoid를 어떻게 개선하고 뛰어나게 만드는지 알아봅시다.\n\n이 섹션은 거의 모든 현재 활성화 함수에 대한 일반적인 개요를 제공하려고 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 태그를 마크다운 형식으로 변경하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nReLU의 고려 사항 중 하나는 선형 세그먼트 간의 급격한 전환으로 인해 x=0에서 미분 불가능하다는 것입니다. 실제로 PyTorch와 같은 프레임워크는 subgradient 개념을 사용하여 이를 해결하며, 종종 x=0에서 도함수를 0.5 또는 [0, 1] 내의 다른 값으로 설정합니다. 이는 보통 정확한 제로 입력이 드물고 데이터의 변동성 때문에 문제가 되지 않습니다.\n\n그래서, ReLU가 여러분에게 적합한 선택일까요? 많은 연구자들은 그렇다고 말합니다. 이는 그 간결함, 효율성 및 주요 DNN 프레임워크의 지원 덕분입니다. 게다가 https://arxiv.org/abs/2310.04564 같은 최근 연구들이 ReLU의 계속된 중요성을 강조하며, ML 분야에서의 부활과 같은 시대를 맞이한다고 강조하고 있습니다.\n\nLeaky ReLUs는 클래식적인 ReLU에 약간의 변화를 준겳이며, ReLU를 더 자세히 살펴보면 몇 가지 문제점이 드러납니다. 음수 입력에 대한 제로 출력으로 이어지는 것은 'dying ReLU' 문제로 이어지며, 뉴런들이 훈련 중 업데이트되지 않게 됩니다. 또한, ReLU는 양수 값을 선호하여 모델에 방향성 편향을 도입할 수 있습니다. 이러한 단점을 극복하면서 ReLU의 이점을 유지하기 위해, 여러 연구자들이 'leaky' ReLU와 같은 여러 변형을 개발했습니다.\n\nLeaky ReLU는 ReLU의 음수 부분을 수정하여 작고 0이 아닌 기울기를 부여합니다. 이 조정은 음수 입력이 작은 음수 출력을 생성하도록하며, 효과적으로 그 외의 0 출력 영역을 '누출'시킵니다. 이 누출의 기울기는 하이퍼파라미터 알파(α)에 의해 제어되며, 전형적으로 뉴런을 활성 유지와 희소성 사이의 균형을 유지하기 위해 0에 가깝게 설정됩니다. 작은 음수 출력을 허용함으로써, Leaky ReLU는 활성 함수의 출력을 0 주변으로 중앙 집중시키고 뉴런이 비활성화되지 않게 하여 'dying ReLU' 문제에 대응합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 하이퍼파라미터로 α를 도입하면 모델 튜닝에 대한 복잡성이 추가됩니다. 이를 관리하기 위해 원본 Leaky ReLU의 변형이 개발되었습니다:\n\n- Randomized Leaky ReLU (RReLU): 이 버전은 훈련 중에 α를 지정된 범위 내에서 무작위로 지정하고 평가 중에는 고정합니다. 무작위성은 모델을 정규화하고 과적합을 방지하는 데 도움이 될 수 있습니다.\n- Parametric Leaky ReLU (PReLU): PReLU는 훈련 중에 α를 학습할 수 있도록 하며, 활성화 함수를 데이터셋의 특정 요구에 맞게 조정할 수 있습니다. 이는 α를 훈련 데이터에 맞게 조정하여 모델 성능을 향상시킬 수 있지만, 과적합의 위험도 증가시킵니다.\n\nLeaky ReLU를 개선한 Exponential Linear Unit (ELU). Leaky ReLU와 ELU는 음의 값을 허용하여 평균 유닛 활성화를 제로에 가깝게 밀어내고 활성화 함수의 활력을 유지하는 데 도움이 됩니다. Leaky ReLU의 문제점은 이 음의 값의 범위를 조절할 수 없다는 것입니다. 이론적으로 이 값들은 작게 유지하려는 의도에도 불구하고 음의 무한대로 확장될 수 있습니다. ELU는 이를 해결하기 위해 비선형 지수 곡선을 비정상적인 입력에 통합하여 음의 출력 범위를 최대 -𝛼(일반적으로 1로 설정되는 새로운 하이퍼파라미터)로 좁히고 제어합니다. 또한 ELU는 매끄러운 함수입니다. 그 지수 요소 덕분에 음과 양 값 사이에서 매끄러운 전환을 가능하게 하며, 입력 값에 대한 잘 정의된 기울기를 보장하여 기울기 기반 최적화에 유리합니다. 이 기능은 ReLU와 Leaky ReLU에서 보이는 미분 불가능 문제를 해결합니다.\n\nSelf-Normalizing 속성을 갖춘 향상된 ELU인 Scaled Exponential Linear Unit (SELU). SELU는 신경망 내에서 제로 평균 및 단위 분산을 유지하도록 설계된 ELU의 확장된 버전입니다. 양의 순입력의 기울기가 1을 초과하도록 고정 스케일 요인 λ(1보다 큰 값)을 통합함으로써 SELU는 하위 레이어의 기울기가 줄어드는 상황에서 기울기를 증폭하여 딥 뉴럴 네트워크에서 자주 발생하는 소멸하는 기울기 문제를 예방하는 데 특히 유용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nSELU에 대해, 매개변수(α 및 λ)는 고정된 값이며 학습할 수 없으므로 조정해야 할 매개변수가 적어 튜닝 과정이 간소화됩니다. SELU 구현에서 이러한 특정 값들을 찾을 수 있습니다.\n\nSELU는 실제로 활성화 함수 세계에서 정교한 \"믹서\"인데요, 특정 요구 사항이 딸려옵니다. 단방향 또는 순차 네트워크에서 가장 효과적이며 RNN, LSTM 또는 건너뛰기 연결을 갖는 아키텍처에서는 그 설계 때문에 그런만큼 성능이 좋지 않을 수 있습니다.\n\nSELU의 자기 정규화 기능을 위해서는 입력 피처가 표준화되어야 합니다. 평균이 0이고 표준 편차가 1인 것이 중요합니다. 또한, 매 숨겨진 레이어의 가중치는 LeCun 정규 초기화를 사용하여 초기화되어야 합니다. 여기서 가중치는 평균이 0이고 분산이 1/fan_in인 정규 분포에서 샘플링됩니다. \"fan_in\"이란 용어가 익숙하지 않다면, 가중치 초기화에 대한 전용 세션에서 설명하겠습니다.\n\n요약하면 SELU의 자기 정규화가 효과적으로 기능하려면 입력 피처가 정규화되고 네트워크 구조가 끊기지 않는 것을 보장해야 합니다. 이 일관성은 네트워크 전체에서 자기 정규화 효과가 유지되도록 도와주며 누출 없이 계속 유지되도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGELU (Gaussian Error Linear Unit)은 Dropout으로부터 규제 아이디어를 통합한 혁신적인 활성화 함수입니다. 기존 ReLU가 음수 입력에 대해 0을 출력하는 반면, leaky ReLU, ELU 및 SELU는 음수 출력을 허용합니다. 이를 통해 활성화의 평균을 0에 가깝게 이동시켜 편향을 줄이는데 도움을 줍니다. 이는 ReLU와 비슷한 방식으로 편향을 줄이지만 음수 입력을 완전히 0으로 만들지 않고 음의 값을 허용한다는 것을 의미합니다. 그러나 이러한 누출은 \"죽어 가는 ReLU\"의 일부 이점을 잃어버릴 수 있음을 의미합니다. 여기서는 일부 뉴런의 비활성으로 더 sparse하고 일반화된 모델을 얻을 수 있습니다.\n\n죽어 가는 ReLU 및 Dropout의 희소성 이점을 고려할 때, GELU는 여기에 한 발 더 나아간 것입니다. GELU는 0 출력의 특성을 가진 죽어 가는 ReLU를 무작위적인 요소와 결합하여 뉴런이 재활성화될 수 있는 가능성을 열어줍니다. 이 접근은 유익한 희소성을 유지하는 것뿐만 아니라 뉴런 활동을 재도입하여 GELU를 견고한 해결책으로 만듭니다. 이 메커니즘을 완전히 이해하기 위해 GELU의 정의를 자세히 살펴보겠습니다:\n\n![이미지](/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_1.png)\n\nGELU 활성화 함수에서 CDF인 Φ(x) 또는 표준 가우스 누적 분포 함수가 중요한 역할을 합니다. 이 함수는 표준 정규 분포를 따를 때 x보다 작거나 같은 값을 갖는 것으로 나타내는 확률을 나타냅니다. Φ(x)는 음수 입력에 대해 0부터 양수 입력에 대해 1로 매끄럽게 전환되어, 입력의 스케일링을 효과적으로 제어합니다. Dan Hendrycks 외(출처)의 논문에 따르면 뉴런 입력은 배치 정규화를 사용할 때 특히 정규 분포를 따르는 경향이 있어 정규 분포의 사용이 정당화됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해당 함수의 디자인은 x 값이 줄어들수록 입력이 더 자주 \"떨어지도록\" 허용하여 변환을 확률적이면서 입력 값에 의존적으로 만듭니다. 이 메커니즘은 흔히 사용되는 직선 함수인 f(x) = x를 더 부드럽게 만들어 ReLU 함수와 유사한 형태를 유지하며, 조각별 선형 함수에서 발생하는 갑작스러운 변화를 피합니다. GELU의 가장 중요한 특징 중 하나는 뉴런을 완전히 비활성화할 수 있다는 것으로, 이를 통해 입력 값의 변화에 따라 다시 활성화될 수 있습니다. 이러한 확률적 성질은 입력 값에 의존하지만 완전히 무작위적이지 않아 뉴런이 다시 활성화될 기회를 제공합니다.\n\n아래는 GELU가 ReLU보다 두드러지는 이점이라고 요약할 수 있습니다. GELU는 어떤 입력 값이 양수인지 음수인지에 관계없이 전체 입력 값 범위를 고려합니다. Φ(x) 값이 감소함에 따라 GELU 함수의 출력이 0에 가까워지는 확률이 증가하여 뉴런을 부드럽게 \"떨어뜨리게\" 됩니다. 이 방법은 전형적인 드롭아웃 방식보다 더 정교하며, 무작위적으로 하는 것이 아니라 데이터에 따라 뉴런의 비활성화를 결정하도록 되어 있습니다. 이 방식은 매우 매력적으로 느껴지며, 마치 고급 디저트에 부드러운 크림을 추가하여 조금 더 향상된 미각을 경험하는 것과 같다고 생각합니다.\n\nGELU는 GPT-3, BERT 및 다른 Transformers와 같은 모델에서 효율적이며 언어 처리 작업에서 강력한 성능을 보여 인기 있는 활성화 함수가 되었습니다. 확률적 성질 때문에 계산 위주이지만, 표준 가우스 누적 분포인 Φ(x)의 곡선은 시그모이드와 tanh 함수와 유사합니다. 흥미로운 점은 GELU가 tanh를 사용하거나 x(1.702\\*x) 공식을 사용하여 근사할 수 있다는 것입니다. 이러한 단순화 가능성에도 불구하고, PyTorch의 GELU 구현은 그러한 근사가 종종 불필요할 정도로 빠르게 진행됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n더 깊이 들어가기 전에 먼저 정리해보자면,\n\n## ReLU를 검토하고 이로부터 영감받은 다른 활성화 함수가 무엇인지를 살펴보면 어떤 활성화 함수가 좋을지 정확히 알아볼까요?\n\nGünter Klambauer 등의 논문에서 SELU가 소개된 적이 있습니다. 여기서는 효과적인 활성화 함수의 중요한 특성을 강조했는데요.\n\n- 범위: 네트워크 전체의 평균 활성화 수준을 조절하는 데 도움이 되기 위해 음수와 양수 값을 출력해야 합니다.\n- 포화 영역: 도함수가 제로에 가까워지는 영역으로, 하위층의 너무 높은 분산을 안정화하는 데 도움을 줍니다.\n- 증폭 슬로프: 하위 층에서 너무 낮은 분산을 높이기 위해 중요한 기울기가 있어야 합니다.\n- 연속성: 연속적인 곡선은 분산의 변화를 안정화하고 증가시키는 효과를 균형있게 유지하는 고정점을 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한 \"이상적인\" 활성화 함수에 대한 두 가지 추가 기준을 제안하고 싶습니다:\n\n- 비선형성: 이것은 명백하고 필수적입니다. 왜냐하면 선형 함수는 복잡한 패턴을 효과적으로 모델링할 수 없기 때문입니다.\n- 동적 출력: 출력이 제로이고 입력 데이터에 따라 출력을 변경할 수 있는 능력은 동적 뉴런 활성화와 비활성화를 가능하게 합니다. 이렇게 하면 네트워크가 변화하는 데이터 조건에 효율적으로 적응할 수 있습니다.\n\n## 활성화 함수가 음수를 출력하는 이유에 대해 더 직관적인 설명을 부탁드려도 될까요?\n\n활성화 함수를 입력 데이터를 변환하는 블렌더로 생각해 보세요. 일부 재료를 선호하는 블렌더처럼, 활성화 함수는 그들의 본질적인 특성에 따라 편향을 도입할 수 있습니다. 예를 들어, 시그모이드 및 ReLU 함수는 일반적으로 입력과 관계없이 비음수 출력만 나타냅니다. 이는 블렌더가 어떤 재료를 넣어도 항상 동일한 맛을 내는 것과 유사합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_3.png)\n\n이 편향을 최소화하려면 부정적이고 긍정적인 값을 출력할 수 있는 활성화 함수를 가지는 것이 좋습니다. 기본적으로 우리는 중심이 제로인 출력을 목표로 합니다. 활성화 함수의 출력을 나타내는 놀이터를 상상해보세요. Sigmoid나 ReLU와 같은 함수로는, 이 놀이터는 부정적인 입력을 무시하거나 제로로 바꾸기 때문에 긍정적인 쪽으로 크게 기울어져 있습니다. Leaky ReLU는 음수 입력이 약간 음수 출력을 생성하도록 허용함으로써 이 놀이터를 균형잡게 시도하지만, 부정적 기울기의 선형 및 상수적 성격 때문에 조정이 미미합니다. 반면에 Exponential Linear Unit (ELU)은 지수 구성 요소로 음수 측면에 더 다이나믹한 밀어넣기를 제공하여, 더 균형 잡힌 상태에 가까워질 수 있도록 돕습니다. 이 균형은 긍정적 및 부정적 업데이트가 훈련에 기여하도록 보장함으로써 신경망에서 건강한 그레이디언트 플로우와 효율적인 학습을 유지하는 데 중요합니다, 단방향 업데이트의 제한을 피하기 위해.\n\n## ReLU와 유사하게 양수 입력을 제로화하는 활성화 함수를 생성할 수 있을까요, min(0, x)를 사용하여 양수 입력을 제로화하는 함수를 선호하는 이유는 무엇인가요?\n\n확실히, ReLU의 양수 값을 제로화하고 음수 값을 그대로 통과시키는 버전을 설계할 수 있습니다. 이것은 기술적으로 실행 가능한데, 중요한 점은 여기서 값의 부호가 아니라 네트워크에 비선형성을 도입하는 것입니다. 이 활성화 함수들이 일반적으로 출력 레이어가 아닌 숨겨진 레이어에서 사용된다는 것을 기억하는 것이 중요합니다. 즉, 이 네트워크 내의 이러한 활성화 함수의 존재는 최종 출력의 부호에 영향을 미치지 않고 이 레이어의 특성에 의해 직접적으로 영향을 받지 않더라도 최종 출력이 여전히 양수와 음수 모두가 될 수 있다는 것을 의미합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n무슨 상황에서든, 네트워크의 가중치와 편향은 출력의 필요한 부호에 맞게 조정될 수 있습니다. 예를 들어, 전통적인 ReLU에서 출력이 1이고 다음 레이어의 가중치가 1이면 출력은 여전히 1로 유지됩니다. 마찬가지로, 제안된 ReLU 변형이 -1을 출력하고 가중치가 -1이면 결과는 여전히 1이 됩니다. 본질적으로, 우리는 출력의 부호보다는 크기에 더 신경을 씁니다.\n\n따라서, ReLU가 부정적인 쪽에서 포화되는 것은 양수 쪽에서 포화되는 것과 근본적으로 다르지 않습니다. 그러나 우리가 영 중심 활성화 함수를 중요시하는 이유는 양수 또는 음수 값에 대한 내재적인 선호도를 방지하여 모델에서 불필요한 편향을 피하기 위한 것입니다. 이 균형은 네트워크 전체에 걸쳐 중립성과 효과적인 학습을 유지하는 데 도움이 됩니다.\n\n## Leaky ReLU와 같은 함수들은 출력을 영 중심 주변에 유지하기 위해 음수값을 출력할 필요가 있습니다. 그렇다면 ELU, SELU, GELU는 왜 음수 입력에 포화되도록 특별히 설계되었을까요?\n\n이를 이해하기 위해, ReLU 뒤에 있는 생물학적 영감을 살펴볼 수 있습니다. ReLU는 생물학적 뉴런을 모방하는데, 이들은 한계값을 가지고 있습니다. 이 한계값을 초과하는 입력은 뉴런을 활성화시키고, 그 이하는 그렇지 않습니다. 활성 및 비활성 상태 간 전환 가능성은 신경 기능에서 중요합니다. ELU, SELU, GELU와 같은 변형을 고려할 때, 이들의 설계가 두 가지 다른 필요에 부합함을 알 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 긍정적 영역: 임계값을 초과하는 신호가 전달될 때 전달되는 원하는 신호를 전송하는 것을 의미합니다.\n- 부정적 영역: 원치 않는 신호를 최소화하거나 걸러내며 대형 부정적 값의 영향을 완화하여 누수하는 게이트처럼 작동합니다.\n\n이러한 기능은 입력에 대한 게이트 역할을 하며, 뉴런의 출력에 영향을 미쳐야 하는 사항과 그렇지 말아야 하는 사항을 관리합니다. 예를 들어, SELU는 다음 두 가지 측면을 구분하여 활용합니다:\n\n- 긍정적 영역: 스케일링 인자 λ (1보다 큼)는 신호를 전달하지 않을 뿐만 아니라 약간 증폭시킵니다. 역전파 중 이 영역의 도함수는 일정하게 유지됩니다 (약 1.0507), 작지만 유용한 기울기를 증가하여 사그라들기 기울기를 희석시키기 위해 사용됩니다.\n- 부정적 영역: 도함수는 0과 λα 사이의 값 사이를 이동합니다 (일반적인 값은 λ ≈ 1.0507 그리고 α ≈ 1.6733), 약 1.7583에 달하는 최대 도함수를 이끌어 냅니다. 여기서 함수는 거의 0에 가깝게 접근하며, 지나치게 큰 기울기를 줄여 폭발 문제를 해결하기 위해 돕습니다.\n\n이 설계는 이러한 활성화 함수들이 유용한 신호를 증가시키면서 잠재적으로 유해한 극단을 억제해 안정적인 학습 환경을 제공할 수 있도록 균형을 맞춘다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n활성화 함수가 게이트로 작용하는 개념은 새로운 아이디어가 아닙니다. 시그모이드 함수가 무엇을 기억하거나 업데이트하거나 잊어버릴지를 결정하는 LSTM과 같은 구조에서 강력한 전례가 있습니다. 이 게이팅 개념은 ReLU의 변형이 특정한 방식으로 설계된 이유를 이해하는 데 도움이 됩니다. 예를 들어 GELU는 표준 정규 분포의 누적 분포 함수(CDF)에서 유도된 스케일 계수를 사용하는 동적 게이트 역할을 합니다. 이 스케일링을 통해 입력의 작은 부분이 0에 가까울 때 통과되도록 하고, 더 큰 양수 값은 대부분 변경되지 않고 통과할 수 있게 합니다. 입력이 다음 레이어에 얼마나 많은 영향을 미치는지 제어함으로써, GELU는 정보 흐름의 효과적인 관리를 용이하게 해주며, 특히 transformer와 같은 구조에서 유용합니다.\n\n언급된 ELU, SELU, 그리고 GELU 모두 음수 측면을 부드럽게 만듭니다. 음수 입력의 부드러운 포화는 큰 음수 값의 영향을 완화하는 것뿐만 아니라, 네트워크가 입력 데이터의 변동에 덜 민감해지도록 만듭니다. 이를 통해 더 안정적인 특징 표현이 이뤄지게 됩니다.\n\n요약하면, 양수인지 음수인지에 상관없이 포화 영역이 구체적으로 중요하지 않습니다. 왜냐하면 이러한 활성화 함수들은 네트워크의 중간 레이어에서 작동하며, 여기서 가중치와 편향이 적절하게 조정될 수 있습니다. 하지만, 한쪽이 신호를 변경하지 않고 전달하거나 심지어 증폭할 수 있도록 허용하는 이러한 함수의 설계가 중요합니다. 이러한 배치는 신호를 조직화하고 효과적인 역전파를 용이하게 도와 전체 네트워크의 성능과 학습 안정성을 향상시킵니다.\n\n## 언제 각 활성화 함수를 선택해야 할까요? 왜 ReLU가 여전히 실무에서 가장 인기 있는 활성화 함수인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n올바른 활성화 함수를 선택하는 데는 계산 리소스, 네트워크 아키텍처의 특정 요구 사항 및 이전 모델로부터의 경험적 증거 등 여러 요소가 관련됩니다.\n\n- 계산 리소스: 충분한 계산 리소스가 있다면 교차 검증을 사용하여 다양한 활성화 함수를 실험해 보는 것이 유익할 수 있습니다. 이를 통해 모델과 데이터셋에 특화된 활성화 함수를 만들 수 있습니다. SELU를 사용할 때 배치 정규화가 필요 없는 경우가 대부분이며, 이는 다른 함수들과 달리 배치 정규화가 필요하지 않아 아키텍처를 간단하게 만들어 줍니다.\n- 경험적 증거: 특정 응용 프로그램에는 특정 함수가 표준으로 사용될 수 있습니다. 예를 들어, 트랜스포머 모델을 훈련시키기 위해 GELU를 선호하는 경우가 많은데, 이는 해당 아키텍처에서 효과적이기 때문입니다. SELU는 자기 정규화 특성과 조절해야 할 하이퍼파라미터가 없다는 장점으로, 훈련 안정성이 핵심인 깊은 네트워크에 특히 유용합니다.\n- 계산 효율성과 간결성: 계산 효율성과 간결성이 중요한 경우, ReLU 및 PReLU, ELU와 같은 변형들이 우수한 선택지입니다. 이들은 매개변수 조정의 필요성을 피하고 모델의 희소성 및 일반화를 지원하여 과적합을 줄이는 데 도움을 줍니다.\n\n더 정교한 함수가 등장했지만, ReLU는 여전히 간결하고 효율적이어서 매우 인기가 있습니다. 구현이 간단하고 이해하기 쉬우며 계산을 복잡하게 하지 않고 비선형성을 소개하는 명확한 방법을 제공합니다. 음수 부분을 제로 처리하는 함수의 능력으로 계산을 단순화하고 계산 속도를 향상시키므로, 특히 대규모 네트워크에서 매우 유리합니다.\n\nReLU의 설계는 음수 활성화를 제로처리하여 모델의 희소성을 기본적으로 증가시키며, 이는 일반화를 개선할 수 있습니다 — 훈련 중심의 과적합이 심각한 문제인 딥 뉴럴 네트워크에서 매우 중요한 요소입니다. 게다가 ReLU는 추가적인 하이퍼파라미터가 필요 없으며, PReLU나 ELU와 같은 함수와 달리 모델 훈련에 추가 복잡성을 도입하지 않습니다. 또한 ReLU가 널리 채택된 상태이므로, 많은 머신러닝 프레임워크와 라이브러리가 이를 위해 특화된 최적화를 제공하여, 많은 개발자에게 실용적인 선택이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요약하자면, 새로운 활성화 함수는 특정 시나리오에 특정 이점을 제공하지만, ReLU의 간단함, 효율성, 효과적인 측면의 균형은 많은 응용 프로그램에서 선호하는 선택지가 되고 있습니다. 어떤 활성화 함수를 선택한다 하더라도, 그 특성을 철저히 이해하는 것이 중요하며 모델의 요구 사항과 일치하고 모델 훈련 중 문제 해결을 용이하게 하는 데 필수적입니다.\n\n# 가중치 초기화\n\n그래, 우리는 기욁할 기울기를 안정화시킬 완벽한 활성화 함수를 찾으려는 것을 그만두고, 가중치를 효율적으로 초기화하여 우리의 신경망을 올바르게 설정하는 다른 중요한 측면에 초점을 맞출 시간입니다.\n\n가중치 초기화에 대한 가장 인기 있는 방법들에 대해 자세히 살펴보기 전에, 기본적인 질문을 하나 다루어 보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 가중치 초기화는 왜 중요하며 불안정한 그래디언트를 완화하는 데 어떻게 도움이 될까요?\n\n적절한 가중치 초기화는 모델 전체를 따라 정확하게 그래디언트가 흐를 수 있도록 보장합니다. 이는 아이스크림 공장에서 반제품이 전달되는 방식과 유사합니다. 초기 기계 설정이 올바른 것만 중요한 것이 아니라 각 부서가 효율적으로 작동하는 것도 중요합니다.\n\n가중치 초기화는 네트워크를 통해 전진 및 역방향으로 정보가 안정적으로 흐를 수 있도록 목표를 합니다. 너무 크거나 너무 작은 가중치는 문제를 일으킬 수 있습니다. 지나치게 큰 가중치는 전진 패스 중 출력을 지나치게 증가시켜 예측을 과대추정하게 할 수 있습니다. 반면 아주 작은 가중치는 출력을 지나치게 줄일 수 있습니다. 이러한 가중치의 크기는 역전파 중에 중요해집니다. 가중치가 너무 크면 그래디언트가 폭발할 수 있고, 너무 작으면 그래디언트가 사라질 수 있습니다. 이를 이해하여 우리는 출력 및 그래디언트를 무효화하는 영옵션 (zero)과 지나치게 높은 값과 같은 극단적인 초기화를 피합니다. 이 균형 잡힌 접근법은 네트워크의 효과성을 유지하고 불안정한 그래디언트와 관련된 문제를 방지하는 데 도움이 됩니다.\n\n## 가중치를 초기화하는 좋은 방법은 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가장 중요한 것은 최적 가중치 초기화는 이미 학습된 가중치를 사용하는 것이 가장 좋습니다. 이미 일부 학습을 거친 가중치를 얻을 수 있다면 손실을 최소화하는 방향으로 진행 중인 이 가중치를 계속 사용하는 것이 이상적입니다.\n\n그러나 처음부터 시작하는 경우 가중치를 초기화하는 방법을 신중하게 고려해야 합니다, 특히 불안정한 기울기를 방지하기 위해. 좋은 가중치 초기화에는 다음을 목표로 하는 것이 중요합니다:\n\n- 극단적인 값은 피해야 합니다. 이전에 논의했던 대로, 가중치는 너무 크거나 작지 않고 0도 아니어야 합니다. 적절히 조절된 가중치는 네트워크 훈련의 전진 및 역진행 중 안정성을 유지하는 데 도움이 됩니다.\n- 대칭을 깨야 합니다. 가중치가 다양한 행동을 하도록 하는 것은 매우 중요합니다. 이렇게 하면 뉴런이 서로 거울에 비친 행동을 하지 않고 동일한 특성만 학습하게 되는 것을 방지합니다. 이러한 차별이 없으면 네트워크가 복잡한 패턴을 모델링하는 능력이 심각하게 제한될 수 있습니다. 각각의 다른 초기 가중치가 각 뉴런이 데이터의 다른 측면을 학습하기 시작하도록 도와줍니다. 이는 아이스크림 공장의 다양한 종류의 생산 라인을 가지고 다양한 맛을 생산할 수 있는 범위를 확대하는 것과 비슷합니다.\n- 손실 표면에서 유리한 위치에 가중치를 배치해야 합니다. 초기 가중치는 모델이 글로벌 최솟값으로 향하는 여정을 더 쉽게 만들기 위해 손실 표면에서 양호한 시작 위치에 모델을 위치시켜야 합니다. 손실 랜드스케이프가 어떻게 보이는지 명확한 그림을 가지고 있지 않기 때문에 가중치 초기화에 약간의 무작위성을 도입하는 것이 유익할 수 있습니다.\n\n모든 가중치를 0으로 설정하는 것이 문제가 되는 이유입니다. 이는 모든 뉴런이 동일하게 행동하고 동일한 속도로 학습하기 때문에 대칭 문제를 발생시킵니다. 다양한 패턴을 효과적으로 포착하지 못하게되는 네트워크의 능력을 제한합니다. ReLU 및 그 변형과 함께 0 가중치는 출력이 0이 되어 학습이 멈추고 모든 뉴런이 비활성화되는 결과를 초래합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 모든 가중치를 작은 무작위 숫자로 초기화해야 하지 않을까요?\n\n가중치를 초기화할 때 작은 무작위 숫자를 사용하는 것은 도움이 될 수 있지만, 종종 충분한 제어가 없을 수 있습니다. 무작위로 할당된 가중치는 너무 작을 수 있어서 기욹기 소멸 문제로 이어질 수 있습니다. 이는 훈련 중 업데이트가 무의미하게 작아져 학습 과정이 정체될 수 있습니다. 또한, 완전히 무작위 초기화는 대칭을 깨는 것을 보장하지 않습니다. 예를 들어, 초기화된 값이 너무 유사하거나 모두 같은 부호를 가지는 경우, 뉴런들도 여전히 너무 유사하게 작동하여 데이터의 다양한 측면을 배우지 못할 수 있습니다.\n\n실무에서는 초기화에 대해 더 구조화된 방법을 사용합니다. 유명한 방법에는 Glorot (또는 Xavier) 초기화, He (또는 Kaiming) 초기화, LeCun 초기화 등이 있습니다. 이러한 기술은 일반적으로 정규 분포나 균일 분포를 기반으로 하지만, 이전 및 다음 레이어의 크기를 고려하여 균형을 제공하는 것으로 조절됩니다. 이는 기울기 소실 또는 폭발의 위험이 없이 효과적인 학습을 촉진합니다.\n\n## 그렇다면, 가중치 초기화에 표준 정규 분포(N(0,1))를 사용하지 않는 이유는 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일반적인 정규 분포(N(0,1))를 사용하면 무작위화 과정을 어느 정도 제어할 수 있지만, 분산을 효과적으로 제어할 수 없어 최적 가중치 초기화에는 부족합니다. 제로 평균은 가중치가 모두 동일한 부호를 공유하지 않도록 보장하여 대칭을 깨는 데 효과적입니다. 그러나 분산이 1인 것은 문제가 될 수 있습니다.\n\n활성화 함수 입력 𝑍이 가중치에 의존하는 시나리오를 고려해 봅시다. 이전 레이어의 𝑁개 뉴런의 출력을 합산하여 계산된다고 가정해보면, 각각의 가중치는 표준 정규 분포에서 초기화됩니다. 여기서 𝑍도 평균이 0인 정규 분포를 따르지만, 분산은 𝑁이 됩니다. 예를 들어 𝑁=100인 경우, 𝑍의 분산은 100이 되어 너무 크기 때문에 활성화 함수로 입력이 불안정하게 전달되어 역전파 과정에서 그래디언트가 불안정해질 수 있습니다. 아이스크림 공장을 비유하면, 각 기계의 설정에서 오차 허용을 높게 설정하는 것은 품질 관리 부재로 인해 원하는 결과와 크게 벗어나는 최종 제품을 만드는 것과 같습니다.\n\n그렇다면 왜 𝑍의 분산에 신경을 쓸까요? 분산은 𝑍 값의 퍼짐을 제어합니다. 분산이 너무 작으면 𝑍의 출력이 충분히 다양하지 않아 대칭을 깨는 데 효과적이지 못할 수 있습니다. 그러나 너무 큰 분산은 값이 너무 높거나 낮아질 수 있습니다. 시그모이드와 같은 활성화 함수의 경우, 극단적으로 높거나 낮은 입력값은 함수의 포화 극으로 출력을 밀어 넣어 그래디언트 소실 문제를 야기할 수 있습니다.\n\n따라서, 분포에서 무작위로 가중치를 초기화할 때 평균과 분산 둘 다 중요합니다. 효과적으로 대칭을 깨기 위해 평균을 0으로 설정하고, 동시에 분산을 최소화하여 중간 제품(즉, 뉴런 출력)이 너무 크거나 작지 않도록 해야 합니다. 올바른 초기화는 네트워크를 통과하는 정보의 안정된 흐름을 보장하고, 전방 및 역방향으로 효율적인 학습 과정을 유지하며, 그래디언트에 불안전성을 도입하지 않습니다. 신중한 초기화 접근은 효과적이고 견고하게 학습하는 네트워크로 이어질 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 그래서, 신경망의 중간 층에서 출력 값을 제어하기 위해 연속된 층에도 입력으로 사용되는 가중치 초기화에 대해 신중히 선택한 평균과 분산을 사용합니다. 그렇다면, 가장 인기 있는 방법들이 어떻게 이 분산을 제어할 수 있는 걸까요?\n\n가중치를 초기화하는 가장 흔한 방법들을 살펴보기 전에, 𝑍Z의 분산은 가중치 초기화의 분산뿐만 아니라 𝑍Z를 계산하는 데 참여하는 뉴런의 수도 영향을 받는다는 점이 중요합니다. 만약 16개의 뉴런만 사용된다면, 𝑍Z의 분산은 16이 되고, 100개의 뉴런이 사용된다면 100이 됩니다. 이 변동은 가중치가 뽑히는 분포만이 아니라 계산에 기여하는 뉴런의 수, 즉 \"팬-인\"이라고도 불리는 요소에 의해 영향을 받습니다. \"팬-인\"은 뉴런으로 들어오는 입력 연결의 수를 의미하며, 비슷하게 \"팬-아웃\"은 뉴런이 가지는 출력 연결의 수를 나타냅니다.\n\n예시를 통해 설명해드리겠습니다: 신경망의 중간 층에 200개의 뉴런이 있고, 이전 층의 100개 뉴런 및 다음 층의 300개 뉴런과 연결되어 있다고 가정해봅시다. 이 경우, 이 층의 팬-인은 100이고, 팬-아웃은 300입니다.\n\n팬-인과 팬-아웃을 이용하면 가중치 초기화 중 분산을 제어할 수 있는 메커니즘을 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 팬-인은 전방 전파 중 현재 레이어의 출력 𝑍의 분산을 조절하는 데 도움을 줍니다.\n- 팬-아웃은 역전파 중 후속 레이어의 가중치가 얼마나 영향을 미치는지 조정합니다.\n\n현재 레이어로 전방 및 역방향에서 공급되는 뉴런의 수를 고려하여, 연구자들은 다양한 초기화 방법들을 아이디어 위에 구축해냈습니다. Lecun, Xavier/Glorot 초기화 및 He/Kaiming 초기화가 이러한 방법들 중 일부입니다. 이러한 방법들의 아이디어는 꽤 유사합니다. 가중치를 생성할 때 균일 분포 또는 정규 분포 중 하나를 사용하고, 분산을 조절하기 위해 팬-인 또는 팬-아웃을 사용합니다. 이 분포들의 평균은 모두 0으로 설정하여 출력 값의 평균을 0으로 만듭니다.\n\n```js\n# 초기화의 다양한 유형\n\n| 초기화          | 활성화 함수             | σ² (정규)  |\n| -------------- | ----------------------------- | --------------- |\n| Xavier/Glorot  | None, tanh, logistic, softmax | 1 / 팬_평균 |\n| He/Kaiming     | ReLU 및 변형                  | 2 / 팬-인    |\n| LeCun          | SELU                          | 1 / 팬-인    |\n```\n\nLecun 초기화는 가중치 분포에 작은 분산을 사용하여 𝑍의 분산을 축소하는 것에 기반합니다. 𝑍의 분산이 팬-인과 각 가중치의 분산의 곱이라면, 𝑍가 분산이 1이 되도록 보장하려면 각 가중치의 분산은 1/팬-인이어야 합니다. 따라서 Lecun 초기화는 가중치를 𝑁(0,1/팬-인)에서 무작위로 선택합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n자비에/글로뤼 초기화는 이전 레이어의 가중치(fan-in)의 영향을 고려할 뿐만 아니라 역전파 중 이러한 가중치가 후속 레이어에 미치는 영향(fan-out)도 고려합니다. 순방향 및 역방향 전파 중 분산을 균형있게 유지하기 위해 분산에 대한 공식인 2/(fan_in + fan_out)을 사용하여 가중치를 그려놓을 수 있습니다. 이 때의 분산은 Normal 분포, N(0,2/(fan_in + fan_out)) 또는 Uniform 분포(- sqrt(6/ (fan_in + fan_out)), sqrt(6/ (fan_in + fan_out))) 중에서 선택할 수 있습니다.\n\n희/카이밍 초기화는 ReLU 및 그 변형에 특히 맞추어져 있습니다. ReLU는 음수 입력을 제로로 처리하므로 뉴런 활성화의 절반은 0이 아닌 것으로 예상되며, 이는 분산을 줄이고 그라디언트 소멸을 유발할 수 있습니다. 이에 대비하여 희 초기화는 Lecun 방법에서 사용된 분산을 두 배로 늘리는데, 이를 통해 ReLU를 사용하는 레이어에 필요한 균형을 유지합니다. Leaky ReLU 및 ELU의 경우 약간의 조정이 필요하지만(예: ELU의 경우 2 대신 1.55 배 사용), 원칙은 그라디언트를 안정화하기 위해 분산을 조정하고자 한다는 것입니다. 반면 SELU의 경우 자체 정규화 속성을 활용하기 위해 모든 숨겨진 레이어에 Lecun 초기화를 사용해야 합니다.\n\n이 토론은 PyTorch와 같은 프레임워크에서 가중치 초기화가 어떻게 구현되는지에 대한 흥미로운 측면을 엽니다. 이는 다음과 같은 질문으로 제시될 수 있습니다 —\n\n## PyTorch에서 가중치 초기화는 어떻게 구현되고, 그것이 특별한 이유는 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이토치에서는 선형 레이어의 가중치 초기화에 대한 기본 접근 방식이 르쿤 초기화 방법을 기반으로 합니다. 반면 케라스에서는 기본 초기화 기술로 제비어/글로럿 초기화가 사용됩니다.\n\n그러나 파이토치는 가중치 초기화에 대해 매우 유연한 접근 방식을 제공합니다. 사용자는 모델에서 사용된 다양한 활성화 함수의 특정 요구 사항과 일치하도록 프로세스를 세밀하게 조정할 수 있습니다. 이 세밀한 조정은 두 가지 주요 구성 요소를 고려하여 달성됩니다:\n\n- 모드: 이 구성 요소는 레이어의 입력 연결 수(fan-in) 또는 출력 연결 수(fan-out)에 따라 초기화된 가중치의 분산이 조정되는지를 결정합니다.\n- 게인: 이는 모델에서 사용된 활성화 함수에 따라 초기화된 가중치의 스케일을 조정하는 스케일링 계수입니다. 파이토치는 가중치 초기화 프로세스를 최적화하기 위해 맞춤형 게인 값을 계산하는 torch.nn.init.calculate_gain 함수를 제공합니다.\n\n가중치 초기화 매개변수를 사용자 정의하는 이 유연성을 통해 모델에서 사용된 특정 활성화 함수와 비교 가능하고 호환되는 초기화 접근 방식을 설정할 수 있습니다. 흥미로운 점은 파이토치의 가중치 초기화 구현이 서로 다른 초기화 방법 간의 어떤 관계를 나타낼 수 있는데, 이를 통해 신경망의 전반적인 기능을 향상시키기 위한 초기화 프로세스를 활용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, SELU 활성화 함수에 대한 PyTorch 문서를 검토하면 가중치 초기화의 흥미로운 측면을 발견할 수 있습니다. 문서에는 SELU 활성화와 함께 kaiming*normal 또는 kaiming_normal*을 사용하여 초기화할 때, nonlinearity=`selu` 대신 nonlinearity=`linear`을 선택해야 자가 정규화를 달성할 수 있다고 언급되어 있습니다. 이 세부 사항은 흥미로운데, PyTorch의 기본 Lecun 초기화가 Kaiming 방법을 선형 비선형성에서 gain이 1로 설정했을 때 Lecun 초기화 방법을 효과적으로 복제한다는 점을 강조합니다. 이는 Lecun 초기화가 보다 일반적인 Kaiming 초기화 접근법의 특정 응용이라는 것을 보여줍니다. 마찬가지로, Xavier 초기화 방법은 입력 연결의 수(fan-in)와 출력 연결의 수(fan-out)를 모두 고려하는 Lecun 초기화의 다른 변형으로 볼 수 있습니다.\n\n## 가중치를 분포로부터 초기화할 때 평균과 분산을 신중하게 선택해야 하는 점에 동의합니다. 그러나 왜 초기 가중치를 정규 분포 대신 균일 분포에서 추출하려고 하는지에 대한 이유는 여전히 명확하지 않습니다. 무엇 때문에 한 가지를 다른 것보다 선호하게 되는지 설명해주실 수 있나요?\n\n가중치를 초기화할 때 분포로부터 추출할 때 평균과 분산을 신중하게 선택하는 중요성에 대한 귀하의 주장은 타당합니다. 신경망에서 가중치를 초기화할 때 중요한 고려 사항 중 하나는 정규 분포나 균일 분포 중에서 추출할지 결정하는 것입니다. 명확한 연구 결과를 지지하는 답변이 없지만, 이러한 선택을 하는 이유에는 몇 가지 타당한 이유가 있습니다:\n\n균일 분포는 엔트로피가 가장 높은 분포로, 범위 내의 모든 값이 동등하게 가능성이 있습니다. 이 공정한 접근은 초기화에 어떤 값이 더 잘 작동할지에 대한 사전 지식이 부족할 때 유용할 수 있습니다. 각 잠정적인 가중치 값에 공정하게 대우하고 균일한 확률을 할당합니다. 이는 한정된 정보로 게임에서 모든 팀에 공평하게 건 게임과 비슷합니다 - 선호되는 결과의 가능성을 최대화합니다. 어떤 구체적인 값이 좋은 초기 가중치인지 알 수 없기 때문에 균일 분포를 사용하면 편향되지 않은 시작점을 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n한편, 정규 분포는 일반적으로 가중치를 0에 가까운 작은 값으로 초기화하는 것이 더 자주 일어납니다. 초기 가중치가 작을수록 출력의 분산이 줄어들고 학습 중 안정적인 기울기를 유지하는 데 도움이 되기 때문에 작은 초기 가중치가 일반적으로 선호됩니다. 이는 가중치 초기화 방법에서 단위 분산 대신 작은 분산을 선호하는 이유와 유사합니다. 게다가, 시그모이드나 하이퍼볼릭 탄젠트와 같은 특정 활성화 함수는 작은 초기 가중치 값에서 더 나은 성능을 발휘하며 이러한 활성화 함수가 숨겨진 레이어가 아닌 최종 출력 레이어에서만 사용되더라도 그렇습니다.\n\n근본적으로, 균일 분포는 사전 지식이 부족한 상황에서 공평한 시작점을 제공하여 모든 잠재적인 가중치 값들을 동등하게 가능성 있는 것으로 간주합니다. 반면 정규 분포는 0에 가까운 작은 초기 가중치를 선호하여 기울기 안정성을 돕고 시그모이드나 하이퍼볼릭 탄젠트와 같은 특정 활성화 함수와 잘 맞습니다. 이러한 분포 사이의 선택은 종종 다른 신경 아키텍처와 작업에 걸쳐 경험적인 결과에 따라 이루어집니다. 보편적으로 최적의 방법은 존재하지 않지만, 균일 및 정규 분포의 특성을 이해하면 더 많이 발견되고 문제에 특화된 초기화 결정을 할 수 있게 됩니다.\n\n## 우리는 편향 항에 대해서도 이러한 가중치 초기화 방법을 사용합니까? 편향 항을 어떻게 초기화합니까?\n\n좋은 질문입니다. 우리는 편향 항에 대해서는 가중치와 동일한 초기화 기술을 반드시 사용하지는 않습니다. 사실, 편향 값을 모두 간단히 0으로 초기화하는 것이 흔한 실천입니다. 그 이유는 가중치가 각 뉴런이 기본 데이터를 근사하는 함수의 모양을 결정하는 반면, 편향은 각 함수를 위아래로 이동시키는 오프셋 값을 제공하기 때문입니다. 그래서 편향은 가중치가 학습하는 전반적인 형태에 직접적으로 영향을 주지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n초기화의 주요 목표는 대칭을 깨고 가중치 학습에 좋은 시작점을 제공하는 것이므로 편향이 어떻게 초기화되는지에 대해 크게 걱정할 필요가 없습니다. 그들을 모두 0으로 설정하는 것이 일반적으로 충분합니다. 이에 대해 더 자세한 논의는 CS231n 강의 노트에서 찾아볼 수 있습니다.\n\n# 배치 정규화\n\n선택한 활성화 함수와 적절하게 초기화된 가중치로 신경망을 훈련 시작할 수 있습니다 (우리의 미니 아이스크림 공장 생산 라인을 가동시키는 것과 같습니다). 그러나 품질 통제가 필요합니다. 초기에는 물론 훈련 반복 중에도요. 두 가지 주요 기술은 특성 정규화와 배치 정규화입니다.\n\n이전 포스트에서 경사 하강법에 대해 논의한 것처럼, 이러한 기술은 빠른 수렴을 위해 손실 풍경을 재구성합니다. 특성 정규화는 초기 데이터 입력에 이를 적용하며, 배치 정규화는 에폭 사이에 숨겨진 레이어의 입력을 정규화합니다. 두 기술 모두 다른 단계에서 품질 보증 점검을 구현하는 것과 유사합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n배치 정규화는 훈련 중에 각 레이어의 입력을 평균이 0이고 분산이 1인 값으로 정규화하여 내부 공변량 이동을 줄이어 경사 소실/폭발 문제를 완화하는 데 도움을 줍니다. 내부 이동이 발생하는 이유에 대해 생각해 보죠. 각 레이어의 매개변수를 기울기에 기반하여 업데이트하는 과정은 신경망의 각 레이어가 공장의 서로 다른 부서라고 생각할 수 있습니다. 한 부서의 매개변수(또는 설정)를 업데이트할 때마다 다음 부서의 입력이 변경됩니다. 이로 인해 각 레이어마다 새로운 변화에 대한 조정이 필요하며 이를 심층 학습에서 내부 공변량 이동이라고 합니다. 그렇다면 이러한 이동이 자주 발생할 때 어떻게 될까요? 네트워크가 안정화하기 어려워지며 각 레이어의 입력이 계속 변화함에 따라 문제가 발생합니다. 이는 공장의 한 부분에서 지속적인 변화가 제품 품질에 일관성 없이 영향을 미치는 것과 유사합니다. 이는 작업자들을 혼란스럽게 하고 작업 흐름을 망치는 결과를 초래할 수 있습니다.\n\n배치 정규화는 훈련 중 미니 배치 전체에서 각 레이어의 입력을 정규화하여 평균이 0이고 분산이 1인 값으로 설정하는 것을 목표로 합니다. 레이어가 예상할 수 있는 일관된, 통제된 입력 분포를 강요합니다. 공장 비유로 돌아가서, 다음 부서로 전달되기 전 각 부서의 출력에 엄격한 품질 기준을 설정하는 것과 유사합니다. 예를 들어, 베이킹 부서가 일관된 크기와 모양의 아이스크림콘을 생산해야 한다는 규칙을 설정하는 것입니다. 다음 장식 부서는 콘의 변화량을 고려할 필요가 없게 되며, 각 일반화된 콘에 동일한 양의 아이스크림을 추가할 수 있습니다.\n\n정규화를 통해 내부 공변량 이동을 줄이는 것으로 배치 정규화는 훈련 과정 중에 기울기가 엉망이 되는 것을 방지합니다. 레이어들이 신속히 변하는 입력 분포에 계속해서 재조정할 필요가 없어져서 기울기가 더 안정적으로 유지됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한 정규화는 정규화자 역할을 하며 목적 함수 랜드스케이프를 부드럽게 만듭니다. 이를 통해 더 높은 학습 속도를 사용하여 수렴 속도를 높일 수 있습니다. 일반적으로 배치 정규화는 내부 분산 이동을 줄이고 그래디언트를 안정화시키며 목적함수를 정규화하고 훈련 가속화를 가능하게 합니다.\n\n## 배치 정규화를 어떻게 적용해야 하나요? 활성화 함수 이전 또는 이후에 적용해야 하나요? 훈련 및 테스트 중에 어떻게 처리해야 하나요?\n\n배치 정규화는 그래디언트를 안정화시키는 추가 레이어를 통해 DNN을 훈련하는 방식을 실제로 바꿨습니다. DL 영역에서 활성화 함수 이전 또는 이후에 적용해야 하는지에 대한 논쟁이 있습니다. 솔직히 말해서, 이는 모델에 따라 다르며 조금은 실험해 봐야 할 수도 있습니다. 그냥 방법을 일정하게 유지하도록 하고 변경하면 예상치 못한 문제가 발생할 수 있습니다.\n\n훈련 중에 배치 정규화 레이어는 각 미니 배치를 통해 각 차원에 대한 평균과 표준편차를 계산합니다. 이러한 통계량은 출력을 정규화하는 데 사용되어 평균이 0이고 분산이 1임을 보장합니다. 이 프로세스는 입력 분포를 표준 정규 분포로 변환하는 것으로 생각할 수 있습니다. 전체 훈련 데이터 세트를 사용하여 특징 정규화를 하는 것과는 달리 배치 정규화는 각 미니 배치에 기초하여 조정되어 처리되는 데이터에 동적이며 반응성을 가지게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제, 테스트는 다른 이야기입니다. 테스트 데이터에서 평균과 분산을 정규화에 사용하면 안 됩니다. 대신에 이러한 매개변수는 학습된 특징으로 간주되어 훈련 과정에서 유지되어야 합니다. 훈련 중 각 미니 배치는 고유의 평균과 분산을 가지지만, 일반적인 실천 방법은 이러한 값들의 이동 평균을 훈련 단계 동안 사용하는 것입니다. 이를 통해 안정된 추정값을 제공하여 테스트 중에 적용할 수 있게 됩니다. 다른 적은 일반적인 방법은 전체 훈련 데이터 세트를 사용하여 포괄적인 평균과 분산을 계산하는 추가 에포크를 실행하는 방법도 있습니다.\n\nPyTorch로 DNN 프레임워크로 훈련할 때, 조정 가능한 하이퍼파라미터인 γ와 β를 사용할 수 있습니다. 이러한 파라미터를 조정하여 배치 정규화 과정을 세밀하게 조정할 수 있습니다. 일반적으로 기본 설정은 매우 효과적입니다. 그러나 훈련 중에 PyTorch는 분산을 계산하기 위해 편향 추정량을 사용하지만, 테스트 중에 이동 평균을 위해 불편 추정량을 사용합니다. 이러한 조정은 모델이 미처 못 본 조건에서 인구 표준 편차를 더 정확하게 근사하고 모델의 신뢰성을 향상하는 데 도움이 됩니다.\n\n배치 정규화를 올바르게 적용하는 것은 네트워크에서 효율적인 학습에 중요합니다. 네트워크가 잘 학습하는 것뿐만 아니라 다양한 데이터 집합과 테스트 시나리오에서 성능을 유지할 수 있게 합니다. 생산 라인의 각 세그먼트를 정확하게 교정하여 운전을 원활하고 일관되게 유지하는 것으로 생각해보세요.\n\n## 왜 역전파 중에 그래디언트에 직접 배치 정규화를 적용하는 대신 순전파 중에 배치 정규화가 적용되나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일반적으로 순방향 패스 중 입력 또는 활성화에 배치 정규화를 적용하는 이유가 역전파 중에 기울기 자체에 직접 배치 정규화를 적용하는 것보다 더 일반적입니다.\n\n먼저, 기울기에 배치 정규화를 직접 적용하는 이점을 보여주는 실증적 증거나 실무가 부족합니다. 내부 공변량 이동의 개념은 주로 순방향 패스 중에 발생하며, 계층 입력의 분포가 매개변수 업데이트로 인해 변경됩니다. 따라서, 후속 계층에서 처리되기 전에 이러한 입력을 안정화시키기 위해 이 단계에서 배치 정규화를 적용하는 것이 합리적입니다. 또한, 기울기에 배치 정규화를 직접 적용하는 것은 기울기의 크기와 방향이 나르는 중요한 정보를 왜곡할 수 있습니다. 이는 내재적 의미를 변경하는 방식으로 고객 피드백을 변조하는 것과 유사하며, 이는 미니 아이스크림 공장의 제조 프로세스에 대한 향후 조정을 잘못 이끌 수 있습니다.\n\n그러나, 기울기를 경사 클리핑과 같은 마이너 조정을 하는 것은 일반적으로 허용되며 유익합니다. 이 기법은 기울기를 지나치게 크게 만들지 않고 안전한 범위 내에 유지하여 기울기를 제한하는 도구입니다. 이는 피드백에서 극단적 아웃라이어를 걸러내는 것과 유사하며, 이는 프로세스를 방해할 수 있는 급격한 반응을 방지하면서 전체 피드백의 무결성을 유지하는 데 도움이 됩니다. PyTorch에서는 기울기 노름을 모니터링하는 것이 일반적이며, 기울기가 폭발하기 시작하면 경사 클리핑과 같은 기법을 사용할 수 있습니다. PyTorch는 torch.nn.utils.clip*grad_norm* 및 torch.nn.utils.clip*grad_value*와 같은 함수를 제공하여 이를 관리할 수 있습니다.\n\n## 직접 정규화 대신 기울기를 클리핑하는 옵션을 언급했습니다. 왜 기울기를 클리핑하는 대신 바닥값을 설정하지 않는지 정확히 선택하는 이유가 무엇인가요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기울기 클리핑은 폭발하는 기울기 문제를 방지하는 데 도움이 되는 간단하면서도 효율적인 기술입니다. 종종 기울기의 최대값을 수동으로 제한합니다. 예를 들어 ReLU 활성화 함수는 상한값을 6으로 설정할 수 있으며, PyTorch에서는 ReLU6로 알려져 있습니다. 이 상한을 설정함으로써, 각 층에서 역전파 과정 중 기울기가 연쇄 법칙에 따라 곱해질 때 값이 지나치게 커지지 않도록 보장합니다. 이러한 클리핑은 기울기가 학습 과정을 방해할 정도로 급격하게 증가하는 것을 방지하여 그 값을 관리 가능한 한도 내에 유지합니다.\n\n한편, 기울기를 억제하는 것은 너무 작아지지 않도록 하기 위해 하한값을 설정하는 것입니다. 그러나 이는 사그라들어 가는 기울기 문제의 근본적인 해결책이 되지는 않습니다. 일부 활성화 함수인 시그모이드나 tanh 같은 경우 입력이 0에서 멀어질수록 기울기 값을 매우 심각하게 축소시키기 때문에 기울기의 사그라들음 문제가 발생합니다. 이는 학습 속도가 극도로 느려지거나 정체되는 매우 작은 기울기 값을 야기합니다. 기울기를 억제해도 해결되지 않는 이유는 문제의 근본이 활성화 함수의 성질에 기인하기 때문입니다. 즉, 단순히 값이 너무 작은데만 있지 않고 활성화 함수가 기울기 값을 압축하는 것에 있습니다. 따라서 사그라드는 기울기 문제를 효과적으로 해결하기 위해서는 네트워크 아키텍처나 활성화 함수 선택을 조정하는 것이 더 유익합니다. 기울기가 사그라들지 않도록 하는 활성화 함수 사용(ReLU같은), ResNet 아키텍처에서 볼 수 있는 스킵 연결 추가, LSTM이나 GRU 같은 RNN에서 게이트 메커니즘을 사용하는 등의 기술을 통해 기울기는 역전파 중 네트워크 전반에 걸쳐 더 건강한 흐름을 보장하여 자연스럽게 사그라드는 것을 방지할 수 있습니다.\n\n요약하면, 기울기 클리핑은 지나치게 큰 기울기를 효과적으로 관리하지만, 하한값을 설정하는 기울기 억제는 지나치게 작은 기울기 문제를 효과적으로 다루지 못합니다. 대신, 사그라드와 관련된 문제를 해결하려면 일반적으로 구조적인 조정이 필요합니다.\n\n#실무에서의 경험(개인 경험)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요약할 때, 모든 논의된 방법이 사라지는 그래디언트 문제와 폭주하는 그래디언트 문제를 해결하는 데 유용하다는 것은 명백합니다. 이들은 모두 모델의 학습 과정을 향상시킬 수 있는 실용적인 접근 방법입니다. 이 글을 마무리하며 한 가지 질문으로 마무리하고 싶습니다 -\n\n## 현실은 무엇인가요? 실무에서는 어떤 일반적인 과정이 있나요?\n\n실무에서 좋은 소식은 가능한 모든 해결책을 실험할 필요가 없다는 것입니다. 활성화 함수를 선택할 때, ReLU가 종종 선택되는 것이며 매우 비용 효율적입니다. ReLU는 양의 입력의 크기를 변경하지 않고 전달합니다 (시그모이드나 tanh는 큰 값을 크기와 관계없이 항상 1로 압축합니다) 그리고 계산 및 미분 측면에서 간단합니다. 주요 프레임워크에서 잘 지원되며 dead ReLU 문제를 우려한다면 Leaky ReLU, ELU, SELU, 또는 GELU와 같은 대안을 고려할 수 있지만 일반적으로 시그모이드와 tanh를 피해야 하는 사라지는 그래디언트 문제를 피하기 위해 명확을 지켜야 합니다.\n\n선호되는 활성화 함수인 ReLU로 인해 가중치 초기화가 지나치게 민감하게 작용하는 문제에 대해 덜 걱정해도 됩니다. 시그모이드, tanh 및 SELU와 같은 함수에서 주로 발생하는 문제일 뿐입니다. 대신, 선택한 활성화 함수에 권장되는 가중치 초기화 방법에 집중하는 것이 적당합니다 (예를 들어, ReLU에 대해 He/Kaiming 초기화를 사용하는 이유는 ReLU의 비선형성을 고려하기 때문입니다).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n네트워크에는 항상 배치 정규화를 포함하세요. 활성화 함수 전 또는 후에 적용할지 결정(또는 실험)하고, 모델 전체에서 일관되게 그 선택을 유지하세요. 배치 정규화는 규제 효과와 높은 학습률 사용이 가능해지는 등 여러 가지 이점을 제공합니다. 이는 교육 및 수렴 속도를 높일 수 있습니다.\n\n그래서 어떤 것을 실험해볼 가치가 있을까요? 옵티마이저는 탐구할 가치가 있습니다. 이전 글에서 그라디언트 디센트 및 그 인기 있는 변형 등 다양한 옵티마이저를 논의했습니다. Adam은 빠르지만 과적합을 유발하고 학습률을 너무 빨리 감소시킬 수 있습니다. SGD는 신뢰성이 있고 병렬 컴퓨팅 환경에서 특히 효과적일 수 있습니다. 느릴 수 있지만 모델로부터 최대 성능을 뽑아내려면 확실한 선택입니다. 때로는 RMSprop이 더 나은 대안일 수 있습니다. 저는 Adam으로 시작하여 속도를 이유로 한 후에 더 나은 최소값을 찾고 과적합을 방지하기 위해 후기 에포크에서 SGD로 전환하는 것이 좋은 전략으로 생각합니다.\n\n만약 이 시리즈를 즐기고 계시다면, 상호작용(박수, 댓글 및 팔로우)이 지지뿐만 아니라 시리즈를 이어가는 원동력이자 저의 계속된 공유를 영감받는 기반이 됩니다.\n\n이 시리즈의 다른 게시물:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- ML 학습의 용기: L1 및 L2 정규화 해독하기 (파트 1)\n- ML 학습의 용기: 우도, MLE 및 MAP 해독하기\n- ML 학습의 용기: F1, 재현율, 정밀도 및 ROC 곡선에 대한 심층 탐구\n- ML 학습의 용기: 가장 일반적인 손실 함수에 대한 상세 가이드\n- ML 학습의 용기: 경사 하강법과 인기 있는 옵티마이저에 대한 심층 탐구\n- ML 학습의 용기: 수학적 이론부터 코딩 실무까지 백프로파게이션 설명\n\n## 참고 자료\n\n활성화 함수\n\n- [가우시안 에러 선형 유닛 (GeLU) 설명](https://ml-explained.com/blog/activation-functions-explained#gaussian-error-linear-unit-gelu)\n- [ReLU 활성화 함수](https://www.mldawn.com/relu-activation-function/)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가중치 초기화\n\n- [normal glorot initialization(일반 글로럿 초기화)의 원천](https://datascience.stackexchange.com/questions/102036/where-does-the-normal-glorot-initialization-come-from)\n- [파이토치(PyTorch)에서의 기본 초기화에 대한 명확한 이해](https://discuss.pytorch.org/t/clarity-on-default-initialization-in-pytorch/84696/2)\n\n그래디언트 클리핑\n\n- [파이토치(PyTorch)에서 그래디언트 클리핑 하는 방법](https://stackoverflow.com/questions/54716377/how-to-do-gradient-clipping-in-pytorch)\n","ogImage":{"url":"/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png"},"coverImage":"/assets/img/2024-05-18-CouragetoLearnMLTacklingVanishingandExplodingGradientsPart2_0.png","tag":["Tech"],"readingTime":39}],"page":"89","totalPageCount":110,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"89"},"buildId":"YUMR4jSyk_WlOHHc7UfOk","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>