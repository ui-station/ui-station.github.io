<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/101" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/101" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_buildManifest.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="쿠버네티스 내에서의 데이터베이스 좋은 아이디어인가요" href="/post/2024-05-18-DatabaseinKubernetesIsthatagoodidea"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="쿠버네티스 내에서의 데이터베이스 좋은 아이디어인가요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="쿠버네티스 내에서의 데이터베이스 좋은 아이디어인가요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">쿠버네티스 내에서의 데이터베이스 좋은 아이디어인가요</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="컨테이너 안에서 RStudio 실행하기" href="/post/2024-05-18-RunningRStudioInsideaContainer"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="컨테이너 안에서 RStudio 실행하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-RunningRStudioInsideaContainer_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="컨테이너 안에서 RStudio 실행하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">컨테이너 안에서 RStudio 실행하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="디커Docker가 죽었나요" href="/post/2024-05-18-Isdockerdead"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="디커Docker가 죽었나요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-Isdockerdead_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="디커Docker가 죽었나요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">디커Docker가 죽었나요</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="비정형 데이터 퍼널" href="/post/2024-05-18-TheUnstructuredDataFunnel"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="비정형 데이터 퍼널" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-TheUnstructuredDataFunnel_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="비정형 데이터 퍼널" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">비정형 데이터 퍼널</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마이크로소프트 Fabric 및 Databricks 열에서 기본 키와 외래 키, 그리고 고유성을 강제하는 낮은 수준의 도전" href="/post/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마이크로소프트 Fabric 및 Databricks 열에서 기본 키와 외래 키, 그리고 고유성을 강제하는 낮은 수준의 도전" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마이크로소프트 Fabric 및 Databricks 열에서 기본 키와 외래 키, 그리고 고유성을 강제하는 낮은 수준의 도전" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">마이크로소프트 Fabric 및 Databricks 열에서 기본 키와 외래 키, 그리고 고유성을 강제하는 낮은 수준의 도전</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="실무에서 활용하는 MAX_BY의 DBSQL 사용 사례 - Gold Layer Views" href="/post/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="실무에서 활용하는 MAX_BY의 DBSQL 사용 사례 - Gold Layer Views" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="실무에서 활용하는 MAX_BY의 DBSQL 사용 사례 - Gold Layer Views" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">실무에서 활용하는 MAX_BY의 DBSQL 사용 사례 - Gold Layer Views</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="델타 레이크 리퀴드 클러스터링 - 시각적 설명" href="/post/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="델타 레이크 리퀴드 클러스터링 - 시각적 설명" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="델타 레이크 리퀴드 클러스터링 - 시각적 설명" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">델타 레이크 리퀴드 클러스터링 - 시각적 설명</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Lakeview 대시보드를 통한 관측력 시리즈 - 기사 1 DBSQL 웨어하우스 어드바이저" href="/post/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Lakeview 대시보드를 통한 관측력 시리즈 - 기사 1 DBSQL 웨어하우스 어드바이저" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Lakeview 대시보드를 통한 관측력 시리즈 - 기사 1 DBSQL 웨어하우스 어드바이저" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Lakeview 대시보드를 통한 관측력 시리즈 - 기사 1 DBSQL 웨어하우스 어드바이저</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">16<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="클라우드 비용 최적화 핀옵스 마인드셋 수용하기" href="/post/2024-05-18-OptimizingCostsintheCloudEmbracingaFinOpsMindset"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="클라우드 비용 최적화 핀옵스 마인드셋 수용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-OptimizingCostsintheCloudEmbracingaFinOpsMindset_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="클라우드 비용 최적화 핀옵스 마인드셋 수용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">클라우드 비용 최적화 핀옵스 마인드셋 수용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS S3와 CloudFront를 이용한 정적 웹사이트 호스팅 공개 vs 비공개" href="/post/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS S3와 CloudFront를 이용한 정적 웹사이트 호스팅 공개 vs 비공개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS S3와 CloudFront를 이용한 정적 웹사이트 호스팅 공개 vs 비공개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">AWS S3와 CloudFront를 이용한 정적 웹사이트 호스팅 공개 vs 비공개</strong><div class="PostList_meta__VCFLX"><span class="date">May 18, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link posts_-active__YVJEi" href="/posts/101">101</a><a class="link" href="/posts/102">102</a><a class="link" href="/posts/103">103</a><a class="link" href="/posts/104">104</a><a class="link" href="/posts/105">105</a><a class="link" href="/posts/106">106</a><a class="link" href="/posts/107">107</a><a class="link" href="/posts/108">108</a><a class="link" href="/posts/109">109</a><a class="link" href="/posts/110">110</a><a class="link" href="/posts/111">111</a><a class="link" href="/posts/112">112</a><a class="link" href="/posts/113">113</a></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"쿠버네티스 내에서의 데이터베이스 좋은 아이디어인가요","description":"","date":"2024-05-18 16:37","slug":"2024-05-18-DatabaseinKubernetesIsthatagoodidea","content":"\nKubernetes/Docker에 데이터베이스를 저장해야 하는지 여전히 논란이 많습니다. Kubernetes(k8s)는 상태가 없는 응용 프로그램을 관리하는 데 뛰어나지만, 특히 PostgreSQL과 MySQL과 같은 데이터베이스와 같은 상태를 유지하는 서비스에서 기본적인 단점을 가지고 있습니다.\n\n이전 글 \"Docker에서 데이터베이스: 좋은 방법인가, 나쁜 방법인가\"에서는 데이터베이스를 컨테이너화하는 장단점에 대해 논의했습니다. 오늘은 K8S에서 데이터베이스를 조율하는 데 어떤 희생을 해야 하는지 탐구하고, 이것이 현명한 결정이 아닌 이유에 대해 살펴보겠습니다.\n\n# 개요\n\nKubernetes(k8s)는 복잡한 상태가 없는 응용 프로그램의 다양한 집합을 더 잘 관리하기 위해 고안된 우수한 컨테이너 조율 도구입니다. StatefulSet, PV, PVC 및 LocalhostPV와 같은 제공 기능에도 불구하고, 이러한 기능들은 여전히 높은 신뢰성을 요구하는 프로덕션 수준의 데이터베이스를 실행하기에는 충분하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터베이스는 \"소 동물\"보다는 \"가축\"과 같이 주의 깊게 양육이 필요한 존재입니다. K8S에서 데이터베이스를 \"가축\"으로 취급한다면 외부 디스크/파일 시스템/스토리지 서비스를 새로운 \"데이터베이스 애완동물\"로 변신시킬 것입니다. 데이터베이스를 EBS/네트워크 스토리지에서 실행하면 신뢰성과 성능에서 상당한 단점이 발생합니다. 그러나 고성능 지역 NVMe 디스크를 사용하면 데이터베이스가 노드에 바인드되어 스케줄할 수 없어져서, K8S에 넣는 주요 목적을 무효화시킬 것입니다.\n\n데이터베이스를 K8S에 배치하는 것은 \"lose-lose(양쪽이 손해)\" 상황으로 이어집니다 - K8S는 비상태성에서의 간단함을 손실하며, 순수한 비상태적 사용처럼 빠르게 재배치, 스케줄링, 파괴, 재구축을 할 유연성이 부족합니다. 반면, 데이터베이스는 신뢰성, 보안, 성능 및 복잡성 비용에 맞교환으로 제한된 \"탄력성\"과 활용도를 얻을 수 있지만 - 가상 머신들도 이를 달성할 수 있습니다. 공중 클라우드 업체 외의 사용자들에게는 단점이 혜택을 제대로 상쇄합니다.\n\nK8S를 통해 나타나는 \"클라우드 네이티브 열기\"는 단지 K8S를 위해 K8S를 채택하는 왜곡된 현상이 되어버렸습니다. 엔지니어들은 대체할 수 없음을 증가시키기 위해 추가 복잡성을 더하고, 한편으로 경영자들은 산업에서 뒤처지는 것을 두려워하며 배포 경쟁에 휩쓸려갑니다. 자전거로 할 수 있는 작업에 탱크를 사용하여 자신을 증명하거나 경험을 쌓고자 하지만, 문제가 그러한 \"용사 퇴치\" 기술이 필요한지 고려하지 않으면, 이러한 종류의 구조적 호흡법은 결국 부정적인 결과로 이어질 것입니다.\n\n네트워크 스토리지의 신뢰성과 성능이 지역 스토리지를 능가할 때까지, 데이터베이스를 K8S에 배치하는 것은 현명한 선택이 아닙니다. 데이터베이스 관리 복잡성을 해결할 수 있는 다른 방법들이 있습니다, RDS와 Pigsty와 같은 오픈 소스 RDS 솔루션을 통한 방법들이 있으며, 이들은 베어 메탈이나 베어 OS에 기반을 두고 있습니다. 사용자들은 자신의 상황과 요구에 근거하여 현명한 결정을 내려야 하며, 이를 위해 장단점을 신중하게 고려해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 현상 유지\n\nK8S는 상태가 없는 애플리케이션 서비스를 관리하는 데 뛰어나지만, 초기에는 상태가 있는 서비스에 제한이 있었습니다. 그러나 K8S와 도커가 의도한 용도가 아니었음에도 불구하고 커뮤니티의 확장 열망은 멈출 줄 모릅니다. 전도자들은 K8S를 차세대 클라우드 운영 체제로 묘사하며, 데이터베이스가 반드시 Kubernetes 내의 일반적인 응용 프로그램이 될 것이라 주장합니다. 상태가 있는 서비스를 지원하기 위해 다양한 추상화가 등장했습니다: StatefulSet, PV, PVC, LocalhostPV 등이 있습니다.\n\n수많은 클라우드 네이티브 열정가들이 기존 데이터베이스를 K8S로 이전하려 시도했으며, 결과적으로 데이터베이스에 대한 CRD와 Operator가 증가하였습니다. PostgreSQL을 예로 들면 이미 PGO, StackGres, CloudNativePG, PostgresOperator, PerconaOperator, CYBERTEC-pg-operator, TemboOperator, Kubegres, KubeDB, KubeBlocks 등 다양한 K8S 배포 솔루션이 있습니다. CNCF 생태계가 빠르게 확장되어 복잡성의 놀이터가 되어가고 있습니다.\n\n그러나 복잡성은 비용을 의미합니다. \"비용 절감\"이 주류가 되면서, 반성의 목소리가 나타나고 있습니다. 공중 클라우드에서 K8S를 깊이 활용한 DHH와 같은 Could-Exit 선구자들은 자체 호스팅 오픈소스 솔루션으로 전환 중에 과도한 복잡성으로 인해 K8S를 버리고 Docker와 Kamal이라는 Ruby 도구만을 대안으로 채택했습니다. 많은 사람들이 데이터베이스와 같은 상태가 있는 서비스가 Kubernetes에 적합한지 의심하기 시작했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nK8S 자체는 상태 지향 애플리케이션을 지원하기 위해 노력하면서, 원래의 컨테이너 오케스트레이션 플랫폼으로부터 벗어나 zun. 쿠버네티스 공동 창립자 팀 호킨은 올해의 KubeCon에서 드문 우려를 표명했습니다. \"K8s is Cannibalizing Itself!\"라고 말하며 \"쿠버네티스는 너무 복잡해졌으며, 자제력을 배워야 합니다. 그렇지 않으면 혁신을 멈추고 기초를 잃을 것입니다.\"\n\n# 승리의 상실\n\n클라우드 네이티브 분야에서 “애완동물”과 “가축”의 비유는 상태 지향 서비스를 설명하는 데 자주 사용됩니다. \"애완동물\"인 데이터베이스는 주의 깊고 개별적인 관리가 필요하지만, \"가축\"은 일회용이며 상태를 가지지 않는 애플리케이션을 나타냅니다(일회용성).\n\n![이미지](/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_0.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nK8S의 주요 아키텍처 목표 중 하나는 가축으로 취급할 수 있는 것들을 가축으로 취급하는 것입니다. 데이터베이스에서 \"저장소와 연산을 분리\"하는 시도는 이 전략을 따릅니다: 상태를 가진 데이터베이스 서비스를 K8S 외부의 상태 저장소로 분리하고 K8S 내부에서 순수한 연산으로 분리하는 것입니다. 상태는 EBS/클라우드 디스크/분산 저장소 서비스에 저장되어 \"무상태\" 데이터베이스 부분이 K8S에서 자유롭게 생성, 삭제 및 예약될 수 있도록 합니다.\n\n그러나 데이터베이스, 특히 OLTP 데이터베이스는 디스크 하드웨어에 심하게 의존하며, 네트워크 저장소의 신뢰성과 성능은 아직도 로컬 디스크의 성능을 크게 뒤쳐지고 있습니다. 따라서 K8S는 LocalhostPV 옵션을 제공하여 컨테이너가 데이터 볼륨을 호스트 운영 체제에 직접 사용할 수 있도록 하여 고성능/고신뢰성 로컬 NVMe 디스크 저장소를 활용합니다.\n\n그러나 이것은 딜레마를 제시합니다: K8S의 스케줄링 및 오케스트레이션 능력을 위해 저품질 클라우드 디스크를 사용하고 데이터베이스의 신뢰성/성능을 용인해야할까요? 아니면 호스트 노드에 연결된 고성능 로컬 디스크를 사용하여 모든 유연한 스케줄링 능력을 사실상 상실해야할까요? 전자는 K8S의 작은 보트에 닻을 박아 전반적인 속도와 민첩성을 늦추는 것처럼 보이며, 후자는 배를 일정한 지점에 고정시키는 것과 같습니다.\n\n상태가 없는 K8S 클러스터를 실행하는 것은 간단하고 신뢰할 수 있지만, 물리적 머신의 순수한 운영 체제에서 상태가 있는 데이터베이스를 실행하는 것도 마찬가지입니다. 그러나 둘을 섞으면 K8S는 상태가 없는 유연성과 비현실적인 스케줄링 능력을 잃게 되고 데이터베이스는 신뢰성, 보안, 효율성 및 단숨함과 같은 핵심 속성을 희생하게 되며 데이터베이스에 근본적으로 중요하지 않은 탄력성, 자원 이용 및 Day1 전달 속도를 얻게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Pros and Cons\n\n중대한 기술 결정을 내리기 위해서는 가장 중요한 측면이 장단점을 따져보는 것입니다. 여기서 \"품질, 보안, 성능, 비용\"의 순서로, 데이터베이스를 K8S에 배치하는 기술적 트레이드오프와 클래식한 베어 메탈/가상머신 배포와의 비교에 대해 토의해보겠습니다. 모든 것을 다 다루는 포괄적인 논문을 쓰고 싶지는 않습니다. 대신 특정 질문 몇 가지를 제시하여 고려하고 토론하려고 합니다.\n\n품질\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nK8S는 물리적 배포와 비교할 때 추가적인 장애 지점과 아키텍처 복잡성을 도입하여 대폭 증가시키며, 장애의 평균 복구 시간을 상당히 연장시킬 수 있습니다. \"Docker에 데이터베이스를 넣는 것이 좋은 아이디어일까?\"라는 글에서, 신뢰성에 관한 논쟁을 제공했었는데, 이는 Kubernetes에도 적용될 수 있습니다. K8S와 Docker는 데이터베이스에 추가적이고 불필요한 의존성과 장애 지점을 도입하며, 커뮤니티 장애 지식 축적과 신뢰성 추적 기록 (MTTR/MTBF)이 부족합니다.\n\n클라우드 공급업체 분류 시스템에서 K8S는 PaaS에 속하고, RDS는 보다 기본적인 IaaS 계층에 속합니다. 데이터베이스 서비스는 K8S보다 높은 신뢰성 요구를 가지고 있습니다. 예를 들어, 많은 기업의 클라우드 관리 플랫폼은 추가 CMDB 데이터베이스에 의존합니다. 이 데이터베이스는 어디에 위치해야 할까요? K8S가 의존하는 것을 관리하게 두면 안 되며, 불필요한 추가적인 의존성을 추가해서도 안 됩니다. 알리바바 클라우드의 세계적인 대형 장애와 디디의 K8S 아키텍처 조정 재해는 우리에게 이 교훈을 전해주었습니다. 게다가, 이미 외부에 있는 데이터베이스 시스템이 있는데, K8S 내에 별도의 데이터베이스 시스템을 유지하는 것은 더욱 정당화하기 어렵습니다.\n\n보안\n\n멀티 테넌트 환경에서의 데이터베이스는 추가적인 공격 표면을 도입하여 더 높은 위험과 더 복잡한 감사 준수 도전을 가져옵니다. K8S는 데이터베이스를 보다 안전하게 만들까요? K8S 아키텍처 조정의 복잡성이 K8S를 잘 모르는 스크립트 키디들을 막을 수도 있지만, 진짜 공격자들에게는 보다 많은 구성 요소와 의존성이 더 넓은 공격 표면을 의미할 때도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"BrokenSesame 알리바바 클라우드 PostgreSQL 취약점 기술 세부 정보”에서 보안 인원이 자체 PostgreSQL 컨테이너를 사용하여 K8S 호스트 노드로 이탈하고 K8S API 및 다른 유저들의 컨테이너와 데이터에 액세스했습니다. 이는 명백히 K8S에만 적용되는 문제입니다 — 리스크는 실재하며 이러한 공격이 발생한 바 있으며 심지어 로컬 클라우드 산업 선두주자인 알리바바 클라우드도 침투당했습니다.\n\n![이미지](/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_1.png)\n\n성능\n\n“도커에 데이터베이스를 넣으면 좋은 아이디어인가?”에서 설명한 대로, 추가적인 네트워크 부하, 인그레스 병목 현상 또는 성능이 저하된 클라우드 디스크는 모두 데이터베이스 성능에 부정적인 영향을 미칩니다. 예를 들어 “PostgreSQL@K8s 성능 최적화”에서 밝혀진 것처럼, K8S에서 데이터베이스 성능을 베어메탈과 거의 맞출 정도로 만들기 위해서는 상당한 기술 능력이 필요합니다.\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Database in Kubernetes](/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_2.png)\n\n효율성에 대한 또 다른 오해는 자원 활용입니다. 오프라인 분석 업무와 달리 중요한 온라인 OLTP 데이터베이스는 자원 활용을 증가시키려는 것이 아니라 시스템의 신뢰성과 사용자 경험을 향상시키기 위해 의도적으로 낮춰야 합니다. 많은 조각화된 비지니스가 있는 경우 PDB/공유 데이터베이스 클러스터를 통해 자원 활용률을 향상시킬 수 있습니다. K8S가 옹호하는 탄력성 효율성은 유일한 것이 아닙니다. — KVM/EC2도 이 문제를 효과적으로 해결할 수 있습니다.\n\n비용 측면에서 K8S와 다양한 오퍼레이터는 데이터베이스 관리의 일부 복잡성을 캡슐화하여 DBA가 없는 팀들에게 매력적입니다. 그러나 데이터베이스 관리를 담당하는 데 사용될 때 줄어드는 복잡성은 K8S 자체를 사용함으로써 도입되는 복잡성과는 비교되지 않을 정도입니다. 예를 들어, 무작위 IP 주소 변화와 Pod 자동 재시작은 상태를 저장하지 않는 응용프로그램에는 큰 문제가 되지 않을 수 있지만 데이터베이스에게는 용납할 수 없습니다. 많은 기업이 이러한 동작을 피하기 위해 kubelet을 수정하려고 시도했으며, 결과적으로 더 많은 복잡성과 유지 보수 비용을 도입하게 됐습니다.\n\n“비용 감소와 효율성 향상으로부터 비용 감소와 복잡성 최소화로”에서 언급한 대로, 지적 능력은 공간적으로 축적하기 어렵습니다. 데이터베이스에 문제가 발생하면 데이터베이스 전문가가 해결해야 하고, Kubernetes에 문제가 발생하면 K8S 전문가가 살펴봐야 합니다. 그러나 데이터베이스를 Kubernetes에 넣으면 복잡성이 결합되어 상태 공간이 급격히 증가하지만 개별 데이터베이스 전문가와 K8S 전문가의 지적 대역폭을 쌓기 어렵습니다. 문제를 해결하기 위해서는 이중 전문가가 필요하며, 이러한 전문가들은 명백히 순수한 데이터베이스 전문가보다 훨씬 더 드물고 비쌉니다. 이러한 건축적인 연출은 대다수의 팀, 상위 퍼블릭 클라우드/대기업을 포함해 대규모 장애가 발생할 경우 주요 진전의 원인이 될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 클라우드 네이티브 열풍\n\n흥미로운 질문이 제기됩니다: K8S가 상태 유지 데이터베이스에 적합하지 않다면, 왜 많은 기업들, 대기업 포함, 이에 급급한 걸까요? 그 이유는 기술적인 측면이 아닙니다.\n\nGoogle이 내부 Borg 우주선을 본따 만든 K8S 전함을 오픈소스로 공개했고, 뒤처지지 않으려는 매니저들이 Google과 동등한 위치에 있을 것이라 생각하여 K8S를 채택하기에 급급했습니다. 그런데 Google 자체는 K8S를 사용하지 않고 있어, AWS를 방해하려고하거나 산업을 오도하기 위한 것이 더 가능성이 높습니다. 그러나 대부분의 기업은 Google과 같은 인력을 운영하기에 훨씬 단순한 방식이 필요할 겁니다. MySQL + PHP, PostgreSQL + Go/Python을 베어 메탈에서 실행하는 것만으로도 이미 많은 기업들이 IPO로 나아가는 길을 걷게 되었습니다.\n\n현대의 하드웨어 환경에서 대부분의 애플리케이션의 복잡성은 전체 수명 주기에 걸쳐 K8S를 사용할 정당성이 부족합니다. 그럼에도 불구하고 K8S를 상징으로 하는 \"클라우드 네이티브\" 열풍은 왜곡된 현상이 되었습니다: 단지 K8S를 사용하기 위해 K8S를 채택한다는 것. 일부 엔지니어들은 자신의 개인 목표를 달성하기 위해 대기업에서 사용하는 \"첨단\"이고 \"멋진\" 기술을 찾아내며, 직장을 옮길 수 있는 기회 혹은 승진을 위해 직장 안정성을 확보하기 위해 복잡성을 더하는 경향이 있습니다. 이 때 그들의 문제를 해결하기 위해 이러한 \"용감한 용사\" 기술이 꼭 필요한지를 고려하지 않습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 네이티브 랜드스케이프는 화려한 프로젝트로 가득합니다. 매번 새로운 개발 팀은 무언가를 도입하고 싶어합니다: 오늘은 헬름, 내일은 쿠벨라. 밝은 미래와 최고의 효율에 대해 크게 이야기하지만, 실제로는 건축적 복잡성의 산과 \"YAML 아이들\"의 놀이터를 만들어냅니다. 최신 기술을 만지작거리고, 개념을 발명하며, 사용자들이 복잡성과 유지보수 비용을 감당하는 대가로 경험과 평판을 쌓는 말이지요.\n\n![이미지](/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_3.png)\n\n클라우드 네이티브 운동의 철학은 매력적입니다 — 모든 사용자를 위해 퍼블릭 클라우드의 탄탄한 예약 기능을 민주화하기 위해서. K8S는 실제로 상태가 없는 애플리케이션에서 뛰어납니다. 그러나 지나친 열정이 K8S를 원래의 의도와 방향에서 벗어나 상태가 있는 애플리케이션을 오케스트레이팅에서 잘못된 결정으로 버거운 상태로 만듭니다.\n\n# 현명한 결정을 내리는 것\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여러 해 전에 K8S를 처음 만났을 때 나도 열정적이었어요. 그곳은 TanTan이었죠. 2만 개가 넘는 코어와 수백 개의 데이터베이스 클러스터가 있었고, 데이터베이스를 Kubernetes에 넣어보고 모든 가능한 Operator를 테스트해보려고 했어요. 그러나 2-3년의 광범위한 연구와 설계 노력 끝에 제가 진정되었고 그 광기를 버렸어요. 대신에 저희 데이터베이스 서비스를 베어 메탈/운영 체제를 기반으로 설계했죠. 우리에게 K8S가 데이터베이스에 제공한 혜택은 문제와 귀찮음에 비해하다는 것을 깨달았거든요.\n\n데이터베이스를 K8S에 넣어야 할까요? 이것은 상황에 따라 다릅니다. 과도한 자원 판매를 기반으로 하는 공개 클라우드 업체의 경우, 확장성과 이용률이 중요할 것이며, 이는 수익과 이윤과 직접적으로 연결됩니다. 신뢰성과 성능은 후순위일 수 있습니다. 그래도 99.9% 이하의 가용성은 매달 25%의 신용을 보상해야 합니다. 그러나 대부분의 사용자, 우리를 포함하여, 이러한 절충안은 다릅니다. 일회성 Day1 설정, 확장성, 자원 사용률은 주요 관심사가 아닙니다. 신뢰성, 성능, Day2 운영 비용은 이러한 데이터베이스의 핵심 속성 중 가장 중요합니다.\n\n우리는 데이터베이스 서비스 아키텍처를 오픈 소스로 공개했어요. PostgreSQL 배포 및 로컬 기반 RDS 대안인 Pigsty입니다. 우리는 K8S 및 Docker의 \"한 번 빌드하고 어디서든 실행\" 접근 방식 대신 다른 OS 배포판 및 주요 버전에 적응했고, Ansible을 사용하여 K8S CRD IaC와 유사한 API를 통해 관리 복잡성을 해결했어요. 이것은 수고스러운 작업이었지만 올바른 선택이었어요. PostgreSQL을 K8S에 넣는 서투른 시도는 세상이 필요로 하는 것이 아니에요. 그럼에도, 하드웨어 성능과 신뢰성을 극대화한 프로덕션 데이터베이스 서비스 아키텍처가 필요합니다.\n\n![Database in Kubernetes](/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n어쩌면 언젠가는 분산 네트워크 스토리지의 신뢰성과 성능이 로컬 스토리지를 넘어서며 주류 데이터베이스가 스토리지-연산 분리를 기본적으로 지원할 때, 상황이 다시 바뀔 수도 있습니다 — K8S가 데이터베이스에 적합해질 수도 있겠죠. 하지만 현재로서는, 제 생각으로는 심각한 프로덕션 OLTP 데이터베이스를 K8S에 배치하는 것은 미숙하고 부적절하다고 믿습니다. 독자 여러분이 이 문제에 대해 현명한 선택을 하시기를 바랍니다.\n\n# 참고\n\n도커에서의 데이터베이스: 좋은 생각인가요?\n\n\"Kubernetes Founder Speaks Out! K8s Facing a Backlash!\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"도커의 저주: 최고의 해결책이라 생각했지만 결국 '죄악'인가?\"\n\n\"디디의 장애로 배우는 것\"\n\n\"Kubernetes에서 PostgreSQL 성능 최적화 기억\"\n\n\"Kubernetes에서 데이터베이스 실행하기\"\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n컴퓨터 하드웨어의 혜택을 다시 누리세요.\n\n비용을 낮추고 효율을 높이는 방법을 찾아보세요.\n\n컴퓨터 하드웨어의 혜택을 다시 누리세요.\n\n우리는 알리바바 클라우드의 역사적 장애로 무엇을 배울 수 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 컴퓨팅을 포기할 시간인가요?\n\n클라우드 SLA는 위약물인가요?\n","ogImage":{"url":"/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_0.png"},"coverImage":"/assets/img/2024-05-18-DatabaseinKubernetesIsthatagoodidea_0.png","tag":["Tech"],"readingTime":14},{"title":"컨테이너 안에서 RStudio 실행하기","description":"","date":"2024-05-18 16:35","slug":"2024-05-18-RunningRStudioInsideaContainer","content":"\n## 로컬 RStudio 설정을 사용하여 컨테이너 내에 RStudio 서버를 설정하는 단계별 가이드\n\n안녕하세요! 이 문서는 로컬 RStudio 설정을 사용하여 컨테이너 내에 RStudio 서버를 설정하는 단계별 가이드입니다. Rocker RStudio 이미지를 사용하여 도커 실행 명령어와 인수를 사용하여 커스터마이징하는 방법을 안내합니다.\n\n이 튜토리얼을 완료하면 다음을 수행할 수 있을 것입니다:\n\n- 컨테이너 내에 RStudio 서버 시작하기\n- 로컬 폴더 마운트하기\n- 로컬 RStudio 설정 복제하기 (색 테마, 코드 스니펫 등)\n- 로컬 Renviron 설정 불러오기\n\n도움이 되길 바라며, 시작해보세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-RunningRStudioInsideaContainer_0.png\" /\u003e\n\n# 소개\n\nRStudio는 R 프로그래밍 언어를 위한 기본 IDE입니다. VScode와 같은 일반적인 목적의 IDE와 달리, RStudio는 R 사용자 및 그들의 요구에 특별히 설계 및 구축되었습니다. 이것이 RStudio가 R 사용자들 사이에서 인기를 얻는 이유 중 하나입니다. 기본적으로 RStudio는 Docker를 지원하지 않습니다. 컨테이너 내에서 RStudio를 설정하고 실행하는 주요 방법은 RStudio 서버 버전을 사용하는 것입니다. 이것은 일부 사용자에게 진입 장벽이 될 수 있는 컨테이너 내에서 서버를 설치하고 설정해야 한다는 것을 의미합니다. 다행히 R 이미지의 주요 소스 인 Rocker 프로젝트는 RStudio 서버가 내장되어 있고 사용 준비가 된 이미지를 제공합니다.\n\n이 튜토리얼에서는 Docker Hub에서 사용 가능한 Rocker RStudio 이미지를 사용할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 준비 사항\n\n이 튜토리얼에 참여하고 아래 코드를 실행하려면 다음이 필요합니다:\n\n- Docker Desktop (또는 대체품)\n- Docker Hub 계정\n- docker run 명령어의 기본적인 이해\n\n# Rocker로 시작하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nThe Rocker Project은 내장된 R 이미지의 주요 허브입니다. base-r, tidyverse, ML-verse, shiny, 지리적 공간 등과 같이 서로 다른 R 환경 설정이 제공됩니다. 물론 RStudio 서버 이미지도 포함되어 있습니다. 사용 가능한 모든 R 이미지 목록은 Rocker의 Docker Hub 페이지에서 확인할 수 있습니다.\n\n![image](/assets/img/2024-05-18-RunningRStudioInsideaContainer_1.png)\n\n이번에는 rocker/rstudio 이미지를 사용할 것인데, 이미지 이름 그대로 RStudio 서버가 설치되어 사용할 준비가 되어 있습니다. docker run 명령을 사용하여 이 컨테이너를 대화형 모드로 실행하고 브라우저를 통해 RStudio 서버에 액세스할 수 있습니다.\n\n이미지를 docker pull 명령으로 가져와 시작해보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n\u003edocker pull rocker/rstudio                                                                                                                                            확인\n기본 태그 사용: latest\nlatest: rocker/rstudio에서 가져오는 중\na4a2c7a57ed8: 가져오기 완료\nd0f9831967fe: 가져오기 완료\ne78811385d51: 가져오기 완료\nc61633a20287: 가져오기 완료\n832cef14f2fb: 가져오기 완료\n8395fbba6231: 가져오기 완료\nfb53abdcfb34: 가져오기 완료\nc942edef0d7f: 가져오기 완료\nDigest: sha256:8e25784e1d29420effefae1f31e543c792d215d89ce717b0cc64fb18a77668f3\n상태: rocker/rstudio:latest에 대한 새로운 이미지 다운로드 완료\ndocker.io/rocker/rstudio:latest\n```\n\n이미지가 성공적으로 다운로드되었는지 확인하려면 docker images 명령어를 사용할 수 있습니다:\n\n```js\n\u003edocker images                                                                                                                                                    확인  36초\n저장소          태그         이미지 ID      작성일         크기\nrocker/rstudio  최신        7039fb162243   2일 전       1.94GB\n```\n\n이제 Rocker Project에서 제안한 명령어를 사용하여 docker run 명령어로 컨테이너 내에서 RStudio를 시작해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n도커를 실행하고 RStudio 서버를 브라우저에서 열기 전에 위에서 사용한 실행 인수를 검토해보겠습니다:\n\n- rm — 컨테이너 종료 시 자동으로 삭제합니다 (터미널에서 control + c를 누름)\n- ti — 대화형 모드로 컨테이너를 실행합니다\n- e — 환경 변수를 설정합니다. 이 경우 서버 로그인 암호를 'yourpassword'로 정의합니다\n- p — 포트 매핑을 정의합니다. 이 경우 컨테이너의 8787포트를 로컬 머신의 8787포트와 매핑합니다\n\n위 명령을 실행한 후, 로컬 호스트 8787번에서 RStudio 서버에 액세스할 수 있습니다 (예: http://localhost:8787). 이때 로그인 페이지가 나타나며, 여기서는 다음을 사용해야 합니다:\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 사용자 이름: rstudio\n- 비밀번호: yourpassword (run 명령에서 설정한 대로)\n\n다음 출력을 기대해야 합니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-RunningRStudioInsideaContainer_2.png\" /\u003e\n\n# 이런! 일시적이네요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기본적으로 Docker 컨테이너는 일회성 모드에서 실행됩니다. 컨테이너에 생성하고 저장한 코드나 입력값은 컨테이너 실행 시간이 종료되면 손실됩니다. Docker를 개발 환경으로 사용하고 싶다면 이는 실용적이거나 유용하지 않습니다. 이 문제를 해결하기 위해 우리는 볼륨(v) 인수를 사용할 것이며, 이를 통해 로컬 폴더를 컨테이너 파일 시스템에 마운트할 수 있습니다.\n\n아래 코드는 볼륨 인수를 사용하여 실행 명령을 실행하는 폴더(e.g., .)를 RStudio 서버 홈 폴더에 마운트하는 방법을 보여줍니다:\n\n```js\ndocker run --rm -ti \\\n-v .:/home/rstudio \\\n-e PASSWORD=yourpassword \\\n-p 8787:8787 rocker/rstudio\n```\n\n이제 브라우저로 돌아가서 지역 호스트 주소인 http://localhost:8787을 사용하여 RStudio 서버를 다시 엽니다. RStudio 파일 섹션에는 마운트된 로컬 폴더에 있는 폴더나 파일을 볼 수 있을 것입니다. 제 경우, 튜토리얼 폴더를 마운트하겠습니다. 이 폴더에는 다음과 같은 폴더가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n.\n├── Introduction-to-Docker\n├── awesome-ds-setting\n├── forecast-poc\n├── forecasting-at-scale\n├── lang2sql\n├── postgres-docker\n├── python\n├── rstudio-docker\n├── sdsu-docker-workshop\n├── shinylive-r\n├── statistical-rethinking-2024\n├── vscode-python\n├── vscode-python-template\n├── vscode-r\n└── vscode-r-template\n```\n\n아래 스크린샷에서 볼 수 있듯이 RStudio 서버에서 로컬 폴더에 접근 가능합니다 (보라색 사각형으로 표시됨):\n\n\u003cimg src=\"/assets/img/2024-05-18-RunningRStudioInsideaContainer_3.png\" /\u003e\n\n이를 통해 컨테이너에서 실행 시 로컬 폴더로 읽고 쓸 수 있게 되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 로컬 RStudio 설정 복제하기\n\n이전 섹션에서는 볼륨 인자를 사용하여 로컬 폴더를 컨테이너에 장착하는 방법을 보았습니다. 이를 통해 컨테이너 안에서 작업하면서 코드를 로컬로 저장할 수 있게 되었습니다. 이번 섹션에서는 우리가 컨테이너 내에 있는 것을 사용한 로컬 RStudio 설정을 적용하는 방법을 살펴보겠습니다. 여기서 아이디어는 컨테이너를 시작하고 로컬 설정으로 RStudio 서버를 실행하여 컨테이너를 다시 시작할 때마다 설정을 업데이트할 필요 없이 로컬 설정을 유지하는 것입니다. 이는 색 테마 설정, 코드 스니펫, 환경 변수 등과 같은 로컬 설정을 로딩하는 것을 포함합니다.\n\n로컬 RStudio 구성 폴더를 가진 도커 실행을 업데이트하기 전에, 로컬과 컨테이너 내의 config 폴더의 경로를 식별해야 합니다. 예를 들어, 내 시스템의 경로는 ~/.config/rstudio이고 아래 폴더와 파일들을 포함합니다:\n\n```js\n.\n├── dictionaries\n│   └── custom\n├── rstudio-prefs.json\n└── snippets\n    └── r.snippets\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n컨테이너 내의 .config/rstudio 폴더도 /home/rstudio/ 아래에 있습니다. 따라서 다음 매핑을 사용할 것입니다:\n\n```js\n$HOME/.config/rstudio:/home/rstudio/.config/rstudio\n```\n\n또한, 로컬 환경 변수를 사용하기 위해 .Renviron 파일을 마운트하려고 합니다. .Renviron 파일은 로컬 머신의 루트 폴더에 있으며, 로컬 파일을 컨테이너 내의 파일로 매핑하기 위해 동일한 접근 방식을 따릅니다:\n\n```js\n$HOME/.Renviron:/home/rstudio/.Renviron\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 모두 함께 추가하고 컨테이너를 다시 시작해봅시다:\n\n```js\ndocker run --rm -ti \\\n-v .:/home/rstudio \\\n-v $HOME/.config/rstudio:/home/rstudio/.config/rstudio \\\n-v $HOME/.Renviron:/home/rstudio/.Renviron \\\n-e PASSWORD=yourpassword \\\n-p 8787:8787 rocker/rstudio\n```\n\n로컬 RStudio 구성 폴더를 컨테이너의 폴더와 연결한 후에는 서버 설정이 이제 내 컴퓨터의 로컬 RStudio 설정과 일치되었습니다:\n\n![Running RStudio Inside a Container](/assets/img/2024-05-18-RunningRStudioInsideaContainer_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 요약\n\n이 튜토리얼은 Rocker의 RStudio 이미지를 사용자 정의하는 데 docker run 명령어를 사용하는 방법에 초점을 맞추고 있습니다. 우리는 볼륨 인수를 사용하여 로컬 폴더를 컨테이너의 작업 디렉토리에 마운트했습니다. 이를 통해 컨테이너 환경에서 작업하고 작업물을 로컬로 저장할 수 있게 되었습니다. 또한 우리는 볼륨 인수를 사용하여 로컬 RStudio 설정을 컨테이너에 복제했습니다. 이를 통해 로컬 환경에서 컨테이너로의 전환이 더 원활해졌습니다. 매개변수를 계속 추가하고 사용함에 따라 명령이 길고 복잡해질 수 있습니다. 실행 설정을 완료하면 Docker Compose를 사용하여 YAML 파일로 전환하는 것이 다음 단계입니다. 컨테이너의 시작 프로세스를 단순화하는 것을 넘어서, Docker Compose는 여러 컨테이너를 시작하는 등 더 복잡한 시나리오를 관리할 수 있게 해줍니다.\n\n# 자원\n\n- RStudio — https://posit.co/products/open-source/rstudio/\n- The Rocker Project — https://rocker-project.org/\n- Docker Hub — https://hub.docker.com/\n","ogImage":{"url":"/assets/img/2024-05-18-RunningRStudioInsideaContainer_0.png"},"coverImage":"/assets/img/2024-05-18-RunningRStudioInsideaContainer_0.png","tag":["Tech"],"readingTime":10},{"title":"디커Docker가 죽었나요","description":"","date":"2024-05-18 16:34","slug":"2024-05-18-Isdockerdead","content":"\n간단한 답변은 \"예\"이며, 그 이유는 여기에 있습니다:\n\n최근에 나는 도커가 더 이상 사용되지 않는다고 한 인스타그램 스토리를 올렸어.\n\n일부 사람들은 이 아이디어에 동의하지 않았어;\n\n그래서 나는 자세히 이야기하려고 해.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 가상화 구성 요소 (가상 머신 및 컨테이너)에 대해 이야기해 보겠습니다.\n\n가상화는 자원을 공유하는 것이 중요하죠. 그래서 구성 요소를 두 가지 주요 카테고리로 나눌 건데요;\n\n1. 메인 구성 요소\n\n2. 관리 구성 요소\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-Isdockerdead_0.png\" /\u003e\n\n그래서 우리가 볼 수 있는 것은 CPU와 RAM과 같은 컴퓨팅 자원을 공유하는 하나, 저장 공간을 공유하는 하나, 네트워크를 공유하는 하나로 주요 구성 요소가 3개 있다는 것입니다.\n\n이는 가상 머신과 컨테이너 개념 모두에서 작동합니다.\n\n이제 관리 구성 요소를 살펴보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![](/assets/img/2024-05-18-Isdockerdead_1.png)\n\n이 3가지 주요 구성요소 외에도 이미지를 관리하는 데 필요한 하나와 API(GUI 또는 CLI)도 필요합니다.\n\n요약하면, 가상화 세계에서 작동할 수 있도록 5개 구성 요소가 필요합니다.\n\n컨테이너의 세계에서 docker는 모든 이러한 구성 요소를 제공하기 때문에 이미 docker가 모든 솔루션을 갖춘 것처럼 좋다고 생각할 수 있습니다. 그러나 조금만 기다려보세요. 더 설명해 드릴게요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 실제로 제품 환경에서 모든 구성 요소가 필요한지 정말로 필요할까요? 제 생각에는 아니죠. 제품 환경에서 이미지를 빌드할 필요는 없습니다. 제품 환경에서는 Kubernetes와 같은 다른 Orchestration 도구를 사용해야 할 수 있습니다. 따라서 발생하는 상황은 꼭 필요하지 않은 많은 도구와 레이어가 설치되어 있는 제품 환경입니다.\n\n하지만 Docker와 같은 올인원 솔루션이 개발 환경에서는 괜찮아 보입니다. 저는 개인적으로 선호하지는 않습니다.\n\n원하시는 대로 개별적으로 필요한 도구들을 설치하고 사용할 수 있습니다.\n\n여기에는 필요에 따라 설치하고 사용할 수 있는 이러한 구성 요소(도구)에 대한 간단한 소개가 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPodman: 컨테이너 생성 및 삭제에는 레드햇과 오픈 소스 커뮤니티에서 적극 유지보수 중인 Podman을 사용할 수 있습니다.\n\nBuildah: 레드햇에서도 지원하는 이미지 생성용 빌더입니다.\n\nKaniko: 구글이 개발한 이미지 생성 도구로, 구글은 지원하지 않지만 오픈 소스 커뮤니티에서 활발히 유지보수 중입니다.\n\n네트워킹 부분에서는 Podman을 사용하면 Netavark라는 네트워킹 백엔드가 함께 제공되지만, 다른 CNI로 변경할 수도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCNI은 컨테이너 네트워킹 인터페이스의 약자로, 컨테이너(팟)의 네트워킹을 관리하는 데 사용됩니다.\n\nweave, flannel, calico 및 cilium과 같은 많은 CNI가 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-Isdockerdead_0.png"},"coverImage":"/assets/img/2024-05-18-Isdockerdead_0.png","tag":["Tech"],"readingTime":4},{"title":"비정형 데이터 퍼널","description":"","date":"2024-05-18 16:32","slug":"2024-05-18-TheUnstructuredDataFunnel","content":"\n만약 당신이 Medium 회원이 아니라면, 여기서 무료로 읽을 수 있습니다.\n\n# 소개\n\n비구조화 데이터는 다양한 형태를 가지고 있습니다. 일반적으로 텍스트가 많지만, 날짜, 숫자, 사전과 같은 데이터도 포함될 수 있습니다. 데이터 엔지니어들은 주로 깊게 중첩된 json 형식의 비구조화 데이터를 다루게 됩니다. 그러나 \"비구조화\" 데이터라는 용어는 실제로 탭형식이 아닌 모든 것을 말합니다; 사실, 세계 데이터의 80%가 비구조화 데이터입니다.\n\n비구조화 데이터는 우리 데이터 전문가들에게는 무해해 보일 수 있지만, 전체적으로는 큰 파장을 일으키고 있습니다. 실제로 GPT 모델은 모두 비구조화 데이터로 훈련됩니다. 이는 최근 Snowflake의 수익 발표에 관한 Tomasz Tunguz의 기사에서 올바르게 관찰되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TheUnstructuredDataFunnel_0.png\" /\u003e\n\n금융 및 거시경제적 맥락에서 비구조적 데이터를 보는 것이 이상할 수 있습니다. 제 첫 직장은 투자은행이었기 때문에 이런 것을 읽을 때는 향수가 솟습니다. \"비구조적 데이터는 성장 엔진\"은 제게는 말이 되는 것 같아요 — 정말 큰 시장 선풍 같아요!\n\n하지만 파워포인트 상자를 정렬하던 시절이 오래되었죠. 개념적으로 비구조적 데이터는 이제 처리되기를 기다리는 깊게 중첩된 JSON입니다. 하지만 수익 발표를 보면 비구조적 데이터는 이제 단순히 JSON이 아니라 텍스트, 문서, 동영상 등이라는 것이 분명합니다.\n\n중요한 유도자 중 일부에 비구조적 데이터가 자리하고 있으며, 이를 처리하는 곳은 데이터 세계의 두 큰 기업인 Databricks와 Snowflake에게 매우 중요합니다. 왜 그런지 알아봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 왜 비구조화 데이터가 중요한가요?\n\nGPT 모델은 데이터를 기반으로 동작합니다. 특히, 비구조화 데이터를 기반으로 동작합니다. 이는 텍스트 문서, HTML 파일 및 코드 조각과 같은 데이터를 의미합니다. 기업들이 LLM을 제품에 구현하려는 노력이 더해질수록, 이러한 데이터를 처리하는 가치가 증가하며 그에 따라 공급이 증가합니다. 그 결과, Snowflake 및 Databricks와 같은 공급업체에게 해당 데이터의 가치가 상승합니다.\n\n그러나 특정 유형의 비구조화 데이터를 처리하는 데는 두 번째 요소가 있습니다. 중첩된 JSON을 예로 들 수 있습니다. 중첩된 JSON은 처리될 때 언네스팅되거나 정리됩니다. 이는 다음과 같이 변환될 수 있음을 의미합니다:\n\n```js\n{\n  \"outer_key1\": {\n    \"inner_key1\": {\n      \"nested_key1\": {\n        \"deeply_nested_key1\": \"value1\",\n        \"deeply_nested_key2\": \"value2\"\n      },\n      \"nested_key2\": {\n        \"deeply_nested_key3\": \"value3\",\n        \"deeply_nested_key4\": \"value4\"\n      }\n    },\n    \"inner_key2\": {\n      \"nested_key3\": {\n        \"deeply_nested_key5\": \"value5\",\n        \"deeply_nested_key6\": \"value6\"\n      },\n      \"nested_key4\": {\n        \"deeply_nested_key7\": \"value7\",\n        \"deeply_nested_key8\": \"value8\"\n      }\n    }\n  },\n  \"outer_key2\": {\n    \"inner_key3\": {\n      \"nested_key5\": {\n        \"deeply_nested_key9\": \"value9\",\n        \"deeply_nested_key10\": \"value10\"\n      },\n      \"nested_key6\": {\n        \"deeply_nested_key11\": \"value11\",\n        \"deeply_nested_key12\": \"value12\"\n      }\n    },\n    \"inner_key4\": {\n      \"nested_key7\": {\n        \"deeply_nested_key13\": \"value13\",\n        \"deeply_nested_key14\": \"value14\"\n      },\n      \"nested_key8\": {\n        \"deeply_nested_key15\": \"value15\",\n        \"deeply_nested_key16\": \"value16\"\n      }\n    }\n  }\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음과 같이 변경하겠습니다:\n\n```js\n{\n  \"deeply_nested_key1\": \"value1\",\n  \"deeply_nested_key2\": \"value2\"\n}\n```\n\n두 번째 JSON을 처리하는 것은 데이터의 초기 정리에 비해 더 적은 계산이 필요합니다. 처음에 처리되는 훨씬 큰 객체의 경우 \"청소\"가 데이터 파이프라인 내 어디에서 일어나는지가 사용되는 계산에 상당한 영향을 미칩니다.\n\n모든 비구조화된 데이터가 이러한 패턴을 따릅니다. Snowflake의 문서 AI는 pdf와 같은 문서를 가져와 데이터를 표 형태로 추출합니다. 이는 처리의 주된 부분이 한 번 일어나고 결과 데이터가 훨씬 깨끗하고 처리하기 쉽다는 것을 의미합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 비구조화 데이터 퍼널\n\n클라우드 벤더들인 Snowflake와 Databricks와 같은 곳에게 데이터 처리가 어디에서 발생하는지에 대한 주목이 중요합니다. 왜냐하면 그들은 클라우드 컴퓨팅에 기반하여 요금을 부과하기 때문입니다. 즉, 필요한 계산 파워가 더 많아질수록 그들에게 더 많은 비용을 지불해야 합니다. 우리는 이전 섹션에서 LLMs로 인해 비구조화 데이터가 점점 중요해지고 있음을 확인하였으나, 또한 비구조화 데이터를 처리하는 데 필요한 계산이 계속해서 줄어든다는 것을 봤습니다. 데이터 파이프라인을 통해 데이터가 계속해서 처리될수록 데이터가 깨끗하고 집계된다는 것은 직관적입니다.\n\n우리는 데이터 파이프라인 인프라가 어떻게 보이는지 상상하면서 이를 시각화할 수 있습니다. 대부분의 경우, 우리는 일반적으로 다음과 같은 아키텍처의 하위 집합을 가지고 있습니다:\n\n## 데이터 이동\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n퍼널의 첫 번째 섹션은 데이터 팀이 비구조화된 데이터와 처음으로 접촉하는 곳입니다. 이는 일괄 처리든 스트리밍 아키텍처든 어느 쪽이든 데이터 이동 계층입니다. 이 계층에는 저장 요소가 없지만, Fivetran, Portable 또는 Striim과 같은 벤더들은 몇 가지 변환 작업(\"ETL\" 또는 \"ET L\"으로 \"ELT\" 또는 \"EL T\"가 아닌)을 수행하기 위해 투자하고 있습니다. 이는 계산을 사용하고 데이터의 크기를 줄여 다음 계층으로 이동하는 데이터에 영향을 줍니다.\n\n이러한 도구들은 전체 데이터 이력이 없기 때문에 백필이나 천천히 변하는 차원과 같은 복잡한 작업을 수행할 수 없기 때문에 처리할 수 있는 내용에 제한이 있습니다. 그러나 이러한 도구들은 스트림을 조인하거나 비구조화된 데이터를 해체하는 것과 같은 간단한 변환 작업에 적합합니다. 이러한 대부분의 벤더들은 어차피 텍스트 파일과 같은 비구조화된 데이터를 다루지 않습니다. 이러한 서비스는 Azure EventHub, BigQuery PubSub와 같은 클라우드 네이티브 서비스를 사용할 수 있습니다. 따라서 이 로고들은 퍼널의 이 부분에 영향을 줍니다.\n\n이 계층에서 얻을 수 있는 계산 리소스: 중간\n\n## 데이터 레이크 / 객체 저장소\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n두 번째 층은 Google Object Storage, AWS S3 또는 Azure ADLS Gen-2와 같은 객체 저장소에 있는 데이터를 말합니다. 이들은 모든 파일 형식의 데이터를 저장하는 세 대 클라우드 제공 업체의 저장소 솔루션입니다. 이 퍼널의 이 층은 모든 데이터가 중앙 집중화되고, 모든 형태의 컴퓨팅이 쉽게 사용 가능한 첫 번째 층입니다. 이 층에서는 클라우드 제공 업체로부터 직접 임대하거나 Databricks for Spark와 같은 업체를 통해 컴퓨팅을 이용할 수 있습니다. 이 층은 복잡한 프로세스를 처리하기에 좋은 후보이며, 특히 차원과 복잡성을 줄이는 데 탁월합니다. 이는 관련 컴퓨팅이 매우 높음을 의미합니다.\n\n내 의견으로는 이 층이 비구조화된 데이터를 처리하는 데 가장 적합한 곳입니다. 여기에는 무엇이든 저장할 수 있습니다. 호환 가능한 클라우드 인프라가 엄청나게 많기 때문에(모든 것이 S3와 상호 작용할 수 있음), 처리된 데이터를 위한 준비된 저장소 계층이 있습니다. 데이터 웨어하우스보다 유연성이 높기 때문에 이 유형의 처리를 여기서 하는 것이 매우 합리적합니다. 데이터 레이크는 모든 형식의 데이터를 보관하도록 만들어진 것이기에, 바로 비구조화된 데이터가 그것이 아닌가요?\n\n컴퓨팅 가능성: 매우 높음\n\n## 데이터 웨어하우스 / SQL 층\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n해당 단계는 특정 형식 또는 특정 형식 세트로 저장된 데이터를 가리키며, 일반적으로 SQL과 유사한 문장을 사용하여 쉽게 쿼리하고 조작할 수 있도록 합니다. Snowflake은 자체 파일 형식을 갖고 있어 이를 용이하게 만들어주며, 데이터를 \"Snowflake로 가져오기\" 위해 \"진입 요금\"을 내야 하는 이유입니다. Databricks 측에서는 .delta를 갖고 있는데, 이는 사실 .parquet 위에 추상화된 것입니다. 또한 오픈 소스입니다. .iceberg와 같은 다른 포맷도 있으며, 이는 Snowflake의 외부 테이블을 지원하여 (이는 Snowflake를 터널의 더 높은 단계로 끌어올립니다).\n\n이 영역은 구조화된 데이터 또는 표 형식의 데이터를 처리하기에 적합합니다. 그러나 JSON을 평평하게 만드는 작업과 같은 연산도 여기서 수행될 수 있습니다 (예: BigQuery나 Snowflake에서 볼 수 있음). 데이터 엔지니어들 사이에서 이 영역이 SQL 기반 컴퓨팅을 최대한 활용하는 최선의 방법이 아닐 수 있다는 인식이 있습니다. 주요 반대 의견은 이러한 작업을 점진적으로 수행하기가 어렵고 느리며 따라서 비용이 많이 든다는 것입니다. 그러나 실제 비용은 이미 데이터를 이동하는 과정에서 발생합니다. 이미 데이터를 터널을 통해 이동하기 위해 비용을 지불했습니다. 데이터를 변환하거나 구조화를 높은 단계에서 수행하고, 그러면 터널을 통해 이동하는 데이터 양이 최소화될 것입니다.\n\n흥미로운 것은 이 부분이 Snowflake 수익 전화에서 주목을 받은 영역이었다는 것입니다. 대부분의 엔지니어들이 비용을 절약하기 위해 가능한 한 터널의 상위에서 데이터 조작을 선호하는 점을 고려하면, \"데이터를 단순히 Snowflake로 가져오기\"라는 교리가 기업 데이터 책임자들과 CIO들에게 호응을 일으킬 수 있다는 가능성이 있습니다. DocumentAI나 SnowPark Container Services와 같은 기능들이 SQL 데이터 웨어하우스와 \"데이터 레이크하우스\" 사이의 경계가 흐려지고 있음을 의미할 수도 있습니다. 동일한 컴퓨팅이 터널의 다른 부분에 있는 데이터에 걸쳐 사용될 수 있습니다.\n\n주의할 점은 데이터 웨어하우스에서 비구조화된 데이터를 처리할 때 발생하는 컴퓨팅 처리의 이중 가격 결제입니다. 만약 Databricks와 같은 서비스를 사용한다면, 클라우드 제공 업체의 컴퓨팅 파워를 사용하여 객체 저장소에 저장된 텍스트 파일을 처리하고 Databricks를 중간 업체로 사용하여 컴퓨팅 처리에 대해 단일 가격 결제를 하게 됩니다. 데이터 웨어하우스를 사용하면 저장소 및 컴퓨팅에 중복적으로 요금을 지불해야 합니다. 또한 그들이 문서를 분석하기 위해 컴퓨팅을 어떻게 사용하는지 정확히 알 수 없으므로 그 부분에서도 약간 더 많은 비용을 지불할 수 있습니다. 데이터 웨어하우스가 외부 테이블을 지원하는 경우에는 전자를 피할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이겹을 마무리하려면— SQL 워크로드를 효율적으로 실행하려면 데이터는 다른 특정 형식이어야 합니다. 이는 데이터를 .delta와 같은 쿼리 가능하고 변환 가능한 형식으로 변환하는 데이터 웨어하우스 시장을 만들었습니다. 비구조화 데이터는 어떤 면에서는 이와 정반대이며 이미 존재하는 위치, 즉 데이터 레이크에 속하는 것으로 보입니다. 이에 대하여 웨어하우스 레이어의 컴퓨팅 리소스를 사용하여 LLMs의 맥락에서 비구조화 데이터 처리를 수행하는 것은 실질적으로 의미가 없습니다. 실제로 일부 인기 있는 Snowflake 사례들은 이미 Snowpark 컨테이너 서비스와 외부 테이블과 같이 컴퓨팅/저장 모델이 더 많이 레이크하우스와 유사한 것들을 보여줍니다.\n\n이용 가능한 컴퓨팅 자원: 높음\n\n## 데이터 활성화 — 분석의 \"마지막 단계\"\n\n파이널 먼션은 퍼널의 끝에 대한 것입니다— 데이터 활성화. 이것은 분석의 \"마지막 단계\"이며, 일반적으로 프로세스가 시작될 수 있는지 확인하기 위해 작은 점검을 수행한 후, 정리된 데이터를 운영 시스템으로 이동시키는 작업을 일컫습니다. 이는 정리된 및 집계된 데이터와 상호작용하는 애플리케이션을 가리킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것들은 전형적인 역 ETL 사용 사례, 대시 보드 또는 자동화된 슬랙/이메일 알림일 수 있습니다.\n\n이 시점에서 모든 데이터(구조화된 및 비구조화된)가 충분히 정리되었을 것으로 예상됩니다. 데이터 엔지니어링, 분석 엔지니어링 및 제품 팀이 모두 이를 검토하고 테스트하고 정리한 것으로 생각됩니다.\n\n이것은 컴퓨팅 측면에서 실제로 할 일이 남아 있지 않음을 의미합니다.\n\n따라서 비구조화 데이터 퍼널의 요소 중에서는 가장 흥미로운 부분이 아니며, 컴퓨팅에 대한 데이터 팀에 지불할 수 있는 가장 적은 기회를 제공합니다. 모든 데이터가 깨끗하고 평탄하며 완벽하기 때문에 더 이상의 작업이 필요하지 않습니다. 게다가 데이터의 크기도 훨씬 작습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 대회 참가 신청: 낮음\n\n# 결론\n\n본 문서는 비정형 데이터 처리에 대한 데이터 전문가들이 새로운 관점을 제시합니다. 비정형 데이터는 텍스트 문서, HTML 파일, 깊게 중첩된 JSON 등이 모두 포함되어 있어 데이터에서 가치를 추출하기 위해 첫 번째 중요한 계산 단계가 필요합니다. 이 처리 단계가 어디서 일어나느냐는 대규모 데이터 클라우드 공급업체에게 중요한데, 이는 사용량과 수익과 밀접하게 관련되어 있습니다. 현재는 특히 LLMs 및 GPT 모델의 배포로 인해 비교적 쓸모없거나 대다수의 데이터 전문가들에게 흥미롭지 않았던 이 데이터에 대한 수요가 만들어지고 있습니다.\n\n퍼널 그림을 통해 데이터 팀이 이러한 번거로운 처리 단계를 미룰수록 총 이동 데이터 양이 증가하여 비용이 증가한다는 것을 알 수 있습니다. 게다가 다양한 파일 형식과 필요한 작업 유형이 다양하기 때문에, 객체 저장소 수준에서 데이터 처리에 집중하는 것이 가장 합리적인 것으로 보입니다. 이는 Snowflake가 비정형 데이터 처리를 용이하게 하기 위해 \"퍼널을 올라가는\" 것으로 잘 나타납니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그리고 클라우드 공급 업체들이 여전히 상승하는 경향을 보일 것인지에 대한 의문을 낳습니다. Gmail에서 이메일을 구문 분석하는 것은 간단할 수 있습니다. 만약 gmail에서 object storage로 데이터를 이동하는 데 특화된 도구가 있다면, 그 도구가 \"T\"도 수행해야 하는 이유는 무엇일까요? 이 경우에는 유용한 정보를 (아마도 AI를 사용하여) 추출하고 레코드의 평면 테이블을 S3에 직접 덤프해야 하지 않을까요? Google 및 Microsoft에 속하는 클라우드 데이터베이스에 가장 유용한 비구조화 데이터가 있는 사실은 Databricks나 Snowflake가 아니라는 점과 데이터 제품 스위트를 갖추고 있다는 점에 대해 어떻게 생각하십니까?\n\n솔직히 말해서, 이 질문에 대한 정확한 답을 모릅니다. 그러나 가능한 한 많은 데이터를 가장 초기에 처리하는 것에는 엄청난 경제적 인센티브가 있다는 점은 확실히 알고 있습니다. 상승할 수 있는 한 얼마나 먼 거리인지는 논쟁이 될 수 있습니다. Snowflake의 성공을 보면 회사들을 나이트를 시작하기 전에 Snowflake로 데이터를 이동하도록 설득하는 능력을 나타냅니다. 수십만 달러에 이르는 비즈니스 인텔리전스 도구들의 시대는 끝났습니다. S3를 위한 전투가 시작되었습니다! 🔥\n","ogImage":{"url":"/assets/img/2024-05-18-TheUnstructuredDataFunnel_0.png"},"coverImage":"/assets/img/2024-05-18-TheUnstructuredDataFunnel_0.png","tag":["Tech"],"readingTime":11},{"title":"마이크로소프트 Fabric 및 Databricks 열에서 기본 키와 외래 키, 그리고 고유성을 강제하는 낮은 수준의 도전","description":"","date":"2024-05-18 16:31","slug":"2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns","content":"\n![이미지](/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_0.png)\n\n전통적인 관계형 데이터베이스의 가장 강력한 기능 중 하나는 데이터 일관성과 데이터 품질과 관련된 주요 키와 해당 고유성을 보장하는 것입니다. 이는 외래 키와 고유 열에도 해당됩니다.\n\nMicrosoft Fabric Warehouse와 Databricks with Unity Catalog에서 주요 키를 선언하는 것은 가능하지만 이것들은 강제되지 않습니다. Microsoft Fabric에서 심지어 우리는 주요 키를 강제하지 않도록 선언합니다.\n\n![이미지](/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_2.png)\n\n기본 키 열이 고유한 값을 보유하는 것을 보장할 수 없다는 것을 의미합니다. 고유 제약 조건이 있는 열에 대해서도 마찬가지입니다. 이 문제에 대한 완벽한 해결책은 없지만, 이를 이해하면 솔루션을 설계할 때 도움이 될 수 있습니다.\n\n# 왜 오래된 기술에서는 작동할까요?\n\n이것이 강제되지 않는 이유 중 하나를 이해하려면 SQL Server, Postgres 등과 같은 오래된 기술에서 왜 작동하는지 살펴보는 것으로 시작합니다. 많은 전통적인 데이터베이스는 메모리 내 데이터베이스로 볼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n많은 전통적인 데이터베이스는 인메모리 데이터베이스로 볼 수 있습니다. 전체 데이터베이스가 메모리에 맞지 않을 경우 데이터는 디스크에도 저장되고 교환됩니다. DBA가 하는 일은 핫 데이터를 메모리에 정리하고 콜드 데이터를 디스크에 남겨두는 것입니다.\n\n테이블은 데이터 페이지라 불리는 행 단위로 저장됩니다. 페이지는 다양한 방식으로 정리될 수 있으며, 가장 일반적인 방법은 연속적인 heap 또는 B+ 트리 구조에서 인덱싱되는 것입니다. 테이블이 전체 메모리에 있지 않아도 검색할 수 있습니다.\n\n힙에서 처럼 단일 값(기본 키와 같은)을 검색할 때는 처음 페이지의 첫 번째 레코드부터 시작하여 마지막 페이지의 마지막 레코드까지 모든 페이지를 읽습니다. 검색 시간은 테이블 크기에 따라 증가하며 이는 최적화되지 않은 방법입니다.\n\n![이미지](/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nB+ 트리로 색인화된 데이터를 가지고 있는 경우, 많은 데이터베이스 시스템에서처럼, 값을 조회하는 것은 테이블의 크기에 관계없이 3~4 페이지를 조금 건너뛰면 됩니다. 트리는 일반적으로 값을 빠르게 조회하는 데 알려져 있습니다. 나는 색인화된 레코드를 검색하는 여행을 표시했어요. 예를 들어 기본 키가 될 수 있는 단일 값을 검색하는 것처럼요.\n\n![이미지](/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_4.png)\n\n기본 키나 고유한 열을 만들 때 B+ 색인 트리가 생성됩니다. B+ 트리에 삽입할 때 이미 값이 존재한다면, 키 위반 오류가 발생하며, 그렇지 않으면 삽입합니다. 참조 키 확인을 수행할 때, 그림에 나와 있는 것처럼 트리를 탐색합니다.\n\n메모리에 페이지를 인코딩하고 압축하지 않고, 메모리에 액세스하는 것이 매우 빠르기 때문에, 하드웨어 및 설정에 따라 수백만 건의 단일 조회를 초 단위로 쉽게 수행할 수 있습니다. 일부 테이블 정보가 메모리로 로드되지 않은 경우에는 약간의 문제가 발생할 수 있지만, 처리 중에 검색할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_5.png)\n\n# Microsoft Fabric나 Databricks와 비교해 보면 어떻게 될까요?\n\n컴퓨팅과 스토리지를 분리할 때, 데이터는 기본적으로 스토리지에 저장되며 메모리에 저장되지 않습니다(캐싱되는 경우도 있음).\n\nSpark를 예로 들어보겠습니다. Spark 작업을 시작할 때, 스토리지에 있는 데이터는 파티션을 제거하고 파일을 제거하며, 파케이트에서 제거되어 Spark 메모리로 읽히기 전 성능을 높이기 위해 정리됩니다. 작업 중에 누락된 데이터는 검색할 수 없습니다(이에 대한 로직을 작성하지 않는 한). 데이터를 스토리지에서 메모리로 옮기는 데는 메모리에서 데이터를 옮기는 것보다 더 오랜 시간이 걸립니다. 데이터는 여전히 메모리에서 CPU로 이동해야 하지만, 스토리지에서 메모리로 이동하는 추가 단계가 추가됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저장소에 저장된 데이터는 Parquet 형식으로 인코딩되고 압축되어 있으며, 값을 읽기 위해 해제되고 디코딩되어야 합니다. 데이터는 연속적인 방식으로 열 단위로 저장되며, 값들을 찾을 때 힙과 비슷한 속성을 가지고 있습니다.\n\n![이미지](/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_6.png)\n\n한 개 또는 몇 개의 레코드를 찾을 때는 경험이 수용 가능합니다. 이제, 주 키 및 외래 키를 강제하고 100,000개의 레코드 배치를 테이블에 삽입하고자 할 때를 상상해보세요.\n\nSpark는 작업 중에 메모리에 있는 것만 처리할 수 있습니다. 따라서 주 키 삽입용 테이블을 메모리에 로드해야 하며 외래 키가 참조하는 테이블도 로드되어야 합니다. Spark는 데이터를 트리와 같은 검색 최적화된 구조로 로드하지 않기 때문에 모든 레코드 삽입 시 전체 테이블이 확인되어야 합니다. 이 경우에는 100,000번이 될 것입니다. 외래 키 확인도 동일합니다. 목표 테이블이 1,000,000이라고 가정해봅시다. 많은 단일 검색과 테이블 스캔이 필요할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요약하자면, 모든 테이블을 로드하면 초기 대기 시간이 소요됩니다. 디코딩 및 압축 해제가 이 대기 시간을 더욱 증가시킵니다. 선형 데이터 구조에서 값을 조회하면 성장하는 대기 시간으로 인해 스케일링이 나빠지며, 특히 테이블 크기가 커질수록 B+ 트리와 비교했을 때 성능이 상당히 떨어집니다.\n\n그래서 미이크로소프트 패브릭과 데이터브릭스에서 키 및 고유성 강제가 없는 이유 중 하나는 저장 및 계산의 유연성을 제공하고 집계 및 분석 처리를 위한 성능을 제공하지만 데이터에서 단일 검색에 대해 최악의 검색 시간을 갖게되는 것입니다. 그것이 타협점이며, 우리가 여전히 기다리는 이유 중 하나일 것입니다.\n\n# 토의\n\n많은 사람들은 이것을 문제로 보지 않을 수 있습니다. 데이터 웨어하우징에 관한 많은 텍스트는 로드 성능을 높이기 위해 사실에 제약을 두지 말라고 권장합니다. 무결성은 테이블 로드에 관한 정책을 통해 보장할 수 있습니다. 그런 다음 사람들이 그룹화된 카운트를 사용하는 것과 같은 무결성 테스트를 실시하는 것을 본 적이 있습니다. 강력한 필요성이 있다면 전통적인 데이터베이스가 더 나은 해결책일지도 모릅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여전히 일부 처리 엔진 최적화 프로그램은 이 정보를 활용할 수 있으므로, 키를 정의하는 것은 나쁜 습관이 아닙니다.\n","ogImage":{"url":"/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_0.png"},"coverImage":"/assets/img/2024-05-18-MicrosoftFabricandDatabricksThelow-levelchallengeofenforcingprimarykeysandforeignkeysanduniquenessincolumns_0.png","tag":["Tech"],"readingTime":6},{"title":"실무에서 활용하는 MAX_BY의 DBSQL 사용 사례 - Gold Layer Views","description":"","date":"2024-05-18 16:29","slug":"2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews","content":"\n제가 SQL에서 MAX_BY의 가장 좋아하는 사용 사례는 데이터의 골드 레벨 뷰를 열별로 제어하는 것입니다.\n\n![image](/assets/img/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews_0.png)\n\n## 작성자:\n\nCody Austin Davis\n\n## 소개\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 글은 MAX_BY/MIN_BY 집계 함수를 사용하는 가장 일반적인 실제 사용 사례 중 하나를 설명하는 짧고 간결한 글입니다. 이 함수는 종종 발견되지 않는다고 생각되며, 주로 사람들이 존재를 모르기 때문에 덜 주목 받습니다. 이 함수는 알려지지 않은 훌륭한 함수일 뿐만 아니라, 한 번 알게 되면 데이터를 효과적으로 사용하는 여러 방법을 보게 될 것입니다. 오늘은 가장 많이 본다고 생각하는 하나를 다룰 것입니다 — 데이터 소스 간에 데이터에 대한 통합된 뷰를 만드는 것입니다.\n\n## 어떤 사용 사례인가요?\n\n기업들은 자주 여러 데이터 소스를 갖습니다. CRM, 앱 데이터, 공개 데이터 소스, 심지어 공급망에서 다양한 고객/이해관계자로부터 받은 데이터도 마찬가지입니다. 이럴 때, 여러 데이터 소스에서 동일한 엔터티를 나타내는 데이터가 실제로 여러 곳에서 들어온다는 것은 흔합니다. 예를 들어, \"고객\"이라는 엔터티라고 가정해봅시다. 소매 웹사이트를 운영 중이라면, 여러 곳에서 고객 데이터를 얻을 수 있으며, 더 나아가 이러한 데이터 소스 간에 해당 고객에 대한 다양한 데이터 포인트를 얻을 수 있습니다. 주문, 고객 프로필, 반품, 리뷰 등이 있습니다. 분석에서 가장 가치 있는 통찰은 모든 이러한 데이터 소스를 특정 고객에 대한 완전하고 통합된 뷰로 펼치는 경우에만 얻을 수 있습니다. 이때 MAX_BY가 도움이 됩니다!\n\n예제를 살펴보겠습니다. 여러 데이터 소스에서 고객 정보를 받아 \"고객\" 테이블에 입력하는 시스템을 가정해보겠습니다. 그런 다음 모든 이러한 데이터 소스에서 가져온 모든 고객 레코드를 \"통합된 뷰\"로 통합하여 각 \"마스터 고객\"에 대한 가장 최근의 정의를 나타내는 방식입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Customer Table Example 1](/assets/img/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews_1.png)\n\nHere is an example output of the customer table, assuming each record is from a separate data source:\n\n![Customer Table Example 2](/assets/img/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews_2.png)\n\nUsually, this requires a sort of fuzzy matching Entity Resolution (blog coming soon on this topic) system for this type of use case, but for the sake of brevity, we will assume that we are already able to “stitch” these disparate records together to identify entities that are the same and link them with a master_customer_id. This can also apply to other scenarios where we just want to create a unified view for an event across entities as well (customers, orders, returns, etc). We will review 3 ways to create the “Unified View”.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 1 — 가장 최근 고객 레코드 선택하기\n\n가장 명백한 아이디어입니다. 우리는 그냥 가장 최근 업데이트된 레코드를 \"마스터 고객\" 레코드로 만들면 됩니다. 이것은 쉽고 이해하기 쉽지만, 모든 데이터 소스의 데이터를 동시에 효과적으로 활용할 수 없다는 단점이 있습니다. 예를 들어, Shipment 데이터 소스에 전화번호가 누락되어 있지만 Order 데이터 소스에는 전화번호가 있지만 Shipment 데이터 소스가 가장 최근 레코드인 경우, 우리의 뷰는 마스터 뷰에서 전화번호를 NULL로 표시할 것입니다. 우리의 그림은 완전하게 보이지 않고 견고하지 않습니다. 이 뷰와 출력의 SQL 예제는 다음과 같습니다:\n\n```js\n-- 윈도우 함수 및 QUALIFY를 사용하여 가장 최근 마스터 id 레코드 선택하기\nSELECT\n*\nFROM customers\nQUALIFY ROW_NUMBER()\n  OVER (PARTITION BY master_customer_id ORDER BY update_timestamp DESC) = 1;\n```\n\n\u003cimg src=\"/assets/img/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews_3.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 방법에는 중요한 제한이 있습니다. 작은 예제에서는 일부 데이터가 누락되었습니다. SSN을 살펴보세요. 다른 데이터 소스에 이 속성이 있지만 가장 최근 레코드가 아닌 경우, 해당 데이터는 사용되지 않을 것입니다. 이 문제를 해결해 보겠습니다.\n\n## 2 — “마스터” 엔티티로 그룹화하고 각 열에서 랜덤 레코드 선택하기\n\n이것은 가장 일반적으로 볼 수 있는 구현 방법입니다. 일부 사용 사례에 적합하며, 단일 출력 레코드를 위해 모든 고객 데이터 소스에서 데이터를 활용할 수 있습니다. 따라서 1개의 데이터 소스에서 속성이 누락되었지만 다른 데이터 소스에 해당 속성이 있는 경우(예: Shipment 데이터 소스에 전화 번호가 누락되어 있지만 주문 데이터 소스에 전화 번호가 있는 경우), 데이터 소스 간에 공란을 채워 더 완전한 그림을 얻을 수 있습니다. 하지만 이는 각 열에 대해 가장 최근 레코드 업데이트를 선택하는 것은 아니므로 아주 강력한 구현은 아닙니다. 단지 각 열의 non-null 값을 선택하기 위해 MAX/MIN과 같은 단순한 집계 함수를 사용하는 것뿐입니다. 이 구현은 다음과 같습니다:\n\n```js\nSELECT\n  master_customer_id,\n  MAX(customer_name) AS customer_name,\n  MAX(state) AS state,\n  MAX(city) AS city,\n  MAX(postcode) AS postcode,\n  MAX(street) AS street,\n  MAX(`number`) AS number,\n  MAX(ship_to_address) AS ship_to_address,\n  MAX(ssn) AS ssn,\n  MAX(phone_number) AS phone_number\nFROM raw_customers\nGROUP BY master_customer_id;\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이렇게 하시면 좋습니다! 보다 복잡한 데이터 세트를 갖게 되었지만, 여전히 한 가지 문제가 남아 있습니다: 알파벳 순서 외에는 이 쿼리가 어떤 레코드를 선택하는지에 대한 제어권이 없습니다. 고객에 대한 통합된 뷰는 낡았거나 관련성이 낮은 데이터를 포함할 수 있습니다.\n\n3 — MAX_BY를 사용하여 제어 및 목적으로 선택된 레코드를 정의\n\n이것은 의도적으로 고객(또는 다른 레코드)에 대한 뷰를 만드는 가장 좋은 방법입니다. 우리는 각 열에 대해 가장 최근의 NOT NULL 레코드를 선택하기 위해 MAX_BY 함수와 선택적인 FILTER 절을 사용할 것입니다. 이 방법으로, 뷰는 데이터 소스와 상관없이 각 열별로 가장 최근의 NOT NULL 레코드를 선택하여 사용할 수 있게 됩니다. 그 방법은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n-- \"final\" 정리된 마스터 뷰에 나쁜 데이터가 들어가지 않도록 필터링 규칙 추가\nSELECT\n  master_customer_id,\n  MAX_BY(customer_name, update_timestamp) FILTER (WHERE customer_name IS NOT NULL) AS customer_name,\n  MAX_BY(state, update_timestamp) FILTER (WHERE state IS NOT NULL) AS state,\n  MAX_BY(city, update_timestamp) FILTER (WHERE city IS NOT NULL) AS city,\n  MAX_BY(postcode, update_timestamp) FILTER (WHERE postcode IS NOT NULL) AS postcode,\n  MAX_BY(street, update_timestamp) FILTER (WHERE street IS NOT NULL) AS street,\n  MAX_BY(`number`, update_timestamp) FILTER (WHERE `number` IS NOT NULL) AS number,\n  MAX_BY(ship_to_address, update_timestamp) FILTER (WHERE ship_to_address IS NOT NULL) AS ship_to_address,\n\n-- 예시의 형식을 확인함\n  MAX_BY(ssn, update_timestamp)\n      FILTER (WHERE ssn IS NOT NULL\n              AND length(regexp_replace(ssn, '\\\\D','')) = 9 ) AS ssn,\n  MAX_BY(phone_number, update_timestamp)\n      FILTER (WHERE phone_number IS NOT NULL\n                AND length(regexp_replace(phone_number, '\\\\D','')) = 10) AS phone_number\nFROM raw_customers\nGROUP BY master_customer_id;\n```\n\n이 코드는 더 견고하며 각 열의 가장 최근 레코드 값을 가져올 뿐만 아니라 선택된 레코드의 품질을 제어하기 위해 선택적인 FILTER 절을 추가할 수 있게 해줍니다. 위 예시에서는 각 열의 가장 최근 레코드를 선택합니다. 또한, 더 중요한 열에 대해 레코드를 선택하기 전에 품질을 확인하는 더 많은 규칙을 추가할 수 있습니다. 위 예시에서는 null이 아닌 가장 최근의 전화번호와 소셜 넘버를 선택합니다. 그리고 이는 데이터 자체의 컨텍스트에 따라 유효한 값을 가지는 레코드만 선택합니다. 이것은 Entity의 단일 뷰를 만드는 가장 견고한 방법입니다.\n\n여기까지입니다! MAX_BY는 흔히 보기 어렵지만, 아마도 이것이 데이터 모델을 효과적이고 창의적으로 구축하는 데 도움이 될 것입니다.\n\n노트북 예시의 전체 코드는 여기서 확인하실 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews_0.png"},"coverImage":"/assets/img/2024-05-18-RealWorldUseCaseforMAX_BYinDBSQLGoldLayerViews_0.png","tag":["Tech"],"readingTime":7},{"title":"델타 레이크 리퀴드 클러스터링 - 시각적 설명","description":"","date":"2024-05-18 16:27","slug":"2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation","content":"\n최소한의 노력으로 레이크하우스 데이터 저장 레이아웃을 최적화하는 방법\n\n![image](/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_0.png)\n\n# 소개\n\n데이터 레이크하우스는 오픈 테이블 형식을 사용하고 특정 공급 업체에 얽매이지 않아 장점을 누립니다. 그러나 이는 특정 읽기 및 쓰기 작업을 위해 데이터 처리를 최적화하기 위해 파일 저장 레이아웃을 최적화해야 한다는 추가적인 부담과 함께 옵니다. 읽기 또는 쓰기 작업에 의해 처리되는 데이터 양을 최소화하기 위해 가능한 한 많은 파일을 제거함으로써 작업을 효율적으로 만드는 것이 핵심 아이디어입니다. 제거는 특정 파일이 해당 쿼리에 관련이 없다는 암묵적 또는 명시적 메타데이터를 사용하여 발생합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n옛날에, Hive은 각 데이터 파티션을 HDFS 또는 클라우드 저장소의 단일 폴더로 범위를 지정하여 유명한 Hive 스타일의 파티셔닝을 소개했습니다. 그것은 작동이 잘 됩니다. 그러나 작은 파일 문제가 발생하거나 워크로드 특성 변경으로 인해 파티션 체계를 변경해야 할 때 문제가 발생합니다. 또한 Hive 스타일의 파티셔닝은 고 카디널리티 질의에 대해 도움이 되지 않습니다.\n\n오픈 테이블 형식에서 제공되는 DML 지원으로 인해, 조각 모음이나 GDPR에서 잊혀져야 할 권리와 같은 경우를 관리하기 위해 단일 또는 몇 개의 레코드를 업데이트/삭제하는 것이 매우 일반적해졌습니다. 이러한 시나리오에는 고 카디널리티 질의가 효율적이어야 합니다. 이러한 요구 사항을 충족하기 위해 Delta Lake Z-Ordering과 같은 기술이 소개되었습니다. Z-Ordering은 꽤 좋지만 OPTIMIZE 명령을 다시 실행할 때 전체 테이블(또는 파티션)을 최적화하는 반복적인 노력과 많은 낭비된 컴퓨팅 파워를 도입하는 일부 제한 사항이 있습니다. Delta Lake Z-Order의 더 자세한 탐구를 위해 Z-Order에 대한 저의 글을 살펴보십시오. 그 글에서는 낮은 수준의 세부 사항도 약간 논의됩니다.\n\nHive 스타일의 파티셔닝과 Z-Ordering의 이러한 제한 사항을 완화하기 위해 Databricks 및 Delta Lake 팀은 액체 클러스터링을 소개했습니다. 작성 시점에서 Delta Lake on Databricks에서는 아직 미리보기 상태이며 OSS Delta Lake에서는 실험적인 기능인 상태입니다. 그러나 설계 문서는 누구나 읽을 수 있습니다. 액체 클러스터링은 레코드-파일 할당 방법으로 Hilbert Curve를 사용할 것으로 예상됩니다. 액체 클러스터링의 비전은 다음과 같은 단일 최적화 기술을 가지는 것입니다:\n\n- 저 및 고 카디널리티 질의에 모두 잘 작동합니다.\n- \"이미 최적화된\" 파일을 최적화할 필요가 없습니다.\n- 클러스터링 열을 변경하면 전체 테이블을 다시 빌드할 필요가 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물에서는 액체 클러스터링이 레코드를 파일에 할당하는 방식을 시각적으로 보여줄 것입니다. 목표는 기술적인 세부 내용을 파헤치는 대신에 해당 기술의 매우 높은 수준의 이해를 갖는 데 초점을 맞추는 것입니다. 여전히 상황이 조리실에 있기 때문에 세부 사항에 대해 심층적으로 파고들지 않습니다.\n\n# 기본으로 돌아가기 — 레코드를 파일에 할당하는 방법은?\n\n우리는 N개의 레코드가 있고 이를 M개의 파일에 쓰려고 한다고 가정해 봅시다. 파일 가지치기의 아이디어를 기억한다면, 비슷한 레코드를 동일한 파일에 저장하는 것이 필수적입니다. 작업 부하에 따라 비슷한 레코드는 같은 픽업 동네의 택시 여행이거나 같은 고객의 은행 거래일 수 있습니다.\n\n아래 streamlit 앱은 이 문제를 처리하는 데 3가지 방법을 보여줍니다. N 및 M에 대한 다양한 값을 사용하고 배치 방식을 조정하여 레코드가 파일에 할당되는 방식을 시각적으로 확인할 수 있습니다. 이 간단한 앱에서는 모든 레코드가 필드 그룹을 갖고 있지만 우리는 2차원 평면 상 좌표인 x 및 y라는 두 개의 정수 필드에 대한 쿼리를 최적화해야 합니다. 레코드는 N개의 레코드를 생성하도록 x와 y의 쌍별 조합을 균등하게 다루기 위해 생성됩니다. 배치 방법 선택에 따라 각 지점(레코드)이 특정 파일에 할당되며 이 할당은 파일 색상을 사용하여 지정됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 랜덤 할당\n\n이 방식은 사용자 정의 로직을 거의 사용하지 않습니다. 레코드가 무작위로 파일에 할당됩니다.\n\n![Image](/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_1.png)\n\n2. Z-Ordering 할당\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 방법은 Z-Ordering을 사용하여 각 레코드 (x와 y의 조합)마다 Z-Order 값을 계산하는 것입니다. 이는 평면 상의 이차원 점을 선 상의 점으로 효과적으로 변환합니다. 그런 다음 선을 M개의 세그먼트로 나눌 수 있으며, 각 세그먼트는 하나의 파일을 나타냅니다. 레코드가 Z-Order 값 z를 갖고 있다면, 파일 z % M에 할당됩니다. 이제 점들은 일차원 관련 값을 갖고 있기 때문에, 그러한 값들을 선으로 연결하여 매핑이 어떻게 이루어지는지 시각적으로 확인할 수 있습니다. 각 점 위에 마우스를 올려놓으면 선형 순서 값을 볼 수 있습니다.\n\n![이미지](/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_2.png)\n\n공간적으로 서로 가까운 레코드들은 Z-Order 라인 상에서 서로 가까이 배치됩니다. 예를 들어, 위 스크린샷을 보면, 점 (2,4)와 (3,4)는 각각 36과 37의 Z-Order 값을 가지고 있습니다. (0,4)에서 (7,3)으로 이동하는 것과 같이, 공간적으로 멀리 떨어져 있지만 연이은 Z-Order 값을 가진 큰 점프가 보이기도 합니다. 그럼에도 불구하고, Z-Ordering은 좋은 데이터 로컬리티 할당을 생성합니다.\n\n3. 힐버트 곡선 할당\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n세 번째 방법은 레코드마다 두 차원 x와 y 값에 기초한 일차원 값을 할당하기 위해 힐버트 곡선을 사용하는 것입니다.\n\n![image](/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_3.png)\n\n이 Python 라이브러리를 사용하여 두 차원 점에 대한 힐버트 곡선 값을 도출했습니다. 이는 Z-Order와 비슷한데, 서로 가까운 포인트들은 동일한 파일에 들어가게 되지만, 일차원 할당에서 멀리 떨어진 지점이 연속적으로 배치되는 급격한 점프가 없다는 추가적인 이점이 있습니다.\n\n이제 우리는 Z-Order와 힐버트 곡선과 같은 공간 채우기 곡선을 사용하여 파일에 포인트를 할당하는 방법에 대한 아이디어가 생겼으니, Databricks에서 Liquid Clustering을 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Liquid clustering in action\n\n이 섹션의 실험은 최소한이지만 대표적입니다. 필요한 설정은 다음과 같습니다:\n\n- Azure 무료 평가판 계정 및 무료 Databricks 계정\n- Liqud 클러스터링을 지원하는 최신 DBR인 DBR 13.3을 사용하는 단일 노드 Databricks 클러스터\n- 빠른 속도와 모자이크가 작동하기 위해 클러스터에서 photon을 활성화\n\n우리는 유명한 뉴욕시 택시 데이터 세트를 사용하고 아래 워크로드를 위해 최적화할 것입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 대부분의 쿼리는 데이터의 한 해 또는 몇 해에 대해서 작동할 것입니다.\n- 많은 쿼리는 픽업 위치(위도 및 경도)를 기반으로 필터링하는 것이 포함될 것입니다.\n\nDatabricks 워크스페이스에 파이썬 노트북을 만들고 샌드박스 데이터베이스를 생성하는 방법을 시작해보세요.\n\n```js\n%sql\nCREATE DATABASE liquid_db;\n```\n\n다음으로, 맨해튼 섬 주변의 경계 상자를 기준으로 뉴욕시 택시 데이터셋을 기반으로 하는 테이블을 생성해보세요. 이 글의 몇 가지 미학적 이유로 테이블은 초기에 액체 클러스터링을 사용할 수 있지만, 모든 작업이 기본적으로 데이터를 클러스터링하는 것은 아님을 인식하셔야 합니다. 예를 들어, 데이터가 MERGE 작업으로 변경되면, 데이터를 클러스터링하기 위해 OPTIMIZE 작업을 실행해야 할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```sql\nCREATE TABLE liquid_db.trips\n    CLUSTER BY (pickup_datetime, pickup_latitude, pickup_longitude)\nAS\nSELECT *\nFROM delta.`dbfs:/databricks-datasets/nyctaxi/tables/nyctaxi_yellow`\nWHERE\n    pickup_longitude between -74.05186503267184 and -73.83200446816883 AND\n    pickup_latitude between 40.69286486137213 and 40.91947608519337\n```\n\n클러스터링 열 목록에서 첫 번째 열은 타임스탬프 열인 픽업 일시임을 주목해주세요. 우리는 하이브 스타일의 파티셔닝을 사용하기 위해 명시적으로 연도 열을 생성할 필요가 없습니다.\n\n나중에 특정 Delta Lake 트랜잭션에서 생성된 파일이 클러스터링되었는지 여부를 감지하는 방법을 보여줄 텐데요, 제 경우에는 파일이 액체 클러스터링되지 않았기 때문에 직접 클러스터링해야 했습니다.\n\n```sql\nOPTIMIZE liquid_db.trips\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n델타 레이크 Z-오더링과 달리, 리퀴드 클러스터링을 사용하여 테이블을 최적화할 때, 파일이 최적화되었는지 여부를 알려주는 트랜잭션 로그 메타데이터가 있습니다. 따라서 나중에 OPTIMIZE 명령을 실행하여 새로운 데이터를 클러스터링할 때 파일을 건너뛸 수 있습니다. 이러한 경우에 대해 더 많은 아이디어가 있지만, 핵심적인 차이점은 ADD 프로토콜 액션의 태그 부분에 LIQUID_METADATA_ID라는 새 메타데이터 항목이 있는 것입니다.\n\n```js\nimport pyspark.sql.functions as F\nsecond_log_file = \"dbfs:/user/hive/warehouse/liquid_db.db/trips/_delta_log/00000000000000000001.json\"\n(\n    spark.read\n    .json(second_log_file)\n    .where(\"add is not null\")\n    .select(\"add.size\", \"add.tags.*\")\n    .withColumn(\"size\", F.expr(\"cast(size/1024/1024 as int)\"))\n    .withColumnRenamed(\"size\", \"size_mb\")\n    .display()\n)\n```\n\n위 스니펫의 출력에서 제 경우 191개의 파일이 나오며 대부분의 크기는 100에서 300MB 범위에 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_4.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 OPTIMIZE 작업을 위해 트랜잭션 로그 엔트리 안에 수집된 최대 및 최소 메타데이터 값을 검토해 봅시다.\n\n```js\nimport pyspark.sql.functions as F\ndef load_stats_from_commit(commit_file):\n  df = spark.read.json(commit_file).where(\"add is not null\")\n  add_schema = \"\"\"\n  struct\n    \u003c\n      numRecords:long,\n      minValues: struct\u003cpickup_latitude: double,pickup_longitude: double, pickup_datetime: timestamp\u003e,\n      maxValues: struct\u003cpickup_latitude: double,pickup_longitude: double, pickup_datetime: timestamp\u003e\n    \u003e\n  \"\"\"\n\n  stats = (\n    df\n      .select(\"add.path\", \"add.size\",\n          F.from_json(\"add.stats\", add_schema).alias(\"stats\")\n      )\n      .selectExpr(\n        \"substring(path, 1, 10) as file\",\n        \"size\",\n        \"stats.minValues.pickup_datetime as min_pickup_datetime\",\n        \"stats.maxValues.pickup_datetime as max_pickup_datetime\",\n        \"stats.minValues.pickup_latitude as min_pickup_latitude\",\n        \"stats.maxValues.pickup_latitude as max_pickup_latitude\",\n        \"stats.minValues.pickup_longitude as min_pickup_longitude\",\n        \"stats.maxValues.pickup_longitude as max_pickup_longitude\"\n      )\n  )\n\n  stats = (\n    stats\n      .withColumn(\"rect\", F.expr(\n        \"\"\"\n          concat('POLYGON ((' ,\n            min_pickup_longitude, ' ', min_pickup_latitude, ',' ,\n            max_pickup_longitude, ' ', min_pickup_latitude, ',' ,\n            max_pickup_longitude, ' ', max_pickup_latitude, ',' ,\n            min_pickup_longitude, ' ', max_pickup_latitude, ',' ,\n            min_pickup_longitude, ' ', min_pickup_latitude,\n          '))'\n          )\n      \"\"\"))\n  )\n\n  return stats\n\nstats = load_stats_from_commit(second_log_file).orderBy(\"min_pickup_datetime\", \"max_pickup_datetime\")\nstats.display()\n```\n\n위의 \"난해한\" 코드 스니펫은 몇 가지 작업을 수행합니다:\n\n- 픽업 시간, 위도 및 경도에 대한 최소 및 최대 값 수집\n- 가독성 목적을 위해 파일 이름의 처음 10자를 고유 식별기로 사용\n- 파일 내의 모든 여행을 포함하는 경계 상자의 GeoJSON 표현 생성 (픽업 위치에 따라)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n상단의 표 출력물은 특별히 흥미로운 것은 아니며, 파일이 클러스터링 열에 따라 어떻게 배치되었는지 쉽게 전달하지 않습니다. 그러나 이를 어떤 종류의 간트 차트로 시각화한다면, 파일이 시간별 범위를 포함하는 그룹으로 클러스터링되었음이 명백해질 것입니다. 파일 중첩이 발생할 수 있지만, 일반적인 주제는 시간 범위를 기반으로 한 클러스터링을 보여줍니다.\n\n```js\nimport plotly.express as px\nfig = px.timeline(stats.toPandas(),\n    x_start=\"min_pickup_datetime\",\n    x_end=\"max_pickup_datetime\",\n    y=\"file\")\nfig.update_yaxes(categoryorder=\"min ascending\")\nfig.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_5.png\" /\u003e\n\nJan 2009부터 April 2010까지의 파일을 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfile_group = (\n  stats\n    .where(\"\"\"\n    min_pickup_datetime \u003e= '2009-01-01' AND\n    max_pickup_datetime \u003c= '2010-04-30'\n    \"\"\"\n    )\n)\nfile_group.count()\n# 29개의 파일이 인쇄됩니다.\n```\n\n해당 Date Range를 공유하는 이 파일들이 커버하는 지리 공간 영역을 시각화하고 싶습니다.\n\n```js\n%pip install databricks-mosaic==0.4.0\n```\n\n```js\nimport mosaic as mos\nspark.conf.set(\"spark.databricks.labs.mosaic.index.system\", \"H3\")\nmos.enable_mosaic(spark, dbutils)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n%%mosaic_kepler\nfile_group \"rect\" \"geometry\"\n\n![Image](/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_6.png)\n\n동일한 파일 그룹에 대해 특정 날짜 범위를 포괄하는 파일들의 경우, 해당 파일들의 레코드는 잔여 클러스터링 키인 위도 및 경도를 기반으로 클러스터링됩니다. 이러한 공간 클러스터링을 통해 지구상의 특정 지점을 커버하는 파일 수가 현저히 줄어들어 파일 가지치기가 크게 향상됩니다.\n\n# 가지치기 혜택\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같은 쿼리를 실행하면 194개 파일 중 126개 파일을 제거합니다 (첫 번째 커밋에서 최적화되지 않은 파일이 3개 발생했습니다).\n\n```js\nSELECT payment_type, sum(total_amount) as total_amount\nFROM liquid_db.trips\nWHERE pickup_datetime \u003e= '2011-01-01' AND pickup_datetime \u003c '2012-01-01'\nGROUP BY payment_type\n```\n\n![이미지](/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_7.png)\n\n위의 쿼리는 8년 데이터 중 1년치의 집계 결과입니다. 순수 Hive 파티셔닝이면 더 좋은 프루닝이 가능할 수도 있지만, 여전히 집계 쿼리에 대한 일정한 값은 얻을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 같은 해를 사용하지만 타임스 스퀘어 근처의 몇 가지 특정 레코드를 찾아보려 한다면, 더 나은 가지치기를 할 수 있어요.\n\n```js\nSELECT *\nFROM liquid_db.trips\nWHERE pickup_datetime \u003e= '2011-01-01' AND pickup_datetime \u003c '2012-01-01'\nAND pickup_latitude BETWEEN 40.757816 AND 40.757832\nAND pickup_longitude BETWEEN -73.985143 AND -73.985105\n```\n\n![이미지](/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_8.png)\n\n특정 워크로드에 유용한지 확인하기 위해 철저한 테스트와 벤치마킹이 필요하지만, 전반적으로 Delta Lake 테이블의 관리를 간편하게 해주는 Liquid 클러스터링은 매우 유망해 보입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마무리\n\n리퀴드 클러스터링을 사용할 때 고려해야 할 측면이 많으며 특정 사용 사례에 맞는 동작을 조정하기 위해 많은 구성 값을 조정해야 할 것입니다. 본 게시물은 리퀴드 클러스터링이 어떻게 작동하는지를 높은 수준에서 시각적으로 보여주는 작은 시도입니다. 단순화된 사용 사례는 Hive 스타일의 파티셔닝과 Z-Order의 혜택을 결합하여 단일 최적화 방법을 사용하는 것입니다.\n\nliquid_db를 삭제하고 정리하려면 DROP DATABASE liquid_db CASCADE를 실행하는 것을 잊지 마십시오.\n\n# 추가 읽을거리\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 델타 테이블에 리퀴드 클러스터링 사용하기\n- [디자인 문서] [공개] 리퀴드 클러스터링 — Google Docs\n- 힐버트 곡선 코딩 (youtube.com)\n- Yousry Mohamed의 미디엄에서 A부터 Z까지의 델타 레이크 Z-오더링\n","ogImage":{"url":"/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_0.png"},"coverImage":"/assets/img/2024-05-18-DeltaLakeLiquidClusteringAvisualexplanation_0.png","tag":["Tech"],"readingTime":15},{"title":"Lakeview 대시보드를 통한 관측력 시리즈 - 기사 1 DBSQL 웨어하우스 어드바이저","description":"","date":"2024-05-18 16:24","slug":"2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor","content":"\n표 태그를 Markdown 형식으로 변경해보세요.\n\n![Lakeview Dashboard](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_0.png)\n\n## 저자:\n\nCody Austin Davis\n\n# Lakeview 대시보드 템플릿 시리즈 - 기사 1 - DBSQL Warehouse Advisor\n\n## 소개\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLakeview 대시보드는 Databricks SQL에서 사용할 수 있는 새로운 가벼운 대시보드 도구입니다. 막 출시했음에도 불구하고 이미 놀라운 성능을 자랑하는데요. 추가 비용이나 관리 부담 없이 빠르게 대시보드를 개발하고 공유할 수 있는 기능을 제공합니다. 예를 들어, 대부분의 고객이 필요로 하는 가장 중요한 측면 중 하나는 데이터 플랫폼의 가시성입니다. 대부분의 고객이 특정 사용 사례에 대한 모니터링과 가시성을 필요로 하기 때문에 나는 Lakeview 템플릿 중 일부를 공개하여 누구나 가져다 쓰고 자신의 환경에서 사용할 수 있도록 했어요. 여러분의 노력을 아낄 수 있게끔 도와주고 Lakeview 대시보드가 무엇을 할 수 있는지 보여줄 수 있도록 했죠!\n\n이 기사에서는 DBSQL Warehouse Advisor 템플릿을 공유하고 소개할 거에요. 대시보드의 4개 섹션에 대해 간단히 검토하고 사용하는 방법을 가르쳐 드리며 각 섹션을 통해 어떤 핵심 질문을 해결할 수 있는지 논의할 거에요.\n\n먼저, 전반적으로, 이 대시보드가 무엇을 하는지와 어떤 부분에 초점을 맞추는지에 대해 알아볼까요. 공유될 여러 템플릿 중 첫 번째로, 템플릿을 언제, 어떻게 사용할지에 대한 맥락을 제시하고자 합니다.\n\nDBSQL Warehouse Advisor Lakeview 대시보드는 DBSQL에서 데이터 웨어하우스에 대해 필요한 모든 정보를 제공합니다. warehouse_events, billing, 그리고 query_history (system table의 프라이빗 프리뷰, API는 이미 GA에서 사용 가능) 시스템 테이블을 자동으로 구문 분석하여 다음과 같은 작업을 지원합니다:\n\n- 섹션 1 — 요금 모니터 — 시스템 내의 billing.usage 시스템 테이블을 모니터링하여 시간별 비용을 요약합니다. 웨어하우스가 너무 빨리 확장되는 시점을 보여주는 내장된 탄력 지표를 제공합니다. BI 워크로드는 특히 변동이 심할 수 있으므로, 부드러운 탄력 지표는 비용 경보에 대한 더 나은 측정 항목을 제공할 수 있습니다. 이 쿼리를 사용하여 경보를 설정할 수 있습니다!\n- 섹션 2 — 크기 조정 모니터 — warehouse_events 시스템 테이블을 모니터링하여 웨어하우스의 크기 조정 비용과 효율성을 요약합니다. 변동이 심하고 고 동시성 워크로드의 사용량을 예측하고 추정하기 어려울 수 있습니다. 이 시각화를 사용하면 웨어하우스가 다른 크기 조정 수준에서 얼마나 시간을 보냈는지 요약하고 계획하기 쉬워집니다.\n- 섹션 3 — 쿼리 성능 분석 — 이것은 매우 중요한 섹션입니다! (private preview 중인) query_history 시스템 테이블을 사용하여 웨어하우스의 전반적인 성능을 요약하고 문제가 되는 쿼리를 찾거나 병목 현상을 식별하며 SLAs를 추적하고 웨어하우스 시간이 어디에 소비되었는지 파악할 수 있습니다. 이 대시보드 하나에 고수준 모니터링부터 개별 쿼리 성능 튜닝까지 모두 담겨 있어요.\n- 섹션 4 — 쿼리 비용/시간 할당 요약 — 웨어하우스를 사용하여 내부 또는 외부 고객에게 서비스를 제공하고, 소비 기반의 가격 모델에 따라 그들에게 요금을 청구해야 한다면, 이 섹션을 사용하여 쿼리, 사용자 및 쿼리 태그 수준에서 웨어하우스 시간을 할당할 수 있습니다! 데이터 제품 및 많은 하위 팀에 서비스를 제공하는 중앙화된 데이터팀에게 매우 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요약을 보여줬으니 이제 섹션을 살펴보겠습니다. 함께 따라오고 싶다면 템플릿을 다운로드하고 대시보드를 환경에 가져와서 데이터웨어하우스 ID를 입력하면 됩니다!\\* 템플릿을 가져오면 전체 대시보드 시각화와 대시보드를 구동하는 전체 백엔드 쿼리와 매개변수를 확인할 수 있습니다. 이 템플릿은 여러분의 특정한 사용 사례에 맞게 필요한 대로 수정하고 확장할 수 있습니다.\n\n- \\*참고: query_history를 위한 시스템 테이블 비공개 미리보기 상태에 있지 않은 경우, query history API를 사용하여 공개 미리보기가 될 때까지 해당 테이블을 생성할 수도 있습니다.\n\n# 섹션 1 — 요금 모니터\n\n![이미지](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_1.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 DBSQL Warehouse Advisor의 청구 모니터입니다. 이 섹션은 간단합니다. Warehouse Id를 매개 변수에 입력하고 날짜 범위를 선택하여 DBUs 및 달러의 추이를 시간에 따라 볼 수 있습니다. 또한 해당 시간 프레임 내의 총 비용에 대한 큰 숫자 요약도 제공됩니다. 또한 DBSQL Warehouse의 목록 요금과 다른 경우에 사용할 클러스터 단위 가격 매개 변수도 있습니다.\n\n또한 시간에 맞춰 부드럽게 조정된 사용량의 추세를 추적할 수도 있어, 일시적인 사용량 변동에 과도하게 반응하는 것을 피할 수 있습니다. 고동시 BI 워크로드에서 일반적인 것으로, 관리자들은 종종 주어진 시간 범위 내에서 사용량이 특정 %로 상승하는 추세를 지켜보고 경보를 울리고 싶어 합니다. 이 운동량 지표 시각화를 사용하여 이를 수행할 수 있습니다:\n\n![이미지](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_2.png)\n\n이것은 앞서 소개한 \"높은 증가 % 장벽\" 매개 변수와 결합됨으로써, 사용 패턴을 \"높은 사용 증가 추세\"로 판단하고 그것을 강조하여 빨간색으로 표시하는 임계값을 정의할 수 있습니다. 그런 다음 최근 값 쿼리에 LIMIT 1을 추가하여 비용 추세에 대한 경보를 설정하는 데 사용할 수 있는 정확한 기본 SQL 쿼리를 사용할 수 있습니다. 이 지표 차트는 \"이전 기간보다 24시간 이동평균 증가량이 20% 이상 증가할 때 보여줘\"라고 말합니다. 이는 이 기능이 종종 발생하는 일시적인 변동보다 지속적이고 심각한 비용 증가에 대한 경보를 보내는 데 좋은 방법입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 섹션 2 — 데이터웨어하우스 동시성 스케일링 요약\n\n다음 섹션에서는 데이터웨어하우스 동시 사용량을 해석하는 데 도움이 되며, DBSQL의 \"모니터링\" 탭에있는 차트는 매우 가파르고 계획하기 어려울 수 있습니다. 특히 Serverless SQL을 사용할 때는 이 차트를 사용하기 어려울 수 있습니다...\n\n![이미지](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_3.png)\n\n...그리고 이를 예산 및 장기적인 워크로드 / 데이터웨어하우스 비용에 대한 기대로 전환하기 어렵습니다. 더구나, 클러스터 크기, 동시성 설정, 쿼리 성능 변경 시 어떤 일이 발생하는지 확인하기 어렵습니다. 이 탭을 사용하면 더 명확한 예측과 사용량에 대한 기대를 만들 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Dashboard](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_4.png)\n\n이 대시보드는 해석이 어려운 모니터링 탭을 자동으로 가져와 시각화로 변환하여 창고에서 N개의 동시 클러스터로 확장해야 하는 빈도를 더 명확하게 보여줍니다. 좀 더 자세히 살펴보면, 특정 시간 기간 동안 창고가 N개 클러스터로 확장되기까지 소요된 시간 및 총 시간 중 % 비율을 정확하게 볼 수 있습니다.\n\n우리는 창고가 대략 80%의 시간 동안 1개 클러스터가 필요하고, 13%의 시간 동안 2개 클러스터가 필요하며, 대략 7%의 시간 동안 3개 클러스터, 그리고 1%의 시간 동안 4개 클러스터가 필요함을 명확히 볼 수 있습니다. 이를 통해 예측이 어려운 이러한 고비용 워크로드를 시간이 지남에 따라 얼마나 비용이 발생할지 예측하는데 도움이 되는 것은 물론, 이에 대한 변경 사항에 대해 계획하는 것도 더 쉽게 할 수 있습니다. 이 정보는 DBSQL의 어떠한 프로덕션 워크로드에 대비한 계획을 세우는 데 중요합니다.\n\n워크로드를 최적화하거나 POC를 실행하거나 사용 사례를 추가할 경우, 이 대시보드를 사용하여 사용 패턴에 미치는 영향을 정확히 파악하여 미리 계획할 수 있습니다. 이 부분은 작지만 굉장히 유용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 섹션 3 — 쿼리 성능 분석\n\n이 섹션은 가장 크며, 고수준 성능 메트릭부터 실행 시간, 디스크 스피릴, 데이터 읽기 등의 쿼리 수준 세부 사항까지 모두 담고 있습니다. 이 섹션의 세부 사항은 전적으로 별도의 블로그를 작성할 수 있을 정도로 방대하므로, 이 글에서는 포함된 고수준 메트릭 및 이 섹션을 사용할 때 일반적으로 고려할 수 있는 몇 가지 이유에 초점을 맞출 것입니다.\n\n이 섹션에서는 주로 쿼리 실행 시간과 대기 시간에 관심이 있습니다. 먼저 이러한 메트릭을 매우 고수준으로 하나의 큰 숫자 요약으로 살펴보고, 이후에는 SLA 차트와 함께 추세를 자세히 살펴볼 것입니다:\n\n![LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_5](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Lakeview Dashboards for Observability Series Article](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_6.png)\n\n![Lakeview Dashboards for Observability Series Article](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_7.png)\n\n쿼리 실행 시간 및 대기 시간 추이를 확인할 수 있습니다. 이제 데이터 웨어하우스가 언제 더 혼잡하거나 덜 혼잡해지는 지 쉽게 파악할 수 있어 문제를 빠르게 찾을 수 있게 되었습니다. 그러나 실제 워크로드에 대한 평균 실행 시간만 살펴본다고 해결되지 않습니다. 실제 SLA에 따라 쿼리 시간을 추적해야하며, 이를 위해 P90, P95 및 P99와 같은 표준 지표를 더 계산해야 합니다. 이 대시보드는 이러한 지표를 자동으로 계산하고 표시합니다. 위 시각적 자료를 통해 쿼리 실행 시간을 추적하여 쿼리 성능 문제가 발생하는 정확한 시기를 찾을 수 있습니다(중간에 큰 증가를 보았나요? 아마 확인해야할 이상 현상일 것입니다). 웨어하우스가 포화 상태에 있는지 추적하기 위해 동일한 방법으로 쿼리 대기 시간도 살펴볼 수 있고, 웨어하우스가 더 많은 동시성을 필요로 할 수도 있습니다. 실제로 여러분은 이 둘을 결합하여 사용 사례의 SLA 요구 사항에 맞게 클러스터 크기를 조절해야 합니다.\n\n예를 들어, Databricks SQL로 구동되는 Downstream 데이터 애플리케이션이 있다고 가정해보겠습니다. 사용자들은 앱이 대부분의 쿼리를 1~2초 이내 또는 그 이하로 수행할 것으로 예상하며, 10초 이상 걸리는 것은 용인할 수 없습니다. 쿼리 실행 시간 차트의 P99 및 P95 백분위 지표를 확인하여 SLA 준수를 먼저 확인할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_8.png)\n\n우리는 SLA 준수에 대해 멋져 보입니다. 대부분의 쿼리 (P95)가 1초 미만으로 실행됩니다. 우리의 가장 나쁜 쿼리도 약 5초 정도로 우리의 최종 사용자가 허용할 범위 내에 있습니다. 이러한 숫자가 허용 가능한 수준을 초과하면 쿼리를 최적화하거나 창고가 포화되었는지 대기 시간 시각화를 확인할 수 있습니다:\n\n![image](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_9.png)\n\n이제 필요한 SLA 범위 내에 있습니다. 그러나 만약 우리의 P99가 3초였다면 어떨까요? 그럴 경우 문제가 생길 수 있습니다. 먼저 할 일은 위의 대시보드에서 쿼리 대기 시간을 살펴보는 것입니다. 대기 시간은 각 쿼리가 실행할 수 있는 슬롯을 기다리며 대기하는 시간입니다. SLA를 준수할 때는 대기가 괜찮지만 그렇지 않은 경우, 소중한 시간이 낭비되고 더 많은 동시성이 필요합니다! 이 시각화는 평균 쿼리 실행 시간과는 다르게 해석되며, 보통 대기 시간이 낮아야 합니다(~0초). 1초보다 훨씬 높아지면 쿼리가 쌓여서 대기열에 앉아있기 시작한다는 것을 의미하며, 이는 우리의 SLA에 영향을 미칩니다. 갱신된 3초 SLA를 고려한 우리 예시에서, 우리의 P99는 현재 5초이며, 이는 허용할 수 없는 수준입니다. 위 시각화에서 많은 쿼리가 거의 2초씩 대기한다는 것을 볼 수 있습니다! 동시 용량을 늘리는 것이 SLA에 더 가까워지는 데 도움이 될 수 있음을 보여줍니다 (DBSQL의 최소 최대 클러스터).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n**기억하세요 — 원하는 SLA에서 시작해서 거꾸로 진행하세요.**\n\n고수준 성능 지표 외에도 이 대시보드에는 많은 유용한 지표가 있습니다!\n\n![대시보드 이미지](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_10.png)\n\n우리는 쿼리 성능을 상태, 소스 및 문장 유형별로 시간에 따라 추세 분석할 수 있고, 심지어 쿼리 태그별 평균 쿼리 실행 시간도 모니터링할 수 있습니다. 대시보드에 내장된 기능이며, 다음 서명을 가진 템플릿된 코멘트를 찾습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n회사의 특정 사용 사례에 중점을 두어 전체 성능 분석에 도움을 줄 수 있습니다. 특히 ETL 워크로드에서 중요합니다.\n\n더욱 심층적으로 파고들 수 있습니다. \"쿼리 성능 상세\" 하위 섹션으로 이동하여 쿼리에서 발생하는 일반적인 문제와 병목 현상을 식별할 수 있습니다. 대시보드에서는 자동으로 플래그를 계산하여 장기 실행 중인 쿼리, 스피룰이 발생한 쿼리, 그리고 이례적으로 높은 데이터 양을 읽는 쿼리를 식별하는 데 도움이 됩니다.\n\n![image](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_11.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래로 내려가면 각 쿼리당 할당된 비용을 계산하고, 쿼리 태그별로 그룹화할 수 있습니다 (기본적으로 위에서 정의되었지만, 필요에 맞게 이 템플릿을 변경할 수 있습니다!). 또한 성능 문제의 근본 원인을 확인하기 위해 쿼리 수준의 세부 정보를 전체 출력할 수도 있습니다. 대시보드에서는 사용자별 할당된 창고 비용, 사용자별 계산 사용량 % 및 사용자별 쿼리 수를 볼 수도 있습니다.\n\n![image](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_12.png)\n\n이것은 시작점으로서 제공되는 것일 뿐이므로, 여러분의 사용 사례에 맞추기 위해 이 대시보드를 가져오고, 탐색하고, 확장하는 데 자유롭게 사용하세요!\n\n# 섹션 4 — 쿼리 비용 할당 요약\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 섹션은 외부 데이터 제품을 가진 고객이 자신들의 데이터 제품에 합리적인 가격 모델을 개발하기 위해 쿼리 수준의 비용 가시성을 원하는 경우에 대해 우리가 자주 받는 질문입니다.\n\n![이미지](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_13.png)\n\n이 차트에서는 이미 쿼리를 어떻게 할당할지에 대해 작업이 이미 진행되었습니다. 당신은 warehouse_id를 정의하고 쿼리 범위를 선택하며 보고 싶은 \"파레토 지점\"을 정의할 수 있습니다. 이것은 당신에게 당신의 데이터 웨어하우스 전체 계산 시간의 상위 X%를 구성하는 쿼리들을 볼 수 있도록 합니다. 예를 들어, 위의 시각화는 SQL 쿼리가 이 시간대에 웨어하우스 계산 시간의 약 20%를 차지한 것을 보여줍니다. 파레토 분석을 통해 당신은 당신의 웨어하우스 활용도의 가장 큰 부분을 차지하는 쿼리들을 살펴볼 수 있으며, 작고 차이점이 없는 \"long tail\" 쿼리들을 걸러낼 수 있습니다.\n\n요약 뿐만 아니라 대시보드에는 데이터 제품에 대해 세부적인 쿼리 수준 리포트가 포함되어 있어, 당신의 데이터 제품에 대한 세부적인 가격 책정을 할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_14.png\" /\u003e\n\n이 보고서에서는 시간이 어디에 사용되는지 쉽게 확인할 수 있으며, 심지어 엔드 유저와 태그별로도 분석할 수 있습니다! 사용자 실행 분석은 이 쿼리를 실행하는 각 사용자의 실행 횟수와 오류율을 제공합니다. 이 정보는 워크로드에 대한 매우 투명한 비용 할당을 갖도록 필요한 모든 세부 정보를 제공합니다.\n\n주의해야 할 중요한 몇 가지 정의가 있습니다:\n\n데이터 웨어하우스 실행 시간 = 시간 창 동안의 모든 쿼리 실행의 총 실행 시간\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n쿼리 할당 비용 = 쿼리 실행 시간 / 데이터베이스 실행 시간\n\n# DBSQL Warehouse Advisor — DBT Version\n\nDBSQL Advisor 템플릿 외에도, DBT 데이터베이스에서 DBSQL로 푸시된 쿼리의 DBT 메타데이터를 이해하는 DBT 버전도 있습니다. 이를 통해 사용자들은 DBT 모델 및 개별 노드 ID에 대한 추가 정보를 즉시 얻을 수 있습니다.\n\n![이미지](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_15.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 쿼리 분석의 섹션 3과 4에서는 dbt 대상, 프로필 이름 또는 노드 ID와 같은 친숙한 메타데이터로 성능 및 쿼리 할당 지표를 분석할 수 있습니다. 이를 통해 DBT 모델에 대한 리소스가 정확히 어디에 사용되고 있는지 확인할 수 있습니다.\n\n![이미지1](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_16.png)\n\n![이미지2](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_17.png)\n\n![이미지3](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_18.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 대시보드를 사용하면 DBSQL의 Lakeview와 함께 DBT 파이프라인을 이해하고 모니터링하는 데 상당히 도움을 받을 수 있습니다! 내부 분석부터 완전한 데이터 제품 제작까지, 데이터 플랫폼에 대한 완전한 제어 및 시각성을 갖게 됩니다.\n\n# 다음 단계\n\n이 시리즈에서 제공하는 4가지 대시보드 템플릿 중 첫 번째로, 데이터브릭스 사용자들이 시스템 테이블과 Lakeview 대시보드를 통해 일반적이고 강력한 사용 사례에 대해 최대한 활용할 수 있도록 지원하는 것이 목표입니다. 우리가 제공하는 탁월한 기능 뿐만 아니라, 이러한 템플릿은 훌륭한 참조 자료가 되어 앞으로 구축하려는 대시보드에 흥미로운 디자인 패턴으로 사용될 수 있습니다!\n\n대시보드를 지원하는 SQL 논리 및 시각/매개변수 선택의 원천에 대해 깊이 파고들어 설명을 듣고 싶다면, 의견을 남겨주시면 감사하겠습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Lakeview Templates:\n\n- DBSQL Warehouse Advisor\n- DBT Version — DBSQL Warehouse Advisor\n\n## 사용 방법:\n\n- 위 링크에서 JSON 파일을 다운로드합니다.\n- 데이터브릭 워크스페이스의 “대시보드” 탭으로 이동합니다.\n- 오른쪽 상단 모서리에 있는 파란색 “대시보드 만들기” 버튼 옆의 화살표를 클릭합니다.\n- “파일에서 대시보드 가져오기”를 선택하고 다운로드한 JSON 템플릿을 업로드합니다.\n- 대시보드를 로드하고 사용 중인 데이터 웨어하우스 ID를 입력합니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_19.png)\n","ogImage":{"url":"/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_0.png"},"coverImage":"/assets/img/2024-05-18-LakeviewDashboardsforObservabilitySeriesArticle1DBSQLWarehouseAdvisor_0.png","tag":["Tech"],"readingTime":16},{"title":"클라우드 비용 최적화 핀옵스 마인드셋 수용하기","description":"","date":"2024-05-18 16:21","slug":"2024-05-18-OptimizingCostsintheCloudEmbracingaFinOpsMindset","content":"\n![image](/assets/img/2024-05-18-OptimizingCostsintheCloudEmbracingaFinOpsMindset_0.png)\n\n서버리스 서비스를 설계할 때, 퍼즐의 각 조각, 선택하는 각 관리 서비스는 구매 선택입니다. 게다가 프로덕션 급 클라우드 서비스가 추가 비용을 야기하며, 주의를 기울이지 않으면 비용이 빠르게 증가할 수 있습니다.\n\n이 블로그에서는 아낌없는 조직이 FinOps 마인드셋에 기대어 클라우드 서비스의 비용을 최적화하고 효율을 극대화하는 데 중요한 역할을 하는 방법을 배우게 될 것입니다. 클라우드에서 재무와 운영 목표를 조율하는 데 필수적인 전략과 실행 항목을 공유할 것입니다.\n\n서버리스 서비스를 예로 들며, 클라우드 서비스 및 선택한 기술에 도움이 되는 통찰력, 자동화, 문화에 대해 설명할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이러한 통찰은 저의 경험에 근거하여 CyberArk에서 AWS 기반 SaaS 제공 업체의 서버리스 서비스를 설계한 것에 기인합니다.\n\n![이미지](/assets/img/2024-05-18-OptimizingCostsintheCloudEmbracingaFinOpsMindset_1.png)\n\n이 블로그 게시물은 원래 \"Ran The Builder\" 웹사이트에 게시되었습니다.\n\n# 서버리스 비용에 대한 오해\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAWS 서버리스 히어로로서, 클라우드 비용과 서버리스 서비스에 대해 이야기할 때 놓치지 말아야 할 부분을 다루고 싶어요.\n\n서버리스는 사용한 만큼만 지불하고 0으로 스케일링이 가능하다는 것으로 알려져 있죠.\n\n만약 그게 사실이라면, 생산급 서버리스 서비스 비용이 비서버리스 서비스보다 낮을 거라고 생각할 수 있겠죠?\n\n음, 그건 가끔 정확한 말이에요. 확실히 Lambda, SNS, SQS, DynamoDB와 같은 \"참\" 서버리스 서비스에 대해서는 사실이지만, 서버리스에는 더 많은 서비스가 포함되어 있고, 매년 새로운 AWS 서버리스 서비스가 등장하고 있어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, DynamoDB가 더 이상 요구 사항과 일치하지 않는 것을 깨달을 수도 있습니다. Amazon Aurora 서버리스를 사용하거나 Elasticache 서버리스를 혼합해 캐시를 추가하거나 OpenSearch 서버리스로 키워드 검색을 최적화할 수도 있습니다. 이러한 서비스들은 서버리스 변형이 있지만 영구로 스케일되지 않습니다. 고객 트래픽이 없더라도 최소 요금을 지불해야 합니다. 따라서 아마도 이러한 서비스들을 AWS가 관리하지만 진정한 서버리스 서비스는 아닌 것으로 부르는 것이 가장 좋을 수 있습니다. 또한, 이러한 서비스들은 VPC가 필요하며, ENI, VPC 엔드포인트 등으로 매월 고정 비용이 추가됩니다.\n\n그리고 Jeremy Daly는 Allen Helton의 훌륭한 팟캐스트에서 AWS의 최신 서비스들의 서버리스 또는 서버리스가 아닌 특성에 대해 논의했는데, 권해드립니다.\n\n# 프로덕션 등급은 추가 비용이 발생합니다.\n\n클라우드 서비스를 위해 선택한 기술에 관계없이 언젠가는 프로덕션을 준비해야 합니다. 규정, 보안 및 관측 요구 사항을 해결해야 하며, 이는 추가되는 과소 평가된 비용을 야기합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리의 사전 제품 서비스에 이러한 기능 몇 가지를 추가해 보는 건 어떨까요?\n\n우리는 서비스에 고객 데이터 암호화 기능을 추가해야 합니다. 우리는 KMS CMK를 사용하여 고객 데이터를 암호화하거나 서비스 간 통신을 용이하게 할 수 있습니다. CMK는 API 호출을 포함하지 않고 제공만 되어도 매달 1달러가 들고, 키 자동 회전을 활성화하면 추가 1달러가 소비됩니다. 10000명의 고객이 있을 것으로 예상하시나요? 멋져요, 당신의 AWS 청구서에 매달 추가로 20000달러가 더해집니다.\n\n프로덕션 준비 관행으로 넘어가 봅시다. 웹 보안과 관찰성을 더해봅시다.\n\nAPI Gateway나 CloudFront 분산에 웹 어플리케이션 방화벽을 활성화하고 CloudWatch 대시보드를 통해 관찰성을 향상시킬 수 있습니다. 이러한 리소스들은 매달 지속적인 가격이 부여되며, 서비스가 매달 트래픽을 전혀 받지 않더라도 이용료가 부과됩니다. 이와 유사한 사례들이 많이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n서비스를 제품으로 제작할 때 수많은 작은 비용이 쌓입니다. 사람들은 이를 인식해야 합니다. 그럼에도, 그저 다른 CMK일 뿐이죠; AWS CDK에서 생성하는 한 줄 뿐이니까; 해로운 점이 뭐가 있을까요?\n\n여러 개의 계정을 사용한다면(당신이 해야 하는 대로) - 개발, 테스트, 제품 용으로 - 모든 비용 추가는 보유한 계정 수에 곱해질 수 있습니다. 한 계정당 5개의 지역에 배포하나요? 그럼 추가적으로 15(5\\*3 - 계정 수)개의 CMK가 생깁니다. 다시 한 번 곱하세요.\n\n이러한 비용은 개발 계정에서 특히 크게 누적됩니다. 자원이 배포되고 삭제되며 종종 콘솔을 통해 수동으로 생성해서 잊혀지기 쉽기 때문입니다. 하지만 AWS는 그 기록을 기억하고 당신은 달이 끝날 때 청구서를 받을 것입니다.\n\n## 고객이 다가온다\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마지막으로, 대부분의 분들에게는 분명한 사실일 것이지만, 고객을 많이 모은다면 규모, API 호출 횟수, 그리고 저장 데이터 양이 커질 것입니다. 이 모든 것이 AWS 클라우드 요금 증대로 이어집니다. 이러한 추가 비용을 계획하고 수익 모델에 반영하지 않으면 비즈니스가 유지될 수 없습니다.\n\n요점은 프로덕션급 서버리스나 서버리스가 빠르게 증가할 수 있는 추가 고정 비용이 있다는 것입니다. 여러 비트와 바이트에 대해 지불해야 하며 처음부터 이를 인식해야 합니다. 예상 고객 트래픽 규모를 위한 예산을 설정하고 이를 지속적으로 모니터링하여 비용이 억제되도록 해야 합니다.\n\n이제 문제를 이해했으니 당신의 조직이 이 문제를 대처하고 비용을 줄이며 효율성을 향상시킬 수 있는 방법에 대해 이야기해 봅시다. 그것은 FinOps 마인드셋을 채택함으로써 가능합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFinOps를 채택하고 비용을 인식하는 것은 조직의 C급 임원에게 중요합니다. 그러나 위에서 논의한 대로, 모든 설계 선택, 모든 CloudFormation 스택 배포, 모든 IT/DevOps 예약 작업 실행은 구매 선택입니다.\n\n귀하의 팀은 매일 AWS 계정에서 돈을 소비합니다.\n\n조직의 사고방식을 비용 인식적으로 바꾸고 싶다면, 그것은 아래부터 시작되어야 합니다. 아키텍트와 팀 리더가 선도할 수 있지만, 아래에 있는 병력들은 따라와서 목표를 이해해야 합니다. 개발자들이 다양한 리소스를 배포하는 것을 막는 자동화를 추가할 수 있지만, 장기적으로 이는 개발팀의 독립성을 방해하고 확장되지 않을 것입니다. 사람들은 FinOps 사고방식을 받아들이고, 이해하며, 개발의 모든 단계에서 클라우드 비용에 대해 생각해야 합니다.\n\n다음 섹션에서는 귀사에서 구현할 수 있는 구체적인 조치 항목을 설명하겠습니다. 아키텍트부터 DevOps, IT, 개발자까지 페르소나는 다를 수 있지만, 아이디어는 같습니다: AWS 비용을 줄이기 위해서는 한 마을이 필요하며, 모두가 함께해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 비용 고려한 디자인\n\n클라우드 아키텍트로써, 우리는 조직에서 전체 AWS 비용에 가장 큰 영향을 미치는 몇 안 되는 사용자 중 하나입니다.\n\n지난 AWS re:Invent에서 Vogels는 \"절약하는 아키텍트\" 가이드라인을 논의했는데, 이는 제 블로그 게시물 \"클라우드 아키텍트의 고수준 디자인 템플릿\"과 관련이 있습니다.\n\n그의 세션에서 주요 포인트는 모든 클라우드 아키텍처 디자인 선택이 구매 선택과 관련이 있다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n건축가로서, 우리는 서비스의 고수준 디자인 뿐만 아니라 저수준 디자인에도 영향을 미칩니다. 우리 회사에서는 개발자들이 제 동행과 함께 저수준 디자인과 컨셉 증명을 수행합니다. 따라서, 이른 시기에 비용을 고려하는 것이 중요합니다.\n\n서버리스 서비스를 설계할 때는 종종 여러 가능한 아키텍처가 있습니다. 예를 들어, SNS 또는 EventBridge를 사용하여 이벤트를 구독자에게 발행할 수 있습니다.\n\n최선의 결정을 내리기 위해, 양쪽 솔루션을 비교할 수 있는 의사 결정 매트릭스를 사용하고 예상 비용을 비기능적 요구 사항으로 고려하는 것을 권장합니다.\n\n이 프로세스에 대해 자세히 설명한 블로그 포스트는 Cloud Architect's High-Level Design Template에서 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n고객 수 및 규모에 대한 예상을 고려하고 이러한 숫자를 AWS 요금 계산기에 입력하세요. 이후에 AWS 비용이 나중에 급증하고 손쉽게 대체할 수 없는 비용이 들어간 제품이 프로덕션 환경에 배포되었을 때 놀라지 마세요.\n\n하지만 여기서 끝이 아닙니다. 아키텍트로서 모든 것을 감시할 수는 없고, 개발자들은 기능을 구현할 때 가격 선택을 합니다. 예를 들어, 내부 대시보드용으로 사용자 정의 CloudWatch 메트릭을 추가하지만 차원을 너무 많이 사용하여 비용이 크게 증가하는 경우가 있다(실제 사례!). 팀이 비용을 종합적으로 고려해 독립적으로 이러한 선택을 할 수 있도록 하여, 상당히 중요합니다. 거의 모든 리소스 배포나 API 호출이 추가 클라우드 비용을 발생시킨다는 점을 이해해야 합니다.\n\n# FinOps 문화\n\n조직 전체의 팀이 클라우드 비용을 이해하고 활발히 줄이고 최적화할 수 있도록 하는 문화적 실천 방법을 검토해봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 금융 오퍼레이션 챔피언\n\n먼저, 각팀 (개발자, IT, 데브옵스 등)에서 금융 오퍼레이션 챔피언을 뽑는 것이 좋습니다. 그들은 GitHub PR이 예상치 못한 비용 증가를 유발하지 않도록 확인하는 역할을 맡고 있습니다. 이 챔피언들은 설계 검토 중에 비용 우려 사항을 제기하고 팀이 비용을 염두에 두도록 도와줍니다.\n\n이상적으로, 금융 오퍼레이션 챔피언은 항상 클라우드 비용을 고려합니다. 설계, 구현 또는 프로덕션 배포 단계에서 모두 해당합니다.\n\n이 챔피언은 제가 아래에 설명할 '청구서 모니터링' 섹션에 적극적으로 참여할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## FinOps Guild\n\n두 번째 실천 방법은 부서 간 및 조직 간 지식 공유입니다. 한 팀이 새로운 Lambda에서 프로비저닝된 동시성의 비용을 줄이는 최상의 실천 방법을 발견했다고 가정해 봅시다. 한 팀이 그 문제를 해결한 것은 좋지만, 동일한 최상의 실천 방법이 조직 전체에 구현되는 것이 더 좋을 것입니다. 이를 위해 지식을 공유할 수 있는 메커니즘이 필요합니다.\n\n그런 메커니즘 중 하나는 모든 FinOps 챔피언들이 매월 한 번 지식을 공유하는 FinOps 길드를 시작하는 것일 수 있습니다.\n\n내부 조직 외부 사람들을 만나 IT, 데브옵스, 제품 등과의 새로운 관계를 형성하는 것도 추가 가치입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n참고로, 공급된 사전 할당량 및 차가운 시작에 대해 더 알고 싶다면 여기에 있는 내 게시물을 확인해보세요.\n\n## FinOps 내부 교육\n\n길드 회의는 정보를 공유하는 좋은 방법입니다. 그러나 더 작은 대상을 대상으로 하는 한계가 있어서 이전 회의의 최상의 실천법이 잊혀질 수 있으므로 귀하의 최상의 실천법을 문서화하는 것이 가장 좋습니다. 간단한 내부 문서부터 시작하거나 내부 비디오 강좌를 만들기 위해 노력해보세요. 강좌는 전문적으로 편집된 비디오일 필요는 없습니다. 팀/슬랙 회의 녹화일 수도 있습니다. 콘텐츠는 신규 FinOps 챔피언을 신속하게 승격시키고 비용 절감 관행을 확산시키기 위한 빠른 방법으로 기능해야 합니다.\n\n## FinOps 해커톤\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이것은 재미있는 아이디어입니다. FinOps를 게임처럼 만들고 직원들이 개선, 자동화 및 기타 비용 절감 방법에 대한 아이디어를 제시할 수 있는 해커톤을 소개해 보세요. 이를 흥미롭게 만들기 위해 가장 영향력 있는 아이디어에 대한 상품을 제공해 보세요.\n\n## 성공을 축하하세요\n\n이 행동 항목은 모든 문화에 중요한 부분이므로 가장 중요할 수 있습니다. 누구나 회사 이익을 개선하는 일에 대한 피드백을 감사히 받을 것이며, 특히 그 작업이 회사 수익을 증가시킬 때 더욱 그렇습니다. 조직 전체에서 성공을 인정하는 것은 긍정적인 효과를 창출하고 다른 팀들이 FinOps 방법을 도입하고 자신들의 비용을 줄일 때를 축하할 동기를 주게 할 것입니다.\n\n# 청구서를 모니터링하세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 재무를 관리할 때는 예산 계획을 따르는 것이 매우 중요합니다. 돈을 현명하게 쓰기 위해서는 AWS 비용 탐색기나 Anodot과 같은 타사 서비스와 같은 도구를 활용하여 지출 패턴을 파악하는 것이 좋습니다.\n\n예산 초과에 대한 경보를 설정하고 매달 지출 내역을 정기적으로 모니터링하여 각 팀이나 서비스와 관련된 비용에 집중할 수 있습니다.\n\n리소스마다 태그를 추가하여 팀 이름, 마이크로서비스 이름 또는 다른 태그를 포함하여 각 팀에 대한 비용을 파악할 수 있습니다. 여러 팀이 동일한 AWS 계정을 공유하는 경우 비용을 이해하는 데 도움이 됩니다. 그런 다음 AWS 비용 탐색기에서 필터링할 수 있습니다.\n\n더 자세한 내용은 이곳에서 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n또한 SaaS (Software as a Service) 제공업체이면 각 고객의 비용을 예산 편성, 라이선스 및 수익성을 위해 추정(또는 많은 경우에는 \"guesstimate\")하는 것이 중요합니다. 이 작업은 간단한 일이 아니며, 풀 또는 사일로 모델 테넌트 격리 전략을 사용하는 경우 도전이 매우 다릅니다. 그러나 이 주제는 이 게시물의 범위 내에서 다루기에는 너무 방대합니다.\n\n여러 계정을 관리하거나 여러 클라우드 공급 업체를 사용하는 조직에게는 Anodot과 같은 도구가 중요한 이점을 제공할 수 있습니다. Anodot은 비용 관리에 대한 집중된 접근 방식을 제공합니다.\n\n마지막으로, FinOps 챔피언 및 기타 이해 관계자가 이러한 도구에 액세스하고 대시보드를 보고 경보를 정의할 수 있도록하세요.\n\n# 비용 방어 자동화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n클라우드 비용을 절감하는 방법 중 하나로 자원 삭제를 자동화하거나 일부 리소스가 처음부터 생성되지 않도록 하는 조직 정책이나 메커니즘을 추가할 수 있습니다.\n\n떠오르는 몇 가지 아이디어는 다음과 같습니다:\n\n- 사용되지 않는 KMS CMK와 같은 자원들을 자동으로 삭제합니다.\n- 삭제되지 못한 CloudFormation 스택 및 \"좀비\" 리소스가 남아 있는 스택을 자동으로 삭제합니다. 예를 들어 S3 버킷이 비어 있지 않아 삭제되지 못한 스택이 있습니다.\n- 개발자가 비인증 지역에 배포하는 것을 방지하는 정책을 시행합니다. AWS 서비스의 가격은 지역에 따라 다릅니다. 필요한 서비스를 사용할 수 있는 지역을 선택하고 고객에게 충분한 응답 시간을 제공할 수 있는 비용 대비 서비스를 선택합니다.\n- 비개발 계정에서 콘솔을 통해 자원을 생성하지 못하도록 하고, 인프라스트럭처-애스-코드(IAC) 방식으로만 생성하도록 합니다. 잊혀진 고아 자원을 생성할 위험을 줄입니다.\n- 스택에 속하지 않거나 사용하지 않는 고아 자원 또는 \"드리프트 된\" 자원을 찾아 삭제합니다.\n- 잠재적인 비용 급증을 알리는 경고를 설정하여 선제적으로 관리합니다. AWS의 비용 이상 탐지와 같은 도구를 사용하여 초기에 비정상적인 지출 패턴을 식별하는 데 도움을 받습니다.\n- 밤에 EC2 인스턴스를 자동으로 종료하는 예약된 작업을 만듭니다.\n- 그 외 다양한 방법이 있습니다. 사용 사례에 따라 다를 수 있습니다.\n\n여기서 가장 중요한 교훈은 선제적인 접근 방식을 채택하는 것입니다. 놀라지 마세요. 비용을 적극적으로 줄이기 위해 노력하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 지속적인 학습\n\n기사, AWS 모임 및 기타 교육 자료를 통해 계속해서 학습하는 것이 매우 중요합니다. 언제 어떤 새로운 기능이나 메커니즘을 발견할지 모릅니다. 혁신과 서비스 발표를 계속해서 파악하는 것도 중요합니다.\n\n모든 것은 변화와 리팩터링에 관한 것입니다.\n\n가끔은 HTTP를 REST API 게이트웨이로 대체하거나 Lambda Powertuning과 같은 도구를 활용하여 함수를 최적화하거나 CloudWatch 로그 보존 기간을 줄이고 로그 수준을 변경하는 등의 서비스 변경이 큰 비용 절감을 이끌 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n팁들이 지나치게 상세해 보일 수 있지만, 그것들은 단지 빙산의 일각에 불과해요. 각 AWS 서비스는 독특한 최적화 기회를 제공하며, FinOut의 DynamoDB 가격 도전과 Best Practices에서 제시된 구체적인 전략들이 그것을 보여줍니다.\n\n집중해서 연구하고 배우고 최적화하세요. 장기적으로 보면 그 노력이 보람 있을 거예요.\n\n# 요약\n\n이 글에서는 모든 조직이 FinOps 마인드셋을 채택해야 할 관행을 다루었습니다. 클라우드 비용을 예방적으로 관리하고 항상 최적화하고 줄이기 위해 전체 조직의 노력이 필요하다는 점을 논의했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물이 귀하의 조직이 클라우드 비용 낙원을 실현하기 위해 FinOps 여정에서 도움이 되길 바랍니다. 행운을 빕니다!\n","ogImage":{"url":"/assets/img/2024-05-18-OptimizingCostsintheCloudEmbracingaFinOpsMindset_0.png"},"coverImage":"/assets/img/2024-05-18-OptimizingCostsintheCloudEmbracingaFinOpsMindset_0.png","tag":["Tech"],"readingTime":14},{"title":"AWS S3와 CloudFront를 이용한 정적 웹사이트 호스팅 공개 vs 비공개","description":"","date":"2024-05-18 16:19","slug":"2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate","content":"\n![Static Website Hosting on AWS S3 and CloudFront](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_0.png)\n\n정적 웹 사이트에는 HTML 페이지, 이미지, CSS 파일, 때로는 JavaScript 및 웹 사이트를 호스팅하는 데 필요한 모든 필수 파일이 포함됩니다. 그들은 변하지 않기 때문에 정적입니다. 웹 사이트를 방문할 때마다 항상 동일한 정보를 동일한 순서와 위치에 보게 됩니다. 이는 로그인한 사용자나 검색 내용에 따라 콘텐츠가 변경되는 동적 웹 사이트와는 달라요.\n\nAWS에서 정적 웹 사이트는 '무언가'라고 불리는 S3 버킷에 저장됩니다. 버킷은 웹 사이트와 관련된 모든 파일을 보관하는 호스트 또는 컨테이너로 비유될 수 있습니다. 서버 측 스크립팅이나 데이터베이스가 필요하지 않기 때문에 그들은 만들기 쉽고 호스팅하기 쉽습니다.\n\n다른 한편 AWS CloudFront는 컨텐츠 전달 네트워크(CDN) 서비스입니다. 주요 기능은 웹 페이지, 비디오, 이미지 및 기타 파일과 같은 콘텐츠를 고성능, 낮은 지연 시간 및 빠른 전송 속도로 사용자에게 전송하는 것입니다. 따라서 정적 웹 사이트를 호스팅하고 CDN으로 CloudFront를 사용하면 사용자에게 웹 사이트 콘텐츠를 전 세계적으로 제공하는 확장 가능하고 신뢰할 수 있으며 고성능 솔루션을 얻을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사에서는 AWS에서 정적 웹 사이트를 호스팅하는 두 가지 방법을 탐색할 것입니다. 이를 위해 공개 S3 버킷 또는 비공개 버킷을 사용할 수 있습니다.\n\n## 목차\n\n- Part A: 공개 S3 버킷에 정적 웹 사이트 호스팅 및 CloudFront에 연결하기\n- Part B: 비공개 S3 버킷에 정적 웹 사이트 호스팅 및 CloudFront로 액세스하기\n- 리소스 종료 및 정리\n\n## Part A: 공개 S3 버킷에 정적 웹 사이트 호스팅 및 CloudFront에 연결하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1. AWS Management Console에서 S3를 검색하세요.\n\n![Step 1](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_1.png)\n\n2. N. Virginia 또는 us-east-1 지역에 있는지 확인하고 버킷 생성을 클릭하세요.\n\n![Step 2](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nStep 3: 일반 목적 버킷 유형, 고유한 버킷 이름을 선택하고 권장대로 ACL 비활성화합니다.\n\n![Step 3 Screenshot](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_3.png)\n\nStep 4: 웹 사이트에 대중 접근 가능하도록 공개 버킷에 호스팅하고 있으므로 'public access 차단'을 선택 해제하고 확인합니다.\n\n![Step 4 Screenshot](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_4.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음 단계: 아래로 스크롤하여 버킷을 만드세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_5.png)\n\n다음 단계: 성공 알림을 받게 될 겁니다. 버킷 이름을 클릭하세요. 이제 웹사이트의 인덱스 파일과 이미지를 업로드할 시간입니다.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nStep 7: 업로드를 클릭하세요.\n\n![Upload](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_7.png)\n\nStep 8: 파일을 추가하세요. 이에는 index.html 파일, css (있을 경우), 자바스크립트 및 웹사이트에 있는 모든 이미지가 포함됩니다. 이 템플릿 웹사이트에서 또는 GitHub 저장소에서 웹사이트 파일을 다운로드하고 추출할 수 있습니다.\n\n![Add Files](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n9단계: 버킷 속성을 클릭하세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_9.png)\n\n10단계: 정적 웹사이트 호스팅으로 스크롤하여 편집하세요. 현재 비활성화 상태입니다.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_10.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n11단계: 정적 웹사이트 호스팅을 활성화하고 index.html을 인덱스 문서로 지정합니다. 변경 사항을 저장하세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_11.png)\n\n12단계: 다시 정적 웹사이트 호스팅으로 돌아가서 버킷 URL을 복사합니다. 브라우저의 새 탭에 붙여넣기하거나 직접 링크를 클릭하여 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_12.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n13. 결과: 403 금지됨. 버킷 정책을 첨부해야 해서 액세스가 거부되었습니다.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_13.png)\n\n14. 버킷으로 돌아가서 권한 탭을 클릭하세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_14.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n15단계: 버킷 정책으로 이동하여 편집하세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_15.png)\n\n16단계: 아래 정책을 복사하여 붙여넣으세요. 'resource'에 있는 ARN을 버킷 이름으로 바꾸세요.\n\n```js\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"PublicReadGetObject\",\n      \"Effect\": \"Allow\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:GetObject\",\n      \"Resource\": \"arn:aws:s3:::YOUR_BUCKET_NAME/*\"\n    }\n  ]\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래의 'ARN'을 복사하고 붙여넣기하세요. 버킷 ARN은 강조된 영역에 표시됩니다.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_16.png)\n\n단계 17: 변경 사항 저장하기.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_17.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n단계 18: 브라우저를 새로고침하세요. 웹사이트가 성공적으로 호스팅되었습니다.\n\n![Image 1](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_18.png)\n\n단계 1: 관리 콘솔에서 CloudFront를 검색하세요.\n\n![Image 2](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_19.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nStep 2: 배포를 만듭니다.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_20.png)\n\nStep 3: 오리진으로 버킷 이름을 선택합니다.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_21.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nStep 4: 방화벽을 활성화하면 청구를 막기 위해 이 데모의 끝에 삭제해야 합니다.\n\n![image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_22.png)\n\nStep 5: 아래로 스크롤하여 기본 루트로 이동하고 index.html을 입력하여 배포를 생성하세요.\n\n![image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_23.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n6단계: 배포가 완료되었습니다. 일반적으로 배포 과정이 완료되기까지 시간이 소요됩니다. 과정이 완료될 때까지 기다리신 후, 분배 도메인 이름을 복사하여 브라우저에 붙여넣어 주세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_24.png)\n\n7단계: 완료되었습니다!\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_25.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 파트 B: 프라이빗 S3 버킷에 정적 웹사이트 호스팅 및 CloudFront로 액세스하기\n\n단계 1: S3로 돌아가서 다른 고유한 버킷 이름을 선택하세요. ACL을 추천대로 비활성화하세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_26.png)\n\n단계 2: 모든 공개 액세스 차단하기.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n마크다운 형식으로 테이블 태그를 변경하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nStep 5: 아직 버킷 정책을 편집하지 마세요. CloudFront로 이동하여 새 유통을 만듭니다.\n\nStep 6: 원본 액세스 아래에서 원본 액세스 제어 설정을 선택하고 새로운 OAC를 생성하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_31.png)\n\n단계 7: Bucket 이름을 선택하고 생성하세요.\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_32.png)\n\n단계 8: 배포를 생성한 후 CloudFront는 웹 사이트에 액세스할 수 있는 버킷 정책을 제공할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Step 9](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_33.png)\n\nStep 9: You can choose either A or B.\n\n![Step 10](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_34.png)\n\nStep 10: If you enable a firewall, you will have to delete it at the end of this demo to avoid billing.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_35.png)\n\nStep 11: 기본 루트 객체에 index.html을 추가하고 변경 사항 저장.\n\n![Image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_36.png)\n\nStep 12: 생성된 정책 문을 복사하고 안전한 곳에 보관하세요. 배포 상태를 현재 날짜로 변경할 수 있도록 허용하고, 분산 도메인 이름을 복사하여 브라우저에 붙여넣으세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_37.png\" /\u003e\n\n13 단계: 당신의 정책은 이와 유사해야 합니다.\n\n```js\n{\n        \"Version\": \"2008-10-17\",\n        \"Id\": \"PolicyForCloudFrontPrivateContent\",\n        \"Statement\": [\n            {\n                \"Sid\": \"AllowCloudFrontServicePrincipal\",\n                \"Effect\": \"Allow\",\n                \"Principal\": {\n                    \"Service\": \"cloudfront.amazonaws.com\"\n                },\n                \"Action\": \"s3:GetObject\",\n                \"Resource\": \"arn:aws:s3:::pemosi/*\",\n                \"Condition\": {\n                    \"StringEquals\": {\n                      \"AWS:SourceArn\": \"arn:aws:cloudfront::296532954493:distribution/E92LWG7KIDQE3\"\n                    }\n                }\n            }\n        ]\n      }\n```\n\n14 단계: S3 버킷으로 돌아가서 클라우드프런트에서 복사한 정책으로 버킷 정책을 편집하십시오. 변경사항을 저장하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_38.png\" /\u003e\n\n단계 15: 여기 왔어요! 이제 클라우드프론트로 웹 사이트에 접근할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_39.png\" /\u003e\n\n더 흥미롭게 만들기 위해 AWS Route 53을 사용하여 도메인 이름을 사용자 정의할 수 있습니다. 그래서 문자와 숫자의 연속이 아닌 당신의 이름 또는 선호하는 별칭으로 정적 웹 사이트가 제작됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 리소스 종료 및 정리\n\n청구를 피하기 위해 생성한 모든 리소스를 삭제하는 것이 좋습니다. 삭제되지 않은 리소스는 직불 카드에 요금이 부과됩니다.\n\n시작하려면 S3 버킷으로 돌아가세요.\n\n단계 1: 버킷 이름 옆의 원형 체크박스를 클릭하고 삭제를 클릭하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_40.png)\n\nStep 2: You’ll be prompted to empty your bucket first before deleting.\n\n![image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_41.png)\n\nStep 3: Type ‘permanently delete’ in the space provided and empty.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_42.png)\n\n단계 4: 이제 버킷을 삭제할 수 있습니다. 다시 확인란을 선택하고 이번에는 삭제를 클릭하세요. 버킷 이름을 입력하여 삭제 요청을 확인하세요. 성공적으로 삭제되었습니다!\n\n![Image](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_43.png)\n\n단계 5: CloudFront로 이동하세요. 배포 확인란을 선택하고 비활성화하세요. 시간이 걸릴 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이미지 태그를 Markdown 형식으로 변경하십시오.\n\nStep 6: 비활성화한 후에 삭제할 수 있습니다.\n\nStep 7: 성공적으로 완료되었습니다! 앞으로 나가서 CloudFront를 위해 생성한 OAC를 분리하고 삭제하십시오!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_46.png)\n\n파이어월을 활성화했다면 저와 같이, 파이어월도 삭제해야 합니다. 콘솔에서 WAF를 검색하여 WAF 및 Shield를 선택합니다. 웹 ACLs를 선택합니다. 지역을 us-east-1에서 Global CloudFront로 변경한 후, 파이어월을 클릭하여 삭제합니다.\n\n본 문서는 Amazon S3 및 CloudFront에서 정적 웹사이트를 호스팅하는 과정을 안내했습니다. 이를 통해 다양한 객체를 S3 버킷에 저장하고 모든 종류의 웹사이트를 호스팅할 수 있습니다. 그러나 제작 목적 외의 모든 생성된 리소스는 항상 종료하여야 합니다.\n\n구름에서 만나요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저와 연락을 주세요:\nTwitter(X)\nLinkedIn\n협업 및 일자리? 이메일\n","ogImage":{"url":"/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_0.png"},"coverImage":"/assets/img/2024-05-18-StaticWebsiteHostingonAWSS3andCloudFrontPublicvsPrivate_0.png","tag":["Tech"],"readingTime":17}],"page":"101","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":13,"currentPageGroup":5},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"101"},"buildId":"T_Nz0g9U1yttYMSEma95P","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>