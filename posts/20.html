<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/20" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/20" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/PgdIX9e0tvkvkdAmDT6qR/_buildManifest.js" defer=""></script><script src="/_next/static/PgdIX9e0tvkvkdAmDT6qR/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="스타일러 AI 얼굴 킷" href="/post/2024-05-20-StylarAIFaceKit"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="스타일러 AI 얼굴 킷" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-StylarAIFaceKit_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="스타일러 AI 얼굴 킷" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">스타일러 AI 얼굴 킷</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="고급 RAG 08 Self-RAG" href="/post/2024-05-20-AdvancedRAG08Self-RAG"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고급 RAG 08 Self-RAG" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고급 RAG 08 Self-RAG" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고급 RAG 08 Self-RAG</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="OpenAI API를 통해 GPT-4o에 접속하기" href="/post/2024-05-20-AccessingGPT-4oviaOpenAIAPI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="OpenAI API를 통해 GPT-4o에 접속하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="OpenAI API를 통해 GPT-4o에 접속하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">OpenAI API를 통해 GPT-4o에 접속하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="BERT 코드와 함께하는 완벽 가이드" href="/post/2024-05-20-ACompleteGuidetoBERTwithCode"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="BERT 코드와 함께하는 완벽 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="BERT 코드와 함께하는 완벽 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">BERT 코드와 함께하는 완벽 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">41<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="고유명사 인식 노출 - 필수 가이드" href="/post/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고유명사 인식 노출 - 필수 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고유명사 인식 노출 - 필수 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고유명사 인식 노출 - 필수 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기" href="/post/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어" href="/post/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="용어 해설 AI 시스템 제어하기" href="/post/2024-05-20-GlossaryControllingAISystems"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="용어 해설 AI 시스템 제어하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-GlossaryControllingAISystems_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="용어 해설 AI 시스템 제어하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">용어 해설 AI 시스템 제어하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="그래프 이론 필수 가이드 18세기 수수께끼부터 인공 지능까지" href="/post/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="그래프 이론 필수 가이드 18세기 수수께끼부터 인공 지능까지" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="그래프 이론 필수 가이드 18세기 수수께끼부터 인공 지능까지" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">그래프 이론 필수 가이드 18세기 수수께끼부터 인공 지능까지</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">21<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="머신 러닝을 위한 피처 엔지니어링" href="/post/2024-05-20-FeatureEngineeringforMachineLearning"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="머신 러닝을 위한 피처 엔지니어링" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="머신 러닝을 위한 피처 엔지니어링" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">머신 러닝을 위한 피처 엔지니어링</strong><div class="PostList_meta__VCFLX"><span class="date">May 20, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link posts_-active__YVJEi" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"스타일러 AI 얼굴 킷","description":"","date":"2024-05-20 21:13","slug":"2024-05-20-StylarAIFaceKit","content":"\n\nAI는 인간 얼굴을 만드는 데 점점 능숙해지고 있어요. 하지만 복잡한 상황에서는 가끔 실수가 발생할 수 있어요. 대부분의 어플리케이션들에서 그런 경우에는 프롬프트를 다시 실행하는 것뿐이에요. 그런데 그렇게 하면 전혀 예상치 못한 이미지가 생성되기도 해요.\n\n그래서 Stylar AI가 전체적인 얼굴 키트를 만들어 줬다는 것이 좋은 소식이에요 — 세 가지 다른 도구들이 있어요. 이 도구들을 사용하면 문제를 해결하고 얼굴을 다룰 수 있답니다.\n\n실제 사진이나 Stylar에서 생성된 이미지, 다른 AI 어플리케이션에서 가져온 이미지를 사용해서 문제를 해결할 수 있는 Stylar의 얼굴 키트를 활용할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**킷에는 세 가지 도구가 포함되어 있습니다: Face Repair(얼굴 수리), Face Swap(얼굴 교체) 및 Face Match(얼굴 일치).**\n\n# Face Repair Tool(얼굴 수리 도구)\n\n![이미지](/assets/img/2024-05-20-StylarAIFaceKit_0.png)\n\n**이름이 말해주는 대로, 이 도구는 얼굴의 렌더링 아티팩트와 문제를 수리합니다. 이 도구에는 자체적인 멋진 창이 있으며, 여는 순간, Stylar AI가 얼굴 영역을 선택하여 수정할 수 있도록 선택 브러시를 활성화합니다.**\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기능에는 Styal에게 이 얼굴을 어떻게 만들고 싶은지 말할 수 있는 별도의 프롬프트 창과 \"원본 얼굴 보존\" 슬라이더가 있습니다.\n\n그 사용법은 명백하고 쉽습니다.\n\n저는 스팀펑크 소녀를 렌더링해보기로 결심했습니다. 원본 이미지에는 좋은 아이디어가 있었지만 품질은 다소 낮았으며, 얼굴은 선글라스에 가려져 있었고, 어떤 이유로 안경 아래에 안경이 있었습니다.\n\n어떤 얼굴을 표시하는 데 한순간이 걸린 후에 약간의 처리 시간이 지난 후에 정말 좋은 결과물을 제시받았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-20-StylarAIFaceKit_1.png)\n\n이 도구는 사용하기 쉽습니다. 그 말대로 작동하며 굉장히 편리합니다. 이미지 렌더링 및 혼합 아티팩트가 있는 이미지들에 자주 사용하며 사랑합니다.\n\n\"원본 얼굴 보존\" 슬라이더도 유용합니다. 특정 얼굴 특징들을 보존하는 것이 중요할 때는 슬라이더를 높이면 되고, 그렇지 않은 경우에는 작은 값을 사용하면 더 나은, 더 아름다운 결과물을 얻을 수 있습니다.\n\n# 얼굴 스왑 도구\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Stylar AI Face Swap Tool](/assets/img/2024-05-20-StylarAIFaceKit_2.png)\n\n얼굴 스왑 도구를 클릭하면 완전히 미니멀한 창이 표시됩니다. 여기에서 새 얼굴을 업로드할 수 있어요. 그것이 전부에요; Stylar AI가 나머지를 처리할 거예요.\n\n얼굴이 이미지 전체를 지배하는 경우, 환상적인 결과를 기대하지 마세요.\n\n하지만 이미지에서 얼굴이 이미지 크기의 약 30-40% 이하인 경우에는 잘 작동할 거예요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사실, 대부분의 테스트에서 얼굴 교체 도구가 광고대로 작동하여 인상적인 결과물을 제공했습니다.\n\n그리고 컨트롤이나 옵션이 없기 때문에 배울 것이 없어요 — 그냥 사용하면 됩니다.\n\n아래는 얼굴 교체의 예시입니다. 나는 이 이미지를 물감이 튀는 것과 함께 만들었고, 내가 좋아했지만 원본 이미지의 얼굴이 너무 일러스트와 같았어요. 얼굴 교체 후 결과물은 정말 좋아 보입니다.\n\n![Face Swap Example](/assets/img/2024-05-20-StylarAIFaceKit_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이렇게 또 다른 예시를 보여드릴게요.\n\n![image](/assets/img/2024-05-20-StylarAIFaceKit_4.png)\n\n그런데 이 도구가 얼굴을 교환하는 데 탁월하게 처리했지만, 이 예시는 이 도구의 조금 특이한 점을 보여줍니다: 때때로 머리 크기를 변경하는 경향이 있어요.\n\n# 얼굴 매치 도구\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![StylarAIFaceKit](/assets/img/2024-05-20-StylarAIFaceKit_5.png)\n\n이 도구는 이미지 간 변환 도구 안에 토글로 위치하고 있습니다. 다른 스타일을 \"영감\" 이미지에 적용할 때 원하는 경우 원본 얼굴을 유지하는 데 목적이 있습니다.\n\n이 도구의 효과에 대해 굉장히 놀랐고 감명을 받았습니다. 활성화되어 있으면 인식 가능한 얼굴을 잘 보존합니다.\n\n이미지 간 변환 도구 안에는 스타일 영향력과 원본 이미지 구조의 강도를 조절하는 두 개의 슬라이더도 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그것은 상당히 좋은 제어를 제공하며 새로운 스타일과 원본 이미지 사이의 균형을 찾을 수 있는 가능성을 제공합니다.\n\n물론, 스타일에 따라 결과가 다를 수 있습니다. 과장된 만화 스타일이나 제작한 독특한 스타일과 같은 극단적인 스타일은 얼굴을 덜 알아볼 수 있게 만들지만, 그것은 예상된 바입니다.\n\n그럼에도 불구하고 대부분의 경우에는 아래 이미지들이 보여주는 대로 아주 잘 작동합니다.\n\n![StylarAIFaceKit_6](/assets/img/2024-05-20-StylarAIFaceKit_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 내 얼굴을 어딘가에 테스트하지 않았다면 테스트는 완전하지 않았을 것입니다. 그래서 Stylar의 인공지능 스타일 중 하나를 사용하여 바이킹 이미지를 만들고 나의 얼굴로 바이킹 얼굴을 바꿨어요.\n\n여기 두 이미지가 있어요; 잘 생긴 사람은 나에요.\n\n![내 얼굴 이미지](/assets/img/2024-05-20-StylarAIFaceKit_7.png)\n\nStylar AI에는 얼굴을 다루는 데 도움이 되는 Enhance 도구가 하나 더 있어요. 이 도구는 특별히 얼굴을 다루기 위해 설계된 것은 아니지만 이미지를 미세하게 조정하는 데(얼굴 포함) 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 있어요. Stylar AI에는 이미지에서 얼굴을 수정, 교체 및 향상하는 멋진, 유용하고 실용적인 도구 세트가 있습니다.\n\n이 도구들은 블로그 포스트 및 마케팅 캠페인에서 브랜드를 대표할 특정 얼굴을 원할 때 유용할 수 있습니다.\n\n이 도구들은 이미지를 복원하고 수정하는 데 도움이 됩니다.\n\n그리고 실제로, 당신은 어디든지 거의 모든 스타일로 자신의 얼굴을 넣을 수 있고, 그것은 재미있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 Stylar로 실험을 하려면 예제 얼굴이나 재미있는 스타일 이미지가 필요하다면 무료로 얻을 수 있어요.\n\nAivaras Grauzinis","ogImage":{"url":"/assets/img/2024-05-20-StylarAIFaceKit_0.png"},"coverImage":"/assets/img/2024-05-20-StylarAIFaceKit_0.png","tag":["Tech"],"readingTime":4},{"title":"고급 RAG 08 Self-RAG","description":"","date":"2024-05-20 21:10","slug":"2024-05-20-AdvancedRAG08Self-RAG","content":"\n\n이 기사는 흔한 시나리오로 시작됩니다: 공개 시험을 보는 경우입니다. 일반적으로 두 가지 전략을 사용합니다:\n\n- 방법 1: 익숙한 주제에 대해서는 빠르게 답변하고, 익숙하지 않은 주제에 대해서는 참고서를 열어서 확인하고, 관련 부분을 빠르게 찾아내어 정리하고 요약한 다음, 시험지에 답변합니다.\n- 방법 2: 모든 주제에 대해 책을 참고합니다. 적절한 부분을 찾아내고, 정리하고 요약한 다음, 시험지에 답변합니다.\n\n분명히 방법 1이 선호되는 방법입니다. 방법 2는 시간이 소비될 수 있고, 관련성 없는 정보나 잘못된 정보가 들어올 수 있어 혼란과 실수를 야기할 수 있습니다. 심지어 처음에 이해한 부분에서도 발생할 수 있습니다.\n\n하지만, 방법 2는 고전적인 RAG 프로세스를 보여주며, 방법 1은 자체 RAG 프로세스를 대표합니다. 이에 대해 이 기사에서 더 자세히 다룰 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 개요\n\n그림 1은 RAG 및 Self-RAG의 주요 프로세스를 비교한 것을 보여줍니다:\n\n![그림](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png)\n\nSelf-RAG는 세 단계로 구성되어 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 필요한 경우 검색: 모델이 검색을 요구하는 경우, 예를 들어 \"미국 주가 이름을 어떻게 얻었습니까?\" (그림 1의 오른쪽 상단)와 같은 쿼리가 있을 때, 모델의 출력에는 [검색] 토큰이 포함됩니다. 이는 쿼리와 관련된 내용을 검색해야 함을 나타냅니다. 반면에 \"최고의 여름 휴가에 대해 에세이를 쓰세요\" (그림 1의 오른쪽 아래)와 같이 물어볼 때, 모델은 검색 없이 직접 답변을 생성하도록 선택합니다.\n- 병렬 생성: 모델은 프롬프트와 검색된 콘텐츠를 모두 사용하여 출력을 생성합니다. 이 과정에서 세 가지 유형의 반영 토큰이 검색된 콘텐츠의 관련성을 나타냅니다.\n- 평가 및 선택: 단계 2에서 생성된 콘텐츠가 평가되고, 최상의 세그먼트가 출력으로 선택됩니다.\n\n상기 모델은 특별히 훈련된 모델이라는 것을 유의하십시오. 이 모델의 훈련 과정은 이 기사의 후반부에서 논의될 것입니다.\n\n# 반영 토큰\n\nSelf-RAG 프레임워크의 RAG와 비교했을 때, Self-RAG 프레임워크의 차이는 생성 중 더 정확한 제어를 위해 반영 토큰을 사용한다는 것입니다. 그림 2에서 보여집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_1.png\" /\u003e\n\n본질적으로, self-RAG는 네 가지 명확한 판단을 내립니다:\n\n- [Retrieve]: 리소스 R로부터 정보를 검색할지를 결정하는 의사결정 과정.\n- [IsREL]: 주어진 데이터 d가 문제 x를 해결하는 데 필요한 정보를 포함하고 있는지를 결정하는 관련성 확인.\n- [IsSUP]: 제공된 응답 y의 내용이 데이터 d로부터 지원되는지를 확인하는 검증 과정.\n- [IsUSE]: 문제 x에 대한 응답 y의 유용성을 평가하는 평가 과정. 결과는 1에서 5까지의 점수로, 5는 가장 높은 유용성을 나타냅니다.\n\nRAG에서 검색은 상태에 관계없이 항상 처음에 수행되는 고정된 과정입니다. 반면 self-RAG는 반사 토큰을 도입하여 LLM을 더 적응적이고 지능적으로 만듭니다. LLM이 텍스트를 생성하다가 불확실성이 발생하는 부분에 도달하면 반사 토큰에서 일시 정지하여 신속하고 정확한 검색을 수행한 후 새로 습득한 정보를 사용하여 생성을 재개합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 코드 설명\n\nself-RAG 프로세스를 직관적으로 이해하기 위해 먼저 코드를 살펴보고 모델의 훈련 과정을 설명하겠습니다.\n\nself-RAG는 오픈 소스이며, Langchain과 LlamaIndex에는 각각의 구현이 있습니다. 우리는 설명을 위해 LlamaIndex의 구현을 참조할 것입니다.\n\n## 환경 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 환경을 설정하세요.\n\n```js\n(base) Florian@instance-1:~$ conda create -n llamaindex python=3.11\n\n(base) Florian@instance-1:~$ conda activate llamaindex\n\n\n(llamaindex) Florian@instance-1:~$ pip install llama-index\n\n(llamaindex) Florian@instance-1:~$ pip install huggingface-hub\n\n(llamaindex) Florian@instance-1:~$ huggingface-cli login\n```\n\n설치 후, LlamaIndex의 대응 버전은 다음과 같습니다:\n\n```js\nllama-index                             0.10.20\n\nllama-index-core                        0.10.20.post2\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"여러분의 오픈AI API 키\"\n\nfrom llama_index.core import Document, VectorStoreIndex\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.readers import SimpleDirectoryReader\nfrom pathlib import Path\n\n\n# 옵션: SelfRAGPack 다운로드\n# 첫 실행 시 SelfRAGPack을 다운로드해야 합니다. \n# 다음 실행부터는 이 부분을 주석 처리할 수 있습니다.\nfrom llama_index.core.llama_pack import download_llama_pack\ndownload_llama_pack(\n    \"SelfRAGPack\",\n    \"./self_rag_pack\")\n\nfrom llama_index.packs.self_rag import SelfRAGQueryEngine\n\n# 이전에 다운로드하고 저장한 Llama2 모델이 있는 디렉토리.\ndownload_dir = \"여러분의 다운로드 모델 디렉토리\"\n\n# 테스트 문서 생성\ndocuments = [\n    Document(\n        text=\"남극 얼음 위를 '웨들'이라고 불리는 물개 떼가 지나다녔다. 그들의 턱시도 같은 깃털은 눈 위에서 돋보였다.\"\n    ),\n    Document(\n        text=\"펭귄 중 가장 키가 큰 황제펭귄은 다른 어떤 새보다도 더 깊이 다이빙을 할 수 있어서 500m 이상의 심해까지 다이빙을 합니다.\"\n    ),\n    Document(\n        text=\"펭귄들의 흑백색깔은 위험 방어라는 화장법의 한 종류인 카운터셰이딩입니다. 위에서 보면 펭귄의 검은 등은 바다 심지와 어우러지고, 아래에서는 펭귄의 흰 배는 밝은 표면과 어우러집니다.\"\n    ),\n    Document(\n        text=\"수직 자세이지만, 펭귄은 날지 못하는 조류입니다. 그들의 날개는 지느러미로 진화했기 때문에 수중에서 전문 수영가입니다.\"\n    ),\n    Document(\n        text=\"가장 빠른 펭귄 종류인 젠투 펭귄은 시속 36킬로미터까지 수영할 수 있으며, 수중을 순찰하는 동안 지느러미와 윤곽을 이용해 물을 가르는 식으로 전진합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 집단생활을 하는 조류입니다. 많은 종들이 번식을 위해 수만 마리까지 이를 결성합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 놀랍게도 귀가 우수하며 지저분한 떼 속에서 배우량과 새끼를 식별하는 데 명확한 호출을 의존합니다.\"\n    ),\n    Document(\n        text=\"가장 작은 펭귄 종인 리틀 블루 펭귄은 약 40cm 높이로, 남부 호주와 뉴질랜드 해안가에서 발견됩니다.\"\n    ),\n    Document(\n        text=\"번식 기간 중, 수컷 황제펭귄은 한없이 지속되는 남극 겨울을 버텨내며 몇 달간 급식없이 알을 부화시키는 반면, 암컷은 바다에서 사냥을 합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 그리고 크릴로 이루어져 있으며 이를 수중 다이빙을 통해 잡습니다.\"\n    ),\n]\n\nindex = VectorStoreIndex.from_documents(documents)\n\n# 간단한 리트리버 설정\nretriever = VectorIndexRetriever(\n    index=index,\n    similarity_top_k=10,\n)\n\n\nmodel_path = Path(download_dir) / \"selfrag_llama2_7b.q4_k_m.gguf\"\nquery_engine = SelfRAGQueryEngine(str(model_path), retriever, verbose=True)\n\n# 리트리벌 예시\nresponse = query_engine.query(\"어떤 장르인가요?\")\n\n# 리트리벌 예시\nresponse = query_engine.query(\"가장 작은 펭귄의 키는 얼마인가요?\")\n```\n\n위의 테스트 코드는 다음 결과를 생성했습니다(대부분의 llama_cpp 디버깅 정보가 제거되었습니다):\n\n```js\nModel metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\nUsing fallback chat format: None\n\nllama_print_timings:        load time =    4887.53 ms\nllama_print_timings:      sample time =      11.29 ms /    22 runs   (    0.51 ms per token,  1947.76 tokens per second)\nllama_print_timings: prompt eval time =    4887.46 ms /    24 tokens (  203.64 ms per token,     4.91 tokens per second)\nllama_print_timings:        eval time =    5883.27 ms /    21 runs   (  280.16 ms per token,     3.57 tokens per second)\nllama_print_timings:       total time =   10901.84 ms /    45 tokens\n최종 답변: '오만과 편견'은 제인 오스틴의 로맨스 소설입니다.\nllama_print_timings:        load time =    4887.53 ms\nllama_print_timings:      sample time =      11.74 ms /    20 runs   (    0.59 ms per token,  1703.29 tokens per second)\nllama_print_timings: prompt eval time =    7473.66 ms /    37 tokens (  201.99 ms per token,     4.95 tokens per second)\nllama_print_timings:        eval time =    5414.34 ms /    19 runs   (  284.96 ms per token,     3.51 tokens per second)\nllama_print_timings:       total time =   13076.88 ms /    56 tokens\n입력: ### 지시사항:\n가장 작은 펭귄은 얼마나 키가 큰가요?\n\n### 응답:\n[검색]\u003c문단\u003e펭귄들은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 크릴로 구성되어 있으며 이를 다이빙으로 잡습니다.\"\u003c/문단\u003e\n예측: [관련]가장 작은 펭귄 종류의 키는 종에 따라 달라질 수 있습니다.[지원되지 않음 / 모순][유틸리티:5]\n점수: 1.4213598342974367\n10/10 단락 완료\n\n평가 종료\n최상의 답변 선정: [관련]가\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테스트 코드를 이해하는 핵심은 SelfRAGQueryEngine 클래스의 구현에 있습니다. 이제 이 클래스를 자세히 살펴보겠습니다.\n\n## 클래스 SelfRAGQueryEngine\n\n먼저 생성자입니다. 주로 llama_cpp를 사용하여 Llama2-7B 모델을 로드하기 위해 사용됩니다.\n\n```python\nclass SelfRAGQueryEngine(CustomQueryEngine):\n    \"\"\"간단한 Self RAG 쿼리 엔진.\"\"\"\n\n    llm: Any = Field(default=None, description=\"llm\")\n    retriever: BaseRetriever = Field(default=None, description=\"retriever\")\n    generate_kwargs: Dict = Field(default=None, description=\"llm generation arguments\")\n    verbose: bool = Field(default=True, description=\"Verbose.\")\n\n    def __init__(\n        self,\n        model_path: str,\n        retriever: BaseRetriever,\n        verbose: bool = False,\n        model_kwargs: Dict = None,\n        generate_kwargs: Dict = None,\n        **kwargs: Any,\n    ) -\u003e None:\n        \"\"\"매개변수 초기화.\"\"\"\n        super().__init__(verbose=verbose, **kwargs)\n        model_kwargs = model_kwargs or _MODEL_KWARGS\n        self.generate_kwargs = generate_kwargs or _GENERATE_KWARGS\n        try:\n            from llama_cpp import Llama\n        except ImportError:\n            raise ImportError(_IMPORT_ERROR_MSG)\n        self.llm = Llama(model_path=model_path, verbose=verbose, **model_kwargs)\n        self.retriever = retriever\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 다음으로 쿼리 기능에 대해 설명하겠습니다. 주요 프로세스는 아래 그림 3에 표시되어 있습니다:\n\n![Image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_2.png)\n\n이해를 돕기 위해 주요 부분에는 주석이 달려 있습니다.\n\n```python\n    def custom_query(self, query_str: str) -\u003e Response:\n        \"\"\"커스텀 쿼리 실행.\"\"\"\n        # Llama2 모델을 사용하여 응답을 가져옵니다.\n        response = self.llm(prompt=_format_prompt(query_str), **_GENERATE_KWARGS)\n        answer = response[\"choices\"][0][\"text\"]\n        source_nodes = []\n\n        # 검색이 필요한지 여부를 결정합니다.\n        if \"[Retrieval]\" in answer:\n            if self.verbose:\n                print_text(\"검색이 필요합니다\\n\", color=\"blue\")\n            # 그림 1의 단계 1, 필요한대로 검색합니다.\n            documents = self.retriever.retrieve(query_str)\n            if self.verbose:\n                print_text(f\"받은 문서: {len(documents)}\\n\", color=\"blue\")\n            paragraphs = [\n                _format_prompt(query_str, document.node.text) for document in documents\n            ]\n\n            if self.verbose:\n                print_text(\"평가 시작\\n\", color=\"blue\")\n\n            # 그림 1의 단계 2 및 3, 병렬로 생성하고 평가합니다 \n            # (코드에서 병렬화를 구현하지는 않음)\n            critic_output = self._run_critic(paragraphs)\n\n            paragraphs_final_score = critic_output.paragraphs_final_score\n            llm_response_per_paragraph = critic_output.llm_response_per_paragraph\n            source_nodes = critic_output.source_nodes\n\n            if self.verbose:\n                print_text(\"평가 종료\\n\", color=\"blue\")\n\n            # 가장 높은 점수를 받은 답변을 선택하고 반환합니다.\n            best_paragraph_id = max(\n                paragraphs_final_score, key=paragraphs_final_score.get\n            )\n            answer = llm_response_per_paragraph[best_paragraph_id]\n            if self.verbose:\n                print_text(f\"최적 답변 선택: {answer}\\n\", color=\"blue\")\n\n        answer = _postprocess_answer(answer)\n        if self.verbose:\n            print_text(f\"최종 답변: {answer}\\n\", color=\"green\")\n        return Response(response=str(answer), source_nodes=source_nodes)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드에서 우리는 그림 1의 모든 세 단계가 표현된 것을 확인할 수 있습니다. 그러나 LlamaIndex의 코드는 병렬 처리를 구현하지 않았습니다. 더 자세한 정보는 관심 있는 독자들이 self._run_critic 함수를 살펴볼 수 있습니다. 해당 함수는 다양한 반사 토큰에 해당하는 점수를 처리합니다.\n\n# Llama2-7B 모델 훈련 방법\n\n이전에 여러 번 Llama2-7B 모델을 사용해왔으니, 이제 어떻게 얻을 지 알아봅시다.\n\n## 훈련 목표\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 과정에서는 평가 모델 C와 생성 모델 M 두 가지 모델이 필요합니다. 평가 모델 C는 모델 M이 필요로 하는 감독 데이터를 생성합니다.\n\n그러나 추론 과정에서는 모델 M만 사용되며 모델 C는 필요하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 비평가 모델 C\n\n비평가 모델은 반사 토큰을 생성하는 데 훈련됩니다. 이 모델을 사용하는 목적은 작업 출력 오프라인에 반사 토큰을 삽입하여 훈련 말뭉치를 업데이트하는 것입니다.\n\n각 세그먼트의 반사 토큰을 수동으로 주석 달기는 비용이 많이 듭니다. Self-RAG는 GPT-4를 활용하여 각 반사 토큰에 대해 고유한 지침을 할당하여 서로 다른 정의, 입력 및 출력을 가지고 있기 때문에 효율적으로 데이터 주석 작업을 완료합니다. 예를 들어, [검색] 토큰의 지시는 GPT-4가 외부 문서를 통합하는 것이 결과를 향상시킬지를 평가하도록 요청합니다.\n\n훈련 데이터 D_critic를 얻으면 표준 조건부 언어 모델을 기반으로 훈련 목표를 구성할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_3.png) \n\n비평가 모델 C는 어떤 언어 모델로도 초기화할 수 있습니다. 예를 들어 생성자와 동일한 모델로 초기화할 수 있습니다. 예를 들면 Llama2-7B와 같은 모델을 사용할 수 있습니다.\n\n## 생성자 모델 M\n\nFigure 4는 훈련 데이터를 수집하는 구체적인 과정을 보여줍니다. 입력-출력 쌍 (x, y)가 주어지면 self-RAG는 검색 및 비평가 모델을 사용하여 원래의 출력 y를 확장하고 지도 데이터를 생성합니다. y의 각 세그먼트 yt에 대해:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_4.png\" /\u003e\n\nFigure 4의 모든 조건 판단은 비평가 모델 C를 통해 실행됩니다. 획득한 훈련 데이터는 Figure 5에 나타나 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_5.png\" /\u003e\n\n훈련 데이터 D_gen을 획득한 후, 다음 토큰 예측 표준 목적 함수를 다음과 같이 구성할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_6.png)\n\nM 생성기는 결과뿐만 아니라 반영 토큰도 예측해야 합니다.\n\n# self-RAG에 대한 나의 인사이트와 생각\n\n일반적으로 self-RAG는 RAG 프로세스를 강화하는 새로운 관점을 제공합니다. 그러나 더 복잡한 훈련 과정이 필요하며 생성 단계 중에 여러 레이블 생성과 판단이 필요하기 때문에 추론 비용이 증가하기 때문에 실시간 성능이 필요한 프로젝트에는 중요한 영향을 줄 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, 이 프레임워크 내에서 최적화할 여지가 많이 있습니다. 더 많은 토론과 혁신을 일으키기 위해 몇 가지 포인트를 공유하겠습니다:\n\n- 반영 토큰을 최적화하는 방법. Self-RAG는 네 가지 반영 토큰을 설계했습니다. [검색] 토큰 외에도 세 가지([IsREL], [IsSUP], [IsUSE])는 특정 유사성이 있습니다. 더 적은 반영 토큰을 사용하거나 다른 의미를 나타내는 반영 토큰을 고려하는 것이 타당한 방향일 수 있습니다.\n- 비평가 모델이 LLM을 사용하는 이유는 무엇인가요? 제 생각에는 [IsUSE]와 같은 토큰이 공통 지식에 많이 의존하기 때문일 수 있습니다. 질의에 대한 답변의 유용성을 판단하는 것은 더 작은 모델이 수행할 수도 있습니다. 그러나 이러한 모델은 일반적인 지식을 부족하게 습득하며 종래의 특정 교육 자료만을 학습합니다. 따라서 비평가 모델로 LLM을 사용하는 것이 합리적일 수 있습니다.\n- 비평가 모델 크기 선택. Self-RAG는 7B 및 13B 모델로 테스트되어 우수한 결과를 얻었습니다. 그러나 만약 더 작은 LLM인 3B로 전환하면 어떤 차이를 관찰할 수 있을까요? 마찬가지로, 더 큰 LLM인 33B로 전환했을 때 얼마나 개선을 기대할 수 있을까요?\n- 인간 피드백을 통한 강화학습(RLHF)을 사용하지 않는 이유는 무엇인가요? 논문에서는 작업 예제를 통해 대상 언어 모델을 학습하는 것을 제안합니다. 이 예제는 비평가 모델에서 오프라인으로 반영 토큰이 추가된 것입니다. 이로 인해 RLHF 대비 훨씬 낮은 교육 비용이 발생합니다. 또한, self-RAG의 반영 토큰은 추론 중 생성을 제어할 수 있게 만들어주며 RLHF는 훈련 중 인간의 선호도 조정에 초점을 두고 있습니다. 그러나 논문에는 RLHF와 관련된 비교 실험 내용이 포함되어 있지 않습니다.\n\n# 결론\n\n본문은 직관적인 예시로 시작하여 Self-RAG의 기본적인 과정을 소개하고 코드 설명을 보완하는 내용을 담고 있습니다. 또한 제 생각과 통찰을 공유하였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 기술에 관심이 있다면, 내 다른 기사들도 살펴보세요.\n\n또한, 최신 AI 관련 콘텐츠는 내 뉴스레터에서 찾을 수 있어요.\n\n마지막으로, 어떠한 오류나 누락이 있거나 궁금한 사항이 있으시면 댓글 섹션에서 자유롭게 토론해 주세요.","ogImage":{"url":"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png"},"coverImage":"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png","tag":["Tech"],"readingTime":13},{"title":"OpenAI API를 통해 GPT-4o에 접속하기","description":"","date":"2024-05-20 21:08","slug":"2024-05-20-AccessingGPT-4oviaOpenAIAPI","content":"\n\n\n![image](/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png)\n\n# 소개\n\nOpenAI가 최근에 발표한 GPT-4o는 텍스트, 이미지, 비디오 및 오디오 분석에 강력한 능력을 갖춘 첫 번째 멀티 모달 모델입니다. 이는 생성적 AI 모델의 응용 프로그램을 크게 확장시켰습니다. 이 블로그에서는 현재 텍스트 및 이미지 입력을 지원하는 API를 통해 이 모델을 사용하는 방법을 보여 드리려고 합니다. 모든 기능이 아직 제공되지 않았지만, OpenAI가 곧 출시할 예정입니다.\n\n# 특징\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 일반 텍스트 생성\n- JSON 모드의 텍스트 생성\n- 이미지 이해\n- 함수 호출\n\n초기 설정\n\nOpenAI 시크릿 키로 라이브러리를 설치하고 가져온 후, 환경 변수를 설정해주세요.\n\n```js\npip install --upgrade openai --quiet\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 단계는 OpenAI 클라이언트를 설정하는 것입니다. 이를 위해 먼저 시크릿 키로 환경 변수를 만들어야 합니다. OPENAI_KEY=xyz와 같이 OpenAI 시크릿 키가 저장된 .env 파일을 만들어주세요.\n\n작업이 완료되면 dotenv를 사용하여 키에 액세스할 수 있습니다.\n\n```python\nimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n## API 키 및 모델 이름 설정\nMODEL=\"gpt-4o\"\n\napi_key = os.getenv('OPENAI_KEY')\nclient = OpenAI(api_key=api_key)\n```\n\n일반 텍스트 생성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ncompletion = client.chat.completions.create(\n  model=MODEL,\n  messages=[\n    {\"role\": \"system\", \"content\": \"당신은 도움이 되는 조수입니다. 수학 숙제를 돕습니다!\"}, # \u003c-- 모델에 맥락을 제공하는 시스템 메시지입니다\n    {\"role\": \"user\", \"content\": \"안녕하세요! 2+2를 해결할 수 있나요?\"}  # \u003c-- 모델이 응답을 생성할 사용자 메시지입니다\n  ]\n)\n\nprint(\"조수: \" + completion.choices[0].message.content)\n```\n\n출력:\n\n물론이죠! 2 + 2 = 4. 다른 도움이 필요하시면 언제든지 물어보세요!\n\nJson 모드에서 텍스트 생성하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ncompletion = client.chat.completions.create(\n  model=MODEL,\n  response_format={\"type\": \"json_object\"},\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a trainer who always responds in JSON\"},\n    {\"role\": \"user\", \"content\": \"Create a weekly workout routine for me\"}\n  ]\n)\n\njson.loads(completion.choices[0].message.content)\n```\n\n출력:\n\n```bash\n'‘workoutRoutine’: '‘week’: 1, ‘days’: '‘Monday’: '‘muscleGroup’: ‘Chest and Triceps’, ‘exercises’: ['‘name’: ‘Bench Press’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Incline Dumbbell Press’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Tricep Dips’, ‘sets’: 3, ‘reps’: 15', '‘name’: ‘Tricep Pushdown’, ‘sets’: 3, ‘reps’: 15']', ‘Tuesday’: '‘muscleGroup’: ‘Back and Biceps’, ‘exercises’: ['‘name’: ‘Pull-Ups’, ‘sets’: 4, ‘reps’: 10', '‘name’: ‘Deadlifts’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Barbell Rows’, ‘sets’: 4, ‘reps’: 12', '‘name’: ‘Bicep Curls’, ‘sets’: 3, ‘reps’: 15']',\n```\n\n- 이미지 이해\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로컬 이미지 사용하기\n\n```js\nfrom IPython.display import Image, display, Audio, Markdown\nimport base64\n\nIMAGE_PATH = \"triangle.png\"\n\n# 컨텍스트를 위한 이미지 미리보기\ndisplay(Image(IMAGE_PATH))\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_1.png\" /\u003e\n\n```js\n# 이미지 파일 열고 base64 문자열로 인코딩하기\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n\nbase64_image = encode_image(IMAGE_PATH)\n\nresponse = client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"system\", \"content\": \"당신은 Markdown으로 응답하는 유용한 도우미입니다. 내 수학 숙제를 도와주세요!\"},\n        {\"role\": \"user\", \"content\": [\n            {\"type\": \"text\", \"text\": \"삼각형의 면적은 얼마인가요?\"},\n            {\"type\": \"image_url\", \"image_url\": {\n                \"url\": f\"data:image/png;base64,{base64_image}\"}\n            }\n        ]}\n    ],\n    temperature=0.0,\n)\n\nprint(response.choices[0].message.content)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n```bash\n삼각형의 면적을 찾기 위해 직갛각 삼각형의 면적을 구하는 공식을 사용할 수 있습니다: \\[ \\text{면적} = \\frac{1}{2} \\times \\text{밑변} \\times \\text{높이} \\] 이 삼각형에서 밑변은 20 cm이고 높이는 15 cm입니다. \\[ \\text{면적} = \\frac{1}{2} \\times 20 \\, \\text{cm} \\times 15 \\, \\text{cm} \\] \\[ \\text{면적} = \\frac{1}{2} \\times 300 \\, \\text{cm}² \\] \\[ \\text{면적} = 150 \\, \\text{cm}² \\] 따라서, 삼각형의 면적은 \\( 150 \\, \\text{cm}² \\)입니다.\n```\n\nURL을 사용하는 예시\n\n```js\nresponse = client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"system\", \"content\": \"마크다운으로 응답하는 유용한 도우미입니다.\"},\n        {\"role\": \"user\", \"content\": [\n            {\"type\": \"text\", \"text\": \"이 이미지에서 무엇을 보고 무슨 감정이 표현되었는지 설명해주세요.\"},\n            {\"type\": \"image_url\", \"image_url\": {\n                \"url\": \"https://pbs.twimg.com/media/GNeb4-Ua8AAuaKp?format=png\u0026name=small\"}\n            }\n        ]}\n    ],\n    temperature=0.0,\n)\n\nprint(response.choices[0].message.content)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지:\n\n![이미지](/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_2.png)\n\n결과:\n\n이 이미지는 웃는 사람을 보여줍니다. 전달되는 감정은 행복이나 만족으로 보입니다. 웃음은 긍정적이고 즐거운 기분을 시사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기능 호출\n\n```js\n# NBA 게임 점수를 가져 오기 위한 Mock 함수\ndef get_nba_game_score(team):\n    print('get_nba_game_score가 호출되었습니다.')\n    \"\"\"주어진 팀에 대한 NBA 게임의 현재 점수를 가져옵니다.\"\"\"\n    if \"lakers\" in team.lower():\n        return json.dumps({\"team\": \"Lakers\", \"score\": \"102\", \"opponent\": \"Warriors\", \"opponent_score\": \"98\"})\n    elif \"bulls\" in team.lower():\n        return json.dumps({\"team\": \"Bulls\", \"score\": \"89\", \"opponent\": \"Celtics\", \"opponent_score\": \"95\"})\n    else:\n        return json.dumps({\"team\": team, \"score\": \"N/A\", \"opponent\": \"N/A\", \"opponent_score\": \"N/A\"})\n```\n\n필요한 경우 도구를 통해 함수 호출:\n\n```js\ndef function_calling():\n    # 단계 1: 사용자 메시지로 대화를 초기화합니다\n    messages = [{\"role\": \"user\", \"content\": \"레이커스 게임 점수가 어떻게 되나요?\"}]\n\n    # 모델이 사용할 수있는 도구(함수) 정의\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"get_nba_game_score\",\n                \"description\": \"주어진 팀의 NBA 게임의 현재 점수를 가져옵니다.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"team\": {\n                            \"type\": \"string\",\n                            \"description\": \"NBA 팀의 이름, 예: 레이커스, 불스\",\n                        },\n                    },\n                    \"required\": [\"team\"],\n                },\n            },\n        }\n    ]\n\n    # 단계 2: 대화 컨텍스트와 사용 가능한 도구를 모델에게 전송합니다\n    response = client.chat.completions.create(\n        model=MODEL,\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",  # auto가 기본값입니다. 명시적으로 지정해줍니다.\n    )\n\n    # 모델의 응답을 추출합니다.\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls  # 모델이 도구를 호출하도록 요청하는지 확인합니다\n\n    # 단계 3: 모델이 요청한 도구 호출이 있는지 확인합니다\n    if tool_calls:\n        # 사용 가능한 함수 정의\n        available_functions = {\n            \"get_nba_game_score\": get_nba_game_score,\n        }  # 이 예제에서는 함수가 한 개뿐이지만 확장할 수 있습니다\n\n        # 모델의 응답을 대화 기록에 추가합니다\n        messages.append(response_message)\n\n        # 단계 4: 모델에서 요청된 함수를 호출합니다\n        for tool_call in tool_calls:\n            function_name = tool_call.function.name\n            function_to_call = available_functions[function_name]\n            function_args = json.loads(tool_call.function.arguments)\n\n            print(f\"도구 호출: {tool_call}\")\n\n            # 추출 된 인수로 함수를 호출합니다\n            function_response = function_to_call(\n                team=function_args.get(\"team\"),\n            )\n\n            # 함수 응답을 대화 기록에 추가합니다\n            messages.append(\n                {\n                    \"tool_call_id\": tool_call.id,\n                    \"role\": \"tool\",\n                    \"name\": function_name,\n                    \"content\": function_response,\n                }\n            )\n\n        # 단계 5: 업데이트된 기록을 사용하여 대화를 계속합니다\n        second_response = client.chat.completions.create(\n            model=MODEL,\n            messages=messages,\n        )  # 함수 응답을 확인할 수 있는 모델의 새로운 응답을 받습니다\n\n        return second_response\n\n# 대화를 실행하고 결과를 인쇄합니다\nresponse = function_calling()\nprint(response.choices[0].message.content)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n출력:\n\n도구 호출: ChatCompletionMessageToolCall(id='call_k2lcfdlVAcQ8PTUL1uwu3fYz', function=Function(arguments=' \"team\": \"Lakers\" ', name='get_nba_game_score'), type='function') get_nba_game_score 호출됨\n\n현재 레이커스 경기 점수는 레이커스 102, 워리어스 98 입니다.\n\n마무리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 전체 기사를 읽으셔서 GPT-4o 모델을 활용해 텍스트 생성, JSON 모드, 이미지 이해, 그리고 함수 호출을 OpenAI API를 통해 사용할 준비가 되셨습니다. API에 오디오 및 비디오 지원이 추가되면 다시 블로그를 쓸 계획입니다. 그 때까지 계속 탐험하고 배우세요!","ogImage":{"url":"/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png"},"coverImage":"/assets/img/2024-05-20-AccessingGPT-4oviaOpenAIAPI_0.png","tag":["Tech"],"readingTime":8},{"title":"BERT 코드와 함께하는 완벽 가이드","description":"","date":"2024-05-20 20:59","slug":"2024-05-20-ACompleteGuidetoBERTwithCode","content":"\n## 역사, 아키텍처, 사전 훈련 및 미세 조정\n\n\"LLMs from Scratch\" 시리즈의 제4부 - 대형 언어 모델을 이해하고 구축하는 완벽한 가이드입니다. 이러한 모델이 어떻게 작동하는지 알아보고 싶다면 아래 내용을 읽어보시기를 권장합니다:\n\n- Prologue: LLMs와 Transformers의 간단한 역사\n- 제1부: 토큰화 - 전체 가이드\n- 제2부: Python에서 처음부터 word2vec으로 단어 임베딩\n- 제3부: Self-Attention으로 Transformer 임베딩 생성\n- 제4부: 코드와 함께 BERT의 완전 가이드 - 역사, 아키텍처, 사전 훈련 및 미세 조정\n\n# 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n버트(Bidirectional Encoder Representations from Transformers)는 구글 AI Language에서 개발한 대규모 언어 모델(Large Language Model, LLM)로, 자연어 처리(Natural Language Processing, NLP) 분야에서 중요한 발전을 이루고 있습니다. 최근 몇 년간 많은 모델이 버트에 영감을 받아 발전하거나 직접적인 개선을 하였는데, RoBERTa, ALBERT, DistilBERT 등이 대표적입니다. 최초의 버트 모델은 OpenAI의 Generative Pre-trained Transformer (GPT) 이후 빠르게 공개되었으며, 둘 다 그 전년에 제안된 Transformer 아키텍처에 기반을 두었습니다. GPT는 자연어 생성(Natural Language Generation, NLG)에 초점을 맞추었지만, 버트는 자연어 이해(Natural Language Understanding, NLU)에 우선순위를 두었습니다. 이 두 개발은 NLP의 지형을 재편하며 기계 학습의 진전에 주목할 만한 이정표로 자리 잡았습니다.\n\n다음 글은 버트의 역사를 살펴보고, 창조 당시의 환경을 자세히 소개할 것입니다. 이를 통해 논문 저자들이 한 아키텍처적 결정 뿐만 아니라 산업 및 취미용 응용 프로그램에서 버트를 훈련하고 세밀 조정하는 방법을 이해할 수 있는 완전한 그림을 제공할 것입니다. 우리는 다이어그램으로 아키텍처를 자세히 살펴보고, 감정 분석 작업을 위해 버트를 세밀 조정하는 코드를 처음부터 작성해볼 것입니다.\n\n# 목차\n\n1 — 버트의 역사 및 주요 기능\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2 - 아키텍처 및 사전 훈련 목표\n\n3 - 감정 분석을 위한 BERT 파인 튜닝\n\n4 - 결론\n\n5 - 더 많은 독해\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1 — BERT의 역사 및 주요 기능\n\nBERT 모델은 다음 네 가지 주요 기능에 의해 정의될 수 있습니다:\n\n- 인코더 전용 구조\n- 사전 훈련 접근 방식\n- 모델 미세 조정\n- 양방향 문맥 활용\n\n이러한 기능 각각은 논문의 저자들이 만든 설계 선택사항이며, 이 모델이 생성된 시기를 고려하여 이해할 수 있습니다. 다음 섹션에서는 이러한 기능 각각을 살펴보고, 이러한 기능이 BERT의 동시대인 Transformer와 GPT에서 영감을 받았거나 그들을 개선하기 위한 것임을 보여줄 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 1.1 — 인코더 전용 아키텍처\n\n2017년 트랜스포머의 등장으로 혁신적인 디자인을 바탕으로 한 새로운 모델을 생산하기 위한 레이스가 시작되었습니다. OpenAI는 2018년 6월 첫 번째로 GPT를 만들어내 역량 있는 NLG를 자랑하며 나중에는 ChatGPT를 구동하는 모델을 발표했습니다. 구글은 이에 4개월 후인 BERT를 공개하여 NLU를 위해 설계된 인코더 전용 모델을 선보였습니다. 이 두 아키텍처 모두 매우 뛰어난 모델을 생산할 수 있지만 수행할 수 있는 작업들은 약간 다를 수 있습니다. 각 아키텍처에 대한 개요는 아래에서 제공됩니다.\n\n디코더 전용 모델:\n\n- 목표: 입력 시퀀스에 대한 새로운 출력 시퀀스 예측\n- 개요: 트랜스포머의 디코더 블록은 인코더에 제공된 입력을 바탕으로 출력 시퀀스를 생성하는 역할을 합니다. 디코더 전용 모델은 인코더 블록을 완전히 생략하고 여러 디코더를 단일 모델에 쌓아 올려 생성됩니다. 이러한 모델은 입력으로 프롬프트를 받아들이고, 다음 가장 확률이 높은 단어를 하나씩 예측함으로써 응답을 생성하는 작업으로 알려진 Next Token Prediction (NTP)이라는 작업을 수행합니다. 그 결과, 디코더 전용 모델은 대화형 챗봇, 기계 번역 및 코드 생성과 같은 NLG 작업에서 뛰어난 성능을 발휘합니다. 이러한 종류의 모델은 ChatGPT에서 구동되는 디코더 전용 모델 (GPT-3.5 및 GPT-4)의 광범위한 사용으로 인해 일반 대중에게 가장 익숙할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인코더 전용 모델:\n\n- 목표: 입력 시퀀스 내의 단어에 대한 예측 수행\n- 개요: Transformer의 인코더 블록은 입력 시퀀스를 수용하고 각 단어(또는 좀 더 구체적으로, 각 토큰)에 대한 풍부한 숫자 벡터 표현을 생성하는 역할을 합니다. 인코더 전용 모델은 디코더를 생략하고 여러 Transformer 인코더를 쌓아 하나의 모델을 생성합니다. 이러한 모델은 프롬프트를 수용하지 않고, 예측을 수행할 입력 시퀀스(예: 시퀀스 내의 빠진 단어를 예측)를 받습니다. 인코더 전용 모델은 새로운 단어 생성을 위해 디코더를 사용하지 않기 때문에 GPT와 같이 대화형 챗봇 애플리케이션에 사용되지 않습니다. 대신, 인코더 전용 모델은 대부분 NLU 작업인 Named Entity Recognition (NER) 및 감성 분석에 주로 사용됩니다. 인코더 블록에서 생성된 풍부한 벡터 표현은 BERT가 입력 텍스트를 심층적으로 이해하는 데 기여합니다. BERT 저자들은 이 구조적 선택이 BERT의 성능을 향상시킬 것이라고 주장했으며, 특히 디코더 전용 구조는 GPT와 비교하여 BERT의 성능을 향상시킬 것이라고 기술했습니다.\n\nTransformer, GPT 및 BERT를 위한 아키텍처 다이어그램:\n\n지금까지 논의한 세 모델에 대한 아키텍처 다이어그램이 아래에 나와 있습니다. 이는 원본 Transformer 논문 \"Attention is All You Need\" [2]의 아키텍처 다이어그램을 적응하여 작성되었습니다. 모델의 인코더 또는 디코더 블록 수는 N으로 표시됩니다. 원래 Transformer에서 인코더와 디코더 각각은 쌓인 6개의 인코더 및 디코더 블록으로 이루어져 있기 때문에, N은 각각 6입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png)\n\n## 1.2 — Pre-training Approach\n\nGPT은 BERT의 개발에 여러 가지 방식으로 영향을 미쳤습니다. 모델이 첫 번째 디코더 전용 변형 모델이었을 뿐만 아니라 GPT는 또한 모델 사전 훈련을 인기 있게 만들었습니다. 사전 훈련은 언어의 넓은 이해를 얻기 위해 단일 대형 모델을 훈련하는 것을 포함하며 이는 단어 사용 및 문법적 패턴과 같은 측면을 아우릅니다. 그 결과, 작업에 중립적인 기본 모델을 생성합니다. 위 다이어그램에서, 기본 모델은 선형 레이어 아래의 구성 요소들로 이루어져 있습니다 (보라색으로 표시됨). 훈련된 후, 이 기본 모델의 복사본은 특정 작업을 해결하기 위해 미세 조정될 수 있습니다. 미세 조정은 선형 레이어만 훈련하는 것을 의미합니다: 작은 피드포워드 신경망으로 종종 분류 헤드 또는 헤드라고 불립니다. 모델의 나머지 부분(즉, 기초 부분)에 있는 가중치와 바이어스는 변경되지 않거나 고정됩니다.\n\n아날로지:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간략한 비유를 만들어보겠습니다. 감성 분석 작업을 생각해보세요. 여기서 목표는 표현된 감정에 기반하여 텍스트를 긍정 또는 부정으로 분류하는 것입니다. 예를 들어, 어떤 영화 리뷰에서 \"이 영화를 사랑했다\"라는 텍스트는 긍정으로 분류되고, \"이 영화를 싫어했다\"라는 텍스트는 부정으로 분류될 것입니다. 전통적인 언어 모델링 접근 방식에서는 이 작업에 특화된 새로운 아키텍처를 일반적으로 처음부터 학습할 것입니다. 이것은 영화 리뷰를 보여주는 것으로 영어를 처음부터 가르치는 것과 같다고 생각할 수 있습니다. 물론, 이것은 느리고 비용이 많이 들며 많은 학습 예제가 필요합니다. 게다가, 그 결과로 얻는 분류기는 여전히 이 한 가지 작업에만 능숙할 것입니다. 대조적으로, 사전 훈련 접근 방식에서는 범용 모델을 가져와서 이를 감성 분석 작업에 대해 미세 조정합니다. 이것은 이미 영어에 능숙한 사람에게 현재 작업에 익숙해지도록 모자란 수의 영화 리뷰를 보여주는 것으로 생각할 수 있습니다. 아마도 두 번째 접근 방식이 훨씬 더 효율적하다는 것이 직관적일 것입니다.\n\n**사전 훈련에 대한 이전 시도:**\n\n사전 훈련 개념은 OpenAI에 의해 발명된 것이 아니며, 그 이전 몇 년 동안 다른 연구자들에의해 탐구되어왔습니다. 한 가지 주목할만한 예는 Allen Institute의 연구자들이 개발한 ELMo 모델(Embeddings from Language Models)입니다. 이전 시도에도 불구하고, OpenAI의 큰 논문에서처럼 다른 연구자들은 사전 훈련의 효과를 명백하게 입증하지 못했습니다. 그들 자신의 말에 따르면, 팀은 이 발견으로 사전 훈련 패러다임을 앞으로의 언어 모델링에서 우세한 접근 방식으로 확립시켰습니다. 이 추세와 일치하도록, BERT 저자들도 사전 훈련 접근 방식을 완전히 채택했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 1.3 — 모델 파인튜닝\n\n파인튜닝의 장점:\n\n파인튜닝은 오늘날 흔한 일로, 이러한 접근 방식이 주목받기 전 얼마나 최신인지 쉽게 간과하기 쉽습니다. 2018년 이전까지는 각기 다른 NLP 작업을 위해 새로운 모델 아키텍처를 도입하는 것이 일반적했습니다. 훈련을 사전에 시작함으로써 신규 모델 개발에 필요한 훈련 시간과 컴퓨팅 비용이 급격히 감소했을 뿐만 아니라 필요한 훈련 데이터의 양도 줄어들었습니다. 언어 모델을 처음부터 완전히 재설계하고 재훈련하는 대신 제네릭 모델인 GPT를 소량의 작업별 데이터로 파인튜닝함으로써 해당 시간을 분수로 줄일 수 있습니다.\n\n작업에 따라서 분류 헤드를 수정하여 다른 수의 출력 뉴런을 포함시킬 수 있습니다. 이는 감정 분석과 같은 분류 작업에 유용합니다. 예를 들어 BERT 모델의 원하는 출력이 리뷰가 긍정인지 부정인지 예측하는 것이라면, 헤드를 두 개의 출력 뉴런이 있는 형태로 변경할 수 있습니다. 각각의 활성화는 리뷰가 긍정인지 부정인지일 확률을 나타냅니다. 10 클래스로 구성된 다중 분류 작업의 경우, 헤드를 10개의 뉴런을 가진 출력 레이어로 변경할 수 있습니다. 이렇게 함으로써 BERT를 더 다양하게 활용할 수 있어 여러 하류 작업에 기본 모델이 사용될 수 있습니다.\n\nBERT의 파인튜닝:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBERT은 GPT의 발자취를 따르며 사전 훈련/미세 조정 접근 방식을 채택했습니다. 구글은 BERT의 두 가지 버전을 출시했는데, Base와 Large로 하드웨어 제약에 따라 모델 크기를 유저에게 유연하게 제공했습니다. 양쪽 모델 모두 많은 TPUs(텐서 처리 장치)에서 약 4일이 걸렸다고 하는데, BERT Base는 16개의 TPUs에서 훈련되었고 BERT Large는 64개의 TPUs에서 훈련되었습니다. 대부분의 연구자, 취미로 연구하는 사람들 및 산업 실무자들에게는 이 수준의 훈련이 현실적이지 않을 수 있습니다. 그래서 어떤 특정 작업에 기초 모델을 몇 시간 동안 미세 조정하는 아이디어는 훨씬 더 매력적인 대안입니다. 원래 BERT 아키텍처는 다양한 작업과 데이터셋에 걸쳐 수천 번의 미세 조정 이터레이션을 거쳤는데, 이 중 많은 것들이 Hugging Face와 같은 플랫폼에서 공개적으로 다운로드할 수 있습니다.\n\n## 1.4 — 양방향 컨텍스트 사용\n\n언어 모델로, BERT는 이전 단어가 관찰되었을 때 특정 단어가 관측될 확률을 예측합니다. 이 기본적인 측면은 아키텍처와 의도된 작업에 관계없이 모든 언어 모델이 공유하는 것입니다. 그러나 모델이 이러한 확률을 활용하는 것이 모델의 특정 작업에 적합한 행동을 부여합니다. 예를 들어 GPT는 시퀀스에서 다음으로 가장 가능성이 높은 단어를 예측하도록 훈련됩니다. 즉, 모델은 이전 단어가 관찰되었을 때 다음 단어를 예측합니다. 다른 모델들은 감정 분석에 훈련될 수 있고, 긍정적 또는 부정적과 같은 텍스트 라벨을 사용하여 입력 시퀀스의 감정을 예측할 수 있습니다. 텍스트에 대한 어떠한 의미 있는 예측을 하려면 주변 컨텍스트가 이해되어야 합니다. 특히 NLU 작업에서는 BERT가 이러한 이해를 보장하여 양방향성이라는 핵심 특성 중 하나를 통해 우수한 이해를 제공합니다.\n\n양방향성은 아마도 BERT의 가장 중요한 특징인데, NLU 작업에서 BERT의 높은 성능의 중요한 이유이며, 또한 모델의 인코더 전용 아키텍처의 주요 동기입니다. Transformer 인코더의 self-attention 메커니즘은 양방향 컨텍스트를 계산하지만, 이와 같은 것을 할 수 없는 디코더는 단방향 컨텍스트를 생산합니다. BERT 저자들은 GPT의 이 양방향성 부족으로 인해 BERT만큼의 언어 표현 깊이를 달성하지 못한다고 주장했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n양방향성 정의하기:\n\n그렇다면 \"양방향성\"이라는 맥락이 정확히 무엇을 의미할까요? 여기서 양방향성은 입력 시퀀스의 각 단어가 앞뒤 단어(좌측 맥락과 우측 맥락이라고 함)로부터 맥락을 확보할 수 있다는 것을 의미합니다. 기술적인 용어로는 어텐션 메커니즘이 각 단어에 대해 이전 및 이후의 토큰에 주의를 기울일 수 있다고 말합니다. 이를 분해해보면 BERT는 입력 시퀀스 내 단어에 대해서만 예측을 하고 GPT처럼 새로운 시퀀스를 생성하지는 않습니다. 따라서 BERT가 입력 시퀀스 내의 단어를 예측할 때, 모든 주변 단어에서 문맥적 단서를 접목할 수 있습니다. 이는 양방향으로 문맥을 제공하므로 BERT가 보다 정보를 기반으로 한 예측을 할 수 있도록 도와줍니다.\n\n이를 GPT와 같은 디코더 전용 모델과 대조해보면, 여기서 목표는 출력 시퀀스를 생성하기 위해 한 번에 새로운 단어를 예측하는 것입니다. 각 예측된 단어는 이전 단어가 제공한 맥락(좌측 맥락)만 활용할 수 있으며, 그 이후의 단어(우측 맥락)는 아직 생성되지 않았습니다. 그러므로 이러한 모델을 단방향으로 지칭합니다.\n\n![이미지](\"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_1.png\")\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지 설명:\n\n위의 이미지는 양방향 컨텍스트를 사용하는 전형적인 BERT 작업과 단방향 컨텍스트를 사용하는 전형적인 GPT 작업의 예시를 보여줍니다. BERT에서는 이 [MASK]로 표시된 가리킨 가림막된 단어를 예측하는 것이 작업입니다. 이 단어는 왼쪽과 오른쪽에 단어가 있기 때문에 양쪽의 단어를 사용하여 컨텍스트를 제공할 수 있습니다. 만약 당신이 인간으로써 이 문장을 왼쪽 또는 오른쪽 컨텍스트만 가지고 읽는다면, 가리킨 가림막된 단어를 본인이 예측하기 어려울 것입니다. 그러나 양방향 컨텍스트를 사용하면 가림막된 단어가 'fishing'이라는 것을 추측하는 것이 훨씬 더 가능해집니다.\n\nGPT의 경우, 목표는 전통적인 NTP 작업을 수행하는 것입니다. 이 경우, 목적은 입력 시퀀스 및 이미 생성된 단어를 기반으로 새로운 시퀀스를 생성하는 것입니다. 입력 시퀀스가 모델에게 시를 쓰라는 지시를 준 상황에서 이미 생성된 단어가 \"Upon a\" 인 것을 고려한다면, 다음 단어는 \"river\"가 될 것으로 예상해볼 수 있습니다. 여러 후보 단어가 있을 때 GPT(언어 모델로서)는 어휘 중 각 단어가 다음에 나타날 가능성을 계산하고 훈련 데이터를 기반으로 가장 가능성이 높은 단어 중 하나를 선택합니다.\n\n## 1.5 — BERT의 한계\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n양방향 모델로서 BERT는 두 가지 주요 단점을 가지고 있습니다:\n\n1. 훈련 시간이 증가합니다:\n\n트랜스포머 기반 모델의 양방향성은 당시 주류였던 좌측에서 우측으로의 문맥 모델에 대한 직접적인 개선으로 제안되었습니다. GPT는 입력 시퀀스에 대한 문맥 정보를 일방적으로만 얻을 수 있기 때문에 단어 사이의 인과 관계에 대해 완전히 파악하지 못했습니다. 그러나 양방향 모델은 단어 간의 인과 관계를 보다 포괄적으로 이해할 수 있으므로 NLU 작업에서 보다 나은 결과를 볼 수 있습니다. 과거에 양방향 모델이 탐구되었지만, 늦은 1990년대의 양방향 RNN과 같은 한계가 있었습니다. 일반적으로 이러한 모델들은 훈련을 위해 더 많은 계산 리소스를 요구하기 때문에 동일한 계산 성능을 달성하기 위해서는 더 큰 단방향 모델을 훈련해야 합니다.\n\n2. 언어 생성 작업에서 성능이 저하됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBERT는 NLU 작업을 해결하기 위해 특별히 설계되었으며, 디코더 및 새로운 시퀀스를 생성하는 능력을 포기하고 인코더 및 입력 시퀀스에 대한 풍부한 이해를 개발하는 것으로 대체했습니다. 결과적으로 BERT는 NER, 감정 분석 등과 같은 NLP 작업 부분에 최적화되어 있습니다. 특히, BERT는 프롬프트를 수용하지 않고 대신 입력 시퀀스를 처리하여 예측을 작성합니다. BERT는 기술적으로 새로운 출력 시퀀스를 생성할 수 있지만, LLM(언어 모델)의 설계적 차이를 인지하고 중대하게 생각해야 합니다. ChatGPT 시대 이후의 LLM들을 생각할 때와 BERT 설계의 현실과의 차이를 인지하는 것이 중요합니다.\n\n## 2 — 아키텍처 및 사전 훈련 목표\n\n### 2.1 — BERT의 사전 훈련 목표 개요\n\n양방향 모델을 훈련시키려면 좌/우 컨텍스트가 모두 예측에 활용되는 작업이 필요합니다. 따라서 저자들은 BERT의 언어 이해를 강화하기 위해 주의 깊게 2가지 사전 훈련 목표를 구성했습니다. 이것들은 Masked Language Model(MLM) 작업과 Next Sentence Prediction(NSP) 작업이었습니다. 각각의 훈련 데이터는 당시 사용 가능한 모든 영어 위키피디아 기사 (25억 단어)와 BookCorpus 데이터셋의 추가 11,038권의 책 (8억 단어)로 구성되었습니다. 초기 데이터는 구체적인 작업에 따라 전처리되어야 했지만, 아래에서 설명한 대로 수행되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.2 — 마스크된 언어 모델링 (MLM)\n\nMLM 개요:\n\n마스크된 언어 모델링 작업은 양방향 모델을 훈련해야 하는 필요를 직접적으로 해결하기 위해 만들어졌습니다. 이를 위해 모델은 입력 시퀀스의 좌측 문맥과 우측 문맥을 모두 사용하여 예측을 수행하도록 훈련되어야 합니다. 이는 훈련 데이터에서 15%의 단어를 무작위로 마스크하고 BERT를 사용하여 누락된 단어를 예측하도록 훈련함으로써 달성됩니다. 입력 시퀀스에서 마스크된 단어는 [MASK] 토큰으로 대체됩니다. 예를 들어, 책 코퍼스에서 발견된 원시 훈련 데이터 중에 A man was fishing on the river 라는 문장이 있다고 가정해보겠습니다. MLM 작업에 대한 훈련 데이터로 원시 텍스트를 변환할 때, 단어 fishing이 무작위로 마스크되어 [MASK] 토큰으로 대체될 수 있으며, 이는 훈련 입력 A man was [MASK] on the river with target fishing을 제공합니다. 따라서 BERT의 목표는 단일 누락된 단어 fishing을 예측하는 것이며, 누락된 단어가 채워진 입력 시퀀스를 재생산하는 것이 아닙니다. 마스킹 프로세스는 MLM 작업의 훈련 데이터를 작성할 때 모든 가능한 입력 시퀀스(예: 문장)에 반복적으로 적용될 수 있습니다. 이 작업은 이전에 언어학 문헌에서 존재했었으며 Cloze 작업으로 알려져 있습니다.[8] 그러나 기계 학습 맥락에서는 BERT의 인기로 인해 MLM으로 흔히 언급됩니다.\n\n미세 조정과 사전 훈련 간 불일치 완화 방법:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저자들은 그러나 [MASK] 토큰은 훈련 데이터에만 나타나고 라이브 데이터(추론 시간)에는 나타나지 않기 때문에 사전 훈련과 세부 튜닝 간에 불일치가 있을 것이라고 지적했습니다. 이를 완화하기 위해 모든 마스킹된 단어가 [MASK] 토큰으로 대체되는 것은 아닙니다. 저자들은 대신 다음과 같이 설명합니다:\n\n예측 단어와 목표 단어 사이의 오차 계산:\n\nBERT는 BERT Base 및 BERT Large 모두 최대 512개의 토큰을 입력으로 받습니다. 시퀀스에서 최대 토큰 수보다 적은 경우, [PAD] 토큰을 사용하여 패딩이 추가되어 최대 512개에 도달합니다. 출력 토큰 수도 입력 토큰 수와 정확히 일치합니다. 입력 시퀀스의 i 위치에 마스크 토큰이 있는 경우, BERT의 예측은 출력 시퀀스의 i 위치에 있을 것입니다. 훈련 목적으로 다른 모든 토큰은 무시되므로 모델의 가중치 및 편향에 대한 업데이트는 입력 시퀀스의 i 위치에 있는 예측 토큰과 목표 토큰 간의 오차를 기반으로 계산됩니다. 이 오차는 Cross Entropy Loss(음의 로그 우도) 함수를 사용하여 계산됩니다. 이러한 내용은 나중에 보게 될 것입니다.\n\n## 2.3 — 다음 문장 예측 (NSP)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개요:\n\nBERT의 사전 학습 작업 중 두 번째는 Next Sentence Prediction입니다. 이 작업은 하나의 세그먼트(일반적으로 문장)가 다른 세그먼트를 논리적으로 잇는지 분류하는 것을 목표로 합니다. NSP를 사전 학습 작업으로 선택한 이유는 MLM을 보완하고 BERT의 NLU 능력을 향상시키기 위한 것이며, 저자들은 다음과 같이 설명합니다:\n\nNSP에 대해 사전 학습함으로써, BERT는 채의 흐름에 대한 이해를 발전시킬 수 있으며, 이는 많은 NLU 문제에 유용합니다. 예를 들어 다음과 같은 것들이 있습니다:\n\n- 내용을 바꿔 말한 문장 쌍\n- 추론을 위한 가설-전제 쌍\n- 질문 응답에서 질문-통과 문장 쌍\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBERT에서의 NSP 구현:\n\nNSP의 입력은 첫 번째와 두 번째 세그먼트(표시된 A 및 B)로 구성되며 두 번째 [SEP] 토큰이 있는 [SEP] 토큰으로 구분되고 끝에 두 번째 [SEP] 토큰이 있습니다. BERT는 실제로 NSP를 수행하든 아니든 입력 시퀀스 당 최소한 하나의 [SEP] 토큰을 예상합니다. 이 토큰은 시퀀스의 끝을 나타내며, MLM 작업에 대한 입력의 끝에 이러한 토큰 중 하나가 추가됩니다. 또한, NSP가 포함되지 않은 다른 모든 작업들에 대해서도 동일한 처리가 이루어집니다. NSP는 분류 문제를 형성하며, 출력은 A 세그먼트가 B 세그먼트를 논리적으로 따르는 경우 IsNext에 해당하고, 그렇지 않은 경우 NotNext에 해당합니다. 교육 데이터는 단어 조각(WordPiece) 토크나이저가 50%의 경우에는 다음 문장과 함께 문장을 선택하고, 나머지 50%의 경우에는 무작위 문장을 선택함으로써 어떤 단일 언어 말뭉치에서 쉽게 생성할 수 있습니다.\n\nBERT의 입력 임베딩:\n\nBERT의 입력 임베딩 과정은 위치 인코딩, 세그먼트 임베딩 및 토큰 임베딩 세 단계로 구성됩니다(아래 다이어그램 참조).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위치 인코딩:\n\nTransformer 모델과 마찬가지로 각 토큰의 임베딩에 위치 정보가 주입됩니다. 그러나 Transformer와 달리 BERT의 위치 인코딩은 고정되어 있고 함수에 의해 생성되지 않습니다. 이는 BERT가 BERT 베이스와 BERT 라지의 입력 시퀀스에서 512개의 토큰으로 제한된다는 것을 의미합니다.\n\n세그먼트 임베딩:\n\n각 토큰이 속한 세그먼트를 인코딩하는 벡터도 추가됩니다. MLM 사전 훈련 작업 또는 다른 NSP 작업(단일 [SEP] 토큰만 있는 경우)의 경우 입력의 모든 토큰은 세그먼트 A에 속하는 것으로 간주됩니다. NSP 작업의 경우, 두 번째 [SEP] 이후의 모든 토큰은 세그먼트 B로 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토큰 임베딩:\n\n원래의 Transformer와 마찬가지로 각 토큰에 대해 학습된 임베딩은 위치 및 세그먼트 벡터에 추가되어 BERT에서 자기 주의 메커니즘에 전달되는 최종 임베딩을 만들어 내며 문맥 정보를 추가합니다.\n\n![이미지](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_2.png)\n\n## 2.5 — 특별 토큰\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 이미지에서 볼 수 있었듯이 입력 시퀀스에는 [CLS] (분류) 토큰이 앞에 추가되었습니다. 이 토큰은 전체 입력 시퀀스의 의미론적 의미를 요약하고, BERT가 분류 작업을 수행하는 데 도움이 됩니다. 예를 들어, 감성 분석 작업에서 최종 층의 [CLS] 토큰은 입력 시퀀스의 감정이 긍정적인지 부정적인지 예측 추출하기 위해 분석될 수 있습니다. [CLS] 및 [PAD] 등은 BERT의 특수 토큰 예시입니다. 여기서 BERT의 특수 토큰은 총 다섯 개 있습니다. 아래에 요약을 제공합니다:\n\n- [PAD] (토큰 ID: 0) — 512개 토큰으로 구성된 입력 시퀀스의 총 수를 맞추기 위해 사용되는 패딩 토큰.\n- [UNK] (토큰 ID: 100) — BERT 어휘에 없는 토큰을 나타내기 위해 사용되는 알 수 없는 토큰.\n- [CLS] (토큰 ID: 101) — 분류 토큰으로 기대되는 것은 각 시퀀스의 시작 부분에 나타냅니다. 이러한 토큰은 분류 작업을 위한 클래스 정보를 캡슐화하며, 종합적인 시퀀스 표현으로 생각할 수 있습니다.\n- [SEP] (토큰 ID: 102) — 단일 입력 시퀀스의 두 세그먼트를 구분하는 데 사용되는 구분자 토큰 (예: Next Sentence Prediction). 적어도 입력 시퀀스 당 하나의 [SEP] 토큰이 필요하며, 최대 두 개까지 사용 가능합니다.\n- [MASK] (토큰 ID: 103) — 마스크 토큰은 BERT를 마스킹된 언어 모델링 작업으로 훈련하거나 마스크된 시퀀스에 대한 추론을 수행하는 데 사용됩니다.\n\n## 2.4 — BERT Base와 BERT Large의 아키텍처 비교\n\nBERT Base와 BERT Large는 아키텍처적으로 매우 유사합니다. 두 모델 모두 WordPiece 토크나이저를 사용하여(따라서 앞에서 설명한 동일한 특수 토큰을 사용) 최대 시퀀스 길이가 512 토큰입니다. BERT의 어휘 크기는 30,522이며, 그 중 약 1,000 개의 토큰은 \"사용되지 않은\" 상태를 유지합니다. 사용되지 않은 토큰은 사용자가 전체 토크나이저를 다시 훈련하지 않고 사용자 지정 토큰을 추가할 수 있도록 고의로 비워둡니다. 의료 및 법률 용어와 같은 도메인별 어휘와 함께 작업할 때 유용합니다. BERT Base와 BERT Large는 원래 Transformer의 embedding 차원 (d_model)보다 높은 수를 갖습니다. 이는 모델의 어휘에 대해 학습된 벡터 표현의 크기에 해당합니다. BERT Base의 d_model은 768이며, BERT Large의 d_model은 1024입니다(원래 Transformer의 512를 두 배 증가시킨 값).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 모델은 주로 네 가지 범주에서 차이가 있습니다:\n\n- 인코더 블록의 수, N: 서로 쌓인 인코더 블록의 수입니다.\n- 인코더 블록 당 어텐션 헤드 수: 어텐션 헤드는 입력 시퀀스의 문맥 벡터 임베딩을 계산합니다. BERT는 멀티헤드 어텐션을 사용하므로, 이 값은 인코더 레이어 당 헤드 수를 나타냅니다.\n- 피드포워드 네트워크의 은닉층 크기: 선형 레이어는 고정된 뉴런 수(예: BERT Base의 경우 3072)를 가진 은닉층으로 구성되며, 다양한 크기의 출력 레이어로 이어집니다. 출력 레이어의 크기는 작업에 따라 다릅니다. 예를 들어, 이진 분류 문제는 단지 두 개의 출력 뉴런이 필요하고, 10개 클래스를 가진 다중 클래스 분류 문제는 10개의 뉴런이 필요합니다.\n- 총 매개변수: 모델 내 가중치와 바이어스의 총 수입니다. 당시 수억 개의 모델이 매우 큰 것으로 여겨졌지만, 오늘날 기준에서는 이 값들이 상대적으로 작습니다.\n\n이러한 범주별 BERT Base와 BERT Large간의 비교는 아래 이미지에서 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3 — 감정 분석을 위한 BERT Feine-Tuning\n\n이 섹션에서는 파이썬을 사용하여 BERT를 세밀 조정하는 실제 예제를 다룹니다. 코드는 작업에 무관한 세밀 조정 파이프라인 형태로, 파이썬 클래스에 구현되어 있습니다. 그런 다음 이 클래스의 객체를 생성하고 이를 사용하여 감정 분석 작업에 대해 BERT 모델을 세밀 조정할 것입니다. 이 클래스는 질문 응답, 개체 인식 등 다른 작업에 대해 BERT를 세밀 조정하는 데 재사용할 수 있습니다. 섹션 3.1에서 3.5는 세밀 조정 과정을 설명하며, 섹션 3.6에서는 전체 파이프라인을 보여줍니다.\n\n## 3.1 — 세밀 조정 데이터 집합 로드 및 전처리\n\n세밀 조정의 첫 번째 단계는 특정 작업에 적합한 데이터 집합을 선택하는 것입니다. 이 예제에서는 스탠퍼드 대학이 제공하는 감정 분석 데이터 세트를 사용할 것입니다. 이 데이터 세트에는 인터넷 영화 데이터베이스 (IMDb)에서 가져온 5만 개의 온라인 영화 리뷰가 포함되어 있으며, 각 리뷰는 긍정적 또는 부정적으로 레이블이 지정되어 있습니다. 스탠퍼드 대학 웹사이트에서 데이터 세트를 직접 다운로드할 수도 있고, Kaggle에서 노트북을 만들어 작업 결과를 다른 사람들과 비교할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport pandas as pd\n\ndf = pd.read_csv('IMDB Dataset.csv')\ndf.head()\n```\n\n![image](/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_4.png)\n\n이제 이전의 NLP 모델과 달리 BERT와 같은 Transformer 기반 모델은 최소한의 전처리가 필요합니다. 불용어(stop words) 및 구두점을 제거하는 단계는 경우에 따라 오히려 역효과를 낼 수 있습니다. 이러한 요소들은 BERT가 입력 문장을 이해하기 위한 중요한 맥락을 제공하기 때문입니다. 그럼에도 불구하고 텍스트를 검사하여 형식 문제나 원치 않는 문자가 있는지 확인하는 것이 여전히 중요합니다. 전반적으로 IMDb 데이터셋은 꽤 깨끗합니다. 그러나 스크래핑 프로세스에서 남은 몇 가지 흔적, 예를 들면 HTML 태그(`\u003cbr /\u003e`)나 불필요한 공백과 같은 것들을 제거해야 합니다.\n\n```js\n# 줄바꿈 태그(\u003cbr /\u003e) 제거\ndf['review_cleaned'] = df['review'].apply(lambda x: x.replace('\u003cbr /\u003e', ''))\n\n# 불필요한 공백 제거\ndf['review_cleaned'] = df['review_cleaned'].replace('\\s+', ' ', regex=True)\n\n# 첫 번째 리뷰의 72자를 비교하여 클리닝 전/후 출력\nprint('클리닝 전:')\nprint(df.iloc[1]['review'][0:72])\n\nprint('\\n클리닝 후:')\nprint(df.iloc[1]['review_cleaned'][0:72])\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nBefore cleaning:\nA wonderful little production. \u003cbr /\u003e\u003cbr /\u003eThe filming technique is very\n\nAfter cleaning:\nA wonderful little production. The filming technique is very unassuming-\n```\n\n감정 인코딩:\n\n전처리의 마지막 단계는 각 리뷰의 감정을 부정인 경우 0 또는 긍정인 경우 1로 인코딩하는 것입니다. 이러한 레이블은 나중에 미세 조정 프로세스에서 분류 헤드를 훈련하는 데 사용될 것입니다.\n\n```js\ndf['sentiment_encoded'] = df['sentiment'].\\\n    apply(lambda x: 0 if x == 'negative' else 1)\ndf.head()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_5.png\" /\u003e\n\n## 3.2 — 데이터 파인튜닝에 토큰화 적용하기\n\n전처리된 이후, 데이터를 파인튜닝할 수 있도록 토큰화가 진행됩니다. 이 과정은 리뷰 텍스트를 개별 토큰으로 분리하고, [CLS] 및 [SEP] 특수 토큰을 추가하며, 패딩을 처리합니다. 모델에 적합한 토크나이저를 선택하는 것이 중요합니다. 다양한 언어 모델은 서로 다른 토큰화 단계가 필요하기 때문입니다 (예: GPT는 [CLS] 및 [SEP] 토큰을 요구하지 않습니다). 본 가이드에서는 Hugging Face transformers 라이브러리의 BertTokenizer 클래스를 사용할 것입니다. 이 클래스는 BERT 기반 모델과 함께 사용하도록 설계되었습니다. 토큰화가 작동하는 방식에 대한 더 자세한 설명은 본 시리즈의 Part 1을 참조하세요.\n\ntransformers 라이브러리의 Tokenizer 클래스들은 from_pretrained 메서드를 사용하여 사전 훈련된 토크나이저 모델을 간단히 생성할 수 있는 방법을 제공합니다. 이 기능을 사용하려면: 토크나이저 클래스를 가져와서 인스턴스화하고, from_pretrained 메서드를 호출하고, Hugging Face 모델 저장소에 호스팅된 토크나이저 모델 이름을 나타내는 문자열을 전달하면 됩니다. 또는 토크나이저가 요구하는 어휘 파일이 포함된 디렉토리 경로를 전달할 수도 있습니다. 이 예시에서는 모델 저장소에서 사전 훈련된 토크나이저를 사용할 것입니다. BERT를 다룰 때 주요한 옵션은 네 가지가 있으며, 각각 구글의 사전 훈련 토크나이저 어휘를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- bert-base-uncased — BERT의 작은 버전에 대한 어휘 사전으로 대소문자를 구분하지 않습니다 (예: 토큰 Cat과 cat은 동일하게 처리됩니다)\n- bert-base-cased — BERT의 작은 버전에 대한 어휘 사전으로 대소문자를 구분합니다 (예: 토큰 Cat과 cat은 동일하게 처리되지 않습니다)\n- bert-large-uncased — BERT의 큰 버전에 대한 어휘 사전으로 대소문자를 구분하지 않습니다 (예: 토큰 Cat과 cat은 동일하게 처리됩니다)\n- bert-large-cased — BERT의 큰 버전에 대한 어휘 사전으로 대소문자를 구분합니다 (예: 토큰 Cat과 cat은 동일하게 처리되지 않습니다)\n\nBERT Base와 BERT Large는 동일한 어휘 사전을 사용하므로 bert-base-uncased와 bert-large-uncased 사이에는 차이가 없으며, bert-base-cased와 bert-large-cased 사이에도 차이가 없습니다. 다른 모델의 경우에는 이와 같지 않을 수 있으므로 확실하지 않을 경우 동일한 토크나이저와 모델 크기를 사용하는 것이 가장 좋습니다.\n\n대소문자 사용 여부 선택:\n\n대소문자 사용 여부를 선택하는 것은 데이터셋의 특성에 따라 달라집니다. IMDb 데이터셋은 인터넷 사용자가 작성한 텍스트를 포함하고 있으며 대문자 사용에 일관성이 없는 경우가 있을 수 있습니다. 예를 들어 일부 사용자는 예상대로 대문자를 생략하거나 강조를 위해 대문자를 사용할 수 있습니다. 이러한 이유로 대소문자를 무시하고 bert-base-uncased 토크나이저 모델을 사용하기로 결정했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 상황에서는 케이스를 고려하여 성능상의 이점을 볼 수 있습니다. 여기 예제 중 하나는 Named Entity Recognition 작업에서, 즉 사람, 조직, 위치 등을 텍스트에서 식별하는 것이 목표인 경우입니다. 이 경우 대문자의 존재는 단어가 누군가의 이름인지 아니면 장소인지를 식별하는 데 매우 도움이 될 수 있어서, 이 상황에서는 bert-base-cased를 선택하는 것이 더 적절할 수 있습니다.\n\nMarkdown 형식으로 표를 변경합니다.\n\n```js\nfrom transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nprint(tokenizer)\n```\n\n```js\nBertTokenizer(\n  (name_or_path = \"bert-base-uncased\"),\n  (vocab_size = 30522),\n  (model_max_length = 512),\n  (is_fast = False),\n  (padding_side = \"right\"),\n  (truncation_side = \"right\"),\n  (special_tokens = {\n    unk_token: \"[UNK]\",\n    sep_token: \"[SEP]\",\n    pad_token: \"[PAD]\",\n    cls_token: \"[CLS]\",\n    mask_token: \"[MASK]\",\n  }),\n  (clean_up_tokenization_spaces = True)\n),\n  (added_tokens_decoder = {\n    0: AddedToken(\n      \"[PAD]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    100: AddedToken(\n      \"[UNK]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    101: AddedToken(\n      \"[CLS]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    102: AddedToken(\n      \"[SEP]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n\n    103: AddedToken(\n      \"[MASK]\",\n      (rstrip = False),\n      (lstrip = False),\n      (single_word = False),\n      (normalized = False),\n      (special = True)\n    ),\n  });\n```\n\n인코딩 프로세스: 텍스트를 토큰으로 변환하여 토큰 ID로 변환하기.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 토크나이저를 사용하여 정제된 파인 튜닝 데이터를 인코딩할 수 있어요. 이 과정은 각 리뷰를 토큰 ID들의 텐서로 변환할 거예요. 예를 들어, 리뷰인 'I liked this movie'는 다음 단계를 통해 인코딩되어요:\n\n1. 리뷰를 소문자로 변환하기 (우리가 'bert-base-uncased'를 사용하고 있으니)\n\n2. 리뷰를 'bert-base-uncased' 어휘에 따라 개별 토큰으로 분리하기: [`i`, `liked`, `this`, `movie`]\n\n3. BERT가 기대하는 특수 토큰을 추가하기: [`[CLS]`, `i`, `liked`, `this`, `movie`, `[SEP]`]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 병합된 토큰을 bert-base-uncased 어휘에 따라 해당 토큰 ID로 변환합니다. (예: [CLS] - 101, i - 1045 등)\n\nBertTokenizer 클래스의 encode 메서드는 위 과정을 사용하여 텍스트를 인코딩하고, PyTorch 텐서, Tensorflow 텐서 또는 NumPy 배열로 된 토큰 ID의 텐서를 반환할 수 있습니다. 반환 텐서의 데이터 유형은 return_tensors 인자를 사용하여 지정할 수 있으며, 각각 pt, tf, np 값을 취합니다.\n\n```js\n# 샘플 입력 문장을 인코딩합니다\nsample_sentence = 'I liked this movie'\ntoken_ids = tokenizer.encode(sample_sentence, return_tensors='np')[0]\nprint(f'Token IDs: {token_ids}')\n\n# 특수 토큰이 추가된 토큰 ID를 토큰으로 다시 변환하여 확인합니다\ntokens = tokenizer.convert_ids_to_tokens(token_ids)\nprint(f'Tokens   : {tokens}')\n```\n\n```js\nToken IDs: [ 101 1045 4669 2023 3185  102]\nTokens   : ['[CLS]', 'i', 'liked', 'this', 'movie', '[SEP]']\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTruncation and Padding:\n\nBERT Base 및 BERT Large는 정확히 512토큰의 입력 시퀀스를 처리하기 위해 설계되었습니다. 그러나 입력 시퀀스가 이 제한에 맞지 않는 경우 어떻게 해야 할까요? 그 답은 Truncation과 Padding입니다! Truncation은 특정 길이 이상의 어떠한 토큰도 간단히 제거하여 토큰 수를 줄입니다. encode 메서드에서 truncation을 True로 설정하고 모든 인코딩된 시퀀스에 길이 제한을 부여할 max_length 인수를 지정할 수 있습니다. 이 데이터 세트의 여러 항목은 512토큰 제한을 초과하므로 여기서 max_length 매개변수가 모든 리뷰에서 가능한 가장 많은 텍스트를 추출하기 위해 512로 설정되었습니다. 리뷰가 512토큰을 초과하는 경우가 없다면 max_length 매개변수를 설정하지 않고 남기면 모델의 최대 길이로 기본 설정됩니다. 또는 Feine-Tuning 중에 학습 시간을 줄이기 위해 512보다 작은 최대 길이를 여전히 강제로 지정할 수 있지만 모델 성능의 손실이 발생합니다. (대부분이 그렇지만) 512토큰보다 짧은 리뷰의 경우 패딩 토큰이 추가되어 인코딩된 리뷰가 512토큰으로 확장됩니다. 이렇게 설정하는 방법에 대해서는 패딩 매개변수를 max_length로 설정하면 됩니다. encode 매서드에 대한 자세한 내용은 Hugging Face 문서를 참조하십시오 [10].\n\n```js\nreview = df[\"review_cleaned\"].iloc[0];\n\ntoken_ids = tokenizer.encode(\n  review,\n  (max_length = 512),\n  (padding = \"max_length\"),\n  (truncation = True),\n  (return_tensors = \"pt\")\n);\n\nprint(token_ids);\n```\n\n```js\ntensor([\n  [\n    101,\n    2028,\n    1997,\n    1996,\n    2060,\n    15814,\n    2038,\n    3855,\n    2008,\n    2044,\n    3666,\n    2074,\n    1015,\n    11472,\n    2792,\n    2017,\n    1005,\n    2222,\n    2022,\n    13322,\n\n    ...0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n    0,\n  ],\n]);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAttention Mask을 encode_plus와 함께 사용하기:\n\n위의 예제는 데이터셋에서 첫 번째 리뷰의 인코딩을 보여줍니다. 이 리뷰에는 119개의 패딩 토큰이 포함되어 있습니다. 현재 상태로 fine-tuning에 사용된다면, BERT는 패딩 토큰에 주의를 기울일 수 있어 성능이 떨어질 수 있습니다. 이를 해결하기 위해 입력에서 특정 토큰(이 경우 패딩 토큰)을 무시하도록 BERT에 지시하는 attention mask를 적용할 수 있습니다. 위의 코드를 수정하여 encode_plus 메소드를 사용하면 이러한 attention mask를 생성할 수 있습니다. encode_plus 메소드는 표준 encode 메소드 대신 사용되며 Batch Encoder(허깅페이스의 용어)라고 불리는 딕셔너리가 반환됩니다. 이 딕셔너리는 다음과 같은 key를 포함합니다:\n\n- input_ids — 표준 encode 메소드로부터 반환된 동일한 토큰 ID\n- token_type_ids — 문장 A (id = 0)와 문장 B (id = 1)를 구분하는 데 사용되는 세그먼트 ID(예: Next Sentence Prediction과 같은 문장 쌍 작업)\n- attention_mask — 특정 토큰이 attention 과정에서 무시되어야 하는지 (0을 의미) 아니면 무시되어서는 안 되는지 (1을 의미) 나타내는 0과 1의 리스트\n\n```js\nreview = df[\"review_cleaned\"].iloc[0];\n\nbatch_encoder = tokenizer.encode_plus(\n  review,\n  (max_length = 512),\n  (padding = \"max_length\"),\n  (truncation = True),\n  (return_tensors = \"pt\")\n);\n\nprint(\"Batch encoder keys:\");\nprint(batch_encoder.keys());\n\nprint(\"\\nAttention mask:\");\nprint(batch_encoder[\"attention_mask\"]);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```md\n벡터 인코더 키:\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n\n주의 마스크:\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n\n                                      ...\n\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])\n```\n\n모든 리뷰 인코딩:\n\n토큰화 단계의 마지막 단계는 데이터 세트의 모든 리뷰를 인코딩하고 토큰 ID 및 해당하는 주의 마스크를 텐서로 저장하는 것입니다.\n\n```python\nimport torch\n\n토큰 ID = []\n주의 마스크 = []\n\n# 각 리뷰 인코딩\nfor review in df['review_cleaned']:\n    batch_encoder = tokenizer.encode_plus(\n        review,\n        max_length = 512,\n        padding = 'max_length',\n        truncation = True,\n        return_tensors = 'pt')\n\n    token_ids.append(batch_encoder['input_ids'])\n    attention_masks.append(batch_encoder['attention_mask'])\n\n# 토큰 ID 및 주의 마스크 목록을 PyTorch 텐서로 변환\n토큰 ID = torch.cat(토큰 ID, dim=0)\n주의 마스크 = torch.cat(주의 마스크, dim=0)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.3 — 트레인 및 검증 데이터로더 생성하기\n\n이제 각 리뷰가 인코딩되었으므로 데이터를 훈련 세트와 검증 세트로 분할할 수 있습니다. 검증 세트는 피니튜닝 프로세스의 효과를 평가하는 데 사용될 것이며, 프로세스 중에 성능을 지속적으로 모니터링할 수 있도록 합니다. 에폭이 진행됨에 따라 손실이 감소하고 모델 정확도가 증가할 것으로 예상됩니다. 에폭이란 트레인 데이터를 전부 한 번 통과하는 것을 의미합니다. BERT 저자들은 플레튜닝을 위해 2~4 에폭을 권장하며, 이는 분류 헤더가 모든 리뷰를 2~4번 보게 됨을 의미합니다.\n\n데이터를 분할하기 위해, SciKit-Learn의 model_selection 패키지에서 제공하는 train_test_split 함수를 사용할 수 있습니다. 이 함수는 분할할 데이터셋, 테스트 세트(또는 우리의 경우에는 검증 세트)로 할당할 아이템의 비율, 그리고 데이터를 무작위로 섞을지에 대한 옵션 인수를 필요로 합니다. 재현성을 위해 무작위로 섞는 매개변수를 False로 설정할 것입니다. 테스트 크기에는 0.1이라는 작은 값(10%에 해당)을 선택할 것입니다. 모델을 평가하고 수행을 정확히 파악하기 위해 충분한 데이터를 사용하는 것과 모델을 훈련하고 성능을 향상시키는 데 충분한 데이터를 유지하는 것 사이에 균형을 유지하는 것이 중요합니다. 따라서 0.1과 같은 작은 값이 종종 선호됩니다. 토큰 ID, 어텐션 마스크, 라벨을 분리한 후, 훈련 및 검증 텐서를 PyTorch TensorDatasets에 함께 그룹화할 수 있습니다. 그런 다음 이 TensorDatasets를 배치로 분할하여 훈련 및 검증용 PyTorch DataLoader 클래스를 생성할 수 있습니다. BERT 논문에서는 16 또는 32의 배치 크기를 권장합니다(즉, 모델에 16개의 리뷰와 해당 감정 라벨을 제시하고 분류 헤더에서 가중치와 바이어스를 다시 계산하기 전에). DataLoader를 사용하면 병렬 처리를 활용하여 피니튜닝 프로세스 중에 데이터를 효율적으로 모델로 로드할 수 있으며, 다중 CPU 코어를 활용할 수 있습니다.\n\n```js\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\n\nval_size = 0.1\n\n# 토큰 ID 분할\ntrain_ids, val_ids = train_test_split(\n                        token_ids,\n                        test_size=val_size,\n                        shuffle=False)\n\n# 어텐션 마스크 분할\ntrain_masks, val_masks = train_test_split(\n                            attention_masks,\n                            test_size=val_size,\n                            shuffle=False)\n\n# 라벨 분할\nlabels = torch.tensor(df['sentiment_encoded'].values)\ntrain_labels, val_labels = train_test_split(\n                                labels,\n                                test_size=val_size,\n                                shuffle=False)\n\n# 데이터로더 생성\ntrain_data = TensorDataset(train_ids, train_masks, train_labels)\ntrain_dataloader = DataLoader(train_data, shuffle=True, batch_size=16)\nval_data = TensorDataset(val_ids, val_masks, val_labels)\nval_dataloader = DataLoader(val_data, batch_size=16)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.4 — BERT 모델 인스턴스화\n\n다음 단계는 미세 조정할 사전 훈련된 BERT 모델을 로드하는 것입니다. 우리는 이전과 마찬가지로 Hugging Face 모델 저장소에서 모델을 가져올 수 있습니다. Hugging Face에는 이미 분류 헤드가 연결된 여러 버전의 BERT가 있어 이 프로세스가 매우 편리합니다. 미리 구성된 분류 헤드를 가진 일부 모델의 예는 다음과 같습니다:\n\n- BertForMaskedLM\n- BertForNextSentencePrediction\n- BertForSequenceClassification\n- BertForMultipleChoice\n- BertForTokenClassification\n- BertForQuestionAnswering\n\n물론, PyTorch 또는 Tensorflow에서 headless BERT 모델을 가져와 직접 분류 헤드를 만들 수도 있습니다. 그러나 우리의 경우에는 이미 필요한 선형 레이어를 포함하는 BertForSequenceClassification 모델을 가져와 사용할 수 있습니다. 이 선형 레이어는 무작위 가중치와 바이어스로 초기화되며, 미세 조정 중에 훈련될 것입니다. BERT Base는 768개의 임베딩 차원을 사용하므로, 숨겨진 레이어에는 모델의 최종 인코더 블록에 연결된 768개의 뉴런이 포함되어 있습니다. 출력 뉴런의 수는 num_labels 인수에 의해 결정되며, 고유한 감정 레이블의 수와 일치합니다. IMDb 데이터셋은 긍정과 부정만 포함하므로 num_labels 인수가 2로 설정됩니다. 중립 또는 혼합과 같은 레이블을 포함하여 보다 복잡한 감정 분석을 수행하려면 num_labels 값을 쉽게 조절할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntransformers 패키지에서 BertForSequenceClassification을 가져옵니다.\n\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased',\n    num_labels=2)\n```\n\n## 3.5 — Optimizer, Loss Function, 및 Scheduler 인스턴스화\n\nOptimizer:\n\n분류 head가 학습 데이터의 일괄 처리를 만나면, 선형 레이어의 가중치와 바이어스를 업데이트하여 그 입력에 대한 모델 성능을 향상시킵니다. 여러 배치와 여러 epoch 동안, 이러한 가중치와 바이어스가 최적값으로 수렴하도록 하는 것이 목표입니다. 각 가중치와 바이어스에 필요한 변경 사항을 계산하기 위해 옵티마이저가 필요하며, PyTorch의 `optim` 패키지에서 가져올 수 있습니다. Hugging Face는 자신들의 예제에서 AdamW 옵티마이저를 사용하므로, 여기서도 이 옵티마이저를 사용할 것입니다 [13].\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n손실 함수:\n\n옵티마이저는 분류 헤드의 가중치 및 편향에 대한 변경이 손실 함수에 어떤 영향을 미칠지 결정함으로써 작동합니다. 이 손실 함수라 불리는 점수 함수에 대한 손실은 PyTorch의 nn 패키지에서 쉽게 가져올 수 있습니다. 언어 모델은 일반적으로 교차 엔트로피 손실 함수(음의 로그 우도 함수라고도 함)를 사용하며, 따라서 여기에서는 이 손실 함수를 사용할 것입니다.\n\n스케줄러:\n\n학습 속도라 불리는 매개변수는 분류 헤드의 가중치와 편향에 대한 변경의 크기를 결정하는 데 사용됩니다. 초기 배치와 에포크에서는 무작위로 초기화된 매개변수가 상당한 조정이 필요할 수 있으므로 큰 변경이 유용할 수 있습니다. 그러나 학습이 진행됨에 따라 가중치와 편향이 향상되면서 큰 변경이 역효과적일 수 있습니다. 스케줄러는 학습 과정이 계속되는 동안 학습 속도를 점차 감소시켜 각 가중치 및 편향에 대한 각 최적화 단계에서 발생하는 변경 크기를 줄이도록 설계되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom torch.optim import AdamW\nimport torch.nn as nn\nfrom transformers import get_linear_schedule_with_warmup\n\nEPOCHS = 2\n\n# Optimizer\noptimizer = AdamW(model.parameters())\n\n# Loss function\nloss_function = nn.CrossEntropyLoss()\n\n# Scheduler\nnum_training_steps = EPOCHS * len(train_dataloader)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps)\n```\n\n## 3.6 — Fine-Tuning Loop\n\nCUDA를 사용하여 GPU 활용:\n\nNVIDIA에서 만든 CUDA(Compute Unified Device Architecture)는 과학 및 공학 분야의 응용 프로그램 성능을 향상시키기 위한 컴퓨팅 플랫폼입니다 [14]. PyTorch의 cuda 패키지를 사용하면 Python에서 CUDA 플랫폼을 활용하여 머신 러닝 모델을 훈련할 때 GPU를 사용할 수 있습니다. torch.cuda.is_available 명령을 사용하여 GPU의 가용성을 확인할 수 있습니다. GPU가 없는 경우 코드는 가속 계산을 위해 그래픽 처리 장치 (GPU)를 사용할 수 없도록 기본 설정됩니다. 이후의 코드 스니펫에서는 PyTorch Tensor.to 메서드를 사용하여 텐서(모델 가중치 및 편향 등이 포함됨)를 더 빠른 계산을 위해 GPU로 이동합니다. 장치가 cpu로 설정된 경우 텐서가 이동되지 않고 코드에 영향을 미치지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# GPU 사용 가능 여부 확인하여 빠른 학습 시간을 위한 준비\n\nif torch.cuda.is_available():\ndevice = torch.device('cuda:0')\nelse:\ndevice = torch.device('cpu')\n\n학습 프로세스는 두 개의 for 루프를 통해 이루어집니다: 각 epoch마다 프로세스를 반복하는 외부 루프(모델이 모든 학습 데이터를 여러 번 보게하는 역할)와 각 배치마다 손실 계산 및 최적화 단계를 반복하는 내부 루프가 있습니다. 학습 루프를 설명하기 위해 아래 단계를 고려해 보세요. 학습 루프의 코드는 Chris McCormick과 Nick Ryan의 훌륭한 블로그 글[15]에서 적용되었으며 매우 추천합니다.\n\n각 epoch에 대해:\n\n1. 모델을 train 모드로 변경합니다. 모델 객체의 train 메서드를 사용하여 모델이 평가 모드일 때와는 다르게 작동하도록 합니다. 특히 batchnorm과 dropout 레이어와 함께 작업할 때 유용합니다. 이전에 BertForSequenceClassification 클래스의 소스 코드를 살펴봤다면, 분류 헤드에 실제로 dropout 레이어가 포함되어 있는 것을 보았을 겁니다. 따라서 fine-tuning 시에 training 및 evaluation 모드를 올바르게 구분해야 합니다. 이러한 종류의 레이어는 학습 중에만 활성화되어야 하며 추론 중에는 활성화되지 않아야 합니다. 따라서 학습과 추론을 위해 서로 다른 모드로 전환할 수 있는 기능은 유용한 기능입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. 에포크 시작 시 훈련 손실을 0으로 설정하세요. 이것은 이후 에포크에서 모델의 훈련 데이터 손실을 추적하는 데 사용됩니다. 훈련이 성공적이라면 각 에포크마다 손실이 감소해야 합니다.\n\n각 배치에 대해:\n\nBERT 저자들의 권장에 따라, 각 에포크의 훈련 데이터를 배치로 나누세요. 각 배치마다 훈련 프로세스를 반복하세요.\n\n3. 가능한 경우 토큰 ID, 어텐션 마스크 및 레이블을 GPU로 이동하여 처리 속도를 높이세요. 그렇지 않으면 이러한 데이터는 CPU에 유지됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. 이 루프의 이전 반복에서 계산된 그래디언트를 재설정하기 위해 zero_grad 메서드를 호출하세요. PyTorch에서 기본 동작이 아닌 이유가 명확하지 않을 수 있지만, 이는 Recurrent Neural Networks와 같은 모델이 반복 사이에 그래디언트를 재설정해선 안 되는 이유로 제안됩니다.\n\n5. 배치를 모델에 전달하여 로짓(현재의 분류기 가중치와 편향에 기반한 예측)과 손실을 계산하세요.\n\n6. 에폭별 총 손실을 증가시키세요. 모델에서 손실이 PyTorch 텐서로 반환되므로 `item` 메서드를 사용하여 부동 소수점 값을 추출하세요.\n\n7. 모델에 역전파를 수행하고 분류기 헤드를 통해 손실을 전파하세요. 이를 통해 모델은 배치에 대한 성능을 향상시키기 위해 가중치와 편향을 조정해야 하는지를 결정할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n8. 모델이 폭발하는 그래디언트 문제를 겪지 않도록 그래디언트를 1.0보다 크게 만들지 마세요.\n\n9. 역전파에 따라 오차 표면 방향으로 옵티마이저를 호출하여 한 단계씩 진행하세요.\n\n각 배치 훈련 후:\n\n10. 에포크에서의 평균 손실과 소요 시간을 계산하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nfor epoch in range(0, EPOCHS):\n\n    model.train()\n    training_loss = 0\n\n    for batch in train_dataloader:\n\n        batch_token_ids = batch[0].to(device)\n        batch_attention_mask = batch[1].to(device)\n        batch_labels = batch[2].to(device)\n\n        model.zero_grad()\n\n        loss, logits = model(\n            batch_token_ids,\n            token_type_ids = None,\n            attention_mask=batch_attention_mask,\n            labels=batch_labels,\n            return_dict=False)\n\n        training_loss += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    average_train_loss = training_loss / len(train_dataloader)\n\n외부 루프 내에서 검증 단계가 수행되므로 각 epoch마다 평균 검증 손실을 계산합니다. epoch 숫자가 증가함에 따라 검증 손실이 감소하고 분류기 정확도가 증가할 것으로 기대됩니다. 검증 프로세스 단계는 아래에 설명되어 있습니다.\n\n에포크의 검증 단계:\n\n11. evaluation 메서드를 사용하여 모델을 평가 모드로 전환합니다. 이렇게 하면 드롭아웃 레이어가 비활성화됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n12. 검증 손실을 0으로 설정하세요. 이 값은 후속 에포크에서 모델의 검증 데이터에 대한 손실을 추적하는 데 사용됩니다. 학습이 성공적이었다면 손실은 각 에포크마다 감소해야 합니다.\n\n13. 검증 데이터를 배치로 나누세요.\n\n각 배치에 대해:\n\n14. 사용 가능한 경우 토큰 ID, 어텐션 마스크 및 레이블을 GPU로 이동하여 처리 속도를 높이세요. 그렇지 않으면 이러한 값들은 CPU에 유지됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n15. 여기서는 최적화 단계를 수행하지 않고 추론만 할 것이기 때문에 모델이 그라디언트를 계산하지 않도록 no_grad 메서드를 호출하세요.\n\n16. 배치를 모델에 전달하여 로짓(현재 분류기의 가중치와 편향을 기반으로 한 예측)와 손실을 계산하세요.\n\n17. 모델에서 로짓과 레이블을 추출하여 CPU로 이동하세요 (이미 CPU에 있지 않은 경우).\n\n18. 손실을 증가시키고 검증 데이터로더의 실제 레이블에 기반하여 정확도를 계산하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n19. 손실 및 정확도의 평균을 계산하세요.\n\n```js\n    model.eval()\n    val_loss = 0\n    val_accuracy = 0\n\n    for batch in val_dataloader:\n\n        batch_token_ids = batch[0].to(device)\n        batch_attention_mask = batch[1].to(device)\n        batch_labels = batch[2].to(device)\n\n        with torch.no_grad():\n            (loss, logits) = model(\n                batch_token_ids,\n                attention_mask = batch_attention_mask,\n                labels = batch_labels,\n                token_type_ids = None,\n                return_dict=False)\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = batch_labels.to('cpu').numpy()\n        val_loss += loss.item()\n        val_accuracy += calculate_accuracy(logits, label_ids)\n\n    average_val_accuracy = val_accuracy / len(val_dataloader)\n```\n\n위의 코드 스니펫의 끝에서 calculate_accuracy 함수를 사용하고 있지만 아직 정의하지 않았으니, 이제 정의해 보겠습니다. 모델의 검증 세트에서의 정확도는 옳은 예측의 비율로 주어집니다. 따라서 모델에 의해 생성된 로짓 값, 즉 변수 logits에 저장된 값을 사용할 수 있고, 이를 NumPy의 argmax 함수를 이용할 수 있습니다. argmax 함수는 배열에서 가장 큰 요소의 인덱스를 반환합니다. 텍스트 I liked this movie에 대한 로짓이 [0.08, 0.92]인 경우, 0.08은 텍스트가 부정일 확률을 나타내고 0.92는 텍스트가 긍정일 확률을 나타내므로 argmax 함수는 인덱스 1을 반환할 것입니다. 모델은 텍스트가 부정보다 긍정일 가능성이 더 높다고 판단합니다. 그런 다음 해당 레이블을 Section 3.3(19번째 줄)에서 이미 인코딩한 labels 텐서와 비교하면 됩니다. 로짓 변수에는 배치(총 16개)의 모든 리뷰에 대한 긍정 및 부정 확률 값이 포함되므로 모델의 정확도는 최대 16개의 옳은 예측 중 계산됩니다. 위의 코드는 val_accuracy 변수가 각 정확도 점수를 기록하고, 검증을 마친 후에 모델의 검증 데이터에 대한 평균 정확도를 결정하기 위해 나누는 것을 보여줍니다.\n\n```js\ndef calculate_accuracy(preds, labels):\n    \"\"\" 모델 예측과 실제 레이블의 정확도를 계산합니다.\n\n    매개변수:\n        preds (np.array): 모델의 예측된 레이블\n        labels (np.array): 실제 레이블\n\n    반환값:\n        정확도 (float): 올바른 예측의 백분율로 정확도가 반환됩니다.\n    \"\"\"\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n    return accuracy\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.7 — 완벽한 파인튜닝 파이프라인\n\n그렇게 해서 우리는 파인튜닝의 설명을 마쳤습니다! 아래 코드는 위의 모든 것을 하나의 재사용 가능한 클래스로 가져와서 BERT를 사용하는 모든 NLP 작업에 사용할 수 있습니다. 데이터 전처리 단계는 작업에 따라 다르기 때문에 이는 파인튜닝 클래스 밖으로 뺐습니다.\n\nIMDb 데이터셋을 이용한 감정 분석을 위한 데이터 전처리 함수:\n\n````python\ndef preprocess_dataset(path):\n    \"\"\" 불필요한 문자를 제거하고 감정 레이블을 인코딩합니다.\n\n    필요한 전처리 유형은 데이터셋에 따라 변경됩니다. IMDb 데이터셋의 경우, 리뷰 텍스트에는 스크래핑 과정에서 남아 있는 HTML 줄 바꿈 태그 (\u003cbr/\u003e)와 일부 불필요한 공백이 있습니다. 이를 제거합니다. 마지막으로, \"부정\"에 대한 감정 값을 0으로, \"긍정\"에 대한 감정 값을 1로 인코딩합니다. 이 메서드는 데이터셋 파일에 \"review\" 및 \"sentiment\" 헤더가 포함되어 있다고 가정합니다.\n\n    매개변수:\n        path (str): 감정 분석 데이터셋을 포함하는 데이터셋 파일의 경로입니다. 파일 구조는 다음과 같아야 합니다:\n            리뷰 텍스트를 담은 \"review\" 열과, ground truth 레이블을 담은 \"sentiment\" 열이 하나씩 있는 한 열인 파일입니다.\n            레이블 옵션은 \"부정\"과 \"긍정\"이어야 합니다.\n\n    반환:\n        df_dataset (pd.DataFrame): self.dataset 경로에서 로드한 원시 데이터가 있는 DataFrame입니다. \"review\"와 \"sentiment\" 열 외에도 다음이 포함됩니다:\n            - review_cleaned: \"review\" 열의 사본이고 HTML 줄 바꿈 태그와 불필요한 공백이 제거된 컬럼\n            - sentiment_encoded: \"sentiment\" 열의 사본이며 \"부정\" 값을 0으로 매핑하고 \"긍정\" 값을 1로 매핑한 컬럼\n    ```\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작업에 중립적인 파인튜닝 파이프라인 클래스:\n\n\n```js\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom transformers import (\n    BertForSequenceClassification,\n    BertTokenizer,\n    get_linear_schedule_with_warmup)\n\n\nclass FineTuningPipeline:\n\n    def __init__(\n            self,\n            dataset,\n            tokenizer,\n            model,\n            optimizer,\n            loss_function = nn.CrossEntropyLoss(),\n            val_size = 0.1,\n            epochs = 4,\n            seed = 42):\n\n        self.df_dataset = dataset\n        self.tokenizer = tokenizer\n        self.model = model\n        self.optimizer = optimizer\n        self.loss_function = loss_function\n        self.val_size = val_size\n        self.epochs = epochs\n        self.seed = seed\n\n        # Check if GPU is available for faster training time\n        if torch.cuda.is_available():\n            self.device = torch.device('cuda:0')\n        else:\n            self.device = torch.device('cpu')\n\n        # Perform fine-tuning\n        self.model.to(self.device)\n        self.set_seeds()\n        self.token_ids, self.attention_masks = self.tokenize_dataset()\n        self.train_dataloader, self.val_dataloader = self.create_dataloaders()\n        self.scheduler = self.create_scheduler()\n        self.fine_tune()\n\n    def tokenize(self, text):\n        \"\"\" Tokenize input text and return the token IDs and attention mask.\n\n        Tokenize an input string, setting a maximum length of 512 tokens.\n        Sequences with more than 512 tokens will be truncated to this limit,\n        and sequences with less than 512 tokens will be supplemented with [PAD]\n        tokens to bring them up to this limit. The datatype of the returned\n        tensors will be the PyTorch tensor format. These return values are\n        tensors of size 1 x max_length where max_length is the maximum number\n        of tokens per input sequence (512 for BERT).\n\n...\n````\n\n감정 분석을 위한 클래스 사용 예 (IMDb 데이터셋):\n\n```js\n# 매개변수 초기화\ndataset = preprocess_dataset('IMDB Dataset Very Small.csv')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased',\nnum_labels=2)\noptimizer = AdamW(model.parameters())\n\n# 클래스를 사용하여 모델을 파인튜닝\nfine_tuned_model = FineTuningPipeline(\n    dataset=dataset,\n    tokenizer=tokenizer,\n    model=model,\n    optimizer=optimizer,\n    val_size=0.1,\n    epochs=2,\n    seed=42\n)\n\n# 유효성 검사 데이터셋을 사용하여 일부 예측 수행\nmodel.predict(model.val_dataloader)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4 — 결론\n\n이 글에서는 BERT의 여러 측면을 탐색했습니다. BERT의 창시 시점의 배경, 모델 아키텍처의 자세한 분석 및 감성 분석을 사용하여 시업 무관한 미세 조정 파이프라인 작성을 포함했습니다. BERT는 가장 초기의 LLM 중 하나임에도 불구하고, 오늘날에도 여전히 중요하며 연구 및 산업 분야에서 응용 프로그램을 발전시키고 있습니다. BERT를 이해하고 NLP 분야에 미치는 영향을 이해하면 최신 고품질 모델을 다루는 데 튼실한 기반을 다질 수 있습니다. 미세 조정 및 사전 훈련이 LLM의 지배적 패러다임으로 유지되고 있으므로, 이 글이 여러분의 프로젝트에 적용해 가며 가치 있는 통찰을 제공했기를 바랍니다!\n\n# 5 — 추가 자료\n\n[1] J. Devlin, M. Chang, K. Lee, and K. Toutanova, BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2019), North American Chapter of the Association for Computational Linguistics\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[2] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, Attention is All You Need (2017), Advances in Neural Information Processing Systems 30 (NIPS 2017)\n\n[3] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer, Deep contextualized word representations (2018), Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)\n\n[4] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever (2018), Improving Language Understanding by Generative Pre-Training,\n\n[5] Hugging Face, Fine-Tuned BERT Models (2024), HuggingFace.co\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 논문 및 참고 자료 목록\n\n- M. Schuster 및 K. K. Paliwal, Bidirectional recurrent neural networks (1997), IEEE Signal Processing 트랜잭션 45\n\n- Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba 및 S. Fidler, Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books (2015), 2015 IEEE International Conference on Computer Vision (ICCV)\n\n- L. W. Taylor, “Cloze Procedure”: A New Tool for Measuring Readability (1953), Journalism Quarterly, 30(4), 415–433.\n\n- Hugging Face, Pre-trained Tokenizers (2024) HuggingFace.co\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[10] Hugging Face, Pre-trained Tokenizer Encode Method (2024) HuggingFace.co\n\n[11] T. Vo, PyTorch DataLoader: Features, Benefits, and How to Use it (2023) SaturnCloud.io\n\n[12] Hugging Face, Modelling BERT (2024) GitHub.com\n\n[13] Hugging Face, Run Glue, GitHub.com\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[14] NVIDIA, CUDA Zone (2024), Developer.NVIDIA.com\n\n[15] C. McCormick and N. Ryan, BERT Fine-tuning (2019), McCormickML.com\n","ogImage":{"url":"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png"},"coverImage":"/assets/img/2024-05-20-ACompleteGuidetoBERTwithCode_0.png","tag":["Tech"],"readingTime":41},{"title":"고유명사 인식 노출 - 필수 가이드","description":"","date":"2024-05-20 20:57","slug":"2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide","content":"\n\n\n![NamedEntityRecognitionUnmaskedTheEssentialGuide](/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png)\n\n## 소개\n\n알겠어요, 상상해보세요— 정보를 처리하고 싶은 기사, 저널 및 블로그의 산더미가 많이 있습니다. 이제 이 데이터에 작업할 기회가 커뮤니티에 도움이 될 것이라고 생각해보세요. 하지만 이 데이터를 즉시 공유하고 싶지는 않을 것입니다. 왜냐하면 사람들의 동의 없이 공유하면 안 되는 개인 정보가 포함될 수도 있기 때문입니다.\n\n모든 사람으로부터 허락을 받는 것은 현실적이지 않기 때문에 당신은 자신의 기술을 사용하여 FERPA 가이드라인에 따라 개인 정보를 숨기기로 결정합니다. 회사들이 분석이나 데모 목적으로 외부에서 공유할 때 데이터를 가리는 것은 흔한 일이며, 숫자 데이터의 경우 더 쉽습니다. 여기서는 텍스트 데이터를 사용하여 동일한 작업을 하려고 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금 여기서는 텍스트 데이터에 대해 이야기하고 있으므로 자연어 처리(NLP) 기술 중 하나를 적용할 것입니다. 그 기술은 Named Entity Recognition (NER)로, 숨겨진 데이터 보물을 찾아내는 신뢰할 수 있는 NLP 탐정입니다. 여기서 목적은 개인 정보를 식별하는 것입니다.\n\n이제 NER이 어떻게 작동하는지, NER 메커니즘의 개념, NER을 구현하는 방법, 선택할 수 있는 해결책 접근 방식 및 그 이유, 그리고 Python에서 이 문제에 대한 해결책을 구현하는 방법에 대해 더 자세히 살펴봅시다.\n\n## Named Entity Recognition (NER): 기술적 분해\n\n간단히 말해, NER은 컴퓨터에게 텍스트 내에서 특정 '개체'를 식별하는 것입니다. 이 경우에는 개인 식별 정보(PII)를 의미합니다. 프로그램에 하이라이터 세트를 제공하는 것과 유사하게 생각해보세요. 이름, 장소, 회사, 대학, 학생 ID, 이메일 주소 또는 개인을 식별할 수 있는 것들을 각각 나타내는 하이라이터가 있다고 상상해보세요. 이제 NER이 어떻게 작동하는지 간단히 살펴보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Rule-based Systems: 예전 방식입니다. 우리는 \"이름은 일반적으로 대문자로 시작합니다.\"와 같은 수기 작성 규칙을 만듭니다. 기본적인 경우에는 잘 작동하지만 굉장히 복잡해질 수 있습니다. 또한 많은 규칙이 있다면 더럽고 혼란스러워질 수 있습니다.\n- Machine Learning Approach: 통계 모델은 대규모 데이터 세트에서 학습합니다. 여러분의 NER 시스템에 많은 예제를 보여주는 것처럼 생각해보세요. 모델이 스스로 패턴을 찾을 수 있도록 합니다. 이것이 모든 것에 대한 머신 러닝이 작동하는 방식입니다. 그러나 텍스트 데이터에 대한 성능 문제가 발생할 수 있습니다.\n- Deep Learning Superstars: 신경망은 텍스트, 이미지 및 비디오 데이터 관련 문제에 대한 가장 유명한 방법론입니다. 우리가 하는 것과 유사한 복잡한 언어를 다룹니다. 이러한 모델은 맥락을 이해하여 매우 정확합니다. 이곳의 유일한 조건은 많은 양의 데이터를 사용해야 한다는 것입니다. 그렇지 않으면 모델은 대부분의 학습 데이터를 기억하게 됩니다 (과적합). 이를 제어하는 기술은 있지만, 여전히 많은 데이터 집합에서 가장 잘 작동합니다.\n\n## 자세한 기술: NER 뒤의 두뇌\n\nNER은 다양한 기술을 활용할 수 있음을 확인했습니다. 각각의 장점을 가진 기술에 대해 자세히 알아봅시다:\n\n- Conditional Random Fields (CRFs):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNER 시스템을 위치를 인식하도록 가르치고 있다고 상상해보세요. \"10 Made UP Street, London, UK.\"와 같은 주소 예시를 보여줍니다. CRF는 이를 뛰어넘는 데 뛰어납니다. 왜냐하면 단어들과 그들 사이의 관계에 대해 전체 시퀀스를 고려하기 때문입니다. 숫자를 따르는 \"London\"과 도시를 따르는 \"UK\"를 이어받으면 이것은 강한 위치 엔티티를 시사합니다. 이러한 이유로, CRF는 맥락이 매우 중요한 NER과 같은 작업에 강력합니다.\n\nTDS에서 이에 대한 수학적 이론인 CRF를 설명한 Nikos Kafritsas의 훌륭한 기사를 읽어보세요.\n\n2. LSTM 네트워크 (Long Short-Term Memory):\n\n텍스트에서 사람 이름을 식별하고자 한다고 가정해봅시다. LSTMs는 RNN 이후에 크게 발명되었습니다. 왜냐하면 특별한 능력을 갖고 있기 때문입니다 — 기억! 네, 그들은 기억이나 맥락을 가지고 예측할 수 있습니다. CRF가 (현재 단어만 고려하는) 반면, LSTMs는 이전 단어를 기억하고 맥락을 잃지 않는 특성이 있습니다. 이것은 NER에 중요합니다. 왜냐하면 이것이 회사인 Apple인지 과일인 Apple인지를 이해하는 데 도움이 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또 다른 예시를 살펴보죠: \"Dr. Smith is a renowned cardiologist\"라는 문장에서 LSTM은 \"Dr.\"이라는 칭호를 기억하고 그 맥락을 사용하여 \"Smith\"를 사람 이름으로 올바르게 분류할 수 있습니다. \n\n실제 세계 예시를 보겠습니다: 사람들이 언급된 기사를 기반으로 분류하는 뉴스 분류기 모델을 만든다고 상상해보세요. LSTM 기반 NER 시스템이 \"Barack Obama\"나 \"Elon Musk\"와 같은 엔티티를 정확하게 식별할 수 있습니다. 이들의 이름이 복잡한 문장 안에 나타나고 분류되어 있더라도 말이죠. 훌륭한 구현 방법이죠, 그렇죠?\n\nRian Dolphin의 LSTM에 대한 포괄적인 소개 기사를 읽어보세요.\n\n3. Transformers:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n트랜스포머는 현재 자연어 처리의 핫한 주제이며, 개체명 인식(NER)도 예왌이 아닙니다. 이러한 모델은 특정 세부사항에 모든 주의를 집중하는 것과 같이 주의 메커니즘을 사용합니다. 그들이 하는 것은 전체 문장 전반에 걸쳐 관련 단어에 주의를 기울이는 것입니다. 인간이 처음 보는 텍스트를 읽는 것처럼 상상해보세요. 여기저기 훑어보면서 (스포트라이트처럼) 각 부분에 마음을 집중하고 의미를 파악하는 것입니다. 이 기술을 통해 그들은 복잡한 관계를 이해하고 미비한 개체조차 식별할 수 있습니다.\n\n예를 들어, \"Acme Corp의 CEO가 캘리포니아를 기반으로 새 제품 출시를 발표했습니다.\" 라는 문장을 생각해보세요. 트랜스포머 기반 NER 시스템은 \"CEO\"와 \"Acme Corp\"에 주의를 기울일 수 있습니다. 이들이 여러 단어로 분리되어 있는데도요. 그런 다음 이 주의를 사용하여 \"Acme Corp\"를 조직으로 올바르게 분류할 수 있습니다.\n\n이 능력은 트랜스포머를 의료 연구 논문에서 의학 용어를 식별하거나 소셜 미디어 데이터에서 특정 제품명을 식별하는 것과 같은 작업에 이상적으로 만들어줍니다.\n\n제임스 브릭스의 기사 \"NER with Transformers and Spacy\"를 읽어보세요. 그리고 아직 '주의'에 대해 궁금하다면, 아륀 사르카의 \"Attention과 Transformers에 대한 이해 - 파트 1\"이라는 기사부터 읽어보는 것도 좋은 시작입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기본을 넘어선 발전 기술\n\nNER의 세계는 끊임없이 진화하고 있습니다. 주목해야 할 몇 가지 흥미로운 발전 사항을 소개합니다:\n\n- 양방향 LSTM(BiLSTM): 이들은 LSTM을 더욱 강력하게 만든 버전으로, 텍스트를 앞뒤로 처리합니다. 이로 인해 더 깊은 맥락을 이해할 수 있습니다. 이 기법에는 단점이 있습니다. 앞뒤로 문장을 모두 입력하기 때문에 예측이 어렵습니다. 그러나 시스템은 맥락에 대해 알고 있습니다.\n- 명명된 엔티티 구별(NED): 다시 말해, \"Apple\"이라는 단어를 본다고 상상해 봅시다. 이것이 기술 거대 기업을 가리키는 것인지 아니면 과일을 가리키는 것인지 구분해야 합니다. NER은 NED와 결합하여 콘텍스트에서 가장 가능성이 높은 의미를 식별할 수 있습니다.\n\n이러한 기술을 이해하고 최신 발전 사항을 파악함으로써, 텍스트 데이터에서 가치 있는 개인 정보를 발굴하고 연구 노력을 지원하는 데 NER의 힘을 활용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## NER 작업 실습: 프로젝트 코드 미리보기\n\n손을 더럽혀 볼 시간이에요! 만약 Python과 훌륭한 spaCy 라이브러리를 사용한다고 가정해봅시다:\n\nPython\n\n```js\npython -m spacy download en_core_web_trf\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\npip install spacy\npip install nltk\n```\n\n```js\nimport spacy\nfrom spacy import displacy\nimport nltk  # NLTK를 추가 작업에 사용할 예정\nfrom nltk.corpus import stopwords  # NLTK 활용 예시\n\n# 강력한 사전 훈련된 NER 모델 로드 (필요에 따라 조정)\nnlp = spacy.load(\"en_core_web_trf\")\n\n# 분석할 텍스트 정의\ntext = \"\"\"\nJane Doe, a researcher at Stanford University, recently published a paper on \nNatural Language Processing.  Dr. John Smith from MIT will be collaborating on the \nproject.  They can be reached at jane.doe@stanford.edu and john_smith@mit.edu.\n\"\"\"\n\n# NER로 텍스트 처리\ndoc = nlp(text)\n\n# 식별된 엔티티 출력\nprint(\"식별된 엔티티:\")\nfor entity in doc.ents:\n    print(entity.text, entity.label_)\n\n# NER 결과 시각화\ndisplacy.render(doc, style=\"ent\", jupyter=True)\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 확인할 수 있듯이 NER은 이름과 조직을 완벽하게 식별할 수 있었지만 이메일 주소를 놓쳤습니다. 이 현상이 발생한 이유를 살펴보고 어떻게 수정할 수 있는지 알아봅시다.\n\n이메일 주소를 놓치는 이유\n\n- NER 모델 한계: 표준 NER 모델은 일반적으로 이름, 조직, 위치 등과 같은 범주로 훈련됩니다. 몇 가지 이메일 패턴을 잡아낼 수 있을 수 있지만 이것이 주된 강점이 아닙니다. 따라서 이 경우에는 그것을 놓쳤습니다.\n- 이메일 주소의 복잡성: 이메일 형식은 놀랍도록 다양할 수 있습니다. \"Gmail 및 Yahoo\"와 같이 간단한 것들은 인식될 수 있지만 더 복잡한 패턴은 놓칠 수 있습니다. 예를 들어 gmail ID를 잡아낼 수 있지만 특정 조직별 ID를 놓칠 수 있습니다. 다시 말해, 이 경우에 발생한 것과 같습니다.\n\n이유를 알고 있지만, 문제를 어떻게 수정할지에 더 초점을 맞출 수 있을 것입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다섯가지 기술 중 하나를 사용하여 작업을 개인화하고 해결합시다:\n\n- 정규 표현식 (Regex): 정규 표현식을 사용하여 이메일 주소에 일치하는 특정 패턴을 작성할 수 있습니다. 이 기술은 예전부터 개발되어 많이 사용되고 있습니다. 이를 프로그래밍에서 패턴을 인식하기 위한 어렵게 코딩된 것으로 생각할 수 있습니다. 다음은 기본적인 예제입니다:\n\n```js\nimport re\n\nemail_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\nemails = re.findall(email_regex, text)\nprint(emails)\n```\n\n- 전문 라이브러리 사용: email_validator와 같은 라이브러리를 사용할 수 있습니다. 이러한 라이브러리들은 이메일 식별 및 유효성 검사에 전념하고 있습니다. 이메일을 유효성 검사하는 것이 당신의 경우라면 이 옵션을 사용할 수 있습니다.\n- NER 모델 개선: 기존 모델을 세밀하게 조정하여 이메일 주소 예제를 추가 엔티티 유형으로 제공할 수 있습니다. 그러나 이 작업에는 더 많은 데이터와 복잡한 모델 훈련이 필요합니다. BERT 등과 같은 사전 훈련된 모델을 사용하는 것도 포함됩니다. 다시 한번, James Briggs의 'NER with Transformers and Spacy' 라는 글을 읽어보세요. 이 글은 roBERTA를 세밀하게 조정하고 spaCy를 사용하는 방법에 대해 이야기합니다. 이 옵션을 확실하게 이해하실 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 방법을 선택하여 시연하고 코드에 구현해 보겠습니다. 이메일 추출을 위한 섹션을 아래와 같이 추가할 수 있습니다:\n\nPython\n\n```js\nimport re\n\nemail_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\nemails = re.findall(email_regex, text)\nprint(\"찾은 이메일:\", emails)\n```\n\n결과\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_2.png\" /\u003e\n\n가장 적합한 방법 선택하기\n\n이상적인 해결책은 프로젝트의 특정성에 따라 다릅니다:\n\n- 간단한 이메일 + 정확도: 정규식(Regex)이 충분할 것으로 예상됩니다.\n- 복잡한 이메일 + 신뢰성: 전문 이메일 유효성 검사 라이브러리가 가장 안전합니다.\n- NER 재학습: 다른 엔티티의 NER 정확도가 중요하고 이메일 중심 데이터가 많이 있는 경우, 모델을 다시 학습시키는 것이 장기적인 해결책이 될 수 있습니다. 당신이 상상한 대로, BERT 사전 훈련된 모델을 파인튜닝하여 사용하는 등의 멋진 기술을 사용할 수 있습니다. 이를 사용하기 전 고려해야 할 중요한 점은:\n\n- 데이터: 파인튜닝을 위해서는 상당량의 레이블이 지정된 데이터가 필요합니다. 데이터가 제한적인 경우, 다른 기술(예: 정규식)이 처음에는 더 실용적일 수 있습니다.\n- 복잡성: 파인튜닝은 설정 및 계산 리소스가 정규식이나 기본 라이브러리보다 많이 필요할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## NER 스킬을 강화할 수 있는 리소스들\n\n- spaCy: 훌륭한 NER 지원을 갖춘 우수한 NLP 라이브러리 (https://spacy.io/).\n- NLTK: 클래식한 NLP 툴킷 (https://www.nltk.org/).\n- Stanford CoreNLP: 강력한 NLP 도구 모음 (https://stanfordnlp.github.io/CoreNLP/)\n\n앞으로의 길\n\nNER은 아직 핫한 연구 분야입니다 — 복잡한 관계를 이해하고 사용자 정의 엔티티를 식별하며 다국어로 작동하는 모델에 대비하세요! 이 기술은 우리 주변의 방대한 텍스트에서 정보를 추출하고 활용하는 방식을 혁신하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 작성자 소개\n\n친애하는 독자 여러분, 저는 이 주제에 열정적이며 데이터 과학 주제와 생각거리 글에 대해 쓰는 것을 즐깁니다. 가장 중요한 것은 피드백을 받을 준비가 되어 있다는 것입니다!\n\n여러분의 의견을 알고 싶습니다. 이 글이 어떤 식으로든 도움이 되었거나 피드백이 있다면 망설이지 마시고 남겨주세요! 또한, 이 주제에 대한 추가 설명이 필요하다면 언제든지 댓글을 남겨 주세요. 저는 여기서 해결하려고 하거나 다른 글을 쓸 것입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 정보에 대해 더 알고 싶다면, 이곳에 내 소개 글이 있어:\n\n함께 얘기 나눠보자...","ogImage":{"url":"/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png"},"coverImage":"/assets/img/2024-05-20-NamedEntityRecognitionUnmaskedTheEssentialGuide_0.png","tag":["Tech"],"readingTime":8},{"title":"텍스트 유사성 마스터하기 임베딩 기술과 거리 측정 결합하기","description":"","date":"2024-05-20 20:54","slug":"2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics","content":"\n\n\"집중하고 있니?\" \"집중하고 있니?\" 이 두 문장은 같은 의미인가요? 기사를 읽고 알고리즘의 답변을 찾아보세요!\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png)\n\n두 개의 텍스트를 비교하는 것은 보편적이고 중요한 작업이라고 보는 경우가 많습니다. 고객 서비스에서 AI 시스템은 동의어적 의미를 이해하여 인간 대화의 유동성을 반영하는 응답을 생성할 수 있어야 합니다. 예를 들어, \"비밀번호를 어떻게 복구할 수 있나요?\" 또는 \"비밀번호를 잊었어요. 다시 로그인하는 방법이 뭐에요?\"와 같은 질문은 의미가 유사하며 동일한 응답을 요구합니다. 게다가, 고객 상호작용 중에 대리인이 계약이나 제안에 대한 정보를 정확하게 전달하는지 확인해야 하는 경우가 종종 있습니다. 또한, 검색 엔진이나 Stack Overflow와 같은 플랫폼에서 이전에 질문이 제기되었는지 알아내야 할 필요가 있습니다. 본질적으로 텍스트 유사성을 빠르게 계산할 수 있는 능력은 효율성 향상과 고객 관계 향상의 기초가 됩니다.\n\n인간은 의미론적 및 문법적 관계를 본성적으로 쉽게 이해하지만, 기계는 같은 작업을 수행하는 데 더 복잡한 도전에 직면합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 유사성을 더 구체적으로 정의해 봅시다: 유사성은 두 데이터 객체가 얼마나 다르거나 비슷한지를 측정한 것입니다. 거리가 짧을수록 객체들은 높은 수준의 유사성을 갖는다고 말하며, 그 반대도 마찬가지입니다.\n\n텍스트 유사성은 두 텍스트 조각이 어휘적으로(사용된 단어)와 의미론적으로(단어의 의미) 얼마나 가까운지를 나타냅니다. 예를 들어, \"병이 비어 있습니다\"와 \"병 안에는 아무 것도 없습니다\"라는 문장은 의미론적으로는 동일하지만 어휘적으로는 다릅니다.\n\n기계가 텍스트 유사성을 계산할 수 있도록하기 위해, 먼저 기계의 언어인 숫자를 기반으로 한 언어를 사용해야 합니다.\n\n그러므로, 텍스트 유사성을 평가하는 핵심 단계 중 하나는 텍스트를 벡터로 변환하는 것입니다. 벡터는 공간에서 크기와 방향을 나타내는 숫자 요소이기도 합니다. 이 프로세스는 텍스트 벡터화 또는 텍스트 인코딩이라고 알려져 있습니다. 유사성을 평가하기 위한 후속 단계는 이러한 벡터들 간의 거리를 측정하는 것입니다. 이 거리를 계산하는 데 선택된 측정 항목이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 텍스트를 임베딩하고 거리를 계산하는 다양한 기술의 장단점을 포괄적으로 탐구하여 귀하의 요구에 맞는 최적의 조합을 찾을 수 있는 포괄적인 안내서를 제공합니다.\n\n자세히 들어가기 전에 이 기사의 상위 수준 색인으로 볼 수 있는 다음 그림을 살펴보겠습니다.\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_1.png)\n\n텍스트 표현은 4가지의 주요 방법으로 군집화될 수 있습니다: 문자 기반, 의미론적 텍스트 일치, 말뭉치 기반(말뭉치는 언어 분석에 사용되는 텍스트 문서의 집합을 가리킵니다), 및 그래프 구조입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문자열 거리는 길이 거리, 분포 거리 및 의미적 거리로 나뉠 수 있습니다.\n\n우리는 위 그림에서 볼드 처리된 주제들에 대해서만 다룰 것입니다. 가장 쉬운 방법부터 가장 복잡한 방법까지 시작하겠습니다.\n\n## 문자열 기반 텍스트 표현\n\n### 자카드 유사도\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자카드 유사도, 또는 교집합 오버 유니온이라고도 알려지고, 두 개의 텍스트의 유사성을 측정하는 방법으로, 공통 단어의 개수를 전체 단어 수로 나눈 비율로 표현됩니다.\n\n다음과 같은 수식으로 설명됩니다:\n\n앞서 언급한 두 문장을 고려해 봅시다:\n\n- A: 병은 비어 있습니다\n- B: 병 안에는 아무것도 없습니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_2.png)\n\n자카드 유사도에 따르면, 문장 A와 B는 달리 의미를 가지고 있습니다. 이는 단순히 문장을 리터럴 레벨에서 비교하기 때문입니다.\n\n자카드 유사도는 쉽게 계산할 수 있지만 의미적 관계를 포착하지 못하므로, 텍스트에서 사용된 단어를 비교하는 것이 필수적이지 않은 이상 권장되지 않습니다.\n\n자카드 유사도에 따르면, 문장 A와 B는 달리 의미를 가지고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 태그를 Markdown 형식으로 변경하겠습니다.\n\n# Corpus based text representation\n\n앞서 언급한 대로, 단어가 숫자로 표현되는 방식은 유사성을 평가하는 데 중요합니다. 이제 텍스트 표현을 위한 다양한 기술을 탐색해보겠습니다.\n\n## Bag of words\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBag of words 기반 기술은 단어의 순서와 관계없이 문서를 단어들의 조합으로 나타냅니다. 이 가족 중에서 가장 간단한 방법은 원핫 인코딩입니다.\n\n원핫 인코딩에 따르면 고유 단어의 총 수만큼의 크기를 가진 벡터가 생성됩니다. 각 단어의 값은 해당하는 인덱스에 1이 할당되고 나머지는 0입니다.\n\n이는 말뭉치의 다양성이 적고 데이터 간 의미 및 통계적 관계를 나타내는 필요가 없는 상황에서 일반적으로 사용됩니다. 큰 문서의 경우, 방대하고 희소한 벡터로 이어질 수 있습니다.\n\n조금 더 세련된 방법은 TF-IDF (단어 빈도-역문서 빈도)입니다. 이는 빈도가 높은 단어는 중요성이나 의미가 적다는 아이디어에 기반합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수학적으로 말하면:\n\nTF = 문서에 단어가 나타나는 횟수 / 문서 내 전체 단어 수\n\nIDF = log(N/n)\n\n여기서 N은 전체 문서 수이고, n은 대상 용어가 나타나는 문서 수입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n0s를 제거하려면 모든 문서에 단어가 있는 경우 TF*IDF 곱에 1을 더하므로, 벡터의 0은 단어의 부재를 나타냅니다.\n\n예제를 통해 이해해 봅시다. 다음과 같은 문장들을 고려해 보겠습니다:\n\n- He is Walter\n- He is William\n- He isn’t Peter or September\n\nTF 벡터는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- [0.33, 0.33, 0.33]\n- [0.33, 0.33, 0.33]\n- [0.20, 0.20, 0.20, 0.20, 0.20]\n\n이제 IDF 점수를 계산해 봅시다.\n\n- \"He\": Log(3/3) = 0,\n- \"is\": Log(3/2) = 0.1761,\n- \"or, Peter, ..\": Log(3/1) = 0.4771 ..\n\n결과 벡터는:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- [1. , 1.1761 , 1.4771 , 0. , 0. , 0. , 0. , 0.],\n- [1. , 1.1761 , 0. , 1.4771 , 0. , 0. , 0. , 0.],\n- [1. , 0. , 0. , 0. , 1.4771 , 1.4771, 1.4771 , 1.4771]\n\n이 방법은 통계적 관계를 가치화하지만 의미론적 관계를 대변하지 않고, 긴 문서에 적합하지 않습니다. 이는 고차원 벡터로 이어집니다.\n\n일반적으로, 대부분의 단어 가방 접근 방식은 의미론적 관계를 중요시하지 않고, 큰 문서에 대해 데이터 희소성으로 이어질 수 있습니다. 따라서, 텍스트 표현에 대한 복잡한 기술인 단어 임베딩 중 하나로 분류될 수 있는 더 복잡한 기술에 대해 심층적으로 살펴보겠습니다.\n\n## 창 기반 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 통계적 관계를 중요시하지만 의미론적 관계를 나타내지는 않고, 긴 문서에는 적합하지 않습니다. 따라서 고차원 벡터로 이어질 수 있습니다.\n\n일반적으로 단어 가방 접근 방식 중 대부분은 의미적 관계를 중요시하지 않을 수 있고, 대규모 문서의 데이터 희소성으로 이어질 수 있습니다. 그러니 텍스트 표현에 대해 더 복잡한 기법으로 다양한 단어 표현 기술 중 하나로 분류될 수 있는 기법을 자세히 살펴보도록 하겠습니다.\n\n## Word2Vec\n\nW2V는 미리 훈련된 두 개의 레이어로 이루어진 신경망입니다. W2V 방식은 기계 학습에서 흔히 사용되는 속임수를 사용합니다: 단일 숨겨진 레이어를 가진 신경망이 특정 작업을 수행하도록 훈련되지만 최종 작업에 사용되지는 않습니다. 실제로 목표는 숨겨진 레이어의 가중치를 학습하는 것뿐입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nW2V는 두 가지 사전 훈련 모델을 가지고 있어요: 연속 단어 주머니 (Continuous Bag Of Words, CBOW)와 스킵-그램.\n\n![이미지](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_3.png)\n\n사진에서 볼 수 있듯이, CBOW에서는 대상 단어에 인접한 단어가 입력으로 주어지고 대상 단어를 예측하는 작업을 하며, 스킵-그램에서는 대상 단어가 입력으로 주어지고 이웃하는 단어들을 출력으로 예측해야 합니다. 이웃 단어로 고려할 단어 수를 \"윈도우 크기\"라고 하며, 이는 알고리즘의 매개변수입니다 (윈도우 크기의 일반적인 값은 5일 수 있어요).\n\n임베딩이 어떻게 생성되는지 이해하기 위해, 스킵-그램에 집중해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 작업의 첫 번째 단계는 문서에 있는 단어들을 인코딩하는 것인데, 일반적으로 이는 원핫인코딩 방식으로 수행됩니다.\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_4.png)\n\n출력은 코퍼스에 있는 단어 수와 동일한 길이의 단일 벡터이며, 각 요소는 입력 단어의 이웃 단어가 될 가능성을 나타냅니다.\n\n만약 두 단어가 매우 유사한 문맥을 가진다면, 주변에 같은 단어들이 있을 가능성이 높다는 것을 의미하며, 모델은 이러한 단어들에 대해 유사한 결과를 생성하여야 합니다. 네트워크가 이를 달성하는 방법 중 하나는 단어 벡터가 유사하도록 하는 것입니다. 그러므로 두 단어가 유사한 문맥을 보여줄 때, 네트워크는 이러한 단어들에 대해 유사한 단어 벡터를 모으도록 자극을 받게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 종류의 네트워크를 비교해 보면, CBOW는 문법적 관계 학습에 뛰어나지만 Skip-gram은 의미적 관계를 파악하는 데 좀 더 우수합니다. 예를 들어, CBOW는 복수형과 같이 형태적으로 유사한 단어에 초점을 맞추지만 Skip-gram은 형태적으로 다른데 의미적으로 관련 있는 단어를 고려합니다. 게다가, Skip-gram은 빈번한 단어의 과적합에 덜 민감하며, 단어 하나만을 입력으로 사용하기 때문에 최적의 성능을 위한 문서 요구 사항 측면에서 더 효율적입니다.\n\nW2V 임베딩은 Spacy나 Genism에서 구현됩니다.\n\n이 접근법은 고차원 문제를 해결하고 의미론적 및 문법적 관계를 고려하지만, 단어의 맥락을 고려하지 않는 한계가 있어서 다의성의 경우 성능이 떨어질 수 있습니다. 예를 들어, \"current\"라는 단어는 다음 두 문장에서 각각 다른 의미를 가집니다:\n\n- 현재 사안 프로그램입니다.\n- 시내는 다리 아래로 빨리 흐릅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nW2V 방법에 따르면 세계의 현재 상태는 하나의 표현만을 갖게 될 것입니다.\n\n맥락 모델은 해당 문서의 모든 단어의 순서를 고려하여 대상 단어를 포함하는데 사용됩니다.\n\n자연어 처리 세계에서 가장 중요한 알고리즘 중 하나를 탐색해봅시다: BERT.\n\n## BERT\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알고리즘에 대한 간결한 개요를 제공하겠습니다. 아키텍처 및 훈련의 중요 측면을 강조하여 문맥적 임베딩의 성취를 이해하는 데 필요한 것을 설명하겠습니다. BERT를 보다 자세히 탐구하려면 이 글의 마지막에 링크된 추가 자료를 참고하시기를 권합니다.\n\nBERT는 Bidirectional Encoder Representation from Transformers의 약자입니다. 이름에서 알 수 있듯이 BERT 아키텍처는 transformers를 기반으로 하며 실제로 양방향 언어 transformers를 사용하여 언어 표현을 합니다.\n\nBERT는 두 가지 다른 작업을 위해 사전 훈련되었습니다: Masked Language Modelling (MLM) 및 Next Sentence Prediction (NSP).\n\n첫 번째 작업인 MLM부터 시작해 보겠습니다. 말뭉치에 있는 단어 중 15%가 \"마스킹\"되었다고 가정됩니다. 이들 중에서:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 단어의 80%가 가리킨 토큰 [MASK]로 대체됩니다.\n- 10%는 무작위 단어로 대체됩니다.\n- 10%는 바뀌지 않은 채로 남겨집니다.\n\n해당 작업은 마스킹된 단어를 예측하는 것입니다. 특히 각 토큰을 마스킹하는 방식은 모형에 매우 중요합니다:\n\n- 단어를 토큰 [MASK]로 대체하면 일반 토큰을 제공하는 대신 주변 텍스트에서만 토큰을 추론할 수 있도록 합니다.\n- 샘플링된 단어를 텍스트 내에서 무작위 단어로 대체하고 예측을 강화하면 모형이 잘못된 토큰에 대응하는 강건함을 향상시킵니다. 모형은 예상치 못한 또는 맥락을 벗어난 단어를 효과적으로 다룰 수 있도록 합니다.\n- 샘플링된 단어를 바꾸지 않고 예측하면 모형이 텍스트의 원래 의미론적 및 구문 구조를 유지합니다. 모형은 잘못된 맥락에 대처하는 강건함을 향상시킵니다.\n\n이 세 가지 마스킹 단어 방식의 결합은 모형을 다양한 NLP 작업에서 강건하고 다재다능하게 만들어줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 번째 과제인 NSP는 문장 간의 관계를 학습하는 데 초점을 맞춥니다: 코퍼스 내 문장 쌍의 50%에 대해 두 번째 문장이 실제로 다음 문장인 경우가 있고, 나머지 쌍에 대해서는 두 번째 문장이 무작위로 선택된 문장입니다. 첫 번째 경우는 \"isNext\"로 레이블이 지정되고, 두 번째 경우는 \"NotNext\"로 레이블이 지정됩니다. 이 과제는 올바른 레이블을 예측하도록 하는 것으로, BERT가 문장 간 관계(예: 질문과 답변)를 학습할 수 있게 합니다.\n\nBERT 모델의 훈련 과정에서 Masked Language Model(MLM) 및 Next Sentence Prediction(NSP) 구성 요소는 함께 훈련되어, 이 두 전략에서 발생하는 결합 손실 함수를 최소화하도록 하고 올바른 레이블을 예측합니다.\n\nBERT의 강점은 이러한 작업을 수행하기 위해 입력 모델을 어떻게 모델링하는지에 있습니다.\n\n각 입력 임베딩은 3가지 임베딩의 조합으로 이루어져 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 위치 임베딩: 문장 내 단어의 위치를 표현하는 데 사용되는 임베딩입니다. 이러한 요소들은 Transformer의 제약을 해결하기 위해 도입되었는데, 순환 신경망과 달리 순차적 정보를 포착하는 능력이 없는 Transformer의 한계를 극복하기 위해 도입되었습니다.\n- 세그먼트 임베딩: 문장 쌍을 식별하는 임베딩입니다. BERT는 모델이 두 문장을 구분할 수 있도록 첫 번째 문장과 두 번째 문장에 대해 고유한 임베딩을 학습합니다. 아래 그림에서 EA로 표시된 모든 토큰은 문장 A에 속하며, EB도 비슷하게 문장 B에 속합니다.\n- 토큰 임베딩: 첫 번째 문장의 시작 부분에 [CLS] 토큰이 삽입되고, 각 문장의 끝 부분에는 [SEP] 토큰이 삽입됩니다.\n\n위 3가지 임베딩을 합산하여 각 입력을 얻습니다.\n\n\u003cimg src=\"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_5.png\" /\u003e\n\n미리 학습된 후, 모델은 특정 말뭉치에서 세밀하게 튜닝될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사전 훈련된 BERT의 버전은 분류(감성 분석), 질의응답, Named Entity Recognition과 같은 특정 작업에 사용할 수 있습니다. 그러나 저희는 임베딩 기법 중 한 가지로 이 알고리즘을 언급했기 때문에, 어떻게 이를 이용하는지 간단히 설명하겠습니다. 이 응용 프로그램의 아이디어는 W2V에 언급된 것과 유사합니다. 사실, 우리는 사전 훈련된 목적으로 그 모델을 사용하지 않습니다. BERT 베이스 모델은 12개의 트랜스포머 인코더 레이어를 사용하며, 각 레이어에서 각 토큰의 출력을 단어 임베딩으로 사용할 수 있습니다. 경험적인 연구를 바탕으로, 저자들은 매우 효과적인 접근 방식은 마지막 4개 레이어의 출력을 합하는 것임을 결정했습니다. BERT를 사용한 임베딩은 Hugging Face의 오픈 소스 라이브러리를 사용하여 Python에서 쉽게 구현할 수 있습니다. 이 라이브러리는 BERT를 PyTorch 또는 TensorFlow에서 사용할 수 있도록 제공합니다.\n\n# 거리 측정 방법\n\n지금까지 우리의 탐구는 텍스트 유사도를 측정하는 한 가지 방법(자카드 유사도)과 텍스트를 벡터로 변환하는 여러 기술에만 집중해 왔습니다. 소개에서 언급했듯이, 단어를 벡터로 변환하는 것은 유사도를 평가하기 위한 예비 단계에 불과하며, 거리 측정 방법의 계산이 필요합니다. 다음 섹션에서는 이러한 거리 측정 방법에 대해 포괄적으로 검토할 것입니다.\n\n## 길이 거리 측정 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n길이 거리 측정 방법에 따르면, 거리는 텍스트의 수치적 특성을 이용하여 측정됩니다. 그 중 가장 인기 있는 측정 방법은 확실히 유클리드 거리입니다.\n\n유클리드 거리\n\n유클리드 거리는 두 점 사이의 거리를 계산하기 위해 피타고라스의 정리를 사용합니다.\n\n길이가 n인 두 벡터를 고려해 보면, 유클리드 거리는 다음 공식으로 설명됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 이미지에서 확인할 수 있습니다:\n\n![이미지1](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_6.png)\n\n두 벡터 간의 거리 d가 클수록 유사도 점수가 낮아지고 그 반대도 마찬가지입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n유클리드 거리에는 몇 가지 제한이 있습니다. 먼저, 비교할 대상이 없다면 이해하기 어려운 값이 계산됩니다. 이 문제를 해결하기 위해 거리를 정규화할 수 있지만, 가장 잘 알려진 공식\n\n![image](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_8.png)\n\n은 이상치의 영향을 매우 민감하게 받습니다.\n\n둘째, 유클리드 거리는 텍스트의 크기에 강하게 영향을 받기 때문에 희소 벡터(예: 원핫 인코딩으로 생성된 벡터)와는 잘 작동하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코사인 유사도\n\n코사인 유사도는 두 벡터의 유사성을 측정하는 것으로, 벡터 사이의 각도의 코사인을 측정합니다. 두 점 사이의 거리를 측정하는 대신 두 벡터가 같은 방향으로 향하는지 확인합니다. 따라서 이는 벡터의 크기에 영향을 받지 않습니다.\n\n코사인 유사도는 다음과 같은 공식을 통해 계산됩니다:\n```js\n\\[ \\text{cosine similarity} = \\frac{{\\textbf{A} \\cdot \\textbf{B}}}{{\\lVert \\textbf{A} \\rVert \\times \\lVert \\textbf{B} \\rVert}} \\]\n```\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_10.png\" /\u003e\n\n벡터의 영향을 받아 이러한 지표를 비교하는 것에 대한 의미를 더 잘 이해해 봅시다.\n\n두 개의 논문을 비교해보자고 가정해보겠습니다. 한 쪽은 정치와 관련된 것이고, 다른 한 쪽은 스포츠와 관련된 것이라고 가정해보겠습니다. \"야구\"라는 단어가 논문 1에 논문 2보다 더 많이 나오는 경우, 유클리드 거리에 따르면, 논문 1이 스포츠와 관련이 더 있습니다. 그러나 논문 1이 그냥 논문 2보다 더 길었을 수도 있습니다. 결과적으로 논문 2가 논문 1보다 스포츠와 더 관련된 경우도 있을 수 있습니다.\n\n대부분의 텍스트 유사성 사용 사례들은 길이에 민감하지 않습니다. 따라서 일반적으로 코사인 유사도가 유클리드 거리보다 선호됩니다. 유클리드 거리가 선호될 수 있는 사용 사례는 길이에 민감한 표절 탐지입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 의미적 거리\n\n텍스트 간에 공통된 단어가 많지 않은 상황에서는, 길이나 분포에 의존하는 거리 측정으로 유도된 유사성은 비교적 낮게 나타날 수 있습니다. 이러한 경우 의미적 거리 계산을 선택하는 것이 좋습니다.\n\n이를 위한 주요 방법은 Word Mover's Distance로, 이는 텍스트 간의 의미적 근접성을 결정하는 데 도움을 줍니다.\n\nWord mover's distance\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단어 이동 거리는 두 텍스트 문서 간에 유사성을 정의하는데, 한 문서의 임베드된 단어가 다른 문서의 임베드된 단어에 도달하기 위해 이동해야 하는 최소 거리를 나타냅니다. 따라서 유사성의 측정은 운송 문제가 됩니다: 텍스트1을 텍스트2로 운송하는 비용을 최소화합니다.\n\n단어 이동 거리는 확률 분포 간 유사성을 측정하는 최적화 문제인 Earth Mover's Distance에서 비롯되었습니다. 이는 한 분포를 다른 분포로 변환하는 비용을 고려하여 유사성을 측정합니다.\n\nWMD를 계산하기 위한 첫 번째 단계는 정규화된 Bag of Words로의 단어 임베딩입니다. 둘째, 유클리드 거리가 계산되고 마지막으로 최적화 문제가 계산됩니다. 최적화 문제의 목적 함수는 한 문서에서 다른 문서로 이동하는 데 필요한 거리를 최소화하는 것이며, \"질량\"의 총량이 보존되어야 한다는 제약조건이 따릅니다. 다시 말해, 제약 조건은 두 문서의 전체 내용이 고려되고 한 단어에서 다른 단어로 이동하는 과정에서 어떤 단어도 중복되거나 손실되지 않도록 보장합니다.\n\n긴 문서에 대해 특히 계산 비용이 많이 드는 WMD는 모든 단어의 존재 여부를 사용하는 방법으로, 순서에 상관없이 문법적인 변경사항에 강하지 않습니다. 그러나 단어의 유사성을 임베딩 공간에서 고려하기 때문에 공통 단어가 거의 없는 문서에 대해서는 매우 효과적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n![이미지](/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_11.png)\n\n의미론적 유사성을 측정하는 것은 자연어 처리 세계에서 가장 복잡한 도전 중 하나입니다. 텍스트 유사성 측정의 공간을 탐험하면 각각 독특한 장단점이 있는 다양한 방법을 발견할 수 있습니다.\n\n문자열 기반 방법은 간단하고 구현하기 쉽지만 의미 관계를 다루지 않습니다. 그에 반해 말뭉치 기반 방법은 더 복잡하지만 의미적이고 통계적인 관계를 중요시하며 여러 언어에 대해 다재다능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n거리 측정에 관한 것은 일부가 길이에 민감하고, 다른 일부는 분포에 의존하거나 의미에 중점을 둡니다. 이러한 측정 방법과 텍스트 표현의 조합은 무한합니다.\n\n계속 발전하는 이 환경에서 완벽한 모델을 찾는 노력이 계속되는 중에도, 하나의 진리는 명확히 남아 있습니다: 최적의 방법을 선택하는 것은 각 사용 사례의 고유한 요구 사항과 깊은 관련이 있습니다. 우리가 앞으로 나아가면서, 표현학습과 거리 계산 사이의 시너지는 계속 발전하는 텍스트 벡터의 길을 열어주며, 의미 유사성에 대한 우리의 이해력에 새 시대를 열어줍니다.\n\n# 참고문헌\n\n[1] Qiu, Xipeng, 등. \"자연어 처리를 위한 사전 훈련된 모델: 설문.\" Science China Technological Sciences 63.10 (2020): 1872-1897.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Goldberg, Yoav, and Omer Levy. \"word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method.\" arXiv preprint arXiv:1402.3722 (2014).\n- Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint arXiv:1810.04805 (2018).\n- Wang, Jiapeng, and Yihong Dong. \"Measurement of text similarity: a survey.\" Information 11.9 (2020): 421.\n- Kusner, Matt, et al. \"From word embeddings to document distances.\" International conference on machine learning. PMLR, 2015.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[6] [Online]. Available: [Newscatcher API - Ultimate Guide to Text Similarity with Python](https://www.newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python).\n\n[7] McCormick, Chris. “Word2vec tutorial-the skip-gram model.” Apr-2016. [Online]. Available: [Word2vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model) (2016).","ogImage":{"url":"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png"},"coverImage":"/assets/img/2024-05-20-MasteringTextSimilaritycombiningembeddingtechniquesanddistancemetrics_0.png","tag":["Tech"],"readingTime":14},{"title":"번드 - 전례 없이 병렬 컴퓨팅을 강력하게 돕는 러스트 기반 언어","description":"","date":"2024-05-20 20:52","slug":"2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore","content":"\n\n안녕하세요! Bend에 대해 들어보셨나요?\n\n아직 안 들어보셨나요? 이 이야기를 읽고 있다면 아직 늦지 않으십니다.\n\n몇 시간 전에 Bend라는 GitHub 저장소를 발견했어요. 'Bend — 대규모 병렬 처리를 지원하는 고수준 프로그래밍 언어'라는 제목이 붙어 있었죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBend는 병렬 계산을 수행하는 방식을 영원히 변경하려는 고수준 프로그래밍 언어입니다.\n\n세계를 바꾼다고 약속한 언어가 많았다는 건 알고 있어요. 하지만 Bend는 실제로 그럴 수도 있어요!\n\nBend가 약속하는 좋은 부분을 알아보기 전에 병렬 계산에 대해 조금 배워볼까요?\n\n# 병렬 계산 - 최소의 시간으로 최대의 일을 하는 기술\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컴퓨터 프로그램은 기본적으로 작업을 하나씩 차례대로 실행합니다.\n\n이는 프로세서 코어에 의해 한 번에 한 가지 명령을 실행하는 단일 스레드에 의존하기 때문입니다.\n\n이 간단한 방식은 순차 계산이라고 합니다.\n\n이로 인해 프로그램 내부의 명령 흐름이 예측 가능하고 디버깅하기 쉬워집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나, 이것은 또한 모든 명령어가 실행을 시작하기 전에 이전 명령어가 끝날 때까지 기다려야 한다는 것을 의미합니다.\n\n현대 컴퓨팅 시대에 있어서 대부분의 프로세서가 여러 코어로 구성되어 있기 때문에, 병렬 연산이라는 다른 접근 방식을 사용하여 지수적으로 빠르게 만들 수 있습니다.\n\n프로그램 내의 많은 명령어들이 여러 스레드를 사용하여 동시에 실행됨으로써 프로그램 전체의 실행 시간을 줄일 수 있습니다.\n\n# 하지만, 병렬 연산을 올바르게 수행하는 것은 어려울 수 있습니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n병렬 계산을 다룬 적이 있는 분이라면, 그것을 올바르게 처리하는 것이 정말 악몽이라고 동의할 것입니다.\n\n동시에 공유 리소스에 접근하는 여러 스레드는 경합 상태를 유발해 완전히 예상치 못한 결과로 이어질 수 있습니다.\n\n또는, 좋지 않은 날이면 두 개 이상의 스레드가 서로가 차지한 리소스를 대기하고 끝없이 기다리는 데드락에 갇힐 수도 있습니다.\n\n이러한 문제는 Python 라이브러리인 threading과 multiprocessing이나 Go의 WaitGroup, Mutex, RWMutex와 같은 동기화 기본 요소를 이용한 Goroutines 등으로 해결되었지만, 이들의 구현은 숙련하기 어렵습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCUDA 및 Metal은 각각 NVIDIA 및 Apple GPU에서 병렬 계산을 활성화하는 몇 가지 다른 프로그래밍 모델입니다. 그러나 이를 다루는 대부분의 사람들은 (정직하다면) 그것을 완벽히 이해하는 데 얼마나 어려운 작업인지 말해 줄 것입니다.\n\n그럼에도 불구하고 남아 있는 의문은 —\n\n병렬 계산을 쉽게 할 수 있는 새로운 사람들에게 좋은 대안이 없는 걸까요?\n\n# Bend가 구해줄게요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단순히 Python처럼 쉽게 느껴지도록 작성된 언어인 Bend는 아마도 우리를 이 비통으로부터 구출해 줄 수 있는 사랑스러운 언어일지도 모르겠어요.\n\n그 철학은 웃기게 간단합니다 —\n\nBend는 기본적으로 코드를 병렬로 실행하기 때문에, 다중 코어 CPU 또는 GPU와 작업하기 위해 CUDA를 배우는 데 수년을 보내야 할 필요가 없어요.\n\n## 하지만, Bend는 어떻게 이것이 가능하게 만드는 걸까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBend은 매우 병렬 실행을 위해 설계된 강력한 계산 프레임워크인 HVM2 또는 Higher-order Virtual Machine 2에 의해 구동됩니다.\n\nPython과 같은 고수준 언어로 작성된 프로그램을 HVM2로 컴파일하면 GPU에서 빠르게 실행할 수 있습니다!\n\nHVM2는 1997년 Yves Lafont가 고안한 병렬 컴퓨테이션 모델인 Interaction Combinators를 기반으로 하며, 그래프 기반 구조를 사용합니다.\n\n이 모델에서 각 계산은 그래프로 시각화됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 그래프들에서 각 노드는 조합자(Combinator)입니다.\n\n조합자는 이 모델의 기본 구성 요소로 작용하는 고차 함수입니다.\n\n각 조합자마다 다른 조합자와의 상호 작용 방식을 결정하는 간단한 규칙 세트가 있습니다. 예를 들어 —\n\n- Identity Combinator는 인수를 변경하지 않고 반환합니다.\n- Constant Combinator는 두 개의 인수를 사용하고 첫 번째 것을 반환합니다(두 번째 것을 무시), 등등.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래프에서 각 엣지는 이 결합자들 간의 연결을 나타냅니다.\n\n이러한 결합자들이 상호작용할 때(엣지에서 시사하는 대로), 그들은 각자의 규칙에 따라 변환되어 결과를 돌려줍니다.\n\n상호작용 결합자 모델에서 가장 훌륭한 부분은 이들의 그래프 구조가 프로그램 내의 다른 계산을 서로 다른 코어(즉, 병렬로)에서 처리할 수 있게 한다는 것입니다.\n\n그리고 이것이 이 모델을 강력하게 만드는 요소입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nHVM2은 고수준 언어로 작성된 프로그램을 대상으로 하는 저수준 컴파일러이며 직접 사용하기 위한 것은 아닙니다.\n\n재귀 합을 구현하려면 다음과 같이 읽을 수 있습니다.\n\n```js\n@main = a\n  \u0026 @sum ~ (28 (0 a))\n\n@sum = (?(((a a) @sum__C0) b) b)\n\n@sum__C0 = ({c a} ({$([*2] $([+1] d)) $([*2] $([+0] b))} f))\n  \u0026! @sum ~ (a (b $(:[+] $(e f))))\n  \u0026! @sum ~ (c (d e))\n```\n\n하지만 걱정하지 마세요. Bend는 우리의 삶을 쉽게 만들기 위해 이 암호화된 HVM2와 인터페이스를 맺기 위해 작성된 사람이 읽을 수 있는 언어입니다. 함께 작업을 병렬로 처리할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Bend 사용 방법\n\nBend는 러스트 프로그래밍 언어로 작성되었으므로, 첫 번째 단계는 Rust nightly를 설치하고, 그 다음으로 HVM2와 Bend를 함께 설치하는 것입니다.\n\n```js\ncargo +nightly install hvm\ncargo +nightly install bend-lang\n```\n\n안타깝게도, 현재 Windows에서는 작동하지 않기 때문에 (나처럼) WSL2를 해결책으로 사용해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 Bend 코드를 작성합니다.\n\n```js\n# sorter.bend\n\n# Sorting Network = just rotate trees!\ndef sort(d, s, tree):\n  switch d:\n    case 0:\n      return tree\n    case _:\n      (x,y) = tree\n      lft   = sort(d-1, 0, x)\n      rgt   = sort(d-1, 1, y)\n      return rots(d, s, lft, rgt)\n\n# Rotates sub-trees (Blue/Green Box)\ndef rots(d, s, tree):\n  switch d:\n    case 0:\n      return tree\n    case _:\n      (x,y) = tree\n      return down(d, s, warp(d-1, s, x, y))\n\n# Swaps distant values (Red Box)\ndef warp(d, s, a, b):\n  switch d:\n    case 0:\n      return swap(s + (a \u003e b), a, b)\n    case _:\n      (a.a, a.b) = a\n      (b.a, b.b) = b\n      (A.a, A.b) = warp(d-1, s, a.a, b.a)\n      (B.a, B.b) = warp(d-1, s, a.b, b.b)\n      return ((A.a,B.a),(A.b,B.b))\n\n# Propagates downwards\ndef down(d,s,t):\n  switch d:\n    case 0:\n      return t\n    case _:\n      (t.a, t.b) = t\n      return (rots(d-1, s, t.a), rots(d-1, s, t.b))\n\n# Swaps a single pair\ndef swap(s, a, b):\n  switch s:\n    case 0:\n      return (a,b)\n    case _:\n      return (b,a)\n\n# Testing\n# -------\n\n# Generates a big tree\ndef gen(d, x):\n  switch d:\n    case 0:\n      return x\n    case _:\n      return (gen(d-1, x * 2 + 1), gen(d-1, x * 2))\n\n# Sums a big tree\ndef sum(d, t):\n  switch d:\n    case 0:\n      return t\n    case _:\n      (t.a, t.b) = t\n      return sum(d-1, t.a) + sum(d-1, t.b)\n\n# Sorts a big tree\ndef main:\n  return sum(18, sort(18, 0, gen(18, 0)))\n```\n\n이것은 공식 저장소에서 가져온 예시로, 병렬 정렬 알고리즘인 Bitonic Merge Sort를 구현한 것입니다.\n\n이 알고리즘은 병렬로 실행할 수 있는 분할 정복 방식을 사용하므로 Bend는 병렬로 실행할 것입니다 (Bend의 철학을 기억하시나요?)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 이 명령어를 사용하여 sorter.bend 프로그램을 실행합니다 —\n\n```js\nbend run sorter.bend # 러스트 해석기(순차 실행) 사용\nbend run-c sorter.bend # C 해석기(병렬 실행) 사용\nbend run-cu sorter.bend # CUDA 해석기(대규모 병렬 실행) 사용\n```\n\n마지막 명령어는 기기의 GPU를 자동으로 사용하며, 세부 사항을 자세히 다룰 필요가 없습니다.\n\n또한 최대 성능을 위해 Bend 파일을 독립적인 C/CUDA 파일로 컴파일할 수 있지만, 이러한 명령어는 아직 성숙하지 않을 수 있으며 오류를 발생시킬 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nBend는 아직 초기 단계에 있지만 매우 유망해보입니다.\n\n다음 섹션의 자원들은 더 많이 배우고 개발에 참여하는 데 도움을 줄 것입니다. 한번 보세요!\n\n즐거운 병렬 처리!\n\n# 더 많이 알아보기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Bend의 GitHub 저장소\n- Bend를 처음부터 배우기\n- Higher-order Virtual Machine 2 (HVM2)의 GitHub 저장소\n- HVM 작동 방식 블로그 포스트\n- HVM 작동 방식 비디오 설명\n- Y. Lafont에 의한 상호 작용 결합 연구 논문\n- Blend의 모기업인 Higher Order Company 웹 사이트\n\n저의 작업과 계속 연락하고 싶다면 이메일 목록 링크를 확인하세요 —","ogImage":{"url":"/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png"},"coverImage":"/assets/img/2024-05-20-BendARust-BackedLanguageThatSuperchargesParallelComputingLikeNeverBefore_0.png","tag":["Tech"],"readingTime":6},{"title":"용어 해설 AI 시스템 제어하기","description":"","date":"2024-05-20 20:51","slug":"2024-05-20-GlossaryControllingAISystems","content":"\n\n## 장난기 많은 해독자들\n\n![이미지](/assets/img/2024-05-20-GlossaryControllingAISystems_0.png)\n\n요즘 AI 제어 시스템에 대한 많은 이야기가 나오고 있는데, 그에 이어서 불가피하게 숨통을 헤친 것들이 많아지고 있어요(인터넷 덕분이죠). 공간을 명료하게 만드는 데 도움을 주기 위해 여러 용어를 수집하고, 각 용어에 대한 짧은 설명을 도출해내는 것을 최대한 노력했어요. 그리고 그것들을 그 구성 요소들로 분해해보려고 노력해봤어요:\n\n- 따뜻한 색상: 소프트웨어가 아닌 것\n- 차가운 색상: 소프트웨어\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노랑: 교육\n주황: 연구\n빨강: 정책/규정\n\n청색: 제품 측면(제품 내부 기능)\n하늘색: 사용자 측면(사용자 능력 향상 도구)\n\n이 57개 항목 중에서 모두 전문가가 될 수 없으니, 약간 틀릴 수밖에 없습니다. 그렇게 많이는 아니지만요 — 사실 확인에 최선을 다하였습니다. 하지만 인간이기 때문에, 제가 미묘한 부분을 잘못 이해했을 경우에는 저에게 토마토를 던지지 말아주시고, 부드럽게 알려주시면 감사하겠습니다. 흥미가 있다면 알파벳으로 정렬된 목록도 아래 텍스트로 제공되었습니다.\n\n그러나 색깔로 구분한 것을 보면 뭔가 흥미로운 점을 알아채셨나요? 핵심 단어를 따라가보세요, 그것들이 관심, 노력 및 투자가 이루어지는 곳과 일치하는 것 같습니다. 그런 식으로 읽으면, 제품 측면이 아닌 인간 측면에 도구를 구축하는 노력이 충분하지 않은 것으로 보입니다. 기술적이지 않은 인간 의사 결정자 및 그들의 조직이 복잡한 기술의 방향을 조정하는 것을 개선할 수 있는 정도보다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n정말 아무것도 없이 순수한 마음만으로 복잡한 기술을 책임있게 다룰 수 있다고 믿는 건가요? 우리가 그런 능력을 갖추기 위해 긴급히 도구를 만들어야 하는 거 아닌가요?\n\n# 알파벳 순 글로시\n\n- AI 책임성 — AI 개발자와 사용자가 자신들의 시스템이 미치는 영향에 대해 책임을 지는 메커니즘을 수립하는 것. [소프트웨어(규칙/정책): 80%, 소프트웨어(연구): 20%]\n- AI 정렬 — 인간의 가치와 의도와 일치하는 AI 시스템의 목표와 행동을 개발하는 것. [소프트웨어(연구): 80%, 소프트웨어(제품): 20%]\n- AI 감사 — AI 시스템을 적합성, 안전성, 도덕적 고려 사항에 대해 평가하고 모니터링하는 것. [소프트웨어(규칙/정책): 70%, 소프트웨어(제품): 30%]\n- 증강지능 — 인간 능력을 대체하는 대신 AI를 통해 향상시키기. [소프트웨어(사용자): 60%, 소프트웨어(제품): 30%]\n- AI 벤치마킹 — AI 시스템을 비교하고 평가하기 위한 표준화된 측정 항목 및 테스트 수립. [소프트웨어(연구): 60%, 소프트웨어(규칙/정책): 40%]\n- AI 편향 완화 — AI 시스템의 편향을 식별하고 줄이는 기술과 방법으로 공정하고 공평한 결과를 보장. [소프트웨어(제품): 70%, 소프트웨어(연구): 30%]\n- AI 능력 구축 — 효율적으로 AI 시스템을 만들고 관리하기 위해 필요한 기술과 지식을 개발. [소프트웨어(교육): 70%, 소프트웨어(제품): 30%]\n- AI 인증 — AI 시스템의 안전성, 신뢰성 및 준수를 인증하기 위한 프로세스 및 표준 수립. [소프트웨어(규칙/정책): 60%, 소프트웨어(제품): 40%]\n- 인지 컴퓨팅 — 복잡한 문제 해결과 의사 결정에서 인간의 사고 과정을 시뮬레이션하는 데 AI 사용. [소프트웨어(제품): 70%, 소프트웨어(사용자): 30%]\n- AI 준수 — AI 시스템이 관련 법률, 규정 및 산업 표준을 준수하도록 보장. [소프트웨어(규칙/정책): 80%, 소프트웨어(제품): 20%]\n- AI 제어 시스템 — AI 시스템의 행동과 작업을 제어하기 위해 설계된 메커니즘. [소프트웨어(제품): 60%, 소프트웨어(연구): 40%]\n...\n\n[중략]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 읽어 주셔서 감사합니다!\n\n저에게서 의사 결정 지능에 대해 배우고 싶으신가요? 무료 강좌 링크가 여기 있어요:","ogImage":{"url":"/assets/img/2024-05-20-GlossaryControllingAISystems_0.png"},"coverImage":"/assets/img/2024-05-20-GlossaryControllingAISystems_0.png","tag":["Tech"],"readingTime":3},{"title":"그래프 이론 필수 가이드 18세기 수수께끼부터 인공 지능까지","description":"","date":"2024-05-20 20:46","slug":"2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence","content":"\n\n![The Essential Guide to Graph Theory: From an 18th Century Riddle to Artificial Intelligence](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_0.png)\n\n안녕하세요! 1736년 프러시아 케니흐스베르크의 번화한 거리를 떠나 떠돌아 보세요. 지금은 러시아 칼리닌그라드로 알려진 이 번창한 항구는 문화적으로도 건축적으로도 경이로운 곳입니다. 프레겔 강 둑을 따라 서성이며 이 도시의 중요한 동맥 중 하나인 이 강은 재주꾼 상인선박들의 먼 바다 속에서 멀리 분주한 시장의 떠들썩함과 만나게 됩니다. 이 강을 가로지르는 일곱 개의 멋진 다리들이 다양한 섬과 동네들을 연결하고 있습니다. 여러분이 걷는 길이 바로 유럽 대륙의 가장 예리한 두뇌들을 괴롭히고 있는 수학적 수수께끼의 기초가 되었다는 사실을 아셨나요.\n\n이곳을 가로지르면서 각 다리를 정확히 한 번씩 건너는 것이 가능한지에 관한 문제를 묻고 있는 것입니다.\n\n![The Essential Guide to Graph Theory: From an 18th Century Riddle to Artificial Intelligence](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n처음에는 그 문제를 진부하다고 생각했지만, 결국 신생 수학 부문 관리자인 29살의 스위스 수학자 레온하르트 오일러가 러시아 성페테르스부르크 과학 아카데미에서의 끌림을 이기지 못했어. 그 오일러야, \"오일러의 수\"로 유명한 그 오일러야 (이거 떠올리기 즐거우신 상수 e, ≈2.71828로 기억하시겠지). 함수, 합, 그리고 허수 표기법 (f(x), Σ, 그리고 i 각각)을 선보인 그 같은 오일러야, 삼각함수 sin과 cos, 지수 함수 사이의 관계를 보여주는 항등식을 세운 그 대 그 오일러야. 오일러는 버노우이, 가우스, 뉴턴, 라이프니츠와 마찬가지로 여러 분야에 영향을 미친 불안한 수학자 중 하나였지. 현대 과학과 수학 원리를 튼튼하게 다지면서 영원히 그들을 바꿔 놓은 그 오일러야가 바로 그랬어.\n\n만약 이미 좋아하는 수학자가 없다면, 적어도 상위 10명에는 오일러를 고려해 보길 권해드려. 그의 영향력을 과소평가하기 어려운 점이 많아. 그는 분명히 알려진 분야로 진출하고 수학과 과학 지식의 영역을 확장했지만, (논란의 여지는 있지만) 그의 가장 오래된 유산은 복잡한 개념을 단순화하는 데 있어. 오일러가 주요 직관적 개념과 표기법을 도입함으로써 어려운 주제를 보다 직관적으로 다가갈 수 있도록 도왔고, 앞으로 몇 세기 동안의 혁신을 허용하기에 더 나은 단순화를 이룰 수 있도록 했지. 어떤 면에선, 오일러는 머리카락을 잡아끌 수 있는 수학적 고난을 잊기 어렵게 만들었던 소리 없는 영웅인 셈이지 — 거기에 뭔가, 감히 말해보자면 즐거운(?) 게임이 되었던 고난을 —.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알겠어요. 필수 오일러 감상 랜트를 끝냈으니... 이제 재미있는 내용으로 넘어가 봅시다.\n\n## 절삭 “에지” — 그리고 “버텍스” — 솔루션\n\n오일러의 채티인버그 다리 문제에 대한 혁신적인 접근은 그의 추상적 사고 능력을 드러냈습니다. 그는 대지내의 구체적인 경로보다 다리의 연속이 더 중요하다고 인식했습니다. 이 통찰력을 통해 그는 다리를 연결하는 \"에지\"로 표시된 노드인 지형을, 효과적으로 그래프를 만들어 주는 \"버텍스\"로 나타낸 문제로 변환할 수 있었습니다(그림 3을 참조하세요).\n\n![그림](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오일러는 그 후에 지금은 \"handshaking lemma\"로 알려진 것을 적용했습니다: 각 다리는 양쪽 땅을 연결하기 때문에 두 번씩 세어집니다. 이는 각 땅에 연결된 다리의 총합이 짝수여야 한다는 것을 의미합니다. 다리의 총 숫자의 두 배입니다. 그러나, 홀수 개의 다리를 가진 홀수 개의 땅이 있는 경우, 통행 가능한 경로가 없게 됩니다.\n\n더 깊이 분석해 보니, 오일러는 이러한 경로가 존재하려면 홀수 개의 다리를 가진 땅이 없거나 두 개여야 한다는 것을 확인했습니다. 케ーニ흐스베르크의 경우, 네 개의 땅 모두 홀수 개의 다리를 가졌기 때문에 각 다리를 정확히 한 번씩 건너는 경로가 불가능했습니다. 이 결론은 지금 그래프 이론에서의 오일러 경로로 이해하게 된 기초를 형성하게 되었습니다.\n\n오일러는 그래프 내 노드와 엣지의 특정 배열은 중요하지 않음을 언급했습니다; 중요한 것은 그들 사이의 연결이라는 것입니다. 이 관찰은 그래프 이론(그리고 최종적으로 위상학 분야)에서 중요한데, 이는 기본 구조를 변경하지 않고 복잡한 네트워크를 대변할 수 있게 해줍니다.\n\n마지막으로, 오일러는 지금은 오일러 경로라고 알려지는 각 엣지를 정확히 한 번씩 통과하는 경로와, 이와 같은 경로가 시작점과 끝점이 동일한 오일러 회로라고 불리는 것 사이에 구별했습니다. 오일러의 이 경로에 대한 기준은 그래프가 연결되어 있고 홀수 차수의 노드가 정확히 제로 또는 두 개일 때 오일러 경로가 존재하며, 그래프가 연결되어 있고 모든 노드가 짝수 차수일 때만 오일러 회로가 존재한다는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 그래프 이론 오늘 — 선택과 경로\n\n오일러가 케ーニ히스베르크 다리 문제를 해결한 것으로 뿌리를 둔 지적 씨앗은 그래프 이론이라는 건강하고 방대한 나무로 자라났습니다. 그래프 이론은 복잡한 시스템에 대한 우리의 이해를 계속해서 형성하고 있는 프레임워크입니다.\n\n그래프 이론은 객체 간의 쌍 관계를 모델링하는 데 사용되는 수학적 구조를 연구합니다. 이 분야는 정점 또는 노드로 알려진 포인트의 모음으로 실제 세계 문제를 추상화하고, 엣지로 불리는 선분에 의해 연결된 그래프로 나타냅니다.\n\n이러한 단순화는 매우 유용하며, 그래프 이론적 렌즈를 통해 다양한 도메인에서 문제를 분석하고 해결하는 것이 가능합니다. 실제 세부 사항의 혼란을 줄이면서, 그래프 이론은 기술부터 사회과학에 이르기까지 다양한 분야에서 직접적인 경로, 효율적인 연결 및 최적의 해결책을 발견하는 것을 가능하게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것의 매력은 네트워크를 모델링하는 능력에만 있는 것이 아닙니다. 그래프의 다양한 유형을 특징 짓는 데 기여하는 것도 있습니다. 각 유형은 가중 그래프, 방향 그래프, 이분 그래프 및 다중 그래프와 같이 파티에 고유한 맛을 불어넣습니다. 이제 옷소매를 걷어차고 상용어로 말하자면 '야생'에서 이러한 그래프를 탐험해봅시다. 우리의 사용 사례에 맞게 몇 가지 Python 데모를 활용하여 이를 직접 만들어보는 방법을 알아보겠습니다. 복잡한 네트워크의 생성, 조작, 및 연구를 위해 설계된 Python 라이브러리인 networkx를 사용할 것입니다.\n\n## 가중 그래프: 적은 이용하는 길\n\n번화한 도시의 도로 네트워크를 고려해보십시오. 모든 도로가 같은 중요도로 만들어지는 것은 아닙니다. 어떤 도로는 도시의 한쪽 끝에서 다른 쪽 끝까지 빠르게 이동할 수 있는 고속도로이며, 다른 도로는 여러분의 인내심을 시험하는 혼잡한 거리입니다. 가중 그래프는 각 에지에 \"가중치\"를 할당하여 이러한 세부 사항을 포착할 수 있습니다. 이 가중치는 건너편으로 이동하는 데 필요한 비용, 거리, 또는 시간을 반영합니다.\n\n```python\nimport networkx as nx #이것은 그다지 흔하지 않은 라이브러리이므로 먼저 pip 설치해야 할 수도 있습니다\nimport matplotlib.pyplot as plt\n\n# 가중 그래프 만들기\nG_weighted = nx.Graph()\n\n# '비용'이 다른 도로를 나타내는 가중 에지 추가\nG_weighted.add_edge('A', 'B', weight=4)\nG_weighted.add_edge('B', 'C', weight=1)\nG_weighted.add_edge('C', 'D', weight=7)\nG_weighted.add_edge('A', 'D', weight=5)\n\n# 노드에 대한 레이아웃 생성\npos = nx.circular_layout(G_weighted)\n\n# 노드 위치에 따라 그래프 그리기\nnx.draw_networkx(G_weighted, pos, with_labels=True, node_color='skyblue', node_size=700)\n\n# 에지 레이블 그리기\nedge_labels = nx.get_edge_attributes(G_weighted, 'weight')\nnx.draw_networkx_edge_labels(G_weighted, pos, edge_labels=edge_labels)\n\n# 그래프 플롯 표시\nplt.title(\"Fig 4a: 가중 그래프: 도시 도로\")\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드를 실행하면 아래와 같은 모습의 그림이 나올 것입니다:\n\n![image](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_3.png)\n\n그다지 화려하지는 않겠지만, 이게 바로 포인트입니다. 더 복잡한 시나리오를 나타내는 데 확장할 수 있으면서도, 우리가 관심 있는 것만 단순하게 유지하고 불필요한 데이터의 이슈를 해결할 수 있습니다.\n\n모델에서 엣지에 있는 가중치는 현실적인 요소를 더해줍니다. 예를 들어 높은 가중치는 긴 도로나 혼잡한 교통이 있는 도로를 나타낼 수 있으며, 이를 통해 계획자들이 병목 현상을 식별하거나 인프라 향상이 필요한 지역을 찾는 데 도움이 됩니다. 결국, 때로는 무엇을 해야할지 모를 만큼 많은 데이터를 보유하고 있는 세상에서 가장 중요한 질문은 종종 다음과 같습니다: 특정 결정을 내리기 위해 정말 필요한 정보는 무엇인가요? 나머지는 그저 소음뿐입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그림 4a의 그래프 유형을 사용하면 알고리즘을 적용하여 가장 짧은 경로를 찾거나 트래픽 흐름을 최적화하거나 심지어 새 도로 건설을 계획할 수 있습니다. 도시의 연결성과 효율성을 향상시키기 위해 데이터 기반 의사결정에 강력한 도구가 됩니다. 이러한 그래프는 다음과 같은 분야에 중요할 수 있습니다:\n\n- 교통 관리: 가중 그래프를 분석함으로써 관할 당국은 교통이 집중되는 경로를 식별하고 대응함으로써 통근 시간을 단축하고 혼잡을 줄일 수 있습니다.\n- 인프라 계획: 계획자들은 서비스가 부족한 지역이나 새 도로나 대중교통 연결 공간의 잠재적 사이트를 발견할 수 있어 도시의 성장과 발전을 위해 더 나은 환경을 조성할 수 있습니다.\n- 비상 대응 최적화: 비상 서비스는 이러한 그래프를 사용하여 가장 빠른 경로를 결정하여 환경적인 상황에서 시기적극적인 대응을 보장할 수 있습니다.\n\n## 방향성 있는 그래프: 일방향 디지털 흐름\n\n이제 방향성 있는 그래프로 이동해 보겠습니다. 여기서 관계는 방향이 있는데, 마치 일방통행거리나 인터넷에서의 정보 흐름과 유사합니다. 가중 그래프는 각 엣지에 값을 할당하여 거리나 비용과 같은 특성을 양적으로 표현하지만, 방향성 있는 그래프는 정보의 흐름에 집중합니다. 가중 에지는 거리나 날짜에 따라 변경되는 통행료가 있는 도로와 같으며, 방향성 있는 에지는 한 방향 도로로, 엄격하게 A 지점에서 B 지점으로의 움직임을 허용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 웹사이트 내 개별 웹페이지를 나타내는 노드로 디지털 수퍼하이웨이의 스냅샷을 만들 것입니다. 방향성을 가진 엣지들은 사용자가 정보를 찾을 때 이동할 수 있는 단방향 경로를 강조합니다.\n\n```js\n# 마지막 예제와 다른 커널에서 작업 중인 경우, 필요한 라이브러리를 가져와야 합니다\n# 방향 그래프 생성\nG_directed = nx.DiGraph()\n\n# 방향을 갖는 엣지 추가. 각 노드는 하나의 웹페이지를 나타냅니다. 각 방향성을 가진 엣지는 한 페이지에서 다른 페이지로 이어지는 하이퍼링크입니다\nG_directed.add_edge('Page 1', 'Page 2')\nG_directed.add_edge('Page 1', 'Page 3')\nG_directed.add_edge('Page 2', 'Page 4')\n\n# 그래프 시각화\npos = nx.spring_layout(G_directed)\nnx.draw_networkx(G_directed, pos, with_labels=True, arrows=True)\nplt.title(\"Fig 4b: Directed Graph: Web Pages\")\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_4.png\" /\u003e\n\n웹 내비게이션에서 이는 사용자가 한 페이지에서 다른 페이지로 이동할 수 있지만 반대로는 그렇지 않음을 의미합니다. 이 흐름을 이해하는 것은 다양한 응용 프로그램에 매우 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 콘텐츠 접근성: 상호 액세스 없이 단방향 링크 뒤에 가치 있는 콘텐츠가 갇히지 않도록 보장합니다.\n- 사이트 구조: 사용자가 막다른 곳에 도달하지 않고 일반 콘텐츠에서 보다 구체적인 페이지로 자연스럽게 이동할 수 있도록 웹사이트의 구조를 설계합니다.\n- 정보 계층 구조: 사용자가 소개 정보에서 상세 콘텐츠로 안내되는 명확한 경로를 수립하여 사이트의 정보 구조를 반영합니다.\n\n이 경우 Fig 4b를 사용하여 디지털 트래픽의 경로를 설명하는 방향 그래프를 사용해 웹사이트의 구조를 통해 사용자가 어떻게 이동할 수 있는지, 각 페이지가 어떻게 상호 연결되어 사이트의 구조를 형성하는지 이해할 수 있었습니다. 이해는 웹 개발자부터 디지털 마케터에 이르기까지 디지털 콘텐츠의 디자인 및 관리에 관여하는 모든 사람들에게 기본적입니다.\n\n## 이분 그래프: 선호도와 예측 사이의 다리\n\n이분 그래프는 연결이 각 클래스 내에서 아닌 두 가지 다른 객체 클래스 사이에만 존재하는 독특한 방식으로 두 가지 서로 다른 객체 클래스를 나타내는 방법을 제공합니다. 두 가지 다른 그룹 사이의 춤으로 생각해보세요. 한 그룹의 각 구성원은 다른 그룹의 구성원과 춤을 추거나 할 수 있지만 자신의 그룹과는 춤을 추지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 Python 데모에서는 추천 시스템의 작은 부분을 모델링하기 위해 이분 그래프를 생성합니다. 사용자를 나타내는 노드 세트와 책, 영화 또는 기타 추천 가능한 엔티티가 될 수 있는 아이템을 나타내는 노드 세트 두 개를 정의합니다. 에지를 추가하여 사용자와 항목을 연결하며 선호도나 상호 작용을 나타냅니다. nx.bipartite_layout 함수를 사용하여 시각적으로 두 세트를 분리하여 구분과 연결을 명확히합니다.\n\n```python\n# 마지막 예제와 다른 커널에서 작업하는 경우 필요한 라이브러리를 가져오는 것을 기억하세요\n# 그래프 인스턴스 생성\nB = nx.Graph()\n\n# \"bipartite\" 노드 속성을 가진 노드 추가\nB.add_nodes_from(['User1', 'User2', 'User3'], bipartite=0)  # 사용자\nB.add_nodes_from(['Book1', 'Book2', 'Movie1', 'Movie2'], bipartite=1)  # 항목\n\n# 서로 다른 세트의 노드 간에 엣지 추가\nB.add_edges_from([('User1', 'Book1'), ('User1', 'Movie2'),\n                  ('User2', 'Book2'), ('User2', 'Movie1'),\n                  ('User3', 'Book1'), ('User3', 'Movie1')])\n\n# B가 이분 그래프인지 확인\nprint(nx.is_bipartite(B))  # 출력: True\n\n# 이분 그래프를 그림\npos = nx.bipartite_layout(B, ['User1', 'User2', 'User3'])\nnx.draw_networkx(B, pos, with_labels=True)\nplt.title(\"Figure 4c: Bipartite Graph: Recommendation System\")\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_5.png\" /\u003e\n\n이분 그래프는 스트리밍 서비스, 전자상거래 플랫폼 및 소셜 네트워크에서 사용되는 추천 시스템에서 특히 효과적입니다. 이들은 아래와 같은 면에서 도움이 됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 개인화(Personalization): 사용자-항목 상호작용을 분석하여, 사용자가 이전에 상호작용했던 항목과 유사한 항목을 제안해 컨텐츠를 개인화할 수 있습니다.\n- 협업 필터링(Collaborative Filtering): 이러한 그래프는 협업 필터링을 가능하게 하며, 비슷한 사용자들의 선호도에 기반하여 추천을 제공합니다.\n- 네트워크 분석(Network Analysis): 연결성과 클러스터 패턴을 이해함으로써, 명확한 마케팅 및 사용자 행동 이해에 도움이 됩니다.\n\n이분 그래프는 추천 엔진 내에서의 관계의 본질을 추상화하여, 사용자가 다음에 좋아할 것으로 예측하고 제안함으로써 사용자 경험을 강화하는 간소화된 유용한 방법을 제공합니다.\n\n# 인공지능을 위한 그래프 이론의 유용한 개념 - 지도학습(Supervised Learning)\n\n## 그래프로 시각화하는 신경망(Visualizing Neural Networks as Graphs)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인공 지능과 기계 학습에서 그래프 이론에 의해 제공되는 추상 모델은 중요합니다. 예를 들어 신경망의 구조를 자세히 들여다보면 그래프가 당신을 노려보고 있는 것을 볼 수 있습니다. 각 뉴런은 노드이고 각 시냅스 가중치는 이야기가 담긴 간선입니다. 입력에서 출력 레이어로 데이터 경로는 방향 그래프의 탐색을 흉내냅니다. 이 그래프 중심적 관점은 메타포에 그치지 않습니다. TensorFlow와 같은 프레임워크에서 연산의 구조적 현실입니다. 이 그래프 기반 표현은 데이터로부터 학습하고 패턴을 인식하며 결정을 내릴 수 있는 알고리즘을 개발하는 데 중요합니다. 이 추상화를 통해 인공 지능 시스템은 인간의 사고 과정의 복잡성을 근사할 수 있습니다.\n\n우리는 방향 그래프를 사용하여 밀도가 높은 연결된 신경망의 표현을 구축할 것입니다. 이 신경망은 두 개의 입력 노드, 두 개의 은닉층(첫 번째 층에는 두 개의 노드, 두 번째 층에는 세 개의 노드) 및 하나의 출력 노드로 구성됩니다. 레이어의 각 노드는 다음 레이어의 노드와 완전히(\"조밀하게\") 연결됩니다.\n\n이러한 시각화 방법은 우리가 한눈에 신경망의 구조를 이해하는 데 도움을 줍니다. 각각의 처리 레이어를 통해 입력 데이터로부터의 정보 흐름을 명확히하며 각각이 입력 데이터로부터 고유한 방식으로 학습하는 것에 기여합니다. 이러한 모델을 설계할 때 신경망의 깊이와 복잡성에 대한 통찰을 제공하기 때문에 중요합니다.\n\n```js\n#직전 예제와 다른 커널에서 작업 중이라면 필요한 라이브러리를 가져와야 합니다.\n#신경망을 모델링하기 위해 NetworkX DiGraph를 초기화합니다.\nneural_net = nx.DiGraph()\n\n#입력 레이어를 위한 노드 추가\nneural_net.add_nodes_from(['Input1', 'Input2'], layer='input')\n\n#첫 번째 은닉층을 위한 노드 추가(2개의 노드)\nneural_net.add_nodes_from(['Hidden1_1', 'Hidden1_2'], layer='hidden1')\n\n#두 번째 은닉층을 위한 노드 추가(3개의 노드)\nneural_net.add_nodes_from(['Hidden2_1', 'Hidden2_2', 'Hidden2_3'], layer='hidden2')\n\n#출력 레이어를 위한 노드 추가\nneural_net.add_node('Output', layer='output')\n\n#시냅스를 나타내는 간선을 사용하여 노드 연결 및 가중치 추가\n#가중치 라벨링 규칙은 'w(현재 노드 인덱스)_(연결 노드 인덱스) 입니다.\nweights = {\n    ('Input1', 'Hidden1_1'): 'w1_3', ('Input2', 'Hidden1_1'): 'w2_3',\n    ('Input1', 'Hidden1_2'): 'w1_4', ('Input2', 'Hidden1_2'): 'w2_4',\n    ('Hidden1_1', 'Hidden2_1'): 'w3_5', ('Hidden1_1', 'Hidden2_2'): 'w3_6', ('Hidden1_1', 'Hidden2_3'): 'w3_7',\n    ('Hidden1_2', 'Hidden2_1'): 'w4_5', ('Hidden1_2', 'Hidden2_2'): 'w4_6', ('Hidden1_2', 'Hidden2_3'): 'w4_7',\n    ('Hidden2_1', 'Output'): 'w5_8', ('Hidden2_2', 'Output'): 'w6_8', ('Hidden2_3', 'Output'): 'w7_8'\n}\n\nfor (u, v), weight in weights.items():\n    neural_net.add_edge(u, v, weight=weight)\n\n#각 노드의 위치를 명확히 하기 위해 수동으로 설정\npos = {\n    'Input1': (0, 1), 'Input2': (0, -1),\n    'Hidden1_1': (1, 1), 'Hidden1_2': (1, -1),\n    'Hidden2_1': (2, 2), 'Hidden2_2': (2, 0), 'Hidden2_3': (2, -2),\n    'Output': (3, 0)\n}\n\n#플로팅을 위한 figure 생성\nfig, ax = plt.subplots(figsize=(12, 8))\n\n#가중치에 대한 에지 라벨 작성\nedge_labels = nx.get_edge_attributes(neural_net, 'weight')\n\n#에지 라벨 포지션 조절(중첩 방지)\nedge_label_pos = {}\nfor edge in neural_net.edges():\n    u, v = edge\n    #중간점 계산 및 라벨 위치 조정\n    mid_x = (pos[u][0] + pos[v][0]) / 2\n    mid_y = (pos[u][1] + pos[v][1]) / 2\n    delta_x = pos[v][0] - pos[u][0]\n    delta_y = pos[v][1] - pos[u][1]\n    if abs(delta_x) \u003e abs(delta_y):\n        edge_label_pos[edge] = (mid_x, mid_y + 0.1)  #수평 에지를 위한 y 오프셋 조정\n    else:\n        edge_label_pos[edge] = (mid_x + 0.1, mid_y)  #수직 에지를 위한 x 오프셋 조정\n\n#신경망 그래프 그리기\nnx.draw_networkx(neural_net, pos, with_labels=True, node_size=1000, node_color='skyblue', arrowsize=20, font_size=10)\n\n#가중치에 대한 에지 라벨 작성\nedge_labels = nx.get_edge_attributes(neural_net, 'weight')\n\n#조정된 위치에 에지 라벨 그리기\nfor (u, v, d) in neural_net.edges(data=True):\n    edge_weight = d['weight']\n    x, y = (pos[u][0] * 0.6 + pos[v][0] * 0.4), (pos[u][1] * 0.6 + pos[v][1] * 0.4)\n    txt = plt.text(x, y, edge_weight, ha='center', va='center', rotation=0, fontsize=8)\n\n#제목 설정\nax.set_title(\"Fig 5a: Neural Network Graph (Directed and Weighted) with Two Hidden Layers\")\n\n#플롯 표시\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_6.png)\n\n신경망을 그래프로 모델링하면 그들의 구조를 이해하고 전달하는 강력한 도구를 얻습니다. 그래프 기반 접근법은 다음과 같은 것이 가능합니다:\n\n- 복잡성 시각화: 신경 계산의 상호 연결된 특성을 시각화할 수 있습니다. 뉴런과 그들의 연결을 배치함으로써, 데이터 내의 복잡한 패턴 및 관계가 어떻게 감지되고 처리되는지 볼 수 있습니다.\n- 아키텍처 디버깅 및 최적화: 병목 현상이나 중복 연결을 식별하는 것이 더 쉬워집니다. 이는 특히 딥 러닝에서 유용할 수 있습니다. 여기서 레이어와 노드의 수를 조정하는 것이 성능에 미치는 영향이 상당할 수 있습니다.\n- 연구 및 개발 지원: 연구자들은 그래프를 사용하여 새로운 네트워크 아키텍처를 제안하고 테스트할 수 있습니다. 그래프의 구조를 조정함으로써, 정보 처리의 새로운 방법을 실험해볼 수 있습니다.\n\n신경망을 그래프로 추상화함으로써, 우리는 모델을 분석하기 위한 다양한 그래프 이론 도구와 지표를 활용할 수도 있습니다. 이는 최단 경로를 조사하는 것(입력부터 출력까지의 가장 적은 변환 횟수를 이해하기 위해), 네트워크 중심성(가장 중요한 뉴런을 찾기 위해) 또는 심지어 커뮤니티 탐지(긴밀하게 협력하는 뉴런 군집 식별)를 포함할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 의사 결정 트리: 가지치기 그래프\n\n의사 결정 트리는 핵심적으로 루트 노드에서 시작하여 잎 노드로 가는 그래프로, 그 구조에 의사 결정의 본질을 담고 있습니다. 노드는 질문이나 결정을 나타내며, 간선은 데이터의 답변을 기반으로 취해진 경로를 표현합니다. 그래프 이론적으로 의사 결정 트리는 방향성이 있고 비순환적인 그래프(DAGs)로, 각 방향 간선은 질문에서 답변으로의 흐름을 나타내어 연속된 질문이나 최종 결정으로 이어집니다. 이 구조는 계층적이며 루트에서 잎까지의 명확한 방향을 나타내며, 잎은 결과를 표현합니다.\n\n우리는 이 그래프 기반의 의사 결정 과정을 클래식한 붓꽃 데이터셋에 적용할 것입니다.  이 데이터셋은 붓꽃의 150개 샘플로 구성되어 있고, 각각의 특징으로서 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 그리고 꽃잎 너비를 설명합니다. 데이터셋은 세 종류의 붓꽃 종(Sestosa, Versicolor, Virginica) 샘플을 담고 있습니다. 우리의 의사 결정 트리는 이러한 특징들로부터 학습을 통해 붓꽃의 종을 정확하게 예측할 것입니다.\n\n의사 결정 트리의 추상적인 개념을 구체적인 그래프로 번역하고자 하며, 의사 권하는 networkx를 계속 활용하여 의사 결정의 흐름을 시각화할 것입니다. 우리는 붓꽃 데이터셋을 사용하여 각 특징을 결정 노드로 사용하고, 해당 값에 따라 가지를 친 의사 결정 트리를 구성할 것입니다. 이는 최종적으로 붓꽃의 종을 예측하는 경로를 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\n# 아이리스 데이터세트 불러오기\niris = load_iris()\nX, y = iris.data, iris.target\n\n# 아이리스 데이터를 기반으로 의사결정 트리 분류기 훈련\nclf = DecisionTreeClassifier()\nclf.fit(X, y)\n\n# sklearn의 plot_tree를 사용하여 트리 그리기\nplt.figure(figsize=(20, 10))  # 그림의 크기 설정\nplot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\nplt.title(\"Fig 5b: 의사결정 트리 그래프 표현\")\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_7.png\" /\u003e\n\n의사결정 트리는 기계 학습에서 그래프 이론의 중요성을 전통적으로 보여주며, 알고리즘의 단계별 논리를 명확히 제시하는 구조를 제공합니다. 이 경우에는 방향 그래프의 간단한 구조가 필요에 따라 확장되어 시작부터 끝까지 알고리즘의 결정 경로를 보여줍니다. 이는 알고리즘이 데이터를 처리하여 특정 결론에 도달하는 방식에 대한 직관적인 이해를 제공하며, 지능적이고 데이터 중심의 솔루션을 개발하는 데 그래프 이론의 실용적인 응용을 보여줍니다.\n\n# 그래프 이론의 인공지능에 유용한 추상화 — 비지도 학습\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비지도 학습, 특히 클러스터링은 데이터 내의 관계를 활용하여 그룹이나 클러스터를 형성함으로써 그래프 이론에서 상당한 이득을 얻습니다. 그래프 이론은 클러스터링에 그 자체에만 있는 것이 아닙니다. 데이터의 기본 구조와 연결을 강조함으로써 이러한 기술을 이해하고 구현하는 방법을 개선할 수 있습니다.\n\n클러스터링은 동일한 클러스터에 속하는 객체들이 다른 클러스터에 속한 객체들보다 서로 더 유사하도록 하는 것을 목표로 합니다. 그래프 이론은 데이터 포인트를 노드로, 이러한 포인트 간의 유사성이나 거리를 엣지로 나타내어 그래프를 형성함으로써 클러스터링을 용이하게 합니다. 이 접근 방식은 연결성 및 네트워크 구조를 기반으로 한 자연적인 그룹화를 드러내는 데 특히 유용하며 전통적인 벡터 공간 표현에서 가려진 경우가 많습니다.\n\n## 스펙트럼 클러스터링: 그래프 기반 접근 방식\n\n스펙트럼 클러스터링은 그래프 이론을 데이터의 그래프 구조를 포착하는 라플라시안 행렬을 사용하여 클러스터링 기술에 통합시킬 수 있는 좋은 예입니다. 그 핵심은 다음과 같이 작동합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 그래프 표현: 스펙트럴 클러스터링은 각 데이터 포인트를 그래프의 노드로 취급하여 시작합니다. 데이터 포인트 간의 유사성이나 차이는 이러한 노드를 연결하는 엣지로 간주됩니다. 각 엣지의 강도나 가중치는 선택한 기준인 유클리드 거리나 다른 유사성 측정에 따라 두 점이 서로 얼마나 유사하거나 가까운지를 반영합니다.\n- 라플라시안 행렬 구성: 라플라시안 행렬은 그래프 표현에서 유도되며 노드 간의 연결성을 이해하는 데 중요합니다. 이 행렬은 그래프의 구조를 이해하는 데 도움이 되며 클러스터링 프로세스에 중요합니다. 이는 그래프의 인접 행렬에서 차수 행렬을 뺌으로써 유도됩니다. 인접 행렬은 노드 사이의 엣지 가중치를 기록하고, 차수 행렬은 노드에 연결된 엣지 가중치의 합을 나타내는 대각선 행렬입니다.\n- 라플라시안 행렬 분해: 다음 단계는 라플라시안 행렬을 분해하여 그 고유값과 해당하는 고유벡터를 추출하는 것입니다. 고유값은 그래프의 연결성에 대한 정보를 드러내고, 고유벡터는 데이터를 새로운 저차원 공간으로 투영하는 데 사용됩니다.\n- 데이터 투영: 가장 작은 비제로 고유값에 해당하는 고유벡터를 사용하여 데이터를 새로운 공간으로 투영합니다. 이 단계는 고차원 데이터를 클러스터가 더 분리되어 식별하기 쉬운 형태로 변환합니다.\n\n다시 말해, 스펙트럴 클러스터링은 복잡한 데이터셋 내에 내재된 구조를 효과적으로 드러내고 활용하기 위해 그래프 이론을 활용하며, 비정형 모양의 클러스터를 식별하는 데 특히 강력합니다.\n\n이제 \"두 달\" 데이터셋을 사용하여 스펙트럴 클러스터링을 시연할 것이며, 이를 통해 비선형 경계를 갖는 클러스터를 탐지하는 방법의 효과를 보여줄 것입니다. (그림 6a 참조)\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom sklearn.cluster import SpectralClustering\n\n# 두 달 데이터셋 생성\nX, _ = make_moons(n_samples=200, noise=0.1, random_state=42)\n\n# \"가장 가까운 이웃\" 클러스터링을 사용하여 스펙트럴 클러스터링 적용\nsc = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', n_neighbors=10)\nlabels = sc.fit_predict(X)\n\n# 결과 플롯\nplt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', edgecolor='k')\nplt.title('Fig 6a: 두 달 데이터의 스펙트럴 클러스터링')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_8.png\" /\u003e\n\n오일러의 스위스 뿌리를 기리며, 더 복잡한 배열과 고차원에서이 전략이 어떻게 더 유용해지는지 모델링하여 클러스터링 알고리즘의 능력을 테스트하는 데 자주 사용되는 클래식 데이터 세트 인 스위스 롤 모양을 살펴보겠습니다. 특히 복잡한 매니폴드 구조를 가진 데이터를 해독할 수있는 알고리즘 (Fig 6b 참조) 입니다. 이 경우에는 스위스 롤 모양을 구성하는 포인트 (노드)를 두 가지 서로 다른 클러스터로 구분 할 수있을까요?\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_swiss_roll\nfrom sklearn.cluster import SpectralClustering\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# 2000개의 샘플과 잡음 수준이 0.1인 스위스 롤 데이터 세트 생성\nX, _ = make_swiss_roll(n_samples=2000, noise=0.1, random_state=42)\n\n# 2개의 클러스터에 Spectral Clustering를 적용하고 \"최근 이웃\" 친화성을 사용합니다.\n# 결과를 확인하기 위해 더 많은 클러스터를 시도해보세요.\nsc = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', n_neighbors=10)\nlabels = sc.fit_predict(X)\n\n# 3D 산점도로 결과 플롯하기\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X[:, 0], X[:, 2], X[:, 1], c=labels, cmap='viridis', edgecolor='k')\nax.set_title('Fig 6b: 스위스 롤 데이터의 스펙트럴 클러스터링')\nax.set_xlabel('특성 1')\nax.set_ylabel('특성 3')\nax.set_zlabel('특성 2')\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_9.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 클러스터링에서 그래프 이론의 유틸리티 및 통찰\n\n- 데이터의 그래픽 표현: 데이터를 그래프로 시각화하면 클러스터링 알고리즘이 공간이 높은 경우와 같이 데이터의 실제 구조를 더 잘 파악할 수 있습니다. 이 그래픽 관점은 접근성이나 밀도에만 의존하는 대신 점들이 어떻게 상호 연결되어 있는지에 기초하여 클러스터를 식별할 수 있도록 합니다.\n- 복잡한 구조 다루기: 그래프 이론은 이음매가 얽힌 나선이나 동심원 같은 복잡한 모양을 형성하는 데이터를 처리하는 데 뛰어나며, 기존의 중심 또는 밀도 기반 클러스터링 방법이 실패할 수 있는 상황에서 능력을 발휘합니다.\n- 유연성과 다양성: 그래프 기반 클러스터링 방법은 다양한 종류의 데이터를 처리하는 데 다재다능하며 다양한 유사성 측정에 적응할 수 있어 데이터의 불규칙성과 잡음에 대해 견고합니다.\n- 시각화와 해석: 그래프 기반 방법은 클러스터링 성능을 향상시키는 데 그치지 않고 결과의 해석 가능성을 향상시킵니다. 클러스터가 어떻게 형성되는지 명확한 시각적 통찰을 제공하여 데이터 분석과 의사 결정 프로세스에 매우 가치 있는 정보를 제공합니다.\n\n그래프 이론을 통합하면 Spectral Clustering은 비지도 학습에서 전통적인 클러스터링 접근 방식의 한계를 극복할 뿐만 아니라 데이터의 고유 구조와 보다 일치하는 방식으로 데이터를 분석하는 새로운 가능성을 열어줍니다.\n\n# 현대 AI 기반 제품에서의 그래프 이론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMicrosoft Copilot은 그래프 이론 원리가 제품의 유용성을 궁극적으로 향상시키는 데 사용될 수 있는 한 예입니다. 이 경우에는 다양한 데이터 유형과 소스를 데이터 생태계 전반에 걸쳐 연결함으로써 사용자 상호작용을 개선합니다.\n\nCopilot의 그래프 이론적 기초는 사용자 상호작용을 문맥화하고 개인화하는 능력에 나타납니다. Copilot은 연결된 지점으로의 방대한 데이터 네트워크를 분석함으로써 사용자의 현재 문맥에 관련된 정보를 종합하고 생성할 수 있습니다.\n\n## Copilot의 그래프 이론 기반 메커니즘 이해\n\nMicrosoft Copilot은 사용자 프롬프트와 조직 데이터를 복잡한 상호 연결 정보 그래프로 변환하여 작동합니다. 이 그래프는 정적 개체가 아니며, 새로운 데이터의 흡수 및 사용자 상호작용을 통해 지속적으로 업데이트되고 풍부화됩니다. 여기서 노드는 데이터 포인트를 나타내고 엣지는 그들 사이의 관계를 반영하며, 데이터 포인트 사이의 다양한 직간접 관계를 고려합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 데이터 수집 및 스키마 생성: Copilot 운영의 핵심은 다양한 소스에서 통합 및 모델링된 데이터가 있는 Microsoft Graph에 있습니다. 여기서 데이터는 단순히 저장되는 것이 아니라 교차 연결성을 반영하는 스키마에 따라 구조화됩니다. 새로운 데이터가 통합되고 사용자 상호 작용이 발전함에 따라 기본 그래프는 성장하고 적응하여 시간이 지남에 따라 Copilot의 학습 능력을 향상시키고 응답을 개선합니다.\n- 데이터 색인 및 쿼리 처리: Copilot이 이 방대한 그래프에서 관련 데이터 포인트를 검색하는 것은 색인 및 쿼리 처리 능력에 달려 있습니다. 이 프로세스들은 AI 도구가 데이터 그래프를 탐색하고 그래프 이론적 모델에서 최단 경로를 찾을 수 있도록 합니다.\n- 내용 이해 및 응답 생성: 그래프 이론 원칙을 활용하여, Copilot은 상호작용의 내용을 \"이해\"합니다. 사용자 쿼리와 데이터를 독립적으로 보는 것이 아니라 더 큰 구조의 일부로 간주합니다. 이 관점을 통해 Copilot은 데이터 노드 간의 연결의 근접성과 강도를 고려하는 그래프의 위상학에 기반한 응답을 수립할 수 있습니다. 데이터의 그래프 구조를 활용하여, Copilot은 사용자의 요구를 더 직관적이고 반영적인 맥락에 맞게 제공할 수 있습니다.\n\n# 마무리하며\n\n끝까지 와서 축하드립니다! 우리는 그래프 이론의 매혹적인 세계를 탐험했습니다. 오일러의 쾨닉스베르크 다리 문제로부터 현대 기술에서의 중요한 역할까지 그 발전을 추적해 왔습니다. 노드와 엣지의 추상화가 복잡한 시스템을 간단하게 만들어 혁신적인 해결책을 이끌어 내는 방법을 확인했습니다. 복잡한 관계를 이해 가능한 모델로 분해하는 것으로, 우리는 그래프 이론이 최적화된 정보 처리, 패턴 발견 및 데이터 기반 결정을 효율적으로 처리할 수 있는 능력을 향상시킨다는 것을 발견했습니다. 이러한 원칙들은 알고리즘의 복잡성을 향상시키는 것뿐만 아니라 정보를 조직하고 검색하는 방식을 최적화합니다.\n\n만약 제가처럼 ML 문제 해결의 세부 사항에 빠져들기를 즐기신다면, LinkedIn 및 Medium에서 팔로우해 주세요. 함께하면 하나의 현명한 해결책으로 AI 미궁을 탐험해 나갈 수 있습니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 알고리즘 모험까지 계속 탐험하고, 계속 배우고, 노드를 계속 연결해 보세요! 데이터 과학의 그래프를 탐험하는 여정이 그 자체의 추상화만큼 명확하고 통찰력 있기를 바랍니다.\n\n참고: 저자가 아닌 경우를 제외하고 모든 이미지는 저자의 것입니다.","ogImage":{"url":"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_0.png"},"coverImage":"/assets/img/2024-05-20-TheEssentialGuidetoGraphTheoryFroman18thCenturyRiddletoArtificialIntelligence_0.png","tag":["Tech"],"readingTime":21},{"title":"머신 러닝을 위한 피처 엔지니어링","description":"","date":"2024-05-20 20:42","slug":"2024-05-20-FeatureEngineeringforMachineLearning","content":"\n\n## 알고리즘이 마법을 발휘할 수 있도록 허용하기\n\n![image](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_0.png)\n\n“\\`쓰레기를 넣으면 쓰레기가 나온다\\` 라는 속담을 들어보셨나요? 이 속담은 기계 학습 모델을 훈련할 때 실제로 적용되는 내용입니다. 무관한 데이터를 사용하여 기계 학습 모델을 훈련하면 최고의 기계 학습 알고리즘도 큰 도움이 되지 않습니다. 반면, 잘 설계된 의미 있는 특성을 사용하면 단순한 기계 학습 알고리즘조차 우수한 성능을 달성할 수 있습니다. 그렇다면, 어떻게 우리 모델의 성능을 극대화할 의미 있는 특성을 만들 수 있을까요? 그 해답은 기능 엔지니어링에 있습니다. 전통적인 기계 학습 알고리즘(회귀, 결정 트리, 서포트 벡터 머신 등)을 사용할 때 특히 중요한 작업입니다. 그러나 이러한 숫자 입력을 생성하는 것은 데이터 기술뿐만 아니라 창의력과 도메인 지식도 요구하는 프로세스이며 과학의 영역만큼 예술도 요구합니다.\n\n일반적으로, 기능 엔지니어링을 두 가지 구성 요소로 나눌 수 있습니다: 1) 새로운 기능 생성 및 2) 이러한 기능을 처리하여 해당 기계 학습 알고리즘과 최적으로 작동하도록 만드는 과정입니다. 이 글에서는 횡단면, 구조화된, NLP가 아닌 데이터 집합에 대한 기능 엔지니어링의 이 두 가지 구성 요소에 대해 논의하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 새로운 기능 생성\n\n원시 데이터 수집은 지치는 작업일 수 있습니다. 이 작업이 끝날 때쯤에는 추가 기능을 만들기 위해 더 많은 시간과 에너지를 투자하기 힘들 수도 있습니다. 하지만 여기서 모델 훈련에 곧바로 뛰어들지 말아야 합니다. 제 약속드립니다, 그 작업이 노력할 가치가 충분할 것입니다! 이 지점에서 우리는 멈추고 스스로에게 물어봐야 합니다. \"내 도메인 지식을 기반으로 수동으로 예측을 한다면, 어떤 기능이 좋은 결과를 도와줬을까요?\" 이 질문을 던짐으로써, 우리의 모델이 그렇지 않았을지도 모르는 새로운 의미 있는 기능을 만들어내는 가능성을 열 수 있습니다. 추가로 어떤 기능이 도움을 줄 수 있는지 고려했다면, 아래 기술들을 활용하여 원시 데이터로부터 새로운 기능을 만들어낼 수 있습니다.\n\n## 1. 집계\n\n이 기법은 이름 그대로 여러 데이터 포인트를 결합하여 더 통합된 관점을 만들 수 있게 도와줍니다. 우리는 일반적으로 count, sum, average, minimum, maximum, percentile, standard deviation, variation 계수와 같은 표준 함수를 사용하여 연속적인 수치 데이터에 집계를 적용합니다. 각 함수는 다른 정보 요소들을 포착할 수 있으며, 사용할 최상의 함수는 특정 사용 사례에 따라 다릅니다. 종종, 우리는 그 문제의 맥락상 의미 있는 특정 시간이나 사건 창을 통해 집계를 적용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가져온 신용 카드 거래가 사기인지 예측하려고 하는 예시를 살펴봅시다. 이 경우에는 거래별 특징을 사용할 수 있겠지만, 이러한 특징들과 함께 고객 단위의 집계된 특징을 만드는 것이 유익할 수 있습니다:\n\n- 고객이 지난 다섯 년 동안 사기 피해자가 된 횟수: 이전에 여러 차례 사기 피해자가 된 고객은 다시 사기 피해자가 될 가능성이 높을 수 있습니다. 따라서 이러한 집계된 고객 단위의 관점을 사용하면 적절한 예측 신호를 제공할 수 있습니다.\n- 마지막 다섯 거래 금액의 중앙값: 신용 카드가 침해당했을 때, 사기꾼들은 카드를 테스트하기 위해 여러 차례 저가 거래를 시도할 수 있습니다. 지금은 단일 저가 거래가 매우 일반적이고 사기의 징후가 될 수 없지만, 짧은 시간 동안 많은 이러한 거래를 보게 된다면, 침해된 신용 카드를 나타낼 수 있습니다. 이러한 경우를 위해, 마지막 몇 거래 금액을 고려하는 집계된 특징을 만들 수 있습니다.\n\n![Feature Engineering for Machine Learning](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_1.png)\n\n## 2. Differences and Ratios\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n많은 유형의 문제에서 집합 패턴의 변경은 예측이나 이상 탐지에 대한 유용한 신호가 될 수 있습니다. 차이와 비율은 숫자 특성의 변화를 나타내는 효과적인 기술입니다. 집계와 마찬가지로 이러한 기술들을 그 문제의 맥락에서 의미 있는 시간 창 위에도 적용할 수 있습니다.\n\n예시:\n- 지난 1시간 동안의 새 상인 거래의 백분율과 지난 30일 동안의 새 상인 거래의 백분율 간의 차이: 빠른 연속으로 발생하는 많은 새 상인 거래의 높은 비율은 사기 위험을 나타낼 수 있지만, 이 행동이 고객의 과거 행동과 비교하여 변경된 것을 보면 더 명백한 신호가 됩니다.\n- 현재 날짜의 거래 건수를 지난 30일간의 중앙값 일일 거래 건수로 나눈 비율: 신용카드가 침해를 당하면 짧은 시간 동안 많은 거래가 발생할 가능성이 높으며, 이는 과거 신용카드 사용 패턴과 일치하지 않을 수 있습니다. 현재 날짜의 거래 건수를 지난 30일간의 중앙값 일일 거래 건수로 나눈 비율이 상당히 높으면 사기 사용 패턴을 나타낼 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_2.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3. 연령 인코딩\n\n날짜 또는 타임스탬프 기능을 숫자로 변환하는데 연령 계산 기술을 사용할 수 있습니다. 두 타임스탬프 또는 날짜 사이의 차이를 이용하여 수치적인 특성을 만들 수 있습니다. 또한, 특정 비숫자적인 특성을 의미있는 수치 특성으로 변환할 수도 있습니다. 특성 값에 연관된 기간이 예측에 유용한 신호가 될 수 있는 경우 이 기술을 사용할 수 있습니다.\n\n예시:\n\n- 최근에 신용카드를 사용한 날로부터 경과한 일수: 오랜 기간 사용되지 않았던 신용카드에서 갑작스러운 거래는 사기 가능성이 높을 수 있습니다. 우리는 신용카드를 마지막으로 사용한 날짜와 현재 거래 날짜 사이의 시간 차이를 이용하여 이 특성을 계산할 수 있습니다.\n- 고객이 사용한 기기가 처음 사용된 날로부터 경과한 일수: 새로운 기기로부터 발생한 거래를 볼 때, 해당 거래는 고객이 오랫동안 사용한 기기에서 만든 거래보다 더 위험할 수 있습니다. 우리는 고객이 이 기기를 처음 사용한 날로부터 현재 거래 날짜 사이의 차이를 나타내는 기기 연령의 특성을 만들 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Feature Engineering for Machine Learning](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_3.png)\n\n## 4. Indicator Encoding\n\nIndicator 또는 Boolean feature는 이진 값 '1, 0' 또는 'True, False'를 가지고 있습니다. Indicator feature는 매우 일반적이며 다양한 유형의 이진 정보를 나타내기 위해 사용됩니다. 경우에 따라 이미 이러한 이진 feature가 숫자 형태로 제공되어 있을 수 있고, 다른 경우에는 숫자가 아닌 값을 갖는 경우도 있습니다. 모델 훈련에 비숫자적인 이진 feature를 사용하려면 이를 숫자 값으로 매핑하면 됩니다.\n\nIndicator feature의 일반적인 발생 및 사용을 넘어서, 우리는 비숫자 데이터 포인트 간의 비교를 나타내는 도구로서 indicator encoding을 활용할 수 있습니다. 이 특성은 비숫자 특성의 변화를 측정하는 방법을 만드는 데 특히 강력합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시:\n\n- 최근 로그인 이벤트 중 검증 실패: 최근 실패한 로그인 이벤트는 사기 거래 위험을 나타낼 수 있습니다. 이 경우, 이 기능에 대한 raw data는 'Yes' 또는 'No' 값을 가질 수 있습니다. 여기서 해야 할 일은 이러한 값을 1 또는 0으로 매핑하는 것뿐입니다.\n- 최근 거래 이전의 국가 위치 변경: 국가 위치 변경은 신용카드가 compromise되었을 수 있음을 나타낼 수 있습니다. 이 경우, '국가 위치' 라는 숫자가 아닌 기능에서 국가 변경 정보를 캡처하는 지표 기능을 생성합니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_4.png)\n\n## 5. One-Hot Encoding\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기술은 우리의 특성 데이터가 범주형 형식인 경우에 적용할 수 있습니다. 숫자 또는 숫자가 아닌 형식으로서 자료가 되는 자료를 말합니다. 숫자-범주형 형식은 비연속적이거나 측정되지 않는 데이터, 예를 들어 지리적 지역 코드, 상점 ID 등과 같은 데이터를 포함하는 숫자 데이터를 참조합니다. 원핫 인코딩 기술은 이러한 특성을 기곽 학습 모델에 사용할 수 있는 지표 특성 세트로 변환할 수 있습니다. 범주형 특성에 원핫 인코딩을 적용하면 해당 범주형 변수의 모든 범주마다 하나의 새로운 이진 특성을 생성합니다. 새로운 특성의 수가 범주의 수가 증가함에 따라 증가하기 때문에 이 기술은 특히 범주의 수가 적은 특성에 적합합니다. 특히 데이터셋이 작은 경우 이 기술을 적용하라는 표준 기준 중 하나는 범주당 최소 열 개의 레코드가 있을 때 이 기술을 적용하는 것을 제안합니다.\n\n예시:\n\n- 거래 구매 범주: 특정 유형의 구매 범주는 사기 위험이 높을 수 있습니다. 구매 범주 이름은 텍스트 데이터이기 때문에 이 기능을 숫자형 지표 특성 세트로 변환할 수 있습니다. 만약 열 가지 다른 구매 범주 이름이 있다면, 원핫 인코딩을 사용하면 각 구매 범주 이름마다 하나의 새로운 지표 특성이 생상됩니다.\n- 기기 유형: 온라인 거래는 iPhone, Android 폰, Windows PC, Mac과 같은 여러 가지 기기를 통해 이루어질 수 있습니다. 이러한 기기 중 일부는 악성 소프트웨어에 민감하거나 사기꾼에게 쉽게 접근 가능하며, 따라서 사기 위험이 높을 수 있습니다. 기기 유형 정보를 숫자 형태로 포함시키기 위해, 기기 유형에 원핫 인코딩을 적용하여 각 기기 유형에 대한 새로운 지표 특성을 생성할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 6. Target Encoding\n\n이 기술은 일종의 피처에 적용되며 이를 원-핫 인코딩할 수도 있지만 원-핫 인코딩보다 장단점이 있습니다. 카테고리의 수가 많을 때(고 카디널리티), 원-핫 인코딩을 사용하면 원하지 않게 피처의 수가 많아져 모델 과적합으로 이어질 수 있습니다. 타겟 인코딩은 이런 경우에 효과적인 기술일 수 있으며, 지도 학습 문제에 사용할 수 있습니다. 이 기술은 각 카테고리 값을 해당 카테고리의 타겟값의 예상 값으로 매핑하는 기법입니다. 연속형 타겟이 있는 회귀 문제를 다룰 때, 이 계산은 카테고리를 해당 카테고리의 평균 타겟값으로 매핑합니다. 이진 타겟을 가진 분류 문제의 경우, 타겟 인코딩은 해당 카테고리의 긍정사건 확률에 매핑합니다. 원-핫 인코딩과 달리, 이 기술은 피처의 수를 증가시키지 않는 장점이 있습니다. 이 기술의 단점은 지도 학습 문제에만 적용할 수 있다는 것입니다. 또한 이 기술을 적용하면 특정 카테고리의 관측치 수가 적은 경우에 모델이 과적합되기 쉬울 수 있습니다.\n\n예시:\n\n- 가맹점 이름: 특정 가맹점에 대한 거래가 사기 활동을 나타낼 수 있습니다. 수천 개의 이러한 가맹점이 있을 수 있으며, 각각이 다른 사기 거래 위험을 가질 수 있습니다. 가맹점 이름을 포함한 피처에 원-핫 인코딩을 적용하면 원하지 않게 수천 개의 새로운 피처가 도입될 수 있는데, 이는 바람직하지 않습니다. 이런 경우에 타겟 인코딩을 통해 가맹점의 사기 위험 정보를 캡쳐할 수 있습니다.\n- 거래 우편번호: 가맹점과 마찬가지로, 서로 다른 우편번호로 이루어진 거래는 서로 다른 사기 위험 수준을 나타낼 수 있습니다. 우편번호가 숫자 값이지만 연속형 측정 변수는 아니며 그대로 모델에 사용해서는 안됩니다. 대신, 우편번호와 관련된 사기 위험 정보를 포함할 수 있도록 타겟 인코딩과 같은 기술을 적용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_6.png\" /\u003e\n\n새로운 피처들을 raw 데이터로부터 만들었다면, 다음 단계는 최적의 모델 성능을 위해 이를 처리하는 것입니다. 이는 다음 섹션에서 논의될 피처 처리를 통해 수행됩니다.\n\n# 피처 처리\n\n피처 처리는 머신러닝 모델이 의도한 대로 데이터에 적합하게 만들기 위한 일련의 데이터 처리 단계를 의미합니다. 일부 피처 처리 단계는 특정 머신러닝 알고리즘을 사용할 때 필수적이지만, 다른 단계들은 피처와 고려 중인 머신러닝 알고리즘 간에 좋은 작동 화학 반응을 일으키도록 하는 역할을 합니다. 이 섹션에서는 몇 가지 일반적인 피처 처리 단계와 그 필요성에 대해 논의하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 1. 이상값 처리\n\n몇몇 머신러닝 알고리즘, 특히 회귀 모델과 같은 모수적 알고리즘들은 이상값에 심각한 영향을 받을 수 있습니다. 이러한 머신러닝 알고리즘들은 이상값을 수용하려고 하다보니 모델 파라미터에 심각한 영향을 미치고 전반적인 성능을 저하시킵니다. 이상값을 처리하기 위해서 먼저 이들을 식별해야 합니다. 특정 기능의 이상값을 식별하기 위해 평균에 세 배의 표준 편차를 더한 절댓값이나 가장 가까운 박스(사분위 값과 상위에서 1.5배의 사분위 범위 값) 값을 초과하는 규칙을 적용함으로써 이상값을 감지할 수 있습니다. 특정 기능에서 이상값을 식별하면 아래 기술 중 하나를 사용하여 처리할 수 있습니다:\n\n- 삭제: 하나 이상의 이상값이 있는 관측치를 삭제할 수 있습니다. 그러나 데이터에 다양한 기능에서 너무 많은 이상값이 포함되어 있다면 많은 관측치를 잃을 수 있습니다.\n- 대체: 주어진 기능의 평균, 중앙값 및 최빈값과 같은 평균값으로 이상값을 대체할 수 있습니다.\n- 기능 변환 또는 표준화: 로그 변환 또는 기능 표준화(척도 설명에 설명되어 있음)를 사용하여 이상값의 크기를 줄일 수 있습니다.\n- 상한과 하한 설정: 일정 값 이상의 이상값을 해당 값으로 대체할 수 있으며, 예를 들어 99번째 백분위의 모든 값보다 큰 값을 99번째 백분위 값으로 대체하고 1번째 백분위의 모든 값보다 작은 값을 1번째 백분위 값으로 대체할 수 있습니다.\n\n![image](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![2024-05-20-FeatureEngineeringforMachineLearning_8](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_8.png)\n\n다변량 이상치 (여러 특성에 대한 이상치)를 감지하는 기술이 있지만, 이는 보통 복잡하고 머신 러닝 모델 훈련 측면에서 크게 가치를 더하지 않습니다. 또한 서포트 벡터 머신 및 의사 결정 트리, 랜덤 포레스트, XGBoost와 같은 트리 기반 알고리즘과 같은 대부분의 비모수형 머신 러닝 모델과 함께 작업할 때 이상치는 걱정거리가 되지 않습니다.\n\n## 2. 결측값 처리\n\n실제 데이터셋에서 결측 데이터는 매우 흔합니다. XGBoost와 같은 몇 가지 제외하고 대부분의 전통적인 머신 러닝 알고리즘은 훈련 데이터셋에서 결측값을 허용하지 않습니다. 그러므로 결측값을 해결하는 것은 머신 러닝 모델링에서의 루틴 작업 중 하나입니다. 결측값을 처리하는 여러 기술이 있지만, 어떤 기술을 실행하기 전에 결측 데이터의 원인을 이해하거나 적어도 데이터가 무작위로 누락되었는지를 알아야 합니다. 데이터가 무작위로 누락되지 않은 경우, 특정 부분집단이 결측 데이터를 더 자주 가지고 있는 경우가 많아 그러한 값에 대한 대치가 어려울 수 있습니다. 데이터가 무작위로 누락된 경우, 아래에서 설명한 몇 가지 일반적인 처리 기술을 사용할 수 있습니다. 이들은 각각 장단점을 가지고 있으며, 어떤 방법이 사용 사례에 가장 적합한지 결정은 우리에게 달려 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 삭제: 최소한 하나의 결측값이 있는 관측치를 삭제할 수 있습니다. 그러나 다양한 특성의 결측값이 많을 경우, 많은 관측치를 잃을 수도 있습니다.\n- 삭제: 특정 특성에 결측값이 많은 경우 해당 특성을 삭제할 수 있습니다.\n- 평균값으로 대체: 평균, 중앙값, 최빈값과 같은 평균값을 사용하여 결측값을 대체할 수 있습니다. 이 방법은 간단하지만 모든 유형의 관측치에 대해 좋은 추정을 제공하지 않을 수 있습니다. 예를 들어, 고 위험 사기 거래의 경우 낮은 위험 사기 거래의 평균 거래 금액과 다를 수 있으며, 높은 위험 사기 거래 금액의 평균값을 결측값으로 사용하는 것이 적절하지 않을 수 있습니다.\n- 최대우도, 다중 대체, K 최근접 이웃: 다른 특성과의 관계를 고려하는 복잡한 방법으로 전체 평균보다 더 정확한 추정을 제공할 수 있습니다. 그러나 이러한 방법을 구현하기 위해서는 추가적인 모델링이나 알고리즘 구현이 필요합니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_9.png)\n\n## 3. 스케일링\n\n머신러닝 모델에서 사용하는 특성들은 종종 서로 다른 범위를 가집니다. 스케일링 없이 사용하면 절대값이 큰 특성이 예측 결과를 지배할 수 있습니다. 그 대신, 각 특성이 예측 결과에 공평하게 기여할 수 있도록 하기 위해 모든 특성을 동일한 척도로 조정해야 합니다. 가장 일반적인 스케일링 기술은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 정규화: 이 스케일링 기술은 특징 값들을 0과 1 사이로 제한합니다. 정규화를 적용하기 위해 우리는 특징의 최소값을 뺀 다음 그 특징의 범위(최솟값과 최댓값의 차이)로 나눕니다. 정규화는 몇 가지 특징이 급격하게 치우친 경우나 몇 개의 극단값을 가지고 있는 경우에는 좋은 기술이 아닐 수 있습니다.\n- 표준화: 이 기술은 특징 데이터 분포를 표준 정규 분포로 변환합니다. 이 기술을 적용하는 방법은 평균을 빼고 표준 편차로 나누는 것입니다. 이 기술은 특징이 급격한 치우침이나 몇 개의 극단값을 가진 경우에 일반적으로 선호됩니다.\n\n결정 트리, 랜덤 포레스트, XGBoost 등과 같은 트리 기반 알고리즘은 조정되지 않은 데이터로 작업할 수 있으며 이러한 알고리즘을 사용할 때 스케일링이 필요하지 않습니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_10.png)\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4. 차원 축소\n\n오늘날, 우리는 거대한 데이터를 보유하고 있으며 모델을 학습시키기 위해 방대한 특성들의 모음을 구축할 수 있습니다. 대부분의 알고리즘에 대해, 더 많은 특성을 가지는 것이 모델 성능을 향상시킬 수 있는 더 많은 옵션을 제공하기 때문에 좋습니다. 그러나 이것이 모든 알고리즘에 대해 참이라는 것은 아닙니다. 거리 측정에 기반한 알고리즘들은 차원의 저주에 영향을 받습니다 - 특성의 수가 상당히 증가하면 두 개의 관측치 사이의 거리 값이 무의미해집니다. 따라서 거리 측정에 의존하는 알고리즘을 사용할 때는 많은 수의 특성을 사용하지 않도록 주의해야 합니다. 만약 데이터셋이 많은 특성을 가지고 있고 어떤 특성을 유지해야 할지 알 수 없다면 주성분 분석(PCA)과 같은 기법을 사용할 수 있습니다. PCA는 기존 특성 집합을 새로운 특성 집합으로 변환합니다. 고유값이 가장 높은 새로운 특성이 기존 특성에서 대부분의 정보를 캡처하도록 새로운 특성을 생성합니다. 그러면 상위 몇 개의 새로운 특성만 유지하고 나머지를 버릴 수 있습니다.\n\n지도 학습 문제에서 특성의 수를 줄이기 위해 연관 분석과 특성 선택 알고리즘과 같은 다른 통계 기법을 사용할 수 있습니다. 그러나 이러한 방법들은 일반적으로 PCA와 동일한 수의 특성으로 동일한 수준의 정보를 포착하지는 못합니다.\n\n![Image](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_12.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 5. 정규 분포로 변환하기\n\n이번 단계는 특이한 경우입니다. 이는 대상에만 적용되며 피처에는 적용되지 않습니다. 또한, 대부분의 머신러닝 알고리즘은 대상의 분포에 제약이 없지만, 선형 회귀와 같은 특정 알고리즘은 대상이 정규 분포를 가져야 합니다. 선형 회귀는 오류 값이 대칭이고 모든 데이터 포인트 주변에 집중되어 있다고 가정하며(마치 정규 분포의 형태처럼), 정규 분포로 분포된 대상 변수는 이 가정이 충족됨을 보장합니다. 대상의 분포를 이해하기 위해 히스토그램을 그려볼 수 있습니다. 샤피로-윌크 검정과 같은 통계 검정은 이 가설을 테스트하여 정규성을 알려줍니다. 대상이 정규 분포가 아닌 경우, 대상 분포를 정규화시키는데 어떤 변환을 시도할 수 있습니다. 로그 변환, 제곱 변환, 제곱근 변환 등 여러 변환을 해보고 대상 분포를 정규화하는데 가장 적합한 변환을 선택할 수 있습니다. 또한 박스-콕스 변환을 사용하여 여러 매개변수 값을 시도해볼 수 있으며, 대상 분포를 정규화시키는데 가장 적합한 값을 선택할 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_13.png)\n\n참고: 피처 전처리 단계를 모든 순서로 구현할 수 있지만, 그 적용 순서를 신중히 고려해야 합니다. 예를 들어, 평균값 대체를 사용한 누락 값 처리는 아웃라이어 탐지 전이나 후에 구현할 수 있습니다. 그러나 대체에 사용하는 평균값은 누락된 값을 아웃라이어 처리 전이나 후에 다르게 처리할 수 있습니다. 이 기사에서 제시된 피처 처리 순서는 성공적인 후속 처리 단계에 미치는 영향의 순서대로 문제를 해결합니다. 따라서 이 순서를 따르면 대부분의 문제를 해결하는데 효과적일 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n소개에서 언급한 대로, 특성 엔지니어링은 모델의 성능을 탁월하게 제어할 수 있게 해주는 기계 학습의 한 측면입니다. 특성 엔지니어링을 최대한 활용하기 위해, 이 기사에서 우리는 새로운 특성을 만들고 기계 학습 모델과 최적으로 작동하도록 이를 처리하는 다양한 기술을 배웠습니다. 이 기사에서 선택한 특성 엔지니어링 원칙과 기술이 무엇이든 사용하더라도 중요한 메시지는 기계 학습이 패턴을 파악하도록 알고리즘에 요청하는 것이 아니다. 그것은 우리가 알고리즘이 필요로 하는 데이터 유형을 제공하여 효과적으로 작동하도록 하는 것입니다.\n\n이미지는 별도로 언급되지 않는 한 모두 저자에 의해 제작되었습니다.","ogImage":{"url":"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_0.png"},"coverImage":"/assets/img/2024-05-20-FeatureEngineeringforMachineLearning_0.png","tag":["Tech"],"readingTime":12}],"page":"20","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"20"},"buildId":"PgdIX9e0tvkvkdAmDT6qR","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>