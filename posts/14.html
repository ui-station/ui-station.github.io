<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/14" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/14" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_buildManifest.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="데이터 엔지니어링 디자인 패턴" href="/post/2024-05-23-DataEngineeringDesignPatterns"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 엔지니어링 디자인 패턴" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DataEngineeringDesignPatterns_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 엔지니어링 디자인 패턴" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터 엔지니어링 디자인 패턴</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터브릭의 DBRX를 사용하면 실시간으로 학습할 수 있어요, 미세 조정 필요 없어요" href="/post/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터브릭의 DBRX를 사용하면 실시간으로 학습할 수 있어요, 미세 조정 필요 없어요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터브릭의 DBRX를 사용하면 실시간으로 학습할 수 있어요, 미세 조정 필요 없어요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터브릭의 DBRX를 사용하면 실시간으로 학습할 수 있어요, 미세 조정 필요 없어요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="넷플릭스 데이터 쇄도를 탐색하며 효과적인 데이터 관리의 필수성" href="/post/2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="넷플릭스 데이터 쇄도를 탐색하며 효과적인 데이터 관리의 필수성" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="넷플릭스 데이터 쇄도를 탐색하며 효과적인 데이터 관리의 필수성" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">넷플릭스 데이터 쇄도를 탐색하며 효과적인 데이터 관리의 필수성</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 안전 보장 암호화되지 않은 RDS 데이터베이스를 암호화된 데이터베이스로 이전하기" href="/post/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 안전 보장 암호화되지 않은 RDS 데이터베이스를 암호화된 데이터베이스로 이전하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 안전 보장 암호화되지 않은 RDS 데이터베이스를 암호화된 데이터베이스로 이전하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">데이터 안전 보장 암호화되지 않은 RDS 데이터베이스를 암호화된 데이터베이스로 이전하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="REST API를 API Gateway, Lambda, DynamoDB, Cognito를 사용하여 배포하는 단계별 가이드  Terraform" href="/post/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="REST API를 API Gateway, Lambda, DynamoDB, Cognito를 사용하여 배포하는 단계별 가이드  Terraform" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="REST API를 API Gateway, Lambda, DynamoDB, Cognito를 사용하여 배포하는 단계별 가이드  Terraform" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">REST API를 API Gateway, Lambda, DynamoDB, Cognito를 사용하여 배포하는 단계별 가이드  Terraform</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">31<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Amazon Redshift의 디자인을 이해하는 데 다시 8시간을 보냈어요 내가 발견한 것은 여기 있어요" href="/post/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Amazon Redshift의 디자인을 이해하는 데 다시 8시간을 보냈어요 내가 발견한 것은 여기 있어요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Amazon Redshift의 디자인을 이해하는 데 다시 8시간을 보냈어요 내가 발견한 것은 여기 있어요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Amazon Redshift의 디자인을 이해하는 데 다시 8시간을 보냈어요 내가 발견한 것은 여기 있어요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">19<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="유튜브에서 배우는 LLMs 사용하기" href="/post/2024-05-23-UsingLLMstoLearnFromYouTube"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="유튜브에서 배우는 LLMs 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="유튜브에서 배우는 LLMs 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">유튜브에서 배우는 LLMs 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="접근성 있는 비디오 게임 디자인하기" href="/post/2024-05-23-Designingaccessiblevideogames"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="접근성 있는 비디오 게임 디자인하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Designingaccessiblevideogames_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="접근성 있는 비디오 게임 디자인하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">접근성 있는 비디오 게임 디자인하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="내가 마케터가 되고 싶지 않았어요 게임" href="/post/2024-05-23-IDidntWanttoBeaGameMarketer"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="내가 마케터가 되고 싶지 않았어요 게임" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-IDidntWanttoBeaGameMarketer_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="내가 마케터가 되고 싶지 않았어요 게임" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">내가 마케터가 되고 싶지 않았어요 게임</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Roomsxyz에서의 프로그래밍 파트 1" href="/post/2024-05-23-ProgramminginRoomsxyzPart1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Roomsxyz에서의 프로그래밍 파트 1" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Roomsxyz에서의 프로그래밍 파트 1" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Roomsxyz에서의 프로그래밍 파트 1</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link posts_-active__YVJEi" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"데이터 엔지니어링 디자인 패턴","description":"","date":"2024-05-23 14:04","slug":"2024-05-23-DataEngineeringDesignPatterns","content":"\n\n디자인 패턴은 소프트웨어 엔지니어들만을 위한 것은 아닙니다. 최신 데이터 솔루션을 구축하는 데 도움이 되는 인기있는 데이터 엔지니어링 디자인 패턴을 알아봅시다.\n\n![이미지](/assets/img/2024-05-23-DataEngineeringDesignPatterns_0.png)\n\nELT 패턴: 추출, 로드, 변환\n\n이는 RDBMS 세계에서 인기있던 ETL 패턴의 후속입니다. 데이터 엔지니어들이 다양한 소스(RDBMS, API 또는 스크래핑)에서 데이터를 추출하고, S3, ADLS Gen 2, 또는 GCS와 같은 객체 스토어에 로드한 후 Databricks와 같은 현대적인 도구를 사용하여 효율적으로 변환하는 인기있는 공통 패턴입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Lakehouse Pattern](/assets/img/2024-05-23-DataEngineeringDesignPatterns_1.png)\n\nDatabricks은 Lakehouse 아키텍처의 선두주자입니다. 이는 데이터 레이크(Data Lake)와 데이터 웨어하우스(Datawarehouse)를 통합합니다. 원시 또는 가공된, 구조화된 또는 반구조화된 데이터가 모두 하나의 환경 안에 모두 사용 가능하며 하나의 플랫폼(Databricks)에서 액세스할 수 있습니다.\n\n![Lakehouse Pattern](/assets/img/2024-05-23-DataEngineeringDesignPatterns_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n중개 아키텍처 패턴:\n\n메달리온 아키텍처 패턴은 주로 Databricks와 함께 사용되며 이제는 사실상의 표준이 되었습니다. 데이터 처리를 위해 원본 데이터인 청동, 정리 및 풍부화된 데이터인 은, 그리고 비즈니스 수준의 집계한 데이터인 금 레이어로 이루어져 있습니다.\n\nDeltaLake 아키텍처 패턴:\n\nDelta Lake은 초기에 Databricks에서 개발된 오픈 소스 프로젝트입니다. 이 프로젝트는 데이터 호수에 안정성을 제공합니다. Deltalake는 ACID 트랜잭션, 타임 트래벌, z-order, CDC, 스키마 진화 및 기타 최적화로 데이터 호수를 개선합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nKappa Architecture Pattern:\n\nKappa Architecture에서는 모든 데이터가 스트림으로 처리됩니다. 이는 기존에 배치 처리로 다뤄졌을 것들을 연속적인 데이터 스트림으로 처리하는 것을 의미합니다. 시스템은 데이터가 도착하는 즉시 실시간으로 처리하며 별도의 배치로 처리하지 않습니다. Kappa Architecture는 실시간 처리에 최적화되어 있지만, \"배치\" 데이터로 간주될 수 있는 대규모의 과거 데이터를 스트림으로 재생하여 처리할 수 있습니다. Databricks Autoloader는 Kappa Architecture를 구현하는 데 가장 적합합니다.\n\nServerless Architecture Pattern:\n\n데이터 엔지니어링에서 서버리스는 클라우드 지역/IP 제약 사항이나 기타 기본 인프라 제약 조건에 대해 걱정하지 않고 데이터 파이프라인을 구축할 수 있습니다. 특히 변수 사용 패턴을 갖는 워크로드에 대한 즉시 클러스터 가용성과 비용 효율적인 스케일링을 위해 유용합니다. 많은 클라우드 제공업체가 이를 제공하고 있습니다. Databricks SQL은 Serverless를 제공하며, SQL 웨어하우스를 3초 미만의 시간 안에 론칭할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMLFlow 아키텍처 패턴:\n\nMLflow는 Databricks가 개발한 오픈 소스 프로젝트로, 실험, 재현성, 모델 배포 및 모델 제공을 포함한 기계 학습 라이프사이클을 관리하는 데 사용됩니다.\n\n이러한 패턴은 견고하고 확장 가능한 데이터 시스템을 설계하는 데 중요합니다. Databricks를 이용하면 이러한 패턴을 더욱 간편하게 구현할 수 있으며 효율적인 데이터 처리 및 분석을 위한 통합 도구를 제공합니다.\n\n좋아하는 패턴이 빠졌나요? 댓글 섹션에서 알려주세요. 흥미로운 내용이라고 생각되면 반가워 하지 마세요.","ogImage":{"url":"/assets/img/2024-05-23-DataEngineeringDesignPatterns_0.png"},"coverImage":"/assets/img/2024-05-23-DataEngineeringDesignPatterns_0.png","tag":["Tech"],"readingTime":3},{"title":"데이터브릭의 DBRX를 사용하면 실시간으로 학습할 수 있어요, 미세 조정 필요 없어요","description":"","date":"2024-05-23 14:02","slug":"2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning","content":"\n![DBRX](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_0.png)\n\nDBRX이란 무엇인가요?\n\nDBRX는 Databricks의 최신 언어 모델 중 하나입니다. 언어 모델이란 충분한 예제를 학습하여 인간의 언어나 다른 유형의 복잡한 데이터를 인식하고 해석할 수 있는 컴퓨터 프로그램입니다. 많은 언어 모델들은 수십억 또는 수백만 기가바이트에 달하는 인터넷에서 수집한 데이터를 기반으로 학습됩니다.\n\nDBRX는 Databricks에서 개발한 오픈, 일반 목적의 언어 모델입니다. 다양한 표준 벤치마크를 통해 DBRX는 이미 알려진 오픈 언어 모델들에 대한 최신 결과를 보여주고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDBRX는 고밀도 전문가 혼합(MoE) 아키텍처 덕분에 오픈 모델 중 효율성 면에서 최첨단 기술을 선도합니다. LLaMA2-70B보다 추론이 최대 2배 빠르고, 전체 및 활성 매개변수 개수 측면에서 Grok-1의 약 40% 크기입니다.\n\nDBRX는 총 1320억 개의 매개변수 중 360억 개가 어떤 입력에 대해서도 활성인 미세 구조 MoE 아키텍처를 사용하는 대형 언어 모델(LLM)입니다. 디코더 전용이며, 12조 개의 텍스트 및 코드 데이터 토큰을 포함하는 대규모 데이터 세트에서 다음 토큰 예측을 사용하여 교육되었습니다. Mixtral 및 Grok-1과 같은 유사한 모델과 달리, DBRX는 세부 접근 방식을 채용하며, 16개 전문가를 활용하고 그 중 4개를 선택합니다. 반면 다른 모델들은 8개 전문가를 가지고 2개를 선택합니다.\n\n전통적인 언어 모델은 최근 이벤트나 트레이닝 데이터 외의 정보를 예측하는 능력에 제한이 있어서 현재 주제에 대한 쿼리에 대해 효과적이지 않을 수 있습니다. 이 제한으로 인해 언어 모델의 생성 능력을 보완하기 위해 검색 증강 생성(RAG)이 필요해졌습니다. 외부 소스를 통합함으로써 RAG는 특히 모델 훈련 데이터를 넘어서는 최근 이벤트나 주제에 대한 질의에 대한 정확도와 시기적절성을 향상시킵니다.\n\nDBRX를 선택하는 이유는 무엇일까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 오픈 소스 모델 우위: 데이터브릭스의 DBRX 모델은 LLaMA2-70B, Mixtral 및 Grok-1과 같은 주요 오픈 소스 모델과 비교하여 우수한 성능을 보여줍니다. 이는 데이터브릭스가 언어 이해, 프로그래밍, 수학 및 논리와 같은 여러 영역에서 오픈 소스 모델 품질 향상에 기여하겠다는 의지를 나타냅니다. 이는 데이터브릭스가 지원하기를 자랑스럽게 생각하는 트렌드입니다.\n\n![이미지 1](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_1.png)\n\n- 전용 모델보다 우위: DBRX는 다양한 벤치마크에서 GPT-3.5를 능가하여, 데이터브릭스의 다양한 고객 기반 중에서 전용 모델 대신 오픈 소스 모델을 선호함에 대한 주목할만한 변화와 조화를 이룹니다. 데이터브릭스는 고객이 오픈 소스 모델을 사용자 지정하여 특정 요구 사항에 맞게 맞춤화하여 더 나은 품질과 속도를 달성할 수 있다는 능력을 강조합니다. 이는 기업과 조직에서 오픈 소스 모델의 도입을 가속화시킬 수 있는 가능성을 제시합니다.\n\n![이미지 2](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- DBRX의 MoE 아키텍처로 향상된 효율성과 확장성: MegaBlocks 연구 및 오픈소스 프로젝트에서 개발된 DBRX의 Mixture-of-Experts(MoE) 모델 아키텍처는 초당 처리된 토큰 수에 대해 높은 속도를 제공합니다. Databricks는 이 혁신이 미래 오픈소스 모델이 MoE 구조를 채택하도록 이끌어내며, 대규모 모델의 훈련을 유지하면서 빠른 처리량을 유지할 수 있도록 할 것으로 기대합니다. DBRX는 총 1320억 개의 매개변수 중 언제든지 360억 개의 매개변수만을 활용하며, 속도와 성능 사이의 균형을 제공하여 사용자에게 효율적인 솔루션을 제공합니다.\n\n![이미지](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_3.png)\n\n언어 모델을 위한 지식 창고!!!\n\nLLM을 위한 지식 창고는 외부 소스의 실시간 정보를 추가함으로써 언어 모델을 더 스마트하게 만듭니다. 이는 다양한 주제에 걸쳐보다 정확하고 의미 있는 응답을 제공하는 데 도움을 줍니다. RAG, 또는 검색 증강 생성,은 이의 주요 구성 요소로서 정확한 정보를 찾아 활용하여 응답을 개선하는 데 도움을 줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![그림](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_4.png)\n\nRAG(검색 보강 생성)이 무엇인가요?\n\n전통적인 언어 모델은 최근 사건이나 학습 데이터 외의 정보를 예측하는 능력이 제한되어 있어서 현재 주제에 대한 질의에 덜 효과적입니다. 이 한계로 인해 검색 보강 생성이 필요해졌습니다.\n\nRAG 또는 검색 보강 생성은 언어를 이해하고 생성하는 새로운 방법입니다. 이 방법은 두 가지 종류의 모델을 결합합니다. 먼저, 관련 정보를 검색하고, 그 정보를 기반으로 텍스트를 생성합니다. 이 두 가지를 함께 사용함으로써 RAG는 놀라운 성과를 거두었습니다. 각 모델의 강점이 서로의 약점을 보완하기 때문에, RAG는 자연어 처리의 혁신적인 방법으로 각광을 받고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 Markdown 형식으로 표를 변환한 내용입니다.\n\n\n![이미지](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_5.png)\n\n벡터 저장소(Vector Store)는 무엇인가요?\n\n벡터 저장소와 벡터 검색은 현대 정보 검색 시스템의 필수 구성 요소입니다.\n\n- **벡터 저장소(Vector Store)**: 각 정보를 벡터로 나타내어 데이터를 저장하는 데이터베이스와 같은 역할입니다. 이러한 방식을 사용하면 각 정보를 다차원 공간에서 수학적으로 표현한 벡터로 저장할 수 있습니다. 이는 기존 인덱싱 방법이 아닌 유사성 측정 기준에 따라 데이터를 효율적으로 저장하고 검색할 수 있도록 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_6.png)\n\n벡터 검색: 벡터 간 유사성을 비교하여 관련 정보를 찾는 과정입니다. 키워드 매칭이나 기타 전통적인 검색 기술 대신 벡터 검색은 벡터 저장소에서 유사한 벡터를 식별하여 정확한 쿼리 용어를 포함하지 않더라도 의미론적으로 관련된 결과를 반환합니다.\n\n![이미지](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_7.png)\n\nHands-on RAG 데모:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 Databricks를 플랫폼으로 선택한 이유는 DBRX라는 기본 모델과 엔드 투 엔드 기계 학습 및 딥 러닝 워크플로에 맞춘 도구 및 라이브러리들을 제공하기 때문입니다.\n\n코드 개요:\n\n- Databricks Foundational Models에서 Chat 모델(DBRX)과 임베딩 모델을 가져오기\n\n![image](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. Hugging Face에서 GPT Tokenizer를 가져오기\n\n![image](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_9.png)\n\n3. 챗 어시스턴트를 위한 클래스 생성: 이 클래스는 Tokenizer, Embedding, Docs 및 LLM을 입력으로 사용하여 클래스 객체를 인스턴스화합니다.\n\n- get_pdf_text(): 제공된 문서에서 텍스트를 추출합니다.\n- Chunk_return(): 텍스트를 입력으로 받아 토큰화하고 거대한 텍스트를 청크로 분할합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_10.png)\n\n- get_vector_text(): 청크를 삽입하고 FAISS 인덱스를 사용하여 내장된 콘텐츠를 색인화하여 Vector Library를 반환합니다.\n\n![image](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_11.png)\n\n- get_conve_chain(): 대화형 Q\u0026A 체인을 가져오는 메서드이며, DBRX의 프롬프트 템플릿 및 언어 모델과 함께 반환합니다.\n- query(): 이 메서드는 LLM 체인과 Vector Library를 호출하여 언어 모델 (DBRX)에 공급하는 데 사용됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시:\n\n- RAG에 대해 DBRX에 쿼리하는 방법\n\n![이미지](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_12.png)\n\n- 지식 창과 함께 DBRX에 쿼리하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![DBRX](/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_13.png)\n\n결론:\n\nDatabricks의 최고 수준 언어 모델인 DBRX는 언어 및 코드를 이해하는 데 뛰어나지만 최근 업데이트에 대한 처리가 약간 어려울 수 있습니다. 따라서 우리는 이를 지원하기 위해 검색 증강 생성(Retrieval-Augmented Generation, RAG) 기술을 사용합니다. 이 기술은 정보를 찾아 새로운 텍스트를 생성하는 방식을 결합하여 DBRX를 더욱 똑똑하게 만듭니다. Databricks에서 구현된 RAG 및 DBRX는 머신 러닝을 보다 쉽고 효과적으로 만들어줍니다.\n\n","ogImage":{"url":"/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_0.png"},"coverImage":"/assets/img/2024-05-23-DatabricksDBRXforreal-timewithoutfine-tuning_0.png","tag":["Tech"],"readingTime":6},{"title":"넷플릭스 데이터 쇄도를 탐색하며 효과적인 데이터 관리의 필수성","description":"","date":"2024-05-23 14:00","slug":"2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement","content":"\n\nBy Vinay Kawade, Obi-Ike Nwoke, Vlad Sydorenko, Priyesh Narayanan, Shannon Heh, Shunfei Chen\n\n소개\n\n오늘날, 디지털 시대에 데이터가 전례없는 속도로 생성되고 있습니다. 예를 들어, Netflix를 살펴보겠습니다. 세계 각지의 Netflix 스튜디오에서 매년 수백 PB의 에셋이 생성됩니다. 콘텐츠는 텍스트와 이미지 시퀀스부터 소스 인코딩용 큰 IMF¹ 파일에 이르기까지 다양합니다. 때로는 생성된 프록시와 중간 파일도 있습니다. 스튜디오로부터 흘러나오는 이 방대한 데이터 양은 실질적인 통찰을 얻기 위한 효율적인 데이터 관리 전략에 대한 중대한 필요성을 강조합니다. 주목할 점은 모든 콘텐츠의 상당 부분이 미사용 상태로 남아있는 것입니다.\n\n본 기사에서, 저희 미디어 인프라스트럭처 플랫폼 팀은 생산 데이터를 효과적으로 관리하기 위한 해결책인 Garbage Collector의 개발을 개요로 설명합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nThe Magnitude of Data Generation\n\n매주 전 세계의 수백 개의 Netflix 스튜디오에서 약 2 페타바이트의 데이터가 생산됩니다. 이는 텍스트, 이미지, 이미지 시퀀스, IMF 등 다양한 소스로부터 생성된 복합 데이터입니다. 이 규모의 데이터는 엄청납니다. 이 정보를 효과적으로 총정리하고 분석하는 것이 더 어려워지고 있습니다. 또한 이로 인해 저장 비용이 크게 증가했습니다. 우리는 역대 기록적인 저장 비용 증가률인 매년 50% 증가를 보고 있습니다. 동시에 내부 연구에 따르면 적어도 데이터의 40%가 사용되지 않고 낭비되고 있다고 합니다.\n\n[이미지]\n\n효과적인 데이터 관리의 필요성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터가 계속해서 증가함에 따라, 특히 스튜디오에서 수집된 데이터는 일반적으로 업로드 - 읽기 - 재업로드 - 미해당을 따르는 수명주기를 거칩니다. 효율적으로 관리하는 작업은 점점 중요성을 갖게 됩니다. Netflix에서는 미디어 인프라 및 저장 플랫폼 팀이 사용자 조치 또는 사전 구성된 수명 주기 정책에 따라 파일 객체를 모니터링하고 정리하는 확장 가능하고 비동기적인 Garbage Collector (GC)를 사용한 데이터 수명주기 관리 솔루션을 개발했습니다. GC는 팀의 Baggins 서비스의 구성 요소로 S3 위에 미디어 특정 사용 사례에 맞춘 내부 추상화 계층입니다.\n\n아키텍처\n\n상위 수준에서 수명주기 관리자를 설계하여 안전하게 삭제하거나 더 차가운 저장소로 이동할 수 있는 데이터를 수동으로 모니터링하고 제거합니다. Garbage Collection에 대해 \"표시 및 정리\"의 관점을 취합니다.\n\n먼저, 우리는 모든 바이트를 AWS의 Simple Storage Service (S3)에 저장합니다. 그러나, S3의 각 파일에 대해 Baggins에 각 파일의 일부 메타데이터를 유지합니다. 이 메타데이터는 카산드라 데이터베이스에 저장되며 파일의 메타해시 목록 체크섬인 SHA-1, MD5 및 전체 파일에 대한 XXHash, 클라이언트 측 암호화된 객체를 위한 암호화 키와 같은 여러 필드가 포함되어 있습니다. S3에서 이러한 파일과 상호 작용하는 수백 개의 내부 넷플릭스 응용 프로그램이 있으며, 종종 여러 프록시, 파생물, 클립 등을 생성합니다. 이러한 응용 프로그램에는 프로모 미디어 생성, 마케팅 통신, 콘텐츠 인텔리전스, 자산 관리 플랫폼 등의 워크플로우가 포함됩니다. 이러한 응용 프로그램은 불필요한 파일을 필요할 때마다 삭제하거나 객체의 TTL을 사전 구성하여 파일이 자동으로 생성된 이후 일정 간격마다 삭제할 수 있습니다. 이 기간은 7일, 15일, 30일, 60일 또는 180일로 설정할 수 있습니다. 삭제 API를 통해 데이터베이스에서 해당 객체를 소프트 삭제로 표시하고 S3에서 해당 객체에 대한 액세스를 중지합니다. 이 소프트 삭제는 99% 분위수에서 삭제 API의 초당 15밀리초 미만의 초저지연을 유지합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 언급한 것처럼, 우리는 얼마 지나지 않아 '하드 삭제' 문제에 직면하게 될 것입니다. 이것은 삭제된 파일과 관련된 모든 흔적이 우리 시스템에서 제거되어야 함을 의미합니다. 이는 S3에서 바이트를 정리하고, Elastic Search에서 수행된 모든 색인을 삭제하며, 마지막으로는 Cassandra DB에서 모든 메타데이터를 삭제하는 것을 포함합니다. 우리는 다음과 같은 요구 사항을 가지고 시작했습니다.\n\n- 삭제 API(소프트 삭제)를 낮은 대기 시간으로 유지합니다.\n- 24시간 내내 수동 정리를 수행합니다.\n- 온라인 데이터베이스에 영향을 미치기 시작하면 정리를 제한합니다.\n- 정리가 급격히 증가해도 쉽게 확장할 수 있습니다.\n- 매일 정리를 편리하게 시각화합니다.\n- 아카이빙과 같은 다른 데이터 최적화 작업을 실행하기 위한 일반적인 프레임워크를 구축합니다.\n\n시스템 하의 구조\n\n다음은 시스템의 고수준 아키텍처입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement_1.png\" /\u003e\n\n클라이언트 관점에서는 ~15밀리초의 대기 시간을 소비하는 삭제 API를 간단히 호출합니다. 그러나 이후에는 이 객체 및 모든 메타데이터를 적절하게 정리하고 모든 위치에서 제대로 정리하는 일이 많이 발생합니다. 이 다이어그램은 처음에 약간 복잡해 보일 수 있지만, 화살표를 추적하면 이해가 쉬워지고 전체 그림이 명확해집니다. 위의 주기는 매일 수행되며, 수동 및 자동화된 방식으로 작동하여 그 날과 지금까지 누적된 삭제 대상 데이터와 백로그를 정리합니다.\n\n- 객체 키 가져오기: 모든 S3 객체는 Cassandra 데이터베이스에 해당 레코드가 있습니다. Cassandra 메타데이터 테이블의 항목들은 주요 참조 지점으로 기능합니다. 대응하는 행에 삭제 표시자를 추가하여 해당 행의 객체 키를 소프트 삭제하도록 표시합니다. 동일한 데이터베이스에는 버킷 수준 구성 정보를 보유하는 테이블도 있으며, 버킷 수준 사전 구성 TTL과 같은 정보를 포함합니다. 그러나 Cassandra는 파티션 키를 제공하지 않으면 TTL이 지정되거나 소프트로 삭제된 행을 필터링하는 것을 허용하지 않습니다. 또한, 메타데이터는 여러 테이블에 분산되어 있으며 정규화가 필요합니다. 여기서 Casspactor와 Apache Iceberg가 필요합니다.\n- Casspactor: 이는 Netflix의 내부 도구로, Cassandra 테이블을 Iceberg로 내보내는 데 사용됩니다. Casspactor는 Cassandra의 백업 복사본을 기반으로 작동하며 온라인 데이터베이스에 대한 지연시간을 발생시키지 않습니다. Iceberg는 Netflix에서 만들어진 오픈 소스 데이터 웨어하우스 솔루션으로, 구조화된/구조화되지 않은 데이터에 대한 SQL과 유사한 액세스를 제공합니다. TTL이 지정된/소프트 삭제된 행을 얻기 위해 Cassandra를 쿼리하는 대신 Iceberg의 복사된 행을 대상으로 쿼리할 수 있게 되었습니다.\n- 우리는 Netflix의 Workflow Orchestration 프레임워크 Maestro를 사용하여 매일 Iceberg를 호출하여 그 날 정리 작업 가능한 키를 필터링하는 일일 워크플로우를 설정합니다. 이 흐름은 버킷 수준 TTL 구성 및 객체 수준 삭제 표시자를 고려합니다.\n- Maestro 워크플로우는 다른 임시 Iceberg 테이블에 결과를 집계하여 이후 작업의 소스로 사용합니다.\n- 그 날 삭제해야 할 모든 관심 있는 행이 준비된 후, 우리는 데이터 이동 및 처리를 위한 홈그로운 솔루션을 사용하여 이를 모두 Kafka 큐로 내보냅니다. Iceberg 커넥터와 Kafka 싱크로 구성된 Data Mesh 파이프라인을 만들었습니다.\n- 우리는 이 Kafka 주제를 청취하는 몇 개의 Garbage Collector (GC) Worker를 실행하고 각 행에 대해 삭제 작업을 수행합니다. 이러한 작업은 수평 확장 가능하며 Kafka 파이프라인에서 발생하는 스파이크나 백로그에 기반해 자동으로 확장됩니다.\n- GC 워커는 객체의 완전한 정리를 처리합니다. 먼저 S3에서 모든 바이트를 삭제합니다. 이는 AWS S3에서 부과하는 5TB 최대 파일 크기 제한을 초과하는 경우 단일 파일 또는 다중 파일이 될 수 있습니다.\n- 그런 다음 우리는 로컬 Elastic Search에서 이 소프트 삭제된 파일에 대한 모든 참조를 정리합니다.\n- 마지막으로, 근무자들은 온라인 Cassandra 데이터베이스에서 이 항목을 제거하여 루프를 완료합니다. GC 워커의 자동 스케일링도 현재 부하 및 지연 시간에 대한 Cassandra 데이터베이스의 입력을 받습니다. 이러한 매개 변수들은 데이터 삭제 속도에 대한 제어된 속도 조절에 반영됩니다.\n- 마지막 단계는 매일 삭제하는 파일 수와 크기에 대한 세부 내용을 제공하는 대시보드를 강화합니다. 이를 위해 Apache Superset을 사용합니다. 이를 통해 AWS 송장과 미래 비용을 예측하는 데 사용할 수 있는 상당한 데이터를 확보할 수 있습니다.\n\n저장 통계\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이렇게 우리 대시보드가 어떻게 보이는지 알려드릴게요,\n\n![대시보드 스냅샷](/assets/img/2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement_2.png)\n\n![대시보드 스냅샷](/assets/img/2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement_3.png)\n\n필수 통찰력\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 데이터 정리 전략 수립을 우선시하세요. 데이터 정리 프로세스는 초기 설계의 중요한 부분이어야 합니다. 후속 고려 사항이 아닙니다. 시간이 흐를수록 데이터 정리는 적절히 관리되지 않으면 압도적인 작업으로 번질 수 있습니다.\n- 지출을 지속적으로 모니터링하고 기록하세요. 비용 없는 부분은 없습니다. 데이터의 각 바이트는 금전적 영향을 가지고 있습니다. 따라서 저장된 모든 데이터에 대한 포괄적인 계획이 필수적입니다. 이는 특정 기간 이후 데이터를 삭제하거나 사용되지 않을 때 더 비용 효율적인 저장 계층으로 이전하거나, 적어도 미래 참조 및 의사 결정을 위해 무기한 보유를 위한 사유를 유지하는 것을 포함할 수 있습니다.\n- 디자인은 다양한 작업과 환경에서 사용할 수 있는 유연성을 가져야 합니다. 활성 데이터부터 비활성 데이터 보관, 그리고 중간에 있는 모든 것까지 관리할 수 있어야 합니다.\n\n**결론**\n\n지수적인 데이터 증가 시대를 계속해서 탐색함에 따라 효과적인 데이터 관리의 필요성은 지나치게 강조될 수 없습니다. 데이터의 양을 다루는 것뿐만 아니라 품질과 관련성을 이해하는 것입니다. 포괄적인 데이터 관리 전략에 투자하는 기ꢣ치는 새로운 데이터 중심 환경에서 선도할 기업들이 될 것입니다.\n\n용어\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nIMF (Interoperable Master Format): 이것은 오디오와 비디오 마스터 파일의 디지털 전송과 저장에 사용되는 표준화된 형식입니다. 더 많은 정보를 원하시면 이 개요를 방문해보세요.\n\nMHL (미디어 해시 목록): 이것은 미디어 파일에서 체크섬을 보존하기 위해 전송 중에 그리고 정적 상태에서 저장하는 데 사용되는 표준입니다. 더 많은 정보를 원하시면 https://mediahashlist.org 를 방문해보세요.\n\nPB (페타바이트): 디지털 정보 저장의 단위로, 천 테라바이트 또는 백만 기가바이트에 해당합니다.\n\nTTL (Time-to-Live): 이 용어는 데이터가 폐기되기 전에 저장되는 기간을 의미합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n감사의 말씀\n\n마에스트로 팀, 캐스팩터 팀, 아이스버그 팀의 업무에 기여한 동료인 엠리 쇼, 앙쿠르 케트라팔, 에샤 팔타, 빅터 예레비치, 미나크시 진달, 페이지 후, 동동 우, 챈텔 양, 그레고리 알몬드, 아비 칸다사미, 그 외 훌륭한 동료들께 특별한 감사를 전합니다.","ogImage":{"url":"/assets/img/2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement_0.png"},"coverImage":"/assets/img/2024-05-23-NavigatingtheNetflixDataDelugeTheImperativeofEffectiveDataManagement_0.png","tag":["Tech"],"readingTime":7},{"title":"데이터 안전 보장 암호화되지 않은 RDS 데이터베이스를 암호화된 데이터베이스로 이전하기","description":"","date":"2024-05-23 13:59","slug":"2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne","content":"\n![태그](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_0.png)\n\nAmazon RDS DB 인스턴스에 대한 암호화는 생성 시에만 활성화할 수 있습니다. 기존 인스턴스를 암호화하려면 스냅샷을 생성한 후 해당 스냅샷의 암호화된 복사본을 만들어 새로운 암호화된 인스턴스로 복원합니다. 다운타임이 허용되는 경우에는 새 인스턴스로 애플리케이션을 전환하십시오. 최소한의 다운타임을 위해 AWS 데이터베이스 마이그레이션 서비스(AWS DMS)를 사용하여 데이터를 지속적으로 마이그레이션하고 복제함으로써 새로운 암호화된 데이터베이스로의 원활한 전환을 허용할 수 있습니다.\n\n## 1. 암호화 상태 확인\n\n첫 번째 단계는 현재 사용 중인 RDS 데이터베이스가 암호화되었는지 확인하는 것입니다. AWS 관리 콘솔에 로그인하고 RDS 서비스로 이동합니다. 대상 데이터베이스를 찾고 \"구성\" 탭을 클릭합니다. \"암호화\" 섹션을 찾아보십시오. 만약 \"활성화되지 않음\"으로 표시된다면 데이터베이스가 암호화되지 않았음을 의미합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_1.png)\n\n## 2. 스냅샷 생성\n\n암호화하려는 인스턴스의 DB 스냅샷을 만듭니다. 스냅샷을 만드는 데 걸리는 시간은 데이터베이스의 크기에 따라 다릅니다. 이제 왼쪽 메뉴에서 \"스냅샷\" 옵션으로 이동하고 \"스냅샷 촬영\"을 클릭합니다. 쉽죠?\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 스냅샷을 만들 데이터베이스를 선택해야 해요:\n\n![image](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_3.png)\n\n이를 \"UnencryptedSnapshot\"이라고 이름 짓을 수 있어요. 실제 데이터베이스의 사본이 될 거에요. 스냅샷이 생성되기를 기다려 주세요. 제 경우에는 약 2분이 걸렸어요.\n\n## 3. 사본 암호화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 생성한 DB 스냅샷을 선택해 주세요. 작업에서 '스냅샷 복사'를 선택하세요. 대상 AWS 지역 및 DB 스냗샷 사본의 이름을 해당 필드에 제공해 주세요. '암호화 사용' 확인란을 선택하세요. 마스터 키로는 DB 스냅샷 사본을 암호화하는 데 사용할 KMS 키 식별자를 지정하세요. '스냅샷 복사'를 선택하세요.\n\n그리고 보시다시피 제가 암호화를 활성화했으며 (기본) aws/rds를 AWS KMS 키로 선택했습니다.\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_4.png)\n\n두 번째 스냅샷이 완료될 때까지 다시 기다릴 것입니다. (참고: 5분이 걸렸습니다)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4. 암호화된 데이터베이스 복원\n\n스냅샷을 사용할 수 있는 상태가 되면, 데이터베이스를 복원해야 합니다. \"암호화된 스냅샷\"을 선택한 후 \"작업\"을 클릭한 다음 \"스냅샷 복원\"을 선택하세요. DB 인스턴스 식별자에는 새로운 DB 인스턴스를 위한 고유한 이름을 제공하세요. 동일한 구성을 유지하겠으며 필요에 따라 편집할 수도 있습니다. 모든 옵션을 확인한 후 복원을 클릭하세요.\n\n지금은 DB가 생성 중인 상태입니다:\n\n![image](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 5. DMS를 사용한 데이터 마이그레이션\n\n마지막 단계는 DMS로 이동하여 작업을 만들어야 합니다. 그러기 전에 소스 엔드포인트, 대상 엔드포인트 및 복제 인스턴스를 만들어야 합니다.\n\n먼저 복제 인스턴스에서 시작해야 합니다. 왼쪽 메뉴 탭에서 '복제 인스턴스'를 선택하고 \"복제 인스턴스 생성\"을 선택하세요.\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 구성에 대한 선호도를 포함할 수 있습니다. 인스턴스가 생성되었으므로 엔드포인트로 진행할 수 있습니다.\n\n소스 엔드포인트의 경우 DMS 콘솔에서 \"엔드포인트\"를 선택하고 \"엔드포인트 생성\"을 해야 합니다.\n\n아래 이미지에서 보이는 대로 소스 엔드포인트로 비암호화된 RDS를 선택해야 합니다:\n\n![image](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_8.png)\n\n수동으로 자격 증명을 추가하는 경우, 비밀번호를 추가해야할 것입니다. 비밀번호를 추가하려면 \"검색\"을 클릭하면 모든 데이터베이스 정보를 찾을 수 있는 시크릿 매니저를 확인해야 합니다.\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_9.png)\n\n이번에도 대상 엔드포인트에 대해 동일한 단계를 수행할 것입니다. 새 데이터베이스를 선택하기만 하면 됩니다. 이제 두 개의 엔드포인트가 준비되었으므로 작업을 생성할 수 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 Markdown 형식의 텍스트입니다.\n\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_10.png)\n\n작업을 만들려면 왼쪽 메뉴에서 \"데이터 마이그레이션 작업\"으로 이동하여 작업을 만들어야 합니다:\n\n![이미지](/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_11.png)\n\n소스, 대상, 복제 인스턴스 및 마이그레이션 유형을 포함한 설정을 올바르게 구성하고, \"기존 데이터 마이그레이션 및 지속적인 변경 복제\"를 선택해야 합니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래의 표태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html\n\nhttps://docs.aws.amazon.com/dms/latest/userguide/Welcome.html\n","ogImage":{"url":"/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_0.png"},"coverImage":"/assets/img/2024-05-23-SecuringYourDataMigratinganUnencryptedRDSDatabasetoanEncryptedOne_0.png","tag":["Tech"],"readingTime":4},{"title":"REST API를 API Gateway, Lambda, DynamoDB, Cognito를 사용하여 배포하는 단계별 가이드  Terraform","description":"","date":"2024-05-23 13:55","slug":"2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform","content":"\n\n![image](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_0.png)\n\n# 소개\n\n우리는 다양한 상황에서 사용할 수 있는 실전 프로젝트를 만들고 싶습니다. 실제 세계에서 매우 일반적인 것으로, 거의 모든 애플리케이션이 모듈식 레고 블록으로 구성된 마이크로서비스에 기반을 두고 있습니다.\n\n특히, 목표는 API 게이트웨이에 호스팅된 API를 만들고, 백엔드는 람다에, 데이터베이스는 DynamoDB에 있는 것입니다. 람다 함수에는 DynamoDB 테이블에서 CRUD 작업 (CREATE, READ, UPDATE, DELETE)을 수행하는 로직이 포함될 것입니다. 그리고 추가로 몇 가지 경로에 대한 공개 액세스를 제한하기 위해 Amazon Cognito를 사용한 인증을 추가할 것입니다. 왜냐하면 데이터베이스에 대한 쓰기 작업은 위험하기 때문입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시칠리아 섬에서 태어났기 때문에 신기한 섬리아 요리 목록을 관리할 수 있는 간단한 API를 생성할 것입니다.\n\n모든 소스 코드는 여기에서 확인하실 수 있습니다:\n\n# 단계 1: 공급자, AWS 지역, S3 백엔드 설정\n\n첫 번째 단계는 AWS를 제공자로 사용하도록 지정하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# provider.tf\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n```\n\n우리는 하나의 변수만 정의하고 있어요.\n\n```js\n# variables.tf\n\nvariable \"aws_region\" {\n  default   = \"eu-west-3\"\n  type      = string\n}\n```\n\n그런 다음 AWS 관리 콘솔로 이동해서 “S3” AWS 서비스로 이동하여 나중에 사용할 Terraform 상태 파일을 저장할 S3 버킷을 생성하세요. \"key\" 속성으로 지정된 경로에 생성할 거에요. 저는 \"my-api-gateway-lambda-terraform-state\"라고 이름지었어요. 모든 옵션을 기본값으로 남겨두세요.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만들었다면, Terraform 구성에서 명시할 것입니다:\n\n```js\n# backend.tf\n\nterraform {\n  backend \"s3\" {\n    bucket = \"my-api-gateway-lambda-terraform-state\"\n    region = var.aws_region\n    key    = \"API-Gateway/terraform.tfstate\"\n  }\n  required_version = \"\u003e= 0.13.0\"\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"\u003e= 2.7.0\"\n    }\n  }\n}\n```\n\n## 단계 2: Lambda IAM 역할 생성\n\nLambda 함수가 DynamoDB 테이블에서 작업을 수행하려면 해당 권한이 있어야 합니다. 따라서 IAM 역할을 생성해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 IAM 역할의 Assume Role 정책(Trust Relationship이라고도 함)을 명시적으로 지정해야 합니다. 이는 어떤 리소스 또는 서비스가 원하는 역할을 가져갈 수 있는 지를 나타내는데, 이 경우에는 Lambda 함수입니다. AWS 서비스에 권한을 제공할 때 이 단계는 항상 필수적입니다. 이 정책의 형식은 다음과 같습니다:\n\n```js\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"lambda.amazonaws.com\" # AWS 서비스의 이름\n        },\n        \"Action\": \"sts:AssumeRole\"\n    }]\n}\n```\n\n기본적으로 \"내 계정의 모든 Lambda 함수가 이 역할을 가져올 수 있습니다\"라고 말하고 있습니다.\n\n또한 Lambda에게 함수 실행과 관련된 로그 작성을 위해 필요한 최소한의 권한을 부여해야 합니다. 이 권한들은 이미 AWS에서 제공하는 AWSLambdaBasicExecutionRole이라는 IAM 서비스 역할에 정의되어 있습니다. 따라서 이 서비스 역할을 새 IAM 역할에 연결하여 Lambda에 할당할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파일 \"iam.tf\"를 생성하고 다음 코드를 붝어 주세요:\n\n```js\n# iam.tf\n\n# 역할 가정 정책\ndata \"aws_iam_policy_document\" \"AWSLambdaTrustPolicy\" {\n  statement {\n    actions    = [\"sts:AssumeRole\"]\n    effect     = \"Allow\"\n    principals {\n      type        = \"Service\"\n      identifiers = [\"lambda.amazonaws.com\"]\n    }\n  }\n}\n\n# IAM 역할 정의 및 가정 역할 정책 첨부\nresource \"aws_iam_role\" \"terraform_function_role\" {\n  name               = \"terraform_function_role\"\n  assume_role_policy = data.aws_iam_policy_document.AWSLambdaTrustPolicy.json\n}\n\n# 방금 정의한 IAM 역할에 IAM 서비스 역할 첨부\n# AWSLambdaBasicExecutionRole은 람다 함수에 최소한의 권한을 부여합니다\n# (실행에 대한 로그 작성, 오류, 디버깅 등)\nresource \"aws_iam_role_policy_attachment\" \"terraform_lambda_policy\" {\n  role       = aws_iam_role.terraform_function_role.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n```\n\n또한, 이외에도 말씀드린대로 Lambda 함수가 생성할 DynamoDB 테이블에 액세스해야 합니다. 이를 위해 DynamoDB 테이블에서 수행할 모든 작업이 명시적으로 허용된 JSON 정책 문서를 작성합니다:\n\n```js\n// lambda_dynamodb_policy.json\n\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n      {\n          \"Sid\": \"ListAndDescribe\",\n          \"Effect\": \"Allow\",\n          \"Action\": [\n              \"dynamodb:List*\",\n              \"dynamodb:DescribeReservedCapacity*\",\n              \"dynamodb:DescribeLimits\",\n              \"dynamodb:DescribeTimeToLive\"\n          ],\n          \"Resource\": \"*\"\n      },\n      {\n          \"Sid\": \"SpecificTable\",\n          \"Effect\": \"Allow\",\n          \"Action\": [\n              \"dynamodb:BatchGet*\",\n              \"dynamodb:DescribeStream\",\n              \"dynamodb:DescribeTable\",\n              \"dynamodb:Get*\",\n              \"dynamodb:Query\",\n              \"dynamodb:Scan\",\n              \"dynamodb:BatchWrite*\",\n              \"dynamodb:CreateTable\",\n              \"dynamodb:Delete*\",\n              \"dynamodb:Update*\",\n              \"dynamodb:PutItem\"\n          ],\n          \"Resource\": \"arn:aws:dynamodb:*:*:table/dishes\" // DynamoDB 테이블\n      }\n  ]\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLambda 함수가 DynamoDB 테이블에서 CRUD 작업(Get, Put, Update, Delete, Scan, Query 및 기타 작업)을 수행할 수 있는 정책을 정의하고, \"dishes\"라는 이름의 테이블을 사용할 것입니다.\n\n\"iam.tf\" 파일에서는 JSON 문서에 정의된 정책을 IAM 역할에 부착하도록 다음과 같이 작성합니다:\n\n```js\n# iam.tf\n\n# DynamoDB에 액세스하기 위한 IAM 역할에 사용자 지정 정책 부착\nresource \"aws_iam_role_policy\" \"lambda_dynamodb_policy\" {\n  name   = \"lambda_dynamodb_policy\"\n  role   = aws_iam_role.lambda-iam-role.name\n  policy = file(\"${path.module}/lambda_dynamodb_policy.json\")\n}\n```\n\n# 단계 3: Lambda 코드 설정하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLambda 함수를 설정하는 것이 다음 단계입니다. 이 함수는 DynamoDB 테이블과 상호 작용할 것입니다. 이 함수는 Python으로 작성될 것입니다.\n\nLambda 함수 안에서는 각각의 작업에 대한 메서드를 정의하고 API Gateway로 응답을 반환할 수 있습니다. 우리는 함수의 코드를 Python으로 작성할 것입니다.\n\n우선적으로 Lambda를 테스트할 때 무슨 일이 벌어지는지 볼 수 있도록 로거를 설정합니다. 그런 다음 lambda_handler() 안에서는 AWS 서비스와 상호 작용하기 위해 사용되는 boto3 라이브러리를 활용하여 DynamoDB 클라이언트를 선언합니다. Lambda를 트리거하는 이벤트는 API Gateway에서 오는 HTTP 요청입니다. 우리는 이를 통해 HTTP 메소드를 읽고 Lambda가 DynamoDB 테이블에서 수행해야 하는 작업을 구별할 수 있습니다.\n\nREST API는 트리 구조로 구성되어 있으며, 우리는 이를 다음과 같이 구조화하고 싶습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_1.png)\n\n우리는 다음을 할 수 있기를 원합니다:\n\n- GET dishes/ : 모든 요리 항목 검색\n- GET dish/'dishId' : ID로 특정 요리 항목 검색\n- POST dish/ : 새로운 요리 항목 저장\n- PATCH dish/ : 특정 요리 항목의 속성 업데이트\n- DELETE dish/ : 테이블에서 요리 항목 삭제\n\n테이블의 모든 항목을 가져 오기 위해 재귀 함수 recursive_scan을 활용하며, 이 함수는 DynamoDB 테이블에서 레코드를 효율적으로 스캔하는 데 사용됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표준 DynamoDB의 scan 작업은 테이블의 모든 항목을 읽는 표준 접근 방식입니다. 그러나 DynamoDB의 분산 특성과 확장성 때문에, 단일 scan 작업으로는 특히 테이블이 큰 경우 모든 항목을 한 번에 검색하지 못할 수 있습니다. DynamoDB는 결과를 페이지별로 반환하며, 다음 결과 페이지가 시작되는 위치를 나타내는 토큰(LastEvaluatedKey)과 함께 항목의 하위 집합을 반환합니다.\n\nrecursive_scan 메서드는 모든 페이지의 결과를 재귀적으로 가져와서 더 이상 페이지가 남아있지 않을 때까지(응답에 LastEvaluatedKey가 없을 때) 검색 프로세스를 최적화합니다. 이를 통해 페이지 수에 관계없이 DynamoDB 테이블의 모든 항목을 효율적으로 검색할 수 있습니다.\n\n```js\ndef recursive_scan(scan_params, items):\n    response = table.scan(**scan_params)\n    items += response['Items']\n    if 'LastEvaluatedKey' in response:\n        scan_params['ExclusiveStartKey'] = response['LastEvaluatedKey']\n        recursive_scan(scan_params, items)\n    return items\n```\n\n여기에 Lambda 함수의 전체 코드가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# lambda_code.py\n\nimport json\nimport logging\nimport boto3\nfrom decimal import Decimal\nfrom botocore.exceptions import ClientError\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('dishes')\n\ndish_path = '/dish'\ndishes_path = '/dishes'\n\ndef lambda_handler(event, context):\n\n    logger.info('API event: {}'.format(event))\n\n    response = None\n\n    try:\n        http_method = event.get('httpMethod')\n        path = event.get('path')\n\n        if http_method == 'GET' and path == dishes_path:\n            response = get_all_dishes()\n\n        elif http_method == 'GET' and path == dish_path:\n            dish_id = event['queryStringParameters']['dish_id']\n            response = get_dish(dish_id)\n\n        elif http_method == 'POST' and path == dish_path:\n            body = json.loads(event['body'])\n            response = save_dish(body)\n\n        elif http_method == 'PATCH' and path == dish_path:\n            body = json.loads(event['body'])\n            response = update_dish(body['dish_id'], body['update_key'], body['update_value'])\n\n        elif http_method == 'DELETE':\n            body = json.loads(event['body'])\n            response = delete_dish(body['dish_id'])\n\n        else:\n            response = generate_response(404, '리소스를 찾을 수 없습니다.')\n\n    except ClientError as e:\n        logger.error('오류: {}'.format(e))\n        response = generate_response(404, e.response['Error']['Message'])\n\n    return response\n\ndef get_dish(dish_id):\n    try:\n        response = table.get_item(Key={'dish_id': dish_id})\n        item = response['Item']\n        logger.info('항목 조회: {}'.format(item))\n        return generate_response(200, item)\n    except ClientError as e:\n        logger.error('오류: {}'.format(e))\n        return generate_response(404, e.response['Error']['Message'])\n\ndef get_all_dishes():\n    try:\n        scan_params = {\n            'TableName': table.name\n        }\n        items = recursive_scan(scan_params, [])\n        logger.info('모든 항목 조회: {}'.format(items))\n        return generate_response(200, items)\n    except ClientError as e:\n        logger.error('오류: {}'.format(e))\n        return generate_response(404, e.response['Error']['Message'])\n\ndef recursive_scan(scan_params, items):\n    response = table.scan(**scan_params)\n    items += response['Items']\n    if 'LastEvaluatedKey' in response:\n        scan_params['ExclusiveStartKey'] = response['LastEvaluatedKey']\n        recursive_scan(scan_params, items)\n    return items\n\ndef save_dish(item):\n    try:\n        table.put_item(Item=item)\n        logger.info('항목 저장: {}'.format(item))\n        body = {\n            '작업': '저장',\n            '메시지': '성공',\n            '항목': item\n        }\n        return generate_response(200, body)\n    except ClientError as e:\n        logger.error('오류: {}'.format(e))\n        return generate_response(404, e.response['Error']['Message'])\n\ndef update_dish(dish_id, update_key, update_value):\n    try:\n        response = table.update_item(\n            Key={'dish_id': dish_id},\n            UpdateExpression=f'SET {update_key} = :value',\n            ExpressionAttributeValues={':value': update_value},\n            ReturnValues='UPDATED_NEW'\n        )\n        logger.info('항목 업데이트: {}'.format(response))\n        body = {\n            '작업': '업데이트',\n            '메시지': '성공',\n            '항목': response\n        }\n        return generate_response(200, response)\n    except ClientError as e:\n        logger.error('오류: {}'.format(e))\n        return generate_response(404, e.response['Error']['Message'])\n\ndef delete_dish(dish_id):\n    try:\n        response = table.delete_item(\n            Key={'dish_id': dish_id},\n            ReturnValues='ALL_OLD'\n        )\n        logger.info('항목 삭제: {}'.format(response))\n        body = {\n            '작업': '삭제',\n            '메시지': '성공',\n            '항목': response\n        }\n        return generate_response(200, body)\n    except ClientError as e:\n        logger.error('오류: {}'.format(e))\n        return generate_response(404, e.response['Error']['Message'])\n\nclass DecimalEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, Decimal):\n            # 정수 또는 소수인지 확인합니다\n            if obj % 1 == 0:\n                return int(obj)\n            else:\n                return float(obj)\n        # 기본 클래스의 default 메서드가 TypeError를 발생시키도록 합니다\n        return super(DecimalEncoder, self).default(obj)\n\ndef generate_response(status_code, body):\n    return {\n        'statusCode': status_code,\n        'headers': {\n            'Content-Type': 'application/json',\n        },\n        'body': json.dumps(body, cls=DecimalEncoder)\n    }\n```\n\n그런 다음, “lambda.tf” Terraform 파일에는 Lambda 코드를 압축하는 데이터 블록을 정의하고 해당 Lambda 자체에 대한 리소스 블록이 있습니다:\n\n```js\ndata \"archive_file\" \"lambda_code\" {\n  type        = \"zip\"\n  source_file = \"${path.module}/lambda_code.py\"\n  output_path = \"${path.module}/lambda_code.zip\"\n}\n\nresource \"aws_lambda_function\" \"my-lambda-function\" {\n  filename      = \"${path.module}/lambda_code.zip\"\n  function_name = \"api-gateway-lambda\"\n  role          = aws_iam_role.lambda-iam-role.arn\n  handler       = \"lambda_code.lambda_handler\"\n  runtime       = \"python3.12\"\n\n  source_code_hash = data.archive_file.lambda_code.output_base64sha256\n}\n```\n\n# 단계 3: DynamoDB 설정\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시칠리아 요리 테이블을 만드는 시간이 왔습니다!\n\n![Sicilian Dishes](https://miro.medium.com/v2/resize:fit:480/1*WMK7Qze__kL4gO7lXQ5LKg.gif)\n\n`database.tf` 파일을 생성하고 다음 코드를 붙여넣으세요:\n\n```js\n# 다이나모DB 테이블 정의\nresource \"aws_dynamodb_table\" \"my_dynamodb_table\" {\n  name         = \"dishes\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"dish_id\"\n\n  attribute {\n    name = \"dish_id\"\n    type = \"S\"\n  }\n\n  tags = {\n    Name = \"dishes-table\"\n  }\n}\n\nlocals {\n  json_data = file(\"${path.module}/dishes.json\")\n  dishes    = jsondecode(local.json_data)\n}\n\n# 각 요리별로 다이나모DB 테이블에 새 항목 생성\nresource \"aws_dynamodb_table_item\" \"dishes\" {\n  for_each   = local.dishes\n  table_name = aws_dynamodb_table.my_dynamodb_table.name\n  hash_key   = aws_dynamodb_table.my_dynamodb_table.hash_key\n  item       = jsonencode(each.value)\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nJSON 문서에서 데이터를 가져 오므로 \"dishes.json\" 파일을 만드십시오. 각 속성에 대해 유형을 지정합니다 (S = 문자열, N = 숫자, L = 목록).\n\n```js\n// dishes.json\n\n{\n    \"Item1\": {\n        \"dish_id\": {\n            \"S\": \"1\"\n        },\n        \"name\": {\n            \"S\": \"아란치니\"\n        },\n        \"description\": {\n            \"S\": \"치즈, 완두 및 고기가 들어있는 튀긴 쌀 공예볼\"\n        },\n        \"price\": {\n            \"N\": \"8.99\"\n        },\n        \"ingredients\": {\n            \"L\": [\n                {\"S\": \"쌀\"},\n                {\"S\": \"치즈\"},\n                {\"S\": \"완두\"},\n                {\"S\": \"고기\"},\n                {\"S\": \"빵 가루\"}\n            ]\n        }\n    },\n    \"Item2\": {\n        \"dish_id\": {\n            \"S\": \"2\"\n        },\n        \"name\": {\n            \"S\": \"카놀리\"\n        },\n        \"description\": {\n            \"S\": \"튜브 모양의 튀겨진 페이스트리 도우로 구운 쉘에 달콤하고 부드러운 필링을 채운 시칠리아 디저트\"\n        },\n        \"price\": {\n            \"N\": \"5.99\"\n        },\n        \"ingredients\": {\n            \"L\": [\n                {\"S\": \"밀가루\"},\n                {\"S\": \"리코타 치즈\"},\n                {\"S\": \"설탕\"},\n                {\"S\": \"초콜릿 칩\"}\n            ]\n        }\n    },\n    \"Item3\": {\n        \"dish_id\": {\n            \"S\": \"3\"\n        },\n        \"name\": {\n            \"S\": \"파스타 알라 노르마\"\n        },\n        \"description\": {\n            \"S\": \"토마토 소스, 튀긴 가지, 갈은 리코타 샐라타 치즈 및 바질이 들어간 파스타\"\n        },\n        \"price\": {\n            \"N\": \"12.99\"\n        },\n        \"ingredients\": {\n            \"L\": [\n                {\"S\": \"파스타\"},\n                {\"S\": \"토마토 소스\"},\n                {\"S\": \"가지\"},\n                {\"S\": \"리코타 치즈\"},\n                {\"S\": \"바질\"}\n            ]\n        }\n    },\n    \"Item4\": {\n        \"dish_id\": {\n            \"S\": \"4\"\n        },\n        \"name\": {\n            \"S\": \"카사타\"\n        },\n        \"description\": {\n            \"S\": \"과일 주스 또는 리큐르로 적시한 둥근 스펀지 케이크로 리코타 치즈, 설탕이 묻혔고 카놀리 크림과 유사한 초콜릿 또는 바닐라 필링이 층층이 쌓인 시칠리아 케이크\"\n        },\n        \"price\": {\n            \"N\": \"15.99\"\n        },\n        \"ingredients\": {\n            \"L\": [\n                {\"S\": \"스펀지 케이크\"},\n                {\"S\": \"과일 주스\"},\n                {\"S\": \"리큐르\"},\n                {\"S\": \"리코타 치즈\"},\n                {\"S\": \"설탕\"},\n                {\"S\": \"초콜릿\"},\n                {\"S\": \"바닐라\"}\n            ]\n        }\n    }\n}\n```\n\n# 단계 4: API Gateway 설정\n\n이제 API 게이트웨이를 설정 할 시간입니다. API 게이트웨이는 프록시 역할을합니다. 클라이언트에서 Lambda 함수로 오는 HTTP 요청을 전달하며이 \"트릭\"을 사용하여 원래의 HTTP 요청이 전송됩니다 (GET, POST 등)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 API 게이트웨이 REST API를 설정하고 두 가지 API 리소스를 만듭니다. 각각의 경로(/dishes 및 /dish)를 위한 한 가지씩:\n\n```js\n# api_gateway.tf\n\n# API 게이트웨이\nresource \"aws_api_gateway_rest_api\" \"API-gw\" {\n  name        = \"lambda_rest_api\"\n  description = \"시칠리아 요리를 위한 REST API입니다.\"\n  endpoint_configuration {\n    types = [\"REGIONAL\"]\n  }\n}\n\n# \"/dishes\" 경로를 위한 API 리소스\nresource \"aws_api_gateway_resource\" \"API-resource-dishes\" {\n  rest_api_id = aws_api_gateway_rest_api.API-gw.id\n  parent_id   = aws_api_gateway_rest_api.API-gw.root_resource_id\n  path_part   = \"dishes\"\n}\n\n# \"/dish\" 경로를 위한 API 리소스\nresource \"aws_api_gateway_resource\" \"API-resource-dish\" {\n  rest_api_id = aws_api_gateway_rest_api.API-gw.id\n  parent_id   = aws_api_gateway_rest_api.API-gw.root_resource_id\n  path_part   = \"dishes\"\n}\n```\n\n우리가 원하는 API 엔드포인트는 다음과 같습니다:\n\n- GET /dishes: 모든 시칠리아 요리의 목록을 가져옵니다.\n- GET /dishes/'dishId': ID에 따라 특정 요리의 세부 정보를 가져옵니다.\n- POST /dishes: 새로운 시칠리아 요리를 데이터베이스에 추가합니다.\n- PATCH /dishes/'dishId': 특정 요리의 세부 정보를 업데이트합니다.\n- DELETE /dishes/'dishId': 데이터베이스에서 시칠리아 요리를 삭제합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 HTTP 메서드에 대해 아래와 같이 몇 가지 블록을 정의합니다:\n\n- Method (HTTP 메서드 지정)\n- Integration (Lambda와 통합)\n- Method response\n- Integration response\n\n![이미지](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_2.png)\n\n“REST API”는 만들 API Gateway 객체 모두를 담고 있는 컨테이너입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAPI Gateway에 들어오는 모든 요청은 다음과 일치해야 합니다:\n\n- 구성된 리소스 (특정한 /dish 또는 다른 /dishes)\n- HTTP 메서드\n\nAPI 게이트웨이 리소스의 각 메서드는 Lambda 함수로 들어오는 요청이 보내지는 통합을 가지고 있습니다. \"AWS_PROXY\" 통합 유형은 API 게이트웨이가 AWS Lambda API를 호출하여 Lambda 함수의 \"invocation\"을 생성하도록합니다. 그런 다음 우리는 메서드 응답(관련된 상태 코드로) 및 통합 응답을 구성합니다.\n\n```js\n# . . .\n\n# Lambda 함수를 트리거하는 API 게이트웨이 정의\nresource \"aws_api_gateway_rest_api\" \"API-gw\" {\n  name        = \"lambda_rest_api\"\n  description = \"이것은 시칠리아 요리를 위한 REST API입니다.\"\n  endpoint_configuration {\n    types = [\"REGIONAL\"]\n  }\n}\n\nresource \"aws_api_gateway_resource\" \"API-resource-dish\" {\n  rest_api_id = aws_api_gateway_rest_api.API-gw.id\n  parent_id   = aws_api_gateway_rest_api.API-gw.root_resource_id\n  path_part   = \"dish\"\n}\n\nresource \"aws_api_gateway_resource\" \"API-resource-dishes\" {\n  rest_api_id = aws_api_gateway_rest_api.API-gw.id\n  parent_id   = aws_api_gateway_rest_api.API-gw.root_resource_id\n  path_part   = \"dishes\"\n}\n\n#####################################################################################################\n########################### GET ALL /dishes #########################################################\n#####################################################################################################\n\nresource \"aws_api_gateway_method\" \"GET_all_method\" {\n  rest_api_id   = aws_api_gateway_rest_api.API-gw.id\n  resource_id   = aws_api_gateway_resource.API-resource-dishes.id\n  http_method   = \"GET\"\n  authorization = \"NONE\"\n}\n\n. . .\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로 API 게이트웨이가 람다 함수를 호출할 수 있도록 설정해야 합니다:\n\n```js\n# . . .\n\n# API 게이트웨이가 람다에 접근할 수 있도록 허용\nresource \"aws_lambda_permission\" \"apigw\" {\n  statement_id  = \"AllowAPIGatewayInvoke\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.my-lambda-function.function_name\n  principal     = \"apigateway.amazonaws.com\"\n\n  # 여기서 /*/* 부분은 \"REST API\" 내에서 어떤 리소스의 어떤 메서드에서도 접근할 수 있게 합니다.\n  source_arn = \"${aws_api_gateway_rest_api.API-gw.execution_arn}/*/*\"\n}\n```\n\n그런 다음 API 배포를 구성하고 \"prod\"라는 스테이지를 생성하여, API 게이트웨이 URL이 \"/prod/dishes\"와 같은 형태가 됩니다:\n\n```js\n# . . .\n\n# 배포\nresource \"aws_api_gateway_deployment\" \"example\" {\n\n  depends_on = [\n    aws_api_gateway_integration.GET_one_lambda_integration,\n    aws_api_gateway_integration.GET_all_lambda_integration,\n    aws_api_gateway_integration.PATCH_lambda_integration,\n    aws_api_gateway_integration.POST_lambda_integration,\n    aws_api_gateway_integration.DELETE_lambda_integration\n  ]\n\n  triggers = {\n    redeployment = sha1(jsonencode([\n      aws_api_gateway_resource.API-resource-dish,\n      aws_api_gateway_method.GET_one_method,\n      aws_api_gateway_integration.GET_one_lambda_integration,\n      aws_api_gateway_method.GET_all_method,\n      aws_api_gateway_integration.GET_all_lambda_integration,\n      aws_api_gateway_method.POST_method,\n      aws_api_gateway_integration.POST_lambda_integration,\n      aws_api_gateway_method.PATCH_method,\n      aws_api_gateway_integration.PATCH_lambda_integration,\n      aws_api_gateway_method.DELETE_method,\n      aws_api_gateway_integration.DELETE_lambda_integration\n    ]))\n  }\n\n  rest_api_id = aws_api_gateway_rest_api.API-gw.id\n}\n\n# 배포 스테이지\nresource \"aws_api_gateway_stage\" \"my-prod-stage\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.API-gw.id\n  stage_name    = \"prod\"\n\n  depends_on = [aws_cloudwatch_log_group.rest-api-logs]\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n백그라운드에서 요청을 보낼 때 무엇이 일어나는지 기록하기 위해 CloudWatch 로그 그룹을 설정하고 있습니다. CloudWatch LogGroup의 이름은 API-Gateway-Execution-Logs\\_'YOUR_API_ID'/'YOUR_STAGE_NAME' 형식이어야 합니다.\n\n그런 다음 API Gateway 스테이지 수준 실행 로깅을 설정하기 위해 \"method_settings\" 리소스를 사용합니다.\n\n```js\n# . . .\n\n# 디버깅 목적의 CloudWatch 로그 그룹\nresource \"aws_cloudwatch_log_group\" \"rest-api-logs\" {\n  name              = \"API-Gateway-Execution-Logs_${aws_api_gateway_rest_api.API-gw.id}/prod\"\n  retention_in_days = 7\n}\n\n# 메서드 설정\nresource \"aws_api_gateway_method_settings\" \"my_settings\" {\n  rest_api_id = aws_api_gateway_rest_api.API-gw.id\n  stage_name  = aws_api_gateway_stage.my-prod-stage.stage_name\n  method_path = \"*/*\"\n  settings {\n    logging_level = \"INFO\"\n    data_trace_enabled = true\n    metrics_enabled = true\n  }\n}\n```\n\n다음으로 CORS 모듈을 정의합니다. AWS 문서는 CORS 및 통합 및 통합 응답과 관련된 모든 뉘앙스를 잘 설명하고 있으므로 여기에 링크만 첨부하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# . . .\n\nmodule \"cors\" {\n  source = \"./modules/cors\"\n\n  api_id            = aws_api_gateway_rest_api.API-gw.id\n  api_resource_id   = aws_api_gateway_resource.API-resource-dish.id\n  allow_credentials = true\n}\n```\n\n![Image](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_3.png)\n\n이 구조를 따라가서 각 파일에 다음 코드를 붙여넣으세요.\n\ncors.tf:\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# cors.tf\n\nresource \"aws_api_gateway_method\" \"_\" {\n  rest_api_id   = var.api_id\n  resource_id   = var.api_resource_id\n  http_method   = \"OPTIONS\"\n  authorization = \"NONE\"\n}\n\n# aws_api_gateway_integration._\nresource \"aws_api_gateway_integration\" \"_\" {\n  rest_api_id = var.api_id\n  resource_id = var.api_resource_id\n  http_method = aws_api_gateway_method._.http_method\n\n  type = \"MOCK\"\n\n  request_templates = {\n    \"application/json\" = \"{ \\\"statusCode\\\": 200 }\"\n  }\n}\n\n# aws_api_gateway_integration_response._\nresource \"aws_api_gateway_integration_response\" \"_\" {\n  rest_api_id = var.api_id\n  resource_id = var.api_resource_id\n  http_method = aws_api_gateway_method._.http_method\n  status_code = 200\n\n  response_parameters = local.integration_response_parameters\n\n  depends_on = [\n    aws_api_gateway_integration._,\n    aws_api_gateway_method_response._,\n  ]\n}\n\n# aws_api_gateway_method_response._\nresource \"aws_api_gateway_method_response\" \"_\" {\n  rest_api_id = var.api_id\n  resource_id = var.api_resource_id\n  http_method = aws_api_gateway_method._.http_method\n  status_code = 200\n\n  response_parameters = local.method_response_parameters\n\n  response_models = {\n    \"application/json\" = \"Empty\"\n  }\n\n  depends_on = [\n    aws_api_gateway_method._,\n  ]\n}\n```\n\nheaders.tf:\n\n```js\n# headers.tf\n\nlocals {\n  headers = tomap({\n     \"Access-Control-Allow-Headers\"= \"'${join(\",\", var.allow_headers)}'\",\n    \"Access-Control-Allow-Methods\"= \"'${join(\",\", var.allow_methods)}'\",\n    \"Access-Control-Allow-Origin\"= \"'${var.allow_origin}'\",\n    \"Access-Control-Max-Age\"= \"'${var.allow_max_age}'\",\n    \"Access-Control-Allow-Credentials\"= var.allow_credentials ? \"'true'\" : \"\"\n  })\n\n  # Pick non-empty header values\n  header_values = compact(values(local.headers))\n\n  # Pick names that from non-empty header values\n  header_names = matchkeys(\n    keys(local.headers),\n    values(local.headers),\n    local.header_values\n  )\n\n  # Parameter names for method and integration responses\n  parameter_names = formatlist(\"method.response.header.%s\", local.header_names)\n\n  # Map parameter list to \"true\" values\n  true_list = split(\"|\",\n    replace(join(\"|\", local.parameter_names), \"/[^|]+/\", \"true\")\n  )\n\n  # Integration response parameters\n  integration_response_parameters = zipmap(\n    local.parameter_names,\n    local.header_values\n  )\n\n  # Method response parameters\n  method_response_parameters = zipmap(\n    local.parameter_names,\n    local.true_list\n  )\n}\n```\n\nvariables.tf:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```json\n변수 \"api_id\" {\n  설명 = \"API 식별자\"\n}\n\n# var.api_resource_id\n변수 \"api_resource_id\" {\n  설명 = \"API 리소스 식별자\"\n}\n\n# -----------------------------------------------------------------------------\n# Variables: CORS-related\n# -----------------------------------------------------------------------------\n\n# var.allow_headers\n변수 \"allow_headers\" {\n  설명 = \"허용 헤더\"\n  유형 = list(string)\n\n  기본값 = [\n    \"Authorization\",\n    \"Content-Type\",\n    \"X-Amz-Date\",\n    \"X-Amz-Security-Token\",\n    \"X-Api-Key\",\n  ]\n}\n\n# var.allow_methods\n변수 \"allow_methods\" {\n  설명 = \"허용 메소드\"\n  유형 = list(string)\n\n  기본값 = [\n    \"OPTIONS\",\n    \"HEAD\",\n    \"GET\",\n    \"POST\",\n    \"PUT\",\n    \"PATCH\",\n    \"DELETE\",\n  ]\n}\n\n# var.allow_origin\n변수 \"allow_origin\" {\n  설명 = \"허용 출처\"\n  유형 = string\n  기본값 = \"*\"\n}\n\n# var.allow_max_age\n변수 \"allow_max_age\" {\n  설명 = \"응답 캐싱 시간을 허용\"\n  유형 = string\n  기본값 = \"7200\"\n}\n\n# var.allowed_credentials\n변수 \"allow_credentials\" {\n  설명 = \"자격 증명 허용\"\n  기본값 = false\n}\n```\n\n마지막으로 \"outputs.tf\" 파일에 아래와 같이 API Gateway를 적용한 후의 호출 URL을 출력하는 블록을 선언하세요:\n\n```json\n# 테스트 API Gateway URL\noutput \"api_gateway_url\" {\n  value = aws_api_gateway_deployment.example.invoke_url\n}\n```\n\n# 단계 5: 코그니토로 인증 추가하기\n\n`\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다이나모DB 테이블의 작업(POST, PATCH, DELETE)은 위험할 수 있습니다. REST API를 공개적으로 노출하고 싶지 않으므로 일부 HTTP 엔드포인트에 대한 액세스를 제한하고 싶습니다. 따라서 인증을 구현하고자 하는데, 첫 번째 단계는 Cognito 사용자 풀을 생성하는 것입니다.\n\n```js\n# authentication.tf\n\nresource \"aws_cognito_user_pool\" \"pool\" {\n  name = \"mypool\"\n}\n```\n\n응용 프로그램이 사용자 풀에 액세스할 수 있도록하려면 사용자 풀 클라이언트를 정의해야 합니다. 우리는 기본 사용자 정보(email, openid, profile)에 대한 허용된 OAuth 플로 및 사용자 스코프를 명시하고 있습니다. 클라이언트 시크릿을 생성하지 않습니다. 또한 관리자 및 사용자 비밀번호 인증이 모두 허용됩니다. Cognito가 식별 제공자입니다. 그런 다음 OAuth 2.0 인증 서버가 사용자를 성공적으로 인증한 후 사용자를 리디렉션해야 할 위치 및 로그아웃 후 리디렉션할 위치가 정의됩니다. 어쨌든 이 프로젝트에 대해서는 이렇게까지 자세히 묘사하는 것은 그리 중요하지 않습니다.\n\n```js\n# authentication.tf\n\nresource \"aws_cognito_user_pool_client\" \"client\" {\n  name = \"client\"\n  allowed_oauth_flows_user_pool_client = true\n  generate_secret = false\n  allowed_oauth_scopes = [\"aws.cognito.signin.user.admin\",\"email\", \"openid\", \"profile\"]\n  allowed_oauth_flows = [\"implicit\", \"code\"]\n  explicit_auth_flows = [\"ADMIN_NO_SRP_AUTH\", \"USER_PASSWORD_AUTH\"]\n  supported_identity_providers = [\"COGNITO\"]\n\n  user_pool_id = aws_cognito_user_pool.pool.id\n  callback_urls = [\"https://example.com\"]\n  logout_urls = [\"https://example.com\"]\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n유저 풀 내에서 API 액세스를 테스트하기 위해 유저도 생성합니다.\n\n```js\n# authentication.tf\n\nresource \"aws_cognito_user\" \"example\" {\n  user_pool_id = aws_cognito_user_pool.pool.id\n  username = \"mattia\"\n  password = \"Test@123\"\n}\n```\n\n이 구성을 적용하여 모든 리소스가 올바르게 생성되었는지 확인해보세요 (유저 풀, 유저 풀 클라이언트 및 유저). AWS 관리 콘솔에서 “Amazon Cognito”로 이동하여 “User pools”를 선택하고 방금 생성한 풀을 클릭합니다. User pool ID를 메모하세요.\n\n\u003cimg src=\"/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_4.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새 사용자도 확인할 수 있습니다:\n\n![이미지](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_5.png)\n\n“앱 통합”을 클릭하고 “앱 클라이언트 및 분석”으로 내려가면 우리가 만든 클라이언트도 확인할 수 있습니다. 클라이언트 ID를 메모해 두세요.\n\n![이미지](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인증을 실제로 구현하고 애플리케이션의 일부 API 엔드포인트에 대한 공개 액세스를 제한하려면 먼저 Cognito 사용자 풀 내에서 Authorizer를 정의해야 합니다. Authorizer가 활성화되면 Lambda가 트리거되기 전에 수신된 요청 토큰이 먼저 이 Cognito 사용자 풀과 대조되어야 합니다. 따라서 \"api_gateway.tf\"에서 Authorizer를 정의합니다:\n\n```js\n# api_gateway.tf\n\nresource \"aws_api_gateway_authorizer\" \"demo\" {\n  name = \"my_apig_authorizer2\"\n  rest_api_id = aws_api_gateway_rest_api.API-gw.id\n  type = \"COGNITO_USER_POOLS\"\n  provider_arns = [aws_cognito_user_pool.pool.arn]\n}\n```\n\n기억하시나요? HTTP 메서드의 리소스 블록을 정의할 때 \"authorization\"을 \"NONE\"으로 설정했던 것을요. 이제 이 값을 변경하여 \"COGNITO_USER_POOLS\"로 설정하고 Authorizer ID를 지정하려고 합니다. 예를 들어 POST HTTP 메서드의 경우:\n\n```js\n# api_gateway.tf\n\n#####################################################################################################\n########################### POST /dish #########################################################\n#####################################################################################################\n\nresource \"aws_api_gateway_method\" \"POST_method\" {\n  rest_api_id   = aws_api_gateway_rest_api.API-gw.id\n  resource_id   = aws_api_gateway_resource.API-resource-dish.id\n  http_method   = \"POST\"\n  # authorization = \"NONE\" // 주석 처리\n  authorization = \"COGNITO_USER_POOLS\"\n  authorizer_id = aws_api_gateway_authorizer.demo.id\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 모든 중요한 엔드포인트(POST, PATCH, DELETE)에 대해 이 작업을 수행하십시오.\n\n더불어 이 구성을 적용하면 Postman으로 새 요청을 보내면 401 Unauthorized가 반환될 것입니다:\n\n![image](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_7.png)\n\n이제 HTTP 요청을 제출할 때 인가를 받기 위해 액세스 토큰을 제공해야 합니다. 액세스 토큰을 생성하려면 이전에 기록한 정보를 사용하여 \"aws cognito-idp\" 명령을 사용할 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```md\naws cognito-idp admin-initiate-auth --user-pool-id \u003cUSER_POOL_ID\u003e --client-id \u003cCLIENT_ID\u003e --auth-flow ADMIN_NO_SRP_AUTH --auth-parameters USERNAME=mattia,PASSWORD=Test@123\n```\n\n위 명령어에서 User Pool ID, User Pool client ID, 그리고 이전에 정의한 테스트 사용자의 사용자 이름과 암호를 교체해야 합니다.\n\n우리는 Cognito 사용자 풀에 대한 테스트 사용자를 인증하고, 그 결과로 액세스 토큰을 받습니다. 위 명령어의 출력은 아래와 유사합니다:\n\n```md\n{\n\"ChallengeParameters\": {},\n\"AuthenticationResult\": {\n\"AccessToken\": \u003cACCESS_TOKEN\u003e,\n\"ExpiresIn\": 3600,\n\"TokenType\": \"Bearer\",\n\"RefreshToken\": \u003cREFRESH_TOKEN\u003e,\n\"IdToken\": \u003cID_TOKEN\u003e # ID 토큰의 값을 복사하세요\n}\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 토큰들을 테스트하려면 ID 토큰의 값을 복사하고 AWS 관리 콘솔에서 \"API Gateway\"로 이동한 다음, API를 선택하고 왼쪽에 있는 \"Authorizers\"를 클릭하세요:\n\n![API Gateway Authorizer Test](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_8.png)\n\n이제 Authorizer를 클릭하세요. 그런 다음 Authorizer 테스트 섹션에 이전에 복사한 ID 토큰을 붙여넣고 \"Test authorizer\" 버튼을 클릭하세요. 파란 상자 안의 그것과 같은 출력이 있어야 합니다:\n\n![Authorizer Test Output](/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"토큰 만료 날짜인 'exp' 필드가 있는 것을 확인할 수 있습니다. 제 경우에는 유효합니다.\n\n이제 Postman으로 돌아가서 \"Headers\" 탭으로 이동하여 새 필드를 만들고 키를 \"Authorization\"로 선택한 후 값 필드에 다음 형식으로 ID 토큰을 지정하세요:\n\n```js\nBearer \u003cID_TOKEN\u003e\n```\n\n\u003cimg src=\"/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_10.png\" /\u003e\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요청을 보내시면 지금은 200 상태 코드를 받게 될 거에요. 모든 것이 잘 되고 있어요.\n\n# 결론\n\n이 프로젝트를 좋아해 주셨으면 좋겠고, 다음에 또 만나요! 궁금한 점 있으면 언제나 물어봐 주세요!\n","ogImage":{"url":"/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_0.png"},"coverImage":"/assets/img/2024-05-23-AStep-by-StepGuideOnDeployingRESTAPIusingAPIGatewayLambdaDynamoDBCognitoTerraform_0.png","tag":["Tech"],"readingTime":31},{"title":"Amazon Redshift의 디자인을 이해하는 데 다시 8시간을 보냈어요 내가 발견한 것은 여기 있어요","description":"","date":"2024-05-23 13:50","slug":"2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound","content":"\n## 레드시프트 학술 논문으로부터의 모든 통찰: 2022년에 새롭게 태어난 아마존 레드시프트\n\n- 역사와 배경\n- 고수준 아키텍처\n- 쿼리의 생애\n- 코드 생성\n- 컴파일 서비스\n- 저장\n- 컴퓨팅\n- 통합\n\n# 소개\n\n나이가 들수록 많은 것들을 잘못 알고 있었다는 것을 깨달았습니다. 아마존 레드시프트에 대해 잘못 생각한 것이 하나입니다. 레드시프트에 갇혀 거의 일 년을 보낸 후 구글 빅쿼리를 처음 사용했을 때, 빅쿼리가 5배 이상 더 발전된 기술이고(특히 빅쿼리의 서버리스 경험 때문에), 레드시프트보다 더 진보했다고 스스로에게 이야기했습니다. 그 인상은 세 년간 지속되었습니다. 돌이켜보면, 나 자신을 비웃으며 왜 그렇게 순진했는지 의문을 제기합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우수한 제품인 BigQuery, Redshift 또는 Snowflake와 같은 데이터베이스는 각각 하드웨어 제약 조건을 다루고 시스템 디자인 문제를 해결하는 고유한 방식이 있습니다. 어떤 데이터베이스가 더 빠른지 비교하는 대신에, 나는 그들의 내부 구현을 살펴가면서 가치 있는 것들을 배우는 것을 좋아해요. 이 기사는 Amazon Redshift에 대해 심층적으로 탐구한 결과물입니다 — 이전에 내가 무시했던 OLAP 시스템입니다.\n\n이 기사에서는 학술 논문 \"Amazon Redshift Re-invented (2022)\"에서 대부분의 자료를 사용할 것이며, 추가 참고 문서는 기사 끝에 포함될 것입니다.\n\n# 역사\n\nAmazon Redshift는 클라우드를 위해 설계된 열 지향적 대규모 병렬 처리 데이터 웨어하우스입니다. 이 시스템은 대규모 병렬 처리 (MPP) 데이터 웨어하우스 회사 ParAccel에서 기술을 기반으로 구축되었으며, 이후 Actian에 인수되었습니다. 이 시스템은 이전 버전인 PostgreSQL 8.0.2를 기반으로 구축되었으며, Redshift는 그 버전에 변경을 가했습니다. 초기 프리뷰 베타판은 2012년 11월에 출시되었고, 전체 버전은 2013년 2월 15일에 제공되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# High-level architecture\n\n![img](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_0.png)\n\nRedshift 클러스터는 쿼리 실행을 처리하기 위해 여러 컴퓨팅 인스턴스로 구성됩니다. 각 클러스터는 단일 코디네이터 노드(=리더)와 여러 워커 노드를 가지고 있습니다.\n\n데이터는 Amazon S3를 기반으로 하는 Redshift 관리 스토리지(RMS)에 저장됩니다. Redshift가 쿼리를 처리할 때, 데이터는 압축된 컬럼 지향 형식으로 로컬 SSD에 있는 컴퓨팅 노드에 캐싱됩니다. (저의 제한된 지식으로는 이것이 Snowflake 저장 계층과 유사하다고 생각됩니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 데이터는 여러 버킷으로 분할되어 모든 워커 노드에 분산됩니다. Redshift는 데이터의 특성에 기반하여 파티션 스키마를 적용할 수도 있고, 사용자가 명시적으로 라운드로빈 또는 해시와 같은 원하는 파티션 스키마를 선언할 수도 있습니다.\n\n컴퓨팅과 스토리지 외에도 Redshift에는 다음과 같은 구성 요소가 있습니다 :\n\n- AQUA는 FPGA를 활용하여 쿼리 성능을 가속화하는 레이어입니다.\n- Compilation-As-A-Service는 생성된 코드(쿼리에서)를 위한 캐싱 서비스입니다.\n- Amazon Redshift Spectrum을 사용하면 Redshift에서 S3의 데이터를 직접 쿼리할 수 있습니다.\n\n# 쿼리의 생명주기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_1.png\" /\u003e\n\n아키텍처 구성 요소를 자세히 살펴보기 전에, Redshift 쿼리의 여정을 간단히 살펴보겠습니다:\n\n- 쿼리는 먼저 리더 노드에 \"안녕\"이라고 말합니다. 여기서 구문 분석, 재작성 및 최적화됩니다.\n- Redshift는 클러스터의 토폴로지를 사용하여 최적의 계획을 선택합니다. 계획 프로세스는 데이터 분포 정보도 활용하여 데이터 이동을 줄입니다.\n- 계획 단계 후 Redshift는 실행 단계로 이동합니다. 계획은 개별 실행 단위로 분할됩니다. 각 단위는 이전 단위의 중간 출력을 사용합니다. Redshift는 각 단위에 대해 최적화된 C++ 코드를 생성 및 컴파일하고 이 코드를 네트워크를 통해 컴퓨트 노드로 전송합니다.\n- 열 지향 데이터는 로컬 SSD에서 스캔되거나 Redshift 관리 스토리지에서 공급됩니다.\n\nRedshift 실행 엔진은 성능을 향상시키기 위해 여러 최적화 기술을 적용합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- zone-maps를 사용하는 것은 작은 해시 테이블이며 각 데이터 블록의 최소-최대 값을 저장합니다. (Snowflake와 BigQuery도 이렇게 합니다.)\n- 스캔 연산은 Vectorization 및 SIMD(단일 명령, 다중 데이터) 처리를 사용합니다.\n- 가벼운 압축 형식입니다.\n- 블룸 필터\n- 프리패칭\n- Redshift의 AZ64 압축.\n\n제가 Redshift 구성 요소에 대해 자세히 설명할 때 이러한 기술들을 다시 볼 수도 있습니다.\n\n# 코드 생성\n\nOLAP(On-Line Analytical Processing) 세계에서 쿼리 성능을 향상시키는 두 가지 주요 방법은 벡터화(Vectorization)와 코드 특수화(Code Specialization)입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVectorization의 주요 아이디어는 하나의 레코드를 처리하는 대신, 엔진이 일괄(벡터) 값으로 처리한다는 것입니다.\n\n후자의 방식에서 엔진은 각 쿼리에 대해 코드를 생성하여 CPU 명령을 줄입니다. 코드 특수화를 적용하지 않는 시스템에서 각 연산자는 데이터 유형을 확인하고 입력 데이터 유형에 적합한 함수를 선택하기 위해 조건 블록(switch)을 통과해야 합니다. 코드 생성 방식은 실행 중에 해당 쿼리의 모든 연산자를 생성하기 때문에 이러한 과정을 피합니다.\n\nRedshift는 코드 생성 방식을 적용했습니다. 시스템은 쿼리 계획과 실행 스키마에 특정한 C++ 코드를 생성합니다. 생성된 코드는 컴파일되고, 바이너리가 실행을 위해 컴퓨팅 노드로 전달됩니다. 각 컴파일된 파일은 물리적 쿼리 계획의 일부인 세그먼트라고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드 생성을 적용했음에도 불구하고 Redshift는 생성된 코드에 SIMD-벡터화된 데이터 스캔 레이어를 추가합니다. 벡터화된 스캔 함수는 미리 컴파일되며 (실시간으로 생성되는 것이 아닌) Switch 문으로 모든 데이터 유형을 처리합니다. 이는 Redshift가 더 나은 데이터 스캔 성능을 달성하고 각 쿼리에 대해 컴파일해야 하는 내장 코드 양을 줄이는 데 도움이 됩니다.\n\n# 컴파일 서비스\n\n위 섹션에서 알 수 있듯이 Redshift는 쿼리 실행을 위해 컴파일된 최적화된 객체를 사용할 것입니다. 이러한 객체는 로컬 클러스터 캐시에 캐싱되므로 동일하거나 유사한 쿼리가 실행될 때 마다 컴파일된 객체가 재사용되어 실행 시간이 더 빨라집니다. Redshift가 쿼리를 컴파일할 필요가 없어지기 때문입니다. 이 전략은 필요한 컴파일된 객체가 로컬 캐시에 있는 경우에만 성능을 향상시킵니다. 그렇지 않은 경우 Redshift는 코드를 생성해야 하므로 지연이 발생합니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_3.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2020년에 Redshift는 컴파일 서비스를 소개했어요 (만약 마일스톤에 관해 틀린 정보를 전달했다면 이를 수정해 주세요). 이 서비스는 클러스터 리소스 대신 별도의 리소스를 사용해요. 컴파일 서비스는 컴파일된 객체를 외부 캐시에 캐싱하여 Redshift가 여러 클러스터에 대해 캐시된 객체를 제공할 수 있게 해줘요.\n\n또한, 컴파일 서비스는 외부 컴파일 서비스의 병렬성을 활용하여 원하는 객체가 로컬 캐시나 외부 캐시에 없을 경우 코드를 더 빨리 컴파일할 수 있어요.\n\nRedshift 뒤에 있는 사람들은 다음을 관찰했어요:\n\n# CPU 친화적인 인코딩\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRedshift은 디스크에 압축된 데이터를 저장합니다. LZO 및 ZSTD와 같은 일반적인 압축 알고리즘 외에도 Redshift는 AZ64 알고리즘과 같은 최적화된 유형별 알고리즘을 지원합니다. 이 알고리즘은 숫자 및 날짜/시간 데이터 유형을 다루는 것으로, 2019년에 Amazon에서 소개되었습니다. AZ64은 높은 압축 비율을 달성하고 성능을 향상시키도록 설계되었습니다. AZ64는 ZSTD와 비슷한 압축률을 달성하지만 빠른 압축 해제 속도를 갖추고 있습니다.\n\n여기서 언급해야 할 멋진 점은 사용자가 AUTO 옵션(레드시프트가 데이터에 대한 압축을 자동으로 정의하도록 하는 옵션) 외에도 열 단위로 명시적으로 압축 체계를 정의할 수 있다는 것입니다. 게다가 한번 정의한 후에는 ALTER TABLE 절을 사용하여 압축 체계를 변경할 수 있습니다. 이것은 흥미로운 기능이라고 생각합니다. 사용자가 데이터에 대해 가장 이해하고 있으므로 유연한 압축 옵션을 허용하는 것이 데이터가 어떻게 저장되는지에 대한 더 나은 통제를 제공할 수 있을 것입니다. 그에 상응하여 더 많은 권한은 더 큰 책임을 의미합니다. 조심하지 않으면 나쁜 (압축) 선택이 성능과 비용에 악영향을 줄 수 있습니다. 내가 아는 한, Google은 BigQuery에서 이 기능을 허용하지 않습니다. Snowflake가 이를 지원하는지 알지 못하니 알고 계시면 의견을 남겨주세요.\n\n# 적응형 실행\n\nRedshift의 쿼리 엔진은 실행 통계에 따라 생성된 코드나 실행 속성을 조정하여 성능을 향상시키는 런타임 결정을 내립니다. 실행 중에 Bloom 필터를 사용하는 것은 Redshift의 동적 최적화의 대담한 예입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Amazon Redshift을 위한 AQUA\n\n\u003cimg src=\"/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_4.png\" /\u003e\n\nAdvanced Query Accelerator (AQUA)는 2021년에 Redshift에 의해 소개된 멀티 테넌시 서비스입니다. 이는 Redshift Managed Storage를 위한 캐싱 레이어 역할을 하며 복잡한 스캔 및 집계를 가속화합니다.\n\nAQUA는 지역 서비스인 Amazon S3에서 데이터를 가져오는 레이턴시를 피하고 Redshift의 캐시 스토리지에 데이터를 채우는 필요성을 줄이기 위해, 클러스터의 핫 데이터(여러 번 액세스되는 데이터)를 로컬 SSD에 캐싱합니다. Redshift는 입력 쿼리로부터 해당 스캔 및 집계 작업을 감지하고 이를 AQUA로 푸시하여 캐시된 데이터로 처리합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아마존의 사람들은 AWS의 Nitro ASIC를 활용한 커스텀 서버를 설계하여 압축 및 암호화를 가속화하고, FPGAs를 사용하여 필터링 및 집합 연산의 실행 속도를 향상시키도록 했습니다.\n\n# 쿼리 재작성 프레임워크\n\nRedshift는 또한 두 가지 목표를 가진 새로운 쿼리 재작성 프레임워크(QRF)를 소개했습니다:\n\n- 연합, 조인 및 집계와 같은 연산의 실행 순서를 최적화하기 위한 재작성 규칙.\n- 점진적 재료화 뷰 쿼리 및 유지 관리를 위한 스크립트 작성. (곧 다룰 예정입니다)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 스토리지\n\n이 섹션에서는 Redshift의 스토리지 레이어인 Redshift Managed Storage부터 동시성 제어까지 살펴볼 것입니다.\n\n# Redshift Managed Storage (RMS)\n\nRA3 클러스터 유형이나 Redshift 서버리스를 선택할 때, 데이터는 RMS에 저장됩니다. 이 저장 레이어는 Amazon S3를 기반으로 하며, 특정 년도 동안 다중 존에서 99.999999999%의 내구성과 99.99%의 가용성을 달성합니다. RMS를 사용하면 데이터가 컴퓨팅 노드에서 분리되어 저장되므로 고객은 컴퓨팅과 스토리지를 독립적으로 확장하고 비용을 지불할 수 있습니다. RMS는 S3를 기반으로 하기 때문에 데이터 블록 온도 및 블록화와 같은 최적화를 사용하여 높은 성능을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRMS는 고대역 네트워킹을 제공하는 AWS Nitro 시스템 위에서 구축되었어요. RMS는 티어-1 캐시로 높은 성능의 SSD 기반 로컬 스토리지를 사용하고 있어요. Redshift는 자동으로 미세하게 데이터를 제거하고 지능적으로 데이터를 미리 가져오는 기술을 활용하여 로컬 SSD에서 최고의 성능을 얻으면서 S3의 무제한 확장성을 달성하고 있어요.\n\n![이미지](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_5.png)\n\nRMS는 S3로부터 데이터 접근을 향상시키기 위해 데이터 블록을 메모리에 넣고 로컬 SSD에 캐시하는 미리가져오기 메커니즘을 사용하고 있어요. RMS는 관련 블록이 로컬에서 사용 가능하도록 유지하기 위해 캐시 대체를 조정하면서 모든 블록에 대한 액세스를 추적해요. 로컬 SSD 위의 캐시 레이어인 메모리 디스크 캐시 크기는 쿼리의 성능과 메모리 요구 사항을 균형있게 조정할 수 있도록 동적으로 변경될 수 있어요.\n\n테이블의 데이터는 데이터 슬라이스로 분할되어 논리적인 데이터 블록 체인으로 저장됩니다. 각 블록(크기 1MB)에는 식별, 테이블 소유권 또는 슬라이스 정보와 같은 정보가 포함된 헤더가 있어요. 블록은 메모리 내 구조인 슈퍼 블록을 사용하여 색인화돼요. 논문에 따르면 슈퍼 블록은 많은 파일 시스템과 유사한 특성을 가진 색인 구조입니다. 쿼리는 슈퍼 블록을 스캔하기 위해 존 맵을 사용하여 필요한 데이터 블록을 가져와요. 게다가 슈퍼 블록은 실행 중인 쿼리에 의해 처리된 데이터 블록을 위한 쿼리 추적 정보도 포함하고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRMS는 Amazon S3로 트랜잭션을 동기화하여 여러 클러스터가 일관된 데이터에 액세스할 수 있게 해줍니다. 데이터는 쓰기 요청을 일괄 처리함으로써 다른 가용 영역에 걸쳐 S3에 쓰여집니다. 동시 클러스터는 동시 쓰기를 위해 필요할 때 요청되며 읽기는 스냅샷 분리에 의존합니다.\n\n메인 클러스터에서 데이터가 삭제되면 Redshift는 해당 데이터가 더 이상 쿼리에 필요하지 않음을 보장하고, 이 데이터를 개체 저장소의 가비지 컬렉터용으로 표시합니다. 데이터가 Amazon S3에 백업되어 있기 때문에 SSD가 고장나도 데이터는 손실되지 않습니다.\n\nAmazon S3는 또한 데이터 스냅샷을 저장합니다. 이러한 스냅샷은 복원 지점으로 작용합니다. Redshift는 전체 클러스터 데이터뿐만 아니라 개별 테이블의 데이터를 복원하는 것도 지원합니다. Amazon S3는 데이터 공유와 머신 러닝의 진실의 원천으로도 기능합니다.\n\n# 데이터 메타데이터 분리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메타데이터와 데이터를 분리하면 Elastic Resize 및 Cross Instance Restore와 같은 프로세스를 구현하기가 더 쉬워집니다. 이 둘 다 메타데이터를 한 클러스터 구성에서 다른 클러스터 구성으로 이동해야 합니다.\n\nElastic Resize는 고객이 클러스터의 노드를 추가하여 성능을 향상시키거나 노드를 제거하여 비용을 절약할 수 있는 기능입니다. Cross-Instance Restore를 통해 사용자는 하나의 인스턴스 유형 클러스터에서 가져온 스냅샷을 다른 인스턴스 유형이나 다른 노드 수의 클러스터로 복원할 수 있습니다.\n\n이 프로세스의 구현 세부 정보는 다음과 같습니다:\n\n- 데이터의 사본이 Amazon S3에 저장되도록 보장합니다.\n- 재구성하기 전 Redshift는 클러스터의 데이터를 고려합니다. 데이터 이동을 최소화하는 재구성 계획을 수립하여 균형 잡힌 클러스터를 생성합니다.\n- 재구성하기 전에 Redshift는 데이터에 대한 카운트와 체크섬을 기록하고 완료 후 정확성을 검증합니다.\n- 복원의 경우 Redshift는 테이블 수, 블록 수, 행 수, 사용된 바이트 및 데이터 분포의 카운트를 기록하고 스냅샷과 함께 저장합니다. 복원 후에 카운트와 체크섬을 검증하고 새 쿼리를 수락하기 전에 확인합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 논문을 따르면:\n\n## 로컬 저장소의 한계를 넘어서\n\nRedshift는 무한한 확장성을 제공하기 위해 Amazon S3를 활용하며, 로컬 메모리와 SSD를 캐시로 사용합니다. (Snowflake와 같이).\n\n클러스터는 각 데이터 블록의 액세스 횟수에 따라 작업 데이터 세트를 로컬로 유지합니다. Tiered 캐시는 이 정보를 추적하는 역할을 합니다. 캐시는 두 단계로 구성됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_6.png)\n\n- Low level: This level stores cold data blocks. Every time the query accesses a data block, the system increases the block’s reference count.\n- High level: the cold blocks become hot (after being accessed multiple times), and the policy promotes data blocks to a high level.\n\nDuring eviction, the reference count of each block is decremented. When the reference count reaches zero, the block will be moved down to the low level or entirely evicted from the cache.\n\n(Sounds like Python object’s reference count, huh?)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRMS는 클러스터 재구성 후 로컬 SSD에 데이터를 다시 채우는 데 티어별 저장소 캐시를 사용합니다 (예 : Elastic Resize). 이와 같은 시나리오에서 컴퓨팅 노드는 고객 쿼리에서 가장 자주 액세스될 것으로 예상되는 데이터 블록을 로컬 디스크에 채웁니다.\n\n마지막으로, Redshift에는 메모리 내에서 가장 빈번하게 액세스되는 가장 뜨거운 블록을 유지하는 동적 디스크 캐시라는 또 다른 캐시 레이어가 있습니다. 또한 특정 쿼리에서 임시 블록을 저장합니다. 이 캐시는 메모리가 사용 가능할 때 자동으로 확장되고 시스템이 메모리 부족 상태가 되면 자동으로 축소됩니다.\n\n# 점진적 커밋\n\n비용을 절감하기 위해 RMS는 마지막 커밋과 비교하여 데이터 변경 사항만 캡처합니다. 이러한 변경 사항은 나중에 커밋 로그에 업데이트됩니다. Redshift의 로그 기반 커밋 프로토콜은 인메모리 구조를 영구 구조(디스크)로부터 분리하며, 각 슈퍼블록은 변경 사항의 로그입니다. 논문에서 가져온 내용:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 로그 구조화된 메타데이터는 일관된 데이터에 접근하여 로그를 적용함으로써 동시성 확장 및 데이터 공유와 같은 기능의 비용을 줄입니다.\n\n# 동시성 제어\n\nRedshift는 다중 버전 동시성 제어를 구현하여 읽기 프로세스가 다른 읽기 요청으로 블록되는 것을 방지합니다. 쓰기 요청은 다른 동시 쓰기 요청에 의해만 차단될 수 있습니다.\n\n각 트랜잭션은 트랜잭션이 시작되기 전에 모든 커밋된 트랜잭션에 의해 설정된 데이터베이스의 일관된 스냅샷을 볼 수 있습니다. 논문에서 Amazon은 스냅샷 격리 위에 Serial Safety Net (SSN)을 기반으로 한 새로운 디자인을 사용하여 엄격한 직렬화를 메모리 효율적인 방식으로 보장하는데 사용했습니다. 이 디자인은 이전에 커밋된 트랜잭션의 요약 정보만 사용하므로 엄격한 직렬화를 보장할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 계산\n\n아마존을 따라가는 레드시프트는 매주 수십억 개의 쿼리를 처리합니다. 사용자는 필요에 따라 계산 성능을 조절할 수 있는 다음 옵션 중 하나를 선택할 수 있습니다:\n\n# 클러스터 크기 확장\n\n![image](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 설정을 통해 고객은 필요에 따라 클러스터에서 컴퓨팅 노드를 추가하거나 제거할 수 있습니다. 데이터를 섞는 대신, Elastic Resize는 데이터 파티션 할당(메타데이터만)을 분배하여 데이터 파티션을 노드 간에 조직화되고 균형 있게 유지합니다. 크기를 조정한 후, 컴퓨팅 노드의 로컬 캐시(SSD)는 할당 정보에 따라 S3에서 데이터를 받아 채웁니다. (Redshift는 핫 데이터에 우선순위를 둠)\n\n그러나 이로 인해 잠재적인 문제가 발생할 수 있습니다. 크기를 조정한 후, 각 노드가 담당하는 데이터의 수가 크기를 조정하기 이전과 다를 수 있으며, 이는 일관되지 않은 쿼리 성능을 초래할 수 있습니다. Redshift는 이를 다루기 위해 컴퓨팅 병렬성(작업자, 프로세스, 스레드 수)을 데이터 파티션과 분리합니다:\n\n![이미지](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_8.png)\n\n- 컴퓨팅 병렬성이 `데이터 파티션의 수와 같은 경우, 개별 컴퓨팅 프로세스는 여러 데이터 파티션에서 작업합니다.\n- 컴퓨팅 병렬성이 `데이터 파티션의 수와 다른 경우, 여러 컴퓨팅 프로세스가 개별 데이터 파티션에서 작업을 공유합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRedshift은 공유 가능한 작업 단위 덕분에 이것을 달성합니다.\n\n## 동시성 스케일링\n\n이 구성은 OLAP 시스템의 전형적인 도전 과제 중 하나인 동시성을 다루는 데 도움을 줍니다. 사용자가 Redshift에서 더 많은 동시성 기능을 필요로 할 때 동적으로 확장됩니다.\n\n![이미지](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nConcurrency Scaling을 사용하면 사용자는 쿼리를 제출하기 위한 단일 클러스터 활성 엔드포인트를 유지합니다. Redshift는 리소스가 완전히 활용되고 새로운 쿼리가 지속적으로 발생하는 것을 감지하면 자동으로 추가적인 Concurrency Scaling 컴퓨팅 클러스터를 추가합니다. 대기 중인 쿼리는 이러한 클러스터로 라우팅되어 처리됩니다. 또한 추가된 클러스터는 S3로부터 데이터를 로컬 디스크에 채웁니다.\n\n# 컴퓨팅 분리\n\nRedshift는 고객이 다른 Redshift 컴퓨팅 클러스터 및 AWS 계정 간에 데이터를 공유할 수 있도록 합니다. 컴퓨팅 클러스터는 단일 데이터 원본에 액세스할 수 있으며 ETL 파이프라인을 개발하거나 데이터 복사 비용을 부담할 필요가 없습니다.\n\n사용자는 스키마와 테이블부터 사용자 정의 함수(UDF)까지 다양한 수준에서 데이터를 공유할 수 있습니다. 다른 사람과 데이터를 공유하려면 데이터의 소유자(생산자)가 먼저 데이터 공유를 생성하고 사용자에게 액세스를 부여합니다. Redshift는 IAM 정책과 메타데이터를 사용하여 인증 및 권한 부여를 구현합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n고객은 메타데이터 요청을 사용하여 공유된 객체에 대한 쿼리를 공유합니다. 공유 데이터에 액세스하는 것이 인가된 고객만 서비스를 제공받을 수 있습니다. 각 요청은 디렉토리 서비스 및 프록시 레이어를 통해 전달됩니다. 프록시는 요청을 인증하고 승인하며 메타데이터 요청을 적절한 프로듀서로 라우팅합니다. 고객 측에서 메타데이터를 수신한 후에는 RMS에서 원하는 데이터를 읽고 쿼리를 처리합니다. 공유 데이터를 쿼리할 때의 캐시 프로세스는 변경되지 않습니다: 공유 데이터는 클러스터에 캐시되며 이후의 쿼리에서는 로컬로 데이터를 읽어옵니다.\n\n## 자동 튜닝 및 운영\n\n첫날부터 Redshift는 전통적인 데이터 웨어하우징 시스템(로컬 서버 및 데이터 센터 구축)과 비교하여 많은 측면을 간소화했습니다. 그럼에도, 일부 유지 관리 및 튜닝 작업은 경험 많은 데이터베이스 관리자가 필요합니다: 사용자는 성능 향상을 위해 명시적으로 vacuum 프로세스를 예약하거나 분산 또는 정렬 키를 결정해야 합니다.\n\n현재 Redshift는 고객 워크로드에 성능 영향을 미치지 않고 비주요 프로세스인 vacuuming, analyzing 또는 materialized views 새로고침을 자동으로 실행합니다. Redshift는 사용자 워크로드를 관찰하고 분석하여 성능 향상 기회를 식별하며, 예를 들어 워크로드에 대한 최적의 분산 및 정렬 키를 자동으로 지정하여 적용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, Redshift는 고급 예측 메커니즘을 활용하여 웜 풀을 통해 필요할 때 추가 노드를 가능한 빨리 사용할 수 있습니다. 이는 Snowflake의 사전 웜 워커 풀과 매우 유사하며, 노드 장애 또는 동시성 스케일링으로 인한 쿼리 대기 시간 및 다운타임을 줄입니다. 마지막으로, Amazon Redshift는 사용자 개입 없이 실행 및 스케일링이 쉬운 서버리스 옵션(예: Google BigQuery)을 제공합니다.\n\n# 자동 테이블 최적화\n\n분배 및 정렬 키와 같은 속성을 최적화하여 작업 부하의 성능을 최적화할 수 있습니다. 분배 키는 테이블 데이터가 클러스터 전체에 분배되는 방식을 나타내는 속성으로, 시스템이 병렬 리소스를 효율적으로 할당할 수 있도록 도와줍니다. 정렬 키는 하나 이상의 열을 기반으로 데이터를 정리하여 존 맵 인덱싱을 활용합니다. 존 맵은 데이터 단위의 최소값 및 최대값을 저장하는 인덱싱 구조로, 불필요한 데이터를 건너뛰는 데 매우 유용하며 데이터 정렬은 존 맵을 효율적으로 활용할 수 있습니다. (이건 BigQuery 클러스터링과 비슷하게 들리나요?)\n\n![Amazon Redshift 디자인을 이해하는 데 또 8시간을 보냈어요. 여기서 발견한 것들](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_10.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n과거에는 이러한 키들이 사용자에 의해 명시적으로 정의되었습니다. 지금은 Redshift가 자동으로 Automatic Table Optimization (ATO)을 통해 이 프로세스를 처리합니다. ATO는 워크로드를 분석하여 최적의 분배 및 정렬 키를 추천합니다. 추천을 생성하기 위해 최적화된 쿼리 계획, 기본치, 및 예측 선택도와 같은 쿼리 실행 메타데이터를 주기적으로 수집합니다.\n\n목표와 함께 추천된 키들:\n\n- 분배 키: 데이터 이동 비용을 최소화하기 위해 시스템은 특정 워크로드의 모든 테이블을 조사하여 추천해야 합니다.\n- 정렬 키: 디스크에서 읽어야 하는 데이터 양을 줄이기 위해.\n\n추천을 받은 후, Redshift는 고객들에게 두 가지 옵션을 제공합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 콘솔을 통한 수동 적용.\n- 자동 백그라운드 워커가 권장 사항을 적용합니다. 이 워커는 설정을 점진적으로 적용하고 클러스터가 너무 바쁘지 않을 때에만 작업을 실행합니다.\n\n# 자동 워크로드 관리\n\nRedshift의 자동 워크로드 관리자(AutoWLM)는 입장 제어, 스케줄링 및 자원 할당을 담당합니다. 쿼리를 수신한 후 AutoWLM은 실행 계획과 최적화된 통계를 벡터 형식으로 변환합니다. 그런 다음 Redshift는 해당 벡터를 ML 모델로 넣어 컴파일 및 실행 시간을 예측합니다. Redshift는 모델의 결과를 사용하여 예측된 실행 시간을 기반으로 쿼리를 대기열에 넣습니다. 추정된 메모리 요구량(모델에 의해 예측됨)이 사용 가능한 메모리 풀에서 충족될 때만 쿼리가 실행 단계로 진행됩니다. 또한 자원 이용률이 너무 높다고 감지될 때 AutoWLM은 병행성 비율을 제한하여 쿼리 대기 시간을 피합니다.\n\nAutoWLM은 스케줄링에 가중 라운드로빈 메커니즘을 활용하여 우선순위가 더 높은 쿼리를 우선적으로 더 자주 스케줄링합니다. 또한 SLA를 준수해야 하는 높은 우선순위 쿼리는 하드웨어 자원의 더 큰 할당을 받습니다. Redshift는 서로 다른 우선순위를 갖는 쿼리가 동시에 실행될 때 CPU 및 I/O를 지수함수적으로 감소하는 부분으로 분할합니다. 이는 높은 우선순위 쿼리를 낮은 우선순위 쿼리보다 지수함수적으로 빠르게 부스트합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하위 우선순위 쿼리 뒤에 높은 우선순위 쿼리가 오면 AutoWLM은 상위 우선순위 쿼리에 공간을 확보하기 위해 하위 우선순위 쿼리에서 리소스를 회수합니다. 낮은 우선순위 쿼리에서 리소스 고갈을 방지하기 위해 시스템에 의해 리소스가 회수되는 확률이 각 빼앗애질 때마다 줄어듭니다. 결과적으로 리소스가 고갈되면 Redshift는 상위 우선순위 리소스를 제공하기 위해 하위 우선순위 쿼리를 대기열에 넣습니다.\n\n# 쿼리 예측 프레임워크\n\n위 섹션에서 언급했듯이 AutoWLM은 메모리 소비량이나 실행 시간과 같은 메트릭을 예측하기 위해 머신 러닝 모델을 사용합니다. Redshift의 쿼리 예측 프레임워크는 이러한 모델을 유지하는 역할을 합니다. 이 프레임워크는 Redshift 클러스터에서 실행되며 데이터를 수집하고 XGBoost 모델로 훈련을 하며 필요할 때 결과를 출력합니다. 클러스터에서 프레임워크를 실행함으로써 변화하는 워크로드에 빠르게 적응할 수 있습니다. 위에서 언급한 코드 컴파일 서비스도 최적화를 위해 쿼리 예측 프레임워크를 사용합니다.\n\n# 자료화된 뷰\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image description](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_11.png)\n\nSQL 뷰와 Materialize View (MV)은 쿼리 결과를 테이블처럼 나타내는 방법을 제공합니다. View와는 달리, MV는 데이터를 디스크에 물리적으로 유지하므로 MV에서 데이터를 쿼리할 때 실행 시간이 빨라집니다. Redshift는 MV 관리를 다음과 같이 자동화합니다:\n\n- 기본 테이블의 변경 사항을 반영하여 필터, 선택, 그룹화 및 조인을 점진적으로 유지합니다.\n- 유지 관리 시간을 자동화합니다: Redshift는 어떤 MV를 새로 고쳐야 하는지 감지합니다. 이는 쿼리 워크로드에서 MV의 유틸리티 및 MV 새로 고침 비용 두 가지 요소를 사용하여 수행됩니다.\n- MV를 통해 쿼리를 자동으로 다시 작성하여 최적의 성능을 달성합니다. 점진적 유지 관리 및 쿼리 다시 작성은 \"쿼리 다시 작성 프레임워크\" 섹션에서 언급된 프레임워크를 사용합니다.\n\n# 스마트 웜 풀\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클라우드 시대에는 하드웨어 고장이 더 이상 예외가 아닙니다. 머신 고장으로 인한 성능 저하를 방지하기 위해 Redshift는 스마트 웜 풀 아키텍처(컴퓨팅 머신이 서비스되기 전에 미리 웜업됨)를 사용합니다. 이 아키텍처는 많은 프로세스에서 효율성을 제공합니다: 실패한 노드 교체, 클러스터 재개, 자동 동시성 스케일링...\n\n![image](/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_12.png)\n\n웜 풀은 사전 설치된 소프트웨어와 네트워킹 구성을 갖춘 EC2 컴퓨트 인스턴스 그룹입니다. 각 지역마다 AWS 가용 영역마다 별도의 웜 풀이 위치해 있습니다. 작업을 낮은 지연 시간으로 유지하기 위해서는 웜 풀에서 노드를 획득할 때 높은 히트율이 필요합니다. Redshift는 머신러닝 모델을 사용하여 특정 시점에서 필요한 EC2 인스턴스 수를 예측합니다. 시스템은 각 지역과 가용 영역에서 웜 풀을 동적으로 조정하여 인프라 비용을 절약합니다.\n\n# 통합\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내장형인 AWS Redshift는 Amazon 클라우드 서비스 생태계의 혜택을 크게 누립니다. 여기에는 Redshift의 통합 옵션 몇 가지가 있습니다.\n\n- Amazon Redshift Spectrum을 사용하면 S3에서 데이터를 직접 쿼리할 수 있습니다. 이 기능은 대규모 Scale-Out 처리를 제공하여 Parquet, Text, ORC 및 AVRO 형식의 데이터를 스캔하고 집계합니다.\n- Amazon Sagemaker와 함께하는 Redshift ML을 사용하면 SQL을 사용하여 기계 학습 모델을 학습하고 예측하는 것이 쉬워집니다. Redshift ML은 Amazon SageMaker를 활용하여 모델을 학습한 뒤 SQL 함수로 노출하고 사용자는 SQL을 사용하여 직접 사용할 수 있습니다\n- Redshift Federated Query를 사용하면 Redshift가 고객의 OLTP 데이터베이스 (Postgres, MySQL 등)에 직접 연결하여 데이터를 가져올 수 있습니다. 이 편리한 기능으로 ETL 파이프라인을 통해 OLTP 출처에서 데이터를 추출할 필요가 없어집니다.\n- 슈퍼 스키마리스 처리: SUPER 반구조화 형식은 스키마가 없는 중첩 데이터를 포함할 수 있습니다. SUPER 형식의 값은 Redshift 문자열 및 숫자 스칼라, 배열 및 구조체로 구성될 수 있습니다. 사용자는 SUPER 유형을 사용할 때 미리 스키마를 정의할 필요가 없습니다. Redshift의 동적 형식 지정은 중첩 데이터를 감지할 수 있습니다.\n- Lambda와 함께하는 Redshift: Redshift는 AWS Lambda 코드를 지원하는 사용자 정의 함수(UDF)를 지원합니다. Lambda UDF는 Java, Go, PowerShell, Node.js, C#, Python 및 Ruby로 작성할 수 있습니다.\n\n# 마무리\n\n조금 긴 글이었죠? 이 글이 제 가장 긴 글입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제목에 언급된 \"8시간\"에도 불구하고, 이 블로그를 마무리하는 데 거의 일주일이 걸렸어요. Redshift 논문은 많은 새로운 내용을 제공해서 조금 힘들었죠. 게다가, 이번에는 코드 특화 접근 방식을 선택한 OLAP 시스템을 연구한 것이 처음이라서 (이전에 공부한 시스템들은 모두 벡터화를 사용했어요: BigQuery, Snowflake, DuckDB).\n\n코드 특화 외에도, Redshift의 주요 기능으로는 컴파일 서비스, Redshift 관리 스토리지, 그리고 데이터베이스 운영을 위해 머신 러닝을 적용한 것이 언급할만해요. 게다가, Redshift의 웜 풀 아키텍처는 Snowflake의 사전 웜 풀과 유사한데, 두 솔루션이 모두 컴퓨팅 스케일링의 지연 시간을 최소화하려고 노력하지만, Redshift의 경우는 머신 러닝 모델을 활용해서 작동한다는 점이 다르죠.\n\n지금은 Redshift가 백그라운드 작업에 머신 러닝을 명시적으로 사용한다는 유일한 시스템인 것으로 보여요. Snowflake나 BigQuery는 이를 언급하지 않았죠. (제가 놓친 부분이 있다면 알려주세요)\n\n이제 이만 헤어집니다. 다음 주에 또 만나요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 참고 자료\n\n논문: Amazon Redshift Re-invented — 2022\n\n문서: Amazon Redshift 공식 문서\n\nPowerPoint 프레젠테이션: Amazon Redshift에 대한 심층 학습 및 모범 사례\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 뉴스레터는 매주 블로그 형식의 이메일로, 내가 더 똑똑한 사람들로부터 배운 것들을 정리해 두는 공간입니다.\n\n그러니 나와 함께 배우고 성장하고 싶다면 여기에서 구독해 주세요: https://vutr.substack.com.\n","ogImage":{"url":"/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_0.png"},"coverImage":"/assets/img/2024-05-23-Ispentanother8hoursunderstandingthedesignofAmazonRedshiftHereswhatIfound_0.png","tag":["Tech"],"readingTime":19},{"title":"유튜브에서 배우는 LLMs 사용하기","description":"","date":"2024-05-23 13:47","slug":"2024-05-23-UsingLLMstoLearnFromYouTube","content":"\n\n![Using LLMs to Learn From YouTube](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_0.png)\n\n# 소개\n\n팟캐스트나 시청하고 싶은 비디오를 만나본 적이 있나요? 하지만 길이 때문에 시간을 내기 어려워한 적이 있나요? 이러한 형태의 내용의 특정 부분을 다시 참조할 수 있는 쉬운 방법을 바란 적이 있나요?\n\n저는 The Diary of a CEO와 같은 인기 팟캐스트의 YouTube 비디오들에 관해 많은 시간을 할애하기 어려운 문제에 직면해왔습니다. 사실 이러한 팟캐스트에서 다루는 많은 정보들은 빠른 구글 검색을 통해 손쉽게 찾을 수 있습니다. 그러나 저자가 열정적으로 어떤 것에 대한 견해를 표현하거나 성공한 기업가의 경험을 그들의 관점에서 듣는 것은 훨씬 더 통찰력과 명확함을 제공합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 문제로 동기부여 받으면서 LLM(언어 모델)을 기반으로 한 애플리케이션 및 개발에 대해 배우고 싶어졌습니다. 그래서 YouTube 동영상의 내용에 관한 질문을 할 수 있는 챗봇을 구축하기로 결정했습니다. 이 프레임워크인 RAG(Retrieval Augmented Generation)를 사용했습니다. 이후에, 이 어플리케이션을 LangChain, Pinecone, Flask, React를 사용하여 개발하고 AWS에 배포하는 경험에 대해 이야기하겠습니다:\n\n# 백엔드\n\nLLM이 사용자 정의 질문에 답변을 생성하는 소스로 YouTube 동영상의 대본을 사용할 것입니다. 이를 용이하게 하기 위해, 백엔드는 이를 실시간으로 검색하고 적절히 저장하여 사용할 수 있는 방법과 답변 생성에 사용할 수 있게 하는 방법이 필요합니다. 또한 사용자가 나중에 참조할 수 있도록 채팅 기록을 저장하는 방법도 있으면 좋겠습니다. 이제 이러한 요구 사항을 모두 충족시키기 위해 백엔드를 개발하는 방법에 대해 살펴보겠습니다.\n\n## 응답 생성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 대화형 질문 응답 도구는 관련 컨텍스트와 채팅 기록을 모두 고려하여 질문에 대한 응답을 생성할 수 있어야 합니다. 이는 아래에 설명된대로 대화 기억을 갖춘 데이터 검색 확장 생성을 사용하여 달성할 수 있습니다:\n\n![image](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_1.png)\n\n불분명한 부분을 명확히 하기 위해 다음과 같은 단계가 포함됩니다:\n\n- 질문 요약: 현재 질문과 채팅 기록을 적절한 프롬프트를 사용하여 단독 질문으로 요약합니다. 이를 위해 LLM에게 요청합니다.\n- 의미 검색: 다음으로, 이러한 축약된 질문과 가장 관련성 있는 YouTube 대본 청크를 검색해야 합니다. 대본 자체는 단어 및 구의 수치적 표현인 임베딩으로 저장되어 있습니다. 이 임베딩은 내용과 의미를 포착하는 임베딩 모델에 의해 학습되었습니다. 의미 검색 중에는 임베딩이 축약된 질문의 임베딩과 가장 유사한 각 대본 구성 요소를 검색합니다.\n- 컨텍스트 인식 생성: 이러한 검색된 대본 청크는 다시 LLM에게 다른 프롬프트로 사용되어 축약된 질문에 대답하도록 요청됩니다. 축약된 질문을 사용하면 생성된 답변이 현재 질문 및 채팅 중 사용자가 이전에 물었던 질문과 관련이 있는지 보장됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터 파이프라인\n\n이미 설명된 프로세스의 구현 단계에 들어가기 전에, YouTube 비디오 트랜스크립트 자체에 집중해 보겠습니다. 언급했듯이, RAG 프로세스의 시맨틱 검색 단계에서 효율적으로 검색하고 검색될 수 있도록 이들을 임베딩으로 저장해야 합니다. 이제 이를 위한 소스, 검색 방법 및 저장 방법을 살펴보겠습니다.\n\n- 소스: YouTube는 비디오 ID 및 자동 생성된 트랜스크립트와 같은 메타데이터에 액세스할 수 있도록 Data API를 제공합니다. 첫 번째로, 다양한 돈 전문가와 기업가가 개인 재무, 투자, 성공적인 비즈니스 구축에 대해 논의하는 The Diary of a CEO 팟캐스트 플레이리스트를 선택했습니다.\n- 검색: YouTube 비디오의 비디오 ID와 같은 메타데이터를 검색하는 데 책임 있는 한 클래스와, youtube-transcript-API Python 패키지를 사용하여 비디오 트랜스크립트를 검색하는 데 책임 있는 다른 클래스를 활용합니다. 이 트랜스크립트는 그들의 원시 형태로 JSON 파일로 저장됩니다.\n- 저장: 그런 다음, 트랜스크립트를 임베딩으로 변환하고 벡터 데이터베이스에 저장해야 합니다. 그러나 이 단계의 사전 조건은 각 질문에 가장 관련성 높은 텍스트 세그먼트를 얻는 동시에 LLM 프롬프트의 길이를 최소화하기 위해 이를 청크로 분할해야 한다는 것입니다. 이 요구 사항을 충족시키기 위해 본 요구 사항을 만족시키기 위해 본 사용자 정의 S3JsonFileLoader 클래스를 정의하고(상자 밖의 문제로 인해 일부 문제가 발생함), 텍스트 분할 객체를 사용하여 트랜스크립트를 로드할 때 분할합니다. 그런 다음, 오픈AI의 gpt-3.5-turbo 모델이 예상하는 임베딩으로 트랜스크립트 청크를 저장하기 위해 LangChain의 인터페이스를 이용하여 선택한 Vectorstore인 Pinecone Vectorstore에 연결합니다:\n\n```js\nimport os\n\nimport pinecone\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Pinecone\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nfrom chatytt.embeddings.s3_json_document_loader import S3JsonFileLoader\n\n# 트랜스크립트를 청크로 나누기 위한 스플리터 정의\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=pre_processing_conf[\"recursive_character_splitting\"][\"chunk_size\"],\n    chunk_overlap=pre_processing_conf[\"recursive_character_splitting\"][\n        \"chunk_overlap\"\n    ],\n)\n\n# 트랜스크립트 로드 및 분할\nloader = S3JsonFileLoader(\n    bucket=\"s3_bucket_name\",\n    key=\"transcript_file_name\",\n    text_splitter=text_splitter,\n)\ntranscript_chunks = loader.load(split_doc=True)\n\n# 관련 Pinecone 벡터스토어에 연결\npinecone.init(\n    api_key=os.environ.get(\"PINECONE_API_KEY\"),\n    environment=\"gcp-starter\"\n)\npinecone_index = pinecone.Index(os.environ.get(\"INDEX_NAME\"), pool_threads=4)\n\n# Pinecone에 트랜스크립트 청크를 임베딩으로 저장\nvector_store = Pinecone(\n    index=pinecone_index,\n    embedding=OpenAIEmbeddings(),\n    text_key=\"text\",\n)\nvector_store.add_documents(documents=transcript_chunks)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 주기적으로 실행되도록 구성된 워크플로를 이용하여 이러한 단계를 자동화하기 위해 몇 가지 AWS 서비스를 활용할 수도 있습니다. 저는 위에서 언급한 세 가지 단계마다 별도의 AWS Lamba 함수(필요한 리소스를 런타임에 필요에 따라 프로비저닝 및 활용하는 서버리스 컴퓨팅 형태)를 구현하고, 이러한 함수의 실행 순서를 AWS Step Functions(서버리스 오케스트레이션 도구)를 사용하여 정의합니다. 그런 다음, 이 워크플로는 매주 한 번 실행되도록 설정한 Amazon EventBridge 일정에 의해 실행됩니다:\n\n![이미지](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_2.png)\n\n## RAG 구현\n\n이제 우리가 선택한 재생 목록의 대본이 주기적으로 검색되고 임베딩으로 변환되어 저장되고 있는데, 이제 응용 프로그램의 핵심 백엔드 기능 구현으로 이동할 수 있습니다. 즉, 사용자 정의 질문에 대한 답변을 생성하는 프로세스를 구현해야 합니다. 다행히 LangChain은 이 작업을 완벽하게 수행하는 ConversationalRetrievalChain을 기본 제공합니다! 필요한 것은 쿼리, 채팅 기록, 대본 청크를 검색하는 데 사용할 수 있는 벡터 저장소 개체 및 선택한 LLM을 이 체인에 전달하는 것뿐입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport pinecone\nfrom langchain.vectorstores import Pinecone\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\n# 세맨틱 검색을 수행할 벡터 저장소를 정의합니다. 이를 위해 Pinecone 벡터 데이터베이스에 대해 세맨틱 검색을 수행합니다.\npinecone.init(\n    api_key=os.environ.get(\"PINECONE_API_KEY\"), environment=\"gcp-starter\"\n)\npinecone_index = pinecone.Index(os.environ.get(\"INDEX_NAME\"), pool_threads=4)\nvector_store = Pinecone(\n    index=pinecone_index,\n    embedding=OpenAIEmbeddings(),\n    text_key=\"text\",\n)\n\n# RAG에서 대화 기억을 갖고 있는 단계를 수행할 검색 연쇄를 정의합니다.\nchain = ConversationalRetrievalChain.from_llm(\n    llm=ChatOpenAI(), retriever=vector_store.as_retriever()\n)\n\n# 현재 질문과 채팅 이력을 전달하여 체인을 호출합니다.\nresponse = chain({\"question\": query, \"chat_history\": chat_history})[\"answer\"]\n```\n\n## 채팅 이력 저장\n\n백엔드는 이제 질문에 대한 답변을 생성할 수 있지만 사용자가 이전 채팅 내용을 참조할 수 있도록 채팅 이력을 저장하고 검색할 수도 있으면 좋을 것입니다. 이는 동일한 항목에 대한 다른 사용자의 액세스 패턴을 알려진 대로 처리하는 NoSQL 데이터베이스인 DynamoDB를 사용하기로 결정했습니다. 이 데이터베이스는 이러한 형식의 비구조적 데이터를 처리하는 빠른 속도와 비용 효율성으로 알려져 있습니다. 추가로 boto3 SDK는 데이터베이스와 상호 작용을 단순화하여 저장 및 검색에 몇 가지 함수만 필요합니다:\n\n```js\nimport os\nimport time\nfrom typing import List, Any\n\nimport boto3\n\ntable = boto3.resource(\"dynamodb\").Table(os.environ.get(\"CHAT_HISTORY_TABLE_NAME\"))\n\ndef fetch_chat_history(user_id: str) -\u003e str:\n    response = table.get_item(Key={\"UserId\": user_id})\n    return response[\"Item\"]\n\n\ndef update_chat_history(user_id: str, chat_history: List[dict[str, Any]]):\n    chat_history_update_data = {\n        \"UpdatedTimestamp\": {\"Value\": int(time.time()), \"Action\": \"PUT\"},\n        \"ChatHistory\": {\"Value\": chat_history, \"Action\": \"PUT\"},\n    }\n    table.update_item(\n        Key={\"UserId\": user_id}, AttributeUpdates=chat_history_update_data\n    )\n\n\ndef is_new_user(user_id: str) -\u003e bool:\n    response = table.get_item(Key={\"UserId\": user_id})\n    return response.get(\"Item\") is None\n\n\ndef create_chat_history(user_id: str, chat_history: List[dict[str, Any]]):\n    item = {\n        \"UserId\": user_id,\n        \"CreatedTimestamp\": int(time.time()),\n        \"UpdatedTimestamp\": None,\n        \"ChatHistory\": chat_history,\n    }\n    table.put_item(Item=item)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## API를 통해 로직 노출하기\n\n이제 모든 핵심 기능을 다루었지만 사용자가 상호작용하는 앱의 클라이언트 측은 이러한 프로세스를 트리거하고 활용하는 방법이 필요합니다. 이를 용이하게하기 위해 Flask API 내의 각 로직 조각(응답 생성, 채팅 기록 저장, 채팅 기록 검색)은 개별 엔드포인트를 통해 노출되며, 프론트 엔드에서 호출될 것입니다:\n\n```js\nfrom dotenv import load_dotenv\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\n\nfrom chatytt.chains.standard import ConversationalQAChain\nfrom chatytt.vector_store.pinecone_db import PineconeDB\nfrom server.utils.chat import parse_chat_history\nfrom server.utils.dynamodb import (\n    is_new_user,\n    fetch_chat_history,\n    create_chat_history,\n    update_chat_history,\n)\n\nload_dotenv()\napp = Flask(__name__)\n\n# 서버와 클라이언트가 각각 호스팅되므로 Cross Origin Resource Sharing을 활성화\nCORS(app)\n\npinecone_db = PineconeDB(index_name=\"youtube-transcripts\", embedding_source=\"open-ai\")\nchain = ConversationalQAChain(vector_store=pinecone_db.vector_store)\n\n@app.route(\"/get-query-response/\", methods=[\"POST\"])\ndef get_query_response():\n    data = request.get_json()\n    query = data[\"query\"]\n\n    raw_chat_history = data[\"chatHistory\"]\n    chat_history = parse_chat_history(raw_chat_history)\n    response = chain.get_response(query=query, chat_history=chat_history)\n\n    return jsonify({\"response\": response})\n\n\n@app.route(\"/get-chat-history/\", methods=[\"GET\"])\ndef get_chat_history():\n    user_id = request.args.get(\"userId\")\n\n    if is_new_user(user_id):\n        response = {\"chatHistory\": []}\n        return jsonify({\"response\": response})\n\n    response = {\"chatHistory\": fetch_chat_history(user_id=user_id)[\"ChatHistory\"]}\n\n    return jsonify({\"response\": response})\n\n\n@app.route(\"/save-chat-history/\", methods=[\"PUT\"])\ndef save_chat_history():\n    data = request.get_json()\n    user_id = data[\"userId\"]\n\n    if is_new_user(user_id):\n        create_chat_history(user_id=user_id, chat_history=data[\"chatHistory\"])\n    else:\n        update_chat_history(user_id=user_id, chat_history=data[\"chatHistory\"])\n\n    return jsonify({\"response\": \"chat saved\"})\n\n\nif __name__ == \"__main__\":\n    app.run(debug=True, port=8080)\n```\n\n마지막으로, 세 개의 엔드포인트를 하나의 함수로 래핑하여 AWS Lambda를 사용하고, API Gateway 리소스에 의해 트리거되는 방식으로 요청을 올바른 엔드포인트로 보내도록 하는 방법을 설명합니다. 이제 이 설정의 흐름은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 이 전체에 사용되는 각 섹션에 대한 전용 기능 컴포넌트를 활용하여 채팅 봇 애플리케이션에서 기대할 수 있는 모든 일반 요구 사항을 다룹니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 사용자 입력을 보내는 채팅 버튼이 있는 컨테이너입니다.\n- 사용자 입력 및 답변이 표시되는 채팅 피드가 있습니다.\n- 채팅 기록, 새로운 채팅 버튼 및 채팅 저장 버튼이 있는 사이드바가 있습니다.\n\n이 컴포넌트들 간의 상호작용과 데이터 흐름은 아래와 같이 설명됩니다:\n\n![Components Interaction](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_4.png)\n\n세 가지 엔드포인트로의 API 호출 및 클라이언트 측에서 관련 변수의 상태 변경은 각각의 기능 컴포넌트에서 정의됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 질문마다 생성된 답변을 가져오는 논리:\n\n```js\nimport React from \"react\";\nimport {chatItem} from \"./LiveChatFeed\";\n\ninterface Props {\n    setCurrentChat: React.SetStateAction\u003cany\u003e\n    userInput: string\n    currentChat: Array\u003cchatItem\u003e\n    setUserInput: React.SetStateAction\u003cany\u003e\n}\n\nfunction getCurrentChat({setCurrentChat, userInput, currentChat, setUserInput}: Props){\n    // 현재 채팅은 라이브 채팅 피드에 표시됩니다. LLM 응답을 기다리기 전에\n    // 사용자 질문을 제공하기 위해 API에 대답을 요청하기 전에 복사하여\n    // 별도 변수에 전달하고 현재 채팅에 추가합니다.\n    const userInputText = userInput\n    setUserInput(\"\")\n    setCurrentChat([\n        ...currentChat,\n        {\n            \"text\": userInputText,\n            isBot: false\n        }\n    ])\n\n    // 포스트 요청을 위한 API 페이로드 생성\n    const options = {\n        method: 'POST',\n        headers: {\n            \"Content-Type\": 'application/json',\n            'Accept': 'application/json'\n        },\n        body: JSON.stringify({\n            query: userInputText,\n            chatHistory: currentChat\n        })\n    }\n\n    // 엔드포인트에 핑을 보내 응답을 기다린 후 현재 채팅에 추가하여\n    // 라이브 채팅 피드에 표시\n    fetch(`${import.meta.env.VITE_ENDPOINT}get-query-response/`, options).then(\n        (response) =\u003e response.json()\n    ).then(\n        (data) =\u003e {\n            setCurrentChat([\n                ...currentChat,\n                {\n                    \"text\": userInputText,\n                    \"isBot\": false\n                },\n                {\n                    \"text\": data.response,\n                    \"isBot\": true\n                }\n            ])\n        }\n    )\n}\n\nexport default getCurrentChat\n```\n\n2. 사용자가 채팅 저장 버튼을 클릭할 때 채팅 기록을 저장하는 방법:\n\n```js\nimport React, {useState} from \"react\";\nimport {chatItem} from \"./LiveChatFeed\";\nimport saveIcon from \"../assets/saveicon.png\"\nimport tickIcon from \"../assets/tickicon.png\"\n\ninterface Props {\n    userId: String\n    previousChats: Array\u003cArray\u003cchatItem\u003e\u003e\n}\n\nfunction SaveChatHistoryButton({userId, previousChats}: Props){\n    // 현재 채팅이 저장되었는지 여부를 결정하는 상태 정의합니다.\n    const [isChatSaved, setIsChatSaved] = useState(false)\n\n    // 채팅 기록을 저장하는 PUT 요청 페이로드 생성\n    const saveChatHistory = () =\u003e {\n        const options = {\n            method: 'PUT',\n            headers: {\n                \"Content-Type\": 'application/json',\n                'Accept': 'application/json'\n            },\n            body: JSON.stringify({\n                \"userId\": userId,\n                \"chatHistory\": previousChats\n            })\n        }\n\n        // 채팅 기록이 성공적으로 저장되면 API에 핑 보내고\n        // isChatSaved 상태를 true로 설정합니다\n        fetch(`${import.meta.env.VITE_ENDPOINT}save-chat-history/`, options).then(\n            (response) =\u003e response.json()\n        ).then(\n            (data) =\u003e {\n                setIsChatSaved(true)\n            }\n        )\n    }\n\n    // isChatSaved 상태 값에 따라 저장된 채팅 버튼에 동적으로 텍스트 표시\n    return (\n        \u003cbutton\n            className=\"save-chat-history-button\"\n            onClick={() =\u003e {saveChatHistory()}\n        \u003e \u003cimg className={isChatSaved?\"tick-icon-img\":\"save-icon-img\"} src={isChatSaved?tickIcon:saveIcon}/\u003e\n        {isChatSaved?\"Chats Saved\":\"Save Chat History\"}\n        \u003c/button\u003e\n    )\n}\n\nexport default SaveChatHistoryButton\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 앱이 처음으로 로드될 때 채팅 기록을 검색합니다:\n\n```js\nimport React from \"react\";\nimport {chatItem} from \"./LiveChatFeed\";\n\ninterface Props {\n    userId: String\n    previousChats: Array\u003cArray\u003cchatItem\u003e\u003e\n    setPreviousChats: React.SetStateAction\u003cany\u003e\n}\n\nfunction getUserChatHistory({userId, previousChats, setPreviousChats}: Props){\n    // GET 요청을 위한 페이로드 생성\n    const options = {\n            method: 'GET',\n            headers: {\n                \"Content-Type\": 'application/json',\n                'Accept': 'application/json'\n            }\n        }\n\n        // GET 요청이므로 사용자 ID를 쿼리 매개변수로 전달합니다.\n        // API에서 반환된 채팅 기록으로 이전 채팅 상태를 설정합니다.\n        fetch(`${import.meta.env.VITE_ENDPOINT}get-chat-history/?userId=${userId}`, options).then(\n            (response) =\u003e response.json()\n        ).then(\n            (data) =\u003e {\n            if (data.response.chatHistory.length \u003e 0) {\n                setPreviousChats(\n                        [\n                            ...previousChats,\n                            ...data.response.chatHistory\n                        ]\n                    )\n                }\n            }\n        )\n}\n\nexport default getUserChatHistory\n```\n\nUI 자체에 대해, ChatGPT의 인터페이스와 매우 유사한 것을 선택했습니다. 중앙의 채팅 피드 구성 요소와 채팅 기록과 같은 지원 콘텐츠를 담은 사이드바가 있습니다. 사용자를 위한 편안함 기능으로는 가장 최근에 생성된 채팅 항목으로 자동 스크롤링 및 로그인시 이전 채팅이 로드되는 등이 있습니다. 최종 UI 모습은 아래와 같습니다:\n\n이제 완전히 기능하는 UI가 준비되었으니 온라인 사용을 위해 호스팅해야 합니다. 저는 AWS Amplify를 사용하여 이를 수행하기로 선택했습니다. Amplify는 리소스 프로비저닝 및 웹 애플리케이션 호스팅을 처리하는 완전 관리형 웹 호스팅 서비스 중 하나입니다. 앱의 사용자 인증은 Amazon Cognito에 의해 관리되며 사용자 회원가입, 로그인, 자격 증명 저장 및 관리를 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_5.png\" /\u003e\n\n# ChatGPT 응답과 비교\n\n앱을 구축하는 과정을 논의했으니, 몇 가지 질문에 대한 생성된 응답을 심도 있게 살펴보고, 이를 ChatGPT\\*에 제시된 동일한 질문과 비교해 보겠습니다.\n\n저희 애플리케이션에서 사용되는 LLM에 제시된 기본 프롬프트에는 시맨틱 검색 단계에서 검색된 추가 컨텍스트(관련 트랜스크립트 청킹 형태)가 포함될 것이기 때문에 이러한 비교는 본질적으로 \"부당\"한 것이라는 점에 유의하십시오. 그러나, RAG를 사용하여 생성된 프롬프트와 같은 기본 LLM에 의해 생성된 응답과 어떤 차이가 있는지 정성적으로 평가할 수 있게 해줄 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\\*All ChatGPT responses are from gpt-3.5, since this was the model used in the application.\n\n## 예시 1:\n\nSteven Bartlett가 금융 작가이자 투자자인 Morgan Housel과의 대화를 나누는 이 비디오의 내용에 대해 알고 싶습니다. 비디오 제목을 보면 집 구입에 반대하는 것으로 보이지만, 시간이 없어서 전체 내용을 확인할 수 없다고 가정해 봅시다. 여기 저는 이에 대해 애플리케이션과의 대화 스니펫을 보여드립니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_6.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 예시 2\n\n아래는 수익화 및 인수 전문가인 Alex Hormozi와의 이 토론에 대한 채팅에서 일부 스니펫이 있습니다. 비디오 제목으로부터, 그는 비즈니스를 성공적으로 확장하는 데에 대해 잘 알고 있다는 것 같아, 그에 대해 더 많은 세부 정보를 요청했습니다:\n\n![이미지](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_8.png)\n\n이것은 합리적인 대답으로 보이지만, 동일한 질문 라인에서 더 많은 정보를 추출할 수 있는지 확인해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![LLM 이미지1](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_9.png)\n\n![LLM 이미지2](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_10.png)\n\nYouTube 트랜스크립트에서 LLM이 추출할 수 있는 세부 수준에 주목해보세요. 위의 내용은 비디오의 17:00-35:00 타임스탬프 주변 15~20분 부분에서 찾을 수 있습니다.\n\nChatGPT에 같은 질문을 한 결과, 기업가에 관한 일반적인 답변만 제공되었지만 비디오 트랜스크립트 내용을 통해 사용할 수 있는 세부 정보가 부족합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![사용 예시 이미지](/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_11.png)\n\n# 배포\n\n마지막으로 논의할 주제는 AWS에서 각 구성 요소를 배포하는 과정입니다. 데이터 파이프라인, 백엔드 및 프론트엔드는 각각 자체 CloudFormation 스택(여러 AWS 리소스의 모음) 내에 포함되어 있습니다. 이렇게 각각을 격리된 상태에서 배포할 수 있도록 해줌으로써, 개발 중에 전체 앱이 불필요하게 다시 배포되지 않도록 합니다. 저는 AWS SAM (서버리스 애플리케이션 모델)을 사용하여 각 구성 요소에 대한 인프라를 코드로 배포하는데 활용하고 있습니다. SAM 템플릿 사양 및 CLI를 활용합니다:\n\n- SAM 템플릿 사양 - AWS CloudFormation을 확장하는 용도로 사용되는 간결한 구문으로, AWS 리소스의 모음을 정의하고 구성하는 데 사용됩니다. 리소스 간 상호 작용 방식 및 필요한 권한을 지정합니다.\n- SAM CLI - SAM 템플릿에 정의된 리소스를 빌드하고 배포하는 데 사용되는 명령줄 도구입니다. 애플리케이션 코드 및 종속성의 패키징, SAM 템플릿을 CloudFormation 구문으로 변환하고 CloudFormation에서 개별 스택으로 템플릿을 배포하는 작업을 처리합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 글 전체 템플릿(자원 정의)을 모두 포함하는 대신, 우리가 이야기한 각 서비스에 대해 특정 관심 영역을 강조하겠습니다.\n\nAWS 리소스에 민감한 환경 변수 전달하기:\n\n유튜브 데이터 API, OpenAI API, Pinecone API와 같은 외부 구성 요소는 애플리케이션 전체에서 많이 의존합니다. 이러한 값을 CloudFormation 템플릿에 하드코딩하고 '매개변수'로 전달하는 것이 가능하지만, 더 안전한 방법은 AWS SecretsManager에서 각각의 비밀을 만들고 다음과 같이 해당 템플릿에서 이 비밀을 참조하는 것입니다:\n\n```js\nParameters: YoutubeDataAPIKey: Type: String;\nDefault: \"{resolve:secretsmanager:youtube-data-api-key:SecretString:youtube-data-api-key}\";\nPineconeAPIKey: Type: String;\nDefault: \"{resolve:secretsmanager:pinecone-api-key:SecretString:pinecone-api-key}\";\nOpenaiAPIKey: Type: String;\nDefault: \"{resolve:secretsmanager:openai-api-key:SecretString:openai-api-key}\";\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n람다 함수 정의:\n\n이 서버리스 코드 단위들은 데이터 파이프라인의 중심을 형성하며 웹 애플리케이션의 백엔드로의 진입점 역할을 합니다. SAM을 사용하여 이들을 배포하는 것은 호출될 때 함수가 실행해야 할 코드의 경로를 정의하는 것과 필요한 권한 및 환경 변수를 함께 지정하는 것만으로 간단합니다. 다음은 데이터 파이프라인에서 사용되는 함수 중 하나의 예시입니다:\n\n```js\nFetchLatestVideoIDsFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ../code_uri/.\n      Handler: chatytt.youtube_data.lambda_handlers.fetch_latest_video_ids.lambda_handler\n      Policies:\n        - AmazonS3FullAccess\n      Environment:\n        Variables:\n          PLAYLIST_NAME:\n            Ref: PlaylistName\n          YOUTUBE_DATA_API_KEY:\n            Ref: YoutubeDataAPIKey\n```\n\nAmazon States 언어로 데이터 파이프라인의 정의를 검색하는 것:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개별 람다 함수에 Step Functions을 오케스트레이터로 사용하려면, Amazon States Language에서 각 함수가 실행되어야 하는 순서 및 최대 재시도 횟수와 같은 구성을 정의해야 합니다. 이 작업을 간단하게 수행하는 방법은 Step Functions 콘솔의 Workflow Studio를 사용하여 워크플로우를 다이어그램으로 만든 다음, 해당 워크플로우의 자동 생성된 ASL 정의를 적절히 수정할 수 있는 시작점으로 활용하는 것입니다. 그러면 이를 CloudFormation 템플릿에 링크하여 해당 위치에 정의하는 대신에 사용할 수 있습니다:\n\n```js\nEmbeddingRetrieverStateMachine:\n  Type: AWS::Serverless::StateMachine\n  Properties:\n    DefinitionUri: statemachine/embedding_retriever.asl.json\n    DefinitionSubstitutions:\n      FetchLatestVideoIDsFunctionArn: !GetAtt FetchLatestVideoIDsFunction.Arn\n      FetchLatestVideoTranscriptsArn: !GetAtt FetchLatestVideoTranscripts.Arn\n      FetchLatestTranscriptEmbeddingsArn: !GetAtt FetchLatestTranscriptEmbeddings.Arn\n    Events:\n      WeeklySchedule:\n        Type: Schedule\n        Properties:\n          Description: Schedule to run the workflow once per week on a Monday.\n          Enabled: true\n          Schedule: cron(0 3 ? * 1 *)\n    Policies:\n    - LambdaInvokePolicy:\n        FunctionName: !Ref FetchLatestVideoIDsFunction\n    - LambdaInvokePolicy:\n        FunctionName: !Ref FetchLatestVideoTranscripts\n    - LambdaInvokePolicy:\n        FunctionName: !Ref FetchLatestTranscriptEmbeddings\n```\n\n이 포스트에서 논의한 데이터 파이프라인을 위해 사용된 ASL 정의는 여기에서 확인할 수 있습니다.\n\nAPI 리소스 정의:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n웹 애플리케이션용 API가 프론트엔드와 별도로 호스팅될 예정이므로 API 리소스를 정의할 때 CORS (Cross-Origin Resource Sharing) 지원을 활성화해야 합니다:\n\n```js\nChatYTTApi: Type: AWS::Serverless::Api;\nProperties: StageName: Prod;\nCors: AllowMethods: \"'*'\";\nAllowHeaders: \"'*'\";\nAllowOrigin: \"'*'\";\n```\n\n위 설정을 통해 두 리소스가 서로 자유롭게 통신할 수 있게 됩니다. 람다 함수를 통해 액세스할 수 있는 여러 엔드포인트는 다음과 같이 정의할 수 있습니다:\n\n```js\nChatResponseFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: python3.9\n      Timeout: 120\n      CodeUri: ../code_uri/.\n      Handler: server.lambda_handler.lambda_handler\n      Policies:\n        - AmazonDynamoDBFullAccess\n      MemorySize: 512\n      Architectures:\n        - x86_64\n      Environment:\n        Variables:\n          PINECONE_API_KEY:\n            Ref: PineconeAPIKey\n          OPENAI_API_KEY:\n            Ref: OpenaiAPIKey\n      Events:\n        GetQueryResponse:\n          Type: Api\n          Properties:\n            RestApiId: !Ref ChatYTTApi\n            Path: /get-query-response/\n            Method: post\n        GetChatHistory:\n          Type: Api\n          Properties:\n            RestApiId: !Ref ChatYTTApi\n            Path: /get-chat-history/\n            Method: get\n        UpdateChatHistory:\n          Type: Api\n          Properties:\n            RestApiId: !Ref ChatYTTApi\n            Path: /save-chat-history/\n            Method: put\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리액트 앱 리소스를 정의하는 방법:\n\nAWS Amplify를 사용하면 관련 Github 저장소에 대한 참조와 적절한 액세스 토큰을 사용하여 애플리케이션을 빌드하고 배포할 수 있습니다:\n\n```js\nAmplifyApp:\n    Type: AWS::Amplify::App\n    Properties:\n      Name: amplify-chatytt-client\n      Repository: \u003chttps://github.com/suresha97/ChatYTT\u003e\n      AccessToken: '{resolve:secretsmanager:github-token:SecretString:github-token}'\n      IAMServiceRole: !GetAtt AmplifyRole.Arn\n      EnvironmentVariables:\n        - Name: ENDPOINT\n          Value: !ImportValue 'chatytt-api-ChatYTTAPIURL'\n```\n\n한 번 저장소 자체에 액세스할 수 있으면, Amplify는 앱을 구축하고 배포하는 방법에 대한 지침이 포함된 구성 파일을 찾습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```yaml\nversion: 1\nfrontend:\n  phases:\n    preBuild:\n      commands:\n        - cd client\n        - npm ci\n    build:\n      commands:\n        - echo \"VITE_ENDPOINT=$ENDPOINT\" \u003e\u003e .env\n        - npm run build\n  artifacts:\n    baseDirectory: ./client/dist\n    files:\n      - \"**/*\"\n  cache:\n    paths:\n      - node_modules/**/*\n```\n\n덤으로, 계속적인 배포 프로세스를 자동화하기 위해 모니터링할 브랜치 리소스를 정의하여 추가 커밋이 발생할 때 앱을 자동으로 재배포할 수도 있습니다:\n\n```yaml\nAmplifyBranch:\n  Type: AWS::Amplify::Branch\n  Properties:\n    BranchName: main\n    AppId: !GetAtt AmplifyApp.AppId\n    EnableAutoBuild: true\n```\n\n이렇게 최종 배포가 완료되면, AWS Amplify 콘솔에서 제공된 링크를 통해 누구에게나 접근 가능합니다. 이렇게 접근한 앱의 데모 기록은 다음에서 확인할 수 있습니다:```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n높은 수준에서 다음 단계를 다뤘습니다:\n\n- 콘텐츠 수집 및 저장을 위한 데이터 파이프라인 구축.\n- 대화 기억을 활용한 검색 증강 생성을 수행하는 백엔드 서버 구성.\n- 생성된 답변 및 채팅 기록을 제공하는 사용자 인터페이스 설계.\n- 이러한 구성 요소를 연결하고 배포하여 가치를 제공하고 시간을 절약하는 솔루션을 생성하는 방법.\n\n이러한 응용프로그램이 학습 및 개발 목적의 YouTube 비디오 소비를 최적화하고 어떤 방식으로든 간소화할 수 있는 방법을 알아보았습니다. 그러나 이러한 방법은 동일하게 직장에서 내부 사용이나 고객을 위한 솔루션을 확장하는 데 쉽게 적용할 수 있습니다. 이것이 LLMs의 인기와 특히 RAG 기술이 많은 조직에서 큰 주목을 받는 이유입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마크다운 형식으로 표 태그를 변경해보세요.\n\n# 감사의 글\n\nDiary of a CEO 팀에게 이 프로젝트와 이 글 작성 중에 이 플레이리스트의 비디오 대본을 사용할 수 있는 허락을 받아 감사의 말씀을 전합니다.\n\n모든 이미지는 별도 명시가 없는 한 저자가 찍은 것입니다.\n","ogImage":{"url":"/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_0.png"},"coverImage":"/assets/img/2024-05-23-UsingLLMstoLearnFromYouTube_0.png","tag":["Tech"],"readingTime":23},{"title":"접근성 있는 비디오 게임 디자인하기","description":"","date":"2024-05-23 13:43","slug":"2024-05-23-Designingaccessiblevideogames","content":"\n\n비디오 게임은 오직 즐거움의 형태에 머무르는 것이 아닙니다; 그것들은 이야기 전달, 소셜 상호 작용, 그리고 몰입형 경험을 위한 강력한 매체입니다.\n\n사람들이 여가 시간을 게이밍에 할애하는 이유는 많습니다. 시작하기에, 그들은 현실에서 벗어나 다른 사람들과 연결되는 방법입니다. 누군가가 왜 게임을 원할 수 있는 가능한 이유들을 모두 나열할 수 있지만, 그것은 그 자체로 한 섹션이 될 것입니다.\n\n모든 사람은 게임의 독특하고 몰입적인 세계를 즐길 자격이 있지만, 불행하게도 그것이 많은 게임에는 해당되지 않습니다. 지난 몇 년 동안 접근성 있는 게임 디자인으로의 움직임이 있었지만, 아직 가야 할 길은 멀습니다.\n\n많은 게임이 일부 접근성 설정과 기능을 구현하고 있지만, 몇몇 회사만이 시간, 예산, 그리고 능력이 The Last of Us Part II만큼 멋지게 접근 가능하도록하는 게임을 만들 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위와 같이, 접근성에 대한 대화를 중요시하고 시작부터 구현하는 것이 중요합니다. 복잡한 설정 메뉴가 모든 게임에 가능하지는 않을 수 있음을 이해합니다, 특히 소규모 스튜디오의 경우에는 더 그렇습니다.\n\n예산이 전무한 소규모 인디 스튜디오에서 근무하고 있는 사람으로서, 제가 이해한다는 것에 신뢰해 주세요.\n\n게임을 접근성 있게 디자인하는 것은 모든 플레이어에 도움이 되며, 접근성을 고려한 기능은 모든 능력을 가진 플레이어들에게 널리 사용됩니다.\n\n자막을 예로 들어 보겠습니다. 명백히 자막은 청각 장애가 있는 플레이어들에게 매우 유용한 도구이지만, 청각 장애가 없는 플레이어들도 자주 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노트: 이 기사는 접근성 있는 게임을 디자인하는 방법 중 일부만 다룹니다.\n\n더 포괄적인 목록이 궁금하시다면 '게임 접근성 지침'을 확인해보세요.\n\n여러분께서는 직접 조사를 하시고, 무엇보다도 다양한 능력을 가진 실제 사용자들로 게임을 테스트하는 것을 권장합니다.\n\n# 어시스트 모드 vs 의도한 경험\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일부 플레이어는 게임 자체의 도움을 필요로하여 제시된 도전들을 극복할 수 있습니다. 특정 게임들은 조준장치를 추가하여 플레이어가 조준, 조향, 내비게이션, 퍼즐 해결 또는 장애물 극복 등 다양한 방식으로 도움을 받을 수 있도록 합니다. 이렇게 함으로써, 플레이어는 게임의 난이도를 맞춤 설정하고 자신의 속도에 맞춰 게임 콘텐츠를 즐길 수 있습니다.\n\n일부 게임 회사들 사이에서 이러한 보조가 어떻게 게임의 정신이나 목적을 망치는지에 대한 논쟁이 있습니다.\n\n특정 프랜차이즈의 개발자들과 팬들은 종종 \"프롬 소프트웨어의 '세키로: 섀도우 다이 트와이스(Sekiro: Shadows Die Twice)'나 Sloclap의 '시퍼(Sifu)'와 같은 게임에 쉬운 난이도나 보조 게임 설정을 추가하는 것을 반대하며, 예술적 방향성과 개발자의 목표인 형벌적인 경험을 만들려는 것을 인용하며 다른 난이도 모드 추가는 '망치게 될 것'이라고 주장합니다.\"\n\n만약 다크 소울즈(Dark Souls)이 쉬웠다면, 다크 솔울즈가 아니었을 것입니다. 이는 사실일 수 있지만, 접근성 옵션은 게임을 쉽게 만드는 것이 아니라 광범위한 대중에 渙근하게 하는 것을 목적으로 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n게임이 제공하는 체험을 제한하거나 묽게 만드는 것이 아닙니다. 만약 당신의 게임이 숲을 통해 야생 동물을 쫓는 긴장감을 제공하길 원한다면, 그것이 플레이어 경험으로 추구해야 할 것입니다.\n\n모든 실력 수준의 플레이어는 게임을 플레이하는 동안 도전과 재미를 동시에 찾고 있습니다. 에임 어시스트와 같은 기능을 도입하면 처음에는 플레이어가 속임수를 쓰는 것을 느낄 수도 있지만, 현실은 그렇지 않습니다. 에임 어시스트를 추가하는 예시에서는, 에임에 대한 신체적 제약을 겪는 개인들에게 기회를 제공하여 게임을 원활히 탐험하고, 멋진 느낌을 느낄 수 있게 합니다.\n\n플레이어가 게임을 진행하는 데 도움이 필요하지 않은데도 어시스트 모드를 사용할까봐 걱정된다면, 경고 문구를 추가하는 것을 고려해보세요.\n\n인기 있는 인디 플랫포머인 'Celeste'는 플레이어가 게임을 자신의 요구에 맞게 조정할 수 있도록 허용하면서도, 이것이 게임을 플레이하는 방식이 아니라는 경고를 제공하는 뛰어난 작업을 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n게임 제작자 도구킷이 말하듯이, 접근성과 게임이 의도대로 플레이되는 것 사이의 균형을 맞추는 것은 하나의 중요한 요소, 소통에 달려 있어요.\n\n우리가 제대로 소통한다면, 사용자들은 게임이 어떻게 플레이되어야 하는지 알게 될 거예요. 특정 보조 모드나 설정을 켜야 하는지 결정하는 것은 플레이어의 몫이에요. 이는 그들을 위해 디자인된 의도된 경험을 변경할 수 있어요.\n\n난이도는 게임의 일부입니다. 그러나 플레이어가 물리적 또는 정신적으로 그것을 완료할 수 없는 정도로 게임을 너무 어렵게 만들면, 그들은 그것을 전혀 플레이할 수 없게 될 거에요.\n\n# 멀티플레이어 게임에서의 접근성 균형 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금, 지금. 방 안의 코끼리에 대해 얘기해 보죠: 멀티플레이어 게임. 멀티플레이 경험을 공정하게 유지하면서 접근성 높은 것으로 만드는 방법은 뭘까요?\n\nAPX 프레임워크는 이를 \"하우스 룰\"이라고 부릅니다.\n\n플레이어들은 온라인에서 다른 사람들과 맞붙을 때 선택지를 받을 수 있습니다. 플레이어들은 특정 설정(에임 어시스트, 매크로 등), 게임 옵션(매치 길이, 게임 모드 등), 그리고/또는 특정 실력 수준의 플레이어들과만 플레이할지 선택할 수 있습니다.\n\n![Designingaccessiblevideogames_0](/assets/img/2024-05-23-Designingaccessiblevideogames_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 플레이어들이 특정 설정으로 다른 사람들에게 이점을 준다고 느낀다면, 그들은 해당 설정을 사용하지 않는 플레이어들과 함께 대기열에 들 수 있습니다.\n\n이렇게 함으로써 플레이어 간 의사 소통에 관한 문제도 해결할 수 있습니다. 예를 들어, 음성 채팅 없이 게임을 선호하는 플레이어들 또는 그러한 방식을 수용할 수 있는 플레이어들과 온라인 멀티플레이 매치를 우선적으로 매칭하는 옵션을 제공하세요. 의사소통에 크게 의존하는 협력 게임에서는 음성 대화를 할 수 없는 플레이어들로 인해 팀원들이 좌절할 수도 있습니다. 이러한 좌절은 게임에서 해당 플레이어를 제거하거나 미래 매치에서 제외시킬 수도 있습니다.\n\n# 저장 — 자동 및 수동\n\n몇몇 사람들은 어려운 도전에 맞서고 같은 레벨을 통과하기 위해 끊임없이 시간을 보내는 것을 좋아합니다 (FromSoftware 팬들에게 주목!).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 사람들은 그렇지 않을 수도 있습니다. 원하는 때에 게임을 저장하고 싶다는 것은 단순히 개인적인 취향일 수도 있고, 신체적, 정신적 스트레스를 덜기 위한 문제일 수도 있습니다.\n\n신체적 장애를 가진 플레이어들은 힘든 동작이나 도전적인 상황을 반복하기 위해 게임을 저장해야 할 수도 있습니다. 가장 유명한 게임 메커니즘 중 하나를 예를 들어보겠습니다: 퀵타임 이벤트. 특히 버튼 누르기입니다.\n\n(이상적으로는 버튼을 연타하는 부분을 우회하거나 그 부분을 완전히 제거할 방법을 추가하고 싶지만, 이 예시를 계속 진행해 봅시다.)\n\n사용자가 방금 큰 무서운 괴물을 피하기 위해 \"X\"를 연타해야 했던 작업을 끝냈다고 상상해봅시다. 안도의 한숨을 내쉬며 그 다음 장면으로 나아갑니다. 은어, 저거는 못 봤네요; 건너 돌다가 절벽으로 떨어지고 큰 “게임 오버”가 화면에 나타납니다. 다시 시도하고, 이미 따가운 버튼 누르기 손이 아팠던 사용자는 그 섹션을 다시 해야 한다는 걸 깨달을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일부 플레이어들은 그 섹션을 다시 시작하면서 한숨을 쉴 수도 있지만, 다른 사람들은 그 섹션을 다시 완료할 물리적 또는 정신적 능력이 되지 않을 수도 있어요.\n\n버튼을 연담하다 보니 플레이어에게 신체적으로 지친 상태가 되어 하루 쉬고 다음 날 다시 시도해야 할 수도 있어요. 다음 날이 왔지만, 다시 시도하여 실패하고 다시 쉬고 다음 날 다시 시도해야 할 수도 있어요. 즐겁지 않죠.\n\n이 도전은 반드시 신체적인 것만은 아닐 수도 있어요.\n\n게임의 특정 섹션에서 플레이어가 계속해서 듣거나 보고 싶어하지 않는 매우 감정적으로 자극하는 대화나 이미지가 있는 가능성도 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특정 섹션이 너무 자극적이어서 진행이 어려울 수 있습니다.\n\n무엇이든 그 이유가 되더라도, 사용자들에게 저장할 수 있게 해주세요.\n\n저는 개인적으로 자동 저장과 수동 저장 둘 다 구현하는 것을 추천드립니다.\n\n왜냐하면 몇 가지 이유가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자동 저장은, 그냥 자동으로 됩니다. 사용자들은 자신이 죽거나 집의 전원이 어떤 이유로든 꺼진다고 해도 많은 진행 상황을 잃을 걱정을 할 필요가 없습니다.\n\n하지만, 자동 저장에는 몇 가지 문제가 있습니다.\n\n우리 아버지는 게임 The Callisto Protocol의 출시일에 대해 매우 흥분했습니다. 그는 잠깐 게임을 플레이하고 멋지다고 생각했지만, 가장 어려운 난이도로 플레이하더라도 실제 도전감이 전혀 느껴지지 않았다고 느꼈습니다.\n\n그는 나를 불러 자신이 특정 부분을 진행하면서 적에게 죽고, 다시 부활해서 방금 전에 있었던 곳에서 10 피트 떨어진 곳에서 되살아났다는 것을 보라고 말했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"그는 말했다, '게임 전체가 이런 식이야. 내가 죽어도 걱정 안 해. 원래 있던 곳으로 돌아가는 데 10초가 걸리니까. 긴장감이 없어.'\n\n게임을 자주 저장하는 것은 일부 플레이어에게 좋을 수 있지만, 다른 사람들의 경험을 방해할 수도 있어. 나는 일정 구간을 거치고 자동 저장하는 것을 선호하지만, 사용자가 수동으로 저장할 수 있는 옵션을 제공하는 게 좋다.\n\n수동 저장 옵션이 없으면 짧은 간격으로만 게임을 플레이하거나 사전 예고 없이 갑자기 게임을 중단해야 하는 게이머에게 불리할 수 있다.\n\n더 큰 장애물을 가진 플레이어들에게는 이 제한이 게임을 할 수 있게 여부를 결정할 수도 있다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 누군가가 다시 하기 싫은 섹션을 완료한다면, 저장할 수 있어요. 도전을 좋아하는 플레이어들은 계속해서 진행할 수 있어요.\n\n# 난이도 모드는 싫어\n\n비디오 게임에서 난이도를 조절하는 것에 대해 이야기해봐요.\n\n엄청나게 많은 게임들이 플레이어들이 난이도를 선택할 수 있는 옵션을 제공하지만, 그중에서 제대로 하는 게임은 매우 드데요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어려움은 적의 체력, 플레이어 체력, 적의 수, 전리품 드랍 빈도, 플레이어 및 적의 공격력 등을 조절합니다.\n\n이 모든 것은 괜찮은데, 더 자세히 살펴보기 시작하면 문제가 될 수 있어요.\n\n예를 들어, 어떤 이용자는 게임의 전투 요소를 정말 좋아하지만 무슨 이유에서인지 게임의 파쿠르 부분을 완료하지 못할 수 있어요. 그들은 전투 부분에 높은 난이도를 원할지 몰라도 파쿠르 부분에는 쉬운 난이도를 원할 수 있어요. 또한 누군가는 액션을 좋아하지만 한 플랫폼을 건너는 데 2시간을 헤매다가, 이 경험이 그만한 가치가 없어지는 경우도 있을 거예요.\n\n난이도 설정을 조절할 수 없다면, 상황은 어려움의 암흑일 수 있어요. 예를 들어, 쉬운 난이도에서 게임을 플레이하면 전투가 재미없어 보일 수 있지만, 어려운 난이도에서 플레이하면 플랫폼이 불편할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n장애를 가진 플레이어를 고려할 때 이 문제는 더욱 복잡해질 수 있습니다.\n\n보편적인 컨트롤의 접근성이 부족하여 어려움을 겪을 수 있는 사람을 고려해 봅시다. 그들은 주로 쉬운 난이도 설정을 선택하여 명령을 단순화하고 게임 플레이 속도를 늦추게 됩니다. 이러한 선택은 어떤 접근성을 제공하기는 하지만 게임에서 찾는 전반적인 도전과 흥미를 떨어뜨릴 수도 있습니다.\n\n많은 게이머들이 쉬운 난이도를 선택하는 것은 도전을 원치 않기 때문이 아니라, 그것이 접근 가능한 유일한 모드이기 때문일 수도 있습니다.\n\n일반적으로 어려움 설정을 선택하는 것은 혼란과 스트레스를 초래할 수도 있습니다. 게임의 여러 요소를 몇 가지 옵션으로 일반화하여 선택할 수 있도록 하는 어려움 모드는 게임에서 각 난이도가 실제 게임 플레이에 어떤 의미를 갖는지 명확히 설명해 주지 않는 경향이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n균형 잡힌 경험. 멋지네요… 하지만… 균형이 정확히 무슨 뜻이죠?\n\n몬스터보다 내가 가진 체력이 동일한 수준이라는 걸 의미하는 건가요? 더 많은가요? 어떤 스탯이 영향을 받나요? 이 중 어떤 설정이 게임을 접근하기 쉽게 만들어줄까요?\n\n전혀 모르겠네요.\n\n그럼, 해결책은 무엇일까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래요, 각 플레이어마다 독특하고 능력 수준 및 개인 성향에 맞는 맞춤형 경험을 얻을 수 있다는 것 같아요. 그렇다면… 그걸 한정된 난이도 옵션에 어떻게 넣을까요?\n\n음, 번들 하나 말이죠.\n\n구체적으로 말하면, 플레이어가 조절할 수 있는 설정들의 번들이죠.\n\n어찌되었든, 난이도 모드는 그냥 서로 다른 설정들의 번들일 뿐이에요; 우리는 그것을 바꿀 수 있는 옵션을 플레이어에게 일반적으로 제공하지 않을 뿐이죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n플레이어들이 적의 수, 시간 제한, 보상 획득량 등을 조절할 수 있는 기능을 제공한다면, 그들이 직접 원하는 난이도 모드를 만들 수 있어요.\n\n난이도 모드에 몇 가지 사전 설정값을 사용자에게 제공하되, 이후 사용자가 직접 선호에 맞게 수정할 수 있도록 해보세요.\n\n여러 난이도 모드를 제공하는 것 외에도, 사용자가 맞춤형 난이도를 선택할 수 있도록 하는 것도 좋아요.\n\n난이도 설정이 정말 잘 된 게임 중 하나인 Pathologic 2 생존 게임이 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n누군가는 가장 강렬하고 복잡한 퍼즐을 원할 수 있고, 또한 가장 쉬운 전투를 선호할 수도 있습니다. 또 다른 누군가는 퍼즐을 완전히 건너뛰고 가장 도전적인 전투 경험을 원할 수도 있죠.\n\n플레이어가 자신만의 플레이 스타일에 가장 적합한 경험을 만들 수 있도록 옵션을 제공해주세요.\n\n# 감각을 활용해보세요\n\n중요한 정보를 플레이어에게 전달할 때 적어도 두 가지 다른 감각을 사용하는 것이 좋은 지침입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 전리품이 나온 경우 시각적인 표시뿐만 아니라 청각적인 표시도 하세요. 플레이어가 피해를 입은 경우 시각적 피드백과 함께 햅틱 피드백을 제공하세요.\n\n여러 감각을 통해 정보를 전달하는 좋은 예시는 게임 모탈 컴뱃(Mortal Kombat)에서 찾을 수 있습니다.\n\n카를로스 바스케즈, 또는 스트리머 래틀헤드로 알려진 사람은 시각 장애인 프로 모탈 컴뱃 플레이어입니다. 그는 소리에 완전히 의존하면서 최고 수준의 경기에 참가할 수 있습니다.\n\nTheGamer와의 인터뷰 중에 Rattlehead는 게임이 설계되는 동안 때로는 \"우연한 접근 가능성\"을 만들어낼 수 있다고 언급합니다. 이 우연한 접근 가능성은 게임을 플레이할 수 있게 만들어 줄 수도 있지만, 개발자들이 실제로 시각 장애인 게이머를 듣게 되면 게임이 완전히 새로운 수준으로 진화될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어떤 사람들은 2D 대전 게임과 같은 일부 종류의 게임만 시각 장애인 커뮤니티에 접근 가능하다고 주장합니다. 이는 사실이 될 수 있지만, 접근성을 처음부터 고려하지 않는다면 해당할 수 있습니다.\n\n접근성을 고려하여 게임을 만든다면 복잡한 3D 게임도 누구에게나 플레이할 수 있게 할 수 있습니다. 이러한 사례 중 하나가 God of War: 라그나로크에 있습니다. 시갚을 사용하지 않고도 게임을 완주할 수 있습니다.\n\n게임에서는 플레이어가 어디로 가야하는지 듣을 수 있는 핑 시스템과 적과 싸울 때 락온 시스템을 사용합니다.\n\nRoss Minor의 게임 플레이를 시청해보면, 2022 게임 어워즈에서 접근성 혁신상을 수상하더라도 해당 게임이 완벽에 가깝지 않음을 알게 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비디오 게임은 접근성 측면에서 많은 발전을 이뤄왔지만, 아직 가야 할 길이 많습니다.\n\nGod of War: Ragnarök과 같이 철저한 접근성 시스템을 갖춘 게임들을 공부하고, 그들이 제대로 한 부분과 개선할 수 있는 부분을 주목해 보는 걸 권장합니다.\n\n이어서 청각 정보를 시각적으로 전달하는 것에 대해 이야기해 보겠습니다. 청각 장애가 있는 플레이어들은 햅틱스나 부가적인 시각적 표시를 통해 정보를 전달받아야 할 수도 있습니다.\n\n시작하려면, 생존 게임인 Raft에서 나쁜 예시를 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(참고: 저는 Raft를 사랑하는 팬으로, 그것과 함께 많은 즐거움을 느꼈지만, 접근성 부분에는 많은 부족함이 있습니다.)\n\nRaft의 주요 기능 중 하나는 상황에 따라 플레이어에게 다가와 그들의 뗏목/기지를 먹으려는 상어를 중심으로 돌아갑니다. 플레이어는 상어를 막기 위해 어떤 종류의 막대나 무기로 상어를 때려야 합니다.\n\n플레이어는 상어가 나타날 때 상어가 나뭇결을 물거나 철퍼지는 소리를 듣고 알 수 있습니다.\n\n플레이어가 청각 장애가 있거나 청력이 떨어지거나 시끄러운 환경에서 플레이하거나 소리 없이 게임을 플레이할 때는 직접 상어를 바라봐야만 상어가 있는지 알 수 있는 방법이 없습니다. 이 문제는 플레이어가 특히 큰 기지를 건설하고 뗏목의 모든 구석을 보는 방법이 없을 때 더 큰 문제가 됩니다. 이 문제는 소리가 어디에서 시계가 오는지 표시하는 시각적 지시기를 사용하여 해결할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n포트나이트는 시각적 오디오를 활용한 게임의 좋은 예시입니다. 플레이어 주위에 나타나는 링은 다양한 소리가 어디에서 나오는지를 표시합니다. 발소리, 총 소리, 전리품 등이 링에 표시되어 플레이어가 특정 방향에서 무슨 일이 일어나고 있는지 알 수 있습니다.\n\n이 설정은 청각 장애가 있는 사용자, 소리 없이 플레이하는 사용자 또는 소음이 있는 환경에서도 사용자들이 공평하게 게임을 즐길 수 있도록 도와줍니다.\n\n각각의 감각을 통해 정보를 전달하는 것 뿐만 아니라 정보가 명확히 표시되도록 하는 것도 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시각 장애를 가진 게이머들을 위해 경험을 맞춤 설정하는 것은 배경 세부사항을 없애는 것을 포함할 수도 있습니다. 이 조정은 그들이 전경의 중요한 물체들을 쉽게 구별하고 집중할 수 있도록 돕습니다. 이에 대한 훌륭한 예시는 The Last of Us: Part II에서 볼 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-Designingaccessiblevideogames_2.png)\n\n상호작용 가능한 항목들과 적들과 같은 중요한 요소들이 강조되고 배경은 회색조로 처리됩니다. 플레이어들은 화면에서 중요한 정보를 더 쉽게 파악할 수 있습니다.\n\n신경 다양성을 가진 일부 플레이어들에게는 특정 요소를 제거하여 시각적 장면을 조정하는 것이 필수적일 수 있습니다. 이 수정은 그들이 받는 시각적 자극을 줄이고, 그들의 독특한 요구에 맞는 편안한 환경을 만들어냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n게이머들은 오디오 설정을 조절하여 볼륨 레벨을 조절하거나 다른 오디오 채널을 관리하기를 원할 수 있습니다. 예를 들어, 플레이어는 음악을 줄이고 특정 효과음을 올려서 게임 진행을 완전히 이해할 수 있을 수도 있습니다. 이 유연성은 게임의 소리 신호를 통해 중요한 정보를 신뢰할 수 있게 흡수할 수 있도록 보장합니다.\n\n# 함께 하면 더 즐겁습니다\n\n친구나 가족과 함께 플레이할 수 있는 기능을 고려해보세요.\n\n어떤 플레이어들은 게임의 일부를 다른 사람에게 맡길 필요가 있을 수도 있습니다. 예를 들어, 플레이어는 버튼을 누를 수 있지만 조이스틱을 사용할 수 없을 수도 있습니다. 다른 사람이 다른 컨트롤러를 이용하여 함께 들어와 조이스틱을 통해 모든 움직임을 제어할 수 있다면, 다른 플레이어는 버튼을 전부 누를 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어 Xbox는 Xbox Copilot을 통해 이 문제를 깔끔하게 해결했습니다. Copilot을 켜면 두 명의 플레이어가 각각 다른 컨트롤러를 사용하여 게임을 조종할 수 있습니다. 이는 \"플레이어들이 게임을 플레이하는 데 필요한 조작을 서로 나눠서 맡도록 할 수 있게 해주는데, 이는 한 명의 플레이어가 게임을 플레이하는 데 필요한 모든 행동을 처리할 수 없는 상황이거나 플레이어들이 공동 경험을 원할 때 유용합니다.\"\n\n난이도가 있는 섹션을 완수하거나 도전적인 퍼즐을 해결하거나 감정적인 콘텐츠를 다룰 때 다른 사람이 도와주는 것은 플레이어가 진전하는 데 큰 도움이 됩니다.\n\n이것은 장애를 가진 사용자들뿐만 아니라, 능숙하지 못한 어린 가족 구성원과 함께 게임을 완주할 수 있는 상황도 고려해보세요.\n\n이것은 플레이어 사이에 공동 경험을 만들어내는 협동 요소를 추가하는 재미있는 방법입니다. 게임이 협동 모드가 아니라면, 일반적으로 한 명이 플레이하는 경험이었던 것을 커플, 친구, 가족끼리 협력하여 공유할 수 있는 방법이 될 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 매크로\n\n마이크로소프트에 따르면, 매크로는 \"작업을 자동으로 수행하기 위해 하나의 명령으로 그룹화된 일련의 명령과 지시\"입니다.\n\n비디오 게임의 맥락에서, 이는 하나의 버튼을 동시에 또는 순서대로 여러 작업을 수행하도록 매핑하는 것이 될 수 있습니다.\n\n매크로가 흔한 게임인 월드 오브 워크래프트(WoW)를 살펴봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWoW은 전투 중 사용할 능력과 액션을 다량 제공하는 것으로 유명합니다. 게임 속에서 여러 막대에 시전할 주문들이 넘치게 되면서 플레이어들 중 일부는 여러 가지 주문들로 가득 찬 액션 바를 가지게 되었습니다.\n\n아래는 너무 많은 것들이 액션 바에 할당된 극단적인 예시의 스크린샷이지만, 요점은 전달됩니다.\n\n![WoW screenshot](/assets/img/2024-05-23-Designingaccessiblevideogames_3.png)\n\n매크로를 사용하면 단일 키가 한 번의 버튼 누름으로 여러 주문을 실행할 수 있도록 할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n버튼을 10번 누르는 작업이 1번으로 줄어들 수 있어요.\n\n게이밍에서 매크로의 주요 장점 중 하나는 개별 플레이어에게 맞춤형 솔루션을 제공할 수 있다는 점입니다.\n\n예를 들어, 신체적 장애가 있는 게이머들은 복잡한 키 조합이나 마우스 이동을 실행하는 데 어려움을 겪을 수 있습니다. 매크로를 사용하면 신체적 스트레인을 줄일 수 있어 게이머가 더 오래 플레이하고 더 즐거운 경험을 할 수 있도록 도와줍니다.\n\n게다가, 매크로 기능은 kognitive 어려움이나 처리 속도에 영향을 주는 상황에 있는 플레이어들의 반응 시간을 크게 향상시킬 수 있어요. 특정 작업들을 자동화함으로써 플레이어는 더 효율적으로 명령을 실행할 수 있어 게임의 속도에 맞춰 가는 데 도움을 줄 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 향상된 반응 시간은 접근성을 높이는 데 훌륭하지만, 멀티플레이 경험에서 부당한 이점에 대한 명백한 우려를 제기합니다. 모든 게임에서 플레이어가 매크로를 사용하는 것이 현실적으로 가능하지는 않을 수 있지만, 고려해 볼 것을 권장합니다.\n\n접근성에서 매크로의 역할에 관심이 있다면 Laura K Buzz의 이 비디오를 확인해보세요.\n\n# 대체 입력 장치 및 키 할당 재설정\n\n일반적인 컨트롤러를 대체 입력 장치로 교체하거나 키 할당을 재설정하는 것이 게임을 접근성 있게 만드는 중요한 부분입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n활동 제약이 있는 플레이어들에게는 적응형 컨트롤러, 스위치, 또는 동작 센서와 같은 대체 입력 장치를 연결할 수 있는 능력이 플레이 여부를 결정할 수도 있어요.\n\n발판부터 QuadStick와 같은 멋진 기술들이 많이 있어요. QuadStick은 입으로 작동하는 비디오 게임 컨트롤러입니다.\n\n게다가 여러 입력 장치를 사용할 수 있는 옵션은 맞춤형이고 유동적인 게이밍 경험을 촉진해요. 플레이어들은 자신의 편안함과 능력에 가장 잘 맞는 장치 조합을 선택할 수 있어서 자기 주도성과 포용성을 유발해요. 이는 장애가 있는 개인들의 접근성을 향상시키는 뿐만 아니라 다양한 게임 취향을 가진 광범위한 관객들에게도 맞춤화됩니다.\n\n모든 종류의 대체 컨트롤러와 설정을 사용하는 플레이어들로 테스트하는 것이 중요해요. 모든 것이 올바르게 작동하는지 확인하기 위해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n플레이어들이 자신의 기기를 사용할 수 있는 것 외에도, 제어를 적절하게 다시 매핑할 수 있어야 합니다.\n\n키 바인딩 다시 매핑을 통해 개인들은 편리하고 관리하기 쉬운 키나 버튼에 명령을 할당할 수 있습니다. 예를 들어, 플레이어는 \"점프\"를 발판으로 또는 움직임 제어를 별도의 조이스틱으로 다시 매핑해야 할 수도 있습니다.\n\n다시 매핑은 모든 플레이어에게 혜택을 주는데, 왜냐하면 각자가 선호하고 익숙한 제어 방식이 있기 때문입니다. 특히 PC에서 게임을 열 때마다, 처음으로 하는 일 중 하나는 설정에 들어가서 쉽게 접근할 수 없는 키 바인딩을 다시 매핑하는 것입니다.\n\n이제 모든 이 키 다시 매핑과 사용자 정의 설정을 고려해주시고, 플레이어의 설정이 세션 간에 유지되도록 해주세요. 누군가가 게임에 들어가서 자신의 플레이 스타일과 고유한 요구를 맞추기 위해 설정을 완벽하게 조정하는 데 한 두 시간을 소비한다면, 돌아왔을 때 모든 게 완벽하게 유지되어야 합니다. 아무도 그 모든 작업을 다시 해야할 필요가 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 아직 나가지 마세요\n\n제가 다룬 내용은 게임 접근성을 위한 초반 작업에 불과해요.\n\n이 글에서는 적절한 자막 및 캡션 추가, 색맹을 위한 디자인, 컨트롤 감도 조절 등을 다루지 않았습니다.\n\n아래 링크된 멋진 자료들을 확인해보는 것을 강력히 권유합니다. 게다가 AbleGamer의 APX (Accessible Player Experiences) 인증 실무자가 되기 위한 2일 과정도 적극 추천해요. (저는 어떠한 방식으로도 후원받고 있지 않아요. 진심으로 이 과정을 좋아했습니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 더 읽을거리\n\n- 접근성은 쉽지 않아요: 게임을 모두에게 알맞게 만드는 것에 대해 '쉬운 모드' 논의에서 빠뜨리는 것 →\n\"난이도가 높은 게임을 더 접근성 있게 만드는 것은 난이도 수준을 넘어서 하는 일입니다.\" \n- 접근 가능한 플레이어 경험 (APX) 패턴 →\n독특하고 플레이어가 자신의 Bedz어에 맞게 조절할 수 있는 플레이 경험이 확보되도록 하는 도전과 접근 패턴 목록. 정말 확인해보세요.\n- 접근 가능한 비디오 게임 디자인 →\n이 기사를 좋아하신다면, 다른 기사도 마음에 드실 거에요.\n- BBC 자막 가이드 라인 →\n여러분 모두에게 자막을 읽을 수 있고 접근할 수 있게 만드는 방법을 배워보세요.\n- 게임 접근성 지침 →\n게임을 접근성 있게 디자인하는 데 가장 필요한 도구/자료 중 하나에요.\n- 게임 제작자의 도구킷(TK) - 비디오 게임 접근성 재생 목록 →\n게임 개발자라면 꼭 봐야 할 GA 재생 목록으로, 접근성이 있는 비디오 게임을 디자인하는 방법이 가득 담겨 있어요. 이 동영상은 꼭 시청해야 할 필수영상입니다.\n\n여러분들의 생각이나 경험이 있으면, 알려주세요! 이 게시물에 응답하거나 LinkedIn에서 알려주세요. UX나 비디오 게임 관련해서 어떤 주제라도 얘기 나누는 것을 즐깁니다.\n\n✨ 누군가에게 UX 디자이너가 필요하다면, 저에게 연락해주세요!","ogImage":{"url":"/assets/img/2024-05-23-Designingaccessiblevideogames_0.png"},"coverImage":"/assets/img/2024-05-23-Designingaccessiblevideogames_0.png","tag":["Tech"],"readingTime":15},{"title":"내가 마케터가 되고 싶지 않았어요 게임","description":"","date":"2024-05-23 13:41","slug":"2024-05-23-IDidntWanttoBeaGameMarketer","content":"\n\n![image](/assets/img/2024-05-23-IDidntWanttoBeaGameMarketer_0.png)\n\n아마도 제가 거절한 사람은 오늘 인도네시아의 가장 큰 인디 게임 회사 중 하나의 마케팅 책임자로 일하고 있는 저를 보고 궁금해 할 것입니다. 저 자신도 제 결정에 대해 여전히 의문을 품고 있습니다.\n\n예전엔 마케팅이 거짓말을 하는 것이라고 생각했어요. 나라에서 가장 인기 있는 제품이 되거나, 그 지역에서 가장 인기 있는 음식점이 된다는 것... \"마케팅\"이라는 말이 별로 듣기 싫었죠. 사람들에게 실망시키는 결과를 원하지 않았어요. 아마 사람을 기쁘게 해주는 것은 고집스러운 사람의 기본적인 성격인 것 같아요. 그리고 저는 그런 사람이에요.\n\n2014년 초, 대학을 졸업한 뒤 첫 직장을 얻었습니다. 저는 그래픽 디자인을 공부했기 때문에, 한 모바일 게임 회사에 2D 아티스트로 지원했고 합격했어요! 하지만, 속은 느낌이 들었어요. 그들은 당시 회사를 떠나는 커뮤니티 매니저를 대신할 수 있느냐고 물었어요. 그냥 잠깐이라고 했어요. 그런데, 2.5년이 지나가고 나는 커뮤니티 관리 이상을 했습니다. 유저 유치, 비즈니스 개발, 약간의 모바일 게임 마케팅, 투자자들에게 프레젠테이션을 하는 법 등 Adobe Photoshop이나 Illustrator를 사용하는 일과는 관련이 없는 일들을 배웠어요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그때, 내가 모바일 게임 마케터로 근무한 직업을 좋아했었나요? 음.\n\n2017년, 1년 동안 미술 교사로 일한 후 게임 산업으로 돌아와 다시 커뮤니티 매니저가 되었습니다. 이번에는 프리미엄 PC(및 콘솔) 인디 게임 회사에서 일하는 기회를 얻었는데, 모바일 게임과는 전혀 다른 비즈니스 모델을 가지고 있습니다. 쉽다고 생각했지만, 아니었습니다. 커뮤니티, 시장 행동, 사용해야 했던 방법 등 모든 것이 달랐습니다.\n\n하지만 그럼에도 게임 마케팅을 하는 것에서 좋아하는 점을 발견했습니다. 특히 프리미엄 게임에 대한 마케팅을 좋아하는 것이었죠.\n\nSeth Godin의 All Marketers Are Liars (Tell Stories)를 읽은 후에 다시 깨닫게 되었습니다. 책을 아직 다 읽지 못했는데, 지금은 친구가 책을 빌려가고 있어요. 그러나 지금까지는 좋은 읽을거리입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-23-IDidntWanttoBeaGameMarketer_1.png)\n\n책에 대해 얘기하지 않을 거예요. 대신 (프리미엄) 게임 마케터로서 이야기를 전하는 방법에 대해 조금 이야기해 볼게요.\n\n솔직하지 않을 수 없어요.\n\n모바일 및 프리미엄 게임의 마케팅을 해본 경험을 통해, 프리미엄 게임 플레이어에게는 솔직하지 않을 수 없다는 것을 배웠어요. 모바일에서는 가짜 광고를 사용하여 다운로드를 받고 설치 횟수가 중요한 반면, 프리미엄 게임 플레이어들은 언제든지 환불을 요청하거나 안 좋은 리뷰를 남겨서 당신의 게임이 사람들에게 구매되지 않도록 할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n게이머들은 똑똑해요. Steam에서 보던 리뷰들을 구글 플레이나 앱 스토어에서 본 것과 비교했을 때 정말 놀랐어요. 거기서 1점을 주고 \"좋은 게임\"이라고 리뷰하는 것들과는 달리 PC와 콘솔 게이머들은 건설적인 피드백을 주고 게임에서 좋은 점이 무엇인지, 어떤 것이 좋았는지 등을 지적해 줘요.\n\n그저 게임의 좋은 점을 보여주세요.\n\n게임의 픽셀 아트가 잘 만들어졌다고 생각하시나요? 그것이 어떻게 만들어졌는지 보여주고, 게임 안에서 픽셀 아트가 얼마나 멋있게 보이는지 보여주세요. 게임이 가장 맛있는 전투 메카닉을 가지고 있다고 생각하시나요? 동영상을 찍어서 보여주세요. 게임의 음악이 좋으시다고 생각하시나요? 그 음악을 들려주세요.\n\n하지만 기억하세요, 마지막으로 게임을 좋아하는지 결정할 사람들은 잠재적 플레이어들이겠죠... 이것은 시장 유효성을 확인할 때 사용할 수 있어요. (이 말을 설명할 필요가 없는데요, 이것은 별도의 글이 될 수 있기 때문에)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n진정성에 관한 이야기예요.\n\n진정성은 매우 중요해요, 특히 당신의 게임이나 회사가 오랫동안 지속되길 원하고 강력한 커뮤니티나 팬 베이스를 갖고, 당신이 즐겁게 제작하는 게임을 계속 제공하고 싶을 때입니다.\n\n저는 현재 회사에서 거의 7년째 근무하고 있어요. 만약 저가 내가 아닌 다른 사람으로 가장해야 하거나 좋아하지 않거나 즐기지 않는 것을 홍보해야 한다면, 이렇게 오래 지속되지 못할 것 같아요. 제가 알고 있는 게임의 좋은 점을 공유하고, 개발자가 이 게임을 만드는 이유를 말해요... 그리고 나는 운이 좋아 내가 게임을 홍보하고 일하는 것을 즐길 수 있는 회사에서 일하고 있다고 생각해요.\n\n이게 회사가 개발하는 모든 게임을 즐기는 것을 의미할까요? 저는 캐주얼 게이머예요. 전략이나 턴 기반 전술 게임을 할 수 없어 해전 게임, 혹은 전략을 구상해야 하는 게임을 할 수 없어요. 하지만, 우리 회사의 주력 타이틀 중 하나는 턴 기반 메카 전략 게임이에요. 그럼에도 불구하고, 팀이 이 게임을 얼마나 사랑하는지 알기 때문에, 제가 할 일은 그들이 왜 그것을 좋아하는지 물어보고, 어떤 것을 사람들에게 보여주길 원하는지 알아내는 것 뿐이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 게임 마케터로 일하는 것을 좋아하나요?\n\n음, 솔직히 말하자면... 제 꿈은 고양이들과 함께 집에서 종일 게임을 하며 간식을 먹고 일하지 않아도 되는 거예요. 그렇지만 그런 꿈이지만 현재로서는 일하는 것을 즐기는 직업이에요.\n\n그런데 여러분은요? 여러분의 이야기는 무엇인가요?\n","ogImage":{"url":"/assets/img/2024-05-23-IDidntWanttoBeaGameMarketer_0.png"},"coverImage":"/assets/img/2024-05-23-IDidntWanttoBeaGameMarketer_0.png","tag":["Tech"],"readingTime":3},{"title":"Roomsxyz에서의 프로그래밍 파트 1","description":"","date":"2024-05-23 13:39","slug":"2024-05-23-ProgramminginRoomsxyzPart1","content":"\nPart 1 | Part 2 | Part 3\n\nRooms.xyz은 정확히 판타지 콘솔은 아니지만 (과거 몇 가지 기사를 써온 주제) 많은 동일한 원칙을 공유합니다. 그것은 당신이 보설 기반 미니 게임과 상호 작용 경험을 매우 쉽게 만들 수 있는 도구이며, 보설 객체와 Lua 스크립팅을 사용합니다.\n\n공개: 나는 Rooms.xyz 뒤의 3인 스타트업 \"Things, Inc.\"의 직원입니다. \"Inc\" 부분이 다소 기업적으로 보일 수 있지만, 사실은 우리는 무엇을 하는지 모르지만 멋진 것을 만들고 싶어 하는 3인 조직입니다.\n\n이 기사는 객체의 동작을 사용자 정의하기 위해 Rooms에서 Lua 코드를 작성하는 방법의 프로그래밍 모델과 기본 사항 (매우 표면적으로)을 면밀히 살펴봅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPart 1에서는 기초 사항을 다룰 것입니다:\n\n- 방과 물건\n- 기본 프로그래밍\n- 물건 이동\n- 순서\n\n![이미지](/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_0.png)\n\n# 프로그래밍을 해야 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n음, 디저트를 먹어야 하나요? 이 기사의 전제는 당신이 프로그래밍에 흥미를 느끼며 프로그래밍이 재미있다는 것입니다. 사실 당신과 나는 당신을 프로그래밍을 하지 못하게 하는 데는 약간의 노력이 필요할 것을 알고 있어요. 만약 토스트기에 API가 있다면 당신은 그것을 프로그래밍할 것입니다. 아마 그것에 API가 있는지도 모르겠네요. 토스트기 프로그래밍을 멈추고 돌아오세요.\n\n이 모든 말의 요점은: 아니, Rooms에서 프로그래밍을 할 필요는 없어요. 단순히 기존 객체를 기반으로 아름다운 방을 만들 수 있어요(라이브러리에는 많은 객체가 있어요!), 많은 객체는 이미 기존 동작을 갖고 있어요. 그러나 높은 천장에 다다르고 동작이 재미있고 독특한 방을 만들고 싶다면, 프로그래밍이 그 방법이에요!\n\n# 방이란 무엇인가요?\n\n방은 작은 상호작용 3D 환경입니다. 그게 바로 당신이 만들고 있는 것. 방이나 상호작용 3D 환경에 흥미가 없다면, 저런, Rooms.xyz를 즐기진 못할 거예요. 방은 미니 게임이 될 수도 있고 사용자가 접근할 수 있는 즐거운(아닐 수도 있지만, 우리는 그렇길 바래요) 경험이 될 수도 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_1.png)\n\n이것은 미니 게임의 예시입니다. 볼링공을 클릭하여 볼링을 할 수 있는 미니 볼링 게임입니다. 아마 볼링은 이렇게 하는 거겠지요.\n\n# 물건이란?\n\n물건이란 객체입니다. 정말, 물건? 더 일반적인 이름을 선택할 수 없었을까요? 음, 네, 객체는 더 일반적이었겠죠. 가끔 커피를 충분히 마시지 않은 경우에는 그것들을 객체라고도 부르기도 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 방 안에 있는 각 물체는 물체(Thing)입니다. 위쪽 방에서 볼링공은 물체입니다. 각 핀도 물체이고, 테이블도 물체이며, 쥬크박스도 물체입니다. 이해하시죠. 모든 것이 물체입니다.\n\n(\\*) 벽과 바닥도 물체입니다만, 누구에게도 말하지 마세요. 왜냐하면 이건 우리 디자인의 이상한 부분이라서 아직 그것이 맞는지 확신하지 못하기 때문이에요.\n\n# 물체를 그렇게 행동하게 만드는 것은 무엇인가요?\n\n스포일러 경고: 코드입니다. 다른 것으로 생각했나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수정 모드에서 물건을 클릭하고 \"Code\" 버튼을 클릭하면 코드 편집기가 표시됩니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_2.png\" /\u003e\n\n코드 편집기에 Lua 코드를 입력할 수 있습니다. Lua는 브라질인이 만든 사랑스러운 스크립트 언어입니다. 나도 브라질인은 아니에요. 다른 브라질인이 만든 거에요. 우리가 참 많죠.\n\n어쨌든, Lua를 자바스크립트의 불편한 부분 없는 버전으로 생각해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![ProgramminginRoomsxyzPart1_3](/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_3.png)\n\n우리가 코드가 없기 때문에 처음부터 시작할 필요가 없다는 메시지가 나옵니다. 간단한 템플릿을 선택하여 시작하는 것이 좋습니다. Hello 템플릿을 선택해주세요. 이 템플릿을 사용하면 좋습니다. 왜냐하면 더 복잡한 것들을 탐험할 때 직접 모든 것을 배울 수 있다는 것을 깨닫고 이 기사를 읽는 것을 중단할 수도 있기 때문입니다.\n\n또한 모든 API 함수에 대한 완전한 문서가 있으므로 이 자습서를 읽은 후 (또는 중간 중간에) API가 수행할 수 있는 모든 것을 알아볼 수 있습니다.\n\n# 코딩에 들어가기 전에...\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRooms.xyz에서 작업을 저장하려면 회원 계정을 만들어야 합니다. 현재 Rooms.xyz가 알파 상태이기 때문에 공식 홈페이지를 통해 초기 액세스를 요청해야 합니다. 홈페이지에서 \"초기 액세스 요청\" 버튼을 클릭하면 됩니다.\n\n그러나 계정을 만들지 않고도 이 튜토리얼을 따라할 수 있습니다. 유일한 주의점은 만든 방을 저장하고 공유할 수 없다는 것입니다.\n\n# 안녕하세요라고 말하기\n\n안녕하세요 템플릿을 클릭하면 미리 작성된 코드가 표시됩니다. 클릭하면 객체가 \"안녕하세요\"라고 말하는 매우 흥미진진한 스크립트입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Programming in Roomsxyz Part1_4](/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_4.png)\n\nNow run it, either in the preview window (click Update Preview), or get out of the code editor and enter Preview mode.\n\nThis thing at the top is how you switch from Edit to Preview (that is, Play) mode. You probably already figured this out, but just in case, it's here:\n\n![Programming in Roomsxyz Part1_5](/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_5.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 마크다운 형식으로 변경해 보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앞으로는 코드 스크린샷을 찍지 않을 거에요 (코드를 보여주는 바보 같은 방식이라서, 커피숍에서 다른 개발자들이 내 모습을 이상하게 쳐다보고 있거든). 대신에 이렇게 작은 블록 안에 코드를 직접 쓸 거에요:\n\n```js\n-- 사용자가 클릭했을 때 실행되는 함수입니다.\nfunction onClick()\n  say(\"Hello\")\nend\n```\n\n물론 그 테이블이 모든 걸 상상할 수 있는 어떤 말이라도 할 수 있도록 string을 수정할 수 있어요. 완전히 다른 문구인 아래와 같이요:\n\n\u003cimg src=\"/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당신이 더 나은 내용을 찾을 수 있다고 확신해요.\n\n# 핸들러 (미리 정의된 함수)\n\n이전 예제에서 우리의 함수는 onClick으로 불렸어요. 이것은 우연이 아니에요: 사용자가 무언가를 클릭할 때 실행되는 함수에요. 모든 Thing은 고유의 onClick 함수를 가질 수 있어요.\n\n이것은 중복되어 보일 수 있지만, onClick 함수는 반드시 onClick으로 불러져야 해요. \"onclick\"이나 \"ONCLICK\"이나 \"clementine\"으로 불러도 작동하지 않아요. 엔진은 정확히 onClick이라는 이름을 대소문자 구분하여 찾기 때문이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일부 다른 핸들러 함수의 예시는 다음과 같습니다:\n\n- onStart(): 방이 시작될 때 호출됩니다.\n- onCollision(): 물체가 다른 물체와 충돌할 때 호출됩니다.\n- onButtonDown(): 가상 조이스틱 버튼이 눌렸을 때 호출됩니다.\n- onButtonUp(): 가상 조이스틱 버튼이 놓였을 때 호출됩니다.\n- onUpdate(): 한 프레임당 한 번 호출됩니다 (초당 60번).\n\n지금은 이에 대해 걱정할 필요가 없어요. 다음에 일부를 살펴볼 텐데, 그 중 일부는 무시할 거에요. 하지만 그 당시에는 멀리 나아가서 당신이 이 목록을 기억할 정도가 되지 않을 거예요. 그리고 제가 이를 건너뛰었다는 걸 알아차리지 못할 거에요.\n\n# onStart() 함수\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n방이 시작할 때 사용자의 작업과 상관없이 무언가를 하고 싶을 때 유용한 기능이에요.\n\n```js\n-- 방이 시작할 때 이 함수가 실행됩니다.\nfunction onStart()\n  say(\"나를 클릭해주세요!\")\nend\n\n-- 사용자가 클릭할 때 이 함수가 실행됩니다.\nfunction onClick()\n  say(\"클릭해주셔서 감사합니다\")\nend\n```\n\n원하는 경우에는 onStart() 안에 초기화 코드를 넣는 대신 함수 밖에 초기화 코드를 놓을 수도 있어요. 이건 스타일의 문제에요:\n\n```js\n-- 방이 시작할 때 이 코드가 실행됩니다.\nsay(\"나를 클릭해주세요!\")\n\n-- 사용자가 클릭할 때 이 함수가 실행됩니다.\nfunction onClick()\n  say(\"클릭해주셔서 감사합니다\")\nend\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n나는 onStart() 안에 있다면 더 깔끔하다고 생각해요. 개인 취향입니다.\n\n# 물리학에 대한 이야기\n\n코드를 따라하며 작업하는 경우, 작업 중인 객체가 물리 유형으로 Kinematic으로 설정되어 있는지 확인하세요. 나중에 더 설명하겠지만, Kinematic 객체는 원하는대로 동작합니다. 동적(비 키네마틱) 객체는 자기 맘대로 동작합니다. 우리는 현재 주인공이니까 그것을 키네마틱으로 설정해서 우리가 움직일 수 있게 해야 해요.\n\n\n# 물리학에 대한 이야기\n\n코드를 따라하며 작업하는 경우, 작업 중인 객체가 물리 유형으로 Kinematic으로 설정되어 있는지 확인하세요. 나중에 더 설명하겠지만, Kinematic 객체는 원하는대로 동작합니다. 동적(비 키네마틱) 객체는 자기 맘대로 동작합니다. 우리는 현재 주인공이니까 그것을 키네마틱으로 설정해서 우리가 움직일 수 있게 해야 해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 한 번 시도해보세요!\n\n이 코드를 객체에 적용해보세요. 시작점이 필요하다면 https://rooms.xyz/btco/tutostart에서 시작해보세요. 택시를 클릭하고 코드를 다음과 같이 설정하세요:\n\n```js\n-- 사용자가 클릭했을 때 실행되는 함수입니다.\nfunction onClick()\n  startSpin()\nend\n```\n\n이제 미리보기 모드로 이동하여 클릭해보세요. 회전하기 시작해야 합니다! 실제 자동차에서는 시도하지 마세요. 일반적으로 이 튜토리얼로부터 운전 조언을 받지 마세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*z8Qu3AWjVrfDKmP1mCaRfw.gif)\n\n[여기](https://rooms.xyz/btco/tutospin)에서 결과물을 확인해보세요.\n\n# 즉시 이동하기 (애니메이션 없이)\n\n만약 물체를 새로운 위치로 이동하고 싶다면, setPosition() 함수를 사용하고 새로운 좌표를 알려주면 됩니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfunction onClick()\n  -- 방의 중앙으로 이동합니다.\n  setPosition(0, 0, 0)\nend\n```\n\n클릭하면 빠앗, 갑자기 방의 중앙으로 이동합니다 (아마도 차의 탑승자들에게는 매우 거친 경험이 될 것입니다).\n\n결과를 확인하려면 다음 링크를 방문해 보세요: https://rooms.xyz/btco/tutosetpos.\n\n# 부드럽게 이동하기 (애니메이션 포함)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n멋져요! 이제 객체를 순조롭게 이동시키는 방법을 알아보겠습니다. 객체를 순간이동시키는 것이 아닌 특정 양만큼 부드럽게 이동시키려면 startMoveBy() 함수를 사용하면 됩니다. 이 함수는 delta(x, y, z)와 총 시간을 인수로 받아 요청한 위치로 객체를 이동시킵니다.\n\n```js\n-- 사용자가 클릭했을 때 실행되는 함수.\nfunction onClick()\n  say(\"출발합니다!\")\n  -- 1초 동안 남쪽으로 30단위 이동합니다.\n  startMoveBy(0, 0, -30, 1)\nend\n```\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*VXfa4E4HAm71LVNfawS4vA.gif\" /\u003e\n\n왜 0, 0, -30일까요? 우리의 좌표 시스템이 그런식으로 작동하기 때문이죠:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_9.png\" /\u003e\n\n그래서 +Z는 왼쪽 벽 쪽이고, +X는 오른쪽 벽 쪽입니다. Cardinal 방향은 다음과 같이 정의합시다:\n\n- \"북쪽\"이라고 할 때, +Z 쪽을 의미합니다.\n- \"동쪽\"이라고 할 때, +X 쪽을 의미합니다.\n- \"남쪽\"이라고 할 때, -Z 쪽을 의미합니다.\n- \"서쪽\"이라고 할 때, -X 쪽을 의미합니다.\n- \"위쪽\"이라고 할 때, +Y 쪽을 의미합니다.\n- \"아래쪽\"이라고 할 때, -Y 쪽을 의미합니다.\n\n그리고 방의 중심은 (0, 0, 0) 입니다. 이는 방 중앙에 있는 바닥의 지점을 의미합니다. 방의 표면은 약 95x95의 크기이며, 높이는 75 단위입니다. 따라서 X와 Z 좌표는 약 -47.5에서 +47.5까지이며, Y 좌표는 0에서 75까지입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과를 확인하려면 다음 주소를 확인해보세요: [https://rooms.xyz/btco/tutomove](https://rooms.xyz/btco/tutomove)\n\n# 움직이고 멈추는 차\n\n오늘 시장에서 가장 좋은 차들은 움직이고 멈추는 기능을 갖추고 있어요. 함께 만들어 보도록 하죠. 클릭하면 차가 움직이고, 다시 클릭하면 멈추는 기능을 만들어 보겠습니다. 이제 코드를 확인해봅시다:\n\n```js\nmoving = false\n\n-- 사용자가 클릭했을 때 실행되는 함수입니다.\nfunction onClick()\n  if moving then\n    stopMove()\n    moving = false\n  else\n    startMoveBy(0, 0, -48, 10)\n    moving = true\n  end\nend\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예시는 startMoveBy()로 시작된 모션을 중지하기 위해 stopMove()를 호출하는 방법을 보여주며, 차량의 상태(이동 중 또는 이동 중이 아님)를 추적할 수 있는 불리언 변수를 가지는 방법을 보여줍니다. 또한 함수 외부에 변수가 존재할 수 있음을 보여주며, 이는 함수 내에서 선언된 경우 함수 호출 간에 값을 유지할 수 있음을 보여줍니다.\n\n결과를 확인하세요: https://rooms.xyz/btco/tutostartstop\n\n# 순차적 실행\n\n의도하지 않은 점 중 하나는 say(), startMoveBy() 등과 같은 함수가 비동기적이라는 것입니다. 즉, 이 함수들은 코드의 실행이 계속될 동안 백그라운드에서 실행됩니다. 따라서 이러한 함수를 여러 번 호출하는 경우 이 함수들은 함께 실행되며 순차적으로 실행되지 않습니다. 예를 들어:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n-- 경고: 이것이 하는 것 같은 일은 하지 않습니다.\nfunction onClick()\n  -- 남쪽으로 20 단위 이동, 1초 동안에.\n  startMoveBy(0, 0, -20, 2)\n  -- 서쪽으로 20 단위 이동, 1초 동안에.\n  startMoveBy(-20, 0, 0, 2)\n  -- 작업이 완료되었다고 말합니다.\n  say(\"작업 완료\")\n  -- 회전을 시작합니다.\n  startSpin()\nend\n```\n\n자동차가 먼저 남쪽으로 20 단위 이동하고, 그런 다음 서쪽으로 20 단위 이동하고, \"작업 완료\"를 말하고 회전을 시작할 것이라고 생각할 수 있습니다. 하지만 실제로 모든 것을 동시에 시도하려고 하고 정말 엉망입니다.\n\n그래서 어떻게 해야 하나요? 다른 함수를 우리 레퍼토리에 추가해야 합니다. 그리고 레퍼토리는 멋진 프랑스어 단어이기도 하니까! 그 함수는 wait()입니다. 특정 시간을 기다렸다가 다른 함수를 호출합니다. 우리는 순서대로 수행하기 위해 이를 사용할 수 있습니다.\n\n```js\nfunction onClick()\n  -- 남쪽으로 20 단위 이동, 1초 동안에.\n  startMoveBy(0, 0, -20, 1)\n  -- 1초 기다립니다 (이동하는 데 걸리는 시간)\n  -- 그리고 moveWest를 호출합니다.\n  wait(1, moveWest)\nend\n\nfunction moveWest()\n  -- 서쪽으로 20 단위 이동, 1초 동안에.\n  startMoveBy(-20, 0, 0, 1)\n  -- 1초 기다립니다 (이동하는 데 걸리는 시간)\n  -- 그리고 sayDone을 호출합니다.\n  wait(1, sayDone)\nend\n\nfunction sayDone()\n  say(\"작업 완료\")\n  -- 회전을 시작합니다.\n  startSpin()\nend\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*CL1gPOlI-i0jEA8VNiiH1w.gif)\n\n이건 동작합니다. 차가 옆으로 드리프트하고 회전하지 않는다는 사실을 제외하고 잘 작동합니다. 하지만 운전 팁은 제게 말하지 않았나요?\n\n결과를 확인하세요: [여기](https://rooms.xyz/btco/tutoseq)\n\n# 주기적으로 무언가를 수행하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특정 간격마다 주기적으로 함수를 호출하려면 every()를 사용할 수 있습니다.\n\n여기 한 예제가 있어요. 이러한 예제의 효과를 해소하기 위해 커피를 마셔야 합니다.\n\n이 예에서 양은 다음과 같은 코드를 가지고 있습니다:\n\n```js\nc = 0\n\nfunction onStart()\n  -- count() 함수를 1초마다 호출합니다.\n  every(1, count)\nend\n\nfunction count()\n  c = c + 1\n  say(c .. \" sheep\")\nend\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n그래서 onStart()에서 우리는 count() 함수가 매 초 호출되기를 원한다고 말합니다. 엔진은 매 초 count() 함수를 호출하여 우리는 카운터를 증가시키고 양이 현재 카운트를 말하도록합니다.\n\n![이미지](/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_10.png)\n\n결과 확인: https://rooms.xyz/btco/tutocount\n\n참고: 성능상의 이유로 간격을 0.25초보다 작게 설정할 수 없습니다. 그러나 다른 방법으로 여전히 성능을 저하시킬 수 있으니 포기하지 마세요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Part 1 마침\n\n와우! 이렇게 멀리 진전했고 내 유머 감각과 글쓰기 스타일을 참으셨군요. Part 2에서 더 나아갈 수는 없지만, 아래 링크를 클릭해서 계속 진행해보세요.\n\nPart 2로 이동하기 →\n","ogImage":{"url":"/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_0.png"},"coverImage":"/assets/img/2024-05-23-ProgramminginRoomsxyzPart1_0.png","tag":["Tech"],"readingTime":11}],"page":"14","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"14"},"buildId":"R1x9p1CQYDDJESXyLXKOK","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>