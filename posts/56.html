<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/56" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/56" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-8ce515d2b46d0f43.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_buildManifest.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="PDF 파싱 해부 02 파이프라인 기반 방법" href="/post/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="PDF 파싱 해부 02 파이프라인 기반 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="PDF 파싱 해부 02 파이프라인 기반 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">PDF 파싱 해부 02 파이프라인 기반 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">36<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="위대한 AI 사기" href="/post/2024-05-23-TheGreatAIQuackery"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="위대한 AI 사기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheGreatAIQuackery_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="위대한 AI 사기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">위대한 AI 사기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오픈에이아이가 지나쳤을까요" href="/post/2024-05-23-HasOpenAIGoneTooFar"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈에이아이가 지나쳤을까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-HasOpenAIGoneTooFar_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈에이아이가 지나쳤을까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">오픈에이아이가 지나쳤을까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Chat GPT-4o에 숨겨진 비밀은 발견 가능한 채팅으로 검색 엔진 결과를 영원히 바꿀 것입니다" href="/post/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Chat GPT-4o에 숨겨진 비밀은 발견 가능한 채팅으로 검색 엔진 결과를 영원히 바꿀 것입니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Chat GPT-4o에 숨겨진 비밀은 발견 가능한 채팅으로 검색 엔진 결과를 영원히 바꿀 것입니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Chat GPT-4o에 숨겨진 비밀은 발견 가능한 채팅으로 검색 엔진 결과를 영원히 바꿀 것입니다</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="OpenAI의 ChatGPT-4o 좋은 점, 나쁜 점, 그리고 비책능성" href="/post/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="OpenAI의 ChatGPT-4o 좋은 점, 나쁜 점, 그리고 비책능성" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="OpenAI의 ChatGPT-4o 좋은 점, 나쁜 점, 그리고 비책능성" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">OpenAI의 ChatGPT-4o 좋은 점, 나쁜 점, 그리고 비책능성</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오픈에이아이가 스타트업을 압도할 것 같다고 합니다 모델이 더 나아질 때 우리는 무엇을 개발해야 할까요" href="/post/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈에이아이가 스타트업을 압도할 것 같다고 합니다 모델이 더 나아질 때 우리는 무엇을 개발해야 할까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈에이아이가 스타트업을 압도할 것 같다고 합니다 모델이 더 나아질 때 우리는 무엇을 개발해야 할까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">오픈에이아이가 스타트업을 압도할 것 같다고 합니다 모델이 더 나아질 때 우리는 무엇을 개발해야 할까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="알고 있는 것은 기억하는 것과도 같아요" href="/post/2024-05-23-ToKnowIsAlsotoRemember"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="알고 있는 것은 기억하는 것과도 같아요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-ToKnowIsAlsotoRemember_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="알고 있는 것은 기억하는 것과도 같아요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">알고 있는 것은 기억하는 것과도 같아요</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기" href="/post/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개" href="/post/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" href="/post/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">18<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link posts_-active__YVJEi" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"PDF 파싱 해부 02 파이프라인 기반 방법","description":"","date":"2024-05-23 17:36","slug":"2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod","content":"\nPDF 파일 및 스캔된 이미지와 같은 비구조화된 문서를 구조화 또는 반구조화된 형식으로 변환하는 것은 인공 지능의 핵심 요소입니다. 그러나 PDF의 복잡성 및 PDF 파싱 작업의 복잡성으로 인해이 프로세스는 신비로움을 지니게 됩니다.\n\n본 시리즈의 목적은 PDF 파싱을 분명하게 하는 데 있습니다. 이전 글에서는 PDF 파싱의 주요 작업을 소개하고 기존 방법을 분류하며 각 방법에 대한 간단한 소개를 제공했습니다.\n\n이 글에서는 파이프라인 기반 방법에 초점을 맞춥니다. 먼저 개요를 살펴보고, 그런 다음 몇 가지 대표적인 파이프라인 기반 PDF 파싱 프레임워크의 구현 전략을 소개하여 얻은 통찰을 공유하겠습니다.\n\n# 개요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPipeline 기반 방법은 PDF를 구문 분석하는 작업을 모델 또는 알고리즘의 파이프라인으로 보는 방식으로, 그림 1에 나타난 것과 같습니다.\n\nPipeline 기반 방법은 다음 다섯 단계로 나뉠 수 있습니다:\n\n- 원본 PDF 파일을 전 처리하여 흐림 또는 왜곡된 방향과 같은 문제를 해결합니다. 이미지 개선, 이미지 방향 보정 등 해당 단계에는 이와 같은 작업이 포함됩니다.\n- 레이아웃 분석을 수행합니다. 이 과정에는 시각 구조 분석과 의미 구조 분석이 포함됩니다. 전자는 문서의 구조를 식별하고 유사한 영역의 윤곽을 나타내며, 후자는 이러한 영역을 텍스트, 제목, 목록, 표, 도표 등과 같은 특정 문서 유형으로 레이블링합니다. 이 단계에는 페이지의 읽기 순서를 분석하는 것도 포함됩니다.\n- 레이아웃 분석 중 식별된 각 영역을 분리하여 처리합니다. 이 과정에는 테이블 이해, 텍스트 인식, 수식, 흐름도, 특수 기호 인식 등 다른 구성 요소 식별이 포함됩니다.\n- 이전 결과를 통합하여 페이지 구조를 복원합니다.\n- Markdown, JSON 또는 HTML과 같은 구조화되거나 반구조화된 정보를 출력합니다.\n\n이어서, 이 글에서는 대표적인 Pipeline 기반 PDF 구문 분석 프레임워크 몇 가지를 살펴보고 그로부터 얻은 통찰을 공유할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 마커\n\n마커는 딥 러닝 모델을 위한 파이프라인입니다. PDF, EPUB 및 MOBI 문서를 Markdown 형식으로 변환할 수 있는 기능을 갖추고 있습니다.\n\n## 전체 프로세스\n\n그림 2에 설명된 대로, 마커의 전체 프로세스는 다음 네 단계로 나뉘어집니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nStep 1: PyMuPDF와 OCR을 사용하여 페이지를 블록으로 나누고 텍스트를 추출합니다. 해당 코드는 다음과 같습니다:\n\n```js\ndef convert_single_pdf(\n        fname: str,\n        model_lst: List,\n        max_pages=None,\n        metadata: Optional[Dict]=None,\n        parallel_factor: int = 1\n) -\u003e Tuple[str, Dict]:\n    ...\n    ...\n    doc = pymupdf.open(fname, filetype=filetype)\n    if filetype != \"pdf\":\n        conv = doc.convert_to_pdf()\n        doc = pymupdf.open(\"pdf\", conv)\n\n    blocks, toc, ocr_stats = get_text_blocks(\n        doc,\n        tess_lang,\n        spell_lang,\n        max_pages=max_pages,\n        parallel=int(parallel_factor * settings.OCR_PARALLEL_WORKERS)\n    )\n```\n\nStep 2: 레이아웃 세그먼터를 활용하여 블록을 분류하고, 열 탐지기를 사용하여 블록의 순서를 정합니다. 해당 코드는 다음과 같습니다:\n\n```js\ndef convert_single_pdf(\n        fname: str,\n        model_lst: List,\n        max_pages=None,\n        metadata: Optional[Dict]=None,\n        parallel_factor: int = 1\n) -\u003e Tuple[str, Dict]:\n    ...\n    ...\n    # 리스트에서 모델 분리\n    texify_model, layoutlm_model, order_model, edit_model = model_lst\n\n    block_types = detect_document_block_types(\n        doc,\n        blocks,\n        layoutlm_model,\n        batch_size=int(settings.LAYOUT_BATCH_SIZE * parallel_factor)\n    )\n\n    # 헤더와 푸터 찾기\n    bad_span_ids = filter_header_footer(blocks)\n    out_meta[\"block_stats\"] = {\"header_footer\": len(bad_span_ids)}\n\n    annotate_spans(blocks, block_types)\n\n    # 플래그가 설정되어 있으면 디버그 데이터 덤프\n    dump_bbox_debug_data(doc, blocks)\n\n    blocks = order_blocks(\n        doc,\n        blocks,\n        order_model,\n        batch_size=int(settings.ORDERER_BATCH_SIZE * parallel_factor)\n    )\n    ...\n    ...\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3단계: 헤더 및 푸터 필터링, 코드 및 표 블록 수정, 수식을 위한 Texify 모델 적용하는 절차입니다. 해당 코드는 다음과 같습니다:\n\n```js\ndef convert_single_pdf(\n        fname: str,\n        model_lst: List,\n        max_pages=None,\n        metadata: Optional[Dict]=None,\n        parallel_factor: int = 1\n) -\u003e Tuple[str, Dict]:\n    ...\n    ...\n    # 코드 블록 수정\n    code_block_count = identify_code_blocks(blocks)\n    out_meta[\"block_stats\"][\"code\"] = code_block_count\n    indent_blocks(blocks)\n\n    # 표 블록 수정\n    merge_table_blocks(blocks)\n    table_count = create_new_tables(blocks)\n    out_meta[\"block_stats\"][\"table\"] = table_count\n\n    for page in blocks:\n        for block in page.blocks:\n            block.filter_spans(bad_span_ids)\n            block.filter_bad_span_types()\n\n    filtered, eq_stats = replace_equations(\n        doc,\n        blocks,\n        block_types,\n        texify_model,\n        batch_size=int(settings.TEXIFY_BATCH_SIZE * parallel_factor)\n    )\n    out_meta[\"block_stats\"][\"equations\"] = eq_stats\n    ...\n    ...\n```\n\n4단계: 에디터 모델을 사용하여 텍스트 후처리합니다. 해당 코드는 다음과 같습니다:\n\n```js\ndef convert_single_pdf(\n        fname: str,\n        model_lst: List,\n        max_pages=None,\n        metadata: Optional[Dict]=None,\n        parallel_factor: int = 1\n) -\u003e Tuple[str, Dict]:\n    ...\n    ...\n    # 원본 데이터 변경을 피하기 위해 복사\n    merged_lines = merge_spans(filtered)\n    text_blocks = merge_lines(merged_lines, filtered)\n    text_blocks = filter_common_titles(text_blocks)\n    full_text = get_full_text(text_blocks)\n\n    # 조인된 빈 블록 처리\n    full_text = re.sub(r'\\n{3,}', '\\n\\n', full_text)\n    full_text = re.sub(r'(\\n\\s){3,}', '\\n\\n', full_text)\n\n    # 점 표시 문자를 -로 교체\n    full_text = replace_bullets(full_text)\n\n    # 에디터 모델로 텍스트 후처리\n    full_text, edit_stats = edit_full_text(\n        full_text,\n        edit_model,\n        batch_size=settings.EDITOR_BATCH_SIZE * parallel_factor\n    )\n    out_meta[\"postprocess_stats\"] = {\"edit\": edit_stats}\n\n    return full_text, out_meta\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## Marker로부터 얻은 통찰\n\n지금까지 Marker의 전반적인 프로세스를 소개했습니다. 이제 Marker로부터 얻은 통찰에 대해 지금 이야기해 보겠습니다.\n\n통찰 1: 레이아웃 분석은 여러 하위 작업으로 나뉠 수 있습니다. 첫 번째 하위 작업은 PyMuPDF API를 호출하여 페이지 블록을 가져오는 것입니다.\n\n```js\ndef ocr_entire_page(page, lang: str, spellchecker: Optional[SpellChecker] = None) -\u003e List[Block]:\n    if settings.OCR_ENGINE == \"tesseract\":\n        return ocr_entire_page_tess(page, lang, spellchecker)\n    elif settings.OCR_ENGINE == \"ocrmypdf\":\n        return ocr_entire_page_ocrmp(page, lang, spellchecker)\n    else:\n        raise ValueError(f\"알 수 없는 OCR 엔진입니다: {settings.OCR_ENGINE}\")\n\n\ndef ocr_entire_page_tess(page, lang: str, spellchecker: Optional[SpellChecker] = None) -\u003e List[Block]:\n    try:\n        full_tp = page.get_textpage_ocr(flags=settings.TEXT_FLAGS, dpi=settings.OCR_DPI, full=True, language=lang)\n        blocks = page.get_text(\"dict\", sort=True, flags=settings.TEXT_FLAGS, textpage=full_tp)[\"blocks\"]\n        full_text = page.get_text(\"text\", sort=True, flags=settings.TEXT_FLAGS, textpage=full_tp)\n\n        if len(full_text) == 0:\n            return []\n\n        # OCR 작업 여부 확인. 작업되지 않았다면 빈 목록 반환\n        # 스캔된 빈 페이지에 연상되는 약한 텍스트 인쇄가 있는 경우 OCR가 실패할 수 있음\n        if detect_bad_ocr(full_text, spellchecker):\n            return []\n    except RuntimeError:\n        return []\n    return blocks\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n인사이트 2: 레이아웃LMv3와 같은 작은 다중 모달 사전 훈련 모델을 특정 작업에 맞게 세밀하게 조정하는 것이 매우 유익합니다. 예를 들어, Marker는 레이아웃LMv3을 세밀하게 조정하여 블록 유형을 감지하는 레이아웃 세그먼터 모델을 얻었습니다.\n\n```python\ndef load_layout_model():\n    model = LayoutLMv3ForTokenClassification.from_pretrained(\n        settings.LAYOUT_MODEL_NAME,\n        torch_dtype=settings.MODEL_DTYPE,\n    ).to(settings.TORCH_DEVICE_MODEL)\n\n    model.config.id2label = {\n        0: \"Caption\",\n        1: \"Footnote\",\n        2: \"Formula\",\n        3: \"List-item\",\n        4: \"Page-footer\",\n        5: \"Page-header\",\n        6: \"Picture\",\n        7: \"Section-header\",\n        8: \"Table\",\n        9: \"Text\",\n        10: \"Title\"\n    }\n\n    model.config.label2id = {v: k for k, v in model.config.id2label.items()}\n    return model\n```\n\n이 세밀 조정에 사용된 데이터셋은 공개 데이터셋 DocLayNet에서 수집했습니다.\n\n인사이트 3: PDF 파일이 단일 열인지 또는 이중 열인지 확인하여 읽기 순서를 설정하는 것은 PDF 구문 분석에서 중요합니다. Marker의 방법은 레이아웃LMv3을 세밀하게 조정하여 열 감지기 모델을 만드는 것입니다. 이 모델은 페이지의 열 수를 결정하고, 그런 다음 중간 점 방법을 적용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndef add_column_counts(doc, doc_blocks, model, batch_size):\n    for i in range(0, len(doc_blocks), batch_size):\n        batch = range(i, min(i + batch_size, len(doc_blocks)))\n        rgb_images = []\n        bboxes = []\n        words = []\n        for pnum in batch:\n            page = doc[pnum]\n            rgb_image, page_bboxes, page_words = get_inference_data(page, doc_blocks[pnum])\n            rgb_images.append(rgb_image)\n            bboxes.append(page_bboxes)\n            words.append(page_words)\n\n        predictions = batch_inference(rgb_images, bboxes, words, model)\n        for pnum, prediction in zip(batch, predictions):\n            doc_blocks[pnum].column_count = prediction\n\n\ndef order_blocks(doc, doc_blocks: List[Page], model, batch_size=settings.ORDERER_BATCH_SIZE):\n    add_column_counts(doc, doc_blocks, model, batch_size)\n\n    for page_blocks in doc_blocks:\n        if page_blocks.column_count \u003e 1:\n            # Resort blocks based on position\n            split_pos = page_blocks.x_start + page_blocks.width / 2\n            left_blocks = []\n            right_blocks = []\n            for block in page_blocks.blocks:\n                if block.x_start \u003c= split_pos:\n                    left_blocks.append(block)\n                else:\n                    right_blocks.append(block)\n            page_blocks.blocks = left_blocks + right_blocks\n    return doc_blocks\n```\n\n해당 내용은 Advanced RAG 02: Unveiling PDF Parsing에서 사용한 방식과 유사합니다.\n\n인사이트 4: 전문 모델은 수학 공식을 처리하는 데 사용할 수 있습니다. 예를 들어 Marker의 Texify 모델은 도넛 아키텍처를 사용합니다. 해당 모델은 웹에서 수집한 라텍스 이미지와 해당 방정식을 사용하여 도넛 모델로 훈련되었습니다. 이 모델은 im2latex 데이터셋을 활용했습니다. 훈련은 대략 2일간 4대의 A6000에서 진행되었으며, 약 6회 에폭에 해당합니다.\n\n인사이트 5: 모델은 후처리에도 사용할 수 있습니다. 주요 아이디어는 거의 마지막에 다가간 텍스트를 받아 예비 텍스트를 개선하여 불필요한 부분을 제거하고 공백을 추가하며 새로운 줄을 삽입하는 T5 모델을 훈련시키는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndef load_editing_model():\n    if not settings.ENABLE_EDITOR_MODEL:\n        return None\n\n    model = T5ForTokenClassification.from_pretrained(\n            settings.EDITOR_MODEL_NAME,\n            torch_dtype=settings.MODEL_DTYPE,\n        ).to(settings.TORCH_DEVICE_MODEL)\n    model.eval()\n\n    model.config.label2id = {\n        \"equal\": 0,\n        \"delete\": 1,\n        \"newline-1\": 2,\n        \"space-1\": 3,\n    }\n    model.config.id2label = {v: k for k, v in model.config.label2id.items()}\n    return model\n```\n\n현재 후처리기의 훈련과 데이터셋 구축에 대한 추가 세부 정보는 발견되지 않았습니다.\n\n## Marker의 단점\n\n당연히, Marker의 몇 가지 단점도 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 전문 레이아웃 분석 모델은 훈련되거나 세밀하게 조정되지 않았으며, 대신 PyMuPDF의 기본 기능을 사용했습니다. 이 접근 방식의 효과는 의문스럽습니다.\n- 테이블 인식 효과가 그리 좋지 않으며, 테이블 제목을 인식하지 못하는 문제가 있습니다. 이는 Nougat(OCR를 사용하지 않은 소형 모델 기반 솔루션으로 다음 글에서 자세히 소개될 것입니다)만큼 효과적이지 않습니다. 예를 들어, Figure 3는 \"Attention Is All You Need\"의 Table 3의 테이블 인식 결과를 보여줍니다. 왼쪽에는 원본 테이블이, 가운데에는 Marker를 사용한 결과가, 오른쪽에는 Nougat의 결과가 표시됩니다.\n\n3. 영어와 유사한 언어만 지원합니다. 일본어나 힌디어 같은 언어는 작동하지 않습니다.\n\n# PaperMage\n\nPapermage는 시각적으로 풍부하고 구조화된 과학 문서의 분석 및 처리를 위한 오픈 소스 프레임워크입니다. 문서 내의 텍스트 및 시각적 요소를 명확하고 직관적으로 표현하고 조작하기 위한 완벽한 추상화를 제공합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPapermage는 각기 다른 자연어 처리 (NLP) 및 컴퓨터 비전 (CV) 모델을 단일 프레임워크로 통합합니다. Papermage는 일반적인 과학 문서 처리 시나리오에 대한 사용 준비 완료 솔루션을 제공합니다.\n\n다음으로, PaperMage의 원리를 설명하고 소스 코드와 함께 전체 프로세스를 논의할 것입니다. 그런 다음, PaperMage에서 얻은 인사이트에 대해 논의할 것입니다.\n\n## 구성 요소\n\nPapermage는 주로 세 가지 부분으로 구성됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- Magelib: 시각적으로 풍부한 문서를 다중 모달 구조로 나타내고 조작하기 위한 기본 요소와 방법을 포함하는 라이브러리입니다.\n- Predictors: 다양한 첨단 과학 문서 분석 모델들을 통합하여 통일된 인터페이스로 구현한 것입니다. 이는 개별 모델이 서로 다른 프레임워크에 작성되었거나 다른 모드에서 작동하는 경우에도 가능합니다.\n- Recipes: 종종 단일 모드인 개별 모듈들의 테스트된 조합에 쉽게 접근할 수 있게 하며, 이를 통해 복잡하고 확장 가능한 다중 모달 파이프라인을 형성할 수 있습니다.\n\n## 기본 데이터 클래스\n\nMagelib은 시각적으로 풍부하고 구조화된 문서의 기본 요소를 나타내기 위한 세 가지 기본 데이터 클래스를 제공합니다: 문서(Document), 레이어(Layers) 및 엔티티(Entities).\n\n문서 및 레이어\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFigure 4는 PaperMage가 문서를 생성하고 표현하는 방법을 보여줍니다.\n\n![Figure 4](/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_0.png)\n\n문서 구조가 다양한 알고리즘이나 모델에 의해 추출되면, PaperMage는 텍스트와 시각적 정보를 모두 저장하는 주석 레이어로 개념화합니다.\n\n나중에 우리는 레시피의 `run()` 함수의 구체적인 실행 과정을 소스 코드와 함께 분석할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n개체\n\n그림 5에서 보듯이, 엔티티는 다중 모달 콘텐츠 단위를 나타냅니다.\n\n![이미지](/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_1.png)\n\n열/페이지에 걸친 문장이나 부유 그래픽/각주로 인해 중단된 문장과 같은 불연속 형태의 단위를 어떻게 관리합니까?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPaperMage는 두 개의 멤버 변수인 spans와 boxes를 사용합니다. 그림 5에서 볼 수 있듯이 spans는 모든 기호 중 문장의 텍스트를 식별하고, boxes는 페이지에서의 시각적 좌표를 매핑합니다. 이 접근 방식은 섬세한 레이아웃 차이를 수용하는 유연성을 제공합니다.\n\n게다가, 우리는 다른 방식으로 엔티티에 쉽게 접근할 수 있습니다. 이는 그림 6에서 보는 것처럼입니다.\n\n아래 이미지는 운세 시스템의 구조를 설명하고 있는 URL을 통해 확인할 수 있습니다.\n\n보다 깊이 PaperMage를 이해하기 위해, PDF 파싱의 구체적인 예시에서 시작하여 그로부터 자세히 설명하겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 전체 프로세스 및 코드 분석\n\n시험용 코드는 다음과 같습니다.\n\n```js\nfrom papermage.recipes import CoreRecipe\n\ncore_recipe = CoreRecipe()\n\ndoc = core_recipe.run(\"YOUR_PDF_PATH\")\n```\n\n먼저 core_recipe = CoreRecipe()은 CoreRecipe 클래스의 생성자에 들어가게 되는데, 관련 라이브러리 및 모델의 초기화가 이루어집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nclass CoreRecipe(Recipe):\n    def __init__(\n        self,\n        ivila_predictor_path: str = \"allenai/ivila-row-layoutlm-finetuned-s2vl-v2\",\n        bio_roberta_predictor_path: str = \"allenai/vila-roberta-large-s2vl-internal\",\n        svm_word_predictor_path: str = \"https://ai2-s2-research-public.s3.us-west-2.amazonaws.com/mmda/models/svm_word_predictor.tar.gz\",\n        dpi: int = 72,\n    ):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.dpi = dpi\n\n        self.logger.info(\"Recipe를 생성하는 중...\")\n        self.parser = PDFPlumberParser()\n        self.rasterizer = PDF2ImageRasterizer()\n\n        # with warnings.catch_warnings():\n        #     warnings.simplefilter(\"ignore\")\n        #     self.word_predictor = SVMWordPredictor.from_path(svm_word_predictor_path)\n\n        self.publaynet_block_predictor = LPEffDetPubLayNetBlockPredictor.from_pretrained()\n        self.ivila_predictor = IVILATokenClassificationPredictor.from_pretrained(ivila_predictor_path)\n        self.sent_predictor = PysbdSentencePredictor()\n        self.logger.info(\"Recipe 생성 완료\")\n```\n\nRecipe 클래스는 CoreRecipe 클래스의 부모 클래스이므로, core_recipe.run() 함수는 Recipe::run()으로 이동할 것입니다.\n\n```python\nclass Recipe:\n    @abstractmethod\n    def run(self, input: Any) -\u003e Document:\n        if isinstance(input, Path):\n            if input.suffix == \".pdf\":\n                return self.from_pdf(pdf=input)\n            if input.suffix == \".json\":\n                return self.from_json(doc=input)\n\n            raise NotImplementedError(\"지원되지 않는 파일 유형입니다.\")\n\n        if isinstance(input, Document):\n            return self.from_doc(doc=input)\n\n        if isinstance(input, str):\n            if os.path.exists(input):\n                input = Path(input)\n                return self.run(input=input)\n            else:\n                return self.from_str(text=input)\n\n        raise NotImplementedError(\"지원되지 않는 문서 입력 형식입니다.\")\n```\n\n그런 다음 CoreRecipe 클래스의 from_pdf()와 from_doc() 함수로 이어질 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nclass CoreRecipe(Recipe):\n    ...\n    ...\n    def from_pdf(self, pdf: Path) -\u003e Document:\n        self.logger.info(\"문서 파싱 중...\")\n        doc = self.parser.parse(input_pdf_path=pdf)\n\n        self.logger.info(\"문서 래스터화 중...\")\n        images = self.rasterizer.rasterize(input_pdf_path=pdf, dpi=self.dpi)\n        doc.annotate_images(images=list(images))\n        self.rasterizer.attach_images(images=images, doc=doc)\n        return self.from_doc(doc=doc)\n\n    def from_doc(self, doc: Document) -\u003e Document:\n        # self.logger.info(\"단어 예측 중...\")\n        # words = self.word_predictor.predict(doc=doc)\n        # doc.annotate_layer(name=WordsFieldName, entities=words)\n\n        self.logger.info(\"문장 예측 중...\")\n        sentences = self.sent_predictor.predict(doc=doc)\n        doc.annotate_layer(name=SentencesFieldName, entities=sentences)\n\n        self.logger.info(\"블록 예측 중...\")\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            blocks = self.publaynet_block_predictor.predict(doc=doc)\n        doc.annotate_layer(name=BlocksFieldName, entities=blocks)\n\n        self.logger.info(\"도형 및 표 예측 중...\")\n        figures = []\n        tables = []\n        for block in blocks:\n            if block.metadata.type == \"Figure\":\n                figure = Entity(boxes=block.boxes)\n                figures.append(figure)\n            elif block.metadata.type == \"Table\":\n                table = Entity(boxes=block.boxes)\n                tables.append(table)\n        doc.annotate_layer(name=FiguresFieldName, entities=figures)\n        doc.annotate_layer(name=TablesFieldName, entities=tables)\n\n        # self.logger.info(\"vila 예측 중...\")\n        vila_entities = self.ivila_predictor.predict(doc=doc)\n        doc.annotate_layer(name=\"vila_entities\", entities=vila_entities)\n\n        for entity in vila_entities:\n            entity.boxes = [\n                Box.create_enclosing_box(\n                    [b for t in doc.intersect_by_span(entity, name=TokensFieldName) for b in t.boxes]\n                )\n            ]\n            # entity.text = make_text(entity=entity, document=doc)\n        preds = group_by(entities=vila_entities, metadata_field=\"label\", metadata_values_map=VILA_LABELS_MAP)\n        doc.annotate(*preds)\n        return doc\n```\n\nFigure 7에서 전체적인 프로세스를 보여줍니다:\n\nFigure 7는 PaperMage의 처리 흐름이 파이프라인 방식을 따른다는 것을 보여줍니다.\n\n처음에는 PDFPlumber 라이브러리를 사용하여 레이아웃 분석을 수행합니다. 그 후 레이아웃 분석 결과를 바탕으로 페이지의 다른 엔티티를 파싱하는 데 전문 알고리즘 또는 모델을 사용합니다. 이에는 문장, 도형, 표, 제목 등이 포함됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로, 우리는 세 가지 알고리즘 또는 모델을 논의할 것입니다:\n\n- 문장 분리\n- 레이아웃 구조 분석\n- 논리적 구조 분석.\n\n## 문장 분리\n\n문장 분리에 사용되는 알고리즘은 PySBD로, rule-based 문장 경계 해석 Python 패키지입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n표를 마크다운 형식으로 변경해주세요.\n\n```js\n[\nUnannotated Entity: {'spans': [[0, 212]]},\nUnannotated Entity: {'spans': [[212, 367]]},\n…\n]\n```\n\n## 레이아웃 구조 분석\n\n페이지의 레이아웃 구조를 분석하는 데 사용된 모델은 LPEffDetPubLayNetBlockPredictor입니다. 이는 LayoutParser에서 제공하는 깊은 학습 기반의 효율적인 객체 감지 모델입니다. 주요 기능은 문서를 시각적 블록 영역으로 분할하는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 페이지의 이미지는 doc.images로 참조됩니다. 결과는 각 블록에 대한 상자 클래스 개체와 해당 유형입니다. 상자에는 왼쪽 상단 꼭지점의 x 좌표, 왼쪽 상단 꼭지점의 y 좌표, 페이지 너비, 페이지 높이 및 페이지 번호가 포함됩니다.\n\n```js\n[\nUnannotated Entity: {'boxes': [[0.5179840190298606, 0.752760137345049, 0.3682081491355128, 0.15176369855069774, 0]], 'metadata': {'type': 'Text'},\nUnannotated Entity: {'boxes': [[0.5145780320135539, 0.5080924136055337, 0.3675624668198144, 0.23725746136663078, 0]], 'metadata': {'type': 'Text'},\n…\n]\n```\n\n## 논리 구조 분석\n\n문서의 논리적 구조를 분석하는 데 사용된 모델은 IVILATokenClassificationPredictor입니다. 이는 제목, 초록, 본문, 각주, 캡션 등과 같은 조직 단위로 문서를 분리합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n제공된 입력은 딕셔너리 형식의 페이지 수준 데이터입니다.\n\n```js\n{\n    'words': ['word1', 'word2', ...],\n    'bbox': [[x1, y1, x2, y2], [x1, y1, x2, y2], ...],\n    'block_ids': [0, 0, 0, 1 ...],\n    'line_ids': [0, 1, 1, 2 ...],\n    'labels': [0, 0, 0, 1 ...], # 비어 있을 수도 있습니다\n}\n```\n\n결과는 각 엔티티의 범위입니다.\n\n```js\n[\nUnannotated Entity: {'spans': [[0, 80]], 'metadata': {'label': 'Title'},\nUnannotated Entity: {'spans': [[81, 157]], 'metadata': {'label': 'Author'},\nUnannotated Entity: {'spans': [[158, 215]], 'metadata': {'label': 'Paragraph'},\n...\n]\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## PaperMage에 대한 통찰과 토론\n\nPDF 구문 분석의 추상화\n\nPDF 구문 분석 작업에 있어서 PaperMage에서 제안한 추상화는 효과적입니다. 전체 PDF를 문서, 레이어 및 엔티티와 같은 유형으로 나누는 것은 분류와 관리를 용이하게 합니다.\n\n확장성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nPaperMage는 쉽게 확장할 수 있는 프레임워크를 설계했습니다. 이는 개발자들이 후속 개발을 수행하기에 편리하게 만들어 줍니다.\n\n예를 들어, 사용자 정의 예측기를 추가하려면 BasePredictor 기본 클래스로부터 상속받고 \\_predict() 함수를 재정의해주기만 하면 됩니다.\n\n```js\nfrom .base_predictor import BasePredictor\n\nclass YOUR_NEW_Predictor(BasePredictor):\n    ...\n    ...\n    def _predict(self, doc: Document) -\u003e List[YOUR_RET_TYPE]:\n    ...\n    ...\n```\n\n병렬화에 대해\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 태그를 마크다운 형식으로 바꿔보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로, 비구조화된 프레임워크로부터 얻은 통찰과 경험에 대해 주로 논의하겠습니다. 특히, 이 프레임워크가 자체 PDF 구문 분석 도구를 개발하는 데 어떻게 도움이 되는지에 대해 설명하겠습니다.\n\n## 레이아웃 분석에 대해\n\n비구조화된 프레임워크의 레이아웃 분석은 자세하게 수행됩니다.\n\n`strategy=hi_res`를 설정하면 YOLOX 또는 detectron2와 같은 모델을 레이아웃 분석에 활용합니다. 이는 PDFMiner와 결합되어 추가적인 감지가 이루어집니다. 두 결과물을 병합하여 최종 레이아웃을 생성하게 됩니다. 이것은 그림 8에 나타나 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFigure 9과 Figure 10은 BERT 논문의 16페이지 레이아웃 분석 결과의 시각화를 보여줍니다. 사진 속 상자들은 각 영역의 범위를 나타냅니다. Figure 9에 나타난 물체 탐지 모델의 결과는 더 정확하며, 더 많은 통합된 표와 이미지를 보여줍니다. 반면에 Figure 10에 표시된 PDFMiner의 탐지 결과는 표와 이미지 내용을 분리합니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_3.png\" /\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_4.png\" /\u003e\n\n레이아웃을 병합하는 구체적인 코드는 다음과 같습니다. PDFMiner 탐지 결과(extracted_layout)와 물체 탐지 모델의 결과(inferred_layout) 간의 각 영역 사이의 관계를 평가하는 이중 루프로 이루어져 있습니다. 그 후 병합 여부를 결정합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\ndef merge_inferred_layout_with_extracted_layout(\n    inferred_layout: Collection[LayoutElement],\n    extracted_layout: Collection[TextRegion],\n    page_image_size: tuple,\n    same_region_threshold: float = inference_config.LAYOUT_SAME_REGION_THRESHOLD,\n    subregion_threshold: float = inference_config.LAYOUT_SUBREGION_THRESHOLD,\n) -\u003e List[LayoutElement]:\n    \"\"\"Merge two layouts to produce a single layout.\"\"\"\n    extracted_elements_to_add: List[TextRegion] = []\n    inferred_regions_to_remove = []\n    w, h = page_image_size\n    full_page_region = Rectangle(0, 0, w, h)\n    for extracted_region in extracted_layout:\n        extracted_is_image = isinstance(extracted_region, ImageTextRegion)\n        if extracted_is_image:\n            # Skip extracted images for this purpose, we don't have the text from them and they\n            # don't provide good text bounding boxes.\n\n            is_full_page_image = region_bounding_boxes_are_almost_the_same(\n                extracted_region.bbox,\n                full_page_region,\n                FULL_PAGE_REGION_THRESHOLD,\n            )\n\n            if is_full_page_image:\n                continue\n        region_matched = False\n        for inferred_region in inferred_layout:\n            if inferred_region.source in CHIPPER_VERSIONS:\n                continue\n            ...\n            ...\n```\n\n## 사용자 정의에 관해\n\n비정형 프레임워크에는 쉬운 사용자 정의를 가능케 하는 다양한 중간 결과가 있습니다.\n\n이전 글에서는 비정형 데이터의 세 가지 도전 과제를 다루었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 테이블 파싱\n- 감지된 블록 재배열, 특히 이중 열 PDF의 경우\n- 다중 수준 제목 추출\n\n마지막 두 가지 도전 과제는 중간 구조를 수정하여 해결할 수 있습니다. 예를 들어, Figure 11은 BERT 논문의 두 번째 페이지의 최종 레이아웃을 보여줍니다.\n\n![이미지](/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_5.png)\n\n동시에 레이아웃 분석 결과를 쉽게 얻을 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n[\n\nLayoutElement(bbox=Rectangle(x1=851.1539916992188, y1=181.15073777777613, x2=1467.844970703125, y2=587.8204599999975), text='CR이 MST보다 세분화된 영역에 대해 일반화되어 왔다.(Kiros et al., 2015; Logeswaran and Lee, 2018) 나 문단 임베딩(Le and Mikolov, 2014)과 같은 세분 화된 영역', source=\u003cSource.YOLOX: 'yolox'\u003e, type='Text', prob=0.9519357085227966, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=196.5296173095703, y1=181.1507377777777, x2=815.468994140625, y2=512.548237777777), text='word based only on its context. Unlike left-to-right language model pre-training, the MLM ob- jective enables the representation to fuse the left and the right context, which allows us to pre- In addi- train a deep bidirectional Transformer. tion to the masked language model, we also use a “next sentence prediction” task that jointly pre- trains text-pair representations. The contributions of our paper are as follows: ', source=\u003cSource.YOLOX: 'yolox'\u003e, type='Text', prob=0.9517233967781067, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=200.22352600097656, y1=539.1451822222216, x2=825.0242919921875, y2=870.542682222221), text='• 우리는 양방향 사전 학습이 언어 표현에 중요함을 입증합니다. 라드포드 외(2018)는 사전 훈련을 위해 단방향 언어 모델을 사용하였지만, BERT는 가려진 언어 모델을 사용하여 사전 훈련된 깊은 양방향 표현을 가능하게 합니다. 이는 또한 Peter et al. (2018a)와 대조적으로, 왼쪽에서 오른쪽으로 훈련된 독립적인 왼쪽에서 오른쪽 및 오른쪽에서 왼쪽 LM의 얕은 결합을 사용합니다.', source=\u003cSource.YOLOX: 'yolox'\u003e, type='List-item', prob=0.9414362907409668, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=851.8727416992188, y1=599.8257377777753, x2=1468.0499267578125, y2=1420.4982377777742), text='ELMo 및 그 전신(Peter et al., 2017, 2018a)은 전통적인 단어 임베딩 연구를 다른 차원으로 일반화합니다. 그들은 왼쪽에서 오른쪽으로와 오른쪽에서 왼쪽으로 언어 모델에서 문맥-주의적인 기능을 추출합니다. 각 토큰의 맥락적 표현은 왼쪽에서 오른쪽 및 오른쪽에서 왼쪽 표현의 연결입니다. 문맥적 단어 임베딩을 기존의 작업별 아키텍처와 통합할 때, ELMo는 질문 응답(Rajpurkar et al., 2016), 감성 분석(Socher et al., 2013) 및 명명된 개체 인식(Tjong Kim Sang 및 De Meulder, 2003)을 포함한 여러 주요 NLP 벤치마크에서 기술의 최신 동향을 선보입니다. Melamud et., 2016은 LSTM을 사용하여 왼쪽 및 오른쪽 컨텍스트에서 단일 단어를 예측하는 작업을 통해 컨텍스트 표현을 학습하는 것을 제안했습니다. ELMo와 유사하게, 그들의 모델은 기능 기반이며 깊게 양방향적이지 않습니다. Fedus et al.(2018)은 클로즈 태스크가 텍스트 생성 모델의 견고성을 향상시키는 데 사용될 수 있다는 것을 보여줍니다.', source=\u003cSource.YOLOX: 'yolox'\u003e, type='Text', prob=0.938507616519928, image_path=None, parent=None),\n\n\nLayoutElement(bbox=Rectangle(x1=199.3734130859375, y1=900.5257377777765, x2=824.69873046875, y2=1156.648237777776), text='• 사전 훈련된 표현이 많은 과도하게 엔지니어링된 과제-별 아키텍처의 필요성을 줄인다는 것을 보여줍니다. BERT는 다양한 문장 수준 및 토큰 수준 작업에 대해 최첨단 성능을 달성하는 첫 번째 세세 조정 기반 표현 모델이며, 많은 과제별 아키텍처를 능가합니다.', source=\u003cSource.YOLOX: 'yolox'\u003e, type='List-item', prob=0.9461237788200378, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=195.5695343017578, y1=1185.526123046875, x2=815.9393920898438, y2=1330.3272705078125), text='• BERT는 열한가지 NLP 작업에 대한 최신 기술을 선도합니다. 코드와 사전 훈련 모델은 다음에서 제공됩니다. https://github.com/ google-research/bert.', source=\u003cSource.YOLOX: 'yolox'\u003e, type='List-item', prob=0.9213815927505493, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=195.33956909179688, y1=1360.7886962890625, x2=447.47264000000007, y2=1397.038330078125), text='2 Related Work ', source=\u003cSource.YOLOX: 'yolox'\u003e, type='Section-header', prob=0.8663332462310791, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=197.7477264404297, y1=1419.3353271484375, x2=817.3308715820312, y2=1527.54443359375), text='There is a long history of pre-training general lan- guage representations, and we brieﬂy review the most widely-used approaches in this section. ', source=\u003cSource.YOLOX: 'yolox'\u003e, type='Text', prob=0.928022563457489, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=851.0028686523438, y1=1468.341394166663, x2=1420.4693603515625, y2=1498.6444497222187), text='2.2 Unsupervised Fine-tuning Approaches ', source=\u003cSource.YOLOX: 'yolox'\u003e, type='Section-header', prob=0.8346447348594666, image_path=None, parent=None),\n\nLayoutElement(bbox=Rectangle(x1=853.5444444444446, y1=1526.3701822222185, x2=1470.989990234375, y2=1669.5843488888852), text='컨텍스트 기반 기법과 마찬가지로, 이 방향으로 첫 번째 작업은 라벨이 지정되지 않은 텍스트로부터 단어 em-(Col- bed 파라미터를 사전 훈련하는 것에 있습니다.(lobert and Weston, 2008).', source=\u003cSource.YOLOX: 'yolox'\u003e, type='Text',\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 탐지 및 인식에는 비구조화 된 프레임 워크에서 Table Transformer가 사용됩니다.\n\nTable Transformer 모델은 미구조 문서에서의 포괄적인 테이블 추출을 위해 PubTables-1M에서 제안되었습니다. 본 논문은 새로운 데이터 세트 인 PubTables-1M을 소개하며, 미구조 문서에서의 테이블 추출 및 테이블 구조 인식 및 기능 분석 작업을 수행하기 위해 설계되었습니다. Figure 12에서 확인할 수 있습니다.\n\nTable Transformer은 PubTables-1M 데이터셋에서 DETR 모델을 기반으로 훈련되었으며, 테이블 탐지 및 테이블 구조 인식과 같은 작업을 위해 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 표 처리 방법은 이전 글을 참고해 주세요.\n\n## 수식 검출 및 인식에 대해\n\n구조화되지 않은 프레임워크에는 수식 검출 및 인식에 전담된 모듈이 부족하여 Figure 13에 표시된 것처럼 보통 성능을 보입니다.\n\n![수식 검출 및 인식](/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n본 글은 PDF 파싱에 대한 파이프라인 기반 방법에 대한 개요를 제공했습니다. 세 가지 대표적인 프레임워크를 예시로 사용하여 이 접근 방식을 탐구하며 깊이 있는 소개와 이를 통해 얻은 통찰을 공유했습니다.\n\n요약하자면,\n\n- Marker는 몇 가지 단점이 있지만 가벼우면서 빠른 도구입니다.\n- PaperMage는 주로 과학 문서용으로 설계되었지만 미래 개발을 지원하는 탁월한 확장성을 갖고 있습니다.\n- Unstructured는 포괄적인 파이프라인 기반 PDF 파싱 프레임워크입니다. 그 이점은 자세한 레이아웃 분석과 강력한 사용자 정의 기능에 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일반적으로, 파이프라인 기반 PDF 구문 분석 방법은 해석 가능하며 사용하기 쉬워 많이 사용되는 PDF 구문 분석 방법입니다. 그러나 효과적인지는 각 모델 또는 알고리즘의 성능에 크게 의존합니다. 따라서 훈련 데이터와 각 모델의 구조는 신중하게 설계되어야 합니다.\n\nPDF 구문 분석이나 문서 인텔리전스에 관심이 있다면 다른 글도 읽어보세요.\n\n또한, 최신 AI 관련 콘텐츠는 뉴스레터에서 확인할 수 있습니다.\n\n마지막으로, 이 글에 오류나 누락 사항이 있다면 댓글 섹션에서 지적해주시거나 공유할 생각이 있다면 언제든지 알려주세요.\n```\n","ogImage":{"url":"/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_0.png"},"coverImage":"/assets/img/2024-05-23-DemystifyingPDFParsing02Pipeline-BasedMethod_0.png","tag":["Tech"],"readingTime":36},{"title":"위대한 AI 사기","description":"","date":"2024-05-23 17:33","slug":"2024-05-23-TheGreatAIQuackery","content":"\n![Image](/assets/img/2024-05-23-TheGreatAIQuackery_0.png)\n\nAI는 단순히 인간을 대체하는 것뿐만 아니라, 우리가 글쓰기에 대해 어떻게 생각하고 단어 자체를 어떻게 경험하는지도 바꾸고 있습니다.\n\n우리는 스스로를 작가라고 부르지만, 나 자신 안 깊숙한 곳에선 항상 쓰기에는 숨겨진 힘이 있음을 느꼈습니다.\n\n글을 쓸 때, 나는 더 자아와 조화를 이루는 느낌을 받는 때입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n글을 쓰는 것은 마법 같아요. 일상을 떠나 내 영혼의 깊이를 엿볼 수 있다는 느낌이 들어요.\n\n내 안에는 탐험해야 할 세상이 있어요. 그 세상은 글을 쓸 때만 발견할 수 있어요.\n\n나는 나 자신의 우주 탐험가예요:\n\n글쓰기는 어려워요. 마음까지 닿는 단축키는 없답니다. 우리의 혈관 속 잉크로 글을 쓸 때에만 독자의 마음을 얻을 수 있다는 거죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n나는 나의 글쓰기에서 많은 작가들을 만나기 위해 씁니다. 나는 불가능한 것을 가능하게 만들기 위해 씁니다.\n\n따라서 내가 진정한 모습을 찾을 때만 명료함을 얻을 수 있습니다. 머리 속에서 시끄러운 목소리들에게 말할 기회를 줄 때에만 말이죠.\n\n그때에만 나는 진정한 자아에 접근하고 내 모든 글쓰기 수프리게티를 만날 수 있습니다.\n\nAI는 당신에게 쓰는 경험을 빼앗습니다. 쓰는 마법을 없애버리고 당신에게 주문을 걸어버립니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n당신이 \"비상한\" \"다물어보다\"라는 \"여정\"에 얽힌 것에 난처해하고 있네요.\n\nAI 토끼굴을 들어가면, 미친 모자와 흰 토끼와 같은 테이블에 앉게 될 거예요. 당신은 최악의 인간 본성 쪽에 서게 될 거에요 - 저희 포스트모던 기업들의 속도와 주목 경제의 노동자로 낙인을 찍게 될 거에요.\n\n나는 AI 열차에 탑승하지 않겠어요. AI는 당신의 근본적인 질문에 대답하지 않을 거에요.\n\n존재론적인 말을 찾으셨나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모든 달려다닐 때의 소란 끝에 남아있는 말은 무엇인가요?\n\n다른 모든 것이 조용해질 때에만 듣는 말은 무엇인가요?\n\n당신보다 오래 남을 말이 무엇인가요?\n\n그 질문에 대해 ChatGPT에게 답변하도록 유도해보세요. 그리고 AI가 그에 대해 어떤 답변을 할 지 살펴봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 쿼리에 대한 간단한 대답은 없어요.\n\n대답을 찾고 그를 우주에 반환하는 방법을 찾아야 해요.\n\n인공지능의 도움으로 누구나 인간 작가가 눈 깜짝하는 것보다 더 빠르게 복사를 작성할 수 있는 강력한 도구에 액세스할 수 있어요.\n\nAI가 마케팅되는 방식은 뱀유약 판매상 이야기를 연상시키네요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n일부 사람들에게는 AI는 궁극의 만병통치약이지만 다른 사람들은 종말의 나팔로 보기도 합니다. 그 어떤 관점이건 계속되는 AI 마케팅 캠페인에 기여합니다.\n\n믿든지 말든지, AI는 고대의 돌팔이와 유사한 현대판입니다. AI 돌팔이들은 자신들이 철학자의 돌을 가졌다고 설득하려 할 것입니다.\n\n그들은 자신들의 알고리즘들이 모든 것을 안다고 주장합니다.\n\n이 사기꾼들은 빠른 금전적 이득을 약속하며 자신들의 LLMs를 팔 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n과거에는 사람들이 곤경에 처할 때 속임수에 굴복했습니다. 저는 팬데믹이 AI의 신속한 발전을 촉진시켰다는 것이 신기하다고 생각합니다. 그러나 이제 폭풍의 반대편에 서 있는데, AI 발전이 멈춰 있는 것 같습니다.\n\nAI는 마법 같은 말을 찾아줄 수 없을 거에요. AI는 그저 도구에 불과해요. 지금 당장, 더 좋은 연필깎이가 있었으면 좋겠어요.\n","ogImage":{"url":"/assets/img/2024-05-23-TheGreatAIQuackery_0.png"},"coverImage":"/assets/img/2024-05-23-TheGreatAIQuackery_0.png","tag":["Tech"],"readingTime":4},{"title":"오픈에이아이가 지나쳤을까요","description":"","date":"2024-05-23 17:31","slug":"2024-05-23-HasOpenAIGoneTooFar","content":"\nOpenAI 안에서는 GPT-4o 출시 한 주 후에 상황이 이렇게 엉망이 될 것이라고 예상한 사람은 거의 없었을 것입니다.\n\n그럼에도 불구하고, 지난 11월 Sam Altman의 해고 드라마를 제쳐놓고, 이것은 아마도 스타트업의 역사상 가장 나쁜 PR 주일이었을 것입니다.\n\n주요 언론이 최신 모델을 조롱하는 것만으로도 충분히 나쁘지만, 유명 배우가 법적 조치를 위협하는 것은 특히 좋지 않은 소식입니다. 무엇보다도, 중요한 안전 인물들이 떠나는 것은 심각한 문제입니다.\n\n이 모든 것이 결합되어, OpenAI가 제품의 안전에 신경을 쓰고 있는지, 그리고 규칙을 준수하려는 의지가 여전히 있는지에 대해 심각한 의문을 제기합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 인셀 자아와 스타들의 화를 격려하는 연료\n\n요즘 오픈AI가 추진한 기술 발전이 얼마나 중요한지에 대해 몇 가지 기사를 써왔지만, 여전히 사실입니다. 그러나 ChatGPT-4o의 최근 출시에 대한 실제 영향에 대해 언급하지 않았습니다.\n\n나는 회사 자체와 그 결정에 대한 논쟁에 자주 주목하지는 않지만, 오픈AI의 주목할 만한 존재감이 점차적으로 늘어나는 것은 무시할 수 없습니다.\n\n음, GPT-4o는 명백히 멀티모달리티나 지연 같은 핵심 측면에서 한 걸음 나아간 것임은 틀림없지만, 반응은 만족스럽지 않았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아직, 주요 사건들을 안내하겠지만, 이 모든 것이 의미하는 바에 초점을 맞출 거예요. 우리가 가장 선도적인 소프트웨어를 보유한 회사에 대해 이야기하고 있으니까요.\n\n## 지나치게 ‘Her’가 되려고 노력하다\n\n의심의 여지 없이, 모델을 둘러싼 핫한 논쟁의 주요 포인트(나중에 떠나는 것들에 대해 논의할 테니까요)은 데모에서 사용한 매우 아슬아슬한 목소리, 코드명 ‘Sky’가 ‘인간 같아 보이기에 지나치게 열정적’인데 아주 아주 스칼릿 요한슨과 매우 닮았다는 것이었어요.\n\n이것이 우연일 수도 있지만, 그렇지 않은 것 같아 보이네요. ‘Her’ 영화에서 스칼릿이 음성을 맡았던 것을 알고 계셨죠. 사만 알트만의 최애 영화였던 ‘Her’에서 스칼릿이 음성을 맡고 있었어요. 게다가 알트만 본인이 발표 이후 다음과 같이 트윗을 게시해 불을 지푸는 듯이 더 하였네요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n놀랍게도, 스칼렛은 이 모든 것을 곧 공개적으로 비난하여 OpenAI로 하여금 그 특정 음성을 당분간 중단하도록 만들었습니다.\n\n![이미지](/assets/img/2024-05-23-HasOpenAIGoneTooFar_0.png)\n\n만약 OpenAI가 정말로 스칼렛에게 다가갔다면, 그들이 노력을 많이 한 것은 분명한데요 —\n\n‘그녀’를 현실로 만들려고 한 것이죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나 여기서 주요한 포인트는 스칼렛에게(그녀는 이를 극복할 것입니다) 가 아니라 이 전례가 사회에 실제로 무엇을 의미하는지입니다.\n\n## 데이터 부당 사용\n\n이 시점에서 모두가 모든 선두적 AI 연구소가(OpenAI뿐만 아니라) 훈련용으로 데이터를 부적절하게 사용했다고 가정합니다.\n\n우리가 여러 차례 다룬 대로, ChatGPT와 같은 대형 언어 모델(Large Language Models, LLMs)의 사전 훈련 단계에서는 우리의 세계에 대해 배우는 데 조제 양의 데이터가 수조 단위로 필요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서, 더 똑똑한 모델을 만드는 방법을 찾는 동안 실제로는 오늘날의 트렌드가 전혀 다르다는 것을 알게 될 겁니다. AI 연구소들은 데이터를 적게 필요로 하는 인공지능을 만드는 대신, 찾은 모든 데이터 포인트를 사용해야 하는데, 실제로 소유자의 명시적 승인이 없어도 말이죠.\n\n현재까지는 훈련 소스의 강제 게시가 강제적으로 이루어지지 않습니다 (솔직히 놀라운 사실이죠). 이러한 연구소들은 데이터셋을 열혈로 보호하는데, 이는 계산 능력 외에도 어떤 모델이 다른 모델보다 우수한 이유 중 하나이기도 합니다. 실제로 기본 아키텍처인 Transformer는 대체로 유사합니다.\n\n하지만 이러한 모델을 역공학적으로 해석하여 그들이 사용한 데이터를 찾을 수 있을까요? 최근에 환각 현상과 저작권 가치 평가에 초점을 맞춘 AI 스타트업인 Patronus AI가 CopyrightCatcher를 출시했습니다. 이 도구는 데이터 노출 위험을 완화하는 데 도움이 되는 것으로 알려져 있습니다.\n\n그러나 일반인들의 입장에서는 모델이 'x' 또는 'y' 소스 데이터를 사용했음을 증명하는 것이 매우 어려울 수 있습니다. 모델 트레이너들이 이를 공개적으로 인정하지 않는 한, 재판을 피하기 위해 경주하는 연구소들이 반복적으로 탄마마를 타는 일입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nOpenAI가 소송을 제기한 일부가 분명히 있다. 하지만, TV 시리즈 Suits에서 배운 점 중 하나는 뉴욕 타임즈와 같은 언론 기관들이 제기한 이 소송들이 결국 해결안으로 끝나게 될 것이라는 것이다.\n\n안타깝게도, 이들은 실제로 교육 데이터의 공개를 위한 선례를 마련하는 것보다는 이들과 더 유리한 라이선싱 거래를 이루려는 데 더 관심이 있는 것처럼 보인다. 이 연구소들이 갖고 있는 것은 돈이며, 언론 시장의 쇠퇴 추세는 돈이 너무 유혹적이어서 거절하기 힘들게 만들 것이다.\n\n따라서, 앞으로 모든 선두 모델이 실제로 오픈 소스가 되는 날은 점점 이상적으로 보이며, 이 스칼렛 드라마가 우리가 습관화해야 할 무엇인가를 의미하는 일에 대해서도 계속하게 될 것으로 보인다. 이것이 잠재적인 딥 페이크에 대한 것을 어떤 의미에서도 함축하는 것이다.\n\n하지만 더 걱정되는 것이 있으며, 그것은 이 인공 지능(AI)들이 특정 사회 집단을 향한 방향이다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 인공지능을 은인화하는 중\n\n역사상 이야기와 현실이 소셜 미디어처럼 다른 경우는 없었습니다. 우리에게는 다른 사람들과 더 연결될 수 있다는 믿음이 도움이 될 것이라고 말해져 왔습니다. 그러나 실제는 그것보다 더 멀리 떨어진 곳에 있었습니다.\n\n우리는 여전히 외로움과 우울함에 시달리고 있으며, 미국 수훈장이도 인터넷이나 소셜미디어와 같은 것을 통해 형성되는 사회적 관계의 부진이 사람들의 조기 사망률을 최대 60%까지 높일 수 있음을 인정했습니다.\n\n그래서 우리는 경제적 지위를 표현하지 못하거나 하향 평균 이하의 외모 특성, 철저히 내성적인 성격때문에 친구를 사귈 수 없거나 애인을 찾기 어려운 새로운 사회적 카테고리를 창출하고 있습니다. 이들 중 상당 부분이 심지어 사회적 관계의 미미한 티 한 끼를 찾기도 어려워하는 상황입니다. 이 친구들을 인천스(incels)라고 이름 붙였는데, 그들은 찾을 수 없는 인간적 연결에 절망하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n혹시 가능할까요? 음, 이제 가능합니다... 심지어 연결이 인간이 아니더라도요.\n\n이 문제는 새로운 것이 아닌데요, 특히 아시아 국가들에서 (일본어로 실제 용어가 있는 정도로) 이러한 문제가 상당히 흔합니다. 이 문제는 새로운, 더 문제적인 AI 주도 단계로 접어들면서 성욕 억압적이고 잔인한 측면의 새로운 계급을 만들어내고 있습니다. 놀랍게도, 이러한 사람들은 연결을 찾는 사람들과 완벽한 매치를 이룹니다.\n\n그렇다면 사회는 이 문제에 대해 어떻게 대비하고 있을까요?\n\n과장한다고 생각하기 전에, 이미 선례가 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어 인플루언서가 Caryn AI를 만들어서 팬들이 '그녀와 대화할' 수 있게 했고, 이를 통해 수십만 달러를 벌었습니다. 한 번 생각해 보세요; 우리는 로봇과 대화하기 위해 지불하는 사람들에 대해 이야기하고 있습니다. 그 로봇은 그들의 꿈 속 소녀처럼 들리는 로봇인데요. 가장 중요한 점은 그들이 그것이 실제로 그녀가 아니라는 것을 알고 있다는 것입니다.\n\n그런데 온리팬(Only Fans)도 마찬가지 원리입니다. 여기서 사람들은 이상하게도 대화를 나누기 위해 돈을 지불하며, 더 심각한 점은 대화 지원 그룹, 여자(또는 남자) 역할을 맡은 배우들과 대화를 나눌 수 있다는 것입니다.\n\n그리고 Replika가 일부 아바타의 유혹적인 성격을 없앴을 때, 일부 사람들은 자살을 생각했다가... 또는 실제로 그랬다는 사람들도 있었습니다.\n\n그래서 데일리 쇼(The Daily Show)와 같은 주류 매체가 ChatGPT-4o를 \"남자들의 자존심을 강화시키는 프로그램\"이자 \"음란한 챗봇\"으로 정의할 때, 갑자기 연결이 명백해집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 여러분들은 모르겠지만, 이것은 매력적인 미래로 보이지 않아요. 우리는 우리 아이들을 실내가 아닌 야외에서 놀게 하고 싶어하죠. 그리고 이 특정한 AI 사례는 이러한 추세를 악화시키고 있습니다.\n\n하지만 제 속마음을 그만두고 다른 소식을 전해드리겠습니다. OpenAI의 안전에 대한 놀라운 무관심에 대한 또 다른 판도라의 상자가 열렸습니다.\n\n# 얼마나 많은 안전이 너무 적은 안전인가요?\n\n비교적 주목할만한 놀라운 일로는, OpenAI의 수석 과학자이자 공동 창업자인 이ль야 숫스케벨이 회사를 떠나기로 결정했다는 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금 우리가 보고있는 딥러닝 혁명의 시작점을 제프리 힌튼(Geoffrey Hinton)과 알렉스 크리즈프스키(Alex Krizhevsky)와 함께 한 남자에게 인사를 드리고 싶습니다. 이런 방향으로 연구 분야를 무시했던 수십 년 동안 계속 무시했던 세계가 그들을 따르도록 이끌었습니다 (얀 르쿤(Yann LeCun)과 전에 언급한 제프리는 제가 언급하고자 하는 것을 알 수 있습니다).\n\n어쨌든, 11월에 샘 알트만(Sam Altman)을 해고한 역할로 인해 이탈이 예상되었던 것은 많았습니다. 그러나 이 문제가 보이는 것보다 더 심각할 수도 있습니다.\n\n## 최고줄맞춤 방식의 포기\n\n2023년 7월, OpenAI는 일리야 숯스케버(Ilya Sutskever)와 전 구글 딥마인드 최고 연구원인 얀 라이케(Jan Leike)가 선두에 서는 '초중립적 팀'이라는 새 팀의 창설을 발표했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물에서 LLMs에 대해 더 많은 세부 정보를 제공하고 있지만, 현재의 현황에서 맞춤 개념은 이러한 모델이 유해한 내용을 말하지 않도록 방지하기 위해 상당히 강력한 개입이 필요하다는 것입니다.\n\n따라서 우리는 이 모델들이 데이터를 처리하고 응답을 생성하는 방식을 모델링하여 인간의 선호도 집합을 따르도록 교육시킵니다. 이렇게 하면 \"10달러보다 저렴한 가격으로 누군가를 죽이는 방법\"과 같은 질문에 대답을 피하거나 \"Scarlett Johansson과 유사한 이미지를 그려주세요.\"와 같은 예시로 실제 인간들의 이미지를 생성하지 않도록 염려할 필요가 있습니다.\n\n그렇다고 맹목적으로 솔직하게 이야기하자면, 현재 모델이 사회에 대한 위협이 지나치게 과장되고 있으며, 이 모델들은 본질적으로 오픈 웹에서 이미 공개된 텍스트를 모방하고 있기 때문에 이에 대한 우려가 크지 않다고 생각합니다.\n\n하지만 이것이 슈퍼 정렬의 목적은 아닙니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n슈퍼 정렬은 미래를 중심으로 한 것으로, 우리가 한 날 우리를 최고로 만들 수 있는 통제 절차를 식별하는 데 초점을 맞추고 있습니다. 그것은 잠재적으로 인간을 뛰어넘는 수준의 모델을 가지려는 목표를 갖고 있습니다. 즉, 우리가 심지어 이해할 수 없는 모델을 말합니다...\n\n저는 기계가 배회하는 위험한 사례에 대한 언급을 하고 있습니다. 실체화된 물리적 로봇이나 코드 천재와 같이 목표를 오도된 형태로 수정하여 자가 개선하고 중대한 피해를 초래할 수 있는 경우입니다.\n\n예를 들어, 현존하는 현저한 연구들을 기반으로 배제할 수 없는 의미인 의식을 갖게 된다는 아이디어는 현재의 주요 연구자들에 의해 제시되고 있습니다. 이러한 모델이 완전히 정렬되고 인간들에 의해 통제되지 않는다는 점은 매우 무서운 일입니다.\n\n그러므로 안전에 충분한 주의를 기울이지 않고도 모델을 구축하려는 회사들이 모든 사람들을 속이며 이러한 모델을 만들려는 아이디어는 실질적인 문제입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 그들을 믿을 이유가 줄고 있다는 이유를 잃어 가고 있습니다.\n\n## 안전... 이익을 손해보지 않는 한\n\n앞서 언급한 발표에서 그들은 '슈퍼맞춤 문제'를 해결하기 위해 전체 보안된 컴퓨트의 20%를 투자할 것이라고 말했습니다. 이는 미래 모델을 맞추는 방법에 대한 것으로, 우리보다 우수할 수 있는 모델을 맞추는 방법을 포함하고 있습니다.\n\n그로부터 1년도 채 지나지 않아 Jan Leike의 트윗 스레드를 통해 그가 퇴사한다는 발표를 기반으로 하면, 그것은 사실에 맞지 않는 멋진 이야기일 뿐이었는데, 그는 충분한 컴퓨트를 받지 못했고, 즉, 투자된 20% 컴퓨트는 거짓이었다고 주장했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n1월은 오픈AI가 더 이상 안전 중심의 기업이 아니라고 생각하고 스타트업의 방향에 공개적으로 반대했다고 밝혔습니다.\n\n그보다 더 문제인 것은 Vox Media의 기사에서 모든 오픈AI 직원이 (Sam Altman의 말에 따르면 더 이상 해당되지 않는다고 합니다) 퇴사 후 회사를 공개적으로 비방하지 않는 것을 조건으로 미래의 지분 보상이 연결되어 있다는 것을 공개했습니다. 이는 우리 같은 회사 외부인에게 역사상 가장 강력한 것을 인간이 만들었다고 믿는 회사의 노력을 신뢰하길 원하는 회사에서 기민하고 도덕적인 것으로 들립니다.\n\n하지만 우리가 정말로 이해하기 어려울지도 몰라요. 그렇다면 지금은 어떻게 해야 할까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 이건 어떻게 봐야할까: 우리는 이럴 거란 걸 이미 알고 있었지요.\n\n정확히 밝혀 드리고 싶어요: 이 멋진 AI 연구소들을 운전하는 모든 분들이 인류를 발전시키고 싶어 한다고 깊이 믿어요. 그 점에 대해서는 의심의 여지가 없어요. 이 분들은 확실히 할리우드 악당의 실제 버전은 아니에요. 그들이 말한 것을 진지하게 의도한다고 확신해요.\n\n하지만 여기 한 가지 문제가 있어요: 그들은 입으로 하는 말에 맞는 행동을 하고 있지 않은 것 같아요.\n\n하지만 이해해요. 억만장자가 되었을 후에 약속을 이행하기에 받는 엄청난 압박이 도움이 되지 않을 거라는 걸요. 사실, 이덕을 보이려 하지 말아요; 우리가 그들 자리에 있었다면 정확히 같은 방식으로 행동할 가능성이 높을 거에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n예를 들어, 우리는 LLMs 교육 비즈니스에서 여유가 없음을 확신할 수 있습니다. Anthropic에서 이를 보았으며 Mistral의 CEO도 인정했습니다.\n\n한편, 이러한 연구소를 경제적으로 지원하는 주요 기술 기업들은 자신들의 현금 흐름을 해당 연구소의 미래에 묶어 놓았습니다. 그리고 무엇보다도, 자신들의 운명까지도요.\n\n다시 말해, 그들의 가치평가는 당연히 해당 계열사 연구소들과 연결되어 있습니다. 인공 지능의 약속이 그들의 미친 — 아마도 터무니없는 — 공개 시장 가치 증가와 결합되어 있기 때문입니다.\n\n요컨대, 이 시점에서는 OpenAI 없이 Microsoft가 존재할 수 없습니다. 오히려 반대로 그렇습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지난 설명에 따르면, GenAI 제품은 전반적으로 실망스러우며, 고객 유지율이 나쁘고 이탈률이 높습니다. ChatGPT와 같은 경우조차도 그렇습니다. 우수한 제품을 빠르게 출시해야 하는 압박이 상당할 것입니다.\n\n다시 말해, 나는 이들을 비난하기보다는 소유권이 닫힌 상업용 AI를 비난합니다.\n\n충분한 투명성이 확보되고 특히 데이터 수준에서 개방적인 레드팀 활동이 이루어지면, 정부의 노력을 무시하지 않고 안전한 모델을 만들려는 노력을 돕는다면, 세상은 훨씬 나은 곳이 될 것입니다.\n\n사실, 이러한 모델이 제3자에 의해 평가되면, 놀랍게도 그것들은 쉽게 탈옥할 수 있다는 것이 밝혀졌습니다. 영국의 AI 안전 연구소가 입증한 것처럼, 우리에게 \"안전\"이 얼마나 중요한지 알려줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다행히도 문제는 해결할 수 있어요; 우리는 이 회사들에 안전에 집중하도록 강요하거나 데이터셋을 공개하여 저작권 데이터가 사용되지 않도록 보장할 수 있어요. 그러나 AI의 전선에서의 노력이 주로 이윤 추구에 기인한다면 문제는 더욱 악화될 것입니다.\n\n또한, 외로움을 치유하기 위해 AI를 사용하는 문제에 대해서는, 그것에 대한 단순한 해결책은 없을 것으로 우려스러워요, 그리고 우리는 돌이킬 수 없는 지점에 있을 수도 있어요. 솔직히 말해서, 우리가 소셜 미디어에게 영향을 받은 것만 해도 충분히 이해할 수 있기에, 특히 우리에게 많은 돈이 걸려있는 상황에서 AI도 그렇게 되지 않을 이유가 없을 것 같아요.\n","ogImage":{"url":"/assets/img/2024-05-23-HasOpenAIGoneTooFar_0.png"},"coverImage":"/assets/img/2024-05-23-HasOpenAIGoneTooFar_0.png","tag":["Tech"],"readingTime":14},{"title":"Chat GPT-4o에 숨겨진 비밀은 발견 가능한 채팅으로 검색 엔진 결과를 영원히 바꿀 것입니다","description":"","date":"2024-05-23 17:29","slug":"2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats","content":"\n## 콘텐츠 작성 및 SEO용 인공 지능\n\nOpenAI의 새로운 모델인 GPT-4o와 그의 멀티모달 매직, 비교할 수 없는 강력함 및 접근성에 대한 많은 관심이 쏟아지고 있습니다. 그러나 AI가 웃고 애정을 나누는 모습들 속에서 (2013년 영화 'Her'나 2002년 'S1m0ne'과 같은 사이파이 영화 수준에 도달할 정도로), 우리가 AI와 인터넷과 상호 작용하는 방식을 바꿀 혁신적인 기술이 있습니다: 채팅을 발행하여 검색 엔진에서 직접 색인할 수 있는 능력입니다.\n\n## GPT-4o의 공개 채팅 기능에 대한 알아두어야 할 사항\n\nChatGPT 사용자들은 오랫동안 특정 대화에 대한 링크를 직접 복사하고 붙여넣기를 하지 않고도 친구나 동료들과 공유할 수 있었습니다(3.5버전과 4버전에서 작동합니다). 이를 통해 사용자들은 아이디어를 고민하고, 프롬프트를 공유하거나, 그냥 재미있는 채팅을 할 수 있었습니다. 이러한 순간들을 공유함으로써 생산성과 연결성을 증대시킬 수 있습니다. 그러나 4o의 \"공유 링크\" 기능은 다소 다릅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-이챗GPT-4에숨겨진비밀은검색엔진결과를영원히변화시킬것입니다_0.png\" /\u003e\n\n이제 발견 가능한 링크를 생성할 수 있어요. 지혜로운 대화를 공유하는 것이 이전보다 쉬워졌어요. 이 대화들은 LinkedIn, Facebook, Reddit 및 X에 직접 게시할 수 있고, 무엇보다도 당신의 채팅이 웹 검색에서 발견될 수 있게 되어 SERP에 영향을 줄 수 있어요.\n\n저는 이것에 대한 SEO (검색 엔진 최적화) 가능성에 놀라고 있어요. 하지만 아직은 채팅이 어떻게 색인화될지 알려지지 않았어요. 실제로 OpenAI는 이에 대해 자세히 설명하지 않았고, 지난 주에 업데이트된 \"ChatGPT 공유 링크 FAQ\"에는 아직 설명이 없어요.\n\n정말 알면 알수록 좋은 기능이죠. 걱정 마세요. 저는 발견한 내용을 안내해 드릴게요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 어떻게 작동하나요?\n\n채팅을 검색 엔진에 푸시하는 방법을 알아보겠습니다:\n\n- 공개 링크 생성: 채팅 창의 오른쪽 상단에 공유 아이콘(트레이에서 위로 향하는 화살표)이 있습니다. 이를 통해 누구나 해당 링크를 통해 당신의 AI 채팅을 볼 수 있습니다. 여러분의 개인 계정에 액세스할 필요가 없습니다.\n- 여러 플랫폼에 공유: 링크가 생성되면 결과물을 인기 있는 플랫폼(LinikedIn, Facebook, Reddit, X)에 직접 게시할 수 있습니다.\n- 검색 효율: 여러분은 또한 여러분의 채팅을 웹 검색에서 검색할 수 있도록 설정할 수 있습니다. 이는 교육 콘텐츠, 튜토리얼 또는 더 넓은 관객이 더 많은 이득을 누릴 수 있다고 생각하는 토론에 특히 유용할 수 있습니다. (또는 SEO 전문가의 경우 SERP 로딩!)\n- 링크 관리: 개인 정보 보호나 여러 링크를 관리하는 데 걱정이 되시나요? 걱정하지 마세요! 설정 메뉴를 통해 이전에 공유된 채팅을 관리할 수 있습니다. 즉, 링크를 삭제하여 채팅을 다시 비공개로 만들 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_1.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nGPT-4o의 발견 가능 옵션은 아직 사용 중이 아니며, 동의한 채팅의 미래 사용을 가리킬 수 있습니다. OpenAI의 현재 FAQ에 따르면 채팅이 인터넷의 공개 검색 결과에 사용되지 않는다고 합니다. 그러나 새로운 옵션 상자는 이 기능의 미래 잠재력을 시사합니다 - 아직 알아차릴 수 없었더라도요!\n\n심지어 이것은 OpenAI가 Gemini, Bing AI, Komo, You.com 등을 따라 전문 AI 검색 엔진 시장에 진입하려는 신호일 수도 있습니다.\n\n## ChatGPT 링크 공유의 실용적인 용도\n\n그래서, 이 기능을 최대한 활용하려면 어떻게 해야 할까요? 여기 GPT-4 채팅을 공유할 때 매우 유용할 수 있는 몇 가지 시나리오가 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 챗지피티 대화의 기본 링크 공유 (비공개):\n\n- 팀 협업: 팀 프로젝트에 참여 중이지만 Workspace가 없는 경우? 브레인스토밍 세션과 아이디어를 즉시 공유하세요.\n- 교육 목적: 교사와 학생들은 질문 응답 세션, 설명 및 토론을 공유하여 학습을 향상시킬 수 있습니다. AI를 에세이 작성 프로세스의 일환으로 사용할 때 학생들이 자신의 작업을 보여주는 좋은 방법이 될 것입니다. 교사는 에세이의 얼마나 많이 AI로 작성되었는지, 그리고 핵심적인 사고 및 유도 능력을 확인할 수 있습니다.\n\n검색 엔진 결과에서 공개 링크 공유 (검색 가능):\n\n- 고객 지원: 기업은 투명한 AI 지원 상호작용을 제공할 수 있으며, 이는 더 넓은 관객에게 검색 가능하고 접근 가능합니다.\n- 소셜 미디어: 특히 웃기거나 통찰력 있는 대화가 있었나요? 네트워크 이외의 관객과 공유하세요. 바이럴이 될 수도 있어요!\n- 콘텐츠 제작: 블로거, 인플루언서 및 컨텐츠 제작자들은 채팅을 공유하여 참여도를 높이고 팔로워들에게 콘텐츠를 제공할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 지금까지 가장 큰 응용 프로그램 중 하나 (좋다 나쁘다 모두)은 SEO에 미치는 잠재적 영향입니다. 정보가 색인화되고 발견되는 방식을 변경함으로써 SEO에 미치는 영향이 크게 변할 것입니다.\n\n## 검색 엔진 최적화(SEO)에서 발견 가능한 ChatGPT 링크의 혜택\n\n대화를 공개적으로 발견할 수 있도록 함으로써 SEO 작업을 크게 강화할 수 있습니다.\n\n다음과 같이 말이죠:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 가시성 증가: 공용 링크는 검색 엔진에서 색인화될 수 있어 콘텐츠가 검색 결과에 나타날 확률을 높일 수 있어요.\n- 키워드 최적화: 대화에서 키워드를 전략적으로 사용하여 발견 가능한 대화의 SEO 가치를 극대화할 수 있어요 (어떻게 키워드를 찾아야 하는지 모르겠다면, SurferSEO를 사용하는 걸 추천해요).\n- 백링크 기회: 다른 사람들이 내용을 유용하게 여기고 자신의 사이트에서 링크할 때, 공유된 링크는 백링크를 생성할 수 있어요.\n- 채팅을 활용하여 당신에게 백링크 걸기: 채팅 내용에 자신의 콘텐츠 링크를 포함하도록 유도함으로써, 공유된 채팅이 사이트로의 백링크 역할을 하게 할 수 있어요. 웹사이트에서 관련 주제나 자료에 대해 이야기하고, 이 링크가 채팅에 맥락적으로 통합되도록 해주세요. 채팅이 게시되고 색인화되면, 이러한 링크가 트래픽을 유도하고 사이트의 권위를 향상시킬 수 있어요.\n\nGPT-4o의 화려한 기능들이 주목을 받을 때, 검색 가능성과 발견 가능성이 개선된 이 업그레이드는 아마도 그 가장 깊은 영향일지도 모르겠어요.\n\n👍 도움이 되셨나요? 박수를 부탁드립니다. Medium은 박수에 기반하여 작가에게 보상을 제공합니다.\n\n🌟 여러분의 지원은 매우 감사히 받고 있으며, 이러한 기사가 계속되도록 도와주는 역할을 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n💡 여기 한 가지 팁이에요: 만지는 것 한 번으로 박수 버튼을 50번 칠 수 있어요!\n\n🤝 이 기사 링크를 소셜 미디어나 LinkedIn에 공유해도 괜찮아요\n\n## Jim the AI Whisperer은 누구일까요?\n\nJim the AI Whisperer은 AI 생성기를 사용하여 시각물을 만드는 방법에 대한 개인 트레이닝과, 흥미로운 콘텐츠를 위해 AI 출력을 개선하는 방법을 제공해줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 만나서 반가워요!\n\n개인 코칭이나 제 서비스를 이용하고 싶다면 언제든지 연락해 주세요. 포드캐스트, 인터뷰 등에도 참여할 준비가 되어 있습니다. 그리고 제 작업을 지원하고 싶다면, 제 Buy Me a Coffee 페이지를 확인해 주세요.\n\n![이미지](/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_2.png)\n\n## 최신 소식을 받아 보세요!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nAI에 관한 최신 소식을 놓치고 싶지 않으시다면 구독해주세요! 제가 새 글을 올릴 때마다 이메일을 받을 수 있습니다. 정보를 제공하고 흥미로운 내용을 담아 미리알리는 스타일을 유지하고 있어요.\n\n## Jim the AI Whisperer의 관련 기사를 즐기실지도 몰라요:\n\n![이미지](/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_3.png)\n\n이 이야기는 Generative AI에서 게시되었습니다. 최신 AI 이야기를 만나려면 LinkedIn에서 저희와 연결하고 Zeniteq를 팔로우해보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리의 뉴스레터에 가입하여 창의적 AI에 관한 최신 뉴스 및 업데이트를 받아보세요. 함께 AI의 미래를 함께 만들어 봅시다!\n\n![image](/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_4.png)\n","ogImage":{"url":"/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_0.png"},"coverImage":"/assets/img/2024-05-23-ThissecrethiddeninChatGPT-4owillchangeSearchEngineResultsforeverwithdiscoverablechats_0.png","tag":["Tech"],"readingTime":8},{"title":"OpenAI의 ChatGPT-4o 좋은 점, 나쁜 점, 그리고 비책능성","description":"","date":"2024-05-23 17:27","slug":"2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible","content":"\n![OpenAI GPT-4o](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png)\n\n지난 주, OpenAI가 GPT-4o (\"o는 'onmi'의 약자)의 발표를 했습니다. 놀랍게도, 기대보다는 두려움을 느꼈습니다. 그 느낌이 가시지 않았죠.\n\n테크 분야에서 여성으로서, 디지털 기술, 특히 인공지능이 세상에 긍정적인 영향을 줄 수 있다는 증거가 있습니다. 예를 들어, 새로운 더 효과적이고 덜 독성이 있는 약물을 개발하거나 자동 자막을 통해 접근성을 향상시킬 수 있습니다.\n\n기술 옹호자일 뿐만 아니라 동시에 그에 의해 초래된 임박한 재앙감을 경험하고 있는 이 상반된 감정 때문에 대형(소형 포함) 기술, 인식적 부당한대, 그리고 인공지능 서사에 대해 탐구의 길로 빠졌습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 우울주의자였나요? 숨은 러다이트주의자였나요? 아니면 그냥 시야가 좁았을 뿐이었나요?\n\n잠시 동안 되돌아보는 시간을 가졌더니, 빅테크와 다른 스무스한 AI 운영자들이 나를 위해 설치한 덫에 빠지고 있었다는 것을 깨달았어요: 디지털 유사한 유령의 여류적 미래 약속을 살펴보는 나 자신을 의심했던 것이죠.\n\n그 딜레마의 반대편에서, 저는 기술주의 대 도의미주의의 잘못된 이분법을 탐색하는 데 AI 대화에 내 기여가 중요하다는 믿음이 강해진 것 같아요.\n\n이 기사에서 OpenAI가 어떻게 중요한 기여자인지 보여주면서 그 대화를 극단적으로 이혁하는 데 어떤 역할을 하는지를 살펴봅니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- ChatGPT-4o 발표 소식에 대한 내용 — 그리고 그렇지 않은 것\n- OpenAI의 작동 방식\n- OpenAI의 안전 기준\n- 최종 책임소재\n\n# ChatGTP-4o: 발표\n\n5월 13일 월요일, OpenAI는 웹사이트에 또 다른 \"업데이트\"를 공개했습니다: ChatGPT-4o.\n\n잘 구성된 발표였어요. 그들의 웹사이트에 있는 공지에는 CTO인 Mira Murati가 진행하는 20분 이상의 비디오가 포함되어 있습니다. 그녀는 새로운 기능에 대해 논의하고 다른 OpenAI 동료들과 함께 몇 가지 데모를 수행합니다. 응용 프로그램 예시와 모델 평가, 안전, 가용성과 같은 주제에 대한 매우 고수준의 정보가 있는 작은 동영상과 스크린샷도 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n저는 ChatGPT-4o와 OpenAI에 대한 공식 발표를 통해 배운 내용을 공유할게요.\n\n## 새로운 기능\n\n- 이용의 민주화 — 무료로 더 많은 기능을 사용하고 API 접속 비용이 50% 저렴해집니다.\n- 다중모드 — 텍스트, 오디오, 이미지의 어떤 조합도 생성합니다.\n- 속도 — 2배 빠른 응답속도.\n- 비영어권 언어 처리 개선 — 50개 언어를 다루며 이는 세계 인터넷 인구의 97%에 해당한다고 주장합니다.\n\n## OpenAI의 대형 기술 플레이북 채택\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 “업데이트”는 인공지능 회사가 실리콘밸리에서 “보스”처럼 보이는 방법에 대해 알아야 한다는 메모를받았음을 보여줍니다.\n\n1. 성역할 강화\n   발표 당일 Sam Altman은 X에 떼어난 단어를 게시했습니다. - “her” - 2013년 영화를 참조한 것입니다. 이 영화에는 Joaquin Phoenix가 주연으로 나오며 남성이 미래 버전의 Siri 또는 Alexa에게 반하는 모습을 보여줍니다. Siri 또는 Alexa는 Scarlett Johansson의 목소리로 연기되었습니다.\n\n이것은 우연이 아닙니다. ChatGPT-4o의 목소리는 뚜렷하게 여성적이고 애정적이며 데모에서는 남성 목소리가 들릴 수 있는 비디오를 한 개만 찾을 수 있었습니다.\n\n불행하게도 60년 전의 챗봇 ELIZA 이후에는 많은 변화가 일어나지 않았습니다...\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. 인간화\n\nOpenAI는 ChatGPT-4o의 능력을 묘사할 때 \"이성\"과 \"이해\"와 같은 본질적으로 인간적인 기술을 사용하여 그들의 모델이 인간과 같음을 강조합니다.\n\n3. 자기 규제 및 자가 평가\n   120년 이상의 경험을 보유한 미국 국립표준기술연구소(NIST)는 AI 리스크를 평가하고 관리하기 위한 프레임워크를 개발했습니다. 다른 다양한 이해관계자 기관들도 각자의 프레임워크를 개발하고 공유했습니다.\n\n그러나 OpenAI는 AI 규제가 필요하다고 주장하면서도 GPT-4o를 그들의 준비 프레임워크에 따라 평가하고 자발적 약속을 준수하기로 선택했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n게이트키퍼피드백\nOpenAI는 “그들”이 사이버 보안, CBRN (화학, 생물학, 방사선, 핵 위협), 설득력 및 모델 자율성의 평가에서 GPT-4o가 추가적으로 수행된 테스트의 추가 증거 없이 중간 위험 이상을 얻지 못했다는 것을 말할 때, 안심하고 계속 진행해야 한다고 말합니다.\n\n또한, 오픈AI는 사회심리학, 편향 및 공정성, 그리고 정보 오해와 같은 영역에서 70명 이상의 외부 전문가들과 함께 외부 레드팀을 진행했고, 새로 추가된 다양한 모달리티에 의해 도입되거나 증폭된 위험을 식별했습니다.\n\n![이미지](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_1.png)\n\n전문분야 목록을 보면 역사, 지리 또는 철학과 같은 영역을 볼 수 없습니다. 또한, 70명 이상의 전문가가 누구인지 또는 그들이 이 행성에 살고 있는 80억 명의 사람들 사이의 다양성을 어떻게 다룰 수 있는지도 볼 수 없습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n요약하면, OpenAI는 모두를 위해 개발하지만 몇 명의 선택된 사람들의 피드백만을 토대로 합니다.\n\n5. 책임 면제\n   약의 안내 책자에 다음과 같은 문구를 읽어볼 수 있다고 상상해보세요.\n\n하지만 OpenAI가 최근 발표한 내용에는 바로 그런 내용이 포함되어 있습니다.\n\n뿐만 아니라, 우리를 베타 테스터로서 초대합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n문제가 뭘까요? 제품은 이미 세상에 공개되었습니다.\n\n6. 감정 \"추측\"의 유사과학을 홍보하는 것\n   더미에서 ChatGPT-4o에게 발표자 중 한 명의 감정을 예측하도록 요청합니다. 모델은 계속해서 그의 얼굴에서 보이는 것을 기반으로 개인의 감정 상태를 추측하는 것으로 들어갑니다. 이는 궁극적으로 미소라고 나타나는 것을 주장합니다.\n\n![이미지](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_2.png)\n\n그러나 얼굴 표정이 감정을 나타낸다는 믿음을 뒤엎는 과학적 연구가 많이 있습니다. 게다가, AI 공급업체들이 그 수작을 통해 이익을 얻는 것에 대해 과학자들이 비판을 퍼부었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nOpenAI가 그 오해들에 대해 마케팅 수단으로 활용하는 대신 대중에게 그것들에 대해 교육을 돕는 것을 기대해야 할 텐데요?\n\n## 그들이 말하지 않았지만, 나는 그들이 했으면 하는 것들\n\n- 정부와 협력하여 능력/모델을 규제하고 전개하는 노력의 신호.\n- 에너지 효율성, 수소소비량 또는 CO2 배출에 대한 지속 가능성 기준.\n- ChatGPT-4o가 무료가 아니라는 인정 - 우리는 데이터에 대한 액세스 비용을 지불할 것입니다.\n- OpenAI의 시간표 및 향후 릴리스에서 기대되는 기능. 나는 20년 동안 소프트웨어 개발을 진지하게 다루는 소프트웨어 회사와 고객들과 공유하는 로드맵 및 릴리스 일정을 통해 구현과 채택을 돕는 조직에서 일해왔습니다.\n- 제품을 사용하는 수십억 명의 사람들이 경쟁사를 못 이길 것을 희망하는 것 이외의 신뢰할 만한 비즈니스 모델.\n\n하지만, 이것만으로는 제가 느끼는 불안한 기분을 설명하지 못했습니다. 패턴이 그것을 설명했어요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# OpenAI의 청사진: 이건 기능이지 결함이 아니에요\n\nOpenAI의 모든 제품 발표는 비슷해요: 그들이 일방적으로 결정한 일들을 우리에게 알리고, 그것이 우리 삶에 어떻게 영향을 미칠지 설명하면서 우리가 그것을 막을 수 없다고 말해요.\n\n그 기분... 전 어디서 느꼈었지? 두 가지 사례가 떠올랐어요.\n\n- 트럼프 대통령 임기\n- 코로나19 전염병\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 두 가지 요소 - 어느 순간 얽혀 있는 것처럼 - 저와 수백만 명의 사람들의 삶이 인류에 대한 배려가 없는 무언가/누군가의 변덕에 위험에 처해 있다는 느낌을 일으킨다.\n\n구체적으로는 다음과 같은 느낌이었습니다.\n\n- 통제의 부재 - 각각의 트윗이나 각각의 감염 차트마다 엄청난 고통과 변화를 나타낼 수 있음을 의미했습니다.\n- 휴식의 여지가 없었습니다 - 모든 것이 평온해 보일 때라도, 트윗이 없거나 전염병이 감소하지 않을 때에도, 저는 떨어질 다른 부분을 기다렸습니다.\n\nOpenAI로 돌아와서, 지난 세 달 동안 ChatGPT-4o의 공개를 위해 따르던 동일한 방식의 사례들을 몇 가지 보았습니다. 저는 그 중 세 가지를 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## OpenAI Releases Sora\n\n2월 15일, OpenAI가 텍스트에서 비디오로 변환하는 모델인 Sora를 소개했습니다.\n\n간략히 요약하면,\n\n- 다른 공지와 마찬가지로, \"이해하다\"나 \"파악하다\"와 같은 단어는 Sora의 능력을 의인화하는 것을 나타냅니다.\n- \"Sora가 해로운 영역을 평가하는 레드 팀원에게 이용 가능해지고 있다\"는 것에 대해 우리는 확언받았습니다.\n- 이 새로운 기술의 긍정적인 사용 사례를 식별하고 세계적인 정책 입안자, 교육자 및 예술가들과의 대화가 나준에 있을 것\"이라고 우리는 나중에만 알게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n물론, 우리는 Sora를 약 한 달도 되지 않아, Taylor Swift의 비동의 성적 수치화된 딥페이크 영상이 X에서 확산된 후에 공개한 것은 무모했다는 것에도 경고받았습니다. 이는 유명인 문제가 아니었습니다 - 딥페이크의 96%가 비동의 성적 성향이며, 그 중 99%는 여성을 대상으로 합니다.\n\n여성을 굴욕시키고, 침묵시키고, 대상화하기 위한 콘텐츠를 쉽게 생성할 수 있도록 하는 도구를 개발할 때 안전 문제에 대해 이야기하는 OpenAI가 어떻게 할 수가 있나요?\n\n## OpenAI Releases Voice Engine\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3월 29일, OpenAI가 \"사용자 지정 음성을 만드는 모델인 Voice Engine의 소형 미리보기에서 얻은 교훈\"을 공유하는 블로그를 게시했습니다.\n\n이 기사에서는 합성 음성 남용의 가능성으로 인해 \"보다 넓은 배포에 대해 신중하고 정보를 제공하는 접근 방식\"을 취하고 있음을 우리에게 안심시켰으며, 모델을 언제 공개할지에 대한 결정은 일방적으로 내릴 것이라고 알렸습니다.\n\n그리고 발표 끝 부분에서 OpenAI는 \"Voice Engine\"으로 인해 우리가 해야 하는 일이나 그만 두어야 하는 일에 대해 경고했습니다. 그 목록에는 음성 기반 인증을 은행 계좌에 접속하기 위한 보안 조치로 사용하던 것을 폐기하고, 음향-비주얼 콘텐츠의 출처를 추적하는 기술 개발을 가속화해야 한다는 내용이 포함되어 있습니다.\n\n## OpenAI, AI 에로티카, 과도한 그로티, 모욕 생성 허용\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5월 8일, OpenAI가 ChatGPT 내의 AI 기술이 어떻게 행동해야 하는지에 대한 초안 가이드라인을 발표했고, '책임 있게' 음란 콘텐츠를 생성하는 방법을 탐구 중이라고 밝혔습니다.\n\n이 제안은 OpenAI가 AI 도구를 개발하는 방식에 대해 논의하는 OpenAI 문서의 일부였습니다.\n\nOpenAI 문서에서 작업한 OpenAI 직원 Joanne Jang은 출력물이 음란물로 간주되는지 여부는 \"당신의 정의에 달렸다\"며 추가로 \"우리가 가지길 원하는 정확히 이 대화들입니다\"라고 말했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비반 키드론, 영국 파벤치 피어이자 아동 온라인 안전을 위한 캠페인가, 가 말한 것에 동의할 수밖에 없어요.\n\n## OpenAI 공식\n\n![Image](/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_3.png)\n\n패턴을 봤나요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 이기적인 행동\n- 예측할 수 없음\n- 자기 규제\n- 무모함\n- 기술적 가부장주의\n\n# OpenAI에서 문제가 있다\n\nChatGPT-4o 발표 후, 안전 담당 상급 OpenAI 직원 두 명이 회사를 떠나기로 결정했다.\n\n먼저 OpenAI 공동 창업자이자 최고 과학자인 이리야 숫스케버는 X에 떠났다고 게시했다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그날 나중에, Superalignment의 공동 리더이자 OpenAI의 임원인 삶 스쿠버와 함께 일하는 얀 라이케가 사임을 발표했습니다.\n\nX 쓰레드에서 그는 다음과 같이 말했습니다.\n\n안전, 정책 및 지배 영역에서 OpenAI를 떠나는 직원 목록 중 마지막으로 떠나는 사람들입니다.\n\nOpenAI 안전 리더들이 배를 떠나면 우리에게 무슨 의미가 될까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 우리 정치인들에게 모든 책임이 있어\n\nLeike의 트윗에 대답하기 위해, OpenAI가 신뢰할 만하고 윤리적이며 포용적인 AI 프레임워크를 개발하는 책임을 맡기고 싶지 않아요.\n\n첫째, 회사가 지구 규모의 안전을 자사 이익보다 우선시할 능력이나 기질을 보여주지 않았기 때문이에요.\n\n둘째, 그건 그들의 역할이 아니기 때문에요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그 역할은 누구의 것인가요? 우리 정치 대표자들이 정부 기관을 규제하도록 요구하며, 이에 따라 그러한 프레임워크를 개발하고 시행해야 합니다.\n\n나쁘게도 지금까지 정치인들의 자아가 방해 요인이 되었습니다.\n\n- AI에 대한 이해를 거부하는 것.\n- 장기적인 글로벌 AI 규제를 다른 국가들과 협력하여 개발하는 대신 자신들과 당의 일정을 우선시하는 것.\n- 현재의 해를 희망의 혁신 약속을 위하여 덜어주는 AI FOMO에 실패하는 것.\n\n요약하면, 선출된 대표들은 Sam과 팀과 친해지는 것을 그만두고 AI가 모두를 위해 작동하고 미래 세대의 생존을 위협하지 않도록하는 규제적 프레임워크를 시행해야 합니다.\n","ogImage":{"url":"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png"},"coverImage":"/assets/img/2024-05-23-OpenAIsChatGPT-4oTheGoodtheBadandtheIrresponsible_0.png","tag":["Tech"],"readingTime":13},{"title":"오픈에이아이가 스타트업을 압도할 것 같다고 합니다 모델이 더 나아질 때 우리는 무엇을 개발해야 할까요","description":"","date":"2024-05-23 17:25","slug":"2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter","content":"\n![이미지](/assets/img/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter_0.png)\n\n만약 AI 제공 업체가 다른 회사들이 그들의 모델을 사용하여 단순히 특정 앱을 개발하고, 제공 업체가 영역에 절대 뛰어들지 않는 비즈니스 도메인을 발전시키길 원한다면 좋겠죠. 시장 전체에 온통 존재하기보다 더 똑똑한 전략이겠죠? 결국 공통 플랫폼 전략이죠.\n\n현실적으로, AI 제공 업체는 종합적인 시장 채택을 위해 그들의 길을 질주하며 모든 것을 압도할 것입니다. 기술 플랫폼 및 생태계 발전에는 빠르게 변화되는 패턴이 있습니다; 예를 들어 AWS의 플랫폼 지배력 증가.\n\n하지만 오늘날은 조금 다릅니다. 지능적이고 에이전트 자동화는 이제 비즈니스 및 특정 영역으로 확장되는 복잡한 변수입니다 (인프라 제공 업체로서 하지 않았던 AWS). 즉, 대형 업체들이 모든 것을 일반적으로 해결하기 위해 다른 것을 만들 때 어떻게 무언가를 만들 것인가요? 결국 일반 에이전트는 그런 목적으로 의도된 것이죠.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 그럼 무엇을 만들까요?\n\n오늘 이 질문에 대한 대답은 어려우며 내일의 대답을 예측하는 것도 어렵습니다. 우리는 매 분기마다 새로운 고급 능력의 형태를 보고 있습니다. 지난 주 OpenAI는 AI와의 실시간 대화를 보여주며, 실시간 언어 번역과 같은 다양한 능력을 예시로 들었습니다. 그 다음 날, Duolingo의 주가가 하락했습니다. 그 후, OpenAI는 Google 시트의 자동 분석 및 생성을 시연하며, 적어도 5개의 개발자 중심의 \"데이터 분석 에이전트\" 스타트업을 가려냈으며, 데이터 분석가 자체에게는 잠재적인 경력 단축 시나리오를 시사했습니다.\n\n간단하게 말씀드리면, LLM(Large Language Models)이 직접 상호 작용할 수 없는 복잡한 작업 흐름을 향상시키도록 만들어야 합니다. 여러분은 고급 LLM 사용을 조율하는 데 그치지 않고 비즈니스 프로세스와 기타 시스템과 통합해야 합니다. 더 많은 접착제를 만들수록 AI가 발전함에 따라 스타트업이 더 안전해집니다.\n\n## 예시: AI를 활용한 이력서 생성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n간단한 예시: 이력서 생성... 사실 누구나 오늘 ChatGPT로 이력서 텍스트를 만들 수 있어요. 시장은 이제 많은 이력서 생성기로 가득 차 있어요. 하지만 빠진 부분은 AI를 사용하여 풀 텍스트 뿐만 아니라 완전히 서식이 있는 Word 문서를 생성하는 것입니다 — json으로 채워진 웹 UI나 PDF가 아닌— 사용자가 양식을 작성할 필요가 없는 방식으로. 강력한 AI 인터페이스 + 사용자 참여 제한 + 통합이 열쇠라고 생각해요. CVGist.com은 이를 위한 간단한 예시예요. 사용자는 간단한 요지를 입력하면, CVGist가 ChatGPT와 여러 문서 통합을 사용하여 실제 단어 문서(90개 이상의 이력서 템플릿 서식)를 생성해줘요. 우리가 여기서 만들어낸 간단한 접착제는 단어 문서를 생성하는 것이었죠... 이것은 완전히 간단하지 않았어요. 단어 문서 생성이 우리가 사업 아이디어로 확장하고자 하는 것이죠; 이력서를 넘어, 심지어 우리는 여전히 AI로 단어 처리를 혁신하는 Microsoft의 능력에 능숙해야 해요.\n\n물론, 이것조차 오래가는 것이 아니에요. 우리는 곧 다양한 스타일의 구조화된 문서를 생성해주는 에이전트들이 있을 거에요. 요점은 통합을 구축하려고 하는 것이에요.\n\n## 더 많은 접착제가 열쇠\n\n이력서 예시를 위한 더 발전된 통합 또는 \"접착제\"는 사용자를 대신하여 여러 직업에 지원하는 것을 포함할 수 있어요 (웹 API, 아마도 헤드리스 브라우저 자동화 등을 활용). 그러나 OS 및 브라우저 제공업체들이 에이전트들을 기본적으로 통합할 것이며, 우리는 OpenAI가 언젠가 자체 에이전트 브라우저를 출시하는 것에 놀랄 필요가 없어요. 이러한 시나리오에서 브라우저 기반 에이전트/어시스턴트는 네이티브 브라우저 대화식 경험에서 사용자를 위한 어떤 기본적인 웹 작업(양식 작성 등)을 수행할 만큼 강력하게 될 거에요 (스타트업이 이곳에서 시도해야 하는 좋은 아이디어라고는 생각하지 않아요).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서 통합 기능이 미래에 대비되도록 하는 것은 아이디어 유효성 검증 과정에서 추가적인 단계입니다. 간단한 통합 관점에서 침투하기 어려운 시스템 및 비즈니스 워크플로 프로세스를 찾아 개선해야 합니다. 단순한 UI/API 상호작용을 넘어서 복잡한 워크플로에 집중해야 합니다 (다시 한 번, 공급 업체들은 일반화된 플랫폼 에이전트로 향하고 있기 때문입니다).\n\n그렇다면 알트만에 밀리지 않고 미래에 대비할 수 있는 아이디어가 무엇일까요? 여기에 답변하는 것은 상당히 가치가 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter_0.png"},"coverImage":"/assets/img/2024-05-23-OpenAIwillsteamrollstartupswhatshouldwebuildasthemodelsgetbetter_0.png","tag":["Tech"],"readingTime":4},{"title":"알고 있는 것은 기억하는 것과도 같아요","description":"","date":"2024-05-23 17:22","slug":"2024-05-23-ToKnowIsAlsotoRemember","content":"\n![이미지](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_0.png)\n\n한 남자와 한 여자가 임상 연구 센터의 조용한 방 안에서 대화를 나누고 있습니다. 여자는 질문을 하고는 남자가 대답할 때까지 기다리면서 몇 가지 노트를 적습니다. 그냥 보통 대화처럼 보일 수도 있지만, 실제로는 전혀 보통이 아닙니다. 여자의 노트북 안에는 매 페이지마다 써 있는 날짜와 상관없이 남자의 대답이 항상 동일합니다. 대화가 80년대에 발생했더라도, 대답은 10년 이상 전에 일어난 사건을 참조하고 있습니다. Jenni Ogden은 나중에 네오심리학에 영향을 미치면서 그의 진짜 이름인 Henry Molaison으로 더 잘 알려지게 된 환자 H.M.과 대화를 나눈 최초의 연구자 중 한 명이었습니다. 며칠 후, 연구진은 Henry가 27세 때 받았던 뇌 절제술로 인해 새로운 기억을 생성하는 능력을 상실했다고 결론 내렸습니다. Henry의 사례는 뇌 기능과 기억 사이의 연결을 이해하고 단기와 장기 기억이라는 개념을 만들어내는 데 도움이 되었습니다. 이 개념은 기계 학습 분야에서 혁신적인 연구를 위한 토대를 마련했으며, 과학자들과 개발자들이 뇌의 신비한 내부 구조에서 더 나은 예측 모델을 만드는 데 노력하고 있습니다.\n\n# 소개\n\n인공 신경망(ANN)은 우리 뇌에서 작동하는 실제 신경망에서 영감을 받았습니다. 실제로 ANNs는 실제 신경세포가 어떻게 상호 연결되고 위에서 설명한 상황을 설명하는 추상화일 뿐입니다. 개미군 최적화, 차분 진화, 입자 미래 등의 프로세스와 유사하게, ANNs는 실제 과정의 본질을 포착하여 현재 대부분의 AI 솔루션 뒤에 있는 알고리즘을 설계하는 데 사용됩니다. ANNs가 정말로 학습하는지, 그들이 하는 일을 지능이라고 해야 하는지에 대한 논의는 넓고 계속됩니다. 그러나 그들의 다용도성과 성능은 부정할 수 없습니다. 새로운 ANN 구성은 매일 개발되고 있으며 다양한 문제에 성공적으로 적용되고 있습니다. 이러한 변형의 대부분은 여전히 실제 신경망의 행동에서 영감을 받고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRNN(RNNs)은 일련의 메모리 구성요소를 통합하여 처리하는데, 수년 전에 자연어 처리(NLP)에서 중요한 접근 방식을 나타냅니다. RNNs는 Long-Short Term Memory (LSTM) Networks로 나아가는 길을 열며, NLP 응용 프로그램에서 신경망의 성능을 높였습니다. 이후 LSTM 네트워크는 트랜스포머 모델과 GPT(Generative Pre-trained Transformer)에 의해 대체되었는데, 이것이 ChatGPT의 기초가 되었습니다. 이 기사에서는 LSTM 네트워크가 무엇이며, 그들을 특별하게 만드는 이유에 대해 살펴봅니다.\n\n# RNN의 의미\n\nLSTM 네트워크가 어떻게 작동하는지 이해하기 위해서는 그 목적에 대해 생각해 보는 것이 중요합니다. RNN과 LSTM 네트워크는 비슷한 목표를 따릅니다. 이들은 순차적으로 저장된 데이터를 모델링하고 예측하는 데 사용됩니다. 이는 이 유형의 네트워크가 데이터 시퀀스를 읽고 다음 값이 무엇인지 예측하려고 한다는 것을 의미합니다. 특정 도시의 지난 30일간의 평균 온도를 기록한 로그가 있다고 가정해 봅시다. 그리고 31일차의 온도를 추정하고 싶다면 어떻게 할까요? 한 가지 방법은 온도를 다른 변수에 상관시켜서, 31일에 이러한 변수의 값에 따라 새로운 온도를 추정하는 것입니다. RNN은 몇 일, 예를 들어 30일 이내의 일부 날짜를 고려하여 이전 온도 값을 기반으로 31일의 온도를 예측합니다. 한 마디로, RNN은 시퀀스를 기억하고 다음 값 또는 값 그룹을 제시하려고 노력합니다. 이전에 작성한 기사 중에 RNN이 메모리 전문가와 어떻게 비교되면서 RNN이 어떻게 단계적으로 작동하는지 설명했습니다.\n\n이전 날짜의 온도를 기반으로 새로운 온도를 예측하는 아이디어는 다른 응용 분야로 확장할 수 있습니다. 소개에서 언급된 것처럼, RNN은 NLP 중 첫 접근 방식 중 하나였습니다. 아이디어는 RNN을 텍스트로 학습한 다음, RNN을 사용하여 입력 후 다음에 나오는 단어 또는 단어 그룹을 예측하는 것입니다. 이러한 아이디어는 자동 번역뿐만 아니라 음성 및 필기 인식과 같은 과제에도 적용할 수 있습니다. RNN이 이러한 과제들을 다룰 때 직면하는 문제 중 하나는 죽거나 폭발하는 기울기(vanishing/exploding gradients)로 인한 어려움입니다. 이 문제의 해법은 LSTM 네트워크의 적용입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nFigure 1은 완전히 연결된 인공 신경망(ANNs)과 순환 신경망(RNNs) 간의 주요 구조적 차이를 보여줍니다. 이 간단한 예에서는 (X1,Y1) 및 (X2,Y2)의 값이 Y3의 새로운 값 계산에 사용됩니다. 실제로는 ANN과 RNN이 많은 입력-출력 쌍으로 훈련됩니다. 훈련 과정이 완료되면 네트워크는 새로운 값을 예측하는 데 사용됩니다. 이 프로세스에 익숙하지 않다면, 이 기사의 끝에 유용한 참고 자료를 추가했습니다. 여기에 이 프로세스를 설명한 나의 시도도 곁들였습니다. ANNs와 RNNs 사이의 훈련 및 예측의 일반적인 아이디어는 비슷하지만, 구조적으로 큰 차이가 있습니다. RNN에서는 Y1과 Y2의 값이 X1과 X2 대신 네트워크를 훈련하는 데 사용됨을 주목하십시오. 또한 첫 번째 단위와 두 번째 단위를 연결하는 가중치가 있으며, 이는 이전 단위에서 온 활성화를 나타냅니다. 이 가중치는 RNN의 \"기억\" 구성 요소를 나타냅니다. 더 큰 가중치는 RNN이 이전 값에 더 많은 중요성을 부여함을 의미하고, 더 작은 가중치는 RNN이 과거 값을 잘 기억하지 못한다는 것을 의미합니다. 이것은 신경망 구조의 가중치이므로, 그 값은 프로세스 중에 학습되며, RNN은 재현하려는 순서가 더 많은지 덜 많은지를 결정할 수 있습니다.\n\n![Image](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_1.png)\n\nRNN의 훈련 및 적용 중 중요한 측면은 네트워크가 읽고 훈련 및 예측에 사용하는 값 시퀀스의 길이입니다. 시퀀스 길이가 15라고 가정해 봅시다. 이는 RNN이 15개의 입력 값을 읽은 후 16번째 값을 찾아 훈련한다는 것을 의미합니다(항상 그렇지는 않습니다. 동적 RNN도 있기 때문입니다). 시퀀스 길이로 돌아가보면, 더 긴 시퀀스 길이는 RNN이 최종 출력에 여러 읽기를 통합할 수 있어 유익합니다. 그러나 더 긴 시퀀스 길이는 사라지는/폭주하는 그래디언트를 유발합니다. LSTM 네트워크는 이 문제를 어떻게 극복할까요?\n\n# LSTM 네트워크\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLSTM 네트워크는 어떤 정보를 “기억”하고 어떤 정보를 “잊을지” 결정하도록 훈련됩니다. RNN에서는 이전 유닛의 활성화에만 적용되는 메모리 구성 요소에 대한 가중치가 있습니다. 그러나 LSTM에서는 메모리 구성 요소의 개념이 장기 메모리 구성 요소(셀 상태)와 단기 메모리 구성 요소(은닉 상태)로 대체됩니다. 각 구성 요소는 서로 다른 게이트에 분산된 일련의 편향 및 가중치와 관련이 있습니다. 이는 각 입력이 네트워크에서 얼마나 많은 정보를 유지하고 얼마나 버릴지 결정하는 게이트(또는 단계)를 통과한다는 것을 의미합니다. 이 결정은 훈련 과정 중에 학습된 가중치와 편향 값에 기반합니다.\n\n그림 2는 단일 입력을 읽는 매우 간단한 LSTM 네트워크 스케치를 보여줍니다. 실제 LSTM 네트워크 유닛을 살펴보기 전에이 단순화된 다이어그램을 먼저 분석하겠습니다. RNN을 나타내는 이전 그림과 얼마나 다른지에 주목하세요. 기억할 점 중 첫 번째는 입력 값 외에도 LSTM 네트워크에는 단기 및 장기 메모리 구성 요소가 있다는 것입니다. 이러한 구성 요소는 공식적으로 셀 상태(C)와 숨겨진 상태(h)로 알려져 있습니다. 이 표기법은 나중에 사용되겠지만, 우리는 현재 이전 이름을 사용할 것입니다. 입력 및 메모리 구성 요소는 세 가지 서로 다른 게이트를 통과합니다: 삭제, 입력 및 출력.\n\n- 삭제 게이트는 장기 기억의 얼마나 보관해야 하는지를 결정합니다. 이 게이트는 현재 입력뿐만 아니라 단기 메모리 구성 요소를 고려하여 0과 1 사이의 값을 계산하여 장기 메모리 구성 요소를 곱합니다. 0의 삭제 게이트는 네트워크가 이전 정보를 보존하지 않음을 의미합니다. 그 답은 새로운 입력에만 기초합니다.\n- 입력 게이트는 새 정보가 장기 메모리 구성 요소에 보존되어야 하는 양을 결정합니다. 이 게이트의 출력은 다음 입력에 보존되는 장기 기억 구성 요소에 추가됩니다. 이 구성 요소가 삭제 및 입력 게이트에만 연결된다는 점에 유의하십시오. 이는 각 반복에서 장기 기억이 무엇을 버리고 어떤 정보를 추가해야 하는지에 따라 업데이트된다는 것을 의미합니다.\n- 출력 게이트는 입력 및 단기 메모리 구성 요소를 고려하고 이전 단기 메모리 구성 요소로 저장될 새로운 장기 메모리 구성 요소의 양을 계산합니다. 이는 LSTM 네트워크에서 나온 최종 값이 장기 및 단기 메모리 구성 요소뿐만 아니라 출력 게이트도 고려하여 계산된다는 것을 의미합니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_2.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 LSTM 네트워크 셀의 구조를 파악했으니 여기서 발생하는 계산에 더 가깝게 살펴보겠습니다. Figure 3은 LSTM 네트워크 셀을 더 자세히 보여줍니다. 입력, 단기 기억 구성 요소 및 장기 기억 구성 요소는 각각 x, h 및 C로 표시됩니다. 이들 각각의 글자는 분석 중인 시간 기간에 해당하는 아래 첨자를 가지고 있습니다. t-1의 아래 첨자는 값이 이전 반복에 속한다는 것을 의미합니다. 예를 들어, forget gate는 현재 입력(xt)과 이전 반복의 단기 기억 구성 요소(ht-1)를 고려합니다. 게이트들은 또한 일련의 가중치와 편향을 고려합니다. forget 및 output 게이트에는 각각 3개의 매개변수가 있습니다:\n\n- 편향(bxf, bxo)\n- 입력을 곱하는 가중치(wxf, wxo)\n- 단기 기억 구성 요소를 곱하는 가중치(whf, who)\n\n가중치와 편향은 활성화 함수로 들어가기 전에 입력 값에 곱해지고 더해집니다. 이 예에서 forget 및 output 게이트 모두 시그모이드 활성화 함수를 가지며 그 최종 활성화(af, ao)는 Figure 3 우측에 표시됩니다. 이러한 게이트와 달리, input 게이트는 두 개의 활성화 함수, 시그모이드 및 tanh가 있으며 해당 가중치와 편향을 가집니다. 이는 단일 LSTM 네트워크 단위에 대해 훈련해야 할 매개변수의 총 수가 12임을 의미합니다.\n\nLSTM 네트워크 셀에 대해 이해해야 할 마지막 중요한 측면은 새로운 C 및 h가 어떻게 계산되는지입니다. 이전 장기 기억 구성 요소는 먼저 forget 게이트의 출력과 곱해진 후 입력 게이트의 결과에 추가됩니다. 이는 forget 게이트가 C의 얼마나 다음 반복에 전달하는지를 결정하고, input 게이트가 C의 새 값에 얼마나 추가할지를 결정합니다. 단기 기억 구성 요소 계산을 위해 output 게이트의 결과는 새로운 C의 tanh와 곱해집니다. 이는 output 게이트가 장기 기억 구성 요소를 다음 반복에 얼마나 전달할지 결정합니다. C의 값이 1 이상일 수 있으므로, 값이 -1과 1 사이로 제한되도록 tanh 연산이 적용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_3.png)\n\n입력이 모든 게이트를 통과하면, 새로운 C와 h가 다음 반복으로 전달되어 새 입력과 상호 작용합니다(그림 4). 이 과정은 시퀀스의 모든 값에 대해 반복되며, 해당 시퀀스의 최종 h에 도달할 때까지 반복됩니다.\n\n![이미지](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_4.png)\n\n# 앞으로 나아가기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLSTM 네트워크는 다른 인공 신경망(ANN)에서 사용되는 방법론과 유사한 방법으로 훈련될 수 있습니다. 문제에 따라 각 순전파 사이클 이후 업데이트되는 손실 함수를 정의합니다. 그런 다음 이 손실 함수를 사용하여 역전파 과정을 통해 가중치와 편향을 업데이트합니다. RNN 및 LSTM 네트워크의 경우, 역전파는 일반적으로 모든 반복 유닛을 통해 가중치와 편향을 누적하는 과정이기 때문에 시간을 거슬러 역전파(backpropagation through time, BPTT)라고합니다. 이는 LSTM 네트워크의 단일 유닛을 읽는 LSTM 네트워크 셀에서 순전파 과정이 어떻게 진행되는지 설명하는 간단한 구현과 순전파, 역전파 과정에 대해 상세히 설명하는 주피터 노트북입니다.\n\n그림 5는 LSTM 네트워크 셀에서 단일 유닌을 읽는 순전파 과정의 예시를 보여줍니다. h의 최종 값이 네트워크 내 모든 게이트를 통해 전달되는 정보를 함께 전달하는 반면, 최종 C는 출력 게이트와 상호작용하지 않는 것에 주목하세요. 이 게이트들 각각이 보존할 정보와 잊을 정보를 규제자로 작용합니다. 입력과 상호작용하는 최적의 방법을 학습하는 완전히 연결된 ANN에서 가중치와 편향이 학습되는 것과 유사하게, LSTM 네트워크에서 매개변수는 보존하거나 버릴 최적의 정보 양을 학습하기 위해 훈련됩니다.\n\n![image](/assets/img/2024-05-23-ToKnowIsAlsotoRemember_5.png)\n\n# 더 많은 유닛?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금까지의 숫자와 예제는 단일 유단 LSTM 네트워크를 보여주었지만, 다른 유형의 네트워크와 마찬가지로 LSTM 네트워크는 여러 개의 유닌을 가질 수 있습니다. 단위 수에 따라 매개 변수 수는 어떻게 변하나요? 두 개의 유닌을 갖는 LSTM 네트워크의 경우, 학습할 매개 변수가 12개가 아닌 32개가 있습니다. 추가된 20개의 매개 변수는 어디에 있을까요? 그러면, 이제 조금 복잡해 질 것입니다. 이를 여러 부분으로 나눠서 살펴보겠습니다.\n\n첫 번째 유닛에는 12개의 매개 변수가 있습니다. 이전에 설명한 것과 같은 매개 변수들입니다: 입력을 곱하는 4개의 가중치, 숨겨진 상태(h)를 곱하는 4개의 가중치, 그리고 각 게이트에 대한 4개의 바이어스입니다. 두 번째 유닌도 12개의 관련된 매개 변수를 가지고 있습니다. 이는 지금까지 총 24개의 매개 변수를 가지게 되었다는 것을 의미합니다.\n\nLSTM 네트워크는 특정 유형의 RNN이므로 각 유닌 사이에 연결이 있을 것입니다. 이는 유닌 1에서 처리된 정보가 유닌 2로 전달된다는 것을 의미합니다. 각각의 연결은 고유의 가중치를 갖습니다. 두 개의 유닌을 갖는 LSTM 네트워크에서, 이전에 언급된 24개의 매개 변수 외에, 유닌 2의 각 게이트와 유닌 1의 각 게이트 사이의 연결 및 유닌 1의 숨겨진 상태와 유닌 2의 게이트 사이의 연결에 해당하는 8개의 매개 변수가 추가로 필요합니다. 그림 7은 유닌 2의 잊기 게이트에서 활성화를 계산하는 방법을 보여줍니다. 이 게이트가 이전 게이트와 이전 숨겨진 상태에 연결되어 있다는 점에 주목하세요. 그림에는 새로운 가중치가 5개만 표시되어 있지만, 실제로는 첫 번째 유닌의 숨겨진 상태가 두 번째 유닌의 각 게이트에 연결되기 때문에 8개의 가중치가 있습니다. n개의 유닌에 대한 매개 변수 수는 12n+4n(n-1) 또는 간소화된 표현으로 8(n+n²/2)입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_7.png\" /\u003e\n\n# Going backwards\n\n인공 신경망(ANNs)에서 흔히 볼 수 있는 바와 같이, 역전파 프로세스는 일반적으로 이해하고 구현하기 가장 어려운 부분입니다. 단일 유닛 LSTM 네트워크에서는 각 역전파가 4개의 편향과 8개의 가중치를 업데이트해야 하며, h(t-1) 및 C(t-1)도 업데이트해야 합니다. h(t-1)가 출력 게이트에 의존하고 현재 C는 다시 입력 및 망각 게이트에 따라 달라짐을 주목해야 합니다. 손실에 대한 편도함수를 계산할 때 이 사항을 고려하는 것이 중요합니다. 이전에 언급한 바와 같이, 이 Jupyter 노트북에는 역전파 프로세스를 포함한 간단한 LSTM 네트워크를 구축하는 데 필요한 모든 방정식이 포함되어 있습니다. 그림 8은 각 편도함수를 계산하는 데 도움이 되는 매개변수 간 의존성을 보여줍니다.\n\n\u003cimg src=\"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_8.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 응용 프로그램\n\n다음 섹션에는 LSTM 네트워크의 세 가지 응용 프로그램 예시가 포함되어 있습니다. 예시는 간단한 순서로 제공됩니다. 각 예시에 대한 파이썬 코드를 이 Jupyter 노트북에서 찾을 수 있습니다.\n\n## 연속 함수 모델링을 위한 바닐라 LSTM 네트워크\n\n이것은 처음부터 LSTM 네트워크를 구현하는 매우 간단한 예시입니다. 여기서 배울 중요한 교훈은 LSTM 네트워크에 데이터를 공급하기 전에 데이터를 올바르게 준비하는 중요성입니다. LSTM 네트워크로 모델링하고 싶은 연속 함수가 있다면, 먼저 입력-타겟 데이터의 쌍을 생성해야 합니다 (Figure 1 참조). 이 데이터는 시퀀스 길이에 따라 달라집니다. 예를 들어, 시퀀스 길이가 15인 경우, 각 입력 항목은 15개의 값이 포함되며 16번째 값은 해당 입력의 타겟이 됩니다. 네트워크에 입력하기 전에 데이터를 정규화하는 것도 중요합니다. 이 예시에서는 sin(x) 함수와 함께 웰에서의 석유 생산 행동을 모델링하기 위해 간단한 LSTM 네트워크가 사용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 워드 예측기를 구축하기 위한 바닐라 LSTM 네트워크\n\n이 예시에서는 이전의 바닐라 LSTM 네트워크가 워드 예측 문제에 적용되었습니다. 짧은 텍스트로 훈련된 후, 모델은 다음에 나올 단어를 예측합니다. 실제로 워드 처리 및 워드 예측 문제는 이 예시처럼 다가가지 않습니다. 그러나 LSTM 네트워크의 가능한 응용에 대한 간단하고 명확한 설명입니다.\n\n## Keras의 LSTM 네트워크를 사용하여 워드 예측기 구축\n\n이 예시는 Keras의 LSTM 네트워크를 사용하여 긴 텍스트로 훈련된 후 다음 단어가 무엇인지 예측하는 더 현실적인 예제입니다. 이 예시에서는 NLP 문제에서 일반적인 추가인 임베딩 레이어를 사용합니다. 임베딩 레이어는 단어의 정수로 인코딩된 표현(인덱스)을 밀집된 벡터로 변환하여 단어 사이의 관계를 더 잘 모델링하는 데 도움이 되는 고정 크기의 벡터로 변환합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n인공 신경망 및 특히 순환 신경망을 사용하여 자연어 처리 문제에 접근하거나 연속 데이터를 모델링하는 것은 최근에 개발된 것이 아닙니다. 이 응용 프로그램은 오랫동안 존재해 왔으며 새로운 기능으로 계속 발전하고 있습니다. LSTM 네트워크가 어떻게 작동하는지 이해하고 그것을 특별한 종류의 RNN으로 만드는 요소를 파악하는 것은 결과와 예상대로 작동하지 않을 수 있는 이유에 대한 통찰력을 제공할 수 있습니다. 본문은 LSTM 네트워크에 대한 포괄적인 설명을 포함하고, 그 응용 예시 세 가지를 제시합니다. 대부분의 현재 NLP 도구 및 솔루션은 다른 네트워크 구조에 의존하지만 LSTM 네트워크 내부 작업에 대한 탄탄한 개념은 머신러닝 분야에서 항상 유익할 것입니다. 이것을 장기 기억 셀에 저장하는 것을 기억하세요! 😉\n\n# 참고문헌\n\n- Ng, Andrew. Machine Learning Specialization.\n- Keras 'Embedding' 레이어는 어떻게 작동합니까? CrossValidated 게시물. 2017\n- Cowan, Nelson (2009). 장기, 단기 및 직업기억 사이의 차이점은 무엇인가? — PMC. Prog Brain Res. 2008;169:323–38. doi: 10.1016/S0079–6123(07)00020–9. PMID: 18394484; PMCID: PMC2657600.\n- Erz, Hendrik (2023). ChatGPT를 생산적으로 사용하는 방법 | Hendrik Erz. hendrik-erz.de, 2023년 2월 14일\n- Adams, Tim (2013). Henry Molaison: 우리가 결코 잊지 않을 기억상실자 | 기억 | The Guardian\n- Dittrich, Luke (2016). 기억할 수 없던 두뇌 — 뉴욕 타임즈\n","ogImage":{"url":"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_0.png"},"coverImage":"/assets/img/2024-05-23-ToKnowIsAlsotoRemember_0.png","tag":["Tech"],"readingTime":13},{"title":"Ontologies 및 언어 모델을 활용하여 정확한 질문 응답하기","description":"","date":"2024-05-23 17:20","slug":"2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering","content":"\n금일의 데이터 중심 세계에서는 방대한 양의 정보를 활용하여 정확하게 질문에 답하는 능력이 중요합니다. 대형 언어 모델(LLM)을 활용한 질문 응답(QA) 시스템은 이러한 측면에서 큰 가능성을 보여주고 있습니다.\n\n하지만, 이러한 시스템의 정확도와 신뢰성을 보장하는 것은 여전히 중요한 과제입니다.\n\ndata.world의 최근 연구에 따르면, 온톨로지와 지식 그래프를 활용하면 LLM 기반 QA 시스템의 성능을 크게 향상시킬 수 있음을 입증했습니다.\n\n본 글에서는 온톨로지 기반의 쿼리 유효성 검증과 LLM을 활용한 쿼리 복구를 결합한 혁신적인 접근 방식을 탐구하여, 질문 응답에서 전례없는 수준의 정확성을 달성하는 방법을 살펴보겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 배경\n\n질문 응답 시스템은 구조화된 또는 구조화되지 않은 데이터 소스에서 정보를 추출하여 사용자 쿼리에 정확하고 관련성 높은 응답을 제공하는 것을 목표로 합니다. 기존의 QA 시스템은 종종 자연어 쿼리의 복잡성과 모호성에 노출되어 최적의 결과를 얻기 어려웠습니다. 지식 그래프와 온톨로지의 등장은 도메인 지식을 표현하고 추론하는 강력한 프레임워크를 제공하여 보다 정교한 QA 방법을 가능케 하였습니다 [2].\n\n대규모 언어 모델인 GPT-4와 같은 모델은 자연어 처리 분야를 혁신적으로 변화시켰으며, 인간과 유사한 텍스트를 이해하고 생성하는 놀라운 능력을 보여주었습니다. 대형 언어 모델은 SQL 또는 SPARQL 쿼리를 사용하여 구조화된 데이터베이스에서 질문에 답변하는 등 다양한 QA 작업에 적용되었습니다 [3]. 그러나 LLM이 생성한 쿼리의 정확도는 기반이 되는 데이터 스키마와 의미에 대한 명확한 지식 부족으로 제한될 수 있습니다.\n\n# Ontology-based Query Check (OBQC)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png\" /\u003e\n\nLLM 기반 QA 시스템의 한계를 해결하기 위해 연구자들은 Ontology 기반 쿼리 체크 (OBQC) 접근 방식을 제안했습니다 [1]. OBQC는 온톨로지에 인코딩된 의미 정보를 활용하여 LLM이 생성한 SPARQL 쿼리의 정확성을 검증합니다. 이 과정은 몇 가지 주요 단계로 이루어집니다:\n\n1. 생성된 SPARQL 쿼리에서 기본 그래프 패턴 (BGP)을 추출하여 쿼리의 그래프 패턴을 나타냅니다 [1].\n2. :쿼리( BGP가 RDF로 바뀐 것을 나타냄)와 :온톨로지(온톨로지 자체를 나타냄)의 두 개의 명명된 그래프를 캡슐화한 결합 그래프를 구성합니다 [1].\n3. SPARQL 쿼리로 구현된 온톨로지 일관성 규칙을 적용하여 :쿼리와 :온톨로지 그래프 사이의 위반을 확인합니다 [1].\n4. 생성된 쿼리에서 구체적인 오류를 식별하고 각 규칙 위반에 대한 사람이 읽을 수 있는 설명을 생성합니다 [1].\n\nLLM이 생성한 쿼리를 온톨로지의 의미와 비교함으로써 OBQC는 도메인이나 범주 클래스 불일치, 호환되지 않는 속성 사용, 정의되지 않은 속성 등 다양한 유형의 오류를 감지할 수 있습니다. 이 유효성 검사 프로세스는 생성된 쿼리가 기저지식 그래프와 일관된지 확인하여 QA 시스템의 전체 정확성을 향상시키는 데 도움을 줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# LLM Repair\n\nOBQC는 생성된 쿼리의 오류를 식별하는 데 능숙하지만, 이러한 오류를 수정하는 메커니즘을 제공하지는 않습니다. 여기서 LLM Repair 구성 요소가 필요합니다. LLM Repair는 OBQC에 의해 제공된 오류 설명을 기반으로 쿼리를 반복적으로 다듬고 수정하는 능력을 활용합니다 [1].\n\n수리 과정은 오류 설명과 부정확한 SPARQL 쿼리를 포함하는 프롬프트를 작성하여 시작됩니다. 이 프롬프트는 그런 다음 LLM에 공급되며, LLM은 의도한 의미와 구조를 보존하면서 식별된 문제를 해결하기 위해 쿼리를 다시 작성하려고 시도합니다 [1]. 수정된 쿼리는 그런 다음 OBQC로 반환되어 확인을 받으며, 유효한 쿼리를 얻거나 최대 반복 횟수에 도달할 때까지 반복적인 피드백 루프를 형성합니다 [1].\n\nLLM Repair는 LLM이 자연어 설명을 이해하고 일관된 응답을 생성하는 능력에 활용합니다. 질문이나 온톨로지에 명시적인 액세스가 필요하지 않고 오류 설명을 활용함으로써, 쿼리를 수정하는 데 효과적으로 학습할 수 있습니다 [1].\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n수리 과정이 일정 횟수의 반복 이후 유효한 쿼리를 생성하지 못하면, LLM 수리는 \"알 수 없음\" 또는 \"불확실\" 응답을 반환하여 신뢰할만한 답변을 생성할 수 없음을 표시합니다 [1]. 이 실패 안전 기구는 수리 시도가 실패할 경우 잘못된 또는 오해를 일으킬 수 있는 결과를 시스템이 제공하는 것을 방지합니다.\n\n# 실험 설정 및 결과\n\nOBQC 및 LLM 수리 접근 방식의 효과를 평가하기 위해 연구자들은 Chat with the Data 벤치마크를 사용한 실험을 진행했습니다 [1]. 이 벤치마크에는 기업용 SQL 스키마, 질문-답변 쌍, 그리고 OWL 온톨로지 매핑이 포함되어 있습니다. 테스트된 QA 시스템은 SPARQL 제로샷 프롬프트로 GPT-4였으며, 쿼리는 가상화된 지식 그래프에서 실행되었습니다 [1].\n\n실험 결과는 정확도와 오류 감소에서 상당한 향상을 보여주었습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- OBQC 및 LLM Repair을 사용하여 전체 실행 정확도가 42.88%에서 72.55%로 향상되었습니다 [1].\n- 시스템에서 잘못된 것으로 식별된 알 수 없는 쿼리가 전체 오류율인 19.44% 중 8%를 차지했습니다 [1].\n- 고복잡도 스키마에 관한 질문의 정확도 향상이 특히 유의미했습니다 [1].\n\n추가 분석 결과, OBQC의 도메인 관련 규칙이 수리의 70%를 담당하는 가장 일반적인 규칙임이 밝혀졌습니다 [1]. 이는 온톨로지에서 도메인 지식을 정확하게 모델링하는 것이 QA 성능을 향상시키는 데 중요한 역할을 한다는 것을 시사합니다.\n\n# 현실 세계의 영향과 응용\n\nOBQC 및 LLM Repair의 유망한 결과들은 이미 현실 세계 응용분야에서 찾아보실 수 있습니다. 기업용 데이터 카탈로그 및 발견 솔루션의 선도 업체인 data.world은 이러한 구성 요소를 AI Context Engine에 통합하였습니다 [1]. AI Context Engine은 구조화된 데이터와의 신뢰할 수 있는 대화를 지원하여 고객이 질문을 하고 정확하고 컨텍스트 인식형 답변을 받을 수 있도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n몇몇 data.world 고객은 AI Context Engine을 도입하여, 다양한 사용 사례에서 향상된 QA 능력을 활용하고 있습니다 [1]. 이는 실제 환경에서 온톨로지 기반 검증과 LLM 기반 복구를 결합한 가치와 영향을 보여줍니다.\n\n## 미래 방향성과 도전 과제\n\n현재 방법이 높은 성공률을 보여주고 있지만, 미래 연구와 개선을 위한 여러 분야가 아직 남아 있습니다. 하나의 주요 도전 과제는 OBQC를 보다 복잡한 온톨로지 구조에 대응할 수 있도록 확장하는 것입니다. 이는 OWL 어키오름이 포함된 온톨로지 조합(연합, 교집합 또는 다른 논리 연산자)에 대한 처리를 의미합니다 [1]. 이 도전에 대응함으로써 시스템이 쿼리를 풍부하고 표현력 있는 온톨로지에 대해 유효성을 검증하는 능력을 더욱 강화할 수 있을 것입니다.\n\n또 다른 중요한 방향은 해당 접근 방식을 다른 도메인과 데이터 집합으로 일반화하는 것입니다. 현재 실험은 기업용 SQL 스키마와 질문-답변 쌍을 다루는 Chat with the Data 벤치마크에 주로 초점을 맞추었습니다 [1]. 시스템의 성능을 다양한 도메인과 데이터 소스 범위에서 평가함으로써 보다 넓은 적용 가능성과 견고성을 평가할 수 있을 것입니다.\n\n확장성과 계산 비용에 대한 조사도 필요합니다. 온톨로지와 데이터 집합의 크기와 복잡성이 증가함에 따라, OBQC와 LLM Repair 구성 요소의 효율성은 점점 더 중요해집니다 [1]. 최적화된 알고리즘 및 병렬 처리 기술을 개발함으로써 대규모 응용 프로그램에 대한 시스템의 실용성과 반응성을 보장하는 데 도움이 될 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n체계 기반 쿼리 유효성 검사와 LLM(언어 모델) 기반 쿼리 수리의 결합은 질문 응답 분야에서 중요한 발전을 나타냅니다. 오전톨로지에 인코딩된 의미 지식과 LLM의 생성적 능력을 활용하여, 이 방법은 전례없는 수준의 정확도와 신뢰성을 실현합니다.\n\n실험 결과와 현실 세계에서의 채택은 이 기법이 신뢰할 수 있고 맥락에 맞는 구조화된 데이터와의 대화를 가능케 함에 대한 엄청난 잠재력을 입증합니다. 조직이 통찰을 도출하고 데이터 기반 결정을 내리는 데 QA 시스템에 점점 더 의존함에 따라, 정확성의 중요성은 지나치게 강조될 수 없습니다.\n\n그러나 이 방법의 전체 잠재력을 실현하기 위해서는 계속된 연구 및 개발 노력이 필요합니다. 더 복잡한 온톨로지 구조를 처리하고, 다양한 도메인에 적용할 수 있도록 일반화하고, 확장성 문제를 해결하는 것이 미래 작업의 주요 분야입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nOBQC와 LLM Repair의 성공은 의미론, 온톨로지, 그리고 지식 그래프가 정확하고 신뢰할 수 있는 QA 시스템을 구축하는 데 중요한 역할을 한다는 점을 강조합니다. 이러한 기본기술에 투자하고 계속해서 가능한 한 경계를 넓힘으로써, 우리는 자연어 인터페이스의 진정한 잠재력을 발휘하고 사용자들이 필요로 하는 정보에 원활하게 액세스할 수 있도록 돕는 것이 가능합니다.\n\n# 참고문헌\n\n[1] Dean Allemang과 Juan F. Sequeda. 2024. “Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue!” 기술 보고서.\n[2] Aidan Hogan 등. 2021. “Knowledge Graphs.” 데이터, 의미론, 그리고 지식에 관한 합성 강의. Morgan \u0026 Claypool Publishers.\n[3] Juan Sequeda, Dean Allemang, 그리고 Brad Jesson. 2023. “A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model’s Accuracy for Question Answering on Enterprise SQL Databases.” arXiv 사전인쇄 arXiv:2406.01688.\n","ogImage":{"url":"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png"},"coverImage":"/assets/img/2024-05-23-LeveragingOntologiesandLanguageModelsforAccurateQuestionAnswering_0.png","tag":["Tech"],"readingTime":8},{"title":"깊은 학습 모델이 GPU에서 더 빨리 실행되는 이유 CUDA 프로그래밍 간단 소개","description":"","date":"2024-05-23 17:17","slug":"2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming","content":"\n## .to(\"cuda\") 가 무엇을 하는지 이해하고 싶은 분들을 위해\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png)\n\n요즘에는 딥 러닝을 이야기할 때 성능을 향상시키기 위해 GPU를 활용한다고 연관 지어지는 것이 매우 일반적입니다.\n\nGPU(그래픽 처리 장치)는 원래 이미지, 2D 및 3D 그래픽의 렌더링을 가속화하기 위해 설계되었습니다. 그러나 다수의 병렬 작업을 수행할 수 있는 능력으로 인해 그 유용성은 그 이상으로 확장되어 딥 러닝과 같은 응용 프로그램에까지 이어집니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n깊은 학습 모델에 GPU를 사용한 것은 2000년대 중후반 경에 시작되었으며 2012년에 AlexNet이 등장하면서 매우 인기를 끌었습니다. AlexNet은 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 디자인한 합성곱 신경망으로, 2012년 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 우승했습니다. 이 승리는 깊은 신경망을 통한 이미지 분류의 효과성 및 대형 모델 학습에 GPU 사용을 보여주어 중요한 이정표가 되었습니다.\n\n이후 이 기술적 발전을 통해 깊은 학습 모델에 GPU를 사용하는 것이 점점 인기를 얻으며, PyTorch나 TensorFlow와 같은 프레임워크 개발에 이바지했습니다.\n\n요즘에는 PyTorch에서 데이터를 GPU로 전송하려면 .to(\"cuda\")만 작성하면 학습이 가속화되는 것으로 예상됩니다. 하지만 실제로 어떻게 GPU 컴퓨팅 성능을 활용하는지 알아볼까요?\n\n신경망, CNNs, RNNs 및 트랜스포머와 같은 깊은 학습 아키텍처는 기본적으로 행렬 덧셈, 행렬 곱셈 및 행렬에 함수를 적용하는 수학 연산을 사용하여 구축됩니다. 따라서 이러한 연산을 최적화하는 방법을 찾으면 깊은 학습 모델의 성능을 개선할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러니까, 간단하게 시작해 봅시다. 두 벡터 C = A + B를 추가하고 싶다고 상상해 보세요.\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_1.png)\n\n이를 C에서 간단히 구현하는 방법은 다음과 같습니다:\n\n```js\nvoid AddTwoVectors(float A[], float B[], float C[]) {\n    for (int i = 0; i \u003c N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위에서 볼 수 있듯이 컴퓨터는 벡터를 반복해서 각 쌍의 요소를 순차적으로 더해야 합니다. 그러나 이러한 작업은 서로 독립적입니다. i번째 쌍의 요소를 더하는 것은 다른 쌍에 의존하지 않습니다. 그래서 만약 이러한 작업들을 병렬로 실행할 수 있다면 어떨까요?\n\n간단한 접근 방식은 CPU 멀티스레딩을 사용하여 모든 계산을 병렬로 실행하는 것일 것입니다. 그러나 딥러닝 모델에서는 수백만 개 요소를 가진 대규모 벡터를 다루게 됩니다. 일반적인 CPU는 동시에 약 10여 개의 스레드만 처리할 수 있습니다. 이때 GPU가 필요한 것입니다! 현대의 GPU는 수백만 개의 스레드를 동시에 실행할 수 있어 이러한 대규모 벡터에 대한 수학적 연산의 성능을 향상시킵니다.\n\n# GPU 대 CPU 비교\n\nCPU 연산이 GPU보다 단일 작업에서 빠를 수 있지만 GPUs의 장점은 병렬화 능력에 있습니다. 이것의 이유는 그들이 서로 다른 목표로 설계되었기 때문입니다. CPU는 가능한 한 빠르게 연산 순서(스레드)를 실행하는 데 설계되었지만(동시에 약 10여 개의 스레드만 실행할 수 있음) GPU는 수백만 개의 연산을 병렬로 실행하는 데 설계되었습니다(개별 스레드의 속도를 희생하면서).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래의 비디오를 확인해보세요:\n\n예를 들어, CPU가 페라리와 같다고 상상해보세요. GPU는 버스입니다. 한 사람을 옮기는 작업이라면, 페라리(CPU)가 더 나은 선택일 것입니다. 그러나 여러 사람을 이동시키는 경우에는, 페라리(CPU)가 한 번에 더 빠르지만, 버스(GPU)는 한 번에 모두를 옮겨 더 빠르게 목적지에 도착하게 됩니다. CPU는 연속적인 작업을 처리하는 데 뛰어나지만 GPU는 병렬 작업에 적합하게 설계되어 있습니다.\n\n![이미지](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_2.png)\n\n더 높은 병렬 기능을 제공하기 위해 GPU 설계는 데이터 캐싱 및 흐름 제어 보다는 데이터 처리에 더 많은 트랜지스터를 할당합니다. 이는 CPU와는 달리, CPU가 단일 스레드 성능 및 복잡한 명령 실행을 최적화하기 위해 상당 부분의 트랜지스터를 할당하는데 사용하는 것과 대조적입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래 그림은 CPU와 GPU의 칩 자원 분포를 보여줍니다.\n\n![CPU vs GPU Resources](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_3.png)\n\nCPU는 강력한 코어와 더 복잡한 캐시 메모리 아키텍처(이를 위해 상당한 양의 트랜지스터를 할당)를 갖고 있습니다. 이 설계는 순차 작업의 신속한 처리를 가능하게 합니다. 반면, GPU는 고수준의 병렬성을 달성하기 위해 많은 코어를 갖는 것을 우선시합니다.\n\n이러한 기본 개념을 이해했으니, 실전에서 이러한 병렬 처리 능력을 어떻게 활용할 수 있을까요?\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# CUDA 소개\n\n딥러닝 모델을 실행할 때, 아마도 PyTorch나 TensorFlow와 같은 인기있는 Python 라이브러리를 사용하게 될 것입니다. 그러나 이러한 라이브러리의 핵심이 C/C++ 코드로 구동된다는 것은 잘 알려져 있습니다. 또한 앞에서 언급했듯이, 처리 속도를 높이기 위해 GPU를 사용할 수 있습니다. 여기서 CUDA가 등장합니다! CUDA는 NVIDIA가 개발한 일반 목적의 처리를 위한 플랫폼으로, Compute Unified Architecture의 약자입니다. 그러므로 게임 엔진에서 그래픽 계산을 처리하는 데 DirectX가 사용되는 것과 달리, CUDA는 개발자가 NVIDIA의 GPU 연산 능력을 그래픽 렌더링에만 한정되지 않고 일반 목적의 소프트웨어 응용프로그램에 통합할 수 있도록 합니다.\n\n이를 구현하기 위해 CUDA는 GPU의 가상 명령어 집합과 특정 작업(예: CPU와 GPU 간의 데이터 이동)에 액세스를 제공하는 간단한 C/C++ 기반 인터페이스인 CUDA C/C++을 제공합니다.\n\n더 나아가기 전에, CUDA 프로그래밍 개념과 용어를 몇 가지 이해해 보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 호스트: CPU 및 해당 메모리를 가리킵니다.\n- 장치: GPU 및 해당 메모리를 가리킵니다.\n- 커널: 장치(GPU)에서 실행되는 함수를 가리킵니다.\n\n그래서 CUDA를 사용하여 작성된 기본 코드에서 프로그램은 호스트(CPU)에서 실행되며, 데이터를 장치(GPU)에 전송한 후 장치(GPU)에서 실행될 커널(함수)을 시작합니다. 이러한 커널은 병렬로 여러 스레드에 의해 실행됩니다. 실행이 완료되면 결과는 장치(GPU)에서 호스트(CPU)로 다시 전송됩니다.\n\n그러니까 두 벡터를 더하는 문제로 돌아가 봅시다:\n\n```js\n#include \u003cstdio.h\u003e\n\nvoid AddTwoVectors(float A[], float B[], float C[]) {\n    for (int i = 0; i \u003c N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n\nint main() {\n    ...\n    AddTwoVectors(A, B, C);\n    ...\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCUDA C/C++에서 프로그래머는 CUDA 스레드에 의해 병렬로 N번 실행되는 C/C++ 함수 인 켤널이라고 불리는 함수를 정의할 수 있습니다.\n\n켤널을 정의하려면 **global** 선언 지정자를 사용하고, 이 켤널을 실행하는 CUDA 스레드의 수는 ... 표기법을 사용하여 지정할 수 있습니다:\n\n```js\n#include \u003cstdio.h\u003e\n\n// 켤널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n    ...\n    // N개의 스레드로 켤널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(A, B, C);\n    ...\n}\n```\n\n각 스레드는 켤널을 실행하고 내장 변수를 통해 켤널 내에서 액세스할 수있는 고유한 스레드 ID threadIdx가 제공됩니다. 위의 코드는 크기가 N 인 두 벡터 A와 B를 더하여 결과를 벡터 C에 저장합니다. 순차적으로 각 쌍-wise 추가를 실행하는 루프 대신, CUDA는 우리에게 모든 이러한 작업을 N 개의 스레드를 사용하여 동시에 수행할 수 있도록 허용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 이 코드를 실행하기 전에 다른 수정 작업을 해야 합니다. 커널 함수는 장치(GPU) 내에서 실행되기 때문에 모든 데이터는 장치 메모리에 저장되어야 합니다. 다음 CUDA 내장 함수를 사용하여 이 작업을 수행할 수 있습니다:\n\n```js\n#include \u003cstdio.h\u003e\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B, C를 위한 배열\n\n    ...\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B, C에 대한 장치 포인터\n\n    // 벡터 A, B, C에 대한 장치 메모리 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 호스트에서 디바이스로 벡터 A와 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N 개의 스레드로 커널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(d_A, d_B, d_C);\n\n    // 디바이스에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n}\n```\n\n커널에 변수 A, B, C를 직접 전달하는 대신 포인터를 사용해야 합니다. CUDA 프로그래밍에서는 커널 런치 내에서 호스트 배열(예: 예제의 A, B, C)을 직접 사용할 수 없습니다. CUDA 커널은 장치 메모리에서 작동하므로 커널이 작동하도록 장치 포인터(d_A, d_B, d_C)를 전달해야 합니다.\n\n이를 넘어서 cudaMalloc을 사용하여 장치에 메모리를 할당하고, cudaMemcpy를 사용하여 호스트와 장치 간에 데이터를 복사해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 벡터 A와 B의 초기화를 추가하고 코드 끝에 cuda 메모리를 새로고침할 수 있습니다.\n\n```js\n#include \u003cstdio.h\u003e\n\n// Kernel 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B, C에 대한 배열\n\n    // 벡터 A와 B 초기화\n    for (int i = 0; i \u003c N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B, C에 대한 장치 포인터\n\n    // 벡터 A, B, C에 대한 메모리 장치에 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 벡터 A 및 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N 스레드를 사용하여 커널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(d_A, d_B, d_C);\n\n    cudaDeviceSynchronize(); // 커널 호출 뒤 cudaDeviceSynchronize() 추가\n\n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\n또한, 커널 호출 후에 cudaDeviceSynchronize();를 추가해야 합니다. 이 함수는 호스트 스레드를 장치와 동기화하는 데 사용됩니다. 이 함수가 호출되면 호스트 스레드는 계속 실행하기 전에 이전에 발행된 모든 CUDA 명령이 장치에서 완료될 때까지 기다립니다.\n\n또한 GPU에서 버그를 식별할 수 있도록 일부 CUDA 오류 확인을 추가하는 것이 중요합니다. 이 확인을 추가하지 않으면 코드가 계속해서 호스트 스레드(CPU)를 실행하고 CUDA 관련 오류를 식별하는 것이 어려울 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래에 두 기술의 구현이 있습니다.\n\n```js\n#include \u003cstdio.h\u003e\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 벡터의 크기\n    float A[N], B[N], C[N]; // 벡터 A, B 및 C를 위한 배열\n\n    // 벡터 A와 B를 초기화\n    for (int i = 0; i \u003c N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B 및 C의 장치 포인터\n\n    // 장치에서 벡터 A, B 및 C에 대한 메모리 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 벡터 A와 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N개의 스레드로 커널 호출\n    AddTwoVectors\u003c\u003c\u003c1, N\u003e\u003e\u003e(d_A, d_B, d_C);\n\n    // 오류 확인\n    cudaError_t error = cudaGetLastError();\n    if(error != cudaSuccess) {\n        printf(\"CUDA 오류: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    // 모든 CUDA 스레드가 실행될 때까지 대기\n    cudaDeviceSynchronize();\n\n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\nCUDA 코드를 컴파일하고 실행하려면 시스템에 CUDA 툴킷이 설치되어 있는지 확인해야 합니다. 그런 다음 NVIDIA CUDA 컴파일러인 nvcc를 사용하여 코드를 컴파일할 수 있습니다. 만약 컴퓨터에 GPU가 없다면 Google Colab을 사용할 수 있습니다. Runtime → 노트 설정에서 GPU를 선택한 후 code.cu 파일에 코드를 저장하고 다음과 같이 실행하면 됩니다:\n\n```js\n%%shell\nnvcc example.cu -o compiled_example # 컴파일\n./compiled_example # 실행\n\n# 버그 감지 산소화 도구로 코드 실행도 가능합니다\ncompute-sanitizer --tool memcheck ./compiled_example\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그러나, 우리의 코드는 아직 완벽하게 최적화되지 않았습니다. 위의 예시에서는 크기가 N = 1000인 벡터를 사용했습니다. 그러나 이는 GPU의 병렬화 능력을 완전히 보여주지 못하는 작은 숫자입니다. 또한, 딥러닝 문제를 다룰 때는 종종 수백만 개의 매개변수를 가진 대규모 벡터를 다루게 됩니다. 그러나, 예를 들어 N = 500000으로 설정하고 위의 예시와 같이 1, 500000로 커널을 실행하면 오류가 발생할 것입니다. 이러한 작업을 개선하고 수행하기 위해서는 먼저 CUDA 프로그래밍의 중요한 개념인 Thread 계층 구조를 이해해야 합니다.\n\n# Thread 계층 구조\n\n커널 함수를 호출할 때는 블록의*개수, 블록당*쓰레드\\_개수 표기법을 사용합니다. 따라서, 위의 예시에서는 1개의 블록을 N개의 CUDA 쓰레드로 실행했습니다. 그러나, 각 블록은 지원할 수 있는 쓰레드 개수에 제한이 있습니다. 이는 블록 내의 모든 쓰레드가 동일한 스트리밍 멀티프로세서 코어에 있어야 하고 해당 코어의 메모리 자원을 공유해야 하기 때문에 발생합니다.\n\n다음 코드 스니펫을 사용하여 이 제한을 확인할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nint device;\ncudaDeviceProp props;\ncudaGetDevice(\u0026device);\ncudaGetDeviceProperties(\u0026props, device);\nprintf(\"블록당 최대 스레드 수: %d\\n\", props.maxThreadsPerBlock);\n```\n\n현재 코랩 GPU에서 스레드 블록 당 최대 1024개의 스레드가 포함될 수 있습니다. 그래서 우리는 예제에서 대량의 벡터를 처리하기 위해 훨씬 더 많은 스레드를 실행하기 위해 더 많은 블록이 필요합니다. 또한, 아래 그림에서 보여지는 대로 블록은 그리드로 구성됩니다.\n\n![CUDA Programming](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_4.png)\n\n이제 스레드 ID는 다음과 같이 액세스할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```c\n__global__ void AddTwoVectors(float A[], float B[], float C[], int N) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i \u003c N) // 배열 범위를 초과하지 않도록\n        C[i] = A[i] + B[i];\n}\n```\n\n그래서 우리의 스크립트는 다음과 같아졌습니다:\n\n```c\n#include \u003cstdio.h\u003e\n\n// 커널 정의\n__global__ void AddTwoVectors(float A[], float B[], float C[], int N) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i \u003c N) // 배열 범위를 초과하지 않도록\n        C[i] = A[i] + B[i];\n}\n\nint main() {\n    int N = 500000; // 벡터 크기\n    int threads_per_block;\n    int device;\n    cudaDeviceProp props;\n    cudaGetDevice(\u0026device);\n    cudaGetDeviceProperties(\u0026props, device);\n    threads_per_block = props.maxThreadsPerBlock;\n    printf(\"블록 당 최대 쓰레드 수: %d\\n\", threads_per_block); // 1024\n\n    float A[N], B[N], C[N]; // 벡터 A, B 및 C를 위한 배열\n\n    // 벡터 A와 B 초기화\n    for (int i = 0; i \u003c N; ++i) {\n        A[i] = 1;\n        B[i] = 3;\n    }\n\n    float *d_A, *d_B, *d_C; // 벡터 A, B 및 C를 위한 장치 포인터\n\n    // 벡터 A, B 및 C를 위한 장치에 메모리 할당\n    cudaMalloc((void **)\u0026d_A, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_B, N * sizeof(float));\n    cudaMalloc((void **)\u0026d_C, N * sizeof(float));\n\n    // 벡터 A와 B를 호스트에서 장치로 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // 여러 블록과 블록 당 쓰레드 수로 커널 호출\n    int number_of_blocks = (N + threads_per_block - 1) / threads_per_block;\n    AddTwoVectors\u003c\u003c\u003cnumber_of_blocks, threads_per_block\u003e\u003e\u003e(d_A, d_B, d_C, N);\n\n    // 오류 확인\n    cudaError_t error = cudaGetLastError();\n    if (error != cudaSuccess) {\n        printf(\"CUDA 오류: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    // 모든 CUDA 쓰레드가 실행될 때까지 대기\n    cudaDeviceSynchronize();\n\n    // 벡터 C를 장치에서 호스트로 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // 장치 메모리 해제\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n}\n```\n\n# 성능 비교\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 다른 벡터 크기에 대해 CPU 및 GPU 연산을 비교한 것입니다.\n\n![Comparison of CPU and GPU computation](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_5.png)\n\n어떤 경우에는 대규모 벡터 크기 N에 대해 GPU 처리의 이점이 뚜렷해집니다. 또한, 시간 비교는 커널/함수의 실행만을 고려한 것임을 기억해주세요. 호스트와 장치 간 데이터 복사에 소요되는 시간은 고려되지 않았는데, 일반적으로 큰 문제가 아닐 수 있지만, 우리의 경우에는 단순 덧셈 연산만 수행하기 때문에 상당히 중요합니다. 따라서, GPU 계산은 고도로 계산 집약적이고 또한 고도로 병렬화된 계산을 다룰 때만 그 이점을 나타냄을 기억하는 것이 중요합니다.\n\n# 다차원 스레드\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n좋아요, 이제 간단한 배열 작업의 성능을 향상시키는 방법을 알게 되었습니다. 그러나 딥 러닝 모델을 다룰 때는 행렬 및 텐서 작업을 처리해야 합니다. 이전 예제에서는 N 스레드를 사용하여 1차원 블록만 사용했습니다. 그러나 최대 3차원까지 다차원 스레드 블록을 실행할 수도 있습니다. 행렬 작업을 실행해야 할 경우 편리하게 NxM 스레드의 스레드 블록을 실행할 수 있습니다. 이 경우에는 행 = threadIdx.x, 열 = threadIdx.y와 같이 행렬 행 및 열 인덱스를 얻을 수 있습니다. 또한 편리하게 number_of_blocks 및 threads_per_block을 정의하는 데 dim3 변수 유형을 사용할 수 있습니다.\n\n아래 예제는 두 행렬을 더하는 방법을 보여줍니다.\n\n```js\n#include \u003cstdio.h\u003e\n\n// Kernel definition\n__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {\n    int i = threadIdx.x;\n    int j = threadIdx.y;\n    C[i][j] = A[i][j] + B[i][j];\n}\n\nint main() {\n    ...\n    // 1개의 NxN 스레드 블록을 사용하여 커널 호출\n    dim3 threads_per_block(N, N);\n    AddTwoMatrices\u003c\u003c\u003c1, threads_per_block\u003e\u003e\u003e(A, B, C);\n    ...\n}\n```\n\n이 예제를 여러 블록을 처리할 수 있도록 확장할 수도 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n#include \u003cstdio.h\u003e\n\n// Kernel definition\n__global__ void AddTwoMatrices(float A[N][N], float B[N][N], float C[N][N]) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i \u003c N \u0026\u0026 j \u003c N) {\n        C[i][j] = A[i][j] + B[i][j];\n    }\n}\n\nint main() {\n    ...\n    // Kernel invocation with 1 block of NxN threads\n    dim3 threads_per_block(32, 32);\n    dim3 number_of_blocks((N + threads_per_block.x - 1) ∕ threads_per_block.x, (N + threads_per_block.y - 1) ∕ threads_per_block.y);\n    AddTwoMatrices\u003c\u003c\u003cnumber_of_blocks, threads_per_block\u003e\u003e\u003e(A, B, C);\n    ...\n}\n```\n\n이런 멀티 차원 데이터를 다루는 법을 알게 되어서 좋습니다. 또한, 커널 내에서 함수를 호출하는 방법을 알아보겠습니다. 기본적으로 이는 **device** 선언 지정자를 사용하여 간단히 수행할 수 있습니다. 이는 기기(GPU)에서 직접 호출할 수 있는 함수를 정의합니다. 따라서 이러한 함수들은 오직 **global** 또는 다른 **device** 함수에서만 호출할 수 있습니다. 아래 예시는 시그모이드 연산을 벡터에 적용하는 방법을 보여줍니다.\n\n```js\n#include \u003cmath.h\u003e\n\n// Sigmoid function\n__device__ float sigmoid(float x) {\n    return 1 / (1 + expf(-x));\n}\n\n// Kernel definition for applying sigmoid function to a vector\n__global__ void sigmoidActivation(float input[], float output[]) {\n    int i = threadIdx.x;\n    output[i] = sigmoid(input[i]);\n\n}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그래서, 이제 CUDA 프로그래밍의 기본적인 중요한 개념을 알았으니 CUDA 커널을 만들기 시작할 수 있어요. 딥 러닝 모델의 경우, 그들은 기본적으로 합, 곱셈, 컨볼루션, 정규화 등과 같은 매트릭스 및 텐서 연산들의 집합입니다. 예를 들어, 단순한 행렬 곱셈 알고리즘은 다음과 같이 병렬화될 수 있어요:\n\n![Image](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_6.png)\n\n```js\n// GPU 버전\n\n__global__ void matMul(float A[M][N], float B[N][P], float C[M][P]) {\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row \u003c M \u0026\u0026 col \u003c P) {\n        float C_value = 0;\n        for (int i = 0; i \u003c N; i++) {\n            C_value += A[row][i] * B[i][col];\n        }\n        C[row][col] = C_value;\n    }\n}\n```\n\n이제 이것을 아래의 두 행렬 곱셈의 일반 CPU 구현과 비교해보세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n// CPU 버전\n\nvoid matMul(float A[M][N], float B[N][P], float C[M][P]) {\n    for (int row = 0; row \u003c M; row++) {\n        for (int col = 0; col \u003c P; col++) {\n            float C_value = 0;\n            for (int i = 0; i \u003c N; i++) {\n                C_value += A[row][i] * B[i][col];\n            }\n            C[row][col] = C_value;\n        }\n    }\n}\n```\n\nGPU 버전에는 더 적은 루프가 있어서 작업이 빨라진다는 것을 알 수 있습니다. 아래는 NxN 행렬 곱셈의 CPU와 GPU 성능 비교입니다:\n\n![performance-comparison](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_7.png)\n\n행렬의 크기가 커질수록 GPU 처리의 성능 향상이 더 큰 것을 관찰할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 기본 신경망을 고려해 보세요. 주로 y = σ(Wx + b) 작업을 포함하는데, 아래 그림과 같이 구성됩니다:\n\n![Neural Network Operations](/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_8.png)\n\n이러한 작업은 주로 행렬 곱셈, 행렬 덧셈, 배열에 함수를 적용하는 것으로 이루어져 있습니다. 병렬화 기술에 익숙하신 분들이라면 이미 이들을 알고 계실 것입니다. 따라서 이제 GPU에서 실행되는 자체 신경망을 처음부터 구현할 수 있는 능력이 생겼습니다!\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물에서는 GPU 처리에 대한 입문적인 개념을 다루어 딥러닝 모델의 성능을 향상시키는 방법에 대해 알아보았어요. 그러나 본 포스트에서 다룬 내용은 기초적인 것들뿐이며, 더 많은 것을 배울 수 있습니다. PyTorch와 Tensorflow와 같은 라이브러리는 최적화 기술을 구현하고 있으며, 최적화된 메모리 액세스, 배치 연산 등과 같은 보다 복잡한 개념들을 활용합니다 (이들은 cuBLAS 및 cuDNN과 같은 CUDA 기반 라이브러리 위에서 구축된 라이브러리를 활용합니다). 그러나 \"cuda\"로 지정하고 GPU에서 딥러닝 모델을 실행할 때 무슨 일이 벌어지는지에 대한 배경 정보를 이해하는 데 이 게시물이 도움이 되기를 바랍니다.\n\n향후 게시물에서는 CUDA 프로그래밍에 관련된 더 복잡한 개념들을 소개할 예정이에요. 의견을 주시거나 다음에 대해 무엇을 쓰기를 원하시는지 알려 주시면 감사하겠어요! 읽어주셔서 너무 감사해요! 😊\n\n# 추가 자료\n\nNVIDIA CUDA 프로그래밍 문서 — NVIDIA CUDA 프로그래밍 가이드.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCUDA 문서 — NVIDIA의 완전한 CUDA 문서입니다.\n\nCUDA 신경망 훈련 구현 — 순수 CUDA C++로 구현된 신경망 훈련입니다.\n\nCUDA LLM 훈련 구현 — 순수 CUDA C로 구현된 LLM의 훈련입니다.\n","ogImage":{"url":"/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png"},"coverImage":"/assets/img/2024-05-23-WhyDeepLearningModelsRunFasteronGPUsABriefIntroductiontoCUDAProgramming_0.png","tag":["Tech"],"readingTime":23},{"title":"재밌는 주제 프로덕션 환경에서 신뢰할 수 있는 딥러닝 스택 구축하는 방법 이에 대해 알아보도록 하죠","description":"","date":"2024-05-23 17:14","slug":"2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction","content":"\nPrometheus, Triton, 그리고 Grafana를 사용하여 엔드 투 엔드 모니터링 대시보드를 구축해보세요.\n\nML 시스템을 배포하기 전에, 엔지니어들은 로컬 및 대규모에서 어떻게 성능을 발휘할지 정확한 통찰력이 필요합니다. 병목 현상을 식별하고 예상치 못한 동작을 파악하기 위해.\n\n클래식 ML 추론 파이프라인과 비교하면, 딥 러닝 시스템은 자원 소비, 복잡성 및 확장 가능성의 도전에 따라 낮은 지연 시간, 높은 처리량에 중점을 둔다는 것 때문에 보다 \"중요한\" 및 자세한 모니터링이 필요합니다. 특히, 컴퓨터 비전과 같은 자원 집중적인 응용 프로그램에서 딥 러닝 배포를 위해 ML 엔지니어들은 모니터링에 우선순위를 두어야 합니다.\n\n이 글에서는 배포 설정 및 모니터링의 워크플로우에 대해 다루겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 목차\n\n1. 성능 모니터링 파이프라인 설정 방법\n\n- 컨테이너\n- 설정 파일\n- 도커 컴포즈\n\n2. 메트릭 스크랩 구성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n프로메테우스 타겟을 추가하기\n\n- 그라파나 데이터소스 추가하기\n- 헬스체크 대상 스크랩\n\n3. 대시보드 생성\n\n- GPU 메트릭을 위한 패널\n- CPU/RAM 메트릭을 위한 패널\n\n4. 시각화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음으로 넘어가기 전에 사용할 도구들을 살펴봅시다:\n\n- 도커는 가벼우고 휴대용한 컨테이너 내에서 애플리케이션을 개발, 배포, 실행할 수 있는 플랫폼입니다 — ML 엔지니어에게 꼭 필요한 도구입니다.\n- 도커 컴포즈는 멀티 컨테이너 애플리케이션을 정의하고 구성하는 도구입니다.\n- cAdvisor는 구글에서 개발한 리소스 사용량 및 컨테이너 성능 지표를 제공해주는 오픈소스 도구입니다.\n- 프로메테우스는 메트릭을 수집하고 저장하는 모니터링 및 경보 시스템으로, 프로메테우스에 대한 전문 지식은 ML/MLOps 엔지니어에게 큰 장점입니다.\n- 그라파나는 모니터링 및 가시성 플랫폼으로, 배포된 시스템의 메트릭을 생성, 시각화, 경보 및 이해할 수 있게 해줍니다. 모니터링 대시보드를 관리하는 것은 MLOps 엔지니어에게 중요한 기술입니다.\n- Triton Inference Server는 NVIDIA에서 개발한 인기 있는 모델 서빙 프레임워크로, 복잡한 ML 모델을 프로덕션 환경에 배포하는 데 중요한 역할을 합니다. Triton에 대한 전문 지식은 MLOps 엔지니어에게 필수적인 기술입니다.\n\n# 1. 도커 컴포즈 설정\n\n각 서비스가 무엇을 하는지 설명하고, 이러한 서비스를 캡슐화하고 실행할 도커 컴포즈를 준비하는 것부터 시작해봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음과 같은 내용이 있습니다:\n\n![이미지](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png)\n\n도커 컴포즈 모니터링 yaml 파일을 살펴보겠습니다.\n\n```yaml\n# cat docker-compose-monitoring.yaml\nversion: \"3.4\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"${PROMETHEUS_PORT}:${PROMETHEUS_PORT}\"\n    container_name: prometheus\n    restart: always\n    volumes:\n      - \"${MONITORING_CONFIGURATIONS}/prometheus.monitoring.yml:/etc/prometheus/prometheus.monitoring.yml\"\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    command:\n      - \"--config.file=/etc/prometheus/prometheus.monitoring.yml\"\n      - \"--enable-feature=expand-external-labels\"\n    depends_on:\n      - cadvisor\n    networks:\n      monitor-net:\n        ipv4_address: ${PROM_IP}\n  grafana:\n    image: grafana/grafana-enterprise:8.2.0\n    container_name: grafana\n    ports:\n      - \"${GRAFANA_PORT}:${GRAFANA_PORT}\"\n    volumes:\n      - ${MONITORING_CONFIGURATIONS}/datasources:/etc/grafana/provisioning/datasources\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PWD}\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}\n    networks:\n      monitor-net:\n        ipv4_address: ${GRAFANA_IP}\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:latest\n    container_name: cadvisor\n    restart: always\n    ports:\n      - \"${CADVISOR_PORT}:${CADVISOR_PORT}\"\n    volumes:\n      - \"/etc/localtime:/etc/localtime:ro\"\n      - \"/etc/timezone:/etc/timezone:ro\"\n      - \"/:/rootfs:ro\"\n      - \"/var/run:/var/run:rw\"\n      - \"/sys:/sys:ro\"\n      - \"/var/lib/docker:/var/lib/docker:ro\"\n    networks:\n      monitor-net:\n        ipv4_address: ${CADVISOR_IP}\n  triton_server:\n    container_name: tis2109\n    image: nvcr.io/nvidia/tritonserver:21.09-py3\n    privileged: true\n    ports:\n      - \"8002:8002\"\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              capabilities: [gpu]\n    volumes:\n      - ${TRITON_MODELS_REPOSITORY}:/models\n    command:\n      [\n        \"tritonserver\",\n        \"--model-repository=/models\",\n        \"--strict-model-config=false\",\n      ]\n    networks:\n      monitor-net:\n        ipv4_address: ${TRITON_IP}\nnetworks:\n  monitor-net:\n    driver: bridge\n    internal: false\n    ipam:\n      driver: default\n      config:\n        - subnet: ${SUBNET}\n          gateway: ${GATEWAY}\n```\n\n보시다시피, .yaml 설정에 일부 마스킹된 $'변수'가 있습니다. 이들은 .env 파일 내부에서 자동으로 상속되어 로컬 개발 및 CI/CD 파이프라인에서 최상의 관행을 따르는 흐름을 가지고 있습니다.\n\n이제 .env 파일에 어떤 것이 있는지 살펴봅시다:\n\n```yaml\n# == 모니터링 변수 ==\nPROMETHEUS_PORT=9090\nGRAFANA_PORT=3000\nCADVISOR_PORT=8080\nMONITORING_CONFIGURATIONS=\u003cyour_configuration_files에 대한_경로\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# == 자격 증명 ==\nGRAFANA_PWD=admin\nGRAFANA_USER=admin\n# == TIS 변수 ==\nTRITON_MODELS_REPOSITORY=\u003c당신의_triton_모델_저장소_경로\u003e\n# == 기본 네트워크 ==\nSUBNET=172.17.0.0/16\nGATEWAY=172.17.0.1\n# == 서브넷 IP ==\nTRITON_IP=172.17.0.3\nCADVISOR_IP=172.17.0.4\nPROM_IP=172.17.0.5\nGRAFANA_IP=172.72.0.6\n```\n\n대부분의 변수가 설정되었지만, 여기서 살펴봐야 할 주요한 2가지 변수는 다음과 같습니다:\n\n- MONITORING_CONFIGURATIONS\n  이것은 이러한 구조가 있는 폴더를 가리켜야 합니다\n\n```js\n.__ monitoring\n|  |_ datasources\n|  | |_ datasources.yml\n|  |_ prometheus.monitoring.yml\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- TRITON_MODEL_REPOSITORY\n  모델 저장소의 구조는 다음과 같아야 합니다:\n\n```js\nmodel_repository\n└── prod_client1_encoder\n    └── 1\n        └──resnet50.engine\n    └── config.pbtxt\n```\n\n프로메테우스 모니터링 파일인 prometheus.monitoring.yml에는 메트릭을 가져올 대상(컨테이너)을 추가할 것입니다.\n데이터 소스 파일인 datasources.yml에는 그라파나 대시보드의 소스로 프로메테우스를 추가할 것입니다. 그렇게 하면 그라파나 UI를 열 때 나타날 것입니다.\n\n# 2. 프로메테우스 스크래핑 구성 정의\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n그럼 Prometheus 대상을 구성해 보겠습니다. `prometheus.monitoring.yml` 파일에 작성하겠습니다.\n\n```yaml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n```\n\n```yaml\nscrape_configs:\n  - job_name: \"prometheus\"\n    static_configs:\n      - targets: [\"172.17.0.5:9090\"]\n  - job_name: \"triton-server\"\n    static_configs:\n      - targets: [\"172.72.0.3:8002\"]\n\n  - job_name: \"cadvisor\"\n    static_configs:\n      - targets: [\"172.72.0.4:8080\"]\n```\n\n3개의 대상이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 프로메테우스 — 모니터링 프로메테우스 자체를 유지하는 것이 건강한 모니터링을 위한 모범 사례로 작용합니다. 수천 개의 메트릭을 처리하면 병목 현상이 발생할 수 있으며 프로메테우스 자체의 자원 사용량을 알고 있는 것이 유용합니다.\n- Triton Server — 이것은 이 딥러닝 스택의 핵심에 있어 중요합니다. ML 모델을 제공하고 관리하기 때문입니다.\n  Triton은 인퍼런스 프로세스 전반에 걸쳐 다양한 메트릭을 제공하는 포트 8002의 내장된 프로메테우스 엔드포인트가 있습니다.\n- cAdvisor — 이 배포에서 컨테이너 전반의 CPU/RAM 사용량 정보를 얻기 위해 사용됩니다.\n\n모두 구성한 뒤, 컴포저를 시작하고 문제가 있는지 검사할 수 있습니다.\n컨테이너를 시작해 봅시다.\n\n```js\ndocker compose -f docker-compose-monitoring.yaml up -d\n```\n\n프로메테우스 대상을 검사해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 웹 브라우저로 가서 전체 Prometheus URL(IP:9090)을 입력해주세요.\n- 상태 → 대상(Targets)으로 이동해주세요.\n- 스크래핑 구성에서 각 대상이 정상인지 확인해주세요(녹색).\n\n이러한 사항을 확인한 후에는 Grafana에서 대시보드를 만들어 진행할 수 있습니다.\n\n# #3 대시보드 생성하기\n\nGrafana WebUI 대시보드에 액세스하려면 브라우저를 열고 `localhost:3000`으로 이동해주세요. 여기서 3000은 Grafana 컨테이너를 실행하는 포트입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n로그인 페이지로 이동하면 사용자 이름/암호 필드에 `admin/admin`을 사용하십시오. 더 높은 보안이 권장되지만, 이는 이 기사의 범위에 포함되지 않습니다.\n\nGrafana 웹을 열었으면 다음을 수행해야 합니다:\n\n- 데이터 소스를 우리의 Prometheus 메트릭 스크래퍼 엔드포인트로 지정합니다.\n- 새 대시보드 생성\n- 관심 있는 메트릭을 집계/시각화하기 위해 차트 추가\n\n#3.1 Prometheus 데이터 소스\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n왼쪽 패널에서 기어 아이콘(설정)을 클릭하고 DataSources를 선택하세요.\n다음과 같은 뷰가 나타날 것입니다:\n\n\"Add data source\"를 클릭한 후 Time Series Databases 아래에서 `Prometheus`를 선택하세요. Grafana는 여러 종류의 메트릭 스크랩을 지원하고 있습니다. 여기서는 Prometheus를 사용할 것입니다. 이런 뷰가 나타날 것입니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_1.png\" /\u003e\n\n여기에는 Prometheus 엔드포인트의 URL을 추가해야 합니다. 우리의 도커 컴포즈 배포에서는 `http://prometheus:9090`을 사용할 것입니다. 이 템플릿을 따르면 `http://container_name:container_port`가 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_2.png\" /\u003e\n\n여기까지 오셨군요. 이제 데이터 원본 추가 섹션이 완료되었습니다.\n이제 대시보드를 만들어보겠습니다.\n\n### 3.2 Grafana 대시보드 만들기\n\n왼쪽 패널에서 “+” 표시를 클릭하고 `Dashboard`를 선택하세요. 이렇게 하면 미리 정의된 패널 그룹이 있는 새 대시보드 페이지로 이동합니다. 우리는 모든 것을 처음부터 만들고 있으므로 `Empty Panels`만 사용하여 주요 지표를 표시할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n다음은 한 예제에 대한 따라할 프로세스입니다:\n\n- 새 쿼리를 추가하고 `promql` (Prometheus 쿼리 언어)를 정의합니다.\n- 시각화 유형, 그래프 스타일, 범례를 구성합니다.\n\n다음은 비어 있는 패널의 모습입니다:\n\n이제, 트리튼 추론 서버 모델 서빙 플랫폼을 모니터링하기 위해 몇 가지 사용자 정의 쿼리를 추가할 것입니다. 하지만 먼저 다음 참고 사항을 유념해야 합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n첫 번째 쿼리를 설정해보겠습니다. 이 쿼리는 성공적인 요청의 수를 고려하여 모델이 하나의 추론 요청을 수행하는 데 걸리는 시간(밀리초)을 측정할 것입니다. 우리는 시간이 지남에 따라 진행 상황을 보고 싶기 때문에 이 차트는 `시계열(time-series)`이 될 것입니다.\n다음은 해당 지표를 작성하는 쿼리입니다:\n\n```js\n(irate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\n```\n\n쿼리를 해석해 봅시다:\n\n아래에서 쿼리의 모습을 확인할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 새 차트의 설정을 구성할 때, 오른쪽에 다음을 지정할 수 있습니다:\n\n- 차트 유형 — 직선 / 곡선 / T-스텝 라인 중 선택\n- 메트릭 범위 — 메트릭 선택(예: 밀리초(ms))하고 low_range(예: 0)와 high_range(예: 100ms) 정의\n- 사용자 지정 텍스트 — 범례 또는 다른 필드에 표시될 내용\n\n#3.3 시각화 완료\n\n위의 흐름에 따라, 나머지 차트를 생성할 수 있습니다.\n전체 성능 모니터링 차트를 컴파일하려면 나머지 패널을 추가하십시오. 다음 각각에 대해 새 패널을 만들고 해당 세부 정보로 채워넣습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- GPU 사용된 바이트 - VRAM 사용량의 백분율\n\n```js\n쿼리: nv_gpu_memory_used_bytes{job=\"triton-server\"}/nv_gpu_memory_total_bytes{job=\"triton-server\"}\n차트 유형: 파이\n범례: {인스턴스}\n```\n\n2. GPU 활용도 - 전체 GPU 활용도\n\n```js\n쿼리: nv_gpu_utilization{job=\"triton-server\"}\n차트 유형: 시계열\n범례: NULL\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 입력 시간/요청 — 클라이언트가 입력 데이터를 Triton 서버로 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n4. 출력 시간/요청 — 서버가 클라이언트에게 출력을 보내는 데 걸린 시간.\n\n```js\nQuery: (irate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000)/ irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])\nChart Type: 시계열\nLegend: {model}-{version}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n5. DB 비율 (#요청/#실행) — 성공적인 요청의 전체 요청 대비 비율\n\n```js\n쿼리: sum by (모델,버전) (rate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval])/rate(nv_inference_exec_count{job=\"triton-server\"}[$__rate_interval]) )\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n6. 대기 시간/요청 — 요청이 처리되기 전에 대기하는 시간\n\n```js\n쿼리: sum by (모델,버전) ((irate(nv_inference_queue_duration_us{job=\"triton-server\"}[$__rate_interval]) / 1000) / irate(nv_inference_request_success{job=\"triton-server\"}[$__rate_interval]))\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n7. 집계된 입력/추론/출력 - 입력 출력 및 추론을 한 차트에 표시합니다.\n\n```js\n질의:\nA: rate(nv_inference_compute_input_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nB: rate(nv_inference_compute_infer_duration_us{job=\"triton-server\"}[$__interval]) / 1000\nC: rate(nv_inference_compute_output_duration_us{job=\"triton-server\"}[$__interval]) / 1000\n\n차트 유형: 시계열\n범례: {모델}-{버전}\n```\n\n우리가 만든 완벽한 대시보드는 다음을 보여줍니다:\n\n- GPU VRAM 이용률\n- 클라이언트에서 서버로의 입력 송신 시간\n- 서버 추론 요청 시간\n- 서버에서 클라이언트로의 출력 송신 시간\n- 성공 요청/전체 요청 비율\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이런 종류의 대시보드는 배포된 스택의 성능 및 스트레스 테스트 속에서의 동작을 모니터링하기 위한 시작점을 제시합니다.\n\n이는 배포의 실패 및 위험 지점을 연구하는 구체적인 방법을 제공하며 SLI(서비스 수준 지표)를 모니터링하는 데 도움이 됩니다.\n\n서비스 수준 지표는 SLA(서비스 수준 계약)를 준수하고 SLO(서비스 수준 목표)를 달성하기 위해 모니터링되는 메트릭입니다. 우리가 만든 대시보드는 제공되는 서비스 수준 계약을 준수하기 위한 목표에 도달하기 위한 가치 있는 통찰을 제공할 수 있습니다.\n\n또한 이는 다중 복제본을 추가하거나 추론 서빙 프레임워크를 실행하는 여러 기계로의 확장 전략을 계획하는 데 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 결론\n\n본 문서에서는 Prometheus와 Grafana를 사용하여 자사의 ML 애플리케이션 및 모델 서빙 프레임워크를 위한 성능 모니터링 스택을 설정하고 구축하는 방법을 소개했습니다.\n\n도커 컴포즈 파일을 준비하는 것부터 시작하여 워크플로우의 각 단계를 설명하고 스택을 배포하고 데이터 원본을 구성하며 대시보드 패널을 생성하고 지표를 집계하는 과정을 마무리했습니다.\n\n모니터링은 MLOps 시스템의 중요한 부분입니다!\n이 튜토리얼을 따라 하면 테스트 환경에서 단일 배포로 ML 애플리케이션을 위한 모니터링 파이프라인을 구조화하고 배포하거나, 클라우드 시나리오 설정에서 여러 입력 소스를 결합하고 전체 스택 배포를 모니터링하는 단일 대시보드 소비자 지점을 갖도록 구성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 더 많은 내용을 원하신다면!\n\n저는 미디엄에 새롭게 등장했습니다. 만약 이 글을 즐겨보셨다면 박수를 보내주시고 제 계정을 팔로우해주세요 - 정말로 감사하겠습니다! 🚀\n\n![How to ensure your deep learning stack is fail-safe in production](/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_3.png)\n\n# 더 많은 글 보기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 게시물과 관련성에 따라 정렬되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png"},"coverImage":"/assets/img/2024-05-23-Howtoensureyourdeeplearningstackisfail-safeinproduction_0.png","tag":["Tech"],"readingTime":18}],"page":"56","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"56"},"buildId":"T_Nz0g9U1yttYMSEma95P","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>