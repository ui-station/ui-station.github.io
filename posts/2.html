<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ui-station</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///posts/2" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ui-station" data-gatsby-head="true"/><meta property="og:title" content="ui-station" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///posts/2" data-gatsby-head="true"/><meta name="twitter:title" content="ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-a9851699c2b6bcaf.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_buildManifest.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="생성 모델과 소음과 구조의 댄스" href="/post/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="생성 모델과 소음과 구조의 댄스" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="생성 모델과 소음과 구조의 댄스" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">생성 모델과 소음과 구조의 댄스</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="10가지 AI 프롬프트와 이미지 시대를 초월한 영화 스타일 탐구" href="/post/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="10가지 AI 프롬프트와 이미지 시대를 초월한 영화 스타일 탐구" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="10가지 AI 프롬프트와 이미지 시대를 초월한 영화 스타일 탐구" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">10가지 AI 프롬프트와 이미지 시대를 초월한 영화 스타일 탐구</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="인테리어 디자이너가 알아야 할 상위 Midjourney sref 코드들" href="/post/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="인테리어 디자이너가 알아야 할 상위 Midjourney sref 코드들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="인테리어 디자이너가 알아야 할 상위 Midjourney sref 코드들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">인테리어 디자이너가 알아야 할 상위 Midjourney sref 코드들</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="DALL-E3의 문제들" href="/post/2024-05-23-TheTroubleWithDALL-E3"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="DALL-E3의 문제들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="DALL-E3의 문제들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">DALL-E3의 문제들</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크" href="/post/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축" href="/post/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1" href="/post/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="토큰화 - 완벽한 가이드" href="/post/2024-05-23-TokenizationACompleteGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="토큰화 - 완벽한 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-TokenizationACompleteGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="토큰화 - 완벽한 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">토큰화 - 완벽한 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">36<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="고급 RAG 07 테이블을 위한 RAG 탐색" href="/post/2024-05-23-AdvancedRAG07ExploringRAGforTables"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="고급 RAG 07 테이블을 위한 RAG 탐색" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="고급 RAG 07 테이블을 위한 RAG 탐색" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">고급 RAG 07 테이블을 위한 RAG 탐색</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">19<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구" href="/post/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">UI STATION</span></div><strong class="PostList_title__loLkl">RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구</strong><div class="PostList_meta__VCFLX"><span class="date">May 23, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link posts_-active__YVJEi" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"생성 모델과 소음과 구조의 댄스","description":"","date":"2024-05-23 18:37","slug":"2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure","content":"\n르네상스 이탈리아의 주민들이, 인간 상상력과 이성에 대한 열정으로 불타는 현재 기술에 가장 놀라워했을만한 것은 무엇일까 고민하는 것을 즐깁니다. 비행 기계를 꿈꾸던 레오나르도 다빈치는 분명 공중을 유유히 달리는 Airbus 380을 볼 때 굳이 확카해 편안하게 의자에서 영화를 보며 와이파이 속도가 충분하지 않다고 불평하는 탑승자들을 볼 때 깊은 감명을 받았을 겁니다.\n\n하지만 중세 시대에 마술처럼 보였을 기술 중에서도 제너레이티브 인공지능의 기이함이 그중에 상위에 속할만 합니다. 수십 년간 노고 끝에 만들어낸 '모나 리자' 초상화를 살펴온 레오나르도가 그의 스타일로 여성 초상화를 몇 초만에 그릴 수 있는 장치를 보여준다면 어떻게 반응했을지 상상해보세요. 보세요:\n\n\u003cimg src=\"/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_0.png\" /\u003e\n\n솔직히 말하자면, 이 여성은 실제 몬나 리자만큼 매혹적이고 신비로울 정도로 미소를 머금지 않습니다(심지어 더 자세히 관찰하면 다소 우스운 것 같습니다). 하지만 많은 사람들은 AI 생성물의 놀라운 사례를 만나봤습니다: 초실감 이미지부터 AI로 작성된 목소리의 믿기 힘든 딥 페이크까지 말이죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n생성적 AI 모델은 꿈꾸는 사람들의 실리콘 버전입니다: 아무것도 없는 상황에서 무언가를 상상할 수 있으며, 소음으로부터 의미를 찾아냅니다. 그들은 질서와 무질서의 춤을 춰내는 법을 배웠습니다. 이미 인간의 창의성에 대한 우리의 생각을 변화시키고, 수천 가지의 새로운 응용 프로그램으로 문을 열었으며, 전통적인 산업들을 위협하고 새로운 산업을 만들어냈습니다.\n\n그리고 우리는 이제 막 시작에 불과합니다. 대부분의 이러한 모델들은 아직 발전 초기 단계에 있습니다. ChatGPT의 글, DALL-E 및 Midjourney의 이미지, 그리고 최근에 Stability AI의 StableAudio와 같은 음악용 생성 모델들을 통해, 우리는 하루에 뇌에 입력되는 감각 신호의 많은 부분이 어떤 식으로든 AI에 의해 변경되거나 완전히 생성된 시대를 살아가고 있습니다.\n\n![이미지](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_1.png)\n\n본 기사에서는 이 마법 같은 블랙 박스의 뚜껑을 열어, 생성 모델의 여러 클래스의 기본 메커니즘(Helmholtz machines, Variational Autoencoders, Normalizing Flows, Diffusion Models, GANs 및 Transformer 기반의 언어 모델)에 대해 탐구하고, 그들의 내부 작동 원리를 밝히며, 뇌과학과 인지학에 대한 기원과 연결을 탐구합니다. 이 주제는 물론 한 기사로 다루기에는 너무 방대하기 때문에(계획대로 많이 커졌지만), 기술적인 세부 정보와 고수준 개요, 일관된 내러티브, 그리고 참고 자료를 균형있게 제공하려고 노력하여, 모두에게 흥미로운 내용이 될 것으로 기대합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어디서부터 시작할까요?\n\n많이 인용된 파인만의 명언으로 시작하는 것은 다소 진부할 수 있지만, 그의 주장에는 이치가 있습니다: 이해는 창조 행위와 관련이 있으며, 머신 러닝 초기부터 이해할 수 있는 모델을 만드는 것은 창조할 수 있는 모델을 만드는 것과 관련이 있었습니다. 튜링의 유명한 테스트 (이른바 모방 게임이라고도 함)는 이 아이디어의 변형으로 볼 수 있습니다: 지능을 속이는데 성공적이라면, 실제 것과 유사한 것을 발견했을 가능성이 높습니다.\n\n가장 중요한 초기 생성 모델 중 두 가지는 볼츠만 머신과 헬멀홀츠 머신입니다.\n\n헬멀홀츠 머신은 특히 흥미롭습니다. 그 원칙은 독일 물리학자 헤르만 폰 헬멀홀츠의 미래를 예언하는 비전과 관련이 있습니다. 헬멀홀츠는 19세기 말에 지각이 객관적인 현실의 객관적 반영보다는 감각 데이터와 사전 지식으로부터의 무의식적 추론 과정으로 더 잘 설명된다는 것을 깨달았습니다. 인식은 본질적으로 확률적이며 잡음에 영향을 받으며, 우리의 기대와 편향으로 강력하게 형성됩니다. 그의 아이디어는 현대 신경과학에서 점점 더 중요해지고 있는데, 칼 프리스턴의 자유 테너지 원리(헬멀홀츠 머신을 영감의 근원으로 명시적으로 언급) 및 베이지안 뇌 가설을 통해 그 영향이 커지고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Generative Models](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_2.png)\n\n베이지안 관점에서, 뇌는 세상의 생성 모델 p(x,z)을 유지합니다. 여기서 x는 감각 관측이고 z는 뇌가 포착하려는 해당 감각 관측의 숨겨진 원인/잠재적 설명입니다. 세상과 세상의 모델에 대한 불확실성을 반영하는 것이며, 이를 보겠지만 모든 생성 모델은 확률적 잠재 변수 모델로 수립됩니다.\n\n베이지안 언어로, 이러한 모델을 가정할 때, 이것은 잠재 원인에 대한 사전 분포 p(z) (뉴욕에 살 경우 사자를 관측할 기대가 개를 관측할 기대보다 작음), 관측치 p(x)에 대한 전체 가능성, 그리고 감각 관측과 숨겨진 원인 간의 관계로 요약됩니다.\n\nx와 z 간의 관계를 분석하는 것이 생성 모델링의 핵심입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n중요한 두 가지 양 름은 사후 확률인 p(z∣x)와 가능도 p(x|z)로 나타나며, 이들은 베이즈의 유명한 법칙에 따라 서로 연관되어 있습니다.\n\n우리는 관찰된 값을 기반으로 한 숨겨진 원인의 확률인 사후 확률 p(z∣x)을 얻습니다. 일반적으로 이에 접근할 수 없는데, 이는 계산 문제 때문인데, 베이즈의 법칙에 따르면 이를 계산하기 위해 p(x)가 필요하며, 이를 계산하려면 모든 가능한 숨겨진 원인을 찾아서 x를 어떻게 설명할지 확인해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n세계 모델이 복잡한 경우, 이들은 고차원 적분이므로 효율적이지 않거나 아예 불가능할 수 있습니다.\n\n사후 확률 추론은 많은 생성 모델의 근본적인 도전 과제입니다.\n\n헬름홀츠 머신에서 사후 확률 p(z∣x)은 인식이라는 프로세스에서 데이터에서 직접 추정되며 근사 사후 확률 q(x|z)을 배우고 이를 가능한 한 진짜 p(z∣x)에 가깝게 일치시킴으로써 추정됩니다.\n\n우도 p(x|z)를 추정하는 역방향은 보통 훨씬 쉽습니다. 특정 잠재 변수 z가 주어지면, 단지 우리에게 관찰 x가 얼마나 가능성 있는지만 알려줍니다. 이를 위해 일반적으로 어떤 적분도 필요하지 않고, 단순히 모델을 순방향으로 실행할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가능성은 생성 네트워크에 의해 매개변수화됩니다: 어떻게하면 z가 주어졌을 때 x를 생산할 수 있을까요? 숨겨진 원인으로 시작하면, 세계에 대한 영향은 어떻게 보일까요? 사람을 상상해보면, 그 사람의 얼굴이나 목소리는 어떻게 보일까요?\n\n대부분의 생성 모델에서, 이것이 실제로 가장 관련이 있는 부분입니다 (이미지/텍스트/오디오를 생성함으로써). z에서 x로의 매핑이 어떻게 생겼는지 아는 즉시, z를 샘플링하고 생성 네트워크를 통해 보내어 샘플을 생성할 수 있습니다.\n\n헬름홀츠 머신에서 이 두 방향은 신경 네트워크를 통해 매개변수화되며, 이는 인지 네트워크를 사용하여 생성된 샘플을 실제 세계 (깨어 있는 상태)와 비교하고 자체 창조물을 잠재적 상태로 다시 매핑하는 것 (꿈의 상태)을 변환하는 인간 인지와 유사한 프로세스에서 영감을 받은 비교기반 깨어 있는-잠자는 알고리즘에 의해 번갈아 학습됩니다.\n\n인지 네트워크 z ← x: q(z|x)\n생성 네트워크 z→ x: p(x|z)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n잠재 공간의 구조는 학습된 모델의 해석을 돕는 데 종종 도움이 됩니다. 잠재 표현을 분리하고 해석 가능한 특징과 맞추는 것은 많은 실용적응용에서 관심을 끄는 것뿐만 아니라 보다 해석 가능한 모델을 얻기 위해서 더 일반적으로 중요합니다.\n\n친숙한 예로, 인간 얼굴 이미지의 생성 모델을 구축한다고 가정해 보겠습니다. Helmholtz 기계의 구조를 따라 이미지를 잠재 공간에 매핑합니다. 그런 다음 해당 잠재 공간에서 흥미로운 변화의 축을 발견해 볼 수 있습니다.\n\n흥미로운 변화의 축 중 하나는 이미지에 표시된 사람의 나이와 관련이 있을 수 있습니다. 그런 다음, 잠재 공간에 제약 조건을 부여할 수 있습니다(나이별로 레이블이 지정된 데이터를 제공하여 지도 학습 설정에서 또는 나이를 식별하여 학습된 잠재 특징 내에서, 중요한 변화로 이어진다고 가정하는 비지도 학습 설정에서), 그래서 그 중 하나의 방향인 z_age가 이미지에 표시된 나이를 인코딩하도록 할 수 있습니다.\n\n이러한 방향을 알면 이미지의 나이를 변경하는 데 사용할 수 있습니다. 또 다른 방향인 z_beard가 수염을 인코딩한다고 가정해 볼 때, 모델을 사용하여 이미지 x를 인코딩하고 an z를 얻은 다음, z를 z'=z+a*z_age+b*z_beard로 변환하여 전달합니다. 그리고 생성 모델 p(x|z')를 통해 다시 보내어 수염이 있는 노인 버전의 나를 볼 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOpenAI의 GLOW와 같은 모델을 사용하면 해당 웹사이트에서 놀 수 있지만, FaceApp과 같은 응용 프로그램을 이미 알고 계실 가능성이 높습니다.\n\n모든 생성 모델링은 이와 더나은 관련이 있는 변형 버전으로 귀결되며, Helmholtz 기계 시대 이후로 상당히 발전해 왔지만, 데이터의 기본 구조를 확률적 프레임워크에서 포착하고 재현하는 기본 아이디어는 유지되고 있습니다. 이제 이러한 개념을 사용하여 지난 10년간 AI 연구의 주목을 받은 생성 모델의 일부 일반적인 버전을 설명하겠습니다.\n\n## 변이 오토인코더 (VAEs)\n\nVAEs는 Kingma와 Rezende에 의해 2013년에 동시에 제안되었으며 (소음 제거, 압축, 시계열 데이터까지 다양한 응용 분야에서 발견됨).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시작하기에 가장 자연한 장소입니다. 헬름홀츠 머신과 정신적으로 가장 유사하기 때문입니다: 인식(인코더) 및 생성(디코더) 네트워크를 모두 사용합니다. 이미 언급했듯이, 인식 네트워크는 근사 밀도 q(z|x)를 통해 사후 밀도 p(z|x)를 근사합니다.\n\n![image](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_5.png)\n\nVAE는 음의 Evidence Lower Bound (ELBO)를 최소화하도록 훈련되어 있습니다. 이는 가능한한 참 사후 분포 p(z|x)에 가까운 근사 밀도 q(z|x)를 찾는 것으로 정리됩니다.\n\n여기서는 간단히 분포 q(z|x)를 매개변수화하여 그래디언트 기반 메서드를 통해 훈련 가능하도록 합니다. 분포를 매개변수화하는 데는 다양한 세부사항이 존재할 수 있지만, 대략적으로 가우시안 근사로 간주하는 경우가 많습니다. 이는 평균 μ와 공분산 σ를 가지며 모델의 자유 매개변수를 구성합니다. 이 값은 신경망에 의해 직접 학습됩니다 (훈련 데이터 x를 NN에 넣으면 출력이 μ가 됩니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVAEs에서는 근사 사후 분포 q(z|x)를 사용하여 하나 또는 여러 개의 랜덤 샘플을 추출하고, 이를 ELBO에 대입합니다. ELBO는 q에서의 샘플로부터의 기댓값으로 정의됩니다.\n\n\n![image](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_6.png)\n\n\n(음의) ELBO는 손실을 구성하므로 우리는 그래디언트를 계산할 수 있고, 그 결과 경사 하강법이 마법을 부리게 됩니다.\n\n사후 분포는 상당히 복잡할 수 있으므로, 잘 행동하는 그래디언트를 계산하는 것이 실제로 어려울 수 있습니다. 그들은 종종 높은 분산을 가지며 많은 샘플이 필요합니다. VAE의 핵심인 재모수화 기술은 이 문제를 빠르고 똑똑하게 우회하도록 도와줍니다. 샘플링을 두 개의 프로세스로 나누는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 먼저, 표준 가우시안 N(0,1)에서 샘플 ϵ을 추출합니다.\n- 다음으로, q(z∣x)의 평균 μ와 표준 편차 σ를 사용하여 ϵ을 변환하여 샘플 z=μ+σ×ϵ를 얻습니다.\n\n리파라미터화 트릭에서 특히 우아하다고 생각하는 점은, 이것이 각 생성 프로세스의 두 가지 핵심 구성 요소를 분리한다는 것입니다. 그것이 일상적인 손글씨 숫자를 생성하는 것일 수도 있고, 성경 인용구에서 하늘과 땅을 창조하는 메타포적인 것일 수도 있습니다: 초기 샘플 ϵ의 \"형태 없고 텅 빈\" 노이즈로부터 주어지는 무작위 구성 요소가 복잡한 변환을 통해 의미를 얻고, 마침내 복호기를 통해 관측된 세계에서 패턴 x를 만듭니다.\n\n![image](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_7.png)\n\n직관적으로 ELBO는 재구성 항과 엔트로피 항으로 구성됩니다. 정보 이론의 세계에서 엔트로피는 정보 내용의 예측 불가능성이나 무작위성을 측정하므로, 엔트로피는 훈련을 자연스럽게 정규화하며 최적화하는 동안 구조와 노이즈를 교환합니다. VAE가 재구성에 너무 많은 초점을 맞추면 데이터를 지나치게 캡처하여 잠재 공간에서 훈련 데이터의 모든 작은 세부 사항(노이즈 포함)을 잡아낼 수 있습니다. 그러나, 엔트로피에 너무 많은 가중치를 부과하면 데이터의 세세한 점들을 캡처하지 못할 너무 단순한 잠재 공간에 빠질 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n근사 사후의 엔트로피는 그 공분산 구조 σ와 관련이 있습니다. 이는 초기 표본에서 남아 있는 \"형태 없는 그리고 빈\" 잡음(우리의 설명에 대한 불확실성을 인코딩한)의 얼마만큼이 남아 있는지 측정해줍니다. 전체 과정을 결정론적으로 만들고 싶다면, σ를 단순히 0으로 설정하여 모든 불확실성을 제거할 수 있습니다.\n\n결정론적 우주에서는 진짜 잡음이 없습니다. 단지 우리의 모델이 포착하기에 충분히 강력하지 않은 것이거나 단순히 필요한 정보가 부족한 것만 있을 뿐입니다(잡음을 좋아하며 여기에서 이에 대한 전체 기사를 작성했습니다). George Box가 언급한 것처럼: \"모든 모델은 틀렸으며, 어떤 것은 유용하다\", VAE는 과신과 미신 사이의 균형을 찾아가는 법을 배우게 됩니다.\n\n이 구조화 원칙은 VAE가 차원 축소(입력 데이터에 포함된 중요한 정보와 중요하지 않은 정보를 구분하는) 및 노이즈 제거와 같은 작업에서 자연스럽게 뛰어나게 성과를 내는 이유를 설명해줍니다. 앞에서 언급한 바와 같이, VAE는 잠재 공간의 구조화된 표현을 얻어 해석 가능한 특징을 이끌어내기도 합니다.\n\n![이미지](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 정규화 흐름 (NF)\n\n누군가가 NF를 \"스테로이드를 이용한 재매개화 트릭\"이라고 표현한 적이 있는데, 이 설명을 정말 좋아합니다. 정규화 흐름은 VAE가 끝낸 곳을 맡아 인식을 흐름의 적용으로 정의합니다.\n\nNF는 간단한 확률 분포를 반복적으로 변형하여 복잡하고 정교한 분포로 바꾸는 방식으로 작동합니다. VAU의 경우와 마찬가지로 NF는 보통 표준 가우스 분포인 N(0,1)를 시작으로 역변환 가능한 변형들을 통해 더 복잡한 형태의 분포로 변환합니다.\n\n![NF Image](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVAE (Variational Autoencoders)는 고정된 분포와 학습된 변환(평균 및 분산)을 사용하여 난수와 구조를 분리합니다. NF (Normalizing Flows)는 동적으로 분포 자체를 조성합니다. 이는 Jacobian determinant를 추적하여 수행됩니다. 이것은 변환의 부피 변화를 나타냅니다. 즉, 공간이 얼마나 축소되거나 늘어나는지 확인하여 전체 잠재 공간이 일관된 방식으로 변형되도록합니다.\n\nVAE의 경우와 마찬가지로, 형태가 없는 덩어리가 형태로 변형됩니다.\n\nNF에 대해 멋진 두 가지는 다음과 같습니다: 역변환이 가능하므로 두 분포 간의 양방향 매핑을 허용합니다. 이것은 많은 상황에서 유용할 수 있습니다. 예를들면, 밀도를 추정하려고 할 때 (특히 다시 표준 가우시안 N(0,1)로 매핑하면 이전에 연구되지 않은 사후확률보다 계산이 쉬워질 수 있습니다.), 또는 이상 감지를 위해 데이터를 걸러내는 경우, 학습된 분포에서 낮은 가능성을 가진 데이터를 걸러냅니다.\n\n저는 앞서 언급한 OpenAI의 GLOW는 또한 이 역변환이용해 잠재 공간에서 미소, 나이 또는 수염 등과 같은 특징을 조작하고 거의 실시간으로 변형된 이미지를 얻습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 번째 멋진 점은 다양한 기하학과 매니폴드에 대한 적응력입니다. 고전적인 예로는 구 형태에 적용되는 것이 있습니다. 이를 통해 NF(정규화 흐름)는 구 위에 존재하는 잠재적 표현을 형성할 수 있습니다. 어떤 주장에도 불구하고 지구는 아마도 구형일 것이므로, 구 형태는 지구의 날씨 시스템 시뮬레이션을 실행할 때 매우 유용합니다.\n\n## 확산 모델\n\n계속해서, 확산 모델은 최근 몇 년간 가장 성공적인 생성 모델 중 하나입니다. 이미 2015년에 Sohl-Dickstein 등에 의해 제안되었지만, 이미지 생성에서의 성공으로 인해 DALL-E, Midjourney 또는 Stable Diffusion을 위한 기초를 마련했습니다. 기본 아키텍처는 매우 다르지만, 개념적으로 VAE(변분 오토인코더) 및 정규화 흐름과 연관이 있습니다.\n\n확산 모델은 생성 과정을 여러 단계로 분할합니다: 각 단계마다 학습 샘플에 노이즈가 적용됩니다. 모델의 목표는 해당 노이즈를 샘플에서 제거하는 방법을 학습하는 것입니다. 이전에 충분히 분명하게 했는지 모르지만, 이 노이즈는 확산 모델에서 다시 주요 역할을 수행합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 중에는 훈련 데이터에 반복적으로 노이즈가 추가됩니다. 이미지의 예시를 사용하면, 모델은 소음의 작은 수준을 제거하고 최종 세부 정보를 다듬는 방법을 배우거나, 왜곡된 이미지에서 모호한 모양을 명확히 하는 방법을 익힐 수 있습니다:\n\n![image](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_10.png)\n\n인식 과정은 인식 네트워크를 통해 직접적으로 모델링되지 않지만, 훈련 목표가 상당히 변경되는 동안, 노이즈 추가와 이에 따른 노이즈 감소 여부의 모니터링은 인식의 한 형태로 볼 수 있으며, 초기 노이즈 샘플은 p(z_0)에서 추출된 초기 상태로 간주될 수 있습니다.\n\n새로운 샘플을 생성할 때, 모델은 순수한 노이즈로 시작하고, 노이즈 아래에 숨겨진 것이 무엇인지 이해하려고 시도할 때 새로운 것을 얻을 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Generative Models Image](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_11.png)\n\n암튼, 아무것도 없는 상황에서 무언가를 환각하는 과정은 그것이 훈련된 데이터의 암시적으로 학습된 분포를 드러낸다.\n\n확산 모델이 왜 그렇게 잘 작동하는지는 여전히 논의 중입니다. 이와 관련하여 에너지 기반의 연상 메모리 모델(Hopfield 네트워크를 통해 40년 전에 유명해짐)과 비교되었습니다.\n\n또한 확산 모델은 Song 등에 의해 인기를 얻는 점수 기반 생성 모델링의 아이디어와 관련이 있습니다: 데이터 가능성을 직접 계산하는 전통적인 방법과 달리, 이러한 모델은 데이터 가능성의 기울기를 나타내는 점수를 근사화하는 데 중점을 둡니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n직관적으로, 점수는 샘플이 더 가능성 있는 방향으로 변경되어야 하는지를 나타냅니다. 직접적으로 가능성을 계산하지 않고, 이러한 모델들은 종종 이전에 마주한 일부 계산적 도전 과제를 피하게 됩니다.\n\n점수 함수는 다시 신경망으로 모델링될 수 있습니다. 이것을 나타내는 특히 흥미로운 방법 중 하나는 확률적 미분 방정식(SDEs)을 통해 나타내는 것입니다. 이는 Neural ODE와 유사하게, 신경망을 통해 미분 방정식을 나타내는 것입니다 (암시적 레이어라고도 알려져 있습니다).\n\n이것은 확산 모델의 연속 시간 버전과 유사합니다. 노이즈로부터 시작하여, 점수 함수는 가능성 있는 샘플로 이동하도록 이끕니다 (이 기술을 개발하는 Stefano Ermon 박사의 연구실은 훌륭한 강의를 진행하며, 자세한 내용은 여기에 설명이 있습니다).\n\n확산 모델에서 생성 과정은 또한 확률적이며, 각 단계에서 확률적 구성 요소를 추가합니다. 생성 프로세스가 여러 단계로 분할되기 때문에, 이는 사슬을 여러 단계 뒤로 되돌아가 과정을 다시 진행하여 샘플의 약간의 변형을 도입할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_12.png)\n\n일부 확산 모델 응용 프로그램(예: DALL-E 또는 Midjourney)에서 초기 상태는 순수한 무작위 샘플 z0이 아닌 시각과 언어 간의 공동 임베딩 p(z0|x)에 의해 제공됩니다. 여기서 x는 강력한 CLIP(대조적 언어-이미지 사전 훈련) 임베딩을 통해 제공된 예를 들어 텍스트 입력일 수 있습니다.\n\n조건부 생성은 다양한 감각 모달리티를 일관된 프레임워크로 결합하기 때문에 모든 종류의 멀티모달 학습 설정에서 가치가 있습니다. 아마도 AI의 가장 흥미로운 발전 중 일부에서 중요한 부분이 될 것입니다.\n\n![Image 2](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_13.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 생성적 적대 신경망 (GANs)\n\nGANs은 최근 10년간 가장 인기 있는 생성 모델 클래스 중 하나로, Ian Goodfellow와 친구들이 술 마시던 밤에 영감을 받아 만들어졌다.\n\nGANs는 헬름홀츠 머신의 이중 네트워크 구조에서 더욱 멀어진다. 앞에서 말했듯이, p(z|x)를 근사하는 것이 생성 모델의 중심적인 과제인 경우가 많아서 GANs는 단순히 인식을 무시하려고 한다.\n\nGANs는 p(z0)에서 무작위 노이즈 벡터를 추출하여 시작한다 (확산 모델에서처럼, 이 초기 벡터는 텍스트와 같은 다른 정보에 의해 조건이 달릴 수도 있다). 하지만, 이후에는 생성 네트워크만 학습하며 (여러 응용 프로그램에서 주로 관심을 두는 부분이기 때문에), 디스크리미네이터를 포함하여 훈련하고, 생성 모델에서 p(x|z)의 샘플을 훈련 데이터의 예제와 일치시키려고 노력한다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n생성 네트워크는 판별자를 속일 수 있는 데이터를 생성하도록 훈련됩니다. 이에 반해 판별자는 실제와 가짜 샘플을 구별하는 데 훈련됩니다.\n\nGAN의 우아함은 이 경쟁적 상호 작용에 있습니다: 생성자는 판별자로부터의 피드백에 따라 데이터 생성 능력을 향상시키는 동안, 판별자 자체는 실제와 가짜를 구별하는 데 더 뛰어나게 됩니다. 이는 완벽한 제로섬 게임이며, 양쪽 네트워크를 계속해서 더 나아지도록 밀어줍니다 (여기에서 딥 페이크 감지에 대해 썼던 특정한 위험 요소들이 있습니다).\n\n그러나 GAN은 독특한 과제를 안고 있으며, 특히 최근에 경쟁 모델인 확산 모델의 성공으로 인해 일부 인기를 잃은 것으로 볼 수 있습니다. GAN을 훈련하는 것은 일반적으로 불안정합니다. 생성자가 처음에 낮은 품질의 샘플을 생성하면, 판별자의 역할이 너무 쉬워져 생성자가 향상되기 어려워집니다. 반면, 판별자가 너무 강력해지면, 생성자의 성장을 저해하여 모드 붕괴로 이어질 수 있습니다. 이는 생성자가 가능한 출력의 일부만 생성하게 되는 현상을 의미합니다.\n\n## 트랜스포머와 대형 언어 모델 (LLMs)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n텍스트의 생성 모델링 환경을 완전히 혁신한 Transformers에 대해 언급하지 않을 수 없네요.\n\n간단히 설명하면, 거의 모든 LLM은 유명한 2017 구글 논문에서 self-attention을 구현한 transformer 아키텍처의 변형에 기반을 두고 있어요. 이 구조는 입력 시퀀스 간의 복잡한 관계를 학습할 수 있게 해줍니다. 이는 텍스트에 특히 잘 작동합니다.\n\nBERT와 같은 Transformer 변형들은 가려진 언어 모델링 설정에서 훈련됩니다. 일부 토큰이 가려지고 가려진 토큰을 인식할 수 있도록 훈련됩니다. 많은 다른 곳에서 설명되어 있겠지만, 이 아키텍처를 통해 LLM은 입력 시퀀스 간의 복잡한 관계를 학습할 수 있습니다.\n\n생성 관점에서 transformer 기반 LLM은 각 단어 또는 구문이 이전 단어를 따라 나올 확률을 모델링합니다. 이는 다시한번, 입력 프롬프트에 종속적인 확률 분포 p(x|z)의 변형을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 대개 Transformer에는 명시적으로 숨겨진 변수 z가 없습니다. 왜냐하면 프롬프트와 맥락 자체가 이미 단어입니다. 대신, self-attention 메커니즘은 관측된 모든 단어 (x1, x2, ..., xt)에서 토큰 p(x_i|(x1,x2,…,xt))의 확률을 추출하며, 물론 훈련 데이터의 수십억 줄에서 보여진 모든 단어와 맥락에 대한 암묵적인 분포에서도 추출합니다.\n\n노이즈는 Transformer 훈련의 직접적인 부분이 아니지만, LLMs는 자연스럽게 확률 구성 요소를 포함합니다. 이는 언어가 고유하게 결정되지 않기 때문에 매우 합리적입니다 (따라서 Markov 모델은 원래 러시아 시에 기초를 둔 것으로 개발되었으며, 이에 대해 자세히 논의하였음). 동일한 단락이 많은 다른 방식으로 표현될 수 있으므로, 응답 또는 샘플 생성 시, 주어진 맥락과 잘 맞는 여러 단어가 일반적으로 있으므로 가능한 계속 p(x_i|(x1,x2,…,xt))에 대한 분포가 있습니다.\n\n다른 단어를 선택하는 확률은 이른바 온도 하이퍼파라미터로 조정할 수 있습니다. 창의적이거나 결정론적인 응답을 찾고 있는지에 따라, 이 매개변수에 의해 효과적으로 노이즈 수준을 제어할 수 있습니다. Chat-GPT와 같은 LLM은 응답 중에 특정 온도를 요청할 수 있게 해줍니다.\n\nChat-GPT가 저에게 높은 온도 설정으로 이 단락을 다시 말해 주었습니다: \"Transformer의 소용돌이치는 은하에서 노이즈가 주연이 되지 않지만, LLMs는 언어의 불확실한 비트에 맞춰 춤을 추고 있습니다. 답변을 만드는 것은 한 마디의 진기한 단어를 찾는 것이 아니라 다양한 단어적 멜로디 p(x_i|(x1,x2,…,xt))를 이용해 잼을 더하고 있는 것입니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n고온은 ChatGPT가 말 그대로 고조 되는 것처럼 들리게 만듭니다. 여기서의 \"고온\"은 볼츠만의 열역학 통계학 형식에 대한 비유로 사용됩니다. 이는 시스템의 상태가 온도와 상태의 에너지에 따라 지수 분포를 따른다는 것을 가정합니다:\n\n![image](/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_14.png)\n\nTransformer와의 비유는 우연이 아닙니다. 소프트맥스 함수는 키(key)와 쿼리(queries) 사이의 얻은 스케일링된 점곱 점수를 확률로 매핑할 때 self-attention 메커니즘에서 사용됩니다. 소프트맥스는 볼츠만 분포와 정확히 동일한 기능 형태를 가지며 양 또는 볼츠만 분포의 에너지들에 대한 정규화된 확률 분포로 매핑하는 데 두 경우 모두 사용됩니다.\n\n열역학에서와 마찬가지로 온도는 엔트로피와 불확실성/잡음과 깊게 관련되어 있습니다. 볼츠만 분포에서는 온도가 증가함에 따라 서로 다른 에너지 상태에 대한 확률이 더 균일해집니다. 최대 균일성은 모든 상태가 동일하게 발생하기 때문에 최대 엔트로피로 이어집니다. LLMs에서는 이것이 의미하는 바는 앞으로 가능성이 있는 모든 단어가 동등한 확률로 예측된다는 것입니다. 하지만 고온에서도 생성된 텍스트가 완전히 무작위인 것은 아닙니다. 예시에서 볼 수 있듯이, 더 높은 온도로 조정된 경우라도 가장 가능성 있는 토큰의 선택은 여전히 주로 일관된 언어를 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이 기사로 한 가지 아이디어를 전달했다면, 그것은 노이즈가 모든 생성 모델에서 중요한 역할을 한다는 것입니다. 생성 모델링은 형태가 없는 노이즈를 가져다 구조를 불어넣는 예술입니다.\n\n지난 몇 년 동안 많은 방법이 로마로 이끄는 것을 보여줬습니다. 목표, 데이터 유형 및 거대한 모델 크기(예: 트랜스포머) 및 그래디언트 기반 방법으로 훈련시킬 때 어떤 것이 가장 잘 작동하는지에 대한 현실적인 고려사항에 따라 다양한 모델이 의미를 갖을 수 있습니다.\n\n최첨단 생성 모델의 거대함과 훈련 데이터의 복잡성은 해석에 도전을 초래했습니다. 확산 모델 및 트랜스포머는 잠재 변수 모델로 구성되지 않아 거대한 블랙박스처럼 느껴질 수 있으며, 실제 세계에 미치는 영향에 대한 우려가 증가함에 따라 해석이 크게 지연될 수 있습니다.\n\n그러나 우리는 아직 그 안에 일부 구조를 발견하여 배울 수 있을지도 모릅니다. Max Tegmark 등의 새 논문에서와 같이, LLMs에서 공간 및 시간의 중간 표현을 발견하고 해석 가능한 세계 모델의 발생과 유사한 것으로 만드는 방법을 설명합니다. 다른 사람들은 LLMs의 행동을 이해하기 위해 인지 심리학 도구를 창의적으로 적용하며, 사람의 복잡성을 이해하려는 노력과 유사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최근 팟캐스트 에피소드에서 Marc Andreessen은 제너레이티브 모델이 제너레이티브 모델로부터 제공된 합성 데이터에서 유의미하게 훈련되고 개선될 수 있는지라는 문제를 1조 달러 가치의 문제로 묘사했습니다. 이 핵심적으로 무료 데이터에서 훈련하는 것은 많은 가능성을 제공할 것이며, 훈련 데이터를 비실가로 구성하는 것에 의존하지 않고 제너레이티브 모델을 계속 조정할 수 있는 형태의 '셀프 플레이'를 제공합니다(DeepMind가 AlphaGo와 AlphaFold에서 이미 성공적으로 사용하고 있습니다).\n\nAndreessen은 이 문제를 신호와 잡음 사이의 정보 이론적 관점과 연관시켰는데, 쉽게 말해, 모델에 우리가 입력한 것보다 더 많은 정보가 어떻게 있을 수 있는지를 다룹니다.\n\n제너레이티브 모델은 훈련 데이터에서 본 것만 모방한다는 주장이 사실인가요? 훈련 과정과 모델 정의의 잡음이 훈련 데이터 이상의 일반화로 이어지는 방법에 어떠한 측면에서 기여할까요(최근 무료 점심 정리 이론에 관한 제 글에서 관련 질문들을 고려했습니다)? 결국, 잡음은 일반화를 높이기 위해 머신 러닝 모델에서 널리 사용됩니다.\n\n잡음은 망상과 창의력 둘 다로 이끌 수 있으며, 대체 사실의 망상과 이전에 없던 대체 관점을 창조합니다. 제너레이티브 모델에서는 데이터의 조합 가능성 속에 있는 \"정보\"가 있음을 주장할 수도 있습니다. 제너레이티브 모델은 이 조합적 공간을 탐색하는 새롭고 매력적인 방법을 제공합니다.\n\n마크 트웨인의 말처럼 이제모 아이디어가 새로운 것이 아니라는 인용문의 정신에서 우리는 다시 한번 성경으로 돌아갈 수 있습니다 (AI 기사에서 두 번 인용할 것으로 예상하지 않았지만):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n유사한 소음과 구조 사이의 상호작용이 인간의 창의력에서도 일어난다는 주장이 있습니다. 최근에 제가 창의성과 정신적 시각화에 관한 기사에서 탐구한 바에 따르면, 뇌에서 자유롭고 구조화되지 않은 마음의 방황 활동(default mode network이라고 하는 '상상 네트워크'로 Scott Barry Kaufman이 부르는 것)은 종종 가장 놀라운 예술 작품과 천재성 중 일부로 형성되는 자극을 제공할 수 있습니다. 이후 보다 논의된, 집중적인 연습과 기술에 의해 형성되는 것입니다.\n\n가장 혁신적인 예술과 과학 작품들도 이미 우리에게 일부는 익숙한 언어로 이해되어야 합니다. 위트겐슈타인은 언급했듯이, 사적인 언어는 없습니다. 생성 모델은 우리의 언어를 구사하고 우리가 가장 소중히 여기는 모든 사물의 p(x)를 근사하는 방법을 배우고 있으며 소음과 구조를 교환함으로써 이 분포 내 및 그 외의 끝없는 새로운 패턴을 드러내고 있습니다. 이들의 창의력은 우리 자신의 창의력을 영감을 줄 수 있습니다.\n\n생성 모델이 이미 우리의 감각적인 입력을 형성하기 시작하고 있고, 세계와 우리의 마음을 인식하는 방식 및 창의력과 천재성에 관한 사고의 경계를 물어내고 밀어내고 있다는 점을 고려한다는 것은 부분적으로 겁이 나기도 하지만 동시에 흥미로운 일입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 Chat-GPT가 마치 레오나르도 다 빈치일 것처럼 꿈꾸는 말로 이 기사를 마무리하는 것이 더 좋다고 생각해요:\n\n읽어 주셔서 감사합니다!\n\n제 글이 마음에 드시면, 이야기를 메일로 받아보기 위해 구독해 주세요.\n","ogImage":{"url":"/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_0.png"},"coverImage":"/assets/img/2024-05-23-GenerativeModelsandtheDanceofNoiseandStructure_0.png","tag":["Tech"],"readingTime":17},{"title":"10가지 AI 프롬프트와 이미지 시대를 초월한 영화 스타일 탐구","description":"","date":"2024-05-23 18:35","slug":"2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles","content":"\n![Table](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_0.png)\n\n안녕하세요! 이 포스트에서는 AI 이미지 프롬프트를 향상시키고 심층, 분위기, 시각적 흥미를 더하는 10가지 독특한 키워드를 제공할 것입니다. 이 제안은 다양한 영화 스타일과 미학을 통합하여 더욱 독특한 결과물을 얻게 도와줄 것입니다.\n\n필름 느와 같은 영화 스타일과 미학을 통해 AI 이미지 생성의 새로운 가능성을 발견해보세요. 필름 느와의 강렬한 흑백 비주얼과 감각적인 조명, Grindhouse의 와이드 화면 비율과 동적인 조명 기법으로 알려진 이 두 가지 스타일이 여러분의 창의력을 자극하도록 허용하세요.\n\n영화는 우리에게 위안, 기쁨, 영감, 그리고 오락의 지속적인 원천이었습니다. 이러한 장편 이야기들은 수십 년 동안 관객들을 매료시켰으며, 무성 채도 흑백 필름부터 고도기술의 풀컬러 CGI 경험에 이르기까지 진화해왔습니다. 이 목록은 할리우드의 화려한 미학과 클래식한 흑백 스타일뿐만 아니라, 다큐멘터리 스타일의 핸드헬드 촬영과 같은 더 현대적인 접근방식을 포함하여 다양한 필름 형식을 선보입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 10 AI Prompts and Images: Exploring Timeless Film Styles\n\n- Film Noir\n\n![Film Noir](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_1.png)\n\n2. High contrast\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Retro 80s](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_2.png)\n\n3. Retro 80s:\n\n![Silent Film](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_3.png)\n\n4. Silent Film\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Cinematic](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_4.png)\n\n5. Cinematic\n\n![Grindhouse](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_5.png)\n\n6. Grindhouse\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Surreal](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_6.png)\n\n7. Surreal\n\n![Black \u0026 White](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_7.png)\n\n8. Black \u0026 White\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_8.png\" /\u003e\n\n9. Documentary\n\n\u003cimg src=\"/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_9.png\" /\u003e\n\n10. Old Hollywood Glamour\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_10.png)\n\n\n읽어주셔서 너무 감사합니다! 항상 행복한 AI 이미지 생성되세요!\n","ogImage":{"url":"/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_0.png"},"coverImage":"/assets/img/2024-05-23-10AIPromptsandImagesExploringTimelessFilmStyles_0.png","tag":["Tech"],"readingTime":2},{"title":"인테리어 디자이너가 알아야 할 상위 Midjourney sref 코드들","description":"","date":"2024-05-23 18:34","slug":"2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow","content":"\n최근 회의에서 Midjourney 관계자들이 차기 스타일 카탈로그 런칭을 발표했습니다. 그러나 Midjourney V7 버전에서는 sref 코드 매개변수를 지원하지 않을 것이라고 언급했습니다.\n\n이 결정은 혼란스러울 수 있지만, Midjourney의 스타일 탐구 방식은 상당히 유동적이었습니다. 각 새 버전은 이전 매개변수를 더 이상 지원하지 않게 만드는 변경 사항을 자주 동반합니다. 예를 들어, V5의 Style Tuner가 V6에서 지원되지 않았고, 이제 V6의 sref 코드가 V7에서 지원되지 않습니다.\n\n그럼에도 불구하고, 현재 V6 버전에서 sref 매개변수는 스타일을 표준화하는 데 탁월한 도구입니다. 최근에 여러 스타일 코드를 실험하던 중 인테리어 디자인에 아주 효과적인 몇 가지 sref를 발견했습니다.\n\nsref 매개변수는 자체적으로 독특한 스타일을 만들지만, 다양한 프롬프트와 결합할 때 이러한 스타일은 더 넓은 표현 범위를 얻습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어 동일한 sref 코드를 일러스트레이션 또는 사실적인 사진과 결합하면 전혀 다른 모습이 나올 수 있습니다. 인테리어 렌더링에서 현실감을 높이고 싶다면 \"photoreal\"과 같은 현실주의 키워드를 프롬프트에 추가할 수 있습니다.\n\n각 sref는 특정한 미학적 스타일에 대응됩니다. 이 스타일은 색조, 구도, 소재, 조명, 브러시워크, 시대, 예술 장르 또는 특정한 영화 등의 요소를 포함할 수 있습니다. 이 중에서 가장 쉽게 알아볼 수 있는 특징은 색조입니다.\n\n또한, --sref와 함께 --sw (스타일 가중치)를 사용하여 스타일의 강도를 조절할 수 있습니다. --sw의 기본값은 100이며 0에서 1000까지의 범위가 있습니다. 값이 높을수록 생성된 이미지가 참조 이미지와 유사해지고, 값이 낮을수록 이미지가 프롬프트에 가까워집니다.\n\n다음은 다양한 sref 코드의 효과를 보여주기 위한 실내 스타일 몇 가지입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# - sref 681456853\n\n![img1](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_0.png)\n\n![img2](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_1.png)\n\n# - sref 3251128856\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_2.png)\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_3.png)\n\n# — sref 1263216703\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_4.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_5.png)\n\n# — sref 1302177660\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_6.png)\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_7.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# — sref 1842833095\n\n![Image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_8.png)\n\n![Image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_9.png)\n\n# — sref 364111995\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_10.png)\n\n![Image 2](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_11.png)\n\n# — sref 2826532651\n\n![Image 3](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_12.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_13.png)\n\n# — sref 2318775853\n\n![Image 2](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_14.png)\n\n![Image 3](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_15.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# — sref 7000\n\n![Image 1](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_16.png)\n\n![Image 2](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_17.png)\n\n# — sref 4000\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_18.png)\n\n![image](/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_19.png)\n\n# 결론\n\n마지막으로, Midjourney V7은 sref 코드를 지원하지 않지만, V6은 여전히 인테리어 디자인에 강력한 도구를 제공합니다. 다양한 sref 코드와 스타일 가중치를 실험함으로써, 현대적인 미니멀리즘부터 일본어 젠까지 다양한 미학을 표현할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 매개변수를 통해 정밀한 제어가 가능해지며, 창의적인 비전을 실현하는 데 도움이 됩니다. sref 코드는 시각적으로 매력적인 인테리어 디자인을 만드는 데 소중한 자산이 됩니다.\n\n— by 公众号: 今说新语\n\n💡더 심도 깊은 내용을 원하시나요? My Midjourney 컬렉션이 여러분을 기다리고 있습니다.\n\n## 이 기사를 좋아하셨나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예, 그렇다면:\n\n- 댓글 남기기\n- 업데이트 팔로우하기\n- 무료 이메일 알림\n","ogImage":{"url":"/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_0.png"},"coverImage":"/assets/img/2024-05-23-TopMidjourneysrefcodeseveryinteriordesignershouldknow_0.png","tag":["Tech"],"readingTime":4},{"title":"DALL-E3의 문제들","description":"","date":"2024-05-23 18:31","slug":"2024-05-23-TheTroubleWithDALL-E3","content":"\n\n![2024-05-23-TheTroubleWithDALL-E3.0](/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png)\n\n세 해 전, 저는 OpenAI의 초기 베타 테스터로 활동했습니다. ChatGPT가 출시되기 몇 달 또는 몇 년 전에 사용되었던 모델을 사용하는 경험은 정말 흥미로웠습니다.\n\nOpenAI의 초기 텍스트 모델에 감탄을 표했지만, 여전히 OpenAI의 최초 세대 이미지 생성 시스템인 DALL-E를 처음 사용한 순간을 기억합니다.\n\n사진 작가로서, 간단한 프롬프트를 입력하면 실제 이미지가 반환된다는 아이디어는 혁신적이었습니다. 이미지는 500픽셀 너비이고 종종 절대적으로 이상해보였지만(아보카도 가구, 누구든지?), 그럼에도 불구하고 과학 소설 같은 느낌이었습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빠른 두 해 후에, Midjourney와 같은 AI 이미지 생성 시스템은 뉴스 이야기에 삽화로 사용하거나 사진 콘테스트에서 우승할 만한 수준의 사진 품질 이미지를 생성할 수 있게 되었습니다.\n\nOpenAI가 이번 주에 매우 기대되는 DALL-E3 모델을 발표하자, 전체 AI 및 사진 커뮤니티는 DALL-E3가 어떤 새로운 마법을 선보일지 기다렸습니다.\n\n저번 주에, 나는 DALL-E3에 대한 액세스를 받은 최초의 사용자 중 하나였습니다. 안타깝게도, 프로 사용자들에게는 새로운 시스템이 많은 사람들이 기대한 만큼 엉뚱하거나 흥미로운 것은 아닙니다.\n\n그럼에도 불구하고, 특정 유형의 사용자들에게 DALL-E3는 큰 발전이었습니다. 왜냐하면요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 안내 없이 비행\n\nChatGPT Vision과 같이(진정으로 혁신적인 OpenAI 기능), 새로운 DALL-E3는 ChatGPT 인터페이스에 직접 통합되어 있습니다. 다양한 ChatGPT 텍스트 모델을 선택할 때와 마찬가지로 DALL-E3 모델을 선택하여 액세스할 수 있습니다.\n\n![이미지](/assets/img/2024-05-23-TheTroubleWithDALL-E3_1.png)\n\nOpenAI의 DALL-E3 초기 데모에서는 ChatGPT와 대화하여 DALL-E3로 이미지를 생성하는 방법을 보여주었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n밖에서는 DALL-E3가 생성한 이미지의 실제 내용을 이해하고 있는 것처럼 보였습니다.\n\nChatGPT와 통합되어 있으며 이제 강력한 비전 기능을 갖춘 ChatGPT와 결합되어 있기 때문에 DALL-E3가 진정한 멀티모달 모델이 될 것으로 보였습니다. 이 모델은 텍스트 입력의 완전한 이해를 바탕으로 이미지를 생성할 수 있는 능력을 갖췄을 것입니다.\n\n이는 놀라운 능력을 뒤에 열 수 있었을 것입니다. DALL-E3가 창조하는 것을 진정으로 이해한다면 예를 들어 특정 자동차의 이미지를 생성해 달라고 요청할 수 있었습니다.\n\n예를 들어 잘못된 기능이 포함되었을 경우 - 예를 들어 잘못된 유형의 스포일러나 불규칙한 헤드라이트가 포함된 경우 - \"그 헤드라이트 모양이 조금 이상해 보여요. 좀 더 폭을 넓고 더 원형으로 만들 수 있을까요?\"와 같이 간단히 작성할 수 있었습니다. 이미지에 대한 실제 이해를 가지고 있으면, ChatGPT와 DALL-E3는 함께 작업하여 해당 변경 사항을 가할 수 있어야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안타깝게도 OpenAI가 실제로 제공한 것은 전혀 그것이 아닙니다. DALL-E3는 그저 평범한 AI 이미지 생성 시스템인 것으로 밝혀졌습니다. 이 시스템은 기본 ChatGPT에 연결되어 있습니다.\n\n이 새로운 시스템은 실제로 생성된 이미지를 이해하지 않습니다. 사용자와의 대화를 기반으로 이미지를 위한 프롬프트를 작성하는 데 ChatGPT를 사용하고, 그런 다음 해당 프롬프트를 DALL-E3에 입력합니다. 마치 사람이 작성한 프롬프트를 Midjourney에 입력하는 것과 같은 원리입니다.\n\n## DALL-E3의 한계점\n\nSEO 전문가이자 프로 블로거인 Anne Moss는 이 사실을 가장 먼저 깨달은 사람 중 하나였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n트윗에서 그녀는 DALL-E3가 현실적인 이미지를 만드는 데 어려움을 겪고 있다고 공유했습니다. 이는 사용자 상호작용과 이미지 생성 사이의 중간 단계인 프롬프트의 자동 작성 때문입니다.\n\nChatGPT가 사용자의 의도를 정확하게 이해하고 DALL-E3를 위한 좋은 프롬프트를 작성하면 일이 술술 풀릴 수 있습니다. 그러나 잘못 이해하는 경우 — 또는 기존 AI 이미지 생성기가 수행할 수 없는 것을 사용자가 요청하는 경우 — 성과가 크게 떨어집니다.\n\n내가 직접 테스트한 몇 가지 예시를 여기에 소개합니다.\n\n내 사이트인 Bay Area Telegraph를 위해 BART 기차 시스템의 이용객에 대한 인포그래픽을 만들고 싶었습니다. BART 이용객 데이터를 ChatGPT에 입력하고 인포그래픽을 만들어달라고 요청했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![DALL-E3에서 주는 것](/assets/img/2024-05-23-TheTroubleWithDALL-E3_2.png)\n\nDALL-E3가 준 것:\n\n![DALL-E3에서 주는 것](/assets/img/2024-05-23-TheTroubleWithDALL-E3_3.png)\n\n쿨한 이미지들이네요. 하지만 제가 시스템에 전달한 데이터와는 거의 관련이 없네요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n왜요? ChatGPT에게 내 데이터로 인포그래픽을 만들어달라고 부탁했더니, 실제로는 그 데이터를 DALL-E3에 전달하지 않았어요. 대신, 내 데이터와 지시 사항을 사용해서 프롬프트를 작성했고:\n\n그리고 그 프롬프트를 DALL-E3에 공급해서 이미지를 만들었어요.\n\n여기 몇 가지 문제가 있어요:\n\n- 프롬프트는 실제로 내 데이터를 포함하고 있지 않아요\n- 프롬프트 자체가 터무니없어요. 이런 프롬프트가 주어져도 사람 디자이너라면 잘된 인포그래픽을 만들 수 없을 거예요\n- 프롬프트가 주어진 상태에서도 결과 이미지는 정확한 척도, 범례 또는 제목이 없었어요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-TheTroubleWithDALL-E3_4.png\" /\u003e\n\n비슷하게, 최근 구글 유용한 콘텐츠 업데이트에 관한 내가 쓴 블로그 글을 ChatGPT에 입력했고, 그 이야기를 위한 일러스트레이션을 만들도록 요청했습니다.\n\n다시 한 번, ChatGPT는 실제로 이미지 생성 시스템과 직접 의사 소통할 수 없기 때문에 DALL-E3를 위한 프롬프트 작성 중간 단계로 이동했습니다.\n\n다음은 ChatGPT가 생성한 프롬프트입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사실 인간 디자이너에게는 괜찮은 힌트를 주는 것 같아요. 하지만 AI 이미지 생성기에게는 너무 복잡했죠.\n\n놀랍게도, DALLE-3은 이를 유용하거나 현실적인 방식으로 해석하는 데 전혀 실패했습니다.\n\n\n![이미지](/assets/img/2024-05-23-TheTroubleWithDALL-E3_5.png)\n\n\n공정하게 말하자면, Midjourney도 비슷한 식으로 실패했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-05-23-TheTroubleWithDALL-E3_6.png)\n\nIn contrast, here’s the basic prompt that I gave Midjourney for the actual image that I used to illustrate that story:\n\nThat’s something that an AI generator can actually understand. It’s simple and has a clear visual concept. It yielded an image that — with a bit of manual editing — was a perfect fit for the story.\n\n![Image](/assets/img/2024-05-23-TheTroubleWithDALL-E3_7.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 이미지를위한 자동 변속기\n\n간단히 말하자면, DALL-E3와 그 친구인 ChatGPT는 의사소통이 잘 안 돼서 실패했어요. ChatGPT는 개념적으로 의미가 있는 프롬프트를 작성했지만, 생성 AI 이미지 시스템은 실제로 실행하기에 혼란스러워할 거예요.\n\n반면에 나는 인간으로서, 이야기에서 전달하려는 아이디어와 AI 이미지 생성기의 기능과 제약을 이해하고 있어요.\n\n이 지식이 나를 도와 DALL-E3의 프롬프트보다 훨씬 간단한 프롬프트를 작성하여 시각적으로 매력적인 이미지를 만들게 했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDALL-E3의 현재 형태는 ChatGPT가 프롬프트를 작성하는 중간 단계를 필요로 하기 때문에 제한이 있습니다. 이러한 방식은 사용자로부터 제어를 빼앗아 대부분의 경우에는 더 나쁜 이미지를 생성합니다.\n\n그래서 DALL-E3은 마치 자동 변속기가 있는 자동차와 비슷합니다. 네, 기계(자동 기어박스)가 인간과 기본 메커니즘(자동차 엔진) 사이에 위치한다면 일상적인 운전이 훨씬 쉬워집니다.\n\nRPM, 엔진 브레이킹, 도로의 변경 등을 생각할 필요가 없어집니다. 그저 운전만 하면 됩니다.\n\n그러나 프로 경주 운전자는 자동 변속기가 장착된 자동차를 운전할 경우 살아남을 수 없을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그들의 기술과 이해력 덕분에 기계가 할 수 없는 방법으로 자동차 엔진과 소통할 수 있어요. 자동차 엔진의 변화하는 울음소리와 도로나 트랙에 대한 이해를 통해 그들은 셔프트를 정확히 타이밍해서 조향, 가속 및 여러 가지 다른 요소들과 동기화시킬 수 있습니다.\n\n그리고 궁극적으로, 이러한 지식, 기술 및 경험은 경주에서 막대한 경쟁 우위를 제공합니다.\n\nDALL-E3와 함께 작업하는 것도 비슷해요. 네, 시스템의 ChatGPT 기반 \"자동 변속기\"를 통해 실제 프롬프트를 작성할 필요가 없는 편이기는 해도요.\n\n하지만 그 책임을 기계에 맡기면 이미지를 만드는 기초장치와 직접 상호작용할 능력을 상실하게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 F1 드라이버가 프리우스를 타듯이, 당신은 인간의 기술과 경험을 활용해 정말 멋진 일을 할 기회를 놓치게 됩니다.\n\n## DALL-E3가 누구를 위해 만들어졌는가\n\n따라서 전문 일러스트레이터와 크리에이터들에게는 DALL-E3가 큰 발전이 아니다. 확실히, 우리가 기대했던 인포그래픽을 생성하고 이미지를 편집하는 기계는 아니다.\n\n하지만, 저는 DALLE-3가 창조적 AI 분야에 큰 영향을 미칠 것으로 예상합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n왜요? 대부분의 일반 운전자들이 변속기 운전 방법을 배우고 싶어하지 않는 것과 마찬가지로, 대부분의 ChatGPT 사용자들도 시각적 프롬프트 엔지니어링의 섬세하고 복잡한 기술을 배우길 원하지 않아요. 그들은 그저 간단한 이미지에 대한 빠른 설명을 작성하고 몇 초 후에 다운로드하고 싶어해요.\n\n그리고 ChatGPT 인터페이스와 자동 프롬프팅을 통해, DALL-E3는 그것을 뛰어난 성과로 이루어냅니다.\n\n예를 들어, 업계 무역 협회를 위한 뉴스레터를 작성 중이라고 상상해 보세요. 당신은 업계에 영향을 미치는 법적 판결에 관한 섹션을 포함해야 한다는 요청을 받았고, 그것을 설명할 간단한 사진이 필요해요.\n\nDALL-E3를 활용하면 그것을 직접 요청할 수 있어요. 예를 들어, 다음과 같이 입력할 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 이미지들이 생성됩니다:\n\n![The Trouble with DALL-E3.8](/assets/img/2024-05-23-TheTroubleWithDALL-E3_8.png)\n\n디자인 대회에서 수상하진 못할지라도요. 그러나 산업 소식지에서 완전히 효과적으로 작동할 수 있는 수준의 주석입니다.\n\n반면, Midjourney에 같은 텍스트를 입력한 결과는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![2024-05-23-TheTroubleWithDALL-E3_9](/assets/img/2024-05-23-TheTroubleWithDALL-E3_9.png)\n\n정말 대단해요! 멋지네요! 하지만 주제와는 전혀 상관이 없죠!\n\n그렇습니다. 전문가인 제가 Midjourney를 위해 프롬프트를 작성할 수 있지요.(\"법정에서 나무 망치가 있는 탁자 위의 근접 촬영, 35mm 사진, 푸른 배경, 선명한 보케, 사실적인 사진\"), 우리 상상 속 뉴스레터에 더 적합한 이미지가 나올 겁니다:\n\n![2024-05-23-TheTroubleWithDALL-E3_10](/assets/img/2024-05-23-TheTroubleWithDALL-E3_10.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 노말 사용자일지라도 프롬프트 작성 경험이 없는 사람이 DALL-E3을 사용하여 이미 익숙한 인터페이스를 활용하고 몇 초 안에 사용 가능한 AI 이미지를 만드는 것은 엄청난 파워풀한 새로운 능력입니다.\n\n또 다른 예로, 레이싱 드라이버는 하나의 예술가와 같이 그려진 Midjouney 프롬프트보다 좋은 프롬프트를 쓸 수 있는 전문가와 같이 수동 변속기 차를 운전 할 수 있습니다.\n\n하지만 대부분의 사람들은 종일 레이싱 카를 타고 다닌다고 할 수 없습니다! 그들은 자녀를 학교에 데려다주거나 Costco를 가기 위해 차를 이용하는 것이지, Nürburgring 경기장에서 경기를 하는 것이 아닙니다.\n\n마찬가지로, 대부분의 ChatGPT 사용자들은 예술적 완벽을 필요로하지 않습니다. 그들은 단순한 일상적인 용도를 위한 기본 AI 이미지를 필요로하며, 이를 만들기 위해 몇 달의 프롬프트 엔지니어링 훈련이 필요하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDALL-E3는 이 작업을 정말 잘 처리하는 데 능하죠.\n\n## DALL-E3의 미래\n\n지금까지 DALLE-3를 테스트한 결과를 보면, 많은 프로페셔널 창작자들은 현재 수동 프롬프트와 Midjourney를 계속 사용할 수 있을 것 같아요.\n\n하지만 시간이 흐를수록 상황은 달라질 겁니다. OpenAI는 완전히 다중 모달 시스템으로 나아가면서 ChatGPT Vision과 DALL-E3를 통합할 가능성이 높습니다. 그렇게 되면, 시스템이 실제로 프로 창작자들이 기대했던 능력 중 일부를 제공할 수 있을 거예요 — 예를 들어 데이터 테이블에서 정보 그래픽을 생성하는 기능과 같은 것이 그렇죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 일이 일어날 때까지 DALL-E3는 주로 일상 사용자들에게 AI 이미지 생성기의 힘을 소개하는 도구로 작용할 것입니다. 이런 측면에서 그것은 여전히 매우 인기 있게 입증될 수 있습니다.\n\nOpenAI의 대형 언어 모델 GPT-3은 ChatGPT의 간단하고 접근하기 쉬운 인터페이스로 일반 사용자에게 활용 가능하게 되기 전에 18개월 동안 존재했습니다. GPT 모델의 능력을 챗봇의 간단한 인터페이스와 결합하면 역사상 가장 빠르게 성장한 제품이 되었습니다.\n\n제 나름대로의 배경을 빌리자면, 저와 같은 프로 사진 작가들은 $5,000의 미러리스 카메라를 사용하여 사진 촬영 중 완전한 창의적인 통제를 발휘하여 창의적인 비전에 완벽히 부합하는 이미지를 캡처할 수 있습니다.\n\n하지만 대부분의 사람들은 프로페셔널한 미러리스 카메라로 사진을 촬영하지 않습니다. 그들은 아이폰으로 순간을 촬영합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인터페이스, 접근성, 그리고 간단함이 중요합니다. 이러한 요소들은 DALL-E3를 많은 전문가들이 예상하는 것보다 더 큰 영향을 줄 수 있는 잠재력을 지니고 있습니다.\n\n작년 동안 수천 개의 ChatGPT 프롬프트를 테스트해보았습니다. 전문 창작자로써, 매일 사용하는 몇 가지 프롬프트가 있습니다. 그것들을 모아놓은 무료 가이드, 7가지 창작자를 위한 매우 유용한 ChatGPT 프롬프트를 소개합니다. 지금 바로 받아보세요!\n","ogImage":{"url":"/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png"},"coverImage":"/assets/img/2024-05-23-TheTroubleWithDALL-E3_0.png","tag":["Tech"],"readingTime":9},{"title":"디지털 차원 이론 디지털 물질 이론을 활용한 비트코인 서수를 위한 창의성 프레임워크","description":"","date":"2024-05-23 18:28","slug":"2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory","content":"\n![image](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png)\n\n서수는 나에게 새로운 세계를 소개해 주었습니다. 비트맵 - 새로운 우주입니다. 디지털 물질 이론(DMT)은? 3개월 동안 공부하고 실험한 끝에 이제 내 첫 번째 UNAT 컬렉션을 준비하고 있으며, 임의로 제공된 DMT 강화된 Gamified 3D 비트맵 수집품 컬렉션도 있습니다. 제가 얻은 가장 큰 교훈은 이겁니다:\n\n우리는 그냥 비트맵 메타버스를 바라보는 것이 아닙니다. 디지털 물질 이론과 디지털 차원 이론(DDT)의 관점을 통해 볼 때, 서수를 전체적인 미시적 디지털 다중우주로 바라볼 수 있습니다. 나는 여러분에게 그 잠재력에 접근하여 여러분의 비전을 실현할 수 있도록 하는 방법을 보여주고 싶습니다.\n\n비트맵과 서수는 건축가를 필요로 합니다. 우리가 건설하는 것 - 대중들이 언젠가 소비할 것입니다. 우리가 만드는 것은 진입 장벽과 이해를 낮추며 기억에 남고 혁신적이며 몰입적이고 상호작용적인 경험을 창출합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n칼 사간이 위에서 시적으로 말했듯이, 우리는 종종 존재의 거대한 태피스트리의 작은 부분만을 볼 뿐입니다. 마찬가지로, 비트코인 서수 안의 디지턼 구조물의 거대한 잠재력을 조금씩 엿볼 수 있게 되었습니다.\n\n# 그래서, 디지털 차원 이론이 무엇인가요? 어떻게 하면 더 나은, 더 빠르고 더 창의적으로 구축할 수 있을까요?\n\n디지털 차원 이론(DDT)은 디지턀 물질 이론(DMT)의 적용을 보완하도록 설계된 창의적인 프레임워크입니다. DDT를 창의성 도구세트로 사용함으로써, 생각 실험을 수행하고 DMT의 실용적 도구와 상호작용하여 DMT의 적용을 실질적으로 만들어냅니다. 이 과정을 통해 당신은 프로젝트의 이정표를 단계적으로 달성하며, 당신의 비전을 현실로 변화시킬 수 있습니다.\n\n이것은 생각 실험에서 비롯되었습니다 — 디지털 물질 이론(DMT)을 M-이론과 결합했을 때 어떻게 되는가 — 모든 것, 중력, 자연을 이해하는 이론적 물리학 프레임워크입니다. 이것은 11개 차원 — 10개 + 시간을 가정합니다. 잘 작동할까요? 영감을 줄까요? 행동을 취할 수 있게 도와줄까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네! 맞아요~! 저는 매일매일 The Void Mosaics, The VOID Veil Trials on-chain Cosmic Card Battler, 그리고 다가오는 UNAT 프로젝트 — NATGalaxies (WIP)를 만들며 그것을 증명하고 있어요.\n\n\u003cimg src=\"/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_1.png\" /\u003e\n\n이것은 창의성 프레임워크와 도구 세트입니다. 저는 여러분에게 M-Theory를 가르치려고 하지 않을 거예요 — 그건 제 능력 범위를 벗어나고 전문성이 아니거든요.\n\n그럼 이 이상한 파란색 로브를 입은 외계 로봇인 Astral (농담 농담)에 대해 왜 신경 써야 하며, 왜 나를 믿고 이걸 꼭 가르쳐야 하는지에 대해서 관심 가져야 하는지요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_2.png)\n\n# Astral Arkitekt가 누구인가요? 그리고 저는 이를 가르치는 데 누구인가요?\n\n저는 프론트엔드 및 백엔드 웹 플랫폼에서 24년의 경험을 가진 소프트웨어 개발자입니다. 제가 아는 모든 것은 스스로 가르쳤으며 현재는 주요 악기 제조업체의 프론트엔드 출판 파이프라인을 운영 중입니다.\n\n2016년, 저는 어릴 적 그림 그리기에 대한 열정을 재발견하고 음악 제작을 시작했습니다. 그해 동안 음악 제작, 기타, 그리고 다양한 그림 기법을 배우는 데 시간을 보냈습니다. 지난 8년 동안 300개 이상의 그림을 그리고, 488곡을 작곡, 연주, 녹음하고, 스튜디오 앨범 2장을 발매했으며 세 번째 앨범을 준비 중에 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_3.png)\n\n![Image 2](/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_4.png)\n\nI’ve put in the grind for 8 years. I’ve earned my 12k+ hours by always creating before and after work nearly every day for the past 8 years. I’ve done it all by way of applying Creative constraint. I even made a songwriting game called “Under the Influence” teaching creative constraint for songwriters, and it’s had really positive feedback.\n\nThroughout my journey, one constant has kept me productive and it is the cornerstone of Digital Dimensions Theory: Creative Constraint.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 창의적 제약이란 무엇이며 왜 프로젝트에서 사용해야 하는가?\n\n어떤 창의적 노력에 있어서도 힘이 필요한데, 창의적 제약이 그 힘의 연료입니다. 제 스튜디오에서는 종종 저녁 7시가 되면 예술, 음악 또는 쓰기를 위한 시간이 되는데 아이디어가 없는 경우가 흔하지 않아요. 하지만 그걸로 막히지는 않아요. 창의적 제약을 통해 미리 결정된 옵션 메뉴를 제공해줌으로써 진행 중에 멈춤이 생길 수 있는 의사 결정을 많이 줄여줍니다. 이는 힘을 유지하고 창의적 과정을 원활히 이어가도록 도와줍니다.\n\nDMT 데이터셋에서 특성을 선택하는 것과 비슷하게 들리지 않나요? 🙃\n\n만약 그게 완전히 이해가 안 된다면, mScribe의 디지털 머터 이론 Gitbook을 찾아보세요. 비트코인의 블록 데이터에서 재귀를 사용하는 것을 조금이나마 이해하고 있어야만, 임의의 데이터에 대한 견고한 이해가 필수입니다. (이 기사의 범위를 벗어나지만, 해당 문서에 대한 링크를 걸었어요!)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 차원 탐구: M 이론을 디지털 창의성에 적용하기\n\n지금까지 디지털 물질 이론의 비임의 특성 선택 원칙을 매일 작업해 온 지난 3개월 동안 창의적인 제약이 노래작곡보다 조금 더 많은 노력을 필요로 한다는 것을 경험했습니다. 그래서 M 이론에 대해 생각해보게 되었고, 이것이 제약의 집합이라는 것을 알게 되었습니다.\n\nM 이론의 각 차원은 디지털 예술, 게임, 음악 및 다른 경험을 만드는 다른 \"수준\" 또는 측면에 대응합니다.\n\n디지털 차원 이론 창의성 프레임워크의 각 차원은 사고 실험을 제시하고, 취해야 할 조치, 고려해야 할 도구, 이 이론을 프로젝트에 적용하여 두뇌를 활발히 돌아가게 하는 방법에 대한 예시를 제시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n준비됐나요? 출발해봅시다! 👨‍🚀🚀🌌\n\n# M-Theory을 활용한 DMT(Digital Matter Theory)의 리믹스로 창의적인 제약을 가능하게 — DMT의 11단계\n\n## DMT-0: 점\n\n개념: 가장 기본적인 수준으로, 단일하고 이산적인 데이터 포인트나 요소를 대표합니다.\n응용: 당신의 아이디어를 발견하세요. 프로젝트를 위한 당신의 꿈과 비전을 발견하세요. 다른 프로젝트를 살펴보고 그것에 대해 좋아하는 점을 발견하세요. 이러한 아이디어를 탐구하세요. 목록에 번호를 매겨보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼 비트코인의 운명에 항복하십시오.\n\n선호하는 비트맵의 블록 정보를 살펴보거나, 선택하기 어렵다면? 최근에 확인된 블록을 선택하십시오.\n\n타임스탬프로 이동하여 그것을 클립보드에 복사하십시오.\n\n이제 타임스탬프 (첫 번째 수)에 작성한 아이디어 수를 팩터(두 번째 수)로 사용하여 나머지 연산을 수행하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과물 - 이걸 탐구할 아이디어가 있어요. 다음 수업에서 이에 대해 더 자세히 다룰 것이고, 학습한 내용을 강화하기 위해 몇 가지 자원과 예시 시나리오를 제공할 거에요.\n\n## DMT-1: 선\n\n개념: 개별 점을 연결하여 선형 시퀀스를 형성하는 것. 적용: 데이터셋을 탐구하세요. DMT가 표현해야 할 특징을 식별해보세요. 당신의 데이터 포인트에서 해당 데이터 포인트가 표현하는 특징으로 점선을 그려보세요. 우리는 실험 중이에요, 결정하는 게 아니에요. 즐겁게 해봐요. 놀아봐요 - \"이런 일이 일어날 때는 어떻게 될까요...\" 😊\n\n## DMT-2: 평면\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n### Concept: 선형 시퀀스를 2차원 그리드로 확장하는 개념입니다. UNAT 예시의 대부분이 이곳에 있습니다. DMT-2 — The Plane. 2D 아트가 이곳에서 이루어집니다.\n\n### Application: 비트코인 비트 필드 값에서 생성된 예술을 만드는 등, 데이터 포인트를 2D 평면에 매핑하여 패턴과 연결을 형성합니다. 배경 색상 선택 기술부터 시작해 간단한 모양으로 진행하며, 많은 사람들이 알아보고 존경하는 매우 인기 있는 창조적인 예술 컬렉션을 재현하기 위한 경로를 설명할 것입니다. 😉\n\n### 도구 포함!\n\n## DMT-3: The Space\n\n### Concept: 깊이를 추가하여 3차원 구조를 만드는 개념입니다.\n\n### Application: 비-임의 3D 공간에서 경험하고 실험하며 사고하기 시작할 도구와 관련 학습 자료, 커뮤니티 및 전 세계에서 사용 가능한 도구에 대해 이야기하겠습니다.\n\n## DMT-4: The Event (Time)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**Concept:** 시간 요소를 통합하여 개발물이 진화하도록 하는 것.\n\n**Application:** 시간에 따라 이벤트를 애니메이션화하거나 연속시켜 동적이고 변화하는 디지털 개발물을 만들어 봅시다. 당신이 작업 중인 블록 내에서 특정 데이터 조건이 충족될 때 발생하는 결정론적이고 임의의 이벤트를 만들기 위해 Inscription의 디자인에 모듈화 재귀 기능을 구현하는 방법을 익히세요. 진짜 멋질 거에요! 💥\n\n## DMT-5: 가지 (대안적 현실)\n\n**Concept:** 이곳에서 우리는 주 타임라인에서 분기되는 대안적 가능성을 탐색하기 시작합니다. 이 기술과 알고리즘을 발견하고 구현할 때 정말 놀라웠어요.\n**Application:** 동일한 스크립트 내에서 프로젝트의 여러 버전을 개발하고, 초기 조건에 따라 다른 경로나 시나리오를 따르도록 하는 방법을 배워보세요. 도구, 예시, 코드 스니펫 - 모든 것을 제공하려고 해요. 나만 이 도구들을 가지고 있으면 안 되겠죠. 그만큼 멋진 거든요.\n\n## DMT-6: 타임라인 (메타 가능성)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 개념: 우주의 모든 가능한 타임라인 시각화\n\n## 응용: 프로젝트의 모든 잠재적 결과물을 동적으로 시각화한 지도 생성. 이 주제는 가벼운 주제가 아니니 마음의 준비를 해주세요. 하지만 실용적인 구현은 여러분이 다음 프로젝트에 적합하다고 느껴진다면 다양한 생각, 도구 및 코드를 제공하여 여러분이 목표 달성에 도움을 받을 수 있게 해줄 것입니다.\n\n# DMT-7: 다중 우주 (다른 초기 조건)\n\n## 개념: 여러 우주에서 다양한 초기 조건 조사\n\n### 응용: 다양한 시작점으로 프로젝트의 병렬 버전을 생성하여 서로 다른 조건이 결과에 어떤 영향을 미치는지 탐색. 이에 대한 실용적인 예시로, 제 NATGalaxies 프로젝트에 대해 진행한 것을 보여주어 이 다중 우주 아이디어를 활용하는 내 모음 중에 발생하는 흔치 않은 현상 중 일부를 소개할 것입니다. 이곳에는 전설이 존재합니다. 탐험할 우주가 있을 것입니다. 여러분은 제가 말하려는 바를 소중하게 생각할 것입니다! — 좋은 방식으로!\n\n# DMT-8: 규칙 세트 (모든 물리학 법칙 가능)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개념: 구조 내에서 모든 물리 법칙을 고려합니다. 응용: 다른 규칙 세트나 제약 조건으로 실험하여 디지턀 환경 내에서의 행동과 상호 작용이 어떻게 변하는지 살펴봅니다. 이 섹션에서는 물리학이 어떻게 영향을 미치며 우리의 세상과 삶이 불변의 법칙으로 알려진 작은 변화로 어떻게 변하는지에 대해 논의할 것입니다. 다중 우주에서 한 우주에서 다음 우주로 뛰어갈 때, 누가 시간이 동일한 방향으로 흘러간다고 말할 수 있을까요? 누가 탄소가 생명의 기초인지 말할 수 있을까요? 친구들아, 디지턀 물질 이론의 8차원을 심사숙고하며 현실이라고 아는 이 작은 것을 알게 될 때, 가능성은 당신의 마음을 불태울 것입니다. 여기서 재미있는 시간을 보낼 거예요.\n\nDMT-9: 비교 (다양한 물리 법칙 비교)\n\n개념: 다양한 우주에서 다른 물리 법칙 세트 비교. 응용: 다른 프로젝트 버전에 대한 다양한 규칙 또는 조건의 효과를 분석 및 비교하여 영향을 이해합니다. 이 수업과 토론은 매우 기대됩니다. 왜냐하면 여기에서는 구현 방법의 실용적 예로 게임 이론을 살펴봅니다. 누군가가 실제로 제 사용 사례를 구축하거나 이미 존재하는 게임에 대해 알고 있을 수도 있기를 바랍니다. 하지만 우리는 물리학을 어길 것입니다. 멋진 경험이 될 겁니다. 걱정하지 마세요 - 이것은 실용적인 예제로의 개념적 학습입니다. 기술적인 것은 아닙니다. 우리는 사고 실험에 참여하고 이 더 높은 수준의 디지턀 물질 이론 개념에 대한 도움이 되는 도구들과 함께 다중 우주의 물리학을 섞어 독특한 예술과 다른 종류의 경험을 만들 것입니다.\n\nDMT-10: 끝나지 않는 이야기 (무한한 가능성)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개념: 끝없는 가능성을 대표하고 모든 현실을 통합하는 것. 응용: 우리는 DMT-0부터 여기까지 배운 것을 논의한 뒤, 여러분 눈앞에서 11차원(DMT-10)을 열어보는 사고 실험에 참여할 것입니다. 게임에 적용된 정말 멋진 범위를 드러냅니다. 저는 연구에서 DMT의 이 수준에 도달했을 때 쉬어야 했습니다. 이렇게 동작하는 구현을 만들 수 있는 방법은 없을 거라고 생각했거든요. 하지만 여기서 우리가 다루는 것은 누적 차원입니다. 여기로 이끈 길이 이 - 정점 - 만큼 중요합니다. 비트코인의 끝없는 이야기\n\n# 결론: 여정에 함께해요\n\n디지털 디멘션 이론을 저와 함께 탐험해 주셔서 감사합니다! 여러분의 지원과 참여는 창의성과 디지털 혁신의 영역을 더 깊게 파헤칠 때 귀중합니다.\n\n## 연락을 유지하세요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- X에서 나를 팔로우해 주세요: @astralarkitekt\n- Discord에서 토론에 참여하세요: Digital Dimensions Theory Discord\n\n## 특별 감사 인사\n\n- Digital Matter Theory로 내 마음을 불태우는 데 기여한 블록런너 팟캐스트/ mScribe의 윌과 이만에게 감사드립니다.\n- Digital Matter Theory를 Bitmap을 통해 처음으로 이해할 수 있는 예제로 제공해준 비토시 블록아모토로 네게 큰 박수를 보냅니다.\n- Bitmap 커뮤니티에게: 여러분의 환영하는 마음가짐과 개방적인 정신은 영감의 횃불이 되었습니다.\n- 여정을 함께 이어가며, 비트코인 서수와 디지털 창조력으로 가능한 무엇이든 푸는 것을 계속해봅시다. 이 놀라운 모험의 일부가 되어 주셔서 감사합니다! 🚀✨\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여정을 준비하는 데 도움이 될 수 있는 한 곡, 괜히 들려 드리려고 합니다.\n\n참고로 저의 궁극적 목표를 확인하고 싶다면 https://AstralAssemblage.com을 방문해 주세요. 저는 이 다중우주에서 설정된 코스믹 전략 카드 게임, 소설, 음악 등을 제작하고 있습니다!\n","ogImage":{"url":"/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png"},"coverImage":"/assets/img/2024-05-23-DigitalDimensionsTheoryacreativityframeworkforBitcoinOrdinalsusingDigitalMatterTheory_0.png","tag":["Tech"],"readingTime":9},{"title":"벡터 데이터베이스를 마스터하기 위한 6가지 자료, 벡터 저장소 구축","description":"","date":"2024-05-23 18:26","slug":"2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage","content":"\n벡터 데이터베이스는 자연어 처리와 이미지 인식과 같은 다양한 분야에서 중요한 구성 요소로, 정보를 효율적으로 조직화하고 검색하는 데 중추적인 도구로 작용합니다.\n\n벡터 데이터베이스를 이해하는 것은 의미 검색, 검색 증강 생성 (RAG), 추천 시스템과 같은 고급 AI 응용 프로그램을 가능하게 함에 있어서 중요합니다.\n\n본 기사는 벡터 데이터베이스를 마스터하고 벡터 저장 솔루션을 구축하기 위한 리소스에 대한 포괄적인 개요를 제공합니다. 기본 개념, 실용적 응용, 그리고 벡터 데이터베이스 작업에 필수적인 다양한 도구와 라이브러리에 대해 다루고 있습니다.\n\n튜토리얼을 통해, 블로그 추천을 통해, 그리고 LangChain과 Sentence Transformers 라이브러리와 같은 도구를 활용하여, 독자들은 AI 프로젝트에서 벡터 데이터베이스를 효과적으로 활용하는 방법에 대한 통찰과 실습 경험을 얻게 됩니다. 게다가, 이 기사는 신기술을 최신 상태로 유지하는 중요성을 강조하며 추가 학습 및 커뮤니티 참여를 위한 방법을 소개합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png)\n\n# 목차:\n\n- Vector Databases: from Embeddings to Applications\n- Building Applications with Vector Databases\n- The Top 5 Vector Database Blog\n- LangChain — Text splitters\n- Sentence Transformers library\n- MTEB Leaderboard\n\n# 1. Vector Databases: from Embeddings to Applications\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_1.png)\n\n벡터 데이터베이스는 자연어 처리, 이미지 인식, 추천 시스템 및 시맨틱 검색과 같은 다양한 분야에서 중요한 역할을 하며, 대규모 언어 모델의 점점 증가하는 채택으로 더 많은 중요성을 얻고 있습니다.\n\n이러한 데이터베이스는 LLM(Large Language Models)에 실시간 독점 데이터에 액세스할 수 있게 함으로써 검색 증강 생성(Retreival Augmented Generation, RAG) 애플리케이션의 개발을 가능케 하는 데에 매우 가치가 있습니다.\n\n핵심적으로, 벡터 데이터베이스는 임베딩의 사용에 의존하여 데이터의 의미를 포착하고 다른 벡터 쌍 사이의 유사성을 측정하며 방대한 데이터 세트를 살피면서 가장 유사한 벡터를 식별합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 과정은 벡터 데이터베이스를 애플리케이션에 적용할 때 언제 결정을 내릴지에 대한 지식을 습득하는 데 도움이 될 것입니다. 다음을 살펴볼 것입니다:\n\n- 벡터 데이터베이스와 LLM을 사용하여 데이터에 대해 더 깊은 통찰을 얻는 방법.\n- 임베딩을 형성하고 유사한 임베딩을 찾는 데 몇 가지 검색 기술을 사용하는 빌드 랩의 방법.\n- 방대한 데이터 세트를 빠르게 검색하기 위한 알고리즘 탐색 및 RAG에서 다국어 검색까지 다양한 애플리케이션 구축.\n\n## 2. 벡터 데이터베이스로 애플리케이션 빌딩\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n벡터 데이터베이스는 데이터의 의미를 포착하기 위해 임베딩을 사용하며, 서로 다른 벡터 쌍 간의 유사성을 측정하고 가장 유사한 벡터를 식별하기 위해 대규모 데이터 세트를 탐색합니다.\n\n대형 언어 모델의 맥락에서 벡터 데이터베이스의 주요 용도는 검색이 강화된 생성 (RAG)이며, 여기서 텍스트 임베딩이 저장되고 특정 쿼리에 대해 검색됩니다.\n\n그러나 벡터 데이터베이스의 다양성은 RAG를 넘어 확장되어 최소한의 코딩으로 빠르게 다양한 응용 프로그램을 구축할 수 있게 합니다.\n\n이 강좌에서는 벡터 데이터베이스를 사용하여 육 가지 응용 프로그램을 구현하는 방법을 탐험하게 됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 시멘틱 검색: 사용자 Q/A 데이터 세트에서 이해 측면에 중점을 둔 콘텐츠의 의미를 가리키며, 단어 일치 이상의 검색 도구를 만듭니다.\n- RAG: 모델이 훈련되지 않은 소스에서 내용을 통합하여 LLM 응용 프로그램을 향상시킵니다. Wikipedia 데이터 세트를 사용하여 질문에 대답합니다.\n- 추천 시스템: 시멘틱 검색과 RAG를 결합하여 주제를 추천하고 뉴스 기사 데이터 세트로 시연하는 시스템을 개발합니다.\n- 혼합 검색: 이미지와 설명 텍스트를 모두 사용하여 항목을 찾는 응용 프로그램을 작성하며, 이를 위해 전자 상거래 데이터 세트를 사용합니다.\n- 얼굴 유사성: 공인 인물 데이터베이스를 사용하여 얼굴 특징을 비교하는 앱을 만듭니다.\n- 이상 감지: 네트워크 통신 로그에서 비정상적인 패턴을 식별하는 이상 감지 앱을 만드는 방법을 배웁니다.\n\n이 과정을 마치면 새로운 아이디어로 어떤 벡터 데이터베이스 애플리케이션을 개발할 수 있을 것입니다.\n\n# 3. 최고의 5가지 벡터 데이터베이스 블로그\n\n![image](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 블로그는 Moez Ali에 의해 작성된 것으로, 최고의 벡터 데이터베이스에 대한 포괄적인 가이드입니다. 고차원 데이터 저장, 비구조적 정보 해독, 그리고 AI 응용 프로그램을 위한 벡터 임베딩을 활용하는 방법을 마스터하는 데 도움이 될 것입니다.\n\n이 블로그는 다음을 다룹니다:\n\n- 벡터 데이터베이스란 무엇인가?\n- 벡터 데이터베이스는 어떻게 작동하는가?\n- 벡터 데이터베이스의 예시\n- 우수한 벡터 데이터베이스의 특징\n- 2023년 최고의 5개 벡터 데이터베이스\n- AI의 부상과 벡터 데이터베이스의 영향\n\n# 4. LangChain — 텍스트 분할기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![LangChain](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_4.png)\n\nLangChain — 텍스트 분리기는 LangChain에서 구현된 다양한 텍스트 분리기 목록입니다. 문서를 로드한 후에는 종종 애플리케이션에 더 적합하도록 변환하고 싶을 것입니다.\n\n가장 간단한 예는 긴 문서를 모델 컨텍스트 창에 맞게 더 작은 조각으로 나누고 싶을 수 있다는 것입니다. LangChain에는 문서를 쉽게 분할, 결합, 필터링 및 기타 조작할 수 있게 해주는 내장 문서 변환기가 여러 개 있습니다.\n\n텍스트의 긴 부분을 처리하려면 해당 텍스트를 조각으로 나누는 것이 필요합니다. 이것이 얼마나 단순한 것처럼 들리더라도 여기에는 많은 잠재적인 복잡성이 있습니다. 이상적으로는 의미론적으로 관련된 텍스트 조각을 함께 유지하고 싶을 것입니다. \"의미론적으로 관련된\"이란 무슨 의미인지는 텍스트 유형에 따라 달라질 수 있습니다. 이 노트북에서는 이를 수행하는 여러 방법을 소개합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 5. Sentence Transformers 라이브러리\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_5.png)\n\nSentence Transformers 라이브러리는 최신의 문장, 텍스트 및 이미지 임베딩을 위한 인기 있는 Python 프레임워크입니다. 초기 작업은 저희 논문인 'Sentence-BERT: Siamese BERT-Networks를 사용한 문장 임베딩'에서 설명되었습니다.\n\n이 프레임워크를 사용하여 100개 이상의 언어에 대한 문장/텍스트 임베딩을 계산할 수 있습니다. 이러한 임베딩은 코사인 유사도와 같이 사용하여 의미가 유사한 문장을 찾는 데 사용할 수 있습니다. 의미론적 텍스트 유사성, 의미론적 검색 또는 패러프레이즈 마이닝에 유용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 프레임워크는 PyTorch와 Transformers를 기반으로 하며, 다양한 작업에 튜닝된 미리 학습된 모델의 큰 컬렉션을 제공합니다. 또한, 모델을 쉽게 세밀 조정할 수 있습니다.\n\n## 6. MTEB 리더보드\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_6.png)\n\nMTEB 리더보드는 임베딩 모델을위한 리더보드이며, 다양한 임베딩 모델을 비교하여 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 만약 이 글을 좋아하시고 저를 지원하고 싶으시면 다음을 확인해주세요:\n\n- 👏 이야기에 박수를 보내주세요 (50번 박수) - 그러면 이 기사를 주목할 수 있습니다\n- To Data \u0026 Beyond 뉴스레터를 구독해주세요\n- 제 Medium 페이지를 팔로우해주세요\n- 📰 제 Medium 프로필에서 더 많은 콘텐츠를 확인해주세요\n- 🔔 저를 팔로우해주세요: LinkedIn | Youtube | GitHub | Twitter\n\n## To Data \u0026 Beyond 뉴스레터를 구독하여 제 글을 미리 보고 전체로 읽어보세요:\n\n## 데이터 과학과 AI 분야에서 새로운 경력을 시작하고 방법을 모르는가요? 데이터 과학 멘토링 세션과 장기적인 경력 멘토링을 제공하고 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 멘토링 세션: [링크](https://lnkd.in/dXeg3KPW)\n- 장기 멘토링: [링크](https://lnkd.in/dtdUYBrM)\n\n![이미지](/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_7.png)\n","ogImage":{"url":"/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png"},"coverImage":"/assets/img/2024-05-23-6ResourcestoMasterVectorDatabasesBuildingaVectorStorage_0.png","tag":["Tech"],"readingTime":6},{"title":"마이크로소프트 Phi2의 Text2SQL 작업을 위한 지도 학습 세부 조정 SFT 파트 1","description":"","date":"2024-05-23 18:24","slug":"2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1","content":"\n\n![image](/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png)\n\n이 글에서는 우리만의 모델, LLM (Large Language Model)을 세밀하게 조정하여 자연어 텍스트에서 유효한 SQL 쿼리를 작성할 수 있는 기능을 추가할 것입니다.\n\n한 단계씩 살펴보겠습니다.\n\n- 소개\n  - 사전 훈련된 모델 선택\n  - 입력/출력 형식\n- 데이터셋 준비\n  - 정리 작업 진행\n  - 하위 집합 생성\n- (계속되는 내용은 Part 2에서)\n- 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 소개\n\n요즘, 트랜스포머 기반 모델이 자연어 처리 분야에서 많은 문제를 해결하고 있어요. 잘 알려진 예시로는 GPT, LLAMA, Mistral 등이 있습니다. 이 모델들은 특정 자연어 처리 문제를 해결하기 위해 입력으로 프롬프트를 사용합니다.\n\n![이미지](/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_1.png)\n\n## 사전 학습된 모델 선택\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n미리 훈련된 모델을 사용하여 시작해 보세요. 미리 훈련된 모델의 정의는 무엇일까요?\n\n미리 훈련된 모델은 수천만 개 또는 수십억 개의 토큰을 사용하여 \"다음 단어 예측\" 목적으로 훈련된 모델입니다. 이 훈련 과정동안, 문장 내 단어의 구조와 의미를 학습합니다.\n\n이 작업에서는 미러소프트/파이2 미리 훈련된 모델을 사용할 것입니다. 이 모델은 1.4 조 토큰으로 훈련되었으며, 27 억 개의 파라미터를 갖추고 있습니다. 이 모델은 SLM(작은 언어 모델)로 간주될 수 있습니다.\n\n이 유형의 미리 훈련된 모델은 앞선 맥락을 기반으로 새로운 토큰을 생성할 수 있는 능력을 갖고 있습니다. 이 모델은 독립적인 질문, QA, 채팅 형식, 그리고 코드 생성과 같은 다양한 용도에 사용될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 모델을 QA 스타일로 텍스트2SQL 생성을 위해 미세 조정할 예정입니다.\n\n## 입력/출력 형식\n\n| | |\n|------------------|----------------------------------|\n| **input**        | User question                    |\n| **output**       | SQL query                        |\n\n질문은 다음과 같습니다: LLM은 사용자 질문에서 어떻게 SQL을 생성할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인간이라도 할 수 없어요. 적어도 테이블 구조에 대한 정보와 샘플 데이터가 필요한데, 그럼에도 불구하고 질문에 대한 SQL 쿼리를 해결할 수 있을 거에요.\n\nLLM과 유사하게, 어떤 맥락을 제공해야 해요. 따라서 우리의 입력은 (맥락) + (사용자 질문)이고, LLM이 우리를 위해 SQL을 생성할 거에요.\n\n그러니 데이터셋 수집 및 준비를 시작해 보고, 그 다음으로 세밀하게 조정해 봐요.\n\n# 데이터셋 준비\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n잠시 찾아보니 huggingface의 “gretelai/synthetic_text_to_sql” 데이터셋을 찾았어요. 제가 찾고 있던 작업에 가장 적합한 것 같아요. 데이터셋에 대해 더 많은 정보를 얻으려면 링크를 클릭해주세요.\n\n```python\nfrom datasets import Dataset, load_dataset\n\n# 데이터셋 불러오고 원치 않는 열 제거하기\ndataset = load_dataset(\"gretelai/synthetic_text_to_sql\") \\\n    .remove_columns(['domain_description', 'sql_complexity_description',\n                     'sql_task_type_description', 'sql_explanation', 'sql_task_type'])\n\ndataset\n```\n\n```python\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 100000\n    })\n    test: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 5851\n    })\n})\n```\n\n```python\ndataset['train'][0]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터셋이 무엇인지 감을 잡기 위해 하나의 샘플을 살펴봅시다. 여기서 우리는 \"sql_context,\" \"sql_prompt,\" 그리고 \"sql\" 필드를 사용할 것입니다.\n\n- sql_context: 테이블 생성 및 삽입 문장\n- sql_prompt: 사용자 쿼리\n- sql: 대상 쿼리\n\n(sql_context + sql_prompt)가 입력이 되고, (sql)이 대상 생성이 됩니다.\n\n```js\n{'id': 5097,\n 'domain': 'forestry',\n 'sql_complexity': 'single join',\n 'sql_prompt': '각 영업사원이 판매한 총 목재 양을 영업사원별로 정렬하여 나타내시오.',\n 'sql_context': \"CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\",\n 'sql': 'SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;'}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 정리를 해봅시다\n\n이 데이터셋은 합성 데이터입니다. 유효하지 않은 문맥이나 SQL 쿼리를 가질 수 있습니다. 이러한 레코드를 찾아 제거해봅시다. 쓰레기를 넣으면 쓰레기가 나온다는 말이죠.\n\n다음 조건에 따라 유효한 데이터를 확인할 것입니다:\n\n- SQL 문맥과 SQL 쿼리는 SQL Lite 데이터베이스에 유효해야 합니다.\n- 테이블은 샘플 레코드를 가져야 합니다.\n- SQL 쿼리를 실행한 후에 결과를 얻을 수 있어야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nimport sqlite3\n\ndef check_all_tables_have_values(row, debug=False):\n\n    # 테이블에 레코드가 있어야 함\n    if row['sql_context'].find('INSERT INTO') == -1:\n        return False\n\n    try:\n        db = sqlite3.connect(\":memory:\")\n        cur = db.cursor()\n        cur.executescript(row['sql_context'])\n        res = cur.execute(row['sql']).fetchall()\n        if debug: print(res)\n        # print(res, len(res))\n        return len(res) \u003e 0\n    except:\n        # print(\"Error while run query\")\n        return False\n\ndataset = dataset.filter(lambda x : check_all_tables_have_values(x))\ndataset\r\n```\n\n```js\r\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 53478\n    })\n    test: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 3133\n    })\n})\r\n```\n\n보시다시피 데이터의 약 46%가 제거되었습니다. 이것은 SQL Lite와 호환되지 않거나 데이터가 없을 수 있습니다.\n\n## 하위 집합 만들기```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼,이 초기 실험을 위한 데이터셋이 훨씬 큽니다. 이를 위해 그 중 일부를 만들어 보겠습니다.\n\n다음과 같이 14개 도메인과 3가지 SQL 복잡성 수준으로 데이터셋을 만들 것입니다:\n\n```js\nSELECTED_SQL_COMPLEXITY = ['basic SQL', 'aggregation','single join']\n\nSELECTED_DOMAINS = [\n    \"technology\", \"sports\", \"logistics\", \"space\", \"energy\",\n    \"finance\", \"agriculture\", \"justice\", \"retail\", \"media\",\n    \"education\", \"healthcare\", \"fashion\", \"music\"\n]\n\ndef filter_by_sql_task_type_and_domains(row):\n    return row['sql_complexity'] in SELECTED_SQL_COMPLEXITY \\\n         and row['domain'] in SELECTED_DOMAINS\n\ndataset = dataset.filter(lambda x : filter_by_sql_task_type_and_domains(x))\ndataset\n```\n\n```js\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 6713\n    })\n    test: Dataset({\n        features: ['id', 'domain', 'sql_complexity', 'sql_prompt', 'sql_context', 'sql'],\n        num_rows: 408\n    })\n})\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_3.png\" /\u003e\n\n여기에는 14개의 도메인 데이터셋이 있으며, 각 도메인은 훈련 데이터에 적어도 300개의 샘플이 있습니다. SQL 복잡성은 \"기본 SQL\"의 50%, \"단일 조인\"의 20%, 그리고 \"집계\"의 30%로 분포됩니다.\n\n# (계속, 파트 2로 이어집니다)\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 문서에서는 SLM이 무엇인지 알아보고 fine-tuning을 통해 Text2SQL 작업을 어떻게 해결할 것인지에 대한 아이디어를 얻게 됩니다.\n\n데이터셋에 대해 작업을 진행했으며, 다음 (제2부) 글에서 실제 fine-tuning 프로세스를 수행할 것입니다.","ogImage":{"url":"/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png"},"coverImage":"/assets/img/2024-05-23-SupervisedfinetuningSFTofMicrosoftPhi2forText2SQLTaskPart1_0.png","tag":["Tech"],"readingTime":7},{"title":"토큰화 - 완벽한 가이드","description":"","date":"2024-05-23 18:17","slug":"2024-05-23-TokenizationACompleteGuide","content":"\n## 바이트 페어 인코딩, 워드피스 등과 같은 것들과 함께 Python 코드!\n\n“LLMs from Scratch” 시리즈 중 제1부 — 대형 언어 모델을 이해하고 구축하는 완벽한 안내서입니다. 이 모델이 어떻게 작동하는지 더 자세히 알아보고 싶다면 다음을 읽어보는 것을 권장합니다:\n\n- 프롤로그: 대형 언어 모델의 간단한 역사\n- 파트 1: 토크나이제이션 — 완벽한 안내서\n- 파트 2: Python에서 워드투벡으로부터 스크래치로 단어 임베딩\n- 파트 3: 코드로 설명하는 셀프 어텐션\n- 파트 4: 코드로 이해하는 BERT의 완벽한 안내서\n\n![이미지](/assets/img/2024-05-23-TokenizationACompleteGuide_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이 콘텐츠가 도움이 되었다면, 아래 방법으로 저를 지원해주십시오:\n\n- 기사에 Clap(박수)을 보내세요\n- 저를 Medium이나 LinkedIn에서 팔로우하여 향후 게시물에 대한 업데이트를 받으세요\n\n## 서두\n\n대형 언어 모델 (LLM)은 2022년 11월 OpenAI의 ChatGPT가 출시된 이후 매우 인기를 얻었습니다. 그 이후로 이러한 언어 모델의 사용이 급증했으며, HuggingFace의 Transformer 라이브러리와 PyTorch와 같은 라이브러리의 도움을 받았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 모든 이들 준비하고 있는 완제품 도구들로 인해, 기본 수준에서 무슨 일이 일어나고 있는지 추상화하는 것이 쉽습니다. 그 결과로 많은 온라인 튜토리얼들이 당신이 자체 모델을 생성할 때 '무엇'을 알려주고 '왜'는 알려주지 않는 경우가 많습니다. 이 기사 시리즈는 이를 해결하고자 합니다. '처음부터 LLMs 만들기'는 대형 언어 모델을 구성하는 구성 요소를 분해하고, 내부 작동 방식을 설명합니다. 그의 목표는 다음과 같습니다:\n\n- 수학의 직관적 이해를 포함한, LLMs가 어떻게 작동하는지의 기본적인 이해 구축\n- 각 구성 요소가 어떻게 작동하는지를 보여주며, Python에서 처음부터 구현 방법을 보여줌\n- 불필요한 추상화를 줄이기 위해 가급적이면 최소한의 라이브러리 사용\n\n말이 다 되었으니, 시작해보겠습니다.\n\n# 토크나이저란 무엇인가?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자연어 처리 문제는 텍스트 데이터를 사용하는데, 기계가 즉시 이해하기 어렵습니다. 컴퓨터가 언어를 처리하려면 먼저 텍스트를 숫자 형식으로 변환해야 합니다. 이 프로세스는 토크나이저라는 모델에 의해 주로 두 단계로 수행됩니다.\n\n단계 1: 입력 텍스트를 토큰으로 분할\n\n토크나이저는 먼저 텍스트를 가져와 단어, 단어 부분 또는 개별 문자가 될 수 있는 작은 조각으로 나눕니다. 이러한 작은 텍스트 조각을 토큰이라고 합니다. 스탠포드 NLP 그룹은 토큰을 더 엄격하게 정의합니다.\n\n단계 2: 각 토큰에 식별자 할당\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토크나이저가 텍스트를 토큰으로 분리한 후, 각 토큰에 토큰 ID라고 불리는 정수 번호를 할당할 수 있습니다. 예를 들어, \"cat\"이라는 단어가 15라는 값으로 할당될 수 있고, 따라서 입력 텍스트의 모든 cat 토큰은 숫자 15로 표시됩니다. 텍스트 토큰을 숫자 표현으로 교체하는 과정을 인코딩이라고 합니다. 비슷하게, 인코딩된 토큰을 다시 텍스트로 변환하는 과정을 디코딩이라고 합니다.\n\n단일 숫자를 사용하여 토큰을 표현하는 것에는 단점이 있다는 것을 알 수 있습니다. 그래서 이러한 코드들은 단어 임베딩을 생성하기 위해 추가로 처리되며, 이것은 이 시리즈의 다음 기사의 주제입니다.\n\n# 토큰화 방법\n\n텍스트를 토큰으로 나누는 세 가지 주요 방법이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 단어 기반\n- 문자 기반\n- 부분어 기반\n\n## 단어 기반 토크나이저:\n\n단어 기반 토크나이제이션은 세 가지 토큰화 방법 중 가장 간단한 방법입니다. 여기서 토크나이저는 문장을 단어로 분할하는데 각 공백 문자를 기준으로 나눕니다(때로는 '화이트스페이스 기반 토큰화'라고도 함) 또는 유사한 규칙 세트(구두점 기반 토큰화, 트리뱅크 토큰화 등)에 따라 분할할 수도 있습니다 [12].\n\n예를 들어, 다음과 같은 문장:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n고양이들은 멋지지만, 개들이 더 좋아요!\n\n띄어쓰기 문자로 분할하면:\n\n[`Cats`, `are`, `great,`, `but`, `dogs`, `are`, `better!`]\n\n또는 구두점과 공백을 기준으로 분할하면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[`Cats`, `are`, `great`, `,`, `but`, `dogs`, `are`, `better`, `!`]\n\n위 간단한 예제를 통해 분할을 결정하는 데 사용하는 규칙이 중요하다는 것을 분명히 이해할 수 있습니다. 공백 접근 방식은 잠재적으로 희귀한 토큰 `better!`를 제공하며, 두 번째 분할은 덜 희귀한 토큰 `better`와 `!`을 생성합니다. 문장부호를 완전히 제거하지 않도록 주의해야 합니다. 문장부호에는 매우 구체적인 의미가 있을 수 있기 때문입니다. 그 중 하나는 ‘작은따옴표(apostrophe)’입니다. 작은따옴표는 단수와 소유 형태를 구별할 수 있습니다. 예를 들어 “book's”는 책의 속성을 가리키며 “the book's spine is damaged”와 같이 사용되고, “books”는 여러 권의 책을 가리킵니다.\n\n토큰을 생성한 후, 각 토큰에 번호를 할당할 수 있습니다. 토큰 생성기가 이미 본 토큰을 생성할 때 다음에 볼 토큰은 그 단어에 지정된 번호를 간단히 할당할 수 있습니다. 예를 들어 위 문장에서 `great`가 1이라는 값으로 할당된 경우, 이후의 `great` 단어는 모두 1의 값으로 할당됩니다.\n\n단어 기반 토크나이저의 장단점:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n워드 기반 방법으로 생성된 토큰들은 각각 의미론적 및 문맥 정보를 포함하고 있어 많은 정보를 담고 있습니다. 그러나 이 방법의 가장 큰 단점 중 하나는 매우 유사한 단어가 완전히 다른 토큰으로 처리된다는 것입니다. 예를 들어, cat과 cats 간의 연결은 존재하지 않으며, 이들은 별개의 단어로 처리됩니다. 이는 많은 단어를 포함하는 대규모 응용 프로그램에서 문제가 될 수 있습니다. 모델 어휘의 가능한 토큰 수가 매우 커질 수 있기 때문입니다. 영어는 약 17만 단어가 있으며, 각 단어에 대한 복수형이나 과거형과 같은 다양한 문법 형태를 포함하면 폭발적인 어휘 문제가 발생할 수 있습니다. TransformerXL 토크나이저가 사용하는 공백 기반 분할은 어휘 크기가 25만 개를 초과하도록 이끌었습니다.\n\n이 문제를 해결하는 한 가지 방법은 모델이 학습할 수 있는 토큰 수에 하드 리미트를 부여하는 것입니다(예: 1만). 이는 가장 빈도가 높은 1만개의 토큰을 벗어나는 모든 단어를 어휘 외로 처리하고, 숫자 값 대신 UNKNOWN 토큰 값을 할당하는 것입니다(UNK로 축약되기도 합니다). 이는 많은 알려지지 않은 단어가 있는 경우에 성능에 영향을 줄 수 있지만, 데이터에 대부분의 일반적인 단어가 포함된 경우에는 적합한 타협안이 될 수 있습니다.\n\n장점 요약:\n\n- 간단한 방법\n- 각 토큰에 저장된 높은 정보량\n- 주로 일반적인 단어를 포함하는 데이터셋과 잘 작동하는 어휘 크기 제한 가능\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약:\n\n- 비슷한 단어에 대해 별도의 토큰이 생성됩니다 (예: cat과 cats)\n- 매우 큰 어휘를 만들 수 있습니다.\n- 어휘를 제한하면 드문 단어가 많은 데이터셋에서 성능이 크게 저하될 수 있습니다.\n\n## 문자 기반 토크나이저:\n\n문자 기반 토크나이제이션은 글자, 숫자 및 구두점과 같은 특수 문자를 포함하여 텍스트를 각 문자 단위로 분할합니다. 이는 영어 언어를 단어 기반 접근법에서 필요한 17만 개 이상의 어휘 대신 약 256개의 토큰으로 표현할 수 있도록 어휘 크기를 크게 줄입니다 [5]. 중국어 및 일본어와 같은 동아시아 언어도 자신들의 문자 시스템에서 수천 개의 고유 문자를 포함하지만 어휘 크기가 크게 축소될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문자 기반 토크나이저에서는 다음과 같은 문장을 아래와 같이 변환할 수 있습니다:\n\n[`C`, `a`, `t`, `s`, ` `, `a`, `r`, `e`, ` `, `g`, `r`, `e`, `a`, `t`, `,`, ` `, `b`, `u`, `t`, ` `, `d`, `o`, `g`, `s`, ` `, `a`, `r`, `e`, ` `, `b`, `e`, `t`, `t`, `e`, `r`, `!`]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n캐릭터 기반 토크나이저의 장단점:\n\n단어 기반 방법과 비교할 때, 캐릭터 기반 접근 방식은 훨씬 작은 어휘 크기를 가지며, 많은 수의 OOV(Out-Of-Vocabulary) 토큰을 생성하지 않는다. 심지어 맞춰 쓰인 단어들이 아닌 오타가 있는 단어들조차도 토큰화할 수 있다는 장점이 있습니다(다만 해당 단어의 올바른 형태와는 다르게 토큰화됩니다). 또한, 빈도 기반 어휘 제한 때문에 단어가 즉시 제거되는 것을 방지합니다.\n\n하지만 이 접근 방식에는 몇 가지 단점도 있습니다. 먼저, 캐릭터 기반 방법으로 생성된 단일 토큰에 저장된 정보량은 매우 적습니다. 이는 단어 기반 방식의 토큰과 달리 의미론적이거나 문맥적인 의미가 캡처되지 않기 때문입니다(특히, 알파벳 기반 언어인 영어와 같은 언어에서). 마지막으로 이 방식은 입력 텍스트를 인코딩하기 위해 많은 수의 숫자가 필요하기 때문에, 언어 모델에 투입할 수 있는 토큰화된 입력의 크기에 제약이 생깁니다.\n\n장점 요약:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 어휘 크기가 작음\n- 철자가 틀린 단어를 제거하지 않음\n\n단점 요약:\n\n- 각 토큰에 저장되는 정보량이 적으며, 알파벳 기반의 글쓰기 체계에서는 문맥적 또는 의미적 의미가 거의 없음\n- 언어 모델에 입력되는 크기가 제한되며, 텍스트를 토큰화하는 데 필요한 숫자가 훨씬 더 많아짐 (단어 기반 접근 방식과 비교했을 때)\n\n## Subword-Based Tokenizers:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n서브워드 기반 토큰화는 단어 기반 및 문자 기반 방법의 이점을 모두 활용하면서 그들의 단점을 최소화하려는 목표를 가지고 있어요. 서브워드 기반 방법은 단어 내에서 텍스트를 분할하여 의미 있는 토큰을 생성하려는 시도를 통해 중간 지점을 취하고 있어요, 심지어 그것들이 완전한 단어가 아니더라도요. 예를 들어, 토큰 ing와 ed는 문법적인 의미를 가지고 있지만 그 자체로 완전한 단어는 아니에요.\n\n이 방법은 단어 기반 방법보다 작은 어휘 크기를 갖게 하지만, 문자 기반 방법보다 큰 어휘 크기를 갖게 해요. 또한 매 토큰 내에 저장된 정보 양도 두 가지 이전 방법으로 생성된 토큰 사이에 위치하게 되요. 서브워드 접근 방식은 다음 두 지침을 사용해요:\n\n- 자주 사용되는 단어를 서브워드로 분리하지 말고 전체 토큰으로 저장해야 함\n- 드물게 사용되는 단어를 서브워드로 분리해야 함\n\n드물게 사용되는 단어만 분리함으로써 활용어나 복수형 등이 그 구성 요소로 분해되는 기회를 주면서 토큰 사이의 관계를 보존하게 돼요. 예를 들어 cat은 데이터셋에서 매우 흔한 단어지만 cats는 덜 흔할 수 있어요. 이 경우 cats는 cat과 s로 분리되어, cat은 이제 다른 모든 cat 토큰과 동일한 값을 갖게 되고, s는 다른 값을 갖게 됩니다. 이는 복수성의 의미를 인코딩할 수 있다는 것이에요. 또 다른 예시로는 단어 토큰화인데요, 이는 루트 단어 토큰과 접미사 ization으로 분할될 수 있어요. 이 방법은 구문 및 의미 유사성을 보존할 수 있습니다. 이러한 이유로, 서브워드 기반 토큰화기는 현재 많은 NLP 모델에서 널리 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 정규화 및 사전 토크나이제이션\n\n토크나이제이션 과정에서는 사전 처리 및 사후 처리 단계가 필요한데, 이 모든 것이 토크나이제이션 파이프라인을 이룹니다. 이것은 로우 텍스트를 토큰으로 변환하는 데 필요한 일련의 조치들을 설명합니다. 이 파이프라인의 단계는 다음과 같습니다:\n\n- 정규화\n- 사전 토큰화\n- 모델\n- 후 처리\n\n여기서 토큰화 방법(서브워드 기반, 문자 기반 등)은 모델 단계에서 이루어집니다 [7]. 이 섹션에서는 서브워드 기반 토큰화 방식을 사용하는 토크나이저에 대해 각 단계를 다룰 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n중요한 알림: 토큰화 파이프라인의 모든 단계는 Hugging Face의 토크나이저 및 트랜스포머 라이브러리와 같은 라이브러리에서 토크나이저를 사용할 때 자동으로 사용자 대신 처리됩니다. 전체 파이프라인은 Tokenizer라는 단일 객체에 의해 수행됩니다. 이 섹션은 대부분의 사용자가 NLP 작업을 수행할 때 직접 처리할 필요가 없는 코드 내부 작업에 대해 다룹니다. 나중에는 토크나이저 라이브러리의 기본 토크나이저 클래스를 사용자 정의하는 단계도 제시되어 필요한 경우 특정 작업용으로 토크나이저를 목적에 맞게 만들 수 있습니다.\n\n## 정규화 방법\n\n정규화는 텍스트를 토큰으로 분할하기 전에 정리하는 과정입니다. 이 과정에는 각 문자를 소문자로 변환하거나 문자에서 강세 기호를 제거하는 단계(예: é가 e가 됨), 불필요한 공백을 제거하는 것 등이 포함됩니다. 예를 들어, 문자열 ThÍs is áN ExaMPlé sÉnteNCE는 정규화 후에는 this is an example sentence가 됩니다. 서로 다른 정규화기는 서로 다른 단계를 수행하며, 사용 사례에 따라 유용할 수 있습니다. 예를 들어, 일부 상황에서는 대소문자나 강세 기호를 유지해야 할 수도 있습니다. 선택한 정규화기에 따라이 단계에서 다양한 효과를 얻을 수 있습니다.\n\nHugging Face의 tokenizers.normalizers 패키지에는 대규모 모델의 일부로서 다양한 토큰화기에서 사용되는 여러 기본 정규화기가 포함되어 있습니다. 아래는 NFC 유니코드, 소문자 및 BERT 정규화기입니다. 이들은 예제 문장에 다음과 같은 효과를 보여줍니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- NFC: 대문자를 변환하지 않거나 악센트를 제거하지 않습니다.\n- Lower: 대문자를 변환하지만 악센트를 제거하지 않습니다.\n- BERT: 대문자를 변환하고 악센트를 제거합니다.\n\n```js\nfrom tokenizers.normalizers import NFC, Lowercase, BertNormalizer\n\n# 정규화할 텍스트\ntext = 'ThÍs is  áN ExaMPlé     sÉnteNCE'\n\n# 정규화 객체 인스턴스화\nNFCNorm = NFC()\nLowercaseNorm = Lowercase()\nBertNorm = BertNormalizer()\n\n# 텍스트 정규화\nprint(f'NFC:   {NFCNorm.normalize_str(text)}')\nprint(f'Lower: {LowercaseNorm.normalize_str(text)}')\nprint(f'BERT:  {BertNorm.normalize_str(text)}')\n```\n\n```js\nNFC:   ThÍs is  áN ExaMPlé     sÉnteNCE\nLower: thís is  án examplé     séntence\nBERT:  this is  an example     sentence\n```\n\n위의 정규화기들은 Hugging Face transformers 라이브러리에서 가져올 수 있는 토크나이저 모델에서 사용됩니다. 아래 코드 셀은 Tokenizer.backend_tokenizer.normalizer를 통해 점 표기법(dot notation)을 사용하여 정규화기에 액세스하는 방법을 보여줍니다. 서로 다른 정규화 방법을 강조하기 위해 일부 비교를 보여줍니다. 이 예시들에서는 FNet 정규화기만 불필요한 공백을 제거합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom transformers import FNetTokenizerFast, CamembertTokenizerFast, \\\n                         BertTokenizerFast\n\n# Text to normalize\ntext = 'ThÍs is  áN ExaMPlé     sÉnteNCE'\n\n# Instantiate tokenizers\nFNetTokenizer = FNetTokenizerFast.from_pretrained('google/fnet-base')\nCamembertTokenizer = CamembertTokenizerFast.from_pretrained('camembert-base')\nBertTokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n\n# Normalize the text\nprint(f'FNet Output:      \\\n    {FNetTokenizer.backend_tokenizer.normalizer.normalize_str(text)}')\n\nprint(f'CamemBERT Output: \\\n    {CamembertTokenizer.backend_tokenizer.normalizer.normalize_str(text)}')\n\nprint(f'BERT Output:      \\\n    {BertTokenizer.backend_tokenizer.normalizer.normalize_str(text)}')\n```\n\n```js\nFNet Output:      ThÍs is áN ExaMPlé sÉnteNCE\nCamemBERT Output: ThÍs is  áN ExaMPlé     sÉnteNCE\nBERT Output:      this is  an example     sentence\n```\n\n## Pre-Tokenization Methods\n\nThe pre-tokenization step is the first splitting of the raw text in the tokenization pipeline. The split is performed to give an upper bound to what the final tokens could be at the end of the pipeline. That is, a sentence can be split into words in the pre-tokenization step, then in the model step some of these words may be split further according to the tokenization method (e.g. subword-based). So the pre-tokenized text represents the largest possible tokens that could still remain after tokenization.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n정규화와 마찬가지로이 단계를 수행하는 여러 가지 방법이 있습니다. 예를 들어, 문장은 매 공백, 모든 공백 및 일부 구두점 또는 매 공백 및 모든 구두점을 기준으로 분할될 수 있습니다.\n\n아래 셀은 기본 Whitespacesplit 프리 토크나이저와 Hugging Face 토크나이저의 pre_tokenizers 패키지에서 약간 더 복잡한 BertPreTokenizer 간의 비교를 보여줍니다. 공백 프리 토크나이저의 출력은 구두점을 그대로 두고 이웃하는 단어에 여전히 붙어 있는 것을 보여줍니다. 예를 들어, \"includes:\"는 이 경우에는 단일 단어로 처리됩니다. 반면 BERT 프리 토크나이저는 구두점을 개별 단어로 취급합니다 [8].\n\n```js\nfrom tokenizers.pre_tokenizers import WhitespaceSplit, BertPreTokenizer\n\n# 텍스트 정규화\ntext = (\"this sentence's content includes: characters, spaces, and \" \\\n        \"punctuation.\")\n\n# 프리 토큰화된 출력을 표시하는 도우미 함수 정의\ndef print_pretokenized_str(pre_tokens):\n    for pre_token in pre_tokens:\n        print(f'\"{pre_token[0]}\", ', end='')\n\n# 프리 토크나이저 인스턴스화\nwss = WhitespaceSplit()\nbpt = BertPreTokenizer()\n\n# 텍스트를 프리 토큰화\nprint('Whitespace Pre-Tokenizer:')\nprint_pretokenized_str(wss.pre_tokenize_str(text))\n\nprint('\\n\\nBERT Pre-Tokenizer:')\nprint_pretokenized_str(bpt.pre_tokenize_str(text))\n```\n\n```js\nWhitespace Pre-Tokenizer:\n\"this\", \"sentence's\", \"content\", \"includes:\", \"characters,\", \"spaces,\",\n\"and\", \"punctuation.\",\n\nBERT Pre-Tokenizer:\n\"this\", \"sentence\", \"'\", \"s\", \"content\", \"includes\", \":\", \"characters\",\n\",\", \"spaces\", \",\", \"and\", \"punctuation\", \".\",\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n정규화 방법들과 마찬가지로 GPT-2와 ALBERT (A Lite BERT) 토크나이저와 같은 일반적인 토크나이저에서 사전 토큰화 방법을 직접 호출할 수 있습니다. 이들은 위에서 보여진 표준 BERT 사전 토큰화 방법과 약간 다른 방식을 사용합니다. 토큰을 분할할 때 공백 문자를 제거하지 않고 특수 문자로 대체합니다. 그 결과, 공백 문자를 처리할 때 무시할 수 있지만 필요할 경우 원래 문장을 검색할 수 있습니다. GPT-2 모델은 Ġ 문자를 사용하며, 이는 위에 점을 찍은 대문자 G가 특징입니다. ALBERT 모델은 밑줄 문자를 사용합니다.\n\n```python\nfrom transformers import AutoTokenizer\n\n# 사전 토큰화할 텍스트\ntext = (\"this sentence's content includes: characters, spaces, and \" \\\n        \"punctuation.\")\n\n# 사전 토큰화 객체 생성\nGPT2_PreTokenizer = AutoTokenizer.from_pretrained('gpt2').backend_tokenizer \\\n                    .pre_tokenizer\n\nAlbert_PreTokenizer = AutoTokenizer.from_pretrained('albert-base-v1') \\\n                      .backend_tokenizer.pre_tokenizer\n\n# 텍스트를 사전 토큰화\nprint('GPT-2 사전 토크나이저:')\nprint_pretokenized_str(GPT2_PreTokenizer.pre_tokenize_str(text))\nprint('\\n\\nALBERT 사전 토크나이저:')\nprint_pretokenized_str(Albert_PreTokenizer.pre_tokenize_str(text))\n```\n\n```python\nGPT-2 사전 토크나이저:\n\"this\", \"Ġsentence\", \"'s\", \"Ġcontent\", \"Ġincludes\", \":\", \"Ġcharacters\", \",\",\n\"Ġspaces\", \",\", \"Ġand\", \"Ġpunctuation\", \".\"\n\nALBERT 사전 토크나이저:\n\"▁this\", \"▁sentence's\", \"▁content\", \"▁includes:\", \"▁characters,\", \"▁spaces,\",\n\"▁and\", \"▁punctuation.\"\n```\n\n위의 예제 문장에 대한 BERT 사전 토큰화 단계 결과를 수정 없이 출력한 내용이 아래에 나와 있습니다. 반환된 객체는 원본 입력 텍스트에서 문자열의 시작 및 끝 색인을 포함하는 파이썬 리스트입니다. 문자열의 시작 색인은 포함되며, 끝 색인은 배타적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom tokenizers.pre_tokenizers import WhitespaceSplit, BertPreTokenizer\n\n# Pre-tokenizer 인스턴스 생성\ntext = (\"this sentence의 내용은: characters, spaces, 그리고 \" \\\n        \"punctuation이 포함되어 있습니다.\")\nbpt = BertPreTokenizer()\nbpt.pre_tokenize_str(text)\n```\n\n```js\n[\n  (\"this\", (0, 4)),\n  (\"sentence\", (5, 13)),\n  (\"'\", (13, 14)),\n  (\"s\", (14, 15)),\n  (\"content\", (16, 23)),\n  (\"includes\", (24, 32)),\n  (\":\", (32, 33)),\n  (\"characters\", (34, 44)),\n  (\",\", (44, 45)),\n  (\"spaces\", (46, 52)),\n  (\",\", (52, 53)),\n  (\"and\", (54, 57)),\n  (\"punctuation\", (58, 69)),\n  (\".\", (69, 70)),\n];\n```\n\n# 서브워드 토큰화 방법\n\n토큰화 파이프라인의 모델 단계는 토큰화 방법이 사용되는 곳입니다. 이전에 설명한대로 여기서 선택할 수 있는 옵션은: 단어 기반, 문자 기반, 서브워드 기반입니다. 서브워드 기반 방법이 일반적으로 선호되는데, 이 방법들은 단어 기반 및 문자 기반 접근법의 한계를 극복하기 위해 설계되었습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n트랜스포머 모델에는 하위 단어 기반 토큰화를 구현하는 데 일반적으로 사용되는 세 가지 토크나이저 방법이 있습니다. 이 방법들은 다음과 같습니다:\n\n- 바이트 페어 인코딩 (BPE)\n- 워드피스\n- 유니그램\n\n각각의 방법은 빈도가 낮은 단어를 더 작은 토큰으로 분리하기 위해 약간 다른 기술을 사용합니다. BPE 및 워드피스 알고리즘의 구현 방법도 여기에 소개되어 있어서 접근 방식 사이의 유사점과 차이점을 강조하는 데 도움이 될 것입니다.\n\n## 바이트 페어 인코딩\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n바이트 페어 인코딩 알고리즘은 GPT 및 GPT-2 모델 (OpenAI), BART (Lewis et al.) 및 기타 많은 트랜스포머 모델에서 발견되는 일반적으로 사용되는 토크나이저입니다 [9-10]. 이 알고리즘은 원래 텍스트 압축 알고리즘으로 설계되었지만, 언어 모델의 토큰화 작업에 매우 효과적으로 작동한다는 것이 밝혀졌습니다. BPE 알고리즘은 텍스트 문자열을 참조 말뭉치(토큰화 모델을 훈련하는 데 사용되는 텍스트)에서 빈번히 나타나는 부분 단어 단위로 분해합니다 [11]. BPE 모델은 다음과 같이 훈련됩니다:\n\n## 단계 1) 말뭉치 작성\n\n입력 텍스트는 정규화 및 사전 토큰화 모델에 제공되어 깨끗한 단어를 생성합니다. 단어는 BPE 모델에 제공되어 각 단어의 빈도를 결정하고, 이 빈도를 단어와 함께 목록인 말뭉치에 저장합니다.\n\n## 단계 2) 어휘 작성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n말뭉치에서 단어들은 개별 문자로 분해되어 \"어휘(vocabulary)\"라는 비어있는 목록에 추가됩니다. 알고리즘은 어떤 문자 쌍을 함께 병합할 수 있는지를 결정할 때마다 이 어휘에 계속 추가합니다.\n\n단계 3) 문자 쌍의 빈도 찾기\n\n그런 다음, 말뭉치의 각 단어에 대해 문자 쌍의 빈도가 기록됩니다. 예를 들어, 단어 \"cats\"는 문자 쌍 \"ca\", \"at\", \"ts\"를 가집니다. 이와 같은 방식으로 모든 단어가 검사되어 전역 빈도 카운터에 기여합니다. 따라서 토큰 중에서 어떤 ca가 발견되는 경우, ca 쌍에 대한 빈도 카운터가 증가합니다.\n\n단계 4) 병합 규칙 작성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 문자 쌍의 빈도가 알려진 경우, 가장 빈번한 문자 쌍이 어휘에 추가됩니다. 어휘는 이제 토큰 내의 모든 개별 문자와 가장 빈번한 문자 쌍으로 구성됩니다. 또한 모델이 사용할 수있는 병합 규칙이 제공됩니다. 예를 들어 모델이 ca가 가장 빈번한 문자 쌍이라는 것을 학습하면, 모델은 말뭉친 c와 a의 모든 인접 인스턴스를 ca로 병합해 ca를 제공합니다. 이제 이를 나머지 단계의 단일 문자 ca로 취급할 수 있습니다.\n\n단계 5) 단계 3과 4 반복\n\n그런 다음 단계 3과 4를 반복하여 더 많은 병합 규칙을 찾고 어휘에 더 많은 문자 쌍을 추가합니다. 이 프로세스는 교육 시작 시 지정된 대상 크기에 도달 할 때까지 계속됩니다.\n\nBPE 알고리즘이 교육되었으므로 (즉, 모든 병합 규칙이 찾아졌다), 모델은 모든 텍스트를 토큰화하기 위해 모든 단어를 각 문자로 분할하고, 그런 다음 병합 규칙에 따라 병합하여 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 표는 마크다운 형식으로 변경하겠습니다.\n\n아래는 BPE 알고리즘의 Python 구현입니다. 위에서 설명한 단계를 따르고 있습니다. 그 후에는 이 모델을 장난감 데이터세트에서 훈련하고 몇 가지 예제 단어에서 테스트합니다.\n\n```py\nclass TargetVocabularySizeError(Exception):\n    def __init__(self, message):\n        super().__init__(message)\n\nclass BPE:\n    '''Byte Pair Encoding tokenizer의 구현.'''\n\n    def calculate_frequency(self, words):\n        ''' 주어진 단어 목록에서 각 단어의 빈도를 계산합니다.\n\n            문자열로 저장된 단어 목록을 받아서, 각 단어의 빈도를 나타내는 정수를 값을 가진 튜플의 목록을 반환합니다.\n\n            매개변수:\n                words (list): 어떠한 순서로든 단어들(문자열)의 목록입니다.\n\n            반환값:\n                corpus (list[tuple(str, int)]): 단어 목록의 각 단어를 나타내는 첫 번째 요소가 문자열이고,\n                  두 번째 요소가 목록에서 단어의 빈도를 나타내는 정수인 튜플의 목록입니다.\n        '''\n        freq_dict = dict()\n\n        for word in words:\n            if word not in freq_dict:\n                freq_dict[word] = 1\n            else:\n                freq_dict[word] += 1\n\n        corpus = [(word, freq_dict[word]) for word in freq_dict.keys()]\n\n        return corpus\n\n    # 나머지 코드 생략\n```\n\nBPE 알고리즘은 '고양이'에 관한 몇 가지 단어가 포함된 장난감 데이터세트에서 훈련됩니다. 토크나이저의 목표는 데이터세트의 단어의 가장 유용하고 의미 있는 하위 단위를 결정하여 토큰으로 사용하는 것입니다. 검사 결과, 'cat', 'eat', 'ing' 등의 단위가 유용한 하위 단위가 될 것임이 분명합니다.\n\n21개의 대상 어휘 크기로 토크나이저를 실행하면(이는 5회 병합만 필요합니다), 위에서 언급한 모든 원하는 하위 단위를 포착하는 데 충분합니다. 더 큰 데이터세트의 경우 대상 어휘도 훨씬 더 높아지겠지만, 이는 BPE 토크나이저가 얼마나 강력한지를 보여줍니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# Training set\nwords = ['cat', 'cat', 'cat', 'cat', 'cat',\n         'cats', 'cats',\n         'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat',\n         'eating', 'eating', 'eating',\n         'running', 'running',\n         'jumping',\n         'food', 'food', 'food', 'food', 'food', 'food']\n\n# Instantiate the tokenizer\nbpe = BPE()\nbpe.train(words, 21)\n\n# Print the corpus at each stage of the process, and the merge rule used\nprint(f'INITIAL CORPUS:\\n{bpe.corpus_history[0]}\\n')\nfor rule, corpus in list(zip(bpe.merge_rules, bpe.corpus_history[1:])):\n    print(f'NEW MERGE RULE: Combine \"{rule[0]}\" and \"{rule[1]}\"')\n    print(corpus, end='\\n\\n')\n```\n\n```js\nINITIAL CORPUS:\n[(['c', 'a', 't'], 5), (['c', 'a', 't', 's'], 2), (['e', 'a', 't'], 10),\n(['e', 'a', 't', 'i', 'n', 'g'], 3), (['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"a\" and \"t\"\n[(['c', 'at'], 5), (['c', 'at', 's'], 2), (['e', 'at'], 10),\n(['e', 'at', 'i', 'n', 'g'], 3), (['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"e\" and \"at\"\n[(['c', 'at'], 5), (['c', 'at', 's'], 2), (['eat'], 10),\n(['eat', 'i', 'n', 'g'], 3), (['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"c\" and \"at\"\n[(['cat'], 5), (['cat', 's'], 2), (['eat'], 10), (['eat', 'i', 'n', 'g'], 3),\n(['r', 'u', 'n', 'n', 'i', 'n', 'g'], 2),\n(['j', 'u', 'm', 'p', 'i', 'n', 'g'], 1), (['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"i\" and \"n\"\n[(['cat'], 5), (['cat', 's'], 2), (['eat'], 10), (['eat', 'in', 'g'], 3),\n(['r', 'u', 'n', 'n', 'in', 'g'], 2), (['j', 'u', 'm', 'p', 'in', 'g'], 1),\n(['f', 'o', 'o', 'd'], 6)]\n\nNEW MERGE RULE: Combine \"in\" and \"g\"\n[(['cat'], 5), (['cat', 's'], 2), (['eat'], 10), (['eat', 'ing'], 3),\n(['r', 'u', 'n', 'n', 'ing'], 2), (['j', 'u', 'm', 'p', 'ing'], 1),\n(['f', 'o', 'o', 'd'], 6)]\n```\n\n크게 작은 데이터셋으로 BPE 알고리즘을 학습했으므로 이제 예제 단어를 토큰화하는 데 사용할 수 있습니다. 아래 셀은 토크나이저가 이전에 본 단어들 및 이전에 보지 못한 단어들을 토큰화하는 데 사용되는 것을 보여줍니다. 토크나이저는 동사 접미사 \"ing\"을 학습했으므로 이를 토큰으로 분리할 수 있습니다. 이 때문에 훈련 데이터에는 'eat'이 포함되어 있어 'eat'이 중요한 토큰임을 학습했습니다. 그러나 모델은 'run'과 'ski'라는 단어를 본 적이 없기 때문에 이를 성공적으로 토큰화하지 못합니다. 이는 토크나이저를 훈련시킬 때 다양하고 광범위한 훈련 세트의 중요성을 강조합니다.\n\n```js\nprint(bpe.tokenize(\"eating\"));\nprint(bpe.tokenize(\"running\"));\nprint(bpe.tokenize(\"skiing\"));\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n[\"먹\", \"어\", \"•\", \"ᆼ\"][(\"\", \"ᄂ\", \"ᄂ\", \"•\", \"ᆼ\")][(\"\", \"스\", \"키\", \"•\", \"ᆼ\")];\n```\n\nBPE 토크나이저는 훈련 데이터에 나타난 문자만 인식할 수 있습니다. 예를 들어, 위의 훈련 데이터에는 고양이에 대해 이야기할 때 필요한 문자만 포함되어 있어서 z가 필요하지 않았습니다. 따라서 해당 토크나이저 버전은 z 문자를 어휘에 포함시키지 않으며, 실제 데이터를 토큰화할 때 해당 문자를 알 수 없는 토큰으로 변환합니다 (실제로, 오류 처리가 없어 모델이 알 수 없는 토큰을 생성하도록 지시하는 기능도 없으므로 모델이 충돌할 것이지만, 제품화된 모델에서는 이런 일이 발생할 수 있습니다).\n\nGPT-2 및 RoBERTa에서 사용되는 BPE 토크나이저는 이 문제가 없으며 코드 내에 한 가지 속임수가 있습니다. Unicode 문자를 기반으로 훈련 데이터를 분석하는 대신, 문자의 바이트를 분석합니다. 이를 Byte-Level BPE라고 하며, 소규모 기본 어휘를 사용하여 모델이 볼 수 있는 모든 문자를 토큰화할 수 있게 합니다.\n\n## WordPiece\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWordPiece는 구글이 개발한 토큰화 방법으로, 그들의 중요한 BERT 모델 및 이로부터 파생된 모델들인 DistilBERT 및 MobileBERT에서 사용됩니다.\n\nWordPiece 알고리즘의 전체 세부 내용은 공개되지 않았기 때문에 여기서 제시하는 방법론은 Hugging Face에 의해 제시된 해석을 기반으로 합니다. WordPiece 알고리즘은 BPE와 유사하지만 병합 규칙을 결정하는 데 다른 지표를 사용합니다. 가장 빈도가 높은 문자 쌍을 선택하는 대신 각 쌍에 대해 점수가 계산되고, 가장 높은 점수를 가진 쌍이 병합될 문자를 결정합니다. WordPiece는 다음과 같이 훈련됩니다.\n\n단계 1) 말뭉치 구축\n\n다시 한 번 입력 텍스트는 정규화 및 사전 토큰화 모델에 제공되어 깨끗한 단어를 생성합니다. 단어는 WordPiece 모델에 제공되어 각 단어의 빈도를 결정하고, 이 번호를 단어와 함께 \"말뭉치\"라고 불리는 리스트에 저장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단계 2) 어휘 구성\n\nBPE와 같이 코퍼스에서 단어를 개별 문자로 분해한 후, 단어들은 비어 있는 어휘 목록에 추가됩니다. 그러나 이번에는 단순히 각 개별 문자를 저장하는 대신, 두 개의 # 기호가 사용되어 문자가 단어의 시작에서 발견되었는지 또는 단어의 중간/끝에서 발견되었는지를 표시하는 마커로 사용됩니다. 예를 들어, 단어 cat은 BPE에서 [`c`, `a`, `t`]로 분할되지만 WordPiece에서는 [`c`, `##a`, `##t`]로 나타납니다. 이 시스템에서는 단어의 시작에서의 c와 단어의 중간 또는 끝에서의 ##c가 다르게 처리됩니다. 알고리즘은 매번 어떤 문자 쌍을 함께 병합할 수 있는지 결정할 때마다 이 어휘에 추가됩니다.\n\n단계 3) 인접 문자 쌍의 쌍 점수 계산\n\nBPE 모델과 달리, 이번에는 각 문자 쌍에 대해 점수가 계산됩니다. 먼저, 코퍼스에서 각 인접 문자 쌍을 식별하고, `c##a`, ##a##t 등이 계산됩니다. 그리고 빈도가 계산됩니다. 각 문자의 빈도도 결정됩니다. 이러한 값들을 알면, 다음 공식에 따라 쌍 점수를 계산할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\n![Tokenization Guide](/assets/img/2024-05-23-TokenizationACompleteGuide_1.png)\n\n이 메트릭은 함께 자주 나타나지만 개별적으로나 다른 문자와 자주 나타나지 않는 문자에 더 높은 점수를 할당합니다. 이것이 WordPiece와 BPE 사이의 주된 차이점인데, BPE는 개별 문자의 전체 빈도를 고려하지 않습니다.\n\n단계 4) 병합 규칙 생성\n\n높은 점수는 자주 함께 나타나는 문자 쌍을 나타냅니다. 즉, c##a가 높은 쌍 점수를 가지면 c와 a가 말뭉치에서 함께 자주 나타나고 개별적으로는 그리 자주 나타나지 않는 것입니다. BPE와 마찬가지로, 병합 규칙은 가장 높은 점수를 가진 문자 쌍에 의해 결정됩니다. 이번에는 빈도가 점수를 결정하는 대신 쌍 점수로 결정됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 5) 단계 3과 4를 반복합니다.\n\n그런 다음 단계 3과 4를 반복하여 더 많은 병합 규칙을 찾고 어휘에 더 많은 문자 쌍을 추가합니다. 이 프로세스는 교육의 시작 부분에서 지정된 목표 크기에 도달할 때까지 계속됩니다.\n\n아래는 이전에 작성한 BPE 모델을 상속하는 WordPiece의 구현입니다.\n\n```js\nclass WordPiece(BPE):\n\n    def add_hashes(self, word):\n        ''' 단어의 각 문자에 # 기호 추가\n\n            문자열로 된 단어를 받아서 처음을 제외한 각 문자에 # 기호를 추가합니다.\n            결과를 반환하며 각 요소가 처음 문자만 일반 문자이고 나머지는 # 기호가\n            앞에 붙은 문자인 리스트로 반환합니다.\n\n            인수:\n                word (str): # 기호를 추가할 단어\n\n            반환값:\n                hashed_word (list): # 기호를 추가한 문자의 목록\n        '''\n        hashed_word = [word[0]]\n\n        for char in word[1:]:\n            hashed_word.append(f'##{char}')\n\n        return hashed_word\n\n\n    def create_merge_rule(self, corpus):\n        ''' 병합 규칙을 만들어 self.merge_rules 목록에 추가합니다.\n\n            인수:\n                corpus (list[tuple(list, int)]): 단어 목록에서 단어의 개별 문자\n                    (또는 나중 반복에서 단어의 하위단어)를 표현하는 요소 및 단어\n                    빈도를 나타내는 정수를 두 번째 요소로 하는 튜플의 목록\n\n            반환값:\n                없음\n        '''\n        pair_frequencies = self.find_pair_frequencies(corpus)\n        char_frequencies = self.find_char_frequencies(corpus)\n        pair_scores = self.find_pair_scores(pair_frequencies, char_frequencies)\n\n        highest_scoring_pair = max(pair_scores, key=pair_scores.get)\n        self.merge_rules.append(highest_scoring_pair.split(','))\n        self.vocabulary.append(highest_scoring_pair)\n\n\n    def create_vocabulary(self, words):\n        ''' 단어 목록에서 고유 문자 목록을 생성합니다.\n\n            BPE 알고리즘과 달리 각 문자를 일반적으로 저장하는 대신 단어의 시작\n            문자 (표시되지 않음)와 단어의 중간 또는 끝에 있는 문자('##'로 표시)를\n            구분합니다. 예를 들어, 단어 'cat'은 ['c', '##a', '##t']로 분할됩니다.\n\n            인수:\n                words (list): 입력 텍스트의 단어를 포함하는 문자열의 목록\n\n            반환값:\n                vocabulary (list): 입력 단어 목록의 모든 고유 문자 목록\n        '''\n        vocabulary = set()\n        for word in words:\n            vocabulary.add(word[0])\n            for char in word[1:]:\n                vocabulary.add(f'##{char}')\n\n        # 나중에 추가할 수 있도록 목록으로 변환\n        vocabulary = list(vocabulary)\n        return vocabulary\n\n\n    def find_char_frequencies(self, corpus):\n        ''' 코퍼스에서 각 문자의 빈도수를 찾습니다.\n\n            코퍼스를 순환하고 문자의 빈도수를 계산합니다.\n            'c'와 '##c'는 서로 다른 문자임에 유의하세요.\n            'c'는 단어의 시작 문자를 나타내고, '##c'는 단어의 중간 또는 끝을\n            나타냅니다. 각 문자 쌍을 키로, 해당 빈도를 값으로 하는 사전 반환합니다.\n\n            인수:\n                corpus (list[tuple(list, int)]): 단어 목록에서 단어의 개별 문자\n                    (또는 나중 반복에서 단어의 하위단어)를 표현하는 요소 및 단어\n                    빈도를 나타내는 정수를 두 번째 요소로 하는 튜플의 목록\n\n            반환값:\n                char_frequencies (dict): 입력 코퍼스의 문자 및 해당 빈도수를\n                    키와 값으로 하는 사전\n        '''\n        char_frequencies = dict()\n\n        for word, word_freq in corpus:\n            for char in word:\n                if char in char_frequencies:\n                    char_frequencies[char] += word_freq\n                else:\n                    char_frequencies[char] = word_freq\n\n        return char_frequencies\n\n\n    def find_pair_scores(self, pair_frequencies, char_frequencies):\n        ''' 코퍼스에서 각 문자 쌍에 대한 쌍 점수를 찾습니다.\n\n            pair_frequencies 사전을 순환하고 코퍼스에서 각 인접 문자 쌍의 쌍\n            점수를 계산합니다. 점수를 사전에 저장하고 반환합니다.\n\n            인수:\n                pair_frequencies (dict): 코퍼스에서 인접 문자 쌍을 키로, 각\n                    쌍 빈도수를 값으로 하는 사전\n\n                char_frequencies (dict): 코퍼스에서 문자를 키로, 해당 빈도수를\n                    값으로 하는 사전\n\n            반환값:\n                pair_scores (dict): 입력 코퍼스의 인접 문자 쌍을 키로, 해당\n                    쌍 점수를 값으로 하는 사전\n        '''\n        pair_scores = dict()\n\n        for pair in pair_frequencies.keys():\n            char_1 = pair.split(',')[0]\n            char_2 = pair.split(',')[1]\n            denominator = (char_frequencies[char_1] * char_frequencies[char_2])\n            score = (pair_frequencies[pair]) / denominator\n            pair_scores[pair] = score\n\n        return pair_scores\n\n\n    def get_merged_chars(self, char_1, char_2):\n        ''' 가장 높은 점수의 쌍을 병합하고 self.merge 메서드에 반환합니다.\n\n            필요에 따라 # 기호를 제거하고 가장 높은 점수의 쌍을 병합한 후\n            병합된 문자를 self.merge 메서드에 반환합니다.\n\n            인수:\n                char_1 (str): 가장 높은 점수의 쌍에서 첫 번째 문자\n                char_2 (str): 가장 높은 점수의 쌍에서 두 번째 문자\n\n            반환값:\n                merged_chars (str): 병합된 문자\n        '''\n        if char_2.startswith('##'):\n            merged_chars = char_1 + char_2[2:]\n        else:\n            merged_chars = char_1 + char_2\n\n        return merged_chars\n\n\n    def initialize_corpus(self, words):\n        ''' 각 단어를 문자로 분할하고 단어 빈도수를 계산합니다.\n\n            입력 단어 목록의 각 단어를 모든 문자로 분할합니다. 각 단어에 대해\n            분할된 단어를 튜플의 첫 번째 요소로 리스트로 저장합니다.\n            단어의 빈도수는 정수로 튜플의 두 번째 요소로 저장합니다.\n            이 작업을 수행한 후 결과인 'corpus' 목록 반환합니다.\n\n            인수:\n                없음\n\n            반환값:\n                corpus (list[tuple(list, int)]): 단어 목록에서 단어의 개별 문자\n                    (또는 나중 반복에서 단어의 하위단어)를 표현하는 요소와 단어\n                    목록에서 해당 단어의 빈도수를 나타내는 정수를 표시하는\n                    두 번째 요소로 하는 튜플의 목록\n        '''\n        corpus = self.calculate_frequency(words)\n        corpus = [(self.add_hashes(word), freq) for (word, freq) in corpus]\n        return corpus\n\n    def tokenize(self, text):\n        ''' 텍스트를 토큰 목록으로 만듭니다.\n\n            인수\n```\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWordPiece 알고리즘은 BPE 알고리즘에 주어진 장난감 데이터세트와 동일한 데이터세트로 아래에서 훈련됩니다. 이번에 학습한 토큰은 매우 다른 것을 알 수 있습니다. WordPiece는 문자가 서로 더 자주 함께 나타나는 경우를 선호하며, 그래서 데이터세트에 함께만 존재하고 홀로 존재하지 않는 'm'과 'p'는 즉시 병합됩니다. 여기서 이 아이디어는 모델이 문자를 병합함으로써 무엇이 손실되는지 고려하도록 강요하는 것입니다. 즉, 이러한 문자들이 항상 함께 있는가요? 그렇다면, 전혀 하나의 단위로 명백하게 병합되어야 합니다. 또는, 코퍼스에서 문자가 매우 빈번한가요? 그렇다면, 문자는 그냥 일반적이며 데이터세트 안에서 풍부하게 나타나므로 다른 토큰 옆에 나타날 것입니다.\n\n```js\nwp = WordPiece()\nwp.train(words, 30)\n\nprint(f'INITIAL CORPUS:\\n{wp.corpus_history[0]}\\n')\nfor rule, corpus in list(zip(wp.merge_rules, wp.corpus_history[1:])):\n    print(f'NEW MERGE RULE: Combine \"{rule[0]}\" and \"{rule[1]}\"')\n    print(corpus, end='\\n\\n')\n```\n\n```js\n초기 코퍼스:\n[(['c', '##a', '##t'], 5), (['c', '##a', '##t', '##s'], 2),\n(['e', '##a', '##t'], 10), (['e', '##a', '##t', '##i', '##n', '##g'], 3),\n(['r', '##u', '##n', '##n', '##i', '##n', '##g'], 2),\n(['j', '##u', '##m', '##p', '##i', '##n', '##g'], 1),\n(['f', '##o', '##o', '##d'], 6)]\n\nNEW MERGE RULE: \"##m\"과 \"##p\" 병합\n[(['c', '##a', '##t'], 5), (['c', '##a', '##t', '##s'], 2),\n(['e', '##a', '##t'], 10), (['e', '##a', '##t', '##i', '##n', '##g'], 3),\n(['r', '##u', '##n', '##n', '##i', '##n', '##g'], 2),\n(['j', '##u', '##mp', '##i', '##n', '##g'], 1),\n(['f', '##o', '##o', '##d'], 6)]\n\n(이하 생략)\n```\n\n이제 WordPiece 알고리즘이 훈련되었으므로(즉, 모든 병합 규칙이 발견되었으므로), 모델은 모든 텍스트를 토큰화하기 위해 각 단어를 모든 문자로 분리한 다음 문자열의 처음부분에 대해 알려진 토큰을 찾을 수 있는 최대 토큰을 찾아서, 나머지 부분은 찾을 수 있는 최대 토큰을 찾는 방식으로 사용할 수 있습니다. 이 과정은 더 이상 훈련 데이터로부터 알려진 토큰과 일치하지 않을 때까지 반복되며, 따라서 문자열의 남은 부분은 최종 토큰으로 취합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n학습 데이터가 제한적이지만, 모델은 여전히 유용한 토큰을 학습했습니다. 그러나 많은 추가 학습 데이터가 필요함을 명백히 알 수 있습니다. 이 토크나이저를 유용하게 만들기 위해 더 많은 학습 데이터가 필요합니다. 예시 문자열에 대한 성능을 테스트할 수 있습니다. 예시로 'jumper' 단어로 시작해보겠습니다. 먼저 문자열은 ['jump', 'er']로 분리됩니다. 왜냐하면 jump는 단어의 시작에서 발견할 수 있는 가장 큰 토큰이기 때문입니다. 다음으로 er 문자열은 각각의 문자 e와 r로 나뉩니다.\n\n```js\nprint(wp.tokenize(\"jumper\"));\n```\n\n```js\n[\"jump\", \"e\", \"r\"];\n```\n\n## 단일 토큰화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUnigram 토크나이저는 BPE와 WordPiece와 다른 방식으로 작동합니다. 큰 어휘로 시작하여 원하는 크기에 도달할 때까지 반복적으로 줄여나갑니다.\n\nUnigram 모델은 각 단어 또는 문자의 확률을 고려하는 통계적 방법을 사용합니다. 예를 들어, \"Cats are great but dogs are better\"라는 문장은 [`Cats`, `are`, `great`, `but`, `dogs`, `are`, `better`] 또는 [`C`, `a`, `t`, `s`, `_a`, `r`, `e`, `_g`,`r`, `e`, `a`, `t`, `_b`, `u`, `t`, `_d`, `o`, `g`, `s` `_a`, `r`, `e`, `_b`, `e`, `t`, `t`, `e`, `r`]로 분할될 수 있습니다. 문장이 문자로 분할된 경우, 새로운 단어의 시작을 나타내기 위해 각 문자의 시작 부분에 밑줄이 추가됩니다.\n\n이러한 목록의 각 요소는 토큰 t로 간주될 수 있으며, t1, t2, ..., tn의 일련의 토큰이 발생할 확률은 다음과 같습니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-TokenizationACompleteGuide_2.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUnigram 모델은 다음 단계를 통해 훈련됩니다:\n\n단계 1) 코퍼스 구성\n\n언제나처럼 입력 텍스트는 정규화 및 사전 토크나이제이션 모델에 전달되어 깨끗한 단어가 생성됩니다. 그런 다음 단어들은 Unigram 모델에 전달되어 각 단어의 빈도를 결정하고, 이 숫자를 단어와 함께 코퍼스라는 목록에 저장합니다.\n\n단계 2) 어휘 구성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUnigram 모델의 어휘 크기는 매우 크게 시작되고, 원하는 크기에 도달할 때까지 반복적으로 감소합니다. 초기 어휘를 구성하려면 말뭉치에서 가능한 모든 부분 문자열을 찾습니다. 예를 들어, 말뭉치의 첫 번째 단어가 'cats'인 경우, 부분 문자열 ['c', 'a', 't', 's', 'ca', 'at', 'ts', 'cat', 'ats']이 어휘에 추가됩니다.\n\n3단계) 각 토큰의 확률 계산\n\n토큰의 확률은 말뭉치에서 토큰의 발생 횟수를 찾아 총 토큰 발생 횟수로 나누어 근사적으로 계산됩니다.\n\n![이미지](/assets/img/2024-05-23-TokenizationACompleteGuide_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4단계) 단어의 모든 가능한 세분화 찾기\n\n학습 말뭉치에서 단어가 cat인 경우를 고려해보겠습니다. 이는 다음과 같이 세분화될 수 있습니다:\n\n[`c`, `a`, `t`]\n\n[`ca`, `t`]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[`c`, `at`]\n\n[`cat`]\n\n단계 5) 말뭉치에서 발생 가능한 각 세분화의 근사 확률 계산\n\n위의 방정식들을 결합하면 각 토큰 시리즈에 대한 확률을 얻을 수 있습니다. 예를 들어, 이것은 다음과 같이 보일 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-23-TokenizationACompleteGuide_4.png\" /\u003e\n\n가장 높은 확률 점수를 가진 세그먼트 [`c`, `at`]가 사용되어 단어를 토크나이즈했습니다. 따라서 단어 cat은 [`c`, `at`]으로 토큰화됩니다. 단어가 긴 경우 토큰화시 단어 내 여러 곳에서 분할이 발생할 수 있습니다. 예를 들어 [`token`, `iza`, tion] 또는 [`token`, `ization`] 같은 경우도 있을 수 있습니다.\n\n6단계) 손실 계산\n\n손실이란 모델의 점수를 나타내며, 중요한 토큰이 어휘에서 제거되면 손실이 크게 증가하지만 중요하지 않은 토큰이 제거되면 손실은 크게 증가하지 않습니다. 모델에서 각 토큰을 제거했을 때 손실이 얼마나 되는지 계산하여, 어휘 중에서 가장 쓸모없는 토큰을 찾을 수 있습니다. 훈련 세트 말뭉치에서 가장 유용한 토큰만 남도록 어휘 크기가 감소할 때까지 반복적으로 수행할 수 있습니다. 손실은 다음과 같이 주어집니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Tokenization Guide](/assets/img/2024-05-23-TokenizationACompleteGuide_5.png)\n\n필요한 양만큼 문자가 제거되어 어휘를 원하는 크기로 줄일 때, 교육은 완료되고 모델을 사용하여 단어를 토큰화할 수 있습니다.\n\n## BPE, WordPiece 및 Unigram 비교\n\n학습 세트 및 토큰화해야 할 데이터에 따라 어떤 토크나이저가 다른 것보다 더 잘 작동할 수 있습니다. 언어 모델에 대한 토크나이저를 선택할 때, 특정 사용 사례에 사용된 학습 세트를 실험하여 최상의 결과를 얻는 것이 가장 좋을 수 있습니다. 그러나 이 세 가지 토크나이저의 일반적인 경향에 대해 논의하는 것이 유용할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n세 가지 중에서 BPE가 현재 언어 모델 토크나이저로 가장 인기 있는 선택인 것으로 보입니다. 그러나 변화가 빠르게 일어나는 이 분야에서는 앞으로 변동이 있을 수 있습니다. 사실, SentencePiece와 같은 다른 서브워드 토크나이저들이 최근에 훨씬 더 인기를 얻고 있습니다.\n\nWordPiece는 BPE와 Unigram에 비해 더 많은 단어 토큰을 생성하는 것으로 보입니다. 그러나 모델 선택과 관계 없이 어휘 크기가 커질수록 모든 토크나이저가 더 적은 토큰을 생성하는 것으로 보입니다.\n\n최종적으로, 토크나이저의 선택은 모델과 함께 사용하려는 데이터셋에 따라 다릅니다. 안전한 선택은 BPE 또는 SentencePiece를 시도하고, 그 이후에 실험하는 것일 수 있습니다.\n\n## 후처리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토큰화 파이프라인의 마지막 단계는 후처리입니다. 여기서 필요한 경우 출력에 최종 수정을 가할 수 있습니다. BERT는 이 단계를 사용하여 두 가지 추가 토큰을 추가하는 데 유명합니다:\n\n- [CLS] - 이 토큰은 `classification`를 나타내며 입력 텍스트의 시작을 표시하는 데 사용됩니다. 이는 BERT에서 필요한 것인데, 이 토큰의 이름에서 알 수 있듯이 이를 사용하여 분류 작업이 수행되었기 때문입니다. 분류 작업에 사용되지 않을 때도 모델에서 여전히 이 토큰을 예상합니다.\n- [SEP] - 이 토큰은 `separation`을 나타내며 입력에서 문장을 분리하는 데 사용됩니다. BERT가 수행하는 많은 작업에 유용하며, 동일한 프롬프트에서 동시에 여러 지시사항을 처리할 때도 사용됩니다.\n\n# Python 라이브러리의 토크나이저\n\nHugging Face는 Python을 포함한 여러 프로그래밍 언어에서 사용할 수 있는 토크나이저 라이브러리를 제공합니다. 이 라이브러리에는 사용자가 사전 훈련된 모델을 사용할 수 있는 일반 Tokenizer 클래스가 포함되어 있으며, 전체 목록은 Hugging Face 웹사이트에서 확인할 수 있습니다. 게다가, 라이브러리에는 사용자가 자체 데이터로 훈련할 수 있는 네 가지 사전 제작되지만 미학습된 모델도 포함되어 있습니다. 이는 특정 유형의 문서에 튜닝된 특정 토크나이저를 작성하는 데 유용합니다. 아래 셀은 Python에서 사전 훈련된 및 미학습된 토크나이저를 사용하는 예시를 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프리트레인 토크나이저 사용하기\n\n토크나이저 라이브러리를 사용하면 프리트레인 토크나이저를 쉽게 사용할 수 있습니다. Tokenizer 클래스를 가져와서 from_pretrained 메소드를 호출하고 사용할 토크나이저의 모델 이름을 전달하면 됩니다. 모델의 목록은 [16]에서 확인할 수 있습니다.\n\n```js\nfrom tokenizers import Tokenizer\n\ntokenizer = Tokenizer.from_pretrained('bert-base-cased')\n```\n\n토크나이저 학습하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n원하는 토큰 만들기되지만 미학습 토크나이저를 사용하려면 tokenizers 라이브러리에서 원하는 모델을 가져와서 모델 클래스의 인스턴스를 만들면 됩니다. 위에서 설명한대로 라이브러리에는 네 가지 모델이 포함되어 있습니다:\n\n- BertWordPieceTokenizer - 유명한 Bert 토크나이저인 WordPiece를 사용합니다.\n- CharBPETokenizer - 원래의 BPE(BPE)\n- ByteLevelBPETokenizer - BPE의 바이트 레벨 버전\n- SentencePieceBPETokenizer - SentencePiece에서 사용하는 BPE 구현과 호환되는 버전\n\n모델을 학습하려면 train 메서드를 사용하고 학습 데이터가 포함된 파일의 경로(또는 파일 경로 목록)를 전달하면 됩니다. 학습을 마치면 모델은 encode 메서드를 사용하여 일부 텍스트를 토큰화하는 데 사용할 수 있습니다. 마지막으로 학습된 토크나이저는 save 메서드를 사용하여 저장할 수 있으므로 학습을 다시 수행할 필요가 없습니다. 아래는 Hugging Face Tokenizers GitHub 페이지에서 제공되는 예제를 수정한 예시 코드입니다 [17].\n\n```js\n# 토크나이저 가져오기\nfrom tokenizers import BertWordPieceTokenizer, CharBPETokenizer, \\\n                       ByteLevelBPETokenizer, SentencePieceBPETokenizer\n\n# 모델 인스턴스화\ntokenizer = CharBPETokenizer()\n\n# 모델 학습\ntokenizer.train(['./path/to/files/1.txt', './path/to/files/2.txt'])\n\n# 텍스트 토큰화\nencoded = tokenizer.encode('I can feel the magic, can you?')\n\n# 모델 저장\ntokenizer.save('./path/to/directory/my-bpe.tokenizer.json')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토크나이저 라이브러리는 이전 섹션에서 보여주었던 것과 같이 처음부터 전체 모델을 구현할 필요 없이 매우 빠르게 사용자 정의 토크나이저를 만들 수 있는 구성 요소도 제공합니다. 아래 셀에는 Hugging Face GitHub 페이지 [17]에서 가져온 예시가 표시되어 있습니다. 해당 예시에서는 토크나이저의 사전 토크나이제이션 및 디코딩 단계를 사용자 정의하는 방법을 보여줍니다. 이 경우, 사전 토크나이제이션 단계에서 접두어 공백이 추가되었고, 디코더로는 ByteLevel 디코더가 선택되었습니다. Hugging Face 문서 [18]에는 사용자 정의 옵션의 전체 목록이 제공됩니다.\n\n```js\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, \\\n                       processors\n\n# 토크나이저 초기화\ntokenizer = Tokenizer(models.BPE())\n\n# 사전 토크나이제이션 및 디코딩 사용자 정의\ntokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\ntokenizer.decoder = decoders.ByteLevel()\ntokenizer.post_processor = processors.ByteLevel(trim_offsets=True)\n\n# 그리고 학습\ntrainer = trainers.BpeTrainer(\n    vocab_size=20000,\n    min_frequency=2,\n    initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\n)\ntokenizer.train([\n    \"./path/to/dataset/1.txt\",\n    \"./path/to/dataset/2.txt\",\n    \"./path/to/dataset/3.txt\"\n], trainer=trainer)\n\n# 그리고 저장\ntokenizer.save(\"byte-level-bpe.tokenizer.json\", pretty=True)\n```\n\n# 결론\n\n토큰화 파이프라인은 언어 모델의 중요한 부분이며, 어떤 종류의 토크나이저를 사용할지 결정할 때 신중한 고려가 필요합니다. 요즘에는 Hugging Face와 같은 라이브러리의 개발자들이 우리를 대신하여 많은 이러한 결정을 내려주고 있습니다. 이를 통해 사용자는 빠르게 사용자 지정 데이터로 언어 모델을 학습하고 사용할 수 있습니다. 그러나 토큰화 방법에 대한 탄탄한 이해는 모델을 미세 조정하고 다양한 데이터셋에서 추가 성능을 얻는 데 귀중합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 참고 자료\n\n[1] 표지 이미지 — Stable Diffusion Web\n\n[2] 토큰 정의 — Stanford NLP 그룹\n\n[3] 단어 토크나이저 — Towards Data Science\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- [4] TransformerXL 논문 — ArXiv\n\n- [5] Tokenizers — Hugging Face\n\n- [6] 단어 기반, 서브워드, 문자 기반 토크나이저 — Towards Data Science\n\n- [7] 토큰화 파이프라인 — Hugging Face\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\\[8\\] Pre-tokenizers — Hugging Face\n\n\\[9\\] Language Models are Unsupervised Multitask Learners — OpenAI\n\n\\[10\\] BART Model for Text Autocompletion in NLP — Geeks for Geeks\n\n\\[11\\] Byte Pair Encoding — Hugging Face\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[12] WordPiece 토큰화 — Hugging Face\n\n[13] 두 분 NLP — 토큰화 방법론의 분류 — Medium\n\n[14] 서브워드 토크나이저 비교 — Vinija AI\n\n[15] BERT가 단어 맥락 관계를 배우는 데 어떻게 Attention 메커니즘과 Transformer를 활용하는가 — Medium\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[16] 사전 훈련된 모델 목록 — Hugging Face\n\n[17] Hugging Face Tokenizers 라이브러리 — GitHub\n\n[18] 사전 토크나이제이션 문서 — Hugging Face\n","ogImage":{"url":"/assets/img/2024-05-23-TokenizationACompleteGuide_0.png"},"coverImage":"/assets/img/2024-05-23-TokenizationACompleteGuide_0.png","tag":["Tech"],"readingTime":36},{"title":"고급 RAG 07 테이블을 위한 RAG 탐색","description":"","date":"2024-05-23 18:13","slug":"2024-05-23-AdvancedRAG07ExploringRAGforTables","content":"\nRAG를 구현하는 것은 도전적인 과제를 제공하는데, 특히 비구조화된 문서의 테이블을 효과적으로 구문 분석하고 이해하는 부분이 그 중요한 부분입니다. 특히 스캔된 문서나 이미지 형식의 문서에서는 이 작업이 특히 어려울 수 있습니다. 이러한 도전 과제에는 적어도 다음 세 가지 측면이 있습니다:\n\n- 스캔된 문서 또는 이미지 문서의 복잡성, 다양한 구조, 비텍스트 요소의 포함 및 필기 및 인쇄된 내용의 결합과 같은 특징들은 테이블 정보를 정확하게 자동 추출하는 데 도전을 제공합니다. 부정확한 구문 분석은 테이블 구조를 손상시킬 수 있으며, 불완전한 테이블을 포함하는 것은 테이블의 의미 정보를 포착하지 못할 뿐만 아니라 RAG 결과를 손상시킬 수 있습니다.\n- 테이블 캡션을 추출하고 해당 테이블에 효과적으로 연결하는 방법.\n- 테이블의 의미 정보를 효과적으로 저장하기 위한 색인 구조를 설계하는 방법.\n\n이 기사는 RAG 내에서 테이블을 관리하는 주요 기술을 소개한 후 일부 기존 오픈 소스 솔루션을 검토한 다음 새로운 솔루션을 제안하고 구현하는 방법을 제시합니다.\n\n# 주요 기술\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 테이블 구문 분석\n\n이 모듈의 주요 기능은 정형화되지 않은 문서나 이미지에서 테이블 구조를 정확하게 추출하는 것입니다.\n\n추가 기능: 해당하는 테이블 캡션을 추출하고, 개발자가 해당 테이블 캡션을 테이블과 관련 짓기 편리하도록 하는 것이 가장 좋습니다.\n\n제 현재 이해에 따르면, Figure 1에 나타난 것처럼 여러 가지 방법이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png)\n\n(a). 다중 모달 LLM(예: GPT-4V)을 활용하여 각 PDF 페이지에서 표를 식별하고 정보를 추출합니다.\n\n- 입력: 이미지 형식의 PDF 페이지\n- 출력: JSON 또는 다른 형식의 표. 다중 모달 LLM이 표 데이터를 추출하지 못하는 경우 이미지를 요약하고 요약본을 반환해야 합니다.\n\n(b). Table Transformer와 같은 전문적인 표 감지 모델을 활용하여 표 구조를 식별합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 입력: 이미지로 된 PDF 페이지\n- 출력: 이미지로 된 테이블\n\n(c). 오픈 소스 프레임워크인 unstructured 등을 사용하여 객체 검출 모델을 활용하세요(unstructured의 테이블 검출 과정은 이 기사에 자세히 기재되어 있습니다). 이러한 프레임워크를 사용하면 전체 문서의 철저한 구문 분석과 구문 분석 결과로부터 테이블 관련 콘텐츠의 추출이 가능합니다.\n\n- 입력: PDF 또는 이미지 형식의 문서\n- 출력: 문서 전체의 구문 분석 결과로부터 얻은 테이블을 일반 텍스트 또는 HTML 형식으로\n\n(d). Nougat, Donut 등의 end-to-end 모델을 사용하여 전체 문서를 구문 분석하고 테이블 관련 콘텐츠를 추출하세요. 이 접근 방식은 OCR 모델을 필요로하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 입력: PDF 또는 이미지 형식의 문서\n- 출력: 전체 문서의 구문 분석 결과를 통해 얻은 LaTeX 또는 JSON 형식의 표\n\n언급할 가치가 있는 것은 표 정보를 추출하는 방법에 관계없이 표 캡션을 포함해야 합니다. 대부분의 경우 표 캡션은 문서나 논문 작성자가 표에 대해 간단히 설명한 것으로, 전체 표를 크게 요약할 수 있습니다.\n\n위에서 언급한 네 가지 방법 중 (d) 방법은 표 캡션을 쉽게 검색할 수 있습니다. 개발자에게는 이 방법이 유용한데, 표 캡션을 표와 연관시킬 수 있도록 해주기 때문입니다. 이 내용은 다음 실험에서 자세히 설명될 것입니다.\n\n## 색인 구조\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n색인 구조에 따라 해결책은 대략 다음 카테고리로 나뉩니다:\n\n(e). 이미지 형식의 색인 표만 있는 경우.\n\n(f). 일반 텍스트 또는 JSON 형식의 색인 표만 있는 경우.\n\n(g). LaTeX 형식의 색인 표만 있는 경우.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n### (h). 테이블 요약만 색인화합니다.\n\n### (i). 작은 부터 큰 또는 문서 요약 색인 구조, Figure 2에 나와 있는 것처럼.\n\n- 작은 청크의 내용은 테이블의 각 행 정보 또는 테이블 요약일 수 있습니다.\n- 큰 청크의 내용은 이미지 형식, 일반 텍스트 형식 또는 LaTeX 형식의 테이블일 수 있습니다.\n\n![Figure 2](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 논의한 대로 Table summary는 일반적으로 LLM을 사용하여 생성됩니다:\n\n- 입력: 이미지 형식, 텍스트 형식 또는 LaTeX 형식의 테이블\n- 출력: 테이블 요약\n\n## Table Parsing, Indexing 또는 RAG가 필요하지 않은 algorithms\n\n일부 알고리즘은 테이블 파싱이 필요하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(j). 관련 이미지(PDF 페이지)와 사용자 쿼리를 VQA 모델(예: DAN 등)이나 멀티모달 LLM에 보내고 답변을 받습니다.\n\n- 색인할 내용: 이미지 형식의 문서\n- VQA 모델이나 멀티모달 LLM에 전송되는 내용: 쿼리 + 해당 이미지 페이지\n\n(k). 관련 텍스트 형식의 PDF 페이지와 사용자 쿼리를 LLM에 보내고, 그런 다음 답변을 받습니다.\n\n- 색인할 내용: 텍스트 형식의 문서\n- LLM에 전송되는 내용: 쿼리 + 해당 텍스트 형식의 페이지\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(l) 사용자의 쿼리와 관련 이미지(PDF 페이지), 텍스트 청크를 다중 모달 LLM(예: GPT-4V 등)에 보내고 답변을 직접 반환합니다.\n\n- 색인할 콘텐츠: 이미지 형식의 문서 및 텍스트 형식의 문서 청크\n- 다중 모달 LLM에 보내는 콘텐츠: 쿼리 + 문서의 이미지 형식 + 해당하는 텍스트 청크\n\n또한, 다음은 색인이 필요하지 않은 몇 가지 방법입니다. 그림 3과 그림 4에서 보듯이:\n\n![image](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(m). 먼저, 문서의 모든 표를 이미지 형태로 변환하기 위해 (a)부터 (d) 범주 중 하나의 방법을 적용하세요. 그런 다음 모든 표 이미지와 사용자 질의를 멀티모달 LLM(예: GPT-4V 등)에 직접 전송하여 답변을 받아보세요.\n\n- 색인할 내용: 없음\n- 멀티모달 LLM에 전송될 내용: 질의 + 모든 변환된 표(이미지 형태)\n\n![표 이미지](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_3.png)\n\n(n). (m)에서 추출된 이미지 형식의 표를 사용하여 OCR 모델을 이용해 표 안의 모든 텍스트를 인식한 후, 표 안의 모든 텍스트와 사용자 질의를 LLM에 직접 전송하여 답변을 받아보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 색인할 콘텐츠: 없음\n- LLM에 보내지는 콘텐츠: 사용자 쿼리 + 모든 테이블 내용(텍스트 형식)\n\n익명의 사실을 공유하자면, 일부 방법은 RAG 프로세스에 의존하지 않습니다:\n\n- 첫 번째 방법은 LLM을 사용하지 않으며, 특정 데이터세트에서 학습하며 모델(예: BERT와 유사한 트랜스포머)이 TAPAS와 같은 테이블 이해 작업을 더 잘 지원하도록 합니다.\n- 두 번째 방법은 LLM을 사용하며, 사전 학습, 파인 튜닝 방법 또는 프롬프트를 사용하여 LLM이 GPT4Table과 같은 테이블 이해 작업을 수행할 수 있도록 합니다.\n\n# 기존 오픈 소스 솔루션\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 섹션에서는 RAG의 테이블에 대한 주요 기술을 요약하고 분류했습니다. 이 글이 구현하는 해결책을 제안하기 전에 오픈 소스 솔루션 중 일부를 탐색해보겠습니다.\n\nLlamaIndex는 네 가지 방법을 제안했는데, 처음 세 가지는 다중 모달 모델을 사용합니다.\n\n- 관련 이미지(PDF 페이지)를 검색하여 이를 GPT-4V에 보내 쿼리에 대답하도록 합니다.\n- 각 PDF 페이지를 이미지로 간주하고, 각 페이지에 대해 이미지 추론을 수행하도록 GPT-4V에게 맡깁니다. 이미지 추론을 위한 텍스트 벡터 저장소 인덱스를 작성합니다. 이미지 추론 벡터 저장소에 대한 답변을 쿼리로 가져옵니다.\n- 테이블 트랜스포머를 사용하여 검색된 이미지에서 테이블 정보를 잘라내고, 이러한 잘린 이미지를 GPT-4V에 보내 쿼리 응답을 받습니다.\n- 잘려진 테이블 이미지에 OCR을 적용하고 데이터를 GPT4/GPT-3.5로 보내어 쿼리에 답변을 받습니다.\n\n이 글의 분류에 따르면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이 기사에서의 (j) 항목과 유사한 첫 번째 방법은 테이블 구문 분석이 필요하지 않습니다. 그러나 결과는 이미지에 정답이 있더라도 올바른 답을 내놓지 못하는 것을 보여줍니다.\n- 두 번째 방법은 테이블 구문 분석을 포함하며 (a) 항목과 일치합니다. 색인된 콘텐츠는 GPT-4V의 결과에 따라 테이블 콘텐츠 또는 요약이며, 이는 (f) 또는 (h)에 해당할 수 있습니다. 이 방법의 단점은 GPT-4V가 이미지에서 테이블을 식별하고 내용을 추출하는 능력이 불안정하다는 것이며, PDF 형식에서 발생하는 테이블, 텍스트 및 다른 이미지가 혼합된 경우에 특히 해당됩니다.\n- 세 번째 방법은 (m) 항목과 유사하며 색인이 필요하지 않습니다.\n- 네 번째 방법은 (n) 항목과 유사하며 또한 색인이 필요하지 않습니다. 결과는 이미지에서 테이블 정보를 추출하는 능력이 없어 잘못된 답변이 생성된다고 나타냅니다.\n\n테스트 결과, 세 번째 방법이 전반적으로 가장 효과적인 것으로 나타났습니다. 그러나 제 테스트에 따르면 세 번째 방법은 테이블을 감지하는 데 어려움을 겪고, 특히 테이블 제목을 올바르게 병합하는 것조차 어렵다는 것을 보여줍니다.\n\nLangchain은 일부 솔루션을 제안했습니다. Semi-structured RAG의 주요 기술은 다음과 같습니다:\n\n- 테이블 구문 분석은 비구조적을 사용하며, 이는 (c) 항목에 해당합니다.\n- 색인 방법은 문서 요약 색인이며, 이는 (i) 항목에 해당합니다. 작은 청크 콘텐츠: 테이블 요약, 큰 청크 콘텐츠: 원시 테이블 콘텐츠(텍스트 형식).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 그림 5에 나타난 대로:\n\n![Figure 5](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_4.png)\n\n반구조화 및 멀티 모달 RAG는 세 가지 해결책을 제안하며, 아키텍처는 아래 그림 6에 나와 있습니다.\n\n![Figure 6](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n옵션 1은 이 기사의 (l) 범주와 유사합니다. 멀티모달 임베딩(예: CLIP)을 사용하여 이미지와 텍스트를 임베드하고 유사성 검색을 통해 둘 다 검색하며, 생 이미지 및 청크를 멀티모달 LLM에게 전달하여 답변 합성을 수행합니다.\n\n옵션 2은 이미지로부터 텍스트 요약을 생성하는 멀티모달 LLM(예: GPT-4V, LLaVA, 또는 FUYU-8b)을 활용합니다. 그런 다음 텍스트를 임베드하고 검색하여 텍스트 청크를 LLM에게 전달하여 답변 합성을 합니다.\n\n- 테이블 파싱은 구조화되지 않은 것을 사용합니다. 이는 범주 (d)입니다.\n- 색인 구조는 문서 요약 인덱스(범주 (i))이며, 작은 청크 내용: 테이블 요약, 큰 청크 내용: 텍스트 형식의 테이블\n\n옵션 3은 이미지로부터 텍스트 요약을 생성하기 위해 멀티모달 LLM(예: GPT-4V, LLaVA, 또는 FUYU-8b)를 사용합니다. 그런 다음 이미지 요약을 임베드하고 검색하여 원본 이미지에 대한 이미지 요약과 함께 반환하고, 원본 이미지 및 텍스트 청크를 멀티모달 LLM에게 전달하여 답변 합성을 수행합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 제안된 솔루션\n\n이 글은 주요 기술 및 기존 솔루션을 요약, 분류 및 논의하였습니다. 이를 기반으로 다음과 같은 솔루션을 제안합니다. 간단히 말해서 Re-ranking 및 query rewriting과 같은 RAG 모듈은 생략되었습니다.\n\n![Figure 7](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_6.png)\n\n- 테이블 파싱: Nougat(catogery (d))를 사용합니다. 제 테스트에 따르면, 이는 테이블 감지가 unstructured(catogery (c))보다 더 효과적입니다. 게다가 Nougat은 테이블 캡션을 잘 추출하여 테이블과 연결하는 데 매우 편리합니다.\n- 문서 요약 인덱스 구조(catogery (i)): 작은 청크의 내용에는 테이블 요약이, 큰 청크의 내용에는 LaTeX 형식의 해당 테이블과 텍스트 형식의 테이블 캡션이 포함됩니다. 이를 다중 벡터 검색기를 사용하여 구현합니다.\n- 테이블 요약 획득 방법: 테이블과 테이블 캡션을 LLM에 보내 요약을 받습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법의 장점은 테이블을 효율적으로 구문 분석하면서 테이블 요약과 테이블 간의 관계를 포괄적으로 고려한다는 것입니다. 또한, 멀티모달 LLM이 필요하지 않아 비용을 절감할 수 있습니다.\n\n## Nougat의 원칙\n\nNougat은 도넛 아키텍처를 바탕으로 개발되었습니다. Figure 8에서 보여지듯이 OCR 관련 입력이나 모듈이 필요하지 않고 네트워크를 통해 텍스트를 인식합니다.\n\n![Nougat Principle](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n누가(Nougat)가 수식을 분석하는 능력이 인상적이에요. 테이블 분석에도 능숙해요. 더불어, 테이블 캡션을 연결하여 보여줄 수 있어 편하지요. 그림 9에서 보여졌듯이요:\n\n![Figure 9](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_8.png)\n\n수많은 논문을 테스트한 결과, 테이블 캡션이 항상 테이블 다음 줄에 고정되어 있는 것을 발견했어요. 이 일관성은 우연이 아님을 시사하며, 그래서 누가(Nougat)가 이 효과를 달성하는 방법에 관심이 있어요.\n\n중간 결과가 없는 엔드 투 엔드 모델이므로, 훈련 데이터에 많이 의존할 것으로 예상됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 누가(Nougat)는 이전 파싱 도구에서 어려웠던 부분인 수식 및 표와 같은 부분을 정확하게 LaTeX 소스 코드로 파싱할 수 있습니다.\n- 누가(Nougat)의 파싱 결과는 마크다운과 유사한 반구조화된 문서입니다.\n- 쉽게 표 제목을 얻고 해당 표와 편리하게 연결할 수 있습니다.\n\n단점:\n\n- 누가(Nougat)의 파싱 속도가 느리기 때문에 대규모 배포에 도전이 될 수 있습니다.\n- 누가(Nougat)는 과학 논문을 기반으로 학습되었기 때문에 비슷한 구조의 문서에서 뛰어난 성능을 발휘합니다. 그러나 비라틴 문자 텍스트 문서에서는 성능이 떨어집니다.\n- 누가(Nougat) 모델은 한 번에 한 페이지의 과학 논문만을 학습하며, 다른 페이지에 대한 지식이 부족합니다. 이로 인해 파싱된 콘텐츠에 일관성이 없을 수 있습니다. 따라서, 인식 효과가 좋지 않다면 PDF를 개별 페이지로 나누고 하나씩 파싱하는 것을 고려해야 합니다.\n- 이중 칼럼 논문에서의 표 파싱은 단일 칼럼 논문과 같이 효과적이지 않을 수 있습니다.\n\n## 코드 구현\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 관련 Python 패키지를 설치해주세요.\n\n```js\npip install langchain\npip install chromadb\npip install nougat-ocr\n```\n\n설치를 완료한 후, Python 패키지의 버전을 확인할 수 있습니다.\n\n```js\nlangchain                                0.1.12\nlangchain-community                      0.0.28\nlangchain-core                           0.1.31\nlangchain-openai                         0.0.8\nlangchain-text-splitters                 0.0.1\n\nchroma-hnswlib                           0.7.3\nchromadb                                 0.4.24\n\nnougat-ocr                               0.1.17\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n환경을 설정하고 라이브러리를 가져와주세요:\n\n```js\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPEN_AI_KEY\"\n\nimport subprocess\nimport uuid\n\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain.retrievers.multi_vector import MultiVectorRetriever\nfrom langchain.storage import InMemoryStore\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_core.documents import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.runnables import RunnablePassthrough\n```\n\nAttention Is All You Need 논문을 YOUR_PDF_PATH로 다운로드하고, nougat을 실행하여 PDF 파일을 구문 분석하고 해당 결과로부터 LaTex 형식의 표 및 텍스트 형식의 표 캡션을 얻어주세요. 첫 실행 시 필요한 모델 파일이 다운로드됩니다.\n\n```js\ndef june_run_nougat(file_path, output_dir):\n    # nougat을 실행하고 결과를 Mathpix Markdown으로 저장합니다.\n    cmd = [\"nougat\", file_path, \"-o\", output_dir, \"-m\", \"0.1.0-base\", \"--no-skipping\"]\n    res = subprocess.run(cmd)\n    if res.returncode != 0:\n        print(\"nougat 실행 중 오류가 발생했습니다.\")\n        return res.returncode\n    else:\n        print(\"작업 완료!\")\n        return 0\n\ndef june_get_tables_from_mmd(mmd_path):\n    f = open(mmd_path)\n    lines = f.readlines()\n    res = []\n    tmp = []\n    flag = \"\"\n    for line in lines:\n        if line == \"\\\\begin{table}\\n\":\n            flag = \"BEGINTABLE\"\n        elif line == \"\\\\end{table}\\n\":\n            flag = \"ENDTABLE\"\n\n        if flag == \"BEGINTABLE\":\n            tmp.append(line)\n        elif flag == \"ENDTABLE\":\n            tmp.append(line)\n            flag = \"CAPTION\"\n        elif flag == \"CAPTION\":\n            tmp.append(line)\n            flag = \"MARKDOWN\"\n            print('-' * 100)\n            print(''.join(tmp))\n            res.append(''.join(tmp))\n            tmp = []\n\n    return res\n\nfile_path = \"YOUR_PDF_PATH\"\noutput_dir = \"YOUR_OUTPUT_DIR_PATH\"\n\nif june_run_nougat(file_path, output_dir) == 1:\n    import sys\n    sys.exit(1)\n\nmmd_path = output_dir + '/' + os.path.splitext(file_path)[0].split('/')[-1] + \".mmd\"\ntables = june_get_tables_from_mmd(mmd_path)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n함수 june_get_tables_from_mmd은 Figure 10에 표시된 mmd 파일에서 'table'부터 'table'까지의 모든 내용 및 'table' 다음 줄을 추출하는 데 사용됩니다.\n\n![이미지](/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_9.png)\n\n표 캡션을 표 아래에 배치해야 하거나 표가 'table'로 시작하고 'end'로 끝나야 한다는 것을 명시하는 공식 문서가 발견되지 않았다는 점을 유의하십시오. 따라서 june_get_tables_from_mmd는 휴리스틱입니다.\n\nPDF에서 표를 구문 분석한 결과는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 1: 다양한 레이어 유형에 대한 최대 경로 길이, 레이어당 복잡성 및 최소 순차 작업 수가 표시됩니다.\n\n표 2: Transformer가 영어-독일어 및 영어-프랑스어 newstest2014 테스트에서 이전 최신 모델보다 더 우수한 BLEU 점수를 달성하며 훈련 비용이 줄어드는 것을 보여줍니다.\n\n표 3: Transformer 아키텍처의 변형이 나열되어 있으며, 기본 모델 정보와 영어-독일어 번역 개발 세트 newstest2013에서의 모든 메트릭스가 제공됩니다.\n\n표 4: Transformer가 영어 구성 구문 분석에 잘 일반화되며, WSJ 23 섹션의 결과가 제시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_10.png\" /\u003e\n\n다중 벡터 리트리버를 사용하여 문서 요약 색인 구조를 구축해보세요.\n\n```js\n# 자식 청크를 색인화하는 데 사용할 벡터스토어\nvectorstore = Chroma(collection_name = \"summaries\", embedding_function = OpenAIEmbeddings())\n\n# 상위 문서를 위한 저장소 레이어\nstore = InMemoryStore()\nid_key = \"doc_id\"\n\n# 리트리버 (시작할 때는 빈 상태)\nretriever = MultiVectorRetriever(\n    vectorstore = vectorstore,\n    docstore = store,\n    id_key = id_key,\n    search_kwargs={\"k\": 1} # 요청된 결과의 수가 색인 요소보다 큰 4이므로, n_results = 1로 업데이트하겠습니다\n)\n\n# 테이블 추가\ntable_ids = [str(uuid.uuid4()) for _ in tables]\nsummary_tables = [\n    Document(page_content = s, metadata = {id_key: table_ids[i]})\n    for i, s in enumerate(table_summaries)\n]\nretriever.vectorstore.add_documents(summary_tables)\nretriever.docstore.mset(list(zip(table_ids, tables)))\n```\n\n모든 준비가 되었습니다. 간단한 RAG 파이프라인을 구축하고 쿼리를 수행해보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 프롬프트 템플릿\n템플릿 = \"\"\"다음 콘텍스트를 기반으로 질문에 답하세요. 이는 텍스트와 테이블을 포함할 수 있으며 LaTeX 형식의 테이블과 일반 텍스트 형식의 테이블 캡션을 포함합니다:\n{context}\n질문: {question}\n\"\"\"\n프롬프트 = ChatPromptTemplate.from_template(템플릿)\n\n# LLM\n모델 = ChatOpenAI(temperature = 0, model = \"gpt-3.5-turbo\")\n\n\n# 간단한 RAG 파이프라인\n체인 = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | 프롬프트\n    | 모델\n    | StrOutputParser()\n)\n\n\nprint(체인.invoke(\"when layer type is Self-Attention, what is the Complexity per Layer?\"))  # 테이블 1에 관한 쿼리\n\nprint(체인.invoke(\"Which parser performs worst for BLEU EN-DE\"))  # 테이블 2에 관한 쿼리\n\nprint(체인.invoke(\"Which parser performs best for WSJ 23 F1\"))  # 테이블 4에 관한 쿼리\n```\n\n아래는 실행 결과입니다. 여러 질문이 정확히 답변되었음을 보여주는데, 이는 도표 12에 나와 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_11.png\" /\u003e\n\n전체 코드는 아래와 같습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPEN_AI_KEY\"\n\nimport subprocess\nimport uuid\n\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain.retrievers.multi_vector import MultiVectorRetriever\nfrom langchain.storage import InMemoryStore\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_core.documents import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.runnables import RunnablePassthrough\n\n\ndef june_run_nougat(file_path, output_dir):\n    # Run Nougat and store results as Mathpix Markdown\n    cmd = [\"nougat\", file_path, \"-o\", output_dir, \"-m\", \"0.1.0-base\", \"--no-skipping\"]\n    res = subprocess.run(cmd)\n    if res.returncode != 0:\n        print(\"Error when running nougat.\")\n        return res.returncode\n    else:\n        print(\"Operation Completed!\")\n        return 0\n\ndef june_get_tables_from_mmd(mmd_path):\n    f = open(mmd_path)\n    lines = f.readlines()\n    res = []\n    tmp = []\n    flag = \"\"\n    for line in lines:\n        if line == \"\\\\begin{table}\\n\":\n            flag = \"BEGINTABLE\"\n        elif line == \"\\\\end{table}\\n\":\n            flag = \"ENDTABLE\"\n\n        if flag == \"BEGINTABLE\":\n            tmp.append(line)\n        elif flag == \"ENDTABLE\":\n            tmp.append(line)\n            flag = \"CAPTION\"\n        elif flag == \"CAPTION\":\n            tmp.append(line)\n            flag = \"MARKDOWN\"\n            print('-' * 100)\n            print(''.join(tmp))\n            res.append(''.join(tmp))\n            tmp = []\n\n    return res\n\nfile_path = \"YOUR_PDF_PATH\"\noutput_dir = \"YOUR_OUTPUT_DIR_PATH\"\n\nif june_run_nougat(file_path, output_dir) == 1:\n    import sys\n    sys.exit(1)\n\nmmd_path = output_dir + '/' + os.path.splitext(file_path)[0].split('/')[-1] + \".mmd\"\ntables = june_get_tables_from_mmd(mmd_path)\n\n\n# Prompt\nprompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\\nGive a concise summary of the table or text. The table is formatted in LaTeX, and its caption is in plain text format: {element}  \"\"\"\nprompt = ChatPromptTemplate.from_template(prompt_text)\n\n# Summary chain\nmodel = ChatOpenAI(temperature = 0, model = \"gpt-3.5-turbo\")\nsummarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n# Get table summaries\ntable_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\nprint(table_summaries)\n\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(collection_name = \"summaries\", embedding_function = OpenAIEmbeddings())\n\n# The storage layer for the parent documents\nstore = InMemoryStore()\nid_key = \"doc_id\"\n\n# The retriever (empty to start)\nretriever = MultiVectorRetriever(\n    vectorstore = vectorstore,\n    docstore = store,\n    id_key = id_key,\n    search_kwargs={\"k\": 1} # Solving Number of requested results 4 is greater than number of elements in index..., updating n_results = 1\n)\n\n# Add tables\ntable_ids = [str(uuid.uuid4()) for _ in tables]\nsummary_tables = [\n    Document(page_content = s, metadata = {id_key: table_ids[i]})\n    for i, s in enumerate(table_summaries)\n]\nretriever.vectorstore.add_documents(summary_tables)\nretriever.docstore.mset(list(zip(table_ids, tables)))\n\n\n# Prompt template\ntemplate = \"\"\"Answer the question based only on the following context, which can include text and tables, there is a table in LaTeX format and a table caption in plain text format:\n{context}\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\n# LLM\nmodel = ChatOpenAI(temperature = 0, model = \"gpt-3.5-turbo\")\n\n# Simple RAG pipeline\nchain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\nprint(chain.invoke(\"when layer type is Self-Attention, what is the Complexity per Layer?\"))  # Query about table 1\n\nprint(chain.invoke(\"Which parser performs worst for BLEU EN-DE\"))  # Query about table 2\n\nprint(chain.invoke(\"Which parser performs best for WSJ 23 F1\"))  # Query about table 4\n```\n\n# 결론\n\n이 글에서는 RAG 프로세스 중 표 처리를 위한 주요 기술과 기존 솔루션을 논의하고 구현과 함께 해결책을 제안합니다.\n\n이 문서에서는 표를 파싱하는 데 nougat을 사용합니다. 그러나 더 빠르고 효과적인 파싱 도구가 있다면 nougat을 대체 고려할 것입니다. 우리의 도구에 대한 태도는 먼저 올바른 아이디어를 가지고, 그런 다음 도구를 찾아 실현하는 것에 있으며, 특정 도구에 의존하는 대신입니다.\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 모든 테이블 콘텐츠를 LLM에 입력합니다. 그러나 실제 시나리오에서는 표가 LLM 콘텍스트 길이를 초과하는 경우를 고려해야 합니다. 이 문제를 효과적인 청킹 방법을 사용하여 해결할 수 있습니다.\n\nRAG 기술에 관심이 있다면, 다른 기사들도 확인해보세요.\n\n그리고 최신 AI 관련 콘텐츠는 제 뉴스레터에서 찾을 수 있습니다.\n\n마지막으로, 이 기사에 오류나 누락된 내용이 있다면, 또는 궁금한 점이 있으면 댓글 섹션에서 언급해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 친근한 어조로 번역한 내용 🚀\n\nIn Plain English 커뮤니티에 참여해 주셔서 감사합니다! 그 전에:\n\n- 저희 작가를 박수로 응원하고 팔로우해 주세요️👏️\n- 저희를 팔로우하세요: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼도 방문해 보세요: Stackademic | CoFeed | Venture | Cubed\n- 더 많은 콘텐츠를 만나실 수 있습니다: PlainEnglish.io\n","ogImage":{"url":"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png"},"coverImage":"/assets/img/2024-05-23-AdvancedRAG07ExploringRAGforTables_0.png","tag":["Tech"],"readingTime":19},{"title":"RAG 기술 대형 언어 모델의 잠재력을 극대화하기 위한 포괄적 탐구","description":"","date":"2024-05-23 18:11","slug":"2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential","content":"\n\n![RAG Technology](/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png)\n\n대형 언어 모델(LLM)은 자연어 처리(NLP)를 혁신적으로 변화시켰습니다. 기계가 이전에는 인간만 할 수 있었던 작업을 수행할 수 있게 했습니다. 그러나 대규모 학습 데이터셋에 대한 의존 및 새로운 도메인에 적응하는 어려움을 포함한 제한 사항이 존재합니다. 검색 증강 생성(RAG) 기술은 더 다재다능하고 효율적인 NLP 프레임워크를 위해 정보 검색과 LLM 강점을 결합한 해결책으로 등장했습니다.\n\n소개\n\n풍부한 텍스트 데이터로 학습된 LLM의 등장은 NLP를 변혁했습니다. 이러한 모델은 인간과 유사한 품질의 텍스트를 생성하고 언어를 번역하며 창의적인 콘텐츠를 작성하고 질문에 정보적으로 답할 수 있습니다. 그러나 놀라운 능력을 가지고 있지만, LLM은 제한 사항을 직면하고 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 데이터 의존성: 최신 정보를 유지하고 특정 도메인에 적응하는 것은 대규모 훈련 데이터 세트에 의존하기 때문에 어려울 수 있습니다.\n- 계산 비용: LLM(대형 언어 모델)을 훈련하고 배포하는 것은 계산적으로 비용이 많이 들 수 있어서, 리소스가 제한된 연구자와 실무자들의 접근성이 제한될 수 있습니다.\n\n**검색-증가 생성 (RAG)이 나타나다**\n\n이러한 제한 사항을 해결하기 위해, 연구자들은 RAG를 개발했습니다. RAG는 LLM의 강점을 정보 검색과 결합하여 보다 다재다능하고 효율적인 NLP 프레임워크를 만드는 새로운 접근 방법입니다. RAG는 정보 검색의 힘을 활용하여 LLM이 외부 지식원에 액세스하여 다음을 강화할 수 있습니다:\n\n- 실시간 정보에 접근하고 처리하여 최신 응답을 제공합니다.\n- 사용자 맥락과 선호도에 기반한 맞춤형 추천 및 출력 생성합니다.\n- 지식 기반이나 문서 저장소를 간단히 변경함으로써 새로운 도메인에 적응합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 아키텍처\n\nRAG는 두 가지 주요 구성 요소로 구성되어 있습니다:\n\n- 검색 모듈:\n  - 지식 베이스 또는 문서 저장소에서 관련 정보를 식별합니다. 이는 텍스트 문서, 데이터베이스 또는 웹 아카이브와 같은 방대한 컬렉션일 수 있습니다.\n  - BM25, TF-IDF 또는 언어 모델 (예: Sentence-BERT)과 같은 검색 알고리즘을 사용하여 사용자 쿼리를 기반으로 지식 베이스를 검색합니다.\n  - 쿼리와 관련이 있는 문서를 순위별로 정렬합니다.\n- 생성 모듈:\n  - 검색된 문서를 생성 프로세스에 대한 맥락으로 활용합니다. 이러한 맥락은 벡터 표현이거나 핵심 구를 또는 문장 세트일 수 있습니다.\n  - 검색된 문서에서 유도된 맥락을 사용자 쿼리와 함께 고려하여 응답을 생성하는 데 LLM 모델 (예: GPT-3, BERT)을 활용합니다.\n  - 도메인별 데이터셋에 대해 LLM을 세밀하게 조정하면 응답의 관련성을 더욱 향상시킬 수 있습니다.\n\nRAG 워크플로우\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 워크플로우는 세 단계 프로세스를 따릅니다:\n\n- 검색: 사용자의 쿼리는 벡터 표현으로 변환되어 지식 베이스에서 관련 정보를 검색하는 데 사용됩니다.\n- 컨텍스트 생성: 검색된 문서는 쿼리와 관련된 주요 정보를 캡처하는 생성 프로세스를 위한 컨텍스트를 생성하는 데 사용됩니다.\n- 생성: LLM 모델은 사용자의 쿼리와 구성된 컨텍스트를 기반으로 응답을 생성합니다.\n\nRAG의 장점\n\nRAG는 전통적인 LLM 접근 방식보다 여러 가지 장점을 제공합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 실시간 정보 접근: 외부 정보 소스에 실시간으로 접근하고 처리하여 최신 응답을 보장합니다.\n- 맞춤형 추천 및 결과물: 사용자 컨텍스트와 선호도에 기반한 맞춤형 추천과 결과물을 생성합니다.\n- 비용 효율성: 새로운 작업이나 도메인에 대한 지속적인 LLM 재교육이 필요하지 않아 전통적인 LLM 방법보다 비용 효율적입니다.\n- 도메인 적응: 지식베이스나 문서 저장소를 간단히 변경하여 새로운 도메인에 쉽게 적응합니다.\n\nRAG의 응용\n\nRAG는 다양한 분야에서 다양한 잠재적인 응용 프로그램을 제공합니다:\n\n- 법률 연구 및 문서 분석: 효율적인 법률 문서 검색 및 분석을 통해 관련 정보를 식별합니다.\n- 맞춤형 학습: 교육과 자료를 개인 학생의 필요에 맞게 조정하여 맞춤형 학습 경험을 제공합니다.\n- 보고서 생성과 분석: 다양한 소스에서 자동 보고서 생성 및 데이터 분석을 자동화합니다.\n- 고객 서비스: 고객의 상황을 이해하고 관련 정보 및 지원을 제공하여 맞춤형 고객 서비스를 제공합니다.\n- 리스크 관리와 사기 분석: 다양한 소스에서 대량의 데이터를 분석하여 잠재적인 위험과 사기를 식별합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 대 Model Fine-tuning\n\nRAG와 Model Fine-tuning 중 어떤 것을 선택할지는 여러 요소에 따라 다릅니다:\n\n- 외부 데이터 필요성: LLM에서 사용 가능한 외부 데이터에 중요한 경우, RAG가 선호되는 옵션이 될 수 있습니다.\n- 모델 성능: 작업에 대해 LLM의 성능에 만족했다면, Model Fine-tuning이 더 효율적인 접근 방법일 수 있습니다.\n- 지속적인 개선: LLM 성능의 지속적인 개선이 필요한 경우, Fine-tuning과 RAG의 결합이 최적일 수 있습니다.\n\n기술적 고려 사항\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최적 RAG 성능을 위한 몇 가지 기술적 고려 사항이 있습니다:\n\n- 지식 베이스 또는 문서 저장소:\n  - 데이터 선택 및 정제: 명명된 엔티티 인식 (NER) 및 주제 모델링과 같은 기술을 활용하여 지식 베이스/저장소 내에서 관련 정보를 식별하고 분류합니다.\n  - 정기적인 업데이트 및 유지관리: 데이터 원본을 정기적으로 업데이트하고 유지하여 정보의 정확성과 시기적 성을 보장합니다.\n  - 사용자 피드백 메커니즘: 사용자 피드백 메커니즘을 통합하여 데이터 내의 잠재적인 편향이나 부정확성을 식별하고 해결합니다.\n- 검색 알고리즘:\n  - 알고리즘 선택: BM25, TF-IDF 또는 언어 모델(Sentence-BERT 등)과 같은 다양한 검색 알고리즘을 탐색하여 작업 및 데이터 특성에 최적화된 알고리즘을 찾습니다. 선택할 때 쿼리 복잡도, 문서 관련성 및 검색 속도와 같은 요소를 고려합니다.\n  - 알고리즘 튜닝: 선택한 검색 알고리즘을 가중 체계나 관련성 임계값과 같은 매개변수를 조정하여 작업에 최적화된 성능을 달성합니다.\n- 생성 모델:\n  - LLM 세밀 조정: 적합한 LLM 아키텍처(생성형 vs. 식별형)를 선택하는 것 외에도 도메인이나 작업에 맞게 조정된 데이터셋에서 LLM을 세밀 조정합니다. 이를 통해 모델이 검색된 문맥에 관련된 응답을 생성하는 능력이 향상될 수 있습니다.\n  - 프롬프트 엔지니어링: 검색된 정보와 사용자 쿼리에 기반하여 정보를 제공하고 일관성 있는 응답을 생성하는 데 LLM을 안내하는 효과적인 프롬프트를 만듭니다.\n- RAG 시스템 평가:\n  - 자동 메트릭: BLEU 점수, ROUGE 점수 또는 Meteor와 같은 자동 메트릭을 활용하여 생성된 응답의 유창성과 문법적 정확성을 평가합니다.\n  - 인간 평가: 자동 메트릭뿐만 아니라 인간 평가 연구를 실시하여 생성된 응답의 정보 전달, 관련성 및 전반적인 품질을 사용자 관점에서 평가합니다.\n\nRAG의 미래 방향\n\nRAG 기술이 계속 발전함에 따라, 더 많은 진전을 위한 유망한 연구 분야가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Explainable AI (XAI): RAG 시스템이 결과물에 도달하는 방법을 설명하는 기술을 개발하여 사용자 신뢰를 촉진하고 잠재적인 오류를 해결하는 데 도움을 줍니다.\n- RAG 시스템을 위한 평생 학습: RAG 모델이 시간이 지남에 따라 지속적으로 학습하고 적응하는 방법을 탐구하여 새로운 정보를 통합하고 장거리 재훈련 없이 성능을 향상시킵니다.\n- 다른 NLP 작업과의 통합: RAG와 다른 NLP 작업(질문 응답, 요약 및 감정 분석 등)을 통합하기 위한 기술을 개발합니다.\n- 응용 분야 확대: RAG의 새로운 응용 분야(의료, 교육 및 금융 등)를 탐색합니다.\n\n결론\n\nRAG 기술은 LLM의 성능을 크게 향상시키고 주요 제약 사항 중 일부를 해결할 수 있는 잠재력을 가지고 있습니다. LLM의 강점을 정보 검색과 결합함으로써 RAG는 더 다양하고 효율적인 NLP 프레임워크를 가능하게 합니다. RAG 기술이 성숙해짐에 따라 NLP 분야에서 더 많은 혁신적인 응용 프로그램과 발전을 기대할 수 있습니다.\n\n이 글은 2021년 이후 InterProbe의 소프트웨어 개발팀 리더로 활동 중인 Ertan Kabakci가 작성했습니다. 그의 주요 관심 분야는 그래프, GraphQL, 분산 시스템, 빅 데이터 분석 및 인공 지능입니다.\n","ogImage":{"url":"/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png"},"coverImage":"/assets/img/2024-05-23-RAGTechnologyAComprehensiveExplorationforMaximizingLargeLanguageModelPotential_0.png","tag":["Tech"],"readingTime":5}],"page":"2","totalPageCount":61,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"2"},"buildId":"R1x9p1CQYDDJESXyLXKOK","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>