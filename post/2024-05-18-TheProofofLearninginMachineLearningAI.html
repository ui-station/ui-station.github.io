<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>기계 학습 AI에서의 학습 증명 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-18-TheProofofLearninginMachineLearningAI" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="기계 학습 AI에서의 학습 증명 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="기계 학습 AI에서의 학습 증명 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-18-TheProofofLearninginMachineLearningAI" data-gatsby-head="true"/><meta name="twitter:title" content="기계 학습 AI에서의 학습 증명 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-18 20:13" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-4f7b40c1114f0d09.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_buildManifest.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">기계 학습 AI에서의 학습 증명</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="기계 학습 AI에서의 학습 증명" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 18, 2024</span><span class="posts_reading_time__f7YPP">13<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-18-TheProofofLearninginMachineLearningAI&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h2>수학적인 개발을 하기 전에, 먼저 학습의 기초를 이해하고 이것이 오류 개념과 얼마나 밀접하게 관련되어 있는지 알아야 합니다.</h2>
<h1>가상의 요리사</h1>
<p>어느 날, 유명한 레스토랑에서 먹은 특별 요리를 복제하기로 결정했다고 상상해보세요. 그 특별 요리의 맛을 완벽하게 기억합니다. 이를 기반으로 온라인에서 레시피를 찾아 집에서 재현하려고 노력합니다.</p>
<p>레스토랑에서 먹은 특별 요리의 맛을 T로 표시하겠습니다. 이는 기대되는 맛, 즉 당신의 목표를 나타냅니다. 온라인에서 찾은 레시피를 토대로 이 목표, 즉 맛 T를 달성하기를 희망합니다.</p>
<p></p>
<p>이 레시피를 재현하려면 지시된 모든 단계를 따라야 하고 모든 재료와 필요한 온도, 조리 시간 등을 사용해야 합니다. 이 모든 방법과 재료를 X로 표기해봅시다.</p>
<p>전체 과정을 완료한 후 요리를 맛보게 됩니다. 이 때, 예상하는 맛 T와 유사한지 판단하게 됩니다. 예상보다 더 짠지 달콤한지에 대한 판단을 하게 되죠. 집에서 재현한 요리의 맛은 Y로 표현됩니다.</p>
<p>따라서, 목표인 T와 다른 맛을 느꼈을 때, 맛 Y를 기반으로 목표 맛과 얼마나 다른지를 양적으로 평가합니다. 다시 말해 더 많은 소금을 넣었을 수도 있고, 더 적게 향신료를 넣었을 수도 있습니다.</p>
<p>T와 Y 간의 차이를 오차 E로 정의할 수 있습니다. T와 Y의 차이는 여러분의 입맛 기억을 통해 이루어지죠. 따라서 이 순간 여러분의 입맛은 특정 기능을 수행하며, 이를 P(Y) = E로 정의할 수 있습니다. 다시 말해 맛 Y를 경험할 때, 입맛은 목표 맛 T를 기준으로 오차를 할당합니다.</p>
<p></p>
<p>Quantitative measure of error E가 있으면 매일 동일한 레시피를 복제하여 매일매일 오차 E가 줄어듭니다. 다른 말로, 목표하는 맛 T와 실제 맛 Y 사이의 거리가 T = Y가 될 때까지 줄어듭니다.</p>
<p>이 가상 시나리오를 기반으로하면, 오류를 관찰된 현실과 다르게 판단하는 것으로 정의할 수 있으며, 항상 판단 작업을 수행하는 기능이 있습니다. 따라서 위의 경우에는 맛과 기억이 이 판단 기능을 만들었습니다.</p>
<p>특정한 경우에서의 학습 행위는 주로 오류를 줄이는 능력으로 특징 지어집니다. 다시 말해, 이는 판단 함수의 출력을 줄이기 위해 복제 된 객체와 다양한 방식으로 상호 작용하는 능력입니다.</p>
<h1>요리사의 전문지식</h1>
<p></p>
<p>가정의 경우로 돌아와서, 우리는 레시피에 나와 있는 재료와 방법 X를 가지고 있습니다. 모든 재료와 장비는 레스토랑에서 사용된 것과 동일하며, 결과는 목표하는 맛 T를 달성하기 위해 그것들을 올바르게 다룰 수 있는 당신의 능력에만 달려 있습니다.</p>
<p>다시 말해서, 당신은 X를 조작하여 Y를 얻는 것입니다. 따라서 당신이 본질적으로 X를 Y로 변환하는 함수라고 정의할 수 있습니다. 이를 f(X) = Y로 표기합니다.</p>
<p>재료를 다루는 행위를 나타내는 함수 f(X)는 또한 당신의 뇌가 어떻게 작용하는지에 따라 달라집니다. 다시 말해, 만약 당신이 요리 경험이 있다면, X를 Y로 변환하는 것이 더 쉬울 것입니다.</p>
<p>이제 우리는 당신의 뉴런의 가중치 W 또는 X를 다루는 신경 능력을 정의해 봅시다. W가 요리 경험에 기반하여 이미 사전에 조정되어 있다면, X를 Y로 변환하는 것이 더 쉬울 것입니다. 그렇지 않으면, X를 Y로 변환할 수 있을 때까지 W를 조정해야 할 것입니다.</p>
<p></p>
<p>따라서 우리는 f(X) = Y가 W에도 의존한다는 것을 알 수 있습니다, 즉 우리는 f(X) = WX로 선형적으로 표현할 수 있습니다.</p>
<p>그래서, 우리의 목표는 생성된 Y가 매우 가깝거나 T와 동일해질 때까지 W를 어떻게 수정할 수 있는지 알아내는 것입니다. 다시 말해, 오차 E가 크게 감소하거나 0이 될 때까지 W를 어떻게 조절할 수 있는지 입니다.</p>
<h1>비용 함수</h1>
<p>결과와 기대 결과 간의 차이를 평가하는 함수가 비용 함수입니다. 재료와 조리 방법을 솜씨 좋게 바꾸는 함수가 바로 우리의 모델인데요, 이는 인공 신경망 또는 다른 머신러닝 모델일 수 있습니다.</p>
<p></p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_0.png" alt="The Proof of Learning in Machine Learning AI 0"></p>
<p>In equation (1), the definition of the cost function E, which depends on the n weights w. In other words, it is a function that indicates the error based on the values of w. In a specific case where all n weights w are not adjusted, the value of the error E will be large. Conversely, in a case where the weights are properly adjusted, the value of the error E will be small or zero.</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_1.png" alt="The Proof of Learning in Machine Learning AI 1"></p>
<p>Therefore, our objective is to find the values of the n weights w such that the condition above is true.</p>
<p></p>
<h1>그래디언트</h1>
<p>이 작업을 수행하는 방법을 이해하는 데 도움이 되도록 다음 함수를 정의합니다:</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_2.png" alt="function"></p>
<p>따라서 x = 0이고 y = 0일 때 f(x, y) = 0임은 직관적으로 알 수 있습니다. 그러나 우리는 무작위로 선택된 x와 y 값이 주어졌을 때, x와 y의 값을 조정하여 함수 f(x, y)가 0이 되도록 하는 알고리즘을 원합니다.</p>
<p></p>
<p>위 작업을 수행하기 위해 함수의 그래디언트를 사용할 수 있습니다. 벡터 미적분학에서 그래디언트는 특정 지점으로부터 변위함으로써 어떤 양의 값을 최대로 증가시킬 수 있는 방향과 크기를 나타내는 벡터입니다.</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_3.png" alt="이미지"></p>
<p>즉, 함수 f(x, y)에 그래디언트를 적용하면 식(3)에 나타난 대로 x와 y의 값을 어떻게 증가시켜야 f(x, y)의 값이 증가하는지 알려주는 벡터를 얻을 수 있습니다. 그러나 우리의 목표는 함수 f(x, y) = 0의 값을 찾는 것입니다. 따라서 우리는 음의 그래디언트를 사용할 수 있습니다.</p>
<p>아래는 함수 f(x, y)의 두 차원 표현이며 색상이 z의 값을 보여줍니다. 음의 그래디언트를 사용하여 함수의 최솟값을 가리키는 벡터들을 볼 수 있습니다.</p>
<p></p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_4.png" alt="image"></p>
<p>이에 따라 f(x, y) 함수의 그래디언트 필드를 사용하여 x와 y를 업데이트하는 방법을 개발할 수 있습니다. 이를 통해 f(x, y) = 0을 찾는 데 필요한 값을 찾을 수 있습니다.</p>
<h1>학습의 증명</h1>
<p>알고리즘 테스트를 위한 간단한 함수 f(x)를 정의하겠습니다. 저희의 의도는 이 함수의 최솟값을 찾는 것입니다. 이를 위해 f(x)의 그래디언트를 적용할 수 있습니다.</p>
<p></p>
<p>아래는 함수 f(x)의 기울기입니다. 이 글에서는 미분의 개념을 깊게 다루지는 않겠지만, 이렇게 표현할 수 있는 이유에 대해 정의와 함께 읽는 것을 추천합니다.</p>
<p>h가 0에 수렴한다는 것을 알 때, f(x)의 기울기를 다음과 같이 표현할 수 있습니다:</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_6.png" alt="image"></p>
<p></p>
<p>아래와 같이 h를 다음 용어로 대체할 수 있습니다:</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_7.png" alt="image"></p>
<p>우리는 요소 알파를 정의하여 용어 h의 필요성을 유지합니다. 이때 알파는 엄격히 양수이어야 하며 항상 영에 수렴하여 h와 동일해야 합니다. 새로운 관계를 도함수의 정의식에 대입하면 다음과 같습니다:</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_8.png" alt="image"></p>
<p></p>
<p>우리는 증명을 위해 소중한 관계를 가지고 있습니다. 우리는 모든 요소를 제곱하면 양수가 될 것을 알고 있습니다. 이 개념에서 h를 f(x)의 gradient의 음수 알파로 대체해야 합니다.</p>
<p>그러므로:</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_9.png" alt="image"></p>
<p>따라서, 알파가 항상 양의 값을 갖는 한 (8)의 조건이 참임을 판단할 수 있습니다.</p>
<p></p>
<p>즉, x의 f(x) 값이 엄격히 양수인 값으로 뺀 값은 항상 f(x)의 원래 값보다 작을 것입니다. 따라서, 우리는 다음과 같은 관계로 대체할 수 있습니다. eq. (7)과 (9)를 사용하여:</p>
<p>따라서, 우리는 x의 값들을 업데이트하는 방법에 대한 증명된 관계가 있으며, 함수 f(x)가 이전 상태보다 적어도 작아지도록 할 수 있습니다.</p>
<p></p>
<p>이제 현재 x를 감소시켜 부등식 (11)을 만족시키는 방법을 알게 되었습니다:</p>
<p>이 관계가 유효한지 확인하려면 우리가 알고 있는 동작을 가진 img. (1) 함수 f(x, y)에이 방법론을 적용할 수 있습니다. 그래서:</p>
<p></p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_14.png" alt="image"></p>
<p>이 알고리즘을 함수 f(x, y)에 여러 번 적용하면 함수의 값이 최소값에 도달할 때까지 감소할 것으로 예상됩니다. 이를 위해 우리는 업데이트된 x와 y의 할당에 노이즈를 적용하여 f(x, y)의 값이 감소하는 것을 시각화한 시뮬레이션을 진행했습니다.</p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_15.png" alt="image"></p>
<p>알파 값이 0에 가까워질수록 x와 y의 값이 함수의 최솟값에 수렴하는 것을 관찰할 수 있습니다. 이러한 경우가 아닌 경우, 예를 들어 알파 = 0.6인 경우, 함수 f(x, y)의 최솟값을 찾는 데 어려움이 있는 것을 관찰할 수 있습니다.</p>
<p></p>
<h1>그라디언트 하강</h1>
<p>이 알고리즘은 "그라디언트 하강" 또는 "가파른 하강 방법"으로 알려져 있으며, 각 단계가 음의 그라디언트 방향으로 이루어지는 함수의 최솟값을 찾기 위한 최적화 방법입니다. 이 방법은 함수의 전역 최솟값을 찾을 수 있다는 것을 보장하지는 않지만, 지역 최솟값을 찾을 수 있습니다.</p>
<p>전역 최솟값을 찾는 데 대한 논의는 다른 문서에서 할 수 있지만, 여기서는 그래디언트가 이러한 목적으로 사용될 수 있는 수학적 방법을 설명했습니다.</p>
<p>이제 이를 가중치 w에 의존하는 비용 함수 E에 적용해 보겠습니다:</p>
<p></p>
<p>W를 기울기 하강법에 따라 모든 요소를 업데이트하려면 다음과 같이 합니다:</p>
<p>그리고 W 벡터의 모든 n번째 요소 𝑤에 대해서 다음과 같이 표시됩니다:</p>
<p></p>
<p><img src="/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_18.png" alt="이미지"></p>
<p>따라서, 우리는 이론적 학습 알고리즘을 갖고 있습니다. 논리적으로, 이는 요리사의 가상 아이디어에는 적용되지 않고 오늘날 우리가 알고 있는 다양한 머신 러닝 알고리즘에 적용됩니다.</p>
<h1>결론</h1>
<p>우리가 본 것을 바탕으로, 우리는 이론적 학습 알고리즘의 시연과 수학적 증명을 도출할 수 있습니다. 이러한 구조는 AdaGrad, Adam 및 확률적 경사 하강법 (SGD)과 같은 다양한 학습 방법에 적용됩니다.</p>
<p></p>
<p>이 방법은 비용 함수가 0 또는 매우 가까운 결과를 반환하는 n-가중치 w를 찾는 것을 보장하지는 않습니다. 그러나 비용 함수의 지역 최소값을 찾을 것을 보증합니다.</p>
<p>지역 최소값 문제를 해결하기 위해 SGD와 Adam과 같은 더 견고한 방법이 사용되고 있습니다. 이러한 방법들은 딥러닝에서 흔히 사용됩니다.</p>
<p>그럼에도 불구하고, 경사 하강법에 기반한 이론적 학습 알고리즘의 구조와 수학적 증명을 이해하면 더 복잡한 알고리즘의 이해에 도움이 될 것입니다.</p>
<h2>참고문헌</h2>
<p></p>
<p>Carreira-Perpinan, M. A., &#x26; Hinton, G. E. (2005). Contrastive divergence 학습에 대해. R. G. Cowell &#x26; Z. Ghahramani 편 (공저). 2005 인공지능과 통계. 33–41쪽. Fort Lauderdale, FL: Society for Artificial Intelligence and Statistics.</p>
<p>García Cabello, J. 수학적 신경망. Axioms 2022, 11, 80.</p>
<p>Geoffrey E. Hinton, Simon Osindero, Yee-Whye Teh. Deep Belief Nets를 위한 빠른 학습 알고리즘. Neural Computation 18, 1527–1554. Massachusetts Institute of Technology.</p>
<p>LeCun, Y., Bottou, L., &#x26; Haffner, P. (1998). 문서 인식에 적용된 Gradient-based 학습. IEEE 학회 논문집, 86(11), 2278–2324.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"기계 학습 AI에서의 학습 증명","description":"","date":"2024-05-18 20:13","slug":"2024-05-18-TheProofofLearninginMachineLearningAI","content":"\n## 수학적인 개발을 하기 전에, 먼저 학습의 기초를 이해하고 이것이 오류 개념과 얼마나 밀접하게 관련되어 있는지 알아야 합니다.\n\n# 가상의 요리사\n\n어느 날, 유명한 레스토랑에서 먹은 특별 요리를 복제하기로 결정했다고 상상해보세요. 그 특별 요리의 맛을 완벽하게 기억합니다. 이를 기반으로 온라인에서 레시피를 찾아 집에서 재현하려고 노력합니다.\n\n레스토랑에서 먹은 특별 요리의 맛을 T로 표시하겠습니다. 이는 기대되는 맛, 즉 당신의 목표를 나타냅니다. 온라인에서 찾은 레시피를 토대로 이 목표, 즉 맛 T를 달성하기를 희망합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 레시피를 재현하려면 지시된 모든 단계를 따라야 하고 모든 재료와 필요한 온도, 조리 시간 등을 사용해야 합니다. 이 모든 방법과 재료를 X로 표기해봅시다.\n\n전체 과정을 완료한 후 요리를 맛보게 됩니다. 이 때, 예상하는 맛 T와 유사한지 판단하게 됩니다. 예상보다 더 짠지 달콤한지에 대한 판단을 하게 되죠. 집에서 재현한 요리의 맛은 Y로 표현됩니다.\n\n따라서, 목표인 T와 다른 맛을 느꼈을 때, 맛 Y를 기반으로 목표 맛과 얼마나 다른지를 양적으로 평가합니다. 다시 말해 더 많은 소금을 넣었을 수도 있고, 더 적게 향신료를 넣었을 수도 있습니다.\n\nT와 Y 간의 차이를 오차 E로 정의할 수 있습니다. T와 Y의 차이는 여러분의 입맛 기억을 통해 이루어지죠. 따라서 이 순간 여러분의 입맛은 특정 기능을 수행하며, 이를 P(Y) = E로 정의할 수 있습니다. 다시 말해 맛 Y를 경험할 때, 입맛은 목표 맛 T를 기준으로 오차를 할당합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nQuantitative measure of error E가 있으면 매일 동일한 레시피를 복제하여 매일매일 오차 E가 줄어듭니다. 다른 말로, 목표하는 맛 T와 실제 맛 Y 사이의 거리가 T = Y가 될 때까지 줄어듭니다.\n\n이 가상 시나리오를 기반으로하면, 오류를 관찰된 현실과 다르게 판단하는 것으로 정의할 수 있으며, 항상 판단 작업을 수행하는 기능이 있습니다. 따라서 위의 경우에는 맛과 기억이 이 판단 기능을 만들었습니다.\n\n특정한 경우에서의 학습 행위는 주로 오류를 줄이는 능력으로 특징 지어집니다. 다시 말해, 이는 판단 함수의 출력을 줄이기 위해 복제 된 객체와 다양한 방식으로 상호 작용하는 능력입니다.\n\n# 요리사의 전문지식\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n가정의 경우로 돌아와서, 우리는 레시피에 나와 있는 재료와 방법 X를 가지고 있습니다. 모든 재료와 장비는 레스토랑에서 사용된 것과 동일하며, 결과는 목표하는 맛 T를 달성하기 위해 그것들을 올바르게 다룰 수 있는 당신의 능력에만 달려 있습니다.\n\n다시 말해서, 당신은 X를 조작하여 Y를 얻는 것입니다. 따라서 당신이 본질적으로 X를 Y로 변환하는 함수라고 정의할 수 있습니다. 이를 f(X) = Y로 표기합니다.\n\n재료를 다루는 행위를 나타내는 함수 f(X)는 또한 당신의 뇌가 어떻게 작용하는지에 따라 달라집니다. 다시 말해, 만약 당신이 요리 경험이 있다면, X를 Y로 변환하는 것이 더 쉬울 것입니다.\n\n이제 우리는 당신의 뉴런의 가중치 W 또는 X를 다루는 신경 능력을 정의해 봅시다. W가 요리 경험에 기반하여 이미 사전에 조정되어 있다면, X를 Y로 변환하는 것이 더 쉬울 것입니다. 그렇지 않으면, X를 Y로 변환할 수 있을 때까지 W를 조정해야 할 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서 우리는 f(X) = Y가 W에도 의존한다는 것을 알 수 있습니다, 즉 우리는 f(X) = WX로 선형적으로 표현할 수 있습니다.\n\n그래서, 우리의 목표는 생성된 Y가 매우 가깝거나 T와 동일해질 때까지 W를 어떻게 수정할 수 있는지 알아내는 것입니다. 다시 말해, 오차 E가 크게 감소하거나 0이 될 때까지 W를 어떻게 조절할 수 있는지 입니다.\n\n# 비용 함수\n\n결과와 기대 결과 간의 차이를 평가하는 함수가 비용 함수입니다. 재료와 조리 방법을 솜씨 좋게 바꾸는 함수가 바로 우리의 모델인데요, 이는 인공 신경망 또는 다른 머신러닝 모델일 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![The Proof of Learning in Machine Learning AI 0](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_0.png)\n\nIn equation (1), the definition of the cost function E, which depends on the n weights w. In other words, it is a function that indicates the error based on the values of w. In a specific case where all n weights w are not adjusted, the value of the error E will be large. Conversely, in a case where the weights are properly adjusted, the value of the error E will be small or zero.\n\n![The Proof of Learning in Machine Learning AI 1](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_1.png)\n\nTherefore, our objective is to find the values of the n weights w such that the condition above is true.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 그래디언트\n\n이 작업을 수행하는 방법을 이해하는 데 도움이 되도록 다음 함수를 정의합니다:\n\n![function](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_2.png)\n\n따라서 x = 0이고 y = 0일 때 f(x, y) = 0임은 직관적으로 알 수 있습니다. 그러나 우리는 무작위로 선택된 x와 y 값이 주어졌을 때, x와 y의 값을 조정하여 함수 f(x, y)가 0이 되도록 하는 알고리즘을 원합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위 작업을 수행하기 위해 함수의 그래디언트를 사용할 수 있습니다. 벡터 미적분학에서 그래디언트는 특정 지점으로부터 변위함으로써 어떤 양의 값을 최대로 증가시킬 수 있는 방향과 크기를 나타내는 벡터입니다.\n\n![이미지](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_3.png)\n\n즉, 함수 f(x, y)에 그래디언트를 적용하면 식(3)에 나타난 대로 x와 y의 값을 어떻게 증가시켜야 f(x, y)의 값이 증가하는지 알려주는 벡터를 얻을 수 있습니다. 그러나 우리의 목표는 함수 f(x, y) = 0의 값을 찾는 것입니다. 따라서 우리는 음의 그래디언트를 사용할 수 있습니다.\n\n아래는 함수 f(x, y)의 두 차원 표현이며 색상이 z의 값을 보여줍니다. 음의 그래디언트를 사용하여 함수의 최솟값을 가리키는 벡터들을 볼 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_4.png)\n\n이에 따라 f(x, y) 함수의 그래디언트 필드를 사용하여 x와 y를 업데이트하는 방법을 개발할 수 있습니다. 이를 통해 f(x, y) = 0을 찾는 데 필요한 값을 찾을 수 있습니다.\n\n# 학습의 증명\n\n알고리즘 테스트를 위한 간단한 함수 f(x)를 정의하겠습니다. 저희의 의도는 이 함수의 최솟값을 찾는 것입니다. 이를 위해 f(x)의 그래디언트를 적용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 함수 f(x)의 기울기입니다. 이 글에서는 미분의 개념을 깊게 다루지는 않겠지만, 이렇게 표현할 수 있는 이유에 대해 정의와 함께 읽는 것을 추천합니다.\n\nh가 0에 수렴한다는 것을 알 때, f(x)의 기울기를 다음과 같이 표현할 수 있습니다:\n\n![image](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_6.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래와 같이 h를 다음 용어로 대체할 수 있습니다:\n\n![image](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_7.png)\n\n우리는 요소 알파를 정의하여 용어 h의 필요성을 유지합니다. 이때 알파는 엄격히 양수이어야 하며 항상 영에 수렴하여 h와 동일해야 합니다. 새로운 관계를 도함수의 정의식에 대입하면 다음과 같습니다:\n\n![image](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_8.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n우리는 증명을 위해 소중한 관계를 가지고 있습니다. 우리는 모든 요소를 제곱하면 양수가 될 것을 알고 있습니다. 이 개념에서 h를 f(x)의 gradient의 음수 알파로 대체해야 합니다.\n\n그러므로:\n\n![image](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_9.png)\n\n따라서, 알파가 항상 양의 값을 갖는 한 (8)의 조건이 참임을 판단할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_10.png\" /\u003e\n\n즉, x의 f(x) 값이 엄격히 양수인 값으로 뺀 값은 항상 f(x)의 원래 값보다 작을 것입니다. 따라서, 우리는 다음과 같은 관계로 대체할 수 있습니다. eq. (7)과 (9)를 사용하여:\n\n\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_11.png\" /\u003e\n\n따라서, 우리는 x의 값들을 업데이트하는 방법에 대한 증명된 관계가 있으며, 함수 f(x)가 이전 상태보다 적어도 작아지도록 할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_12.png\" /\u003e\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n이제 현재 x를 감소시켜 부등식 (11)을 만족시키는 방법을 알게 되었습니다:\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_13.png\" /\u003e\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n이 관계가 유효한지 확인하려면 우리가 알고 있는 동작을 가진 img. (1) 함수 f(x, y)에이 방법론을 적용할 수 있습니다. 그래서:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![image](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_14.png)\n\n이 알고리즘을 함수 f(x, y)에 여러 번 적용하면 함수의 값이 최소값에 도달할 때까지 감소할 것으로 예상됩니다. 이를 위해 우리는 업데이트된 x와 y의 할당에 노이즈를 적용하여 f(x, y)의 값이 감소하는 것을 시각화한 시뮬레이션을 진행했습니다.\n\n![image](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_15.png)\n\n알파 값이 0에 가까워질수록 x와 y의 값이 함수의 최솟값에 수렴하는 것을 관찰할 수 있습니다. 이러한 경우가 아닌 경우, 예를 들어 알파 = 0.6인 경우, 함수 f(x, y)의 최솟값을 찾는 데 어려움이 있는 것을 관찰할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 그라디언트 하강\n\n이 알고리즘은 \"그라디언트 하강\" 또는 \"가파른 하강 방법\"으로 알려져 있으며, 각 단계가 음의 그라디언트 방향으로 이루어지는 함수의 최솟값을 찾기 위한 최적화 방법입니다. 이 방법은 함수의 전역 최솟값을 찾을 수 있다는 것을 보장하지는 않지만, 지역 최솟값을 찾을 수 있습니다.\n\n전역 최솟값을 찾는 데 대한 논의는 다른 문서에서 할 수 있지만, 여기서는 그래디언트가 이러한 목적으로 사용될 수 있는 수학적 방법을 설명했습니다.\n\n이제 이를 가중치 w에 의존하는 비용 함수 E에 적용해 보겠습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_16.png\" /\u003e\n\nW를 기울기 하강법에 따라 모든 요소를 업데이트하려면 다음과 같이 합니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_17.png\" /\u003e\n\n그리고 W 벡터의 모든 n번째 요소 𝑤에 대해서 다음과 같이 표시됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_18.png)\n\n따라서, 우리는 이론적 학습 알고리즘을 갖고 있습니다. 논리적으로, 이는 요리사의 가상 아이디어에는 적용되지 않고 오늘날 우리가 알고 있는 다양한 머신 러닝 알고리즘에 적용됩니다.\n\n# 결론\n\n우리가 본 것을 바탕으로, 우리는 이론적 학습 알고리즘의 시연과 수학적 증명을 도출할 수 있습니다. 이러한 구조는 AdaGrad, Adam 및 확률적 경사 하강법 (SGD)과 같은 다양한 학습 방법에 적용됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 방법은 비용 함수가 0 또는 매우 가까운 결과를 반환하는 n-가중치 w를 찾는 것을 보장하지는 않습니다. 그러나 비용 함수의 지역 최소값을 찾을 것을 보증합니다.\n\n지역 최소값 문제를 해결하기 위해 SGD와 Adam과 같은 더 견고한 방법이 사용되고 있습니다. 이러한 방법들은 딥러닝에서 흔히 사용됩니다.\n\n그럼에도 불구하고, 경사 하강법에 기반한 이론적 학습 알고리즘의 구조와 수학적 증명을 이해하면 더 복잡한 알고리즘의 이해에 도움이 될 것입니다.\n\n## 참고문헌\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nCarreira-Perpinan, M. A., \u0026 Hinton, G. E. (2005). Contrastive divergence 학습에 대해. R. G. Cowell \u0026 Z. Ghahramani 편 (공저). 2005 인공지능과 통계. 33–41쪽. Fort Lauderdale, FL: Society for Artificial Intelligence and Statistics.\n\nGarcía Cabello, J. 수학적 신경망. Axioms 2022, 11, 80.\n\nGeoffrey E. Hinton, Simon Osindero, Yee-Whye Teh. Deep Belief Nets를 위한 빠른 학습 알고리즘. Neural Computation 18, 1527–1554. Massachusetts Institute of Technology.\n\nLeCun, Y., Bottou, L., \u0026 Haffner, P. (1998). 문서 인식에 적용된 Gradient-based 학습. IEEE 학회 논문집, 86(11), 2278–2324.\n","ogImage":{"url":"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_0.png"},"coverImage":"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_0.png","tag":["Tech"],"readingTime":13},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch2\u003e수학적인 개발을 하기 전에, 먼저 학습의 기초를 이해하고 이것이 오류 개념과 얼마나 밀접하게 관련되어 있는지 알아야 합니다.\u003c/h2\u003e\n\u003ch1\u003e가상의 요리사\u003c/h1\u003e\n\u003cp\u003e어느 날, 유명한 레스토랑에서 먹은 특별 요리를 복제하기로 결정했다고 상상해보세요. 그 특별 요리의 맛을 완벽하게 기억합니다. 이를 기반으로 온라인에서 레시피를 찾아 집에서 재현하려고 노력합니다.\u003c/p\u003e\n\u003cp\u003e레스토랑에서 먹은 특별 요리의 맛을 T로 표시하겠습니다. 이는 기대되는 맛, 즉 당신의 목표를 나타냅니다. 온라인에서 찾은 레시피를 토대로 이 목표, 즉 맛 T를 달성하기를 희망합니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이 레시피를 재현하려면 지시된 모든 단계를 따라야 하고 모든 재료와 필요한 온도, 조리 시간 등을 사용해야 합니다. 이 모든 방법과 재료를 X로 표기해봅시다.\u003c/p\u003e\n\u003cp\u003e전체 과정을 완료한 후 요리를 맛보게 됩니다. 이 때, 예상하는 맛 T와 유사한지 판단하게 됩니다. 예상보다 더 짠지 달콤한지에 대한 판단을 하게 되죠. 집에서 재현한 요리의 맛은 Y로 표현됩니다.\u003c/p\u003e\n\u003cp\u003e따라서, 목표인 T와 다른 맛을 느꼈을 때, 맛 Y를 기반으로 목표 맛과 얼마나 다른지를 양적으로 평가합니다. 다시 말해 더 많은 소금을 넣었을 수도 있고, 더 적게 향신료를 넣었을 수도 있습니다.\u003c/p\u003e\n\u003cp\u003eT와 Y 간의 차이를 오차 E로 정의할 수 있습니다. T와 Y의 차이는 여러분의 입맛 기억을 통해 이루어지죠. 따라서 이 순간 여러분의 입맛은 특정 기능을 수행하며, 이를 P(Y) = E로 정의할 수 있습니다. 다시 말해 맛 Y를 경험할 때, 입맛은 목표 맛 T를 기준으로 오차를 할당합니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003eQuantitative measure of error E가 있으면 매일 동일한 레시피를 복제하여 매일매일 오차 E가 줄어듭니다. 다른 말로, 목표하는 맛 T와 실제 맛 Y 사이의 거리가 T = Y가 될 때까지 줄어듭니다.\u003c/p\u003e\n\u003cp\u003e이 가상 시나리오를 기반으로하면, 오류를 관찰된 현실과 다르게 판단하는 것으로 정의할 수 있으며, 항상 판단 작업을 수행하는 기능이 있습니다. 따라서 위의 경우에는 맛과 기억이 이 판단 기능을 만들었습니다.\u003c/p\u003e\n\u003cp\u003e특정한 경우에서의 학습 행위는 주로 오류를 줄이는 능력으로 특징 지어집니다. 다시 말해, 이는 판단 함수의 출력을 줄이기 위해 복제 된 객체와 다양한 방식으로 상호 작용하는 능력입니다.\u003c/p\u003e\n\u003ch1\u003e요리사의 전문지식\u003c/h1\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e가정의 경우로 돌아와서, 우리는 레시피에 나와 있는 재료와 방법 X를 가지고 있습니다. 모든 재료와 장비는 레스토랑에서 사용된 것과 동일하며, 결과는 목표하는 맛 T를 달성하기 위해 그것들을 올바르게 다룰 수 있는 당신의 능력에만 달려 있습니다.\u003c/p\u003e\n\u003cp\u003e다시 말해서, 당신은 X를 조작하여 Y를 얻는 것입니다. 따라서 당신이 본질적으로 X를 Y로 변환하는 함수라고 정의할 수 있습니다. 이를 f(X) = Y로 표기합니다.\u003c/p\u003e\n\u003cp\u003e재료를 다루는 행위를 나타내는 함수 f(X)는 또한 당신의 뇌가 어떻게 작용하는지에 따라 달라집니다. 다시 말해, 만약 당신이 요리 경험이 있다면, X를 Y로 변환하는 것이 더 쉬울 것입니다.\u003c/p\u003e\n\u003cp\u003e이제 우리는 당신의 뉴런의 가중치 W 또는 X를 다루는 신경 능력을 정의해 봅시다. W가 요리 경험에 기반하여 이미 사전에 조정되어 있다면, X를 Y로 변환하는 것이 더 쉬울 것입니다. 그렇지 않으면, X를 Y로 변환할 수 있을 때까지 W를 조정해야 할 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e따라서 우리는 f(X) = Y가 W에도 의존한다는 것을 알 수 있습니다, 즉 우리는 f(X) = WX로 선형적으로 표현할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e그래서, 우리의 목표는 생성된 Y가 매우 가깝거나 T와 동일해질 때까지 W를 어떻게 수정할 수 있는지 알아내는 것입니다. 다시 말해, 오차 E가 크게 감소하거나 0이 될 때까지 W를 어떻게 조절할 수 있는지 입니다.\u003c/p\u003e\n\u003ch1\u003e비용 함수\u003c/h1\u003e\n\u003cp\u003e결과와 기대 결과 간의 차이를 평가하는 함수가 비용 함수입니다. 재료와 조리 방법을 솜씨 좋게 바꾸는 함수가 바로 우리의 모델인데요, 이는 인공 신경망 또는 다른 머신러닝 모델일 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_0.png\" alt=\"The Proof of Learning in Machine Learning AI 0\"\u003e\u003c/p\u003e\n\u003cp\u003eIn equation (1), the definition of the cost function E, which depends on the n weights w. In other words, it is a function that indicates the error based on the values of w. In a specific case where all n weights w are not adjusted, the value of the error E will be large. Conversely, in a case where the weights are properly adjusted, the value of the error E will be small or zero.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_1.png\" alt=\"The Proof of Learning in Machine Learning AI 1\"\u003e\u003c/p\u003e\n\u003cp\u003eTherefore, our objective is to find the values of the n weights w such that the condition above is true.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003ch1\u003e그래디언트\u003c/h1\u003e\n\u003cp\u003e이 작업을 수행하는 방법을 이해하는 데 도움이 되도록 다음 함수를 정의합니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_2.png\" alt=\"function\"\u003e\u003c/p\u003e\n\u003cp\u003e따라서 x = 0이고 y = 0일 때 f(x, y) = 0임은 직관적으로 알 수 있습니다. 그러나 우리는 무작위로 선택된 x와 y 값이 주어졌을 때, x와 y의 값을 조정하여 함수 f(x, y)가 0이 되도록 하는 알고리즘을 원합니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e위 작업을 수행하기 위해 함수의 그래디언트를 사용할 수 있습니다. 벡터 미적분학에서 그래디언트는 특정 지점으로부터 변위함으로써 어떤 양의 값을 최대로 증가시킬 수 있는 방향과 크기를 나타내는 벡터입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e즉, 함수 f(x, y)에 그래디언트를 적용하면 식(3)에 나타난 대로 x와 y의 값을 어떻게 증가시켜야 f(x, y)의 값이 증가하는지 알려주는 벡터를 얻을 수 있습니다. 그러나 우리의 목표는 함수 f(x, y) = 0의 값을 찾는 것입니다. 따라서 우리는 음의 그래디언트를 사용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e아래는 함수 f(x, y)의 두 차원 표현이며 색상이 z의 값을 보여줍니다. 음의 그래디언트를 사용하여 함수의 최솟값을 가리키는 벡터들을 볼 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_4.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e이에 따라 f(x, y) 함수의 그래디언트 필드를 사용하여 x와 y를 업데이트하는 방법을 개발할 수 있습니다. 이를 통해 f(x, y) = 0을 찾는 데 필요한 값을 찾을 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e학습의 증명\u003c/h1\u003e\n\u003cp\u003e알고리즘 테스트를 위한 간단한 함수 f(x)를 정의하겠습니다. 저희의 의도는 이 함수의 최솟값을 찾는 것입니다. 이를 위해 f(x)의 그래디언트를 적용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e아래는 함수 f(x)의 기울기입니다. 이 글에서는 미분의 개념을 깊게 다루지는 않겠지만, 이렇게 표현할 수 있는 이유에 대해 정의와 함께 읽는 것을 추천합니다.\u003c/p\u003e\n\u003cp\u003eh가 0에 수렴한다는 것을 알 때, f(x)의 기울기를 다음과 같이 표현할 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_6.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e아래와 같이 h를 다음 용어로 대체할 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_7.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e우리는 요소 알파를 정의하여 용어 h의 필요성을 유지합니다. 이때 알파는 엄격히 양수이어야 하며 항상 영에 수렴하여 h와 동일해야 합니다. 새로운 관계를 도함수의 정의식에 대입하면 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_8.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e우리는 증명을 위해 소중한 관계를 가지고 있습니다. 우리는 모든 요소를 제곱하면 양수가 될 것을 알고 있습니다. 이 개념에서 h를 f(x)의 gradient의 음수 알파로 대체해야 합니다.\u003c/p\u003e\n\u003cp\u003e그러므로:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_9.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e따라서, 알파가 항상 양의 값을 갖는 한 (8)의 조건이 참임을 판단할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e즉, x의 f(x) 값이 엄격히 양수인 값으로 뺀 값은 항상 f(x)의 원래 값보다 작을 것입니다. 따라서, 우리는 다음과 같은 관계로 대체할 수 있습니다. eq. (7)과 (9)를 사용하여:\u003c/p\u003e\n\u003cp\u003e따라서, 우리는 x의 값들을 업데이트하는 방법에 대한 증명된 관계가 있으며, 함수 f(x)가 이전 상태보다 적어도 작아지도록 할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이제 현재 x를 감소시켜 부등식 (11)을 만족시키는 방법을 알게 되었습니다:\u003c/p\u003e\n\u003cp\u003e이 관계가 유효한지 확인하려면 우리가 알고 있는 동작을 가진 img. (1) 함수 f(x, y)에이 방법론을 적용할 수 있습니다. 그래서:\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_14.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e이 알고리즘을 함수 f(x, y)에 여러 번 적용하면 함수의 값이 최소값에 도달할 때까지 감소할 것으로 예상됩니다. 이를 위해 우리는 업데이트된 x와 y의 할당에 노이즈를 적용하여 f(x, y)의 값이 감소하는 것을 시각화한 시뮬레이션을 진행했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_15.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e알파 값이 0에 가까워질수록 x와 y의 값이 함수의 최솟값에 수렴하는 것을 관찰할 수 있습니다. 이러한 경우가 아닌 경우, 예를 들어 알파 = 0.6인 경우, 함수 f(x, y)의 최솟값을 찾는 데 어려움이 있는 것을 관찰할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003ch1\u003e그라디언트 하강\u003c/h1\u003e\n\u003cp\u003e이 알고리즘은 \"그라디언트 하강\" 또는 \"가파른 하강 방법\"으로 알려져 있으며, 각 단계가 음의 그라디언트 방향으로 이루어지는 함수의 최솟값을 찾기 위한 최적화 방법입니다. 이 방법은 함수의 전역 최솟값을 찾을 수 있다는 것을 보장하지는 않지만, 지역 최솟값을 찾을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e전역 최솟값을 찾는 데 대한 논의는 다른 문서에서 할 수 있지만, 여기서는 그래디언트가 이러한 목적으로 사용될 수 있는 수학적 방법을 설명했습니다.\u003c/p\u003e\n\u003cp\u003e이제 이를 가중치 w에 의존하는 비용 함수 E에 적용해 보겠습니다:\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003eW를 기울기 하강법에 따라 모든 요소를 업데이트하려면 다음과 같이 합니다:\u003c/p\u003e\n\u003cp\u003e그리고 W 벡터의 모든 n번째 요소 𝑤에 대해서 다음과 같이 표시됩니다:\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-TheProofofLearninginMachineLearningAI_18.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e따라서, 우리는 이론적 학습 알고리즘을 갖고 있습니다. 논리적으로, 이는 요리사의 가상 아이디어에는 적용되지 않고 오늘날 우리가 알고 있는 다양한 머신 러닝 알고리즘에 적용됩니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e우리가 본 것을 바탕으로, 우리는 이론적 학습 알고리즘의 시연과 수학적 증명을 도출할 수 있습니다. 이러한 구조는 AdaGrad, Adam 및 확률적 경사 하강법 (SGD)과 같은 다양한 학습 방법에 적용됩니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이 방법은 비용 함수가 0 또는 매우 가까운 결과를 반환하는 n-가중치 w를 찾는 것을 보장하지는 않습니다. 그러나 비용 함수의 지역 최소값을 찾을 것을 보증합니다.\u003c/p\u003e\n\u003cp\u003e지역 최소값 문제를 해결하기 위해 SGD와 Adam과 같은 더 견고한 방법이 사용되고 있습니다. 이러한 방법들은 딥러닝에서 흔히 사용됩니다.\u003c/p\u003e\n\u003cp\u003e그럼에도 불구하고, 경사 하강법에 기반한 이론적 학습 알고리즘의 구조와 수학적 증명을 이해하면 더 복잡한 알고리즘의 이해에 도움이 될 것입니다.\u003c/p\u003e\n\u003ch2\u003e참고문헌\u003c/h2\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003eCarreira-Perpinan, M. A., \u0026#x26; Hinton, G. E. (2005). Contrastive divergence 학습에 대해. R. G. Cowell \u0026#x26; Z. Ghahramani 편 (공저). 2005 인공지능과 통계. 33–41쪽. Fort Lauderdale, FL: Society for Artificial Intelligence and Statistics.\u003c/p\u003e\n\u003cp\u003eGarcía Cabello, J. 수학적 신경망. Axioms 2022, 11, 80.\u003c/p\u003e\n\u003cp\u003eGeoffrey E. Hinton, Simon Osindero, Yee-Whye Teh. Deep Belief Nets를 위한 빠른 학습 알고리즘. Neural Computation 18, 1527–1554. Massachusetts Institute of Technology.\u003c/p\u003e\n\u003cp\u003eLeCun, Y., Bottou, L., \u0026#x26; Haffner, P. (1998). 문서 인식에 적용된 Gradient-based 학습. IEEE 학회 논문집, 86(11), 2278–2324.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-18-TheProofofLearninginMachineLearningAI"},"buildId":"bb_yO9GbCvdfc_n71SfUf","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>