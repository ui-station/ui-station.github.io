<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Postgres RDS가 빅데이터 솔루션 구현에 적합하지 않은 이유 우리가 겪은 문제 및 해결방안 포함 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Postgres RDS가 빅데이터 솔루션 구현에 적합하지 않은 이유 우리가 겪은 문제 및 해결방안 포함 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="Postgres RDS가 빅데이터 솔루션 구현에 적합하지 않은 이유 우리가 겪은 문제 및 해결방안 포함 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution" data-gatsby-head="true"/><meta name="twitter:title" content="Postgres RDS가 빅데이터 솔루션 구현에 적합하지 않은 이유 우리가 겪은 문제 및 해결방안 포함 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 22:37" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_buildManifest.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Postgres RDS가 빅데이터 솔루션 구현에 적합하지 않은 이유 우리가 겪은 문제 및 해결방안 포함</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Postgres RDS가 빅데이터 솔루션 구현에 적합하지 않은 이유 우리가 겪은 문제 및 해결방안 포함" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h1>배경</h1>
<p>우리는 마케팅 효과를 통계적으로 측정하는 스타트업을 만들고 있었습니다. 이를 위해 온라인 사용자 행동에 대한 많은 데이터를 수집해야 했습니다. 모든 클릭, 모든 입력 필드, 모든 액션을 모으는 작업이 필요했습니다. 데이터는 포스트그레스에 저장되었고, 최종 사용자들은 UI를 통해 상기 (때로는 매우 큰) 데이터 집합을 분석하는 대시보드 및 보고서를 실행했습니다. 여러 테넌트를 지원하는 멀티 테넌트 SAAS 애플리케이션을 구축하고 있기 때문에 데이터는 수백 개의 테넌트별로 수집되고 저장되었습니다. 이 시스템은 확장 가능하고 성능이 좋아야 했습니다. 우리는 AWS RDS 관리형 포스트그레SQL로 시작했습니다.</p>
<p><img src="/assets/img/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution_0.png" alt="이미지"></p>
<h1>EBS와 관련된 큰 문제: 처리량 투명성</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>EBS의 처리량을 정확하게 측정하는 것은 거의 불가능합니다. AWS가 제공하는 지표는 지연 시간과 IOPS입니다. 이 둘 다 처리량을 측정하는 방법은 제공하지 않습니다. 디스크에 10GB의 크기를 가지는 시간 순서 테이블(예: 2000만 개 행)을 저장하고 테이블을 스캔하려고 할 때(어떤 이유로든 - 예를 들어 순차 스캔이 필요한 경우) 디스크에서 데이터를 스캔하는 데 얼마나 오랜 시간이 걸릴지 이해하려면 처리량을 정확히 측정해야 합니다.</p>
<h1>폭발과 제한된 IOPS - 사태의 시작</h1>
<p>위의 쿼리와 같은 작업들은 IO 크레딧을 빨리 소진시킵니다. 우리는 더 많은 IOPS를 원하기 때문에 어떻게 해야 할까요? 당연히 스토리지 볼륨을 늘려서 작은 볼륨으로부터 얻을 수 있는 3000 IOPS보다 높은 10000 IOPS 기본선을 얻을 수 있도록 합니다. 하지만 백업 비용이 증가하게 되고, 전체 볼륨을 지불하게 되므로 비용이 증가합니다. 비용은 증가하는데 성능이 거의 개선되지 않는다 - 이러한 상황은 더 악화됩니다.</p>
<p>우리는 또한 캐싱을 위해 더 많은 메모리를 얻기 위해 인스턴스 크기를 계속해서 늘렸습니다. 모든 것을 메모리에 맞게 만들면 DB를 빠르게 만드는 것이 쉽습니다. 불행히도 PG v10에서 제공되는 더 큰 병렬 처리는 IO 제한 때문에 실제로 많은 혜택을 가져다주지 않았습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>쓰루풋을 측정하는 데 문제가 있는 내용은 여기에서 자세히 설명되어 있습니다:</p>
<p><a href="https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/" rel="nofollow" target="_blank">https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/</a></p>
<h1>Aurora</h1>
<p>그래서 우리는 Aurora로 마이그레이션했습니다. 표준 PostgreSQL 대비 5~7배의 성능 향상을 약속받을 수 있다는 것은 놓칠 수 없는 이점입니다. 그러나 이러한 성능 메트릭은 pgbench를 기반으로 하고 있습니다 (PostgreSQL의 경우). 대규모 데이터 집합 및 데이터 마이닝 작업에 대한 성능 지표로는 적합하지 않지만 수많은 병렬 클라이언트와 함께 트랜잭션의 속도(또는 지연 시간)를 측정하고 싶은 OLTP 시스템이 있다면 이러한 결과는 훌륭합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>비용이 줄어들었는데 오히려 올라갔어요.</p>
<p>이 글에서는 IOPS 및 요금 청구 가능한 IOPS에 관한 내용이 있습니다. <a href="https://forums.aws.amazon.com/message.jspa?messageID=835303#835303" rel="nofollow" target="_blank">https://forums.aws.amazon.com/message.jspa?messageID=835303#835303</a></p>
<p>다시 한 번 가장 큰 답답함은 처리량의 정확한 측정을 얻는 데 있었습니다. 단순히 tack_io_timing을 사용하여 스캔된 데이터 양을 시간으로 나눈 것을 보면, 대규모 데이터셋에 대한 성능이 SSD 속도처럼이 아니라 자기 디스크와 유사하다는 것을 알 수 있습니다.</p>
<p>부담스럽게 느껴지는 것 중 하나는 지원과의 끝없는 시간입니다. 지원 직원은 항상 매우 지식이 풍부하고 도움이 되려는 자세였지만, 항상 쿼리 조정이나 DB 조정에 차질이 생겼습니다. 다시 말해서 처리량에 관한 문제로 돌아왔죠. "귀하의 작업 부하에 고려해 보기에는 이 서비스를 선택하는 것이 좋지 않다."는 말을 듣고 싶어했지만, 결국 우리 스스로 그것을 해결해야 했습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>해결책: 직접 만들어보세요</h1>
<p>저희에게는 해결책이 꽤 간단했습니다. 관리형 데이터베이스 서비스를 사용하지 말고 EC2에서 직접 인프라를 구축했어요.</p>
<p>저희는 상대적으로 저사양의 EC2 인스턴스(저희는 RDS에서 4XL을 실행 중이었습니다) xl과 2xl을 사용했어요.</p>
<p>중요한 점은 마스터와 스탠바이 레플리카 간의 READ 및 WRITE 워크로드를 분리하는 것이었고, 이를 위해 WAL-G(<a href="https://github.com/wal-g/wal-g)%EB%A5%BC" rel="nofollow" target="_blank">https://github.com/wal-g/wal-g)를</a> 사용하여 최신 상태를 유지하는 것이었습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>WRITE 노드는 데이터를 처리하기만 하므로 EBS가 충분했지만 ZFS를 사용하여 EBS 처리량을 2배로 늘릴 수 있었습니다.</p>
<p>READ 노드의 경우 일시적인 NVMe 드라이브와 다시 한 번 ZFS를 사용하여 성능을 향상시켰습니다.</p>
<p>결과가 자연스럽게 이야기해줍니다:</p>
<p>비용이 $11K에서 $2100으로 감소했습니다(9월에 예상되는 첫 번째 RDS 부담이 없는 완전한 한 달을 기준으로).</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>아주 길고 끝이 나지 않을 쿼리도 몇 시간이 걸리거나 완전히 시간초과될 정도로 실행되던 것이 몇 초만에 완료되었어요.</p>
<p>유닉스 인스턴스에서 명령 줄 도구(zpool iostat)를 사용하여 실제 처리량을 측정할 수 있습니다.</p>
<h1>결론</h1>
<p>인스턴스를 시작하고 백업과 복구에 대해 걱정하지 않고 한 번 클릭하면 편리할 수 있지만, 이는 저희의 경우에는 비용과 성능 측면에서 비용이 발생합니다. TB 또는 GB 데이터를 처리하는 데 실제 속도가 필요하다면 베어 메탈을 사용하십시오. 베어 메탈을 사용할 수 없다면 NVMe 드라이브가 장착된 EC2를 사용하는 것이 다음으로 좋은 방법입니다. NVMe 드라이브가 장착된 인스턴스를 사용하여 AWS에서 자체 Postgres 클러스터를 시작하는 방법에 대한 조리법을 제공하는 부분 두 번째를 읽어보세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Postgres RDS가 빅데이터 솔루션 구현에 적합하지 않은 이유 우리가 겪은 문제 및 해결방안 포함","description":"","date":"2024-06-23 22:37","slug":"2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution","content":"\n# 배경\n\n우리는 마케팅 효과를 통계적으로 측정하는 스타트업을 만들고 있었습니다. 이를 위해 온라인 사용자 행동에 대한 많은 데이터를 수집해야 했습니다. 모든 클릭, 모든 입력 필드, 모든 액션을 모으는 작업이 필요했습니다. 데이터는 포스트그레스에 저장되었고, 최종 사용자들은 UI를 통해 상기 (때로는 매우 큰) 데이터 집합을 분석하는 대시보드 및 보고서를 실행했습니다. 여러 테넌트를 지원하는 멀티 테넌트 SAAS 애플리케이션을 구축하고 있기 때문에 데이터는 수백 개의 테넌트별로 수집되고 저장되었습니다. 이 시스템은 확장 가능하고 성능이 좋아야 했습니다. 우리는 AWS RDS 관리형 포스트그레SQL로 시작했습니다.\n\n![이미지](/assets/img/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution_0.png)\n\n# EBS와 관련된 큰 문제: 처리량 투명성\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nEBS의 처리량을 정확하게 측정하는 것은 거의 불가능합니다. AWS가 제공하는 지표는 지연 시간과 IOPS입니다. 이 둘 다 처리량을 측정하는 방법은 제공하지 않습니다. 디스크에 10GB의 크기를 가지는 시간 순서 테이블(예: 2000만 개 행)을 저장하고 테이블을 스캔하려고 할 때(어떤 이유로든 - 예를 들어 순차 스캔이 필요한 경우) 디스크에서 데이터를 스캔하는 데 얼마나 오랜 시간이 걸릴지 이해하려면 처리량을 정확히 측정해야 합니다.\n\n# 폭발과 제한된 IOPS - 사태의 시작\n\n위의 쿼리와 같은 작업들은 IO 크레딧을 빨리 소진시킵니다. 우리는 더 많은 IOPS를 원하기 때문에 어떻게 해야 할까요? 당연히 스토리지 볼륨을 늘려서 작은 볼륨으로부터 얻을 수 있는 3000 IOPS보다 높은 10000 IOPS 기본선을 얻을 수 있도록 합니다. 하지만 백업 비용이 증가하게 되고, 전체 볼륨을 지불하게 되므로 비용이 증가합니다. 비용은 증가하는데 성능이 거의 개선되지 않는다 - 이러한 상황은 더 악화됩니다.\n\n우리는 또한 캐싱을 위해 더 많은 메모리를 얻기 위해 인스턴스 크기를 계속해서 늘렸습니다. 모든 것을 메모리에 맞게 만들면 DB를 빠르게 만드는 것이 쉽습니다. 불행히도 PG v10에서 제공되는 더 큰 병렬 처리는 IO 제한 때문에 실제로 많은 혜택을 가져다주지 않았습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n쓰루풋을 측정하는 데 문제가 있는 내용은 여기에서 자세히 설명되어 있습니다:\n\n[https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/](https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/)\n\n# Aurora\n\n그래서 우리는 Aurora로 마이그레이션했습니다. 표준 PostgreSQL 대비 5~7배의 성능 향상을 약속받을 수 있다는 것은 놓칠 수 없는 이점입니다. 그러나 이러한 성능 메트릭은 pgbench를 기반으로 하고 있습니다 (PostgreSQL의 경우). 대규모 데이터 집합 및 데이터 마이닝 작업에 대한 성능 지표로는 적합하지 않지만 수많은 병렬 클라이언트와 함께 트랜잭션의 속도(또는 지연 시간)를 측정하고 싶은 OLTP 시스템이 있다면 이러한 결과는 훌륭합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n비용이 줄어들었는데 오히려 올라갔어요.\n\n이 글에서는 IOPS 및 요금 청구 가능한 IOPS에 관한 내용이 있습니다. https://forums.aws.amazon.com/message.jspa?messageID=835303#835303\n\n다시 한 번 가장 큰 답답함은 처리량의 정확한 측정을 얻는 데 있었습니다. 단순히 tack_io_timing을 사용하여 스캔된 데이터 양을 시간으로 나눈 것을 보면, 대규모 데이터셋에 대한 성능이 SSD 속도처럼이 아니라 자기 디스크와 유사하다는 것을 알 수 있습니다.\n\n부담스럽게 느껴지는 것 중 하나는 지원과의 끝없는 시간입니다. 지원 직원은 항상 매우 지식이 풍부하고 도움이 되려는 자세였지만, 항상 쿼리 조정이나 DB 조정에 차질이 생겼습니다. 다시 말해서 처리량에 관한 문제로 돌아왔죠. \"귀하의 작업 부하에 고려해 보기에는 이 서비스를 선택하는 것이 좋지 않다.\"는 말을 듣고 싶어했지만, 결국 우리 스스로 그것을 해결해야 했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 해결책: 직접 만들어보세요\n\n저희에게는 해결책이 꽤 간단했습니다. 관리형 데이터베이스 서비스를 사용하지 말고 EC2에서 직접 인프라를 구축했어요.\n\n저희는 상대적으로 저사양의 EC2 인스턴스(저희는 RDS에서 4XL을 실행 중이었습니다) xl과 2xl을 사용했어요.\n\n중요한 점은 마스터와 스탠바이 레플리카 간의 READ 및 WRITE 워크로드를 분리하는 것이었고, 이를 위해 WAL-G(https://github.com/wal-g/wal-g)를 사용하여 최신 상태를 유지하는 것이었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nWRITE 노드는 데이터를 처리하기만 하므로 EBS가 충분했지만 ZFS를 사용하여 EBS 처리량을 2배로 늘릴 수 있었습니다.\n\nREAD 노드의 경우 일시적인 NVMe 드라이브와 다시 한 번 ZFS를 사용하여 성능을 향상시켰습니다.\n\n결과가 자연스럽게 이야기해줍니다:\n\n비용이 $11K에서 $2100으로 감소했습니다(9월에 예상되는 첫 번째 RDS 부담이 없는 완전한 한 달을 기준으로).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아주 길고 끝이 나지 않을 쿼리도 몇 시간이 걸리거나 완전히 시간초과될 정도로 실행되던 것이 몇 초만에 완료되었어요.\n\n유닉스 인스턴스에서 명령 줄 도구(zpool iostat)를 사용하여 실제 처리량을 측정할 수 있습니다.\n\n# 결론\n\n인스턴스를 시작하고 백업과 복구에 대해 걱정하지 않고 한 번 클릭하면 편리할 수 있지만, 이는 저희의 경우에는 비용과 성능 측면에서 비용이 발생합니다. TB 또는 GB 데이터를 처리하는 데 실제 속도가 필요하다면 베어 메탈을 사용하십시오. 베어 메탈을 사용할 수 없다면 NVMe 드라이브가 장착된 EC2를 사용하는 것이 다음으로 좋은 방법입니다. NVMe 드라이브가 장착된 인스턴스를 사용하여 AWS에서 자체 Postgres 클러스터를 시작하는 방법에 대한 조리법을 제공하는 부분 두 번째를 읽어보세요.\n","ogImage":{"url":"/assets/img/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution_0.png"},"coverImage":"/assets/img/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch1\u003e배경\u003c/h1\u003e\n\u003cp\u003e우리는 마케팅 효과를 통계적으로 측정하는 스타트업을 만들고 있었습니다. 이를 위해 온라인 사용자 행동에 대한 많은 데이터를 수집해야 했습니다. 모든 클릭, 모든 입력 필드, 모든 액션을 모으는 작업이 필요했습니다. 데이터는 포스트그레스에 저장되었고, 최종 사용자들은 UI를 통해 상기 (때로는 매우 큰) 데이터 집합을 분석하는 대시보드 및 보고서를 실행했습니다. 여러 테넌트를 지원하는 멀티 테넌트 SAAS 애플리케이션을 구축하고 있기 때문에 데이터는 수백 개의 테넌트별로 수집되고 저장되었습니다. 이 시스템은 확장 가능하고 성능이 좋아야 했습니다. 우리는 AWS RDS 관리형 포스트그레SQL로 시작했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003eEBS와 관련된 큰 문제: 처리량 투명성\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eEBS의 처리량을 정확하게 측정하는 것은 거의 불가능합니다. AWS가 제공하는 지표는 지연 시간과 IOPS입니다. 이 둘 다 처리량을 측정하는 방법은 제공하지 않습니다. 디스크에 10GB의 크기를 가지는 시간 순서 테이블(예: 2000만 개 행)을 저장하고 테이블을 스캔하려고 할 때(어떤 이유로든 - 예를 들어 순차 스캔이 필요한 경우) 디스크에서 데이터를 스캔하는 데 얼마나 오랜 시간이 걸릴지 이해하려면 처리량을 정확히 측정해야 합니다.\u003c/p\u003e\n\u003ch1\u003e폭발과 제한된 IOPS - 사태의 시작\u003c/h1\u003e\n\u003cp\u003e위의 쿼리와 같은 작업들은 IO 크레딧을 빨리 소진시킵니다. 우리는 더 많은 IOPS를 원하기 때문에 어떻게 해야 할까요? 당연히 스토리지 볼륨을 늘려서 작은 볼륨으로부터 얻을 수 있는 3000 IOPS보다 높은 10000 IOPS 기본선을 얻을 수 있도록 합니다. 하지만 백업 비용이 증가하게 되고, 전체 볼륨을 지불하게 되므로 비용이 증가합니다. 비용은 증가하는데 성능이 거의 개선되지 않는다 - 이러한 상황은 더 악화됩니다.\u003c/p\u003e\n\u003cp\u003e우리는 또한 캐싱을 위해 더 많은 메모리를 얻기 위해 인스턴스 크기를 계속해서 늘렸습니다. 모든 것을 메모리에 맞게 만들면 DB를 빠르게 만드는 것이 쉽습니다. 불행히도 PG v10에서 제공되는 더 큰 병렬 처리는 IO 제한 때문에 실제로 많은 혜택을 가져다주지 않았습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e쓰루풋을 측정하는 데 문제가 있는 내용은 여기에서 자세히 설명되어 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003eAurora\u003c/h1\u003e\n\u003cp\u003e그래서 우리는 Aurora로 마이그레이션했습니다. 표준 PostgreSQL 대비 5~7배의 성능 향상을 약속받을 수 있다는 것은 놓칠 수 없는 이점입니다. 그러나 이러한 성능 메트릭은 pgbench를 기반으로 하고 있습니다 (PostgreSQL의 경우). 대규모 데이터 집합 및 데이터 마이닝 작업에 대한 성능 지표로는 적합하지 않지만 수많은 병렬 클라이언트와 함께 트랜잭션의 속도(또는 지연 시간)를 측정하고 싶은 OLTP 시스템이 있다면 이러한 결과는 훌륭합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e비용이 줄어들었는데 오히려 올라갔어요.\u003c/p\u003e\n\u003cp\u003e이 글에서는 IOPS 및 요금 청구 가능한 IOPS에 관한 내용이 있습니다. \u003ca href=\"https://forums.aws.amazon.com/message.jspa?messageID=835303#835303\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://forums.aws.amazon.com/message.jspa?messageID=835303#835303\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e다시 한 번 가장 큰 답답함은 처리량의 정확한 측정을 얻는 데 있었습니다. 단순히 tack_io_timing을 사용하여 스캔된 데이터 양을 시간으로 나눈 것을 보면, 대규모 데이터셋에 대한 성능이 SSD 속도처럼이 아니라 자기 디스크와 유사하다는 것을 알 수 있습니다.\u003c/p\u003e\n\u003cp\u003e부담스럽게 느껴지는 것 중 하나는 지원과의 끝없는 시간입니다. 지원 직원은 항상 매우 지식이 풍부하고 도움이 되려는 자세였지만, 항상 쿼리 조정이나 DB 조정에 차질이 생겼습니다. 다시 말해서 처리량에 관한 문제로 돌아왔죠. \"귀하의 작업 부하에 고려해 보기에는 이 서비스를 선택하는 것이 좋지 않다.\"는 말을 듣고 싶어했지만, 결국 우리 스스로 그것을 해결해야 했습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e해결책: 직접 만들어보세요\u003c/h1\u003e\n\u003cp\u003e저희에게는 해결책이 꽤 간단했습니다. 관리형 데이터베이스 서비스를 사용하지 말고 EC2에서 직접 인프라를 구축했어요.\u003c/p\u003e\n\u003cp\u003e저희는 상대적으로 저사양의 EC2 인스턴스(저희는 RDS에서 4XL을 실행 중이었습니다) xl과 2xl을 사용했어요.\u003c/p\u003e\n\u003cp\u003e중요한 점은 마스터와 스탠바이 레플리카 간의 READ 및 WRITE 워크로드를 분리하는 것이었고, 이를 위해 WAL-G(\u003ca href=\"https://github.com/wal-g/wal-g)%EB%A5%BC\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://github.com/wal-g/wal-g)를\u003c/a\u003e 사용하여 최신 상태를 유지하는 것이었습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eWRITE 노드는 데이터를 처리하기만 하므로 EBS가 충분했지만 ZFS를 사용하여 EBS 처리량을 2배로 늘릴 수 있었습니다.\u003c/p\u003e\n\u003cp\u003eREAD 노드의 경우 일시적인 NVMe 드라이브와 다시 한 번 ZFS를 사용하여 성능을 향상시켰습니다.\u003c/p\u003e\n\u003cp\u003e결과가 자연스럽게 이야기해줍니다:\u003c/p\u003e\n\u003cp\u003e비용이 $11K에서 $2100으로 감소했습니다(9월에 예상되는 첫 번째 RDS 부담이 없는 완전한 한 달을 기준으로).\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e아주 길고 끝이 나지 않을 쿼리도 몇 시간이 걸리거나 완전히 시간초과될 정도로 실행되던 것이 몇 초만에 완료되었어요.\u003c/p\u003e\n\u003cp\u003e유닉스 인스턴스에서 명령 줄 도구(zpool iostat)를 사용하여 실제 처리량을 측정할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e인스턴스를 시작하고 백업과 복구에 대해 걱정하지 않고 한 번 클릭하면 편리할 수 있지만, 이는 저희의 경우에는 비용과 성능 측면에서 비용이 발생합니다. TB 또는 GB 데이터를 처리하는 데 실제 속도가 필요하다면 베어 메탈을 사용하십시오. 베어 메탈을 사용할 수 없다면 NVMe 드라이브가 장착된 EC2를 사용하는 것이 다음으로 좋은 방법입니다. NVMe 드라이브가 장착된 인스턴스를 사용하여 AWS에서 자체 Postgres 클러스터를 시작하는 방법에 대한 조리법을 제공하는 부분 두 번째를 읽어보세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-WhyPostgresRDSdidntworkforusandwhyitwontworkforyouifyoureimplementingabigdatasolution"},"buildId":"JlBEgQDLGRx6DYlBnT8eD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>