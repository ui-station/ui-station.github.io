<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>단위 테스트 및 코드 모듈화를 위한 Databricks | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-06-19-UnitTestingandCodeModularizationinDatabricks" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="단위 테스트 및 코드 모듈화를 위한 Databricks | ui-station" data-gatsby-head="true"/><meta property="og:title" content="단위 테스트 및 코드 모듈화를 위한 Databricks | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-06-19-UnitTestingandCodeModularizationinDatabricks" data-gatsby-head="true"/><meta name="twitter:title" content="단위 테스트 및 코드 모듈화를 위한 Databricks | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 12:22" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_buildManifest.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">단위 테스트 및 코드 모듈화를 위한 Databricks</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="단위 테스트 및 코드 모듈화를 위한 Databricks" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">13<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-UnitTestingandCodeModularizationinDatabricks&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>노트북은 Databricks에서 데이터를 다루는 인기 있는 방법입니다. 노트북 사용자는 데이터를 빠르게 읽고 변환하며 상호적으로 탐색할 수 있습니다. 게다가, 노트북을 공유하고 협업하는 것은 간단합니다. 그러나 프로젝트가 확장될수록 코드 중복을 방지하고 재사용성을 용이하게 하는 모듈화 기능이 필요해집니다.</p>
<p>이를 달성하는 한 가지 방법은 공유 함수를 포함하는 노트북을 생성하고 각 노트북의 시작 부분에서 실행하는 것입니다. 또는 모듈을 만들어 일반적인 Python 개발과 유사한 Python import 명령어를 사용할 수 있습니다. 긴 코드 블록을 함수로 나누면 코드의 재사용을 촉진할 뿐만 아니라 테스트도 용이해집니다.</p>
<p><img src="/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png" alt="이미지"></p>
<h2>모듈화</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>파이썬에서 모듈화란 프로그램을 작은 관리 가능한 모듈로 나누는 것을 말합니다. 파이썬에서 코드를 모듈화하는 것에는 여러 가지 이점이 있습니다:</p>
<ul>
<li>재사용성: 모듈은 다른 프로젝트에서 다시 사용할 수 있어 재작성이 필요하지 않습니다.</li>
<li>유지보수성: 작은 중점적인 모듈로 인해 업데이트와 디버깅이 쉬워집니다.</li>
<li>확장성: 프로젝트가 성장할 때 효율적인 확장이 가능합니다.</li>
<li>협업: 다른 개발자들이 동시에 작업하기를 용이하게 합니다.</li>
<li>테스트: 단위 테스트가 간소화되어 더 신뢰할 수 있는 코드를 작성할 수 있습니다.</li>
<li>가독성: 특정 작업에 집중함으로써 코드 이해가 향상됩니다.</li>
</ul>
<p>Databricks에서 모듈을 사용하기 위해서는 클래스 또는 함수를 포함한 파일들로 구성된 폴더와 <strong>init</strong>.py 파일을 생성해야 합니다. 이는 Databricks에 모듈임을 알려줍니다. 아래는 공통 모듈과 함께 공유 함수, 변환 로직을 포함한 변환 모듈, 그리고 테스트 데이터가 포함된 내 솔루션의 구조입니다.</p>
<p>코드 구조:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">워크스페이스
├── test_data
│    └── testdata.<span class="hljs-property">csv</span>
├── common
│    └── __init__.<span class="hljs-property">py</span>
│    └── utilis.<span class="hljs-property">py</span>
├── transform
│    └── __init__.<span class="hljs-property">py</span>
│    └── operations.<span class="hljs-property">py</span>
├── test_utils.<span class="hljs-property">py</span>
├── test_tran.<span class="hljs-property">py</span>
├── test
</code></pre>
<p>testdata.csv:</p>
<pre><code class="hljs language-js">entity,iso_code,date,indicator,value
<span class="hljs-title class_">United</span> <span class="hljs-title class_">States</span>,<span class="hljs-variable constant_">USA</span>,<span class="hljs-number">2022</span>-<span class="hljs-number">04</span>-<span class="hljs-number">17</span>,<span class="hljs-title class_">Daily</span> <span class="hljs-variable constant_">ICU</span> occupancy,
<span class="hljs-title class_">United</span> <span class="hljs-title class_">States</span>,<span class="hljs-variable constant_">USA</span>,<span class="hljs-number">2022</span>-<span class="hljs-number">04</span>-<span class="hljs-number">17</span>,<span class="hljs-title class_">Daily</span> <span class="hljs-variable constant_">ICU</span> occupancy per million,<span class="hljs-number">4.1</span>
<span class="hljs-title class_">United</span> <span class="hljs-title class_">States</span>,<span class="hljs-variable constant_">USA</span>,<span class="hljs-number">2022</span>-<span class="hljs-number">04</span>-<span class="hljs-number">17</span>,<span class="hljs-title class_">Daily</span> hospital occupancy,<span class="hljs-number">10000</span>
<span class="hljs-title class_">United</span> <span class="hljs-title class_">States</span>,<span class="hljs-variable constant_">USA</span>,<span class="hljs-number">2022</span>-<span class="hljs-number">04</span>-<span class="hljs-number">17</span>,<span class="hljs-title class_">Daily</span> hospital occupancy per million,<span class="hljs-number">30.3</span>
<span class="hljs-title class_">United</span> <span class="hljs-title class_">States</span>,<span class="hljs-variable constant_">USA</span>,<span class="hljs-number">2022</span>-<span class="hljs-number">04</span>-<span class="hljs-number">17</span>,<span class="hljs-title class_">Weekly</span> <span class="hljs-keyword">new</span> hospital admissions,<span class="hljs-number">11000</span>
<span class="hljs-title class_">United</span> <span class="hljs-title class_">States</span>,<span class="hljs-variable constant_">USA</span>,<span class="hljs-number">2022</span>-<span class="hljs-number">04</span>-<span class="hljs-number">17</span>,<span class="hljs-title class_">Weekly</span> <span class="hljs-keyword">new</span> hospital admissions per million,<span class="hljs-number">32.8</span>
</code></pre>
<p>ulits.py:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">sql</span>.<span class="hljs-property">functions</span> <span class="hljs-keyword">import</span> udf
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">sql</span>.<span class="hljs-property">types</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">StringType</span>

def <span class="hljs-title function_">mask_func</span>(col_val):
    <span class="hljs-keyword">if</span> col_val is not <span class="hljs-title class_">None</span>:
        <span class="hljs-keyword">if</span> <span class="hljs-title function_">len</span>(col_val)>=<span class="hljs-number">16</span>:
            charList=<span class="hljs-title function_">list</span>(col_val)
            charList[<span class="hljs-number">4</span>:<span class="hljs-number">12</span>]=<span class="hljs-string">'x'</span>*<span class="hljs-number">8</span>
            <span class="hljs-keyword">return</span> <span class="hljs-string">""</span>.<span class="hljs-title function_">join</span>(charList)
        <span class="hljs-attr">else</span>:
            <span class="hljs-keyword">return</span> col_val
    <span class="hljs-attr">else</span>:
        <span class="hljs-keyword">return</span> col_val
</code></pre>
<p>operations.py:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">sql</span>.<span class="hljs-property">window</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">Window</span>
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">sql</span>.<span class="hljs-property">functions</span> <span class="hljs-keyword">import</span> row_number, col

def <span class="hljs-title function_">deduplicate</span>(df, uniq_col, orderby_col):
    df = df.<span class="hljs-title function_">withColumn</span>(<span class="hljs-string">"rn"</span>, <span class="hljs-title function_">row_number</span>()
        .<span class="hljs-title function_">over</span>(<span class="hljs-title class_">Window</span>.<span class="hljs-title function_">partitionBy</span>(uniq_col)
        .<span class="hljs-title function_">orderBy</span>(<span class="hljs-title function_">col</span>(orderby_col).<span class="hljs-title function_">desc</span>())))

    df = df.<span class="hljs-title function_">filter</span>(<span class="hljs-title function_">col</span>(<span class="hljs-string">"rn"</span>) == <span class="hljs-number">1</span>).<span class="hljs-title function_">drop</span>(<span class="hljs-string">"rn"</span>)
    <span class="hljs-keyword">return</span> df

def <span class="hljs-title function_">clean_clients</span>(df):
    df = df.<span class="hljs-title function_">where</span>(<span class="hljs-title function_">col</span>(<span class="hljs-string">"name"</span>) != <span class="hljs-string">""</span>).<span class="hljs-title function_">withColumn</span>(<span class="hljs-string">"timestamp"</span>, <span class="hljs-title function_">col</span>(<span class="hljs-string">"timestamp"</span>).<span class="hljs-title function_">cast</span>(<span class="hljs-string">"date"</span>))

    <span class="hljs-keyword">return</span> df
</code></pre>
<p>모듈에서 이러한 함수를 사용하려는 사람은 아래 예시와 같이 import 명령을 사용하여 노트북에 쉽게 추가할 수 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_1.png" alt="UnitTestingandCodeModularizationinDatabricks1"></p>
<p>Similarly, it’s possible to import transformation functions from the module and remove duplicated records from the DataFrame.</p>
<p><img src="/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_2.png" alt="UnitTestingandCodeModularizationinDatabricks2"></p>
<h1>Unit Testing in Databricks</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>소프트웨어 개발에서 단위 테스트는 코드의 정확성, 안정성, 유지 보수 가능성을 보장하는 중요한 요소입니다. 데이터 처리를 위해 노트북이 일반적으로 사용되는 Databricks에서는 단위 테스트가 더욱 중요해집니다.</p>
<p>Databricks에서 단위 테스트를 시작하려면 코드를 테스트할 수 있는 함수로 분해해야 합니다. 이 프로세스는 코드의 모듈성을 향상시키는 것뿐만 아니라 포괄적인 테스트 스위트를 작성하는 데 도움이 됩니다. Python에서 유닛 테스트를 수행하는 두 가지 인기있는 프레임워크인 Unittest와 pytest가 있습니다.</p>
<p>Unittest 예시:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> unittest

<span class="hljs-keyword">class</span> <span class="hljs-title class_">ExampleTestSuite</span>(unittest.TestCase):

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_import</span>(<span class="hljs-params">self</span>):
        self.assertTrue(<span class="hljs-literal">True</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_addition</span>(<span class="hljs-params">self</span>):
        self.assertEqual(<span class="hljs-number">1</span> + <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_subtraction</span>(<span class="hljs-params">self</span>):
        self.assertNotEqual(<span class="hljs-number">1</span> - <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>테이블 태그를 Markdown 형식으로 변경하세요.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>왜 단위 테스팅을 해야 할까요?</h2>
<p>처음 테스트 중에 코드가 정상적으로 작동하는 것처럼 보이더라도, 단위 테스트는 여러 가지 이유로 중요한 역할을 합니다:</p>
<ul>
<li>정확성 확인: 단위 테스트는 코드의 개별 단위 기능을 확인하여 다양한 조건에서 예상대로 작동하는지 확인합니다.</li>
<li>초기 버그 탐지: 개발 과정 초기에 버그를 식별함으로써, 개발자는 이를 신속히 해결하여 시스템의 다른 부분으로 전파되는 가능성을 줄일 수 있습니다.</li>
<li>리팩토링 및 유지보수: 단위 테스트는 코드 리팩토링 및 유지보수 과정에서 안전망 역할을 하며, 개발자가 확신을 갖고 변경을 가할 수 있으면서도 일관된 동작을 보장합니다.</li>
<li>회귀 테스트: 단위 테스트는 회귀 테스트로 작용하여 새로운 변경사항이나 기능이 기존의 기능을 망가뜨리지 않도록 하여 시스템의 안정성을 유지합니다.</li>
</ul>
<p>마스킹 기능에 대한 단위 테스트의 간단한 예제를 살펴보겠습니다. 이 단위 테스트는 입력 숫자가 올바르게 마스킹되거나 None을 반환하는지를 확인하여, 함수가 변경되더라도 예상되는 동작이 유지되도록 합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>test_utils.py</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> common.utils <span class="hljs-keyword">import</span> mask_func

<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_mask_func</span>():
    <span class="hljs-keyword">assert</span> <span class="hljs-string">"1234xxxxxxxx4568"</span> == mask_func(<span class="hljs-string">"1234567891234568"</span>)
    <span class="hljs-keyword">assert</span> mask_func(<span class="hljs-literal">None</span>) <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>
</code></pre>
<p>ETL(Extract, Transform, Load)과 같은 복잡한 프로세스의 경우, 데이터 변환 과정의 다양한 측면을 확인하는 데 개선된 테스트를 개발할 수 있습니다. 이러한 테스트에는 스키마 확인, 데이터프레임 비교, 행 수 유효성 검사 또는 특정 값의 존재 여부 확인이 포함될 수 있습니다.</p>
<p>test_tran.py:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">from</span> transform.<span class="hljs-property">operations</span> <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">testing</span>.<span class="hljs-property">utils</span> <span class="hljs-keyword">import</span> assertDataFrameEqual
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">sql</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">SparkSession</span>
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">testing</span> <span class="hljs-keyword">import</span> assertDataFrameEqual, assertSchemaEqual
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">sql</span>.<span class="hljs-property">types</span> <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

@pytest.<span class="hljs-title function_">fixture</span>()
def <span class="hljs-title function_">spark</span>():
    <span class="hljs-keyword">return</span> <span class="hljs-title class_">SparkSession</span>.<span class="hljs-property">builder</span>.<span class="hljs-title function_">appName</span>(<span class="hljs-string">"integrity-tests"</span>).<span class="hljs-title function_">getOrCreate</span>()

@pytest.<span class="hljs-title function_">fixture</span>()
def <span class="hljs-title function_">raw_input_df</span>(spark):
    df = pd.<span class="hljs-title function_">read_csv</span>(<span class="hljs-string">'test_data/testdata.csv'</span>)
    <span class="hljs-keyword">return</span> spark.<span class="hljs-title function_">createDataFrame</span>(df)

@pytest.<span class="hljs-title function_">fixture</span>()
def <span class="hljs-title function_">test_df</span>(spark):

    schema = <span class="hljs-string">"name STRING, age INTEGER, city STRING, timestamp STRING"</span>
    input_data = [
        (<span class="hljs-string">"John"</span>, <span class="hljs-number">25</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
        (<span class="hljs-string">"Jane"</span>, <span class="hljs-number">30</span>, <span class="hljs-string">"Los Angeles"</span>, <span class="hljs-string">"20210101"</span>),
        (<span class="hljs-string">"Jane"</span>, <span class="hljs-number">30</span>, <span class="hljs-string">"Chicago"</span>, <span class="hljs-string">"20220101"</span>),
        (<span class="hljs-string">"Doe"</span>, <span class="hljs-number">40</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
        (<span class="hljs-string">""</span>, <span class="hljs-number">39</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
    ]
    df = spark.<span class="hljs-title function_">createDataFrame</span>(input_data, schema)

    <span class="hljs-keyword">return</span> df

def <span class="hljs-title function_">test_deduplicate</span>(test_df, spark):
    schema = <span class="hljs-string">"name STRING, age INTEGER, city STRING, timestamp STRING"</span>
    input_data = [
        (<span class="hljs-string">"John"</span>, <span class="hljs-number">25</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
        (<span class="hljs-string">"Jane"</span>, <span class="hljs-number">30</span>, <span class="hljs-string">"Chicago"</span>, <span class="hljs-string">"20220101"</span>),
        (<span class="hljs-string">"Doe"</span>, <span class="hljs-number">40</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
        (<span class="hljs-string">""</span>, <span class="hljs-number">39</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
    ]
    df = spark.<span class="hljs-title function_">createDataFrame</span>(input_data, schema)

    df1 = <span class="hljs-title function_">deduplicate</span>(test_df, <span class="hljs-string">"Name"</span>, <span class="hljs-string">"timestamp"</span>)
    <span class="hljs-title function_">assertDataFrameEqual</span>(df1, df)

def <span class="hljs-title function_">test_schema_deduplicated</span>(test_df, spark):
    schema = <span class="hljs-string">"name STRING, age INTEGER, city STRING, timestamp STRING"</span>
    input_data = [
        (<span class="hljs-string">"John"</span>, <span class="hljs-number">25</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
        (<span class="hljs-string">"Jane"</span>, <span class="hljs-number">30</span>, <span class="hljs-string">"Chicago"</span>, <span class="hljs-string">"20220101"</span>),
        (<span class="hljs-string">"Doe"</span>, <span class="hljs-number">40</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
        (<span class="hljs-string">""</span>, <span class="hljs-number">39</span>, <span class="hljs-string">"New York"</span>, <span class="hljs-string">"20210101"</span>),
    ]
    df_expected = spark.<span class="hljs-title function_">createDataFrame</span>(input_data, schema)

    test_df = <span class="hljs-title function_">deduplicate</span>(test_df, <span class="hljs-string">"Name"</span>, <span class="hljs-string">"timestamp"</span>)
    <span class="hljs-title function_">assertSchemaEqual</span>(test_df.<span class="hljs-property">schema</span>, df_expected.<span class="hljs-property">schema</span>)

def <span class="hljs-title function_">test_clean_clients</span>(test_df, spark):
    df = <span class="hljs-title function_">clean_clients</span>(test_df)
    assert df.<span class="hljs-title function_">where</span>(<span class="hljs-string">"name == '' "</span>).<span class="hljs-title function_">count</span>() == <span class="hljs-number">0</span>

def <span class="hljs-title function_">test_readfromfile</span>(raw_input_df):
    assert raw_input_df.<span class="hljs-title function_">count</span>() > <span class="hljs-number">0</span>
</code></pre>
<h2>Initializing Spark Session for Tests:</h2>
<p>테스트 파일은 주피터 노트북이 아니기 때문에, Spark 세션을 초기화하는 것이 필요합니다. 이를 위해서 <code>spark</code> 함수와 <code>fixture</code> 데코레이터를 사용해서 Spark 세션을 만들 수 있습니다. <code>fixture</code> 데코레이터는 자동으로 실행되며 각 테스트 함수에 해당하는 테스트 객체를 제공해주어 테스트 데이터의 생성 및 공유를 간편하게 할 수 있습니다.</p>
<pre><code class="hljs language-js">@pytest.<span class="hljs-title function_">fixture</span>()
def <span class="hljs-title function_">spark</span>():
    <span class="hljs-keyword">return</span> <span class="hljs-title class_">SparkSession</span>.<span class="hljs-property">builder</span>.<span class="hljs-title function_">appName</span>(<span class="hljs-string">"integrity-tests"</span>).<span class="hljs-title function_">getOrCreate</span>()
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>선언했던 fixture 데코레이터의 동작 방식을 주목하는 것이 중요합니다. 이 기법을 사용하면 테스트 데이터를 원활하게 실행하고 전달할 수 있습니다. 이 기법을 이용하면 Spark 세션을 생성하여 테스트 데이터를 로드하고 이를 테스트 함수 사이에서 공유할 수 있습니다. 테스트 데이터는 목록을 기반으로 생성하거나 테스트 파일에서 로드할 수 있습니다.</p>
<pre><code class="hljs language-js">@pytest.<span class="hljs-title function_">fixture</span>()
def <span class="hljs-title function_">raw_input_df</span>(spark):
 df = pd.<span class="hljs-title function_">read_csv</span>(<span class="hljs-string">'test_data/testdata.csv'</span>)

 <span class="hljs-keyword">return</span> spark.<span class="hljs-title function_">createDataFrame</span>(df)
</code></pre>
<p>테스트용 데이터 원본으로 샘플 파일을 사용하는 것도 가능합니다. 그러나 워크스페이스에서 로드해야 하는 경우에는 Spark가 워크스페이스로부터 파일을 직접 로드하는 것을 지원하지 않기 때문에 Pandas를 사용해야 합니다.</p>
<h2>모듈의 지연 변경 사항 처리하기:</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>모듈을 다룰 때 변경 내용을 구현하는 데 지연이 발생하는 것은 일반적입니다. 이 동작을 해결하기 위해 매직 함수를 사용할 수 있습니다:</p>
<pre><code class="hljs language-js">%load_ext autoreload

%autoreload <span class="hljs-number">2</span>

%aimport test_tran
</code></pre>
<h1>Databricks에서 단위 테스트 실행</h1>
<p>Databricks에서 단위 테스트를 실행하려면 pytest 모듈을 호출하는 노트북을 생성해야 합니다. 아래는 지정된 저장소에서 테스트 실행을 트리거하는 코드 스니펫입니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>테스트 노트북:</p>
<pre><code class="hljs language-js">%pip install pytest
</code></pre>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> os, sys

repo_name = <span class="hljs-string">"&#x3C;저장소 위치>"</span>

notebook_path = dbutils.<span class="hljs-property">notebook</span>.<span class="hljs-property">entry_point</span>.<span class="hljs-title function_">getDbutils</span>().<span class="hljs-title function_">notebook</span>().<span class="hljs-title function_">getContext</span>().<span class="hljs-title function_">notebookPath</span>().<span class="hljs-title function_">get</span>()
repo_root = os.<span class="hljs-property">path</span>.<span class="hljs-title function_">dirname</span>(os.<span class="hljs-property">path</span>.<span class="hljs-title function_">dirname</span>(notebook_path))

os.<span class="hljs-title function_">chdir</span>(f<span class="hljs-string">"/Workspace/{repo_root}/{repo_name}"</span>)
<span class="hljs-title function_">print</span>(os.<span class="hljs-title function_">getcwd</span>())
# 읽기 전용 파일 시스템에 pyc 파일을 쓰지 않도록 설정합니다.
sys.<span class="hljs-property">dont_write_bytecode</span> = <span class="hljs-title class_">True</span>

# pytest 실행.
retcode = pytest.<span class="hljs-title function_">main</span>([<span class="hljs-string">"."</span>, <span class="hljs-string">"-v"</span>, <span class="hljs-string">"-p"</span>, <span class="hljs-string">"no:cacheprovider"</span>])

# 테스트 실패가 있는 경우 셀 실행 실패 처리합니다.
assert retcode == <span class="hljs-number">0</span>, <span class="hljs-string">"pytest 호출에 실패했습니다. 자세한 내용은 로그를 확인하세요."</span>
</code></pre>
<p>pytest를 실행하면 현재 디렉토리와 서브디렉토리에서 이름이 test__.py 또는 __test.py 패턴을 따르는 모든 파일을 자동으로 실행합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>스크립트를 실행하면 다음과 비슷한 보고서가 표시됩니다:</p>
<p><img src="/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_4.png" alt="보고서"></p>
<h1>요약</h1>
<p>요약하면 모듈화와 유닛 테스팅은 소프트웨어 개발에서 널리 사용되는 관행이며, 이러한 적용은 데이터 엔지니어링 활동에 매끄럽게 확장됩니다. 코드의 모듈화 및 유닛 테스트를 구현하여 데이터 처리 솔루션이 더욱 신뢰성 있고 유연해집니다. 모듈화는 코드 구성 요소의 더 나은 조직화와 재사용을 가능하게 하며, 유닛 테스트는 각 구성 요소가 다양한 조건에서 예상대로 동작하는지 확인합니다. 이러한 기술들이 함께 사용되면 데이터 엔지니어링 솔루션의 전체적인 견고성과 유지보수성에 기여하며, 마지막으로 데이터 처리 파이프라인 및 워크플로의 품질을 향상시킵니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>만약 이 기사를 유익하게 여기셨다면, 'clap' 버튼을 클릭하거나 LinkedIn에서 좋아요를 표시해 주시면 감사하겠습니다. 여러분의 지원을 감사히 여깁니다. 궁금한 점이나 조언이 있으시다면 언제든 LinkedIn에서 연락해 주세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"단위 테스트 및 코드 모듈화를 위한 Databricks","description":"","date":"2024-06-19 12:22","slug":"2024-06-19-UnitTestingandCodeModularizationinDatabricks","content":"\n노트북은 Databricks에서 데이터를 다루는 인기 있는 방법입니다. 노트북 사용자는 데이터를 빠르게 읽고 변환하며 상호적으로 탐색할 수 있습니다. 게다가, 노트북을 공유하고 협업하는 것은 간단합니다. 그러나 프로젝트가 확장될수록 코드 중복을 방지하고 재사용성을 용이하게 하는 모듈화 기능이 필요해집니다.\n\n이를 달성하는 한 가지 방법은 공유 함수를 포함하는 노트북을 생성하고 각 노트북의 시작 부분에서 실행하는 것입니다. 또는 모듈을 만들어 일반적인 Python 개발과 유사한 Python import 명령어를 사용할 수 있습니다. 긴 코드 블록을 함수로 나누면 코드의 재사용을 촉진할 뿐만 아니라 테스트도 용이해집니다.\n\n![이미지](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png)\n\n## 모듈화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n파이썬에서 모듈화란 프로그램을 작은 관리 가능한 모듈로 나누는 것을 말합니다. 파이썬에서 코드를 모듈화하는 것에는 여러 가지 이점이 있습니다:\n\n- 재사용성: 모듈은 다른 프로젝트에서 다시 사용할 수 있어 재작성이 필요하지 않습니다.\n- 유지보수성: 작은 중점적인 모듈로 인해 업데이트와 디버깅이 쉬워집니다.\n- 확장성: 프로젝트가 성장할 때 효율적인 확장이 가능합니다.\n- 협업: 다른 개발자들이 동시에 작업하기를 용이하게 합니다.\n- 테스트: 단위 테스트가 간소화되어 더 신뢰할 수 있는 코드를 작성할 수 있습니다.\n- 가독성: 특정 작업에 집중함으로써 코드 이해가 향상됩니다.\n\nDatabricks에서 모듈을 사용하기 위해서는 클래스 또는 함수를 포함한 파일들로 구성된 폴더와 **init**.py 파일을 생성해야 합니다. 이는 Databricks에 모듈임을 알려줍니다. 아래는 공통 모듈과 함께 공유 함수, 변환 로직을 포함한 변환 모듈, 그리고 테스트 데이터가 포함된 내 솔루션의 구조입니다.\n\n코드 구조:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n워크스페이스\n├── test_data\n│    └── testdata.csv\n├── common\n│    └── __init__.py\n│    └── utilis.py\n├── transform\n│    └── __init__.py\n│    └── operations.py\n├── test_utils.py\n├── test_tran.py\n├── test\n```\n\ntestdata.csv:\n\n```js\nentity,iso_code,date,indicator,value\nUnited States,USA,2022-04-17,Daily ICU occupancy,\nUnited States,USA,2022-04-17,Daily ICU occupancy per million,4.1\nUnited States,USA,2022-04-17,Daily hospital occupancy,10000\nUnited States,USA,2022-04-17,Daily hospital occupancy per million,30.3\nUnited States,USA,2022-04-17,Weekly new hospital admissions,11000\nUnited States,USA,2022-04-17,Weekly new hospital admissions per million,32.8\n```\n\nulits.py:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\n\ndef mask_func(col_val):\n    if col_val is not None:\n        if len(col_val)\u003e=16:\n            charList=list(col_val)\n            charList[4:12]='x'*8\n            return \"\".join(charList)\n        else:\n            return col_val\n    else:\n        return col_val\n```\n\noperations.py:\n\n```js\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import row_number, col\n\ndef deduplicate(df, uniq_col, orderby_col):\n    df = df.withColumn(\"rn\", row_number()\n        .over(Window.partitionBy(uniq_col)\n        .orderBy(col(orderby_col).desc())))\n\n    df = df.filter(col(\"rn\") == 1).drop(\"rn\")\n    return df\n\ndef clean_clients(df):\n    df = df.where(col(\"name\") != \"\").withColumn(\"timestamp\", col(\"timestamp\").cast(\"date\"))\n\n    return df\n```\n\n모듈에서 이러한 함수를 사용하려는 사람은 아래 예시와 같이 import 명령을 사용하여 노트북에 쉽게 추가할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![UnitTestingandCodeModularizationinDatabricks1](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_1.png)\n\nSimilarly, it’s possible to import transformation functions from the module and remove duplicated records from the DataFrame.\n\n![UnitTestingandCodeModularizationinDatabricks2](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_2.png)\n\n# Unit Testing in Databricks\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n소프트웨어 개발에서 단위 테스트는 코드의 정확성, 안정성, 유지 보수 가능성을 보장하는 중요한 요소입니다. 데이터 처리를 위해 노트북이 일반적으로 사용되는 Databricks에서는 단위 테스트가 더욱 중요해집니다.\n\nDatabricks에서 단위 테스트를 시작하려면 코드를 테스트할 수 있는 함수로 분해해야 합니다. 이 프로세스는 코드의 모듈성을 향상시키는 것뿐만 아니라 포괄적인 테스트 스위트를 작성하는 데 도움이 됩니다. Python에서 유닛 테스트를 수행하는 두 가지 인기있는 프레임워크인 Unittest와 pytest가 있습니다.\n\nUnittest 예시:\n\n```python\nimport unittest\n\nclass ExampleTestSuite(unittest.TestCase):\n\n    def test_import(self):\n        self.assertTrue(True)\n\n    def test_addition(self):\n        self.assertEqual(1 + 2, 3)\n\n    def test_subtraction(self):\n        self.assertNotEqual(1 - 2, 0)\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 왜 단위 테스팅을 해야 할까요?\n\n처음 테스트 중에 코드가 정상적으로 작동하는 것처럼 보이더라도, 단위 테스트는 여러 가지 이유로 중요한 역할을 합니다:\n\n- 정확성 확인: 단위 테스트는 코드의 개별 단위 기능을 확인하여 다양한 조건에서 예상대로 작동하는지 확인합니다.\n- 초기 버그 탐지: 개발 과정 초기에 버그를 식별함으로써, 개발자는 이를 신속히 해결하여 시스템의 다른 부분으로 전파되는 가능성을 줄일 수 있습니다.\n- 리팩토링 및 유지보수: 단위 테스트는 코드 리팩토링 및 유지보수 과정에서 안전망 역할을 하며, 개발자가 확신을 갖고 변경을 가할 수 있으면서도 일관된 동작을 보장합니다.\n- 회귀 테스트: 단위 테스트는 회귀 테스트로 작용하여 새로운 변경사항이나 기능이 기존의 기능을 망가뜨리지 않도록 하여 시스템의 안정성을 유지합니다.\n\n마스킹 기능에 대한 단위 테스트의 간단한 예제를 살펴보겠습니다. 이 단위 테스트는 입력 숫자가 올바르게 마스킹되거나 None을 반환하는지를 확인하여, 함수가 변경되더라도 예상되는 동작이 유지되도록 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\ntest_utils.py\n\n```python\nfrom common.utils import mask_func\n\ndef test_mask_func():\n    assert \"1234xxxxxxxx4568\" == mask_func(\"1234567891234568\")\n    assert mask_func(None) is None\n```\n\nETL(Extract, Transform, Load)과 같은 복잡한 프로세스의 경우, 데이터 변환 과정의 다양한 측면을 확인하는 데 개선된 테스트를 개발할 수 있습니다. 이러한 테스트에는 스키마 확인, 데이터프레임 비교, 행 수 유효성 검사 또는 특정 값의 존재 여부 확인이 포함될 수 있습니다.\n\ntest_tran.py:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport pytest\nfrom transform.operations import *\nfrom pyspark.testing.utils import assertDataFrameEqual\nfrom pyspark.sql import SparkSession\nfrom pyspark.testing import assertDataFrameEqual, assertSchemaEqual\nfrom pyspark.sql.types import *\nimport pandas as pd\n\n@pytest.fixture()\ndef spark():\n    return SparkSession.builder.appName(\"integrity-tests\").getOrCreate()\n\n@pytest.fixture()\ndef raw_input_df(spark):\n    df = pd.read_csv('test_data/testdata.csv')\n    return spark.createDataFrame(df)\n\n@pytest.fixture()\ndef test_df(spark):\n\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Los Angeles\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df = spark.createDataFrame(input_data, schema)\n\n    return df\n\ndef test_deduplicate(test_df, spark):\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df = spark.createDataFrame(input_data, schema)\n\n    df1 = deduplicate(test_df, \"Name\", \"timestamp\")\n    assertDataFrameEqual(df1, df)\n\ndef test_schema_deduplicated(test_df, spark):\n    schema = \"name STRING, age INTEGER, city STRING, timestamp STRING\"\n    input_data = [\n        (\"John\", 25, \"New York\", \"20210101\"),\n        (\"Jane\", 30, \"Chicago\", \"20220101\"),\n        (\"Doe\", 40, \"New York\", \"20210101\"),\n        (\"\", 39, \"New York\", \"20210101\"),\n    ]\n    df_expected = spark.createDataFrame(input_data, schema)\n\n    test_df = deduplicate(test_df, \"Name\", \"timestamp\")\n    assertSchemaEqual(test_df.schema, df_expected.schema)\n\ndef test_clean_clients(test_df, spark):\n    df = clean_clients(test_df)\n    assert df.where(\"name == '' \").count() == 0\n\ndef test_readfromfile(raw_input_df):\n    assert raw_input_df.count() \u003e 0\n```\n\n## Initializing Spark Session for Tests:\n\n테스트 파일은 주피터 노트북이 아니기 때문에, Spark 세션을 초기화하는 것이 필요합니다. 이를 위해서 `spark` 함수와 `fixture` 데코레이터를 사용해서 Spark 세션을 만들 수 있습니다. `fixture` 데코레이터는 자동으로 실행되며 각 테스트 함수에 해당하는 테스트 객체를 제공해주어 테스트 데이터의 생성 및 공유를 간편하게 할 수 있습니다.\n\n```js\n@pytest.fixture()\ndef spark():\n    return SparkSession.builder.appName(\"integrity-tests\").getOrCreate()\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n선언했던 fixture 데코레이터의 동작 방식을 주목하는 것이 중요합니다. 이 기법을 사용하면 테스트 데이터를 원활하게 실행하고 전달할 수 있습니다. 이 기법을 이용하면 Spark 세션을 생성하여 테스트 데이터를 로드하고 이를 테스트 함수 사이에서 공유할 수 있습니다. 테스트 데이터는 목록을 기반으로 생성하거나 테스트 파일에서 로드할 수 있습니다.\n\n```js\n@pytest.fixture()\ndef raw_input_df(spark):\n df = pd.read_csv('test_data/testdata.csv')\n\n return spark.createDataFrame(df)\n```\n\n테스트용 데이터 원본으로 샘플 파일을 사용하는 것도 가능합니다. 그러나 워크스페이스에서 로드해야 하는 경우에는 Spark가 워크스페이스로부터 파일을 직접 로드하는 것을 지원하지 않기 때문에 Pandas를 사용해야 합니다.\n\n## 모듈의 지연 변경 사항 처리하기:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모듈을 다룰 때 변경 내용을 구현하는 데 지연이 발생하는 것은 일반적입니다. 이 동작을 해결하기 위해 매직 함수를 사용할 수 있습니다:\n\n```js\n%load_ext autoreload\n\n%autoreload 2\n\n%aimport test_tran\n```\n\n# Databricks에서 단위 테스트 실행\n\nDatabricks에서 단위 테스트를 실행하려면 pytest 모듈을 호출하는 노트북을 생성해야 합니다. 아래는 지정된 저장소에서 테스트 실행을 트리거하는 코드 스니펫입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n테스트 노트북:\n\n```js\n%pip install pytest\n```\n\n```js\nimport pytest\nimport sys\nimport os, sys\n\nrepo_name = \"\u003c저장소 위치\u003e\"\n\nnotebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\nrepo_root = os.path.dirname(os.path.dirname(notebook_path))\n\nos.chdir(f\"/Workspace/{repo_root}/{repo_name}\")\nprint(os.getcwd())\n# 읽기 전용 파일 시스템에 pyc 파일을 쓰지 않도록 설정합니다.\nsys.dont_write_bytecode = True\n\n# pytest 실행.\nretcode = pytest.main([\".\", \"-v\", \"-p\", \"no:cacheprovider\"])\n\n# 테스트 실패가 있는 경우 셀 실행 실패 처리합니다.\nassert retcode == 0, \"pytest 호출에 실패했습니다. 자세한 내용은 로그를 확인하세요.\"\n```\n\npytest를 실행하면 현재 디렉토리와 서브디렉토리에서 이름이 test\\__.py 또는 _\\_test.py 패턴을 따르는 모든 파일을 자동으로 실행합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스크립트를 실행하면 다음과 비슷한 보고서가 표시됩니다:\n\n![보고서](/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_4.png)\n\n# 요약\n\n요약하면 모듈화와 유닛 테스팅은 소프트웨어 개발에서 널리 사용되는 관행이며, 이러한 적용은 데이터 엔지니어링 활동에 매끄럽게 확장됩니다. 코드의 모듈화 및 유닛 테스트를 구현하여 데이터 처리 솔루션이 더욱 신뢰성 있고 유연해집니다. 모듈화는 코드 구성 요소의 더 나은 조직화와 재사용을 가능하게 하며, 유닛 테스트는 각 구성 요소가 다양한 조건에서 예상대로 동작하는지 확인합니다. 이러한 기술들이 함께 사용되면 데이터 엔지니어링 솔루션의 전체적인 견고성과 유지보수성에 기여하며, 마지막으로 데이터 처리 파이프라인 및 워크플로의 품질을 향상시킵니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 이 기사를 유익하게 여기셨다면, 'clap' 버튼을 클릭하거나 LinkedIn에서 좋아요를 표시해 주시면 감사하겠습니다. 여러분의 지원을 감사히 여깁니다. 궁금한 점이나 조언이 있으시다면 언제든 LinkedIn에서 연락해 주세요.\n","ogImage":{"url":"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png"},"coverImage":"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png","tag":["Tech"],"readingTime":13},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e노트북은 Databricks에서 데이터를 다루는 인기 있는 방법입니다. 노트북 사용자는 데이터를 빠르게 읽고 변환하며 상호적으로 탐색할 수 있습니다. 게다가, 노트북을 공유하고 협업하는 것은 간단합니다. 그러나 프로젝트가 확장될수록 코드 중복을 방지하고 재사용성을 용이하게 하는 모듈화 기능이 필요해집니다.\u003c/p\u003e\n\u003cp\u003e이를 달성하는 한 가지 방법은 공유 함수를 포함하는 노트북을 생성하고 각 노트북의 시작 부분에서 실행하는 것입니다. 또는 모듈을 만들어 일반적인 Python 개발과 유사한 Python import 명령어를 사용할 수 있습니다. 긴 코드 블록을 함수로 나누면 코드의 재사용을 촉진할 뿐만 아니라 테스트도 용이해집니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch2\u003e모듈화\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e파이썬에서 모듈화란 프로그램을 작은 관리 가능한 모듈로 나누는 것을 말합니다. 파이썬에서 코드를 모듈화하는 것에는 여러 가지 이점이 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e재사용성: 모듈은 다른 프로젝트에서 다시 사용할 수 있어 재작성이 필요하지 않습니다.\u003c/li\u003e\n\u003cli\u003e유지보수성: 작은 중점적인 모듈로 인해 업데이트와 디버깅이 쉬워집니다.\u003c/li\u003e\n\u003cli\u003e확장성: 프로젝트가 성장할 때 효율적인 확장이 가능합니다.\u003c/li\u003e\n\u003cli\u003e협업: 다른 개발자들이 동시에 작업하기를 용이하게 합니다.\u003c/li\u003e\n\u003cli\u003e테스트: 단위 테스트가 간소화되어 더 신뢰할 수 있는 코드를 작성할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e가독성: 특정 작업에 집중함으로써 코드 이해가 향상됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDatabricks에서 모듈을 사용하기 위해서는 클래스 또는 함수를 포함한 파일들로 구성된 폴더와 \u003cstrong\u003einit\u003c/strong\u003e.py 파일을 생성해야 합니다. 이는 Databricks에 모듈임을 알려줍니다. 아래는 공통 모듈과 함께 공유 함수, 변환 로직을 포함한 변환 모듈, 그리고 테스트 데이터가 포함된 내 솔루션의 구조입니다.\u003c/p\u003e\n\u003cp\u003e코드 구조:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e워크스페이스\n├── test_data\n│    └── testdata.\u003cspan class=\"hljs-property\"\u003ecsv\u003c/span\u003e\n├── common\n│    └── __init__.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n│    └── utilis.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n├── transform\n│    └── __init__.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n│    └── operations.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n├── test_utils.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n├── test_tran.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n├── test\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003etestdata.csv:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eentity,iso_code,date,indicator,value\n\u003cspan class=\"hljs-title class_\"\u003eUnited\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStates\u003c/span\u003e,\u003cspan class=\"hljs-variable constant_\"\u003eUSA\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e2022\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e04\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e17\u003c/span\u003e,\u003cspan class=\"hljs-title class_\"\u003eDaily\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eICU\u003c/span\u003e occupancy,\n\u003cspan class=\"hljs-title class_\"\u003eUnited\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStates\u003c/span\u003e,\u003cspan class=\"hljs-variable constant_\"\u003eUSA\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e2022\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e04\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e17\u003c/span\u003e,\u003cspan class=\"hljs-title class_\"\u003eDaily\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eICU\u003c/span\u003e occupancy per million,\u003cspan class=\"hljs-number\"\u003e4.1\u003c/span\u003e\n\u003cspan class=\"hljs-title class_\"\u003eUnited\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStates\u003c/span\u003e,\u003cspan class=\"hljs-variable constant_\"\u003eUSA\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e2022\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e04\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e17\u003c/span\u003e,\u003cspan class=\"hljs-title class_\"\u003eDaily\u003c/span\u003e hospital occupancy,\u003cspan class=\"hljs-number\"\u003e10000\u003c/span\u003e\n\u003cspan class=\"hljs-title class_\"\u003eUnited\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStates\u003c/span\u003e,\u003cspan class=\"hljs-variable constant_\"\u003eUSA\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e2022\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e04\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e17\u003c/span\u003e,\u003cspan class=\"hljs-title class_\"\u003eDaily\u003c/span\u003e hospital occupancy per million,\u003cspan class=\"hljs-number\"\u003e30.3\u003c/span\u003e\n\u003cspan class=\"hljs-title class_\"\u003eUnited\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStates\u003c/span\u003e,\u003cspan class=\"hljs-variable constant_\"\u003eUSA\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e2022\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e04\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e17\u003c/span\u003e,\u003cspan class=\"hljs-title class_\"\u003eWeekly\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enew\u003c/span\u003e hospital admissions,\u003cspan class=\"hljs-number\"\u003e11000\u003c/span\u003e\n\u003cspan class=\"hljs-title class_\"\u003eUnited\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStates\u003c/span\u003e,\u003cspan class=\"hljs-variable constant_\"\u003eUSA\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e2022\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e04\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e17\u003c/span\u003e,\u003cspan class=\"hljs-title class_\"\u003eWeekly\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enew\u003c/span\u003e hospital admissions per million,\u003cspan class=\"hljs-number\"\u003e32.8\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eulits.py:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003esql\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003efunctions\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e udf\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003esql\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003etypes\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eStringType\u003c/span\u003e\n\ndef \u003cspan class=\"hljs-title function_\"\u003emask_func\u003c/span\u003e(col_val):\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e col_val is not \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e:\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(col_val)\u003e=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e:\n            charList=\u003cspan class=\"hljs-title function_\"\u003elist\u003c/span\u003e(col_val)\n            charList[\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e]=\u003cspan class=\"hljs-string\"\u003e'x'\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e\n            \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ejoin\u003c/span\u003e(charList)\n        \u003cspan class=\"hljs-attr\"\u003eelse\u003c/span\u003e:\n            \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e col_val\n    \u003cspan class=\"hljs-attr\"\u003eelse\u003c/span\u003e:\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e col_val\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eoperations.py:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003esql\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ewindow\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eWindow\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003esql\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003efunctions\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e row_number, col\n\ndef \u003cspan class=\"hljs-title function_\"\u003ededuplicate\u003c/span\u003e(df, uniq_col, orderby_col):\n    df = df.\u003cspan class=\"hljs-title function_\"\u003ewithColumn\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"rn\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003erow_number\u003c/span\u003e()\n        .\u003cspan class=\"hljs-title function_\"\u003eover\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eWindow\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003epartitionBy\u003c/span\u003e(uniq_col)\n        .\u003cspan class=\"hljs-title function_\"\u003eorderBy\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003ecol\u003c/span\u003e(orderby_col).\u003cspan class=\"hljs-title function_\"\u003edesc\u003c/span\u003e())))\n\n    df = df.\u003cspan class=\"hljs-title function_\"\u003efilter\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003ecol\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"rn\"\u003c/span\u003e) == \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003edrop\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"rn\"\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e df\n\ndef \u003cspan class=\"hljs-title function_\"\u003eclean_clients\u003c/span\u003e(df):\n    df = df.\u003cspan class=\"hljs-title function_\"\u003ewhere\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003ecol\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"name\"\u003c/span\u003e) != \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003ewithColumn\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"timestamp\"\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003ecol\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"timestamp\"\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003ecast\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"date\"\u003c/span\u003e))\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e df\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e모듈에서 이러한 함수를 사용하려는 사람은 아래 예시와 같이 import 명령을 사용하여 노트북에 쉽게 추가할 수 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_1.png\" alt=\"UnitTestingandCodeModularizationinDatabricks1\"\u003e\u003c/p\u003e\n\u003cp\u003eSimilarly, it’s possible to import transformation functions from the module and remove duplicated records from the DataFrame.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_2.png\" alt=\"UnitTestingandCodeModularizationinDatabricks2\"\u003e\u003c/p\u003e\n\u003ch1\u003eUnit Testing in Databricks\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e소프트웨어 개발에서 단위 테스트는 코드의 정확성, 안정성, 유지 보수 가능성을 보장하는 중요한 요소입니다. 데이터 처리를 위해 노트북이 일반적으로 사용되는 Databricks에서는 단위 테스트가 더욱 중요해집니다.\u003c/p\u003e\n\u003cp\u003eDatabricks에서 단위 테스트를 시작하려면 코드를 테스트할 수 있는 함수로 분해해야 합니다. 이 프로세스는 코드의 모듈성을 향상시키는 것뿐만 아니라 포괄적인 테스트 스위트를 작성하는 데 도움이 됩니다. Python에서 유닛 테스트를 수행하는 두 가지 인기있는 프레임워크인 Unittest와 pytest가 있습니다.\u003c/p\u003e\n\u003cp\u003eUnittest 예시:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e unittest\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eExampleTestSuite\u003c/span\u003e(unittest.TestCase):\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etest_import\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        self.assertTrue(\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etest_addition\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        self.assertEqual(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e + \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etest_subtraction\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        self.assertNotEqual(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e - \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e테이블 태그를 Markdown 형식으로 변경하세요.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e왜 단위 테스팅을 해야 할까요?\u003c/h2\u003e\n\u003cp\u003e처음 테스트 중에 코드가 정상적으로 작동하는 것처럼 보이더라도, 단위 테스트는 여러 가지 이유로 중요한 역할을 합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e정확성 확인: 단위 테스트는 코드의 개별 단위 기능을 확인하여 다양한 조건에서 예상대로 작동하는지 확인합니다.\u003c/li\u003e\n\u003cli\u003e초기 버그 탐지: 개발 과정 초기에 버그를 식별함으로써, 개발자는 이를 신속히 해결하여 시스템의 다른 부분으로 전파되는 가능성을 줄일 수 있습니다.\u003c/li\u003e\n\u003cli\u003e리팩토링 및 유지보수: 단위 테스트는 코드 리팩토링 및 유지보수 과정에서 안전망 역할을 하며, 개발자가 확신을 갖고 변경을 가할 수 있으면서도 일관된 동작을 보장합니다.\u003c/li\u003e\n\u003cli\u003e회귀 테스트: 단위 테스트는 회귀 테스트로 작용하여 새로운 변경사항이나 기능이 기존의 기능을 망가뜨리지 않도록 하여 시스템의 안정성을 유지합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e마스킹 기능에 대한 단위 테스트의 간단한 예제를 살펴보겠습니다. 이 단위 테스트는 입력 숫자가 올바르게 마스킹되거나 None을 반환하는지를 확인하여, 함수가 변경되더라도 예상되는 동작이 유지되도록 합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003etest_utils.py\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e common.utils \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e mask_func\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etest_mask_func\u003c/span\u003e():\n    \u003cspan class=\"hljs-keyword\"\u003eassert\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"1234xxxxxxxx4568\"\u003c/span\u003e == mask_func(\u003cspan class=\"hljs-string\"\u003e\"1234567891234568\"\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003eassert\u003c/span\u003e mask_func(\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eis\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eETL(Extract, Transform, Load)과 같은 복잡한 프로세스의 경우, 데이터 변환 과정의 다양한 측면을 확인하는 데 개선된 테스트를 개발할 수 있습니다. 이러한 테스트에는 스키마 확인, 데이터프레임 비교, 행 수 유효성 검사 또는 특정 값의 존재 여부 확인이 포함될 수 있습니다.\u003c/p\u003e\n\u003cp\u003etest_tran.py:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pytest\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transform.\u003cspan class=\"hljs-property\"\u003eoperations\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e *\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003etesting\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eutils\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e assertDataFrameEqual\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003esql\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSparkSession\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003etesting\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e assertDataFrameEqual, assertSchemaEqual\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003esql\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003etypes\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e *\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\n@pytest.\u003cspan class=\"hljs-title function_\"\u003efixture\u003c/span\u003e()\ndef \u003cspan class=\"hljs-title function_\"\u003espark\u003c/span\u003e():\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSparkSession\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ebuilder\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappName\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"integrity-tests\"\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003egetOrCreate\u003c/span\u003e()\n\n@pytest.\u003cspan class=\"hljs-title function_\"\u003efixture\u003c/span\u003e()\ndef \u003cspan class=\"hljs-title function_\"\u003eraw_input_df\u003c/span\u003e(spark):\n    df = pd.\u003cspan class=\"hljs-title function_\"\u003eread_csv\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'test_data/testdata.csv'\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e spark.\u003cspan class=\"hljs-title function_\"\u003ecreateDataFrame\u003c/span\u003e(df)\n\n@pytest.\u003cspan class=\"hljs-title function_\"\u003efixture\u003c/span\u003e()\ndef \u003cspan class=\"hljs-title function_\"\u003etest_df\u003c/span\u003e(spark):\n\n    schema = \u003cspan class=\"hljs-string\"\u003e\"name STRING, age INTEGER, city STRING, timestamp STRING\"\u003c/span\u003e\n    input_data = [\n        (\u003cspan class=\"hljs-string\"\u003e\"John\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"Jane\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"Los Angeles\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"Jane\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"Chicago\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20220101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"Doe\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e40\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e39\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n    ]\n    df = spark.\u003cspan class=\"hljs-title function_\"\u003ecreateDataFrame\u003c/span\u003e(input_data, schema)\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e df\n\ndef \u003cspan class=\"hljs-title function_\"\u003etest_deduplicate\u003c/span\u003e(test_df, spark):\n    schema = \u003cspan class=\"hljs-string\"\u003e\"name STRING, age INTEGER, city STRING, timestamp STRING\"\u003c/span\u003e\n    input_data = [\n        (\u003cspan class=\"hljs-string\"\u003e\"John\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"Jane\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"Chicago\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20220101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"Doe\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e40\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e39\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n    ]\n    df = spark.\u003cspan class=\"hljs-title function_\"\u003ecreateDataFrame\u003c/span\u003e(input_data, schema)\n\n    df1 = \u003cspan class=\"hljs-title function_\"\u003ededuplicate\u003c/span\u003e(test_df, \u003cspan class=\"hljs-string\"\u003e\"Name\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"timestamp\"\u003c/span\u003e)\n    \u003cspan class=\"hljs-title function_\"\u003eassertDataFrameEqual\u003c/span\u003e(df1, df)\n\ndef \u003cspan class=\"hljs-title function_\"\u003etest_schema_deduplicated\u003c/span\u003e(test_df, spark):\n    schema = \u003cspan class=\"hljs-string\"\u003e\"name STRING, age INTEGER, city STRING, timestamp STRING\"\u003c/span\u003e\n    input_data = [\n        (\u003cspan class=\"hljs-string\"\u003e\"John\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"Jane\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"Chicago\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20220101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"Doe\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e40\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n        (\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e39\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"New York\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"20210101\"\u003c/span\u003e),\n    ]\n    df_expected = spark.\u003cspan class=\"hljs-title function_\"\u003ecreateDataFrame\u003c/span\u003e(input_data, schema)\n\n    test_df = \u003cspan class=\"hljs-title function_\"\u003ededuplicate\u003c/span\u003e(test_df, \u003cspan class=\"hljs-string\"\u003e\"Name\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"timestamp\"\u003c/span\u003e)\n    \u003cspan class=\"hljs-title function_\"\u003eassertSchemaEqual\u003c/span\u003e(test_df.\u003cspan class=\"hljs-property\"\u003eschema\u003c/span\u003e, df_expected.\u003cspan class=\"hljs-property\"\u003eschema\u003c/span\u003e)\n\ndef \u003cspan class=\"hljs-title function_\"\u003etest_clean_clients\u003c/span\u003e(test_df, spark):\n    df = \u003cspan class=\"hljs-title function_\"\u003eclean_clients\u003c/span\u003e(test_df)\n    assert df.\u003cspan class=\"hljs-title function_\"\u003ewhere\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"name == '' \"\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003ecount\u003c/span\u003e() == \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n\ndef \u003cspan class=\"hljs-title function_\"\u003etest_readfromfile\u003c/span\u003e(raw_input_df):\n    assert raw_input_df.\u003cspan class=\"hljs-title function_\"\u003ecount\u003c/span\u003e() \u003e \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eInitializing Spark Session for Tests:\u003c/h2\u003e\n\u003cp\u003e테스트 파일은 주피터 노트북이 아니기 때문에, Spark 세션을 초기화하는 것이 필요합니다. 이를 위해서 \u003ccode\u003espark\u003c/code\u003e 함수와 \u003ccode\u003efixture\u003c/code\u003e 데코레이터를 사용해서 Spark 세션을 만들 수 있습니다. \u003ccode\u003efixture\u003c/code\u003e 데코레이터는 자동으로 실행되며 각 테스트 함수에 해당하는 테스트 객체를 제공해주어 테스트 데이터의 생성 및 공유를 간편하게 할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e@pytest.\u003cspan class=\"hljs-title function_\"\u003efixture\u003c/span\u003e()\ndef \u003cspan class=\"hljs-title function_\"\u003espark\u003c/span\u003e():\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSparkSession\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ebuilder\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappName\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"integrity-tests\"\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003egetOrCreate\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e선언했던 fixture 데코레이터의 동작 방식을 주목하는 것이 중요합니다. 이 기법을 사용하면 테스트 데이터를 원활하게 실행하고 전달할 수 있습니다. 이 기법을 이용하면 Spark 세션을 생성하여 테스트 데이터를 로드하고 이를 테스트 함수 사이에서 공유할 수 있습니다. 테스트 데이터는 목록을 기반으로 생성하거나 테스트 파일에서 로드할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e@pytest.\u003cspan class=\"hljs-title function_\"\u003efixture\u003c/span\u003e()\ndef \u003cspan class=\"hljs-title function_\"\u003eraw_input_df\u003c/span\u003e(spark):\n df = pd.\u003cspan class=\"hljs-title function_\"\u003eread_csv\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'test_data/testdata.csv'\u003c/span\u003e)\n\n \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e spark.\u003cspan class=\"hljs-title function_\"\u003ecreateDataFrame\u003c/span\u003e(df)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e테스트용 데이터 원본으로 샘플 파일을 사용하는 것도 가능합니다. 그러나 워크스페이스에서 로드해야 하는 경우에는 Spark가 워크스페이스로부터 파일을 직접 로드하는 것을 지원하지 않기 때문에 Pandas를 사용해야 합니다.\u003c/p\u003e\n\u003ch2\u003e모듈의 지연 변경 사항 처리하기:\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e모듈을 다룰 때 변경 내용을 구현하는 데 지연이 발생하는 것은 일반적입니다. 이 동작을 해결하기 위해 매직 함수를 사용할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e%load_ext autoreload\n\n%autoreload \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n\n%aimport test_tran\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eDatabricks에서 단위 테스트 실행\u003c/h1\u003e\n\u003cp\u003eDatabricks에서 단위 테스트를 실행하려면 pytest 모듈을 호출하는 노트북을 생성해야 합니다. 아래는 지정된 저장소에서 테스트 실행을 트리거하는 코드 스니펫입니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e테스트 노트북:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e%pip install pytest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pytest\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e sys\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os, sys\n\nrepo_name = \u003cspan class=\"hljs-string\"\u003e\"\u0026#x3C;저장소 위치\u003e\"\u003c/span\u003e\n\nnotebook_path = dbutils.\u003cspan class=\"hljs-property\"\u003enotebook\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eentry_point\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egetDbutils\u003c/span\u003e().\u003cspan class=\"hljs-title function_\"\u003enotebook\u003c/span\u003e().\u003cspan class=\"hljs-title function_\"\u003egetContext\u003c/span\u003e().\u003cspan class=\"hljs-title function_\"\u003enotebookPath\u003c/span\u003e().\u003cspan class=\"hljs-title function_\"\u003eget\u003c/span\u003e()\nrepo_root = os.\u003cspan class=\"hljs-property\"\u003epath\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003edirname\u003c/span\u003e(os.\u003cspan class=\"hljs-property\"\u003epath\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003edirname\u003c/span\u003e(notebook_path))\n\nos.\u003cspan class=\"hljs-title function_\"\u003echdir\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"/Workspace/{repo_root}/{repo_name}\"\u003c/span\u003e)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(os.\u003cspan class=\"hljs-title function_\"\u003egetcwd\u003c/span\u003e())\n# 읽기 전용 파일 시스템에 pyc 파일을 쓰지 않도록 설정합니다.\nsys.\u003cspan class=\"hljs-property\"\u003edont_write_bytecode\u003c/span\u003e = \u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e\n\n# pytest 실행.\nretcode = pytest.\u003cspan class=\"hljs-title function_\"\u003emain\u003c/span\u003e([\u003cspan class=\"hljs-string\"\u003e\".\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"-v\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"-p\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"no:cacheprovider\"\u003c/span\u003e])\n\n# 테스트 실패가 있는 경우 셀 실행 실패 처리합니다.\nassert retcode == \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"pytest 호출에 실패했습니다. 자세한 내용은 로그를 확인하세요.\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003epytest를 실행하면 현재 디렉토리와 서브디렉토리에서 이름이 test__.py 또는 __test.py 패턴을 따르는 모든 파일을 자동으로 실행합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e스크립트를 실행하면 다음과 비슷한 보고서가 표시됩니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-UnitTestingandCodeModularizationinDatabricks_4.png\" alt=\"보고서\"\u003e\u003c/p\u003e\n\u003ch1\u003e요약\u003c/h1\u003e\n\u003cp\u003e요약하면 모듈화와 유닛 테스팅은 소프트웨어 개발에서 널리 사용되는 관행이며, 이러한 적용은 데이터 엔지니어링 활동에 매끄럽게 확장됩니다. 코드의 모듈화 및 유닛 테스트를 구현하여 데이터 처리 솔루션이 더욱 신뢰성 있고 유연해집니다. 모듈화는 코드 구성 요소의 더 나은 조직화와 재사용을 가능하게 하며, 유닛 테스트는 각 구성 요소가 다양한 조건에서 예상대로 동작하는지 확인합니다. 이러한 기술들이 함께 사용되면 데이터 엔지니어링 솔루션의 전체적인 견고성과 유지보수성에 기여하며, 마지막으로 데이터 처리 파이프라인 및 워크플로의 품질을 향상시킵니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e만약 이 기사를 유익하게 여기셨다면, 'clap' 버튼을 클릭하거나 LinkedIn에서 좋아요를 표시해 주시면 감사하겠습니다. 여러분의 지원을 감사히 여깁니다. 궁금한 점이나 조언이 있으시다면 언제든 LinkedIn에서 연락해 주세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-UnitTestingandCodeModularizationinDatabricks"},"buildId":"GsgRekSb--BvxYwv9FPn6","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>