<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>K8sGPT  Ollama 무료 Kubernetes 자동 진단 솔루션 사용법 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="K8sGPT  Ollama 무료 Kubernetes 자동 진단 솔루션 사용법 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="K8sGPT  Ollama 무료 Kubernetes 자동 진단 솔루션 사용법 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution" data-gatsby-head="true"/><meta name="twitter:title" content="K8sGPT  Ollama 무료 Kubernetes 자동 진단 솔루션 사용법 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 23:00" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_buildManifest.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">K8sGPT  Ollama 무료 Kubernetes 자동 진단 솔루션 사용법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="K8sGPT  Ollama 무료 Kubernetes 자동 진단 솔루션 사용법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_0.png" alt="Kubernetes Automated Diagnosis Tool: k8sgpt-operator"></p>
<p>주말에 블로그 초고를 확인했더니 이 글이 있었어요. 한 해 전 'Kubernetes Automated Diagnosis Tool: k8sgpt-operator'를 쓸 때의 기억이 떠오르네요. 처음에는 K8sGPT + LocalAI를 써보려 했지만, Ollama로 시도해보니 더 사용하기 편리했어요. 게다가 Ollama는 OpenAI API를 지원하기도 해서 Ollama로 바꾸기로 결정했죠.</p>
<p>k8sgpt-operator를 소개하는 글을 게시한 후 몇몇 독자들이 OpenAI를 사용하기 위한 높은 진입 장벽을 언급했어요. 이 문제는 정말 어려운 문제이지만 극복할 수 있는 문제에요. 하지만 이 글은 그 문제를 해결하는 게 아니라 OpenAI 대안인 Ollama를 소개하기 위한 글이에요. 작년 말에 k8sgpt는 CNCF Sandbox에 들어갔어요.</p>
<h1>1. Ollama 설치하기</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_1.png" alt="Ollama"></p>
<p>Ollama은 로컬이나 클라우드에서 쉽게 설치하고 실행할 수 있는 여러 대형 모델을 지원하는 오픈 소스 대형 모델 도구입니다. 매우 사용하기 편리하며 간단한 명령어로 실행할 수 있습니다. macOS에서는 homebrew를 사용하여 다음 명령어로 쉽게 설치할 수 있습니다:</p>
<pre><code class="hljs language-js">brew install ollama
</code></pre>
<p>최신 버전은 0.1.44입니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">ollama -v
경고: 실행 중인 <span class="hljs-title class_">Ollama</span> 인스턴스에 연결할 수 없습니다
경고: 클라이언트 버전은 <span class="hljs-number">0.1</span><span class="hljs-number">.44</span>입니다
</code></pre>
<p>리눅스에서는 공식 스크립트로도 설치할 수 있습니다.</p>
<pre><code class="hljs language-js">curl -sSL <span class="hljs-attr">https</span>:<span class="hljs-comment">//ollama.com/install.sh | sh</span>
</code></pre>
<p>Ollama를 시작하고 컨테이너나 K8s 클러스터에서 접근할 수 있도록 환경 변수를 통해 수신 주소를 0.0.0.0으로 설정하세요.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-variable constant_">OLLAMA_HOST</span>=<span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> ollama start
</code></pre>
<pre><code class="hljs language-js">...
time=<span class="hljs-number">2024</span>-<span class="hljs-number">06</span>-16<span class="hljs-attr">T07</span>:<span class="hljs-number">54</span>:<span class="hljs-number">57.329</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=<span class="hljs-variable constant_">INFO</span> source=routes.<span class="hljs-property">go</span>:<span class="hljs-number">1057</span> msg=<span class="hljs-string">"127.0.0.1:11434에서 수신 대기 중 (버전 0.1.44)"</span>
time=<span class="hljs-number">2024</span>-<span class="hljs-number">06</span>-16<span class="hljs-attr">T07</span>:<span class="hljs-number">54</span>:<span class="hljs-number">57.329</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=<span class="hljs-variable constant_">INFO</span> source=payload.<span class="hljs-property">go</span>:<span class="hljs-number">30</span> msg=<span class="hljs-string">"임베디드 파일 추출 중"</span> dir=<span class="hljs-regexp">/var/</span>folders/9p/2tp6g0896715zst_bfkynff00000gn/T/ollama1722873865/runners
time=<span class="hljs-number">2024</span>-<span class="hljs-number">06</span>-16<span class="hljs-attr">T07</span>:<span class="hljs-number">54</span>:<span class="hljs-number">57.346</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=<span class="hljs-variable constant_">INFO</span> source=payload.<span class="hljs-property">go</span>:<span class="hljs-number">44</span> msg=<span class="hljs-string">"동적 LLM 라이브러리 [metal]"</span>
time=<span class="hljs-number">2024</span>-<span class="hljs-number">06</span>-16<span class="hljs-attr">T07</span>:<span class="hljs-number">54</span>:<span class="hljs-number">57.385</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=<span class="hljs-variable constant_">INFO</span> source=types.<span class="hljs-property">go</span>:<span class="hljs-number">71</span> msg=<span class="hljs-string">"추론 계산 중"</span> id=<span class="hljs-number">0</span> library=metal compute=<span class="hljs-string">""</span> driver=<span class="hljs-number">0.0</span> name=<span class="hljs-string">""</span> total=<span class="hljs-string">"21.3 GiB"</span> available=<span class="hljs-string">"21.3 GiB"</span>
</code></pre>
<h1>2. 큰 모델 다운로드 및 실행하기</h1>
<p>4월에 Meta에서 오픈 소스로 공개된 인기 있는 큰 모델 중 하나인 Llama3가 있습니다. Llama3에는 8B와 70B 두 가지 버전이 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>맥OS에서 실행 중이고, 8B 버전을 선택했어요. 8B 버전은 4.7GB이며, 빠른 인터넷 연결로 다운로드하면 3-4분이 소요돼요.</p>
<pre><code class="hljs language-js">ollama run llama3
</code></pre>
<p>제 M1 Pro에서 32GB 메모리를 사용하고 있는데, 실행하는 데 약 12초 정도 걸려요.</p>
<pre><code class="hljs language-js">time=<span class="hljs-number">2024</span>-<span class="hljs-number">06</span>-17<span class="hljs-attr">T09</span>:<span class="hljs-number">30</span>:<span class="hljs-number">25.070</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=<span class="hljs-variable constant_">INFO</span> source=server.<span class="hljs-property">go</span>:<span class="hljs-number">572</span> msg=<span class="hljs-string">"llama runner started in 12.58 seconds"</span>
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>각 쿼리마다 약 14초가 소요됩니다.</p>
<pre><code class="hljs language-js">curl <span class="hljs-attr">http</span>:<span class="hljs-comment">//localhost:11434/api/generate -d '{</span>
  <span class="hljs-string">"model"</span>: <span class="hljs-string">"llama3"</span>,
  <span class="hljs-string">"prompt"</span>: <span class="hljs-string">"Why is the sky blue?"</span>,
  <span class="hljs-string">"stream"</span>: <span class="hljs-literal">false</span>
}<span class="hljs-string">'
</span></code></pre>
<pre><code class="hljs language-js">....
<span class="hljs-string">"total_duration"</span>:<span class="hljs-number">14064009500</span>,<span class="hljs-string">"load_duration"</span>:<span class="hljs-number">1605750</span>,<span class="hljs-string">"prompt_eval_duration"</span>:<span class="hljs-number">166998000</span>,<span class="hljs-string">"eval_count"</span>:<span class="hljs-number">419</span>,<span class="hljs-string">"eval_duration"</span>:<span class="hljs-number">13894579000</span>}
</code></pre>
<h1>3. K8sGPT CLI 백엔드 구성하기</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>만약 k8sgpt-operator를 테스트하려면 이 단계를 건너뛸 수 있어요.</p>
<p>k8sgpt의 백엔드로 Ollama REST API를 사용할 거에요. 이 API는 추론 제공자로 기능하며, backend 유형은 localai로 선택했어요. LocalAI는 OpenAI API와 호환되며, 실제 제공자는 여전히 Llama를 실행하는 Ollama일 거예요.</p>
<pre><code class="hljs language-js">k8sgpt auth add --backend localai --model llama3 --baseurl <span class="hljs-attr">http</span>:<span class="hljs-comment">//localhost:11434/v1</span>
</code></pre>
<p>이를 기본 제공자로 설정하세요.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">k8sgpt auth <span class="hljs-keyword">default</span> --provider localai
localai로 기본 제공자가 설정되었습니다.

테스트 중:

image-not-exist 이미지를 사용하여 k8s 내에서 <span class="hljs-title class_">Pod</span>를 생성합니다.

kubectl get po k8sgpt-test
이름          준비     상태         다시 시작     나이
k8sgpt-test   <span class="hljs-number">0</span>/<span class="hljs-number">1</span>     <span class="hljs-title class_">ErrImagePull</span>   <span class="hljs-number">0</span>          <span class="hljs-number">6</span>초

&#x3C;!-- ui-station 사각형 -->
<span class="xml"><span class="hljs-tag">&#x3C;<span class="hljs-name">ins</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"adsbygoogle"</span>
<span class="hljs-attr">style</span>=<span class="hljs-string">"display:block"</span>
<span class="hljs-attr">data-ad-client</span>=<span class="hljs-string">"ca-pub-4877378276818686"</span>
<span class="hljs-attr">data-ad-slot</span>=<span class="hljs-string">"7249294152"</span>
<span class="hljs-attr">data-ad-format</span>=<span class="hljs-string">"auto"</span>
<span class="hljs-attr">data-full-width-responsive</span>=<span class="hljs-string">"true"</span>></span><span class="hljs-tag">&#x3C;/<span class="hljs-name">ins</span>></span></span>
<span class="xml"><span class="hljs-tag">&#x3C;<span class="hljs-name">script</span>></span><span class="javascript">
(adsbygoogle = <span class="hljs-variable language_">window</span>.<span class="hljs-property">adsbygoogle</span> || []).<span class="hljs-title function_">push</span>({});
</span><span class="hljs-tag">&#x3C;/<span class="hljs-name">script</span>></span></span>

에러를 분석하려면 k8sgpt를 사용해보세요.

k8sgpt analyze --explain --filter=<span class="hljs-title class_">Pod</span> --namespace=<span class="hljs-keyword">default</span> --output=json

{
  <span class="hljs-string">"provider"</span>: <span class="hljs-string">"localai"</span>,
  <span class="hljs-string">"errors"</span>: <span class="hljs-literal">null</span>,
  <span class="hljs-string">"status"</span>: <span class="hljs-string">"ProblemDetected"</span>,
  <span class="hljs-string">"problems"</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">"results"</span>: [
    {
      <span class="hljs-string">"kind"</span>: <span class="hljs-string">"Pod"</span>,
      <span class="hljs-string">"name"</span>: <span class="hljs-string">"default/k8sgpt-test"</span>,
      <span class="hljs-string">"error"</span>: [
        {
          <span class="hljs-string">"Text"</span>: <span class="hljs-string">"Back-off pulling image \"image-not-exist\""</span>,
          <span class="hljs-string">"KubernetesDoc"</span>: <span class="hljs-string">""</span>,
          <span class="hljs-string">"Sensitive"</span>: []
        }
      ],
      <span class="hljs-string">"details"</span>: <span class="hljs-string">"Error: Back-off pulling image \"image-not-exist\"\n\nSolution: \n1. Check if the image exists on Docker Hub or your local registry.\n2. If not, create the image using a Dockerfile and build it.\n3. If the image exists, check the spelling and try again.\n4. Verify the image repository URL in your Kubernetes configuration file (e.g., deployment.yaml)."</span>,
      <span class="hljs-string">"parentObject"</span>: <span class="hljs-string">""</span>
    }
  ]
}

# <span class="hljs-number">4.</span> k8sgpt-operator 배포 및 설정하기

&#x3C;!-- ui-station 사각형 -->
<span class="xml"><span class="hljs-tag">&#x3C;<span class="hljs-name">ins</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"adsbygoogle"</span>
<span class="hljs-attr">style</span>=<span class="hljs-string">"display:block"</span>
<span class="hljs-attr">data-ad-client</span>=<span class="hljs-string">"ca-pub-4877378276818686"</span>
<span class="hljs-attr">data-ad-slot</span>=<span class="hljs-string">"7249294152"</span>
<span class="hljs-attr">data-ad-format</span>=<span class="hljs-string">"auto"</span>
<span class="hljs-attr">data-full-width-responsive</span>=<span class="hljs-string">"true"</span>></span><span class="hljs-tag">&#x3C;/<span class="hljs-name">ins</span>></span></span>
<span class="xml"><span class="hljs-tag">&#x3C;<span class="hljs-name">script</span>></span><span class="javascript">
(adsbygoogle = <span class="hljs-variable language_">window</span>.<span class="hljs-property">adsbygoogle</span> || []).<span class="hljs-title function_">push</span>({});
</span><span class="hljs-tag">&#x3C;/<span class="hljs-name">script</span>></span></span>

k8sgpt-operator은 클러스터 내에서 k8sgpt를 자동화할 수 있습니다. <span class="hljs-title class_">Helm</span>을 사용하여 쉽게 설치할 수 있어요.

</code></pre>
<p>helm repo add k8sgpt <a href="https://charts.k8sgpt.ai/" rel="nofollow" target="_blank">https://charts.k8sgpt.ai/</a>
helm repo update
helm install release k8sgpt/k8sgpt-operator -n k8sgpt --create-namespace</p>
<p>k8sgpt-operator는 K8sGPT를 구성하고 분석 결과를 출력하는 Result를 위한 두 가지 CRD를 제공합니다.</p>
<p>kubectl api-resources | grep -i gpt
k8sgpts core.k8sgpt.ai/v1alpha1 true K8sGPT
results core.k8sgpt.ai/v1alpha1 true Result</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Ollama의 IP 주소를 baseUrl로 사용하여 K8sGPT를 구성하세요.</p>
<pre><code class="hljs language-js">kubectl apply -n k8sgpt -f - &#x3C;&#x3C; <span class="hljs-variable constant_">EOF</span>
<span class="hljs-attr">apiVersion</span>: core.<span class="hljs-property">k8sgpt</span>.<span class="hljs-property">ai</span>/v1alpha1
<span class="hljs-attr">kind</span>: K8sGPT
<span class="hljs-attr">metadata</span>:
  <span class="hljs-attr">name</span>: k8sgpt-ollama
<span class="hljs-attr">spec</span>:
  <span class="hljs-attr">ai</span>:
    <span class="hljs-attr">enabled</span>: <span class="hljs-literal">true</span>
    <span class="hljs-attr">model</span>: llama3
    <span class="hljs-attr">backend</span>: localai
    <span class="hljs-attr">baseUrl</span>: <span class="hljs-attr">http</span>:<span class="hljs-comment">//198.19.249.3:11434/v1</span>
  <span class="hljs-attr">noCache</span>: <span class="hljs-literal">false</span>
  <span class="hljs-attr">filters</span>: [<span class="hljs-string">"Pod"</span>]
  <span class="hljs-attr">repository</span>: ghcr.<span class="hljs-property">io</span>/k8sgpt-ai/k8sgpt
  <span class="hljs-attr">version</span>: v0<span class="hljs-number">.3</span><span class="hljs-number">.8</span>
<span class="hljs-variable constant_">EOF</span>
</code></pre>
<p>K8sGPT CR을 생성한 후, 연산자(operator)가 이를 위한 파드를 자동으로 만듭니다. result CR을 확인하면 동일한 결과가 표시됩니다.</p>
<pre><code class="hljs language-js">kubectl get result -n k8sgpt -o jsonpath=<span class="hljs-string">'{.items[].spec}'</span> | jq .
{
  <span class="hljs-string">"backend"</span>: <span class="hljs-string">"localai"</span>,
  <span class="hljs-string">"details"</span>: <span class="hljs-string">"Error: Kubernetes is unable to pull the image \"image-not-exist\" due to it not existing.\n\nSolution: \n1. Check if the image actually exists.\n2. If not, create the image or use an alternative one.\n3. If the image does exist, ensure that the Docker daemon and registry are properly configured."</span>,
  <span class="hljs-string">"error"</span>: [
    {
      <span class="hljs-string">"text"</span>: <span class="hljs-string">"Back-off pulling image \"image-not-exist\""</span>
    }
  ],
  <span class="hljs-string">"kind"</span>: <span class="hljs-string">"Pod"</span>,
  <span class="hljs-string">"name"</span>: <span class="hljs-string">"default/k8sgpt-test"</span>,
  <span class="hljs-string">"parentObject"</span>: <span class="hljs-string">""</span>
}
</code></pre>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"K8sGPT  Ollama 무료 Kubernetes 자동 진단 솔루션 사용법","description":"","date":"2024-06-23 23:00","slug":"2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution","content":"\n![Kubernetes Automated Diagnosis Tool: k8sgpt-operator](/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_0.png)\n\n주말에 블로그 초고를 확인했더니 이 글이 있었어요. 한 해 전 'Kubernetes Automated Diagnosis Tool: k8sgpt-operator'를 쓸 때의 기억이 떠오르네요. 처음에는 K8sGPT + LocalAI를 써보려 했지만, Ollama로 시도해보니 더 사용하기 편리했어요. 게다가 Ollama는 OpenAI API를 지원하기도 해서 Ollama로 바꾸기로 결정했죠.\n\nk8sgpt-operator를 소개하는 글을 게시한 후 몇몇 독자들이 OpenAI를 사용하기 위한 높은 진입 장벽을 언급했어요. 이 문제는 정말 어려운 문제이지만 극복할 수 있는 문제에요. 하지만 이 글은 그 문제를 해결하는 게 아니라 OpenAI 대안인 Ollama를 소개하기 위한 글이에요. 작년 말에 k8sgpt는 CNCF Sandbox에 들어갔어요.\n\n# 1. Ollama 설치하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![Ollama](/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_1.png)\n\nOllama은 로컬이나 클라우드에서 쉽게 설치하고 실행할 수 있는 여러 대형 모델을 지원하는 오픈 소스 대형 모델 도구입니다. 매우 사용하기 편리하며 간단한 명령어로 실행할 수 있습니다. macOS에서는 homebrew를 사용하여 다음 명령어로 쉽게 설치할 수 있습니다:\n\n```js\nbrew install ollama\n```\n\n최신 버전은 0.1.44입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nollama -v\n경고: 실행 중인 Ollama 인스턴스에 연결할 수 없습니다\n경고: 클라이언트 버전은 0.1.44입니다\n```\n\n리눅스에서는 공식 스크립트로도 설치할 수 있습니다.\n\n```js\ncurl -sSL https://ollama.com/install.sh | sh\n```\n\nOllama를 시작하고 컨테이너나 K8s 클러스터에서 접근할 수 있도록 환경 변수를 통해 수신 주소를 0.0.0.0으로 설정하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nOLLAMA_HOST=0.0.0.0 ollama start\n```\n\n```js\n...\ntime=2024-06-16T07:54:57.329+08:00 level=INFO source=routes.go:1057 msg=\"127.0.0.1:11434에서 수신 대기 중 (버전 0.1.44)\"\ntime=2024-06-16T07:54:57.329+08:00 level=INFO source=payload.go:30 msg=\"임베디드 파일 추출 중\" dir=/var/folders/9p/2tp6g0896715zst_bfkynff00000gn/T/ollama1722873865/runners\ntime=2024-06-16T07:54:57.346+08:00 level=INFO source=payload.go:44 msg=\"동적 LLM 라이브러리 [metal]\"\ntime=2024-06-16T07:54:57.385+08:00 level=INFO source=types.go:71 msg=\"추론 계산 중\" id=0 library=metal compute=\"\" driver=0.0 name=\"\" total=\"21.3 GiB\" available=\"21.3 GiB\"\n```\n\n# 2. 큰 모델 다운로드 및 실행하기\n\n4월에 Meta에서 오픈 소스로 공개된 인기 있는 큰 모델 중 하나인 Llama3가 있습니다. Llama3에는 8B와 70B 두 가지 버전이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n맥OS에서 실행 중이고, 8B 버전을 선택했어요. 8B 버전은 4.7GB이며, 빠른 인터넷 연결로 다운로드하면 3-4분이 소요돼요.\n\n```js\nollama run llama3\n```\n\n제 M1 Pro에서 32GB 메모리를 사용하고 있는데, 실행하는 데 약 12초 정도 걸려요.\n\n```js\ntime=2024-06-17T09:30:25.070+08:00 level=INFO source=server.go:572 msg=\"llama runner started in 12.58 seconds\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n각 쿼리마다 약 14초가 소요됩니다.\n\n```js\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3\",\n  \"prompt\": \"Why is the sky blue?\",\n  \"stream\": false\n}'\n```\n\n```js\n....\n\"total_duration\":14064009500,\"load_duration\":1605750,\"prompt_eval_duration\":166998000,\"eval_count\":419,\"eval_duration\":13894579000}\n```\n\n# 3. K8sGPT CLI 백엔드 구성하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만약 k8sgpt-operator를 테스트하려면 이 단계를 건너뛸 수 있어요.\n\nk8sgpt의 백엔드로 Ollama REST API를 사용할 거에요. 이 API는 추론 제공자로 기능하며, backend 유형은 localai로 선택했어요. LocalAI는 OpenAI API와 호환되며, 실제 제공자는 여전히 Llama를 실행하는 Ollama일 거예요.\n\n```js\nk8sgpt auth add --backend localai --model llama3 --baseurl http://localhost:11434/v1\n```\n\n이를 기본 제공자로 설정하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nk8sgpt auth default --provider localai\nlocalai로 기본 제공자가 설정되었습니다.\n\n테스트 중:\n\nimage-not-exist 이미지를 사용하여 k8s 내에서 Pod를 생성합니다.\n\nkubectl get po k8sgpt-test\n이름          준비     상태         다시 시작     나이\nk8sgpt-test   0/1     ErrImagePull   0          6초\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n에러를 분석하려면 k8sgpt를 사용해보세요.\n\nk8sgpt analyze --explain --filter=Pod --namespace=default --output=json\n\n{\n  \"provider\": \"localai\",\n  \"errors\": null,\n  \"status\": \"ProblemDetected\",\n  \"problems\": 1,\n  \"results\": [\n    {\n      \"kind\": \"Pod\",\n      \"name\": \"default/k8sgpt-test\",\n      \"error\": [\n        {\n          \"Text\": \"Back-off pulling image \\\"image-not-exist\\\"\",\n          \"KubernetesDoc\": \"\",\n          \"Sensitive\": []\n        }\n      ],\n      \"details\": \"Error: Back-off pulling image \\\"image-not-exist\\\"\\n\\nSolution: \\n1. Check if the image exists on Docker Hub or your local registry.\\n2. If not, create the image using a Dockerfile and build it.\\n3. If the image exists, check the spelling and try again.\\n4. Verify the image repository URL in your Kubernetes configuration file (e.g., deployment.yaml).\",\n      \"parentObject\": \"\"\n    }\n  ]\n}\n\n# 4. k8sgpt-operator 배포 및 설정하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nk8sgpt-operator은 클러스터 내에서 k8sgpt를 자동화할 수 있습니다. Helm을 사용하여 쉽게 설치할 수 있어요.\n\n```\n\nhelm repo add k8sgpt https://charts.k8sgpt.ai/\nhelm repo update\nhelm install release k8sgpt/k8sgpt-operator -n k8sgpt --create-namespace\n\nk8sgpt-operator는 K8sGPT를 구성하고 분석 결과를 출력하는 Result를 위한 두 가지 CRD를 제공합니다.\n\nkubectl api-resources | grep -i gpt\nk8sgpts core.k8sgpt.ai/v1alpha1 true K8sGPT\nresults core.k8sgpt.ai/v1alpha1 true Result\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nOllama의 IP 주소를 baseUrl로 사용하여 K8sGPT를 구성하세요.\n\n```js\nkubectl apply -n k8sgpt -f - \u003c\u003c EOF\napiVersion: core.k8sgpt.ai/v1alpha1\nkind: K8sGPT\nmetadata:\n  name: k8sgpt-ollama\nspec:\n  ai:\n    enabled: true\n    model: llama3\n    backend: localai\n    baseUrl: http://198.19.249.3:11434/v1\n  noCache: false\n  filters: [\"Pod\"]\n  repository: ghcr.io/k8sgpt-ai/k8sgpt\n  version: v0.3.8\nEOF\n```\n\nK8sGPT CR을 생성한 후, 연산자(operator)가 이를 위한 파드를 자동으로 만듭니다. result CR을 확인하면 동일한 결과가 표시됩니다.\n\n```js\nkubectl get result -n k8sgpt -o jsonpath='{.items[].spec}' | jq .\n{\n  \"backend\": \"localai\",\n  \"details\": \"Error: Kubernetes is unable to pull the image \\\"image-not-exist\\\" due to it not existing.\\n\\nSolution: \\n1. Check if the image actually exists.\\n2. If not, create the image or use an alternative one.\\n3. If the image does exist, ensure that the Docker daemon and registry are properly configured.\",\n  \"error\": [\n    {\n      \"text\": \"Back-off pulling image \\\"image-not-exist\\\"\"\n    }\n  ],\n  \"kind\": \"Pod\",\n  \"name\": \"default/k8sgpt-test\",\n  \"parentObject\": \"\"\n}\n```\n","ogImage":{"url":"/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_0.png"},"coverImage":"/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_0.png\" alt=\"Kubernetes Automated Diagnosis Tool: k8sgpt-operator\"\u003e\u003c/p\u003e\n\u003cp\u003e주말에 블로그 초고를 확인했더니 이 글이 있었어요. 한 해 전 'Kubernetes Automated Diagnosis Tool: k8sgpt-operator'를 쓸 때의 기억이 떠오르네요. 처음에는 K8sGPT + LocalAI를 써보려 했지만, Ollama로 시도해보니 더 사용하기 편리했어요. 게다가 Ollama는 OpenAI API를 지원하기도 해서 Ollama로 바꾸기로 결정했죠.\u003c/p\u003e\n\u003cp\u003ek8sgpt-operator를 소개하는 글을 게시한 후 몇몇 독자들이 OpenAI를 사용하기 위한 높은 진입 장벽을 언급했어요. 이 문제는 정말 어려운 문제이지만 극복할 수 있는 문제에요. 하지만 이 글은 그 문제를 해결하는 게 아니라 OpenAI 대안인 Ollama를 소개하기 위한 글이에요. 작년 말에 k8sgpt는 CNCF Sandbox에 들어갔어요.\u003c/p\u003e\n\u003ch1\u003e1. Ollama 설치하기\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution_1.png\" alt=\"Ollama\"\u003e\u003c/p\u003e\n\u003cp\u003eOllama은 로컬이나 클라우드에서 쉽게 설치하고 실행할 수 있는 여러 대형 모델을 지원하는 오픈 소스 대형 모델 도구입니다. 매우 사용하기 편리하며 간단한 명령어로 실행할 수 있습니다. macOS에서는 homebrew를 사용하여 다음 명령어로 쉽게 설치할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ebrew install ollama\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e최신 버전은 0.1.44입니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eollama -v\n경고: 실행 중인 \u003cspan class=\"hljs-title class_\"\u003eOllama\u003c/span\u003e 인스턴스에 연결할 수 없습니다\n경고: 클라이언트 버전은 \u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.44\u003c/span\u003e입니다\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e리눅스에서는 공식 스크립트로도 설치할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ecurl -sSL \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//ollama.com/install.sh | sh\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOllama를 시작하고 컨테이너나 K8s 클러스터에서 접근할 수 있도록 환경 변수를 통해 수신 주소를 0.0.0.0으로 설정하세요.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-variable constant_\"\u003eOLLAMA_HOST\u003c/span\u003e=\u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.0\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.0\u003c/span\u003e ollama start\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e...\ntime=\u003cspan class=\"hljs-number\"\u003e2024\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e06\u003c/span\u003e-16\u003cspan class=\"hljs-attr\"\u003eT07\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e54\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e57.329\u003c/span\u003e+\u003cspan class=\"hljs-number\"\u003e08\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e00\u003c/span\u003e level=\u003cspan class=\"hljs-variable constant_\"\u003eINFO\u003c/span\u003e source=routes.\u003cspan class=\"hljs-property\"\u003ego\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e1057\u003c/span\u003e msg=\u003cspan class=\"hljs-string\"\u003e\"127.0.0.1:11434에서 수신 대기 중 (버전 0.1.44)\"\u003c/span\u003e\ntime=\u003cspan class=\"hljs-number\"\u003e2024\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e06\u003c/span\u003e-16\u003cspan class=\"hljs-attr\"\u003eT07\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e54\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e57.329\u003c/span\u003e+\u003cspan class=\"hljs-number\"\u003e08\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e00\u003c/span\u003e level=\u003cspan class=\"hljs-variable constant_\"\u003eINFO\u003c/span\u003e source=payload.\u003cspan class=\"hljs-property\"\u003ego\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e msg=\u003cspan class=\"hljs-string\"\u003e\"임베디드 파일 추출 중\"\u003c/span\u003e dir=\u003cspan class=\"hljs-regexp\"\u003e/var/\u003c/span\u003efolders/9p/2tp6g0896715zst_bfkynff00000gn/T/ollama1722873865/runners\ntime=\u003cspan class=\"hljs-number\"\u003e2024\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e06\u003c/span\u003e-16\u003cspan class=\"hljs-attr\"\u003eT07\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e54\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e57.346\u003c/span\u003e+\u003cspan class=\"hljs-number\"\u003e08\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e00\u003c/span\u003e level=\u003cspan class=\"hljs-variable constant_\"\u003eINFO\u003c/span\u003e source=payload.\u003cspan class=\"hljs-property\"\u003ego\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e44\u003c/span\u003e msg=\u003cspan class=\"hljs-string\"\u003e\"동적 LLM 라이브러리 [metal]\"\u003c/span\u003e\ntime=\u003cspan class=\"hljs-number\"\u003e2024\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e06\u003c/span\u003e-16\u003cspan class=\"hljs-attr\"\u003eT07\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e54\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e57.385\u003c/span\u003e+\u003cspan class=\"hljs-number\"\u003e08\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e00\u003c/span\u003e level=\u003cspan class=\"hljs-variable constant_\"\u003eINFO\u003c/span\u003e source=types.\u003cspan class=\"hljs-property\"\u003ego\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e71\u003c/span\u003e msg=\u003cspan class=\"hljs-string\"\u003e\"추론 계산 중\"\u003c/span\u003e id=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e library=metal compute=\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e driver=\u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e name=\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e total=\u003cspan class=\"hljs-string\"\u003e\"21.3 GiB\"\u003c/span\u003e available=\u003cspan class=\"hljs-string\"\u003e\"21.3 GiB\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e2. 큰 모델 다운로드 및 실행하기\u003c/h1\u003e\n\u003cp\u003e4월에 Meta에서 오픈 소스로 공개된 인기 있는 큰 모델 중 하나인 Llama3가 있습니다. Llama3에는 8B와 70B 두 가지 버전이 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e맥OS에서 실행 중이고, 8B 버전을 선택했어요. 8B 버전은 4.7GB이며, 빠른 인터넷 연결로 다운로드하면 3-4분이 소요돼요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eollama run llama3\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e제 M1 Pro에서 32GB 메모리를 사용하고 있는데, 실행하는 데 약 12초 정도 걸려요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etime=\u003cspan class=\"hljs-number\"\u003e2024\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e06\u003c/span\u003e-17\u003cspan class=\"hljs-attr\"\u003eT09\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e25.070\u003c/span\u003e+\u003cspan class=\"hljs-number\"\u003e08\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e00\u003c/span\u003e level=\u003cspan class=\"hljs-variable constant_\"\u003eINFO\u003c/span\u003e source=server.\u003cspan class=\"hljs-property\"\u003ego\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e572\u003c/span\u003e msg=\u003cspan class=\"hljs-string\"\u003e\"llama runner started in 12.58 seconds\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e각 쿼리마다 약 14초가 소요됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ecurl \u003cspan class=\"hljs-attr\"\u003ehttp\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//localhost:11434/api/generate -d '{\u003c/span\u003e\n  \u003cspan class=\"hljs-string\"\u003e\"model\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"llama3\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"prompt\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Why is the sky blue?\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"stream\"\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e\n}\u003cspan class=\"hljs-string\"\u003e'\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e....\n\u003cspan class=\"hljs-string\"\u003e\"total_duration\"\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e14064009500\u003c/span\u003e,\u003cspan class=\"hljs-string\"\u003e\"load_duration\"\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e1605750\u003c/span\u003e,\u003cspan class=\"hljs-string\"\u003e\"prompt_eval_duration\"\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e166998000\u003c/span\u003e,\u003cspan class=\"hljs-string\"\u003e\"eval_count\"\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e419\u003c/span\u003e,\u003cspan class=\"hljs-string\"\u003e\"eval_duration\"\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e13894579000\u003c/span\u003e}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e3. K8sGPT CLI 백엔드 구성하기\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e만약 k8sgpt-operator를 테스트하려면 이 단계를 건너뛸 수 있어요.\u003c/p\u003e\n\u003cp\u003ek8sgpt의 백엔드로 Ollama REST API를 사용할 거에요. 이 API는 추론 제공자로 기능하며, backend 유형은 localai로 선택했어요. LocalAI는 OpenAI API와 호환되며, 실제 제공자는 여전히 Llama를 실행하는 Ollama일 거예요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ek8sgpt auth add --backend localai --model llama3 --baseurl \u003cspan class=\"hljs-attr\"\u003ehttp\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//localhost:11434/v1\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이를 기본 제공자로 설정하세요.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ek8sgpt auth \u003cspan class=\"hljs-keyword\"\u003edefault\u003c/span\u003e --provider localai\nlocalai로 기본 제공자가 설정되었습니다.\n\n테스트 중:\n\nimage-not-exist 이미지를 사용하여 k8s 내에서 \u003cspan class=\"hljs-title class_\"\u003ePod\u003c/span\u003e를 생성합니다.\n\nkubectl get po k8sgpt-test\n이름          준비     상태         다시 시작     나이\nk8sgpt-test   \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e/\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e     \u003cspan class=\"hljs-title class_\"\u003eErrImagePull\u003c/span\u003e   \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e          \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e초\n\n\u0026#x3C;!-- ui-station 사각형 --\u003e\n\u003cspan class=\"xml\"\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;\u003cspan class=\"hljs-name\"\u003eins\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eclass\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"adsbygoogle\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003estyle\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"display:block\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-ad-client\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"ca-pub-4877378276818686\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-ad-slot\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"7249294152\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-ad-format\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"auto\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-full-width-responsive\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"true\"\u003c/span\u003e\u003e\u003c/span\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;/\u003cspan class=\"hljs-name\"\u003eins\u003c/span\u003e\u003e\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"xml\"\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;\u003cspan class=\"hljs-name\"\u003escript\u003c/span\u003e\u003e\u003c/span\u003e\u003cspan class=\"javascript\"\u003e\n(adsbygoogle = \u003cspan class=\"hljs-variable language_\"\u003ewindow\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eadsbygoogle\u003c/span\u003e || []).\u003cspan class=\"hljs-title function_\"\u003epush\u003c/span\u003e({});\n\u003c/span\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;/\u003cspan class=\"hljs-name\"\u003escript\u003c/span\u003e\u003e\u003c/span\u003e\u003c/span\u003e\n\n에러를 분석하려면 k8sgpt를 사용해보세요.\n\nk8sgpt analyze --explain --filter=\u003cspan class=\"hljs-title class_\"\u003ePod\u003c/span\u003e --namespace=\u003cspan class=\"hljs-keyword\"\u003edefault\u003c/span\u003e --output=json\n\n{\n  \u003cspan class=\"hljs-string\"\u003e\"provider\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"localai\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"errors\"\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003enull\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"status\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"ProblemDetected\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"problems\"\u003c/span\u003e: \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"results\"\u003c/span\u003e: [\n    {\n      \u003cspan class=\"hljs-string\"\u003e\"kind\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Pod\"\u003c/span\u003e,\n      \u003cspan class=\"hljs-string\"\u003e\"name\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"default/k8sgpt-test\"\u003c/span\u003e,\n      \u003cspan class=\"hljs-string\"\u003e\"error\"\u003c/span\u003e: [\n        {\n          \u003cspan class=\"hljs-string\"\u003e\"Text\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Back-off pulling image \\\"image-not-exist\\\"\"\u003c/span\u003e,\n          \u003cspan class=\"hljs-string\"\u003e\"KubernetesDoc\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e,\n          \u003cspan class=\"hljs-string\"\u003e\"Sensitive\"\u003c/span\u003e: []\n        }\n      ],\n      \u003cspan class=\"hljs-string\"\u003e\"details\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Error: Back-off pulling image \\\"image-not-exist\\\"\\n\\nSolution: \\n1. Check if the image exists on Docker Hub or your local registry.\\n2. If not, create the image using a Dockerfile and build it.\\n3. If the image exists, check the spelling and try again.\\n4. Verify the image repository URL in your Kubernetes configuration file (e.g., deployment.yaml).\"\u003c/span\u003e,\n      \u003cspan class=\"hljs-string\"\u003e\"parentObject\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n    }\n  ]\n}\n\n# \u003cspan class=\"hljs-number\"\u003e4.\u003c/span\u003e k8sgpt-operator 배포 및 설정하기\n\n\u0026#x3C;!-- ui-station 사각형 --\u003e\n\u003cspan class=\"xml\"\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;\u003cspan class=\"hljs-name\"\u003eins\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eclass\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"adsbygoogle\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003estyle\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"display:block\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-ad-client\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"ca-pub-4877378276818686\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-ad-slot\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"7249294152\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-ad-format\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"auto\"\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003edata-full-width-responsive\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"true\"\u003c/span\u003e\u003e\u003c/span\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;/\u003cspan class=\"hljs-name\"\u003eins\u003c/span\u003e\u003e\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"xml\"\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;\u003cspan class=\"hljs-name\"\u003escript\u003c/span\u003e\u003e\u003c/span\u003e\u003cspan class=\"javascript\"\u003e\n(adsbygoogle = \u003cspan class=\"hljs-variable language_\"\u003ewindow\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eadsbygoogle\u003c/span\u003e || []).\u003cspan class=\"hljs-title function_\"\u003epush\u003c/span\u003e({});\n\u003c/span\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;/\u003cspan class=\"hljs-name\"\u003escript\u003c/span\u003e\u003e\u003c/span\u003e\u003c/span\u003e\n\nk8sgpt-operator은 클러스터 내에서 k8sgpt를 자동화할 수 있습니다. \u003cspan class=\"hljs-title class_\"\u003eHelm\u003c/span\u003e을 사용하여 쉽게 설치할 수 있어요.\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ehelm repo add k8sgpt \u003ca href=\"https://charts.k8sgpt.ai/\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://charts.k8sgpt.ai/\u003c/a\u003e\nhelm repo update\nhelm install release k8sgpt/k8sgpt-operator -n k8sgpt --create-namespace\u003c/p\u003e\n\u003cp\u003ek8sgpt-operator는 K8sGPT를 구성하고 분석 결과를 출력하는 Result를 위한 두 가지 CRD를 제공합니다.\u003c/p\u003e\n\u003cp\u003ekubectl api-resources | grep -i gpt\nk8sgpts core.k8sgpt.ai/v1alpha1 true K8sGPT\nresults core.k8sgpt.ai/v1alpha1 true Result\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eOllama의 IP 주소를 baseUrl로 사용하여 K8sGPT를 구성하세요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ekubectl apply -n k8sgpt -f - \u0026#x3C;\u0026#x3C; \u003cspan class=\"hljs-variable constant_\"\u003eEOF\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003eapiVersion\u003c/span\u003e: core.\u003cspan class=\"hljs-property\"\u003ek8sgpt\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eai\u003c/span\u003e/v1alpha1\n\u003cspan class=\"hljs-attr\"\u003ekind\u003c/span\u003e: K8sGPT\n\u003cspan class=\"hljs-attr\"\u003emetadata\u003c/span\u003e:\n  \u003cspan class=\"hljs-attr\"\u003ename\u003c/span\u003e: k8sgpt-ollama\n\u003cspan class=\"hljs-attr\"\u003espec\u003c/span\u003e:\n  \u003cspan class=\"hljs-attr\"\u003eai\u003c/span\u003e:\n    \u003cspan class=\"hljs-attr\"\u003eenabled\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: llama3\n    \u003cspan class=\"hljs-attr\"\u003ebackend\u003c/span\u003e: localai\n    \u003cspan class=\"hljs-attr\"\u003ebaseUrl\u003c/span\u003e: \u003cspan class=\"hljs-attr\"\u003ehttp\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//198.19.249.3:11434/v1\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003enoCache\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003efilters\u003c/span\u003e: [\u003cspan class=\"hljs-string\"\u003e\"Pod\"\u003c/span\u003e]\n  \u003cspan class=\"hljs-attr\"\u003erepository\u003c/span\u003e: ghcr.\u003cspan class=\"hljs-property\"\u003eio\u003c/span\u003e/k8sgpt-ai/k8sgpt\n  \u003cspan class=\"hljs-attr\"\u003eversion\u003c/span\u003e: v0\u003cspan class=\"hljs-number\"\u003e.3\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.8\u003c/span\u003e\n\u003cspan class=\"hljs-variable constant_\"\u003eEOF\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eK8sGPT CR을 생성한 후, 연산자(operator)가 이를 위한 파드를 자동으로 만듭니다. result CR을 확인하면 동일한 결과가 표시됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ekubectl get result -n k8sgpt -o jsonpath=\u003cspan class=\"hljs-string\"\u003e'{.items[].spec}'\u003c/span\u003e | jq .\n{\n  \u003cspan class=\"hljs-string\"\u003e\"backend\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"localai\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"details\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Error: Kubernetes is unable to pull the image \\\"image-not-exist\\\" due to it not existing.\\n\\nSolution: \\n1. Check if the image actually exists.\\n2. If not, create the image or use an alternative one.\\n3. If the image does exist, ensure that the Docker daemon and registry are properly configured.\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"error\"\u003c/span\u003e: [\n    {\n      \u003cspan class=\"hljs-string\"\u003e\"text\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Back-off pulling image \\\"image-not-exist\\\"\"\u003c/span\u003e\n    }\n  ],\n  \u003cspan class=\"hljs-string\"\u003e\"kind\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Pod\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"name\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"default/k8sgpt-test\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-string\"\u003e\"parentObject\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-K8sGPTOllamaAFreeKubernetesAutomatedDiagnosticSolution"},"buildId":"wfHLuDA3kTGBYfaM5IGXk","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>