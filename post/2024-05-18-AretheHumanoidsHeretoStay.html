<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>휴머노이드는 여기에 머물러 있을까요 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-18-AretheHumanoidsHeretoStay" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="휴머노이드는 여기에 머물러 있을까요 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="휴머노이드는 여기에 머물러 있을까요 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-18-AretheHumanoidsHeretoStay" data-gatsby-head="true"/><meta name="twitter:title" content="휴머노이드는 여기에 머물러 있을까요 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-18 19:24" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/acd99c507555fdc6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/acd99c507555fdc6.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-4f7b40c1114f0d09.js" defer=""></script><script src="/_next/static/RZIEBQ2aNAp_DXFVTV6eL/_buildManifest.js" defer=""></script><script src="/_next/static/RZIEBQ2aNAp_DXFVTV6eL/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">휴머노이드는 여기에 머물러 있을까요</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="휴머노이드는 여기에 머물러 있을까요" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 18, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-18-AretheHumanoidsHeretoStay&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>매주 이런 식으로 새로운 업데이트를 내놓는 인간형 회사들을 볼 수 없네요. 옵티머스가 걸을 수 있어요? 디지트가 빈 토트백을 옮겼다구요? 피거도 그렇게 하는군요! 드디어 실제 회사들도 흥미를 느끼기 시작한 것 같아요. 테슬라부터 시작해서 아마존과 BMW에서도 이제는 "작동 중"이랍니다. 마치 집과 정원에서 우리에게 한 발짝 떨어진 것 같아요.</p>
<p>하지만 정말로 일하고 있는 걸까요? 보여지는 데모들은 보스턴 다이내믹스의 아틀라스가 파크our을 하는 것만큼 흥미로운 것이 아니라 humanoids가 생산적인 것 같지도 않아요. 그래서 시장이 정말로 흥분한 것일까요? Humanoids가 무언가를 준비하고 있는 걸까요? 저는 두 가지 이유로 humanoids에 흥분해요:</p>
<ol>
<li>인간형 로봇은 마침내 "브라운필드" 문제를 해결할 수도 있어요. 이것이 로봇 솔루션들이 실험 단계에 머무는 주된 이유이기도 하거든요.</li>
</ol>
<ol start="2">
<li>2023년에 기계 학습은 큰 발전을 이루었습니다. 컴퓨터들이 이번에 처음으로 노력의 스킬을 발휘하여 오픈 월드 환경에서 작동하고 접촉 시키는 것이 가능해졌습니다.</li>
</ol>
<h1>Greenfield vs. Brownfield</h1>
<p>로봇 공학은 아직 큰 산업이 아니며 대부분의 산업은 “Greenfield” 배치로만 성공을 거둡니다. 기존 공정을 개조하는 대신, 공장과 그 제품을 로봇 솔루션 주위에 설계합니다. 이것이 ABB, Fanuc 및 Kuka와 같은 기업들이 수익을 올리는 방식이며 자동차 산업을 위한 생산 라인과 같은 전문 솔루션을 구축합니다. 아마존도 이와 같은 원리로 Kiva 자동화 시스템과 함께 작동하는 건물 구축을 하고 있습니다. 반면, 기존 공정과 통합되는 솔루션 (기존 토지 또는 "갈색" 영역에)은 종종 생산적으로 성공하지 못하고 버려지는 경우가 많습니다.</p>
<p>아래 이미지는 이러한 딜레마를 설명합니다:</p>
<p><img src="/assets/img/2024-05-18-AretheHumanoidsHeretoStay_1.png" alt="2024-05-18-AretheHumanoidsHeretoStay_1.png"></p>
<p>작지만 성공한 커피 사업을 상상해보세요. 이 사업은 역사적으로 분리된 분쇄기, 커피 포트 및 열판을 사용하여 커피를 만들어 왔습니다. 여기에 "협력 로봇"이라는 자동화된 과정이 도입됩니다. 이런 로봇은 커피 포트를 열판 위에 놓는 등 일부 작업만 수행할 수 있고, 추가적인 장비들을 필요로 합니다. 이런 해결책은 기존 과정을 준비된 자동화 솔루션으로 교체하는 것이 실제로 쉽고 저렴하게 가능합니다. 에스프레소 메이커만 사면 끝이죠. 수동으로 만든 커피에 집착하는 사람들처럼, 산업 환경에서의 공정은 종종 다른 공정과 깊게 연결되어있어 하류 공정을 변경해야 할 수도 있습니다.</p>
<p>(계속)</p>
<p>이러한 매우 기본적인 작업들 다음에는 조립 작업장을 위한 키트를 생성하고 배포하고, 슈퍼마켓 선반이 깔끔하고 적절히 구비되어 있는지 확인하거나 식기 세척기, 커피 메이커 및 진공 청소기와 같은 가정용 가전제품을 작동하는 등 보다 복잡한 작업을 빠르게 수행하게 될 것입니다.</p>
<p>하지만 또 다른 이점도 있습니다: 전력에 연결되었거나 무선으로 충전 중이라면, 인간형 로봇은 휴식 없이 세 번의 교대 근무를 할 수 있으며, 학습한 모든 것은 즉시 동종 로봇들 모두에게 전달될 수 있습니다. 더욱 좋은 점은, 일단 인간형 로봇이 프로세스에 통합되면, 알고리즘을 통해 작업자들로부터 과도한 정직을 요구하는 Lean 및 Six-Sigma의 모든 기술을 완전히 디지털 방식으로 구현할 수 있게 되어 엄청난 생산성 향상을 이끌어낼 수도 있습니다.</p>
<p><img src="/assets/img/2024-05-18-AretheHumanoidsHeretoStay_2.png" alt="이미지"></p>
<p>투자자, 기업가 및 과학자들을 흥분하게 만드는 것은 이런 전망이며, 비록 게임이 오래 소요될 지라도요. 그럼에도 불구하고, 2023년에 역사책에 기록된 또 다른 Durchbruch 덕분에 아마도 많은 사람들이 모두 출자하지 않을까 합니다:</p>
<h1>기계 학습이 이끄는 전례 없는 능력</h1>
<p>2023년은 ChatGPT의 해였습니다. ChatGPT의 명백한 이점 외에, 트랜스포머 신경망 구조는 텍스트에 국한되지 않고 훨씬 더 강력해졌다는 것이 밝혀졌습니다. 그것은 이미지와 언어를 결합하는 능력으로 인해 기계 학습이 미리 정의된 클래스로의 지도 학습을 벗어나게 하였고, 로봇이 이전에 본 적이없는 물체를 다루도록 허용하였습니다. 예를 들어, "나사"라는 물체를 이미지에서 제로샷 방식으로 찾을 수 있는 Owl-VIT [1] 비전-언어 모델이 있습니다. "나사"가 무엇이며 어떻게 생겼는지에 대해 명시적으로 학습되지 않고도 가능합니다.</p>
<p><img src="/assets/img/2024-05-18-AretheHumanoidsHeretoStay_3.png" alt="이미지"></p>
<p>라벨링 및 물체 탐지가 완벽하지는 않지만, 비전 임베딩은 원격 조작된 데모와 결합하여 확산을 사용하여 시각 운동 표현을 학습할 수 있도록 허용합니다[2]. 마치 DallE나 Midjourney에서 이미지를 생성할 때 사용되는 방식과 유사합니다. 로봇은 텍스트를 프롬프트로 변환하는 대신, 센서 관측치를 궤적으로 변환합니다.</p>
<p>인간을 훈련시킬 때와 달리 현장에 배치된 로봇이 생산한 경험은 쉽게 다른 로봇으로 전달될 수 있습니다. 여기서 심지어 소수의 인간형 프로토타입만으로도 다양한 제조 및 가정 업무에 대한 전문 지식을 통한 무료롭 처리 양을 만들어낼 수 있습니다. 트랜스포머 모델이 자연스럽게 멀티모달이기 때문에 시각과 텍스트/음성 설명만 적용하는 것이 아니라 촉각적 정보, 소리 또는 진동을 받아들이고, 시맨틱한 구조화 정보와 연결하는 데 도움이 될 것입니다.</p>
<p>대형 언어 모델은 또한 인간 언어와 컴퓨터 코드 사이를 매끄럽게 오가며 소프트웨어 습득 및 인간 피드백을 기반으로 코드를 적절하게 수정할 수도 있을 것입니다. 최근 이 논문[3]과 이 비디오에서 보여준 것처럼, 로봇의 가능성에 대한 "API"를 제공받음으로써 ChatGPT는 합리적인 코드를 생성하고 인간 피드백에 따라 조정할 수 있습니다. 인간 지침서, 책 지식 또는 이 두 가지의 조합에서 위와 같은 예시인 전문적인 로봇 임무를 빠르게 학습할 수 있는 능력을 가진 LLM을 인터랙션 훈련을 통해 미세조정함으로써 더 향상시킬 수 있을 것입니다.</p>
<h1>다음은 무엇일까요?</h1>
<p>그래서 우리는 대규모로 인간형 로봇을 배치할 준비가 되어 있고, 곧 더 매력적인 사용 사례들을 보게 되겠죠? 많은 기업들이 하드웨어 중심 접근 방식을 선택하여 동적 보행과 기본 조작이 가능하다는 것을 입증했습니다. 아직은 이 로봇들이 많은 것을 실제로 하거나 더 많은 가치를 창출하지는 못하고 있습니다. 고가치 임무인 자율 키팅, 조립 또는 선반 보충과 같은 임무는 이미 어느 정도 시간이 경과했으며 이전 창업 시절에도 가능했습니다:</p>
<p>위의 비디오에 나오는 산업용 하드웨어와 현재 볼 수 있는 휴머노이드 사이에 중요한 차이가 있습니다. 처음부터 로봇을 만드는 것은 심각한 시스템 공학적 도전이 따르며 현재의 프로토 타입은 안정적인 기지에 장착된 협력 로봇의 0.1mm 정확도에서 현재는 상당히 멀리 떨어져 있을 것으로 보입니다. 관성과 진동을 제어하는 어려운 작업은 물론 토크 감지를 사용하여 이를 가능케하지만 대부분의 휴머노이드는 아직 이 기능이 없는 액추에이터에 의존하지만 저렴한 비용 접근 방식을 택하여 엔지니어링 아츠의 아름다운 로봇이 뻣뻣한 산업 시스템과 유사하다고 할 수 있을 정도의 선택을 했습니다.</p>
<p>따라서 다리가 없는 휴머노이드는?</p>
<p>누구나 로봇이 바로 다리가 필요할 것이라고 믿지 않습니다. 이러한 기업은 고가치의 조작 작업, 훈련 용이성 및 매끄러운 배치에 중점을 둡니다. 이 분야의 초기 사례 중 하나는 Rodney Brook의 "배터" (안식을 바라며) 로봇이며 나중에는 그의 한 팔로 된 후속자인 소이어가 있습니다:</p>
<p>Baxter가 슈퍼 저렴한 비용(`$25k에 이중 팔로봇)을 정밀성과 강성으로 바꾸는 지나치게 야 amb 계약의 하드웨어 디자인을 겪던 동안, Sawyer는 보다 전통적인 로봇 드라이브를 사용하여 최소한의 조립물과 기본적인 프로그래밍만으로도 다양한 응용 분야에서 성능을 발휘할 수 있습니다. Sawyer는 아직 몇몇 국가에서 판매 중이지만, 모든 “Cobots”이 겪는 브라운필드 문제에 시달립니다: 작업이 자동화 솔루션이 정당화할만큼 반복적인 경우, 이미 해당 솔루션이 만들어졌으며 상당히 더 나은, 빠르고 저렴할 가능성이 높습니다.</p>
<p>“정체된 상반신” 방식의 또 다른 예는 Giant AI인데, 이는 2023년에 공개되고 (사업을 종료한 채) 잠잠하게 알려진 비디오 시리즈로 나타났습니다:</p>
<p>Baxter와 마찬가지로, Giant의 Universal Worker는 기본 조작에 중점을 둔 정적 솔루션이었습니다. Baxter와 같이, Giant는 모든 하드웨어를 처음부터 개발했으며 힘줄 기반 접근법을 구현하여 (잠재적인) 비용 절감을 굉장한 개발 관리부담과 정확성으로 교환했으며, 제 시간에 진정한 고객 가치를 제공하지 못했습니다.</p>
<p>Giant의 일부 지적재산권은 Sanctuary.ai에서 살아 있으며, 여기서도 상체 민첩성에 중점을 두지만, 유압 구동 재래를 복원함으로써, 로봇이 정밀한 조작부터 무거운 들기까지 다양한 작업 범위에 대처할 수 있도록 해줍니다.</p>
<h1>인간 모양은 맞지만 걷지는 않아요?</h1>
<p>로봇을 특정 장소에 제한하는 것은 이전에 좋은 생각이 아니었습니다. 왜냐하면 브라운필드 문제를 해결하지 못했기 때문입니다. 동일한 장소에서 상당한 시간을 보내는 로봇은 보다 효율적으로 자동화할 수 있는 작업에 종사하는 것일 가능성이 높습니다. 또한 이동성은 배치의 다양성만을 고려하는 것이 아니라, 로봇이 더 넓은 작업 공간에 대응하고 도구와 부품을 스스로 가져올 수 있게 해줍니다. 그렇다고 해서 즉시 다리가 필요한 건 아닐까요?</p>
<p>회사들은 이 가설을 테스트하기 위해 인간형 상반신과 저렴하고 견고한 구동 장치를 결합해봅니다. 예를 들어, 1X 로보틱스(1X robotics)…</p>
<p>…영상에서 보여지는 것 이상의 작업을 수행하려면 소프트웨어 업데이트 이상이 필요할 것입니다)과 바닥에서 물건을 줍는 능력을 결합한 상반신의 민첩성과 인간의 발자국만 조금 더 큰 바퀴 플랫폼을 함께 사용합니다. 산업용 공동 로봇의 성능을 얻는 것은 여전히 매우 어려울 것이며, 작은 바퀴 기반으로 인해 로봇이 운반할 수 있는 하중이 제한될 것입니다. 이러한 로봇은 따라서 인간과 로봇의 흥미로운 상호 작용을 창출하는 데 굉장히 뛰어난 '페퍼'처럼 많이 능력있지는 않지만, 다리가 달린 플랫폼의 이동성이나 협업 로봇의 일군 능력만큼은 갖춘 것이 아닙니다.</p>
<p>작은 휠베이스는 동적 안정성을 제한하는 기회를 줄입니다. 이는 Boston Dynamics의 - 극도로 익살스러운 - 핸들 로봇들에서 나타납니다. 이 로봇들은 카운터 웨이트를 움직여 세그웨이와 같은 드라이브 체인에서 균형을 맞춰 다양한 하중 조건에 적응할 수 있습니다.</p>
<p>아마도 주위에 있는 사람들이 이 두 친구 가까이 다가가지 못한 것을 눈치챘을 겁니다. 실제로, 어떠한 형태의 동적 활동도 일반적으로 안전하지 않습니다. 이것이 신뢰할 만한 동적 보행을 시연하는 것이 결핵되는 연결고리이자 많은 데모의 중심 주제인 이유입니다.</p>
<h1>인간형 로봇 경주에서 우승하기</h1>
<p>하지만 이 파도가 줄어들지 않으려면, 인간형 로봇은 가능한 빨리 생산 환경으로 이동해야 합니다. 이는 동시에 어느 정도의 소프트웨어와 하드웨어 혼합을 제공해야만 가능합니다.</p>
<ul>
<li>기존 설치물, 도구, 및 장치를 쉽게 활용할 수 있는 인간 근로자의 형태 요인,</li>
<li>개방형 세계에 대한 쉬운 범용화와 훈련 가능성을 갖춘 인간 근로자의 기능성,</li>
<li>그리고 최소한의 조작 기술 세트,</li>
</ul>
<p>몇 가지 특정 사용 사례에 대한 브라운필드 문제를 해결하는 데 충분합니다. 언제나 새로운 하드웨어를 개발하는 것은 일반적으로 좋지 않은 생각입니다. 학습과 교육을 더욱 쉽게 만드는 것이 아니라 어렵게 하는 경우가 많습니다. 인간형 로봇이 고객 가치를 창출하고, 책지식과 시각-촉각적 경험을 결합한 다중 모드 기반 모델을 위한 데이터 기초를 먼저 제공할수록 좋습니다.</p>
<h1>참고 문헌</h1>
<p>[1] Minderer, M., Gritsenko, A., Stone, A., Neumann, M., Weissenborn, D., Dosovitskiy, A., Mahendran, A., Arnab, A., Dehghani, M. and Shen, Z., Simple open-vocabulary object detection with vision transformers. arXiv 2022. arXiv preprint arXiv:2205.06230.</p>
<p>[2] Chi, C., Feng, S., Du, Y., Xu, Z., Cousineau, E., Burchfiel, B. and Song, S., 2023. Diffusion policy: Visuomotor policy learning via action diffusion. arXiv preprint arXiv:2303.04137.</p>
<p>[3] Liang J, Xia F, Yu W, Zeng A, Arenas MG, Attarian M, Bauza M, Bennice M, Bewley A, Dostmohamed A, Fu CK. Learning to Learn Faster from Human Feedback with Language Model Predictive Control. arXiv preprint arXiv:2402.11450. 2024 Feb 18.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"휴머노이드는 여기에 머물러 있을까요","description":"","date":"2024-05-18 19:24","slug":"2024-05-18-AretheHumanoidsHeretoStay","content":"\n\n매주 이런 식으로 새로운 업데이트를 내놓는 인간형 회사들을 볼 수 없네요. 옵티머스가 걸을 수 있어요? 디지트가 빈 토트백을 옮겼다구요? 피거도 그렇게 하는군요! 드디어 실제 회사들도 흥미를 느끼기 시작한 것 같아요. 테슬라부터 시작해서 아마존과 BMW에서도 이제는 \"작동 중\"이랍니다. 마치 집과 정원에서 우리에게 한 발짝 떨어진 것 같아요.\n\n하지만 정말로 일하고 있는 걸까요? 보여지는 데모들은 보스턴 다이내믹스의 아틀라스가 파크our을 하는 것만큼 흥미로운 것이 아니라 humanoids가 생산적인 것 같지도 않아요. 그래서 시장이 정말로 흥분한 것일까요? Humanoids가 무언가를 준비하고 있는 걸까요? 저는 두 가지 이유로 humanoids에 흥분해요:\n\n1) 인간형 로봇은 마침내 \"브라운필드\" 문제를 해결할 수도 있어요. 이것이 로봇 솔루션들이 실험 단계에 머무는 주된 이유이기도 하거든요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2) 2023년에 기계 학습은 큰 발전을 이루었습니다. 컴퓨터들이 이번에 처음으로 노력의 스킬을 발휘하여 오픈 월드 환경에서 작동하고 접촉 시키는 것이 가능해졌습니다.\n\n# Greenfield vs. Brownfield\n\n로봇 공학은 아직 큰 산업이 아니며 대부분의 산업은 “Greenfield” 배치로만 성공을 거둡니다. 기존 공정을 개조하는 대신, 공장과 그 제품을 로봇 솔루션 주위에 설계합니다. 이것이 ABB, Fanuc 및 Kuka와 같은 기업들이 수익을 올리는 방식이며 자동차 산업을 위한 생산 라인과 같은 전문 솔루션을 구축합니다. 아마존도 이와 같은 원리로 Kiva 자동화 시스템과 함께 작동하는 건물 구축을 하고 있습니다. 반면, 기존 공정과 통합되는 솔루션 (기존 토지 또는 \"갈색\" 영역에)은 종종 생산적으로 성공하지 못하고 버려지는 경우가 많습니다.\n\n아래 이미지는 이러한 딜레마를 설명합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![2024-05-18-AretheHumanoidsHeretoStay_1.png](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_1.png)\n\n작지만 성공한 커피 사업을 상상해보세요. 이 사업은 역사적으로 분리된 분쇄기, 커피 포트 및 열판을 사용하여 커피를 만들어 왔습니다. 여기에 \"협력 로봇\"이라는 자동화된 과정이 도입됩니다. 이런 로봇은 커피 포트를 열판 위에 놓는 등 일부 작업만 수행할 수 있고, 추가적인 장비들을 필요로 합니다. 이런 해결책은 기존 과정을 준비된 자동화 솔루션으로 교체하는 것이 실제로 쉽고 저렴하게 가능합니다. 에스프레소 메이커만 사면 끝이죠. 수동으로 만든 커피에 집착하는 사람들처럼, 산업 환경에서의 공정은 종종 다른 공정과 깊게 연결되어있어 하류 공정을 변경해야 할 수도 있습니다.\n\n(계속)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 매우 기본적인 작업들 다음에는 조립 작업장을 위한 키트를 생성하고 배포하고, 슈퍼마켓 선반이 깔끔하고 적절히 구비되어 있는지 확인하거나 식기 세척기, 커피 메이커 및 진공 청소기와 같은 가정용 가전제품을 작동하는 등 보다 복잡한 작업을 빠르게 수행하게 될 것입니다.\n\n하지만 또 다른 이점도 있습니다: 전력에 연결되었거나 무선으로 충전 중이라면, 인간형 로봇은 휴식 없이 세 번의 교대 근무를 할 수 있으며, 학습한 모든 것은 즉시 동종 로봇들 모두에게 전달될 수 있습니다. 더욱 좋은 점은, 일단 인간형 로봇이 프로세스에 통합되면, 알고리즘을 통해 작업자들로부터 과도한 정직을 요구하는 Lean 및 Six-Sigma의 모든 기술을 완전히 디지털 방식으로 구현할 수 있게 되어 엄청난 생산성 향상을 이끌어낼 수도 있습니다.\n\n![이미지](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_2.png)\n\n투자자, 기업가 및 과학자들을 흥분하게 만드는 것은 이런 전망이며, 비록 게임이 오래 소요될 지라도요. 그럼에도 불구하고, 2023년에 역사책에 기록된 또 다른 Durchbruch 덕분에 아마도 많은 사람들이 모두 출자하지 않을까 합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 기계 학습이 이끄는 전례 없는 능력\n\n2023년은 ChatGPT의 해였습니다. ChatGPT의 명백한 이점 외에, 트랜스포머 신경망 구조는 텍스트에 국한되지 않고 훨씬 더 강력해졌다는 것이 밝혀졌습니다. 그것은 이미지와 언어를 결합하는 능력으로 인해 기계 학습이 미리 정의된 클래스로의 지도 학습을 벗어나게 하였고, 로봇이 이전에 본 적이없는 물체를 다루도록 허용하였습니다. 예를 들어, \"나사\"라는 물체를 이미지에서 제로샷 방식으로 찾을 수 있는 Owl-VIT [1] 비전-언어 모델이 있습니다. \"나사\"가 무엇이며 어떻게 생겼는지에 대해 명시적으로 학습되지 않고도 가능합니다.\n\n![이미지](/assets/img/2024-05-18-AretheHumanoidsHeretoStay_3.png)\n\n라벨링 및 물체 탐지가 완벽하지는 않지만, 비전 임베딩은 원격 조작된 데모와 결합하여 확산을 사용하여 시각 운동 표현을 학습할 수 있도록 허용합니다[2]. 마치 DallE나 Midjourney에서 이미지를 생성할 때 사용되는 방식과 유사합니다. 로봇은 텍스트를 프롬프트로 변환하는 대신, 센서 관측치를 궤적으로 변환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인간을 훈련시킬 때와 달리 현장에 배치된 로봇이 생산한 경험은 쉽게 다른 로봇으로 전달될 수 있습니다. 여기서 심지어 소수의 인간형 프로토타입만으로도 다양한 제조 및 가정 업무에 대한 전문 지식을 통한 무료롭 처리 양을 만들어낼 수 있습니다. 트랜스포머 모델이 자연스럽게 멀티모달이기 때문에 시각과 텍스트/음성 설명만 적용하는 것이 아니라 촉각적 정보, 소리 또는 진동을 받아들이고, 시맨틱한 구조화 정보와 연결하는 데 도움이 될 것입니다.\n\n대형 언어 모델은 또한 인간 언어와 컴퓨터 코드 사이를 매끄럽게 오가며 소프트웨어 습득 및 인간 피드백을 기반으로 코드를 적절하게 수정할 수도 있을 것입니다. 최근 이 논문[3]과 이 비디오에서 보여준 것처럼, 로봇의 가능성에 대한 \"API\"를 제공받음으로써 ChatGPT는 합리적인 코드를 생성하고 인간 피드백에 따라 조정할 수 있습니다. 인간 지침서, 책 지식 또는 이 두 가지의 조합에서 위와 같은 예시인 전문적인 로봇 임무를 빠르게 학습할 수 있는 능력을 가진 LLM을 인터랙션 훈련을 통해 미세조정함으로써 더 향상시킬 수 있을 것입니다.\n\n# 다음은 무엇일까요?\n\n그래서 우리는 대규모로 인간형 로봇을 배치할 준비가 되어 있고, 곧 더 매력적인 사용 사례들을 보게 되겠죠? 많은 기업들이 하드웨어 중심 접근 방식을 선택하여 동적 보행과 기본 조작이 가능하다는 것을 입증했습니다. 아직은 이 로봇들이 많은 것을 실제로 하거나 더 많은 가치를 창출하지는 못하고 있습니다. 고가치 임무인 자율 키팅, 조립 또는 선반 보충과 같은 임무는 이미 어느 정도 시간이 경과했으며 이전 창업 시절에도 가능했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 비디오에 나오는 산업용 하드웨어와 현재 볼 수 있는 휴머노이드 사이에 중요한 차이가 있습니다. 처음부터 로봇을 만드는 것은 심각한 시스템 공학적 도전이 따르며 현재의 프로토 타입은 안정적인 기지에 장착된 협력 로봇의 0.1mm 정확도에서 현재는 상당히 멀리 떨어져 있을 것으로 보입니다. 관성과 진동을 제어하는 어려운 작업은 물론 토크 감지를 사용하여 이를 가능케하지만 대부분의 휴머노이드는 아직 이 기능이 없는 액추에이터에 의존하지만 저렴한 비용 접근 방식을 택하여 엔지니어링 아츠의 아름다운 로봇이 뻣뻣한 산업 시스템과 유사하다고 할 수 있을 정도의 선택을 했습니다.\n\n따라서 다리가 없는 휴머노이드는?\n\n누구나 로봇이 바로 다리가 필요할 것이라고 믿지 않습니다. 이러한 기업은 고가치의 조작 작업, 훈련 용이성 및 매끄러운 배치에 중점을 둡니다. 이 분야의 초기 사례 중 하나는 Rodney Brook의 \"배터\" (안식을 바라며) 로봇이며 나중에는 그의 한 팔로 된 후속자인 소이어가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBaxter가 슈퍼 저렴한 비용(`$25k에 이중 팔로봇)을 정밀성과 강성으로 바꾸는 지나치게 야 amb 계약의 하드웨어 디자인을 겪던 동안, Sawyer는 보다 전통적인 로봇 드라이브를 사용하여 최소한의 조립물과 기본적인 프로그래밍만으로도 다양한 응용 분야에서 성능을 발휘할 수 있습니다. Sawyer는 아직 몇몇 국가에서 판매 중이지만, 모든 “Cobots”이 겪는 브라운필드 문제에 시달립니다: 작업이 자동화 솔루션이 정당화할만큼 반복적인 경우, 이미 해당 솔루션이 만들어졌으며 상당히 더 나은, 빠르고 저렴할 가능성이 높습니다.\n\n“정체된 상반신” 방식의 또 다른 예는 Giant AI인데, 이는 2023년에 공개되고 (사업을 종료한 채) 잠잠하게 알려진 비디오 시리즈로 나타났습니다:\n\nBaxter와 마찬가지로, Giant의 Universal Worker는 기본 조작에 중점을 둔 정적 솔루션이었습니다. Baxter와 같이, Giant는 모든 하드웨어를 처음부터 개발했으며 힘줄 기반 접근법을 구현하여 (잠재적인) 비용 절감을 굉장한 개발 관리부담과 정확성으로 교환했으며, 제 시간에 진정한 고객 가치를 제공하지 못했습니다.\n\nGiant의 일부 지적재산권은 Sanctuary.ai에서 살아 있으며, 여기서도 상체 민첩성에 중점을 두지만, 유압 구동 재래를 복원함으로써, 로봇이 정밀한 조작부터 무거운 들기까지 다양한 작업 범위에 대처할 수 있도록 해줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 인간 모양은 맞지만 걷지는 않아요?\n\n로봇을 특정 장소에 제한하는 것은 이전에 좋은 생각이 아니었습니다. 왜냐하면 브라운필드 문제를 해결하지 못했기 때문입니다. 동일한 장소에서 상당한 시간을 보내는 로봇은 보다 효율적으로 자동화할 수 있는 작업에 종사하는 것일 가능성이 높습니다. 또한 이동성은 배치의 다양성만을 고려하는 것이 아니라, 로봇이 더 넓은 작업 공간에 대응하고 도구와 부품을 스스로 가져올 수 있게 해줍니다. 그렇다고 해서 즉시 다리가 필요한 건 아닐까요?\n\n회사들은 이 가설을 테스트하기 위해 인간형 상반신과 저렴하고 견고한 구동 장치를 결합해봅니다. 예를 들어, 1X 로보틱스(1X robotics)…\n\n…영상에서 보여지는 것 이상의 작업을 수행하려면 소프트웨어 업데이트 이상이 필요할 것입니다)과 바닥에서 물건을 줍는 능력을 결합한 상반신의 민첩성과 인간의 발자국만 조금 더 큰 바퀴 플랫폼을 함께 사용합니다. 산업용 공동 로봇의 성능을 얻는 것은 여전히 매우 어려울 것이며, 작은 바퀴 기반으로 인해 로봇이 운반할 수 있는 하중이 제한될 것입니다. 이러한 로봇은 따라서 인간과 로봇의 흥미로운 상호 작용을 창출하는 데 굉장히 뛰어난 '페퍼'처럼 많이 능력있지는 않지만, 다리가 달린 플랫폼의 이동성이나 협업 로봇의 일군 능력만큼은 갖춘 것이 아닙니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작은 휠베이스는 동적 안정성을 제한하는 기회를 줄입니다. 이는 Boston Dynamics의 - 극도로 익살스러운 - 핸들 로봇들에서 나타납니다. 이 로봇들은 카운터 웨이트를 움직여 세그웨이와 같은 드라이브 체인에서 균형을 맞춰 다양한 하중 조건에 적응할 수 있습니다.\n\n아마도 주위에 있는 사람들이 이 두 친구 가까이 다가가지 못한 것을 눈치챘을 겁니다. 실제로, 어떠한 형태의 동적 활동도 일반적으로 안전하지 않습니다. 이것이 신뢰할 만한 동적 보행을 시연하는 것이 결핵되는 연결고리이자 많은 데모의 중심 주제인 이유입니다.\n\n# 인간형 로봇 경주에서 우승하기\n\n하지만 이 파도가 줄어들지 않으려면, 인간형 로봇은 가능한 빨리 생산 환경으로 이동해야 합니다. 이는 동시에 어느 정도의 소프트웨어와 하드웨어 혼합을 제공해야만 가능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 기존 설치물, 도구, 및 장치를 쉽게 활용할 수 있는 인간 근로자의 형태 요인,\n- 개방형 세계에 대한 쉬운 범용화와 훈련 가능성을 갖춘 인간 근로자의 기능성,\n- 그리고 최소한의 조작 기술 세트,\n\n몇 가지 특정 사용 사례에 대한 브라운필드 문제를 해결하는 데 충분합니다. 언제나 새로운 하드웨어를 개발하는 것은 일반적으로 좋지 않은 생각입니다. 학습과 교육을 더욱 쉽게 만드는 것이 아니라 어렵게 하는 경우가 많습니다. 인간형 로봇이 고객 가치를 창출하고, 책지식과 시각-촉각적 경험을 결합한 다중 모드 기반 모델을 위한 데이터 기초를 먼저 제공할수록 좋습니다.\n\n# 참고 문헌\n\n[1] Minderer, M., Gritsenko, A., Stone, A., Neumann, M., Weissenborn, D., Dosovitskiy, A., Mahendran, A., Arnab, A., Dehghani, M. and Shen, Z., Simple open-vocabulary object detection with vision transformers. arXiv 2022. arXiv preprint arXiv:2205.06230.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[2] Chi, C., Feng, S., Du, Y., Xu, Z., Cousineau, E., Burchfiel, B. and Song, S., 2023. Diffusion policy: Visuomotor policy learning via action diffusion. arXiv preprint arXiv:2303.04137.\n\n[3] Liang J, Xia F, Yu W, Zeng A, Arenas MG, Attarian M, Bauza M, Bennice M, Bewley A, Dostmohamed A, Fu CK. Learning to Learn Faster from Human Feedback with Language Model Predictive Control. arXiv preprint arXiv:2402.11450. 2024 Feb 18.","ogImage":{"url":"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png"},"coverImage":"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e매주 이런 식으로 새로운 업데이트를 내놓는 인간형 회사들을 볼 수 없네요. 옵티머스가 걸을 수 있어요? 디지트가 빈 토트백을 옮겼다구요? 피거도 그렇게 하는군요! 드디어 실제 회사들도 흥미를 느끼기 시작한 것 같아요. 테슬라부터 시작해서 아마존과 BMW에서도 이제는 \"작동 중\"이랍니다. 마치 집과 정원에서 우리에게 한 발짝 떨어진 것 같아요.\u003c/p\u003e\n\u003cp\u003e하지만 정말로 일하고 있는 걸까요? 보여지는 데모들은 보스턴 다이내믹스의 아틀라스가 파크our을 하는 것만큼 흥미로운 것이 아니라 humanoids가 생산적인 것 같지도 않아요. 그래서 시장이 정말로 흥분한 것일까요? Humanoids가 무언가를 준비하고 있는 걸까요? 저는 두 가지 이유로 humanoids에 흥분해요:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e인간형 로봇은 마침내 \"브라운필드\" 문제를 해결할 수도 있어요. 이것이 로봇 솔루션들이 실험 단계에 머무는 주된 이유이기도 하거든요.\u003c/li\u003e\n\u003c/ol\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e2023년에 기계 학습은 큰 발전을 이루었습니다. 컴퓨터들이 이번에 처음으로 노력의 스킬을 발휘하여 오픈 월드 환경에서 작동하고 접촉 시키는 것이 가능해졌습니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1\u003eGreenfield vs. Brownfield\u003c/h1\u003e\n\u003cp\u003e로봇 공학은 아직 큰 산업이 아니며 대부분의 산업은 “Greenfield” 배치로만 성공을 거둡니다. 기존 공정을 개조하는 대신, 공장과 그 제품을 로봇 솔루션 주위에 설계합니다. 이것이 ABB, Fanuc 및 Kuka와 같은 기업들이 수익을 올리는 방식이며 자동차 산업을 위한 생산 라인과 같은 전문 솔루션을 구축합니다. 아마존도 이와 같은 원리로 Kiva 자동화 시스템과 함께 작동하는 건물 구축을 하고 있습니다. 반면, 기존 공정과 통합되는 솔루션 (기존 토지 또는 \"갈색\" 영역에)은 종종 생산적으로 성공하지 못하고 버려지는 경우가 많습니다.\u003c/p\u003e\n\u003cp\u003e아래 이미지는 이러한 딜레마를 설명합니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_1.png\" alt=\"2024-05-18-AretheHumanoidsHeretoStay_1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e작지만 성공한 커피 사업을 상상해보세요. 이 사업은 역사적으로 분리된 분쇄기, 커피 포트 및 열판을 사용하여 커피를 만들어 왔습니다. 여기에 \"협력 로봇\"이라는 자동화된 과정이 도입됩니다. 이런 로봇은 커피 포트를 열판 위에 놓는 등 일부 작업만 수행할 수 있고, 추가적인 장비들을 필요로 합니다. 이런 해결책은 기존 과정을 준비된 자동화 솔루션으로 교체하는 것이 실제로 쉽고 저렴하게 가능합니다. 에스프레소 메이커만 사면 끝이죠. 수동으로 만든 커피에 집착하는 사람들처럼, 산업 환경에서의 공정은 종종 다른 공정과 깊게 연결되어있어 하류 공정을 변경해야 할 수도 있습니다.\u003c/p\u003e\n\u003cp\u003e(계속)\u003c/p\u003e\n\u003cp\u003e이러한 매우 기본적인 작업들 다음에는 조립 작업장을 위한 키트를 생성하고 배포하고, 슈퍼마켓 선반이 깔끔하고 적절히 구비되어 있는지 확인하거나 식기 세척기, 커피 메이커 및 진공 청소기와 같은 가정용 가전제품을 작동하는 등 보다 복잡한 작업을 빠르게 수행하게 될 것입니다.\u003c/p\u003e\n\u003cp\u003e하지만 또 다른 이점도 있습니다: 전력에 연결되었거나 무선으로 충전 중이라면, 인간형 로봇은 휴식 없이 세 번의 교대 근무를 할 수 있으며, 학습한 모든 것은 즉시 동종 로봇들 모두에게 전달될 수 있습니다. 더욱 좋은 점은, 일단 인간형 로봇이 프로세스에 통합되면, 알고리즘을 통해 작업자들로부터 과도한 정직을 요구하는 Lean 및 Six-Sigma의 모든 기술을 완전히 디지털 방식으로 구현할 수 있게 되어 엄청난 생산성 향상을 이끌어낼 수도 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e투자자, 기업가 및 과학자들을 흥분하게 만드는 것은 이런 전망이며, 비록 게임이 오래 소요될 지라도요. 그럼에도 불구하고, 2023년에 역사책에 기록된 또 다른 Durchbruch 덕분에 아마도 많은 사람들이 모두 출자하지 않을까 합니다:\u003c/p\u003e\n\u003ch1\u003e기계 학습이 이끄는 전례 없는 능력\u003c/h1\u003e\n\u003cp\u003e2023년은 ChatGPT의 해였습니다. ChatGPT의 명백한 이점 외에, 트랜스포머 신경망 구조는 텍스트에 국한되지 않고 훨씬 더 강력해졌다는 것이 밝혀졌습니다. 그것은 이미지와 언어를 결합하는 능력으로 인해 기계 학습이 미리 정의된 클래스로의 지도 학습을 벗어나게 하였고, 로봇이 이전에 본 적이없는 물체를 다루도록 허용하였습니다. 예를 들어, \"나사\"라는 물체를 이미지에서 제로샷 방식으로 찾을 수 있는 Owl-VIT [1] 비전-언어 모델이 있습니다. \"나사\"가 무엇이며 어떻게 생겼는지에 대해 명시적으로 학습되지 않고도 가능합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AretheHumanoidsHeretoStay_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e라벨링 및 물체 탐지가 완벽하지는 않지만, 비전 임베딩은 원격 조작된 데모와 결합하여 확산을 사용하여 시각 운동 표현을 학습할 수 있도록 허용합니다[2]. 마치 DallE나 Midjourney에서 이미지를 생성할 때 사용되는 방식과 유사합니다. 로봇은 텍스트를 프롬프트로 변환하는 대신, 센서 관측치를 궤적으로 변환합니다.\u003c/p\u003e\n\u003cp\u003e인간을 훈련시킬 때와 달리 현장에 배치된 로봇이 생산한 경험은 쉽게 다른 로봇으로 전달될 수 있습니다. 여기서 심지어 소수의 인간형 프로토타입만으로도 다양한 제조 및 가정 업무에 대한 전문 지식을 통한 무료롭 처리 양을 만들어낼 수 있습니다. 트랜스포머 모델이 자연스럽게 멀티모달이기 때문에 시각과 텍스트/음성 설명만 적용하는 것이 아니라 촉각적 정보, 소리 또는 진동을 받아들이고, 시맨틱한 구조화 정보와 연결하는 데 도움이 될 것입니다.\u003c/p\u003e\n\u003cp\u003e대형 언어 모델은 또한 인간 언어와 컴퓨터 코드 사이를 매끄럽게 오가며 소프트웨어 습득 및 인간 피드백을 기반으로 코드를 적절하게 수정할 수도 있을 것입니다. 최근 이 논문[3]과 이 비디오에서 보여준 것처럼, 로봇의 가능성에 대한 \"API\"를 제공받음으로써 ChatGPT는 합리적인 코드를 생성하고 인간 피드백에 따라 조정할 수 있습니다. 인간 지침서, 책 지식 또는 이 두 가지의 조합에서 위와 같은 예시인 전문적인 로봇 임무를 빠르게 학습할 수 있는 능력을 가진 LLM을 인터랙션 훈련을 통해 미세조정함으로써 더 향상시킬 수 있을 것입니다.\u003c/p\u003e\n\u003ch1\u003e다음은 무엇일까요?\u003c/h1\u003e\n\u003cp\u003e그래서 우리는 대규모로 인간형 로봇을 배치할 준비가 되어 있고, 곧 더 매력적인 사용 사례들을 보게 되겠죠? 많은 기업들이 하드웨어 중심 접근 방식을 선택하여 동적 보행과 기본 조작이 가능하다는 것을 입증했습니다. 아직은 이 로봇들이 많은 것을 실제로 하거나 더 많은 가치를 창출하지는 못하고 있습니다. 고가치 임무인 자율 키팅, 조립 또는 선반 보충과 같은 임무는 이미 어느 정도 시간이 경과했으며 이전 창업 시절에도 가능했습니다:\u003c/p\u003e\n\u003cp\u003e위의 비디오에 나오는 산업용 하드웨어와 현재 볼 수 있는 휴머노이드 사이에 중요한 차이가 있습니다. 처음부터 로봇을 만드는 것은 심각한 시스템 공학적 도전이 따르며 현재의 프로토 타입은 안정적인 기지에 장착된 협력 로봇의 0.1mm 정확도에서 현재는 상당히 멀리 떨어져 있을 것으로 보입니다. 관성과 진동을 제어하는 어려운 작업은 물론 토크 감지를 사용하여 이를 가능케하지만 대부분의 휴머노이드는 아직 이 기능이 없는 액추에이터에 의존하지만 저렴한 비용 접근 방식을 택하여 엔지니어링 아츠의 아름다운 로봇이 뻣뻣한 산업 시스템과 유사하다고 할 수 있을 정도의 선택을 했습니다.\u003c/p\u003e\n\u003cp\u003e따라서 다리가 없는 휴머노이드는?\u003c/p\u003e\n\u003cp\u003e누구나 로봇이 바로 다리가 필요할 것이라고 믿지 않습니다. 이러한 기업은 고가치의 조작 작업, 훈련 용이성 및 매끄러운 배치에 중점을 둡니다. 이 분야의 초기 사례 중 하나는 Rodney Brook의 \"배터\" (안식을 바라며) 로봇이며 나중에는 그의 한 팔로 된 후속자인 소이어가 있습니다:\u003c/p\u003e\n\u003cp\u003eBaxter가 슈퍼 저렴한 비용(`$25k에 이중 팔로봇)을 정밀성과 강성으로 바꾸는 지나치게 야 amb 계약의 하드웨어 디자인을 겪던 동안, Sawyer는 보다 전통적인 로봇 드라이브를 사용하여 최소한의 조립물과 기본적인 프로그래밍만으로도 다양한 응용 분야에서 성능을 발휘할 수 있습니다. Sawyer는 아직 몇몇 국가에서 판매 중이지만, 모든 “Cobots”이 겪는 브라운필드 문제에 시달립니다: 작업이 자동화 솔루션이 정당화할만큼 반복적인 경우, 이미 해당 솔루션이 만들어졌으며 상당히 더 나은, 빠르고 저렴할 가능성이 높습니다.\u003c/p\u003e\n\u003cp\u003e“정체된 상반신” 방식의 또 다른 예는 Giant AI인데, 이는 2023년에 공개되고 (사업을 종료한 채) 잠잠하게 알려진 비디오 시리즈로 나타났습니다:\u003c/p\u003e\n\u003cp\u003eBaxter와 마찬가지로, Giant의 Universal Worker는 기본 조작에 중점을 둔 정적 솔루션이었습니다. Baxter와 같이, Giant는 모든 하드웨어를 처음부터 개발했으며 힘줄 기반 접근법을 구현하여 (잠재적인) 비용 절감을 굉장한 개발 관리부담과 정확성으로 교환했으며, 제 시간에 진정한 고객 가치를 제공하지 못했습니다.\u003c/p\u003e\n\u003cp\u003eGiant의 일부 지적재산권은 Sanctuary.ai에서 살아 있으며, 여기서도 상체 민첩성에 중점을 두지만, 유압 구동 재래를 복원함으로써, 로봇이 정밀한 조작부터 무거운 들기까지 다양한 작업 범위에 대처할 수 있도록 해줍니다.\u003c/p\u003e\n\u003ch1\u003e인간 모양은 맞지만 걷지는 않아요?\u003c/h1\u003e\n\u003cp\u003e로봇을 특정 장소에 제한하는 것은 이전에 좋은 생각이 아니었습니다. 왜냐하면 브라운필드 문제를 해결하지 못했기 때문입니다. 동일한 장소에서 상당한 시간을 보내는 로봇은 보다 효율적으로 자동화할 수 있는 작업에 종사하는 것일 가능성이 높습니다. 또한 이동성은 배치의 다양성만을 고려하는 것이 아니라, 로봇이 더 넓은 작업 공간에 대응하고 도구와 부품을 스스로 가져올 수 있게 해줍니다. 그렇다고 해서 즉시 다리가 필요한 건 아닐까요?\u003c/p\u003e\n\u003cp\u003e회사들은 이 가설을 테스트하기 위해 인간형 상반신과 저렴하고 견고한 구동 장치를 결합해봅니다. 예를 들어, 1X 로보틱스(1X robotics)…\u003c/p\u003e\n\u003cp\u003e…영상에서 보여지는 것 이상의 작업을 수행하려면 소프트웨어 업데이트 이상이 필요할 것입니다)과 바닥에서 물건을 줍는 능력을 결합한 상반신의 민첩성과 인간의 발자국만 조금 더 큰 바퀴 플랫폼을 함께 사용합니다. 산업용 공동 로봇의 성능을 얻는 것은 여전히 매우 어려울 것이며, 작은 바퀴 기반으로 인해 로봇이 운반할 수 있는 하중이 제한될 것입니다. 이러한 로봇은 따라서 인간과 로봇의 흥미로운 상호 작용을 창출하는 데 굉장히 뛰어난 '페퍼'처럼 많이 능력있지는 않지만, 다리가 달린 플랫폼의 이동성이나 협업 로봇의 일군 능력만큼은 갖춘 것이 아닙니다.\u003c/p\u003e\n\u003cp\u003e작은 휠베이스는 동적 안정성을 제한하는 기회를 줄입니다. 이는 Boston Dynamics의 - 극도로 익살스러운 - 핸들 로봇들에서 나타납니다. 이 로봇들은 카운터 웨이트를 움직여 세그웨이와 같은 드라이브 체인에서 균형을 맞춰 다양한 하중 조건에 적응할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e아마도 주위에 있는 사람들이 이 두 친구 가까이 다가가지 못한 것을 눈치챘을 겁니다. 실제로, 어떠한 형태의 동적 활동도 일반적으로 안전하지 않습니다. 이것이 신뢰할 만한 동적 보행을 시연하는 것이 결핵되는 연결고리이자 많은 데모의 중심 주제인 이유입니다.\u003c/p\u003e\n\u003ch1\u003e인간형 로봇 경주에서 우승하기\u003c/h1\u003e\n\u003cp\u003e하지만 이 파도가 줄어들지 않으려면, 인간형 로봇은 가능한 빨리 생산 환경으로 이동해야 합니다. 이는 동시에 어느 정도의 소프트웨어와 하드웨어 혼합을 제공해야만 가능합니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e기존 설치물, 도구, 및 장치를 쉽게 활용할 수 있는 인간 근로자의 형태 요인,\u003c/li\u003e\n\u003cli\u003e개방형 세계에 대한 쉬운 범용화와 훈련 가능성을 갖춘 인간 근로자의 기능성,\u003c/li\u003e\n\u003cli\u003e그리고 최소한의 조작 기술 세트,\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e몇 가지 특정 사용 사례에 대한 브라운필드 문제를 해결하는 데 충분합니다. 언제나 새로운 하드웨어를 개발하는 것은 일반적으로 좋지 않은 생각입니다. 학습과 교육을 더욱 쉽게 만드는 것이 아니라 어렵게 하는 경우가 많습니다. 인간형 로봇이 고객 가치를 창출하고, 책지식과 시각-촉각적 경험을 결합한 다중 모드 기반 모델을 위한 데이터 기초를 먼저 제공할수록 좋습니다.\u003c/p\u003e\n\u003ch1\u003e참고 문헌\u003c/h1\u003e\n\u003cp\u003e[1] Minderer, M., Gritsenko, A., Stone, A., Neumann, M., Weissenborn, D., Dosovitskiy, A., Mahendran, A., Arnab, A., Dehghani, M. and Shen, Z., Simple open-vocabulary object detection with vision transformers. arXiv 2022. arXiv preprint arXiv:2205.06230.\u003c/p\u003e\n\u003cp\u003e[2] Chi, C., Feng, S., Du, Y., Xu, Z., Cousineau, E., Burchfiel, B. and Song, S., 2023. Diffusion policy: Visuomotor policy learning via action diffusion. arXiv preprint arXiv:2303.04137.\u003c/p\u003e\n\u003cp\u003e[3] Liang J, Xia F, Yu W, Zeng A, Arenas MG, Attarian M, Bauza M, Bennice M, Bewley A, Dostmohamed A, Fu CK. Learning to Learn Faster from Human Feedback with Language Model Predictive Control. arXiv preprint arXiv:2402.11450. 2024 Feb 18.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-18-AretheHumanoidsHeretoStay"},"buildId":"RZIEBQ2aNAp_DXFVTV6eL","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>