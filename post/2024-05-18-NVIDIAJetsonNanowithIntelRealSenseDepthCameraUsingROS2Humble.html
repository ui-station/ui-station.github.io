<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble" data-gatsby-head="true"/><meta name="twitter:title" content="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-18 19:15" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_buildManifest.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 18, 2024</span><span class="posts_reading_time__f7YPP">6<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png">
<p>이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.</p>
<img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png">
<h1>Prerequisites</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>시작하기 전에 다음 구성 요소가 있는지 확인하십시오:</p>
<ul>
<li>NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04</li>
<li>Intel RealSense Depth Camera (예: D435i)</li>
<li>Jetson Nano에 설치된 ROS2 Humble</li>
<li>RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블</li>
<li>필요한 패키지를 다운로드하기 위한 인터넷 연결</li>
</ul>
<p>ROS2 RealSense 패키지 설치</p>
<pre><code class="hljs language-js">sudo apt install ros-humble-realsense2-camera
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>RealSense 노드를 시작해주세요:</p>
<p>RealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> launch <span class="hljs-keyword">import</span> LaunchDescription
<span class="hljs-keyword">from</span> launch_ros.actions <span class="hljs-keyword">import</span> Node

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_launch_description</span>():
    <span class="hljs-keyword">return</span> LaunchDescription([
        Node(
            package=<span class="hljs-string">'realsense2_camera'</span>,
            executable=<span class="hljs-string">'realsense2_camera_node'</span>,
            name=<span class="hljs-string">'realsense2_camera'</span>,
            output=<span class="hljs-string">'screen'</span>,
            parameters=[{
                <span class="hljs-string">'enable_depth'</span>: <span class="hljs-literal">True</span>,
                <span class="hljs-string">'enable_infra1'</span>: <span class="hljs-literal">True</span>,
                <span class="hljs-string">'enable_infra2'</span>: <span class="hljs-literal">True</span>,
                <span class="hljs-string">'enable_color'</span>: <span class="hljs-literal">True</span>,
            }],
        ),
    ])
</code></pre>
<p>란치 파일을 실행하세요:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<table>
    <tbody><tr>
        <td>![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png)</td>
    </tr>
</tbody></table>
<pre><code class="hljs language-js">ros2 launch your_package_name realsense_launch.<span class="hljs-property">py</span>
</code></pre>
<p>rqt에서 데이터 시각화:</p>
<p><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png" alt="이미지"></p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>rqt에 RealSense 데이터 추가하기:</p>
<p><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png" alt="이미지"></p>
<ul>
<li>새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.</li>
<li>이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.</li>
</ul>
<p><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png" alt="이미지"></p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>깊이 이미지</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif" alt="깊이 이미지"></p>
<h1>깊이 이미지란?</h1>
<p>깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>주요 주제 및 메시지</h1>
<p>ROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:</p>
<ul>
<li>토픽: /camera/depth/image_raw</li>
<li>메시지 유형: sensor_msgs/Image</li>
</ul>
<h2>sensor_msgs/Image 메시지</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>sensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:</p>
<ul>
<li>header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.</li>
<li>height: 이미지의 높이(픽셀 단위).</li>
<li>width: 이미지의 너비(픽셀 단위).</li>
<li>encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.</li>
<li>is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.</li>
<li>step: 바이트 단위의 전체 행 길이.</li>
<li>data: 바이트 배열로 저장된 실제 픽셀 데이터.</li>
</ul>
<h2>깊이 이미지 처리</h2>
<p>깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.</li>
<li>장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.</li>
<li>3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.</li>
</ul>
<h1>결론</h1>
<p>위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.</p>
<p>문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기","description":"","date":"2024-05-18 19:15","slug":"2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble","content":"\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png\" /\u003e\n\n이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png\" /\u003e\n\n# Prerequisites\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시작하기 전에 다음 구성 요소가 있는지 확인하십시오:\n\n- NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04\n- Intel RealSense Depth Camera (예: D435i)\n- Jetson Nano에 설치된 ROS2 Humble\n- RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블\n- 필요한 패키지를 다운로드하기 위한 인터넷 연결\n\nROS2 RealSense 패키지 설치\n\n```js\nsudo apt install ros-humble-realsense2-camera\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nRealSense 노드를 시작해주세요:\n\nRealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:\n\n```python\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='realsense2_camera',\n            executable='realsense2_camera_node',\n            name='realsense2_camera',\n            output='screen',\n            parameters=[{\n                'enable_depth': True,\n                'enable_infra1': True,\n                'enable_infra2': True,\n                'enable_color': True,\n            }],\n        ),\n    ])\n```\n\n란치 파일을 실행하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003ctable\u003e\n    \u003ctr\u003e\n        \u003ctd\u003e![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png)\u003c/td\u003e\n    \u003c/tr\u003e\n\u003c/table\u003e\n\n```js\nros2 launch your_package_name realsense_launch.py\n```\n\nrqt에서 데이터 시각화:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nrqt에 RealSense 데이터 추가하기:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png)\n\n- 새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.\n- 이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n깊이 이미지\n\n![깊이 이미지](https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif)\n\n# 깊이 이미지란?\n\n깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 주요 주제 및 메시지\n\nROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:\n\n- 토픽: /camera/depth/image_raw\n- 메시지 유형: sensor_msgs/Image\n\n## sensor_msgs/Image 메시지\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nsensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:\n\n- header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.\n- height: 이미지의 높이(픽셀 단위).\n- width: 이미지의 너비(픽셀 단위).\n- encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.\n- is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.\n- step: 바이트 단위의 전체 행 길이.\n- data: 바이트 배열로 저장된 실제 픽셀 데이터.\n\n## 깊이 이미지 처리\n\n깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.\n- 장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.\n- 3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.\n\n# 결론\n\n위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.\n\n문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!\n","ogImage":{"url":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"},"coverImage":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png","tag":["Tech"],"readingTime":6},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png\"\u003e\n\u003cp\u003e이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.\u003c/p\u003e\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png\"\u003e\n\u003ch1\u003ePrerequisites\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e시작하기 전에 다음 구성 요소가 있는지 확인하십시오:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04\u003c/li\u003e\n\u003cli\u003eIntel RealSense Depth Camera (예: D435i)\u003c/li\u003e\n\u003cli\u003eJetson Nano에 설치된 ROS2 Humble\u003c/li\u003e\n\u003cli\u003eRealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블\u003c/li\u003e\n\u003cli\u003e필요한 패키지를 다운로드하기 위한 인터넷 연결\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eROS2 RealSense 패키지 설치\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003esudo apt install ros-humble-realsense2-camera\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eRealSense 노드를 시작해주세요:\u003c/p\u003e\n\u003cp\u003eRealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e launch \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e LaunchDescription\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e launch_ros.actions \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Node\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003egenerate_launch_description\u003c/span\u003e():\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e LaunchDescription([\n        Node(\n            package=\u003cspan class=\"hljs-string\"\u003e'realsense2_camera'\u003c/span\u003e,\n            executable=\u003cspan class=\"hljs-string\"\u003e'realsense2_camera_node'\u003c/span\u003e,\n            name=\u003cspan class=\"hljs-string\"\u003e'realsense2_camera'\u003c/span\u003e,\n            output=\u003cspan class=\"hljs-string\"\u003e'screen'\u003c/span\u003e,\n            parameters=[{\n                \u003cspan class=\"hljs-string\"\u003e'enable_depth'\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                \u003cspan class=\"hljs-string\"\u003e'enable_infra1'\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                \u003cspan class=\"hljs-string\"\u003e'enable_infra2'\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n                \u003cspan class=\"hljs-string\"\u003e'enable_color'\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n            }],\n        ),\n    ])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e란치 파일을 실행하세요:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ctable\u003e\n    \u003ctbody\u003e\u003ctr\u003e\n        \u003ctd\u003e![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png)\u003c/td\u003e\n    \u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eros2 launch your_package_name realsense_launch.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003erqt에서 데이터 시각화:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003erqt에 RealSense 데이터 추가하기:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.\u003c/li\u003e\n\u003cli\u003e이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e깊이 이미지\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif\" alt=\"깊이 이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003e깊이 이미지란?\u003c/h1\u003e\n\u003cp\u003e깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e주요 주제 및 메시지\u003c/h1\u003e\n\u003cp\u003eROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e토픽: /camera/depth/image_raw\u003c/li\u003e\n\u003cli\u003e메시지 유형: sensor_msgs/Image\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003esensor_msgs/Image 메시지\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003esensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eheader: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.\u003c/li\u003e\n\u003cli\u003eheight: 이미지의 높이(픽셀 단위).\u003c/li\u003e\n\u003cli\u003ewidth: 이미지의 너비(픽셀 단위).\u003c/li\u003e\n\u003cli\u003eencoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.\u003c/li\u003e\n\u003cli\u003eis_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.\u003c/li\u003e\n\u003cli\u003estep: 바이트 단위의 전체 행 길이.\u003c/li\u003e\n\u003cli\u003edata: 바이트 배열로 저장된 실제 픽셀 데이터.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e깊이 이미지 처리\u003c/h2\u003e\n\u003cp\u003e깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.\u003c/li\u003e\n\u003cli\u003e장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.\u003c/li\u003e\n\u003cli\u003e3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.\u003c/p\u003e\n\u003cp\u003e문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble"},"buildId":"wfHLuDA3kTGBYfaM5IGXk","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>