<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble" data-gatsby-head="true"/><meta name="twitter:title" content="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-18 19:15" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-561ae49ab5aab7f5.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_buildManifest.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 18, 2024</span><span class="posts_reading_time__f7YPP">4<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"/>
<p>이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.</p>
<img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png"/>
<h1>Prerequisites</h1>
<div class="content-ad"></div>
<p>시작하기 전에 다음 구성 요소가 있는지 확인하십시오:</p>
<ul>
<li>NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04</li>
<li>Intel RealSense Depth Camera (예: D435i)</li>
<li>Jetson Nano에 설치된 ROS2 Humble</li>
<li>RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블</li>
<li>필요한 패키지를 다운로드하기 위한 인터넷 연결</li>
</ul>
<p>ROS2 RealSense 패키지 설치</p>
<pre><code class="hljs language-js">sudo apt install ros-humble-realsense2-camera
</code></pre>
<div class="content-ad"></div>
<p>RealSense 노드를 시작해주세요:</p>
<p>RealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> launch <span class="hljs-keyword">import</span> LaunchDescription
<span class="hljs-keyword">from</span> launch_ros.actions <span class="hljs-keyword">import</span> Node

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_launch_description</span>():
    <span class="hljs-keyword">return</span> LaunchDescription([
        Node(
            package=<span class="hljs-string">&#x27;realsense2_camera&#x27;</span>,
            executable=<span class="hljs-string">&#x27;realsense2_camera_node&#x27;</span>,
            name=<span class="hljs-string">&#x27;realsense2_camera&#x27;</span>,
            output=<span class="hljs-string">&#x27;screen&#x27;</span>,
            parameters=[{
                <span class="hljs-string">&#x27;enable_depth&#x27;</span>: <span class="hljs-literal">True</span>,
                <span class="hljs-string">&#x27;enable_infra1&#x27;</span>: <span class="hljs-literal">True</span>,
                <span class="hljs-string">&#x27;enable_infra2&#x27;</span>: <span class="hljs-literal">True</span>,
                <span class="hljs-string">&#x27;enable_color&#x27;</span>: <span class="hljs-literal">True</span>,
            }],
        ),
    ])
</code></pre>
<p>란치 파일을 실행하세요:</p>
<div class="content-ad"></div>
<table><tr><td><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png" alt="이미지"/></td></tr></table>
<pre><code class="hljs language-js">ros2 launch your_package_name realsense_launch.<span class="hljs-property">py</span>
</code></pre>
<p>rqt에서 데이터 시각화:</p>
<p><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png" alt="이미지"/></p>
<div class="content-ad"></div>
<p>rqt에 RealSense 데이터 추가하기:</p>
<p><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png" alt="이미지"/></p>
<ul>
<li>새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.</li>
<li>이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.</li>
</ul>
<p><img src="/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png" alt="이미지"/></p>
<div class="content-ad"></div>
<p>깊이 이미지</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif" alt="깊이 이미지"/></p>
<h1>깊이 이미지란?</h1>
<p>깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.</p>
<div class="content-ad"></div>
<h1>주요 주제 및 메시지</h1>
<p>ROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:</p>
<ul>
<li>토픽: /camera/depth/image_raw</li>
<li>메시지 유형: sensor_msgs/Image</li>
</ul>
<h2>sensor_msgs/Image 메시지</h2>
<div class="content-ad"></div>
<p>sensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:</p>
<ul>
<li>header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.</li>
<li>height: 이미지의 높이(픽셀 단위).</li>
<li>width: 이미지의 너비(픽셀 단위).</li>
<li>encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.</li>
<li>is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.</li>
<li>step: 바이트 단위의 전체 행 길이.</li>
<li>data: 바이트 배열로 저장된 실제 픽셀 데이터.</li>
</ul>
<h2>깊이 이미지 처리</h2>
<p>깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:</p>
<div class="content-ad"></div>
<ul>
<li>객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.</li>
<li>장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.</li>
<li>3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.</li>
</ul>
<h1>결론</h1>
<p>위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.</p>
<p>문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"NVIDIA Jetson Nano에서 Intel RealSense Depth Camera를 사용하여 ROS2 Humble를 활용하기","description":"","date":"2024-05-18 19:15","slug":"2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble","content":"\n\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png\" /\u003e\n\n이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png\" /\u003e\n\n# Prerequisites\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시작하기 전에 다음 구성 요소가 있는지 확인하십시오:\n\n- NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04\n- Intel RealSense Depth Camera (예: D435i)\n- Jetson Nano에 설치된 ROS2 Humble\n- RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블\n- 필요한 패키지를 다운로드하기 위한 인터넷 연결\n\nROS2 RealSense 패키지 설치\n\n```js\nsudo apt install ros-humble-realsense2-camera\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRealSense 노드를 시작해주세요:\n\nRealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:\n\n```python\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='realsense2_camera',\n            executable='realsense2_camera_node',\n            name='realsense2_camera',\n            output='screen',\n            parameters=[{\n                'enable_depth': True,\n                'enable_infra1': True,\n                'enable_infra2': True,\n                'enable_color': True,\n            }],\n        ),\n    ])\n```\n\n란치 파일을 실행하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003ctable\u003e\n    \u003ctr\u003e\n        \u003ctd\u003e![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png)\u003c/td\u003e\n    \u003c/tr\u003e\n\u003c/table\u003e\n\n```js\nros2 launch your_package_name realsense_launch.py\n```\n\nrqt에서 데이터 시각화:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nrqt에 RealSense 데이터 추가하기:\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png)\n\n- 새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.\n- 이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.\n\n![이미지](/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n깊이 이미지\n\n![깊이 이미지](https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif)\n\n# 깊이 이미지란?\n\n깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 주요 주제 및 메시지\n\nROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:\n\n- 토픽: /camera/depth/image_raw\n- 메시지 유형: sensor_msgs/Image\n\n## sensor_msgs/Image 메시지\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nsensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:\n\n- header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.\n- height: 이미지의 높이(픽셀 단위).\n- width: 이미지의 너비(픽셀 단위).\n- encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.\n- is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.\n- step: 바이트 단위의 전체 행 길이.\n- data: 바이트 배열로 저장된 실제 픽셀 데이터.\n\n## 깊이 이미지 처리\n\n깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.\n- 장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.\n- 3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.\n\n# 결론\n\n위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.\n\n문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!","ogImage":{"url":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png"},"coverImage":"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png","tag":["Tech"],"readingTime":4},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    h1: \"h1\",\n    ul: \"ul\",\n    li: \"li\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\",\n    img: \"img\",\n    h2: \"h2\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(\"img\", {\n      src: \"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_0.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 튜토리얼에서는 NVIDIA Jetson Nano와 Intel RealSense Depth Camera를 ROS2 Humble을 사용하여 어떻게 연결하는지 살펴볼 것입니다. 이 설정은 실시간 인식 및 처리 기능이 필요한 로봇 응용 프로그램에 강력합니다. Jetson Nano는 RealSense 카메라에서 데이터를 처리하는 데 필요한 계산 성능을 제공하며, ROS2 Humble은 로봇 소프트웨어 개발과 관리를 위한 견고한 프레임워크를 제공합니다.\"\n    }), \"\\n\", _jsx(\"img\", {\n      src: \"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_1.png\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Prerequisites\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"시작하기 전에 다음 구성 요소가 있는지 확인하십시오:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"NVIDIA Jetson Nano 운영 체제 이미지가 설치된 Ubuntu 20.04\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Intel RealSense Depth Camera (예: D435i)\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Jetson Nano에 설치된 ROS2 Humble\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"RealSense 카메라를 Jetson Nano에 연결하기 위한 USB 3.0 케이블\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"필요한 패키지를 다운로드하기 위한 인터넷 연결\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"ROS2 RealSense 패키지 설치\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"hljs language-js\",\n        children: \"sudo apt install ros-humble-realsense2-camera\\n\"\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"RealSense 노드를 시작해주세요:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"RealSense 노드를 시작하는 런치 파일을 만들어 보세요. 새로운 파일 realsense_launch.py를 만들어 주세요:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-python\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" launch \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" LaunchDescription\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" launch_ros.actions \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" Node\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"def\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"generate_launch_description\"\n        }), \"():\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" LaunchDescription([\\n        Node(\\n            package=\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'realsense2_camera'\"\n        }), \",\\n            executable=\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'realsense2_camera_node'\"\n        }), \",\\n            name=\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'realsense2_camera'\"\n        }), \",\\n            output=\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'screen'\"\n        }), \",\\n            parameters=[{\\n                \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'enable_depth'\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"True\"\n        }), \",\\n                \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'enable_infra1'\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"True\"\n        }), \",\\n                \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'enable_infra2'\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"True\"\n        }), \",\\n                \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'enable_color'\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"True\"\n        }), \",\\n            }],\\n        ),\\n    ])\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"란치 파일을 실행하세요:\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(\"table\", {\n      children: _jsx(\"tr\", {\n        children: _jsx(\"td\", {\n          children: _jsx(_components.img, {\n            src: \"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_2.png\",\n            alt: \"이미지\"\n          })\n        })\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"ros2 launch your_package_name realsense_launch.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"py\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"rqt에서 데이터 시각화:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_3.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"rqt에 RealSense 데이터 추가하기:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_4.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"새로운 DepthCloud 표시 추가 및 토픽을 /camera/depth/color/points로 설정합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"이미지 표시 추가 및 토픽을 /camera/color/image_raw로 설정합니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble_5.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"깊이 이미지\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1400/1*lqW7eh_9bQwt7jdi9FNFDg.gif\",\n        alt: \"깊이 이미지\"\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"깊이 이미지란?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"깊이 이미지는 각 픽셀이 카메라에서 씬 내 객체까지의 거리를 나타내는 회색조 이미지입니다. 색상 정보를 포함하는 일반적인 RGB 이미지와 달리, 깊이 이미지는 깊이 정보를 인코딩하여 환경의 3D 구조를 인식할 수 있게 합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"주요 주제 및 메시지\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"ROS 2에서 RealSense 카메라의 깊이 이미지는 특정 토픽, 보통은 /camera/depth/image_raw에 발행됩니다. 깊이 이미지의 메시지 유형은 sensor_msgs/Image입니다. 주요 요소를 살펴보겠습니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"토픽: /camera/depth/image_raw\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"메시지 유형: sensor_msgs/Image\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"sensor_msgs/Image 메시지\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"sensor_msgs/Image 메시지에는 여러 필드가 포함되어 있지만, 깊이 이미지에 가장 관련있는 필드는 다음과 같습니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"header: 타임스탬프와 좌표 프레임 정보를 포함하는 표준 ROS 메시지 헤더입니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"height: 이미지의 높이(픽셀 단위).\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"width: 이미지의 너비(픽셀 단위).\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"encoding: 이미지 데이터의 인코딩 유형, 예를 들어 16비트 무부호 단일 채널 이미지의 경우 16UC1입니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"is_bigendian: 이미지 데이터가 빅엔디안 바이트 순서로 저장되어 있는지 여부.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"step: 바이트 단위의 전체 행 길이.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"data: 바이트 배열로 저장된 실제 픽셀 데이터.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"깊이 이미지 처리\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"깊이 이미지는 애플리케이션에 따라 다양한 방식으로 처리할 수 있습니다. 일반적인 작업은 다음과 같습니다:\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"객체 감지 및 인식: 3D 모양에 기반하여 객체를 식별하고 분류합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"장애물 피하기: 로봇의 경로에서 장애물을 감지하고 피하기 위해 깊이 정보를 활용합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"3D 매핑: 내비게이션 목적으로 환경의 3D 지도를 작성합니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"결론\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위 단계를 따라서 NVIDIA Jetson Nano가 ROS2 Humble을 사용하여 Intel RealSense Depth Camera와 연결되어 있어야 합니다. 이 설정은 내비게이션, 객체 감지 등을 위해 실시간 깊이 및 색상 데이터를 활용하여 다양한 로봇 응용 프로그램에 매우 유용합니다. 로봇 시스템의 능력을 확장하기 위해 다양한 ROS2 노드 및 패키지를 실험해보세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"문제가 발생하거나 추가 질문이 있으시면 아래에 댓글을 남겨 주세요!\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-18-NVIDIAJetsonNanowithIntelRealSenseDepthCameraUsingROS2Humble"},"buildId":"ll1cGyplNwh83dpggeai1","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>