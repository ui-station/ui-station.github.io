<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels" data-gatsby-head="true"/><meta name="twitter:title" content="논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-17 19:51" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_buildManifest.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 17, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>큰 언어 모델 환시 문제를 해결하기 위해 프롬프트 엔지니어들이 얼마나 빠르게 작업하고 있는지 알아보세요.</p>
<h2>TL;DR</h2>
<p>Chat-GPT와 같은 대규모 언어 모델(Large Language Models, LLM)이 최근 몇 년 동안 인기를 얻고 있습니다. 불행하게도 LLM은 논리 추론을 필요로 하는 작업에 직면하면 종종 "환시"하는 경향이 있어 전문적인 응용 프로그램에서 신뢰할 수 없는 경우가 많습니다.</p>
<p>인간-언어 모델 상호작용을 개선하려는 목적으로 일하는 프롬프트 엔지니어들은 LLM의 논리 추론을 개선하기 위한 새로운 방법을 개발했습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 기사의 기반인 원본 논문 "Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic"은 Zhao 등의 연구진에 의해 2023년 9월에 발표되었으며 다음에서 찾을 수 있습니다: <a href="https://arxiv.org/pdf/2309.13339" rel="nofollow" target="_blank">링크</a>.</p>
<h2>배경</h2>
<p>최근 몇 년간 대형 언어 모델(Large Language Models, LLM)이 인기를 얻고 있으며 가정, 학교 및 직장에서 일상생활에 영향을 미치고 있습니다. 특히 Chat-GPT는 불가결한 가정 이름이 되었습니다.</p>
<p>LLM은 극도로 방대한 데이터셋을 활용하며 수십억 개 또는 심지어 수조 개의 기계 학습 매개변수로 훈련됩니다. 이 방대한 훈련을 통해 인간 언어의 미묘한 복잡성을 포착하여 인간 대화를 닮은 사용자와의 상호작용을 가능케 합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>LLM(거문고 언어 모델)은 다양한 정보를 검색하는 능력을 갖고 있어 신비롭게 보일 수 있지만, 심각한 응용에 사용하기에 제약이 있는 특성을 가지고 있습니다. 근본적으로 LLM은 인간과 같은 지식을 갖고 있지 않습니다. 그들은 단순히 자신의 훈련 데이터와 프롬프트에서 파생된 텍스트를 생성합니다.</p>
<p>이러한 이유로 LLM은 인간 언어의 내재적 논리에 완전히 의존하며, 이는 "환영"의 경우를 초래할 수 있습니다. 여기서 환영은 잘못된 결과를 생성하거나 일반적으로 인간이 쉽게 처리하는 논리적 단어 문제를 해결하지 못하는 상황을 의미합니다. 이러한 논리적 도전은 프롬프트를 다시 구성함으로써 완화될 수 있으며, 이는 본질적으로 LLM이 논리적 사고를 하도록 강요하는 것입니다.</p>
<p>LLM의 보급화를 고려할 때, 현대 기계 학습에서 중요한 프롬프트 엔지니어링이라는 전용 학문 분야가 LLM의 성능을 향상시키고 실용적 목적을 위해 그 출력을 정제하는 데 집중하고 있음을 발견하는 것은 놀라운 일이 아닙니다. 이 분야는 Chat-GPT와 같은 기존 LLM을 보다 효과적으로 활용하기 위한 해결책을 제공하기 때문에, 일종의 없던 기능을 개발하는 대신 기존 LLM을 개선하는 것이 필요한데 그것은 방대한 데이터, 처리 능력, 시간이 필요하기 때문입니다.</p>
<p>본 기사에서 논의된 프롬프트 엔지니어링 논문은 LLM 환영 문제를 해결하기 위해 논리적 원칙을 프롬프트 디자인에 통합하려는 목표를 가지고 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>방법</h2>
<p>해당 논문은 LLM을 위한 제로샷 연쇄사고 프롬프팅을 개선하기 위해 특별히 고안된 새로운 프롬프트 엔지니어링 방법인 Logical Thoughts(LoT)을 소개합니다.</p>
<p>Wei 등이 처음 제시한 연쇄사고(CoT) 프롬프팅은 퓨샷 프롬프팅의 한 형태입니다. 제로샷 프롬프팅과는 달리 퓨샷 프롬프팅은 LLM이 해결해야 할 질문을 제기하기 전에 비슷한 질문-답변 쌍의 "예시"를 제공하는 것을 포함합니다. CoT 프롬프팅에서 예시 답변은 문제를 단계별로 설명합니다. 이를 통해 LLM은 실제 질문에 단계별로 응답해야 하며, 예시 답변을 모방합니다. LLM에게 문제를 단계별로 처리하도록 강요함으로써 응답의 정확도를 크게 향상시킬 수 있습니다.</p>
<p>Kojima 등이 제시한 제로샷 연쇄사고 프롬프팅은 기존 예시를 제공하지 않고 프롬프트에 "한 단계씩 생각해 봅시다"라는 구문을 추가하여 이 효과를 흉내 낼려고 시도합니다. 이 새로운 방법이 개선하려는 것은 이 "제로샷" 연쇄사고 프롬프팅이며, 원래의 "퓨샷" CoT 프롬프팅이 아님을 이해하는 것이 중요합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png" alt="이미지"></p>
<p>LoT은 LLM에게 일반적인 제로샷 CoT 프롬프팅에 따라 문제를 단계별로 해결하도록 합니다. LLM이 초기 단계별 솔루션을 제시한 후, 후속 프롬프트에서는 LLM에게 각 단계를 확인하고 필요에 따라 수정하도록 요청합니다. 이는 LLM에게 각 단계에 대해 긍정적 및 부정적 리뷰를 제공하도록 지시한 다음, 올바른 리뷰를 정당화하고 잘못된 리뷰를 비판하도록 지시하며, 원본 문제의 가정을 고려합니다. 그런 다음 필요한 경우 LLM에게 올바른 리뷰를 사용하여 단계를 수정하도록 요청합니다. 단계가 수정되거나 확인된 후, 원본 문제가 LLM에게 다시 제시되고, 이미 수정되거나 확인된 각 단계가 함께 제시됩니다.</p>
<p><img src="/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_1.png" alt="이미지"></p>
<p>기본적으로, LoT은 LLM을 문제 해결 프로세스를 진행하도록 안내하여 각 단계를 검증하는 데 자체 논리를 사용하도록 요청합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>결과</h2>
<p>논문은 정확도를 기반으로 LoT 방법을 표준 제로샷 CoT 프롬팅과 비교한 결과를 평가합니다. 연구자들은 Vicuna-7b, Vicuna-13b, Vicuna-33b, GPT-3.5-turbo 및 GPT-4 모델을 GSM8K, AQuA, Date, SocialQA, CauseEffect, Objects, Letter 및 OddOut 데이터셋과 짝지어서 해당 방법을 평가했습니다.</p>
<p>연구 결과는 LoT 방법을 사용할 때 대부분의 모델-데이터셋 조합에서 정확도가 향상된다는 것을 보여줍니다. 특히, OddOut 데이터셋에서 Vicuna-13b 모델을 사용했을 때 +16.28%의 정확도 향상이 있었습니다. 반면, Objects 데이터셋에서 GPT-3.5-turbo 모델을 사용했을 때 -2.50%의 정확도 감소가 관찰되었습니다.</p>
<p>이러한 결과는 LoT 방법이 다양한 모델과 데이터셋에 걸쳐 LLM 응답의 정확도를 향상시키는 데 효과적임을 보여줍니다. 그러나 모델과 데이터셋에 따라 개선의 정도가 다르다는 것을 기억해야 합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>토론</h2>
<p>사고 연결 추진이 프롬프팅 방식에 작은 변화만으로 LLM의 추론 능력을 크게 향상시켰지만, LoT 방법은 더 복잡한 프레임워크를 도입하여 실제적인 측면에서는 덜 실용적일 수 있습니다. 게다가 이 연구는 LoT 프롬프팅을 퓨-샷 CoT 프롬프팅과 비교하지 않았기 때문에 LoT가 퓨-샷 CoT 프롬프팅보다 더 효과적인지 여부가 분명하지 않습니다. LoT 프롬프팅은 매우 특화된 범위와 복잡한 구현 과정으로 인해 현실 세계에서 그다지 활용될 가능성이 낮을 수 있습니다.</p>
<p>전반적으로, LoT는 LLM의 내재적인 논리 추론 한계를 해결하기 위한 또 다른 해결책에 불과합니다. 이상적인 시나리오에서 LLM이 인간과 같이 논리를 사용할 수 있기를 바라지만, 단순히 더 많은 매개변수로 훈련된 더 큰 모델을 만들더라도 달성될 수 있는지 여부는 불확실합니다. 아니면 보다 근본적인 논리 통합이 필요한지도 모릅니다.</p>
<p>당분간은 LoT와 같은 접근 방식이 기존 LLM의 유틸리티를 최적화하는 데 효과적인 전략으로 기능할 수 있습니다. 특히 의학과 같이 의도적으로 실수를 줄이기 위해 AI로부터 도움을 받을 때 조심스런 경향이 있는 분야에 유용할 수 있는데, 이러한 프롬프팅 엔지니어링 방법은 고객 서비스 응용 프로그램의 효율성을 향상시킬 수 있는 AI 챗봇에도 활용될 수 있습니다. 이 경우, 이러한 프롬프팅 방식은 사용자와 LLM 자체 사이의 버퍼로 구현되어야 할 것으로 생각됩니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>앞으로 몇 년 동안의 프롬프트 엔지니어링 진화가 흥미로울 것입니다. 이는 LLMs가 더욱 신뢰할 만한 수준으로 발전하여 더욱 비판적인 응용 프로그램에도 사용될 수 있는 길을 열어 줄 수도 있고, 반대로 LLMs가 발전하여 프롬프트 엔지니어링이 쓸모 없어지는 지점까지 발전 할 수도 있습니다. AI가 일상생활에 더욱 통합되는 시대에 LLM 효과성을 향상시키기 위한 노력의 한 부분으로 LoT를 이해하는 것이 중요합니다.</p>
<h2>참고문헌</h2>
<p>Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., &#x26; Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. <a href="https://arxiv.org/abs/2205.11916" rel="nofollow" target="_blank">https://arxiv.org/abs/2205.11916</a></p>
<p>Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., &#x26; Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. <a href="https://arxiv.org/abs/2201.11903" rel="nofollow" target="_blank">https://arxiv.org/abs/2201.11903</a></p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Zhao, X., Li, M., Lu, W., Weber, C., Lee, J., Chu, K., &#x26; Wermter, S. (2023). 대규모 언어 모델에서 논리를 통한 Zero-Shot Chain-of-Thought Reasoning 강화. <a href="https://arxiv.org/abs/2309.13339" rel="nofollow" target="_blank">arXiv 링크</a></p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"논리적인 사고 - 대형 언어 모델의 추론 능력 강화를 위한 새로운 프롬프트 엔지니어링 방법","description":"","date":"2024-05-17 19:51","slug":"2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels","content":"\n큰 언어 모델 환시 문제를 해결하기 위해 프롬프트 엔지니어들이 얼마나 빠르게 작업하고 있는지 알아보세요.\n\n## TL;DR\n\nChat-GPT와 같은 대규모 언어 모델(Large Language Models, LLM)이 최근 몇 년 동안 인기를 얻고 있습니다. 불행하게도 LLM은 논리 추론을 필요로 하는 작업에 직면하면 종종 \"환시\"하는 경향이 있어 전문적인 응용 프로그램에서 신뢰할 수 없는 경우가 많습니다.\n\n인간-언어 모델 상호작용을 개선하려는 목적으로 일하는 프롬프트 엔지니어들은 LLM의 논리 추론을 개선하기 위한 새로운 방법을 개발했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사의 기반인 원본 논문 \"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic\"은 Zhao 등의 연구진에 의해 2023년 9월에 발표되었으며 다음에서 찾을 수 있습니다: [링크](https://arxiv.org/pdf/2309.13339).\n\n## 배경\n\n최근 몇 년간 대형 언어 모델(Large Language Models, LLM)이 인기를 얻고 있으며 가정, 학교 및 직장에서 일상생활에 영향을 미치고 있습니다. 특히 Chat-GPT는 불가결한 가정 이름이 되었습니다.\n\nLLM은 극도로 방대한 데이터셋을 활용하며 수십억 개 또는 심지어 수조 개의 기계 학습 매개변수로 훈련됩니다. 이 방대한 훈련을 통해 인간 언어의 미묘한 복잡성을 포착하여 인간 대화를 닮은 사용자와의 상호작용을 가능케 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLLM(거문고 언어 모델)은 다양한 정보를 검색하는 능력을 갖고 있어 신비롭게 보일 수 있지만, 심각한 응용에 사용하기에 제약이 있는 특성을 가지고 있습니다. 근본적으로 LLM은 인간과 같은 지식을 갖고 있지 않습니다. 그들은 단순히 자신의 훈련 데이터와 프롬프트에서 파생된 텍스트를 생성합니다.\n\n이러한 이유로 LLM은 인간 언어의 내재적 논리에 완전히 의존하며, 이는 \"환영\"의 경우를 초래할 수 있습니다. 여기서 환영은 잘못된 결과를 생성하거나 일반적으로 인간이 쉽게 처리하는 논리적 단어 문제를 해결하지 못하는 상황을 의미합니다. 이러한 논리적 도전은 프롬프트를 다시 구성함으로써 완화될 수 있으며, 이는 본질적으로 LLM이 논리적 사고를 하도록 강요하는 것입니다.\n\nLLM의 보급화를 고려할 때, 현대 기계 학습에서 중요한 프롬프트 엔지니어링이라는 전용 학문 분야가 LLM의 성능을 향상시키고 실용적 목적을 위해 그 출력을 정제하는 데 집중하고 있음을 발견하는 것은 놀라운 일이 아닙니다. 이 분야는 Chat-GPT와 같은 기존 LLM을 보다 효과적으로 활용하기 위한 해결책을 제공하기 때문에, 일종의 없던 기능을 개발하는 대신 기존 LLM을 개선하는 것이 필요한데 그것은 방대한 데이터, 처리 능력, 시간이 필요하기 때문입니다.\n\n본 기사에서 논의된 프롬프트 엔지니어링 논문은 LLM 환영 문제를 해결하기 위해 논리적 원칙을 프롬프트 디자인에 통합하려는 목표를 가지고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 방법\n\n해당 논문은 LLM을 위한 제로샷 연쇄사고 프롬프팅을 개선하기 위해 특별히 고안된 새로운 프롬프트 엔지니어링 방법인 Logical Thoughts(LoT)을 소개합니다.\n\nWei 등이 처음 제시한 연쇄사고(CoT) 프롬프팅은 퓨샷 프롬프팅의 한 형태입니다. 제로샷 프롬프팅과는 달리 퓨샷 프롬프팅은 LLM이 해결해야 할 질문을 제기하기 전에 비슷한 질문-답변 쌍의 \"예시\"를 제공하는 것을 포함합니다. CoT 프롬프팅에서 예시 답변은 문제를 단계별로 설명합니다. 이를 통해 LLM은 실제 질문에 단계별로 응답해야 하며, 예시 답변을 모방합니다. LLM에게 문제를 단계별로 처리하도록 강요함으로써 응답의 정확도를 크게 향상시킬 수 있습니다.\n\nKojima 등이 제시한 제로샷 연쇄사고 프롬프팅은 기존 예시를 제공하지 않고 프롬프트에 \"한 단계씩 생각해 봅시다\"라는 구문을 추가하여 이 효과를 흉내 낼려고 시도합니다. 이 새로운 방법이 개선하려는 것은 이 \"제로샷\" 연쇄사고 프롬프팅이며, 원래의 \"퓨샷\" CoT 프롬프팅이 아님을 이해하는 것이 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png)\n\nLoT은 LLM에게 일반적인 제로샷 CoT 프롬프팅에 따라 문제를 단계별로 해결하도록 합니다. LLM이 초기 단계별 솔루션을 제시한 후, 후속 프롬프트에서는 LLM에게 각 단계를 확인하고 필요에 따라 수정하도록 요청합니다. 이는 LLM에게 각 단계에 대해 긍정적 및 부정적 리뷰를 제공하도록 지시한 다음, 올바른 리뷰를 정당화하고 잘못된 리뷰를 비판하도록 지시하며, 원본 문제의 가정을 고려합니다. 그런 다음 필요한 경우 LLM에게 올바른 리뷰를 사용하여 단계를 수정하도록 요청합니다. 단계가 수정되거나 확인된 후, 원본 문제가 LLM에게 다시 제시되고, 이미 수정되거나 확인된 각 단계가 함께 제시됩니다.\n\n![이미지](/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_1.png)\n\n기본적으로, LoT은 LLM을 문제 해결 프로세스를 진행하도록 안내하여 각 단계를 검증하는 데 자체 논리를 사용하도록 요청합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 결과\n\n논문은 정확도를 기반으로 LoT 방법을 표준 제로샷 CoT 프롬팅과 비교한 결과를 평가합니다. 연구자들은 Vicuna-7b, Vicuna-13b, Vicuna-33b, GPT-3.5-turbo 및 GPT-4 모델을 GSM8K, AQuA, Date, SocialQA, CauseEffect, Objects, Letter 및 OddOut 데이터셋과 짝지어서 해당 방법을 평가했습니다.\n\n연구 결과는 LoT 방법을 사용할 때 대부분의 모델-데이터셋 조합에서 정확도가 향상된다는 것을 보여줍니다. 특히, OddOut 데이터셋에서 Vicuna-13b 모델을 사용했을 때 +16.28%의 정확도 향상이 있었습니다. 반면, Objects 데이터셋에서 GPT-3.5-turbo 모델을 사용했을 때 -2.50%의 정확도 감소가 관찰되었습니다.\n\n이러한 결과는 LoT 방법이 다양한 모델과 데이터셋에 걸쳐 LLM 응답의 정확도를 향상시키는 데 효과적임을 보여줍니다. 그러나 모델과 데이터셋에 따라 개선의 정도가 다르다는 것을 기억해야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 토론\n\n사고 연결 추진이 프롬프팅 방식에 작은 변화만으로 LLM의 추론 능력을 크게 향상시켰지만, LoT 방법은 더 복잡한 프레임워크를 도입하여 실제적인 측면에서는 덜 실용적일 수 있습니다. 게다가 이 연구는 LoT 프롬프팅을 퓨-샷 CoT 프롬프팅과 비교하지 않았기 때문에 LoT가 퓨-샷 CoT 프롬프팅보다 더 효과적인지 여부가 분명하지 않습니다. LoT 프롬프팅은 매우 특화된 범위와 복잡한 구현 과정으로 인해 현실 세계에서 그다지 활용될 가능성이 낮을 수 있습니다.\n\n전반적으로, LoT는 LLM의 내재적인 논리 추론 한계를 해결하기 위한 또 다른 해결책에 불과합니다. 이상적인 시나리오에서 LLM이 인간과 같이 논리를 사용할 수 있기를 바라지만, 단순히 더 많은 매개변수로 훈련된 더 큰 모델을 만들더라도 달성될 수 있는지 여부는 불확실합니다. 아니면 보다 근본적인 논리 통합이 필요한지도 모릅니다.\n\n당분간은 LoT와 같은 접근 방식이 기존 LLM의 유틸리티를 최적화하는 데 효과적인 전략으로 기능할 수 있습니다. 특히 의학과 같이 의도적으로 실수를 줄이기 위해 AI로부터 도움을 받을 때 조심스런 경향이 있는 분야에 유용할 수 있는데, 이러한 프롬프팅 엔지니어링 방법은 고객 서비스 응용 프로그램의 효율성을 향상시킬 수 있는 AI 챗봇에도 활용될 수 있습니다. 이 경우, 이러한 프롬프팅 방식은 사용자와 LLM 자체 사이의 버퍼로 구현되어야 할 것으로 생각됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n앞으로 몇 년 동안의 프롬프트 엔지니어링 진화가 흥미로울 것입니다. 이는 LLMs가 더욱 신뢰할 만한 수준으로 발전하여 더욱 비판적인 응용 프로그램에도 사용될 수 있는 길을 열어 줄 수도 있고, 반대로 LLMs가 발전하여 프롬프트 엔지니어링이 쓸모 없어지는 지점까지 발전 할 수도 있습니다. AI가 일상생활에 더욱 통합되는 시대에 LLM 효과성을 향상시키기 위한 노력의 한 부분으로 LoT를 이해하는 것이 중요합니다.\n\n## 참고문헌\n\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., \u0026 Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. https://arxiv.org/abs/2205.11916\n\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., \u0026 Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nZhao, X., Li, M., Lu, W., Weber, C., Lee, J., Chu, K., \u0026 Wermter, S. (2023). 대규모 언어 모델에서 논리를 통한 Zero-Shot Chain-of-Thought Reasoning 강화. [arXiv 링크](https://arxiv.org/abs/2309.13339)\n","ogImage":{"url":"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e큰 언어 모델 환시 문제를 해결하기 위해 프롬프트 엔지니어들이 얼마나 빠르게 작업하고 있는지 알아보세요.\u003c/p\u003e\n\u003ch2\u003eTL;DR\u003c/h2\u003e\n\u003cp\u003eChat-GPT와 같은 대규모 언어 모델(Large Language Models, LLM)이 최근 몇 년 동안 인기를 얻고 있습니다. 불행하게도 LLM은 논리 추론을 필요로 하는 작업에 직면하면 종종 \"환시\"하는 경향이 있어 전문적인 응용 프로그램에서 신뢰할 수 없는 경우가 많습니다.\u003c/p\u003e\n\u003cp\u003e인간-언어 모델 상호작용을 개선하려는 목적으로 일하는 프롬프트 엔지니어들은 LLM의 논리 추론을 개선하기 위한 새로운 방법을 개발했습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 기사의 기반인 원본 논문 \"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic\"은 Zhao 등의 연구진에 의해 2023년 9월에 발표되었으며 다음에서 찾을 수 있습니다: \u003ca href=\"https://arxiv.org/pdf/2309.13339\" rel=\"nofollow\" target=\"_blank\"\u003e링크\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e배경\u003c/h2\u003e\n\u003cp\u003e최근 몇 년간 대형 언어 모델(Large Language Models, LLM)이 인기를 얻고 있으며 가정, 학교 및 직장에서 일상생활에 영향을 미치고 있습니다. 특히 Chat-GPT는 불가결한 가정 이름이 되었습니다.\u003c/p\u003e\n\u003cp\u003eLLM은 극도로 방대한 데이터셋을 활용하며 수십억 개 또는 심지어 수조 개의 기계 학습 매개변수로 훈련됩니다. 이 방대한 훈련을 통해 인간 언어의 미묘한 복잡성을 포착하여 인간 대화를 닮은 사용자와의 상호작용을 가능케 합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eLLM(거문고 언어 모델)은 다양한 정보를 검색하는 능력을 갖고 있어 신비롭게 보일 수 있지만, 심각한 응용에 사용하기에 제약이 있는 특성을 가지고 있습니다. 근본적으로 LLM은 인간과 같은 지식을 갖고 있지 않습니다. 그들은 단순히 자신의 훈련 데이터와 프롬프트에서 파생된 텍스트를 생성합니다.\u003c/p\u003e\n\u003cp\u003e이러한 이유로 LLM은 인간 언어의 내재적 논리에 완전히 의존하며, 이는 \"환영\"의 경우를 초래할 수 있습니다. 여기서 환영은 잘못된 결과를 생성하거나 일반적으로 인간이 쉽게 처리하는 논리적 단어 문제를 해결하지 못하는 상황을 의미합니다. 이러한 논리적 도전은 프롬프트를 다시 구성함으로써 완화될 수 있으며, 이는 본질적으로 LLM이 논리적 사고를 하도록 강요하는 것입니다.\u003c/p\u003e\n\u003cp\u003eLLM의 보급화를 고려할 때, 현대 기계 학습에서 중요한 프롬프트 엔지니어링이라는 전용 학문 분야가 LLM의 성능을 향상시키고 실용적 목적을 위해 그 출력을 정제하는 데 집중하고 있음을 발견하는 것은 놀라운 일이 아닙니다. 이 분야는 Chat-GPT와 같은 기존 LLM을 보다 효과적으로 활용하기 위한 해결책을 제공하기 때문에, 일종의 없던 기능을 개발하는 대신 기존 LLM을 개선하는 것이 필요한데 그것은 방대한 데이터, 처리 능력, 시간이 필요하기 때문입니다.\u003c/p\u003e\n\u003cp\u003e본 기사에서 논의된 프롬프트 엔지니어링 논문은 LLM 환영 문제를 해결하기 위해 논리적 원칙을 프롬프트 디자인에 통합하려는 목표를 가지고 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e방법\u003c/h2\u003e\n\u003cp\u003e해당 논문은 LLM을 위한 제로샷 연쇄사고 프롬프팅을 개선하기 위해 특별히 고안된 새로운 프롬프트 엔지니어링 방법인 Logical Thoughts(LoT)을 소개합니다.\u003c/p\u003e\n\u003cp\u003eWei 등이 처음 제시한 연쇄사고(CoT) 프롬프팅은 퓨샷 프롬프팅의 한 형태입니다. 제로샷 프롬프팅과는 달리 퓨샷 프롬프팅은 LLM이 해결해야 할 질문을 제기하기 전에 비슷한 질문-답변 쌍의 \"예시\"를 제공하는 것을 포함합니다. CoT 프롬프팅에서 예시 답변은 문제를 단계별로 설명합니다. 이를 통해 LLM은 실제 질문에 단계별로 응답해야 하며, 예시 답변을 모방합니다. LLM에게 문제를 단계별로 처리하도록 강요함으로써 응답의 정확도를 크게 향상시킬 수 있습니다.\u003c/p\u003e\n\u003cp\u003eKojima 등이 제시한 제로샷 연쇄사고 프롬프팅은 기존 예시를 제공하지 않고 프롬프트에 \"한 단계씩 생각해 봅시다\"라는 구문을 추가하여 이 효과를 흉내 낼려고 시도합니다. 이 새로운 방법이 개선하려는 것은 이 \"제로샷\" 연쇄사고 프롬프팅이며, 원래의 \"퓨샷\" CoT 프롬프팅이 아님을 이해하는 것이 중요합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eLoT은 LLM에게 일반적인 제로샷 CoT 프롬프팅에 따라 문제를 단계별로 해결하도록 합니다. LLM이 초기 단계별 솔루션을 제시한 후, 후속 프롬프트에서는 LLM에게 각 단계를 확인하고 필요에 따라 수정하도록 요청합니다. 이는 LLM에게 각 단계에 대해 긍정적 및 부정적 리뷰를 제공하도록 지시한 다음, 올바른 리뷰를 정당화하고 잘못된 리뷰를 비판하도록 지시하며, 원본 문제의 가정을 고려합니다. 그런 다음 필요한 경우 LLM에게 올바른 리뷰를 사용하여 단계를 수정하도록 요청합니다. 단계가 수정되거나 확인된 후, 원본 문제가 LLM에게 다시 제시되고, 이미 수정되거나 확인된 각 단계가 함께 제시됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e기본적으로, LoT은 LLM을 문제 해결 프로세스를 진행하도록 안내하여 각 단계를 검증하는 데 자체 논리를 사용하도록 요청합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e결과\u003c/h2\u003e\n\u003cp\u003e논문은 정확도를 기반으로 LoT 방법을 표준 제로샷 CoT 프롬팅과 비교한 결과를 평가합니다. 연구자들은 Vicuna-7b, Vicuna-13b, Vicuna-33b, GPT-3.5-turbo 및 GPT-4 모델을 GSM8K, AQuA, Date, SocialQA, CauseEffect, Objects, Letter 및 OddOut 데이터셋과 짝지어서 해당 방법을 평가했습니다.\u003c/p\u003e\n\u003cp\u003e연구 결과는 LoT 방법을 사용할 때 대부분의 모델-데이터셋 조합에서 정확도가 향상된다는 것을 보여줍니다. 특히, OddOut 데이터셋에서 Vicuna-13b 모델을 사용했을 때 +16.28%의 정확도 향상이 있었습니다. 반면, Objects 데이터셋에서 GPT-3.5-turbo 모델을 사용했을 때 -2.50%의 정확도 감소가 관찰되었습니다.\u003c/p\u003e\n\u003cp\u003e이러한 결과는 LoT 방법이 다양한 모델과 데이터셋에 걸쳐 LLM 응답의 정확도를 향상시키는 데 효과적임을 보여줍니다. 그러나 모델과 데이터셋에 따라 개선의 정도가 다르다는 것을 기억해야 합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e토론\u003c/h2\u003e\n\u003cp\u003e사고 연결 추진이 프롬프팅 방식에 작은 변화만으로 LLM의 추론 능력을 크게 향상시켰지만, LoT 방법은 더 복잡한 프레임워크를 도입하여 실제적인 측면에서는 덜 실용적일 수 있습니다. 게다가 이 연구는 LoT 프롬프팅을 퓨-샷 CoT 프롬프팅과 비교하지 않았기 때문에 LoT가 퓨-샷 CoT 프롬프팅보다 더 효과적인지 여부가 분명하지 않습니다. LoT 프롬프팅은 매우 특화된 범위와 복잡한 구현 과정으로 인해 현실 세계에서 그다지 활용될 가능성이 낮을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e전반적으로, LoT는 LLM의 내재적인 논리 추론 한계를 해결하기 위한 또 다른 해결책에 불과합니다. 이상적인 시나리오에서 LLM이 인간과 같이 논리를 사용할 수 있기를 바라지만, 단순히 더 많은 매개변수로 훈련된 더 큰 모델을 만들더라도 달성될 수 있는지 여부는 불확실합니다. 아니면 보다 근본적인 논리 통합이 필요한지도 모릅니다.\u003c/p\u003e\n\u003cp\u003e당분간은 LoT와 같은 접근 방식이 기존 LLM의 유틸리티를 최적화하는 데 효과적인 전략으로 기능할 수 있습니다. 특히 의학과 같이 의도적으로 실수를 줄이기 위해 AI로부터 도움을 받을 때 조심스런 경향이 있는 분야에 유용할 수 있는데, 이러한 프롬프팅 엔지니어링 방법은 고객 서비스 응용 프로그램의 효율성을 향상시킬 수 있는 AI 챗봇에도 활용될 수 있습니다. 이 경우, 이러한 프롬프팅 방식은 사용자와 LLM 자체 사이의 버퍼로 구현되어야 할 것으로 생각됩니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e앞으로 몇 년 동안의 프롬프트 엔지니어링 진화가 흥미로울 것입니다. 이는 LLMs가 더욱 신뢰할 만한 수준으로 발전하여 더욱 비판적인 응용 프로그램에도 사용될 수 있는 길을 열어 줄 수도 있고, 반대로 LLMs가 발전하여 프롬프트 엔지니어링이 쓸모 없어지는 지점까지 발전 할 수도 있습니다. AI가 일상생활에 더욱 통합되는 시대에 LLM 효과성을 향상시키기 위한 노력의 한 부분으로 LoT를 이해하는 것이 중요합니다.\u003c/p\u003e\n\u003ch2\u003e참고문헌\u003c/h2\u003e\n\u003cp\u003eKojima, T., Gu, S. S., Reid, M., Matsuo, Y., \u0026#x26; Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. \u003ca href=\"https://arxiv.org/abs/2205.11916\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://arxiv.org/abs/2205.11916\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., \u0026#x26; Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. \u003ca href=\"https://arxiv.org/abs/2201.11903\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://arxiv.org/abs/2201.11903\u003c/a\u003e\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eZhao, X., Li, M., Lu, W., Weber, C., Lee, J., Chu, K., \u0026#x26; Wermter, S. (2023). 대규모 언어 모델에서 논리를 통한 Zero-Shot Chain-of-Thought Reasoning 강화. \u003ca href=\"https://arxiv.org/abs/2309.13339\" rel=\"nofollow\" target=\"_blank\"\u003earXiv 링크\u003c/a\u003e\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-17-LogicalThoughtsaNewPromptEngineeringMethodtoEnhanceReasoningSkillsofLargeLanguageModels"},"buildId":"GsgRekSb--BvxYwv9FPn6","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>