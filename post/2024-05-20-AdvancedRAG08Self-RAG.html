<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>고급 RAG 08 Self-RAG | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-20-AdvancedRAG08Self-RAG" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="고급 RAG 08 Self-RAG | ui-station" data-gatsby-head="true"/><meta property="og:title" content="고급 RAG 08 Self-RAG | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-20-AdvancedRAG08Self-RAG" data-gatsby-head="true"/><meta name="twitter:title" content="고급 RAG 08 Self-RAG | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-20 21:10" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-4f7b40c1114f0d09.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_buildManifest.js" defer=""></script><script src="/_next/static/o1YmnmSuZvAX2O4TI9r41/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">고급 RAG 08 Self-RAG</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="고급 RAG 08 Self-RAG" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 20, 2024</span><span class="posts_reading_time__f7YPP">13<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-20-AdvancedRAG08Self-RAG&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>이 기사는 흔한 시나리오로 시작됩니다: 공개 시험을 보는 경우입니다. 일반적으로 두 가지 전략을 사용합니다:</p>
<ul>
<li>방법 1: 익숙한 주제에 대해서는 빠르게 답변하고, 익숙하지 않은 주제에 대해서는 참고서를 열어서 확인하고, 관련 부분을 빠르게 찾아내어 정리하고 요약한 다음, 시험지에 답변합니다.</li>
<li>방법 2: 모든 주제에 대해 책을 참고합니다. 적절한 부분을 찾아내고, 정리하고 요약한 다음, 시험지에 답변합니다.</li>
</ul>
<p>분명히 방법 1이 선호되는 방법입니다. 방법 2는 시간이 소비될 수 있고, 관련성 없는 정보나 잘못된 정보가 들어올 수 있어 혼란과 실수를 야기할 수 있습니다. 심지어 처음에 이해한 부분에서도 발생할 수 있습니다.</p>
<p>하지만, 방법 2는 고전적인 RAG 프로세스를 보여주며, 방법 1은 자체 RAG 프로세스를 대표합니다. 이에 대해 이 기사에서 더 자세히 다룰 것입니다.</p>
<h1>개요</h1>
<p>그림 1은 RAG 및 Self-RAG의 주요 프로세스를 비교한 것을 보여줍니다:</p>
<p><img src="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png" alt="그림"></p>
<p>Self-RAG는 세 단계로 구성되어 있습니다:</p>
<ul>
<li>필요한 경우 검색: 모델이 검색을 요구하는 경우, 예를 들어 "미국 주가 이름을 어떻게 얻었습니까?" (그림 1의 오른쪽 상단)와 같은 쿼리가 있을 때, 모델의 출력에는 [검색] 토큰이 포함됩니다. 이는 쿼리와 관련된 내용을 검색해야 함을 나타냅니다. 반면에 "최고의 여름 휴가에 대해 에세이를 쓰세요" (그림 1의 오른쪽 아래)와 같이 물어볼 때, 모델은 검색 없이 직접 답변을 생성하도록 선택합니다.</li>
<li>병렬 생성: 모델은 프롬프트와 검색된 콘텐츠를 모두 사용하여 출력을 생성합니다. 이 과정에서 세 가지 유형의 반영 토큰이 검색된 콘텐츠의 관련성을 나타냅니다.</li>
<li>평가 및 선택: 단계 2에서 생성된 콘텐츠가 평가되고, 최상의 세그먼트가 출력으로 선택됩니다.</li>
</ul>
<p>상기 모델은 특별히 훈련된 모델이라는 것을 유의하십시오. 이 모델의 훈련 과정은 이 기사의 후반부에서 논의될 것입니다.</p>
<h1>반영 토큰</h1>
<p>Self-RAG 프레임워크의 RAG와 비교했을 때, Self-RAG 프레임워크의 차이는 생성 중 더 정확한 제어를 위해 반영 토큰을 사용한다는 것입니다. 그림 2에서 보여집니다.</p>
<p>본질적으로, self-RAG는 네 가지 명확한 판단을 내립니다:</p>
<ul>
<li>[Retrieve]: 리소스 R로부터 정보를 검색할지를 결정하는 의사결정 과정.</li>
<li>[IsREL]: 주어진 데이터 d가 문제 x를 해결하는 데 필요한 정보를 포함하고 있는지를 결정하는 관련성 확인.</li>
<li>[IsSUP]: 제공된 응답 y의 내용이 데이터 d로부터 지원되는지를 확인하는 검증 과정.</li>
<li>[IsUSE]: 문제 x에 대한 응답 y의 유용성을 평가하는 평가 과정. 결과는 1에서 5까지의 점수로, 5는 가장 높은 유용성을 나타냅니다.</li>
</ul>
<p>RAG에서 검색은 상태에 관계없이 항상 처음에 수행되는 고정된 과정입니다. 반면 self-RAG는 반사 토큰을 도입하여 LLM을 더 적응적이고 지능적으로 만듭니다. LLM이 텍스트를 생성하다가 불확실성이 발생하는 부분에 도달하면 반사 토큰에서 일시 정지하여 신속하고 정확한 검색을 수행한 후 새로 습득한 정보를 사용하여 생성을 재개합니다.</p>
<h1>코드 설명</h1>
<p>self-RAG 프로세스를 직관적으로 이해하기 위해 먼저 코드를 살펴보고 모델의 훈련 과정을 설명하겠습니다.</p>
<p>self-RAG는 오픈 소스이며, Langchain과 LlamaIndex에는 각각의 구현이 있습니다. 우리는 설명을 위해 LlamaIndex의 구현을 참조할 것입니다.</p>
<h2>환경 설정</h2>
<p>먼저, 환경을 설정하세요.</p>
<pre><code class="hljs language-js">(base) <span class="hljs-title class_">Florian</span>@instance-<span class="hljs-number">1</span>:~$ conda create -n llamaindex python=<span class="hljs-number">3.11</span>

(base) <span class="hljs-title class_">Florian</span>@instance-<span class="hljs-number">1</span>:~$ conda activate llamaindex


(llamaindex) <span class="hljs-title class_">Florian</span>@instance-<span class="hljs-number">1</span>:~$ pip install llama-index

(llamaindex) <span class="hljs-title class_">Florian</span>@instance-<span class="hljs-number">1</span>:~$ pip install huggingface-hub

(llamaindex) <span class="hljs-title class_">Florian</span>@instance-<span class="hljs-number">1</span>:~$ huggingface-cli login
</code></pre>
<p>설치 후, LlamaIndex의 대응 버전은 다음과 같습니다:</p>
<pre><code class="hljs language-js">llama-index                             <span class="hljs-number">0.10</span><span class="hljs-number">.20</span>

llama-index-core                        <span class="hljs-number">0.10</span><span class="hljs-number">.20</span>.<span class="hljs-property">post2</span>
</code></pre>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> os
os.<span class="hljs-property">environ</span>[<span class="hljs-string">"OPENAI_API_KEY"</span>] = <span class="hljs-string">"여러분의 오픈AI API 키"</span>

<span class="hljs-keyword">from</span> llama_index.<span class="hljs-property">core</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">Document</span>, <span class="hljs-title class_">VectorStoreIndex</span>
<span class="hljs-keyword">from</span> llama_index.<span class="hljs-property">core</span>.<span class="hljs-property">retrievers</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">VectorIndexRetriever</span>
<span class="hljs-keyword">from</span> llama_index.<span class="hljs-property">core</span>.<span class="hljs-property">readers</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">SimpleDirectoryReader</span>
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> <span class="hljs-title class_">Path</span>


# 옵션: <span class="hljs-title class_">SelfRAGPack</span> 다운로드
# 첫 실행 시 <span class="hljs-title class_">SelfRAGPack</span>을 다운로드해야 합니다. 
# 다음 실행부터는 이 부분을 주석 처리할 수 있습니다.
<span class="hljs-keyword">from</span> llama_index.<span class="hljs-property">core</span>.<span class="hljs-property">llama_pack</span> <span class="hljs-keyword">import</span> download_llama_pack
<span class="hljs-title function_">download_llama_pack</span>(
    <span class="hljs-string">"SelfRAGPack"</span>,
    <span class="hljs-string">"./self_rag_pack"</span>)

<span class="hljs-keyword">from</span> llama_index.<span class="hljs-property">packs</span>.<span class="hljs-property">self_rag</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">SelfRAGQueryEngine</span>

# 이전에 다운로드하고 저장한 <span class="hljs-title class_">Llama2</span> 모델이 있는 디렉토리.
download_dir = <span class="hljs-string">"여러분의 다운로드 모델 디렉토리"</span>

# 테스트 문서 생성
documents = [
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"남극 얼음 위를 '웨들'이라고 불리는 물개 떼가 지나다녔다. 그들의 턱시도 같은 깃털은 눈 위에서 돋보였다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"펭귄 중 가장 키가 큰 황제펭귄은 다른 어떤 새보다도 더 깊이 다이빙을 할 수 있어서 500m 이상의 심해까지 다이빙을 합니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"펭귄들의 흑백색깔은 위험 방어라는 화장법의 한 종류인 카운터셰이딩입니다. 위에서 보면 펭귄의 검은 등은 바다 심지와 어우러지고, 아래에서는 펭귄의 흰 배는 밝은 표면과 어우러집니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"수직 자세이지만, 펭귄은 날지 못하는 조류입니다. 그들의 날개는 지느러미로 진화했기 때문에 수중에서 전문 수영가입니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"가장 빠른 펭귄 종류인 젠투 펭귄은 시속 36킬로미터까지 수영할 수 있으며, 수중을 순찰하는 동안 지느러미와 윤곽을 이용해 물을 가르는 식으로 전진합니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"펭귄은 집단생활을 하는 조류입니다. 많은 종들이 번식을 위해 수만 마리까지 이를 결성합니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"펭귄은 놀랍게도 귀가 우수하며 지저분한 떼 속에서 배우량과 새끼를 식별하는 데 명확한 호출을 의존합니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"가장 작은 펭귄 종인 리틀 블루 펭귄은 약 40cm 높이로, 남부 호주와 뉴질랜드 해안가에서 발견됩니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"번식 기간 중, 수컷 황제펭귄은 한없이 지속되는 남극 겨울을 버텨내며 몇 달간 급식없이 알을 부화시키는 반면, 암컷은 바다에서 사냥을 합니다."</span>
    ),
    <span class="hljs-title class_">Document</span>(
        text=<span class="hljs-string">"펭귄은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 그리고 크릴로 이루어져 있으며 이를 수중 다이빙을 통해 잡습니다."</span>
    ),
]

index = <span class="hljs-title class_">VectorStoreIndex</span>.<span class="hljs-title function_">from_documents</span>(documents)

# 간단한 리트리버 설정
retriever = <span class="hljs-title class_">VectorIndexRetriever</span>(
    index=index,
    similarity_top_k=<span class="hljs-number">10</span>,
)


model_path = <span class="hljs-title class_">Path</span>(download_dir) / <span class="hljs-string">"selfrag_llama2_7b.q4_k_m.gguf"</span>
query_engine = <span class="hljs-title class_">SelfRAGQueryEngine</span>(<span class="hljs-title function_">str</span>(model_path), retriever, verbose=<span class="hljs-title class_">True</span>)

# 리트리벌 예시
response = query_engine.<span class="hljs-title function_">query</span>(<span class="hljs-string">"어떤 장르인가요?"</span>)

# 리트리벌 예시
response = query_engine.<span class="hljs-title function_">query</span>(<span class="hljs-string">"가장 작은 펭귄의 키는 얼마인가요?"</span>)
</code></pre>
<p>위의 테스트 코드는 다음 결과를 생성했습니다(대부분의 llama_cpp 디버깅 정보가 제거되었습니다):</p>
<pre><code class="hljs language-js"><span class="hljs-title class_">Model</span> <span class="hljs-attr">metadata</span>: {<span class="hljs-string">'tokenizer.ggml.add_eos_token'</span>: <span class="hljs-string">'false'</span>, <span class="hljs-string">'tokenizer.ggml.eos_token_id'</span>: <span class="hljs-string">'2'</span>, <span class="hljs-string">'general.architecture'</span>: <span class="hljs-string">'llama'</span>, <span class="hljs-string">'llama.rope.freq_base'</span>: <span class="hljs-string">'10000.000000'</span>, <span class="hljs-string">'llama.context_length'</span>: <span class="hljs-string">'4096'</span>, <span class="hljs-string">'general.name'</span>: <span class="hljs-string">'LLaMA v2'</span>, <span class="hljs-string">'tokenizer.ggml.add_bos_token'</span>: <span class="hljs-string">'true'</span>, <span class="hljs-string">'llama.embedding_length'</span>: <span class="hljs-string">'4096'</span>, <span class="hljs-string">'llama.feed_forward_length'</span>: <span class="hljs-string">'11008'</span>, <span class="hljs-string">'llama.attention.layer_norm_rms_epsilon'</span>: <span class="hljs-string">'0.000010'</span>, <span class="hljs-string">'llama.rope.dimension_count'</span>: <span class="hljs-string">'128'</span>, <span class="hljs-string">'tokenizer.ggml.bos_token_id'</span>: <span class="hljs-string">'1'</span>, <span class="hljs-string">'llama.attention.head_count'</span>: <span class="hljs-string">'32'</span>, <span class="hljs-string">'llama.block_count'</span>: <span class="hljs-string">'32'</span>, <span class="hljs-string">'llama.attention.head_count_kv'</span>: <span class="hljs-string">'32'</span>, <span class="hljs-string">'general.quantization_version'</span>: <span class="hljs-string">'2'</span>, <span class="hljs-string">'tokenizer.ggml.model'</span>: <span class="hljs-string">'llama'</span>, <span class="hljs-string">'general.file_type'</span>: <span class="hljs-string">'15'</span>}
<span class="hljs-title class_">Using</span> fallback chat <span class="hljs-attr">format</span>: <span class="hljs-title class_">None</span>

<span class="hljs-attr">llama_print_timings</span>:        load time =    <span class="hljs-number">4887.53</span> ms
<span class="hljs-attr">llama_print_timings</span>:      sample time =      <span class="hljs-number">11.29</span> ms /    <span class="hljs-number">22</span> runs   (    <span class="hljs-number">0.51</span> ms per token,  <span class="hljs-number">1947.76</span> tokens per second)
<span class="hljs-attr">llama_print_timings</span>: prompt <span class="hljs-built_in">eval</span> time =    <span class="hljs-number">4887.46</span> ms /    <span class="hljs-number">24</span> tokens (  <span class="hljs-number">203.64</span> ms per token,     <span class="hljs-number">4.91</span> tokens per second)
<span class="hljs-attr">llama_print_timings</span>:        <span class="hljs-built_in">eval</span> time =    <span class="hljs-number">5883.27</span> ms /    <span class="hljs-number">21</span> runs   (  <span class="hljs-number">280.16</span> ms per token,     <span class="hljs-number">3.57</span> tokens per second)
<span class="hljs-attr">llama_print_timings</span>:       total time =   <span class="hljs-number">10901.84</span> ms /    <span class="hljs-number">45</span> tokens
최종 답변: <span class="hljs-string">'오만과 편견'</span>은 제인 오스틴의 로맨스 소설입니다.
<span class="hljs-attr">llama_print_timings</span>:        load time =    <span class="hljs-number">4887.53</span> ms
<span class="hljs-attr">llama_print_timings</span>:      sample time =      <span class="hljs-number">11.74</span> ms /    <span class="hljs-number">20</span> runs   (    <span class="hljs-number">0.59</span> ms per token,  <span class="hljs-number">1703.29</span> tokens per second)
<span class="hljs-attr">llama_print_timings</span>: prompt <span class="hljs-built_in">eval</span> time =    <span class="hljs-number">7473.66</span> ms /    <span class="hljs-number">37</span> tokens (  <span class="hljs-number">201.99</span> ms per token,     <span class="hljs-number">4.95</span> tokens per second)
<span class="hljs-attr">llama_print_timings</span>:        <span class="hljs-built_in">eval</span> time =    <span class="hljs-number">5414.34</span> ms /    <span class="hljs-number">19</span> runs   (  <span class="hljs-number">284.96</span> ms per token,     <span class="hljs-number">3.51</span> tokens per second)
<span class="hljs-attr">llama_print_timings</span>:       total time =   <span class="hljs-number">13076.88</span> ms /    <span class="hljs-number">56</span> tokens
입력: ### 지시사항:
가장 작은 펭귄은 얼마나 키가 큰가요?

### 응답:
[검색]&#x3C;문단>펭귄들은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 크릴로 구성되어 있으며 이를 다이빙으로 잡습니다.<span class="hljs-string">"&#x3C;/문단>
예측: [관련]가장 작은 펭귄 종류의 키는 종에 따라 달라질 수 있습니다.[지원되지 않음 / 모순][유틸리티:5]
점수: 1.4213598342974367
10/10 단락 완료

평가 종료
최상의 답변 선정: [관련]가
</span></code></pre>
<p>테스트 코드를 이해하는 핵심은 SelfRAGQueryEngine 클래스의 구현에 있습니다. 이제 이 클래스를 자세히 살펴보겠습니다.</p>
<h2>클래스 SelfRAGQueryEngine</h2>
<p>먼저 생성자입니다. 주로 llama_cpp를 사용하여 Llama2-7B 모델을 로드하기 위해 사용됩니다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SelfRAGQueryEngine</span>(<span class="hljs-title class_ inherited__">CustomQueryEngine</span>):
    <span class="hljs-string">"""간단한 Self RAG 쿼리 엔진."""</span>

    llm: <span class="hljs-type">Any</span> = Field(default=<span class="hljs-literal">None</span>, description=<span class="hljs-string">"llm"</span>)
    retriever: BaseRetriever = Field(default=<span class="hljs-literal">None</span>, description=<span class="hljs-string">"retriever"</span>)
    generate_kwargs: <span class="hljs-type">Dict</span> = Field(default=<span class="hljs-literal">None</span>, description=<span class="hljs-string">"llm generation arguments"</span>)
    verbose: <span class="hljs-built_in">bool</span> = Field(default=<span class="hljs-literal">True</span>, description=<span class="hljs-string">"Verbose."</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">
        self,
        model_path: <span class="hljs-built_in">str</span>,
        retriever: BaseRetriever,
        verbose: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,
        model_kwargs: <span class="hljs-type">Dict</span> = <span class="hljs-literal">None</span>,
        generate_kwargs: <span class="hljs-type">Dict</span> = <span class="hljs-literal">None</span>,
        **kwargs: <span class="hljs-type">Any</span>,
    </span>) -> <span class="hljs-literal">None</span>:
        <span class="hljs-string">"""매개변수 초기화."""</span>
        <span class="hljs-built_in">super</span>().__init__(verbose=verbose, **kwargs)
        model_kwargs = model_kwargs <span class="hljs-keyword">or</span> _MODEL_KWARGS
        self.generate_kwargs = generate_kwargs <span class="hljs-keyword">or</span> _GENERATE_KWARGS
        <span class="hljs-keyword">try</span>:
            <span class="hljs-keyword">from</span> llama_cpp <span class="hljs-keyword">import</span> Llama
        <span class="hljs-keyword">except</span> ImportError:
            <span class="hljs-keyword">raise</span> ImportError(_IMPORT_ERROR_MSG)
        self.llm = Llama(model_path=model_path, verbose=verbose, **model_kwargs)
        self.retriever = retriever
</code></pre>
<p>그 다음으로 쿼리 기능에 대해 설명하겠습니다. 주요 프로세스는 아래 그림 3에 표시되어 있습니다:</p>
<p><img src="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_2.png" alt="Image"></p>
<p>이해를 돕기 위해 주요 부분에는 주석이 달려 있습니다.</p>
<pre><code class="hljs language-python">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">custom_query</span>(<span class="hljs-params">self, query_str: <span class="hljs-built_in">str</span></span>) -> Response:
        <span class="hljs-string">"""커스텀 쿼리 실행."""</span>
        <span class="hljs-comment"># Llama2 모델을 사용하여 응답을 가져옵니다.</span>
        response = self.llm(prompt=_format_prompt(query_str), **_GENERATE_KWARGS)
        answer = response[<span class="hljs-string">"choices"</span>][<span class="hljs-number">0</span>][<span class="hljs-string">"text"</span>]
        source_nodes = []

        <span class="hljs-comment"># 검색이 필요한지 여부를 결정합니다.</span>
        <span class="hljs-keyword">if</span> <span class="hljs-string">"[Retrieval]"</span> <span class="hljs-keyword">in</span> answer:
            <span class="hljs-keyword">if</span> self.verbose:
                print_text(<span class="hljs-string">"검색이 필요합니다\n"</span>, color=<span class="hljs-string">"blue"</span>)
            <span class="hljs-comment"># 그림 1의 단계 1, 필요한대로 검색합니다.</span>
            documents = self.retriever.retrieve(query_str)
            <span class="hljs-keyword">if</span> self.verbose:
                print_text(<span class="hljs-string">f"받은 문서: <span class="hljs-subst">{<span class="hljs-built_in">len</span>(documents)}</span>\n"</span>, color=<span class="hljs-string">"blue"</span>)
            paragraphs = [
                _format_prompt(query_str, document.node.text) <span class="hljs-keyword">for</span> document <span class="hljs-keyword">in</span> documents
            ]

            <span class="hljs-keyword">if</span> self.verbose:
                print_text(<span class="hljs-string">"평가 시작\n"</span>, color=<span class="hljs-string">"blue"</span>)

            <span class="hljs-comment"># 그림 1의 단계 2 및 3, 병렬로 생성하고 평가합니다 </span>
            <span class="hljs-comment"># (코드에서 병렬화를 구현하지는 않음)</span>
            critic_output = self._run_critic(paragraphs)

            paragraphs_final_score = critic_output.paragraphs_final_score
            llm_response_per_paragraph = critic_output.llm_response_per_paragraph
            source_nodes = critic_output.source_nodes

            <span class="hljs-keyword">if</span> self.verbose:
                print_text(<span class="hljs-string">"평가 종료\n"</span>, color=<span class="hljs-string">"blue"</span>)

            <span class="hljs-comment"># 가장 높은 점수를 받은 답변을 선택하고 반환합니다.</span>
            best_paragraph_id = <span class="hljs-built_in">max</span>(
                paragraphs_final_score, key=paragraphs_final_score.get
            )
            answer = llm_response_per_paragraph[best_paragraph_id]
            <span class="hljs-keyword">if</span> self.verbose:
                print_text(<span class="hljs-string">f"최적 답변 선택: <span class="hljs-subst">{answer}</span>\n"</span>, color=<span class="hljs-string">"blue"</span>)

        answer = _postprocess_answer(answer)
        <span class="hljs-keyword">if</span> self.verbose:
            print_text(<span class="hljs-string">f"최종 답변: <span class="hljs-subst">{answer}</span>\n"</span>, color=<span class="hljs-string">"green"</span>)
        <span class="hljs-keyword">return</span> Response(response=<span class="hljs-built_in">str</span>(answer), source_nodes=source_nodes)
</code></pre>
<p>위의 코드에서 우리는 그림 1의 모든 세 단계가 표현된 것을 확인할 수 있습니다. 그러나 LlamaIndex의 코드는 병렬 처리를 구현하지 않았습니다. 더 자세한 정보는 관심 있는 독자들이 self._run_critic 함수를 살펴볼 수 있습니다. 해당 함수는 다양한 반사 토큰에 해당하는 점수를 처리합니다.</p>
<h1>Llama2-7B 모델 훈련 방법</h1>
<p>이전에 여러 번 Llama2-7B 모델을 사용해왔으니, 이제 어떻게 얻을 지 알아봅시다.</p>
<h2>훈련 목표</h2>
<p>훈련 과정에서는 평가 모델 C와 생성 모델 M 두 가지 모델이 필요합니다. 평가 모델 C는 모델 M이 필요로 하는 감독 데이터를 생성합니다.</p>
<p>그러나 추론 과정에서는 모델 M만 사용되며 모델 C는 필요하지 않습니다.</p>
<h2>비평가 모델 C</h2>
<p>비평가 모델은 반사 토큰을 생성하는 데 훈련됩니다. 이 모델을 사용하는 목적은 작업 출력 오프라인에 반사 토큰을 삽입하여 훈련 말뭉치를 업데이트하는 것입니다.</p>
<p>각 세그먼트의 반사 토큰을 수동으로 주석 달기는 비용이 많이 듭니다. Self-RAG는 GPT-4를 활용하여 각 반사 토큰에 대해 고유한 지침을 할당하여 서로 다른 정의, 입력 및 출력을 가지고 있기 때문에 효율적으로 데이터 주석 작업을 완료합니다. 예를 들어, [검색] 토큰의 지시는 GPT-4가 외부 문서를 통합하는 것이 결과를 향상시킬지를 평가하도록 요청합니다.</p>
<p>훈련 데이터 D_critic를 얻으면 표준 조건부 언어 모델을 기반으로 훈련 목표를 구성할 수 있습니다.</p>
<p><img src="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_3.png" alt="image"></p>
<p>비평가 모델 C는 어떤 언어 모델로도 초기화할 수 있습니다. 예를 들어 생성자와 동일한 모델로 초기화할 수 있습니다. 예를 들면 Llama2-7B와 같은 모델을 사용할 수 있습니다.</p>
<h2>생성자 모델 M</h2>
<p>Figure 4는 훈련 데이터를 수집하는 구체적인 과정을 보여줍니다. 입력-출력 쌍 (x, y)가 주어지면 self-RAG는 검색 및 비평가 모델을 사용하여 원래의 출력 y를 확장하고 지도 데이터를 생성합니다. y의 각 세그먼트 yt에 대해:</p>
<p>Figure 4의 모든 조건 판단은 비평가 모델 C를 통해 실행됩니다. 획득한 훈련 데이터는 Figure 5에 나타나 있습니다:</p>
<p>훈련 데이터 D_gen을 획득한 후, 다음 토큰 예측 표준 목적 함수를 다음과 같이 구성할 수 있습니다:</p>
<p><img src="/assets/img/2024-05-20-AdvancedRAG08Self-RAG_6.png" alt="image"></p>
<p>M 생성기는 결과뿐만 아니라 반영 토큰도 예측해야 합니다.</p>
<h1>self-RAG에 대한 나의 인사이트와 생각</h1>
<p>일반적으로 self-RAG는 RAG 프로세스를 강화하는 새로운 관점을 제공합니다. 그러나 더 복잡한 훈련 과정이 필요하며 생성 단계 중에 여러 레이블 생성과 판단이 필요하기 때문에 추론 비용이 증가하기 때문에 실시간 성능이 필요한 프로젝트에는 중요한 영향을 줄 수 있습니다.</p>
<p>또한, 이 프레임워크 내에서 최적화할 여지가 많이 있습니다. 더 많은 토론과 혁신을 일으키기 위해 몇 가지 포인트를 공유하겠습니다:</p>
<ul>
<li>반영 토큰을 최적화하는 방법. Self-RAG는 네 가지 반영 토큰을 설계했습니다. [검색] 토큰 외에도 세 가지([IsREL], [IsSUP], [IsUSE])는 특정 유사성이 있습니다. 더 적은 반영 토큰을 사용하거나 다른 의미를 나타내는 반영 토큰을 고려하는 것이 타당한 방향일 수 있습니다.</li>
<li>비평가 모델이 LLM을 사용하는 이유는 무엇인가요? 제 생각에는 [IsUSE]와 같은 토큰이 공통 지식에 많이 의존하기 때문일 수 있습니다. 질의에 대한 답변의 유용성을 판단하는 것은 더 작은 모델이 수행할 수도 있습니다. 그러나 이러한 모델은 일반적인 지식을 부족하게 습득하며 종래의 특정 교육 자료만을 학습합니다. 따라서 비평가 모델로 LLM을 사용하는 것이 합리적일 수 있습니다.</li>
<li>비평가 모델 크기 선택. Self-RAG는 7B 및 13B 모델로 테스트되어 우수한 결과를 얻었습니다. 그러나 만약 더 작은 LLM인 3B로 전환하면 어떤 차이를 관찰할 수 있을까요? 마찬가지로, 더 큰 LLM인 33B로 전환했을 때 얼마나 개선을 기대할 수 있을까요?</li>
<li>인간 피드백을 통한 강화학습(RLHF)을 사용하지 않는 이유는 무엇인가요? 논문에서는 작업 예제를 통해 대상 언어 모델을 학습하는 것을 제안합니다. 이 예제는 비평가 모델에서 오프라인으로 반영 토큰이 추가된 것입니다. 이로 인해 RLHF 대비 훨씬 낮은 교육 비용이 발생합니다. 또한, self-RAG의 반영 토큰은 추론 중 생성을 제어할 수 있게 만들어주며 RLHF는 훈련 중 인간의 선호도 조정에 초점을 두고 있습니다. 그러나 논문에는 RLHF와 관련된 비교 실험 내용이 포함되어 있지 않습니다.</li>
</ul>
<h1>결론</h1>
<p>본문은 직관적인 예시로 시작하여 Self-RAG의 기본적인 과정을 소개하고 코드 설명을 보완하는 내용을 담고 있습니다. 또한 제 생각과 통찰을 공유하였습니다.</p>
<p>RAG 기술에 관심이 있다면, 내 다른 기사들도 살펴보세요.</p>
<p>또한, 최신 AI 관련 콘텐츠는 내 뉴스레터에서 찾을 수 있어요.</p>
<p>마지막으로, 어떠한 오류나 누락이 있거나 궁금한 사항이 있으시면 댓글 섹션에서 자유롭게 토론해 주세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"고급 RAG 08 Self-RAG","description":"","date":"2024-05-20 21:10","slug":"2024-05-20-AdvancedRAG08Self-RAG","content":"\n\n이 기사는 흔한 시나리오로 시작됩니다: 공개 시험을 보는 경우입니다. 일반적으로 두 가지 전략을 사용합니다:\n\n- 방법 1: 익숙한 주제에 대해서는 빠르게 답변하고, 익숙하지 않은 주제에 대해서는 참고서를 열어서 확인하고, 관련 부분을 빠르게 찾아내어 정리하고 요약한 다음, 시험지에 답변합니다.\n- 방법 2: 모든 주제에 대해 책을 참고합니다. 적절한 부분을 찾아내고, 정리하고 요약한 다음, 시험지에 답변합니다.\n\n분명히 방법 1이 선호되는 방법입니다. 방법 2는 시간이 소비될 수 있고, 관련성 없는 정보나 잘못된 정보가 들어올 수 있어 혼란과 실수를 야기할 수 있습니다. 심지어 처음에 이해한 부분에서도 발생할 수 있습니다.\n\n하지만, 방법 2는 고전적인 RAG 프로세스를 보여주며, 방법 1은 자체 RAG 프로세스를 대표합니다. 이에 대해 이 기사에서 더 자세히 다룰 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 개요\n\n그림 1은 RAG 및 Self-RAG의 주요 프로세스를 비교한 것을 보여줍니다:\n\n![그림](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png)\n\nSelf-RAG는 세 단계로 구성되어 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 필요한 경우 검색: 모델이 검색을 요구하는 경우, 예를 들어 \"미국 주가 이름을 어떻게 얻었습니까?\" (그림 1의 오른쪽 상단)와 같은 쿼리가 있을 때, 모델의 출력에는 [검색] 토큰이 포함됩니다. 이는 쿼리와 관련된 내용을 검색해야 함을 나타냅니다. 반면에 \"최고의 여름 휴가에 대해 에세이를 쓰세요\" (그림 1의 오른쪽 아래)와 같이 물어볼 때, 모델은 검색 없이 직접 답변을 생성하도록 선택합니다.\n- 병렬 생성: 모델은 프롬프트와 검색된 콘텐츠를 모두 사용하여 출력을 생성합니다. 이 과정에서 세 가지 유형의 반영 토큰이 검색된 콘텐츠의 관련성을 나타냅니다.\n- 평가 및 선택: 단계 2에서 생성된 콘텐츠가 평가되고, 최상의 세그먼트가 출력으로 선택됩니다.\n\n상기 모델은 특별히 훈련된 모델이라는 것을 유의하십시오. 이 모델의 훈련 과정은 이 기사의 후반부에서 논의될 것입니다.\n\n# 반영 토큰\n\nSelf-RAG 프레임워크의 RAG와 비교했을 때, Self-RAG 프레임워크의 차이는 생성 중 더 정확한 제어를 위해 반영 토큰을 사용한다는 것입니다. 그림 2에서 보여집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_1.png\" /\u003e\n\n본질적으로, self-RAG는 네 가지 명확한 판단을 내립니다:\n\n- [Retrieve]: 리소스 R로부터 정보를 검색할지를 결정하는 의사결정 과정.\n- [IsREL]: 주어진 데이터 d가 문제 x를 해결하는 데 필요한 정보를 포함하고 있는지를 결정하는 관련성 확인.\n- [IsSUP]: 제공된 응답 y의 내용이 데이터 d로부터 지원되는지를 확인하는 검증 과정.\n- [IsUSE]: 문제 x에 대한 응답 y의 유용성을 평가하는 평가 과정. 결과는 1에서 5까지의 점수로, 5는 가장 높은 유용성을 나타냅니다.\n\nRAG에서 검색은 상태에 관계없이 항상 처음에 수행되는 고정된 과정입니다. 반면 self-RAG는 반사 토큰을 도입하여 LLM을 더 적응적이고 지능적으로 만듭니다. LLM이 텍스트를 생성하다가 불확실성이 발생하는 부분에 도달하면 반사 토큰에서 일시 정지하여 신속하고 정확한 검색을 수행한 후 새로 습득한 정보를 사용하여 생성을 재개합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 코드 설명\n\nself-RAG 프로세스를 직관적으로 이해하기 위해 먼저 코드를 살펴보고 모델의 훈련 과정을 설명하겠습니다.\n\nself-RAG는 오픈 소스이며, Langchain과 LlamaIndex에는 각각의 구현이 있습니다. 우리는 설명을 위해 LlamaIndex의 구현을 참조할 것입니다.\n\n## 환경 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 환경을 설정하세요.\n\n```js\n(base) Florian@instance-1:~$ conda create -n llamaindex python=3.11\n\n(base) Florian@instance-1:~$ conda activate llamaindex\n\n\n(llamaindex) Florian@instance-1:~$ pip install llama-index\n\n(llamaindex) Florian@instance-1:~$ pip install huggingface-hub\n\n(llamaindex) Florian@instance-1:~$ huggingface-cli login\n```\n\n설치 후, LlamaIndex의 대응 버전은 다음과 같습니다:\n\n```js\nllama-index                             0.10.20\n\nllama-index-core                        0.10.20.post2\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"여러분의 오픈AI API 키\"\n\nfrom llama_index.core import Document, VectorStoreIndex\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.readers import SimpleDirectoryReader\nfrom pathlib import Path\n\n\n# 옵션: SelfRAGPack 다운로드\n# 첫 실행 시 SelfRAGPack을 다운로드해야 합니다. \n# 다음 실행부터는 이 부분을 주석 처리할 수 있습니다.\nfrom llama_index.core.llama_pack import download_llama_pack\ndownload_llama_pack(\n    \"SelfRAGPack\",\n    \"./self_rag_pack\")\n\nfrom llama_index.packs.self_rag import SelfRAGQueryEngine\n\n# 이전에 다운로드하고 저장한 Llama2 모델이 있는 디렉토리.\ndownload_dir = \"여러분의 다운로드 모델 디렉토리\"\n\n# 테스트 문서 생성\ndocuments = [\n    Document(\n        text=\"남극 얼음 위를 '웨들'이라고 불리는 물개 떼가 지나다녔다. 그들의 턱시도 같은 깃털은 눈 위에서 돋보였다.\"\n    ),\n    Document(\n        text=\"펭귄 중 가장 키가 큰 황제펭귄은 다른 어떤 새보다도 더 깊이 다이빙을 할 수 있어서 500m 이상의 심해까지 다이빙을 합니다.\"\n    ),\n    Document(\n        text=\"펭귄들의 흑백색깔은 위험 방어라는 화장법의 한 종류인 카운터셰이딩입니다. 위에서 보면 펭귄의 검은 등은 바다 심지와 어우러지고, 아래에서는 펭귄의 흰 배는 밝은 표면과 어우러집니다.\"\n    ),\n    Document(\n        text=\"수직 자세이지만, 펭귄은 날지 못하는 조류입니다. 그들의 날개는 지느러미로 진화했기 때문에 수중에서 전문 수영가입니다.\"\n    ),\n    Document(\n        text=\"가장 빠른 펭귄 종류인 젠투 펭귄은 시속 36킬로미터까지 수영할 수 있으며, 수중을 순찰하는 동안 지느러미와 윤곽을 이용해 물을 가르는 식으로 전진합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 집단생활을 하는 조류입니다. 많은 종들이 번식을 위해 수만 마리까지 이를 결성합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 놀랍게도 귀가 우수하며 지저분한 떼 속에서 배우량과 새끼를 식별하는 데 명확한 호출을 의존합니다.\"\n    ),\n    Document(\n        text=\"가장 작은 펭귄 종인 리틀 블루 펭귄은 약 40cm 높이로, 남부 호주와 뉴질랜드 해안가에서 발견됩니다.\"\n    ),\n    Document(\n        text=\"번식 기간 중, 수컷 황제펭귄은 한없이 지속되는 남극 겨울을 버텨내며 몇 달간 급식없이 알을 부화시키는 반면, 암컷은 바다에서 사냥을 합니다.\"\n    ),\n    Document(\n        text=\"펭귄은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 그리고 크릴로 이루어져 있으며 이를 수중 다이빙을 통해 잡습니다.\"\n    ),\n]\n\nindex = VectorStoreIndex.from_documents(documents)\n\n# 간단한 리트리버 설정\nretriever = VectorIndexRetriever(\n    index=index,\n    similarity_top_k=10,\n)\n\n\nmodel_path = Path(download_dir) / \"selfrag_llama2_7b.q4_k_m.gguf\"\nquery_engine = SelfRAGQueryEngine(str(model_path), retriever, verbose=True)\n\n# 리트리벌 예시\nresponse = query_engine.query(\"어떤 장르인가요?\")\n\n# 리트리벌 예시\nresponse = query_engine.query(\"가장 작은 펭귄의 키는 얼마인가요?\")\n```\n\n위의 테스트 코드는 다음 결과를 생성했습니다(대부분의 llama_cpp 디버깅 정보가 제거되었습니다):\n\n```js\nModel metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\nUsing fallback chat format: None\n\nllama_print_timings:        load time =    4887.53 ms\nllama_print_timings:      sample time =      11.29 ms /    22 runs   (    0.51 ms per token,  1947.76 tokens per second)\nllama_print_timings: prompt eval time =    4887.46 ms /    24 tokens (  203.64 ms per token,     4.91 tokens per second)\nllama_print_timings:        eval time =    5883.27 ms /    21 runs   (  280.16 ms per token,     3.57 tokens per second)\nllama_print_timings:       total time =   10901.84 ms /    45 tokens\n최종 답변: '오만과 편견'은 제인 오스틴의 로맨스 소설입니다.\nllama_print_timings:        load time =    4887.53 ms\nllama_print_timings:      sample time =      11.74 ms /    20 runs   (    0.59 ms per token,  1703.29 tokens per second)\nllama_print_timings: prompt eval time =    7473.66 ms /    37 tokens (  201.99 ms per token,     4.95 tokens per second)\nllama_print_timings:        eval time =    5414.34 ms /    19 runs   (  284.96 ms per token,     3.51 tokens per second)\nllama_print_timings:       total time =   13076.88 ms /    56 tokens\n입력: ### 지시사항:\n가장 작은 펭귄은 얼마나 키가 큰가요?\n\n### 응답:\n[검색]\u003c문단\u003e펭귄들은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 크릴로 구성되어 있으며 이를 다이빙으로 잡습니다.\"\u003c/문단\u003e\n예측: [관련]가장 작은 펭귄 종류의 키는 종에 따라 달라질 수 있습니다.[지원되지 않음 / 모순][유틸리티:5]\n점수: 1.4213598342974367\n10/10 단락 완료\n\n평가 종료\n최상의 답변 선정: [관련]가\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테스트 코드를 이해하는 핵심은 SelfRAGQueryEngine 클래스의 구현에 있습니다. 이제 이 클래스를 자세히 살펴보겠습니다.\n\n## 클래스 SelfRAGQueryEngine\n\n먼저 생성자입니다. 주로 llama_cpp를 사용하여 Llama2-7B 모델을 로드하기 위해 사용됩니다.\n\n```python\nclass SelfRAGQueryEngine(CustomQueryEngine):\n    \"\"\"간단한 Self RAG 쿼리 엔진.\"\"\"\n\n    llm: Any = Field(default=None, description=\"llm\")\n    retriever: BaseRetriever = Field(default=None, description=\"retriever\")\n    generate_kwargs: Dict = Field(default=None, description=\"llm generation arguments\")\n    verbose: bool = Field(default=True, description=\"Verbose.\")\n\n    def __init__(\n        self,\n        model_path: str,\n        retriever: BaseRetriever,\n        verbose: bool = False,\n        model_kwargs: Dict = None,\n        generate_kwargs: Dict = None,\n        **kwargs: Any,\n    ) -\u003e None:\n        \"\"\"매개변수 초기화.\"\"\"\n        super().__init__(verbose=verbose, **kwargs)\n        model_kwargs = model_kwargs or _MODEL_KWARGS\n        self.generate_kwargs = generate_kwargs or _GENERATE_KWARGS\n        try:\n            from llama_cpp import Llama\n        except ImportError:\n            raise ImportError(_IMPORT_ERROR_MSG)\n        self.llm = Llama(model_path=model_path, verbose=verbose, **model_kwargs)\n        self.retriever = retriever\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 다음으로 쿼리 기능에 대해 설명하겠습니다. 주요 프로세스는 아래 그림 3에 표시되어 있습니다:\n\n![Image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_2.png)\n\n이해를 돕기 위해 주요 부분에는 주석이 달려 있습니다.\n\n```python\n    def custom_query(self, query_str: str) -\u003e Response:\n        \"\"\"커스텀 쿼리 실행.\"\"\"\n        # Llama2 모델을 사용하여 응답을 가져옵니다.\n        response = self.llm(prompt=_format_prompt(query_str), **_GENERATE_KWARGS)\n        answer = response[\"choices\"][0][\"text\"]\n        source_nodes = []\n\n        # 검색이 필요한지 여부를 결정합니다.\n        if \"[Retrieval]\" in answer:\n            if self.verbose:\n                print_text(\"검색이 필요합니다\\n\", color=\"blue\")\n            # 그림 1의 단계 1, 필요한대로 검색합니다.\n            documents = self.retriever.retrieve(query_str)\n            if self.verbose:\n                print_text(f\"받은 문서: {len(documents)}\\n\", color=\"blue\")\n            paragraphs = [\n                _format_prompt(query_str, document.node.text) for document in documents\n            ]\n\n            if self.verbose:\n                print_text(\"평가 시작\\n\", color=\"blue\")\n\n            # 그림 1의 단계 2 및 3, 병렬로 생성하고 평가합니다 \n            # (코드에서 병렬화를 구현하지는 않음)\n            critic_output = self._run_critic(paragraphs)\n\n            paragraphs_final_score = critic_output.paragraphs_final_score\n            llm_response_per_paragraph = critic_output.llm_response_per_paragraph\n            source_nodes = critic_output.source_nodes\n\n            if self.verbose:\n                print_text(\"평가 종료\\n\", color=\"blue\")\n\n            # 가장 높은 점수를 받은 답변을 선택하고 반환합니다.\n            best_paragraph_id = max(\n                paragraphs_final_score, key=paragraphs_final_score.get\n            )\n            answer = llm_response_per_paragraph[best_paragraph_id]\n            if self.verbose:\n                print_text(f\"최적 답변 선택: {answer}\\n\", color=\"blue\")\n\n        answer = _postprocess_answer(answer)\n        if self.verbose:\n            print_text(f\"최종 답변: {answer}\\n\", color=\"green\")\n        return Response(response=str(answer), source_nodes=source_nodes)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드에서 우리는 그림 1의 모든 세 단계가 표현된 것을 확인할 수 있습니다. 그러나 LlamaIndex의 코드는 병렬 처리를 구현하지 않았습니다. 더 자세한 정보는 관심 있는 독자들이 self._run_critic 함수를 살펴볼 수 있습니다. 해당 함수는 다양한 반사 토큰에 해당하는 점수를 처리합니다.\n\n# Llama2-7B 모델 훈련 방법\n\n이전에 여러 번 Llama2-7B 모델을 사용해왔으니, 이제 어떻게 얻을 지 알아봅시다.\n\n## 훈련 목표\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 과정에서는 평가 모델 C와 생성 모델 M 두 가지 모델이 필요합니다. 평가 모델 C는 모델 M이 필요로 하는 감독 데이터를 생성합니다.\n\n그러나 추론 과정에서는 모델 M만 사용되며 모델 C는 필요하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 비평가 모델 C\n\n비평가 모델은 반사 토큰을 생성하는 데 훈련됩니다. 이 모델을 사용하는 목적은 작업 출력 오프라인에 반사 토큰을 삽입하여 훈련 말뭉치를 업데이트하는 것입니다.\n\n각 세그먼트의 반사 토큰을 수동으로 주석 달기는 비용이 많이 듭니다. Self-RAG는 GPT-4를 활용하여 각 반사 토큰에 대해 고유한 지침을 할당하여 서로 다른 정의, 입력 및 출력을 가지고 있기 때문에 효율적으로 데이터 주석 작업을 완료합니다. 예를 들어, [검색] 토큰의 지시는 GPT-4가 외부 문서를 통합하는 것이 결과를 향상시킬지를 평가하도록 요청합니다.\n\n훈련 데이터 D_critic를 얻으면 표준 조건부 언어 모델을 기반으로 훈련 목표를 구성할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_3.png) \n\n비평가 모델 C는 어떤 언어 모델로도 초기화할 수 있습니다. 예를 들어 생성자와 동일한 모델로 초기화할 수 있습니다. 예를 들면 Llama2-7B와 같은 모델을 사용할 수 있습니다.\n\n## 생성자 모델 M\n\nFigure 4는 훈련 데이터를 수집하는 구체적인 과정을 보여줍니다. 입력-출력 쌍 (x, y)가 주어지면 self-RAG는 검색 및 비평가 모델을 사용하여 원래의 출력 y를 확장하고 지도 데이터를 생성합니다. y의 각 세그먼트 yt에 대해:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_4.png\" /\u003e\n\nFigure 4의 모든 조건 판단은 비평가 모델 C를 통해 실행됩니다. 획득한 훈련 데이터는 Figure 5에 나타나 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_5.png\" /\u003e\n\n훈련 데이터 D_gen을 획득한 후, 다음 토큰 예측 표준 목적 함수를 다음과 같이 구성할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-20-AdvancedRAG08Self-RAG_6.png)\n\nM 생성기는 결과뿐만 아니라 반영 토큰도 예측해야 합니다.\n\n# self-RAG에 대한 나의 인사이트와 생각\n\n일반적으로 self-RAG는 RAG 프로세스를 강화하는 새로운 관점을 제공합니다. 그러나 더 복잡한 훈련 과정이 필요하며 생성 단계 중에 여러 레이블 생성과 판단이 필요하기 때문에 추론 비용이 증가하기 때문에 실시간 성능이 필요한 프로젝트에는 중요한 영향을 줄 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, 이 프레임워크 내에서 최적화할 여지가 많이 있습니다. 더 많은 토론과 혁신을 일으키기 위해 몇 가지 포인트를 공유하겠습니다:\n\n- 반영 토큰을 최적화하는 방법. Self-RAG는 네 가지 반영 토큰을 설계했습니다. [검색] 토큰 외에도 세 가지([IsREL], [IsSUP], [IsUSE])는 특정 유사성이 있습니다. 더 적은 반영 토큰을 사용하거나 다른 의미를 나타내는 반영 토큰을 고려하는 것이 타당한 방향일 수 있습니다.\n- 비평가 모델이 LLM을 사용하는 이유는 무엇인가요? 제 생각에는 [IsUSE]와 같은 토큰이 공통 지식에 많이 의존하기 때문일 수 있습니다. 질의에 대한 답변의 유용성을 판단하는 것은 더 작은 모델이 수행할 수도 있습니다. 그러나 이러한 모델은 일반적인 지식을 부족하게 습득하며 종래의 특정 교육 자료만을 학습합니다. 따라서 비평가 모델로 LLM을 사용하는 것이 합리적일 수 있습니다.\n- 비평가 모델 크기 선택. Self-RAG는 7B 및 13B 모델로 테스트되어 우수한 결과를 얻었습니다. 그러나 만약 더 작은 LLM인 3B로 전환하면 어떤 차이를 관찰할 수 있을까요? 마찬가지로, 더 큰 LLM인 33B로 전환했을 때 얼마나 개선을 기대할 수 있을까요?\n- 인간 피드백을 통한 강화학습(RLHF)을 사용하지 않는 이유는 무엇인가요? 논문에서는 작업 예제를 통해 대상 언어 모델을 학습하는 것을 제안합니다. 이 예제는 비평가 모델에서 오프라인으로 반영 토큰이 추가된 것입니다. 이로 인해 RLHF 대비 훨씬 낮은 교육 비용이 발생합니다. 또한, self-RAG의 반영 토큰은 추론 중 생성을 제어할 수 있게 만들어주며 RLHF는 훈련 중 인간의 선호도 조정에 초점을 두고 있습니다. 그러나 논문에는 RLHF와 관련된 비교 실험 내용이 포함되어 있지 않습니다.\n\n# 결론\n\n본문은 직관적인 예시로 시작하여 Self-RAG의 기본적인 과정을 소개하고 코드 설명을 보완하는 내용을 담고 있습니다. 또한 제 생각과 통찰을 공유하였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 기술에 관심이 있다면, 내 다른 기사들도 살펴보세요.\n\n또한, 최신 AI 관련 콘텐츠는 내 뉴스레터에서 찾을 수 있어요.\n\n마지막으로, 어떠한 오류나 누락이 있거나 궁금한 사항이 있으시면 댓글 섹션에서 자유롭게 토론해 주세요.","ogImage":{"url":"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png"},"coverImage":"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png","tag":["Tech"],"readingTime":13},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e이 기사는 흔한 시나리오로 시작됩니다: 공개 시험을 보는 경우입니다. 일반적으로 두 가지 전략을 사용합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e방법 1: 익숙한 주제에 대해서는 빠르게 답변하고, 익숙하지 않은 주제에 대해서는 참고서를 열어서 확인하고, 관련 부분을 빠르게 찾아내어 정리하고 요약한 다음, 시험지에 답변합니다.\u003c/li\u003e\n\u003cli\u003e방법 2: 모든 주제에 대해 책을 참고합니다. 적절한 부분을 찾아내고, 정리하고 요약한 다음, 시험지에 답변합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e분명히 방법 1이 선호되는 방법입니다. 방법 2는 시간이 소비될 수 있고, 관련성 없는 정보나 잘못된 정보가 들어올 수 있어 혼란과 실수를 야기할 수 있습니다. 심지어 처음에 이해한 부분에서도 발생할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e하지만, 방법 2는 고전적인 RAG 프로세스를 보여주며, 방법 1은 자체 RAG 프로세스를 대표합니다. 이에 대해 이 기사에서 더 자세히 다룰 것입니다.\u003c/p\u003e\n\u003ch1\u003e개요\u003c/h1\u003e\n\u003cp\u003e그림 1은 RAG 및 Self-RAG의 주요 프로세스를 비교한 것을 보여줍니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_0.png\" alt=\"그림\"\u003e\u003c/p\u003e\n\u003cp\u003eSelf-RAG는 세 단계로 구성되어 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e필요한 경우 검색: 모델이 검색을 요구하는 경우, 예를 들어 \"미국 주가 이름을 어떻게 얻었습니까?\" (그림 1의 오른쪽 상단)와 같은 쿼리가 있을 때, 모델의 출력에는 [검색] 토큰이 포함됩니다. 이는 쿼리와 관련된 내용을 검색해야 함을 나타냅니다. 반면에 \"최고의 여름 휴가에 대해 에세이를 쓰세요\" (그림 1의 오른쪽 아래)와 같이 물어볼 때, 모델은 검색 없이 직접 답변을 생성하도록 선택합니다.\u003c/li\u003e\n\u003cli\u003e병렬 생성: 모델은 프롬프트와 검색된 콘텐츠를 모두 사용하여 출력을 생성합니다. 이 과정에서 세 가지 유형의 반영 토큰이 검색된 콘텐츠의 관련성을 나타냅니다.\u003c/li\u003e\n\u003cli\u003e평가 및 선택: 단계 2에서 생성된 콘텐츠가 평가되고, 최상의 세그먼트가 출력으로 선택됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e상기 모델은 특별히 훈련된 모델이라는 것을 유의하십시오. 이 모델의 훈련 과정은 이 기사의 후반부에서 논의될 것입니다.\u003c/p\u003e\n\u003ch1\u003e반영 토큰\u003c/h1\u003e\n\u003cp\u003eSelf-RAG 프레임워크의 RAG와 비교했을 때, Self-RAG 프레임워크의 차이는 생성 중 더 정확한 제어를 위해 반영 토큰을 사용한다는 것입니다. 그림 2에서 보여집니다.\u003c/p\u003e\n\u003cp\u003e본질적으로, self-RAG는 네 가지 명확한 판단을 내립니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e[Retrieve]: 리소스 R로부터 정보를 검색할지를 결정하는 의사결정 과정.\u003c/li\u003e\n\u003cli\u003e[IsREL]: 주어진 데이터 d가 문제 x를 해결하는 데 필요한 정보를 포함하고 있는지를 결정하는 관련성 확인.\u003c/li\u003e\n\u003cli\u003e[IsSUP]: 제공된 응답 y의 내용이 데이터 d로부터 지원되는지를 확인하는 검증 과정.\u003c/li\u003e\n\u003cli\u003e[IsUSE]: 문제 x에 대한 응답 y의 유용성을 평가하는 평가 과정. 결과는 1에서 5까지의 점수로, 5는 가장 높은 유용성을 나타냅니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eRAG에서 검색은 상태에 관계없이 항상 처음에 수행되는 고정된 과정입니다. 반면 self-RAG는 반사 토큰을 도입하여 LLM을 더 적응적이고 지능적으로 만듭니다. LLM이 텍스트를 생성하다가 불확실성이 발생하는 부분에 도달하면 반사 토큰에서 일시 정지하여 신속하고 정확한 검색을 수행한 후 새로 습득한 정보를 사용하여 생성을 재개합니다.\u003c/p\u003e\n\u003ch1\u003e코드 설명\u003c/h1\u003e\n\u003cp\u003eself-RAG 프로세스를 직관적으로 이해하기 위해 먼저 코드를 살펴보고 모델의 훈련 과정을 설명하겠습니다.\u003c/p\u003e\n\u003cp\u003eself-RAG는 오픈 소스이며, Langchain과 LlamaIndex에는 각각의 구현이 있습니다. 우리는 설명을 위해 LlamaIndex의 구현을 참조할 것입니다.\u003c/p\u003e\n\u003ch2\u003e환경 설정\u003c/h2\u003e\n\u003cp\u003e먼저, 환경을 설정하세요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e(base) \u003cspan class=\"hljs-title class_\"\u003eFlorian\u003c/span\u003e@instance-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e:~$ conda create -n llamaindex python=\u003cspan class=\"hljs-number\"\u003e3.11\u003c/span\u003e\n\n(base) \u003cspan class=\"hljs-title class_\"\u003eFlorian\u003c/span\u003e@instance-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e:~$ conda activate llamaindex\n\n\n(llamaindex) \u003cspan class=\"hljs-title class_\"\u003eFlorian\u003c/span\u003e@instance-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e:~$ pip install llama-index\n\n(llamaindex) \u003cspan class=\"hljs-title class_\"\u003eFlorian\u003c/span\u003e@instance-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e:~$ pip install huggingface-hub\n\n(llamaindex) \u003cspan class=\"hljs-title class_\"\u003eFlorian\u003c/span\u003e@instance-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e:~$ huggingface-cli login\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e설치 후, LlamaIndex의 대응 버전은 다음과 같습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ellama-index                             \u003cspan class=\"hljs-number\"\u003e0.10\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.20\u003c/span\u003e\n\nllama-index-core                        \u003cspan class=\"hljs-number\"\u003e0.10\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.20\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003epost2\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\nos.\u003cspan class=\"hljs-property\"\u003eenviron\u003c/span\u003e[\u003cspan class=\"hljs-string\"\u003e\"OPENAI_API_KEY\"\u003c/span\u003e] = \u003cspan class=\"hljs-string\"\u003e\"여러분의 오픈AI API 키\"\u003c/span\u003e\n\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.\u003cspan class=\"hljs-property\"\u003ecore\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e, \u003cspan class=\"hljs-title class_\"\u003eVectorStoreIndex\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.\u003cspan class=\"hljs-property\"\u003ecore\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eretrievers\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eVectorIndexRetriever\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.\u003cspan class=\"hljs-property\"\u003ecore\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ereaders\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSimpleDirectoryReader\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pathlib \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003ePath\u003c/span\u003e\n\n\n# 옵션: \u003cspan class=\"hljs-title class_\"\u003eSelfRAGPack\u003c/span\u003e 다운로드\n# 첫 실행 시 \u003cspan class=\"hljs-title class_\"\u003eSelfRAGPack\u003c/span\u003e을 다운로드해야 합니다. \n# 다음 실행부터는 이 부분을 주석 처리할 수 있습니다.\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.\u003cspan class=\"hljs-property\"\u003ecore\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ellama_pack\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e download_llama_pack\n\u003cspan class=\"hljs-title function_\"\u003edownload_llama_pack\u003c/span\u003e(\n    \u003cspan class=\"hljs-string\"\u003e\"SelfRAGPack\"\u003c/span\u003e,\n    \u003cspan class=\"hljs-string\"\u003e\"./self_rag_pack\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.\u003cspan class=\"hljs-property\"\u003epacks\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eself_rag\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSelfRAGQueryEngine\u003c/span\u003e\n\n# 이전에 다운로드하고 저장한 \u003cspan class=\"hljs-title class_\"\u003eLlama2\u003c/span\u003e 모델이 있는 디렉토리.\ndownload_dir = \u003cspan class=\"hljs-string\"\u003e\"여러분의 다운로드 모델 디렉토리\"\u003c/span\u003e\n\n# 테스트 문서 생성\ndocuments = [\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"남극 얼음 위를 '웨들'이라고 불리는 물개 떼가 지나다녔다. 그들의 턱시도 같은 깃털은 눈 위에서 돋보였다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"펭귄 중 가장 키가 큰 황제펭귄은 다른 어떤 새보다도 더 깊이 다이빙을 할 수 있어서 500m 이상의 심해까지 다이빙을 합니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"펭귄들의 흑백색깔은 위험 방어라는 화장법의 한 종류인 카운터셰이딩입니다. 위에서 보면 펭귄의 검은 등은 바다 심지와 어우러지고, 아래에서는 펭귄의 흰 배는 밝은 표면과 어우러집니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"수직 자세이지만, 펭귄은 날지 못하는 조류입니다. 그들의 날개는 지느러미로 진화했기 때문에 수중에서 전문 수영가입니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"가장 빠른 펭귄 종류인 젠투 펭귄은 시속 36킬로미터까지 수영할 수 있으며, 수중을 순찰하는 동안 지느러미와 윤곽을 이용해 물을 가르는 식으로 전진합니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"펭귄은 집단생활을 하는 조류입니다. 많은 종들이 번식을 위해 수만 마리까지 이를 결성합니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"펭귄은 놀랍게도 귀가 우수하며 지저분한 떼 속에서 배우량과 새끼를 식별하는 데 명확한 호출을 의존합니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"가장 작은 펭귄 종인 리틀 블루 펭귄은 약 40cm 높이로, 남부 호주와 뉴질랜드 해안가에서 발견됩니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"번식 기간 중, 수컷 황제펭귄은 한없이 지속되는 남극 겨울을 버텨내며 몇 달간 급식없이 알을 부화시키는 반면, 암컷은 바다에서 사냥을 합니다.\"\u003c/span\u003e\n    ),\n    \u003cspan class=\"hljs-title class_\"\u003eDocument\u003c/span\u003e(\n        text=\u003cspan class=\"hljs-string\"\u003e\"펭귄은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 그리고 크릴로 이루어져 있으며 이를 수중 다이빙을 통해 잡습니다.\"\u003c/span\u003e\n    ),\n]\n\nindex = \u003cspan class=\"hljs-title class_\"\u003eVectorStoreIndex\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_documents\u003c/span\u003e(documents)\n\n# 간단한 리트리버 설정\nretriever = \u003cspan class=\"hljs-title class_\"\u003eVectorIndexRetriever\u003c/span\u003e(\n    index=index,\n    similarity_top_k=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e,\n)\n\n\nmodel_path = \u003cspan class=\"hljs-title class_\"\u003ePath\u003c/span\u003e(download_dir) / \u003cspan class=\"hljs-string\"\u003e\"selfrag_llama2_7b.q4_k_m.gguf\"\u003c/span\u003e\nquery_engine = \u003cspan class=\"hljs-title class_\"\u003eSelfRAGQueryEngine\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003estr\u003c/span\u003e(model_path), retriever, verbose=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\n\n# 리트리벌 예시\nresponse = query_engine.\u003cspan class=\"hljs-title function_\"\u003equery\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"어떤 장르인가요?\"\u003c/span\u003e)\n\n# 리트리벌 예시\nresponse = query_engine.\u003cspan class=\"hljs-title function_\"\u003equery\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"가장 작은 펭귄의 키는 얼마인가요?\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e위의 테스트 코드는 다음 결과를 생성했습니다(대부분의 llama_cpp 디버깅 정보가 제거되었습니다):\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-title class_\"\u003eModel\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003emetadata\u003c/span\u003e: {\u003cspan class=\"hljs-string\"\u003e'tokenizer.ggml.add_eos_token'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'false'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'tokenizer.ggml.eos_token_id'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'2'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'general.architecture'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'llama'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.rope.freq_base'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'10000.000000'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.context_length'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'4096'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'general.name'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'LLaMA v2'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'tokenizer.ggml.add_bos_token'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'true'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.embedding_length'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'4096'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.feed_forward_length'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'11008'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.attention.layer_norm_rms_epsilon'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'0.000010'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.rope.dimension_count'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'128'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'tokenizer.ggml.bos_token_id'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'1'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.attention.head_count'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'32'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.block_count'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'32'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'llama.attention.head_count_kv'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'32'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'general.quantization_version'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'2'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'tokenizer.ggml.model'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'llama'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'general.file_type'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'15'\u003c/span\u003e}\n\u003cspan class=\"hljs-title class_\"\u003eUsing\u003c/span\u003e fallback chat \u003cspan class=\"hljs-attr\"\u003eformat\u003c/span\u003e: \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e\n\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:        load time =    \u003cspan class=\"hljs-number\"\u003e4887.53\u003c/span\u003e ms\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:      sample time =      \u003cspan class=\"hljs-number\"\u003e11.29\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e22\u003c/span\u003e runs   (    \u003cspan class=\"hljs-number\"\u003e0.51\u003c/span\u003e ms per token,  \u003cspan class=\"hljs-number\"\u003e1947.76\u003c/span\u003e tokens per second)\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e: prompt \u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e time =    \u003cspan class=\"hljs-number\"\u003e4887.46\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e24\u003c/span\u003e tokens (  \u003cspan class=\"hljs-number\"\u003e203.64\u003c/span\u003e ms per token,     \u003cspan class=\"hljs-number\"\u003e4.91\u003c/span\u003e tokens per second)\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:        \u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e time =    \u003cspan class=\"hljs-number\"\u003e5883.27\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e21\u003c/span\u003e runs   (  \u003cspan class=\"hljs-number\"\u003e280.16\u003c/span\u003e ms per token,     \u003cspan class=\"hljs-number\"\u003e3.57\u003c/span\u003e tokens per second)\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:       total time =   \u003cspan class=\"hljs-number\"\u003e10901.84\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e45\u003c/span\u003e tokens\n최종 답변: \u003cspan class=\"hljs-string\"\u003e'오만과 편견'\u003c/span\u003e은 제인 오스틴의 로맨스 소설입니다.\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:        load time =    \u003cspan class=\"hljs-number\"\u003e4887.53\u003c/span\u003e ms\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:      sample time =      \u003cspan class=\"hljs-number\"\u003e11.74\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e runs   (    \u003cspan class=\"hljs-number\"\u003e0.59\u003c/span\u003e ms per token,  \u003cspan class=\"hljs-number\"\u003e1703.29\u003c/span\u003e tokens per second)\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e: prompt \u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e time =    \u003cspan class=\"hljs-number\"\u003e7473.66\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e37\u003c/span\u003e tokens (  \u003cspan class=\"hljs-number\"\u003e201.99\u003c/span\u003e ms per token,     \u003cspan class=\"hljs-number\"\u003e4.95\u003c/span\u003e tokens per second)\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:        \u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e time =    \u003cspan class=\"hljs-number\"\u003e5414.34\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e19\u003c/span\u003e runs   (  \u003cspan class=\"hljs-number\"\u003e284.96\u003c/span\u003e ms per token,     \u003cspan class=\"hljs-number\"\u003e3.51\u003c/span\u003e tokens per second)\n\u003cspan class=\"hljs-attr\"\u003ellama_print_timings\u003c/span\u003e:       total time =   \u003cspan class=\"hljs-number\"\u003e13076.88\u003c/span\u003e ms /    \u003cspan class=\"hljs-number\"\u003e56\u003c/span\u003e tokens\n입력: ### 지시사항:\n가장 작은 펭귄은 얼마나 키가 큰가요?\n\n### 응답:\n[검색]\u0026#x3C;문단\u003e펭귄들은 다양한 해산물을 섭취합니다. 그들의 식단은 주로 생선, 오징어, 크릴로 구성되어 있으며 이를 다이빙으로 잡습니다.\u003cspan class=\"hljs-string\"\u003e\"\u0026#x3C;/문단\u003e\n예측: [관련]가장 작은 펭귄 종류의 키는 종에 따라 달라질 수 있습니다.[지원되지 않음 / 모순][유틸리티:5]\n점수: 1.4213598342974367\n10/10 단락 완료\n\n평가 종료\n최상의 답변 선정: [관련]가\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e테스트 코드를 이해하는 핵심은 SelfRAGQueryEngine 클래스의 구현에 있습니다. 이제 이 클래스를 자세히 살펴보겠습니다.\u003c/p\u003e\n\u003ch2\u003e클래스 SelfRAGQueryEngine\u003c/h2\u003e\n\u003cp\u003e먼저 생성자입니다. 주로 llama_cpp를 사용하여 Llama2-7B 모델을 로드하기 위해 사용됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSelfRAGQueryEngine\u003c/span\u003e(\u003cspan class=\"hljs-title class_ inherited__\"\u003eCustomQueryEngine\u003c/span\u003e):\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"간단한 Self RAG 쿼리 엔진.\"\"\"\u003c/span\u003e\n\n    llm: \u003cspan class=\"hljs-type\"\u003eAny\u003c/span\u003e = Field(default=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e, description=\u003cspan class=\"hljs-string\"\u003e\"llm\"\u003c/span\u003e)\n    retriever: BaseRetriever = Field(default=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e, description=\u003cspan class=\"hljs-string\"\u003e\"retriever\"\u003c/span\u003e)\n    generate_kwargs: \u003cspan class=\"hljs-type\"\u003eDict\u003c/span\u003e = Field(default=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e, description=\u003cspan class=\"hljs-string\"\u003e\"llm generation arguments\"\u003c/span\u003e)\n    verbose: \u003cspan class=\"hljs-built_in\"\u003ebool\u003c/span\u003e = Field(default=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e, description=\u003cspan class=\"hljs-string\"\u003e\"Verbose.\"\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003e\n        self,\n        model_path: \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e,\n        retriever: BaseRetriever,\n        verbose: \u003cspan class=\"hljs-built_in\"\u003ebool\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003eFalse\u003c/span\u003e,\n        model_kwargs: \u003cspan class=\"hljs-type\"\u003eDict\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e,\n        generate_kwargs: \u003cspan class=\"hljs-type\"\u003eDict\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e,\n        **kwargs: \u003cspan class=\"hljs-type\"\u003eAny\u003c/span\u003e,\n    \u003c/span\u003e) -\u003e \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e:\n        \u003cspan class=\"hljs-string\"\u003e\"\"\"매개변수 초기화.\"\"\"\u003c/span\u003e\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e().__init__(verbose=verbose, **kwargs)\n        model_kwargs = model_kwargs \u003cspan class=\"hljs-keyword\"\u003eor\u003c/span\u003e _MODEL_KWARGS\n        self.generate_kwargs = generate_kwargs \u003cspan class=\"hljs-keyword\"\u003eor\u003c/span\u003e _GENERATE_KWARGS\n        \u003cspan class=\"hljs-keyword\"\u003etry\u003c/span\u003e:\n            \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_cpp \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Llama\n        \u003cspan class=\"hljs-keyword\"\u003eexcept\u003c/span\u003e ImportError:\n            \u003cspan class=\"hljs-keyword\"\u003eraise\u003c/span\u003e ImportError(_IMPORT_ERROR_MSG)\n        self.llm = Llama(model_path=model_path, verbose=verbose, **model_kwargs)\n        self.retriever = retriever\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그 다음으로 쿼리 기능에 대해 설명하겠습니다. 주요 프로세스는 아래 그림 3에 표시되어 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_2.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e이해를 돕기 위해 주요 부분에는 주석이 달려 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecustom_query\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, query_str: \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e\u003c/span\u003e) -\u003e Response:\n        \u003cspan class=\"hljs-string\"\u003e\"\"\"커스텀 쿼리 실행.\"\"\"\u003c/span\u003e\n        \u003cspan class=\"hljs-comment\"\u003e# Llama2 모델을 사용하여 응답을 가져옵니다.\u003c/span\u003e\n        response = self.llm(prompt=_format_prompt(query_str), **_GENERATE_KWARGS)\n        answer = response[\u003cspan class=\"hljs-string\"\u003e\"choices\"\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e\"text\"\u003c/span\u003e]\n        source_nodes = []\n\n        \u003cspan class=\"hljs-comment\"\u003e# 검색이 필요한지 여부를 결정합니다.\u003c/span\u003e\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"[Retrieval]\"\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e answer:\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self.verbose:\n                print_text(\u003cspan class=\"hljs-string\"\u003e\"검색이 필요합니다\\n\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n            \u003cspan class=\"hljs-comment\"\u003e# 그림 1의 단계 1, 필요한대로 검색합니다.\u003c/span\u003e\n            documents = self.retriever.retrieve(query_str)\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self.verbose:\n                print_text(\u003cspan class=\"hljs-string\"\u003ef\"받은 문서: \u003cspan class=\"hljs-subst\"\u003e{\u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(documents)}\u003c/span\u003e\\n\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n            paragraphs = [\n                _format_prompt(query_str, document.node.text) \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e document \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e documents\n            ]\n\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self.verbose:\n                print_text(\u003cspan class=\"hljs-string\"\u003e\"평가 시작\\n\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n\n            \u003cspan class=\"hljs-comment\"\u003e# 그림 1의 단계 2 및 3, 병렬로 생성하고 평가합니다 \u003c/span\u003e\n            \u003cspan class=\"hljs-comment\"\u003e# (코드에서 병렬화를 구현하지는 않음)\u003c/span\u003e\n            critic_output = self._run_critic(paragraphs)\n\n            paragraphs_final_score = critic_output.paragraphs_final_score\n            llm_response_per_paragraph = critic_output.llm_response_per_paragraph\n            source_nodes = critic_output.source_nodes\n\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self.verbose:\n                print_text(\u003cspan class=\"hljs-string\"\u003e\"평가 종료\\n\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n\n            \u003cspan class=\"hljs-comment\"\u003e# 가장 높은 점수를 받은 답변을 선택하고 반환합니다.\u003c/span\u003e\n            best_paragraph_id = \u003cspan class=\"hljs-built_in\"\u003emax\u003c/span\u003e(\n                paragraphs_final_score, key=paragraphs_final_score.get\n            )\n            answer = llm_response_per_paragraph[best_paragraph_id]\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self.verbose:\n                print_text(\u003cspan class=\"hljs-string\"\u003ef\"최적 답변 선택: \u003cspan class=\"hljs-subst\"\u003e{answer}\u003c/span\u003e\\n\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n\n        answer = _postprocess_answer(answer)\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self.verbose:\n            print_text(\u003cspan class=\"hljs-string\"\u003ef\"최종 답변: \u003cspan class=\"hljs-subst\"\u003e{answer}\u003c/span\u003e\\n\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"green\"\u003c/span\u003e)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e Response(response=\u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e(answer), source_nodes=source_nodes)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e위의 코드에서 우리는 그림 1의 모든 세 단계가 표현된 것을 확인할 수 있습니다. 그러나 LlamaIndex의 코드는 병렬 처리를 구현하지 않았습니다. 더 자세한 정보는 관심 있는 독자들이 self._run_critic 함수를 살펴볼 수 있습니다. 해당 함수는 다양한 반사 토큰에 해당하는 점수를 처리합니다.\u003c/p\u003e\n\u003ch1\u003eLlama2-7B 모델 훈련 방법\u003c/h1\u003e\n\u003cp\u003e이전에 여러 번 Llama2-7B 모델을 사용해왔으니, 이제 어떻게 얻을 지 알아봅시다.\u003c/p\u003e\n\u003ch2\u003e훈련 목표\u003c/h2\u003e\n\u003cp\u003e훈련 과정에서는 평가 모델 C와 생성 모델 M 두 가지 모델이 필요합니다. 평가 모델 C는 모델 M이 필요로 하는 감독 데이터를 생성합니다.\u003c/p\u003e\n\u003cp\u003e그러나 추론 과정에서는 모델 M만 사용되며 모델 C는 필요하지 않습니다.\u003c/p\u003e\n\u003ch2\u003e비평가 모델 C\u003c/h2\u003e\n\u003cp\u003e비평가 모델은 반사 토큰을 생성하는 데 훈련됩니다. 이 모델을 사용하는 목적은 작업 출력 오프라인에 반사 토큰을 삽입하여 훈련 말뭉치를 업데이트하는 것입니다.\u003c/p\u003e\n\u003cp\u003e각 세그먼트의 반사 토큰을 수동으로 주석 달기는 비용이 많이 듭니다. Self-RAG는 GPT-4를 활용하여 각 반사 토큰에 대해 고유한 지침을 할당하여 서로 다른 정의, 입력 및 출력을 가지고 있기 때문에 효율적으로 데이터 주석 작업을 완료합니다. 예를 들어, [검색] 토큰의 지시는 GPT-4가 외부 문서를 통합하는 것이 결과를 향상시킬지를 평가하도록 요청합니다.\u003c/p\u003e\n\u003cp\u003e훈련 데이터 D_critic를 얻으면 표준 조건부 언어 모델을 기반으로 훈련 목표를 구성할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e비평가 모델 C는 어떤 언어 모델로도 초기화할 수 있습니다. 예를 들어 생성자와 동일한 모델로 초기화할 수 있습니다. 예를 들면 Llama2-7B와 같은 모델을 사용할 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e생성자 모델 M\u003c/h2\u003e\n\u003cp\u003eFigure 4는 훈련 데이터를 수집하는 구체적인 과정을 보여줍니다. 입력-출력 쌍 (x, y)가 주어지면 self-RAG는 검색 및 비평가 모델을 사용하여 원래의 출력 y를 확장하고 지도 데이터를 생성합니다. y의 각 세그먼트 yt에 대해:\u003c/p\u003e\n\u003cp\u003eFigure 4의 모든 조건 판단은 비평가 모델 C를 통해 실행됩니다. 획득한 훈련 데이터는 Figure 5에 나타나 있습니다:\u003c/p\u003e\n\u003cp\u003e훈련 데이터 D_gen을 획득한 후, 다음 토큰 예측 표준 목적 함수를 다음과 같이 구성할 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-20-AdvancedRAG08Self-RAG_6.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eM 생성기는 결과뿐만 아니라 반영 토큰도 예측해야 합니다.\u003c/p\u003e\n\u003ch1\u003eself-RAG에 대한 나의 인사이트와 생각\u003c/h1\u003e\n\u003cp\u003e일반적으로 self-RAG는 RAG 프로세스를 강화하는 새로운 관점을 제공합니다. 그러나 더 복잡한 훈련 과정이 필요하며 생성 단계 중에 여러 레이블 생성과 판단이 필요하기 때문에 추론 비용이 증가하기 때문에 실시간 성능이 필요한 프로젝트에는 중요한 영향을 줄 수 있습니다.\u003c/p\u003e\n\u003cp\u003e또한, 이 프레임워크 내에서 최적화할 여지가 많이 있습니다. 더 많은 토론과 혁신을 일으키기 위해 몇 가지 포인트를 공유하겠습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e반영 토큰을 최적화하는 방법. Self-RAG는 네 가지 반영 토큰을 설계했습니다. [검색] 토큰 외에도 세 가지([IsREL], [IsSUP], [IsUSE])는 특정 유사성이 있습니다. 더 적은 반영 토큰을 사용하거나 다른 의미를 나타내는 반영 토큰을 고려하는 것이 타당한 방향일 수 있습니다.\u003c/li\u003e\n\u003cli\u003e비평가 모델이 LLM을 사용하는 이유는 무엇인가요? 제 생각에는 [IsUSE]와 같은 토큰이 공통 지식에 많이 의존하기 때문일 수 있습니다. 질의에 대한 답변의 유용성을 판단하는 것은 더 작은 모델이 수행할 수도 있습니다. 그러나 이러한 모델은 일반적인 지식을 부족하게 습득하며 종래의 특정 교육 자료만을 학습합니다. 따라서 비평가 모델로 LLM을 사용하는 것이 합리적일 수 있습니다.\u003c/li\u003e\n\u003cli\u003e비평가 모델 크기 선택. Self-RAG는 7B 및 13B 모델로 테스트되어 우수한 결과를 얻었습니다. 그러나 만약 더 작은 LLM인 3B로 전환하면 어떤 차이를 관찰할 수 있을까요? 마찬가지로, 더 큰 LLM인 33B로 전환했을 때 얼마나 개선을 기대할 수 있을까요?\u003c/li\u003e\n\u003cli\u003e인간 피드백을 통한 강화학습(RLHF)을 사용하지 않는 이유는 무엇인가요? 논문에서는 작업 예제를 통해 대상 언어 모델을 학습하는 것을 제안합니다. 이 예제는 비평가 모델에서 오프라인으로 반영 토큰이 추가된 것입니다. 이로 인해 RLHF 대비 훨씬 낮은 교육 비용이 발생합니다. 또한, self-RAG의 반영 토큰은 추론 중 생성을 제어할 수 있게 만들어주며 RLHF는 훈련 중 인간의 선호도 조정에 초점을 두고 있습니다. 그러나 논문에는 RLHF와 관련된 비교 실험 내용이 포함되어 있지 않습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e본문은 직관적인 예시로 시작하여 Self-RAG의 기본적인 과정을 소개하고 코드 설명을 보완하는 내용을 담고 있습니다. 또한 제 생각과 통찰을 공유하였습니다.\u003c/p\u003e\n\u003cp\u003eRAG 기술에 관심이 있다면, 내 다른 기사들도 살펴보세요.\u003c/p\u003e\n\u003cp\u003e또한, 최신 AI 관련 콘텐츠는 내 뉴스레터에서 찾을 수 있어요.\u003c/p\u003e\n\u003cp\u003e마지막으로, 어떠한 오류나 누락이 있거나 궁금한 사항이 있으시면 댓글 섹션에서 자유롭게 토론해 주세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-20-AdvancedRAG08Self-RAG"},"buildId":"o1YmnmSuZvAX2O4TI9r41","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>