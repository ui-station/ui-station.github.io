<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation" data-gatsby-head="true"/><meta name="twitter:title" content="오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-20 20:36" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-561ae49ab5aab7f5.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_buildManifest.js" defer=""></script><script src="/_next/static/R1x9p1CQYDDJESXyLXKOK/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 20, 2024</span><span class="posts_reading_time__f7YPP">6<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><h2>바늘을 찾는 이박사 - OpenAI 대 Google</h2>
<p><img src="/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png" alt="이미지"/></p>
<p>대규모 언어 모델(LLM)이 큰 맥락 창 내에서 세부 정보를 찾고 이해하는 능력은 요새 필수적입니다.</p>
<p>바늘을 찾는 이박사 테스트는 이러한 작업을 위한 대규모 언어 모델을 평가하는 중요한 기준으로 나타납니다.</p>
<div class="content-ad"></div>
<p>이 글에서는 OpenAI와 Google의 최상위 LLM들의 맥락 기반 이해력을 측정한 독립적인 분석을 제시하겠습니다.</p>
<p>긴 맥락 작업에는 어떤 LLM을 사용해야 할까요?</p>
<h1>&quot;바늘 찾기&quot; 테스트란 무엇인가요? 🕵️‍♂️</h1>
<p>대규모 언어 모델(LLMs)의 &quot;바늘 찾기&quot; 테스트는 특정 정보(바늘)를 관련 없는 방대한 텍스트(쌀질) 안에 배치하는 것을 의미합니다.</p>
<div class="content-ad"></div>
<p>LLM은 그 후 바늘 추출이 필요한 쿼리에 응답하는 작업을 맡게 됩니다.</p>
<p>이러한 테스트는 LLM의 맥락 이해 및 긴 맥락에서 정보를 검색하는 능력을 평가하는 데 사용됩니다.</p>
<p>쿼리에 성공적으로 응답하면 상세한 컨텍스트 이해를 보여줄 수 있습니다. 이는 컨텍스트 기반 LLM 주변의 애플리케이션을 개발하는 데 중요합니다.</p>
<p>사용자 지정 지식을 LLM에 통합하는 것이 점점 인기를 얻고 있는데, 이를 검색으로 보강된 생성(RAG) 시스템이라고 합니다.</p>
<div class="content-ad"></div>
<p>RAG 시스템에 대해 더 많이 알아보고 싶으시면 제 이전 게시물 중 하나를 확인해보세요.</p>
<p>더 긴 컨텍스트 창의 트렌드를 더욱 촉진하기 위해, Google이 최근 Gemini 모델의 새로운 기능을 발표했는데, 이는 하나의 쿼리에 100만 개의 토큰을 입력할 수 있다는 것입니다!</p>
<p><img src="/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_1.png" alt="이미지"/></p>
<h1>데이터셋 🔢</h1>
<div class="content-ad"></div>
<p>저는 &quot;바늘을 찾기 위한&quot; 데이터셋을 만드는 데 사용되는 스크립트를 개발했습니다. 이 스크립트를 사용하면 두 가지 주요 요소를 입력할 수 있습니다:</p>
<ul>
<li>맥락 (헤이스택): 특별한 정보가 삽입된 텍스트입니다.</li>
<li>고유 정보 (바늘): 큰 맥락 속에 숨겨진 특정 정보입니다.</li>
</ul>
<p>데이터셋 생성 프로세스는 다음과 같이 작동합니다:</p>
<ul>
<li>시작점 선택: 스크립트는 대규모 텍스트 내에서 시작점을 무작위로 선택하여 시작합니다. 시작점은 전체 텍스트의 10~40번째 백분위에 위치합니다.</li>
<li>바늘 삽입: 고유 정보(바늘)는 그 후 헤이스택 내에 삽입됩니다. 바늘의 위치는 무작위로 선택되지만 헤이스택 길이의 20~80번째 백분위 내에 위치하도록 제약이 걸립니다.</li>
</ul>
<div class="content-ad"></div>
<p>LLMs는 일반적으로 프롬프트의 시작과 끝에서 정보를 가장 정확하게 기억한다고 알려져 있어요.</p>
<p>이 알고리즘은 바늘을 특정 백분위 범위 내에 전략적으로 배치합니다. 이렇게 함으로써 평가가 모델이 텍스트 전체 범위 내에서 데이터를 인식하고 추출하는 능력을 포착하도록 하고, 프롬프트의 더 쉽게 기억되는 가장자리 부분에만 의존하지 않도록 합니다.</p>
<p>다음은 데이터셋 생성 알고리즘의 코드 스니펫입니다:</p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">create_one_needle</span>(<span class="hljs-attr">num_chars</span>: int, <span class="hljs-attr">needle_line</span>: str, <span class="hljs-attr">lines</span>: list[str]):
    # 시작 위치는 텍스트의 <span class="hljs-number">10</span>에서 <span class="hljs-number">40</span> 백분위 사이의 임의의 위치입니다
    rnd_place = random.<span class="hljs-title function_">randint</span>(<span class="hljs-number">10</span>, <span class="hljs-number">40</span>) / <span class="hljs-number">100</span>
    start_position = <span class="hljs-title function_">int</span>(<span class="hljs-title function_">len</span>(lines) * rnd_place)

    # 바늘은 텍스트의 <span class="hljs-number">20</span>에서 <span class="hljs-number">80</span> 백분위 사이에 있습니다
    needle_rnd_place = random.<span class="hljs-title function_">randint</span>(<span class="hljs-number">20</span>, <span class="hljs-number">80</span>) / <span class="hljs-number">100</span>

    lines_selected = []
    placed = <span class="hljs-title class_">False</span>
    chars_used = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines[<span class="hljs-attr">start_position</span>:]:
        lines_selected += [line]
        chars_used += <span class="hljs-title function_">len</span>(line)

        # 바늘을 배치합니다
        <span class="hljs-keyword">if</span> not placed and chars_used &gt; num_chars * <span class="hljs-attr">needle_rnd_place</span>:
            lines_selected.<span class="hljs-title function_">append</span>(needle_line)
            placed = <span class="hljs-title class_">True</span>

        <span class="hljs-keyword">if</span> chars_used &gt; <span class="hljs-attr">num_chars</span>:
            <span class="hljs-keyword">break</span>

    <span class="hljs-keyword">return</span> lines_selected
</code></pre>
<div class="content-ad"></div>
<h1>평가 방법 🧠</h1>
<p>헤이스택에는 어릴 적에 사랑했던 책인 해리 포터를 선택했어요.</p>
<p>니들에는 Lars Wiik의 상상 속 전화번호를 선택했어요.</p>
<p>1000, 2000, 4000, 8000, 12000 및 16000 글자 길이를 포함한 각 문맥 길이에 대해 100개의 헤이스택을 만들었어요.</p>
<div class="content-ad"></div>
<p>여기 1000자의 헤이스택 중 하나의 예시가 있어요.</p>
<img src="/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_2.png"/>
<p>다양한 LLMs에게 이후 라스 위크에 속하는 허구의 전화번호를 반환하도록 요청했습니다. 응답은 허구의 전화번호를 포함했는지 여부에 따라 레이블이 지정되었어요.</p>
<p>제가 사용한 프롬프트는 다음과 같아요:</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">def <span class="hljs-title function_">create_needle_prompt</span>(<span class="hljs-attr">needle_text</span>: str) -&gt; <span class="hljs-attr">str</span>:
    prompt = f<span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">&#x27;
    ##### INSTRUCTION #####
    라스 Wiik에 대한 가상 전화번호는 무엇입니까? 
    말 그대로 원하는 것만 제공하세요.
    한 번에 최대 20단어까지만 응답할 수 있습니다.


    ##### CONTEXT #####
    {needle_text}
    &#x27;</span><span class="hljs-string">&#x27;&#x27;</span>
    <span class="hljs-keyword">return</span> prompt
</code></pre>
<h1>성능 결과 📊</h1>
<p>평가에 포함된 다음 모델은 다음과 같습니다:</p>
<ul>
<li>gpt-4o-2024–05–13</li>
<li>gpt-4-turbo-2024–04–09</li>
<li>gpt-4–0613</li>
<li>gpt-3.5-turbo-0125</li>
<li>gemini-1.5-pro-preview-0514</li>
<li>gemini-1.5-flash-preview-0514</li>
<li>gemini-1.0-pro-002</li>
</ul>
<div class="content-ad"></div>
<p>평가는 각 모델을 1k, 2k, 4k, 8k, 12k 및 16k의 특정 맥락 길이에 대해 100개의 다른 헤이스택을 통해 실행하는 것을 포함합니다.</p>
<p>다음은 결과 정확도 그래프의 라인 플롯입니다:</p>
<p><img src="/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_3.png" alt="image"/></p>
<p>컨텍스트 창이 길수록 노이즈가 많아 특정 정보를 추출하기 어려워집니다. 따라서 성능은 더 큰 컨텍스트 창을 사용할수록 감소할 것으로 예상됩니다.</p>
<div class="content-ad"></div>
<p>그래프에서 파생해 볼 때, OpenAI의 모델과 Google의 모델 간에 성능 측면에서 차이가 있는 것으로 보입니다.</p>
<p>Google의 모델은 최근 이벤트인 구글 I/O 2024에서 그들의 Gemini의 메모리와 맥락 이해에 대해 따뜻한 이야기를 한 후에도, 제 기대를 어느 정도 아래에서 달성하였습니다. 모든 Google의 모델은 8천 개의 맥락 길이 이후에 약 50%의 정확도로 수렴하는 것으로 보입니다.</p>
<p>한편 OpenAI의 모델은 이 테스트에서 뚜렷하게 잘 수행했는데, gpt-4o, gpt-4-turbo-2024-04-09 및 gpt-4-0613가 최고의 성능을 보였습니다.</p>
<p>또한 gpt-3.5-turbo-0125가 모든 Gemini 모델보다 우수한 성능을 보인다는 점도 언급해야 할 것입니다!</p>
<div class="content-ad"></div>
<p>평가 과정 중에 중요한 오류가 없었는지 확인하기 위해 Gemini 1.5에서 받은 모든 응답을 저장해서 나중에 참조할 수 있도록 했어요.</p>
<p>다음은 Gemini 1.5에서 얻은 일부 응답입니다:</p>
<pre><code class="hljs language-js"><span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>의 전화번호가 포함된 문맥이 제공되지 않았어요.

<span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>이나 그의 전화번호에 대한 언급이 없어요.

제공된 텍스트에는 <span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>의 전화번호가 없어요.

제공된 텍스트에 <span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>이나 그의 전화번호에 대한 언급이 없어요.

<span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>이나 그의 전화번호에 대한 언급이 없습니다.

텍스트에 <span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>의 전화번호가 제공되지 않았어요.

제공된 텍스트에 <span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>을 위한 가짜 전화번호가 포함되어 있지 않아요.

죄송하지만, 제공된 문맥에서 <span class="hljs-title class_">Lars</span> <span class="hljs-title class_">Wiik</span>을 위한 가짜 전화번호가 언급되지 않았어요.
</code></pre>
<p>Gemini 모델은 해리 포터 이야기 속에서 가짜 전화번호를 찾는 데 어려움을 겪는 것으로 보입니다.</p>
<div class="content-ad"></div>
<p>오픈AI의 gpt-3.5-turbo-0125에서 몇 가지 응답을 확인해보세요:</p>
<pre><code class="hljs language-js">N/A

N/A

주어진 맥락에서 랄스 빅에 대한 가짜 전화번호가 없습니다.

N/A

<span class="hljs-number">9</span> <span class="hljs-number">3</span>/<span class="hljs-number">4</span> 번 승강장.

랄스 빅을 위한 전화번호는 제공되지 않았습니다.
</code></pre>
<p>웃기게도, LLM은 &quot;9 3/4 번 승강장&quot;이라고 한적이 있어요 😄</p>
<h1>결론 💡</h1>
<div class="content-ad"></div>
<p>결론적으로, &quot;Needle in the Haystack&quot; 평가는 긴 맥락을 사용할 때 대형 언어 모델의 이해력과 정보 검색 능력을 측정하는 데 사용될 수 있습니다.</p>
<p>이 분석에서는 OpenAI의 모델과 Google의 Gemini 시리즈 간에 성능 격차를 관찰했습니다. 여기서 OpenAI의 gpt-4, gpt-4o 및 gpt-4-turbo가 가장 높은 점수를 받았습니다.</p>
<p>Google의 최근 Gemini의 100만 토큰을 처리할 수 있는 능력을 향상시킨 것에도 불구하고, OpenAI 모델이 큰 텍스트에서 구체적인 정보를 정확하게 검색하는 더 일관된 능력을 보인 것으로 나타났습니다.</p>
<p>사용자와 개발자들에게는 응용 프로그램의 특정 요구 사항에 따라 모델 선택이 달라질 것으로 예상됩니다.</p>
<div class="content-ad"></div>
<p>읽어 주셔서 감사합니다!</p>
<p>앞으로도 비슷한 콘텐츠를 받으려면 팔로우하세요!</p>
<p>질문이 있으면 언제든지 문의해 주세요!</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"오픈에이아이의 GPT-4o 대 젤미니 15  컨텍스트 메모리 평가","description":"","date":"2024-05-20 20:36","slug":"2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation","content":"\n\n## 바늘을 찾는 이박사 - OpenAI 대 Google\n\n![이미지](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png)\n\n대규모 언어 모델(LLM)이 큰 맥락 창 내에서 세부 정보를 찾고 이해하는 능력은 요새 필수적입니다.\n\n바늘을 찾는 이박사 테스트는 이러한 작업을 위한 대규모 언어 모델을 평가하는 중요한 기준으로 나타납니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글에서는 OpenAI와 Google의 최상위 LLM들의 맥락 기반 이해력을 측정한 독립적인 분석을 제시하겠습니다.\n\n긴 맥락 작업에는 어떤 LLM을 사용해야 할까요?\n\n# \"바늘 찾기\" 테스트란 무엇인가요? 🕵️‍♂️\n\n대규모 언어 모델(LLMs)의 \"바늘 찾기\" 테스트는 특정 정보(바늘)를 관련 없는 방대한 텍스트(쌀질) 안에 배치하는 것을 의미합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM은 그 후 바늘 추출이 필요한 쿼리에 응답하는 작업을 맡게 됩니다.\n\n이러한 테스트는 LLM의 맥락 이해 및 긴 맥락에서 정보를 검색하는 능력을 평가하는 데 사용됩니다.\n\n쿼리에 성공적으로 응답하면 상세한 컨텍스트 이해를 보여줄 수 있습니다. 이는 컨텍스트 기반 LLM 주변의 애플리케이션을 개발하는 데 중요합니다.\n\n사용자 지정 지식을 LLM에 통합하는 것이 점점 인기를 얻고 있는데, 이를 검색으로 보강된 생성(RAG) 시스템이라고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 시스템에 대해 더 많이 알아보고 싶으시면 제 이전 게시물 중 하나를 확인해보세요.\n\n더 긴 컨텍스트 창의 트렌드를 더욱 촉진하기 위해, Google이 최근 Gemini 모델의 새로운 기능을 발표했는데, 이는 하나의 쿼리에 100만 개의 토큰을 입력할 수 있다는 것입니다!\n\n![이미지](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_1.png)\n\n# 데이터셋 🔢\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 \"바늘을 찾기 위한\" 데이터셋을 만드는 데 사용되는 스크립트를 개발했습니다. 이 스크립트를 사용하면 두 가지 주요 요소를 입력할 수 있습니다:\n\n- 맥락 (헤이스택): 특별한 정보가 삽입된 텍스트입니다.\n- 고유 정보 (바늘): 큰 맥락 속에 숨겨진 특정 정보입니다.\n\n데이터셋 생성 프로세스는 다음과 같이 작동합니다:\n\n- 시작점 선택: 스크립트는 대규모 텍스트 내에서 시작점을 무작위로 선택하여 시작합니다. 시작점은 전체 텍스트의 10~40번째 백분위에 위치합니다.\n- 바늘 삽입: 고유 정보(바늘)는 그 후 헤이스택 내에 삽입됩니다. 바늘의 위치는 무작위로 선택되지만 헤이스택 길이의 20~80번째 백분위 내에 위치하도록 제약이 걸립니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLMs는 일반적으로 프롬프트의 시작과 끝에서 정보를 가장 정확하게 기억한다고 알려져 있어요.\n\n이 알고리즘은 바늘을 특정 백분위 범위 내에 전략적으로 배치합니다. 이렇게 함으로써 평가가 모델이 텍스트 전체 범위 내에서 데이터를 인식하고 추출하는 능력을 포착하도록 하고, 프롬프트의 더 쉽게 기억되는 가장자리 부분에만 의존하지 않도록 합니다.\n\n다음은 데이터셋 생성 알고리즘의 코드 스니펫입니다:\n\n```js\ndef create_one_needle(num_chars: int, needle_line: str, lines: list[str]):\n    # 시작 위치는 텍스트의 10에서 40 백분위 사이의 임의의 위치입니다\n    rnd_place = random.randint(10, 40) / 100\n    start_position = int(len(lines) * rnd_place)\n\n    # 바늘은 텍스트의 20에서 80 백분위 사이에 있습니다\n    needle_rnd_place = random.randint(20, 80) / 100\n\n    lines_selected = []\n    placed = False\n    chars_used = 0\n    for line in lines[start_position:]:\n        lines_selected += [line]\n        chars_used += len(line)\n\n        # 바늘을 배치합니다\n        if not placed and chars_used \u003e num_chars * needle_rnd_place:\n            lines_selected.append(needle_line)\n            placed = True\n\n        if chars_used \u003e num_chars:\n            break\n\n    return lines_selected\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 평가 방법 🧠\n\n헤이스택에는 어릴 적에 사랑했던 책인 해리 포터를 선택했어요.\n\n니들에는 Lars Wiik의 상상 속 전화번호를 선택했어요.\n\n1000, 2000, 4000, 8000, 12000 및 16000 글자 길이를 포함한 각 문맥 길이에 대해 100개의 헤이스택을 만들었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 1000자의 헤이스택 중 하나의 예시가 있어요.\n\n\u003cimg src=\"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_2.png\" /\u003e\n\n다양한 LLMs에게 이후 라스 위크에 속하는 허구의 전화번호를 반환하도록 요청했습니다. 응답은 허구의 전화번호를 포함했는지 여부에 따라 레이블이 지정되었어요.\n\n제가 사용한 프롬프트는 다음과 같아요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef create_needle_prompt(needle_text: str) -\u003e str:\n    prompt = f'''\n    ##### INSTRUCTION #####\n    라스 Wiik에 대한 가상 전화번호는 무엇입니까? \n    말 그대로 원하는 것만 제공하세요.\n    한 번에 최대 20단어까지만 응답할 수 있습니다.\n\n\n    ##### CONTEXT #####\n    {needle_text}\n    '''\n    return prompt\n```\n\n# 성능 결과 📊\n\n평가에 포함된 다음 모델은 다음과 같습니다:\n\n- gpt-4o-2024–05–13\n- gpt-4-turbo-2024–04–09\n- gpt-4–0613\n- gpt-3.5-turbo-0125\n- gemini-1.5-pro-preview-0514\n- gemini-1.5-flash-preview-0514\n- gemini-1.0-pro-002\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n평가는 각 모델을 1k, 2k, 4k, 8k, 12k 및 16k의 특정 맥락 길이에 대해 100개의 다른 헤이스택을 통해 실행하는 것을 포함합니다.\n\n다음은 결과 정확도 그래프의 라인 플롯입니다:\n\n![image](/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_3.png)\n\n컨텍스트 창이 길수록 노이즈가 많아 특정 정보를 추출하기 어려워집니다. 따라서 성능은 더 큰 컨텍스트 창을 사용할수록 감소할 것으로 예상됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래프에서 파생해 볼 때, OpenAI의 모델과 Google의 모델 간에 성능 측면에서 차이가 있는 것으로 보입니다.\n\nGoogle의 모델은 최근 이벤트인 구글 I/O 2024에서 그들의 Gemini의 메모리와 맥락 이해에 대해 따뜻한 이야기를 한 후에도, 제 기대를 어느 정도 아래에서 달성하였습니다. 모든 Google의 모델은 8천 개의 맥락 길이 이후에 약 50%의 정확도로 수렴하는 것으로 보입니다.\n\n한편 OpenAI의 모델은 이 테스트에서 뚜렷하게 잘 수행했는데, gpt-4o, gpt-4-turbo-2024-04-09 및 gpt-4-0613가 최고의 성능을 보였습니다.\n\n또한 gpt-3.5-turbo-0125가 모든 Gemini 모델보다 우수한 성능을 보인다는 점도 언급해야 할 것입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n평가 과정 중에 중요한 오류가 없었는지 확인하기 위해 Gemini 1.5에서 받은 모든 응답을 저장해서 나중에 참조할 수 있도록 했어요.\n\n다음은 Gemini 1.5에서 얻은 일부 응답입니다:\n\n```js\nLars Wiik의 전화번호가 포함된 문맥이 제공되지 않았어요.\n\nLars Wiik이나 그의 전화번호에 대한 언급이 없어요.\n\n제공된 텍스트에는 Lars Wiik의 전화번호가 없어요.\n\n제공된 텍스트에 Lars Wiik이나 그의 전화번호에 대한 언급이 없어요.\n\nLars Wiik이나 그의 전화번호에 대한 언급이 없습니다.\n\n텍스트에 Lars Wiik의 전화번호가 제공되지 않았어요.\n\n제공된 텍스트에 Lars Wiik을 위한 가짜 전화번호가 포함되어 있지 않아요.\n\n죄송하지만, 제공된 문맥에서 Lars Wiik을 위한 가짜 전화번호가 언급되지 않았어요.\n```\n\nGemini 모델은 해리 포터 이야기 속에서 가짜 전화번호를 찾는 데 어려움을 겪는 것으로 보입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오픈AI의 gpt-3.5-turbo-0125에서 몇 가지 응답을 확인해보세요:\n\n```js\nN/A\n\nN/A\n\n주어진 맥락에서 랄스 빅에 대한 가짜 전화번호가 없습니다.\n\nN/A\n\n9 3/4 번 승강장.\n\n랄스 빅을 위한 전화번호는 제공되지 않았습니다.\n```\n\n웃기게도, LLM은 \"9 3/4 번 승강장\"이라고 한적이 있어요 😄\n\n# 결론 💡\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결론적으로, \"Needle in the Haystack\" 평가는 긴 맥락을 사용할 때 대형 언어 모델의 이해력과 정보 검색 능력을 측정하는 데 사용될 수 있습니다.\n\n이 분석에서는 OpenAI의 모델과 Google의 Gemini 시리즈 간에 성능 격차를 관찰했습니다. 여기서 OpenAI의 gpt-4, gpt-4o 및 gpt-4-turbo가 가장 높은 점수를 받았습니다.\n\nGoogle의 최근 Gemini의 100만 토큰을 처리할 수 있는 능력을 향상시킨 것에도 불구하고, OpenAI 모델이 큰 텍스트에서 구체적인 정보를 정확하게 검색하는 더 일관된 능력을 보인 것으로 나타났습니다.\n\n사용자와 개발자들에게는 응용 프로그램의 특정 요구 사항에 따라 모델 선택이 달라질 것으로 예상됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n읽어 주셔서 감사합니다!\n\n앞으로도 비슷한 콘텐츠를 받으려면 팔로우하세요!\n\n질문이 있으면 언제든지 문의해 주세요!","ogImage":{"url":"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png"},"coverImage":"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png","tag":["Tech"],"readingTime":6},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h2: \"h2\",\n    p: \"p\",\n    img: \"img\",\n    h1: \"h1\",\n    ul: \"ul\",\n    li: \"li\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.h2, {\n      children: \"바늘을 찾는 이박사 - OpenAI 대 Google\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_0.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"대규모 언어 모델(LLM)이 큰 맥락 창 내에서 세부 정보를 찾고 이해하는 능력은 요새 필수적입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"바늘을 찾는 이박사 테스트는 이러한 작업을 위한 대규모 언어 모델을 평가하는 중요한 기준으로 나타납니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 글에서는 OpenAI와 Google의 최상위 LLM들의 맥락 기반 이해력을 측정한 독립적인 분석을 제시하겠습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"긴 맥락 작업에는 어떤 LLM을 사용해야 할까요?\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"\\\"바늘 찾기\\\" 테스트란 무엇인가요? 🕵️‍♂️\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"대규모 언어 모델(LLMs)의 \\\"바늘 찾기\\\" 테스트는 특정 정보(바늘)를 관련 없는 방대한 텍스트(쌀질) 안에 배치하는 것을 의미합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LLM은 그 후 바늘 추출이 필요한 쿼리에 응답하는 작업을 맡게 됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이러한 테스트는 LLM의 맥락 이해 및 긴 맥락에서 정보를 검색하는 능력을 평가하는 데 사용됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"쿼리에 성공적으로 응답하면 상세한 컨텍스트 이해를 보여줄 수 있습니다. 이는 컨텍스트 기반 LLM 주변의 애플리케이션을 개발하는 데 중요합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"사용자 지정 지식을 LLM에 통합하는 것이 점점 인기를 얻고 있는데, 이를 검색으로 보강된 생성(RAG) 시스템이라고 합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"RAG 시스템에 대해 더 많이 알아보고 싶으시면 제 이전 게시물 중 하나를 확인해보세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"더 긴 컨텍스트 창의 트렌드를 더욱 촉진하기 위해, Google이 최근 Gemini 모델의 새로운 기능을 발표했는데, 이는 하나의 쿼리에 100만 개의 토큰을 입력할 수 있다는 것입니다!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_1.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"데이터셋 🔢\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"저는 \\\"바늘을 찾기 위한\\\" 데이터셋을 만드는 데 사용되는 스크립트를 개발했습니다. 이 스크립트를 사용하면 두 가지 주요 요소를 입력할 수 있습니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"맥락 (헤이스택): 특별한 정보가 삽입된 텍스트입니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"고유 정보 (바늘): 큰 맥락 속에 숨겨진 특정 정보입니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"데이터셋 생성 프로세스는 다음과 같이 작동합니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"시작점 선택: 스크립트는 대규모 텍스트 내에서 시작점을 무작위로 선택하여 시작합니다. 시작점은 전체 텍스트의 10~40번째 백분위에 위치합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"바늘 삽입: 고유 정보(바늘)는 그 후 헤이스택 내에 삽입됩니다. 바늘의 위치는 무작위로 선택되지만 헤이스택 길이의 20~80번째 백분위 내에 위치하도록 제약이 걸립니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LLMs는 일반적으로 프롬프트의 시작과 끝에서 정보를 가장 정확하게 기억한다고 알려져 있어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 알고리즘은 바늘을 특정 백분위 범위 내에 전략적으로 배치합니다. 이렇게 함으로써 평가가 모델이 텍스트 전체 범위 내에서 데이터를 인식하고 추출하는 능력을 포착하도록 하고, 프롬프트의 더 쉽게 기억되는 가장자리 부분에만 의존하지 않도록 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"다음은 데이터셋 생성 알고리즘의 코드 스니펫입니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"def \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"create_one_needle\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"num_chars\"\n        }), \": int, \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"needle_line\"\n        }), \": str, \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"lines\"\n        }), \": list[str]):\\n    # 시작 위치는 텍스트의 \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"10\"\n        }), \"에서 \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"40\"\n        }), \" 백분위 사이의 임의의 위치입니다\\n    rnd_place = random.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"randint\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"10\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"40\"\n        }), \") / \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"100\"\n        }), \"\\n    start_position = \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"int\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"len\"\n        }), \"(lines) * rnd_place)\\n\\n    # 바늘은 텍스트의 \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"20\"\n        }), \"에서 \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"80\"\n        }), \" 백분위 사이에 있습니다\\n    needle_rnd_place = random.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"randint\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"20\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"80\"\n        }), \") / \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"100\"\n        }), \"\\n\\n    lines_selected = []\\n    placed = \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"False\"\n        }), \"\\n    chars_used = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"for\"\n        }), \" line \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"in\"\n        }), \" lines[\", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"start_position\"\n        }), \":]:\\n        lines_selected += [line]\\n        chars_used += \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"len\"\n        }), \"(line)\\n\\n        # 바늘을 배치합니다\\n        \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"if\"\n        }), \" not placed and chars_used \u003e num_chars * \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"needle_rnd_place\"\n        }), \":\\n            lines_selected.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"append\"\n        }), \"(needle_line)\\n            placed = \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"True\"\n        }), \"\\n\\n        \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"if\"\n        }), \" chars_used \u003e \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"num_chars\"\n        }), \":\\n            \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"break\"\n        }), \"\\n\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" lines_selected\\n\"]\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"평가 방법 🧠\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"헤이스택에는 어릴 적에 사랑했던 책인 해리 포터를 선택했어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"니들에는 Lars Wiik의 상상 속 전화번호를 선택했어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"1000, 2000, 4000, 8000, 12000 및 16000 글자 길이를 포함한 각 문맥 길이에 대해 100개의 헤이스택을 만들었어요.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기 1000자의 헤이스택 중 하나의 예시가 있어요.\"\n    }), \"\\n\", _jsx(\"img\", {\n      src: \"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_2.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"다양한 LLMs에게 이후 라스 위크에 속하는 허구의 전화번호를 반환하도록 요청했습니다. 응답은 허구의 전화번호를 포함했는지 여부에 따라 레이블이 지정되었어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"제가 사용한 프롬프트는 다음과 같아요:\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"def \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"create_needle_prompt\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"needle_text\"\n        }), \": str) -\u003e \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"str\"\n        }), \":\\n    prompt = f\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"''\"\n        }), _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'\\n    ##### INSTRUCTION #####\\n    라스 Wiik에 대한 가상 전화번호는 무엇입니까? \\n    말 그대로 원하는 것만 제공하세요.\\n    한 번에 최대 20단어까지만 응답할 수 있습니다.\\n\\n\\n    ##### CONTEXT #####\\n    {needle_text}\\n    '\"\n        }), _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"''\"\n        }), \"\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" prompt\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"성능 결과 📊\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"평가에 포함된 다음 모델은 다음과 같습니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"gpt-4o-2024–05–13\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"gpt-4-turbo-2024–04–09\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"gpt-4–0613\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"gpt-3.5-turbo-0125\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"gemini-1.5-pro-preview-0514\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"gemini-1.5-flash-preview-0514\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"gemini-1.0-pro-002\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"평가는 각 모델을 1k, 2k, 4k, 8k, 12k 및 16k의 특정 맥락 길이에 대해 100개의 다른 헤이스택을 통해 실행하는 것을 포함합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"다음은 결과 정확도 그래프의 라인 플롯입니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation_3.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"컨텍스트 창이 길수록 노이즈가 많아 특정 정보를 추출하기 어려워집니다. 따라서 성능은 더 큰 컨텍스트 창을 사용할수록 감소할 것으로 예상됩니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그래프에서 파생해 볼 때, OpenAI의 모델과 Google의 모델 간에 성능 측면에서 차이가 있는 것으로 보입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Google의 모델은 최근 이벤트인 구글 I/O 2024에서 그들의 Gemini의 메모리와 맥락 이해에 대해 따뜻한 이야기를 한 후에도, 제 기대를 어느 정도 아래에서 달성하였습니다. 모든 Google의 모델은 8천 개의 맥락 길이 이후에 약 50%의 정확도로 수렴하는 것으로 보입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"한편 OpenAI의 모델은 이 테스트에서 뚜렷하게 잘 수행했는데, gpt-4o, gpt-4-turbo-2024-04-09 및 gpt-4-0613가 최고의 성능을 보였습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"또한 gpt-3.5-turbo-0125가 모든 Gemini 모델보다 우수한 성능을 보인다는 점도 언급해야 할 것입니다!\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"평가 과정 중에 중요한 오류가 없었는지 확인하기 위해 Gemini 1.5에서 받은 모든 응답을 저장해서 나중에 참조할 수 있도록 했어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"다음은 Gemini 1.5에서 얻은 일부 응답입니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"의 전화번호가 포함된 문맥이 제공되지 않았어요.\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"이나 그의 전화번호에 대한 언급이 없어요.\\n\\n제공된 텍스트에는 \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"의 전화번호가 없어요.\\n\\n제공된 텍스트에 \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"이나 그의 전화번호에 대한 언급이 없어요.\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"이나 그의 전화번호에 대한 언급이 없습니다.\\n\\n텍스트에 \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"의 전화번호가 제공되지 않았어요.\\n\\n제공된 텍스트에 \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"을 위한 가짜 전화번호가 포함되어 있지 않아요.\\n\\n죄송하지만, 제공된 문맥에서 \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Lars\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Wiik\"\n        }), \"을 위한 가짜 전화번호가 언급되지 않았어요.\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Gemini 모델은 해리 포터 이야기 속에서 가짜 전화번호를 찾는 데 어려움을 겪는 것으로 보입니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"오픈AI의 gpt-3.5-turbo-0125에서 몇 가지 응답을 확인해보세요:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"N/A\\n\\nN/A\\n\\n주어진 맥락에서 랄스 빅에 대한 가짜 전화번호가 없습니다.\\n\\nN/A\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"9\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"3\"\n        }), \"/\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"4\"\n        }), \" 번 승강장.\\n\\n랄스 빅을 위한 전화번호는 제공되지 않았습니다.\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"웃기게도, LLM은 \\\"9 3/4 번 승강장\\\"이라고 한적이 있어요 😄\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"결론 💡\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"결론적으로, \\\"Needle in the Haystack\\\" 평가는 긴 맥락을 사용할 때 대형 언어 모델의 이해력과 정보 검색 능력을 측정하는 데 사용될 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 분석에서는 OpenAI의 모델과 Google의 Gemini 시리즈 간에 성능 격차를 관찰했습니다. 여기서 OpenAI의 gpt-4, gpt-4o 및 gpt-4-turbo가 가장 높은 점수를 받았습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Google의 최근 Gemini의 100만 토큰을 처리할 수 있는 능력을 향상시킨 것에도 불구하고, OpenAI 모델이 큰 텍스트에서 구체적인 정보를 정확하게 검색하는 더 일관된 능력을 보인 것으로 나타났습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"사용자와 개발자들에게는 응용 프로그램의 특정 요구 사항에 따라 모델 선택이 달라질 것으로 예상됩니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"읽어 주셔서 감사합니다!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"앞으로도 비슷한 콘텐츠를 받으려면 팔로우하세요!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"질문이 있으면 언제든지 문의해 주세요!\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-20-OpenAIsGPT-4ovsGemini15ContextMemoryEvaluation"},"buildId":"R1x9p1CQYDDJESXyLXKOK","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>