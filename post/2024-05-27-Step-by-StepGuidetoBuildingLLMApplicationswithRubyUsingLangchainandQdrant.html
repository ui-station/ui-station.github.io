<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>루비를 사용하여 LLM 애플리케이션을 Langchain과 Qdrant를 이용해 만드는 단계별 가이드 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="루비를 사용하여 LLM 애플리케이션을 Langchain과 Qdrant를 이용해 만드는 단계별 가이드 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="루비를 사용하여 LLM 애플리케이션을 Langchain과 Qdrant를 이용해 만드는 단계별 가이드 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant" data-gatsby-head="true"/><meta name="twitter:title" content="루비를 사용하여 LLM 애플리케이션을 Langchain과 Qdrant를 이용해 만드는 단계별 가이드 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-27 16:04" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_buildManifest.js" defer=""></script><script src="/_next/static/JlBEgQDLGRx6DYlBnT8eD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">루비를 사용하여 LLM 애플리케이션을 Langchain과 Qdrant를 이용해 만드는 단계별 가이드</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="루비를 사용하여 LLM 애플리케이션을 Langchain과 Qdrant를 이용해 만드는 단계별 가이드" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 27, 2024</span><span class="posts_reading_time__f7YPP">27<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<img src="/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_0.png">
<p>소프트웨어 개발의 세계에서 프로그래밍 언어와 도구의 선택은 단순히 선호도의 문제가 아니라 프로젝트 결과에 상당한 영향을 미칠 수 있는 전략적인 선택입니다. 파이썬이 인공 지능(AI) 및 기계 학습(ML) 애플리케이션에서 선두 주자였던 반면, 루비의 잠재력은 이러한 영역에서 여전히 충분히 발휘되지 않았습니다. 이 안내서는 특히 고급 AI 구현의 맥락에서 루비의 능력을 밝히고자 합니다.</p>
<p>우아하고 간결함으로 유명한 루비는 작성하기 쉽기만한 문법과 읽기 즐거운 문법을 제공합니다. 주로 웹 개발에서 유능함으로 인정받았던 이 언어는 AI 및 ML 분야에서는 과소평가되고 있습니다. 그러나 견고한 프레임워크와 커뮤니티 주도의 접근 방식으로, 루비는 특히 이미 루비 생태계에 몸담은 팀 및 프로젝트에 대한 선택지로 자리잡고 있습니다.</p>
<p>우리의 여정은 루비가 LangChain, Mistral 7B, 그리고 Qdrant Vector DB와 같은 최첨단 기술과 효과적으로 결합되어 얼마나 활용될 수 있는지를 탐색함으로 시작됩니다. 이러한 도구들이 결합되면 정교한 Retriever-Augmented Generation (RAG) 모델을 만들 수 있습니다. 이 모델은 루비가 더 전통적인 AI 언어와 어깨를 나란히 할 수 있는 능력을 보여줍니다. 이는 AI 및 ML 분야에서 새로운 지평을 열어주며 루비 애호가들을 위한 새로운 가능성을 제시합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>Ruby 설치 가이드</h1>
<p>루비의 이러한 측면을 이해하면 프로그래밍에 가져다주는 가치와 파워를 더욱 높이게 될 것입니다. 설치 과정은 보상을 받는 여정의 첫걸음입니다.</p>
<h2>원하는 루비 버전 매니저 선택</h2>
<p>버전 매니저를 선택하는 것은 집을 건설할 때 올바른 기초를 선택하는 것과 같습니다. 루비의 다양한 버전 및 의존성을 관리하는 데 필수적이기 때문입니다. 이는 루비의 자주 업데이트되는 언어와 서로 다른 프로젝트의 요구 사항 때문에 특히 중요합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>RVM (루비 버전 관리자)</h2>
<p>장점: 루비 환경을 효율적으로 관리할 수 있는 방법을 제공합니다. 여러 루비 버전 및 젬 세트(젬셋)를 처리하는 데 좋습니다. 또한 동일한 컴퓨터에서 여러 루비 환경을 설치, 관리 및 사용할 수 있습니다. 이는 여러 프로젝트에 작업하는 개발자에게 이상적입니다.</p>
<h2>설치 안내</h2>
<h2>시스템 패키지 업데이트</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>시스템을 최신 상태로 유지하려면 다음 명령을 실행하세요:</p>
<pre><code class="hljs language-bash">sudo apt update
sudo apt upgrade
</code></pre>
<p>루비 설치에 필요한 종속성을 설치하세요:</p>
<pre><code class="hljs language-bash">sudo apt install git curl libssl-dev libreadline-dev zlib1g-dev autoconf bison build-essential libyaml-dev libreadline-dev libncurses5-dev libffi-dev libgdbm-dev
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">sudo apt install rbenv
</code></pre>
<p>GitHub에서 가져온 설치 스크립트를 사용하여 rbenv를 설치하세요:</p>
<pre><code class="hljs language-js">curl -fsSL <span class="hljs-attr">https</span>:<span class="hljs-comment">//github.com/rbenv/rbenv-installer/raw/HEAD/bin/rbenv-installer | bash</span>
</code></pre>
<p>rbenv 명령어를 사용하기 위해 $PATH에 ~/.rbenv/bin을 추가하세요.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">echo <span class="hljs-string">'export PATH="$HOME/.rbenv/bin:$PATH"'</span> >> ~/.<span class="hljs-property">bashrc</span>
</code></pre>
<p>rbenv를 자동으로 로드하도록 초기화 명령어를 추가하세요:</p>
<pre><code class="hljs language-js">echo <span class="hljs-string">'eval "$(rbenv init -)"'</span> >> ~/.<span class="hljs-property">bashrc</span>
</code></pre>
<p>모든 변경 사항을 쉘 세션에 적용하세요:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-sh">소스 ~/.bashrc
</code></pre>
<p>rbenv이 제대로 설정되었는지 확인하세요:</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">type</span> rbenv
</code></pre>
<h2>Ruby-Build</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>루비 빌드는 유니스류 시스템에서 소스로부터 루비 버전을 설치하는 과정을 간소화하기 위해 설계된 명령줄 유틸리티입니다.</p>
<h2>루비 버전 설치</h2>
<p>rbenv install 명령은 rbenv에 기본적으로 포함되어 있지 않습니다. 대신에 ruby-build 플러그인에서 제공됩니다.</p>
<p>루비를 설치하기 전에 필요한 도구와 라이브러리가 포함된 빌드 환경을 확인하세요. 확인이 완료되면 다음 단계를 따르세요:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>최신 안정 버전 목록:</h1>
<p>rbenv install -l</p>
<h1>모든 로컬 버전 목록:</h1>
<p>rbenv install -L</p>
<h1>Ruby 버전 설치:</h1>
<p>rbenv install 3.1.2</p>
<h1>왜 Ruby를 선택해야 하는가?</h1>
<p>Ruby는 프로그래밍 세계에서 실무자들 사이에 잘 보호된 비밀 같은 존재입니다. AI와 ML 분야에서 Python의 높은 인기에 가려져, Ruby의 이 분야에서의 능력은 종종 간과되곤 합니다.</p>
<p>Ruby의 진정한 강점은 그 간단함에 있으며 사용자들에게 제공하는 생산성입니다. 이 언어의 우아한 구문과 튼튼한 표준 라이브러리는 신속한 개발 주기에 이상적인 후보입니다. 코드 작성의 용이성뿐만 아니라, 그것을 유지하는 용이성에 있습니다. Ruby의 가독성이 뛰어나고 직관적인 코드베이스는 장기 프로젝트를 위한 큰 도움이 됩니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>기존 응용 프로그램 스택에서는 이미 Ruby가 핵심 구성 요소로 사용되고 있습니다. 이러한 스택에 AI 기능을 전환하거나 통합하는 것은 새로운 언어인 Python으로 전환할 필요가 없다는 것을 의미합니다. 대신, AI 응용 프로그램에 대한 기존 Ruby 워크플로를 활용하는 것이 실용적이고 효율적인 접근 방법이 될 수 있습니다.</p>
<p>또한 Ruby의 생태계는 AI 및 ML 작업에 적합한 라이브러리와 도구로 장착되어 있습니다. 딥 러닝을 위한 Ruby-DNN과 머신 러닝을 위한 Rumale과 같은 젬들은 Ruby가 이러한 분야에서 점차 늘어나는 능력을 입증하고 있습니다.</p>
<p>따라서 이미 Ruby에 익숙한 응용 프로그램 및 팀에 대해, Ruby를 계속 사용하여 AI 및 ML 작업을 수행하는 것은 안락함뿐만 아니라 전략적 효율성의 문제입니다.</p>
<h2>Ruby로 기본 데이터 처리하기</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"># 간단한 데이터 처리
data = [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>, <span class="hljs-number">10</span>]
processed_data = data.<span class="hljs-property">map</span> { |number| number * <span class="hljs-number">2</span> }
puts processed_data
</code></pre>
<h2>출력</h2>
<pre><code class="hljs language-js">[<span class="hljs-number">4</span>, <span class="hljs-number">8</span>, <span class="hljs-number">12</span>, <span class="hljs-number">16</span>, <span class="hljs-number">20</span>];
</code></pre>
<h2>루비로 하는 기본 머신 러닝</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>"rumale"을 설치하려면 RubyGems 패키지 매니저를 사용하세요. 터미널에서 다음 명령을 실행해주세요:</p>
<pre><code class="hljs language-js">gem install rumale
</code></pre>
<p>"rumale"을 설치한 후에, gem 파일에 다음 줄을 추가해주세요:</p>
<pre><code class="hljs language-js">gem <span class="hljs-string">"rumale"</span>
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-ruby"><span class="hljs-comment"># 단순 선형 회귀를 위해 Rumale 젬을 사용합니다</span>
<span class="hljs-keyword">require</span> <span class="hljs-string">'rumale'</span>
x = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>]]
y = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]
model = <span class="hljs-title class_">Rumale</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:LinearModel</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:LinearRegression</span>.new
model.fit(x, y)
predictions = model.predict(x)
<span class="hljs-comment"># Numo::DFloat를 Ruby 배열로 변환합니다</span>
predictions_array = predictions.to_a
puts <span class="hljs-string">"예측 값: <span class="hljs-subst">#{predictions_array}</span>"</span>
</code></pre>
<p>이 코드 예제들은 Ruby의 간단한 작업 처리 방식을 보여줍니다. 이는 AI 및 ML을 포함한 다양한 응용 프로그램에 대한 접근성과 강력함을 제공합니다.</p>
<h3>아키텍처: LangChain, Mistral 7B, GPU 노드 위의 Qdrant</h3>
<p>저희 Ruby 기반 AI 시스템 아키텍처에서는 LangChain, Mistra 7B, 그리고 Qdrant 세 가지 주요 구성 요소를 통합하고 있습니다. 각 구성 요소는 시스템의 기능성에 중요한 역할을 하며 특히 GPU 노드에서 활용될 때 중요합니다. 각 구성 요소에 대해 자세히 살펴보고 전체 아키텍처에 어떻게 기여하는지 이해해 봅시다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>LangChain</h2>
<p>LangChain은 언어 모델의 구축과 활용을 용이하게 하는 오픈 소스 라이브러리입니다. 언어 처리 작업의 복잡성을 추상화하여 개발자가 정교한 NLP 기능을 구현하기 쉽도록 설계되었습니다. Ruby 환경에서 LangChain은 언어 모델과 데이터베이스 간 상호작용을 관리하는 오케스트레이터 역할을 합니다.</p>
<h2>Mistral 7B</h2>
<p>Mistral 7B는 Transformer 모델의 변형 버전으로, 자연어 처리 작업에서 효율적이고 효과적인 성능으로 알려져 있습니다. AI 및 기계 학습 분야의 선두주자인 Hugging Face에서 제공되며, Mistral 7B는 인간과 유사한 텍스트를 이해하고 생성하는 데 능숙합니다. 우리의 아키텍처에서 Mistral 7B는 핵심 언어 이해 및 생성 작업을 담당합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>큐드런트</h2>
<p>큐드런트는 주로 AI 및 ML 애플리케이션에서 찾을 수 있는 고차원 데이터를 처리하기에 최적화된 벡터 데이터베이스로 작용합니다. 이는 벡터의 효율적인 저장 및 검색을 위해 설계되었으며, Mistral 7B와 같은 AI 모델로부터 생성되고 사용되는 데이터를 관리하기에 이상적인 솔루션입니다. 저희 설정에서는 큐드런트가 언어 모델에서 생성된 벡터의 저장을 담당하며, 빠르고 정확한 검색을 용이하게 합니다.</p>
<h2>GPU 노드 활용</h2>
<p>이 아키텍처에 GPU 노드를 포함하는 것은 중요합니다. GPU는 병렬 처리 능력을 통해 AI 및 ML에 관련된 계산 집약적 작업에 매우 적합합니다. GPU 노드에서 구성 요소를 실행함으로써 시스템의 성능을 크게 향상시킬 수 있습니다. GPU는 Mistral 7B 및 큐드런트의 작업을 가속화하여 언어 모델이 데이터를 신속하고 효율적으로 처리하도록 보장합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>구성 요소 통합</h2>
<p>이러한 구성 요소의 루비 환경 통합은 핵심적입니다. 랭체인은 루비 인터페이스를 통해 미스트랄 7B 모델과 큐드란트 데이터베이스 간 상호 작용을 조율하는 중심 요소로 작용합니다. 미스트랄 7B 모델은 언어 데이터를 처리하고 텍스트를 의미 있는 벡터로 변환한 다음 큐드란트에 의해 저장되고 관리됩니다. 이 설정을 통해 데이터가 효율적으로 처리되고 저장되며 검색되어 GPU의 능력을 최대한 활용할 수 있는 워크플로우가 구축됩니다.</p>
<h2>루비에서 LangChain 초기화</h2>
<p>"LangChain"과 "transformer"를 설치하려면 RubyGems 패키지 관리자를 사용하십시오. 터미널에서 다음을 실행하십시오:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">gem install langchainrb
gem install hugging-face
</code></pre>
<p>이 명령은 LangChain과 transformers 및 그 종속성을 설치합니다. "langchain" 및 "transformers"를 설치한 후, gem 파일에 다음 줄을 추가하세요:</p>
<pre><code class="hljs language-js">gem <span class="hljs-string">"langchainrb"</span>
gem <span class="hljs-string">"hugging-face"</span>
</code></pre>
<h2>Hugging Face 및 LangChain과 상호 작용하기</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-ruby"><span class="hljs-keyword">require</span> <span class="hljs-string">'langchain'</span>
client = <span class="hljs-title class_">HuggingFace::InferenceApi</span>.new(<span class="hljs-symbol">api_token:</span><span class="hljs-string">"hf_llpPsAVgQYqSmWhlC*****"</span>) <span class="hljs-comment"># add your inference endpoint api key.</span>
puts client
</code></pre>
<h1>루비에서 Qdrant 클라이언트 설정하기</h1>
<p>루비에서 Qdrant와 상호 작용하려면 qdrant_client 젬을 설치해야 합니다. 이 젬은 Qdrant API에 편리한 루비 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치할 수 있습니다:</p>
<pre><code class="hljs language-sh">gem install qdrant-ruby
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>“qdrant-ruby”을 설치한 후 젬 파일에 다음 줄을 추가해주세요:</p>
<pre><code class="hljs language-js">gem <span class="hljs-string">"qdrant-ruby"</span>
</code></pre>
<pre><code class="hljs language-js"><span class="hljs-built_in">require</span> <span class="hljs-string">'qdrant'</span>
# <span class="hljs-title class_">Qdrant</span> 클라이언트를 초기화합니다.
client = <span class="hljs-title class_">Qdrant</span>::<span class="hljs-title class_">Client</span>.<span class="hljs-title function_">new</span>(
 <span class="hljs-attr">url</span>: <span class="hljs-string">"여러분의-qdrant-URL"</span>,
 <span class="hljs-attr">api_key</span>: <span class="hljs-string">"여러분의-qdrant-API-키"</span>
)
</code></pre>
<p>이 아키텍처는 루비에서 인공 지능 및 기계 학습에 대한 혁신적인 접근 방식을 보여주며, 해당 언어의 유연성과 첨단 인공 지능 도구 및 기술과 통합할 수 있는 능력을 뽐내고 있습니다. 특히 LangChain, Mistral 7B 및 Qdrant 간의 시너지는 GPU 노드에서 활용될 때 강력하고 효율적인 인공 지능 시스템을 만들어냅니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>LangChain - 루비 설치 가이드</h1>
<p><img src="/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_1.png" alt="LangChain"></p>
<p>LangChain은 언어 모델을 구축하기 위한 혁신적인 라이브러리로, 루비 기반의 AI 아키텍처에서 중심적인 역할을 합니다. 복잡한 언어 처리 작업을 통합하는 간소화된 방법을 제공합니다. 이제 루비 환경에서 LangChain을 설치하고 코드 스니펫을 통해 기본 사용법을 살펴보겠습니다.</p>
<h2>LangChain 설치하기</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>LangChain을 설치하기 전에 시스템에 Ruby가 설치되어 있는지 확인하세요. LangChain은 Ruby 버전 2.5 이상이 필요합니다. Ruby 버전을 확인하려면 "ruby -v" 명령을 사용하실 수 있습니다. 올바른 Ruby 버전이 설치되어 있다면 다음과 같이 설치를 진행할 수 있습니다:</p>
<h2>Ruby 스크립트에 LangChain을 요구하세요</h2>
<p>설치 후에는 Ruby 스크립트에 LangChain을 포함하여 사용을 시작할 수 있습니다:</p>
<pre><code class="hljs language-rb"><span class="hljs-keyword">require</span> <span class="hljs-string">'langchain'</span>
<span class="hljs-keyword">require</span> <span class="hljs-string">"hugging_face"</span>
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>여기에 시작하는 방법이 있습니다:</p>
<h3>언어 모델 초기화</h3>
<p>LangChain을 사용하면 다양한 종류의 언어 모델을 초기화할 수 있습니다. 기본 모델을 초기화하는 예제를 보여드리겠습니다:</p>
<pre><code class="hljs language-js">client = <span class="hljs-title class_">HuggingFace</span>::<span class="hljs-title class_">InferenceApi</span>.<span class="hljs-title function_">new</span>(<span class="hljs-attr">api_token</span>:<span class="hljs-string">"hf_llpPsAVgQYqSmW*****"</span>)
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>Mistral 7B (Hugging Face 모델): 루비 설치 가이드</h1>
<p>루비 애플리케이션에 Hugging Face의 Mistral 7B 모델을 통합하는 것은 최첨단 자연어 처리 (NLP) 능력을 활용하는 강력한 방법을 제공합니다. 여기에는 Mistral 7B를 루비에서 설치하고 사용하는 방법에 대한 자세한 안내서 및 시작하는 데 도움이 되는 코드 조각이 포함되어 있습니다.</p>
<h2>루비에서 Mistral 7B 설치</h2>
<p>Mistral 7B를 사용하려면 먼저 transformers-ruby 젬을 설치해야 합니다. 이 젬은 Hugging Face의 Transformers 라이브러리에 대한 루비 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치할 수 있습니다:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">gem install hugging-face
</code></pre>
<h2>루비 스크립트에서 HuggingFace 및 LangChain Gem을 요구하십시오</h2>
<p>설치한 후에는 HuggingFace 및 LangChain 젬을 루비 스크립트에 포함시키세요:</p>
<pre><code class="hljs language-js"><span class="hljs-built_in">require</span> <span class="hljs-string">'langchain'</span>
<span class="hljs-built_in">require</span> <span class="hljs-string">"hugging_face"</span>
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>Mistral 7B 모델을 초기화합니다</h1>
<p>Mistral 7B를 사용하려면 Hugging Face를 사용하여 초기화해야 합니다. 다음은 초기화하는 방법입니다:</p>
<pre><code class="hljs language-js"># 텍스트 생성을 위해 <span class="hljs-title class_">Mistral</span> 7B 모델을 초기화합니다
model = <span class="hljs-string">"mistralai/Mistral-7B-v0.1"</span>
call_model = client.<span class="hljs-title function_">call</span>(<span class="hljs-attr">model</span>:model,<span class="hljs-attr">input</span>:{ <span class="hljs-attr">inputs</span>: <span class="hljs-string">'더 많은 세부 정보에 대해 알려주시겠어요?'</span>})
</code></pre>
<h2>Mistral 7B로 텍스트 생성하기</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Mistral 7B는 텍스트 생성과 같은 다양한 NLP 작업에 사용될 수 있습니다. 아래는 텍스트를 생성하는 예제입니다:</p>
<pre><code class="hljs language-js">test = <span class="hljs-title class_">Langchain</span>::<span class="hljs-attr">LLM</span>::<span class="hljs-title class_">HuggingFaceResponse</span>.<span class="hljs-title function_">new</span>(call_model, <span class="hljs-attr">model</span>: model)
puts test.<span class="hljs-property">raw_response</span>[<span class="hljs-number">0</span>][<span class="hljs-string">"generated_text"</span>]
</code></pre>
<h1>Qdrant: 루비 설치 안내서</h1>
<img src="/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_2.png">
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Qdrant은 머신 러닝 작업에 최적화된 강력한 벡터 검색 엔진으로, Ruby에서 AI 애플리케이션에 이상적인 선택지입니다. 이 섹션에서는 Ruby 환경에서 Qdrant를 설치하고 사용하는 방법에 대해 자세히 안내하며, 코드 스니펫이 포함되어 있습니다.</p>
<h2>Ruby에서 Qdrant 설치하기</h2>
<p>Qdrant 클라이언트 젬 설치</p>
<p>Ruby에서 Qdrant와 상호 작용하려면 qdrant_client 젬을 설치해야 합니다. 이 젬은 Qdrant API에 편리한 Ruby 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치하세요:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">gem install qdrant-ruby
</code></pre>
<p>“qdrant-ruby”를 설치한 후, 젬 파일에 다음 라인을 추가해주세요:</p>
<pre><code class="hljs language-js">gem <span class="hljs-string">"qdrant-ruby"</span>
</code></pre>
<h1>루비 스크립트에서 Qdrant 클라이언트를 요청하기</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이젠 gem을 설치한 후 Ruby 스크립트에 포함하세요:</p>
<pre><code class="hljs language-js"><span class="hljs-built_in">require</span> <span class="hljs-string">'qdrant'</span>
</code></pre>
<p>Qdrant 클라이언트를 설치하면 Ruby 어플리케이션에서 해당 기능을 활용할 수 있습니다.</p>
<h1>Qdrant 클라이언트 초기화</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Qdrant 서버에 연결하려면 Qdrant 클라이언트를 초기화하십시오. 로컬 또는 원격으로 실행 중인 Qdrant 서버가 있어야 합니다.</p>
<pre><code class="hljs language-js"># <span class="hljs-title class_">Qdrant</span> 클라이언트 초기화
client = <span class="hljs-title class_">Qdrant</span>::<span class="hljs-title class_">Client</span>.<span class="hljs-title function_">new</span>(
 <span class="hljs-attr">url</span>: <span class="hljs-string">"your-qdrant-url"</span>,
 <span class="hljs-attr">api_key</span>: <span class="hljs-string">"your-qdrant-api-key"</span>
)
</code></pre>
<h2>Qdrant에서 컬렉션 만들기</h2>
<p>Qdrant에서의 컬렉션은 전통적인 데이터베이스의 테이블과 유사합니다. 벡터와 해당 payload를 저장합니다. 다음은 컬렉션을 만드는 방법입니다:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"># <span class="hljs-title class_">Qdrant</span>에 컬렉션 만들기
collection_name = <span class="hljs-string">'my_collection'</span>
qdrant_client.<span class="hljs-title function_">create_collection</span>(collection_name)
</code></pre>
<h2>컬렉션에 벡터 삽입하기</h2>
<p>컬렉션에 벡터를 삽입합니다. 이러한 벡터는 NLP 모델로부터의 텍스트 임베딩과 같은 다양한 데이터 지점을 나타낼 수 있습니다.</p>
<pre><code class="hljs language-js"># 예시: 벡터를 컬렉션에 삽입하기
vector_id = <span class="hljs-number">1</span>
vector_data = [<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>] # 예시 벡터 데이터
qdrant_client.<span class="hljs-title function_">upsert_points</span>(collection_name, [{ <span class="hljs-attr">id</span>: vector_id, <span class="hljs-attr">vector</span>: vector_data }])
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>비슷한 벡터 검색하기</h2>
<p>Qdrant는 비슷한 벡터를 검색하는 데 능숙합니다. 다음은 벡터 검색을 수행하는 방법입니다:</p>
<pre><code class="hljs language-js"># 벡터 검색 수행
query_vector = [<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>] # 예시 쿼리 벡터
search_results = qdrant_client.<span class="hljs-title function_">search</span>(collection_name, query_vector)
puts search_results
</code></pre>
<h2>Mistral 7B 및 LangChain에 Qdrant 통합</h2>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Qdrant를 Mistral 7B와 LangChain과 통합하는 것은 고급 AI 응용 프로그램을 가능하게 합니다. 예를 들어, AI 생성 콘텐츠로 구동되는 검색 엔진을 만들거나 벡터 기반 검색을 통해 언어 모델을 개선할 수 있습니다.</p>
<pre><code class="hljs language-js"># <span class="hljs-title class_">LangChain</span> 및 <span class="hljs-title class_">HuggingFace</span> 초기화
<span class="hljs-built_in">require</span> <span class="hljs-string">'langchain'</span>
<span class="hljs-built_in">require</span> <span class="hljs-string">'hugging_face'</span>

# <span class="hljs-variable constant_">API</span> 토큰으로 <span class="hljs-title class_">HuggingFace</span> 클라이언트 초기화
client = <span class="hljs-title class_">HuggingFace</span>::<span class="hljs-title class_">InferenceApi</span>.<span class="hljs-title function_">new</span>(<span class="hljs-attr">api_token</span>: <span class="hljs-string">"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"</span>)

# 텍스트 생성 및 임베딩을 위한 모델 정의
mistral_model = <span class="hljs-string">"mistralai/Mistral-7B-v0.1"</span>
embedding_model = <span class="hljs-string">'sentence-transformers/all-MiniLM-L6-v2'</span>

# <span class="hljs-title class_">Mistral</span> 모델을 사용하여 텍스트 생성
text_generation = client.<span class="hljs-title function_">call</span>(<span class="hljs-attr">model</span>: mistral_model, <span class="hljs-attr">input</span>: { <span class="hljs-attr">inputs</span>: <span class="hljs-string">'Can you please let us know more details about your '</span>})

# <span class="hljs-title class_">Mistral</span> 모델을 위한 <span class="hljs-title class_">LangChain</span> 클라이언트 초기화
llm = <span class="hljs-title class_">Langchain</span>::<span class="hljs-attr">LLM</span>::<span class="hljs-title class_">HuggingFaceResponse</span>.<span class="hljs-title function_">new</span>(text_generation, <span class="hljs-attr">model</span>: mistral_model)

# <span class="hljs-title class_">LangChain</span> 응답에서 생성된 텍스트 추출
generated_text = llm.<span class="hljs-property">raw_response</span>[<span class="hljs-number">0</span>][<span class="hljs-string">"generated_text"</span>]

# 생성된 텍스트를 임베딩 모델을 사용하여 임베딩
embedding_text = client.<span class="hljs-title function_">call</span>(<span class="hljs-attr">model</span>: embedding_model, <span class="hljs-attr">input</span>: { <span class="hljs-attr">inputs</span>: generated_text })

# 임베딩 모델을 위한 <span class="hljs-title class_">LangChain</span> 클라이언트 초기화
llm_embed = <span class="hljs-title class_">Langchain</span>::<span class="hljs-attr">LLM</span>::<span class="hljs-title class_">HuggingFaceResponse</span>.<span class="hljs-title function_">new</span>(embedding_text, <span class="hljs-attr">model</span>: embedding_model)

# <span class="hljs-title class_">LangChain</span> 응답에서 임베딩된 텍스트 추출
generated_embed = llm_embed.<span class="hljs-property">raw_response</span>

# 생성된 임베딩 텍스트를 출력
puts generated_embed

# <span class="hljs-title class_">Qdrant</span> 클라이언트 초기화
qdrant_client = <span class="hljs-title class_">Qdrant</span>::<span class="hljs-title class_">Client</span>.<span class="hljs-title function_">new</span>(
 <span class="hljs-attr">url</span>: <span class="hljs-string">"your-qdrant-url"</span>,
 <span class="hljs-attr">api_key</span>: <span class="hljs-string">"your-qdrant-api-key"</span>
)

# 생성된 텍스트를 벡터로 변환하여 <span class="hljs-title class_">Qdrant</span>에 저장
qdrant_client.<span class="hljs-title function_">upsert_points</span>(<span class="hljs-string">'my_collection'</span>, [{ <span class="hljs-attr">id</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">vector</span>: generated_embed }])
</code></pre>
<p>위 예제는 Qdrant가 Ruby 응용 프로그램에 신속하게 통합될 수 있음을 보여줍니다. 이를 통해 현대 AI 및 ML 응용 프로그램에서 중요한 강력한 벡터 기반 작업을 가능하게 합니다. Qdrant의 효율적인 벡터 처리 기능과 Ruby의 간결함과 우아함이 결합되어 개발자들이 고급 데이터 처리 및 검색 시스템을 탐색할 수 있는 새로운 방법이 열립니다.</p>
<h1>Qdrant, Mistral 7B, LangChain 및 Ruby 언어를 사용하여 RAG (LLM) 만들기</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_3.png" alt="RAG Model"></p>
<p>클린체인과 Qdrant를 사용하여 루비 언어로 작성된 LLM 애플리케이션을 구축하는 단계별 가이드에서 Retriever-Augmented Generation (RAG) 모델을 만드는 과정은 고급 AI 분야로의 정교한 진출입니다. 이 섹션에서는 이러한 구성 요소를 통합하여 효율적이고 강력한 RAG 모델을 구축하는 과정을 안내합니다.</p>
<h2>개념적 개요</h2>
<p>Retriever (Qdrant): Qdrant는 RAG 모델에서 우리의 검색기 역할을 합니다. 이는 고차원 벡터(텍스트 데이터의 표현)를 효율적으로 저장하고 검색합니다. 이러한 벡터는 Mistral 7B 모델을 사용하여 텍스트에서 생성할 수 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>생성기 (Mistral 7B):</h2>
<p>Mistral 7B는 transformer 모델로, 생성기 역할을 합니다. 이 모델은 텍스트 임베딩을 생성하는 데 사용되며 (Qdrant에 저장하기 위해) 입력 프롬프트와 Qdrant에서 검색된 문맥 데이터를 기반으로 사람과 유사한 텍스트를 생성합니다.</p>
<p>오케스트레이션 (LangChain):
LangChain은 검색기와 생성기를 결합하여 함께 작동합니다. Qdrant와 Mistral 7B 간의 데이터 흐름을 관리하며, 검색기의 출력이 생성기에 의해 효과적으로 활용되어 관련성이 있는 일관된 텍스트가 생성되도록 보장합니다.</p>
<h2>코드 통합</h2>
<p>이것이 이러한 시스템을 구축하는 구조화된 접근 방식입니다:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>텍스트 생성: Hugging Face API를 사용하여 사용자의 프롬프트를 기반으로 텍스트 생성하기</li>
<li>텍스트 임베딩: 생성된 텍스트를 문장 변환 모델을 사용하여 벡터 표현으로 변환하기</li>
<li>Qdrant 검색: 임베드된 벡터를 사용하여 Qdrant 데이터베이스를 쿼리하고 가장 관련성 있는 데이터 검색하기</li>
<li>응답 구성: 원본 생성된 텍스트와 검색된 정보를 결합하여 최종 응답 형성하기</li>
</ul>
<pre><code class="hljs language-js"><span class="hljs-built_in">require</span> <span class="hljs-string">'langchain'</span>
<span class="hljs-built_in">require</span> <span class="hljs-string">'hugging_face'</span>
<span class="hljs-built_in">require</span> <span class="hljs-string">'qdrant_client'</span>

# <span class="hljs-variable constant_">API</span> 토큰을 사용하여 <span class="hljs-title class_">HuggingFace</span> 클라이언트 초기화
hf_client = <span class="hljs-title class_">HuggingFace</span>::<span class="hljs-title class_">InferenceApi</span>.<span class="hljs-title function_">new</span>(<span class="hljs-attr">api_token</span>: <span class="hljs-string">"your-hf-api-token"</span>)

# 모델 정의
mistral_model = <span class="hljs-string">"mistralai/Mistral-7B-v0.1"</span>
embedding_model = <span class="hljs-string">'sentence-transformers/all-MiniLM-L6-v2'</span>

# 텍스트 생성하는 함수
def <span class="hljs-title function_">generate_text</span>(hf_client, model, prompt)
 response = hf_client.<span class="hljs-title function_">call</span>(<span class="hljs-attr">model</span>: model, <span class="hljs-attr">input</span>: { <span class="hljs-attr">inputs</span>: prompt })
 response[<span class="hljs-number">0</span>][<span class="hljs-string">"generated_text"</span>]
end

# 텍스트 임베딩하는 함수
def <span class="hljs-title function_">embed_text</span>(hf_client, model, text)
 response = hf_client.<span class="hljs-title function_">call</span>(<span class="hljs-attr">model</span>: model, <span class="hljs-attr">input</span>: { <span class="hljs-attr">inputs</span>: text })
 response[<span class="hljs-number">0</span>][<span class="hljs-string">"vector"</span>]
end

# <span class="hljs-title class_">Qdrant</span> 클라이언트 초기화
qdrant_client = <span class="hljs-title class_">Qdrant</span>::<span class="hljs-title class_">Client</span>.<span class="hljs-title function_">new</span>(<span class="hljs-attr">url</span>: <span class="hljs-string">"your-qdrant-url"</span>, <span class="hljs-attr">api_key</span>: <span class="hljs-string">"your-qdrant-api-key"</span>)
# <span class="hljs-title class_">Qdrant</span>에서 데이터를 검색하는 함수
def <span class="hljs-title function_">retrieve_from_qdrant</span>(client, collection, vector, top_k)
 client.<span class="hljs-title function_">search_points</span>(collection, vector, top_k)
end

# 사용자 프롬프트
user_prompt = <span class="hljs-string">"사용자의 프롬프트를 입력하세요"</span>

# 텍스트 생성 및 임베딩
generated_text = <span class="hljs-title function_">generate_text</span>(hf_client, mistral_model, user_prompt)
embedded_vector = <span class="hljs-title function_">embed_text</span>(hf_client, embedding_model, generated_text)

# <span class="hljs-title class_">Qdrant</span>에서 관련 데이터 검색
retrieved_data = <span class="hljs-title function_">retrieve_from_qdrant</span>(qdrant_client, <span class="hljs-string">'your-collection-name'</span>, embedded_vector, <span class="hljs-number">5</span>)

# 응답 구성
final_response = <span class="hljs-string">"생성된 텍스트: #{generated_text}\n\n관련 정보:\n#{retrieved_data}"</span>
puts final_response
</code></pre>
<h2>RAG 모델 결과</h2>
<p>LangChain, Mistral 7B, Qdrant 및 Ruby를 통합하여 Retriever-Augmented Generation (RAG) 모델을 구축한 결과, 성능 평가를 통해 놀라운 결과를 확인할 수 있었습니다. 이 섹션은 핵심 성능 메트릭 및 질적 분석을 강조하며, 또한 RAG 모델의 실제 출력을 포함하여 해당 능력을 시연합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>성능 지표</h2>
<p>정확성: 모델은 맥락적으로 관련성이 높고 일관된 텍스트를 생성하는 데 높은 정확도를 보였습니다. Qdrant의 통합은 언어 모델의 맥락 인식을 효과적으로 증가시켜 더 정확하고 적합한 응답을 이끌어 냈습니다.</p>
<p>속도: GPU 가속을 활용하여 모델은 신속하게 응답하여 실시간 응용 프로그램에 중요한 역할을 합니다. Qdrant로부터 벡터의 신속한 검색과 Mistral 7B에 의한 효율적인 텍스트 생성이 이 속도에 기여했습니다.</p>
<p>확장성: 모델은 데이터 양이 증가함에 따라 성능 효율을 유지하며 원활하게 확장되었습니다. Qdrant의 고차원 벡터 데이터를 견고하게 처리하는 것이 여기서 중요한 역할을 했습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>질적 분석 및 모델 출력</h2>
<p>생성된 텍스트는 구문적으로 맞고 의미론적으로 풍부하여 맥락을 깊이 이해한다는 것을 시사합니다. 예를 들어:</p>
<pre><code class="hljs language-js">입력 프롬프트: <span class="hljs-string">"인공지능의 최신 트렌드는 무엇인가요?"</span>

생성된 텍스트: 인공지능의 최신 트렌드에는 자연어 처리의 발전, 윤리적 <span class="hljs-variable constant_">AI</span>에 대한 관심 증가, 그리고 더 효율적인 기계 학습 알고리즘의 개발이 포함됩니다.
관련 정보:
현대 개발에서의 <span class="hljs-variable constant_">AI</span> 윤리
기계 학습의 효율성: <span class="hljs-number">2024</span>년의 전망
자연어 처리: 언어 장벽 극복
</code></pre>
<p>이 출력물은 모델이 제공된 프롬프트와 잘 일치하면서도 정보를 제공하고 응집된 콘텐츠를 생성할 수 있는 능력을 잘 보여줍니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>사용자 피드백</h2>
<p>사용자들은 이 모델이 미묘하고 문맥을 이해하는 응답을 생성하는 데 효과적이라고 언급했습니다. 또한 루비 환경 내에서의 원활한 통합이 잘 받아들여졌으며, 해당 모델의 실용성과 사용 편의성을 강조했습니다.</p>
<h2>비교 분석</h2>
<p>전통적인 루비 기반 NLP 모델과 비교할 때, 저희 RAG 모델은 문맥 이해와 응답 생성 측면에서 우수한 성능을 보여주었으며, Mistral 7B와 Qdrant와 같이 고급 AI 구성 요소를 통합하는 이점을 강조했습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>사용 사례</h2>
<p>모델은 다양한 분야에서 실용적인 응용 프로그램을 찾아 챗봇 상호 작용, 자동화된 콘텐츠 생성 및 정교한 텍스트 분석과 같은 작업을 개선했습니다.</p>
<h1>결론</h1>
<p>우리가 마침내 도달한 결론은 루비의 영역을 탐험하는 과정은 LangChain, Mistral 7B 및 Qdrant와 같은 최첨단 기술로 보강된 것으로 나타났지만 그것은 과거에만 한하는 것이 아니라 또한 교육적이었습니다. 루비 환경에서 Retriever-Augmented Generation 모델의 성공적인 생성 및 배포는 언어의 응용 분야의 전통적인 경계에 도전했습니다. 이 프로젝트는 루비를 주로 웹 개발에 적합한 언어로 간주하던 것을 뒤엎으며 고급 인공 지능 및 기계 학습 분야에서 미개척된 잠재력을 품고 있다는 것을 명확하게 입증했습니다. 이 프로젝트의 성과인 루비의 복잡한 AI 작업과의 호환성을 강조하고, 세련된 도구들과 신속한 통합 능력, 그리고 RAG 모델의 놀라운 성능을 모두 루비의 능력의 범위를 확대하는 중요한 이정표로 인식하게 됩니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>전망을 바라볼 때, 이 성공적인 통합의 함의는 깊이 있습니다. 이는 루비 개발자들에게 새로운 가능성들을 열어주며, 그들이 자신감을 가지고 AI 분야로 진출하도록 격려합니다. RAG 모델은 루비의 다재다능함과 강력함을 보여주며 복잡하고 컨텍스트에 민감하며 계산적으로 요구되는 작업을 다룹니다. 이 노력은 다양한 영역에서 혁신적인 응용 프로그램을 위한 길을 열 뿐만 아니라 루비 기반의 AI 솔루션을 더 깊게 탐구하고 발전시키는 선례로 남깁니다. AI 및 기계 학습 분야가 계속 발전함에 따라, 루비의 역할은 약속만큼 중요하며 AI 및 기계 학습 기술의 발전된 능력과 함께 루비의 우아함과 효율성이 손에 잡힌다는 미래가 약속됩니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"루비를 사용하여 LLM 애플리케이션을 Langchain과 Qdrant를 이용해 만드는 단계별 가이드","description":"","date":"2024-05-27 16:04","slug":"2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant","content":"\n\u003cimg src=\"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_0.png\" /\u003e\n\n소프트웨어 개발의 세계에서 프로그래밍 언어와 도구의 선택은 단순히 선호도의 문제가 아니라 프로젝트 결과에 상당한 영향을 미칠 수 있는 전략적인 선택입니다. 파이썬이 인공 지능(AI) 및 기계 학습(ML) 애플리케이션에서 선두 주자였던 반면, 루비의 잠재력은 이러한 영역에서 여전히 충분히 발휘되지 않았습니다. 이 안내서는 특히 고급 AI 구현의 맥락에서 루비의 능력을 밝히고자 합니다.\n\n우아하고 간결함으로 유명한 루비는 작성하기 쉽기만한 문법과 읽기 즐거운 문법을 제공합니다. 주로 웹 개발에서 유능함으로 인정받았던 이 언어는 AI 및 ML 분야에서는 과소평가되고 있습니다. 그러나 견고한 프레임워크와 커뮤니티 주도의 접근 방식으로, 루비는 특히 이미 루비 생태계에 몸담은 팀 및 프로젝트에 대한 선택지로 자리잡고 있습니다.\n\n우리의 여정은 루비가 LangChain, Mistral 7B, 그리고 Qdrant Vector DB와 같은 최첨단 기술과 효과적으로 결합되어 얼마나 활용될 수 있는지를 탐색함으로 시작됩니다. 이러한 도구들이 결합되면 정교한 Retriever-Augmented Generation (RAG) 모델을 만들 수 있습니다. 이 모델은 루비가 더 전통적인 AI 언어와 어깨를 나란히 할 수 있는 능력을 보여줍니다. 이는 AI 및 ML 분야에서 새로운 지평을 열어주며 루비 애호가들을 위한 새로운 가능성을 제시합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Ruby 설치 가이드\n\n루비의 이러한 측면을 이해하면 프로그래밍에 가져다주는 가치와 파워를 더욱 높이게 될 것입니다. 설치 과정은 보상을 받는 여정의 첫걸음입니다.\n\n## 원하는 루비 버전 매니저 선택\n\n버전 매니저를 선택하는 것은 집을 건설할 때 올바른 기초를 선택하는 것과 같습니다. 루비의 다양한 버전 및 의존성을 관리하는 데 필수적이기 때문입니다. 이는 루비의 자주 업데이트되는 언어와 서로 다른 프로젝트의 요구 사항 때문에 특히 중요합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## RVM (루비 버전 관리자)\n\n장점: 루비 환경을 효율적으로 관리할 수 있는 방법을 제공합니다. 여러 루비 버전 및 젬 세트(젬셋)를 처리하는 데 좋습니다. 또한 동일한 컴퓨터에서 여러 루비 환경을 설치, 관리 및 사용할 수 있습니다. 이는 여러 프로젝트에 작업하는 개발자에게 이상적입니다.\n\n## 설치 안내\n\n## 시스템 패키지 업데이트\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n시스템을 최신 상태로 유지하려면 다음 명령을 실행하세요:\n\n```bash\nsudo apt update\nsudo apt upgrade\n```\n\n루비 설치에 필요한 종속성을 설치하세요:\n\n```bash\nsudo apt install git curl libssl-dev libreadline-dev zlib1g-dev autoconf bison build-essential libyaml-dev libreadline-dev libncurses5-dev libffi-dev libgdbm-dev\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nsudo apt install rbenv\n```\n\nGitHub에서 가져온 설치 스크립트를 사용하여 rbenv를 설치하세요:\n\n```js\ncurl -fsSL https://github.com/rbenv/rbenv-installer/raw/HEAD/bin/rbenv-installer | bash\n```\n\nrbenv 명령어를 사용하기 위해 $PATH에 ~/.rbenv/bin을 추가하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\necho 'export PATH=\"$HOME/.rbenv/bin:$PATH\"' \u003e\u003e ~/.bashrc\n```\n\nrbenv를 자동으로 로드하도록 초기화 명령어를 추가하세요:\n\n```js\necho 'eval \"$(rbenv init -)\"' \u003e\u003e ~/.bashrc\n```\n\n모든 변경 사항을 쉘 세션에 적용하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```sh\n소스 ~/.bashrc\n```\n\nrbenv이 제대로 설정되었는지 확인하세요:\n\n```sh\ntype rbenv\n```\n\n## Ruby-Build\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n루비 빌드는 유니스류 시스템에서 소스로부터 루비 버전을 설치하는 과정을 간소화하기 위해 설계된 명령줄 유틸리티입니다.\n\n## 루비 버전 설치\n\nrbenv install 명령은 rbenv에 기본적으로 포함되어 있지 않습니다. 대신에 ruby-build 플러그인에서 제공됩니다.\n\n루비를 설치하기 전에 필요한 도구와 라이브러리가 포함된 빌드 환경을 확인하세요. 확인이 완료되면 다음 단계를 따르세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 최신 안정 버전 목록:\n\nrbenv install -l\n\n# 모든 로컬 버전 목록:\n\nrbenv install -L\n\n# Ruby 버전 설치:\n\nrbenv install 3.1.2\n\n# 왜 Ruby를 선택해야 하는가?\n\nRuby는 프로그래밍 세계에서 실무자들 사이에 잘 보호된 비밀 같은 존재입니다. AI와 ML 분야에서 Python의 높은 인기에 가려져, Ruby의 이 분야에서의 능력은 종종 간과되곤 합니다.\n\nRuby의 진정한 강점은 그 간단함에 있으며 사용자들에게 제공하는 생산성입니다. 이 언어의 우아한 구문과 튼튼한 표준 라이브러리는 신속한 개발 주기에 이상적인 후보입니다. 코드 작성의 용이성뿐만 아니라, 그것을 유지하는 용이성에 있습니다. Ruby의 가독성이 뛰어나고 직관적인 코드베이스는 장기 프로젝트를 위한 큰 도움이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n기존 응용 프로그램 스택에서는 이미 Ruby가 핵심 구성 요소로 사용되고 있습니다. 이러한 스택에 AI 기능을 전환하거나 통합하는 것은 새로운 언어인 Python으로 전환할 필요가 없다는 것을 의미합니다. 대신, AI 응용 프로그램에 대한 기존 Ruby 워크플로를 활용하는 것이 실용적이고 효율적인 접근 방법이 될 수 있습니다.\n\n또한 Ruby의 생태계는 AI 및 ML 작업에 적합한 라이브러리와 도구로 장착되어 있습니다. 딥 러닝을 위한 Ruby-DNN과 머신 러닝을 위한 Rumale과 같은 젬들은 Ruby가 이러한 분야에서 점차 늘어나는 능력을 입증하고 있습니다.\n\n따라서 이미 Ruby에 익숙한 응용 프로그램 및 팀에 대해, Ruby를 계속 사용하여 AI 및 ML 작업을 수행하는 것은 안락함뿐만 아니라 전략적 효율성의 문제입니다.\n\n## Ruby로 기본 데이터 처리하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# 간단한 데이터 처리\ndata = [2, 4, 6, 8, 10]\nprocessed_data = data.map { |number| number * 2 }\nputs processed_data\n```\n\n## 출력\n\n```js\n[4, 8, 12, 16, 20];\n```\n\n## 루비로 하는 기본 머신 러닝\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\"rumale\"을 설치하려면 RubyGems 패키지 매니저를 사용하세요. 터미널에서 다음 명령을 실행해주세요:\n\n```js\ngem install rumale\n```\n\n\"rumale\"을 설치한 후에, gem 파일에 다음 줄을 추가해주세요:\n\n```js\ngem \"rumale\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```ruby\n# 단순 선형 회귀를 위해 Rumale 젬을 사용합니다\nrequire 'rumale'\nx = [[1, 2], [2, 3], [3, 4], [4, 5]]\ny = [1, 2, 3, 4]\nmodel = Rumale::LinearModel::LinearRegression.new\nmodel.fit(x, y)\npredictions = model.predict(x)\n# Numo::DFloat를 Ruby 배열로 변환합니다\npredictions_array = predictions.to_a\nputs \"예측 값: #{predictions_array}\"\n```\n\n이 코드 예제들은 Ruby의 간단한 작업 처리 방식을 보여줍니다. 이는 AI 및 ML을 포함한 다양한 응용 프로그램에 대한 접근성과 강력함을 제공합니다.\n\n### 아키텍처: LangChain, Mistral 7B, GPU 노드 위의 Qdrant\n\n저희 Ruby 기반 AI 시스템 아키텍처에서는 LangChain, Mistra 7B, 그리고 Qdrant 세 가지 주요 구성 요소를 통합하고 있습니다. 각 구성 요소는 시스템의 기능성에 중요한 역할을 하며 특히 GPU 노드에서 활용될 때 중요합니다. 각 구성 요소에 대해 자세히 살펴보고 전체 아키텍처에 어떻게 기여하는지 이해해 봅시다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## LangChain\n\nLangChain은 언어 모델의 구축과 활용을 용이하게 하는 오픈 소스 라이브러리입니다. 언어 처리 작업의 복잡성을 추상화하여 개발자가 정교한 NLP 기능을 구현하기 쉽도록 설계되었습니다. Ruby 환경에서 LangChain은 언어 모델과 데이터베이스 간 상호작용을 관리하는 오케스트레이터 역할을 합니다.\n\n## Mistral 7B\n\nMistral 7B는 Transformer 모델의 변형 버전으로, 자연어 처리 작업에서 효율적이고 효과적인 성능으로 알려져 있습니다. AI 및 기계 학습 분야의 선두주자인 Hugging Face에서 제공되며, Mistral 7B는 인간과 유사한 텍스트를 이해하고 생성하는 데 능숙합니다. 우리의 아키텍처에서 Mistral 7B는 핵심 언어 이해 및 생성 작업을 담당합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 큐드런트\n\n큐드런트는 주로 AI 및 ML 애플리케이션에서 찾을 수 있는 고차원 데이터를 처리하기에 최적화된 벡터 데이터베이스로 작용합니다. 이는 벡터의 효율적인 저장 및 검색을 위해 설계되었으며, Mistral 7B와 같은 AI 모델로부터 생성되고 사용되는 데이터를 관리하기에 이상적인 솔루션입니다. 저희 설정에서는 큐드런트가 언어 모델에서 생성된 벡터의 저장을 담당하며, 빠르고 정확한 검색을 용이하게 합니다.\n\n## GPU 노드 활용\n\n이 아키텍처에 GPU 노드를 포함하는 것은 중요합니다. GPU는 병렬 처리 능력을 통해 AI 및 ML에 관련된 계산 집약적 작업에 매우 적합합니다. GPU 노드에서 구성 요소를 실행함으로써 시스템의 성능을 크게 향상시킬 수 있습니다. GPU는 Mistral 7B 및 큐드런트의 작업을 가속화하여 언어 모델이 데이터를 신속하고 효율적으로 처리하도록 보장합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 구성 요소 통합\n\n이러한 구성 요소의 루비 환경 통합은 핵심적입니다. 랭체인은 루비 인터페이스를 통해 미스트랄 7B 모델과 큐드란트 데이터베이스 간 상호 작용을 조율하는 중심 요소로 작용합니다. 미스트랄 7B 모델은 언어 데이터를 처리하고 텍스트를 의미 있는 벡터로 변환한 다음 큐드란트에 의해 저장되고 관리됩니다. 이 설정을 통해 데이터가 효율적으로 처리되고 저장되며 검색되어 GPU의 능력을 최대한 활용할 수 있는 워크플로우가 구축됩니다.\n\n## 루비에서 LangChain 초기화\n\n\"LangChain\"과 \"transformer\"를 설치하려면 RubyGems 패키지 관리자를 사용하십시오. 터미널에서 다음을 실행하십시오:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngem install langchainrb\ngem install hugging-face\n```\n\n이 명령은 LangChain과 transformers 및 그 종속성을 설치합니다. \"langchain\" 및 \"transformers\"를 설치한 후, gem 파일에 다음 줄을 추가하세요:\n\n```js\ngem \"langchainrb\"\ngem \"hugging-face\"\n```\n\n## Hugging Face 및 LangChain과 상호 작용하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```ruby\nrequire 'langchain'\nclient = HuggingFace::InferenceApi.new(api_token:\"hf_llpPsAVgQYqSmWhlC*****\") # add your inference endpoint api key.\nputs client\n```\n\n# 루비에서 Qdrant 클라이언트 설정하기\n\n루비에서 Qdrant와 상호 작용하려면 qdrant_client 젬을 설치해야 합니다. 이 젬은 Qdrant API에 편리한 루비 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치할 수 있습니다:\n\n```sh\ngem install qdrant-ruby\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n“qdrant-ruby”을 설치한 후 젬 파일에 다음 줄을 추가해주세요:\n\n```js\ngem \"qdrant-ruby\"\n```\n\n```js\nrequire 'qdrant'\n# Qdrant 클라이언트를 초기화합니다.\nclient = Qdrant::Client.new(\n url: \"여러분의-qdrant-URL\",\n api_key: \"여러분의-qdrant-API-키\"\n)\n```\n\n이 아키텍처는 루비에서 인공 지능 및 기계 학습에 대한 혁신적인 접근 방식을 보여주며, 해당 언어의 유연성과 첨단 인공 지능 도구 및 기술과 통합할 수 있는 능력을 뽐내고 있습니다. 특히 LangChain, Mistral 7B 및 Qdrant 간의 시너지는 GPU 노드에서 활용될 때 강력하고 효율적인 인공 지능 시스템을 만들어냅니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# LangChain - 루비 설치 가이드\n\n![LangChain](/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_1.png)\n\nLangChain은 언어 모델을 구축하기 위한 혁신적인 라이브러리로, 루비 기반의 AI 아키텍처에서 중심적인 역할을 합니다. 복잡한 언어 처리 작업을 통합하는 간소화된 방법을 제공합니다. 이제 루비 환경에서 LangChain을 설치하고 코드 스니펫을 통해 기본 사용법을 살펴보겠습니다.\n\n## LangChain 설치하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nLangChain을 설치하기 전에 시스템에 Ruby가 설치되어 있는지 확인하세요. LangChain은 Ruby 버전 2.5 이상이 필요합니다. Ruby 버전을 확인하려면 \"ruby -v\" 명령을 사용하실 수 있습니다. 올바른 Ruby 버전이 설치되어 있다면 다음과 같이 설치를 진행할 수 있습니다:\n\n## Ruby 스크립트에 LangChain을 요구하세요\n\n설치 후에는 Ruby 스크립트에 LangChain을 포함하여 사용을 시작할 수 있습니다:\n\n```rb\nrequire 'langchain'\nrequire \"hugging_face\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기에 시작하는 방법이 있습니다:\n\n### 언어 모델 초기화\n\nLangChain을 사용하면 다양한 종류의 언어 모델을 초기화할 수 있습니다. 기본 모델을 초기화하는 예제를 보여드리겠습니다:\n\n```js\nclient = HuggingFace::InferenceApi.new(api_token:\"hf_llpPsAVgQYqSmW*****\")\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Mistral 7B (Hugging Face 모델): 루비 설치 가이드\n\n루비 애플리케이션에 Hugging Face의 Mistral 7B 모델을 통합하는 것은 최첨단 자연어 처리 (NLP) 능력을 활용하는 강력한 방법을 제공합니다. 여기에는 Mistral 7B를 루비에서 설치하고 사용하는 방법에 대한 자세한 안내서 및 시작하는 데 도움이 되는 코드 조각이 포함되어 있습니다.\n\n## 루비에서 Mistral 7B 설치\n\nMistral 7B를 사용하려면 먼저 transformers-ruby 젬을 설치해야 합니다. 이 젬은 Hugging Face의 Transformers 라이브러리에 대한 루비 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngem install hugging-face\n```\n\n## 루비 스크립트에서 HuggingFace 및 LangChain Gem을 요구하십시오\n\n설치한 후에는 HuggingFace 및 LangChain 젬을 루비 스크립트에 포함시키세요:\n\n```js\nrequire 'langchain'\nrequire \"hugging_face\"\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Mistral 7B 모델을 초기화합니다\n\nMistral 7B를 사용하려면 Hugging Face를 사용하여 초기화해야 합니다. 다음은 초기화하는 방법입니다:\n\n```js\n# 텍스트 생성을 위해 Mistral 7B 모델을 초기화합니다\nmodel = \"mistralai/Mistral-7B-v0.1\"\ncall_model = client.call(model:model,input:{ inputs: '더 많은 세부 정보에 대해 알려주시겠어요?'})\n```\n\n## Mistral 7B로 텍스트 생성하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMistral 7B는 텍스트 생성과 같은 다양한 NLP 작업에 사용될 수 있습니다. 아래는 텍스트를 생성하는 예제입니다:\n\n```js\ntest = Langchain::LLM::HuggingFaceResponse.new(call_model, model: model)\nputs test.raw_response[0][\"generated_text\"]\n```\n\n# Qdrant: 루비 설치 안내서\n\n\u003cimg src=\"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_2.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nQdrant은 머신 러닝 작업에 최적화된 강력한 벡터 검색 엔진으로, Ruby에서 AI 애플리케이션에 이상적인 선택지입니다. 이 섹션에서는 Ruby 환경에서 Qdrant를 설치하고 사용하는 방법에 대해 자세히 안내하며, 코드 스니펫이 포함되어 있습니다.\n\n## Ruby에서 Qdrant 설치하기\n\nQdrant 클라이언트 젬 설치\n\nRuby에서 Qdrant와 상호 작용하려면 qdrant_client 젬을 설치해야 합니다. 이 젬은 Qdrant API에 편리한 Ruby 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치하세요:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ngem install qdrant-ruby\n```\n\n“qdrant-ruby”를 설치한 후, 젬 파일에 다음 라인을 추가해주세요:\n\n```js\ngem \"qdrant-ruby\"\n```\n\n# 루비 스크립트에서 Qdrant 클라이언트를 요청하기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이젠 gem을 설치한 후 Ruby 스크립트에 포함하세요:\n\n```js\nrequire 'qdrant'\n```\n\nQdrant 클라이언트를 설치하면 Ruby 어플리케이션에서 해당 기능을 활용할 수 있습니다.\n\n# Qdrant 클라이언트 초기화\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nQdrant 서버에 연결하려면 Qdrant 클라이언트를 초기화하십시오. 로컬 또는 원격으로 실행 중인 Qdrant 서버가 있어야 합니다.\n\n```js\n# Qdrant 클라이언트 초기화\nclient = Qdrant::Client.new(\n url: \"your-qdrant-url\",\n api_key: \"your-qdrant-api-key\"\n)\n```\n\n## Qdrant에서 컬렉션 만들기\n\nQdrant에서의 컬렉션은 전통적인 데이터베이스의 테이블과 유사합니다. 벡터와 해당 payload를 저장합니다. 다음은 컬렉션을 만드는 방법입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\n# Qdrant에 컬렉션 만들기\ncollection_name = 'my_collection'\nqdrant_client.create_collection(collection_name)\n```\n\n## 컬렉션에 벡터 삽입하기\n\n컬렉션에 벡터를 삽입합니다. 이러한 벡터는 NLP 모델로부터의 텍스트 임베딩과 같은 다양한 데이터 지점을 나타낼 수 있습니다.\n\n```js\n# 예시: 벡터를 컬렉션에 삽입하기\nvector_id = 1\nvector_data = [0.1, 0.2, 0.3] # 예시 벡터 데이터\nqdrant_client.upsert_points(collection_name, [{ id: vector_id, vector: vector_data }])\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 비슷한 벡터 검색하기\n\nQdrant는 비슷한 벡터를 검색하는 데 능숙합니다. 다음은 벡터 검색을 수행하는 방법입니다:\n\n```js\n# 벡터 검색 수행\nquery_vector = [0.1, 0.2, 0.3] # 예시 쿼리 벡터\nsearch_results = qdrant_client.search(collection_name, query_vector)\nputs search_results\n```\n\n## Mistral 7B 및 LangChain에 Qdrant 통합\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nQdrant를 Mistral 7B와 LangChain과 통합하는 것은 고급 AI 응용 프로그램을 가능하게 합니다. 예를 들어, AI 생성 콘텐츠로 구동되는 검색 엔진을 만들거나 벡터 기반 검색을 통해 언어 모델을 개선할 수 있습니다.\n\n```js\n# LangChain 및 HuggingFace 초기화\nrequire 'langchain'\nrequire 'hugging_face'\n\n# API 토큰으로 HuggingFace 클라이언트 초기화\nclient = HuggingFace::InferenceApi.new(api_token: \"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\")\n\n# 텍스트 생성 및 임베딩을 위한 모델 정의\nmistral_model = \"mistralai/Mistral-7B-v0.1\"\nembedding_model = 'sentence-transformers/all-MiniLM-L6-v2'\n\n# Mistral 모델을 사용하여 텍스트 생성\ntext_generation = client.call(model: mistral_model, input: { inputs: 'Can you please let us know more details about your '})\n\n# Mistral 모델을 위한 LangChain 클라이언트 초기화\nllm = Langchain::LLM::HuggingFaceResponse.new(text_generation, model: mistral_model)\n\n# LangChain 응답에서 생성된 텍스트 추출\ngenerated_text = llm.raw_response[0][\"generated_text\"]\n\n# 생성된 텍스트를 임베딩 모델을 사용하여 임베딩\nembedding_text = client.call(model: embedding_model, input: { inputs: generated_text })\n\n# 임베딩 모델을 위한 LangChain 클라이언트 초기화\nllm_embed = Langchain::LLM::HuggingFaceResponse.new(embedding_text, model: embedding_model)\n\n# LangChain 응답에서 임베딩된 텍스트 추출\ngenerated_embed = llm_embed.raw_response\n\n# 생성된 임베딩 텍스트를 출력\nputs generated_embed\n\n# Qdrant 클라이언트 초기화\nqdrant_client = Qdrant::Client.new(\n url: \"your-qdrant-url\",\n api_key: \"your-qdrant-api-key\"\n)\n\n# 생성된 텍스트를 벡터로 변환하여 Qdrant에 저장\nqdrant_client.upsert_points('my_collection', [{ id: 1, vector: generated_embed }])\n```\n\n위 예제는 Qdrant가 Ruby 응용 프로그램에 신속하게 통합될 수 있음을 보여줍니다. 이를 통해 현대 AI 및 ML 응용 프로그램에서 중요한 강력한 벡터 기반 작업을 가능하게 합니다. Qdrant의 효율적인 벡터 처리 기능과 Ruby의 간결함과 우아함이 결합되어 개발자들이 고급 데이터 처리 및 검색 시스템을 탐색할 수 있는 새로운 방법이 열립니다.\n\n# Qdrant, Mistral 7B, LangChain 및 Ruby 언어를 사용하여 RAG (LLM) 만들기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![RAG Model](/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_3.png)\n\n클린체인과 Qdrant를 사용하여 루비 언어로 작성된 LLM 애플리케이션을 구축하는 단계별 가이드에서 Retriever-Augmented Generation (RAG) 모델을 만드는 과정은 고급 AI 분야로의 정교한 진출입니다. 이 섹션에서는 이러한 구성 요소를 통합하여 효율적이고 강력한 RAG 모델을 구축하는 과정을 안내합니다.\n\n## 개념적 개요\n\nRetriever (Qdrant): Qdrant는 RAG 모델에서 우리의 검색기 역할을 합니다. 이는 고차원 벡터(텍스트 데이터의 표현)를 효율적으로 저장하고 검색합니다. 이러한 벡터는 Mistral 7B 모델을 사용하여 텍스트에서 생성할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 생성기 (Mistral 7B):\n\nMistral 7B는 transformer 모델로, 생성기 역할을 합니다. 이 모델은 텍스트 임베딩을 생성하는 데 사용되며 (Qdrant에 저장하기 위해) 입력 프롬프트와 Qdrant에서 검색된 문맥 데이터를 기반으로 사람과 유사한 텍스트를 생성합니다.\n\n오케스트레이션 (LangChain):\nLangChain은 검색기와 생성기를 결합하여 함께 작동합니다. Qdrant와 Mistral 7B 간의 데이터 흐름을 관리하며, 검색기의 출력이 생성기에 의해 효과적으로 활용되어 관련성이 있는 일관된 텍스트가 생성되도록 보장합니다.\n\n## 코드 통합\n\n이것이 이러한 시스템을 구축하는 구조화된 접근 방식입니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- 텍스트 생성: Hugging Face API를 사용하여 사용자의 프롬프트를 기반으로 텍스트 생성하기\n- 텍스트 임베딩: 생성된 텍스트를 문장 변환 모델을 사용하여 벡터 표현으로 변환하기\n- Qdrant 검색: 임베드된 벡터를 사용하여 Qdrant 데이터베이스를 쿼리하고 가장 관련성 있는 데이터 검색하기\n- 응답 구성: 원본 생성된 텍스트와 검색된 정보를 결합하여 최종 응답 형성하기\n\n```js\nrequire 'langchain'\nrequire 'hugging_face'\nrequire 'qdrant_client'\n\n# API 토큰을 사용하여 HuggingFace 클라이언트 초기화\nhf_client = HuggingFace::InferenceApi.new(api_token: \"your-hf-api-token\")\n\n# 모델 정의\nmistral_model = \"mistralai/Mistral-7B-v0.1\"\nembedding_model = 'sentence-transformers/all-MiniLM-L6-v2'\n\n# 텍스트 생성하는 함수\ndef generate_text(hf_client, model, prompt)\n response = hf_client.call(model: model, input: { inputs: prompt })\n response[0][\"generated_text\"]\nend\n\n# 텍스트 임베딩하는 함수\ndef embed_text(hf_client, model, text)\n response = hf_client.call(model: model, input: { inputs: text })\n response[0][\"vector\"]\nend\n\n# Qdrant 클라이언트 초기화\nqdrant_client = Qdrant::Client.new(url: \"your-qdrant-url\", api_key: \"your-qdrant-api-key\")\n# Qdrant에서 데이터를 검색하는 함수\ndef retrieve_from_qdrant(client, collection, vector, top_k)\n client.search_points(collection, vector, top_k)\nend\n\n# 사용자 프롬프트\nuser_prompt = \"사용자의 프롬프트를 입력하세요\"\n\n# 텍스트 생성 및 임베딩\ngenerated_text = generate_text(hf_client, mistral_model, user_prompt)\nembedded_vector = embed_text(hf_client, embedding_model, generated_text)\n\n# Qdrant에서 관련 데이터 검색\nretrieved_data = retrieve_from_qdrant(qdrant_client, 'your-collection-name', embedded_vector, 5)\n\n# 응답 구성\nfinal_response = \"생성된 텍스트: #{generated_text}\\n\\n관련 정보:\\n#{retrieved_data}\"\nputs final_response\n```\n\n## RAG 모델 결과\n\nLangChain, Mistral 7B, Qdrant 및 Ruby를 통합하여 Retriever-Augmented Generation (RAG) 모델을 구축한 결과, 성능 평가를 통해 놀라운 결과를 확인할 수 있었습니다. 이 섹션은 핵심 성능 메트릭 및 질적 분석을 강조하며, 또한 RAG 모델의 실제 출력을 포함하여 해당 능력을 시연합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 성능 지표\n\n정확성: 모델은 맥락적으로 관련성이 높고 일관된 텍스트를 생성하는 데 높은 정확도를 보였습니다. Qdrant의 통합은 언어 모델의 맥락 인식을 효과적으로 증가시켜 더 정확하고 적합한 응답을 이끌어 냈습니다.\n\n속도: GPU 가속을 활용하여 모델은 신속하게 응답하여 실시간 응용 프로그램에 중요한 역할을 합니다. Qdrant로부터 벡터의 신속한 검색과 Mistral 7B에 의한 효율적인 텍스트 생성이 이 속도에 기여했습니다.\n\n확장성: 모델은 데이터 양이 증가함에 따라 성능 효율을 유지하며 원활하게 확장되었습니다. Qdrant의 고차원 벡터 데이터를 견고하게 처리하는 것이 여기서 중요한 역할을 했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 질적 분석 및 모델 출력\n\n생성된 텍스트는 구문적으로 맞고 의미론적으로 풍부하여 맥락을 깊이 이해한다는 것을 시사합니다. 예를 들어:\n\n```js\n입력 프롬프트: \"인공지능의 최신 트렌드는 무엇인가요?\"\n\n생성된 텍스트: 인공지능의 최신 트렌드에는 자연어 처리의 발전, 윤리적 AI에 대한 관심 증가, 그리고 더 효율적인 기계 학습 알고리즘의 개발이 포함됩니다.\n관련 정보:\n현대 개발에서의 AI 윤리\n기계 학습의 효율성: 2024년의 전망\n자연어 처리: 언어 장벽 극복\n```\n\n이 출력물은 모델이 제공된 프롬프트와 잘 일치하면서도 정보를 제공하고 응집된 콘텐츠를 생성할 수 있는 능력을 잘 보여줍니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 사용자 피드백\n\n사용자들은 이 모델이 미묘하고 문맥을 이해하는 응답을 생성하는 데 효과적이라고 언급했습니다. 또한 루비 환경 내에서의 원활한 통합이 잘 받아들여졌으며, 해당 모델의 실용성과 사용 편의성을 강조했습니다.\n\n## 비교 분석\n\n전통적인 루비 기반 NLP 모델과 비교할 때, 저희 RAG 모델은 문맥 이해와 응답 생성 측면에서 우수한 성능을 보여주었으며, Mistral 7B와 Qdrant와 같이 고급 AI 구성 요소를 통합하는 이점을 강조했습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 사용 사례\n\n모델은 다양한 분야에서 실용적인 응용 프로그램을 찾아 챗봇 상호 작용, 자동화된 콘텐츠 생성 및 정교한 텍스트 분석과 같은 작업을 개선했습니다.\n\n# 결론\n\n우리가 마침내 도달한 결론은 루비의 영역을 탐험하는 과정은 LangChain, Mistral 7B 및 Qdrant와 같은 최첨단 기술로 보강된 것으로 나타났지만 그것은 과거에만 한하는 것이 아니라 또한 교육적이었습니다. 루비 환경에서 Retriever-Augmented Generation 모델의 성공적인 생성 및 배포는 언어의 응용 분야의 전통적인 경계에 도전했습니다. 이 프로젝트는 루비를 주로 웹 개발에 적합한 언어로 간주하던 것을 뒤엎으며 고급 인공 지능 및 기계 학습 분야에서 미개척된 잠재력을 품고 있다는 것을 명확하게 입증했습니다. 이 프로젝트의 성과인 루비의 복잡한 AI 작업과의 호환성을 강조하고, 세련된 도구들과 신속한 통합 능력, 그리고 RAG 모델의 놀라운 성능을 모두 루비의 능력의 범위를 확대하는 중요한 이정표로 인식하게 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n전망을 바라볼 때, 이 성공적인 통합의 함의는 깊이 있습니다. 이는 루비 개발자들에게 새로운 가능성들을 열어주며, 그들이 자신감을 가지고 AI 분야로 진출하도록 격려합니다. RAG 모델은 루비의 다재다능함과 강력함을 보여주며 복잡하고 컨텍스트에 민감하며 계산적으로 요구되는 작업을 다룹니다. 이 노력은 다양한 영역에서 혁신적인 응용 프로그램을 위한 길을 열 뿐만 아니라 루비 기반의 AI 솔루션을 더 깊게 탐구하고 발전시키는 선례로 남깁니다. AI 및 기계 학습 분야가 계속 발전함에 따라, 루비의 역할은 약속만큼 중요하며 AI 및 기계 학습 기술의 발전된 능력과 함께 루비의 우아함과 효율성이 손에 잡힌다는 미래가 약속됩니다.\n","ogImage":{"url":"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_0.png"},"coverImage":"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_0.png","tag":["Tech"],"readingTime":27},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cimg src=\"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_0.png\"\u003e\n\u003cp\u003e소프트웨어 개발의 세계에서 프로그래밍 언어와 도구의 선택은 단순히 선호도의 문제가 아니라 프로젝트 결과에 상당한 영향을 미칠 수 있는 전략적인 선택입니다. 파이썬이 인공 지능(AI) 및 기계 학습(ML) 애플리케이션에서 선두 주자였던 반면, 루비의 잠재력은 이러한 영역에서 여전히 충분히 발휘되지 않았습니다. 이 안내서는 특히 고급 AI 구현의 맥락에서 루비의 능력을 밝히고자 합니다.\u003c/p\u003e\n\u003cp\u003e우아하고 간결함으로 유명한 루비는 작성하기 쉽기만한 문법과 읽기 즐거운 문법을 제공합니다. 주로 웹 개발에서 유능함으로 인정받았던 이 언어는 AI 및 ML 분야에서는 과소평가되고 있습니다. 그러나 견고한 프레임워크와 커뮤니티 주도의 접근 방식으로, 루비는 특히 이미 루비 생태계에 몸담은 팀 및 프로젝트에 대한 선택지로 자리잡고 있습니다.\u003c/p\u003e\n\u003cp\u003e우리의 여정은 루비가 LangChain, Mistral 7B, 그리고 Qdrant Vector DB와 같은 최첨단 기술과 효과적으로 결합되어 얼마나 활용될 수 있는지를 탐색함으로 시작됩니다. 이러한 도구들이 결합되면 정교한 Retriever-Augmented Generation (RAG) 모델을 만들 수 있습니다. 이 모델은 루비가 더 전통적인 AI 언어와 어깨를 나란히 할 수 있는 능력을 보여줍니다. 이는 AI 및 ML 분야에서 새로운 지평을 열어주며 루비 애호가들을 위한 새로운 가능성을 제시합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003eRuby 설치 가이드\u003c/h1\u003e\n\u003cp\u003e루비의 이러한 측면을 이해하면 프로그래밍에 가져다주는 가치와 파워를 더욱 높이게 될 것입니다. 설치 과정은 보상을 받는 여정의 첫걸음입니다.\u003c/p\u003e\n\u003ch2\u003e원하는 루비 버전 매니저 선택\u003c/h2\u003e\n\u003cp\u003e버전 매니저를 선택하는 것은 집을 건설할 때 올바른 기초를 선택하는 것과 같습니다. 루비의 다양한 버전 및 의존성을 관리하는 데 필수적이기 때문입니다. 이는 루비의 자주 업데이트되는 언어와 서로 다른 프로젝트의 요구 사항 때문에 특히 중요합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003eRVM (루비 버전 관리자)\u003c/h2\u003e\n\u003cp\u003e장점: 루비 환경을 효율적으로 관리할 수 있는 방법을 제공합니다. 여러 루비 버전 및 젬 세트(젬셋)를 처리하는 데 좋습니다. 또한 동일한 컴퓨터에서 여러 루비 환경을 설치, 관리 및 사용할 수 있습니다. 이는 여러 프로젝트에 작업하는 개발자에게 이상적입니다.\u003c/p\u003e\n\u003ch2\u003e설치 안내\u003c/h2\u003e\n\u003ch2\u003e시스템 패키지 업데이트\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e시스템을 최신 상태로 유지하려면 다음 명령을 실행하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003esudo apt update\nsudo apt upgrade\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e루비 설치에 필요한 종속성을 설치하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003esudo apt install git curl libssl-dev libreadline-dev zlib1g-dev autoconf bison build-essential libyaml-dev libreadline-dev libncurses5-dev libffi-dev libgdbm-dev\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003esudo apt install rbenv\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eGitHub에서 가져온 설치 스크립트를 사용하여 rbenv를 설치하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ecurl -fsSL \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//github.com/rbenv/rbenv-installer/raw/HEAD/bin/rbenv-installer | bash\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003erbenv 명령어를 사용하기 위해 $PATH에 ~/.rbenv/bin을 추가하세요.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eecho \u003cspan class=\"hljs-string\"\u003e'export PATH=\"$HOME/.rbenv/bin:$PATH\"'\u003c/span\u003e \u003e\u003e ~/.\u003cspan class=\"hljs-property\"\u003ebashrc\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003erbenv를 자동으로 로드하도록 초기화 명령어를 추가하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eecho \u003cspan class=\"hljs-string\"\u003e'eval \"$(rbenv init -)\"'\u003c/span\u003e \u003e\u003e ~/.\u003cspan class=\"hljs-property\"\u003ebashrc\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e모든 변경 사항을 쉘 세션에 적용하세요:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-sh\"\u003e소스 ~/.bashrc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003erbenv이 제대로 설정되었는지 확인하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-sh\"\u003e\u003cspan class=\"hljs-built_in\"\u003etype\u003c/span\u003e rbenv\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eRuby-Build\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e루비 빌드는 유니스류 시스템에서 소스로부터 루비 버전을 설치하는 과정을 간소화하기 위해 설계된 명령줄 유틸리티입니다.\u003c/p\u003e\n\u003ch2\u003e루비 버전 설치\u003c/h2\u003e\n\u003cp\u003erbenv install 명령은 rbenv에 기본적으로 포함되어 있지 않습니다. 대신에 ruby-build 플러그인에서 제공됩니다.\u003c/p\u003e\n\u003cp\u003e루비를 설치하기 전에 필요한 도구와 라이브러리가 포함된 빌드 환경을 확인하세요. 확인이 완료되면 다음 단계를 따르세요:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e최신 안정 버전 목록:\u003c/h1\u003e\n\u003cp\u003erbenv install -l\u003c/p\u003e\n\u003ch1\u003e모든 로컬 버전 목록:\u003c/h1\u003e\n\u003cp\u003erbenv install -L\u003c/p\u003e\n\u003ch1\u003eRuby 버전 설치:\u003c/h1\u003e\n\u003cp\u003erbenv install 3.1.2\u003c/p\u003e\n\u003ch1\u003e왜 Ruby를 선택해야 하는가?\u003c/h1\u003e\n\u003cp\u003eRuby는 프로그래밍 세계에서 실무자들 사이에 잘 보호된 비밀 같은 존재입니다. AI와 ML 분야에서 Python의 높은 인기에 가려져, Ruby의 이 분야에서의 능력은 종종 간과되곤 합니다.\u003c/p\u003e\n\u003cp\u003eRuby의 진정한 강점은 그 간단함에 있으며 사용자들에게 제공하는 생산성입니다. 이 언어의 우아한 구문과 튼튼한 표준 라이브러리는 신속한 개발 주기에 이상적인 후보입니다. 코드 작성의 용이성뿐만 아니라, 그것을 유지하는 용이성에 있습니다. Ruby의 가독성이 뛰어나고 직관적인 코드베이스는 장기 프로젝트를 위한 큰 도움이 됩니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e기존 응용 프로그램 스택에서는 이미 Ruby가 핵심 구성 요소로 사용되고 있습니다. 이러한 스택에 AI 기능을 전환하거나 통합하는 것은 새로운 언어인 Python으로 전환할 필요가 없다는 것을 의미합니다. 대신, AI 응용 프로그램에 대한 기존 Ruby 워크플로를 활용하는 것이 실용적이고 효율적인 접근 방법이 될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e또한 Ruby의 생태계는 AI 및 ML 작업에 적합한 라이브러리와 도구로 장착되어 있습니다. 딥 러닝을 위한 Ruby-DNN과 머신 러닝을 위한 Rumale과 같은 젬들은 Ruby가 이러한 분야에서 점차 늘어나는 능력을 입증하고 있습니다.\u003c/p\u003e\n\u003cp\u003e따라서 이미 Ruby에 익숙한 응용 프로그램 및 팀에 대해, Ruby를 계속 사용하여 AI 및 ML 작업을 수행하는 것은 안락함뿐만 아니라 전략적 효율성의 문제입니다.\u003c/p\u003e\n\u003ch2\u003eRuby로 기본 데이터 처리하기\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 간단한 데이터 처리\ndata = [\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e]\nprocessed_data = data.\u003cspan class=\"hljs-property\"\u003emap\u003c/span\u003e { |number| number * \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e }\nputs processed_data\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e출력\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e[\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e];\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e루비로 하는 기본 머신 러닝\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\"rumale\"을 설치하려면 RubyGems 패키지 매니저를 사용하세요. 터미널에서 다음 명령을 실행해주세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem install rumale\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\"rumale\"을 설치한 후에, gem 파일에 다음 줄을 추가해주세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem \u003cspan class=\"hljs-string\"\u003e\"rumale\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-ruby\"\u003e\u003cspan class=\"hljs-comment\"\u003e# 단순 선형 회귀를 위해 Rumale 젬을 사용합니다\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'rumale'\u003c/span\u003e\nx = [[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e]]\ny = [\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e]\nmodel = \u003cspan class=\"hljs-title class_\"\u003eRumale\u003c/span\u003e\u003cspan class=\"hljs-symbol\"\u003e:\u003c/span\u003e\u003cspan class=\"hljs-symbol\"\u003e:LinearModel\u003c/span\u003e\u003cspan class=\"hljs-symbol\"\u003e:\u003c/span\u003e\u003cspan class=\"hljs-symbol\"\u003e:LinearRegression\u003c/span\u003e.new\nmodel.fit(x, y)\npredictions = model.predict(x)\n\u003cspan class=\"hljs-comment\"\u003e# Numo::DFloat를 Ruby 배열로 변환합니다\u003c/span\u003e\npredictions_array = predictions.to_a\nputs \u003cspan class=\"hljs-string\"\u003e\"예측 값: \u003cspan class=\"hljs-subst\"\u003e#{predictions_array}\u003c/span\u003e\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 코드 예제들은 Ruby의 간단한 작업 처리 방식을 보여줍니다. 이는 AI 및 ML을 포함한 다양한 응용 프로그램에 대한 접근성과 강력함을 제공합니다.\u003c/p\u003e\n\u003ch3\u003e아키텍처: LangChain, Mistral 7B, GPU 노드 위의 Qdrant\u003c/h3\u003e\n\u003cp\u003e저희 Ruby 기반 AI 시스템 아키텍처에서는 LangChain, Mistra 7B, 그리고 Qdrant 세 가지 주요 구성 요소를 통합하고 있습니다. 각 구성 요소는 시스템의 기능성에 중요한 역할을 하며 특히 GPU 노드에서 활용될 때 중요합니다. 각 구성 요소에 대해 자세히 살펴보고 전체 아키텍처에 어떻게 기여하는지 이해해 봅시다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003eLangChain\u003c/h2\u003e\n\u003cp\u003eLangChain은 언어 모델의 구축과 활용을 용이하게 하는 오픈 소스 라이브러리입니다. 언어 처리 작업의 복잡성을 추상화하여 개발자가 정교한 NLP 기능을 구현하기 쉽도록 설계되었습니다. Ruby 환경에서 LangChain은 언어 모델과 데이터베이스 간 상호작용을 관리하는 오케스트레이터 역할을 합니다.\u003c/p\u003e\n\u003ch2\u003eMistral 7B\u003c/h2\u003e\n\u003cp\u003eMistral 7B는 Transformer 모델의 변형 버전으로, 자연어 처리 작업에서 효율적이고 효과적인 성능으로 알려져 있습니다. AI 및 기계 학습 분야의 선두주자인 Hugging Face에서 제공되며, Mistral 7B는 인간과 유사한 텍스트를 이해하고 생성하는 데 능숙합니다. 우리의 아키텍처에서 Mistral 7B는 핵심 언어 이해 및 생성 작업을 담당합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e큐드런트\u003c/h2\u003e\n\u003cp\u003e큐드런트는 주로 AI 및 ML 애플리케이션에서 찾을 수 있는 고차원 데이터를 처리하기에 최적화된 벡터 데이터베이스로 작용합니다. 이는 벡터의 효율적인 저장 및 검색을 위해 설계되었으며, Mistral 7B와 같은 AI 모델로부터 생성되고 사용되는 데이터를 관리하기에 이상적인 솔루션입니다. 저희 설정에서는 큐드런트가 언어 모델에서 생성된 벡터의 저장을 담당하며, 빠르고 정확한 검색을 용이하게 합니다.\u003c/p\u003e\n\u003ch2\u003eGPU 노드 활용\u003c/h2\u003e\n\u003cp\u003e이 아키텍처에 GPU 노드를 포함하는 것은 중요합니다. GPU는 병렬 처리 능력을 통해 AI 및 ML에 관련된 계산 집약적 작업에 매우 적합합니다. GPU 노드에서 구성 요소를 실행함으로써 시스템의 성능을 크게 향상시킬 수 있습니다. GPU는 Mistral 7B 및 큐드런트의 작업을 가속화하여 언어 모델이 데이터를 신속하고 효율적으로 처리하도록 보장합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e구성 요소 통합\u003c/h2\u003e\n\u003cp\u003e이러한 구성 요소의 루비 환경 통합은 핵심적입니다. 랭체인은 루비 인터페이스를 통해 미스트랄 7B 모델과 큐드란트 데이터베이스 간 상호 작용을 조율하는 중심 요소로 작용합니다. 미스트랄 7B 모델은 언어 데이터를 처리하고 텍스트를 의미 있는 벡터로 변환한 다음 큐드란트에 의해 저장되고 관리됩니다. 이 설정을 통해 데이터가 효율적으로 처리되고 저장되며 검색되어 GPU의 능력을 최대한 활용할 수 있는 워크플로우가 구축됩니다.\u003c/p\u003e\n\u003ch2\u003e루비에서 LangChain 초기화\u003c/h2\u003e\n\u003cp\u003e\"LangChain\"과 \"transformer\"를 설치하려면 RubyGems 패키지 관리자를 사용하십시오. 터미널에서 다음을 실행하십시오:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem install langchainrb\ngem install hugging-face\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 명령은 LangChain과 transformers 및 그 종속성을 설치합니다. \"langchain\" 및 \"transformers\"를 설치한 후, gem 파일에 다음 줄을 추가하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem \u003cspan class=\"hljs-string\"\u003e\"langchainrb\"\u003c/span\u003e\ngem \u003cspan class=\"hljs-string\"\u003e\"hugging-face\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eHugging Face 및 LangChain과 상호 작용하기\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-ruby\"\u003e\u003cspan class=\"hljs-keyword\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'langchain'\u003c/span\u003e\nclient = \u003cspan class=\"hljs-title class_\"\u003eHuggingFace::InferenceApi\u003c/span\u003e.new(\u003cspan class=\"hljs-symbol\"\u003eapi_token:\u003c/span\u003e\u003cspan class=\"hljs-string\"\u003e\"hf_llpPsAVgQYqSmWhlC*****\"\u003c/span\u003e) \u003cspan class=\"hljs-comment\"\u003e# add your inference endpoint api key.\u003c/span\u003e\nputs client\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e루비에서 Qdrant 클라이언트 설정하기\u003c/h1\u003e\n\u003cp\u003e루비에서 Qdrant와 상호 작용하려면 qdrant_client 젬을 설치해야 합니다. 이 젬은 Qdrant API에 편리한 루비 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-sh\"\u003egem install qdrant-ruby\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e“qdrant-ruby”을 설치한 후 젬 파일에 다음 줄을 추가해주세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem \u003cspan class=\"hljs-string\"\u003e\"qdrant-ruby\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'qdrant'\u003c/span\u003e\n# \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e 클라이언트를 초기화합니다.\nclient = \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eClient\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(\n \u003cspan class=\"hljs-attr\"\u003eurl\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"여러분의-qdrant-URL\"\u003c/span\u003e,\n \u003cspan class=\"hljs-attr\"\u003eapi_key\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"여러분의-qdrant-API-키\"\u003c/span\u003e\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 아키텍처는 루비에서 인공 지능 및 기계 학습에 대한 혁신적인 접근 방식을 보여주며, 해당 언어의 유연성과 첨단 인공 지능 도구 및 기술과 통합할 수 있는 능력을 뽐내고 있습니다. 특히 LangChain, Mistral 7B 및 Qdrant 간의 시너지는 GPU 노드에서 활용될 때 강력하고 효율적인 인공 지능 시스템을 만들어냅니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003eLangChain - 루비 설치 가이드\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_1.png\" alt=\"LangChain\"\u003e\u003c/p\u003e\n\u003cp\u003eLangChain은 언어 모델을 구축하기 위한 혁신적인 라이브러리로, 루비 기반의 AI 아키텍처에서 중심적인 역할을 합니다. 복잡한 언어 처리 작업을 통합하는 간소화된 방법을 제공합니다. 이제 루비 환경에서 LangChain을 설치하고 코드 스니펫을 통해 기본 사용법을 살펴보겠습니다.\u003c/p\u003e\n\u003ch2\u003eLangChain 설치하기\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eLangChain을 설치하기 전에 시스템에 Ruby가 설치되어 있는지 확인하세요. LangChain은 Ruby 버전 2.5 이상이 필요합니다. Ruby 버전을 확인하려면 \"ruby -v\" 명령을 사용하실 수 있습니다. 올바른 Ruby 버전이 설치되어 있다면 다음과 같이 설치를 진행할 수 있습니다:\u003c/p\u003e\n\u003ch2\u003eRuby 스크립트에 LangChain을 요구하세요\u003c/h2\u003e\n\u003cp\u003e설치 후에는 Ruby 스크립트에 LangChain을 포함하여 사용을 시작할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-rb\"\u003e\u003cspan class=\"hljs-keyword\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'langchain'\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"hugging_face\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e여기에 시작하는 방법이 있습니다:\u003c/p\u003e\n\u003ch3\u003e언어 모델 초기화\u003c/h3\u003e\n\u003cp\u003eLangChain을 사용하면 다양한 종류의 언어 모델을 초기화할 수 있습니다. 기본 모델을 초기화하는 예제를 보여드리겠습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eclient = \u003cspan class=\"hljs-title class_\"\u003eHuggingFace\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eInferenceApi\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003eapi_token\u003c/span\u003e:\u003cspan class=\"hljs-string\"\u003e\"hf_llpPsAVgQYqSmW*****\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003eMistral 7B (Hugging Face 모델): 루비 설치 가이드\u003c/h1\u003e\n\u003cp\u003e루비 애플리케이션에 Hugging Face의 Mistral 7B 모델을 통합하는 것은 최첨단 자연어 처리 (NLP) 능력을 활용하는 강력한 방법을 제공합니다. 여기에는 Mistral 7B를 루비에서 설치하고 사용하는 방법에 대한 자세한 안내서 및 시작하는 데 도움이 되는 코드 조각이 포함되어 있습니다.\u003c/p\u003e\n\u003ch2\u003e루비에서 Mistral 7B 설치\u003c/h2\u003e\n\u003cp\u003eMistral 7B를 사용하려면 먼저 transformers-ruby 젬을 설치해야 합니다. 이 젬은 Hugging Face의 Transformers 라이브러리에 대한 루비 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치할 수 있습니다:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem install hugging-face\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e루비 스크립트에서 HuggingFace 및 LangChain Gem을 요구하십시오\u003c/h2\u003e\n\u003cp\u003e설치한 후에는 HuggingFace 및 LangChain 젬을 루비 스크립트에 포함시키세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'langchain'\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"hugging_face\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003eMistral 7B 모델을 초기화합니다\u003c/h1\u003e\n\u003cp\u003eMistral 7B를 사용하려면 Hugging Face를 사용하여 초기화해야 합니다. 다음은 초기화하는 방법입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 텍스트 생성을 위해 \u003cspan class=\"hljs-title class_\"\u003eMistral\u003c/span\u003e 7B 모델을 초기화합니다\nmodel = \u003cspan class=\"hljs-string\"\u003e\"mistralai/Mistral-7B-v0.1\"\u003c/span\u003e\ncall_model = client.\u003cspan class=\"hljs-title function_\"\u003ecall\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e:model,\u003cspan class=\"hljs-attr\"\u003einput\u003c/span\u003e:{ \u003cspan class=\"hljs-attr\"\u003einputs\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'더 많은 세부 정보에 대해 알려주시겠어요?'\u003c/span\u003e})\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eMistral 7B로 텍스트 생성하기\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eMistral 7B는 텍스트 생성과 같은 다양한 NLP 작업에 사용될 수 있습니다. 아래는 텍스트를 생성하는 예제입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etest = \u003cspan class=\"hljs-title class_\"\u003eLangchain\u003c/span\u003e::\u003cspan class=\"hljs-attr\"\u003eLLM\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eHuggingFaceResponse\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(call_model, \u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: model)\nputs test.\u003cspan class=\"hljs-property\"\u003eraw_response\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e\"generated_text\"\u003c/span\u003e]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eQdrant: 루비 설치 안내서\u003c/h1\u003e\n\u003cimg src=\"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_2.png\"\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eQdrant은 머신 러닝 작업에 최적화된 강력한 벡터 검색 엔진으로, Ruby에서 AI 애플리케이션에 이상적인 선택지입니다. 이 섹션에서는 Ruby 환경에서 Qdrant를 설치하고 사용하는 방법에 대해 자세히 안내하며, 코드 스니펫이 포함되어 있습니다.\u003c/p\u003e\n\u003ch2\u003eRuby에서 Qdrant 설치하기\u003c/h2\u003e\n\u003cp\u003eQdrant 클라이언트 젬 설치\u003c/p\u003e\n\u003cp\u003eRuby에서 Qdrant와 상호 작용하려면 qdrant_client 젬을 설치해야 합니다. 이 젬은 Qdrant API에 편리한 Ruby 인터페이스를 제공합니다. 터미널을 통해 다음과 같이 설치하세요:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem install qdrant-ruby\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e“qdrant-ruby”를 설치한 후, 젬 파일에 다음 라인을 추가해주세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egem \u003cspan class=\"hljs-string\"\u003e\"qdrant-ruby\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e루비 스크립트에서 Qdrant 클라이언트를 요청하기\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이젠 gem을 설치한 후 Ruby 스크립트에 포함하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'qdrant'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eQdrant 클라이언트를 설치하면 Ruby 어플리케이션에서 해당 기능을 활용할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003eQdrant 클라이언트 초기화\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eQdrant 서버에 연결하려면 Qdrant 클라이언트를 초기화하십시오. 로컬 또는 원격으로 실행 중인 Qdrant 서버가 있어야 합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e 클라이언트 초기화\nclient = \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eClient\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(\n \u003cspan class=\"hljs-attr\"\u003eurl\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"your-qdrant-url\"\u003c/span\u003e,\n \u003cspan class=\"hljs-attr\"\u003eapi_key\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"your-qdrant-api-key\"\u003c/span\u003e\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eQdrant에서 컬렉션 만들기\u003c/h2\u003e\n\u003cp\u003eQdrant에서의 컬렉션은 전통적인 데이터베이스의 테이블과 유사합니다. 벡터와 해당 payload를 저장합니다. 다음은 컬렉션을 만드는 방법입니다:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e에 컬렉션 만들기\ncollection_name = \u003cspan class=\"hljs-string\"\u003e'my_collection'\u003c/span\u003e\nqdrant_client.\u003cspan class=\"hljs-title function_\"\u003ecreate_collection\u003c/span\u003e(collection_name)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e컬렉션에 벡터 삽입하기\u003c/h2\u003e\n\u003cp\u003e컬렉션에 벡터를 삽입합니다. 이러한 벡터는 NLP 모델로부터의 텍스트 임베딩과 같은 다양한 데이터 지점을 나타낼 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 예시: 벡터를 컬렉션에 삽입하기\nvector_id = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\nvector_data = [\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e] # 예시 벡터 데이터\nqdrant_client.\u003cspan class=\"hljs-title function_\"\u003eupsert_points\u003c/span\u003e(collection_name, [{ \u003cspan class=\"hljs-attr\"\u003eid\u003c/span\u003e: vector_id, \u003cspan class=\"hljs-attr\"\u003evector\u003c/span\u003e: vector_data }])\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e비슷한 벡터 검색하기\u003c/h2\u003e\n\u003cp\u003eQdrant는 비슷한 벡터를 검색하는 데 능숙합니다. 다음은 벡터 검색을 수행하는 방법입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 벡터 검색 수행\nquery_vector = [\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e] # 예시 쿼리 벡터\nsearch_results = qdrant_client.\u003cspan class=\"hljs-title function_\"\u003esearch\u003c/span\u003e(collection_name, query_vector)\nputs search_results\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eMistral 7B 및 LangChain에 Qdrant 통합\u003c/h2\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eQdrant를 Mistral 7B와 LangChain과 통합하는 것은 고급 AI 응용 프로그램을 가능하게 합니다. 예를 들어, AI 생성 콘텐츠로 구동되는 검색 엔진을 만들거나 벡터 기반 검색을 통해 언어 모델을 개선할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# \u003cspan class=\"hljs-title class_\"\u003eLangChain\u003c/span\u003e 및 \u003cspan class=\"hljs-title class_\"\u003eHuggingFace\u003c/span\u003e 초기화\n\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'langchain'\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'hugging_face'\u003c/span\u003e\n\n# \u003cspan class=\"hljs-variable constant_\"\u003eAPI\u003c/span\u003e 토큰으로 \u003cspan class=\"hljs-title class_\"\u003eHuggingFace\u003c/span\u003e 클라이언트 초기화\nclient = \u003cspan class=\"hljs-title class_\"\u003eHuggingFace\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eInferenceApi\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003eapi_token\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"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\"\u003c/span\u003e)\n\n# 텍스트 생성 및 임베딩을 위한 모델 정의\nmistral_model = \u003cspan class=\"hljs-string\"\u003e\"mistralai/Mistral-7B-v0.1\"\u003c/span\u003e\nembedding_model = \u003cspan class=\"hljs-string\"\u003e'sentence-transformers/all-MiniLM-L6-v2'\u003c/span\u003e\n\n# \u003cspan class=\"hljs-title class_\"\u003eMistral\u003c/span\u003e 모델을 사용하여 텍스트 생성\ntext_generation = client.\u003cspan class=\"hljs-title function_\"\u003ecall\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: mistral_model, \u003cspan class=\"hljs-attr\"\u003einput\u003c/span\u003e: { \u003cspan class=\"hljs-attr\"\u003einputs\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'Can you please let us know more details about your '\u003c/span\u003e})\n\n# \u003cspan class=\"hljs-title class_\"\u003eMistral\u003c/span\u003e 모델을 위한 \u003cspan class=\"hljs-title class_\"\u003eLangChain\u003c/span\u003e 클라이언트 초기화\nllm = \u003cspan class=\"hljs-title class_\"\u003eLangchain\u003c/span\u003e::\u003cspan class=\"hljs-attr\"\u003eLLM\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eHuggingFaceResponse\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(text_generation, \u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: mistral_model)\n\n# \u003cspan class=\"hljs-title class_\"\u003eLangChain\u003c/span\u003e 응답에서 생성된 텍스트 추출\ngenerated_text = llm.\u003cspan class=\"hljs-property\"\u003eraw_response\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e\"generated_text\"\u003c/span\u003e]\n\n# 생성된 텍스트를 임베딩 모델을 사용하여 임베딩\nembedding_text = client.\u003cspan class=\"hljs-title function_\"\u003ecall\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: embedding_model, \u003cspan class=\"hljs-attr\"\u003einput\u003c/span\u003e: { \u003cspan class=\"hljs-attr\"\u003einputs\u003c/span\u003e: generated_text })\n\n# 임베딩 모델을 위한 \u003cspan class=\"hljs-title class_\"\u003eLangChain\u003c/span\u003e 클라이언트 초기화\nllm_embed = \u003cspan class=\"hljs-title class_\"\u003eLangchain\u003c/span\u003e::\u003cspan class=\"hljs-attr\"\u003eLLM\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eHuggingFaceResponse\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(embedding_text, \u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: embedding_model)\n\n# \u003cspan class=\"hljs-title class_\"\u003eLangChain\u003c/span\u003e 응답에서 임베딩된 텍스트 추출\ngenerated_embed = llm_embed.\u003cspan class=\"hljs-property\"\u003eraw_response\u003c/span\u003e\n\n# 생성된 임베딩 텍스트를 출력\nputs generated_embed\n\n# \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e 클라이언트 초기화\nqdrant_client = \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eClient\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(\n \u003cspan class=\"hljs-attr\"\u003eurl\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"your-qdrant-url\"\u003c/span\u003e,\n \u003cspan class=\"hljs-attr\"\u003eapi_key\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"your-qdrant-api-key\"\u003c/span\u003e\n)\n\n# 생성된 텍스트를 벡터로 변환하여 \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e에 저장\nqdrant_client.\u003cspan class=\"hljs-title function_\"\u003eupsert_points\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'my_collection'\u003c/span\u003e, [{ \u003cspan class=\"hljs-attr\"\u003eid\u003c/span\u003e: \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-attr\"\u003evector\u003c/span\u003e: generated_embed }])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e위 예제는 Qdrant가 Ruby 응용 프로그램에 신속하게 통합될 수 있음을 보여줍니다. 이를 통해 현대 AI 및 ML 응용 프로그램에서 중요한 강력한 벡터 기반 작업을 가능하게 합니다. Qdrant의 효율적인 벡터 처리 기능과 Ruby의 간결함과 우아함이 결합되어 개발자들이 고급 데이터 처리 및 검색 시스템을 탐색할 수 있는 새로운 방법이 열립니다.\u003c/p\u003e\n\u003ch1\u003eQdrant, Mistral 7B, LangChain 및 Ruby 언어를 사용하여 RAG (LLM) 만들기\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant_3.png\" alt=\"RAG Model\"\u003e\u003c/p\u003e\n\u003cp\u003e클린체인과 Qdrant를 사용하여 루비 언어로 작성된 LLM 애플리케이션을 구축하는 단계별 가이드에서 Retriever-Augmented Generation (RAG) 모델을 만드는 과정은 고급 AI 분야로의 정교한 진출입니다. 이 섹션에서는 이러한 구성 요소를 통합하여 효율적이고 강력한 RAG 모델을 구축하는 과정을 안내합니다.\u003c/p\u003e\n\u003ch2\u003e개념적 개요\u003c/h2\u003e\n\u003cp\u003eRetriever (Qdrant): Qdrant는 RAG 모델에서 우리의 검색기 역할을 합니다. 이는 고차원 벡터(텍스트 데이터의 표현)를 효율적으로 저장하고 검색합니다. 이러한 벡터는 Mistral 7B 모델을 사용하여 텍스트에서 생성할 수 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e생성기 (Mistral 7B):\u003c/h2\u003e\n\u003cp\u003eMistral 7B는 transformer 모델로, 생성기 역할을 합니다. 이 모델은 텍스트 임베딩을 생성하는 데 사용되며 (Qdrant에 저장하기 위해) 입력 프롬프트와 Qdrant에서 검색된 문맥 데이터를 기반으로 사람과 유사한 텍스트를 생성합니다.\u003c/p\u003e\n\u003cp\u003e오케스트레이션 (LangChain):\nLangChain은 검색기와 생성기를 결합하여 함께 작동합니다. Qdrant와 Mistral 7B 간의 데이터 흐름을 관리하며, 검색기의 출력이 생성기에 의해 효과적으로 활용되어 관련성이 있는 일관된 텍스트가 생성되도록 보장합니다.\u003c/p\u003e\n\u003ch2\u003e코드 통합\u003c/h2\u003e\n\u003cp\u003e이것이 이러한 시스템을 구축하는 구조화된 접근 방식입니다:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e텍스트 생성: Hugging Face API를 사용하여 사용자의 프롬프트를 기반으로 텍스트 생성하기\u003c/li\u003e\n\u003cli\u003e텍스트 임베딩: 생성된 텍스트를 문장 변환 모델을 사용하여 벡터 표현으로 변환하기\u003c/li\u003e\n\u003cli\u003eQdrant 검색: 임베드된 벡터를 사용하여 Qdrant 데이터베이스를 쿼리하고 가장 관련성 있는 데이터 검색하기\u003c/li\u003e\n\u003cli\u003e응답 구성: 원본 생성된 텍스트와 검색된 정보를 결합하여 최종 응답 형성하기\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'langchain'\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'hugging_face'\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003erequire\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e'qdrant_client'\u003c/span\u003e\n\n# \u003cspan class=\"hljs-variable constant_\"\u003eAPI\u003c/span\u003e 토큰을 사용하여 \u003cspan class=\"hljs-title class_\"\u003eHuggingFace\u003c/span\u003e 클라이언트 초기화\nhf_client = \u003cspan class=\"hljs-title class_\"\u003eHuggingFace\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eInferenceApi\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003eapi_token\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"your-hf-api-token\"\u003c/span\u003e)\n\n# 모델 정의\nmistral_model = \u003cspan class=\"hljs-string\"\u003e\"mistralai/Mistral-7B-v0.1\"\u003c/span\u003e\nembedding_model = \u003cspan class=\"hljs-string\"\u003e'sentence-transformers/all-MiniLM-L6-v2'\u003c/span\u003e\n\n# 텍스트 생성하는 함수\ndef \u003cspan class=\"hljs-title function_\"\u003egenerate_text\u003c/span\u003e(hf_client, model, prompt)\n response = hf_client.\u003cspan class=\"hljs-title function_\"\u003ecall\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: model, \u003cspan class=\"hljs-attr\"\u003einput\u003c/span\u003e: { \u003cspan class=\"hljs-attr\"\u003einputs\u003c/span\u003e: prompt })\n response[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e\"generated_text\"\u003c/span\u003e]\nend\n\n# 텍스트 임베딩하는 함수\ndef \u003cspan class=\"hljs-title function_\"\u003eembed_text\u003c/span\u003e(hf_client, model, text)\n response = hf_client.\u003cspan class=\"hljs-title function_\"\u003ecall\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: model, \u003cspan class=\"hljs-attr\"\u003einput\u003c/span\u003e: { \u003cspan class=\"hljs-attr\"\u003einputs\u003c/span\u003e: text })\n response[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e\"vector\"\u003c/span\u003e]\nend\n\n# \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e 클라이언트 초기화\nqdrant_client = \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eClient\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enew\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003eurl\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"your-qdrant-url\"\u003c/span\u003e, \u003cspan class=\"hljs-attr\"\u003eapi_key\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"your-qdrant-api-key\"\u003c/span\u003e)\n# \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e에서 데이터를 검색하는 함수\ndef \u003cspan class=\"hljs-title function_\"\u003eretrieve_from_qdrant\u003c/span\u003e(client, collection, vector, top_k)\n client.\u003cspan class=\"hljs-title function_\"\u003esearch_points\u003c/span\u003e(collection, vector, top_k)\nend\n\n# 사용자 프롬프트\nuser_prompt = \u003cspan class=\"hljs-string\"\u003e\"사용자의 프롬프트를 입력하세요\"\u003c/span\u003e\n\n# 텍스트 생성 및 임베딩\ngenerated_text = \u003cspan class=\"hljs-title function_\"\u003egenerate_text\u003c/span\u003e(hf_client, mistral_model, user_prompt)\nembedded_vector = \u003cspan class=\"hljs-title function_\"\u003eembed_text\u003c/span\u003e(hf_client, embedding_model, generated_text)\n\n# \u003cspan class=\"hljs-title class_\"\u003eQdrant\u003c/span\u003e에서 관련 데이터 검색\nretrieved_data = \u003cspan class=\"hljs-title function_\"\u003eretrieve_from_qdrant\u003c/span\u003e(qdrant_client, \u003cspan class=\"hljs-string\"\u003e'your-collection-name'\u003c/span\u003e, embedded_vector, \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\n# 응답 구성\nfinal_response = \u003cspan class=\"hljs-string\"\u003e\"생성된 텍스트: #{generated_text}\\n\\n관련 정보:\\n#{retrieved_data}\"\u003c/span\u003e\nputs final_response\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eRAG 모델 결과\u003c/h2\u003e\n\u003cp\u003eLangChain, Mistral 7B, Qdrant 및 Ruby를 통합하여 Retriever-Augmented Generation (RAG) 모델을 구축한 결과, 성능 평가를 통해 놀라운 결과를 확인할 수 있었습니다. 이 섹션은 핵심 성능 메트릭 및 질적 분석을 강조하며, 또한 RAG 모델의 실제 출력을 포함하여 해당 능력을 시연합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e성능 지표\u003c/h2\u003e\n\u003cp\u003e정확성: 모델은 맥락적으로 관련성이 높고 일관된 텍스트를 생성하는 데 높은 정확도를 보였습니다. Qdrant의 통합은 언어 모델의 맥락 인식을 효과적으로 증가시켜 더 정확하고 적합한 응답을 이끌어 냈습니다.\u003c/p\u003e\n\u003cp\u003e속도: GPU 가속을 활용하여 모델은 신속하게 응답하여 실시간 응용 프로그램에 중요한 역할을 합니다. Qdrant로부터 벡터의 신속한 검색과 Mistral 7B에 의한 효율적인 텍스트 생성이 이 속도에 기여했습니다.\u003c/p\u003e\n\u003cp\u003e확장성: 모델은 데이터 양이 증가함에 따라 성능 효율을 유지하며 원활하게 확장되었습니다. Qdrant의 고차원 벡터 데이터를 견고하게 처리하는 것이 여기서 중요한 역할을 했습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e질적 분석 및 모델 출력\u003c/h2\u003e\n\u003cp\u003e생성된 텍스트는 구문적으로 맞고 의미론적으로 풍부하여 맥락을 깊이 이해한다는 것을 시사합니다. 예를 들어:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e입력 프롬프트: \u003cspan class=\"hljs-string\"\u003e\"인공지능의 최신 트렌드는 무엇인가요?\"\u003c/span\u003e\n\n생성된 텍스트: 인공지능의 최신 트렌드에는 자연어 처리의 발전, 윤리적 \u003cspan class=\"hljs-variable constant_\"\u003eAI\u003c/span\u003e에 대한 관심 증가, 그리고 더 효율적인 기계 학습 알고리즘의 개발이 포함됩니다.\n관련 정보:\n현대 개발에서의 \u003cspan class=\"hljs-variable constant_\"\u003eAI\u003c/span\u003e 윤리\n기계 학습의 효율성: \u003cspan class=\"hljs-number\"\u003e2024\u003c/span\u003e년의 전망\n자연어 처리: 언어 장벽 극복\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 출력물은 모델이 제공된 프롬프트와 잘 일치하면서도 정보를 제공하고 응집된 콘텐츠를 생성할 수 있는 능력을 잘 보여줍니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e사용자 피드백\u003c/h2\u003e\n\u003cp\u003e사용자들은 이 모델이 미묘하고 문맥을 이해하는 응답을 생성하는 데 효과적이라고 언급했습니다. 또한 루비 환경 내에서의 원활한 통합이 잘 받아들여졌으며, 해당 모델의 실용성과 사용 편의성을 강조했습니다.\u003c/p\u003e\n\u003ch2\u003e비교 분석\u003c/h2\u003e\n\u003cp\u003e전통적인 루비 기반 NLP 모델과 비교할 때, 저희 RAG 모델은 문맥 이해와 응답 생성 측면에서 우수한 성능을 보여주었으며, Mistral 7B와 Qdrant와 같이 고급 AI 구성 요소를 통합하는 이점을 강조했습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e사용 사례\u003c/h2\u003e\n\u003cp\u003e모델은 다양한 분야에서 실용적인 응용 프로그램을 찾아 챗봇 상호 작용, 자동화된 콘텐츠 생성 및 정교한 텍스트 분석과 같은 작업을 개선했습니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e우리가 마침내 도달한 결론은 루비의 영역을 탐험하는 과정은 LangChain, Mistral 7B 및 Qdrant와 같은 최첨단 기술로 보강된 것으로 나타났지만 그것은 과거에만 한하는 것이 아니라 또한 교육적이었습니다. 루비 환경에서 Retriever-Augmented Generation 모델의 성공적인 생성 및 배포는 언어의 응용 분야의 전통적인 경계에 도전했습니다. 이 프로젝트는 루비를 주로 웹 개발에 적합한 언어로 간주하던 것을 뒤엎으며 고급 인공 지능 및 기계 학습 분야에서 미개척된 잠재력을 품고 있다는 것을 명확하게 입증했습니다. 이 프로젝트의 성과인 루비의 복잡한 AI 작업과의 호환성을 강조하고, 세련된 도구들과 신속한 통합 능력, 그리고 RAG 모델의 놀라운 성능을 모두 루비의 능력의 범위를 확대하는 중요한 이정표로 인식하게 됩니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e전망을 바라볼 때, 이 성공적인 통합의 함의는 깊이 있습니다. 이는 루비 개발자들에게 새로운 가능성들을 열어주며, 그들이 자신감을 가지고 AI 분야로 진출하도록 격려합니다. RAG 모델은 루비의 다재다능함과 강력함을 보여주며 복잡하고 컨텍스트에 민감하며 계산적으로 요구되는 작업을 다룹니다. 이 노력은 다양한 영역에서 혁신적인 응용 프로그램을 위한 길을 열 뿐만 아니라 루비 기반의 AI 솔루션을 더 깊게 탐구하고 발전시키는 선례로 남깁니다. AI 및 기계 학습 분야가 계속 발전함에 따라, 루비의 역할은 약속만큼 중요하며 AI 및 기계 학습 기술의 발전된 능력과 함께 루비의 우아함과 효율성이 손에 잡힌다는 미래가 약속됩니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-27-Step-by-StepGuidetoBuildingLLMApplicationswithRubyUsingLangchainandQdrant"},"buildId":"JlBEgQDLGRx6DYlBnT8eD","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>