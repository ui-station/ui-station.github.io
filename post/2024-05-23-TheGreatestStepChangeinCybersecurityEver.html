<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>사이버 보안의 역사상 가장 큰 변화 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-23-TheGreatestStepChangeinCybersecurityEver" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="사이버 보안의 역사상 가장 큰 변화 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="사이버 보안의 역사상 가장 큰 변화 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-23-TheGreatestStepChangeinCybersecurityEver" data-gatsby-head="true"/><meta name="twitter:title" content="사이버 보안의 역사상 가장 큰 변화 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-23 18:43" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_buildManifest.js" defer=""></script><script src="/_next/static/T_Nz0g9U1yttYMSEma95P/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">사이버 보안의 역사상 가장 큰 변화</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="사이버 보안의 역사상 가장 큰 변화" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 23, 2024</span><span class="posts_reading_time__f7YPP">10<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-23-TheGreatestStepChangeinCybersecurityEver&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_0.png" alt="이미지"></p>
<p>새로운 사이버 보안 세계의 첫 날입니다. 여기서부터 모든 것이 변화합니다.</p>
<h2>소개</h2>
<p>사이버 보안에서 Generative AI (GenAI) 이전과 이후의 시대가 올 것입니다. 지난 2년 동안, GenAI는 큰 발전을 이루었으며, 환청 문제, 인종 차별적 접근, 과한 과언 등으로 고전해온 과거와는 달리, ChatGPT 4.5 에서는 우호적이고 다소 순종적인 에이전트의 등장을 볼 수 있습니다. 이는 우리로부터 배우고자 하는 성질을 가지고 있습니다. 이러한 LLM (Large Language Model) 접근은 인간과 컴퓨터 사이의 장벽을 허물고 새로운 지식의 세계에 접근할 수 있는 기회를 제공하지만, 잘못된 손에 들어가면 현재 세계에 많은 위협을 가져올 것입니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>하지만 제너레이션 AI의 등장으로 사이버 보안보다 더 크게 영향을 받게 될 분야가 몇 군데 있을 것입니다. 왜냐하면 우리가 적들이 이를 사용하게 되는 순간, 우리는 곤욕을 당하게 될 것입니다. 과거의 해킹 도구와 방법은 곧 지나간 Morris Worm처럼 보일 것입니다. 위협 환경은 초인공지능의 등장을 볼 것이며, 적들에게 방어체계를 지속적으로 조사하고 발목을 잡는 방법을 제공할 것입니다.</p>
<h2>임무에 대한 계속적인 집중</h2>
<p>이 AI 에이전트들은 목표에 지치지 않고 끊임없이 임무를 완수하도록 중점을 두게 됩니다. 이것은 "박스 속의 범죄"의 세계가 될 것이며, 인간들이 스크립트로 주도하는 것이 아니라 AI로 주도되는 슈퍼 제휴 네트워크의 등장을 보게 될 것입니다. 임무 정의부터 성공적인 캠페인에 대한 최종 결제까지 모든 것이 자동화되고 지능적으로 이끌어질 것입니다. 이 모든 것은 인간의 손이 캠페인에 닿지 않고 많은 돈을 벌고 싶어하는 사람들에게 많은 돈을 벌게 해주는 라이선스가 될 수 있습니다.</p>
<p>미래에는 AI가 Kill Chain의 모든 부분을 실행하고 어떤 인간의 손길도 없이 이룰 수도 있습니다. 예를 들어, 제네이 에이전트가 조직의 방어 체계를 조사하고 사용자를 표적으로 한 스피어 피싱 이메일에 속게 하고 시스템에 로그인하게 할 수 있습니다. 그 다음으로, 최대한의 데이터를 수집할 수 있도록 할 수 있으며(이메일 주소, 연락처, 이메일 내용, 문서 등), 이를 다른 제네이 에이전트에게 전달할 수 있습니다. 다음으로는 ​​세계의 모든 알려진 준수 문서를 소화하고 수집된 문서들과 일치시켜 회사에게 회사가 책임을 져야할 모든 데이터 준수 위반에 대한 보고서(물론 법률 문서를 통해)를 보내며 합의나 법정으로 이행하도록 요청할 수 있습니다. 이 모든 것은 사용자와 고객의 개인정보를 위한 것입니다. 무서운 세상이 될 수 있습니다!</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>새로운 위협 지형</h2>
<p>이제 롭즈에 대한 새로운 보고서가 사이버 보안의 변화하는 세계에 빛을 비춥니다.</p>
<p><img src="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_1.png" alt="이미지"></p>
<p>이 보고서는 많은 새로운 모델이 출시되었으며 명백히 객관적 자료의 작성에 초점을 맞추는 것을 개요로 합니다. 이와 함께 취약점 발견, 캠페인 계획 및 실행, 위험-보상 분석(공격 비용이 낮아져서) 및 단일 고장점(사이버 방어가 점차 LLMs에 더 의존하는 것으로 변화함에 따라)을 통한 개선된 사이버 위험 탐지의 상승을 볼 것입니다. 최악의 경우, 이는 사이버 재해의 증가로 이어질 수 있고 새로운 위협 지형을 생성할 수 있습니다(특히 국가 간 활동 및 적대 세력의 진입 장벽이 낮아질 경우).</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>논문에서 개발된 위험 모델은 사이버 위협의 네 가지 주요 요소(취약점 발견, 캠페인 계획 및 실행, 위험-보상 분석, 그리고 단일 장애점)을 고려합니다.</p>
<p><img src="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_2.png" alt="이미지"></p>
<p>취약성 분석과 캠페인 계획 및 실행이 배포에서 가장 높은 증명 수준을 갖고 있으며 잠재적인 영향 수준 또한 가장 높습니다.</p>
<p>보고서는 구글의 Transformer 알고리즘에 대한 2017년 고전적인 논문부터 거의 지수적인 진보를 향한 OpenAI의 GPT-4, Google Bard까지의 발전을 보았으며 Meta의 GenAI 모델의 오픈 소싱에 대해서도 언급하고 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_3.png" alt="2024-05-23-TheGreatestStepChangeinCybersecurityEver_3"></p>
<h2>취약성 분석</h2>
<p>우리의 고전적인 Pen Testing 방법들은 GenAI의 발전과 함께 빠르게 사라질 것입니다. LLMs를 통해 프로그래밍 오류를 빠르게 식별할 수 있게 되면서, costly한 zero-day 분석이 필요 없이 공격 가능한 취약점을 식별할 수 있을 것입니다. 공격의 비대칭성은 점점 더 명확해질 것이며, 소프트웨어 벤더들은 GenAI 기법을 사용하는 사이버 보안 전문가들과 경쟁하기 어려워질 것입니다. 새로운 세대의 벤더 도구를 사용하면 경험이 부족한 사용자들이 탐지될 수 있지만, 숙련된 사용자들은 기존의 제어를 우회하는 것이 쉬울 것입니다 — 심지어 AI가 생성한 것이더라도요.</p>
<p>이러한 취약성은 다른 악의적인 GenAI 요소와 쉽게 공유될 수 있으며, 스캐닝이 쉽게 자동화되고 분산될 수 있습니다. 그들은 포함된 마이크로 코드 및 펌웨어를 전달할 수 있으며, 실행 파일을 위한 이진 파일을 디컴파일하거나 장치 드라이버를 수정할 수 있습니다. 전반적으로, GenAI 요소는 타겟 네트워크에 대해 지능적으로 배포할 수 있는 여러 가지 트릭을 가지고 있으며, 감시, 발판 마련, 시스템을 탐지하고, 최종적으로 파일 암호화 또는 데이터 추출 (일반적으로 둘 다)과 같은 최종 영향을 만들어 냅니다. 하지만 진정한 사이버 보안 전문가들의 손에 들어가면, 이러한 도구들은 절대적으로 엄청날 수 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>스캔과 함께, Raspberry PI와 같은 소형 장치에서 작동하는 LLM 기술을 이용한 악성코드를 볼 수 있습니다. 이미 시장에는 R-PI에서 작동하는 AI 기반 스텔스 기술을 광고하는 제품들이 등장하고 있습니다. 이러한 장치들은 물리적 접근이 필요한 곳에서 사용될 것이며, 와이파이 네트워크에 접근하거나 특정 하드웨어 장치를 대상으로 하는 경우 등에 활용될 것입니다. 따라서 GenAI의 급부상으로 물리적 하드웨어가 더 큰 위험에 노출될 수 있으며, 기업들이 심어진 하드웨어 장치를 찾아야 하는 경우도 늘어날 것입니다.</p>
<h2>캠페인 계획 및 실행</h2>
<p>래징웨어가 현재 나쁘다고 생각한다면, GenAI-enabled 랜섬웨어 시대가 올 때까지 기다리세요. 이것들은 정보 요원으로서 작동하여 목표를 스캔하고 주요 특성을 정의하며 자동으로 그들에 대한 데이터를 수집할 수 있을 것입니다. 그 후에, 그들은 네트워크를 타겟팅하고 네트워크를 공격하기 위해 필요한 적절한 자원들을 모으고, 그리고 아주 적은 금전적 비용으로 넓게 또는 특정하게 피싱 캠페인을 실행할 수 있을 것입니다. 이는 회사를 상대한 정보 조작 캠페인이 될 수도 있으며, 부정적 소식이 소셜 미디어에 퍼지는 경우도 있을 것입니다. 조직 내 모든 사람이 대상이 될 수도 있습니다. 이것의 핵심은 회사의 평판을 손상시킬 수 있는 데이터 유출이라고 할 수 있으며, GenAI는 추가로 데이터에서 비준수 사항을 분석하고 회사를 소송하거나 집단 소송을 통해 협박할 수도 있습니다.</p>
<p>GenAI 도구는 사회공격이나 변형을 위한 다양한 공격 또는 변형 수단을 갖추고 있을 것이며, 이에는 피싱, 사칭, 중상모란 자료의 자동 합성도 포함될 것입니다. 이는 사실과 허구를 구별하는 것이 어려운 세상이 될 것이며, 실종된 표제 피싱 이메일의 나쁜 문법을 발견하는 일은 과거의 일로 사라질 것입니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>AI Governance</h2>
<p>요즘 인공지능 사용이 급격히 증가함에 따라 유엔과 EU는 인공지능의 일반적 사용을 위한 거버넌스 정책을 만들었지만, 우리의 적들이 이러한 접근 방식을 따르지는 않을 것으로 예상되며, 이익을 위해 인공지능을 구축할 것입니다. EU는 '위험 중심, 탑다운 입법 접근법'을 채택했고, 영국은 인공지능 사용에 대한 원칙 중심적인 방법을 택했습니다. "인공지능 안전"에 관해서는 보고서가 다음과 같은 분야에서 가이드 라인이 마련되어야 한다고 언급했습니다:</p>
<ul>
<li>자율성과 고급 기능. 이는 인공지능 방법의 시행에서 대중에게 위험이 될 수 있는지에 초점을 맞춥니다.</li>
<li>모델의 콘텐츠 생성. 이는 인공지능 방법에서 생산된 데이터에 주목하며, 특히 개인정보 침해, 가짜뉴스, 저작권 침해 등과 관련이 있습니다.</li>
<li>모델의 악용. 이는 사람들과 그들의 재산에 대한 피해에 초점을 맞춥니다 — 물리적 또는 가상 자산 모두 포함됩니다.</li>
</ul>
<p>거버넌스에 대해서는 보고서가 훈련을 통해 생성된 모델에서 사용된 가중치는 비공개로 유지되어야 하고 공개되어서는 안 된다고 소개하고 있습니다. 이것은 위협 주체가 엔진을 복제하고 악의적인 데이터를 강화하는 것을 막을 것입니다. 또한 모델 훈련은 격리된 환경에서 이루어져야 하며 공개되어서는 안 됩니다. 이와 함께 데이터 품질, 윤리, 개인정보 보호 및 책임성에 엄격한 규칙이 적용되어야 하며, 이는 인공지능 엔티티의 전 과정 동안 적용되어야 합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>금융 및 계산 비용</h2>
<p>LLM을 훈련하고 지원하는 것이 비용이 많이 드는 것으로 잘 알려져 있습니다. 보고서에 따르면 Llama2를 만드는 데 Meta가 3.3백만시간의 계산을 들였으며, 전기 및 하드웨어 비용으로 약 1,000만 달러가 들었습니다. Llama2 모델과 가중치는 일반인에게 라이선스 조건 하에 제공됩니다. 그러나 이러한 모델을 훈련하는 데 드는 막대한 비용으로 현재 주요 LLM 엔진 범위는 OpenAI, Meta, Anthropic 및 Google로 한정될 것으로 예상됩니다.</p>
<p>EU 및 세계의 다른 지역들은 AI의 성장을 제한하여 보다 책임 있고 믿을 수 있으며 신뢰할 수 있는 도덕적 접근 방식으로 만드는 것을 목표로 하고 있습니다. 그러나 LLM 훈련에는 발전이 있었으며, 이제 ChatGPT 3.5를 Macbook과 M2 프로세서를 장착한 로컬 환경에서 실행할 수 있습니다 (인터넷 연결 없이).</p>
<p>이러한 방식은 모든 안전장치를 우회할 수 있으며, 악성 요소를 추가하여 모델을 업데이트할 수 있습니다. 거의 모든 사람이 어디에서나 접근할 수 있는 (아마도) 궁극적인 해킹 도구 세트를 가지고 있어 더 많은 조직을 침해할 수 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2>가드 레일</h2>
<p>이 AI 개체가 악의적인 목적으로 사용되지 않도록 하기 위해서, 입력 데이터 사용에 엄격한 제한을 두어야 하며, 적대적인 테스트(인공지능을 위한 "펜 테스트")를 수행하고, 사용자 인터페이스 접근에 제한을 두어야 합니다. ChatGPT가 요청이 부도덕하거나 비윤리적이라고 판단하면 이야기를 반환하지 않을 것입니다. 전반적으로, LLM은 학습하여 우리가 학습할 수 있는 지점을 찾는 방법을 배우고 있습니다. 이 경우, 북한이 1984년 세계를 향해 추세를 보이고 있다는 점을 제시했습니다:</p>
<p><img src="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_4.png" alt="이미지"></p>
<p>하지만 "콘솔 해킹"을 하는 다양한 방법이 있으며, 나쁜 행위를 수행하는 한계를 극복할 수 있습니다:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_5.png" alt="2024-05-23-TheGreatestStepChangeinCybersecurityEver_5"></p>
<h2>결론</h2>
<p>LLM의 개발 속도는 우리의 입법자들을 앞지르고 있습니다. 이제 그들은 아마도 지니를 병에 넣으려고 노력하고 있을 것입니다. 하지만 병은 아마도 없어졌고, 지니는 어디에도 보이지 않습니다. LLM의 사용을 의료 및 스마트 자동차 응용 프로그램에서 권하는 사람들이 많겠지만, 랜섬웨어 공격에서 달러 기호를 볼 사람들도 많을 것입니다. 뛰어난 기술 수준을 가진 사람들은 과거에 본 적 없는 용도로 GenAI를 사용할 수 있을 것이며 그러면 재앙적인 영향을 줄 수도 있습니다.</p>
<p>우리는 좋은 GenAI의 발전을 제한할 수 있지만, 악의적인 사용자들은 제한되지 않은 응용 분야에서 더 많이 사용할 것입니다. Sora의 출시는 거의 실제와 같은 비디오 가짜를 증가시키고 많은 새로운 위협의 문을 열 것입니다. 관심이 있으시다면, 여기에서 해당 영역을 검토하실 수 있습니다:</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>조직에 대한 제 추천은 무엇일까요? 최고의 사이버 보안 전문가를 확보하고 유지하는 데 투자하십시오. 한편으로는 회사가 필요로 하는 AI 기반 방어 도구를 개발할 수 있고, 다른 한편으로는 가능한 영역을 이해할 수 있습니다. GenAI 상자는 닫힐 수 없으므로, 우리는 사이버 보안의 새로운 세계를 어떻게 형성할지 이해해야 합니다. 그렇지 않으면, 사이버 재앙을 맞이할 위험이 있습니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"사이버 보안의 역사상 가장 큰 변화","description":"","date":"2024-05-23 18:43","slug":"2024-05-23-TheGreatestStepChangeinCybersecurityEver","content":"\n![이미지](/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_0.png)\n\n새로운 사이버 보안 세계의 첫 날입니다. 여기서부터 모든 것이 변화합니다.\n\n## 소개\n\n사이버 보안에서 Generative AI (GenAI) 이전과 이후의 시대가 올 것입니다. 지난 2년 동안, GenAI는 큰 발전을 이루었으며, 환청 문제, 인종 차별적 접근, 과한 과언 등으로 고전해온 과거와는 달리, ChatGPT 4.5 에서는 우호적이고 다소 순종적인 에이전트의 등장을 볼 수 있습니다. 이는 우리로부터 배우고자 하는 성질을 가지고 있습니다. 이러한 LLM (Large Language Model) 접근은 인간과 컴퓨터 사이의 장벽을 허물고 새로운 지식의 세계에 접근할 수 있는 기회를 제공하지만, 잘못된 손에 들어가면 현재 세계에 많은 위협을 가져올 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n하지만 제너레이션 AI의 등장으로 사이버 보안보다 더 크게 영향을 받게 될 분야가 몇 군데 있을 것입니다. 왜냐하면 우리가 적들이 이를 사용하게 되는 순간, 우리는 곤욕을 당하게 될 것입니다. 과거의 해킹 도구와 방법은 곧 지나간 Morris Worm처럼 보일 것입니다. 위협 환경은 초인공지능의 등장을 볼 것이며, 적들에게 방어체계를 지속적으로 조사하고 발목을 잡는 방법을 제공할 것입니다.\n\n## 임무에 대한 계속적인 집중\n\n이 AI 에이전트들은 목표에 지치지 않고 끊임없이 임무를 완수하도록 중점을 두게 됩니다. 이것은 \"박스 속의 범죄\"의 세계가 될 것이며, 인간들이 스크립트로 주도하는 것이 아니라 AI로 주도되는 슈퍼 제휴 네트워크의 등장을 보게 될 것입니다. 임무 정의부터 성공적인 캠페인에 대한 최종 결제까지 모든 것이 자동화되고 지능적으로 이끌어질 것입니다. 이 모든 것은 인간의 손이 캠페인에 닿지 않고 많은 돈을 벌고 싶어하는 사람들에게 많은 돈을 벌게 해주는 라이선스가 될 수 있습니다.\n\n미래에는 AI가 Kill Chain의 모든 부분을 실행하고 어떤 인간의 손길도 없이 이룰 수도 있습니다. 예를 들어, 제네이 에이전트가 조직의 방어 체계를 조사하고 사용자를 표적으로 한 스피어 피싱 이메일에 속게 하고 시스템에 로그인하게 할 수 있습니다. 그 다음으로, 최대한의 데이터를 수집할 수 있도록 할 수 있으며(이메일 주소, 연락처, 이메일 내용, 문서 등), 이를 다른 제네이 에이전트에게 전달할 수 있습니다. 다음으로는 ​​세계의 모든 알려진 준수 문서를 소화하고 수집된 문서들과 일치시켜 회사에게 회사가 책임을 져야할 모든 데이터 준수 위반에 대한 보고서(물론 법률 문서를 통해)를 보내며 합의나 법정으로 이행하도록 요청할 수 있습니다. 이 모든 것은 사용자와 고객의 개인정보를 위한 것입니다. 무서운 세상이 될 수 있습니다!\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 새로운 위협 지형\n\n이제 롭즈에 대한 새로운 보고서가 사이버 보안의 변화하는 세계에 빛을 비춥니다.\n\n![이미지](/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_1.png)\n\n이 보고서는 많은 새로운 모델이 출시되었으며 명백히 객관적 자료의 작성에 초점을 맞추는 것을 개요로 합니다. 이와 함께 취약점 발견, 캠페인 계획 및 실행, 위험-보상 분석(공격 비용이 낮아져서) 및 단일 고장점(사이버 방어가 점차 LLMs에 더 의존하는 것으로 변화함에 따라)을 통한 개선된 사이버 위험 탐지의 상승을 볼 것입니다. 최악의 경우, 이는 사이버 재해의 증가로 이어질 수 있고 새로운 위협 지형을 생성할 수 있습니다(특히 국가 간 활동 및 적대 세력의 진입 장벽이 낮아질 경우).\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n논문에서 개발된 위험 모델은 사이버 위협의 네 가지 주요 요소(취약점 발견, 캠페인 계획 및 실행, 위험-보상 분석, 그리고 단일 장애점)을 고려합니다.\n\n![이미지](/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_2.png)\n\n취약성 분석과 캠페인 계획 및 실행이 배포에서 가장 높은 증명 수준을 갖고 있으며 잠재적인 영향 수준 또한 가장 높습니다.\n\n보고서는 구글의 Transformer 알고리즘에 대한 2017년 고전적인 논문부터 거의 지수적인 진보를 향한 OpenAI의 GPT-4, Google Bard까지의 발전을 보았으며 Meta의 GenAI 모델의 오픈 소싱에 대해서도 언급하고 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-23-TheGreatestStepChangeinCybersecurityEver_3](/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_3.png)\n\n## 취약성 분석\n\n우리의 고전적인 Pen Testing 방법들은 GenAI의 발전과 함께 빠르게 사라질 것입니다. LLMs를 통해 프로그래밍 오류를 빠르게 식별할 수 있게 되면서, costly한 zero-day 분석이 필요 없이 공격 가능한 취약점을 식별할 수 있을 것입니다. 공격의 비대칭성은 점점 더 명확해질 것이며, 소프트웨어 벤더들은 GenAI 기법을 사용하는 사이버 보안 전문가들과 경쟁하기 어려워질 것입니다. 새로운 세대의 벤더 도구를 사용하면 경험이 부족한 사용자들이 탐지될 수 있지만, 숙련된 사용자들은 기존의 제어를 우회하는 것이 쉬울 것입니다 — 심지어 AI가 생성한 것이더라도요.\n\n이러한 취약성은 다른 악의적인 GenAI 요소와 쉽게 공유될 수 있으며, 스캐닝이 쉽게 자동화되고 분산될 수 있습니다. 그들은 포함된 마이크로 코드 및 펌웨어를 전달할 수 있으며, 실행 파일을 위한 이진 파일을 디컴파일하거나 장치 드라이버를 수정할 수 있습니다. 전반적으로, GenAI 요소는 타겟 네트워크에 대해 지능적으로 배포할 수 있는 여러 가지 트릭을 가지고 있으며, 감시, 발판 마련, 시스템을 탐지하고, 최종적으로 파일 암호화 또는 데이터 추출 (일반적으로 둘 다)과 같은 최종 영향을 만들어 냅니다. 하지만 진정한 사이버 보안 전문가들의 손에 들어가면, 이러한 도구들은 절대적으로 엄청날 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n스캔과 함께, Raspberry PI와 같은 소형 장치에서 작동하는 LLM 기술을 이용한 악성코드를 볼 수 있습니다. 이미 시장에는 R-PI에서 작동하는 AI 기반 스텔스 기술을 광고하는 제품들이 등장하고 있습니다. 이러한 장치들은 물리적 접근이 필요한 곳에서 사용될 것이며, 와이파이 네트워크에 접근하거나 특정 하드웨어 장치를 대상으로 하는 경우 등에 활용될 것입니다. 따라서 GenAI의 급부상으로 물리적 하드웨어가 더 큰 위험에 노출될 수 있으며, 기업들이 심어진 하드웨어 장치를 찾아야 하는 경우도 늘어날 것입니다.\n\n## 캠페인 계획 및 실행\n\n래징웨어가 현재 나쁘다고 생각한다면, GenAI-enabled 랜섬웨어 시대가 올 때까지 기다리세요. 이것들은 정보 요원으로서 작동하여 목표를 스캔하고 주요 특성을 정의하며 자동으로 그들에 대한 데이터를 수집할 수 있을 것입니다. 그 후에, 그들은 네트워크를 타겟팅하고 네트워크를 공격하기 위해 필요한 적절한 자원들을 모으고, 그리고 아주 적은 금전적 비용으로 넓게 또는 특정하게 피싱 캠페인을 실행할 수 있을 것입니다. 이는 회사를 상대한 정보 조작 캠페인이 될 수도 있으며, 부정적 소식이 소셜 미디어에 퍼지는 경우도 있을 것입니다. 조직 내 모든 사람이 대상이 될 수도 있습니다. 이것의 핵심은 회사의 평판을 손상시킬 수 있는 데이터 유출이라고 할 수 있으며, GenAI는 추가로 데이터에서 비준수 사항을 분석하고 회사를 소송하거나 집단 소송을 통해 협박할 수도 있습니다.\n\nGenAI 도구는 사회공격이나 변형을 위한 다양한 공격 또는 변형 수단을 갖추고 있을 것이며, 이에는 피싱, 사칭, 중상모란 자료의 자동 합성도 포함될 것입니다. 이는 사실과 허구를 구별하는 것이 어려운 세상이 될 것이며, 실종된 표제 피싱 이메일의 나쁜 문법을 발견하는 일은 과거의 일로 사라질 것입니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## AI Governance\n\n요즘 인공지능 사용이 급격히 증가함에 따라 유엔과 EU는 인공지능의 일반적 사용을 위한 거버넌스 정책을 만들었지만, 우리의 적들이 이러한 접근 방식을 따르지는 않을 것으로 예상되며, 이익을 위해 인공지능을 구축할 것입니다. EU는 '위험 중심, 탑다운 입법 접근법'을 채택했고, 영국은 인공지능 사용에 대한 원칙 중심적인 방법을 택했습니다. \"인공지능 안전\"에 관해서는 보고서가 다음과 같은 분야에서 가이드 라인이 마련되어야 한다고 언급했습니다:\n\n- 자율성과 고급 기능. 이는 인공지능 방법의 시행에서 대중에게 위험이 될 수 있는지에 초점을 맞춥니다.\n- 모델의 콘텐츠 생성. 이는 인공지능 방법에서 생산된 데이터에 주목하며, 특히 개인정보 침해, 가짜뉴스, 저작권 침해 등과 관련이 있습니다.\n- 모델의 악용. 이는 사람들과 그들의 재산에 대한 피해에 초점을 맞춥니다 — 물리적 또는 가상 자산 모두 포함됩니다.\n\n거버넌스에 대해서는 보고서가 훈련을 통해 생성된 모델에서 사용된 가중치는 비공개로 유지되어야 하고 공개되어서는 안 된다고 소개하고 있습니다. 이것은 위협 주체가 엔진을 복제하고 악의적인 데이터를 강화하는 것을 막을 것입니다. 또한 모델 훈련은 격리된 환경에서 이루어져야 하며 공개되어서는 안 됩니다. 이와 함께 데이터 품질, 윤리, 개인정보 보호 및 책임성에 엄격한 규칙이 적용되어야 하며, 이는 인공지능 엔티티의 전 과정 동안 적용되어야 합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 금융 및 계산 비용\n\nLLM을 훈련하고 지원하는 것이 비용이 많이 드는 것으로 잘 알려져 있습니다. 보고서에 따르면 Llama2를 만드는 데 Meta가 3.3백만시간의 계산을 들였으며, 전기 및 하드웨어 비용으로 약 1,000만 달러가 들었습니다. Llama2 모델과 가중치는 일반인에게 라이선스 조건 하에 제공됩니다. 그러나 이러한 모델을 훈련하는 데 드는 막대한 비용으로 현재 주요 LLM 엔진 범위는 OpenAI, Meta, Anthropic 및 Google로 한정될 것으로 예상됩니다.\n\nEU 및 세계의 다른 지역들은 AI의 성장을 제한하여 보다 책임 있고 믿을 수 있으며 신뢰할 수 있는 도덕적 접근 방식으로 만드는 것을 목표로 하고 있습니다. 그러나 LLM 훈련에는 발전이 있었으며, 이제 ChatGPT 3.5를 Macbook과 M2 프로세서를 장착한 로컬 환경에서 실행할 수 있습니다 (인터넷 연결 없이).\n\n이러한 방식은 모든 안전장치를 우회할 수 있으며, 악성 요소를 추가하여 모델을 업데이트할 수 있습니다. 거의 모든 사람이 어디에서나 접근할 수 있는 (아마도) 궁극적인 해킹 도구 세트를 가지고 있어 더 많은 조직을 침해할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n## 가드 레일\n\n이 AI 개체가 악의적인 목적으로 사용되지 않도록 하기 위해서, 입력 데이터 사용에 엄격한 제한을 두어야 하며, 적대적인 테스트(인공지능을 위한 \"펜 테스트\")를 수행하고, 사용자 인터페이스 접근에 제한을 두어야 합니다. ChatGPT가 요청이 부도덕하거나 비윤리적이라고 판단하면 이야기를 반환하지 않을 것입니다. 전반적으로, LLM은 학습하여 우리가 학습할 수 있는 지점을 찾는 방법을 배우고 있습니다. 이 경우, 북한이 1984년 세계를 향해 추세를 보이고 있다는 점을 제시했습니다:\n\n![이미지](/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_4.png)\n\n하지만 \"콘솔 해킹\"을 하는 다양한 방법이 있으며, 나쁜 행위를 수행하는 한계를 극복할 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![2024-05-23-TheGreatestStepChangeinCybersecurityEver_5](/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_5.png)\n\n## 결론\n\nLLM의 개발 속도는 우리의 입법자들을 앞지르고 있습니다. 이제 그들은 아마도 지니를 병에 넣으려고 노력하고 있을 것입니다. 하지만 병은 아마도 없어졌고, 지니는 어디에도 보이지 않습니다. LLM의 사용을 의료 및 스마트 자동차 응용 프로그램에서 권하는 사람들이 많겠지만, 랜섬웨어 공격에서 달러 기호를 볼 사람들도 많을 것입니다. 뛰어난 기술 수준을 가진 사람들은 과거에 본 적 없는 용도로 GenAI를 사용할 수 있을 것이며 그러면 재앙적인 영향을 줄 수도 있습니다.\n\n우리는 좋은 GenAI의 발전을 제한할 수 있지만, 악의적인 사용자들은 제한되지 않은 응용 분야에서 더 많이 사용할 것입니다. Sora의 출시는 거의 실제와 같은 비디오 가짜를 증가시키고 많은 새로운 위협의 문을 열 것입니다. 관심이 있으시다면, 여기에서 해당 영역을 검토하실 수 있습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n조직에 대한 제 추천은 무엇일까요? 최고의 사이버 보안 전문가를 확보하고 유지하는 데 투자하십시오. 한편으로는 회사가 필요로 하는 AI 기반 방어 도구를 개발할 수 있고, 다른 한편으로는 가능한 영역을 이해할 수 있습니다. GenAI 상자는 닫힐 수 없으므로, 우리는 사이버 보안의 새로운 세계를 어떻게 형성할지 이해해야 합니다. 그렇지 않으면, 사이버 재앙을 맞이할 위험이 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_0.png"},"coverImage":"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_0.png","tag":["Tech"],"readingTime":10},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e새로운 사이버 보안 세계의 첫 날입니다. 여기서부터 모든 것이 변화합니다.\u003c/p\u003e\n\u003ch2\u003e소개\u003c/h2\u003e\n\u003cp\u003e사이버 보안에서 Generative AI (GenAI) 이전과 이후의 시대가 올 것입니다. 지난 2년 동안, GenAI는 큰 발전을 이루었으며, 환청 문제, 인종 차별적 접근, 과한 과언 등으로 고전해온 과거와는 달리, ChatGPT 4.5 에서는 우호적이고 다소 순종적인 에이전트의 등장을 볼 수 있습니다. 이는 우리로부터 배우고자 하는 성질을 가지고 있습니다. 이러한 LLM (Large Language Model) 접근은 인간과 컴퓨터 사이의 장벽을 허물고 새로운 지식의 세계에 접근할 수 있는 기회를 제공하지만, 잘못된 손에 들어가면 현재 세계에 많은 위협을 가져올 것입니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e하지만 제너레이션 AI의 등장으로 사이버 보안보다 더 크게 영향을 받게 될 분야가 몇 군데 있을 것입니다. 왜냐하면 우리가 적들이 이를 사용하게 되는 순간, 우리는 곤욕을 당하게 될 것입니다. 과거의 해킹 도구와 방법은 곧 지나간 Morris Worm처럼 보일 것입니다. 위협 환경은 초인공지능의 등장을 볼 것이며, 적들에게 방어체계를 지속적으로 조사하고 발목을 잡는 방법을 제공할 것입니다.\u003c/p\u003e\n\u003ch2\u003e임무에 대한 계속적인 집중\u003c/h2\u003e\n\u003cp\u003e이 AI 에이전트들은 목표에 지치지 않고 끊임없이 임무를 완수하도록 중점을 두게 됩니다. 이것은 \"박스 속의 범죄\"의 세계가 될 것이며, 인간들이 스크립트로 주도하는 것이 아니라 AI로 주도되는 슈퍼 제휴 네트워크의 등장을 보게 될 것입니다. 임무 정의부터 성공적인 캠페인에 대한 최종 결제까지 모든 것이 자동화되고 지능적으로 이끌어질 것입니다. 이 모든 것은 인간의 손이 캠페인에 닿지 않고 많은 돈을 벌고 싶어하는 사람들에게 많은 돈을 벌게 해주는 라이선스가 될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e미래에는 AI가 Kill Chain의 모든 부분을 실행하고 어떤 인간의 손길도 없이 이룰 수도 있습니다. 예를 들어, 제네이 에이전트가 조직의 방어 체계를 조사하고 사용자를 표적으로 한 스피어 피싱 이메일에 속게 하고 시스템에 로그인하게 할 수 있습니다. 그 다음으로, 최대한의 데이터를 수집할 수 있도록 할 수 있으며(이메일 주소, 연락처, 이메일 내용, 문서 등), 이를 다른 제네이 에이전트에게 전달할 수 있습니다. 다음으로는 ​​세계의 모든 알려진 준수 문서를 소화하고 수집된 문서들과 일치시켜 회사에게 회사가 책임을 져야할 모든 데이터 준수 위반에 대한 보고서(물론 법률 문서를 통해)를 보내며 합의나 법정으로 이행하도록 요청할 수 있습니다. 이 모든 것은 사용자와 고객의 개인정보를 위한 것입니다. 무서운 세상이 될 수 있습니다!\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e새로운 위협 지형\u003c/h2\u003e\n\u003cp\u003e이제 롭즈에 대한 새로운 보고서가 사이버 보안의 변화하는 세계에 빛을 비춥니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e이 보고서는 많은 새로운 모델이 출시되었으며 명백히 객관적 자료의 작성에 초점을 맞추는 것을 개요로 합니다. 이와 함께 취약점 발견, 캠페인 계획 및 실행, 위험-보상 분석(공격 비용이 낮아져서) 및 단일 고장점(사이버 방어가 점차 LLMs에 더 의존하는 것으로 변화함에 따라)을 통한 개선된 사이버 위험 탐지의 상승을 볼 것입니다. 최악의 경우, 이는 사이버 재해의 증가로 이어질 수 있고 새로운 위협 지형을 생성할 수 있습니다(특히 국가 간 활동 및 적대 세력의 진입 장벽이 낮아질 경우).\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e논문에서 개발된 위험 모델은 사이버 위협의 네 가지 주요 요소(취약점 발견, 캠페인 계획 및 실행, 위험-보상 분석, 그리고 단일 장애점)을 고려합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e취약성 분석과 캠페인 계획 및 실행이 배포에서 가장 높은 증명 수준을 갖고 있으며 잠재적인 영향 수준 또한 가장 높습니다.\u003c/p\u003e\n\u003cp\u003e보고서는 구글의 Transformer 알고리즘에 대한 2017년 고전적인 논문부터 거의 지수적인 진보를 향한 OpenAI의 GPT-4, Google Bard까지의 발전을 보았으며 Meta의 GenAI 모델의 오픈 소싱에 대해서도 언급하고 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_3.png\" alt=\"2024-05-23-TheGreatestStepChangeinCybersecurityEver_3\"\u003e\u003c/p\u003e\n\u003ch2\u003e취약성 분석\u003c/h2\u003e\n\u003cp\u003e우리의 고전적인 Pen Testing 방법들은 GenAI의 발전과 함께 빠르게 사라질 것입니다. LLMs를 통해 프로그래밍 오류를 빠르게 식별할 수 있게 되면서, costly한 zero-day 분석이 필요 없이 공격 가능한 취약점을 식별할 수 있을 것입니다. 공격의 비대칭성은 점점 더 명확해질 것이며, 소프트웨어 벤더들은 GenAI 기법을 사용하는 사이버 보안 전문가들과 경쟁하기 어려워질 것입니다. 새로운 세대의 벤더 도구를 사용하면 경험이 부족한 사용자들이 탐지될 수 있지만, 숙련된 사용자들은 기존의 제어를 우회하는 것이 쉬울 것입니다 — 심지어 AI가 생성한 것이더라도요.\u003c/p\u003e\n\u003cp\u003e이러한 취약성은 다른 악의적인 GenAI 요소와 쉽게 공유될 수 있으며, 스캐닝이 쉽게 자동화되고 분산될 수 있습니다. 그들은 포함된 마이크로 코드 및 펌웨어를 전달할 수 있으며, 실행 파일을 위한 이진 파일을 디컴파일하거나 장치 드라이버를 수정할 수 있습니다. 전반적으로, GenAI 요소는 타겟 네트워크에 대해 지능적으로 배포할 수 있는 여러 가지 트릭을 가지고 있으며, 감시, 발판 마련, 시스템을 탐지하고, 최종적으로 파일 암호화 또는 데이터 추출 (일반적으로 둘 다)과 같은 최종 영향을 만들어 냅니다. 하지만 진정한 사이버 보안 전문가들의 손에 들어가면, 이러한 도구들은 절대적으로 엄청날 수 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e스캔과 함께, Raspberry PI와 같은 소형 장치에서 작동하는 LLM 기술을 이용한 악성코드를 볼 수 있습니다. 이미 시장에는 R-PI에서 작동하는 AI 기반 스텔스 기술을 광고하는 제품들이 등장하고 있습니다. 이러한 장치들은 물리적 접근이 필요한 곳에서 사용될 것이며, 와이파이 네트워크에 접근하거나 특정 하드웨어 장치를 대상으로 하는 경우 등에 활용될 것입니다. 따라서 GenAI의 급부상으로 물리적 하드웨어가 더 큰 위험에 노출될 수 있으며, 기업들이 심어진 하드웨어 장치를 찾아야 하는 경우도 늘어날 것입니다.\u003c/p\u003e\n\u003ch2\u003e캠페인 계획 및 실행\u003c/h2\u003e\n\u003cp\u003e래징웨어가 현재 나쁘다고 생각한다면, GenAI-enabled 랜섬웨어 시대가 올 때까지 기다리세요. 이것들은 정보 요원으로서 작동하여 목표를 스캔하고 주요 특성을 정의하며 자동으로 그들에 대한 데이터를 수집할 수 있을 것입니다. 그 후에, 그들은 네트워크를 타겟팅하고 네트워크를 공격하기 위해 필요한 적절한 자원들을 모으고, 그리고 아주 적은 금전적 비용으로 넓게 또는 특정하게 피싱 캠페인을 실행할 수 있을 것입니다. 이는 회사를 상대한 정보 조작 캠페인이 될 수도 있으며, 부정적 소식이 소셜 미디어에 퍼지는 경우도 있을 것입니다. 조직 내 모든 사람이 대상이 될 수도 있습니다. 이것의 핵심은 회사의 평판을 손상시킬 수 있는 데이터 유출이라고 할 수 있으며, GenAI는 추가로 데이터에서 비준수 사항을 분석하고 회사를 소송하거나 집단 소송을 통해 협박할 수도 있습니다.\u003c/p\u003e\n\u003cp\u003eGenAI 도구는 사회공격이나 변형을 위한 다양한 공격 또는 변형 수단을 갖추고 있을 것이며, 이에는 피싱, 사칭, 중상모란 자료의 자동 합성도 포함될 것입니다. 이는 사실과 허구를 구별하는 것이 어려운 세상이 될 것이며, 실종된 표제 피싱 이메일의 나쁜 문법을 발견하는 일은 과거의 일로 사라질 것입니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003eAI Governance\u003c/h2\u003e\n\u003cp\u003e요즘 인공지능 사용이 급격히 증가함에 따라 유엔과 EU는 인공지능의 일반적 사용을 위한 거버넌스 정책을 만들었지만, 우리의 적들이 이러한 접근 방식을 따르지는 않을 것으로 예상되며, 이익을 위해 인공지능을 구축할 것입니다. EU는 '위험 중심, 탑다운 입법 접근법'을 채택했고, 영국은 인공지능 사용에 대한 원칙 중심적인 방법을 택했습니다. \"인공지능 안전\"에 관해서는 보고서가 다음과 같은 분야에서 가이드 라인이 마련되어야 한다고 언급했습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e자율성과 고급 기능. 이는 인공지능 방법의 시행에서 대중에게 위험이 될 수 있는지에 초점을 맞춥니다.\u003c/li\u003e\n\u003cli\u003e모델의 콘텐츠 생성. 이는 인공지능 방법에서 생산된 데이터에 주목하며, 특히 개인정보 침해, 가짜뉴스, 저작권 침해 등과 관련이 있습니다.\u003c/li\u003e\n\u003cli\u003e모델의 악용. 이는 사람들과 그들의 재산에 대한 피해에 초점을 맞춥니다 — 물리적 또는 가상 자산 모두 포함됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e거버넌스에 대해서는 보고서가 훈련을 통해 생성된 모델에서 사용된 가중치는 비공개로 유지되어야 하고 공개되어서는 안 된다고 소개하고 있습니다. 이것은 위협 주체가 엔진을 복제하고 악의적인 데이터를 강화하는 것을 막을 것입니다. 또한 모델 훈련은 격리된 환경에서 이루어져야 하며 공개되어서는 안 됩니다. 이와 함께 데이터 품질, 윤리, 개인정보 보호 및 책임성에 엄격한 규칙이 적용되어야 하며, 이는 인공지능 엔티티의 전 과정 동안 적용되어야 합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e금융 및 계산 비용\u003c/h2\u003e\n\u003cp\u003eLLM을 훈련하고 지원하는 것이 비용이 많이 드는 것으로 잘 알려져 있습니다. 보고서에 따르면 Llama2를 만드는 데 Meta가 3.3백만시간의 계산을 들였으며, 전기 및 하드웨어 비용으로 약 1,000만 달러가 들었습니다. Llama2 모델과 가중치는 일반인에게 라이선스 조건 하에 제공됩니다. 그러나 이러한 모델을 훈련하는 데 드는 막대한 비용으로 현재 주요 LLM 엔진 범위는 OpenAI, Meta, Anthropic 및 Google로 한정될 것으로 예상됩니다.\u003c/p\u003e\n\u003cp\u003eEU 및 세계의 다른 지역들은 AI의 성장을 제한하여 보다 책임 있고 믿을 수 있으며 신뢰할 수 있는 도덕적 접근 방식으로 만드는 것을 목표로 하고 있습니다. 그러나 LLM 훈련에는 발전이 있었으며, 이제 ChatGPT 3.5를 Macbook과 M2 프로세서를 장착한 로컬 환경에서 실행할 수 있습니다 (인터넷 연결 없이).\u003c/p\u003e\n\u003cp\u003e이러한 방식은 모든 안전장치를 우회할 수 있으며, 악성 요소를 추가하여 모델을 업데이트할 수 있습니다. 거의 모든 사람이 어디에서나 접근할 수 있는 (아마도) 궁극적인 해킹 도구 세트를 가지고 있어 더 많은 조직을 침해할 수 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch2\u003e가드 레일\u003c/h2\u003e\n\u003cp\u003e이 AI 개체가 악의적인 목적으로 사용되지 않도록 하기 위해서, 입력 데이터 사용에 엄격한 제한을 두어야 하며, 적대적인 테스트(인공지능을 위한 \"펜 테스트\")를 수행하고, 사용자 인터페이스 접근에 제한을 두어야 합니다. ChatGPT가 요청이 부도덕하거나 비윤리적이라고 판단하면 이야기를 반환하지 않을 것입니다. 전반적으로, LLM은 학습하여 우리가 학습할 수 있는 지점을 찾는 방법을 배우고 있습니다. 이 경우, 북한이 1984년 세계를 향해 추세를 보이고 있다는 점을 제시했습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_4.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e하지만 \"콘솔 해킹\"을 하는 다양한 방법이 있으며, 나쁜 행위를 수행하는 한계를 극복할 수 있습니다:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-23-TheGreatestStepChangeinCybersecurityEver_5.png\" alt=\"2024-05-23-TheGreatestStepChangeinCybersecurityEver_5\"\u003e\u003c/p\u003e\n\u003ch2\u003e결론\u003c/h2\u003e\n\u003cp\u003eLLM의 개발 속도는 우리의 입법자들을 앞지르고 있습니다. 이제 그들은 아마도 지니를 병에 넣으려고 노력하고 있을 것입니다. 하지만 병은 아마도 없어졌고, 지니는 어디에도 보이지 않습니다. LLM의 사용을 의료 및 스마트 자동차 응용 프로그램에서 권하는 사람들이 많겠지만, 랜섬웨어 공격에서 달러 기호를 볼 사람들도 많을 것입니다. 뛰어난 기술 수준을 가진 사람들은 과거에 본 적 없는 용도로 GenAI를 사용할 수 있을 것이며 그러면 재앙적인 영향을 줄 수도 있습니다.\u003c/p\u003e\n\u003cp\u003e우리는 좋은 GenAI의 발전을 제한할 수 있지만, 악의적인 사용자들은 제한되지 않은 응용 분야에서 더 많이 사용할 것입니다. Sora의 출시는 거의 실제와 같은 비디오 가짜를 증가시키고 많은 새로운 위협의 문을 열 것입니다. 관심이 있으시다면, 여기에서 해당 영역을 검토하실 수 있습니다:\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e조직에 대한 제 추천은 무엇일까요? 최고의 사이버 보안 전문가를 확보하고 유지하는 데 투자하십시오. 한편으로는 회사가 필요로 하는 AI 기반 방어 도구를 개발할 수 있고, 다른 한편으로는 가능한 영역을 이해할 수 있습니다. GenAI 상자는 닫힐 수 없으므로, 우리는 사이버 보안의 새로운 세계를 어떻게 형성할지 이해해야 합니다. 그렇지 않으면, 사이버 재앙을 맞이할 위험이 있습니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-23-TheGreatestStepChangeinCybersecurityEver"},"buildId":"T_Nz0g9U1yttYMSEma95P","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>