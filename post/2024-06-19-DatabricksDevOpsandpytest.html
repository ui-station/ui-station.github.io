<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>데이터브릭스, 데브옵스 및 파이테스트 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-06-19-DatabricksDevOpsandpytest" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="데이터브릭스, 데브옵스 및 파이테스트 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="데이터브릭스, 데브옵스 및 파이테스트 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-06-19-DatabricksDevOpsandpytest" data-gatsby-head="true"/><meta name="twitter:title" content="데이터브릭스, 데브옵스 및 파이테스트 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 12:24" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_buildManifest.js" defer=""></script><script src="/_next/static/GsgRekSb--BvxYwv9FPn6/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">데이터브릭스, 데브옵스 및 파이테스트</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="데이터브릭스, 데브옵스 및 파이테스트" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-DatabricksDevOpsandpytest&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>Databricks에서 코드 품질을 지속적으로 보장하고 DevOps 작업 프로세스에 통합하는 방법에 궁금증을 풀어 보셨나요? 더 이상 망설이지 마세요.</p>
<p>다음 예시에서는 Databricks에서 pytest와 DevOps를 사용하여 구현된 테스트 기능을 쉽게 시작하는 방법에 대해 살펴볼 것입니다.</p>
<h1>목표</h1>
<p>이 글을 마치면 Databricks에 구현된 함수를 테스트하고, DevOps에서 pull request가 제출될 때마다 테스트 스위트를 실행할 수 있게 될 것입니다. 아래에서 이를 어떻게 구현할지 살펴보세요.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<img src="/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png">
<h1>DevOps에서 프로젝트 설정하기</h1>
<p>Pytest는 두 가지 테스트 레이아웃을 지원하는데, 이 예시에서는 테스트가 애플리케이션 코드 외부에 배치되는 테스트 레이아웃을 사용할 것입니다. 이 분리는 나중에 데브옵스와 데이타브릭스 자산 번들을 사용하여 자동 릴리스를 다루는 기사에서 유용할 것입니다.</p>
<pre><code class="hljs language-js">project.<span class="hljs-property">toml</span>;
pipelines / pipeline_pytest.<span class="hljs-property">yml</span>;
src / functions / column_funtions.<span class="hljs-property">py</span>;
soultion / demo_notebook.<span class="hljs-property">py</span>;
tests / test_column_funtions.<span class="hljs-property">py</span>;
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 예시에서는 src(소스 코드)와 tests(테스트)로 구성된 두 개의 주요 폴더를 갖춘 간단한 설정이 있습니다. src 폴더는 지원하는 함수를 포함하는 functions와 Lakehouse를 구현하는 노트북을 포함하는 solution 폴더로 구분됩니다.</p>
<p>column_functions.py에서는 주어진 열을 제곱하는 간단한 함수를 구현했습니다.</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># Databricks notebook source</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">column_squared</span>(<span class="hljs-params">df, columnname</span>):
    df_squared = df.withColumn(columnname + <span class="hljs-string">"_squared"</span>, df[columnname] * df[columnname])
    <span class="hljs-keyword">return</span> df_squared
</code></pre>
<p>test_column_functions.py에서는 column_functions.py의 함수 기능을 유효성 검사하는 간단한 테스트를 구현했습니다. 여기서 중요한 부분은 외부 데이터 소스나 스파크 세션에 의존하지 않고 독립적으로 유닛 테스트를 구현하고 있다는 것입니다. 입력과 예상 출력을 비교하기 위해 Databricks의 내장 기능을 사용합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pytest
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">sql</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">SparkSession</span>
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">testing</span> <span class="hljs-keyword">import</span> assertDataFrameEqual
<span class="hljs-keyword">from</span> src.<span class="hljs-property">functions</span>.<span class="hljs-property">column_functions</span> <span class="hljs-keyword">import</span> column_squared

<span class="hljs-keyword">class</span> <span class="hljs-title class_">TestColumnFuntions</span>(object):
    def <span class="hljs-title function_">test_column_squared</span>(self):
        spark = <span class="hljs-title class_">SparkSession</span>.<span class="hljs-property">builder</span>.<span class="hljs-title function_">getOrCreate</span>()

        source_data = [(<span class="hljs-string">"John"</span>, <span class="hljs-number">25</span>), (<span class="hljs-string">"Alice"</span>, <span class="hljs-number">30</span>), (<span class="hljs-string">"Bob"</span>, <span class="hljs-number">35</span>)]
        source_df = spark.<span class="hljs-title function_">createDataFrame</span>(source_data, [<span class="hljs-string">"name"</span>, <span class="hljs-string">"age"</span>])

        df_actual = <span class="hljs-title function_">column_squared</span>(source_df,<span class="hljs-string">'age'</span>)

        expected_data = [(<span class="hljs-string">"John"</span>, <span class="hljs-number">25</span>, <span class="hljs-number">625</span>), (<span class="hljs-string">"Alice"</span>, <span class="hljs-number">30</span>, <span class="hljs-number">900</span>), (<span class="hljs-string">"Bob"</span>, <span class="hljs-number">35</span>, <span class="hljs-number">1225</span>)]
        df_expected = spark.<span class="hljs-title function_">createDataFrame</span>(expected_data, [<span class="hljs-string">"name"</span>, <span class="hljs-string">"age"</span>, <span class="hljs-string">"age_squared"</span>])

        <span class="hljs-title function_">assertDataFrameEqual</span>(df_actual, df_expected)
</code></pre>
<h1>DevOps 파이프라인</h1>
<p>함수와 관련된 테스트를 구현한 후에는 이제 Azure DevOps에서 파이프라인을 설정할 수 있습니다.</p>
<p>파이프라인(pipeline<em>pytest.yml)에 대해 가상 환경을 Python용으로 생성하고 필요한 패키지를 설치한 다음 'tests' 디렉토리에서 pytest를 실행합니다. 이 경우 pytest-azurepipelines를 사용하여 pytest를 DevOps 파이프라인에 통합합니다. 이제 pytest는 'test</em>.py'로 시작하거나 '_test.py'로 끝나는 모든 테스트를 찾아 이 경로를 따라 이동합니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-yaml"><span class="hljs-attr">trigger:</span> <span class="hljs-string">none</span>

<span class="hljs-attr">steps:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">task:</span> <span class="hljs-string">UsePythonVersion@0</span>
    <span class="hljs-attr">inputs:</span>
      <span class="hljs-attr">versionSpec:</span> <span class="hljs-string">"3.9"</span>
      <span class="hljs-attr">addToPath:</span> <span class="hljs-literal">true</span>

  <span class="hljs-bullet">-</span> <span class="hljs-attr">script:</span> <span class="hljs-string">|
      python -m venv .venv
      source .venv/bin/activate
      python -m pip install --upgrade pip
      pip install numpy==1.22.4
      pip install pyspark
      pip install pandas
      pip install pyarrow
      pip install pytest-azurepipelines
      python -m pytest -vv tests
</span>    <span class="hljs-attr">displayName:</span> <span class="hljs-string">"pytest"</span>
</code></pre>
<p>이제 메인 브랜치에서 빌드 검증을 설정하여, 개발자가 풀 리퀘스트를 만들 때마다 정의된 테스트가 실행되도록 할 수 있습니다.</p>
<img src="/assets/img/2024-06-19-DatabricksDevOpsandpytest_1.png">
<h1>결론</h1>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>이 예시에서는 Databricks에서 구현된 기능에 대한 테스트 슈트를 설정하고 DevOps 워크플로에 통합하는 것이 얼마나 간단한지 살펴보았습니다. 이제 프로젝트에 필요한 테스트를 구현하여 지속적으로 고품질 코드를 제공할 수 있도록 만들어 보세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"데이터브릭스, 데브옵스 및 파이테스트","description":"","date":"2024-06-19 12:24","slug":"2024-06-19-DatabricksDevOpsandpytest","content":"\nDatabricks에서 코드 품질을 지속적으로 보장하고 DevOps 작업 프로세스에 통합하는 방법에 궁금증을 풀어 보셨나요? 더 이상 망설이지 마세요.\n\n다음 예시에서는 Databricks에서 pytest와 DevOps를 사용하여 구현된 테스트 기능을 쉽게 시작하는 방법에 대해 살펴볼 것입니다.\n\n# 목표\n\n이 글을 마치면 Databricks에 구현된 함수를 테스트하고, DevOps에서 pull request가 제출될 때마다 테스트 스위트를 실행할 수 있게 될 것입니다. 아래에서 이를 어떻게 구현할지 살펴보세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png\" /\u003e\n\n# DevOps에서 프로젝트 설정하기\n\nPytest는 두 가지 테스트 레이아웃을 지원하는데, 이 예시에서는 테스트가 애플리케이션 코드 외부에 배치되는 테스트 레이아웃을 사용할 것입니다. 이 분리는 나중에 데브옵스와 데이타브릭스 자산 번들을 사용하여 자동 릴리스를 다루는 기사에서 유용할 것입니다.\n\n```js\nproject.toml;\npipelines / pipeline_pytest.yml;\nsrc / functions / column_funtions.py;\nsoultion / demo_notebook.py;\ntests / test_column_funtions.py;\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 예시에서는 src(소스 코드)와 tests(테스트)로 구성된 두 개의 주요 폴더를 갖춘 간단한 설정이 있습니다. src 폴더는 지원하는 함수를 포함하는 functions와 Lakehouse를 구현하는 노트북을 포함하는 solution 폴더로 구분됩니다.\n\ncolumn_functions.py에서는 주어진 열을 제곱하는 간단한 함수를 구현했습니다.\n\n```python\n# Databricks notebook source\ndef column_squared(df, columnname):\n    df_squared = df.withColumn(columnname + \"_squared\", df[columnname] * df[columnname])\n    return df_squared\n```\n\ntest_column_functions.py에서는 column_functions.py의 함수 기능을 유효성 검사하는 간단한 테스트를 구현했습니다. 여기서 중요한 부분은 외부 데이터 소스나 스파크 세션에 의존하지 않고 독립적으로 유닛 테스트를 구현하고 있다는 것입니다. 입력과 예상 출력을 비교하기 위해 Databricks의 내장 기능을 사용합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nimport pytest\nfrom pyspark.sql import SparkSession\nfrom pyspark.testing import assertDataFrameEqual\nfrom src.functions.column_functions import column_squared\n\nclass TestColumnFuntions(object):\n    def test_column_squared(self):\n        spark = SparkSession.builder.getOrCreate()\n\n        source_data = [(\"John\", 25), (\"Alice\", 30), (\"Bob\", 35)]\n        source_df = spark.createDataFrame(source_data, [\"name\", \"age\"])\n\n        df_actual = column_squared(source_df,'age')\n\n        expected_data = [(\"John\", 25, 625), (\"Alice\", 30, 900), (\"Bob\", 35, 1225)]\n        df_expected = spark.createDataFrame(expected_data, [\"name\", \"age\", \"age_squared\"])\n\n        assertDataFrameEqual(df_actual, df_expected)\n```\n\n# DevOps 파이프라인\n\n함수와 관련된 테스트를 구현한 후에는 이제 Azure DevOps에서 파이프라인을 설정할 수 있습니다.\n\n파이프라인(pipeline*pytest.yml)에 대해 가상 환경을 Python용으로 생성하고 필요한 패키지를 설치한 다음 'tests' 디렉토리에서 pytest를 실행합니다. 이 경우 pytest-azurepipelines를 사용하여 pytest를 DevOps 파이프라인에 통합합니다. 이제 pytest는 'test*.py'로 시작하거나 '\\_test.py'로 끝나는 모든 테스트를 찾아 이 경로를 따라 이동합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\ntrigger: none\n\nsteps:\n  - task: UsePythonVersion@0\n    inputs:\n      versionSpec: \"3.9\"\n      addToPath: true\n\n  - script: |\n      python -m venv .venv\n      source .venv/bin/activate\n      python -m pip install --upgrade pip\n      pip install numpy==1.22.4\n      pip install pyspark\n      pip install pandas\n      pip install pyarrow\n      pip install pytest-azurepipelines\n      python -m pytest -vv tests\n    displayName: \"pytest\"\n```\n\n이제 메인 브랜치에서 빌드 검증을 설정하여, 개발자가 풀 리퀘스트를 만들 때마다 정의된 테스트가 실행되도록 할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_1.png\" /\u003e\n\n# 결론\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 예시에서는 Databricks에서 구현된 기능에 대한 테스트 슈트를 설정하고 DevOps 워크플로에 통합하는 것이 얼마나 간단한지 살펴보았습니다. 이제 프로젝트에 필요한 테스트를 구현하여 지속적으로 고품질 코드를 제공할 수 있도록 만들어 보세요.\n","ogImage":{"url":"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png"},"coverImage":"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003eDatabricks에서 코드 품질을 지속적으로 보장하고 DevOps 작업 프로세스에 통합하는 방법에 궁금증을 풀어 보셨나요? 더 이상 망설이지 마세요.\u003c/p\u003e\n\u003cp\u003e다음 예시에서는 Databricks에서 pytest와 DevOps를 사용하여 구현된 테스트 기능을 쉽게 시작하는 방법에 대해 살펴볼 것입니다.\u003c/p\u003e\n\u003ch1\u003e목표\u003c/h1\u003e\n\u003cp\u003e이 글을 마치면 Databricks에 구현된 함수를 테스트하고, DevOps에서 pull request가 제출될 때마다 테스트 스위트를 실행할 수 있게 될 것입니다. 아래에서 이를 어떻게 구현할지 살펴보세요.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cimg src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_0.png\"\u003e\n\u003ch1\u003eDevOps에서 프로젝트 설정하기\u003c/h1\u003e\n\u003cp\u003ePytest는 두 가지 테스트 레이아웃을 지원하는데, 이 예시에서는 테스트가 애플리케이션 코드 외부에 배치되는 테스트 레이아웃을 사용할 것입니다. 이 분리는 나중에 데브옵스와 데이타브릭스 자산 번들을 사용하여 자동 릴리스를 다루는 기사에서 유용할 것입니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eproject.\u003cspan class=\"hljs-property\"\u003etoml\u003c/span\u003e;\npipelines / pipeline_pytest.\u003cspan class=\"hljs-property\"\u003eyml\u003c/span\u003e;\nsrc / functions / column_funtions.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e;\nsoultion / demo_notebook.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e;\ntests / test_column_funtions.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 예시에서는 src(소스 코드)와 tests(테스트)로 구성된 두 개의 주요 폴더를 갖춘 간단한 설정이 있습니다. src 폴더는 지원하는 함수를 포함하는 functions와 Lakehouse를 구현하는 노트북을 포함하는 solution 폴더로 구분됩니다.\u003c/p\u003e\n\u003cp\u003ecolumn_functions.py에서는 주어진 열을 제곱하는 간단한 함수를 구현했습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Databricks notebook source\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecolumn_squared\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003edf, columnname\u003c/span\u003e):\n    df_squared = df.withColumn(columnname + \u003cspan class=\"hljs-string\"\u003e\"_squared\"\u003c/span\u003e, df[columnname] * df[columnname])\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e df_squared\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003etest_column_functions.py에서는 column_functions.py의 함수 기능을 유효성 검사하는 간단한 테스트를 구현했습니다. 여기서 중요한 부분은 외부 데이터 소스나 스파크 세션에 의존하지 않고 독립적으로 유닛 테스트를 구현하고 있다는 것입니다. 입력과 예상 출력을 비교하기 위해 Databricks의 내장 기능을 사용합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pytest\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003esql\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSparkSession\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003etesting\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e assertDataFrameEqual\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e src.\u003cspan class=\"hljs-property\"\u003efunctions\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ecolumn_functions\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e column_squared\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eTestColumnFuntions\u003c/span\u003e(object):\n    def \u003cspan class=\"hljs-title function_\"\u003etest_column_squared\u003c/span\u003e(self):\n        spark = \u003cspan class=\"hljs-title class_\"\u003eSparkSession\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ebuilder\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egetOrCreate\u003c/span\u003e()\n\n        source_data = [(\u003cspan class=\"hljs-string\"\u003e\"John\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e), (\u003cspan class=\"hljs-string\"\u003e\"Alice\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e), (\u003cspan class=\"hljs-string\"\u003e\"Bob\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e)]\n        source_df = spark.\u003cspan class=\"hljs-title function_\"\u003ecreateDataFrame\u003c/span\u003e(source_data, [\u003cspan class=\"hljs-string\"\u003e\"name\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"age\"\u003c/span\u003e])\n\n        df_actual = \u003cspan class=\"hljs-title function_\"\u003ecolumn_squared\u003c/span\u003e(source_df,\u003cspan class=\"hljs-string\"\u003e'age'\u003c/span\u003e)\n\n        expected_data = [(\u003cspan class=\"hljs-string\"\u003e\"John\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e625\u003c/span\u003e), (\u003cspan class=\"hljs-string\"\u003e\"Alice\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e900\u003c/span\u003e), (\u003cspan class=\"hljs-string\"\u003e\"Bob\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1225\u003c/span\u003e)]\n        df_expected = spark.\u003cspan class=\"hljs-title function_\"\u003ecreateDataFrame\u003c/span\u003e(expected_data, [\u003cspan class=\"hljs-string\"\u003e\"name\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"age\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"age_squared\"\u003c/span\u003e])\n\n        \u003cspan class=\"hljs-title function_\"\u003eassertDataFrameEqual\u003c/span\u003e(df_actual, df_expected)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eDevOps 파이프라인\u003c/h1\u003e\n\u003cp\u003e함수와 관련된 테스트를 구현한 후에는 이제 Azure DevOps에서 파이프라인을 설정할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e파이프라인(pipeline\u003cem\u003epytest.yml)에 대해 가상 환경을 Python용으로 생성하고 필요한 패키지를 설치한 다음 'tests' 디렉토리에서 pytest를 실행합니다. 이 경우 pytest-azurepipelines를 사용하여 pytest를 DevOps 파이프라인에 통합합니다. 이제 pytest는 'test\u003c/em\u003e.py'로 시작하거나 '_test.py'로 끝나는 모든 테스트를 찾아 이 경로를 따라 이동합니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-yaml\"\u003e\u003cspan class=\"hljs-attr\"\u003etrigger:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003enone\u003c/span\u003e\n\n\u003cspan class=\"hljs-attr\"\u003esteps:\u003c/span\u003e\n  \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etask:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eUsePythonVersion@0\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003einputs:\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eversionSpec:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"3.9\"\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eaddToPath:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\n\n  \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003escript:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n      python -m venv .venv\n      source .venv/bin/activate\n      python -m pip install --upgrade pip\n      pip install numpy==1.22.4\n      pip install pyspark\n      pip install pandas\n      pip install pyarrow\n      pip install pytest-azurepipelines\n      python -m pytest -vv tests\n\u003c/span\u003e    \u003cspan class=\"hljs-attr\"\u003edisplayName:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"pytest\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이제 메인 브랜치에서 빌드 검증을 설정하여, 개발자가 풀 리퀘스트를 만들 때마다 정의된 테스트가 실행되도록 할 수 있습니다.\u003c/p\u003e\n\u003cimg src=\"/assets/img/2024-06-19-DatabricksDevOpsandpytest_1.png\"\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e이 예시에서는 Databricks에서 구현된 기능에 대한 테스트 슈트를 설정하고 DevOps 워크플로에 통합하는 것이 얼마나 간단한지 살펴보았습니다. 이제 프로젝트에 필요한 테스트를 구현하여 지속적으로 고품질 코드를 제공할 수 있도록 만들어 보세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-DatabricksDevOpsandpytest"},"buildId":"GsgRekSb--BvxYwv9FPn6","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>