<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>무엇보다도 새로운 글로벌 디자인 트렌드  | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="무엇보다도 새로운 글로벌 디자인 트렌드  | ui-station" data-gatsby-head="true"/><meta property="og:title" content="무엇보다도 새로운 글로벌 디자인 트렌드  | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch" data-gatsby-head="true"/><meta name="twitter:title" content="무엇보다도 새로운 글로벌 디자인 트렌드  | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-20 19:58" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-561ae49ab5aab7f5.js" defer=""></script><script src="/_next/static/0asLlD6on3tm8cIfzBaxd/_buildManifest.js" defer=""></script><script src="/_next/static/0asLlD6on3tm8cIfzBaxd/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">무엇보다도 새로운 글로벌 디자인 트렌드 </h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="무엇보다도 새로운 글로벌 디자인 트렌드 " loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 20, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><h2>Alex Alspach과 Punyo 팀</h2>
<p>Punyo 팀: Alex Alspach (기술 리드), Andrew Beaulieu (기술 리드), Kate Tsui (기술 리드), Jose Barreiros, Aditya Bhat, Bisi Chikwendu, Sam Creasey, Eric Dusel, Aimee Goncalves, Manabu Nishiura, Aykut Önol 및 Leticia Priebe Rocha</p>
<h2>“Punyo 만나기” 소개 동영상 (YouTube)</h2>
<p>TRI에서는 사람을 대체하는 것이 아닌 보완하는 로봇 능력을 개발하고 있습니다. 우리는 손끝만으로는 부족한 일상적인 작업을 돕는 데 도움을 주기 위해 노력하고 있습니다.</p>
<div class="content-ad"></div>
<p>우리의 연구 플랫폼인 Punyo는 이 미션을 대변합니다. Punyo 팀은 TRI의 세밀한 로봇 손과 그리퍼 기반의 민첩성을 보완하기 위해 팔과 가슴을 사용한 거대 물체 조작에 초점을 맞추고 있습니다. 우리는 진정으로 능숙한 로봇이 대형, 무거운, 그리고 다루기 힘든 물건들을 다룰 수 있도록 하는 하드웨어와 알고리즘을 개발하고 있습니다.</p>
<p>사람들은 주변 세계를 다루기 위해 창의적인 방법으로 자신의 몸을 사용합니다. 한 번에 식료품을 집 안으로 가져오는 것을 생각해보세요. 여러 개의 봉지를 팔로 들고 문을 팔꿈치로 열고, 엉덩이로 문을 열어놓고 들어가는 것일 수 있습니다. 또한 큰 상자를 들어 올리고 보관하거나 가구를 옮기거나 빨래 더미를 모을 때와 같이 가슴, 팔 및 기타 신체 부위를 사용하여 이러한 작업을 수행합니다.</p>
<p>사람들과 로봇 모두에게 부드럽고 그립감있는 피부를 가지고 물체를 몸 가까이 다루면 더 적은 힘으로 더 무거운 물건을 다룰 수 있습니다. 그럼에도 불구하고 오늘날의 로봇들이 무거운 물체를 손만 사용하여 옮기는 것이 흔하지만 비효율적입니다. Punyo는 다르게 하고 있습니다. 그것은 많은 접촉을 두려워하지 않으며, 손을 뻗어서 잡는 대신 온몸을 활용하여 더 많은 물건을 들고 조작할 수 있습니다.</p>
<h1>Punyo가 무엇인가요?</h1>
<div class="content-ad"></div>
<p>푸뇨는 저희 로봇의 이름입니다. 일본어로는 &quot;푸뇨&quot; (ぷにょ)란 부드럽고 귀여우며 탄력 있는 것을 설명합니다. 이는 토요타의 미래 가정 로봇이 안전하고 능력이 있으며 일하는 것이 즐거워야 한다는 우리의 철학을 나타냅니다. 이러한 로봇공학 접근은 다양한 형태로 나타날 수 있지만, 저희를 움직이게 하는 비전은 친근하고 안전하게 가정에서 일상적인 도전 과제를 수행할 수 있는 인간형 로봇입니다.</p>
<p><img src="/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_0.png" alt="푸뇨"/></p>
<h2>푸뇨 하드웨어 플랫폼</h2>
<p>푸뇨의 손, 팔, 그리고 가슴은 유연한 소재와 촉각 센서로 덮여 있어서 접촉을 느낄 수 있습니다. 이러한 부드러움은 푸뇨가 다루는 물건에 적응하여 안정성, 마찰력 증가, 그리고 균일하게 분산된 접촉력을 가능하게 합니다. 촉각 감지를 통해 푸뇨는 물체에 조절된 힘을 가할 수 있고, 접촉을 감지하며 (예기치 못한 접촉도), 물체의 미끄러짐이나 충돌에 반응할 수 있습니다. 촉각 감지는 또한 사람들과 상호 작용하는 데 중요합니다. 무거운 물건을 들거나 사람들을 신체적으로 지원하는 상황에서, 로봇은 자신의 몸을 인식하고 적절히 상호 작용해야 합니다.</p>
<div class="content-ad"></div>
<p>Punyo는 소프트 로봇으로 간주되지만 그 소프트함의 기초에는 두 개의 &quot;단단한&quot; 로봇 팔, 강성의 상체 프레임 및 허리 액추에이터가 있습니다. 저희 방식은 기존 로봇의 정밀성, 강도 및 신뢰성을 기계식 소프트 로봇 시스템의 적응성, 충격 저항성 및 감각 단숨함과 결합한 것입니다.</p>
<p><img src="/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_1.png" alt="Punyo Soft Robot"/></p>
<p>어깨부터 손목까지, Punyo의 팔은 공기로 채워진 블래더 또는 &quot;버블&quot;로 덮여 있습니다. 이 블래더는 우리 뼈를 덮는 살과 비슷합니다. 각 버블은 압력 센서에 튜브를 통해 연결되어 버블의 외부 표면에 가해지는 힘을 감지합니다. 각각의 버블(각 팔에 13개)은 원하는 강성으로 개별적으로 압력을 가할 수 있으며, 로봇 팔의 표면에 대략 5cm의 유연성을 추가합니다. 이것은 로봇의 큰 표면에 적응성 및 촉각 감지 기능을 추가하는 저렴하고 가벼운 모듈식 방법입니다.</p>
<p><img src="/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_2.png" alt="Punyo Soft Robot"/></p>
<div class="content-ad"></div>
<p>팔을 덮고 있는 거품은 성형 열 밀봉 PVC 패널을 사용하여 만들어졌어요. 큰 하나의 거품이 푸뇨(Punyo)의 손목을 덮고 있지만 팔 아래의 관절이 움직이는 데 제약이 없어요. 나머지 팔 거품은 각각 두 개의 챔버로 이루어진 여섯 개의 작은 링으로 구성되어 있어요. 팔을 덮고 있는 것은 거품을 보호하고 케이블 걸림을 방지하며 외부 접촉 표면 소재를 수정할 수 있도록 하는 맞춤형 패브릭 슬리브입니다. 슬리브는 유지보수 용이하게 제거 가능하며 미적인 사용자 정의 기회를 제공해요.</p>
<p>푸뇨에는 그립퍼가 없기 때문에 손가락이나 엄지가 없어요. 적어도 아직은요. 대신, 푸뇨는 &quot;발&quot;을 가지고 있어요. 각 발은 안에 카메라가 있는 단일 고 마찰 라텍스 거품이에요 (TRI의 소프트-버블 비수용각감각 센서 기반, punyo.tech/bubblegripper). 이 거품 내부에는 점 패턴이 인쇄되어 있어요. 거품이 무언가에 닿으면 점 패턴이 변형돼요. 내부 카메라는 이 변형을 사용하여 힘을 추정하고 이미지를 바로 학습된 시각 운동 정책에 전달해요.</p>
<h1>전신 기술 교육을 위한 원격 작동 도구</h1>
<p>우리는 다양한 전신 작업에서 하드웨어를 테스트했어요. 푸뇨는 고감각 정책을 학습하기 위해 두 가지 강력한 방법인 확산 정책과 예시 지도 강화 학습을 사용해요. 하드웨어에서 직접 새로운 작업을 시도하고 이러한 학습 파이프라인에 예시 시연을 제공하기 위해 전신 기술에 직관적인 원격 운영 인터페이스를 개발 중이에요. 작년 TRI에서 발표된 확산 정책은 사람의 시범을 사용하여 어려운 모델링 작업을 위한 견고한 감각 운동 정책(카메라 및 촉각 피드백 사용)을 학습해요. 예시 지도 강화 학습(EGRL)은 작업이 시뮬레이션에서 모델링되어야 하며 작은 시범 집합이 로봇의 탐색을 안내해야 해요. 두 가지 방법 모두 유연성을 활용하고 촉각 피드백을 통합하는 견고한 정책을 생성해요.</p>
<div class="content-ad"></div>
<h3>Synergy Teleop을 이해하세요: 핵심 전신 조작 작업, 예를 들어 붙잡기와 들기와 같은 작업은 손을 사용한 붙잡기와 유사한 시너지로 분할되어 있습니다. 이러한 동작은 우리가 게임패드 인터페이스를 통해 개별적으로 제어하는 동작입니다. 팔을 독립적으로 들린 후 내리고, 각 팔의 붙잡기를 열고 닫음으로써 단일 및 양손으로 붙잡고 다시 붙잡고 들기 및 붙잡은 상태에서 조작하는 팔을 위해 조합합니다. 표준적이고 저렴한 게임패드만 필요로 하며, 실험은 연구실이나 야생에서 아무 곳에서나 수행될 수 있습니다.</h3>
<p><img src="/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_3.png" alt="이미지"/></p>
<h3>계층적 운영-공간 Teleop: 더 복잡하고 정교하거나 섬세한 작업을 위해, 발과 팔꿈치, 그리고 상체 각도를 직접 제어할 수 있습니다. 이들을 제어함으로써 우리는 예를 들어 몸을 앞으로 숙여 가슴에 물건을 모을 수 있고, 다른 팔을 물체 위에 감아놓거나 다른 팔은 아래에 위치시키고, 뒤로 기울여 들 수 있습니다. 움직임 캡처 카메라를 사용하여 우리의 원격 조종자의 등, 어깨, 팔꿈치, 그리고 손에 부착된 톱니들을 추적하고 이를 로봇의 유사한 지점(운영 지점)에 대응시킵니다. 원격 조종자의 동작은 Punyo로 리디렉팅되어 어떤 사람이든 체형과 관계없이 시스템을 운영할 수 있습니다.</h3>
<p>우리는 전신 움직임 제어 접근 방식을 통해 원격 조작 및 자율 확산 정책을 전개합니다. 예를 들어, 원격 조작 중에는 최우선 순위 작업인 종단부 자세 추적이 필요해 Punyo의 발이 원격 조종자의 발을 신뢰할 수 있게 추적해야 합니다. 팔꿈치 자세 추적은 중요도가 낮을 수 있으며, Punyo가 최우선 순위인 종단부 추적과 간섭하지 않는 한 원격 조작 팔꿈치 자세를 달성할 수 있습니다. 계층적 움직임 제어 프레임워크를 사용하면 제약 조건과 운영 지점 추적을 추가, 제거, 조정 및 재우선화하여 원격 조작 인터페이스를 신속히 반복할 수 있습니다.</p>
<div class="content-ad"></div>
<p>The hierarchical framework also provides an interface for exploring physically reactive motions and human-robot interaction. An example is Punyo moving its elbow out of the way when an accidental bump is sensed. Because of the redundant joints in our arms, we can move the elbow without sacrificing end-effector motion. This control scheme can be used to allow a person to push Punyo’s arm out of the way mid-task to quickly grab something.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*wGszjFTuqa5Ludd8foyQXA.gif" alt="Image"/></p>
<h2>Guiding Reinforcement Learning with Human Examples</h2>
<p>We employ Example-Guided Reinforcement Learning (EGRL) to develop sturdy manipulation policies for tasks we can simulate. Demonstrating the task enhances the learning process efficiency and lets us influence the style of motion the robot uses to complete the task. We utilize Adversarial Motion Priors (AMP), typically used for stylizing computer-animated characters, to introduce human motion imitation into our reinforcement learning pipeline. All policies displayed below were trained with just one demonstration.</p>
<div class="content-ad"></div>
<p>우리의 파이프라인은 시범 본따기 보상과 작업 목표 보상의 비율인 λ변수를 노출합니다. 이 변수를 사용하면 Punnyo가 동작을 모방하는 것과 순전히 탐구를 통해 작업을 성공적으로 수행하는 것 사이에서 어떻게 균형을 맞출지 조절할 수 있습니다. 예를 들어, 로봇의 어깨 위로 큰 항아리를 올리는 작업을 배우는 경우를 생각해보세요. 다이얼을 한 방향으로 돌리면(λ = 0), 로봇은 단순히 &quot;자세를 따라 하는&quot; 것으로, 항아리가 탁자를 떠나는지 여부에 관계없이 동일한 작업에 대한 인간 시범 동작을 모방합니다. 다이얼을 다른 방향으로 돌리면(λ = 1), 로봇은 전혀 시범을 무시하고, 항아리를 탁자에서 내리는 데만 집중하며 임무를 수행하는 데 필요한 어떤 비자연스러운 동작이라도 (희망적으로) 수렴합니다. 그 사이의 λ는 시범의 스타일로 작업을 완료하는 정책을 생성합니다.</p>
<p>작업 설명은 단지 항아리를 올리는 것보다 복잡할 수 있습니다. 예를 들어, 우리는 속도, 저에너지 소비, 또는 보다 견고한 작업 완료를 장려할 수도 있습니다. 기능 요구 사항을 인간 시범 스타일과 섞어서 결합하면 효율적이지만 사람들이 예측하고 가인화하기가 더 쉬운 로봇이 될 수 있으며, 그들이 더 편안하고 생산적으로 협력할 수 있게 해줍니다. 다양한 작업, 상황, 로봇, 인간 협력자에 대한 적절한 균형을 발견하기를 고대합니다.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*UbzHiHf4pgipEfifAtmnSw.gif" alt="이미지"/></p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*Ne8RXDgCjVWAZenDHi5zxA.gif" alt="이미지"/></p>
<div class="content-ad"></div>
<h1>Plan-Guided Reinforcement Learning</h1>
<p>강화 학습은 훈련을 위해 작업을 시뮬레이션에서 모델링해야 합니다. 따라서 우리는 텔레오퍼레이션 대신 모델 기반 플래너를 사용하여 데모를 위한 계획을 세울 수 있습니다. 이를 Plan-Guided Reinforcement Learning (PGRL)라고 부릅니다. 플래너를 활용하면 텔레오퍼레이션으로는 어려운 장기 과제들도 수행할 수 있습니다. 또한 인간 입력에 대한 의존성을 줄여 자동으로 여러 데모를 생성할 수 있으며, 이는 Punyo가 처리할 수 있는 작업 수를 확장하는 한 걸음입니다. 이 능력은 언젠가 Punyo가 스스로 새로운 기술을 학습할 수 있게 할 수도 있습니다.</p>
<p>현재 최신 모델 기반 플래너는 복잡한 접촉 시퀀스를 포함하는 동작 계획을 생성할 수 있지만, 그 결과를 온라인에서 폐쇄 루프 방식으로 사용하기에는 충분히 빠르지 않습니다. 또한 모델의 부정확함과 가정으로 인해 시뮬레이션에서도 물리적으로 실행할 수 없는 경우가 있을 수 있습니다. 따라서 로봇 하드웨어에서 열린 루프로 재생될 때 원하는 대로 대상 객체를 조작하지 못할 가능성이 있는 궤적이 남습니다. 그러나 이대로 오픈 루프로 실행되는 경우 원하는 대상 객체를 조작하지 못할 가능성이 매우 큽니다. 그러나 예제 기반 강화 학습을 사용하여 이러한 불안정한 궤적을 가져다가 실행 가능한 피드백 정책으로 변경할 수 있습니다.</p>
<p>짧은 접촉을 통해 장기적인 행동을 합성하는 데 접촉 묵시 플래너를 사용합니다. 플래너는 글로벌 접촉 추론을 가능하게 하는 몇 가지 가정을 합니다. 그런데 이로 인해 해당 결과를 하드웨어에서 직접 사용할 수 없습니다. 그러나 이 궤적은 EGRL 파이프라인에 시드로 작업에 필요한 동작 및 접촉 시퀀스를 제공하는 훌륭한 데모로 작용합니다. 작업 목표, 도메인 랜덤화 및 이러한 초기 데모로 동작 탐색을 가리키는 경우, Punyo는 모션 계획을 따르는 폐쇄 루프 정책을 효율적으로 학습하여 하드웨어에서 견고하게 어려운 작업을 수행할 수 있습니다.</p>
<div class="content-ad"></div>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*XuViGzzbwQISa9HyDmIzMw.gif" alt="Image"/></p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*XiqFuPa83jIeSndMtEsczg.gif" alt="Image"/></p>
<h1>안전하고 생산적인 협력을 향해</h1>
<p>TRI와 다른 곳에서 능숙한 능력이 급증하는 가운데, 현재의 로봇 및 조작 전략은 여러 작업과 기술을 이루리 하는 데 많은 어려움을 겪고 있습니다. 손으로 다루기에 너무 큰 물체, 팔이 안정화해야 하는 물건 더미, 한 팔에 들고 있는 물체와 다른 물체를 다루는 작업, 그리고 좁은 공간과 사람 주변에서 안전하게 운영하는 능력이 필요합니다. 그리퍼 기반 민첩성과 병행하여 전체 몸을 이용한 조작을 위한 하드웨어, 지식 및 데이터셋 개발은 다양한 능력을 갖춘 조작 플랫폼을 만들기 위해 중요합니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_4.png" alt="Punyo Soft Robot"/></p>
<p>로봇의 가슴, 팔 및 기타 몸 표면을 조작하기 위해 잠금 해제하는 것은 기계적으로 유리합니다. 준수 및 마찰과 결합하여, 로봇은 더 적은 에너지로 큰 물건을 잡고 조작할 수 있어서 페이로드와 배터리 수명을 늘리고 더 저렴한 시스템을 가능하게합니다. 부드럽기 때문에 충격을 흡수할 수 있어 로봇의 안전과 주변 사람들의 안전을 위해 사용될 수 있습니다. 촉각 감지를 추가하면 접촉력을 밀접하게 모니터링하고 제어하여 부드럽고 복잡하며 상호작용적이고 안정적인 조작이 가능합니다.</p>
<p>TRI의 Punyo 팀은 이 문제를 해결하기 위해 구축되었습니다. 부드러운 로봇공학, 접촉을 고려한 계획 및 학습, 촉각 감지 및 인간-로봇 상호작용에 대한 우리의 전문가들은 로봇과 사람이 안전하게, 생산적으로, 행복하게 공존할 수 있는 미래에 전념하고 있습니다.</p>
<h1>감사의 글</h1>
<div class="content-ad"></div>
<p>러스트 테드레이크, 토피 알비나, 막스 바지라차리야, 길 프랫, 꽁대짱 하시모토(푸뇨라는 이름으로!), 벤 버치필, 알레한드로 카스트로, 에릭 쿠시너, 홍카이 다이, 리처드 데니토, 에블린 딕슨, 지미 도르니에, 세라 에브치민, 시유안 펑, 크리스 기드웰, 스테이시 기드웰, 담롱 구오이, 브렌든 해쓰어웨이, 앨리슨 헨리, 피비 호르간, 제나 홀만, 스티브 이아코비노, 루카스 카울, 나빈 쿠퍼스와미, 앨리사 라우, 존 라이히티, 수잔 마이클, 고든 리차드슨, 파스 샤, 리사 토바스코, 아비나시 우딤찬다니, 트리스탄 위팅, 자로드 윌슨, 존 요우, 맹채오 장, 알렉스 알렉자니안, 리드 알스팩, 윌 나이트, 리즈 펄먼, 그리고 우리 아기들과 소중한 이들에게 특별한 감사를 ❤️</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"무엇보다도 새로운 글로벌 디자인 트렌드 ","description":"","date":"2024-05-20 19:58","slug":"2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch","content":"\n\n## Alex Alspach과 Punyo 팀\n\nPunyo 팀: Alex Alspach (기술 리드), Andrew Beaulieu (기술 리드), Kate Tsui (기술 리드), Jose Barreiros, Aditya Bhat, Bisi Chikwendu, Sam Creasey, Eric Dusel, Aimee Goncalves, Manabu Nishiura, Aykut Önol 및 Leticia Priebe Rocha\n\n## “Punyo 만나기” 소개 동영상 (YouTube)\n\nTRI에서는 사람을 대체하는 것이 아닌 보완하는 로봇 능력을 개발하고 있습니다. 우리는 손끝만으로는 부족한 일상적인 작업을 돕는 데 도움을 주기 위해 노력하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 연구 플랫폼인 Punyo는 이 미션을 대변합니다. Punyo 팀은 TRI의 세밀한 로봇 손과 그리퍼 기반의 민첩성을 보완하기 위해 팔과 가슴을 사용한 거대 물체 조작에 초점을 맞추고 있습니다. 우리는 진정으로 능숙한 로봇이 대형, 무거운, 그리고 다루기 힘든 물건들을 다룰 수 있도록 하는 하드웨어와 알고리즘을 개발하고 있습니다.\n\n사람들은 주변 세계를 다루기 위해 창의적인 방법으로 자신의 몸을 사용합니다. 한 번에 식료품을 집 안으로 가져오는 것을 생각해보세요. 여러 개의 봉지를 팔로 들고 문을 팔꿈치로 열고, 엉덩이로 문을 열어놓고 들어가는 것일 수 있습니다. 또한 큰 상자를 들어 올리고 보관하거나 가구를 옮기거나 빨래 더미를 모을 때와 같이 가슴, 팔 및 기타 신체 부위를 사용하여 이러한 작업을 수행합니다.\n\n사람들과 로봇 모두에게 부드럽고 그립감있는 피부를 가지고 물체를 몸 가까이 다루면 더 적은 힘으로 더 무거운 물건을 다룰 수 있습니다. 그럼에도 불구하고 오늘날의 로봇들이 무거운 물체를 손만 사용하여 옮기는 것이 흔하지만 비효율적입니다. Punyo는 다르게 하고 있습니다. 그것은 많은 접촉을 두려워하지 않으며, 손을 뻗어서 잡는 대신 온몸을 활용하여 더 많은 물건을 들고 조작할 수 있습니다.\n\n# Punyo가 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n푸뇨는 저희 로봇의 이름입니다. 일본어로는 \"푸뇨\" (ぷにょ)란 부드럽고 귀여우며 탄력 있는 것을 설명합니다. 이는 토요타의 미래 가정 로봇이 안전하고 능력이 있으며 일하는 것이 즐거워야 한다는 우리의 철학을 나타냅니다. 이러한 로봇공학 접근은 다양한 형태로 나타날 수 있지만, 저희를 움직이게 하는 비전은 친근하고 안전하게 가정에서 일상적인 도전 과제를 수행할 수 있는 인간형 로봇입니다.\n\n![푸뇨](/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_0.png)\n\n## 푸뇨 하드웨어 플랫폼\n\n푸뇨의 손, 팔, 그리고 가슴은 유연한 소재와 촉각 센서로 덮여 있어서 접촉을 느낄 수 있습니다. 이러한 부드러움은 푸뇨가 다루는 물건에 적응하여 안정성, 마찰력 증가, 그리고 균일하게 분산된 접촉력을 가능하게 합니다. 촉각 감지를 통해 푸뇨는 물체에 조절된 힘을 가할 수 있고, 접촉을 감지하며 (예기치 못한 접촉도), 물체의 미끄러짐이나 충돌에 반응할 수 있습니다. 촉각 감지는 또한 사람들과 상호 작용하는 데 중요합니다. 무거운 물건을 들거나 사람들을 신체적으로 지원하는 상황에서, 로봇은 자신의 몸을 인식하고 적절히 상호 작용해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPunyo는 소프트 로봇으로 간주되지만 그 소프트함의 기초에는 두 개의 \"단단한\" 로봇 팔, 강성의 상체 프레임 및 허리 액추에이터가 있습니다. 저희 방식은 기존 로봇의 정밀성, 강도 및 신뢰성을 기계식 소프트 로봇 시스템의 적응성, 충격 저항성 및 감각 단숨함과 결합한 것입니다.\n\n![Punyo Soft Robot](/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_1.png)\n\n어깨부터 손목까지, Punyo의 팔은 공기로 채워진 블래더 또는 \"버블\"로 덮여 있습니다. 이 블래더는 우리 뼈를 덮는 살과 비슷합니다. 각 버블은 압력 센서에 튜브를 통해 연결되어 버블의 외부 표면에 가해지는 힘을 감지합니다. 각각의 버블(각 팔에 13개)은 원하는 강성으로 개별적으로 압력을 가할 수 있으며, 로봇 팔의 표면에 대략 5cm의 유연성을 추가합니다. 이것은 로봇의 큰 표면에 적응성 및 촉각 감지 기능을 추가하는 저렴하고 가벼운 모듈식 방법입니다.\n\n![Punyo Soft Robot](/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n팔을 덮고 있는 거품은 성형 열 밀봉 PVC 패널을 사용하여 만들어졌어요. 큰 하나의 거품이 푸뇨(Punyo)의 손목을 덮고 있지만 팔 아래의 관절이 움직이는 데 제약이 없어요. 나머지 팔 거품은 각각 두 개의 챔버로 이루어진 여섯 개의 작은 링으로 구성되어 있어요. 팔을 덮고 있는 것은 거품을 보호하고 케이블 걸림을 방지하며 외부 접촉 표면 소재를 수정할 수 있도록 하는 맞춤형 패브릭 슬리브입니다. 슬리브는 유지보수 용이하게 제거 가능하며 미적인 사용자 정의 기회를 제공해요.\n\n푸뇨에는 그립퍼가 없기 때문에 손가락이나 엄지가 없어요. 적어도 아직은요. 대신, 푸뇨는 \"발\"을 가지고 있어요. 각 발은 안에 카메라가 있는 단일 고 마찰 라텍스 거품이에요 (TRI의 소프트-버블 비수용각감각 센서 기반, punyo.tech/bubblegripper). 이 거품 내부에는 점 패턴이 인쇄되어 있어요. 거품이 무언가에 닿으면 점 패턴이 변형돼요. 내부 카메라는 이 변형을 사용하여 힘을 추정하고 이미지를 바로 학습된 시각 운동 정책에 전달해요.\n\n# 전신 기술 교육을 위한 원격 작동 도구\n\n우리는 다양한 전신 작업에서 하드웨어를 테스트했어요. 푸뇨는 고감각 정책을 학습하기 위해 두 가지 강력한 방법인 확산 정책과 예시 지도 강화 학습을 사용해요. 하드웨어에서 직접 새로운 작업을 시도하고 이러한 학습 파이프라인에 예시 시연을 제공하기 위해 전신 기술에 직관적인 원격 운영 인터페이스를 개발 중이에요. 작년 TRI에서 발표된 확산 정책은 사람의 시범을 사용하여 어려운 모델링 작업을 위한 견고한 감각 운동 정책(카메라 및 촉각 피드백 사용)을 학습해요. 예시 지도 강화 학습(EGRL)은 작업이 시뮬레이션에서 모델링되어야 하며 작은 시범 집합이 로봇의 탐색을 안내해야 해요. 두 가지 방법 모두 유연성을 활용하고 촉각 피드백을 통합하는 견고한 정책을 생성해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n### Synergy Teleop을 이해하세요: 핵심 전신 조작 작업, 예를 들어 붙잡기와 들기와 같은 작업은 손을 사용한 붙잡기와 유사한 시너지로 분할되어 있습니다. 이러한 동작은 우리가 게임패드 인터페이스를 통해 개별적으로 제어하는 동작입니다. 팔을 독립적으로 들린 후 내리고, 각 팔의 붙잡기를 열고 닫음으로써 단일 및 양손으로 붙잡고 다시 붙잡고 들기 및 붙잡은 상태에서 조작하는 팔을 위해 조합합니다. 표준적이고 저렴한 게임패드만 필요로 하며, 실험은 연구실이나 야생에서 아무 곳에서나 수행될 수 있습니다.\n\n![이미지](/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_3.png)\n\n### 계층적 운영-공간 Teleop: 더 복잡하고 정교하거나 섬세한 작업을 위해, 발과 팔꿈치, 그리고 상체 각도를 직접 제어할 수 있습니다. 이들을 제어함으로써 우리는 예를 들어 몸을 앞으로 숙여 가슴에 물건을 모을 수 있고, 다른 팔을 물체 위에 감아놓거나 다른 팔은 아래에 위치시키고, 뒤로 기울여 들 수 있습니다. 움직임 캡처 카메라를 사용하여 우리의 원격 조종자의 등, 어깨, 팔꿈치, 그리고 손에 부착된 톱니들을 추적하고 이를 로봇의 유사한 지점(운영 지점)에 대응시킵니다. 원격 조종자의 동작은 Punyo로 리디렉팅되어 어떤 사람이든 체형과 관계없이 시스템을 운영할 수 있습니다.\n\n우리는 전신 움직임 제어 접근 방식을 통해 원격 조작 및 자율 확산 정책을 전개합니다. 예를 들어, 원격 조작 중에는 최우선 순위 작업인 종단부 자세 추적이 필요해 Punyo의 발이 원격 조종자의 발을 신뢰할 수 있게 추적해야 합니다. 팔꿈치 자세 추적은 중요도가 낮을 수 있으며, Punyo가 최우선 순위인 종단부 추적과 간섭하지 않는 한 원격 조작 팔꿈치 자세를 달성할 수 있습니다. 계층적 움직임 제어 프레임워크를 사용하면 제약 조건과 운영 지점 추적을 추가, 제거, 조정 및 재우선화하여 원격 조작 인터페이스를 신속히 반복할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nThe hierarchical framework also provides an interface for exploring physically reactive motions and human-robot interaction. An example is Punyo moving its elbow out of the way when an accidental bump is sensed. Because of the redundant joints in our arms, we can move the elbow without sacrificing end-effector motion. This control scheme can be used to allow a person to push Punyo’s arm out of the way mid-task to quickly grab something.\n\n\n![Image](https://miro.medium.com/v2/resize:fit:1400/1*wGszjFTuqa5Ludd8foyQXA.gif)\n\n## Guiding Reinforcement Learning with Human Examples\n\nWe employ Example-Guided Reinforcement Learning (EGRL) to develop sturdy manipulation policies for tasks we can simulate. Demonstrating the task enhances the learning process efficiency and lets us influence the style of motion the robot uses to complete the task. We utilize Adversarial Motion Priors (AMP), typically used for stylizing computer-animated characters, to introduce human motion imitation into our reinforcement learning pipeline. All policies displayed below were trained with just one demonstration.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 파이프라인은 시범 본따기 보상과 작업 목표 보상의 비율인 λ변수를 노출합니다. 이 변수를 사용하면 Punnyo가 동작을 모방하는 것과 순전히 탐구를 통해 작업을 성공적으로 수행하는 것 사이에서 어떻게 균형을 맞출지 조절할 수 있습니다. 예를 들어, 로봇의 어깨 위로 큰 항아리를 올리는 작업을 배우는 경우를 생각해보세요. 다이얼을 한 방향으로 돌리면(λ = 0), 로봇은 단순히 \"자세를 따라 하는\" 것으로, 항아리가 탁자를 떠나는지 여부에 관계없이 동일한 작업에 대한 인간 시범 동작을 모방합니다. 다이얼을 다른 방향으로 돌리면(λ = 1), 로봇은 전혀 시범을 무시하고, 항아리를 탁자에서 내리는 데만 집중하며 임무를 수행하는 데 필요한 어떤 비자연스러운 동작이라도 (희망적으로) 수렴합니다. 그 사이의 λ는 시범의 스타일로 작업을 완료하는 정책을 생성합니다.\n\n작업 설명은 단지 항아리를 올리는 것보다 복잡할 수 있습니다. 예를 들어, 우리는 속도, 저에너지 소비, 또는 보다 견고한 작업 완료를 장려할 수도 있습니다. 기능 요구 사항을 인간 시범 스타일과 섞어서 결합하면 효율적이지만 사람들이 예측하고 가인화하기가 더 쉬운 로봇이 될 수 있으며, 그들이 더 편안하고 생산적으로 협력할 수 있게 해줍니다. 다양한 작업, 상황, 로봇, 인간 협력자에 대한 적절한 균형을 발견하기를 고대합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*UbzHiHf4pgipEfifAtmnSw.gif)\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*Ne8RXDgCjVWAZenDHi5zxA.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Plan-Guided Reinforcement Learning\n\n강화 학습은 훈련을 위해 작업을 시뮬레이션에서 모델링해야 합니다. 따라서 우리는 텔레오퍼레이션 대신 모델 기반 플래너를 사용하여 데모를 위한 계획을 세울 수 있습니다. 이를 Plan-Guided Reinforcement Learning (PGRL)라고 부릅니다. 플래너를 활용하면 텔레오퍼레이션으로는 어려운 장기 과제들도 수행할 수 있습니다. 또한 인간 입력에 대한 의존성을 줄여 자동으로 여러 데모를 생성할 수 있으며, 이는 Punyo가 처리할 수 있는 작업 수를 확장하는 한 걸음입니다. 이 능력은 언젠가 Punyo가 스스로 새로운 기술을 학습할 수 있게 할 수도 있습니다.\n\n현재 최신 모델 기반 플래너는 복잡한 접촉 시퀀스를 포함하는 동작 계획을 생성할 수 있지만, 그 결과를 온라인에서 폐쇄 루프 방식으로 사용하기에는 충분히 빠르지 않습니다. 또한 모델의 부정확함과 가정으로 인해 시뮬레이션에서도 물리적으로 실행할 수 없는 경우가 있을 수 있습니다. 따라서 로봇 하드웨어에서 열린 루프로 재생될 때 원하는 대로 대상 객체를 조작하지 못할 가능성이 있는 궤적이 남습니다. 그러나 이대로 오픈 루프로 실행되는 경우 원하는 대상 객체를 조작하지 못할 가능성이 매우 큽니다. 그러나 예제 기반 강화 학습을 사용하여 이러한 불안정한 궤적을 가져다가 실행 가능한 피드백 정책으로 변경할 수 있습니다.\n\n짧은 접촉을 통해 장기적인 행동을 합성하는 데 접촉 묵시 플래너를 사용합니다. 플래너는 글로벌 접촉 추론을 가능하게 하는 몇 가지 가정을 합니다. 그런데 이로 인해 해당 결과를 하드웨어에서 직접 사용할 수 없습니다. 그러나 이 궤적은 EGRL 파이프라인에 시드로 작업에 필요한 동작 및 접촉 시퀀스를 제공하는 훌륭한 데모로 작용합니다. 작업 목표, 도메인 랜덤화 및 이러한 초기 데모로 동작 탐색을 가리키는 경우, Punyo는 모션 계획을 따르는 폐쇄 루프 정책을 효율적으로 학습하여 하드웨어에서 견고하게 어려운 작업을 수행할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](https://miro.medium.com/v2/resize:fit:1400/1*XuViGzzbwQISa9HyDmIzMw.gif)\n\n![Image](https://miro.medium.com/v2/resize:fit:1400/1*XiqFuPa83jIeSndMtEsczg.gif)\n\n# 안전하고 생산적인 협력을 향해\n\nTRI와 다른 곳에서 능숙한 능력이 급증하는 가운데, 현재의 로봇 및 조작 전략은 여러 작업과 기술을 이루리 하는 데 많은 어려움을 겪고 있습니다. 손으로 다루기에 너무 큰 물체, 팔이 안정화해야 하는 물건 더미, 한 팔에 들고 있는 물체와 다른 물체를 다루는 작업, 그리고 좁은 공간과 사람 주변에서 안전하게 운영하는 능력이 필요합니다. 그리퍼 기반 민첩성과 병행하여 전체 몸을 이용한 조작을 위한 하드웨어, 지식 및 데이터셋 개발은 다양한 능력을 갖춘 조작 플랫폼을 만들기 위해 중요합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Punyo Soft Robot](/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_4.png)\n\n로봇의 가슴, 팔 및 기타 몸 표면을 조작하기 위해 잠금 해제하는 것은 기계적으로 유리합니다. 준수 및 마찰과 결합하여, 로봇은 더 적은 에너지로 큰 물건을 잡고 조작할 수 있어서 페이로드와 배터리 수명을 늘리고 더 저렴한 시스템을 가능하게합니다. 부드럽기 때문에 충격을 흡수할 수 있어 로봇의 안전과 주변 사람들의 안전을 위해 사용될 수 있습니다. 촉각 감지를 추가하면 접촉력을 밀접하게 모니터링하고 제어하여 부드럽고 복잡하며 상호작용적이고 안정적인 조작이 가능합니다.\n\nTRI의 Punyo 팀은 이 문제를 해결하기 위해 구축되었습니다. 부드러운 로봇공학, 접촉을 고려한 계획 및 학습, 촉각 감지 및 인간-로봇 상호작용에 대한 우리의 전문가들은 로봇과 사람이 안전하게, 생산적으로, 행복하게 공존할 수 있는 미래에 전념하고 있습니다.\n\n# 감사의 글\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n러스트 테드레이크, 토피 알비나, 막스 바지라차리야, 길 프랫, 꽁대짱 하시모토(푸뇨라는 이름으로!), 벤 버치필, 알레한드로 카스트로, 에릭 쿠시너, 홍카이 다이, 리처드 데니토, 에블린 딕슨, 지미 도르니에, 세라 에브치민, 시유안 펑, 크리스 기드웰, 스테이시 기드웰, 담롱 구오이, 브렌든 해쓰어웨이, 앨리슨 헨리, 피비 호르간, 제나 홀만, 스티브 이아코비노, 루카스 카울, 나빈 쿠퍼스와미, 앨리사 라우, 존 라이히티, 수잔 마이클, 고든 리차드슨, 파스 샤, 리사 토바스코, 아비나시 우딤찬다니, 트리스탄 위팅, 자로드 윌슨, 존 요우, 맹채오 장, 알렉스 알렉자니안, 리드 알스팩, 윌 나이트, 리즈 펄먼, 그리고 우리 아기들과 소중한 이들에게 특별한 감사를 ❤️","ogImage":{"url":"/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_0.png"},"coverImage":"/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_0.png","tag":["Tech"],"readingTime":9},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h2: \"h2\",\n    p: \"p\",\n    h1: \"h1\",\n    img: \"img\",\n    h3: \"h3\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.h2, {\n      children: \"Alex Alspach과 Punyo 팀\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Punyo 팀: Alex Alspach (기술 리드), Andrew Beaulieu (기술 리드), Kate Tsui (기술 리드), Jose Barreiros, Aditya Bhat, Bisi Chikwendu, Sam Creasey, Eric Dusel, Aimee Goncalves, Manabu Nishiura, Aykut Önol 및 Leticia Priebe Rocha\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"“Punyo 만나기” 소개 동영상 (YouTube)\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"TRI에서는 사람을 대체하는 것이 아닌 보완하는 로봇 능력을 개발하고 있습니다. 우리는 손끝만으로는 부족한 일상적인 작업을 돕는 데 도움을 주기 위해 노력하고 있습니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우리의 연구 플랫폼인 Punyo는 이 미션을 대변합니다. Punyo 팀은 TRI의 세밀한 로봇 손과 그리퍼 기반의 민첩성을 보완하기 위해 팔과 가슴을 사용한 거대 물체 조작에 초점을 맞추고 있습니다. 우리는 진정으로 능숙한 로봇이 대형, 무거운, 그리고 다루기 힘든 물건들을 다룰 수 있도록 하는 하드웨어와 알고리즘을 개발하고 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"사람들은 주변 세계를 다루기 위해 창의적인 방법으로 자신의 몸을 사용합니다. 한 번에 식료품을 집 안으로 가져오는 것을 생각해보세요. 여러 개의 봉지를 팔로 들고 문을 팔꿈치로 열고, 엉덩이로 문을 열어놓고 들어가는 것일 수 있습니다. 또한 큰 상자를 들어 올리고 보관하거나 가구를 옮기거나 빨래 더미를 모을 때와 같이 가슴, 팔 및 기타 신체 부위를 사용하여 이러한 작업을 수행합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"사람들과 로봇 모두에게 부드럽고 그립감있는 피부를 가지고 물체를 몸 가까이 다루면 더 적은 힘으로 더 무거운 물건을 다룰 수 있습니다. 그럼에도 불구하고 오늘날의 로봇들이 무거운 물체를 손만 사용하여 옮기는 것이 흔하지만 비효율적입니다. Punyo는 다르게 하고 있습니다. 그것은 많은 접촉을 두려워하지 않으며, 손을 뻗어서 잡는 대신 온몸을 활용하여 더 많은 물건을 들고 조작할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Punyo가 무엇인가요?\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"푸뇨는 저희 로봇의 이름입니다. 일본어로는 \\\"푸뇨\\\" (ぷにょ)란 부드럽고 귀여우며 탄력 있는 것을 설명합니다. 이는 토요타의 미래 가정 로봇이 안전하고 능력이 있으며 일하는 것이 즐거워야 한다는 우리의 철학을 나타냅니다. 이러한 로봇공학 접근은 다양한 형태로 나타날 수 있지만, 저희를 움직이게 하는 비전은 친근하고 안전하게 가정에서 일상적인 도전 과제를 수행할 수 있는 인간형 로봇입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_0.png\",\n        alt: \"푸뇨\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"푸뇨 하드웨어 플랫폼\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"푸뇨의 손, 팔, 그리고 가슴은 유연한 소재와 촉각 센서로 덮여 있어서 접촉을 느낄 수 있습니다. 이러한 부드러움은 푸뇨가 다루는 물건에 적응하여 안정성, 마찰력 증가, 그리고 균일하게 분산된 접촉력을 가능하게 합니다. 촉각 감지를 통해 푸뇨는 물체에 조절된 힘을 가할 수 있고, 접촉을 감지하며 (예기치 못한 접촉도), 물체의 미끄러짐이나 충돌에 반응할 수 있습니다. 촉각 감지는 또한 사람들과 상호 작용하는 데 중요합니다. 무거운 물건을 들거나 사람들을 신체적으로 지원하는 상황에서, 로봇은 자신의 몸을 인식하고 적절히 상호 작용해야 합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Punyo는 소프트 로봇으로 간주되지만 그 소프트함의 기초에는 두 개의 \\\"단단한\\\" 로봇 팔, 강성의 상체 프레임 및 허리 액추에이터가 있습니다. 저희 방식은 기존 로봇의 정밀성, 강도 및 신뢰성을 기계식 소프트 로봇 시스템의 적응성, 충격 저항성 및 감각 단숨함과 결합한 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_1.png\",\n        alt: \"Punyo Soft Robot\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"어깨부터 손목까지, Punyo의 팔은 공기로 채워진 블래더 또는 \\\"버블\\\"로 덮여 있습니다. 이 블래더는 우리 뼈를 덮는 살과 비슷합니다. 각 버블은 압력 센서에 튜브를 통해 연결되어 버블의 외부 표면에 가해지는 힘을 감지합니다. 각각의 버블(각 팔에 13개)은 원하는 강성으로 개별적으로 압력을 가할 수 있으며, 로봇 팔의 표면에 대략 5cm의 유연성을 추가합니다. 이것은 로봇의 큰 표면에 적응성 및 촉각 감지 기능을 추가하는 저렴하고 가벼운 모듈식 방법입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_2.png\",\n        alt: \"Punyo Soft Robot\"\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"팔을 덮고 있는 거품은 성형 열 밀봉 PVC 패널을 사용하여 만들어졌어요. 큰 하나의 거품이 푸뇨(Punyo)의 손목을 덮고 있지만 팔 아래의 관절이 움직이는 데 제약이 없어요. 나머지 팔 거품은 각각 두 개의 챔버로 이루어진 여섯 개의 작은 링으로 구성되어 있어요. 팔을 덮고 있는 것은 거품을 보호하고 케이블 걸림을 방지하며 외부 접촉 표면 소재를 수정할 수 있도록 하는 맞춤형 패브릭 슬리브입니다. 슬리브는 유지보수 용이하게 제거 가능하며 미적인 사용자 정의 기회를 제공해요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"푸뇨에는 그립퍼가 없기 때문에 손가락이나 엄지가 없어요. 적어도 아직은요. 대신, 푸뇨는 \\\"발\\\"을 가지고 있어요. 각 발은 안에 카메라가 있는 단일 고 마찰 라텍스 거품이에요 (TRI의 소프트-버블 비수용각감각 센서 기반, punyo.tech/bubblegripper). 이 거품 내부에는 점 패턴이 인쇄되어 있어요. 거품이 무언가에 닿으면 점 패턴이 변형돼요. 내부 카메라는 이 변형을 사용하여 힘을 추정하고 이미지를 바로 학습된 시각 운동 정책에 전달해요.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"전신 기술 교육을 위한 원격 작동 도구\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우리는 다양한 전신 작업에서 하드웨어를 테스트했어요. 푸뇨는 고감각 정책을 학습하기 위해 두 가지 강력한 방법인 확산 정책과 예시 지도 강화 학습을 사용해요. 하드웨어에서 직접 새로운 작업을 시도하고 이러한 학습 파이프라인에 예시 시연을 제공하기 위해 전신 기술에 직관적인 원격 운영 인터페이스를 개발 중이에요. 작년 TRI에서 발표된 확산 정책은 사람의 시범을 사용하여 어려운 모델링 작업을 위한 견고한 감각 운동 정책(카메라 및 촉각 피드백 사용)을 학습해요. 예시 지도 강화 학습(EGRL)은 작업이 시뮬레이션에서 모델링되어야 하며 작은 시범 집합이 로봇의 탐색을 안내해야 해요. 두 가지 방법 모두 유연성을 활용하고 촉각 피드백을 통합하는 견고한 정책을 생성해요.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Synergy Teleop을 이해하세요: 핵심 전신 조작 작업, 예를 들어 붙잡기와 들기와 같은 작업은 손을 사용한 붙잡기와 유사한 시너지로 분할되어 있습니다. 이러한 동작은 우리가 게임패드 인터페이스를 통해 개별적으로 제어하는 동작입니다. 팔을 독립적으로 들린 후 내리고, 각 팔의 붙잡기를 열고 닫음으로써 단일 및 양손으로 붙잡고 다시 붙잡고 들기 및 붙잡은 상태에서 조작하는 팔을 위해 조합합니다. 표준적이고 저렴한 게임패드만 필요로 하며, 실험은 연구실이나 야생에서 아무 곳에서나 수행될 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_3.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"계층적 운영-공간 Teleop: 더 복잡하고 정교하거나 섬세한 작업을 위해, 발과 팔꿈치, 그리고 상체 각도를 직접 제어할 수 있습니다. 이들을 제어함으로써 우리는 예를 들어 몸을 앞으로 숙여 가슴에 물건을 모을 수 있고, 다른 팔을 물체 위에 감아놓거나 다른 팔은 아래에 위치시키고, 뒤로 기울여 들 수 있습니다. 움직임 캡처 카메라를 사용하여 우리의 원격 조종자의 등, 어깨, 팔꿈치, 그리고 손에 부착된 톱니들을 추적하고 이를 로봇의 유사한 지점(운영 지점)에 대응시킵니다. 원격 조종자의 동작은 Punyo로 리디렉팅되어 어떤 사람이든 체형과 관계없이 시스템을 운영할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우리는 전신 움직임 제어 접근 방식을 통해 원격 조작 및 자율 확산 정책을 전개합니다. 예를 들어, 원격 조작 중에는 최우선 순위 작업인 종단부 자세 추적이 필요해 Punyo의 발이 원격 조종자의 발을 신뢰할 수 있게 추적해야 합니다. 팔꿈치 자세 추적은 중요도가 낮을 수 있으며, Punyo가 최우선 순위인 종단부 추적과 간섭하지 않는 한 원격 조작 팔꿈치 자세를 달성할 수 있습니다. 계층적 움직임 제어 프레임워크를 사용하면 제약 조건과 운영 지점 추적을 추가, 제거, 조정 및 재우선화하여 원격 조작 인터페이스를 신속히 반복할 수 있습니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The hierarchical framework also provides an interface for exploring physically reactive motions and human-robot interaction. An example is Punyo moving its elbow out of the way when an accidental bump is sensed. Because of the redundant joints in our arms, we can move the elbow without sacrificing end-effector motion. This control scheme can be used to allow a person to push Punyo’s arm out of the way mid-task to quickly grab something.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1400/1*wGszjFTuqa5Ludd8foyQXA.gif\",\n        alt: \"Image\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Guiding Reinforcement Learning with Human Examples\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We employ Example-Guided Reinforcement Learning (EGRL) to develop sturdy manipulation policies for tasks we can simulate. Demonstrating the task enhances the learning process efficiency and lets us influence the style of motion the robot uses to complete the task. We utilize Adversarial Motion Priors (AMP), typically used for stylizing computer-animated characters, to introduce human motion imitation into our reinforcement learning pipeline. All policies displayed below were trained with just one demonstration.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우리의 파이프라인은 시범 본따기 보상과 작업 목표 보상의 비율인 λ변수를 노출합니다. 이 변수를 사용하면 Punnyo가 동작을 모방하는 것과 순전히 탐구를 통해 작업을 성공적으로 수행하는 것 사이에서 어떻게 균형을 맞출지 조절할 수 있습니다. 예를 들어, 로봇의 어깨 위로 큰 항아리를 올리는 작업을 배우는 경우를 생각해보세요. 다이얼을 한 방향으로 돌리면(λ = 0), 로봇은 단순히 \\\"자세를 따라 하는\\\" 것으로, 항아리가 탁자를 떠나는지 여부에 관계없이 동일한 작업에 대한 인간 시범 동작을 모방합니다. 다이얼을 다른 방향으로 돌리면(λ = 1), 로봇은 전혀 시범을 무시하고, 항아리를 탁자에서 내리는 데만 집중하며 임무를 수행하는 데 필요한 어떤 비자연스러운 동작이라도 (희망적으로) 수렴합니다. 그 사이의 λ는 시범의 스타일로 작업을 완료하는 정책을 생성합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"작업 설명은 단지 항아리를 올리는 것보다 복잡할 수 있습니다. 예를 들어, 우리는 속도, 저에너지 소비, 또는 보다 견고한 작업 완료를 장려할 수도 있습니다. 기능 요구 사항을 인간 시범 스타일과 섞어서 결합하면 효율적이지만 사람들이 예측하고 가인화하기가 더 쉬운 로봇이 될 수 있으며, 그들이 더 편안하고 생산적으로 협력할 수 있게 해줍니다. 다양한 작업, 상황, 로봇, 인간 협력자에 대한 적절한 균형을 발견하기를 고대합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1400/1*UbzHiHf4pgipEfifAtmnSw.gif\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1400/1*Ne8RXDgCjVWAZenDHi5zxA.gif\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Plan-Guided Reinforcement Learning\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"강화 학습은 훈련을 위해 작업을 시뮬레이션에서 모델링해야 합니다. 따라서 우리는 텔레오퍼레이션 대신 모델 기반 플래너를 사용하여 데모를 위한 계획을 세울 수 있습니다. 이를 Plan-Guided Reinforcement Learning (PGRL)라고 부릅니다. 플래너를 활용하면 텔레오퍼레이션으로는 어려운 장기 과제들도 수행할 수 있습니다. 또한 인간 입력에 대한 의존성을 줄여 자동으로 여러 데모를 생성할 수 있으며, 이는 Punyo가 처리할 수 있는 작업 수를 확장하는 한 걸음입니다. 이 능력은 언젠가 Punyo가 스스로 새로운 기술을 학습할 수 있게 할 수도 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"현재 최신 모델 기반 플래너는 복잡한 접촉 시퀀스를 포함하는 동작 계획을 생성할 수 있지만, 그 결과를 온라인에서 폐쇄 루프 방식으로 사용하기에는 충분히 빠르지 않습니다. 또한 모델의 부정확함과 가정으로 인해 시뮬레이션에서도 물리적으로 실행할 수 없는 경우가 있을 수 있습니다. 따라서 로봇 하드웨어에서 열린 루프로 재생될 때 원하는 대로 대상 객체를 조작하지 못할 가능성이 있는 궤적이 남습니다. 그러나 이대로 오픈 루프로 실행되는 경우 원하는 대상 객체를 조작하지 못할 가능성이 매우 큽니다. 그러나 예제 기반 강화 학습을 사용하여 이러한 불안정한 궤적을 가져다가 실행 가능한 피드백 정책으로 변경할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"짧은 접촉을 통해 장기적인 행동을 합성하는 데 접촉 묵시 플래너를 사용합니다. 플래너는 글로벌 접촉 추론을 가능하게 하는 몇 가지 가정을 합니다. 그런데 이로 인해 해당 결과를 하드웨어에서 직접 사용할 수 없습니다. 그러나 이 궤적은 EGRL 파이프라인에 시드로 작업에 필요한 동작 및 접촉 시퀀스를 제공하는 훌륭한 데모로 작용합니다. 작업 목표, 도메인 랜덤화 및 이러한 초기 데모로 동작 탐색을 가리키는 경우, Punyo는 모션 계획을 따르는 폐쇄 루프 정책을 효율적으로 학습하여 하드웨어에서 견고하게 어려운 작업을 수행할 수 있습니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1400/1*XuViGzzbwQISa9HyDmIzMw.gif\",\n        alt: \"Image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1400/1*XiqFuPa83jIeSndMtEsczg.gif\",\n        alt: \"Image\"\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"안전하고 생산적인 협력을 향해\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"TRI와 다른 곳에서 능숙한 능력이 급증하는 가운데, 현재의 로봇 및 조작 전략은 여러 작업과 기술을 이루리 하는 데 많은 어려움을 겪고 있습니다. 손으로 다루기에 너무 큰 물체, 팔이 안정화해야 하는 물건 더미, 한 팔에 들고 있는 물체와 다른 물체를 다루는 작업, 그리고 좁은 공간과 사람 주변에서 안전하게 운영하는 능력이 필요합니다. 그리퍼 기반 민첩성과 병행하여 전체 몸을 이용한 조작을 위한 하드웨어, 지식 및 데이터셋 개발은 다양한 능력을 갖춘 조작 플랫폼을 만들기 위해 중요합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch_4.png\",\n        alt: \"Punyo Soft Robot\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"로봇의 가슴, 팔 및 기타 몸 표면을 조작하기 위해 잠금 해제하는 것은 기계적으로 유리합니다. 준수 및 마찰과 결합하여, 로봇은 더 적은 에너지로 큰 물건을 잡고 조작할 수 있어서 페이로드와 배터리 수명을 늘리고 더 저렴한 시스템을 가능하게합니다. 부드럽기 때문에 충격을 흡수할 수 있어 로봇의 안전과 주변 사람들의 안전을 위해 사용될 수 있습니다. 촉각 감지를 추가하면 접촉력을 밀접하게 모니터링하고 제어하여 부드럽고 복잡하며 상호작용적이고 안정적인 조작이 가능합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"TRI의 Punyo 팀은 이 문제를 해결하기 위해 구축되었습니다. 부드러운 로봇공학, 접촉을 고려한 계획 및 학습, 촉각 감지 및 인간-로봇 상호작용에 대한 우리의 전문가들은 로봇과 사람이 안전하게, 생산적으로, 행복하게 공존할 수 있는 미래에 전념하고 있습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"감사의 글\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"러스트 테드레이크, 토피 알비나, 막스 바지라차리야, 길 프랫, 꽁대짱 하시모토(푸뇨라는 이름으로!), 벤 버치필, 알레한드로 카스트로, 에릭 쿠시너, 홍카이 다이, 리처드 데니토, 에블린 딕슨, 지미 도르니에, 세라 에브치민, 시유안 펑, 크리스 기드웰, 스테이시 기드웰, 담롱 구오이, 브렌든 해쓰어웨이, 앨리슨 헨리, 피비 호르간, 제나 홀만, 스티브 이아코비노, 루카스 카울, 나빈 쿠퍼스와미, 앨리사 라우, 존 라이히티, 수잔 마이클, 고든 리차드슨, 파스 샤, 리사 토바스코, 아비나시 우딤찬다니, 트리스탄 위팅, 자로드 윌슨, 존 요우, 맹채오 장, 알렉스 알렉자니안, 리드 알스팩, 윌 나이트, 리즈 펄먼, 그리고 우리 아기들과 소중한 이들에게 특별한 감사를 ❤️\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-20-MeetPunyoTRIsSoftRobotforWhole-BodyManipulationResearch"},"buildId":"0asLlD6on3tm8cIfzBaxd","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>