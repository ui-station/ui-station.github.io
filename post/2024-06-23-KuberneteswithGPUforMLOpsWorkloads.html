<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-06-23-KuberneteswithGPUforMLOpsWorkloads" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-06-23-KuberneteswithGPUforMLOpsWorkloads" data-gatsby-head="true"/><meta name="twitter:title" content="MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 00:51" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-70e5ce89f3d962ac.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_buildManifest.js" defer=""></script><script src="/_next/static/wfHLuDA3kTGBYfaM5IGXk/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-KuberneteswithGPUforMLOpsWorkloads&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>이 기사에서는 GPU가 쿠버네티스와 통합되어 기계 학습 워크로드를 실행하는 방법에 대해 논의하고자 합니다.</p>
<p>저는 주변에 있는 NVIDIA GeForce RTX 3050을 가지고 아이디어를 얻었어요 💡... ` Kubernetes</p>
<p>빠르게 쿠버네티스와 GPU를 통합하여 딥 러닝 훈련 배포를 실행해봅시다!</p>
<ol start="0">
<li>Docker가 설치되어 있는지 확인하세요. 아직 설치되지 않았다면 여기에서 Docker를 다운로드하세요.</li>
</ol>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>NVIDIA Container Toolkit for Docker</h1>
<ul>
<li>NVIDIA 드라이버를 업데이트해주세요</li>
</ul>
<pre><code class="hljs language-js">wget <span class="hljs-attr">https</span>:<span class="hljs-comment">//developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb</span>
sudo dpkg -i cuda-keyring_1<span class="hljs-number">.1</span>-1_all.<span class="hljs-property">deb</span>
sudo apt-get update
sudo apt-get -y install cuda-toolkit-<span class="hljs-number">12</span>-<span class="hljs-number">5</span>
</code></pre>
<ul>
<li>공식 웹사이트에서 해당 OS에 맞는 NVIDIA 컨테이너 툴킷을 설치해주세요.</li>
<li>제가 WSL을 사용하고 있기 때문에 apt 명령어를 통해 설치하겠습니다.</li>
</ul>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">curl -fsSL <span class="hljs-attr">https</span>:<span class="hljs-comment">//nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \</span>
  &#x26;&#x26; curl -s -L <span class="hljs-attr">https</span>:<span class="hljs-comment">//nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \</span>
    sed <span class="hljs-string">'s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g'</span> | \
    sudo tee /etc/apt/sources.<span class="hljs-property">list</span>.<span class="hljs-property">d</span>/nvidia-container-toolkit.<span class="hljs-property">list</span>
</code></pre>
<ul>
<li>저장소에서 패키지 목록을 업데이트합니다:</li>
</ul>
<pre><code class="hljs language-js">sudo apt-get update
</code></pre>
<ul>
<li>NVIDIA Container Toolkit 패키지를 설치합니다:</li>
</ul>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">sudo apt-get install -y nvidia-container-toolkit
</code></pre>
<p><img src="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png" alt="KuberneteswithGPUforMLOpsWorkloads"></p>
<ul>
<li>도커를 실행할 수 있도록 런타임 구성하기</li>
</ul>
<pre><code class="hljs language-js">sudo nvidia-ctk runtime configure --runtime=docker
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>아래는 테이블 태그를 Markdown 형식으로 변경한 코드입니다.</p>
<img src="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_1.png">
<ul>
<li>restart docker</li>
</ul>
<pre><code class="hljs language-js">sudo systemctl restart docker
</code></pre>
<ul>
<li>Docker Desktop</li>
</ul>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>만일 Docker Desktop을 사용 중이라면, 설정을 다르게 구성하고 daemon.json을 수정해야 합니다.</p>
<ul>
<li>왼쪽 상단의 설정 ⚙️ 로 이동하여 Docker Engine으로 이동한 다음 다음 구성을 추가하십시오. (,를 잊지 말고 json 구문을 확인해주세요 😅)</li>
</ul>
<pre><code class="hljs language-js"><span class="hljs-string">"runtimes"</span>: {
  <span class="hljs-string">"nvidia"</span>: {
    <span class="hljs-string">"args"</span>: [],
    <span class="hljs-string">"path"</span>: <span class="hljs-string">"nvidia-container-runtime"</span>
  }
}
</code></pre>
<p><img src="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_2.png" alt="이미지"></p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ol start="2">
<li>Apply 및 다시 시작을 클릭하고 GPU 확인</li>
</ol>
<p>다음 명령어로 도커가 런타임으로 GPU를 사용하는지 확인하세요.</p>
<pre><code class="hljs language-shell">sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi
</code></pre>
<p><img src="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_3.png" alt="이미지"></p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>Minikube</h1>
<p>로컬에서 Kubernetes 클러스터를 프로비저닝하는 데 Minikube를 사용할 것입니다.</p>
<ul>
<li><a href="%EB%A7%81%ED%81%AC">여기</a>에서 운영 체제에 맞게 Minikube를 다운로드하세요.</li>
<li>Minikube 이진 파일을 다운로드한 후 다음 명령어로 Minikube를 시작하세요. Minikube를 시작하기 전에 Docker가 실행 중인지 확인하세요.</li>
</ul>
<pre><code class="hljs language-js">minikube start --gpus all --driver=docker --addons=ingress
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>Minikube의 nvidia-gpu-device-plugin 애드온은 Kubernetes 클러스터에서 GPU 지원을 활성화하는 데 설계되었습니다. 이 애드온을 사용하면 Kubernetes가 GPU가 필요한 작업로드를 인식하고 예약하여 클러스터에서 GPU 리소스를 사용할 수 있게 됩니다.</p>
<p>NVIDIA GPU 장치 플러그인이란 무엇인가요?</p>
<p>NVIDIA GPU 장치 플러그인은 Kubernetes 클러스터에서 NVIDIA GPU를 사용할 수 있게 하는 Kubernetes 장치 플러그인입니다. 이 플러그인을 사용하면 Kubernetes가 GPU 리소스를 컨테이너에 할당하고 예약하여 응용 프로그램이 GPU 가속을 사용할 수 있도록 합니다.</p>
<p>주요 기능</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ul>
<li>
<p>GPU 발견:</p>
<ul>
<li>노드에서 NVIDIA GPU를 자동으로 발견하여 Kubernetes에서 스케줄 가능한 리소스로 이용할 수 있습니다.</li>
</ul>
</li>
<li>
<p>GPU 리소스 관리:</p>
<ul>
<li>GPU 리소스를 컨테이너에 할당하는 작업을 관리합니다. Pod에 요청된 GPU 수를 확인하고 GPU 리소스를 스케줄링하는 복잡성을 처리합니다.</li>
</ul>
</li>
</ul>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<ol start="3">
<li>격리:</li>
</ol>
<ul>
<li>GPU 리소스의 격리를 제공하여 GPU 워크로드가 서로 간섭하지 않도록 보장합니다.</li>
</ul>
<ol start="4">
<li>메트릭 및 모니터링:</li>
</ol>
<ul>
<li>GPU 활용에 관한 메트릭을 노출하여 GPU 워크로드의 모니터링과 스케일링에 활용할 수 있습니다.</li>
</ul>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>쿠버네티스에서 GPU 가용성 확인하기</h1>
<p>GPU 노드가 사용 가능한지 노드 세부정보를 확인하여 확인하세요</p>
<pre><code class="hljs language-js">kubectl get nodes -o <span class="hljs-string">"custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,CAPACITY:.status.capacity"</span>
</code></pre>
<ul>
<li>작업으로 확인하고 매니페스트 파일을 적용하세요</li>
</ul>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">batch/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Job</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">gpu-job</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">template:</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">containers:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">gpu-container</span>
          <span class="hljs-attr">image:</span> <span class="hljs-string">nvidia/cuda:12.5.0-base-ubuntu22.04</span>
          <span class="hljs-attr">resources:</span>
            <span class="hljs-attr">limits:</span>
              <span class="hljs-attr">nvidia.com/gpu:</span> <span class="hljs-number">1</span> <span class="hljs-comment"># Request 1 GPU</span>
          <span class="hljs-attr">command:</span> [<span class="hljs-string">"nvidia-smi"</span>]
      <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Never</span>
</code></pre>
<pre><code class="hljs language-bash">kubectl apply -f gpu-verify.yaml
</code></pre>
<p><img src="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_4.png" alt="Kubernetes with GPU for MLOps Workloads"></p>
<ul>
<li>파드 가져오기</li>
</ul>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<pre><code class="hljs language-js">kubectl get po
</code></pre>
<p><img src="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_5.png" alt="이미지"></p>
<ul>
<li>GPU 로그 확인</li>
</ul>
<pre><code class="hljs language-js">kubectl logs &#x3C;pod>
</code></pre>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p><img src="/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_6.png" alt="이미지"></p>
<p>그리고 시작합니다..!</p>
<p>GPU를 보실 수 있습니다. 업데이트를 기다려주세요. 몇 가지 워크로드를 실행하고 여기에 공유할 예정입니다.</p>
<p>이제 쿠버네티스에서 머신러닝 모델을 훈련할 수 있습니다.</p>
<!-- ui-station 사각형 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4877378276818686" data-ad-slot="7249294152" data-ad-format="auto" data-full-width-responsive="true"></ins></p>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<p>읽어 주셔서 감사합니다!</p>
<p><a href="https://www.linkedin.com/in/sivanaik/" rel="nofollow" target="_blank">LinkedIn 프로필</a></p>
<p><a href="https://x.com/sivanaikk" rel="nofollow" target="_blank">x.com에서의 프로필</a></p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"MLOps 작업을 위한 GPU와 함께 Kubernetes 사용 방법","description":"","date":"2024-06-23 00:51","slug":"2024-06-23-KuberneteswithGPUforMLOpsWorkloads","content":"\n이 기사에서는 GPU가 쿠버네티스와 통합되어 기계 학습 워크로드를 실행하는 방법에 대해 논의하고자 합니다.\n\n저는 주변에 있는 NVIDIA GeForce RTX 3050을 가지고 아이디어를 얻었어요 💡... ` Kubernetes\n\n빠르게 쿠버네티스와 GPU를 통합하여 딥 러닝 훈련 배포를 실행해봅시다!\n\n0. Docker가 설치되어 있는지 확인하세요. 아직 설치되지 않았다면 여기에서 Docker를 다운로드하세요.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# NVIDIA Container Toolkit for Docker\n\n- NVIDIA 드라이버를 업데이트해주세요\n\n```js\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb\nsudo dpkg -i cuda-keyring_1.1-1_all.deb\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-12-5\n```\n\n- 공식 웹사이트에서 해당 OS에 맞는 NVIDIA 컨테이너 툴킷을 설치해주세요.\n- 제가 WSL을 사용하고 있기 때문에 apt 명령어를 통해 설치하겠습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n  \u0026\u0026 curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n```\n\n- 저장소에서 패키지 목록을 업데이트합니다:\n\n```js\nsudo apt-get update\n```\n\n- NVIDIA Container Toolkit 패키지를 설치합니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nsudo apt-get install -y nvidia-container-toolkit\n```\n\n![KuberneteswithGPUforMLOpsWorkloads](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png)\n\n- 도커를 실행할 수 있도록 런타임 구성하기\n\n```js\nsudo nvidia-ctk runtime configure --runtime=docker\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n아래는 테이블 태그를 Markdown 형식으로 변경한 코드입니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_1.png\" /\u003e\n\n- restart docker\n\n```js\nsudo systemctl restart docker\n```\n\n- Docker Desktop\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n만일 Docker Desktop을 사용 중이라면, 설정을 다르게 구성하고 daemon.json을 수정해야 합니다.\n\n- 왼쪽 상단의 설정 ⚙️ 로 이동하여 Docker Engine으로 이동한 다음 다음 구성을 추가하십시오. (,를 잊지 말고 json 구문을 확인해주세요 😅)\n\n```js\n\"runtimes\": {\n  \"nvidia\": {\n    \"args\": [],\n    \"path\": \"nvidia-container-runtime\"\n  }\n}\n```\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n2. Apply 및 다시 시작을 클릭하고 GPU 확인\n\n다음 명령어로 도커가 런타임으로 GPU를 사용하는지 확인하세요.\n\n```shell\nsudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi\n```\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_3.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# Minikube\n\n로컬에서 Kubernetes 클러스터를 프로비저닝하는 데 Minikube를 사용할 것입니다.\n\n- [여기](링크)에서 운영 체제에 맞게 Minikube를 다운로드하세요.\n- Minikube 이진 파일을 다운로드한 후 다음 명령어로 Minikube를 시작하세요. Minikube를 시작하기 전에 Docker가 실행 중인지 확인하세요.\n\n```js\nminikube start --gpus all --driver=docker --addons=ingress\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nMinikube의 nvidia-gpu-device-plugin 애드온은 Kubernetes 클러스터에서 GPU 지원을 활성화하는 데 설계되었습니다. 이 애드온을 사용하면 Kubernetes가 GPU가 필요한 작업로드를 인식하고 예약하여 클러스터에서 GPU 리소스를 사용할 수 있게 됩니다.\n\nNVIDIA GPU 장치 플러그인이란 무엇인가요?\n\nNVIDIA GPU 장치 플러그인은 Kubernetes 클러스터에서 NVIDIA GPU를 사용할 수 있게 하는 Kubernetes 장치 플러그인입니다. 이 플러그인을 사용하면 Kubernetes가 GPU 리소스를 컨테이너에 할당하고 예약하여 응용 프로그램이 GPU 가속을 사용할 수 있도록 합니다.\n\n주요 기능\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n- GPU 발견:\n\n  - 노드에서 NVIDIA GPU를 자동으로 발견하여 Kubernetes에서 스케줄 가능한 리소스로 이용할 수 있습니다.\n\n- GPU 리소스 관리:\n\n  - GPU 리소스를 컨테이너에 할당하는 작업을 관리합니다. Pod에 요청된 GPU 수를 확인하고 GPU 리소스를 스케줄링하는 복잡성을 처리합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n3. 격리:\n\n- GPU 리소스의 격리를 제공하여 GPU 워크로드가 서로 간섭하지 않도록 보장합니다.\n\n4. 메트릭 및 모니터링:\n\n- GPU 활용에 관한 메트릭을 노출하여 GPU 워크로드의 모니터링과 스케일링에 활용할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n# 쿠버네티스에서 GPU 가용성 확인하기\n\nGPU 노드가 사용 가능한지 노드 세부정보를 확인하여 확인하세요\n\n```js\nkubectl get nodes -o \"custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,CAPACITY:.status.capacity\"\n```\n\n- 작업으로 확인하고 매니페스트 파일을 적용하세요\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: gpu-job\nspec:\n  template:\n    spec:\n      containers:\n        - name: gpu-container\n          image: nvidia/cuda:12.5.0-base-ubuntu22.04\n          resources:\n            limits:\n              nvidia.com/gpu: 1 # Request 1 GPU\n          command: [\"nvidia-smi\"]\n      restartPolicy: Never\n```\n\n```bash\nkubectl apply -f gpu-verify.yaml\n```\n\n![Kubernetes with GPU for MLOps Workloads](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_4.png)\n\n- 파드 가져오기\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nkubectl get po\n```\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_5.png)\n\n- GPU 로그 확인\n\n```js\nkubectl logs \u003cpod\u003e\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n![이미지](/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_6.png)\n\n그리고 시작합니다..!\n\nGPU를 보실 수 있습니다. 업데이트를 기다려주세요. 몇 가지 워크로드를 실행하고 여기에 공유할 예정입니다.\n\n이제 쿠버네티스에서 머신러닝 모델을 훈련할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n읽어 주셔서 감사합니다!\n\n[LinkedIn 프로필](https://www.linkedin.com/in/sivanaik/)\n\n[x.com에서의 프로필](https://x.com/sivanaikk)\n","ogImage":{"url":"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png"},"coverImage":"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e이 기사에서는 GPU가 쿠버네티스와 통합되어 기계 학습 워크로드를 실행하는 방법에 대해 논의하고자 합니다.\u003c/p\u003e\n\u003cp\u003e저는 주변에 있는 NVIDIA GeForce RTX 3050을 가지고 아이디어를 얻었어요 💡... ` Kubernetes\u003c/p\u003e\n\u003cp\u003e빠르게 쿠버네티스와 GPU를 통합하여 딥 러닝 훈련 배포를 실행해봅시다!\u003c/p\u003e\n\u003col start=\"0\"\u003e\n\u003cli\u003eDocker가 설치되어 있는지 확인하세요. 아직 설치되지 않았다면 여기에서 Docker를 다운로드하세요.\u003c/li\u003e\n\u003c/ol\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003eNVIDIA Container Toolkit for Docker\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eNVIDIA 드라이버를 업데이트해주세요\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ewget \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb\u003c/span\u003e\nsudo dpkg -i cuda-keyring_1\u003cspan class=\"hljs-number\"\u003e.1\u003c/span\u003e-1_all.\u003cspan class=\"hljs-property\"\u003edeb\u003c/span\u003e\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e공식 웹사이트에서 해당 OS에 맞는 NVIDIA 컨테이너 툴킷을 설치해주세요.\u003c/li\u003e\n\u003cli\u003e제가 WSL을 사용하고 있기 때문에 apt 명령어를 통해 설치하겠습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ecurl -fsSL \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\u003c/span\u003e\n  \u0026#x26;\u0026#x26; curl -s -L \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\u003c/span\u003e\n    sed \u003cspan class=\"hljs-string\"\u003e's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g'\u003c/span\u003e | \\\n    sudo tee /etc/apt/sources.\u003cspan class=\"hljs-property\"\u003elist\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ed\u003c/span\u003e/nvidia-container-toolkit.\u003cspan class=\"hljs-property\"\u003elist\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e저장소에서 패키지 목록을 업데이트합니다:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003esudo apt-get update\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eNVIDIA Container Toolkit 패키지를 설치합니다:\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003esudo apt-get install -y nvidia-container-toolkit\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_0.png\" alt=\"KuberneteswithGPUforMLOpsWorkloads\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e도커를 실행할 수 있도록 런타임 구성하기\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003esudo nvidia-ctk runtime configure --runtime=docker\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e아래는 테이블 태그를 Markdown 형식으로 변경한 코드입니다.\u003c/p\u003e\n\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_1.png\"\u003e\n\u003cul\u003e\n\u003cli\u003erestart docker\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003esudo systemctl restart docker\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eDocker Desktop\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e만일 Docker Desktop을 사용 중이라면, 설정을 다르게 구성하고 daemon.json을 수정해야 합니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e왼쪽 상단의 설정 ⚙️ 로 이동하여 Docker Engine으로 이동한 다음 다음 구성을 추가하십시오. (,를 잊지 말고 json 구문을 확인해주세요 😅)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-string\"\u003e\"runtimes\"\u003c/span\u003e: {\n  \u003cspan class=\"hljs-string\"\u003e\"nvidia\"\u003c/span\u003e: {\n    \u003cspan class=\"hljs-string\"\u003e\"args\"\u003c/span\u003e: [],\n    \u003cspan class=\"hljs-string\"\u003e\"path\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"nvidia-container-runtime\"\u003c/span\u003e\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eApply 및 다시 시작을 클릭하고 GPU 확인\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e다음 명령어로 도커가 런타임으로 GPU를 사용하는지 확인하세요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-shell\"\u003esudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003eMinikube\u003c/h1\u003e\n\u003cp\u003e로컬에서 Kubernetes 클러스터를 프로비저닝하는 데 Minikube를 사용할 것입니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"%EB%A7%81%ED%81%AC\"\u003e여기\u003c/a\u003e에서 운영 체제에 맞게 Minikube를 다운로드하세요.\u003c/li\u003e\n\u003cli\u003eMinikube 이진 파일을 다운로드한 후 다음 명령어로 Minikube를 시작하세요. Minikube를 시작하기 전에 Docker가 실행 중인지 확인하세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eminikube start --gpus all --driver=docker --addons=ingress\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003eMinikube의 nvidia-gpu-device-plugin 애드온은 Kubernetes 클러스터에서 GPU 지원을 활성화하는 데 설계되었습니다. 이 애드온을 사용하면 Kubernetes가 GPU가 필요한 작업로드를 인식하고 예약하여 클러스터에서 GPU 리소스를 사용할 수 있게 됩니다.\u003c/p\u003e\n\u003cp\u003eNVIDIA GPU 장치 플러그인이란 무엇인가요?\u003c/p\u003e\n\u003cp\u003eNVIDIA GPU 장치 플러그인은 Kubernetes 클러스터에서 NVIDIA GPU를 사용할 수 있게 하는 Kubernetes 장치 플러그인입니다. 이 플러그인을 사용하면 Kubernetes가 GPU 리소스를 컨테이너에 할당하고 예약하여 응용 프로그램이 GPU 가속을 사용할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e주요 기능\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eGPU 발견:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e노드에서 NVIDIA GPU를 자동으로 발견하여 Kubernetes에서 스케줄 가능한 리소스로 이용할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eGPU 리소스 관리:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGPU 리소스를 컨테이너에 할당하는 작업을 관리합니다. Pod에 요청된 GPU 수를 확인하고 GPU 리소스를 스케줄링하는 복잡성을 처리합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e격리:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eGPU 리소스의 격리를 제공하여 GPU 워크로드가 서로 간섭하지 않도록 보장합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e메트릭 및 모니터링:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eGPU 활용에 관한 메트릭을 노출하여 GPU 워크로드의 모니터링과 스케일링에 활용할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003ch1\u003e쿠버네티스에서 GPU 가용성 확인하기\u003c/h1\u003e\n\u003cp\u003eGPU 노드가 사용 가능한지 노드 세부정보를 확인하여 확인하세요\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ekubectl get nodes -o \u003cspan class=\"hljs-string\"\u003e\"custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,CAPACITY:.status.capacity\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e작업으로 확인하고 매니페스트 파일을 적용하세요\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-yaml\"\u003e\u003cspan class=\"hljs-attr\"\u003eapiVersion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ebatch/v1\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003ekind:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eJob\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003emetadata:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003egpu-job\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003espec:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003etemplate:\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003espec:\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003econtainers:\u003c/span\u003e\n        \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003egpu-container\u003c/span\u003e\n          \u003cspan class=\"hljs-attr\"\u003eimage:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003envidia/cuda:12.5.0-base-ubuntu22.04\u003c/span\u003e\n          \u003cspan class=\"hljs-attr\"\u003eresources:\u003c/span\u003e\n            \u003cspan class=\"hljs-attr\"\u003elimits:\u003c/span\u003e\n              \u003cspan class=\"hljs-attr\"\u003envidia.com/gpu:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003e# Request 1 GPU\u003c/span\u003e\n          \u003cspan class=\"hljs-attr\"\u003ecommand:\u003c/span\u003e [\u003cspan class=\"hljs-string\"\u003e\"nvidia-smi\"\u003c/span\u003e]\n      \u003cspan class=\"hljs-attr\"\u003erestartPolicy:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eNever\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003ekubectl apply -f gpu-verify.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_4.png\" alt=\"Kubernetes with GPU for MLOps Workloads\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e파드 가져오기\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ekubectl get po\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_5.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGPU 로그 확인\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ekubectl logs \u0026#x3C;pod\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-KuberneteswithGPUforMLOpsWorkloads_6.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e그리고 시작합니다..!\u003c/p\u003e\n\u003cp\u003eGPU를 보실 수 있습니다. 업데이트를 기다려주세요. 몇 가지 워크로드를 실행하고 여기에 공유할 예정입니다.\u003c/p\u003e\n\u003cp\u003e이제 쿠버네티스에서 머신러닝 모델을 훈련할 수 있습니다.\u003c/p\u003e\n\u003c!-- ui-station 사각형 --\u003e\n\u003cp\u003e\u003cins class=\"adsbygoogle\" style=\"display:block\" data-ad-client=\"ca-pub-4877378276818686\" data-ad-slot=\"7249294152\" data-ad-format=\"auto\" data-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\u003c/p\u003e\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\u003cp\u003e읽어 주셔서 감사합니다!\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.linkedin.com/in/sivanaik/\" rel=\"nofollow\" target=\"_blank\"\u003eLinkedIn 프로필\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://x.com/sivanaikk\" rel=\"nofollow\" target=\"_blank\"\u003ex.com에서의 프로필\u003c/a\u003e\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-KuberneteswithGPUforMLOpsWorkloads"},"buildId":"wfHLuDA3kTGBYfaM5IGXk","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>