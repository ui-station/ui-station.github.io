<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>로지스틱 회귀의 시각적 이해 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-18-AVisualUnderstandingofLogisticRegression" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="로지스틱 회귀의 시각적 이해 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="로지스틱 회귀의 시각적 이해 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-18-AVisualUnderstandingofLogisticRegression" data-gatsby-head="true"/><meta name="twitter:title" content="로지스틱 회귀의 시각적 이해 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-18 20:20" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BHFR6GTH9P"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-BHFR6GTH9P');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-4f7b40c1114f0d09.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_buildManifest.js" defer=""></script><script src="/_next/static/bb_yO9GbCvdfc_n71SfUf/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">로지스틱 회귀의 시각적 이해</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="로지스틱 회귀의 시각적 이해" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 18, 2024</span><span class="posts_reading_time__f7YPP">26<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-18-AVisualUnderstandingofLogisticRegression&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>로지스틱 회귀는 이진 분류에서 사용되는 통계 모델입니다. 이진 분류 문제에서 대상은 두 가지 범주만 가지고 있으므로 기계 학습 알고리즘은 데이터를 이 두 범주 중 하나로 분류해야 합니다. 로지스틱 회귀는 각 범주에 속할 확률을 예측하는 데 사용되는 로지스틱 함수에서 유래했습니다. 로지스틱 회귀는 지도 기계 학습, 금융, 의학 및 사회과학 등 여러 분야에 응용됩니다.</p>
<p>본 문서에서는 로지스틱 회귀의 시각적 이해를 제시하고, 이 모델의 각 요소의 역할을 설명할 것입니다. 이 글을 읽으면 독자는 로지스틱 회귀와 그 한계에 대한 직관적인 이해를 가질 수 있습니다.</p>
<p>본 문서의 모든 이미지는 저자에 의해 제작되었습니다.</p>
<p></p>
<p>간단한 데이터셋</p>
<p>로지스틱 회귀가 분류 문제를 해결하는 방법을 보여주기 위해 간단한 데이터셋을 만들겠습니다. 먼저 필요한 모든 Python 라이브러리를 가져옵니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.<span class="hljs-property">pyplot</span> <span class="hljs-keyword">as</span> plt

<span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">linear_model</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">LogisticRegression</span>
<span class="hljs-keyword">from</span> matplotlib.<span class="hljs-property">colors</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">ListedColormap</span>

<span class="hljs-keyword">import</span> warnings
warnings.<span class="hljs-title function_">filterwarnings</span>(<span class="hljs-string">"ignore"</span>)
</code></pre>
<p>우리의 데이터셋은 두 개의 특성 (x₁, x₂)과 100개의 예제가 있습니다. 이는 두 개의 클러스터로 구성되어 각각 정규 분포를 사용하여 만들어졌습니다.</p>
<p></p>
<pre><code class="hljs language-python">np.random.seed(<span class="hljs-number">0</span>)
x1 = np.random.randn(<span class="hljs-number">50</span>, <span class="hljs-number">2</span>) * <span class="hljs-number">0.4</span> + np.array([-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>])
x2 = np.random.randn(<span class="hljs-number">50</span>, <span class="hljs-number">2</span>) * <span class="hljs-number">0.4</span> + np.array([<span class="hljs-number">2.6</span>, <span class="hljs-number">2.6</span>])

y = <span class="hljs-number">50</span>*[<span class="hljs-number">0</span>]+<span class="hljs-number">50</span>*[<span class="hljs-number">1</span>]
X = np.vstack((x1, x2))
</code></pre>
<p>이 데이터셋에 대한 target 또는 label 열 (y)도 정의했습니다. 첫 번째 클러스터의 데이터 포인트들의 레이블은 0이고, 두 번째 클러스터의 데이터 포인트들의 레이블은 1입니다. 따라서 target 열에는 2개의 레이블만 있어서 binary classification 문제가 됩니다. 이제 이 데이터셋을 플롯합니다. 결과는 아래 그림에서 확인할 수 있습니다.</p>
<pre><code class="hljs language-python">plt.scatter(x1[:, <span class="hljs-number">0</span>], x1[:,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=0"</span>)
plt.scatter(x2[:, <span class="hljs-number">0</span>], x2[:,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=1"</span>)
plt.legend(loc=<span class="hljs-string">"best"</span>, fontsize=<span class="hljs-number">14</span>)
plt.xlabel(<span class="hljs-string">"$x_1$"</span>, fontsize=<span class="hljs-number">16</span>)
plt.ylabel(<span class="hljs-string">"$x_2$"</span>, fontsize=<span class="hljs-number">16</span>)
plt.show()
</code></pre>
<p></p>
<p>지금 이 데이터셋을 분류하기 위해 로지스틱 회귀 모델을 사용할 수 있습니다. 이 모델을 훈련시켜 이 데이터셋의 데이터 포인트의 이진 레이블을 예측할 것입니다. 또한 이 모델은 이 훈련 데이터셋에 없는 어떤 보이지 않는 데이터 포인트에 대한 예측을 총체화할 수 있어야 합니다.</p>
<p>로지스틱 회귀 방정식</p>
<p>로지스틱 회귀 모델을 이해하려면 먼저 그 방정식을 자세히 살펴봐야 합니다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_2.png" alt="로지스틱 회귀 방정식"></p>
<p></p>
<p>여기서 P는 데이터 포인트 (x₁, x₂)가 레이블 1일 확률을 예측한 값입니다. 이 방정식은 로지스틱 회귀 모델의 핵심입니다. 그냥 데이터 포인트를 가져와서 해당 레이블이 1일 확률을 계산하는 것이죠. 이 함수는 표준 로지스틱 또는 시그모이드 함수라고 불립니다. 아래 소개된 그림 2는 이 함수의 플롯을 보여줍니다. x가 ∞로 다가갈수록 y는 1로 수렴하고, x가 -∞로 다가갈수록 y는 0으로 수렴함을 주목하세요. 게다가 x=0에서 y=0.5인 것을 알 수 있습니다. 따라서 y는 항상 0과 1 사이에 제한됩니다. 우리는 확률이 항상 [0,1] 범위 내에 있음을 알고 있기 때문에 결과의 확률을 표현하기 위해 시그모이드 함수를 사용할 수 있습니다. 이 함수는 임의의 실수 값을 가진 입력(x)을 0과 1 사이의 확률 값으로 매핑할 수 있습니다.</p>
<p></p>
<p>이제 방정식 1이 특징 x₁과 x₂로 표현된 데이터 포인트를 입력하여 해당 레이블이 1일 확률로 변환하는 방법을 알아봅시다.</p>
<p>차원 축소</p>
<p>방정식 1을 두 부분으로 나눌 수 있습니다. 먼저 입력 데이터(x₁, x₂)를 선형 항으로 변환합니다.</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_5.png" alt="equation"></p>
<p></p>
<p>여기서 w₀, w₁ 및 w₂는 모델의 매개변수이며 이 값은 모델을 학습한 후에 결정될 것입니다. 이것은 두 개의 특징 (x₁, x₂)으로 시작하여 방정식 2에 의해 제공된 단일 숫자로 변환하는 차원 축소의 예입니다. 실제로 우리는 입력 데이터 포인트의 차원을 2에서 1로 줄입니다. 이 차원 축소가 기하학적으로 어떻게 이루어지는지 살펴보겠습니다. 데이터 포인트 (x₁, x₂)로 시작합니다. 우리는 이를 2차원 공간에서 점 또는 벡터로 표시할 수 있습니다(Figure 3). 또한 벡터 w를 다음과 같이 정의할 수 있습니다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_6.png" alt="vector w equation"></p>
<p>벡터 u를 w의 단위 벡터로 정의할 수 있도록 하는 다음 방정식을 사용하여 정의합시다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_7.png" alt="unit vector equation"></p>
<p></p>
<p>벡터 u가 w와 같은 방향을 가지지만 길이는 1입니다. 이제 벡터 x를 w에 평행한 벡터와 수직인 벡터 두 가지 구성 요소 벡터로 분해할 수 있습니다. 평행 벡터는 x를 w에 투영한 벡터로 불리며 x^로 표시됩니다(그림 3). 또한 x와 w의 내적을 사용하여 x^를 얻을 수 있습니다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_8.png" alt="Figure 3"></p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_9.png" alt="Image"></p>
<p>x^의 길이는 x를 w에 투영한 스칼라 투영이라고 하며 다음과 같이 주어집니다:</p>
<p></p>
<p>이제 x^를 ||w||로 곱하면 d로 표시된 새로운 벡터를 얻습니다:</p>
<p>그리고 d의 길이는 u가 단위 벡터이기 때문에 w.x와 동일합니다. 내적의 정의에 따라 다음과 같습니다:</p>
<p></p>
<p>이것은 방정식 2에서 정의된 용어 일부를 제공합니다. 그러나 w₀를 추가해야 합니다.</p>
<p>이를 위해 다음과 같은 벡터를 정의합니다.</p>
<p></p>
<p>이제, d에서 o를 뺀다면 다음과 같습니다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_14.png" alt="image"></p>
<p>즉, d-o의 길이는 방정식 2에서 정의된 용어와 같다는 것을 의미합니다 (그림 4). 이것은 벡터 d의 새로운 원점을 정의하는 것과 같습니다. 기하학적 관점에서 보면, 우리는 벡터 o의 끝 지점을 기준으로 d의 길이를 측정합니다. 반면 2차원 공간의 원점을 기준으로 하지 않습니다. (이 그림에서 w₀가 양수라고 가정하였기 때문에 벡터 o는 w의 반대 방향에 있습니다).</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_15.png" alt="image"></p>
<p></p>
<p>위의 텍스트를 친근한 톤으로 한국어로 번역하겠습니다.</p>
<p>요약하자면, 방정식 2의 용어 역할은 차원 축소입니다. 입력 데이터 점의 차원을 1로 줄입니다. 따라서 변환된 데이터 점은 모두 원점을 통과하고 벡터 w를 따라 있는 선 l로 가정할 수 있습니다. 이 선을 새로운 축으로 생각하면, 원점은 벡터 o의 끝에 있는 새 축이라는 것을 알 수 있습니다. 이제 이 축 위의 변환된 데이터 점의 좌표는 방정식 2에 의해 주어집니다.</p>
<p>벡터 x가 입력 데이터 점을 나타낸다고 가정했습니다. 새로운 축 l 상의 변환된 데이터 점을 얻기 위해 우리는 먼저 직교 투영을 수행하고 x를 w에 투영한 벡터를 찾았습니다. 그런 다음 결과 벡터인 (x^)에 w의 길이를 곱하여 벡터 d를 얻었습니다. 벡터 d는 새로운 축 l 상의 변환된 데이터 점을 나타내지만, 그 좌표는 o에서 d를 뺀 d-o로 주어집니다.</p>
<p>이제 우리는 장난감 데이터 세트에서 변환된 일차원 데이터 점을 계산할 수 있습니다. 여기서는 scikit-learn 라이브러리의 로지스틱 회귀 모델을 사용합니다. 데이터 세트를 fitting한 후, 방정식 2의 선형 항의 계수를 검색할 수 있습니다.</p>
<pre><code class="hljs language-python">lg=LogisticRegression()
lg.fit(X,y)
w = lg.coef_[<span class="hljs-number">0</span>]
w1, w2 = w[<span class="hljs-number">0</span>], w[<span class="hljs-number">1</span>]
w0 = lg.intercept_[<span class="hljs-number">0</span>]
<span class="hljs-built_in">print</span>(<span class="hljs-string">"w0={}, w1={}, w2={}"</span>.<span class="hljs-built_in">format</span>(w0, w1, w2))
</code></pre>
<p></p>
<p>w0=1.2124, w1=0.9033, w2=0.9075</p>
<p>이제 w₁와 w₂의 값을 사용하여 벡터 w를 형성할 수 있습니다. w의 단위 벡터는 다음과 같이 정의됩니다:</p>
<p>[ w = \begin{bmatrix} 1.2124 \ 0.9033 \ 0.9075 \end{bmatrix} ]</p>
<p>다음과 같이 계산됩니다:</p>
<p></p>
<pre><code class="hljs language-js">length_w = np.<span class="hljs-property">linalg</span>.<span class="hljs-title function_">norm</span>(w);
u = w / length_w;
</code></pre>
<p>변환된 일차원 데이터 포인트들은 이 벡터를 따라 놓이게 될 것이고, u와 w가 동일한 방향을 가지고 있기 때문에 w도 따라 늘어날 것입니다. 이 선의 원점은 벡터 o=-w₀u의 끝에 위치합니다.</p>
<pre><code class="hljs language-js">o = -w0 * u;
</code></pre>
<p>다음 코드 스니펫을 통해 원본 데이터 세트, 벡터 w와 o, 그리고 변환된 데이터 포인트를 플롯합니다. 결과는 Figure 5에 표시됩니다.</p>
<p></p>
<pre><code class="hljs language-python">lt.figure(figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))

<span class="hljs-comment"># 원본 데이터 세트 플롯</span>
plt.scatter(X[y==<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=0"</span>, alpha=<span class="hljs-number">0.4</span>, color=<span class="hljs-string">"red"</span>)
plt.scatter(X[y==<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=1"</span>, alpha=<span class="hljs-number">0.4</span>, color=<span class="hljs-string">"blue"</span>)

<span class="hljs-comment"># 변환된 포인트 플롯</span>
transformed_points = np.dot(X, w).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) * np.tile(w, (<span class="hljs-built_in">len</span>(X), <span class="hljs-number">1</span>))
plt.scatter(transformed_points[:, <span class="hljs-number">0</span>], transformed_points[:, <span class="hljs-number">1</span>],
            alpha=<span class="hljs-number">0.5</span>, color=<span class="hljs-string">'green'</span>, label=<span class="hljs-string">"변환된\n포인트"</span>)

<span class="hljs-comment"># 포인트 o 플롯</span>
plt.scatter(o[<span class="hljs-number">0</span>], o[<span class="hljs-number">1</span>], color=<span class="hljs-string">'black'</span>, s=<span class="hljs-number">35</span>, zorder=<span class="hljs-number">10</span>)
<span class="hljs-comment"># 벡터 w와 o 플롯</span>
plt.quiver([<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>], w[<span class="hljs-number">0</span>], w[<span class="hljs-number">1</span>], color=[<span class="hljs-string">'b'</span>],
           width=<span class="hljs-number">0.01</span>, angles=<span class="hljs-string">'xy'</span>, scale_units=<span class="hljs-string">'xy'</span>, scale=<span class="hljs-number">1</span>, zorder=<span class="hljs-number">5</span>)
plt.quiver([<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>], o[<span class="hljs-number">0</span>], o[<span class="hljs-number">1</span>], color=[<span class="hljs-string">'black'</span>],
           width=<span class="hljs-number">0.01</span>, angles=<span class="hljs-string">'xy'</span>, scale_units=<span class="hljs-string">'xy'</span>, scale=<span class="hljs-number">1</span>, zorder=<span class="hljs-number">5</span>)

<span class="hljs-comment"># 벡터 w를 따라 나아가는 선</span>
plt.plot([-<span class="hljs-number">12</span>*u[<span class="hljs-number">0</span>], <span class="hljs-number">19</span>*u[<span class="hljs-number">0</span>]],
         [-<span class="hljs-number">12</span>*u[<span class="hljs-number">1</span>], <span class="hljs-number">19</span>*u[<span class="hljs-number">1</span>]], color=<span class="hljs-string">'gray'</span>)

<span class="hljs-comment"># 축 생성</span>
plt.axhline(<span class="hljs-number">0</span>, color=<span class="hljs-string">'black'</span>, linewidth=<span class="hljs-number">0.8</span>)
plt.axvline(<span class="hljs-number">0</span>, color=<span class="hljs-string">'black'</span>, linewidth=<span class="hljs-number">0.8</span>)
plt.text(<span class="hljs-number">0.3</span>, <span class="hljs-number">1.2</span>, <span class="hljs-string">"$\mathregular{w}$"</span>, color=<span class="hljs-string">'b'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)
plt.text(-<span class="hljs-number">1.7</span>, -<span class="hljs-number">1</span>, <span class="hljs-string">"$\mathregular{o}$"</span>, color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)

plt.xlim([-<span class="hljs-number">8</span>, <span class="hljs-number">6</span>])
plt.ylim([-<span class="hljs-number">8</span>, <span class="hljs-number">6</span>])
ax = plt.gca()
ax.set_aspect(<span class="hljs-string">'equal'</span>)
plt.legend(loc=<span class="hljs-string">"best"</span>, fontsize=<span class="hljs-number">13</span>)
plt.xlabel(<span class="hljs-string">'$x_1$'</span>, fontsize=<span class="hljs-number">16</span>)
plt.ylabel(<span class="hljs-string">'$x_2$'</span>, fontsize=<span class="hljs-number">16</span>)

plt.show()
</code></pre>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_17.png" alt="그림"></p>
<p>모든 변환된 데이터 포인트는 w 벡터를 따라 있는 선상에 있음을 유의해주세요. 이 선의 원점은 점 o에 위치합니다. 원본 데이터 세트의 각 데이터 포인트 (x₁, x₂)는 이 선상의 데이터 포인트로 변환되며, 변환된 데이터 포인트 (각 녹색 점)의 점 o로부터의 거리는 w₀+w₁x₁+w₂x₂와 같습니다.</p>
<p>시그모이드 함수 추가</p>
<p></p>
<p>먼저 우리는 방정식 1을 두 부분으로 나눴다는 것을 기억해야 해요. 먼저 입력 데이터 (x₁, x₂)를 선형 항인 w₀+w₁x₁+w₂x₂로 변환합니다. 이는 차원 축소 과정으로, 변환된 일차원 데이터 포인트를 만들어냅니다. 다음 부분은 이러한 변환된 데이터 포인트에 시그모이드 함수를 정의합니다. 이 함수는 변환된 데이터 포인트가 레이블 1을 가지는 확률을 계산합니다. 이 확률을 계산하기 위해 각 변환된 데이터 포인트의 좌표 (l=w₀+w₁x₁+w₂x₂)를 시그모이드 함수에 넣는 것입니다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_18.png" alt="이미지"></p>
<p>다음 코드 스니펫은 이 확률을 계산하고 도표 6에 시그모이드 함수를 그리는 것입니다:</p>
<pre><code class="hljs language-js">plt.<span class="hljs-title function_">figure</span>((figsize = (<span class="hljs-number">15</span>, <span class="hljs-number">5</span>)));

transformed_points = np.<span class="hljs-title function_">dot</span>(X, w) + w0;
plt.<span class="hljs-title function_">scatter</span>(
  transformed_points,
  [<span class="hljs-number">0</span>] * <span class="hljs-title function_">len</span>(transformed_points),
  (s = <span class="hljs-number">280</span>),
  (color = <span class="hljs-string">"green"</span>),
  (alpha = <span class="hljs-number">0.4</span>),
  (label = <span class="hljs-string">"변환된 데이터 포인트"</span>)
);
l_array = np.<span class="hljs-title function_">linspace</span>(-<span class="hljs-number">12</span>, <span class="hljs-number">8</span>, <span class="hljs-number">100</span>);
P = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.<span class="hljs-title function_">exp</span>(-l_array));
plt.<span class="hljs-title function_">plot</span>(l_array, P, (color = <span class="hljs-string">"black"</span>), (label = <span class="hljs-string">"시그모이드 함수"</span>));

plt.<span class="hljs-title function_">xlim</span>([-<span class="hljs-number">8</span>, <span class="hljs-number">8</span>]);
plt.<span class="hljs-title function_">ylim</span>([<span class="hljs-number">0</span>, <span class="hljs-number">1.05</span>]);
plt.<span class="hljs-title function_">legend</span>((loc = <span class="hljs-string">"best"</span>), (fontsize = <span class="hljs-number">18</span>));
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">"$l$"</span>, (fontsize = <span class="hljs-number">22</span>));
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">"$P$"</span>, (fontsize = <span class="hljs-number">22</span>));
plt.<span class="hljs-title function_">xticks</span>((fontsize = <span class="hljs-number">18</span>));
plt.<span class="hljs-title function_">yticks</span>((fontsize = <span class="hljs-number">18</span>));
plt.<span class="hljs-title function_">show</span>();
</code></pre>
<p></p>
<p>그래서 각 변환된 데이터 포인트마다 y=1의 확률이 있습니다. 그러나 실제 레이블을 얻기 위해서는 확률 임계값을 정의해야 합니다 (y의 실제 값). 이 임계값은 이진 분류 결정을 내릴 확률을 정의합니다. 기본적으로 로지스틱 회귀는 P=0.5의 임계값을 선택합니다. 시그모이드 곡선은 원점에서 값이 0.5임을 기억해 주세요. 따라서 w₀+w₁x₁+w₂x₂≥0 (y^=1)인 모든 포인트에 대해 예측된 레이블은 1이며, <code>w₀+w₁x₁+w₂x₂&#x3C;0 (y^=0)</code>인 모든 포인트에 대해 예측된 레이블은 0입니다. 따라서 확률 임계값은 각 변환된 데이터 포인트의 예측된 확률(P)을 y^로 나타내는 예측된 이진 레이블로 변환합니다. 이것은 Figure 7에 표시되어 있습니다.</p>
<p>우리는 또한 이 시그모이드 곡선을 원래 2차원 공간에 그릴 수 있습니다. 이 결과는 Figure 8에 표시되어 있습니다.</p>
<p></p>
<pre><code class="hljs language-js">plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))

# 원본 데이터셋 플롯
plt.<span class="hljs-title function_">scatter</span>(X[y==<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=0"</span>, alpha=<span class="hljs-number">0.7</span>, color=<span class="hljs-string">"red"</span>)
plt.<span class="hljs-title function_">scatter</span>(X[y==<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=1"</span>, alpha=<span class="hljs-number">0.7</span>, color=<span class="hljs-string">"blue"</span>)

# 투영된 점 플롯
transformed_points = np.<span class="hljs-title function_">dot</span>(X, w).<span class="hljs-title function_">reshape</span>(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) * np.<span class="hljs-title function_">tile</span>(w, (<span class="hljs-title function_">len</span>(X), <span class="hljs-number">1</span>))
plt.<span class="hljs-title function_">scatter</span>(transformed_points[:, <span class="hljs-number">0</span>], transformed_points[:, <span class="hljs-number">1</span>],
            alpha=<span class="hljs-number">0.5</span>, color=<span class="hljs-string">'green'</span>, label=<span class="hljs-string">"Transformed\n data points"</span>)

# 점 o 플롯
plt.<span class="hljs-title function_">scatter</span>(o[<span class="hljs-number">0</span>], o[<span class="hljs-number">1</span>], color=<span class="hljs-string">'black'</span>, s=<span class="hljs-number">35</span>)
# 벡터 w 플롯
plt.<span class="hljs-title function_">quiver</span>([<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>], w[<span class="hljs-number">0</span>], w[<span class="hljs-number">1</span>], color=[<span class="hljs-string">'b'</span>],
           width=<span class="hljs-number">0.01</span>, angles=<span class="hljs-string">'xy'</span>, scale_units=<span class="hljs-string">'xy'</span>, scale=<span class="hljs-number">1</span>, zorder=<span class="hljs-number">5</span>)


# 시그모이드 곡선 플롯
k = <span class="hljs-number">200</span>
l_array = np.<span class="hljs-title function_">linspace</span>(-<span class="hljs-number">12</span>, <span class="hljs-number">8</span>, k).<span class="hljs-title function_">reshape</span>(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)
w_array = l_array * np.<span class="hljs-title function_">tile</span>(u, (k, <span class="hljs-number">1</span>))
# 벡터 w를 따라 선 그리기
plt.<span class="hljs-title function_">plot</span>([-<span class="hljs-number">12</span>*u[<span class="hljs-number">0</span>], <span class="hljs-number">19</span>*u[<span class="hljs-number">0</span>]],
         [-<span class="hljs-number">12</span>*u[<span class="hljs-number">1</span>], <span class="hljs-number">19</span>*u[<span class="hljs-number">1</span>]], color=<span class="hljs-string">'gray'</span>)

sigm_x_array = ((w_array - o) /u)[:,<span class="hljs-number">0</span>]
sigm_prob = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span>+np.<span class="hljs-title function_">exp</span>(-sigm_x_array))
norm_vector = np.<span class="hljs-title function_">array</span>([-w2, w1]) <span class="hljs-keyword">if</span> w1>=<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> np.<span class="hljs-title function_">array</span>([w2, -w1])
sigm_y_array = sigm_prob.<span class="hljs-title function_">reshape</span>(k, <span class="hljs-number">1</span>) * np.<span class="hljs-title function_">tile</span>(norm_vector, (k, <span class="hljs-number">1</span>))
sigm_curve_array = sigm_y_array + w_array

plt.<span class="hljs-title function_">plot</span>(sigm_curve_array[:, <span class="hljs-number">0</span>], sigm_curve_array[:, <span class="hljs-number">1</span>], color=<span class="hljs-string">"blue"</span>)
# 시그모이드 곡선의 y축 플롯
plt.<span class="hljs-title function_">plot</span>([o[<span class="hljs-number">0</span>], o[<span class="hljs-number">0</span>]+<span class="hljs-number">2</span>*norm_vector[<span class="hljs-number">0</span>]],
         [o[<span class="hljs-number">1</span>], o[<span class="hljs-number">1</span>]+<span class="hljs-number">2</span>*norm_vector[<span class="hljs-number">1</span>]], color=<span class="hljs-string">'gray'</span>)

# 축 그리기
plt.<span class="hljs-title function_">axhline</span>(<span class="hljs-number">0</span>, color=<span class="hljs-string">'black'</span>, linewidth=<span class="hljs-number">0.8</span>)
plt.<span class="hljs-title function_">axvline</span>(<span class="hljs-number">0</span>, color=<span class="hljs-string">'black'</span>, linewidth=<span class="hljs-number">0.8</span>)
plt.<span class="hljs-title function_">text</span>(<span class="hljs-number">0.3</span>, <span class="hljs-number">1.2</span>, <span class="hljs-string">"$\mathregular{w}$"</span>, color=<span class="hljs-string">'b'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)
plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">0.8</span>, -<span class="hljs-number">1.4</span>, <span class="hljs-string">"$\mathregular{o}$"</span>, color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)
plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">2.9</span>, <span class="hljs-number">1.3</span>, <span class="hljs-string">"$P$"</span>, color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>, rotation = <span class="hljs-number">50</span>)

plt.<span class="hljs-title function_">xlim</span>([-<span class="hljs-number">8</span>, <span class="hljs-number">6.2</span>])
plt.<span class="hljs-title function_">ylim</span>([-<span class="hljs-number">8</span>, <span class="hljs-number">6.2</span>])
ax = plt.<span class="hljs-title function_">gca</span>()
ax.<span class="hljs-title function_">set_aspect</span>(<span class="hljs-string">'equal'</span>)
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">'$x_1$'</span>, fontsize=<span class="hljs-number">16</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">'$x_2$'</span>, fontsize=<span class="hljs-number">16</span>)

plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p>하지만 2차원 공간에서 결정 경계를 어떻게 찾을까요? 이를 위해 2차원 공간의 모든 점을 찾아야 합니다. 이러한 점들은 1차원 공간의 원점으로 매핑됩니다 (Figure 8의 점 o). Figure 9에서 이러한 점들을 찾을 수 있는 방법을 보여줍니다.</p>
<p></p>
<p>여기서는 x라는 지점을 찾고 있습니다.</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_23.png" alt="image"></p>
<p>이러한 점들은 x^에서 l에 수직인 선상에 있습니다. 우리는 이 선을 s로 표시할 것입니다 (도표 9). 모든 점들이 2차원 평면의 원점으로부터의 거리는 |w₀| / ||w||입니다(점과 선 사이의 거리는 그 선에 수직이고 해당 점을 통과하는 선분의 길이입니다). 이제 s의 모든 점들에 대한 벡터 d는 다음과 같습니다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_24.png" alt="image"></p>
<p></p>
<p>따라서 데이터 지점이 선 s에 있으면, 해당 변환된 지점은 지점 o(1차원 공간의 원점)에 있고, 그 확률은 0.5가 됩니다. 이로써 선 s가 2차원 공간의 로지스틱 회귀의 결정 경계라는 것을 결론짓게 되었습니다. 왜냐하면 이 선 상의 모든 데이터 지점은 1차원 공간의 시그모이드 곡선의 결정 경계로 매핑되기 때문입니다. 따라서 이제 우리 모델의 결정 경계를 쉽게 그릴 수 있습니다.</p>
<pre><code class="hljs language-js">boundary_point = (-w0 / length_w**<span class="hljs-number">2</span>) * w

plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))

plt.<span class="hljs-title function_">scatter</span>(X[y==<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=0"</span>, alpha=<span class="hljs-number">0.7</span>, color=<span class="hljs-string">"red"</span>)
plt.<span class="hljs-title function_">scatter</span>(X[y==<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=1"</span>, alpha=<span class="hljs-number">0.7</span>, color=<span class="hljs-string">"blue"</span>)

plt.<span class="hljs-title function_">scatter</span>(o[<span class="hljs-number">0</span>], o[<span class="hljs-number">1</span>], color=<span class="hljs-string">'black'</span>, s=<span class="hljs-number">35</span>)
# 벡터 w 그리기
plt.<span class="hljs-title function_">quiver</span>([<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>], w[<span class="hljs-number">0</span>], w[<span class="hljs-number">1</span>], color=[<span class="hljs-string">'b'</span>],
           width=<span class="hljs-number">0.01</span>, angles=<span class="hljs-string">'xy'</span>, scale_units=<span class="hljs-string">'xy'</span>, scale=<span class="hljs-number">1</span>, zorder=<span class="hljs-number">5</span>)

plt.<span class="hljs-title function_">quiver</span>([<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">1</span>], color=[<span class="hljs-string">'black'</span>],
           width=<span class="hljs-number">0.01</span>, angles=<span class="hljs-string">'xy'</span>, scale_units=<span class="hljs-string">'xy'</span>, scale=<span class="hljs-number">1</span>, zorder=<span class="hljs-number">5</span>)

# 결정 경계 그리기
plt.<span class="hljs-title function_">plot</span>([boundary_point[<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">0</span>]-<span class="hljs-number">6</span>],
         [boundary_point[<span class="hljs-number">1</span>], boundary_point[<span class="hljs-number">1</span>]-<span class="hljs-number">6</span>*(-w1/w2)],
         color=<span class="hljs-string">'black'</span>, linestyle=<span class="hljs-string">"--"</span>)
plt.<span class="hljs-title function_">plot</span>([boundary_point[<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">0</span>]+<span class="hljs-number">6</span>],
         [boundary_point[<span class="hljs-number">1</span>], boundary_point[<span class="hljs-number">1</span>]+<span class="hljs-number">6</span>*(-w1/w2)],
         color=<span class="hljs-string">'black'</span>, linestyle=<span class="hljs-string">"--"</span>)

# 시그모이드 곡선 그리기
k = <span class="hljs-number">200</span>
l_array = np.<span class="hljs-title function_">linspace</span>(-<span class="hljs-number">8.4</span>, <span class="hljs-number">8</span>, k).<span class="hljs-title function_">reshape</span>(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)
w_array = l_array * np.<span class="hljs-title function_">tile</span>(u, (k, <span class="hljs-number">1</span>))

# 벡터 w를 따른 선 그리기
plt.<span class="hljs-title function_">plot</span>([-<span class="hljs-number">9</span>*u[<span class="hljs-number">0</span>], <span class="hljs-number">8</span>*u[<span class="hljs-number">0</span>]],
         [-<span class="hljs-number">9</span>*u[<span class="hljs-number">1</span>], <span class="hljs-number">8</span>*u[<span class="hljs-number">1</span>]], color=<span class="hljs-string">'gray'</span>)

sigm_x_array = ((w_array - o) /u)[:,<span class="hljs-number">0</span>]
sigm_prob = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span>+np.<span class="hljs-title function_">exp</span>(-sigm_x_array))
norm_vector = np.<span class="hljs-title function_">array</span>([-w2, w1]) <span class="hljs-keyword">if</span> w1>=<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> np.<span class="hljs-title function_">array</span>([w2, -w1])
sigm_y_array = sigm_prob.<span class="hljs-title function_">reshape</span>(k, <span class="hljs-number">1</span>) * np.<span class="hljs-title function_">tile</span>(norm_vector, (k, <span class="hljs-number">1</span>))
sigm_curve_array = sigm_y_array + w_array

plt.<span class="hljs-title function_">plot</span>(sigm_curve_array[:, <span class="hljs-number">0</span>], sigm_curve_array[:, <span class="hljs-number">1</span>], color=<span class="hljs-string">"blue"</span>)
# 시그모이드 곡선의 y축 그리기
plt.<span class="hljs-title function_">plot</span>([o[<span class="hljs-number">0</span>], o[<span class="hljs-number">0</span>]+<span class="hljs-number">2</span>*norm_vector[<span class="hljs-number">0</span>]],
         [o[<span class="hljs-number">1</span>], o[<span class="hljs-number">1</span>]+<span class="hljs-number">2</span>*norm_vector[<span class="hljs-number">1</span>]], color=<span class="hljs-string">'gray'</span>)

# 축 그리기
plt.<span class="hljs-title function_">axhline</span>(<span class="hljs-number">0</span>, color=<span class="hljs-string">'grey'</span>, linewidth=<span class="hljs-number">0.8</span>)
plt.<span class="hljs-title function_">axvline</span>(<span class="hljs-number">0</span>, color=<span class="hljs-string">'grey'</span>, linewidth=<span class="hljs-number">0.8</span>)

plt.<span class="hljs-title function_">text</span>(<span class="hljs-number">0.35</span>, <span class="hljs-number">1</span>, <span class="hljs-string">"$\mathregular{w}$"</span>, color=<span class="hljs-string">'b'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)
plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">0.95</span>, -<span class="hljs-number">1.35</span>, <span class="hljs-string">"$\mathregular{o}$"</span>, color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)
plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">3.15</span>, <span class="hljs-number">0.5</span>, <span class="hljs-string">"$P$"</span>, color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>, rotation = <span class="hljs-number">50</span>)
plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-string">"결정 경계"</span>, color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">14</span>)
plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">0.3</span>, -<span class="hljs-number">0.7</span>, r<span class="hljs-string">"$\frac{-w_0}{\mathregular{||w||^2}\mathregular{w}$"</span>,
         color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">15</span>, weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)


plt.<span class="hljs-title function_">xlim</span>([-<span class="hljs-number">5.6</span>, <span class="hljs-number">4.2</span>])
plt.<span class="hljs-title function_">ylim</span>([-<span class="hljs-number">5.6</span>, <span class="hljs-number">4.2</span>])
ax = plt.<span class="hljs-title function_">gca</span>()
ax.<span class="hljs-title function_">set_aspect</span>(<span class="hljs-string">'equal'</span>)

plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">'$x_1$'</span>, fontsize=<span class="hljs-number">16</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">'$x_2$'</span>, fontsize=<span class="hljs-number">16</span>)

plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p>우리는 또한 여기서 발견한 결정 경계의 위치를 유효성 검사할 수 있습니다. 이를 위해 모델의 경계를 다른 방법을 사용하여 그리는 함수를 정의합니다. 먼저 2차원 공간에 메시 그리드를 생성하고 이를 사용하여 훈련된 로지스틱 회귀 모델을 사용하여 해당 지점의 목표를 예측합니다. y^=0 및 y^=1인 지점은 서로 다른 색으로 표시되므로 그리드가 충분히 잘 그려진 경우 모델의 결정 경계를 쉽게 확인할 수 있습니다. 결과는 Figure 11에 나와 있으며 이전에 발견한 결정 경계와 일치합니다.</p>
<p></p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">plot_boundary</span>(X, y, clf, lims):
    gx1, gx2 = np.<span class="hljs-title function_">meshgrid</span>(np.<span class="hljs-title function_">arange</span>(lims[<span class="hljs-number">0</span>], lims[<span class="hljs-number">1</span>], (lims[<span class="hljs-number">1</span>]-lims[<span class="hljs-number">0</span>])/<span class="hljs-number">300.0</span>),
                           np.<span class="hljs-title function_">arange</span>(lims[<span class="hljs-number">2</span>], lims[<span class="hljs-number">3</span>], (lims[<span class="hljs-number">3</span>]-lims[<span class="hljs-number">2</span>])/<span class="hljs-number">300.0</span>))
    
    cmap_light = <span class="hljs-title class_">ListedColormap</span>([<span class="hljs-string">'lightsalmon'</span>, <span class="hljs-string">'aqua'</span>])
            
    gx1l = gx1.<span class="hljs-title function_">flatten</span>()
    gx2l = gx2.<span class="hljs-title function_">flatten</span>()
    gx = np.<span class="hljs-title function_">vstack</span>((gx1l,gx2l)).<span class="hljs-property">T</span>
    gyhat = clf.<span class="hljs-title function_">predict</span>(gx)
    gyhat = gyhat.<span class="hljs-title function_">reshape</span>(gx1.<span class="hljs-property">shape</span>)

    plt.<span class="hljs-title function_">pcolormesh</span>(gx1, gx2, gyhat, cmap=cmap_light)
    plt.<span class="hljs-title function_">scatter</span>(X[y==<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=0"</span>, alpha=<span class="hljs-number">0.7</span>, color=<span class="hljs-string">"red"</span>)
    plt.<span class="hljs-title function_">scatter</span>(X[y==<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], X[y==<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], label=<span class="hljs-string">"y=1"</span>, alpha=<span class="hljs-number">0.7</span>, color=<span class="hljs-string">"blue"</span>)
    plt.<span class="hljs-title function_">legend</span>(loc=<span class="hljs-string">'upper left'</span>)


plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))
<span class="hljs-title function_">plot_boundary</span>(X,y,lg, lims=[-<span class="hljs-number">5.6</span>, <span class="hljs-number">4.2</span>, -<span class="hljs-number">5.6</span>, <span class="hljs-number">4.2</span>])

# <span class="hljs-title class_">Plot</span> the vector w
plt.<span class="hljs-title function_">quiver</span>([<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>], w[<span class="hljs-number">0</span>], w[<span class="hljs-number">1</span>], color=[<span class="hljs-string">'b'</span>],
           width=<span class="hljs-number">0.01</span>, angles=<span class="hljs-string">'xy'</span>, scale_units=<span class="hljs-string">'xy'</span>, scale=<span class="hljs-number">1</span>, zorder=<span class="hljs-number">5</span>)

plt.<span class="hljs-title function_">quiver</span>([<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">1</span>], color=[<span class="hljs-string">'black'</span>],
           width=<span class="hljs-number">0.01</span>, angles=<span class="hljs-string">'xy'</span>, scale_units=<span class="hljs-string">'xy'</span>, scale=<span class="hljs-number">1</span>, zorder=<span class="hljs-number">5</span>)

# plot the decision boundary
plt.<span class="hljs-title function_">plot</span>([boundary_point[<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">0</span>]-<span class="hljs-number">6</span>],
         [boundary_point[<span class="hljs-number">1</span>], boundary_point[<span class="hljs-number">1</span>]-<span class="hljs-number">6</span>*(-w1/w2)],
         color=<span class="hljs-string">'black'</span>, linestyle=<span class="hljs-string">"--"</span>)
plt.<span class="hljs-title function_">plot</span>([boundary_point[<span class="hljs-number">0</span>], boundary_point[<span class="hljs-number">0</span>]+<span class="hljs-number">6</span>],
         [boundary_point[<span class="hljs-number">1</span>], boundary_point[<span class="hljs-number">1</span>]+<span class="hljs-number">6</span>*(-w1/w2)],
         color=<span class="hljs-string">'black'</span>, linestyle=<span class="hljs-string">"--"</span>)

# <span class="hljs-title class_">Plot</span> the line along the vector w
plt.<span class="hljs-title function_">plot</span>([-<span class="hljs-number">9</span>*u[<span class="hljs-number">0</span>], <span class="hljs-number">8</span>*u[<span class="hljs-number">0</span>]],
         [-<span class="hljs-number">9</span>*u[<span class="hljs-number">1</span>], <span class="hljs-number">8</span>*u[<span class="hljs-number">1</span>]], color=<span class="hljs-string">'gray'</span>)

# <span class="hljs-title class_">Draw</span> axes
plt.<span class="hljs-title function_">axhline</span>(<span class="hljs-number">0</span>, color=<span class="hljs-string">'grey'</span>, linewidth=<span class="hljs-number">0.8</span>)
plt.<span class="hljs-title function_">axvline</span>(<span class="hljs-number">0</span>, color=<span class="hljs-string">'grey'</span>, linewidth=<span class="hljs-number">0.8</span>)

plt.<span class="hljs-title function_">text</span>(<span class="hljs-number">0.35</span>, <span class="hljs-number">1</span>, <span class="hljs-string">"$\mathregular{w}$"</span>, color=<span class="hljs-string">'b'</span>, fontsize=<span class="hljs-number">14</span>,
         weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)

plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-string">"$\hat{y}=1$\nregion"</span>, color=<span class="hljs-string">'blue'</span>, fontsize=<span class="hljs-number">14</span>)
plt.<span class="hljs-title function_">text</span>(<span class="hljs-number">1</span>, -<span class="hljs-number">5</span>, <span class="hljs-string">"$\hat{y}=0$\nregion"</span>, color=<span class="hljs-string">'red'</span>, fontsize=<span class="hljs-number">14</span>)
plt.<span class="hljs-title function_">text</span>(-<span class="hljs-number">0.3</span>, -<span class="hljs-number">0.7</span>, r<span class="hljs-string">"$\frac{-w_0}{\mathregular{||w||^2}\mathregular{w}$"</span>,
         color=<span class="hljs-string">'black'</span>, fontsize=<span class="hljs-number">15</span>, weight=<span class="hljs-string">"bold"</span>, style=<span class="hljs-string">"italic"</span>)

plt.<span class="hljs-title function_">xlim</span>([-<span class="hljs-number">5.6</span>, <span class="hljs-number">4.2</span>])
plt.<span class="hljs-title function_">ylim</span>([-<span class="hljs-number">5.6</span>, <span class="hljs-number">4.2</span>])
ax = plt.<span class="hljs-title function_">gca</span>()
ax.<span class="hljs-title function_">set_aspect</span>(<span class="hljs-string">'equal'</span>)

plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">'$x_1$'</span>, fontsize=<span class="hljs-number">16</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">'$x_2$'</span>, fontsize=<span class="hljs-number">16</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_26.png" alt="image"></p>
<p>여기에 결과를 요약해보겠습니다. 두 가지 특성을 갖는 데이터셋에서 로지스틱 회귀 모델의 의사결정 경계는 직선으로 형성됩니다. 이 직선은 모델의 매개변수 w₀, w₁, w₂에 의해 결정됩니다. 의사결정 경계는 벡터를 연장한 선에 수직입니다.</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_27.png" alt="image"></p>
<p></p>
<p>이 라인과 의사결정 경계의 교차점은 (-w₀ / ||w||²)w 벡터에 의해 결정됩니다.</p>
<p>고차원에서의 의사결정 경계</p>
<p>저희가 데이터셋에서 더 많은 피쳐를 가지고 있는 경우에 어떻게 될지 살펴봅시다. 우리는 같은 컨셉을 고차원으로 쉽게 적용할 수 있습니다. x₁, x₂, x₃라는 세 개의 피쳐를 가지고 있다고 상상해보겠습니다. 이제 로지스틱 회귀 방정식은 다음과 같습니다:</p>
<p></p>
<p>모델 매개변수는 w₀, w₁, w₂ 및 w₃입니다. 차원 축소 부분은 동일하며, 원본 데이터 포인트는 여전히 1차원 공간에 매핑됩니다. 변환된 데이터 포인트는 여전히 직선 l 상에 있으며 해당 벡터를 확장합니다:</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_29.png" alt="image"></p>
<p>결정 경계는 w로의 벡터 투영이 (-w₀ / ||w||²)w인 모든 포인트의 위치입니다. 이러한 포인트는 차원 축소 후 P=0.5를 갖게 됩니다. 따라서 결정 경계는 3차원 공간에서 평면입니다(도 12 참조). 이 평면은 l에 수직이며, l과의 교차점은 (-w₀ / ||w||²)w 벡터로 주어집니다.</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_30.png" alt="image"></p>
<p></p>
<p>보다 일반적으로, n차원 공간에서 로지스틱 회귀 모델은 n개의 매개변수 w₀, w₁, …, w_n을 가지고 있습니다. 여기에서, 만약 벡터를 확장한다면,</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_31.png" alt="image"></p>
<p>선 l로, 결정 경계는 n차원 초평면입니다. 이 초평면은 l에 수직이며, (-w₀ / ||w||²)w 벡터는 초평면과 l의 교차점을 나타냅니다.</p>
<p>로지스틱 회귀는 항상 n차원 공간에서 1차원 공간으로 차원 축소를 시작합니다. 따라서 그 결정 경계는 곡률이 없는 초평면입니다. 결정 경계가 초평면인 분류기는 선형 분류기라고 하며, 로지스틱 회귀는 그러한 분류기의 한 예입니다. 다른 예시로는 퍼셉트론과 서포트 벡터 머신(SVM)이 있습니다.</p>
<p></p>
<p>데이터 세트(특성이 n개 있는)는 이진 대상을 가지고 있고 n차원 초평면을 사용하여 서로 다른 라벨을 가진 데이터 포인트들을 완전히 분리할 수 있다면 선형 분리 가능하다고 합니다. 따라서 선형 분류기는 선형 분리 가능한 데이터 세트에 대한 완벽한 모델입니다. 지금까지 사용된 토이 데이터 세트는 선형 분리 가능했습니다(Figure 1), 그러나 많은 데이터 세트는 선형 분리가 불가능하며 로지스틱 회귀와 같은 모델은 그에 적합하지 않을 수 있습니다. Figure 13는 선형 분리가 불가능한 데이터 세트의 예시를 보여줍니다.</p>
<p><img src="/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_32.png" alt="Figure 13"></p>
<p>여기서 데이터 세트는 원 모양을 가지고 있으며, 직선을 사용하여 y=0 및 y=1을 가진 데이터 포인트들을 완벽하게 나눌 수 없습니다. 따라서 이러한 분류 문제에 로지스틱 회귀 모델을 사용할 수 없습니다.</p>
<p>이 기사에서는 선형 대수를 사용하여 로지스틱 회귀의 시각적 해석을 제공하려고 노력했습니다. 로지스틱 회귀는 1차원 공간으로의 차원 축소부터 시작하고, 그런 다음 변환된 데이터 포인트에 대한 확률을 할당합니다. 확률 임계값을 정의함으로써, 해당 데이터 포인트의 이진 대상에 대한 최종 예측을 얻을 수 있습니다. 1차원 공간으로의 차원 축소로 인해 로지스틱 회귀는 선형 분류기가 됩니다. 따라서 n개의 특성을 가진 데이터 세트에 적용되는 경우 의사 결정 경계는 n차원 초평면이 됩니다.</p>
<p></p>
<p>이 기사를 즐겁게 읽었으면 좋겠어요. 제 기사가 도움이 된다면, 저를 Medium에서 팔로우해 주세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"로지스틱 회귀의 시각적 이해","description":"","date":"2024-05-18 20:20","slug":"2024-05-18-AVisualUnderstandingofLogisticRegression","content":"\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_0.png\" /\u003e\n\n로지스틱 회귀는 이진 분류에서 사용되는 통계 모델입니다. 이진 분류 문제에서 대상은 두 가지 범주만 가지고 있으므로 기계 학습 알고리즘은 데이터를 이 두 범주 중 하나로 분류해야 합니다. 로지스틱 회귀는 각 범주에 속할 확률을 예측하는 데 사용되는 로지스틱 함수에서 유래했습니다. 로지스틱 회귀는 지도 기계 학습, 금융, 의학 및 사회과학 등 여러 분야에 응용됩니다.\n\n본 문서에서는 로지스틱 회귀의 시각적 이해를 제시하고, 이 모델의 각 요소의 역할을 설명할 것입니다. 이 글을 읽으면 독자는 로지스틱 회귀와 그 한계에 대한 직관적인 이해를 가질 수 있습니다.\n\n본 문서의 모든 이미지는 저자에 의해 제작되었습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n간단한 데이터셋\n\n로지스틱 회귀가 분류 문제를 해결하는 방법을 보여주기 위해 간단한 데이터셋을 만들겠습니다. 먼저 필요한 모든 Python 라이브러리를 가져옵니다.\n\n```js\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\nfrom matplotlib.colors import ListedColormap\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n```\n\n우리의 데이터셋은 두 개의 특성 (x₁, x₂)과 100개의 예제가 있습니다. 이는 두 개의 클러스터로 구성되어 각각 정규 분포를 사용하여 만들어졌습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nnp.random.seed(0)\nx1 = np.random.randn(50, 2) * 0.4 + np.array([-1, -1])\nx2 = np.random.randn(50, 2) * 0.4 + np.array([2.6, 2.6])\n\ny = 50*[0]+50*[1]\nX = np.vstack((x1, x2))\n```\n\n이 데이터셋에 대한 target 또는 label 열 (y)도 정의했습니다. 첫 번째 클러스터의 데이터 포인트들의 레이블은 0이고, 두 번째 클러스터의 데이터 포인트들의 레이블은 1입니다. 따라서 target 열에는 2개의 레이블만 있어서 binary classification 문제가 됩니다. 이제 이 데이터셋을 플롯합니다. 결과는 아래 그림에서 확인할 수 있습니다.\n\n```python\nplt.scatter(x1[:, 0], x1[:,1], label=\"y=0\")\nplt.scatter(x2[:, 0], x2[:,1], label=\"y=1\")\nplt.legend(loc=\"best\", fontsize=14)\nplt.xlabel(\"$x_1$\", fontsize=16)\nplt.ylabel(\"$x_2$\", fontsize=16)\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_1.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n지금 이 데이터셋을 분류하기 위해 로지스틱 회귀 모델을 사용할 수 있습니다. 이 모델을 훈련시켜 이 데이터셋의 데이터 포인트의 이진 레이블을 예측할 것입니다. 또한 이 모델은 이 훈련 데이터셋에 없는 어떤 보이지 않는 데이터 포인트에 대한 예측을 총체화할 수 있어야 합니다.\n\n로지스틱 회귀 방정식\n\n로지스틱 회귀 모델을 이해하려면 먼저 그 방정식을 자세히 살펴봐야 합니다:\n\n![로지스틱 회귀 방정식](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_2.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 P는 데이터 포인트 (x₁, x₂)가 레이블 1일 확률을 예측한 값입니다. 이 방정식은 로지스틱 회귀 모델의 핵심입니다. 그냥 데이터 포인트를 가져와서 해당 레이블이 1일 확률을 계산하는 것이죠. 이 함수는 표준 로지스틱 또는 시그모이드 함수라고 불립니다. 아래 소개된 그림 2는 이 함수의 플롯을 보여줍니다. x가 ∞로 다가갈수록 y는 1로 수렴하고, x가 -∞로 다가갈수록 y는 0으로 수렴함을 주목하세요. 게다가 x=0에서 y=0.5인 것을 알 수 있습니다. 따라서 y는 항상 0과 1 사이에 제한됩니다. 우리는 확률이 항상 [0,1] 범위 내에 있음을 알고 있기 때문에 결과의 확률을 표현하기 위해 시그모이드 함수를 사용할 수 있습니다. 이 함수는 임의의 실수 값을 가진 입력(x)을 0과 1 사이의 확률 값으로 매핑할 수 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제 방정식 1이 특징 x₁과 x₂로 표현된 데이터 포인트를 입력하여 해당 레이블이 1일 확률로 변환하는 방법을 알아봅시다.\n\n차원 축소\n\n방정식 1을 두 부분으로 나눌 수 있습니다. 먼저 입력 데이터(x₁, x₂)를 선형 항으로 변환합니다.\n\n![equation](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_5.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서 w₀, w₁ 및 w₂는 모델의 매개변수이며 이 값은 모델을 학습한 후에 결정될 것입니다. 이것은 두 개의 특징 (x₁, x₂)으로 시작하여 방정식 2에 의해 제공된 단일 숫자로 변환하는 차원 축소의 예입니다. 실제로 우리는 입력 데이터 포인트의 차원을 2에서 1로 줄입니다. 이 차원 축소가 기하학적으로 어떻게 이루어지는지 살펴보겠습니다. 데이터 포인트 (x₁, x₂)로 시작합니다. 우리는 이를 2차원 공간에서 점 또는 벡터로 표시할 수 있습니다(Figure 3). 또한 벡터 w를 다음과 같이 정의할 수 있습니다:\n\n![vector w equation](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_6.png)\n\n벡터 u를 w의 단위 벡터로 정의할 수 있도록 하는 다음 방정식을 사용하여 정의합시다:\n\n![unit vector equation](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_7.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n벡터 u가 w와 같은 방향을 가지지만 길이는 1입니다. 이제 벡터 x를 w에 평행한 벡터와 수직인 벡터 두 가지 구성 요소 벡터로 분해할 수 있습니다. 평행 벡터는 x를 w에 투영한 벡터로 불리며 x^로 표시됩니다(그림 3). 또한 x와 w의 내적을 사용하여 x^를 얻을 수 있습니다:\n\n![Figure 3](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_8.png)\n\n![Image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_9.png)\n\nx^의 길이는 x를 w에 투영한 스칼라 투영이라고 하며 다음과 같이 주어집니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_10.png\" /\u003e\n\n이제 x^를 ||w||로 곱하면 d로 표시된 새로운 벡터를 얻습니다:\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_11.png\" /\u003e\n\n그리고 d의 길이는 u가 단위 벡터이기 때문에 w.x와 동일합니다. 내적의 정의에 따라 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_12.png\" /\u003e\n\n이것은 방정식 2에서 정의된 용어 일부를 제공합니다. 그러나 w₀를 추가해야 합니다.\n\n이를 위해 다음과 같은 벡터를 정의합니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_13.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이제, d에서 o를 뺀다면 다음과 같습니다:\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_14.png)\n\n즉, d-o의 길이는 방정식 2에서 정의된 용어와 같다는 것을 의미합니다 (그림 4). 이것은 벡터 d의 새로운 원점을 정의하는 것과 같습니다. 기하학적 관점에서 보면, 우리는 벡터 o의 끝 지점을 기준으로 d의 길이를 측정합니다. 반면 2차원 공간의 원점을 기준으로 하지 않습니다. (이 그림에서 w₀가 양수라고 가정하였기 때문에 벡터 o는 w의 반대 방향에 있습니다).\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_15.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n위의 텍스트를 친근한 톤으로 한국어로 번역하겠습니다.\n\n요약하자면, 방정식 2의 용어 역할은 차원 축소입니다. 입력 데이터 점의 차원을 1로 줄입니다. 따라서 변환된 데이터 점은 모두 원점을 통과하고 벡터 w를 따라 있는 선 l로 가정할 수 있습니다. 이 선을 새로운 축으로 생각하면, 원점은 벡터 o의 끝에 있는 새 축이라는 것을 알 수 있습니다. 이제 이 축 위의 변환된 데이터 점의 좌표는 방정식 2에 의해 주어집니다.\n\n벡터 x가 입력 데이터 점을 나타낸다고 가정했습니다. 새로운 축 l 상의 변환된 데이터 점을 얻기 위해 우리는 먼저 직교 투영을 수행하고 x를 w에 투영한 벡터를 찾았습니다. 그런 다음 결과 벡터인 (x^)에 w의 길이를 곱하여 벡터 d를 얻었습니다. 벡터 d는 새로운 축 l 상의 변환된 데이터 점을 나타내지만, 그 좌표는 o에서 d를 뺀 d-o로 주어집니다.\n\n이제 우리는 장난감 데이터 세트에서 변환된 일차원 데이터 점을 계산할 수 있습니다. 여기서는 scikit-learn 라이브러리의 로지스틱 회귀 모델을 사용합니다. 데이터 세트를 fitting한 후, 방정식 2의 선형 항의 계수를 검색할 수 있습니다.\n\n```python\nlg=LogisticRegression()\nlg.fit(X,y)\nw = lg.coef_[0]\nw1, w2 = w[0], w[1]\nw0 = lg.intercept_[0]\nprint(\"w0={}, w1={}, w2={}\".format(w0, w1, w2))\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\nw0=1.2124, w1=0.9033, w2=0.9075\n\n이제 w₁와 w₂의 값을 사용하여 벡터 w를 형성할 수 있습니다. w의 단위 벡터는 다음과 같이 정의됩니다:\n\n\\[ w = \\begin{bmatrix} 1.2124 \\\\ 0.9033 \\\\ 0.9075 \\end{bmatrix} \\]\n\n다음과 같이 계산됩니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nlength_w = np.linalg.norm(w);\nu = w / length_w;\n```\n\n변환된 일차원 데이터 포인트들은 이 벡터를 따라 놓이게 될 것이고, u와 w가 동일한 방향을 가지고 있기 때문에 w도 따라 늘어날 것입니다. 이 선의 원점은 벡터 o=-w₀u의 끝에 위치합니다.\n\n```js\no = -w0 * u;\n```\n\n다음 코드 스니펫을 통해 원본 데이터 세트, 벡터 w와 o, 그리고 변환된 데이터 포인트를 플롯합니다. 결과는 Figure 5에 표시됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```python\nlt.figure(figsize=(6,6))\n\n# 원본 데이터 세트 플롯\nplt.scatter(X[y==0, 0], X[y==0,1], label=\"y=0\", alpha=0.4, color=\"red\")\nplt.scatter(X[y==1, 0], X[y==1,1], label=\"y=1\", alpha=0.4, color=\"blue\")\n\n# 변환된 포인트 플롯\ntransformed_points = np.dot(X, w).reshape(-1,1) * np.tile(w, (len(X), 1))\nplt.scatter(transformed_points[:, 0], transformed_points[:, 1],\n            alpha=0.5, color='green', label=\"변환된\\n포인트\")\n\n# 포인트 o 플롯\nplt.scatter(o[0], o[1], color='black', s=35, zorder=10)\n# 벡터 w와 o 플롯\nplt.quiver([0], [0], w[0], w[1], color=['b'],\n           width=0.01, angles='xy', scale_units='xy', scale=1, zorder=5)\nplt.quiver([0], [0], o[0], o[1], color=['black'],\n           width=0.01, angles='xy', scale_units='xy', scale=1, zorder=5)\n\n# 벡터 w를 따라 나아가는 선\nplt.plot([-12*u[0], 19*u[0]],\n         [-12*u[1], 19*u[1]], color='gray')\n\n# 축 생성\nplt.axhline(0, color='black', linewidth=0.8)\nplt.axvline(0, color='black', linewidth=0.8)\nplt.text(0.3, 1.2, \"$\\mathregular{w}$\", color='b', fontsize=14,\n         weight=\"bold\", style=\"italic\")\nplt.text(-1.7, -1, \"$\\mathregular{o}$\", color='black', fontsize=14,\n         weight=\"bold\", style=\"italic\")\n\nplt.xlim([-8, 6])\nplt.ylim([-8, 6])\nax = plt.gca()\nax.set_aspect('equal')\nplt.legend(loc=\"best\", fontsize=13)\nplt.xlabel('$x_1$', fontsize=16)\nplt.ylabel('$x_2$', fontsize=16)\n\nplt.show()\n```\n\n![그림](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_17.png)\n\n모든 변환된 데이터 포인트는 w 벡터를 따라 있는 선상에 있음을 유의해주세요. 이 선의 원점은 점 o에 위치합니다. 원본 데이터 세트의 각 데이터 포인트 (x₁, x₂)는 이 선상의 데이터 포인트로 변환되며, 변환된 데이터 포인트 (각 녹색 점)의 점 o로부터의 거리는 w₀+w₁x₁+w₂x₂와 같습니다.\n\n시그모이드 함수 추가\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n먼저 우리는 방정식 1을 두 부분으로 나눴다는 것을 기억해야 해요. 먼저 입력 데이터 (x₁, x₂)를 선형 항인 w₀+w₁x₁+w₂x₂로 변환합니다. 이는 차원 축소 과정으로, 변환된 일차원 데이터 포인트를 만들어냅니다. 다음 부분은 이러한 변환된 데이터 포인트에 시그모이드 함수를 정의합니다. 이 함수는 변환된 데이터 포인트가 레이블 1을 가지는 확률을 계산합니다. 이 확률을 계산하기 위해 각 변환된 데이터 포인트의 좌표 (l=w₀+w₁x₁+w₂x₂)를 시그모이드 함수에 넣는 것입니다:\n\n![이미지](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_18.png)\n\n다음 코드 스니펫은 이 확률을 계산하고 도표 6에 시그모이드 함수를 그리는 것입니다:\n\n```js\nplt.figure((figsize = (15, 5)));\n\ntransformed_points = np.dot(X, w) + w0;\nplt.scatter(\n  transformed_points,\n  [0] * len(transformed_points),\n  (s = 280),\n  (color = \"green\"),\n  (alpha = 0.4),\n  (label = \"변환된 데이터 포인트\")\n);\nl_array = np.linspace(-12, 8, 100);\nP = 1 / (1 + np.exp(-l_array));\nplt.plot(l_array, P, (color = \"black\"), (label = \"시그모이드 함수\"));\n\nplt.xlim([-8, 8]);\nplt.ylim([0, 1.05]);\nplt.legend((loc = \"best\"), (fontsize = 18));\nplt.xlabel(\"$l$\", (fontsize = 22));\nplt.ylabel(\"$P$\", (fontsize = 22));\nplt.xticks((fontsize = 18));\nplt.yticks((fontsize = 18));\nplt.show();\n```\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_19.png\" /\u003e\n\n그래서 각 변환된 데이터 포인트마다 y=1의 확률이 있습니다. 그러나 실제 레이블을 얻기 위해서는 확률 임계값을 정의해야 합니다 (y의 실제 값). 이 임계값은 이진 분류 결정을 내릴 확률을 정의합니다. 기본적으로 로지스틱 회귀는 P=0.5의 임계값을 선택합니다. 시그모이드 곡선은 원점에서 값이 0.5임을 기억해 주세요. 따라서 w₀+w₁x₁+w₂x₂≥0 (y^=1)인 모든 포인트에 대해 예측된 레이블은 1이며, `w₀+w₁x₁+w₂x₂\u003c0 (y^=0)`인 모든 포인트에 대해 예측된 레이블은 0입니다. 따라서 확률 임계값은 각 변환된 데이터 포인트의 예측된 확률(P)을 y^로 나타내는 예측된 이진 레이블로 변환합니다. 이것은 Figure 7에 표시되어 있습니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_20.png\" /\u003e\n\n우리는 또한 이 시그모이드 곡선을 원래 2차원 공간에 그릴 수 있습니다. 이 결과는 Figure 8에 표시되어 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\nplt.figure(figsize=(6,6))\n\n# 원본 데이터셋 플롯\nplt.scatter(X[y==0, 0], X[y==0,1], label=\"y=0\", alpha=0.7, color=\"red\")\nplt.scatter(X[y==1, 0], X[y==1,1], label=\"y=1\", alpha=0.7, color=\"blue\")\n\n# 투영된 점 플롯\ntransformed_points = np.dot(X, w).reshape(-1,1) * np.tile(w, (len(X), 1))\nplt.scatter(transformed_points[:, 0], transformed_points[:, 1],\n            alpha=0.5, color='green', label=\"Transformed\\n data points\")\n\n# 점 o 플롯\nplt.scatter(o[0], o[1], color='black', s=35)\n# 벡터 w 플롯\nplt.quiver([0], [0], w[0], w[1], color=['b'],\n           width=0.01, angles='xy', scale_units='xy', scale=1, zorder=5)\n\n\n# 시그모이드 곡선 플롯\nk = 200\nl_array = np.linspace(-12, 8, k).reshape(-1, 1)\nw_array = l_array * np.tile(u, (k, 1))\n# 벡터 w를 따라 선 그리기\nplt.plot([-12*u[0], 19*u[0]],\n         [-12*u[1], 19*u[1]], color='gray')\n\nsigm_x_array = ((w_array - o) /u)[:,0]\nsigm_prob = 1 / (1+np.exp(-sigm_x_array))\nnorm_vector = np.array([-w2, w1]) if w1\u003e=0 else np.array([w2, -w1])\nsigm_y_array = sigm_prob.reshape(k, 1) * np.tile(norm_vector, (k, 1))\nsigm_curve_array = sigm_y_array + w_array\n\nplt.plot(sigm_curve_array[:, 0], sigm_curve_array[:, 1], color=\"blue\")\n# 시그모이드 곡선의 y축 플롯\nplt.plot([o[0], o[0]+2*norm_vector[0]],\n         [o[1], o[1]+2*norm_vector[1]], color='gray')\n\n# 축 그리기\nplt.axhline(0, color='black', linewidth=0.8)\nplt.axvline(0, color='black', linewidth=0.8)\nplt.text(0.3, 1.2, \"$\\mathregular{w}$\", color='b', fontsize=14,\n         weight=\"bold\", style=\"italic\")\nplt.text(-0.8, -1.4, \"$\\mathregular{o}$\", color='black', fontsize=14,\n         weight=\"bold\", style=\"italic\")\nplt.text(-2.9, 1.3, \"$P$\", color='black', fontsize=14,\n         weight=\"bold\", style=\"italic\", rotation = 50)\n\nplt.xlim([-8, 6.2])\nplt.ylim([-8, 6.2])\nax = plt.gca()\nax.set_aspect('equal')\nplt.xlabel('$x_1$', fontsize=16)\nplt.ylabel('$x_2$', fontsize=16)\n\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_21.png\" /\u003e\n\n하지만 2차원 공간에서 결정 경계를 어떻게 찾을까요? 이를 위해 2차원 공간의 모든 점을 찾아야 합니다. 이러한 점들은 1차원 공간의 원점으로 매핑됩니다 (Figure 8의 점 o). Figure 9에서 이러한 점들을 찾을 수 있는 방법을 보여줍니다.\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_22.png\" /\u003e\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n여기서는 x라는 지점을 찾고 있습니다.\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_23.png)\n\n이러한 점들은 x^에서 l에 수직인 선상에 있습니다. 우리는 이 선을 s로 표시할 것입니다 (도표 9). 모든 점들이 2차원 평면의 원점으로부터의 거리는 |w₀| / ||w||입니다(점과 선 사이의 거리는 그 선에 수직이고 해당 점을 통과하는 선분의 길이입니다). 이제 s의 모든 점들에 대한 벡터 d는 다음과 같습니다:\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_24.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n따라서 데이터 지점이 선 s에 있으면, 해당 변환된 지점은 지점 o(1차원 공간의 원점)에 있고, 그 확률은 0.5가 됩니다. 이로써 선 s가 2차원 공간의 로지스틱 회귀의 결정 경계라는 것을 결론짓게 되었습니다. 왜냐하면 이 선 상의 모든 데이터 지점은 1차원 공간의 시그모이드 곡선의 결정 경계로 매핑되기 때문입니다. 따라서 이제 우리 모델의 결정 경계를 쉽게 그릴 수 있습니다.\n\n```js\nboundary_point = (-w0 / length_w**2) * w\n\nplt.figure(figsize=(6,6))\n\nplt.scatter(X[y==0, 0], X[y==0,1], label=\"y=0\", alpha=0.7, color=\"red\")\nplt.scatter(X[y==1, 0], X[y==1,1], label=\"y=1\", alpha=0.7, color=\"blue\")\n\nplt.scatter(o[0], o[1], color='black', s=35)\n# 벡터 w 그리기\nplt.quiver([0], [0], w[0], w[1], color=['b'],\n           width=0.01, angles='xy', scale_units='xy', scale=1, zorder=5)\n\nplt.quiver([0], [0], boundary_point[0], boundary_point[1], color=['black'],\n           width=0.01, angles='xy', scale_units='xy', scale=1, zorder=5)\n\n# 결정 경계 그리기\nplt.plot([boundary_point[0], boundary_point[0]-6],\n         [boundary_point[1], boundary_point[1]-6*(-w1/w2)],\n         color='black', linestyle=\"--\")\nplt.plot([boundary_point[0], boundary_point[0]+6],\n         [boundary_point[1], boundary_point[1]+6*(-w1/w2)],\n         color='black', linestyle=\"--\")\n\n# 시그모이드 곡선 그리기\nk = 200\nl_array = np.linspace(-8.4, 8, k).reshape(-1, 1)\nw_array = l_array * np.tile(u, (k, 1))\n\n# 벡터 w를 따른 선 그리기\nplt.plot([-9*u[0], 8*u[0]],\n         [-9*u[1], 8*u[1]], color='gray')\n\nsigm_x_array = ((w_array - o) /u)[:,0]\nsigm_prob = 1 / (1+np.exp(-sigm_x_array))\nnorm_vector = np.array([-w2, w1]) if w1\u003e=0 else np.array([w2, -w1])\nsigm_y_array = sigm_prob.reshape(k, 1) * np.tile(norm_vector, (k, 1))\nsigm_curve_array = sigm_y_array + w_array\n\nplt.plot(sigm_curve_array[:, 0], sigm_curve_array[:, 1], color=\"blue\")\n# 시그모이드 곡선의 y축 그리기\nplt.plot([o[0], o[0]+2*norm_vector[0]],\n         [o[1], o[1]+2*norm_vector[1]], color='gray')\n\n# 축 그리기\nplt.axhline(0, color='grey', linewidth=0.8)\nplt.axvline(0, color='grey', linewidth=0.8)\n\nplt.text(0.35, 1, \"$\\mathregular{w}$\", color='b', fontsize=14,\n         weight=\"bold\", style=\"italic\")\nplt.text(-0.95, -1.35, \"$\\mathregular{o}$\", color='black', fontsize=14,\n         weight=\"bold\", style=\"italic\")\nplt.text(-3.15, 0.5, \"$P$\", color='black', fontsize=14,\n         weight=\"bold\", style=\"italic\", rotation = 50)\nplt.text(-4, 3, \"결정 경계\", color='black', fontsize=14)\nplt.text(-0.3, -0.7, r\"$\\frac{-w_0}{\\mathregular{||w||^2}\\mathregular{w}$\",\n         color='black', fontsize=15, weight=\"bold\", style=\"italic\")\n\n\nplt.xlim([-5.6, 4.2])\nplt.ylim([-5.6, 4.2])\nax = plt.gca()\nax.set_aspect('equal')\n\nplt.xlabel('$x_1$', fontsize=16)\nplt.ylabel('$x_2$', fontsize=16)\n\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_25.png\" /\u003e\n\n우리는 또한 여기서 발견한 결정 경계의 위치를 유효성 검사할 수 있습니다. 이를 위해 모델의 경계를 다른 방법을 사용하여 그리는 함수를 정의합니다. 먼저 2차원 공간에 메시 그리드를 생성하고 이를 사용하여 훈련된 로지스틱 회귀 모델을 사용하여 해당 지점의 목표를 예측합니다. y^=0 및 y^=1인 지점은 서로 다른 색으로 표시되므로 그리드가 충분히 잘 그려진 경우 모델의 결정 경계를 쉽게 확인할 수 있습니다. 결과는 Figure 11에 나와 있으며 이전에 발견한 결정 경계와 일치합니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n```js\ndef plot_boundary(X, y, clf, lims):\n    gx1, gx2 = np.meshgrid(np.arange(lims[0], lims[1], (lims[1]-lims[0])/300.0),\n                           np.arange(lims[2], lims[3], (lims[3]-lims[2])/300.0))\n    \n    cmap_light = ListedColormap(['lightsalmon', 'aqua'])\n            \n    gx1l = gx1.flatten()\n    gx2l = gx2.flatten()\n    gx = np.vstack((gx1l,gx2l)).T\n    gyhat = clf.predict(gx)\n    gyhat = gyhat.reshape(gx1.shape)\n\n    plt.pcolormesh(gx1, gx2, gyhat, cmap=cmap_light)\n    plt.scatter(X[y==0, 0], X[y==0,1], label=\"y=0\", alpha=0.7, color=\"red\")\n    plt.scatter(X[y==1, 0], X[y==1,1], label=\"y=1\", alpha=0.7, color=\"blue\")\n    plt.legend(loc='upper left')\n\n\nplt.figure(figsize=(6,6))\nplot_boundary(X,y,lg, lims=[-5.6, 4.2, -5.6, 4.2])\n\n# Plot the vector w\nplt.quiver([0], [0], w[0], w[1], color=['b'],\n           width=0.01, angles='xy', scale_units='xy', scale=1, zorder=5)\n\nplt.quiver([0], [0], boundary_point[0], boundary_point[1], color=['black'],\n           width=0.01, angles='xy', scale_units='xy', scale=1, zorder=5)\n\n# plot the decision boundary\nplt.plot([boundary_point[0], boundary_point[0]-6],\n         [boundary_point[1], boundary_point[1]-6*(-w1/w2)],\n         color='black', linestyle=\"--\")\nplt.plot([boundary_point[0], boundary_point[0]+6],\n         [boundary_point[1], boundary_point[1]+6*(-w1/w2)],\n         color='black', linestyle=\"--\")\n\n# Plot the line along the vector w\nplt.plot([-9*u[0], 8*u[0]],\n         [-9*u[1], 8*u[1]], color='gray')\n\n# Draw axes\nplt.axhline(0, color='grey', linewidth=0.8)\nplt.axvline(0, color='grey', linewidth=0.8)\n\nplt.text(0.35, 1, \"$\\mathregular{w}$\", color='b', fontsize=14,\n         weight=\"bold\", style=\"italic\")\n\nplt.text(-2, 3, \"$\\hat{y}=1$\\nregion\", color='blue', fontsize=14)\nplt.text(1, -5, \"$\\hat{y}=0$\\nregion\", color='red', fontsize=14)\nplt.text(-0.3, -0.7, r\"$\\frac{-w_0}{\\mathregular{||w||^2}\\mathregular{w}$\",\n         color='black', fontsize=15, weight=\"bold\", style=\"italic\")\n\nplt.xlim([-5.6, 4.2])\nplt.ylim([-5.6, 4.2])\nax = plt.gca()\nax.set_aspect('equal')\n\nplt.xlabel('$x_1$', fontsize=16)\nplt.ylabel('$x_2$', fontsize=16)\nplt.show()\n```\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_26.png)\n\n여기에 결과를 요약해보겠습니다. 두 가지 특성을 갖는 데이터셋에서 로지스틱 회귀 모델의 의사결정 경계는 직선으로 형성됩니다. 이 직선은 모델의 매개변수 w₀, w₁, w₂에 의해 결정됩니다. 의사결정 경계는 벡터를 연장한 선에 수직입니다.\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_27.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 라인과 의사결정 경계의 교차점은 (-w₀ / ||w||²)w 벡터에 의해 결정됩니다.\n\n고차원에서의 의사결정 경계\n\n저희가 데이터셋에서 더 많은 피쳐를 가지고 있는 경우에 어떻게 될지 살펴봅시다. 우리는 같은 컨셉을 고차원으로 쉽게 적용할 수 있습니다. x₁, x₂, x₃라는 세 개의 피쳐를 가지고 있다고 상상해보겠습니다. 이제 로지스틱 회귀 방정식은 다음과 같습니다:\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n모델 매개변수는 w₀, w₁, w₂ 및 w₃입니다. 차원 축소 부분은 동일하며, 원본 데이터 포인트는 여전히 1차원 공간에 매핑됩니다. 변환된 데이터 포인트는 여전히 직선 l 상에 있으며 해당 벡터를 확장합니다:\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_29.png)\n\n결정 경계는 w로의 벡터 투영이 (-w₀ / ||w||²)w인 모든 포인트의 위치입니다. 이러한 포인트는 차원 축소 후 P=0.5를 갖게 됩니다. 따라서 결정 경계는 3차원 공간에서 평면입니다(도 12 참조). 이 평면은 l에 수직이며, l과의 교차점은 (-w₀ / ||w||²)w 벡터로 주어집니다.\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_30.png)\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n보다 일반적으로, n차원 공간에서 로지스틱 회귀 모델은 n개의 매개변수 w₀, w₁, …, w_n을 가지고 있습니다. 여기에서, 만약 벡터를 확장한다면,\n\n![image](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_31.png)\n\n선 l로, 결정 경계는 n차원 초평면입니다. 이 초평면은 l에 수직이며, (-w₀ / ||w||²)w 벡터는 초평면과 l의 교차점을 나타냅니다.\n\n로지스틱 회귀는 항상 n차원 공간에서 1차원 공간으로 차원 축소를 시작합니다. 따라서 그 결정 경계는 곡률이 없는 초평면입니다. 결정 경계가 초평면인 분류기는 선형 분류기라고 하며, 로지스틱 회귀는 그러한 분류기의 한 예입니다. 다른 예시로는 퍼셉트론과 서포트 벡터 머신(SVM)이 있습니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n데이터 세트(특성이 n개 있는)는 이진 대상을 가지고 있고 n차원 초평면을 사용하여 서로 다른 라벨을 가진 데이터 포인트들을 완전히 분리할 수 있다면 선형 분리 가능하다고 합니다. 따라서 선형 분류기는 선형 분리 가능한 데이터 세트에 대한 완벽한 모델입니다. 지금까지 사용된 토이 데이터 세트는 선형 분리 가능했습니다(Figure 1), 그러나 많은 데이터 세트는 선형 분리가 불가능하며 로지스틱 회귀와 같은 모델은 그에 적합하지 않을 수 있습니다. Figure 13는 선형 분리가 불가능한 데이터 세트의 예시를 보여줍니다.\n\n![Figure 13](/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_32.png)\n\n여기서 데이터 세트는 원 모양을 가지고 있으며, 직선을 사용하여 y=0 및 y=1을 가진 데이터 포인트들을 완벽하게 나눌 수 없습니다. 따라서 이러한 분류 문제에 로지스틱 회귀 모델을 사용할 수 없습니다.\n\n이 기사에서는 선형 대수를 사용하여 로지스틱 회귀의 시각적 해석을 제공하려고 노력했습니다. 로지스틱 회귀는 1차원 공간으로의 차원 축소부터 시작하고, 그런 다음 변환된 데이터 포인트에 대한 확률을 할당합니다. 확률 임계값을 정의함으로써, 해당 데이터 포인트의 이진 대상에 대한 최종 예측을 얻을 수 있습니다. 1차원 공간으로의 차원 축소로 인해 로지스틱 회귀는 선형 분류기가 됩니다. 따라서 n개의 특성을 가진 데이터 세트에 적용되는 경우 의사 결정 경계는 n차원 초평면이 됩니다.\n\n\u003c!-- ui-station 사각형 --\u003e\n\n\u003cins class=\"adsbygoogle\"\nstyle=\"display:block\"\ndata-ad-client=\"ca-pub-4877378276818686\"\ndata-ad-slot=\"7249294152\"\ndata-ad-format=\"auto\"\ndata-full-width-responsive=\"true\"\u003e\u003c/ins\u003e\n\n\u003cscript\u003e\n(adsbygoogle = window.adsbygoogle || []).push({});\n\u003c/script\u003e\n\n이 기사를 즐겁게 읽었으면 좋겠어요. 제 기사가 도움이 된다면, 저를 Medium에서 팔로우해 주세요.\n","ogImage":{"url":"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_0.png"},"coverImage":"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_0.png","tag":["Tech"],"readingTime":26},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e로지스틱 회귀는 이진 분류에서 사용되는 통계 모델입니다. 이진 분류 문제에서 대상은 두 가지 범주만 가지고 있으므로 기계 학습 알고리즘은 데이터를 이 두 범주 중 하나로 분류해야 합니다. 로지스틱 회귀는 각 범주에 속할 확률을 예측하는 데 사용되는 로지스틱 함수에서 유래했습니다. 로지스틱 회귀는 지도 기계 학습, 금융, 의학 및 사회과학 등 여러 분야에 응용됩니다.\u003c/p\u003e\n\u003cp\u003e본 문서에서는 로지스틱 회귀의 시각적 이해를 제시하고, 이 모델의 각 요소의 역할을 설명할 것입니다. 이 글을 읽으면 독자는 로지스틱 회귀와 그 한계에 대한 직관적인 이해를 가질 수 있습니다.\u003c/p\u003e\n\u003cp\u003e본 문서의 모든 이미지는 저자에 의해 제작되었습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e간단한 데이터셋\u003c/p\u003e\n\u003cp\u003e로지스틱 회귀가 분류 문제를 해결하는 방법을 보여주기 위해 간단한 데이터셋을 만들겠습니다. 먼저 필요한 모든 Python 라이브러리를 가져옵니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.\u003cspan class=\"hljs-property\"\u003epyplot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003elinear_model\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eLogisticRegression\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e matplotlib.\u003cspan class=\"hljs-property\"\u003ecolors\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eListedColormap\u003c/span\u003e\n\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e warnings\nwarnings.\u003cspan class=\"hljs-title function_\"\u003efilterwarnings\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"ignore\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e우리의 데이터셋은 두 개의 특성 (x₁, x₂)과 100개의 예제가 있습니다. 이는 두 개의 클러스터로 구성되어 각각 정규 분포를 사용하여 만들어졌습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003enp.random.seed(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\nx1 = np.random.randn(\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e) * \u003cspan class=\"hljs-number\"\u003e0.4\u003c/span\u003e + np.array([-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e])\nx2 = np.random.randn(\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e) * \u003cspan class=\"hljs-number\"\u003e0.4\u003c/span\u003e + np.array([\u003cspan class=\"hljs-number\"\u003e2.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2.6\u003c/span\u003e])\n\ny = \u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e*[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e*[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\nX = np.vstack((x1, x2))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 데이터셋에 대한 target 또는 label 열 (y)도 정의했습니다. 첫 번째 클러스터의 데이터 포인트들의 레이블은 0이고, 두 번째 클러스터의 데이터 포인트들의 레이블은 1입니다. 따라서 target 열에는 2개의 레이블만 있어서 binary classification 문제가 됩니다. 이제 이 데이터셋을 플롯합니다. 결과는 아래 그림에서 확인할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eplt.scatter(x1[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], x1[:,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=0\"\u003c/span\u003e)\nplt.scatter(x2[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], x2[:,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=1\"\u003c/span\u003e)\nplt.legend(loc=\u003cspan class=\"hljs-string\"\u003e\"best\"\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e\"$x_1$\"\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e\"$x_2$\"\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e지금 이 데이터셋을 분류하기 위해 로지스틱 회귀 모델을 사용할 수 있습니다. 이 모델을 훈련시켜 이 데이터셋의 데이터 포인트의 이진 레이블을 예측할 것입니다. 또한 이 모델은 이 훈련 데이터셋에 없는 어떤 보이지 않는 데이터 포인트에 대한 예측을 총체화할 수 있어야 합니다.\u003c/p\u003e\n\u003cp\u003e로지스틱 회귀 방정식\u003c/p\u003e\n\u003cp\u003e로지스틱 회귀 모델을 이해하려면 먼저 그 방정식을 자세히 살펴봐야 합니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_2.png\" alt=\"로지스틱 회귀 방정식\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e여기서 P는 데이터 포인트 (x₁, x₂)가 레이블 1일 확률을 예측한 값입니다. 이 방정식은 로지스틱 회귀 모델의 핵심입니다. 그냥 데이터 포인트를 가져와서 해당 레이블이 1일 확률을 계산하는 것이죠. 이 함수는 표준 로지스틱 또는 시그모이드 함수라고 불립니다. 아래 소개된 그림 2는 이 함수의 플롯을 보여줍니다. x가 ∞로 다가갈수록 y는 1로 수렴하고, x가 -∞로 다가갈수록 y는 0으로 수렴함을 주목하세요. 게다가 x=0에서 y=0.5인 것을 알 수 있습니다. 따라서 y는 항상 0과 1 사이에 제한됩니다. 우리는 확률이 항상 [0,1] 범위 내에 있음을 알고 있기 때문에 결과의 확률을 표현하기 위해 시그모이드 함수를 사용할 수 있습니다. 이 함수는 임의의 실수 값을 가진 입력(x)을 0과 1 사이의 확률 값으로 매핑할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이제 방정식 1이 특징 x₁과 x₂로 표현된 데이터 포인트를 입력하여 해당 레이블이 1일 확률로 변환하는 방법을 알아봅시다.\u003c/p\u003e\n\u003cp\u003e차원 축소\u003c/p\u003e\n\u003cp\u003e방정식 1을 두 부분으로 나눌 수 있습니다. 먼저 입력 데이터(x₁, x₂)를 선형 항으로 변환합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_5.png\" alt=\"equation\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e여기서 w₀, w₁ 및 w₂는 모델의 매개변수이며 이 값은 모델을 학습한 후에 결정될 것입니다. 이것은 두 개의 특징 (x₁, x₂)으로 시작하여 방정식 2에 의해 제공된 단일 숫자로 변환하는 차원 축소의 예입니다. 실제로 우리는 입력 데이터 포인트의 차원을 2에서 1로 줄입니다. 이 차원 축소가 기하학적으로 어떻게 이루어지는지 살펴보겠습니다. 데이터 포인트 (x₁, x₂)로 시작합니다. 우리는 이를 2차원 공간에서 점 또는 벡터로 표시할 수 있습니다(Figure 3). 또한 벡터 w를 다음과 같이 정의할 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_6.png\" alt=\"vector w equation\"\u003e\u003c/p\u003e\n\u003cp\u003e벡터 u를 w의 단위 벡터로 정의할 수 있도록 하는 다음 방정식을 사용하여 정의합시다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_7.png\" alt=\"unit vector equation\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e벡터 u가 w와 같은 방향을 가지지만 길이는 1입니다. 이제 벡터 x를 w에 평행한 벡터와 수직인 벡터 두 가지 구성 요소 벡터로 분해할 수 있습니다. 평행 벡터는 x를 w에 투영한 벡터로 불리며 x^로 표시됩니다(그림 3). 또한 x와 w의 내적을 사용하여 x^를 얻을 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_8.png\" alt=\"Figure 3\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_9.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003ex^의 길이는 x를 w에 투영한 스칼라 투영이라고 하며 다음과 같이 주어집니다:\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이제 x^를 ||w||로 곱하면 d로 표시된 새로운 벡터를 얻습니다:\u003c/p\u003e\n\u003cp\u003e그리고 d의 길이는 u가 단위 벡터이기 때문에 w.x와 동일합니다. 내적의 정의에 따라 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이것은 방정식 2에서 정의된 용어 일부를 제공합니다. 그러나 w₀를 추가해야 합니다.\u003c/p\u003e\n\u003cp\u003e이를 위해 다음과 같은 벡터를 정의합니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이제, d에서 o를 뺀다면 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_14.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e즉, d-o의 길이는 방정식 2에서 정의된 용어와 같다는 것을 의미합니다 (그림 4). 이것은 벡터 d의 새로운 원점을 정의하는 것과 같습니다. 기하학적 관점에서 보면, 우리는 벡터 o의 끝 지점을 기준으로 d의 길이를 측정합니다. 반면 2차원 공간의 원점을 기준으로 하지 않습니다. (이 그림에서 w₀가 양수라고 가정하였기 때문에 벡터 o는 w의 반대 방향에 있습니다).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_15.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e위의 텍스트를 친근한 톤으로 한국어로 번역하겠습니다.\u003c/p\u003e\n\u003cp\u003e요약하자면, 방정식 2의 용어 역할은 차원 축소입니다. 입력 데이터 점의 차원을 1로 줄입니다. 따라서 변환된 데이터 점은 모두 원점을 통과하고 벡터 w를 따라 있는 선 l로 가정할 수 있습니다. 이 선을 새로운 축으로 생각하면, 원점은 벡터 o의 끝에 있는 새 축이라는 것을 알 수 있습니다. 이제 이 축 위의 변환된 데이터 점의 좌표는 방정식 2에 의해 주어집니다.\u003c/p\u003e\n\u003cp\u003e벡터 x가 입력 데이터 점을 나타낸다고 가정했습니다. 새로운 축 l 상의 변환된 데이터 점을 얻기 위해 우리는 먼저 직교 투영을 수행하고 x를 w에 투영한 벡터를 찾았습니다. 그런 다음 결과 벡터인 (x^)에 w의 길이를 곱하여 벡터 d를 얻었습니다. 벡터 d는 새로운 축 l 상의 변환된 데이터 점을 나타내지만, 그 좌표는 o에서 d를 뺀 d-o로 주어집니다.\u003c/p\u003e\n\u003cp\u003e이제 우리는 장난감 데이터 세트에서 변환된 일차원 데이터 점을 계산할 수 있습니다. 여기서는 scikit-learn 라이브러리의 로지스틱 회귀 모델을 사용합니다. 데이터 세트를 fitting한 후, 방정식 2의 선형 항의 계수를 검색할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003elg=LogisticRegression()\nlg.fit(X,y)\nw = lg.coef_[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\nw1, w2 = w[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\nw0 = lg.intercept_[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"w0={}, w1={}, w2={}\"\u003c/span\u003e.\u003cspan class=\"hljs-built_in\"\u003eformat\u003c/span\u003e(w0, w1, w2))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003ew0=1.2124, w1=0.9033, w2=0.9075\u003c/p\u003e\n\u003cp\u003e이제 w₁와 w₂의 값을 사용하여 벡터 w를 형성할 수 있습니다. w의 단위 벡터는 다음과 같이 정의됩니다:\u003c/p\u003e\n\u003cp\u003e[ w = \\begin{bmatrix} 1.2124 \\ 0.9033 \\ 0.9075 \\end{bmatrix} ]\u003c/p\u003e\n\u003cp\u003e다음과 같이 계산됩니다:\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003elength_w = np.\u003cspan class=\"hljs-property\"\u003elinalg\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enorm\u003c/span\u003e(w);\nu = w / length_w;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e변환된 일차원 데이터 포인트들은 이 벡터를 따라 놓이게 될 것이고, u와 w가 동일한 방향을 가지고 있기 때문에 w도 따라 늘어날 것입니다. 이 선의 원점은 벡터 o=-w₀u의 끝에 위치합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eo = -w0 * u;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e다음 코드 스니펫을 통해 원본 데이터 세트, 벡터 w와 o, 그리고 변환된 데이터 포인트를 플롯합니다. 결과는 Figure 5에 표시됩니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003elt.figure(figsize=(\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\n\n\u003cspan class=\"hljs-comment\"\u003e# 원본 데이터 세트 플롯\u003c/span\u003e\nplt.scatter(X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=0\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.4\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"red\"\u003c/span\u003e)\nplt.scatter(X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=1\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.4\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 변환된 포인트 플롯\u003c/span\u003e\ntransformed_points = np.dot(X, w).reshape(-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) * np.tile(w, (\u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(X), \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\nplt.scatter(transformed_points[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], transformed_points[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e],\n            alpha=\u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'green'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e\"변환된\\n포인트\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 포인트 o 플롯\u003c/span\u003e\nplt.scatter(o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, s=\u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)\n\u003cspan class=\"hljs-comment\"\u003e# 벡터 w와 o 플롯\u003c/span\u003e\nplt.quiver([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=[\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e],\n           width=\u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e, angles=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale_units=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\nplt.quiver([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=[\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e],\n           width=\u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e, angles=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale_units=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 벡터 w를 따라 나아가는 선\u003c/span\u003e\nplt.plot([-\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e19\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]],\n         [-\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e19\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]], color=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# 축 생성\u003c/span\u003e\nplt.axhline(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\nplt.axvline(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\nplt.text(\u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1.2\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\mathregular{w}$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\nplt.text(-\u003cspan class=\"hljs-number\"\u003e1.7\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\mathregular{o}$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\n\nplt.xlim([-\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e])\nplt.ylim([-\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e])\nax = plt.gca()\nax.set_aspect(\u003cspan class=\"hljs-string\"\u003e'equal'\u003c/span\u003e)\nplt.legend(loc=\u003cspan class=\"hljs-string\"\u003e\"best\"\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e13\u003c/span\u003e)\nplt.xlabel(\u003cspan class=\"hljs-string\"\u003e'$x_1$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\nplt.ylabel(\u003cspan class=\"hljs-string\"\u003e'$x_2$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\n\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_17.png\" alt=\"그림\"\u003e\u003c/p\u003e\n\u003cp\u003e모든 변환된 데이터 포인트는 w 벡터를 따라 있는 선상에 있음을 유의해주세요. 이 선의 원점은 점 o에 위치합니다. 원본 데이터 세트의 각 데이터 포인트 (x₁, x₂)는 이 선상의 데이터 포인트로 변환되며, 변환된 데이터 포인트 (각 녹색 점)의 점 o로부터의 거리는 w₀+w₁x₁+w₂x₂와 같습니다.\u003c/p\u003e\n\u003cp\u003e시그모이드 함수 추가\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e먼저 우리는 방정식 1을 두 부분으로 나눴다는 것을 기억해야 해요. 먼저 입력 데이터 (x₁, x₂)를 선형 항인 w₀+w₁x₁+w₂x₂로 변환합니다. 이는 차원 축소 과정으로, 변환된 일차원 데이터 포인트를 만들어냅니다. 다음 부분은 이러한 변환된 데이터 포인트에 시그모이드 함수를 정의합니다. 이 함수는 변환된 데이터 포인트가 레이블 1을 가지는 확률을 계산합니다. 이 확률을 계산하기 위해 각 변환된 데이터 포인트의 좌표 (l=w₀+w₁x₁+w₂x₂)를 시그모이드 함수에 넣는 것입니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_18.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e다음 코드 스니펫은 이 확률을 계산하고 도표 6에 시그모이드 함수를 그리는 것입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e((figsize = (\u003cspan class=\"hljs-number\"\u003e15\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)));\n\ntransformed_points = np.\u003cspan class=\"hljs-title function_\"\u003edot\u003c/span\u003e(X, w) + w0;\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(\n  transformed_points,\n  [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e] * \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(transformed_points),\n  (s = \u003cspan class=\"hljs-number\"\u003e280\u003c/span\u003e),\n  (color = \u003cspan class=\"hljs-string\"\u003e\"green\"\u003c/span\u003e),\n  (alpha = \u003cspan class=\"hljs-number\"\u003e0.4\u003c/span\u003e),\n  (label = \u003cspan class=\"hljs-string\"\u003e\"변환된 데이터 포인트\"\u003c/span\u003e)\n);\nl_array = np.\u003cspan class=\"hljs-title function_\"\u003elinspace\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e);\nP = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e / (\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e + np.\u003cspan class=\"hljs-title function_\"\u003eexp\u003c/span\u003e(-l_array));\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(l_array, P, (color = \u003cspan class=\"hljs-string\"\u003e\"black\"\u003c/span\u003e), (label = \u003cspan class=\"hljs-string\"\u003e\"시그모이드 함수\"\u003c/span\u003e));\n\nplt.\u003cspan class=\"hljs-title function_\"\u003exlim\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e]);\nplt.\u003cspan class=\"hljs-title function_\"\u003eylim\u003c/span\u003e([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1.05\u003c/span\u003e]);\nplt.\u003cspan class=\"hljs-title function_\"\u003elegend\u003c/span\u003e((loc = \u003cspan class=\"hljs-string\"\u003e\"best\"\u003c/span\u003e), (fontsize = \u003cspan class=\"hljs-number\"\u003e18\u003c/span\u003e));\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"$l$\"\u003c/span\u003e, (fontsize = \u003cspan class=\"hljs-number\"\u003e22\u003c/span\u003e));\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"$P$\"\u003c/span\u003e, (fontsize = \u003cspan class=\"hljs-number\"\u003e22\u003c/span\u003e));\nplt.\u003cspan class=\"hljs-title function_\"\u003exticks\u003c/span\u003e((fontsize = \u003cspan class=\"hljs-number\"\u003e18\u003c/span\u003e));\nplt.\u003cspan class=\"hljs-title function_\"\u003eyticks\u003c/span\u003e((fontsize = \u003cspan class=\"hljs-number\"\u003e18\u003c/span\u003e));\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e();\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e그래서 각 변환된 데이터 포인트마다 y=1의 확률이 있습니다. 그러나 실제 레이블을 얻기 위해서는 확률 임계값을 정의해야 합니다 (y의 실제 값). 이 임계값은 이진 분류 결정을 내릴 확률을 정의합니다. 기본적으로 로지스틱 회귀는 P=0.5의 임계값을 선택합니다. 시그모이드 곡선은 원점에서 값이 0.5임을 기억해 주세요. 따라서 w₀+w₁x₁+w₂x₂≥0 (y^=1)인 모든 포인트에 대해 예측된 레이블은 1이며, \u003ccode\u003ew₀+w₁x₁+w₂x₂\u0026#x3C;0 (y^=0)\u003c/code\u003e인 모든 포인트에 대해 예측된 레이블은 0입니다. 따라서 확률 임계값은 각 변환된 데이터 포인트의 예측된 확률(P)을 y^로 나타내는 예측된 이진 레이블로 변환합니다. 이것은 Figure 7에 표시되어 있습니다.\u003c/p\u003e\n\u003cp\u003e우리는 또한 이 시그모이드 곡선을 원래 2차원 공간에 그릴 수 있습니다. 이 결과는 Figure 8에 표시되어 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\n\n# 원본 데이터셋 플롯\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=0\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"red\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=1\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n\n# 투영된 점 플롯\ntransformed_points = np.\u003cspan class=\"hljs-title function_\"\u003edot\u003c/span\u003e(X, w).\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) * np.\u003cspan class=\"hljs-title function_\"\u003etile\u003c/span\u003e(w, (\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(X), \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(transformed_points[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], transformed_points[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e],\n            alpha=\u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'green'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e\"Transformed\\n data points\"\u003c/span\u003e)\n\n# 점 o 플롯\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, s=\u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e)\n# 벡터 w 플롯\nplt.\u003cspan class=\"hljs-title function_\"\u003equiver\u003c/span\u003e([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=[\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e],\n           width=\u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e, angles=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale_units=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\n\n# 시그모이드 곡선 플롯\nk = \u003cspan class=\"hljs-number\"\u003e200\u003c/span\u003e\nl_array = np.\u003cspan class=\"hljs-title function_\"\u003elinspace\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, k).\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\nw_array = l_array * np.\u003cspan class=\"hljs-title function_\"\u003etile\u003c/span\u003e(u, (k, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n# 벡터 w를 따라 선 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e19\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]],\n         [-\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e19\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]], color=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e)\n\nsigm_x_array = ((w_array - o) /u)[:,\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\nsigm_prob = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e / (\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e+np.\u003cspan class=\"hljs-title function_\"\u003eexp\u003c/span\u003e(-sigm_x_array))\nnorm_vector = np.\u003cspan class=\"hljs-title function_\"\u003earray\u003c/span\u003e([-w2, w1]) \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e w1\u003e=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e np.\u003cspan class=\"hljs-title function_\"\u003earray\u003c/span\u003e([w2, -w1])\nsigm_y_array = sigm_prob.\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e(k, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) * np.\u003cspan class=\"hljs-title function_\"\u003etile\u003c/span\u003e(norm_vector, (k, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\nsigm_curve_array = sigm_y_array + w_array\n\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(sigm_curve_array[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], sigm_curve_array[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n# 시그모이드 곡선의 y축 플롯\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e*norm_vector[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]],\n         [o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e*norm_vector[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]], color=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e)\n\n# 축 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003eaxhline\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eaxvline\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1.2\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\mathregular{w}$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e1.4\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\mathregular{o}$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e2.9\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1.3\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$P$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e, rotation = \u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003exlim\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6.2\u003c/span\u003e])\nplt.\u003cspan class=\"hljs-title function_\"\u003eylim\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e6.2\u003c/span\u003e])\nax = plt.\u003cspan class=\"hljs-title function_\"\u003egca\u003c/span\u003e()\nax.\u003cspan class=\"hljs-title function_\"\u003eset_aspect\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'equal'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'$x_1$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'$x_2$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e하지만 2차원 공간에서 결정 경계를 어떻게 찾을까요? 이를 위해 2차원 공간의 모든 점을 찾아야 합니다. 이러한 점들은 1차원 공간의 원점으로 매핑됩니다 (Figure 8의 점 o). Figure 9에서 이러한 점들을 찾을 수 있는 방법을 보여줍니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e여기서는 x라는 지점을 찾고 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_23.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e이러한 점들은 x^에서 l에 수직인 선상에 있습니다. 우리는 이 선을 s로 표시할 것입니다 (도표 9). 모든 점들이 2차원 평면의 원점으로부터의 거리는 |w₀| / ||w||입니다(점과 선 사이의 거리는 그 선에 수직이고 해당 점을 통과하는 선분의 길이입니다). 이제 s의 모든 점들에 대한 벡터 d는 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_24.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e따라서 데이터 지점이 선 s에 있으면, 해당 변환된 지점은 지점 o(1차원 공간의 원점)에 있고, 그 확률은 0.5가 됩니다. 이로써 선 s가 2차원 공간의 로지스틱 회귀의 결정 경계라는 것을 결론짓게 되었습니다. 왜냐하면 이 선 상의 모든 데이터 지점은 1차원 공간의 시그모이드 곡선의 결정 경계로 매핑되기 때문입니다. 따라서 이제 우리 모델의 결정 경계를 쉽게 그릴 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eboundary_point = (-w0 / length_w**\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e) * w\n\nplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\n\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=0\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"red\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=1\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, s=\u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e)\n# 벡터 w 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003equiver\u003c/span\u003e([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=[\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e],\n           width=\u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e, angles=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale_units=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003equiver\u003c/span\u003e([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=[\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e],\n           width=\u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e, angles=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale_units=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\n# 결정 경계 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]-\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e],\n         [boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]-\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e*(-w1/w2)],\n         color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linestyle=\u003cspan class=\"hljs-string\"\u003e\"--\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e],\n         [boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e*(-w1/w2)],\n         color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linestyle=\u003cspan class=\"hljs-string\"\u003e\"--\"\u003c/span\u003e)\n\n# 시그모이드 곡선 그리기\nk = \u003cspan class=\"hljs-number\"\u003e200\u003c/span\u003e\nl_array = np.\u003cspan class=\"hljs-title function_\"\u003elinspace\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e8.4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, k).\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\nw_array = l_array * np.\u003cspan class=\"hljs-title function_\"\u003etile\u003c/span\u003e(u, (k, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n\n# 벡터 w를 따른 선 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e9\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]],\n         [-\u003cspan class=\"hljs-number\"\u003e9\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]], color=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e)\n\nsigm_x_array = ((w_array - o) /u)[:,\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\nsigm_prob = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e / (\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e+np.\u003cspan class=\"hljs-title function_\"\u003eexp\u003c/span\u003e(-sigm_x_array))\nnorm_vector = np.\u003cspan class=\"hljs-title function_\"\u003earray\u003c/span\u003e([-w2, w1]) \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e w1\u003e=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e np.\u003cspan class=\"hljs-title function_\"\u003earray\u003c/span\u003e([w2, -w1])\nsigm_y_array = sigm_prob.\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e(k, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) * np.\u003cspan class=\"hljs-title function_\"\u003etile\u003c/span\u003e(norm_vector, (k, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\nsigm_curve_array = sigm_y_array + w_array\n\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(sigm_curve_array[:, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], sigm_curve_array[:, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n# 시그모이드 곡선의 y축 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e*norm_vector[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]],\n         [o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], o[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e*norm_vector[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]], color=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e)\n\n# 축 그리기\nplt.\u003cspan class=\"hljs-title function_\"\u003eaxhline\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'grey'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eaxvline\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'grey'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.35\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\mathregular{w}$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e0.95\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e1.35\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\mathregular{o}$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e3.15\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$P$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e, rotation = \u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"결정 경계\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, r\u003cspan class=\"hljs-string\"\u003e\"$\\frac{-w_0}{\\mathregular{||w||^2}\\mathregular{w}$\"\u003c/span\u003e,\n         color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e15\u003c/span\u003e, weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\n\n\nplt.\u003cspan class=\"hljs-title function_\"\u003exlim\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e5.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4.2\u003c/span\u003e])\nplt.\u003cspan class=\"hljs-title function_\"\u003eylim\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e5.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4.2\u003c/span\u003e])\nax = plt.\u003cspan class=\"hljs-title function_\"\u003egca\u003c/span\u003e()\nax.\u003cspan class=\"hljs-title function_\"\u003eset_aspect\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'equal'\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'$x_1$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'$x_2$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e우리는 또한 여기서 발견한 결정 경계의 위치를 유효성 검사할 수 있습니다. 이를 위해 모델의 경계를 다른 방법을 사용하여 그리는 함수를 정의합니다. 먼저 2차원 공간에 메시 그리드를 생성하고 이를 사용하여 훈련된 로지스틱 회귀 모델을 사용하여 해당 지점의 목표를 예측합니다. y^=0 및 y^=1인 지점은 서로 다른 색으로 표시되므로 그리드가 충분히 잘 그려진 경우 모델의 결정 경계를 쉽게 확인할 수 있습니다. 결과는 Figure 11에 나와 있으며 이전에 발견한 결정 경계와 일치합니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef \u003cspan class=\"hljs-title function_\"\u003eplot_boundary\u003c/span\u003e(X, y, clf, lims):\n    gx1, gx2 = np.\u003cspan class=\"hljs-title function_\"\u003emeshgrid\u003c/span\u003e(np.\u003cspan class=\"hljs-title function_\"\u003earange\u003c/span\u003e(lims[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], lims[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], (lims[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]-lims[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e])/\u003cspan class=\"hljs-number\"\u003e300.0\u003c/span\u003e),\n                           np.\u003cspan class=\"hljs-title function_\"\u003earange\u003c/span\u003e(lims[\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e], lims[\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e], (lims[\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e]-lims[\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e])/\u003cspan class=\"hljs-number\"\u003e300.0\u003c/span\u003e))\n    \n    cmap_light = \u003cspan class=\"hljs-title class_\"\u003eListedColormap\u003c/span\u003e([\u003cspan class=\"hljs-string\"\u003e'lightsalmon'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'aqua'\u003c/span\u003e])\n            \n    gx1l = gx1.\u003cspan class=\"hljs-title function_\"\u003eflatten\u003c/span\u003e()\n    gx2l = gx2.\u003cspan class=\"hljs-title function_\"\u003eflatten\u003c/span\u003e()\n    gx = np.\u003cspan class=\"hljs-title function_\"\u003evstack\u003c/span\u003e((gx1l,gx2l)).\u003cspan class=\"hljs-property\"\u003eT\u003c/span\u003e\n    gyhat = clf.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(gx)\n    gyhat = gyhat.\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e(gx1.\u003cspan class=\"hljs-property\"\u003eshape\u003c/span\u003e)\n\n    plt.\u003cspan class=\"hljs-title function_\"\u003epcolormesh\u003c/span\u003e(gx1, gx2, gyhat, cmap=cmap_light)\n    plt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=0\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"red\"\u003c/span\u003e)\n    plt.\u003cspan class=\"hljs-title function_\"\u003escatter\u003c/span\u003e(X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], X[y==\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], label=\u003cspan class=\"hljs-string\"\u003e\"y=1\"\u003c/span\u003e, alpha=\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e\"blue\"\u003c/span\u003e)\n    plt.\u003cspan class=\"hljs-title function_\"\u003elegend\u003c/span\u003e(loc=\u003cspan class=\"hljs-string\"\u003e'upper left'\u003c/span\u003e)\n\n\nplt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e,\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e))\n\u003cspan class=\"hljs-title function_\"\u003eplot_boundary\u003c/span\u003e(X,y,lg, lims=[-\u003cspan class=\"hljs-number\"\u003e5.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4.2\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e5.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4.2\u003c/span\u003e])\n\n# \u003cspan class=\"hljs-title class_\"\u003ePlot\u003c/span\u003e the vector w\nplt.\u003cspan class=\"hljs-title function_\"\u003equiver\u003c/span\u003e([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], w[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=[\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e],\n           width=\u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e, angles=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale_units=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003equiver\u003c/span\u003e([\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], [\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], color=[\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e],\n           width=\u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e, angles=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale_units=\u003cspan class=\"hljs-string\"\u003e'xy'\u003c/span\u003e, scale=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, zorder=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\n# plot the decision boundary\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]-\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e],\n         [boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]-\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e*(-w1/w2)],\n         color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linestyle=\u003cspan class=\"hljs-string\"\u003e\"--\"\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e],\n         [boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], boundary_point[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]+\u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e*(-w1/w2)],\n         color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, linestyle=\u003cspan class=\"hljs-string\"\u003e\"--\"\u003c/span\u003e)\n\n# \u003cspan class=\"hljs-title class_\"\u003ePlot\u003c/span\u003e the line along the vector w\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e9\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]],\n         [-\u003cspan class=\"hljs-number\"\u003e9\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e*u[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]], color=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e)\n\n# \u003cspan class=\"hljs-title class_\"\u003eDraw\u003c/span\u003e axes\nplt.\u003cspan class=\"hljs-title function_\"\u003eaxhline\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'grey'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eaxvline\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'grey'\u003c/span\u003e, linewidth=\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.35\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\mathregular{w}$\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'b'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e,\n         weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\hat{y}=1$\\nregion\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'blue'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"$\\hat{y}=0$\\nregion\"\u003c/span\u003e, color=\u003cspan class=\"hljs-string\"\u003e'red'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etext\u003c/span\u003e(-\u003cspan class=\"hljs-number\"\u003e0.3\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e0.7\u003c/span\u003e, r\u003cspan class=\"hljs-string\"\u003e\"$\\frac{-w_0}{\\mathregular{||w||^2}\\mathregular{w}$\"\u003c/span\u003e,\n         color=\u003cspan class=\"hljs-string\"\u003e'black'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e15\u003c/span\u003e, weight=\u003cspan class=\"hljs-string\"\u003e\"bold\"\u003c/span\u003e, style=\u003cspan class=\"hljs-string\"\u003e\"italic\"\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003exlim\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e5.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4.2\u003c/span\u003e])\nplt.\u003cspan class=\"hljs-title function_\"\u003eylim\u003c/span\u003e([-\u003cspan class=\"hljs-number\"\u003e5.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4.2\u003c/span\u003e])\nax = plt.\u003cspan class=\"hljs-title function_\"\u003egca\u003c/span\u003e()\nax.\u003cspan class=\"hljs-title function_\"\u003eset_aspect\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'equal'\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'$x_1$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'$x_2$'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_26.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e여기에 결과를 요약해보겠습니다. 두 가지 특성을 갖는 데이터셋에서 로지스틱 회귀 모델의 의사결정 경계는 직선으로 형성됩니다. 이 직선은 모델의 매개변수 w₀, w₁, w₂에 의해 결정됩니다. 의사결정 경계는 벡터를 연장한 선에 수직입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_27.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이 라인과 의사결정 경계의 교차점은 (-w₀ / ||w||²)w 벡터에 의해 결정됩니다.\u003c/p\u003e\n\u003cp\u003e고차원에서의 의사결정 경계\u003c/p\u003e\n\u003cp\u003e저희가 데이터셋에서 더 많은 피쳐를 가지고 있는 경우에 어떻게 될지 살펴봅시다. 우리는 같은 컨셉을 고차원으로 쉽게 적용할 수 있습니다. x₁, x₂, x₃라는 세 개의 피쳐를 가지고 있다고 상상해보겠습니다. 이제 로지스틱 회귀 방정식은 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e모델 매개변수는 w₀, w₁, w₂ 및 w₃입니다. 차원 축소 부분은 동일하며, 원본 데이터 포인트는 여전히 1차원 공간에 매핑됩니다. 변환된 데이터 포인트는 여전히 직선 l 상에 있으며 해당 벡터를 확장합니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_29.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e결정 경계는 w로의 벡터 투영이 (-w₀ / ||w||²)w인 모든 포인트의 위치입니다. 이러한 포인트는 차원 축소 후 P=0.5를 갖게 됩니다. 따라서 결정 경계는 3차원 공간에서 평면입니다(도 12 참조). 이 평면은 l에 수직이며, l과의 교차점은 (-w₀ / ||w||²)w 벡터로 주어집니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_30.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e보다 일반적으로, n차원 공간에서 로지스틱 회귀 모델은 n개의 매개변수 w₀, w₁, …, w_n을 가지고 있습니다. 여기에서, 만약 벡터를 확장한다면,\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_31.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e선 l로, 결정 경계는 n차원 초평면입니다. 이 초평면은 l에 수직이며, (-w₀ / ||w||²)w 벡터는 초평면과 l의 교차점을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e로지스틱 회귀는 항상 n차원 공간에서 1차원 공간으로 차원 축소를 시작합니다. 따라서 그 결정 경계는 곡률이 없는 초평면입니다. 결정 경계가 초평면인 분류기는 선형 분류기라고 하며, 로지스틱 회귀는 그러한 분류기의 한 예입니다. 다른 예시로는 퍼셉트론과 서포트 벡터 머신(SVM)이 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e데이터 세트(특성이 n개 있는)는 이진 대상을 가지고 있고 n차원 초평면을 사용하여 서로 다른 라벨을 가진 데이터 포인트들을 완전히 분리할 수 있다면 선형 분리 가능하다고 합니다. 따라서 선형 분류기는 선형 분리 가능한 데이터 세트에 대한 완벽한 모델입니다. 지금까지 사용된 토이 데이터 세트는 선형 분리 가능했습니다(Figure 1), 그러나 많은 데이터 세트는 선형 분리가 불가능하며 로지스틱 회귀와 같은 모델은 그에 적합하지 않을 수 있습니다. Figure 13는 선형 분리가 불가능한 데이터 세트의 예시를 보여줍니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-AVisualUnderstandingofLogisticRegression_32.png\" alt=\"Figure 13\"\u003e\u003c/p\u003e\n\u003cp\u003e여기서 데이터 세트는 원 모양을 가지고 있으며, 직선을 사용하여 y=0 및 y=1을 가진 데이터 포인트들을 완벽하게 나눌 수 없습니다. 따라서 이러한 분류 문제에 로지스틱 회귀 모델을 사용할 수 없습니다.\u003c/p\u003e\n\u003cp\u003e이 기사에서는 선형 대수를 사용하여 로지스틱 회귀의 시각적 해석을 제공하려고 노력했습니다. 로지스틱 회귀는 1차원 공간으로의 차원 축소부터 시작하고, 그런 다음 변환된 데이터 포인트에 대한 확률을 할당합니다. 확률 임계값을 정의함으로써, 해당 데이터 포인트의 이진 대상에 대한 최종 예측을 얻을 수 있습니다. 1차원 공간으로의 차원 축소로 인해 로지스틱 회귀는 선형 분류기가 됩니다. 따라서 n개의 특성을 가진 데이터 세트에 적용되는 경우 의사 결정 경계는 n차원 초평면이 됩니다.\u003c/p\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp\u003e이 기사를 즐겁게 읽었으면 좋겠어요. 제 기사가 도움이 된다면, 저를 Medium에서 팔로우해 주세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-18-AVisualUnderstandingofLogisticRegression"},"buildId":"bb_yO9GbCvdfc_n71SfUf","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>