<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>인공지능 얼굴 인식 금지 조치의 해결책 및 경찰에서 불량한 인공지능 제품의 위험 요소 | ui-station</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://ui-station.github.io///post/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="인공지능 얼굴 인식 금지 조치의 해결책 및 경찰에서 불량한 인공지능 제품의 위험 요소 | ui-station" data-gatsby-head="true"/><meta property="og:title" content="인공지능 얼굴 인식 금지 조치의 해결책 및 경찰에서 불량한 인공지능 제품의 위험 요소 | ui-station" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://ui-station.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://ui-station.github.io///post/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement" data-gatsby-head="true"/><meta name="twitter:title" content="인공지능 얼굴 인식 금지 조치의 해결책 및 경찰에서 불량한 인공지능 제품의 위험 요소 | ui-station" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | ui-station" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-20 21:29" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-561ae49ab5aab7f5.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_buildManifest.js" defer=""></script><script src="/_next/static/ll1cGyplNwh83dpggeai1/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">UI STATION</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">인공지능 얼굴 인식 금지 조치의 해결책 및 경찰에서 불량한 인공지능 제품의 위험 요소</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="인공지능 얼굴 인식 금지 조치의 해결책 및 경찰에서 불량한 인공지능 제품의 위험 요소" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">UI STATION</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 20, 2024</span><span class="posts_reading_time__f7YPP">3<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><p><img src="/assets/img/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement_0.png" alt="Workaround of AI Facial Recognition Bans and the Pitfalls of Defective AI Products in Law Enforcement"/></p>
<p>지역 경찰이 얼굴 인식 기술 사용을 금지하는 오스틴과 샌프란시스코와 같은 도시들이 이를 시행함에 따라, 수사기관은 경찰 내 피해가 감지되는 기술의 더 큰 문제를 강조하는 회피 방법을 찾고 있습니다. 이 기사에서는 경찰이 이러한 금지 조치를 우회하기 위해 사용하는 방법, Clearview AI와 같은 기술에서 내재된 부정확성 및 COMPAS와 같은 알고리즘 도구의 불투명한 사용 등을 탐구합니다.</p>
<div class="content-ad"></div>
<p>페이셜 인식 기술이 금지된 도시들에서는 경찰 사무소가 해당 제한이 없는 인접 지역의 담당자들과 협력했습니다. 이 협력은 일반적으로 용의자 이미지를 식별 목적으로 공유함을 포함하며, 현지 금지 조항을 우회하는 효과를 냅니다. 이러한 실천은 로컬 규정의 효과성 뿐만 아니라 중요한 프라이버시 및 시민 자유 우려를 제기합니다.</p>
<p>출처: 워싱턴 포스트의 경찰 문서 검토</p>
<p>Clearview AI의 결함</p>
<p>경찰이 사용하기 위해 검토된 AI 기술 중 Clearview AI는 수십억 장의 인터넷 이미지를 스크래핑하는 방식과 그 얼굴 인식 알고리즘의 부정확성으로 인해 상당한 비판을 받았습니다. 특히 이 소프트웨어는 범죄 기록이 없는 공인 인물과 국회의원을 잘못 식별하여 범죄자로 지목했는데, 이는 그 신뢰성의 심각한 결함과 해로운 잘못된 식별의 가능성을 강조하고 있습니다.</p>
<div class="content-ad"></div>
<p>소스: Clearview AI에 대한 공개 기록 및 입법 청문회.</p>
<p>COMPAS 및 &quot;블랙박스&quot; 딜레마</p>
<p>주목할만한 윈콘신 주 대 루미스 사건 등 사법 환경에서 COMPAS 소프트웨어를 사용하는 것은, 수사 기관에 문제가 있는 AI 응용 프로그램의 또 다른 차원을 보여줍니다. 피의자의 재범 가능성을 평가하기 위해 사용되는 COMPAS는 위험 평가에 영향을 미치는 요소에 대해 적은 투명성을 가지고 &quot;블랙박스&quot;로 작동하며, 이는 판결 실천에서 공정성과 책임성 문제를 제기합니다.</p>
<p>소스: 윈콘신 주 최고 법원 문서 및 법률 제도에 관한 AI 투명성에 대한 학술 분석.</p>
<div class="content-ad"></div>
<p>윤리 및 개인 정보 보호 문제</p>
<p>법 집행에서 AI 기술을 도입하는 것은 다양한 윤리적 및 개인 정보 보호 문제와 교차합니다. 이에는 얼굴 인식 기술의 인종적 편향, 데이터의 비동의적 수집에 대한 우려, 그리고 적절한 투명성과 감시 없이 이루어지는 감시의 보다 광범위한 영향 등이 포함됩니다.</p>
<p>출처: 학술 연구 및 개인 정보 보호 단체 보고서.</p>
<p>AI 및 법 집행에 대한 디스토피아적 시각</p>
<div class="content-ad"></div>
<p>점점 더 디스토피아 소설의 어둠 같은 상황 속에서, 경찰 조직에서 AI 기술을 도입하는 것은 디지털 시대의 대첩 정보기술 전술로 해석될 수 있는 냉혹한 방향을 향하고 있습니다. 오스틴과 샌프란시스코와 같은 도시들은 얼굴 인식 기술 금지법을 발포했지만, 이웃 지역의 경찰 부서들과의 협력을 활용하는 경찰 부서들에 의해 권모술수로 물리쳐지고 있습니다. 이 전략적 우회는 전체주의 국가에서 기대할 수 있는 모습과 뼈아픈 유사성을 보여주며, 지역 민주주의 결정의 본질을 획기적으로 훼손시키며 공공안전의 입장으로 공정 절차 권리를 침해할 가능성이 있습니다.</p>
<p>게다가, COMPAS와 같은 AI 시스템의 그림자 같은 오퍼레이션은 사법 체계에 오웰리안 통제의 또 다른 층을 더합니다. 이 &quot;흑색 상자&quot; 도구들은 개인들의 운명을 결정하지만 그들에게 그 근거를 이해하거나 논의하거나 묻는 권리를 부여하지 않습니다. 알고리즘 판결에서의 투명성과 책임감의 부재는 개인들의 권리를 제거할 뿐만 아니라 정의의 개념 자체에 어두운 그림자를 드리우고 있습니다.</p>
<p>이 길을 더욱 탐험할수록, 정의와 개인의 자유 원칙 자체가 위험에 처합니다. 문제는 새로운 도구들을 범죄와의 전투를 위한 도구로 채택하는 것뿐만이 아니라, 디스토피아 사회로의 첫걸음으로 볼 수 있는 무관심하고 책임감 없는 알고리즘 통치가 대신하고 있는 점입니다. 이 현실 세계 시나리오에서, 기술의 자기 과도한 확장에 사로잡힌 사회는 현재의 현실과 일맥상통합니다 — 기술이 단순한 도구가 아니라 사람의 효율성에 대한 비인간적이고 냉소적인 권위자로 변모합니다. 이것은 단지 범죄에 대항하기 위한 새로운 도구의 채택이 아니라, 개인과 국가 간의 관계의 본질적 재편이며, 이는 사회 구조 자체를 영구적으로 바꿀 수 있는 변화일 수 있습니다. 1984년 아무도?</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"인공지능 얼굴 인식 금지 조치의 해결책 및 경찰에서 불량한 인공지능 제품의 위험 요소","description":"","date":"2024-05-20 21:29","slug":"2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement","content":"\n\n\n![Workaround of AI Facial Recognition Bans and the Pitfalls of Defective AI Products in Law Enforcement](/assets/img/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement_0.png)\n\n지역 경찰이 얼굴 인식 기술 사용을 금지하는 오스틴과 샌프란시스코와 같은 도시들이 이를 시행함에 따라, 수사기관은 경찰 내 피해가 감지되는 기술의 더 큰 문제를 강조하는 회피 방법을 찾고 있습니다. 이 기사에서는 경찰이 이러한 금지 조치를 우회하기 위해 사용하는 방법, Clearview AI와 같은 기술에서 내재된 부정확성 및 COMPAS와 같은 알고리즘 도구의 불투명한 사용 등을 탐구합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n페이셜 인식 기술이 금지된 도시들에서는 경찰 사무소가 해당 제한이 없는 인접 지역의 담당자들과 협력했습니다. 이 협력은 일반적으로 용의자 이미지를 식별 목적으로 공유함을 포함하며, 현지 금지 조항을 우회하는 효과를 냅니다. 이러한 실천은 로컬 규정의 효과성 뿐만 아니라 중요한 프라이버시 및 시민 자유 우려를 제기합니다.\n\n출처: 워싱턴 포스트의 경찰 문서 검토\n\nClearview AI의 결함\n\n경찰이 사용하기 위해 검토된 AI 기술 중 Clearview AI는 수십억 장의 인터넷 이미지를 스크래핑하는 방식과 그 얼굴 인식 알고리즘의 부정확성으로 인해 상당한 비판을 받았습니다. 특히 이 소프트웨어는 범죄 기록이 없는 공인 인물과 국회의원을 잘못 식별하여 범죄자로 지목했는데, 이는 그 신뢰성의 심각한 결함과 해로운 잘못된 식별의 가능성을 강조하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n소스: Clearview AI에 대한 공개 기록 및 입법 청문회.\n\nCOMPAS 및 \"블랙박스\" 딜레마\n\n주목할만한 윈콘신 주 대 루미스 사건 등 사법 환경에서 COMPAS 소프트웨어를 사용하는 것은, 수사 기관에 문제가 있는 AI 응용 프로그램의 또 다른 차원을 보여줍니다. 피의자의 재범 가능성을 평가하기 위해 사용되는 COMPAS는 위험 평가에 영향을 미치는 요소에 대해 적은 투명성을 가지고 \"블랙박스\"로 작동하며, 이는 판결 실천에서 공정성과 책임성 문제를 제기합니다.\n\n소스: 윈콘신 주 최고 법원 문서 및 법률 제도에 관한 AI 투명성에 대한 학술 분석.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n윤리 및 개인 정보 보호 문제\n\n법 집행에서 AI 기술을 도입하는 것은 다양한 윤리적 및 개인 정보 보호 문제와 교차합니다. 이에는 얼굴 인식 기술의 인종적 편향, 데이터의 비동의적 수집에 대한 우려, 그리고 적절한 투명성과 감시 없이 이루어지는 감시의 보다 광범위한 영향 등이 포함됩니다.\n\n출처: 학술 연구 및 개인 정보 보호 단체 보고서.\n\nAI 및 법 집행에 대한 디스토피아적 시각\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n점점 더 디스토피아 소설의 어둠 같은 상황 속에서, 경찰 조직에서 AI 기술을 도입하는 것은 디지털 시대의 대첩 정보기술 전술로 해석될 수 있는 냉혹한 방향을 향하고 있습니다. 오스틴과 샌프란시스코와 같은 도시들은 얼굴 인식 기술 금지법을 발포했지만, 이웃 지역의 경찰 부서들과의 협력을 활용하는 경찰 부서들에 의해 권모술수로 물리쳐지고 있습니다. 이 전략적 우회는 전체주의 국가에서 기대할 수 있는 모습과 뼈아픈 유사성을 보여주며, 지역 민주주의 결정의 본질을 획기적으로 훼손시키며 공공안전의 입장으로 공정 절차 권리를 침해할 가능성이 있습니다.\n\n게다가, COMPAS와 같은 AI 시스템의 그림자 같은 오퍼레이션은 사법 체계에 오웰리안 통제의 또 다른 층을 더합니다. 이 \"흑색 상자\" 도구들은 개인들의 운명을 결정하지만 그들에게 그 근거를 이해하거나 논의하거나 묻는 권리를 부여하지 않습니다. 알고리즘 판결에서의 투명성과 책임감의 부재는 개인들의 권리를 제거할 뿐만 아니라 정의의 개념 자체에 어두운 그림자를 드리우고 있습니다.\n\n이 길을 더욱 탐험할수록, 정의와 개인의 자유 원칙 자체가 위험에 처합니다. 문제는 새로운 도구들을 범죄와의 전투를 위한 도구로 채택하는 것뿐만이 아니라, 디스토피아 사회로의 첫걸음으로 볼 수 있는 무관심하고 책임감 없는 알고리즘 통치가 대신하고 있는 점입니다. 이 현실 세계 시나리오에서, 기술의 자기 과도한 확장에 사로잡힌 사회는 현재의 현실과 일맥상통합니다 — 기술이 단순한 도구가 아니라 사람의 효율성에 대한 비인간적이고 냉소적인 권위자로 변모합니다. 이것은 단지 범죄에 대항하기 위한 새로운 도구의 채택이 아니라, 개인과 국가 간의 관계의 본질적 재편이며, 이는 사회 구조 자체를 영구적으로 바꿀 수 있는 변화일 수 있습니다. 1984년 아무도?","ogImage":{"url":"/assets/img/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement_0.png"},"coverImage":"/assets/img/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement_0.png","tag":["Tech"],"readingTime":3},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement_0.png\",\n        alt: \"Workaround of AI Facial Recognition Bans and the Pitfalls of Defective AI Products in Law Enforcement\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"지역 경찰이 얼굴 인식 기술 사용을 금지하는 오스틴과 샌프란시스코와 같은 도시들이 이를 시행함에 따라, 수사기관은 경찰 내 피해가 감지되는 기술의 더 큰 문제를 강조하는 회피 방법을 찾고 있습니다. 이 기사에서는 경찰이 이러한 금지 조치를 우회하기 위해 사용하는 방법, Clearview AI와 같은 기술에서 내재된 부정확성 및 COMPAS와 같은 알고리즘 도구의 불투명한 사용 등을 탐구합니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"페이셜 인식 기술이 금지된 도시들에서는 경찰 사무소가 해당 제한이 없는 인접 지역의 담당자들과 협력했습니다. 이 협력은 일반적으로 용의자 이미지를 식별 목적으로 공유함을 포함하며, 현지 금지 조항을 우회하는 효과를 냅니다. 이러한 실천은 로컬 규정의 효과성 뿐만 아니라 중요한 프라이버시 및 시민 자유 우려를 제기합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"출처: 워싱턴 포스트의 경찰 문서 검토\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Clearview AI의 결함\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"경찰이 사용하기 위해 검토된 AI 기술 중 Clearview AI는 수십억 장의 인터넷 이미지를 스크래핑하는 방식과 그 얼굴 인식 알고리즘의 부정확성으로 인해 상당한 비판을 받았습니다. 특히 이 소프트웨어는 범죄 기록이 없는 공인 인물과 국회의원을 잘못 식별하여 범죄자로 지목했는데, 이는 그 신뢰성의 심각한 결함과 해로운 잘못된 식별의 가능성을 강조하고 있습니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"소스: Clearview AI에 대한 공개 기록 및 입법 청문회.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"COMPAS 및 \\\"블랙박스\\\" 딜레마\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"주목할만한 윈콘신 주 대 루미스 사건 등 사법 환경에서 COMPAS 소프트웨어를 사용하는 것은, 수사 기관에 문제가 있는 AI 응용 프로그램의 또 다른 차원을 보여줍니다. 피의자의 재범 가능성을 평가하기 위해 사용되는 COMPAS는 위험 평가에 영향을 미치는 요소에 대해 적은 투명성을 가지고 \\\"블랙박스\\\"로 작동하며, 이는 판결 실천에서 공정성과 책임성 문제를 제기합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"소스: 윈콘신 주 최고 법원 문서 및 법률 제도에 관한 AI 투명성에 대한 학술 분석.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"윤리 및 개인 정보 보호 문제\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"법 집행에서 AI 기술을 도입하는 것은 다양한 윤리적 및 개인 정보 보호 문제와 교차합니다. 이에는 얼굴 인식 기술의 인종적 편향, 데이터의 비동의적 수집에 대한 우려, 그리고 적절한 투명성과 감시 없이 이루어지는 감시의 보다 광범위한 영향 등이 포함됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"출처: 학술 연구 및 개인 정보 보호 단체 보고서.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"AI 및 법 집행에 대한 디스토피아적 시각\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"점점 더 디스토피아 소설의 어둠 같은 상황 속에서, 경찰 조직에서 AI 기술을 도입하는 것은 디지털 시대의 대첩 정보기술 전술로 해석될 수 있는 냉혹한 방향을 향하고 있습니다. 오스틴과 샌프란시스코와 같은 도시들은 얼굴 인식 기술 금지법을 발포했지만, 이웃 지역의 경찰 부서들과의 협력을 활용하는 경찰 부서들에 의해 권모술수로 물리쳐지고 있습니다. 이 전략적 우회는 전체주의 국가에서 기대할 수 있는 모습과 뼈아픈 유사성을 보여주며, 지역 민주주의 결정의 본질을 획기적으로 훼손시키며 공공안전의 입장으로 공정 절차 권리를 침해할 가능성이 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"게다가, COMPAS와 같은 AI 시스템의 그림자 같은 오퍼레이션은 사법 체계에 오웰리안 통제의 또 다른 층을 더합니다. 이 \\\"흑색 상자\\\" 도구들은 개인들의 운명을 결정하지만 그들에게 그 근거를 이해하거나 논의하거나 묻는 권리를 부여하지 않습니다. 알고리즘 판결에서의 투명성과 책임감의 부재는 개인들의 권리를 제거할 뿐만 아니라 정의의 개념 자체에 어두운 그림자를 드리우고 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 길을 더욱 탐험할수록, 정의와 개인의 자유 원칙 자체가 위험에 처합니다. 문제는 새로운 도구들을 범죄와의 전투를 위한 도구로 채택하는 것뿐만이 아니라, 디스토피아 사회로의 첫걸음으로 볼 수 있는 무관심하고 책임감 없는 알고리즘 통치가 대신하고 있는 점입니다. 이 현실 세계 시나리오에서, 기술의 자기 과도한 확장에 사로잡힌 사회는 현재의 현실과 일맥상통합니다 — 기술이 단순한 도구가 아니라 사람의 효율성에 대한 비인간적이고 냉소적인 권위자로 변모합니다. 이것은 단지 범죄에 대항하기 위한 새로운 도구의 채택이 아니라, 개인과 국가 간의 관계의 본질적 재편이며, 이는 사회 구조 자체를 영구적으로 바꿀 수 있는 변화일 수 있습니다. 1984년 아무도?\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-20-WorkaroundofAIFacialRecognitionBansandthePitfallsofDefectiveAIProductsinLawEnforcement"},"buildId":"ll1cGyplNwh83dpggeai1","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>